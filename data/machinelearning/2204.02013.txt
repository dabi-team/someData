RL4ReAl: Reinforcement Learning for Register Allocation

S. VenkataKeerthy1 , Siddharth Jain1 , Rohit Aggarwal1 , Albert
Cohen2 and Ramakrishna Upadrasta1
1Indian Institute of Technology Hyderabad
2Google
{cs17m20p100001, cs20mtech12003, cs18mtech11030}@iith.ac.in, albertcohen@google.com,
ramakrishna@cse.iith.ac.in

2
2
0
2

r
p
A
5

]

G
L
.
s
c
[

1
v
3
1
0
2
0
.
4
0
2
2
:
v
i
X
r
a

Abstract

We propose a novel solution for the Register Al-
location problem, leveraging multi-agent hier-
archical Reinforcement Learning. We formalize
the constraints that precisely deﬁne the prob-
lem for a given instruction-set architecture,
while ensuring that the generated code pre-
serves semantic correctness. We also develop
a gRPC based framework providing a modu-
lar and eﬃcient compiler interface for training
and inference. Experimental results match or
outperform the LLVM register allocators, tar-
geting Intel x86 and ARM AArch64.

1

Introduction

Register allocation is one of the well-studied and im-
portant compiler optimization problems. It involves as-
signing a ﬁnite set of registers to an unbounded set of
variables. Its decision problem is reducible to graph col-
oring, which is one of the classical NP-Complete prob-
lems [Garey and Johnson, 1979; Bouchez et al., 2006].
Register allocation as an optimization involves addi-
tional sub-tasks, upstream and downstream from graph
coloring itself. Several formulations have been proposed
that return exact, or heuristic-based solutions.

Broadly, the optimal solutions are often formulated
as constraint-based optimizations [Lozano et al., 2012;
Kuchcinski, 2003], ILP formulations [Appel and George,
2001; Barik et al., 2006; Chang et al., 1997; Nagarakatte
and Govindarajan, 2007], PBQP formulations [Kim et
al., 2021], and are fed to a variety of solvers. These
approaches are known to have scalability issues.

On the other hand, several heuristic-based approaches
also exist. They have been widely used in modern com-
pilers owing to their scalability: good solutions for prac-
tical benchmarks in near linear time. However, de-
veloping good heuristics is highly non-trivial and re-
quires very specialized domain expertise, on compiler
construction as well as on hardware architecture. Var-
ious heuristics have been proposed over the past 40
years [Chaitin et al., 1981; Chow and Hennessy, 1990;
Briggs et al., 1994], extending to recent times [Chen et

al., 2018]. They are often ﬁne-tuned for a particular
architecture and give non-optimal performance.

Recently, with the success of Machine Learning (ML)
in several domains, ML-based approaches are being pro-
posed to solve compiler optimization problems that have
been known to be computationally expensive. Anal-
ogous to that of natural language representations like
word2vec [Mikolov et al., 2013], and GloVe [Penning-
ton et al., 2014], several approaches have been proposed
to represent programs as information-rich embeddings:
inst2vec [Ben-Nun et al., 2018], IR2Vec [VenkataKeerthy
et al., 2020], Flow2Vec [Sui et al., 2020]. These ap-
proaches have been applied to classical optimizations
like phase ordering of optimization passes [Fursin and
others, 2011; Ashouri et al., 2017], function inlining deci-
sions [Simon et al., 2013], throughput prediction [Mendis
et al., 2019a], etc., where correctness is not an issue.
However, they remain to be applied to compiler opti-
mizations under hard semantic constraints, such as reg-
ister allocation. We believe this did not happen yet be-
cause of some of the following reasons.

• Register allocation is a complex problem, composed
of multiple sub-tasks, including splitting, coalescing,
spilling. These sub-tasks all have to considered in
addition to modeling hardware complexities.

• ML-based allocation schemes should ensure correct-
ness; no two variables in the same live range be as-
signed to the same register, and the register types
Such semantic constraints
should be respected.
should not suﬀer any approximation, unlike forget-
ful optimizations like function inlining decisions.
• On the practical side, it is hard to integrate ML
solutions with modern compiler frameworks where
the ML solutions are often written in Python and
compilers are written in C++ and are among the
most complex software engineering architectures. It
is a challenging engineering problem.

In this work, we propose a retargetable Reinforce-
ment Learning (RL) register allocator addressing the
above mentioned challenges. Our approach ﬁnds a mid-
dle ground between the heuristic-based and exact solu-
tions in terms of scalability and performance. We for-
mulate a multi-agent hierarchical reinforcement learning
approach (1) to model the sub-tasks of register allocation

 
 
 
 
 
 
like coloring, live range splitting and spilling, and (2) to
encode the correctness constraints for semantically pre-
serving and hardware-compatible register assignments.
The legality of the register allocations and assignments
is preserved by imposing constraints on the action space,
or outcome of each agent. Formulating register alloca-
tion as an RL approach is more natural, as it results in
a complex combinatorial problem for which establishing
the ground truth is hard. Also, imposing correctness
constraints would otherwise be not possible.

We leverage the LLVM infrastructure [Lattner and
Adve, 2004]. The interference graph of a function is ex-
tracted from the Machine Intermediate Representation
(MIR) of LLVM, representing the instructions within
each node as IR2Vec vectors [VenkataKeerthy et al.,
2020]. For this, we extend IR2Vec to generate embed-
dings for MIR entities. These embeddings represent ver-
tices of the interference graph which is traversed by RL
agents. Finally, we propose a generic gRPC-based frame-
work (https://grpc.io) to interface the RL model with
the compiler.

Earlier works [Huang et al., 2019a; Lemos et al., 2019;
Musliu and Schwengerer, 2013] addressed the conven-
tional graph coloring problem using ML. However, these
approaches may not result in a practical register alloca-
tion scheme: they only solve one sub-task of the overall
problem, and do not exploit semantic information such
as live ranges to arrive at the ﬁnal coloring and spilling
decisions.

Das et al. [2020] investigated the usage of LSTM for
register allocation. They use ML to construct an initial
graph coloring, which then undergoes a correction phase
to rectify inconsistencies in coloring interfering nodes.
Their work focuses on graph coloring alone, and to our
understanding it was not integrated in a compiler to pro-
duce actual spilling decisions and register assignments.

Contributions

• We propose the ﬁrst end-to-end application of RL

for solving the register allocation problem.

• Formalizing the constraints to restrict the action

space and preserve semantic correctness.

• MIR2Vec encodings to generate representations at

Machine IR (MIR) level.

• Experimental evaluation on two hardware architec-
tures (x86-64, AArch64) and reference benchmarks.

2 Background and Mathematical Model
In this section, we mathematically formulate the regis-
ter allocation problem by deﬁning the constraints that
arise out of hardware and the program. We also give an
overview of the available register allocators in LLVM.

2.1 Register constraints
Optimizing compilers convert the source code into
an Intermediate Representation (IR), where target-
In the backend
independent optimizations take place.
compiler, this IR is incrementally lowered to a machine-
speciﬁc one. In LLVM this representation is called Ma-

chine IR (MIR). The MIR at the stage of register allo-
cation is very close to machine instructions, as instruc-
tion selection and other low-level optimizations have al-
ready been performed. After instruction selection, cer-
tain physical registers that are mandated by the archi-
tecture are immediately assigned.

For instance, x86 processors mandate the output of 32-
bit division to be stored only in $eax and $edx registers.
As it can be seen from Fig. 1, the IDIV32 instruc-
tion divides the contents of $eax and $edx by %x and
stores the result in $eax. Such mandatory assignments–
including calling conventions—are assigned. The regis-
ter allocation problem can now be reduced to assigning
physical registers to the other left-out virtual registers
(V) while respecting the following constraints.
Type constraint The register ﬁle (R) of a machine
consists of collection of registers Rt belonging to diﬀer-
ent types (t): R = (cid:83)
Rt. Assigning a physical register r
t
to a virtual register v of type t, vt (cid:73) r, should satisfy the
register type constraint χT (vt) = {vt (cid:73) r : r ∈ Rt}. In
Fig. 1(b), each virtual register is associated with a partic-
ular register type. For instance, %x is of gr32 type, which
means that it belongs to a 32-bit wide general-purpose
register type. Consequently, only registers belonging to
that type (like $eax) can be assigned.
Congruence constraint Real-world instruction set
architectures like x86 and AArch64 have a hierarchy
of register classes. For instance, 32 bit type of reg-
isters (like $eax, $ebx) are physically part of the 64
bit ones (like $rax, $rbx). We consider the registers
that adhere to this part of relation as a congruent class
C(r). For example, registers $al, $ah, $ax, $eax,
$rax of x86, which are “chunks” of the same physical
register belong to the same congruent class, satisfying
$al, $ah (cid:118) $ax (cid:118) $eax (cid:118) $rax. So, the register assign-
ments for virtual register v should be among the set of
registers that satisfy the following congruence constraint:
χC(vt) = {vt
i

(cid:73) r : ∀vi, vj ∈ V, vi (cid:54)= vj, (cid:64)vj (cid:73) C(r) ∈ L(vi)}

v

, P end
v

Here L(v) corresponds to the live range of variable v,
and is computed as L(v) = [P def
]; the deﬁnition
of v occurs at program point P def, and its last use is in
P end. Fig. 1(a) gives an example. The live ranges of the
corresponding variables are shown in Fig. 2(b).
Interference constraint Register allocation has been
modeled as a graph coloring problem [Chaitin et al.,
1981]. For each function in the program,
it involves
creating an Interference graph G(V, E) deﬁned as fol-
lows:
the vertices of the graph are mapped to vir-
tual registers (v) or physical registers (Ra), meaning
V ∈ (V ∪ Ra); the edges E are computed as {(vi, vj) :
vi, vj ∈ V ∧ L(vi) ∩ L(vj)}. The interference graph corre-
sponding to the example in Fig. 1 is shown in Fig. 2(b).
The interference constraint says that no two adjacent
nodes in G should be allocated the same color. The set
of registers that satisfy this constraint is given by:
χI(vt) = {Rt \ {r : ∀u((u, v) ∈ E ∧ u (cid:73) r)}}

In summary, for a given virtual register v of type t,
the set of available registers for allocation χ(vt) is de-
ﬁned as the set of registers that satisfy the (i) type, (ii)
congruence, and (iii) interference constraints:
χ(vt) = χT (vt) ∩ χC(vt) ∩ χI(vt)

2.2 Live range splitting and spilling
The above formulation of register allocation in terms of
graph coloring is well known and natural, as a decision
problem. Yet register allocation as an optimization prob-
lem is actually much more than graph coloring. For
instance, when there are not enough physical registers
available, deciding which variable (virtual register) has
to be spilled to memory is important, as memory accesses
take far more time than register accesses. Spilling a vari-
able, µ(v) involves writing/reading it to/from a memory
location on access. A trivial example is the loop in-
duction variable: it would incur high cost to read/write
from/to memory, if a decision is made to spill it. Hence,
register allocators try to reduce the spill cost M (v), in
addition to minimizing the number of spills. For a ma-
chine with 3 registers, the example code shown in Fig. 1
is not 3-colorable, and results in spilling a variable.

A live range of a virtual register can be split. Let
k ∈ K denote a program point among the uses of v.
Splitting live range of v at k is deﬁned as ϕ(v, k) : L(v) (cid:32)
(L(v(cid:48)), L(v(cid:48)(cid:48))); L(v(cid:48)) = [P def
].
Determining which variable to split, and at which point
is non trivial. In Fig. 2(b), splitting i at 5 into (i(cid:48), i(cid:48)(cid:48))
makes the interference graph 3-colorable.

v ], L(v(cid:48)(cid:48)) = [P k+1

, P end
v

, P k

v

v

2.3 Register allocators in LLVM
Register allocators are implemented in compilers as
passes. LLVM currently has four diﬀerent register allo-
cators: fast, basic, greedy, and PBQP, ranked according
to the complexity of implementation. They are strictly
intraprocedural, operating one function at a time.

The fast register allocator which operates at the ba-
sic block level is an improved version of the linear scan
algorithm [Poletto and Sarkar, 1999]. The basic register
allocator is an improved variation of the fast register al-
locator and operates at the function level [Xavier et al.,
2012]. The greedy allocator was developed to address the
shortcomings of the basic allocator [Jakob, 2011]; it com-
bines four strategies iteratively: splitting, spilling, coa-
lescing (merging of live ranges), eviction (de-allocating
the already-allocated physical register). Each of these
strategies is driven by greedy heuristics. This alloca-
tor iterates over the virtual registers and obtains a legal
physical register allocation if possible. In this process it
applies node-splitting and eviction. The PBQP register
allocator is the only solver based mechanism in LLVM
and models it as a Partitioned Boolean Quadratic Prob-
lem to obtain allocations [Hames and Scholz, 2006].

Not all allocators implement all strategies; live range
splitting only takes place in greedy, whereas coalescing
is present in greedy and PBQP, and eviction in iterative
allocators like greedy and not PBQP. Our framework is

non-iterative, and we currently model splitting, spilling
and coloring; we leave coalescing for future work.

3 Representing Interference Graphs

We represent nodes of the interference graph as embed-
dings obtained from LLVM’s MIR instructions. This
forms the input to a Gated Graph Neural Network
(GGNN) that learns to generate the representation of
the state space. Here, we describe this process.

The IR2Vec framework is based on the generic IR of
LLVM. We use the same approach on MIR to gener-
ate MIR2Vec representations. This involves generating
triplets by forming relations between entities, training
TransE [Bordes et al., 2013] to obtain the seed embed-
ding vocabulary, and using it to create instruction-level
representations. As MIR is target-speciﬁc, the generated
embeddings are also speciﬁc to the architecture.

MIR Entities Opcodes and MIR instruction argu-
ments form the entities. The arguments to MIR in-
structions primarily include physical and virtual regis-
ters, and immediate values. Like IR2Vec, we abstract
out these arguments with generic identiﬁers.

We create 2 diﬀerent relations. (i) N extInst: Cap-
tures the relation between the current opcode and the
next instruction opcode, (ii) Argi: Captures the rela-
tion between the opcode and the arguments of the in-
struction. Once the triplets are generated, we train the
TransE model to obtain the embeddings for each of the
entities.

Grouping of opcodes Unlike LLVM IR, MIR con-
tains more specialized opcodes, in terms of the operating
width, among other factors. LLVM exposes about 15.3K
of diﬀerent possible opcodes in X86 and about 5.4K in
Aarch641. In comparison, LLVM IR only has about 64
entities (used by IR2Vec) in total.

Obtaining a dataset to cover all such specialized
operands would be highly infeasible, and in turn, would
not generate good representations. Hence we mask
out the opcodes based on their operating width, the
source and destination locations (immediate, register,
and memory) and group them together. For example,
there are about 200 diﬀerent MOV instructions operat-
ing on diﬀerent bit width, sources, and destinations, like
MOV32r0, MOVZX64rr16, MOVAPDrr, etc. All such opcodes
are grouped together as a generic MOV token while form-
ing the triplets. The generated triplets are used as an
input to the TransE model to generate the embeddings
for each entity. This forms the seed embedding vocabu-
lary for our problem.

Representing instructions For a given MIR instruc-
tion with opcode O and n arguments A1, A2, . . . , An, its
representation is computed as

Wo.
(cid:74)

O
(cid:75)

+ Wa. (
(cid:74)

A1

(cid:75)

+

(cid:74)

A2

(cid:75)

+ · · · +

An

(cid:74)

(cid:75)

) , Wo > Wa

1From the inc ﬁles - {build dir}/lib/Target/X86/X86GenInstrInfo.inc

and {build dir}/lib/Target/AArch64/AArch64GenInstrInfo.inc

1
2
3
4
5
6
7
8
9
10
11

i = 0
x = 10
y = 20
print x
z = y / x
i ++
z = z + 10
i ++
print y
print z
print i

MOV32ri 0 , %i : gr32
MOV32ri 10 , %x : gr32
MOV32ri 20 , %y : gr32
< call print on %x >
$eax = COPY %y : gr32
< clear $edx >
IDIV32r %x : gr32, implicit-def ←(cid:45)
$eax, implicit-def $edx

%z : gr32 = COPY $eax
%i : gr32 = ADD32ri %i : gr32, 1
< call print on %y, %z, %i >

Figure 1: (a) Example source code and (b) its Machine IR

Figure 2: Register allocation with and without splitting

Figure 3: Overview of the RL4ReAl framework

·
(cid:74)

where
denotes the embedding of the entity from seed-
(cid:75)
embedding vocabulary, as proposed by the symbolic en-
codings of IR2Vec.

3.1

Interference Graphs

We use the information collected from MIR to obtain
the interference graphs in LLVM. As mentioned earlier,
the MIR at the stage of register allocation contains par-
tial physical register assignments and virtual registers.
The physical registers are assigned for the instruction
operands that have restrictions on the particular regis-
ter to be used. Virtual registers are used in all other
places.

Consequently, we need to take into account the edges
corresponding to both virtual and physical registers.
Virtual registers are marked with the register class as
explained earlier. Hence the assignments can only be
one among the physical registers in that class.

For computing the interference graphs, considering the
interferences between the (physical register, virtual reg-
ister) and (virtual register, virtual register) would be
suﬃcient as the graph is bidirectional and that we do
not need to worry about the physical registers that are
already assigned. Hence the interference graph G is com-
puted as shown in Algorithm 1.

We use a collection of instructions in the live-range of
a variable to represent a vertex of the interference graph.
Each instruction is represented in Rn using MIR2Vec

Algorithm 1: Creating Interference Graph

Parameter: MachineFunction F, Graph &G
for each physical register pi ∈ F do

for each virtual register vi ∈ F do
if Interference(pi, vi then
G.addEdge(pi, vi)

for each virtual register vi ∈ F do

for each virtual register vj ∈ F and vi (cid:54)= vj
do

if Interference(vi, vj then
G.addEdge(vi, vj)

embeddings. Consequently, a vertex v is represented as
in Rm×n, where m denotes
a matrix of embeddings
the number of instructions in its live range.

v

(cid:74)

(cid:75)

In the recent times, Gated Graph Neural Networks
(GGNNs) have found wide applications in programming
language problems that are modeled as graphs [Cum-
mins and others, 2021b; Mendis et al., 2019b]. GGNNs
involve message passing between the nodes of the graph
where the information is propagated across the nodes
multiple times to arrive at the representation for a node.
Also, they allow annotating the nodes and edges based
on their types and properties, and consider them while
learning the representations. We use GGNNs to process
the embedded interference graph to get the ﬁnal repre-
sentation. This network transforms Rm×n → Rk, where

MIR FunctionInterferenceGraphRegister Assignment and spillingSplit NodeSplitColoror SpillCode GenerationMLRegAllocMIR2VecEmbeddingsgRPCSplittingAgentColouringAgentTaskSelectorAgentNodeSelectorAgentGGNNRL FrameworkORSplit InfoColor Map for all nodesNodeEmbeddingsSelectedNodeGraph InfoSplitColorLLVM EnvironmentPickNext nodeUpdateSourcecodeLowering &OptimizationsBinarygRPCStubgRPCStubk is a hyperparameter. We set k = n in our experiments,
while considering the following node types.

• Not visited — Nodes that are not visited yet.
• Spill — Nodes that are marked as spill.
• Colored — Nodes that are assigned a register.
Nodes in the graph are marked with these annotations,
along with the spill cost. Such node representations are
propagated through a GGNN by means of message pass-
ing. Messages received from adjacent nodes are aggre-
gated and passed through a Gated Recurrent Unit [Cho
et al., 2014] to yield a ﬁnal representation.

4 Hierarchical Reinforcement Learning

We formulate register allocation as a Markov Decision
Process (MDP) using hierarchical Reinforcement Learn-
ing (RL). We model the sub-tasks of register allocation
as lower level tasks controlled by multiple agents. Fig. 3
provides an overview of our approach. It involves inter-
actions between the LLVM compiler and the RL model
for both training and inference.

4.1 Environment
We implemented a new MLRegAlloc pass in LLVM, to
generate an interference graph (G), allocate, split and
spill registers as predicted by the agents. This pass also
generates a representation of G using MIR2Vec.

4.2 Agents
The task of allocating registers is split into multiple sub-
tasks across the horizon. Each of these tasks are modeled
as agents {ωυ, ωτ , ωϕ, ωξ} ∈ Ω, that learn their respec-
tive policies πω to optimally solve the low level tasks.
We formulate hierarchical agents for four sub-tasks as
shown in Fig. 3:

• Node selector (ωυ): Top level agent that learns to

pick a node v ∈ G.

• Task selector (ωτ ): Mid level agent that learns to
select a task among {χ, ϕ} on v picked by ωυ.
• Splitter (ωϕ): Low level agent that learns to identify

a split point k for v.

• Coloring Agent (ωξ): Low level agent that learns to

pick a valid χi ∈ χ or µ.

As it can be seen, each high level agent invokes a low
level agent while following the timeline: ωυ ≺ ωτ ≺
{ωϕ, ωξ}. Each agent ω has its own state space Sω, ac-
tion space Aω, and reward Rω to learn a policy πω.

v

Coloring Agent (ωξ) For a graph of V nodes, given
a set of registers χ(v) available at the instant, the state
space of ωξ is given as a tuple (
, |χ(v)|, |Vnclr|), where
(cid:75)
Vnclr = V \ Vclrd are the nodes to be colored, v is the
denotes its embedding.
node that is picked by ωυ, and
Meaning, the coloring agent uses the following informa-
tion to decide the register to be assigned: the embedding
of the vertex v, the number of registers that satisfy the
constraints (deﬁned in Sec. 2.1), and the number of un-
colored nodes in the interference graph. If no registers
are available, the coloring agent spills v. Hence the legal

(cid:74)
.

(cid:75)

(cid:74)

action space of ωξ is:

A(ωξ) =

(cid:26)χ(v),
µ(v),

|χ(v)| > 0
otherwise

χ(v) gives the set of legal registers for v (Sec. 2.1). To
improve performance, the agent should maximize the use
of registers for vertices with higher spill cost. And, spill
cost roughly corresponds to the importance of the node
v. Hence the reward for the coloring agent is given as:

R(ωξ) =

(cid:26)+M (v),
−M (v),

if χ(v)
if µ(v)

v

v
(cid:74)

Splitter (ωϕ) For predicting where to split the live
range of a variable v, the node splitter considers the spill
weights at each use of the variable M(v) = {M (vk) :
∀k ∈ K}, the distances between each successive use
Dv = {D(vi, vi+1), ∀i ∈ K}, and the embedding of
.
(cid:75)
The use distance is the number of program points be-
tween two uses of v. Hence, the state space is given as
a tuple (
, M(v), Dv). For a given state, the agent
(cid:74)
learns an optimal program point p ∈ K where v can be
split. Hence the action space A(ωϕ) = K. The reward
for the agent on splitting v into (v(cid:48), v(cid:48)(cid:48)) is dependent on
two factors: (i) the variation of use distance between
the chosen split point and the successor use, and (ii) the
variation in the number of interferences (δ(v)), the de-
gree of v before and after the split. If the variation of
use distances is higher than that of the interferences, the
split is beneﬁcial. The corresponding reward is:

(cid:75)

R(ωϕ) = D(v(cid:48), v(cid:48)(cid:48)) + δ(v) − (δ(v(cid:48)) + δ(v(cid:48)(cid:48)))

Task Selector (ωτ ) For selecting a task (τ ) among
coloring and splitting, the agent ωτ considers the param-
eters speciﬁc to each of the tasks: the representation of
v, the number of available registers, the number of inter-
ferences, its life-time, spill cost. Hence the state space is
, |χ(v)|, δ(v), |K(v)|, M (v)).
v
formulated as the tuple: (
(cid:74)
The action space of ωτ is deﬁned as:

(cid:75)

A(ωτ ) =

(cid:26){ϕ, χ},
χ,

|K(v)| ≥ k
otherwise

Here |K(v)| ≥ k indicates that v should have at least
k uses to be considered for splitting. We deﬁne k as a
hyper-parameter. We set k = 2 (1 deﬁnition and 1 use)
in our experiments. We model the reward for this agent
based on the outcome of the low level tasks.

R(ωτ ) =

(cid:26)R(ωξ),

R(ωϕ) − (1.001 × #Splits)/10,

τ = χ
τ = ϕ

Clearly, R(ωϕ) is always positive hence ωτ would always
favor splitting. But too many splits are also not desirable
because they may induce extraneous move instructions
in the generated assembly code. So, while computing
R(ωτ ), a discount factor is applied that decreases the
reward with increase in number of splits.

Arch.

Considered registers

x86

[A-D]L, [A-D]X, [E,R][A-D]X, [SI,DI]L,
SI, DI, [E,R][SI,DI], R[8-15][B,W,D]

Aarch64 X[0-30], W[0-30]

Table 1: Registers considered

training a TransE model on the generated triplets, with
the same hyperparameters as IR2Vec, running an SGD
optimizer over 1000 epochs to obtain an embedding vec-
tor of 100 dimensions. We evaluate performance on a
complex x86 microarchitecture (Intel Xeon W2265, 16
cores, 64GB RAM) and a simpler mobile AArch64 pro-
cessor (ARM Cortex A72, 2 cores, 4GB RAM).

We obtain 1 billion MIR triplets

from which
{675, 315} entities and {25, 17} relations are generated
for {x86, AArch64} respectively. For training the RL
model, we generate the interference graphs correspond-
ing to the selected functions using our MLRegAlloc pass.
We randomly choose ≈ 2000 functions having a number
of variables between 70–120. Functions with less than 70
variables are skipped as the number of registers is large
enough to color the vast majority of them without split-
ting or spilling. We also skipped those with more than
120 variables as they only form ≈ 1% of the dataset. For
the purpose of experimentation, we consider allocations
of general purpose registers for both x86 and AArch64,
as these registers contribute to major portion of the code.
The list of registers is detailed in Tab. 1. Training took
place on a P100 GPU and sampling was done using 12
threads of an Intel Xeon server.

Our framework controls the set of registers to be con-
sidered for allocation through a conﬁguration ﬁle. For
the virtual registers that belong to other register classes
that are not speciﬁed in this ﬁle, allocation is done by
the existing greedy register allocator of LLVM. We dis-
able allocations to vector registers while generating the
code for the purpose of comparison. Our framework is
implemented as a compiler pass—MLRegAlloc in LLVM
10.0.1. We integrated gRPC v1.34, and protobuﬀ v3.13,
and designed a client-server model for a seamless com-
munication between LLVM and the Python model. We
train the RL models using the PPO policy with the stan-
dard set of hyperparameters on the training set of func-
tions, until convergence of reward graph. The reward
curve is shown in the Fig. 4.

Results We study the performance on the standard
benchmarks from SPEC CPU 2017 and 2006 in terms
of runtimes and number of reloads (memory access) per
spill, and compare the results with the standard regis-
ter allocators of LLVM. By design, basic, greedy and
PBQP allocators generally outperform better the fast
allocator. However, it is not possible to identify a sin-
gle allocator among these that perform the best for all
programs. Hence, we compare our results with these
three allocators. The runtimes of the code generated by
using our register allocator RL4ReAl and other alloca-
tors are shown in Fig. 5(I). These runtimes are obtained

Figure 4: Reward Vs. step

Node Selector (ωυ) The state space of ωυ comprises
the embedding of each vertex in G obtained from a
GGNN. Along with these embeddings, the agent uses
the spill weights of the nodes M to characterize the state.
, M (V ))
Hence, the state space is given as a tuple (
(cid:75)
Its legal action space is A(ωυ) = Vnclr. The learned pol-
icy is deemed good based on the ﬁnal outcome of the
node. Hence the reward for this agent is also modeled
based on the rewards of the low-level agents.

G
(cid:74)

R(ωυ) =

(cid:26)R(ωξ),
R(ωϕ),

τ = χ
τ = ϕ

5 Compiler Integration
Developing frameworks to ease the integration of com-
pilers with RL environments is important to make the
solution practically viable. CompilerGym [2021a] makes
it possible to leverage Python libraries for solving com-
piler optimization problems; it exposes RL environments
and datasets by training RL models.

In this work, we developed a framework to support
both training and inference, where the deployment of the
model is transparent to the end user. It is particularly
critical to demonstrate the practicality of our approach
to representative benchmarks. The design of RL4ReAl
involves to-and-fro communication between the compiler
and Python model (Fig. 3). To our knowledge, such a
facility is not available in other frameworks; it allows to
integrate ML models easily with the compiler, and give
RL4ReAl the power to operate on any module—basic-
block, loop, function—of the input program.

For example, a splitting decision by the model is com-
municated to the compiler, which then applies it and
responds back with the update containing new interfer-
ences and live ranges. The model then updates the inter-
ference graph using the received information and contin-
ues the traversal. After processing all vertices of G, all
the coloring decisions are communicated to the compiler
as a color map. The backend compiler uses the allocation
decisions made by the model to generate code.

6 Experimental Evaluation
training MIR2Vec representa-
Methodology For
tions, we randomly select 2000 source code ﬁles from
SPEC CPU 2017 benchmarks and C++ Boost library.
MIR triplets are generated by applying -O3 optimiza-
tions. The seed embedding vocabulary is obtained by

500.00K1.00M1.50M2.00M2.50M3.00MAgent Steps Sampled50.00K100.00K150.00K200.00K250.00K300.00KEpisode RewardAArch64x86Figure 5: Comparison of runtimes and #reloads/spill obtained using various register allocators

Benchmark

Basic

Greedy PBQP

RL4ReAl

Benchmarks

Basic Greedy PBQP RL4ReAl

505.mcf r
519.lbm r
531.deepsjeng r
541.leela r
557.xz r
401.bzip2
429.mcf
470.lbm

1658.00
1616.50
890.00
1309.00
1330.00
1517.41
1359.24
1603.47

1631.30
1653.50
863.88
1308.99
1287.85
1497.66
1332.93
1603.46

1610.47
1620.61
903.38
1291.85
1290.61
1515.20
1342.83
1600.60

1650.53
1601.34
901.07
1269.66
1270.92
1517.26
1336.59
1603.46

Average

1410.45

1397.45

1396.94

1393.85

Table 2: Runtimes (in s) with diﬀerent register allocators on
AArch64

341.83
505.mcf r
249.40
519.lbm r
531.deepsjeng r
274.91
197.73
429.mcf
458.sjeng
276.18
462.libquantum 213.04
151.34
470.lbm
219.44
471.omnetpp

344.20
225.56
260.52
193.89
271.83
219.23
150.28
216.18

339.70
246.83
268.99
194.07
277.50
211.27
153.82
219.44

Average

240.48

235.21

238.95

354.45
224.99
260.70
199.92
272.64
217.12
148.70
214.66

236.65

Table 3: Runtimes (in s) with diﬀerent register allocators on
x86

by taking the median of three executions. On average,
the runtimes obtained by RL4ReAl are comparable or
perform better than the best allocator of LLVM.

Among the standard allocators, greedy is best on x86
and results in 2.19% and 1.57% improvement over ba-
sic and PBQP allocators. On AArch64, PBQP is best
and results an improvement of 0.96% and 0.04% over ba-
sic and greedy allocators. RL4ReAl itself improves the
runtime over basic and PBQP by 1.59% and 0.96% re-
spectively, and nearly matches greedy at -0.61% On the
other hand, in AArch64, RL4ReAl results in an im-
provement of 1.18%, 0.22% and 0.26% on the runtimes
obtained by basic, PBQP, and greedy respectively.
It
can be noted that these strong results have been obtained
fully automatically, against production-grade allocators
tuned over many man-decades of experience and eﬀort.
The obtained runtimes corresponding to AArch64 and
x86 architectures are shown in Tab. 2 and Tab. 3 respec-
tively.

Another metric which can be used to evaluate the reg-
ister allocator is based on eﬀective spilling strategy. It is
important to note that the absolute number of spills is
not a suﬃcient metric for comparison. Indeed, allocators
that perform live range splitting may create multiple live
ranges that could result in multiple spilling instances, yet
delivering higher overall performance. Hence, to study
spilling, we use the number of times a spilled virtual reg-

ister is reloaded from memory as a metric. Any register
allocator should try to minimize the number of memory
accesses (reloads) by spilling a virtual register which is
used infrequently. The number of reloads performed per
a spilled virtual register is shown in Fig. 5(II). As it can
be observed, RL4ReAl results in less reloads per spill
among all the allocators in both the architectures. This
shows the RL agents have learned a good policy that
chooses an appropriate vertex in the interference graph
to spill. We believe that the spilling improvments result
from a better coordination among all the agents in our
model; this helps picking an appropriate node, splitting
its live range to ease coloring, and eﬃcient spilling that
minimize the number of reloads. The number of spills,
reloads and reloads per spill ratio for AArch64 and x86
architectures are shown in Tab. 4 and Tab. 5 respectively.
It is also important to note that minimizing the num-
ber of reloads per spill alone may not necessarily lead to
improved runtime. Several other factors, like other com-
piler optimizations post register allocations, link time
optimizations, and the complexity of underlying micro-
architecture etc. will play a major role in the perfor-
mance of the ﬁnal code that is generated.

7 Related Work
ML for compiler optimizations There is a grow-
ing interest in applying machine learning techniques

12001400160018002000Run Time(s)(I)1658.01616.51309.01330.01517.411359.241603.471410.451631.31653.51308.991287.851497.661332.931603.461397.451610.471620.611291.851290.611515.21342.831600.61396.941650.531601.341269.661270.921517.261336.591603.461393.85800900890.0863.88903.38901.07050505.mcf519.lbm531.dsj541.leela557.xz401.bzip2429.mcf470.lbmAverage0510Reloads\Spill(II)3.882.373.94.216.955.852.02.03.892.351.22.41.922.974.111.01.72.213.391.443.142.694.374.622.01.52.892.351.22.881.992.373.681.01.72.15(a) AArch64150200250300350400450341.83249.4274.91197.73276.18213.04151.34219.44240.48344.2225.56260.52193.89271.83219.23150.28216.18235.21339.7246.83268.99194.07277.5211.27153.82219.44238.95354.45224.99260.7199.92272.64217.12148.7214.66236.65BasicGreedyPBQPRL4REAL010505.mcf519.lbm531.dsj429.mcf458.sjeng462.lq470.lbm471.oppAverage05104.252.714.395.294.843.252.389.214.542.231.382.762.293.252.061.127.742.852.382.522.752.944.052.642.115.343.092.381.382.772.262.922.191.124.242.41(b) x86Greedy

R R/S

54
42
471
263
555
349
1
17

219

2.35
1.2
2.4
1.92
2.97
4.11
1
1.7

2.21

S

23
35
196
137
187
85
1
10

84.25

S

23
32
198
132
187
76
1
2

PBQP

R R/S

RL4ReAl
S

R R/S

78
46
621
355
818
351
2
3

3.39
1.44
3.14
2.69
4.37
4.62
2
1.5

2.89

23
35
215
140
171
102
9
10

88.12

54
42
619
279
405
375
9
17

225

2.35
1.2
2.88
1.99
2.37
3.68
1
1.7

2.15

Benchmarks

505.mcf r
519.lbm r
531.dsj r
541.leela r
557.xz r
401.bzip2
429.mcf
470.lbm

S

24
30
188
144
192
71
3
3

Benchmarks

505.mcf r
519.lbm r
531.deepsjeng r
429.mcf
458.sjeng
462.libquantum
470.lbm
471.omnetpp

S

53
52
265
14
58
128
24
143

Basic

R R/S

93
71
734
606
1334
415
6
6

225
141
1163
74
281
416
57
1317

3.88
2.37
3.9
4.21
6.95
5.85
2
2

3.89

4.25
2.71
4.39
5.29
4.84
3.25
2.38
9.21

4.54

Average

81.87

408.12

81.37

284.25

Table 4: Number of spills (S) and reloads (R) and reloads per spill ratio (R/S) induced by diﬀerent allocators in AArch64

Basic

R R/S

Greedy

R R/S

S

56
56
269
14
61
135
25
143

125
77
743
32
198
278
28
1107

PBQP

R R/S

RL4ReAl
S

R R/S

133
136
763
50
239
333
57
929

330

2.38
2.52
2.75
2.94
4.05
2.64
2.11
5.34

3.09

60
56
276
19
72
135
100
83

143
77
764
43
210
295
112
352

100.12

249.5

2.38
1.38
2.77
2.26
2.92
2.19
1.12
4.24

2.41

S

56
54
277
17
59
126
27
174

98.75

2.23
1.38
2.76
2.29
3.25
2.06
1.12
7.74

2.85

Average

92.12

459.25

94.87

323.5

Table 5: Number of spills (S) and reloads (R) and reloads per spill ratio (R/S) induced by diﬀerent allocators in x86

for compiler optimizations. They include prediction of
vectorization factor [Haj-Ali et al., 2020], unroll fac-
tors [Stephenson and Amarasinghe, 2005], making in-
lining decisions [Simon et al., 2013], predicting thread
coarsening factor [Magni et al., 2013], estimation of
throughput of a code [Mendis et al., 2019a], etc. Such re-
cent works use learned embeddings for representing the
input programs to the ML model. Several ways of repre-
senting programs have been proposed [Alon et al., 2019;
Ben-Nun et al., 2018; Sui et al., 2020]. In this work, we
use an extension of IR2Vec [VenkataKeerthy et al., 2020]
to represent programs.

Reinforcement Learning solutions for optimiza-
tions Recently, several works have been proposed that
use machine learning reinforcement learning based so-
lutions for compilation. This can possibly be because
such problems are computationally hard to determine
the ground truth, which would otherwise be necessary.
Mammadli et al [2020] and Huang et al [2019b] proposed
a phase ordering solution using reinforcement learning
that would result in better optimization characteristics
when compared to O3. Khadka et al [2021] formulate
memory placement in neural network accelerators as
a reinforcement learning problem to optimize memory
movement. Haj-Ali et al [2020] model loop vector factor
prediction using reinforcement learning to obtain better
performance when compared to the native LLVM’s vec-
torizer. Mendis et al used a variation of reinforcement
learning, called imitation learning to model SLP vector-

ization decisions by imitating a solver [2019b]. Other
optimization works that use reinforcement learning can
be found in the survey paper by Wang et al [2018].

ML and Register Allocation Ours is the ﬁrst end-
to-end application of reinforcement learning for solv-
ing the register allocation problem. An initial attempt
to solve this problem using ML models was by Das et
al [2020], where they use an LSTM network to come up
with an initial graph coloring scheme, which then un-
dergoes a correction phase to rectify the inconsistency in
coloring interfering nodes. Their work focuses on solving
the graph coloring problem, and to our understanding,
the solution was not integrated to obtain the ﬁnal regis-
ter assignments so as to study the performance.

Several works [Huang et al., 2019a; Lemos et al., 2019;
Santos, 2020; Musliu and Schwengerer, 2013] have been
proposed to solve the conventional graph coloring prob-
lem using machine learning. These however may not be
applied directly to obtain an optimal register allocation
scheme, as such approaches do not consider program-
speciﬁc information like live ranges to arrive at the ﬁnal
coloring.

RL Framework to support compiler optimiza-
tions With the growing interest in applying machine
learning in compilation, a couple of frameworks have
been proposed to ease the integration of compiler APIs
and RL environments for training and inference.

Cummins et al. proposed CompilerGym [2021a], a
It

python library for compiler optimization problems.

exposes RL environments and datasets, integrated with
popular compilers and tools.

Another framework, MLGO [Troﬁn et al., 2021] in-
tegrates trained machine learning models within the
LLVM compiler. For this purpose, the compiler loads
a trained model and accesses it via C++ APIs of Ten-
sorﬂow or ahead-of-time generated code (release mode).
The framework is used in production, with improved de-
cisions for inlining for size, and live range eviction (in
register allocation) when compared to the compiler’s de-
fault heuristics.2

The problem of supporting multiple stages of register
allocation involves a two-way communication between
the model and the compiler. To our understanding, these
frameworks do not support such a communication, while
our framework is designed to handle it.

several

1990; Chen et al.,

Register Allocation Traditionally
ap-
proaches [Chaitin et al., 1981; Briggs et al., 1994;
Chow and Hennessy,
2018;
Huang et al., 2012] have been proposed to solve
the register allocation problem using heuristics. Of-
ten the register allocation problem is understood
to interfere with other optimizations
like instruc-
tion selection.
Hence, diﬀerent works have been
proposed to model them as a combinatorial prob-
lem of these two using solvers [Wilson et al., 1994;
Gebotys,
1999;
Nagarakatte and Govindarajan,
2007; Lozano et
al., 2019].

1997; Bashford

Leupers,

and

8 Conclusion and Future Work
We propose an architecture-independent Reinforcement
Learning solution to the Register Allocation problem.
We use a multi-agent hierarchical approach to learn an
optimal policy for the diﬀerent sub-tasks of register al-
location,
live range splitting, and
spilling. Semantic correctness is ensured by the con-
straints encoded as the action masks for the agents. Our
method exhibits better allocations, improved runtime,
and less memory accesses when compared to the stan-
dard register allocators of LLVM.

including coloring,

We plan to address other sub-tasks of register alloca-
tion: coalescing, multi-allocation and register packing.
We will open-source the framework in the near future.

References
[Alon et al., 2019] U Alon, M Zilberstein, O Levy, and E Ya-
hav. Code2vec: Learning distributed representations of
code. POPL, pages 40:1–40:29, 2019.

[Appel and George, 2001] A W. Appel and L George. Op-
timal spilling for cisc machines with few registers. PLDI
’01, page 243–253, 2001.

[Ashouri et al., 2017] A. H. Ashouri, A Bignoli, G Palermo,
C Silvano, S Kulkarni, and J Cavazos. Micomp: Mitigating
the compiler phase-ordering problem using optimization
sub-sequences and machine learning. 14(3), 2017.

2https://github.com/google/ml-compiler-opt

[Barik et al., 2006] R Barik, C Grothoﬀ, R Gupta, V Pandit,
and R Udupa. Optimal bitwise register allocation using
integer linear programming. LCPC, pages 267–282, 2006.
[Bashford and Leupers, 1999] Steven Bashford and Rainer
Leupers. Phase-coupled mapping of data ﬂow graphs to
irregular data paths. Design automation for embedded sys-
tems, 4(2):119–165, 1999.

[Ben-Nun et al., 2018] T Ben-Nun, A S Jakobovits, and
T Hoeﬂer. Neural code comprehension: A learnable rep-
resentation of code semantics. NIPS’18, pages 3589–3601,
2018.

[Bordes et al., 2013] A Bordes, N Usunier, A Garcia-Dur´an,
J Weston, and O Yakhnenko. Translating embeddings for
modeling multi-relational data. NIPS’13, pages 2787–2795,
2013.

[Bouchez et al., 2006] F Bouchez, A Darte, C Guillon, and
F Rastello. Register allocation: What does the np-
completeness proof of chaitin et al. really prove? or revis-
iting register allocation: Why and how. In Int. Workshop
on LCPC, pages 283–298, 2006.

[Briggs et al., 1994] P Briggs, K D. Cooper, and L Torczon.
Improvements to graph coloring register allocation. ACM
Trans. Program. Lang. Syst., 16(3):428–455, may 1994.
[Chaitin et al., 1981] G J Chaitin, M A Auslander, A K
Chandra, J Cocke, M E Hopkins, and P W Markstein. Reg-
ister allocation via coloring. Computer languages, 6(1):47–
57, 1981.

[Chang et al., 1997] CM Chang, CM Chen, and CT King.
Using integer linear programming for instruction schedul-
ing and register allocation in multi-issue processors. Com-
puters & Mathematics with Applications, 34(9):1–14, 1997.
[Chen et al., 2018] WY Chen, GY Lueh, P Ashar, K Chen,
and B Cheng. Register allocation for intel processor graph-
ics. CGO 2018, page 352–364, 2018.

[Cho et al., 2014] K Cho, M B van, C Gulcehre, D Bah-
danau, F Bougares, H Schwenk, and Y Bengio. Learn-
ing phrase representations using RNN encoder–decoder for
statistical machine translation. EMNLP 2014, pages 1724–
1734, October 2014.

[Chow and Hennessy, 1990] F C. Chow and J L. Hennessy.
The priority-based coloring approach to register allocation.
ACM TOPLAS, 12(4):501–536, oct 1990.

[Cummins and others, 2021a] C Cummins et al. Compiler-
gym: Robust, performant compiler optimization environ-
ments for AI research, 2021.

[Cummins and others, 2021b] C Cummins et al. Programl:
A graph-based program representation for data ﬂow anal-
ysis and compiler optimizations. volume 139 of ICML’21,
pages 2244–2253, 18–24 Jul 2021.

[Das et al., 2020] D Das, S A Ahmad, and V Kumar. Deep
learning-based approximate graph-coloring algorithm for
register allocation. Workshop on the LLVM Compiler In-
frastructure in HPC, pages 23–32, 2020.

[Fursin and others, 2011] G Fursin et al. Milepost gcc:
IJPP,

Machine learning enabled self-tuning compiler.
39(3):296–327, Jun 2011.

[Garey and Johnson, 1979] M R Garey and D S Johnson.
Computers and Intractability: A Guide to the Theory of
NP-Completeness. W. H. Freeman, 1979.

[Gebotys, 1997] C.H. Gebotys. An eﬃcient model for dsp
code generation: performance, code size, estimated energy.
In Proceedings. Tenth International Symposium on System
Synthesis (Cat. No.97TB100114), pages 41–47, 1997.

gerer. Algorithm selection for the graph coloring problem.
In ICLIO, pages 389–403, 2013.

[Nagarakatte and Govindarajan, 2007] S G Nagarakatte and
R Govindarajan. Register allocation and optimal spill code
scheduling in software pipelined loops using 0-1 ilp formu-
lation. CC’07, pages 126–140, 2007.

[Pennington et al., 2014] J Pennington, R Socher, and C D
Manning. Glove: Global vectors for word representation.
EMNLP’14, pages 1532–1543, 2014.

[Poletto and Sarkar, 1999] M Poletto and V Sarkar. Linear
scan register allocation. ACM TOPLAS, 21(5):895–913,
sep 1999.

[Santos, 2020] H L Santos. Solving the decision version of
the graph coloring problem: a neural-symbolic approach
using graph neural networks. Master’s thesis, Universidade
Federal do Rio Grande do Sul, 2020.

[Simon et al., 2013] D Simon, J Cavazos, C Wimmer, and
S Kulkarni. Automatic construction of inlining heuristics
using machine learning. CGO’13, page 1–12, 2013.

[Stephenson and Amarasinghe, 2005] M. Stephenson and
S. Amarasinghe. Predicting unroll factors using supervised
classiﬁcation. CGO’05, pages 123–134, March 2005.

[Sui et al., 2020] Y Sui, X Cheng, G Zhang, and H Wang.
Flow2vec: Value-ﬂow-based precise code embedding. Proc.
ACM Program. Lang., 4(OOPSLA), Nov 2020.

[Troﬁn et al., 2021] Mircea Troﬁn, Yundi Qian, Eugene
Brevdo, Zinan Lin, Krzysztof Choromanski, and David Li.
MLGO: a machine learning guided compiler optimizations
framework. CoRR, abs/2101.04808, 2021.

[VenkataKeerthy et al., 2020] S. VenkataKeerthy, R Aggar-
wal, S Jain, M S Desarkar, R Upadrasta, and Y. N. Srikant.
IR2Vec: LLVM IR Based Scalable Program Embeddings.
ACM Trans. Archit. Code Optim., 17(4), December 2020.
[Wang and O’Boyle, 2018] Z Wang and M O’Boyle. Ma-
chine learning in compiler optimization. Proceedings of
the IEEE, 106(11):1879–1901, 2018.

[Wilson et al., 1994] T. Wilson, G. Grewal, B. Halley, and
D. Banerji. An integrated approach to retargetable code
generation. In Proceedings of 7th International Symposium
on High-Level Synthesis, pages 70–75, 1994.

[Xavier et al., 2012] T Xavier, G Oliveira, E Lima, and
A Silva. A detailed analysis of the llvm’s register alloca-
tors. In 2012 31st International Conference of the Chilean
Computer Science Society, pages 190–198, 2012.

[Haj-Ali et al., 2020] A Haj-Ali, N K. Ahmed, T Willke,
Y S Shao, K Asanovic, and I Stoica. Neurovectorizer:
End-to-end vectorization with deep reinforcement learn-
ing. CGO’20, page 242–255, 2020.

[Hames and Scholz, 2006] L Hames and B Scholz. Nearly
optimal register allocation with pbqp. In Joint Modular
Languages Conference, pages 346–361. Springer, 2006.
[Huang et al., 2012] Y Huang, M Zhao, and C J Xue. Wcet-
aware re-scheduling register allocation for real-time em-
bedded systems with clustered vliw architecture. LCTES
’12, page 31–40, 2012.

[Huang et al., 2019a] J Huang, M M A Patwary, and G F.
Diamos. Coloring big graphs with alphagozero. CoRR,
abs/1902.10162, 2019.

[Huang et al., 2019b] Q Huang, A Haj-Ali, W S Moses,
J Xiang, I Stoica, K Asanovi´c, and J Wawrzynek. Au-
tophase: Compiler phase-ordering for hls with deep rein-
International Symposium on Field-
forcement learning.
Programmable Custom Computing Machines (FCCM),
pages 308–308, 2019.
[Jakob, 2011] S O Jakob.

Greedy Register Alloca-
http://blog.llvm.org/2011/09/

tion in LLVM 3.0.
greedy-register-allocation-in-llvm-30.html, 2011.
[Khadka et al., 2021] S Khadka, E Aﬂalo, M Mardar, A Ben-
David, S Miret, S Mannor, T Hazan, H Tang, and S Ma-
jumdar. Optimizing memory placement using evolutionary
graph reinforcement learning. ICLR’21, 2021.

[Kim et al., 2021] M Kim, JK Park, and SM Moon. Irregular
register allocation for translation of test-pattern programs.
ACM Trans. Archit. Code Optim., 18(1), dec 2021.

[Kuchcinski, 2003] K Kuchcinski.

Constraints-driven
scheduling and resource assignment. ACM TODAES,
8(3):355–383, 2003.

[Lattner and Adve, 2004] C Lattner and V Adve. Llvm: A
compilation framework for lifelong program analysis &
transformation. CGO’04, page 75, 2004.

[Lemos et al., 2019] H Lemos, M Prates, P Avelar, and
L Lamb. Graph colouring meets deep learning: Eﬀective
graph neural network models for combinatorial problems.
ICTAI’19, pages 879–885, 2019.

[Lozano et al., 2012] R Lozano, M Carlsson, F Drejhammar,
and C Schulte. Constraint-based register allocation and
instruction scheduling. In ICPPCP, pages 750–766, 2012.
[Lozano et al., 2019] R Lozano, M Carlsson, G Hjort Blin-
dell, and C Schulte. Combinatorial register allocation and
instruction scheduling. ACM TOPLAS, 41(3), jul 2019.
[Magni et al., 2013] A Magni, C Dubach, and M F P
O’Boyle. A large-scale cross-architecture evaluation of
thread-coarsening. SC’13, pages 11:1–11:11, 2013.

[Mammadli et al., 2020] R Mammadli, A Jannesari, and
F Wolf. Workshop on the LLVM Compiler Infrastructure
in HPC, pages 1–11, 11 2020.

[Mendis et al., 2019a] C Mendis, A Renda, S Amarasinghe,
and M Carbin. Ithemal: Accurate, portable and fast basic
block throughput estimation using deep neural networks.
volume 97 of ICML’19, pages 4505–4515, 09–15 Jun 2019.
[Mendis et al., 2019b] C Mendis, C Yang, Y Pu, S Amaras-
inghe, and M Carbin. Compiler auto-vectorization with
imitation learning. volume 32 of NeurIPS’19, 2019.

[Mikolov et al., 2013] T Mikolov, K Chen, G Corrado, and
J Dean. Eﬃcient estimation of word representations in
vector space. arXiv preprint arXiv:1301.3781, 2013.

[Musliu and Schwengerer, 2013] N Musliu and M Schwen-

