Accelerating Metropolis-Hastings with Lightweight Inference
Compilation

Feynman Liang Nimar Arora Nazanin Tehrani
Facebook

UC Berkeley

Facebook

0
2
0
2

t
c
O
3
2

]

G
L
.
s
c
[

1
v
8
2
1
2
1
.
0
1
0
2
:
v
i
X
r
a

Abstract

In order to construct accurate proposers for
Metropolis-Hastings Markov Chain Monte
Carlo, we integrate ideas from probabilistic
graphical models and neural networks in an
open-source framework we call Lightweight
Inference Compilation (LIC). LIC imple-
ments amortized inference within an open-
universe declarative probabilistic program-
ming language (PPL). Graph neural net-
works are used to parameterize proposal dis-
tributions as functions of Markov blankets,
which during “compilation” are optimized
to approximate single-site Gibbs sampling
distributions. Unlike prior work in infer-
ence compilation (IC), LIC forgoes impor-
tance sampling of linear execution traces in
favor of operating directly on Bayesian net-
works. Through using a declarative PPL,
the Markov blankets of nodes (which may
be non-static) are queried at inference-time
to produce proposers Experimental results
show LIC can produce proposers which have
less parameters, greater robustness to nui-
sance random variables, and improved poste-
rior sampling in a Bayesian logistic regression
and n-schools inference application.

1 Background

Deriving and implementing samplers has traditionally
been a high-eﬀort and application-speciﬁc endeavour
(Porteous et al., 2008; Murray et al., 2010), motivat-
ing the development of general-purpose probabilistic
programming languages (PPLs) where a non-expert
can specify a generative model (i.e. joint distribution)

Yucen Li
Facebook

Michael Tingley
Facebook

Erik Meijer
Facebook

p(x, y) and the software automatically performs in-
ference to sample latent variables x from the poste-
rior p(x | y) conditioned on observations y. While
exceptions exist, modern general-purpose PPLs typi-
cally implement variational inference (Bingham et al.,
2019), importance sampling (Wood et al., 2014; Le
et al., 2017), or Monte Carlo Markov Chain (MCMC,
Wingate et al. (2011); Tehrani et al. (2020)).

Our work focuses on MCMC. More speciﬁcally, we tar-
get lightweight Metropolis-Hastings (LMH, Wingate
et al. (2011)) within a recently developed declarative
PPL called beanmachine (Tehrani et al., 2020). The
performance of Metropolis-Hastings critically depends
on the quality of the proposal distribution used, which
is the primary goal of LIC. LIC makes the following
contributions:

1. We present a novel implementation of inference
compilation (IC) within an open-universe declar-
ative PPL which combines Markov blanket struc-
ture with graph neural network architectures

2. We describe how to handle novel data encoun-
tered at run-time which was not observed during
compilation, which is an issue faced by any imple-
mentation of IC supporting open-universe models.

3. We demonstrate LIC’s ability to escape local
modes, improved robustness to nuisance random
variables, and improvements over state-of-the-
art methods across a number of metrics in two
industry-relevant applications

1.1 Declarative Probabilistic Programming

To make Bayesian inference accessible to non-exports,
PPLs provide user-friendly primitives in high-level
programming languages for abstraction and com-
position in model representation (Goodman, 2013;
Ghahramani, 2015). Existing PPLs can be broadly
classiﬁed based on the representation inference is per-
formed over, with declarative PPLs (Lunn et al., 2000;
Plummer et al., 2003; Milch et al., 2007; Tehrani et al.,
2020) performing inference over Bayesian graphical

 
 
 
 
 
 
Accelerating Metropolis-Hastings with Lightweight Inference Compilation

Figure 1: Intuition for Lightweight Inference Compilation (LIC). LIC uses samples (xi, yi) iid∼ p (blue “x” in
left) drawn from the joint density p(x, y) to approximate the expected inclusive KL-divergence Ep(y)DKL(p(x |
y) (cid:107) q(x; φ(y))) between the posterior p(x | y) and the LIC proposal distribution q(x; φ(y)). For an observation
y = 0.25 (dashed red line in left), the posterior p(x | y = 0.25) (dashed red line in right) is “approximated”
by samples “close” to y (blue “x” in right) to form an empirical inclusive KL-divergence minimized by LIC.
As inclusive KL-divergence encourages a mass-covering / mean-seeking ﬁt, the resulting proposal distribution
q(x; φ(y = 0.25), K = 1) (green dotted line in right) when using a single (K = 1) Gaussian proposal density
covers both modes and can successfully propose moves which cross between the two mixture components. Using a
2-component (K = 2) GMM proposal density results in q(x; φ(y = 0.25), K = 2) (purple solid line in right) which
captures both the bi-modality of the posterior as well as the low probability region between the two modes. As
a result of sampling the generative model, LIC can discover both posterior modes and their appropriate mixture
weights (whereas other state of the art MCMC samplers fail, see ﬁg. 3).

networks and imperative PPLs conducting importance
sampling (Wood et al., 2014) or MCMC (Wingate
et al., 2011) on linearized execution traces. Because
an execution trace is a topological sort of an instanti-
ated Bayesian network, declarative PPLs preserve ad-
ditional model structure such as Markov blanket rela-
tionships which are lost in imperative PPLs.

Deﬁnition 1.1. The Markov Blanket MB(xi) of a
node xi is the minimal set of random variables such
that

p(xi | x−i, y) = p(xi | MB(xi))

(1)

In a Bayesian network, MB(xi) consists of the parents,
children, and children’s parents of xi (Pearl, 1987).

1.2

Inference Compilation

Amortized inference (Gershman and Goodman, 2014)
refers to the re-use of initial up-front learning to im-
prove future queries. In context of Bayesian inference
(Marino et al., 2018; Zhang et al., 2018) and IC (Paige
and Wood, 2016; Weilbach et al., 2019; Harvey et al.,
2019), this means using acceleration performing mul-
tiple inferences over diﬀerent observations y to amor-
tize a one-time “compilation time.” While compila-
tion in both trace-based IC (Paige and Wood, 2016;
Le et al., 2017; Harvey et al., 2019) and LIC consists
of drawing forward samples from the generative model

p(x, y) and training neural networks to minimize in-
clusive KL-divergence, trace-based IC uses the result-
ing neural network artifacts to parameterize proposal
distributions for importance sampling while LIC uses
them for MCMC proposers.

1.3 Lightweight Metropolis Hastings

LMH (Wingate et al. (2011); Ritchie et al. (2016b))
updates random variables within a probabilistic model
one at a time according to a Metropolis-Hastings rule
while keeping all the other variables ﬁxed. While a
number of choices for proposal distribution exist, the
single-site Gibbs sampler which proposes from eq. (1)
enjoys a 100% acceptance probability (Pearl, 1987)
and provides a good choice when available (Lunn et al.,
2000; Plummer et al., 2003). Unfortunately, outside of
discrete models they are oftentimes intractable to di-
rectly sample so another proposal distribution must be
used. LIC seeks to approximate these single-site Gibbs
distributions using tractable neural network approxi-
mations.

1.4 Related Works

Prior work on IC in imperative PPLs can be broadly
classiﬁed based on the order in which nodes are sam-
pled. “Backwards” methods approximate an inverse
factorization, starting at observations and using IC

−5.0−2.50.02.55.07.510.012.515.0x−4−2024yGenerativemodelp(x,y)−5.0−2.50.02.55.07.510.012.515.0x0.000.020.040.060.080.10PDFPosteriordensitygiveny=0.25p(x|y=0.25)x∼p(x|y=0.25)q(x;φ(y=0.25),K=1)q(x;φ(y=0.25),K=2)Liang, Arora, Tehrani, Li, Tingley, Meijer

Figure 2: The Markov blankets in the Bayesian network for eq. (3) (left, expressed in plate notation) are
available in a declarative PPL, and are used as inputs to LIC. The LIC proposer for node x1 (right) is obtained
by ﬁrst performing neural network embedding of x1 and every node in its Markov blanket, followed by a graph
convolutional network aggregation over the Markov blanket of x1. The resulting vectors are then combined to
yield a parameter vector φ(x1) for a proposal distribution q(·; φ(x1)) which is then sampled for proposing an
update within Metropolis-Hastings.

artifacts to propose propose parent random variables.
Along these lines, Paige and Wood (2016) use neural
autoregressive density estimators but heuristically in-
vert the model by expanding parent sets. Webb et al.
(2018) proposes a more principled approach utilizing
minimal I-maps and demonstrate that minimality of
inputs to IC neural networks can be beneﬁcial; an in-
sight also exploited through LIC’s usage of Markov
blankets. Unfortunately, model inversion is not possi-
ble in universal PPLs (Le et al., 2017).

The other group of “forwards” methods operate in
the same direction as the probabilistic model’s de-
pendency graph. Starting at root nodes, these meth-
ods produce inference compilation artifacts which map
an execution trace’s preﬁx to a proposal distribu-
tion. In Ritchie et al. (2016a), a user-speciﬁed model-
speciﬁc guide program parameterizes the proposer’s
architecture and results in more interpretable IC ar-
tifacts at the expense of increased user eﬀort. Le
et al. (2017) automates this by using a recurrent neu-
ral network (RNN) to summarize the execution pre-
ﬁx while constructing a node’s proposal distribution.
This approach suﬀers from well-documented RNN lim-
itations learning long distance dependencies (Hochre-
iter, 1998), requiring mechanisms like attention (Har-
vey et al., 2019) to avoid degradation in the presence
of long execution trace preﬁxes (e.g. when nuisance
random variables are present).

With respect to prior work, LIC is most similar to the
attention-based extension (Harvey et al., 2019) of Le
et al. (2017). Both methods minimize inclusive KL-
divergence empirically approximated by samples from
the generative model p(x, y), and both methods use

neural networks to produce a parametric proposal dis-
tribution from a set of inputs suﬃcient for determin-
ing a node’s posterior distribution. However, impor-
tant distinctions include (1) LIC’s use of a declarative
PPL implies Markov blanket relationships are directly
queryable and ameliorates the need for also learning
an attention mechanism, (2) LIC uses a graph neu-
ral network to summarize the Markov blanket rather
than a RNN over the execution trace preﬁx, and (3)
LIC can handle open-universe models where novel ran-
dom variables are encountered at inference time and
no embedding network exists.

2 Lightweight Inference Compilation

2.1 Architecture

Figure 2 shows a sketch of LIC’s architecture. For
every latent node xi, LIC constructs a mapping
(xi, MB(xi)) (cid:55)→ φ(xi) parameterized by feedforward
and graph neural networks to produce a parame-
ter vector φ(xi) for a parametric density estimator
q(·; φ(xi)). Every node xi has feedforward “node em-
bedding network” used to map the value of the under-
lying random variable into a vector space of common
dimensionality. The set of nodes in the Markov blan-
ket are then summarized to a ﬁxed-length vector fol-
lowing section 2.1.1, and a feedforward neural network
ultimately maps the concatenation of the node’s em-
bedding with its Markov blanket summary to proposal
distribution parameters φ(xi).

σxiyii∈[n]Bayesian network for current worldLIC network for x1 proposerMB=σσ embedding nety1y1 embedding netnode=x1x1 embedding net∑ ∑ GCN @ x1 Accelerating Metropolis-Hastings with Lightweight Inference Compilation

2.1.1 Dynamic Markov Blanket embeddings

The resulting objective function is given by

Because a node’s Markov blanket may vary in both
its size and elements (e.g.
in a GMM, a data point’s
component membership may change during MCMC),
MB(xi) is a non-static set of vectors (albeit all of the
same dimension after node embeddings are applied)
and a feed-forward network with ﬁxed input dimension
is unsuitable for computing a ﬁxed-length proposal pa-
rameter vector φ(xi). Furthermore, Markov blankets
(unlike execution trace preﬁxes) are unordered sets
and lack a natural ordering hence use of a RNN as
done in Le et al. (2017) is inappropriate.
Instead,
LIC draws motivation from graph neural networks
(Scarselli et al., 2008; Dai et al., 2016) which have
demonstrated superior results in representation learn-
ing Bruna et al. (2013) and performs summarization
of Markov Blankets following Kipf and Welling (2016)
by deﬁning

Ep(y) [DKL(p(x | y) (cid:107) q(x | y; φ))]

(2)

= Ep(x,y)

(cid:20)

log

(cid:21)

p(x | y)
q(x | y; φ)

∝ Ep(x,y) [− log q(x | y; φ)]

N
(cid:88)

≈

− log q(x | y; φ),

(x, y) iid∼ p(x, y)

i=1
=: L(φ)

where we have neglected a conditional entropy term
independent of φ and performed Monte-Carlo approx-
imation to an expectation. The intuition for this ob-
jective is shown in Figure 1, which shows how samples
from p(x, y) (left) form an empirical joint approxima-
tion where “slices” (at y = 0.25 in ﬁg. 1) yield posterior
approximations which the objective is computed over
(right).

(cid:32)

φ(xi) = σ

W (cid:3)

xj ∈MB(xi)

1
(cid:112)|MB(xi)||MB(xj)|

(cid:33)

2.2.1 Open-universe support / novel data at

fj(xj)

runtime

where fj(xj) denotes the output of the node embed-
ding network for node xj when provided its current
value as an input, (cid:3) is any diﬀerentiable permutation-
invariant function (summation in LIC’s case), and σ is
an activation function.

2.1.2 Parameterized density estimation

The resulting parameter vectors φ(xi) of LIC are ul-
timately used to parameterize proposal distributions
q(xi; φ(MB(xi))) for MCMC sampling. For discrete
xi, LIC directly estimates logit scores over the sup-
port. For continuous xi, LIC transforms continuous
xi to unconstrained space following Carpenter et al.
(2017) and models the density using a Gaussian mix-
ture model (GMM). Note that although more sophisti-
cated density estimators such as masked autoregressive
ﬂows (Kingma et al., 2016; Papamakarios et al., 2017)
can equally be used.

2.2 Objective Function

To “compile” LIC, parameters are optimized to min-
imize the inclusive KL-divergence between the poste-
rior distributions and inference compilation proposers:
DKL(p(x | y) (cid:107) q(x | y; φ)). Consistent with Le et al.
(2017), observations y are sampled from the marginal
distribution p(y), but note that this may not be rep-
resentative of observations y encountered at inference.

Because the number of random variables in an open-
universe probabilistic can be unbounded, it is impos-
sible for any ﬁnite-time training procedure which re-
lies on sampling the generative model p(x, y) to en-
counter all possible random variables. As a conse-
quence, any implementation of IC within a univer-
sal PPL must address the issue of novel data en-
countered at inference time. This issue is not explic-
itly addressed in prior work (Le et al., 2017; Harvey
et al., 2019).
In LIC’s case, if a node xi does not
have an existing LIC artifact xi (cid:55)→ φ(xi) then we fall
back to proposing from the parent-conditional prior
q(xi; MB(xi), φi) = p(xi | Pa(xi)) (i.e. ancestral sam-
pling).

3 Experiments

To validate LIC’s competitiveness, we conducted ex-
periments benchmarking a variety of desired behaviors
and relevant applications. In particular:

• Training on samples from the joint distribution
p(x, y) should enable discovery of distant modes,
so LIC samplers should be less likely to to get
“stuck” in a local mode. We validate this in sec-
tion 3.1 using a GMM mode escape experiment,
where we see LIC escape not only escape a local
mode but also yield accurate mixture component
weights.

• When there is no approximation error (i.e. the
true posterior density is within the family of para-
metric densities representable by LIC), we expect

Liang, Arora, Tehrani, Li, Tingley, Meijer

LIC to closely approximate the posterior at least
for the range of observations y sampled during
compilation (eq. (2)) with high probability under
the prior p(y). Section 3.2 shows this is indeed
the case in a conjugate Gaussian-Gaussian model
where a closed form expression for the posterior
is available.

• Because Markov blankets

can be

explicitly
queried, we expect LIC’s performance to be unaf-
fected by the presence of nuisance random vari-
ables (i.e.
random variables which extend the
execution trace but are statistically independent
from the observations and queried latent vari-
ables). This is conﬁrmed in section 3.3 using the
probabilistic program from Harvey et al. (2019),
where we see trace-based IC suﬀering an order
of magnitude increase in model parameters and
compilation time while yielding an eﬀective sam-
ple size almost 5× smaller (Figure 5).

• To verify LIC yields competitive performance
in applications of interest, we benchmark LIC
against other state-of-the-art MCMC methods
on a Bayesian logistic regression problem (sec-
tion 3.4) and on a generalization of the classi-
cal eight schools problem (Rubin, 1981) called
n-schools (section 3.5) which is used in produc-
tion at a large internet company for Bayesian
meta-analysis Sutton and Abrams (2001). We
ﬁnd that LIC exceeds the performance of adaptive
random walk Metropolis-Hastings (Garthwaite
et al., 2016) and Newtonian Monte Carlo (Arora
et al., 2020) and yields comparable performance
to NUTS (Hoﬀman and Gelman, 2014) despite be-
ing implemented in an interpreted (Python) ver-
sus compiled (C++) language.

3.1 GMM mode escape

Consider the multi-modal posterior resulting from con-
ditioning on y = 0.25 in the 2-dimensional GMM in
ﬁg. 1, which is comprised of two Gaussian components
with greater mixture probability on the right-hand
component and a large energy barrier separating the
two components. Because LIC is compiled by train-
ing on samples from the joint distribution p(x, y), it
is reasonable to expect LIC’s proposers to assign high
probability to values for the latent variable x from both
modes. In contrast, uncompiled methods such as ran-
dom walk Metropolis-Hastings (RWMH) and NUTS
may encounter diﬃculty crossing the low-probability
energy barrier and be unable to escape the basin of
attraction of the mode closest to their initialization.

tained by a variety of MCMC algorithms as well as
ground truth samples. HMC with adaptive step size
(Hoﬀman and Gelman, 2014), NMC, and NUTS with
the default settings as implemented in Stan (Carpenter
et al., 2017) are all unable to escape the mode they are
initialized in. While both LIC and RWMH with adap-
tive step size escape the local mode, RWMH’s sam-
ples erroneously imply equal mixture component prob-
abilities whereas LIC’s samples faithfully reproduce a
higher component probability for the right-hand mode.

3.2 Conjugate Gaussian-Gaussian Model

We next consider a Gaussian likelihood with a Gaus-
sian mean prior, a conjugate model with closed-form
posterior given by:

x ∼ N (0, σx),

Pr[x | y, σx, σy] ∼ N

y ∼ N (x, σy)
(cid:32)

σ−2
y
x + σ−2
σ−2

y

(3)

(cid:33)

y,

1
x + σ−2
σ−2

y

There is minimal approximation error because the pos-
terior density is in the same family as LIC’s GMM pro-
posal distributions and the relationship between the
Markov blanket MB(x) = {y} and the posterior mean
is a linear function easily approximated (locally) by
neural networks. As a result, we expect LIC’s pro-
posal distribution to provide a good approximation to
the true posterior and LIC to approximately imple-
ment a direct posterior sampler.

(cid:113)

x + σ2
σ2

To conﬁrm this behavior, we trained LIC with a K =
1 component GMM proposal density on 1,000 sam-
ples and show the resulting LIC proposer’s mean as
the observed value y varies in ﬁg. 4. Here σx = 2
and σy = 0.1, so the marginal distribution of y
(i.e. the observations sampled during compilation in
eq. (2)) is Gaussian with mean 0 and standard devia-
tion
y ≈ 2.0025. Consistent with our expecta-
tions, LIC provides a good approximation to the true
posterior for observed values y well-represented during
training (i.e. with high probability under the marginal
p(y)). While LIC also provides a reasonable proposer
by extrapolation to less represented observed values y,
it is clear from ﬁg. 4 that the approximation is less
accurate. This motivates future work into modifying
the forward sampling distribution used to approximate
eq. (2) (e.g. “inﬂating” the prior) as well as adapting
LIC towards the distribution of observations y used at
inference time.

3.3 Robustness to Nuisance Variables

This intuition is conﬁrmed in ﬁg. 3, which illustrates
kernel density estimates of 1,000 posterior samples ob-

An important innovation of LIC is its use of a declara-
tive PPL and ability to query for Markov blanket rela-

Accelerating Metropolis-Hastings with Lightweight Inference Compilation

Figure 3: When sampling the bi-modal posterior density from ﬁg. 1, only inference compilation (IC, this paper)
and adaptive step-size random walk Metropolis-Hastings (Adaptive RWMH, Garthwaite et al. (2016)) are able
to recover both posterior modes. Whereas RWMH’s posterior samples erroneously assign approximately equal
probability to both modes, IC’s samples faithfully reproduce the ground truth and yields higher probability for
the mode at x = 10 than the mode at x = 0.

artifacts.

We reproduce trace-based IC as described in Le et al.
(2017) using the author-provided PyProb1 software
package, and implement Program 1 from Harvey et al.
(2019) with the source code illustrated in listing 1
where 100 nuisance random variables are added. Note
that although nuisance has no relationship to the re-
mainder of the program, the line number where they
are instantiated has a dramatic impact on perfor-
mance. By extending the trace between where x and y
are deﬁned, trace-based IC’s RNNs degrade due to dif-
ﬁculty learning a long-range dependency(Hochreiter,
1998) between the two variables. For LIC, the equiv-
alent program expressed in the beanmachine declara-
tive PPL (Tehrani et al., 2020) is shown in listing 2. In
this case, the order in which random variable declara-
tions appear is irrelevant as all permutations describe
the same probabilistic graphical model.

1 def magnitude ( obs ) :
2

x = sample ( Normal (0 , 10) )
for _ in range (100) :

3

4

5

6

7

8

9

nuisance = sample ( Normal (0 , 10) )

y = sample ( Normal (0 , 10) )
observe (

obs **2 ,
likelihood = Normal ( x **2 + y **2 , 0.1) )

return x

Listing 1: A version of Program 1 from Harvey et al.
(2019) to illustrate nuisance random variables

1https://github.com/probprog/pyprob

In a conjugate normal-normal model,
Figure 4:
LIC’s proposal distribution mean (dashed orange line)
closely follows the closed-form posterior mean (blue
solid line) across a wide range of observed values y.

tionships so that only statistically relevant inputs are
utilized when constructing proposal distributions. To
validate this yields signiﬁcant improvement over prior
work in IC, we reproduced an experiment from Har-
vey et al. (2019) where nuisance random variables (i.e.
random variables which are statistically independent
from the queried latent variables/observations whose
only purpose is to extend the execution trace) are in-
troduced and the impact on system performance is
measured. As trace-based inference compilation uti-
lizes the execution trace preﬁx to summarize program
state, extending the trace of the program with nui-
sance random variables typically results in degrada-
tion of performance due to diﬃculties encountered by
RNN in capturing long range dependencies as well as
the production of irrelevant neural network embedding

0.0000.0250.0500.075Densitymethod=AdaptiveHMC(Hoﬀman2014)method=AdaptiveRWMH(Garthwaite2016)method=GroundTruth−5051015x0.0000.0250.0500.075Densitymethod=InferenceCompilation(thispaper)−5051015xmethod=NMC(Arora2020)−5051015xmethod=NUTS(Standefaults)1050510y (Observed value)1050510valueLearning a conjugate model's posteriorvariableClosed-form meanMean of LIC proposerLiang, Arora, Tehrani, Li, Tingley, Meijer

# params

compile time

ESS

LIC (this paper)
Le et al. (2017)

3,358
21,952

44 sec.
472 sec.

49.75
10.99

Figure 5: Number of parameters, compilation time
(10,000 samples), and eﬀective sample size (100 sam-
ples) for inference compilation in declarative (beanma-
chine, this work) versus imperative (pyprob, Le et al.
(2017)) PPLs

1 class NuisanceModel :
2

@random_variable
def x ( self ) :

3

4

5

6

7

8

9

10

11

12

13

return dist . Normal (0 , 10)

@random_variable
def nuisance ( self , i ) :

return dist . Normal (0 , 10)

@random_variable
def y ( self ) :

return dist . Normal (0 , 10)

@random_variable
def noisy_sq_length ( self ) :

return dist . Normal ( self . x () **2 +

self . y () **2 , 0.1)

Listing 2: The equivalent program in beanmachine,
where
in program
are
speciﬁcation

independencies

explicit

Figure 6a shows the results of performing inference
using LIC compared against other MCMC inference
methods. All methods yield similar predictive log-
likelihoods on held-out test data, but LIC and NUTS
yield signiﬁcantly higher ESS and (cid:98)Rs closer to 1.0 sug-
gesting better mixing and more eﬀective sampling.

3.5 n-Schools

The eight schools model (Rubin, 1981) is a Bayesian
hierarchical model originally used to model the eﬀec-
tiveness of schools at improving SAT scores. n-schools
is a generalization of this model from 8 to n possi-
ble treatments, and is used at a large internet com-
pany for performing Bayesian meta-analysis Sutton
and Abrams (2001) to estimate eﬀect sizes across a
range of industry-speciﬁc applications. Let K denote
the total number of schools, nj the number of district-
s/states/types, and jk the district/state/type of school
k.

β0 ∼ StudentT(3, 0, 10)
τi ∼ HalfCauchy(σi)

βi,j ∼ N (0, τi)

yk ∼ N (β0 +

(cid:88)

i

βi,jk , σk)

for i ∈ [district, state, type]
for i ∈ [district, state, type], j ∈ [ni]

Figure 5 compares the results between LIC and trace-
based IC (Le et al., 2017) for this nuisance variable
model. Both pyprob’s defaults (1 layer 4 dimension
sample embedding, 64 dimension address embedding,
8 dimension distribution type embedding, 10 compo-
nent GMM proposer, 1 layer 512 dimension LSTM)
and LIC’s defaults (used for all experiments in this
paper, 1 layer 4 dimension node embedding, 3 layer
8 dimension Markov blanket embedding, 1 layer node
proposal network) with a 10 component GMM pro-
poser are trained on 10,000 samples and subsequently
used to draw 100 posterior samples. Although model
size is not directly comparable due diﬀerences in model
architecture, pyprob’s resulting models were over 7×
larger than those of LIC. Furthermore, despite requir-
ing more than 10× longer time to train, the resulting
sampler produced by pyprob yields an eﬀective sample
size almost 5× smaller than that produced by LIC.

3.4 Bayesian Logistic Regression

Consider a Bayesian logistic regression model over d
covariates with prior β ∼ Nd+1(0d+1, diag(10, 2.51d))
iid∼ Bernoulli(σ(β(cid:62)xi)) where
and likelihood yi
σ(t) = (1 + e−t)−1 is the logistic function. This model
is appropriate in a wide range of classiﬁcation prob-
lems where prior knowledge about the regression coef-
ﬁcients β are available.

| xi

Figure 6b presents results in a format analogous to sec-
tion 3.4. Here, we see that while both LIC and NUTS
yield higher PLLs (with NUTS outperforming LIC in
this case), LICs ESS is signiﬁcantly higher than other
compared methods. Additionally, the (cid:98)R of NUTS is
also larger than the other methods which suggests that
even after 1,000 burn-in samples NUTS has still not
properly mixed.

4 Conclusion

We introduced Lightweight Inference Compilation
(LIC) for building high quality single-site proposal dis-
tributions to accelerate Metropolis-Hastings MCMC.
LIC utilizes declarative probabilistic programming to
retain graphical model structure and graph neural net-
works to approximate single-site Gibbs sampling dis-
tributions. To our knowledge, LIC is the ﬁrst pro-
posed method for inference compilation within an
open-universe declarative probabilistic programming
language and an open-source implementation will be
released in early 2021. Compared to prior work, LIC’s
use of Markov blankets resolves the need for attention
to handle nuisance random variances and yields pos-
terior sampling comparable to state-of-the-art MCMC
samplers such as NUTS and adaptive RWMH.

Accelerating Metropolis-Hastings with Lightweight Inference Compilation

Figure 6: Results drawing 100 samples across 10 chains (after 1,000 burn-in / adaptation / compilation samples)
on two Bayesian inference problems. The top row of each subﬁgure aggregates over the 10 chains the (left to
right) compilation time (time to instantiate the Python class, includes neural network training for LIC and
Stan’s C++ codegen and compilation for NUTS), inference time (time from invoking infer() to when sampling
terminates), and the predictive log-likelihood (PLL) on held-out test data. The bottom row aggregates over both
the 10 chains as well as over all latent variables the (left to right) estimated expected sample size (ESS, higher is
better, Geyer (2011)) and the rank normalized (cid:98)R diagnostic (Rhat, closer to 1 is better, Vehtari et al. (2020)).

(a) Bayesian logistic regression (2000 rows, 10 features). Both LIC and Stan (NUTS) amortize the upfront compilation
cost with accelerated inference times. LIC achieves comparable PLL to NUTS Hoﬀman and Gelman (2014) and other
methods, and yields ESS comparable to NUTS and higher than any other method. The (cid:98)R of LIC is close to 1 (similar to
NUTS and lower than all other methods).

(b) n-schools (1000 schools, 8 states, 5 districts, 5 types). Again, increased compilation times are oﬀset by accelerated
inference times. In this case, LIC achieves comparable PLL to NUTS while simultaneously producing higher ESS and
lower (cid:98)R, suggesting that the resulting posterior samples are less autocorrelated and provide a more accurate posterior
approximation.

LICNMCRWMHNUTSppl010203040valuevariable = Compile timeLICNMCRWMHNUTSppl01020variable = Inference timeLICNMCRWMHNUTSppl4.34.44.54.6variable = PLLLICNMCRWMHNUTSppl100200valuevariable = ESSLICNMCRWMHNUTSppl1.21.41.6variable = RhatLICNMCRWMHNUTSppl0255075100valuevariable = Compile time (sec)LICNMCRWMHNUTSppl01020variable = Inference time (sec)LICNMCRWMHNUTSppl78910variable = PLLLICNMCRWMHNUTSppl10152025valuevariable = ESSLICNMCRWMHNUTSppl2468variable = RhatLiang, Arora, Tehrani, Li, Tingley, Meijer

References

Arora, N. S., Tehrani, N. K., Shah, K. D., Tingley,
M., Li, Y. L., Torabi, N., Noursi, D., Masouleh,
S. A., Lippert, E., and Meijer, E. (2020). Newtonian
monte carlo: single-site mcmc meets second-order
gradient methods. arXiv preprint arXiv:2001.05567.

Bingham, E., Chen, J. P., Jankowiak, M., Obermeyer,
F., Pradhan, N., Karaletsos, T., Singh, R., Szerlip,
P., Horsfall, P., and Goodman, N. D. (2019). Pyro:
Deep universal probabilistic programming. The
Journal of Machine Learning Research, 20(1):973–
978.

Bruna, J., Zaremba, W., Szlam, A., and LeCun, Y.
(2013). Spectral networks and locally connected net-
works on graphs. arXiv preprint arXiv:1312.6203.

Carpenter, B., Gelman, A., Hoﬀman, M. D., Lee, D.,
Goodrich, B., Betancourt, M., Brubaker, M., Guo,
J., Li, P., and Riddell, A. (2017). Stan: A proba-
bilistic programming language. Journal of statistical
software, 76(1).

Dai, H., Dai, B., and Song, L. (2016). Discriminative
embeddings of latent variable models for structured
data. In International conference on machine learn-
ing, pages 2702–2711.

Garthwaite, P. H., Fan, Y., and Sisson, S. A.
(2016). Adaptive optimal scaling of metropolis–
hastings algorithms using the robbins–monro pro-
cess. Communications in Statistics-Theory and
Methods, 45(17):5098–5111.

Gershman, S. and Goodman, N. (2014). Amortized in-
ference in probabilistic reasoning. In Proceedings of
the annual meeting of the cognitive science society,
volume 36.

Geyer, C. (2011). Introduction to markov chain monte
carlo. Handbook of markov chain monte carlo,
20116022:45.

Ghahramani, Z. (2015). Probabilistic machine learning
and artiﬁcial intelligence. Nature, 521(7553):452–
459.

Goodman, N. D. (2013). The principles and practice
of probabilistic programming. ACM SIGPLAN No-
tices, 48(1):399–402.

Harvey, W., Munk, A., Baydin, A. G., Bergholm, A.,
and Wood, F. (2019). Attention for inference com-
pilation. arXiv preprint arXiv:1910.11961.

Hochreiter, S. (1998). The vanishing gradient prob-
lem during learning recurrent neural nets and prob-
lem solutions.
International Journal of Uncer-
tainty, Fuzziness and Knowledge-Based Systems,
6(02):107–116.

Hoﬀman, M. D. and Gelman, A. (2014). The no-u-turn
sampler: adaptively setting path lengths in hamilto-
nian monte carlo. J. Mach. Learn. Res., 15(1):1593–
1623.

Kingma, D. P., Salimans, T., Jozefowicz, R., Chen,
X., Sutskever, I., and Welling, M. (2016).
Im-
proved variational inference with inverse autoregres-
sive ﬂow. In Advances in neural information process-
ing systems, pages 4743–4751.

Kipf, T. N. and Welling, M. (2016). Semi-supervised
classiﬁcation with graph convolutional networks.
arXiv preprint arXiv:1609.02907.

Le, T. A., Baydin, A. G., and Wood, F. (2017). In-
ference compilation and universal probabilistic pro-
gramming. In Artiﬁcial Intelligence and Statistics,
pages 1338–1348.

Lunn, D. J., Thomas, A., Best, N., and Spiegelhal-
ter, D. (2000). Winbugs-a bayesian modelling frame-
work: concepts, structure, and extensibility. Statis-
tics and computing, 10(4):325–337.

Marino,

J., Yue, Y.,
Iterative amortized inference.
arXiv:1807.09356.

and Mandt, S.

(2018).
arXiv preprint

Milch, B., Marthi, B., Russell, S., Sontag, D., Ong,
D. L., and Kolobov, A. (2007). 1 blog: Probabilistic
models with unknown objects. Statistical relational
learning, page 373.

Murray, I., Adams, R., and MacKay, D. (2010). El-
liptical slice sampling.
In Proceedings of the thir-
teenth international conference on artiﬁcial intelli-
gence and statistics, pages 541–548.

Paige, B. and Wood, F. (2016). Inference networks for
sequential monte carlo in graphical models. In In-
ternational Conference on Machine Learning, pages
3040–3049.

Papamakarios, G., Pavlakou, T., and Murray,

I.
(2017). Masked autoregressive ﬂow for density es-
timation. In Advances in Neural Information Pro-
cessing Systems, pages 2338–2347.

Pearl, J. (1987). Evidential reasoning using stochastic
simulation of causal models. Artiﬁcial Intelligence,
32(2):245–257.

Plummer, M. et al. (2003).

Jags: A program for
analysis of bayesian graphical models using gibbs
sampling.
In Proceedings of the 3rd international
workshop on distributed statistical computing, vol-
ume 124, pages 1–10. Vienna, Austria.

Porteous, I., Newman, D., Ihler, A., Asuncion, A.,
Smyth, P., and Welling, M. (2008). Fast collapsed
gibbs sampling for latent dirichlet allocation. In Pro-
ceedings of the 14th ACM SIGKDD international

Accelerating Metropolis-Hastings with Lightweight Inference Compilation

Zhang, C., B¨utepage, J., Kjellstr¨om, H., and Mandt,
S. (2018). Advances in variational inference. IEEE
transactions on pattern analysis and machine intel-
ligence, 41(8):2008–2026.

conference on Knowledge discovery and data min-
ing, pages 569–577.

Ritchie, D., Horsfall, P., and Goodman, N. D. (2016a).
Deep amortized inference for probabilistic programs.
arXiv preprint arXiv:1610.05735.

Ritchie, D., Stuhlm¨uller, A., and Goodman, N.
(2016b). C3: Lightweight incrementalized mcmc for
probabilistic programs using continuations and call-
site caching. In Artiﬁcial Intelligence and Statistics,
pages 28–37.

Rubin, D. B. (1981). Estimation in parallel random-
ized experiments. Journal of Educational Statistics,
6(4):377–401.

Scarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner,
M., and Monfardini, G. (2008). The graph neu-
ral network model. IEEE Transactions on Neural
Networks, 20(1):61–80.

Sutton, A. J. and Abrams, K. R. (2001). Bayesian
methods in meta-analysis and evidence synthesis.
Statistical methods in medical research, 10(4):277–
303.

Tehrani, N., Arora, N. S., Li, Y. L., Shah, K. D.,
Noursi, D., Tingley, M., Torabi, N., Masouleh, S.,
Lippert, E., Meijer, E., and et al. (2020). Bean
machine: A declarative probabilistic programming
language for eﬃcient programmable inference.
In
The 10th International Conference on Probabilistic
Graphical Models.

Vehtari, A., Gelman, A., Simpson, D., Carpenter, B.,
B¨urkner, P.-C., et al. (2020). Rank-normalization,
folding, and localization: An improved (cid:98)R for assess-
ing convergence of mcmc. Bayesian Analysis.

Webb, S., Golinski, A., Zinkov, R., Siddharth, N.,
Rainforth, T., Teh, Y. W., and Wood, F. (2018).
Faithful inversion of generative models for eﬀective
amortized inference. In Advances in Neural Infor-
mation Processing Systems, pages 3070–3080.

Weilbach, C., Beronov, B., Harvey, W., and Wood, F.
(2019). Eﬃcient inference amortization in graphi-
cal models using structured continuous conditional
normalizing ﬂows.

Wingate, D., Stuhlm¨uller, A., and Goodman, N.
Lightweight implementations of proba-
(2011).
bilistic programming languages via transformational
compilation.
In Proceedings of the Fourteenth In-
ternational Conference on Artiﬁcial Intelligence and
Statistics, pages 770–778.

Wood, F., Meent, J. W., and Mansinghka, V. (2014).
A new approach to probabilistic programming infer-
ence. In Artiﬁcial Intelligence and Statistics, pages
1024–1032.

