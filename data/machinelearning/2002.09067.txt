Incremental Sampling Without Replacement for Sequence Models

1
2
0
2

l
u
J

0
2

]

G
L
.
s
c
[

2
v
7
6
0
9
0
.
2
0
0
2
:
v
i
X
r
a

Kensen Shi 1 David Bieber 1 Charles Sutton 1

Abstract

Sampling is a fundamental technique, and sam-
pling without replacement is often desirable when
duplicate samples are not beneﬁcial. Within ma-
chine learning, sampling is useful for generat-
ing diverse outputs from a trained model. We
present an elegant procedure for sampling with-
out replacement from a broad class of randomized
programs, including generative neural models that
construct outputs sequentially. Our procedure
is efﬁcient even for exponentially-large output
spaces. Unlike prior work, our approach is incre-
mental, i.e., samples can be drawn one at a time,
allowing for increased ﬂexibility. We also present
a new estimator for computing expectations from
samples drawn without replacement. We show
that incremental sampling without replacement is
applicable to many domains, e.g., program syn-
thesis and combinatorial optimization.

1. Introduction

Sampling from programmatically-deﬁned distributions is a
fundamental technique. Machine learning problems often
involve learning distributions over structured objects such as
sentences, images, audio, biological sequences, and source
code. These distributions usually factorize into a product
of conditional distributions, e.g., the probability of a word
given the previous words. Such distributions are naturally
represented as programs with sampling operations, which
we call randomized programs.

To predict a structured output, traditional search methods
like beam search compute a set of predictions that approx-
imately maximize the probability according to a learned
model. However, recent work has instead favored sampling
from the model, with the goal of obtaining diverse and
higher-quality predictions (Shi et al., 2019; Fan et al., 2018;
Kool et al., 2019b; Holtzman et al., 2018; 2019; Radford
et al., 2019). The same considerations suggest that sampling

1Google. Correspondence to: Kensen Shi <kshi@google.com>.

Proceedings of the 37 th International Conference on Machine
Learning, Online, PMLR 119, 2020. Copyright 2020 by the au-
thor(s).

without replacement could be even more desirable by avoid-
ing duplicate samples, especially in machine learning where
the training objective often pushes the output distribution to
become extremely peaked.

We present a data structure called UniqueRandomizer for
sampling without replacement from randomized programs.
The main advantage is that it is incremental, allowing for
increased ﬂexibility in stopping conditions for the sampling
procedure. For instance, one can draw more samples until a
solution is found, or until a sample-based estimate has con-
verged, or enough sample diversity is obtained, and so on. A
closely related algorithm for sampling without replacement
is Stochastic Beam Search (SBS) (Kool et al., 2019b), based
on the Gumbel-top-k trick. SBS is mathematically more
complex than UniqueRandomizer and does not readily sup-
port incrementality, but it has advantages in parallelism and
in providing an importance-sampling method for statistical
estimation. Fortunately, we are able to present a combined
method with both advantages, i.e., the ﬂexibility of incre-
mental sampling and efﬁciency of batched computations.
We also derive an improved estimator that can be used with
any method of sampling without replacement.

We experimentally demonstrate that using UniqueRandom-
izer leads to higher-quality samples in program synthesis
and combinatorial optimization. More broadly, a major con-
tribution of this paper is making the case that UniqueRan-
domizer is a general technique that can be applied to many
scenarios.

2. Approach

As a motivating example, consider a program synthesis task:
given pseudocode for a short program and some input/output
examples, generate the corresponding source code. Suppose
that we train a neural sequence-to-sequence model that takes
pseudocode as input and generates candidate programs. We
would like to sample from the model until we ﬁnd a program
that satisﬁes the examples.

We do not know upfront how many samples are needed to
ﬁnd a solution, so to minimize computational waste, we
want to sample from the model incrementally, one sample
at a time until a solution is found. Furthermore, we have no
use for duplicate samples because the quality of a sampled

 
 
 
 
 
 
Incremental Sampling Without Replacement for Sequence Models

def P([h, W0, W1], C):

tokens = []
for i in range(0, 100):

h = softmax(matmul(W0, h))
probs = softmax(matmul(W1, h))
tokens.append(C(probs))

return tokens

Figure 1: A simple example of a randomized program.
This program samples from a recurrent neural network with
weights W0 and W1 and initial state h. The random choice
operator C is used to sample tokens from the outptut distri-
bution probs at each step of the RNN.

program is deterministic. Since we want to trust the trained
model’s decisions, we may apply a low temperature when
sampling, but this in turn increases the chance of sampling
duplicate programs. If we sample without replacement, then
we can obtain higher-quality samples while avoiding dupli-
cates altogether. Rejection sampling is a standard approach
for this, but can be inefﬁcient for highly skewed distribu-
tions, such as what we expect to obtain from a trained model
with low sampling temperature. Our approach solves these
issues with an augmented trie, described in Section 2.3.

2.1. Problem Formalization

In this section, we formalize the sampling problem that we
consider. To unify the broad class of distributions that our
method applies to, it is convenient to represent the distri-
bution of interest as a program. Speciﬁcally, suppose we
have a program P that deﬁnes a function mapping objects
of an arbitrary type X to those of type Y . We further en-
dow P with a second argument that acts as a source of
randomness—a random choice operation C(π), which sam-
ples from the discrete1 probability distribution π, returning
a choice c ∈ {0, . . . , len(π) − 1} with probability πc, like
numpy.random.choice in Python. Except for choices
produced by C, the program P is deterministic. Note that P
may take other input arguments, and it can use control ﬂow
including loops, conditionals, and recursion.

We call any program that has this form a discrete random-
ized program. This class of programs does not seem to have
a standard name in the literature, but it is quite broad, includ-
ing probabilistic grammars, neural sequence models, and
graphical models. Randomized programs are essentially the
subset of probabilistic programs (van de Meent et al., 2018)
without a conditioning operator. An example of a discrete
randomized program is shown in Figure 1, which samples

1A discrete randomized program P cannot draw a random
ﬂoating-point number, such as Uniform(0, 1), because this is not
a discrete probability distribution. However, the boolean expres-
sion Uniform(0, 1) < 0.3 can be rewritten as C([0.3,
0.7]) == 0, which is allowed in P.

from a recurrent neural network. Of course, randomized
programs can be more complex than this—for example, the
length of the output can be random, such as for programs
that sample from a probabilistic context free grammar.

A call to a randomized program deﬁnes a distribution
P (y = P(x, C)) over outputs y. We assume that the func-
tion call P(x, C) terminates with probability 1, although in
general this can be tricky to ensure (Booth and Thompson,
1973). Our goal is to obtain samples y1, . . . , yN from the
distribution P (y) incrementally, and without replacement
(WOR). Sampling without replacement can be formalized
as sampling from a sequence of modiﬁed distributions

PWOR(yi | y1:i−1) = P (yi = P(x, C) | yi (cid:54)∈ y1:i−1).

(1)

By sampling incrementally, we mean that samples yi are
drawn one by one with a minimal amount of computa-
tion performed for each sample. Given previous samples
y1, . . . , yN drawn WOR from P, we may easily obtain a
new sample yN +1 drawn from PWOR(yN +1 | y1:N ), without
slowing down the sampler as N increases (as is possible in
rejection sampling).

2.2. Sampling WOR with UniqueRandomizer

Our method is able to sample without replacement, even
without modifying the program P. We introduce a data
structure called UniqueRandomizer that deﬁnes a drop-in
replacement for the random choice operator C, which efﬁ-
ciently keeps track of the samples made so far to prevent du-
plicates. Here, we give an overview of the method, while in
the next section we describe the speciﬁcs of the UniqueRan-
domizer data structure and its random choice operator.

To do this, we deﬁne two additional concepts. An execution
of P produces a sequence of calls to C. Each such call takes
as input a probability distribution πi and outputs a random
choice ci ∈ {0, . . . , len(πi) − 1}. We deﬁne a trace as the
sequence of all random choices t = [c1, . . . , ch] produced
during a complete execution of P. Note that P deﬁnes a
distribution over its traces

P (t) =

h
(cid:89)

i=1

P (ci | c1, . . . , ci−1) =

h
(cid:89)

(πi)ci.

(2)

i=1

UniqueRandomizer samples traces of P, incrementally and
without replacement, according to P (t).

Sampling WOR from traces yields a sample WOR of pro-
gram outputs under a particular condition. We say that P is
trace-injective if P necessarily produces different outputs
under different traces. This usually occurs when every call
to C produces a part of the output, such as when sampling
from a sequence model. This seems to be the most common
situation in machine learning, e.g., the RNN example in Fig-
ure 1 is trace-injective. If P is trace-injective, then sampling

Incremental Sampling Without Replacement for Sequence Models

Algorithm 1 Using UniqueRandomizer to sample outputs
of P without replacement.

Algorithm 2 Random choice operation and trie construction
for UniqueRandomizer.

samples ← []
INITIALIZE()
for i ∈ {1, 2, . . . , k} do

1: procedure SAMPLEWOR(P, x, k)
2:
3:
4:
5:
6:
7:

y ← P(x, RANDOMCHOICE)
samples.append (y)
PROCESSTERMINATION()

8:

return samples

traces WOR is equivalent to sampling outputs WOR (which
follows from the change-of-variable rules for discrete dis-
tributions), so UniqueRandomizer will produce a sample of
outputs without replacement.

Trace-injectivity can be characterized more precisely. First,
we deﬁne a mapping between traces and program outputs.
Every execution of P produces a trace t and an output y; let
f (t) = y where y is the output when P executes with trace
t. Trace-injectivity means that the map f is injective. We
can extend this map to trace preﬁxes by deﬁning F (t(cid:48)) =
{f (t) | t(cid:48) is a preﬁx of t}. Then the following theorem says
that P is trace-injective when every choice contributes to
the ﬁnal output, in a certain sense (proof in Appendix A):

Theorem 1. P is trace-injective ⇐⇒ for all trace pre-
ﬁxes t(cid:48) = [c1, . . . , ch], the set of possible outputs F (t(cid:48)) is
partitioned by the next choice ch+1 ∼ C(πh+1), i.e., the set
{F ([c1, . . . , ch, ch+1]) | ch+1 ∈ {0, . . . , len(πh+1) − 1}}
is a partition of F (t(cid:48)).

UniqueRandomizer can be used to sample without replace-
ment from a trace-injective discrete randomized program
P, as shown in Algorithm 1. To obtain k samples, we
simply run P for k iterations, providing it with UniqueRan-
domizer’s RANDOMCHOICE function that remembers the
sequence of choices that are made by each invocation of P,
and prevents duplicate traces from being generated. The
way in which we do this, as well as the implementation
of the functions INITIALIZE, RANDOMCHOICE, and PRO-
CESSTERMINATION, are described in the next section.

2.3. The UniqueRandomizer Data Structure

Our main idea is to maintain an augmented trie data struc-
ture, which we call the UniqueRandomizer, containing the
traces that have been generated while executing the program
P multiple times. Nodes in the trie correspond to trace
preﬁxes seen so far. Each edge represents one element of a
trace, i.e., a possible outcome for the next call to C. A trie
node is a leaf if its trace preﬁx is actually a full trace, i.e.,
P terminates without further calls to C. After P terminates,
the trie is updated accordingly. Figure 2 shows an example.

1: procedure INITIALIZE()
2:
3:

root ← TRIENODE(parent = ∅, mass = 1)
cur ← root

if cur’s children are not initialized yet then

4: procedure RANDOMCHOICE(π)
5:
6:
7:

for 0 ≤ i < len(π) do

cur.children[i] ← TRIENODE(

parent = cur, mass = π[i] · cur.mass)

index ← randomly sample i with probability

∝ cur.children[i].mass

cur ← cur.children[index]
return index

8:

9:
10:

node ← cur
while node (cid:54)= ∅ do

11: procedure PROCESSTERMINATION()
12:
13:
14:
15:

node.mass ← node.mass − cur.mass
node ← node.parent

16:

cur ← root

Each trie node n stores its total unsampled probability mass,
denoted mass(n). If n represents the trace preﬁx t(cid:48), then
mass(n) equals

(cid:88)

traces t

1[t is unsampled] · 1[t(cid:48) is a preﬁx of t] · P (t).

(3)

We do not compute this sum directly because there will
usually be too many traces to enumerate. Instead, we can
compute the initial mass(n) value for a trie node n using
Equation (2), and then update it incrementally after a trace is
sampled (when P terminates). This is shown in Algorithm 2.

First, INITIALIZE is called exactly once, before the pro-
gram P is run. When P requests a new random choice
(RANDOMCHOICE in Algorithm 2), we look up the “current”
trie node cur that corresponds to the state of P’s execution.
If cur has not been reached before in a previous execution,
we initialize its children. Then, we sample a child ni of cur
with probability proportional to mass(ni), update cur to
ni, and return i. When one execution of P terminates, we
have sampled a full trace ts, and execute PROCESSTERMI-
NATION in Algorithm 2. We mark the corresponding node
nl as a leaf, and we must now update the mass values. The
affected nodes are nl and all of its ancestors, corresponding
to all preﬁxes of ts, including ts itself. For each affected
node na, we update mass(na) := mass(na)−P (ts), where
P (ts) equals mass(nl) before it is updated. Appendix B
proves that this scheme results in traces sampled exactly
from P (t) without replacement.

Finally, it is useful to detect when all possible traces have
been sampled. Mathematically, this simply involves check-

Incremental Sampling Without Replacement for Sequence Models

def P(C):

length = C([0.5, 0.4, 0.1])
sequence = []
for i in range(0, length):

sequence.append(C([0.75, 0.25]))

sequence.append(C([0.1, 0.9]))
return sequence

(a) A simple randomized program P that deﬁnes a distribu-
tion over binary sequences of length 1-3. P repeatedly calls
the random choice function C, which may be provided by
UniqueRandomizer (Algorithm 2).

(b) Left: trie after the partial trace [1, 0], immediately before
making the third random choice. Right: updated trie after P
terminates for the full trace [1, 0, 1].

Figure 2: An example ﬁrst run of a simple randomized program P, using UniqueRandomizer to sample without replacement
(Algorithm 1). Trie nodes store their unsampled probability mass. Shaded nodes are those that have been sampled from before,
so all of their children are instantiated. Known leaves are outlined in bold. After P terminates, PROCESSTERMINATION is
called: the leaf’s probability mass of 0.27 is subtracted from the leaf and its ancestors. On the next run of P, its ﬁrst random
choice request is again [0.5, 0.4, 0.1]. However, UniqueRandomizer’s RANDOMCHOICE function will return an index with
probability proportional to the mass values [0.5, 0.13, 0.1], reﬂecting the fact that the trace [1, 0, 1] was previously sampled.

ing if the root node has zero unsampled probability mass.
In practice however, accumulation of ﬂoating-point errors
makes this unreliable. Appendix C describes a solution.

2.4. Extensions and Optimizations

Skipping Probability Computations Notice that
the
probability distributions computed by P and passed to C are
only needed to compute initial mass values for the corre-
sponding trie node’s children. Thus, P could be modiﬁed
to only compute probability distributions when needed, de-
pending on whether the current node’s children have already
been initialized. This optimization can make sampling with
UniqueRandomizer even faster than running P in a plain
loop (i.e., naïve sampling with replacement), especially
when the same initial program states are seen many times
while drawing samples.

Incremental Batched Sampling One downside of Uni-
queRandomizer is that runs of P are difﬁcult to parallelize,
since the trie must be updated after each run of P before
the next run can start. Kool et al. (2019b) previously intro-
duced a different approach to sampling without replacement,
called Stochastic Beam Search (SBS), which is a modiﬁca-
tion of beam search using the Gumbel-top-k trick to sample
beam state expansions WOR. Like normal beam search,
SBS allows for parallelization when expanding beam states.
Section 3 compares UniqueRandomizer and SBS in detail.

the factorized probability distribution of the next sample,
conditioned on the fact that previous samples can no longer
be chosen. SBS is run with this probability distribution to
select the next batch of samples without replacement, where
beam states in SBS correspond to UniqueRandomizer’s trie
nodes. After SBS returns a batch of samples, the mass val-
ues in the UniqueRandomizer trie are updated so that the
new samples cannot be chosen by later batches.

Locally Modifying Probabilities By storing more infor-
mation in the trie, we can enable efﬁcient local updates to the
factorized probability distribution, allowing it to change over
time in response to new data while still avoiding previously-
seen samples. See Appendix D for details.

2.5. Estimating Expectations

Many statistical estimators and learning methods expect
i.i.d. samples; is there a way to reweight WOR samples so
that they can be used as if they were i.i.d.? Suppose that we
have samples s1, . . . , sk drawn without replacement from
an arbitrary distribution p(s), perhaps using UniqueRan-
domizer or some other algorithm, and we wish to estimate
the expectation Es∼p[f (s)] for some function f . Estimat-
ing an expectation from WOR samples is a fundamental
problem in survey statistics (Horvitz and Thompson, 1952),
but many of these methods do not scale computationally to
non-uniform distributions over large outcome spaces.

It is actually possible to combine the strengths of Uni-
queRandomizer and SBS, resulting in a method of incremen-
tal batched sampling where each batch allows for paralleliza-
tion and further batches can be sampled without replacement.
Intuitively, one can think of UniqueRandomizer as storing

Kool et al. (2019b) present a clever solution to this problem.
When asked to produce k samples WOR from p, SBS ac-
tually produces a sequence of samples (si, Gi), where the
set {s1, . . . , sk} is the desired WOR sample, and each Gi
is an auxiliary variable drawn from a Gumbel distribution

Incremental Sampling Without Replacement for Sequence Models

(Gumbel, 1954).2 Kool et al. use these Gumbels to construct
an unbiased estimator of the desired expectation, which we
call the threshold Gumbel estimator (TGE):

subsequent Gi, for i = 2, . . . , k + 1, in order: at every
iteration, the remaining items have a total probability of
1 − (cid:80)i−1

j=1 p(sj), so we draw

Ep[f (s)] ≈

k
(cid:88)

i=1

w(si)f (si), where w(si) =

p(si)
qκ(si)

. (4)

(cid:18)

Gi ∼ Gumbel

log

(cid:16)

1 −

i−1
(cid:88)

j=1

p(sj)

(cid:17) (cid:12)
(cid:12)
(cid:12) Gi−1 > Gi

(cid:19)

, (6)

The “threshold” κ is the (k+1)-th largest Gumbel variate ob-
tained during SBS, and qκ(si) = P (Gumbel(log p(si)) >
κ), one minus the Gumbel CDF. As usual, it is possible to
deﬁne a variant that normalizes the weights, introducing
bias while often reducing variance (Kool et al., 2019b):

Ep[f (s)] ≈

(cid:80)k

i=1 w(si)f (si)
(cid:80)k
i=1 w(si)

.

(5)

We derive an equivalent estimator for UniqueRandomizer
(which, unlike SBS, does not draw Gumbel variates or pro-
duce a κ threshold). We call this the Hindsight Gumbel
Estimator (HGE) because we ﬁrst draw samples and then
draw a set of Gumbel variates conditioned on the samples.
After drawing the Gumbels “in hindsight” to obtain κ, we
directly apply Equation (4) or (5). In fact, this technique
applies to any method of sampling without replacement.
For example, if the probabilities can be enumerated, one
can sample an element according to the given probabilities,
set that element’s probability to zero, and renormalize the
remaining probabilities before drawing the next sample.

To obtain κ from samples obtained with UniqueRandomizer,
we draw a decreasing sequence of k + 1 Gumbel variates
G1, . . . , Gk+1 to match the samples s1, . . . , sk (and the re-
maining unsampled probability mass), as if we had used
the Gumbel-top-k trick (Vieira, 2014) with G1, . . . , Gk+1
to sample s1, . . . , sk. In the Gumbel-top-k trick, one ﬁrst
draws a Gumbel variate from Gumbel(log p(s)) for every
element s in some sample space S. By selecting the maxi-
mum k such Gumbels, one actually obtains a WOR sample
of k elements from S from the distribution p.

The SBS algorithm implicitly deﬁnes a joint distribu-
tion P (G1, . . . , Gk+1, s1, . . . , sk). From WOR samples
s1, . . . , sk produced by UniqueRandomizer, we sample
the hindsight Gumbels from the conditional distribution
P (G1, . . . , Gk+1 | s1, . . . , sk) induced by SBS3. To do
this, we use a key property of Gumbels:
if we draw
Gi ∼ Gumbel(log p(si)) for every element si in some
sample space, then maxi Gi ∼ Gumbel(log (cid:80)
Because s1 is the ﬁrst sample, G1 is the maximum Gumbel,
so we draw G1 ∼ Gumbel(log(1)). Then, we draw the

i p(si)).

2Kool et al. (2019b) and Maddison and Tarlow (2017) provide
an excellent overview of Gumbels. For more on the Gumbel-top-k
trick, see Vieira (2014) and Kool et al. (2019b).

3Sampling from this conditional distribution is related to the
single-sample retrospective Gumbel question considered by Mad-
dison and Tarlow (2017) and Dinh (2016).

where the condition reﬂects the fact that si−1 was sampled
before si. Appendix B of Kool et al. (2019b) describes
a numerically stable way to draw Gi from this truncated
Gumbel distribution. At the end, we assign κ := Gk+1 and
apply Equation (4) or (5). This procedure samples from
the same joint distribution over G1, . . . , Gk+1, s1, . . . , sk
as SBS. Therefore, HGE is equivalent to TGE in the sense
that the two estimators have the same distribution, but HGE
is more generally applicable to any algorithm for sampling
without replacement.

Intuitively, the variance in HGE can be attributed to the
samples s1, . . . , sk and the stochastically-chosen κ. We can
reduce variance in the latter case by repeating the “hindsight
Gumbel” process to draw multiple κ (using the same sam-
ples), producing multiple HGE estimates. Averaging these
gives the Repeated HGE estimate with lower variance.

3. Analysis and Comparison to Related Work

SBS Stochastic Beam Search (Kool et al., 2019b) is a
prior method of sampling WOR from sequence models. It
is similar to UniqueRandomizer but has key differences.

First, one main advantage of UniqueRandomizer is that it
draws samples incrementally, while SBS returns a ﬁxed-
size batch of samples. Thus, UniqueRandomizer allows for
increased ﬂexibility in the number of samples drawn, e.g.,
drawing samples until a solution is found, until a timeout is
reached, after sampling a target fraction of the probability
space, until reaching enough diversity in samples, or after
the Hindsight Gumbel Estimator (Section 2.5) begins to
converge. These kinds of stopping criteria would not be pos-
sible with SBS4. Because UniqueRandomizer can be used
with any arbitrary stopping criterion, it enables sampling-
based approaches to be applicable in more scenarios. For
example, given a model that generates candidate solutions
to a Traveling Salesman Problem instance, SBS could be
used to ﬁnd the best tour among a ﬁxed number of samples,
but it would not be able to efﬁciently ﬁnd a tour with cost
below some threshold. In contrast, UniqueRandomizer is
applicable in the latter case due to its incrementality.

Second, like normal beam search, the input to SBS is a

4Although beam search and SBS produce batches of distinct
samples, drawing multiple batches may lead to duplicates between
batches. One also cannot reuse computation performed for one
batch without an auxiliary data structure, which is the purpose of
the trie in the incremental batched version of UniqueRandomizer.

Incremental Sampling Without Replacement for Sequence Models

next-state function that enumerates the children of a state.
For randomized programs P, this requires “pausing” and
“unpausing” P’s execution. Thus, the state must contain
all of the program context (e.g., local variables) necessary
to resume execution. While this is easy for a sequence
model, it can be challenging for more complex programs. In
contrast, UniqueRandomizer can be elegantly implemented
as a wrapper on libraries for random number generation,
and it is agnostic to the program context that P might use.

A third difference is in the number of nodes expanded.
When sampling from machine learning models, it is usu-
ally expensive to compute the probability distribution over
a node’s children required to expand a node.
In non-
degenerate scenarios, UniqueRandomizer requires fewer ex-
pansions than SBS, since UniqueRandomizer only expands
the nodes necessary to reach the sampled leaves, while SBS
also expands states that later fall off the beam. For example,
suppose we sample k sequences of length L with a vocabu-
lary size V ≥ k. SBS expands exactly 1 + (L − 1)k beam
states. For UniqueRandomizer, the worst case is when all k
sequences have a different ﬁrst element, so UniqueRandom-
izer expands the same number of nodes as SBS. In the best
case, only L expansions are needed if all k sequences differ
only at the ﬁnal position. We also note that the combination
of UniqueRandomizer and SBS (incremental batched sam-
pling in Section 2.4) provides smooth intermediate behavior:
by sampling b batches of size k/b, we reduce the number
of expansions with high b but obtain better parallelization
for low b. Setting b = k or b = 1 reduces to the behavior of
UniqueRandomizer or SBS, respectively.

Finally, SBS maintains beam nodes for the current and next
time step, where each node stores an arbitrarily-complex
intermediate state of P. In contrast, UniqueRandomizer
stores more nodes (i.e., the entire trie), but each node only
stores one mass value. Using UniqueRandomizer to sample
outputs of P is at worst a constant factor slower than running
P in a loop5, but with the optimization in Section 2.4, the
UniqueRandomizer approach may actually be faster.

UniqueRandomizer is mathematically simpler than SBS and
was developed independently, but we build upon SBS for the
incremental batched sampling extension and the Hindsight
Gumbel Estimator.

Algorithms for Random Sampling Matias et al. (2003)
describe a dynamic tree data structure to sample from dis-
crete distributions with dynamically changing weights, but
this is not naturally adapted to sampling WOR. Various al-
gorithms have been proposed for sampling WOR (Wong

5RANDOMCHOICE takes Θ(len(π)) time, but i.i.d. sampling
requires Ω(len(π)) time anyway to create the distribution π. PRO-
CESSTERMINATION takes Θ(h) time where h is the leaf depth,
which is amortized to an extra O(1) time per random choice.

and Easton, 1980; Vinterbo, 2010; Dufﬁeld et al., 2007;
Efraimidis and Spirakis, 2006), but generally these algo-
rithms do not consider the case of factorized distributions
like (2), and so are inefﬁcient for programs with poten-
tially long traces. The relationship between these methods
and the Gumbel-max trick is described by Vieira (2014).
The incremental batched version of UniqueRandomizer is
related to the top-down Gumbel heap of Maddison et al.
(2014). An alternate way of obtaining diverse samples is to
explicitly add penalties to beam search to encourage diver-
sity (Vijayakumar et al., 2018; Li and Jurafsky, 2016). It is
likely possible that UniqueRandomizer can be alternatively
implemented using a continuation-passing style and other
techniques common in probabilistic programming (Good-
man and Stuhlmüller, 2014).

4. Experiments

We demonstrate that UniqueRandomizer can lead to im-
provements in a variety of applications.

4.1. Program Synthesis

We apply UniqueRandomizer to program synthesis as de-
scribed in the motivating example (Section 2). We use the
Search-based Pseudocode to Code (SPoC) dataset (Kulal
et al., 2019), which is a collection of 677 problems from pro-
gramming competitions with 18,356 C++ solution programs
written by competitors. Each line of each program has an
accompanying human-authored line of pseudocode. Addi-
tionally, each problem has corresponding test cases that we
can use to verify the correctness of a solution program. The
goal is to translate given pseudocode into a code solution
for the problem. Compared to natural language translation,
the difference is that our “translation” is expected to be syn-
tactically correct code consistent with the test cases, and
even a single token error likely means that the translation is
incorrect.

We train a Transformer model (Vaswani et al., 2017) on
the sequence-to-sequence task of generating a line of code
given a line of pseudocode. Details are in Appendix E. To
sample full programs, we iteratively condition the model on
each line of pseudocode and sample one code line for each.
Concatenating the code lines produces the full program.

We evaluate on the 3,386 pseudocode prompts in the two
test splits of the SPoC dataset, “testp” and “testw,” draw-
ing up to 100 samples for each pseudocode prompt. We
compare sampling with replacement (using Monte Carlo
i.i.d. sampling) and sampling without replacement (using
the batched version of UniqueRandomizer with batch size
10). Each sampled program is checked for correctness using
the provided test cases. We use a temperature τ = 0.8 when
sampling with replacement and τ = 0.4 when sampling

Incremental Sampling Without Replacement for Sequence Models

(a) For SPoC testp, in 47 samples, Uni-
queRandomizer achieves the same success
rate as i.i.d. sampling does in 100 samples.

(b) For SPoC testw, in 66 samples, Uni-
queRandomizer achieves the same success
rate as i.i.d. sampling does in 100 samples.

(c) Efﬁciency of various sampling meth-
ods for a 12-line program. The batched
UniqueRandomizer is the fastest overall.

Figure 3: Experiment results on the SPoC dataset for program synthesis.

without replacement, which we found to be the best among
{0.2, 0.4, 0.6, 0.8, 1.0}. Note that a low temperature leads
to samples for which the model is more conﬁdent but also
causes more duplicates when sampling with replacement.

For both methods of sampling, we report the number of
pseudocode prompts for which a sampled program passes all
test cases. Figures 3a and 3b show that UniqueRandomizer
ﬁnds solutions with fewer samples than i.i.d. sampling, and
succeeds on more prompts overall.

The success rate of our approach is slightly lower than the
method in Kulal et al. (2019) which achieves 32.5% success
on testp and 51.0% on testw, with a budget of 100 programs
and without using compiler diagnostics for error localization.
This may be because Kulal et al. use a more sophisticated
model with a copy mechanism and coverage vector, while
we simply use a vanilla Transformer. In any case, Kulal
et al. ﬁnd that using compiler diagnostics increases the
success rate by 1.7% on testp and 2.7% on testw, while our
approach of sampling WOR improves over i.i.d. sampling
by a comparable amount, 2.0% on testp and 2.3% on testw.

Our objective in this experiment was not to surpass the state-
of-the-art, but rather to show that using UniqueRandomizer
to draw samples without replacement leads to signiﬁcant im-
provement over sampling with replacement. Note that beam
search and SBS are existing methods of drawing unique
samples, but they are not incremental and would be difﬁcult
to use in this setting where one does not know upfront how
many samples are needed. Additionally, sampling a pro-
gram takes about 3 times as long as compiling and executing
it on the test cases, so drawing fewer samples is important.

Efﬁciency We also examine the efﬁciency of various sam-
pling methods in Figure 3c, where we draw 100 samples
with a GPU using the same medium-sized pseudocode
prompt with 12 lines. We observe that UniqueRandom-

izer is more than twice as fast as Monte Carlo i.i.d. sam-
pling, explained by the optimization of skipping probability
computations (Section 2.4). Further note that UniqueRan-
domizer produces unique samples, while Monte Carlo i.i.d.
sampling does not. Rejection sampling is a naïve method
of obtaining unique samples but it is slower than Monte
Carlo i.i.d sampling, in fact becoming progressively slower
as more samples are drawn. SBS achieves a low time for
100 samples by using batched computations, but all samples
are drawn simultaneously, even if a solution is found within
the ﬁrst few samples, and there is no easy way to draw
further unique samples if the ﬁrst 100 samples are insufﬁ-
cient. The batched version of UniqueRandomizer allows
for drawing further batches of unique samples, while still
taking advantage of batched computation. Thus, if fewer
than 100 samples were actually needed, the batched version
of UniqueRandomizer would be signiﬁcantly faster than
SBS. We also compare to a naïve way of using SBS “incre-
mentally,” where the batch size doubles on each iteration as
min{2 · (previous batch size), 100} and duplicate samples
between batches are discarded, but this method is much
slower than UniqueRandomizer.

4.2. Traveling Salesman Problem

Sampling without replacement can be used for combinato-
rial optimization problems, such as the Traveling Salesman
Problem (TSP). Several deep learning models for TSP have
been proposed (Bello et al., 2016; Deudon et al., 2018; Kool
et al., 2018), where the model outputs candidate tours, and
the best tour is chosen among multiple samples drawn from
the model. Most recently, the Attention Model by Kool et al.
(2018) was shown to be better than the others on randomly-
generated TSP instances with n = 20, 50, and 100 nodes.

We compare sampling with and without replacement from
the Attention Model, using 1280 samples as in Kool et al.
(2018), as well as 100 samples. We also record the number

Incremental Sampling Without Replacement for Sequence Models

Table 1: Sampling without replacement from the Attention Model (Kool et al., 2018) improves upon i.i.d. sampling. We
show results for 100 and 1280 samples per TSP instance. Concorde (Applegate et al., 2003) is an exact solver, and “Gap” is
the optimality gap relative to Concorde’s exact solution.

Method

Cost

n = 20
Gap

Duplicates Cost

n = 50
Gap

Duplicates Cost

n = 100
Gap

Duplicates

Concorde (exact)
3.8357
AM, with rep. ×100
3.8397
AM, with rep. ×1280
3.8381
AM, w/o rep. ×100
3.8361
AM, w/o rep. ×1280 3.8358

0%
0.105%
0.063%
0.011%
0.002%

–
96.8
1274.5
0
0

5.696
5.735
5.724
5.726
5.712

0%
0.69%
0.49%
0.53%
0.29%

–
63.6
1121.3
0
0

7.765
7.979
7.944
7.979
7.942

0%
2.77%
2.31%
2.76%
2.28%

–
4.2
218.9
0
0

Table 2: UniqueRandomizer applied to the farthest insertion heuristic for TSP outperforms two of three recent deep-learning
approaches (Bello et al., 2016; Deudon et al., 2018; Kool et al., 2018). For methods marked with (*), the results are copied
from Kool et al. (2018). All of the sampling approaches use 1280 samples per TSP instance.

Method

n = 20

n = 50

n = 100

Cost

Gap

Cost

Gap

Cost

Gap

Concorde (exact)
Bello et al., i.i.d. sampling (*)
EAN, i.i.d. sampling (*)
AM, i.i.d. sampling
Farthest Insertion, greedy (1 tour)
Farthest Insertion, UniqueRandomizer

3.8357

3.84
3.8381
3.9262
3.8372

–

0%

5.696
5.75
5.77
0.11%
0.063% 5.724
2.358% 6.011
0.038% 5.746

0%
7.765
0.95% 8.00
1.28% 8.75
0.49% 7.944
5.53% 8.354
0.88% 7.981

0%
3.03%
12.70%
2.31%
7.59%
2.79%

of duplicate tours sampled in each setting, which quantiﬁes
the amount of computation wasted by i.i.d. sampling (with
replacement). Table 1 shows the results on Kool et al.’s
dataset. Observe that i.i.d. sampling (used by Kool et al.)
results in many duplicate tours, especially on the smaller
graphs. The duplicate rate also increases with the number
of samples, e.g., from 63.6% duplicate in 100 samples to
87.6% duplicate in 1280 samples for n = 50. In contrast,
sampling without replacement avoids duplicates altogether,
leading to better ﬁnal costs. For n = 20, sampling 100
tours without replacement outperforms sampling 1280 i.i.d.
tours with replacement (with optimality gaps of 0.011% and
0.063% respectively).

For this application, incremental sampling with UniqueRan-
domizer is 5-25% faster than naïve incremental i.i.d. sam-
In the
pling due to the optimization from Section 2.4.
batched case, sampling without replacement using SBS is
about 45-80% slower than batched i.i.d. sampling, but for
the smaller graph sizes, the slowdown of SBS is outweighed
by the beneﬁt of avoiding duplicate samples.

Farthest Insertion To demonstrate that UniqueRandom-
izer is applicable to a wide range of randomized programs,
we also consider the farthest insertion heuristic for TSP,
which is the best greedy baseline in Kool et al. (2018)’s
results. This heuristic maintains a cycle for a subset of the

nodes, and on each iteration, the node that is farthest from
the cycle is inserted into the cycle at the cheapest location
(such that the new cycle has minimal cost). We transform
the greedy heuristic into a discrete randomized program by
relaxing the greedy choice for insertion location. Speciﬁ-
cally, if inserting a node at location i causes the cycle’s cost
to increase by costDelta(i), then we sample an insertion lo-
cation i with probability proportional to costDelta(i)−1/τ
where τ is a temperature hyperparameter. In the limit, τ = 0
corresponds to the greedy heuristic, while τ = ∞ corre-
sponds to choosing an insertion location uniformly. We set
τ = 0.3, 0.2, and 0.15 for n = 20, 50, and 100 nodes, re-
spectively. These choices of τ were obtained from a simple
search over the range 0.05 ≤ τ ≤ 0.5.

We then use UniqueRandomizer to sample candidate tours
without replacement from the modiﬁed farthest insertion
heuristic. The results are in Table 2. We found that the
heuristic approach actually outperforms two of the three
learned models included in Kool et al. (2018)’s comparison,
in fact outperforming all three for n = 20.

This result is encouraging given the simplicity of this exper-
iment. We started with a well-known greedy heuristic, and
by changing only a few lines of code, we turned it into a
randomized program via a straightforward relaxation and
used UniqueRandomizer to sample without replacement.
By tuning only one hyperparameter (the temperature τ ),

Incremental Sampling Without Replacement for Sequence Models

efﬁcient sampling, and the batched version is even more
efﬁcient.

Because UniqueRandomizer is compatible with a broad
class of programs, we believe it could be applicable to other
problems beyond those explored in this paper. As with
our program synthesis and TSP experiments, UniqueRan-
domizer can be used to sample distinct outputs of a neu-
ral model to solve search problems (including constraint
satisfaction problems) or obtain diversity in natural lan-
guage generation (Kool et al., 2019b). One can also use
UniqueRandomizer to perform distinct rollouts in reinforce-
ment learning (Kool et al., 2019a) or Monte Carlo Tree
Search (Browne et al., 2012) to estimate the value of a state
with the Hindsight Gumbel Estimator until that estimate
converges sufﬁciently. UniqueRandomizer may also be use-
ful in the context of randomized rounding (Raghavan and
Tompson, 1987) and probabilistic programming (van de
Meent et al., 2018).

Our Python implementations of UniqueRandomizer, its
batched version, Stochastic Beam Search, and the Hindsight
Gumbel Estimator can be found at https://github.
com/google-research/unique-randomizer.

Acknowledgments

The authors would like to thank David Dohan, Andreea
Gane, David Belanger, Danny Tarlow, and Percy Liang for
helpful conversations and explorations.

References

David Applegate, Robert Bixby, Vasek Chvatal, and William
Cook. Concorde TSP solver, 2003. URL http://www.
math.uwaterloo.ca/tsp/concorde/.

Irwan Bello, Hieu Pham, Quoc V Le, Mohammad Norouzi,
and Samy Bengio. Neural combinatorial optimiza-
arXiv preprint
tion with reinforcement
arXiv:1611.09940, 2016.

learning.

T. L. Booth and R. A. Thompson. Applying probability
measures to abstract languages. IEEE Transactions on
Computers, C-22(5):442–450, May 1973. ISSN 0018-
9340. doi: 10.1109/T-C.1973.223746.

Cameron B Browne, Edward Powley, Daniel Whitehouse,
Simon M Lucas, Peter I Cowling, Philipp Rohlfshagen,
Stephen Tavener, Diego Perez, Spyridon Samothrakis,
and Simon Colton. A survey of monte carlo tree search
methods. IEEE Transactions on Computational Intelli-
gence and AI in games, 4(1):1–43, 2012.

Michel Deudon, Pierre Cournut, Alexandre Lacoste, Yos-
siri Adulyasak, and Louis-Martin Rousseau. Learning
heuristics for the TSP by policy gradient. In International

Figure 4: HGE variations on synthetic data. The sample
space has 100 elements, and all HGE variations converge
to the exact value after all elements are sampled. We drew
2000 sequences of samples. Dotted and solid lines show the
inner 90% and 50% of the data, respectively.

and without any training, we obtained results that are com-
petitive with those of carefully-constructed deep learning
models.

4.3. (Repeated) Hindsight Gumbel Estimator

In Section 2.5 we proposed the Hindsight Gumbel Estima-
tor for Ep[f (s)], the expectation of a function of samples
drawn without replacement from a distribution p. HGE can
be normalized using Equation (5) and/or repeated. Figure 4
shows the performance of the estimators on synthetic data.
The Monte Carlo estimate simply averages f (s) for i.i.d. s
sampled with replacement. We see that HGE, normalized
and repeated for 10 iterations, has the lowest variance. We
chose a heavily-skewed p so that sampling with replacement
encounters many duplicates, and we enforce a strong corre-
lation between p and f (or else incorrect estimators might
appear to do well). These properties are common when
performing estimation in the context of machine learning.

5. Conclusion

We presented UniqueRandomizer, an efﬁcient data struc-
ture for incremental sampling without replacement. We
also derived the Hindsight Gumbel Estimator, a new estima-
tor for samples drawn without replacement that has lower
variance than similar previous estimators. Our experiments
show that sampling without replacement leads to signiﬁcant
improvements over i.i.d. sampling in program synthesis
and combinatorial optimization. The incremental nature of
UniqueRandomizer is especially important in domains like
program synthesis where the number of required samples
is not known upfront. By eliminating redundant probabil-
ity computations, UniqueRandomizer also allows for very

Incremental Sampling Without Replacement for Sequence Models

Conference on the Integration of Constraint Program-
ming, Artiﬁcial Intelligence, and Operations Research,
pages 170–181. Springer, 2018.

Sumith Kulal, Panupong Pasupat, Kartik Chandra, Mina
Lee, Oded Padon, Alex Aiken, and Percy Liang. Spoc:
Search-based pseudocode to code. 2019.

Laurent Dinh.

Gumbel-max

trick

inference.

https://laurent-dinh.github.io/2016/
11/22/gumbel-max.html, 2016.

Nick Dufﬁeld, Carsten Lund, and Mikkel Thorup. Priority
sampling for estimation of arbitrary subset sums. J. ACM,
54(6), December 2007. ISSN 0004-5411. doi: 10.1145/
1314690.1314696. URL http://doi.acm.org/10.
1145/1314690.1314696.

Pavlos S Efraimidis and Paul G Spirakis. Weighted random
sampling with a reservoir. Information Processing Letters,
97(5):181–185, 2006.

Angela Fan, Mike Lewis, and Yann Dauphin. Hierarchical

neural story generation. In ACL, 2018.

Noah D Goodman and Andreas Stuhlmüller. The Design and
Implementation of Probabilistic Programming Languages.
http://dippl.org, 2014. Accessed: 2020-8-13.

Emil Julius Gumbel. Statistical theory of extreme values
and some practical applications: a series of lectures,
volume 33. US Government Printing Ofﬁce, 1954.

Ari Holtzman, Jan Buys, Maxwell Forbes, Antoine Bosse-
lut, David Golub, and Yejin Choi. Learning to write with
cooperative discriminators. In Association for Computa-
tional Linguistics, 2018.

Ari Holtzman, Jan Buys, Maxwell Forbes, and Yejin Choi.
The curious case of neural text degeneration. CoRR,
abs/1904.09751, 2019. URL http://arxiv.org/
abs/1904.09751.

D. G. Horvitz and D. J. Thompson. A generalization of sam-
pling without replacement from a ﬁnite universe. Journal
of the American Statistical Association, 47(260):663–685,
1952. ISSN 01621459. URL http://www.jstor.
org/stable/2280784.

Wouter Kool, Herke van Hoof, and Max Welling. Atten-
tion, learn to solve routing problems! arXiv preprint
arXiv:1803.08475, 2018.

Wouter Kool, Herke van Hoof, and Max Welling. Buy 4
ICLR

REINFORCE samples, get a baseline for free!
Workshop, 2019a.

Wouter Kool, Herke van Hoof, and Max Welling. Stochas-
tic beams and where to ﬁnd them: The Gumbel-top-k
trick for sampling sequences without replacement. CoRR,
abs/1903.06059, 2019b. URL http://arxiv.org/
abs/1903.06059.

Jiwei Li and Dan Jurafsky. Mutual information and diverse
decoding improve neural machine translation. CoRR,
abs/1601.00372, 2016. URL http://arxiv.org/
abs/1601.00372.

Chris J. Maddison and Danny Tarlow. Gumbel ma-
https://cmaddis.github.io/

chinery.
gumbel-machinery, 2017.

Chris J Maddison, Daniel Tarlow, and Tom Minka. A*
sampling. In Advances in Neural Information Processing
Systems, pages 3086–3094, 2014.

Yossi Matias,

Jeffrey Scott Vitter,

and Wen-Chun
Ni. Dynamic generation of discrete random vari-
Theory of Computing Systems, 36(4):329–
ates.
358, Aug 2003.
doi: 10.1007/
ISSN 1433-0490.
s00224-003-1078-6. URL https://doi.org/10.
1007/s00224-003-1078-6.

Alec Radford,

Jeffrey Wu, Rewon Child, David
Luan, Dario Amodei, and Ilya Sutskever.
Lan-
guage models are unsupervised multitask learn-
ers.
URL
https://d4mucfpksywv.cloudfront.net/
better-language-models/language_
models_are_unsupervised_multitask_
learners.pdf.

Unpublished manuscript,

2019.

Prabhakar Raghavan and Clark D Tompson. Randomized
rounding: a technique for provably good algorithms and
algorithmic proofs. Combinatorica, 7(4):365–374, 1987.

Kensen Shi, Jacob Steinhardt, and Percy Liang. FrAngel:
component-based synthesis with control structures. In
ACM SIGPLAN Symposium on Principles of Program-
ming Languages (POPL), 2019.

Jan-Willem van de Meent, Brooks Paige, Hongseok Yang,
and Frank Wood. An Introduction to Probabilistic Pro-
gramming. arXiv e-prints, art. arXiv:1809.10756, Sep
2018.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko-
reit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and
Illia Polosukhin. Attention is all you need. In Advances in
neural information processing systems, pages 5998–6008,
2017.

sampling.

Gumbel-max trick and weighted
http://timvieira.

Tim Vieira.
reservoir
github.io/blog/post/2014/08/01/
gumbel-max-trick-and-weighted-reservoir-sampling/,
2014.

Incremental Sampling Without Replacement for Sequence Models

Ashwin K. Vijayakumar, Michael Cogswell, Ramprasaath R.
Selvaraju, Qing Sun, Stefan Lee, David J. Crandall, and
Dhruv Batra. Diverse beam search for improved descrip-
tion of complex scenes. In National Conference on Artiﬁ-
cial Intelligence (AAAI), pages 7371–7379, 2018.

Staal A. Vinterbo. Efﬁcient sampling without replacement
https://folk.ntnu.no/staal/

in Python.
programming/algorithms/wrsampling/,
2010.

Chak-Kuen Wong and Malcolm C. Easton. An efﬁcient
method for weighted sampling without replacement.
SIAM Journal on Computing, 9(1):111–113, 1980.

Incremental Sampling Without Replacement for Sequence Models

A. Proof of Theorem 1

B. Proof of Correctness

Theorem 1. P is trace-injective ⇐⇒ for all trace pre-
ﬁxes t(cid:48) = [c1, . . . , ch], the set of possible outputs F (t(cid:48)) is
partitioned by the next choice ch+1 ∼ C(πh+1), i.e., the set
{F ([c1, . . . , ch, ch+1]) | ch+1 ∈ {0, . . . , len(πh+1) − 1}}
is a partition of F (t(cid:48)).

Proof. For any trace preﬁx [c1, . . . , ch], deﬁne the collec-
tion

F([c1, . . . , ch]) = {F ([c1, . . . , ch, ch+1])

| ch+1 ∈ {0, . . . , len(πh+1) − 1}}.

First, if P is trace-injective, then for any trace preﬁx
[c1, . . . , ch], and any c (cid:54)= c(cid:48), let y1 ∈ F ([c1, . . . , ch, c])
and y2 ∈ F ([c1, . . . , ch, c(cid:48)]). Then there exist traces

Theorem 2. Let P be a discrete randomized program that
terminates, and let P (t) be the probability that P runs with
trace t. Suppose we have already sampled distinct traces
t1, . . . , tj. If, at any UniqueRandomizer trie node n we
move to a child c with probability proportional to mass(c),
then upon reaching a leaf node, the resulting trace is drawn
from P (t | t (cid:54)∈ {t1, . . . , tj}).

Proof. Let n0, . . . , nh be any root-to-leaf path, where n0 is
the root and nh is the leaf. Let t be the trace corresponding
to nh. According to Equation (3),

mass(nh) =

(cid:40)
0
P (t)

if t ∈ {t1, . . . , tj}
otherwise.

t(1) = [c1, . . . , ch, c(1)

h+1, . . . , c(1)
h1

]

We complete the proof by showing that the leaf nh is reached
with the desired probability:

and

such that

t(2) = [c1, . . . , ch, c(2)

h+1, . . . , c(2)
h2

]

(a) c(1)

h+1 = c and c(2)

h+1 = c(cid:48),

(b) f (t(1)) = y1 and f (t(2)) = y2.

(cid:54)= t(2), so because f is injective, we
Clearly t(1)
(cid:54)= y2. Also ∪c(cid:48)F ([c1, . . . , ch, c(cid:48)]) =
have that y1
F ([c1, . . . , ch]). This means that F([c1, . . . , ch]) is a parti-
tion of F ([c1, . . . , ch]).

Conversely, assume that F(t(cid:48)) is a partition of F (t(cid:48)) for any
trace preﬁx t(cid:48). Let

and

t(1) = [c(1)

1 , . . . , c(1)
h1

]

t(2) = [c(2)

1 , . . . , c(2)
h2

]

be distinct traces. Let h be the length of their longest
common preﬁx, so c(1)
for all 1 ≤ i ≤ h, and
h+1 (cid:54)= c(2)
c(1)

h+1. By deﬁnition,

i = c(2)

i

f (t(1)) ∈ F ([c(1)

1 , . . . , c(1)

h , c(1)

h+1])

and

f (t(2)) ∈ F ([c(2)
= F ([c(1)

1 , . . . , c(2)
1 , . . . , c(1)

h , c(2)
h , c(2)

h+1])
h+1]).

1 , . . . , c(1)
But these two sets are disjoint, because F([c(1)
h ])
partitions the set F ([c(1)
1 , . . . , c(1)
h ]). Therefore, f (t(1)) (cid:54)=
f (t(2)), establishing that f is injective and that P is trace-
injective.

P (nh is reached)
h
(cid:89)

P (ni is the selected child of ni−1)

mass(ni)
c∈children(ni−1) mass(c)

(cid:80)

i=1

h
(cid:89)

i=1

h
(cid:89)

=

=

=

=

=

=

mass(ni)
mass(ni−1)

i=1
mass(nh)
mass(n0)

mass(nh)

i=1 P (ti)

1 − (cid:80)j
(cid:40)0

1

P (t)

1−(cid:80)j

i=1 P (ti)
= P (t | t (cid:54)∈ {t1, . . . , tj}).

(7)

if t ∈ {t1, . . . , tj}
otherwise

Equality (7) holds because a non-leaf node’s mass equals
the sum of its children’s mass values.

C. Detecting Exhausted Nodes

We say that a trie node is exhausted if it has zero unsampled
probability mass, i.e., all of its probability mass is sampled.
Due to ﬂoating-point errors, a node’s mass might not be set
to exactly zero after it should be exhausted. We handle this
by carefully propagating the information that a given node
has zero unsampled probability mass.

When a node n is marked as a leaf, we directly assign
mass(n) := 0. Then, when subtracting mass from one of
n’s ancestors a, we ﬁrst check if mass(c) = 0 for all chil-
dren c of a. If so, we directly set mass(a) := 0 instead of

Incremental Sampling Without Replacement for Sequence Models

a hidden dimension size of 512. We train using ADAM
with learning rate 0.05 and batch size 512 for 12,000 steps,
which is approximately when the models achieve their low-
est evaluation loss. We use linear learning rate warmup for
the ﬁrst 1,000 steps. These hyperparameters were chosen
from the search space in Table 3, selecting the run with the
lowest evaluation loss at the end of training. As in Kulal
et al. (2019), we withhold 10% of the training examples as
the validation set.

Some of the shorter lines of code in the SPoC dataset have
no pseudocode. In some of these instances, we augment the
line with pseudocode ourselves. Speciﬁcally, if the line is
exactly “}” or “};” we provide pseudocode “end”, if the
line is exactly “int main() {” we provide pseudocode
“main”, and if the line is exactly “return 0;” we provide
pseudocode “return”.

using a subtraction operation. With this approach, a node’s
mass will be exactly 0 after all of its descendent leaves are
sampled. Algorithm 3 includes this process, elaborating on
the pseudocode in Algorithm 2.

D. Locally Modifying the Factorized

Probability Distribution

A slight modiﬁcation of UniqueRandomizer’s trie allows
for efﬁcient local updates to the factorized probability dis-
tribution. Instead of storing unsampled probability masses
of nodes, the modiﬁed trie nodes now store the unsampled
fraction of the node’s total probability mass. Edges in the
trie now store the initial probability of following that edge
from the source node, as given in the probability distribution
provided by P.

Note that the unsampled probability mass of a node n is
equal to the product of the edge probabilities from the root to
n, times the unsampled fraction at n. Therefore, by accumu-
lating the product of edge probabilities while walking down
the trie, we can compute the unsampled probability mass of
nodes, so we can recreate the original UniqueRandomizer
behavior with the modiﬁed trie.

This decomposition enables local modiﬁcations to the fac-
torized probability distribution. More precisely, suppose
that a trie node n has k children, denoted n1, . . . , nk, and n
initially has outward edge probabilities of p1, . . . , pk. We
wish to change these edge probabilities to p(cid:48)
k, so
that further samples come from the updated probability dis-
tribution and previously-seen samples are still avoided. We
do this by updating the trie in the following way. First,
we directly replace n’s outward edge probabilities with the
desired p(cid:48)
k. Then, we compute the new unsampled
fraction at n with a weighted average of n’s children:

1, . . . , p(cid:48)

1, . . . , p(cid:48)

unsampledFraction(n) :=

k
(cid:88)

i=1

edgeProbability(n, ni) · unsampledFraction(ni).

Finally, we perform a similar update for all of n’s ancestors
in upward order (with the root being updated last). After
these updates, all values in the trie reﬂect the new probability
distribution.

E. Program Synthesis Experiment Details

For the program synthesis task, we train a Transformer
model (Vaswani et al., 2017) to translate lines of pseudocode
to lines of C++ code. We use the Transformer implemen-
tation in the Trax framework6. The Transformer uses 2
attention heads, 3 hidden layers, a ﬁlter size of 1024, and

6https://github.com/google/trax.

Incremental Sampling Without Replacement for Sequence Models

Table 3: The search space used for tuning the Transformer model.

Hyperparameter

Search space

Selected value

Learning rate
Hidden layers
Hidden dimension size
Attention heads
Filter size

{0.05, 0.075, 0.1, 0.15}
{1, 2, 3}
{512, 1024}
{2, 4}
{512, 1024}

0.05
3
512
2
1024

Algorithm 3 UniqueRandomizer, with careful detection of
exhausted nodes

(cid:46) Called once to initialize the data structure

1: procedure INITIALIZE()
2:
3:

root ← TRIENODE(parent = ∅, mass = 1)
cur ← root

(cid:46) Whether node is completely sampled

4: procedure EXHAUSTED(node)
if node is a leaf then
5:
return True
6:
7:
8:
9:

return False

if node has never been sampled from before then

return whether all of node’s children have 0 mass

(cid:46) Called when P requests a random choice

10: procedure RANDOMCHOICE(π)
11:
12:

if EXHAUSTED(cur) then

raise Error(“no more unique traces exist”)

13:
14:
15:

16:

17:
18:

if cur’s children are not initialized yet then

for 0 ≤ i < len(π) do

cur.children[i] ← TRIENODE(

parent = cur, mass = π[i] · cur.mass)

index ← randomly sample i with probability

∝ cur.children[i].mass

cur ← cur.children[index]
return index

(cid:46) Called after P terminates

mark cur as a leaf
node ← cur
while node (cid:54)= ∅ do

19: procedure PROCESSTERMINATION()
20:
21:
22:
23:
24:
25:
26:

if EXHAUSTED(node) then

node.mass ← 0

else

node.mass ← max{node.mass − cur.mass,
0}

27:

28:

node ← node.parent

cur ← root

