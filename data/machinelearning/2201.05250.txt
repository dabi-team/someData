2
2
0
2

g
u
A
8

]

C
O
.
h
t
a
m

[

2
v
0
5
2
5
0
.
1
0
2
2
:
v
i
X
r
a

Consistent Approximations in Composite Optimization

Johannes O. Royset
Operations Research Department
Naval Postgraduate School
joroyset@nps.edu

Abstract.
Approximations of optimization problems arise in computational procedures and sensi-
tivity analysis. The resulting eﬀect on solutions can be signiﬁcant, with even small approximations of
components of a problem translating into large errors in the solutions. We specify conditions under
which approximations are well behaved in the sense of minimizers, stationary points, and level-sets
and this leads to a framework of consistent approximations. The framework is developed for a broad
class of composite problems, which are neither convex nor smooth. We demonstrate the framework
using examples from stochastic optimization, neural-network based machine learning, distributionally
robust optimization, penalty and augmented Lagrangian methods, interior-point methods, homotopy
methods, smoothing methods, extended nonlinear programming, diﬀerence-of-convex programming,
and multi-objective optimization. An enhanced proximal method illustrates the algorithmic possibili-
ties. A quantitative analysis supplements the development by furnishing rates of convergence.

Keywords: set-convergence, epi-convergence, graphical convergence, approximation theory.

Date: August 10, 2022

1

Introduction

A fundamental approach to optimization is to replace an actual problem by an approximating one,
which is then solved using an existing algorithm. In sensitivity analysis, the actual problem of interest
is also replaced by approximating ones for the purpose of identifying the eﬀect of perturbations. These
situations raise the questions: If some portion of an optimization problem is changed and the resulting
problem is solved, would the obtained solution be a reasonable approximation of a solution of the actual
problem? How large would the solution error be relative to the magnitude of the initial change? These
questions are further complicated by the need for considering both optimal and stationary points in the
nonconvex setting. Thus, we aspire to construct approximations that have minimizers and stationary
points near the corresponding points for the actual problem. We may even seek approximating objective
functions and feasible sets that are near those of the actual problem in a broad sense.

In this paper, we provide a comprehensive framework for constructing and analyzing approximations
of optimization problems with a composite structure. We provide suﬃcient conditions for consistent
approximations, which guarantee that the approximating problems eventually become accurate relative
to the actual problem in the sense of minimizers, stationary points, and level-sets. Examples from
stochastic optimization, neural-network based machine learning, distributionally robust optimization,
penalty and augmented Lagrangian methods, interior-point methods, homotopy methods, smoothing

1

 
 
 
 
 
 
methods, extended nonlinear programming, diﬀerence-of-convex programming, and multi-objective op-
timization demonstrate the framework. The algorithmic possibilities are illustrated by a proximal
composite method for solving an array of nonconvex composite problems via a sequence of convex
problems. A quantitative analysis supplements the development by furnishing rates of convergence.

We consider the broad class of composite optimization problems in the form

minimize
x∈Rn

ϕ(x) = ιX (x) + h

F (x)

,

(1.1)

(cid:0)

(cid:1)

⊂

→

→

∞}

∪ {−∞

R = R

is deﬁned in terms of a nonempty closed set
,
Rn, often representing “basic” constraints such as bounds on the variables, and a locally Lipschitz
Rm that models m quantities of interest with f1, . . . , fm being the

where the objective function ϕ : Rn
X
continuous mapping F : Rn
component functions, i.e., F (x) = (f1(x), . . . , fm(x)). For any set C, ιC(x) = 0 if x
∞
otherwise. The quantities of interest are combined by a convex function h : Rm
R, which might
assign an inﬁnite penalty to certain values of F (x). For example, h = ι{0}m sets h(F (x)) =
whenever
F (x) deviates from the zero vector and thus encodes the equality constraint F (x) = 0. The actual
problem (1.1) captures classical nonlinear programming as well as many other problem formulations.
In general, ϕ is nonconvex. The convexity assumption imposed on h is not as restrictive as it might
appear and helps us to leverage convexity properties when present.

C and ιC(x) =

∈
→

∞

The study of (1.1) and similar problems goes at least back to [45, 46]. Recent eﬀorts [35, 11, 21,
23, 17, 18, 22, 13] suggest that the problem class might be among the most important ones in the
nonconvex setting. Its structural properties are theoretically and computationally attractive, especially
to address large-scale problems in machine learning and elsewhere. Nevertheless, the actual problem
may not be solvable directly and often needs approximations. The mapping F may be approximated by
a smooth or even an aﬃne mapping. It might be speciﬁed by integrals, suprema, or other expressions
that necessitate imprecise, numerical evaluation. The function h could be nonsmooth and extended real-
valued, and then approximated by real-valued functions, piecewise aﬃne or smooth, acting as penalties.
The set X might be approximated by a polyhedron or other simpliﬁcations. The approximations can
be computationally motivated or introduced as part of sensitivity, stability, or error analysis.

Our approach is traced back to 1902 when P. Painlev´e deﬁned set-convergence.

It is now well-
known that set-convergence of epigraphs (i.e., epi-convergence) of approximating functions and set-
convergence of graphs (i.e., graphical convergence) of approximating set-valued mappings furnish the
desired convergence guarantees about the solutions of the corresponding minimization problems and
If the set-valued mappings represent optimality
generalized equations; see [50, Chap. 4, 5, and 7].
conditions for the approximating problems, then graphical convergence translates into convergence of
stationary points. We deﬁne approximating problems and their optimality conditions as being consistent
approximations of the actual problem (1.1), paired with an optimality condition, when they exhibit such
epi-convergence and graphical convergence.

In the convex setting, epi-convergence of approximating functions ϕν to the actual objective function
ϕ suﬃces for the subgradient mappings ∂ϕν to graphically converge to ∂ϕ by Attouch’s theorem; see
for example [50, Thm. 12.35]. Thus, epi-convergence of the approximating functions ensures that the
approximations are consistent. In the nonconvex case, one explicitly needs to impose conditions related

2

to the optimality conditions to guarantee convergence of stationary points and this is recognized by the
added requirement about graphical convergence of set-valued mappings in the deﬁnition of consistent
approximations. If the approximating functions ϕν are smooth, their epi-convergence to ϕ does provide
ϕν and ∂ϕ but in a less-than-ideal “outer” sense; cf. [10, Lem. 3.4] and [50,
some relation between
Cor. 8.47]. A far-reaching extension of Attouch’s theorem for nonconvex functions is provided by [44],
which implies in the context of (1.1) that epi-convergence of certain approximating functions hν to h
combined with a smooth F and a constraint qualiﬁcation suﬃce for graphical convergence in a local
sense of the resulting subgradient mappings [11].

∇

}

0, γ
{

Approximations of (1.1) may stem from the smoothing of h and/or F . The speciﬁc function γ

7→
max
can be approximated by smooth functions via convolution [15]. The approximations exhibit
both epi-convergence as well as certain convergence of gradients to the subgradients of the max-function
[14]; the reference includes many examples of such smoothing. This approach is closely related to
molliﬁers, which may even approximate discontinuous functions [25]. Further developments in these
directions are furnished by [10, 11], where in the context of (1.1), h is approximated by a smooth function
constructed using inf-convolution; see also [12] for details about smoothing of ﬁnite max-functions. For
approximations of a weakly convex expectation function caused by sample averages, [19] gives rates by
which subdiﬀerentials of the approximating functions graphically converge to the subdiﬀerential of the
expectation function.

In contrast to these eﬀorts, we consider broad sets of approximations; X, h, and F in (1.1) may
all be approximated and not necessarily smoothly. In sensitivity and error analysis, nonsmooth ap-
proximations are especially relevant as computational concerns tend to be secondary. We also deviate
from the focus on the subgradient mapping of ϕ and that of its approximations, and instead express
optimality conditions using (generalized) multipliers, which provide additional ﬂexibility for absorbing
inaccuracies. Thus, consistent approximations emerge as widely available under mild assumptions. As
compared to [19] speciﬁcally, we consider a broader range of approximations beyond sample averages
and also do not rely on weak convexity. While ϕ is weakly convex when X = Rn, h is real-valued,
convex, and Lipschitz continuous, and F is continuously diﬀerentiable with Lipschitz continuous Ja-
cobian, we emphasize situations with a nontrivial X, even nonconvex, an extended real-valued h, and
nonsmooth F .

There is an extensive literature on general approximations and related stability analysis; see the
monographs [42, 50, 7, 37, 16] as well as eﬀorts based on metric regularity and calmness [31, 40], tilt-
stability [24, 36, 20], full-stability [38], convergence of abstract iteration schemes [32], and the truncated
Hausdorﬀ distance [1, 2, 3, 52, 53]. The latter approach is closely related to the present paper, with
direct relevance to our rate of convergence analysis.

Our choice of the term “consistent approximations” is motivated by E. Polak’s concept in [42, Chap.
3-4]. There epi-convergence of approximating objective functions combined with an outer epi-limit of
approximating optimality functions (after a sign change) are deﬁned as consistent; see [51, 54, 27, 41, 55]
for applications in stochastic optimization, semi-inﬁnite programming, nonsmooth optimization, and
optimal control. Since optimality functions are essentially gap-functions of generalized equations repre-
senting optimality conditions, Polak’s concept is, roughly, equivalent to weak consistency as we deﬁne

3

it below. A related concept based on epigraphical nesting of directional derivatives is deﬁned in [29].
We deviate from these earlier developments by viewing optimality conditions as generalized equations
deﬁned by set-valued mappings and thus bypass the need for deﬁning optimality functions. This brings
into play well-developed calculus rules and computational procedures for generalized equations. The
ﬂexibility of this approach is demonstrated by a set of suﬃcient conditions for consistency (Theorem
2.4). An introductory treatment of consistent approximations under the assumption of a smooth map-
ping F is, in parallel, provided by the textbook [56]. While we limit the discussion to ﬁnite-dimensional
problems, many of the concepts can be extended; see [41, 34] for such eﬀorts.

We continue in Section 2 by stating the approximating problems, deﬁning consistency, and speci-
fying suﬃcient conditions. Section 3 furnishes 12 examples. Section 4 describes a speciﬁc algorithm.
Section 5 applies the framework to machine learning problems. Section 6 discusses rates of convergence.

|

x

∈

→

| k

Rn

−∞

f (x) <

for all x

→
∞
∈

k · k
x
∈
{

¯x
−
k ≤
(x, α)
{

R has a domain dom f =

. A function
ρ
}
Rn+1

is denoted by B(¯x, ρ) =
Rn

C implies that f (xν)
) such that

x
x
{
and an epigraph epi f =

∈
) and κ
Rn, then f is lLc. A mapping F : Rn

Terminology. A ball under norm
f : Rn
≤
∞}
. The function is lower semicontinuous (lsc) if epi f is closed and is convex if epi f is convex. It is
α
}
Rn if
proper if epi f is nonempty and f (x) >
xν
f (x). It is locally Lipschitz continuous (lLc) at ¯x when there are
C
∈
B(¯x, δ). If f is lLc at
k2 whenever x, x′
δ
(0,
| ≤
∈
Rm is lLc (at ¯x) if its component functions f1, . . . , fm
every ¯x
are lLc (at ¯x). Functions and mappings are smooth (at ¯x) if they are continuously diﬀerentiable (at ¯x).
inf f + ε
dom f
Moreover, inf f = inf
, which is simply
f (x)
∈
}
{
Rn
. The convex hull of a
written as argmin f if ε = 0. A lower level-set
α
x
}
{
∈
Rn is typically indicated by xj. We let
set C is denoted by con C. The jth component of a vector x
∈
bdry C be the boundary1 of a set C
int C, where int C is the interior of C. We
adopt the usual rules for extended arithmetic, including

and ε- argmin f =
x
{
=
α
}

It is continuous relative to C

Rn, i.e., bdry C = C

→
f (x)
|

f (x)
f (x)

x
κ
k

≤
≤

f (x′)

f (x)

Rn.

f
{

Rn

|
|

[0,

→

∞

x′

−

≤

=

−

⊂

⊂

∈

∈

∈

∈

∈

x

}

|

|

.

#

Sequences of points, sets, and so forth are usually indexed by superscript ν
xν , ν
{

∞, with convergence of

∈ N

∞ being denoted by xν

The collection of subsequences of N is denoted by
subsequence N
∃
all,” respectively. The inner limit of a sequence of sets
⊂
Rn
x
| ∃
{
∈
C ν set-converges to C
s C, if LimOut C ν
→
N
f ν : Rn
→
∈
{
place if and only if

N
→N x. The symbols
C ν
{
Rn
∈

. The outer limit is LimOut C ν =
}

Rn, denoted by C ν
⊂
epi-converge to f : Rn

R, denoted by f ν

R, ν

C ν

| ∃

xν

→

→

∈
∈

N =
N

.
1, 2, . . .
}
{
to x along a
}
mean “there exist” and “for
is LimInn C ν =
C ν

x
∈
{
. Thus,
}
LimInn C ν. The functions
s epi f . This takes
→

N
}
∈
∞ and xν
#

→N x

⊂
e f , if epi f ν
→

and
∀
Rn, ν
N

∈ N
C
⊂

∈

x

}

#

\
∞ − ∞

∞

xν

x,

∀

∀

liminf f ν(xν)
x with limsup f ν(xν)

f (x)

≥

x,
→
xν

∃

→

f (x).

≤

(1.2)

(1.3)

A set-valued mapping T : Rn
(x, y)
{

Rm has subsets of Rm as its “values” and a graph written as gph T =
converges

→→
. A sequence of set-valued mappings
T (x)
}

T ν : Rn
{

Rm, ν

Rn+m

N

∈

∈

∈

}

y

|

→→

1We exclude points in the closure of C that are not in C, which is most natural in the present context.

4

graphically to T : Rn
generalized equation v

Rm, denoted by T ν
T (x) is written as T −1(v) =

We denote the normal cone to C

Rn at x

g T , if gph T ν
→
Rn
x
{

s gph T . The set of solutions to the
→
v
|
C by NC(x) and let NC (x) =

.
T (x)
}

for x

∈

∈

⊂
∈
the set of subgradients of f : Rn
R at a point x with f (x)
These quantities are understood in the general (Mordukhovich) sense; see [50, Chap. 6 and 8].

R is ∂f (x); ∂f (x) =

→

∈

∅

∅

C. Likewise,
R.

6∈
when f (x)

6∈

→→
∈

2 Consistent Approximations

Parallel to the actual problem (1.1), we deﬁne the approximating problems

minimize
x∈Rn

ϕν (x) = ιX ν (x) + hν

F ν(x)

,

N

ν

∈

(cid:0)

(cid:1)

(cid:27)

(cid:26)

(2.1)

⊂

→

→

Rn, hν : Rm

R, and F ν : Rn

Rm are approximations of the corresponding components
where X ν
of the actual problem. We seek to conﬁrm that small discrepancies between the respective components
of the approximating and actual problems indeed translate into small errors in the solutions of the
approximating problems relative to those of the actual problem. It is clear that pointwise convergence
Rn would not suﬃce; see [50, Figure 7-1]. Uniform convergence of ϕν to ϕ
ϕν (x)
on Rn ensures that cluster points of
argmin ϕν , ν
indeed are minimizers of ϕ, but such a
requirement is too stringent, especially when X ν is diﬀerent than X or dom hν is diﬀerent than dom h.
We also would like to address convergence of stationary points for the approximating problems to those
of the actual problem and then neither pointwise nor uniform convergence of ϕν to ϕ is suﬃcient.

ϕ(x) for all x

xν
{

→

N

∈

∈

∈

}

We make the following universal assumptions for the remainder of the paper:

X, X ν are nonempty and closed;

h, hν are proper, lsc, and convex; F, F ν are lLc.

This limits the scope to a well-structured class of problems for which convenient calculus rules can be
brought in, while still addressing a vast array of applications. In particular, [50, Thm. 10.46, Exer.
10.52] lead to optimality conditions for the actual and approximating problems.

If both h and F were smooth, then 0

local minimizer of ϕ by [50, Thm. 6.12]. Here,
corresponding to the gradients of f1, . . . , fm at x. This condition is equivalently written as

∇

F (x)⊤

∈ ∇

h(F (x)) + NX(x) is a necessary condition for a
∇
F (x) is the Jacobian matrix of F at x with rows

0 = F (x)

z,

0 =

h(z)

y,

0

yi

fi(x) + NX (x),

∇
Rm are multiplier vectors. This condition naturally extends to
where y = (y1, . . . , ym)
nonsmooth h and F by essentially “replacing” gradients by subgradients. Thus, we express optimality
conditions for the actual and approximating problems concisely as the generalized equations

Rm and z

X

i=1

∇

−

−

∈

∈

∈

m

using the set-valued mappings S, Sν : Rn+2m

R2m+n given by

0

S(x, y, z)

and

0

Sν(x, y, z)

∈

S(x, y, z) =

Sν(x, y, z) =

F (x)

−
(cid:8)
F ν (x)

z

×

−

(cid:9)
z

(cid:8)
×

(cid:9)

(cid:8)

(cid:8)

i=1

yi con ∂fi(x) + NX(x)
m

yi con ∂f ν

i (x) + NX ν (x)

.

(cid:17)

(cid:17)

→→
∂h(z)

−
∂hν (z)

∈

m

y

×
(cid:9)
y
−

(cid:9)

5

(cid:16) X
×

(cid:16) X

i=1

∈

∈

∈

Rm and z

S(x, y, z) for some y

Rm, then x is a stationary point for the actual
If x satisﬁes 0
problem, with similar terminology being adopted for the approximating problems. The set of subgradi-
ents ∂fi(x) is convex when fi is epi-regular2 at x, which, for example, is the case if fi is smooth at x or
if fi is convex [50, Thm. 8.30]. Under such circumstances, “con” in the expression for S is superﬂuous.
Since fi is lLc, con ∂fi(x) coincides with the set of Clarke subgradients [50, Thm. 8.49] of fi at x.
Aligned with the approach in [50], we shy away from this terminology. We view the convexiﬁcation in
the optimality condition as stemming from a slight relaxation of otherwise valid optimality conditions
and resulting in an additional “buﬀer” to absorb approximations.

The optimality conditions generalize many familiar ones. For example, 0
only if the KKT condition hold for the actual problem with X = Rn, h(z) = z1 +

∈

S(x, y, z) if and
s
i=2 ι{0}(zi) +

m
i=s+1 ι(−∞,0](zi), and F being smooth. We see this by deriving NX (x) =

, ∂h(z) =
0
}
{

P

1
} ×
{

N{0}s−1 (z2, . . . , zs)
P

×

N(−∞,0]m−s(zs+1, . . . , zm), and

m

i=1

yi con ∂fi(x) + NX(x) =

m

i=1

fi(x)

yi

∇

X

X

so that y1 = 1, y2, . . . , ys are unrestricted in sign, and, for i = s + 1, . . . , m, yi = 0 if fi(x) < 0 and
0 if fi(x) = 0. Since even the KKT condition requires a constraint qualiﬁcation (such as the
yi
Mangasarian-Fromovitz), it is not surprising that 0
S(x, y, z) likewise requires a qualiﬁcation for it
to be a necessary optimality condition. This is formalized in the next proposition.

≥

∈

2.1 Proposition (optimality condition). Suppose that the following qualiﬁcation holds at x⋆:

Ndom h

F (x⋆)

and 0

y

∈

m

i=1

∈

yi con ∂fi(x⋆) + NX(x⋆) =

⇒

y = 0.

(2.2)

If x⋆ is a local minimizer of (1.1), then

(cid:0)

(cid:1)

X

0

∈

S(x⋆, y⋆, z⋆)

Rm and z⋆

for some y⋆
additional assumptions that X is Clarke regular at x⋆ and, for each y
yifi is epi-regular at x⋆.

Rm, with this optimality condition being equivalent to 0

∈

∈

∈

∂ϕ(x⋆) under the
∂h(F (x⋆)) and i = 1, . . . , m,

∈

Proof. Guided by [50, Exer. 10.52], the ﬁrst conclusion follows straightforwardly when recalling that
lF (x, y) =

implies

F (x), y
h

i

∂xlF (x, y)

⊂

m

i=1

∂(yifi)(x)

⊂

m

i=1

con

∂(yifi)(x)

=

m

i=1

yi con ∂fi(x)

via [50, Cor. 10.9, Thm. 9.61].

X

X

(cid:8)

(cid:9)

X

The second conclusion about equivalence with 0

˜h : Rn

Rm

×

→

R and ˜F : Rn

→

Rn+m given by

∈

∂ϕ(x⋆) holds by the following argument. For

˜h(z0, z) = ιX (z0) + h(z)

and

˜F (x) =

x, F (x)

,

2A function f is epi-regular at x if its epigraph is Clarke regular [50, Def. 6.4] at (x, f (x)).

(cid:0)

(cid:1)

6

we obtain that ϕ(x) = ˜h( ˜F (x)). Clearly, ˜F is lLc and ˜h is lsc and proper. Let l ˜F (x, (w, y)) =
˜F (x), (w, y)
. Under a qualiﬁcation, [56, Thm. 6.23] conﬁrms that
i
h

∂ϕ(x⋆) =

∂xl ˜F

x⋆, (w, y)

[(w,y)∈∂˜h( ˜F (x⋆))

(cid:0)

(cid:1)

∂˜h( ˜F (x⋆)).
as long as ˜h is epi-regular at ˜F (x⋆) and l ˜F (
·
A closer examination shows that (2.2) ensure that the qualiﬁcation of the theorem indeed holds. By
[56, Prop. 4.63], we conclude that ˜h is epi-regular at ˜F (x⋆) because X is Clarke regular at x⋆ and
, (w, y)) is epi-regular at x⋆ because yifi is assumed to be epi-regular at
∂h(F (x⋆))
x⋆; see [56, Exam. 4.70]. Thus, it only remains to untangle the expression for ∂ϕ(x⋆). We obtain that

, (w, y)) is epi-regular at x⋆ for all (w, y)

. Moreover, l ˜F (
·
∅

=

∈

∂ϕ(x⋆)

0

∈

⇐⇒ ∃

y

∈

∂h

F (x⋆)

, 0

∈

m

i=1

∂(yifi)(x⋆) + NX(x⋆),

(cid:1)
where we again appeal to [56, Exam. 4.70] to compute ∂xl ˜F (x⋆, (w, y)). Since yifi is epi-regular at x⋆,
∂(yifi)(x⋆) is a convex set and we conclude that

(cid:0)

X

∂(yifi)(x⋆) = con

∂(yifi)(x⋆)

= yi con ∂fi(x⋆),

which implies the assertion.

(cid:8)

(cid:9)

In the absence of regularity of the kind invoked in the second part of the proposition, the optimality
S(x⋆, y⋆, z⋆). For example, let X = R, h(z) =
x/2
}

x
x,
). Then, ϕ(x) = ιX (x) + h(F (x)) = max
}
S(0, y⋆, z⋆) for y⋆ = (1, 1) and z⋆ = (0, 0) because

condition 0
∈
z1 + z2, and F (x) = (max
∂ϕ(0) = [
with 0

∂ϕ(x⋆) could be strictly stronger than 0

0,
{
1/2]. In contrast, 0

, min
x, x/2
}

{−

{−

−

1,

∈

6∈

−

−
S(0, y⋆, z⋆) =

−
∈
∂h(z⋆)

F (0)

z⋆

−

×

y⋆

−

y⋆
1 con[

−

×

1, 1/2] + y⋆

2 con

{−

.

1, 0
}
(cid:1)

(cid:8)

(cid:9)

(cid:8)

∈

(cid:9)
(cid:0)
S(x, y, z) is its explicit form in terms of the
Generally, the advantage of the optimality condition 0
“primitives” of the actual problem (1.1). It is therefore much more computationally accessible than
0

∂ϕ(x), which can be checked numerically only in special cases.
Proposition 2.1 likewise conﬁrms that 0

Sν(x, y, z) is a necessary optimality condition for an
approximating problem under a qualiﬁcation parallel to (2.2). We are now in a position to state what
it means for the approximating problems, paired with their optimality conditions, to be well-justiﬁed
surrogates of the actual problem and its optimality condition.

∈

∈

2.2 Deﬁnition (consistent approximations). The pairs
tions of (ϕ, S) when

(ϕν , Sν), ν
{

N

}

∈

are consistent approxima-

If the graphical convergence is relaxed to merely LimOut(gph Sν )
weakly consistent approximations of (ϕ, S).

ϕν

e ϕ
→

and

Sν

g S.
→

gph S, then

⊂

(ϕν , Sν ), ν
{

N

}

∈

are

7

6
Under consistency, even in its weak form, we are on solid ground because the approximating problems
indeed produce approximating solutions of the actual problem as formalized next using the following
Rm, the set of δ-solutions to the generalized equation 0
notation. For T : Rn

T (x) is deﬁned as

→→
T −1

B(0, δ)

=

T −1(v) =

∈

Rn

x

∈

v

∈

T (x)

.

[v∈B(0,δ)
(cid:0)
T −1(B(0, δ)) “almost” satisﬁes 0

(cid:1)

[v∈B(0,δ)

(cid:8)

(cid:12)
(cid:12)
T (x) in the sense that v

(cid:9)

∈
δ. We observe that such near-solutions may depend on the choice of norm

∈

∈

Thus, a δ-solution ˆx
with

v
k

k ≤

T (ˆx) for some v

.
k · k

2.3 Proposition (consequences of consistency). Suppose that
approximations of (ϕ, S), the tolerances εν and δν vanish, and α < β. Then, the following hold:

are weakly consistent

(ϕν , Sν), ν
{

∈

}

N

(a) LimOut

εν- argmin ϕν

⊂

argmin ϕ, provided that dom ϕ

=

.
∅

(cid:0)
ϕν
(b) LimOut
{

≤
(c) LimOut(Sν)−1

α

} ⊂ {
B(0, δν )

(cid:1)
ϕ
≤

α

} ⊂
S−1(0).

ϕν
LimInn
{

β

.
}

≤

(cid:0)

⊂

(cid:1)

Moreover, if the approximations are consistent (and not merely weakly consistent), then there are
γν

0 such that LimInn(Sν )−1(B(0, γν ))

S−1(0).

→

⊃

Proof. This is a compilation of well-known facts; see [50, Thm. 7.31] for (a); [50, Prop. 7.7] for (b);
and [50, Thm. 5.37] for (c) and the ﬁnal statement.

Consistency indeed guarantees a comprehensive sense of approximation tailored to the need of
minimization problems. From (a) in the proposition, we see that every cluster point of a sequence of
near-minimizers of the approximating problems is a minimizer of the actual problem provided that the
tolerances vanish. That is, if xν
argmin ϕ.
This is a valuable property, but remains somewhat conceptual in nonconvex settings because there
might be no practical algorithm for computing near-minimizers of the approximating problems. Item
(b) shows that the lower level-sets of ϕν eventually become essentially indistinguishable from those of
ϕ. For example, if ϕν (xν )
α by the ﬁrst inclusion in (b). The second
inclusion in (b) establishes that any ¯x with ϕ(¯x)
β.
≤
Thus, ϕν accurately “predicts” the values of ϕ as ν

α can be approached by points xν with ϕν (xν)

→N ¯x along a subsequence N

εν- argmin ϕν

¯x, then ϕ(¯x)

∞, then ¯x

α and xν

∈ N

→

≤

≤

≤

∈

∈

#

.

Item (c) conﬁrms that any cluster point (¯x, ¯y, ¯z) of a sequence

∈
Sν(xν , yν, zν ), satisﬁes 0
S(¯x, ¯y, ¯z). This holds even if the points (xν, yν , zν ) are computed with
tolerances δν as long as they vanish. The approximating problems and their optimality conditions
are often constructed such that computing nearly stationary points is indeed possible in ﬁnite time;
see Section 3 for examples. Combining the facts from (b) and (c), we summarize: If N
∞ and
(xν , yν, zν )

B(0, δν )

(Sν )−1

∈ N

∈

∈

#

(xν , yν, zν ), ν
{

N

, with 0
}

→ ∞

∈

(cid:0)

→N (¯x, ¯y, ¯z), then
S−1(0)

(cid:1)
(¯x, ¯y, ¯z)

∈

and ϕ(¯x)

liminfν∈N ϕν (xν).

≤

8

6
Thus, ¯x is stationary for the actual problem, with an objective function value at least as good as
predicted by the approximations.

These consequences occur under weak consistency. Passing to consistency, we achieve enhanced
robustness in the sense that every stationary point of the actual problem can be approached by nearly
stationary points of the approximating problems.
In fact, the proposition guarantees that for some
tolerances γν

0, one has (Sν)−1(B(0, γν ))

The proposition justiﬁes the following broad algorithmic framework for solving the actual problem.

s S−1(0).
→

→

Consistent Approximation Algorithm.

Data.

δν

≥

0, with δν

0.

→

Step 0. Set ν = 1.

Step 1. Minimize hν ◦ F ν over X ν until one obtains xν, with corresponding (yν , zν ), satisfying

Step 2. Replace ν by ν + 1 and go to Step 1.

(cid:0)

(cid:1)

(xν, yν , zν )

∈

(Sν )−1

B(0, δν )

.

A multitude of implementation details remain unsettled. What approximations are most suitable
for the actual problem at hand? What subroutine should be used in Step 1 and with what δν ? We list
many examples of approximations in Section 3 and describe a concrete algorithm in Section 4.

Veriﬁcation of consistency is supported by suﬃcient conditions for epi-convergence of ϕν to ϕ and
graphical convergence of Sν to S. There are several known results. For example, if X = X ν = Rn,
e ϕ by [10, Thm. 3.2]; see also [50,
F = F ν are smooth with
→
Chap. 5 and 7]. The following conditions appear especially versatile by allowing for approximations of
X, h, and F under relatively mild assumptions.

F having rank m, and hν

e h, then ϕν
→

∇

2.4 Theorem (suﬃcient conditions for consistent approximations). Suppose that hν
with these sets being convex, and, for i = 1, . . . , m, one has the property:

e h, X ν
→

s X
→

xν
vν

∈

∈

X ν
∂f ν

x
→
i (xν )

X

∈

)

f ν
i (xν)
=
vν , ν
⇒ (
{

→
N
∈

fi(x)

is bounded with all its cluster points in con ∂fi(x).

}

(2.3)

Then, each one of the following conditions is suﬃcient for
approximations of (ϕ, S):

(ϕν , Sν), ν
{

N

}

∈

to be weakly consistent

(a) (real-valuedness): h is real-valued.

(b) (pointwise convergence): hν(z)

all x

∈

X and X

⊂

→
X ν for each ν.

h(z) for all z

∈

bdry(dom h) and, in addition, F ν(x) = F (x) for

(c) (monotonicity): For each ν: hν (z)
F (x) for all x

F ν(x)

X.

≤

∈

hν (¯z) when z

¯z, hν(z)

≤

≤

≤

h(z) for all z, X

X ν , and

⊂

9

(d) (interior points): h is continuous relative to dom h, X

X ν for each ν, and for all x

F (x)

bdry(dom h), there is xν

X

⊂
x such that F (xν )

int(dom h).

∈
(e) (separability): For

∈
r
k=1 mk = m, lLc F ν
→
R, k = 1, . . . , r, one can express F ν(x) = (F ν
1 (x), . . . , F ν

→

∈

P

r
k=1 hν
hk(zk) for all zk
P

k(zk), and h(z) =

bdry(dom hk) and F ν

P

∈

k , Fk : Rn

Rmk , and proper, lsc, and convex hν

k, hk :
r (x)), F (x) = (F1(x), . . . , Fr(x)),
r
k=1 hk(zk) with hk being either real-valued or hk satisfying
X ν .

X. Moreover, X

k (x) = Fk(x) for all x

∈

⊂

Rmk
→
hν(z) =
hν
k(zk)

→

X with

∈

i = fi, then (2.3) holds automatically.
i , fi are convex and f ν

We also have the reﬁnements:
If X ν = X, then each of (a)-(e) remains suﬃcient without the convexity assumption on X.
If f ν
If f ν
If X ν = X and (c) holds, then f ν
If X ν = X and f ν
If f ν
If f ν

i , fi are smooth, then (2.3) is equivalent to f ν
i , fi are smooth, then each of (a)-(e) is suﬃcient for consistent approximations.

i = fi, then each of (a)-(e) is suﬃcient for consistent approximations.

e fi, then (2.3) holds automatically.

fi(x) in (2.3) is relaxed to liminf f ν

fi(x) as xν

fi(x) and

i (xν)
f ν

i (xν)

i (xν)

i (xν)

fi(x).

i →

→ ∇

→

→

∇

≥

X ν

x.

→

∈

Proof. We start by establishing ϕν
Since neither ιX(x) nor h(F (x)) is equal to

e ϕ. To prove the liminf-condition (1.2) for ϕν and ϕ, let xν
→

x.

→

liminf

ιX ν (xν ) + hν
(cid:16)

F ν(xν )

liminf ιX ν (xν) + liminf hν

F ν(xν )

.

≥

Certainly, X ν
ιX ν (xν ) =
cause X ν

(cid:0)
e ιX and then also liminf ιX ν (xν )
s X implies that ιX ν
→
→
. Thus, we assume without loss of generality that xν

X ν , then
X be-
e h. These facts ensure that liminf hν(F ν (xν ))
→
h(F (x)). When combined with the earlier inequalities, this relation establishes the liminf-condition

∞
s X. By assumption, F ν (xν)
→

X ν . This implies that x

F (x) and hν

(cid:0)
ιX (x).

(cid:1)
If xν

→

≥

∈

∈

6∈

≥
(1.2) for ϕν and ϕ, which thus holds without any of the additional conditions (a)-(e).

Next, we establish the limsup-condition (1.3) for ϕν and ϕ. Let x

Rn be arbitrary. If x

dom h, then ϕ(x) =

F (x)
then we argue as follows:

6∈

∞

and the limsup-condition holds trivially. If x

First, suppose that (a) holds. Since X ν

x. Moreover, hν converges
uniformly to h on compact sets because h is convex and real-valued; see [50, Thm. 7.17]. Consequently,
hν (F ν(xν ))

s X, there exists xν
→

h(F (x)) and one has

X ν

→

∈

→

Second, suppose that (c) holds. Since X

X ν , we construct

limsup

ιX ν (xν) + hν
(cid:16)

(cid:0)

F ν(xν)

limsup ιX ν (xν ) + limsup hν

F ν(xν )

= h

F (x)

.

≤

(cid:1)(cid:17)

⊂

h(F (x)). This holds because F ν(x)

F (x) and then hν (F ν (x))

(cid:0)

xν = x, ν
{

(cid:1)
∈

N

}

(cid:0)
and simply need

(cid:1)

≤

≤

to prove that limsup hν(F ν (x))
hν (F (x))

h(F (x)) for all ν

≤
N.

≤

∈

Third, suppose that (d) holds. We consider two cases. Suppose that F (x)

construct
bounded subsets of the interior of dom h; see [50, Thm. 7.17]. Next, suppose that F (x)

and note that hν (F ν (x))

xν = x, ν
{

int(dom h). Then,
h(F (x)) because hν converges uniformly to h on
bdry(dom h).

→

N

∈

∈

}

∈

10

∈

X and F (x)

∈

∈

X or
6∈
dom h,

,

−∞

(cid:1)(cid:17)

)

∈

X

→

→

x with F (¯xk)

→
int(dom h) for all k. Let εk

∈
0 such that B(F (¯xk), δk)
F (¯xk) as ν

Then, by condition (d), there are ¯xk
(0,
δk
∞
∈
¯xk
X ν , F ν(¯xk)
X
∩
∈
for all ν
interior of dom h (again cf. [50, Thm. 7.17]), there is ¯νk
for all ν
and xν = ¯xk for ¯νk < ν
As ν
, k tends to
recall that h is continuous on its domain. We have shown that limsup hν(F ν (xν))

int(dom h). Consequently, there exist
0. Fix k. Since
B(F (¯xk), δk)
N, with νk
νk. Since hν converges uniformly to h on B(F (¯xk), δk) by virtue of that set being in the
h(F (¯xk)) + εk
N. Now, we construct xν = ¯x1 for ν = 1, . . . , ¯ν2
¯νk+1. Then, xν
¯νk+1.
≤
as well in this expression. Thus, its right-hand side converges to h(F (x));

(0,
k, be such that F ν (¯xk)

¯νk. We repeat these arguments for all k

h(F (xν )) + εk for all ¯νk < ν

νk such that hν(F ν (¯xk))

∈
x and hν (F ν(xν ))

⊂
. Let νk

h(F (x)).

≤
∞

→ ∞

→ ∞

∞

→

→

≤

≥

≥

≥

≥

≤

∈

∈

∈

)

X ν , one has x

∈

⊂

X ν for all ν and we construct

≤

Fourth, suppose that (e) holds. Since X
. Certainly, F ν (x)
F (x) and
}

xν = x, ν
{

N

∈

limsup

ιX ν (xν) +

k (xν)
F ν

limsup ιX ν (x) +

≤

r

k=1

limsup hν
k

F ν

k (x)

.

(cid:16)

X

(cid:0)

(cid:1)(cid:17)

Suppose that hk is real-valued. Then, hν
convex; see [50, Thm. 7.17]. This implies that hν
bdry(dom hk) and F ν
hν
k(zk)
→
we have Fk(x)
If Fk(x)
∈
summary,

hk(zk) for all zk
dom hk.
int(dom hk), then hν

∈
k(Fk(x))

∈
If Fk(x)

→

∈

k (x))

k(F ν
→
k (x′) = Fk(x′) for all x′

k converges uniformly to hk on compact sets because hk is
hk(Fk(x)). Alternatively, suppose that
dom h,
hk(Fk(x)).
hk(Fk(x)) as well because these functions are convex. In

bdry(dom hk), then, by assumption, hν

X. Since F (x)

k(Fk(x))

→

∈

∈

X

(cid:0)

(cid:1)

→
hν
k

r

k=1

r

k=1

limsup hν
k

F ν

k (x)

=

r

k=1

hk

Fk(x)

and the needed limsup-condition holds.

(cid:1)
Fifth, suppose that (b) holds. This is a special case of (e) with r = 1.
We have conﬁrmed that each one of (a)-(e) suﬃces for ϕν

(cid:0)

(cid:1)

(cid:0)

X

X

the convexity of X ν and X.

e ϕ and, in fact, this holds even without
→

We next turn to the relation between gph Sν and gph S and start by showing LimOut(gph Sν)

gph S. Let (¯x, ¯y, ¯z, ¯u, ¯v, ¯w)
uν

→N ¯u, vν

∈

→N ¯v, and wν
uν = F ν (xν)

→N ¯w with (xν , yν, zν , uν , vν , wν )
yν, wν
∂hν (zν )
zν,

vν

LimOut(gph Sν). Then, there are N

∞, xν
gph Sν. Consequently,

∈ N

#

→N ¯x, yν

→N ¯y, zν

⊂
→N ¯z,

m

i=1

i con ∂f ν
yν

i (xν) + NX ν (xν ).

−

∈
The existence of wν implies that xν
s X, we also have ¯x
set. Since X ν
→
Attouch’s theorem [50, Thm. 12.35] states that hν
The inclusion for wν implies that there exist

−

∈

∈
X. Thus, F ν(xν )

X ν because otherwise NX ν (xν) would have been an empty
¯z.
¯y.

→N F (¯x) and we conclude that ¯u = F (¯x)
g ∂h. Consequently, ¯v
∂h(¯z)
→

e h implies ∂hν
→

−
−

∈

∈

∈

X

aν
i ∈

con ∂f ν

i (xν ), i = 1, . . . , m,

such that wν

m

i=1

i aν
yν

i ∈

NX ν (xν).

−

(2.4)

By Caratheodory’s theorem, there are λν
ij ≥
i0, . . . , λν
(λν
ijbν
and aν
{
a convergent subsequence. By assumption (2.3),

ij. The sequence

n
j=0 λν

i =

0 and bν
ij ∈
in), ν
∈
bν
ij, ν
{

P

∈

}

X

∂f ν
N

i (xν), j = 0, 1, . . . , n, such that

ij = 1
is contained in a compact set and thus has
is bounded with all its cluster points in

n
j=0 λν

}
N

P

11

con ∂fi(¯x). Consequently, there exist ¯λi = (¯λi0, . . . , ¯λin)
which we also denote by N , such that

∈

R1+n, ¯bi0, . . . , ¯bin, and a subsequence of N ,

(λν

i0, . . . , λν

in)

This means that

¯λi

→N

≥

0, with

n

j=0

X

¯λij = 1,

and

bν
ij →N

¯bij

∈

con ∂fi(¯x).

aν
i →N ¯ai =
j=0
X
e ιX implies NX ν
Via Attouch’s theorem [50, Thm. 12.35], ιX ν
→
i →N ¯yi and wν
Using this fact as well as the observations that yν
m
i=1 ¯yi¯ai
from (2.4) that ¯w
∈

NX (¯x). Thus, because ¯ai

¯λij¯bij

−

∈

∈

n

con ∂fi(¯x).

g NX because X ν and X are convex.
→
m
i=1 ¯yi¯ai, we obtain

m
i=1 yν
i →N ¯w
con ∂fi(¯x), one has

i aν

−

−

P

P

P

¯w

∈

m

i=1

¯yi con ∂fi(¯x) + NX(¯x)

and we conclude that (¯u, ¯v, ¯w)
holds without leveraging any of the conditions (a)-(e).

∈

S(¯x, ¯y, ¯z). We have established that LimOut(gph Sν)

X

gph S and this

⊂

Under the modiﬁed assumption that X ν = X, but not necessarily convex, we still have NX ν =
g NX because NX is outer semicontinuous; see [50, Prop. 6.6]. Thus, the above argument carries
→

NX
over.

If f ν
Prop. 8.7].

i = fi, then (2.3) holds automatically because fi is lLc and ∂fi is outer semicontinuous; see [50,

If X ν = X and (c) holds, then limsup f ν

i (xν )

following by continuity of fi.

limsup fi(xν ) = fi(x), with the last equality

≤

If f ν

i , fi are convex and f ν
i (xν ), ν
Cluster points of the sequence
Thm. 12.35]. It only remains to show that the sequence is bounded. We recall that

e f , then [56, Prop. 4.18] establishes that f ν
i →
vν
{

i (xν )
¯x.
must be in ∂fi(¯x) by Attouch’s theorem; see [50,

fi(¯x) if xν

∂f ν

→

→

N

∈

∈

}

i
(cid:9)

i
(cid:9)

∂f (x) = argminv

f ∗(v)

v, x

− h

and

∂f ν(x) = argminv

f ν∗(v)

v, x

− h

(cid:8)

∈

Rn; see [50, Prop. 11.3]. Here, f ∗ and f ν∗ are the conjugates of f and f ν, respectively,
for every x
which are also proper, lsc, and convex by the Fenchel-Moreau theorem 5.23 in [56]. By Wijsman’s
theorem [50, Thm. 11.34], f ν∗
, ¯x
as seen
) such that
from [56, Prop. 4.19(a)]. Since ∂f (¯x) is compact by [56, Prop. 2.54], there is ρ
∂f (¯x) = argmin g
for some
argminbdry B g.
v
Since argmin g
argminbdry B g. Thus, regardless of η being ﬁnite or
not, there is δ

e f ∗ and then we also have gν = f ν∗
→

B(0, ρ/2). Let B = B(0, ρ). Set η = inf bdry B g. If η <

, g(v⋆) > inf g for v⋆
∅
) such that

bdry B so [56, Thm. 4.9] applies, argminbdry B g

, and η = g(v⋆) for all v⋆
∅

− h·
∞
∈
, then g(v) <

bdry B =
(0,

e g = f ∗

i →

, xν

− h·

(0,

∞

∞

=

⊂

∈

∈

∈

i

(cid:8)

∩
∈

∞

g(v)

≥

inf g + δ

v

∀

∈

bdry B.

(2.5)

Since ∂f (¯x) is nonempty by [56, Prop. 2.25], there is ¯v
convergence, gν
exists ν0 such that gν(wν )

e g implies that there are points wν
→

¯v such that limsup gν(wν )

argmin g. From the deﬁnition of epi-
g(¯v). Thus, there
ν0. For the sake of contradiction, suppose

B for all ν

inf g + 1

3 δ and wν

→

≤

∈

≤

∈

≥

12

6
that there are N
N . For ν
all ν
and wν , i.e., zν = (1
applied to gν implies that

∈ N
∈

−

∈

N with ν

#

∞ such that

6∈

N

B, ν

vν
{

gν (wν ) for
ν0, let zν be the unique point in bdry B on the line segment between vν
[0, 1]. The convexity inequality ([56, Prop. 1.10])

argmin gν , one has gν (vν )

. Since vν
}

≤

∈

∈

λν)vν + λνwν for some λν

≥

∈

(1

(1

−

λν)gν (vν ) + λνgν (wν )
λν)gν (wν ) + λνgν (wν ) = gν(wν )

gν (zν )

≤

≤
ν0. Since

−
zν , ν
{

inf g + 1
3 δ

≤

(2.6)

∈

≥

N, ν

N with ν

for ν
∈
cluster point ¯z
∈
we ﬁnd that liminf ν∈N gν (zν )
gν
this contradicts (2.6) and we conclude that vν

is contained in the compact set bdry B, it has a
bdry B. After passing to the corresponding subsequence, which we also denote by N ,
inf g + δ, where the ﬁrst inequality follows from the fact that
3 δ. However,

g(¯z)
e g and the second one by (2.5). Thus, for suﬃciently large ν
→

B for all but a ﬁnite number of ν.
∈
Under the assumption that X ν = X and f ν
i = fi, we show that LimInn(gph Sν)

N , gν (zν)

inf g + 2

ν0}

≥

≥

≥

≥

∈

gph S. Let

⊃

(¯x, ¯y, ¯z, ¯u, ¯v, ¯w)

∈

gph S. This means that

¯u = F (¯x)

¯z,

¯v

∂h(¯z)

¯y,

∈

−

−
Set xν = ¯x, yν = ¯y, and wν = ¯w. Since hν
that ∂hν
¯v and zν
This means that (xν, yν , zν, uν , vν , wν )
LimInn(gph Sν) and LimInn(gph Sν)
conclude that the approximations are consistent.

g ∂h and there are vν
→

→

⊃

∈

¯w

∈

m

i=1

¯yi con ∂fi(¯x) + NX(¯x).

X

¯z such that vν + ¯y

e h, it follows by Attouch’s theorem [50, Thm. 12.35]
→
zν.
→
gph Sν
gph S holds.

−
(¯x, ¯y, ¯z, ¯u, ¯v, ¯w). Consequently, (¯x, ¯y, ¯z, ¯u, ¯v, ¯w)

In view of the earlier results, Sν

∂hν(zν ). Let uν = F (¯x)

→

∈

∈
g S and we
→

For the case with smooth f ν

i , fi, the claim about (2.3) is trivial and it only remains to show

LimInn(gph Sν)

⊃

gph S. Now, we obtain the simpliﬁcation

m

i=1

yi con ∂fi(x) =

m

i=1

yi

fi(x)

=

∇

∇

F (x)⊤y

,

X

¯z, ¯v

n X
(cid:9)
with a similar expression for the approximating functions. Let (¯x, ¯y, ¯z, ¯u, ¯v, ¯w)
F (¯x)⊤ ¯y + NX (¯x). In particular, ¯x
that ¯u = F (¯x)
hν
zν

¯y, and ¯w
e h, it follows by Attouch’s theorem [50, Thm. 12.35] that ∂hν
→
→
Since NX ν

g NX , as argued above, there’s (xν , tν)
→

¯z such that vν + ¯y

gph NX ν with xν

∂hν (zν ).

∂h(¯z)

∈ ∇

−

−

∈

∈

o

(cid:8)

gph S. This means
∈
X. Set yν = ¯y. Since
¯v and

∈
g ∂h and there are vν
→

→

∈

→
F ν(xν)⊤ ¯y. We then have wν
∈
→
zν, which converges to ¯u. In summary, we have constructed
LimInn(gph Sν)

(¯x, ¯y, ¯z, ¯u, ¯v, ¯w). This means that (¯x, ¯y, ¯z, ¯u, ¯v, ¯w)

→
− ∇

∇
−

X ν
∈
¯w and wν

¯x and tν
F ν(xν)⊤ ¯y

− ∇

F (¯x)⊤ ¯y. Construct wν = tν +
¯w
NX ν (xν ). Also, construct uν = F ν(xν)
(xν , yν, zν , uν , vν , wν )
and, thus, LimInn(gph Sν)

gph Sν

→

∈

gph S holds.

∈

⊃

While we believe weak consistency is the natural goal in most applications, in some cases one might

be willing to sacriﬁce some assurances with the beneﬁt of relaxed assumptions.

2.5 Corollary (approximations without full epi-convergence). Suppose that hν
these sets being convex, and (2.3) holds for i = 1, . . . , m. Then, for α

e h, X ν
→
R and vanishing δν , one has

s X with
→

ϕν
LimOut
{

≤

α

ϕ

α
}

≤

and

LimOut(Sν)−1

} ⊂ {

∈
B(0, δν )

S−1(0).

⊂

13

(cid:0)

(cid:1)

If X ν = X, then the assertions hold without the convexity assumption on X.

ϕ(x) to hold whenever xν

Proof. Following the proof of Theorem 2.4, we see that the present assumption suﬃces for liminf ϕν(xν )
x. By [50, Prop. 7.7], the assertion about level-sets follows. Again
gph S holds without the conditions (a)-(e) in

≥
following the proof, we deduce that LimOut(gph Sν)
the theorem and we invoke [50, Thm. 5.37] to reach the conclusion.

→

⊂

The assumptions of the corollary permit the approximating ϕν to be arbitrarily “high” relative to
ϕ, i.e., LimOut(epi ϕν ) could be a strict subset of epi ϕ. This is a main reason why we avoid calling the
approximations consistent in this case. Still, the mild assumptions make the corollary widely applicable.

3 Examples

An array of examples illustrate the breadth of the framework, but numerous possibilities are omitted
including those involving polyhedral approximations of X as in [6]. We recall that X, X ν and fi, f ν
i are
nonconvex unless speciﬁed otherwise.

3.1 Example (goal optimization). For parameters αi

[0,

∈

∞

) and τi

∈

R, we consider the problem

minimize
x∈X

m

i=1

αi max

0, fi(x)

τi

,

−

which aims to lower each fi(x) down to the goal of τi, with αi being the per-unit penalty for failing to
. A possible approximation
do so. The problem is of the form (1.1) with h(z) =
}
is to set X ν = X and F ν = F , but replace h by

m
i=1 αi max

0, zi
{

−

τi

P

X

(cid:8)

(cid:9)

hν (z) =

m

i=1

αiψν (zi

−

τi), where ψν(γ) =

1
θν ln

1 + exp(θνγ)

,

θν

(0,

).

∞

∈

Since hν is convex and diﬀerentiable any number of times, it oﬀers computational beneﬁts over h.
The resulting approximating problems and their optimality conditions are consistent approximations
provided that θν
. We refer to [14, 12] for more general smoothing schemes.

(cid:0)

(cid:1)

X

→ ∞

Detail. By Theorem 2.4, condition (a), and the reﬁnements, we only need to show hν
supγ∈R

(ln 2)/θν as seen from [43], (1.2) and (1.3) hold.

max

e h. Since
→

ψν (γ)
|

−

0, γ
{

}| ≤

For an illustration of the optimality conditions, suppose that f1, . . . , fm are smooth. Then, 0

∈
NX (x). In fact, this can be written as

Sν(x, y, z) simpliﬁes to F (x) = z, y =

F (x)⊤

∇

−∇

hν (F (x))

∈

NX (x), with

hν (z),

∇

−∇

F (x)⊤y

∈

∇

hν (z) = 



α1∇

αm

∇

ψν(z1 −
...
ψν (zm

−

and

ψν(γ) =

∇

exp(θνγ)
1 + exp(θνγ)

.

τ1)

τm)






Similarly, the optimality condition 0
NX (x). Since ∂h(z) = C1 × · · · ×

∈

S(x, y, z) specializes to F (x) = z, y

∂h(z),

F (x)⊤y

Cm, where Ci =

if zi < τi, Ci = [0, αi] if zi = τi, and Ci =

∈

−∇

∈
}

αi
{

0
}
{

14

NX (x) with yi = 0 if fi(x) < τi,
otherwise, the optimality condition simpliﬁes further to
[0, αi] if fi(x) = τi, and yi = αi otherwise. These conditions are necessary for optimality in the
yi
actual and approximating problems by Proposition 2.1; the qualiﬁcation (2.2) holds in each case because
dom h = dom hν = Rm.

−∇

∈

∈

F (x)⊤y

3.2 Example (stochastic optimization). For probabilities p = (p1, . . . , pm)
set of nonnegative vectors with components summing to one, consider the problem

∈

P , where P

Rm is the

⊂

minimize
x∈X

m

i=1

pifi(x),

X
which appears in stochastic optimization and machine learning. The problem is of the form (1.1) with
m
i=1 pizi. In practice, the probabilities might not be fully known and this leads to approximating
h(z) =
m
i=1 pν
problems with p replaced by pν
i zi in (2.1). The change may also be part
of a sensitivity analysis such as when developing inﬂuence functions [33, 4]. The approximations are
consistent provided that pν

P , i.e., hν (z) =

P

P

p.

∈

→

h(z) whenever zν

e h; see (1.2) and (1.3). Thus, the
Detail. Since hν(zν )
→
consistency follows via condition (a) of Theorem 2.4. The optimality condition 0
S(x, y, z) is necessary
by Proposition 2.1 because the qualiﬁcation (2.2) holds. In fact, the optimality condition simpliﬁes to
h(z) = p.
0

m
i=1 pi con ∂fi(x) + NX(x) because y =

z, we obtain hν

→

→

∈

∇

3.3 Example (distributionally robust optimization). Let P
let A and Aν be nonempty closed subsets of P . We consider the problem

⊂

Rm be as in the previous example and

minimize
x∈X

maxp∈A

m

i=1

pifi(x)

X

s A, then the approximations are consistent.
→

and its approximation obtained by replacing A by Aν. The set A might consist of a single, true
probability vector and be approximated by a set Aν “centered” on a current best estimate of the true
probability vector with some “radius” reﬂecting the uncertainty about this estimate. The resulting
If
problems ﬁt the forms of (1.1) and (2.1) with h(z) = maxp∈A
Aν
and ˆAν(z) = argmaxp∈Aν
Detail. Let ˆA(z) = argmaxp∈Ah
. The functions h and hν are
i
convex. They are also real-valued, and thus continuous, because A and Aν are compact. To establish
hν
s A, there exists
→
pν

e h, we argue using (1.2) and (1.3). Suppose that zν
→
∈

and hν (z) = maxp∈Aν

¯p. This implies that

ˆA(z). Since Aν

z. Let ¯p

p, z
h

p, z
h

p, z
h

p, z

Aν

.
i

→

→

∈

i

i

Thus, (1.2) holds for h and hν . For ﬁxed z, let pν
(cid:0)

liminf

maxp∈Aν

p, zν
h

liminf

≥

i
(cid:1)

=

pν, zν
h

¯p, z
h
ˆAν(z). Then, for any

i

i

= maxp∈A

p, z
h

.
i
A, ν

∈

P

=

p, z
h

maxp∈Aν

z
k2k
−
s A, limsup hν(z)
¯pν
k2 →
→
e h and we again invoke condition (a) of Theorem 2.4 and the reﬁnements.
→

i
i ≤ k
0 because Aν

Since there are ¯pν
hν

A such that

pν
k

−

+

=

−

∈

i

i

pν, z
h

pν
h

pν

¯pν

¯pν, z

N

¯pν
{
∈
∈
k2 + maxp∈A

, one has
}
p, z
h

.
i

h(z). Consequently,

≤

∈

¯pν, z
h

15

3.4 Example (augmented Lagrangian methods). With h(z) = z1 +

m
i=2 ι{0}(zi), the problem

minimize
x∈X

f1(x) subject to f2(x) = 0, . . . , fm(x) = 0

P

ﬁts the mold (1.1). An approximation stemming from augmented Lagrangian methods utilizes

hν (z) = z1 +

m

i=2

i zi + 1
yν

2 θνz2
i

,

Rm−1 and θν
2 , . . . , yν
where yν = (yν
resulting approximations are consistent.

m)

∈

[0,

(cid:0)
). If

X
∞

yν , ν
{

∈

N

}

∈

(cid:1)
is bounded and θν

, then the

→ ∞

Detail. The function h is not real-valued and we turn to condition (b) of Theorem 2.4. For z
dom h = R
limsup-condition (1.3) for hν and h. For the liminf-condition (1.2), suppose that zν

∈
m−1, one has hν (z) = z1 = h(z) and the condition holds. This also conﬁrms the
0
}
× {

z. Then,

liminf hν (zν )

z1 +

≥

m

i=2

liminf(yν

i zν

i ) + 1
2

m

i=2

liminf

θν(zν

i )2

→
.

If any z2, . . . , zm is nonzero, then the right-hand side equals
zm = 0, then the right-hand size is no smaller than z1 = h(z). Thus, hν

∞

X

X
, which coincides with h(z). If z2 =

(cid:1)

=

· · ·

(cid:0)
e h.
→

3.5 Example (min-functions). For smooth gik : Rn

R, k = 1, . . . , si, i = 1, . . . , m, let

→

We adopt smooth approximations of fi by deﬁning

fi(x) = min

k=1,...,si

gik(x).

f ν
i (x) =

1
θν ln

−

si

k=1

exp

θνgik(x)

−

,
(cid:1)(cid:17)

where θν
(0,
Moreover, if in addition X ν
z

¯z, and hν (z)

∞

∈

≤

≤

(cid:16) X
); see [39, 14, 5, 12] for related smoothing techniques. If θν

(cid:0)

X, X ν

s X, with these sets being convex, hν
→

⊃

h(z) for all z, then the approximations are weakly consistent.

, then (2.3) holds.
hν(¯z) when

→ ∞
e h, hν (z)
→

≤

Detail. We leverage condition (c) of Theorem 2.4 and observe that F ν(x)

F (x) because (see [43])

≤

0

fi(x)

f ν
i (x)

ln si
θν

≤

Rn.

x

∀

∈

−
Moreover, we need to conﬁrm (2.3). Let xν
because θν

. It is apparent that f ν
i

≤

→

→ ∞

¯x. The previous inequalities show that f ν

i (xν )

is smooth and, in fact,

(3.1)

fi(¯x)

→

f ν
i (x) =

∇

si

k=1

µν
ik(x)

∇

gik(x), with µν

ik(x) =

X

Since µν
ik(x)
suppose that

∈
∇

(0, 1) regardless of x, we have that
i (xν )
f ν

{∇
→N ¯v. We would like to show ¯v
∈
gik)(x)

fi)(x) =

con ∂(

con

−

−

(
−

∇

con ∂fi(x) =

−

exp
si
j=1 exp
(cid:0)
N

θν(fi(x)

gik(x))

−
θν(fi(x)

gij(x))
(cid:1)

−
(cid:0)
is bounded. For some N

(cid:1)

.

i (xν ), ν
f ν
P
}
con ∂fi(¯x). We observe that

∈

#

∞,

∈ N

Ai(x)

= con

k

∈

(cid:9)

∇

(cid:8)

gik(x)

k

Ai(x)

,

∈

(cid:12)
(cid:12)

(cid:9)

(cid:8)

(cid:12)
(cid:12)

16

where Ai(x) = argmink=1,...,si gik(x). If k

Ai(¯x), then the continuity of fi and gik implies that

6∈
θν(fi(xν)

exp

(cid:0)

gik(xν))

−

→N 0.

The denominator in the deﬁning expression for µν
ik(xν )
for j

Ai(xν). Thus, µν
ik(xν)

For any k, µν

∈

→N 0.

denote by N , there are µ∞
all ν, we must also have

(0, 1). Consequently, after passing to another subsequence which we also
ik(xν) = 1 for
ik(xν )

[0, 1], k = 1, . . . , si, such that µν

ik . Since

si
k=1 µν

ik = 1, with µ∞

ik = 0 if k

Ai(¯x) as already seen. We conclude that

→N µ∞

P

ik(xν ) is greater than one because fi(xν )

(cid:1)

gij(xν) = 0

−

i (xν ) =
f ν

∇

ik(xν )
µν

gik(xν)

→N ¯v =

k∈Ai(¯x)

µ∞
ik ∇

gik(¯x)

∈

con ∂fi(¯x)

∇

k=1

and (2.3) holds. An instance of h and hν satisfying condition (c) of Theorem 2.4 follows next.

∈
ik ∈
si
k=1 µ∞
si

P

X

6∈

X

3.6 Example (penalty methods). With h(z) = z1 + ι(−∞,0]m−1(z2, . . . , zm), we consider the problem

minimize
x∈X

f1(x) subject to f2(x)

0, . . . , fm(x)

0,

≤

≤

which is of the form (1.1). An approximation stemming from penalty methods utilizes

where θν

[0,

∈

∞

). If X ν = X, F ν = F , and θν

X
→ ∞

(cid:0)

, then the resulting approximations are consistent.

hν (z) = z1 + θν

m

i=2

max

0, zi
{

2,

}
(cid:1)

Detail. We turn to condition (c) of Theorem 2.4. Certainly, hν(z)
requirements hold as well. To conﬁrm hν
zν
z. We note that liminf hν (zν )
these zi are positive, then zν
hν and h. For any z, limsup hν(z)

¯z and the other
e h, we leverage the characterization (1.2) and (1.3). Let
→
0 for i = 2, . . . , m. If any of
= h(z) and (1.2) holds for

i > 0 for suﬃciently large ν. Thus, hν(zν )

h(z) and (1.3) holds as well. Consequently, hν

h(z) when z = (z1, . . . , zm) has zi

hν (¯z) when z

≤
→ ∞

→

≤

≤

≥

Condition (c) of Theorem 2.4 also permits outer approximations of X and lower bounding approx-

e h.
→

≤

imations of F (see Example 3.5) while retaining weak consistency.

3.7 Example (interior-point methods). For the actual problem in Example 3.6, we consider the ap-
proximation

hν (z) =

z1 −
(
∞

1
θν

m
i=2 ln(

−

zi)

P

if z2 < 0, . . . , zm < 0
otherwise,

where θν
If θν
X, with fi(x)
fi(xν) < 0 for all i = 2, . . . , m, then the approximations are consistent.

). This logarithmic penalty approach is the basis for (primal) interior-point methods.
x such that

0 for all i = 2, . . . , m, there exists xν

(0,
and for all x

∈
→ ∞

→

∞

X

≤

∈

∈

17

Detail. We leverage condition (d) of Theorem 2.4. Trivially, h is continuous relative to its domain.
z. If zi > 0 for some i = 2, . . . , m, then zν
e h via (1.2) and (1.3). Let zν
We establish hν
0 for
→
suﬃciently large ν and liminf hν (zν)
0 for i = 2, . . . , m, then
. If zi
≤
≥
h(z) = z1 and the liminf-condition holds again. The condition limsup hν(zν )
h(z) holds because for
≤
any zi = 0, one can select zν

h(z) because both sides are

√θν). Then, zν

i ))/θν = √θν/θν
zν

zi and

i ≥

exp(

i =

(ln(

→

∞

0.

−

−

i →

−

−

→

3.8 Example (expectation functions). Expectation functions arise in stochastic optimization and
machine learning and then the component functions f1, . . . , fm may take the form

fi(x) = E

gi(ξ, x)

,

R is deﬁned in terms of a probability space (Ξ,
where gi : Ξ
identically distributed sample ξ1, . . . , ξν according to P deﬁnes a sample average approximation

, P). An independent and

Rn

→

×

B

(cid:2)

(cid:3)

f ν
i (x) =

1
ν

ν

j=1

gi(ξj, x).

X

If both gi and
deﬁnitions), then, with probability one, f ν

gi are random lower semicontinuous and locally inf-integrable (see [56, Sec. 8.G] for
fi(x) whenever xν

x by [56, Thm. 8.56].

−

i (xν )

→
such that P(B) = 1 and gi(ξ,

→

Detail. If there is a set B
B, then one can
attempt to repeat the above arguments with fi replaced by the partial derivatives of fi and conclude
that
x. This would allow us to satisfy the requirement (2.3). For
further details and reﬁnements about approximations of expectation functions and their subgradients,
we refer to [19].

) is smooth for all ξ
·

fi(x) whenever xν

i (xν )
f ν

→ ∇

∈ B

→

∇

∈

3.9 Example (oracle functions). Suppose that h is real-valued, but not available in an explicit form.
If for each z we can compute h(z) and a subgradient v

∂h(z), then the approximation

∈

hν(z) = max
k=1,...,ν

h(zk) +

vk, z
h

zk

, with zk
i

−

∈

Rm, vk

∈

∂h(zk),

N

e h if
→

remains available. Now, hν

Detail. By [50, Thm. 7.17], hν
subset of Rm. Let ¯z
of its aﬃne supports; see [50, Thm. 8.13]. Moreover, there is ¯ν such that ¯z
hν (¯z)

zk, k
{
e h whenever the functions converge pointwise on a countable dense
→
N
h(¯z) because h is the pointwise supremum
. Thus,
}
Rm.

¯ν. By [50, Thm. 7.17], this also means that hν(z)

. Obviously, hν (¯z)
}

is a countable dense subset of Rm.

h(¯z) for all ν

h(z) for all z

z1, . . . , z ¯ν

zk, k

∈ {

∈ {

≤

∈

∈

}

≥

≥

→

∈

3.10 Example (homotopy method). For proper, lsc, and convex ˆh : Rm−1
Rm−1, consider the problem

→

R and lLc ˆF : Rn

→

minimize
x∈X

ˆh

ˆF (x)

,

(cid:0)

(cid:1)

18

which is of the form (1.1) with h(z) = ˆh(z1, . . . , zm−1) for z = (z1, . . . , zm) and F (x) = ( ˆF (x), fm(x))
for some lLc fm : Rn

R. A homotopy method for the problem solves the approximations

→

minimize
x∈X

(1

−

λν)ˆh

ˆF (x)

+ λνfm(x)

as λν
actual one while beneﬁtting from warm starts. The approximations are of the form (2.1) with

0. If fm is chosen wisely, then the approximating problems might be simpler to solve than the

→

(cid:0)

(cid:1)

If λν

→

0, then the approximations are consistent.

hν (z) = (1

−

λν)ˆh(z1, . . . , zm−1) + λνzm.

Detail. To establish hν

e h via (1.2) and (1.3), we note that for zν
→
m−1) + λνzν
1 , . . . , zν

z, one has

→

−

liminf(1

λν )ˆh(zν

ˆh(z1, . . . , zm−1) = h(z).
m−1) + liminf λν zν
ˆh(z1, . . . , zm−1). We therefore have both epi-
Moreover, for z
convergence and pointwise convergence (on dom h) and condition (b) of Theorem 2.4, with reﬁnements,
establishes consistency.

λν)ˆh(z1, . . . , zm−1)+λνzm

liminf ˆh(zν

1 , . . . , zν

dom h, (1

m ≥

m ≥

→

−

∈

3.11 Example (monitoring functions). In extended nonlinear programming [49], one utilizes

h(z) = supy∈Y

z, y
h

y, By

1
2 h

and

hν(z) = supy∈Y ν

i −

Rm are nonempty polyhedral sets and B, Bν are symmetric positive semideﬁnite m

i
where Y, Y ν
(cid:9)
m-
⊂
e h. If in addition B is positive deﬁnite or Y is bounded,
matrices. If Bν
s Y , then hν
→
→
Rm. Thus, main steps toward (weak) consistency via
then h is real-valued and hν (z)
h(z) for z
Theorem 2.4 are immediately accomplished.

B and Y ν

i
(cid:9)

i −

→

→

×

∈

(cid:8)

y, Bνy

,

1
2 h

z, y
h
(cid:8)

e h is established via the corresponding conjugate functions hν∗ and
Detail. The epi-convergence hν
→
e h∗. Since h∗(y) = 1
h∗. By Wijsman’s theorem [50, Thm. 11.34], it suﬃces to show that hν∗
+
2 h
→
ιY (y), hν∗(y) = 1
e h∗.
e ιY , we conclude that hν∗
+ ιY ν (y), and ιY ν
2 h
→
→
It follows by [50, Thm. 7.17] that the pointwise convergence hν (z)
→
valued. This is the case when B is positive deﬁnite or when Y is bounded.

h(z) holds when h is real-

y, Bνy

y, By

i

i

3.12 Example (diﬀerence-of-convex functions). For a proper, lsc, and convex f : Rn
g : Rn

R, consider the problem

R and convex

→

→

minimize
x∈X

f (x)

−

g(x),

which involves an objective function of the diﬀerence-of-convex kind. As the only approximation,
suppose that g is replaced by smooth functions gν : Rn

R that also satisfy the property:

xν

X

x =

gν (xν )

g(x) and

gν(xν ), ν

is bounded with all cluster points in ∂g(x),

∈

→

⇒

∈
→
which holds, for instance, when gν is convex and gν
reﬁnement of Theorem 2.4. This produces weakly consistent approximations.

∇

(cid:8)

e g; see the arguments leading to the third
(cid:9)
→

→
N

19

−

Rn and z2 ∈

R, we set h(z) = h1(z1) + h2(z2), where h1(z1) = f (z1)
Detail. For z = (z1, z2), with z1 ∈
z2. Moreover, let F (x) = (x, g(x)) and F ν(x) = (x, gν (x)) so that m = n + 1, m1 = n,
and h2(z2) =
m2 = 1, and r = 2 in the notation of condition (e) of Theorem 2.4. Since g is real-valued and convex, it
is lLc and then F is also lLc. With hν = h, we trivially obtain hν
e h. The requirement (2.3) translates
→
into the assumed property. We then invoke condition (e) of Theorem 2.4 to conclude weak consistency.
R being smooth, could be approximated parallel
For instance g(x) = maxk=1,...,s gk(x), with gk : Rn
to Example 3.5. In this case, 0

S(x, y, z) reduces to 0

∂g(x) + NX (x).

∂f (x)

→

∈

∈

−

4 Enhanced Proximal Composite Algorithm

As an example of an implementable version of the consistent approximation algorithm, we consider the
setting where X ν is convex, hν is real-valued, and F ν is twice continuously diﬀerentiable. Then, the
approximating problems (2.1) are solvable by proximal composite methods, which can be traced back
to [26, 47, 8]; see also [48, 57, 9] for trust-region versions and [22] for details about rates of convergence
under the assumption that hν and
F ν are Lipschitz continuous. Let prjX ν (x) be the projection of x
on X ν .

∇

Enhanced Proximal Composite Algorithm (EPCA).

Data.

Rn, τ

x0

∈

(1,

), σ

∞

∈

∈

(0, 1), ¯λ

(0,

∈

∞

), λ0

∈

(0, ¯λ],

δν > 0, ν
{

∈

N

} →

0.

Step 0. Set ν = 1.

Step 1. Set k = 0 and ¯x0 = prjX ν (xν−1).

Step 2. Compute x⋆

argminx∈X ν hν
∈
If x⋆ = ¯xk, then go to Step 4.

(cid:0)

F ν(¯xk) +

F ν(¯xk)(x

¯xk)

−

+ 1

x
2λk k

−

¯xk

2
2.
k

∇

Step 3. If hν

F ν(¯xk)

hν

−

F ν (x⋆)

σ

hν

F ν (¯xk)

then set λk+1 = min
(cid:0)
(cid:1)

(cid:0)

(cid:16)
and go to Step 5.

(cid:1)

(cid:0)

(cid:0)

≥
τ λk, ¯λ
(cid:1)
{

}

Else, replace λk by λk/τ and go to Step 2.

(cid:1)

hν

F ν(¯xk) +

−

F ν(¯xk)(x⋆

∇

−

¯xk)

,

(cid:1)(cid:17)

Step 4. Set xν = x⋆, zν = F ν(xν ), and yν such that yν

∂hν (zν ) and

F ν(xν)⊤yν

NX ν (xν).

∈

−∇

∈

Replace ν by ν + 1 and go to Step 1.

Step 5. Set ¯xk+1 = x⋆, ¯zk+1 = F ν (¯xk) +

∇

F ν(¯xk)(¯xk+1

¯xk), and ¯yk+1 such that

¯yk+1

∈

∂hν (¯zk+1)

and

If max

Set ¯uk+1 = F ν (¯xk+1)
¯uk+1
k
(cid:8)

and go to Step 1.

−
¯wk+1
k

k2,

k2

≤

(cid:9)

−
F ν(¯xk)⊤ ¯yk+1

1

λk (¯xk+1

¯xk)

NX ν (¯xk+1).

¯zk+1 and ¯wk+1 =

− ∇

−
F ν(¯xk)
δν , then set xν = ¯xk+1, yν = ¯yk+1, zν = ¯zk+1, replace ν by ν + 1,

−
F ν(¯xk+1)

∈
⊤ ¯yk+1

λk (¯xk+1

¯xk).

− ∇

∇

−

−

1

(cid:1)

(cid:0)

Else, replace k by k + 1, and go to Step 2.

20

4.1 Theorem (enhanced proximal composite algorithm). Suppose that X ν
convex, hν
1, . . . , m. If
then

e h with hν real-valued, and (2.3) holds with f ν
→
(xν , yν , zν ), ν
{

is generated by EPCA and (xν , yν, zν )

s X with these sets being
→
i twice continuously diﬀerentiable for i =
∞,

→N (ˆx, ˆy, ˆz) for some N

∈ N

N

∈

}

#

X,

ˆx

∈

h

F (ˆx)

≤

liminf ν∈N hν

F ν(xν )

,

S(ˆx, ˆy, ˆz).

0

∈

Proof. The two ﬁrst claims follow by Corollary 2.5. The construction in Steps 4 and 5 ensures that
(xν , yν, zν )
;
k2}
see the discussion below. Thus, Corollary 2.5 also conﬁrms that 0

(Sν )−1(B(0, δν )) for all ν when the norm on R2m+n is (u, v, w)

7→
S(ˆx, ˆy, ˆz).

k2,
u

k2,

w
k

max

v
k

{k

∈

(cid:0)

(cid:1)

(cid:0)

(cid:1)

∈

EPCA solves the sequence of approximating problems using a composite proximal method of the
kind proposed in [35] for each problem. The outer loop indexed by ν represents reﬁnement of the
approximating problems. The inner loop indexed by k corresponds to the iterative solution of each
approximating problem by means of solving the convex subproblems in Step 2 obtained by linearization
of F ν. (For inexact solution of such subproblems, we refer to [22].) The proximal parameter λk is
controlled adaptively using the test in Step 3.

A concern is whether EPCA terminates after a ﬁnite k in Step 4 or 5 and thus always produces the

next (xν, yν , zν ). This turns out to be the case as long as

≤
where ¯x0 = prjX ν (xν−1). We see this as follows:

(cid:8)

◦

ιX ν + hν

F ν

hν

F ν(¯x0)

is bounded,

(4.1)

(cid:0)

(cid:1)(cid:9)

An optimality condition for the subproblem in Step 2 states that x⋆ satisﬁes

F ν(¯xk)⊤y

1

λk (x⋆

¯xk)

−

∈

−

− ∇

NX ν (x⋆) for some y

∂hν

F ν(¯xk) +

F ν(¯xk)(x⋆

∇

−

¯xk)

.

(4.2)

∂hν (F ν (¯xk)) and

Thus, when x⋆ = ¯xk, one has y
NX ν (x⋆). This means that there
exists yν in Step 4. The best way to compute such yν depends on the nature of hν and X ν, but it can
be achieved by convex optimization since it at most involves ﬁnding points in two convex sets. Then,
(xν , yν, zν )
(Sν)−1(0). In Step 5, there exists likewise ¯yk+1 by (4.2), again computable by convex
optimization. The construction in Step 5 ensures that (¯uk+1, 0, ¯wk+1)

Sν(¯xk+1, ¯yk+1, ¯zk+1).

−∇

∈

∈

∈

(cid:1)

∈
F ν(¯xk)⊤y

(cid:0)

}

∈

N

−

→ ∞

¯xk)/λk

¯xk, k
{

and (¯xk+1

For the sake of contradiction, suppose that the algorithm iterates indeﬁnitely without generating
the next (xν , yν, zν ). Let
be the resulting sequence, which has a cluster point in view
of (4.1), say ¯x. We deduce from [35], especially Theorem 5.4 and is proof, that ¯xk+1
0
→
(We
0 as k
as k
note that EPCA eventually exits Steps 2-3 and moves to Step 4 or 5, and that
is
bounded along the subsequence corresponding to the cluster point ¯x.) Then, for k along the subsequence
F ν (¯x), which means that the associated sets of subgradients ∂hν (¯zk+1) are
corresponding to ¯x, ¯zk+1
contained in a compact set and then the same holds for ¯yk+1. This fact as well as the recognition that
0 and ¯wk+1
F ν(¯xk+1)
F ν(¯xk+1)
→
¯wk⋆+1
¯uk⋆+1
along the subsequence. Consequently, there’s k⋆ such that max
k2,
k
shown that EPCA augments ν after some ﬁnite k in either Step 4 or 5.

¯xk
along the subsequence corresponding to ¯x.

0 as k
→ ∞
δν . We have

0 imply that ¯uk+1

1/λk, k
{

→
k2} ≤

F ν(¯x) and

F ν(¯xk)

→ ∞

− ∇

→

→

→

→

{k

∇

−

N

∈

}

∈

21

5

Inverse Problems in Machine Learning

An inverse problem in machine learning is that of determining an input to a collection of neural networks
such that their outputs best match a given quantity [28, 30]. Speciﬁcally, we are given s neural networks
Rnq , i = 1, . . . , s. Each network associates an input vector
represented by the mappings Fi : Rn0
→
Rnq . The goal is to determine an input vector x such that the
Rn0 with an output vector Fi(x)
x
output vectors F1(x), . . . , Fs(x) are optimized in the sense of a convex function ˆh : Rsnq

R, i.e.,

∈

∈

→

minimize
x∈ ˆX

ˆh

F1(x), . . . , Fs(x)

,

(5.1)

Rn0 is a nonempty closed set that could impose restrictions on the choice of input vector.

(cid:0)

(cid:1)

where ˆX
For some target output vector t

⊂

Rnq and nonnegative weights p1, . . . , ps, we may simply have

∈

ˆh

F1(x), . . . , Fs(x)

=

s

i=1

pi

t

−

Fi(x)

2
2.

X
Suppose that the neural networks are of the feed-forward kind producing their output from passing
through q aﬃne mappings composed with an activation function. For each layer k = 1, . . . , q, there is
a given nk

nk−1-matrix Ai,k, a given vector bi,k

Rnk, and Fi,k : Rnk−1

Rnk with

(cid:13)
(cid:13)

(cid:13)
(cid:13)

(cid:0)

(cid:1)

∈

→

×

Fi,k(x) = Gi,k(Ai,kx + bi,k)

for x

Rnk−1,

∈

where Gi,k : Rnk
gi,j,k : R
is a common such activation function; it is epi-regular and lLc. Then, Fi = Fi,q

Rnk has Gi,k(y) = (gi,1,k(y1), . . . , gi,nk,k(ynk )) for y = (y1, . . . , ynk )

R are given epi-regular lLc functions. For example, the ReLU function gi,j,k(γ) = max

Rnk and
0, γ
{

→

→

Fi,1.

∈

}

It is convenient to express (5.1) using additional variables as follows: We think of x1,i,k

the output of the kth layer for neural network i. Let r =
with x0 ∈
F (x) =

Rn0 and x1 = (x1,1,1, . . . , x1,s,q)

x1,1,q, . . . , x1,s,q, H1(x), . . . , Hs(x)

Rsr. Set

Rsnq+sr

∈

∈

where, for z = (z0, z1, . . . , zs), with z0 ∈

(cid:0)

(cid:1)
Rsnq and zi

Rr, i = 1, . . . , s, and

q

k=1 nk, X = ˆX

×

◦ · · · ◦

Rnk as
Rsr, and x = (x0, x1),

∈

P

and

h(z) = ˆh(z0) + ι{0}sr (z1, . . . , zs),

Gi,1
Gi,2

∈
Ai,1 x0 + bi,1
Ai,2 x1,i,1 + bi,2
(cid:1)
(cid:0)
...
(cid:1)
(cid:0)
Ai,q x1,i,q−1 + bi,q

x1,i,1
x1,i,2

−

−

x1,i,q

−

(cid:1)



.






Hi(x) = 





Gi,q

(cid:0)

Thus, the inverse problem (5.1) is equivalently expressed in the form (1.1) with n = n0 + sr and
m = snq + sr; h is proper, lsc, and convex and F is lLc. For theoretical and computational reasons,
R, and epi-regular lLc
several approximations may arise. Suppose that Aν
R approximate Ai,k, bi,k, ˆh, and gi,j,k, respectively. The approximating quantities deﬁne
i,j,k : R
gν
→
i,k in the manner laid out for h, F , Hi, and Gi,k. For simplicity, ˆX is not
hν and F ν via H ν
approximated so that X ν = X. It turns out that weak consistency follows naturally.

i,k, convex ˆhν : Rsnq

i and Gν

i,k, bν

→

22

5.1 Proposition (weak consistency in inverse machine learning).
suppose that for each (i, j, k), the following property holds:

In the notation of this section,

γν
αν

∈

∈

R

γ
→
i,j,k(γν ))
∂gν

i,j,k(γν )
gν
=
αν , ν
⇒ (
{

∈

→
N
}

gi,j,k(γ)
is bounded with all its cluster points in ∂gi,j,k(γ).

(5.2)

Ai,k, bν
If Aν
approximations of (ϕ, S).

i,k →

i,k →

bi,k, and ˆhν

e ˆh, then the resulting pairs
→

(ϕν , Sν), ν
{

N

}

∈

are weakly consistent

Proof. We establish ϕν
H ν
i (xν )
→
such that ¯x0 ∈
1 = (xν
xν

e ϕ using (1.2) and (1.3). The liminf-condition holds because hν
→

e h and
→
x. For the limsup-condition, it suﬃces to consider ¯x = (¯x0, ¯x1)
0 = ¯x0 and

ˆX and Hi(¯x) = 0 for i = 1, . . . , s. Construct xν = (xν
1,s,q), where for each i = 1, . . . , s,

Hi(x) whenever xν

1,1,1, . . . , xν

1) with xν

0, xν

→

1,i,1 = Gν
xν
i,1

Aν

i,1 ¯x0 + bν
i,1

, xν

1,i,2 = Gν
i,2

Aν

i,2 xν

1,i,1 + bν
i,2

,

. . . , xν

1,i,q = Gν
i,q

Aν

i,q xν

1,i,q−1 + bν
i,q

.

Thus, we have H ν
ˆh(¯x1,1,q, . . . , ¯x1,s,q) by [50, Thm. 7.17]. This implies that ϕν(xν )

i (xν ) = 0 and xν

→

¯x. Since ˆh is real-valued and convex, ˆhν (xν

ϕ(¯x).

(cid:0)

(cid:1)

(cid:0)

(cid:1)

(cid:0)

1,1,q, . . . , xν

(cid:1)
1,s,q)

→

there are N

#

Next, we turn to the optimality conditions. Suppose that (¯x, ¯y, ¯z, ¯u, ¯v, ¯w)

∞ and (xν, yν , zν , uν, vν , wν )

∈
→N (¯x, ¯y, ¯z, ¯u, ¯v, ¯w) with (uν , vν , wν )
Let Ai,j,k be the jth row of Ai,k and bi,j,k be the jth component of bi,k, with parallel deﬁnitions of
Rnk is denoted by x1,i,j,k. Moreover, the aﬃne function

i,j,k. The jth component of x1,i,k

∈ N

LimOut(gph Sν). Then,
Sν (xν, yν, zν ).

∈

→

∈

Aν
i,j,k and bν
ai,j,k : Rn0+sr

R has

→

ai,j,k(x) =

Ai,j,k, x1,i,k−1i
h

+ bi,j,k

with the convention that x1,i,0 = x0. The function fi,j,k : Rn0+sr

R has

→

fi,j,k(x) = gi,j,k

ai,j,k(x)

x1,i,j,k.

−

The approximations aν
Since uν = F ν(xν )

i,j,k and f ν

i,j,k are deﬁned similarly.

(cid:0)

(cid:1)

−

→

γ. The fact that vν + yν
0 , vν

zν , we conclude that ¯u = F (¯x)
∂hν (zν ) implies that vν

¯z; recall that gν
gi,j,k(γ) when
→
∂ˆhν (zν
Rr,
i = 0, vν
i + yν
γν
Rr for i = 1, . . . , s; the vectors ¯v,
i = 1, . . . , s, where vν = (vν
0 ∈
¯y, ¯z, yν, and zν are partitioned similarly. By Attouch’s theorem [50, Thm. 12.35], we conclude that
¯v0 + ¯y0 ∈

−
0 + yν
0 ∈
Rsnq and vν
i ∈

∂ˆh(¯z0). Thus, ¯v + ¯y

∈
1 , . . . , vν

s ), with vν

0 ) and zν

i,j,k(γν )

∂h(¯z).

i ∈

∈

It remains to conﬁrm the last portion of (¯u, ¯v, ¯w)

S(¯x, ¯y, ¯z) involving subgradients of the compo-

nent functions of F . Since gi,j,k is lLc and epi-regular, the component function fi,j,k has

where ci,j,k =
zero elsewhere. Likewise,

∇

ai,j,k(x) and ei,j,k

∈

∂fi,j,k(x) = c⊤

i,j,k∂gi,j,k

ai,j,k(x)

ei,j,k,

−

Rn0+sr is a vector with a single 1 placed appropriately and with

(cid:1)

∈

(cid:0)

∂f ν

i,j,k(x) = (cν

i,j,k)⊤∂gν

i,j,k

aν
i,j,k(x)

ei,j,k,

−

(cid:0)

(cid:1)

23

i,j,k =

aν
i,j,k(x). The assumption (5.2) implies that any sequence

where cν
N
semicontinuous, we deduce that the last requirement holds and, thus, (¯u, ¯v, ¯w)

∈
is bounded and thus has a cluster point, with any such point in ∂fi,j,k(¯x). Since N ˆX is outer

dν
i,j,k ∈
{

i,j,k(xν ), ν

∂f ν

∇

}

S(¯x, ¯y, ¯z).

∈

A typical activation function is the ReLU with gi,j,k(γ) = max

0, γ
{

. A smooth approximation
}

could be gν

i,j,k(γ) = 1

θν ln(1 + exp(θνγ)). The assumption (5.2) holds in this case; see Example 3.1.

6 Rates and Error Estimates

Consistency furnishes guarantees about the limiting behavior of approximations, but it also can be
beneﬁcial to quantify the rate of convergence. In this section, we reﬁne results from [53] and estimate the
discrepancy between near-solutions of the optimality condition 0
S(x, y, z).
Chapter 8 of [16] addresses similar issues using diﬀerent techniques, especially for problems with aﬃne
structure. For error estimates of minimizers, minima, and level-sets, we refer to [52, 53].
is denoted by

The point-to-set distance between ¯x

Sν (x, y, z) and those of 0

Rn under norm

Rn and C

∈

∈

∈

⊂

k · k

The excess of C

Rn over D

⊂

⊂

dist(¯x, C) = infx∈C

¯x

x
k
Rn is deﬁned as

−

k

when C

=

∅

and dist(¯x,

) =
∅

.

∞

supx∈C dist(x, D)

exs(C; D) = 


∞
0

=
if C
if C
=
otherwise.

=
, D
∅
, D =
∅

∅
∅

We concentrate on a truncated version given by



exsρ(C; D) = exs

C

B(0, ρ); D

∩

for ρ

[0,

).

∞

∈

All these concepts rely on the choice of norm. The Euclidean norm remains the default, but in the

(cid:0)

(cid:1)

context of S, Sν : Rn+2m

→→

R2m+n we adopt the norms given by

(x, y, z)
k

kin = max

x
k

k2,

y
k

k2,

z
k

k2

and

(u, v, w)
k

(cid:8)
for the argument and value spaces, respectively, where x
Rn. The graphs of S, Sν are subsets of Rn+2m
w

(cid:9)

∈

∈

×
kin,
Thus, S−1(B(0, ε)) is the set of near-solutions of 0
by

(x, y, z)
k

max

(cid:8)

∈

k · kout, i.e., (¯x, ¯y, ¯z)

∈

S−1(B(0, ε)) if and only if (¯u, ¯v, ¯w)

kout = max
(cid:8)
Rm, z
Rn, y

v
k2,
u
k
k
Rm, u

k2,

w
k2
k
(cid:9)
Rm, v

(6.1)

Rm, and

R2m+n, for which we adopt the norm given by

∈

∈

∈

∈

(u, v, w)
k

kout

.

(6.2)

S(x, y, z) with the tolerance now being speciﬁed

(cid:9)

S(¯x, ¯y, ¯z) and

(¯u, ¯v, ¯w)
k

kout ≤

ε.

∈

6.1 Proposition (solution error in optimality conditions). Suppose that 0
δν + exsρ(gph Sν; gph S). Then, under the norms (6.1) and (6.2), one has

δν

≤

≤

ρ <

∞

and ε

≥

exsρ

(Sν )−1

B(0, δν )

; S−1

B(0, ε)

(cid:16)

(cid:0)

(cid:1)

(cid:1) (cid:17)

(cid:0)

24

exsρ

gph Sν; gph S

.

≤

(cid:0)

(cid:1)

6
6
6
6
Proof. A slight modiﬁcation of the proof of Theorem 5.1 in [53] yields this fact.

The proposition ensures that if (ˆx, ˆy, ˆz)

B(0, ρ) nearly satisﬁes the optimality condition 0

∈

∈

∞

[0,

), i.e., dist(0, Sν (ˆx, ˆy, ˆz))

∈
δν , then (ˆx, ˆy, ˆz) is no further away
Sν(x, y, z) with tolerance δν
than exsρ(gph Sν; gph S) from a point that nearly satisﬁes the optimality condition 0
S(x, y, z) with
tolerance ε. Thus, the rate of convergence of near-solutions of the approximating problems is governed
by the rate of decay of exsρ(gph Sν; gph S) as ν

→ ∞
In the context of the consistent approximation algorithm, Proposition 6.1 asserts that the solution
tolerance ε (for the actual problem) is bounded by the sum of δν (the tolerance adopted when solving
the approximating problem) and the error in the approximation as expressed by exsρ(gph Sν ; gph S).
Thus, it would be “optimal” to make δν in the consistent approximation algorithm vanish at the same
rate as exsρ(gph Sν ; gph S) tends to zero. Concrete illustrations follow in the examples below.

≤

∈

.

6.2 Theorem (estimate of excess). Suppose that ρ

∈

[0,

) and X = X ν. Let

∞
B(0, ρ)

ην
0 = sup

F ν (x)

ην = sup

n(cid:13)
exs
(cid:13)

F (x)

x

X

2

−
∈
(cid:13)
∂f ν
i (x); con ∂fi(x)
(cid:13)

(cid:12)
(cid:12)
(cid:12)

∩
x

∩
n
R2m+n is (6.2) and the norm on Rm

∈

(cid:0)

(cid:1) (cid:12)
(cid:12)
(cid:12)

If the norm on Rn+2m

×

exsρ(gph Sν; gph S)

Proof. Suppose that (¯x, ¯y, ¯z, ¯u, ¯v, ¯w)

≤

∈

¯u = F ν(¯x)

¯z,

−

¯v + ¯y

∈

∩
∂hν (¯z),

max

√mρην, ην

Since (¯x, ¯y, ¯z, ¯u, ¯v, ¯w)

¯v + ¯y
k
which follows largely from the deﬁnition of subgradients; cf.
that there are z, v

Rm such that (z, v + ¯y)

gph ∂h and

k2,
¯z

{k

∈

∈
B(0, ρ), one has max

∈

∈

max

k2,
z
¯z
k
n
con ∂f ν
i (¯x) such that ¯w

(cid:13)
(cid:13)

−

(v + ¯y)

o

(cid:13)
m
i=1 ¯yi¯ai
(cid:13)

∈

There are ¯ai
exist λk
assumption, there exists bk
¯bi =
i bk

0 and ak

n
k=0 λk

i ≥

i ∈

∂f ν

−
i (¯x), k = 0, 1, . . . , n, such that

∈

P

bk
con ∂fi(¯x) such that
i k2 ≤
P
i , which then also is in con ∂fi(¯x). We construct
m

ak
i −
k

i ∈

P

X

o
B(0, ρ), i = 1, . . . , m

.

Rm is max

o
v
k2}
k
0 + exs2ρ(gph ∂hν; gph ∂h)
.

z
{k

k2,

×

, then one has

(cid:8)
gph Sν

B(0, ρ), where the ball is speciﬁed by (6.2). Then,

(cid:9)

¯w

∈

m

i=1

¯yi con ∂f ν

i (¯x) + NX(¯x).

X

2ρ. Moreover, gph ∂h is nonempty,
k2} ≤
[50, Corollary 8.10]. These facts ensure

(¯v + ¯y)

2

−

exs2ρ(gph ∂hν ; gph ∂h).

≤

NX(¯x). By Caratheodory’s theorem, there
n
k=0 λk
i . By
ην and this holds for each i and k. Let

i = 1 and ¯ai =

n
k=0 λk

i ak

P

We construct a point (¯x, ¯y, z, u, v, w)

gph S that is near (¯x, ¯y, ¯z, ¯u, ¯v, ¯w) in the norm (6.2).

w = ¯w +

¯yi(¯bi

¯ai)

−

i=1

and

u = F (¯x)

z.

−

It now follows that (¯x, ¯y, z, u, v, w)
and (¯x, ¯y, ¯z, ¯u, ¯v, ¯w). We already have max

X
∈

gph S and it remains to compute the distance between this point

z
{k
2 +

−

v
k

k2,
¯z
¯z
k2 ≤

−

−

z
k

exs2ρ(gph ∂hν ; gph ∂h). Moreover,

¯v
k2} ≤
0 + exs2ρ(gph ∂hν ; gph ∂h).
ην

u
k

−

¯u
k2 ≤

F ν(¯x)

F (¯x)

−

(cid:13)
(cid:13)

(cid:13)
(cid:13)

25

Finally, one has

w
k

−

¯w

k2 ≤

m
i=1 |

¯yi

¯bi

|k

¯ai

k2 ≤

−

√mρην .

The theorem allows us to bound the solution error associated with a particular approximation in
P
terms of the error in the individual components hν and F ν.
(We refer to [53] for error estimates
involving X ν
= X in the simpliﬁed setting with smooth F .) Thus, the focus turns to estimating the
component errors. For that purpose, the following fact, which is a direct application of Theorem 5.2 in
[1], is useful. It leverages the truncated Hausdorﬀ distance between the sets C and D:

dˆlρ(C, D) = max

exsρ(C; D); exsρ(D; C)

.

(cid:8)
6.3 Proposition (approximation of subgradients). Suppose that the norm on Rm+1 is max
the norm on Rm
[0,
α, ¯ρ

(cid:9)
,
z
|}
{k
dist(0, epi hν), dist(0, epi h)
. Then, there are
}
{

Rm is max
), dependent on ρ, such that

, and ρ > max

z
{k

k2,

k2,

k2}

v
k

α
|

×

∈

∞

exsρ

gph ∂hν ; gph ∂h

dˆlρ

gph ∂hν , gph ∂h

α

dˆl ¯ρ(epi hν , epi h)

≤

≤

α

supz∈B(0,¯ρ)

h(z)

hν(z)

.

−

≤

q
(cid:12)
The truncated Hausdorﬀ distance between epigraphs can be computed using results from [53], with
(cid:12)

q

(cid:12)
(cid:12)

(cid:0)

(cid:1)

(cid:0)

(cid:1)

the sup-expression given above being among the crudest possibilities.

6.4 Example (goal optimization; cont.). In Example 3.1, smoothing of hν causes a solution error

for a constant β when 0
where ¯α = (ln 2)(

≤
m
i=1 αi).

δν

(cid:16)
≤

ρ <

(cid:0)
, ε
∞

≥

exsρ

(Sν )−1

B(0, δν )

; S−1

B(0, ε)

β/√θν

≤
δν + β/√θν, and ρ > 1

(cid:1) (cid:17)

(cid:0)

(cid:1)

2 max

m
i=1 min

0, τi
{

2, ¯α/θν
}

,
}

{
pP

Detail. Since supz∈Rm

P

hν (z)
|

−

h(z)

| ≤

¯α/θν by Example 3.1, we obtain via Proposition 6.3 that

exs2ρ(gph ∂hν; gph ∂h)

α

¯α/θν

≤

for some α
and Proposition 6.1.

[0,

∞

∈

) when ρ is suﬃciently large as indicated. The claim then follows by Theorem 6.2

p

6.5 Example (distributionally robust optimization; cont.). For Example 3.3, there is a constant β
[0,

) such that

∈

∞

exsρ

(Sν )−1

B(0, δν )

; S−1

B(0, ε)

β√αν

as long as 0

δν

≤

≤

ρ <

∞

(cid:16)
and ε

≥

δν + β√αν , where αν = max
(cid:1)

(cid:0)

(cid:0)

Detail. Since dist(0, epi hν ) = dist(0, epi h) = 0, it follows by Proposition 6.3 that

≤
(cid:1) (cid:17)
exs(A; Aν ), exs(Aν ; A)
.
}
{

dˆl2ρ(gph ∂hν , gph ∂h)

α

≤
B(0, ¯ρ) and let pν

∈

[0,
A such that

for some α, ¯ρ
exists ¯p
i ≤ k
repeat this argument with the roles of h and hν reversed and conclude that
combination with (6.3), Theorem 6.2, and Proposition 6.1, the claim follows.

(cid:12)
ˆAν(z); see Example 3.3 for notation. Then, there
(cid:12)
¯ραν . We
pν
−
¯ραν . In
h(z)
|

z
¯p
k2k
hν (z)
−

). Fix z
pν
k

q
∈
αν . Thus, hν (z)

k2 ≤
| ≤

∈
¯p
k2 ≤

(cid:12)
(cid:12)
pν

h(z)

≤ h

¯p, z

∞

−

−

−

∈

supz∈B(0,¯ρ)

h(z)

hν(z)

−

(6.3)

26

6
6.6 Example (augmented Lagrangian methods; cont.). For Example 3.4, we obtain that

exsρ

(Sν)−1

B(0, δν )

; S−1

B(0, ε)

βν /θν, where βν =

(cid:16)
provided that 0

≤
Detail. In this case, gph ∂h = (R

∞

δν

(cid:0)
≤

ρ <

gph ∂hν =

≤
(cid:1) (cid:17)
δν + βν/θν.

(cid:1)
and ε

(cid:0)
≥
m−1)
0
× {
}
(z, v)

R2m

∈

Rm−1) and

1
(
×
} ×
{
v = (1, yν

2 + θνz2, . . . , yν

m + θνzm)

.

2ρ +

yν
k

k∞

√m

1,

−

(cid:0)

(cid:1)

(cid:8)

B(0, 2ρ). We construct (¯z, ¯v)

In view Proposition 6.1 and Theorem 6.2, it suﬃces to bound exs2ρ(gph ∂hν ; gph ∂h). Let (zν , vν )
i + θνzν
gph ∂hν
∩
i = 2, . . . , m. Since
vν
2
2 = 0 and
¯v
k
k

gph ∂h by setting ¯v1 = 1, ¯z1 = zν
i + θνzν
yν
vν
i | ≤
|
|

∈
i for
2ρ for i = 2, . . . , m. Moreover,

1 , ¯zi = 0, ¯vi = yν

∈
2ρ, one has

2ρ and

k2 ≤

vν
k

i | ≤

−

(cid:9)

(cid:12)
(cid:12)

zν
k

2
2 =
¯z
k

−

m

i=2

(zν

i −

¯zi)2 =

m

i=2

(zν

i )2

≤

m

i=2

yν
2ρ +
i |
|
θν

2

(cid:17)

(cid:16)

(βν /θν)2.

≤

X
Thus, the distance (in the appropriate norm) between (zν , vν) and (¯z, ¯v) is at most βν /θν.

X

X

6.7 Example (exact penalty methods). We next approach the problem in Example 3.4 using an exact
penalty method. Thus, h(z) = z1 +

) we set

[0,

m
i=2 ι{0}(zi) as before, but for θν
m

∈

∞

P

hν (z) = z1 +

θν

zi
|

.
|

i=2

If θν

→ ∞

, then the resulting approximations are consistent; the details are omitted. Interestingly,

X

(Sν)−1

B(0, δν )

B(0, ρ)

∩

⊂

S−1

B(0, ε)

δν

2ρ. This means that the approximating problem has
provided that 0
a certain “exactness” property: for suﬃciently large θν, satisfaction of the optimality condition for the
approximation problem locally in B(0, ρ) implies satisfaction of the condition for the actual problem.

ρ <

, ε

∞

≥

≤

≤

≥

(cid:0)
(cid:1)
δν , and θν

(cid:0)

(cid:1)

Detail. Example 6.6 furnishes gph ∂h. Moreover, ∂hν (z) =
zi > 0, Ci = [

θν, θν] if zi = 0, and Ci =

otherwise.

1
} ×
{

−

θν
{−
}
gph ∂hν

2ρ. Let (zν , vν )

Suppose that θν

vν
k

Since
the deﬁnition of Ci. We conclude that (zν , vν )
∈
implies that exsρ(gph Sν; gph S) = 0 by Theorem 6.2. The claim follows from Proposition 6.1.

Ci for i = 2, . . . , m.
i = 0 for such i in view of
gph ∂h and exs2ρ(gph ∂hν ; gph ∂h) = 0. This in turn

∈
θν for i = 2, . . . , m. This means that zν

≥
2ρ, one has

vν
i |
|

k2 ≤

< 2ρ

i ∈

≤

∩

B(0, 2ρ). Then, vν

C2 × · · · ×
1 = 1 and vν

Cm, where Ci =

θν
{

}

if

6.8 Example (homotopy method; cont.). In Example 3.10, we obtain for λν

(0, 1) that

∈

exsρ

(Sν )−1

B(0, δν )

; S−1

B(0, ε)

provided that 0

(cid:16)

≤

δν

≤

(cid:0)
ρ <

(cid:1)

≥

, ε

∞

(cid:0)

(cid:1) (cid:17)

δν + βν λν, and ρ

λν/2.

≥

βνλν, where βν =

≤

1 +

s

4ρ2
(1

−
−

(λν)2
λν)2 ,

27

Detail. In this case, ∂h(z) = ∂ˆh(z1, . . . , zm−1)
To bound exs2ρ(gph ∂hν ; gph ∂h), let (zν , vν )
ˆyν
∈
zν
k
−
that 1 +
follows by Theorem 6.2 and Proposition 6.1.

m−1). We construct (¯z, ¯v)
2
2 = (1 +
¯v
k

∂ˆh(zν
1 , . . . , zν
k2 = 0 and
¯z
ˆyν
2
2 ≤
k
k

∈

and ∂hν (z) = (1

λν)∂ˆh(z1, . . . , zm−1)

0
× {
}
gph ∂hν

−
B(0, 2ρ). Then vν = ((1

.
}
λν )ˆyν, λν ) with
∈
gph ∂h by setting ¯v = (ˆyν, 0) and ¯z = zν . Then, one has
ˆyν
4ρ2, we obtain
k
βνλν. The result then

× {

λν

−

≤

−

∩

2 + (λν)2
2)(λν )2. Since
vν
2
2
k
k
k
(βν )2. From this we conclude that exs2ρ(gph ∂hν ; gph ∂h)

2
2 = (1
k

ˆyν
k

vν
k

λν)2

−

≤

Acknowledgement. The author is thankful to K. Balasubramanian (UC Davis) for introducing him
to the inverse problem in Section 5. The research is supported in part by ONR Science of Autonomy
(N0001421WX00142) and AFOSR (18RT0599, 21RT0484).

References

[1] H. Attouch and R. J-B Wets. Quantitative stability of variational systems: I. The epigraphical

distance. Transactions of the American Mathematical Society, 328(2):695–729, 1991.

[2] H. Attouch and R. J-B Wets. Quantitative stability of variational systems: II. A framework for

nonlinear conditioning. SIAM J. Optimization, 3:359–381, 1993.

[3] H. Attouch and R. J-B Wets. Quantitative stability of variational systems: III. ε-approximate

solutions. Mathematical Programming, 61:197–214, 1993.

[4] S. Basu, P. Pope, and S. Feizi. Inﬂuence functions in deep learning are fragile. arXiv:2006.14651,

2020.

[5] A. Beck and M. Teboulle. Smoothing and ﬁrst order methods: A uniﬁed framework. SIAM J.

Optimization, 22(2):557–580, 2012.

[6] A. Ben-Tal and A. Nemirovski. On polyhedral approximations of the second-order cone. Mathe-

matics of Operations Research, 26(2):193–205, 2001.

[7] J.F. Bonnans and A. Shapiro. Perturbation Analysis of Optimization Problems. Springer, 2000.

[8] J.V. Burke. Descent methods for composite nondiﬀerentiable optimization problems. Mathematical

Programming, 33(3):260–279, 1985.

[9] J.V. Burke and M.C. Ferris. A Gauss-Newton method for convex composite optimization. Mathe-

matical Programming, 71:179–194, 1995.

[10] J.V. Burke and T. Hoheisel. Epi-convergent smoothing with applications to convex composite

functions. SIAM J. Optimization, 23(3):1457–1479, 2013.

[11] J.V. Burke and T. Hoheisel. Epi-convergence properties of smoothing by inﬁmal convolution.

Set-Valued and Variational Analysis, 25:1–23, 2017.

28

[12] J.V. Burke, T. Hoheisel, and C. Kanzow. Gradient consistency for integral-convolution smoothing

functions. Set-Valued and Variational Analysis, 21(2):359–376, 2013.

[13] J.V. Burke, T. Hoheisel, and Q.V. Nguyen. A study of convex convex-composite functions via
inﬁmal convolution with applications. Mathematics of Operations Research, 46(4):1324–1348, 2021.

[14] X. Chen. Smoothing methods for nonsmooth, nonconvex minimization. Mathematical Program-

ming, 134:71–99, 2012.

[15] X. Chen and O. L. Mangasarian. A class of smoothing functions for nonlinear and mixed comple-

mentarity problems. Mathematical Programming, 71:51–70, 1995.

[16] Y. Cui and J.-S. Pang. Modern Nonconvex Nondiﬀerentiable Optimization. SIAM, 2021.

[17] Y. Cui, J.-S. Pang, and B. Sen. Composite diﬀerence-max programs for modern statistical estima-

tion problems. SIAM J. Optimization, 28(4):3344–3374, 2018.

[18] D. Davis and D. Drusvyatskiy. Stochastic model-based minimization of weakly convex functions.

SIAM J. Optimization, 29(1):207–239, 2019.

[19] D. Davis and D. Drusvyatskiy. Graphical convergence of subgradients in nonconvex optimization

and learning. Mathematics of Operations Research, 47(1):209–231, 2022.

[20] D. Drusvyatskiy and A.S. Lewis. Tilt stability, uniform quadratic growth, and strong metric

regularity of the subdiﬀerential. SIAM J. Optimization, 23:256–267, 2013.

[21] D. Drusvyatskiy and A.S. Lewis. Error bounds, quadratic growth, and linear convergence of

proximal methods. Mathematics of Operations Research, 43(3):919–948, 2018.

[22] D. Drusvyatskiy and C. Paquette. Eﬃciency of minimizing compositions of convex functions and

smooth maps. Mathematical Programming, 178:503–558, 2019.

[23] J.C. Duchi and F. Ruan. Stochastic methods for composite and weakly convex optimization

problems. SIAM J. Optimization, 28(4):3229–3259, 2018.

[24] A.C. Eberhard and R. Wenczel. A study of tilt-stable optimality and suﬃcient conditions. Non-

linear Analysis, 75:1260–1281, 2012.

[25] Y.M. Ermoliev, V.I. Norkin, and R.J-B Wets. The minimization of discontinuous functions: mol-

liﬁer subgradients. SIAM J. Control and Optimization, 33(1):149–167, 1995.

[26] R. Fletcher. Nondiﬀerential and variational techniques in optimization.

In D.C. Sorensen and
R. J-B Wets, editors, Nondiﬀerential and variational techniques in optimization, Mathematical
Programming Study 17, page 67–76. Academic Press, 1982.

[27] J.C. Foraker, J.O. Royset, and I. Kaminer. Search-trajectory optimization: Part 1, formulation

and theory. J. Optimization Theory and Applications, 169(2):530–549, 2016.

29

[28] P. Hand and V. Voroninski. Global guarantees for enforcing deep generative priors by empirical

risk. In 31st Annual Conference On Learning Theory, 2018.

[29] J.L. Higle and S. Sen. Epigraphical nesting: A unifying theory for the convergence of algorithms.

J. Optimization Theory and Applications, 84(2):339–360, 1995.

[30] W. Huang, P. Hand, R. Heckel, and V. Voroninski. A provably convergent scheme for compressive

sensing under random generative priors. J. Fourier Analysis and Applications, 27(2):1–34, 2021.

[31] A.D. Ioﬀe and J.V. Outrata. On metric and calmness qualiﬁcation conditions in subdiﬀerential

calculus. Set-Valued and Variational Analysis, 16(2-3):199–227, 2008.

[32] D. Klatte, A. Kruger, and B. Kummer. From convergence principles to stability and optimality

conditions. J. Convex Analysis, 19(4):1043–1072, 2012.

[33] P.W. Koh and P. Liang.
arXiv:1703.04730, 2017.

Understanding black-box predictions via inﬂuence functions.

[34] D.P. Kouri and T.M. Surowiec. Epi-regularization of risk measures. Mathematics of Operations

Research, 45(2):774–795, 2020.

[35] A.S. Lewis and S.J. Wright. A proximal method for composite minimization. Mathematical Pro-

gramming, 158:501–546, 2016.

[36] A.S. Lewis and S. Zhang. Partial smoothness, tilt stability, and generalized Hessians. SIAM J.

Optimization, 23:74–94, 2013.

[37] B.S. Mordukhovich. Variational Analysis and Generalized Diﬀerentiation I: Basic Theory.

Grundlehren der mathematischen Wissenschaften. Springer, 2. edition, 2013.

[38] B.S. Mordukhovich, R.T. Rockafellar, and M.E. Sarabi. Characterizations of full stability in con-

strained optimization. SIAM J. Optimization, 23:1810–1849, 2013.

[39] Y. Nesterov. Smooth minimization of non-smooth functions. Mathematical Programming, 103:127–

152, 2005.

[40] J.P. Penot. Error bounds, calmness and their applications in nonsmooth analysis. Contemporary

Mathematics, 514:225–247, 2010.

[41] C. Phelps, J.O. Royset, and Q. Gong. Optimal control of uncertain systems using sample average

approximations. SIAM J. Control and Optimization, 54(1):1–29, 2016.

[42] E. Polak. Optimization. Algorithms and Consistent Approximations, volume 124 of Applied Math-

ematical Sciences. Springer, 1997.

[43] E. Polak, J.O. Royset, and R.S. Womersley. Algorithms with adaptive smoothing for ﬁnite minimax

problems. J. Optimization Theory and Applications, 119(3):459–484, 2003.

30

[44] R.A. Poliquin. An extension of Attouch’s theorem and its application to second-order epi-
diﬀerentiation of convexly composite functions. Transactions of the American Mathematical Soci-
ety, 332(2):861–874, 1992.

[45] M.J.D. Powell. Algorithms for nonlinear constraints that use Lagrangian functions. Mathematical

Programming, 14(2):224–248, 1978.

[46] M.J.D. Powell. A fast algorithm for nonlinearly constrained optimization calculations. In G.A. Wat-
son, editor, Numerical Analysis, Lecture Notes in Mathematics, vol. 630, page 144–157. Springer,
1978.

[47] M.J.D. Powell. General algorithms for discrete nonlinear approximation calculations. In Approxi-

mation Theory, IV, page 187–218. Academic Press, 1983.

[48] M.J.D. Powell. On the global convergence of trust region algorithms for unconstrained minimiza-

tion. Mathematical Programming, 29(3):299–303, 1984.

[49] R.T. Rockafellar. Extended nonlinear programming.

In G. Di Pillo and R. Giannessi, editors,

Nonlinear Optimization and Related Topics, pages 381–399. Kluwer, 1999.

[50] R.T. Rockafellar and R. J-B Wets. Variational Analysis. Springer, 3rd printing-2009 edition, 1998.

[51] J.O. Royset. Optimality functions in stochastic programming. Mathematical Programming,

135(1):293–321, 2012.

[52] J.O. Royset. Approximations and solution estimates in optimization. Mathematical Programming,

170(2):479–506, 2018.

[53] J.O. Royset. Stability and error analysis for optimization and generalized equations. SIAM J.

Optimization, 30(1):752–780, 2020.

[54] J.O. Royset and E.Y. Pee. Rate of convergence analysis of discretization and smoothing algorithms
for semi-inﬁnite minimax problems. J. Optimization Theory and Applications, 155(3):855–882,
2012.

[55] J.O. Royset and R. J-B Wets. Optimality functions and lopsided convergence. J. Optimization

Theory and Applications, 169(3):965–983, 2016.

[56] J.O. Royset and R. J-B Wets. An Optimization Primer. Springer, 2021.

[57] Y. Yuan. On the superlinear convergence of a trust region algorithm for nonsmooth optimization.

Mathematical Programming, 31(3):269–285, 1985.

31

