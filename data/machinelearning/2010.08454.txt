0
2
0
2

t
c
O
6
1

]
L
P
.
s
c
[

1
v
4
5
4
8
0
.
0
1
0
2
:
v
i
X
r
a

Probabilistic Programming with CuPPL

Probabilistic Programming with CuPPL

Alexander Collins
NVIDIA
acollins@nvidia.com

Vinod Grover
NVIDIA
vgrover@nvidia.com

Abstract
Probabilistic Programming Languages (PPLs) are a powerful
tool in machine learning, allowing highly expressive genera-
tive models to be expressed succinctly. They couple complex
inference algorithms, implemented by the language, with an
expressive modelling language that allows a user to imple-
ment any computable function as the generative model.

Such languages are usually implemented on top of existing
high level programming languages and do not make use of
hardware accelerators. PPLs that do make use of accelerators
exist, but restrict the expressivity of the language in order
to do so.

In this paper, we present a language and toolchain that
generates highly efficient code for both CPUs and GPUs.
The language is functional in style, and the toolchain is
built on top of LLVM. Our implementation uses delimited
continuations on CPU to perform inference, and custom
CUDA codes on GPU.

We obtain significant speed ups across a suite of PPL work-
loads, compared to other state of the art approaches on CPU.
Furthermore, our compiler can also generate efficient code
that runs on CUDA GPUs.

1 Introduction
Probabilistic Programming Languages (PPLs) are a powerful
machine learning tool, allowing highly expressive generative
models to be expressed succinctly, and complex inference to
be applied to them. They typically provide a range of built-in
distributions from which samples can be drawn and scored,
along with a range of inference algorithms.

CuPPL is a functional programming language, with all of
the standard control flow constructs including let expres-
sions, conditional expressions, recursive functions, algebraic
datatypes and case statements. It also includes a vector data
type and a suite of built-in vector operators such as map,
reduce and repeat. CuPPL provides two basic probabilistic
primitives: sample and factor. These can be used within a
generative model to sample from and score a suite of built-in
distributions and user defined distribution objects. These
primitives are implemented in using delimited continuations
and the operators shift and reset [8]. CuPPL then provides
inference methods that can be applied to a model function in
order to generate the posterior distribution from the model.

1.1 PPL Example

An example of a generative model is given in Figure 1, which
demonstrates the diverse control flow that CuPPL allows

model <- function () {

n <- sample ( uniform-discrete (2 ,5));
line <- repeat (

function (i) { sample ( normal (0 ,10)) },
n );

factor ( -distance ( line , data ));
line

}

Figure 1. An example program that demonstrates the use
of universal language features in a model function. The im-
plementation of distance is omitted for brevity.

within the model function, and which gives PPLs their ex-
pressive power.

This model finds the 𝑛-degree polynomial that best fits
some given data. The degree of the polynomial is sampled
from a uniform prior, and its coefficients from gaussian pri-
ors. The polynomial is then conditioned on a measure of its
“distance” from the data. The model returns the polynomial,
as a vector of coefficients. Running inference on this model
produces an empirical distribution over polynomials, and
the mode of this distribution is the “line of best fit” for the
data.

1.2 Delimited Continuations

Whenever the model function calls sample or factor, or re-
turns a value, the inference algorithm needs to make deci-
sions about its execution – more specifically the probability
of a trace of execution through the model needs to be tracked
and samples need to be generated.

We use delimited continuations (the shift and reset op-
erators) to allow the inference algorithm to manipulate the
execution of the model function and generate samples from
its posterior distribution.

shift(k, e) captures the current state of the program up
to the last enclosing reset(.), creates a function from this
that can be called via 𝑘, and evaluates 𝑒. 𝑒 may call 𝑘 as few
or as many times as it likes.

Using shift whenever sample or factor are called captures
the current state of execution of the model function (up to
the start of the execution of the model function) and allows
the inference algorithm to decide what to execute next.

Section 3 describes our implementation of sample and factor

in more detail.

 
 
 
 
 
 
1.3 Contributions

In this paper, we make the following contributions:

• We describe a probabilistic programming language
that is functional in nature, and supports delimited
continuations using the shift and reset operators de-
scribed in [4]. The language uses answer type poly-
morphism in its type system to statically type check
the code enabling statically typed LLVM IR to be gen-
erated from it.

• A novel implementation strategy for delimited con-
tinuations in LLVM IR that enables inference to be
implemented in LLVM IR in a similar style to that
described in [11].

• The code generated by our compiler performs signifi-
cantly better than both Anglican [19] and webppl [13]
over a range of benchmark programs.

• Moreover, the code generated by our compiler also

scales well to large numbers of samples.

1.4 Structure

The rest of the paper is structured as follows. In Section 2 we
discuss related work, in Section 3 we give an overview of the
features and type system CuPPL, and in Section 4 we discuss
the design and implementation of the code generator. This
is followed in Section 5 by a performance analysis of our
language across a range of benchmarks, comparing against
both webppl [13] and Anglican [19]. Section 6 concludes the
paper.

2 Related Work
The probabilistic programming languages most similar to
our own are Anglican [19] and webppl [13], however both
of these languages are embedded in other programming lan-
guages. The semantics of our language also borrows heavily
from [11] which describes many of the principles behind
implementing probabilistic languages.

Anglican [19] is embedded in Clojure [1], a dialect of Lisp
that works in the Java Virtual Machine. In is built on top of
continuations and trampolines in order to capture control
and pass it to the inference algorithm.

webppl [13] is written in Javascript, on top of the NodeJS
ecosystem [2]. It uses coroutines to capture control and pass
it to the inference algorithm.

Similarly to Anglican and webppl, Kiselyov et al [14] de-
scribe a domain specific probabilistic language that is em-
bedded in OCaml. They also use the delimited continuation
approach to explore programs as models.

Edward [20, 21] is a probabilistic modelling library for
TensorFlow [3]. This is not a true PPL as it does not allow
arbitrary control flow, and is limited by the graph structures
that are representable in TensorFlow.

Compiler based techniques to producing PPL code include
[22]. This approach translates a PPL problem into MCMC

2

code, rather than compiling the model function in the lan-
guage itself. TerpreT [10] is a domain specific probabilistic
language for program induction, generating programs from
a PPL model.

Earlier approaches to probabilitic programming and mod-
elling include BUGS [16], which is restricted to Bayesian
modelling and cannot handle the complex control structure
that true PPLs can.

Stan [7], similarly to BUGS, is restricted to Bayesian mod-
elling. Bindings exist for embedding Stan in either R or
Python. Other early, and similar, approaches include Church
[12].

Borgstrom et al [6] present a rigorous lambda calculus for
probabilistic programming, in the style of CuPPL, Anglican,
webbpl and Church. They use this to prove that they perform
MCMC inference on program traces correctly.

3 The Language
CuPPL is a statically-typed functional language, and its de-
sign is centered around vectors and data parallel operations.
It is also designed to allow high-level language transfor-
mations such as deforestation of vector operations, closure
conversion and other high level optimization passes.

The rest of this section is structured as follows. Section 3.1
describes the salient features of CuPPL. Section 3.3 describes
how delimited continuations are expressed, Section 3.4 de-
tails how these are used to implement sample and factor, and
finally Section 3.5 details how the polymorphic type system
treats delimited continuations using answer types.

3.1 Language Features

CuPPL includes the usual control flow constructs you would
expect from a functional language including lambda expres-
sions, let-expressions, conditionals, case statements and re-
cursion. The language also includes first class vector data
types of arbitrary dimensions, and a suite of parallel opera-
tors that work over them, including:

• map applies a function to every element of the vector
• repeat generates a vector by running a function a given

number of times

• reduce performs a parallel reduction over a vector
• filter constructs a new vector that includes only those
elements from the input vector for which a given pred-
icate returns true

3.1.1 Type Generalization and Specialization

CuPPL allows type generalization and specialization, in a
similar manner to System F. Polymorphic types can be de-
fined as follows:

type List 'a :

(+ ( Nil : unit )

( Cons : ( 'a , ( List 'a ))));

This example demonstrates both type generalization and

sample <- function ( dist : ~a) : a {

type specialization. List is the type constructor:

forall 'a .

(+ ( Nil : unit )

( Cons : ( 'a , ( List 'a ))))

This type can be specialized to store a list of integers by

using a type application:
( List int )

This produces the concrete type:

(+ ( Nil : unit )

( Cons : ( int , ( List int ))))

We impose a few restrictions on the use of generalized
types, forall types and type applications. Firstly, general
types can only be constructed at the start of a module, as
the type constructors need to be unique within a module.
Secondly, after type checking a program, all types must be
specialized, or turned into concrete types. This is because
the LLVM IR target environment requires all types to be
concrete. If an expression is discovered whose type is not
specialized to a concrete type (such as partial application of
a parallel operator), the compiler complains that it could not
statically determine the concrete type of the expression.

3.2 Distribution Values

The type system includes a distribution type, denoted ~t
which is a distribution over values of type t. It also includes
a suite of built-in distributions, including gaussian, bernoulli,
poisson and many others. Built-in functions to perform op-
erations on distribution values are also provided, such as
sample* which produces a sample from a distribution, dist-score
which scores a sample from a distribution and dist-var which
returns the variance of a distribution.

3.3 Delimited Continuations

CuPPL allows delimited continuations through the use of
the shift and reset constructs [4, 8].

Informally, the meaning of shift is to capture the current
execution state up to the last reset, wrap it in a function, and
bind a name to that function.

For example, consider the following:
reset (1 + shift (k , k (2)))

When shift is encountered, it captures the current pro-

gram as a function named 𝑘. In this case 𝑘 is:

function (x) { 1 + x }

It then executes the body of the shift expression, which
executes k(2), so the program returns 3.

Reset limits the scope to which shift will capture the state

of the program. For example, consider the following:

1 + reset (3 + shift (k , 1))

When shift is encountered, it captures the current program
as a function 𝑘 up to the last reset. In this case 𝑘 is:

3

shift (k : a => b) {

x <- sample-impl ( dist , k );
(x [0])( x [1])

}

}

factor = function ( log-p : a) : unit {

shift k {

f <- factor-impl ( log-p , k );
f ()

}

}

observe = function ( dist , x) : unit {

factor ( dist-score ( dist , x ))

}

Figure 2. Implementation of sample, factor and observe using
delimited continuations

function (x) { 3 + x }

It then executes the body of the shift expression, which
simply returns 1 and does not execute 𝑘, so the program
returns 2 as its result.

3.4 Inference, sample and Factor

The two basic PPL primitives sample and factor are expressed
in terms of delimited continuations. Figure 2 gives the defi-
nition of sample and factor (and the observe helper function)
in terms of shift and reset.

sample uses the shift operator to capture the current ex-
ecution state of the model function as a function 𝑘. When
inference starts, reset is called to limit the scope of this cap-
ture up to the start of the execution of the model function.
sample then calls sample-impl with the distribution object that
was sampled from and 𝑘. The implementation of sample-impl
depends on the choice of inference algorithm, however it
always returns a tuple of type (a => b, a). This function rep-
resents what the program should do next: the first element of
the tuple is a continuation, with the same type as 𝑘, and the
second element of the tuple is a sample from the distribution,
of type a.

factor also uses shift operator to capture the current ex-
ecution state of the model function as a function 𝑘. It then
calls factor-impl with the log probability with which to up-
date the program trace. The implementation of sample-impl
depends on the choice of inference algorithm, however it
always returns a function of type unit => unit. This is a func-
tion denoting what the program should do next, and has the
same type as 𝑘.

observe is a wrapper function around factor that makes
altering the log probability of the execution trace based on
observing data from a distribution simpler. It calls factor with

(lambda)

(apply)

(reset)

(shift)

(expr)

Γ {𝑥 : 𝜏1 }, 𝛼1 ⊢ 𝑒 : 𝜏2, 𝛼2
Γ ⊢𝑝 function [𝛼1𝛼2] (𝑥:𝜏1):𝜏2 { 𝑒 } : 𝜏1/𝛼1 → 𝜏2/𝛼2
Γ, 𝛼1 ⊢ 𝑒1 : 𝜏2/𝛼 → 𝜏/𝛼2, 𝛽

Γ, 𝛼2 ⊢ 𝑒2 : 𝜏2, 𝛼1

Γ, 𝛼 ⊢ 𝑒1(𝑒2) : 𝜏, 𝛽

Γ, 𝛼 ⊢ 𝑒 : 𝛼, 𝜏
Γ ⊢𝑝 reset { 𝑒 } : 𝜏
Γ {𝑥 : ∀𝑡 .(𝜏/𝑡 → 𝛼/𝑡 ) }, 𝜏2 ⊢ 𝑒 : 𝜏2, 𝛽
Γ, 𝛼 ⊢ shift (𝑥 : 𝜏1) : 𝜏2 { 𝑒 } : 𝜏, 𝛽
Γ ⊢𝑝 𝑒 : 𝜏
Γ, 𝛼 ⊢ 𝑒 : 𝜏, 𝛼

Figure 3. Subset of the type rules for CuPPL.

the score of the given sample x from the given distribution
dist.

CuPPL provides two inference methods that implement
sample-impl and factor-impl. They are invoked via built-in
functions called importance (for running importance sam-
pling) and mcmc (for running Monte Carlo Marov Chain based
inference. More details on the implementation of these func-
tions can be found in Section 4.

3.5 Type System

CuPPL uses Hindley-Milner type inference, augmented with
polymorphic answer types [4]. Figure 3 gives a subset of the
type rules. Te following notation is used:

• Types are denoted 𝜏.
• Type schemes are denoted 𝜎. They have the syntax

𝜎 = 𝜏 | ∀𝐴.𝜏 where 𝐴 is a set of type variables.

• 𝜏 ≺ 𝜎 denotes that type 𝜏 is an instance of type scheme

𝜎

• Answer types are denoted 𝛼, 𝛽, 𝛾. Answer types can

be any type 𝜏 or the empty type, denoted ⊥

• Expressions are denoted 𝑒.
• Constant values are denoted 𝑐.
• Variable identifiers are denoted 𝑥.
• Type environments are denoted Γ. These map vari-
able identifiers 𝑥 to type schemes 𝜎. The notation
Γ{𝑥 : 𝜎 } denotes mapping Γ updated with identifier 𝑥
mapped to type scheme 𝜎. Γ0 denotes an empty type
environment, that does not map any identifiers to type
schemes.

• There are two forms of type judgements:

– Pure type judgments are written Γ ⊢𝑝 𝑒 : 𝜏. This
means that expression 𝑒 has type 𝜏, given type envi-
ronment Γ.

– Impure type judgments are written Γ, 𝛼 ⊢ 𝑒 : 𝜏, 𝛽.
This means that expression 𝑒 has type 𝜏, given type
environment Γ and the execution of 𝑒 changes the
answer type from 𝛼 to 𝛽.

The expr rule allows an expression with the same input
and output answer types to be type checked as a pure ex-
pression.

3.6 Inference Methods

CuPPL supports three inference methods.

3.6.1 Enumeration

Enumeration performs precise inference on the model func-
tion, by executing all possible paths through the function.
The probabilistic branching points are when the model calls
sample. Whenever sample is called, the inference algorithm
executes the model function from that point for all values
in the support of the distribution. This only works for dis-
tributions with finite support, and returns a runtime error
if a continuous distribution is encountered. This performs a
breadth first traversal through the model function, and the
depth of this traversal can be limited to a maximum depth if
desired.

3.6.2 Importance Sampling

This performs importance sampling [18] on the model func-
tion. This is done by repeatedly running the model function.
The calls to sample and factor made by each execution pre-
scribe a log probability the value returned by the model
function. The model function is repeated up to a chosen
number of times, and the posterior distribution is computed
by normalizing the log probabilities of the returned values.

3.6.3 Lightweight Metropolis-Hastings

This inference method [22] uses the Metrolpolis-Hastings
algorithm to generate samples from the posterior distribu-
tion of the model function. First, the model function is run
once to memorize the return values of any calls to sample.
To generate a new sample, One of the memorized return
values is chosen uniformly randomly, re-sampled, and the
model function is re-executed from this point. Subsequent
calls to sample reuse memorized values where possible. This
may not be possible if the modification affects the control
flow of the program, in which case new values are sampled
and memorized. When the model function completes, the
Metropolis-hasting acceptance criteria is used to either ac-
cept or reject the sample.

4 Code Generation
Our compiler parses the code, performs language-specific
optimization passes on the AST, and then generates code for
either CPU or GPU using a code generator built on top of
the LLVM toolchain [15].

The rest of this section is structured as follows. Section 4.1
describes how various language features are compiled to
LLVM IR, including closures and distribution objects. Sec-
tion 4.2 describes the implementation of the call stack and

4

how different language constructs interact with it. Section 4.3
describes how delimited continuations are implemented for
CPU. Finally Section 4.4 describes the code generation for the
inference methods on CPU, using delimited continuations,
and GPU, using custom generated NVVM IR.

4.1 Language Features

4.2 Call Stack
The generated LLVM IR does not use the call operator. In-
stead it uses a combination of indirectbr and a custom “man-
aged stack”. This allows for more complex stack operations
necessary for implementing delimited continuations as dis-
cussed in Section 4.3.

The managed stack is stored in region of heap allocated
memory, allocated when the program starts. A stack pointer
is also stored. LLVM IR is generated for the operations that
modify the stack:

• Push and pop work just like a conventional stack.
• The stack save operation copies a chosen number of
bytes from the top of the stack into a newly allocated
region on the heap, and returns a pointer to it, and
then pops this region off of the stack. This operation is
used by delimited continuations to capture the current
state of the program up to the last reset, as part of the
implementation of shift discussed in Section 4.3.
• The stack restore operation pushes a previously saved
stack region onto the top of the stack. This operation
is used to restore the state of the stack when calling a
continuation that was captured by the shift operator,
as detailed in Section 4.3.

4.2.1 Closures

The LLVM IR code for a closure begins with a labelled basic
block. A closure is called using an indirectbr to the address
of this block (obtained using blockaddress). This label is an-
notated with all possible predecessor blocks, as required by
LLVM IR. These are statically known, but may be a superset
of all possibly call sites at runtime.

A closure value is represented by an LLVM IR struct of
type {i64,i64}, containing a pointer to its code and and some
memory storing its environment. The environment of a clo-
sure is represented by an LLVM IR struct containing the
values of its captured variables. If the environment is empty,
this struct has type {}. The instructions in the entry block
of the closure first unpack this environment into registers,
before continuing with the execution of the closure.

When calling a closure, the LLVM IR call instruction is not
used, so that more complex stack operations can be handled.
This requires the code generator to generate code for entry
and return from the call. The code generation strategy is
summarised by the pseudocode in Figure 4.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

1
2
3
4
5
6
7

1
2
3
4
5

generateClosureCall ( entryPtr , envPtr , args ) {

retBlk = llvm :: BasicBlock :: Create ();
retAddr = llvm :: BlockAddress :: get ( retBlk );
for ( var in symTab )

generateStackPush ( var );

generatePush ( retAddr );
generatePush ( envPtr );
for ( arg in args )

generateStackPush ( arg );

builder . CreateIndirectBr ( entryPtr );
builder . SetInsertPoint ( retBlk );
result = generatePop ();
for ( var in reverse ( symTab ))

symTab . update ( var , generateStackPop ());

return result ;

}

generateClosureEntry ( argVars , freeVars ) {

for ( var in reverse ( argVars ))

symTab . update ( var , generateStackPop ());

envPtr = generateStackPop ();
for ( var in freeVars )

symTab . update ( var , unpack ( envPtr , var ));

}

generateClosureExit ( result ) {

retAddr = generateStackPop ();
generateStackPush ( result );
builder . CreateIndirectBr ( returnAddress );

}

Figure 4. Code generation strategy for closures

4.2.2 Distribution Values

Built-in distributions are represented by a struct of type
{int32, int64, int64, int64}. The first element is a tag deter-
mining the type of the distribution, and the subsequent ele-
ments contain distribution specific data. These three values
provide sufficient space to store parameters for any of the
built-in distributions. This fixed sized encoding of distri-
bution values allows them to be treated as plain values in
LLVM IR, avoiding the need for heap allocation. This makes
them suitable for use on a GPU where heap allocations are
expensive.

4.2.3 Built-in Functions and Runtime Library

CuPPL includes a runtime library which implements the
built-in functions that are not directly available in the LLVM
IR instruction set. For example, sampling and scoring dis-
tributions is implemented in the runtime library. Separate
implementations of this library are provided for CPU and
CUDA GPUs.

4.2.4 Garbage Collection

On CPU, where it is needed, the Boehm-Demers-Weiser
Garbage Collector [5] is used. On GPU, garbage collection

5

is not feasible. Static shape analysis is used to determine a
fixed upper bound for the size of any vectors used so that
they can be stack allocated. If the size of a vector cannot
be statically determined the code generator will fall back to
making a heap allocation. Depending on the structure of the
program, this heap allocation fallback may exhaust the heap
space available on the GPU, in which case the program will
have to be reworked.

4.3 Delimited Continuations

The reset operator marks the current state of the program.
It does this by pushing the value of the stack pointer onto
the top of a separate “reset stack”. When the reset operator
exits, the value is popped off of the reset stack.

The shift operator captures the current program state
as closure value that can be called at some later point. It
creates a closure value containing a pointer to the current
instruction and the contents of the stack up to the last call
to reset. The address of the current instruction is obtained
by starting a new basic block before that instruction and
obtaining its address using blockaddress. A copy of the stack
is obtained using the stack copy operation, to save the region
from the current stack pointer up to the stack pointer stored
on the top of the reset stack.

The environment for the captured continuation differs
from that of a regular closure. Instead of a struct containing
the values of any captured variables, it is a struct containing
the saved stack region. It has type {int32, int8*} – storing
the size of the captured stack and a pointer to it.

When a captured continuation is called the same steps
are taken as calling a regular closure. However, instead of
unpacking the environment structure into local variables, the
saved stack from the environment structure and is pushed
onto the top of the call stack. This restores the stack (up to the
last reset) to the same state it was in when the continuation
was captured.

Pseudocode for the implementation of this code genera-
tion is shown in Figure 5. generateResetEntry generates code
for the entry into a reset expression, and returns the exit
block so that the caller can pass it to generateResetExit later.
generateResetExit is called, with the exit block and the return
value of the sub-expression, after code has been generated
for the sub-expression in the reset. generateShiftEntry and
generateShiftExit generate code for the entry and exit from
a shift expression.

4.4 Inference

Code is generated for the model function, which uses shift
expressions to capture the model functions continuation
and pass it to sample-impl and factor-impl, as described in
Section 3.4, and in the previous section.

Code is generated for the inference methods importance
and mcmc, first by converting them to calls to infer-impl, as

1
2
3
4
5
6
7
8
9
10
11

1
2
3
4
5
6
7
8
9
10
11

1
2
3
4
5
6
7
8
9
10
11
12

1
2
3
4
5
6
7
8
9
10
11
12

generateResetEntry () {
for ( var in symTab )

generateStackPush ( var );

exitBlock = llvm :: BasicBlock :: Create ();
exitAddress = llvm :: BlockAddress :: get (

exitBlock );

generateStackPush ( exitAddress );
stackPtr = generateGetStackPtr ();
generateResetStackPush ( stackPtr );
return exitBlock ;

}

generateResetExit ( exitBlock , value ) {
returnAddress = generateStackPop ();
generateStackPush ( value );
builder . CreateIndirectBr ( returnAddress );
builder . SetInsertPoint ( exitBlock );
result = generateStackPop ();
generateResetStackPop ();
for ( var in reverse ( symTab ))

symtab . update ( var , generateStackPop ());

return result ;

}

generateShiftEntry () {
for ( var in symTab )

generateStackPush ( var );

kBlock = llvm :: BasicBlock :: Create ();
kAddress = llvm :: BlockAddress :: Get ( kBlock );
startPtr = generateResetStackPeek ();
capturedStack = generateStackSave ( startPtr );
k = builder . CreateStruct (

kAddress , capturedStack );
return builder . CreateStruct (

k , kBlock );

}

generateShiftExit (k , kBlock , value ) {
returnAddress = generateStackPop ();
generateStackPush ( value );
builder . CreateIndirectBr ( returnAddress );
builder . SetInsertPoint ( kBlock );
argument = generateStackPop ();
capturedStack = generateStackPop ();
generateStackRestore ( capturedStack );
for ( var in reverse ( symTab ))

symTab . upate ( var , generateStackPop ());

return argument ;

}

Figure 5. Pseudocode for code generation of delimited con-
tinuation operators shift and reset

described in Section 3.6, and then generating the code for
the resulting abstract syntax tree.

6

biasedcoin

customdist

linear_regression
logistic_regression
binomial

sevenscientists

linefitting

enumerate_geometric

Importance sampling to compute expected
value of a biased coin, conditioned on ob-
served coin flips
Importance sampling from a custom distri-
bution (sum of two gaussians)
Linear regression using MCMC
Logistic regression using MCMC
Importance sampling to generate a binomial
distribution
Importance sampling for the seven scientists
problem
n-degree polynomial line fitting using impor-
tance sampling
Exact inference to generate a geometric dis-
tribution

Figure 6. Benchmark programs

5 Evaluation
This section explores the performance of CuPPL. In Sec-
tion 5.1 we compare CuPPL against webppl [13] and Anglican
[19] across a range of benchmarks, including probabilistic
models and micro-benchmarks. In Section 5.3 we compare
the performance of our implementation of delimited contin-
uations against Racket [9].

5.1 Performance vs Other PPLs

The experiments were run on an i7-5820K CPU with 16 GB
of main memory and an NVIDIA GTX 710. The wall clock
execution time of the entire program is measured for 10
repeats. Error bars in the plots show the standard deviation
of the measured data.

The benchmark programs are summarized in Table 6. Each
benchmark was implemented in Anglican [19], webppl [13]
and CuPPL. The CuPPL versions of the benchmark code
were compiled for both CPU and GPU and run separately.
Anglican does not support exact inference, therefore the
enumerate_geometric benchmark is omitted for this lan-
guage.

For models using importance sampling, each language
is configured to generate 2 million samples, For MCMC in-
ference, each language is configured to generate 100 thou-
sand samples and for exact inference, 10 thousand maximum
executions are used. These values were chosen to provide
execution times of the order of a few seconds across most
benchmarks.

The results are shown in Figure 7. This plot shows that
CuPPL is significantly more performant that both webppl
and Anglican across all but one of the benchmarks. webppl
fails to run the line fitting benchmark – the program was
terminated after 10 minutes without producing a result.

The GPU implementation of CuPPL improves performance
compared to the CPU implementation, for most of the im-
portance sampling benchmarks. GPU inference does not yet
support MCMC or exact inference. The customdist bench-
mark performs similarly on CPU and GPU, most likely due

Figure 7. Execution time across all benchmarks and lan-
guages. Error bars show one standard deviation for 10 re-
peated measurements. Where data is omitted, the benchmark
is either not supported by that language or takes more than
10 minutes to run.

Figure 8. Performance two benchmarks using different in-
ference methods. Error bars show one standard deviation for
10 repeated measurements.

to the branching nature of the benchmark. The more com-
plex line fitting benchmark also shows less of a performance
improvement on GPU compared to CPU. This is also likely
due to the branching nature of the program, which is de-
pendent on an integer sampled from the uniform discrete
distribution.

The scalability for two of the benchmarks is shown in Fig-
ure 8. linefitting is the more complex of the importance
sampling benchmarks, and linear_regression uses Light-
weight MH inference. These results show that each language
scales similarly, however the slope for CuPPL is reduced.

7

biasedcoincustomdistbinomial7scientistslinefittinglinreglogreggeometricExecution time / s0510152025301.60.87204.44.31421.90.915.8270.840.3810160.860.8130.120.6536.30.824.93.8gppl−cpugppl−cudawebpplanglicanExecution time / s50000150000051525linefittingNumber of sampleslllllllllllllllllllllllll2e+046e+041e+0502468linregNumber of samplesllllllllllllllllllllllllllllllgppl−cpugppl−cudawebpplanglicantype List : (+ ( Cons : ( int , List ))

( Nil : unit ));

visit <- function ( lst ) {

case ( lst ) {

Nil = shift (k , Nil ())
Cons (a , rst ) =

( Cons (a ,

shift (k ,

append (k( Nil ()) ,
reset (k( visit ( rst )))))))

}

};
prefix <- function ( lst ) {

reset ( visit ( lst ))

}

Figure 10. Code for the prefix benchmark in CuPPL. append
is omitted for brevity. For input [1, 2, 3], this outputs
[1, 1, 2, 1, 2, 3].

Figure 11. Execution time against input size for the prefix
benchmark, comparing CuPPL to Racket.

References
[1] 2018. Clojure. https://clojure.org. (2018). Accessed: 2018-02-23.
[2] 2018. NodeJS. https://nodejs.org. (2018). Accessed: 2018-02-23.
[3] Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng
Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu
Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey
Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser,
Manjunath Kudlur, Josh Levenberg, Dan Mané, Rajat Monga, Sherry
Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens,
Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent
Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete
Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang
Zheng. 2015. TensorFlow: Large-Scale Machine Learning on Heteroge-
neous Systems. (2015). https://www.tensorflow.org/ Software available
from tensorflow.org.

8

Figure 9. Performance results for two micro-benchmarks.
Error bars show one standard deviation for 10 repeated mea-
surements.

5.2 Micro-benchmarks

Figure 9 compares the scalability of CuPPL, webppl, An-
glican and Racket for two microbenchmarks. fibonacci
implements the naive recursive fibonacci algorithm to test
function call performance. vectorsum sums a vector of 𝑛
ones, to test memory bound performance.

The results show that CuPPL, Anglican and Racket all per-
form similarly for function call performance, whereas webppl
performance is initially similar but does not scale well. For
memory bound performance, webppl performs poorly. The
other languages all scale similarly, however CuPPL is signifi-
cantly faster.

5.3 Delimited Continuation Performance

The prefix algorithm, shown in Figure 10 is used to com-
pare our implementation against Racket [9]. The results are
shown in Figure 11, and show that the performance of our
implementation is competitive.

6 Conclusions and Future Work
In this paper, we have presented CuPPL, a probabilistic pro-
gramming language that generates highly efficient code for
both CPUs and CUDA GPUs. The language is functional in
style, and the toolchain is built on top of LLVM. Our imple-
mentation uses delimited continuations on CPU to perform
inference, and custom CUDA codes on GPU.

Compared to other state of the art PPLs Anglican [19]
and webppl [13], CuPPL achieves significantly better perfor-
mance across a range of benchmarks, and scales linearly to
large numbers of samples. Our implementation of delimited
continuations is also competitive with Racket [9].

In future, we plan to extend our language to support a
greater variety of inference methods on both CPU and GPU.
We are investigating parallelizable particle-based inference
methods [17] for use on GPU.

Execution time / s253035400103050fibonacciNumber of samplesllllllllllllllllllllllllllllllllllllllll1e+064e+067e+060123456vectorsumNumber of samplesllllllllllllllllllllllllllgppl−cpuwebpplanglicanracket1002003004005006000.00.51.01.52.02.5Input nExecution time / sllllllllllllgppl−cpuracket[22] David Wingate, Andreas Stuhlmueller, and Noah Goodman. 2011.
Lightweight Implementations of Probabilistic Programming Lan-
guages via Transformational Compilation. In Proceedings of the Four-
teenth International Conference on Artificial Intelligence and Statistics
(Proceedings of Machine Learning Research), Vol. 15. PMLR, Fort Laud-
erdale, FL, USA, 770–778.

[4] Kenichi Asai and Yukiyoshi Kameyama. 2007. Polymorphic Delim-
ited Continuations. In Proceedings of the 5th Asian Conference on Pro-
gramming Languages and Systems (APLAS’07). Springer-Verlag, Berlin,
Heidelberg, 239–254.

[5] Hans-Juergen Boehm and Mark Weiser. 1988. Garbage Collection in
an Uncooperative Environment. Software Practices and Experience 18,
9 (Sept. 1988), 807–820.

[6] Johannes Borgström, Ugo Dal Lago, Andrew D. Gordon, and Marcin
Szymczak. 2016. A Lambda-calculus Foundation for Universal Proba-
bilistic Programming. In Proceedings of the 21st ACM SIGPLAN Interna-
tional Conference on Functional Programming (ICFP 2016). ACM, New
York, NY, USA, 33–46.

[7] Bob Carpenter, Andrew Gelman, Matthew Hoffman, Daniel Lee, Ben
Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li,
and Allen Riddell. 2017. Stan: A Probabilistic Programming Language.
Journal of Statistical Software, Articles 76, 1 (2017), 1–32.

[8] Mattias Felleisen. 1988. The Theory and Practice of First-class Prompts.
In Proceedings of the 15th ACM SIGPLAN-SIGACT Symposium on Princi-
ples of Programming Languages (POPL ’88). ACM, New York, NY, USA,
180–190.

[9] Matthew Flatt and PLT. 2010. Reference: Racket. Technical Report

PLT-TR-2010-1. PLT Design Inc. https://racket-lang.org/tr1/.

[10] Alexander L. Gaunt, Marc Brockschmidt, Rishabh Singh, Nate Kush-
man, Pushmeet Kohli, Jonathan Taylor, and Daniel Tarlow. 2016. Ter-
preT: A Probabilistic Programming Language for Program Induction.
CoRR abs/1608.04428 (2016).

[11] Noah D. Goodman. 2013. The Principles and Practice of Probabilis-
tic Programming. In Proceedings of the 40th Annual ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages (POPL
’13). ACM, New York, NY, USA, 399–402.

[12] Noah D. Goodman, Vikash K. Mansinghka, Daniel M. Roy, Keith
Bonawitz, and Joshua B. Tenenbaum. 2012. Church: a language for
generative models. CoRR abs/1206.3255 (2012).

[13] Noah D Goodman and Andreas Stuhlmüller. 2014. The Design and
Implementation of Probabilistic Programming Languages. http://dippl.
org. (2014). Accessed: 2018-02-23.

[14] Oleg Kiselyov and Chung-Chieh Shan. 2009. Embedded Probabilistic
Programming. In Proceedings of the IFIP TC 2 Working Conference on
Domain-Specific Languages (DSL ’09). Springer-Verlag, Berlin, Heidel-
berg, 360–384.

[15] Chris Lattner and Vikram Adve. 2004. LLVM: A Compilation Frame-
work for Lifelong Program Analysis and Transformation. In COde
Generation and Optimization. San Jose, CA, USA, 75–88.

[16] David Lunn, David Spiegelhalter, Andrew Thomas, and Nicky Best.
2009. The BUGS project: Evolution, critique and future directions.
Statistics in Medicine 28, 25 (2009), 3049–3067.

[17] Brooks Paige, Frank Wood, Arnaud Doucet, and Yee Whye Teh. 2014.
Asynchronous Anytime Sequential Monte Carlo. In Advances in Neu-
ral Information Processing Systems 27, Z. Ghahramani, M. Welling,
C. Cortes, N.D. Lawrence, and K.Q. Weinberger (Eds.). Curran Asso-
ciates, Inc., 3410–3418.

[18] Brian D Ripley. 2008. Stochastic Simulation.
[19] David Tolpin, Jan Willem van de Meent, Hongseok Yang, and Frank
Wood. 2016. Design and Implementation of Probabilistic Programming
Language Anglican. arXiv preprint arXiv:1608.05263 (2016).

[20] Dustin Tran, Matthew D. Hoffman, Rif A. Saurous, Eugene Brevdo,
Kevin Murphy, and David M. Blei. 2017. Deep probabilistic program-
ming. In International Conference on Learning Representations.
[21] Dustin Tran, Alp Kucukelbir, Adji B. Dieng, Maja Rudolph, Dawen
Liang, and David M. Blei. 2016. Edward: A library for probabilistic
modeling, inference, and criticism. arXiv preprint arXiv:1610.09787
(2016).

9

