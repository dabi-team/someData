Integer Programming for Learning Directed Acyclic Graphs
from Continuous Data

Hasan Manzour∗

Simge K¨u¸c¨ukyavuz†

Ali Shojaie‡

April 25, 2019

Abstract

Learning directed acyclic graphs (DAGs) from data is a challenging task both in theory and
in practice, because the number of possible DAGs scales superexponentially with the number
of nodes. In this paper, we study the problem of learning an optimal DAG from continuous
observational data. We cast this problem in the form of a mathematical programming model
which can naturally incorporate a super-structure in order to reduce the set of possible can-
didate DAGs. We use the penalized negative log-likelihood score function with both (cid:96)0 and
(cid:96)1 regularizations and propose a new mixed-integer quadratic optimization (MIQO) model,
referred to as a layered network (LN) formulation. The LN formulation is a compact model,
which enjoys as tight an optimal continuous relaxation value as the stronger but larger formu-
lations under a mild condition. Computational results indicate that the proposed formulation
outperforms existing mathematical formulations and scales better than available algorithms
that can solve the same problem with only (cid:96)1 regularization. In particular, the LN formulation
clearly outperforms existing methods in terms of computational time needed to ﬁnd an optimal
DAG in the presence of a sparse super-structure.

1 Introduction

The study of Probabilistic Graphical Models (PGMs) is an essential topic in modern artiﬁcial
intelligence [23]. A PGM is a rich framework that represents the joint probability distribution and
dependency structure among a set of random variables in the form of a graph. Once learned from
data or constructed from expert knowledge, PGMs can be utilized for probabilistic reasoning tasks,
such as prediction; see [23, 24] for comprehensive reviews of PGMs.

Two most common classes of PGMs are Markov networks (undirected graphical models) and
Bayesian networks (directed graphical models). A Bayesian Network (BN) is a PGM in which the
conditional probability relationships among random variables are represented in the form of a Di-
rected Acyclic Graph (DAG). BNs use the richer language of directed graphs to model probabilistic
inﬂuence among random variables that have clear directionality; they are particularly popular in
practice, with applications in genetics [45], biology [27], machine learning [23], and causal inference
[39].

9
1
0
2

r
p
A
3
2

]

G
L
.
s
c
[

1
v
4
7
5
0
1
.
4
0
9
1
:
v
i
X
r
a

∗Department of Industrial and Systems Engineering, University of Washington (hmanzour@uw.edu).
†Department

and Management

Engineering

Industrial

Sciences,

of

Northwestern University

(simge@northwestern.edu).

‡Department of Biostatistics, University of Washington (ashojaie@uw.edu).

1

 
 
 
 
 
 
Learning BNs is a central problem in machine learning. An essential part of this problem
entails learning the DAG structure that accurately represents the (hypothetical) joint probability
distribution of the BN. Although one can form the DAG based on expert knowledge, acquisition of
knowledge from experts is often costly and nontrivial. Hence, there has been considerable interest
in learning the DAG directly from observational data [3, 6, 9, 10, 17, 29, 34, 39].

Learning the DAG which best explains observed data is an NP-hard problem [5]. Despite this
negative theoretical result, there has been interest in developing methods for learning DAGs in
practice. There are two main approaches for learning DAGs from observational data: constraint-
based and score-based. In constraint-based methods, such as the well-known PC-Algorithm [39],
the goal is to learn a completed partially DAG (CPDAG) consistent with conditional independence
relations inferred from the data. Score-based methods, including the approach in this paper, aim
to ﬁnd a DAG that maximizes a score that measures how well the DAG ﬁts the data.

Existing DAG learning algorithms can also be divided into methods for discrete and continuous
data. Score-based methods for learning DAGs from discrete data typically involve a two-stage
learning process. In stage 1, the score for each candidate parent set (CPS) of each node is computed.
In stage 2, a search algorithm is used to maximize the global score, so that the resulting graph is
acyclic. Both of these stages require exponential computation time [42]. For stage 2, there exist
elegant exact algorithms based on dynamic programming [13, 21, 22, 30, 32, 36, 44], A(cid:63) algorithm
[43, 44], and integer-programming [2, 3, 7, 8, 9, 10]. The A(cid:63) algorithm identiﬁes the optimal
DAG by solving a shortest path problem in an implicit state-space search graph, whereas integer
programming (IP) directly casts the problem as a constrained optimization problem. Speciﬁcally,
the variables in the IP model indicate whether or not a given parent set is assigned to a node in the
network. Hence, the problem involves m2m−1 binary variables for m nodes. To reduce the number
of binary variables, a common practice is to limit the cardinality of each parent set [3, 9], which
can lead to suboptimal solutions.

A comprehensive empirical evaluation of A(cid:63) algorithm and IP methods for discrete data is
conducted in [26]. The results show that the relative eﬃciency of these methods varies due to the
intrinsic diﬀerences between them. In particular, state-of-the-art IP methods can solve instances
up to 1,000 CPS per variable regardless of the number of nodes, whereas A(cid:63) algorithm works for
problems with up to 30 nodes, even with tens of thousands of CPS per node.

While statistical properties of DAG learning from continuous data have been extensively studied
[15, 25, 34, 37, 41], the development of eﬃcient computational tools for learning the optimal DAG
In addition, despite the existence of elegant
from continuous data remains an open challenge.
exact search algorithms for discrete data, the literature on DAG learning from continuous data has
primarily focused on approximate algorithms based on coordinate descent [14, 17] and non-convex
continuous optimization [46]. To our knowledge, [29] and [42] provide the only exact algorithms for
learning medium to large DAGs from continuous data. An IP-based model using the topological
ordering of variables is proposed in [29]. An A(cid:63)-lasso algorithm for learning an optimal DAG from
continuous data with an (cid:96)1 regularization is developed in [42]. A(cid:63)-lasso incorporates the lasso-based
scoring method within dynamic programming to avoid an exponential number of parent sets and
uses the A(cid:63) algorithm to prune the search space of the dynamic programming method.

Given the state of existing algorithms for DAG learning from continuous data, there is currently
a gap between theory and computation: While statistical properties of exact algorithms can be
rigorously analyzed [25, 41], it is much harder to assess the statistical properties of approximate
algorithms [1, 14, 17, 46] that oﬀer no optimality guarantees [21]. This gap becomes particularly
noticeable in cases where the statistical model is identiﬁable from observational data. In this case,

2

the optimal score from exact search algorithms is guaranteed to reveal the true underlying DAG
when the sample size is large. Therefore, causal structure learning from observational data becomes
feasible [25, 33].

In this paper, we focus on DAG learning for an important class of BNs for continuous data,
where causal relations among random variables are linear. More speciﬁcally, we consider DAGs
corresponding to linear structural equations models (SEMs). In this case, network edges are as-
sociated with the coeﬃcients of regression models corresponding to linear SEMs. Consequently,
the score function can be explicitly encoded as a penalized negative log-likelihood function with an
appropriate choice of regularization [29, 35, 41]. Hence, the process of computing scores (i.e., stage
1) is completely bypassed, and a single-stage model can be formulated [42]. Moreover, in this case,
IP formulations only require a polynomial, rather than exponential, number of variables, because
each variable can be deﬁned in the space of arcs instead of parent sets. Therefore, cardinality
constraints on the size of parent sets, which are used in earlier methods to reduce the search space
and may lead to suboptimal solutions, are no longer necessary.

Contributions
data from linear SEMs, and make the following contributions:

In this paper, we develop tailored exact DAG learning methods for continuous

– We develop a mathematical framework that can naturally incorporate prior structural
knowledge, when available. Prior structural knowledge can be supplied in the form of an
undirected and possibly cyclic graph (super-structure). An example is the skeleton of the
DAG, obtained by removing the direction of all edges in a graph. Another example is
the moral graph of the DAG, obtained by adding an edge between pairs of nodes with
common children and removing the direction of all edges [39]. The skeleton and moral
graphs are particularly important cases, because they can be consistently estimated from
observational data under proper assumptions [20, 25]. Such prior information limits the
number of possible DAGs and improves the computational performance.

– We discuss three mathematical formulations, namely, cutting plane (CP), linear ordering
(LO), and topological ordering (TO) formulations, for learning an optimal DAG, using both
(cid:96)0 and (cid:96)1-penalized likelihood scores. We also propose a new mathematical formulation to
learn an optimal DAG from continuous data, the layered network (LN) formulation, and es-
tablish that other DAG learning formulations entail a smaller continuous relaxation feasible
region compared to that of the continuous relaxation of the LN formulation (Propositions 3
and 4). Nonetheless, all formulations attain the same optimal continuous relaxation objec-
tive function value under a mild condition (Propositions 5 and 6). Notably, the number of
binary variables and constraints in the LN formulation solely depend on the number of edges
in the super-structure (e.g., moral graph). Thus, the performance of the LN formulation
substantially improves in the presence of a sparse super-structure. The LN formulation has
a number of other advantages; it is a compact formulation in contrast to the CP formula-
tion; its relaxation can be solved much more eﬃciently compared with the LO formulation;
and it requires fewer binary variables and explores fewer branch-and-bound nodes than
the TO formulation. Our empirical results aﬃrm the computational advantages of the LN
formulation. They also demonstrate that the LN formulation can ﬁnd a graph closer to
the true underlying DAG. These improvements become more noticeable in the presence of
a prior super-structure (e.g., moral graph).

3

– We compare the IP-based method and the A(cid:63)-lasso algorithm for the case of (cid:96)1 regulariza-
tion. As noted earlier, there is no clear winner among A(cid:63)-style algorithms and IP-based
models for DAG learning from discrete data [26]. Thus, a wide range of approaches based
on dynamic programming, A(cid:63) algorithm, and IP-based models have been proposed for
discrete data. In contrast, for DAG learning from continuous data with complete super-
structure, the LN formulation remains competitive with the state-of-art A(cid:63)-lasso algorithm
for small graphs, whereas it performs better for larger problems. Moreover, LN performs
substantially better when a sparse super-structure is available. This is mainly because the
LN formulation directly deﬁnes the variables based on the super-structure, whereas the
A(cid:63)-lasso algorithm cannot take advantage of the prior structural knowledge as eﬀectively
as the LN formulation.

In Section 2, we outline the necessary preliminaries, deﬁne the DAG structure learning problem,
and present a general framework for the problem. Mathematical formulations for DAG learning are
presented in Section 3. The strengths of diﬀerent optimization problems are discussed in Section
4. Empirical results are presented in Sections 5 and 6. We end the paper with a summary and
discussion of future research in Section 7.

2 Penalized DAG Estimation with Linear SEMs

The causal eﬀect of (continuous) random variables in a DAG G0 can be described by SEMs that
represent each variable as a (nonlinear) function of its parents. The general form of these models
is given by [31]

Xk = fk

(cid:0)paG0

k , δk

(cid:1),

k = 1, . . . , m,

(1)

where Xk is the random variable associated with node k; paG0
k denotes the parents of node k in G0,
i.e., the set of nodes with arcs pointing to node k; m is the number of nodes; and latent random
variables, δk represent the unexplained variation in each node.

An important class of SEMs is deﬁned by linear functions, fk(·), which can be described by m

linear regressions of the form

Xk =

(cid:88)

j∈paG0
k

βjkXj + δk,

k = 1, . . . , m,

(2)

where βjk represents the eﬀect of node j on k for j ∈ paG0
k . In the special case where the random
variables are Gaussian, Equations (1) and (2) are equivalent, in the sense that βjk are coeﬃcients
of the linear regression model of Xk on Xj, j ∈ paG0
[35]. However,
estimation procedures proposed in this paper are not limited to Gaussian random variables and
apply more generally to linear SEMs [25, 35].

k , and βjk = 0 for j /∈ paG0

k

Let M = (V, E) be an undirected and possibly cyclic super-structure graph with node set
−→
E )
−→
E = {(j, k), (k, j)|(j, k) ∈ E}. Throughout the paper, we refer to directed edges as arcs and

V = {1, 2, . . . , m} and edge set E ⊆ V × V . From M, generate a bi-directional graph
where
to undirected edges as edges.

−→
M = (V,

Consider n i.i.d. observations from the linear SEM (2). Let X = (X1, . . . , Xm) be the n × m
data matrix with n rows representing i.i.d. samples, and m columns representing random variables.

4

The linear SEM (2) can be compactly written as

X = X B + ∆,

(3)

−→
where B = [β] ∈ Rm×m is a matrix with βkk = 0 for k = 1, . . . , m and βjk = 0 for all (j, k) /∈
E ; ∆
is the n × m noise matrix. More generally, B deﬁnes a directed graph G(B) on m nodes such that
arc (j, k) appears in G(B) if and only if βjk (cid:54)= 0.

Let σ2

k denote the variance of δk; k = 1, 2, , . . . , m. We assume that all noise variables have
equal variances, i.e., σk = σ. This condition implies the identiﬁability of DAGs from Gaussian [33]
and non-Gaussian [25] data. Under this condition, the negative log likelihood for linear SEMs with
Gaussian or non-Gaussian noise is proportional to

ln(β) =

1
2

tr{(I − B)(I − B)T S},

(4)

where S = X T X and I is the identity matrix [25].

In practice, we are often interested in learning sparse DAGs. Thus, a regularization term is used
to obtain a sparse estimate. For the linear SEM (2), the optimization problem corresponding to
the penalized negative log-likelihood with super-structure M (PNLM) for learning sparse DAGs
is given by

PNLM min

B∈Rm×m

ln(β) + λφ(B),

s.t., G(B) induces a DAG from

−→
M.

(5a)

(5b)

The objective function (5a) consists of two parts: the quadratic loss function, ln(β), from (4),
and the regularization term, φ(B). Popular choices for φ(B) include (cid:96)1-regularization or lasso
[40], φ(B) = (cid:80)
E 1(βjk), where 1(βjk) = 1
−→
if βjk (cid:54)= 0, and 0 otherwise. The tuning parameter λ controls the degree of regularization. The
constraint (5b) stipulates that the resulting directed subgraph (digraph) has to be an induced DAG
from

(j,k)∈E→ |βjk|, and (cid:96)0-regularization, φ(B) = (cid:80)

−→
M.

(j,k)∈

When the super-structure M is a complete graph, PNLM reduces to the classical PNL. In
this case, the consistency of sparse PNL for DAG learning from Gaussian data with an (cid:96)0 penalty
follows from an analysis similar to [41]. In particular, we have

pr( ˆGn = G0) → 1

(n → ∞),

where ˆGn is the estimate of the true structure G0. An important advantage of the PNL estimation
problem is that its consistency does not require the (strong) faithfulness assumption [33, 41].

The mathematical model (5) incorporates a super-structure M (e.g., moral graph) into the
PNL model. When M is the moral graph, the consistency of sparse PNLM follows from the
analysis in [25], which studies the consistency of the following two-stage framework for estimating
sparse DAGs: (1) infer the moral graph from the support of the inverse covariance matrix; and (2)
choose the best-scoring induced DAG from the moral graph. The authors investigate conditions for
identiﬁability of the underlying DAG from observational data and establish the consistency of the
two-stage framework.

While PNL and PNLM enjoy desirable statistical properties for linear SEMs with Gaussian [41]
and non-Gaussian [25] noise, the computational challenges associated with these problems have not
been fully addressed. This paper aims to bridge this gap.

5

Figure 1: A super-structure graph M (left) and a tournament (right) with six nodes which does
not contain any cycles.

3 Mathematical Formulations

Prior to presenting mathematical formulations for solving PNLM, we discuss a property of DAG
learning from continuous data that distinguishes it from the corresponding problem for discrete
data. To present this property in Proposition 1, we need a new deﬁnition.

Deﬁnition 1. A tournament is a directed graph obtained by specifying a direction for each edge
in the super-structure graph M (see Figure 1).

Proposition 1. There exists an optimal solution G(B) to PNLM (5) with an (cid:96)0 (or an (cid:96)1) regu-
larization that is a cycle-free tournament.

All proofs are given in Appendix I. Proposition 1 implies that for DAG learning from continuous
variables, the search space reduces to acyclic tournament structures. This is a far smaller search
space when compared with the super-exponential O
search space of DAGs for discrete
variables. However, one has to also identify the optimal β parameters. This search for optimal β
parameters is critical, as it further reduces the super-structure to the edges of the DAG by removing
the edges with zero β coeﬃcients.

m!2(m

2 )(cid:17)

(cid:16)

A solution method based on brute force enumeration of all tournaments requires m!γ computa-
tional time when M is complete, where γ denotes the computational time associated with solving
PNLM given a known tournament structure. This is because when M is complete, the total num-
ber of tournaments (equivalently the total number of permutations) is m!. However, when M is
incomplete, the number of DAGs is fewer than m!. The topological search space is m! regardless
of the structure of M and several topological orderings can correspond to the same DAG. The TO
formulation [29] is based on this search space. In Section 3.2, we discuss a search space based on
the layering of a DAG, which uniquely identiﬁes a DAG, and propose the corresponding Layered
Network (LN) formulation, which eﬀectively utilizes the structure of M. We ﬁrst discuss existing
mathematical formulations for the PNLM optimization problem (5) in the next section. Given
the desirable statistical properties of (cid:96)0 regularization [41] and the fact that existing mathematical
formulations are given for (cid:96)1 regularization, we present the formulations for (cid:96)0 regularization. We
outline the necessary notation below.

6

123456123456Indices
V = {1, 2, . . . , m}: index set of random variables
D = {1, 2, . . . , n}: index set of samples

−→
E ): the bi-directional graph corresponding to the undirected graph M

Input
M = (V, E): an undirected super-structure graph (e.g., the moral graph)
−→
M = (V,
X = (X1, . . . , Xm), where Xv = (x1v, x2v, . . . , xnv)(cid:62) and xdv denotes dth sample (d ∈ D) of random
variable Xv
λ : tuning parameter (penalty coeﬃcient)

Continuous optimization variables
βjk: weight of arc (j, k) representing the regression coeﬃcients ∀(j, k) ∈

−→
E

Binary optimization variables
zjk = 1 if arc (j, k) exists in a DAG; otherwise 0, ∀(j, k) ∈
gjk = 1 if βjk (cid:54)= 0; otherwise 0, ∀(j, k) ∈

−→
E

−→
E

3.1 Existing Mathematical Models

The main source of diﬃculty in solving PNLM is due to the acyclic nature of DAG imposed by
the constraint in (5b). A popular technique for ensuring acyclicity is to use cycle elimination
constraints, which were ﬁrst introduced in the context of the Traveling Salesman Problem (TSP)
in [11].

Let C be the set of all possible cycles and CA ∈ C be the set of arcs deﬁning a cycle and deﬁne
(cid:17)2
E gjk. Then, the (cid:96)0-PNLM model
−→

E βjkxdj
−→

xdk −(cid:80)

+λ (cid:80)

(j,k)∈

(j,k)∈

d∈D

(cid:80)

(cid:16)

F (β, g) := n−1 (cid:80)
k∈V
can be formulated as

(cid:96)0-CP min F (β, g)

− M gjk ≤ βjk ≤ M gjk, ∀(j, k) ∈

−→
E ,

(cid:88)

(j,k)∈ CA

gjk ≤ |CA| − 1,

∀CA ∈ C,

gjk ∈ {0, 1},

∀(j, k) ∈

−→
E .

(6a)

(6b)

(6c)

(6d)

Following [29], the objective function (6a) is an expanded version of ln(β) in PNLM (multiplied
by 2n−1) with an (cid:96)0 regularization. The constraints in (6b) stipulate that βjk (cid:54)= 0 only if zjk = 1,
where M is a suﬃciently large constant. The constraints in (6c) rule out all cycles. Note that for
|CA| = 2, constraints in (6c) ensure that at most one arc exists among two nodes. The last set of
constraints speciﬁes the binary nature of the decision vector g. Note that β variables are continuous
and unrestricted; however, in typical applications, they can be bounded by a ﬁnite number M . This
−→
formulation requires |
E | binary variables and an exponential number of constraints. A cutting plane
method [28] that adds the cycle elimination inequalities as needed is often used to solve this problem.
We refer to this formulation as the cutting plane (CP) formulation.

7

Remark 1. For a complete super-structure M, it suﬃces to impose the set of constraints in (6c)
only for cycles of size 2 and 3 given by

gij + gjk + gki ≤ 2, ∀i, j, k ∈ V, i (cid:54)= j (cid:54)= k,
gjk + gkj ≤ 1, ∀j, k ∈ V, j (cid:54)= k.

In other words, the CP formulation (both with (cid:96)0 and (cid:96)1 regularizations) needs a polynomial number
of constraints for complete super-structure M.

The second formulation is based on a well-known combinatorial optimization problem, known as
linear ordering (LO) [16]. Given a ﬁnite set S with q elements, a linear ordering of S is a permutation
P ∈ Sq where Sq denotes the set of all permutations with q elements. In the LO problem, the goal
is to identify the best permutation among m nodes. The “cost” for a permutation P depends on the
order of the elements in a pairwise fashion. Let pj denote the order of node j ∈ V in permutation
P. Then, for two nodes j, k ∈ {1, . . . , m}, the cost is cjk if the order of node j precedes the order of
node k (pj ≺ pk) and is ckj otherwise (pj (cid:31) pk). A binary variable wjk indicates whether pj ≺ pk.
(cid:1) variables to cast the LO problem as an IP
Because wjk + wkj = 1 and wjj = 0, one only needs (cid:0)m
formulation [16].

2

The LO formulation for DAG learning from continuous data has two noticeable diﬀerences com-
pared with the classical LO problem: (i) the objective function is quadratic, and (ii) an additional
set of continuous variables, i.e., βs, is added. Cycles are ruled out by directly imposing the linear
ordering constraints. The PNLM can be formulated as (8).

(cid:96)0-LO min F (β, g),

− M gjk ≤ βjk ≤ M gjk, ∀(j, k) ∈

−→
E ,
−→
E ,

gjk ≤ wjk,
wjk + wkj = 1,
wij + wjk + wki ≤ 2,
wjk ∈ {0, 1},

gjk ∈ {0, 1},

∀(j, k) ∈
∀j, k ∈ V, j (cid:54)= k,
∀i, j, k ∈ V, i (cid:54)= j (cid:54)= k,
∀j, k ∈ V, j (cid:54)= k,

∀(j, k) ∈

−→
E .

(8a)

(8b)

(8c)

(8d)

(8e)

(8f)

(8g)

The interpretation of constraints (8b)-(8d) is straightforward. The constraints in (8c) imply that if
node j appears after node k in a linear ordering (wjk = 0), then there should not exist an arc from
j to k (gjk = 0). The set of inequalities (8e) implies that if pi ≺ pj and pj ≺ pk, then pi ≺ pk. This
ensures the linear ordering of nodes and removes cycles.

The third approach for ruling out cycles is to impose a set of constraints such that the nodes
follow a topological ordering. A topological ordering is a linear ordering of the nodes of a graph
such that the graph contains an arc (j, k) if node j appears before node k in the linear order. Deﬁne
decision variables ors ∈ {0, 1} for all r, s ∈ {1, . . . , m}. This variable takes value 1 if topological
order of node r (i.e., pr) equals s, and 0, otherwise. If a topological ordering is known, the DAG
structure can be eﬃciently learned in polynomial time [35], but the problem remains challenging
when the ordering is not known. The topological ordering prevents cycles in the graph. This
property is used in [29] to model the problem of learning a DAG with (cid:96)1 regularization. We extend

8

2

2

3

1

3

1

4

(a)

4

(b)

Figure 2: The role of the binary decision variables in (cid:96)0 regularization: Using z (instead of g) in
the objective function creates a graph similar to (b) and counts the number of arcs instead of the
number of non-zero βs in (b).

their formulation to (cid:96)0 regularization. The topological ordering (TO) formulation is given by

(cid:96)0-TO min F (β, g),

− M gjk ≤ βjk ≤ M gjk,

∀(j, k) ∈

∀(j, k) ∈

∀(j, k) ∈

−→
E ,
−→
E ,
−→
E ,
−→
E ,

s (oks − ojs), ∀(j, k) ∈

gjk ≤ zjk,

zjk + zkj ≤ 1,

zjk − mzkj ≤

(cid:88)

s∈V

(cid:88)

s∈V
(cid:88)

r∈V

ors = 1,

ors = 1,

zjk ∈ {0, 1},
ors ∈ {0, 1},

gjk ∈ {0, 1},

∀r ∈ V,

∀s ∈ V,

−→
∀(j, k) ∈
E ,
∀ r, s ∈ {1, 2, . . . , m},
−→
E .

∀(j, k) ∈

(9a)

(9b)

(9c)

(9d)

(9e)

(9f)

(9g)

(9h)

(9i)

(9j)

In this formulation, zjk is an auxiliary binary variable which takes value 1 if an arc exists from
node j to node k. Recall that, gjk = 1 if |βjk| > 0. The constraints in (9c) enforce the correct
link between gjk and zjk, i.e., gjk has to take value zero if zjk = 0. The constraints in (9d) imply
that there should not exist a bi-directional arc among two nodes. This inequality can be replaced
with equality (Corollary 1). The constraints in (9e) remove cycles by imposing an ordering among
nodes. The set of constraints in (9f)-(9g) assigns a unique topological order to each node. The last
two sets of constraints indicate the binary nature of decision variables o and z.

9

Corollary 1, which is a direct consequence of Proposition 1, implies that we can use zjk = 1−zkj

for all j < k and reduce the number of binary variables.

Corollary 1. The constraints in (9d) can be replaced by zjk + zkj = 1, ∀(j, k) ∈

−→
E .

−→
E and zjk = 1 for (j, k) ∈

s∈V s(ojs −ois) ≥ 1; similarly, zjk = 1 implies (cid:80)

In constraints (9b)-(9i), both variables z and g are needed to correctly model the (cid:96)0 regularization
term in the objective function (see Figure 2a). This is because the constraints (9e) satisfy the
−→
E ,
transitivity property: if zij = 1 for (i, j) ∈
since zij = 1 implies that (cid:80)
s∈V s (oks −ojs) ≥ 1. If
we sum both inequalities, we have (cid:80)
s∈V s (oks−ois) ≥ 2, which enforces zik = 1. Such a transitivity
relation, however, need not hold for the decision vector g. In other words, the decision variable gjk
is used to keep track of the number of non-zero weights βjk associated with the arc (j, k), and the
decision vector z is used to remove cycles via the set of constraints in (9e) by creating an acyclic
tournament on the super-structure M. A tournament on super-structure M assigns a direction
for each edge in an undirected super-structure M. In other words, if we were to let gij = zij for
−→
E and hence use the decision variable z in the objective, then we would be counting the
(i, j) ∈
number of edges, equal to |E|, instead of number of non-zero β values.

−→
E , then zik = 1 for (i, k) ∈

3.2 A New Mathematical Model: The Layered Network (LN) Formula-

tion

As an alternative to the existing mathematical formulations, we propose a new formulation for
imposing acyclicity constraints that is motivated by the layering of nodes in DAGs [18]. More
speciﬁcally, our formulation ensures that the resulting graph is a layered network, in the sense that
there exists no arc from a layer v to layer u, where u < v. Let ψk be the layer value for node k.
One may interpret ψk as (cid:80)m
s=1 s oks for all k ∈ V , where the variables oks are as deﬁned in the TO
formulation. However, note that the notion of ψk is more general because ψk need not be integer.
Figure 3 depicts the layered network encoding of a DAG. With this notation, our layered network
(LN) formulation can be written as

min F (β, g),

− M gjk ≤ βjk ≤ M gjk,

gjk ≤ zjk,

zjk + zkj = 1,

∀(j, k) ∈

∀(j, k) ∈

∀(j, k) ∈

zjk − (m − 1)zkj ≤ ψk − ψj, ∀(j, k) ∈

zjk ∈ {0, 1},
1 ≤ ψk ≤ m,

gjk ∈ {0, 1},

∀(j, k) ∈
∀k ∈ V,

∀(j, k) ∈

−→
E ,
−→
E ,
−→
E ,
−→
E ,
−→
E ,

−→
E .

(10a)

(10b)

(10c)

(10d)

(10e)

(10f)

(10g)

(10h)

The interpretation of the constraints (10b)-(10c) is straightforward. The constraints in (10e)
ensure that the graph is a layered network. The last set of constraints indicates the continuous
nature of the decision variable ψ and gives the tightest valid bound for ψ. It suﬃces to consider
any real number for layer values ψ as long as layer values of any two nodes diﬀer by at least one if

10

Figure 3: Layered Network encoding of a DAG.

there exists an arc between them. Additionally, LN uses a tighter inequality compared to TO, by
replacing m with parameter m − 1 in (10e). This is because the diﬀerence between the layer values
of two nodes can be at most m − 1 for a DAG with m nodes. The next proposition establishes the
validity of the LN formulation.

Proposition 2. An optimal solution to (10) is an optimal solution to (5).

The LN formulation highlights a desirable property of the layered network representation of a
DAG in comparison to the topological ordering representation. Let us deﬁne nodes in layer 1 as
the set of nodes that have no incoming arcs in the DAG, nodes in layer 2 as the set of nodes that
have incoming arcs only from nodes in the layer 1, layer 3 as the set of nodes that have incoming
arcs from layer 2 (and possibly layer 1), etc. (see Figure 3). The minimal layer number of a node
is the length of the longest directed path from any node in layer 1 to that node. For a given DAG,
there is a unique minimal layer number, but not a unique topological order. As an example, Figure
2a has three valid topological orders: (i) 1,2,4,3, (ii) 1,4,2,3, and (iii) 4,1,2,3. In contrast, it has a
unique layer representation, 1,2,3,1.

There is a one-to-one correspondence between minimal layer numbering and a DAG. However,
the solutions of the LN formulation, i.e., ψ variables (layer values), do not necessarily correspond
to the minimal layer numbering. This is because the LN formulation does not impose additional
constraints to enforce a minimal numbering and can output solutions that are not minimally num-
bered. However, because branch-and-bound does not branch on continuous variables, alternative
(non-minimal) feasible solutions for the ψ variables do not impact the branch-and-bound process.
On the contrary, we have multiple possible representations of the same DAG with topological or-
dering. Because topological ordering variables are binary, the branch-and-bound method applied
to the TO formulation explores multiple identical DAGs as it branches on the topological ordering
variables. This enlarges the size of the branch-and-bound tree and increases the computational
burden.

Layered network representation also has an important practical implication: Using this repre-
sentation, the search space can be reduced to the total number of ways we can layer a network (or
equivalently the total number of possible minimal layer numberings) instead of the total number of

11

layer#2layer#1layer#3Table 1: The number of binary variables and the number of constraints

Incomplete (moral) M

Complete (moral) M

# Binary Vars ((cid:96)0)

CP
−→
E |
|

LO
−→
E | + (cid:0)m
|
2

TO

LN

(cid:1) m2 + |E| + |

−→
E |

|E| + |

−→
E |

# Binary Vars ((cid:96)1)

|E|

# Constraints

(both (cid:96)0 and (cid:96)1)

Exp

(cid:1)

(cid:0)m
2

(cid:1)
2(cid:0)m
3

m2 + |E|

−→
E | + 2m
|

|E|

−→
E |
|

CP
2(cid:0)m
2

(cid:1)

(cid:1)

(cid:0)m
2

LO
(cid:1)
(cid:0)m
2

(cid:1)

(cid:0)m
2

TO
(cid:1)
m2 + 3(cid:0)m
2

m2 + (cid:0)m
2

(cid:1)

LN
(cid:1)
3(cid:0)m
2

(cid:1)

(cid:0)m
2

(cid:1)

2(cid:0)m
3

(cid:1)

2(cid:0)m
3

(cid:0)m
2

(cid:1) + 2m

(cid:1)

(cid:0)m
2

topological orderings. When the super-structure M is complete, both quantities are the same, and
equal to m!. Otherwise, a brute-force search for ﬁnding the optimal DAG has computational time
Lγ, where L denotes the total number of minimal layered numberings, and γ is the computational
complexity of solving PNLM given a known tournament structure.

We close this section by noting that a set of constraints similar to (10e) was introduced in [7]
for learning pedigree. However, the formulation in [7] requires an exponential number of variables.
In more recent work on DAGs for discrete data, Cussens and colleagues have focused on a tighter
formulation for removing cycles, known as cluster constraints [8, 9, 10]. To represent the set of
cluster constraints, variables have to be deﬁned according to the parent set choice leading to an
exponential number of variables. Thus, such a representation is not available in the space of arcs.

3.2.1 Layered Network with (cid:96)1 regularization

Because of its convexity, the structure learning literature has utilized the (cid:96)1-regularization for learn-
ing DAGs from continuous variables [17, 29, 35, 42, 46]. The LN formulation with (cid:96)1-regularization
can be written as

min

1
n

(cid:88)

(cid:88)

(xik −

(cid:88)

βjkxij)2 + λ

(cid:88)

|βjk|,

i∈I

k∈V

(j,k)∈E→

(j,k)∈

−→
E

− M zjk ≤ βjk ≤ M zjk
(10e) − (10g).

∀(j, k) ∈

−→
E ,

(11a)

(11b)

Remark 2. For a complete super-structure M, ψk = (cid:80)
(both (cid:96)0 and (cid:96)1) can be encoded without ψ variables by writing (10e) as

j∈V \k zjk ∀k ∈ V . Thus, the LN formulations

zjk − (m − 1)zkj ≤

(cid:88)

zjk −

(cid:88)

j∈V \k

k∈V \j

zkj ∀ j, k ∈ V

j (cid:54)= k.

Remark 3. CP and LO formulations reduce to the same formulation for (cid:96)1 regularization when the
super-structure M is complete by letting wij = gij in formulation (8) for all (j, k) ∈

−→
E .

An advantage of the (cid:96)1-regularization for DAG learning is that all models (CP, LO, TO and
LN) can be formulated without decision variables gjk, since counting the number of non-zero βjk
is no longer necessary.

Table 1 shows the number of binary variables and the number of constraints associated with
cycle prevention constraints in each model. Evidently, (cid:96)0 models require additional binary variables

12

•

•

•
•

•

•

•

•
•

•
•

•
•

•

•

•
•

•
•
•

•
•

•

•

•

•

•

•

Figure 4: Continuous relaxation regions of three IP models. The tightest model (convex hull)
is represented by the black polygon strictly inside other polygons. The blue and red polygons
represent valid yet weaker formulations. The black points show the feasible integer points for all
three formulations.

compared to the corresponding (cid:96)1 models. Note that the number of binary variables and constraints
for the LN formulation solely depend on the number of edges in the super-structure M. This
property is particularly desirable when the super-structure M is sparse. The LN formulation requires
the fewest number of constraints among all models. The LN formulation also requires fewer binary
variables than the TO formulation. More importantly, diﬀerent topological orders for the same
DAG are symmetric solutions to the associated TO formulation. Consequently, branch-and-bound
requires exploring multiple symmetric formulations as it branches on fractional TO variables. As
for the LO formulation, the number of constraints is O(m3) which makes its continuous relaxation
cumbersome to solve in the branch-and-bound process. The LN formulation is compact, whereas the
CP formulation requires an exponential number of constraints for incomplete super-structure M.
The CP formulation requires fewer binary variables for (cid:96)0 formulation than LN; both formulations
need the least number of binary variables for (cid:96)1 regularization.

In the next section, we discuss the theoretical strength of these mathematical formulations and
provide a key insight on why the LN formulation performs well for learning DAGs from continuous
data.

4 Continuous Relaxation

One of the fundamental concepts in IP is relaxations, wherein some or all constraints of a prob-
lem are loosened. Relaxations are often used to obtain a sequence of easier problems which can
be solved eﬃciently yielding bounds and approximate, not necessarily feasible, solutions for the
original problem. Continuous relaxation is a common relaxation obtained by relaxing the binary
variables of the original mixed-integer quadratic program (MIQP) and allowing them to take real
values. Continuous relaxation is at the heart of branch-and-bound methods for solving MIQPs. An
important concept when comparing diﬀerent MIQP formulations is the strength of their continuous
relaxations.

Deﬁnition 2. A formulation A is said to be stronger than formulation B if R(A) ⊂ R(B) where
R(A) and R(B) correspond to the feasible regions of continuous relaxations of A and B, respectively.

13

Proposition 3. The LO formulation is stronger than the LN formulation, that is,
R(LO) ⊂ R(LN ).

Proposition 4. When the parameter m in (9e) is replaced with m − 1, the TO formulation is
stronger than the LN formulation, that is, R(T O) ⊂ R(LN ).

These propositions are somewhat expected because the LN formulation uses the fewest number
of constraints. Hence, the continuous relaxation feasible region of the LN formulation is loos-
ened compared to the other formulations. The next two results justify the advantages of the LN
formulation.

−→
Proposition 5. Let β(cid:63)
E from (5).
For both (cid:96)0 and (cid:96)1 regularizations, the initial continuous relaxations of the LN formulation attain
jk|.
as tight an optimal objective function value as the LO, CP, TO formulations if M ≥ 2 max
−→
E
(j,k)∈

jk denote the optimal coeﬃcient associated with an arc (j, k) ∈

|β(cid:63)

Proposition 5 states that although the LO and TO formulations are tighter than the LN formu-
lation with respect to the feasible region of their continuous relaxations, the continuous relaxation
of all models attain the same objective function value (root relaxation).

Proposition 6. For the same variable branching in the branch-and-bound process, the continuous
relaxations of the LN formulation for both (cid:96)0 and (cid:96)1 regularizations attain as tight an optimal
objective function value as LO, CP and TO, if M ≥ 2 max
−→
E
(j,k)∈

jk|.

|β(cid:63)

Proposition 6 is at the crux of this section. It shows that not only does the tightness of the
optimal objective function value of the continuous relaxation hold for the root relaxation, but it
also holds throughout the branch-and-bound process under the speciﬁed condition on M , if the
same branching choices are made. Thus, the advantages of the LN formulation are due to the fact
that it is a compact formulation that entails the fewest number of constraints, while attaining the
same optimal objective value of continuous relaxation as tighter models.

In practice, ﬁnding a tight value for M is diﬃcult. Our computational results show that the
approach suggested in [29] to obtain a value of M , which is explained in Section 5 and used in
our computational experiments, always satisﬁes the condition in Proposition 6 across all generated
instances.

5 Comparison of MIQP Formulations

We present numerical results comparing the proposed LN formulation with existing approaches.
Experiments are performed on a cluster operating on UNIX with Intel Xeon E5-2640v4 2.4GHz.
All MIQP formulations are implemented in the Python programming language. Gurobi 8.0 is used
as the MIQP solver. A time limit of 50m (in seconds), where m denotes the number of nodes, is
imposed across all experiments after which runs are aborted. Unless otherwise stated, an MIQP
optimality gap of 0.001 is imposed across all experiments; the gap is calculated by U B−LB
U B where
UB denotes the objective value associated with the best feasible integer solution (incumbent) and
LB represents the best obtained lower bound during the branch-and-bound process.

For CP, instead of incorporating all constraints given by (6c), we begin with no constraint
of type (6c). Given an integer solution with cycles, we detect a cycle and impose a new cycle

14

prevention constraint to remove the detected cycle. Depth First Search (DFS) can detect a cycle in
a directed graph with complexity O(|V | + |E|). Gurobi Lazy Callback is used, which allows adding
cycle prevention constraints in the branch-and-bound algorithm, whenever an integer solution with
cycles is found. The same approach is used by [29]. Note that Gurobi solver follows a branch-and-cut
implementation and adds many general-purpose and special-purpose cutting planes.

To select the M parameter in all formulations we use the proposal of [29]. Speciﬁcally, given
λ, we solve each problem without cycle prevention constraints. We then use the upper bound
|βjk|. The results provided in [29] computationally conﬁrm that this approach gives a
M = 2 max
−→
E
(j,k)∈

large enough value of M . We also conﬁrmed the validity of this choice across all our test instances.

5.1 Synthetic datasets

We use the R package pcalg to generate random Erd˝os-R´enyi graphs. Firstly, we create a DAG
using randomDAG function and assign random arc weights (i.e., β) from a uniform distribution,
U[0.1, 1]. This ground truth DAG is used to assess the quality of estimates. Next, the resulting
DAG and random coeﬃcients are input to the rmvDAG function, which uses linear regression as the
underlying model, to generate multivariate data (columns of matrix X ) with the standard normal
error distribution.

We consider m ∈ {10, 20, 30, 40} nodes and n ∈ {100, 1000} samples. The average outgoing
degree of each node, denoted by d, is set to 2. We generate 10 random graphs for each setting (m,
n, d). The raw observational data, X , for the datasets with n = 100 is the same as ﬁrst 100 rows
of the datasets with n = 1000.

We consider two types of problem instances: (i) a set of instances for which the moral graph
corresponding to the true DAG is available; (ii) a set of instances with a complete undirected graph,
i.e., assuming no prior knowledge. The ﬁrst class of problems is referred to as moral instances,
whereas the second class is called complete instances. The raw observational data, X , for moral
and complete instances are the same. The function moralize(graph) in the pcalg R-package is
used to generated the moral graph from the true DAG. The moral graph can also be (consistently)
estimated from data using penalized estimation procedures with polynomial complexity [20, 25].
However, since the quality of the moral graph equally aﬀects all optimization models, the true moral
graph is used in our experiments.

We use the following IP-based metrics to measure the quality of a solution: Optimality gap
(MIQP GAP), computation time in seconds (Time), Upper Bound (UB), Lower Bound (LB), com-
putational time of root continuous relaxation (Time LP), and the number of explored nodes in the
branch-and-bound tree.

We also evaluate the quality of the estimated DAGs by comparing them with the ground truth.
To this end, we use the average structural Hamming distance (SHD), as well as true positive
(TPR) and false positive rates (FPR). These criteria evaluate diﬀerent aspects of the quality of
the estimated DAGs: SHD counts the number of diﬀerences (addition, deletion, or arc reversal)
required to transform predicted DAG to the true DAG; TPR is the number of correctly identiﬁed
arcs divided by the total number of true arcs, P ; FPR is the number of incorrectly identiﬁed arcs
divided by the total number of negatives (non-existing arcs), N . For brevity, TPR and FPR plots
are presented in Appendix II.

15

5.2 Comparison of (cid:96)0 formulations

Figure 5 reports the average metrics across 10 random graphs for (cid:96)0 formulations with n = 1000.
The LO formulation fails to attain a reasonable solution for one graph (out of 10) with m = 40 and
λ ∈ {0.1, 1}. This is due to the large computation time for solving its continuous relaxation. We
excluded these two instances from LO results.

Figure 5(a) shows that the LN formulation outperforms other formulations in terms of the av-
erage optimality gap across all number of nodes m ∈ {10, 20, 30, 40} and regularization parameters,
λ ∈ {0.1, 1}. The diﬀerence becomes more pronounced for moral instances. For moral instances,
the number of binary variables and constraints for LN solely depends on the size of moral graph.
Figure 5(b) also indicates that the LN formulation requires the least computational time for small
instances, whereas all models hit the time limit for larger instances.

Figures 5(c)-(d) show the performance of all methods in terms of their upper and lower bounds.
For easier instances (e.g., complete instances with m ∈ {10, 20} and moral instances), all methods
attain almost the same upper bound. Nonetheless, LN performs better in terms of improving the
lower bound. For more diﬃcult instances, LN outperforms other methods in terms of attaining a
smaller upper bound (feasible solution) and a larger lower bound.

Figures 5(e)-(f) show the continuous relaxation time of all models, and the number of explored
nodes in the branch-and-bound tree, respectively. The fastest computational time for the continuous
relaxation is for the TO formulation followed by the LN formulation. However, the number of
explored nodes provides more information about the performance of mathematical formulations.
In small instances, i.e., m = 10, where an optimal solution is attained, the size of the branch-and-
bound tree for the LN formulation is smaller than the TO formulation. This is because the TO
formulation has a larger number of binary variables, leading to a larger branch-and-bound tree.
On the other hand, for large instances, the number of explored nodes in the LN formulation is
larger than the TO formulation. This implies that the LN formulation explores more nodes in the
branch-and-bound tree given a time limit. This may be because continuous relaxations of the LN
formulation are easier to solve in comparison to the continuous relaxations of the TO formulation in
the branch-and-bound process. As stated earlier, the branch-and-bound algorithm needs to explore
multiple symmetric formulations in the TO formulation as it branches on fractional topological
ordering variables. This degrades the performance of the TO formulation. The LO formulation
is very slow because its continuous relaxation becomes cumbersome as the number of nodes, m,
increases. Thus, we can see a substantial decrease in the number of explored nodes in branch-
and-bound trees associated with the LO formulation. The CP formulation is implemented in a
cutting-plane fashion. Hence, its number of explored nodes is not directly comparable with other
formulations.

Figures 5(a)-(f) show the importance of incorporating available structural knowledge (e.g., moral
graph). The average optimality gap and computational time are substantially lower for moral
instances compared to complete instances. Moreover, the substantial diﬀerence in the optimality
gap elucidates the importance of incorporating structural knowledge. Similar results are obtained
for n = 100 samples; see Appendix II.

We next discuss the performance of diﬀerent methods in terms of estimating the true DAG.
The choice of tuning parameter λ, the number of samples n, and the quality of the best feasible
solution (i.e., upper bound) inﬂuence the resulting DAG. Because our focus in this paper is on
computational aspects, we ﬁxed the values of λ for a fair comparison between the formulations, and
used λ = 0.1 based on results in preliminary experiments. Thus, we focus on the impact of sample
size as well as the quality of the feasible solution in the explanation of our results.

16

Figures 6(a)-(b) show the SHDs for all formulations for n = 1000 and n = 100, respectively.
Comparing Figure 6(a) with Figure 6(b), we observe that the SHD tends to increase as the number
of samples decreases. As discussed earlier, when n → ∞, penalized likelihood likelihood estimate
with an (cid:96)0 regularization ensures identiﬁability in our setting [33, 41]. However, for a ﬁnite sample
size, identiﬁability may not be guaranteed. Moreover, the appropriate choice of λ for n = 100 may
be diﬀerent than the corresponding λ for n = 1000.

Figure 6(a) shows that all methods learn the true DAG with λ = 0.1, and given a moral graph
In addition, SHD is negligible for LN and CP formulations for m = 40.
for m ∈ {10, 20, 30}.
However, we observe a substantial increase in SHD (e.g., from 0.2 to near 10 for LN) for complete
graphs. These ﬁgures indicate the importance of incorporating available structural knowledge (e.g.,
a moral graph) for better estimation of the true DAG.

While, in general, LN performs well compared with other formulations, we do not expect to
see a clear dominance in terms of accuracy of DAG estimation either due to ﬁnite samples or the
fact that none of the methods could attain a global optimal solution for larger instances. On the
contrary, we retrieve the true DAG for smaller graphs for which optimal solutions are obtained.
As pointed out in [29], a slight change in the objective function value could signiﬁcantly alter the
estimated DAG. Our results corroborate this observation.

5.3 Comparison of (cid:96)1 formulations

Figure 7 shows various average metrics across 10 random graphs for (cid:96)1 regularization with n = 1000
samples. Figure 7(a) shows that the LN formulation clearly outperforms other formulations in terms
of average optimality gap across all number of nodes, m ∈ {10, 20, 30, 40}, and regularization pa-
rameters, λ ∈ {0.1, 1}. Moreover, Figure 7(b) shows that the LN formulation requires signiﬁcantly
less computational time in moral instances, and in complete instances with m ∈ {10, 20} compared
to other methods. In complete instances, all methods hit the time limit for m ∈ {30, 40}. Fig-
ures 7(c)-(f) can be interpreted similar to the Figures 5(c)-(f) for (cid:96)0 regularization. Similar to (cid:96)0
regularization, Figures 7(a)-(b) demonstrate the importance of incorporating structural knowledge
(e.g., a moral graph) for (cid:96)1 regularization. Similar results are observed for n = 100 samples; see
Appendix II.

As expected, the DAG estimation accuracy with (cid:96)1 regularization is inferior to the (cid:96)0 regular-
ization. This is in part due to the bias associated with the (cid:96)1 regularization, which could be further
controlled with, for example, adaptive (cid:96)1-norm regularization [47]. Nonetheless, formulations for
(cid:96)1 regularization require less computational time and are easier to solve than the corresponding
formulations for (cid:96)0 regularization.

6 Comparison with the A(cid:63)-lasso algorithm

In this section, we compare the LN formulation with A(cid:63)-lasso [42], using the MATLAB code made
available by the authors. For this comparison, the same true DAG structures are taken from [42]
and the strength of arcs (β) are chosen from U[−1, −0.1] ∪ U[0.1, 1]. The number of nodes in the
10 true DAGs varies from m = 6 to m = 27 (see Table 2). The true DAG and resulting random β
coeﬃcients are used to generate n = 500 samples for each column of data matrix X .

A time limit of six hours is imposed across all experiments after which runs are aborted. In
addition, for a fairer comparison with A(cid:63)-lasso, we do not impose an MIQP gap termination criterion
of 0.001 for LN and use the Gurobi default optimality gap criterion of 0.0001.

17

(a) Optimality GAPs for MIQPs

(b) Time (in seconds) for MIQPs

(c) Best upper bounds for MIQPs

(d) Best lower bounds for MIQPs

(e) Time (in seconds) for continuous root relaxation

(f) Number of explored nodes in B&B tree

Figure 5: Optimization-based measures for MIQPs for (cid:96)0 regularization with the number of samples
n = 1000.

18

0.000.050.100.150.200.25Optimality GAP (MIP GAP)Moral  =1.00.00.10.20.30.4Complete  =1.010203040Number of nodes0.000.050.100.15Optimality GAP (MIP GAP)=0.110203040Number of nodes0.00.10.20.30.4=0.10500100015002000Time (seconds)Moral  =1.00500100015002000Complete  =1.010203040Number of nodes0500100015002000Time (seconds)=0.110203040Number of nodes0500100015002000=0.1020406080Upper BoundMoral  =1.0020406080Complete  =1.010203040Number of nodes010203040Upper Bound=0.110203040Number of nodes0102030405060=0.1020406080Lower BoundMoral  =1.00102030405060Complete  =1.010203040Number of nodes010203040Lower Bound=0.110203040Number of nodes0102030=0.1LNTOCPLO0500100015002000Time (seconds)Moral  =1.00500100015002000Complete  =1.010203040Number of nodes0500100015002000Time (seconds)=0.110203040Number of nodes0500100015002000=0.101000000200000030000004000000Number of Nodes in B&BMoral  =1.002000004000006000008000001000000Complete  =1.010203040Number of nodes05000001000000150000020000002500000Number of Nodes in B&B=0.110203040Number of nodes0200000400000600000=0.1LNTOCPLO(a) n = 1000

(b) n = 100

Figure 6: Structural Hamming Distance (SHD) of MIQP estimates with (cid:96)0 regularization.

Similar to synthetic data described in Section 5.1, we consider two cases: (i) moral instances
and (ii) complete instances. For the former case, the moral graph is constructed from the true DAG
as done in Section 5.1. The raw observational data (i.e., X ) for moral and complete instances are
the same.

We compare the LN formulation with A(cid:63)-lasso using (cid:96)1 regularization. Note that A(cid:63)-lasso cannot
solve the model with (cid:96)0 regularization. Furthermore, the original A(cid:63)-lasso algorithm assumes no
super-structure. Therefore, to enhance its performance, we modiﬁed the MATLAB code for A(cid:63)-
lasso in order to incorporate the moral graph structure, when available. We consider two values
for λ ∈ {0, 0.1} for our comparison. As λ decreases, identifying an optimal DAG becomes more
diﬃcult. Thus, it is of interest to evaluate the computational performance of both methods for
λ = 0 (i.e., no regularization) to assess the performance of these approaches on diﬃcult cases (see,
e.g., the computational results in [46] and the statistical analysis in [25] for λ = 0). We note that
model selection methods (such as Bayesian Information Criterion [38]) can be used to identify the
best value of λ. However, in this section, our focus is to evaluate the computational performance
of these approaches for a given λ value.

Table 2 shows the solution times (in seconds) of A(cid:63)-lasso versus the LN formulation for com-
plete and moral instances. For the LN formulation, if the algorithm cannot prove optimality within
the 6-hour time limit, we stop the algorithm and report, in parentheses, the optimality gap at
termination. For complete instances with λ = 0, the results highlight that for small instances (up
to 14 nodes) A(cid:63)-algorithm performs better, whereas the LN formulation outperforms A(cid:63)-lasso for
larger instances. In particular, we see that the LN formulation attains the optimal solution for the
Cloud data set in 810.47 seconds and it obtains a feasible solution that is provably within 99.5%
of the optimal objective value for Funnel and Galaxy data sets. For moral instances, we observe
signiﬁcant improvement in the computational performance of the LN formulation, whereas the im-
provement in A(cid:63)-lasso is marginal in comparison. This observation highlights the fact that dynamic
programming-based approaches cannot eﬀectively utilize the super-structure knowledge, whereas
an IP-based approach, particularly the LN formulation, can signiﬁcantly reduce the computational
times. For instance, LN’s computational time for the Cloud data reduces from ∼ 810 seconds to less
than two seconds when the moral graph is provided. In contrast, the reduction in computational

19

051015Structural Hamming DistanceMoral  =1.0010203040Complete  =1.010203040Number of nodes0.000.250.500.751.001.25Structural Hamming Distance=0.110203040Number of nodes05101520=0.1LNTOCPLO051015Structural Hamming DistanceMoral  =1.0010203040Complete  =1.010203040Number of nodes0.000.250.500.751.001.25Structural Hamming Distance=0.110203040Number of nodes0204060=0.1LNTOCPLO(a) Optimality GAPs for MIQPs

(b) Time (in seconds) for MIQPs

(c) Best upper bounds for MIQPs

(d) Best lower bounds for MIQPs

(e) Time (in seconds) for continuous root relaxation

(f) Number of explored nodes in B&B tree

Figure 7: Optimization-based measures for MIQPs for (cid:96)1 regularization with the number of samples
n = 1000.

20

0.000.050.100.150.20Optimality GAP (MIP GAP)Moral  =1.00.000.050.100.150.20Complete  =1.010203040Number of nodes0.000.050.100.150.20Optimality GAP (MIP GAP)=0.110203040Number of nodes0.00.10.20.30.4=0.10500100015002000Time (seconds)Moral  =1.00500100015002000Complete  =1.010203040Number of nodes0500100015002000Time (seconds)=0.110203040Number of nodes0500100015002000=0.1020406080Upper BoundMoral  =1.0020406080Complete  =1.010203040Number of nodes010203040Upper Bound=0.110203040Number of nodes01020304050=0.1020406080Lower BoundMoral  =1.00204060Complete  =1.010203040Number of nodes010203040Lower Bound=0.110203040Number of nodes0102030=0.1LNTOCPLO0500100015002000Time (seconds)Moral  =1.00500100015002000Complete  =1.010203040Number of nodes0500100015002000Time (seconds)=0.110203040Number of nodes0500100015002000=0.105000100001500020000Number of Nodes in B&BMoral  =1.0050000100000150000200000Complete  =1.010203040Number of nodes0100000200000300000400000500000Number of Nodes in B&B=0.110203040Number of nodes050000100000150000200000250000=0.1LNTOCPLO(a) n = 1000 samples

(b) n = 100 samples

Figure 8: Structural Hamming Distance (SHD) of MIQP estimates with (cid:96)1 regularization.

time for A(cid:63)-algorithm with the moral graph is negligible. For λ = 0.1, the problem is easier to
solve. Nevertheless, LN performs well in comparison to A(cid:63)-lasso and the performance of the LN
formulation improves for moral instances.

For DAG learning from discrete data, an IP-based model (see e.g., [19]) outperforms A(cid:63) algo-
rithms when a cardinality constraint on the number of the parent set for each node is imposed; A(cid:63)
tends to perform better if such constraints are not enforced. This is mainly because an IP-based
model for discrete data requires an exponential number of variables which becomes cumbersome
if such cardinality constraints are not permitted. In contrast, for DAG learning from continuous
data with linear SEMs, our results show that an IP-based approach does not have such a limitation
because variables are encoded in the space of arcs (instead of parent sets). That is why LN performs
well even for complete instances (i.e., no restriction on the cardinality of parent set).

There are several fundamental advantages of IP-based modeling, particularly the LN formula-
tion, compared to A(cid:63)-lasso: (i) The variables in IP-based models (i.e., TO, LN, and CP) depend
on the super-structure. Therefore, these IP-based models can eﬀectively utilize the prior knowl-
edge to reduce the search space, whereas A(cid:63)-lasso cannot utilize the super-structure information
as eﬀectively. This is particularly important for the LN formulation, as the number of variables
and constraints depend only on the super-structure; (ii) all IP-based models can incorporate both
(cid:96)0 and (cid:96)1 regularizations, whereas A(cid:63)-lasso can solve the problem only with (cid:96)1 regularization; (iii)
all IP-based methods in general enjoy the versatility to incorporate a wide variety of structural
constraints, whereas A(cid:63)-lasso and dynamic programming approaches cannot accommodate many
structural assumptions. For instance, a modeler may prefer restricting the number of arcs in the
DAG, this is achievable by imposing a constraint on an IP-based model, whereas one cannot impose
such structural knowledge on A(cid:63)-lasso algorithm; (iv) A(cid:63)-lasso is based on dynamic programming;
therefore, one cannot abrupt the search with the aim of achieving a feasible solution. On the other
hand, one can impose a time limit or an optimality gap tolerance to stop the search process in a
branch-and-bound tree. The output is then a feasible solution to the problem, which provides an
upper bound as well as a lower bound which guarantees the quality of the feasible solution; (v)
algorithmic advances in integer optimization alone (such as faster continuous relaxation solution,
heuristics for better upper bounds, and cutting planes for better lower bounds) have resulted in

21

051015Structural Hamming DistanceMoral  =1.0020406080Complete  =1.010203040Number of nodes05101520Structural Hamming Distance=0.110203040Number of nodes050100150200250=0.1LNTOCPLO01234Structural Hamming DistanceMoral  =1.0020406080100Complete  =1.010203040Number of nodes0204060Structural Hamming Distance=0.110203040Number of nodes0100200300400=0.1LNTOCPLO(a) Factors dataset with complete graph

(b) Factor dataset with moral graph

Figure 9: The progress of upper bound versus lower bound in the branch-and-bound tree for the
LN formulation with no regularization (i.e., λ = 0).

29,000 factor speedup in solving IPs [4] using a branch-and-bound process. Many of these advances
have been implemented in powerful state-of-the-art optimization solvers (e.g., Gurobi), but they
cannot be used in dynamic programming methods, such as A(cid:63)-lasso.

Figures 9(a)-(b) illustrate the progress of upper bound versus lower bound in the branch-and-
bound process for the Factor dataset and highlight an important practical implication of an IP-
based model: such models often attain high quality upper bounds (i.e., feasible solutions) in a short
amount of time whereas the rest of the time is spent to close the optimality gap by increasing the
lower bound.

The results for the moral graph in Figure 9(b) highlight another important observation. That is,
providing the moral graph can signiﬁcantly accelerate the progress of the lower bound in the branch-
and-bound process. In other words, information from the moral graph helps close the optimality
gap more quickly.

Table 2: Computational performance of LN versus A(cid:63)-algorithm with (cid:96)1 regularization for λ ∈
{0, 0.1}

Graphs (Data sets) m |M|
dsep
Asia
Bowling
Insurancesmall
Rain
Cloud
Funnel
Galaxy
Insurance
Factors

16
40
36
76
70
58
62
76
168
310

6
8
9
15
14
16
18
20
27
27

Moral λ = 0

A(cid:63)-lasso LN
0.017
0.016
0.018
391
119.15
4433.29
6 hrs
6 hrs
6 hrs
6 hrs

0.378
0.401
0.554
2.719
1.752
1.421
1.291
1.739
131.741
6 hrs (.001)

Complete λ = 0

A(cid:63)-lasso LN
0.0261
0.152
0.467
547.171
101.33
18839
6 hrs
6 hrs
6 hrs
6 hrs

0.388
0.887
1.31
613.543
246.25
810.471
6 hrs (.002)
6 hrs (.005)
6 hrs (.162)
6 hrs (.081)

Moral λ = 0.1

A(cid:63)-lasso LN
0.455
0.195
0.417
2.694
51.737
1066.08
6 hrs
6 hrs
6 hours
6 hours

0.025
0.071
0.225
1.135
0.632
0.426
0.395
0.740
12.120
55.961

Complete λ = 0.1

A(cid:63)-lasso
0.429
0.191
0.489
3.048
69.404
2230.035
6 hrs
6 hrs
6 hrs
6 hrs

LN
0.108
0.319
0.291
0.531
3.502
7.249
3.478
9.615
6 hrs (.031)
6 hrs (.01)

22

0500010000150002000025000Time (in seconds)22.022.523.023.524.024.525.025.526.0Upper BoundLower Bound0500010000150002000025000Time (in seconds)24.525.025.526.026.5Upper BoundLower Bound7 Conclusion

In this paper, we study the problem of learning an optimal DAG from continuous observational
data using a score function, where the causal eﬀect among the random variables is linear. We cast
the problem as a mathematical program and use a penalized negative log-likelihood score function
with both (cid:96)0 and (cid:96)1 regularizations. The mathematical programming framework can naturally in-
corporate a wide range of structural assumptions. For instance, it can incorporate a super-structure
(e.g., skeleton or moral graph) in the form of an undirected and possibly cyclic graph. Such super-
structures can be estimated from observational data. We review three mathematical formulations:
cutting plane (CP), topological ordering (TO), and Linear Ordering (LO), and propose a new
mixed-integer quadratic optimization (MIQO) formulation, referred to as the layered network (LN)
formulation. We establish that the continuous relaxations of all models attain the same optimal
objective function value under a mild condition. Nonetheless, the LN formulation is a compact
formulation in contrast to CP, its relaxation can be solved much more eﬃciently compared to LO,
and enjoys a fewer number of binary variables and traces a fewer number of branch-and-bound
nodes than TO.

Our numerical experiments indicate that these advantages result in considerable improvement
in the performance of LN compared to other MIQP formulations (CP, LO, and TO). These im-
provements are particularly pronounced when a sparse super-structure is available, because LN is
the only formulation in which the number of constraints and binary variables solely depend on
the super-structure. Our numerical experiments also demonstrate that the LN formulation has
a number of advantages over the A(cid:63)-lasso algorithm, especially when a sparse super-structure is
available.

At least two future research avenues are worth exploring. First, one of the diﬃculties of esti-
mating DAGs using mathematical programming techniques is the constraints in (6b). The big-M
constraint is often very loose, which makes the convergence of branch-and-bound process slow. It is
of interest to study these constraints in order to improve the lower bounds obtained from continuous
relaxations. Second, in many real-world applications, the underlying DAG has special structures.
For instance, the true DAG may be a polytree [12]. Another example is a hierarchical structure. In
that case, it is natural to learn a DAG such that it satisﬁes the hierarchy among diﬀerent groups
of random variables. This problem has important applications in discovering the genetic basis of
complex diseases (e.g., asthma, diabetes, atherosclerosis).

References

[1] Bryon Aragam and Qing Zhou. Concave penalized estimation of sparse Gaussian Bayesian

networks. Journal of Machine Learning Research, 16:2273–2328, 2015.

[2] Mark Bartlett and James Cussens. Advances in Bayesian network learning using integer pro-

gramming. arXiv preprint arXiv:1309.6825, 2013.

[3] Mark Bartlett and James Cussens.

Integer linear programming for the Bayesian network

structure learning problem. Artiﬁcial Intelligence, 244:258–271, 2017.

[4] Dimitris Bertsimas, Angela King, Rahul Mazumder, et al. Best subset selection via a modern

optimization lens. The annals of statistics, 44(2):813–852, 2016.

23

[5] David Maxwell Chickering. Learning Bayesian networks is NP-complete.

In Learning from

data, pages 121–130. Springer, 1996.

[6] David Maxwell Chickering. Optimal structure identiﬁcation with greedy search. Journal of

machine learning research, 3(Nov):507–554, 2002.

[7] James Cussens. Maximum likelihood pedigree reconstruction using integer programming. In

WCB@ ICLP, pages 8–19, 2010.

[8] James Cussens.

Bayesian network learning with cutting planes.

arXiv preprint

arXiv:1202.3713, 2012.

[9] James Cussens, David Haws, and Milan Studen`y. Polyhedral aspects of score equivalence in
Bayesian network structure learning. Mathematical Programming, 164(1-2):285–324, 2017.

[10] James Cussens, Matti J¨arvisalo, Janne H Korhonen, and Mark Bartlett. Bayesian network
structure learning with integer programming: Polytopes, facets and complexity. J. Artif.
Intell. Res.(JAIR), 58:185–229, 2017.

[11] George Dantzig, Ray Fulkerson, and Selmer Johnson. Solution of a large-scale traveling-
salesman problem. Journal of the operations research society of America, 2(4):393–410, 1954.

[12] Sanjoy Dasgupta. Learning polytrees. In Proceedings of the Fifteenth conference on Uncertainty

in artiﬁcial intelligence, pages 134–141. Morgan Kaufmann Publishers Inc., 1999.

[13] Daniel Eaton and Kevin Murphy. Exact Bayesian structure learning from uncertain interven-

tions. In Artiﬁcial Intelligence and Statistics, pages 107–114, 2007.

[14] Fei Fu and Qing Zhou. Learning sparse causal Gaussian networks with experimental interven-
tion: regularization and coordinate descent. Journal of the American Statistical Association,
108(501):288–300, 2013.

[15] Asish Ghoshal and Jean Honorio. Information-theoretic limits of Bayesian network structure
learning. In Aarti Singh and Jerry Zhu, editors, Proceedings of the 20th International Con-
ference on Artiﬁcial Intelligence and Statistics, volume 54 of Proceedings of Machine Learning
Research, pages 767–775, Fort Lauderdale, FL, USA, 20–22 Apr 2017. PMLR.

[16] Martin Gr¨otschel, Michael J¨unger, and Gerhard Reinelt. On the acyclic subgraph polytope.

Mathematical Programming, 33(1):28–42, 1985.

[17] Sung Won Han, Gong Chen, Myun-Seok Cheon, and Hua Zhong. Estimation of directed acyclic
graphs through two-stage adaptive lasso for gene network inference. Journal of the American
Statistical Association, 111(515):1004–1019, 2016.

[18] Patrick Healy and Nikola S Nikolov. A branch-and-cut approach to the directed acyclic graph
In International Symposium on Graph Drawing, pages 98–109. Springer,

layering problem.
2002.

[19] Tommi Jaakkola, David Sontag, Amir Globerson, and Marina Meila. Learning Bayesian net-
work structure using LP relaxations. In Proceedings of the Thirteenth International Conference
on Artiﬁcial Intelligence and Statistics, pages 358–365, 2010.

24

[20] Markus Kalisch and Peter B¨uhlmann. Estimating high-dimensional directed acyclic graphs
with the PC-algorithm. Journal of Machine Learning Research, 8(Mar):613–636, 2007.

[21] Mikko Koivisto. Advances in exact Bayesian structure discovery in Bayesian networks. arXiv

preprint arXiv:1206.6828, 2012.

[22] Mikko Koivisto and Kismat Sood. Exact Bayesian structure discovery in Bayesian networks.

Journal of Machine Learning Research, 5(May):549–573, 2004.

[23] Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques.

MIT press, 2009.

[24] Steﬀen L. Lauritzen. Graphical Models. Oxford University Press, 1996.

[25] Po-Ling Loh and Peter B¨uhlmann. High-dimensional learning of linear causal networks via
inverse covariance estimation. The Journal of Machine Learning Research, 15(1):3065–3105,
2014.

[26] Brandon Malone, Kustaa Kangas, Matti J¨arvisalo, Mikko Koivisto, and Petri Myllym¨aki.
Predicting the hardness of learning Bayesian networks. In AAAI, pages 2460–2466, 2014.

[27] Florian Markowetz and Rainer Spang. Inferring cellular networks–a review. BMC bioinfor-

matics, 8(6):S5, 2007.

[28] George L Nemhauser and Laurence A Wolsey. Integer programming and combinatorial opti-
mization. Wiley, Chichester. GL Nemhauser, MWP Savelsbergh, GS Sigismondi (1992). Con-
straint Classiﬁcation for Mixed Integer Programming Formulations. COAL Bulletin, 20:8–12,
1988.

[29] Young Woong Park and Diego Klabjan. Bayesian network learning via topological order. The

Journal of Machine Learning Research, 18(1):3451–3482, 2017.

[30] Pekka Parviainen and Mikko Koivisto. Exact structure discovery in Bayesian networks with less
space. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artiﬁcial Intelligence,
pages 436–443. AUAI Press, 2009.

[31] Judea Pearl et al. Causal inference in statistics: An overview. Statistics surveys, 3:96–146,

2009.

[32] Eric Perrier, Seiya Imoto, and Satoru Miyano. Finding optimal Bayesian network given a

super-structure. Journal of Machine Learning Research, 9(Oct):2251–2286, 2008.

[33] Jonas Peters and Peter B¨uhlmann. Identiﬁability of Gaussian structural equation models with

equal error variances. Biometrika, 101(1):219–228, 2013.

[34] Garvesh Raskutti and Caroline Uhler. Learning directed acyclic graphs based on sparsest

permutations. arXiv preprint arXiv:1307.0366, 2013.

[35] Ali Shojaie and George Michailidis. Penalized likelihood methods for estimation of sparse

high-dimensional directed acyclic graphs. Biometrika, 97(3):519–538, 2010.

25

[36] Tomi Silander and Petri Myllymaki. A simple approach for ﬁnding the globally optimal

Bayesian network structure. arXiv preprint arXiv:1206.6875, 2012.

[37] Liam Solus, Yuhao Wang, Lenka Matejovicova, and Caroline Uhler. Consistency guarantees
for permutation-based causal inference algorithms. arXiv preprint arXiv:1702.03530, 2017.

[38] A Sondhi and A Shojaei. The reduced PC-algorithm: Improved causal structure learning in

large random networks. arXiv preprint arXiv:1806.06209, 2018.

[39] Peter Spirtes, Clark N Glymour, and Richard Scheines. Causation, prediction, and search.

MIT press, 2000.

[40] Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal

Statistical Society. Series B (Methodological), pages 267–288, 1996.

[41] Sara van de Geer and Peter B¨uhlmann. (cid:96)0-penalized maximum likelihood for sparse directed

acyclic graphs. The Annals of Statistics, 41(2):536–567, 2013.

[42] Jing Xiang and Seyoung Kim. A* lasso for learning a sparse Bayesian network structure for
continuous variables. In Advances in neural information processing systems, pages 2418–2426,
2013.

[43] Changhe Yuan and Brandon Malone. Learning optimal Bayesian networks: A shortest path

perspective. Journal of Artiﬁcial Intelligence Research, 48:23–65, 2013.

[44] Changhe Yuan, Brandon Malone, and Xiaojian Wu. Learning optimal Bayesian networks
using A* search. In IJCAI proceedings-international joint conference on artiﬁcial intelligence,
volume 22, page 2186, 2011.

[45] Bin Zhang, Chris Gaiteri, Liviu-Gabriel Bodea, Zhi Wang, Joshua McElwee, Alexei A
Podtelezhnikov, Chunsheng Zhang, Tao Xie, Linh Tran, Radu Dobrin, et al. Integrated sys-
tems approach identiﬁes genetic nodes and networks in late-onset Alzheimer’s disease. Cell,
153(3):707–720, 2013.

[46] Xun Zheng, Bryon Aragam, Pradeep Ravikumar, and Eric P Xing. DAGs with NO TEARS:

smooth optimization for structure learning. arXiv preprint arXiv:1803.01422, 2018.

[47] Hui Zou. The adaptive lasso and its oracle properties. Journal of the American statistical

association, 101(476):1418–1429, 2006.

26

Appendix I

PROOF OF PROPOSITION 1
Let ( ˆβ, ˆz) be an optimal solution for (5) with an optimal objective value F ( ˆβ). Let us refer to the
DAG structure corresponding to this optimal solution by DAG(V, ˆE→). Suppose that for some
(j, k), we have ˆzjk + ˆzkj = 0. To prove the proposition, we construct an optimal solution which
satisﬁes zjk +zkj = 1 for all pairs of (j, k) and meets the following conditions: (i) this corresponding
DAG (tournament) is cycle free (ii) this tournament has the same objective value, i.e., F ( ˆβ), as an
optimal DAG.

Select a pair of nodes, say p, q ∈ M, p (cid:54)= q from DAG(V, ˆE) for which ˆzpq + ˆzqp = 0. If there is a
directed path from p to q (respectively q to p), then we can add the following arc (p, q) (respectively,
(q, p)). This arc does not create a cycle in the graph. If there is no directed path between p and q,
we can add an arc in either direction. In all cases, set β value corresponding to the added arc to
zero. We repeat this process for all pairs of nodes with ˆzpq + ˆzqp = 0.

We can add such arcs without creating any cycle. This is because if we cannot add an arc in
either direction, it implies that we should have a directed path from p to q and a directed path
from q to p in graph DAG(V, ˆE) which is a contradiction because it implies a directed cycle in an
optimal DAG. Note that in each step, we maintain a DAG. Hence, by induction we conclude that
condition (i) is satisﬁed. The pair of nodes can be chosen arbitrarily.

Since in the constructed solution we set β for the added arcs as zero, the objective value does
(cid:3)

not change. This satisﬁes condition (ii), and completes the proof.

PROOF OF PROPOSITION 2
First we prove that (10e) removes all cycles. Suppose, for contradiction, that a cycle of size p ≥ 2 is
available and represented by (1, 2, . . . , p, 1). This implies zj+1,j = 0 and zj,j+1 = 1, ∀j = {1, . . . , p −
1}, and zp,1 = 1, z1,p = 0. Then,

1 = z12 − mz21 ≤ ψ2 − ψ1,
1 = z23 − mz32 ≤ ψ3 − ψ2,
...
1 = zp−1,p − mzp,p−1 ≤ ψp − ψ1,
1 = zp,1 − mz1,p ≤ ψ1 − ψp.

We sum the above inequalities and conclude p ≤ 0, a contradiction.

To complete the proof, we also need to prove that any DAG is feasible for the LN formulation.
To this end, we know that each DAG has a topological ordering. For all the existing arcs in the
DAG, substitute zjk = 1 and assign a topological ordering number to the variables ψk, k ∈ V in
(cid:3)
LN. Then, the set of constraints in (10e) is always satisﬁed.

PROOF OF PROPOSITION 3
The LO formulation is in w-space whereas LN is in (z, ψ)-space. Hence, we ﬁrst construct a mapping
between these decision variables.

(j, k) ∈

Given a feasible solution wjk for all j, k ∈ V, j (cid:54)= k in the LO formulation, we deﬁne zjk = wjk,
(cid:96)∈V \{j} w(cid:96)j, j ∈ V . Let 1(x ≥ 0) be a function which takes value 1 if x ≥ 0
−→
E and ψj for j ∈ V in the LN formulation, we map

and 0 otherwise. Given zjk for all (j, k) ∈

−→
E and ψj = (cid:80)

27

−→
E and wjk = 1(ψk − ψj + 1 ≥ 0) for all (j, k) /∈

wjk = zjk for all (j, k) ∈
is deﬁned for all pair of nodes whereas z-space is deﬁned for the set of arcs in
−→
E .
mapping, we have wjk = zjk, ∀(j, k) ∈
Fixing j and k for each (j, k) ∈

−→
E and summing the left hand-side of inequalities (8e) over

−→
E . Note that w-space
−→
E . In every correct

i ∈ V \ {j, k} we obtain

(m − 2)wjk +

(cid:88)

wki +

(cid:88)

wij ≤ m − 2

i∈V \{k,j}
(cid:88)

≡ (m − 2)wjk +

i∈V \{j,k}
(cid:88)

wki +

(1 − wji) ≤ m − 2

≡ mwjk − 1 +

≡ mwjk − 1 −

i∈V \{k,j}
(cid:88)

wki −

i∈V \{k}
(cid:88)

wik +

i∈V \{j,k}

(cid:88)

i∈V \{j}
(cid:88)

wji ≤ m − 2

wij ≤ m − 2

i∈V \{k}

i∈V \{j}

≡ mwjk − m + 1 ≤

(cid:88)

wik −

(cid:88)

wij,

i∈V \{k}

i∈V \{j}

where the equivalences follow from constraints (8d). Given our mapping, zjk = wjk for all (j, k) ∈
and ψj = (cid:80)
(cid:96)∈V \{j} w(cid:96)j for j ∈ V , the above set of constraints can be written as

−→
E

zjk − (m − 1)zkj ≤ ψk − ψj ∀ (j, k) ∈

−→
E ,

which satisﬁes (10e) in the LN formulation. This implies R(LO) ⊆ R(LN ) for (cid:96)1-regularization.
For (cid:96)0-regularization, we need to add that gjk ≤ wjk = zjk, ∀(j, k) ∈ E→. This implies R(LO) ⊆
R(LN ) for (cid:96)0 regularization.

To show strict containment, we give a point that is feasible to the LN formulation that cannot
be mapped to any feasible point in the LO formulation. Consider m = 3, z13 = 1, z31 = 0, z32 =
0.5 + (cid:15), z23 = 0.5 − (cid:15), z12 = z21 = 0.5, ψ = (1, 2, 2), for 0 < (cid:15) < 1
6 , with an appropriate choice of
β. It is easy to check that this is a feasible solution to the LN formulation. Because we must have
−→
wij = zij, ∀(i, j) ∈
E , we have w13 + w32 + w21 > 2. Therefore, the corresponding point is infeasible
to the LO formulation and this completes the proof.

(cid:3)

PROOF OF PROPOSITION 4
This proof is for TO formulation when the parameter m on (9e) is replaced with m − 1.

In the TO formulation, deﬁne the term (cid:80)

s∈V sojs as ψj. Further,
remove the set of constraints in (9f), (9g), and (9i). This implies that R(T O) ⊆ R(LN ). To see
strict containment, consider the point described in the proof of Proposition 3, which is feasible to
the LN formulation. For this point, there can be no feasible assignment of the decision matrix o
such that ψj = (cid:80)

s∈V sojs, hence R(T O) ⊂ R(LN ).

s∈V soks as ψk and the term (cid:80)

(cid:3)

PROOF OF PROPOSITION 5

Let ¯F (β(cid:63)

X ) denote the optimal objective value associated with the continuous relaxation of model

28

X ∈ {CO, LO, LN }.

Part A. ¯F (β(cid:63)

LO) = ¯F (β(cid:63)
Case 1. (cid:96)1 regularization

LN ).

Suppose (β(cid:63)
formulation (10a)-(10g) and (β(cid:63)
of the LO formulation with (cid:96)1-regularization.

LN , z(cid:63)) is an optimal solution associated with the continuous relaxation of the LN
LO, w(cid:63)) is an optimal solution associated with continuous relaxation

Given Proposition 3, we conclude that ¯F (β(cid:63)

LO)
also holds in an optimal solution. To this end, we map an optimal solution in continuous relaxation
of the (cid:96)1-LN formulation to a feasible solution in continuous relaxation of the (cid:96)1-LO formulation
with the same objective function. This implies ¯F (β(cid:63)

LO). We prove that ¯F (β(cid:63)

LO).
LN , z(cid:63)) to the continuous relaxation of the (cid:96)1-LN formulation, we

Given an optimal solution (β(cid:63)

LN ) ≥ ¯F (β(cid:63)

LN ) ≤ ¯F (β(cid:63)

LN ) ≥ ¯F (β(cid:63)

construct a feasible solution (βLO, w) to the continuous relaxation of the LO formulation as

wjk = wkj =

(cid:40) 1
2 ,
0,

z(cid:63)
jk > 0, (i, j) ∈
otherwise,

−→
E ,

and let βLO = β∗

LN .

We now show that this mapping is always valid for the (cid:96)1-LO formulation. Recall that for the
(cid:96)1 regularization, we do not have the decision vector g in the formulation. Three set of constraints
have to be satisﬁed in the (cid:96)1-LO formulation.
|βjk| ≤ M wjk,
wjk + wkj = 1,
wij + wjk + wki ≤ 2,

−→
E
(8b)
−→
E (8d)

∀(j, k) ∈
∀(j, k) ∈

−→
E i (cid:54)= j (cid:54)= k.

∀(i, j), (j, k), (k, i) ∈

(8e)

The set of constraints (8b) is trivially satisﬁed because we set M ≥ 2 max
−→
E
(j,k)∈

|β(cid:63)

jk|. The set of

constraints (8d) is trivially satisﬁed. The set of constraints (8e) is satisﬁed because the left hand
side of inequality can take at most 3
LN ).
This completes this part of the proof.
Case 2. (cid:96)0 regularization

2 given this mapping. Therefore, ¯F (β(cid:63)

LO) ≤ ¯F (βLO) = ¯F (β(cid:63)

LN , z(cid:63)) is an optimal solution associated with a continuous relaxation of the (cid:96)0-LN
LO, w(cid:63)) is an optimal solution associated with a continuous relaxation of

LO, g(cid:63)

LN ) ≤ ¯F (β(cid:63)

LO, g(cid:63)

LO). We now prove that, in an optimal solution

LN , z(cid:63)) for the continuous relaxation of the (cid:96)0-LN formulation,
we construct a feasible solution (βLO, gLO, w) for the continuous relaxation of the (cid:96)0-LO formulation
as

LN , g(cid:63)

LN , g(cid:63)

Suppose (β(cid:63)
formulation, and (β(cid:63)
the (cid:96)0-LO formulation.

¯F (β(cid:63)

Given Proposition 3, ¯F (β(cid:63)
LN ) ≥ ¯F (β(cid:63)
LN , g(cid:63)
Given an optimal solution (β(cid:63)

LN , g(cid:63)
LO) also holds.

LO, g(cid:63)

wjk = wkj =

(cid:40) 1
2 ,
0,

z(cid:63)
jk > 0, (j, k) ∈
otherwise,

−→
E ,

and let βLO = β∗

LN and gLO = g(cid:63)

LN .

We now show that this mapping is always valid for the LO formulation. Four sets of constraints

have to be satisﬁed in the LO formulation.

29

−→
E , (8b)

|βjk| ≤ M gjk,
gjk ≤ wkj,
wjk + wkj = 1,
wij + wjk + wki ≤ 2,

∀(j, k) ∈

∀(j, k) ∈
−→
E (8c)
−→
E (8d)

∀(j, k) ∈

∀i, j, k ∈ V, i (cid:54)= j (cid:54)= k,

(8e)

jk = g(cid:63)

The set of constraints in (8d) is satisﬁed similar to (cid:96)1 case. The proof that constraints (8b),
(8c), and (8e) are also met is more involved. If the (cid:96)0-LN formulation attains a solution for which
g(cid:63)
ij = g(cid:63)
ki = 1 (we dropped subscript LN), then our mapping leads to an infeasible solution
to the (cid:96)0-LO formulation, because it forces wij + wjk + wki ≥ 2 for (cid:96)0-LO. Next we show that
this will not be the case and that our mapping is valid. To this end, we show that in an optimal
−→
solution for the continuous relaxation of (cid:96)0-LN, we always have g(cid:63)
E . Note that in
the LN formulation, we have |βjk| ≤ M gjk, ∀(j, k) ∈ E→ and gjk ≤ zjk (we dropped the subscript
LN). Suppose that g(cid:63)
2 . In this case, the objective function forces g(cid:63)
2 . Note
that the objective function can reduce g(cid:63)
2 and decreases the regularization term without
any increase on the loss function. This is because βjk ≤ M gjk, ∀(j, k) ∈ E→ can be replaced by
βjk ≤ M 1
jk|. Therefore, our

2 , ∀(j, k) ∈ E→ without any restriction on β because M ≥ 2 max
−→
E
(j,k)∈
LO, g(cid:63)
LN , g(cid:63)
LN ).

LO) ≤ ¯F (βLO, gLO) = ¯F (β(cid:63)

jk to be at most 1

jk up to 1

2 , ∀(j, k) ∈

jk ≥ 1

jk ≤ 1

|β(cid:63)

mapping is valid and implies that ¯F (β(cid:63)
T O) = ¯F (β(cid:63)
Part B. ¯F (β(cid:63)
Case 1. (cid:96)1 regularization

LN ).

LN ) ≤ F (β(cid:63)
Given Proposition 4, we conclude that F (β(cid:63)
T O)
also holds in an optimal solution. We map an optimal solution in continuous relaxation of the
(cid:96)1-LN formulation to a feasible solution in continuous relaxation of the (cid:96)1-TO formulation with the
same objective value. This implies ¯F (β(cid:63)

T O). We now prove that ¯F (β(cid:63)

LN ) ≥ ¯F (β(cid:63)

LN ) ≥ ¯F (β(cid:63)

T O).

LN , z(cid:63)

LN , ψ(cid:63)) for a continuous relaxation of the LN formulation, rank the ψ(cid:63)

Next we construct a feasible solution (βT O, zT O, o) to the TO formulation. Given an optimal
solution (β(cid:63)
j in non-
descending order. Ties between ψ values can be broken arbitrarily in this ranking. Then, for
each variable j ∈ {1, . . . , m}, ojr = 1 where r denotes the rank of ψj in a non-descending order
(the ﬁrst element is ranked 0). This mapping satisﬁes the two assignment constraints (9f)-(9g).
Let βT O = β∗
LN . This gives a feasible solution for the TO formulation. Thus,
LN ) ≥ ¯F (β(cid:63)
¯F (β(cid:63)
Case 2. (cid:96)0 regularization

LN , zT O = z∗
T O).

Deﬁne g(cid:63)

LN = gT O. The rest of the proof is similar to the previous proofs.

Part C. ¯F (β(cid:63)

CP ) = ¯F (β(cid:63)

LN ).

To prove this, we ﬁrst prove the following Lemma.

Lemma. The LO formulation is at least as strong as the CP formulation, that is R(LO) ⊆ R(CP ).

Proof. Consider (8d)-(8e) in the linear ordering formulation given by

wjk + wkj = 1 ∀ (j, k) ∈

−→
E ,

wij + wjk + wki ≤ 2 ∀(i, j), (j, k), (k, i) ∈

−→
E .

30

Consider the set of constraints in CP given by (6c) as

(cid:88)

(j,k)∈ CA

gjk ≤ |CA| − 1 ∀CA ∈ C,

Consider the same mapping as in Proposition 3. Select an arbitrary constraint from (6c).
Without loss of generality, consider g1,2 + g2,3 + · · · + gp−1,p + gp,1 ≤ p − 1. We arrange the terms
in (8d)-(8e) as

w1,2 + w2,3 + w3,1 ≤ 2
w1,3 + w3,4 + w4,1 ≤ 2
w1,4 + w4,5 + w5,1 ≤ 2
...
w1,p−2 + wp−2,p−1 + wp−1,1 ≤ 2
w1,p−1 + wp−1,p + wp,1 ≤ 2

w1,2 + w2,3 + w3,4 + · · · + wp,1 ≤ p − 1. Thus, we conclude that R(LO) ⊆ R(CP ).

Summing the above set of inequalities and substituting wij = 1 − wji, when appropriate, gives
(cid:3)
(cid:3)

Given this lemma and Proposition 3, we conclude that ¯F (β(cid:63)

LN ) ≥ ¯F (β(cid:63)

T O).

PROOF OF PROPOSITION 6

This is a generalization of Proposition 5. Suppose we have branched on variable wjk in the LO
formulation or correspondingly on variable zjk in the LN formulation. If wjk = 0, then βjk = 0.
−→
In this case, it is as if we now need to solve the original model with (j, k) /∈
E . Thus, Proposition
5 (Part A) implies that both models attain the same continuous relaxation. On the other hand, if
wjk = 1 in LO (or correspondingly zjk = 1 in LN), we deﬁne our mapping as

wjk = wkj =






1
2 ,
1,
0,

−→
E ,

z(cid:63)
jk > 0, (j, k) ∈
(j, k) ∈ B
otherwise,

where B is the set of (j, k) for which zjk = 1. The rest of the proof follows from Proposition 5 (Part
A).

The proofs for the TO and CP formulations are almost identical with Proposition 5. Suppose
we have branched on variable zjk on any of the models (CP, LO, TO). If zjk = 0, then βjk = 0. In
−→
this case, it is as if we now need to solve the original model with (j, k) /∈
E . If zjk = 1, one deﬁnes
the mapping in Proposition 5. The proof follows from Proposition 5 parts B and C, respectively. (cid:3)

31

Appendix II

(a) Optimality GAPs for MIQPs

(b) Time (in seconds) for MIQPs

(c) Best upper bounds for MIQPs

(d) Best lower bounds for MIQPs

(e) Time (in seconds) for continuous root relaxation

(f) Number of explored nodes in B&B tree

Figure 10: Optimization-based measures for MIQPs for (cid:96)0 model with number of samples n = 100.

32

0.000.050.100.150.20Optimality GAP (MIP GAP)Moral  =1.00.00.10.20.30.40.5Complete  =1.010203040Number of nodes0.000.050.100.150.200.25Optimality GAP (MIP GAP)=0.110203040Number of nodes0.00.10.20.30.40.50.60.7=0.10500100015002000Time (seconds)Moral  =1.00500100015002000Complete  =1.010203040Number of nodes0500100015002000Time (seconds)=0.110203040Number of nodes0500100015002000=0.1020406080Upper BoundMoral  =1.0020406080100Complete  =1.010203040Number of nodes010203040Upper Bound=0.110203040Number of nodes020406080=0.1020406080Lower BoundMoral  =1.001020304050Complete  =1.010203040Number of nodes010203040Lower Bound=0.110203040Number of nodes0510152025=0.1LNTOCPLO0500100015002000Time (seconds)Moral  =1.00500100015002000Complete  =1.010203040Number of nodes0500100015002000Time (seconds)=0.110203040Number of nodes0500100015002000=0.10100000020000003000000Number of Nodes in B&BMoral  =1.00200000400000600000800000Complete  =1.010203040Number of nodes05000001000000150000020000002500000Number of Nodes in B&B=0.110203040Number of nodes0200000400000600000800000=0.1LNTOCPLO(a) True Positive Rate (TPR) for MIQPs

(b) True Positive Rate(TPR) for MIQPs

(c) False Positive Rate(FPR) for MIQPs

(d) False Positive Rate(FPR) for MIQPs

Figure 11: Graph metrics for the MIQPs for (cid:96)0 regularization. Plots a, c (left) show graph metrics
with the number of samples n = 1000 and plots b, d (right) show the graph metrics with the number
of samples n = 100.

33

0.00.20.40.6True Positive Rate (TPR)Moral  =1.00.00.20.40.6Complete  =1.010203040Number of nodes0.00.20.40.60.81.0True Positive Rate (TPR)=0.110203040Number of nodes0.00.20.40.60.81.0=0.10.00.20.40.6True Positive Rate (TPR)Moral  =1.00.00.10.20.30.40.50.6Complete  =1.010203040Number of nodes0.00.20.40.60.81.0True Positive Rate (TPR)=0.110203040Number of nodes0.00.20.40.60.81.0=0.10.0000.0020.0040.0060.008False Positive Rate (FPR)Moral  =1.00.0000.0020.0040.0060.0080.010Complete  =1.010203040Number of nodes0.00000.00050.00100.00150.0020False Positive Rate (FPR)=0.110203040Number of nodes0.0000.0050.0100.015=0.1LNTOCPLO0.000.010.020.03False Positive Rate (FPR)Moral  =1.00.000.010.020.03Complete  =1.010203040Number of nodes0.00000.00050.00100.00150.0020False Positive Rate (FPR)=0.110203040Number of nodes0.000.010.020.030.040.05=0.1LNTOCPLO(a) Optimality GAPs for MIQPs

(b) Time (in seconds) for MIQPs

(c) Best obtained upper bounds for MIQPs

(d) Best obtained lower bounds for MIQPs

(e) Time (in seconds) for continuous root relaxation

(f) Number of explored nodes in B&B tree

Figure 12: Optimization-based measures for MIQPs for (cid:96)1 model with the number of samples
n = 100.

34

0.000.020.040.060.080.10Optimality GAP (MIP GAP)Moral  =1.00.000.050.100.150.200.25Complete  =1.010203040Number of nodes0.000.050.100.150.200.25Optimality GAP (MIP GAP)=0.110203040Number of nodes0.00.10.20.30.40.5=0.10500100015002000Time (seconds)Moral  =1.00500100015002000Complete  =1.010203040Number of nodes0500100015002000Time (seconds)=0.110203040Number of nodes0500100015002000=0.1020406080Upper BoundMoral  =1.0020406080Complete  =1.010203040Number of nodes01020304050Upper Bound=0.110203040Number of nodes0204060=0.1020406080Lower BoundMoral  =1.00204060Complete  =1.010203040Number of nodes010203040Lower Bound=0.110203040Number of nodes051015202530=0.1LNTOCPLO0500100015002000Time (seconds)Moral  =1.00500100015002000Complete  =1.010203040Number of nodes0500100015002000Time (seconds)=0.110203040Number of nodes0500100015002000=0.1010000200003000040000Number of Nodes in B&BMoral  =1.0050000100000150000200000Complete  =1.010203040Number of nodes0200000400000600000800000Number of Nodes in B&B=0.110203040Number of nodes0100000200000300000=0.1LNTOCPLO(a) True Positive Rate (TPR) for MIQPs

(b) True Positive Rate (TPR) for MIQPs

(c) False Positive Rate (FPR) for MIQPs

(d) False Positive Rate (FPR) for MIQPs

Figure 13: Graph metrics for MIQPs for (cid:96)1 regularization. Plots a, c (left) show graph metrics with
the number of samples n = 1000. Plots b, d (right) show the graph metrics with the number of
samples n = 100.

35

0.00.20.40.60.81.0True Positive Rate (TPR)Moral  =1.00.00.20.40.60.81.0Complete  =1.010203040Number of nodes0.00.20.40.60.81.0True Positive Rate (TPR)=0.110203040Number of nodes0.00.20.40.60.81.0=0.10.00.20.40.60.81.0True Positive Rate (TPR)Moral  =1.00.00.20.40.60.8Complete  =1.010203040Number of nodes0.00.20.40.60.81.0True Positive Rate (TPR)=0.110203040Number of nodes0.00.20.40.60.81.0=0.10.000.010.020.030.04False Positive Rate (FPR)Moral  =1.00.000.050.100.15Complete  =1.010203040Number of nodes0.000.010.020.03False Positive Rate (FPR)=0.110203040Number of nodes0.00.10.20.3=0.1LNTOCPLO0.000.020.040.06False Positive Rate (FPR)Moral  =1.00.000.050.100.150.20Complete  =1.010203040Number of nodes0.0000.0250.0500.0750.1000.125False Positive Rate (FPR)=0.110203040Number of nodes0.00.20.40.6=0.1LNTOCPLO