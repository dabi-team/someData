MSc Artificial Intelligence
Master Thesis

Type-driven Neural Programming by Example

by
Kiara Grouwstra

6195180

September 18, 2020

48
2019-2020

Supervisor:
MSc. Emile van Krieken

Assessor:
Dr. Annette ten Teije

Second Reader:
Dr. Clemens Grelck

0
2
0
2

p
e
S
7
1

]
E
S
.
s
c
[

5
v
3
1
6
2
1
.
8
0
0
2
:
v
i
X
r
a

University of Amsterdam
Informatics Institute

 
 
 
 
 
 
Truly solving program synthesis is the last
programming problem mankind will have to
solve.

Kant [50]

1

Contents

1 Research Direction

1.1 Program Synthesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Related ﬁelds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2.1 Program Induction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2.2
Supervised Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2.3 Constraint satisfaction vs. discrete optimization . . . . . . . . . . . . . . . . . . . . . . .
1.3 Challenges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3.1 Challenge of program synthesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3.2 Challenge of type-theoretic programming by example . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . .
1.3.3 Challenges of neural programming by example
1.4 Research question . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.4.1 Hypothesis

2 Expected Contribution

3 Literature review

3.1 Types of program synthesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Existing approaches to programming by example . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.1
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2.2 Neural programming by example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Search-based programming by example

3
3
4
4
4
5
5
5
5
6
6
6

6

7
7
8
8
9

4 Background

13
4.1 Lambda calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
4.2 Complementing synthesis grammars with static typing . . . . . . . . . . . . . . . . . . . . . . . . 13

5 Methodology

5.1 User intent
5.2 Program search space

14
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
5.2.1 The functional programming context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
Synthesis language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
5.2.2
5.2.3 Grammatical subset
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
5.2.4 Operator whitelist . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
5.3 Dataset generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
5.3.1 Preventing data leakage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
5.4 Search technique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
5.4.1 Our adaptation of neuro-symbolic program synthesis . . . . . . . . . . . . . . . . . . . . . 19
5.4.2 Functional program domain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
5.4.3 Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20

6 Experiment

22
6.1 Benchmark task . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

7 Result

23

8 Discussion

25
8.1 Dataset considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
8.2 Design limitations
8.3 Topics for future research . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
8.4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26

9 Acknowledgements

27

A Hyperparameters

34
A.1 Hyperparameters used for dataset generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
A.2 Hyperparameters in our synthesizer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34

B Miscellaneous experiments

34
B.1 Type ﬁlter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
B.2 Picking holes

2

Abstract

In this thesis we look into programming by example (PBE), which is about ﬁnding a program mapping
given inputs to given outputs. PBE has traditionally seen a split between formal versus neural approaches,
where formal approaches typically involve deductive techniques such as SAT solvers and types, while the
neural approaches involve training on sample input-outputs with their corresponding program, typically using
sequence-based machine learning techniques such as LSTMs [41]. As a result of this split, programming types
had yet to be used in neural program synthesis techniques.

We propose a way to incorporate programming types into a neural program synthesis approach for
PBE. We introduce the Typed Neuro-Symbolic Program Synthesis (TNSPS) method based on this idea,
and test it in the functional programming context to empirically verify type information may help improve
generalization in neural synthesizers on limited-size datasets.

Our TNSPS model builds upon the existing Neuro-Symbolic Program Synthesis (NSPS) [76], a tree-based
neural synthesizer combining info from input-output examples plus the current program, by further exposing
information on types of those input-output examples, of the grammar production rules, as well as of the
hole that we wish to expand in the program.

We further explain how we generated a dataset within our domain, which uses a limited subset of Haskell
as the synthesis language. Finally we discuss several topics of interest that may help take these ideas further.
For reproducibility, we release our code publicly. [33]

1 Research Direction

If AI is software 2.0 [51], then program synthesis lets us apply software 2.0 to software development itself.

1.1 Program Synthesis

After chess engine Deep Blue defeated grandmaster Kasparov in 1997 [18], in a freestyle chess tournament in
2005, both a supercomputer and a grandmaster with a laptop lost to two amateurs using three laptops [52],
demonstrating the importance of man-machine cooperation.

While time has passed since then, this lesson remains relevant today. Human engineers take time to accrue
experience and write software, while even our largest generative models require human feedback for non-trivial
tasks [71].

Again, at the heart of this lies having to face the complementary strengths of people versus machines, and
in this case, applying these to improve the process of software development. This idea of machines producing
software is called program synthesis [21].

Historically, program synthesis has been popularized by Microsoft Excel’s FlashFill feature [61], as well as
by intelligent code completion tools, such as Microsoft’s Intellisense [62], Google’s ML Complete [100], as well
as Codota’s TabNine [22].

Formally speaking, program synthesis is the task of automatically constructing a program that satisﬁes a
given high-level speciﬁcation, be it a formal speciﬁcation, a natural language description, full program traces,
input-output examples, or an existing program. [36].

This enables us to distill our modeled program to a simpliﬁed discrete form that may well be intelligible
to humans as well as computers, opening up opportunities for human-machine cooperation in writing software.
Speciﬁcally, this will allow machines to improve on programs written by humans, and the other way around.
As such, program synthesis may bring hybrid intelligence [99] to the ﬁeld of software development.

For example, software engineering has brought the idea of test-driven development, that is, the cycle of
writing a test for your program to check if it does what it should, then iterating on an implementation of the
program until it passes the test. Program synthesis may well help automate this second half.

While machine learning practicioners have gradually expanded the use-cases of AI, GitHub in 2018 already
counted 100 million code repositories [106], still limited by human developers, demonstrating the potential
impact of the single AI branch of neural program synthesis.

Program synthesis itself has typically been split between formal (deductive, type-theoretic) vs. neural ap-
proaches. This thesis aims to contribute to narrowing this gap by exploring the intersection of these approaches.
The idea of a program synthesizer utilizing a human feedback loop is not new, having been used for ambiguity

resolution when multiple programs of diﬀerent behavior both fulﬁlled the speciﬁed requirements.

For real-life scenarios however, the amount of viable programs might be numerous, making it less viable to
burden humans with more feedback requests than might be needed. Neural synthesis methods such as OpenAI’s
GPT-3 [71] instead use sequence completion to provide the user with a likely candidate, allowing the user to
intervene as deemed ﬁt. This approach however has caused concern of a rise in generated code that is neither
tested nor understood. [92]

Synthesizer-human interaction has been further explored by the idea of type-driven development [14], using
type annotations to inform iteratively synthesizing completions to ﬁll program holes, i.e. placeholder nodes in

3

the AST to be ﬁlled by the synthesizer. This is what directly inspired the direction of this thesis, aiming to on
the one hand facilitate such predictions where only type info by itself falls short, while simultaneously aiming
to improve on existing neural synthesis methods by also utilizing such type info.

We will now further expand on ﬁelds related to program synthesis, before going into the challenges faced by

diﬀerent synthesis methods, then lay out our research questions.

1.2 Related ﬁelds

To give more context on how program synthesis ﬁts into the bigger picture, we will brieﬂy compare it to some
other ﬁelds: program induction, supervised learning, as well as constraint satisfaction and discrete optimization.

1.2.1 Program Induction

Unfortunately the ﬁeld of program induction suﬀers from competing deﬁnitions, blurring the distinction between
what constitutes program synthesis versus what constitutes program induction. In short though, those in either
ﬁeld claim to be more general than the other branch.

The ﬁeld of inductive programming [84, 79, 29], primarily known for its sub-branch inductive logic program-
ming [66] focused on propositional logic, is simply automatic synthesis using inductive logic, and was coined
to distinguish itself from the deductive techniques used in Church [21]’s synthesis of circuits. Under this deﬁ-
nition, the term program synthesis is used to refer to its original scope of program generation using deductive
techniques.

Whereas in the original problem deﬁnition the desired behavior was fully speciﬁed, program induction aimed
to generalize the problem to also tackle automatic generation of programs for which the desired behavior had
only partially been made explicit, through e.g. input/output examples or incomplete data.

Under this deﬁnition, there is no signiﬁcant distinction between our present work and program induction’s
sub-branch of inductive functional programming, focused on the generation of programs in functional program-
ming languages such as Lisp [98] or Haskell.

Nevertheless, in current parlance program synthesis is often used in a broader scope, extending from the
original deductive approach to include inductive approaches as well. In this view, the two ﬁelds are distinguished
in that program synthesis is deﬁned as to explicitly return a program, whereas program induction learns to
mimic it rather than explicitly return it. [24, 36, 50] While this usage appears to clash with the term program
induction as used in inductive functional programming, this view of program induction being limited to this
smaller scope likely stems from widespread use of the term in the ﬁeld of inductive logic programming.

This terminology itself is not of much concern for our present paper, as the boundaries between the ﬁelds
have often been muddy. Moreover, recent applications of AI to this ﬁeld have led to the more recent term of
neural program synthesis [50]. Therefore, we will simply settle for using ‘program synthesis’ to refer to the ﬁeld
in general as well.

1.2.2 Supervised Learning

The above deﬁnition of program synthesis as explicitly returning a program is helpful to explain how it diﬀers
from supervised learning, the machine learning task of learning a function that maps an input to an output
based on example input-output pairs [90].

Deep learning methods may potentially be applied to diﬀerent branches of program synthesis, and several
of these may in fact be tackled using setups involving supervised learning. Of particular note here however is a
branch referred to as programming by example (PBE), which like supervised learning is based on the question
of how to reconstruct a mapping between input and output — in the supervised learning context also referred
to as features and labels, respectively.

What sets these apart is that, whereas supervised learning would construct such a model in a continuous
vector space, allowing probabilistic interpretations of the data to be taken at prediction time, PBE instead ﬁts
its model into the discrete form of a given grammar to produce a program, forcing one to instantiate such a
model from probabilistic data interpretations.

This also explains the relative beneﬁts of these two ﬁelds: supervised learning enables diﬀerentiable evalu-
ation without needing workarounds (see Section 3.2.2), allowing for optimization by backpropagation [89], and
is not limited in expressivity by the limitations of any particular grammar or set of operations. This makes it
well-positioned to solve problems deemed too complex for traditional programming, such as image recognition.
Program synthesis techniques may instead construct a traditional program, which can generalize better [50],
be provably correct [50], as well as potentially faster to execute than predictions using the equivalent supervised
learning model.

4

Moreover, using programs as a common denominator between human and machine-based programmers
makes for human-intelligible machine-made models, relevant in the ﬁeld of interpretable or explainable artiﬁcial
intelligence 1, while also enabling human-machine cooperation in the production and maintenance of software.
In program synthesis, one may take an existing program, and synthesize variants intended to generalize the
existing logic to match the new data. [74] This makes program synthesis well-suited to facilitate the automation
of programming. 2

In other words, whereas supervised learning makes for simpler learning, since it foregoes the need to de-
ﬁne a synthesis grammar and operator set, program synthesis may make for programs that are potentially
more eﬃcient, more understandable, which for the machine learning models produced in supervised learning
requires adding the non-trivial ﬁeld of explainable AI [37], while program synthesis also facilitates incorporating
knowledge of human experts, by allowing them to oﬀer relevant operators.

1.2.3 Constraint satisfaction vs. discrete optimization

While its deﬁnition may appear to frame program synthesis as a type of constraint satisfaction problem (CSP),
where a program either does or does not satisfy the given speciﬁcation, one could also opt to approach it as a
discrete optimization problem, as speciﬁcations such as input-output examples allow us to count the examples
our candidate program satisﬁes.

Intuitively, a program satisfying part of our examples may be regarded as closer to a solution than one that
does not satisfy as many. Furthermore, additional considerations such as performance may further push us
to ﬁnd a solution that not only calculates outputs correctly but also runs within reasonable time or memory
constraints. These then provide a quantiﬁable feedback measure for us to optimize.

However, constraint satisfaction and discrete optimization were intended to solve fully speciﬁed problems
(deduction), while in modern-day program synthesis, as we will explain later, we usually need to settle for a
partial speciﬁcation of the intended program’s behavior (induction).

In other words, in such an inductive setting one cannot even deﬁnitively tell whether one program is better
or worse than another on unspeciﬁed intended behavior, meaning the metric that would be used for constraint
satisfaction or optimization may not be representative of the actual problem. This is a general diﬀerence between
constraint satisfaction and optimization versus pattern recognition techniques including machine learning:
in
the latter case, the actual goal is to generalize learned behavior to an unseen test set, rather than merely
performing well on known examples.

As such, applying such techniques to the ﬁeld of program synthesis using partial speciﬁcations may lead us
to the problem of overﬁtting: while found solutions might well satisfy the speciﬁed behavior, the question would
be whether these would also generalize to match our intended behavior, as is the goal in PBE.

1.3 Challenges

Having given a brief background on where the ﬁeld of program synthesis ﬁts in, we will now brieﬂy outline
some of the challenges in this ﬁeld, with a focus on programming by example, as a backdrop informing our own
research direction.

1.3.1 Challenge of program synthesis

While considered a holy grail of computer science [36], program synthesis in general is a challenging task,
characterized by large search spaces, e.g. a search space of 105,943 programs to discover an expert implementation
of the MD5 hash function. [36]

1.3.2 Challenge of type-theoretic programming by example

One issue with type-theoretic approaches to PBE, later introduced in further detail, is that while such search
methods are able to make use of both input/output examples and types in their search, there is no sense of
learning across problem instances to further reduce the synthesis time caused by these large search spaces.

1 If the goal in using program synthesis is to make models more interpretable, one could potentially start out by training a
neural model, then approximate this by synthesizing a program similar to it. And in fact, Verma et al. [104] apply exactly this
approach for reinforcement learning.

2 One may note that this would technically enable the synthesis of programs implementing machine learning models as well.
However, such an approach would make for a relatively expensive evaluation function, and as such is traditionally left to the ﬁeld
of neural architecture search.

5

1.3.3 Challenges of neural programming by example

For neural methods in PBE, the original challenge of large search spaces means it will not be viable to propor-
tionally scale our training sets by program size.

Furthermore, whereas a program synthesizer may be programmed or taught to output programs adhering to
a given grammar, we may generally only be able to evaluate the quality of complete programs: there is typically
no guarantee that partial constructions of the program would also qualify as a full executable program adherent
to the grammar. As a result, neural synthesizers will have little intermediary feedback to go by, limiting their
eﬀectiveness.

But if only complete programs can be evaluated for validity and behavior, then we will be ill-equipped to
provide synthesizers with an accurate understanding of partial programs, which make up for a large part of our
prediction steps. As such, it would be desirable to somehow better supervise the intermediate prediction steps.
This echoes Kant [50]’s conclusion that one area of research in neural program synthesis that requires further
exploration is speciﬁcally designing neural architectures to excel at the diﬃcult problems of program synthesis.
Most neural synthesis techniques, particular those using a sequence-to-sequence approach, additionally face
the issue of dissonance between their representation of complete programs and that of intermediate states. As
such intermediate states do not in general constitute valid programs, these neural synthesizers have an additional
task to solve: compensating for their lack of an inherently meaningful incremental state.

1.4 Research question

Based on the previous section, our key observation here is thus that input-output examples and types are
quite complementary as speciﬁcations constraining our program behavior. Input-output examples are relatively
expressive, but may only help us to evaluate the quality of complete programs. Types, on the other hand, are
by themselves not usually descriptive enough of our task, but may help us to provide a less noisy summary
of program behavior, hopefully aiding generalization, as well as to evaluate even incomplete programs still
containing holes, and to inform further incremental synthesis steps.

This brings us to the question: can neural program synthesis methods beneﬁt from using type information?

1.4.1 Hypothesis

Based on the complementary strengths mentioned above, we therefore hypothesize that program synthesizers
may capitalize on this synergy by utilizing both kinds of information, rather than settling for only one of the
two, as most existing methods have done. 3

Speciﬁcally, we formulate the following hypothesis:

Hypothesis: the eﬀectiveness of neural program synthesis may be improved by adding type informa-
tion as additional features.

2 Expected Contribution

The present work aims to be the ﬁrst experiment to:

• bring the type-based information traditionally used in functional program synthesis into the newer branch
of neural program synthesis, better constraining the search space to improve the eﬀectiveness of neural
program synthesis methods;

• show that the neural synthesis of statically typable programs may beneﬁt from techniques speciﬁc to this

domain, and therefore for the purpose of automatic programming merits further study in itself;

• oﬀer an open-source implementation of the algorithm described in Parisotto et al. [76];

• generate a dataset for neural synthesis of functional programs, and lay out how to do this, including an

open-source implementation, addressing the current reliance on hand-crafted curricula [50].

3 While one might wonder if this constrains our idea to the subset of PBE problems where type information is available, this
limitation is essentially meaningless: when one has input-output examples in a programming language supporting type inference,
one would already have the types of these input-output examples. This would render our idea applicable for practically any (neural)
methods for PBE.

6

3 Literature review

To provide some background to our hypothesis, we will use this section to ﬁrst give a brief overview of how
programming by example (PBE) ﬁts into the broader picture of program synthesis, as well as what existing
approaches there have been to PBE, including the neuro-symbolic program synthesis model we build upon
ourselves.

On types of synthesizers, Gulwani et al. [36] introduce a taxonomy based on three key dimensions:

• the kind of constraints that it accepts as expression of user intent;

• the space of programs over which it searches;

• the search technique it employs, i.e. the synthesizer.

User intent in program synthesis can be expressed in various forms, including logical speciﬁcation [28]
(among which types [80]), input-output examples, traces, natural language [85], partial programs, or even
related programs. [36]

While the common thread in program synthesis is that our intended output takes the form of a program,
sub-branches of this ﬁeld are primarily deﬁned by the types of input we use to come to this output, i.e. the ﬁrst
point in the above classiﬁcation.

We will brieﬂy describe such variants of program synthesis in the next section, with some minor focus on
search technique as inﬂuenced by this problem description. Search technique we will explore in further depth
for PBE in Section 3.2.

3.1 Types of program synthesis

Program synthesis was traditionally studied as a computer science problem, where the problem was typically
framed using a formal speciﬁcation. This problem was then tackled using e.g. an enumerative search, deductive
methods, or constraint-solving techniques. [36] However, such formal speciﬁcations ended up about as hard to
write as the original program, rendering this approach to the problem not very useful.

Closely related to this ﬁeld is the idea of synthesizing a program solely from its type signature. [7, 80]
Traditionally types would make for inductive synthesis, i.e. only making for an incomplete program speciﬁcation,
but this may end up not suﬃciently expressive: while certainly constraining the program space, input/output
examples may still be needed to disambiguate between potential candidate programs. Adding such examples
brings us to the branch of type-theoretic PBE, which we will introduce in further detail in Section 3.2.1. Program
synthesis approaches using types have commonly focused on using functional programming languages as the
synthesis language. [80, 25, 73, 72, 31, 13, 63]

There have also been attempts to get such a type-based approach to become closer to deductive synthesis, i.e.
making for a complete behavioral program speciﬁcation, through the use of e.g. the more expressive reﬁnement
types [80] or succinct types [38]. However, these approaches tend to fall into a similar pitfall as synthesis from
formal speciﬁcations, requiring the user to write such a detailed type speciﬁcation that they might have as well
just written the program directly. 4

Compared to formal speciﬁcations, it was found that for users, input-output examples were a more attractive
way to specify desired program behavior. [11] This ﬁeld is named programming by example (PBE). As the
speciﬁcation is incomplete here, PBE is considered inductive synthesis, as opposed to the deductive synthesis
where we do have a complete speciﬁcation. In other words, from the perspective of the synthesizer, PBE is
generally a more diﬃcult problem.

PBE may be further split up according to the type of program to be synthesized [11], generating logic
programs (assigning truth values to variables), or generating functional programs (e.g. Lisp, Haskell). PBE
too has branches based on deductive techniques (including type-theoretic PBE), inspired by synthesis from
formal speciﬁcations. Our work will focus on PBE in the category of functional programs, where the goal is to
automate traditional programming tasks.

Synthesis from program traces [56], and the related synthesis from Linear Temporal Logic (LTL) speciﬁca-
tions [17], are about a system reacting to sequences of inputs to mimic the desired program behavior. These
are useful for e.g. specifying the expected behavior of user interfaces. Essentially this task may be viewed as a
generalized version of PBE, adding the additional challenge of ﬁguring out which inputs triggered which state
changes.

4 However, perhaps one might instead also be able to synthesize this detailed type speciﬁcation, giving the beneﬁt of additional

formal guarantees from our actual program that we could then synthesize from this type speciﬁcation!

7

3.2 Existing approaches to programming by example

PBE has traditionally known heuristics such as Version Space Algebras (VSAs) [64], which aim to constrain
grammar productions by using candidate elimination to keep track of a hypothesis space. Another useful tool
is ambiguity resolution, i.e. requesting user input to resolve ambiguity in the event that multiple candidate
programs fulﬁll the given input-output example pairs. [36] However, these two techniques are primarily used to
complement other methods we will introduce here now.

It must be noted that program synthesis has been somewhat diﬀerent from other branches of machine
learning, such as image recognition: although there have been competitions like the Syntax-Guided Synthesis
competition (SyGuS-Comp) [75], unfortunately the ﬁeld has been so diverse that there has been only limited
standardization of benchmarking tasks to compare approaches, as ImageNet [23] had done for computer vision
tasks.

While this means we will not present statistics comparing the performance of these various approaches, we

will instead lay out their conceptual diﬀerences and weaknesses.

3.2.1 Search-based programming by example

Under search-based methods for programming by example we will classify any approaches that do not involve
learning to synthesize by means of a neural component. While the approaches in this category range from naive
to sophisticated, they unfortunately share a common drawback: whereas neural synthesizers allow one to tweak
a loss function to take into account various sub-goals, non-neural synthesizers have no sense of learning from
existing programs or across problem instances, meaning they will have trouble achieving:

• generalizability [50];

• interpretability to humans (human source code bias, i.e. make generated code more similar to the way it

is written by humans) [50];

• synthesized program performance (as measured in e.g. raw CPU time) [91];

• an increase in synthesizer performance, as they must solve any new synthesis task essentially from scratch,
and could never have as much information to this end as a neural synthesizer, which may in fact be able
to use arbitrary learned features [70].

Enumerative search

The naive approach to synthesis would be to enumerate all the possible programs in our search space, and for
each one evaluate whether it satisﬁes our task speciﬁcation. This is called enumerative or depth-ﬁrst search
(DFS). As one might expect, such an approach does not generally scale well with search space size however.

Oracle-guided synthesis

One attempt to overcome the computational complexity of program synthesis has been oracle-guided synthe-
sis [96], which splits the synthesis task into generating and ﬁlling of program sketches [67]. Unlike full synthesis
itself, sketch ﬁlling is not a second-order but a ﬁrst-order logic problem [36], enabling the use of constraint-
solving methods such as satisﬁability (SAT) or satisﬁability modulo theories (SMT) solvers (which combine
SAT-style search with theories like arithmetic and inequalities) [3, 4, 5, 101, 109] to ﬁll sketches, potentially
further extended with conﬂict-driven learning [26, 68], which helps backtrack if the branch explored turns out
unviable. The point here is that if a given sketch has multiple holes, once a ﬁlled version turns out unviable
due to a certain production rule used for one of its holes, other variants involving the faulty choice in question
may be ruled out as well.

This synthesis method has also spawned a solver-aided language designed to facilitate this type of program
synthesis [101], which generates satisﬁability conditions for satisfactory programs based on failing input-output
examples such as to synthesize program repairs.

Deductive techniques

Deductive search techniques for PBE were inspired by techniques used in synthesis from formal speciﬁcations, but
have been applied to the inductive task of PBE as well. Deductive techniques are based on theorem provers, and
recursively reduce the synthesis problem into sub-problems, propagating constraints. These include approaches
based on inverse semantics of domain-speciﬁc language (DSL) operators and type-theoretic PBE.

The idea of inverse semantics is to reduce the complexity of the synthesis task by using inverse logic. [83, 35]
This is a top-down search where we would take a grammatical production rule, presume it to be our outer

8

expression, and use its inverse logic to propagate our original input-output examples to its sub-expressions.
This way we have obtained a simpler sub-problem to solve.

While this is a useful search technique however, its use is unfortunately limited to invertible operations,

rendering this a helpful complement to, yet not a reliable alternative to other PBE methods. 5

Type-theoretic deductive search is about the use of programming types to constrain the synthesis search

space.

While in Section 3.1 we noted such purely type-based approaches fell into the pitfall of requiring the user to
write a type speciﬁcation similar in complexity to the actual program itself, this branch is nevertheless useful
in combination with other methods, and the use of type-theoretic deductive search has been combined with
PBE. [74]

3.2.2 Neural programming by example

More recently, PBE has been explored using machine learning approaches as part of neural program synthe-
sis. [50] Whereas traditional approaches in program synthesis (and particularly PBE) focused on constraining
the large discrete search space, such as deductive and constraint-solving approaches, neural program synthesis
generally uses autoregressive [53] methods, i.e.
incrementally generating programs with each prediction step
depending on the previous prediction result. Neural synthesis models use continuous representations of the
state space to predict the next token, be it in a sequential fashion [86, 93, 78], or in a structured one based on
ASTs [76].

Unfortunately though, program synthesis in its general sense has been less straight-forward to tackle by
neural methods than some other AI problems, as like in natural language processing (NLP), our search space
is typically discrete, meaning we cannot simply apply gradient-based optimization such as stochastic gradient
descent (SGD). [50]

The issue here is that, in order to learn the parameters of a neural network, SGD uses the gradients available
in a continuous search space to evaluate in which direction to adjust its parameters. However, our program
synthesis setting does not have an inherent continuous space: it does not make sense to ask e.g. what program
is half-way in between x + x and x · x.

As such, in discrete settings we lack this required notion of gradients: while we might evaluate the quality
of diﬀerent programs, we may not have intermediate programs to evaluate the quality of a given optimization
direction.

This problem can be worked around in diﬀerent ways:

• Using a diﬀerentiable interpreter to directly enable gradient-based optimization. [87, 30, 103, 27, 88, 1]
However, while only empirical evidence is available to compare this approach, as per Gaunt et al. [30] such
purely SGD-based methods so far appear to have proven less eﬀective than traditional or mixed methods
such as linear programming, Sketch [96] or SMT.

• Using strong supervision, i.e. create a diﬀerentiable loss signal to supervise synthesis training by checking
if the synthesized program is identical to the target program, rather than if it has equivalent behavior.
This approach unfortunately simpliﬁes our problem too much 6, but does make for a relatively simple
setup.

• Using weak supervision [60], which tends to address the problem of reward diﬀerentiability by using
reinforcement learning techniques to estimate a gradient to optimize by [19, 15, 107, 17], so as to learn
to synthesize by trying based on program performance rather than from direct supervision signals. This
approach solves the issues of supervised neural synthesis, but requires a more complex setup. This typically
involves bootstrapping on strong supervision to overcome the cold start problem of ﬁnding an initial reward
gradient.

• Using neural methods in a hybrid setup. This approach is explored further in Section 3.2.2.

5 A recent potential workaround not reliant on invertability has been the approach by Odena and Sutton [70], who would,
given properties of a function composition f ◦ g and of f , use machine learning to predict the properties of g. However, it is not
immediately clear if this technique has a straight-forward equivalent in the domain of input-output examples.

6 In reality, we wish to condition our model to synthesize not just the known programs, but to generalize to learn to synthesize
unknown programs matching our task speciﬁcation as well. Supervising by a given ‘known correct’ program instead tells our model
that other programs matching our speciﬁcation somehow do not qualify as correct.

As a result, such supervision requires that the training dataset provides a representative sample of our full program space:
training on the full program search space ensures that such bias from individual samples should be approximately averaged out.
This assumption is broken however for datasets much smaller than the program space, meaning that this approach does not scale
well to bigger search spaces. [76]

9

Sequence-based neural program synthesis

Neural synthesis methods typically employ sequence-to-sequence (or simply seq2seq) techniques [86, 93, 78], such
as the recurrent neural network (RNN) [89] and long short-term memory (LSTM) [41], leveraging techniques
commonly used in NLP to represent program synthesis as a sequence prediction problem.

Such sequential neural synthesizers have been extended with mechanisms such as convolutional recur-

rence [47], attention [9, 105, 54], memory [32, 57, 69, 6], function hierarchies [86, 59], and recursion [16].

However, while a hypothetical synthesizer only producing compilable programs would always have direct
feedback to its program embeddings, this feedback signal is much delayed if a synthesizer would gradually
synthesize a program e.g. one character at a time, only learning about resulting program behavior once the
program is complete.

As such, sequence-based neural techniques must learn quite a lot: in addition to (continuous logical equiva-
lents of) the traditional compiler tasks of lexing input into token categories, parsing these token sequences into
hierarchical structures (ASTs), and interpreting these to execute them as programs, these synthesizers must
additionally learn how to construct and update a (memorized) state so as to ultimately, when the synthesizer
considers its code complete, obtain a correct program.

In addition, for our purposes, in sequence-based neural synthesis techniques, any given intermediate pre-
diction does not necessarily itself qualify as a program in the grammar, meaning we are not able to apply a
type-based analysis to gain further info for use in further synthesis steps.

Tree-based neural program synthesis

More recently, there have also been approaches framing program synthesis by representing programs as ASTs
rather than as sequences [81], allowing such methods to use tree-structured networks.

While we previously mentioned the issue of sequence-based neural methods lacking an inherently meaningful
incremental state, tree-based methods should at least result in an (incomplete) abstract syntax tree (AST). This
is signiﬁcantly easier to learn to embed given the knowledge of how to embed a complete AST than it would be
to embed a program that does not even parse, as the unﬁlled dummy nodes or holes may simply be added as
an additional AST symbol to embed.

Of particular interest to us in this category has been the work of Parisotto et al. [76], which we will introduce

in more detail in the next section.

Neuro-symbolic program synthesis

The neuro-symbolic program synthesis (NSPS) model introduced in Parisotto et al. [76] is the model we will
build upon for our own experiment, so we will explain it in more detail here. The reason we picked NSPS as
our benchmark algorithm in particular is that there have been only few neural synthesizers out there based on
abstract syntax trees (ASTs) rather than sequences.

NSPS is named after the fact that it uses programming symbols as neural features, allowing it to combine
symbolic and neural approaches. NSPS improves on existing sequence-to-sequence-based neural synthesis models
by using a tree-based neural architecture they call the recursive-reverse-recursive neural network (R3NN).

NSPS then aims to make predictions on credible rule expansions to ﬁll holes in partial program trees (PPTs)
— basically ASTs containing holes — based on the program’s content and structure. As usual in neural PBE
NSPS also conditions on the (encoded) input/output examples, as seen in Figure 1. These hole expansions
are based on a context-free grammar describing the domain-speciﬁc language (DSL) to be synthesized. Such a
grammar consists of sets of expansions rules from left-hand symbols to productions in the grammar (which may
include further left-hand symbols).

(a) Training Phase

(b) Test Phase

Figure 1: overview of the Neuro-Symbolic Program Synthesis model, taken from [76]

Parisotto et al. [76] try out diﬀerent example encoders, each embedding into a continuous space a one-hot
representation of the input or output strings of their domain, i.e. for a vocabulary of ‘a’, ‘b’ and ‘c’, encode ‘b’

10

R3NNDSLR3NNI/O EncoderR3NN...DSLDSLProgram SamplerDSLInput GenRulesi1–o1i2–o2…ik–ok{p1i1–o1i2–o2…ik–ok{pji1–o1i2–o2…ik–ok{pn…pj,0pj,1pj,2pj…R3NNDSLR3NNI/O EncoderR3NN...DSLDSLLearnt programi1–o1i2–o2…ik–okas 010, meaning the second option out of three. They start out with a simple LSTM baseline, then introduce
diﬀerent variants based on the cross-correlation [12] between inputs and outputs.

The baseline sample encoder processes input/output strings of example pairs using two separate deep bidi-
rectional LSTM networks, one for inputs, one for outputs. For each I/O pair, it then concatenates the topmost
hidden representation at every time step to produce a 4HT -dimensional feature vector per I/O pair, where T
is the maximum string length for any input or output string, and H is the topmost LSTM hidden dimension
It then concatenates the
controlling the amount of features we would like per one-hot encoded characters.
encoding vectors across all I/O pairs to get a vector representation of the entire I/O set. [76]

(a) Recursive pass

(b) Reverse-Recursive pass

Figure 2: (a) The initial recursive pass of the R3NN. (b) The reverse-recursive pass of the R3NN where the
input is the output of the previous recursive pass. Illustrations taken from [76].

The workings of the R3NN are illustrated in Figure 2. The R3NN utilizes two parallel sets of neural networks,
fr and gr, both consisting of one neural net per grammar production rule r ∈ R. In the diagram these are
denoted by W (r) and G(r), respectively, with r calculated as production rule R(n) of non-leaf node n. or
determined by its symbol s ∈ S at any leaf l ∈ L, where s represents an operator in our grammar, calculated
by S(l). These two sets correspond to the R3NN’s two passes through an AST (explained below). Their neural
networks use a single layer with hyperbolic tangent activation function (denoted by σ).

R3NN deﬁnes a hyperparameter M indicating the number of features used in their embeddings. It uses this
in an embedded representation φ(s) ∈ RM for every operator in the DSL (e.g. +), which they refer to as symbols
s ∈ S, as well as in a representation ω(r) ∈ RM for every production rule r ∈ R.

The R3NN ﬁrst makes a recursive pass from the embeddings φ(l) of leaves l ∈ L of the program tree
gradually toward the root node of the partial program, making for an embedding φ(root) of the full program
so far. Given a number of child nodes Q of the branch in question (as dictated by the grammar expansion rule
it represents), this recursive pass goes through neural networks fr at each branch, mapping from Q · M to M
dimensions, i.e. from concatenated right-hand side (RHS) vectors to a left-hand side (LHS) vector.

It then performs a reverse recursive pass from this root embedding φ(root), now passing back to the leaves
through gr, one of a second set of neural networks, mapping back from M to Q · M dimensions, i.e. from a LHS
vector back to concatenated RHS vectors φ(cid:48)(c) for any node c, which now have their individual embeddings
instilled with structural information about the entire program and how they ﬁt into this larger structure.

In the event a node c constitutes a non-leaf node n, this process is then repeated, until reaching leaf
embeddings φ(cid:48)(l). Such leaf embeddings φ(cid:48)(l) are now diﬀerent for leaf nodes sharing the same symbol, while
before these two passes their original embeddings φ(l) would have been identical.

Parisotto et al. [76] deﬁne an expansion e ∈ E as a combination of a hole (non-terminal leaf node) e.l and
a grammar production rule e.r, together making up for a way we can expand our PPT. Expansion scores of an
expansion e they deﬁne as the dot product of their respective embeddings: ze = φ(cid:48)(e.l) · ω(e.r).

These scores are then normalized to probabilities using a softmax operation. They ﬁnd processing leaf
embeddings φ(cid:48)(l) by a bidirectional LSTM [43] before the score calculation helped as well. To condition R3NN
expansion probabilities on the input-output examples specifying desired program behavior in PBE, they con-
catenate them to the node features φ before the recursive pass.

For the training phase they use the strong supervision (see start of Section 3.2.2) setup of supervising by
the task function, i.e. the function we aim to synthesize, while for the test phase they sample 100 programs
from their trained model. They consider the synthesized program to have passed if any of these demonstrate
the correct behavior on the input/output.

As this is a strongly supervised model, the loss J (task)

P P T predicting one hole-expansion for a task function
task given a partial-program tree P P T is deﬁned as the cross-entropy between our predicted probability matrix
ˆPP P T (over holes H and expansion rules R) versus the golden ‘probabilities’ P(task)
P P T as per the task function
we are supervising against, i.e. a matrix that for each hole is deﬁned as a one-hot vector marking the chosen

11

expansion rule as 1, the remaining expansion rules as 0:

P P T = CE(P(task)
J (task)

P P T , ˆPP P T ) = − EP(task)

P P T

[log ˆPP P T ]

If the task function consists of more than a single node, then we will obtain such a loss for every such
prediction step (each starting from their own P P T ). Note that the P P T we start from in a prediction step is
carried over to inform our next rule expansion. Informing our current prediction using previous predictions in
such a way makes the model autoregressive [53].

Some critiques of the model have included it being harder to batch (i.e. enable parallel execution) over
multiple task functions for larger programs due to its tree-based architecture, as well as its pooling at the I/O
encoding level being harder to reconcile with attention [8] mechanisms. [24]

For our purposes, by merit of the untyped Microsoft Excel FlashFill [35] domain this model was tested on, it
also shares a weakness with other neural synthesis models: as neural synthesis models have usually been applied
to untyped domains, they have not been augmented to use information on types, while existing type-theoretic
synthesis approaches have shown this info to be highly valuable.

Neural-guided search

Neural-guided search is an another approach to hybrid neural synthesis, and like Parisotto et al. [76]’s neuro-
symbolic program synthesis model combines symbolic and statistical synthesis methods [50]. It employs neural
components to indicate search order within traditional search methods such as enumerative search (possibly
pruned using deduction), ‘sort-and-add’ enumeration or sketch ﬁlling. [10]

Kalyan et al. [49] built on this to extend the guidance to each search step, integrating deductive search (e.g. a
SAT/SMT solver, extensions like conﬂict-driven learning [26]), a statistical model judging generalization, and a
heuristic search controller deciding which of the model’s suggested branches to explore (branch-and-bound [49],
beam search [81], A∗ [58]). The statistical model mentioned here is where other neural synthesis methods would
ﬁt into this approach.

Feng et al. [26] expanded on neural-guided deductive techniques like SMT solvers by conﬂict-driven learning,
ensuring that if e.g. a map operation would yield an output list length not corresponding to the desired length,
other operations suﬀering from the same issue such as reverse and sort would be automatically ruled out as
well.

Zhang et al. [108] focus on incorporating deduced constraints into the statistical model, to allow taking this
info into account in the decision of which branches to focus on. Another similar eﬀort has been that of Odena
and Sutton [70], which adds additional features describing properties of a function. Types however have so far
been missing here.

Compared to other neural methods, neural-guided search seems more of a complementary than a competing
eﬀort. The engineering involved to conciliate the beneﬁts of diﬀerent approaches here may be quite involved,
and as such are likely less common in research papers comparing neural components, but their beneﬁts in
production systems seem clear.

12

4 Background

In order to test our hypothesis, we would like to still quickly explain two additional topics before moving on to
our own methodology: lambda calculus, which forms the basis for a simple DSL, as well as static typing, which
is the topic of our investigation within neural program synthesis.

4.1 Lambda calculus

Whereas modern programming languages might have a broad plethora of grammatical constructs available, for
the purpose of our proof-of-concept we will opt to hide much of this.

Types are most powerful in a setting where the underlying DSL is loosely-constrained, that is, permits
arbitrary type-safe combinations of subexpressions, such that checks be deferred from the grammar to the type
level. In other words, to keep things simple, our DSL should ideally support such a notion of an expression, but
preferably as little else as possible.

This brings us to the lambda calculus [20], the simplest [94] Turing-complete [102] grammar in terms of
number of grammar expansion rules. The lambda calculus requires only three grammatical categories: variables,
function deﬁnition, and function application (in notation further adding parentheses to indicate structure).

With this lambda calculus, we now have a solid basis for a simple expressive grammar that allows us to

defer most checks from the grammar to the type level. 7

4.2 Complementing synthesis grammars with static typing

One might note here that traditionally, search spaces in program synthesis have been restricted primarily
using the generally available context-free grammars, as in the Syntax-Guided Synthesis competition (SyGuS-
Comp) [75], rather than additionally doing so using types, which may only be available in certain DSLs. One
might wonder: how then might adding restrictions based on types compare to solely relying on restrictions
imposed by a grammar?

In a type system consisting only of unparametrized types, such as boolean or integer but not list of booleans,

restraining a search using types is in fact equivalent to a grammar where types are used as left-hand symbols
in the grammar.

However, what makes the use of types diﬀerent from, and more powerful than grammars in restricting the
search space, is the use of parametric polymorphism, i.e. availability of type variables: a function append may
work using either lists of numbers or lists of strings. As such, its type signature may be made generic such as
to have its return type reﬂect the types of the parameters used.

Having such information available at the type level may add additional information over what is used in the
simpler case above. For example, a function to look up elements in a list based on their respective locations
might take as its inputs one list containing any type of element, along with a second list of integers containing
the indices.

Now, in a context-free grammar, such distinctions could not be expressed in a meaningful way: such a
grammar would quickly explode to the point of no longer remaining a reasonable abstraction to a human
observer. As such, one may regard the reliance of types over a grammar for the purpose of restricting the search
space as a generalization of solely relying on a grammar for the purpose of restricting the search space.

We may therefore use types to prune out additional programs that are not sensible, i.e. would not pass
a type-check. This way types may help us restrict the synthesis search space, as per our hypothesis thereby
improving synthesis performance.

7 As an interesting coincidence, using this as the basis of our synthesis target language means we will use an implementation of

Church [20]’s lambda calculus to address Church [21]’s problem of synthesizing programs.

13

5 Methodology

In this section we will discuss our program synthesis model, which applies type information to improve synthesis
quality in programming by example.

We further explain how this synthesizer builds upon the work of Parisotto et al. [76], explain the functional
programming synthesis DSL we use with this to exploit its features, as well as how we generate datasets in
order to obtain training and test sets in our DSL.

To explain the design decisions we made, we will go by the synthesizer taxonomy of Gulwani et al. [36]
introduced in Section 3. The ﬁrst two criteria, i.e. constraints on expressions of user intent and search space,
together give the background needed to understand both our dataset generation method as well as the synthesizer
itself.

We will therefore ﬁrst explain our design decisions with regard to these, then continue to lay out the design

of our dataset generation method and synthesizer.

One should bear in mind that our goal here is not to create the perfect production-ready synthesizer; instead
we will aim to answer each of these categories with the question: what is the simplest way in which we might
eﬀectively test our hypothesis?

5.1 User intent

For our expression of user intent, we would like to use input-output examples, which may be considered a
compromise between what is easier for the end-user, who may ideally prefer natural-language descriptions
of program behavior, versus what is easier for the synthesizer, which may ideally prefer a complete formal
speciﬁcation of program behavior.

This puts us in the ﬁeld of programming by example (PBE), which has a broad area of application despite

being conceptually simple.

To (1) reduce ambiguity, (2) increase result quality, and (3) speed up synthesis, a synthesizer may be passed

more information in various ways:

• additional data within the same mode of user intent, e.g. further input-output examples;

• an additional expression of user intent of a diﬀerent type, e.g. a natural language description [81] or type

signature of the desired function [74];

• more descriptive types [80];

• additional features describing properties of the function [70].

Of interest here is the realization that, in modern programming languages, types may be inferred even
without explicit type annotations. This is then a hidden beneﬁt of synthesis from input-output examples: if the
types of input-output example pairs may be inferred, then we may regard this as free additional information we
can incorporate in our synthesis process. Optionally letting users explicitly clarify their desired function type
may further help ensure a suﬃciently widely-applicable function.

5.2 Program search space

The program search space consists of the synthesis language (deﬁned by a context-free grammar ), either general-
purpose or a domain-speciﬁc language (DSL), potentially further restricted to a subset of its original operators,
such as by providing a whitelist of operators.

The trade-oﬀ here is one of expressiveness (achieve more with less code) versus limiting our search space

(ensure we can ﬁnd a solution within too long).

So, how does this ﬁt into our question on reaching a conﬁguration that could best demonstrate the use of
types? Now, providing empirical evidence on how every design choice impacts the usefulness of type information
is not in scope for this thesis, as just any one good conﬁguration may suﬃce to demonstrate our hypothesis.
Instead, we will make informed guesses to pick our language, grammar subset and operator set.

Not having empirical evidence to guide our design decisions upfront, however, we appear free to take some
guidance from program search space considerations to generally improve synthesis eﬃciency: how might we
achieve the highest amount of expressiveness within a limited search space? The answers we have found to this
question, we argue, is intuitively in line with a program search space designed to demonstrate the utility in
synthesis of type information.

Under this goal, it would seem preferable to pick a limited grammar in the functional programming paradigm.

In the following sections we will lay out how we have reached this conclusion.

14

5.2.1 The functional programming context

The functional paradigm, named after the use of functions in mathematics, has been characterized by its
composability or modularity [44], which is key in the creation of synthesizers that generalize well, as it encourages
reusing existing abstractions to allow for a large expressivity using only a small vocabulary, matching our
synthesizer search space requirement of maintaining expressiveness while limiting our search space.

In addition, functional programming oﬀers various general-purpose programming languages, which helps
potentially make our synthesizer potentially applicable to a wide variety of domains. It is also well amenable
to programming types, which help reduce the search space in program synthesis.

The basic abstraction in functional programming is the function. This means we would view our synthesized
programs as being and consisting of pure functions [45], i.e. returning a deterministic output for any given
inputs, without performing any additional side eﬀects. 8

One may well regard programs in this paradigm as constructed of a (nested) tree of function applications.
One reason we would like to consider such programs of a tree-based form, rather than as a list of imperative
statements such as variable deﬁnitions or mutations, is that the view of programs as function compositions
guarantees us that any complete type-checking program from the root, ﬁltered to the right output type, will
yield us output of the desired type, helping us reduce our synthesis search space to a sensible subset, devoid of
e.g. programs containing variable deﬁnitions that end up never being used.

This guarantees that, rather than just branching out, our search will focus on ﬁnding acceptable solutions.
This is to be contrasted with imperative programs, a coding style characterized by variable mutation. Synthesis
for such languages unfortunately does not support the use of e.g.
type-theoretic approaches, limiting the
synthesis methods we might use there while giving us less means to constrain our search space.

We will next discuss our decision on an actual synthesis language, followed by a further explanation on how

we adapt lambda calculus for our own synthesis grammar.

5.2.2 Synthesis language

Our synthesis language, or target language, is the language we would like for our synthesizer to generate. This
is as opposed to the host language, i.e. the language that our synthesizer is implemented in.

Neural synthesis methods have often used custom DSLs as the target language, while for the host language
typically using Python. For our purposes working with types however, it would be nice to be able to defer type
logic to an existing language.

This idea though would require our host language to be able to construct ASTs for, compile, and interpret our
target language, while also requiring the availability of a deep learning framework for our model implementations.
We conciliate these requirements by using Haskell [46] as both our host and target language, a statically
typed, purely functional programming language based on the lambda calculus and featuring type inference,
already in use in various non-neural synthesis papers. [80, 68, 73, 31]

For a deep learning framework, we evaluated Haskell ports of PyTorch [77] and TensorFlow [2]. At the
moment of choosing, one Haskell port of PyTorch, named HaskTorch [42], turned out signiﬁcantly more active,
and along with its welcoming and helpful community solidiﬁed our choice.

5.2.3 Grammatical subset

Our synthesis DSL only requires a subset of the functionality in the lambda calculus, that is, function application
and referencing variables, though without function deﬁnition.

For the purpose of expressing partial programs, one feature missing in the lambda calculus that we will need

to add in our DSL is that of holes, i.e. placeholder nodes in the AST to be ﬁlled by the synthesizer.

An attempt to express our DSL as a context-free grammar, taking inspiration from the notation of extended

Backus–Naur form (EBNF) [97], might look as follows: 9

expr = "(", expr, ") (", expr, ")";
expr = <any variable contained in our whitelisted operators>;

8 These properties of determinism and lack of side eﬀects are generally taken as prerequisites in programming by example, as we

will verify program behavior by comparing the output of our synthesized output to that of our original task function.

If non-determinism came into play, forcing us to test samples of our stochastic function output, we would need to extend our

synthesis domain to something that could well be called synthesis by property instead.

Synthesizing functions with side eﬀects instead appears closer to the domain of synthesis from traces, where the synthesis

speciﬁcation instead consists of a description of such triggered side eﬀects as a function of various user inputs.

9 One may note that function application here is unary in its number of parameters, as it is in Haskell, meaning that multiple-
parameter functions must be emulated using a chain of such applications. Parisotto et al. [76]’s R3NN, however, presumes nodes
may in fact have multiple child nodes.

Using the R3NN on our DSL then means that we must break Parisotto et al. [76]’s original assumption that each branch node
itself corresponds to one rule expansion, as rule expansions may in our case then span multiple AST branch nodes. Despite this
shift, the theory of R3NN still applies, however.

15

As such, given an operator list consisting of operators and and false, we would then obtain the following

EBNF:

expr = "(", expr, ") (", expr, ")";
expr = "and" | "false";

Now, in practice, we would like to support the use of diﬀerent operator sets rather than just the one hard-
coded for illustrative purposes above, so it is fortunate we did not need to ﬁx these at the grammar level
itself.

However, this simple grammar can unfortunately still generate some bad programs:

• programs where the argument of a function is not of the right type. This class of mistakes we are no
longer able to reliably solve at the grammar level due to our polymorphic parametrism. Instead, we wish
to defer this kind of check to the type level.

• programs where the arity of a given operator is not respected, i.e. by invoking more function applications

than we up-front know are supported.

The latter problem we can deal with in either of two ways:

• we ignore the problem by deferring it to the type-level, providing a solution consistent with how we handle

problems of the former type.

• we reframe the grammar by statically unrolling any provided operators such as to ensure only valid

function arities are supported.

We consider the second option to be preferable from the perspective of a type-based synthesizer; although
this would expand the number of production rules in the grammar, diﬀerent numbers of function application
for a given operator yield diﬀerent result types. For a type-based synthesizer, distinguishing these makes sense,
as this distinction should facilitate learning.

While this poses limitations in terms of supporting arity-agnostic operators such as the argument ﬂipping
and function composition combinators, we will consider this as suﬃcient for the purpose of our present paper.
As an example, let’s say our operator list again contains the two operators from above, one operator false,
a variable that does not describe a function, and thus takes no arguments, and one operator and as a function
as per lambda calculus curried to take at most two arguments,

Such a curried function allows arguments to be applied one at a time. The way this works is that, when
an argument is applied to a curried form of a function taking two parameters, the result is a function that still
takes one parameter, before yielding the actual result of the original function.

Our unrolled grammar would then look as follows:

expr = "(and ", expr, " ", expr, ")";
expr = "(and ", expr, ")";
expr = "and";
expr = "false";

It must be noted that context-free grammars like the above describe how to generate full programs in the
associated grammar. However, in partial programs, we express holes or unresolved expr symbols as using the
dummy variable of undefined (which in our Haskell context passes compilation unlike the built-in hole ‘ ’):

expr = "(and ", expr, " ", expr, ")";
expr = "(and ", expr, ")";
expr = "and";
expr = "false";
expr = "undefined :: ", <type>;

This grammar is not technically a valid EBNF, as we have deferred specifying the type. This is not a
coincidence: the type actually depends on the entire program tree. In other words, our grammar productions
are dependent on context, meaning our grammar is not actually context-free.

As such, context-free grammar notations such as EBNF cannot fully express our production rules inclusive
of hole types. Any implementation however might use the synthesis language’s type inference, in our case built
into Haskell, in order to calculate these types.

16

task function
type instance parameter input types
type instance output type
input expression
output expression

let just = Just; compose = (.) in compose just unzip
[(Int, Char)]
Maybe ([Int], [Char])
([((17), ’0’), ((20), ’2’)])
Right (Just ([17, 20], "02"))

Figure 3: A task function instance from our dataset with a corresponding sample input/output pair.

5.2.4 Operator whitelist

Our synthesis approach itself is agnostic to the set of operators used, allowing for relatively straight-forward
experimentation with diﬀerent sets of operators. Adding new operators simply involves generating a new dataset,
then retraining the model.

We will further expand on our operator set in Section 6.

5.3 Dataset generation

As we were unable to ﬁnd existing datasets in the functional program synthesis domain of a size appropriate
for training a neural model, we have opted to instead generate a dataset of our own.

As the potential space of viable programs is potentially unbounded, we instead opt to artiﬁcally limit the

space to generate from.

Our main goal in creating a dataset consists of generating the programs to be synthesized, alongside the
input-output data we would like to use to synthesize them from (as per our PBE setting). Now, the inputs here
are generated, whereas the outputs are obtained simply by running these inputs through our programs.

However, as our programs may take parameters of parametric types, e.g. list of any given type [a], we take
the intermediate step of instantiating such types to monomorphic types, i.e. types not containing type variables
themselves, which we may then generate inputs for.

Note that to make our task easier, we further maintain such a separation by type instances for our generated
programs, meaning that a potential identity function in our dataset might be included in our training set under
type instance Int → Int, then perhaps in our test set under another type instance like Char → Char. We may
sometimes still refer to just task functions however, as the distinction is not otherwise relevant.

An example showing what diﬀerent components of our dataset items might look like may be found in Figure

3.

Our full generated dataset consists of the following elements:

• the right-hand symbols or operators we allow in our DSL, to be detailed in Section 6.1;

• the types of any task function in our dataset;

• sample input-output pairs for diﬀerent type instances of our task functions;

• a split over training/validation/test sets of any of our tasks, i.e. type instances for a given task function;

• pairs of symbols in our DSL with their corresponding expansion rules (including type annotations for

holes);

• types of any expansion rules in our DSL;

• NSPS’s maximum string length T , based on our stringiﬁed input-output examples (also taking into account

types for the augmented model);

• mappings of characters to contiguous integers so we can construct one-hot encodings covering the minimum

required range of characters (tracked separately for input-output, types, and either);

• the conﬁguration used for data generation to make data reproducible, discussed further in Appendix

section A.1;

• the types we generate to instantiate type variables, again for reproducibility purposes, separated by arity

based on the number of type parameters they take.

A brief overview of how to generate such a dataset to train our synthesizer on is shown in Algorithm 1.
We ﬁrst generate our expansion rules by unrolling each operator in the dataset as described in Section 5.2.3,

using a diﬀerent number of holes corresponding to any applicable arity.

To create our dataset of task functions, we start from an expression consisting of only a hole, then step by
step generate any type-checking permutation by ﬁlling a hole in such an expression using our expansion rules.

17

Algorithm 1 dataset generation

s

given: expression space E, operators or symbols s ∈ S ⊂ E, expansion rules rs ∈ R ⊂ E, programs p ∈ E,
types t ∈ T , monomorphic types t(m) ∈ T (m) ⊂ T , input expressions i ∈ E, output expressions o ∈ E,
parameters a;
calculate expansion rules r(1,...,n)
generate any possible program p given expansion rules ∀s : r(1,...,n)
sample monomorphic types t(m) ∈ T (m) up to a max number and within a given nesting limit;
generate instances t(m)
types t(m);
sample type instances t(m)
generate sample expressions i(1,...,n)

for each generic non-function parameter types ∀p : ta(1,...,n)

for each non-function parameter type instance t(m)

for each function type ∀p ∈ E : tp up to a given number;

from s ∈ S by unrolling our grammar symbols;

∈ Rn and a max number of holes;

given sampled

, up to a

a(1,...,n)
p

p

s

p

a(1,...,n)
p

t(m)
(1,...,n)
a
p

maximum each and within given value bounds;
calculate a ﬁltered map of generated programs p(1,...,n) ∈ E for each instantiated function parameter type
combination ∀ap : t(m)

by matching its type to obtain samples i(1,...,n)

for our function types;

a(1,...,n)
p

t(m)
(1,...,n)
a
p

for each task function instance t(m)

p

given a sample of generated inputs i(1,...,n)

t(m)

;

t(m)
p

calculate outputs o(1,...,n)
ﬁlter out program type instances t(m)
ﬁlter out any functions instances t(m)
sample task function type instances t(m)
calculate longest strings and character maps;
split our task function type instances t(m)

p

p

p without i/o samples (i, o)(1,...,n)

;

t(m)
p
p with i/o behavior identical to others to prevent data leakage;

from any remaining programs p;

over train, validation and test datasets.

We only ﬁll holes in a generated expression up to a user-deﬁned limit, disregarding any programs still containing
holes after this point.

Like Parisotto et al. [76] we uniformly sample programs from our DSL, based on a user-deﬁned maximum,
while still respecting the above complexity limits. We similarly use sampling for the generation of sample
input-output pairs and, for instantiating our type variables, monomorphic types, i.e. types not containing type
variables.

While we quickly mentioned type-checking programs to ﬁlter out bad ones, we had yet to expand on this
practice: we presently use a Haskell interpreter to type-check our generated programs at run-time, ﬁlter out
non-function programs (e.g. false), and check if program types look sane: to weed out some programs we
deem less commonly useful, we ﬁlter out types containing functions (e.g. list of functions), as well as types with
constraints that span more than a single type variable (e.g. (Eq(a → Bool)) ⇒ a). 10

As we cannot directly generate samples for types containing type variables, we ﬁrst instantiate any such
type variables using a ﬁxed number of monomorphic types we generate. We deﬁne a maximum level of type
nesting for such sampled types, to prevent generating types like ‘list of lists of booleans’. We further specify a
maximum number of types generated.

We then use these monomorphic types to instantiate any polymorphic (non-function) input types occurring
in our task functions. To simplify things, we restrict ourselves to substituting only non-parametric types (e.g.
In the event the
boolean yet not list of boolean) for type variables contained in a larger type expression.
type variables in our types involve type constraints, we ensure to only instantiate such type variables using our
monomorphic types that satisfy the applicable type constraints.

This yields us a set of monomorphic input types, for which we then generate up to a given maximum number
of sample inputs, although this may get less after ﬁltering out duplicate samples. We use hyperparameters to
indicate range restrictions for diﬀerent types here.

For any given given task function type signature, we then check for the types of each of their input parameters,

and take any corresponding combination of type instances in case of polymorphic types.

Now, for any non-function parameter types, we may just take the previously generated sample input-output
pairs for those types. Parameters with function types, however, we instead instantiate to function values by
just taking any of our generated task functions corresponding to that type.

Based on these sample inputs, we would then like to generate corresponding outputs for our generated task
functions. For our task functions that are polymorphic, i.e. contain type variables, we must do this separately
for diﬀerent type instances.

10 Programs not passing these checks are not necessarily invalid, but by our engineering judgement, are much more circumstantial
in their usage, making for only a smaller portion of valid programs, aggravating our search space problem. For this reason, we
would currently prefer for our synthesizer to focus on the region of our search space that we generally deem to be of higher interest.

18

We run our programs using our run-time Haskell interpreter. We catch run-time errors on speciﬁc inputs
such that we can regard these errors as just another resulting output that our synthesizer should consider when
comparing behavior between programs. In other words, a partial function, i.e. a function that only works on a
subset all inputs of the desired input types, may still constitute a valid program that we may wish to learn to
synthesize.

Having generated input/output examples for our task functions, we ﬁnally ﬁlter out any task function type
instances for which we have somehow failed to generate such samples. We moreover limit our dataset to a given
maximum.

At this point we:

• use a random split to divide our task function type instances over training, validation and test sets;

• calculate the longest input-output examples in our dataset (as string), when considering types (as per our
experiment) also taking into account the length of the string representations of such types of inputs and
outputs;

• track any characters used in string representations of the expressions in our dataset (for our type exper-
iment also those used in string representations of the types), and assign them to indices for our one-hot
encodings of input-output examples (and their associated types).

5.3.1 Preventing data leakage

One additional concern here is data leakage [39], which is the issue of a model being able to ‘cheat’ on its
predictions due to e.g. items shared between training and test sets.

Now, in supervised learning settings, one would typically ensure labeled samples would not be duplicated
across sets: if we train a classiﬁer on a cat picture, then evaluate it on this same cat picture, the classiﬁer could
simply remember the examples, rather than learning how to generalize in its task to unseen samples.

In programming by example on the other hand, the equivalent is not simply to ensure task function instances
are deduplicated across sets. Imagine we had two distinct task function instances exhibiting identical behavior:
if one were allocated to our training set, the other to the test set, then we have again created an opportunity
for our synthesizer to cheat: it could remember the program from our training set, then synthesize it during
evaluation.

While this program would not be the same, for the purpose of synthesis evaluation of accuracy, synthesizing
a function exhibiting the correct behavior already qualiﬁes as successful synthesis, as synthesizing one speciﬁc
function implementation is not the goal of programming by example.

Unfortunately, under the strong supervision used in our implementation, these two are conﬂated for the
purpose of calculating the loss. We avert this problem by ensuring no task function instances across diﬀerent
datasets share the same input-output pairs.

Now, one would then presume that as long as we then ensure that functions across diﬀerent datasets would

not share the same input-output pairs, this issue would be averted.

However, the reality is slightly more complicated still: presume we have an increment function mapping

input 0 to 1, along with a successor function mapping 0 to 1 and False to True.

If we would simply deduplicate by identical input-output pairs, we would conclude these functions to behave
diﬀerently, and would accept e.g. having the successor function in our training set, the increment function
in our test set.

This again leads us to a similar same problem however: our synthesizer could simply memorize how to
synthesize our successor function, then during evaluation use this knowledge to pass our increment synthesis
test. As such, the solution would be to ensure we cannot train on task functions exhibiting all of the behaviors
of a function we would evaluate on.

The way we tackle this in our implementation is to identify any such function pairs where either would fully
subsume the behavior of the other. For the sake of simplicity, we presently ensure that only one of any such
semi-duplicate set is kept in our dataset, rather than still allowing less general versions in our training set.

When deciding which task function instance of a similar pair to keep, we ﬁrst look for the more general
function (i.e. operating across more type intances as used in our dataset), otherwise look for the task function
with the shortest implementation (in terms of number of nodes), or ﬁnally, as a tiebreaker, arbitrarily keep
either of the two.

5.4 Search technique

5.4.1 Our adaptation of neuro-symbolic program synthesis

Type-based approaches typically call for a top-down search strategy. As such, we will need to build upon tree-
based (or AST-based) rather than sequential (or token-based) neural synthesis methods: we can apply types to

19

an AST containing holes, which we cannot do for arbitrary sequences representing a partial program.

As a benchmark algorithm we will therefore use the neuro-symbolic program synthesis method from Parisotto

et al. [76] introduced in Section 3.2.2, a top-down neural synthesis method.

For conditioning programs we use a (bidirectional) LSTM. We also use Parisotto et al. [76]’s bidirectional

LSTM processing global leaf representations right before score calculation.

Like them we also use the hyperbolic tangent activation function in the neural networks part of the recursive
and reverse recursive passes of the R3NN. As a place for input-output conditioning we use pre-conditioning
(adding embedded input-output examples before the recursive pass), which they report to work best.

While not indicated in their paper but only in a related patent [65], it appears the synthesizer was trained

using the Adam optimizer [55]. We follow this example.

As in the original paper, our evaluation on the test set involves sampling 100 programs using the synthesizer
(which may include duplicates), and considering the trial a success if any of these demonstrates the desired
program behavior. A more sophisticated alternative here might be to use a controller such as beam search [81].
For the purpose of calculating total loss for an epoch, we presently aggregate the loss over the diﬀerent
prediction steps by taking the mean of their respective losses, then similarly aggregate over task function
instances in our training set. Such losses across prediction steps for a task function instance potentially cover
a hole multiple times if it initially remains unﬁlled.

5.4.2 Functional program domain

Aside from the grammar we have described in Section 5.2.3, translating Parisotto et al. [76]’s synthesizer from
its original FlashFill [35] domain to our domain of functional programs, we have had to make the following
adjustments to their original algorithm:

While the input-output samples used by Parisotto et al. [76] were all strings, in our functional domain these
could essentially comprise arbitrary expressions. While ideally a synthesizer would respect the tree-like structure
of such expressions as ASTs, our naive approach has been to simply perform sample serialization here, taking
string versions of our actual input/output expressions, then one-hot encode the strings’ characters as Parisotto
et al. [76] did using their string samples.

In our functional setup, we distinguished potentially multiple type instances for each function, which may
depend on its type signature’s number of type variables, as well as on any potential type constraints on these
type variables.

While this does not pose a problem for our sample encoder, it did actually end up problematic for the
purpose of Parisotto et al. [76]’s R3NN, which conditioned programs on these sample features using an LSTM,
which expected a ﬁxed number of embedded samples. To work around this, we sample a ﬁxed number of i/o
pairs per task function instance during dataset generation.

We have chosen to sample without replacement for any sample sizes lower than the number of available
input-output example pairs, which oﬀers a lower stochasticity than sampling with replacement. In the event
we have less pairs available (e.g. 4) than we would like to sample (e.g. 10), we would ﬁrst take each available
pair while we still wish to sample more items than are available in the pool (i.e. ﬁrst sample the 4 available
pairs twice), then ﬁnally use sampling without replacement to uniformly sample the remaining desired pairs
(i.e. randomly pick 2 of the 4).

5.4.3 Types

We will now explain how we augment the NSPS model to incorporate type info. We also refer back to NSPS’s
hyperparameters T , H and M here, where T indicates the maximum string length for any input or output
string, H controls the amount of features per one-hot encoded characters, M indicates the number of features
the R3NN uses in its embeddings, ω(r) the production rule embeddings, and φ(s) the symbol embeddings.

Consistent with how we embed expressions, we similarly serialize types to strings, then one-hot encode their
characters as we do for input/output expressions. To get the most out of our types, we will want to provide
them for:

• inputs and outputs, which we simply incorporate as additional features in Parisotto et al. [76]’s example
encoder as explained in Section 3.2.2, concatenating their one-hot embeddings to those of the input/output
pairs before passing them through the input/output LSTMs, increasing the amount of features per sample
under their baseline LSTM encoder by another 4HT making for a total of 8HT features per sample;

• expressions from expansion rules r; for these we may calculate types statically upfront, then embed these
to obtain M · T features per expansion rule r ∈ R, and during R3NN prediction concatenate these features
to the existing representation ω(r) ∈ RM , yielding ω(cid:48)(r) ∈ RM ·(T +1).

• (hole) AST nodes c in any PPT. A proper attempt here would be based on type inference across the

program.

20

For the sake of simplicity, however, we will settle for simply using the hole’s parent branch node to obtain
its parameter type without type variables ﬁlled out, i.e. a local type that has yet to take into account
some of the type information available elsewhere in the PPT.

During prediction in the R3NN, we then embed these types by an LSTM into M · T features per hole
type. As with rule embeddings, we then concatenate these with the original M hole node features, once
concatenated together, yielding φ(cid:48)(cid:48)(l) ∈ RM ·(T +1).

Having obtained our respective rule and hole embeddings expanded to M ·(T +1) from the original M features,
we would then proceed to calculate the scores from these enhanced embeddings using the same calculations as
before, simply swapping out the embeddings to their enhanced versions, i.e. going from ze = φ(cid:48)(e.l) · ω(e.r) to
ze = φ(cid:48)(cid:48)(e.l) · ω(cid:48)(e.r).

The basic idea here is simple: on the type level we may provide information not only about how outputs
correlate to inputs, but may also provide info about how our expansion rules may match up to particular holes
in our program. Using this extra information should improve our search, as per our research hypothesis.

21

↓ typeclass / dataclass → Char

Int Maybe List

(,) Either

Enum
Foldable
Traversable
Functor
Monoid
Semigroup

○ ○

○
○
○
○
○

○ ○ ○
○ ○ ○
○ ○ ○
○
○ ○ ○

Figure 4: The types used in generating our synthesis dataset (column headers), along with their respective
typeclass memberships as marked by a ‘○’.

6 Experiment

We will now detail the particular setup we used for our experiment. We will ﬁrst explain the benchmark task
we use in our experiment in the next section. To perform our experiment, we ﬁrst ﬁnd an appropriate learning
rate on our vanilla implementation of NSPS, otherwise taking the hyperparameter values described in Section
A.

We will then evaluate on our task to evaluate a few diﬀerent models; our vanilla implementation of Parisotto
et al. [76]’s NSPS model, our type-based additions described in 5.4.3, as well as an enlarged version of the vanilla
model for fair comparison. To reduce variance, we run each model to convergence using 4 diﬀerent seeds. For
ﬁnal evaluation, we provide a uniform random synthesizer as a reference baseline as well.

6.1 Benchmark task

We pick our own set of types and operators to generate a dataset as described in Section 5.3. For this purpose we
have picked a limited set of operators widely applicable over the types used. To this end, we focus on functions
operating on typeclasses based on categories taken from category theory. Types used and their membership to
our used typeclasses may be found in Figure 4.

In order to pick our operator set, we had to use a number of heuristics to ﬁlter down the operators (comprising

either functions or data constructors) oﬀered:

• avoiding side-eﬀects, as this category is not a great match for programming by example;

• avoiding unnecessarily type-speciﬁc operators, as we would like to keep our operator set small yet reusable;

• focusing on diﬀerent inter-type over using various similar intra-type operators, as the former helps make

our operator set more amenable to reducing the search space using type information;

• avoiding inﬁnite lists, which are relatively circumstantial in their usage, as these would crash evaluation

unless speciﬁcally converted back to ﬁnite lists;

• functions particularly circumstantial in their accepted input values, e.g. the list-indexing take function

requiring input integers that are valid index values of the given list;

• functions taking predicates, i.e. functions returning boolean values, as we have few predicate functions we
can use to this end given the previous point, as many of these require concrete values as parameters;

• function variants using a parameter order less amenable to currying;

• functions discarding values, as these mostly make for redundant programs;

• functions otherwise likely to induce redundancy, such as the identity function;

• reducing redundancy, i.e. preferably not including operators that can already be constructed from existing

ones;

• preferably reducing the number of functions with similar type signatures;

• not necessarily aiming for full expressiveness in terms of manipulation of the chosen types.

Inspired by this list of heuristics, we have picked the following set of operators for our chosen types: 0, zero,
Just, maybe, (:), length, (,), zip, unzip, toEnum, fromEnum, foldMap, elem, sequenceA, sequence, fmap,
mempty, (<>), and (.).

22

7 Result

Having added our type-level supervision during training, we expect synthesis success rates to rise compared to
the baseline algorithm. This demonstrates that the ﬁndings from traditional program synthesis methods are
relevant also in the ﬁeld of neural program synthesis.

Any results here are trained on our dataset spanning programs of up to 3 nodes, during training evaluated

by sampling 100 programs from the synthesizer for any task function instance.

Figure 5: Prediction accuracy over 100 samples across training epochs for our diﬀerent model variants, trained
on our dataset of programs of up to 3 nodes.

Accuracy results over training on our validation set can be found in Figure 5, while accuracy on the test
set for the fully trained models may be found in Figure 6. We see that the simpler vanilla NSPS model is both
more limited in variance while also learning to a more limited extent before converging.

Our ﬁrst observation here is that the task has turned out relatively challenging, with accuracy for the
baseline model increasing only somewhat beyond its initial random accuracy. Furthermore, most of the gains
in accuracy for the baseline model are attained over the initial 10 epochs of training. We feel these issues may
be explained largely from the limited size of our dataset.

We additionally trained an enlarged version of this baseline model, doubling the sample encoder output
dimension parameter H from 32 to 64, giving it a similar amount of expressiveness as our typed model as a
reference. To our surprise however, this model fared little better than the baseline, again likely stemming from
generalization issues related to the size of our dataset.

Our ‘typed’ NSPS model however, keeping H at 32 but allotting that same amount for types, starts from
sub-random accuracies, yet ends up able to learn more, after 20 epochs out-performing both our baseline and
enlarged models, indicating it is in fact worthwhile to distribute features between input/output pairs and types.
We additionally attempted to look into whether we could ﬁnd a correlation between this advantage gained
by incorporating type information (as seen in Figure 7) with the number of nodes in a program. However, the
data we managed to gather was insuﬃcient to demonstrate such a correlation.

Speciﬁcally, our task turned out hard, with none of the models signiﬁcantly out-performing a random
synthesizer on the task functions of 3 nodes. On the 1-node task functions at 100 samples, similarly none
of the models outperformed the random synthesizer’s 84% accuracy, although at 20 samples the typed model
out-performed it at 55% vs. 43%. This means that most of the learning success for these models has been
on the 2-node task functions, particularly for the typed model, achieving over double the random accuracy for
either 20 or 100 samples.

Unfortunately for our purposes, performing best on the 2-node programs means we cannot presently distin-
guish any clear correlation between task function node size and advantage from type information. As such, we
would love to see similar experiments scaled up to larger datasets including higher node sizes.

In order to verify the statistical signiﬁcance of our proposed model variant, we have performed an independent
two-sample t-test comparing the accuracy across our models (as evaluated on 20 samples per task function
instance), results for which may be found in Figure 7.

23

evaluated @ 20 samples

evaluated @ 100 samples

accuracy

acc mean @ x nodes

accuracy

acc mean @ x nodes

mean
experiment
0.13
vanilla NSPS
0.12
large
typed
0.22
uniform random 0.14

var
0.000
0.001
0.002
0.000

1
0.27
0.30
0.55
0.43

2
0.13
0.12
0.24
0.11

3
0.11
0.09
0.12
0.11

mean
0.37
0.38
0.48
0.33

var
0.000
0.002
0.003
0.000

1
0.77
0.73
0.77
0.84

2
0.36
0.38
0.55
0.25

3
0.30
0.30
0.34
0.31

Figure 6: Summary of ﬁnal prediction accuracy on our test set over diﬀerent models after training (4 seeds
each), for each selecting the best-performing epoch as per validation accuracy i.e. before overﬁt. Results are
separated by evaluation on 20 vs. 100 samples, and metrics include mean accuracy, variance of accuracy, as well
as mean accuracy separated by programs of a given number of nodes. Bolded cells indicate the best accuracy
in a given category.

vanilla
p-values
1.000
vanilla
0.859
large
types
0.010
uniform 0.013

large
0.859
1.000
0.024
0.065

types uniform
0.010
0.024
1.000
0.001

0.013
0.065
0.001
1.000

Figure 7: P-values for diﬀerent model combinations under the independent two-sample t-test comparing accuracy
as evaluated on 100 samples per task function instance.

Whereas we similarly compared such diﬀerences for accuracy as evaluated on 100 samples, we found the
outcome for 20 samples to more clearly demonstrate the diﬀerence between models. Under 4 seeds each our
typed model turns out to have only p=1.0% to stem from the same distribution as our baseline model, indicating
the improvement in performance is statistically signiﬁcant.

24

8 Discussion

8.1 Dataset considerations

In Section 7 we mentioned dataset design as one of our concerns, as the size of our current dataset potentially
may have hindered further generalization, consisting of only 259 task function instances in total, split up across
training, validation and test datasets.

Picking our dataset deﬁnitely felt like a dilemma. The dataset we used supported task functions of up to 3
nodes. We initially tried sampling only 20 programs upon evaluation to reduce running times, but to generate
reliable accuracy graphs raised this to sampling 100 programs, which meant that 95% of training time was in
fact spent on accuracy evaluations.

This put us in the undesirable position of having to choose between dataset sizes not conducive to strong
generalization, versus increasing run-time and memory requirements, as an increase in the maximum number
of nodes brings a potentially exponential growth in the size of the dataset. Facing a compiler-induced memory
leak through our interpreter library [40], we felt compelled to err toward our current dataset of limited size to
keep run-time requirements in check.

We had in fact constructed a dataset of programs of up to 4 nodes, for which we were in fact able to conﬁrm
a lower level of overﬁt than on our current dataset, but had not evaluated on 100 samples during these runs,
preventing us from generating reliable accuracy graphs for this.

However, another potential culprit to proper generalization would be our strong supervision setup itself,
which would consistently penalize any correct solutions not identical to the task function itself. While in a
larger dataset these biases may even out, at our scale this might well still pose a barrier to learning.

8.2 Design limitations

• Our implementation settled for Parisotto et al. [76]’s baseline LSTM encoder rather than its more complex
cross-correlation encoder variants. While such variants may improve synthesis quality, these come at an
increased amount of computation as well.

• Also of note is that our present implementation has yet to be optimized for run-time performance: we
conducted our experiment on CPU, as our implementation is still missing batching over task functions.

• Parisotto et al. [76] used a limit of 13 operations for their synthesized programs.

In order to restrict
ourselves to a ﬁnite subset of an otherwise potentially inﬁnite search space, we apply such a limit during
task function generation as well, in our case using a maximum of 3. For the sake of simplicity, we have
opted to share this limit, speciﬁed during dataset generation, with our synthesizer as well. This disregards
any synthesized programs of correct behavior exceeding our complexity limit.

• Our present implementation unfortunately still defers full type inference in favor of local types based on
our unrolled grammar, meaning it is unable to ﬁll in further type variables based on information elsewhere
in the program tree.

• The interpreter library we presently use for type inference may fail in the face of ambiguous type variables,

somewhat limiting the potential eﬀectiveness of our type-ﬁlter model.

• For run-time performance considerations, our dataset presently includes the input-output examples for
each task function, in fact additionally shared across instantiated parameter types. A proper approach
here would perhaps ensure diﬀerent input-output pairs would be used across training epochs. This could
be achieved by either generating a greater variety upfront, then sampling from these during training,
or by generating these input-output pairs on the ﬂy during training, incurring an additional run-time
performance cost.

• Moreover, while ﬁxing such a sample size satisﬁes the constraints of our LSTM used in sample conditioning,
this is essentially an unfortunate compromise; if a function is signiﬁcantly more general in its applicability,
allowing for a wider variety of input types, then being forced to pick a ﬁxed sample size means simpler
programs with few types may potentially be learned more easily than programs with e.g. a greater number
of type instances. It would likely be preferable to oﬀset this sample size ﬁxing by e.g. giving more weight
to hard programs (or samples, for that matter).

8.3 Topics for future research

As neural synthesis methods aimed at programming by example in the functional programming domain is a
broad topic encompassing a variety of design decisions, we have had to leave quite some questions unanswered.
We will give an overview in this section of some of the questions raised during our design process speciﬁcally.

25

While we have focused on types as features here, after each synthesis step, we might also pre-compile even
partial programs such as to provide the synthesizer with immediate feedback on whether a program type-checks;
as with types, we similarly hypothesize neural program synthesis methods can beneﬁt from using compilation
checks as additional features.

However, this would require a weakly supervised neural synthesizer, i.e. using reinforcement learning, whereas
our present synthesizer is based on the simpler strongly supervised setup. As such, this was unfortunately out
of scope for our current paper.

While we have looked into the added value of types as features, this gives rise to an additional question:
what kind of operators are most conducive to beneﬁting from type info? While we have brieﬂy conjectured this
to involve having few yet generically applicable operators, this question has fallen out of scope for our paper,
and remains a question for future research.

As we touched upon in Section 5.2.3, the merits of our unrolled grammar approach are still up for empirical
evaluation. As our present dataset allowed us to settle for this approach, we decided to regard this question as
out of scope for our present paper.

For supervising with types, we have so far used the types we were able to infer from sample inputs and
outputs. However, for each such diﬀerent type, these make up type instances of the task function’s type
signature.

When synthesizing an identity function, the sample mappings 0 → 0 and f alse → f alse might give us the
instantiated type signatures Int → Int or Bool → Bool, yet the true underlying type signature of this task
function is ∀a.a → a.

One might then conclude that, in order to synthesize the intended function, knowing its true type signature
would be more valuable than the sum of (knowing) its parts. This poses some challenges however: What can
we learn about the true type signature from its instances? Is a given type variable shared between multiple
parameters? That is, how do we know it should be ∀a.a → a over say ∀ab.a → b? How much can we infer of
type constraints on such type variables? That is, do we know the function should be as general as ∀a.a → a, as
opposed to say having some type constraint e.g. ∀a.Enum a ⇒ a → a?

Now, for either question, we could err in either direction, toward common denominator upper and lower

bounds.

Suppose we cannot guarantee the type variable is shared across its two parameters, and we consider ∀ab.a → b
the minimum requirement that a function type signature must satisfy. This might be the bare minimum
requirement, but trying the more speciﬁc variants such as ∀a.a → a, while potentially not guaranteed to cover
all cases, would nevertheless still be a useful type signature to consider during our synthesis, as its additional
constraint may well make for some welcome search space reduction.

Instead, we could also consider the case in which we don’t need to infer the type signature from out in-
put/output samples, but it is simply given to us as additional information for our (modiﬁed) PBE exercise. It
would be interesting to investigate to what extent such true type signatures might aid synthesis, and further-
more, to what extent these may be inferred. However, given all these questions surrounding the use of such
type signatures, we have opted to leave this as a topic for future research.

8.4 Conclusion

We presented a way to incorporate programming types into a neural program synthesis approach for program-
ming by example. We generated a dataset in the functional programming context, and demonstrated type
information to improve synthesis accuracy even given a comparable number of parameters. Finally, we suggest
a number of topics of interest for future research in type-driven neural programming by example.

26

9 Acknowledgements

First of all, I would like to thank my supervisor Emile van Krieken, who has actively supported me with his
broader knowledge on program synthesis and AI whenever my own familiarity failed me.

Furthermore, I would like to thank my assessor Annette ten Teije for approving my research direction,

despite it falling outside the well-trodden path for either artiﬁcial intelligence or computer science separately.

I additionally thank Emilio Parisotto, who helped answer my questions to better understand their neuro-

symbolic program synthesis architecture. [76]

I must also thank my fellow students, discussions with whom helped me tremendously throughout this

program — without them, I probably wouldn’t have made it this far.

On the implementation, I am further indebted to the HaskTorch team, including Austin Huang, Junji
Hashimoto, Torsten Scholak, Sam Stites, and Adam Paszke, any of whom have not hesitated to advise me when
I got stuck on technical aspects including HaskTorch, Nix, Haskell, or machine learning.

I also owe gratitude to my friend Alejandra Ortiz, who was there for me when I needed it.
Finally, I would like to dedicate this work to Jaques Lagerweij, whom I never got to meet.

27

References

[1] Mart´ın Abadi and Gordon D Plotkin. A simple diﬀerentiable programming language. Proceedings of the

ACM on Programming Languages, 4(POPL):1–28, 2019.

[2] Mart´ın Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeﬀrey Dean, Matthieu Devin,
Sanjay Ghemawat, Geoﬀrey Irving, Michael Isard, et al. Tensorﬂow: A system for large-scale machine
learning. In 12th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 16),
pages 265–283, 2016.

[3] Takuya Akiba, Kentaro Imajo, Hiroaki Iwami, Yoichi Iwata, Toshiki Kataoka, Naohiro Takahashi, Micha(cid:32)l
Moskal, and Nikhil Swamy. Calibrating research in program synthesis using 72,000 hours of programmer
time. MSR, Redmond, WA, USA, Tech. Rep, 2013. URL https://pdfs.semanticscholar.org/1cde/
a6fa2f0a400f509aed98f9a857ab1788257e.pdf.

[4] Rajeev Alur, Rastislav Bodik, Garvit Juniwal, Milo MK Martin, Mukund Raghothaman, Sanjit A Seshia,
Rishabh Singh, Armando Solar-Lezama, Emina Torlak, and Abhishek Udupa. Syntax-guided synthe-
sis. IEEE, 2013. doi: 10.1109/FMCAD.2013.6679385. URL https://ieeexplore.ieee.org/abstract/
document/6679385.

[5] Rajeev Alur, Dana Fisman, Rishabh Singh, and Armando Solar-Lezama. Sygus-comp 2016: results and

analysis. arXiv preprint arXiv:1611.07627, 2016. URL https://arxiv.org/abs/1611.07627.

[6] Marcin Andrychowicz and Karol Kurach. Learning eﬃcient algorithms with hierarchical attentive memory.

arXiv preprint arXiv:1602.03218, 2016. URL https://arxiv.org/abs/1602.03218.

[7] Lennart Augustsson. djinn: Generate haskell code from a type, Sep 2014. URL http://hackage.

haskell.org/package/djinn.

[8] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning
to align and translate. arXiv preprint arXiv:1409.0473, 2014. URL https://arxiv.org/abs/1409.0473.

[9] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning
to align and translate. arXiv preprint arXiv:1409.0473, 2014. URL https://arxiv.org/abs/1409.0473.

[10] Matej Balog, Alexander L Gaunt, Marc Brockschmidt, Sebastian Nowozin, and Daniel Tarlow. Deepcoder:
Learning to write programs. arXiv preprint arXiv:1611.01989, 2016. URL https://arxiv.org/abs/
1611.01989.

[11] Rastislav Bod´ık and Barbara Jobstmann. Algorithmic program synthesis:
https://link.springer.com/article/10.1007/s10009-013-0287-9.

introduction, 2013. URL

[12] Ronald Newbold Bracewell and Ronald N Bracewell. The Fourier transform and its applications, vol-
ume 31999. McGraw-Hill New York, 1986. URL https://www.academia.edu/download/44001876/
34957138.pdf.

[13] Edwin Brady. Idris, a general-purpose dependently typed programming language: Design and implemen-
tation. Journal of functional programming, 23(5):552–593, 2013. doi: 10.1017/S095679681300018X. URL
https://eb.host.cs.st-andrews.ac.uk/drafts/impldtp.pdf.

[14] Edwin Brady. Type-driven development with Idris. Manning Publications Company, 2017.

[15] Rudy Bunel, Matthew Hausknecht, Jacob Devlin, Rishabh Singh, and Pushmeet Kohli. Leveraging
grammar and reinforcement learning for neural program synthesis. arXiv preprint arXiv:1805.04276,
2018. URL https://arxiv.org/abs/1805.04276.

[16] Jonathon Cai, Richard Shin, and Dawn Song. Making neural programming architectures generalize via

recursion. arXiv preprint arXiv:1704.06611, 2017. URL https://arxiv.org/abs/1704.06611.

[17] Alberto Camacho and Sheila A McIlraith. Towards neural-guided program synthesis for linear temporal
logic speciﬁcations. arXiv preprint arXiv:1912.13430, 2019. URL https://arxiv.org/abs/1912.13430.

[18] Murray Campbell, A Joseph Hoane Jr, and Feng-hsiung Hsu. Deep blue. Artiﬁcial intelligence, 134(1-2):

57–83, 2002.

[19] Xinyun Chen, Chang Liu, and Dawn Song. Towards synthesizing complex programs from input-output

examples. arXiv preprint arXiv:1706.01284, 2017. URL https://arxiv.org/abs/1706.01284.

28

[20] Alonzo Church. A set of postulates for the foundation of logic. Annals of mathematics, pages 346–366,

1932. doi: 10.2307/1968337.

[21] Alonzo Church. Applications of recursive arithmetic to the problem of circuit synthesis. Institute for

Symbolic Logic, Cornell University, 1957. doi: 10.2307/2271310.

[22] Codota. Ai smart compose for your code — tabnine. URL https://www.tabnine.com/.

[23] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Fei-Fei Li. Imagenet: A large-scale hierarchical
image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248–255.
Ieee, 2009. doi: 10.1109/CVPR.2009.5206848. URL https://doi.org/10.1109/CVPR.2009.5206848.

[24] Jacob Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh, Abdel-rahman Mohamed, and
In Proceedings of the 34th
doi:

Pushmeet Kohli. Robustﬁll: Neural program learning under noisy i/o.
International Conference on Machine Learning-Volume 70, pages 990–998. JMLR. org, 2017.
10.5555/3305381.3305484. URL https://doi.org/10.5555/3305381.3305484.

[25] Shingo Eguchi, Naoki Kobayashi, and Takeshi Tsukada. Automated synthesis of functional programs
with auxiliary functions.
In Asian Symposium on Programming Languages and Systems, pages 223–
241. Springer, 2018. doi: 10.1007/978-3-030-02768-1 13. URL https://www-kb.is.s.u-tokyo.ac.jp/
~koba/papers/aplas18-long.pdf.

[26] Yu Feng, Ruben Martins, Osbert Bastani, and Isil Dillig. Program synthesis using conﬂict-driven learning.
ACM SIGPLAN Notices, 53(4):420–435, 2018. doi: 10.1145/3296979.3192382. URL https://dl.acm.
org/doi/abs/10.1145/3296979.3192382.

[27] John K. Feser, Marc Brockschmidt, Alexander L. Gaunt, and Daniel Tarlow. Neural functional program-

ming. CoRR, abs/1611.01988, 2016. URL http://arxiv.org/abs/1611.01988.

[28] Bernd Finkbeiner, Felix Klein, Ruzica Piskac, and Mark Santolucito. Temporal stream logic: Synthesis
beyond the bools. In International Conference on Computer Aided Veriﬁcation, pages 609–629. Springer,
2019. URL https://arxiv.org/abs/1712.00246.

[29] Lawrence J Fogel, Alvin J Owens, and Michael J Walsh. Intelligent decision making through a simulation

of evolution. Behavioral science, 11(4):253–272, 1966.

[30] Alexander L Gaunt, Marc Brockschmidt, Rishabh Singh, Nate Kushman, Pushmeet Kohli, Jonathan
Taylor, and Daniel Tarlow. Terpret: A probabilistic programming language for program induction. arXiv
preprint arXiv:1608.04428, 2016. URL https://arxiv.org/abs/1608.04428.

[31] Matth´ıas P´all Gissurarson. Suggesting Valid Hole Fits for Typed-Holes in Haskell. PhD thesis, Master’s
thesis. Chalmers University of Technology, University of Gothenburg . . . , 2018. URL https://www.mpg.
is/papers/gissurarson2018suggesting-msc.pdf.

[32] Alex Graves, Greg Wayne, and Ivo Danihelka. Neural turing machines. arXiv preprint arXiv:1410.5401,

2014. URL https://arxiv.org/abs/1410.5401.

[33] Kiara Grouwstra. Typed nsps source code, Aug 2020. URL https://gitlab.com/tycho01/hasktorch/

-/tree/synthesis/synthesis.

[34] Kiara Grouwstra. Hint: ambiguous type variables, Jul 2020. URL https://github.com/haskell-hint/

hint/issues/102.

[35] Sumit Gulwani. Automating string processing in spreadsheets using input-output examples. ACM Sigplan
Notices, 46(1):317–330, 2011. doi: 10.1145/1925844.1926423. URL https://dl.acm.org/doi/abs/10.
1145/1925844.1926423.

[36] Sumit Gulwani, Oleksandr Polozov, Rishabh Singh, et al. Program synthesis. Foundations and
Trends in Programming Languages, 4(1-2):1–119, 2017. doi: 10.1561/2500000010. URL https://www.
nowpublishers.com/article/Details/PGL-010.

[37] David Gunning. Explainable artiﬁcial intelligence (xai). Defense Advanced Research Projects Agency

(DARPA), nd Web, 2, 2017.

[38] Zheng Guo. Speeding up type-driven program synthesis with polymorphic succinct types. 2018. URL

https://icfp18.sigplan.org/getImage/orig/icfp18src-zheng-guo.pdf.

29

[39] Daniel D. Gutierrez. Ask a data scientist: Data leakage, Nov 2014. URL https://insidebigdata.com/

2014/11/26/ask-data-scientist-data-leakage/.

[40] Samuel G´elineau. Hint: memory leak, Apr 2020. URL https://github.com/haskell-hint/hint/

issues/96.

[41] Sepp Hochreiter and J¨urgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735–1780,

1997.

[42] Austin Huang, Sam Stites, Junji Hashimoto, Torsten Scholak, Adam Paszke, et al. Hasktorch: Tensors

and neural networks in haskell, Sep 2017. URL https://github.com/hasktorch/hasktorch.

[43] Zhiheng Huang, Wei Xu, and Kai Yu. Bidirectional LSTM-CRF models for sequence tagging. CoRR,

abs/1508.01991, 2015. URL http://arxiv.org/abs/1508.01991.

[44] John Hughes. Why functional programming matters. The computer journal, 32(2):98–107, 1989. URL

https://academic.oup.com/comjnl/article/32/2/98/543535.

[45] ISO. Information technology — programming languages — fortran - part 1: Base language. Standard,
International Organization for Standardization, Geneva, CH, Dec 1997. URL https://www.iso.org/
standard/26933.html.

[46] Simon Peyton Jones. Haskell 98 language and libraries: the revised report. Cambridge University Press,

2003. URL https://books.google.com/books?id=mMGQgcnCxjAC.

[47] (cid:32)Lukasz Kaiser and Ilya Sutskever. Neural gpus learn algorithms. arXiv preprint arXiv:1511.08228, 2015.

URL https://arxiv.org/abs/1511.08228.

[48] Nal Kalchbrenner and Phil Blunsom. Recurrent continuous translation models.

In Proceedings of the
2013 Conference on Empirical Methods in Natural Language Processing, pages 1700–1709, 2013. URL
https://www.aclweb.org/anthology/D13-1176.pdf.

[49] Ashwin Kalyan, Abhishek Mohta, Oleksandr Polozov, Dhruv Batra, Prateek Jain, and Sumit Gul-
wani.
arXiv
Neural-guided deductive search for real-time program synthesis from examples.
preprint arXiv:1804.01186, 2018. URL https://www.microsoft.com/en-us/research/publication/
neural-guided-deductive-search-real-time-program-synthesis-examples/.

[50] Neel Kant. Recent advances in neural program synthesis. CoRR, abs/1802.02353, 2018. URL http:

//arxiv.org/abs/1802.02353.

[51] Andrej Karpathy.

Software

2.0, Nov

2017.

URL https://medium.com/@karpathy/

software-2-0-a64152b37c35.

[52] Garry Kasparov. Don’t fear intelligent machines. work with them, Apr 2017. URL https://www.ted.

com/talks/garry_kasparov_don_t_fear_intelligent_machines_work_with_them.

[53] Maurice G Kendall. On autoregressive time series. Biometrika, pages 105–122, 1944.

[54] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M Rush. Structured attention networks. arXiv

preprint arXiv:1702.00887, 2017. URL https://arxiv.org/abs/1702.00887.

[55] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint

arXiv:1412.6980, 2014. URL https://arxiv.org/abs/1412.6980.

[56] Kai Koskimies and Erkki M¨akinen. Automatic synthesis of state machines from trace diagrams. Software:
Practice and Experience, 24(7):643–658, 1994. doi: 10.1002/spe.4380240704. URL https://doi.org/10.
1002/spe.4380240704.

[57] Karol Kurach, Marcin Andrychowicz, and Ilya Sutskever. Neural random-access machines. arXiv preprint

arXiv:1511.06392, 2015. URL https://arxiv.org/abs/1511.06392.

[58] Woosuk Lee, Kihong Heo, Rajeev Alur, and Mayur Naik. Accelerating search-based program synthesis
using learned probabilistic models. ACM SIGPLAN Notices, 53(4):436–449, 2018. URL https://www.
cis.upenn.edu/~alur/PLDI18.pdf.

[59] Chengtao Li, Daniel Tarlow, Alexander L Gaunt, Marc Brockschmidt, and Nate Kushman. Neural pro-

gram lattices. 2016. URL https://openreview.net/forum?id=HJjiFK5gx.

30

[60] Chen Liang, Mohammad Norouzi, Jonathan Berant, Quoc V Le, and Ni Lao. Memory augmented policy
In S. Bengio, H. Wallach, H. Larochelle,
optimization for program synthesis and semantic parsing.
K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing
Systems 31, pages 9994–10006. Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/
8204-memory-augmented-policy-optimization-for-program-synthesis-and-semantic-parsing.
pdf.

[61] Microsoft.

Using ﬂash ﬁll

in excel,

.

URL https://support.microsoft.com/en-us/office/

using-flash-fill-in-excel-3f9bcf1e-db93-4890-94a0-1578341f73f7.

[62] Microsoft. Intellisense in visual studio code, . URL https://code.visualstudio.com/docs/editor/

intellisense.

[63] Anders Miltner, Kathleen Fisher, Benjamin C Pierce, David Walker, and Steve Zdancewic. Synthesizing
bijective lenses. Proceedings of the ACM on Programming Languages, 2(POPL):1, 2017. doi: 10.1145/
3158089. URL https://dl.acm.org/doi/abs/10.1145/3158089.

[64] Tom M Mitchell. Generalization as search. Artiﬁcial intelligence, 18(2):203–226, 1982. doi: 10.1016/

0004-3702(82)90040-6. URL https://doi.org/10.1016/0004-3702(82)90040-6.

[65] Abdelrahman S.A. Mohamed, Rishabh Singh, Lihong Li, Dengyong Zhou, Pushmeet Kohli, and Emilio
Parisotto. Neural network for program synthesis, Mar 2017. URL https://patents.google.com/
patent/US20180275967A1.

[66] Stephen Muggleton. Inductive logic programming. New generation computing, 8(4):295–318, 1991. doi:

10.1007/BF03037089.

[67] Vijayaraghavan Murali, Letao Qi, Swarat Chaudhuri, and Chris Jermaine. Neural sketch learning for
conditional program generation. arXiv preprint arXiv:1703.05698, 2017. URL https://arxiv.org/abs/
1703.05698.

[68] Shuu Nakao, Yuki Satake, and Hiroshi Amano. Functional program synthesis from relational speciﬁcations.
Japan Computer Science Conference Journal, 34:207–220, 2017. URL http://jssst.or.jp/files/user/
taikai/2017/PPL/ppl3-1.pdf.

[69] Arvind Neelakantan, Quoc V Le, and Ilya Sutskever. Neural programmer: Inducing latent programs with

gradient descent. arXiv preprint arXiv:1511.04834, 2015. URL https://arxiv.org/abs/1511.04834.

[70] Augustus Odena and Charles Sutton. Learning to represent programs with property signatures.

In
International Conference on Learning Representations, 2020. URL https://arxiv.org/abs/2002.09030.

[71] OpenAI. Msbuild2020: Gpt-3 program synthesis demo, May 2020. URL https://twitter.com/

soumithchintala/status/1263221177650159620.

[72] Peter-Michael Osera. Programming assistance for type-directed programming. In Proceedings of the 1st
International Workshop on Type-Driven Development, pages 56–57. ACM, 2016. doi: 10.1145/2976022.
2976027. URL https://www.cs.grinnell.edu/~osera/publications/osera-tyde-2016.pdf.

[73] Peter-Michael Osera. Constraint-based type-directed program synthesis. In Proceedings of the 4th ACM
SIGPLAN International Workshop on Type-Driven Development, pages 64–76. ACM, 2019. URL https:
//arxiv.org/abs/1907.03105.

[74] Peter-Michael Osera and Steve Zdancewic. Type-and-example-directed program synthesis. ACM SIG-
doi: 10.1145/2813885.2738007. URL https://dl.acm.org/

PLAN Notices, 50(6):619–630, 2015.
citation.cfm?id=2738007.

[75] Saswat Padh. Syntax-guided synthesis competition (sygus-comp), 2014. URL https://sygus.org/.

[76] Emilio Parisotto, Abdel-rahman Mohamed, Rishabh Singh, Lihong Li, Dengyong Zhou, and Pushmeet
Kohli. Neuro-symbolic program synthesis. CoRR, abs/1611.01855, 2016. URL http://arxiv.org/abs/
1611.01855.

[77] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf,
Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit

31

Steiner, Lu Fang, Junjie Bai, and Soumith Chintala.
performance deep learning library.
Buc, E. Fox, and R. Garnett,
32, pages 8024–8035. Curran Associates,
9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf.

Pytorch: An imperative style, high-
In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch´e-
Information Processing Systems
URL http://papers.neurips.cc/paper/

editors, Advances
Inc., 2019.

in Neural

[78] Thomas Pierrot, Guillaume Ligner, Scott E. Reed, Olivier Sigaud, Nicolas Perrin, Alexandre Laterre,
David Kas, Karim Beguir, and Nando de Freitas. Learning compositional neural programs with recursive
tree search and planning. CoRR, abs/1905.12941, 2019. URL http://arxiv.org/abs/1905.12941.

[79] Gordon D Plotkin. A note on inductive generalization. Machine intelligence, 5(1):153–163, 1970. URL

http://homepages.inf.ed.ac.uk/gdp/publications/MI5_note_ind_gen.pdf.

[80] Nadia Polikarpova, Ivan Kuraj, and Armando Solar-Lezama. Program synthesis from polymorphic reﬁne-
ment types. In ACM SIGPLAN Notices, volume 51, pages 522–538. ACM, 2016. doi: 10.1145/2980983.
2908093. URL https://dl.acm.org/citation.cfm?id=2908093.

[81] Illia Polosukhin and Alexander Skidanov. Neural program search: Solving programming tasks from
description and examples. arXiv preprint arXiv:1802.04335, 2018. URL https://arxiv.org/abs/1802.
04335.

[82] Alex Polozov. Program synthesis in 2017-18, Jul 2018. URL https://alexpolozov.com/blog/

program-synthesis-2018/.

[83] Oleksandr Polozov and Sumit Gulwani. Flashmeta: a framework for inductive program synthesis.

In
ACM SIGPLAN Notices, volume 50, pages 107–126. ACM, 2015. doi: 10.1145/2814270.2814310. URL
https://dl.acm.org/citation.cfm?id=2814310.

[84] RJ Popplestone. An experiment in automatic induction. machine intelligence 5, 1969. URL https:

//aitopics.org/download/classics:0B2939E6.

[85] Maxim Rabinovich, Mitchell Stern, and Dan Klein. Abstract syntax networks for code generation and

semantic parsing. CoRR, abs/1704.07535, 2017. URL http://arxiv.org/abs/1704.07535.

[86] Scott Reed and Nando De Freitas. Neural programmer-interpreters. arXiv preprint arXiv:1511.06279,

2015. URL https://arxiv.org/abs/1511.06279.

[87] Sebastian Riedel, Matko Bosnjak, and Tim Rockt¨aschel. Programming with a diﬀerentiable forth inter-

preter. CoRR, abs/1605.06640, 2016. URL http://arxiv.org/abs/1605.06640.

[88] Tim Rockt¨aschel and Sebastian Riedel. End-to-end diﬀerentiable proving.

In Advances in Neu-
ral Information Processing Systems, pages 3788–3800, 2017. URL http://papers.nips.cc/paper/
6969-end-to-end-differentiable-proving.

[89] David E Rumelhart, Geoﬀrey E Hinton, and Ronald J Williams. Learning representations by back-

propagating errors. nature, 323(6088):533–536, 1986.

[90] Stuart Russell and Peter Norvig. Artiﬁcial intelligence: a modern approach. 2002. URL https://people.

eecs.berkeley.edu/~russell/aima1e.html.

[91] Eric Schkufza, Rahul Sharma, and Alex Aiken. Stochastic program optimization. Communications of the

ACM, 59(2):114–122, 2016. doi: 10.1145/2863701. URL https://doi.org/10.1145/2863701.

[92] Torsten Scholak. Gpt-3 generated code and software bugs, Jul 2020. URL https://twitter.com/

tscholak/status/1279061409570213895.

[93] Taro Sekiyama, Akifumi Imanishi, and Kohei Suenaga. Towards proof synthesis guided by neural machine
translation for intuitionistic propositional logic. CoRR, abs/1706.06462, 2017. URL http://arxiv.org/
abs/1706.06462.

[94] Peter Selinger. Lecture notes on the lambda calculus. CoRR, abs/0804.3434, 2008. URL http://arxiv.

org/abs/0804.3434.

[95] Burr Settles. Active learning literature survey. Technical report, University of Wisconsin-Madison Depart-
ment of Computer Sciences, 2009. URL http://burrsettles.com/pub/settles.activelearning.pdf.

32

[96] Armando Solar-Lezama and Rastislav Bodik. Program synthesis by sketching. Citeseer, 2008. doi: 10.
5555/1714168. URL http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.207.9048&rep=
rep1&type=pdf.

[97] EBNF Syntaxt Speciﬁcation Standard. Ebnf: Iso/iec 14977: 1996 (e). 70, 1996. URL http://www.cl.

cam.ac.uk/mgk25/iso-14977.pdf.

[98] Phillip D. Summers. A methodology for lisp program construction from examples. J. ACM, 24(1):161–175,
January 1977. ISSN 0004-5411. doi: 10.1145/321992.322002. URL https://doi.org/10.1145/321992.
322002.

[99] Ron Sun and Lawrence A Bookman. Computational architectures integrating neural and symbolic pro-
cesses: A perspective on the state of the art, volume 292. Springer Science & Business Media, 1994.

[100] Michael Thomsen. Announcing dart 2.5: Super-charged development, Sep 2019. URL https://medium.

com/dartlang/announcing-dart-2-5-super-charged-development-328822024970.

[101] Emina Torlak and Rastislav Bodik. Growing solver-aided languages with rosette. In Proceedings of the 2013
ACM international symposium on New ideas, new paradigms, and reﬂections on programming & software,
pages 135–152. ACM, 2013. doi: 10.1145/2509578.2509586. URL https://homes.cs.washington.edu/
~emina/pubs/rosette.onward13.pdf.

[102] Alan Mathison Turing. On computable numbers, with an application to the entscheidungsproblem. J.
of Math, 58(345-363):5, 1936. URL https://www.wolframscience.com/prizes/tm23/images/Turing.
pdf.

[103] Lazar Valkov, Dipak Chaudhari, Akash Srivastava, Charles Sutton, and Swarat Chaudhuri. Houdini:
Lifelong learning as program synthesis. In Advances in Neural Information Processing Systems, pages
8687–8698, 2018. URL https://arxiv.org/abs/1804.00218.

[104] Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh, Pushmeet Kohli, and Swarat Chaudhuri. Pro-
arXiv preprint arXiv:1804.02477, 2018. URL

grammatically interpretable reinforcement learning.
https://arxiv.org/abs/1804.02477.

[105] Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly.

In Advances in neu-
ral information processing systems, pages 2692–2700, 2015. URL http://papers.nips.cc/paper/
5866-pointer-networks.

Pointer networks.

[106] Jason Warner. Thank you for 100 million repositories, Nov 2018. URL https://github.blog/

2018-11-08-100M-repos/.

[107] Yifan Xu, Lu Dai, Udaikaran Singh, Kening Zhang, and Zhuowen Tu. Neural program synthesis by
self-learning. arXiv preprint arXiv:1910.05865, 2019. URL https://arxiv.org/abs/1910.05865.

[108] Lisa Zhang, Gregory Rosenblatt, Ethan Fetaya, Renjie Liao, William E Byrd, Raquel Urtasun, and
Richard Zemel. Leveraging constraint logic programming for neural guided program synthesis. 2018.
URL https://openreview.net/pdf?id=HJIHtIJvz.

[109] Andrew Zukoski and Drew Wolpert. Program synthesis for declarative building design, Sep 2017. URL

https://youtu.be/yJW--wNMv1M.

33

A Hyperparameters

A.1 Hyperparameters used for dataset generation

In this section we will describe the hyperparameter values we have used in our dataset generation.

We generate types to substitute into type variables using a maximum of only one level of nesting, i.e. allowing

type list of booleans though not type list of lists of booleans.

For any parameter type containing type variables used in task functions, we generate a maximum of 5 type
instances, before deduplication. Whereas Parisotto et al. [76] generated 10 inputs for each task function, we
instead generate up to 10 for each type instance of a task function, before deduplicating.

While they limited functions to a maximum of 13 operations, we instead limit ours to a maximum of 3,

given that our current operator set is considerably bigger than those of their FlashFill domain.

Numbers that we generate, all of them integers, we limit to the range from −20 to 20. For characters we
stick to the range of digits, i.e. from ‘0’ to ‘9’, a decision made with the intent to let their characters overlap
with those of digits for the purpose of helping reduce characters used in the encoder, in turn reducing the size of
its one-hot embedding. This arbitrary constraint serves no other purpose than to constrain required compute.
Data structures such as string, list, set, and hashmap, we each generate using lengths in the range from 0 to

5. Of these, sets might further deduplicate down, as this structure only holds unique items.

Our dataset we split into training, validation and test sets using a ratio of 35%, 35%, and 30%, respectively.

As [76] we sample 1, 000 training programs from the total function space.

A.2 Hyperparameters in our synthesizer

In this section we will describe the hyperparameter values we have during the training and evaluation of our
synthesizers.

We use 3 layers in our LSTMs, which are present in our sample encoder (for both input and output), our
type encoders (for rule expansions and holes), as well as for sample conditioning and scoring in our R3NN. We
do allow bias terms although the original paper did not show these in their formulas. We train for a maximum
of 1, 000 epochs.

Our encoders process items (either input-output samples or types) using a batch size of 8. Our R3NN must
use a ﬁxed number of embedded input-output pairs on the basis of its LSTM used for conditioning, and as such
we have ﬁxed this to use samples of 8 embedded input-output pairs.

As Parisotto et al. [76], for synthesizer evaluation we sample 100 functions from the model for each task
function, determining success based on the best from this sample, i.e. considering the synthesis a success if any
of these pass our PBE task, exhibiting the desired behavior.

We evaluate performance on our validation set once after every 5 epochs of training. During evaluation we
similarly check for convergence based on the loss, averaging over windows of 2 evaluations, i.e. stop training if
the validation loss over the past two evaluations has increased from the two before.

We arbitrarily limit synthesized functions to the same complexity limit of 6 operators as used during gener-

ation of task functions.

We allow 32 features in our symbol and expansion rule embeddings, i.e. M in Parisotto et al. [76]’s R3NN.
We allow 32 features per input or output per LSTM direction, i.e. H in Parisotto et al. [76]’s sample encoder.

We clip gradients to stay within a range from −1 to 1.
The learning rate for our Adam optimizer we search over by a grid search using our vanilla NSPS model,

considering values of 1e−2, 1e−3, 1e−4, and 1e−5. Of these, we settle on a learning rate of 1e−2.

B Miscellaneous experiments

Aside from our main experiment, we also tried a few other conﬁgurations for which we had not managed to
obtain conclusive results.

B.1 Type ﬁlter

The ﬁrst of these was the idea to combine a synthesizer with a compiler check to ﬁlter out any non-compiling
programs. While the downside to this would be that the synthesizer would be made dependent on this extra
compiler check, incurring a run-time penalty during synthesis, linear in the number of expansion rules provided,
the advantage to such a setup would be that the synthesizer would no longer need to learn to disregard non-
compiling programs itself, reducing synthesis to a ranking problem of the compiling (partial) candidate programs.
We achieve this by simply masking the predicted scores of uncompiling programs in our NSPS implementation
(before calculating actual probabilities by softmax) to have no probability, i.e. p(e) = 0.0.

34

While we failed to obtain any signiﬁcant improvement over the baseline model using this setup, this result
may well have related to our implementation. We presently used the hint Haskell library as our interpreter
for type-checks, which unfortunately yielded false positive compiler errors for types containing ambiguous type
variables, such as show undefined, which the Haskell compiler would resolve to type string, whereas the hint
library would complain that the undefined argument would prevent resolving show’s type variable. [34]

As this counter-factual signal would prevent this synthesizer from correctly synthesizing the aﬀected pro-
grams, the fact that it nevertheless performed on par with our baseline algorithm suggests this approach does
in fact have potential. While we might have addressed this ﬂaw in our implementation by switching from this
interpreter library to using Haskell’s compiler API directly, due to time constraints this unfortunately fell out
of scope for this thesis.

B.2 Picking holes

Although the topic of which hole to ﬁll was not directly touched upon in Parisotto et al. [76], our baseline
implementation had the synthesizer deterministically ﬁll the ﬁrst hole (under any given order — we used left-
to-right). Nevertheless, we did also wonder what the eﬀect might be if we would allow ﬁlling any hole.

During training, we would then opt to randomly pick a hole to try and ﬁll. On evaluation, we would then
look at the conﬁdence scores for any hole expansions across holes, sampling from this full matrix rather than
just the vector slice corresponding to the ﬁrst hole. This allows the synthesizer to take into account the relative
conﬁdence of expansions for diﬀerent holes, enabling it to forego holes involving more uncertainty in favor of
those it feels more conﬁdent about, which may in turn provide additional information that may then reduce
ambiguity for the remaining holes. 11

Unfortunately, we obtained inconsistent results on this model versus our baselines across diﬀerent experi-
ment attempts, originally getting the expected improvement, although in our ﬁnal implementation we had not
managed to reproduce this improvement. We had to leave further analysis of these inconsistent results out of
scope due to time constraints, and as such feel hard-pressed to make deﬁnitive statements on the eﬀectiveness of
this approach. Nevertheless, we consider this to be a topic of interest in AST-based neural program synthesis.

11 An additional advantage of this would be it could more uniformly explore various partial program trees across synthesis steps.
That said, uniform exploration there isn’t necessarily the ideal situation — one might for example imagine using weights to prioritize
situations our synthesizer is less conﬁdent about.

35

