1

Joint Optimization of Communications and

Federated Learning Over the Air

Xin Fan1, Yue Wang2, Member, IEEE, Yan Huo1, Senior Member, IEEE, and Zhi

Tian2, Fellow, IEEE

1School of Electronics and Information Engineering, Beijing Jiaotong University,

Beijing, China

2Department of Electrical & Computer Engineering, George Mason University,

Fairfax, VA, USA

E-mails: {yhuo,fanxin}@bjtu.edu.cn, {ywang56,ztian1}@gmu.edu

Abstract

Federated learning (FL) is an attractive paradigm for making use of rich distributed data while

protecting data privacy. Nonetheless, nonideal communication links and limited transmission resources

may hinder the implementation of fast and accurate FL. In this paper, we study joint optimization of

communications and FL based on analog aggregation transmission in realistic wireless networks. We ﬁrst

derive closed-form expressions for the expected convergence rate of FL over the air, which theoretically

quantify the impact of analog aggregation on FL. Based on the analytical results, we develop a joint

optimization model for accurate FL implementation, which allows a parameter server to select a subset

of workers and determine an appropriate power scaling factor. Since the practical setting of FL over the

air encounters unobservable parameters, we reformulate the joint optimization of worker selection and

power allocation using controlled approximation. Finally, we efﬁciently solve the resulting mixed-integer

programming problem via a simple yet optimal ﬁnite-set search method by reducing the search space.

Simulation results show that the proposed solutions developed for realistic wireless analog channels

outperform a benchmark method, and achieve comparable performance of the ideal case where FL is

implemented over noise-free wireless channels.

Index Terms

Federated learning, analog aggregation, convergence analysis, joint optimization, worker scheduling,

power scaling.

1
2
0
2

t
c
O
5

]

G
L
.
s
c
[

2
v
0
9
4
3
0
.
4
0
1
2
:
v
i
X
r
a

 
 
 
 
 
 
2

I. INTRODUCTION

In recent years, with the development of IoT and social networks, huge amounts of data have

been generated at the edge of networks [1]. To obtain useful information from big data, machine

learning has been widely applied to deal with complex models and tasks in emerging data-driven

applications, such as autonomous driving, virtual and augmented reality [2]. Standard machine

learning is usually developed under a centralized architecture, where each node located at the

edge sends its collected data to a central node for centralized data processing. However, with

the exponential growth of the volume of local data and the increasing concerns on user data

privacy, it is neither practical nor safe to directly transmit the data of local devices to a central

node due to the limited communication and processing capability as well as the lack of privacy

protection. As such, distributed machine learning is well motivated to overcome these issues.

In the regime of distributed machine learning, federated learning (FL) has been proposed as

a well noted approach for collaborative learning [3]. In FL, local workers train local models

from their own data, and then transmit their local updates to a parameter server (PS). The

PS aggregates these received local updates and sends the averaged update back to the local

workers.These iterative updates between the PS and workers, can be either model parameters

or their gradients, for model averaging [4] and gradient averaging [5], respectively. In this way,

FL relieves communication overheads and protects user privacy compared to traditional data-

sharing based collaborative learning, especially when the local data is in large volume and

privacy-sensitive. Existing research on FL mostly focuses on FL algorithms under idealized link

assumptions. However, the impacts of wireless environments on FL performance should be taken

into account in the design of FL deployed in practical wireless systems. Otherwise, such impacts

may introduce unwanted training errors that dramatically degrade the learning performance in

terms of accuracy and convergence rate [6].

To solve this problem, research efforts have been spent on optimizing network resources

used for transmitting model updates in FL [7], [8]. These works of FL over wireless networks

adopt digital communications, using a transmission-then-aggregation policy. Unfortunately, the

communication overhead and transmission latency become large as the number of active workers

increases. On the other hand, it is worth noting that FL aims for global aggregation and hence

only utilizes the averaged updates of distributed workers rather than the individual local updates

from workers. Alternatively, the nature of waveform superposition in wireless multiple access

3

channel (MAC) [9]–[12] provides a direct and efﬁcient way for transmission of the averaged

updates in FL, also known as analog aggregation based FL [13]–[18]. As a joint transmission-

and-aggregation policy, analog aggregation transmission enables all the participating workers to

simultaneously upload their local model updates to the PS over the same time-frequency resources

as long as the aggregated waveform represents the averaged updates, thus substantially reducing

the overhead of wireless communication for FL.

The research on analog aggregation based FL is still at early stage, leaving some fundamental

questions unexplored, such as its convergence behavior and design of efﬁcient algorithms. Given

the limited transmit power and communication bandwidth at user devices, users may have to

contend for communication resources when transmitting their local updates to the PS. It gives

rise to the need for an efﬁcient transmission paradigm, along with network resource allocation

in terms of worker selection and transmit power control. All these practical issues motivate our

work to study FL from the perspectives of both wireless communications and machine learning.

In this paper, we quantify the impact of analog aggregation on the convergence behavior and

performance of FL. Such quantitative results are essential in guiding the joint optimization

of communication and computing resources. This paper aims at a comprehensive study on

problem formulation, solution development, and algorithm implementation for the joint design

and optimization of wireless communication and FL. Our key contributions are summarized as

follows:

• We derive closed-form expressions for the expected convergence rate of FL over the air

in the cases of convex and non-convex, respectively, which not only interprets but also

quantiﬁes the impact of wireless communications on the convergence and accuracy of FL

over the air. Also, full-size gradient descent (GD) and mini-batched statistical gradient

descent (SGD) methods are both considered in this work. These closed-form expressions

unveil a fundamental connection between analog wireless communication and FL with

analog aggregation, which provides a fresh perspective to measure how the parameter design

of analog wireless systems affects the performance of FL over the air.

• Based on the closed-form theoretical results, we formulate a joint optimization problem of

learning, worker selection, and power control, with a goal of minimizing the global FL

loss function given limited transmit power and bandwidth. The optimization formulation

turns out to be universal for the convex and non-convex cases with GD and SGD. Further,

for practical implementation of the joint optimization problem in the presence of some

4

unobservable parameters, we develop an alternative reformulation that approximates the

original unattainable problem as a feasible optimization problem under the operational

constraints of analog aggregation.

• To efﬁciently solve the approximate problem, we identity a tight solution space by exploring

the relationship between the number of workers and the power scaling. Thanks to the

reduced search space, we propose a simple discrete enumeration method to efﬁciently ﬁnd

the globally optimal solution.

We evaluate the proposed joint optimization scheme for FL with analog aggregation in solving

linear regression and image classiﬁcation problems, respectively. Simulation results show that

our proposed FL is superior to the benchmark scheme that uses random worker selection and

power control, and achieves comparable performance to the ideal case where FL is implemented

over noise-free wireless channels.

The remainder of this paper is organized as follows. Related work is presented in Section II.

The system model for FL over the air and the associated joint communication and learning opti-

mization formulation are presented in Section III. Section IV derives the closed-form expressions

of the expected convergence rate of the FL over the air as the foundation for algorithm design and

performance analysis. Section V provides a framework of joint optimization of communication

and FL, and develops the corresponding algorithms. Section VI presents numerical results,

followed by conclusions in Section VII.

II. RELATED WORK

This section reviews the literature and highlights the novelty of this paper with respect to

related works.

To achieve communication efﬁciency in distributed learning, most of the existing strategies

focus on digital communications, which may involve the preprocessing of transmitted updates

or the management of wireless resources. For example, a popular line of work is to reduce

the communication load per worker by compression of the updates under the assumptions of

ideal communication links, such as exploiting coding schemes [19], utilizing the sparsity of

updates [20], employing quantization of the updates [21], and avoiding less informative local

updates via communication censoring schemes [22]–[26]. Another line of work is to support FL

through communication resource management, such as worker scheduling schemes to maximize

the number of participating workers [27], joint optimization of resource allocation and worker

5

Fig. 1: Federated learning via analog aggregation from wirelessly distributed data.

scheduling [7], and communication and computation resource allocation and scheduling for cell-

free networks [8].

There are some pioneering works on analog aggregation based FL [13]–[18], most of which

focus on designing transmission schemes [13]–[16]. They adopt preselected participating workers

and ﬁx their power allocation without further optimization along FL iterations. The optimization

issues are considered in [17], [18], but they are mainly conducted on the communication side

alone, without an underlying connection to FL. When communication-based metrics are used, the

optimization in existing works often suggests to maximize the number of selected workers that

participate FL, but our theoretical results indicate that selecting more workers is not necessarily

better over imperfect links or under limited communication resources. Thus, unlike these existing

works, we seek to analyze the convergence behavior of analog aggregation based FL, which

provides a fresh angle to interpret the speciﬁc relationship between communications and FL in

the paradigm of analog aggregation. Such a connection leads to this work on a joint optimization

framework for analog communications and FL, in which the work selection and power allocation

decisions are optimized during the iterative FL process.

III. SYSTEM MODEL

As shown in Fig. 1, we consider a one-hop wireless network consisting of a single parameter

server (PS) at a base station and U user devices as distributed local workers. Through federated

learning, the PS and all workers collaborate to train a common model for supervised learning

and data inference, without sharing local data.

⊕Parameter server (PS)Model copiesat localworkersGlobalFL model...Worker 1Worker 2Worker UNoisew1w2wUiiiwKK1g=A. FL Model

6

Let Di = {xi,k, yi,k}Ki

k=1 denote the local dataset at the i-th worker, i = 1, . . . , U , where xi,k
is the input data vector, yi,k is the labeled output vector, k = 1, 2, ..., Ki, and Ki = |Di| is the
number of data samples available at the i-th worker. With K = (cid:80)U

i=1 Ki samples in total, these
U workers seek to collectively train a learning model parameterized by a global model parameter

w = [w1, . . . , wD] ∈ RD of dimension D, by minimizing the following loss function

(Global loss function) F (w; D) =

1
K

U
(cid:88)

Ki(cid:88)

i=1

k=1

f (w; xi,k, yi,k),

(1)

where the global loss function F (w; D) is a summation of K data-dependent components, each

component f (w; xi,k, yi,k) is a sample-wise local function that quantiﬁes the model prediction
error of the same data model parameterized by the shared model parameter w, and D = (cid:83)

i Di.
In distributed learning, each worker trains a local model wi from its local data Di, which can

be viewed as a local copy of the global model w. That is, the local loss function is

(Local loss function) Fi(wi; Di) =

Ki(cid:88)

f (wi; xi,k, yi,k),

(2)

1
Ki

k=1
where wi = [w1
i ] ∈ RD is the local model parameter. Through collaboration, it is
desired to achieve wi = w = w∗, ∀i, so that all workers reach the globally optimal model w∗.

i , . . . , wD

Such a distributed learning can be formulated via consensus optimization as [4], [28]

P1:

min
w

1
K

U
(cid:88)

Ki(cid:88)

i=1

k=1

f (wi; xi,k, yi,k).

(3a)

To solve P1, this paper adopts a model-averaging algorithm for FL [4], [28]. It is essentially

an iterative process consisting of both computing and communication steps at each iteration.

Speciﬁcally, in each communication round, the PS broadcasts the current w to all workers.

Then, the i-th worker uses a learning algorithm to update its wi by minimizing its local data-

dependent loss function in (2). In this work, gradient descent1 is applied, in which the local

model at the i-th local worker is updated as

(Local model updating) wi = w − α∇Fi(wi; Di)

= w −

α
Ki

Ki(cid:88)

k=1

∇f (w; xi,k, yi,k),

(4)

1In this work, we take the basic gradient descent as an example, while the proposed methodology can be extended to mini-batch

gradient descent as well.

7

where α is the learning rate, and ∇f (w; xi,k, yi,k) is the gradient of f (w; xi,k, yi,k) with respect

to w.

When local updating is completed, each worker transmits its updated parameter wi to the PS

via wireless uplinks to update the global w as

(Global model updating) w =

(cid:80)U

i=1 Kiwi
K

.

(5)

Then, the PS broadcasts w in (5) to all participating workers as their initial value in the next

round. The FL implements the local model-updating in (4) and the global model-averaging in (5)

iteratively, until convergence. It has been shown that this FL algorithm converges to the globally

optimal solution of the original problem in P1 under the conditions that F is a convex function

and the data transmission between the PS and workers is error-free [4], [28].

Note that the implementation steps in (4) and (5) only concern the computational aspect of

FL, by assuming perfect communications for both the global w and local wi between the PS and

all workers. However, the communication impacts on FL performance should not be ignored.

Especially in practical wireless network environments, certain errors are inevitably introduced

during transmissions of the updates due to the imperfect characteristics of wireless channels.

B. Analog Aggregation Transmission Model

To avoid heavy communication overhead and save transmission bandwidth of FL over wireless

channels, we adopt analog aggregation without coding, which allows multiple workers to simul-

taneously upload their local model updates to the PS over the same time-frequency resources.

All workers transmit their local wi’s in an analog form with perfect time synchronization among
them2. In this way, the local updates wi’s are aggregated over the air to implement the global

model updating step in (5). Such an analog aggregation is conducted in an entry-wise manner.
i from all workers, i = 1, ..., U , are aggregated to compute wd in (5),

That is, the d-th entries wd

for any d ∈ [1, D].

Let pi,t = [p1

i,t] denote the power control vector of worker i at the t-th
iteration. Noticeably, the choice of pi,t in FL over the air should be made not only to effectively

i,t, . . . , pD

i,t, . . . , pd

2The implementation of time synchronization and the impact of imperfect synchronization are beyond the scope of this work.

Interested readers are referred to [12], [29].

implement the aggregation rule in (5), but also to properly accommodate the need for network

resource allocation. Accordingly, we set the power control policy as

pd
i,t =

i,tKibd
βd
t
hd
i,t

,

(6)

8

where hi,t is the channel gain between the i-th worker and the PS at the t-th iteration3, bd
power scaling factor, and βd

t is the
i,t = 1 means that
the d-th entry of the local model parameter wi,t of the i-th worker is scheduled to contribute

i,t is a transmission scheduling indicator. That is, βd

to the FL algorithm at the t-th iteration, and βd

i,t = 0, otherwise. Through power scaling, the
transmit power used for uploading the d-th entry from the i-th worker should not exceed a
maximum power limit P d,max

for any d, as follows:

= P max
i

i

|pd

i,twd

i,t|2 =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

i,tKibd
βd
t
hd
i,t

wd
i,t

2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ P max
i

.

At the PS side, the received signal at the t-th iteration can be written as

yt =

=

U
(cid:88)

i=1

U
(cid:88)

i=1

pi,t (cid:12) wi,t (cid:12) hi,t + zt

Kibt (cid:12) βi,t (cid:12) wi,t + zt,

(7)

(8)

where (cid:12) represents Hadamard product, hi,t = [h1
[b1

t , ..., bD

t ], and zt ∼ CN (0, σ2I) is additive white Gaussian noise (AWGN).
t , b2
Given the received yt, the PS estimates wt via a post-processing operation as

i,t, h2

i,t, ..., hD

i,t], βi,t = [β1

i,t, β2

i,t, .., βD

i,t], bt =

wt =

=

(cid:32) U

(cid:88)

i=1
(cid:32) U

(cid:88)

i=1

(cid:33)(cid:12)−1

Kiβi,t (cid:12) bt

(cid:12) yt

Kiβi,t

(cid:33)(cid:12)−1 U

(cid:88)

i=1

Kiβi,t (cid:12) wi,t +

(cid:32) U

(cid:88)

i=1

(cid:33)(cid:12)−1

Kiβi,t (cid:12) bt

(cid:12) zt,

(9)

where ((cid:80)U
i=1 Kiβi,t (cid:12) bt)(cid:12)−1 is a properly chosen scaling vector to produce equal weighting for
participating wi’s in (9) as desired in (5), and (X)(cid:12)−1 represents the inverse Hadamard operation

of X that calculates its entry-wise reciprocal. Noticeably, in order to implement the averaging

of (5) in FL over the air, such a post-processing operation requires bt to be the same for all

workers for given t and d, which allows to eliminate bt from the ﬁrst term in (9).

3In this paper, we assume the channel state information (CSI) to be constant within each iteration, but may vary over iterations.

We also assume that the CSI is perfectly known at the PS, and leave the imperfect CSI case in future work.

9

Comparing (9) with (5), there exist differences between wt and w due to the effect of wireless

communications. This work aims to mitigate such a gap through optimizing the worker selection

βi,t and power scaling bt for FL over the air. To this end, our next step is to unveil an important

but unexplored foundation, i.e., how wireless communications affect the convergence behavior

of FL over the air.

IV. THE CONVERGENCE ANALYSIS OF FL WITH ANALOG AGGREGATION

In this section, we study the effect of analog aggregation transmission on FL over the air, by

analyzing its convergence behavior for both the convex and the non-convex cases. To average the

effects of instantaneous SNRs, we derive the expected convergence rate of FL over the air, which

quantiﬁes the impact of wireless communications on FL using analog aggregation transmissions.

A. Convex Case

We ﬁrst make the following assumptions that are commonly adopted in the optimization

literature [7], [30]–[34].

Assumption 1 (Lipschitz continuity, smoothness): The gradient ∇F (w) of the loss function

F (w) is uniformly Lipschitz continuous with respect to w, that is,

(cid:107)∇F (wt+1) − ∇F (wt)(cid:107) ≤ L(cid:107)wt+1 − wt(cid:107),

∀wt, wt+1,

(10)

where L is a positive constant, referred to as a Lipschitz constant for the function F (·).

Assumption 2 (strongly convex): ∇F (w) is strongly convex with a positive parameter µ,

obeying

F (wt+1) ≥ F (wt) + (wt+1 − wt)T ∇F (wt) +

µ
2

(cid:107)wt+1 − wt(cid:107)2,

∀wt, wt+1.

(11)

Assumption 3 (bounded local gradients): The sample-wised local gradients at local workers

are bounded by their global counterpart [32], [33]

(cid:107)∇f (wt)(cid:107)2 ≤ ρ1 + ρ2(cid:107)∇F (wt)(cid:107)2,

(12)

where ρ1, ρ2 ≥ 0.

According to [5], [35], the FL algorithm applied over ideal wireless channels is able to solve

P1 and converges to an optimal w∗. In the presence of wireless transmission errors, we derive

the expected convergence rate of the FL over the air with analog aggregation, as in Theorem 1.

Theorem 1. Adopt Assumptions 1-3, and denote the globally optimal learning model in (3) as

w∗. The model updating rule for wt of the FL-over-the-air scheme is given by (9), ∀t. Given the

transmit power scaling factors bt, worker selection vectors βi,t, and setting the learning rate to
L , the expected performance gap E[F (wt) − F (w∗)] of wt at the t-th iteration is given
be α = 1

10

by

with

E[F (wt) − F (w∗)] ≤ Bt + AtE[F (wt−1) − F (w∗)],

At = 1 −

µ
L

+ ρ2

(cid:32)

D
(cid:88)

d=1

K
i=1 Kiβd
i,t

(cid:80)U

(cid:33)

− 1

,

(cid:32)

D
(cid:88)

Bt =

K
i=1 Kiβd
i,t
where the expectation is over the channel AWGN of zero mean and variance σ2.

Kiβi,t (cid:12) bt

ρ1
2L

(cid:80)U

− 1

(cid:88)

d=1

i=1

+

Lσ2
2

(cid:33)(cid:12)−1 (cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:33)

(cid:32) U

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(13)

(14)

,

(15)

Proof. The proof of Theorem 1 is provide in Appendix A.

Based on Theorem 1, we further derive the cumulative performance gap resulted from wireless

communications and the worker selection of the whole FL process, summarized by the following

Lemma 1.

Lemma 1. Given an initial global model w0, the cumulative performance gap E[F (wt)−F (w∗)]

of FL after t iterations is bounded by

E[F (wt) − F (w∗)] ≤

t−1
(cid:88)

i
(cid:89)

j=1

i=1
(cid:124)

At+1−jBt−i + Bt

+

(cid:123)(cid:122)
∆t

(cid:125)

t
(cid:89)

j=1

AjE[F (w0) − F (w∗)].

(16)

Proof. Given the expected performance gap at the t-th iteration in (13), we carry out recursions

as follows:

E[F (wt) − F (w∗)] ≤ Bt + AtE[F (wt−1) − F (w∗)]

Å

≤ Bt + At

Bt−1 + At−1E[F (wt−2) − F (w∗)]

ã

≤ ...

t−1
(cid:88)

i
(cid:89)

≤

i=1

j=1

At+1−jBt−i + Bt +

t
(cid:89)

j=1

AjE[F (w0) − F (w∗)].

(17)

11

.

Lemma 1 reveals that the FL algorithm converges asymptotically in t under mild conditions,

as stated in Proposition 1.

Proposition 1. Given the learning rate α = 1

L, the convergence of the FL algorithm is guaranteed

with limt→∞ wt = w∗, as long as ρ2 in (12) satisﬁes the following condition:

0 < ρ2 <

µ
− 1)DL

,

( K
Kmin

(18)

where Kmin = min{Ki}U

i=1.

Proof. When At < 1, ∀t, it is evident that limt→∞
j=1 Aj = 0. From Lemma 1, to guarantee
the convergence, a sufﬁcient condition is to ensure Amax (cid:44) max{At, t = 1, 2...} < 1. Given

(cid:81)t+1

(14), it holds that

At = 1 −

≤ 1 −

µ
L

µ
L

+ ρ2

+ ρ2

(cid:32)

D
(cid:88)

(cid:32)

d=1

D
(cid:88)

d=1

K
i=1 Kiβd
i,t
(cid:33)
,

− 1

(cid:33)

− 1

(19)

(cid:80)U

K
Kmin

where Kmin = min{Ki}U
then At ≤ 1 − µ

L + ρ2D(U − 1).
To ensure Amax < 1, we have

i=1. When all workers have the same amount of data, i.e., Ki = K

U , ∀i,

Amax ≤ 1 −

µ
L

+ ρ2

(cid:32)

D
(cid:88)

d=1

K
Kmin

(cid:33)

− 1

< 1.

(20)

From (20), it holds that ρ2 <

. On the other hand, ρ2 > 0, according to (12) in

µ
−1)DL

( K
Kmin

Assumption 3. As a result, we have 0 < ρ2 <

µ
−1)DL

( K
Kmin

, which completes the proof.

Proposition 1 indicates that the convergence behavior of the FL algorithm depends on both the

learning-related parameters, i.e., µ, L, ρ1, ρ2, and communication-related parameters, including
β, b and σ2. Interestingly, the channel noise σ2 and b do not affect At, and hence they do not

affect the convergence of the FL algorithm but determine the steady state that the FL algorithm

converges to.

Lemma 1 also provides the expected convergence rate of an FL algorithm when the trans-

mission link is error-free. In this ideal case, it offers the fastest convergence rate achievable by

the FL algorithm, which is derived by the following Lemma 2.

12

Lemma 2. Consider a resource-unconstrained and error-free mode where the effects of wireless

channels, as well as that of noise, are already mitigated or fully compensated. Given the optimal
global w∗ and the learned wt in (9), the upper bound of E[F (wt) − F (w∗)] for the FL over

the air is given by

E[F (wt) − F (w∗)] ≤ (1 −

µ
L

)tE[F (w0) − F (w∗)].

(21)

Proof. Without channel noise or worker selection (that is, all workers participate the FL and
deliver their data perfectly), we have σ2 = 0 and (cid:80)D
(15), we have Bt = B = 0 and At = A = 1 − µ

L , ∀t. As a result, (16) is reduced to (21).

= 0. Then, in (14) and

K
i=1 Kiβd
i,t

− 1

d=1

(cid:80)U

(cid:16)

(cid:17)

It is worth noting that Lemma 2 provides the convergence rate for the ideal case, which

assumes that the impacts of wireless communications, including noise, channel and constrained

resources, are all mitigated to result in error-free transmission. According to (16) in the realistic
case, the trajectory of E[F (wt+1)] exhibits jump discontinuity with a gap term ∆t at each step

t, as deﬁned in (16):

∆t =

t−1
(cid:88)

i
(cid:89)

i=1

j=1

At+1−jBt−i + Bt.

This gap reﬂects the impact of wireless communication factors on FL, by means of the worker

selection, transmit power scaling and AWGN. Intuitively, this gap diminishes as the number of

selected workers increases, which reduces the value of At. Meanwhile, as the power scaling

factor bt increases, Bt is decreased, which leads to a reduction of the gap as well. Hence, it is

necessary to optimize transmit power scaling factors and worker selection in order to minimize

the gap in (16) for the implementation of FL algorithms over a realistic wireless network.

B. Non-convex Case

When the loss function F (w) is nonconvex, such as in the case of convolutional neural

networks, we derive the convergence rate of the FL over the air with analog aggregation for the

nonconvex case without Assumption 2, which is summarized in Theorem 2.

Theorem 2. Under the Assumptions 1 and 3 for the non-convex case, given the transmit power

13

scaling factors bt, worker selection vectors βi,t, the optimal global FL model w∗, and the
learning rate α = 1

L , the convergence at the T -th iteration is given by
T
(cid:88)

2L

(cid:107)∇F (wt−1)(cid:107)2 ≤

E[F (w0)] − F (w∗)]

1
T

t=1

− 1))

T (1 − ρ2D( K
Kmin
2L (cid:80)T
T (1 − ρ2D( K
Kmin

t=1 Bt

+

.

− 1))

(22)

Proof. Please refer to Appendix B.

As we can see from Theorem 2, when T is large enough, we have

min
0,1,...,T

E[(cid:107)∇F (wt−1)(cid:107)2] ≤

1
T

T
(cid:88)

t=1

(cid:107)∇F (wt−1)(cid:107)2

T →∞
≤

t=1 Bt

2L (cid:80)T
T (1 − ρ2D( K
Kmin
(cid:124)

(cid:123)(cid:122)
(cid:52)N C
T

,

(23)

− 1))
(cid:125)

which guarantees convergence of the FL algorithm to a stationary point [28], [36]. Similarly,

the performance gap at the step t for non-convex cases is given by

(cid:52)N C

t =

2L (cid:80)T
T (1 − ρ2D( K
Kmin

t=1 Bt

.

− 1))

(24)

Note that the non-convex case and the convex shares the same sufﬁcient condition for con-

vergence as (18) in Proposition 1.

C. Stochastic gradient descent

Our work can be extended to stochastic versions of gradient descent (SGD) as well. Here, we

provide convergence analysis for mini-batch gradient descent with a constant mini-batch size Kb,

while the results directly apply to the standard SGD by setting Kb = 1. Theorem 3 summarizes

the convergence behavior of SGD for the strongly convex case.

Theorem 3. Under the Assumptions 1, 2 and 3 for the convex case, and given the transmit power

scaling factors bt, worker selection vectors βi,t, the optimal global FL model w∗, the learning
rate α = 1

L and the mini-batch size Kb, the convergence behavior of the SGD implementation

of FL over the air is given by

E[F (wt) − F (w∗)] ≤

t−1
(cid:88)

i
(cid:89)

j=1

i=1
(cid:124)

ASGD

t+1−jBSGD

t−i + BSGD

t

(cid:123)(cid:122)
∆SGD
t

(cid:125)

+

t
(cid:89)

j=1

ASGD
j

E[F (w0) − F (w∗)],

(25)

(cid:33)

+

((cid:80)U
(cid:80)U

i=1 Kb)
i=1 Kbβd
i,t

14

(26)

where

ASGD
t

=1 −

µ
L

(cid:32) D
(cid:88)

(cid:32)

+ ρ2

((cid:80)U

i=1 Kb)2 − 2K((cid:80)U
K 2

i=1 Kb)

d=1
i=1(Ki − Kb))2

((cid:80)U

(cid:33)
,

+

K 2

(cid:32) D
(cid:88)

(cid:32)

d=1

BSGD
t

=

ρ1
2L

+

((cid:80)U

i=1 Kb)2 − 2K((cid:80)U
K 2

i=1 Kb)

+

((cid:80)U

i=1(Ki − Kb))2

K 2

(cid:33)

+

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:32) U

(cid:88)

i=1

(cid:33)

((cid:80)U
(cid:80)U

i=1 Kb)
i=1 Kbβd
i,t
(cid:33)(cid:12)−1(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Lσ2
2

Kiβi,t (cid:12) bt

.

(27)

Proof. Please refer to Appendix C.

From Theorem 3, the cumulative performance gap of FL after the t-th iteration for the SGD

case is bounded by

(cid:52)SGD
t

=

t−1
(cid:88)

i
(cid:89)

i=1

j=1

ASGD

t+1−jBSGD

t−i + BSGD

t

.

(28)

Remark 1. If Kb is set to be Ki, then Theorem 3 for SGD is the same as Theorem 1 for GD.

In addition, since the common mini-batch size is no larger than the minimum local data size,
i.e., Kb ≤ Kmin ≤ K
leads to a smaller ∆SGD

in (25). In other words, FL has a better convergence performance with

in (27) decrease as Kb increases, which

in (26) and BSGD

U , both ASGD

t

t

t

a larger Kb. On the other hand, such an improvement on performance is achieved at the cost

of high computation load at the local workers in each communication round, which reﬂects the

tradeoff between training performance and computational complexity in SGD.

Similarly, we can also derive the mild convergence condition for SGD, given by the following

Proposition 2.

Proposition 2. Given the learning rate α = 1

L , the convergence of the FL algorithm for SGD
cases is guaranteed with limt→∞ wt = w∗, as long as ρ2 in (12) satisﬁes the following condition:

0 < ρ2 <

( 2U Kb

K + U 2K2

b

µ
K2 + DU − 2DU Kb

K + DU 2K2

K2

b

.

)L

(29)

Proof. Similar to the GD case, to guarantee the convergence, a sufﬁcient condition is still to

15

ensure ASGD
max

(cid:44) max{ASGD

t

ASGD
t

=1 −

≤1 −

µ
L

µ
L

, t = 1, 2...} < 1. It holds that,
(cid:32)

(cid:32)

+ ρ2

(cid:32)

+ ρ2

(K − U Kb)2
K 2

(K − U Kb)2
K 2

+

+

D
(cid:88)

U 2K 2

b − 2KU Kb

d=1

K 2

DU 2K 2

b − 2DKU Kb

K 2

(cid:33)(cid:33)

+

(cid:80)U

U
i=1 βd
i,t
(cid:33)

+ DU

,

(30)

which comes from the fact that (cid:80)U

i=1 βd

i,t ≥ 1.

Thus, we have

ASGD

max ≤ 1 −

(cid:32)

µ
L

+ ρ2

b − 2DKU Kb + DU K 2
(K − U Kb)2 + DU 2K 2
K 2

(cid:33)

< 1.

(31)

From (31), we can get ρ2 <

(1−

Assumption 3, we get (29) as a result.

µ

U 2K2
b
K2 +DU −

2DU Kb

K +

DU 2K2
b
K2

)L

. Considering ρ2 > 0 in

2U Kb

K +

V. PERFORMANCE OPTIMIZATION FOR FEDERATED LEARNING OVER THE AIR

In this section, we ﬁrst formulate a joint optimization problem to reduce the gap for FL

over the air, which turns out to be applicable for both the convex and non-convex cases, using

either GD or SGD implementations. To make it applicable in practice in the presence of some

unobservable parameters at the PS, we reformulate it to an approximate problem by imposing a

conservative power constraint. To efﬁciently solve such an approximate problem, we ﬁrst identify

a tight solution space and then develop an optimal solution via discrete programming.

A. Problem Formulation for Joint Optimization

Since we are concerned with convergence accuracy, our optimization problem boils down to

minimizing the performance gap for different cases (i.e., (cid:52)t, (cid:52)N C

t

, and (cid:52)SGD

t

) at each iteration

under the corresponding convergence conditions (i.e., Proposition 1 and Proposition 2).

We recognize that solving P1 amounts to iteratively minimizing those gap (cid:52)t, (cid:52)N C

t

, and

(cid:52)SGD
t

under the transmit power constraint in (7). At the t-th iteration, the objective functions

for those three cases are given by

(cid:52)t =Bt + At(cid:52)t−1,

(cid:52)N C

t =Bt,

(cid:52)SGD
t

=BSGD
t

+ ASGD

t (cid:52)SGD
t−1

.

(32)

(33)

(34)

= 0. Note that when the optimization is executed at the t-th iteration,

16

where (cid:52)0 = 0 and (cid:52)SGD
(cid:52)t−1 and (cid:52)SGD

0

t−1 can be treated as constants.

Considering the entry-wise transmission for analog aggregation, we remove irrelevant items

and extract the component of the d-th entry from those gap in (32), (33) and (34) as the objective

to minimize, which is given by

Rt[d] =

RN C
t

[d] =

RSGD
t

[d] =

2

2

2

Ä(cid:80)U

Ä(cid:80)U

Lσ2

i=1 βd
Lσ2

i=1 βd
Lσ2

i,tKibd
t

i,tKibd
t

Ä(cid:80)U

i=1 βd

i,tKibd
t

ä2 +

Kρ1 + 2KLρ2(cid:52)t−1

2L (cid:80)U

i=1 Kiβd
i,t

,

∀d,

ä2 +

Kρ1
i=1 Kiβd
i,t

2L (cid:80)U

,

∀d,

ä2 +

U (ρ1 + 2Lρ2(cid:52)t−1)

2L (cid:80)U

i=1 Kiβd
i,t

,

∀d.

(35)

(36)

(37)

Since all entries indexed by d are separable with respect to the design parameters, we perform

entry-wise optimization by considering wt and wi,t one entry at a time, where the superscript d

and the index of different cases are omitted hereafter. To determine the worker selection vector

βi,t and the power scaling factor bt at the t-th iteration, the PS carries out a joint optimization

problem formulated as follows:

P2:

min
{bt,βi,t}U

i=1

Rt

s.t.

(cid:12)
(cid:12)
(cid:12)
(cid:12)

βi,tKibt
hi,t

wi,t

2

(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ P max
i

,

βi,t ∈ {0, 1}, i ∈ {1, 2, ..., U },

(38a)

(38b)

where Ki should be Kb in (38b) for the SGD case.
However, in (38b), the knowledge of {wi,t}U

i=1 is needed but is unavailable to the PS due to

analog aggregation.

To overcome this issue, we reformulate a practical optimization problem via an approximation

(cid:80)U

that wt−1 ≈ 1
U

i=1 wi,t, in light of the consensus constraint in P1. According to (47) in the
proof of Theorem 1, each local parameter wi,t is updated from the broadcast wt−1 along the
direction of the averaged gradient over its local data α
Ki

k=1 ∇f (wt−1; xi,k, yi,k). Hence, it is
reasonable to make the following common assumption on bounded local gradients, considering

(cid:80)Ki

that the local gradients can be controlled by adjusting the learning rate or through simple clipping

[21], [28], [37], [38].

17

Assumption 4 (bounded local gradients): The gap between the global parameter wt−1 and

the local parameter update wi,t, ∀i, t is bounded by

|wt−1 − wi,t| ≤ η,

where η ≥ 0 is related to the learning rate α that satisﬁes the following condition4

η ≥ max






(cid:40)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

α
Ki

Ki(cid:88)

k=1

(cid:12)
(cid:12)
(cid:12)
∇f (w, xi,k, yi,k)
(cid:12)
(cid:12)

(cid:41)U

i=1






.

(39)

(40)

Under Assumption 4, we reformulate the original optimization problem (P2) into the following

problem (P3), by replacing wi,t in (38b) by its approximation:

P3:

min
{bt,βi,t}U

i=1

Rt

s.t.

(cid:12)
(cid:12)
(cid:12)
(cid:12)

βi,tKibt
hi,t

2

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(|wt−1| + η)2 ≤ P max

i

,

βi,t ∈ {0, 1}, i ∈ {1, 2, ..., U },

(41a)

(41b)

(41c)

where the power constraint (41b) is constructed based on the fact that

(cid:12)
(cid:12)
(cid:12)
(cid:12)

βi,tKibt
hi,t

wi,t

2

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
=
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤

βi,tKibt
hi,t

βi,tKibt
hi,t

2

2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

|wi,t|2

(|wt−1| + η)2.

(42)

Since wt−1 is always available at the PS, P3 becomes a feasible formulation for adoption in

practice. Next, we develop the optimal solution to P3.

B. Optimal Solution to P3 via Discrete Programming

At ﬁrst glance, a direct solution to P3 leads to a mixed integer programming (MIP), which

unfortunately incurs high complexity. To solve P3 in an efﬁcient manner, we develop a simple

solution by identifying a tight search space without loss of optimality. The tight search space,

given in the following Theorem 4, is a result of the constraints in (41b) and (41c), irrespective

of the objective function (41a). Hence, it holds universally for any Rt, such as those in (35)-(37).

4This implies the value range of η. In practice, η can take |wt−1 − wt−2|. In addition, for the SGD case, we have η ≥

max{{|αEDi [∇f (w, xi,k, yi,k)]|}U

i=1}

(43)

(44)

Theorem 4. When all the required parameters in P3 i.e., {P max

i=1, are avail-
able at the PS, the solution space of (bt, βi,t) in P3 can be reduced to the following tight search

, wt−1, hi,t, Ki, η}U

i

18

space without loss of optimality as

(cid:40)ß Ä

b(k)
t

ä ™U

, β(k)
i,t

S =

k=1

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

b(k)
t =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:112)P max

k hk,t

Kk(|wt−1| + η)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

where β(k)

t

is a function of b(k)

t

, in the form:

, β(k)

t (b(k)

t ) =

î

1,t , . . . , β(k)
β(k)

U,t

ó

(cid:41)

, k = 1, . . . , U

,

β(k)
i,t = H

Å

P max

i −

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Kib(k)

t (|wt−1| + η)

hi,t

ã

(cid:12)
(cid:12)
(cid:12)
(cid:12)

and H(x) is the Heaviside step function, i.e., H(x) = 1 for x > 0, and H(x) = 0 otherwise.

Proof. Please see Appendix B.

Thanks to Theorem 4, we equivalently transform P3 from a MIP into a discrete programming

(DP) problem P4 as follows

P4:

min
(bt,βt)∈S

Rt = Rt (bt, βt)

(45)

According to P4, the objective Rt can only take on U possible values corresponding to the U

feasible values of bt; meanwhile, given each bt, the value of βt is uniquely determined. Hence

the minimum Rt can be obtained via line search over the U feasible points (bt, βt) in (43). Note

that the feasible points in (43) are determined by the channel gains, power limits and data sizes

of the U workers. Hence, the optimal transmission policy decided by P4 reﬂects the tradeoff

among workers in terms of their channel quality, available power resource, and data quality.

It is worth noting that the solution b∗

t of P4 may exceed the maximum value allowed at
a worker, due to the approximation introduced in Assumption 4. To strictly comply to the

power constraint, each worker needs to take the following bounding step when sending its local

parameters:
Kib∗
t wi,t
hi,t

(cid:12)
(cid:12)
1) if
(cid:12)
(cid:12)
2) otherwise, it sends (cid:112)P max

≤ P max
i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

2

i

, then the i-th worker sends Kib∗
t wi,t
hi,t

;

sgn(wi,t), where sgn(·) is the sign function.

Putting together, we propose a joint optimization for FL over the air (INFLOTA) as sum-

marized in Algorithm 1, which is a dynamic scheduling and power scaling policy. By using

different Rt, our INFLOTA can be adjust to all the considered cases including the convex and

non-convex, using either GD or SGD implementations.

Algorithm 1 The implementation of INFLOTA
Given:

19

System parameters {P max

i

i=1;

, Ki, η}U
1, β∗

1: The PS initializes {w0, b∗

1} and broadcasts them to all the local workers.

2: for t = 1 : T do

3: At the workers:

4:

5:

Computation: Iteratively update the local model via (4) where w = wt−1 is from the PS;

Communication: Upon receiving (bt, βt), send sgn(wi,t) min

Ä Kibt|wi,t|
hi,t

, (cid:112)P Max

i

ä

to the

PS, if βi,t = 1, ∀i, d;

6: At the PS:

7:

8:

9:

10:

11:

12:

Calculate the global model wt via (9) from yt that is aggregated from local workers;

for d = 1 : D do

Calculate S from (43), which yields U feasible points {(b(k)

t+1, β(k

t+1)}U

k=1;

Solve P4 in (45) by using a line search over the U feasible points to ﬁnd the optimal

{b∗

t+1, β∗

t+1} for given d and t;

end for

Send wt and (bt+1, βt+1) (including all D optimal {b∗

t+1, β∗

t+1}) to all the workers;

13: end for

Remark 2. (Optimality) P3 is equivalently reformulated as P4, which is solved by a search

method with much reduced computational complexity thanks to the reduced search space. Com-

paring P3 to P2, the constraint (41b) of P3 is more restrictive than the constraint in (38b) of P2.

Since P3 reduces the feasible domain of P2, the solution to P3 cannot be superior to that of P2.

Therefore, the optimal solution of P3 is an upper bound of P2, i.e., Rt calculated by solving P3

is larger than the actual one.

Remark 3. (Complexity) Algorithm 1 provides a holistic solution for implementation of the

overall FL at both the PS and workers sides. Its computational complexity is mainly determined

by that of the optimization step in P4. The complexity order of the optimization step is low at

O(U ), since the search space is reduced to U points only via P4.

Remark 4. (Implementation) To implement the FL over the air in Algorithm 1, the PS must

20

know the CSI, the number of the data samples and the maximum transmit power of all local

workers. This information can be obtained by the PS when local workers initially connect to

it. Before the implementation of Algorithm 1, the PS must ﬁrst broadcast the global model

information to the workers. Noticeably, taking P4 into the implementation of FL, some workers

need to send sgn(wi,t) min

Ä Kibt|wi,t|
hi,t

, (cid:112)P Max

i

ä

to meet the requirement on the maximum transmit

power. Such a bounding method can be viewed as a quantization measure, which does not affect

the convergence [39].

VI. SIMULATION RESULTS AND ANALYSIS

In the simulations, we evaluate the performance of the proposed INFLOTA for both linear

regression and image classiﬁcation tasks, which are based on a synthetic dataset and the MNIST

dataset, respectively.

The considered network has U = 20 workers, whose maximum power is set to be P max

i

=

P max = 10 mW for any i ∈ [1, U ]. The receiver noise power at PS is set to be σ2 = 10−4
mW, i.e., SN R = P max

σ2 = 5 dB. The wireless channel gain between the workers and the PS are
generated from a Rayleigh fading model. Here, hi,t is generated from an exponential distribution

with unit mean for different i and t.

We use two baseline methods for comparison: a) an FL algorithm that assumes idealized

wireless transmissions with error-free links to achieve perfect aggregation, and b) an FL algorithm

that randomly determines the power scalar and user selection. They are named as Perfect

aggregation and Random policy, respectively. In Random policy, the probability of each worker

being selected is 50% and the power scalar is generated from an exponential distribution with

unit mean.

A. Linear regression experiments

In linear regression experiments, the synthetic data used to train the FL algorithm is generated

randomly from [0, 1]. The input x and the output y follow the function y = −2x+1+n×0.4 where

n follows a Gaussian distribution N (0, 1). The FL algorithm is used to model the relationship

between x and y.

Since linear regression only involves two parameters, we train a simple two-layer neural

network, with one neuron in each layer, without activation functions, which is the convex case.

21

Fig. 2: An example of implementing FL for linear regression.

Fig. 3: MSE as the number of iteration varies.

The loss function is the MSE of the model prediction ˆy and the labeled true output y. The

learning rate is set to 0.01.

Fig. 2 shows an example of using FL for linear regression. The optimal result of a linear

regression is y = −2x + 1, because the original data generation function is y = −2x + 1 + 0.4n.

In Fig. 2, we can see that the most accurate approximation is achieved by Perfect aggregation,

which is the ideal case without considering the inﬂuence of wireless communication. Random

policy considers the inﬂuence of wireless communication but without any optimization. Thus, its

performance is worst. Our proposed INFLOTA performs closely to the ideal case, which jointly

considers the learning and the inﬂuence of wireless communication. This is because that our

proposed INFLOTA can optimize worker selection and power control so as to reduce the effect

of wireless transmission errors on FL.

00.20.40.60.81Input of the FL algorithm-1.5-1-0.500.511.52Output of the FL algorithmData samplesOptimal resultPerfect aggregationOur INFLOTARandom policy1020304050Iteration (t)100MSEPerfect aggregationOur INFLOTARandom policy22

Fig. 4: MSE as the number of workers varies.

In Fig. 3, we show how wireless transmission affects the convergence behavior of the global

FL model training in terms the value of the loss function and the global FL model remains

unchanged which shows that the global FL model converges. As we can see, as the number of

iterations increases, the MSE values of all the considered learning algorithms decrease at different

rates, and eventually ﬂatten out to reach their steady state. All schemes converge, but to different

steady state values. This behavior corroborates the results in Lemma 1 and Proposition 1 that

the channel noise does not affect the convergence of the FL algorithm but it affects the value

that the FL algorithm converges to.

Fig. 4 shows how MSE varies with the total number of workers U . In general, the MSE

performance of all considered FL schemes decreases as U increases. This is due to the fact

that an increase in the number of workers leads to an increased volume of data available for

the FL training and hence improved accuracy of the estimated model parameters. Moreover, as

the number of workers increases, the effect of wireless transmission on the global FL model

accuracy starts to diminish. This is because the data samples may be already enough for accurate

training when U exceeds a certain level.

In Fig. 5, we present how the MSE changes with the average number of samples per worker
¯K = K/U . The number of data samples per worker ﬂuctuates around the average number,
i.e., we set Ki = round(uniform[ ¯K − 5, ¯K + 5]). As ¯K increases, all of the considered learning

algorithms have more data samples available for training, and hence the MSE of all of considered

FL algorithms decrease in Fig. 5. As the average data samples per worker continues to increase,

the MSE improvement slows down and eventually saturates. This is because that as the data

345678910Number of workers0.150.20.250.30.350.40.450.50.55MSEPerfect aggregationOur INFLOTARandom policy23

Fig. 5: MSE as the number of data samples per worker varies.

Fig. 6: MSE as the noise variance varies.

samples per worker continues to increase, the data samples are enough for training the FL

model.

Fig. 6 presents how the AWGN received by the PS affects the MSE. We can see that as the

noise variance increases, the MSE values of all of considered FL algorithms increase, except for

Perfect aggregation. When the noise variance is small (e.g., less than 10−1), it has little effect

on the performance of FL algorithms.

B. Evaluation on the MNIST dataset

In order to evaluate the performance of our proposed INFLOTA in realistic application sce-

narios with real data, we train a multilayer perceptron (MLP) on the MNIST dataset5 with a

5http://yann.lecun.com/exdb/mnist/

81624324048Average number of data samples per worker0.150.20.250.30.350.40.45MSEPerfect aggregationOur INFLOTARandom policy00.20.40.60.81Noise variance00.511.522.53MSEPerfect aggregationOur INFLOTARandom policy24

Fig. 7: Cross entropy as the number of iteration varies.

Fig. 8: Test accuracy as the number of iteration varies.

784-neuron input layer, a 64-neuron hidden layer, and a 10-neuron softmax output layer, which

is a non-convex case. We adopt cross entropy as the loss function, and rectiﬁed linear unit

(ReLU) as the activation function. The total number of parameters in the MLP is 50890. The

learning rate α is set as 0.1. In MNIST dataset, there are 60000 training samples and 10000

test samples. We randomly take out 500 − 1000 training samples and distribute them to 20 local

workers as their local data. Then the three trained FL are tested with 10000 test samples. We

provide the results of cross entropy and test accuracy versus the iteration index t in Fig. 7 and

Fig. 8, respectively. Since the MNIST dataset is designed for handwritten digit identiﬁcation,

the test accuracy presents the identiﬁcation accuracy. As we can see, our proposed INFLOTA

outperforms Random policy, and achieves comparable performance as Perfect aggregation.

01020304050Iteration00.511.522.533.5Cross entropyPerfect aggregationOur INFLOTARandom policy01020304050Iteration0.10.20.30.40.50.60.70.80.9Test accuracyPerfect aggregationOur INFLOTARandom policy25

VII. CONCLUSION

In this paper, we have studied the joint optimization of communications and FL over the

air with analog aggregation, in which both worker selection and transmit power control are

considered under the constraints of limited communication resources. Under the convex and

non-convex cases with either the GD or SGD implementations, we respectively derive closed-

form expressions for the expected convergence rate of the FL algorithm, which can quantify the

impact of resource-constrained wireless communications on FL under the analog aggregation

paradigm. Through analyzing the expected convergence rate, we have proposed a joint optimiza-

tion scheme of worker selection and power control, which can mitigate the impact of wireless

communications on the convergence and performance of the FL algorithm. More signiﬁcantly,

our joint optimization scheme is applicable for both the convex and non-convex cases, using

either GD or SGD implementations. Simulation results show that the proposed optimization

scheme is effective in mitigating the impact of wireless communications on FL.

ACKNOWLEDGMENTS

We are very grateful to all reviewers who have helped improve the quality of this paper. This

work was partly supported by the National Natural Science Foundation of China (Grant Nos.

61871023 and 61931001), Beijing Natural Science Foundation (Grant No. 4202054), and the

National Science Foundation of the US (Grant Nos. 1741338 and 1939553).

APPENDIX A

PROOF OF THEOREM 1

Theorem 1 considers the full GD method for convex problems. Following the proof for the

gradient methods with noise in [33], we ﬁrst present the inequality implied by the Assumption

1, as follows

F (wt) ≤ F (wt−1) + (wt − wt−1)T ∇F (wt−1) +

L
2

(cid:107)wt − wt−1(cid:107)2.

(46)

Employing a standard full GD method, the i-th worker updates its local FL model parameter

wi,t at the t-th iteration by

wi,t = wt−1 −

α
Ki

Ki(cid:88)

k=1

∇f (wt−1, xi,k, yi,k),

i = 1, 2, ..., U.

(47)

Substituting (47) to (9), we have

wt =wt−1 +

(cid:33)(cid:12)−1

Kiβi,t (cid:12) bt

(cid:12) zt

(cid:32) U

(cid:88)

i=1

− α

(cid:32) U

(cid:88)

i=1

(cid:33)(cid:12)−1

Kiβi,t

(cid:12)

U
(cid:88)

Ki(cid:88)

i=1

k=1

=wt−1 − α(∇F (wt−1) − o),

βi,t (cid:12) ∇f (wt−1; xi,k, yi,k)

26

(48)

where

(cid:32)

o =∇F (wt−1) +

α

U
(cid:88)

(cid:33)(cid:12)−1

Kiβi,t (cid:12) bt

(cid:12) zt

i=1
(cid:33)(cid:12)−1

Kiβi,t

(cid:12)

(cid:32) U

(cid:88)

−

i=1

U
(cid:88)

Ki(cid:88)

i=1

k=1

βi,t (cid:12) ∇f (wt−1; xi,k, yi,k).

(49)

Given the learning rate α = 1

L (a special setting for simple expression without loss of

generality), the expected optimization function of E[F (wt)] can be expressed as

ï
E[F (wt)] ≤E

F (wt−1) − α(∇F (wt−1) − o)T ∇F (wt−1) +

(cid:107)∇F (wt−1) − o(cid:107)2

ò

Lα2
2

(a)
=E[F (wt−1)] −

1
2L

(cid:107)∇F (wt−1)(cid:107)2 +

1
2L

E[(cid:107)o(cid:107)2],

where the step (a) is derived from the fact that

Lα2
2

(cid:107)∇F (wt−1) − o(cid:107)2 =

1
2L

(cid:107)∇F (wt−1)(cid:107)2 −

1
L

oT ∇F (wt−1) +

1
2L

(cid:107)o(cid:107)2.

(50)

(51)

E[(cid:107)o(cid:107)2] can be derived as follows
(cid:34)(cid:13)
(cid:32)
(cid:13)
(cid:13)
(cid:13)

∇F (wt−1) +

E[(cid:107)o(cid:107)2] =E

α

(cid:33)(cid:12)−1

Kiβi,t (cid:12) bt

(cid:12) zt

U
(cid:88)

i=1

(cid:32) U

(cid:88)

−

(cid:33)(cid:12)−1

Kiβi,t

(cid:12)

U
(cid:88)

Ki(cid:88)

i=1

k=1

βi,t (cid:12) ∇f (wt−1; xi,k, yi,k)

2(cid:35)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:80)Ki

k=1 ∇f (wt−1; xi,k, yi,k)

K

(cid:33)(cid:12)−1

Kiβi,t

(cid:12)

− βi,t (cid:12)

i=1

(cid:80)U

i=1

=E

(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:32) U

(cid:88)

−

i=1

U
(cid:88)

i=1

(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)

Ñ

1
K

=E

(cid:32)

+

α

U
(cid:88)

i=1

U
(cid:88)

Ki(cid:88)

k=1

i=1
(cid:32) U

(cid:88)

i=1

(cid:33)(cid:12)−1

Kiβi,t (cid:12) bt

(cid:12) zt

2(cid:35)
,

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:32)

+

α

U
(cid:88)

i=1

(cid:33)(cid:12)−1

Kiβi,t (cid:12) bt

(cid:12) zt

βi,t (cid:12) ∇f (wt−1; xi,k, yi,k)

2(cid:35)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:33)(cid:12)−1é

Kiβi,t

(cid:12)

Ki(cid:88)

k=1

∇f (wt−1; xi,k, yi,k)

27

(52)

where 1 is the all-1 vector of length D. The dimension of 1 is the same length as that of βi,t.

Employing the triangle inequality of norms (cid:107)X + Y(cid:107) ≤ (cid:107)X(cid:107) + (cid:107)Y(cid:107), the submultiplicative

property of norms (cid:107)XY(cid:107) ≤ (cid:107)X(cid:107)(cid:107)Y(cid:107), and the Jensen’s inequality, (52) can be further derived

as follows

E[(cid:107)o(cid:107)2] ≤E

(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Ñ

U
(cid:88)

1
K

− βi,t (cid:12)

(cid:32) U

(cid:88)

i=1

Kiβi,t

(cid:33)(cid:12)−1é

(cid:12)

Ki(cid:88)

k=1

∇f (wt−1; xi,k, yi,k)

(cid:32)

i=1
(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

+ E

(cid:33)(cid:12)−1

α

U
(cid:88)

i=1

Kiβi,t (cid:12) bt

(cid:34)
≤E

K

U
(cid:88)

i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
K

− βi,t (cid:12)

(cid:32) U

(cid:88)

i=1

Kiβi,t

+ E

(cid:32)

(cid:34) (cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
K

U
(cid:88)

i=1
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:32) U

(cid:88)

i=1

≤K

+

(cid:33)(cid:12)−1

α

U
(cid:88)

i=1

Kiβi,t (cid:12) bt

(cid:32) U

(cid:88)

Kiβi,t

− βi,t (cid:12)

i=1

(cid:33)(cid:12)−1(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

2(cid:35)

(cid:12) zt

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:33)(cid:12)−1 (cid:13)
2 Ki(cid:88)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
2 (cid:35)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:33)(cid:12)−1 (cid:13)
2 Ki(cid:88)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:12) zt

k=1

k=1

(cid:107)∇f (wt−1; xi,k, yi,k)(cid:107)2

(cid:107)∇f (wt−1; xi,k, yi,k)(cid:107)2

Kiβi,t (cid:12) bt

σ2L2.

(53)

Applying (12) in Assumption 3 to (53) leads to

2(cid:35)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:35)

E[(cid:107)o(cid:107)2] ≤K

U
(cid:88)

(cid:32) U

(cid:88)

Kiβi,t

− βi,t (cid:12)

28

(cid:33)(cid:12)−1 (cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Ki(ρ1 + ρ2(cid:107)∇F (wt−1)(cid:107)2)

+

Kiβi,t (cid:12) bt

σ2L2

(cid:32)

U
(cid:88)

D
(cid:88)

=K

1
K

−

(cid:80)U

(cid:33)2

Ki(ρ1 + ρ2(cid:107)∇F (wt−1)(cid:107)2)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
K

i=1
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:32) U

(cid:88)

i=1

d=1

i=1
(cid:13)
U
(cid:13)
(cid:88)
(cid:13)
(
(cid:13)
(cid:13)
U
(cid:88)

i=1

D
(cid:88)

d=1

i=1
(cid:13)
U
(cid:13)
(cid:88)
(cid:13)
(
(cid:13)
(cid:13)

i=1

+

=K

+

i=1

(cid:33)(cid:12)−1(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

βd
i,t
i=1 Kiβd
i,t
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

βd
i,t
i=1 Kiβd
i,t
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

σ2L2

Kiβi,t (cid:12) bt)(cid:12)−1

σ2L2

(cid:32)

1
K 2 −

2
K

(cid:80)U

+

i,t)2
(βd
i=1 Kiβd

i,t)2

((cid:80)U

(cid:33)

Ki(ρ1 + ρ2(cid:107)∇F (wt−1)(cid:107)2)

Kiβi,t (cid:12) bt)(cid:12)−1

(cid:32)

D
(cid:88)

=

d=1

K
i=1 Kiβd
i,t

(cid:80)U

(cid:33)

− 1

(ρ1 + ρ2(cid:107)∇F (wt−1)(cid:107)2) +

(cid:13)
(cid:13)
(cid:13)
(
(cid:13)
(cid:13)

U
(cid:88)

i=1

Kiβi,t (cid:12) bt)(cid:12)−1

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

σ2L2.

(54)

Substituting (54) to (50), we have:

E[F (wt)] ≤

1
2L

(cid:32) D
(cid:88)

(cid:32)

d=1

K
i=1 Kiβd
i,t

(cid:80)U

(cid:33)

− 1

(ρ1 + ρ2(cid:107)∇F (wt−1)(cid:107)2)

+

(cid:13)
U
(cid:13)
(cid:88)
(cid:13)
(
(cid:13)
(cid:13)

i=1

Kiβi,t (cid:12) bt)(cid:12)−1

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:33)

σ2L2

+ E[F (wt−1)] −

1
2L

(cid:107)∇F (wt−1)(cid:107)2.

(55)

Subtract E[F (w∗)] from both sides of (55), we have:

E[F (wt) − F (w∗)] ≤ E[F (wt−1) − F (w∗)] −

1
2L

(cid:107)∇F (wt−1)(cid:107)2

+

1
2L

(cid:32) D
(cid:88)

(cid:32)

d=1

K
i=1 Kiβd
i,t

(cid:80)U

(cid:33)

− 1

(ρ1 + ρ2(cid:107)∇F (wt−1)(cid:107)2) +

(cid:13)
U
(cid:13)
(cid:88)
(cid:13)
(
(cid:13)
(cid:13)

i=1

Kiβi,t (cid:12) bt)(cid:12)−1

(cid:33)
.

σ2L2

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(56)

To minimize both sides of (11), we have

min
wt

F (wt) ≥ min
wt

(F (wt−1) + (wt − wt−1)T ∇F (wt−1) +

µ
2

(cid:107)wt − wt−1(cid:107)2).

(57)

29

The minimization of the left-hand side is achieved by wt = w∗, while the minimization of

the right-hand side is achieved by wt = wt−1 − 1

µ∇F (wt−1). Thus, we have

Then

F (w∗) ≥ F (wt−1) −

1
2µ

(cid:107)∇F (wt−1)(cid:107)2.

(cid:107)∇F (wt−1)(cid:107)2 ≥ 2µ(F (wt−1) − F (w∗)).

(58)

(59)

Substituting (59) to (56), we get

E[F (wt) − F (w∗)] ≤ (1 −

+

1
2L

(cid:32) D
(cid:88)

(cid:32)

d=1

K
i=1 Kiβd
i,t

(cid:80)U

µ
L

)E[F (wt−1) − F (w∗)]

(cid:33)

− 1

(ρ1 + ρ2(cid:107)∇F (wt−1)(cid:107)2) +

= (1 −

µ
L

)E[F (wt−1) − F (w∗)] +

ρ2
2L

(cid:32) D
(cid:88)

(cid:32)

d=1

(cid:80)U

+

ρ1
2L

(cid:32)

D
(cid:88)

d=1

K
i=1 Kiβd
i,t

(cid:80)U

(cid:33)

− 1

+

(cid:13)
U
(cid:13)
(cid:88)
(cid:13)
(
(cid:13)
(cid:13)

i=1

Kiβi,t (cid:12) bt)(cid:12)−1

K
i=1 Kiβd
i,t
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Lσ2
2

.

(cid:13)
U
(cid:13)
(cid:88)
(cid:13)
(
(cid:13)
(cid:13)

i=1

Kiβi,t (cid:12) bt)(cid:12)−1

(cid:33)

σ2L2

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:33)(cid:33)

− 1

(cid:107)∇F (wt−1)(cid:107)2

Next, in the same way that (59) is derived, to minimize both sides of (46), we have

(cid:107)∇F (wt−1)(cid:107)2 ≤ 2L(F (wt−1) − F (w∗)).

Substituting (61) to (60), we get

E[F (wt) − F (w∗)] ≤

1 −

(cid:32)

+

ρ1
2L

µ
L

+ ρ2

(cid:32)

D
(cid:88)

d=1

(cid:32)

D
(cid:88)

d=1

(cid:80)U

K
i=1 Kiβd
i,t
(cid:33)

K
i=1 Kiβd
i,t

(cid:80)U

− 1

+

(cid:33)(cid:33)

− 1

E[F (wt−1) − F (w∗)]

(cid:13)
(cid:13)
(cid:13)
(
(cid:13)
(cid:13)

U
(cid:88)

i=1

Kiβi,t (cid:12) bt)(cid:12)−1

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Lσ2
2

=Bt + AtE[F (wt−1) − F (w∗)],

where

At = 1 −

µ
L

+ ρ2

Bt =

ρ1
2L

(cid:32)

D
(cid:88)

d=1

K
i=1 Kiβd
i,t

(cid:80)U

The proof is completed.

K
i=1 Kiβd
i,t

(cid:80)U

(cid:33)

− 1

,

(cid:32)

D
(cid:88)

d=1

(cid:33)

− 1

+

(cid:13)
U
(cid:13)
(cid:88)
(cid:13)
(
(cid:13)
(cid:13)

i=1

Kiβi,t (cid:12) bt)(cid:12)−1

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Lσ2
2

.

(60)

(61)

(62)

(63)

(64)

30

APPENDIX B

PROOF OF THEOREM 2

Theorem 2 considers the full GD method for non-convex problems. The proof of Theorem

2 follows that of Theorem 1 until (55). From (55), we have

E[F (wt)] ≤E[F (wt−1)] −

1
2L

(cid:32)

1 − ρ2

(cid:32)

D
(cid:88)

K
i=1 Kiβd
i,t

(cid:80)U

(cid:33)(cid:33)

− 1

(cid:107)∇F (wt−1)(cid:107)2

+

ρ1
2L

(cid:32)

D
(cid:88)

d=1

(cid:80)U

d=1
(cid:33)

− 1

K
i=1 Kiβd
i,t
2 − At − µ
L
2L

= E[F (wt−1)] −

(cid:107)∇F (wt−1)(cid:107)2 + Bt.

+

(cid:13)
(cid:13)
(cid:13)
(
(cid:13)
(cid:13)

U
(cid:88)

i=1

Kiβi,t (cid:12) bt)(cid:12)−1

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Lσ2
2

Summing up the above inequality from t = 1 to t = T , we get

E[F (wt)] − E[F (w0)] ≤ −

T
(cid:88)

t=1

2 − At − µ
L
2L

(cid:107)∇F (wt−1)(cid:107)2 +

T
(cid:88)

t=1

Bt,

which leads to

T
(cid:88)

t=1

2 − At − µ
L
2L

(cid:107)∇F (wt−1)(cid:107)2 ≤ E[F (w0)] − E[F (wt)] +

≤ E[F (w0)] − E[F (w∗)] +

T
(cid:88)

t=1

T
(cid:88)

t=1

Bt

Bt.

Recalling Proposition 1, we have

0 ≤

1 − ρ2D( K
Kmin
2L

− 1)

≤

2 − At − µ
L
2L

≤

1
2L

,

∀t.

(65)

(66)

(67)

(68)

Substituting (68) to (67), we get

1
T

T
(cid:88)

t=1

1 − ρ2D( K
Kmin
2L

− 1)

(cid:107)∇F (wt−1)(cid:107)2 ≤

≤

1
T

1
T

T
(cid:88)

t=1

2 − At − µ
L
2L

(cid:107)∇F (wt−1)(cid:107)2

(E[F (w0)] − E[F (w∗)]) +

1
T

T
(cid:88)

t=1

Bt.

(69)

As a result, we have the conclusion in Theorem 2,

1
T

T
(cid:88)

t=1

(cid:107)∇F (wt−1)(cid:107)2 ≤

2L

− 1))

T (1 − ρ2D( K
Kmin
2L (cid:80)T
T (1 − ρ2D( K
Kmin

t=1 Bt

+

E[F (w0)] − E[F (w∗)]

.

− 1))

(70)

31

APPENDIX C

PROOF OF THEOREM 3

Exploiting the SGD method, the local parameter of the i-th worker is updated at the t-th

iteration by

ñ(cid:80)Kb

ô

wi,t = wt−1 − αEDi

k=1 ∇f (wt−1, xi,k, yi,k)
Kb
where EDi[·] is the expectation, which represents that the i-th worker randomly chooses Kb
samples from its local dataset Di to compute the local gradient.

i = 1, 2, ..., U,

(71)

,

Substituting (71) to (9), we reach a averaged gradient estimate as

wt =wt−1 +

(cid:33)(cid:12)−1

Kbβi,t (cid:12) bt

(cid:12) zt

(cid:32) U

(cid:88)

i=1

(cid:33)(cid:12)−1

− α

(cid:32) U

(cid:88)

i=1

Kbβi,t

(cid:12)

U
(cid:88)

i=1

Ç

Kbβi,t (cid:12) EDi

ñ(cid:80)Kb

k=1 ∇f (wt−1, xi,k, yi,k)
Kb

ôå

=wt−1 − α(∇F (wt−1) − o),

(72)

where

(cid:32)

o =∇F (wt−1) +

α

U
(cid:88)

(cid:33)(cid:12)−1

Kbβi,t (cid:12) bt

(cid:12) zt

i=1
(cid:33)(cid:12)−1

(cid:32) U

(cid:88)

−

i=1

Kbβi,t

(cid:32)

U
(cid:88)

(cid:12)

i=1

βi,t (cid:12) EDi

(cid:34) Kb(cid:88)

k=1

(cid:35)(cid:33)

∇f (wt−1, xi,k, yi,k)

.

(73)

Let Ni,t denote the set of the samples that are not chosen by the i-th worker at the t-th

iteration, E[(cid:107)o(cid:107)2] can be derived as follows
(cid:80)Ki

(cid:80)U

i=1

k=1 ∇f (wt−1; xi,k, yi,k)

E[(cid:107)o(cid:107)2] =E

(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)

K

32

(cid:32)

+

α

U
(cid:88)

i=1

(cid:33)(cid:12)−1

Kbβi,t (cid:12) bt

(cid:12) zt

(cid:32) U

(cid:88)

−

(cid:33)(cid:12)−1

(cid:32)

U
(cid:88)

(cid:12)

Kbβi,t

βi,t (cid:12) EDi

(cid:34) Kb(cid:88)

∇f (wt−1, xi,k, yi,k)

2(cid:35)

(cid:35)(cid:33) (cid:13)
(cid:13)
(cid:13)
(cid:13)

=E

(cid:34)(cid:13)
(cid:13)
(cid:13)
(cid:13)

i=1

U
(cid:88)

i=1

Ñ

1
K

− βi,t (cid:12)

k=1
(cid:33)(cid:12)−1é

Kbβi,t

(cid:12) E

N i,t

i=1
(cid:32) U

(cid:88)

i=1





(cid:88)

k∈N i,t



∇f (wt−1; xi,k, yi,k)



(cid:80)U

i=1

E[(cid:80)

k∈Ni,t

+

∇f (wt−1; xi,k, yi,k)]
K

(cid:32)

+

α

U
(cid:88)

i=1

(cid:33)(cid:12)−1

Kbβi,t (cid:12) bt

(cid:12) zt

2(cid:35)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

,

(cid:32) U

(cid:88)

≤

Kb

(cid:33) U

(cid:88)

i=1

i=1

(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
K

− βi,t (cid:12)

(cid:32) U

(cid:88)

i=1

Kbβi,t

(cid:33)(cid:12)−1 (cid:13)
2
(cid:13)
(cid:13)
(cid:13)

E

N i,t





(cid:88)

k∈N i,t

(cid:107)∇f (wt−1; xi,k, yi,k)(cid:107)2





(cid:107) (cid:80)U

i=1

E[(cid:80)

k∈Ni,t

+

∇f (wt−1; xi,k, yi,k)](cid:107)2
K 2

+

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:32) U

(cid:88)

i=1

Kbβi,t (cid:12) bt

(cid:33)(cid:12)−1(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

σ2L2.

(74)

Applying Assumption 3, we get
Ñ Ä(cid:80)U

(cid:32) U

(cid:33) D
(cid:88)

E[(cid:107)o(cid:107)2] ≤

(cid:88)

Kb

ä

i=1 Kb
K 2

− 2K

+

(cid:80)U

i=1

d=1

((cid:80)U

i=1(Ki − Kb))2

K 2

E[F (wt)] ≤

Substituting (75) into (50), we have

(ρ1 + ρ2(cid:107)∇F (wt−1)(cid:107)2) +

1
i=1 Kbβd
i,t
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:32) U

(cid:88)

i=1

é

(ρ1 + ρ2(cid:107)∇F (wt−1)(cid:107)2)+

Kbβi,t (cid:12) bt

(cid:33)(cid:12)−1(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

σ2L2. (75)

ä

+

ä

(cid:33)

Ä(cid:80)U

(cid:80)U

i=1 Kb
i=1 Kbβd
i,t
(cid:33)

(cid:32) U

(cid:88)

1
2L

(cid:32) (cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:32) D
(cid:88)

Kbβi,t (cid:12) bt

i=1
(cid:32)Ä(cid:80)U

i=1 Kb

ä2

σ2L2

(cid:33)(cid:12)−1(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
Ä(cid:80)U

− 2K

i=1 Kb

+

+

K 2

(cid:33)(cid:33)

d=1
i=1(Ki − Kb))2

((cid:80)U

K 2

(ρ1 + ρ2(cid:107)∇F (wt−1)(cid:107)2)

1
2L
Subtracting E[F (w∗)] from both sides of (76), and applying (59) and (61), we get

+ E[F (wt−1)] −

(cid:107)∇F (wt−1)(cid:107)2.

E[F (wt) − F (w∗)] ≤ BSGD

t

+ ASGD
t

E[F (wt−1) − F (w∗)],

(76)

(77)

(cid:33)

+

((cid:80)U
(cid:80)U

i=1 Kb)
i=1 Kbβd
i,t

33

(78)

where

ASGD
t

=1 −

µ
L

(cid:32) D
(cid:88)

(cid:32)

+ ρ2

((cid:80)U

i=1 Kb)2 − 2K((cid:80)U
K 2

i=1 Kb)

d=1
i=1(Ki − Kb))2

((cid:80)U

(cid:33)
,

+

K 2

(cid:32) D
(cid:88)

(cid:32)

d=1

BSGD
t

=

ρ1
2L

+

((cid:80)U

i=1 Kb)2 − 2K((cid:80)U
K 2

i=1 Kb)

+

((cid:80)U

i=1(Ki − Kb))2

K 2

(cid:33)

+

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:32) U

(cid:88)

i=1

(cid:33)

((cid:80)U
(cid:80)U

i=1 Kb)
i=1 Kbβd
i,t
(cid:33)(cid:12)−1(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Lσ2
2

Kiβi,t (cid:12) bt

.

(79)

Applying (77) recursively, we have

E[F (wt) − F (w∗)] ≤

t−1
(cid:88)

i
(cid:89)

i=1

j=1

which completes the proof.

ASGD

t+1−jBSGD

t−i + BSGD

t

+

t
(cid:89)

j=1

ASGD
j

E[F (w0) − F (w∗)].

(80)

APPENDIX D

PROOF OF THEOREM 4

To minimize Rt, it can be seen from (35), (36) and (37) that we should maximize the number

of the selected workers and the transmit power scaling factor in the t-th iteration. Thus, the

selected workers should send their parameters at their maximum power. In order to reach the

desired parameter aggregation at the PS as in (5), each worker needs to use the same transmit

power scaling factor bt, which is a parameter that needs to be optimized (bt determines the

worker selection). According to (35), (36) and (37), a larger bt leads to a smaller Rt. On the

other hand, (41b) indicates that a larger bt results in less workers is selected, which then results

in an increase of Rt.

Rewriting (38b) and replacing |wi,t| with (|wt−1| + η), we obtain the maximum acceptable bt

of the i-th worker as

bmax
i,t =

hi,t

(cid:12)
(cid:112)P max
(cid:12)
i
(cid:12)
(cid:12)
Ki(|wt−1| + η)
(cid:12)
i,t }U

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

(81)

Accordingly, bt should be chosen from {bmax

i=1. Once bt is determined, βt can be determined
by verifying whether the transmit power meets the condition in (7). As a result, we obtain a

reduced solution space of the optimization problem P2 as

(cid:40)

S =

{(b(k)
t

, β(k)

i,t )}U

k=1

(cid:12)
(cid:12)
(cid:12)
(cid:12)

b(k)
t = bmax

k,t , β(k)

t (b(k)

t ) = [β(k)

1,t , . . . , β(k)

U,t ], k = 1, . . . , U

(cid:41)
,

(82)

with

where

β(k)
U,t = H

is the Heaviside step function.

Å

P max

U −

(cid:12)
(cid:12)
(cid:12)
(cid:12)

KU b(k)

t (|wt−1| + η)

hU,t

ã

(cid:12)
(cid:12)
(cid:12)
(cid:12)

H(x) =




1, x > 0,



0, x ≤ 0.

REFERENCES

34

(83)

(84)

[1] M. Chiang and T. Zhang, “Fog and iot: An overview of research opportunities,” IEEE Internet of Things Journal, vol. 3,

no. 6, pp. 854–864, 2016.

[2] J. Park, S. Samarakoon, M. Bennis, and M. Debbah, “Wireless network intelligence at the edge,” Proceedings of the IEEE,

vol. 107, no. 11, pp. 2204–2239, 2019.

[3] T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, “Federated learning: Challenges, methods, and future directions,” IEEE

Signal Processing Magazine, vol. 37, no. 3, pp. 50–60, 2020.

[4] H. B. McMahan, E. Moore, D. Ramage, S. Hampson et al., “Communication-efﬁcient learning of deep networks from

decentralized data,” arXiv preprint arXiv:1602.05629, 2016.

[5] J. Koneˇcn`y, H. B. McMahan, D. Ramage, and P. Richt´arik, “Federated optimization: Distributed machine learning for

on-device intelligence,” arXiv preprint arXiv:1610.02527, 2016.

[6] G. Zhu, D. Liu, Y. Du, C. You, J. Zhang, and K. Huang, “Toward an intelligent edge: wireless communication meets

machine learning,” IEEE Communications Magazine, vol. 58, no. 1, pp. 19–25, 2020.

[7] M. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and S. Cui, “A joint learning and communications framework for federated

learning over wireless networks,” IEEE Transactions on Wireless Communications, 2020.

[8] T. T. Vu, D. T. Ngo, N. H. Tran, H. Q. Ngo, M. N. Dao, and R. H. Middleton, “Cell-free massive mimo for wireless

federated learning,” IEEE Transactions on Wireless Communications, 2020.

[9] B. Nazer and M. Gastpar, “Computation over multiple-access channels,” IEEE Transactions on information theory, vol. 53,

no. 10, pp. 3498–3516, 2007.

[10] L. Chen, N. Zhao, Y. Chen, F. R. Yu, and G. Wei, “Over-the-air computation for iot networks: Computing multiple functions

with antenna arrays,” IEEE Internet of Things Journal, vol. 5, no. 6, pp. 5296–5306, 2018.

[11] M. Goldenbaum, H. Boche, and S. Sta´nczak, “Harnessing interference for analog function computation in wireless sensor

networks,” IEEE Transactions on Signal Processing, vol. 61, no. 20, pp. 4893–4906, 2013.

[12] O. Abari, H. Rahul, D. Katabi, and M. Pant, “Airshare: Distributed coherent transmission made seamless,” in 2015 IEEE

Conference on Computer Communications (INFOCOM).

IEEE, 2015, pp. 1742–1750.

[13] M. M. Amiri and D. G¨und¨uz, “Machine learning at the wireless edge: Distributed stochastic gradient descent over-the-air,”

IEEE Transactions on Signal Processing, vol. 68, pp. 2155–2169, 2020.

[14] ——, “Federated learning over wireless fading channels,” IEEE Transactions on Wireless Communications, vol. 19, no. 5,

pp. 3546–3557, 2020.

[15] M. M. Amiri, T. M. Duman, and D. G¨und¨uz, “Collaborative machine learning at the wireless edge with blind transmitters,”

arXiv preprint arXiv:1907.03909, 2019.

35

[16] G. Zhu, Y. Wang, and K. Huang, “Broadband analog aggregation for low-latency federated edge learning,” IEEE

Transactions on Wireless Communications, vol. 19, no. 1, pp. 491–506, 2019.

[17] Y. Sun, S. Zhou, and D. G¨und¨uz, “Energy-aware analog aggregation for federated learning with redundant data,” arXiv

preprint arXiv:1911.00188, 2019.

[18] K. Yang, T. Jiang, Y. Shi, and Z. Ding, “Federated learning via over-the-air computation,” IEEE Transactions on Wireless

Communications, vol. 19, no. 3, pp. 2022–2035, 2020.

[19] M. Ye and E. Abbe, “Communication-computation efﬁcient gradient coding,” arXiv preprint arXiv:1802.03475, 2018.

[20] A. F. Aji and K. Heaﬁeld, “Sparse communication for distributed gradient descent,” arXiv preprint arXiv:1704.05021,

2017.

[21] Y. Liu, K. Yuan, G. Wu, Z. Tian, and Q. Ling, “Decentralized dynamic admm with quantized and censored communications,”

in 2019 53rd Asilomar Conference on Signals, Systems, and Computers.

IEEE, 2019, pp. 1496–1500.

[22] Y. Liu, W. Xu, G. Wu, Z. Tian, and Q. Ling, “Communication-censored admm for decentralized consensus optimization,”

IEEE Transactions on Signal Processing, vol. 67, no. 10, pp. 2565–2579, 2019.

[23] P. Xu, Z. Tian, Z. Zhang, and Y. Wang, “Coke: Communication-censored kernel learning via random features,” in 2019

IEEE Data Science Workshop (DSW), 2019, pp. 32–36.

[24] T. Chen, G. Giannakis, T. Sun, and W. Yin, “Lag: Lazily aggregated gradient for communication-efﬁcient distributed

learning,” in Advances in Neural Information Processing Systems, 2018, pp. 5050–5060.

[25] P. Xu, Z. Tian, and Y. Wang, “An energy-efﬁcient distributed average consensus scheme via infrequent communication,”

in 2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP), 2018, pp. 648–652.

[26] P. Xu, Y. Wang, X. Chen, and T. Zhi, “Coke: Communication-censored kernel learning for decentralized non-parametric

learning,” arXiv preprint arXiv:2001.10133, 2020.

[27] Q. Zeng, Y. Du, K. K. Leung, and K. Huang, “Energy-efﬁcient radio resource allocation for federated edge learning,”

arXiv preprint arXiv:1907.06040, 2019.

[28] J. Wang and G. Joshi, “Cooperative sgd: A uniﬁed framework for the design and analysis of communication-efﬁcient sgd

algorithms,” arXiv preprint arXiv:1808.07576, 2018.

[29] M. Goldenbaum and S. Stanczak, “Robust analog function computation via wireless multiple-access channels,” IEEE

Transactions on Communications, vol. 61, no. 9, pp. 3863–3877, 2013.

[30] O. Shamir, N. Srebro, and T. Zhang, “Communication-efﬁcient distributed optimization using an approximate newton-type

method,” in International conference on machine learning, 2014, pp. 1000–1008.

[31] S. Magn´usson, H. Shokri-Ghadikolaei, and N. Li, “On maintaining linear convergence of distributed learning and

optimization under limited communication,” IEEE Transactions on Signal Processing, 2020.

[32] D. P. Bertsekas, J. N. Tsitsiklis, and J. Tsitsiklis, Neuro-Dynamic Programming. Athena Scientiﬁc, 1996.

[33] M. P. Friedlander and M. Schmidt, “Hybrid deterministic-stochastic methods for data ﬁtting,” SIAM Journal on Scientiﬁc

Computing, vol. 34, no. 3, pp. A1380–A1405, 2012.

[34] D. Alistarh, T. Hoeﬂer, M. Johansson, N. Konstantinov, S. Khirirat, and C. Renggli, “The convergence of sparsiﬁed gradient

methods,” in Advances in Neural Information Processing Systems, 2018, pp. 5973–5983.

[35] K. Yuan, Q. Ling, and W. Yin, “On the convergence of decentralized gradient descent,” SIAM Journal on Optimization,

vol. 26, no. 3, pp. 1835–1854, 2016.

[36] L. Bottou, F. E. Curtis, and J. Nocedal, “Optimization methods for large-scale machine learning,” Siam Review, vol. 60,

no. 2, pp. 223–311, 2018.

[37] S. U. Stich, J.-B. Cordonnier, and M. Jaggi, “Sparsiﬁed sgd with memory,” in Advances in Neural Information Processing

Systems, 2018, pp. 4447–4458.

[38] H. Tang, C. Yu, X. Lian, T. Zhang, and J. Liu, “Doublesqueeze: Parallel stochastic gradient descent with double-pass

error-compensated compression,” in International Conference on Machine Learning. PMLR, 2019, pp. 6155–6165.

[39] D. Alistarh, D. Grubic, J. Li, R. Tomioka, and M. Vojnovic, “Qsgd: Communication-efﬁcient sgd via gradient quantization

and encoding,” in Advances in Neural Information Processing Systems, 2017, pp. 1709–1720.

36

