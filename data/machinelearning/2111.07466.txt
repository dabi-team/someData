2
2
0
2

t
c
O
3

]

Y
S
.
s
s
e
e
[

4
v
6
6
4
7
0
.
1
1
1
2
:
v
i
X
r
a

Discrete-Time Nonlinear Systems Identiﬁcation with
Probabilistic Safety and Stability Constraints

⋆

Iman Salehi a, Tyler Taplin a, Ashwin Dani a

aDepartment of Electrical and Computer Engineering, University of Connecticut, Storrs, CT, USA

Abstract

This paper presents a discrete-time nonlinear system identiﬁcation method while satisfying the stability and safety properties
of the system with high probability. An Extreme Learning Machine (ELM) is used with a Gaussian assumption on the function
reconstruction error. A quadratically constrained quadratic program (QCQP) is developed with probabilistic safety and
stability constraints that are only required to be satisﬁed at sampled points inside the invariant region. The proposed method
is validated using two simulation examples: a two degrees-of-freedom (DoF) robot manipulator with constraints on joint angles
whose trajectories are guaranteed to remain inside a safe set and on motion trajectories data of a hand-drawn shape.

Key words: Extreme Learning Machines; Safe Model Learning; Discrete Control Barrier Function.

1 Introduction

a closed set with respect to a system model.

Data-driven dynamic system model learning approaches
create black box models that do not require much prior
ﬁrst principles knowledge about the system [1,2,3]. The
data generated by the controlled system often exhibit
system properties such as stability, invariance with re-
spect to a set and so on. Preserving these properties in
system identiﬁcation by formulating them as constraints
leads to accurate identiﬁcation of dynamical systems
[2,3]. This can be useful in many model learning applica-
tions to engineering problems [4,5,6,7,8,9]. In [7,6] and
[10] stability and stabilizability of system dynamics is
considered for model learning in learning from demon-
stration. Our recent eﬀorts have focused on adding safety
property in the data-driven system model learning, see,
e.g., [8,11].

The concept of safety is centered around the idea of con-
straining the behavior of the system model to a pre-
scribed set, by ensuring forward invariance of the set
with respect to the system model. Barrier functions (BF)
are commonly used to certify the forward invariance of

⋆

This work was supported in part by NSF grant no. SMA-
2134367 and in part by a Space Technology Research Insti-
tutes grant (number 80NSSC19K1076) from NASA Space
Technology Research Grants Program.

Email addresses: iman.salehi@uconn.edu (Iman Salehi),

tyler.taplin@uconn.edu (Tyler Taplin),
ashwin.dani@uconn.edu (Ashwin Dani).

Control barrier functions (CBFs) are used for the syn-
thesis of safety-critical controllers via Quadratic Pro-
gramming (QP) [12,13,14]. Control Lyapunov functions
(CLF) and CBF are merged to synthesize stable and safe
controllers by solving a QP in [15,16]. In [17], an adap-
tive CBF (aCBF) is proposed, which ensures the forward
invariance of a closed set with respect to a nonlinear
control-aﬃne system with parametric uncertainties. In
[18] the aCBF method is merged with an adaptive data-
driven safety controller for contracting systems. These
methods mainly focus on controller synthesis problem
with a known dynamic system model. The controller
synthesis methods assume the knowledge of barrier func-
tion. A framework for estimating barrier functions and
safe regions directly from sensor data is developed in [13]
and [19].

Classical system identiﬁcation techniques, focused on
linear systems, utilize parametric model structure and
guarantee the stability of learned models [2,3]. Ma-
chine learning techniques, such as neural networks and
Gaussian processes (GPs), have recently been used for
nonlinear system identiﬁcation. Model uncertainties, in
the form of the neural network approximation error and
external disturbances, are accounted for in our prior
study in [11] along with stability and safety constraints
using reciprocal BFs, but noise is not explicitly mod-
eled. In the context of Bayesian learning, GP state-space
models are learned with stability constraints in [9]. In

 
 
 
 
 
 
[20], simultaneous continuous system model learning
and control synthesis method is developed, where GPs
are used for model learning, and probabilistic CBF and
CLF are used to achieve safety and stability. This paper
develops a system identiﬁcation method for discrete-
time systems while simultaneously verifying probabilis-
tic safety and stability properties by utilizing CBFs
for discrete-time nonlinear systems developed in [21].
The uncertainties are modeled using white Gaussian
noise. A discrete-time zeroing control barrier function
(DT-ZCBF) and discrete-time control Lyapunov func-
tions (DT-CLF) are used to obtain safety and stabil-
ity chance constraints. An extreme learning machine
(ELM) network, which is a computationally eﬃcient
approximation for system model, is used to represent
the unknown nonlinear discrete-time system. The ELM
parameter learning problem is formulated as a quadrat-
ically constrained quadratic program (QCQP) subject
to discrete-time safety and stability chance constraints.
The optimization problem contains ﬁnite number of
decision variables with inﬁnite constraints. To make
the optimization tractable, an equivalent optimization
problem is derived that requires the constraints to be
evaluated only at a ﬁnite number of sampled points.
Finally, the constrained model
learning approach is
demonstrated in simulation using two examples: a 2 DoF
planar robot whose joint positions are lower and upper
bounded using an ellipse zeroing barrier function, and
learning motion trajectories of one of the complicated
shapes from a publicly available dataset [22].

2 Preliminaries

In this section, preliminaries of discrete-barrier and dis-
crete Lyapunov functions are presented. Consider an un-
known nonlinear discrete-time system of the form

x(k + 1) = f (x(k), u(k)),

(1)

where f :

is a continuous function, x(k)

D × U → D

Rn is the state of the system at time step k

∈
Z+,
D ⊂
Rm is the system control
and u(k) = π(e(k))
∈ U ⊂
input with a policy π(
) that depends on the error e(k) =
·
x(k)
x∗, and x∗ is the system equilibrium. For ease of
notation, the time dependency of variables, for example,
x(k) is abbreviated by xk, unless necessary for clarity.

−

∈

2.1 Discrete-Time Control Lyapunov Functions

The classical stability analysis of continuous-time non-
linear dynamical systems using Lyapunov theory is ex-
tended to the discrete-time domain. It entails ﬁnding
a positive deﬁnite or semi-deﬁnite function V :
D →
R, which decreases along the trajectories of the system
given in (1). Refer to [21] and references therein for a
comprehensive study on discrete-time Lyapunov theo-
rems.

2

Deﬁnition 1 (DT-CLF) Given the discrete-time sys-
tem (1), V (xk) is said to be a DT-CLF if it can be
bounded by α1(
V (xk)
) and there
≤
k
exists a control input uk :

xk
α2(
≤
k
k
such that

xk

k

)

D → U

L (xk, uk) = ∆V (xk, uk)+β(
k

C
where ∆V (xk, uk) := V (xk+1)
and β belong to class
norm on Rn.

K

−

xk

)

k

≤

0,

xk

∀

∈ D

, (2)

function, and

V (xk) = ∆Vk, α1, α2,
is an arbitrary

k · k

2.2 Discrete-Time Zeroing Control Barrier Functions

Safety properties can be achieved by constraining the
solutions of the discrete-time dynamical system to a pre-
xk
speciﬁed closed set
, where
h : Rn
R is a continuously diﬀerentiable function
associated with a barrier function [14].

: h(xk)

∈ D

→

=

≥

S

{

0

}

Deﬁnition 2 (DT-ZCBF) Given the discrete-time
, a continuously diﬀerentiable func-
system (1), the set
tion h : Rn
R is said to be a DT-CZBF, if there exists
a class
with
that

→
function satisfying η(r) < r,

Rn, and a control input uk :

r > 0, a set

S ⊆ D ⊂

D → U

D
such

K

S

∀

(xk, uk) = ∆h(xk, uk) + η(h(xk))

0,

CB

xk

, (3)

∈ D

∀

≥
h(xk) = ∆hk.

where ∆h(xk, uk) := h(xk+1)

−

S

The set
is forward invariant with respect to the
discrete-time system in (1) if and only if there exists a
DT-ZCBF as deﬁned in Deﬁnition 2, which means for
Z+
any initial condition x0 ∈ S
[23].

, implies xk

∈ S

∈

∀

k

,

Assumption 1 The function f :
Lipschitz continuous and bounded in

D × U → D
.

D

is locally

3 Constrained ELM Learning Problem

×

∈
n is the unknown ideal bounded constant out-

Consider a discrete-time nonlinear dynamical system in
(1), it is assumed that the unknown function f (
) can be
·
parametrized as f (xk, π(ek)) = WT g(sk), where W
R(nh+1)
put layer weight matrix, g(sk) = [ψ(q
→
Rnh+1, sk =
Rnh is the
k , eT
xT
vector Sigmoid activation function, nh is the number of
(cid:2)
neurons in the hidden layer of the ELM. The vector Sig-
moid activation function ψ(
·

Rn+m+1, ψ(
·

sk), 1] : Rn+m+1

) is given by

k , 1

∈

∈

(cid:3)

)

T

·

ψ (q

·

sk) =

1
(q
1+e−

·

(cid:20)

T

,

(4)

1
(q

,

sk)1

,

· · ·

1+e−

sk)nh (cid:21)
(n+m+1), P = diag(ap)

·

where q = [P, bp]
Rnh
(n+m), ap

×

∈

Rnh

×
∈
Rnh and bp

∈

∈
Rnh are the internal

·

U T

R(n+m)

nh

×

∈

slopes and biases vectors, respectively, U
is the ideal bounded input layer weight matrix. The pa-
rameters ap, bp and U of ELM are computed using in-
trinsic plasticity (IP) or batch intrinsic plasticity (BIP)
algorithms. See [11] for preliminaries of ELM. Other ac-
tivation functions such as radial basis functions, tan-
gent Sigmoid can also be used [24,25]. Using the ELM
parametrization of f (
), the discrete system in (1) is writ-
·
ten as

xk+1 = W T g(sk) + ǫk,

(5)

R(nh+1)
where W
×
∈
weight matrix and ǫk
unmodeled eﬀects.

n is the estimated ELM output
Rn is the uncertainty due to

∈

Assumption 2 The weights of the ELM are bounded
by known positive constants, i.e.,
¯U , where

≤
F is the Frobenius norm [24].

¯W ,

W

≤

U

k

k

k

k

F

F

k · k

Remark 1 The sigmoid function ψi(
·
hence its derivative ψi(
)(1
·
−
ψi(
ψi(
))
bounds given by 0
)(1
·
·
1,
ψ(
nh. Thus,
ψ(
√nh and
·
k ≤
·
k
0.25√nh. Using Assumptions 2, Assumption 1 is still
valid for the ELM parameterization of f (xk, uk) [24].

[0, 1] and
∈
)) has upper and lower
i =

0.25,
ψ(
·

ψi(
·
−

≤
)
k ≤

≤
)(1

· · ·

∀
))

−

k

)

Assumption 3 The uncertainty, ǫk is independent and
identically distributed with Gaussian distribution of zero
mean and covariance σ2I, i.e., ǫk
[26,27].

0, σ2I

∼ N

(cid:0)

(cid:1)

x1,

{
, g(sTm

Let X1:Tm =
denote Tm time samples
, xTm}
of the system’s trajectory of (1) and G0:Tm
1 =
g(s0),
denote their Sigmoid functions.
{
The Gaussian assumption on the ELM reconstruction
error for the dynamic model in (5) yields the following
likelihood function

· · ·
1)
}

· · ·

−

−

G, W ) =

p(X
|

=

Tm

−

1

k=0
Y
Tm
1
−

N

k=0
Y

1
2 σn exp
n
(2π)
(cid:18)

k
−

xk+1 −

W T g(sk)
k
2σ2

(W T g(sk), σ2I)

2

,

(cid:19)

(6)

4 Chance-constrained Optimization

4.1 Encoding Probabilistic Safety Constraints

DT-ZCBF deﬁnes a forward invariant set such that so-
lutions of the nonlinear dynamical system that start in
that set remain in that set for all time. A hyperellipsoid
is used to represent a DT-ZCBF, h(xk) : Rn
R, and it
is given by

→

h(xk) = 1

(xk

−

−

¯x)T A(xk

¯x),

−

(7)

Rn

n is a symmetric positive deﬁnite matrix,
where A
∈
and ¯x is the vector that denotes the center of gravity of
the hyperellipsoid.

×

Lemma 1 Given the system model in (5) and Assump-
tion 3, the uncertainty, ǫk induces a distribution over the
DT-ZCBF constraint in (3) with the following parame-
ters:

E [

] =1

−

CB

Var[

CB

] = 4

1
2

A

W Tg

(cid:13)
(cid:13)
(cid:13)
σA

(cid:0)
W Tg

−

−

2

¯x
−
(cid:1)(cid:13)
(cid:13)
(cid:13)
2

¯x

σ2tr(A)

−

γ)h(xk)

(1

−

+2σ4tr

A2

,

(8)

(9)

(cid:13)
(cid:1)(cid:13)
(cid:0)
function η(h(xk)) in Deﬁnition 2 is se-
where the class
(cid:13)
(cid:13)
lected as η(h(xk)) = γh(xk), and γ is a positive constant.

K

(cid:0)

(cid:1)

PROOF. Substituting (7) in (3) for h(xk+1) and using
(5) yields

=1

−

CB

W Tg +ǫk

T
A

¯x

−

W Tg +ǫk

−

(cid:0)

(cid:1)

(cid:0)

−

−
(cid:1)

¯x

(1

γ)h(xk).

(10)

Taking the expectation of

we have

CB

E

1

h
1
−
(cid:0)

−
W Tg
(cid:0)

W Tg +ǫk

T
A

¯x

−

T
A

¯x

−
W Tg
(cid:1)

W Tg +ǫk

¯x

−

−

(1

−

(cid:0)
¯x

tr

Aσ2

−
(cid:1)

(cid:0)

(cid:1)
(1

−

−
(cid:1)

(cid:0)
and the variance is

(cid:1)

γ) h(xk)

=

−
γ)h(xk),

i
(11)

where the indexes for X and G are dropped for brevity.
The Gaussian distribution of the ELM reconstruction
error also induces a distribution over the DT-CLF and
DT-ZCBF constraints in (2) and (3), which can be used
to obtain probabilistic stability and safety guarantees in
the constrained parameter learning of the ELM, respec-
tively.
Given a set of state trajectories and state feedback con-
trol, the constrained system identiﬁcation problem is for-
mulated as a parameter learning problem of an ELM ap-
proximation of f (
) given in (5), such that the system in
·
(5) satisfy probabilistic safety and stability properties.

Var[

CB

] =E
(h(xk+1)
=E
h

2gT W Aǫk

E [h(xk+1)])2
i
k Aǫk + 2¯xT Aǫk +tr(Aσ2)
ǫT

−

(12)

2

.

−

−

(cid:2)(cid:0)

(cid:1)
Utilizing properties such as the odd moments of mul-
tivariate Gaussian distribution are zero and the trace
when the matrices are of suitable dimensions is invariant
under circular permutations, (12) can be written as blue

(cid:3)

] = 4σ2
E

gT W A2W T g + ¯xT A2 ¯x
ǫT
k Aǫk
(cid:0)
h(cid:0)

σ4tr(A)2

−

i

(cid:1)

2

2gT W A2 ¯x

+

−

(13)
(cid:1)

Var [

CB

3

After substituting E
in (13), the result in (9) is obtained.

ǫT
k Aǫk

2

h(cid:0)

i

(cid:1)

= σ4tr(A)2+2σ4tr(A2)

PROOF. Substituting V (xk) = (xk
−
in (2) for V (xk+1) and using (5) yields

x∗)T P (xk

x∗)

−

To account for the uncertainty in safety constraint sat-
isfaction, the DT-ZCBF is rewritten as

(cid:0)

(cid:1)

(cid:0)

Taking the expectation of

L we have

C

P (

CB ≥

xk) = 1

ζ

|

B (ζ)

− FC

pk

≥

(14)

E

L=

W Tg +ǫk

x∗

TP

−

W Tg +ǫk

−

x∗

C

(1

ρ)V (xk).

−

−
(cid:1)

(19)

where pk
R+, and
standard Gaussian given by

∈
FC

(0, 1) is a user-speciﬁed risk tolerance, ζ
∈
B (ζ) is the cumulative distribution of the

B (ζ) , Φ

FC

ζ

E [
−
Var[

CB
CB

p

]
]!

=

1
2

+

1
2

erf

ζ

E [
−
2Var[

]

CB
CB

p

Var[

C

]!

(15)

and Φ(
) is a cumulative distribution function of the
·
standard Gaussian. The parameters derived in Lemma 1
can be used to compute cumulative distribution in (15).
Note that as the variance tends to zero, i.e., Var [
→
0, the probability P (
xk) tends to one when ζ <
|
E [
]. As the uncertainty in the system dynamics de-
creases to zero the safety assurance can be guaranteed
with probability one.

CB ≥

CB

CB

ζ

]

Substituting (15) into (14), the probabilistic safety con-
straint is given by

ζ

E [

]

CB

−

≤ −

c(pk)

Var [

],

CB

(16)

where c(pk) = √2 erf−

1 (2pk

p
1).

−

4.2 Encoding Probabilistic Stability Constraints

In this subsection, a probabilistic stability constraint is
derived using Deﬁnition 1 for the uncertain discrete-time
system given in (5) and a Lyapunov candidate V (xk) =
n such that P =
(xk
−
P T > 0.

x∗), where P

x∗)T P (xk

Rn

−

∈

×

Lemma 2 Given the system in (5) and Assumption 3,
the Gaussian model uncertainty induces a distribution
over the DT-CLF constraint in (2) with the following
parameters:

E [

L] =

1
2

P

W Tg

C

(cid:13)
(cid:13)
(cid:13)
L] = 4

−

(cid:0)
σP

W Tg

Var[

C

(cid:1)(cid:13)
(cid:13)
(cid:13)
x∗

−

2
+σ2tr(P )

x∗

(1

−

−

ρ)V (xk),

2

+2σ4tr

P 2

,

(17)

(18)

where the class
xk
ﬁned as β(
k

(cid:0)

(cid:1)(cid:13)
xk
function β(
(cid:13)
k

(cid:13)
(cid:1)
(cid:13)
) in Deﬁnition 1 is de-
K
) = ρV (xk) and ρ is a positive constant.
k

k

(cid:0)

4

x∗

T
P

W Tg +ǫk

x∗

W Tg +ǫk
−
T
P

x∗

h(cid:0)
W Tg

−

W Tg
(cid:1)

(cid:0)
x∗
−

+tr

−
P σ2

−
(cid:1)
(1
−
(cid:1)

−

(cid:0)

and the variance is

(cid:1)

(cid:0)

(cid:1)

(cid:0)

(1

ρ) V (xk)

=

−
ρ)V (xk), (20)

i

L] =E
(V (xk+1)
h
=E

−

2gT W P ǫk +ǫT

E [V (xk+1)])2
i
T
2x∗

k P ǫk

−

(cid:20)(cid:16)

(21)

P ǫk

−

tr(P σ2)
(cid:17)

2

.

(cid:21)

Utilizing properties such as the odd moments of mul-
tivariate Gaussian distribution are zero and the trace
when the matrices are of suitable dimensions is invariant
under circular permutations, (21) can be written as

L] = 4σ2

gT W P 2W T g +x∗

T

P 2x∗

Var[

C

E

(cid:16)
ǫT
k P ǫk

2

σ4tr(P )2

−

2gT W P 2x∗

+

(cid:17)
(22)

h(cid:0)

−

i
(cid:1)
ǫT
k P ǫk

After substituting E
in (22), the result in (18) is obtained.

2

h(cid:0)

i

(cid:1)

= σ4tr(P )2+2σ4tr(P 2)

To account for the uncertainty in stability constraint
satisfaction, the DT-CLF in (2) can be rewritten as

P (
C

L

δ

|

≤

xk) =

L (δ)

FC

pk,

≥

(23)

where

L (δ) =

FC

1
2

+

1
2

erf

δ

E [
−
C
2Var[

L]
L] !

C

.

(24)

Substituting (24) into (23) and utilizing (17) and (18),
the probabilistic stability constraint is given by

p

δ

−

E [

L]

C

≥

c(pk)

Var [

L],

C

(25)

where E [

C

L] and Var [

C

L] are given in Lemma 2.

p

Assumption 4 The variances Var [
Var [

1.

L]

C

≥

]

CB

≥

1 and

Var [
Remark 2 Functions
L] are not
Lipschitz continuous on [0, 1] as the slope of the tangent

Var [

] and

CB

C

p

p

 
 
 
line to their corresponding arguments become steeper as
they approach to zero. Therefore, Assumption 4 is made
to satisfy the constraint’s Lipschitz continuity require-
ment.

CB

] < 1 and Var [

Remark 3 If Assumption 4 does not hold,
i.e.,
Var [
L] < 1, the right hand side
(RHS) of the constraints in (16) and (25) can be
modiﬁed by introducing a constant ξ > 1 such that
ξ2Var[
1. For example, for

ξ2Var[

C

]

1 and
≥
the safety constraint in (16) we get
p

CB

p

L]

≥

C

PROOF. Using Assumption 4, the RHS of (16) can be
lower bounded, and the constraint can be rewritten as

−
Substituting E [
(29) we have

ζ

E [

]

CB

≤ −

c(pk)Var [

] .

CB

(29)

] and Var [

CB

] from (8) and (9) into

CB

1
2

A

ζ

(cid:13)
1
(cid:13)
−
(cid:13)

(cid:0)
−

W T g(sk)
σ2tr(A)

−

¯x
(cid:1)(cid:13)
(cid:13)
−
(cid:13)

(1

−

2
+4c(pk)

γ)h(xk)

(cid:13)
(cid:13)
−

σA

W T g(sk)

¯x

≤
2σ4c(pk)tr(A2), (30)

−

(cid:0)

2

(cid:1)(cid:13)
(cid:13)

ζ

E [

]

CB

≤

−

−

c(pk)
ξ

ξ2Var [

],

CB

p

(26)

where the RHS of (30) can be substituted by Γ
panding and rearranging (30) we get

B . Ex-
C

E [

which the right hand side of (26) can be lower bounded
by ζ
]. Scaling by the selected
CB
ξ is equivalent to solving the optimization problem with
a tighter constraint.

ξc(pk)Var [

≤ −

CB

−

]

4.3 Chance-Constrained ELM Learning Problem

S

deﬁned in Section 2, the ELM param-
Given a safe set
eterized model in (5), the initial state x0 ∈ S
, and the
likelihood function p(X
G, W ) in (6), the ELM parame-
|
ter learning problem can be formulated as a chance con-
strained regularized maximum log-likelihood estimation
as follows

W ∗= arg min
W

R(nh+1)×n−

ln p (X

G, W )+µW tr

W TW

|

∈

s.t. P (
CB ≥
P (
L
≤
C

ζ
δ

xk)
|
xk)
|

≥
≥

pk,
pk,

xk
∀
xk
∀

,
∈ D
,
∈ D

(cid:0)

(cid:1)(27a)
(27b)
(27c)

W Tg(sk)

T

¯x

−

A+4σ2c(pk)A2

W T g(sk)

(cid:0)

(cid:1)

(cid:0)

(cid:1) (cid:0)

¯x

−

(cid:1)

≤

B ,
Γ
C
(31)

which after substituting
for the middle term in (31) the
result in (28a) is obtained. Similarly, using Assumption
4 to upper bound the RHS of (25) we have

A

δ

−

E [

L]

C

≥

c(pk)Var [

L] ,

C

(32)

and when E [
L] and Var [
C
C
substituted into (32) we get

L] from (17) and (18) are

2
+4c(pk)

P

1
2

W Tg(sk)
−
σ2tr(P ) + (1

x∗

σP

W T g(sk)
2σ4c(pk)tr(P 2),
(cid:13)
(cid:13)

(cid:0)

x∗

−

2
≤
(33)
(cid:1)(cid:13)
(cid:13)

(cid:0)

−

(cid:13)
δ
(cid:13)
(cid:13)
where the RHS of (33) can be substituted by Γ
panding and rearranging (33) we get

(cid:1)(cid:13)
ρ)V (xk)
(cid:13)
(cid:13)

−

−

L . Ex-
C

k

ln p (X

Z+, where
2, µW

xk+1−
and
−
∈
∀
R+ is the regularization parameter,
W T g(sk)
k
and W ∗ denotes the optimal solution for W , which is
used in (5) to represent the learned system.

G, W ) = 1
2σ2

Tm
1
−
k=0 k

P

∈

|

Proposition 1 Given the system model
in (5) and
Assumption 4, the ELM parameter learning problem
with probabilistic safety and stability constraints given
in (27a)-(27c) can be formulated as a QCQP with the
objective function in (27a) and the following constraints:

1
2

1
2

W T g(sk)
W T g(sk)
(cid:0)

¯x

x∗
(cid:1)

−

−

kA

kP

2

k

≤
2

k

≤

Γ

B ,
C
Γ

L,
C

(28a)

(28b)

where

(cid:0)

(cid:1)

W Tg(sk)

T

x∗

−

P +4σ2c(pk)P 2

W Tg(sk)

(cid:0)

(cid:1)

(cid:0)

(cid:1) (cid:0)

x∗

−

≤

L ,
Γ
C
(34)

(cid:1)

which after substituting
the result in (28b) is obtained.

P

for the middle term in (34)

The constraints (28a) and (28b) for the optimization
problem must be satisﬁed for all xk
, which leads to
a semi-inﬁnite program. In order to circumvent the chal-
lenge of having an uncountably inﬁnite set, Theorem 1
is formulated that proves only enforcing a modiﬁed con-
straints for a ﬁnite number of sampled points is suﬃcient
for obtaining a solution for the optimization problem in
(27a).

∈ D

A

,A + 4σ2c(pk)A2,
, 1
σ2tr(A)
ζ
−
−
C
L , δ
σ2tr(P )+(1
C

−

B

−

Γ

Γ

(1

−

P

, P + 4σ2c(pk)P 2
γ)h(xk)

2σ4c(pk)tr(A2)

−
ρ)V (xk)

−
2σ4c(pk)tr(P 2)

−

τ
D

be a discretization of the state space
xk

Let
D
⊂ D
with the closest point in
−
τ
[xk]τ
2 , where τ is the discretization resolution and
]τ denotes the function is evaluated at a point of the
[
·
discretized space
τ , we
sk
have

τ . Thus, sampling xk from

denoted by

τ to xk

∈ D

k ≤

D

D

k

.

D
[sk]τ k ≤

τ
√2

k

−

5

Theorem 1 If Assumptions 2-4 hold, then the optimiza-
tion problem in (27a)-(27c) can be solved with the objec-
tive in (27a) and the following modiﬁed conditions

kA

1
2

kP

¯x

1
2

W T [g(sk)]τ−
(cid:0)
W T [g(sk)]τ−
(cid:0)

x∗

k
(cid:1)

k
(cid:1)

2

[Γ

2
−

B ]τ ≤ −

C

τ (χ

B +Υ
C

B),
C
(35)

[Γ

L ]τ ≤ −

C

−

τ (χ

L +Υ
C

L),
C
(36)

[x]τ ∈ D

τ , where

∀

√nh + 1 + ¯W λmax{A}k

¯x
k

¯g,

χ

B

C

,

λmax{M}
(cid:0)
, (1

Υ

χ

Υ

B

C
L ,
C

−
λmax{H}
(cid:0)
L , (1
C

−

, W

M

A

γ) λmax{

(
k

A
}

xk
+
k
√nh + 1 + ¯W λmax{P}k

¯x
k

) ,

k

x∗

k

P

ρ) λmax{
W T ,

}
, W

(
k

k

+

xk
x∗
) ,
k
k
W T , ¯g , ¯ap ¯U √nh
2√2

P

H

(cid:1)

(37a)

(37b)

¯g,

(37c)

(37d)

(cid:1)

,

(37e)

diag(ap)
k

¯ap =
denotes the maximum
eigenvalue of the argument, then the safety and stability
conditions in (28a) and (28b) are satisﬁed

F , and λmax{·}

k

xk

.

∀

∈ D

PROOF. The modiﬁed safety constraint in (35) can be
written as

[Γ

B ]τ+ τ (χ
C

B +Υ
C

B)
C

≤

0, (38)

1
2

kA

¯x

W T [g]τ−
(cid:0)

2

−

k
(cid:1)
W T g

1
2

xk

. If

∈ D

¯x
B is a lower bound
∀
C
on the left hand side of (38) then the safety constraint
(cid:1)
in (28a) is satisﬁed. Consider

kA

−

−

Γ

k

(cid:0)

2

1
2

1
2

¯x

=

kA

OB

W Tg

2
−kA

W T [g]τ−
k
(cid:0)
(cid:1)
which by using the triangle inequality,
bounded as

−

(cid:0)

¯x

2

k
(cid:1)
OB

(Γ

−

B−
C

[Γ

B ]τ ),
C

can be upper

1
2

¯x

OB≤

W Tg

W T [g]τ−
(cid:0)
After expanding each term and using Remark 1, we have

kA
(cid:12)
(cid:12)
(cid:12)

2
−kA

k
(cid:1)

k
(cid:1)

B−
C

B ]τ
C

[Γ

−

+

(cid:12)
(cid:12)
(cid:12)

Γ

¯x

(cid:12)
(cid:12)

(cid:0)

2

(cid:12)
(cid:12)

1
2

2

1
2

1
2

2

¯x

¯x

−kA

W Tg

W T [g]τ−
k
k
−
kA
(cid:12)
(cid:1)
(cid:0)
(cid:1)
(cid:0)
(cid:12)
√nh + 1 + ¯W λmax{A} k
λmax {M}
¯x
(cid:12)
(cid:0)
A
γ) λmax {
+
(1
}

¯x
k

(
k

) τ,

xk

−

k

k

(cid:12)
(cid:12)
(cid:12)
k
(cid:1)

Γ

[Γ
+
B −
C
¯ap ¯U √nh
(cid:12)
(cid:12)
2√2

B ]τ
C

≤

τ +

(cid:12)
(cid:12)

.

6

which yields

1
2

Γ

2
−

W T [g]τ −
W Tg
¯x
¯x
B ≤ kA
kA
−
k
−
k
C
√nh + 1 + ¯W λmax {A} k
λmax {M}
¯x
¯gτ + (1
(cid:0)
(cid:0)
(cid:1)
(cid:1)
k
[xk]τ
xk
A
λmax{
and
(
(cid:0)
(cid:1)
∀
∀
k
k
}

¯x
k
k

∈ D

∈ D

) τ,

xk

+

2

1
2

[Γ

−
τ .

B ]τ +
C
γ)

×

(39)

From (38), (39), and (37) it is concluded that
Γ

W T g

0,

¯x

xk

1
2

2

.

−

B ≤
C

∀

∈ D

kA

−

k
(cid:1)

(cid:0)

In a similar fashion, the modiﬁed stability constraint in
(36) can be written as

[Γ

L ]τ+τ (χ
C

L +Υ
C

L)
C

≤

0, (40)

kP

1
2

W T [g]τ−
(cid:0)
. If
∈ D

1
2

x∗

2

−

k
(cid:1)
W T g

xk

x∗
L is a lower bound
∀
C
on the left hand side of (40) then the safety constraint
(cid:1)
in (28b) is satisﬁed. Consider

kP

−

−

Γ

k

(cid:0)

2

1
2

O

x∗

kP

L=

W Tg

W T[g]τ−
k
(cid:1)
(cid:0)
which by using the triangle inequality,
bounded as

2
−kP

−

(cid:0)

1
2

x∗

k
(cid:1)
O

2

(Γ

[Γ

L ]τ),
C

−

L−
C
L can be upper

1
2

L

≤

O

W Tg

W T [g]τ−
(cid:0)
After expanding each term and using Remark 1, we have

2
−kP

L−
C

kP
(cid:12)
(cid:12)
(cid:12)

k
(cid:1)

k
(cid:1)

x∗

x∗

[Γ

−

+

(cid:12)
(cid:12)
(cid:12)

L ]τ
C

Γ

(cid:12)
(cid:12)

(cid:0)

2

(cid:12)
(cid:12)

.

1
2

1
2

1
2

2

(cid:12)
(cid:12)
(cid:12)

x∗

x∗

−kP

k
(cid:1)

W Tg

W T [g]τ−
−
k
kP
(cid:0)
(cid:0)
(cid:1)
√nh + 1 + ¯W λmax{P} k
λmax {M}
x∗
(cid:0)
P
γ) λmax {
+
(1
which yields

) τ,
k

xk
k

x∗

−

k

}

k

(

(cid:1)

2

(cid:12)
(cid:12)
(cid:12)
k

Γ

[Γ
+
L−
C
¯ap ¯U √nh
(cid:12)
(cid:12)
2√2

L ]τ
C

≤

τ +

(cid:12)
(cid:12)

1
2

Γ

2
−

W Tg
W T [g]τ −
x∗
kP
−
√nh + 1 + ¯W λmax {P} k
λmax {H}
x∗
(cid:0)
(cid:0)
k
[xk]τ
)τ,
xk
P
λmax{
and
(
(cid:0)
(cid:1)
∀
∀
k
k
}

L ≤ kP
C

k
(cid:1)
+

x∗
k

∈ D

xk

k

x∗
−
k
¯gτ + (1
(cid:1)

∈ D

2

−
τ .

1
2

L]τ+
[Γ
C
ρ)

×

(41)

From (40),

(41), and (37),

it

is concluded that

1
2

W Tg

x∗

−

kP

Γ

2
−

L ≤
C

0,

xk

∀

.

∈ D

k
(cid:1)

(cid:0)

Remark 4 Theorem 1 proves that enforcing a modiﬁed
stability and Lyapunov constraints for a ﬁnite number of
sampled points is suﬃcient to obtain an optimal solution
of the QCQP deﬁned in (27a).

5 Numerical Evaluations

In this section two numerical examples of the proposed
method are presented. The optimization problem is

2.5

2

1.5

1

0.5

0

-0.5

-1

-1.5

-2

-2.5

-1.8

-2

1.6

1.8

3

2

1

0

-1

-2

-3

0

-1.8

-2

2

2.4

2

4

6

8

10

Fig. 2. Evolution of the joint angles for the planar robot
simulation using the learned ELM parameters.

-2

-1

0

1

2

Fig. 1. Illustration of the ELM model learning using prob-
abilistic safety and stability constraints on joint positions
data of a 2 DoF planar robot manipulator.

solved using the CVX package in MATLAB 2020b. Ran-
dom initialization process in the ELM algorithm may
lead to having saturated or constant neurons, which
are not desired while learning the model [28]. To cir-
cumvent this problem, a batch intrinsic plasticity (BIP)
learning rule is used to estimate the slopes and biases of
the ELM [28]. The active sampling strategy introduced
in [11] is also used to select informative points for the
constraint computations of the optimization problem in
(27a), (35), (36). For both examples, the risk tolerance
of pk = 0.9, the variance of ǫ of σ = 0.02, and regulariza-
tion parameter µW = 0.01 are chosen. The subsequent
results are generated using an ELM network with hid-
den neurons nh = 25. For both examples 100 Monte
Carlo simulation runs are conducted to test the model
on bound violations during the trajectory reproduction
from various initial conditions.

In the ﬁrst example a two-link robot planar manipula-
tor with lengths L1 = 1 [m] and L2 = 1 [m] and masses
m1 = 1 [kg] and m2 = 1 [kg] is considered. Consider
the Euler-Lagrange (EL) dynamics M (q)¨q + C(q, ˙q) ˙q +
R2
2 denotes the inertia ma-
G(q) = u, where M (q)
2 denotes the centripetal-Coriolis ma-
trix, C(q, ˙q)
R2
trix, G(q)
∈
R2 de-
represents the control input vector, and q, ˙q
note the joint angles and angular velocity, respectively.
A nonlinear black-box model of the EL-dynamics with
only position states is considered, and it is given by
qk+1 = f (qk, uk).

R2
R2 denotes the gravity vector, u

∈
∈

∈

∈

×

×

To generate the state trajectories data qk for training
the ELM model, a PID set-point controller is designed
to regulate the joint positions to a desired value q =
[ π
π
2 ,
2 ]. Through empirical investigations, a set of ﬁve
trajectories with randomly selected initial conditions are

−

(cid:1)
+ sin2 α
ι2
2
1
ι2
1 −

(cid:16)

|

q(2)

collected and their PID gains are tuned individually. The
joint position satisﬁes the following constraints:
| ≤
1.90, where q(1) and q(2) denote the
1.90 and
joint’s ﬁrst and second dimension. An invariant region
in the form of an ellipse is selected, i.e., h(qk) = 1
qk
lipsoid’s center of gravity,
(cid:0)

−
R2 denotes the hyperel-

¯q)T A(qk

, where ¯q

q(1)

| ≤

−

−

∈

¯q

|

cos2 α
ι2
1
cos α sin α

A =



cos α sin α
sin2 α
ι2
1

1
ι2
1 −
+ cos2 α
(cid:16)
ι2
2

1
ι2
2

1
ι2
2

, (42)

(cid:17)





(cid:17)



ι1 and ι2 are the major and minor axes of the ellipse, re-
spectively and α is the orientation of the ellipse. Parame-
ters of the ellipse are chosen such that the ellipse encloses
the demonstrations data and meets the constraints on
the joint positions. Other parameters γ = 0.9, ρ = 0.01,
ζ = 0.01, and δ = 0.01 are selected empirically. In Fig.
1 the results of the ELM parameter learning are shown
when the system parameters are subject to probabilistic
safety and stability constraints given in (35) and (36).
Using the DT-ZCBF implies asymptotic stability of set
, shown as an invariant region in Fig. 1. Hence, if any
S
bounded disturbances push the state outside the invari-
is asymptotically reached. For this
ant region, the set
reason, when training the system model, the points are
sampled from a more extensive set than the selected el-
lipse [16]. The joint position trajectory is produced at
a diﬀerent initial condition selected at random from a
uniform distribution between the initial condition used
during training and a point that is 0.5 millimeters dis-
tant apart. It can be seen from Fig. 1, the reproduced
trajectory remains inside the desired invariant region for
all time and converges to the desired set-point. Same re-
sults are observed for all the Monte Carlo runs. Fig. 2
shows the evolution of the joint angles using the learned
ELM parameters plotted as function of time. The re-
produced joint position trajectories never cross the set
boundaries in either direction and asymptotically con-
verge to a point very close to the desired position.

S

For the second example, the proposed method is tested

7

40

30

20

10

0

-10

-20

-30

-20

-10

0

10

20

30

40

50

60

Fig. 3. Model Snake, learned with probabilistic safety and
stability constraints for ellipse sets.

on the Snake shape from the LASA human handwriting
dataset [22]. An ellipse is chosen for the invariant region
that encloses the Snake shape’s 7 demonstrations. The
state trajectory data are translated by a constant be-
fore training so that the error between the current state
and the target location can be used as an input to the
network instead of the control signal. Once the model
is learned the state trajectories are translated back to
zero. The optimization design parameters for this simu-
lation are as follows: γ = 0.9 and ρ = 0.3, ζ = 0.1, δ = 1,
and they are selected empirically. Fig. 3 shows the tra-
jectories generated by the learned model remain inside
a safe set, and converge to the system equilibrium. Since
the constraints are derived for one-step-ahead predic-
tion, no barrier violation occurs during the Monte Carlo
runs if the initial condition is suﬃciently close to the ini-
tial condition of the demonstration trajectories. The av-
erage CPU time for training the ELM network for both
simulations is computed over ﬁve independent runs with
a 1000 number of sampling points is 2.32 seconds.

6 Conclusion

A nonlinear system identiﬁcation method using the
ELM with probabilistic DT-ZCBF and DT-CLF con-
straints is presented. The ELM reconstruction error
is modeled as a normally distributed Gaussian noise,
which induces a distribution over the safety and sta-
bility constraints. Therefore, the probabilistic form of
the ZBF and Lyapunov constraints are derived such
that safety and stability are guaranteed within user-
deﬁned risk tolerance. A theorem is developed to make
the QCQP implementable, which proves that with a
modiﬁcation to the constraints, the quadratic program
with an inﬁnite number of constraints can be relaxed to
a ﬁnite number of constraints. The applicability of the
proposed model learning method is demonstrated using
two practical robotics engineering examples.

References

[1] Steven L Brunton, Joshua L Proctor, and J Nathan
Kutz. Discovering governing equations from data by sparse
identiﬁcation of nonlinear dynamical systems. Proceedings of
the National Academy of Sciences, 113(15):3932–3937, 2016.

[2] Alessandro Chiuso and Gianluigi Pillonetto.

System
identiﬁcation: A machine learning perspective. Annual
Review of Control, Robotics, and Autonomous Systems,
2:281–304, 2019.

[3] Mario Sznaier. Control oriented learning in the era of big
data. IEEE Control Systems Letters, 5(6):1855–1867, 2020.

[4] Jan M Maciejowski. Guaranteed stability with subspace

methods. Systems & Control Letters, 26(2):153–156, 1995.

[5] M. Khosravi and R. S. Smith. Nonlinear system identiﬁcation
IEEE

with prior knowledge on the region of attraction.
Control Systems Letters, 5(3):1091–1096, 2021.

[6] S Mohammad Khansari-Zadeh and Aude Billard. Learning
control Lyapunov function to ensure stability of dynamical
Robotics and
system-based robot
Autonomous Systems, 62(6):752–765, 2014.

reaching motions.

[7] Harish Ravichandar, Iman Salehi, and Ashwin P Dani.
from
In Conference on Robot Learning, pages

Learning partially contracting dynamical
demonstrations.
369–378, 2017.

systems

[8]

Iman Salehi, Gang Yao, and Ashwin P Dani. Active
sampling based safe identiﬁcation of dynamical systems using
extreme learning machines and barrier certiﬁcates. In IEEE
International Conference on Robotics and Automation, pages
22–28, 2019.

[9] Jonas Umlauft and Sandra Hirche. Learning stochastically
stable Gaussian process state–space models. IFAC Journal
of Systems and Control, 12:100079, 2020.

[10] Sumeet Singh, Spencer M Richards, Vikas Sindhwani, Jean-
Jacques E Slotine, and Marco Pavone. Learning stabilizable
nonlinear dynamics with contraction-based regularization.
The International Journal of Robotics Research, 40(10-
11):1123–1150, 2021.

[11] Iman Salehi, Ghananeel Rotithor, Gang Yao, and Ashwin P
Dani. Dynamical system learning using extreme learning
machines with safety and stability guarantees. International
Journal of Adaptive Control and Signal Processing,
35(6):894–914, 2021.

[12] Quan Nguyen and Koushil Sreenath. Exponential control
barrier functions for enforcing high relative-degree safety-
critical constraints. In American Control Conference, pages
322–328, 2016.

[13] F. Berkenkamp, R. Moriconi, A. P. Schoellig, and A. Krause.
Safe learning of regions of attraction for uncertain, nonlinear
In IEEE Conference on
systems with Gaussian processes.
Decision and Control, pages 4661–4666, Dec 2016.

[14] Aaron D Ames, Xiangru Xu, Jessy W Grizzle, and Paulo
Tabuada. Control barrier function based quadratic programs
for safety critical systems. IEEE Transactions on Automatic
Control, 62(8):3861–3876, 2017.

[15] Muhammad Zakiyullah Romdlony and Bayu Jayawardhana.
Stabilization with
using Control
guaranteed
Lyapunov–Barrier Function. Automatica, 66:39–47, 2016.

safety

[16] Xiangru Xu, Paulo Tabuada, Jessy W Grizzle, and Aaron D
Ames. Robustness of control barrier functions for safety
critical control. IFAC-PapersOnLine, 48(27):54–61, 2015.

8

[17] Andrew J. Taylor and Aaron D. Ames. Adaptive safety with
control barrier functions. In American Control Conference,
pages 1399–1405, 2020.

[18] B. T. Lopez, J. J. E. Slotine, and J. P. How. Robust
adaptive control barrier functions: An adaptive and data-
driven approach to safety. IEEE Control Systems Letters,
5(3):1031–1036, 2021.

[19] Mohit Srinivasan, Amogh Dabholkar, Samuel Coogan, and
Patricio Vela. Synthesis of control barrier functions using
arXiv preprint
a supervised machine learning approach.
arXiv:2003.04950, 2020.

[20] Mohammad Javad Khojasteh, Vikas Dhiman, Massimo
Franceschetti, and Nikolay Atanasov. Probabilistic safety
constraints for learned high relative degree system dynamics.
In Learning for Dynamics and Control, pages 781–792.
PMLR, 2020.

[21] Ayush Agrawal and Koushil Sreenath. Discrete control
barrier functions for safety-critical control of discrete systems
In Robotics:
with application to bipedal robot navigation.
Science and Systems, volume 13. Cambridge, MA, USA, 2017.

[22] Andre Lemme, Yaron Meirovitch, Seyed Mohammad
Khansari-Zadeh, Tamar Flash, Aude Billard, and Jochen J
Steil. Open-source benchmarking for learned reaching motion
generation in robotics. Paladyn, J. Behav. Robot., 6:30–41,
2015.

[23] Mohamadreza Ahmadi, Andrew Singletary, Joel W Burdick,
and Aaron D Ames. Safe policy synthesis in multi-agent
In IEEE 58th
pomdps via discrete-time barrier functions.
Conference on Decision and Control, pages 4797–4803. IEEE,
2019.

[24] Frank L Lewis, Javier Campos, and Rastko Selmic.
industrial systems with actuator

Neuro-fuzzy control of
nonlinearities. SIAM, 2002.

[25] Gao Huang, Guang-Bin Huang, Shiji Song, and Keyou You.
Trends in Extreme Learning Machines: A review. Neural
Networks, 61:32–48, 2015.

[26] Peter M¨uller and David Rios Insua.

Issues in Bayesian
Analysis of Neural Network Models. Neural Computation,
10(3):749–770, 04 1998.

[27] Carl Edward Rasmussen. Gaussian Processes in Machine
Learning, pages 63–71. Springer Berlin Heidelberg, Berlin,
Heidelberg, 2004.

[28] Klaus Neumann and Jochen J Steil. Optimizing extreme
learning machines via ridge regression and batch intrinsic
plasticity. Neurocomputing, 102:23–30, 2013.

9

