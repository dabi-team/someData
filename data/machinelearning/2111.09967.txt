Differentiable quantum computational chemistry with
PennyLane

Juan Miguel Arrazola,1 Soran Jahangiri,1 Alain Delgado,1 Jack Ceroni,1 Josh Izaac,1
Antal Száva,1 Utkarsh Azad,1 Robert A. Lang,2, 3 Zeyue Niu,1 Olivia Di Matteo,1 Ro-
main Moyard,1 Jay Soni,1 Maria Schuld,1 Rodrigo A. Vargas-Hernández,2, 4 Teresa
Tamayo-Mendoza,2, 5 Cedric Yen-Yu Lin,3 Alán Aspuru-Guzik,2, 4, 6, 7 and Nathan Killoran1

1 Xanadu, 777 Bay Street, Toronto, Canada

2 Chemical Physics Theory Group, Department of Chemistry, University of Toronto, Canada

3 AWS Quantum Technologies, Seattle, Washington 98170, USA

4 Vector Institute for Artiﬁcial Intelligence, Toronto, Canada

5 Department of Chemistry and Chemical Biology, Harvard University

6 Department of Computer Science, University of Toronto, Canada

7 Canadian Institute for Advanced Research (CIFAR) Lebovic Fellow, Toronto, Canada

This work describes the theoretical foundation for all quantum chemistry functionality in PennyLane, a quantum computing

software library specializing in quantum differentiable programming. We provide an overview of fundamental concepts

in quantum chemistry, including the basic principles of the Hartree-Fock method. A ﬂagship feature in PennyLane is the

differentiable Hartree-Fock solver, allowing users to compute exact gradients of molecular Hamiltonians with respect to

nuclear coordinates and basis set parameters. PennyLane provides specialized operations for quantum chemistry, including

excitation gates as Givens rotations and templates for quantum chemistry circuits. Moreover, built-in simulators exploit

sparse matrix techniques for representing molecular Hamiltonians that lead to fast simulation for quantum chemistry ap-

plications. In combination with PennyLane’s existing methods for constructing, optimizing, and executing circuits, these

methods allow users to implement a wide range of quantum algorithms for quantum chemistry. We discuss how PennyLane

can be used to implement variational algorithms for calculating ground-state energies, excited-state energies, and energy

derivatives, all of which can be differentiated with respect to both circuit and Hamiltonian parameters. We conclude with an

example workﬂow describing how to jointly optimize circuit parameters, nuclear coordinates, and basis set parameters for

quantum chemistry algorithms. By combining insights from quantum computing, computational chemistry, and machine

learning, PennyLane is the ﬁrst library for differentiable quantum computational chemistry.

1
2
0
2

v
o
N
0
3

]
h
p
-
t
n
a
u
q
[

2
v
7
6
9
9
0
.
1
1
1
2
:
v
i
X
r
a

 
 
 
 
 
 
2

Introduction

Differentiable programming, which is central to machine learning and artiﬁcial intelligence, has beneﬁted both from new
hardware architectures such as graphical and tensor processing units, and from specialized software libraries for automatic
differentiation [1–4]. An analogous trend is occurring for quantum computing. Quantum devices across different platforms
are now accessible through the cloud, and considerable efforts are ongoing to scale up the number of components and
to improve their performance [5–13]. Simultaneously, quantum software platforms continue their development with the
goal of providing functionality across the entire spectrum of quantum computing [14–22]. This includes libraries designed
for quantum differentiable programming, with native support for computing gradients of hybrid quantum-classical mod-
els [18, 19].

The motivation for building quantum software originates from the underlying interest in quantum computing due to its
importance to fundamental science and to its potential to outperform existing approaches, notably for problems related to
the simulation of quantum systems [23, 24]. Quantum chemistry is recognized as one of the key potential application areas
of quantum computing because simulating properties of molecules and materials plays a central role in many industrial
processes [25–28]. This has led to considerable interest in developing new and improved quantum algorithms for quan-
tum chemistry, ranging from proof-of-principle methods that can be implemented in simulators and small-scale quantum
computers [29–33], to advanced techniques designed to run on large-scale fault-tolerant machines [34–39]. Researchers
and enthusiasts working in this ﬁeld have created a demand for quantum software tools designed for quantum chemistry
applications, leading to the appearance of software libraries aimed speciﬁcally at fulﬁlling their needs [40–42].

This work describes quantum chemistry functionality available in PennyLane, a quantum software library for quantum
differentiable programming (www.pennylane.ai) [18]. By combining methodologies from quantum computing,
computational chemistry, and machine learning, PennyLane is the ﬁrst library built speciﬁcally for differentiable quantum
computational chemistry. PennyLane users can natively compute gradients of all relevant methods, allowing for a ﬂexible
and general approach to the optimization of hybrid quantum-classical algorithms for quantum chemistry. This document is
a summary of the theoretical foundation of the software, serving as a technical complement to the online documentation
(pennylane.readthedocs.io). It is intended as a living manuscript to be periodically updated to reﬂect major
new features from all contributing developers.

A distinguishing feature of PennyLane’s quantum chemistry capabilities is a differentiable implementation of the Hartree-
Fock method, as pioneered in Ref. [43] and also implemented in Ref. [44]. PennyLane’s differentiable solver enables users
to compute exact gradients of atomic and molecular orbitals, Hartree-Fock energies, and molecular Hamiltonians, which
can then be employed in quantum algorithms. PennyLane provides custom gates and operations for quantum chemistry, in-
cluding excitation gates as Givens rotations, templates for chemically-inspired circuits, built-in functionality for computing
observables, and sparse matrix techniques for representing molecular Hamiltonians. Together with PennyLane’s existing
methods for designing, optimizing, and executing quantum circuits across simulators and hardware devices, these methods
allow users to implement a wide range of quantum algorithms for quantum chemistry, which can be optimized with respect
to both circuit and Hamiltonian parameters. PennyLane also includes a collection of tutorials aimed speciﬁcally at quantum
chemistry, suitable for both beginners and experts.

The rest of this manuscript is organized as follows. The ﬁrst section covers basic principles of quantum chemistry such
as the electronic structure problem and methods based on linear combinations of atomic orbitals. We then focus on the
differentiable implementation of the Hartree-Fock method, describing fundamental principles of automatic differentiation
and explaining how they can be used to construct differentiable implementations of electronic integrals, Fock matrices, and
solvers for self-consistent ﬁeld equations. We also explain how to use these calculations to construct qubit representations
of molecular Hamiltonians, which are also fully differentiable.

We continue by providing an overview of quantum algorithms for quantum chemistry. We outline the core idea of
using quantum computers to build many-body wavefunctions of molecules and compute expectation values of molecular
Hamiltonians. We summarize the main methods for achieving this with a focus on variational approaches. The rest of the
section describes how to design quantum circuits, compute expectation values, calculate ground and excited-state energies,
and obtain exact energy derivatives, which can be used to perform geometry optimization and to compute vibrational
normal modes and frequencies of molecules. As a ﬁnal example, we describe how to use PennyLane to implement fully
differentiable workﬂows for quantum chemistry capable of simultaneously optimizing gate parameters, nuclear coordinates,
and basis set parameters. Examples of PennyLane code are used throughout the manuscript as illustrations of the user

3

interface.

Quantum chemistry

This section reviews basic principles of quantum chemistry that are central to the entire manuscript. This includes
a discussion of central concepts such as fermionic ladder operators, the occupation-number representation, molecular
Hamiltonians, molecular orbitals, and electron integrals.

The electronic structure problem

The underlying laws of quantum mechanics that govern the properties of molecules and materials have been understood
for decades, yet the challenge remains to perform efﬁcient and accurate calculations of these properties. A ﬁrst step in
taming the computational challenges of quantum chemistry is to decouple the electronic and nuclear degrees of freedom.
This is known as the Born-Oppenheimer approximation, which is supported by the fact that electrons are largely responsible
for the chemical properties of molecules, and nuclei are orders-of-magnitude heavier than electrons. The result is the
electronic structure problem: solving the time-independent Schrödinger equation

H

Ψ
|

〉

= E

Ψ
|

〉

,

(1)

for a collection of interacting electrons in the presence of an electrostatic ﬁeld generated by the nuclei, which are treated
as stationary point particles ﬁxed to their positions. Here H is the electronic Hamiltonian depending parametrically on the
positions of the nuclei and
is the quantum state of the electronic degrees of freedom. Knowledge of the eigenvalues Ei
and eigenstates
of the Hamiltonian is enough to compute important properties of molecules. Typically it is sufﬁcient
to consider only the ground state and the ﬁrst few excited states.

Ei〉

Ψ
|

〉

|

We focus on the second-quantization approach where the antisymmetry of fermionic systems is captured by properties
of operators, and states are represented in terms of occupation numbers. More concretely, we consider a set of functions
, where x = (r, σ) includes spatial (r) and spin (σ) degrees of freedom. These functions are referred to as spin-
φp(x)
}
{
orbitals. We introduce the notation

n1, n2, . . . , nM 〉
to denote an electronic state in the space of M spin-orbitals, where np = 1 if φp is occupied by an electron and np = 0
otherwise. Within the restrictions of the chosen set of spin-orbitals, any possible electronic state can be expressed as a
superposition of states of this form.

(2)

|

,

To represent general operators, it is useful to deﬁne the fermionic ladder operators ap, a†

p. They satisfy the anticommu-

tation relations

Their action on states in the occupation number representation is given by

ap, a†
q}
ap, aq}

{

{

= δpq,
p, a†
a†
q}

=

{

= 0.

ap |
a†
p |

n1, . . . , nM 〉
n1, . . . , nM 〉

= δ1,np
= δ0,np

(
−
(
−

1)Np

1)Np

n1, . . . , np ⊕
n1, . . . , np ⊕

1, . . . , nM

,

1, . . . , nM

(cid:11)

,

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1)Np applied to the state encodes the exchange
where Np =
symmetry of fermions, meaning that the states themselves do not need to be explicitly antisymmetrized — an important
property that both classical and quantum algorithms beneﬁt from.

denotes addition modulo 2. The phase (

P

−

⊕

p
i=1 ni and

(cid:11)

In the regime where relativistic effects are not important and we can decouple electronic and nuclear degrees of freedom,

a molecular Hamiltonian can be represented in terms of these operators as

H =

hpqa†

paq +

Xpq

1
2

Xpqrs

hpqrsa†

pa†

qar as.

(7)

(3)

(4)

(5)

(6)

The coefﬁcients hpq and hpqrs are known respectively as the one- and two-electron integrals. They will be described in more
detail in future sections.

Linear combination of atomic orbitals

For very simple systems like the hydrogen atom, it is possible to derive analytical solutions of the Schrödinger equation.

For example, the ground-state wavefunction of the electron in the hydrogen atom is

Ψ(r) =

1
pπ

e−

r,

(8)

4

x 2 + y 2 + z2, and we use atomic units that set the Bohr radius
where r = (x, y, z) is the electron coordinate vector, r =
equal to one. Analytical solutions for more complicated systems quickly become intractable, requiring the use of numerical
methods. Any function can be represented in terms of a complete basis, for example the set of all plane waves of the form
r. Since exact representations require an inﬁnitely large basis set, it is customary to deﬁne a restricted basis set that
e−
can be used as an approximation to the continuum limit. The challenge is to ﬁnd basis sets containing few elements that
can still provide accurate representations.

p

ik

·

The most common approach in quantum chemistry is to introduce localized basis sets that are appropriate for describing
functions centered at the nuclei of each atom. These are used to represent localized functions known as atomic orbitals.
By taking linear combinations of atomic orbitals, it is possible to represent molecular orbitals that describe how electrons
are distributed around the entire molecule. This strategy is known as the linear combination of atomic orbitals (LCAO) [45].

Atomic orbitals χ(r) are expanded in terms of primitive functions ψ(r) as

n

χ(r) = N

aiψi(r, αi ),

(9)

Xi=1
where the ai are coefﬁcients, αi denote possible internal parameters of the primitive functions, and N is a normalization
constant. Here we are implicitly assuming that these functions are centered at the origin, but their centers can be translated
to the nuclear coordinates R by setting r
R. This choice is a key feature of the LCAO approach: electron wave functions
have cusps centered at the nuclei where the Coulomb potential peaks, so it is useful to employ nuclei-centered orbitals that
can replicate this behaviour. Molecular orbitals are denoted by φ(r) and can be expressed as

→

−

r

φ(r) =

Ci χi(r),

(10)

Xi
where the Ci are real coefﬁcients and the index i runs over all atomic orbitals. Molecular orbitals can thus be viewed as a
double expansion: they are a linear combination of atomic orbitals, which are themselves linear combinations of primitive
basis set functions. In the restricted case, particles of different spin occupy the same spatial orbitals, allowing us to drop
the spin label and consider both types of spin-orbitals on the same footing.

Experts have worked for decades to develop a vast array of increasingly sophisticated basis sets for chemistry applica-
tions [46, 47]. The coefﬁcients ai, which have been optimized to describe the electronic structure of isolated atoms, are
typically used regardless of the molecule containing the atoms. The parameters that are individually optimized for each
molecule are the coefﬁcients Ci . Large basis sets are needed for highly-accurate simulations, which leads to increased
computational costs. This establishes a fundamental trade-off between accuracy and efﬁciency which is particularly im-
portant for quantum algorithms, where the number of qubits typically increases with the number of elements in the basis set.

The one- and two-electron integrals hpq, hpqrs introduced in Eq. (7) can be interpreted as matrix elements of the Hamil-

tonian in the basis of molecular orbitals. Their full expressions are

hpq =

hpqrs =

Z

Z

dx φ∗p(x)

dx1dx2

2

N

∇
2 −

Zi
Ri | Œ

φq(x),

−

‚−
r
Xi=1
|
φ∗p(x1)φ∗q(x2)φr (x2)φs(x1)
r1 −
|

r2|

,

(11)

(12)

where Zi is the atomic number of the i-th nucleus and the sum is taken over all atoms in the molecule. The one-electron in-

tegral contains contributions from the electronic kinetic energy and the electron-nuclear attraction, while the two-electron
integral represents energy contributions from the Coulomb repulsion between pairs of electrons.

Molecular Hamiltonians are deﬁned in terms of the integrals in Eqs. (11) and (12), which depend explicitly on the choice
of molecular spin-orbitals. In the following section, we discuss the Hartree-Fock method, which can be employed to obtain
optimized spin-orbitals. In PennyLane, the Hartree-Fock method is implemented in a fully differentiable manner, allowing
users to compute gradients of all relevant quantities with respect to basis set parameters and nuclear coordinates. This
is achieved using the techniques of automatic differentiation, which we describe brieﬂy in comparison to other strategies
such as symbolic and numerical differentiation.

5

Differentiable Hartree-Fock

The ability to compute derivatives of functions is a central task in science and mathematics. Symbolic differentiation
obtains derivatives of an input function by direct mathematical manipulation, for example using standard strategies of
differential calculus. These can be performed by hand or with the help of computer algebra software. The resulting
expressions are exact, but the symbolic approach is of limited scope, particularly since many functions are not known in
explicit analytical form. Symbolic methods also suffer from the expression swell problem where careless usage can lead
to exponentially large symbolic expressions. Numerical differentiation is a versatile but unstable method, often relying on
ﬁnite differences to calculate approximate derivatives. This is problematic especially for large computations consisting of
many differentiable parameters [48].

Automatic differentiation is a computational strategy where a function implemented using computer code is differen-
tiated by expressing it in terms of elementary operations for which derivatives are known [48, 49]. The gradient of the
target function is then obtained by applying the chain rule through the entire code. In principle, automatic differentiation
can be used to calculate derivatives of a function using resources comparable to those required to evaluate the function
itself. This strategy has gained signiﬁcant attention in machine learning, and consequently several software packages for
automatic differentiation have been developed [1–4].

In this section, we describe the Hartree-Fock method for quantum chemistry and outline its implementation in PennyLane
using principles of automatic differentiation. Building upon work pioneered in Ref. [43], PennyLane provides built-in meth-
ods for constructing atomic and molecular orbitals, building Fock matrices, and solving the self-consistent Hartree-Fock
equations to obtain optimized orbitals, which can be used to construct molecular Hamiltonians. PennyLane allows users
to natively compute derivatives of all these objects with respect to the underlying parameters. The implementation makes
use of differentiable transforms, allowing the entire workﬂow to be differentiable while maintaining a simple and ﬂexible
user interface. All physical quantities in this context are deﬁned in atomic units.

The main goal of the Hartree-Fock method is to obtain molecular spin-orbitals that minimize the energy of a state where
electrons are treated as independent particles occupying the lowest-energy orbitals. Here we provide an overview of the
main steps of this process and their PennyLane implementation. An in-depth pedagogical review can be found in Ref. [45].
We focus on the restricted Hartree-Fock method, where each spatial orbital is occupied by two electrons with opposite spin.

Basis sets, orbitals, and molecules

The design and choice of basis sets is largely guided by their usefulness in computational methods. Part of the challenge
in optimizing molecular orbitals, building Hamiltonians, and performing electronic structure calculations is to compute
integrals over primitive basis functions. Most modern methods in quantum chemistry employ Gaussian functions as the
primitive basis because they are simple to evaluate analytically and numerically [50]. These are functions of the form

ψ(r, α) = x l y mzne−

αr2

,

(13)

αr2
where for simplicity we assume are centered at the origin. Gaussian functions e−
are smoother at the origin and decay
αr, as in Eq. (8). Nonetheless, linear combinations of Gaussians can be used to
more quickly than Slater-type functions e−
approximate Slater-type orbitals. This is the strategy of the STO-nG class (Slater-type orbitals with n primitive Gaussians),
of which the simplest example that is commonly used is the STO-3G basis set. This consists of atomic orbitals of the form

3

χ(r) =

aiψ(r, αi),

Xi=1

(14)

where the contraction coefﬁcients ai and the exponents αi are typically predeﬁned for each atom, but in principle can be
optimized for speciﬁc molecules. PennyLane provides native support for STO-3G in the differentiable solver, while also
allowing users to manually import coefﬁcients and exponents from other basis sets. Moreover, PennyLane provides native
support for differentiating atomic orbitals with respect to contraction coefﬁcients, exponents, and nuclear coordinates.

The Molecule class can be used to encapsulate all relevant information about a system. By specifying a list of atomic
symbols and nuclear coordinates, we can instantiate a molecule object containing as attributes the charge of the molecule,
number of electrons, nuclear charges, number of orbitals, Gaussian exponents α, Gaussian centers, contraction coefﬁcients
a, and angular momentum values (l, m, n) of the basis functions, which can also be optionally passed by the user. This
enables sophisticated functions that depend on all these parameters to simply take a molecule object as an argument.

6

1 from pennylane import hf
2 from pennylane import numpy as np

3

4 symbols = ['H', 'H']
5 geometry = np.array([[0.0, 0.0, -0.6614], [0.0, 0.0, 0.6614]])
6 mol = hf.Molecule(symbols, geometry)

Codeblock 1: Constructing a molecule object for the hydrogen molecule.

Matrices and integrals

To group all coefﬁcients in a single object, we can deﬁne the coefﬁcient matrix C with entries Cµi such that the i-th

molecular orbital can be expressed as

where Greek letters are used to denote sums over basis functions. We also deﬁne the matrix P with entries

φi(r) =

Cµi χµ(r),

Xµ

Pµν =

Cµi Cνi ,

Xi

which leads to a concise expression for the Hartree-Fock energy

The matrices appearing in this expansion are the core Hamiltonian H with entries

E = 2

PµνHµν +

Xµν

Pµν

2Jµν −

Kµν

.

(cid:0)

(cid:1)

Xµν

Hµν =

Z

d r χ ∗µ(r)

2

1
2 ∇

‚−

N

−

r
|

Xi=1

Zi
Ri| Œ

−

χν(r),

the Coulomb matrix J with entries

and the exchange matrix K with entries

Jµν =

Xηγ

Pηγ(µν

ηγ),
|

Kµν =

1
2

Xηγ

Pµν(µη

νγ),
|

where the electron repulsion integral is deﬁned as

(µν

ηγ) =
|

Z

dr1 dr2

χ ∗µ(r1)χ ∗ν(r2)χη(r1)χγ(r2)
r1 −
|

r2|

.

(15)

(16)

(17)

(18)

(19)

(20)

(21)

The core Hamiltonian does not depend on the coefﬁcients Cµi , but the total energy depends on them through the matrix P.

7

The goal of the Hartree-Fock method is to ﬁnd the coefﬁcients Cµi that minimize the total energy function. While this
problem could be tackled through different strategies, a closed-form solution is known that can be used to directly obtain
the optimized molecular orbitals [50]. Central to this approach is the Fock matrix F, whose entries are deﬁned as

Fµν :=

∂ E
∂ Pµν

= Hµν + 2Jµν −

Kµν.

(22)

PennyLane provides functionality to compute core Hamiltonians, Coulomb matrices, exchange matrices, repulsion in-
tegrals, Fock matrices, and total energy, all of which are differentiable with respect to nuclear coordinates, contraction
coefﬁcients, and Gaussian exponents. By expanding the atomic orbitals in terms of the primitive Gaussian functions, the
core Hamiltonian integrals of Eq. (18) and the electron repulsion integrals of Eq. (21) can be expressed as linear combi-
nations of Gaussian integrals, for which there exist closed-form analytical formulas [51]. This enables an implementation
that is directly compatible with automatic differentiation techniques. PennyLane currently builds on Autograd [1] as a
lightweight approach to computing derivatives.

Self-consistent equations

The problem of ﬁnding the optimal coefﬁcients Cµi can be reduced to solving the Roothaan-Hall equation [45, 52, 53]

FC = SCE,

(23)

where F and C are respectively the Fock and coefﬁcient matrix, E is a diagonal matrix of eigenvalues, and S is the overlap
matrix with entries

Equation (23) can be further simpliﬁed by transforming the Fock and coefﬁcient matrices. Diagonalizing the overlap matrix
as

Sµν =

Z

dr χµ(r)∗χν(r).

(24)

where D is a diagonal matrix, we deﬁne X = V D−
standard form

S = V D VT ,

(25)

1/2 VT , C = X ˜C, and ˜F = XT F X. The equation can then be cast in its

˜F˜C = ˜CE.

(26)

This is an eigenvalue problem that can be solved using standard techniques in linear algebra, which are compatible with
automatic differentiation.

The Fock matrix depends implicitly on the coefﬁcient matrix. By setting an initial value for ˜C0, computing the resulting
matrix ˜F0, and solving Eq. (26), it is possible to end with a solution ˜C1 that is inconsistent with the original choice of
˜C0. Instead, we seek a self-consistent solution by iteratively repeating the process until Ck = Ck+1. Once a self-consistent
solution is found, the resulting coefﬁcients can be used to construct optimized molecular orbitals, compute the Hartree-
Fock energy, and build molecular Hamiltonians. Different initialization strategies are possible, but a simple and effective
approach is to set the ﬁrst coefﬁcient matrix equal to zero, meaning the only contribution to the energy arises from the
core Hamiltonian. The example code below shows how to calculate the Hartree-Fock energy and its gradient with respect
to nuclear coordinates for the simple case of the hydrogen molecule, which we focus on for subsequent code examples:

1 import pennylane as qml

2

3 energy = hf.hf_energy(mol)
4 g = qml.grad(hf.hf_energy(mol))(geometry)

Codeblock 2: Calculating the Hartree-Fock energy and its derivative with respect to nuclear coordinates. This uses the same
quantities deﬁned in Codeblock 1. The nuclear coordinates that deﬁne the molecular geometry are differentiable by default.

This simple user interface for constructing molecule objects makes use of default values for the basis set, charge, multi-

plicity, and active space of the molecule. Advanced users can also specify custom values for all these quantities.

Qubit Hamiltonians

The starting point of many quantum algorithms for quantum chemistry is the Hamiltonian describing the system of
interest. The molecule itself is described by the set of its constituent atoms and their coordinates in three-dimensional
space. Within a given basis set, this information is sufﬁcient to build the Fock matrix and implement the Hartree-Fock
method. The resulting optimized orbitals are then used to compute the one- and two-electron integrals that specify the
molecular Hamiltonian in terms of fermionic ladder operators.

8

To execute a quantum algorithm, it is necessary to express the Hamiltonian as a qubit operator while ensuring that it
retains all the required fermionic exchange symmetries. This in turn requires a description of fermionic states in terms of
qubit states. These transformations are performed using fermionic-to-qubit mappings [28]. The most widely used is the
Jordan-Wigner transformation [54]. Here, a state
in the occupation number representation on M spin-orbitals
can be directly mapped to a state
if the corresponding
nM 〉
spin-orbital is occupied, and

n1, . . . , nM 〉
|
on M qubits, where the state of the i-th qubit is

otherwise. Fermionic ladder operators are transformed as

n2〉 · · · |

n1〉|

1
〉
|

|

0
〉
|

ap =

a†
p =

1
2
1
2

Z0 ⊗ · · ·

Zp

1 ⊗

−

(X p + iYp),

Z0 ⊗ · · ·

Zp

1 ⊗

−

(X p −

iYp),

where X , Y, Z are Pauli matrices. This results in a Hamiltonian of the form

H =

h j Pj,

Xj

(27)

(28)

(29)

where Pj is a tensor product of the Pauli matrices I , X , Y, Z. In PennyLane, a qubit Hamiltonian can be easily obtained
directly from the molecule object:

1 H = hf.generate_hamiltonian(mol)(geometry)

Codeblock 3: Constructing the Hamiltonian for the hydrogen molecule, using the same deﬁnitions as in Codeblock 1.

As an alternative to the differentiable Hartree-Fock solver, PennyLane can also interface with the external packages
PySCF [55] or Psi4 [56] to calculate the one- and two-electron integrals and use functionality in OpenFermion [40] to con-
struct the qubit Hamiltonian. Users can also construct OpenFermion Hamiltonians themselves and map them to PennyLane
Hamiltonians.

The output of generate_hamiltonian() is a function that can take differentiable parameters as input to con-
struct the Hamiltonian. Under the hood, this function uses the differentiable solver to compute the optimized Hartree-Fock
orbitals, calculate the one- and two-electron integrals, and perform the Jordan-Wigner fermionic-to-qubit mapping to con-
struct a PennyLane Hamiltonian.

Differentiable qubit Hamiltonians can be constructed by deﬁning the atomic symbols and nuclear coordinates for a given
molecule and specifying the molecular parameters that will be differentiated. Currently, the exponents, contraction coefﬁ-
cients, and centers of the Gaussian basis functions can be speciﬁed to be differentiable by setting requires_grad=True
when their initial values are deﬁned. The following example code shows how to build a differentiable qubit Hamiltonian
when the atomic coordinates and the basis set parameters are all differentiable:

1 geometry = np.array([[0.0, 0.0, -0.6614], [0.0, 0.0, 0.6614]], requires_grad=True)

2

3 # basis set exponents
4 alpha = np.array([[3.4, 0.6, 0.2], [3.4, 0.6, 0.2]], requires_grad = True)

5

6 # basis set contraction coefficients
7 coeff = np.array([[0.2, 0.5, 0.4], [0.2, 0.5, 0.4]], requires_grad = True)

8

9 mol = hf.Molecule(symbols, geometry, alpha=alpha, coeff=coeff)

10

9

11 args = [geometry, alpha, coeff]

12

13 H = hf.generate_hamiltonian(mol)(*args)

Codeblock 4: Constructing the differentiable Hamiltonian for the hydrogen molecule.

PennyLane also provides functionality to construct sparse matrix representations of molecular Hamiltonians. In simula-
tors, this is used by PennyLane to perform fast computations of expectation values. PennyLane also allows users to directly
diagonalize the target Hamiltonian from its sparse-matrix representation, which can be used to benchmark the performance
of quantum algorithms without the need to perform additional quantum chemistry calculations, such as full-conﬁguration
interaction. Besides molecular Hamiltonians, PennyLane also provides support for constructing other observables, which
currently require interfacing with external packages. These include total particle number, total spin, spin projection, dipole
moment, and user-speciﬁed observables.

Quantum circuits

Quantum algorithms for quantum chemistry construct states of many-body fermionic systems and extract relevant infor-
mation from them. The most popular methods to achieve this are quantum phase estimation and variational algorithms.
In quantum phase estimation [57], the eigenvalues of a Hamiltonian H are encoded in the eigenvalues of a unitary U, for
iH t . The algorithm samples from the spectrum of U by performing
example through the time-evolution operator U = e−
repeated calls to an oracle implementing U controlled on the state of auxiliary qubits. The auxiliary qubits are then ro-
tated using an inverse quantum Fourier transform and measured to reveal a sampled eigenvalue. If the input state has a
sufﬁciently large overlap with a target eigenstate of H, quantum phase estimation can probabilistically prepare the target
eigenstate and compute its corresponding eigenvalue.

This is a remarkable capability that underlies the long-term potential of quantum computing for quantum chemistry.
However, quantum phase estimation requires a large number of qubits and long-depth circuits that make it challenging
to implement in both hardware and simulators, even for small systems. Still, PennyLane provides a general template for
quantum phase estimation that can be leveraged by advanced users to study prototype applications to quantum chemistry.

In variational algorithms, the goal is to design quantum circuits that can be optimized to prepare fermionic states of
interest. This allows for shorter-depth circuits without the need for auxiliary qubits, making them more appropriate for
simulation and implementation in noisy hardware. However, variational algorithms lack the theoretical guarantees of
quantum phase estimation and struggle to compute expectation values efﬁciently when implemented in hardware [58].
Optimization can often be carried out using gradient-based methods, meaning variational algorithms are amenable to
the methodologies of quantum differentiable programming that are PennyLane’s core strength. Below we discuss the
various strategies that can be used in PennyLane to create, evaluate, and optimize variational quantum circuits for quantum
chemistry.

Givens rotations

Under the Jordan-Wigner transformation, a qubit is associated with each spin-orbital and its states are used to represent
occupied
spin-orbitals. When designing quantum circuits for quantum chemistry, it is useful to employ
only particle-number conserving gates guaranteeing that the trial space is within the correct particle number subspace. The
simplest non-trivial particle-conserving gate is a two-qubit transformation that couples the states

or unoccupied

0
〉
|

1
〉
|

as

,

01
〉

|

10
|

〉

01
|
10
|
〉
2 = 1 and a b∗ + cd ∗ = 0 to ensure unitarity. This
2 =
while acting as the identity on
|
|
is an example of a Givens rotation: a two-dimensional rotation in the subspace of a larger Hilbert space. Restricting to the
case of real parameters, this gate can be written as

|
2 +
|

〉
2 +
|

01
〉
10
|

10
〉
01
〉

. Here

11
〉

= a
= c

+ b
+ d

00
|

(30)

(31)

and

U

U

a

d

b

c

〉

〉

|

|

|

|

|

|

|

,

,

0

1
0 cos(θ /2)
0 sin(θ /2)
0

0

G(θ ) = 




0

0
sin(θ /2) 0
−
cos(θ /2) 0
1

0






,

(32)

10

where we use the ordering
the states
the states

01
,
10
|
|
〉
1100
〉
|

0011
|

〉
and

as:

〉

of computational basis states. We call this a single-excitation gate because
differ by the excitation of a single particle. Similarly, we can consider the four-qubit gate that couples

11
〉

00
〉

01
|

10

〉

〉

|

|

|

,

,

,

G(2)(θ )
G(2)(θ )

0011

1100

|

|

〉

〉

= cos(θ /2)

= cos(θ /2)

0011

1100

|

|

+ sin(θ /2)

〉

sin(θ /2)

〉 −

1100

0011

,

.

〉

〉

|

|

(33)

(34)

This is an example of a double-excitation gate. Single-excitation and double-excitation gates are implemented natively in
PennyLane, together with decompositions into elementary gate sets and analytical gradient rules [59, 60].

It was proven in Ref. [61] that controlled single-excitation gates are universal for particle-conserving unitaries, establish-
ing the role of Givens rotations as the ideal building blocks of quantum circuits for quantum chemistry. PennyLane places
an emphasis on single and double-excitation gates in the construction of variational circuits, as shown in the example
code below. Using the qnode decorator, quantum circuits can be connected to a speciﬁc device performing its execution,
whether hardware or simulators. In this case the circuit is executed by the built-in default.qubit simulator, which
returns the expectation value of the Hamiltonian:

1 H = hf.generate_hamiltonian(mol)(*args)

2

3 dev = qml.device("default.qubit", wires=4)

4

5 @qml.qnode(dev)
6 def circuit(params, wires):

7

8

9

10

11

12

qml.BasisState(np.array([1, 1, 0, 0]), wires=wires)
qml.DoubleExcitation(params[0], wires=[0, 1, 2, 3])
qml.SingleExcitation(params[1], wires=[0, 2])
qml.SingleExcitation(params[2], wires=[1, 3])

return qml.expval(H)

Codeblock 5: An example circuit built using excitation gates based on Givens rotations. The circuit is initialized in the
Hartree-Fock state for a system with two electrons in two spin-orbitals. It then applies a double-excitation gate and two
single-excitation gates that are chosen to preserve spin.

Templates

A common approach in the design of quantum circuits for quantum chemistry is to propose a ﬁxed circuit architecture
that can be used for a variety of molecules. Also known as ansätze, these circuits aim to provide a general strategy for
creating states of interest in quantum chemistry. Circuits composed of multiple gates can be pre-coded in PennyLane as
templates, which can then be called in the same way as individual operations. This allows for a simple interface to build
circuits that implement various ansätze for quantum chemistry.

PennyLane currently provides templates for the unitary coupled-cluster singles and doubles (UCCSD) [62, 63], particle-
conserving gate fabrics [64], k-UpCCGSD [65], and the AllSinglesDoubles [61] ansatz consisting of all spin-conserving
single and double-excitation gates, which is shown in the example code below:

1 singles = [[0, 2], [1, 3]]
2 doubles = [[0, 1, 2, 3]]
3 hf = np.array([1, 1, 0, 0])

4

5 @qml.qnode(dev)
6 def circuit(params, wires):

7

8

9

qml.AllSinglesDoubles(params, wires, hf, singles, doubles)

return qml.expval(H)

Codeblock 6: Using a template to implement a circuit consisting of all spin-conserving single- and double-excitation gates
acting on the Hartree-Fock state deﬁned on a system with two electrons and four spin-orbitals, as in the hydrogen molecule in
a minimal basis set.

11

Adaptive circuits

A ﬁxed circuit ansatz may work well in many cases but it will not be optimized for the speciﬁc problem at hand. This
motivates strategies that select gates using information from the system being studied, which can lead to more efﬁcient
circuits. The most common approach for adaptively creating circuits is to select gates that have a large gradient with respect
to the relevant cost function. By design, PennyLane allows the computation of gradients with respect to all parametrized
gates in a quantum circuit.

The strategy of the ADAPT-VQE algorithm [31, 66] is to deﬁne a pool of gates, apply each to an initial state (typically
the Hartree-Fock state), and select the gate with the largest gradient. This gate is then optimized and the resulting gate
parameter ﬁxed, which deﬁnes a new initial state. The procedure is repeated until a convergence criterion is reached. An
alternative strategy proposed in Ref. [61] is to deﬁne a circuit including all single and double excitation gates, then compute
the gradient for all gates in the circuit, keeping only the gates whose gradient is above a threshold value.

Ground and excited-state energies

Once a quantum circuit has been deﬁned, the goal of variational algorithms is to optimize the circuit with respect to an ap-
propriate cost function. As discussed before, it is often sufﬁcient to compute ground and excited-state energies of molecular
Hamiltonians. This section discusses algorithms for performing these calculations and their PennyLane implementation.

Ground states

The variational quantum eigensolver (VQE) is an algorithm that computes approximate ground-state energies by optimiz-
ing the parameters of a quantum circuit with respect to the expectation value of a molecular Hamiltonian. More precisely,
using θ = (θ1, . . . , θn) to denote the parameters of a variational circuit,
to denote the state prepared by the circuit,
and H for the molecular Hamiltonian, the goal of VQE is to optimize the quantum circuit in order to minimize the cost
function

ψ(θ )
|

〉

C(θ ) =

ψ(θ )
〈

|

H

ψ(θ )
〉

|

.

(35)

This is a broad approach that encompasses a variety of methods for circuit design and parameter optimization. As
discussed above, PennyLane provides functionality to build molecular Hamiltonians and design quantum circuits using
individual gates, templates, or adaptive methods. To perform the circuit optimization, users have access to a wide ar-
ray of gradient-based optimizers that leverage PennyLane’s built-in ability to compute gradients of quantum circuits. This
includes quantum-aware optimizers such as the quantum natural gradient [67], Rotosolve [60, 68, 69], and Rotoselect [69].

To compute expectation values of Hamiltonians using simulators, PennyLane converts the Hamiltonian to a sparse matrix,
then uses the vector representation of the state to compute the expectation value
directly using matrix-
vector multiplication. It is also possible to directly pass a sparse matrix representation of the Hamiltonian to PennyLane’s
expval() function. Gradients are obtained using parameter-shift rules [70], backpropagation, or the adjoint method.

ψ
|

ψ

=

H

H

〈

〉

〈

〉

|

To calculate expectation values in hardware, it is necessary to compute the expectation of each term in the Hamiltonian’s

expansion as a linear combination of Pauli words:

=

H

〈

〉

h j〈

.
Pj 〉

Xj

(36)

〈

Pj 〉

The expectation values
can be calculated by performing only additional single-qubit rotations because the Pauli words
Pj are tensor products of local qubit operators. One major challenge is the large number of terms in this expansion, which
increases rapidly for larger molecules. This leads to the requirement for a total number of samples that scales dramatically
with system size; a major obstacle for scaling these algorithms. To partially alleviate this problem, it is possible to group
Pauli words into sets of mutually-commuting operators whose expectation values can then be calculated from the same
measurement statistics. This functionality is provided in PennyLane’s grouping module, and can be activated by passing
the keyword argument optimize=True when computing the expectation value.

The code below shows a full VQE workﬂow in PennyLane for computing the ground state of the hydrogen molecule in

the default minimal basis set.

1 import pennylane as qml
2 from pennylane import hf
3 from pennylane import numpy as np

4

5 symbols = ['H', 'H']
6 geometry = np.array([[0.0, 0.0, -0.6614], [0.0, 0.0, 0.6614]], requires_grad=False)
7 mol = hf.Molecule(symbols, geometry)

12

8

9 H = hf.generate_hamiltonian(mol)()

10

11 dev = qml.device("default.qubit", wires=4)

12

13 @qml.qnode(dev)
14 def circuit(param, wires):

qml.BasisState(np.array([1, 1, 0, 0]), wires=wires)
qml.DoubleExcitation(param, wires=[0, 1, 2, 3])
return qml.expval(H)

15

16

17

18

19 opt = qml.AdamOptimizer()
20 theta = 0.0
21 for n in range(50):

22

theta, energy = opt.step_and_cost(circuit, theta, wires=[0, 1, 2, 3])

Codeblock 7: VQE workﬂow to compute the ground-state energy of the hydrogen molecule.

By performing ground-state calculations for Hamiltonians H(R) deﬁned on different nuclear coordinates R, it is possible

to compute ground-state potential energy surfaces of molecules, which are deﬁned by the energy function

E(R) = min
〉

ψ

|

ψ
〈

|

H(R)

ψ

|

〉

=

ψ0(R)
〈

|

H(R)

ψ0(R)

,

〉

|

(37)

|

ψ0(R)

is the ground state, which depends on the nuclear coordinates R. The minima of a potential energy surface
where
correspond to equilibrium geometries, while local maxima correspond to transition states. Computing the energies at these
conﬁgurations allows us to calculate activation energies and chemical reaction rates.

〉

Excited states

The simplest method to extend ground-state algorithms to excited states is to leverage the fact that eigenstates are
mutually orthogonal [71, 72]. Excited-state energies can be computed by adding penalty terms to the cost function that
enforce orthogonality with lower-lying eigenstates. For example, to optimize a circuit that prepares the ﬁrst excited state
we employ the cost function

where β > 0 is an adjustable penalty parameter. The ground state
where E0 is the ground-state energy of H. Setting β > E1 −
the ﬁrst excited state of H. This procedure can be iterated to ﬁnd the k-th excited state by minimizing the cost function

is also an eigenstate of H (1) with eigenvalue E0 + β ,
E0 ensures that the lowest-energy eigenstate of H (1) is actually

,

(38)

(39)

C (1)(θ ) =

ψ(θ )
〈
H (1) = H + β

|

|

H (1)
ψ(θ )
|
〉
ψ0|
ψ0〉 〈
ψ0〉
|

,

C (k)(θ ) =

ψ(θ )
〈

H (k)
|
1
−

k

ψ(θ )
|

〉

,

βi |

ψi 〉 〈

ψi|

.

H (k) = H +

Xi=0
PennyLane users can perform excited-state calculations using the same functionalities as for ground-state computations by
adjusting the cost function accordingly. It is also possible to employ the built-in spin and dipole moment observables to
add penalties that select excited states corresponding to desired transitions.

These extended cost functions can be readily evaluated using simulators, but require additional resources in hardware.
2 can be computed using a SWAP test, which requires roughly doubling the number
. The
2, which is the probability of measuring the all-zero

Penalty terms of the form
ψi〉|
of qubits for the same circuit depth. An alternative is to apply a unitary V † at the end of the circuit, where V
desired overlap can be computed as

U(θ )V †

ψi 〉
|

ψ(θ )

2 =

0
〉

| 〈

=

0

|

|

ψ(θ )
ψi 〉|
|

|〈

0
|

| 〈

|

〉 |

(40)

(41)

state in the adjusted circuit and U(θ ) is a unitary preparing the trial ground state. This maintains the same number of
qubits while roughly doubling the circuit depth.

13

Energy derivatives

Ground and excited-state energies provide valuable information about the properties of molecules, but they are not
exhaustive in revealing all relevant information. Further insights can be obtained by studying gradients of the total energy.
This provides the ability to calculate forces on nuclei, perform molecular geometry optimization, and compute vibrational
normal modes and frequencies in the harmonic approximation. This section describes the theory of energy derivatives in
quantum chemistry and explains how to implement related algorithms in PennyLane.

Nuclear forces and geometry optimization

The force experienced by the nuclei of each atom in a molecule is given by the gradient of the total energy with respect

to the nuclear coordinates

where E(R) is deﬁned as in Eq. (37). From the Hellmann-Feynman theorem, the derivative of the ground-state energy with
respect to the coordinates of the i-th atom can be written as

F (R) =

−∇R E(R),

(42)

¬
This is an analytical expression that can be calculated from a circuit that has been optimized to prepare

ψ0(R)
(cid:12)
(cid:12)
(cid:12)
. Cru-
〉
cially, it requires a method to compute the Hamiltonian derivatives ∂ H(R)/∂ Ri . One of the key advantages of PennyLane’s
differentiable Hartree-Fock solver is that energy can be calculated directly and exactly using methods of automatic differ-
entiation, as illustrated in the example code below:

ψ0(R)
¶

ψ0(R)

(43)

=

(cid:12)
(cid:12)
(cid:12)

|

.

∂ E(R)
∂ Ri

∂ H(R)
∂ Ri

1 symbols = ['H', 'H']
2 geometry = np.array([[0.0, 0.0, -0.6614], [0.0, 0.0, 0.6614]], requires_grad=True)
3 mol = hf.Molecule(symbols, geometry)
4 args = [geometry]

5

6 dev = qml.device("default.qubit", wires=4)

7

8 def energy(mol):

@qml.qnode(dev)
def circuit(*args):

qml.BasisState(np.array([1, 1, 0, 0]), wires=range(4))
# applies gate with optimal parameter
qml.DoubleExcitation(0.209733, wires=[0, 1, 2, 3])
return qml.expval(hf.generate_hamiltonian(mol)(*args))

return circuit

9

10

11

12

13

14

15

16

17 forces = -qml.grad(energy(mol))(*args)

Codeblock 8: The nuclear forces can be computed exactly using the differentiable Hartree-Fock solver to compute gradients of
an optimized circuit that calculates the ground-state energy.

More broadly, as described in Ref. [73], Hamiltonian derivatives permit the study of cost functions that depend both on

circuit parameters θ and Hamiltonian parameters such as the nuclear coordinates R:

PennyLane users can compute gradients of this cost function with respect to both set of parameters, allowing for a joint
optimization of the cost function. The results are optimal circuit parameters θ ∗ that prepare an approximate ground state
and optimal nuclear coordinates R∗ that describe the equilibrium geometry of the molecule.

C(θ , R) =

ψ(θ )
〈

|

H(R)

ψ(θ )

.

〉

|

(44)

Hessians and vibrational modes

14

Expressions for higher-order energy derivatives can also be obtained [32, 74], but in this case there are contributions
, which themselves depend on derivatives of the optimal parameters
〉

arising from derivatives of the ground state
θ ∗(R). The second-order derivatives that deﬁne the Hessian of the energy can be calculated as [32]:

ψ0(R)

|

∂ 2 E(R)
∂ Ri∂ R j

=

∂ θ ∗a (R)
∂ Ri

∂
∂ θa

∂ E(R)
∂ R j

+

Xa ”

ψ(θ ∗(R))
(cid:12)
(cid:12)
(cid:12)

∂ 2H(R)
∂ Ri∂ R j (cid:12)
(cid:12)
(cid:12)

ψ(θ ∗(R))

.

—
To evaluate this expression, it is necessary to compute the expectation value of the Hessian of the Hamiltonian ∂ 2H(R)/∂ Ri ∂ R j,
which again can be performed exactly using PennyLane’s differentiable Hartree-Fock solver. The need for exact calculations
is even more important in this case since approximate techniques such as ﬁnite-difference are notoriously problematic for
Hessians.

¬

¶

∂ E(R)
∂ R j

To compute ∂
∂ θa

, it sufﬁces to take the circuit that has been optimized to prepare the ground-state energy and
compute its gradient with respect to the expectation vale of ∂ H(R)/∂ R j. This can be performed natively with PennyLane
by computing gradients of a circuit that has been optimized to calculate the ground-state energy. The remaining term
∂ θ ∗a (R)/∂ Ri can be obtained by solving the response equations [32]:

∂
∂ θa

∂ E(R)
∂ θb

∂ θ ∗b (R)
∂ Ri

=

−

∂
∂ θa

∂ E(R)
∂ R j

.

Xb

(45)

We previously discussed how ∂
is the second-order derivative of the circuit with
∂ θa
respect to the expectation value of the Hamiltonian, evaluated at the optimal circuit parameters. It can also be performed
natively with PennyLane by expressing the Hessian as the Jacobian of the gradient. Therefore all terms in the equation can
be calculated except for ∂ θ ∗b (R)/∂ Ri. This can be obtained by constructing the response equations of Eq. (45) and solving
the resulting system of linear equations.

can be computed. The term ∂
∂ θa

∂ E(R)
∂ θb

∂ E(R)
∂ R j

Computing energy Hessians provides information about the vibrational structure of molecules, which can be used as
inputs to algorithms for calculating properties such as vibronic spectra and vibrational dynamics [75–78]. In the harmonic
approximation, the potential experienced by the nuclei is approximated by a quadratic function that leads to harmonic mo-
tion. The eigenvectors of the energy Hessian correspond to the normal modes of vibration in the harmonic approximation,
and the eigenvalues are the vibrational normal mode frequencies.

Fully-differentiable workﬂows

This section combines concepts described throughout the manuscript to illustrate how PennyLane can be used to cre-
ate differentiable quantum chemistry workﬂows for electronic structure calculations capable of simultaneously optimizing
circuit parameters, nuclear coordinates, and basis set parameters. The example code below illustrates this for the H+
3 cation.

1 import pennylane as qml
2 from pennylane import numpy as np
3 from pennylane import hf

4

5 symbols = ["H", "H", "H"]

6

7 # non-equilibrium geometry
8 geometry = np.array([[0.0, 0.0, 0.0], [1.0, 1.0, 0.0],

9

10

[2.0, 0.0, 0.0]], requires_grad=True)

11 # basis set exponents
12 alpha = np.array([[3.4253, 0.6239, 0.1689], [3.4253, 0.6239, 0.1689],

13

14

[3.4253, 0.6239, 0.1689]], requires_grad=True)

15 # basis set contraction coefficients
16 coeff = np.array([[0.1543, 0.5353, 0.4446], [0.1543, 0.5353, 0.4446],

17

18

[0.1543, 0.5353, 0.4446]], requires_grad=True)

19 params = [np.array([0.0], requires_grad=True)] * 2

20

21 dev = qml.device("default.qubit", wires=6)

22

23 def energy(mol):

15

@qml.qnode(dev)
def circuit(*args):

qml.BasisState(np.array([1, 1, 0, 0, 0, 0]), wires=range(6))
qml.DoubleExcitation(*args[0][0], wires=[0, 1, 2, 3])
qml.DoubleExcitation(*args[0][1], wires=[0, 1, 4, 5])
return qml.expval(hf.generate_hamiltonian(mol)(*args[1:]))

return circuit

24

25

26

27

28

29

30

31

32

33 mol = hf.Molecule(symbols, geometry, alpha=alpha, coeff=coeff)
34 args = [params, geometry, alpha, coeff]

35

36 # gradient for circuit parameters
37 gradient_params = qml.grad(energy(mol), argnum = 0)(*args)

38

39 # gradient for nuclear coordinates
40 forces = -qml.grad(energy(mol), argnum = 1)(*args)

41

42 # gradient for basis set exponents
43 gradient_alpha = qml.grad(energy(mol), argnum = 2)(*args)

44

45 # gradient for basis set contraction coefficients
46 gradient_coeff = qml.grad(energy(mol), argnum = 3)(*args)

Codeblock 9: Workﬂow for simultaneously optimizing circuit parameters, nuclear coordinates, and basis set parameters for
the H+

3 cation.

Conclusion

Quantum chemistry is arguably the leading application of quantum computing: it combines (i) a mathematical foundation
underpinning the long-term potential for quantum advantage, and (ii) an area of signiﬁcant industrial interest. Scientists
working at the interface between quantum computing and quantum chemistry face the challenge of gaining expertise in
these two ﬁelds, both of which have a considerable barrier of entry. Software plays a central role in lowering these obstacles
and boosting scientiﬁc progress. This is one of the main goals of PennyLane: to create a tool that can enhance progress in
quantum computing. With this technical manuscript, we aim to provide an additional resource for users that beneﬁt from a
deeper dive into the scientiﬁc concepts that underly PennyLane’s quantum chemistry functionality, enabling them to better
employ the software and advance research combining differentiable programming, quantum computing, and quantum
chemistry.

The functionality described in this manuscript reﬂects PennyLane’s capabilities at the time of writing. Our goal is to
continue working on further development to expand its scope and enhance its performance. As an open-source software
library, PennyLane welcomes contributions from users across the world. This effort will constitute incorporation of state-
of-the-art techniques in the scientiﬁc literature as well as innovations from the team of PennyLane developers. Quantum
computational chemistry is a relatively young ﬁeld and there still remains much to be discovered.

[1] Dougal Maclaurin, David Duvenaud, and Ryan P Adams, “Autograd: Effortless gradients in numpy,” in ICML 2015 AutoML workshop,

Vol. 238 (2015) p. 5.

16

[2] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey
Irving, Michael Isard, et al., “Tensorﬂow: A system for large-scale machine learning,” in 12th USENIX symposium on operating
systems design and implementation (OSDI 16) (2016) pp. 265–283.

[3] James Bradbury, Roy Frostig, Peter Hawkins, Matthew J. Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake
VanderPlas, Skye Wanderman-Milne, and Qiao Zhang, “JAX: composable transformations of Python+NumPy programs,” (2018).
[4] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia
Gimelshein, Luca Antiga, et al., “Pytorch: An imperative style, high-performance deep learning library,” Adv. Neural Inf. Process.
Syst. 32, 8026–8037 (2019).

[5] Matthew Reagor, Christopher B Osborn, Nikolas Tezak, Alexa Staley, Guenevere Prawiroatmodjo, Michael Scheer, Nasser Alidoust,
Eyob A Sete, Nicolas Didier, Marcus P da Silva, et al., “Demonstration of universal parametric entangling gates on a multi-qubit
lattice,” Sci. Adv. 4, eaao3603 (2018).

[6] Frank Arute, Kunal Arya, Ryan Babbush, Dave Bacon, Joseph C Bardin, Rami Barends, Rupak Biswas, Sergio Boixo, Fernando GSL
Brandao, David A Buell, et al., “Quantum supremacy using a programmable superconducting processor,” Nature 574, 505–510
(2019).

[7] K Wright, KM Beck, Sea Debnath, JM Amini, Y Nam, N Grzesiak, J-S Chen, NC Pisenti, M Chmielewski, C Collins, et al., “Bench-

marking an 11-qubit quantum computer,” Nat. Commun. 10, 5464 (2019).

[8] JM Arrazola, V Bergholm, K Brádler, TR Bromley, MJ Collins, I Dhand, A Fumagalli, T Gerrits, A Goussev, LG Helt, et al., “Quantum

circuits with many photons on a programmable nanophotonic chip,” Nature 591, 54–60 (2021).

[9] Petar Jurcevic, Ali Javadi-Abhari, Lev S Bishop, Isaac Lauer, Daniela F Bogorin, Markus Brink, Lauren Capelluto, Oktay Günlük,
Toshinari Itoko, Naoki Kanazawa, et al., “Demonstration of quantum volume 64 on a superconducting quantum computing system,”
Quantum Sci. Technol. 6, 025020 (2021).

[10] Sepehr Ebadi, Tout T Wang, Harry Levine, Alexander Keesling, Giulia Semeghini, Ahmed Omran, Dolev Bluvstein, Rhine Samajdar,
Hannes Pichler, Wen Wei Ho, et al., “Quantum phases of matter on a 256-atom programmable quantum simulator,” Nature 595,
227–232 (2021).

[11] Juan M Pino, Jennifer M Dreiling, Caroline Figgatt, John P Gaebler, Steven A Moses, MS Allman, CH Baldwin, M Foss-Feig, D Hayes,

K Mayer, et al., “Demonstration of the trapped-ion quantum CCD computer architecture,” Nature 592, 209–213 (2021).

[12] Yuri Alexeev, Dave Bacon, Kenneth R Brown, Robert Calderbank, Lincoln D Carr, Frederic T Chong, Brian DeMarco, Dirk Englund,
Edward Farhi, Bill Fefferman, et al., “Quantum computer systems for scientiﬁc discovery,” PRX Quantum 2, 017001 (2021).
[13] Ivan Pogorelov, Thomas Feldker, Christian D Marciniak, Lukas Postler, Georg Jacob, Oliver Krieglsteiner, Verena Podlesnic, Michael
Meth, Vlad Negnevitsky, Martin Stadler, et al., “Compact ion-trap quantum computing demonstrator,” PRX Quantum 2, 020343
(2021).

[14] IBM Corporation, “Qiskit,” (2016).
[15] Rigetti Computing, “Forest SDK,” (2017).
[16] Google Inc., “Cirq,” (2018).
[17] Amazon Web Services, “Braket,” (2021).
[18] Ville Bergholm, Josh Izaac, Maria Schuld, Christian Gogolin, M Sohaib Alam, Shahnawaz Ahmed, Juan Miguel Arrazola, Carsten
Blank, Alain Delgado, Soran Jahangiri, et al., “Pennylane: Automatic differentiation of hybrid quantum-classical computations,”
arXiv:1811.04968 (2018).

[19] Michael Broughton, Guillaume Verdon, Trevor McCourt, Antonio J Martinez, Jae Hyeon Yoo, Sergei V Isakov, Philip Massey, Mur-
phy Yuezhen Niu, Ramin Halavati, Evan Peters, et al., “Tensorﬂow quantum: A software framework for quantum machine learning,”
arXiv:2003.02989 (2020).

[20] Nathan Killoran, Josh Izaac, Nicolás Quesada, Ville Bergholm, Matthew Amy, and Christian Weedbrook, “Strawberry ﬁelds: A

software platform for photonic quantum computing,” Quantum 3, 129 (2019).

[21] Yasunari Suzuki, Yoshiaki Kawase, Yuya Masumura, Yuria Hiraga, Masahiro Nakadai, Jiabao Chen, Ken M Nakanishi, Kosuke Mitarai,
Ryosuke Imai, Shiro Tamiya, et al., “Qulacs: a fast and versatile quantum circuit simulator for research purpose,” arXiv:2011.13524
(2020).

[22] Mark Fingerhuth, Tomáš Babej, and Peter Wittek, “Open source software in quantum computing,” PloS one 13, e0208561 (2018).
[23] J Ignacio Cirac and Peter Zoller, “Goals and opportunities in quantum simulation,” Nat. Phys. 8, 264–266 (2012).
[24] Iulia M Georgescu, Sahel Ashhab, and Franco Nori, “Quantum simulation,” Rev. Mod. Phys. 86, 153 (2014).
[25] Benjamin P Lanyon, James D Whitﬁeld, Geoff G Gillett, Michael E Goggin, Marcelo P Almeida, Ivan Kassal, Jacob D Biamonte,
Masoud Mohseni, Ben J Powell, Marco Barbieri, et al., “Towards quantum chemistry on a quantum computer,” Nat. Chem. 2,
106–111 (2010).

[26] Yudong Cao, Jonathan Romero, Jonathan P Olson, Matthias Degroote, Peter D Johnson, Mária Kieferová, Ian D Kivlichan, Tim
Menke, Borja Peropadre, Nicolas PD Sawaya, et al., “Quantum chemistry in the age of quantum computing,” Chem. Rev. 119,
10856–10915 (2019).

[27] Bela Bauer, Sergey Bravyi, Mario Motta, and Garnet Kin-Lic Chan, “Quantum algorithms for quantum chemistry and quantum

materials science,” Chem. Rev. 120, 12685–12717 (2020).

[28] Sam McArdle, Suguru Endo, Alan Aspuru-Guzik, Simon C Benjamin, and Xiao Yuan, “Quantum computational chemistry,” Rev.

Mod. Phys. 92, 015003 (2020).

[29] Alberto Peruzzo, Jarrod McClean, Peter Shadbolt, Man-Hong Yung, Xiao-Qi Zhou, Peter J Love, Alán Aspuru-Guzik, and Jeremy L

O’Brien, “A variational eigenvalue solver on a photonic quantum processor,” Nat. Commun. 5, 4213 (2014).

[30] Abhinav Kandala, Antonio Mezzacapo, Kristan Temme, Maika Takita, Markus Brink, Jerry M Chow,

and Jay M Gambetta,

“Hardware-efﬁcient variational quantum eigensolver for small molecules and quantum magnets,” Nature 549, 242–246 (2017).

[31] Harper R Grimsley, Sophia E Economou, Edwin Barnes, and Nicholas J Mayhall, “An adaptive variational algorithm for exact

17

molecular simulations on a quantum computer,” Nat. Commun. 10, 3007 (2019).

[32] Kosuke Mitarai, Yuya O Nakagawa, and Wataru Mizukami, “Theory of analytical energy derivatives for the variational quantum

eigensolver,” Phys. Rev. Res. 2, 013129 (2020).

[33] Marco Cerezo, Andrew Arrasmith, Ryan Babbush, Simon C Benjamin, Suguru Endo, Keisuke Fujii, Jarrod R McClean, Kosuke

Mitarai, Xiao Yuan, Lukasz Cincio, et al., “Variational quantum algorithms,” Nat. Rev. Phys. , 625–644 (2021).

[34] Peter JJ O’Malley, Ryan Babbush, Ian D Kivlichan, Jonathan Romero, Jarrod R McClean, Rami Barends, Julian Kelly, Pedram
Roushan, Andrew Tranter, Nan Ding, et al., “Scalable quantum simulation of molecular energies,” Phys. Rev. X 6, 031007 (2016).
[35] Ian D Kivlichan, Jarrod McClean, Nathan Wiebe, Craig Gidney, Alán Aspuru-Guzik, Garnet Kin-Lic Chan, and Ryan Babbush,

“Quantum simulation of electronic structure with linear depth and connectivity,” Phys. Rev. Lett. 120, 110501 (2018).

[36] Andrew M Childs, Dmitri Maslov, Yunseong Nam, Neil J Ross, and Yuan Su, “Toward the ﬁrst quantum simulation with quantum

speedup,” PNAS 115, 9456–9461 (2018).

[37] Joonho Lee, Dominic Berry, Craig Gidney, William J Huggins, Jarrod R McClean, Nathan Wiebe, and Ryan Babbush, “Even more

efﬁcient quantum computations of chemistry through tensor hypercontraction,” arXiv:2011.03494 (2020).

[38] Mario Motta, Erika Ye, Jarrod R McClean, Zhendong Li, Austin J Minnich, Ryan Babbush, and Garnet Kin-Lic Chan, “Low rank

representations for quantum simulation of electronic structure,” npj Quantum Inf. 7, 83 (2021).

[39] Yuan Su, Dominic W Berry, Nathan Wiebe, Nicholas Rubin, and Ryan Babbush, “Fault-tolerant quantum simulations of chemistry

in ﬁrst quantization,” arXiv:2105.12767 (2021).

[40] Jarrod R McClean, Nicholas C Rubin, Kevin J Sung, Ian D Kivlichan, Xavier Bonet-Monroig, Yudong Cao, Chengyu Dai, E Schuyler
Fried, Craig Gidney, Brendan Gimby, et al., “Openfermion: the electronic structure package for quantum computers,” Quantum Sci.
Technol. 5, 034014 (2020).

[41] Jakob S Kottmann, Sumner Alperin-Lea, Teresa Tamayo-Mendoza, Alba Cervera-Lierta, Cyrille Lavigne, Tzu-Ching Yen, Vladyslav
Verteletskyi, Philipp Schleich, Abhinav Anand, Matthias Degroote, et al., “Tequila: A platform for rapid development of quantum
algorithms,” Quantum Sci. Technol. 6, 024009 (2021).

[42] Nicholas H Stair and Francesco A Evangelista, “Qforte: an efﬁcient state simulator and quantum algorithms library for molecular

electronic structure,” arXiv:2108.04413 (2021).

[43] Teresa Tamayo-Mendoza, Christoph Kreisbeck, Roland Lindh, and Alán Aspuru-Guzik, “Automatic differentiation in quantum

chemistry with applications to fully variational Hartree–Fock,” ACS Cent. Sci. 4, 559–566 (2018).

[44] Muhammad F Kasim, Susi Lehtola, and Sam M Vinko, “DQC: a Python program package for differentiable quantum chemistry,”

arXiv:2110.11678 (2021).

[45] Susi Lehtola, Frank Blockhuys, and Christian Van Alsenoy, “An overview of self-consistent ﬁeld calculations within ﬁnite basis sets,”

Molecules 25, 1218 (2020).

[46] Balazs Nagy and Frank Jensen, “Basis sets in quantum chemistry,” Rev. Comput. Chem. 30, 93–149 (2017).
[47] Benjamin P Pritchard, Doaa Altarawy, Brett Didier, Tara D Gibson, and Theresa L Windus, “New basis set exchange: An open,

up-to-date resource for the molecular sciences community,” J. Chem. Inf. Model. 59, 4814–4820 (2019).

[48] Atilim Gunes Baydin, Barak A Pearlmutter, Alexey Andreyevich Radul, and Jeffrey Mark Siskind, “Automatic differentiation in

machine learning: a survey,” J. Mach. Learn. Res. 18, 1–43 (2018).

[49] Andreas Griewank, “On automatic differentiation,” Math. Program. 6, 83–107 (1989).
[50] Justin T Fermann and Edward F Valeev, “Fundamentals of molecular integrals evaluation,” arXiv:2007.12057 (2020).
[51] Trygve Helgaker and Peter R Taylor, “Gaussian basis sets and molecular integrals,” in Modern Electronic Structure Theory: Part II

(World Scientiﬁc, 1995) pp. 725–856.

[52] John A Pople and Robert K Nesbet, “Self-consistent orbitals for radicals,” J. Chem. Phys. 22, 571–572 (1954).
[53] John A Pople, Peter MW Gill, and Benny G Johnson, “Kohn-Sham density-functional theory within a ﬁnite basis set,” Chem. Phys.

Lett. 199, 557–560 (1992).

[54] P Jordan and E Wigner, “Über das paulische äquivalenzverbot,” Zeitschrift für Physik 47, 631–651 (1928).
[55] Qiming Sun, Timothy C Berkelbach, Nick S Blunt, George H Booth, Sheng Guo, Zhendong Li, Junzi Liu, James D McClain, Elvira R
Sayfutyarova, Sandeep Sharma, et al., “PySCF: the python-based simulations of chemistry framework,” Wiley Interdiscip. Rev.:
Comput. Mol. Sci. 8, e1340 (2018).

[56] Justin M Turney, Andrew C Simmonett, Robert M Parrish, Edward G Hohenstein, Francesco A Evangelista, Justin T Fermann,
Benjamin J Mintz, Lori A Burns, Jeremiah J Wilke, Micah L Abrams, et al., “Psi4: an open-source ab initio electronic structure
program,” Wiley Interdiscip. Rev.: Comput. Mol. Sci. 2, 556–565 (2012).

[57] Michael A Nielsen and Isaac L Chuang, Quantum Computation and Quantum Information (Cambridge University Press, 2010).
[58] Jérôme F Gonthier, Maxwell D Radin, Corneliu Buda, Eric J Doskocil, Clena M Abuan, and Jhonathan Romero, “Identifying chal-
lenges towards practical quantum advantage through resource estimation: the measurement roadblock in the variational quantum
eigensolver,” arXiv:2012.04001 (2020).

[59] Jakob S Kottmann, Abhinav Anand, and Alán Aspuru-Guzik, “A feasible approach for automatically differentiable unitary coupled-

cluster on quantum computers,” Chem. Sci. 12, 3497–3508 (2021).

[60] David Wierichs, Josh Izaac, Cody Wang,

and Cedric Yen-Yu Lin, “General parameter-shift rules for quantum gradients,”

arXiv:2107.12390 (2021).

[61] Juan Miguel Arrazola, Olivia Di Matteo, Nicolás Quesada, Soran Jahangiri, Alain Delgado, and Nathan Killoran, “Universal quantum

circuits for quantum chemistry,” arXiv:2106.13839 (2021).

[62] Jonathan Romero, Ryan Babbush, Jarrod R McClean, Cornelius Hempel, Peter J Love, and Alán Aspuru-Guzik, “Strategies for
quantum computing molecular energies using the unitary coupled cluster ansatz,” Quantum Sci. Technol. 4, 014008 (2018).
[63] Abhinav Anand, Philipp Schleich, Sumner Alperin-Lea, Phillip WK Jensen, Sukin Sim, Manuel Díaz-Tinoco, Jakob S Kottmann,
Matthias Degroote, Artur F Izmaylov, and Alán Aspuru-Guzik, “A quantum computing view on unitary coupled cluster theory,”

18

arXiv:2109.15176 (2021).

[64] Gian-Luca R. Anselmetti, David Wierichs, Christian Gogolin, and Robert M. Parrish, “Local, expressive, quantum-number-preserving

VQE ansatze for fermionic systems,” arXiv:2104.05695 (2021).

[65] Joonho Lee, William J Huggins, Martin Head-Gordon, and K Birgitta Whaley, “Generalized unitary coupled cluster wave functions

for quantum computation,” J. Chem. Theory Comput. 15, 311–324 (2018).

[66] Ho Lun Tang, VO Shkolnikov, George S Barron, Harper R Grimsley, Nicholas J Mayhall, Edwin Barnes, and Sophia E Economou,
“qubit-ADAPT-VQE: An adaptive algorithm for constructing hardware-efﬁcient ansatze on a quantum processor,” arXiv:1911.10205
(2019).

[67] James Stokes, Josh Izaac, Nathan Killoran, and Giuseppe Carleo, “Quantum natural gradient,” Quantum 4, 269 (2020).
[68] Javier Gil Vidal and Dirk Oliver Theis, “Calculus on parameterized quantum circuits,” arXiv:1812.06323 (2018).
[69] Mateusz Ostaszewski, Edward Grant, and Marcello Benedetti, “Structure optimization for parameterized quantum circuits,” Quan-

tum 5, 391 (2021).

[70] Maria Schuld, Ville Bergholm, Christian Gogolin, Josh Izaac, and Nathan Killoran, “Evaluating analytic gradients on quantum

hardware,” Phys. Rev. A 99, 032331 (2019).

[71] Tyson Jones, Suguru Endo, Sam McArdle, Xiao Yuan, and Simon C Benjamin, “Variational quantum algorithms for discovering

hamiltonian spectra,” Phys. Rev. A 99, 062304 (2019).

[72] Oscar Higgott, Daochen Wang, and Stephen Brierley, “Variational quantum computation of excited states,” Quantum 3, 156 (2019).
[73] Alain Delgado, Juan Miguel Arrazola, Soran Jahangiri, Zeyue Niu, Josh Izaac, Chase Roberts, and Nathan Killoran, “Variational

quantum algorithm for molecular geometry optimization,” Phys. Rev. A 104, 052402 (2021).

[74] Utkarsh Azad and Harjinder Singh, “Quantum chemistry calculations using energy derivatives on quantum computers,”

arXiv:2106.06463 (2021).

[75] Joonsuk Huh, Gian Giacomo Guerreschi, Borja Peropadre, Jarrod R McClean, and Alán Aspuru-Guzik, “Boson sampling for molec-

ular vibronic spectra,” Nat. Photonics 9, 615–620 (2015).

[76] Chris Sparrow, Enrique Martín-López, Nicola Maraviglia, Alex Neville, Christopher Harrold, Jacques Carolan, Yogesh N. Joglekar,
Toshikazu Hashimoto, Nobuyuki Matsuda, Jeremy L. O’Brien, David P. Tew, and Anthony Laing, “Simulating the vibrational quantum
dynamics of molecules using photonics,” Nature 557, 660–667 (2018).

[77] Soran Jahangiri, Juan Miguel Arrazola, Nicolás Quesada, and Alain Delgado, “Quantum algorithm for simulating molecular vibra-

tional excitations,” Phys. Chem. Chem. Phys. 22, 25528–25537 (2020).

[78] Soran Jahangiri, Juan Miguel Arrazola, and Alain Delgado, “Quantum algorithm for simulating single-molecule electron transport,”

J. Phys. Chem. Lett. 12, 1256–1261 (2021).

