9
1
0
2

t
c
O
3

]

G
L
.
s
c
[

1
v
2
8
3
1
0
.
0
1
9
1
:
v
i
X
r
a

Silas: High Performance, Explainable and Veriﬁable
Machine Learning

Hadrien Bride, Zh´e H´ou

Grifﬁth University, Nathan, Brisbane, Australia

Jie Dong

Dependable Intelligence Pty Ltd, Brisbane, Australia

Jin Song Dong

National University of Singapore, Singapore

Ali Mirjalili

Grifﬁth University, Nathan, Brisbane, Australia

Abstract

This paper introduces a new classiﬁcation tool named Silas, which is built to pro-

vide a more transparent and dependable data analytics service. A focus of Silas is

on providing a formal foundation of decision trees in order to support logical analysis

and veriﬁcation of learned prediction models. This paper describes the distinct fea-

tures of Silas: The Model Audit module formally veriﬁes the prediction model against

user speciﬁcations, the Enforcement Learning module trains prediction models that

are guaranteed correct, the Model Insight and Prediction Insight modules reason about

the prediction model and explain the decision-making of predictions. We also discuss

implementation details ranging from programming paradigm to memory management

that help achieve high-performance computation.

1. Introduction

Machine learning has enjoyed great success in many research areas and industries,

including entertainment [1], self-driving cars [2], banking [3], medical diagnosis [4],

shopping [5], and among many others. However, the wide adoption of machine learn-

Preprint submitted to Elsevier

October 4, 2019

 
 
 
 
 
 
2

ing raises the concern that most people use it as a “black-box” in their data analytics

pipeline. The ramiﬁcations of the black-box approach are multifold. First, it may lead

to unexpected results that are only observable after the deployment of the algorithm.

For instance, Amazon’s Alexa offered porn to a child [6], a self-driving car had a deadly

accident [7], etc. Some of these accidents result in lawsuits or even lost lives, the cost

of which is immeasurable. Second, it prevents the adoption in some applications and

industries where an explanation is mandatory or certain speciﬁcations must be satis-

ﬁed. For example, in some countries, it is required by law to give a reason why a loan

application is rejected.

In recent years, eXplainable AI (XAI) has been gaining attention, and there is a

surge of interest in studying how prediction models work and how to provide formal

guarantees for the models. A common theme in this space is to use statistical methods

to analyse prediction models. On the other hand, Bonacina recently envisaged that

automated reasoning could be the key to the advances of XAI and machine learning [8].

This aligns well with our interest of building a new machine learning tool with logic

and reasoning as the engine to produce “white-box” prediction models. A “white-box”

machine learning method in our vision should feature the following key points:

Explainability : The inner workings of produced predictive models should be inter-

pretable and users should be able to query the rationale behind their predictions.

Veriﬁability : The validity of the produced predictive models with respect to user

speciﬁcations should be formally veriﬁable.

Interactability : Data engineers should be able to guide the learning phase of predic-

tion models so that they conform with given speciﬁcations.

Towards this direction, we have been searching for a suitable machine learning

technique that (1) has good predictive performance and (2) is suitable for logical rea-

soning and formal veriﬁcation. We have found that some techniques show excellent

performance but are difﬁcult to understand, such as neural networks. Some tech-

niques are easy to explain, e.g., linear methods, but often do not perform as well as

the state-of-the-art. Some techniques have a solid probabilistic reasoning foundation,

3

e.g., Bayesian methods, but are not suitable to reason about using formal logic. Some

techniques that are interactive by nature, e.g., reinforcement learning, but are not in the

supervised learning scope of this work. Between neural networks and ensemble trees,

we choose the latter mainly because it is more amiable to logical reasoning, it has

excellent predictive performance, sometimes better than deep learning [9], on tabular

data, and it requires less data-preprocessing.

The current gap in the literature is the lack of understanding of the internal mecha-

nism of ensemble trees and their perceived black-box nature, which make them imprac-

tical in critical applications (e.g. medicine, law, Defence etc.) as discussed above. This

gap motivated our attempts to reinvent a new classiﬁcation tool named Silas, which is

a fusion of ensemble trees machine learning and automated reasoning and is built to

provide transparent data analytics. We aim to make Silas a high-performance alterna-

tive to existing machine learning tools for supervised learning of structured data with

an emphasis on dependability and transparency. Silas has the following novelties:

First, Silas builds decision trees that are deﬁned in a logical language that is de-

signed for formal reasoning and veriﬁcation. This theoretical foundation enables it to

produce prediction models for which automated reasoning techniques can be leveraged

to provide the following features:

Model Audit : Formally verify the correctness and safety of very large prediction

models in order to provide strong guarantees.

Enforcement Learning : Train prediction models that are correct-by-construction

with respect to user speciﬁcations.

Model Insight : Analyse the prediction model and give a general idea of how the

model makes predictions on each class.

Prediction Insight : Explain the decision-making of individual predictions by relating

them to their signiﬁcant predictors.

Second, Silas targets high-performance applications. Its predictive performance is

on par with industrial leaders of similar techniques. Moreover, its C++ implementation

4

is efﬁcient and outperforms competitors in term of time and memory consumptions.

As machine learning becomes more and more prevalent in everyday applications, Silas

will provide increased productivity with lower operating costs.

The remainder of the paper is organised as follows: Section 2 discusses the litera-

ture and how they relate to Silas. Section 3 describes the machine learning foundation

of Silas. Section 4 discusses the white-box aspects of Silas with case studies using

public datasets. Section 5 gives experimental results on Silas performance for large

datasets. It also details implementation choices and illutrate their impact on computa-

tional performance. Finlay, section 6 concludes the paper.

2. Related Work

There are many implementations of ensemble trees, such as xgBoost [10], H2O [11]

and Ranger [12]. The latter two are more relevant to the bagging implementation of

Silas. H2O is a Java implementation that is shown more efﬁcient than other tools [9],

and it supports distributed computing. Ranger is a fast implementation of random for-

est written in C++ that is designed to handle high dimensional data. It is non-trivial to

introspect and extract logical semantics from the structure of decision trees in popular

tools. Thus, we have developed our own implementation of ensemble trees [13, 14]

by using a tree structure that is amiable to logical reasoning. We show that our imple-

mentation is much faster and more memory efﬁcient than both H2O and Ranger. The

literature on ensemble trees and machine learning is rich and we will only focus on a

subset that is related to the interpretability and veriﬁcation of machine learning.

Although not yet substantial, there have been early steps taken towards under-

standing prediction models and providing guarantees for them. For instance, the Lime

tool [15] is able to provide local linear approximations of various types of prediction

models and show which features are the most decisive in predictions. Similarly, Hara

and Hayashi [16] proposed post-processing for ensemble trees to obtain an approx-

imation of the model with probabilistic interpretations. Another interesting work is

Lundberg et al.’s SHAP method [17], which uses the game theory to obtain consistent

explanations. Ehlers [18] developed an SMT based method to verify linear approxima-

5

tions of feed-forward neural networks. While these methods have shown potential in

interpreting and verifying predictions, they still treat the prediction model as a black-

box and try to analyse or verify an approximation of the black-box. On the contrary, we

are interested in treating the prediction model as a white-box and studying the internal

mechanism of prediction models.

A logical approach seems more natural for understanding the internal structure of

decision trees because decision trees are inherently connected with logical semantics

and are very similar to binary decision diagrams (BDDs) which are widely-used in

implementations of logical systems such as theorem provers [19] and model check-

ers [20]. Caruana et al.’s work [21] attempts to explain how a boosting machine makes

predictions by analysing the logical conditions in the decision trees. However, at the

time of writing their new Microsoft project was only 2 months old and the cited paper

did not give enough details on interpretability.

Complementary to the above work, we are also interested in providing formal guar-

antees for prediction models. T¨ornblom and Nadjm-Tehrani [22] proposed a method

to extract equivalent classes from random forest and verify that the input/output of the

model satisﬁes safety properties. Their approach considers all possible combinations

of results from all the trees, which means they have to verify 2d·B equivalent classes of

the results where d is the depth of trees and B is the number of trees. The advantage

of their approach is that they can give bi-directional results: (completeness) if the con-

straint is satisﬁed, their veriﬁcation returns positive, and (soundness) if the veriﬁcation

returns positive, the constraints must be satisﬁed. The disadvantage of their approach

is the high complexity and the veriﬁcation of 25 trees of depth 20 in practice. Our

veriﬁcation approach focuses on soundness, as a result, we can simplify and parallelise

the veriﬁcation in order to verify very large models.

Table 1 gives a comparison of key features of interest for this paper in popular

machine learning methods and tools. Note that we only consider the veriﬁcation of

the full prediction model instead of the veriﬁcation of an approximation of the model.

In this work, we focus on providing a white-box analysis for binary classiﬁcation as

the stepping stone for more general data analysis tasks. The remainder of the paper

Methods/Tools

Prediction Explanation Veriﬁcation

6

Correct-By-

Construction

Neural Networks (cid:51)
(cid:51)

Ensemble Trees

Silas

(cid:51)

(cid:51)*
(cid:51)*
(cid:51)

(cid:55)

(cid:51)†
(cid:51)

(cid:55)

(cid:55)

(cid:51)

Table 1: A comparison of key features of interest on some machine learning methods and tools. Correct-

By-Construction means the ability to train models that are guaranteed correct w.r.t. user speciﬁcations.

*For neural networks and other ensemble trees implementations, the explanation feature can be achieved

via additional packages such as LIME and SHAP. †Current veriﬁcation methods for ensemble trees is not

feasible to verify large models.

describes technical details of Silas1.

3. Machine Learning Preliminaries

This section provides the essential deﬁnitions of decision trees and their ensembles

for classiﬁcation. The focus is on subtle differences between our implementation and

the common deﬁnitions in the literature. Speciﬁcally, we give a logic-oriented deﬁni-

tion of decision trees that facilitates the reasoning and veriﬁcation of prediction models.

We also give the theoretical time complexity of the algorithm training an ensemble of

trees in Silas.

3.1. Decision Trees With a Logical Foundation

In the context of supervised learning, a structured dataset for classiﬁcation is de-

ﬁned as set of instances of the form (cid:104)x, y(cid:105) where x = (cid:104)x1, ..., xn(cid:105) is an input vector of
n ∈ N values often called features and y is an outcome value often called label. We

denote by X the feature space and Y the outcome space. In this paper, we focus on

binary classiﬁcation problems where Y = {positive, negative}.

1Download the education version at https://www.depintel.com/silas_download.html. Note

that this version does not include graphical interface and output. Please contact the authors if the reader

wishes to generate the ﬁgures in Section 4.4 and 4.5.

7

A decision tree is a tree-like structure composed of internal nodes and terminal

nodes called leaves. Internal nodes are predicates over the variables {x1, ..., xn} cor-

responding to features. Leaves are sets of instances. Without loss of generality, we

focus on binary trees. Internal nodes have two successors respectively called the left

and right child nodes. By convention, let p : X → {(cid:62), ⊥} be an internal node v,

left) child node of v is the root of a decision (sub)tree whose set of
the right (resp.
leaves L is a set of sets of instances such that ∀ x ∈ (cid:83){l | l ∈ L}, p(x) = (cid:62) (resp.

p(x) = ⊥). It follows that, given a decision tree, any input vector is associated with a

single leaf. Further, let D(Y ) : Y → [0, 1] be the set of distributions over Y such that
∀ d ∈ D(Y ), (cid:80)

y ∈ Y d(y) = 1. Every given leaf l is associated with a distribution

dl ∈ D(Y ) such that for all y ∈ Y , dl(y) is the proportion of instances in l whose

outcome is y. A decision tree is, therefore, a compact representation of a function of

the form X → D(Y ).

Let t : X → D(Y ) be a tree and x ∈ X be an input vector. Further, let M :

D(Y ) → Y be a function such that ∀ d ∈ D(Y ), M(d) = ymax such that d(ymax) =

max{d(y) | y ∈ Y }. The outcome predicted by t for the input vector x is the outcome

value M(t(x)).

F1

false

true

(0,6)

F2

false

true

(2,1)

(3,1)

Figure 1: An example binary decision tree.

An example of a decision tree is given in Figure 1. In this example, decision nodes

are diamonds and leaves are ovals. F1 and F2 are two logical formulae. The pair (2, 1)

means that there are 3 instances at this leaf, 2 of them are labelled negative and 1 of

them is labelled positive.

In Silas, similarly to popular greedy approaches such as C4.5 [23], trees are con-

8

structed by recursively splitting an input dataset until a stopping criterion is satisﬁed.

The splitting predicates are chosen based on the information gain they provide, a mea-

sure which is computed by comparing the entropy [24] between the parent node and the

child nodes. Contrary to generic decision trees grown by approaches such as C4.5 [23]

the predicates of internal nodes can be arbitrary logical formulae of the propositional

logic described below.

A logical formula in Silas is deﬁned as an extension of propositional logic with

arithmetic terms and comparison operators. The semantics of the logical language

follows that of standard arithmetic and propositional logic. An arithmetic term T is

deﬁned below where c is a constant (discrete or continuous value) and var is a variable

corresponding to (the name of) a feature:

T := c | var | −T | sqrt(T ) | T + T | T − T | T ∗ T | T /T

A Boolean formula F takes the following form where C denotes a set of constants

and ⊕ is the exclusive disjunction operator:

F := (cid:62) | ⊥ | var ∈ C | T < T | T ≤ T | T = T | T > T | T ≥ T |

¬F | F ∧ F | F ∨ F | F → F | F ⊕ F

In the implementation, we use var ∈ C to express formulae of nominal features,

which have discrete values and use (in)equalities to express formulae of numeric fea-

tures, which have continuous values.

3.2. Ensemble of Decision Trees

In general, deep decision trees tend to have low bias but high variance due to the

fact that they often overﬁt. Conversely, shallow decision trees tend to have high bias but

low variance. To balance bias and variance, a popular approach is to consider multiple

trees and aggregate their predictions.

In this paper, we focus on additive ensemble

approaches as they are the most widely adopted.

Let T = {(cid:104)w1,t1(cid:105), ..., (cid:104)wm,tm(cid:105)} be a set of m ∈ N weighted decision trees. We

deﬁne, similarly to the framework of Cui et al. [25], an additive ensemble ET : X →

D(Y ) as follows.

9

∀ x ∈ X, ET (x) = (cid:80)m

i=1 wi · ti(x)

Note that we overload the deﬁnition of the addition to apply to distribution over the

outcome space as follows.

∀ d1, d2 ∈ D(Y ), ∀ y ∈ Y, (d1 + d2)(y) = d1(y)+d2(y)

2

.

In this framework, several popular ensemble methods can be summarised, we brieﬂy

describe two of the most popular ones in the sequel.

Bagging. Each decision tree is trained using a subset of the dataset that is sampled

uniformly with replacement. The remaining instances form the out-of-bag (OOB) set.

The OOB set is often used to measure the performance of trees. When selecting the

best formula at each decision node in a tree, it only considers a subset of the features.

This is commonly found in algorithms such as Random Forest [26]. Bagging grows

large trees with low bias and the ensemble reduces variance.

Boosting. Boosting trains weak learners, i.e., small trees, iteratively as follows:

Ei+1(x) = Ei(x) + αi · ti(x)

where ti is the weak leaner trained at iteration i and αi is its weight. The ﬁnal ensemble

is thus a special case of ET (x) above where wi is αi. Boosting reduces bias.

A well known boosting approach, AdaBoost [27], focuses on training instances that

are misclassiﬁed in the previous iteration by minimising αi and ti in the formula below:

minimiseαi,ti

(cid:80)N

j=0 L(y( j), Ei(x( j)) + αi · ti(x( j)))

where L is a loss function measuring the difference between the actual outcome y( j)
of instance j and Ei+1(x( j)). AdaBoost often uses exponential loss L(a, b) = e−a·b in

which case the shallow decision trees are trained by weighted instances.

Silas. The remainder of the paper is focused on bagging, although the techniques we

describe can also be applied to boosting as well as other additive ensemble approaches.

In the following, we give the theoretical time complexity of the algorithm training an

ensemble of trees in Silas.

10

Theorem 1. Let t be the number of trees, m be the number of attributes and N be

the number of data points. The complexity of training an ensemble of trees in Silas is

O(t ∗ m ∗ N2 ∗ log(N)) in the worst case, and O(t ∗

√

m ∗ N ∗ log(N)) on average.

PROOF. (Outline) Silas builds trees by recursively splitting leaves. Given n data points,

the complexity of ﬁnding an appropriate split predicate is O(n) for a numerical attribute

and O(n + c ∗ log(c)) for a nominal attribute with c distinct values. This operation has

to be performed at each of the internal nodes of the tree. Further, we note that multiple

attributes are considered at each splitting nodes.

In the worse case, all attributes are nominal with N distinct values, and there are t

trees with N leaves, i.e., one data point per leaf. This corresponds to the computation

of t ∗ (2 ∗ N + 1) splitting predicates. Assuming that all attributes are considered at

each split, it follows that the complexity of training an ensemble of tree in Silas is

O(t ∗ m ∗ N2 ∗ log(N)) in the worst case.

In the average case, nominal attributes have at most c distinct values such that

c (cid:28) N. It follows that the complexity of ﬁnding an appropriate split predicate is O(N)

for both nominal and numerical attributes. Further, only

√

m attributes are consid-

ered at each split, and trees have log(N) leaves on average. Hence, growing t trees

corresponds to the computation of t ∗ (2 ∗ log(N) + 1) splitting predicates. It follows

that the complexity of training an ensemble of tree in Silas is, in the average case,

O(t ∗

√

m ∗ N ∗ log(N)).

We note that these complexity results are similar to those of the random forest

algorithm [28].

(cid:50)

4. Proposed Explainable And Veriﬁable Machine Learning

This section is concerned with eXplainable AI and safe machine learning. We de-

scribe our solution towards a more trustworthy machine learning technique using logic

and automated reasoning as the backbone. We discuss the Model Audit module for for-

mally verifying prediction models against user speciﬁcations, the Enforcement Learn-

ing module for training correct-by-construction models, Model Insight for explaining

prediction models and Prediction Insight for explaining prediction instances.

11

4.1. Logical Semantics of Decision Trees

Given a decision tree, we can obtain the following types of logical formulae:

Internal Node formula: The logical formula corresponding to every internal node.

Branch formula: The logical formula ((cid:86) N) → (y = M(dl)), where N is the set of
internal node formulae along the branch leading to the leaf l and dl is the distri-

bution associated with l.

Tree formula: The logical formula (cid:87) B where B is the set of branch formulae.

Each of the above mentioned formula is associated with a weight. An internal

node formula is weighted by the information gain computed during training. A branch

formula leading to a leaf l is weighted by the value log2(2) − H(l) where H(l) is the

entropy [24] of the leaf l. A tree formula is weighted by the ROC-AUC score obtained

on its out-of-bag sample during training.

4.2. Model Audit

The purpose of the model audit module is to provide the means to formally cer-

tify that the prediction model complies with user speciﬁcations. To do so we adopt

advanced automated reasoning techniques, especially satisﬁability modulo theories

(SMT) solvers [29]. SMT solvers determine the satisﬁability of logical formulae with

respect to combinations of background theories expressed in classical ﬁrst-order logic

with equality. A logical formula f is said satisﬁable, denoted by SAT ( f ), if and only if

there exists a valuation assigning values to its variables such that it is evaluated to true.

A user speciﬁcation is a tuple S = (cid:104)s⊥, s(cid:62)(cid:105) where s⊥ and s(cid:62) are logical formula

over {x1, ..., xn}. A prediction model complies with the user speciﬁcation S if for all

input instance x ∈ X leading to a positive (resp. negative) prediction, s(cid:62)(x) (resp.

s⊥(x)) evaluates to true. Formally, a user speciﬁcation S is valid over a prediction

model G : X → D(Y ), denoted by G |= S, if and only if:

∀ x ∈ X, ((M(G(x)) = negative) → s⊥(x)) ∧ ((M(G(x)) = positive) → s(cid:62)(x)).

12

In order to verify the validity of a user speciﬁcation S over an ensemble trees model

ET , i.e. ET |= S, we propose to reduce the problem to the veriﬁcation of the validity of

S over each of the decision trees in T . The following theorem proves the soundness of

this approach.

Theorem 2 (Soundness). If S is valid over all tree in T , i.e. ∀ ti ∈ T,ti |= S, then S is

valid over ET , i.e. ET |= S.

PROOF. (Outline) Without loss of generality, let us consider an ensemble trees model

ET based on two trees, i.e. T = {(cid:104)w1,t1(cid:105), (cid:104)w2,t2(cid:105)}. Now assume that ∀ ti ∈ T,ti |= S.

Given an arbitrary x ∈ X, we have to consider two case: (i) M(t1(x)) = M(t2(x)) and

(ii) M(t1(x)) (cid:54)= M(t2(x)). Case i: Let y ∈ Y such that M(t1(x)) = M(t2(x)) = y then,

by deﬁnition of ET , we have M(ET (x)) = y and we can conclude that ((M(ET (x)) =

negative) → s⊥(x))∧((M(ET (x)) = positive) → s(cid:62)(x)) holds. Case ii: Without loss of

generality, let us consider the case where M(t1(x)) = positive and M(t2(x)) = negative.

Since we assumed that t1 |= S and M(t1(x)) = positive, we know that s(cid:62)(x) holds.

Similarly, since we assumed that t2 |= S and M(t2(x)) = negative, we know that s⊥(x)

holds. We can conclude that s(cid:62)(x) ∧ s⊥(x) holds, hence ((M(ET (x)) = negative) →
(cid:50)

s⊥(x)) ∧ ((M(ET (x)) = positive) → s(cid:62)(x)) holds.

We note that this reduction is not sound when considering multiclass classiﬁcation

where the number of classes is greater than two. Further, this reduction is not com-

plete since a tree could violate the speciﬁcation while being outnumbered by trees that

comply with the speciﬁcation in the aggregation phase of the ensemble tree model. It

follows that veriﬁcation procedures based this reduction are therefore incomplete. This

is a trade-off purposefully made to reduce the overall complexity in order to achieve

better scalability.

We now proceed to show that, using the reduction we described, SMT solver can be

efﬁciently applied to the veriﬁcation of user speciﬁcation over ensemble tree models.

Let t be a tree and Ft its corresponding tree formula, the user speciﬁcation S is valid

over t if and only if:

¬SAT (Ft ∧ ¬(((y = negative) → s⊥(x)) ∧ ((y = positive) → s(cid:62)(x))))

13

By Theorem 2 this means that we can use SMT solvers to verify the validity of a

user speciﬁcation over ensemble trees models. This can be done in a parallel fashion

since each tree of an ensemble tree model can be veriﬁed independently.

Silas. The Model Audit feature employs the Z3 solver [30]. The interaction with

Z3 is straightforward as Silas supports direct translation from logical formulae to the

z3::expr type in Z3 C++ binding.

The remainder of this section presents a case study and report experimental results

demonstrating the feasibility and efﬁciency of the proposed approach.

Case study. We use the Kick dataset as a real-life application to illustrate the Model

Audit feature2. The goal of this dataset is to predict whether a used car at an auction is

a good buy or a bad buy. In a hypothetical scenario where car maker B discovered that

model C produced in year YY have problems and they had recalled all those cars. We

wish to check if our prediction model already “knows” this. We formulate the spec-

iﬁcation as follows: (y = positive) → ¬(make = B ∧ model = C ∧ year = YY ). The

Model Audit feature can be used to check if the prediction model meets the speciﬁca-

tion. In case it does not, we can use Enforcement Learning described in the following

section to train a new model that builds in this information. Running Model Audit on

the new model again shows that it meets the speciﬁcation (guaranteed).

To evaluate the efﬁciency of the veriﬁcation procedure, we generate models of var-

ious sizes (in terms of the number of trees and leaf size) for the Kick dataset and record

the computation time of the Model Audit feature when verifying the above property.

Experimental results are given in Figure 2. We observe that, as expected, the compu-

tation time grows linearly with respect to the number of trees and exponentially with

respect to the depth of trees. Full trees in this example are often smaller than depth 32,

so the increase from depth 16 to 32 is not large. The veriﬁcation time for models with

positive results and negative results are almost identical. Overall, the veriﬁcation can

be done in a reasonable time (< 20 min) for models with 1000 trees of depth 32.

2Detailed case study can be found at https://www.depintel.com/documentation/_build/html/

tutorials/advanced.html

14

Figure 2: Experiment results of Model Audit.

4.3. Enforcement Learning

The purpose of the Enforcement Learning module is to provide the means to build

prediction models that, given a user speciﬁcation, are correct-by-construction. This

feature is notably used in the context of critical or regulated applications. It can also

be used to enforce additional knowledge given by domain experts or existing expert

systems.

Given a user speciﬁcation S = (cid:104)s⊥, s(cid:62)(cid:105), Enforcement Learning proceeds as follows:

(1) It ﬁlters out from the dataset all instance (cid:104)x, y(cid:105) where:

((y = negative) ∧ ¬(s⊥)) ∨ ((y = positive) ∧ ¬(s(cid:62)))

(2) It constructs trees of the form given by ﬁgure 3 where t is a tree grown from the

ﬁltered dataset.

Trees built according to the above procedure are, by construction, valid with respect

to the given user speciﬁcation. By theorem 2 the resulting ensemble tree models are

also valid with respect to the given user speciﬁcation.

4.4. Model Insight

When the user obtains a model with satisfactory performance, we provide a feature

named Model Insight for analysing the general decision-making of the model.

15

s

false

true

(1,0)

s

false

true

(0,1)

t

Figure 3: Template of correct by construction trees

Given a label v (e.g. positive), we are interested in knowing which set of input

values would be predicted as v by an ensemble tree model ET . This way, domain

experts may use their knowledge to conﬁrm or refute the rationale exhibited by ET

when predicting label v.

To achieve this, we consider the set B of branches in trees of ET that predict v. This

set corresponds to the set FB of weighted branch formulae. We can then apply auto-

mated reasoning techniques to extract the maximum satisﬁable subset corresponding

to the set of input values on which the majority of branches in B agree. This subset is

called the max-sat core (MSC). We can do so using SMT solvers such as Z3 [30]. How-

ever, when considering all formulae in FB, the resulting MSC relates to a very small

set of input values for which the model predicts v with very high conﬁdence. Such an

MSC corresponds to very speciﬁc cases that are not useful in general explanations of

the prediction model. Therefore, to broaden the scope of the explanation we sample at

three different levels: the node level, the branch level and the tree level. The sampling

results in MSCs that correspond to more general explanations.

The explanations based on MSC extraction can be combined with feature impor-

tance to better illustrate the decision-making of the prediction model. There are several

methods to compute feature importance in the literature, e.g., [31]. Our computation

and presentation of feature importance are inspired by the LIME tool [15] and the

SHAP method [17].

The remainder of this section presents a small case study that illustrates the above

approach.

16

Decision Logic

30 ≤ age < 47

31 ≤ skin < 99

155 ≤ plas < 157

40 ≤ pres < 122

30 ≤ mass < 40.8

21 ≤ age < 27

0 ≤ skin < 31

103 ≤ plas < 120

0 ≤ pres < 68

0 ≤ mass < 29.8

e
v
i
t
i
s
o
P

e
v
i
t
a
g
e
N

Figure 4: Model Insight: feature importance.

Table 2: Model Insight: decision logic.

Case study. Consider the diabetes dataset [32]. The eight features are the number of

times pregnant (preg), plasma glucose concentration (plas), diastolic blood pressure

(pres), 2-hour serum insulin (insu), triceps skinfold thickness (skin), body mass index

(mass), diabetes pedigree function (pedi) and age. We build a forest of 100 trees with

the default settings of Silas and perform the Model Insight analysis on the best model

in 10-fold cross-validation. Figure 4 shows the feature importance score of the model.

The values are normalised into percentages, thus, we can read the ﬁgure as “the feature

age contributes 26.55% of the decision making of the model”. Table 2 gives the general

decision logic of the same model. The pedi and insu features are less important and we

do not show them in Table 2. The decision logic is divided into the constraints that lead

to positive diabetes and those that lead to negative diabetes. Medical practitioners can

cross-reference the pie chart and the table to evaluate whether the logic of the model

is consistent with their knowledge. Disclaimer: the diabetes dataset only contains 768

instances and their characteristics may not be representative for a larger population.

17

4.5. Prediction Insight

The prediction insight aims at providing users with the decision logic correspond-

ing to individual predictions. This aspect is often an essential element in critical or

regulated predictive applications.

Any decision tree, and by extension any ensemble tree model, can be seen as a

simple decision rules system composed of rules of the form: if condition then pre-

diction.

Consider an instance x ∈ X and the decision tree t, the condition of the decision

rule associated with the prediction t(x) is the branch formula that leads to the predic-

tion t(x). Likewise, consider the ensemble tree ET , the condition of the decision rule

associated with the prediction Et (x) is the conjunction of all the branch formula that

lead to the predictions t1(x), ...,tm(x).

Similar to model insights, prediction insights can be mixed with feature impor-

tance scores of individual predictions obtained from feature attribution methods such

as SHAP [17] as illustrated by the following case study.

Figure 5: Prediction Insight examples.

Case study. Figure 5 illustrates a typical prediction insight’s output on an instance

from the diabetes dataset. The model predicts that there is 62.96% chance that the

patient has diabetes. The ﬁgure shows how each feature contributes to the prediction

and the range at which it does so.

5. Performance Results and Analysis

This section provides experimental results on the predictive, time and memory per-

formances of Silas. It also describes relevant implementation details and lesson learned

18

during the development.

There are multiple incentives to develop high-performance machine learning tools.

The beneﬁts include a smaller ecological footprint as well as cost savings and increase

in productivity. Reducing the hardware requirements of machine learning applications

also fosters security as the data no longer need to be transmitted through off-site cloud

infrastructures and can instead be locally hosted.

5.1. Comparative Results On Predictive Performance

We show empiric evidence that our implementation of ensemble trees is fast, efﬁ-

cient and has state-of-the-art predictive performance.

Dataset

#Instances

#Numeric

#Nominal Max Norminal

#Missing

Balance

Features

Features

Cardinality

Values

Kick [33]

72,983

Creditcard [34]

284,807

Flight [35]

Higgs [36]

10M

10.5M

14

30

2

28

18

0

6

0

1,063

N.A.

315

N.A.

149,271

7:1

0

0

0

577:1

4:1

1:1

Table 3: Details of datasets.

We compared Silas with H2O [11] and Ranger [12], which are industry leaders of

random forest implementations. The results reported in this paper were obtained on

a desktop machine with an Intel Core i7-7700 processor and 32 GB of memory. We

selected four datasets [33, 34, 35, 36], shown in Table 3, with the following criteria:

(1) They have at least 50,000 instances. (2) They are public datasets. (3) They are

binary classiﬁcation problems. (4) They are datasets with real-life applications. We

focus on these datasets in order to study how different parameters affect the predictive

performance for each dataset. The chosen datasets have a variety of characteristics in

terms of missing values, types of features, the balance of classes, etc., and should reﬂect

the tools’ abilities in different scenarios. Notably, we chose Kick and Flight because

they have a mixture of numeric features and nominal features, and the nominal feature

with the largest number of unique values, indicated by “Max Norminal Cardinality” in

Table 3, has hundreds of values.

19

Figure 6: Experimental results plotted by time(s) and area under the ROC curve (AUC).

For each dataset, we ran the tools with all combinations of the following settings:

Number of trees: 100, 200, 400, 800. Number of instances at leaves (leaf size): 1, 4,

16, 64, 128, 256. Max depth of trees: 64 or unlimited. The other parameters are set

to default [37, 38, 39]. The training time is limited to 2 hours. The results are shown

in Figure 6. Each point in the ﬁgure corresponds to a model with a certain number

of trees and leaf size. The vertical axis reports the ROC-AUC obtained using 10-fold

cross-validation (Kick and Creditcard) or on a test dataset (Flight and Higgs). The

horizontal axis reports the time (in seconds) of the computation including the training

phase as well as the time required to compute the ROC-AUC metric. For instance, the

20

six points for Silas in the Higgs sub-ﬁgure are models of 100 trees and leaf size 256 to

1 respectively (left to right). In the Flight-10M sub-ﬁgure, three “columns” of points

are observed for Silas. Those correspond to the models of 100 trees, 200 trees and 400

trees respectively (left to right).

Observations. Generally speaking, the points for Silas are more clustered than other

tools, which indicates that Silas’s results are less sensitive to hyperparameter settings.

For Kick, Silas and Ranger outperformed H2O in a much shorter time. For Creditcard,

Silas and H2O slightly outperformed Ranger, and Silas is much faster than the other

two. For Flight, Silas outperformed both H2O and Ranger and is the only tool that can

generate 200 and 400 trees within the time limit and without crashing. For Higgs, Silas

and H2O yielded similar results with 100 trees, however, Silas is faster. Ranger failed

to parse the dataset.

Synthesis. Overall, we observe that Silas trains models that are as good as H2O and

Ranger in a much shorter time. The predictive performance of Silas is very consistent

across different parameters and datasets and often better than comparable tools. We

note, however, that H2O slightly outperformed Silas under some parameters on Cred-

itcard and Higgs. This can be explained by the fact that the search resolution over

numerical features is ﬁxed in Silas whereas the resolution is adaptive in H2O. In future

work, we plan on improving the discretisation of numerical features in order to improve

predictive performance.

5.2. Implementation

We list some of the major implementation and design choices which we believe

contribute to the excellent time and memory efﬁciency of Silas.

Efﬁcient software is built on a good foundation. We have studied various program-

ming languages and styles and settled with the following three key points at the core of

Silas code base.

Programming language. The programming language itself must be efﬁcient and low-

level enough to give us the liberty to perform cache and instruction level optimisations.

21

According to recent benchmarks for comparing the speed of programming languages,

e.g., [40], Go, C, C++ and Crystal are among the fastest languages. We chose C++

because it also provides enough high-level programming features, such as template

metaprogramming [41], which are useful when realising the other key points.

Programming paradigm. We adopt a programming paradigm largely inspired by the

functional programming paradigm. More speciﬁcally, we predominantly employ pure

functions due to the following beneﬁcial properties [42]: reusability, testability, thread

safety and the absence of side effects. To do so, we developed a C++ framework that

enables us to statically compose pure functions in a straight forward manner. This

framework notably relies on a static dispatch technique called Curiously Recurring

Template Pattern (CRTP) [41] to offer efﬁcient means of sequential and parallel com-

positions. In a multi-core execution environment, this organisational framework incurs

no run-time overhead.

Programming design. Our codebase follows the data-oriented design approach. The

emphasis is placed on the data being created, manipulated and stored. The main ad-

vantage of data-oriented programs is the constraint on the locality of reference which

enables safe and effective parallelism (e.g. vectorisation of code). Another beneﬁt of

data-oriented programming is the efﬁcient use of memory caching, an essential aspect

of modern hardware.

Like many high-performance tools, the development of Silas required multiple at-

tempts. There were two major recodings. We ﬁrst coded Silas as a classic C++ object-

oriented application. This version, referred to as the legacy version, served as the

baseline of the subsequent implementation. Due to the difﬁculty we had in safely par-

allelising the core algorithms of Silas (e.g. training, computation of predictive metrics)

we decided to adopt a pure-function based framework inspired by functional program-

ming aspects. This second implementation, referred to as the 1st revision, was more

stable and efﬁcient than the legacy version. It also forced us to reconsider the data

structures in use. For instance, we switched to using a column-based database instead

of the more traditional row-based database. Finally, in order to further optimise our

code base (e.g. optimise caching, increase information density), we made the design

choice to adopt strongly data-oriented coding guidelines. This lead to a new imple-

mentation of Silas, referred to as the 2nd revision.

22

1M ﬂights Dataset

Metrics

Time (s)

Legacy

1st Rev

2nd Rev H2O

Ranger

Memory Usage (GB)

3

77.5

23.1

0.6

16.8

0.6

61.2

62.9

5.1

3.1

ROC-AUC

0.757

0.753

0.752

0.744

0.722

10M ﬂights Dataset

Metrics

Time (s)

Legacy

1st Rev

2nd Rev H2O

Ranger

804.4

281.1

195.7

1216

1195.9

Memory Usage (GB)

25.9

4.6

4.3

12.6

30

ROC-AUC

0.802

0.796

0.793

0.772

0.741

Table 4: Computational performance for the Flight dataset. We report the total time used for loading data,

training, testing and computing the predictive performance. The Memory Usage row shows the peak memory

usage during the computation.

To illustrate the evolution of Silas throughout its recoding phases, Table 4 shows

results obtained over the Flight dataset [9] using the legacy, 1st revision and 2nd revi-

sion of Silas as well as ranger and H2O for reference. We can observe that the time

efﬁciency of Silas signiﬁcantly improved with each revision. We also note that 1st

revision of Silas signiﬁcantly improved its memory efﬁciency. More speciﬁcally, the

2nd revision of Silas is 3.6x faster than H2O on the 1M dataset and is 6.1x faster than

Ranger on the 10M dataset. In terms of memory usage, Ranger uses 5x more memory

than the 2nd revision of Silas on the 1M dataset, and H2O uses 3x more memory than

Rev 2 on the 10M dataset.

6. Conclusion And Future Work

This work proposed a new classiﬁcation tool called Silas, which has state-of-the-art

predictive performance and often runs faster and uses less memory than other imple-

23

mentations. Moreover, Silas provides features for a more dependable machine learn-

ing service. These include: Model Audit, which formally veriﬁes user speciﬁcations

against predictive models; Enforcement Learning, which generates predictive models

that are guaranteed to satisfy user speciﬁcations; Model Insight, which provides ex-

planations on how the model works; and a special case of the above called Prediction

Insight, which explains how a particular prediction is made.

Although not discussed in this paper, Silas does support multi-class classiﬁcation.

However, we have not investigated how veriﬁcation and explanation analysis can be

done for multiple classes. Similarly, we have not studied how to make regression tasks

more white-box. These topics will be our focus of future research and development

directions.

References

[1] C. A. Gomez-Uribe, N. Hunt, The netﬂix recommender system: Algorithms,

business value, and innovation, ACM Trans. Manage. Inf. Syst. 6 (4) (2015) 13:1–

13:19 (Dec. 2015). doi:10.1145/2843948.

URL http://doi.acm.org/10.1145/2843948

[2] L. Eliot, M. Eliot, Autonomous Vehicle Driverless Self-Driving Cars and Artiﬁ-

cial Intelligence: Practical Advances in AI and Machine Learning, 1st Edition,

LBE Press Publishing, 2017 (2017).

[3] R. E. Turkson, E. Y. Baagyere, G. E. Wenya, A machine learning approach for

predicting bank credit worthiness, in: 2016 Third International Conference on

Artiﬁcial Intelligence and Pattern Recognition (AIPR), 2016, pp. 1–7 (Sep. 2016).

doi:10.1109/ICAIPR.2016.7585216.

[4] I. Kononenko, Machine learning for medical diagnosis: History, state of the art

and perspective, Artif. Intell. Med. 23 (1) (2001) 89–109 (Aug. 2001). doi:

10.1016/S0933-3657(01)00077-X.

URL http://dx.doi.org/10.1016/S0933-3657(01)00077-X

24

[5] C. Cumby, A. Fano, R. Ghani, M. Krema, Predicting customer shopping lists

from point-of-sale purchase data, in: Proceedings of the tenth ACM SIGKDD

international conference on Knowledge discovery and data mining, ACM, 2004,

pp. 402–409 (2004).

[6] N.

Y.

Post,

Toddler

asks

amazons

alexa

to

play

song

but

gets

porn

instead,

https://nypost.com/2016/12/30/

toddler-asks-amazons-alexa-to-play-song-but-gets-porn-instead/

(2016).

[7] T. Guardian, Self-driving uber kills arizona woman in ﬁrst fatal crash involv-

ing pedestrian, https://www.theguardian.com/technology/2018/mar/

19/uber-self-driving-car-kills-woman-arizona-tempe (2018).

[8] M. P. Bonacina, Automated reasoning for explainable artiﬁcial intelligence, in:

ARCADE Workshop (in association with CADE-26), Gothenburg, Sweden, 2017

(2017).

[9] S. Pafka, A minimal benchmark for scalability, speed and accuracy of commonly

used open source implementations of the top machine learning algorithms for

binary classiﬁcation, https://github.com/szilard/benchm-ml (2018).

[10] T. Chen, C. Guestrin, Xgboost: A scalable tree boosting system, in: Proceedings

of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery

and Data Mining, KDD ’16, ACM, New York, NY, USA, 2016, pp. 785–794

(2016). doi:10.1145/2939672.2939785.

URL http://doi.acm.org/10.1145/2939672.2939785

[11] H2O, H2o, https://github.com/h2oai/h2o-3 (2019).

[12] M. Wright, A. Ziegler, ranger: A fast implementation of random forests for high

dimensional data in c++ and r, Journal of Statistical Software 77 (08 2015). doi:

10.18637/jss.v077.i01.

[13] H. Bride, J. Dong, J. S. Dong, Z. H´ou, Towards dependable and explainable ma-

chine learning using automated reasoning, in: Formal Methods and Software

25

Engineering - 20th International Conference on Formal Engineering Methods,

ICFEM 2018, Gold Coast, QLD, Australia, November 12-16, 2018, Proceedings,

2018, pp. 412–416 (2018).

[14] D.

Intelligence, Silas, https://www.depintel.com/silas_about.html

(2019).

[15] M. T. Ribeiro, S. Singh, C. Guestrin, ”why should I trust you?”: Explaining the

predictions of any classiﬁer, in: Proceedings of the 22nd ACM SIGKDD Inter-

national Conference on Knowledge Discovery and Data Mining, San Francisco,

CA, USA, August 13-17, 2016, 2016, pp. 1135–1144 (2016).

[16] S. Hara, K. Hayashi, Making tree ensembles interpretable (06 2016).

[17] S. M. Lundberg, S.-I. Lee, A uniﬁed approach to interpreting model predictions,

in: I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan,

R. Garnett (Eds.), Advances in Neural Information Processing Systems 30, Cur-

ran Associates, Inc., 2017, pp. 4765–4774 (2017).

[18] R. Ehlers, Formal veriﬁcation of piece-wise linear feed-forward neural networks,

in: D. D’Souza, K. Narayan Kumar (Eds.), Automated Technology for Veriﬁca-

tion and Analysis, Springer International Publishing, Cham, 2017 (2017).

[19] R. Gor´e, K. Olesen, J. Thomson, Implementing tableau calculi using bdds: Bd-

dtab system description, in: Automated Reasoning - 7th International Joint Con-

ference, IJCAR 2014, Held as Part of the Vienna Summer of Logic, VSL 2014,

Vienna, Austria, July 19-22, 2014. Proceedings, 2014, pp. 337–343 (2014).

[20] A. Cimatti, E. Clarke, E. Giunchiglia, F. Giunchiglia, M. Pistore, M. Roveri,

R. Sebastiani, A. Tacchella, NuSMV Version 2: An OpenSource Tool for Sym-

bolic Model Checking, in: Proc. International Conference on Computer-Aided

Veriﬁcation (CAV 2002), Vol. 2404 of LNCS, Springer, Copenhagen, Denmark,

2002 (July 2002).

[21] R. Caruana, Y. Lou, J. Gehrke, P. Koch, M. Sturm, N. Elhadad, Intelligible models

for healthcare: Predicting pneumonia risk and hospital 30-day readmission, in:

26

Proceedings of the 21th ACM SIGKDD International Conference on Knowledge

Discovery and Data Mining, KDD ’15, ACM, New York, NY, USA, 2015, pp.

1721–1730 (2015). doi:10.1145/2783258.2788613.

URL http://doi.acm.org/10.1145/2783258.2788613

[22] J. Trnblom, S. Nadjm-Tehrani, Formal Veriﬁcation of Random Forests in Safety-

Critical Applications: 6th International Workshop, FTSCS 2018, Gold Coast,

Australia, November 16, 2018, Revised Selected Papers, 2019, pp. 55–71 (01

2019).

[23] J. R. Quinlan, C4.5: Programs for Machine Learning, Morgan Kaufmann Pub-

lishers Inc., San Francisco, CA, USA, 1993 (1993).

[24] C. E. Shannon, A mathematical theory of communication, Bell system technical

journal 27 (3) (1948) 379–423 (1948).

[25] Z. Cui, W. Chen, Y. He, Y. Chen, Optimal action extraction for random forests

and boosted trees, in: Proceedings of the 21th ACM SIGKDD International Con-

ference on Knowledge Discovery and Data Mining, KDD ’15, ACM, New York,

NY, USA, 2015, pp. 179–188 (2015). doi:10.1145/2783258.2783281.

URL http://doi.acm.org/10.1145/2783258.2783281

[26] L. Breiman, Random forests, Machine Learning 45 (1) (2001) 5–32 (Oct 2001).

[27] Y. Freund, R. E Schapire, A short introduction to boosting, Journal of Japanese

Society for Artiﬁcial Intelligence 14 (1999) 771–780 (10 1999).

[28] G. Louppe, Understanding random forests: From theory to practice, arXiv

preprint arXiv:1407.7502 (2014).

[29] L. De Moura, N. Bjørner, Satisﬁability modulo theories: introduction and appli-

cations, Communications of the ACM 54 (9) (2011) 69–77 (2011).

[30] L. de Moura, N. Bjørner, Z3: An efﬁcient smt solver, in: C. R. Ramakrishnan,

J. Rehof (Eds.), Tools and Algorithms for the Construction and Analysis of Sys-

tems, Springer Berlin Heidelberg, Berlin, Heidelberg, 2008, pp. 337–340 (2008).

27

[31] A. Altmann, L. Toloi, O. Sander, T. Lengauer, Permutation importance: a cor-

rected feature importance measure, Bioinformatics 26 (10) (2010) 1340–1347

(04 2010). doi:10.1093/bioinformatics/btq134.

URL https://doi.org/10.1093/bioinformatics/btq134

[32] D. Dua, C. Graff, UCI machine learning repository (2017).

URL http://archive.ics.uci.edu/ml

[33] OpenML, Kick dataset, https://www.openml.org/d/41162 (2019).

[34] OpenML, Creditcard dataset, https://www.openml.org/d/1597 (2019).

[35] S. Pafka, Flight dataset, https://github.com/szilard/benchm-ml/tree/

master/z-other-tools (2019).

[36] P. Baldi, P. Sadowski, D. Whiteson, Searching for exotic particles in high-energy

physics with deep learning, Nature communications 5 (2014) 4308 (07 2014).

[37] D.

I. P. Ltd,

Silas

edu

documentation,

https://www.depintel.

com/documentation/_build/html/usage/learning/prep.html#

parameters-in-settings (2019).

[38] H2O.ai, H2o dcoumentation:

Build a random forest model, http:

//docs.h2o.ai/h2o/latest-stable/h2o-r/docs/reference/h2o.

randomForest.html (2019).

[39] M. Wright, R dcoumentation: Ranger, https://www.rdocumentation.org/

packages/ranger/versions/0.11.2/topics/ranger (2019).

[40] N. Heer, Speed comparison of programming languages, https://github.com/

niklas-heer/speed-comparison (2019).

[41] D. Abrahams, A. Gurtovoy, C++ Template Metaprogramming: Concepts, Tools,

and Techniques from Boost and Beyond (C++ in Depth Series), Addison-Wesley

Professional, 2004 (2004).

[42] J. Carmack,

In-depth:

Functional

programming

in

c++,

https:

//www.gamasutra.com/view/news/169296/Indepth_Functional_

programming_in_C.php (2012).

28

