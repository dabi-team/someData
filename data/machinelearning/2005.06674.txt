On the Convergence of Overlapping Schwarz
Decomposition for Nonlinear Optimal Control

Sen Na, Sungho Shin, Mihai Anitescu, and Victor M. Zavala

1

2
2
0
2

r
a

M
5
1

]

C
O
.
h
t
a
m

[

5
v
4
7
6
6
0
.
5
0
0
2
:
v
i
X
r
a

Abstract—We study the convergence properties of an over-
lapping Schwarz decomposition algorithm for solving nonlin-
ear optimal control problems (OCPs). The algorithm decom-
poses the time domain into a set of overlapping subdomains,
and solves all subproblems deﬁned over subdomains in parallel.
The convergence is attained by updating primal-dual informa-
tion at the boundaries of overlapping subdomains. We show
that the algorithm exhibits local linear convergence, and that
the convergence rate improves exponentially with the overlap
size. We also establish global convergence results for a general
quadratic programming, which enables the application of the
Schwarz scheme inside second-order optimization algorithms
(e.g., sequential quadratic programming). The theoretical foun-
dation of our convergence analysis is a sensitivity result of
nonlinear OCPs, which we call “exponential decay of sensitivity”
(EDS). Intuitively, EDS states that the impact of perturbations
at domain boundaries (i.e.
initial and terminal time) on the
solution decays exponentially as one moves into the domain.
Here, we expand a previous analysis available in the literature by
showing that EDS holds for both primal and dual solutions of
nonlinear OCPs, under uniform second-order sufﬁcient condition,
controllability condition, and boundedness condition. We conduct
experiments with a quadrotor motion planning problem and a
PDE control problem to validate our theory; and show that the
approach is signiﬁcantly more efﬁcient than ADMM and as
efﬁcient as the centralized solver Ipopt.

Index Terms—Optimal Control; Nonlinear Programming; De-

composition Methods; Overlapping; Parallel algorithms

I. INTRODUCTION

We study the nonlinear optimal control problem (OCP):

min
{xk},{uk}

N −1
(cid:88)

k=0

gk(xk, uk) + gN (xN ),

s.t. xk+1 = fk(xk, uk)

x0 = ¯x0

(λk),
(λ−1),

(1a)

(1b)

(1c)

where xk ∈ Rnx are the state variables; uk ∈ Rnu are the
control variables; λk ∈ Rnx are the dual variables associated
with the dynamics (1b); λ−1 ∈ Rnx are the dual variables

S. Na and S. Shin equally contributed to this work.
S. Na is with the Department of Statistics, University of Chicago, 5747
South Ellis Avenue, Chicago, IL 60637, USA (e-mail: senna@uchicago.edu)
S. Shin is with the Department of Chemical and Biological Engineer-
ing, University of Wisconsin-Madison, Madison, WI 53706 USA (e-mail:
sungho.shin@wisc.edu)

M. Anitescu is with the Mathematics and Computer Science Division,
Argonne National Laboratory, Lemont, IL 60439, USA, and also with the
Department of Statistics, University of Chicago, Chicago, IL 60637, USA
(e-mail: anitescu@mcs.anl.gov)

V. M. Zavala is with the Department of Chemical and Biological
Engineering, University of Wisconsin-Madison, Madison, WI 53706 USA and
also with the Mathematics and Computer Science Division, Argonne National
Laboratory, Lemont, IL 60439, USA (e-mail: victor.zavala@wisc.edu)

associated with the initial conditions (1c); gk : Rnx ×Rnu → R
(gN : Rnx → R) are the cost functions; fk : Rnx ×Rnu → Rnx
are the dynamical constraint functions; N is the horizon length;
and ¯x0 ∈ Rnx is the given initial state. We assume that fk, gk
are twice continuously differentiable, nonlinear, and possibly
nonconvex; as such, (1) is a nonconvex nonlinear program
(NLP). The problem of interest has been studied extensively in
the context of model predictive control [1] with applications in
chemical process control [2], energy systems [3], production
planning [4], autonomous vehicles [5], power systems [6],
supply chains [7], and neural networks [8].

In this work, we are interested in solving OCPs with a large
number of stages N . Such problems arise in the settings with
long horizons, ﬁne time discretization resolutions, and multiple
timescales [9]. Temporal decomposition provides an approach
to deal with such problems. In this approach, one partitions the
time domain [0, N ] into a set of subdomains {[mi, mi+1]}T −1
i=0 .
One then solves more tractable subproblems over subdomains
in parallel, and their solution trajectories are concatenated by
using a coordination mechanism. Traditional coordination mech-
anisms include Lagrangian dual decomposition [10], alternating
direction method of multipliers (ADMM) [11], dual dynamic
programming [12], and Jacobi/Gauss-Seidel methods [13].
These decomposition approaches offer ﬂexibility in that they
can be implemented in different types of computing hardware
that might have limitations on memory and processor speeds.
This is critical because the performance of centralized nonlinear
optimization solvers (e.g., Ipopt) degrades rapidly in resource-
constrained computing environments [14]. Unfortunately, while
Lagrangian dual decomposition, ADMM, and dual dynamic
programming are guaranteed to converge under a variety of
OCP settings, they often exhibit slow convergence [15]. This
highlights the existence of a fundamental trade-off between
the ﬂexibility offered by distributed solvers and the efﬁciency
offered by centralized solvers.

Direct decomposition approaches have also been studied for
convex OCPs with long horizons. Speciﬁcally, such approaches
have been used to decompose linear algebra systems inside
interior-point solvers [16]–[23]. They also offer ﬂexibility to
enable limited-resource-hardware implementations and, since
the methods are direct (as opposed to iterative), they do not
suffer from convergence issues. However, direct approaches rely
on reduction procedures (they are block elimination techniques),
and such procedures suffer from scalability issues. For instance,
parallel cyclic reduction, Schur, and Riccati decompositions
do not scale well with the number of states and/or control
variables. Moreover, we also highlight that iterative approaches
such as ADMM and Lagrangian dual decomposition often offer

 
 
 
 
 
 
more ﬂexibility than direct decomposition methods in that the
amount of communication needed is limited (thus preserving
data privacy).

i , n2

A recent study [24] has empirically tested the effectiveness
of a different decomposition paradigm for OCPs. Speciﬁcally,
the authors performed numerical tests with a temporal decom-
position scheme with overlaps (see Fig. 1). Here, overlapping
i ]}T −1
subdomains {[n1
i=0 are constructed by expanding the
non-overlapping subdomains {[mi, mi+1]}T −1
i=0 by τ stages on
the left and right boundaries. Subproblems on the expanded
subdomains are solved in parallel, and the resulting solution
trajectories are concatenated by discarding the pieces of the
trajectory in the overlapping regions. The authors observed that,
as the size of the overlap increases, the approximation error
of the concatenated solution trajectory drops rapidly. However,
no quantitative analysis was provided. Subsequent work [25]
provided the ﬁrst rigorous error analysis of such overlapping de-
composition scheme. The authors proved that, for strongly con-
vex OCPs with linear dynamics and positive-deﬁnite quadratic
stage costs that satisfy uniform controllability and boundedness
conditions, the error of the concatenated trajectory decreases
exponentially in τ . This result requires a sensitivity property
for convex OCPs that we call “exponential decay of sensitivity”
the impact of parametric
(EDS). This property says that
perturbations on the primal solution trajectory {(x(cid:63)
k)}k
decays exponentially as one moves away from the perturbation
stage. Unfortunately, the analysis in [25] does not apply for the
general nonlinear OCP (1) and thus has limited applicability.
Furthermore, we emphasize that the sensitivity on the dual
solution (even for convex case) is not resolved in that work,
and that the decomposition scheme analyzed there is only an
approximation scheme (not a convergent algorithm).

k, u(cid:63)

Recent work [26] has applied the overlapping decomposition
scheme for solving time-invariant nonlinear OCPs. This relies
on the observation that such a decomposition scheme can be
interpreted as a single iteration of an overlapping Schwarz
decomposition scheme. In particular, for solving nonlinear
OCPs, [26] partitions the time domain as in [24], [25],
but utilizes both primal and dual information from adjacent
subdomains to perform an iterative coordination to achieve the
convergence. The authors of [26] conjectured that the effect of
perturbations at two ends (that is initial and terminal stages) on
the primal and dual trajectory {(x(cid:63)
k)}k (not only for the
primal trajectory as in [25]) decays asymptotically. Under this
conjecture, they proved that the overlapping Schwarz scheme
converges locally. The authors also provided empirical evidence
with a nonlinear OCP that, the perturbation effect decays not
only asymptotically, but indeed exponentially. That is, EDS
empirically holds for nonlinear OCPs just like for convex
quadratic OCPs as in [25], although a theoretical justiﬁcation
for such behavior was not provided.

k, λ(cid:63)

k, u(cid:63)

The work in [27] investigated primal sensitivity for nonlinear
OCPs. The authors showed that, under uniform second-order
sufﬁcient condition, controllability condition, and boundedness
condition, EDS holds for primal solution of nonlinear OCPs.
This result generalizes the convex setup in [25] to a general
nonconvex nonlinear setup under the same conditions. The
generalization relies on a convexiﬁcation technique, which

2

convexiﬁes nonconvex problems to convex problems without
altering primal solutions (cf. Algorithm 1). However, the result
in [27] is not sufﬁcient for studying the convergence of Schwarz
scheme in [26] because (i) a terminal perturbation is missing
and (ii) the dual sensitivity is not formally analyzed.

This paper extends the related literature [24]–[27] in the
following aspects. (i) We expand the results in [27] by enabling
a terminal perturbation, and more importantly, complement [27]
by showing that EDS also holds for the dual solution of nonlin-
ear OCPs. We emphasize that obtaining dual sensitivity from
primal sensitivity is not straightforward; and we emphasize that
the former has not been studied even in the context of convex
OCPs. To address this knowledge gap, we delve deeper into the
convexiﬁcation technique in [27]; and show that, although the
dual solution is altered by convexiﬁcation (not preserved like
primal solution), it is shifted only by an afﬁne transformation
of the primal solution (cf. Theorem 3). With this relation, we
further provide a stagewise closed form of the dual solution (cf.
Theorem 4) and establish dual sensitivity (cf. Theorem 5). (ii)
By sensitivity analysis, we enhance the existing overlapping
decomposition and Schwarz schemes [24]–[26] by providing a
convergence analysis for time-varying nonlinear OCPs, which
cover a much wider range of applications than convex OCPs in
[24], [25] and time-invariant OCPs in [26]. Furthermore, our
primal-dual sensitivity analysis validates the conjecture in [26].
(iii) We prove that the overlapping Schwarz scheme enjoys
linear convergence locally, provided the overlap size τ is
sufﬁciently large. We also show that the linear rate is given
by Cρτ , where C > 0, ρ ∈ (0, 1) are constants independent
of horizon length N . In other words, the linear rate improves
exponentially with the overlap size. As a special case, we also
show that the Schwarz scheme exhibits global convergence for
a linear-quadratic OCP setting (but potentially with nonconvex
objective). This result is of relevance, as it suggests that the
Schwarz method can be used to solve quadratic programs and
linear algebra systems inside second-order algorithms such as
sequential quadratic programming and interior-point methods.
Such a special case is still more general than [25] and requires
a fundamentally different proof technique. Our theory explains
favorable performance noticed in recent computational studies
that use this approach [28].

It is worth mentioning that a recent work [29] made use of
the established primal-dual sensitivity in this paper to study a
real-time online model predictive control algorithm. Although
this paper also solves nonlinear OCPs, there are signiﬁcant
differences in problem setup, techniques, and results with
[29]. First, [29] solved (1) in an online fashion, where a
single Newton step is performed to solve the subproblem
inexactly, and then the system shifts to the next stage with
a new subproblem to be targeted. Online algorithms are a
special class of inexact methods for nonlinear predictive control
problems, mostly used for systems that require a fast reaction
to disturbances (for example, autonomous vehicles) [30]–[33].
In contrast, our approach solves a long-horizon problem (1) in
an ofﬂine fashion with a parallel environment, where problems
do not shift but are solved to the optimality. Second, [29] relied
on the sensitivity (of linear-quadratic OCPs) to show a decay
structure of KKT matrix inverse, based on which [29] explored

3

|

|

|

|

|

|

|

m0 = 0

n1
1

x((cid:96))
n1
1

|

|

|

τ

|

|
m1

|

n1

0 = 0

|

|

|

|

|

|

|

|

|

|

Subproblem 0

Full Problem

|

|

|

|

Subproblem 1

|

|

|

|

|

|

w((cid:96))
n2
0

|

n2
0

x((cid:96))
n1
2

n1
2

|

|

|

|

|

|

τ

|

|

|

τ

|
m2

|

|

τ

|

|

|

|

|

|

|

|

|

|

m3 = N

n2
1

w((cid:96))
n2
1

|

|

|

|

|

|

|

|

|

|

n2

2 = N

Subproblem 2

Fig. 1. Overlapping Schwarz decomposition scheme for OCPs. Here, mi denotes non-overlapping subdomains boundaries; n1
i denote left and right
overlapping subdomains boundaries; x((cid:96))
k ) is the primal-dual iterate at stage k in
k
the (cid:96)-th iteration. Each subproblem depends on the initial state iterate coming from the previous subproblem, and the terminal primal-dual iterate coming from
the next subproblem.

is the state iterate at stage k in the (cid:96)-th iteration; w((cid:96))

k = (x((cid:96))

k ; u((cid:96))

k ; λ((cid:96))

i , n2

Newton’s method and showed a linear-quadratic error recursion.
In contrast, we rely on the sensitivity (of nonlinear OCPs)
to have an increasingly more accurate boundary primal-dual
iterates for subproblems and, hence, the subproblem solutions
are increasingly closer to the truncated full-horizon solution.
Third, [29] only showed the real-time iterates stably track the
solution (i.e. stay in a neighborhood), while we show the ofﬂine
iterates converge to the solution linearly with a quantitative
relation between the convergence rate and the overlap size.

Our work focuses on the convergence properties of overlap-
ping Schwarz scheme, which is a new and different paradigm
for decomposing OCPs compared to traditional approaches [10]–
[13]. This approach is interesting in that it spans a spectrum
of algorithms that go from a fully centralized/sequential
communication pattern (the overlap is the entire horizon) to
a no-interaction communication pattern (no overlap). This
iterative approach thus provides ﬂexibility to enable different
hardware implementations. The paper is motivated by the great
success observed in practice [24]–[26], [28], [34]. Prior to this
work, the convergence of overlapping decomposition schemes
has only been explored for restrictive linear-quadratic convex
cases. Here, we show that the Schwarz decomposition exhibits
linear convergence for general nonconvex OCPs (cf. Theorem
8). This provides an advantage over the widely-used ADMM,
whose convergence is established mostly for restrictive setups
that do not apply for (1). For instance, the standard result
only deals with convex problems [11], and the nonconvex
results in [35, Equation (2.2)] and [36, Equation (1)] do not
allow nonlinear dynamical constraints as in (1b). Furthermore,
we numerically demonstrate that overlapping Schwarz has
much faster convergence than ADMM and may be as efﬁcient
as Ipopt (a centralized solver). This observation is important
because Ipopt is highly efﬁcient but does not offer ﬂexibility in
hardware implementations. Establishing convergence theory for
Schwarz scheme is also meaningful from a control practitioner’s
stand-point, as it explains the performance observed in many
recent computational studies. Moreover, the established theory
provides insights on how the scheme will behave when tuning

the overlap size τ . Our primal-dual EDS result also provides a
foundation for analyzing the behavior of a variety of algorithms
and approximations for predictive control [37]–[39].

The remainder of the paper is organized as follows. In
Section II we establish primal-dual sensitivity results for (1).
In Section III we describe the overlapping Schwarz scheme
and its convergence analysis. Numerical results are shown in
Section IV and conclusions are presented in Section V.

II. PRIMAL-DUAL EXPONENTIAL DECAY OF SENSITIVITY

In this section, we enhance the analysis in [27] and establish a
primal-dual sensitivity result for nonlinear OCPs that we call
exponential decay of sensitivity (EDS). We use the following
notation: for n, m ∈ Z>0, we let [n, m], [n, m), (n, m], (n, m)
be the corresponding integer sets; also, [n] = [0, n]. Boldface
symbols denote column vectors. For a set of vectors {ai}n
i=m,
am:n = (am; . . . ; an) represents a long vector that stacks them
together. For scalars a, b, a ∨ b = max(a, b); a ∧ b = min(a, b).
i=m, (cid:81)n
For a set of matrices {Ai}n
i=m Ai = AnAn−1 · · · Am
if m ≤ n and I otherwise. Without speciﬁcation, (cid:107) · (cid:107) denotes
either (cid:96)2 norm for a vector or spectral norm for a matrix. For
a function f : Rn → Rm, ∇f ∈ Rn×m is its Jacobian.

A. Sensitivity Analysis and Primal EDS Results

We begin by analyzing the sensitivity of the primal solution.
Most of the results in this subsection are presented in [27], but
we revisit them for completeness and to lay the groundwork
for the new dual sensitivity in Section II-B. We rewrite (1)
by explicitly expressing the dependence on external data
(parameters) as

N −1
(cid:88)

gk(xk, uk; dk) + gN (xN ; dN ),

min
{xk}
{uk}
s.t. xk+1 = fk(xk, uk; dk), k ∈ [N − 1], (λk)

k=0

x0 = ¯x0, (λ−1).

(2a)

(2b)

(2c)

Here dk ∈ Rnd and d−1 = ¯x0 are the external problem data.
In what follows, we let zk = (xk; uk), wk = (zk; λk) for
k ∈ [N −1], and wN = zN = xN and w−1 = λ−1. x = x0:N
(similar for u, d, λ, z, w) is the full vector with variables being
ordered by stages. We also denote z = (x, u), w = (x, u, λ)
for simplicity. We let nx (similar for nu, nd, nλ, nz, nw) be
the dimension of x.

The Lagrange function of (2) is

N −1
(cid:88)

L(w; d) =

(cid:122)
gk(zk; dk) + λT

Lk(zk,λk−1:k;dk)
(cid:125)(cid:124)
k−1xk − λT

(cid:123)
k fk(zk; dk)

k=0
+ gN (zN ; dN ) + λT

−λT

−1d−1.

N −1xN
(cid:125)

(cid:124)

(cid:123)(cid:122)
LN (zN ,λN −1;dN )
Suppose that w(cid:63)(d) = (x(cid:63)(d), u(cid:63)(d), λ(cid:63)(d)) is a local mini-
mizer of (2) with unperturbed data d. Sensitivity analysis char-
acterizes how the solution trajectory w(cid:63)(d) varies with respect
to perturbations on d. In particular, we let l ∈ Rnd be the
perturbation direction of d and let the corresponding parametric
perturbation path be:

d(h, l) = d + hl + o(h).

(3)

Then we deﬁne directional derivatives of solution trajectories as

p(cid:63)

k = lim
h(cid:38)0

q(cid:63)
k = lim
h(cid:38)0

ζ(cid:63)
k = lim
h(cid:38)0

u(cid:63)

k(d(h, l)) − x(cid:63)
x(cid:63)
h
k(d(h, l)) − u(cid:63)
h
k(d(h, l)) − λ(cid:63)
λ(cid:63)
h

k(d)

k(d)

k(d)

, ∀k ∈ [N ],

, ∀k ∈ [N − 1],

(4a)

(4b)

, ∀k ∈ [−1, N − 1].

(4c)

Sensitivity analysis is equivalent to bounding the magnitude of
directional derivatives. We are particularly interested in bound-
ing (cid:107)p(cid:63)
k(cid:107) when only di is perturbed. That is we
enforce l = ei, where ei ∈ Rnd for i ∈ [−1, N ] is any unit
vector with support within stage i.

k(cid:107), (cid:107)ζ(cid:63)

k(cid:107), (cid:107)q(cid:63)

(cid:19)

=

Deﬁnition 1 (Reduced Hessian). For k ∈ [N −1], we let Ak =
∇T
fk(zk; dk),
xk
and Hessian matrices be

fk(zk; dk), Ck = ∇T
dk

fk(zk; dk), Bk = ∇T
uk

ukxk

xkuk

Lk
Lk
Lk

(cid:18) ∇2
xk
∇2
(cid:1) = (cid:0)∇2

Lk ∇2
Lk ∇2
uk
Lk ∇2

(cid:18)Qk ST
k
Hk(wk; dk) =
Sk Rk
Dk(wk; dk) = (cid:0)Dk1 Dk2
dkxk
together with HN (zN ; dN ) = ∇2
LN (zN , λN −1; dN ) and
DN (zN ; dN ) = ∇2
LN (zN , λN −1; dN ). The evalua-
tion point of Ak, Bk, Ck is suppressed for conciseness. We
also use QN and HN interchangeably. In addition, we let
H(w; d) = diag(H0, . . . , HN ) ∈ Rnz×nz and let Jacobian
matrix G(z; d) ∈ Rnx×nz (which has full row rank) be

dN xN

dkuk

(cid:1) ,

xN

(cid:19)

,






I

−A0 −B0

I

−A1 −B1 I

...

...

−AN −1 −BN −1 I




 .

4

We then introduce three assumptions to establish sensitivity:
uniform second-order sufﬁcient condition (SOSC), controlla-
bility, and boundedness. Recall that d is the unperturbed data
with w(cid:63)(d) being a local solution. We drop d hereinafter from
the notation and denote the solution as w(cid:63).

Assumption 1 (Uniform SOSC). At (w(cid:63); d), the reduced
Hessian of (2) satisﬁes ReH(w(cid:63); d) (cid:23) γH I for some uniform
constant γH > 0 independent of horizon N .

Assumption 1 requires the Lagrangian Hessian to be positive
deﬁnite in the null space of the linearized constraints (instead
of in the whole space). The uniformity in Assumption 1 means
the independence of γH from N .

Deﬁnition 2 (Controllability Matrix). For any k ∈ [N − 1]
and evolution length t ∈ [1, N − k], the controllability matrix
is given by

Ξk,t(zk:k+t−1; dk:k+t−1)

l=1 Ak+l)Bk

=(cid:0) Bk+t−1 Ak+t−1Bk+t−2 ... ((cid:81)t−1
i=k+1, {Bi}k+t−1

(cid:1) ∈ Rnx×tnu ,
evaluates at {(zi; di)}k+t−1

where {Ai}k+t−1
Assumption 2 (Uniform Controllability). At (z(cid:63); d), there
exist uniform constants γC, t > 0 independent of N such that
∀k ∈ [N − t], ∃1 ≤ tk ≤ t and such that

i=k

i=k

.

Ξk,tk ΞT
where Ξk,tk evaluates at (z(cid:63)

(cid:23) γCI,

k,tk
k:k+tk−1; dk:k+tk−1).

The controllability condition is imposed on the constraint
matrices. It captures the local geometry of the null space, which
follows the notion of uniform complete controllability, intro-
duced in [40, Deﬁnition 3.1] and used in sensitivity analysis
in [25, Deﬁnition 2.2].

Assumption 3 (Uniform Boundedness). At (w(cid:63); d), there ex-
ists a uniform constant Υupper independent of N such that
(cid:107)HN (cid:107) ≤ Υupper and ∀k ∈ [N − 1]:

(cid:107)Hk(cid:107) ∨ (cid:107)Dk(cid:107) ∨ (cid:107)Ak(cid:107) ∨ (cid:107)Bk(cid:107) ∨ (cid:107)Ck(cid:107) ≤ Υupper.

The following result shows that p(cid:63)

k in (4) are the
solution of a linear-quadratic OCP provided SOSC holds at w(cid:63).

k, q(cid:63)

k, ζ(cid:63)

Theorem 1 (Sensitivity of Problem (2)). Consider OCP (2),
and suppose d is perturbed along the path (3). If w(cid:63) satisﬁes
SOSC, the directional derivatives (p(cid:63)
k) deﬁned in (4)
exists and is the primal-dual solution of the problem:

k, ζ(cid:63)

k, q(cid:63)

N −1
(cid:88)

k=0

(cid:18) pk
qk
lk

min
{pk}
{qk}

(cid:19)T (cid:18) Qk ST

k DT
k1
Sk Rk DT
k2
Dk1 Dk2 0

(cid:19)

(cid:19)(cid:18) pk
qk
lk

(cid:19)T (cid:18)

(cid:18)

+

pN
lN

QN DT
N
DN 0

(cid:19)(cid:18)

(cid:19)
,

pN
lN

s.t. pk+1 = Akpk + Bkqk + Cklk, (ζk)

p0 = l−1, (ζ−1).

(5a)

(5b)

(5c)

Let Z(z; d) ∈ Rnz×nu (nu = nz − nx) be a full column rank
matrix whose columns are orthonormal and span the null space
of G(z; d). Then the reduced Hessian is deﬁned as

ReH(w; d) = Z T HZ.

Here, ζ−1:N −1 are dual variables associated to constraints.
All matrices are evaluated at (w(cid:63); d).

Proof. See [41, Theorem 5.61] for the proof. Observe from the
structure of G(z; d) in Deﬁnition 1 that the linear independence

constraint qualiﬁcation (LICQ) holds with any (z; d). Thus, the
results hold for any perturbation direction l.

Let ξk = (pk; qk; ζk) for k ∈ [N − 1], and ξ−1 = ζ−1 and
ξN = pN . Further, ξ = (p, q, ζ) = ξ−1:N (similar for p, q, ζ)
is the full vector with variables being ordered by stages. From
SOSC (cf. Assumption 1), LICQ, and [42, Lemma 16.1], we
know that ξ(cid:63) = (p(cid:63), q(cid:63), ζ(cid:63)) is unique global solution of (5).
However, the indeﬁniteness of the Hessians Hk in Problem (5)
brings difﬁculty in analyzing the solution of (5) obtained from
the Riccati recursion. Thus, [27] relied on the convexiﬁcation
procedure proposed in [43], which transfers (5) into another
linear-quadratic program whose new matrices ˜Hk are positive
deﬁnite. The procedure is displayed in Algorithm 1. One inputs
quadratic matrices {Hk, Dk, Ak, Bk, Ck} of Problem (5), and
then obtains new matrices { ˜Hk, ˜Dk}. The constraint matrices
{Ak, Bk, Ck} need not be transformed. As shown in [27],
with a proper set of β > 0, Algorithm 1 preserves the primal
solution. We will show later that Algorithm 1 shifts the dual
solution.

Theorem 2 (Primal EDS). Let Assumptions 1, 2, 3 hold at the
solution w(cid:63) of Problem (2). Then there exist constants Υ > 0,
ρ ∈ (0, 1), which only depend on constants in the assumptions
and hence are independent of horizon length N , such that
(a) if l = ei, ∀i ∈ [N ], then (cid:107)p(cid:63)

k(cid:107) ≤ Υρ|k−i| for

k(cid:107) ∨ (cid:107)q(cid:63)

k ∈ [N − 1] and (cid:107)p(cid:63)
(b) if l = e−1, then (cid:107)p(cid:63)

N (cid:107) ≤ ΥρN −i;
k(cid:107) ∨ (cid:107)q(cid:63)

and (cid:107)p(cid:63)

N (cid:107) ≤ ΥρN .

k(cid:107) ≤ Υρk for k ∈ [N − 1]

This is [27, Theorem 5.7]1 and indicates that the impact
k at stage k

of a perturbation on di on the primal solution z(cid:63)
decays exponentially fast as one moves away from stage i.

B. Dual EDS Results

We now present dual sensitivity for (2) based on convexiﬁca-
tion procedure in Algorithm 1. As shown in [27], because of the
positive deﬁniteness of ˜Hk, the convexiﬁed problem (obtained
by replacing {Hk, Dk} in (5) with outputs { ˜Hk, ˜Dk}) also has
a unique global solution. Thus, we need to understand how the
dual solutions are affected by convexiﬁcation. We will show
from the Karush-Kuhn-Tucker (KKT) conditions (i.e., the ﬁrst-
order necessary conditions) that Algorithm 1 shifts the dual
solution by an afﬁne transformation of the primal solution. In
what follows, we use LQP to denote Problem (5) deﬁned with
original matrices {Hk, Dk}, and CLQP to denote Problem
(5) deﬁned with convexiﬁed matrices { ˜Hk, ˜Dk}. Furthermore,
ξc(cid:63) = (pc(cid:63), qc(cid:63), ζc(cid:63)) denotes the (global) primal-dual solution
of CLQP. Recall that, by Theorem 1, (p(cid:63), q(cid:63), ζ(cid:63)) is the global
solution of LQP.

The following result establishes a relationship between the

solutions (p(cid:63), q(cid:63), ζ(cid:63)) and (pc(cid:63), qc(cid:63), ζc(cid:63)).

Theorem 3. Under Assumption 1, we execute Algorithm 1 with
β ∈ (0, γH ) for LQP. We then have that

Algorithm 1 Convexiﬁcation Procedure

5

k=0, {Ak, Bk, Ck}N −1

k=0 , β > 0;

1: Input: {Hk, Dk}N
2: ˜HN = ˜QN = βI;
3: ¯QN = QN − ˜QN ;
4: for k = N − 1, . . . , 0 do

(cid:18) ˆQk
˜Sk
˜Dk1 ˜Dk2

˜ST
˜DT
k
k1
˜Rk ˜DT
k2
∗

(cid:19)

=

(cid:18) Qk ST

k DT
k1
Sk Rk DT
k2
Dk1 Dk2 0

(cid:19)

(cid:19)

¯Qk+1( Ak Bk Ck )

+

(cid:18) AT
k
BT
k
CT
k

5:

6:

7:

˜R−1
k

˜Qk = ˜ST
˜Sk + βI
k
(cid:19)
(cid:18) ˜Qk
˜ST
˜Hk =
k
˜Rk
˜Sk
¯Qk = ˆQk − ˜Qk;

8:
9: end for
10: Output: { ˜Hk}N

k=0, { ˜Dk}N −1

k=0 , DN (= ˜DN ).

where ¯Q = diag( ¯Q0, . . . , ¯QN ) with { ¯Qk}N
Algorithm 1 recursively.

k=0 is deﬁned in

Proof. See Appendix V-A.

Using (6), we ﬁrst focus on CLQP and establish the expo-
nential decay result for ζc(cid:63). Then we use relation (6) to bound
ζ(cid:63). The motivation is that some nice properties of { ˜Hk, ˜Dk}
does not hold for {Hk, Dk}, which brings difﬁculties to directly
study LQP.

The following theorem provides the stagewise closed form of
the dual solution for linear-quadratic problems (either LQP or
CLQP). Our notation is the same as [27, Lemma 3.5], which
provides the stagewise closed form of the primal solution.

Theorem 4. Consider LQP under Assumption 1. Suppose
(p(cid:63), q(cid:63)) is the primal solution. Then the dual solution ζ(cid:63) at
each stage is:

ζ(cid:63)
k = − 2Kk+1p(cid:63)

k+1 + 2

N
(cid:88)

(M k+1
i

)T li

i=k+1

N −1
(cid:88)

+ 2

(V k+1
i

)T Cili,

∀k ∈ [−1, N − 1],

(7)

i=k+1

with KN = QN , DN 1 = DN , DN 2 = 0, and ∀k ∈ [N − 1],

Wk =Rk + BT
Kk = − (BT

k Kk+1Bk,

k Kk+1Ak + Sk)T W −1
k Kk+1Ak,
k Kk+1Ak + Sk),

+ Qk + AT
Pk = − W −1
k (BT
Ek =Ak + BkPk,

k (BT

k Kk+1Ak + Sk)

V k
i = − Ki+1

i
(cid:89)

j=k

Ej,

∀i ∈ [N − 1],

i−1
(cid:89)

j=k

Ej,

∀i ∈ [N ].

p(cid:63) = pc(cid:63),

q(cid:63) = qc(cid:63),

ζ(cid:63) = ζc(cid:63) − 2 ¯Qp(cid:63),

(6)

M k

i = − (Di1 + Di2Pi)

1We note that Problem (2) is slightly different from the one in [27], in
that [27] does not include the terminal data dN . However, with fairly slight
adjustment, their Theorem 5.7 can be extended to the case l = eN .

We obtain a similar formula for ζc(cid:63) of CLQP, where one
replaces {Hk, Dk} in the above recursions by { ˜Hk, ˜Dk}.

Proof. See Appendix V-B.

We now study the dual solution ζc(cid:63) of CLQP. To enable
concise notation, we abuse the notation Kk, M k
i , and so on
to denote the matrices computed by { ˜Hk, ˜Dk}. The following
lemma establishes the exponential decay for ζc(cid:63).

i , V k

Lemma 1. Let Assumptions 1, 2, 3 hold at the unperturbed
solution w(cid:63) of Problem (2). We execute Algorithm 1 with
β ∈ (0, γH ). Let ζc(cid:63) be the optimal dual solution of CLQP.
Then there exist constants Υ(cid:48) > 0, ρ ∈ (0, 1), independent of
N , such that for any k ∈ [−1, N − 1],
(a) if l = ei for i ∈ [N ], then (cid:107)ζc(cid:63)
(b) if l = e−1, then (cid:107)ζc(cid:63)

k (cid:107) ≤ Υ(cid:48)ρ|k+1−i|;

k (cid:107) ≤ Υ(cid:48)ρk+1.

Proof. See Appendix V-C.

We note that the constant ρ in this result is the same as the
one used in Theorem 2. Combining Lemma 1 with Theorem 3,
we can ﬁnally bound the dual solution for LQP.

Theorem 5 (Dual EDS). Let Assumptions 1, 2, 3 hold at
the unperturbed solution w(cid:63) of Problem (2). Then for any
k ∈ [−1, N − 1], Lemma 1 holds for ζ(cid:63)
k with some constants
Υ(cid:48)(cid:48) > 0, ρ ∈ (0, 1) that are determined by constants in the
assumptions and hence are independent of N .

Proof. See Appendix V-D.

√

Combining Theorems 2 and 5, we get the desired primal-dual
EDS result. The perturbation on the left and right boundaries
{−1, N } are of particular interest in the following sections.
Redeﬁning Υ ←
(a) if l = eN , then (cid:107)ξ(cid:63)
(b) if l = e−1, then (cid:107)ξ(cid:63)
where ξ(cid:63)
k = (p(cid:63)
k) is deﬁned in (4). The above exponen-
tial property plays a key role in the analysis of the algorithm.

3 max(Υ, Υ(cid:48)(cid:48)ρ−1) yields the following2:

k(cid:107) ≤ ΥρN −k;
k(cid:107) ≤ Υρk,

k; ζ(cid:63)

k; q(cid:63)

III. OVERLAPPING SCHWARZ DECOMPOSITION

In this section we introduce the overlapping Schwarz scheme

and establish its convergence.

A. Setting

The full horizon of Problem (1) is [N ]. Suppose T is the
number of short horizons and τ is the overlap size. Then we
can decompose [N ] into T consecutive intervals as

[N ] =

T −1
(cid:91)

[mi, mi+1],

i=0

where m0 = 0 < m1 < . . . < mT = N . Moreover, we deﬁne
the expanded (overlapping) boundaries:

i = (mi − τ ) ∨ 0, n2
n1
i , n2

Then we have [N ] = (cid:83)T −1
[mi, mi+1] ⊂ [n1

i=0 [n1
i , n2
i ],

i ] and

∀i ∈ [T − 1].

i = (mi+1 + τ ) ∧ N.

(8)

2This is because (cid:107)ξ(cid:63)
k(cid:107) ≤
Theorem 2 for bounding (cid:107)p(cid:63)

3((cid:107)p(cid:63)

k(cid:107) ∨ (cid:107)q(cid:63)

k(cid:107) and Theorem 5 for bounding (cid:107)ζ(cid:63)

k(cid:107)). One can apply
k(cid:107).

k(cid:107) ∨ (cid:107)ζ(cid:63)

k(cid:107) ∨ (cid:107)q(cid:63)

√

6

In the overlapping Schwarz scheme, the truncated approxima-
tion within the interval [mi, mi+1] is obtained by ﬁrst solving a
subproblem over an expanded interval [n1
i ], then discarding
the piece of the solution associated with the stages acquired
from the expansion (8). We now introduce the subproblem for
the expanded short horizon [n1
i , n2
i ]. For any i ∈ [T − 1], the
i , n2
subproblem Pi for the interval [n1

i ] is deﬁned as

i , n2

min
{xk},{uk}

n2
i −1
(cid:88)

k=n1
i

gk(xk, uk) + ˜gn2

i

(xn2

i

; ¯wn2

i

),

(9a)

s.t. xk+1 = fk(xk, uk), k ∈ [n1
,

= ¯xn1

(λn1

xn1

i −1).

i

i

i , n2

i − 1], (λk) (9b)
(9c)

i

Here, ˜gn2
(xn2
gn2
i
and is formally deﬁned as

(xn2
, un2

i

i

i

; ¯wn2
). It is parameterized by ¯wn2

) is the terminal cost function adjusted from
; ¯λn2
)

= (¯xn2

; ¯un2

i

i

i

i

i

˜gn2

i

(xn2

i

; ¯wn2

i

) =






i

, ¯un2
2 (cid:107)xn2

i

i

i

gn2

(xn2
+ µ
gN (xN ),

) − ¯λT
n2
i
− ¯xn2

fn2
(cid:107)2,

i

i

(xn2

, ¯un2

)

i
i
i ∈ [T − 2],
i = T − 1,

where µ is a uniform penalty parameter that does not depend on
i. In other words, µ is set uniformly over all subproblems. When
i (cid:54)= T − 1, the terminal cost is adjusted by a dual penalty and
a quadratic penalty on the state. Intuitively, the dual penalty
reduces the KKT residuals, while the quadratic penalty ensures
that SOSC holds for subproblems provided it holds for the full
problem and µ is set large enough (see Lemma 2). The formula-
tion (9) is adopted from [29], which differs from the one in [26].
In particular, [26] imposed assumptions on subproblems, while
we impose (standard) assumptions directly on the full problem,
which is more reasonable. An alternative subproblem formula-
tion can be found in [44, (5)], where the terminal adjustment
on the cost is replaced by a terminal constraint.

i

i

, ¯wn2

We note that Problem (9) is a parametric subproblem with
). The parameter (¯xn1
Pi = Pi(¯xn1
) consists of
the primal-dual data on both ends of the horizon (i.e. domain
boundaries). Each time we have to ﬁrst specify the parameter
and then solve the subproblem. For i = T − 1, ¯wn2
is not
necessary (see the deﬁnition of ˜gN (·)). The formal justiﬁcation
of the formulation in (9) will be given in Lemma 3.

, ¯wn2

i

i

i

Deﬁnition 3. We deﬁne the following quantities for subproblem
Pi with i ∈ [T − 1]:
(a) we let w[i] be the primal-dual variable of Pi, i.e. w[i] =

(λn1

i −1; wn1

i −1; xn2

i

i :n2

).

(b) we let w(i) be the primal-dual variable of Pi on the non-
overlapping subdomains, i.e. w(i) = wmi:mi+1−1 (for the
boundaries, w(0) and w(T −1), are adjusted by letting
w(0) = w−1:m1−1 and w(T −1) = wmT −1:mT ).

(c) we let w[−i] be the parameter variable of Pi, i.e. w[−i] =
) (the boundary w[−(T −1)] is adjusted by letting

; wn2

(xn1
w[−(T −1)] = xn1

i

i

).

T −1

(d) we let n[i], n(i), n[−i] be the corresponding dimensions

of w[i], w(i), w[−i].

(e) we let w†

of Pi, i.e. w†

[i](·) : Rn[−i] → Rn[i] be the solution mapping
[i](w[−i]) is a local solution of Pi(w[−i]).

(cid:16)

T(i)

w†

[i](w((cid:96))

(cid:17)
[−i])

Discarded

Discarded

|

|
n1
i

|

|
mi

|

|

|

|

|

|

|

Subproblem i

|

|

|
mi+1

|

|
n2
i

Fig. 2. Schematic of restriction operation.

(f) for k ∈ [n1

i −1, n2

i ], we use Tk(w[i]) to extract the variable
on stage k of w[i]; we also use T(i)(w[i]) to extract
variables of w[i] that are on non-overlapping subdomains.

The solution of Pi(·) may not be unique. The issues of the
existence and uniqueness of the solution will be resolved in
Theorem 6. For now, we assume that the solution w†
[i](·) exists
and consider this as one of the local solutions.

We now formally present the overlapping Schwarz scheme in
Algorithm 2. Here, we use the superscript (·)((cid:96)) to denote its
value at the (cid:96)-th iteration. In addition, we suppose that the
problem information (e.g. {fk}N −1
k=0) and the decom-
i ]}T −1
position information (e.g. {mi}T
i=0 ) are
already given to the algorithm. Thus, the algorithm is well
deﬁned using only the initial guess w(0) of the full primal-dual
solution as an input. Note that x(0)
should match the initial
0
state ¯x0 given to the original problem (1).

i=0 and {[n1

k=0 , {gk}N

i , n2

n1
i

i , n2

; w((cid:96))
n2
i

[−i] = (x((cid:96))

[−i])}T −1
[i](w((cid:96))

Starting with w(0), the procedure iteratively ﬁnds the primal-
dual solution w((cid:96)) for (1). At each iteration (cid:96) = 0, 1, . . ., the
subproblems {Pi(w((cid:96))
i=0 are solved to obtain the short-
horizon solutions w†
[−i]) over the expanded subdomains
i ]}T −1
{[n1
i=0 . Here, we note that the previous primal-dual
iterate enters into the subproblems as boundary conditions
w((cid:96))
). This step is illustrated in Fig. 1. The
solution is then restricted to the non-overlapping subdo-
mains {[mi, mi+1]}T −1
i=0 by applying the operator T(i)(·) (cf.
Deﬁnition 3(f)), which is illustrated in Fig. 2. After that,
one concatenates the short-horizon solutions by w((cid:96)+1) =
(w((cid:96)+1)
(T −1)). We do not explicitly write this step in
(0)
Algorithm 2 since updating the subvectors w((cid:96))
(i) of w((cid:96)) over
i ∈ [T − 1] effectively concatenates the short-horizon solutions.
In Proposition 1 we provide stopping criteria for the scheme.
Observe that, unless τ = 0, the boundary conditions w((cid:96))
[−i]
of subproblem i are set by the output of other subproblems
(in particular, adjacent ones if τ does not exceed the horizon

; . . . ; w((cid:96)+1)

Algorithm 2 Overlapping Schwarz Decomposition

1: Input: w(0)
2: for (cid:96) = 0, 1, . . . do
3:

for (in parallel) i = 0, 1, . . . , T − 1 do

4:

w((cid:96)+1)

(i) = T(i)(w†

[i](w((cid:96))

[−i]));

end for

5:
6: end for
7: Output: w((cid:96))

7

i , n2

lengths of the adjacent problems). Thus, the procedure aims to
achieve coordination across the subproblems by exchanging the
primal-dual solution information. Furthermore, one can observe
that n1
i are at least τ stages apart from [mi, mi+1). This
guarantees all iterates improve (as shown in the next section)
because the adverse effect of misspeciﬁcation of boundary
conditions has enough stages to be damped. We can hence
anticipate that having larger τ makes the convergence faster at
the cost of having moderately larger subproblems.

We emphasize that Algorithm 2 can be implemented in
parallel, although the subproblems are coupled. This is because
subproblems are parameterized by boundary variables {w[−i] =
(xn1
)}i (as deﬁned in Problem (9)) and, in each iteration,
; wn2
once {w((cid:96))
[−i]}i are speciﬁed all subproblems can be solved
independently. To ensure convergence, we require information
exchange between subproblems after each iteration. This is
similar in spirit to traditional Jacobi and Gauss-Seidel schemes.

i

i

B. Convergence Analysis

We now establish convergence for Algorithm 2. A sketch of
convergence analysis is as follows. (i) We extend Assumptions
1, 2, 3 to a neighborhood of a local solution w(cid:63) of Problem
(1). (ii) We show that w†
[−i]) = w(cid:63)
[i](w(cid:63)
[i]. (iii) We bound
the difference of solutions w†
[i]( ¯w[−i]) and w†
[i](w(cid:63)
[−i]) by the
difference in boundary conditions (cid:107) ¯w[−i]−w(cid:63)
[−i](cid:107) using primal-
dual EDS results in Section II. (iv) We combine (i)-(iii) and
derive an explicit estimate of the local convergence rate.

Deﬁnition 4. We deﬁne (cid:107)(·)(cid:107)w as the stagewise max (cid:96)2-norm
of the variable (·). For example,

(cid:107)zk(cid:107)w = (cid:107)xk(cid:107) ∨ (cid:107)uk(cid:107),
(cid:107)w(cid:107)w = max

(cid:107)wk(cid:107)w,

k∈[−1,N ]

(cid:107)wk(cid:107)w = (cid:107)zk(cid:107)w ∨ (cid:107)λk(cid:107),
(cid:107) ∨ (cid:107)wn2

(cid:107)w[−i](cid:107)w = (cid:107)xn1

i

(cid:107)w,

i

(cid:107)w[i](cid:107)w = (cid:107)λn1

i −1(cid:107) ∨ max
i ,n2
k∈[n1
i )

(cid:107)wk(cid:107)w ∨ (cid:107)xn2

i

(cid:107).

Further, we deﬁne Nε(·) as the (closed) ε-neighborhood of the
variable (·) based on the norm (cid:107)(·)(cid:107)w. For example,

Nε(z(cid:63)
Nε(w(cid:63)

k) = {zk ∈ Rnzk : (cid:107)zk − z(cid:63)
k) = {wk ∈ Rnwk : (cid:107)wk − w(cid:63)

k(cid:107)w ≤ ε},

k(cid:107)w ≤ ε}.

Similarly we have Nε(w(cid:63)), Nε(w(cid:63)

[−i]), Nε(w(cid:63)

[i]).

The norm (cid:107)(·)(cid:107)w in Deﬁnition 4 takes the maximum of the
(cid:96)2-norms of stagewise state, control, and dual variables over
the corresponding horizon. One can verify that it is indeed a
vector norm (triangle inequality, absolute homogeneity, and
positive deﬁniteness hold). With Deﬁnition 4, here we extend
assumptions in Section II, which are stated for a local solution
point, to the neighborhood of such a local solution. In what
follows, we inherit the notation in Deﬁnition 1 but drop the
reference variable d. We denote Ak, Bk to be the Jacobian of
fk(xk, uk) with respect to xk and uk, respectively. Hk is the
Hessian of the Lagrange function with respect to (xk, uk).

Assumption 4. For a local primal-dual solution w(cid:63) of Problem
(1), we assume that there exists ε > 0 such that:

(a) There exists a uniform constant γH > 0 such that

Analogously, the KKT system of Pi( ¯w[−i]) is

8

ReH(w) (cid:23) γH I,

for any w = w−1:N with wk ∈ Nε(w(cid:63)
for some i ∈ [T − 1], and wk = w(cid:63)

k otherwise.

k) for k ∈ [n1

i , n2
i ]

(b) There exists a uniform constant Υupper such that ∀k ∈ [N ]:

(cid:107)Hk(wk)(cid:107) ∨ (cid:107)Ak(zk)(cid:107) ∨ (cid:107)Bk(zk)(cid:107) ≤ Υupper,

for any wk ∈ Nε(w(cid:63)

k).

(c) There exist uniform constants γC, t > 0 such that ∀k ∈

[N − t] and some tk ∈ [1, t]:

Ξk,tk (zk:k+tk−1)Ξk,tk (zk:k+tk−1)T (cid:23) γCI,

for any zk:k+tk−1 ∈ Nε(z(cid:63)

k:k+tk−1).

We now show that the subproblem’s solution recover the
truncated full-horizon solution if perfect boundary conditions
are given. We ﬁrst state the following lemma, which adapts [29,
Lemma 1 and Theorem 1] and suggests that the subproblem
formulation (9) inherits uniform SOSC from the full problem,
provided µ is sufﬁciently large.

Lemma 2. Let Assumption 4 hold for the local solution w(cid:63)
of Problem (1) and ε > 0. There exists ¯µ depending on
(Υupper, γC, t) only such that if µ ≥ ¯µ, w[i] ∈ Nε(w(cid:63)
[i]), and
¯w[−i] ∈ Nε(w(cid:63)
[−i]), then the reduced Hessian of subproblem
Pi( ¯w[−i]) at w[i] is lower bounded by γH as well. That is,

ReH i(w[i]; ¯w[−i]) (cid:23) γH I,

where ReH i(w[i]; ¯w[−i]) denotes the reduced Hessian of
Pi( ¯w[−i]) evaluated at w[i], deﬁned similarly as in Deﬁnition 1.

More precisely, we see from [29, (15)] that

¯µ = ¯µ(Υupper, γC, t) :=

upper − Υ4t
16Υupper(Υ6t
γ2
C

upper)

.

(10)

However, the above expression is only a conservative bound
for µ. In our experiments, we will see that µ = 1 works well
for different nonlinear OCPs.

Lemma 3. Let Assumption 4 hold for the local solution w(cid:63) of
Problem (1) and ε > 0. We choose µ ≥ ¯µ deﬁned in Lemma 2.
Then, for any i ∈ [T − 1], w(cid:63)
[−i]).
Proof. By Lemma 2, we know that the reduced Hessian of
Pi(w(cid:63)
[−i]) evaluated at w(cid:63)
[i] is lower bounded by γH . Thus,
it sufﬁces to show that w(cid:63)
[i] satisﬁes the KKT conditions for
Pi(w(cid:63)
[−i]). First, we write the KKT systems for Problem (1):

[i] is a local solution of Pi(w(cid:63)

0 =






∇xk gk(zk) + λk−1 − AT
∇uk gk(zk) − BT
k (zk)λk,
∇xN gN (xN ) + λN −1,
xk+1 − fk(zk),
x0 − ¯x0.

k (zk)λk, ∀k ∈ [N − 1],
∀k ∈ [N − 1],

k (zk)λk, ∀k ∈ [n1
∀k ∈ [n1

i , n2
i , n2

i ),
i ),

0 =






∇xk gk(zk) + λk−1 − AT
∇uk gk(zk) − BT
k (zk)λk,
; ¯wn2
) + λn2
∇xn2
xk+1 − fk(zk),
− ¯xn1
xn1

(xn2

˜gn2

,

i

i

i

i

i

i

i −1,

∀k ∈ [n1

i , n2

i ),

(12)

where ∇xn2

i

˜gn2

i

(xn2

i

; ¯wn2

i

) is






=

i

i

i

gn2

∇xn2

(xn2
+µ(xn2
∇xN gN (xN ),

i

, ¯un2

i

) − AT
, ¯un2
(xn2
n2
i
i
i ∈ [T − 2],
i = T − 1.

),

i

i

− ¯xn2

)¯λn2

i

One can see from the satisfaction of KKT system (11) for the
full problem (1) with w(cid:63) that (12) is satisﬁed with w(cid:63)
[i] when
¯w[−i] = w(cid:63)
[−i]. This completes the proof.

We now estimate errors for the short-horizon solutions. The
next theorem characterizes the existence and uniqueness of the
local mapping w†
[i](·) from the boundary variable w[−i] to the
local solution of Pi(w[−i]).

Theorem 6. Let Assumption 4 hold for the local solution w(cid:63) of
Problem (1) and ε > 0. We choose µ ≥ ¯µ deﬁned in Lemma 2.
Then, for any i ∈ [T − 1], there exist δ > 0, ε(cid:48) ∈ (0, ε)
and a continuously differentiable function w†
[−i]) →
[i]) such that, if boundary variable ¯w[−i] ∈ Nδ(w(cid:63)
Nε(cid:48)(w(cid:63)
[−i]),
then w†
[i]( ¯w[−i]) is a unique local solution of Pi( ¯w[−i]) in the
neighborhood Nε(cid:48)(w(cid:63)

[i] : Nδ(w(cid:63)

[i]).

Theorem 6 is a specialization of the classical result of [45,
Theorem 2.1]. Since w†
[i] is differentiable, we analogize the
directional derivatives deﬁnitions in (4) and, for any point
¯w[−i] and perturbation direction l, deﬁne

ξ†
[i]( ¯w[−i], l) = lim
h(cid:38)0

w†

[i]( ¯w[−i] + hl + o(h)) − w†

[i]( ¯w[−i])

h

as the directional derivatives of w†
[i]( ¯w[−i]). Here, we disregard
i , n2
the perturbation for stages [n1
i ) since in the formulation of
subproblems (9), only stages n1
i −1 and n2
i are perturbed. Imple-
menting the exact computation of w†
[i]( ¯w[−i]) is challenging. In
practice, one resorts to solving Pi( ¯w[−i]) using a generic NLP
solver, and the solver may return a local solution outside of
the neighborhood Nε(cid:48)(w(cid:63)
[i]). Strictly preventing this is difﬁcult
in general. Fortunately, by warm-starting the solver with the
previous iterate, one may reduce the chance that the solver
returns a solution that is far from the previous iterate. Thus,
in our numerical implementation, we implement Algorithm 2
by using the warm-start strategy.

The next result characterizes the stagewise difference be-
[−i]).

[i]( ¯w[−i]) and w†

[i](w(cid:63)

tween w†

∀k ∈ [N − 1],

(11)

Theorem 7. Let Assumption 4 hold for the local solution w(cid:63) of
Problem (1) and ε > 0. We choose µ ≥ ¯µ deﬁned in Lemma 2,
and δ > 0 deﬁned in Theorem 6. For i ∈ [T − 1], if boundary

variable ¯w[−i] ∈ Nδ(w(cid:63)
and ρ ∈ (0, 1) independent from N and i, such that

[−i]), then there exist constants Υ > 0

[i]}(cid:107)w ≤ Υ(cid:8)ρk−n1

(cid:107)Tk{w†
+ ρn2

− x(cid:63)
[i]( ¯w[−i]) − w(cid:63)
n1
i
i − 1, n2
− w(cid:63)
i −k(cid:107) ¯wn2
i ].
n2
i
= w(cid:63)
= x(cid:63)
Proof. We deﬁne ∆xn1
n2
n1
i
i
and an intermediate boundary variable ˜w[−i] = (x(cid:63)
n1
i
Then ˜w[−i] ∈ Nδ(w(cid:63)

− ¯wn2
,
, ¯wn2
).
[i]( ˜w[−i]) exist. We have

i (cid:107)¯xn1
∀k ∈ [n1

[−i]) and thus w†

, ∆wn2

− ¯xn1

(13)

(cid:107)w

(cid:9),

(cid:107)

i

i

i

i

i

i

i

[i]( ¯w[−i]) − w†
w†
= {w†

[i](w(cid:63)
[i]( ¯w[−i]) − w†

[−i])
[i]( ˜w[−i])} + {w†
The ﬁrst term corresponds to the perturbation of the initial
stage, while the second term corresponds to the perturbation of
the terminal stage. Let us deﬁne two directions l1 and l2 as:

[i]( ˜w[−i]) − w†

[i](w(cid:63)

(14)

[−i])}.

l1 =

l2 =




0







0

∆xn1
i
(cid:107)∆xn1
i

(cid:107)

∆wn2
i
(cid:107)∆wn2
i

(cid:107)

if (cid:107)∆xn1

i

(cid:107) = 0,

otherwise,

if (cid:107)∆wn2

i

(cid:107) = 0,

otherwise,

i

i

[i]).

(cid:107)]} and P2 = { ˜w[−i] + sl2 : s ∈ [0, (cid:107)∆wn2

and accordingly the perturbation paths P1 = { ¯w[−i] + sl1 :
s ∈ [0, (cid:107)∆xn1
(cid:107)]}.
Along P1 the boundary variable changes from ¯w[−i] to ˜w[−i];
and along P2 the boundary variable changes from ˜w[−i] to
w(cid:63)
[−i]. We can easily verify from Deﬁnition 4 that any points on
P1 ∪ P2 are in the neighborhood Nδ(w(cid:63)). Thus, by Theorem 6,
w†

[i](P1 ∪ P2) exists and lies in Nε(cid:48)(w(cid:63)
The perturbations along the path P1 ∪P2 will be analyzed us-
ing Theorems 2 and 5. We ﬁrst check that Assumptions 1, 2,
3 hold at w†
[i](w[−i]) over w[−i] ∈ P1 ∪ P2. Assumption 1
holds at each w†
[i](w[−i]) by Assumption 4(a) and Lemma 2.
Assumption 2 holds at each w†
[i](w[−i]) by Assumption 4(c).
For Assumption 3, we know Hk, Ak, Bk for k ∈ [n1
i ) are
upper bounded by Assumption 4(b); further, one can verify that
Hn2
are also uniformly bounded by inspecting
Pi(·) and noting that µ is a parameter independent of N and
i. Thus, Assumptions 1, 2, 3 hold at each w†
[i](w[−i]) over
w[−i] ∈ P1 ∪ P2.

, and Dn2

i , n2

, Cn1

i

i

i

By Lemma 3, for any i ∈ [T − 1] and k ∈ [n1
(cid:107)Tk{w†

[i]}(cid:107)w

i , n2

i ], we have

[i]( ¯w[−i]) − w(cid:63)
= (cid:107)Tk{w†
(14)
≤ (cid:107)Tk{w†
+ (cid:107)Tk{w†

[i]( ¯w[−i]) − w†
[i]( ¯w[−i]) − w†
[i]( ˜w[−i]) − w†

[i](w(cid:63)

[−i])}(cid:107)w

[i]( ˜w[−i])}(cid:107)w
[i](w(cid:63)

[−i])}(cid:107)w.

(15)

Rewriting the ﬁrst term of the right-hand side of the inequality
in (15) and using the integral of line derivative yields

[i]( ¯w[−i]) − w†
(cid:107)Tk{w†
(cid:13)
(cid:90) (cid:107)∆xn1
(cid:13)
(cid:13)
(cid:13)
(cid:13)
0
(cid:90) (cid:107)∆xn1
i

=

(cid:107)

(cid:107)

i

Tk{ξ†

[i]( ˜w[−i])}(cid:107)w

(cid:13)
(cid:13)
(cid:13)
[i]( ¯w[−i] + sl1; l1)}ds
(cid:13)
(cid:13)w

(cid:107)Tk{ξ†

[i]( ¯w[−i] + sl1; l1)}(cid:107)wds

≤

0

≤ (cid:107)∆xn1

i

(cid:107) · Υρk−n1
i ,

9

where the second inequality follows from triangle inequality
of integrals and the third inequality follows from Theorems 2
and 5. Similarly, the second term in (15) can be bounded by
Υρn2
(cid:107)w where the inequal-
ity is due to

i −k(cid:107)∆wn2

i −k(cid:107)∆wn2

3Υρn2

(cid:107) ≤

√

i

i

√

(cid:107)∆wn2

i

(cid:107) ≤

3((cid:107)∆xn2

i

(cid:107) ∨ (cid:107)∆un2

i

(cid:107))

(cid:107) ∨ (cid:107)∆λn2
√
=

i

3(cid:107)∆wn2

i

Thus, combining these results with (15) and letting Υ ←
we obtain (13). This completes the proof.

(cid:107)w.
√

3Υ,

[i](w(cid:63)

[−i]) = w(cid:63)

[i]. However, since w(cid:63)

Theorem 7 provides a proof for the conjecture made in [26,
Property 1]. It shows that the effect of the perturbation of
the boundary variable w[−i] of Pi on the solution w†
[i](w[−i])
decays exponentially as moving away from two boundary ends.
Here, the unperturbed data is w(cid:63)
[−i], and by Lemma 3, the
truncated full-horizon solution is the unperturbed subproblem
solution, i.e. w†
[−i] is
unknown, the algorithm uses the previous iterate to specify
the boundary variable, which results in a perturbation of w(cid:63)
[−i].
Suppose we perturb w(cid:63)
[−i] to ¯w[−i], which corresponds to
the perturbation of both initial and terminal stages. Theorem 7
makes use of the EDS property in Theorems 2 and 5 and shows
that the stagewise error brought by the perturbation decays
exponentially. In particular, for k ∈ [mi−1, mi], we note that
k − n1
i − k ≥ τ , which implies the stagewise error within
[mi−1, mi] has been improved by at least a factor 2Υρτ . Thus,
if τ ≥ log(2Υ)/ log(1/ρ), we can observe a clear improvement
for middle stages [mi, mi+1]. This justiﬁes discarding iterates
for the subdomain overlaps and concatenating iterates of the
non-overlapping subdomains.

i ∧ n2

We are now in a position to establish our main convergence
result. Based on Lemma 3 and Theorem 7, we establish the
local convergence of Algorithm 2.

Theorem 8. Let Assumption 4 hold for the local solution w(cid:63) of
Problem (1) and ε > 0. There exist parameters ¯µ, ¯τ > 0, and a
constant δ > 0 such that if µ ≥ ¯µ, τ ≥ ¯τ , and w(0) ∈ Nδ(w(cid:63)),
the following holds for (cid:96) = 0, 1, · · · :

(cid:107)w((cid:96)) − w(cid:63)(cid:107)w ≤ α(cid:96)(cid:107)w(0) − w(cid:63)(cid:107)w,

(16)

where α = 2Υρτ is independent of N .

Proof. We choose ¯µ in Lemma 2, ¯τ = (cid:100)log(2Υ)/ log(1/ρ)(cid:101) +
1, and δ deﬁned in Theorem 6. Then α < 1. We ﬁrst show
w((cid:96)) ∈ Nδ(w(cid:63)) for (cid:96) = 0, 1, . . . using mathematical induction.
The claim trivially holds for (cid:96) = 0 from the assumption.
Assume that the claim holds for (cid:96); thus w((cid:96))
[−i]).
From Theorem 7 and noting that for any i ∈ [T − 1] and any
∀k ∈ [mi, mi+1), k − n1
(cid:107)w((cid:96)+1)
k

[−i](cid:107)w ≤ α(cid:107)w((cid:96)) − w(cid:63)(cid:107)w.

i − k ≥ τ , we obtain

k(cid:107)w ≤ α(cid:107)w((cid:96))

[−i] ∈ Nδ(w(cid:63)

[−i] − w(cid:63)

i ∧ n2

− w(cid:63)

Taking maximum over k on the left hand side,

(cid:107)w((cid:96)+1) − w(cid:63)(cid:107)w ≤ α(cid:107)w((cid:96)) − w(cid:63)(cid:107)w.
From α < 1, we have w((cid:96)+1) ∈ Nδ(w(cid:63)) and the induction is
complete. Recursively using (17), we obtain (16).

(17)

Theorem 8 establishes local linear convergence of Algorithm
2. In summary, if SOSC, controllability condition, and bound-
edness condition are satisﬁed around the neighborhood of the
local primal-dual solution of interest, the algorithm converges to
the solution at a linear rate (provided that the overlap size τ is
sufﬁciently large). Furthermore, the convergence rate α decays
exponentially in τ . One may observe that the overlap size may
reach the maximum (i.e., [n1
i , n2
i ] = [0, N ] for i ∈ [T − 1])
before α < 1 is achieved. In that case, the algorithm converges
in one iteration (it becomes a centralized algorithm). However,
since Υ and ρ are parameters independent of N , when a
problem with a sufﬁciently long horizon is considered, one can
always obtain the exponential improvement of the convergence
rate before reaching the maximum overlap. The argument states
the existence of ¯µ, ¯τ and δ. The expression of ¯µ is provided in
(10); ¯τ is selected by enforcing α = 2Υρ¯τ < 1 so that ¯τ =
(cid:100)log(2Υ)/ log(1/ρ)(cid:101) + 1. Here, Υ, ρ are constants from Theo-
rem 7, originating from the sensitivity analysis presented in the
end of Section II. Their expressions in terms of the constants
in Assumption 4 can be found in [27], but we do not present
them here observing that they are often conservative in practice.
As typical for local convergence analysis for NLP, the local
radius δ is not accessible due to the intrinsic nonlinearity of the
problem (e.g., see Theorems 11.2 and 18.4 in the textbook [42]
for comparison), while it is also not required for performing
our algorithm.

i

i

at ¯xn2

As stated in Theorem 8, Algorithm 2 has two tuning param-
eters µ and τ , where the former is the penalty parameter for
the subproblem (cf. (9)) and the latter is the overlap size. We
note that the quadratic penalty is only added to the terminal
state variable. Thus a very large µ is equivalent to ﬁxing the
. We can let µ be large to ensure the
terminal state xn2
condition µ ≥ ¯µ to be satisﬁed, though our experiments show
that a moderate µ also works well in practice. On the other
hand, a larger τ implies faster convergence, but also results in
longer subproblems. In practice, we may tune τ to balance the
fast convergence rate and the increased subproblem complexity.
Moreover, one beneﬁt from our analysis is that tuning µ and
τ is independent from horizon length N . Thus, we only target
the subproblems with ﬁxed, short horizons to tune µ and τ , and
the same parameters work even when N is extremely large.

The convergence of Algorithm 2 can be monitored by
checking the KKT residuals of (1). However, a more convenient
surrogate of the full KKT residuals can be derived as follows.

Proposition 1. Let {w((cid:96))}∞
(cid:96)=0 be the sequence generated by
Algorithm 2 with τ ≥ 1. Any limit point of the sequence satisﬁes
the KKT conditions (11) for the full problem (1) if the following
is satisﬁed for i ∈ (0, T ) as (cid:96) → ∞:

(cid:40)

Tmi(x†
Tmi−1(λ†

[i−1](w((cid:96))
[i](w((cid:96))

[−(i−1)])) − x((cid:96)+1)
[−i])) − λ((cid:96)+1)

mi−1 → 0.

mi → 0,

[i](w((cid:96))
[−i]), one can observe that

Proof. Recalling that each w†
[−i]) satisﬁes the KKT
conditions of P(w((cid:96))
the KKT
conditions (11) for the full problem (1) are violated only
in the ﬁrst equation of (11) over k ∈ {mi}T −1
i=1 and in the
fourth equation of (11) over k ∈ {mi − 1}T −1
i=1 ; and the

10

[−i])) − λ((cid:96)+1)
residuals at iteration (cid:96) + 1 are Tmi−1(λ†
mi−1
and Tmi(x†
, respectively. Therefore,
by the given condition, we have that (11) is satisﬁed for any
limit points of the sequence.

[−(i−1)])) − x((cid:96)+1)

[i−1](w((cid:96))

[i](w((cid:96))

mi

Accordingly, we deﬁne the monitoring metrics by
[−(i−1)])) − x((cid:96)+1)
[−i])) − λ((cid:96)+1)

[i−1](w((cid:96))
[i](w((cid:96))

(cid:15)((cid:96))
pr = max
i∈(0,T )

(cid:107)Tmi−1(λ†

(cid:107)Tmi(x†

mi−1(cid:107),

(cid:15)((cid:96))
du = max
i∈(0,T )

mi

(cid:107),

and then set the convergence criteria by
pr and (cid:15)((cid:96))
pr , (cid:15)tol
du.

for the given tolerance values (cid:15)tol

stop if: (cid:15)((cid:96))

pr ≤ (cid:15)tol

du ≤ (cid:15)tol
du,

Before showing numerical results, we discuss the global
behavior of Schwarz decomposition. In general, there is no
guarantee for the scheme to converge globally for nonlinear
OCPs. As shown in Theorem 6, the solution mapping w†
[i]
exists only in a neighborhood of w(cid:63)
[−i] and our main rate
of convergence result, Theorem 8, is strictly local in nature.
Outside of the neighborhood, Pi(w[−i]) may have inﬁnite so-
lutions or may have no solution due to nonlinearity. In general,
we would need a merit function and a line search to ensure
local convergence to a stationary point globally [42]. However,
when we have more structure in the problem, the scheme can
converge globally. For example, we show in the next theorem
that Algorithm 2 converges globally for linear-quadratic OCPs.
More general results using merit functions will be investigated
in future research.

Theorem 9. Let us consider linear-quadratic problems with
(cid:19)

(cid:19)

(cid:19)

(cid:18)xk
uk

+

(cid:18)rk
sk

(cid:19)T (cid:18)xk
uk

gk(xk, uk) =

(cid:18)xk
uk

(cid:19)T (cid:18)Qk ST
k
Sk Rk
(cid:123)(cid:122)
Hk
N QN xN + rT

(cid:124)

N xN

(cid:125)

gN (xN ) = xT

and fk(xk, uk) = Akxk + Bkuk + vk. Suppose Assumption 4
holds for {Hk, Ak, Bk}. Then there exist parameters ¯µ, ¯τ > 0
such that if µ ≥ ¯µ, τ ≥ ¯τ , the linear convergence to the unique
global solution w(cid:63) of Problem (1), shown in (16), holds for
any initial point w(0).

We note that {Hk, Ak, Bk} do not depend on wk, and linear
terms {rk, sk, vk} do not affect the Lagrangian Hessian and
constraint Jacobian. Thus, Assumption 4 holds in the whole
space.

Proof. First, each subproblem (9) is still a linear quadratic
problem with any boundary variable w[−i]. By Lemma 2, there
exists ¯µ such that µ ≥ ¯µ implies ReH i (cid:23) γH I. Moreover,
by LICQ of (9) (i.e. the Jacobian G has full row rank, see
Deﬁnition 1), we know from [42, Lemma 16.1] that each
subproblem has a unique, global solution for any w[−i], denoted
by w†
[i](w[−i]). Thus, Theorem 6 is applicable with the stated
neighborhoods being the entire space.
Second, from Lemma 3, we know w†

[i]. More-
over, the one-step error recursion in (13) holds directly follow-
ing the same proof as in Theorem 7, and ﬁnally (17) holds as
well. This shows (16) holds.

[−i]) = w(cid:63)

[i](w(cid:63)

Although Theorem 9 is limited to the linear-quadratic set-
tings, we allow for the possibility of negative curvature in
the objective. Speciﬁcally, note that Assumption 4(a) only
requires ReH (cid:23) γH I, while existing results [25] require the
strong convexity H (cid:23) γH I. This beneﬁt comes from the
convexiﬁcation procedure in Algorithm 1 that our EDS results
are based on.

It is worthwhile to mention that computation of the Newton
step (search direction) for nonlinear OCPs effectively reduces to
solving a linear-quadratic OCP. Accordingly, the overlapping
Schwarz scheme can be used as a method to compute the
search directions within second-order methods (such as interior-
point approaches). Theorem 9 provides the global convergence
proof for overlapping Schwarz-based step computations. We
acknowledge that there is a wide range of decomposition
methods for linear-quadratic OCPs (that include both iterative
and direct approaches). Studying and comparing the scalability
of these methods with that of the Schwarz scheme is an
interesting direction of future work.

IV. NUMERICAL EXPERIMENTS

We apply the overlapping Schwarz scheme to a quadrotor
control problem (governed by equations of motions) and to a
thin plate temperature control problem (governed by nonlinear
PDEs). Here, we aim to illustrate the convergence behavior of
the Schwarz scheme and also to compare performance against
state-of-the-art approaches such as ADMM and a centralized
interior-point solver (Ipopt). We will demonstrate that Schwarz
provides ﬂexibility (as ADMM) and efﬁciency (as Ipopt). Our
results also illustrate how EDS property arises in applications.

A. Quadrotor Control

We consider a quadrotor model studied in [46], [47]:

d2X
dt2 = a(cos γ sin β cos α + sin γ sin α)
d2Y
dt2 = a(cos γ sin β sin α − sin γ cos α)
d2Z
dt2 = a cos γ cos β − g
dγ
dt
dβ
dt
dα
dt

= (ωX cos γ + ωY sin γ)/ cos β

= −ωX sin γ + ωY cos γ

= ωX cos γ tan β + ωY sin γ tan β + ωZ.

Here, (X, Y, Z) are the positions, (γ, β, α) are the angles, and
g = 9.8 is the gravitational acceleration. We regard x =
˙X, Y, ˙Y , Z, ˙Z, γ, β, α) as the state variables and u =
(X,
(a, ωX , ωY , ωZ) as the control variables. The dynamics are
discretized with an explicit Euler scheme with time step
∆t = 0.005 to obtain an OCP of the form of interest.
Furthermore, the stage cost function is gk(xk, uk) = 1
2 (cid:107)xk −
R; gN (xN ) = 1
k (cid:107)2
xref
Q; Q =
diag(1, 0, 1, 0, 1, 0, 1, 1, 1); R = diag(1/10, 1/10, 1/10, 1/10);
{xref
k=1 is generated from a sinusoidal function; N = 24, 000
(full problem; corresponds to 60 secs horizon); µ = 1; and
¯x0 = (0; 0; 0; 0; 0; 0; 0; 0; 0).

2∆t (cid:107)xN − xref

2 (cid:107)uk(cid:107)2

Q + 1

k }N

N (cid:107)2

11

B. Thin Plate Temperature Control

We consider a thin plate temperature control problem [48]:

min
x,u

(cid:90) T

(cid:90)

0

w∈Ω

1
2

(x(w, t) − d(w, t))2 +

1
2

ru(w, t)2 dwdt

(18a)

s.t.

∂x(w, t)
∂t

= −∆x(w, t) +

+

2(cid:15)σ
κtz

(x(w, t)4 − T

w ∈ Ω, t ∈ [0, T ]

2hc
κtz
4

) −

(x(w, t) − T )

1
κtz

u(w, t),

(18b)

w ∈ ∂Ω,

x(w, t) = T ,

(18c)
where Ω = [0, 1] × [0, 1] ⊆ R2 is the 2-dimensional domain
of interest; x : Ω × [0, T ] → R is the temperature; u : Ω ×
[0, T ] → R is the control; ∆ is the Laplacian operator; ∂Ω
is the boundary of Ω; d : Ω × [0, T ] → R is the desired
temperature; r = 0.1, κ = 400, tz = 0.01, hc = 1, (cid:15) = 0.5,
σ = 5.67 × 10−8, and T = 300 are the problem parameters
(see [48]). The desired temperature data are generated from a
sinusoidal function. The PDE in (18b) is governed by the heat
equation which consists of convection, radiation, and forcing
terms, and the Dirichlet boundary condition is enforced. We
consider a discretized version of the problem: we discretize Ω
by a 10 × 10 mesh and T = 24 hour prediction horizon with
∆t = 10 secs.

C. Methods and Results

We ﬁrst present a numerical veriﬁcation of primal-dual EDS
(Theorem 7) using the quadrotor problem. We ﬁrst obtain
the reference primal-dual solution trajectory by solving the
full problem. Then, the perturbed trajectories are obtained by
solving the problem with the perturbation on the given initial
state ¯x0, and on the terminal state xref
N . In particular, we solved
the full problem with random perturbations ∆¯x0 and ∆xref
N
drawn from a zero-mean normal distribution.

The reference trajectory and 30 samples of the perturbed
trajectories are shown in Fig. 3. One can see that the solution
trajectories coalesce in the middle of the time domain and
increase the spread at two boundaries. This result indicates that
the sensitivity is decreasing toward the middle of the interval
and veriﬁes our theoretical results.

TABLE I
ITERATIONS AND SOLUTION TIME AS A FUNCTION OF OVERLAP SIZE.

Iterations
Solution Time (sec)

(cid:101)τ = 0.3
31
6.03

(cid:101)τ = 0.5
11
2.41

(cid:101)τ = 1.0
7
2.46

We now illustrate the convergence of the Schwarz scheme
for the quadrotor problem with 3 subdomains. The evolution
of KKT errors with different overlap sizes are plotted in Fig.
4. Here, we expand the domain until the size of the extended
domain reaches (cid:101)τ times the original non-overlapping domain.
Such relative criteria are often more practical because the
scaling of the problem changes with discretization mesh size.
We observe that the convergence rate improves dramatically
as (cid:101)τ increases. This result veriﬁes Theorem 8. Fig. 5 further

12

Fig. 3. Primal-dual exponential decay of sensitivity for quadrotor problem.
The black line represents the reference trajectory; the light blue lines represent
the perturbed trajectories; the diamonds represent the initial state; and the
circles represent the terminal state. Observe the collapse of the perturbed
trajectories to the reference one in the middle of the time intervals.

Fig. 5. Convergence of primal trajectory with ˜τ = 0.1. Top-to-bottom:
iterations 1,2, and 3; blue, red, green markers are solutions from subproblems
1, 2, and 3, respectively; black line is solution trajectory.

Fig. 4. Convergence of KKT residuals for overlapping Schwarz scheme.

illustrates convergence of the trajectories for (cid:101)τ = 0.1. At the
ﬁrst iteration, the error is large at the boundaries and small
in the middle of the domain. The error decays rapidly as the
high-error components of the solution are discarded and the
low-error components are kept. This behavior illustrates why
EDS is central to achieve convergence. A computational trade-
off exists for the Schwarz scheme when increasing (cid:101)τ (since
the subproblem complexity increases with (cid:101)τ ). This trade-off
is revealed from time per iteration (see Table I): we ﬁnd the
scheme takes 0.219 sec/iter when (cid:101)τ = 0.5 and 0.352 sec/iter
when (cid:101)τ = 1.0.

We also benchmark the Schwarz scheme against a centralized
solver (Ipopt) and against a popular decomposition scheme

(ADMM) for solving the above two problems. For both the
Schwarz and ADMM schemes, we partition the domain into
20 intervals with the same length. For the Schwarz scheme, we
expand each interval by (8) with the relative size of overlap ˜τ =
1.0. For ADMM, subproblems are formulated by introducing
duplicate variables and decomposing on the time domain [49].
To ensure consistency, subproblems in the Schwarz and ADMM
schemes are all solved with Ipopt [50], conﬁgured with the
sparse solver MA27 [51]. The study is run on a multicore
parallel computing server (shared memory and 40 cores of Intel
Xeon Gold 6140 CPU running at 2.30GHz) using the multi-
thread parallelism in Julia. For both the Schwarz and ADMM
schemes, we vary the penalty parameter as indicated in Figure
6. All results can be reproduced using the provided scripts in
https://github.com/zavalab/JuliaBox/tree/master/SchwarzOCP.
One can see that, for both problems, the overlapping Schwarz
scheme has much faster convergence than ADMM (Fig. 6)

13

the scheme enjoys linear convergence locally, with a linear rate
that improves exponentially with the size of the overlap. Central
to our convergence proof is a primal-dual parametric sensitivity
result that we call exponential decay of sensitivity. We also
provided a global convergence proof for the Schwarz scheme
for the linear-quadratic OCP case. This result is of relevance,
as it suggests that the scheme could be used to solve linear
systems inside NLP solvers. Computational results reveal that
the Schwarz scheme is signiﬁcantly more efﬁcient than ADMM
and as efﬁcient as the centralized NLP solver Ipopt. In future
work, we will seek to expand our results to alternative problem
structures (e.g., networks and stochastic programs). Moreover,
it will be interesting to compare performance in different
hardware architectures (e.g., embedded systems) and against
different decomposition schemes (e.g., Riccati and block cyclic
reduction).

ACKNOWLEDGMENT

This material is based upon work supported by the U.S.
Department of Energy, Ofﬁce of Science, Ofﬁce of Advanced
Scientiﬁc Computing Research (ASCR) under Contract DE-
AC02-06CH11347 and by NSF through award CNS-1545046
and ECCS-1609183. We also acknowledge partial support from
the National Science Foundation under award NSF-EECS-
1609183.

APPENDIX

The missing proofs in Section II-B are presented here.

A. Proof of Theorem 3

Under Assumption 1, we know that (p(cid:63), q(cid:63), ζ(cid:63)) is a unique
global solution of LQP. When executing Algorithm 1 with
β ∈ (0, γH ), we know from [27, Theorem 3.8] that ˜Hk (cid:31) 0 (i.e.
˜Hk(β) in their notation). Thus, (pc(cid:63), qc(cid:63), ζc(cid:63)) is also a unique
global solution of CLQP. By [27, Lemma 3.4], we know that
LQP and CLQP have the same objective. Since Algorithm 1
does not change constraint matrices Ak, Bk, Ck of (5), we have
p(cid:63) = pc(cid:63) and q(cid:63) = qc(cid:63). We now establish the relation of dual
solutions ζ(cid:63) and ζc(cid:63) by studying KKT conditions of Problem
(5). To simplify notation, we denote the k-th component of
the objective by

Ok(pk, qk) =

ON (pN ) =

(cid:18) pk
qk
lk

(cid:18)

pN
lN

(cid:19)T (cid:18) Qk ST

k DT
k1
Sk Rk DT
k2
Dk1 Dk2 0
(cid:19)(cid:18)

QN DT
N
DN 0

(cid:19)

, ∀k ∈ [N − 1],

(cid:19)(cid:18) pk
qk
lk

(cid:19)

.

pN
lN

(cid:19)T (cid:18)

Similarly, we deﬁne ˜Ok(pk, qk) and ˜ON (pN ) by replacing
Hk, Dk by ˜Hk, ˜Dk. The KKT system of LQP is then given by

Fig. 6. Benchmark of overlapping Schwarz against Ipopt and ADMM. Top:
Quadrotor control problem; bottom: Thin plate temperature control problem.

regardless of the choice of µ. One can also observe that the
performance of ADMM is sensitive to the choice of µ, while
the performance Schwarz scheme is insensitive to it. We note
that ADMM tends to decrease the overall error but eventually
the error settles to a rather high value. We also emphasize that
ADMM does not have convergence guarantees for the general
nonconvex OCPs considered here (as discussed in Section I).
In contrast, the overlapping Schwarz scheme converges almost
as fast as centralized solver Ipopt. The ﬁnal accuracy of the
Schwarz scheme (10−6) is much higher than that achieved by
ADMM, but not as that achieved by Ipopt (less than 10−8). The
difference between the accuracy between Schwarz and Ipopt
are due to the fact that Schwarz is an iterative scheme, while the
linear algebra performed inside Ipopt uses a direct linear solver
(MA27). Direct solvers are known for delivering high accuracy.
We highlight, however, that in many control applications there
is often ﬂexibility to deliver moderate accuracy, so being able to
deliver moderately accurate solution in a reasonably short time
can be a favorable characteristic. For the thin plate temperature
control problem, the accuracy of ADMM is notably worse than
that achieved with the Schwarz scheme.

To sum up, the overlapping Schwarz scheme is an efﬁcient
method to solve OCPs and offers ﬂexibility to be implemented
in different computing hardware architectures.

V. CONCLUSIONS

We established the convergence properties of an overlapping
Schwarz decomposition scheme for general nonlinear optimal
control problems. Under standard SOSC, controllability, and
boundedness conditions for the full problem, we showed that

0 =






∇pk Ok(pk, qk) + ζk−1 − AT
∇qk Ok(pk, qk) − BT
∇pN ON (pN ) + ζN −1,
pk+1 − (Akpk + Bkqk + Cklk),
p0 − l−1.

k ζk,

k ζk, ∀k ∈ [N − 1],
∀k ∈ [N − 1],

(19)

∀k ∈ [N − 1],

For the KKT system of CLQP, we replace ∇Ok by ∇ ˜Ok and
ζ by ζc in (19) since two problems have the same linear-
quadratic form. By Algorithm 1, we know that ∀k ∈ [N − 1],

∇pk

˜Ok(pk, qk) = 2 ˜Qkpk + 2 ˜ST
=2( ˆQk − ¯Qk)pk + 2 ˜ST
=2Qkpk + 2ST

k qk + 2 ˜DT
k1lk

k qk + 2 ˜DT

k qk + 2DT

k1lk − 2 ¯Qkpk
¯Qk+1(Akpk + Bkqk + Cklk)

+ 2AT
k

k1lk

=∇pk Ok(pk, qk) − 2 ¯Qkpk + 2AT

k

¯Qk+1pk+1,

(20)

where the last equality results from deﬁnition of Ok and the
k-th dynamic constraint. We can also show that
˜Ok(pk, qk) =∇qk Ok(pk, qk) + 2BT

¯Qk+1pk+1,

∇qk

k

(21)

∇pN

˜ON (pN ) =∇pN ON (pN ) − 2 ¯QN pN .

Plugging (20), (21) back into (19), we obtain that the KKT
system of LQP is equivalent to

ζ(cid:63)
k−1 = −2(AT

0 =






˜Ok + (ζk−1 + 2 ¯Qkpk) − AT
∇pk
˜Ok − BT
k (ζk + 2 ¯Qk+1pk+1),
∇qk
˜ON + (ζN −1 + 2 ¯QN pN ),
∇pN
pk+1 − (Akpk + Bkqk + Cklk),
p0 − l−1.

k (ζk + 2 ¯Qk+1pk+1),
∀k ∈ [N − 1],

+ W −1

k BT

k

∀k ∈ [N − 1],

Comparing the above equation with the KKT system of CLQP,
and using the invariance of the primal solution, we see that
(pc(cid:63), qc(cid:63), ζ(cid:63) + 2 ¯Qp(cid:63)) satisﬁes the KKT system of CLQP.
Since LICQ holds for CLQP, the dual solution is unique. This
implies ζc(cid:63) = ζ(cid:63) + 2 ¯Qp(cid:63) and we complete the proof.

B. Proof of Theorem 4

First of all, the invertibility of Wk is guaranteed by Assump-
tion 1, as directly shown in [27, Lemma 3.5(i)]. We use reverse
induction to prove the formula of ζ(cid:63)
k. According to (19), for
k = N − 1 we have

ζ(cid:63)
N −1 = −∇pN ON (p(cid:63)

N ) = −2QN p(cid:63)

N − 2DT

N lN ,

which satisﬁes (7) and proves the ﬁrst induction step. Suppose
ζ(cid:63)
k satisﬁes (7). From (19), we have
k ζ(cid:63)
k − ∇pk Ok(p(cid:63)
k ζ(cid:63)
k − 2Qkp(cid:63)
Plugging the expression for ζ(cid:63)

k, q(cid:63)
k)
k q(cid:63)
k − 2ST

ζ(cid:63)
k−1 =AT
=AT

k − 2DT

k1lk.

k from (7), we get
N
(cid:88)

(cid:0)

ζ(cid:63)
k−1 = −2AT

k Kk+1p(cid:63)

k+1 + 2AT
k

(M k+1
i

)T li

N −1
(cid:88)

+

(V k+1
i

)T Cili

(cid:1) − 2Qkp(cid:63)

k − 2ST

k q(cid:63)

k − 2DT

k1lk

i=k+1

i=k+1
= −2(AT

k Kk+1Ak + Qk)p(cid:63)
(cid:40) N
(cid:88)

k − 2(Sk + BT
N −1
(cid:88)

(M k+1
i

)T li +

(V k+1
i

)T Cili

k Kk+1Ak)T q(cid:63)
k

(cid:41)

+ 2AT
k

i=k+1

i=k+1

− 2AT
= −2(AT

k Kk+1Cklk − 2DT
k Kk+1Ak + Qk)p(cid:63)

k1lk
k + 2P T

k Wkq(cid:63)
k

14

(cid:40) N
(cid:88)

+ 2AT
k

(M k+1
i

)T li +

N −1
(cid:88)

(V k+1
i

)T Cili

(cid:41)

i=k+1

i=k+1

k1lk,

− 2AT

k Kk+1Cklk − 2DT
where the second equality follows from p(cid:63)
k +
Cklk) = 0, and the third equality follows from the deﬁnition
of Pk. By [27, Lemma 3.5(ii)], we have

k+1−(Akp(cid:63)

k +Bkq(cid:63)

k =Pkp(cid:63)
q(cid:63)

k + W −1

k BT

k

N
(cid:88)

(M k+1
i

)T li − W −1

k DT

k2lk

+ W −1

k BT

k

N −1
(cid:88)

i=k+1

(V k+1
i

i=k+1

)T Cili − W −1

k BT

k Kk+1Cklk.

Combining the above two displays, we obtain

k Kk+1Ak + Qk)p(cid:63)
(cid:40) N
(cid:88)

(M k+1
i

)T li +

i=k+1

k + 2P T

k Wk

(cid:18)

Pkp(cid:63)
k

N
(cid:88)

(V k+1
i

)T Cili

(cid:41)

i=k+1
(cid:19)

− W −1

k BT

k Kk+1Cklk − W −1

k DT

k2lk

− 2DT

k1lk

(cid:18) N
(cid:88)

+ 2AT
k

(M k+1
i

)T li +

N −1
(cid:88)

(cid:19)

(V k+1
i

)T Cili

i=k+1

− 2AT
= −2(AT

+ 2ET
k

i=k+1
k Kk+1Cklk
k Kk+1Ak + Qk − P T
(cid:18) N
(cid:88)

(M k+1
i

)T li +

k WkPk)p(cid:63)
k
N −1
(cid:88)

(cid:19)

)T Cili

(V k+1
i

i=k+1

i=k+1

− 2ET

k Kk+1Cklk − 2(Dk1 + Dk2Pk)T lk

= −2Kkp(cid:63)

k + 2

N
(cid:88)

(M k

i )T li + 2

i=k

N
(cid:88)

i=k

(V k

i )T Cili,

where the second equality follows from the deﬁnition of Ek
and the third equality follows from deﬁnitions of Kk, M k
i , and
V k
i . This veriﬁes the induction step and ﬁnishes the proof.

C. Proof of Lemma 1

We use the closed form of ζc(cid:63) established in Theorem 4. We
mention that all matrices are calculated based on { ˜Hk, ˜Dk}.
For any k ∈ [−1, N − 1], we consider two cases.
(a) l = ei for i ∈ [N ]. We then have three subcases.
(a1) i ≤ k. In this case, we apply (7) and immediately have
for some constant Υ1 > 0 that

(cid:107)ζc(cid:63)

k (cid:107) = (cid:107)−2Kk+1p(cid:63)

k+1(cid:107) ≤ 2(cid:107)Kk+1(cid:107)(cid:107)p(cid:63)

k+1(cid:107) ≤ 2Υ1Υρk+1−i.
(22)
Here, the last inequality is due to Theorem 2 that (cid:107)p(cid:63)
k+1(cid:107) ≤
Υρk+1−i, and the fact that (cid:107)Kk+1(cid:107) ≤ Υ1 for some constant
Υ1 > 0, stated precisely in [27, (4.7)].
(a2) k + 1 ≤ i ≤ N − 1. We apply (7) and have for some con-
stants Υ2, Υ3 > 0 that

(cid:107)ζc(cid:63)

k (cid:107) =(cid:107) − 2Kk+1p(cid:63)

k+1 + 2(M k+1
≤2Υ1Υρi−k−1 + 2Υ2ρi−k−1 + 2Υ3Υupperρi−k

)T ei + 2(V k+1

i

i

)T Ciei(cid:107)

≤2(Υ1Υ + Υ2 + Υ3Υupper)ρi−k−1.

The second inequality is due to (22), the fact that (cid:107)Ci(cid:107) ≤ Υupper
in Assumption 3, and the fact that

(cid:107)M k+1
i

(cid:107) ≤ Υ2ρi−k−1,

(cid:107)V k+1
i

(cid:107) ≤ Υ3ρi−k

for some constants Υ2, Υ3 > 0, stated precisely in [27, (5.11)].
(a3) i = N . Analogous to the derivations in (a2), we apply (7)
and have

k (cid:107) = (cid:107) − 2Kk+1p(cid:63)

(cid:107)ζc(cid:63)
k+1 + 2(M k+1
≤ 2Υ1ΥρN −k−1 + 2Υ2ρN −k−1 = 2(Υ1Υ + Υ2)ρN −k−1.

N )T eN (cid:107)

(b) l = e−1. Applying (7) and Theorem 2, we obtain that

(cid:107)ζc(cid:63)

k (cid:107) = (cid:107) − 2Kk+1p(cid:63)

k+1(cid:107) ≤ 2Υ1Υρk+1.

Combining the above two cases, we let Υ(cid:48) = 2(Υ1Υ + Υ2 +
Υ3Υupper) and complete the proof.

D. Proof of Theorem 5

By Lemma 1 and Theorem 3 we have for all k ∈ [−1, N −1]

that

(cid:107)ζ(cid:63)

k(cid:107) = (cid:107)ζc(cid:63)

k − 2 ¯Qk+1p(cid:63)

k (cid:107) + 2(cid:107) ¯Qk+1(cid:107)(cid:107)p(cid:63)

k+1(cid:107) ≤ (cid:107)ζc(cid:63)
By [27, Theorem 3.8, Claim 1] and [27, Lemma 4.3], we know
¯Qk+1 (which is ¯Qk+1(δ) in their context) satisﬁes (cid:107) ¯Qk+1(cid:107) ≤
ΥQ for some constant ΥQ. Thus, by Theorem 2, we can let
Υ(cid:48)(cid:48) = Υ(cid:48) + 2ΥQΥ to complete the proof.

k+1(cid:107).

REFERENCES

[1] J. Rawlings, Model predictive control : theory, computation, and design.
Madison, Wisconsin: Nob Hill Publishing, 2017, vol. 2. [Online].
Available: http://www.nobhillpublishing.com/mpc/index-mpc.html
[2] S. Qin and T. A. Badgwell, “A survey of industrial model predictive
technology,” Control Engineering Practice, vol. 11, no. 7,
control
pp. 733–764, jul 2003. [Online]. Available: https://doi.org/10.1016/
S0967-0661(02)00186-7

[3] R. Kumar, M. J. Wenzel, M. N. ElBsat, M. J. Risbeck, K. H. Drees,
and V. M. Zavala, “Stochastic model predictive control for central
HVAC plants,” Journal of Process Control, vol. 90, pp. 1–17, jun 2020.
[Online]. Available: https://doi.org/10.1016/j.jprocont.2020.03.015
[4] J. R. Jackson and I. E. Grossmann, “Temporal decomposition scheme
for nonlinear multisite production planning and distribution models,”
Industrial & Engineering Chemistry Research, vol. 42, no. 13, pp. 3045–
3055, jun 2003. [Online]. Available: https://doi.org/10.1021/ie030070p
[5] P. Falcone, F. Borrelli, J. Asgari, H. E. Tseng, and D. Hrovat,
“Predictive active steering control for autonomous vehicle systems,”
IEEE Transactions on Control Systems Technology, vol. 15, no. 3, pp.
566–580, may 2007. [Online]. Available: https://doi.org/10.1109/TCST.
2007.894653

[6] H. Shanechi, N. Pariz, and E. Vaahedi, “General nonlinear modal
representation of large scale power systems,” IEEE Transactions on
Power Systems, vol. 18, no. 3, pp. 1103–1109, aug 2003. [Online].
Available: https://doi.org/10.1109/tpwrs.2003.814883

[7] W. B. Dunbar, “Distributed receding horizon control of dynamically
coupled nonlinear systems,” IEEE Transactions on Automatic Control,
vol. 52, no. 7, pp. 1249–1263,
[Online]. Available:
https://doi.org/10.1109/TAC.2007.900828

jul 2007.

[8] J.-Q. Huang and F. Lewis, “Neural-network predictive control for
nonlinear dynamic systems with time-delay,” IEEE Transactions on
Neural Networks, vol. 14, no. 2, pp. 377–389, mar 2003. [Online].
Available: https://doi.org/10.1109/tnn.2003.809424

[9] R. Kumar, M. J. Wenzel, M. J. Ellis, M. N. ElBsat, K. H. Drees,
and V. M. Zavala, “Handling long horizons in MPC: A stochastic
programming approach,” in 2018 Annual American Control Conference
(ACC), IEEE.
IEEE, jun 2018, pp. 715–720. [Online]. Available:
https://doi.org/10.23919/acc.2018.8430780

15

[10] A. Beccuti, T. Geyer, and M. Morari, “Temporal

lagrangian
decomposition of model predictive control for hybrid systems,” in 2004
43rd IEEE Conference on Decision and Control (CDC) (IEEE Cat.
No.04CH37601), vol. 3, IEEE.
IEEE, 2004, pp. 2509–2514. [Online].
Available: https://doi.org/10.1109/cdc.2004.1428793
[11] S. Boyd, “Distributed optimization and statistical

learning via the
alternating direction method of multipliers,” Foundations and Trends®
in Machine Learning, vol. 3, no. 1, pp. 1–122, 2010. [Online]. Available:
https://doi.org/10.1561/2200000016

[12] R. Kumar, M. J. Wenzel, M. J. Ellis, M. N. ElBsat, K. H. Drees, and
V. M. Zavala, “A stochastic dual dynamic programming framework for
multiscale MPC,” IFAC-PapersOnLine, vol. 51, no. 20, pp. 493–498,
2018. [Online]. Available: https://doi.org/10.1016/j.ifacol.2018.11.041

[13] V. M. Zavala, “New architectures for hierarchical predictive control,”
IFAC-PapersOnLine, vol. 49, no. 7, pp. 43–48, 2016. [Online]. Available:
https://doi.org/10.1016/j.ifacol.2016.07.214

[14] N.-Y. Chiang, R. Huang, and V. M. Zavala, “An augmented lagrangian
ﬁlter method for real-time embedded optimization,” IEEE Transactions
on Automatic Control, vol. 62, no. 12, pp. 6110–6121, dec 2017.
[Online]. Available: https://doi.org/10.1109/tac.2017.2694806

[15] A. Kozma, C. Conte, and M. Diehl, “Benchmarking large-scale
distributed convex quadratic programming algorithms,” Optimization
Methods and Software, vol. 30, no. 1, pp. 191–214, may 2014. [Online].
Available: https://doi.org/10.1080/10556788.2014.911298

[16] I. Nielsen and D. Axehill, “An o (log n) parallel algorithm for newton
step computation in model predictive control,” IFAC Proceedings
Volumes, vol. 47, no. 3, pp. 10 505–10 511, 2014. [Online]. Available:
https://doi.org/10.3182/20140824-6-ZA-1003.01577

[17] ——, “A parallel structure exploiting factorization algorithm with
applications to model predictive control,” in 2015 54th IEEE Conference
on Decision and Control (CDC), IEEE.
IEEE, dec 2015, pp. 3932–3938.
[Online]. Available: https://doi.org/10.1109/CDC.2015.7402830

[18] F. Laine and C. Tomlin, “Parallelizing LQR computation through
endpoint-explicit riccati recursion,” in 2019 IEEE 58th Conference on
Decision and Control (CDC), IEEE.
IEEE, dec 2019, pp. 1395–1402.
[Online]. Available: https://doi.org/10.1109/CDC40024.2019.9029974

[19] S. J. Wright, “Solution of discrete-time optimal control problems on
parallel computers,” Parallel Computing, vol. 16, no. 2-3, pp. 221–237,
dec 1990. [Online]. Available: https://doi.org/10.1016/0167-8191(90)
90060-M

[20] C. V. Rao, S. J. Wright, and J. B. Rawlings, “Application of interior-point
methods to model predictive control,” Journal of Optimization Theory
and Applications, vol. 99, no. 3, pp. 723–757, dec 1998. [Online].
Available: https://doi.org/10.1023/A:1021711402723

[21] W. Wan, J. P. Eason, B. Nicholson, and L. T. Biegler, “Parallel
cyclic reduction decomposition for dynamic optimization problems,”
Computers & Chemical Engineering, vol. 120, pp. 54–69, jan 2019.
[Online]. Available: https://doi.org/10.1016/j.compchemeng.2017.09.023
[22] J. Kang, N. Chiang, C. D. Laird, and V. M. Zavala, “Nonlinear
programming strategies on high-performance computers,” in 2015 54th
IEEE Conference on Decision and Control (CDC), IEEE.
IEEE, dec
2015, pp. 4612–4620. [Online]. Available: https://doi.org/10.1109/CDC.
2015.7402938

[23] G. Frison and J. B. Jorgensen, “Efﬁcient

implementation of the
riccati recursion for solving linear-quadratic control problems,” in
2013 IEEE International Conference on Control Applications (CCA),
IEEE.
[Online]. Available:
https://doi.org/10.1109/CCA.2013.6662901

IEEE, aug 2013, pp. 1117–1122.

[24] C. Barrows, M. Hummon, W. Jones, and E. Hale, “Time domain
partitioning of electricity production cost simulations,” National
Renewable Energy Lab.(NREL), Golden, CO (United States), jan 2014.
[Online]. Available: https://doi.org/10.2172/1123223

[25] W. Xu and M. Anitescu, “Exponentially accurate temporal decomposition
for long-horizon linear-quadratic dynamic optimization,” SIAM Journal
on Optimization, vol. 28, no. 3, pp. 2541–2573, jan 2018. [Online].
Available: https://doi.org/10.1137/16M1081993

[26] S. Shin, T. Faulwasser, M. Zanon, and V. M. Zavala, “A parallel
decomposition scheme for solving long-horizon optimal control
problems,” in 2019 IEEE 58th Conference on Decision and Control
(CDC).
[Online]. Available:
https://doi.org/10.1109/cdc40024.2019.9030139

IEEE, dec 2019, pp. 5264–5271.

[27] S. Na and M. Anitescu, “Exponential decay in the sensitivity analysis
of nonlinear dynamic programming,” SIAM Journal on Optimization,
vol. 30, no. 2, pp. 1527–1554,
[Online]. Available:
https://doi.org/10.1137/19M1265065

jan 2020.

[28] S. Shin, C. Coffrin, K. Sundar, and V. M. Zavala, “Graph-based
modeling and decomposition of energy infrastructures,” arXiv preprint

arXiv:2010.02404, 2020. [Online]. Available: https://arxiv.org/abs/2010.
02404

[29] S. Na and M. Anitescu, “Superconvergence of online optimization
for model predictive control,” arXiv preprint arXiv:2001.03707, 2020.
[Online]. Available: https://arxiv.org/abs/2001.03707

[30] T. Ohtsuka, “A continuation/GMRES method for fast computation
of nonlinear receding horizon control,” Automatica, vol. 40, no. 4,
pp. 563–574, apr 2004. [Online]. Available: https://doi.org/10.1016/j.
automatica.2003.11.005

[31] M. Diehl, H. G. Bock, and J. P. Schl¨oder, “A real-time iteration scheme
for nonlinear optimization in optimal feedback control,” SIAM Journal
on Control and Optimization, vol. 43, no. 5, pp. 1714–1736, jan 2005.
[Online]. Available: https://doi.org/10.1137/S0363012902400713
[32] V. M. Zavala and L. T. Biegler, “The advanced-step NMPC controller:
Optimality, stability and robustness,” Automatica, vol. 45, no. 1, pp.
86–93, jan 2009. [Online]. Available: https://doi.org/10.1016/j.automatica.
2008.06.011

[33] V. M. Zavala and M. Anitescu, “Real-time nonlinear optimization as
a generalized equation,” SIAM Journal on Control and Optimization,
[Online]. Available:
vol. 48, no. 8, pp. 5444–5467,
https://doi.org/10.1137/090762634

jan 2010.

[34] D. Collet, M. Alamir, D. D. Domenico, and G. Sabiron, “Non quadratic
smooth model of fatigue for optimal fatigue-oriented individual pitch
control,” in Journal of Physics: Conference Series, vol. 1618, no. 2, IOP
Publishing.
IOP Publishing, sep 2020, p. 022004. [Online]. Available:
https://doi.org/10.1088/1742-6596/1618/2/022004

[35] M. Hong, Z.-Q. Luo, and M. Razaviyayn, “Convergence analysis of
alternating direction method of multipliers for a family of nonconvex
problems,” SIAM Journal on Optimization, vol. 26, no. 1, pp. 337–364,
jan 2016. [Online]. Available: https://doi.org/10.1137/140990309
[36] Y. Wang, W. Yin, and J. Zeng, “Global convergence of ADMM in
nonconvex nonsmooth optimization,” Journal of Scientiﬁc Computing,
vol. 78, no. 1, pp. 29–63,
jun 2018. [Online]. Available: https:
//doi.org/10.1007/s10915-018-0757-z

[37] S. Shin and V. M. Zavala, “Diffusing-horizon model predictive
control,” arXiv preprint arXiv:2002.08556, 2020. [Online]. Available:
https://arxiv.org/abs/2002.08556

[38] L. Gr¨une, M. Schaller, and A. Schiela, “Efﬁcient mpc for parabolic pdes
with goal oriented error estimation,” arXiv preprint arXiv:2007.14446,
2020. [Online]. Available: https://arxiv.org/abs/2007.14446

[39] L. Gr¨une, M. Schaller, and A. Schiela, “Abstract nonlinear sensitivity
and turnpike analysis and an application to semilinear parabolic PDEs,”
ESAIM: Control, Optimisation and Calculus of Variations, vol. 27, p. 56,
2021. [Online]. Available: https://doi.org/10.1051/cocv/2021030
[40] S. S. Keerthi and E. G. Gilbert, “Optimal inﬁnite-horizon feedback laws
for a general class of constrained discrete-time systems: Stability and
moving-horizon approximations,” Journal of Optimization Theory and
Applications, vol. 57, no. 2, pp. 265–293, may 1988. [Online]. Available:
https://doi.org/10.1007/bf00938540

[41] J. F. Bonnans and A. Shapiro, Perturbation Analysis of Optimization
Springer New York, 2000. [Online]. Available: https:

Problems.
//doi.org/10.1007/978-1-4612-1394-9

[42] J. Nocedal and S. J. Wright, Numerical Optimization, 2nd ed., ser.
Springer Series in Operations Research and Financial Engineering.
Springer New York, 2006. [Online]. Available: https://doi.org/10.1007/
978-0-387-40065-5

[43] R. Verschueren, M. Zanon, R. Quirynen, and M. Diehl, “A sparsity
preserving convexiﬁcation procedure for indeﬁnite quadratic programs
arising in direct optimal control,” SIAM Journal on Optimization,
vol. 27, no. 3, pp. 2085–2109,
[Online]. Available:
https://doi.org/10.1137/16m1081543

jan 2017.

[44] M. Diehl, R. Findeisen, H. Bock, F. Allg¨ower, and J. Schl¨oder,
“Nominal stability of real-time iteration scheme for nonlinear model
predictive control,” IEE Proceedings - Control Theory and Applications,
[Online]. Available:
vol. 152, no. 3, pp. 296–308, may 2005.
https://doi.org/10.1049/ip-cta:20040008

[45] S. M. Robinson, “Perturbed kuhn-tucker points and rates of convergence
for a class of nonlinear-programming algorithms,” Mathematical
Programming, vol. 7, no. 1, pp. 1–16, dec 1974. [Online]. Available:
https://doi.org/10.1007/bf01585500

[46] M. Hehn and R. D’Andrea, “A ﬂying inverted pendulum,” in
2011 IEEE International Conference on Robotics and Automation,
IEEE.
IEEE, may 2011, pp. 763–770. [Online]. Available: https:
//doi.org/10.1109/icra.2011.5980244

[47] H. Deng and T. Ohtsuka, “A parallel newton-type method for nonlinear
model predictive control,” Automatica, vol. 109, p. 108560, nov 2019.
[Online]. Available: https://doi.org/10.1016/j.automatica.2019.108560

16

[48] “Nonlinear

heat

transfer
https://www.mathworks.com/help/pde/ug/nonlinear-heat-transfer-
in-a-thin-plate.html. [Online]. Available: https://www.mathworks.com/
help/pde/ug/nonlinear-heat-transfer-in-a-thin-plate.html

plate,”

thin

in

[49] J. S. Rodriguez, B. Nicholson, C. Laird, and V. M. Zavala,
“Benchmarking ADMM in nonconvex NLPs,” Computers & Chemical
Engineering, vol. 119, pp. 315–325, nov 2018. [Online]. Available:
https://doi.org/10.1016/j.compchemeng.2018.08.036

[50] A. W¨achter and L. T. Biegler, “On the implementation of an interior-point
ﬁlter line-search algorithm for large-scale nonlinear programming,”
Mathematical Programming, vol. 106, no. 1, pp. 25–57, apr 2005.
[Online]. Available: https://doi.org/10.1007/s10107-004-0559-y

[51] A. HSL, “collection of Fortran codes for

large-scale scientiﬁc
computation,” See http://www. hsl. rl. ac. uk, 2007. [Online]. Available:
http://www.hsl.rl.ac.uk/

Sen Na is a ﬁfth-year Ph.D. student in the Department of Statistics at the
University of Chicago under the supervision of Mihai Anitescu and Mladen
Kolar. Before coming to UChicago, he received B.S. degree in mathematics
from Nanjing University, China. His research interests lie in nonlinear dynamic
programming, high-dimensional statistics, semiparametric modeling, and their
interface. He is also serving as a reviewer of the SIAM Journal on Optimization,
and Journal of Machine Learning Research.

Sungho Shin is a Ph.D. candidate in the Department of Chemical and
Biological Engineering at the University of Wisconsin-Madison. He received his
B.S. in chemical engineering and mathematics from Seoul National University,
South Korea, in 2016. His research interests include control theory and
optimization algorithms for complex networks.

Mihai Anitescu is a senior computational mathematician in the Mathematics
and Computer Science Division at Argonne National Laboratory and a professor
in the Department of Statistics at the University of Chicago. He obtained his
engineer diploma (electrical engineering) from the Polytechnic University of
Bucharest in 1992 and his Ph.D. in applied mathematical and computational
sciences from the University of Iowa in 1997. He specializes in the areas
of numerical optimization, computational science, numerical analysis, and
uncertainty quantiﬁcation. He is on the editorial board of the SIAM Journal on
Optimization, and he is a senior editor for Optimization Methods and Software.
He is a past member of the editorial boards of Mathematical Programming A
and B, SIAM Journal on Scientiﬁc Computing, and SIAM/ASA Journal in
Uncertainty Quantiﬁcation.

Victor M. Zavala is the Baldovin-DaPra Associate Professor in the Department
of Chemical and Biological Engineering at the University of Wisconsin-
Madison. He holds a B.Sc. degree from Universidad Iberoamericana and a
Ph.D. degree from Carnegie Mellon University, both in chemical engineering.
He is an associate editor for the Journal of Process Control and for IEEE
Transactions on Control and Systems Technology. He is also a technical editor
of Mathematical Programming Computation. His research interests are in the
areas of energy systems, high-performance computing, stochastic programming,
and predictive control.

Government License: The submitted manuscript has been created by UChicago
Argonne, LLC, Operator of Argonne National Laboratory (“Argonne”). Argonne, a
U.S. Department of Energy Ofﬁce of Science laboratory, is operated under Contract
No. DE-AC02-06CH11357. The U.S. Government retains for itself, and others acting
on its behalf, a paid-up nonexclusive, irrevocable worldwide license in said article
to reproduce, prepare derivative works, distribute copies to the public, and perform
publicly and display publicly, by or on behalf of the Government. The Department of
Energy will provide public access to these results of federally sponsored research in
accordance with the DOE Public Access Plan. http://energy.gov/downloads/doe-public-
access-plan.

