On Generating and Labeling Network Trafﬁc with
Realistic, Self-Propagating Malware

Molly Buchanan, Jeffrey W. Collyer, Jack W.
Davidson, Jason D. Hiser, Alastair Nottingham
University of Virginia, Charlottesville, VA, U.S.A.
{mkb4vb,jwc3f,jwd,hiser,atn5vs}@virginia.edu

Saikat Dey, Mark Gardner, Jeffry Lang
Virginia Tech, Blacksburg, VA, U.S.A.
{dsaikat,mkg,jefﬂang}@vt.edu

Alina Oprea
Northeastern University,
Boston, MA, U.S.A.
a.oprea@northeastern.edu

2
2
0
2

y
a
M
7
2

]

R
C
.
s
c
[

2
v
4
3
0
0
1
.
4
0
1
2
:
v
i
X
r
a

Abstract—Research and development of

techniques which
detect or remediate malicious network activity require access to
diverse, realistic, contemporary data sets containing labeled ma-
licious connections. In the absence of such data, said techniques
cannot be meaningfully trained, tested, and evaluated. Synthet-
ically produced data containing fabricated or merged network
trafﬁc is of limited value as it is easily distinguishable from real
trafﬁc by even simple machine learning (ML) algorithms. Real
network data is preferable, but while ubiquitous is broadly both
sensitive and lacking in ground truth labels, limiting its utility
for ML research.

This paper presents a multi-faceted approach to generating
a data set of labeled malicious connections embedded within
anonymized network trafﬁc collected from large production
networks. Real-world malware is defanged and introduced to
simulated, secured nodes within those networks to generate
realistic trafﬁc while maintaining sufﬁcient isolation to protect
real data and infrastructure. Network sensor data, including this
embedded malware trafﬁc, is collected at a network edge and
anonymized for research use.

Network trafﬁc was collected and produced in accordance
with the aforementioned methods at two major educational
institutions. The result is a highly realistic, long term, multi-
institution data set with embedded data labels spanning over
1.5 trillion connections and over a petabyte of sensor log data.
The usability of this data set is demonstrated by its utility to
our artiﬁcial intelligence and machine learning (AI/ML) research
program.

Index Terms—Artiﬁcial Intelligence, Machine Learning, Cyber

security, Network Data Collection, Attack Recreation, Mirai

I. INTRODUCTION

Computing networks face a variety of attacks, but large
network trafﬁc volumes and the need to keep connected
devices operational make it infeasible for limited personnel to
manually detect and respond to every attack. Though desirable,
automatic or semi-automatic attack detection and remediation
techniques are difﬁcult to develop due to the dearth of publicly
available, representative data sets [1]. Considering their ability
to model network trafﬁc and pick out unusual patterns, AI/ML
techniques are particularly suited to automatic network attack
detection. AI methods can be supervised (learning to classify
malicious and benign trafﬁc) [2], [3], or unsupervised (learning
the normal trafﬁc distribution and detecting anomalies) [4], [5].

The research reported in this document/presentation was performed in
connection with contract number W911NF-18-C- 0019 with the U.S. Army
Contracting Command - Aberdeen Proving Ground (ACC-APG) and the
Defense Advanced Research Projects Agency (DARPA).

Supervised AI techniques rely on the availability of ground
truth samples of malicious trafﬁc for training; both methods
need malicious samples for testing and evaluation. However,
infected machines usually generate copious legitimate trafﬁc,
thus necessitating ﬁne-grained labeling of the exclusively
malicious activity. One of the main challenges in developing
AI/ML for network security is obtaining realistic network
trafﬁc including benign and malicious connections with ﬁne-
grained labeling [6].

Of course, one cannot simply permit unmodiﬁed malware
to infect in-use machines and record the ensuing trafﬁc to
generate the necessary data. A real-world network cannot
reasonably and responsibly risk the operational interruption
and data loss that malware can cause. But continuously
recording trafﬁc and waiting for an inevitable infection is also
insufﬁcient due to the uncertainty and difﬁculty of correctly
identifying malicious trafﬁc. Modern tools like VirusTotal are
not adequately accurate to provide sufﬁcient information to
determine which network nodes were infected and when, or
which trafﬁc from said nodes was malicious [7].

To address the AI/ML requirements and concerns of using
real malware on a real network, these data sets can be gener-
ated by introducing defanged malware into the real network
and capturing and anonymizing the resulting trafﬁc, which will
include a realistic mix of benign and malicious trafﬁc. The
remainder of the paper describes how this goal was achieved
to facilitate AI/ML research and experimentation.
The major contributions of this work are:

• a workable system to capture and anonymize network

trafﬁc,

• a model to safely deploy malware in a real network,

including a realization of the Mirai virus, and

• a model for ﬁne-grained labeling of the generated mali-

cious trafﬁc in the network capture.

II. ANONYMOUS DATA COLLECTION AND USE

This section brieﬂy explores the collection and anonymiza-
tion of enterprise scale network sensor data to produce a
diverse, realistic, long-term data set for developing and training
machine learning algorithms and AI approaches.

The data set is composed of anonymized network sensor
data from two large, disjoint, and geographically separated
enterprise networks at the University of Virginia (UVA) and

 
 
 
 
 
 
Virginia Tech (VT); these networks differ in topology, service
and application ecosystems, and baseline behavior. Figure 1
provides an overview of the data collection and anonymization
process.

UVA

VT

Network Border Trafﬁc

IPv6
NAT Type [11]

Zeek
FireEye
STINGAR
NAT, DHCP, Asset

No
Carrier Grade NAT
Sensor Logs

Yes [Corelight [12]]
Yes
Yes
Yes

Yes
Traditional NAT

Yes [Custom]
No
Yes
No

Connections Records
Total Volume

Current Zeek Dataset (Combined)

~1.5 Trillion
~1 Petabyte

TABLE I
SUMMARY OF UVA AND VT DATA COLLECTION.

B. Log Anonymization

Collected network sensor data contains signiﬁcant PII (Per-
sonally Identiﬁable Information) and other sensitive informa-
tion. To protect network users and organizational security,
sensitive ﬁelds must be obfuscated or removed from logs
before the data set can be made accessible to researchers.
Anonymization through overwriting or otherwise destroying
ﬁeld data [13], [14], while effective, signiﬁcantly reduces
the ﬁdelity of anonymized records [15]. In particular, ﬁelds
anonymized by destructive methods cannot be leveraged ef-
fectively in inter-record and cross-network comparisons.

To retain a measure of ﬁdelity and comparability in ﬁeld
data, the removal or destruction of ﬁeld values is avoided
wherever possible. Instead, a combination of careful ﬁeld
parsing and one-way cryptographic functions are used to elim-
inate identifying data while preserving many of the features
and patterns inherent in the raw logs. Such functions include
preﬁx preserving IP address anonymization [16], [17] and
custom hash-based functions for other ﬁeld types. Hashes use
a 256-bit secret key as salt to (a) add entropy to ﬁelds and
protect against collision-based attacks on anonymization and
(b) ensure consistency across log types and institutions over
time. Anonymization is subject to extensive testing to identify
emergent issues, and is regularly updated and improved. When
necessary, archived logs are re-anonymized to take advantage
of new features and correct identiﬁed anonymization errors.

While every effort is made to ensure all data elements are
correctly anonymized, the complex nature of the produced
data set presents an unavoidable known risk of anonymization
errors in edge cases. This risk is addressed through mitigating
policy and infrastructure-based controls to protect edge cases
when anonymization is insufﬁcient or otherwise fails.

To this end, sensor data is only made available on Sentinel:
a dedicated, access-controlled High Performance Computing
(HPC) cluster provisioned to support AI/ML research (see
Figure 1). Data access is limited to approved researchers
and subject to restrictions that prohibit data exﬁltration and
govern how records may be used in publications. Anonymized
sensor data is published daily (i) as compressed ﬁles, (ii) in
Apache Kafka [18] as a message streams, and (iii) in Apache
Druid [19] which supports fast SQL-like (Structured Query
Language-like) queries. Figure 2 provides a high-level view
of the data set available on Sentinel.

As the data collected at the network edge is composed of
real trafﬁc from institutions that actively defend their networks,

Fig. 1. Overview of the collection, anonymization and processing of network
sensor data.
A. Data Collection

The generated data set includes a variety of network sensor
and appliance logs that collectively provide a detailed trace
of the network state and user/device behavior. While packet
traces may provide a more complete view of network behavior
and additional metrics, sensor logs are preferred because
they are (a) pre-aggregated and normalized, which simpliﬁes
anonymization without sacriﬁcing application level detail, (b)
appreciably smaller and more compressible, making long term
storage less expensive, and (c) signiﬁcantly less computation-
ally expensive and complicated to process at enterprise scale.
Zeek [8] provides the primary source of network activity
data; it generates a wide selection of inter-connected logs
across a broad range of protocols and ﬁeld types. Zeek logs
are supplemented by a range of other sensor and appliance
logs that provide context regarding the network’s state. These
include logs generated by FireEye [9] — which enumerate
detected threats such as known malware callbacks — and
STINGAR honeypot logs [10] — which provide community-
sourced threat intelligence from a distributed honeypot net-
work. Together, these provide a valuable source of ground
truth to seed discovery of natural malicious behavior in Zeek
logs. UVA additionally collects NAT [11] (Network Address
Translation), DHCP (Dynamic Host Conﬁguration Protocol),
and asset registration logs to map between public and private
addresses.

The creation of this data set is achieved through partnership
with and oversight from Information Security departments and
professionals at UVA and VT. As network trafﬁc transitions
across the UVA and VT network edges, trafﬁc is mirrored
through a packet broker to sensor appliances within the
respective networks for log creation. All logs are archived,
allowing future retrieval and reprocessing when necessary.

Though collection is broadly similar at both institutions,
it differs in trafﬁc composition,
the types and placement
of sensor appliances, and how data is transitioned through
anonymization to be made accessible to researchers. Some of
the primary differences between UVA and VT data collection
are shown in Table I.

2

Fig. 2. Data volume and number of distinct connections per day for the
combined Zeek data set. It currently takes between 30 and 45 minutes to
anonymize a days worth of trafﬁc at a given institution using a single server.
actual instances of known malware campaigns and malicious
trafﬁc are uncommon. The following sections present a method
for safely and realistically introducing attack trafﬁc into sensor
logs through attack recreation exercises. These provide addi-
tional and veriﬁable ground truth for malicious activity in the
data set.

III. ATTACK RECREATION

A key aspect of the proposed data set production approach
is the introduction of realistic malware trafﬁc to the network.
Said generated trafﬁc should combine with the network’s
natural trafﬁc using standard network protocols, yet machines
and appliances should be secure from compromise. To achieve
this balance of realism and safety, real-world malware is
defanged and carefully deployed on real networked systems.
This approach has two key advantages. First, as malware
trafﬁc is naturally mixed in the network, no artifacts from
mixing are evident in the data set. This feature is important be-
cause otherwise machine learners can easily determine which
trafﬁc is which by examining artifacts unintentionally added
during the trafﬁc merging process. Second, the malware never
resides on operational systems with sensitive data. This feature
is essential to obtain permission for deployment from network
operators, as normal network operation can not be interrupted,
and intentional data exposure will not be tolerated.

As a proof of concept, the Mirai virus was defanged and de-
ployed on the University of Virginia (UVA) and Virginia Tech
(VT) networks. Mirai, as depicted in Figure 3, operates by
leveraging already infected nodes to scan the network to locate
new nodes that respond to telnet or ssh. It then brute-forces
the passwords using a built-in dictionary of common/default
credentials [20], [21]. When a new vulnerable node is detected,
an infected node reports this to the report server, which
instructs the malware loader to infect the vulnerable node.
After infection, the vulnerable node reports to the command
and control server as a bot; at this point, the bot master can
leverage the new addition to its botnet for other purposes, such
as a DDoS attack.

Mirai is an excellent candidate for experimentation because
it was particularly successful real-world malware, variants of
which continue to be seen in the wild. Mirai infected over
65,000 on its ﬁrst day of deployment and totaled over 600,000
nodes at its peak. Additionally, since Mirai and its control

Fig. 3. Mirai malware, as deployed for collecting datasets
components were open-sourced, it was easy to safely defang.
Mirai was defanged by: 1) Removing portions of the infection
that might cause damage. 2) Replacing the default credential
dictionary with 20 and 25 character randomly-selected alpha-
numeric usernames and passwords, respectively, which were
statistically unlikely to match any real-world accounts. 3)
Adjusting the malware loader to safeguard user nodes by only
permitting infection of nodes in the pre-selected vulnerable
nodes pool. 4) Limiting scanning trafﬁc to permissible and
non-critical nodes - for example, UVA’s hospital system is not
scanned.

To provide further evidence to the UVA and VT network
and security groups, unit and integration tests were developed
for defanged components. Test deployments in a sandbox
veriﬁed that only acceptable IPs would be contacted. While
these techniques are speciﬁc to Mirai, safely handling other
malware should be possible, especially via careful application
of network ﬁrewall rules.

The precautions installed in Mirai were sufﬁcient to con-
vince UVA and VT’s network operation centers to allow Mirai
to scan a large subset of public IP space. The defanged Mirai
has scanned a large swath of over 500,000 IPs at UVA and
VT.

Nodes sending only malicious trafﬁc might be conspicuous
to machine learners, so the Caldera human plugin was run to
add mitigating benign trafﬁc. The plugin randomly browses
websites, performs google searches of random sentences, and
provides realistic delays between operations [22]–[24].

To mimic an outside attacker’s command and control (C2)
server, C2 components were positioned on the third-party
NSF-funded Chameleon Cloud system [25]. Trafﬁc generated
as infected nodes in each network contact external C2 com-
ponents or scan vulnerable nodes in the adjacent network is
collected as it transits the network edge, resulting in realistic
merging of the attack trafﬁc in sensor logs.

IV. GENERATED LABELED TRAFFIC

A key requirement for both training and evaluating AI/ML
algorithms is labeled data. Each connection captured in the
anonymized logs includes associated metadata which deter-
mines whether it was natural trafﬁc on the network or gen-
erated during the attack recreation. Ideally, separate labels

3

InfectedNodesMalware LoaderReport ServerCommand & ControlC2 ComponentsUser NodesVuln.NodesScanningInfectionFound Vuln.Bot Masterwould be generated for each phase of the attack; for example,
scanning trafﬁc might be labeled differently than infection
trafﬁc that downloads malware to a new system.

In this experimental setup, such labels can typically be
applied in a post-hoc manner by inspecting particular ﬁelds
in the network trafﬁc and applying a set of simple heuristics.
If Mirai uses port 80 of a particular web server to download the
malware from a particular set of URLs, simply ﬁlter trafﬁc that
matches those criteria and label them as malware download
trafﬁc.

A library was developed to label trafﬁc captured during a
Mirai attack recreation event according to the aforementioned
ﬁltering technique. For the defanged Mirai, scanning trafﬁc
occurs on ports 23 and 2323, virus download happens from
a web sever set up on port 80, and C2 communication
happens on ports 23 and 48101. Furthermore, a record is kept
of the (anonymized) IPs of all the vulnerable nodes in the
experiment. Any trafﬁc not to or from these IPs is labeled
as natural. Trafﬁc to/from these IPs which matches one of
the above rules is labeled as indicated; other trafﬁc from the
experimental nodes is labeled as generated, benign trafﬁc.

These simple rules were able to label 99.9% of all trafﬁc
during a 6 hour experiment. Only a handful of unlabeled
connections remained, all of which seemed to be oddities
of the capture process (e.g., when trafﬁc capture was started
during an already active connection).

One might wonder whether the network’s natural trafﬁc
is benign or could contain trafﬁc from an infected node.
In a network of sufﬁcient size and complexity, it is likely
that some trafﬁc is malicious (hence the application of the
natural rather than benign label.) However, the trafﬁc labeled
malicious during attack recreations is veriﬁable so, and can
be accurately used for training and evaluation of AI/ML
techniques. Further, during evaluation of a (good) algorithm,
little trafﬁc should be detected as malicious; such trafﬁc can
(and should) be analyzed by an expert to determine whether
it is truly malicious or a false positive detection. In fact,
this type of event happened during the associated AI/ML
research, where previously unknown malware was detected in
the network.

The labeled Mirai attack was used to evaluate an ML-
based system for self-propagating malware detection [5].
The PORTFILER system creates aggregated network trafﬁc
features for a set of monitored ports, learns the legitimate
network proﬁles on those ports during training in an unsu-
pervised manner, and detects and ranks anomalies at testing
time. Labeling the different attack stages (e.g., scanning, C2)
was particularly useful for evaluating this detector. In use,
PORTFILER detected scanning trafﬁc with high precision
and recall and low false positive rates; detection results were
more accurate at higher scanning rates. The detailed analysis
of PORTFILER’s performance was made possible by ﬁne-
grained labeling of individual connections and attack stages.
Moreover, by analyzing the trafﬁc of all infected machines, it
was possible to identify and conﬁrm the C2 server IP based on
the number of connections on port 23 and the large duration

of those connections compared to legitimate connections. In
future experiments, likewise defanged evasive variants of Mirai
and other malware will be generated, and novel ML techniques
will be developed to detect them more robustly.

V. RELATED WORK

While IP address anonymization is well understood [16],
[17], [26] and signiﬁcant related work exists in the area of net-
work trafﬁc anonymization, most approaches focus on packet
traces. A wide variety of approaches to trace anonymization
have been developed, both in software [13], [14], [27]–[33],
and in hardware [26], [34], [35], although many of these ap-
proaches are now defunct. While some implementations focus
on appliance and service logs [36]–[40], these approaches
are typically quite destructive as they are intended for broad
sharing. Published available data sets [41]–[43] tend to have
a limited duration, are more specialized and/or synthetic, and
are not representative of normal enterprise trafﬁc [1].

Previous work on generating and labeling data synthetically
also exists [44]–[48]. Synthetic techniques suffer to various
degrees with artiﬁcial artifacts, but
issues with unrealistic
data have been generally accepted in light of the working
assumption that real data on real networks is too cumbersome
to generate and too sensitive to provide to researchers. The
approach outlined in this paper contrasts said assumption by
demonstrating the viability of a more natural means of data
production and illustrating its successful use in ML research.

VI. FUTURE WORK AND SUMMARY

A good way to create data sets for AI/ML training and
evaluation is to outﬁt existing networks for collection and
anonymization. This approach can be achieved with commod-
ity hardware and software solutions. Malicious trafﬁc can be
carefully added to the existing network by defanging real
malware and controlling where in the network it is deployed.
Labeling the trafﬁc can be achieved through simple heuristics
based on knowledge of the malware’s behavior and the known
IPs of the infected machines.

Utilizing this approach and working with UVA and VT’s
network operators, extant networks were instrumented, trafﬁc
collection and anonymization were measured, defanged Mirai
was deployed, and secure access infrastructure for researchers
was provided. Simple labeling heuristics were able to generate
useful labels for internal research programs; their success in
using the produced data set to train models that detected
malware demonstrates the proposed approach’s feasibility.

In the future, the range of collected sensor data will be
expanded, and ﬁeld coverage for anonymization will continue
to be reﬁned and improved. In particular, incorporation of
host-based sensor data is planned to supplement network
logs. Additionally, there are plans to leverage Mitre’s Caldera
infrastructure to deploy more sophisticated, subtle attacks [24].

ACKNOWLEDGMENTS

The authors would like to thank the late Dr. Malathi
Veeraraghavan for her signiﬁcant contributions to this work.

4

REFERENCES

[1] W. Haider, J. Hu, J. Slay, B. Turnbull, and Y. Xie, “Generating realistic
intrusion detection system dataset based on fuzzy qualitative modeling,”
J. Netw. Comput. Appl., vol. 87, pp. 185–192, 2017.

[2] L. Bilge, S. Sen, D. Balzarotti, E. Kirda, and C. Kruegel, “Exposure: A
passive DNS analysis service to detect and report malicious domains,”
ACM Trans. Inf. Syst. Secur., vol. 16, no. 4, Apr. 2014. [Online].
Available: https://doi.org/10.1145/2584679

[3] A. Oprea, Z. Li, R. Norris, and K. Bowers, “MADE: Security analytics
for enterprise threat detection,” in In 34th Annual Computer Security
Applications Conference, 2018, pp. 124–136.

[4] T.-F. Yen, A. Oprea, K. Onarlioglu, T. Leetham, W. Robertson, A. Juels,
and E. Kirda, “Beehive: Large-scale log analysis for detecting suspicious
activity in enterprise networks,” in In 29th Annual Computer Security
Applications Conference, 2013, pp. 199–208.

[5] T. Ongun, O. Spohngellert, B. Miller, S. Boboila, A. Oprea,
T. Eliassi-Rad, J. Hiser, A. Nottingham, J. Davidson, and M. Veer-
araghavan,
self-
propagating malware detection,” https://www.ccs.neu.edu/home/tongun/
ﬁles/TrafﬁcProﬁler.pdf, 2021.

“PORTFILER: Port-level network proﬁling for

[6] R. Sommer and V. Paxson, “Outside the closed world: On using
machine learning for network intrusion detection,” in Proceedings of
the 2010 IEEE Symposium on Security and Privacy, ser. SP ’10.
USA: IEEE Computer Society, 2010, p. 305–316. [Online]. Available:
https://doi.org/10.1109/SP.2010.25
[7] (2021) The VirusTotal website.

[Online]. Available: https://www.

virustotal.com/

[8] The Bro Project, “The Zeek Network Security Monitor,” Online, 2021.

[Online]. Available: https://www.zeek.org/

[9] FireEye, Inc., “FireEye,” Online, 2021. [Online]. Available: https:

//www.ﬁreeye.com/

[10] Duke STINGAR, “Shared Threat Intelligence for Network Gatekeeping
and Automated Response,” Online, last Updated: 10/2020. [Online].
Available: https://stingar.security.duke.edu/

[11] K. B. Egevang and P. Srisuresh, “RFC3022: Traditional IP Network

Address Translator (Traditional NAT),” USA, 2001.

[12] Corelight,

Inc.,
https://www.corelight.com/

“Corelight,” Online, 2021.

[Online]. Available:

[13] ISI, “dag scrubber,” Online, Jan. 2016. [Online]. Available: https:

//ant.isi.edu/software/dag scrubber/index.html

[14] W. Yurcik, C. Woolam, G. Hellings, L. Khan, and B. Thuraisingham,
“SCRUB-tcpdump: A multi-level packet anonymizer demonstrating pri-
vacy/analysis tradeoffs,” in 2007 Third International Conference on
Security and Privacy in Communications Networks and the Workshops
- SecureComm 2007, Sep. 2007, pp. 49–56.

[16] J. Fan,

[15] W. Brockelsby and R. Dutta, “A Graded Approach to Network Forensics
with Privacy Concerns,” in 2019 International Conference on Comput-
ing, Networking and Communications (ICNC), Feb 2019, pp. 292–297.
“Preﬁx-
preserving ip address anonymization: measurement-based security
evaluation and a new cryptography-based scheme,” Computer Networks,
[Online]. Available:
vol. 46, no. 2, pp. 253 – 272, 2004.
http://www.sciencedirect.com/science/article/pii/S1389128604001197

J. Xu, M. H. Ammar,

and S. B. Moon,

[17] Y. Pradkin, “cryptopANT IP Address Anonymization Library,” Online,
[Online]. Available: https://ant.isi.edu/software/cryptopANT/

2018.
index.html

[18] Apache Software Foundation, “Apache kafka,” Online, 2021. [Online].

Available: https://kafka.apache.org/
[19] ——, “Apache druid,” Online, 2021.

//druid.apache.org/

[Online]. Available: https:

[20] C. Kolias, G. Kambourakis, A. Stavrou, and J. Voas, “DDoS in the IoT:

Mirai and other botnets,” Computer, vol. 50, no. 7, pp. 80–84, 2017.

[21] M. Antonakakis, T. April, M. Bailey, M. Bernhard, E. Bursztein,
J. Cochran, Z. Durumeric, J. A. Halderman, L. Invernizzi, M. Kallitsis
et al., “Understanding the mirai botnet,” in 26th {USENIX} security
symposium ({USENIX} Security 17), 2017, pp. 1093–1110.

[22] (2021) The Caldera Human Plugin on GitHub. [Online]. Available:

https://github.com/mitre/human

[23] J. A. Booz, “Towards scalable automated vulnerability scanning &
exploitation,” Ph.D. dissertation, Carnegie Mellon University, 2020.

[24] (2021) Mitre’s Caldera on GitHub.

[Online]. Available: https:

//github.com/mitre/caldera

[25] K. Keahey, J. Anderson, Z. Zhen, P. Riteau, P. Ruth, D. Stanzione,
M. Cevik, J. Colleran, H. S. Gunawi, C. Hammock, J. Mambretti,
A. Barnes, F. Halbach, A. Rocha, and J. Stubbs, “Lessons learned from
the chameleon testbed,” in Proceedings of the 2020 USENIX Annual
Technical Conference (USENIX ATC ’20). USENIX Association, July
2020.

[26] H. Kim and A. Gupta, “ONTAS: Flexible and Scalable Online
Network Trafﬁc Anonymization System,” in Proceedings of
the
2019 Workshop on Network Meets AI & ML, ser. NetAI’19. New
York, NY, USA: ACM, 2019, pp. 15–21.
[Online]. Available:
http://doi.acm.org/10.1145/3341216.3342208

[27] Y. Lin, P. Lin, S. Wang, I. Chen, and Y. Lai, “PCAPLib: A System of
Extracting, Classifying, and Anonymizing Real Packet Traces,” IEEE
Systems Journal, vol. 10, no. 2, pp. 520–531, June 2016.

[28] F. Gringoli, “tcpanon,” Online,

Jan. 2009.

[Online]. Available:

http://netweb.ing.unibs.it/∼ntw/tools/tcpanon/

[29] Lawrence Brkley National Laboratory

“tcpmkpub,”
Online, 2005. [Online]. Available: http://www.icir.org/enterprise-tracing/
tcpmkpub.html

ICSI,

and

[30] CAIDA, “Anonymization Tools Taxonomy,” Online, 2004. [Online].
Available: https://www.caida.org/tools/taxonomy/anontaxonomy.xml
[31] ISI, “LANDER Trace Software,” Online, May 2017. [Online]. Available:

https://ant.isi.edu/software/lander/index.html

[32] D. Koukis, S. Antonatos, D. Antoniades, E. P. Markatos, and P. Trim-
intzios, “A Generic Anonymization Framework for Network Trafﬁc,” in
2006 IEEE International Conference on Communications, vol. 5, June
2006, pp. 2302–2309.

[33] R. Pang and V. Paxson, “A High-level Programming Environment
for Packet Trace Anonymization and Transformation,” in Proceedings
of the 2003 Conference on Applications, Technologies, Architectures,
and Protocols for Computer Communications, ser. SIGCOMM ’03.
New York, NY, USA: ACM, 2003, pp. 339–351. [Online]. Available:
http://doi.acm.org/10.1145/863955.863994

[34] S. Shohata, Y. Nakamura, and H. Nishi, “Hardware for Accelerating
Anonymization Transparent to Network,” in 2018 Sixth International
Symposium on Computing and Networking (CANDAR), Nov 2018, pp.
181–187.

[35] A. Fukuhara, T. Iwai, Y. Sakuma, and H. Nishi, “Implementation of
Content-Based Anonymization Edge Router on NetFPGA,” in 2019
IEEE 13th International Symposium on Embedded Multicore/Many-core
Systems-on-Chip (MCSoC), Oct 2019, pp. 123–128.

[36] A. Slagell, J. Wang, and W. Yurcik, “Network log anonymization:

Application of crypto-pan to cisco netﬂows,” 2004.

[37] K. Luo, Y. Li, A. Slagell, and W. Yurcik, “Canine: A netﬂows con-
verter/anonymizer tool for format interoperability and secure sharing,”
01 2005.

[38] Y. Li, A. Slagell, K. Luo, and W. Yurcik, “Canine: A combined
conversion and anonymization tool for processing netﬂows for security,”
01 2005.

computer

framework

Installation

20th Large

[39] A. Slagell, K. Lakkaraju, and K. Luo, “FLAIM: A multi-level
logs,”
for
anonymization
System Administration Conference
in
(LISA 06). Washington, D.C.: USENIX Association, Dec.
2006. [Online]. Available: https://www.usenix.org/conference/lisa-06/
ﬂaim-multi-level-anonymization-framework-computer-and-network-logs
from pcap to text with
optionally anonymization,” Online, May 2019. [Online]. Available:
https://ant.isi.edu/software/dnsanon/index.html

extract DNS trafﬁc

“Dnsanon:

[40] ISI,

network

and

[41] M. J. M. Turcotte, A. D. Kent, and C. Hash, Uniﬁed Host and
Network Data Set. World Scientiﬁc, nov 2018, ch. Chapter 1, pp.
1–22. [Online]. Available: https://www.worldscientiﬁc.com/doi/abs/10.
1142/9781786345646 001

[42] A. D. Kent, “Comprehensive, Multi-Source Cyber-Security Events,” Los

Alamos National Laboratory, 2015.

[43] N. Moustafa and J. Slay, “Unsw-nb15: a comprehensive data set for
network intrusion detection systems (unsw-nb15 network data set),” in
2015 Military Communications and Information Systems Conference
(MilCIS), Nov 2015, pp. 1–6.

[44] M. Landauer, F. Skopik, M. Wurzenberger, W. Hotwagner, and
A. Rauber, “Have it your way: Generating customized log datasets with
a model-driven simulation testbed,” IEEE Transactions on Reliability,
pp. 1–14, 2020.

5

[45] I. Sharafaldin, A. H. Lashkari, and A. Ghorbani, “Toward generating a
new intrusion detection dataset and intrusion trafﬁc characterization,” in
ICISSP, 2018.

[46] S. Choi, J. Choi, J.-H. Yun, B.-G. Min, and H. Kim, “Expansion of
ics testbed for security validation based on mitre att&ck techniques,” in
CSET @ USENIX Security Symposium, 2020.

[47] W. Haider, J. Hu, J. Slay, B. Turnbull, and Y. Xie, “Generating realistic
intrusion detection system dataset based on fuzzy qualitative modeling,”
J. Netw. Comput. Appl., vol. 87, pp. 185–192, 2017.

[48] F. Skopik, G. Settanni, R. Fiedler, and I. Friedberg, “Semi-synthetic data
set generation for security software evaluation,” 2014 Twelfth Annual
International Conference on Privacy, Security and Trust, pp. 156–163,
2014.

6

