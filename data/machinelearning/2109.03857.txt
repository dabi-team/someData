Robust Optimal Classiﬁcation Trees Against Adversarial Examples

Dani¨el Vos, Sicco Verwer

Delft University of Technology
d.a.vos@tudelft.nl, s.e.verwer@tudelft.nl

1
2
0
2

p
e
S
8

]

G
L
.
s
c
[

1
v
7
5
8
3
0
.
9
0
1
2
:
v
i
X
r
a

Abstract

Decision trees are a popular choice of explainable model, but
just like neural networks, they suffer from adversarial ex-
amples. Existing algorithms for ﬁtting decision trees robust
against adversarial examples are greedy heuristics and lack
approximation guarantees. In this paper we propose ROCT, a
collection of methods to train decision trees that are optimally
robust against user-speciﬁed attack models. We show that
the min-max optimization problem that arises in adversarial
learning can be solved using a single minimization formula-
tion for decision trees with 0-1 loss. We propose such for-
mulations in Mixed-Integer Linear Programming and Max-
imum Satisﬁability, which widely available solvers can op-
timize. We also present a method that determines the upper
bound on adversarial accuracy for any model using bipartite
matching. Our experimental results demonstrate that the ex-
isting heuristics achieve close to optimal scores while ROCT
achieves state-of-the-art scores.

Introduction
Since the discovery of adversarial examples in neural net-
works (Szegedy et al. 2013) much work has gone into train-
ing models that are robust to these attacks. Recently, efforts
were made to train robust decision trees against adversarial
examples. Chen et al. (Chen et al. 2019) trained robust trees
by scoring with the worst-case information gain or Gini im-
purity criteria and proposed a fast approximation. Calzavara
et al. (Calzavara et al. 2020) created TREANT, a ﬂexible
approach in which the user describes a threat model using
rules and a loss function under attack that it greedily opti-
mizes. GROOT (Vos and Verwer 2020) sped up the worst-
case Gini impurity computation and defended against user-
speciﬁed box-shaped attack models. All these algorithms are
greedy and therefore only make locally optimal decisions.

In decision tree learning, there has been an increased in-
terest in optimal learning algorithms (Carrizosa, Molero-
R´ıo, and Morales 2021). Although the problem of learning
decision trees is NP-complete (Laurent and Rivest 1976),
these methods can produce optimally accurate decision trees
for many (typically small) datasets. Most methods trans-
late the problem to well-known frameworks such as Mixed-
Integer Linear Programming (Bertsimas and Dunn 2017;

Copyright © 2022, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

Verwer and Zhang 2017), Boolean Satisﬁability (Narodyt-
ska et al. 2018; Avellaneda 2020), and Constraint Program-
ming (Verhaeghe et al. 2020).

In this work we combine these lines of research and pro-
pose Robust Optimal Classiﬁcation Trees (ROCT), a method
to train decision trees that are optimally robust against user-
speciﬁed adversarial attack models. Like existing robust de-
cision tree learning algorithms (Calzavara et al. 2020; Vos
and Verwer 2020), ROCT allows users to specify a box-
shaped attack model that encodes an attacker’s capability
to modify feature values with the aim of maximizing loss.
Existing robust decision tree learning methods use a greedy
node splitting approach. Other robust learning algorithms
such as adversarial training (Madry et al. 2017) solve the
inner maximization (adversarial attacks) and the outer min-
imization problems (minimize expected loss) separately. In
this work we demonstrate that this separation is not needed
in the case of decision trees. We provide a formulation that
solves the problem of ﬁtting robust decision trees exactly in
a single minimization step for a tree up to a given depth.

ROCT uses a novel translation of the problem of ﬁt-
ting robust decision trees into a Mixed-Integer Linear Pro-
gramming (MILP) or Maximum Satisﬁability (MaxSAT)
formulations. We also propose a new upper-bound calcula-
tion for the adversarial accuracy of any machine learning
model based on bipartite matching which can be used to
choose appropriate attack models for experimentation. Our
results show that ROCT trees optimized with a warm-started
MILP solver achieve state-of-the-art adversarial accuracy
scores compared to existing methods on 8 datasets. More-
over, given sufﬁcient solver time, ROCT provably ﬁnds an
optimally robust decision tree. In our experiments, ROCT
was able to ﬁt and prove optimality of depth 2 decision trees
on six datasets. Where there are no known approximation
bounds on the performance of existing heuristic methods for
ﬁtting robust decision trees, our results demonstrate that they
are empirically close to optimal.

Background and Related Work

Mixed-Integer Linear Programming

Mixed-Integer Linear Programming (MILP) is a variation of
Linear Programming in which some variables are integers or
binary. The goal of these formulations is to optimize a linear

 
 
 
 
 
 
function under linear constraints. While the problem is gen-
erally NP-hard there exist many fast MILP solvers. In this
paper, we translate the robust decision tree learning prob-
lem into a MILP formulation and solve it using GUROBI1 9.
Since MILP solvers usually become less efﬁcient with more
integer variables, we introduce two formulations that differ
in the number of such variables.

Maximum Satisﬁability Solving
Maximum Satisﬁability (MaxSAT) is an optimization ver-
sion of the classical boolean satisﬁability problem (SAT). In
MaxSAT, problems are modeled as a set of hard clauses that
have to be satisﬁed and a set of soft clauses of which the
solver tries to satisfy as many as possible. One advantage
of MaxSAT solvers is their availability, with many state-of-
the-art solvers available as open source programs. In this
work we use the PySat implementation (Alexey, Antonio,
and Joao 2018) of the Linear Sat-Unsat (LSU) algorithm
(Morgado et al. 2013) improved with incremental cardinal-
ity constraints (Martins et al. 2014), and the RC2 algorithm
(Ignatiev, Morgado, and Marques-Silva 2019). These algo-
rithms differ in the direction in which they optimize, LSU
starts with a poor solution and creates increasingly optimal
solutions over time while RC2 starts by attempting to sat-
isfy all soft clauses then relaxes this constraint until it ﬁnds
a solution. Both algorithms use the Glucose2 4.1 SAT solver.

Optimal Decision Trees
Most popular decision tree learning algorithms such as
CART (Breiman et al. 1984), ID3 (Quinlan 1986) and C4.5
(Quinlan 1993) are greedy and can return arbitrarily bad
trees (Kearns 1996). In recent years, there has been extensive
effort to train optimal trees. One of the earliest works (Bert-
simas and Shioda 2007) proposes a MILP formulation for
ﬁnding a tree of a given maximum depth that uses cluster-
ing to reduce the dataset size. Independently, (Nijssen and
Fromont 2010) maps this problem for the restricted case
of Boolean decision nodes to itemset mining. Several years
later the ﬁrst MILP formulations were proposed for the full
problem (Bertsimas and Dunn 2017) and (Verwer and
Zhang 2017). The latest methods improve these works us-
ing a binary encoding (Verwer and Zhang 2019), transla-
tion to CP (Verhaeghe et al. 2020), dynamic programming
with search (Demirovi´c et al. 2020), and caching branch-
and-bound (Aglin, Nijssen, and Schaus 2020). In this work,
we build on these works to create the ﬁrst formulation for
optimal learning of robust decision trees.

Robust Decision Trees
Previous works have already put effort into ﬁtting deci-
sion trees that are more robust to adversarial perturbations
than the trees created by regular decision tree algorithms.
(Kantchelian, Tygar, and Joseph 2016) deﬁnes a MILP for-
mulation for ﬁnding adversarial examples in decision tree
ensembles and used these samples to ﬁt an ensemble of
more robust decision trees. (Chen et al. 2019) adapts greedy

1https://www.gurobi.com/
2https://www.labri.fr/perso/lsimon/glucose/

decision tree learning algorithms by using the worst case
score functions under attacker inﬂuence to ﬁt more robust
trees against L∞ norm bounded attackers. Later, TREANT
(Calzavara et al. 2020) uses a more ﬂexible greedy algorithm
that could optimize arbitrary convex score functions under
attacker inﬂuence and allowed users to describe attacker ca-
pabilities using axis-aligned rules. This ﬂexibility comes at a
cost in run-time, as it uses an iterative solver to optimize this
score for each split it learns. GROOT (Vos and Verwer 2020)
improve the greedy procedure by efﬁciently computing the
worst-case Gini impurity and allowing users to specify box-
shaped attacker perturbation limits. In this paper, we com-
pare against GROOT and TREANT as these greedy methods
achieve state-of-the-art scores.

ROCT: Robust Optimal Classiﬁcation Trees
When training robust classiﬁers we ﬁnd ourselves in a com-
petition with the adversary. Madry et al. (Madry et al. 2017)
present the robust learning problem as the following min-
max optimization problem:
(cid:18)

(cid:19)

E(x,y)∼D

min
θ

max
δ∈S

L(θ, x + δ, y)

(1)

Here the learning algorithm attempts to ﬁnd model param-
eters θ that minimize the expected risk (outer minimization)
after an attacker moves samples from distribution D within
perturbation domain S (inner maximization). Intuitively, the
min-max nature of training robust models makes it a much
more challenging optimization problem than regular learn-
ing. For example in adversarial training (Madry et al. 2017)
one approximately optimizes this function by incorporating
expensive adversarial attacks into the training procedure. In
this work, we demonstrate that this intuition does not hold
when learning decision trees. We present Robust Optimal
Classiﬁcation Trees (ROCT), which turns Equation 1 into a
single minimization problem that can be solved using com-
binatorial optimization. ROCT consists of 6 methods that are
based on the same intuitions but vary in the kind of solver
(MILP or MaxSAT) and type of variables used to represent
splitting thresholds, see Table 1.
Theorem 1. Robust learning (Equation 1) with 0-1 loss in
the case of binary classiﬁcation trees is equivalent to:

(cid:88)





(cid:95)



ct (cid:54)= y



(x,y)∼D

t∈T S
L

min
θ

where T S
sible perturbations S, and ct is the class label of leaf t.

L is the set of leaf nodes that intersect with the pos-

Proof. For 0-1 loss L0-1, Equation 1 is equivalent to:

min
θ

(cid:18)

(cid:88)

(x,y)∼D

max
δ∈S

L0-1(θ, x + δ, y)

(cid:19)

A decision tree T maps any data point x to a leaf node t =
T (x) and assigns ct as its prediction. Any perturbation in
the inner maximization maxδ∈S such that T (x) = T (x +
δ) gives the same classiﬁcation outcome for 0-1 loss. The

Table 1: Summary of introduced methods, they differ in
solver type and whether thresholds are formulated with bi-
nary or continuous variables. ‘Warm’ methods are initialized
with the GROOT heuristic.

Method

Threshold
formulation

Solver

Init. with
GROOT

LSU-MaxSAT

binary

RC2-MaxSAT

binary

LSU
(glucose 4.1)

RC2
(glucose 4.1)

Binary-MILP

binary

GUROBI 9

Binary-MILP-
warm

binary

GUROBI 9

MILP

continuous

GUROBI 9

MILP-warm

continuous

GUROBI 9

(cid:88)

(cid:88)

maximization over all δ ∈ S can therefore be replaced by a
maximization over all leaf nodes t ∈ T S
L that can be reached
by any permutation in S. By deﬁnition, the 0-1 loss term is
equivalent to the absolute difference |ct − y| of prediction ct
and label y, which gives:

min
θ

(cid:88)

(x,y)∼D

(cid:32)

(cid:33)

|ct − y|

max
t∈T S
L

The term |ct −y| takes value 1 when ct (cid:54)= y and 0 otherwise.
When any of the reachable leafs t ∈ T S
L returns ct (cid:54)= y,
the inner maximization becomes 1. This is equivalent to the
disjunction over ct (cid:54)= y for all reachable leafs:

(cid:88)





(cid:95)



ct (cid:54)= y



(x,y)∼D

t∈T S
L

min
θ

The resulting formulation can be solved in one shot using

discrete optimization solvers such as MaxSAT and MILP.

Attack Model

We assume the existence of a white-box adversary that
can move all samples within a box-shaped region centered
around each sample. This box-shaped region can be deﬁned
by two vectors ∆l and ∆r specifying for each feature by
how much the feature value can be decreased and increased
respectively. For the ease of our formulation we scale all
feature values to be in the range [0, 1] which means that the
values in ∆l and ∆r encode distance as a fraction of the fea-
ture range. While our encoding is more ﬂexible, we only test
on attack models that encode an L∞ radius. This allows us
to easily evaluate performance against a variety of attacker
strengths by only changing the perturbation radius (cid:15).

Table 2: Summary of the notation used throughout the paper.

Symbol Type

Deﬁnition

ajm
bvm
b(cid:48)
m
ct
sim0
sim1
ei
Xij
yi
∆l
j
∆r
j
n
p

A(t)
Al(t)
Ar(t)
TB
TL
Vj

variable
variable
variable
variable
variable
variable
variable

node m splits on feature j
node m’s threshold is left/right of v
node m’s continuous threshold value
leaf node t predicts class 0 or 1
sample i can move left of node m
sample i can move right of node m
sample i can be misclassiﬁed

constant value of data row i in feature j
constant
constant
constant
constant number of samples
constant number of features

class label of data row i
left perturbation range for feature j
right perturbation range for feature j

set
set
set
set
set
set

ancestors of node t
... with left branch on the path to t
... with right branch on the path to t
all decision nodes
all leaf nodes
unique values in feature j

Intuition
We borrow much of the notation from OCT (Bertsimas and
Dunn 2017), summarized in Table 2. Figure 1 visualizes the
variables in ROCT and Figure 2 shows an example of the
constraints for a single sample and a tree of depth 1. In the
regular learning setting where samples cannot be perturbed
by an adversary, samples can only propagate to the left or
right child of decision node. In the adversarial setting, sam-
ples can permute and are able to reach both the left and right
sides, i.e. sim0 and sim1 can be true at the same time.

Given the attacker capabilities ∆l and ∆r, we create the
constraints to set the variables s. To determine whether sam-
ple Xi can move left of the chosen split we can decrease
its feature values as far as the attacker capabilities allow
(Xi − ∆l) and see if it reaches the left side. Similarly to
see if it reaches the right side we increase the feature values
maximally (Xi + ∆r). We give two kinds of constraints for
determining these s variables that differ in whether decision
thresholds are represented by binary or continuous variables.

Continuous Decision Thresholds To select a threshold
value an intuitive method is to create a continuous variable
bm for every decision node. We can then use this variable
to determine the values sim0 and sim1 by checking whether
Xi − ∆l and Xi + ∆r can reach the left and right side of the
threshold respectively. We create the following constraints:

Xi · am ≤ b(cid:48)
Xi · am > b(cid:48)

m =⇒ sim0
m =⇒ sim1

Since these constraints use a dot product with continuous
variables it is not possible to implement this in MaxSAT.
Another challenge comes with the second constraint being
a strict inequality which is not directly supported in MILP.

(a) Decision node m (binary)

(b) Decision node m (continuous)

(c) Path variables for sample i

Figure 1: Example of ROCT’s formulation. For each decision node the a variables select a splitting feature and b select the
threshold value. b can be deﬁned as multiple binary (a) or a single continuous (b) variable. Using the s variables (c) ROCT
traces all sample paths through the tree to the leaves and counts an error if any reachable leaf predicts the wrong class.

Like (Bertsimas and Dunn 2017), we add a small value to
the right hand side to turn it into a regular inequality.

Binary Decision Thresholds We create a set of variables
bvm for each unique decision threshold value v, with v in
ascending order. Instead of forcing one of them to true, we
create an ordering in the variables such that if one threshold
variable is true, the larger variables also become true:

bvm =⇒ b(v+1)m

Intuitively if A(bvm) is true a sample with feature value
v will be sent to the right of the split and when A(bvm)
is false it will be sent to the left. A useful property of
this constraint is that we only have to encode the local inﬂu-
ence of a threshold variable bvm on close-by data points, the
rest is forced by the chain of constraints. For each feature j
we determine what threshold values vl and vr correspond to
Xij − ∆l
j and check whether their bvm values
indicate that the sample can reach the left / right side:

j and Xij + ∆r

ajm ∧ ¬bvlm =⇒ sim0

ajm ∧ bvrm =⇒ sim1

Selecting Features Consider a single decision node m,
such a decision node needs to decide a feature to split on.
We create a binary variable ajm for each feature j and force
that exactly one of these variables can be equal to 1:

p
(cid:88)

j=1

ajm = 1

This constraint can be relaxed to (cid:80)p
j=1 aj ≥ 1 as selecting
more than one feature can only make more s variables true
and thus can only increase the number of errors.

Counting errors We create a variable ei for each sam-
ple i which is true when any reachable leaf t ∈ T S
L
(see Theorem 1) predicts the other class. These leaves are

found by following all paths a sample can take through
the tree using the sim0 and sim1 variables. This is visual-
ized in Figure 1c. Sample i can reach leaf t when the val-
ues sim... are true for all nodes m on the path to t, i.e.
(cid:86)
m∈Ar(t) sim1. Here Al(t) refers to the set
of ancestors of leaf t of which we follow the path through
its left child and Ar(t) for child nodes on the right. When
sample i can reach leaf t and its label does not match t’s
prediction (yi (cid:54)= ct), force ei to true:

m∈Al(t) sim0

(cid:86)

(cid:94)

sim0

(cid:94)

m∈Al(t)

m∈Ar(t)

sim1 ∧ (ct (cid:54)= yi) =⇒ ei

With one constraint per decision leaf and sample combina-
tion this determines the e values. To then turn all possible
paths into predictions we need to assign a prediction label
to each decision leaf. Each leaf t gets a variable ct where
false means class 0 and true means class 1.

Objective Function Our goal is to minimize the equation
from Theorem 1. This is equivalent to minimizing the sum
of errors ei (i = 1...n). We convert this MILP objective to
MaxSAT by adding a soft constraint ¬ei for each sample
and maximizing the number of correctly predicted samples:

maximize

n
(cid:88)

i=1

¬ei

or minimize

n
(cid:88)

i=1

ei

Complete Formulation

Below we give the full formulation for ROCT, in Table
2 we summarize the notation used. The equations can
easily be formulated as MILP or MaxSAT instances, these
conversions are given in the appendix.

baabbbbbbb2m1m1m2m3m4m4m3m2m1mbaab2m1mmm1245673si10si11si20si21si30si31si10si20si10si21si11si30si11si31Figure 2: Example of a decision tree of depth 1 with the bi-
nary threshold formulation. Sample A and C get correctly
classiﬁed since all their reachable leaves predict the correct
label. Sample B reaches both leaves, since the left leaf pre-
dicts the wrong label, B gets misclassiﬁed.

min.

n
(cid:88)

i=1

ei

subject to:

p
(cid:88)

ajm = 1,

j=1
bvm ⇒ b(v+1)m,

∀m ∈ TB

∀m ∈ TB, v=1..|Vj| − 1

(cid:94)

sim0

(cid:94)

sim1 ∧ [ct(cid:54)=yi] ⇒ ei, ∀t ∈ TL, i=1..n

m∈Ar (t)

m∈Al(t)
continuous threshold variables:
Xi · am ≤ b(cid:48)
Xi · am > b(cid:48)
binary threshold variables:
ajm ∧ ¬bvlm ⇒ sim0,
ajm ∧ bvr m ⇒ sim1,

m ⇒ sim0
m ⇒ sim1

∀m ∈ TB, i=1..n

∀m ∈ TB, i=1..n

∀m ∈ TB, i=1..n, j=1..p
∀m ∈ TB, i=1..n, j=1..p

Example For clarity we give a small example of a decision
tree of depth 1 that we ﬁt on 3 samples. In Figure 2 the solver
selects a threshold that forces two samples into a leaf with
their correct label but leaves one sample close enough to the
split that it can move both ways. Since we only show a single
decision node, we drop m from all subscripts of variables.
The assignments A to the variables are A(a1) = 1 (selecting
feature 1), A(b1), . . . , A(b6) = 0, 0, 0, 1, 1, 1 (selecting the
3rd out of 6 possible thresholds), the s variables become:

A(b1) = 0 ⇒ A(s1,0) = 1 A(b3) = 0 ⇒ A(s1,1) = 0

A(b2) = 0 ⇒ A(s2,0) = 1 A(b5) = 1 ⇒ A(s2,1) = 1

A(b4) = 1 ⇒ A(s3,0) = 0 A(b6) = 1 ⇒ A(s3,1) = 1
Since A(c1) = y1 and A(c2) = y3, e1 and e3 are un-
constrained and minimized to 0 by the solver, and since
A(s2,0) = A(s2,1) = 1 the constraints force A(e2) = 1.
The second sample is hence misclassiﬁed (it reaches at least
one leaf with a prediction value different than its label).
Note that, although the thresholds in Figure 2 are always ex-
actly on the perturbation ranges of a sample, we post-process
these to maximize the margin.

Figure 3: Computing a bound on adversarial accuracy by
maximum matching. The maximum matching and minimum
vertex cover are shown in black. Since the matching has a
cardinality of 2 it is impossible to misclassify fewer than 2
samples when accounting for perturbations.

Upper Bound on Adversarial Accuracy
In a regular learning setting with stationary samples one
strives for a predictive accuracy of 100%. As long as there
are no data points with different labels but same coordi-
nates achieving this score is theoretically possible. However,
we realize that in the adversarial setting a perfect classiﬁer
cannot always score 100% accuracy as samples can be per-
turbed. We present a method to compute the upper bound
on adversarial accuracy using a bipartite matching that can
be computed regardless of what model is used. We use this
bound to choose better (cid:15) values for our experiments. It also
lets us compare the scores of optimal decision trees to a
score that is theoretically achievable by perfect classiﬁers.
Such a matching approach was also used in (Wang, Jha, and
Chaudhuri 2018) to train robust kNN classiﬁers.
Theorem 2. The maximum cardinality bipartite matching
between samples with overlapping perturbation range and
different labels {(i, j) : Si ∩ Sj (cid:54)= ∅ ∧ yi (cid:54)= yj} gives an
upper bound to the adversarial accuracy achievable by any
model for binary decision problems.

Proof. The reduction to maximum bipartite matching is
based on the realization that when the perturbation ranges of
two samples with different labels overlap it is not possible to
predict both of these samples correctly. A visual explanation
is given in Figure 3. Formally, given a classiﬁer C that maps
samples to a class 0 or 1, a sample i can only be correctly
predicted against an adversary if its entire perturbation range
Si is correctly predicted:

∀x ∈ Si : C(x) = yi

(2)

Now given a sample j of a different class (e.g. yi = 0
and y1 = 1) that has an overlapping perturbation range such
that Si ∩ Sj (cid:54)= ∅, it is clear that Equation 2 cannot simulta-
neously hold for both samples. We create a bipartite graph
G = (V0, V1, E) with V0 = {i : yi = 0} and V1 = {i : yi =
1}, i.e., vertices representing samples of class 0 on one side
and class 1 on the other. We then connect two vertices with
an edge if their perturbation ranges overlap and their labels
are different: E = {(i, j) : Si ∩ Sj (cid:54)= ∅ ∧ yi (cid:54)= yj}.

To obtain the upper bound, we consider the minimum ver-
tex cover V (cid:48) from G. By removing all vertices / samples in

AACorrectCorrectIncorrectBC123B123C123connect points with overlapping
regions and different labelsdetermine maximum
bipartite matchingFigure 4: Varying the L∞ perturbation radius (cid:15) and com-
puting the adversarial accuracy bound. Datasets are affected
differently, e.g. (cid:15)=0.1 has no effect on cylinder-bands while
the bound for blood-transfusion shows that it is not possible
to score better than constantly predicting its majority class.

V (cid:48), none of the remaining samples can be transformed to
have identical feature values with a sample from the oppo-
site class. A perfect classiﬁer C (cid:48)(x) would therefore assign
these rows their correct class values and an attacker will not
be able to inﬂuence the score of this classiﬁer. It is not pos-
sible to misclassify fewer samples than the cardinality of the
minimum vertex cover V (cid:48) since removing any vertex from it
will add at least one edge e ∈ {(i, j) : Si∩Sj (cid:54)= ∅∧yi (cid:54)= yj}
which will cause an additional misclassiﬁcation. By K¨onig’s
theorem such a minimum cover in a bipartite graph is equiv-
alent to a maximum matching. Therefore we can use a max-
imum matching solver to compute an upper bound on the
adversarial accuracy.

Improving Experiment Design
In previous works (Calzavara et al. 2020; Vos and Verwer
2020) attacker capabilities were arbitrarily chosen but this
limits the value of algorithm comparisons, shown in Figure
4. In this ﬁgure we vary the L∞ radius (cid:15) by which an adver-
sary can perturb samples. Particularly, if this value is chosen
too large, the best possible model is a trivial one that con-
stantly predict the majority class. If (cid:15) is chosen too small,
the adversary has no effect on the learning problem.

To improve the design of our experiments we propose to
choose values for (cid:15) along these curves that cause the adver-
sarial accuracy bound to be non-trivial. In our experiments
we choose three (cid:15) values for each dataset such that their val-
ues corresponds to an adversarial accuracy bound that is at
25%-50%-75% of the range.

Results
To demonstrate the effectiveness of ROCT we compare it
to the state-of-the-art robust tree learning algorithms TRE-
ANT and GROOT. First we run the algorithms on an artiﬁ-
cial XOR dataset to show that the heuristics can theoretically

(a) GROOT

(b) TREANT

(c) ROCT (MILP)

Figure 5: Model prediction regions on a worst case exam-
ple for greedy tree learning algorithms (XOR dataset with
(cid:15)=0.1). Heuristic methods GROOT and TREANT cannot
ﬁnd any good splits, ROCT ﬁnds the optimal solution.

learn arbitrarily bad trees, see Figure 5. Then to compare
the practical performance we run the algorithms on eight
popular datasets (Chen et al. 2019; Vos and Verwer 2020)
and varying perturbation radii ((cid:15)). All of our experiments
ran on 15 Intel Xeon CPU cores and 72 GB of RAM to-
tal, where each algorithm ran on a single core. We give an
overview of the datasets and epsilon radii in the Appendix.
These datasets are used in many of the existing works to
compare robust tree learning algorithms and are available
on OpenML3.

Predictive Performance on Real Data

To demonstrate the practical performance of ROCT we com-
pared the scores of ROCT, GROOT and TREANT on eight
datasets. For each dataset we used an 80%-20% train-test
split. To limit overﬁtting it is typical to constrain the maxi-
mum depth of the decision tree. To this end we select the best
value for the maximum depth hyperparameter using 3-fold
stratiﬁed cross validation on the training set. In each run, ev-
ery algorithm gets 30 minutes to ﬁt. For MILP, binary-MILP
and LSU-MaxSAT this means that we stop the solver and
retrieve its best solution at that time. The methods GROOT,
TREANT and RC2-MaxSAT cannot return a solution when
interrupted. Therefore when these algorithms exceed the
timeout we use a dummy classiﬁer that predicts a constant
value. The adversarial accuracy scores were determined by
testing for each sample whether a sample with a different
label intersects its perturbation range.

Table 3 shows the aggregated results over these 8 datasets,
all individual results are displayed in the appendix. The over-
all best scores were achieved with the MILP-warm method
which is the MILP formulation with continous variables for
thresholds and is warm started with the tree produced by
GROOT. The LSU-MaxSAT method also performed well
and runs without reliance on trees trained with GROOT.
TREANT’s scores were lower than expected which can be
attributed to the number of time outs.

Runtime

An advantage of using optimization solvers for training ro-
bust decision trees is that most solvers can be early stopped

3http://www.openml.org

0.00.10.20.30.40.5ε0.60.70.80.91.0Adversarial accuracy boundbanknote-authenticationblood-transfusionbreast-cancercylinder-bandsdiabeteshabermanionospherewine0.00.20.40.60.81.00.00.20.40.60.81.00.00.20.40.60.81.00.00.20.40.60.81.00.00.20.40.60.81.00.00.20.40.60.81.0Figure 6: Mean percentage of misclassiﬁed training samples
of all 8 datasets over time for trees of depth 3. The ranges
represent one standard error. LSU-MaxSAT is faster at ﬁrst
but after 30 minutes the other methods catch up.

to output a valid tree. In ﬁgure 6 we plotted the mean train-
ing scores over all datasets for trees of depth 3 of the solvers
that can be stopped. We see that all algorithms converge to
nearly the same value given enough time. Moreover we ﬁnd
that LSU-MaxSAT quickly achieves good scores where it
takes MILP-warm and Binary-MILP-warm approximately
10 and 100 seconds to catch up. The MILP-based methods
that were not warm started with GROOT took approximately
1000 seconds to catch up with LSU-MaxSAT.

Optimality
Existing robust decision tree learning algorithms such as
TREANT and GROOT have no performance guarantees.
Using the LSU-MaxSAT solver we can ﬁnd trees and prove
their optimality on the training set which allows us to com-
pare the scores of the heuristics with these optimal scores. In
Figure 7 we plot the approximation ratios of GROOT trees
after 2 hours of training. Although LSU-MaxSAT was not
able to prove optimality for many datasets after a depth of
2 we can still see that GROOT scores close to optimal. All
but one tree scores within a ratio of 0.92 with only one case
having a ratio of approximately 0.87. We also plot the ratio
between our upper bound and optimal trees. Interestingly,
optimal trees of depths 1 and 2 already score close to the
upper bounds in some cases.

Conclusions
In this work we propose ROCT, a new solver based method
for ﬁtting robust decision trees against adversarial examples.
Where existing methods for ﬁtting robust decision trees can
perform arbitrarily poorly in theory, ROCT ﬁts the optimal
tree given enough time. Important for the computational ef-
ﬁciency of ROCT is the insight and proof that the min-max
adversarial training procedure can be computed in one shot
for decision trees (Theorem 1). We compared ROCT to ex-

Figure 7: Ratios of training adversarial accuracy scores be-
tween GROOT vs LSU-MaxSAT’s optimal trees and optimal
trees vs our bound (Theorem 2). In most cases GROOT per-
forms within 5% of optimal. In some cases trees of depth 1
or 2 already score as well as the upper bound.

Table 3: Aggregate results over 8 datasets, means are shown
with their standard error. All trees trained for 30 minutes.

Algorithm

Mean adv. Mean rank Wins
accuracy

.692 ± .013
TREANT
.714 ± .013
Binary-MILP
.720 ± .015
MILP
.724 ± .014
RC2-MaxSAT
GROOT
.726 ± .015
Binary-MILP-warm .726 ± .015
.729 ± .014
LSU-MaxSAT
.735 ± .015
MILP-warm

5.167 ± .604
3.958 ± .576
2.917 ± .454
2.667 ± .393
2.375 ± .450
2.083 ± .399
2.125 ± .303
1.583 ± .225

7
10
12
10
16
16
13
17

isting methods on 8 datasets and found that given 30 minutes
of runtime ROCT improved upon the state-of-the-art. More-
over, although greedy methods have been compared to each
other in earlier works, we demonstrate for the ﬁrst time that
the state-of-the-art actually performs close to optimal. We
also presented a new upper bound for adversarial accuracy
that can be computed efﬁciently using maximum bipartite
matching (Theorem 2).

Although ROCT was frequently able to ﬁnd an optimal
solution and shows competitive testing performance, the
choice of tree depth strongly inﬂuences runtime. Optimal-
ity could only be proven for most datasets up to a depth of 2
and for some until depth 4. Additionally, the size of ROCT’s
formulation grows linearly in terms of the number of unique
feature values of the training dataset. For small datasets of up
to a few 1000 samples and tens of features ROCT is likely
to improve performance over state-of-the-art greedy meth-
ods. Overall, ROCT can increase the performance of state-
of-the-art heuristic methods and, due to its optimal nature
and new upper bound, provide insight into the difﬁculty of
robust learning.

In the future, we will investigate realistic use cases of
adversarial learning in security such as fraud / intrusion /
malware detection. We expect our upper-bound method to
be a useful tool in determining the sensibility of adversarial
learning problems and for robust feature selection.

10−1100101102103Time (s)0.30.40.50.60.70.80.91.0Mean % training errorMILPBinary-MILPMILP-warmBinary-MILP-warmLSU-MaxSAT12345Depth0.700.750.800.850.900.951.00RatioRatioGROOT / OptimalOptimal / BoundNarodytska, N.; Ignatiev, A.; Pereira, F.; Marques-Silva, J.;
and RAS, I. 2018. Learning Optimal Decision Trees with
SAT. In IJCAI, 1362–1368.
Nijssen, S.; and Fromont, E. 2010. Optimal constraint-based
decision tree induction from itemset lattices. Data Mining
and Knowledge Discovery, 21(1): 9–51.
Quinlan, J. 1993. C4. 5: Programs for machine learning
Morgan Kaufmann San Francisco. CA, USA.
Quinlan, J. R. 1986. Induction of decision trees. Machine
learning, 1(1): 81–106.
Szegedy, C.; Zaremba, W.; Sutskever, I.; Bruna, J.; Erhan,
D.; Goodfellow, I.; and Fergus, R. 2013. Intriguing proper-
ties of neural networks. arXiv preprint arXiv:1312.6199.
Verhaeghe, H.; Nijssen, S.; Pesant, G.; Quimper, C.-G.; and
Schaus, P. 2020. Learning optimal decision trees using con-
straint programming. Constraints, 25(3): 226–250.
Verwer, S.; and Zhang, Y. 2017. Learning decision trees with
ﬂexible constraints and objectives using integer optimiza-
tion. In International Conference on AI and OR Techniques
in Constraint Programming for Combinatorial Optimization
Problems, 94–103. Springer.
Verwer, S.; and Zhang, Y. 2019. Learning optimal classiﬁca-
tion trees using a binary linear program formulation. In Pro-
ceedings of the AAAI Conference on Artiﬁcial Intelligence,
volume 33, 1625–1632.
Vos, D.; and Verwer, S. 2020. Efﬁcient Training of Ro-
bust Decision Trees Against Adversarial Examples. arXiv
preprint arXiv:2012.10438.
Wang, Y.; Jha, S.; and Chaudhuri, K. 2018. Analyzing
the robustness of nearest neighbors to adversarial examples.
In International Conference on Machine Learning, 5133–
5142. PMLR.

References
Aglin, G.; Nijssen, S.; and Schaus, P. 2020. Learning opti-
mal decision trees using caching branch-and-bound search.
In Proceedings of the AAAI Conference on Artiﬁcial Intelli-
gence, volume 34, 3146–3153.
Alexey, I.; Antonio, M.; and Joao, M. 2018. PySAT: A
Python Toolkit for Prototyping with SAT Oracles. In SAT,
428–437.
Avellaneda, F. 2020. Efﬁcient inference of optimal decision
trees. In Proceedings of the AAAI Conference on Artiﬁcial
Intelligence, volume 34, 3195–3202.
Bertsimas, D.; and Dunn, J. 2017. Optimal classiﬁcation
trees. Machine Learning, 106(7): 1039–1082.
Bertsimas, D.; and Shioda, R. 2007. Classiﬁcation and re-
gression via integer optimization. Operations Research,
55(2): 252–271.
Breiman, L.; Friedman, J.; Stone, C. J.; and Olshen, R. A.
1984. Classiﬁcation and regression trees. CRC press.
Calzavara, S.; Lucchese, C.; Tolomei, G.; Abebe, S. A.; and
Orlando, S. 2020. Treant: training evasion-aware decision
trees. Data Mining and Knowledge Discovery, 34(5): 1390–
1420.
Carrizosa, E.; Molero-R´ıo, C.; and Morales, D. R. 2021.
Mathematical optimization in classiﬁcation and regression
trees. TOP, 1–29.
Chen, H.; Zhang, H.; Boning, D.; and Hsieh, C.-J. 2019.
Robust decision trees against adversarial examples. arXiv
preprint arXiv:1902.10660.
Demirovi´c, E.; Lukina, A.; Hebrard, E.; Chan, J.; Bailey, J.;
Leckie, C.; Ramamohanarao, K.; and Stuckey, P. J. 2020.
MurTree: Optimal Classiﬁcation Trees via Dynamic Pro-
gramming and Search. arXiv preprint arXiv:2007.12652.
Ignatiev, A.; Morgado, A.; and Marques-Silva, J. 2019.
RC2: An efﬁcient MaxSAT solver. Journal on Satisﬁabil-
ity, Boolean Modeling and Computation, 11(1): 53–64.
Kantchelian, A.; Tygar, J. D.; and Joseph, A. 2016. Evasion
and hardening of tree ensemble classiﬁers. In International
Conference on Machine Learning, 2387–2396.
Kearns, M. 1996. Boosting theory towards practice: Recent
developments in decision tree induction and the weak learn-
ing framework. In Proceedings of the national conference
on artiﬁcial intelligence, 1337–1339.
Laurent, H.; and Rivest, R. L. 1976. Constructing optimal
binary decision trees is NP-complete. Information process-
ing letters, 5(1): 15–17.
Madry, A.; Makelov, A.; Schmidt, L.; Tsipras, D.; and
Vladu, A. 2017. Towards deep learning models resistant to
adversarial attacks. arXiv preprint arXiv:1706.06083.
Martins, R.; Joshi, S.; Manquinho, V.; and Lynce, I. 2014.
Incremental cardinality constraints for MaxSAT. In Interna-
tional Conference on Principles and Practice of Constraint
Programming, 531–548. Springer.
Morgado, A.; Heras, F.; Lifﬁton, M.; Planes, J.; and
Marques-Silva, J. 2013. Iterative and core-guided MaxSAT
solving: A survey and assessment. Constraints, 18(4): 478–
534.

