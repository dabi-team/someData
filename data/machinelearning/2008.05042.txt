Trust-Based Cloud Machine Learning Model
Selection For Industrial IoT and Smart City Services

Basheer Qolomany, Graduate Student Member, IEEE, Ihab Mohammed, Graduate Student Member, IEEE,
Ala Al-Fuqaha, Senior Member, IEEE, Mohsen Guizani, Fellow, IEEE, Junaid Qadir, Senior Member, IEEE

1

0
2
0
2

g
u
A
1
1

]

G
L
.
s
c
[

1
v
2
4
0
5
0
.
8
0
0
2
:
v
i
X
r
a

Abstract—With Machine Learning (ML) services now used in
a number of mission-critical human-facing domains, ensuring
the integrity and trustworthiness of ML models becomes all-
important. In this work, we consider the paradigm where cloud
service providers collect big data from resource-constrained
devices for building ML-based prediction models that are then
sent back to be run locally on the intermittently-connected
resource-constrained devices. Our proposed solution comprises
an intelligent polynomial-time heuristic that maximizes the level
of trust of ML models by selecting and switching between a subset
of the ML models from a superset of models in order to maximize
the trustworthiness while respecting the given reconﬁguration
budget/rate and reducing the cloud communication overhead. We
evaluate the performance of our proposed heuristic using two case
studies. First, we consider Industrial IoT (IIoT) services, and as
a proxy for this setting we use the turbofan engine degradation
simulation dataset to predict the remaining useful
life of an
engine. Our results in this setting show that the trust level of the
selected models is 0.49% to 3.17% less compared to the results
obtained using Integer Linear Programming (ILP). Second, we
consider Smart Cities services, and as a proxy of this setting we
use an experimental transportation dataset to predict the number
of cars. Our results show that the selected model’s trust level is
0.7% to 2.53% less compared to the results obtained using ILP.
We also show that our proposed heuristic achieves an optimal
competitive ratio in a polynomial-time approximation scheme for
the problem.

Index Terms—Trusted Machine Learning Models, Deep Learn-
ing, Adversarial Attacks, MLaaS, Automatic Model Selection,
Smart City, Industrial IoT (IIoT).

I. INTRODUCTION
The global market for Machine Learning (ML) has grown
rapidly over the last few years largely due to the fast pace
of integrating ML with many facets of everyday life, par-
ticularly for enabling smart Internet-of-Things (IoT) services.
Most of today(cid:48)s IoT predictive analytics rely on cloud-based
services, in which IoT resource-constrained devices continu-
ously send their collected data to the cloud [1]. Resource-
constrained devices have limited processing, communication

B. Qolomany is with Department of Cyber Systems, College of Business
& Technology, University of Nebraska at Kearney, Kearney, NE 68849, USA
(e-mail: qolomanyb@unk.edu)

I. Mohammed is with the Department of Computer Science, Western
ihabahmed-

Michigan University, Kalamazoo, MI 49008 USA (e-mail:
moha.mohammed@wmich.edu).

A. Al-Fuqaha is with the Information and Computing Technology Divi-
sion, College of Science and Engineering, Hamad Bin Khalifa University,
Doha, Qatar and with the Computer Science Department, Western Michigan
University, Kalamazoo, Michigan (e-mail: ala@ieee.org).

M. Guizani is with the Computer Science and Engineering Department,

Qatar University, Doha, Qatar (e-mail: mguizani@ieee.org).

J. Qadir is with Information Technology University, Lahore, Pakistan (e-

mail: junaid.qadir@itu.edu.pk).

and/or storage capabilities, and often run on batteries. On
the cloud, ML as a Service (MLaaS) providers carry out
the prediction process and provide data pre-processing, model
training, model evaluation, and model update capabilities [2].
The MLaaS market is expected to exceed $3,754 million by
2024 at a compound annual growth rate (CAGR) of 42% in
the given forecast period [3]. Typical systems include elec-
trical power grids [4], intelligent transportation and vehicular
management [5], health care devices [6], household appliances
[7], predictive maintenance systems [8] in Industrial IoT (IIoT)
and many more. However, ML models can be targeted by
malicious adversaries [9] due to the participatory nature of
such systems. Cyber-attacks against critical infrastructure are
not just theories, they are very real and have already been used
to effect. For example, in December 2015 a cyber-attack on
Ukraine’s power grid left 700,000 people without electricity
for several hours [10]. The Stuxnet worm, which was ﬁrst
uncovered in 2010, is believed to be responsible for causing
substantial damage to Iran’s nuclear program [11]. In March
2016, the U.S. Justice Department indicated that cyber-attacks
tied to the Iranian regime [12] targeted 46 major ﬁnancial
institutions and a dam outside of New York City.

Perhaps the most pressing challenge in the emerging cloud
computing area is that of establishing trust [13] [14]. De-
spite the importance of trust in cloud computing, a common
conceptual model of trust in cloud computing has not yet
been deﬁned [15] and it is becoming increasingly complex for
cloud users to distinguish between service providers offering
similar types of services in terms of trustworthiness [16].
Trust has been investigated from different disciplinary lenses
such as psychology, sociology, economics, management, and
information systems (IS) but there is no commonly accepted
deﬁnition of trust [17] [18]. That is, depending on the context,
we may think of many different things when someone uses the
word ‘trust.’ Merriam-Webster’s dictionary deﬁnes the word
’trust’ as ”assured reliance on the character, ability, strength,
or truth of someone or something.” Our deﬁnition for the trust
in this paper refers to the ML models that agree most with the
predictions of an ensemble of ML models. Therefore, a model
that agrees more with the predictions of the ensemble is more
‘trustworthy’ compared to the one that agrees less with the
ensemble. For example, assume that we have 5 models (M1,
M2, M3, M4 and M5), and the model M1 agrees with 3 other
models, while M2 agrees with only 2 other models, then M1
is more trustworthy than M2.

The performance of ML models can be quantiﬁed based
on their decision time, accuracy, and precision of resulting

 
 
 
 
 
 
decisions [19]. However, as such models are used for more
critical and sensitive decisions (e.g., whether a drug should be
administered to a patient or should an autonomous vehicle stop
for pedestrians), it becomes more important to ensure that they
provide high accuracy and precision guarantees. Assessing
learning models in terms of trustworthiness along with the
traditional criteria of decision time, accuracy, and precision
establishes a tradeoff between simplicity and power [20]. ML
classiﬁers are vulnerable to adversarial examples, which are
samples of input data that are maliciously modiﬁed in a way
that is intended to cause an ML classiﬁer to misclassify similar
examples. Moreover, it is known that adversarial examples
generated by one classiﬁer are likely to cause another classiﬁer
to make the same mistake [21]. In many cases, the modiﬁca-
tions can successfully cause a classiﬁer to make a mistake
even though the modiﬁcations is imperceptible to a human
observer. In general, adversarial attacks can be classiﬁed into
a misclassiﬁcation attack or a targeted attack based on its
goals [22] [23] [24]. In a misclassiﬁcation attack, the adversary
intends to cause the classiﬁer to output a label different from
the original label. In a targeted attack, on the other hand, the
adversary intends to cause the classiﬁer to output a speciﬁc
misleading label.

In this paper, we envision the paradigm where resource-
constrained IoT devices execute ML models locally, without
necessarily being always connected to the cloud. Some advan-
tages of our proposed heuristic is its applicability to a number
of applications scenarios beyond the pale of the traditional
paradigm where it is not desirable to execute the model on
the cloud due to latency, connectivity, energy, privacy, and
security concerns. Consequently, it is expected that the users
should be able to determine the trustworthiness of service
providers in order to select them with conﬁdence and with
some degree of assurance that their service offerings will not
behave unpredictably or maliciously. Our proposed heuristic
strives to minimize the communications overhead between
the cloud and the resource-constrained devices. Selected ML
models are sent to resource-constrained devices to be used.
The proposed heuristic also has a limitation that it is not
intended to improve the trustworthiness of the models trained
in Federated Learning (FL) systems when each client preserves
its own data locally. Instead, our approach can be applied
to improve the trustworthiness of centralized approach of
learning, when all the clients send their data to a MLaaS
provider to build ML model on the cloud, then this model
will be sent back to be hosted on a resource-constrained
devices. The target of the proposed heuristic is not to handle
all different types of the attacks. We only consider poisoning
attacks on ML classiﬁers. Within this scenario, an attacker
may poison the training data by injecting carefully designed
samples to eventually compromise the whole learning process.
Figure 1 shows a general architecture for the proposed system.
On the cloud side we have M ML models, model1, model2,
. . . , modelM .

The main contributions of the work can be summarized as:
(i) We formulate the problem of ﬁnding a subset of ML
models that maximize the trustworthiness while respect-
ing given reconﬁguration budget and rate constraints. We

2

also prove the problem is NP-complete.

(ii) We propose a heuristic that maximizes the level of
trust of ML models and ﬁnds a near-optimal solution in
polynomial time by selecting a subset from a superset of
ML models. Our trust metric of an ML model is based
on recent and past historical data that measure the degree
of agreement of the ML model with other models in an
ensemble of ML models.

(iii) The proposed system has fail-safe state, such that if the
proposed heuristic does not ﬁnd a trusted ML model in
the superset of models, it sends a fail-safe execution alert.
This alert informs the resource-constrained devices that
no trusted ML model exists in the system. As a result, the
resource-constrained devices can fail safely as required
by the application that they service.

(iv) Building on the above insights, we apply the proposed
heuristic to two different
training datasets. The ﬁrst
dataset, based on the CityPulse project [25], is used to
predict the number of vehicles as a surrogate use-case
for smart city services. The second data set, provided
by the Prognostics CoE at NASA Ames [26], is used to
predict the remaining useful life of a turbofan engine as
a surrogate use-case for IIoT smart services.

(v) We applied the swap x and 100 − x percentiles approach
as a causative adversarial attack by altering the training
dataset label as we will describe in Section VI.

For the convenience of the readers, Table I provides a list

of the acronyms used in this paper.

TABLE I: List of Important Acronyms Used

DL
FL
IIoT
ILP
IoT
IS
LP
LSTM
ML

Deep Learning
Federated Learning
Industrial Internet of Things
Integer Linear Programming
Internet of Things
Information System
Linear Programming
Long Short-Term Memory
Machine Learning
MLaaS Machine Learning as a Service

NP
PM
RMSE
TML

Non-deterministic Polynomial-time
Predictive Maintenance
Root Mean Square Error
Trusted Machine Learning

The remainder of this paper is organized as follows: Section
III presents the most recent related work. The background
information of case studies and thread model is introduced in
Section II. Section IV discusses the system model and problem
formulation. Section V discusses our proposed solutions and
their competitive ratio analysis. Section VI presents our ex-
perimental setup, experimental results and the lessons learned.
Finally, Section VII concludes the paper and discusses future
research directions.

II. BACKGROUND

A. Case Studies

Several case studies could be considered,

in which the
proposed heuristic helps to gain the best trust level. Here,
we discuss two representative case studies. The ﬁrst case
study considers IIoT predictive maintenance while the second

3

time control of the machines based on the deviation of the real-
time ﬂow readings from the predicted ones. In such systems,
embedded sensors collect short-term state of the machine
readings, which are relayed to the cloud directly through
communications infrastructure, or indirectly through the use
of ferry nodes. Because of its compute and store capabilities,
the cloud is capable of collecting the short-term readings to
build long-term big data of sensor readings. These readings are
then utilized to build a PM model for each of the underlying
ﬂow sensors. The constructed models are then sent back to
the ﬂow sensors so that they actuate their associated machines
when a deviation is observed between the actual and projected
ﬂow readings.

There are scenarios in which cyber-attackers attempt to
compromise PM models directly. Consequently, data that
leaves its internal operating environment is subject to third-
party attacks. For instance, an adversary can create a causative
attack to poison the learner’s classiﬁcations. This is possible
by altering the training process through inﬂuence over the
training data. Therefore, when the system is re-trained, the
learner learns an incorrect decision-making function. Thus it
is important to ensure the trustworthiness of ML models before
they are hosted and used on resource-constrained devices.

2) Smart City (Trafﬁc Flow Prediction) Case Study: Trafﬁc
ﬂow prediction plays an important role in intelligent trans-
portation management and route guidance. Such predictions
can help in relieving trafﬁc congestion, reducing air pollution,
and in providing secure trafﬁc conditions [29]. Trafﬁc ﬂow
prediction heavily depends on historical and real-time trafﬁc
data collected from various sensor sources. These sources
include inductive loops, radars, cameras, mobile global po-
sitioning systems (GPS), crowdsourcing, social media, etc.
Transportation management and control are now becoming
more data-driven [30]. However, inferring trafﬁc ﬂow under
real-world conditions in real-time is still a challenging research
problem due to the computational complexity of building,
training, learning and storing trafﬁc ﬂow models on resource-
constrained devices.

In our proposed approach, various sensor technologies are
used to automatically collect short-term data of the trafﬁc
ﬂow and send them to the cloud through communications
infrastructure or through the use of ferry nodes. The cloud is
capable of collecting the short-term readings to build long-
term big data of sensor readings. These readings are then
utilized by MLaaS service providers to build a model. The
constructed models are then sent back to be hosted on the
resource-constrained devices, in order to predict the trafﬁc ﬂow
in real-time. Intelligent transportation systems are highly visi-
ble, and attacks against them result in high impact on critical
infrastructure. For instance, the attacks can cause vehicular
accidents or create trafﬁc jams that affect freight movements,
and daily commutes, etc. Thus to make the trafﬁc movement
more efﬁcient and improve road safety, road operators need
to constantly monitor trafﬁc and current roadway conditions
by using an array of cameras and sensors that are strategically
placed on the road network. These cameras and sensors send
back real-time data to the control center [31]. The data is
subject to causative adversarial attacks, which are launched

Fig. 1: General architecture for the proposed system of select-
ing a trustworthy subset of ML models built by different cloud
service providers.

one considers real-time trafﬁc ﬂow prediction in smart cities.
Figure 2 illustrates the trust-based model selection problem
addressed in this research and also depicts the two considered
case studies. During each decision period, our proposed heuris-
tic switches between the subset of selected models with a goal
of maximizing the overall trustworthiness while respecting the
given reconﬁguration budget and rate.

Fig. 2: Trust-based model selection problem for IIoT and smart
city case scenarios.

1) IIoT Predictive Maintenance Case Study: A predictive
maintenance (PM) strategy uses ML methods to identify,
monitor, and analyze system variables during operation. Also,
PM alerts operators to preemptively perform maintenance
before a system failure occurs [27]. Being able to stay ahead
of equipment shutdowns in a mine, steel mill, or factory, PM
can save money and time for a busy enterprise [28]. With
PM, the data is collected over time to monitor the state of
the machine and is then analyzed to ﬁnd patterns that can
help predict failures. In many cases, it is desirable to have
prediction models hosted on resource-constrained embedded
devices. Predictive maintenance systems need to provide real-

4

Fig. 3: The exchange of data/models between resource-
constrained devices and the cloud using message ferries.

by altering the training process by inﬂuencing the training
data and consequently causing the learner to learn an incorrect
decision-making function.

Figure 3 illustrates the use of message ferries to collect data
from resource-constrained devices. Collected data is delivered
to the cloud in order to build the ML models by the MLaaS
service providers. Next, the ferrying nodes deliver the ML
models to be hosted on the resource-constrained devices.

B. Threat Model

1) Adversary Knowledge: For both the case studies, we
only consider poisoning attacks on the ML classiﬁers. Within
this scenario, an attacker may poison the training data by
injecting carefully designed samples to eventually compromise
the whole learning process. Poisoning may thus be regarded
as an adversarial contamination of the training data. In our
experiments, we use the swap x and 100−x percentiles attack
model as a causative attack against the LSTM algorithm.

2) Adversary Goal: The goal of an adversarial MLaaS
provider is to deliver an ML model that results in sub-optimal
or erroneous results when executed on resource-constrained
IoT devices. The incentive of the adversarial MLaaS provider
is to seek gains by colluding with business competitors of
MLaaS clients.

III. RELATED WORK

In this section, we review recent related works. Figure 4
shows the research gap that we address in this research. To
the best of our knowledge, this paper is the ﬁrst attempt
at designing an intelligent polynomial-time heuristic on the
cloud that selects the ML models that should be hosted on
IoT resource-constrained devices in order to maximize the
trustworthiness of the overall system.

A. Trust-based ML Models

Researchers have proposed various approaches to design
machine learning algorithms that are trustworthy when using
predictions to make critical decisions in real-world applica-
tions including healthcare, law, self-driving cars etc. Speicher
et al. [32] propose an approach to establish of complex ML
models by ensuring that in a particular way, a complex model

Fig. 4: The research gap addressed in the paper.

to achieve correct predictions at least on all those data points
where a trusted model was already correct.

Ghosh et al. [33] proposed the Trusted ML (TML) frame-
work for self-driving cars that uses principles from formal
methods for learning ML models. These ML models satisfy
properties in temporal logic by using model repair or the
is learned. Zhang et al. [34]
data from which the model
propose Debugging Using Trusted Items (DUTI) algorithm
that uses trusted items to detect outlier and systematic training
set bugs. The approach looks for the smallest set of changes
in the training set labels, such that, the model learned from
this corrected training set predicts labels of the trusted items
correctly.

Ribeiro et al. [35] proposed the LIME algorithm, which
explains the predictions of any classiﬁer or regressor in an
interpretable manner by approximating an interpretable model
locally around the prediction. The authors also proposed a
method called SP-LIME to select representative and non-
redundant predictions, which provides a global view of the
model to users. The authors applied the proposed algorithm
on both simulated and human subjects in order to decide
between and assess models and also identiﬁed reasons for
not trusting a classiﬁer. Jayasinghe et al. [36] proposed trust
assessment model which speciﬁes the formation of trust from
raw data to a ﬁnal trust value, they proposed an algorithm
based on machine learning principles that determine whether
an incoming interaction is trustworthy, based on several trust
features corresponding to an IoT environment. Fariha et al.
[37] introduced data invariant technique as an approach to
achieve trusted machine learning by reliably detecting tuples
on which the prediction of a machine-learned model should
not be trusted. They proposed a quantitative semantics to
measure the degree of violation of a data invariant, and

establish that strong data invariants can be constructed from
observations with low variance on the given dataset. Drozdal
et al. [38] explore trust in the relationship between human
data scientists and models produced by AutoML systems.
They ﬁnd that including transparency features in an AutoML
tool increased user trust and understandability in the tool;
and out of all proposed features, model performance metrics
and visualizations are the most important information to data
scientists when establishing their trust with an AutoML tool.
Wahab et al. [39] proposed a solution for maximizing the
detection of VM-based DDoS attacks in cloud systems. Their
proposed solution has two components. First, they proposed a
trust model between the hypervisor and its guest VMs for the
purpose of establishing a credible trust relationship between
the hypervisor and guest VMs. Second, they designed a trust-
based maximin game between DDoS attackers and hypervisor
to minimize the cloud system’s detection and maximize this
minimization under limited budget of resources. In [40], the
authors make three arguments about the trustworthiness of
deep learning (DL) systems to prevent the deception of the
algorithm: (1) the trustworthiness should be an essential and
mandatory component of a DL system for algorithmic decision
making; (2) the trust of a DL model should be evaluated along
multiple dimensions in terms of its correctness, accountability,
transparency, and resilience; and (3) there should be a proac-
tive safeguard mechanisms to enforce the trustworthiness of a
deep learning framework.

In this work, the trust metric of an ML model is based
on recent and past historical data that measure the degree of
agreement of the ML model with other models in an ensemble
of ML models.

B. Adversary attacks on ML models

Recent research shows that ML models trained entirely on
private data are still vulnerable to adversarial examples, which
have been maliciously altered so as to be misclassiﬁed by
a target model while appearing unaltered to the human eye
[21][22]. Madry et al. [41] propose an approach to study the
adversarial robustness of neural networks through the lens of
robust optimization, this approach enables to identify meth-
ods for both training and attacking neural networks models.
Finlayson et al. [42] demonstrate that adversarial examples
are capable of manipulating deep learning systems. They
synthesize a body of knowledge about the healthcare system
across three clinical domains to argue that medicine may be
uniquely susceptible to adversarial attacks. Huang et al. [43]
discuss the effective machine learning techniques against an
adversarial opponent. They introduce two machine learning
models for modeling an adversarys capabilities and discuss
how speciﬁc application domain, features and data distribution
restrict an adversarys attacks. Saadatpanah et al. [44] discuss
how the machine learning methods in industrial copyright
detection systems are susceptible to adversarial attacks and
why those methods are particularly vulnerable to attacks. Ren
et al. [45] introduce the theoretical foundations, algorithms,
and applications of adversarial attack and defense techniques
in deep learning models. Chakraborty et al. [46] provide

5

a discussion on different types of adversarial attacks with
various threat models and also elaborate the efﬁciency and
challenges of recent countermeasures against them. Akhtar and
Mian [47] present a comprehensive survey paper on adversarial
attacks on deep learning in computer vision. Yuan et al.
[48] investigate and summarize the approaches for generating
adversarial examples, applications for adversarial examples,
and corresponding countermeasures for deep neural network
models.

C. Automatic Model Selection

Researchers have proposed various automatic selection
methods for ML algorithms. ML model selection is the
problem of determining which algorithm, among a set of ML
algorithms, is the best suited to the data [49]. Choosing the
right technique is a crucial task that directly impacts the quality
of predictions. However, deciding which ML technique is well
suited for processing speciﬁc data is not an easy task, even for
an expert, as the number of choices is usually very large [50].
Auto-WEKA [51] considers all 39 ML classiﬁcation al-
gorithms implemented in Weka to automatically and simul-
taneously choose a learning algorithm. Auto-WEKA uses
sequential model-based optimization and a random forest
regression model to approximate the dependence of a model’s
accuracy on the algorithm and hyper-parameter values. Using
an approach similar to that in Auto-WEKA, Komer et al. [52]
developed the software hyperopt-sklearn, which automatically
selects ML algorithms and the hyper-parameter values for
Scikit-learn.

In another work, Sparks et al. proposed MLbase [53], an
architecture for automatically selecting ML algorithms, that
supports distributed computing on a cluster of computers
by combining better model search methods, bandit methods,
batching techniques, and a cost-based cluster sizing estimator.
Lokuciejewski et al. [54] presented a generic framework
for automatically selecting an appropriate ML algorithm for
the compiler generation of optimization heuristics. Leite et al.
[55] proposed a method called active testing for automatically
selecting ML algorithms, that exploits metadata information
concerning past evaluation results to recommend the best
algorithm using a limited number of tests on the new dataset.
Van Rijn et al. [56] proposed a method for automatically
selecting algorithms. They addressed the problem of algorithm
selection under a budget, where multiple algorithms can be
run on the full data set until the budget expires. Their method
produces a ranking of classiﬁers and takes into account the
run times of classiﬁers.

D. ML models for Resource-constrained Devices

Researchers have worked on the inference problem on tiny
resource-constrained IoT devices, which are not necessarily
always-connected to the cloud. Kumar et al. [57][58] de-
veloped tree and k-nearest neighbor based algorithms, called
Bonsai and ProtoNN respectively, for classiﬁcation, regression,
ranking, and other common IoT tasks. Their algorithm can
be trained on the cloud and then be hosted onto resource-
constrained IoT devices based on the Arduino Uno board.

Bonsai and ProtoNN maintain prediction accuracy while min-
imizing model size and prediction costs. Motamedi et al.
[59] presented a framework for the synthesis of efﬁcient
Convolutional Neural Networks (CNN) inference software
targeting mobile System on Chip (SoC) based platforms. They
used parallelization approaches for deploying a CNN on SoC-
based platforms. Meng et al. [60] presented Two-Bit Networks
(TBNs) approach for CNN model compression to reduce the
memory usage and improve computational efﬁciency in terms
of classiﬁcation accuracy on resource-constrained devices.
They utilized parameter quantization for computation work-
load reduction. Shoeb et al. [61] present an ML approach on a
wearable device to identify epileptic seizures through analysis
of the scalp electroencephalogram, a non-invasive measure of
the brains electrical activity.

IV. SYSTEM MODEL AND PROBLEM FORMULATION
In this paper, we assume an MLaaS provider that has M ML
models from which a subset needs to be selected and deployed
on IoT devices for T time slots. P is a constant matrix of size
M × T , where element pi,j indicates the trust value obtained
by model i at time j. This matrix is created based on recent
and past historical data that measure the degree of agreement
of ML model i with the other M −1 models in the ensemble of
ML models. B is the maximum number of allowed ML model
reconﬁgurations during T time slots. A is a variable matrix of
size M × T , where element ai,j ∈ {0, 1}. ai,j = 1 indicates
that the model i at time j is trustworthy; ai,j is equal to zero
otherwise. In other words, A is a variable selection matrix
where a value of 1 in row r column c indicates that model
number r is selected at time c; otherwise, if the value is 0 then
model r is not selected at time slot c. Thus, the objective of
the formulation is to ﬁnd the values of ai,j and pi,j such that
the selected models maximize the overall trust values during
the entire time period as shown in Equation (2).

As our proposed heuristic depends on the prediction output
of ML model,
it can be used with any supervised ML
algorithms as classiﬁcation and regression problems. In our
experiments we use the proposed approach to select trusted
LSTM models in regression problems. To compute the trust
level of model i at time j, we use Equation (1), which assigns a
higher trust metric to models that agree more with the average
of all models. This equation is inspired from the majority
voting approach presented in the literature to quantify the level
of trust [62] [63] [64] [65] [66]. Therefore, model i at time j is
assigned trust level pi,j that represents the degree of agreement
k=1 d(Oi,j ,Ok,j )
)
(i.e., reciprocal of the degree of deviation
of model i with other models in the ensemble of ML models.
d(Oi,j, Ok,j) is a function that provides the distance between
Oi,j and Ok,j. The trust level metric ranges from 0 to pmax
where a higher value indicates a higher level of trust.

(cid:80)M

M

(cid:18)

pi,j = min

pmax ,

(cid:34) (cid:80)M

k=1 d(Oi,j, Ok,j)
M

(cid:35)−1 (cid:19)

, (1)

where pmax is the maximum attainable trust level in the given
application domain and pi,j is the trust level of model i at
time j, Oi,j is the output of model i at time j, and Oi,j ∈ R.

6

TABLE II: Description of Formulation Parameters

Parameter Meaning

A
B
H

(cid:15)
M
Oi,j
P

Pi,j
PM ax
R
T

Variable matrix of size M×T, ai,j ∈ {0, 1}
Maximum number of allowed ML model conﬁgurations
Constant value which represents the threshold of maximum
trust level value selected from the fractional solution
Constant small value that is subtracted from H value
Number of ML models
Output of the model i at time j
Constant matrix of size M×T, which represents the trust value
obtained by all models at all time slots
Trust value obtained by model i at time j
Maximum attainable trust level
Maximum rate of reconﬁguration
The number of time slots

Problem Formulation: The goal of this work is to maxi-
mize the trust level gained by selecting a subset of ML models
from a superset of models to be hosted on resource-constrained
devices for a period of time R, where 0 ≤ R ≤ T . The number
of reconﬁgurations is limited to B and the maximum rate of
reconﬁguration is limited to R. We formulate the problem
using ILP as follows:

max

T
(cid:88)

M
(cid:88)

j=1

i=1

ai,j · pi,j

s.t.

M
(cid:88)

i=1

ai,j = 1

∀j ∈ 1 . . . T,

ai,j ∈ {0, 1}

∀i ∈ 1 . . . M

1
2

1
2

·

·

∀j ∈ 1 . . . T,

M
(cid:88)

T
(cid:88)

|ai,j − ai,j−1| ≤ B,

i=1

M
(cid:88)

j=2
k+(cid:100) T
(cid:88)

B (cid:101)

i=1

j=k

|ai,j − ai,j−1| ≤ R

∀k ∈ 1 . . . (T −

T
B

),

(2)

(3)

(4)

(5)

(6)

The ﬁrst constraint in (3) is to ensure that only one ML
model is selected at each time slot, because there will be
only one ML model hosted in a resource-constrained device
at a time. The second constraint in (4) indicates that this
formulation is combinatorial, where the values can either be
0 or 1 with 1 indicating the trustworthiness of the ML model
and 0 indicating that it is not. In order to comply with the
maximum number of allowed reconﬁgurations (B), the third
constraint in (5) is used. The fourth constraint in (6) restricts
the solution to adhere to the models’ maximum reconﬁguration
rate R (i.e., the maximum number of reconﬁguration per time
unit). Table II summarizes the description of the formulation
parameters.

V. PROPOSED SOLUTION

In this section, we discuss the proposed algorithms for
the lower bound and competitive solution along with the

7

Fig. 5: An illustration of our proposed splice heuristic work. Here, the splice heuristic selects 3 longest consecutive sequences
of 1s segments, then merges the adjacent unselected segments.

upper bound algorithm. We also illustrate the proof of NP-
completeness of selecting a subset of ML models from a
superset of ML models in order to maximize the trust level of
ML models.

A. Lower Bound

To ﬁnd a lower bound solution, we propose the Splice
Heuristic shown in Algorithm (1). The heuristic accepts A,
a matrix of size M × T , where the element ai,j represents
the trust level of model i at time slot j. Initially, the heuristic
considers A as one unselected segment. Next, the heuristic
iteratively uses three steps. In the ﬁrst step, for each unselected
segment that is at least R in length, the heuristic ﬁnds the
model (row) k with the longest consecutive sequence of 1s (i.e.
the highest trust level). In the second step, the segment that
has the highest trust level is marked as selected. Additionally,
the row k is selected by setting all the values in row k to 1
and in rows other than k to 0. The third step merges adjacent
selected segments (from the previous rounds) into a single
selected segment if they share the same selected model.

These three steps are repeated until at most B segments
are selected or on unselected segments are left. Finally, the
heuristic identiﬁes unselected segments, if such segments exist.
For each unselected segment, the heuristic ﬁnds the trust level
using the highest trust level from a selected adjacent segment,
if one exists. Finally, the heuristic compares the trust level
resulting from the adjacent ML models (if they exist) and
chooses the one with the highest trust level.

The example in Figure 5 illustrates the details of our
proposed Splice heuristic. In this example, we assume that
R = 4, B = 2. Consequently, the heuristic selects B + 1 = 3
segments that maximize the trust level. The ﬁrst section covers
time slots T1 − T4 with the selected ML model M3. M2 is
selected in the second segment, which covers the time slots
T7 − T10. Finally, the last segment has M4 selected in the
time slots T13 − T16. After that the heuristic determines which
ML model to use for the remaining unselected segments. For
the time slots T5 − T6, M2 is selected based on the selected
adjacent segment to the right. In addition, for the time slots
T11 − T12, M4 is selected based on the selected adjacent
segment to the right.

B. Upper Bound

We relax the ILP formulation presented in Section IV to a
Linear Programming (LP) problem by replacing the constraint
(4) with

ai,j ∈ [0, 1],

∀i ∈ 1 . . . M .

(7)

This relaxed formulation produces an upper bound solution

for our problem.

C. Competitive Solution

To produce a competitive solution, we propose the Fixing
Heuristic shown in Algorithm (2). The algorithm accepts
the matrix A, of dimensions M × T where the element ai,j
time slot j. The
level of model i at
represents the trust
heuristic selects a maximum of B + 1 ML models (which
results in a maximum of B model reconﬁgurations) to be
used during T in order to maximize the overall trust level.
The proposed heuristic employs two constants: (1) a threshold
H that represents the maximum trust level selected from the
fractional solution (0 <H< 1); and (2) epsilon (cid:15) which is a
small value that is subtracted from the value of H during each
iteration of the ﬁxing process (0 <(cid:15)< 0.1).

The proposed heuristic ﬁnds the lower bound solution ﬁrst
using the Splice heuristic 1 on matrix A. Next, the proposed
ﬁxing heuristic applies LP on matrix A to ﬁnd a fractional
upper bound solution using H. Actually, the ML model with
the highest trust level in each time slot of A is compared with
H. The highest trust level is rounded to 1 if it is greater than
or equal to H while setting all other ML models to 0 during
that time slot. The same process is applied for trust levels
less than H. If the highest trust level is less than H in any
time slot, the selected ML model in the previous time slot is
selected for this time slot and is rounded to 1 while other ML
models are set to 0. After converting the matrix into a binary
one (i.e., 0 or 1 entries), the upper bound solution is computed
by counting the number of entries in A that are set to 1. If
the upper bound solution is found to be greater than the lower
bound solution, the lower bound solution is set to the value
of the upper bound solution. Also, H is reduced by (cid:15) and the
upper bound solution is recomputed in the hope of ﬁnding a

Algorithm 1 Splice Heuristic to ﬁnd a lower-bound solution
Input: Matrix A of size M × T where element ai,j
represents the trust level of model i at time slot j;
Maximum number of allowed reconﬁgurations B;
Maximum reconﬁguration rate R.
Output: matrix A, with each column having only 1 entry
to indicate the selected ML model at the given time slot.

1: Mark A as one unselected segment
2: Set i = 0
3: while i ≤ B AND number of unselected segments > 0

4:
5:

6:

7:

8:
9:

10:

do

Set ﬂag = False
Identify unselected segment j with at least R columns
that has the longest consecutive sequence of 1s in row k.

if Segment j exists then

Set all entries of row k to 1, and set all entries of

other rows of segment j to 0

Mark segment j as selected
if w is a selected segment that is adjacent to j and

both have 1s in the same row then

Merge segments w and j
Set ﬂag = True

end if

end if
if ﬂag = False then
Set i = i + 1

11:
12:
13:
14:
15:
16:
17: end while
18: Merge adjacent unselected segments into one
19: for every unselected segment j do
20:
21:

end if

Set leftSum = 0, rightSum = 0, selectedRow = 0
if there is a selected segment w with selected row k left

adjacent to segment j then

Set leftSum = sum of values of row k in segment j
Set selectedRow = k

end if
if there is a selected segment w with selected row z

right adjacent to segment j then

Set rightSum = sum of values of row z in segment j
if rightSum > leftSum then
Set selectedRow = z

end if

end if
Set all entries of selectedRow of segment j to 1 and all

22:
23:
24:
25:

26:
27:
28:
29:
30:
31:

entries of the other rows to 0

32: end for
33: Return A as the best solution.

8

Algorithm 2 Fixing Heuristic to produce a competitive
solution

Input: Matrix A of size M × T where element ai,j
represents the trust level of model i at time slot j;
Maximum number of allowed reconﬁgurations B;
Maximum reconﬁguration rate R;
Maximum trust level selected from fractional solution H;
Epsilon (cid:15), a small value subtracted from H.

Output: matrix A with each column having only one value
as 1 to indicate the selected ML model at the given time
slot.

PART I - Fixing

1: Set XSplice = A
2: Run the Splice heuristic on matrix XSplice
3: Set PreviousTrustLevel = element-wise sum of A &

XSplice where & is the bitwise AND operator

4: Set XFraction = A and apply linear programming to

generate a fractional solution

5: Set X = XFraction
6: Compute CurrentTrustLevel using PART II
7: while H > 0 AND equation 1 through 3 are satisﬁed

8:
9:
10:

AND CurrentTrustLevel > PreviousTrsutLevel do
Set PreviousTrustLevel = CurrentTrustLevel
Set H = H − eps
Set X = XFraction
Compute CurrentTrustLevel using PART II

11:
12: end while
13: Return X as the best solution.

PART II - Computing CurrentTrustLevel

14: Set rowNum = -1
15: for t from t0 to T do
16:

if maximum value from column t of matrix X ≥ H

17:

18:
19:
20:

21:
22:

then

Set this maximum value to 1 and set rest of values

in column t to 0

Set rowNum = row number of the maximum value

else if rowNum = −1 then

Set the maximum value to 1 and set rest of values in

column t to 0

else

Set the value at rowNum to 1 and set rest of values

in column t to 0

end if
23:
24: end for
25: Set CurrentTrustLevel = element-wise sum of A & X

where & is the bitwise AND operator

better solution. This process is repeated as long as the upper
bound solution is improved.

D. Proof of NP-completeness

Because our proposed algorithm depends on the solution
produced by Linear Programming (LP), which can be solved
using the Simplex algorithm,
then the complexity of our
proposed algorithm is similar to the complexity of the Sim-
plex algorithm which has polynomial-time complexity under
various probability distributions.

In this section, we show that the problem discussed in this
paper can be reduced from the decision version of the set cover
problem, which is known to be NP-complete.

We deﬁne the universe U as a set of tuples (i, j), i, j ∈ T
and i ≤ j. Each tuple (i, j) represents a time interval that
starts at time i and ends at time j during which the system

uses the same model without any reconﬁgurations. We also
deﬁne S as a family of subsets of U. The union of S results
in a period that covers U. In other words, the union of S results
in a period that starts at time 0 and ends at time T . Now the
cardinality of S is represented as follows:

0 ≤ ||S|| ≤

(cid:19)(cid:35)

(cid:34) T

(cid:88)

i=1

(cid:18)T
i

∗ M.

(8)

If k represents the maximum number of model reconﬁgura-
tions, the objective of our problem is to ﬁnd k subsets from S
while maximizing the total trust level. This problem is similar
to the decision version of the set cover problem. The universe
U and the set S of our problem are the same as the universe U
and set S in the set cover problem. However, in our problem,
every element is a tuple. The maximum number of model
reconﬁgurations k is the same as the integer number k in the
set cover problem. Consequently, the problem introduced in
this paper is NP-complete.

E. Worst-Case Analysis (Competitive Ratio Analysis)

The performance of our proposed ﬁxing heuristic is at least
the
as good as that of the splice heuristic. Consequently,
worst case scenario is encountered when the proposed heuristic
performs as the splice heuristic. When the maximum number
of allowed reconﬁgurations is set to B, the splice heuristic
ﬁnds (B + 1) segments, each of length R, that provide the
maximal trust level.

Proposition 1. For any conﬁguration X, the splice heuristic’s
worst-case performance has a competitive ratio of O(1) when
R is proportional to T and B is constant.

Proof. Let ALG be the splice heuristic and OPT be the optimal
algorithm. The ﬁrst part of the splice heuristic (Algorithm
1), speciﬁcally steps 1 through 17, ﬁnds the segments with
the longest consecutive sequence of 1s. Actually, both ALG
and OPT select those segments since they have the largest
sum of values (i.e., maximum trust levels). Speciﬁcally, those
segments have a total length of R(B + 1). However, the
two approaches differ in the rest of the solution, which is
the unselected segments in ALG. Now, at the end of the
ﬁrst part and in the worst-case scenario, Algorithm (1) may
already have performed B reconﬁgurations and cannot use
more reconﬁgurations. In other words, for every unselected
segment, Algorithm (1) can only use either of the selected
models in the adjacent selected segments but never a different
model. Consequently,
the two
models in the selected segments adjacent to the unselected
segment are different. Thus, the second part of Algorithm (1),
speciﬁcally steps 17 through 32, will pick the model that has
the largest sum in the unselected segment. In the worst-case
scenario, both the left and right adjacent selected segments
may have the same value when both used in the unselected
segment and therefore Algorithm (1)’s maximum loss is half
the segment length. However, the loss can never be less than
half the segment length. Mathematically, in the second part of
the solution, OPT achieves a maximum of T −R(B +1) while

in the worst-case scenario,

9

ALG achieves a minimum of 1
the following proof is concluded as follows.

2 [T − R(B + 1)]. Consequently,

Competitive Ratio = ALG(X)
OP T (X)
R(B + 1) + 1
2 [T − R(B + 1)]
R(B + 1) + [T − R(B + 1)]
2 T + 1
1

=

=

=

=

1
2
1
2

= O

2 R(B + 1)
T
T + R(B + 1)
T
RB
T

(cid:20) T
T

R
T

+

+

(cid:19)

(cid:18) R(B + 1)
T

(cid:21)

This competitive ratio is O(1) when R is proportional to T
and B is constant.

VI. PERFORMANCE EVALUATION

In order to evaluate the performance of the proposed heuris-
tic, we designed and implemented the data processing shown
in Figure 6. In our experiments, we focused on two case
studies that serve as proxies for smart city and IIoT services.
In our experiments, we trained multiple ML models using
sampled experimental datasets to simulate multiple service
providers sending ML models to resource-constrained devices.

A. Experimental Setup

The ﬁrst case study is a proxy for smart city services in
which the City Pulse EU FP7 project [25] dataset is used for
trafﬁc prediction. This dataset conveys the vehicular trafﬁc
volume collected from the city of Aarhus, Denmark, observed
between two points for a set duration of time over a period of
6 months.

is to predict

the remaining useful

The second case study is a proxy for IIoT services in
which the Turbofan engine degradation simulation dataset,
provided by the Prognostics CoE at NASA Ames [26], is used
for predicting the remaining useful life of engines. Engine
degradation simulation was carried out using a C-MAPSS
tool. The goal
life, or
the remaining number of cycles before the turbofan engine
reaches a level that no longer performs up to requirements. The
requirement is based on data collected from sensors located on
the turbofan and also on the number of cycles completed. The
prediction helps to plan maintenance in advance. The training
data consists of multiple multivariate time series with “cycle”
as the time unit, together with 21 sensor readings for each
cycle. Each time series can be assumed as being generated
from a different engine of the same type. The testing data
has the same data schema as the training data. The only
difference is that the data does not indicate when the failure
occurs. Finally, the ground truth data provides the number of
remaining work cycles for the engines in the test data. Table
III shows the description of datasets for both use case studies.
Each dataset is divided into training and testing subsets.
Each training dataset is sampled into 27 different datasets that
we used to train 27 deep LSTM models (17 of those models

10

Fig. 6: The data processing pipeline utilized in our experimental studies starting from the data collection phase and ending
with the selection of trustworthy ML models.

TABLE III: Description of datasets for case studies

Dataset

Trafﬁc
volume

Turbofan
engine
degrada-
tion

each

Number of records
in
training
sample
One week of hourly
counting the num-
ber of vehicles
3716 records sam-
pled from 250 en-
gines

Number of records
in testing set

Number of features

weeks
Seven
of
the
counting
number of vehicles
1800 records sam-
pled from 250 en-
gines

12 lags of number
of vehicles

27 features include
engine
cycle
id,
number, 3 settings,
21 sensors readings,
and
remaining
useful life (RUL)

are benign and 10 are malicious, 20% of the training data
of the malicious models are poisoned with causative attacks).
Even though it is possible to sample our experimental datasets
differently to produce a higher/lower number of machine
learning models, our choice of 27 was based on exploratory
experiments designed to explore the maximum number of ML
models that can be produced from our experimental datasets
without affecting the accuracy of the generated models. Specif-
ically, we use the swap x and 100 − x percentiles attack
model as a causative attack to intentionally poison the learners’
classiﬁcations by altering the labels of the training dataset. In
the swap x and 100 − x percentiles attack, the x percentile
value is exchanged with the 100 − x percentile value. As an
example of the swap x and 100−x percentiles attack, consider
the numeric dataset in Figure 7. To ﬁnd the ith percentile, we
need to sort the values in the unsorted list in ascending order.
Next, we multiply i% by the total number of items in the list
(i.e., 10 items). Now, for example, let us ﬁnd 20th and 80th
percentiles in the list. 20th percentile = 0.2 × 10 = 2 (item
index), which is value 174 in the list. 80th percentile = 0.8 ×
10 = 8 (item index), which is value 188 in the list. Now, to
swap the x and 100 − x percentiles in this dataset, every 174
will be replaced with 188, and every 188 will be replaced with
174 in the region in which we want to introduce the swap x
and 100 − x percentiles attack.

Since our goal in this paper is to assess the trust level
of LSTM models, we used grid search to tune the number
of hidden layers,
the
batch size, and the activation function parameters that play
a major role in the building of LSTM models [67] [68]
[69]. ML models are trained using different conﬁgurations.
Each conﬁguration includes different values for the number

the number of neurons in a layer,

Fig. 7: Example of swap x and 100 − x percentiles attack
model.

of hidden layers, the number of neurons in each layer, and
activation functions. Finally, we select the conﬁguration that
gives the best accuracy. Table IV shows the ranges of the
conﬁguration parameters used in our experiments to generate
the LSTM models.

TABLE IV: Conﬁguration parameter ranges

Parameter

Value

Number of hidden layers
Number of Neurons
Activation function
Batch size
Epochs

[1–6]
[4–1024]
Rectiﬁed Linear Unit (ReLU)
[72–200]
[10-50]

After building the models, we evaluated our model selection
approach on two experimental datasets. Every row in the trafﬁc
dataset represents the number of vehicles during a speciﬁc
hour. On the other hand, a row in the Turbofan engine dataset
represents the remaining useful life during a speciﬁc cycle.
Figures 9 to 12 for the smart city trafﬁc ﬂow prediction use-
case and Figures 14 to 17 for the IIoT predictive maintenance
use-case show that the trust level varies between the two
datsets. This is because the number of the observations in
the test set is different for the two experimental datasets.
For the trafﬁc dataset, the number of observations is ∼900
while for the turbofan dataset the number of observations is

∼1800. Next, we utilize λ standard deviations strategy, which
is inspired by the Six Sigma strategy [70] to exclude the
malicious models by identifying and removing the causes of
defects and minimizing variability using statistical methods
(namely, the mean and the standard deviation as shown in
Equations (9) and (10)), which leads to better trust prediction
models.

OutU pper = µ + λ × σ

OutLower = µ − λ × σ

(9)

(10)

Every time step, we compute µ, which is the mean of
the outputs of all models. Also, we compute σ, the standard
deviation of the outputs of all models. λ deﬁnes the model
exclusion strategy (i.e., any model that has an output that is
> µ + λ × σ or is < µ − λ × σ is excluded). The λ standard
deviations strategy produces a trust matrix of size M × T ,
with 1 indicating a trusted model and 0 indicating a malicious
model. The resulting matrix is then used as the input (i.e.,
matrix A) for the proposed ﬁxing heuristic.

B. Experimental Results

In this section, we discuss the results of using the proposed
ﬁxing heuristic along with the lower bound and upper bound
heuristics on the two datasets introduced in the previous
section.

1) Trafﬁc Flow Volume Prediction: In our ﬁrst experiment,
we studied the Root Mean Square Error (RMSE) of the models
selected using our proposed ﬁxing heuristic vis-`a-vis the
individual models. We set the reconﬁguration budget B to 7
as shown in Figure 8. As the ﬁgure shows, the proposed ﬁxing
heuristic results in 11%–66.95% less RMSE when compared
to the individual models.

In our second experiment, the trust levels resulting from the
three heuristics are compared under different reconﬁguration
budgets as illustrated in Figure 9. The ﬁgure shows the
conﬁdence interval for 5 replications. In each replication, the
malicious model is applied on a different model (e.g., M M1,
M M2, . . . , or M Mn). In this experiment, we set λ to 0.85,
M to 7, and the number of malicious models C to 1. The
number of non-malicious models is M − C.

In our third experiment, the trust level of the selected models
is studied as the number of models M is varied (5, 9, and 17)
as illustrated in Figure 10. In this experiment, we set λ to
0.85 and C to 1. In addition, the ﬁgure indicates that as M is
increased, the trust level of the selected models is increased
too.

Figure 11 shows the results of our fourth experiment. In
this experiment, the effect of using different values of λ (0.8,
0.85, 0.9, 0.95) on the trust level of the selected models is
analyzed. In this experiment, we set C to 1 and M to 7. The
ﬁgure shows this effect for different reconﬁguration budgets
B. The ﬁgure indicates that as λ is increased, the trust level
of the selected models is increased too.

Figure 12 shows the effect of the number of the malicious
LSTM models C (3, 5, and 7) on the trust level of the selected

11

models for different values of λ (0.8, 0.85, 0.9). The ﬁgure
also shows the actual number of malicious LSTM models
versus the identiﬁed number of malicious LSTM models. In
this experiment, we set M to 17 and B to 7.

2) Predictive Maintenance in IIoT: In our ﬁrst experiment,
we studied the Root Mean Square Error (RMSE) of the
models selected using our proposed ﬁxing heuristic vis-`a-
vis the individual models. We set the reconﬁguration budget
B to 7 as shown in Figure 13. As the ﬁgure shows, the
proposed ﬁxing heuristic results in 0.5%–15% less RMSE
when compared to the individual models.

In our second experiment, the trust levels resulting from the
three heuristics are compared under different reconﬁguration
budgets as illustrated in Figure 14. The ﬁgure shows the conﬁ-
dence interval for 5 different replications. In each replication,
the malicious model is applied to a different model (e.g. M M1,
M M2, . . . , or M Mn). In this experiment, we set λ to 0.75,
number of malicious models C to 1, and M to 7. The number
of non-malicious models is M − C.

In the third experiment, the trust level of the selected models
is studied as the number of models M is varied (5, 7, and 9)
as illustrated in Figure 15. In this experiment, we set λ to
0.75 and C to 1. In addition, the ﬁgure indicates that as M is
increased, the trust level of the selected models is increased
too.

Figure 16 shows the results of our fourth experiment. In this
experiment, the effect of using different values of λ (0.7, 0.75,
0.8) on the trust level of the selected models is analyzed. In this
experiment, we set C to 1 and M to 7. The ﬁgure shows this
effect given different reconﬁguration budgets B. The ﬁgure
indicates that as λ is increased, the trust level of the selected
models is increased too.

Figure 17 shows the effect of the number of the malicious
LSTM models C (1, 2, and 3) on the trust level of the selected
models for different values of λ (0.7, 0.75, 0.8). The ﬁgure
also shows the actual number of malicious LSTM models
versus the identiﬁed number of malicious LSTM models. In
this experiment, we set M to 7 and B to 7.

C. Discussion and Lessons Learned

We can conclude the following based on the results pre-

sented in the previous section:

1) It is important to evaluate ML models used in critical
and sensitive decisions in terms of trustworthiness and
reliability. Additionally, other traditional criteria of ML
model evaluation must be considered (e.g., accuracy, run
time, etc.).

2) Our proposed ﬁxing heuristic strives to maximize the
trust level while not affecting the accuracy of the se-
lected models, as Figures 8 and 13 indicate.

level

3) Figures 9 and 14 show that our proposed ﬁxing heuristic
is 0.7%–2.53%
is able to obtain a trust
lower than that obtained by the upper bound solution
in smart city case study, and 0.49%–3.17% lower than
that obtained by the upper bound solution in IIoT case
study. Figures 9 and 14 also indicate that by increasing
the reconﬁguration budget, the trust level is increased.

that

12

Fig. 8: Smart city trafﬁc ﬂow prediction use-case: RMSE of
the models using the ﬁxing heuristic vs. individual models.

Fig. 9: Smart city trafﬁc ﬂow prediction use-case: Trust level
of upper bound, lower bound, and proposed heuristics.

Fig. 10: Smart city trafﬁc ﬂow prediction use-case: The
effect of the number of selected models on the trust level.

Fig. 11: Smart city trafﬁc ﬂow prediction use-case: The
effect of λ on the trust level.

Fig. 12: Smart city trafﬁc ﬂow prediction use-case: The
effect of malicious models on the trust level.

Fig. 13: IIoT predictive maintenance use-case: RMSE
using the ﬁxing heuristic vs. individual models.

13

Fig. 14: IIoT predictive maintenance use-case: Trust level of
upper bound, lower bound, and proposed heuristics.

Fig. 15: IIoT predictive maintenance use-case: The effect
of the number of selected models on the trust level.

Fig. 16: IIoT predictive maintenance use-case: The effect
of λ on the trust level.

Fig. 17: IIoT predictive maintenance use-case: The effect of
malicious models on the trust level.

However, there is a limit beyond which increasing the
number of reconﬁgurations does not increase the trust
level.

4) Figures 10 and 15 indicate that increasing the number of
selected models lead to an increase in the trust level of
the overall system. This fact is similar to the concept
of evaluating the seller feedback on online shopping
sites, restaurants, or hotels reviews. As the volume
of feedback increases, the level of reliability of such
reviews increases as well.

5) Figures 11 and 16 indicate that increasing λ, the number
of the excluded models is decreased. However, increas-
ing λ beyond a speciﬁc threshold may lead to the use
of malicious models. On the other hand, using a small
value for λ leads to excluding more models, which might
not be malicious.

6) Figures 12 and 17 indicate that increasing the number
of malicious models leads to a decrease in the trust

level of the overall system. This is due to the fact that
the proposed heuristic excludes malicious models and
it might reach a fail-safe execution state in which it
informs the resource-constrained devices that there are
no trusted ML models to be hosted on them.

VII. CONCLUSIONS AND FUTURE WORKS

In this paper, we consider the paradigm in which resource-
constrained IoT devices execute ML algorithms locally, with-
out necessarily being connected to the cloud all the time.
This paradigm is desirable in systems that have strict latency,
connectivity, energy, privacy, and security requirements. There
is a strong need in such environments to evaluate the level
of trustworthiness of ML models built by different service
providers, we formulate the problem of ﬁnding a subset of ML
models that maximizes the trustworthiness while adhering to
a given reconﬁguration budget and rate constraints. We prove

that this problem is NP-complete and propose a ﬁxing heuristic
that ﬁnds a near-optimal solution in polynomial time.

To measure the performance of the proposed ﬁxing heuristic
compared to integer linear programming (ILP), we applied our
proposed ﬁxing heuristic to two different case studies: (1) the
trafﬁc ﬂow volume dataset to predict the number of vehicles
(as a proxy case study for smart cities services); and (2) the
turbofan engine degradation simulation dataset to predict the
remaining useful life for the engine (as a proxy for IIoT
services). Our proposed ﬁxing heuristic returns impressive
performance achieving a high trust level that is less than the
optimal ILP solution by only 0.7%–2.53% in the smart city
service case study and 0.49%–3.17% less in the IIoT service
case study.

There are a number of avenues of future work that can
be pursued. Although we only use LSTM for developing the
models in this paper, other types of models (e.g., CNN, deep
neural networks, and SVM) can also be explored. It would
be interesting to perform a comparative study of these models
and also consider their robustness to adversarial attacks com-
pared to our proposed ﬁxing heuristic. Additionally, potential
applications of our proposed heuristic can be explored in the
speech, video, and medical domains, and in recommendation
systems.

REFERENCES

[1] P. P. Ray, “A survey of IoT cloud platforms,” Future Computing
and Informatics Journal, vol. 1, no. 1, pp. 35–46, Dec. 2016.
[Online]. Available: http://www.sciencedirect.com/science/article/pii/
S2314728816300149

[2] F. Tramr, F. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart, “Stealing
Machine Learning Models via Prediction APIs,” in Proceedings of
the 25th USENIX Conference on Security Symposium, ser. SEC’16.
Berkeley, CA, USA: USENIX Association, 2016, pp. 601–618.
[Online]. Available: http://dl.acm.org/citation.cfm?id=3241094.3241142
Re-
Nov.
https://www.marketresearchengine.com/

[3] “Machine
search
[Online]. Available:
2017.
machine-learning-as-a-service-market

Service Market,” Market
Report

as
a
Technical

TMMLSM1117,

Learning

Engine,

[4] G. Dn, R. B. Bobba, G. Gross, and R. H. Campbell, “Cloud computing
for the power grid: From service composition to assured clouds,” in
proceedings 5th USENIX Workshop on Hot Topics in Cloud Computing
(HotCloud 13), San Jose, CA, June 2013, pp. 1–6.

[5] R.

the
I. Meneguette, “A Vehicular Cloud-Based Framework for
Intelligent Transport Management of Big Cities,” International Journal
of Distributed Sensor Networks, vol. 12, no. 5, p. 8198597, May 2016.
[Online]. Available: https://doi.org/10.1155/2016/8198597

[6] J. Hanen, Z. Kechaou, and M. B. Ayed, “An enhanced healthcare
system in mobile cloud computing environment,” Vietnam Journal of
Computer Science, vol. 3, no. 4, pp. 267–277, Nov. 2016. [Online].
Available: https://doi.org/10.1007/s40595-016-0076-y

[7] X. Zhang, Y. Wang, L. Chao, C. Li, L. Wu, X. Peng, and Z. Xu,
“IEHouse: A non-intrusive household appliance state recognition sys-
tem,” in Proceedings 2017 IEEE SmartWorld, Ubiquitous Intelligence
Computing, Advanced Trusted Computed, Scalable Computing Commu-
nications, Cloud Big Data Computing, Internet of People and Smart
City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI),
San Francisco, CA, USA, August 2017, pp. 1–8.

[8] D. Mourtzis, E. Vlachou, N. Milas, and N. Xanthopoulos, “A Cloud-
based Approach for Maintenance of Machine Tools and Equipment
Based on Shop-ﬂoor Monitoring,” Procedia CIRP, vol. 41, pp. 655–660,
Jan. 2016. [Online]. Available: http://www.sciencedirect.com/science/
article/pii/S2212827115011488

[9] M. Barreno, B. Nelson, R. Sears, A. D. Joseph, and J. D. Tygar, “Can
machine learning be secure,” in Proceedings of the ACM Symposium
on Information, Computer, and Communication Security (ASIACCS).
Taipei, Taiwan: ACM Press, March 2006, pp. 16–25.

14

[10] R. Lee, M. Assante, and T. Conway, “Analysis of

the cyber
attack on the Ukrainian power grid,” Mar. 2016, Available at:
https://ics.sans.org/media/E-ISAC SANS Ukraine DUC 5.pdf.

[11] D. Kushner, “The Real Story of Stuxnet,” IEEE Spectrum: Technology,
Engineering, and Science News, February 2013. [Online]. Available:
https://spectrum.ieee.org/telecom/security/the-real-story-of-stuxnet
[12] “Seven Iranians Working for Islamic Revolutionary Guard Corps-
Afﬁliated Entities Charged for Conducting Coordinated Campaign
of Cyber Attacks Against U.S. Financial Sector,” Mar. 2016, avail-
able at https://www.justice.gov/opa/pr/seven-iranians-working-islamic-
revolutionary-guard-corps-afﬁliated-entities-charged.

[13] K. M. Khan and Q. Malluhi, “Establishing Trust in Cloud Computing,”

IT Professional, vol. 12, no. 5, pp. 20–27, Sep. 2010.

[14] S. Pearson, “Privacy, Security and Trust

in Cloud Computing,” in
Privacy and Security for Cloud Computing, S. Pearson and G. Yee,
Eds. Springer London, 2013, pp. 3–42.

[15] M. Chiregi and N.

Jafari Navimipour, “Cloud computing and
trust evaluation: A systematic literature review of the state-of-the-
art mechanisms,” Journal of Electrical Systems and Information
Technology, Oct. 2017. [Online]. Available: http://www.sciencedirect.
com/science/article/pii/S2314717217300430

[16] J. Sidhu and S. Singh, “Compliance based Trustworthiness Calculation
Mechanism in Cloud Environment,” Procedia Computer Science,
vol. 37, pp. 439–446, Jan. 2014. [Online]. Available: http://www.
sciencedirect.com/science/article/pii/S187705091401031X

[17] D. H. Mcknight and N. L. Chervany, “What is Trust? A Conceptual
Analysis and an Interdisciplinary Model,” in Proceedings of the Ameri-
cas Conference on Information Systems, 2000, pp. 10–13.

[18] D. H. McKnight and N. L. Chervany, “What Trust Means in
E-Commerce Customer Relationships: An Interdisciplinary Conceptual
Typology,” International Journal of Electronic Commerce, vol. 6, no. 2,
pp. 35–59, Dec. 2001. [Online]. Available: https://www.tandfonline.
com/doi/full/10.1080/10864415.2001.11044235

[19] P. Domingos, “A few useful things to know about machine learning,”
Communications of the ACM, vol. 55, no. 10, p. 78, Oct. 2012. [Online].
Available: http://dl.acm.org/citation.cfm?doid=2347736.2347755
[20] S. Kaul, “Speed and accuracy are not enough! Trustworthy machine
learning,” in AAAI/ACM Conference on AI, Ethics, and Society, New
Orleans, USA, Feb. 2018, pp. 372–373.

[21] A. Kurakin, I. Goodfellow, and S. Bengio, “Adversarial examples in
the physical world,” arXiv:1607.02533 [cs, stat], Jul. 2016. [Online].
Available: http://arxiv.org/abs/1607.02533

[22] G. F. Elsayed, S. Shankar, B. Cheung, N. Papernot, A. Kurakin,
I. Goodfellow, and J. Sohl-Dickstein, “Adversarial Examples that Fool
both Computer Vision and Time-Limited Humans,” arXiv:1802.08195
[cs, q-bio, stat], Feb. 2018. [Online]. Available: http://arxiv.org/abs/
1802.08195

[23] H. Hosseini, Y. Chen, S. Kannan, B. Zhang, and R. Poovendran,
“Blocking Transferability of Adversarial Examples in Black-Box
Learning Systems,” arXiv:1703.04318 [cs], Mar. 2017.
[Online].
Available: http://arxiv.org/abs/1703.04318

[24] N. Moati, H. Otrok, A. Mourad, and J.-M. Robert, “Reputation-based
cooperative detection model of selﬁsh nodes in cluster-based QoS-
OLSR protocol,” vol. 75, no. 3, pp. 1747–1768. [Online]. Available:
http://link.springer.com/10.1007/s11277-013-1419-y

[25] “CityPulse

Dataset

Collection,”

Available

at:

http://iot.ee.surrey.ac.uk:8080/.

[26] A.

Saxena

and G. K.,

Engine Degradation
2008,
at: https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-
[Online]. Available: https://ti.arc.nasa.gov/tech/dash/

Simulation Data Set,” NASA Ames Research Center,
Available
data-repository/.
groups/pcoe/prognostic-data-repository/

“Turbofan

[27] B. Cline, R. S. Niculescu, D. Huffman, and B. Deckel, “Predictive main-
tenance applications for machine learning,” in 2017 Annual Reliability
and Maintainability Symposium (RAMS), Orlando, FL, USA, Jan. 2017,
pp. 1–7.

[28] R. Sipos, D. Fradkin, F. Moerchen, and Z. Wang, “Log-based predictive
maintenance,” in Proceedings of the 20th ACM SIGKDD international
conference on Knowledge discovery and data mining - KDD ’14. New
York, New York, USA: ACM Press, 2014, pp. 1867–1876. [Online].
Available: http://dl.acm.org/citation.cfm?doid=2623330.2623340
[29] Y. Lv, Y. Duan, W. Kang, Z. Li, and F. Wang, “Trafﬁc Flow Prediction
With Big Data: A Deep Learning Approach,” IEEE Transactions on
Intelligent Transportation Systems, vol. 16, no. 2, pp. 865–873, Apr.
2015.

[30] A. Paul, N. Chilamkurti, A. Daniel, and S. Rho, “Chapter 8 - Big
Data collision analysis framework,” in Intelligent Vehicular Networks

and Communications, A. Paul, N. Chilamkurti, A. Daniel, and S. Rho,
Eds.
Elsevier, Jan. 2017, pp. 177–184. [Online]. Available: http:
//www.sciencedirect.com/science/article/pii/B9780128092668000089
[31] N. Huq, R. Vosseler, and M. Swimmer, “Cyberattacks Against Intelligent
Transportation Systems: Assessing Future Threats to ITS,” Trend Micro,
Technical Report, 2017.

[32] T. Speicher, M. B. Zafar, K. P. Gummadi, A. Singla, and A. Weller,
“Reliable learning by subsuming a trusted model: Safe exploration of the
space of complex models,” in ICML 2017 Workshop, Sydney, Australia,
August 2017, pp. 1–5.

[33] S. Ghosh, P. Lincoln, A. Tiwari, and X. Zhu, “Trusted Machine Learning
for Probabilistic Models,” in Reliable Machine Learning in the Wild at
ICML 2016, New York City, NY, USA, June 2016, pp. 1–5. [Online].
Available: https://sites.google.com/site/wildml2016/ghosh16trusted.pdf

[34] X. Zhang, X. Zhu, and S. J. Wright, “Training Set Debugging
Using Trusted Items,” arXiv:1801.08019, pp. 1–8, Jan. 2018. [Online].
Available: https://arxiv.org/abs/1801.08019

[35] M. T. Ribeiro, S. Singh, and C. Guestrin, “”Why Should I Trust You?”:
Explaining the Predictions of Any Classiﬁer,” arXiv:1602.04938 [cs,
stat], Feb. 2016. [Online]. Available: http://arxiv.org/abs/1602.04938

[36] U. Jayasinghe, G. M. Lee, T.-W. Um, and Q. Shi, “Machine learning
based trust computational model for IoT services,” IEEE Transactions
on Sustainable Computing, vol. 4, no. 1, pp. 39–52, Jan. 2019.
[37] A. Fariha, A. Tiwari, A. Radhakrishna, S. Gulwani, and A. Meliou,
“Data invariants: On trust in data-driven systems,” arXiv:2003.01289
[cs], Mar. 2020. [Online]. Available: http://arxiv.org/abs/2003.01289

[38] J. Drozdal, J. Weisz, D. Wang, G. Dass, B. Yao, C. Zhao, M. Muller,
L. Ju, and H. Su, “Trust in AutoML: Exploring information needs
for establishing trust
in automated machine learning systems,” in
Proceedings of the 25th International Conference on Intelligent User
Interfaces, Cagliari, Italy, Mar. 2020, pp. 297–307. [Online]. Available:
http://arxiv.org/abs/2001.06509

[39] O. A. Wahab, J. Bentahar, H. Otrok, and A. Mourad, “Optimal load
distribution for the detection of VM-based DDoS attacks in the cloud,”
IEEE Transactions on Services Computing, vol. 13, no. 1, pp. 114–129,
January 2020.

[40] T. Liu, H. Yao, R. Ji, Y. Liu, X. Liu, X. Sun, P. Xu, and Z. Zhang,
“Vision-Based Semi-supervised Homecare with Spatial Constraint,” in
Advances in Multimedia Information Processing - PCM 2008, ser.
Lecture Notes in Computer Science, Y.-M. R. Huang, C. Xu, K.-S.
Cheng, J.-F. K. Yang, M. N. S. Swamy, S. Li, and J.-W. Ding, Eds.
Springer Berlin Heidelberg, 2008, pp. 416–425.

[41] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu,
“Towards deep learning models resistant
to adversarial attacks,”
arXiv:1706.06083 [cs, stat], Sept. 2019. [Online]. Available: http:
//arxiv.org/abs/1706.06083

[42] S. G. Finlayson, J. D. Bowers, J. Ito, J. L. Zittrain, A. L. Beam,
and I. S. Kohane, “Adversarial attacks on medical machine learning,”
Science, vol. 363, no. 6433, pp. 1287–1289, March 2019, publisher:
American Association for the Advancement of Science Section: Policy
Forum. [Online]. Available: https://science.sciencemag.org/content/363/
6433/1287

[43] L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, and J. D.
the 4th
Tygar, “Adversarial machine learning,” in Proceedings of
ACM workshop on Security and artiﬁcial intelligence, ser. AISec ’11.
Chicago, Illinois, USA: Association for Computing Machinery, Oct.
2011, pp. 43–58. [Online]. Available: https://doi.org/10.1145/2046684.
2046692

[44] P. Saadatpanah, A. Shafahi, and T. Goldstein, “Adversarial attacks on
copyright detection systems,” arXiv:1906.07153 [cs, stat], June 2019.
[Online]. Available: http://arxiv.org/abs/1906.07153

[45] K. Ren, T. Zheng, Z. Qin, and X. Liu, “Adversarial attacks and
defenses in deep learning,” Engineering, vol. 6, no. 3, pp. 346–360,
Mar. 2020. [Online]. Available: http://www.sciencedirect.com/science/
article/pii/S209580991930503X

[46] A. Chakraborty, M. Alam, V. Dey, A. Chattopadhyay,

and
D. Mukhopadhyay, “Adversarial attacks and defences: A survey,”
arXiv:1810.00069
[Online]. Available:
http://arxiv.org/abs/1810.00069

stat], Sept.

2018.

[cs,

[47] N. Akhtar and A. Mian, “Threat of Adversarial Attacks on Deep
Learning in Computer Vision: A Survey,” arXiv:1801.00553 [cs], Jan.
2018. [Online]. Available: http://arxiv.org/abs/1801.00553

[48] X. Yuan, P. He, Q. Zhu, and X. Li, “Adversarial examples: Attacks and
defenses for deep learning,” IEEE Transactions on Neural Networks and
Learning Systems, vol. 30, no. 9, pp. 2805–2824, Sept. 2019.

15

pp. 205–231, Mar. 2000. [Online]. Available: http://linkinghub.elsevier.
com/retrieve/pii/S0022249699912841

[50] L. Kotthoff, “Algorithm Selection for Combinatorial Search Problems: A
Survey,” in Data Mining and Constraint Programming: Foundations of
a Cross-Disciplinary Approach, ser. Lecture Notes in Computer Science,
C. Bessiere, L. De Raedt, L. Kotthoff, S. Nijssen, B. O’Sullivan, and
D. Pedreschi, Eds. Cham: Springer International Publishing, 2016, pp.
149–190.

[51] C. Thornton, F. Hutter, H. H. Hoos, and K. Leyton-Brown, “Auto-
WEKA: combined selection and hyperparameter optimization of
classiﬁcation algorithms,” Chicago, Illinois, USA, pp. 847–855, August
2013. [Online]. Available: http://dl.acm.org/citation.cfm?doid=2487575.
2487629

[52] B. Komer, J. Bergstra, and C. Eliasmith, “Hyperopt-Sklearn: Automatic
Hyperparameter Conguration for Scikit-Learn,” in proceedings of The
13th Python in Science Conf. (Scipy 2014), Austin, Texas, July 2014,
pp. 32–37.

[53] E. R. Sparks, A. Talwalkar, V. Smith,

J. Franklin, M.

J. Kottalam, X. Pan,
J. Gonzalez, M.
and T. Kraska,
“MLI: An API for Distributed Machine Learning,” in 2013 IEEE
13th International Conference on Data Mining.
Dallas, TX,
USA: IEEE, Dec. 2013, pp. 1187–1192. [Online]. Available: http:
//ieeexplore.ieee.org/document/6729619/

Jordan,

I.

[54] P. Lokuciejewski, M. Stolpe, K. Morik, and P. Marwedel, “Automatic
selection of machine learning models for compiler heuristic generation,”
in Proceedings of the 4th Workshop on Statistical and Machine Learning
Approaches to Architecture and Compilation (SMART), Pisa, Italy, Jan.
2010, pp. 3–17.

[55] R. Leite, P. Brazdil, and J. Vanschoren, “Selecting Classiﬁcation Algo-
rithms with Active Testing,” in Machine Learning and Data Mining in
Pattern Recognition, ser. Lecture Notes in Computer Science, P. Perner,
Ed. Springer Berlin Heidelberg, 2012, pp. 117–131.

[56] J. N. van Rijn, S. M. Abdulrahman, P. Brazdil, and J. Vanschoren, “Fast
Algorithm Selection Using Learning Curves,” in Advances in Intelligent
Data Analysis XIV, ser. Lecture Notes in Computer Science, E. Fromont,
T. De Bie, and M. van Leeuwen, Eds. Springer International Publishing,
2015, pp. 298–309.

[57] A. Kumar, S. Goyal, and M. Varma, “Resource-efﬁcient Machine
Learning in 2 KB RAM for the Internet of Things,” in Proceedings
the 34 th International Conference on Machine Learning,
of
Sydney, Australia, Jul. 2017, pp. 1935–1944.
[Online]. Available:
http://proceedings.mlr.press/v70/kumar17a.html

[58] C. Gupta, A. S. Suggala, A. Goyal, H. V. Simhadri, B. Paranjape,
A. Kumar, S. Goyal, R. Udupa, M. Varma, and P. Jain, “ProtoNN:
Compressed and Accurate kNN for Resource-scarce Devices,” in
International Conference on Machine Learning, Sydney, Australia, Jul.
2017, pp. 1331–1340. [Online]. Available: http://proceedings.mlr.press/
v70/gupta17a.html

[59] M. Motamedi, D. Fong, and S. Ghiasi, “Machine Intelligence on
Resource-Constrained IoT Devices: The Case of Thread Granularity
Optimization for CNN Inference,” ACM Trans. Embed. Comput. Syst.,
vol. 16, no. 5s, pp. 151:1–151:19, Sep. 2017. [Online]. Available:
http://doi.acm.org/10.1145/3126555

[60] W. Meng, Z. Gu, M. Zhang, and Z. Wu, “Two-Bit Networks
for Deep Learning on Resource-Constrained Embedded Devices,”
arXiv:1701.00485, Jan. 2017. [Online]. Available: https://arxiv.org/abs/
1701.00485

[61] A. Shoeb and J. Guttag, “Application of Machine Learning to
Epileptic Seizure Detection,” in Proceedings of the 27th International
Conference on International Conference on Machine Learning, ser.
ICML’10. USA: Omnipress, 2010, pp. 975–982. [Online]. Available:
http://dl.acm.org/citation.cfm?id=3104322.3104446

[62] B. Li, R. Lu, W. Wang, and K.-K. R. Choo, “Distributed host-based
collaborative detection for
in smart
grid cyber-physical system,” Journal of Parallel and Distributed
Computing, vol. 103, pp. 32–41, May 2017.
[Online]. Available:
http://www.sciencedirect.com/science/article/pii/S0743731516301885

false data injection attacks

[63] J.-H. Cho,

I.-R. Chen, and K. S. Chan, “Trust

public key management
Networks, vol. 44, pp. 58–75,
https://linkinghub.elsevier.com/retrieve/pii/S1570870516300555

threshold based
in mobile ad hoc networks,” Ad Hoc
[Online]. Available:

Jul. 2016.

[64] M. Raya, P. Papadimitratos, V. D. Gligor, and J. Hubaux, “On Data-
Centric Trust Establishment in Ephemeral Ad Hoc Networks,” in IEEE
INFOCOM 2008 - The 27th Conference on Computer Communications,
Phoenix, AZ, USA, Apr. 2008, pp. 1238–1246.

[49] M. R. Forster, “Key Concepts in Model Selection: Performance and
Generalizability,” Journal of Mathematical Psychology, vol. 44, no. 1,

[65] A. Srinivasan,

J. Teitelbaum, and J. Wu, “DRBTS: Distributed
Reputation-based Beacon Trust System,” in 2006 2nd IEEE Interna-

tional Symposium on Dependable, Autonomic and Secure Computing,
Indianapolis, IN, USA, Sep. 2006, pp. 277–283.

[66] R. K. Shahzad and N. Lavesson, “Comparative Analysis of Voting
Schemes for Ensemble-based Malware Detection,” Journal of Wireless
Mobile Networks, Ubiquitous Computing, and Dependable Applications,
vol. 4, pp. 98–117, Mar. 2013.

[67] B. Qolomany, M. Maabreh, A. Al-Fuqaha, A. Gupta, and D. Benhaddou,
“Parameters optimization of deep learning models using particle swarm
optimization,” in 2017 13th International Wireless Communications and
Mobile Computing Conference (IWCMC). Valencia, Spain: IEEE, June
2017, pp. 1285–1290.

[68] B. Qolomany, A. Al-Fuqaha, D. Benhaddou, and A. Gupta, “Role of
Deep LSTM Neural Networks and Wi-Fi Networks in Support of Occu-
pancy Prediction in Smart Buildings,” in 2017 IEEE 19th International
Conference on High Performance Computing and Communications;
IEEE 15th International Conference on Smart City; IEEE 3rd Interna-
tional Conference on Data Science and Systems (HPCC/SmartCity/DSS),
Bangkok, Thailand, Dec. 2017, pp. 50–57.

[69] B. Qolomany, A. Al-Fuqaha, A. Gupta, D. Benhaddou, S. Alwajidi,
J. Qadir, and A. C. Fong, “Leveraging Machine Learning and Big Data
for Smart Buildings: A Comprehensive Survey,” IEEE Access, vol. 7,
pp. 90 316–90 356, 2019.

[70] T. Pyzdek, The Six Sigma Handbook: The Complete Guide for Green-
belts, Blackbelts, and Managers at All Levels, Revised and Expanded
Edition, 2nd ed. New York: McGraw-Hill, Mar. 2003.

Basheer Qolomany (S’17) received the Ph.D. and
second masters en-route to Ph.D. degrees in Com-
puter Science from Western Michigan University
(WMU), Kalamazoo, MI, USA, in 2018. He also
received his B.Sc. and M.Sc. degrees in computer
science from University of Mosul, Mosul city, Iraq,
in 2008 and 2011, respectively. He is currently an
Assistant Professor at Department of Cyber Systems,
University of Nebraska at Kearney (UNK), Kearney,
NE, USA. Previously, he served as a Visiting Assis-
tant Professor at Department of Computer Science,
Kennesaw State University (KSU), Marietta, GA, USA, in 2018-2019; a
Graduate Doctoral Assistant at Department of Computer Science, WMU, in
2016-2018; he also served as a lecturer at Department of Computer Science,
University of Duhok, Kurdistan region of Iraq, in 2011-2013. His research
interests include machine learning, deep learning, Internet of Things, smart
services, cloud computing, and big data analytics. Dr. Qolomany has served
as a reviewer of multiple journals, including IEEE Internet of Things journal,
Energies Open Access Journal, and Elsevier - Computers and Electrical
Engineering journal. He also served as a Technical Program Committee (TPC)
member and a reviewer of some international conferences including IEEE
Globecom, IEEE IWCMC, and IEEE VTC.

Ihab Mohammed (S’14)
is a Ph.D. student at
the NEST Research Lab in the Computer Sci-
ence department of Western Michigan University,
Kalamazoo, MI, USA. He received his B.S. and
M.S. degrees in computer science from Al-Nahrain
University in Iraq in 2002 and 2005, respectively.
His current research interests include the design,
simulation, and analysis of algorithms in the ﬁelds
of computer networks, Internet of Things, vehicular
networks, and big data.

16

Ala Al-Fuqaha (S’00-M’04-SM’09) received Ph.D.
degree in Computer Engineering and Networking
from the University of Missouri-Kansas City, Kansas
City, MO, USA, in 2004. He is currently a profes-
sor at Hamad Bin Khalifa University (HBKU) and
Western Michigan University. His research interests
include the use of machine learning in general and
deep learning in particular in support of the data-
driven and self-driven management of large-scale
deployments of IoT and smart city infrastructure and
services, Wireless Vehicular Networks (VANETs),
cooperation and spectrum access etiquette in cognitive radio networks, and
management and planning of software deﬁned networks (SDN). He is a senior
member of the IEEE and an ABET Program Evaluator (PEV). He serves on
editorial boards of multiple journals including IEEE Communications Letter
and IEEE Network Magazine. He also served as chair, co-chair, and technical
program committee member of multiple international conferences including
IEEE VTC, IEEE Globecom, IEEE ICC, and IWCMC.

(S’85-M’89-SM’99-F’09)

Mohsen Guizani
re-
ceived the B.S. and M.S. degrees in electrical en-
gineering and the M.S. and Ph.D. degrees in com-
puter engineering from Syracuse University, in 1984,
1986, 1987, and 1990, respectively. He was the
Associate Vice President of Qatar University, the
Chair of the Computer Science Department, Western
Michigan University,
the Chair of the Computer
Science Department, University of West Florida, and
the Director of graduate studies at the University of
MissouriColumbia. He is currently a Professor with
the Department of Computer Science and Engineering, Qatar University. He
has authored or coauthored nine books and publications in refereed journals
and conferences. His research interests include wireless communications and
mobile computing, vehicular communications, smart grid, cloud computing,
and security.

Junaid Qadir (M’14 – SM’14) received Ph.D. from
University of New South Wales, Australia in 2008
and his Bachelors in Electrical Engineering from
UET, Lahore, Pakistan in 2000. He is a Professor
at the Information Technology University (ITU)–
Punjab, Lahore. He is the Director of the IHSAN
(ICTD; Human Development; Systems; Big Data
Analytics; Networks Lab) Research Lab at ITU
(http://ihsanlab.itu.edu.pk/). His primary research in-
terests are in the areas of computer systems and
networking and using ICT for development (ICT4D).
Dr. Qadir has served on the program committee of a number of international
conferences and reviews regularly for various high-quality journals. He is an
Associate Editor for IEEE Access, Springer Nature Central’s Big Data Ana-
lytics journal, Springer Human-Centric Computing and Information Sciences,
and the IEEE Communications Magazine. He is an award-winning teacher
who has been awarded the highest national teaching award in Pakistanthe
higher education commissions (HEC) best university teacher awardfor the year
2012-2013. He has considerable teaching experience and a wide portfolio of
taught courses in the disciplines of systems & networking; signal processing;
and wireless communications and networking. He is a senior member of IEEE
and ACM. He has been appointed as an ACM Distinguished Speaker from
2020 to 2022.

