1
2
0
2

y
a
M
0
1

]

C
O
.
h
t
a
m

[

2
v
4
9
4
3
1
.
2
1
9
1
:
v
i
X
r
a

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT
METHODS

ORAN GANNOT

Abstract. We study robustness properties of some iterative gradient-based meth-
ods for strongly convex functions, as well as for the larger class of functions with
sector-bounded gradients, under a relative error model. Proofs of the corresponding
convergence rates are based on frequency-domain criteria for the stability of nonlin-
ear systems. Applications are given to inexact versions of gradient descent and the
Triple Momentum Method. To further emphasize the usefulness of frequency-domain
methods, we derive improved analytic bounds for the convergence rate of Nesterov’s
accelerated method (in the exact setting) on strongly convex functions.

1. Introduction

1.1. Overview. As observed in [LRP], control-theoretic techniques originating with
the absolute stability problem provide a useful framework for the design and analysis of
iterative ﬁrst-order optimization methods. Certain fundamental algorithms, including
f
gradient descent, can be viewed as a linear system in feedback with the gradient
of the function to be optimized. More precisely, their iterates are of the form

∇

xt+1 = Axt + B

f (Cxt)

∇

(1.1)

for matrices A, B, C. The purpose of this paper is to show how frequency-domain
methods can be used to characterize robustness properties of such algorithms under a
relative error model.

To formulate the error model, suppose that instead of the exact gradient in (1.1) one
f (Cxt) + et, where the magnitude of the error et is bounded by a multiple

measures
δ

∇

∈

[0, 1) of the exact gradient:

et| ≤

|

δ

|∇

f (Cxt)

,

|

0.

t

≥

(1.2)

If f belongs to a class of functions for which the exact iterates converge exponentially
(i.e., geometrically) to a unique equilibrium, then it is still possible for the inexact
iterates to converge exponentially as well. Naturally, any convergence rate for the
inexact problem is expected to degrade with the size of δ. Since the error sequence
e can be chosen adversarially, upper bounds on the inexact rates provide a strong
measure of the robustness of a given algorithm to gradient perturbations.

 
 
 
 
 
 
2

ORAN GANNOT

Following a long tradition in control theory, exponential stability at a prescribed
rate for systems of the form (1.1) (often called Lur’e systems [Lur]) can be certiﬁed
in the time domain via the feasibility of a certain linear matrix inequality (LMI) with
two sets of decision variables:

(1) a storage function (a Lyapunov-type function), which is a quadratic form in

the state variables,

(2) multipliers corresponding to constraints satisﬁed by the nonlinearity (so-called

integral quadratic constraints, or IQCs).

For a ﬁxed set of IQCs, we refer to this feasibility problem as a stability test or stability
criterion. The frequency methods in this paper provide a systematic way of reducing
the number of free parameters for a given stability test: the feasibility problem can
alternatively be formulated in the frequency domain, wherein the storage function
does not appear explicitly. This eliminates a number of decision variables that grows
quadratically with the dimension of the state space. Furthermore, at the margins of
stability (e.g., when searching for the best possible exponential convergence rate), the
values of the multipliers are often determined uniquely by the frequency test.

These frequency methods are applied to inexact gradient descent, which exhibits
richer phenomenology than its exact counterpart. We study convergence rates for
inexact gradient descent over the set of strongly convex functions, as well as the larger
class of functions with sector-bounded gradients. For a discussion of these function
classes see §1.2 below, but we stress that functions with sector-bounded gradients
need not be convex. In the exact setting it is known that the worst-case exponential
convergence rates over these two classes coincide.

For inexact gradient descent our results are partially contained in [dKGT1], although
the methodology diﬀers. Using essentially the same stability tests but in the time-
domain, the authors of [dKGT1] numerically solve the feasibility problem for a range
of problem instantiations, and then guess analytic formulas for the decision variables.
This work proposes a principled and potentially simpler approach for deriving these
analytical results that does not depend on access to numerical solvers, nor on explicit
constructions of Lyapunov functions.

At the opposite end of the complexity scale, we consider an inexact version of the
Triple Momentum Method [VSFL]. Although this is the fastest known ﬁrst-order
method for optimizing strongly convex functions when an exact oracle is available, nu-
merical evidence suggests that it is not robust to perturbations [CHVSL]. We establish
an explicit convergence rate for the inexact problem. Based on numerical evidence we
conjecture that this rate is optimal with respect to the Jury–Lee criterion (the least
conservative stability test for strongly convex functions considered in this paper).

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

3

As an introduction to frequency-domain analysis, we also revisit Nesterov’s acceler-
ated gradient method in the exact setting for strongly convex functions. The standard
tuning and basic convergence rate for this method are given in [Nes, §2.2]. However,
it was observed numerically in [LRP] that this basic rate is conservative. In §2.5, we
show how the Jury–Lee criterion can be used to easily improve upon the known rate
by a constant factor.

1.2. Results for inexact gradient descent. First we introduce the function classes
used throughout the paper, which depend on two parameters 0

m < L.

≤

1 function is said to be bounded in the sector

Deﬁnition 1.1. The gradient of a
[m, L] if there exists y⋆ ∈
m(y

C
Rn such that

y⋆)

h

−

f (y), L(y

y⋆)

−

− ∇

f (y)

i ≤

0

− ∇

Rn. Denote by

for all y
S
the subset of functions such that y⋆ = 0 satisﬁes (1.3).

(m, L) the set of all such functions. Let

∈

(1.3)

0(m, L) denote

S

If f

∈ S

(m, L), then

f (y⋆) = 0 by continuity. Furthermore, if m > 0, then
the reference point y⋆ is the unique global minimizer of f . Observe that functions in
(m, L)

(m, L) can be far from convex. This is easily seen in one dimension: if f

∇

S
and y⋆ = 0, then the sector condition is equivalent to

∈ S

min(my, Ly)

f ′(y)

≤

≤

max(my, Ly),

which places no slope restrictions on f ′ at all. Sector-boundedness is also related to dif-
ferent notions of one-point convexity that arise in the literature; for some applications
in neural networks, matrix completion, and phase retrieval, see [KLY, LY, AGMM,
SL, CC, CLS, XCHZ]. In the context of robust control, the question of stability for
systems in feedback with sector-bounded nonlinearities is as old the subject itself [Lur].

Deﬁnition 1.2. Denote by
Lipschitz gradients. Let

(m, L) the set of m-strongly convex functions with L-
f (0) = 0.

0(m, L) denote the subset of functions such that

F

∇

R belongs to

(m, L) if x

F

f (x)

−

7→

(m/2)

2 is

x
k

k

→

F
1 function f : Rn

Precisely, a

convex and

C

f (y1)

f (y2)

y1

L
k

y2

−
− ∇
Rn. It is well-known that membership in

k
(m, L) is equivalent to the
for all y1, y2
strong monotonicity (or cocoercivity) of its gradient [Nes, Theorem 2.1.5]. In other
words, f

(m, L) if and only if

k ≤

k∇

F

∈

∈ F
f (y1)

h∇

for all y1, y2

∈

f (y2)

m(y1

− ∇
Rn. In particular,

−

−

F

y2),

∇
(m, L)

f (y1)

f (y2)

− ∇
(m, L) and

−

L(y1

−
0(m, L)

⊂ S

F

y2)

0

i ≤

(1.4)

0(m, L).

⊂ S

4

ORAN GANNOT

Next, we recall standard convergence properties of gradient descent on Rn over the

class

S

(m, L), where 0 < m < L. The iterates are given by

xt+1 = xt −
where α > 0. This can be written in the form (1.1) with A = C = In and B =
Set

f (xt),

∇

α

(1.5)

αIn.

−

ρGD = ρGD(m, L, α) := max(1

αm, αL

1).

−
(m, L), the gradient descent iterates

−

If α < 2/L, then ρGD
satisfy the exponential stability estimate

(0, 1). For a given f

∈

∈ S

xt −

k

x⋆k ≤

ρt

x0

k

,

x⋆k

−

0

t

≥

(1.6)

with ρ = ρGD. For a frequency interpretation of this bound see §2.3. The optimal
step size α = 2/(L + m) corresponds to the solution of 1
1, yielding the
well-known rate

αm = αL

−

−

ρGD(m, L, 2/(L + m)) =

κ
1
−
κ + 1

.

If f

1/κ.

Here κ = L/m is the condition number. When α = 1/L, one recovers the rate
ρGD(m, L, 1/L) = 1

−
2, then the fact that (1.6) holds with ρ = ρGD is classical [Pol]. As
far as we are aware, the fact that this is also true for f
(m, L) was ﬁrst emphasized
in [LRP]. The popular reference [Nes, Theorem 2.1.15] establishes (1.6) with the more
conservative rate

(m, L)

∈ F

∈ S

∩ C

¯ρGD :=

1

2αmL
L + m

−

(cid:19)

(cid:18)

1/2

.

(1.7)

This quantity is never less than ρGD, and equality holds if and only if α = 2/(L + m).

The rate ρGD is tight over

functions

(m, L). Speciﬁcally,

S

S

(m, L) includes all the quadratic

f (x) = 1
2h

+

Qx, x
i

p, x
i
for which the system (1.5) is linear. Consequently, a spectral analysis shows that
any ρ > 0 for which (1.6) holds is bounded from below by ρGD. Since this lower
(m, L) is
bound is attained, the worst-case convergence rate of gradient descent over
determined purely by its performance on quadratic functions.1

+ b, mIn (cid:22)

LIn

(cid:22)

Q

S

h

Now consider the inexact version of (1.5), where the gradient is perturbed by an

arbitrary sequence e satisfying (1.2):

∇
1For the reader familiar with the control-theoretic absolute stability problem, the convergence

xt+1 = xt −

α(

f (xt) + et).

(1.8)

result quoted above shows that gradient descent satisﬁes a version of the Aizerman conjecture.

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

5

If an estimate of the form (1.6) holds uniformly over
ρ

ρGD(δ), where now

≥

(m, L) for some ρ > 0, then

S

ρGD(δ) = ρGD(δ; m, L, α) := max(1

(1

−

−

δ)αm, (1 + δ)αL

1).

−

If α < 2/((1 + δ)L), then ρGD(δ)

(0, 1).

∈

In contrast with the exact setting, we are not able to verify that the rate ρGD(δ) is
[0, 1). Instead,

(m, L) for all choices of parameters and noise levels δ

∈

attained over
we have the following:

S

Proposition 1.3. Let 0 < m < L and α > 0. Suppose that 0
deﬁne

≤

δ < 2/(κ + 1), and

If α

≤

α− or α

≥

1

2

α− :=

δ

(cid:18)

−

L + m −
1
α+, then for any f
x⋆k ≤
xt −

k

∈ S
ρGD(δ)t

δ
m

, α+ :=

1
1 + δ

2
L + m

+

δ
L

.

(cid:19)

(cid:19)
(cid:18)
(m, L) the iterates (1.8) satisfy

x0

k

,

x⋆k

−

0.

t

≥

It is important to note that the range of parameters for which Proposition 1.3 holds
is optimal with respect to the stability criterion used in its proof, namely a perturbed
version of the circle criterion — see Lemma 2.15. More precisely, the frequency test
used to establish Proposition 1.3 depends on multipliers encoding the constraints (1.2)
and (1.3). The corresponding test is feasible for ρ = ρGD(δ) if and only if (m, L, α, δ)
satisfy the hypotheses of Proposition 1.3. In principle the test itself could be conser-
vative (in terms of certifying asymptotic stability), but for a non-asymptotic tightness
result see Lemma 1.7 below.

S

When α

α−, Proposition 1.3 was previously established in [dKGT1] using a
numerically-assisted method, as mentioned in §1.1. Their result was stated for strongly
convex functions, but it is clear that the proof also applies to

(m, L).

≤

As κ grows, the amount of noise that can be tolerated decreases towards zero. The
optimal step size in the context of Proposition 1.3 occurs when either α = α− or
α = α+. The corresponding convergence rate is

κ
1
−
κ + 1
Meanwhile, the value of α that minimizes ρGD(δ) over all α > 0 and the corresponding
value of ρGD(δ) are given by

+ δ.

ρ =

2

,

α⋆ :=

(1 + δ)L + (1

−
−
(0, 1). Thus Proposition 1.3 fails
Observe that α⋆ ∈
to certify the rate in (1.9), even for arbitrarily small δ > 0. Instead, we can use the
following result, which is new:

(α−, α+) for any L > m and δ

ρGD(δ; m, L, α⋆) =

(1.9)

δ)m

−

−

∈

.

(1 + δ)κ
(1
(1 + δ)κ + (1

δ)
δ)

6

ORAN GANNOT

Proposition 1.4. Let 0 < m < L and 0

≤

δ < 2√κ/(κ + 1). Deﬁne

¯ρGD(δ) :=

2αLm
L + m

+

1
(cid:18)

−

αδ2(L + m
2

−
α(L + m)

2αLm)

−

where in order to ensure that ¯ρGD(δ)

∈

0 < α < ¯α− :=

(0, 1) we assume that

4κ

δ2(κ + 1)2

−
2mκ(1 + κ)(1

δ2)

−

.

Then for any f

∈ S

(m, L) the iterates (1.8) satisfy

1/2

,

(cid:19)

(1.10)

xt −
It is always the case that ¯α−

k

x⋆k ≤

¯ρGD(δ)t

x0

k

,

x⋆k

−

0.

t

≥

2/((1 + δ)L), but α+ > 2/((1 + δ)L) if δ > 2/(κ + 1).
Observe that the restriction on δ is weaker than the one in Proposition 1.3. The
rate ¯ρGD(δ) has the following precise characterization: if (m, L, α, δ) are such that the
inexact circle criterion is infeasible with ρGD(δ), then ¯ρGD(δ) is the smallest rate for
which feasibility does hold. Conversely,

≤

≥
with equality if and only if α = α− or α = α+. Note that when δ vanishes, ¯ρGD(0) is
simply (1.7).

¯ρGD(δ)

ρGD(δ),

Let us now assume that δ < 2√κ/(κ + 1). The best possible rate aﬀorded by either
Proposition 1.3 or Proposition 1.4 is obtained by minimizing ¯ρGD(δ) over α < ¯α−. The
minimizer ¯α⋆ is

¯α⋆ :=

2

L + m −

m(1

δ(κ
1)
δ2)1/2κ1/2(κ + 1)

−

,

(1.11)

and the corresponding minimal rate is given by

−

¯ρGD(δ; m, L, ¯α⋆) =

1
κ + 1

(κ

−

1)((1

−

δ2)(κ

−

1) + 4κ1/2(1

−

δ2)1/2δ) + 4κδ2

1/2

.

Proposition 1.3 and Proposition 1.4 are best understood in tandem graphically — see
Figure 1.

(cid:1)

(cid:0)

Finally, we show that by restricting to

(m, L), inexact gradient descent attains its

optimal exponential convergence rate ρGD(δ) for any δ

F

[0, 1).2

∈

Proposition 1.5. Let 0 < m < L and 0
ρ
≥
satisfy

ρGD(δ), then there exists c > 0 such that for any f

≤

∈ F

δ < 1. If 0 < α < 2/((1 + δ)L) and
(m, L) the iterates (1.5)

xt −

k

x⋆k ≤

cρt

x0

k

,

x⋆k

−

0.

t

≥

2In the language of the absolute stability problem, inexact gradient descent satisﬁes a version of

the Kalman conjecture.

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

7

1

ρ

0

1

ρ

0

LMI
ρGD(δ)
¯ρGD(δ)

LMI
ρGD(δ)
¯ρGD(δ)

α−

α

¯α⋆

α⋆

α+

¯α−

α

Figure 1. An illustration of Proposition 1.3 and Proposition 1.4.
These ﬁgures were produced with m = 1 and L = 3. In the top ﬁgure
δ = 2/5, so that δ < 2/(κ + 1), and in the bottom ﬁgure δ = 4/5,
so that 2/(κ + 1) < δ < 2√κ/(κ + 1). The largest value on the α
axis is 2/((1 + δ)L). The thick gray line is the optimal rate computed
numerically using (LMI) and the sector IQC (see §3.1 for details). In
α+ the numerically computed rate
the top ﬁgure, when α
α− or α
(α−, α+),
agrees with ρGD(δ) in accordance with Proposition 1.3; if α
then it agrees with ¯ρGD(δ). In the bottom ﬁgure only Proposition 1.4 is
applicable.

≥

≤

∈

8

ORAN GANNOT

1

ρ

0

LMI
ρGD(δ)

α

Figure 2. Here m = 1, L = 3, and δ = 3/5. The thick gray line is
the optimal rate computed numerically using (LMI) and the oﬀ-by-one
IQC for strongly convex functions (see §3.2 for details). These numerical
results are consistent with Proposition 1.5.

In particular, the optimal rate (1.9) is feasible for inexact gradient descent on
strongly convex functions — see Figure 2. When an exact line search is employed,
it was shown in [dKGT2] that the rate (1.9) holds for inexact gradient descent on
strongly convex functions.

Remark 1.6. As observed by an anonymous referee, Proposition 1.5 can already be
deduced from [dKGT1, Appendix B, Proof of Theorem 5.3]. There, the authors show
that

f (xt+1)

f (x⋆)

−

ρGD(δ)2(f (xt)

f (x⋆)),

t

0

≤
α+, but a close examination shows that the same

≥

−

(1.12)

whenever f
∈ F
proof actually applies for α

(m, L) and α

≤

2/((1 + δ)L).

≤

Using the convex interpolation and duality techniques from [THG2], one can also
(m, L) are optimal over one time step in the following

show that the above results for
non-asymptotic sense, at least in dimensions n

S

3:

≥

Lemma 1.7. Let 0 < m < L and 0
α

(0, ¯α−). If

∈

δ < 2√κ/(κ + 1). Suppose that n

≤

ρGD(δ) if α /
∈

¯ρGD(δ) if α

(α−, α+),

(α−, α+),

ρ <

(

∈

3 and

≥

(1.13)

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

9

then there exists f

∈ S

(m, L) and x0, e0
x⋆k

f (x0) + e0)

−

Rn such that
x⋆k

x0

−

∈
> ρ
k

,

x0

k

−

α(

∇

e0

k

k ≤

δ

k∇

f (x0)

.

k

In fact, we can choose a counterexample f

(m, L), which does not contradict
the asymptotic result of Proposition 1.5 (because of the constant c > 0 appearing
in the stability estimate), nor (1.12) (because convergence to optimality is not being
measured in the Euclidean norm). Such non-asymptotic optimality results are the
subject of the closely related performance estimation problem discussed in §1.4 below.

∈ F

1.3. Results for the inexact Triple Momentum Method. A general class of
momentum-based methods is given by the recursion

ξt+1 = ξt + β(ξt −
yt = ξt + γ(ξt −

f (yt),

α

∇

(1.14)

−

ξt−1)

ξt−1).

In particular, these iterates admit a state-space representation as in (1.1), where the
state is (ξt, ξt−1)

R2n. For simplicity, we assume the initialization ξ−1 = 0. Deﬁne

∈

−
The Triple Momentum Method (TMM), developed in [VSFL]3, is given by the choices

ρTM := 1

1/√κ.

α =

1 + ρTM
L

,

β =

2

ρ2
TM
ρTM

,

γ =

ρ2
TM
(1 + ρTM)(2

−

.

ρTM)

(1.15)

−

TMM is the fastest known gradient-based method for optimizing strongly convex func-
tions: given ρ

≥

ρTM, there exists c > 0 such that
ξ⋆k
ξ⋆k ≤

ξt −

cρt

ξ0

−

k

k

,

t

0

≥

whenever f

(m, L), where ξ⋆ is the unique minimizer of f .

Next, suppose that TMM is perturbed by replacing

f (yt) + et in
(1.14), where the error sequence e satisﬁes (1.2). We refer to the resulting recursion
as inexact TMM.

f (yt) with

∇

∇

∈ F

Proposition 1.8. Let 0 < m < L, and deﬁne θTM := (2
Furthermore, deﬁne

−

ρTM)ρTM + (2 + ρTM)δ.

θTM + (θ2

¯ρTM(δ) :=

TM + 4δρ2
2(2

TM(2
ρTM)

−

ρTM))1/2

,

−

(1.16)

where in order to ensure ¯ρTM(δ)

∈

(0, 1) we assume that

√κ + 1

0

δ <

≤

4κ

3√κ + 1

.

−
3In fact, the choice of parameters (1.15) was originally motivated by a frequency-domain analysis;

for more, see §4 and [VSFL].

10

ORAN GANNOT

¯ρTM(δ), then there exists c > 0 such that for any f

If ρ
iterates satisfy

≥

(m, L) the inexact TMM

∈ F

ξt −

k

ξ⋆k ≤

cρt

ξ0

k

,

ξ⋆k

−

0.

t

≥

Proposition 1.8 is based on a perturbed version of the Jury–Lee criterion — see
Lemma 2.17. We conjecture that the rate (1.16) is actually optimal with respect to
this criterion. While a proof is currently out of reach, we have been unable to ﬁnd any
counterexamples (see Figure 4 for some numerical illustrations).

1.4. Previous work. Following [LRP], numerous papers have adopted a control-
theoretic viewpoint for the analysis of gradient-based optimization methods; a par-
tial list of recent contributions in a variety of directions includes [HS1, HL2, CHVSL,
VSFL, TVSL, HWL, LS, FRMP, HMJ, MSE, BS, NLR+, HS2, FB, HSL1, DD, Mic,
GES, XCHZ, HSL2, HL1, SJFB]. A few of these works apply frequency methods, no-
tably [VSFL, CHVSL, XCHZ]. However, the frequency approach is not always taken
as far as possible. For instance, [VSFL, CHVSL] use a frequency interpretation for
algorithm design via pole-zero assignment, but then resort to time-domain methods in
order to prove their convergence results. This is because the frequency criteria that are
employed degenerate at the margins of Lyapunov stability. In this paper we emphasize
a more robust set of tools, in particular Popov’s hyperstability theorem, that enables
a self-contained analysis in the frequency domain; for a thorough discussion, see §2.1.

Earlier, [DT2] introduced a closely related semideﬁnite programming formulation,
the so-called performance estimation problem (PEP), for analyzing the worst-case
performance of iterative optimization methods over a given number of time steps.
Subsequent developments include [dKGT2, dKGT1, THG1, KF1, RTBG, DT1, THG3,
KF2]. Importantly, one input to PEP is a choice of user-speciﬁed performance measure.
An example is distance to optimality, but this is not always appropriate, e.g., for
Nesterov’s method or TMM (of course distance to optimality is a good measure of
convergence, but not necessarily for the behavior of an algorithm over a given set of
time steps).

In general, ﬁnding a suitable performance measure is nontrivial.

In [TVSL], the
authors search for a performance measure in the form of a Lur’e–Postnikov-type Lya-
punov function; under a dimensionality condition, they formulate a semideﬁnite pro-
gram whose feasibility is equivalent to the existence of such a Lyapunov function de-
(m, L). Of course it is not clear whether
creasing geometrically at each iteration over
this approach provides necessary conditions for exponential stability, since the class of
Lyapunov functions under consideration is parametric.

F

The speciﬁc IQCs used in this paper, as well as other works derivative of [LRP],
provide simpler suﬃcient conditions for the existence of a Lyapunov function within
a certain parametric family. However, we do not stress the existence of a Lyapunov

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

11

function, and instead choose to work within Popov’s framework of hyperstability (the
relationship between the two viewpoints is especially clear in the frequency domain —
see the discussion following Lemma 2.12).

As noted in §1.2, some analytic bounds for the convergence of inexact gradient
descent under the error model (1.2) were given in [dKGT2, dKGT1]. Numerical com-
putations of exponential convergence rates under the same error model were carried
out in [LRP, CHVSL] for the case of strongly convex functions, but without analytic
results. Simpler results can be found in [Pol, Ber]. Stochastic gradient descent, where
the gradients are subject to additional relative noise, was analyzed in [HSL2]. The
relative error model also arises naturally in the analysis of various incremental gradi-
ent methods for minimizing ﬁnite sums [FS2] (inexactness arises from sampling only a
subset of the terms in the sum).

Other error models are considered in [d’A, DGN3, DGN1, DGN2, CDO], with both
deterministic and stochastic perturbations. For example, [DGN3] considers an inexact
f (y)), the oracle returns a pair (fδ(y), gδ(y))
oracle for
satisfying

instead of (f (y),

(0, L):

∇

F

f (x)

0

≤

−

(fδ(y) +

gδ(y), x

h

y

)

i

−

≤

x

L
2 k

−

2,

y

k

Rn.

x

∈

The case of strongly convex functions was considered in [DGN1].
In contrast, the
error model in this paper only involves errors in the gradient calculations, and the
aforementioned works do not overlap with ours.

1.5. Outline of the paper. In §2, we introduce Popov’s notion of hyperstability and
its frequency-domain formulation. The two frequency criteria used in this paper, the
circle and Jury–Lee criteria, are described in §2.2 and §2.4. Applications of these two
criteria in the exact setting to gradient descent and Nesterov’s method are discussed
in §2.3 and §2.5, respectively.

The necessary modiﬁcations to the frequency criteria in the inexact setting are de-
scribed in §2.6. The results for inexact gradient descent given in §1.2 are proved in §3.
Proposition 1.8 for inexact TMM is derived in §4.

Cp×q, we use the notation M ⊤ for its transpose
1.6. Notation. Given a matrix M
and M ∗ for its adjoint. If M is square, we deﬁne Re M := (M + M ∗)/2. Positive deﬁ-
niteness and semideﬁniteness is denoted M
0. The standard sesquilinear
(in the second factor) inner product on Cp (and its restriction to Rp) is denoted by
.
·i
For an arbitrary complex-valued function f we write f
0 if f vanishes identically on
its domain. Denote by ℓd the space of sequences on N≥0 with values in Cd.

0 and M

≡

(cid:23)

≻

h·

∈

,

12

ORAN GANNOT

2. Stability criteria

2.1. Hyperstability. Consider a linear time-invariant (LTI) control system of the
form

xt+1 = Axt + But,

(2.1)

where A

∈

Rd×d and B

Rd×n. Also let

∈
B(A, B) =

(x, u)

{

ℓd+n : xt+1 = Axt + But}

.

∈

(The notation B refers to a behavior in the sense of Willems [WP].) Popov formulated
the notion of hyperstability in the early 1960’s to formalize the problem of certifying
stability for (2.1) when the control u
ℓd are jointly constrained by
quadratic inequalities.

ℓn and state x

∈

∈

First we discuss the notion of an integral quadratic constraint (IQC). Fix a quadratic

form

on Cd+n, where Q = Q⊤

Rd×d, S

∈

∈

σ(x, u) =

∗

x
u

Q S⊤
x
u
S R
(cid:21)
(cid:20)
Rn×d, and R = R⊤

(cid:21) (cid:20)

(cid:21)

(cid:20)

(2.2)

Rn×n.

∈

Deﬁnition 2.1. Let ρ > 0. A pair (x, u)
by σ if

∈

T

ℓd+n is said to satisfy the ρ-IQC deﬁned

ρ−2tσ(xt, ut)

0 for all T

0.

≥

≥

(2.3)

t=0
X

Let IQC(σ; ρ) denote the set of all such pairs. Furthermore, given σ1, . . . , σq, deﬁne

IQC(σ1, . . . , σq; ρ) :=

IQC(σj; ρ).

q

j=1
\

Although dating back to early work of Yakubovich and Popov, the term IQC was
popularized in the landmark paper [MR]. While we use the IQC terminology, it is
important to note that we do not apply the frequency-domain formulation in [MR] to
the analysis of gradient methods; instead, we depend on an earlier result due to Popov.

Deﬁnition 2.2. Given σ1, . . . , σq and ρ > 0, we say that (A, B; σ1, . . . , σq) is ρ-
hyperstable if there exists c > 0 such that

whenever (x, u)

B(A, B)

∩

∈

xtk ≤

k

cρt

x0

,

k

k

0

t

≥

IQC(σ1, . . . , σq; ρ).

(2.4)

In other words, hyperstability guarantees that the system xt+1 = Axt + But is

uniformly exponentially stable over arbitrary input sequences u as long as (x, u)
IQC(σj; ρ) for each j = 1, . . . , q.

∈

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

To show that (A, B; σ) is ρ-hyperstable for a single constraint σ(x, u) =

13

+

Qx, x
i

h

2 Re
h

Sx, u

+

i

h

Ru, u

i

, consider the LMI

A⊤P A

ρ2P A⊤P B
B⊤P B

−
B⊤P A

+

Q S⊤
S R

(cid:22)

0

(LMI)

(cid:20)

(cid:21)
Rd×d. In [Wil3, Wil4], (LMI) is called the dissipation

(cid:20)

(cid:21)

with decision variable P = P ⊤
inequality, and the function

∈

is called a storage function. If (LMI) holds, then each (x, u)
satisﬁes

x

P x, x
i

7→ h

B(A, B)

∩

∈

IQC(σ; ρ)

P xt, xti ≤
Hyperstability is an immediate consequence of (2.5) provided P
(A, B; σ) and ρ > 0, feasibility of (LMI) for P
(cid:23)
be solved numerically (see [LRP] for more details).

P x0, x0

≥

0.

h

i

h

t

,

ρ2t

0. For ﬁxed
≻
0 is a convex program, and can

(2.5)

The dissipation inequality can also provide suﬃcient conditions for ρ-hyperstability

in the case of multiple constraints by observing that

IQC(σ1, . . . , σq; ρ)

IQC(λ1σ1 +

+ λqσq; ρ)

· · ·

⊂

for any collection of nonnegative multipliers λ1, . . . λq. Taking σ =
λjσj, one can also
consider feasibility of (LMI) with λ1, . . . , λp as additional decision variables. Observe
that this formulation is also a convex program.

P

Popov gave a complete frequency-domain characterization of hyperstability under
If ρ = 1, then hy-
a certain minimal stability hypothesis, which we now discuss.
perstability implies that a trajectory x is bounded whenever the input is such that
IQC(σ; 1). Minimal stability requires us to exhibit an input for which the
(x, u)
corresponding trajectory x actually converges to zero and (x, u)
IQC(σ; 1). The
condition for general ρ > 0 is just a rescaling of this requirement:

∈

∈

∈

B(A, B)

Cd there exists (x, u)

Deﬁnition 2.3. The triple (A, B; σ) is said to be ρ-minimally stable if for every
x0

IQC(σ; ρ) satisfying
∩
ρ−txt →
Among other consequences, minimal stability implies that every storage function is
B(A, B) be a
in (2.5) to deduce that

positive semideﬁnite. Indeed, given an arbitrary x0
∈
trajectory as in the deﬁnition of minimal stability; let t

∈
x0 = x0,

Rd, let (x, u)

0 as t

→ ∞

∈

.

P x0, x0

h

0.

i ≥

→ ∞

In applications the minimal stability hypothesis is typically straightforward to verify
— see Lemma 2.5 below.

14

ORAN GANNOT

Next, given (A, B) and σ(x, u) =

function

Qx, x
i

h

+ 2 Re
h

Sx, u

+

i

h

Ru, u

i

, deﬁne the Popov

(¯ζI

Π(ζ, z) = Π(ζ, z; A, B; σ) :=

A)−1B
In
which is a meromorphic function of (ζ, z) with Hermitian values in Cn×n. The dis-
sipation inequality is linked to properties of Π(ζ, z) via the following observation:
if
P = P ⊤ solves (LMI), then

A)−1B
I

Q S⊤
S R

(zI

(cid:21) (cid:20)

−

−

(cid:21)

(cid:21)

(cid:20)

(cid:20)

,

∗

Π(¯z, z)

0 whenever

z

= ρ and det(A

zI)

= 0.

(cid:22)

|
This is easily seen by multiplying (LMI) on the right by the column vector ((zI
−
A)−1Bu, u) and by its conjugate transpose on the left. The converse of this result is
the content of the Kalman–Yakubovich–Popov (KYP) lemma (sometimes called the
Kalman–Szeg¨o lemma in discrete time [KS]):

−

|

(FDI)

Lemma 2.4. If (A, B) is controllable, then there exists P = P ⊤
(LMI) if and only if (FDI) holds.

∈

Rd×d satisfying

Recall that (A, B) is controllable if for any pair of states there exists an input driving
the system xt+1 = Axt + But from the initial state to the terminal state in ﬁnite time.
Equivalently, (A, B) is controllable if

rank

B AB

Ad−1B

= d.

(2.6)

· · ·
(See [Kal].) Perhaps the simplest proof of Lemma 2.4 is due to Willems via an optimal
control argument [Wil1, Theorem 4].4 For the classical proof using spectral factoriza-
tions, see [PG, §10, Theorem 1]. An alternative argument is provided in [Ran].5

(cid:3)

(cid:2)

Even if (A, B) is controllable and (FDI) holds, Lemma 2.4 does not necessarily
0. In particular, a naive application of (2.5) does

imply feasibility of (LMI) for P
not guarantee hyperstability. Instead, Popov established the following result.

≻

Theorem 1 ([PG, §18, Theorem 1]). Given ρ > 0, suppose that (A, B; σ) satisﬁes the
following conditions.

(1) B

= 0,

(2) (A, B; σ) is ρ-minimally stable,

z

4The reader should ignore the statement about the ﬁniteness of Vf , which is famously false [Wil2].
5[Ran] explicitly states that A should not have spectrum with
= ρ, but this is unnecessary.
Such an assumption can always be removed when (A, B) is controllable by shifting the eigenvalues
oﬀ of
= ρ via linear feedback: an equivalent characterization of controllability is that for any
monic polynomial there is a matrix N such that the characteristic polynomial of A + BN is the given
polynomial [PG, §34, Theorem 1]. The corresponding linear change of variables (x, u)
(x, u + N x)
does not aﬀect the validity of (FDI) (it corresponds to a congruency transformation of the Popov
function by a rational matrix function), and leaves invariant any solution of (LMI).

7→

z

|

|

|

|

6
6
A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

15

(3) (ζ, z)

det Π(ζ, z)

0.

6≡
Then (A, B; σ) is ρ-hyperstable if and only if (FDI) holds.

7→

In addition, if (A, B) is controllable and Π(¯z0, z0)

0 for some

(A, B; σ) is ρ-hyperstable if and only if (LMI) admits a solution P

≺

= ρ, then

z0

|
0.

|

≻

Apart from dispensing with issues like controllability, the main advantage of Theo-
rem 1 in the context of this paper is that it replaces the search for P with the task of
checking (FDI). Although in principle the latter consists of verifying an inﬁnite set of
inequalities, the fact that Π(¯z, z) involves only rational functions of z reduces (FDI)
to a small number of scalar inequalities. This plays a crucial role in analytic proofs,
since additional parameters tend to make such problems disproportionately harder.

Theorem 1 is also particularly well-suited for analysis at the margins of ℓ∞ stability:
(FDI) need not hold strictly, and A can have eigenvalues on the circle of radius ρ. This
should be compared with other frequency-domain formulations that are often cited in
the optimization literature based on [MR] or strict versions of the KYP lemma (for
example [BLR, VSFL]). Such results are useful in the context of ℓ2 stability, but fail
to characterize ℓ∞ behavior as (FDI) degenerates.

Using only the assumption B

= 0, it is easy to show that ρ-hyperstability implies

(FDI): suppose that

for some Cn
using B

= 0, where
= 0, we can assume that Bu0

u0

∋

|

|

Π(¯z0, z0)u0, u0
> ρ not an eigenvalue of A. By perturbing u0 and

> 0

i

h
z0

ℓd are deﬁned by

ut = zt

0u0,

= 0. If u
xt = zt

0(zI

∈

ℓn and x
∈
A)−1Bu0,
−
ρ−txt| → ∞

B(A, B)

then (x, u)
as t
which contradicts ρ-hyperstability. Thus we must have Π(¯z0, z0)
by continuity up to

IQC(σ; ρ). However,

= ρ.

∈

∩

z

|

→ ∞
(cid:22)

since Bu0
= 0,
0, so (LMI) holds

The converse proof that (FDI) implies hyperstability under the hypotheses of The-
orem 1 is not entirely trivial; it relies on the existence of zero-dynamics for certain
nondegenerate control systems which is outside the scope of this paper. Roughly
speaking, the proof proceeds in three steps:

|

|

(1) Use that B

= 0 to pass to a controllable subsystem; the uncontrollable states

are estimated using minimal stability.

(2) Apply the KYP lemma to obtain a solution P = P ⊤ of (LMI), which is positive
semideﬁnite by minimal stability. States in the positive spectral subspace of P
are estimated by (2.5).

(3) The nondegeneracy condition det Π(ζ, z)

0 is used to construct a normal

form that allows for states in ker P to be estimated using minimal stability.

6≡

6
6
6
6
6
6
16

ORAN GANNOT

The original proof in [PG] is not entirely straightforward, but there do not seem to be
many alternative references. A modern proof in the continuous-time setting is given
in [Gan]; the adaptations needed in discrete time are straightforward.

The hypothesis that det Π(ζ, z)

0 in Theorem 1 is not intuitive, but it is typically

easy to check. For instance, it is always satisﬁed if

6≡

det(S(zI

−

A)−1B + R)

0,

6≡

as can seen by taking ζ

. This in turn is true if det R

= 0.

In the context of this paper, minimal stability is established via linear feedback, i.e.,
by choosing a control in the form u = Nx. Given ρ > 0, a square matrix is said to be
ρ-Schur if all its eigenvalues lie in the open disk of radius ρ. The following result is
used repeatedly.

→ ∞

Lemma 2.5. If there exists N
εBS is ρ-Schur and

∈

Cn×d and ε

[0, 2/

R

k

k

∈

] such that A + B(I + εR)N +

then (A, B; σ) is ρ-minimally stable.

Q + 2 Re N ∗S + N ∗RN

0,

(cid:23)

(2.7)

IQC(σ; ρ) for any sequence
ℓd. Now observe that (2.7) is stable under replacing N with N + ε(S + RN),
]. Here the norm of R is the operator norm. The ρ-Schur

Proof. The inequality (2.7) guarantees that (x, Nx)
x
provided ε
condition implies that solutions of the closed-loop system

[0, 2/

R

∈

∈

∈

k

k

xt+1 = (A + B(N + ε(S + RN))xt

satisfy ρ−txt →

0 as t

.

→ ∞

(cid:3)

The following result is useful in bounding the values of certain multipliers. For
simplicity we only provide the (trivial) proof in the controllable case, since the full
strength of the result is only used for gradient descent, whose underlying LTI system
is evidently controllable. It is true in general by passing to a controllable subsystem
as in [PG, Eq. (26), §14];

Lemma 2.6. Let B
R

0.

(cid:22)

= 0. If (A, B; σ) is ρ-minimally stable and ρ-hyperstable, then

Proof. Since (FDI) holds, it follows that in the controllable case (LMI) admits a solu-
0. (cid:3)
0. We then conclude from the bottom right entry of (LMI) that R
tion P

(cid:22)

(cid:23)

When (A, B) is controllable and the nondegeneracy condition Π(¯z0, z0)

0 holds for
= ρ, Popov showed that the so-called maximal solution of the KYP equations
some
(see [Wil1] for the deﬁnitions) is positive deﬁnite.6 Unfortunately, this nondegeneracy

z0

≺

|

|

6In general, this is not true of every solution to (LMI).

6
6
A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

17

condition often fails at the margins of stability. Instead, we record a simple algebraic
criterion that ensures every positive semideﬁnite solution of (LMI) is actually positive
deﬁnite. Recall that the (in this case real-valued) pair (A, S) is said to be observ-
able if (A⊤, S⊤) is controllable. Equivalently, (A, S) is observable if every A-invariant
subspace of Rd contained in ker S is trivial.

Lemma 2.7. Let Q
then ker P =

0

.

{

}

0, and suppose that P

(cid:23)

(cid:23)

0 solves (LMI). If (A, S) is observable,

Proof. It suﬃces to show that ker P is A-invariant and contained in ker S. The fact
that ker P is A-invariant follows immediately from the Lyapunov inequality

implied by the upper left block of (LMI). To see that ker P
pair (LMI) with (x, εSx). Then

A⊤P A

ρ2P

−

0

(cid:22)

ker S, ﬁx x

Rd and

∈

⊂

ε2

(cid:3)

Rn×d.

(2.8)

P (A + εBS)x, (A + εBS)x

h

If P x = 0 and we choose ε

(0, 2/

R

k

∈

k

ρ2

P x, x

h

i −
), then Sx = 0.

i ≤ −

(2ε

−

R

)

Sx
k

k

k

k

2.

2.2. Circle criterion. Consider an LTI system of the form (2.1), and let C
∈
Given m < L, consider the so-called sector IQC deﬁned by the quadratic form

σ0(x, u) = σ0(x, u; m, L, C) := 2

u

h

−

mCx, LCx

u

.

i

−

If f

0(m, L), then

∈ S

(x,

for every ρ > 0 and every real-valued x

where H(z) = C(zI

2 Re [(I

−

Π(¯z, z) =

A)−1B.

−

f (Cx))

IQC(σ0; ρ)

∇

∈
ℓd. The corresponding Popov function is
mH(z))∗(I

LH(z))] ,

−

∈

−

Lemma 2.8 (Circle criterion). Let ρ > 0. If B
= 0 and there exists k
that A + kBC is ρ-Schur, then (A, B; σ0) is ρ-hyperstable if and only if

∈

[m, L] such

whenever

z

|

|

= ρ and det(A

−

Re [(I

mH(z))∗(I

LH(z))]

0

(cid:23)

−

= 0.

(2.9)

−
zI)

[m, L], then (A, B; σ0) is ρ-minimally stable.
Proof. If A+kBC is ρ-Schur for some k
Indeed, the feedback u = mCx renders the left-hand side of (2.7) identically zero, at
which point the result follows from Lemma 2.5 with

∈

Since R =

2I has nonzero determinant, Theorem 1 applies.

−

k = (1

−

ε)m + εL,

ε

[0, 1].

∈

(cid:3)

6
6
18

ORAN GANNOT

If (A, B; σ0) is ρ-hyperstable for a given ρ

(0, 1), then the system

∈
xt+1 = Axt + B

∇

f (Cxt)

(2.10)

is uniformly ρ-exponentially stable over
such that

0(m, L). More precisely, there exists c > 0

S

≥
0(m, L). Finally, suppose that the dissipation inequality (LMI) corre-

k

k

k

xtk ≤

cρt

x0

,

t

0

whenever f
sponding to (A, B; σ0) admits a solution P
ρ2

P xt+1, xt+1

∈ S

≥
along any trajectory of (2.10). In particular, x
is a valid Lyapunov function,
and the constant c > 0 in the deﬁnition of ρ-hyperstability can be taken to be the
condition number of P 1/2.

i ≤

h

h

0 for a given ρ > 0. Then
≻
P xt, xti
7→ h

P x, x
i

0

t

,

2.3. Gradient descent. As an illustration of Lemma 2.8, consider the convergence
(m, L), where 0 < m < L (see §1.2 for the deﬁnitions).
of gradient descent for f
By a coordinate shift, we can assume that x⋆ = 0, namely
f (0) = 0. The gradient
descent iterates

∈ S

∇

f (xt)
on Rn are of the form (2.1) with A = C = In and B =

xt+1 = xt −

∇

α

αIn.

Let ρ

(0, 1) and k

∈

−
[m, L]. In order for gradient descent to converge exponentially
2, it is necessary and suﬃcient for

(k/2)

∈

with rate ρ when applied to quadratics x
the step size α > 0 to be such that

7→

x
|

|

ρ

≥

ρGD := max(1

αm, αL

1).

(2.11)

−

−

According to the discussion in §2.2, to show that the gradient descent iterates satisfy
(1.6) for a given ρ
αIn; σ0) is ρ-hyperstable (here
σ0 is given by (2.8)). This is an application of the circle criterion, Lemma 2.8:

ρGD, it suﬃces to show that (In,

≥

−

Lemma 2.9. If ρ

ρGD, then (In,

≥

αIn; σ0) is ρ-hyperstable

−

Proof. The transfer function as in Lemma 2.8 is H(z) =
plying by

2, the frequency condition of Lemma 2.8 is equivalent to

α(z

−

−

1

z

1)−1In. After multi-

|

−

|

Re [(z

−

1 + Lα)(¯z

1 + mα)]

0,

z

= ρ.

−

|
ρ, ρ], so the inequality above holds if and only if

≥

|

This is a linear function of Re z
it holds for Re z =

[
−
ρ. In other words, we must have

∈

±

1 + Lα)(ρ

(ρ

−

−

1 + mα)

≥

0,

(ρ + 1

The ﬁrst inequality holds if and only if ρ
only if ρ

1. In particular, any ρ

αL

≥

−

≥

Lα)(ρ + 1

mα)

0.

−
αm, whereas the second holds if and

−

≥

(2.12)

1

≥
ρGD is feasible for (FDI). Furthermore,

−

A + kBC = (1

αk)In,

−

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

19

so the eigenvalues of A + kBC are certainly contained in the open disk of radius ρ
αIn; σ0) is ρ-minimally stable. Finally,
when ρ
(cid:3)
Lemma 2.8 implies that (In,

αIn; σ0) is ρ-hyperstable.

(m, L). Thus (In,

ρGD and k

−

≥

∈

−

(cid:23)

−

In this case (A, B) = (In,

αIn) is clearly controllable, so (LMI) with ρ = ρGD
admits a solution P
0, which from the underlying block structure can assumed to
be a multiple of the identity — cf. the remarks in [LRP, §4.2]. Furthermore, P
0
by Lemma 2.7.7 Since P has condition number equal to one, the constant c > 0 in
the deﬁnition of hyperstability can be chosen as c = 1. Gradient descent is suﬃciently
simple that P can also be found directly; this is precisely what is done in [LRP], and
we review the procedure to compare with Lemma 2.9.

≻

Rather than parameterizing P = pIn for some p > 0, it is convenient to ﬁx p = 1
0 for the constraint matrix associated to σ0.

and instead introduce a multiplier λ
Thus the aim is to minimize ρ
ρ2
α

α
−
α2

≥

1

≥

−
−

(cid:20)
From the lower right entry, λ must satisfy λ
(κ

(cid:20)

(cid:21)

≥

1)/(κ + 1), and (2.13) is feasible for this value of ρ by taking

2Lm L + m

+ λ

−
L + m

0.

(cid:22)

(cid:21)

(2.13)

2
−

α2/2. If α = 2/(L + m), then ρGD =

ρGD subject to feasibility of the LMI

−

λ = α2/2.

= 2/(L + m), then feasibility for a given ρ > 0 requires that λ > α2/2. In that

If α
case, by Schur complements, feasibility holds if and only if ρ satisﬁes

ρ2

1

−

≥

2Lmλ +

((L + m)λ
2λ

−
α2

α)2

.

−

If α

= 2/(L + m), then right hand side is minimized when

λ =

α(1

−
α(αL

(

αm)/(L

1)/(L

−

m)

m)

−

−

if α < 2/(L + m),

if α > 2/(L + m).

This indeed yields ρ
ρGD. Compare this to Lemma 2.9: the frequency-domain test
requires minimizing ρ subject to the trivial inequalities (2.12), which does not involve
the decision variable p (or equivalently λ).

≥

2.4. Jury–Lee criterion. As in §2.2, consider an LTI system of the form (2.1), and
Rn×d. As usual, let 0 < m < L. Although the sector IQC is certainly satisﬁed
let C
0(m, L), it does not exploit the fact that (1.4) holds for
by gradients of functions in
arbitrary pairs (y1, y2). More precisely, the sector IQC describes a certain property

F

∈

7In reference to the remarks preceding Lemma 2.7, note that Π(¯z, z)

α = 2/(m + L).

0 when

z

|

|

≡

= ρGD and

6
6
20

ORAN GANNOT

satisﬁed by the current iterate, but ignores that the same relationship holds between
all the previous iterates as well.

To capture memory of this additional structure for the most recent previous iterate,

augment x

∈

ℓd with a lag variable v

∈

ℓn evolving according to

vt+1 = LCxt −
The augmented state (x, v) also satisﬁes an LTI system of the form (2.1) with system
matrices ( ˆA, ˆB) given by

ut.

ˆA =

A 0
LC 0

B
I
−
f (y), we then have vt = Lyt−1

ˆB =

(cid:21)

(cid:20)

(cid:20)

,

.

(cid:21)

(2.14)

With y = Cx and u =
encode the constraint (1.4) for the pair (yt, yt−1). More precisely, given τ
the IQC deﬁned by the quadratic form

f (yt−1), which allows us to
0, consider

− ∇

∇

≥

στ (x, v, u) = στ (x, v, u; m, L, C)

:= 2

u

h

−

mCx, LCx

u

−

i −

2τ 2

u

h

−

mCx, v

.

i

(2.15)

When τ = 0 the form στ is independent of v, and agrees with (2.8). In [LRP], the
IQC deﬁned by στ is termed the oﬀ-by-one IQC. It is part of a larger class of so-called
Zames–Falb IQCs satisﬁed by gradients of strongly convex functions [BLR, FS1], but
we will not have opportunity to use other IQCs from this family.

If 0

τ

ρ

1, then gradients of strongly convex function satisfy the ρ-IQC

≤

≤

≤

deﬁned by στ in the following precise sense.

Lemma 2.10 ([LRP, Lemma 10]). Let L > m > 0, and suppose that f
Given a real valued x

ℓd, deﬁne v

0(m, L).

∈ F

f (Cxt),

v0 = 0.

(2.16)

∈

∈

ℓn by
vt = LCxt − ∇
1, then (x, v,

If ρ > 0 and 0

τ

≤

≤

ρ

≤

f (Cx))

IQC(στ ; ρ).

∈

∇

Suppose that ( ˆA, ˆB; στ ) is ρ-hyperstable for a given ρ
∈
the hypotheses of Lemma 2.10, there exists c > 0 such that

(0, 1] and τ

[0, ρ]. Under

∈

whenever xt+1 = Axt + B
does not appear on the right-hand side.

∇

cρk

k

xtk ≤
f (Cxt) and f

,

x0

k

∈ F

t

0

≥

k
0(m, L). Note that v0 = 0, so this term

Remark 2.11. For a ﬁxed ρ
∈
tional decision variable is a convex program. This is because

(0, 1], feasibility of (LMI) with τ

∈

[0, ρ] as an addi-

στ =

λσ0 + σρ
1 + λ

,

λ = (ρ/τ )2

1,

−

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

21

so it suﬃces to consider conic combinations of the ﬁxed IQC σρ and the sector IQC
σ0 with multipliers as additional linear decision variables. In particular, it suﬃces to
prove Lemma 2.10 for the case τ = ρ.

Next, we address the analogue of Lemma 2.8. To compute the Popov function
corresponding to ( ˆA, ˆB; στ ), observe that with respect to the splitting (x, v) of the
state,

−

(zI

ˆA)−1 =

(zI
−
z−1LC(z
(cid:20)
where H(z) = C(zI
function satisﬁes

−

A)−1

0

A)−1 z−1I

−

(cid:21)

,

(zI

−

ˆA)−1 ˆB =

(zI

A)−1B

−
z−1(LH(z)

,

I)

(cid:21)

−

(cid:20)

A)−1B. A straightforward computation shows that the Popov

Π(¯z, z) =

2 Re

−

(1

mH(z))∗(I

−

LH(z))

.

−

τ 2/z)(I

−
0. If B

= 0 and there exists ε

[0, 1] such that

(cid:3)

∈

(cid:2)
Lemma 2.12. Let ρ > 0 and τ
≥
A + ((1

ε)m + εL) BC
m)C

−
ε)(L

−

ετ 2B
−
ετ 2I

(cid:21)

(1

(cid:20)

−

is ρ-Schur, then ( ˆA; ˆB; στ ) is ρ-hyperstable if and only if

Re

(1

−
= ρ and det(A

(cid:2)

τ 2/z)(I

mH(z))∗(I

LH(z))

−

0

(cid:23)

(cid:3)

−
= 0.

zI)

−

whenever

z

|

|

(2.17)

(2.18)

Proof. As in Lemma 2.8, the control u = mCx makes the left-hand side of (2.7) vanish.
The ρ-Schur property of (2.17) veriﬁes the remaining hypotheses of Lemma 2.5. Again,
(cid:3)
since R =

2I has nonzero determinant, Theorem 1 applies.

−

When ρ = 1, the frequency condition (2.18) was ﬁrst obtained by Jury–Lee [JL1]. Its
relationship with the multiplier approach of Zames–Falb was recognized immediately
[OY].

One can also formally derive (2.18) from the KYP lemma via a Lur’e–Postnikov-type

Lyapunov function of the form

V (x) =

P ˜x, ˜x
i

h

+ f (Cx)

f (0)

−

−

(m/2)

2,

Cx
k

k

˜x = (x,

∇

f (Cx)),

(2.19)

where f
as a function of the augmented state ˜x rather than the original state x.

0(m, L) [ACH]. In general it is necessary to consider the quadratic part

∈ F

Several recent works have considered Lyapunov functions for the analysis of opti-
mization methods in the form (2.19) (e.g., [TVSL, TB]), which in an appropriate sense
is equivalent to the oﬀ-by-one IQC: as shown in [ACH], from the exponential decrease
condition V (xt+1)
ρV (xt) one can derive an inequality of the form (LMI) whose
frequency-domain dual is equivalent to the Jury–Lee inequality (2.18).

≤

6
6
22

ORAN GANNOT

A more restrictive class of Lyapunov functions is

V (x) =

P x, x
i

h

+ f (Cx)

f (0)

−

−

(m/2)

2.

Cx
k

k

(2.20)

It is shown in [HL2] that such a Lyapunov function suﬃces to recover standard con-
vergence results for Nesterov’s accelerated method. Using the constraints derived in
[FRMP, Lemma 4.1] or [HL2], one formally recovers from (2.20) an earlier frequency
condition due to Jury–Lee [JL2].

2.5. Nesterov’s accelerated method. Nesterov’s accelerated gradient method for
strongly convex functions on Rn is of the form

ξk+1 = ξk + β(ξk −
yk = ξk + β(ξk −

ξk−1)

ξk−1),

f (yk),

α

∇

(2.21)

−

where ξk ∈
the form (1.1) with state (ξk, ξk−1) and system matrices

Rn (cf. the more general recursion (1.14)). This is a feedback system of

1 + β
1

β
−
0

A =

(cid:20)

⊗

(cid:21)

In, B =

α
−
0

(cid:20)

⊗

(cid:21)

In, C =

1 + β

β

−

In.

⊗

For the remainder of this section ﬁx 0 < m < L, and specify the parameters

(cid:2)

(cid:3)

α :=

1
L

,

β :=

√κ
1
−
√κ + 1

,

(2.22)

where recall κ = L/m. We refer to these choices as the standard tuning for Nesterov’s
method. Also deﬁne

¯ρAG = ¯ρAG(m, L) =

1

κ−1/2.

−

Nesterov’s classical result [Nes, §2.2] states that for each f
(2.21) (with the standard tuning) satisfy

p

(m, L) the iterates

∈ F

ξ⋆k ≤
Here c > 0 is independent of f , and ξ⋆ is the global optimizer of f .

ξt −

ξ⋆k

AGk

ξ0

−

≥

0.

k

t

,

c¯ρ t

By numerically solving the feasibility problem for (LMI) using the oﬀ-by-one IQC,
it was observed in [LRP] that the rate ¯ρAG is conservative. For a graphical illustration,
see Figure 3. In Proposition 2.13 below, we give an analytic formula for the best rate
that can be certiﬁed using the Jury–Lee criterion. For this we take τ = ρ, but a more
involved analysis shows that this rate is actually optimal over all admissible τ ; the
details are omitted, although it can already be seen numerically in Figure 3.

Proposition 2.13. Let 0 < m < L, and deﬁne (α, β) by (2.22). Denote by r− > 0
the smallest positive root of

h(r) = 8(1

−
+ 2κ(3κ

√κ)4

(1

√κ)2(15κ
−
4√κ + 1)r2 + κ2r3,

−

−

10√κ

1)r

−

−

(2.23)

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

23

and set

1/2
− .
ρAG, then there exists c > 0 such that for any f

ρAG = ρAG(m, L) = r

If ρ
≥
satisfy

(m, L) the iterates (2.21)

∈ F

Furthermore, ρAG < ¯ρAG.

ξt −

k

ξ⋆k ≤

cρt

ξ0

k

,

ξ⋆k

−

0.

t

≥

The discriminant of h(r) is positive, and it is easy to check that h(0) > 0 and
h′(0) < 0. Consequently, h(r) has one negative root and two positive roots 0 < r− <
r+. Standard asymptotic analysis reveals that
3 κ−1/2,
In particular, for large κ, Nesterov’s method with its standard tuning converges at a
rate

→ ∞

r−

∼

−

κ

1

.

4

ρAG

1

∼

−

2

3 κ−1/2,

κ

.

→ ∞

Meanwhile, the more conservative classical rate has the asymptotics ¯ρAG

2κ−1/2.
In order to prove Proposition 2.13, we begin by examining the frequency condition
(2.18). Because of its block structure, for the purposes of verifying (FDI) we can
assume that the transfer matrix H(z) = C(zI

A)−1B is scalar, given by

−

∼

1

1

−
−
= ρ for a given ρ > 0 and we ﬁx α = 1/L, then

H(z) =

−

−

α

−

(1 + β)z
1)(z
(z

β
β)

.

If

z

|

|

z

|

−

1

z

2

|

|

β

|

−

2 Re

(1

−

ρ2/z)(mH(z)

I)∗(LH(z)

−

−

I)

= F (Re z, ρ),

where

(cid:2)
F (t, ρ) := ρ2β(1

−

+ (ρ2(1 + 2β)(1

κ)

κ) + ρ4((2 + β)κ

β)
1
−
ρ4κ)t + 2β(κ

−

1)t2.

(cid:3)

−
0, then F (t, ρ) is a convex quadratic function of t, and ∂tF (0, ρ) < 0 for any ρ

−

−

Now ﬁx β according to (2.22). The remarks above show that F (t, ρ) is nonnegative

ρ, ρ] if and only if it is nonnegative for t

[0, ρ]. Deﬁne

ρ⋆ := inf

{

ρ > 0 : F (t, ρ)

≥

∈
0 for all t

[0, ρ]
}

.

∈

This inﬁmum is ﬁnite, since it can be checked that ρ = 1 is always feasible. In fact,
ρ⋆ < 1 since the derivative of ρ
1 and ∂tF (t, 1) is strictly
negative for t

7→
[0, 1]. By continuity,

F (ρ, ρ) at ρ = 1 is

−

∈

F (t, ρ⋆)

0,

t

∈

≥

[0, ρ⋆].

If β
≥
since κ > 1.

for t

∈

[
−

24

ORAN GANNOT

LMI
ρAG
¯ρAG

1

0.8

0.6

0.4

0.2

ρ

0
100

101

102

103

κ

Figure 3. A comparison of the improved rate ρAG from Proposition
2.13 versus the classical rate ¯ρAG as a function of κ. The thick gray line
is the numerically computed optimal ρ such that (LMI) is feasible for
P

0 using the oﬀ-by-one IQC (over all admissible τ ).

(cid:23)

It is easy to see that ρ⋆ > 0 as expected, since F (0, ρ) < 0 for arbitrarily small
positive ρ. Note that any root of F (t, ρ⋆) must be nonnegative, since F (0, ρ⋆)
0 and
∂tF (0, ρ⋆) < 0.

≥

In order to compute ρ⋆, we argue that

disc(F (t, ρ⋆); t) = 0.

Consider the alternatives: (1) If the discriminant is negative, then F (t, ρ⋆) > 0 for all
[0, ρ⋆]. The latter is an open condition with respect to ρ, which contradicts the
t
deﬁnition of ρ⋆ as an inﬁmum.

∈

(2) If the discriminant is positive, then we must have ∂tF (ρ⋆, ρ⋆)
F (t, ρ⋆) would be negative somewhere in the interval [0, ρ⋆]. Furthermore,

≤

0, otherwise

F (ρ⋆, ρ⋆) = 0,

since otherwise we would again have F (t, ρ⋆) > 0 for t

F (ρ, ρ) = ρ2(1

ρ)((1

−

−

ρ)√κ

[0, ρ⋆]. Now
1)2,

∈

−

which would imply ρ⋆ = 1
that

−

1/√κ. In that case, however, a direct calculation shows

which is a contradiction.

∂tF (ρ⋆, ρ⋆) = 2κ−1(√κ

1)3 > 0,

−

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

25

Proof of Proposition 2.13. The discriminant of F (t, ρ) with respect to t is ρ2h(ρ2),
where h(r) is the cubic polynomial (2.23). Therefore ρAG := ρ⋆ is the square root
of the smallest positive root of h(r). To apply Lemma 2.12, we verify that (2.17) is
ρAG-Schur when ε = 0. Owing to the block structure, this is the same as showing that
the matrix

2(1

−

1/√κ)
1

(1

−

−

2L(1

1/√κ)

−

L(1

−

−

1/√κ)2
0
0
0
1/√κ)2 0







is ρAG-Schur. The eigenvalues of this matrix are 0 and 1

h((1

−

1/√κ)2) =

1)6

4(√κ
−
κ2

> 0,

h′((1

−

−
1/√κ)2) = −


1/√κ. Now compute

12(√κ
κ

1)5

−

< 0.

The cubic nature of h implies that 1
ρAG-Schur.

−

1/√κ < ρAG, so the matrix above is indeed

To ﬁnish the proof of Proposition 2.13, it remains to show that ¯ρAG > ρAG. For this,

compute

h(¯ρ2

AG) =

(√κ

1)4

−
κ

> 0,

h′(¯ρ2

AG) =

2(√κ

−

1)3(3√κ + 1)
√κ

> 0.

Again, the cubic nature of h(r) implies that ¯ρ2

AG > r+, and hence ¯ρAG > ρAG.

(cid:3)

2.6. Inexact inputs. We begin this section with some abstract considerations, and
then discuss applications to feedback systems. Consider an LTI system of the form

xt+1 = Axt + Bue

ut
et(cid:21)

(cid:20)

, Bue =

Bu Be

,

ℓd and u, e

ℓn. We assume that (u, e) satisfy the IQC σ∆(ut, et)

(cid:2)

(cid:3)

0 for

≥

where x
all t

≥

∈

0, where

∈

for some ﬁxed δ

∈

σ∆(u, e) = δ2

u

2

2

e
k

k
[0, 1). We also ﬁx some reference quadratic form

− k

k

σref (x, u) =

Qx, x
i

h

+ 2 Re
h

Sx, u

+

i

h

Ru, u

,

i

which we insist is independent of e. Our goal is to characterize the ρ-hyperstability of
(A, Bue; σref, σ∆). As discussed in §2.1, it suﬃces to show that (A, Bue; σref + λσ∆) is
ρ-hyperstable for some λ

0.

Note that ρ-hyperstability of (A, Bue; σref + λσ∆) implies the same for (A, Bu; σref).
It is also easy to see that ρ-minimal stability of (A, Bu; σref) implies the same for
(A, Bue; σref + λσ∆):

≥

Lemma 2.14. Let ρ > 0. If (A, Bu; σref) is ρ-minimally stable, then (A, Bue; σref +λσ∆)
is ρ-minimally stable for any λ

0.

≥

26

ORAN GANNOT

Proof. Given x0
ρ-minimal stability. Obviously

Cm, let (x, u)

∈

B(A, Bu)

∩

∈

IQC(σref; ρ) be as in the deﬁnition of

since adding λδ2

ut|

|

(x, u, 0)

B(A, Bue)

IQC(σref + λσ∆; ρ),

∈

∩

2 to the left-hand side of (2.3) has a favorable sign.

(cid:3)

Similarly, if (A, Bu) is controllable, then so is (A, Bue). Finally, observe that ac-
cording to Lemma 2.6, a necessary condition for hyperstability of (A, Bue; σref + λσ∆)
is

This provides an a priori bound on λ that will prove useful later on.

λδ2I

R.

(cid:22) −

(2.24)

Next, we record the form taken by (FDI) for the triple (A, Bue, σref + λσ∆). Let

Πue(ζ, z) denote the Popov function corresponding to this triple. Deﬁne

Gu(z) := (zI

−

A)−1Bu, Ge(z) := (zI

A)−1(Bu −

−

Be).

The reason for considering the diﬀerence Bu −
either vanishes or is otherwise easy to handle. Denote by

Be is that in our applications this term

Πu(¯z, z) = Gu(z)∗QGu(z) + 2 Re SGu(z) + R

the Popov function for the triple (A, Bu; σref). Similarly, let Πe(¯z, z) denote the Popov
function for (A, Bu −

Be; σref). Finally, deﬁne the oﬀ-diagonal part
Ψ(z) = Ge(z)∗QGu(z) + SGu(z) + (SGe(z))∗ + R.

The Popov function corresponding to (A, Bue; σref + λσ∆) satisﬁes

I
0

(cid:20)

∗

(cid:21)

I
I
−

Πue(¯z, z)

I
0

(cid:20)

=

I
I
−

(cid:21)

Πu(¯z, z) + λδ2I
Ψ(z) + λδ2I

(cid:20)

Ψ(z)∗ + λδ2I

Πe(¯z, z)

λ(1

−

−

δ2)I

.

(cid:21)

(2.25)

Of course this conjugation preserves deﬁniteness properties of Πue(¯z, z), but it leads
to more transparent computations.

Now we consider the two cases of interest. First is the case of a perturbed feedback

system

where f

xt+1 = Axt + B(

0(m, L). In this case we have

∈ S

f (Cxt) + et),

∇

Bu = Be = B.

(2.26)

(2.27)

For the reference IQC we take σref = σ0, where the sector IQC σ0 is given by (2.8) and
only acts on the (x, u) variables. In particular Ge(z)

0, so

Πe(¯z, z)

λ(1

−

−

δ2)I =

−

≡
(2 + λ(1

δ2))I.

−

Clearly this term is negative deﬁnite for λ
and using that this term is a multiple of the identity, we deduce the following:

0; taking Schur complements in (2.25)

≥

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

27

Lemma 2.15. Fix (A, B) and consider the triple (A, Bue; σ0 + λσ∆), where Bue is
determined by (2.27). If ρ > 0, then (FDI) holds if and only if

2λ Re [(I

−

mH(z))∗(I

−

LH(z))]

whenever

z

|

|

= ρ and det(A

−

= 0, where H(z) = C(zI

−

((L

m)2 + 2Lmλδ2)H(z)∗H(z)

λ2δ2I

0 (2.28)

(cid:23)

−
A)−1B.

−

−
zI)

This is an inexact version of the circle criterion.

Remark 2.16. Lemma 2.15 also makes it clear that (FDI) cannot hold for λ = 0
unless H(z)

0.

≡

The second case also concerns the perturbed system (2.26), but now we make the
0(m, L). Here we take the reference IQC to be the
stronger assumption that f
oﬀ-by-one IQC from §2.4. This of course requires augmenting the original state space.
Thus we consider the system

∈ F

xt+1
vt+1

(cid:20)

(cid:21)

xt
vt(cid:21)

(cid:20)

= ˆA

+ ˆBut + ˆBet +

et,

0
I
(cid:20)

(cid:21)

where ( ˆA, ˆB) are deﬁned by (2.14). The ﬁnal counterterm involving et ensures that vt
ut, as needed to apply Lemma 2.10. Thus we take
evolves according to vt+1 = LCxt −

Bu = ˆB, Be = ˆB +

(cid:20)

0
I

.

(cid:21)

(2.29)

Let σref = στ , where στ is given by (2.15). This time, the bottom right entry of (2.25)
is

Πe(¯z, z)

λ(1

−

−

δ2)I = (2 Re(τ 2/z

1)

λ(1

−

−

−

δ2))I.

∈

[0, ρ] in order to test for ρ-hyperstability.
= ρ and λ

Recall τ must be constrained by τ
In
particular, the bottom right entry of (2.25) is negative deﬁnite for
0
(except in the degenerate case τ = ρ = 1 and λ = 0, but this is irrelevant since
negativity only fails at a single point z = 1). By taking Schur complements we obtain
after some algebra the following:
Lemma 2.17. Fix (A, B) and consider the triple ( ˆA, Bue; στ + λσ∆), where ˆA is de-
termined by (2.14) and Bue is given by (2.29). If ρ > 0 and τ
[0, ρ], then (FDI)
holds if and only if

≥

∈

z

|

|

2λ Re

(1

−
((L
(cid:2)
−
whenever

z

|

|

τ 2/z)(I
m)2

1

−

|

−
= ρ and det(A

−

mH(z))∗(I
τ 2/z

LH(z))
−
2 + 2λδ2Lm Re[1
(cid:3)
−
= 0, where H(z) = C(zI

zI)

|

−

−
A)−1B.

−

τ 2/z])H(z)∗H(z)

λ2δ2I

0 (2.30)

(cid:23)

This is an inexact version of the Jury–Lee criterion. The same considerations as in

Remark 2.16 show that (FDI) cannot hold with λ = 0 unless H(z)

0.

≡

6
6
28

ORAN GANNOT

3. Inexact gradient descent

3.1. Functions with sector bounded gradients. This section extends the discus-
sion in §2.3 of gradient descent over
(m, L) to the inexact case. Let 0 < m < L and
(0, 1). Consider the iterates
δ

S

∈

on Rn, where f
sequence satisfying

∈ S
k

f (xt) + et)

α(

xt+1 = xt −

∇
(m, L) is normalized by
f (xt)
etk ≤

k∇

δ

k
e =

f (x),

δ
±

∇

f (0) = 0, and e

∈
. Two valid choices for e are

∇

ℓn is an arbitrary

which correspond to gradient descent with step-sizes (1
vergence rate must therefore satisfy ρ

ρGD(δ), where

δ)α. Any exponential con-

±

ρGD(δ) = max(1

δ), αL(1 + δ)

1).

−

−

(3.1)

≥
αm(1

−

We now apply the results of §2.6 to the LTI system xt+1 = xt −

notation of §2.6, the system matrices are A = C = In and Bu = Be =
particular,

α(ut + et). In the
In

αIn.

−

Bue =

α

−

1 1

In

⊗

We choose σref = σ0 as the reference IQC. The goal is to compute

(cid:2)

(cid:3)

ρ⋆ = inf

ρ

{

≥

ρGD(δ) : (A, Bue; σ0 + λσ∆) is ρ-hyperstable for some λ

and show that this inﬁmum is attained. The constraint λ
from (2.24) and Remark 2.16, is a necessary condition for hyperstability.

∈

(0, 2δ−2]
}
(3.2)
(0, 2δ−2], which arises

∈

Lemma 3.1. If ρ > 0 and λ
and only (FDI) holds.

∈

(0, 2δ−2], then (A, Bue; σ0 + λσ∆) is ρ-hyperstable if

Proof. Since B
= 0, hyperstability automatically implies (FDI). The converse follows
from Theorem 1: the minimal stability hypothesis is satisﬁed according to Lemma 2.9
and Lemma 2.14. To verify the last hypothesis of Theorem 1, let Πue(ζ, z) denote the
Popov function corresponding to (A, Bue; σ0 + λσ∆). Then

Πue(

∞

, z) =

(cid:20)

(L + m)H(z) + (λδ2

−

2)I H(z)
λI

,

0

−
= 0, the determinant of this rational matrix does
(cid:3)

(cid:21)

where H(z) =
−
not vanish identically.

α(z

−

1)−1I. Since λ

Let λ

(0, 2δ−2], and suppose that z not an eigenvalue of A. We apply the inexact

circle criterion, Lemma 2.15: if (2.28) is multiplied through by

∈

2, then Πue(¯z, z)

z

|

1

|

−

(cid:22)

6
6
A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

29

0 if and only if

α2(L

−

−

m)2 + 2mLα2λ(1

δ2)

−

+ 2αλ(m + L) Re(z

1) + λ(2

−

δ2λ)

z

|

−

2

1

|

−

≥

0.

(3.3)

When restricted to the circle of radius ρ, the left-hand side of (3.3) is a linear function
ρ.
of Re z
For ﬁxed parameters (L, m, α, δ), deﬁne

ρ, ρ]. Therefore (3.3) holds for all

= ρ if and only if it holds for z =

[
−

±

∈

z

|

|

F (t, λ) =

α2(L

−

−

m)2 + 2mLα2λ(1

−

δ2)

+ 2αλ(m + L)(t

Thus (3.3) holds for a given λ
In particular, ρ⋆ can be computed as

≥

0 if and only if F (

ρ, λ)

±

1) + λ(2

δ2λ)(t

1)2.

−

−

0 for both choices of sign.

−

≥

ρ⋆ = inf

ρ

ρGD(δ) : F (

ρ, λ)

0 for some λ

≥

±

≥

{
ρGD(δ). Since we do not impose any upper bound on ρ, the
By deﬁnition, ρ⋆ ≥
quadratic nature of F in t implies that the inﬁmum is ﬁnite. Since F is continuous
and λ is bounded, there exists λ⋆ ∈
0. According to
Remark 2.16, we in fact have λ⋆ ∈
F (1

[0, 2δ−2] for which F (

(0, 2δ−2]. Also,

δ), λ) =

ρ⋆, λ⋆)

αm(1

≥

±

∈

(0, 2δ−2]
}

.

F (1

αL(1 + δ), λ) =

−

−

−

α2(L + m(δ2λ
δλ
α2(m + L(δ2λ + δλ

−

1))2,
1))2

−

−

−

−

(3.4)

for all λ. The following auxiliary lemma establishes some useful properties of F (

ρ⋆, λ⋆).

±

Lemma 3.2. The pair (ρ⋆, λ⋆) satisﬁes the following properties.

ρ⋆, λ⋆)) = 0.

(1) min(F (ρ⋆, λ⋆), F (
(2) λ⋆ ∈
(3) If max(F (ρ⋆, λ⋆), F (

(0, 2δ−2).

−

ρ⋆, λ⋆)) > 0, then ρ⋆ = ρGD(δ).

−

Proof. (1) If F (
deﬁnition of ρ⋆ we must have ρ⋆ = ρGD(δ). This contradicts (3.4).

ρ⋆, λ⋆) > 0 for both choices of sign, then by continuity of F and the

±

(2) If λ⋆ = 2δ−2, then F (t, 2δ−2) reduces to a strictly increasing linear function of t.
ρ⋆ by the ﬁrst part,

Since we know that F (t, λ⋆) must vanish at one of the endpoints
it must do so at

ρ⋆, i.e.,

±

−

F (

ρ⋆, 2δ−2) = 0.

−

On the other hand, it follows from (3.4) that F (1

−

αL(1 + δ), 2δ−2) < 0, so

ρ⋆ > 1

−

−

αL(1 + δ)

ρGD(δ),

≥ −

30

ORAN GANNOT

which is a contradiction.

−

ρ⋆, λ⋆)

(3) Suppose that F (ρ⋆, λ⋆) > 0. By the ﬁrst part we have F (

If
∂λF (
= 0 but ρ⋆ > ρGD(δ), then by perturbing ρ and λ slightly we can con-
tradict the deﬁnition of ρ⋆. This is possible since λ⋆ is in the open interval (0, 2δ−2).
ρ⋆, λ⋆) = 0. But in the latter case, the
Thus we either have ρ⋆ = ρGD(δ) or ∂λF (
simultaneous equations

ρ⋆, λ⋆) = 0.

−

−

∂λF (

ρ⋆, λ⋆) = 0, F (

−

ρ⋆, λ⋆) = 0
−
1. Since ρ⋆ ≥

imply that ρ⋆ = αL(1+δ)
−
this implies ρ⋆ = αL(1 + δ)
ρ⋆ reversed.
roles of ρ⋆ and

1 or ρ⋆ = αm(1

1,
1 = ρGD(δ) as well. The same argument applies with
(cid:3)

αL(1+δ)

ρGD(δ)

δ)

−

−

−

−

≥

−

It remains to compute ρ⋆. First we characterize the parameters (m, L, α, δ) for which

ρ⋆ = ρGD(δ). Recall that κ = L/m.

Lemma 3.3. Let 0 < m < L and δ
∈
one of the following conditions holds.

(1) δ < 2/(κ + 1) and

(0, 1). If α > 0, then ρ⋆ = ρGD(δ) if and only if

(2) δ

∈

[0, 1) and

α−(m, L, δ) =

α

≤

1

−

1

2

L + m −

δ

(cid:18)

δ
m

(cid:19)

α+(m, L, δ) =

α

≥

1
1 + δ

2
L + m

+

δ
L

(cid:19)
δ) or ρGD(δ) = αL(1 + δ)

(cid:18)

.

.

−

−

−

λ⋆ =

κ
δ(1

1
δ)

.

−
−

Proof. We have ρGD(δ) = 1
is larger.

−

αm(1

−

1 depending on which

(1) First suppose that ρGD(δ) = 1

αm(1

δ). If ρ⋆ = ρGD(δ), then from (3.4) we

must have F (ρ⋆, λ⋆) = 0, which uniquely determines

(3.5)

0, where

≤

Now F is quadratic in t, so F (

ρ⋆, λ⋆)

−

≥

0 if and only if ∂tF (0, λ⋆)

∂tF (0, λ⋆) = 2λ⋆(α(m + L)

2 + δ2λ⋆).

−

This is true if and only if λ⋆ ≤
equivalent to α
≤

−
α−. Conversely, if α

(2

α−, then

≤
δ) > αL(1 + δ)

1

−

αm(1

−

1

−
αm(1

and hence ρGD(δ) = 1
which shows that ρ⋆ = ρGD(δ). Finally, observe that α− > 0 if and only if

δ). If λ⋆ is deﬁned by (3.5), then F (

−

−

±

ρGD(δ), λ⋆)

0,

≥

α(m + L))δ−2, which combined with (3.5) is

δ < 2/(κ + 1),

6
A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

31

which is also equivalent to 2

δ2λ⋆ > 0 (cf. the second part of Lemma 3.2).

−
(2) A similar argument applies if ρGD(δ) = αL(1 + δ)

1. If ρ⋆ = ρGD(δ), then

−

λ⋆ =

κ

1

−
κδ(1 + δ)

.

in order to ensure F (
∂tF (0, λ⋆)
αL(1 + δ)

−
0, is the same as α
ρGD(δ), λ⋆)

1 and F (

≥
−

±

α+. Conversely,

if α

≥
≥

0.

≥

ρ⋆, λ⋆) = 0. The condition F (ρ⋆, λ⋆)

0, or equivalently
≥
α+, then ρGD(δ) =
(cid:3)

In the context of Lemma 3.3, we have ρGD(δ) = αL(1 + δ)

α+. In
that case there is no restriction on δ, but observe that δ < 2/(κ + 1) is necessary for
ρGD(δ) < 1 to hold; if α = α+, then it is also suﬃcient.

1 when α

−

≥

Proof of Proposition 1.3. The Proposition follows from Lemma 3.3 and the deﬁnition
of ρ⋆. To show that one can take c = 1 in the deﬁnition of hyperstability, note that
(A, Bue) is controllable for α > 0. Using Lemma 2.4 and Lemma 2.7, there exists
(cid:3)
P = pI satisfying (LMI) with p > 0.

When the conditions of Lemma 3.3 are violated, we must have ρ⋆ > ρGD(δ). By the

third part of Lemma 3.2, it is easy to compute ρ⋆. This leads to Proposition 1.4:

Proof of Proposition 1.4. If ρ⋆ > ρGD(δ), then we must have F (ρ⋆, λ⋆) = F (
ρ⋆, λ⋆) =
0. Since F is quadratic in t, this happens if and only if ∂tF (0, λ⋆) = 0, or equivalently,

−

λ⋆ =

2

−

α(L + m)

δ2

.

The second part of Lemma 3.2 gives an upper bound α < 2/(L + m). We can then
compute

ρ⋆ =

1
(cid:18)

2αLm
L + m

+

−

αδ2(L + m
2

−
α(L + m)

2αLm)

−

1/2

(cid:19)

as claimed. Conversely, the proof of Lemma 3.3 makes it clear that this value of ρ⋆
is strictly larger than ρGD(δ) unless α = α− or α = α+. The same argument as
in the proof of Proposition 1.4 shows that one can take c = 1 in the deﬁnition of
(cid:3)
hyperstability.

3.2. Strongly convex functions. Next, we address Proposition 1.5 for strongly con-
0(m, L) by translations. We
vex functions in
again apply the results of §2.6, using the oﬀ-by-one IQC as the reference IQC. The
underlying LTI system is

(m, L). As usual, we assume that f

∈ F

F

xt+1
vt+1

(cid:20)

(cid:21)

= ˆA

xt
vt(cid:21)

(cid:20)

+ Bue

,

ut
et(cid:21)

(cid:20)

ˆA =

1 0
L 0

(cid:20)

⊗

(cid:21)

In, Bue =

α
−
1
−

(cid:20)

α
−
0

⊗

(cid:21)

In.

32

ORAN GANNOT

First, we verify that the inexact Jury–Lee criterion (2.30) holds for some λ > 0 when

τ = ρ = ρGD(δ).

Denote by Φ(z, λ) the left-hand side of (2.30) and consider the two possible values of
ρGD(δ).

(3.6)

δ)ρ⋆)).

(1) First, suppose that ρ⋆ := ρGD(δ) = 1

αm(1
−
δ)2(δλ

−

δ), and calculate
m)α)2.

(L

−
Requiring this quantity to be nonnegative uniquely determines

−

−

−

Φ(ρ⋆, λ) =

m2α2(1

Plugging in this value of λ, we can write Φ(z, λ⋆) = F (Re z), where

λ⋆ =

(L

m)α
−
δ

.

F (t) = 2λ⋆(z

ρ⋆)(2(1

αL)z

1

−

−

−

−

ρ2
⋆ + αL((1 + δ)

(1

1/L, then this is a concave function of t, so F (t)

−
0 for all t

−

≥

ρ⋆, ρ⋆] if and

[
−

∈

If α
≥
only if F (

ρ⋆)

−

≥

0. But

F (

ρ⋆) = 4λ⋆ρ⋆(1 + ρ⋆)(ρ⋆ −
−
αL(1 + δ)
1 by assumption.
−

since ρ⋆ ≥

(αL(1 + δ)

1))

0,

≥

−

On the other hand, if α < 1/L, then F (t) is a convex quadratic, so F (t)
0. Now

0 for all

≥

t

[
−

∈

ρ⋆, ρ⋆] if and only if F ′(ρ⋆)
F ′(ρ⋆) =

2αλ⋆(1

≤

−

δ)(2L

αm((3

δ)L

(1

−

−

−

−

−

δ)m)),

and this is certainly negative for α < 1/L.

(2) Next, suppose that ρ⋆ := ρGD(δ) = αL(1 + δ)
L2α2(1 + δ)2(λδ

ρ⋆, λ) =

Φ(

−

−

−

(L

−

−

m)α)2.

1. In that case, compute

Nonnegativity of this quantity uniquely determines λ by the same formula (3.6). We
can again express Φ(z, λ⋆) = F (Re z), where this time

F (t) = 2λ⋆(z + ρ⋆)(2(1

αL)z

2(1

αm) + α(L

m)(2δ + αL(1

−
−
This is a concave function, so as above we only need to verify that F (ρ⋆)
algebra gives

−

−

−

≥

δ2))).

0. Some

Since ρ⋆ ≥

1

−

αm(1

F (ρ⋆) = 4λ⋆ρ⋆(1

−
δ) by assumption, this quantity is nonnegative provided ρ⋆ ≤

−

−

−

1.

ρ⋆)(ρ⋆ −

(1

αm(1

δ))).

In the context of establishing ρGD(δ)-hyperstability via Theorem 1, we have shown
that (FDI) holds under the hypotheses of Proposition 1.5. To verify the ρGD(δ)-minimal
stability hypothesis, we combine Lemma 2.14 with the following result.

Lemma 3.4. Let A = C = In and B =
exists ε

≥
[0, 1] such that the matrix (2.17) is ρ-Schur.

αIn. If ρ

−

∈

ρGD and τ

∈

[0, ρ], then there

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

33

Proof. Because of its block structure, we can assume (2.17) is the 2

2 matrix

×

1

α((1
(1

ε)m + εL) αετ 2
ετ 2

m)

−
ε)(L

−

.

(cid:21)

−
Up to a scalar factor of ρ2, the characteristic polynomial of this matrix as a function
of ρz is

−

(cid:20)

ρ−1(1

z2

−

αm

−

−

αε(L

−

m) + ετ 2)z + ετ 2ρ−2(1

αL).

−

It suﬃces to show that the roots of this function lie in the open unit disk, or equiva-
lently,

ρ−1

1

|

−

αm + ετ 2

m)

< 1 + ετ 2ρ−2(1

αε(L
−
ετ 2ρ−2

−
1

|
αL
|
0 suﬃciently small. If ρ >

< 1.

−

|

αL),

−

(3.7)

(3.8)

Clearly (3.8) is satisﬁed for ε
satisﬁed with ε = 0. Thus we can assume ρ =
ρGD. Now we must verify
since ρ

≥

1

αm
|
, which implies ρ = 1

, then (3.7) is
αm

−

|

−

1

|

−

αm
|

≥
ετ 2ρ−2(1

1
−

−

αL) < ρ−1(1

αm + ετ 2

−

αε(L

−

−

−

m)) < 1 + ετ 2ρ−2(1

αL).

−

Clearly the ﬁrst inequality holds for suﬃciently small ε
equality, it suﬃces to show ρ(τ 2

m)) < τ 2(1

α(L

≥

αL). But

0. As for the second in-

τ 2(1

αL)

−
ρ(τ 2

−
α(L

−
m)) = α(L

−
which is strictly positive since ρ = 1
choose ε > 0 suﬃciently small.

−

−

−

−
αm

m)(ρ

−

τ 2),

−
ρ. Thus it suﬃces to
(cid:3)

(0, 1) and τ

∈

≤

Proof of Proposition 1.5. Let τ = ρGD(δ) and deﬁne λ⋆ by (3.6). In view of the obser-
vations above, to show that ( ˆA, Bue; στ + λ⋆σ∆) is ρGD(δ)-hyperstable using Theorem
1, we need only verify that det Πue(ζ, z)
0. The bottom right entry of στ + λ⋆σ∆ in
the block decomposition (2.2) is

6≡

R =

λ⋆δ2
0

2

−

0
λ⋆(cid:21)
−

In.

⊗

Since we are assuming that α
certainly has nonzero determinant, and hence det Πue(

(cid:20)
2/((1 + δ)L) and λ⋆ is given by (3.6), this matrix
(cid:3)
)

= 0.

≤

,

∞

∞

3.3. Proof of Lemma 1.7. The proof is essentially contained in [THG2], so we only
δ <
provide a brief sketch. As in the statement of Lemma 1.7, suppose that 0
2√κ/(κ + 1) and α
(0, ¯α−). Denote by ρ⋆ the right-hand side of (1.13). The
combination of Proposition 1.3 and Proposition 1.4 shows that

≤

∈

ρ2
⋆ = inf

{

ρ2 : ρ2, λ1, λ2

0, L1

−

≥

ρ2L0 + λ1M1 + λ2M2

0

,

}

(cid:22)

6
34

ORAN GANNOT

where we deﬁne

L0 =

1 0 0
0 0 0
0 0 0





, L1 =

α
1
−
α α2
α α2

−
−





, M2 =

,

α
−
α2
α2 

0
0
0 δ2

0
0


0
0
1
−

.





M1 =





−
L + m
0


2Lm L + m 0
0

0


2
−
0



This minimization problem is the dual of the primal semideﬁnite program

sup

tr(L1G) : G

0, tr(L0G)

1, tr(M1G)

0, tr(M2G)

0

.

{

(cid:23)

≤
It is easy to construct a strictly feasible point for the primal problem: ﬁrst take any
f + u′′
nonzero xf
f ,
where u′′
f). Finally, choose a
f ∈
nonzero ef
∈

∈
R3 is nonzero and orthogonal to xf (and hence also u′
R3 orthogonal to (xf, uf). The matrix

f = (L + m)xf/2. Then choose uf = u′

< 1 and let u′

R3 with

≥

≥

xf

k

k

}

Gf :=

xf uf

ef

xf uf

ef

⊤

tr(M1Gf) = (L

−
ef

is positive deﬁnite, and satisﬁes tr(L0Gf) =

(cid:2)
2/2

m)2

xf

k

k

2

k

−

xf
(cid:2)
k
2,

2 < 1. Furthermore,
(cid:3)
tr(M2Gf) = δ2

uf

(cid:3)
k
u′′
f k

2

ef

2.

k

− k

k

k

u′′
f k

k

and

If we choose
suﬃciently small, then both terms above are strictly pos-
itive, so Gf is strictly feasible. Since Slater’s condition is satisﬁed there is no duality
gap and the supremum in the primal problem is also equal to ρ2
⋆.
3, then any R3×3

Now observe that if the ambient dimension is n

0 can

G

k

k

≥

∋

(cid:23)

certainly be written in the form

G =

x u e

⊤

x u e

Rn. In particular, if ρ < ρ⋆, then there exists x0, u0, e0
(cid:3)

(cid:2)

(cid:2)

(cid:3)

for some x, u, e

∈

x0

k

−

α(u0 + e0)

2 > ρ2

x0

2,

σ0(x0, u0)

0,

δ2

u0

2

Now given (x0, u0) with σ0(x0, u0)
such that u0 =

k
0, we can always ﬁnd f
f (x0). Indeed, according to [THG2, Theorem 4], there exists f

− k
0(m, L)

⊂ S

∈ F

≥

≥

≥

k

k

k

k

k

0(m, L)

Rn satisfying

∈
2

e0

0.

∇
0(m, L) such that

F

f (x0) = 1
2h
f (x0) = u0,

u0, x0

i ≥

∇

0,

f (0) = 0,

f (0) = 0.

In conclusion, if ρ < ρ⋆, then we can ﬁnd f

0(m, L) and x0, e0

x0

k

−

α(

∇

f (x0) + e0)

k

as desired.

> ρ
k

,

e0

k

k ≤

δ

k∇

k

∈
f (x0)

Rn satisfying

k

∇

∈ F
x0

∈

(cid:3)

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

35

4. Inexact Triple Momentum Method

4.1. TMM. In this section we discuss basic properties of TMM in the exact setting.
Recall from §1.3 that TMM is deﬁned on Rn by the recursion (1.14), where (α, β, γ)
(m, L) is
are deﬁned by (1.15). The corresponding convergence rate that holds over

F

ρTM = 1

1/√κ.

−

By translations we can restrict our attention to f

0(m, L).

∈ F

Similar to §2.5, TMM admits a state-representation on R2n with system matrices

α
−
0

⊗

A =

1 + β
1

β
−
0

⊗

In, B =

In, C =

1 + γ

In.

(4.1)

γ

−

⊗

(cid:20)

(cid:21)

(cid:21)
In [VSFL], the parameters (1.15) were chosen in the frequency domain to satisfy the
Jury–Lee criterion (2.18) via pole-zero assignment as follows. Let H(z) = C(zI
A)−1B. Since z
(2.18) is equivalent to

−
mH(z))−1 shows that

0, conjugating by (I

mH(z))

det(I

7→

−

−

6≡

(cid:20)

(cid:3)

(cid:2)

Re

(1

−

τ 2/z)(I

−

LH(z))(I

−

mH(z))−1

0.

(cid:23)

(cid:2)
In fact, because of the block structure, for the purposes of verifying (2.18) for TMM
we can assume that H(z) is scalar, given by

(cid:3)

H(z) =

α

−

(1 + γ)z
1)(z
(z

−

−
−

γ
β)

.

(4.2)

−

τ 2/z)(1

LH(z))(1

mH(z))−1 to a linear fractional transformation
We can reduce (1
of the disk of radius ρ (for a certain ρ > 0) onto the left half-plane by an appropriate
choice of pole-zero cancellations: there is precisely one way to choose the four unknowns
(α, β, γ, ρ) so that 1
ρ, τ 2

. These parameters are

mH(z) has roots z

LH(z) has roots z

, and 1

∈ {−

ρ, 0

−

−

−

−

∈

}

{

}

α =

τ 2)
−
τ 2) + m

,

2(1

L(1

−

β =

(κ(1

(κ(1

τ 2)

1)κτ 2

−
−
τ 2) + 1)(κ
−
τ 2)
1
.
−
τ 2) + 1

,

γ =

1)

(κ(1
2(κ

−
−

τ 2) + 1)τ 2
τ 2)
1)(1

,

ρ =

−
κ(1
κ(1
τ 2) in order to have ρ > 0. Furthermore, ρ is

−
−

−

Note that we must have κ > 1/(1
related to τ by 0

τ

ρ. With these choices,

−

≤

≤

τ 2/z)(1

(1

−

−

LH(z))(1

−

mH(z))−1 =

z + ρ
ρ
z

.

−

Since ρ is a decreasing function of τ , the best rate is obtained by setting τ = ρ. This
1/√κ, and also yields
provides an implicit equation for ρ whose solution is ρTM = 1
the parameter choices (1.15).

−

36

ORAN GANNOT

In [VSFL] the authors resort to constructing an explicit Lyapunov function to show
that TMM converges at rate ρTM. This is because the properties of TMM in the
frequency domain are (by design) quite degenerate. In contrast, a reﬁned result like
Theorem 1 enables an analysis entirely within the frequency domain. We apply the
Jury–Lee criterion. Since the frequency condition (2.18) is satisﬁed by construction,
[0, 1]. Because of the block
it remains to show that (2.17) is ρTM-Schur for some ε
structure, we can assume that the matrix (2.17) is given by

∈

ρTM(1 + ρTM

(2 + ρTM)ε)

−
1

(1

−

ε)ρ3
−
0

TM

εm−1ρ2

TM(1

ρTM)2(1 + ρTM)
0

−



m(1
(1

−
−

ε)ρTM(2 + ρTM)
ρTM)2(1 + ρTM)




The eigenvalues of this matrix are 0, ρ2
−
this matrix is ρTM-Schur. Lemma 2.12 now applies.

TM, and (1

(1

ε)ρ3
m(1
ρTM)2(1 + ρTM)

−

TM

−
−

ερ2

TM

2ε)ρTM. Clearly if ε



.




(0, 1), then

∈

4.2. Inexact TMM. In order to analyze inexact TMM, we follow §2.6 and consider
the system

xt+1
vt+1

(cid:20)

(cid:21)

= ˆA

xt
vt(cid:21)

(cid:20)

+ Bue

,

ut
et(cid:21)

(cid:20)

ˆA =

A 0n
LC 0n(cid:21)
(cid:20)

, Bue =

B B
In 0n(cid:21)
−

(cid:20)

,

where xt = (ξt, ξt−1) and (A, B, C) are speciﬁed by (4.1). We begin by examining the
perturbed Jury–Lee frequency condition (2.30). Fixing τ = ρ and using the notation
of §2.6, we can write

2 Re

(1

−
= ρ, where

(cid:2)

ρ2/z)(1

−

mH(z))∗(1

−

LH(z))

= q(Re z, ρ)

(cid:3)

whenever

z

|

|
q(t, ρ) =

2(ρ2

−

−

We now introduce some additional notation: given µ
linear (in t) function

∈

TM)(2ρTMt2 + (ρ2 + ρ2
ρ2

TM)t

(1 + ρTM)2ρ2).

−

R and a ﬁxed ρ > 0, deﬁne the

If

z

|

|

= ρ, then we can express

ℓ(t, ρ, µ) := ρ2 + µ2

2µt.

−

z

µ

2 = ℓ(Re z, ρ, µ).

|
Denote by Φ(z, ρ, λ) the left-hand side of (2.30), where we take τ = ρ. Then for
we can write Φ(z, ρ, λ) = F (Re z, ρ, λ), where

−

|

= ρ,

z

|

|

F (t, ρ, λ) = λq(t, ρ)

−
α2(1 + γ)2

λ2δ2

(L

ℓ(Re z, β)

ℓ(Re z, 1)
m)2ℓ(Re z, 1) + 2λδ2Lm(1

·

Re z)

ℓ(Re z, γ/(1 + γ)).

−

·

−

It is easy to see that F (t, ρ, λ) is a concave quadratic function of t. Thus, for a given
ρ > 0 and λ

(cid:0)
0, we have F (t, ρ, λ)

ρ, ρ] if and only if F (

ρ, ρ, λ)

0 for t

0.

(cid:1)

≥

[
−

∈

−

≥

±

≥

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

37

κ = 2

κ = 10

ρ

1

0.8

0.6

0.4

0

1

0.95

ρ

0.9

0

1

0.9

0.8

0.7

0

1

0.99

0.98

0.97

LMI
ρTM(δ)

5 · 10−2

0.1

κ = 103

LMI
ρTM(δ)

0

2 · 10−3

4 · 10−3

6 · 10−3

8 · 10−3

δ

LMI
ρTM(δ)

0.2

0.4

κ = 102

LMI
ρTM(δ)

1 · 10−2

2 · 10−2

δ

Figure 4. Plots of ρTM(δ) and the numerically computed rate obtained
by solving (LMI) for P
0 using the oﬀ-by-one IQC (over all admissible
τ ). This supports the conjecture that ρTM(δ) is actually optimal with
respect to the inexact Jury–Lee criterion.

(cid:23)

Next, deﬁne

ρ⋆ := inf

ρ

ρTM : F (

ρ, ρ, λ)

0 for some λ

±
By arguing as in §3.1, if the optimal value ρ⋆ is ﬁnite, then F (t, ρ⋆, λ⋆)
(0, 2δ−2]. Since ρTM
t

(0, 1), it is easy to check that

≥

≥

≥

∈

{

(0, 2δ−2]
}

.

ρ⋆, ρ⋆] and some λ⋆ ∈
[
−

∈

0 for all

∈
F (0, ρ, 2δ−2) < 0

for any ρ > 0. Consequently, λ⋆ ∈

(0, 2δ−2).

As in §3.1, we must have that at least one of F (

ρ⋆, ρ⋆, λ⋆) = 0. Furthermore,
(0, 2/δ2), we must
ρ⋆, ρ⋆, λ⋆) = 0, otherwise by perturbing λ slightly we could contradict the

ρ⋆, ρ⋆, λ⋆) = 0 but F (ρ⋆, ρ⋆, λ⋆) > 0. Since λ⋆ ∈
−

suppose that F (
have ∂λF (

±

−

38

ORAN GANNOT

deﬁnition of ρ⋆. The same argument applies if we replace t =
there are three (not mutually exclusive) possibilities:

ρ⋆ with t = ρ⋆. Thus

−

(1) F (

ρ⋆, ρ⋆, λ⋆) = 0 = F (ρ⋆, ρ⋆, λ⋆),

−

(2) F (ρ⋆, ρ⋆, λ⋆) = 0 = ∂λF (ρ⋆, ρ⋆, λ⋆),

(3) F (

ρ⋆, ρ⋆, λ⋆) = 0 = ∂λF (

−

ρ⋆, ρ⋆, λ⋆).

−

We have been unable to analytically characterize which of these conditions is optimal
depending on the values of the parameters. However, some experimentation suggests
that the third condition always leads to the smallest value of feasible ρ. Thus, as a
relaxation, we ﬁnd the smallest ρ satisfying

F (

ρ, ρ, λ) = 0 = ∂λF (

−

ρ, ρ, λ)

−

(0, 2δ−2), and then show that (FDI) indeed holds.

for some λ

∈

Due to the quadratic nature of F (t, ρ, λ) in λ, it suﬃces to solve for ρ satisfying

Deﬁne the quadratic functions

disc(F (ρ, ρ, λ); λ) = 0.

a±(ρ) :=

b±(ρ) :=

−

−

(2

(2

−
−
ρ2
TM((2

ρTM)ρ2 + (ρTM(2
ρTM)ρ2

−

(ρTM(2 + ρTM

−

ρTM)ρTM

δ(1

ρTM)

δ(2 + ρTM))ρ
±
ρ2
TM)
−
ρTM)2).

δ(2

∓

−

δρ2
TM,
±
3ρTM + ρ3

TM))ρ

−
Then the discriminant admits the factorization

−

∓

−

disc(F (

ρ, ρ, λ); λ) = 4ρ−2(2

−

−

ρTM)−4(ρ + ρ2

TM)2a+(ρ)a−(ρ)b+(ρ)b−(ρ).

Only a+ and b+ can have positive roots for δ > 0. Furthermore, while b+ can have
positive roots, the corresponding unique value of λ for which F (
ρ, ρ, λ) = 0 is actually
negative for ρ > 0. Thus the only feasible value of ρ is the unique positive root a+
(such a root always exists, since a+ is a concave quadratic and a+(0) > 0). In the
notation of Proposition 1.8, this positive root is

−

ρTM(δ) :=

θTM + (θ2

TM + 4δρ2
2(2

TM(2
ρTM)

−

ρTM))1/2

,

−

where θTM = (2

ρTM)ρTM + (2 + ρTM)δ.

−

Next, we verify that ρTM(δ) is actually feasible for (FDI). To ease the notational

burden, let us write ρ0 = ρTM(δ). Let λ0 be the unique value satisfying

F (

ρ0, ρ0, λ0) = 0.

−

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

39

It suﬃces to show that ∂tF (0, ρ0, λ0)
≥
ﬁrst express δ and λ0 as functions of ρ0:

0. Perhaps the simplest way to show this is to

δ =

ρ0ρTM(ρ0

ρTM)(2

−

−
ρ0(2 + ρTM) + ρ2
TM

ρTM)2

TM + ρ0(2 + ρTM))2

ρTM(ρ2
ρTM)

,

(4.3)

λ0 =

ρ0(ρ2

0(2

−
Now plug (4.3) back into the derivative.
coeﬃcients of the polynomial ρ
implies that the derivative is nonnegative for any value of ρ0
brevity we omit the details.

TM)
It is then easy show that all the Taylor
∂tF (0, ρ, λ0) at ρ = ρTM are nonnegative, which
ρTM. For the sake of

2ρ0ρTM(1

7→

≥

−

−

ρTM) + ρ3

.

Proof of Proposition 1.8. To ﬁnish the proof of Proposition 1.8, we must show that
( ˆA, Bue; σρ0 + λ0σ∆) is actually ρ0-hyperstable. The minimal stability hypothesis of
Theorem 1 follows from Lemma 2.14 and the results of §4.1. It is also easy to see that
(0, 1), so we can apply Theorem 1 as in the proof of
λ0
(cid:3)
Proposition 1.5 (which can be found at the end of §3.2).

(0, 2δ−2) for any ρTM, ρ0

∈

∈

References

[ACH]

N Syazreen Ahmad, Joaqu´ın Carrasco, and William Paul Heath. A less conservative lmi
condition for stability of discrete-time systems with slope-restricted nonlinearities. IEEE
Transactions on Automatic Control, 60(6):1692–1697, 2014.

[Ber]

[BLR]

[AGMM] Sanjeev Arora, Rong Ge, Tengyu Ma, and Ankur Moitra. Simple, eﬃcient, and neural
algorithms for sparse coding. In Conference on learning theory, pages 113–149. PMLR,
2015.
Dimitri P Bertsekas. Nonlinear programming. athena scientiﬁc belmont. Massachusets,
USA, 1999.
Ross Boczar, Laurent Lessard, and Benjamin Recht. Exponential convergence bounds using
integral quadratic constraints. In 2015 54th IEEE Conference on Decision and Control
(CDC), pages 7516–7521. IEEE, 2015.
Apurva Badithela and Peter Seiler. Analysis of the heavy-ball algorithm using integral qua-
dratic constraints. In 2019 American Control Conference (ACC), pages 4081–4085. IEEE,
2019.
Yuxin Chen and Emmanuel Candes. Solving random quadratic systems of equations is
nearly as easy as solving linear systems. In Advances in Neural Information Processing
Systems, pages 739–747, 2015.

[CC]

[BS]

[CDO] Michael B Cohen, Jelena Diakonikolas, and Lorenzo Orecchia. On acceleration with noise-

corrupted gradients. arXiv:1805.12591, 2018.

[CHVSL] Saman Cyrus, Bin Hu, Bryan Van Scoy, and Laurent Lessard. A robust accelerated opti-
mization algorithm for strongly convex functions. In 2018 Annual American Control Con-
ference (ACC), pages 1376–1381. IEEE, 2018.
Emmanuel J Candes, Xiaodong Li, and Mahdi Soltanolkotabi. Phase retrieval via Wirtinger
ﬂow: Theory and algorithms. IEEE Transactions on Information Theory, 61(4):1985–2007,
2015.

[CLS]

40

[d’A]

[DD]

ORAN GANNOT

Alexandre d’Aspremont. Smooth optimization with approximate gradient. SIAM Journal
on Optimization, 19(3):1171–1183, 2008.
Ross Drummond and Stephen Duncan. Accelerated gradient methods with memory.
arXiv:1805.09077, 2018.

[DGN1] Olivier Devolder, Fran¸cois Glineur, and Yurii Nesterov. First-order methods with inexact

oracle: the strongly convex case. CORE Discussion Papers, 2013016, 2013.

[DGN2] Olivier Devolder, Fran¸cois Glineur, and Yurii Nesterov. Intermediate gradient methods for

smooth convex problems with inexact oracle. Technical report, 2013.

[DGN3] Olivier Devolder, Fran¸cois Glineur, and Yurii Nesterov. First-order methods of smooth
convex optimization with inexact oracle. Mathematical Programming, 146(1-2):37–75, 2014.
[dKGT1] Etienne de Klerk, Francois Glineur, and Adrien Taylor. Worst-case convergence analysis of
gradient and Newton methods through semideﬁnite programming performance estimation.
arXiv:1709.05191, 2017.

[DT1]

[dKGT2] Etienne de Klerk, Fran¸cois Glineur, and Adrien B Taylor. On the worst-case complex-
ity of the gradient method with exact line search for smooth strongly convex functions.
Optimization Letters, 11(7):1185–1199, 2017.
Yoel Drori and Adrien B Taylor. Eﬃcient ﬁrst-order methods for convex minimization: a
constructive approach. Mathematical Programming, pages 1–38, 2018.
Yoel Drori and Marc Teboulle. Performance of ﬁrst-order methods for smooth convex min-
imization: a novel approach. Mathematical Programming, 145(1-2):451–482, 2014.
Guilherme Fran¸ca and Jos´e Bento. An explicit rate bound for over-relaxed ADMM. In 2016
IEEE International Symposium on Information Theory (ISIT), pages 2104–2108. IEEE,
2016.

[DT2]

[FB]

[FS1]

[FS2]

[Gan]

[GES]

[FRMP] Mahyar Fazlyab, Alejandro Ribeiro, Manfred Morari, and Victor M Preciado. Analysis of
optimization algorithms via integral quadratic constraints: Nonstrongly convex problems.
SIAM Journal on Optimization, 28(3):2654–2689, 2018.
Matthias Fetzer and Carsten W Scherer. Absolute stability analysis of discrete time feed-
back interconnections. IFAC-PapersOnLine, 50(1):8447–8453, 2017.
Michael P Friedlander and Mark Schmidt. Hybrid deterministic-stochastic methods for data
ﬁtting. SIAM Journal on Scientiﬁc Computing, 34(3):A1380–A1405, 2012.
Oran Gannot. Frequency criteria for exponential stability. arXiv preprint arXiv:1910.10855,
2019.
Dennis Gramlich, Christian Ebenbauer, and Carsten W Scherer. Convex synthesis of ac-
celerated gradient algorithms for optimization and saddle point problems using Lyapunov
functions. arXiv preprint arXiv:2006.09946, 2020.
Bin Hu and Laurent Lessard. Control interpretations for ﬁrst-order optimization methods.
In 2017 American Control Conference (ACC), pages 3114–3119. IEEE, 2017.
Bin Hu and Laurent Lessard. Dissipativity theory for nesterov’s accelerated method. In
Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages
1549–1557, 2017.
Sepideh Hassan-Moghaddam and Mihailo R Jovanovi´c. Proximal gradient ﬂow and
Douglas–Rachford splitting dynamics: global exponential stability via integral quadratic
constraints. arXiv:1908.09043, 2019.
Bin Hu and Peter Seiler. Exponential decay rate conditions for uncertain linear systems us-
ing integral quadratic constraints. IEEE Transactions on Automatic Control, 61(11):3631–
3637, 2016.

[HMJ]

[HL1]

[HL2]

[HS1]

[HS2]

[HSL1]

[HSL2]

[HWL]

[JL1]

[JL2]

[Kal]

[KF1]

[KF2]

[KLY]

[KS]

[LRP]

[LS]

[Lur]

[LY]

[Mic]

[MR]

[MSE]

A FREQUENCY-DOMAIN ANALYSIS OF INEXACT GRADIENT METHODS

41

Bin Hu and Usman Ahmed Syed. Characterizing the exact behaviors of temporal diﬀerence
learning algorithms using Markov jump linear system theory. arXiv:1906.06781, 2019.
Bin Hu, Peter Seiler, and Laurent Lessard. Analysis of approximate stochastic gra-
dient using quadratic constraints and sequential semideﬁnite programs. arXiv preprint
arXiv:1711.00987, 2017.
Bin Hu, Peter Seiler, and Laurent Lessard. Analysis of biased stochastic gradient descent
using sequential semideﬁnite programs. Mathematical Programming, pages 1–26, 2020.
Bin Hu, Stephen Wright, and Laurent Lessard. Dissipativity theory for accelerating sto-
chastic variance reduction: A uniﬁed analysis of SVRG and Katyusha using semideﬁnite
programs. arXiv:1806.03677, 2018.
EI Jury and BW Lee. A stability theory for multinonlinear control systems. In The third
IFAC World Congress, volume 28, pages A1–A11, 1966.
EL Jury and B Lee. On the stability of a certain class of nonlinear sampled-data systems.
IEEE Transactions on Automatic Control, 9(1):51–61, 1964.
RE Kalman. Lectures on controllability and observability. In Controllability and Observ-
ability, pages 1–149. Springer, 2010.
Donghwan Kim and Jeﬀrey A Fessler. Optimized ﬁrst-order methods for smooth convex
minimization. Mathematical programming, 159(1-2):81–107, 2016.
Donghwan Kim and Jeﬀrey A Fessler. On the convergence analysis of the optimized gradient
method. Journal of optimization theory and applications, 172(1):187–205, 2017.
Robert Kleinberg, Yuanzhi Li, and Yang Yuan. An alternative view: When does SGD
escape local minima? arXiv preprint arXiv:1802.06175, 2018.
Rudolf E Kalman and G Szego¨o. Sur la stabilit´e absolue d’un syst`eme d’´equations aux
diﬀ`erences ﬁnies. C R Acad Sci Paris.
Laurent Lessard, Benjamin Recht, and Andrew Packard. Analysis and design of optimiza-
tion algorithms via integral quadratic constraints. SIAM Journal on Optimization, 26(1):57–
95, 2016.
Laurent Lessard and Peter Seiler. Direct synthesis of iterative algorithms with bounds on
achievable worst-case convergence rate. arXiv:1904.09046, 2019.
AI Lurie. Some nonlinear problems in the theory of automatic control. London: HM Sta-
tionary Oﬃce, 1957.
Yuanzhi Li and Yang Yuan. Convergence analysis of two-layer neural networks with ReLU
activation. arXiv preprint arXiv:1705.09886, 2017.
Simon Michalowsky. Design of Distributed and Robust Optimization Algorithms. A Systems
Theoretic Approach. Logos Verlag Berlin GmbH, 2020.
Alexandre Megretski and Anders Rantzer. System analysis via integral quadratic con-
straints. IEEE Transactions on Automatic Control, 42(6):819–830, 1997.
Simon Michalowsky, Carsten Scherer, and Christian Ebenbauer. Robust and struc-
ture exploiting optimization algorithms: An integral quadratic constraint approach.
arXiv:1905.00279, 2019.
Yurii Nesterov. Lectures on convex optimization, volume 137. Springer, 2018.

[Nes]
[NLR+] Robert Nishihara, Laurent Lessard, Benjamin Recht, Andrew Packard, and Michael I Jor-
dan. A general analysis of the convergence of ADMM. arXiv:1502.02009, 2015.
R O’Shea and M Younis. A frequency-time domain stability criterion for sampled-data
systems. IEEE Transactions on Automatic Control, 12(6):719–724, 1967.
VM Popov and Radu Georgescu. Hyperstability of control systems. Springer-Verlag, 1973.

[OY]

[PG]

42

[Pol]

[Ran]

ORAN GANNOT

Boris T Polyak. Introduction to optimization. Inc., Publications Division, New York, 1,
1987.
Anders Rantzer. On the kalman—yakubovich—popov lemma. Systems & Control Letters,
28(1):7–10, 1996.

[SJFB]

[RTBG] Ernest K Ryu, Adrien B Taylor, Carolina Bergeling, and Pontus Giselsson. Operator split-
ting performance estimation: Tight contraction factors and optimal parameter selection.
arXiv:1812.00146, 2018.
Sam Safavi, Bikash Joshi, Guilherme Fran¸ca, and Jos´e Bento. An explicit convergence rate
for nesterov’s method from SDP. In 2018 IEEE International Symposium on Information
Theory (ISIT), pages 1560–1564. IEEE, 2018.
Ruoyu Sun and Zhi-Quan Luo. Guaranteed matrix completion via non-convex factorization.
IEEE Transactions on Information Theory, 62(11):6535–6579, 2016.
Adrien Taylor and Francis Bach. Stochastic ﬁrst-order methods: non-asymptotic and
computer-aided analyses via potential functions. arXiv:1902.00947, 2019.

[TB]

[SL]

[THG1] Adrien B Taylor, Julien M Hendrickx, and Fran¸cois Glineur. Exact worst-case performance
of ﬁrst-order methods for composite convex optimization. SIAM Journal on Optimization,
27(3):1283–1313, 2017.

[THG2] Adrien B Taylor, Julien M Hendrickx, and Fran¸cois Glineur. Smooth strongly convex inter-
polation and exact worst-case performance of ﬁrst-order methods. Mathematical Program-
ming, 161(1-2):307–345, 2017.

[THG3] Adrien B Taylor, Julien M Hendrickx, and Fran¸cois Glineur. Exact worst-case convergence
rates of the proximal gradient method for composite convex minimization. Journal of Op-
timization Theory and Applications, 178(2):455–476, 2018.

[Wil1]

[TVSL] Adrien Taylor, Bryan Van Scoy, and Laurent Lessard. Lyapunov functions for ﬁrst-order
methods: Tight automated convergence guarantees. arXiv preprint arXiv:1803.06073, 2018.
[VSFL] Bryan Van Scoy, Randy A Freeman, and Kevin M Lynch. The fastest known globally con-
vergent ﬁrst-order method for minimizing strongly convex functions. IEEE Control Systems
Letters, 2(1):49–54, 2017.
Jan Willems. Least squares stationary optimal control and the algebraic Riccati equation.
IEEE Transactions on Automatic Control, 16(6):621–634, 1971.
Jan Willems. On the existence of a nonpositive solution to the Riccati equation. IEEE
Transactions on Automatic Control, 19(5):592–593, 1974.
Jan C Willems. Dissipative dynamical systems part I: General theory. Archive for rational
mechanics and analysis, 45(5):321–351, 1972.
Jan C Willems. Dissipative dynamical systems part II: Linear systems with quadratic supply
rates. Archive for rational mechanics and analysis, 45(5):352–393, 1972.
Jan C Willems and Jan W Polderman. Introduction to mathematical systems theory: a
behavioral approach, volume 26. Springer Science & Business Media, 1997.

[Wil4]

[Wil3]

[Wil2]

[WP]

[XCHZ] Huaqing Xiong, Yuejie Chi, Bin Hu, and Wei Zhang. Analytical convergence regions of
accelerated gradient descent in nonconvex optimization under Regularity Condition. Auto-
matica, 113:108715, 2020.

Email address: ogannot@berkeley.edu

