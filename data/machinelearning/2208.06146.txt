Feature-Based Time-Series Analysis in R using the
theft Package

1

Trent Henderson
The University of Sydney

Ben D. Fulcher
The University of Sydney

Abstract

Time series are measured and analyzed across the sciences. One method of quantifying
the structure of time series is by calculating a set of summary statistics or ‘features’, and
then representing a time series in terms of its properties as a feature vector. The resulting
feature space is interpretable and informative, and enables conventional statistical learning
approaches, including clustering, regression, and classiﬁcation, to be applied to time-
series datasets. Many open-source software packages for computing sets of time-series
features exist across multiple programming languages, including catch22 (22 features:
Matlab, R, Python, Julia), feasts (42 features: R), tsfeatures (63 features: R), Kats (40
features: Python), tsfresh (779 features: Python), and TSFEL (390 features: Python).
However, there are several issues: (i) a singular access point to these packages is not
currently available; (ii) to access all feature sets, users must be ﬂuent in multiple languages;
and (iii) these feature-extraction packages lack extensive accompanying methodological
pipelines for performing feature-based time-series analysis, such as applications to time-
series classiﬁcation. Here we introduce a solution to these issues in the form of a statistical
software package for R called theft: Tools for Handling Extraction of Features from Time
series. theft is a uniﬁed and extendable framework for computing features from the six
open-source time-series feature sets listed above. It also includes a suite of functions for
processing and interpreting the performance of extracted features, including extensive
data-visualization templates, low-dimensional projections, and time-series classiﬁcation
operations. With an increasing volume and complexity of large time-series datasets in
the sciences and industry, theft provides a standardized framework for comprehensively
quantifying and interpreting informative structure in time series.

Keywords: time-series analysis, time-series features, R, machine learning.

1. Introduction

Taking repeated measurements of some quantity through time, forming a time series, is com-
mon across the sciences and industry. The types of time series commonly analyzed are diverse,
ranging from signals from an electroencephalogram (West, Prado, and Krystal 1999), CO2
concentration in the atmosphere (Kodra, Chatterjee, and Ganguly 2011), light-curves from
distant stars (Barbara, Bedding, Fulcher, Murphy, and Van Reeth 2022), and the number of
clicks on a webpage (Kao, Chiu, Wang, and Ko 2021). We can ask many diﬀerent questions
about such data, for example: (i) “can we distinguish the dynamics of brain disorders from
neurotypical brain function?”; (ii) “can we classify diﬀerent geospatial regions based on their
temporal CO2 concentration”; or (iii) “can we classify new stars based on their light curves?”.

2
2
0
2

g
u
A
7
1

]
L
M

.
t
a
t
s
[

3
v
6
4
1
6
0
.
8
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
2

One approach to answering such questions is to capture properties of each time series and use
that information to train a classiﬁcation algorithm. This can be achieved by extracting from
each time series a set of interpretable summary statistics or ‘features’. Using this procedure, a
collection of univariate time series can be represented as a time series × feature matrix which
can be used as the basis for a range of conventional statistical learning procedures (Fulcher,
Little, and Jones 2013; Fulcher 2018).

The range of time-series analysis methods that can be used to deﬁne time-series features is
vast, including properties of the distribution, autocorrelation function, stationarity, entropy,
methods from the physics nonlinear time-series analysis literature (Fulcher et al. 2013). Be-
cause features are direct outputs of a mathematical operation, and are often tightly linked to
underlying theory (e.g., Fourier analysis or information theory), they can yield interpretable
understanding of patterns in time series and the processes that produce them—information
that can guide further investigation. The ﬁrst work to organize these methods from across
the interdisciplinary literature encoded thousands of diverse time-series analysis methods as
features and compared their behavior on a wide range of time series (Fulcher et al. 2013). The
resulting interdisciplinary library of thousands of time-series features has enabled new ways
of doing time-series analysis, including the ability to discover high-performing methods for a
given problem in a systematic, data-driven way through large-scale comparison (overcoming
the subjective and time-consuming task of selecting methods manually) (Fulcher and Jones
2014). This approach has been termed ‘highly comparative time-series analysis’, and has
been implemented in the Matlab software hctsa, which computes > 7700 time-series features
(Fulcher and Jones 2017). The approach of automated discovery provided by hctsa has been
applied successfully to many scientiﬁc problems, such as classifying zebra ﬁnch motifs across
diﬀerent social contexts (Paul, McLendon, Rally, Sakata, and Woolley 2021), classifying cord
pH from fetal heart-rate dynamics (Fulcher, Georgieva, Redman, and Jones 2012), and clas-
sifying changes in cortical dynamics from manipulating the ﬁring of excitatory and inhibitory
neurons (Markicevic, Fulcher, Lewis, Helmchen, Rudin, Zerbi, and Wenderoth 2020). While
hctsa is comprehensive in its coverage of time-series analysis methods, calculating all of its fea-
tures on a given dataset is computationally expensive and it requires access to the proprietary
Matlab software, limiting its broader use.
The past decade has seen the development of multiple software libraries that implement
diﬀerent sets of time-series features across a range of open-source programming languages.
Here, we focus on the following six libraries:

• catch22 (C, Matlab, R, Python, Julia) computes a representative subset of 22 features
from hctsa (Lubba, Sethi, Knaute, Schultz, Fulcher, and Jones 2019). The >7700
features in hctsa were applied to 93 time-series classiﬁcation tasks to retain the smallest
number of features that maintained high performance on these tasks while also being
minimally redundant with each other, yielding the catch22 set. catch22 was coded in C
for computational eﬃciency, with wrappers for Matlab, and packages for: R, as Rcatch22
(Henderson 2021); Julia, as Catch22.jl (Harris 2021); and Python, as pycatch22. The
construction of the catch22 feature set focused on dynamical properties, but users can
also include the mean and standard deviation of time series in addition to the regular
22 features (yielding the 24-feature set termed ‘catch24’).

• tsfeatures (R) is the most prominent package for computing time-series features in R
(Hyndman, Kang, Montero-Manso, Talagala, Wang, Yang, and O’Hara-Wild 2020).

3

The 63 features in tsfeatures include techniques commonly used by econometricians
and forecasters, such as crossing points, seasonal and trend decomposition using Loess
(STL; Cleveland, Cleveland, McRae, and Terpenning (1990)), autoregressive conditional
heteroscedasticity (ARCH) models, unit-root tests, and sliding windows. tsfeatures also
includes a small subset of features from hctsa that were previously used to organize tens
of thousands of time series in the CompEngine time-series database (Fulcher, Lubba,
Sethi, and Jones 2020).

• feasts (R) shares a subset of the same features as tsfeatures, computing a total of 42
features. However, the scope of feasts as a software package is larger: it is a vehicle to
incorporate time-series features into the software ecosystem known as the tidyverts1—a
collection of packages for time series that follow tidy data principles (Wickham 2014).
This ensures alignment with the broader and popular tidyverse collection of packages
for data wrangling, summarization, and statistical graphics (Wickham, Averick, Bryan,
Chang, McGowan, François, Grolemund, Hayes, Henry, Hester, Kuhn, Pedersen, Miller,
Bache, Müller, Ooms, Robinson, Seidel, Spinu, Takahashi, Vaughan, Wilke, Woo, and
Yutani 2019). feasts also includes functions for producing graphics, but these are largely
focused on exploring quantities of interest in econometrics, such as autocorrelation,
seasonality, and STL decomposition.

• tsfresh (Python) includes 779 features that measure properties of the autocorrelation
function, entropy, quantiles, fast Fourier transforms, and distributional characteristics
(Christ, Kempa-Liehr, and Feindt 2017). tsfresh also includes a built-in feature ﬁltering
procedure, FeatuRe Extraction based on Scalable Hypothesis tests (FRESH), that uses
a hypothesis-testing process to control the percentage of irrelevant extracted features
(Christ, Braun, Neuﬀer, and Kempa-Liehr 2018). tsfresh has been used widely to solve
time-series problems, such as anomaly detection in Internet-of-Things streaming data
(Yang, Abbasi, Mustafa, Ali, and Zhang 2021) and sensor-fault classiﬁcation (Liu, Li,
Zhang, Li, and Law 2020).

• TSFEL (Python) contains 390 features that measure properties associated with distri-
butional characteristics, the autocorrelation function, fast Fourier transforms, spectral
quantities, and wavelets (Barandas, Folgado, Fernandes, Santos, Abreu, Bota, Liu,
Schultz, and Gamboa 2020). TSFEL was initially designed to support feature extrac-
tion of inertial data—such as data produced by human wearables—for the purpose of
activity detection and rehabilitation.

• Kats (Python), developed by Facebook Research, contains a broad range of time-series
functionality, including operations for forecasting, outlier and property detection, and
feature calculation (Facebook Infrastructure Data Science 2021). The feature-calculation
module of Kats is called TSFeatures and includes 40 features (30 of which are based
on R’s tsfeatures package). Kats includes features associated with crossing points, STL
decomposition, sliding windows, autocorrelation and partial autocorrelation, and Holt–
Winters methods for detecting linear trends.

The six sets vary over several orders of magnitude in their computation time, and exhibit
large diﬀerences in both within-set feature redundancy—how correlated features are within

1https://tidyverts.org

4

a given set—and between-set feature redundancy—how correlated, on average, features are
between diﬀerent pairwise comparisons of sets (Henderson and Fulcher 2021). While each
set contains a range of features that could be used to tackle time-series analysis problems,
there are currently no guidelines for selecting an appropriate feature set for a given problem,
nor methods for combining the diﬀerent strengths of all sets. Performance on a given time-
series analysis task depends on the choice of the features that are used to represent the time
series, highlighting the importance of being able to easily compute many diﬀerent features
from across diﬀerent feature sets. Furthermore, following feature extraction, there is no
set of visualization and analysis templates for common feature-based problem classes, such
as feature-based time-series classiﬁcation (like the tools provided in hctsa Fulcher and Jones
(2017)). Here we present a solution for these challenges in the form of an open-source package
for R called theft: Tools for Handling Extraction of Features from Time series.

2. The theft package for R

theft uniﬁes the six free and open-source feature sets described in Section 1, thus overcoming
barriers in using diverse feature sets developed in diﬀerent software environments and using
diﬀerent syntax.
theft also provides an extensive analytical pipeline and statistical data
visualization templates similar to those found in hctsa for understanding feature behavior and
performance. Such pipelines and templates do not currently exist in the free and open-source
setting, making theft an invaluable tool for both computing and understanding features.
While there is some software support for computing features in a consistent setting (such
as in tsﬂex Van Der Donckt, Van Der Donckt, Deprost, and Van Hoecke (2022), which also
provides sliding window extraction capability), such software is limited to specifying the
functional form of individual time-series features rather than automatically accessing every
feature contained in diﬀerent sets.
The functionality provided by theft is summarized in Fig. 1 and broadly follows the feature-
based time-series analysis workﬂow of hctsa (Fulcher and Jones 2017). The workﬂow begins
with a time-series dataset (Fig. 1A) that is converted to a tidy format (Fig. 1B). If any of the
Python feature sets are to be used, the Python environment containing the installed software is
passed to theft using init_theft (Fig. 1C). Time-series features are then extracted (Fig. 1D).
The user can pass the extracted features into a range of statistical and visualization functions
to derive interpretable understanding of the informative patterns in their dataset (Figs 1E–J).
In this paper, we demonstrate how theft can be used to tackle a time-series classiﬁcation
problem, using the Bonn University electroencephalogram (EEG) dataset as a case study (An-
drzejak, Lehnertz, Mormann, Rieke, David, and Elger 2001). The dataset contains 500 time
series, with 100 time series each from ﬁve labeled classes: (i) awake with eyes open (labeled
‘eyesOpen’); (ii) awake with eyes closed (‘eyesClosed’); (iii) epileptogenic zone (‘epilepto-
genic’); (iv) hippocampal formation of the opposite hemisphere of the brain (‘hippocampus’);
and (v) seizure activity (‘seizure’). Note that classes (i) and (ii) are from healthy volunteers,
while classes (iii), (iv), and (v) are from a presurgical diagnosis archive. This dataset was
chosen as a demonstrative example because it has been widely studied as a time-series classiﬁ-
cation problem, and prior studies have focused on properties of the dynamics that accurately
distinguish the classes—which is well-suited to the feature-based approach. For example, an
analysis using hctsa revealed that seizure recordings are characterized most notably by higher
variance, as well as lower entropy, lower long-range scaling exponents, and many other dif-

5

Figure 1:
theft implements a workﬂow for extracting features from univariate
time series and processing and analyzing the results. First, a time-series dataset (A)
is converted into a tidy (‘long’) data frame (B) with variable names for unique identiﬁers,
time-point indices, values, and group labels (e.g., in the case of classiﬁcation problems). If
one of the feature sets selected is a Python library, the user can point R to the Python ver-
sion containing the installed software (C). One or more feature sets are then computed on
the dataset (D). A range of statistical analysis and data visualization functionality is also
implemented, including: (E) feature quality assessment (e.g., understanding the proportion
of non-NA values by feature); (F) normalized time series × feature matrix visualization; (G)
low-dimensional projections of the feature space; and (H) normalized feature × feature cor-
relation matrix visualization. Functionality is also provided for time-series classiﬁcation (a
common application of feature-based time-series analysis), including: (I) understanding the
most discriminative individual features; and (J) ﬁtting and evaluating classiﬁers with more
than one feature as input.

ferences (Fulcher et al. 2013). Further, it was also found that 172 individual features within
hctsa could distinguish between healthy EEGs and seizures using a 10-fold cross-validation
linear classiﬁer with > 95% accuracy, with eight of these features achieving > 98.75% — ex-
ceeding previous results which used operations from the discrete wavelet transform as inputs
to a support vector machine classiﬁer (Subasi and Ismail Gursoy 2010).

2.1. Extracting features

In feature-based time-series analysis, each univariate time series in a dataset is represented
as a feature vector, such that the dataset can be represented as a time series × feature data

1. Load in raw time-series dataset3. Analyze and visualize featuresHFeatureFeatureplot_feature_correlations- Visualize time-series structure- Visualize feature relationshipsEFeature% of  outputs- Understand extraction quality- Identify poor features to filterplot_quality_matrixtsfeaturesfeastscatch22tsfreshTSFELKatsGDimension 1Dimension 2plot_low_dimension- Reduce feature matrix size- Classify time-series groupsFplot_feature_matrix- Visualize extracted features- Understand similaritiesFeatureTime seriesI- Classify time-series groups- Visualize feature performanceGroupFeature valuecompute_top_featuresJ- Classify time-series groups- Visualize set/all performancefit_multi_feature_classifier2. Extract features for each unique time seriescalculate_featuresidtimevalue............group1231110.751.240.42ControlControlTreatmentClassification accuracyFeature setDCABinit_theft(If using Python feature sets)6

matrix. Any single feature set, or combination of multiple feature sets, can be computed for
a given time-series dataset with the theft function calculate_features. An example call
which extracts features from all six sets is shown in Listing 1. Note that throughout this paper
we will present the code to execute each piece of analysis, but will largely omit the extensive
amount of optional arguments for clarity. The vignette and function documentation that
comes with every download of theft contains detailed information regarding these arguments
(Henderson and Bryant 2022). The call in Listing 1 takes a tidy data frame that contains
the time-series data (tmp in this example), takes the relevant user-speciﬁed columns, and
computes the time series × feature matrix for the speciﬁed feature set(s). The output of this
function is a tidy data frame object, which in this example is stored as feature_matrix. This
function produces a data frame with ﬁve columns if the dataset is labeled (as in time-series
classiﬁcation), and four otherwise: id (unique identiﬁer for each time series), names (feature
name), values (feature value), method (feature set), and group (class label, if applicable).
This output structure ensures that, regardless of the feature set selected, the resulting object
is always of the same format and can be used with the rest of theft’s functions without manual
data reshaping.

all _ features <- calculate _ features (

data = tmp ,
id _ var = " id " ,
time _ var = " timepoint " ,
values _ var = " values " ,
group _ var = " group " ,
feature _ set = c ( " catch22 " , " feasts " , " tsfeatures " ,

" tsfresh " , " TSFEL " , " Kats " )

Listing 1

1
2
3
4
5
6
7
8

2.2. Assessing feature extraction quality

Not all features return real-valued outputs for all time series, meaning non-numeric values,
such as NaN or Inf/-Inf, or even missing outputs or errors, can be returned as a result of
feature extraction. For example, a feature which computes the variance across multiple 200-
sample time-series windows cannot be computed for time series shorter than 200 samples (as
there are not enough samples to form even a single window). For eﬀective quality control,
it is important to visualize numeric and non-numeric outputs following feature extraction,
which is implemented in theft in the plot_quality_matrix function. plot_quality_matrix
plots the proportion of values in each that are numeric, NaN/NA, or Inf/-Inf for each feature
as a bar plot. Users can extract the underlying data by indexing the plot object through
standard R conventions. There are only two arguments to plot_quality_matrix (as shown
in Listing 2): (i) data, the name of the data frame object containing the computed features;
and (ii) ignore_good_features, which if TRUE will only plot features that did not calculate
successfully for all time series. This is especially useful if the number of extracted features is
large.

1

plot _ quality _ matrix ( data = all _ features , ignore _ good _ features = FALSE )

Listing 2

2.3. Normalizing features

7

Diﬀerent features vary over very diﬀerent ranges; e.g., features that estimate p-values from a
hypothesis test vary over the unit interval, whereas a feature that computes the length of a
time series can take (often large) positive integers. These diﬀerences in scale can complicate
the visualization of feature behavior and the construction of statistical learning algorithms
involving diverse features. To overcome these limitations, a common pre-processing step
involves scaling all features. theft includes four such methods for converting a set of raw
feature values, x, to a normalized version, z:

1. z-score: zi = xi−µ

σ

,

2. linear scaling to unit interval: zi = xi−min(x)

max(x)−min(x)

,

3. sigmoid: zi = h1 + exp(− xi−µ

σ

)i−1

,

4. and outlier-robust sigmoid: zi = h1 + exp (cid:16)

− xi−median(x)
IQR(x)/1.35

(cid:17)i−1

,

where µ is the mean, σ is the standard deviation, and IQR(x) is the interquartile range of
x. All four transformations end with a linear rescaling to the unit interval. The outlier-
robust sigmoid transformation, introduced in Fulcher et al. (2013), can be helpful in nor-
malizing feature-value distributions with large outliers. Normalization is an option in each
of the core analysis and visualization functions within theft, but users can also perform
normalization outside of these functions on vectors (using normalize_feature_vector for
the catch22 feature DN_HistogramMode_5, as shown in Listing 3) or data frames (using
normalize_feature_frame as shown in Listing 4).

x <- all _ features [ all _ features == " DN _ HistogramMode _ 5 " , ]
x <- x [[ " values " ]]
xnormed <- normalize _ feature _ vector (x , method = " RobustSigmoid " )

Listing 3

normed <- normalize _ feature _ frame (
data = all _ features ,
method = " RobustSigmoid " )

Listing 4

1
2
3

1
2
3

2.4. Visualizing the feature matrix

A hallmark of large-scale feature extraction is the ability to visualize the intricate patterns of
how diﬀerent scientiﬁc algorithms behave across a time-series dataset. This can be achieved
in theft using the plot_all_features function to produce a heatmap of the time series
(rows) × feature matrix (columns) which organizes the rows and columns to help reveal
interesting patterns in the data. The plot of the combination of all six open feature sets
produced by plot_all_features for the Bonn EEG dataset is shown in Fig. 2, with the code
displayed in Listing 5. We can see some informative structure in this graphic, including many
groups of features with similar behavior on this dataset (i.e., columns with similar patterns),
indicating substantial redundancy across the joint set of features (Henderson and Fulcher
2021). The top block of 100 rows, which visually have the most distinctive properties, were

8

Figure 2: A time series × feature matrix heatmap produced by plot_all_features.
Extracted feature vectors for each time series (500) in the Bonn EEG dataset using all six
feature sets in theft (1253 features in total, after ﬁltering out 63 features with NaN values) are
represented as a heatmap. Similar features (columns) and time series (rows) are positioned
close to each other using (average) hierarchical clustering. Each tile is a normalized value for
a given time series and feature. This plot is generated by the code in Listing 5.

found to correspond to time series from the “seizure” class, indicating the ability of this large
combination of time-series features to meaningfully structure the dataset.
In plot_all_features, hierarchical clustering is used to reorder rows and columns so that
time series (rows) with similar properties are placed close to each other and features (columns)
with similar behavior across the dataset are placed close to each other—where similarity in
behavior is quantiﬁed using Euclidean distance in both cases (Day and Edelsbrunner 1984).
Default settings within plot_all_features enable users to easily generate outputs in a sin-
gle line of code, but more advanced users may seek to tweak the optional arguments. For
example, diﬀerent linkage algorithms for hierarchical clustering can be controlled supplied to
clust_method, which uses average linkage as a default. If the optional interactive argu-
ment is set to TRUE, an interactive graphic is produced, which allows the user to hover over and
click on each tile to see a time series, feature, and value summary. Finally, the is_normalised

FeatureTime series00.20.40.60.81Scaled valueData matrixargument can be used to specify whether the features have already been normalized (scaled),
otherwise the normalization method speciﬁed under method is used.

1

plot _ all _ features ( data = all _ features )

Listing 5

9

2.5. Projecting low-dimensional feature-spaces

Low-dimensional projections are a useful tool for visualizing the structure of high-dimensional
datasets in low-dimensional spaces. Here we are interested in representing a time-series
dataset in a two-dimensional projection of the high-dimensional feature space, which can re-
veal structure in the dataset, including how diﬀerent labeled classes are organized. For linear
dimensionality reduction techniques—such as principal components analysis (PCA) (Jolliﬀe
2002)—the results can be visualised in two dimensions as a scatterplot, where the principal
component (PC) that explains the most variance in the data is positioned on the horizontal
axis and the second PC on the vertical axis, and each time series is represented as a point
(colored by its group label in the case of a labeled dataset). When the structure of a dataset
in the low-dimensional feature space matches known aspects of the dataset (such as class
labels), it suggests that the combination of diverse time-series features can capture relevant
dynamical properties that diﬀer between the classes. It can also reveal new types of structure
in the dataset, like clear sub-clusters within a labeled class, that can guide new understanding
of the dataset. Low-dimensional projections of time-series features have been shown to mean-
ingfully structure time-series datasets—revealing sex and day/night diﬀerences in Drosophila
(Fulcher and Jones 2017), distinguishing types of stars based on their light curves (Barbara
et al. 2022), and categorizing sleep epochs (Decat, Walter, Koh, Sribanditmongkol, Fulcher,
Windt, Andrillon, and Tsuchiya 2022).
In theft, both a linear dimensionality reduction method—PCA—and a nonlinear dimen-
sionality reduction method—t-distributed stochastic neighbour embedding (t-SNE) (van der
Maaten and Hinton 2008)—are included. While many dimensionality-reduction algorithms
exist (Sorzano, Vargas, and Montano 2014), here we selected just these two to minimize pack-
age dependencies. Time-series datasets can be visualized in low-dimensional feature spaces
in theft using the plot_low_dimension function demonstrated in Listing 6. For t-SNE, users
can control the perplexity hyperparameter using the perplexity argument. An optional plot
argument is also available, and when set to FALSE, a data frame containing PCA or t-SNE
results is returned.

low _ dim <- plot _ low _ dimension ( data = all _ features ,

group _ var = " group " ,
method = " MinMax " ,
low _ dim _ method = "t - SNE " ,
perplexity = 15)

Listing 6

1
2
3
4
5

The low-dimensional projection plot for the Bonn EEG dataset (using t-SNE and all non-NaN
features across the six feature sets included in theft) is shown in Fig. 3 with perplexity 10,
as produced by the code in Listing 6. The low-dimensional projection (formed from > 1200
features in theft) meaningfully structures the labeled classes of the dataset. Speciﬁcally, two
of the presurgical diagnosis classes—“epileptogenic” (epileptogenic zone) and “hippocampus”

10

Figure 3: Low-dimensional projection of the Bonn EEG dataset using theft. Using
t-SNE with perplexity 10, the high-dimensional feature space of over 1200 features is projected
into two dimensions. Each point represents a time series which is colored according to its class
label. Time series that are located close in this space have similar properties, as measured by
the six feature sets in theft. This plot is generated by the code in Listing 6.

(hippocampal formation of the opposite hemisphere of the brain)—appear to exhibit con-
siderable overlap in the projected space, while the two healthy volunteer classes “eyesOpen”
(awake state with eyes open) and “eyesClosed” (awake state with eyes closed) occupy space
further away from the other classes but closer to each other. The “seizure” class occupies
a space largely separate from the other four classes in the projection, consistent with its
distinctive dynamics (Fulcher et al. 2013).

2.6. Constructing classiﬁers with multiple features

Combinations of complementary, discriminative features can often be used to construct ac-
curate time-series classiﬁers (Fulcher and Jones 2014). Drawing on computed time-series
features (that may derive from one or more existing feature sets), theft can ﬁt and evaluate
classiﬁers using the fit_multi_feature_classifier function. This allows users to evalu-

−40−20020−50−2502550Dimension 1Dimension 2epileptogeniceyesClosedeyesOpenhippocampusseizureLow dimensional projection of time series11

ate the relative performance of each feature set, of the combination of all sets, or any other
combination of features. Providing easy access to a range of classiﬁcation algorithms and
accompanying inferential tools (such as null permutation testing to obtain p-values) through
fit_multi_feature_classifier allows users to compare sets of features to better under-
stand the most accurate feature sets for a given time-series classiﬁcation problem. The code
presented in Listing 7 provides an example usage for the Bonn EEG dataset with a linear
support vector machine (SVM) classiﬁer.

mf _ results <- fit _ multi _ feature _ classifier (

data = all _ features ,
by _ set = TRUE ,
test _ method = " svmLinear " ,
use _ k _ fold = TRUE ,
num _ folds = 10)

Listing 7

1
2
3
4
5
6

The fit_multi_feature_classifier function returns a list object. If by_set is TRUE, an
plot object called FeatureSetResultsPlot is created and returned in the list which contains
a bar plot of classiﬁcation accuracy for each feature set (if by_set is set to FALSE, all features
will be used as predictors in the chosen classiﬁcation model, ignoring the set they originate
from and not returning a plot).
The modeling components of fit_multi_feature_classifier are executed through a wrap-
per for the machine-learning package caret (Kuhn 2020). This means the extensive list of clas-
siﬁcation models available in caret can be accessed from theft by specifying the method name
in the test_method argument. Prior to ﬁtting a model, fit_multi_feature_classifier
performs two operations: (i) ﬁltering out features that are constants or contain NaN/NA or
Inf/-Inf values; and (ii) re-coding of class labels into syntactically valid names for model ob-
jects in R. The resulting data is then passed into a caret train operation, where if use_k_fold
is set to TRUE, k-fold cross-validation is performed, with the number of folds set by the
num_folds argument. All operations produced by fit_multi_feature_classifier use cen-
tering and scaling preprocessing provided by caret and exclude time-series features with
near-zero variance after executing this procedure. The performance metric is speciﬁed by
use_balanced_accuracy where if FALSE, mean classiﬁcation accuracy is used and if TRUE,
balanced mean classiﬁcation accuracy is used. Balanced classiﬁcation accuracy is a useful
metric for problems where class imbalances can artiﬁcially inﬂate the accuracy metric (i.e., a
classiﬁer might assign the majority or all of the predicted class labels to the class with the
most representation in the data).
The summary FeatureSetResultsPlot graphic produced by Listing 7 for the Bonn EEG
dataset (in which all time series have been z-scored, to focus on diﬀerences in dynamical
properties between the classes) is shown in Fig. 4. On this problem, we ﬁnd that TSFEL
(with 378 features after ﬁltering) has the highest mean classiﬁcation accuracy (70.8%, SD
= 3.6% over 10 folds) and feasts has the lowest mean accuracy (60.4%, SD = 4.2%). The
combination of all > 1260 features from across every set demonstrates accuracy consistent
with the top performer (TSFEL), with slightly lower mean performance (potentially due to
over-ﬁtting in a higher-dimensional feature space).

Permutation testing

12

Figure 4: Comparison of mean classiﬁcation accuracy between feature sets in theft
for the ﬁve-class Bonn EEG classiﬁcation task. Classiﬁcation accuracy using a linear
SVM is presented for each of the six feature sets in theft as well as the combination of all
their features (‘All features’). The number of features retained for analysis after ﬁltering is
displayed in parentheses after the feature set name on the horizontal axis which has been
sorted from highest to lowest mean accuracy. Mean classiﬁcation accuracy across the same 10
cross-validation folds is displayed as colored points for each set with ±1SD error bars. This
plot is generated by the code in Listing 7.

In applications involving small datasets, or when small eﬀects are expected, it is useful to
quantify how diﬀerent the calculated classiﬁcation performance is from a null setting in which
data are classiﬁed randomly. One method for inferring test statistics is to use permutation
testing—a procedure that samples a null process many times to form a distribution against
which a value of importance (i.e., the classiﬁcation accuracy result from a model) can be
compared to estimate a p-value (Ojala and Garriga 2009). In theft, permutation testing is
implemented for evaluating classiﬁcation performance in fit_multi_feature_classifier
through the use_empirical_null argument. When set to TRUE, an object is returned in the
list called TestStatistics which contains a data frame of classiﬁcation accuracy results and
associated p-values. Regardless of the options speciﬁed to by_set and use_empirical_null,
an object called RawClassificationResults is always returned in the overall list object
created by fit_multi_feature_classifier, which contains a data frame of classiﬁcation
accuracy outputs from each model that is trained and evaluated.

A more detailed version of Listing 7 with the optional arguments speciﬁed to execute the null
testing procedure is displayed in Listing 8.

1

mf _ results <- fit _ multi _ feature _ classifier (

50%60%70%80%TSFEL (378)All features (1264)catch22 (22)tsfeatures (59)Kats (36)tsfresh (733)feasts (36)Feature setClassification accuracy (%)Number of features is indicated in parentheses. Error bars are +/− 1 times SDClassification accuracy by feature set13

2
3
4
5
6
7
8

data = all _ features ,
by _ set = TRUE ,
test _ method = " svmLinear " ,
use _ empirical _ null = TRUE ,
null _ testing _ method = " ModelFreeShuff les " ,
p _ value _ method = " gaussian " ,
num _ permutations = 10000)

Listing 8

Two methods for permutation testing are implemented: (i) model-free random shuﬄes
("ModelFreeShuffles")—from the vector of class labels in the dataset, randomly permutes
num_permutations random shuﬄes (permutations) and calculates either mean classiﬁcation
accuracy or balanced accuracy for each shuﬄed vector against the original vector of class
labels; and (ii) null model ﬁts ("NullModelFits")—ﬁts num_permutations models with the
same classiﬁer, same input data, and same k-fold cross-validation procedure as the main
classiﬁcation model, but trains the null models on randomly shuﬄed class labels as the target
variable.

The model-free procedure (which assumes a null model that produces randomized outputs
labels) is very fast, and provides a good approximation for the null distribution obtained using
randomized input labels when cross-validation is used (i.e., when all evaluation is performed
on unseen data). From the resulting null distribution, a p-value can be assigned to the main
model’s performance statistic via one of two methods: (i) "gaussian" and (ii) "empirical".
The former takes the mean and standard deviation of the null classiﬁcation accuracy values,
and evaluates the probability of the classiﬁcation accuracy result of the model ﬁt on the correct
class labels against a Gaussian distribution parameterized by this null mean and standard
deviation. The latter simply calculates the proportion of null classiﬁcation accuracy values
that are equal to or greater than the classiﬁcation accuracy result of the model ﬁt on the
correct class labels. If the null distribution is believed to be approximately Gaussian, then
an estimate of potentially small p-values can be obtained using the "gaussian" setting with
less samples rather than expending a large computing time to resolve the potential for small
p-values through permutation testing and frequencies using the "empirical" setting.
For the full Bonn EEG dataset, with 100 time series per class and strong diﬀerences between
signals, classiﬁcation accuracies are far higher than chance level (20%), and we obtain ex-
tremely small p-values, conﬁrming the low probability of obtaining such high accuracies by
chance. To more clearly demonstrate the permutation testing functionality, we analyzed a
smaller random subsample of the dataset: 14 z-scored time series each from the ‘hippocampus’
and ‘epileptogenic’ classes, and ﬁt binary classiﬁcation models using the code presented in
Listing 8. The mean classiﬁcation accuracy of feasts (64%, p = 0.07), catch22 (68%, p = 0.07),
and TSFEL (69%, p = 0.07) were not statistically signiﬁcantly diﬀerent (at p < 0.05 with
all p-values adjusted using the Holm-Bonferroni method for multiple comparisons) from the
null distribution, despite their mean accuracy values being above the chance probability of
50%. The remaining sets were statistically signiﬁcant: Kats (74%, p = 0.02), tsfresh (79%,
p = 0.007), and tsfeatures (84%, p = 0.001).

2.7. Finding and understanding informative individual features

Fitting models which use multiple features as inputs is often useful for predicting class labels.
However, users are also typically interested in understanding patterns in their dataset, such

14

as interpreting the types of time-series analysis methods that best separate diﬀerent classes,
and the relationships between these top-performing features. This can be achieved using mass
univariate statistical testing of individual features, quantifying their importance either with
conventional statistical tests (e.g., t-tests, Wilcoxon Rank Sum Tests, and Signed Rank Tests),
or with one-dimensional classiﬁcation algorithms (e.g., linear SVM, random forest classiﬁers).
theft implements the ability to identify top-performing features in the compute_top_features
function, with an example usage for the Bonn EEG dataset (using features from all six
packages) shown in Listing 9.

top _ feature _ results <- compute _ top _ features (

data = all _ features ,
num _ features = 40 ,
test _ method = " svmLinear " ,
use _ k _ fold = TRUE ,
num _ folds = 10 ,
use _ empirical _ null =
Listing 9

TRUE )

1
2
3
4
5
6
7

For two-class problems, users can access the traditional statistical tests by specifying either
test_method = "t-test", test_method = "wilcox", or test_method =
"BinomialLogistic" to ﬁt the desired statistical test instead of a caret classiﬁcation model.
compute_top_features allows users to ﬁt the same set of caret classiﬁcation models available
in fit_multi_feature_classifier in the one-dimensional space (i.e., the input to the algo-
rithm is values on a single time-series feature), which can be used for two-class or multi-class
problems (where traditional two-sample statistical tests cannot be used).
Regardless of the test_method used, compute_top_features always returns a list object
with three elements: (i) ResultsTable (a data frame of either statistical test results and
model information or classiﬁcation results and resulting null test statistics based on whether
a caret model was used or not); (ii) FeatureFeatureCorrelationPlot (pairwise feature ×
feature correlation plot with the correlation method in the cor_method argument); and (iii)
ViolinPlots (violin plots for each feature that show each time series as a point, colored and
arranged in columns by class, with class-level probability density lines around them).
The ResultsTable summary of classiﬁcation accuracy values and p-values for the top 40
features on the Bonn EEG classiﬁcation task (determined by p-value of mean classiﬁca-
tion accuracy against the empirical null) is displayed in Table 1. There is representa-
tion from all six feature sets, with the majority coming from the two largest sets:
ts-
fresh and TSFEL. Inspecting the feature names within the table can provide insight into
the types of features relevant for the classiﬁcation problem. These features inlcude prop-
erties associated with wavelets (e.g., 0_wavelet_energy_7, which measures the area un-
der the squared magnitude of the continuous wavelet transform at scale 7), variance (e.g.,
0_standard_deviation, which is the standard deviation of the signal), and autocorrela-
tion (e.g., values_autocorrelation_lag_7, which measures the value of the autocorrelation
function at lag 7).
In addition, it can also be seen that two of strongest performing fea-
tures (53.8% individual classiﬁcation accuracy) are in fact the same feature implemented
in two diﬀerent sets (SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1 from catch22 and
fluctanal_prop_r1 from tsfeatures). However, interpreting this table is challenging as the
relationships between the features are unknown—are all the 40 features behaving diﬀerently,
or are they all highly correlated to each other and essentially proxy metrics for the same

underlying time-series property? We can better understand these relationships by visualizing
the pairwise feature × feature correlation matrix.

15

Feature Feature Set Classiﬁcation Accuracy

SC_FluctAnal_2_rsrangeﬁt_50_1_logi_prop_r1
ﬂuctanal_prop_r1

catch22
tsfeatures

0_wavelet_energy_7 TSFEL
0_wavelet_standard_deviation_7 TSFEL
0_wavelet_energy_5 TSFEL
0_wavelet_standard_deviation_5 TSFEL
0_wavelet_energy_4 TSFEL
0_wavelet_standard_deviation_4 TSFEL
0_wavelet_energy_8 TSFEL
0_wavelet_standard_deviation_8 TSFEL
tsfresh
0_wavelet_energy_6 TSFEL
0_wavelet_standard_deviation_6 TSFEL
tsfresh

values_autocorrelation_lag_6

values_autocorrelation_lag_7

values_agg_linear_trend_attr_stderr_chunk_len_10_f_agg_mean tsfresh

seas_acf1 Kats

hurst Kats

values_autocorrelation_lag_5

0_wavelet_variance_6 TSFEL
0_wavelet_variance_7 TSFEL
0_spectral_distance TSFEL
tsfresh
0_root_mean_square TSFEL
0_area_under_the_curve TSFEL
0_peak_to_peak_distance TSFEL
tsfresh
values_maximum tsfresh
values_agg_linear_trend_attr_stderr_chunk_len_5_f_agg_mean tsfresh
tsfresh
values_agg_linear_trend_attr_stderr_chunk_len_10_f_agg_max
tsfresh
values_agg_linear_trend_attr_stderr_chunk_len_50_f_agg_var
0_wavelet_variance_8 TSFEL
0_max TSFEL
0_mean_absolute_deviation TSFEL

values_agg_linear_trend_attr_stderr_chunk_len_5_f_agg_max

shift_level_max
feasts
var_tiled_mean feasts
stability

tsfeatures

values_agg_linear_trend_attr_intercept_chunk_len_50_f_agg_min tsfresh
values_agg_linear_trend_attr_stderr_chunk_len_10_f_agg_min tsfresh
values_standard_deviation tsfresh
tsfresh
0_standard_deviation TSFEL

values_linear_trend_attr_stderr

53.8%
53.8%
53.8%
53.8%
52.0%
52.0%
51.4%
51.4%
51.0%
51.0%
50.6%
50.6%
50.6%
50.4%
50.4%
50.0%
50.0%
49.8%
49.6%
49.4%
48.8%
48.8%
48.8%
48.6%
48.4%
48.4%
48.4%
48.4%
48.4%
48.4%
48.4%
48.2%
48.0%
47.8%
47.8%
47.8%
47.8%
47.6%
47.6%
47.6%

p-value
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001

Table 1: Comparison of classiﬁcation accuracy and p-values between the top 40
individual features in theft for the Bonn EEG dataset. p-values were calculated by
comparing each individual feature’s model classiﬁcation accuracy against a Gaussian null
distribution parameterized by the mean and SD of model-free shuﬄed samples. These values
were generated by the code in Listing 9.

The plot of the pairwise absolute correlation coeﬃcients between the top 40 features (returned
as FeatureFeatureCorrelationPlot in Listing 9) is displayed in Fig. 5. The plot reveals
two main groups of highly correlated (|ρ| (cid:39) 0.8) features: in the bottom left and upper right
of the plot. The large cluster in the bottom left (containing features from tsfresh, TSFEL,
and feasts) contains features sensitive to signal variance. While a number of features in this
cluster have names associated with wavelets (e.g., TSFEL_0_wavelet_variance_7), the plot
reveals that on this dataset, these features exhibit similar behavior as features measuring
signal variance (e.g., TSFEL_0_standard_deviation). The second cluster, in the top right,
contains features that capture diﬀerent types of autocorrelation structure in the time series,
including linear autocorrelation coeﬃcients (e.g., TSFRESH_values_autocorrelation_lag_7
and KATS_seas_acf1). The smaller third sub-cluster (a sub-group of the autocorrelation
cluster) is comprised of two copies of the exact same feature as described earlier—
SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1 (which is contained in both catch22 and

16

Figure 5: A group of variance-sensitive features and a group of autocorrelation-
sensitive features perform the best at distinguishing between the ﬁve classes in
the Bonn EEG dataset using the absolute Spearman correlation coeﬃcient, |ρ|,
to capture feature–feature similarity. To aid the identiﬁcation of similarly performing
features, the matrix of correlation coeﬃcients between features were then organized using
hierarchical clustering (on Euclidean distances with average linkage) along rows and columns
to order the heatmap graphic. This plot was generated by the code in Listing 9.

tsfeatures). This analysis reveals that the two broad types of time-series properties that
best distinguish the classes of the Bonn EEG dataset are in fact very simple: variance and
linear autocorrelation structure. This understanding was obtained by comparing the results
across six diﬀerent open-source feature sets, aided by the ability to inspect the table of top
performing features alongside the clustered feature–feature correlation plot. However, while
the diﬀerences between classes in this case were simple, other, more complex features may
perform the strongest on other problems, or even diﬀerent pairs of classes within the ﬁve-class
dataset investigated here. Identifying when simple features perform well is important as it
can provide interpretable benchmarks for assessing relative performance gains achieved by
more complex and/or less interpretable alternative classiﬁers.

Having identiﬁed the discriminative features, it is important understand how they diﬀer

TSFRESH_values_agg_linear_trend_attr_stderr_chunk_len_10_f_agg_minTSFRESH_values_agg_linear_trend_attr_stderr_chunk_len_10_f_agg_meanTSFEL_0_wavelet_variance_8TSFEL_0_wavelet_energy_8TSFEL_0_wavelet_standard_deviation_8TSFEL_0_wavelet_energy_7TSFEL_0_wavelet_standard_deviation_7TSFEL_0_wavelet_variance_7TSFEL_0_spectral_distanceTSFEL_0_wavelet_energy_5TSFEL_0_wavelet_standard_deviation_5TSFEL_0_wavelet_energy_6TSFEL_0_wavelet_standard_deviation_6TSFEL_0_wavelet_variance_6TSFEL_0_peak_to_peak_distanceTSFEL_0_mean_absolute_deviationTSFRESH_values_linear_trend_attr_stderrTSFRESH_values_standard_deviationTSFEL_0_standard_deviationFEASTS_shift_level_maxTSFRESH_values_agg_linear_trend_attr_stderr_chunk_len_50_f_agg_varTSFRESH_values_agg_linear_trend_attr_stderr_chunk_len_10_f_agg_maxTSFRESH_values_agg_linear_trend_attr_stderr_chunk_len_5_f_agg_maxTSFRESH_values_agg_linear_trend_attr_stderr_chunk_len_5_f_agg_meanTSFRESH_values_maximumTSFEL_0_maxTSFEL_0_root_mean_squareTSFEL_0_area_under_the_curveTSFRESH_values_agg_linear_trend_attr_intercept_chunk_len_50_f_agg_minTSFEL_0_wavelet_energy_4TSFEL_0_wavelet_standard_deviation_4CATCH22_sc_fluct_anal_2_rsrangefit_50_1_logi_prop_r1TSFEATURES_fluctanal_prop_r1KATS_hurstTSFRESH_values_autocorrelation_lag_5FEASTS_var_tiled_meanTSFEATURES_stabilityTSFRESH_values_autocorrelation_lag_6TSFRESH_values_autocorrelation_lag_7KATS_seas_acf1TSFRESH_values_agg_linear_trend_attr_stderr_chunk_len_10_f_agg_minTSFRESH_values_agg_linear_trend_attr_stderr_chunk_len_10_f_agg_meanTSFEL_0_wavelet_variance_8TSFEL_0_wavelet_energy_8TSFEL_0_wavelet_standard_deviation_8TSFEL_0_wavelet_energy_7TSFEL_0_wavelet_standard_deviation_7TSFEL_0_wavelet_variance_7TSFEL_0_spectral_distanceTSFEL_0_wavelet_energy_5TSFEL_0_wavelet_standard_deviation_5TSFEL_0_wavelet_energy_6TSFEL_0_wavelet_standard_deviation_6TSFEL_0_wavelet_variance_6TSFEL_0_peak_to_peak_distanceTSFEL_0_mean_absolute_deviationTSFRESH_values_linear_trend_attr_stderrTSFRESH_values_standard_deviationTSFEL_0_standard_deviationFEASTS_shift_level_maxTSFRESH_values_agg_linear_trend_attr_stderr_chunk_len_50_f_agg_varTSFRESH_values_agg_linear_trend_attr_stderr_chunk_len_10_f_agg_maxTSFRESH_values_agg_linear_trend_attr_stderr_chunk_len_5_f_agg_maxTSFRESH_values_agg_linear_trend_attr_stderr_chunk_len_5_f_agg_meanTSFRESH_values_maximumTSFEL_0_maxTSFEL_0_root_mean_squareTSFEL_0_area_under_the_curveTSFRESH_values_agg_linear_trend_attr_intercept_chunk_len_50_f_agg_minTSFEL_0_wavelet_energy_4TSFEL_0_wavelet_standard_deviation_4CATCH22_sc_fluct_anal_2_rsrangefit_50_1_logi_prop_r1TSFEATURES_fluctanal_prop_r1KATS_hurstTSFRESH_values_autocorrelation_lag_5FEASTS_var_tiled_meanTSFEATURES_stabilityTSFRESH_values_autocorrelation_lag_6TSFRESH_values_autocorrelation_lag_7KATS_seas_acf100.20.40.60.81Absolute correlation coefficientPairwise correlation matrix of top 40 features17

Figure 6: Violin plots (on original feature value scale) of a sample of two of the
top 40 features of all six feature sets in theft for classifying Bonn EEG groups from
the compute_top_features function. Classes diﬀer in their variance and autocorrelation
properties. The features selected for this plot were determined through the code in Listing 9.

amongst the labeled classes of a dataset. This can be achieved by visualizing the distri-
bution of values for each class for each of the features.
In theft, compute_top_features
produces the object ViolinPlots, where each time series is represented as a point colored
by its class label. Example code is shown in Listing 9, which produces violin plots for all
40 top features. Here, for visual clarity, we show the violin plots for a selected feature from
the variance-sensitive cluster of features from Fig. 5: 0_standard_deviation from TSFEL
(measures the standard deviation); and a selected feature from the autocorrelation-sensitive
cluster of features: values_autocorrelation_lag_5 from tsfresh (calculates the autocorre-
lation coeﬃcient at a time lag of 5 samples). The outputs are shown in Fig. 6. Consistent with
their high classiﬁcation scores, both features are informative of class diﬀerences. The plot
shows that with regards to autocorrelation structure, we see that ‘eyesClosed’ exhibits the
lowest coeﬃcient at lag 5, while ‘hippocampus’ and ‘epileptogenic’ exhibit the highest. The
plot also highlights that ‘seizure’ time series have increased standard deviation, consistent
with prior work (Fulcher et al. 2013).

2.8. Additional functionality

In addition to the functionality demonstrated here, theft includes a collection of other func-
tions not demonstrated here, including visualizations of pairwise correlation matrices (of both
feature vectors and raw time-series values), processing of hctsa-formatted Matlab ﬁles, and
a number of functions for investigating and cleaning feature data. These have been omitted
from this article for space, but readers are encouraged to explore them in the detailed vignette
that is included in theft, and in the source code (Henderson and Bryant 2022).

2.9. Accompanying interactive web application

TSFRESH_values_autocorrelation_lag_5TSFEL_0_standard_deviationepileptogeniceyesClosedeyesOpenhippocampusseizureepileptogeniceyesClosedeyesOpenhippocampusseizure0200400600−0.50.00.5ClassValueClass discrimination for sample of top performing features18

Figure 7: Example screenshot of the interactive web application implementation
of theft. An example of the interactivity of the top feature identiﬁcation page is shown. The
adjustable parameters on the left are user-interface renders of the function arguments in the
theft package.

To provide the functionality of theft to analysts who may not be ﬂuent with R and who
also seek a fast impression of feature values and class discrimination, we have also developed
an accompanying interactive web application (Henderson 2022) written in Shiny (Chang,
Cheng, Allaire, Xie, and McPherson 2020)2. The application allows users to upload a time-
series dataset via a drag-and-drop interface, and the core functionality of theft can then be
performed in the web browser. Most of the graphical and computational functionality included
in theft is presented in the web browser and users can download a ﬁle of the computed time-
series features in a tidy format that can be read into any analysis program. All the graphics
available in theft are presented as interactive graphics by default to further enable an intuitive
exploration of the uploaded dataset. A screenshot of the informative feature identiﬁcation
page in the web application is displayed in Fig. 7.

3. Discussion

Feature-based time-series analysis is a powerful computational tool for solving problems us-
ing sequential (e.g., time-ordered) data. We have introduced theft, an open-source package
for R which implements the extraction, processing, visualization, and statistical analysis of
time-series features. The value of time-series features stems from their interpretability and
strong connection to theory that can be used to understand empirical dynamics. theft pro-
vides a uniﬁed interface to extracting features from six open-source packages—catch22, feasts,
tsfeatures, Kats, tsfresh, and TSFEL—along with a comprehensive range of analyses to lever-
age the combined contributions from all of these packages. For the ﬁrst time in the free and

2https://dynamicsandneuralsystems.shinyapps.io/timeseriesfeaturevis/

19

open-source software setting, theft provides a full workﬂow for conducting feature-based time-
series analysis, taking the analyst from feature extraction through to generating interpretable
insights about their data. We demonstrated theft on the ﬁve-class Bonn EEG time-series
classiﬁcation problem (Andrzejak et al. 2001), in which the full feature-based classiﬁcation
analysis pipeline—from feature extraction to normalization, classiﬁcation, and interpretation
of individual features—was achieved using a small number of key functions in theft. theft
can compare feature-set performance and leverage the combined set of features from all six
packages, with in-built techniques like low-dimensional projections (plot_low_dimension)
and feature–feature correlation matrices (compute_top_features) assisting in interpreting
the patterns detected. Analysts no longer need to construct complex workﬂows with mul-
tiple software libraries that were not designed to work together—theft provides a full suite
of functionality, but also provides a blueprint for advanced users to alter and adapt as their
research requires.

As new and more powerful features (and feature sets) are developed in the future, they can
be incorporated into theft to enable ongoing assessments of the types of problems they are
In addition to the analysis templates provided through functions in
best placed to solve.
theft, there is much ﬂexibility for users to adapt them or build new functionality for their
own use-cases, such as applying diﬀerent types of statistical learning algorithms on extracted
feature matrices (e.g., feature selection), or to adapt the results to diﬀerent applications such
as extrinsic regression (Tan, Bergmeir, Petitjean, and Webb 2021) or forecasting (Montero-
Manso, Athanasopoulos, Hyndman, and Talagala 2020). Future work could also aim to
reduce redundancy from across the combined features towards a new reduced feature set
that combines the most generically informative and unique features from across the available
feature-extraction packages (following the aims of the catch22 feature set, selected from a
library of > 7700 candidate features in hctsa Lubba et al. (2019)).

4. Code Availability

The source code for theft is available on GitHub at https://github.com/hendersontrent/
theft (Henderson and Bryant 2022).

References

Andrzejak RG, Lehnertz K, Mormann F, Rieke C, David P, Elger CE (2001). “Indications of
Nonlinear Deterministic and Finite-Dimensional Structures in Time Series of Brain Elec-
trical Activity: Dependence on Recording Region and Brain State.” Physical Review. E,
Statistical, Nonlinear, and Soft Matter Physics, 64(6 Pt 1), 061907. ISSN 1539-3755. doi:
10.1103/PhysRevE.64.061907.

Barandas M, Folgado D, Fernandes L, Santos S, Abreu M, Bota P, Liu H, Schultz T, Gamboa
H (2020). “TSFEL: Time Series Feature Extraction Library.” SoftwareX, 11, 100456. ISSN
2352-7110. doi:10.1016/j.softx.2020.100456.

Barbara NH, Bedding TR, Fulcher BD, Murphy SJ, Van Reeth T (2022). “Classifying Kepler
Light Curves for 12,000 A and F Stars Using Supervised Feature-Based Machine Learning.”

20

Monthly Notices of the Royal Astronomical Society, p. stac1515. ISSN 0035-8711. doi:
10.1093/mnras/stac1515.

Chang W, Cheng J, Allaire J, Xie Y, McPherson J (2020). shiny: Web Application Framework
for R. R package version 1.5.0, URL https://CRAN.R-project.org/package=shiny.

Christ M, Braun N, Neuﬀer J, Kempa-Liehr AW (2018). “Time Series FeatuRe Extraction on
Basis of Scalable Hypothesis Tests (Tsfresh – A Python Package).” Neurocomputing, 307,
72–77. ISSN 0925-2312. doi:10.1016/j.neucom.2018.03.067.

Christ M, Kempa-Liehr AW, Feindt M (2017). “Distributed and Parallel Time Series Fea-
ture Extraction for Industrial Big Data Applications.” doi:10.48550/arXiv.1610.07717.
1610.07717.

Cleveland RB, Cleveland WS, McRae JE, Terpenning I (1990). “STL: A Seasonal-Trend
Decomposition Procedure Based on Loess (with Discussion).” Journal of Oﬃcial Statistics,
6, 3–73.

Day WHE, Edelsbrunner H (1984). “Eﬃcient Algorithms for Agglomerative Hierarchical
ISSN 1432-1343. doi:10.

Clustering Methods.” Journal of Classiﬁcation, 1(1), 7–24.
1007/BF01890115.

Decat N, Walter J, Koh ZH, Sribanditmongkol P, Fulcher BD, Windt JM, Andrillon T,
Tsuchiya N (2022). “Beyond Traditional Sleep Scoring: Massive Feature Extraction and
Data-Driven Clustering of Sleep Time Series.” Sleep Medicine, 98, 39–52. ISSN 1389-9457.
doi:10.1016/j.sleep.2022.06.013.

Facebook Infrastructure Data Science (2021). “Kats.” URL https://facebookresearch.

github.io/Kats/.

Fulcher BD (2018). “Feature-Based Time-Series Analysis.” In Feature Engineering for Ma-

chine Learning and Data Analytics. CRC Press. ISBN 978-1-315-18108-0.

Fulcher BD, Georgieva AE, Redman CWG, Jones NS (2012). “Highly Comparative Fetal
Heart Rate Analysis.” In 2012 Annual International Conference of the IEEE Engineering
in Medicine and Biology Society, pp. 3135–3138.
ISSN 1558-4615. doi:10.1109/EMBC.
2012.6346629.

Fulcher BD, Jones NS (2014). “Highly Comparative Feature-Based Time-Series Classiﬁca-
tion.” IEEE Transactions on Knowledge and Data Engineering, 26(12), 3026–3037. ISSN
1041-4347, 1558-2191, 2326-3865. doi:10.1109/TKDE.2014.2316504. 1401.3531.

Fulcher BD, Jones NS (2017). “Hctsa: A Computational Framework for Automated Time-
Series Phenotyping Using Massive Feature Extraction.” Cell Systems, 5(5), 527–531.e3.
ISSN 2405-4712. doi:10.1016/j.cels.2017.10.001.

Fulcher BD, Little MA, Jones NS (2013). “Highly Comparative Time-Series Analysis: The
Empirical Structure of Time Series and Their Methods.” Journal of The Royal Society
Interface, 10(83), 20130048. doi:10.1098/rsif.2013.0048.

21

Fulcher BD, Lubba CH, Sethi SS, Jones NS (2020). “A Self-Organizing, Living Library
doi:10.1038/

Scientiﬁc Data, 7(1), 213.

ISSN 2052-4463.

of Time-Series Data.”
s41597-020-0553-0.

Harris BJ (2021). Catch22.jl. doi:https://doi.org/10.5281/zenodo.5030712. V0.2.1.

Henderson T (2021). Rcatch22: Calculation of 22 CAnonical Time-Series CHaracteristics. R

package version 0.1.12.

Henderson T (2022). “hendersontrent/theft-webtool: v0.1.1.” doi:10.5281/ZENODO.6656286.

URL https://zenodo.org/record/6656286.

Henderson T, Bryant AG (2022). “hendersontrent/theft: v0.3.9.7.” doi:10.5281/ZENODO.

6650876. URL https://zenodo.org/record/6650876.

Henderson T, Fulcher BD (2021). “An Empirical Evaluation of Time-Series Feature Sets.”
In 2021 International Conference on Data Mining Workshops (ICDMW), pp. 1032–1038.
ISSN 2375-9259. doi:10.1109/ICDMW53433.2021.00134.

Hyndman R, Kang Y, Montero-Manso P, Talagala T, Wang E, Yang Y, O’Hara-Wild M
(2020). tsfeatures: Time Series Feature Extraction. R package version 1.0.2, URL https:
//CRAN.R-project.org/package=tsfeatures.

Jolliﬀe IT (2002). Principal Component Analysis. Springer Series in Statistics. Springer-

Verlag, New York. ISBN 978-0-387-95442-4. doi:10.1007/b98835.

Kao LJ, Chiu CC, Wang HJ, Ko CY (2021). “Prediction of Remaining Time on Site for E-
Commerce Users: A SOM and Long Short-Term Memory Study.” Journal of Forecasting,
n/a(n/a). ISSN 1099-131X. doi:10.1002/for.2771.

Kodra E, Chatterjee S, Ganguly AR (2011). “Exploring Granger Causality between Global
Average Observed Time Series of Carbon Dioxide and Temperature.” Theoretical and Ap-
plied Climatology, 104(3), 325–335. ISSN 1434-4483. doi:10.1007/s00704-010-0342-3.

Kuhn M (2020). caret: Classiﬁcation and Regression Training. R package version 6.0-86,

URL https://CRAN.R-project.org/package=caret.

Liu G, Li L, Zhang L, Li Q, Law SS (2020). “Sensor Faults Classiﬁcation for SHM Systems Us-
ing Deep Learning-Based Method with Tsfresh Features.” Smart Materials and Structures,
29(7), 075005. ISSN 0964-1726. doi:10.1088/1361-665X/ab85a6.

Lubba CH, Sethi SS, Knaute P, Schultz SR, Fulcher BD, Jones NS (2019). “Catch22: CAnoni-
cal Time-series CHaracteristics.” Data Mining and Knowledge Discovery, 33(6), 1821–1852.
ISSN 1573-756X. doi:10.1007/s10618-019-00647-x.

Markicevic M, Fulcher BD, Lewis C, Helmchen F, Rudin M, Zerbi V, Wenderoth N (2020).
“Cortical Excitation:Inhibition Imbalance Causes Abnormal Brain Network Dynamics as
ISSN
Observed in Neurodevelopmental Disorders.” Cerebral Cortex, 30(9), 4922–4937.
1047-3211. doi:10.1093/cercor/bhaa084.

Montero-Manso P, Athanasopoulos G, Hyndman RJ, Talagala TS (2020).

“FFORMA:
Feature-based Forecast Model Averaging.” International Journal of Forecasting, 36(1),
86–92. ISSN 0169-2070. doi:10.1016/j.ijforecast.2019.02.011.

22

Ojala M, Garriga GC (2009). “Permutation Tests for Studying Classiﬁer Performance.” In
2009 Ninth IEEE International Conference on Data Mining, pp. 908–913. IEEE, Miami
Beach, FL, USA. ISBN 978-1-4244-5242-2. doi:10.1109/ICDM.2009.108.

Paul A, McLendon H, Rally V, Sakata JT, Woolley SC (2021). “Behavioral Discrimination
and Time-Series Phenotyping of Birdsong Performance.” PLOS Computational Biology,
17(4), e1008820. ISSN 1553-7358. doi:10.1371/journal.pcbi.1008820.

Sorzano COS, Vargas J, Montano AP (2014). “A Survey of Dimensionality Reduction Tech-

niques.” doi:10.48550/arXiv.1403.2877. 1403.2877.

Subasi A, Ismail Gursoy M (2010). “EEG Signal Classiﬁcation Using PCA, ICA, LDA and
Support Vector Machines.” Expert Systems with Applications, 37(12), 8659–8666. ISSN
0957-4174. doi:10.1016/j.eswa.2010.06.065.

Tan CW, Bergmeir C, Petitjean F, Webb GI (2021). “Time Series Extrinsic Regression.”
ISSN 1573-756X. doi:10.

Data Mining and Knowledge Discovery, 35(3), 1032–1060.
1007/s10618-021-00745-9.

Van Der Donckt J, Van Der Donckt J, Deprost E, Van Hoecke S (2022). “Tsﬂex: Flexible
Time Series Processing & Feature Extraction.” SoftwareX, 17, 100971. ISSN 2352-7110.
doi:10.1016/j.softx.2021.100971.

van der Maaten L, Hinton G (2008). “Visualizing Data Using T-SNE.” Journal of Machine

Learning Research, 9(86), 2579–2605. ISSN 1533-7928.

West M, Prado R, Krystal AD (1999). “Evaluation and Comparison of EEG Traces: Latent
Structure in Nonstationary Time Series.” Journal of the American Statistical Association,
94(446), 375–387. ISSN 0162-1459. doi:10.1080/01621459.1999.10474128.

Wickham H (2014). “Tidy Data.” Journal of Statistical Software, 59(1), 1–23. ISSN 1548-

7660. doi:10.18637/jss.v059.i10.

Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes
A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J,
Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H
(2019). “Welcome to the Tidyverse.” Journal of Open Source Software, 4(43), 1686. ISSN
2475-9066. doi:10.21105/joss.01686.

Yang Z, Abbasi IA, Mustafa EE, Ali S, Zhang M (2021). “An Anomaly Detection Algorithm
Selection Service for IoT Stream Data Based on Tsfresh Tool and Genetic Algorithm.”
Security and Communication Networks, 2021, 6677027. ISSN 1939-0114. doi:10.1155/
2021/6677027.

Aﬃliation:
Trent Henderson
Dynamics and Neural Systems Group
School of Physics

The University of Sydney
Camperdown NSW 2006, Australia
E-mail: then6675@uni.sydney.edu.au

23

