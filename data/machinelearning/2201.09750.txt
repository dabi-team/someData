Springer Nature 2021 LATEX template

2
2
0
2

y
a
M
0
1

]

G
L
.
s
c
[

2
v
0
5
7
9
0
.
1
0
2
2
:
v
i
X
r
a

Online AutoML: An adaptive AutoML
framework for online learning

Bilge Celik1*, Prabhant Singh1* and Joaquin Vanschoren1*

1Department of Computer Science & Mathematics, Eindhoven
University of Technology, Groene Loper 5, Eindhoven, 5600MB,
The Netherlands.

*Corresponding author(s). E-mail(s): B.Celik.Aydin@tue.nl;
P.Singh@tue.nl; J.Vanschoren@tue.nl;

Abstract

Automated Machine Learning (AutoML) has been used successfully in
settings where the learning task is assumed to be static. In many real-
world scenarios, however, the data distribution will evolve over time,
and it is yet to be shown whether AutoML techniques can eﬀectively
design online pipelines in dynamic environments. This study aims to
automate pipeline design for online learning while continuously adapting
to data drift. For this purpose, we design an adaptive Online Automated
Machine Learning (OAML) system, searching the complete pipeline con-
ﬁguration space of online learners, including preprocessing algorithms
and ensembling techniques. This system combines the inherent adap-
tation capabilities of online learners with the fast automated pipeline
(re)optimization capabilities of AutoML. Focusing on optimization tech-
niques that can adapt to evolving objectives, we evaluate asynchronous
genetic programming and asynchronous successive halving to optimize
these pipelines continually. We experiment on real and artiﬁcial data
streams with varying types of concept drift to test the performance and
adaptation capabilities of the proposed system. The results conﬁrm the
utility of OAML over popular online learning algorithms and underscore
the beneﬁts of continuous pipeline redesign in the presence of data drift.

Keywords: online automl, automated online learning, concept drift,
automated drift adaptation

1

 
 
 
 
 
 
Springer Nature 2021 LATEX template

2

Online AutoML: An adaptive AutoML framework for online learning

1 Introduction

Machine learning has moved beyond static environments with the rise of
streaming data sources in every corner of life. This new era of data also intro-
duced new challenges that created a need to redeﬁne old solutions. Online
or stream learning addresses the research questions arising from this trans-
formation (Gomes, Read, Bifet, Barddal, & Gama, 2019). A more dynamic
environment naturally entails change, time constaints, and uncertainty. One of
the main challenges of online learning is successful and timely adaptation to a
change in data-generating dynamics, known as concept drift (Gama, Zliobaite,
Bifet, Pechenizkiy, & Bouchachia, 2014). Machine learning algorithms are usu-
ally also bounded by limited memory and can only do a single pass over the
data samples in pursuit of this goal. Hence, online algorithms have emerged
that cope with all these challenges. However, these algorithms also come with
hyperparameters that need to be tuned to the task at hand and, since these
tasks are dynamic in nature, they may need to be retuned when concept drift
occurs. Recent studies focus on online hyperparameter tuning and algorithm
selection (Carnein, Trautmann, Bifet, & Pfahringer, 2019; Veloso, Gama, &
Malheiro, 2018). This also extends to the data preprocessing techniques that
need to be selected, tuned, and continuously adapted. The rising interest in
automated algorithm adaptation to underlying changes in the data highlights
the importance of updating both the model parameters and hyperparameters
and the need for a ﬂexibility strategy to do so (Bakirov, Fay, & Gabrys, 2021).
Automated machine learning (AutoML) has demonstrated its beneﬁts in
hyperparameter tuning and algorithm selection in numerous modelling and
optimization scenarios (Feurer et al., 2015; Gijsbers et al., 2019; Thornton,
Hutter, Hoos, & Leyton-Brown, 2013). Some of the initial attempts in carry-
ing these capabilities into the online world make use of well-known AutoML
libraries, adapted to data stream settings by re-optimizing pipelines as needed
(Celik & Vanschoren, 2021; Madrid et al., 2019). Separately, initial steps are
taken to design AutoML systems that automatically conﬁgure online learning
algorithms (Wu, Wang, Langford, Mineiro, & Rossi, 2021). However, the lat-
ter still lack fundamental AutoML features such as exploring a large space of
learning algorithms and including preprocessing steps in pipelines.

In this paper, we aim to combine the power of AutoML approaches to oper-
ate over a wide gamut of pipeline conﬁgurations with the intrinsic adaptability
of online learning algorithms. We design a search space created fully with online
learning algorithms, ensembles, and preprocessors. The search spans pipelines
with one or more steps, focusing on algorithm selection and hyperparameter
optimization simultaneously. Available optimization algorithms include but are
not limited to asynchronous evolutionary algorithm and asynchronous succes-
sive halving, due to their ability to adapt to evolving objectives. Our methods
are integrated into a modular AutoML system (Gijsbers & Vanschoren, 2021),
thus allowing further extensions of the search space, optimizers, and objective
functions. Moreover, to ensure fast adaptation to concept drift, our system
includes backup ensembles and model stores. This Online AutoML framework

Springer Nature 2021 LATEX template

Online AutoML: An adaptive AutoML framework for online learning

3

(OAML) is, to the best of our knowledge, the ﬁrst to propose a ﬂexible AutoML
system for adaptive online learning pipelines.

We evaluate our system on a range of concept drift data with diﬀerent con-
cept drift characteristics, and compare against popular adaptive learners. Our
ﬁndings indicate that optimizing complete pipelines beneﬁts fast adaptation
to concept drift and that the system eﬀectively leverages intermediate pipeline
evaluations and updates.

The remainder of the paper is organized as follows. Section 2 formulates
our core problem and its intrinsic challenges. Following that, Section 3 pro-
vides the necessary background on AutoML and Online Adaptive Learning.
Section 4 introduces existing approaches with a similar goal to ours. Our pro-
posed method, OAML, is detailed in Section 5. Section 6 describes the design
of our empirical evaluation, and we present and analyze the results in Section 7.
Section 8 concludes.

2 Problem deﬁnition

Finding the optimal conﬁguration of machine learning pipelines is one of the
main goals of AutoML research. In the context of batch learning, the problem
is described for a ﬁxed dataset D = (cid:8)(xi, yi), i = 1, .., n(cid:9). Combined algo-
rithm selection and hyperparameter optimization (CASH) (Thornton et al.,
2013) is the search over learning algorithms A and associated hyperparame-
ter spaces Λ for an optimal combination A∗
λ that maximizes the performance
of prediction over k subsets of D (e.g., k cross-validation folds). Equation 1
formalizes this optimization problem, where L is an evaluation measure, and
(cid:9) represent the training and validation sets, respec-
(cid:8)X tr, ytr
tively. The search can be extended to include preprocessing algorithms as well
as postprocessing steps, in which case A is the space of all possible pipelines.

(cid:9) and (cid:8)X val, yval

A∗

λ = argmin
∀Aj ∈A
∀λ∈Λ

1
k

k
(cid:88)

i=1

(cid:16)

L

λ, (cid:8)X i
Aj

tr, yi
tr

(cid:9), (cid:8)X i

val, yi

val

(cid:9)(cid:17)

(1)

AutoML for online learning can be described similarly to the batch learning
setting, with the exception that data has a temporal dimension and is con-
sidered to be inﬁnitely long. Some other constraints online learning imposes
are the requirement to process the data in order of arrival and restricting the
memory usage to a limited scale (Gama et al., 2014). Hence, not all data can
be stored in memory, which limits the range of possible algorithms to a set
AOL ⊂ A. In addition, evaluation happens in a prequential way, where X t is
the batch (or window) of data at time step t. As shown in Equation 2, our
objective is now to return the best online pipeline A∗
λ,t at each time step t,
where this pipeline is continually trained on the previous batch (cid:8)X t−1, yt−1
(cid:9)
and evaluated on the current one (cid:8)X t, yt

(cid:9):

Springer Nature 2021 LATEX template

4

Online AutoML: An adaptive AutoML framework for online learning

A∗

λ,t = argmin
∀Aj ∈AOL
∀λ∈Λ

(cid:16)

L

λ,t, (cid:8)X t−1, yt−1
Aj

(cid:9), (cid:8)X t, yt

(cid:9)(cid:17)

(2)

Another big challenge of online learning are unpredictable shifts in the data
distribution resulting from data generating processes, known as concept drift.
Although this shift can happen in several components of the underlying data
distribution, the most interesting and challenging case for supervised learning
is a change in the posterior probabilities of output variables, pt(y | X) at
a certain time step t. This is known as real concept drift (Equation 3) and
aﬀects the class boundary, thus requiring the learner to adapt to the change.
Since real concept drift can occur without aﬀecting the input data distribution,
p(X), it is mostly detected through changes in the predictive performance of
the learner.

∃X : pt0(y | X) (cid:54)= pt1(y | X)

(3)

Concept drift can occur in many forms with diﬀerent characteristics, where
the duration, transition and magnitude of the change are expected to have the
biggest eﬀect on a learner’s ability to adapt (Webb, Hyde, Cao, Nguyen, &
Petitjean, 2016). Therefore, in this research we will evaluate our methods on
data with both abrupt and gradual drift, and typically with high drift mag-
nitudes, which are most challenging. Abrupt drift occurs when the concept
changes suddenly and duration of this shift is smaller than a certain time
period, usually over a single sample. Gradual drift, on the other hand, is iden-
tiﬁed when the diﬀerence between concepts (i.e., the drift magnitude) over a
time period is smaller than a maximum value.

3 Background

3.1 AutoML

Diﬀerent approaches to the CASH problem in combination with a variety of
pipeline structures and search spaces lead to a vast amount of AutoML sys-
tems. Most diﬀer mainly in the optimization algorithm used to search the
pipeline conﬁguration space. Bayesian optimization (BO) (Feurer et al., 2015;
Thornton et al., 2013), one of the most widely and successfully used methods in
oﬄine settings, ﬁts a probabilistic surrogate model over the evaluated pipelines
in the search space and predicts the performance and uncertainty of unseen
conﬁgurations. Gaussian Processes are one of the most popular choices for the
surrogate model for smaller hyperparameter search spaces (Snoek, Larochelle,
& Adams, 2012) while Random Forests are often used for larger spaces (Feurer
et al., 2015). Evolutionary mwthods are another eﬀective approach for pipeline
optimization (Gijsbers & Vanschoren, 2021; Olson, Bartley, Urbanowicz, &
Moore, 2016), in which pipelines are evolved with crossover and mutations

Springer Nature 2021 LATEX template

Online AutoML: An adaptive AutoML framework for online learning

5

through genetic programming. GAMA (General Automated Machine Learn-
ing Assistant) (Gijsbers & Vanschoren, 2021) is an AutoML library that uses
asynchronous genetic programming. This approach has also shown to be eﬀec-
tive for adaptive learning with online data (Celik & Vanschoren, 2021). Hence,
we use GAMA’s genetic programming conﬁguration and search algorithms as
one of our optimization methods, as explained in more detail in section 5. The
library also includes other search algorithms such as Random Search, which
randomly samples hyperparameter conﬁgurations, and Asynchronous Succes-
sive Halving (ASHA), which speeds up random search by asynchronous early
stopping.

3.2 Online adaptive learning

What distinguishes online learning from oﬄine learning is the progress of data
availability. In online learning, data is received over time and used in arriving
order for updating the model (Gama et al., 2014). This is one of the main chal-
lenges for AutoML in online learning since existing search algorithms require
access to all data a priori. The online model can have access to previous data
partially in case the model keeps a partial memory (Maloof & Michalski, 2004).
In general, though, the assumption is that past and future training data is
unavailable to the learner and each data sample only has a single pass through
the training of the learner. Another characteristic of online learning is anytime
prediction: the trained learner can be used for prediction at any given time.

Adaptation is required when data evolves over time and results in con-
cept drift, making the previous decision model obsolete. In online adaptive
learning, the continuous cycle includes prediction, evaluation and training
steps. Whether adaptation is required or not is determined in the evalua-
tion step, where a drift detector checks whether the current model suﬀers
a negative performance change. Some well-known drift detectors keep track
of variables related to model performance (Baena-Garc´ıa et al., 2006; Gama,
Medas, Castillo, & Rodrigues, 2004), while others use a data window approach
(Bifet & Gavald`a, 2007). DDM (Drift Detection Method) records the error-rate
of the learner and ﬁts a distribution over time. It emits a drift alert when the
conﬁdence interval exceeds a certain threshold. Another benchmark method,
EDDM (Early Drift Detection Method), monitors the distance between the
errors in addition to frequency. Both methods work well with abrupt concept
drift and have low memory footprints, yet EDDM is known to be superior
in detecting gradual drift. One drawback of EDDM is the occurence of false
alarms in the early stages of learning due to the small distance between initial
errors. ADWIN (Adaptive Sliding Window), a well-known window approach,
compares the means of two subsets of data and emits a drift signal when there
is a signiﬁcant diﬀerence between those means. ADWIN requires more mem-
ory and execution runtime compared to error-rate monitoring methods, due
to the need to maintain sliding windows.

When a drift is detected at a certain time point, these methods can adapt
the model locally or globally depending on their adaptation strategy and the

Springer Nature 2021 LATEX template

6

Online AutoML: An adaptive AutoML framework for online learning

characteristics of the drift (Gama et al., 2014). Discriminant classiﬁers or naive
Bayes methods require global replacement, i.e., delete the old model and train
a completely new one. Yet, in some occasions the drift characteristics can
allow a local adaptation to restore the performance of the learner. Decision
trees allow that kind of adaptation due to their modular structure. Celik and
Vanschoren (2021) shows that drift characteristics such as the magnitude and
duration of the drift inﬂuence the correct adaptation strategy to follow. In case
the learner keeps a limited memory of past samples, a forgetting mechanism
is another critical aspect to adapt successfully in concept drift scenarios. A
straightforward and common approach is a constant rate sliding window where
data samples are erased and added at the same rate as data ﬂows. Smaller slid-
ing windows contribute to faster adaptation to the new concept, yet can lead
to unstable and low performance due to insuﬃcient training data. Dynamic
weighing of data is another possible forgetting mechanism, where the dynamic
rate can be adjusted in case of drift.

Prequential evaluation, also known as interleaved test-then-train, is the
most widely used evaluation approach, where each individual sample is ﬁrst
used to evaluate the performance and then to update the learner. This
approach can also be applied in batches of arriving samples (data chunk
evaluation). Prequential accuracy is dynamic as the performance is updated
incrementally. This contributes to the diﬃculty of using AutoML for online
learning, since most AutoML libraries use cross-validation, which can’t be
applied here. Holdouts can be used if the temporal order of the data is
respected. Although prequential evaluation scores are shown to be lower com-
pared to holdout evaluation (van Rijn, Holmes, Pfahringer, & Vanschoren,
2014), it is widely used in adaptive online learning methods.

Among online learning methods, online bagging approaches are among the
best performing ones due to the advantages ensembles bring to smooth drift
adaptation. Oza Bagging (Oza & Russell, 2001) and its updated version Lever-
age Bagging (Bifet, Holmes, & Pfahringer, 2010) simulate re-sampling in online
settings. In the former, ensemble diversity is obtained by increased random-
ization of the data, yet it also brings a heavier computational burden. Another
popular ensemble approach following a re-sampling strategy is the Adaptive
Random Forest (ARF) (Gomes et al., 2017). ARF also includes random fea-
ture re-sampling for splitting the nodes, which contributes to diversity. Each
base tree is monitored and retrained individually in case of drifts. In order
to reduce response times the in adaptation process, base trees are trained in
the background when the detector gives a warning of a possible drift. These
adaptive features make ARF one of the most well-performing online learn-
ing methods. Among the non-ensemble learners, the Hoeﬀding Adaptive Tree
(Domingos & Hulten, 2000) is one of the fastest adapting approaches, It uses
a drift detector to monitor and update individual branches.

Springer Nature 2021 LATEX template

Online AutoML: An adaptive AutoML framework for online learning

7

4 Related Work

Automating pipeline conﬁguration in data streams gained interest over the
last few years with the increase of online learning use cases. Some research
focuses on hyperparameter tuning under concept drift, yet they restrict the
optimization problem to a single learner. For the stream clustering problem,
confStream (Carnein et al., 2019) is proposed. It keeps an ensemble of sev-
eral hyperparameter conﬁgurations of a stream learning algorithm, and uses
their individual performances to train a linear regression model that predicts
which new conﬁgurations to add. The evaluation shows an improvement over
default clustering algorithm settings. SSPT (Single-pass Self Parameter Tun-
ing) (Veloso et al., 2018) is another auto-hyperparameter tuning method that
uses a heuristic search algorithm. The approach is problem agnostic yet again
is designed for a single learner and two hyperparameters.

Another line of research focuses on adapting a previously trained stream
learning algorithm in case of concept drift, by automatically selecting an appro-
priate adaptation strategy (Bakirov, Gabrys, & Fay, 2018). This approach
is extended with automated adaptations of several ensemble stream learners
(Bakirov et al., 2021). However, these adaptation strategies can only be applied
to a single model.

A step from stream learning adaptation towards AutoML is taken by
extending existing AutoML libraries with several adaptation strategies, often
based on drift detection, that allow them to retrain or re-optimize models in
online learning scenarios (Celik & Vanschoren, 2021). These adaptive AutoML
methods perform better than stream learning algorithms across many tasks
with various drift characteristics. Moreover, several AutoML techniques are
used to examine the eﬀectiveness of diﬀerent search algorithms (e.g., Bayesian
Optimization or Evolutionary techniques) in adapting to concept drift. Like-
wise, Madrid et al. (Madrid et al., 2019) extend Autosklearn with a drift
detector and two adaptation algorithms. The results corroborate the poten-
tial of AutoML for stream learning settings. However, in both studies,the
underlying search spaces contain batch learning algorithms designed for oﬄine
settings, instead of the online learning algorithms considered in this work.

ChaCha (Champion-Challengers) (Wu et al., 2021) is one of the most sim-
ilar works to our purpose as it uses an AutoML setting designed for online
learning. The search space of conﬁgurations is expanded progressively based
on the online performance of existing base learners. It also balances computa-
tional eﬀort by categorizing choices based on their learning cost and assigning
resources only to the most promising ones. ChaCha is built on the FLAML
(Wu et al., 2021) library and uses algorithms from the Vowpal Wabbit online
machine learning library. The method considers only one base learning algo-
rithm at a time and focuses on ﬁnding promising hyperparameter settings
for it. Therefore, it supports neither the optimization of complete pipelines
(with preprocessing), nor the combined algorithm selection and hyperparam-
eter optimization problem typical of AutoML. To the best of our knowledge,

Springer Nature 2021 LATEX template

8

Online AutoML: An adaptive AutoML framework for online learning

our online OAML system is the ﬁrst to propose an automated system for tun-
ing and selecting online learning algorithms to create full pipelines including
data and feature preprocessing.

5 Online AutoML (OAML)

In this paper, we introduce an automated adaptive online learning method,
OAML (Online Automated Machine Learning), that is developed to solve the
online CASH problem described in section 2. Currently it only supports clas-
siﬁcation tasks, yet it can easily be extended to other supervised machine
learning problems in the future. The model search space comprises a large
set of online learning classiﬁers, ensembles and preprocessors, all implemented
in the online learning library River (Montiel et al., 2020), which is described
further in Section 5.1.

Pipelines can include one or more of these algorithms, including data and
feature preprocessing steps. It performs an online model search that combines
algorithm selection and hyperparameter conﬁguration, similar to oﬄine ver-
sions of AutoML libraries. Up to our knowledge, this is the only automated
online learning system that includes a search space combining multiple online
algorithms as well as their hyperparameters. OAML can be constrained with
a time budget for the pipeline design and the optimized pipelines are used in
the online learning phase. A constant-rate sliding window approach is used to
manage memory in a restricted way and also provide an up-to-date training
set for pipeline search. OAML uses prequential evaluation to validate online
pipelines according to a user-selected metric. It is publicly available, integrated
into the open source AutoML library GAMA.1

5.1 Search space design

OAML comprises a wide selection of popular online learning algorithms. The
pipelines can consist of multiple steps, therefore data and feature preprocessors
are also included in the search space.

The classiﬁer algorithms in the search space mostly focus on adaptive
ensemble methods since they are shown to be the most successful for online
learning under concept drift (Gama et al., 2014). Our selection includes Oza
Bagging (Oza & Russell, 2001) with the ADWIN drift detector, Leverage Bag-
ging (Bifet et al., 2010), Ada Boosting (Oza & Russell, 2001), and Adaptive
Random Forests (Gomes et al., 2017). The base learners to be considered in the
ensemble methods are online versions of Logistic Regression, k-Nearest Neigh-
bors (KNN) Classiﬁers, Perceptrons and Hoeﬀding Trees. The base learners are
chosen without adaptive mechanisms since each ensembling method includes
a drift detector. The Adaptive Hoeﬀding Tree (HAT) (Hulten, Spencer, &
Domingos, 2001) is also added as an independent single learner due to its
eﬃciency.

1https://github.com/openml-labs/gama/tree/oaml

Springer Nature 2021 LATEX template

Online AutoML: An adaptive AutoML framework for online learning

9

Fig. 1 OAML Framework

The search space also includes online versions of preprocessing algorithms,
including data scaling and normalization, categorical variable encoding and
feature extraction. The selected methods are Adaptive Standard Scaler, Bina-
rizer, Maximum Absolute Scaler, MinMax Scaler, Normalizer, Robust Scaler,
Standard Scaler and Polynomial Feature Extender. We also aim to include
further preprocessing techniques for missing value imputation and feature
selection.2

The details of algorithms can be found in Montiel et al. (2020). A list of
the main hyperparameters for all these methods, with their defaults and value
ranges, is shown in Table 1. As mentioned earlier, there is limited research
on hyperparameter optimization in this setting, and the existing work only
scarcely explored hyperparameter grids. Hence, there is no go-to reference for
these search intervals, so we had to design these based on our own insight and
additional experimentation.

5.2 Method overview

Figure 1 shows an overview of the structure of our method, with the diﬀerent
system modules and ﬂow. A more formal description in pseudo-code is given in
Section 5.2.2. The online learning process begins with an initial AutoML search
(shown on the left of Fig. 1) using an initial batch of n0 samples (X0, ..., Xn0)
of a data stream X, y. The search algorithm S trains and evaluates pipeline

2Some preprocessors could not yet be included since their implementation in River still con-
tained bugs. We are collaboration with the River developers to resolve these and extend the search
space further.

Springer Nature 2021 LATEX template

10

Online AutoML: An adaptive AutoML framework for online learning

}
r
e
ﬁ
i
s
s
a
l
C
e
e
r
T
g
n
d
ﬀ
e
o
H

i

,

n
o
r
t
p
e
c
r
e
P

,
r
e
ﬁ
i
s
s
a
l
C
N
N
K

,

n
o
i
s
s
e
r
g
e
R
c
i
t
s
i
g
o
L
{

}
8
0
.
0

,
7
0
.
0

,
6
0
.
0

,
5
0
.
0

,
4
0
.
0

,
3
0
.
0

,
2
0
.
0
{

}
0
5

,
0
4

,
0
3

,
0
2

,
0
1

,
0
{

}
a
b
n

,

b
n

,
c
m
{

}
1
0
.
0

,
5
0
0
.
0

,
2
0
0
.
0

,
1
0
0
.
0
{

}
g
a
b
u
s

,
t
w

,
f
l
a
h

,
e
m

,
g
a
b
{

]
0
2

]
0
1

-

-

1
[

1
[

}
r
e
ﬁ
i
s
s
a
l
C
e
e
r
T
g
n
d
ﬀ
e
o
H

i

,

n
o
r
t
p
e
c
r
e
P

,
r
e
ﬁ
i
s
s
a
l
C
N
N
K

,

n
o
i
s
s
e
r
g
e
R
c
i
t
s
i
g
o
L
{

}
e
s
l
a
F

,
e
u
r
T
{

]
0
2

-

1
[

}
e
s
l
a
F

,
e
u
r
T
{

]
5
0
.
0
+

]
5
0
.
0
+

,
1

,
1

-

-

0
[

0
[

-

-

-

-

]
5
0
.
0
+

,
1
0
.
1

-

0
[

}
2
L

,
1
L
{

}
e
s
l
a
F

,
e
u
r
T
{

}
e
s
l
a
F

,
e
u
r
T
{

}
3

,
2
{

}
e
n
o
N

,
)
s
e
r
u
t
a
e
f

n
(
2
g
o
l

,
)
s
e
r
u
t
a
e
f

n
(
t
r
q
s

,
0
.
1

,
7
.
0

,
5
.
0

,
2
.
0
{

)
s
e
r
u
t
a
e
f

n
(

t
r
q
s

}
2
0
-
E
0
0
.
1

,
4
0
-
E
0
0
.
1

,
7
0
-
E
0
0
.
1

,
9
0
-
E
0
0
.
1
{

2
0
-
E
0
0
.
1

]
0
5
3

-

0
5
[

]
0
1

-

2
[

0
5

6

}
9
0
-
E
0
0
.
1

,
7
0
-
E
0
0
.
1

,
4
0
-
E
0
0
.
1

,
2
0
-
E
0
0
.
1
{

}
8
0
.
0

,
7
0
.
0

,
6
0
.
0

,
5
0
.
0

,
4
0
.
0

,
3
0
.
0

,
2
0
.
0
{

}
i
n
i
g

o
f
n

i

,
r
e
g
n

i
l
l
e
h

,
i

n

i
g
{

]
0
5
3

-

0
5
[

}
2
0
-
E
0
0
.
2

,
3
0
-
E
0
0
.
2

,
4
0
-
E
0
0
.
2
{

}
0
0
5

,
0
0
4

,
0
0
3

,
0
0
2

,
0
0
1
{

]
0
2
-
1
[

}
a
b
n

,

b
n

,
c
m
{

}
e
s
l
a
F

,
e
u
r
T
{

i

n

i
g

o
f
n

i

7
0
-
E
0
0
.
1

0
0
2

5
0
.
0

a
b
n

e
u
r
T

0
0
3

3
0
-
E
0
0
.
2

0
1

5
0
.
0

a
b
n

0

-

0
1

1

2
0
0
.
0

g
a
b

e
u
r
T

e
u
r
T

5
2
.
0

5
7
.
0

0
1

-

-

-

-

-

d
l
o
h
s
e
r
h
t
w
o
d
n
i
w
t
f
i
r
d

g
n
i
l
p
m
a
s

p
a
r
t
s
t
o
o
b

e
c
n
e
d
ﬁ
n
o
c

n
i
w
d
a

e
c
n
e
d
ﬁ
n
o
c

t
i
l
p
s

n
o
i
t
c
i
d
e
r
p

f
a
e
l

d
l
o
h
s
e
r
h
t

e
i
t

n
o
i
r
e
t
i
r
c

t
i
l
p
s

d
o
i
r
e
p

e
c
a
r
g

s
e
r
u
t
a
e
f

x
a
m

e
u
l
a
v

a
d
b
m
a
l

d
o
i
r
e
p

e
c
a
r
g

s
l
e
d
o
m
n

e
c
n
e
d
ﬁ
n
o
c

t
i
l
p
s

n
o
i
t
c
i
d
e
r
p

f
a
e
l

d
l
o
h
s
e
r
h
t

e
i
t

d
l
o
h
s
e
r
h
t

b
n

s
l
e
d
o
m
n

l
e
d
o
m

w

d
o
h
t
e
m
g
n
i
g
g
a
b

a
t
l
e
d

n
i
w
d
a

g
n
i
r
e
t
n
e
c

h
t
i
w

s
l
e
d
o
m
n

l
e
d
o
m

g
n
i
l
a
c
s

h
t
i
w

f
n
i

p
u
s

q

q

-

-

-

-

m
r
o
n

2
L

e
s
l
a
F

e
s
l
a
F

0

2

y
l
n
o

n
o
i
t
c
a
r
e
t
n
i

s
a
i
b

e
d
u
l
c
n
i

d
l
o
h
s
e
r
h
t

e
e
r
g
e
d

r
e
d
r
o

)
T
A
H
(

e
e
r
T
e
v
i
t
p
a
d
A
g
n
i
d
ﬀ
e
o
H

)
F
R
A
(

t
s
e
r
o
F
m
o
d
n
a
R
e
v
i
t
p
a
d
A

g
n
i
g
g
a
B
)
a
z
O
(
N
W
D
A

I

r
e
l
a
c
S

t
s
u
b
o
R

g
n
i
g
g
a
B
e
g
a
r
e
v
e
L

r
e
l
a
c
S

d
r
a
d
n
a
t
S

e
v
i
t
p
a
d
A

r
e
l
a
c
S

d
r
a
d
n
a
t
S

r
e
l
a
c
S

s
b
A
x
a
M

r
e
l
a
c
S

x
a
M
n
i
M

r
e
z
i
l
a
m
r
o
N

r
e
z
i
r
a
n
i
B

r
e
d
n
e
t
x
E

l
a
i
m
o
n
y
l
o
P

.

w
o
l
e
b

s
d
o
h
t
e
m
g
n
i
s
s
e
c
o
r
p
e
r
p

n
i
a
m
e
h
t

d
n
a

,

p
o
t

n
o

s
r
e
n
r
a
e
l

e
n

i
l

n
o

e
h
t

h
t
i
w

,

L
M
A
O

f
o

e
c
a
p
s

h
c
r
a
e
S

1

e
l
b
a
T

e
g
n
a
r

h
c
r
a
e
S

e
u

l
a
v

t
l
u
a
f
e
D

r
e
t
e
m
a
r
a
p
r
e
p
y
H

l
e
d
o
M

Springer Nature 2021 LATEX template

Online AutoML: An adaptive AutoML framework for online learning

11

conﬁgurations with a classiﬁcation metric Ma over the initial batch of data
within the given time budget tmax. The best-found single pipeline of the search,
P ∗
0 , is ﬁtted to the available data and the trained pipeline is passed to the
online learning module (shown on the right of Fig. 1) to be assigned as the
online model AO. From now on, data samples are assumed to arrive one by
one, hence P ∗
0 is used to predict the label for Xt as ˆyt. When the real label yt
is known to the model, the online evaluation metric Mo is updated with the
feedback.3 At this point, (yt, ˆyt) is also used to update the drift detector, ADD.
In case of a drift signal, OAML is triggered to start a new AutoML pipeline
search with the batch of the latest ns samples, where ns is the sliding window
size. This sliding window allows the search algorithm to have a restricted
memory and discard outdated samples. In order to diminish the eﬀect of drift
detector errors on the system performance, regular checkups are scheduled.
If the pipeline is not changed over M axtrain iterations, the system gives an
automatic trigger to start another OAML search.

The OAML framework allows diﬀerent adaption strategies to update the
old model after concept drift has occured. Next, we describe three methods:
Basic, Ensemble, and Model Store.

5.2.1 OAML - Basic

The adaptation strategy in OAML - Basic is global replacement, where the
old model is completely discarded and a new one is built from scratch. OAML
search replaces the previous pipeline with the new one P ∗
t as soon as possible,
and the online learning cycle begins again. In case (yt, ˆyt) does not trigger
the drift detector, (Xt, yt) is used to incrementally train P ∗
0 and the updated
pipeline predicts the new sample. OAML - Basic is expected to suit adaptation
to high and abrupt concept drift. It also has a low memory footprint since old
models are discarded and only a limited amount of data is kept in memory at
any time.

5.2.2 OAML - Ensemble

i

OAML - Ensemble follows the same steps as the basic version except for the
adaptation phase. An ensemble of the best performing k pipelines is used to
create a dynamic backup ensemble E = (cid:8)P ∗
(cid:9). Each pipeline in the ensemble
has the same weight and the predictions are aggregated equally. When a drift
occurs at time t and OAML is triggered to start a new pipeline search, the
output pipeline P ∗
is not directly used to replace the old one but instead
t
compared with the backup ensemble, Et, based on their predictive performance
over last sliding window ((Xt−ns, yt−ns ), ..., (Xt, yt)). If the backup ensemble
has a better predictive score, the current model P ∗
t−1 is replaced with Et.
Instead of discarding the newly found pipeline P ∗
t , the algorithm adds that to
the ensemble and removes the oldest pipeline in the ensemble in case its length

3The AutoML evaluation metric Ma and online metric Mo are usually the same, but could
potentially be deﬁned diﬀerently. For instance, Ma could be a cheaper approximation to speed up
the search.

Springer Nature 2021 LATEX template

12

Online AutoML: An adaptive AutoML framework for online learning

Algorithm 1 OAML - Ensemble

Inputs: n0, ns, Ma, Mo, tmax, S(), (X, y), M axtrain, k where n0 ≥ ns
Initialization: OAM LSearch ⇐ S(), E0 = {}, ADD ⇐ Drif tDetector()
0 ⇐ argmintmax,Ma OAM LSearch((X0, y0)..., (Xni, yni))

0 to E0

1: P ∗
2: append P ∗
3: i ⇐ n0 + 1
4: t ⇐ 0
5: AO ⇐ P ∗
0
6: while Xi ∈ (cid:126)X do
7:

(cid:46) Test-then-train evaluation

predict ˆyi ⇐ AO(Xi)
evaluate Mo ⇐ Mo(yi, ˆyi)
train online model AO(Xi, yi)
update ADD ⇐ Mo
if drift signal ∨ i − LastT raining ≥ M axtrain

t ⇐ t + 1
Xsliding = (Xi−ns , ..., Xi), ysliding = (yi−ns , ..., yi)
P ∗
M E
M P ∗
if M E

t ⇐ argmintmax,Ma OAM LSearch(Xsliding, ysliding)
o ⇐ evaluate Et(Xsliding, ysliding)
o ⇐ evaluate P ∗
t (Xsliding, ysliding)
o ≤ M P ∗
then
o
update AO ⇐ Et

(cid:46) Drift detection

then
(cid:46) Redesign pipelines

(cid:46) Ensemble evaluation

else

update AO ⇐ P ∗
t

end if
append P ∗
t to Et
if |Et| ≥ k then
pop ﬁrst P ∗

j from Et

end if

(cid:46) Ensemble update

8:

9:

10:

11:

12:

13:

14:

15:

16:

17:

18:

19:

20:

21:

22:

23:

24:

25:

end if
26:
27: end while

exceeds the limit k. This way, the OAML system keeps a memory of previously
learned pipelines and the global model replacement strategy is relaxed. Older
models can still partially aﬀect the future decisions with their votes in the
ensemble until they are replaced. Algorithm - 1 shows the steps of OAML -
Ensemble in pseudocode, in which performance metrics are supposed to be
minimized.

5.2.3 OAML - Model Store

In order to understand the trade-oﬀs of ensembling versus storing models based
on their online performance, OAML- Model Store is designed to keep k indi-
vidual pipelines in memory. This model store (M St) is eﬀectively a history of
the best pipelines used earlier in the data stream. Every time a new pipeline
P ∗
t arrives, each pipeline in the model store, P ∗
j ∈ M St, is evaluated with the

Springer Nature 2021 LATEX template

Online AutoML: An adaptive AutoML framework for online learning

13

last ns samples of data ((Xt−ns, yt−ns), ..., (Xt, yt)) and their performances are
compared with the new pipeline P ∗
t . The online model, AO is updated with
the best performing one among the model store pipelines and the new pipeline.
If the length of the model store is greater than k, the least performing one is
removed and the newest pipeline is added to the store. OAML - Model Store
keeps an extended memory similar to OAML - Ensemble, yet the update of
this memory is based on individual pipeline performance. Hence, data streams
with repeating concepts could beneﬁt from this strategy.

6 Experiment design

In this section, we evaluate our online AutoML system with concept drift data
streams, and analyze the results from diﬀerent perspectives in order to gain
a better understanding of the performance of OAML mechanisms. Our code,
as well as the data streams and the results of these experiments are publicly
available for reproducibility in our github repository.4

6.1 Data streams

We evaluated our method on 6 well-known data streams from the concept drift
literature that are commonly used to test online algorithms’ adaptability. 3
of these streams are from real-world settings. Others are generated with the
online machine learning library MOA (Bifet et al., 2011). Artiﬁcial data is
critical in online learning research since the existence and characteristics of
concept drift can only be certainly known in this setting. Drift is induced in
these streams by altering the parameters of the generating function at certain
points. Table 2 presents an overview of all datasets used.

6.2 OAML conﬁguration

OAML can be run with diﬀerent settings that can be adjusted based on the
application requirements or preferences. The initial batch size, n0 and sliding
window size ns determine how much data is fed into the automated pipeline
design process. In this paper, we use 5000 for both values. The AutoML bud-
get, tmax, is set to 600 seconds as aligned with the batch size. OAML allows
choosing among several online learning metrics. In our experiments, the perfor-
mance metric is set to prequential accuracy for both the pipeline search (Ma)
and online learning phase (Mo). The search algorithm, OAM LSearch, can be
Asynchronous Evolutionary Optimization, Random Search or Asynchronous
Successive Halving (ASHA). We mainly use the evolutionary search algorithm
for evaluating the performance of OAML, yet we also conduct experiments to
compare diﬀerent choices for the search algorithm. The drift detection algo-
rithm is set to EDDM due to its precision in detecting both gradual and abrupt
drift, as explained in Section 3.2. In order to decrease our dependency on the

4https://github.com/openml-labs/gama/tree/oaml

Springer Nature 2021 LATEX template

14

Online AutoML: An adaptive AutoML framework for online learning

drift detector, the alternative trigger for pipeline search, M axtrain is set to
50000 samples, considering size of the data streams.

6.3 Baselines and state of the art

We compare our method against the most competitive alternative techniques
in this area. First, we compare against Leverage Bagging (Bifet et al., 2010),
which has shown to outperform many other online learning techniques in the
literature. We also include the Hoeﬀding Adaptive Tree (Hulten et al., 2001)
as one of the strongest non-ensembling techniques. Finally, we also compare
against the state-of-the-art AutoML library for online learning, ChaCha (Wu
et al., 2021). Even though it does not construct entire pipelines, and includes
a much smaller model search space than OAML, it should be very competitive
on the datasets in this study since these datasets don’t require signiﬁcant
preprocessing.

7 Results

Here we present the results of our experiments. We ﬁrst compare the diﬀerent
versions of our method with each other and with the baselines described above,
on both real-world and synthetic datasets. Next, we analyse which pipelines are
actually generated by OAML, which components they contain, and whether
the actively used pipelines come directly from the AutoML phase, or from
the ensemble or model store. Finally, we also explore which AutoML search
algorithms perform best for the diﬀerent types of concept drift.

Table 2 Overview of the data streams used in our experiments1

Data stream

Samples Features Data generation

Electricity (Har-
ries, 1999)

45312

7

Airlines (Bifet et
al., 2011)

539383

9

Vehicle (Duarte
& Hu, 2004)
SEA
Abrupt
(Street & Kim,
2001)

HYPERPLANE
Gradual (Hulten
et al., 2001)

SEA
Mixed
(Street & Kim,
2001)

98528

100

500000

3

500000

10

500000

3

A time series electricity price data from the Australian New South
Wales market. The prices are volatile and change with demand and
supply every ﬁve minutes. The class shows the price direction per day
average.
A time series data with each sample representing a ﬂight with its
schedule information.The class shows whether the ﬂight arrived on
time. Flight schedule changes daily or weekly.
Sensor data from a wireless sensor network for moving vehicles. The
class divides the vehicles into categories.
Data generated with Streaming Ensemble Algorithm (SEA). Abrupt
drift is introduced at the middle point by shifting from one classiﬁca-
tion function to the other. The drift window is set to 1 and 10% label
noise is added. Drift magnitude is set to high by switching between
most diﬀerent functions.
Data generated with Rotating Hyperplane Algorithm. Drift is added
by shifting the orientation and position of the hyperplane. This shift
creates a gradual drift by setting the window size to 100000. Data
includes 5% label noise.
Data generated with Streaming Ensemble Algorithm (SEA). Abrupt
drift is introduced the same as SEA-Abrupt data. In addition, gradual
drift is added before and after abrupt drift with window of 100000
samples. Data includes 5% label noise.

1Source: Search www.openml.org for datasets tagged ‘concept drift‘.

Springer Nature 2021 LATEX template

Online AutoML: An adaptive AutoML framework for online learning

15

7.1 OAML experiments with real-world data

Evaluating OAML’s capability to handle real-world challenges is critical to see
its practical utility. The results on the real data streams are shown in Figures 2,
3 and 4. Each line plots the prequential accuracy of a diﬀerent algorithm over
the entire stream. The markers on the plot lines indicate drift points, i.e. that
the drift detector triggered an alarm at that point in the stream.

For the Electricity data stream (Figure 2), drift is detected often due to the
quickly changing nature of data from day to day. Leveraging Bagging performs
very well here, although it clearly struggles in the other streams. Note that
we ran Leveraging Bagging with its default conﬁguration on all data streams.
It is likely that optimizing it to each stream individually would yield better
results. In fact, as shown in Section 7.3, OAML does exactly this: it often
uses a (tuned) Leveraging Bagging pipeline, while switching to HAT in other
parts of the stream. This underlines that, not surprisingly, the AutoML tuning
typically yields a signiﬁcant improvement over untuned algorithms, and that
OAML manages to bring these beneﬁts to dynamic environments.5

After a couple of initial iterations, OAML with either an ensemble or
model store outperform the remaining methods. The Model Store strategy may
beneﬁt from cyclic eﬀects in this data stream. OAML - Ensemble performs
best throughout the airlines (Figure 3) and vehicle (Figure 4) data streams,
although it is tied with ChaCha on the latter, which seems to have very little
or very gradual concept drift.

Overall, OAML handles concept drift complexities that are sourced from
diﬀerent data generating environments quite well, especially with the backup
ensemble strategy.

7.2 OAML experiments with artiﬁcial data

Next, we evaluate the adaptability of the OAML framework on data streams
with artiﬁcially controlled drifts, leading to both abrupt and gradual shifts in
the underlying concepts. Figures 5-a to 5-c plot the results of data streams
with gradual, abrupt and mixed drift, respectively. As explained in Table 2,
each drift is created with a high magnitude to see their eﬀects more clearly.
For SEA - High Abrupt Drift data stream (5-a), OAML - Ensemble and HAT
exhibit similar accuracy levels, followed closely by ChaCha, with almost no
drop in performance at the middle drift point. This shows the fast adapta-
tion capability of OAML since this SEA has a sudden and signiﬁcant concept
change. OAML - Basic, Model Store and Leverage Bagging cannot reach that
level of performance.

For Hyperplane - High Gradual Drift data, ChaCha performs best, sug-
gesting that its model search technique (quite diﬀerent from the evolutionary
approach used here by OAML) seems to perform well under gradual drift. This
suggests that it would be interesting to integrate it in OAML as well. OAML

5The fact that Leveraging Bagging outperforms OAML on Electricity is likely due to the rapid

cyclical concept drift. OAML likely requires a smaller window size to better adapt to it.

Springer Nature 2021 LATEX template

16

Online AutoML: An adaptive AutoML framework for online learning

Fig. 2 Prequential performance for Electricity data stream

Fig. 3 Prequential performance for Airlines data stream

Fig. 4 Prequential performance for Vehicle data stream

Springer Nature 2021 LATEX template

Online AutoML: An adaptive AutoML framework for online learning

17

(a)

(b)

(c)

Fig. 5 Prequential performance for artiﬁcial data streams: (a) SEA - High abrupt drift (b)
HYPERPLANE - High gradual drift (c) SEA - High mixed drift

- Model Store outperforms most other methods, showing a signiﬁcant capabil-
ity to adapt fast when drift is introduced slowly. Since also OAML-Ensemble
catches up but OAML-Basic does not, keeping a certain amount of memory
seems to be work better under gradual drift.

Figure 5-c shows the results of SEA - High Mixed Drift, which is designed
to combine the challenges of both drift types and identify the approach that
handles that the best. In this case, although quite close to HAT, OAML -
Ensemble perform best across the whole data stream. It can also be seen that
OAML - Model Store ﬁrst suﬀers, but recovers quite well in the second half of
the stream with an performance increasing with every concept drift detected.
Overall, we see that, again, OAML - Ensemble adapts to diﬀerent types of
drift consistently.

Springer Nature 2021 LATEX template

18

Online AutoML: An adaptive AutoML framework for online learning

Fig. 6 Model update switches for OAML - Ensemble and Model Store

7.3 Pipeline analysis

In this section, we analyze the pipelines designed and update while running
OAML.

First, we analyze whether the actively used pipeline comes directly from
the AutoML optimizer, or whether it is recovered from the Model Store or
the backup Ensemble. OAML can decide to switch between them according
to what seems best. Figure 6 shows the switch points between these models
throughout the data streams Airlines, Hyperplane-Gradual and SEA-Mixed.
Since OAML starts with a pipeline created by the AutoML Model, all lines
start as green. OAML-Ensemble tends to switch quickly to the ensemble model,
except for Hyperplane-Gradual, where the ensemble is occasionally replaced
by a new AutoML model. The same holds for OAML-Model Store, although
here it is the Airlines data stream where new AutoML models are frequently

Springer Nature 2021 LATEX template

Online AutoML: An adaptive AutoML framework for online learning

19

Fig. 7 Models used by OAML - Basic throughout streams

injected. For SEA-Mixed Drift, we see that the sudden recovery of OAML-
Model Store, previously seen in Figure 5-c, is due to a switch from the old
AutoML model to the Model Store.

Gradual drift leads to more switches for both versions than the Mixed drift
setting where drift occurs with varying speeds. In that case, OAML keeps using
the Ensemble or Model Store options which handle these variations better.
This also shows the beneﬁt of pipeline redesign since the models only switch
to AutoML when the newly redesigned pipeline is better than the Ensemble
or all the pipelines in the Model Store.

Looking deeper into the pipeline optimization phase, we examine exactly
which models are used throughout the online learning process. Figure 7 shows
how the used classiﬁer switches throughout the stream when using OAML-
Basic, with the retraining points marked in between.

Springer Nature 2021 LATEX template

20

Online AutoML: An adaptive AutoML framework for online learning

Fig. 8 Performance comparison of search algorithms Random Search, ASHA and AsyncEA

It can be seen that each data stream experiences several model switches,
and that the model used can be an online ensemble or single online learner.
Although ensemble learners are more dominant, the Hoeﬀding Adaptive Tree
(HAT) is also used in each data stream at several points. For Hyperplane-
Gradual data, changes between models are relatively slow, which reﬂects the
gradual drift eﬀect on algorithm selection. With SEA-Mixed stream, we also see
quicker jumps at the abrupt drift points in the middle of the stream. This is the
phase where OAML tries to ﬁnd a ﬁtting model to the new concept after a quick
change. When Figure 7 shows the same color line segments before and after a
retraining point, this means that its hyperparameters were retuned instead of
being replaced with a new model. This can be observed in all three data streams
with the HAT or ARF classiﬁers. Overall, pipeline analysis shows that both
hyperparameter tuning and algorithm selection are used interchangeably by
OAML, indicating that pipeline redesign leads to a better performing pipelines.

7.4 Search Algorithm Eﬀect

In order to understand how the choice of search algorithm impacts drift adapta-
tion in OAML, we experimented with random search, asynchronous successive
halving (ASHA) and evolutionary algorithm (AsyncEA) on artiﬁcial data
streams with diﬀerent drift types. The results are shown in Figure 8. In the
ﬁgure, each color represents a data stream and each line type a diﬀerent search
algorithm.

For SEA generated data, ASHA performs slightly better compared to oth-
ers (red dotted line), especially in the beginning of the stream. This could be
due to the successive halving strategy working well with quick adaptation to
abrupt drifts present in these data streams. ASHA will evaluate more pipeline
randomly but quickly, while the evolutionary approach may need more itera-
tions to start evolving good pipelines. On the other hand, ASHA performed less
well on Hyperplane-Gradual, where more continuity is needed in the pipelines
to follow the gradual change, and hence evolutionary search algorithm adapts
better (green solid line plot). Overall, it can be observed that each algorithm

Springer Nature 2021 LATEX template

Online AutoML: An adaptive AutoML framework for online learning

21

adapts quite well without a drastic drop in performance. This is aligned with
previous ﬁndings (Celik & Vanschoren, 2021) that although some search algo-
rithms ﬁt better to speciﬁc drift types with diﬀerences in computational cost,
search algorithm selection doesn’t greatly aﬀect the adaptation capability as
much as the other algorithm design choices in online learning pipeline search.

8 Conclusion

We introduced a novel framework that enables AutoML methods to be applied
eﬀectively in dynamic environments with evolving data streams. It automati-
cally searches for optimal pipelines that can contain preprocessing techniques
and that exclusively use online learning algorithms which adapt to grad-
ual changes in the data. It also detects concept drift and can automatically
redesign or retune the pipelines when needed. As a result, it addresses both
the traditional challenges of AutoML, such as combined algorithm selection
and hyperparameter optimization under time constraints, as well as new chal-
lenges particular to real-world data streams, such as concept drift, memory
restrictions, and forgetting mechanisms.

We deﬁned a rich pipeline search space that includes many online learning
algorithms, ensembles, data and feature preprocessing steps. Our framework
includes three strategies to update the currently used pipelines after drift is
detected: Basic, which ﬁts a new pipeline every time drift is detected and
replaces the old one; Model Store, which keeps a memory of the best performing
prior pipelines and selects the best current one; and Ensemble, which makes a
backup ensemble from the best prior pipelines.

We evaluate the developed method on both real-world and artiﬁcial data
streams with concept drift and compare its performance with several baselines
and state-of-the-art systems. The results show that OAML-Ensemble performs
consistently well on data with various kinds of concept drift, while OAML-
Model Store performs best when there are cyclic/seasonal processes underlying
the data stream. We also examine how OAML behaves by tracking the under-
lying changes in the generated pipelines through time. Our results show that
there is no one online algorithm that is optimal across the life cycle of a data
stream. As the data changes over time, online learners in these pipelines are
either replaced, or their hyperparameters are re-optimized to adapt to the
changing data. This demonstrates the beneﬁts of automating both algorithm
selection and hyperparameter tuning for online learning, unlike several previ-
ous studies that focus only on either one of these. In all, we believe that this
work opens up interesting avenues for further research.

Springer Nature 2021 LATEX template

22

Online AutoML: An adaptive AutoML framework for online learning

Acknowledgments. We would like to give special thanks to Pieter Gijs-
bers for his help in integrating OAML into the GAMA library. This research
was supported by the Dutch Foundation for Scientiﬁc Research (NWO) under
the DACCOMPLI grant, and by the European Commission’s H2020 program
under the StairwAI grant. It was also partially supported by TAILOR, a
project funded by EU Horizon 2020 research and innovation programme under
GA No 952215.

Declarations

• Funding: The research is funded under the NWO project DACCOMPLI.
• Availability of data and materials and code: All our data, materials and
code are available publicly at https://github.com/openml-labs/gama/
tree/OAML.

• Financial or non-ﬁnancial interests: Not applicable.
• Ethics approval: Not applicable.
• Consent to participate: Not applicable.
• Welfare of animals: Not applicable
• Authors’ contributions: The authors contributed equally to the research

and publication.

References

Baena-Garc´ıa, M., Campo- ´Avila, J., Fidalgo-Merino, R., Bifet, A., Gavald, R.,
Morales-Bueno, R. (2006). Early drift detection method. Fourth inter-
national workshop on knowledge discovery from data streams (Vol. 6, pp.
77–86).

Bakirov, R., Fay, D., Gabrys, B. (2021). Automated adaptation strategies for

stream learning. Machine Learning, 110 , 1429–1462.

Bakirov, R., Gabrys, B., Fay, D. (2018). Generic adaptation strategies for
automated machine learning. CoRR, abs/1812.10793 . https://arxiv
.org/abs/1812.10793

Bifet, A., & Gavald`a, R. (2007). Learning from time-changing data with adap-
tive windowing. In Proceedings of the 2007 siam international conference
on data mining (sdm) (p. 443-448).

Bifet, A., Holmes, G., Pfahringer, B. (2010). Leveraging bagging for evolving
data streams. J.L. Balc´azar, F. Bonchi, A. Gionis, & M. Sebag (Eds.),
Machine learning and knowledge discovery in databases (pp. 135–150).
Berlin, Heidelberg: Springer Berlin Heidelberg.

Springer Nature 2021 LATEX template

Online AutoML: An adaptive AutoML framework for online learning

23

Bifet, A., Holmes, G., Pfahringer, B., Read, J., Kranen, P., Kremer, H., . . .
Seidl, T. (2011). MOA: A real-time analytics open source framework.
Lecture notes in computer science (Vol. 6913, pp. 617–620).

Carnein, M., Trautmann, H., Bifet, A., Pfahringer, B.

(2019). Towards
automated conﬁguration of stream clustering algorithms. European con-
ference on machine learning and knowledge discovery in databases (pp.
137–143).

Celik, B., & Vanschoren, J.

machine learning on evolving data.
Analysis and Machine Intelligence, 43 (9), 3067-3078.

(2021). Adaptation strategies for automated
IEEE Transactions on Pattern

Domingos, P., & Hulten, G. (2000). Mining high-speed data streams. Pro-
ceedings of the sixth acm sigkdd international conference on knowledge
discovery and data mining (p. 71–80). 10.1145/347090.347107

Duarte, M., & Hu, Y.H. (2004). Vehicle classiﬁcation in distributed sensor
networks. Journal of Parallel and Distributed Computing, 64 , 826-838.

10.1016/j.jpdc.2004.03.020

Feurer, M., Klein, A., Eggensperger, K., Springenberg, J.T., Blum, M., Hutter,
F. (2015). Eﬃcient and robust automated machine learning. Proceedings
of the 28th international conference on neural information processing
systems - volume 2 (p. 2755–2763). MIT Press.

Gama, J., Medas, P., Castillo, G., Rodrigues, P. (2004). Learning with drift
detection. In sbia brazilian symposium on artiﬁcial intelligence (pp. 286–
295). Springer Verlag.

Gama, J., Zliobaite, I., Bifet, A., Pechenizkiy, M., Bouchachia, A. (2014). A
survey on concept drift adaptation. ACM Compututer Surveys, 46 (4),
44:1–44:37.

Gijsbers, P., LeDell, E., Poirier, S., Thomas, J., Bischl, B., Vanschoren,
arXiv preprint
J.
arXiv:1907.00909 [cs.LG] . (Accepted at AutoML Workshop at ICML
2019)

(2019). An open source automl benchmark.

Gijsbers, P., & Vanschoren, J. (2021). Gama: A general automated machine
learning assistant. Lecture notes in computer science (including subseries
lecture notes in artiﬁcial intelligence and lecture notes in bioinformatics)
(Vol. 12461 LNAI, p. 560-564).

Springer Nature 2021 LATEX template

24

Online AutoML: An adaptive AutoML framework for online learning

Gomes, H.M., Bifet, A., Read, J., Barddal, J.P., Enembreck, F., Pfharinger,
B., . . . Abdessalem, T. (2017). Adaptive random forests for evolving
data stream classiﬁcation. Machine Learning, 106 (9), 1469-1495.

10.1007/s10994-017-5642-8

Gomes, H.M., Read, J., Bifet, A., Barddal, J.P., Gama, J.a.

(2019).
Machine learning for streaming data: State of the art, challenges, and
opportunities. SIGKDD Explor. Newsl., 21 (2), 6–22.

Harries, M. (1999). Splice-2 comparative evaluation: Electricity pricing (Tech.
Rep. No. UNSW-CSE-TR9905). The University of South Wales.

Hulten, G., Spencer, L., Domingos, P.

(2001). Mining time-changing data
streams. Proceedings of the 7th acm sigkdd international conference
on knowledge discovery and data mining (p. 97–106). 10.1145/502512
.502529

Madrid, J.G., Escalante, H.J., Morales, E.F., Tu, W., Yu, Y., Sun-Hosoya, L.,
. . . Sebag, M. (2019). Towards AutoML in the presence of drift: ﬁrst
results. CoRR, abs/1907.10772 .

Maloof, M., & Michalski, R. (2004). Incremental learning with partial instance

memory. Artiﬁcial Intelligence, 154 , 95-126.

Montiel, J., Halford, M., Mastelini, S.M., Bolmier, G., Sourty, R., Vaysse, R.,
(2020). River: machine learning for streaming data in

. . . Bifet, A.
python.

Olson, R.S., Bartley, N., Urbanowicz, R.J., Moore, J.H. (2016). Evaluation
of a tree-based pipeline optimization tool for automating data science.
Proceedings of the genetic and evolutionary computation conference 2016
(p. 485–492). 10.1145/2908812.2908918

Oza, N.C., & Russell, S.

(2001). Experimental comparisons of online and
batch versions of bagging and boosting. Proceedings of the seventh acm
sigkdd international conference on knowledge discovery and data mining
(p. 359–364). 10.1145/502512.502565

Snoek, J., Larochelle, H., Adams, R.P. (2012). Practical bayesian optimiza-
tion of machine learning algorithms. Advances in neural information
processing systems 25 (pp. 2951–2959).

Springer Nature 2021 LATEX template

Online AutoML: An adaptive AutoML framework for online learning

25

Street, W., & Kim, Y. (2001). A streaming ensemble algorithm sea for large-
scale classiﬁcation. 7th acm sigkdd int. conf. on knowledge discovery and
data mining (p. 377-382).

Thornton, C., Hutter, F., Hoos, H.H., Leyton-Brown, K. (2013). Auto-WEKA:
Combined selection and hyperparameter optimization of classiﬁcation
algorithms.
19th acm sigkdd international conference on knowledge
discovery and data mining (p. 847–855). 10.1145/2487575.2487629

van Rijn, J.N., Holmes, G., Pfahringer, B., Vanschoren, J. (2014). Algorithm
selection on data streams. Discovery science (p. 325-336). Springer.

Veloso, B., Gama, J., Malheiro, B. (2018). Self hyper-parameter tuning for data

streams. International conference on discovery science (pp. 241–255).

Webb, G.I., Hyde, R., Cao, H., Nguyen, H.L., Petitjean, F. (2016). Charac-
terizing concept drift. Data Mining and Knowledge Discovery, 30 (4),
964–994.

Wu, Q., Wang, C., Langford, J., Mineiro, P., Rossi, M.

(2021, July).
Chacha for online automl. 2021 international conference on machine
learning (icml 2021). Retrieved from https://www.microsoft.com/en-
us/research/publication/chacha-for-online-automl/

