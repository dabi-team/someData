On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

Yihan Wang 1 Huan Zhang 2 Hongge Chen 3 Duane Boning 3 Cho-Jui Hsieh 2

0
2
0
2

p
e
S
9
2

]

G
L
.
s
c
[

2
v
5
5
7
8
0
.
8
0
0
2
:
v
i
X
r
a

Abstract
Recent papers have demonstrated that ensemble
stumps and trees could be vulnerable to small in-
put perturbations, so robustness veriﬁcation and
defense for those models have become an impor-
tant research problem. However, due to the struc-
ture of decision trees, where each node makes
decision purely based on one feature value, all
the previous works only consider the (cid:96)∞ norm
perturbation. To study robustness with respect to
a general (cid:96)p norm perturbation, one has to con-
sider the correlation between perturbations on dif-
ferent features, which has not been handled by
previous algorithms. In this paper, we study the
problem of robustness veriﬁcation and certiﬁed
defense with respect to general (cid:96)p norm perturba-
tions for ensemble decision stumps and trees. For
robustness veriﬁcation of ensemble stumps, we
prove that complete veriﬁcation is NP-complete
for p ∈ (0, ∞) while polynomial time algorithms
exist for p = 0 or ∞. For p ∈ (0, ∞) we develop
an efﬁcient dynamic programming based algo-
rithm for sound veriﬁcation of ensemble stumps.
For ensemble trees, we generalize the previous
multi-level robustness veriﬁcation algorithm to (cid:96)p
norm. We demonstrate the ﬁrst certiﬁed defense
method for training ensemble stumps and trees
with respect to (cid:96)p norm perturbations, and verify
its effectiveness empirically on real datasets.

1. Introduction

It has been observed that small human-imperceptible per-
turbations can mislead a well-trained deep neural net-
work (Goodfellow et al., 2015; Szegedy et al., 2013), which
leads to extensive studies on robustness of deep neural net-
work models. In addition to strong attack methods that can
ﬁnd adversarial perturbations in both white-box (Carlini &
Wagner, 2017; Madry et al., 2018; Chen et al., 2018; Zhang
et al., 2019a; Xu et al., 2019) and black-box settings (Chen

1 Tsinghua University, Beijing, China 2UCLA, Los Angeles, USA
3MIT, Cambridge, USA. Correspondence to: Yihan Wang <wangy-
ihan617@gmail.com>.
Proceedings of the 37 th International Conference on Machine
Learning, Online, PMLR 119, 2020. Copyright 2020 by the
author(s).

et al., 2017; Ilyas et al., 2018; Brendel et al., 2018; Cheng
et al., 2019a; 2020), various algorithms have been proposed
for formal robustness veriﬁcation (Katz et al., 2017; Gehr
et al., 2018; Zhang et al., 2018; Weng et al., 2018; Zhang
et al., 2019d; Wang et al., 2018b) and improving the robust-
ness of neural networks (Madry et al., 2018; Wong & Kolter,
2018; Wong et al., 2018; Zhang et al., 2019c;b).

In this paper, we consider the robustness of ensemble deci-
sion trees and stumps. Although tree based model ensem-
bles, including Gradient Boosting Trees (GBDT) (Friedman,
2001) and random forest, have been widely used in prac-
tice, their robustness properties have not been fully under-
stood. Recently, Cheng et al. (2019a); Chen et al. (2019a);
Kantchelian et al. (2016) showed that adversarial exam-
ples also exist in ensemble trees, and several recent works
considered the problem of robustness veriﬁcation (Chen
et al., 2019b; Ranzato & Zanella, 2019; 2020; Törnblom
& Nadjm-Tehrani, 2019) and adversarial defense (Chen
et al., 2019a; Andriushchenko & Hein, 2019; Chen et al.,
2019e; Calzavara et al., 2019; 2020; Chen et al., 2019d)
for ensemble trees and stumps. However, most of these
works focus on evaluating and enhancing the robustness
for (cid:96)∞ norm perturbations, while (cid:96)p norm perturbations
with p < ∞ were not considered. Since each node or each
stump makes decision by looking at only a single feature,
the perturbations are independent across features in (cid:96)∞ ro-
bustness veriﬁcation and defense for tree ensembles, which
makes the problem intrinsically simpler than the other (cid:96)p
norm cases with p < ∞. In fact, we will show that in some
cases verifying (cid:96)p norm and (cid:96)∞ norm belong to different
complexity classes – verifying (cid:96)p norm robustness of an
ensemble decision stump is NP-complete for p ∈ (0, ∞)
while polynomial time algorithms exist for p = 0, ∞.

In practice, robustness on a single (cid:96)∞ norm is not sufﬁcient
– it has been demonstrated that an (cid:96)∞ robust model can
still be vulnerable to invisible adversarial perturbations in
other (cid:96)p norms (Schott et al., 2018; Tramèr & Boneh, 2019).
Additionally, there are cases where an (cid:96)p norm threat model
is more suitable than (cid:96)∞ norm. For instance, when the
perturbation can be made only to few features, it should
be modeled as an (cid:96)0 norm perturbation. Thus, it is crucial
to have robustness veriﬁcation and defense algorithms that
can work for general (cid:96)p norms. In this paper, We give a
comprehensive study of this problem for tree based models.

 
 
 
 
 
 
On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

Table 1. Summary of the algorithms and their complexity for robustness veriﬁcation of ensemble trees and stumps. Blue cells are the
contribution of this paper.

Single Tree

Ensemble Stump

Ensemble Tree

Veriﬁcation method
complete
complete
incomplete
complete
incomplete

(cid:96)∞
Linear (Chen et al., 2019b)
Polynomial (Andriushchenko & Hein, 2019)
Not needed

(cid:96)0
Linear (Sec 3.1)
Linearithmic (Sec 3.2)
Not needed

(cid:96)p, p ∈ (0, ∞)
Linear (Sec 3.1)
NP-complete (Sec 3.2)
Approximate Knapsack (Sec 3.2)

Multi-level (Chen et al., 2019b)

Extended Multi-level (Sec 3.3)

NP-complete (Kantchelian et al., 2016)

Our contribution can be summarized as follows:

• In the ﬁrst part of paper, we consider the problem of veri-
fying (cid:96)p norm robustness of tree and stump ensembles. For
a single decision tree, similar to the (cid:96)∞ norm case, we show
that the problem of complete robustness veriﬁcation of (cid:96)p
norm robustness can be done in linear time. However, for
ensemble decision stump, although complete (cid:96)∞ norm veri-
ﬁcation can be done in polynomial time, it’s NP-complete
for verifying (cid:96)p norm robustness when p ∈ (0, ∞). We
then provide an efﬁcient algorithm to conduct sound but
incomplete veriﬁcation by dynamic programming. For tree
ensembles, the (cid:96)p case is NP-complete for any p and we
propose an efﬁcient algorithm for computing a reasonably
tight lower bound. Table 1 the algorithms proposed in our
paper and previous works, as well as their complexity.

• Based on the proposed robustness veriﬁcation algorithms,
we develop training algorithms for ensemble stumps and
trees that can improve certiﬁed robust test errors with respect
to general (cid:96)p norm perturbations. Experiments on multiple
datasets verify that the proposed methods can improve (cid:96)p
norm robustness where the previous (cid:96)∞ norm certiﬁed de-
fense (Andriushchenko & Hein, 2019) cannot.

The rest of the paper is organized as follows. In Section
2, we introduce the robustness veriﬁcation and certiﬁed
defense problems. In Section 3, we discuss complexity and
algorithms for (cid:96)p norm robustness veriﬁcation for ensemble
stumps and trees. In Section 4, we show how to use our
proposed veriﬁcation algorithms to train ensemble stumps
and trees with certiﬁed (cid:96)p norm robustness. Experiments on
multiple datasets are conducted in Section 5.

2. Background and Related Work

Background Assume F : Rd → {1, . . . , C} is a C-way
classiﬁcation model, given a correctly classiﬁed example
x0 with F (x0) = y0, an adversarial perturbation is deﬁned
as δ ∈ Rd such that F (x0 + δ) (cid:54)= y0.
Deﬁnition 1 (Robustness Veriﬁcation Problem). Given
F, x0 and a perturbation radius (cid:15), the robustness veriﬁ-
cation problem aims to determine whether there exists an
adversarial example within (cid:15) ball around x0. Formally, we
determine whether the following statement is true:

F (x0 + δ) = y0, ∀(cid:107)δ(cid:107)p ≤ (cid:15).

(1)

Giving the exact “yes/no” answer to (1) is NP-complete
for neural networks (Katz et al., 2017) and tree ensem-
bles (Kantchelian et al., 2016). Adversarial attack algo-
rithms are developed to ﬁnd an adverarial perturbation δ that
satisﬁes (1). For example, several widely used attacks have
been developed for attacking neural networks (Carlini &
Wagner, 2017; Madry et al., 2018; Goodfellow et al., 2015)
and other general classiﬁers (Cheng et al., 2019b; Chen
et al., 2019c). However, adversarial attacks can only ﬁnd
adversarial examples which do not provide a sound safety
guarantee — even if an attack fails to ﬁnd an adversarial
example, it does not imply no adversarial example exists.

Robustness veriﬁcation algorithms aim to ﬁnd a sound solu-
tion to (1) — they output yes for a subset of yes instances of
(1). However they may not be complete, in the sense that it
may not be able to answer yes for all the yes instances of (1).
Therefore we will refer solving (1) exactly as the “complete
veriﬁcation problem”, while in general a veriﬁcation algo-
rithm can be incomplete1 (providing a sound but incomplete
solution to (1)). Below we will review existing works on
veriﬁcation and their connections to certiﬁed defense.

Robustness veriﬁcation For neural network, it has been
shown complete veriﬁcation is NP-complete for ReLU net-
works, so many recent works have been focusing on de-
veloping efﬁcient (but incomplete) robustness veriﬁcation
algorithms (Wong & Kolter, 2018; Zhang et al., 2018; Weng
et al., 2018; Singh et al., 2018; Wang et al., 2018b; Singh
et al., 2019; Dvijotham et al., 2018). Many of them fol-
low the linear or convex relaxation based approach (Salman
et al., 2019), where (1) is solved as an optimization problem
with relaxed constraints. However, since ensemble trees
are discrete step functions, none of these neural network
veriﬁcation algorithms can be effectively applied.

Specialized algorithms are required for verifying tree en-
sembles. Kantchelian et al. (2016) ﬁrst showed that com-
plete veriﬁcation for ensemble tree is NP-complete when

1 In some works, incomplete veriﬁcation is referred to as “approx-
imate” veriﬁcation where the goal is to guarantee a lower bound
for the norm of the minimum adversarial example, or “relaxed”
veriﬁcation emphasizing the relaxation techniques used to solving
an optimization problem related to (1).

On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

there are multiple trees with depth ≥ 2. An integer pro-
gramming method was proposed for complete veriﬁcation
which requires exponential time. Later on, a single decision
tree is veriﬁed for evaluating robustness of an RL policy in
(Bastani et al., 2018). More recently, Chen et al. (2019b)
gave a comprehensive study on the robustness of tree en-
semble models; Ranzato & Zanella (2020) and Ranzato &
Zanella (2019) proposed a tree ensemble robustness and
stability veriﬁcation method based on abstract interpreta-
tion; and Törnblom & Nadjm-Tehrani (2019) introduced an
abstraction-reﬁnement procedure which iteratively reﬁnes
a partition of the input space. However, all these previous
works only consider (cid:96)∞ perturbation model (i.e., setting the
norm to be (cid:107)δ(cid:107)∞ in (1)). The (cid:96)∞ norm assumption makes
veriﬁcation much easier on decision trees and stumps as per-
turbations can be considered independently across features,
aligning with the decision procedure of tree based models.

Certiﬁed Defense Many approaches have been proposed
to improve the robustness of a classiﬁer, however evaluat-
ing a defense method is often tricky. Many works evaluate
model robustness based on empirical robust accuracy, de-
ﬁned as the percentage of correctly classiﬁed samples under
a speciﬁc set of attacks within a predeﬁned threat model
(e.g., an (cid:96)p (cid:15)-ball) (Madry et al., 2018; Chen et al., 2019a).
However, using such measurement can lead to a false sense
of robustness (Athalye et al., 2018), since robustness against
a speciﬁc kind of attack doesn’t give a sound solution to (1).
In fact, many proposed empirical defense algorithms were
broken under more sophisticated attacks (Athalye et al.,
2018; Tramer et al., 2020). Instead, certiﬁed adversarial
defense algorithms evaluate the classiﬁer based on certiﬁed
robust accuracy, deﬁned as the percentage of correctly
classiﬁed samples for which the robustness can be veriﬁed
within the (cid:15) ball. Most of the certiﬁed defense algorithms
are based on ﬁnding the weights to minimize the certiﬁed
robust loss measured by some robustness veriﬁcation algo-
rithms (Wong & Kolter, 2018; Wong et al., 2018; Wang
et al., 2018a; Mirman et al., 2018; Zhang et al., 2019b).

Several recent works studied robust tree based models. In
(Chen et al., 2019a), an adversarial training approach is
proposed to improve (cid:96)∞ norm robustness of random forest
and GBDT. Chen et al. (2019e) proposed another empirical
defense also for (cid:96)∞ norm robustness. The only certiﬁed
defense that can provide provable robustness guarantees is
given in (Andriushchenko & Hein, 2019), where they pro-
posed a boosting algorithm to improve the certiﬁed robust
error of ensemble trees and stumps with respect to (cid:96)∞ norm
perturbation. This method cannot be directly extended to (cid:96)p
norm perturbations since it relies on independence between
features: when one feature is perturbed, the perturbations of
other features are irrelevant.

3. (cid:96)p-norm Robustness Veriﬁcation of Stumps

and Trees

The robustness veriﬁcation problem for ensemble trees and
stumps requires us to solve (1) given a model F (·). For
some of the cases, we will show that computing (1) exactly
(complete robustness veriﬁcation) is NP-complete, so in
those cases we will propose efﬁcient polynomial time algo-
rithms for computing a sound but incomplete solution to the
robustness veriﬁcation problem.

Summary of our results For a single decision tree, Chen
et al. (2019b) shows that (cid:96)∞ robustness can be evaluated in
linear time. We show that their algorithm can be extended
to the (cid:96)p norm case for p ∈ [0, ∞]. Furthermore, we can
also extend the multi-level (cid:96)∞ veriﬁcation framework (Chen
et al., 2019b) for tree ensembles to general (cid:96)p cases, allow-
ing efﬁcient and sound veriﬁcation for general (cid:96)p norm. For
evaluating the robustness of an ensemble decision stump,
Andriushchenko & Hein (2019) showed that the (cid:96)∞ case can
be solved in polynomial time, but their algorithm uses the
fact that features are uncorrelated under (cid:96)∞ norm perturba-
tions so cannot be used for any p < ∞ case. We prove that
the (cid:96)0 norm robustness evaluation can be done in linear time,
while for the (cid:96)p norm case with p ∈ (0, ∞), the robustness
veriﬁcation problem is NP-complete. We then propose an
efﬁcient dynamic programming algorithm to obtain a good
lower bound for veriﬁcation.

3.1. A single decision tree

We ﬁrst consider the simple case of a single decision tree.
Assume the decision tree has n leaf nodes and for a given
example x with d features, starting from the root, x traverses
the intermediate tree levels until reaching a leaf node. Each
internal node i determines whether x will be passed to left or
right child by checking I(xti > ηi), where ti is the feature
to spilt at in node i and ηi is the threshold. Each leaf node
vi has a value vi indicating the prediction value of the tree.

If we deﬁne Bi as the set of input x that can reach leaf node
i, due to the decision tree structure, Bi can be represented
as a d-dimensional box:

Bi = (li

1, ri

1] × · · · × (li

d, ri

d].

(2)

Some of the l, r can be −∞ or +∞. As discussed in Sec-
tion 3.1 of (Chen et al., 2019b), the box can be computed
efﬁciently in linear time by traversing the tree. To certify
whether there exists any misclassiﬁed points under perturba-
tion (cid:107)δ(cid:107)p ≤ (cid:15), we can enumerate boxes for all n leaf nodes
and check the minimum distance from x0 to each box. The
following proposition shows that the (cid:96)p norm distance be-
tween a point and a box can be computed in O(d) time,
and thus the complete robustness veriﬁcation problem for a
single tree can be solved in O(dn) time.

On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

Proposition 1. Given a box B = (l1, r1] × · · · × (ld, rd]
and a point x ∈ Rd. The minimum (cid:96)p distance (p ∈ [0, ∞])
from x to B is (cid:107)z − x(cid:107)p where:

and we should choose δ features with smallest cj values to
perturb. Let Sδ denotes the set with δ smallest cj values, we
have

zi =






li ≤ xi ≤ ui
xi < li

xi,
li,
ui, xi > ui.

min
(cid:107)x−x(cid:48)(cid:107)0≤K

F (x(cid:48)) = F (x) +

cj.

(7)

(cid:88)

i∈SK

(3)

Therefore veriﬁcation can be done exactly in O(T +dlog(d))
time, where O(dlog(d)) is the cost of sorting d values
{c1, ..., cd}.

We deﬁne the operator distp(B, x) to be the minimum (cid:96)p
distance between x to a box B. We deﬁne the (cid:96)p norm
ball Ballp(x, (cid:15)) = {x(cid:48)|(cid:107)x(cid:48) − x(cid:107)p ≤ (cid:15)}, and we use ∩ to
denote the intersection between a (cid:96)p ball and a box. B ∩
Ballp(x, (cid:15)) (cid:54)= ∅ if and only if distp(B, x) ≤ (cid:15).

3.2. Ensemble decision stumps

A decision stump is a decision tree with only one root node
and two leaf nodes. We assume there are T decision stumps
and the i-th decision stump gives the prediction

f i(x) =

(cid:40)

wi
l
wi
r

if xti < ηi
if xti ≥ ηi.

The prediction of a decision stump ensemble F (x) =
(cid:80)
i f i(x) can be decomposed into each feature in the fol-
lowing way. For each feature j, assume j1, . . . , jTj are
the decision stumps using feature j, we can collect all the
thresholds [ηj1 , . . . , ηjTj ]. Without loss of generality, as-
sume ηj1 ≤ · · · ≤ ηjTj then the prediction values assigned
in each interval can be denoted as

gj(xj) = vjt

if ηjt < xj ≤ ηjt+1

(4)

where

vjt = wj1

l + · · · + wjt

l + wjt+1

jTj
r + · · · + w
r

,

and xj is the value of sample x on feature j. The overall pre-
diction can be written as the summation over the predicted
values of each feature:

F (x) =

d
(cid:88)

j=1

gj(xj),

(5)

and the ﬁnal prediction is given by y = sgn(F (x)).

(cid:96)0 ensemble stump veriﬁcation Assume F (x) is origi-
nally positive and we want to make it as small as possible
by perturbing δ features (in this case, δ should be a positive
integer). For each feature j, we want to know the maximum
decrease of prediction value by changing this feature, which
can be computed as

(cid:96)p ensemble stump veriﬁcation The difﬁculty of (cid:96)p
norm robustness veriﬁcation is that the perturbations on
each feature are correlated, so we can’t separate all the fea-
tures as in (Andriushchenko & Hein, 2019) for the (cid:96)∞ norm
case. In the following, we prove that the complete (cid:96)p norm
veriﬁcation is NP-complete by showing a reduction from
Knapsack to (cid:96)p norm ensemble stump veriﬁcation. This
shows that (cid:96)p norm veriﬁcation can belong to a different
complexity class compared to the (cid:96)∞ norm case.

Theorem 1. Solving (cid:96)p norm robustness veriﬁcation (with
soundness and completeness) as in Eq. (1) for an ensemble
decision stumps is NP-complete when p ∈ (0, ∞).

Proof. We show that a 0-1 Knapsack problem can be re-
duced to an ensemble stump veriﬁcation problem. A 0-
1 Knapsack problem can be deﬁned as follows. Assume
there are T items each with weight wi and value vi, the
(decision version of) 0-1 Knapsack problem aims to deter-
mine whether there exists a subset of items S such that
(cid:80)

i∈S wi ≤ C and with value (cid:80)

i∈S vi ≥ D.

Now we construct a decision stump veriﬁcation problem
with T features and T stumps from the 0-1 Knapsack prob-
lem, where each decision stump corresponds to one feature.
Assume x is the original example, we deﬁne each decision
stump to be

D
T

i

, where ηi = xi + w(1/p)

gi(s) = −viI(s > ηi) +

,
(8)
where I(·) is the indicator function. The goal is to ver-
ify (cid:96)p robustness with (cid:15) = C (1/p). We need to show
that this robustness veriﬁcation problem outputs YES
i) < 0) if and only if the Knap-
(min(cid:107)x−x(cid:48)(cid:107)p≤(cid:15)
sack solution is also YES. If the veriﬁcation found v∗ =
i) < 0, let x(cid:48) be the corresponding
min(cid:107)x−x(cid:48)(cid:107)p≤(cid:15)
solution of veriﬁcation, then we can choose the following S
for 0-1 Knapsack:

i gi(x(cid:48)

i gi(x(cid:48)

(cid:80)

(cid:80)

S = {i | x(cid:48)

i > ηi}

(9)

It is guaranteed that

cj = min

t

vjt − gj(xj),

(6)

(cid:88)

i∈S

wi =

(cid:88)

i∈S

|ηi − xi|p ≤

(cid:88)

i

|x(cid:48)

i − xi|p ≤ (cid:15)p = C (10)

On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

and by the deﬁnition of gi we have (cid:80)
(cid:80)

i) = D −
i∈S vi ≤ 0, so this subset S will also be feasible for the
Knapsack problem. On the other hand, if the 0-1 Knap-
sack problem has a solution S, for robustness veriﬁcation
problem we can choose x(cid:48) such that

i gi(x(cid:48)

x(cid:48)
i =

(cid:40)

ηi
xi

if i ∈ S
otherwise

By deﬁnition we have (cid:80)
i gi(x(cid:48)
i∈S vi < 0.
Therefore the Knapsack problem, which is NP-complete,
can be reduced to (cid:96)p norm decision stump veriﬁcation prob-
lem with any p ∈ (0, ∞) in polynomial time.

i) = D − (cid:80)

Incomplete Veriﬁcation for (cid:96)p robustness Although it’s
impossible to solve (cid:96)p veriﬁcation for decision stumps in
polynomial time, we show sound veriﬁcation can be done
in polynomial time by dynamic programming, inspired by
the pseudo-polynomial time algorithm for Knapsack.
Let ηj1, . . . , ηjTj be the thresholds for feature j and
vj1, . . . , vjTj be the corresponding values, our dynamic pro-
gramming maintains the following value for each (cid:15): “given
maximal (cid:15) perturbation to the ﬁrst j features, what’s the
minimal prediction of the perturbed x”. We denote this
value as D((cid:15), j), then the following recursion holds:

D((cid:15), j + 1) = min
δ∈[0,(cid:15)]

D((cid:15) − δ, j) + C(δ, j + 1),

j −xj |<δ gj(x(cid:48)

where C(δ, j + 1) := min|x(cid:48)
j) which can be
pre-computed. Note that δ, (cid:15) can be real numbers so exactly
running this DP requires exponential time. Our approx-
imate algorithm allows (cid:15), δ only up to certain precision.
If we choose precision ν, then we only consider values
ν, 2ν, . . . , P ν (the smallest P with P ν > (cid:15)). To ensure the
veriﬁcation algorithm is sound, the recursion will become

˜D(aν, j +1) = min

b∈{1,...,a}

˜D((a−b+1)ν, j)+C(bν, j +1),

(11)
and the ﬁnal solution should be ˜D((cid:100)(cid:15)(cid:101), d) where (cid:100)(cid:15)(cid:101) := P ν
means rounding (cid:15) up to the closest grid. Note that the +1
term in the recursion is to ensure that the resulting value
is a lower bound of the original solution. The veriﬁcation
algorithm can verify a sample in O(P d + T ) time , in which
d is dimension and P is the number of discretizations.

3.3. (cid:96)p norm veriﬁcation for ensemble decision trees

Kantchelian et al. (2016) showed that for general ensemble
trees, complete (cid:96)∞ robustness veriﬁcation can formulated
as a mixed integer linear programming problem, which is
NP-Complete, and Chen et al. (2019b) proposed a fast poly-
nomial time hierarchical veriﬁcation framework to verify
the model to a desired precision. For a tree ensemble with T
trees and an input example x, Chen et al. (2019b) ﬁrst check

all the leaf nodes of each tree and only keep the leaf nodes
that x can reach under the given perturbation. In the (cid:96)∞
case, both the perturbation ball of x and the decision bound-
ary of a leaf node can be represented as boxes (see Sec. 3.1),
therefore it is easy to check whether the two boxes have an
intersection. Then T trees are splited into T
K groups, each
with K trees. Trees from different groups are considered
independently; the K trees within a group form a graph
where each size-K clique in this graph represents a possible
prediction value of all trees within this group given (cid:96)∞ in-
put perturbation. Enumerating all size-K cliques allows us
to obtain the worst case prediction of the K trees within a
group, and then we can combine the worst case predictions
of all T
K groups (e.g., directly adding all of them) to obtain
an over-estimated worst case prediction of the entire ensem-
ble. The results can be tightened by considering each group
as a “virtual tree” and merge virtual trees into a new level
of groups.

The most important procedure in (Chen et al., 2019b) is to
check whether a set of leaf nodes from different trees within
a group can form a valid size-K clique, which involves
checking the intersections among the decision boundaries of
leaf nodes from different trees and the intersection among
the clique and the perturbation ball. We extend this proce-
dure to (cid:96)p setting in our work following two steps:

First, we check the intersection between input perturbation
Ballp(x, (cid:15)) and a box Bi using Proposition 1. Initially, we
only consider the set of leaf node that has distp(Bi, x) ≤ (cid:15)
(Bi is the decision boundary of a leaf).

Second, in (cid:96)∞ case, since the (cid:96)∞ perturbation ball is also a
box, it is possible to use the boxicity property to obtain in-
tersections which are represented as size-K cliques in Chen
et al. (2019b).This boxicity property is not hold anymore for
general (cid:96)p input perturbations. Chen et al. (2019b) showed
that for a set of (cid:96)∞ boxes {B1, . . . , BT }, if Bi ∩ Bj (cid:54)= ∅
for all i, j (i (cid:54)= j), and Bi ∩ Ball∞(x, (cid:15)) (cid:54)= ∅ for all i,
then it guarantees that B1 ∩ B2... ∩ BT ∩ Ball∞(x, (cid:15)) (cid:54)= ∅.
However, for (cid:96)p (p (cid:54)= ∞) norm perturbation, under the
same condition cannot guarantee that B1 ∩ B2... ∩ BT ∩
Ballp(x, (cid:15)) (cid:54)= ∅. In fact, even if Ballp(x, (cid:15)) ∩ Bt (cid:54)= ∅ for
any t, B1 ∩ B2... ∩ BT ∩ Ball∞(x, (cid:15)) can still be empty. A
counter example with (cid:96)1 is shown in Figure 1 and similar
counter examples can be found for any p < ∞.
Therefore, we need to check whether ¯B := B1 ∩ · · · ∩ BT ,
which is still a box, has nonempty intersection with input
perturbation Ballp(x, (cid:15)). This step can be computed using
Proposition 1, which costs O(d) time. After this additional
procedure, we can safely generalize the (cid:96)∞ framework to
(cid:96)p(p ≥ 0) cases by simply replacing the procedure. We
include the detail algorithm for enumerating the size-K
cliques in Appendix 1.

On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

= L

(cid:18)

(cid:18)

min
(cid:107)δ(cid:107)p≤(cid:15)

= L

min
(cid:107)δ(cid:107)p≤(cid:15)

(yFT −1(x + δ) + yfT (x + δ))

(cid:19)

(yFT −1(x + δ) + ywl + ywr1xj(cid:48) +δj(cid:48) ≥b(cid:48))

(cid:19)

The inner minimization can then be considered as a stump
ensemble veriﬁcation problem. According to Section 3.2,
for each x, we can derive a lower bound of the inner mini-
mization, denoted as ˜D((cid:100)(cid:15)(cid:101), d):

(yFT −1(x + δ) + ywl + ywr1xj(cid:48) +δj(cid:48) ≥b(cid:48))

min
(cid:107)δ(cid:107)p≤(cid:15)
≥ ˜D(x,y)((cid:100)(cid:15)(cid:101), d).

For simplicity, we omit subscript (x, y) in the analysis below.
Our goal is to give ˜D((cid:100)(cid:15)(cid:101), d) as a function of wl and wr.
This requires a small extension to the DP based veriﬁcation
algorithm. In (11), we can consider the d features in any
order. We can solve the DP by ﬁrst solving all other d −
1 features except j(cid:48), and obtain ˜D\j(cid:48)(aν, j) for all a ∈
{1, · · · , P } and j ∈ {1, · · · .d − 1} (we denote the DP
table as ˜D\j(cid:48) to emphasize that it does not include feature
j(cid:48)). ˜D\j(cid:48)(aν, d − 1) is a lower bound of the minimum
prediction value under perturbation aν excluding all stumps
involving feature j(cid:48). Then, the recursion for ˜D((cid:100)(cid:15)(cid:101), d) needs
to consider the minimum of two settings, representing the
left or right leaf is selected for the last stump:

˜D((cid:100)(cid:15)(cid:101), d) = min

˜DL((cid:100)(cid:15)(cid:101),d) = min
a∈[P ]

(cid:16) ˜DL((cid:100)(cid:15)(cid:101), d), ˜DR((cid:100)(cid:15)(cid:101), d)
(cid:17)
(cid:16) ˜D\j(cid:48)((P −a+1)ν, d−1)+CL(aν, j(cid:48))

(cid:17)

+ywl
˜DR((cid:100)(cid:15)(cid:101), d) = min
a∈[P ]

(cid:17)
(cid:16) ˜D\j(cid:48)((P −a+1)ν, d−1)+CR(aν, j(cid:48))

+y(wr +wl)

Figure 1. In the (cid:96)p case, the perturbation ball is not a box and the
general (cid:96)p version of the Lemma 1 in (Chen et al., 2019b) is not
true. Here we present a counter example in (cid:96)1.

4. Training (cid:96)p-robust Boosted Stumps and

Trees

Based on the general (cid:96)p veriﬁcation algorithm for stump
ensembles described in Section 3.2, we develop certiﬁed
defense algorithms for training ensemble stumps and trees.
The main challenge is that for (cid:96)p(p > 0), different from the
(cid:96)∞ case, the correlation between features should be con-
sidered. Following the setting in (Andriushchenko & Hein,
2019), we use an exponential loss function L, where for a
point (x, y) ∈ Rd × {−1, 1}, L(yf (x)) = exp (−yf (x)).
However, our algorithms can be generalized to other strictly
monotonic and convex loss functions. We consider each
training example (x, y) ∈ S is perturbed in Ballp(x, (cid:15)), S is
the training set.

4.1. (cid:96)p robust boosted stumps
Given a decision stump ensemble F (x) = (cid:80)T
i=1 fi(x) with
T stumps, without loss of generality, we assume the ﬁrst
T − 1 stumps, deﬁned as FT −1(x) = (cid:80)T −1
i=1 fi(x), are
already trained and ﬁxed, and our target is to update F
with a new stump fT (x). Here we deﬁne a stump as f (x) =
wl+1xj ≥bwr which splits the space at threshold b on feature
j and predict wl (left leaf prediction) or wl + wr (right leaf
prediction). Our goal is to select the 4 parameters (b, j, wl,
wr) robustly by minimizing the minimax loss:
(cid:88)

min
j,b,wl,wr

max
(cid:107)δ(cid:107)p≤(cid:15)

L(yF (x + δ))

(x,y)∈S

CL(aν, j) =

min
j |≤aν,x(cid:48)

j <b(cid:48)

|xj −x(cid:48)

(12)

CR(aν, j) =

min
j |≤aν,x(cid:48)

j ≥b(cid:48)

|xj −x(cid:48)

gj(x(cid:48))

gj(x(cid:48))

(14)

To solve this optimization, we ﬁrst consider a sub-problem
l for a ﬁxed split (j(cid:48), b(cid:48)).
r and w∗
which ﬁnds the optimal w∗
(cid:88)
max
(cid:107)δ(cid:107)p≤(cid:15)

r = arg min

L(yF (x + δ))

l , w∗

w∗

wl,wr

(x,y)∈S

(13)

s.t. j = j(cid:48), b = b(cid:48)

For the inner maximization, we note that the loss function
is monotonically decreasing, therefore we can replace the
maximization as an minimization inside the loss function:

max
(cid:107)δ(cid:107)p≤(cid:15)

L(yF (x + δ))

= max
(cid:107)δ(cid:107)p≤(cid:15)

L (yFT −1(x + δ) + yfT (x + δ))

In (14), ˜DL((cid:100)(cid:15)(cid:101),d) and ˜DR((cid:100)(cid:15)(cid:101),d) denote the minimum pre-
diction value of the sample (x, y) when perturbed into the
left or right side of the split (j(cid:48), b(cid:48)). CL(aν, j), CR(aν, j)
denote the minimum prediction when x is perturbed into the
left or right side of the split on feature j with perturbation
aν, where gj(x) is deﬁned as in (4) but with the last tree
fT (x) excluded (i.e., computed on FT −1).

After obtaining the lower bound of the inner minimization,
instead of solving the original optimization (13), here we
solve

w∗

l , w∗

r = arg min

wl,wr

(cid:88)

(x,y)∈S

L( ˜D(x,y)((cid:100)(cid:15)(cid:101), d)).

(15)

On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

Theorem 2. (cid:80)
jointly convex in wl, wr.

(x,y)∈S L( ˜D(x,y)((cid:100)(cid:15)(cid:101), d)) deﬁned in (15) is

The proof can be found in the Appendix D. Based on this
theorem, we can use coordinate descent to solve the mini-
mization: ﬁx wr and minimize over wl, then ﬁx wl and min-
imize over wr (similar to Andriushchenko & Hein (2019)).
For exponential loss, when wr is ﬁxed, we can use a closed
form solution to update wl (see Appendix B). When wl is
ﬁxed, we use bisection to get the optimal wr. For general
loss functions, both wl and wr can be solved by bisection.

l , w∗

After estimating w∗
r in (13), we can iterate over all the
possible split positions (j, b) and select the position with
minimum robust loss. Our proposed general (cid:96)p norm ro-
bust training algorithm for stump ensembles can train a new
stump in O(T N (P d+T )+dBT ) time, where B is the num-
ber of candidate bs and N is the size of dataset. For ﬁxed
j, (cid:15) and precision, ˜D\j(cid:48)(aν, d − 1) is ﬁxed for all a ∈ [P ]
and can be pre-calculated, which costs O(N (P d + T )) time.
And in implementation, we only need to calculate T + 1
different ˜D\j(cid:48)(aν, d − 1), which costs O(T N (P d + T ))
time. After obtaining ˜D\j(cid:48)(aν, d − 1), in each iteration,
˜D((cid:100)(cid:15)(cid:101), d) can be derived in O(T ) time (despite having P
discretizations, there are only T possible values in the mini-
mization in Eq. (14), and an efﬁcient implementation can
l and w∗
exploit this fact). The bisection searching for w∗
r
can also be ﬁnished in O(1) time with ﬁxed parameters.
Thus the above algorithm can train a stump ensemble in
O(T N (P d + T ) + dBT ) time.

4.2. (cid:96)p robust boosted trees

Single decision tree Our goal is to solve (12) where F is a
single tree. Different from the (cid:96)∞ case, in (cid:96)p cases, perturba-
tion on one dimension can reduce the possible perturbation
on other dimensions. Therefore, when updating a stump en-
semble, perturbation bound (cid:15) will be consumed along the tra-
jectory from the tree root to leaf nodes. Because the number
of features is typically more than the depth of a decision tree,
we use each feature only once along one trajectory on the de-
cision tree. We deﬁne S = {(x, y) ∈ S|distp(x, BNk ) ≤ (cid:15)}
as the set of samples that can fall into node Nk under (cid:96)p
norm (cid:15) bounded perturbation, and (N0, N1, ..., Nk−1) as
the sequence of nodes on the trajectory from tree root N0 to
tree node Nk. Each node Nt (0 ≤ t < k) contains a split
(jt, bt) which splits the space on feature jt at value bt.

In the (cid:96)p norm case, each example has an unique pertur-
bation budget at node Nk, as some of the perturbation
budget has been consumed in parent nodes splitting other
features. For each sample (x, y), (cid:96)p norm bounded pertur-
bation in node Nk can be calculated along the trajectory
by (cid:15)(x) = ((cid:15)p − (cid:80)
t∈E(xjt − bt)p)
p , where E is a sub-
set of the node trajectory in which x and Nt+1 are on the

1

different sides of node Nt, ∀t ∈ E. Formally, we can de-
ﬁne E as {t : t < k − 1, 1(xjt ≥ bt) (cid:54)= 1(Nt+1 ≥ bt)},
where Nt+1 ≥ bt denotes that x(cid:48)
≥ bt, ∀x(cid:48) ∈ BNt+1.
jt
This is different from previous works on (cid:96)∞ perturbations.
Now we consider training the node Nk and get the optimal
parameters (j∗, b∗, w∗

l , w∗

r ):

j∗, b∗, w∗

l , w∗
r
(cid:88)

= arg min
j,b,wl,wr

(x,y)∈S

max
(cid:107)δ(cid:107)p≤(cid:15)(x)

L(f (x + δ)y),

(16)

where f (·) is a new leaf node f (x) = I(x ≥ b)wr + wl,
and when training node Nk, we only consider the training
examples in S. The objective in (16) is similar to that in (12)
except that there is only one stump to be trained. Therefore,
we can use a similar procedure as in previous section to ﬁnd
the optimal parameters.

Boosted decision tree ensemble Given a tree ensemble
with T trees F (x) = (cid:80)T
i=1 fi(x), we ﬁx the ﬁrst T − 1
trees and train a node N on the (T )-th decision tree fT (x).
The optimization problem will be essentially the same as
Eq. (16), but here for (x, y) ∈ S, we should also consider
the ﬁrst T − 1 trees, along with prediction of node N :

max
(cid:107)δ(cid:107)p≤(cid:15)(x)

L(yFT (x + δ))

= max

(cid:107)δ(cid:107)p≤(cid:15)(x)

L(yFT −1(x + δ)+y(wl +1xj +δj≥bwr))

(cid:18)

= L

min
(cid:107)δ(cid:107)p≤(cid:15)(x)

(yFT −1(x + δ)+y(wl +1xj +δj≥bwr))

.

(cid:19)

Here FT −1(x) is the prediction from the ensemble of the
ﬁrst T − 1 trees. We further lower bound the minimization:

min
(cid:107)δ(cid:107)p≤(cid:15)(x)

(yFT −1(x + δ)+y(wl +1xj +δj≥bwr))

≥ min

(cid:107)δ(cid:107)p≤(cid:15)(x)

yFT −1(x + δ)+ min

y(wl +1xj +δj≥bwr)

(cid:107)δ(cid:107)p≤(cid:15)(x)

The ﬁrst part is the (cid:96)p robustness veriﬁcation for tree en-
semble, which is challenging to solve efﬁciently during
training time. Here we apply a relatively loose lower bound
of yFT −1(x), where

T −1
(cid:88)

i=1

min
(cid:107)δ(cid:107)p≤(cid:15)(x)

(yf (x + δ)) ≤ min

(cid:107)δ(cid:107)p≤(cid:15)(x)

yFT −1(x)

We simply sum up the worst prediction on each previous
tree, which can be easily maintained during training. By
doing this relaxation, the problem is reduced to building a
single tree to boost the (cid:96)p norm robustness.

4.3. (cid:15) schedule

When features are correlated in (cid:96)p cases, we ﬁnd that it is
important to have an (cid:15) schedule during the training process

On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

Table 2. General (cid:96)p-norm ensemble stump veriﬁcation. This table reports veriﬁed test error (veriﬁed err.) and average per sample
veriﬁcation time (avg. time) of each method. For our proposed DP based veriﬁcation, precision is also reported. For (cid:96)0 veriﬁcation, we
report veriﬁed errors with (cid:15)0 = 1 (changing 1 pixels). For (cid:96)0 norm, we also report r∗, which is the average the number features that can
be perturbed at most while the prediction stays the same.

Dataset

(cid:96)1 MILP (complete) Ours (cid:96)1 DP approx. (incomplete)

Ours vs. MILP

Ours (cid:96)0 (complete) veriﬁcation

name
breast-cancer
diabetes

(cid:15)∞ veriﬁed err. avg. time precision veriﬁed err. avg. time MILP/ours speedup avg. robust r∗ veriﬁed err. avg. time
95.62% .0006s
0.3
100.0% .0005s
0.05
.010s
16.35%
Fashion-MNIST shoes 0.1
.010s
4.50%
0.3
.012s
26.43%
0.3

.00025s
.0004s
.0013s
0.0013s
.0012s

10.94%
35.06%
10.45%
3.30%
9.64%

10.94%
35.06%
10.55%
3.35%
9.69%

0.01
0.0002
0.005
0.005
0.005

.030s
.017s
.105s
0.11s
0.099s

120X
40X
80.8X
71X
82X

MNIST 1 vs. 5
MNIST 2 vs. 6

.04
.0
2.09
3.33
1.22

1.00
1.00
.99
1.00
.98

Table 3. General (cid:96)p-norm tree ensemble veriﬁcation. We report veriﬁed test error (veriﬁed err.) and average per-example veriﬁcation
time (avg. time) of each method. K: size of cliques; L: number of levels in multi-level veriﬁcation (deﬁned similarly as in (Chen et al.,
2019b)). Our (cid:96)p incomplete veriﬁcation can obtain results very close to complete veriﬁcation (MILP), with huge speedups.

Dataset

(cid:96)1 MILP

Ours (cid:96)1 approx.

Ours vs. MILP

name
breast-cancer
diabetes

(cid:15)
0.3
0.05
Fashion-MNIST shoes 0.1
0.3
0.3

MNIST 1 vs. 5
MNIST 2 vs. 6

veriﬁed err. avg. time K L veriﬁed err. avg. time ratio of veriﬁed err. speedup

8.03%
33.12%
10%
4.20%
8.60%

.036s
.027s
.091s
0.088s
.098s

3 2
3 2
3 2
3 2
3 2

8.03%
33.12%
10%
4.20%
8.80%

.012s
.012s
.011s
.011s
.012s

1.00
1.00
1.00
1.00
.98

3X
2.25X
8.23X
8X
8.17X

– the (cid:15) increases gradually from small to large, instead of
using a ﬁxed large (cid:15) in the beginning. If one directly uses a
large (cid:15) in the beginning, the ﬁrst few stumps will allow too
much perturbation and the later stumps tend to allow fewer
perturbation, making it harder to explore the correlation
between features. In ensemble stump training, we increase
the (cid:15) when training a new stump, and in ensemble tree
training, we increase the (cid:15) when height of the tree grows.
We also include the choice of (cid:15) schedules in Appendix D.1.

5. Experimental Results

In this section we empirically test the proposed algo-
rithms for (cid:96)p robustness veriﬁcation and training. The
code is implemented in Python and all the experiments
are conducted on a machine with 2.7 GHz Intel Core
i5 CPU with 8G RAM. Our code is publicly available
at https://github.com/YihanWang617/On-ell_p-Robustness-
of-Ensemble-Stumps-and-Trees

5.1. (cid:96)p stump and tree ensemble veriﬁcation

(cid:96)p stump ensemble veriﬁcation We evaluate our incom-
plete (cid:96)p veriﬁcation method for stump ensembles on ﬁve
real datasets. Ensembles are robustly trained using the (cid:96)∞
training procedure proposed in (Andriushchenko & Hein,
2019), each of which contains 20 stumps.

For the (cid:96)1 norm robustness veriﬁcation problem, we have
shown it’s NP-complete to conduct complete veriﬁcation.
To demonstrate the tightness and efﬁciency of the proposed

Dynamic Programming (DP) based veriﬁcation, we also
run the Mixed Integer Linear Programming (Kantchelian
et al., 2016) to conduct complete veriﬁcation, which can take
exponential time. In Table 2, we can ﬁnd that the proposed
DP algorithm gives almost exactly the same bound as MILP,
while being 50 − 100 times faster. This speedup guarantees
its further applications in certiﬁed robust training.

For the (cid:96)0 norm robustness veriﬁcation, we propose a lin-
earithmic time algorithm for complete veriﬁcation. The
results for (cid:15)0 = 1 (changing only 1 feature) are also re-
ported in Table 2. We can observe that the proposed method
can conduct complete veriﬁcation in less than 0.1 second.
We ﬁnd that some models are not robust to (cid:96)0 perturbations
with high veriﬁed errors. Since our veriﬁcation method is
complete, these models suffer from adversarial examples
that change classiﬁcation outcome by changing only 1 pixel.

(cid:96)p tree ensemble veriﬁcation We evaluate our incom-
plete (cid:96)p veriﬁcation method for tree ensembles on ﬁve
real datasets. Ensemble models being veriﬁed are robustly
trained with (Andriushchenko & Hein, 2019), each of which
contains 20 trees.

Again, we compare our proposed algorithm with MILP-
based complete veriﬁcation (Kantchelian et al., 2016) which
can take exponential time to get the exact bound. The results
are presented in Table 3, and parameters of the proposed
method (K and L) are also reported. We observe that the
proposed veriﬁcation method gets very tight veriﬁed errors
while being much faster than the MILP solver.

On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

Table 4. (cid:96)1 robust training for stump ensembles. We report standard errors and (cid:96)1 veriﬁed errors of our training methods ((cid:96)1 training)
versus the previous (cid:96)∞ training algorithm. (cid:15) is the perturbation bound for each dataset. For (cid:15) = 1.0 in mnist dataset, we train the models
using (cid:15)∞ = 0.3. Our proposed (cid:96)1 training can signiﬁcantly reduce the (cid:96)1 veriﬁed error, and the previous (cid:96)∞ approach cannot as it was
designed to reduce (cid:96)∞ error only. We conduct a similar experiment for (cid:96)2 norm in Appendix E.2.

Dataset

standard training

(cid:96)∞ training(Andriushchenko & Hein, 2019)

name
breast-cancer
diabetes

Fashion-MNIST shoes

MNIST 1 vs. 5

MNIST 2 vs. 6

(cid:15)∞ (cid:15)1 n. stumps standard err. veriﬁed err. standard err.
0.3 1.0
0.05 0.05
0.1 0.1
0.2 0.5
0.3 0.3
0.3 1.0
0.3 0.3
0.3 1.0

0.73%
21.43%
6.60%
5.05%
1.23%
0.59%
3.17%
2.81%

95.62%
37.66%
69.85%
87.5%
58.76%
66.01%
92.46%
99.49%

4.37%
29.2%
7.50%
9.25%
1.68%
1.33%
4.52%
3.91%

20
20
20
40
20
40
20
40

veriﬁed err.
99.27%
35.06%
10.45%
57.05%
3.30%
17.46%
9.64%
44.22%

(cid:96)1 training (ours)
standard err. veriﬁed err.

1.46%
27.27%
7.10%
12.40%
1.28%
4.49%
3.71%
7.73%

35.77%
31.82%
10.35%
32.20%
2.81%
16.23%
8.24%
33.46%

Table 5. (cid:96)1 robust training for tree ensembles. We report standard and (cid:96)1 robust test error for all the three methods. We also report (cid:15) for
each dataset, and the number of trees in each ensemble. We also report the results of (cid:96)2 robust training for tree ensembles in Appendix E.2.

Dataset

standard training

(cid:96)∞ training (Andriushchenko & Hein, 2019)

name

(cid:15)∞ (cid:15)1 n. trees depth standard err. veriﬁed err. standard err.

Fashion-MNIST shoes 0.2 0.5
0.3 1.0
0.3 0.8
0.3 0.6

breast-cancer
MNIST 1 vs. 5
MNIST 2 vs. 6

5
5
5
5

5
5
5
5

4.65%
0.73%
0.64%
4.12%

99.85%
99.26%
97.38%
100.0%

7.85%
0.73%
0.64%
1.96%

veriﬁed err.
89.54%
99.63%
64.11%
52.33%

(cid:96)1 training (ours)
standard err. veriﬁed err.

18.71%
9.56%
4.59%
7.64%

65.18%
47.05%
36.23%
39.67%

5.2. (cid:96)p robust stump and tree ensemble training

(cid:96)p robust stump training We evaluate our proposed certi-
ﬁed training methods on two small size datasets and three
medium-size datasets. All the models are trained with stan-
dard training, (cid:96)∞ robust training (Andriushchenko & Hein,
2019) and our proposed general (cid:96)p robust training algorithm
(in experiments, we set p = 1. We also report the p = 2
results in Appendix E.2). Models of the same dataset are
trained with the same set of hyperparameters (details can
be found in the Appendix). We evaluate (cid:96)1 veriﬁed test
error using MILP. In our experiments, we choose different
(cid:15)∞ and (cid:15)p such that the (cid:96)∞ and (cid:96)p perturbation balls do
not contain each other. Standard error and veriﬁed robust
test error of each model are reported in Table 4. We also
report (cid:96)∞ robustness of these models in Appendix E.1. We
observe that the proposed training method can successfully
get a more robust model against (cid:96)1 perturbation compared
to the previous (cid:96)∞-norm only training method.

(cid:96)p robust tree training We evaluate our (cid:96)p robust training
method for trees on subsets of three medium size datasets
(dataset statistics can be found in the Appendix). We report
the results of (cid:96)1 robust training tree ensembles in Tables 5,
and results of (cid:96)2 robust training in Appendix E.2. It shows
that our algorithm achieves better or at least comparable
veriﬁed error in most cases. In addition, we also conduct an
example to test the performance of certiﬁed training with
respect to number of trees. In Figure 2, we compare (cid:96)∞
and (cid:96)1 robust training on fashion-mnist dataset and monitor

Figure 2. (cid:96)1 and (cid:96)∞ robust training on fashion-mnist dataset
((cid:15)∞ = 0.2 and (cid:15)1 = 0.5). We compare veriﬁed errors during
training when the number of stumps increases.

the performance over the ﬁrst 20 stumps (the (cid:15) scheduling
length is 5). We can observe that when number of stumps
increases, the our (cid:96)1 robust training can indeed gradually
reduce (cid:96)1 veriﬁed test error, where the (cid:96)∞ robust training
(as a reference) can only slightly improve (cid:96)1 robustness.

6. Conclusion

In this paper, we ﬁrst develop methods to efﬁciently ver-
ify the general (cid:96)p norm robustness for tree-based ensemble
models. Based on our proposed efﬁcient veriﬁcation algo-
rithms proposed, we further derive the ﬁrst (cid:96)p norm certiﬁed
robust training algorithms for ensemble stumps and trees.

On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

Acknowledgement

We acknowledge Maksym Andriushchenko and Matthias
Hein for providing their (cid:96)∞ certiﬁed training code. This
work is partially supported by NSF IIS-1719097, Intel,
Google cloud and Facebook. Huan Zhang is supported
by the IBM fellowship.

References

Chen, P.-Y., Zhang, H., Sharma, Y., Yi, J., and Hsieh, C.-J.
Zoo: Zeroth order optimization based black-box attacks
to deep neural networks without training substitute mod-
els. In Proceedings of the 10th ACM Workshop on Artiﬁ-
cial Intelligence and Security, pp. 15–26. ACM, 2017.

Chen, Y., Wang, S., Jiang, W., Cidon, A., and Jana, S.
Training robust tree ensembles for security. arXiv preprint
arXiv:1912.01149, 2019d.

Andriushchenko, M. and Hein, M. Provably robust boosted
decision stumps and trees against adversarial attacks. In
NeurIPS, 2019.

Chen, Y., Wang, S., Jiang, W., Cidon, A., and Jana, S. Cost-
aware robust tree ensembles for security applications.
arXiv preprint arXiv:1912.01149, 2019e.

Athalye, A., Carlini, N., and Wagner, D. Obfuscated
gradients give a false sense of security: Circumvent-
ing defenses to adversarial examples. arXiv preprint
arXiv:1802.00420, 2018.

Bastani, O., Pu, Y., and Solar-Lezama, A. Veriﬁable rein-
forcement learning via policy extraction. In Advances in
Neural Information Processing Systems, pp. 2494–2504,
2018.

Cheng, M., Le, T., Chen, P.-Y., Yi, J., Zhang, H., and Hsieh,
C.-J. Query-efﬁcient hard-label black-box attack: An
optimization-based approach. In ICLR, 2019a.

Cheng, M., Le, T., Chen, P.-Y., Zhang, H., Yi, J., and
Hsieh, C.-J. Query-efﬁcient hard-label black-box at-
tack: An optimization-based approach. In International
Conference on Learning Representations, 2019b. URL
https://openreview.net/forum?id=rJlk6iRqKX.

Brendel, W., Rauber, J., and Bethge, M. Decision-based
adversarial attacks: Reliable attacks against black-box
machine learning models. In ICLR, 2018.

Cheng, M., Singh, S., Chen, P., Chen, P.-Y., Liu, S., and
Hsieh, C.-J. Sign-opt: A query-efﬁcient hard-label adver-
sarial attackh. In ICLR, 2020.

Calzavara, S., Lucchese, C., Tolomei, G., Abebe, S. A.,
and Orlando, S. Treant: Training evasion-aware decision
trees. arXiv preprint arXiv:1907.01197, 2019.

Dvijotham, K., Stanforth, R., Gowal, S., Mann, T., and
Kohli, P. A dual approach to scalable veriﬁcation of deep
networks. UAI, 2018.

Calzavara, S., Lucchese, C., Marcuzzi, F., and Orlando,
S. Feature partitioning for robust tree ensembles and
their certiﬁcation in adversarial scenarios. arXiv preprint
arXiv:2004.03295, 2020.

Carlini, N. and Wagner, D. Towards evaluating the robust-
ness of neural networks. In Security and Privacy (SP),
2017 IEEE Symposium on, pp. 39–57. IEEE, 2017.

Chen, H., Zhang, H., Chen, P.-Y., Yi, J., and Hsieh, C.-J.
Attacking visual language grounding with adversarial ex-
amples: A case study on neural image captioning. In
Proceedings of the 56th Annual Meeting of the Associ-
ation for Computational Linguistics (Volume 1: Long
Papers), pp. 2587–2597, 2018.

Chen, H., Zhang, H., Boning, D., and Hsieh, C.-J. Robust
decision trees against adversarial examples. In ICML,
2019a.

Chen, H., Zhang, H., Si, S., Li, Y., Boning, D., and Hsieh,
C.-J. Robustness veriﬁcation of tree-based models. In
NeurIPS, 2019b.

Friedman, J. H. Greedy function approximation: a gradient
boosting machine. Annals of statistics, pp. 1189–1232,
2001.

Gehr, T., Mirman, M., Drachsler-Cohen, D., Tsankov, P.,
Chaudhuri, S., and Vechev, M. Ai2: Safety and robustness
certiﬁcation of neural networks with abstract interpreta-
tion. In 2018 IEEE Symposium on Security and Privacy
(SP), pp. 3–18. IEEE, 2018.

Goodfellow, I. J., Shlens, J., and Szegedy, C. Explaining
and harnessing adversarial examples. In ICLR, 2015.

Ilyas, A., Engstrom, L., Athalye, A., and Lin, J. Query-
efﬁcient black-box adversarial examples. In ICLR, 2018.

Kantchelian, A., Tygar, J., and Joseph, A. Evasion and
hardening of tree ensemble classiﬁers. In ICML, 2016.

Katz, G., Barrett, C., Dill, D. L., Julian, K., and Kochender-
fer, M. J. Reluplex: An efﬁcient smt solver for verifying
deep neural networks. In International Conference on
Computer Aided Veriﬁcation, pp. 97–117. Springer, 2017.

Chen, J., Jordan, M. I., and Wainwright, M. J. Hop-
skipjumpattack: A query-efﬁcient decision-based adver-
sarial attack. arXiv preprint arXiv:1904.02144, 2019c.

Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and
Vladu, A. Towards deep learning models resistant to
adversarial attacks. In ICLR, 2018.

On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

Wong, E. and Kolter, J. Z. Provable defenses against adver-
sarial examples via the convex outer adversarial polytope.
In ICML, 2018.

Wong, E., Schmidt, F., Metzen, J. H., and Kolter, J. Z.
Scaling provable adversarial defenses. In NIPS, 2018.

Xu, K., Chen, H., Liu, S., Chen, P.-Y., Weng, T.-W., Hong,
M., and Lin, X. Topology attack and defense for graph
neural networks: an optimization perspective. In Pro-
ceedings of the 28th International Joint Conference on
Artiﬁcial Intelligence, pp. 3961–3967. AAAI Press, 2019.

Zhang, H., Weng, T.-W., Chen, P.-Y., Hsieh, C.-J., and
Daniel, L. Efﬁcient neural network robustness certiﬁca-
tion with general activation functions. In NIPS, 2018.

Zhang, H., Chen, H., Song, Z., Boning, D., Dhillon, I. S.,
and Hsieh, C.-J. The limitations of adversarial training
and the blind-spot attack. In ICLR, 2019a.

Zhang, H., Chen, H., Xiao, C., Li, B., Boning, D., and Hsieh,
C.-J. Towards stable and efﬁcient training of veriﬁably
robust neural networks. arXiv preprint arXiv:1906.06316,
2019b.

Zhang, H., Yu, Y., Jiao, J., Xing, E. P., Ghaoui, L. E., and Jor-
dan, M. I. Theoretically principled trade-off between ro-
bustness and accuracy. arXiv preprint arXiv:1901.08573,
2019c.

Zhang, H., Zhang, P., and Hsieh, C.-J. Recurjac: An efﬁ-
cient recursive algorithm for bounding jacobian matrix of
neural networks and its applications. In AAAI, 2019d.

Mirman, M., Gehr, T., and Vechev, M. Differentiable ab-
stract interpretation for provably robust neural networks.
In International Conference on Machine Learning, pp.
3578–3586, 2018.

Ranzato, F. and Zanella, M. Robustness veriﬁcation of
decision tree ensembles. OVERLAY@ AI* IA, 2509:59–
64, 2019.

Ranzato, F. and Zanella, M. Abstract interpretation of deci-
sion tree ensemble classiﬁers. In AAAI, pp. 5478–5486,
2020.

Salman, H., Yang, G., Zhang, H., Hsieh, C.-J., and Zhang, P.
A convex relaxation barrier to tight robustness veriﬁcation
of neural networks. arXiv preprint arXiv:1902.08722,
2019.

Schott, L., Rauber, J., Bethge, M., and Brendel, W. Towards
the ﬁrst adversarially robust neural network model on
mnist. arXiv preprint arXiv:1805.09190, 2018.

Singh, G., Gehr, T., Mirman, M., Püschel, M., and Vechev,
M. Fast and effective robustness certiﬁcation. In NIPS,
2018.

Singh, G., Gehr, T., Püschel, M., and Vechev, M. An abstract
domain for certifying neural networks. Proceedings of the
ACM on Programming Languages, 3(POPL):41, 2019.

Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan,
D., Goodfellow, I., and Fergus, R. Intriguing properties
of neural networks. In ICLR, 2013.

Törnblom, J. and Nadjm-Tehrani, S. An abstraction-
reﬁnement approach to formal veriﬁcation of tree ensem-
bles. In International Conference on Computer Safety,
Reliability, and Security, pp. 301–313. Springer, 2019.

Tramèr, F. and Boneh, D. Adversarial training and robust-
ness for multiple perturbations. In Advances in Neural
Information Processing Systems, pp. 5866–5876, 2019.

Tramer, F., Carlini, N., Brendel, W., and Madry, A. On
adaptive attacks to adversarial example defenses. arXiv
preprint arXiv:2002.08347, 2020.

Wang, S., Chen, Y., Abdou, A., and Jana, S. Mixtrain: Scal-
able training of formally robust neural networks. arXiv
preprint arXiv:1811.02625, 2018a.

Wang, S., Pei, K., Whitehouse, J., Yang, J., and Jana, S.
Efﬁcient formal safety analysis of neural networks. In
NIPS, 2018b.

Weng, T.-W., Zhang, H., Chen, H., Song, Z., Hsieh, C.-J.,
Boning, D., Dhillon, I. S., and Daniel, L. Towards fast
computation of certiﬁed robustness for relu networks. In
ICML, 2018.

On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

A. Proof of Proposition 1

Proposition 1. Given a box B = (l1, r1] × · · · × (ld, rd] and a point x ∈ Rd. The closest (cid:96)p distance (p ∈ [0, ∞]) from x
to B is (cid:107)z − x(cid:107)p where:

zi =






li ≤ xi ≤ ui
xi < li

xi,
li,
ui, xi > ui.

Proof. For p > 0, The goal is to minimize the following objective:

And for p = 0, the objective is

min
z

min
z

(cid:107)z − x(cid:107)p

p = min

z

d
(cid:88)

|zi − xi|p

i=1
s.t. li < zi ≤ ri, ∀i ∈ [d].

(cid:107)z − x(cid:107)0 = min

z

d
(cid:88)

I(zi (cid:54)= xi)

i=1
s.t. li < zi ≤ ri, ∀i ∈ [d].

where I(·) is an indicator function. For p = ∞, the objective is

min
z

(cid:107)z − x(cid:107)∞ = min

z

d
(cid:88)

|zi − xi|

i=1
s.t. li < zi ≤ ri, ∀i ∈ [d].

Since each term in the summation is separable, we can consider minimizing each term in the summation signs separately.
Given the constraints on zi, the minimum is achieved at the condition speciﬁed in Eq. (3) regardless of the choice of p:

zi =






li ≤ xi ≤ ui
xi < li

xi,
li,
ui, xi > ui.

B. Closed form update rule for (cid:96)p Stump Ensemble Training

For exponential loss we can rewrite eq (15) as

N −1
(cid:88)

i=1

L( ˜D((cid:100)(cid:15)(cid:101), d)) =

=

N −1
(cid:88)

i=1
(cid:88)

yi=1

γi exp(−yiwl)

γi exp(−wl)+

(cid:88)

yi=−1

γi exp(wl)

where

which is ﬁxed with a ﬁxed wr.

γi = L( ˜D((cid:100)(cid:15)(cid:101), d) − yiwl)

On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

And we can further derive the optimal wl at each update step

(cid:88)

yi=1

γi(− exp(−w∗

l )) +

(cid:88)

yi=1

γi exp(−w∗

l ) =

(cid:88)

yi=−1
(cid:88)

γi exp(w∗

l ) = 0

γi exp(w∗
l )

yi=−1
(cid:80)

w∗

l = ln

(cid:80)

yi=1 γi
yi=−1 γi

/2.

C. Robustness veriﬁcation for ensemble trees

In this section, we provide the detail algorithm of robustness veriﬁcation for ensemble trees. This algorithm is based
on the robustness veriﬁcation framework in (Chen et al., 2019b). In Algorithm 1, we describe the modiﬁed function
CliqueEnumerate, which is the key procedure of this framework. The main difference is that after we form the initial
set of cliques, we will recheck whether the formed cliques have intersection with the (cid:96)p perturbation ball (line 18 to 22).

D. Proof of Theorem 2

Proof. By deﬁnition, we have

L( ˜D((cid:100)(cid:15)(cid:101), d)) = L(min( ˜DL((cid:100)(cid:15)(cid:101),d), ˜DR((cid:100)(cid:15)(cid:101),d)))

= max(L( ˜DL((cid:100)(cid:15)(cid:101),d)), L( ˜DR((cid:100)(cid:15)(cid:101),d))).

Exponential loss L is convex and monotonically increasing; L( ˜DL((cid:100)(cid:15)(cid:101),d)) and L( ˜DR((cid:100)(cid:15)(cid:101),d)) are both jointly convex in
wl, wr. Note that the dynamic programming related terms become constants after they are computed, so they are irrelevant
to wl, wr. Therefore, L( ˜D((cid:100)(cid:15)(cid:101), d)) and further (cid:80)N −1

i=0 L( ˜D((cid:100)(cid:15)(cid:101), d)) are jointly convex in wl, wr.

Dataset

ensemble stumps lr. ensemble trees lr.

breast-cancer
diabetes
Fashion-MNIST shoes
MNIST 1 vs. 5
MNIST 2 vs. 6

0.4
0.4
0.4
0.4
0.4

-
-
1.0
1.0
1.0

(cid:96)1 training
ensemble trees sample size
-
-
5000
5000
5000

Table 6. Detail settings of the experiments. Here we report the learning rate of different training methods for ensemble stumps and trees.
We also report the sample size in experiments for ensemble tree training and the scheduling length in (cid:96)p robust training for ensemble
stumps.

D.1. Detail settings of the experiments

Here we report the detail settings of our experiments in Table 6. For most of the experiments, we follow the learning rate
settings in (Andriushchenko & Hein, 2019). For (cid:15) scheduling length, we empirically set to the best value near (cid:15)p/(cid:15)std for
each dataset and (cid:15) settings (e.g., for (cid:96)1 norm training, the best schedule length is among 2, 3 and 4 epochs for (cid:15)1 = 1.0 and
(cid:15)std = 0.3). Here the (cid:15)std is (cid:15)∞ used in (Andriushchenko & Hein, 2019). For each dataset, different methods are trained
with the same group of parameters.

For (cid:96)1 robust training for ensemble trees, we use a subsample of training datasets to reduce training time. On Fashion-MNIST
shoes, MNIST 1 vs. 5 and MNIST 2 vs. 6 datasets, we subsample 5000 images of the selected classes from the original
dataset. For (cid:96)2 robust training, we subsample 1000 images of the selected classes from the original dataset.

D.2. (cid:96)∞ vs. (cid:96)p robust training

For a binary classiﬁer y = sgn(F (x)), and a ﬁxed (cid:15), we have min(cid:107)δ(cid:107)p≤(cid:15) yF (x + δ) ≥ min(cid:107)δ(cid:107)∞≤(cid:15) yF (x + δ). Therefore,
the exact (cid:96)∞ robust loss can be a natural upper bound of (cid:96)p robust loss. This explains the close result from (cid:96)∞ and (cid:96)p robust
training, when using the same (cid:15). However, this (cid:96)∞ upper bound tends to hurt the clean accuracy , which we can see from
Table 4. Additionally, unlike (cid:96)1 or (cid:96)2 norms, it is impossible to set this (cid:96)∞ perturbation to a large value (e.g., (cid:15)∞ = 1.0).

On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

E. Additional experiment results

E.1. Comparison of (cid:96)∞ robustness

In this section, we report the (cid:96)∞ veriﬁed errors of models in Table 4. For each model in the table, we verify the models
using (cid:96)∞ robustness veriﬁcation of decision stumps (Andriushchenko & Hein, 2019) with perturbation norm (cid:15)∞. In general,
Andriushchenko & Hein (2019) produces better (cid:96)∞ norm veriﬁcation error because it is designed for that case, but when
training using our (cid:96)1 robust training procedure with a larger (cid:96)1, models also get relatively good (cid:96)∞ robustness. Note that
here we train different number of stumps for different (cid:15)1(e.g. For MNIST dataset, we train 20 stumps for (cid:15)1 = 0.3 and 40
stumps for (cid:15)1 = 1.0). And for a ﬁxed (cid:15), we train the (cid:96)∞ robust model with the same number of stumps with other methods
when making comparisons.

Dataset

name
breast-cancer
diabetes

Fashion-MNIST shoes

MNIST 1 vs. 5

MNIST 2 vs. 6

(cid:15)∞ (cid:15)1
0.3 1.0
0.05 0.05
0.1 0.1
0.2 0.5
0.3 0.3
0.3 1.0
0.3 0.3
0.3 1.0

standard training
(cid:96)∞ veriﬁed err.
88.32%
42.85%
69.85%
98.85%
67.09%
66.20%
97.74%
100.0%

(cid:96)∞ training

(cid:96)1 training

(cid:96)∞ veriﬁed err. (cid:96)∞ veriﬁed err.

10.94%
35.06%
11.35%
19.30%
4.09%
3.60%
8.63%
8.69%

17.51%
31.81%
11.75%
27.60%
4.05%
11.59%
9.10%
15.28%

Table 7. (cid:96)∞ robustness of ensemble decision stumps. This table reports the (cid:96)∞ robustness for the same set of models in Table 4. For
each dataset, we evaluate standard models, the (cid:96)∞ robust models trained using (Andriushchenko & Hein, 2019) with perturbation norm
(cid:15)∞, and our (cid:96)p robust model with p = 1 and perturbation norm (cid:15)1. We test the models with (cid:96)∞ norm perturbation (cid:15)∞. Standard test
errors are omitted as they as the same as in Table 4.

E.2. (cid:96)2 robust training

In Section 5 we mainly presented results for the p = 1 setting, however our robust training procedure works for general
(cid:96)p norm. In this section, we show some (cid:96)2 robust training results. For each dataset, we train three models using standard
training, (cid:96)∞ robust training (Andriushchenko & Hein, 2019) with (cid:96)∞ perturbation norm (cid:15)∞, and (cid:96)p robust training with
p = 2 and (cid:96)2 perturbation norm (cid:15)2. And in Table 8 and 9, we report the veriﬁcation results of these models from (cid:96)2
veriﬁcation.

Dataset

standard training

(cid:96)∞ training

(cid:96)2 training

name
breast-cancer

(cid:15)∞ (cid:15)2 standard err. (cid:96)2 veriﬁed err. standard err. (cid:96)2 veriﬁed err. standard err. (cid:96)2 veriﬁed err.
0.3 0.7
Fashion-MNIST shoes 0.2 0.4
0.3 0.8
0.3 0.8

39.42%
49.55%
36.56%
76.98%

97.08%
69.85%
67.09%
97.74%

99.27%
81.05%
66.45%
85.52%

8.76%
14.55%
4.44%
13.67%

MNIST 1 vs. 5
MNIST 2 vs. 6

4.37%
9.25%
1.33%
3.91%

0.73%
5.05%
0.59%
2.81%

Table 8. (cid:96)2 robust training for ensemble stumps In this table, we train the model with p = 2 and compare the results with (cid:96)∞ trained
models. For each dataset, we train three models using standard training, (cid:96)∞ norm robust training with (cid:15)∞ and (cid:96)2 norm robust training
with (cid:15)2. And we test and compare the (cid:96)2 robustness of these models using (cid:96)2 robust veriﬁcation.

Dataset

standard training

(cid:96)∞ training (Andriushchenko & Hein, 2019)

name

(cid:15)∞ (cid:15)2 n. trees depth standard err. veriﬁed err. standard err.

Fashion-MNIST shoes 0.2 0.4
0.3 0.8
0.3 0.8
0.3 0.8

breast-cancer
MNIST 1 vs. 5
MNIST 2 vs. 6

3
5
3
3

5
5
5
5

8.05%
1.47%
2.37%
3.82%

99.40%
97.06%
100.0%
100.0%

7.65%
1.47%
2.12%
3.12%

veriﬁed err.
93.49%
97.79%
97.72%
100.0%

(cid:96)2 training (ours)
standard err. veriﬁed err.

17.36%
12.50%
23.25%
19.80%

68.23%
55.88%
50.54%
93.56%

Table 9. (cid:96)2 robust training for tree ensembles. We report standard and (cid:96)2 robust test error for all the three methods. We also report (cid:15)∞
and (cid:15)2 for each dataset, and the number of trees in each ensemble.

On (cid:96)p-norm Robustness of Ensemble Decision Stumps and Trees

Algorithm 1 Enumerating all K-cliques on a K-partite graph with (cid:15)p, dimension d and example x
input : V1, V2, , . . . , VK are the K independent sets (“parts”) of a K-partite graph; the graph is deﬁned similarly as in

Chen et al. (2019b).

1 for k ← 1, 2, 3, . . . , K do
Uk ← {(Ai, Bi(k)

2

)|i(k) ∈ Vk, Ai = {i(k)}} /* U is a set of tuples (A, B), which stores a

set of cliques and their corresponding boxes. A is the set of nodes in one clique
and B is the corresponding box of this clique.
Initially, each node in Vk forms a
1-clique itself.

*/

3 end
4 CliqueEnumerate(U1, U2, , . . . , UK)
5 Function CliqueEnumerate(U1, U2, , . . . , UK)
6

ˆUold ← U1
for k ← 2, 3, . . . , K do

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

ˆUnew ← ∅
for ( ˆA, ˆB) ∈ ˆUold do

for (A, B) ∈ Uk do

if B ∩ ˆB (cid:54)= ∅ then

/* A k-clique is found; add it as a pseudo node with the intersection of

two boxes.

ˆUnew ← ˆUnew ∪ {(A ∪ ˆA, B ∩ ˆB)}

*/

end

end
ˆUold ← ˆUnew

end
ˆU ← ∅
for (A, B) ∈ ˆUnew do

if CheckClique(B, d, p, (cid:15)p) then

/* After finding all the k-cliques, we need to recheck whether these cliques have
*/

intersection with the (cid:96)p perturbation ball around the example x.

ˆU ← ˆU ∪ {(A, B)}

end
return ˆU

22
23 end
24 Function CheckClique(B, d, p, (cid:15))
dist ← minz∈B(cid:107)z − x(cid:107)p
25
if dist < (cid:15)p then
return false

27

26

return true

28
29 end

p using Proposition 1

