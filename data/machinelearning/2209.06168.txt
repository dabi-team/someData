2
2
0
2

p
e
S
3
1

]
I

A
.
s
c
[

1
v
8
6
1
6
0
.
9
0
2
2
:
v
i
X
r
a

BORCH: A DEEP UNIVERSAL PROBABILISTIC PROGRAMMING
LANGUAGE

A PREPRINT

Lewis Belcher
Department of AI Research
Desupervised ApS
Copenhagen, 2100
lb@desupervised.io

Johan Gudmundsson
Department of AI Research
Desupervised ApS
Copenhagen, 2100
jg@desupervised.io

Michael Green
Department of AI Research
Desupervised ApS
Copenhagen, 2100
mg@desupervised.io

September 14, 2022

ABSTRACT

Ever since the Multilayered Perceptron was ﬁrst introduced the connectionist community has struggled
with the concept of uncertainty and how this could be represented in these types of models. This
past decade has seen a lot of effort in trying to join the principled approach of probabilistic modeling
with the scalable nature of deep neural networks. While the theoretical beneﬁts of this consolidation
are clear, there are also several important practical aspects of these endeavors; namely to force the
models we create to represent, learn, and report uncertainty in every prediction that is made. Many
of these efforts have been based on extending existing frameworks with additional structures. We
present Borch, a scalable deep universal probabilistic programming language, built on top of PyTorch.
The code is available for download and use in our repo.

Keywords uppl • neural networks • uncertainty • pytorch

1

Introduction

The ability to solve a wide variety of challenging real world problems using machine learning has ﬂourished during the
course of the past decade. We’ve seen advancements within diverse application areas, e.g., vision (Bojarski et al. 2016),
natural language and physics (Bakarji et al. 2022). We’ve also seen the emergence of a new paradigm for machine
learning where it is possible to teach a computer how to complete mathematical proofs (Davis 2021; Davies et al.
2021) and even compete in a real-world programming competition (Li et al. 2022). Despite the fact that most of these
advances were achieved by neural networks, there are still areas where neural networks are far from being superior to
more traditional machine learning methods(Shwartz-Ziv and Armon 2021). The strength in many of these methods
lies in that they are easier to interpret and reason about. However, despite these recent success, most of the models

 
 
 
 
 
 
A PREPRINT - SEPTEMBER 14, 2022

developed and in use today lack the ability to adequately quantify the conﬁdence in the predictions given (Ghahramani
2015).

This is especially problematic for models that are exposed to out of distribution (OOD) examples. When it comes to
deploying neural networks in real world applications, OOD data will inevitably be an issue (Henriksson et al. 2021).
Elaborate data augmentation processes and larger training datasets can help make the networks more robust (Zheng et
al. 2016), but will never cover the entire spectrum of possible scenarios. This is the most signiﬁcant reason to model
and report the uncertainty in model parameters as well as the data.

With the ambition to understand uncertainty in predictions it is natural to turn to a Bayesian treatment of model
parameters, likelihood and data (Dasgupta et al. 2020).

2 About Uncertainties

One of the most important concepts in modeling any system is to know what you do not know (Kläs and Vollmer 2018).
That may sound like an impossible situation to resolve, but it’s really quite simple. We don’t need to know why we
don’t know something, we only need to quantify the degree of our ignorance. As such, it is important to categorize
different uncertainties to help us reason about where our lack of knowledge resides.

For most practical purposes in machine learning we categorize uncertainties into Epistemic and Aleatoric uncertainty
(Kiureghian and Ditlevsen 2009). They are shown in Figure 1.

Epistemic uncertainty encapsulates the uncertainty the model has about its own representation of the problem at hand. It
represents all things the model doesn’t know but in principle could. Examples of this can be data left out of the training
set. Another example is structural limitations of the model itself.

Aleatoric uncertainty on the other hand encapsulates the uncertainty that happens as a consequence of running an
experiment multiple times. It’s basically the innate uncertainty that we cannot model our way out of. This particular
type of uncertainty comes in two ﬂavors.

Homoskedastic Aleatoric Uncertainty is the uncertainty or variance observed across the entire dataset, i.e., one value.

Heteroskedastic Aleatoric Uncertainty on the other hand changes as a function of each observation. This means that
you can have a rather high “data uncertainty” for observation A, while having a low uncertainty for observation B.

Figure 1: A classiﬁcation of common uncertainties that are useful to consider in machine learning models.

2

A PREPRINT - SEPTEMBER 14, 2022

2.1 Probabilistic Programming
Universal Deep Probabilistic programming languages unify techniques for formal description of computation with the
representation and use of uncertain knowledge (Goodman and Stuhlmüller 2014). These languages have seen recent
interest from artiﬁcial intelligence, programming languages, cognitive science, and natural languages communities
(Gawlikowski et al. 2021).

Implementing probabilistic models from scratch is highly error-prone and requires a high degree of expertise (Goodman
and Stuhlmüller 2014; Tolpin et al. 2016). This results in models that are very hard to develop, extend and to reuse. To
combat these issues practitioners usually revert to using a probabilistic programming language (PPL) which enables the
expression of probabilistic programs and performing inference on those programs.

We introduce Borch, a universal probabilistic programming language built on PyTorch (Paszke et al. 2019).
Throughout the paper we illustrate code1 to show the expressiveness of the language.

3 Design Principles

3.1 Basic Syntax
Borch is built around a few core primitives. (i) Distributions that provide standard features such as generation of
samples and calculation of log probabilities of distributions etc. (ii) Random Variables (RV) which unify distributions
with tensors. (iii) Posteriors that handle how the inference algorithm creates samples. (iv) A Module which is the object
used to keep track of RVs and the inference algorithm.

We recommend two different coding patters, functional and object-oriented depending on the type of model used. The
functional syntax is straightforward and easy to understand. The forward pass of a simple linear regression model can
be implemented as follows:

def forward(bm, x):

bm.b = Normal(0, 3)
bm.a = Normal(0, 3)
bm.sigma = HalfNormal(1)
mu = bm.b * x + bm.a
bm.y = Normal(mu, bm.sigma)
return bm.y

The functional programming paradigm has the beneﬁt of being more similar to the actual mathematics of neural
networks in ﬂow and execution order.

In some cases the object-oriented paradigm is more natural and the corresponding code for the forward pass of the
simple linear regression model would look like below:

class Model(Module):

def __init__(self):

super ().__init__()
self.b = Normal(0, 3)
self.a = Normal(0, 3)
self.sigma = HalfNormal(1)

def forward(self, x):

mu = self.b * x + self.a
self.y = Normal(mu, self.sigma)
return self.y

For users of torch.nn (Paszke et al. 2019) and tensorflow.keras (Chollet et al. 2015) this should look familiar.

As illustrated in the code snippets above, Borch supports both formalisms which enables ﬂexibility in the model
expression. Thus, one can choose the most suitable approach for the model at hand. When working with hierarchical
models a functional style tends to produce cleaner code (Buitléir, Russell, and Daly 2013) as there is a lot of code that
needs to be executed on each pass. When following the object-oriented approach, the hierarchy should be expressed

1The

available
are
https://gitlab.com/desupervised/research/borch-paper and more elaborate tutorials are available at https://borch.readthedocs.io.

examples

excerpts.

snippets

shown

paper

code

Full

just

the

are

in

at

3

A PREPRINT - SEPTEMBER 14, 2022

in the forward pass, and only isolated random variables should be put in the __init__ function. This is a common
pattern for neural networks and thus the object-oriented paradigm is more compatible with many existing tutorials and
applications for neural networks.

In order to be an effective PPL it is important to have the ability to condition on any random variable in the model.
Further, being able to ﬁt a model while conditioning on an arbitrary set of random variables is key. Also, un-conditioning
a subset of those variables such the same model can be used to generate predictions allows for the expression of a wide
variety of models. This is done in Borch using the observe method on the Module object.

model.observe(y=y)
forward(model, x) == y

Then in order to stop observing and be able to generate predictions from the model one can use:

model.observe(None)
forward(model, x) != y

This way of conditioning on data enables us to move from a generative state to a discriminatory state in one line of code.

3.2 Scaling
In order to handle the ever-growing size of models and data, a PPL needs to be scalable. This means handling everything
from a simple linear regression model to a billion parameter image classiﬁcation neural network trained on a graphics
processing unit (GPU). At the same time it needs to be ﬂexible enough to express a wide range of models and that
these models can be ﬁt with a multitude of inference methods. Borch is composable such that models can be ﬁt by the
method most suitable to a given problem. As such, any model can be conditioned on data through diverse methods, e.g.,
Markov Chain Monte Carlo (MCMC) (Brooks et al. 2011), Variational Inference (VI) (Blei, Kucukelbir, and McAuliffe
2017) and Maximum a Postiori (MAP) (Bassett and Deride 2018).

3.3 Variable Scoping
In many Python-based PPLs there is a lack of reﬂectiveness in the model expression resulting in model speciﬁcations
that require explicit naming of the variables instantiated. For example in PyMC3 (Salvatier, Wiecki, and Fonnesbeck
2016) it looks like this:

with pm.Model() as linear_model:

weights = pm.Normal("weights", mu=0, sigma=1)

and in Pyro (Bingham et al. 2019) it is written as below.

weights = pyro.sample("weights", dist.Normal(0, 1))

This results in the variable weights which will be shared across the model and thus does not enable scoping using the
standard Python syntax but has to be handled manually or with custom primitives. This lack of scoping results in a
source of potential bugs, it is easy to deal with for small models but as the model grows in complexity it becomes more
problematic. In Borch we strived to make probabilistic programming as easy as we possibly could. That’s why we can
simply write the following and avoid the verbose syntax present in, e.g., Pyro, NumPyro and PyMC3.

module.weights = Normal(0, 1)

3.4 Native Feel
We aim to allow the full expressiveness of normal Python code and ease of integration with other tools. Since PyTorch
(Paszke et al. 2019) offers auto differentiation for dynamic computational graphs, GPU support and native integration
with Python primitives the same holds true for Borch since it builds on top of PyTorch. Thus, we support features like
stochastic control ﬂow out of the box.

def forward(module, data):

if randn(1) > 0:

module.weight = Normal(-1, 1)

else:

module.weight = Normal(1, 10)
return data*torch.exp(module.weight)

4

A PREPRINT - SEPTEMBER 14, 2022

3.5 Neural Networks

We set out to keep the feel of how PyTorch expresses neural networks and make it a seamless experience to do Bayesian
inference using Borch for anyone with PyTorch experience. Thus, we wanted it to be fully compatible with normal
Python functions. We also wanted a tight integration with PyTorch such that one gets dynamic control ﬂow and the
same type of user experience when creating models in Borch.

To enable this for neural networks we provide an interface almost identical to the torch.nn modules and in most cases
it is possible to just switch from import torch.nn as nn to import borch.nn as nn. This makes a network
deﬁned in PyTorch probabilistic, without any other changes in the model speciﬁcation. Thus, a simple MNIST (Deng
2012) image classiﬁcation model can be written like below.

import torch.nn.functional as F
from borch import nn

class Net(nn.Module):

def __init__(self):

super (Net, self).__init__()
self.conv1 = nn.Conv2d(1, 6, 5)
self.conv2 = nn.Conv2d(6, 16, 5)
self.fc1 = nn.Linear(16 * 5 * 5, 120)
self.fc2 = nn.Linear(120, 84)
self.fc3 = nn.Linear(84, 10)

def forward(self, x):

x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
x = F.max_pool2d(F.relu(self.conv2(x)), 2)
x = x.view(1, -1)
x = F.relu(self.fc1(x))
x = F.relu(self.fc2(x))
x = self.fc3(x)
return x

Changing an entire neural network to be Bayesian is not always required though. Often it makes sense to only make
speciﬁc parts or layers of the neural network Bayesian. Using the MNIST example above we can easily compose
Borch and PyTorch such that only the two last layers are Bayesian. This means that the last decision layers will learn
uncertainty while the earlier layers of the network will have point parameters. We write the adapted MNIST model as
below.

import torch
import borch
import torch.nn.functional as F

class Net(borch.nn.Module):
def __init__(self):

super (Net, self).__init__()
self.conv1 = torch.nn.Conv2d(1, 6, 5)
self.conv2 = torch.nn.Conv2d(6, 16, 5)
self.fc1 = torch.nn.Linear(16 * 5 * 5, 120)
self.fc2 = borch.nn.Linear(120, 84)
self.fc3 = borch.nn.Linear(84, 10)

def forward(self, x):

x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
x = F.max_pool2d(F.relu(self.conv2(x)), 2)
x = x.view(1, -1)
x = F.relu(self.fc1(x))
x = F.relu(self.fc2(x))
x = self.fc3(x)
return x

5

A PREPRINT - SEPTEMBER 14, 2022

The signature for PyTorch nn modules has also been extended to support the ability to set priors for the weights of an
nn module. Thus, to use the priors in Figure 2 for the fully connected dense layer fc3 in the Bayesian MNIST model, it
is as simple as

self.fc3 = nn.Linear(84, 10, weight=Normal(0, 1e-2), bias=Normal(0, 1))

where the weight and bias arguments are broadcast to the shape of each tensor in the nn.Linear module.

Figure 2: Illustration of the histograms of the two prior distributions broadcast to the weights and the biases of the dense
layer fc3 in the MNIST model. In this example the biases and weights are given by b ∼ N (0, 1) and ω ∼ N (0, 0.01)
respectively.

3.6 Transforming Networks to Become Bayesian
Transfer learning (Farahani et al. 2021) is commonly used to take a network trained on one problem as a starting point
and train it to solve a different problem. In the same way Borch allows taking a torch.nn network and converting the
whole or a part of it to be Bayesian. This makes it possible to quickly introduce uncertainty to a full scale model.

Here we show how to create a Bayesian MobileNetV3 (Howard et al. 2019) network in just a few lines of code.

import torchvision
import borch
import torch
mobilenet = borch.nn.borchify_network(

torchvision.models.mobilenet_v3_small(pretrained=True),

)
# Now it can be used to predict
borch.sample(mobilenet)
mobilenet(torch.randn(3, 3, 224, 224))

However, we do not need to make the entire network Bayesian. Instead, we can make parts of the network Bayesian
and the process is the same.

mobilenet= models.mobilenet_v3_small(pretrained=True)
mobilenet.classifier = borchify_network(mobilenet.classifier)
borch.sample(mobilenet)
mobilenet(torch.randn(3, 3, 224, 224))

A couple of notable differences compared to PyTorch are:

1. We need to borchify or lift the network up to a probabilistic network.

6

BiasWeight−2.50.02.55.0−0.0250.0000.0250.0500200040006000ValueCountTypeBiasWeight2. We need to sample the posterior weights before generating a prediction. Without the sample statement we will

reuse the same weights over and over again.

A PREPRINT - SEPTEMBER 14, 2022

that

it makes

Note
classiﬁer
(borch.sample(mobilenet.classifier)) or on the entire network (borch.sample(mobilenet)) as the
operation is applied recursively and only affects the segments of the network which are constructed with Borch.

difference whether we

borch.sample

only

call

the

no

on

3.7

Inference

The primary focus in the development of Borch has been to ensure that one can actually create and train state of the
art neural networks. In order to achieve this a lot of attention has been focused on variational inference (Paisley, Blei,
and Jordan 2012) as an inference method, as it, together with MAP, are the ﬁtting methods that can scale to big neural
networks.

To this end we wanted to make it easy to control the approximating distribution for different parts of the network. This
is done by the concept of a posterior, that guides the approximating distribution. In order to offer full control of the
approximating distribution we have Manual posterior. Below is a minimal example where we simply infer the location
and scale of a normal distribution.

def forward(mod):

mod.test = Normal(5, 1)

The posterior is speciﬁed in the same way. In order for the parameters to be learnable we need to deﬁne them as
torch.Parameters. The Parameter wrapper for tensors just lets the framework know that it should be returned
when calling model.parameters() in the same way torch does it. Thus, this is a convenient way to pass them to an
optimizer.

man_posterior = posterior.Manual()
man_posterior.mean = torch.nn.Parameter(torch.ones(1))
man_posterior.sd = torch.nn.Parameter(torch.ones(1))

def forward_posterior(posterior):

scale = torch.exp(posterior.sd)+0.01
mean = posterior.mean.abs ()
posterior.test = dist.Normal(mean, scale)

While we support the manual expression of the posterior using the borch.posterior.Manual, we found that in the
case of large neural networks it was simply easier to automatically create the appropriate approximate posterior. This
still allows control over what posterior is used where in the network. It is done by simply specifying the posterior for
each module.

class Net(nn.Module):

def __init__(self):

super (Net, self).__init__(posterior=borch.posterior.Automatic())
self.conv1 = Conv2d(1, 6, 5, posterior=borch.posterior.Normal(log_scale=-3))
self.conv2 = Conv2d(6, 16, 5, posterior=borch.posterior.Normal(log_scale=-3))
self.fc1 = Linear(16 * 5 * 5, 120,

posterior=borch.posterior.ScaledNormal(scaling=1e-2)

self.fc2 = Linear(120, 10,

)

posterior=borch.posterior.ScaledNormal(scaling=1e-2)

def forward(self, x):

)

x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
x = F.max_pool2d(F.relu(self.conv2(x)), 2)
x = x.view(1, -1)
x = F.relu(self.fc1(x))
x = self.fc2(x)
self.classification = Categorical(logits=x)
return x

7

A PREPRINT - SEPTEMBER 14, 2022

In this example we used the Automatic posterior for the top level module as it will automatically detect that the x
in self.classification = Categorical(logits=x) will be updated in each forward. Thus, it will not create
a parameter for logits that would be optimized. For the layers conv1 and conv2 the Normal posterior was used,
creating a normal distribution as an approximating distribution where the scale goes through a exp transform. We can
control at what value the unconstrained scale is initialized at. This is different to the ScaledNormal used for fc1 and
fc2 which creates a Normal distribution as the approximating distribution but scales the width of the initialization point
based on the prior.

When using a PPL, depending on the model, one will be interested in using different inference methods. For high
conﬁdence in the accuracy of the ﬁt posteriors MCMC methods like The No-U-Turn Sampler (Hoffman and Gelman
2011) are preferred. For bigger models that are more data hungry like a neural network, MCMC methods do not
scale well and also suffer from sampling issues (Blei, Kucukelbir, and McAuliffe 2017; Jospin et al. 2022) due to a
massively degenerate energy landscape. Here, we need to use some other method like MAP or VI (Blei, Kucukelbir,
and McAuliffe 2017).

Borch enables this by tying inference methods to a speciﬁc posterior. Thus, if we want to ﬁt a model with MCMC even
though the model set a posterior tied to VI at creation, we can simply replace the posterior on all the modules in a model
like this:

net = Net()
net.apply (set_posteriors(PointMass))

This facilitates the ability to encode the desired posterior when expressing the model. It also allows us to quickly alter
the posterior on an instantiated object in order to use a different inference method, or simply to test the effect of a
different posterior guide. The use of the term PointMass can be confusing but here it refers to a single sample, since
each forward pass produces a set of values. It is the distribution of many forward passes that will eventually make up
the posterior in this case.

4 Comparison to Existing PPLs

The development of Borch started in 2018 out of a necessity to build robust deep learning models that perform well
on OOD data. The models developed at Desupervised were required to perform in critical environments where the
consequence of a bad decision could be devastating. With this particular need, we realized that a Bayesian formalism
made the most sense, but we were unhappy with the performance and coding style of existing frameworks. So we
wanted to build large and deep neural networks while still maintaining a standard PPL interface. Thus, Borch is by no
means the ﬁrst PPL of its kind since there has been active development in this area for a long time. The landscape today
is also different from when Borch was ﬁrst developed.

Today, in our point of view, the two main alternatives are Pyro (Bingham et al. 2019) and Tensorﬂow probability (Dillon
et al. 2017). Pyro offers a very solid PPL but very little tooling for neural networks. Tensorﬂow probability integrates
with the Tensorﬂow Keras api that allows the creation of neural networks in a similar fashion as one can do with Borch.

Borch offers a wider range of Neural Network modules and an interface as a universal PPL that is more intuitive and
does not require manual creation of the joint distribution of the model. Several PPLs that inﬂuenced the design of Borch
were Stan (Stan Development Team 2018), Edward (Tran et al. 2016), PyMC3 (Salvatier, Wiecki, and Fonnesbeck
2016) and ProbTorch (Siddharth et al. 2017).

5 Conclusion

In order for deep neural networks to be deployed and used at scale across safety critical industries, e.g., healthcare,
pharma, and construction they need the ability to report uncertainty for every prediction made. The importance does not
reside in the pursuit of statistical excellence but rather in the necessity for the end user to know how much conﬁdence
should be put into the prediction at hand. The likelihood is of little help here since it’s uncalibrated, unnormalized
and cannot easily be interpreted. A full Bayesian treatment of a model is required to produce useful, normalized and
calibrated probabilities for each prediction.

Many interesting models do not have a closed form expression for the posterior distributions from which predictions
are drawn. This predicament often leads practitioners to turn to powerful MCMC techniques like NUTS (Hoffman
and Gelman 2011). While NUTS creates good approximations of the posteriors it’s limited in terms of parameter and
data scale, making its application to neural networks suboptimal. Several attempts have been made to create languages
which extend modern deep learning libraries with a probabilistic framework, e.g, Pyro and Tensorﬂow Probability.
While powerful, we feel that these languages are verbose and put extra mental burden onto the practitioner.

8

A PREPRINT - SEPTEMBER 14, 2022

We introduce Borch, a deep universal probabilistic programming language built on PyTorch. It provides a true Pythonic
look and feel and can easily enable deep learning practitioners to include uncertainty estimates into their models. A
process we call borchify turns a standard PyTorch model into its Bayesian counterpart. This process can operate
on the entire network or be constrained to parts of it. This allows the practitioner to choose which pieces of a neural
network that make the most sense to make Bayesian.

With this work we aim to remove the obstacles deep learning practitioners have in implementing Bayesian models by
providing a language that looks and feels exactly like PyTorch. We hope that the community will build upon this and
focus more on OOD predictive quality in all application areas.

References

Bakarji, Joseph, Kathleen Champion, J. Nathan Kutz, and Steven L. Brunton. 2022. “Discovering Governing Equations
from Partial Measurements with Deep Delay Autoencoders.” arXiv. https://doi.org/10.48550/ARXIV.2201.05136.
Bassett, Robert, and Julio Deride. 2018. “Maximum a Posteriori Estimators as a Limit of Bayes Estimators.” Mathe-

matical Programming 174 (1-2): 129–44. https://doi.org/10.1007/s10107-018-1241-0.

Bingham, Eli, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer, Neeraj Pradhan, Theofanis Karaletsos, Rohit
Singh, Paul Szerlip, Paul Horsfall, and Noah D. Goodman. 2019. “Pyro: Deep Universal Probabilistic Programming.”
Journal of Machine Learning Research 20 (28): 1–6. http://jmlr.org/papers/v20/18-403.html.

Blei, David M., Alp Kucukelbir, and Jon D. McAuliffe. 2017. “Variational Inference: A Review for Statisticians.”
Journal of the American Statistical Association 112 (518): 859–77. https://doi.org/10.1080/01621459.2017.128577
3.

Bojarski, Mariusz, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D.
Jackel, et al. 2016. “End to End Learning for Self-Driving Cars.” arXiv. https://doi.org/10.48550/ARXIV.1604.07
316.

Brooks, Steve, Andrew Gelman, Galin L. Jones, and Xiao-Li Meng. 2011. “Handbook of Markov Chain Monte Carlo.”

Handbook of Markov Chain Monte Carlo. https://doi.org/10.1201/b10905.

Buitléir, Amy de, Michael Russell, and Mark Daly. 2013. “A Functional Approach to Neural Networks.” Edited by
Edward Z. Yang. The Monad.Reader 21 (March): 5–24. http://themonadreader.files.wordpress.com/2013/03/issue
214.pdf.

Chollet, Francois et al. 2015. “Keras.” GitHub. 2015. https://github.com/fchollet/keras.
Dasgupta, Ishita, Eric Schulz, Joshua B Tenenbaum, and Samuel J Gershman. 2020. “A Theory of Learning to Infer.”

Psychological Review 127 (3): 412.

Davies, Alex, Petar Veliˇckovi´c, Lars Buesing, Sam Blackwell, Daniel Zheng, Nenad Tomašev, Richard Tanburn, et al.

2021. “Advancing Mathematics by Guiding Human Intuition with AI.” Nature 600 (7887): 70–74.

Davis, Ernest. 2021. “Deep Learning and Mathematical Intuition: A Review of (Davies Et Al. 2021).” arXiv.

https://doi.org/10.48550/ARXIV.2112.04324.

Deng, Li. 2012. “The Mnist Database of Handwritten Digit Images for Machine Learning Research.” IEEE Signal

Processing Magazine 29 (6): 141–42.

Dillon, Joshua V., Ian Langmore, Dustin Tran, Eugene Brevdo, Srinivas Vasudevan, Dave Moore, Brian Patton, Alex
Alemi, Matt Hoffman, and Rif A. Saurous. 2017. “TensorFlow Distributions.” arXiv. https://doi.org/10.48550/ARX
IV.1711.10604.

Farahani, Abolfazl, Behrouz Pourshojae, Khaled Rasheed, and Hamid R. Arabnia. 2021. “A Concise Review of Transfer

Learning.” arXiv. https://doi.org/10.48550/ARXIV.2104.02144.

Gawlikowski, Jakob, Cedrique Rovile Njieutcheu Tassi, Mohsin Ali, Jongseok Lee, Matthias Humt, Jianxiang Feng,
Anna Kruspe, et al. 2021. “A Survey of Uncertainty in Deep Neural Networks.” arXiv. https://doi.org/10.48550/A
RXIV.2107.03342.

Ghahramani, Zoubin. 2015. “Probabilistic Machine Learning and Artiﬁcial Intelligence.” Nature 521 (7553): 452–59.

https://doi.org/10.1038/nature14541.

Goodman, Noah D, and Andreas Stuhlmüller. 2014. “The Design and Implementation of Probabilistic Programming

Languages.” http://dippl.org.

Henriksson, Jens, Christian Berger, Markus Borg, Lars Tornberg, Sankar Raman Sathyamoorthy, and Cristofer Englund.
2021. “Performance Analysis of Out-of-Distribution Detection on Trained Neural Networks.” Information and
Software Technology 130 (February): 106409. https://doi.org/10.1016/j.infsof.2020.106409.

Hoffman, Matthew D., and Andrew Gelman. 2011. “The No-u-Turn Sampler: Adaptively Setting Path Lengths in

Hamiltonian Monte Carlo.” arXiv. https://doi.org/10.48550/ARXIV.1111.4246.

Howard, Andrew, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, et al. 2019.

“Searching for MobileNetV3.” arXiv. https://doi.org/10.48550/ARXIV.1905.02244.

9

A PREPRINT - SEPTEMBER 14, 2022

Jospin, Laurent Valentin, Hamid Laga, Farid Boussaid, Wray Buntine, and Mohammed Bennamoun. 2022. “Hands-on
Bayesian Neural Networks — a Tutorial for Deep Learning Users.” IEEE Computational Intelligence Magazine 17
(2): 29–48. https://doi.org/10.1109/MCI.2022.3155327.

Kiureghian, Armen Der, and Ove Ditlevsen. 2009. “Aleatory or Epistemic? Does It Matter?” Structural Safety 31 (2):

105–12. https://doi.org/https://doi.org/10.1016/j.strusafe.2008.06.020.

Kläs, Michael, and Anna Maria Vollmer. 2018. “Uncertainty in Machine Learning Applications: A Practice-Driven
Classiﬁcation of Uncertainty.” In Computer Safety, Reliability, and Security, edited by Barbara Gallina, Amund
Skavhaug, Erwin Schoitsch, and Friedemann Bitsch, 431–38. Cham: Springer International Publishing.

Li, Yujia, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, et al. 2022.
“Competition-Level Code Generation with AlphaCode.” arXiv. https://doi.org/10.48550/ARXIV.2203.07814.
Paisley, John, David Blei, and Michael Jordan. 2012. “Variational Bayesian Inference with Stochastic Search.” arXiv.

https://doi.org/10.48550/ARXIV.1206.6430.

Paszke, Adam, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, et al. 2019.
“PyTorch: An Imperative Style, High-Performance Deep Learning Library.” In Advances in Neural Information
Processing Systems 32, edited by H. Wallach, H. Larochelle, A. Beygelzimer, F. dAlché-Buc, E. Fox, and R.
Garnett, 8024–35. Curran Associates, Inc. http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-
performance-deep-learning-library.pdf.

Salvatier, John, Thomas V Wiecki, and Christopher Fonnesbeck. 2016. “Probabilistic Programming in Python Using

PyMC3.” PeerJ Computer Science 2: e55.

Shwartz-Ziv, Ravid, and Amitai Armon. 2021. “Tabular Data: Deep Learning Is Not All You Need.” arXiv. https:

//doi.org/10.48550/ARXIV.2106.03253.

Siddharth, N., Brooks Paige, Jan-Willem van de Meent, Alban Desmaison, Noah Goodman, Pushmeet Kohli, Frank
Wood, and Philip H.S. Torr. 2017. “Learning Disentangled Representations with Semi-Supervised Deep Generative
Models.” In Advances in Neural Information Processing Systems, edited by I. Guyon, U. V. Luxburg, S. Bengio, H.
Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, 5925–35. Neural Information Processing Systems.

Stan Development Team. 2018. “RStan: The R Interface to Stan.” http://mc-stan.org/.
Tolpin, David, Jan-Willem van de Meent, Hongseok Yang, and Frank Wood. 2016. “Design and Implementation of
Probabilistic Programming Language Anglican.” In Proceedings of the 28th Symposium on the Implementation and
Application of Functional Programming Languages. IFL 2016. New York, NY, USA: Association for Computing
Machinery. https://doi.org/10.1145/3064899.3064910.

Tran, Dustin, Alp Kucukelbir, Adji B. Dieng, Maja Rudolph, Dawen Liang, and David M. Blei. 2016. “Edward: A
Library for Probabilistic Modeling, Inference, and Criticism.” arXiv. https://doi.org/10.48550/ARXIV.1610.09787.
Zheng, Stephan, Yang Song, Thomas Leung, and Ian Goodfellow. 2016. “Improving the Robustness of Deep Neural

Networks via Stability Training.” arXiv. https://doi.org/10.48550/ARXIV.1604.04326.

10

