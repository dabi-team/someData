An Integer Linear Programming Framework for Mining Constraints from Data

Tao Meng 1 Kai-Wei Chang 1

Abstract

Structured output prediction problems (e.g., se-
quential tagging, hierarchical multi-class classi-
ï¬cation) often involve constraints over the out-
put label space. These constraints interact with
the learned models to ï¬lter infeasible solutions
and facilitate in building an accountable system.
However, although constraints are useful, they are
often based on hand-crafted rules. This raises a
question â€“ can we mine constraints and rules from
data based on a learning algorithm?

In this paper, we present a general framework for
mining constraints from data. In particular, we
consider the inference in structured output pre-
diction as an integer linear programming (ILP)
problem. Then, given the coefï¬cients of the objec-
tive function and the corresponding solution, we
mine the underlying constraints by estimating the
outer and inner polytopes of the feasible set. We
verify the proposed constraint mining algorithm
in various synthetic and real-world applications
and demonstrate that the proposed approach suc-
cessfully identiï¬es the feasible set at scale. In
particular, we show that our approach can learn to
solve 9x9 Sudoku puzzles and minimal spanning
tree problems from examples without providing
the underlying rules. Our algorithm can also in-
tegrate with a neural network model to learn the
hierarchical label structure of a multi-label clas-
siï¬cation task. Besides, we provide a theoretical
analysis about the tightness of the polytopes and
the reliability of the mined constraints.

1
2
0
2

n
u
J

1
1

]

G
L
.
s
c
[

2
v
6
3
8
0
1
.
6
0
0
2
:
v
i
X
r
a

1. Introduction

A variety of machine learning problems involve making
coherent decisions over a set of output variables, where
the dependencies between them can be described by con-

1Department of Computer Science, University of Cali-
fornia, Los Angeles, USA. Correspondence to: Tao Meng
<tmeng@cs.ucla.edu>, Kai-Wei Chang <kwchang@cs.ucla.edu>.

Proceedings of the 38 th International Conference on Machine
Learning, PMLR 139, 2021. Copyright 2021 by the author(s).

straints (Punyakanok et al., 2005; Samdani & Roth, 2012;
Nowozin & Lampert, 2011). For example, in part-of-speech
tagging, a constraint specifying that every sentence should
contain at least one verb and one noun can greatly improve
the performance (Ganchev et al., 2010). Similarly, in hier-
archical multi-label classiï¬cation, a ï¬gure labeled â€˜ï¬‚owerâ€™
should also be labeled â€˜plantâ€™ as well (Dimitrovski et al.,
2011). To incorporate constraints with learned models, one
popular method is to formulate the inference problem into
an integer linear programming (ILP) (Roth & Yih, 2004).
This framework is general and can cope with constraints
formed as propositional logics (Hooker, 1988; Richardson
& Domingos, 2006). This approach has been widely used in
natural language processing, computer vision, and many ap-
plication areas. It has demonstrated great performance gains
in various applications (e.g., Martins et al. (2010); Nowozin
& Lampert (2011); Roth & Yih (2004); Goldwasser et al.
(2012); Chang et al. (2008); Meng et al. (2019)).1

In the literature, existing works most focus on how to uti-
lize constraints to facilitate learning. They mostly assume
constraints are given as a priori. However, for some applica-
tions, manually identifying constraints is tedious. Besides,
some constraints are obscure and cannot be easily identi-
ï¬ed by human experts.2 Inspired by representation learning
methods automate feature extraction, we envision that an
artiï¬cial intelligence system that could automatically recog-
nize underlying constraints among output labels from data
and incorporate them in the prediction time.

To illustrate the goal, consider the following learning prob-
lem. We are given a set of input-output pairs as training
data, where each input is an adjacency matrix of a graph
representing the distances between nodes and the output is
corresponding minimal spanning tree (MST). Our goal is
to train a model to generate MST of a given graph (adja-
cency matrix) without telling the model that the output is a

1Solving ILP is in general NP-hard. However, in practice,
inference problems often can be solved efï¬ciently using a com-
mercial ILP solver or an approximation inference technique (e.g.,
LP-relaxation (Fromer & Globerson, 2009), loopy belief proproga-
tion (Murphy et al., 2013)). See discussion in (Finley & Joachims,
2008).

2For example, if we shufï¬‚e columns of all sudoku puzzles
with the same order, the puzzles still follow a set of constraints.
However, it is hard for humans to recognize these underlying rules.

 
 
 
 
 
 
An Integer Linear Programming Framework for Mining Constraints from Data

tree. Speciï¬cally, the model has to identify the underlying
constraints that are satisï¬ed by all training samples from a
family of candidate constraints. The success in this problem
has a great potential; however, there are limited prior works
except some methods extending the basic Valiantâ€™s algo-
rithm (Valiant, 1984), such as inductive logic programming
(Muggleton & Raedt, 1994; Riedel & Clarke, 2006) and
constraint learning (Bessiere et al., 2013; 2016; 2017). Most
of them use logic clauses to formulate the constraints and
solve the satisï¬ability problem. However, it is unclear how
to incorporate them with machine learning models.

Inspired by the great success of ILP in constrained output
structure predictions, we propose a novel framework to for-
mulate the constraint learning based on ILP. In particular,
we estimate the feasible set deï¬ned by the constraints and
explore three techniques: 1) mining inequality constraints to
form a superset of the feasible set by constructing an outer
polytope based on seen data; 2) mining equality constraints
by dimension reduction of the superset; and 3) mining com-
plex constraints with a latent variable method. We also
propose an algorithm to induce the subset of the feasible
set for evaluating the quality of the constraints. Note that
although the constraint mining algorithm is designed under
the ILP framework, our algorithm does not involve solving
ILP when mining the constraints.

We evaluate the proposed framework on three tasks: MST,
Sudoku, and hierarchical multi-label classiï¬cation. The
ï¬rst two tasks demonstrate that our method is able to
mine complex structures and deal with large label space.
For example, in Sudoku, our model can perfectly learn
the underlying rules and achieve 100% accuracy. We
then incorporate the proposed approach with a learned
neural network on hierarchical multi-label classiï¬cation.
Our framework helps models learn the structure in label
space and improve the performance by over 10% com-
pared with the baseline. Finally, we conduct a compre-
hensive analysis on MST. We verify the constraints learned
by our approaches by comparing the corresponding fea-
sible set with the ground truth. We also provide a theo-
retical estimation on the feasible set size and compare it
with the empirical results and discuss the running time of
the algorithm. The source code and data are available at
https://github.com/uclanlp/ILPLearning.

2. Related Work

Constraints Formulated by Integer Linear Program-
ming
ILP is widely used in formulating constrained in-
ference in machine learning tasks, including semantic role
labeling (Punyakanok et al., 2004), entity-relation extrac-
tion (Roth & Yih, 2005), sentence compression (Clarke &
Lapata, 2008), dependency parsing (Martins et al., 2009),
multi-lingual transfer (Meng et al., 2019), corefernece res-

olution (Chang et al., 2013), relation extraction (Ye et al.,
2020) and reducing bias ampliï¬cation (Zhao et al., 2017).
These works use pre-deï¬ned constraints to formulate ILPs.
In contrast, we aim to mine constraints from data.

Mining Constraints From Data Raedt et al. (2018) sum-
marize the milestones in constraint mining. Learning logical
rules from data can be traced back to the Valiantâ€™s algorithm
(Valiant, 1984) that mines the hard constraints formulated as
kâˆ’CNF. Inductive logic programming (Muggleton & Raedt,
1994; Riedel & Clarke, 2006), as an extension of Valiantâ€™s
Algorithm, is aiming to deal with general ï¬rst-order logic.
It has been used in both real world (Bratko & King, 1994)
and mathematical applications (Colton & Muggleton, 2006).
Constraint learning (Bessiere et al., 2013; 2016; 2017) com-
bines these two approaches together. Besides, several ef-
forts have been put on relaxing logical constraints such as
soft constraint learning (Rossi & Sperduti, 2004). Wang
et al. (2019) use semideï¬nite programming (SDP) (Wang &
Kolter, 2019) to relax the maxSAT problem and cooperate
with deep learning (see Sec. 4 for comparison). Another
way to relax the logical constraints is to relax the Boolean
variables to be continuous variables (Li et al., 2019; Li &
Srikumar, 2019), or continuous random variables like prob-
abilistic soft logic (Kimmig et al., 2012; Bach et al., 2015;
Embar et al., 2018). Most of these previous works use log-
ics to represent the constraints. In contrast, we design a
framework based on ILP and use the linear form to for-
mulate the constraints. This allows us directly incorporate
constraints with inference in structured output predictions.
Some concurrent works (Pan et al., 2020; Tan et al., 2020)
learn constraints by initializing a set of constraints and up-
dating them based on gradient, but it is not able to obtain
the guarantee that the constraints are tight and converge to
the ground truth as ours do (see discussion in Sec. 3 and
Sec. 5.1).

3. Mining Constraints with Integer Linear

Programming

We ï¬rst review the constraint mining framework based on
ILP. We then propose an approach to mine constraints by
estimating the outer and inner polytopes of the feasible set.
Finally, we discuss how to extend the framework to capture
complex constraints.

ILP is a linear optimization problem with linear constraints
and the values of variables are restricted to integers. For-
mally, the ILP problem can be formulated as

maxyâˆˆZd w Â· y

s.t. Ay â‰¤ b,

(1)

where w âˆˆ Rd is the coefï¬cients of the objective function
(a.k.a. weights) and y is an integer vector that encodes

An Integer Linear Programming Framework for Mining Constraints from Data

(a) Outer polytope (SO)

(b) Inner polytope (SI )

Figure 1: The pentagons (blue solid line) in Fig. 1a and 1b
show the outer and the inner polytopes of 5 training samples
{wi, yi}5
i=1 (see Sec. 3.1). The dashed red line shows the
boundary of the feasible set (yellow region). We also show
wi as the normal vector of the outer line.

the output label.3 The matrix A and vector b specify the
constraints. We use Sâˆ— to denote the feasible set deï¬ned by
the constraints. Various structure prediction problems can be
casted into the ILP formulation. For example, dependency
parsing can be formulated as ï¬nding the maximum spanning
tree in a directed graph (McDonald et al., 2005), where each
node represents a word and the edge wij represents how
likely the word i is the dependent of the word j predicted
by a model. y = {yij}, yij âˆˆ {0, 1} is the indicator of
the edges in the resulting tree. The objective in Eq. (1)
then can be interpreted as the total score of edges in y,
and the constraints, described by (A, b), restrict y to be a
tree (Martins et al., 2009).

Prior works (see, e.g., (Martins et al., 2009)) mostly assume
the constraints (A, b) are given. However, in this paper,
we assume (A, b) are unknown and our goal is to identify
the underlying feasible set Sâˆ— spanned by (A, b) using a
set of objective-solution pairs {(w(i), y(i))}k
i=1 that satisfy
constraints deï¬ned by (A, b). For example, in MST, giving
a set of weights w(i) (adjacency matrix) with the corre-
sponding optimal solution y(i), our algorithm identiï¬es the
structure of the output y form a tree structure.

In the following, we introduce algorithms to estimate the
feasible set for mining the underlying constraints. These
mined constraints deï¬ne an superset of the feasible set. We
also design an algorithm to get the subset of the feasible set
to evaluate the estimation.

3.1. Mining Inequality Constraints

In the following, we discuss how to estimate the underlying
feasible set Sâˆ— associated with inequality constraints. Our
approach ï¬nds a convex hull SO deï¬ned by a set of learned
inequality constraints that is an outer polytope (i.e., super-

3In structure output prediction, usually each element of y takes
value 1 or 0, indicating if a speciï¬c value is assign to a speciï¬c
output variable or not. w are the scores of sub-components of
output assigned by a model.

set) of the feasible set Sâˆ—. We also propose a method to get
an inner polytope SI that is a subset of Sâˆ— and use the gap
between the SO and SI to estimate the quality of approxi-
mation. Figure 1 shows an example about SI , SO deï¬ned
by 5 training samples in a 2-dimensional space. We denote
I , S(i)
S(i)
O as the inner and outer polytopes after considering
the ï¬rst i samples.

Outer polytope We ï¬rst introduce how to identify SO.
Assume that we already know part of the constraints A(cid:48), b(cid:48).
We initialize the outer polytope as S(0)
O = {y âˆˆ Zd | A(cid:48)y â‰¤
b(cid:48)} (if A(cid:48), b(cid:48) are empty, S(0)
O = Zd). For every training
sample (w(i), y(i)), we consider adding the following con-
straint to the outer polytope

w(i) Â· y â‰¤ w(i) Â· y(i).

(2)

Since y(i) is the optimal solution under weight w(i), all the
points in the feasible set must sit in the half-space deï¬ned
by Eq. (2), otherwise y(i) is not the optimal solution. We
O = {y âˆˆ S(0)
have S(i)
O | w(j) Â· y â‰¤ w(j) Â· y(j), j =
O âŠ† Â· Â· Â· âŠ† S(1)
1, 2, . . . , i}, and Sâˆ— âŠ† SO = S(k)
The outer polytope S(i)
O (the upper bound of the feasible set
Sâˆ—) is tight when we only observe the ï¬rst i samples. That is,
assuming S(i)
O is the feasible set, if we query w(1), . . . , w(i),
we will ï¬nd y(1), . . . , y(i) are (one of) the optimal solutions.
Therefore, S(i)
O is a possible feasible set. Since Sâˆ— âŠ† S(i)
O ,
this bound is tight. This shows that without any further
assumption, we cannot do better than SO for estimating the
outer polytope of the feasible set Sâˆ—.

O âŠ† S(0)
O .

In the test time, we are requested to conduct inference with
unseen input weight w(q). Since all constraints in SO are
linear, we solve the following ILP problem

maxyâˆˆZd w(q) Â· y

s.t.

. . . w(k)(cid:3)T

(cid:2)A(cid:48)T w(1)
â‰¤ (cid:2)b(cid:48)T w(1) Â· y(1)

y

(3)

. . . w(k) Â· y(k)(cid:3)T
.

The objective value of the solution of Eq. (3) might be
higher than the optimum as the solution might not satisfy all
the underlying constraints. We will show that empirically
the outer polytope can approximate the feasible set effec-
tively in Sec. 4. Although the number of constraints grows
linearly with the number of training samples, we ï¬nd that
empirically the inference time does not grow much.4

4In structure output prediction, constraints are often associ-
ated with only the problem structure. Therefore, all the inference
instances share the same constraint set, and the overhead in solv-
ing ILPs is amortized (Srikumar et al., 2012; Kundu et al., 2013;
Chang et al., 2015).

ğ’šğŸğ’˜ğŸğ’šğŸğ’šğŸ‘ğ’šğŸ’ğ’šğŸ“ğ’˜ğŸ“ğ’˜ğŸ’ğ’˜ğŸ‘ğ’˜ğŸğ’šğŸğ’˜ğŸğ’šğŸğ’šğŸ‘ğ’šğŸ’ğ’šğŸ“ğ’˜ğŸ“ğ’˜ğŸ’ğ’˜ğŸ‘ğ’˜ğŸAn Integer Linear Programming Framework for Mining Constraints from Data

Inner polytope To understand the quality of SO, we
also construct the inner polytope SI , then we can use
the gap between SO and SI to estimate the quality of
the approximation. We ï¬rst initialize S(0)
I = âˆ…. For
(w(i), y(i)), we set S(i)
I =
every training sample i:
convex_hull({y(1), y(2), . . . , y(i)}), and then S(iâˆ’1)
âŠ†
S(i)
I . Since all {y(i)} are in the feasible set that is con-
vex, all the convex hulls must be subsets of the feasible set.
Therefore, we have S(0)
I = SI âŠ† Sâˆ—.

I âŠ† S(1)
Similarly, we can prove that S(i)
is a possible feasible set
I
after observing the ï¬rst i samples, which means as a lower
bound, S(i)
I

I âŠ† Â· Â· Â· âŠ† S(k)

is also tight.

I

When we conduct inference with SI , we examine every
vertex of the convex hull and choose the one with the optimal
objective. Since it is an inner polytope of the feasible set,
the solution is guaranteed to satisfy all constraints, and the
objective value can be lower than the optimum. Although
inner polytope and outer polytope methods are two separate
algorithms, the gap between their objective function value
and the size of the feasible set provide an estimation of the
tightness of the bound.

In Sec. 5.1 we will show that, empirically, this approach
converges with reasonable number of training samples and
running time is discussed in Sec. 5.2.

Dealing with predicted weights When we incorporate
the proposed approach with a structured prediction model,
the weights w are predicted by a base model. In this situ-
ation, the predicted weights w can be noisy and the corre-
sponding label y may not be the optimal solution to Eq. (3).
As the result, the outer polytope may not contain some fea-
sible solutions as they are ï¬ltered out later by the algorithm.
To handle the noise, we adapt Eq. (2) to

w(i) Â· y â‰¤ w(i) Â· y(i) + Î¾i, i âˆˆ [k],

(4)

We denote this d(cid:48)âˆ’dimensional afï¬ne sub-space as SD =
{y | Weq Â· y = c}. We can obtain Weq, c by solving the
kernel of [yT , 1], which is

(cid:20)yT
1
1

yT
2
1

. . . yT
n
1
. . .

(cid:21)

(cid:21)T (cid:20)W T
eq
âˆ’cT

= 0.

(5)

The intersection of SO and SD is used to replace SO as the
outer polytope of the feasible set: SI âŠ† Sâˆ— âŠ† SO âˆ© SD =
{y âˆˆ SO | Weqy = c}. For the reliability of this algorithm,
we give two lemmas:

Lemma 1: Given training data {(w(i), y(i))}M
i=1 that sat-
isfy the ILP constraints set deï¬ned in Eq.(1), if the ILP
contains an equality constraint Weq Â· y = c, our equality
constraint mining algorithm can identify it.

Proof Sketch: For any underlying equality constraint
Weq Â· y = c, all the labels of training points yi should
satisfy it and it must be in the kernel of Eq. (5).

Lemma 2: For an equality constraint given by this algo-
rithm, the probability that this constraint does not hold for
the optimal solution of a random query is less than 1
eM ,
where M is the number of training points.

Proof Sketch: We use Dw to denote the domain of the
query (weights), and f âˆ—(w) as the ground truth solu-
tion for the query w. We denote the equality constraint
learned by the algorithm is g(y) = 0. Therefore, all the
data yi in the training data satisfy g(yi) = 0. We let
p = P rwâˆ¼Dw (g(f âˆ—(w) = 0)). The probability of all the
training data satisfying g(yi) = 0 is pM . Thus, the proba-
bility that this constraint does not hold for a random query
solution is

pM (1 âˆ’ p) â‰¤

M M
(M + 1)M +1 <

1
eM

.

where Î¾i is a slack variable to ensure every training point
yi âˆˆ Sâˆ— satisï¬es Eq. (4)

3.3. Latent Variables

Î¾i = minjâˆˆ[k]{w(i) Â· y(j) âˆ’ w(i) Â· y(i)}.

3.2. Mining Equality Constraints

When there are equality constraints in the output label space.
Effectively, the dimension of the output space is reduced.
However, the dimension of the set SO is the same as that of
w and y. Therefore, this inspires us to ï¬nd the sub-space of
SO to further tighten the feasible set.

For example, in the MST problem the number of edges
we select is exact N âˆ’ 1 where N is the number of nodes.
Formally, the linear constraint 1 Â· y = N âˆ’ 1 holds for every
feasible point y.

Some prediction problems involve constraints with complex
logics and require auxiliary variables to model the problem
structure. Thanks to the ï¬‚exibility of the ILP framework, we
can introduce latent variables to extend the expressiveness
of the constraint mining framework:

max
yâˆˆZd

w Â· y

s.t. Apre

(cid:21)

(cid:20)y
h

â‰¤ bpre, A

(cid:21)

(cid:20)y
h

â‰¤ b,

(6)
where h are latent variables, and they appear in the con-
straints but not in the objective function in Eq. (6). Despite
that h is not part of the output, it facilitates to formulate the
ILP problem. In general, a set of pre-deï¬ned constraints
(Apre, bpre) are given to describe the relations between y

An Integer Linear Programming Framework for Mining Constraints from Data

and h. Then, given a set of {(w(i), y(i))}k
learn the constraints (A, b).

i=1, our goal is to

The latent variables can help us formulate the constraints
better in the ILP framework. Speciï¬cally, with the help
of the latent variables, some inequality constraints can be
reformulated as the equality ones. As it is easier to identify
equality constraints in our framework, this will make the
constraints we learn more accurate. We adapt the method
in Sec 3.2 to solve the kernel of the matrix [yT , hT , 1]T .
In this way, we can mine equality constraints with respect
to h and then derive the outer polytope SO. Since h is
determined by the variables y, adding constraints on h also
reduces the size of SO.

For example, consider multi-label classiï¬cation with out-
put y, where yi, i = 1 . . . m is a binary indicator of class
i.
If we would like to identify the constraints between
pairs of labels from {(w(i), y(i))}, we can introduce a set
of latent variables {hi,j,b1,b2}i,j=1...m;b1,b2âˆˆ{0,1}} with pre-
deï¬ned equality constraints hi,j,b1,b2 = (yi = b1) âˆ§ (yj =
b2), âˆ€i, j, b1, b2. They can be further formulated as

âˆ€i, j,

ï£±
ï£´ï£²

ï£´ï£³

hi,j,1,0 + hi,j,1,1 = yi
hi,j,0,1 + hi,j,1,1 = yj
(cid:80)

b1,b2âˆˆ{0,1} hi,j,b1,b2 = 1.

By introducing hi,j,b1,b2 , we are able to capture some corre-
lations between labels better. For example, label i and label
j cannot be positive at the same time can be represented
by an equality constraint hi,j,1,1 = 0. Without latent vari-
ables, it can only be represented by inequality constraint
yi + yj â‰¤ 1. In this case, the introducing of latent variables
make the learned constraints more accurate.

4. Experiments

We experiment on two synthetic problems, 9 Ã— 9 Sudoku
and minimal spanning tree (MST), to show that the pro-
posed methods can capture different kinds of constraints.
We then incorporate the proposed technique with a feed-
forward neural network in a hierarchical multi-label classiï¬-
cation problem. For all the experiments, we use the Gurobi
v8.1.1 (Gurobi Optimization, 2019) as the ILP solver.5

4.1. Sudoku

In Sudoku, given a 9 Ã— 9 grid with numbers partially ï¬lled
in, the player is requested to ï¬ll in the remaining of the
grid with constraints that each 3 Ã— 3 sub-grid, each column
and each row must contain all the numbers of 1, 2, . . . , 9.
The size of the feasible set is 6.67 Ã— 1021 (Felgenhauer &

5We conï¬gure the ILP solver such that it outputs optimal solu-
tion (i.e., set M IP Gap = 0). The relaxed LP will be discussed
in Sec. 5.2.

Table 1: Sudoku results. EQ stands for equality constraint
mining. Performance is reported in entry-level accuracy.
Our approaches can successfully identify the underlying
Sudoku constraints.

(a) Original Sudoku

Model
ConvNet (Park, 2018)
ConvNetMask (Park, 2018)
SATNet (Wang et al., 2019)
Outer + EQ (ours)

Train
Test
72.6% 0.04%
91.4% 15.1%
99.8% 98.3%
100% 100%

(b) Permuted Sudoku

Model
ConvNet (Park, 2018)
ConvNetMask (Park, 2018)
SATNet (Wang et al., 2019)
Outer + EQ (ours)

Test
0%
0%

Train
0%
0.01%
99.7% 98.3%
100% 100%

Jarvis, 2005) which is extremely large. Our goal is to use the
proposed method to solve Sudoku puzzles without telling
the model the rules.

We follow the experiment setting in Wang et al. (2019) to
represent the solution of Sudoku as a vector y âˆˆ {0, 1}729,
where yijk denotes the iâˆ’th row jâˆ’th column is the number
k or not. The partially ï¬lled entries (ri, ci) = ni (i.e., row
ri column ci is number ni) are encoded in w âˆˆ {0, 1}729,
where we set the corresponding weight for wricini to be 1
and the rest to be 0. In this way, maximizing the objective
function w Â· y guarantees yijk = 1 if wijk = 1. Then
given pairs of {w, y}, our methods mine the underlying
constraints A and b in Eq. (3).

We experiment on the dataset introduced in Wang et al.
(2019). The dataset contains 9, 000 training and 1, 000 test
samples, each of which has a unique solution. We also
conduct experiments in the permuted setting (Wang et al.,
2019), where a pre-deï¬ned permutation function is used to
shufï¬‚e the 9 Ã— 9 grid. In the permuted setting, it is almost
impossible for humans to identify the underlying rules, de-
spite the puzzle is still ï¬lled in a certain order. We follow the
conï¬guration in Wang et al. (2019) to compare our approach
with a convolution neural network for Sudoku (Park, 2018)
(ConvNet) and SATNet (Wang et al., 2019) and report our
results along with their published results in Table 1.

As shown in the table, by using the equality constraints
mining technique, our framework can realize the Sudoku
rules and achieve 100% accuracy. The constraints we mine
reduce the size of candidate solution space from 2729 to
6.67 Ã— 1021 (i.e., the number of feasible Sudoku puzzles).
Note that our approaches, as well as SATNet, do not utilize
the position clues in the data. Therefore, it is not affected
by permutations.

An Integer Linear Programming Framework for Mining Constraints from Data

Table 2: MST results in exact match (EM) accuracy in Train
and Test, the average edge accuracy (Edge) and the ratio of
solutions that are feasible (Feasibility). Here, the feasibility
means the solution forms a tree.

(a) 10, 000 training samples

Model
NN
Inner
Outer
Outer+EQ

Model
NN
Inner
Outer
Outer+EQ

Train EM Test EM Test Edge Test Feasibility

8.3%
100%
100%
100%

6.9%
41.6%
71.1%
72.9%

89.3%
93.7%
96.1%
96.1%

(b) 20, 000 training samples

12.8%
100%
71.1%
72.9%

Train EM Test EM Test Edge Test Feasibility

9.5%
100%
100%
100%

10.4%
69.2%
87.2%
91.8%

91.1%
97.0%
98.0%
98.7%

13.4%
100 %
87.2%
91.8%

In fact, the equality constraints we learn are exactly the rules
of Sudoku. The Sudoku rules can be represented linearly as

9
(cid:88)

i=1

ykij = 1,

9
(cid:88)

i=1

yjki = 1, âˆ€j, k,

(7)

y(x+i)(y+j)k = 1, âˆ€x, y âˆˆ {0, 3, 6}âˆ€k.

3
(cid:88)

3
(cid:88)

i=1

j=1

We use Sâˆ— to denote the space deï¬ned by Eq. (10) and Ë†S as
the space of our constraints. We verify the Sâˆ— = Ë†S by

1. Verifying that each constraint in Sâˆ— is indicated by
the constraints we learn. This property guarantee that
Sâˆ— âŠ† Ë†S.

2. Comparing the dimension of Sâˆ— and S. We ï¬nd that

d(Sâˆ—) = d( Ë†S) = 249.

In this way, we conï¬rm that our framework can mine the
underlying Sudoku rules successfully.

4.2. Minimal Spanning Tree

As discussed in Sec. 1, inference problems in many struc-
tured output prediction applications (e.g., dependency pars-
ing) can be modeled as searching the minimal (or maximal)
spanning tree (MST). In the following, we verify if the pro-
posed approach can identify the structure of solution is a
tree by merely providing pairs of adjacency matrices and
the corresponding MST. We encode the MST problem as
described in Sec. 3.

We generate a dataset with 7 nodes. The dataset contains
20, 000 training and 500 test data. Every data point consists
of an adjacency matrix serialized in a vector w, where wi,j
represents the distance between node i and node j, and
its corresponding MST. The entry in the adjacency matrix
is independently sampled from a uniform distribution in

Figure 2: Results on ImCLEF07A in EM accuracy using
base models with different performance levels.

[âˆ’1, 1]. We ï¬ltered out the adjacency matrix with identical
values to ensure every sample has a unique optimal solution.

the inner polytope (Inner), outer polytope
We test
(Outer) and outer polytope with equality constraint min-
ing (Outer+EQ) methods. We compare our approaches
with fully connected feed-forward neural networks (NN)
with 1, 2 or 3 layers, which directly learn the association
between w and y and the hyper-parameters are given in the
Appendix. We set the hidden dimension to be 50. Despite
that our methods do not have hyper-parameters, to tune the
neural network, we generate another 500 dev data points.

Table 2 shows the results in exact match (i.e., correct MST)
and edge accuracies. The results show that Baseline-NN is
unable to learn the tree structure from the given examples.
We ï¬nd that NN can learn reasonably well in each individ-
ual edge but is terrible to capture the output is a tree. In
particular, in 87.2% and 86.6% of cases for 10,000, 20,000
training samples, respectively, the output by NN is not fea-
sible (not a tree). Therefore, its exact match accuracy is
low. In comparison, the proposed approaches Outer and
Outer+EQ mostly produce feasible solutions6, resulting in
much higher exact match accuracy. Comparing the results
for 10, 000 and 20, 000 data points, we ï¬nd that Outer+EQ
is more effective than NN when doubling the training data
as it improves 20% exact match accuracy.

4.3. Hierarchical Multi-label Classiï¬cation

Finally, we apply the proposed approaches to a real-world
problem and demonstrate its ability to cooperate with
machine learning models. We conduct experiments on
ImCLEF07A (Dimitrovski et al., 2011), which contains
10, 000 training samples and 1, 006 test samples. Each sam-

6Note that for Outer and Outer+EQ methods, the results of
feasibility are the same as test EM because all feasible trees are in
the outer polytope. Therefore, if a model outputs a feasible tree,
the tree is guaranteed to be optimal.

010203040506070NN EM accuracy (%)01020304050607080Model EM accuracy (%)BaselineOuterOuter + LatentAn Integer Linear Programming Framework for Mining Constraints from Data

Table 3: Detailed results (grey zone in Fig. 2) evaluated
by exact match accuracy (EM), the ratio of solutions that
are feasible (Feasibility), and average accuracy of label
assignments (Label Acc.).

learned by Outer can not ï¬lter out any point in the space.
Therefore, Outer achieves the same performance as Base-
line. However, Outer+Latent can still mine constraints
related to the latent variable and improve the performance.

Model
Baseline
Inner
Outer
Outer+Latent

Test EM Test Feasibility
62.6%
79.8%
71.3%
79.8%

73.8%
100%
89.7%
100%

Test Label Acc.
98.92%
98.98%
98.85%
98.98%

ple has 80 features and a set of labels selected from 96
classes. There is a hierarchy among the labels and the depth
of the hierarchical structure is 4. A feasible label set forms
a path from the root to a leaf node.

The base model is a 3-layer fully connected feed-forward
neural network with hidden dimension 80. This model out-
puts a vector c, where each component ci âˆˆ [0, 1] is pre-
dicted independently to the input instance. For the baseline
model, if ci > 0.5, then the label i is positive.

We take the base model as a sub-routine and use it to assign
weight w in Eq.
(3). Speciï¬cally, w = c âˆ’ 0.5 Ã— 1.
Without constraints, solving the ILP in Eq. (3) is equivalent
to make predicton by the baseline model. We evaluate 1)
the inner polytope method (Inner), 2) the outer polytope
method (Outer) and 3) the outer polytope method with latent
variables (Outer+Latent). In Outer, as w is generated
by a predicted model, we use Eq. (4) to allow noise. In
Outer+Latent, we use the label pairwise latent variables
deï¬ned in Sec 3.3. To reduce the label spaces, we follow
the convention to consider only induce latent variables to
label pairs that occur in the training set.

Different from Sec. 4.1 and 4.2, the weight w is a score
vector predicted by the base model. To understand how the
constraint mining approaches incorporate with base models
with different performance levels, we train multiple versions
of base models with different number of layers and training
epochs then demonstrate the performance of our approach
with these base models. The hyper-parameters for these
models are given in the Appendix. The results are shown in
Fig. 2.

Results show that Outer and Outer+Latent
improve
the base models in all cases. Even with a weak base
model with only 10% in exact match accuracy, Outer and
Outer+Latent are able to learn underlying constraints and
improve the performance by more than 20%. The difference
between Outer and Outer+Latent is not apparent when the
base model is inaccurate. However, when the base model
performance increases, Outer+Latent is capable of captur-
ing more ï¬ne-grained constraints than Outer and achieves
better performance. When the baseline achieves 0 loss in
training data (the right-most column points), the constraints

Table 3 highlights the detailed results with one base model.7
Outer improves Baseline about 12% in exact match accu-
racy and 16% in feasibility. This demonstrates Outer can
successfully ï¬lter out many infeasible solutions and guide
the model to ï¬nd the correct ones. Inner learns exactly the
feasible set as all pairs of labels appear in the test set also
appear in the training. Similarly, Outer+Latent is able to
identify all dependencies between labels and achieves high
performance. The classes in this task have a tree structure
and it has depth 4 including the root (root is a virtual con-
cept, and it is not a real class). We use p(x) to denote the
parent class of class x, and Li to denote the set of classes
on layer i, i âˆˆ {1, 2, 3}. We verify the constraints with the
same method in Sec. 4.1. The mined equality constraints
are the linear transformation of the following constraints:

(cid:88)

jâˆˆLi

yj = 1, âˆ€i âˆˆ {1, 2, 3},

hparent(x),x,0,1 = 0, âˆ€x : parent(x) (cid:54)= root.

(8)

5. Analysis and Discussion

5.1. Feasible Set Size Analysis

We provide a theoretical analysis about the convergence
speed of the proposed approaches by estimating the car-
dinality of the outer polytope and inner polytopes. Our
methods in Sec. 3 estimate the feasible set by squeezing
the outer polytope and enlarging the inner polytope. We
analyze how the sizes of outer polytope and inner polytope
change with respect to the number of training samples.

We denote the size of ground truth feasible set Sâˆ— as M , the
size of universal label space is N . The weights w are drawn
from the distribution Dw. For each point i, we use pi to
denote the probability that given a randomly sampled weight
w âˆ¼ Dw, y(i) get higher score than all the feasible points.
Formally, pi = Pwâˆ¼Dw {w Â· y(i) â‰¥ w Â· y(j), âˆ€j âˆˆ Sâˆ—}. The
following lemma bounds the expectation sizes of the outer
and inner polygons. Full proof is in the Appendix.

Lemma 3: The expectation of the sizes of outer and inner
polygon is given by

E[|SI |] = M âˆ’

E[|SO|] = M +

(cid:88)

iâˆˆSâˆ—

(cid:88)

j /âˆˆSâˆ—

(1 âˆ’ pi)k ;

(1 âˆ’ pj)k.

(9)

7We choose the second best baseline model since the best one
gets 100% accuracy in training set, which causes the inequality
constraints learned by Outer method ï¬lter out nothing.

An Integer Linear Programming Framework for Mining Constraints from Data

Table 4: Running time in seconds for experiments. The
training time is computed by averaging in 3 runs, while
inference time is computed by averaging in 100 samples.

Experiment

MST

Sudoku

HMC

Model
Baseline NN
Outer
Outer+EQ
ConvNet
Outer+EQ
Baseline NN
Outer
Outer+Latent

Training
190
24.1
26.5
636.4
5.2
44.9
560.3
599.3

Inference
5e-4
7.9
3.8
5e-4
1.2
4e-4
1.1
7.1

5.2. Discussion about Running Time

There are two main factors affecting the running time: the
number of data samples, the number of constraints K, and
the size of the output variables D. Our approach contains
two steps: identifying the feasible set (training) and solv-
ing ILPs (inference). In training, as shown in Sec 3, our
approach is linear in K since we only needs to pass all sam-
ples once, and no worse than quadratic in D. In inference,
we solve ILP which is generally NP-hard, and the main
factor in complexity is D. However, for most structured
prediction tasks, D is small. In our experiments, D is 21
and 729 and 96 in MST, Sudoku and HMC, respectively.

Table 4 shows the training and test running time of our ap-
proaches compared to neural network models. In training,
our approach is more efï¬cient than the baseline neural net-
work in the Sudoku and MST experiments. For the HMC
experiment, the training time of our approach includes up-
dating the model parameters of the underlying neural net-
works. Therefore, the training time is longer compared to
the Sudoku and MST cases.

For the inference time, we report the average time on solv-
ing one test sample. Despite ILP is NP-hard, a commer-
cial solver (e.g., Gurobi) is capable of solving the problem
within a reasonable time. Therefore, without carefully en-
gineering to optimize the running time, the ILP solver can
produce solutions within a few seconds.

To empirically understand the scalability of our approach
in the inference, we test the inference time in the MST
experiment with larger graph. Here we ï¬x the number of
constraints (number of training sampels) as 20, 000. The
results are shown in Fig. 4. We ï¬nd that despite some
extreme cases, the inference time grows generally linearly
in terms of the number of variables empirically.

Note that although the constraints are mined using the ILP
framework, it does not mean that the inference has to be
solved by an ILP solver. Once the constraints are identiï¬ed,
one can design a speciï¬c constraint solver to speed up the
inference. Besides, the ILP inference can be accelerated

(a) Set size

(b) The dist. of pj, j /âˆˆ Sâˆ—

Figure 3: On the left Fig. 3a shows the empirical and
expectation sizes of outer and inner polytope, comparing
with ground truth. E[|SO|](1/(M +1)) is the expectation of
outer polytope size estimated by pj = 1
M +1 while E[|SO|]
is estimated with empirical pj. Note that the empirical inner
polytope and its theoretical curve almost coincide. On the
right Fig. 3b shows the distribution of pj estimated from
20, 000 training data comparing with 1/(M + 1).

Proof sketch: We ï¬rst consider the outer polygon. The
point j out of the feasible set appears in the outer polygon
if and only if it is not ï¬ltered out by any constraints, which
is (1 âˆ’ pj)k.

We then consider the inner polygon. The point i appears in
the inner polygon if and only if at least one training sample
takes it as the optimal solution, which is 1 âˆ’ (1 âˆ’ pi)k.

Case study: MST We take MST discussed in Sec.4.2 as
an example. According to Matrix-Tree Theorem (Chaiken
& Kleitman, 1978), we know that the number of spanning
trees is M = 16, 807. The universal set size before mining
equality constraints is NO = 221 = 2, 097, 152. However,
with the equality constraints mining method, we can identify
the constraint (cid:80)21
i=1 yi = 6, (i.e., number of edges is 6).
With this constraint the size of the space is reduced to N =
(cid:0)21
6

(cid:1) = 54, 264.

M for i âˆˆ Sâˆ— and pj = 1

pi in Eq. (9) is difï¬cult to estimate directly; therefore, we
approximate it by pi = 1
M +1
for j /âˆˆ Sâˆ—. The approximation is exact if the follow-
ing assumption holds (see details and proof in Appendix).
Data symmetric: for k different points y(1), y(2), . . . , y(k),
Pwâˆ¼Dw {w Â· y(1) â‰¥ w Â· y(i), i âˆˆ [k]} = 1
k . MST only sat-
isï¬es the part of the assumption, therefore, for i âˆˆ Sâˆ—, the
approximation pi = 1
M is close, and there is a gap between
empirical pj(j /âˆˆ Sâˆ—) compared with
M +1 (see Fig. 3b),
this causes the gap between the empirical result and the esti-
mated expectation about the outer polytope. Fig. 3a shows
the empirical sizes of outer and inner polytope |SO|, |SI |,
with their theoretical expectation in Eq. (9) and the ground
truth |Sâˆ—|. The expectation of Inner perfectly ï¬ts the em-
pirical results and the two curves are almost coincide. Both
of the Outer and Inner methods eventually converge to the
ground truth, and the Outer method is closer.

1

05000100001500020000#training samples0100002000030000400005000060000#points in setEmpirical |S_O|Empirical |S_I|E[|S_O|] (1/(M+1))E[|S_O|]E[|S_I|]|S*|0.00000.00030.00060.00090.00120.0015p_j010002000300040005000#pointsdistribution of p_j1/(M+1)mean of p_jAn Integer Linear Programming Framework for Mining Constraints from Data

using an approximate inference solver with a trade-off of
moderate performance loss.

6. Conclusion

We propose an integer linear programming framework for
mining constraints from data. The framework is general
and is able to identify underlying constraints in structured
prediction problems. Experiments on synthetic problems
and hierarchical classiï¬cation show that the framework is
capable of mining complex constraints over a label space,
and it can cooperate with neural models. As the ï¬rst paper to
formulate the constraints mining as ILP, we focus on build-
ing the foundation for this potential area and understanding
the properties of the proposed approach.

7. Acknowledgement

This work was supported by National Science Foundation
Grant IIS 1927554 and a Facebook Research Award. We
appreciate Cheng Ma and members of the UCLA-NLP lab
for their inputs and feedback during this project. We also
thank the anonymous reviewers their valuable comments.

References

Bach, S. H., Broecheler, M., Huang, B., and Getoor, L.
Hinge-loss markov random ï¬elds and probabilistic soft
logic. arXiv preprint arXiv:1505.04406, 2015.

Bessiere, C., Coletta, R., Hebrard, E., Katsirelos, G., Lazaar,
N., Narodytska, N., Quimper, C., and Walsh, T. Con-
straint acquisition via partial queries. In IJCAI, 2013.

Bessiere, C., Daoudi, A., Hebrard, E., Katsirelos, G., Lazaar,
N., Mechqrane, Y., Narodytska, N., Quimper, C.-G., and
Walsh, T. New approaches to constraint acquisition. In
Data mining and constraint programming, pp. 51â€“76.
Springer, 2016.

Bessiere, C., Raedt, L. D., Guns, T., Kotthoff, L., Nanni, M.,
Nijssen, S., Oâ€™Sullivan, B., Paparrizou, A., Pedreschi, D.,
and Simonis, H. The inductive constraint programming
loop. IEEE Intelligent Systems, 32(5):44â€“52, 2017.

Bratko, I. and King, R. D. Applications of inductive logic
programming. SIGART Bulletin, 5(1):43â€“49, 1994.

Chaiken, S. and Kleitman, D. J. Matrix tree theorems. Jour-
nal of combinatorial theory, Series A, 24(3):377â€“381,
1978.

Chang, K., Sundararajan, S., and Keerthi, S. S. Tractable
semi-supervised learning of complex structured predic-
tion models. In ECML/PKDD, 2013.

Figure 4: The inference time per instance on MST experi-
ments with different number of variables. Here x-axis is the
number of variables D, which equals to N (N âˆ’ 1)/2. N
is the number of nodes in the graph. y-axis is the inference
time, computed by averaging 100 samples.

(a) EM accuracy

(b) Inference time

Figure 5: The trade-off between inference time and model
accuracy when an approximate inference solver is used.
Results are on MST. The x-axis is the allowed maximum
relative gap between the returned solution and the optimum
solution. On the left ï¬gure, the performance of our approach
drops when the MIPGap is large, but our approach still sig-
niï¬cantly outperforms the neural network baseline (10.4%).
The right ï¬gure shows that the inference time signiï¬cantly
reduces when MIPGap gets large.

by amortizing the computations when solving a batch test
instances (Srikumar et al., 2012; Chang et al., 2015) or
by applying approximate inference algorithms for solving
ILP, e.g., LP relaxation methods (Kulesza & Pereira, 2007;
Martins et al., 2015).

To demonstrate how the performance of our approach is
affected by the approximate ILP solver. We show a trade-off
curve in MST 20,000 training experiments in Fig. 5 by
solving inference using Gurobi with different MIPGap, a
parameter of the Gurobi solver controlling the quality of
solutions. Speciï¬cally, MIPGap speciï¬es the maximum
gap of the objective function values between the returned
solution and the optimum solution. We vary MIPGap from
0 (exact solutions are returned) to 0.15. The experimental
results demonstrate that the inference can be accelerated

050100150200#Variables0.02.55.07.510.012.515.017.520.0Inference Time (s)Outer+EQ0.000.030.060.090.120.15MIPGap020406080EM accuracy (%)Outer+EQBaseline0.000.030.060.090.120.15MIPGap2.02.53.03.54.0Inference Time (s)Outer+EQAn Integer Linear Programming Framework for Mining Constraints from Data

Chang, K., Upadhyay, S., Kundu, G., and Roth, D. Struc-
tural learning with amortized inference. In AAAI, 2015.

Kundu, G., Srikumar, V., and Roth, D. Margin-based de-

composed amortized inference. In ACL, 2013.

Chang, M., Ratinov, L., and Roth, D. Constraints as prior

Li, T. and Srikumar, V. Augmenting neural networks with

knowledge. In ICML, 2008.

ï¬rst-order logic. In ACL, 2019.

Clarke, J. and Lapata, M. Global inference for sentence
compression: An integer linear programming approach.
J. Artif. Intell. Res., 31:399â€“429, 2008.

Li, T., Gupta, V., Mehta, M., and Srikumar, V. A logic-
driven framework for consistency of neural models. In
EMNLP/IJCNLP, 2019.

Colton, S. and Muggleton, S. Mathematical applications
of inductive logic programming. Machine Learning, 64
(1-3):25â€“64, 2006.

Martins, A. F. T., Smith, N. A., and Xing, E. P. Concise
integer linear programming formulations for dependency
parsing. In ACL/IJCNLP, 2009.

Dimitrovski, I., Kocev, D., Loskovska, S., and DÅ¾eroski,
S. Hierarchical annotation of medical images. Pattern
Recognition, 44(10-11):2436â€“2449, 2011.

Embar, V., Sridhar, D., Farnadi, G., and Getoor, L. Scal-
able structure learning for probabilistic soft logic. arXiv
preprint arXiv:1807.00973, 2018.

Felgenhauer, B. and Jarvis, F. Enumerating possible sudoku
grids. Preprint available at http://www. afjarvis. staff.
shef. ac. uk/sudoku/sudoku. pdf, 2005.

Finley, T. and Joachims, T. Training structural svms when

exact inference is intractable. In ICML, 2008.

Fromer, M. and Globerson, A. An LP view of the M-best

MAP problem. In NIPS, 2009.

Ganchev, K., GraÃ§a, J., Gillenwater, J., and Taskar, B. Pos-
terior regularization for structured latent variable models.
J. Mach. Learn. Res., 11:2001â€“2049, 2010.

Goldwasser, D., Srikumar, V., and Roth, D. Predicting
structures in NLP: constrained conditional models and
In HLT-NAACL,
integer linear programming in NLP.
2012.

Gurobi Optimization, L. Gurobi optimizer reference manual,

2019. URL http://www.gurobi.com.

Hooker, J. N. Generalized resolution and cutting planes.
Annals of Operations Research, 12(1):217â€“239, 1988.

Kimmig, A., Bach, S., Broecheler, M., Huang, B., and
Getoor, L. A short introduction to probabilistic soft logic.
In Proceedings of the NIPS Workshop on Probabilistic
Programming: Foundations and Applications, 2012.

Kingma, D. P. and Ba, J. Adam: A method for stochastic
optimization. In Bengio, Y. and LeCun, Y. (eds.), ICLR,
2015.

Kulesza, A. and Pereira, F. Structured learning with approx-

imate inference. In NIPS, 2007.

Martins, A. F. T., Smith, N. A., Xing, E. P., Aguiar, P. M. Q.,
and Figueiredo, M. A. T. Turbo parsers: Dependency
parsing by approximate variational inference. In EMNLP,
2010.

Martins, A. F. T., Figueiredo, M. A. T., Aguiar, P. M. Q.,
Smith, N. A., and Xing, E. P. AD3: alternating direc-
tions dual decomposition for MAP inference in graphical
models. J. Mach. Learn. Res., 16:495â€“545, 2015.

McDonald, R. T., Pereira, F., Ribarov, K., and Hajic, J.
Non-projective dependency parsing using spanning tree
algorithms. In HLT/EMNLP, 2005.

Meng, T., Peng, N., and Chang, K. Target language-aware
constrained inference for cross-lingual dependency pars-
ing. In EMNLP, 2019.

Muggleton, S. and Raedt, L. D. Inductive logic program-
ming: Theory and methods. J. Log. Program., 19/20:
629â€“679, 1994.

Murphy, K., Weiss, Y., and Jordan, M. I. Loopy belief
propagation for approximate inference: An empirical
study. arXiv preprint arXiv:1301.6725, 2013.

Nowozin, S. and Lampert, C. H. Structured learning and
prediction in computer vision. Foundations and Trends
in Computer Graphics and Vision, 6(3-4):185â€“365, 2011.

Pan, X., Mehta, M., and Srikumar, V. Learning constraints
for structured prediction using rectiï¬er networks. In ACL,
2020.

Park, K. Can convolutional neural networks crack sudoku
https://github.com/Kyubyong/

puzzles?
sudoku, 2018.

Punyakanok, V., Roth, D., Yih, W., and Zimak, D. Semantic
role labeling via integer linear programming inference.
In COLING, 2004.

Punyakanok, V., Roth, D., Yih, W.-t., and Zimak, D. Learn-
In IJCAI,

ing and inference over constrained output.
2005.

An Integer Linear Programming Framework for Mining Constraints from Data

Raedt, L. D., Passerini, A., and Teso, S. Learning constraints

from examples. In AAAI, 2018.

Richardson, M. and Domingos, P. M. Markov logic net-

works. Machine Learning, 62(1-2):107â€“136, 2006.

Riedel, S. and Clarke, J. Incremental integer linear program-
ming for non-projective dependency parsing. In EMNLP,
2006.

Rossi, F. and Sperduti, A. Acquiring both constraint and so-
lution preferences in interactive constraint systems. Con-
straints, 9(4):311â€“332, 2004.

Roth, D. and Yih, W. A linear programming formulation
for global inference in natural language tasks. In CoNLL,
2004.

Roth, D. and Yih, W. Integer linear programming inference

for conditional random ï¬elds. In ICML, 2005.

Samdani, R. and Roth, D. Efï¬cient decomposed learning

for structured prediction. In ICML, 2012.

Srikumar, V., Kundu, G., and Roth, D. On amortizing infer-
ence cost for structured prediction. In EMNLP-CoNLL,
2012.

Tan, Y., Terekhov, D., and Delong, A. Learning lin-
ear programs from optimal decisions. arXiv preprint
arXiv:2006.08923, 2020.

Valiant, L. G. A theory of the learnable. In STOC, 1984.

Wang, P. and Kolter, J. Z. Low-rank semideï¬nite program-

ming for the MAX2SAT problem. In AAAI, 2019.

Wang, P., Donti, P. L., Wilder, B., and Kolter, J. Z. SATNet:
Bridging deep learning and logical reasoning using a
differentiable satisï¬ability solver. In ICML, 2019.

Ye, Y., Feng, Y., Luo, B., Lai, Y., and Zhao, D. Integrating
relation constraints with neural relation extractors. In
AAAI, 2020.

Zhao, J., Wang, T., Yatskar, M., Ordonez, V., and Chang,
K. Men also like shopping: Reducing gender bias am-
In EMNLP,
pliï¬cation using corpus-level constraints.
2017.

An Integer Linear Programming Framework for Mining Constraints from Data

A. Mined Equality Constraints in Sudoku

Experiments

The mined equality constraints are the linear transformation
of the following constraints:

9
(cid:88)

i=1

9
(cid:88)

j=1

9
(cid:88)

k=1

yijk = 1, âˆ€j, k,

yijk = 1, âˆ€i, k,

yijk = 1, âˆ€i, j,

(10)

where M = |Sâˆ—|.

i is the ground truth label for a random weight w sampled
from Dw.

We then consider E[SI ]. The inner polytope is a convex
hull of seen feasible points. For each feasible point i âˆˆ
Sâˆ—, the probability that we have seen it after k samples is
1âˆ’(1âˆ’pi)k. Thus, after k training samples, the expectation
size of the inner polytope is given by

E[SI ] =

(cid:88)

iâˆˆSâˆ—

(1 âˆ’ (1 âˆ’ pi)k) = M âˆ’

(1 âˆ’ pi)k,

(cid:88)

iâˆˆSâˆ—

When i /âˆˆ Sâˆ—, the condition in pi means the given weight w,
i is better than all the feasible points. Given w in training,
we ï¬nd the label is worse than i, which indicate i is infeasi-
ble and it will be ï¬ltered out. So pi is the probability that
infeasible point i is not ï¬ltered out in training for a random
weight w sampled from Dw.

We then consider E[SO]. The outer polytope is initialized as
the whole space and ï¬lters out infeasible points in training.
For each infeasible point i /âˆˆ Sâˆ—, the probability that it is
not ï¬ltered out after k samples is (1 âˆ’ pi)k. We also know
that all the feasible points will not be ï¬ltered out. Thus,
after k training samples, the expectation size of the outer
polytope is given by

E[SO] = M +

(1 âˆ’ pi)k,

(cid:88)

i /âˆˆSâˆ—

where N is the size of the universal set.

D. Expectation Approximation under

Assumptions

The data symmetric assumption is: for k different points
y(1), y(2), . . . , y(k),

Pwâˆ¼Dw {w Â· y(1) â‰¥ w Â· y(i), i âˆˆ [k]} =

1
k

.

With this assumption, consider pi = Pwâˆ¼Dw {w Â· y(i) â‰¥
w Â· y(j), âˆ€j âˆˆ Sâˆ—}. When i âˆˆ Sâˆ—, there are M points are
taken into consideration. With the assumption, we can get
pi = 1
M , i âˆˆ Sâˆ—. When i /âˆˆ Sâˆ—, there are M + 1 points are
taken into consideration. With the assumption, we can get
pi = 1

M +1 , i /âˆˆ Sâˆ—.

E. Conï¬gurations for the Reproducibility

Data All the date and code can be found in https://
github.com/MtSomeThree/ILPLearning.

3
(cid:88)

3
(cid:88)

i=1

j=1

y(x+i)(y+j)k = 1, âˆ€x, y âˆˆ {0, 3, 6}âˆ€k.

These are the rules of Sudoku described by linear constraints.
We denote the linear space deï¬ned by these constraints as
Sâˆ—, and the linear space given by our mined constraints as
Ë†S. We verify Sâˆ— = S by

1. For each constraint in Eq. (10), we verify it is indicated

in Ë†S. This property guarantee that Sâˆ— âŠ† Ë†S.

2. Comparing the dimension of Sâˆ— and S. We ï¬nd that

d(Sâˆ—) = d( Ë†S) = 249.

B. Mined Equality Constraints in

Hierarchical Multiclass Classiï¬cation
Experiments

The classes in this task have a tree structure and it has depth
4 including the root (root is a virtual concept that it is not a
real class). We use p(x) to denote the parent class of class x,
and Li to denote the set of classes on layer i, i âˆˆ {1, 2, 3}.
The mined equality constraints are the linear transformation
of the following constraints:

(cid:88)

jâˆˆLi

, yj = 1, âˆ€i âˆˆ {1, 2, 3},

(11)

hparent(x),x,0,1 = 0, âˆ€x : parent(x) (cid:54)= root.

We use the same method in Appendix. A to verify it.

C. The Expectation of the Size of Outer and

Inner Polytopes

We deï¬ne

pi = Pwâˆ¼Dw {w Â· y(i) â‰¥ w Â· y(j), âˆ€j âˆˆ Sâˆ—}.

When i âˆˆ Sâˆ—, the condition in pi means the under the given
weight w, i is the optimal point. So pi is the probability of

Sudoku Experiments
In the Sudoku experiments, we use
the baseline following the settings in SATNet(Wang et al.,

An Integer Linear Programming Framework for Mining Constraints from Data

2019) 8.

MST Experiments
In the MST experiments, we use the
3-layer feedforward neural network as the baseline model
with ReLU activation. The hidden dimension is set to be
50. The input and output dimension is 21. We use the
sigmoid function to regularize the output in (âˆ’1, 1). We
train the model for 300 epochs and we use the Adam op-
timizer(Kingma & Ba, 2015) to optimize the model. The
learning rate is set to be 0.001.

Hierarchical Multi-label Classiï¬cation Experiments
In the HMC experiments, we use multiple base models.
We enumerate the number of layers in {1, 2, 3}, the number
of training epochs in {1, 5, 50, 300}., and the learning rate
in {0.001, 0.0003, 0.0001}. The hidden dimension is set to
be 100. The input dimension is 80 and the output dimension
is 96. In hidden layer we use ReLU as the activation and in
output we use sigmoid function to regularize the output.

8The baseline models can be found in https://github.

com/locuslab/SATNet.

