Copyright © 2020 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including
reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted
component of this work in other works by sending a request to pubs-permissions@ieee.org. Accepted and published in 2020 IEEE Latin-American Conference on Communications.
Citation information: DOI: 10.1109/LATINCOM50620.2020.9282342.

A Low-Complexity Multi-Survivor Dynamic
Programming for Constrained Discrete Optimization

I. Zakir Ahmed and Hamid Sadjadpour
Department of Electrical and Computer Engineering
University of California, Santa Cruz

Shahram Youseﬁ
Department of Electrical and Computer Engineering
Queen’s University, Canada

1
2
0
2

y
a
M
3
1

]

C
O
.
h
t
a
m

[

1
v
5
8
0
6
0
.
5
0
1
2
:
v
i
X
r
a

Abstract—Constrained discrete optimization problems are en-
countered in many areas of communication and machine learn-
ing. We consider the case where the objective function satisﬁes
Bellman’s optimality principle without the constraints on which
we place no conditions. We ﬁrst show that these problems are
a generalization of optimization in constrained Markov decision
processes with ﬁnite horizon used in reinforcement learning and
are NP-Hard. We then present a novel multi-survivor dynamic
programming (msDP) algorithm that guarantees optimality at
signiﬁcant computational savings. We demonstrate this by solv-
ing 5G quantizer bit allocation and DNA fragment assembly
problems. The results are very promising and suggest that msDP
can be used for many applications.

I. INTRODUCTION

We deﬁne a class of problems H that are constrained
discrete optimization problems with the objective function
(OF) satisfying the principle of optimality (PO) without
considering the constraints [1]. The constraint functions are
assumed to be neither convex nor linear in their decision
variables. Nor are the constraints required to satisfy the
[2].
independence constraint qualiﬁcation (LICQ)
linear
These problems, in general, are NP-Hard [3]. Solving H to
optimality with reduced computational resources is highly
desirable. Popular methods like Dynamic Programming (DP),
Branch and Bound (BB), and Lagrangian relaxation methods
can solve H to optimality [4]–[8] as long as we place either
linearity or quadratic conditions on the OF or constraints [6],
[9], while many others do not ensure optimality [10].

Examples of H include resource allocation (power,
in massive Multiple-Input Multiple-Output
ADC bits)
(MaMIMO)
constrained
systems with constraints
network optimization problems used in routing protocols
[12], and Reinforcement Learning (RL) applied to Markov
decision processes with constraints [13], to name a few.

[11],

The contributions of this paper are as follows

• we propose a novel multi-survivor Dynamic Program-
ming (msDP) algorithm to solve H optimally at signiﬁ-
cantly reduced computational cost, and,

• we show that Constrained Markov Decision Processes

(CMDP) with ﬁnite horizons belong to H.

Notations: The

column vectors

boldface

small

letters. The

are
superscripts

represented as
denote

T

transpose. The terms I and R,
indicate space of integers
and real numbers
respectively. We represent a vector
x = [x1, x2, · · · , xN ]T whose entries are constants up to
xi for i ≤ m as xm and call such vectors partial,
i.e.,
xm = [a1, a2, · · · , am, xm+1, · · · , xN ]T where ai’s are
constants. The xi’s belong to a ﬁnite set X with cardinality
M .
there are multiple of such partial vectors under
consideration, we refer to the kth such vector as xm
k and its
N ]T .
elements as xm
2, · · · , ak
1, ak
The jth element of the set X is represented as {X }j. If the
mth element of xm
k takes a value {X }j, we represent such
partial vector as xmj
k .

m+2, · · · , xk

k = [ak

m+1, xk

m, xk

If

The rest of this paper is organized as follows. We deﬁne
the problem H in Section II. We ﬁrst show in Section III that
the CMDP framework typically used in RL belongs to H. In
Section IV we describe the theoretical foundations that lead to
the proposed msDP algorithm. We describe the proposed algo-
rithm and evaluate its worst-case computational complexity in
Section V. We compare the performance and computational
complexity of the proposed method with exhaustive search
(ES) and the heuristic algorithm in Section VI, followed by
the conclusions in Section VII.

II. PROBLEM SETUP

We deﬁne H as stated below, where x∗ is the optimal

solution to (1) if it exists.

f (x),

max
x

such that ci(x) ≤ αi; for 1 ≤ i ≤ QI,
|{z}
hj(x) = βj; for 1 ≤ j ≤ QE,

(1)

N

where x = [x1, x2, · · · , xN ]T ∈ RN . The OF f (x) satisﬁes the
PO without the constraint functions ci(x) and hj(x), where
αi, βj ∈ R, ∀i, j [1]. Thus, it can be written in the form
i=1 biφi(xi) where bi ∈ R are constants, xi ∈ X
f (x) =
can only take values from the set X whose cardinality is M ,
and, φi : X −→ Y, for 1 ≤ i ≤ N . The mapping φi need not
be known in closed form. The constraint functions ci(x) and
hj(x) are not limited to linear mappings in xi, nor convex and
need not satisfy LICQ [2]. The terms QI and QE represent
the number of inequality and equality constraints, respectively.

P

1

 
 
 
 
 
 
III. FINITE HORIZON CMDP AS PROBLEM H

A ﬁnite-state Markov decision process

is a 5-tuple
(X, A, P, r, µ) where X is the ﬁnite set of states, A is the
→ [0, 1] are the state
ﬁnite set of actions, P : X × A × X
transition probabilities px,a(x
is attained when
an action a ∈ A is taken in state x. Both x, x
∈ X. A
reward r : X × A → R is associated with an a ∈ A from
a state x ∈ X. The map µ : X → [0, 1] is the starting state
distribution [14].

) that a state x

′

′

′

′

A policy π = (D1, D2, · · · , DN −1) is deﬁned as a set of
decisions taken by an agent over states that maximize a certain
cumulative reward. A stationary deterministic policy has a
decision rule Di : X → A that maps states to actions. In
case of randomized policies, the decision rule Di is a random
variable and described using state dependent distributions on
possible actions. Hence, Di is described as Di : X → P(A)
where P(A) is the probability distribution over actions deﬁned
by qi(a|x) = Prob[Di = a|xi] for every action a ∈ A.

The cumulative reward is deﬁned as R =

N
i=1 γiri where
ri is a reward accrued at ith time instance when the agent uses
a policy π. The discount factor γ ∈ [0, 1]. We can write the
expected sum of discounted rewards as a function of a given
policy and an initial state x as V π(x) = E[R | x1 = x] [14],
which can be rewritten as

P

V π(x) = E
(cid:20)

N

N

i=1
X

γiri(xi, Di(xi)) | x1 = x
(cid:21)

,

=

γi ˆri(xi), where ˆri(xi) =

qi(a|xi)ri(xi, a),

(2)

i=1
X

a∈A
X

assuming a random stationary policy. Considering an initial
distribution µ on all the possible starting states on set X, we
can deﬁne the value of the policy as [14]

J(π) = Ex∼µ

(cid:20)

V π(x)
(cid:21)

N

=

µ(x)

=

µ(x)V π(x).

x∈X
X
γi ˆri(xi) =

N

γiφi(xi),

(3)

i=1
X

x∈X
X

i=1
X
where φi(xi) =
x∈X µ(x) ˆri(xi), which is obtained by
substituting V π(x) from (2). We see that with bi = γi the
N
OF J(π) of (3) is similar to the OF f (x) =
i=1 biφi(xi) of
H in (1).

P

For the CMDP case, we have constraint functions that could
be either secondary reward functions or penalty functions. The
constraint functions c deﬁned as c : X × A → R such that
cπ(x) ≤ d. The whole optimization problem is written as [14]

P

J(π), such that c(π) ≤ d.

(4)

max
π

In (4), c(π) = E[cπ(x)] = E[

|{z}

N
i=1 γici(xi, ai)].

P
IV. THEORETICAL FOUNDATIONS OF MSDP

In this section, we construct the theoretical foundations for
the proposed msDP. We ﬁrst deﬁne the Constraint Satisfaction

Function (CSF). We deﬁne a boolean function A : x → {0, 1}
such that

1,

if x satisﬁes all the constraints
ci(x), hj (x) of H; for all i, j.

(5)

0, otherwise.

A(x) = 




k as
k ) = 1 for 1 ≤ m < N if there exists at least one vector
N ]T such that bi ∈ X for i > m that

We also deﬁne A(·) on a partially assigned vector xm
A(xm
bk = [bk
satisﬁes all the constraints. This is represented as

m+2, · · · , bk

m+1, bk

1,

if there exists at least one bk deﬁned
above, that satisﬁes all the constraints
ci(xm
k ) for all i, j.
0, otherwise.

k ), hj(xm

A(xm

k ) = 


A. Principle of Optimality

(6)

a

deﬁne

partially

computed OF of H as
We
λ(xm
is to be
k ) =
noted that A(x) = A(xN ) and λ(xN ) = f (x). Here xN is a
P
completely known vector.

m
i=1 biφi(ai) for 1 ≤ m < N . It

Now we show that H does not satisfy the PO. We then
introduce a multi-valued function maxl{·} that returns l
maximum values from its domain. Adopting maxl{·}, we
reformulate H to satisfy the PO.

Theorem 1. If x∗ is the optimal solution to H described in (1)
and if there exists at least one infeasible solution x1 to H such
that f (x1) > f (x∗) with constraint satisfaction function being
true at some intermediate stage l in the recursion A(xl
1) > 0,
f (x) does not obey
then it can be shown that J = max

the PO.

x,A(x)>0

|{z}

Proof. We say that (1) satisﬁes the PO if we can express it as
a value function [1]. That is, given

J = f (x∗) = J(x1) = max
{xi}N
i=1,
A(x)>0
|{z}

N

n

i=1
X

biφi(xi)

, then

o

N

J(xi) = max
xi;
A(xi)>0
|{z}

(

biφi(xi) + max

bjφi(xj )

)

,

j=i+1
X

{xj}N
j=i+1;
A(xi+1)>0
|{z}

J(xi) = max

xi;A(xi)>0 (

biφi(xi) + J(xi+1)

)

.

|{z}

Let x1 be an infeasible solution to H such that

(7)

f (x1) > f (x∗), where
A(x1) = 0 and A(x∗) > 0.
However, at some intermediate stage l < N in the recursion,
the condition depicted below would arise as a consequence of

(8)

no conditions placed on the constraints [2], [15].
As λ(xl
λ(xl

1) > λ(x∗l), such that A(xl
λ(xl

1) > 0 and A(x∗l) > 0 :
. Thus, we can write

1), λ(x∗l), · · ·

1) = max

xl;A(xl)>0 (cid:26)

(cid:27)

|{z}

1 at stage l. However,

the recursion at stage l in (7) as J = λ(xl
1) + J(xl+1).
As a result, we see that the optimal solution x∗l is dropped
against xl
in the subsequent stage
r, where l < r ≤ N , another candidate solution xr
2 is
picked against xr
1 shows up
as A(xr
1 is dropped
and we have the recursion equation at stage r ≤ N as

1 because the infeasibility of xr
1) = 0. Consequently, xr

2) > 0, and A(xr

the recursion in Γ(xi).
Theorem 2. If x∗ is the optimal solution to H described in
(1), then with an appropriate choice of Ne that is dependent on
the constraint satisfaction function A(·), it can be shown that
always satisﬁes the
Γ(x1) =

N
i=1 biφi(xi)

max
Ne

{xj}N

j=1;A(˜x)>0

n P

o

|{z}

PO.
Proof. Let x1 be an infeasible solution to H as described in
(8) in Theorem 1. Let the PO (13) hold true; we can then write
the same at recursion l ≤ N as

J = λ(xr

2) + J(xr+1).

(9)

Extending the result to stage N , we can see that

J = f (x2) = λ(xN

2 ) = max

biφi(xi).

(10)

N

However, by deﬁnition we have

|{z}

x;A(x)>0

i=1
X

Γ(x1) = maxNe

blφl(xl) + Γ(xl+1)

,

xl;A(˜xl)>0 n
= λ(˜xl) + Γ(xl+1).

| {z }

o

(14)

We now let Ne be large enough such that λ(˜xl) =
[λ(xl

1), λ(x∗l), · · ·]T . That is (xl

1, x∗l) ∈ ˜xl.

However, at some later stage r where l < r ≤ N , we can

N

write the recursion as

J = f (x∗) = λ(x∗N ) = max

biφi(xi),

(11)

where x∗ 6= x2, hence, H deﬁned in (1) does not satisfy the
PO.

|{z}

x;A(x)>0

i=1
X

We now deﬁne a multi-valued function maxNe : Rm →
RNe such that it returns at-most Ne maximum values over a
combination of m variables in its domain. We now rewrite H
in (1) using Γ as deﬁned below

f (x) = J = max

Γ(x1)

, where

max
x;A(x)>0

|{z}

n

o
N

(12)

,

{xj }N

biφi(xi)

Γ(x1) = λ(˜x) =

maxNe
j=1;A(˜x)>0 n
where λ(˜x) is a vector of Ne maximum values. That is,
λ(˜x) = [λ(x1), λ(x2), · · · , λ(xNe )]T that corresponds to the
Ne solutions ˜x = [x1, x2, · · · , xNe ]T . It is also to be noted
that the CSF A(˜x) > 0 is true iff A(xi) > 0 is satisﬁed for
all xi ∈ ˜x.

| {z }

i=1
X

o

1 ), λ(xm

2 ), · · · , λ(xm

We also deﬁne the partially evaluated objective at stage
Ne )]T =
the CSF

m ≤ N as λ(˜xm) = [λ(xm
m
i=1 biφi(xi)

maxNe
j=1;A(˜xm)>0 n P
{xj }m
A(˜xm) > 0 is true iff A(xm
i ∈ ˜xm.
| {z }
Given the optimal solution x∗, we say that the value function
Γ(·) in (12) satisﬁes the PO if we can write

i ) > 0 is satisﬁed for all xm

. As before,

o

Γ(xi) = maxNe

biφi(xi) + Γ(xi+1)

, where

xi;A(˜xi)>0 n

o

(13)

J = f (x∗) = max
| {z }

Γ(x1)

.

That is, the optimal solution is maintained at every stage of

n

o

Γ(x1) = maxNe

brφl(xr) + Γ(xr+1)

,

xr;A(˜xr)>0 n
= λ(˜xr) + Γ(xr+1).

| {z }

o

(15)

2) ∈ λ(˜xr) and λ(xr

1) = 0. Thus the solution xr

1) 6∈ λ(˜xl). This
Now we note that λ(xr
is because, at this stage in the recursion, the infeasibility of
the candidate solution xr
1 becomes known as indicated by
A(xr
With the appropriate choice of Ne, it can be ensured that
2, x∗r) ∈ ˜xr. The determination of Ne is discussed in
(xr
Lemmas 1 and 2 in section IV. Extending r to N , we have
(xN

2 , x∗N ) ∈ ˜xN . Hence, we can write

1 is not part of ˜xr.

Γ(x1) = λ(˜xN ) =

maxNe
j=1;A(˜xN )>0 n

i=1
X
with x∗ ∈ ˜xN ; Thus, f (x∗) = max

| {z }

{xj}N

o

(16)

Γ(x1)

.

N

biφi(xi)

,

Thus, with an appropriate choice of Ne, we see that the PO
for (12) is always satisﬁed.

n

o

B. Trellis for H

We deﬁne a graph G(V, E, A) with nodes V , edges E, and

edge label A as

Vi =

xij | xij = {X }j; 1 ≤ i ≤ N ; 1 ≤ j ≤ M

∪ S ∪ F,

E =

n

o
(xij , xi+1m) | xij = {X }j; xi+1m = {X }m;

n

1 ≤ j, m ≤ M ; 1 ≤ i ≤ N − 1; (S, x1j), (xN m, F )

,

A =

o
ψi(xi+1 | xi) = φi(xi) ← (xi, xi+1) | ∀xi ∈ X ;

1 ≤ i ≤ N ; φN (xN ) ← (xN , F ) | ∀xN ∈ X ;

n

0 ← (S, x1) | ∀x1 ∈ X

.

o

(17)

The nodes S and F are the starting and terminal nodes,
respectively. The optimal solution x∗ = [x1j , x2j, · · · , xN j]T
can be thought of as a walk through this graph starting at
node S and ending at the destination node F passing through
the nodes xij ∈ Vi from stage i = 1 to i = N , along the
edges (xij , xi+1m) ∈ E accruing a reward ψi(xi+1m | xij ) =
φi(xij ) ∈ A that results in the maximum total accumulated
reward f (x∗) such that all the constraints are satisﬁed. That
is A(x∗) > 0. It can also be noted that this graph G(V, E, A)
can be qualiﬁed as a trellis T (V, E, A) [7]. An example
T (V, E, A) with M = 4 is shown in Fig 1.

A DP approach can not be used to obtain x∗ as shown using
Theorem 1. We note from Theorem 2 that the PO is satisﬁed
by using the multi-valued function maxNe. Thus, maintaining
multiple survivor paths (Ne) at each stage of the trellis ensures
optimality if Ne is picked properly. An appropriate choice of
Ne is discussed in the next subsection. Thus the DP algorithm
is modiﬁed to perform Add, Compare, and Multiple Select
(ACMS) as basic operation at each node in the trellis as
opposed to Add, Compare, and Select (ACS). The algorithm
is described in section V.

C. Determination of Ne

In the Lemmas below, we establish a relationship between
the number of survivors Ne and CSF A(·) to ensure optimality.
Due to the page limitation, the proofs are omitted.

Lemma 1. The number of survivor paths (or partial solutions)
that need to be maintained at a given node xij in trellis
T (V, A, E) to obtain optimal solution to H is dependent on
the constraint satisfaction function A(xij ) at the node xij in
the trellis. It can be shown that

Lij

B(xij ) ,

A(xij

k ),

(18)

k=1
X
where Lij is the number of paths incident on the node xij,
out of which B(xij ) paths satisfy all the constraints as per the
deﬁnition of CSF in (6).

Lemma 2. The minimum number of maximum paths Ne that
need to be maintained in (13) at each stage in the recursion
for optimality of H can be expressed as a lower bound:

M

Lij

Ne ≥ max

A(xij

k ).

(19)

j=1
X
V. MULTI-SURVIVOR DYNAMIC PROGRAMMING
|{z}
ALGORITHM

k=1
X

i

A. Evaluation of CSF

It can be shown that the A(xm) can be evaluated at any
intermediate stage m ≤ N by posing it as an unconstrained
discrete optimization (UDO) problem. The UDO problems
can be solved in polynomial time using graph structures like
Depth-First-Search (DFS), Breadth-First-Search (BFS), or BB
algorithms [6], [16].

Algorithm 1 Multi-survivor Dynamic Programming.

Input:M ,N ,A(·),X
M ← Cardinality of sets X
N ← Number of stages or variables of f (·) of problem H
A(·) ← Constraint satisfaction function of H
X ← Set of discrete values that xi’s can take
Determine the path valency E(xir) for all nodes
Initialize paths and its associated costs
x1,1={X }1,x1,2={X }2,···,x1,M ={X }M
λ(x1,1)=b1φ1({X }1),λ(x1,2)=b1φ1({X }2),···,
λ(x1,M )=b1φ1({X }M )
for i = 2 : N do

for r = 1 : M do
m ← 1
for b = 1 : M do

if (xi−1b, xir) ∈ T (A) then

for k = 1 : E(xir) do

if A(xir

k ) > 0 then

xir = {X }r
xi,r
k = [(xi−1,b
λ(xi,r

k ) = λ(xi−1,b

k

k

)T , xir]T

) + biφi(xir)

end if

end for

end if

end for
Keep only {xi,r
m }m=1,···,E(xi,r) paths, that
correspond to E(xir) maximum values of
and ignore the rest!
λ(xi,r
m )

)m=1,···,E(xir )

(

end for

end for
Process the termial node ”F”
m ← 1
for b = 1 : M do

for k = 1 : LT All paths incident on terminal node F do

m)=λ(xN −1,b

k

λ(xF
m←m+1

)+bN φN (xN b)

end for

end for
Pick x∗ that has maximum of nλ(xF
return x∗ Optimal Solution

k )ok=1,···,m−1

B. Computational Complexity Analysis

The computational blocks of the msDP involve (i) evaluat-
ing the CSF A(xij
k ), and (ii) performing the ACMS operation
on the E(xij ) paths incident on a given node xij of the trellis.
For (i), a BFS or DFS can be used in such cases which has
complexity of O(E + V ), where E and V are the numbers
of edges and vertices of the trellis [16]. In the worst case of
a fully connected trellis, E = (N − 1)M 2, and V = N M .
Also, in the worst case scenario of N
M incident on
all the nodes in the given trellis, the net complexity of CSF
evaluation TCSF can be expressed as

e = Ne

′

(cid:16)

TCSF = Ne

(N − 1)N M 2 + N 2M

for all the N M nodes.
(20)
In case of (ii), the total number of ACMS evaluations for
the trellis in the worst case is TACMS = Ne
M N M = NeN .
Thus, the complexity of msDP is O(NeN 2M 2) or in general
O(NeN l), where l ∈ R. On the other hand, the ES requires

(cid:17)

0

0

0

0

S

i = 1

x11

x12

x13

x14

Φ1(x11)

Φ1(x12)

Φ1(x12)

Φ1(x13)

Φ1(x13)

Φ1(x14)

Φ1(x14)

i = 2

x21

x22

x23

x24

Φ2(x21)
Φ2(x22)

Φ2(x22)
Φ2(x23)

Φ2(x23)
Φ2(x24)

i = 3

x31

x32

x33

Φ1(x14)

x34

Fig. 1. An example trellis T (V, E, A) for M = 4.

i = N

xN 1

ΦN (xN 1)

xN 2
ΦN (xN 2)
ΦN (xN 3)

xN 3

F

ΦN (xN 4)

xN 4

an evaluation of the CSF and OF for M N solutions. Hence its
complexity is O(M N ). In the case of learning techniques like
RL, to guarantee an optimal solution, the complexity required
is ≈ O(M N ) [17].

VI. SIMULATIONS

In this section, we apply the proposed msDP to solve (i)
Analog to Digital Converter (ADC) Bit-Allocation (BA) prob-
lem for MaMIMO receiver, and (ii) DNA fragment assembly
(DFA) problem that is a part of DNA sequencing [18], [19].
We evaluate the performance and compare the number of
computations1 against the ES and the heuristic suboptimal
simulated annealing (SA) algorithms2 [20].

A. ADC Bit Allocation for MaMIMO

The ADC BA problem is to assign the number of bits
to be used by Variable-Resolution ADCs on different Radio
Frequency (RF) paths of the MaMIMO receivers. An optimal
BA ensures that the performance, of the receiver is maximized
under a non-linear power constraint. It is to be noted that the
OF is non-linear. In [11], the authors reduce this to a problem
in H, which is described as

J =

max
i=1;A(x)>0 n

{xi}N

N

i=1
X

a2
i
b2
i + di2xi

,

o

(21)

|{z}

where ai, bi, and di are constants ∈ R that represent channel
singular value, noise power, and coefﬁcient of quantization
noise due to bit allocation xi on the ith RF path, respectively.
Here N is the number of RF paths in the receiver. The CSF
N
A(x) > 0 iff the power constraint
i=1 2xi ≤ Pt, and bit-
ordering constraint x1 ≥ x2 ≥ · · · ≥ xN are satisﬁed. The
total ADC power budget is Pt. Hence we have

P

1, if

A(x) = 


0,

N
i=1 2xi ≤ Pt,
x1 ≥ x2 ≥ · · · ≥ xN .
P
Otherwise.

(22)

We perform simulations considering the parameters used by
the authors in [11]. They consider a maximum bit resolution



1Number of computations = Actual number of CSF evaluations + ACMS

operations.

2The optimality is compromised against complexity with heuristic algo-

of M = 4, such that xi’s (bits) take values from the set X =
{1, 2, 3, 4} for 1 ≤ i ≤ N . We assume the number of RF
paths in the receiver as N = 12 and the power budget of
Pt = 48. For this case, we achieve Ne ≥ 13. The number of
computations with msDP, ES, and SA algorithms are shown
in Table I. Both the brute-force and msDP methods obtain the
optimal solution of x∗ = [4, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1]T [21].

B. DNA Fragment Assembly

We apply our proposed formalism to the DFA problem,
which has equivalence to the TSP [18], [22]. DFA is the
challenging process of the DNA sequencing [23]. DNA se-
quencing’s main problem is that the current technology can not
read an entire genome in one shot, sometimes not even more
than 1000 bases. Even the simplest organisms, like bacteria
and viruses, have much longer genome lengths. Consequently,
the genomes are broken down into smaller readable fragments
and sequenced [24]. In this step, N copies of DNA are created.
A short fragment is derived from each of the replicated DNA at
some random location. These short fragments are sequenced.
The ﬁnal and challenging step is to assemble these sequenced
fragments to obtain the original DNA sequence. This step is
called the DFA, which is illustrated through an example below
[18].

We assume the DNA sequence to be T T ACCGT GC,
and the fragments sequenced using 4 DNA copies being
F1 = ACCGT , F2 = CGT GC, F3 = T T AC, and
F4 = T ACCGT . The overlap of each fragment with the
other three fragments are computed using similarity measure.
Based on this similarity measure, the order of fragments are
determined which in the case of this example is F3F4F1F2.
The DFA problem is posed as a maximization problem
where the sum of the similarity measures3 between two
adjacent DNA fragments is maximized. This is subject to the
constraint that there is no repetition of the fragments in the
sequence. Formally, this problem is deﬁned as [18]

N −1

J =

max

φ(Fσi , Fσi+1 )

,

(23)

{Fσi }N

i=1;A(F )>0 n

i=1
X

o

3The similarity scores between different pairs of fragments are derived

|{z}

rithms like SA.

using the Smith-Waterman algorithm [18], [25].

TABLE I
COMPARISON OF THE TOTAL ACTUAL NUMBER OF COMPUTATIONS §
REQUIRED FOR MSDP, ES, AND SA ALGORITHMS.

PROPOSED
METHOD
O(Ne N 2M 2)
6912 (Ne = 13)
83890 (Ne = 434)

EXHAUSTIVE
SEARCH
O(M N ), O(N ! )
16.7 × 106
3.62 × 106

SIMULATED
ANNEALING

≈ O(M N ), O(N ! )‡
5220
380

ADC BA
DFA-1†

† DFA with a second constraint. § Number of computations = Actual number of CSF evaluations + ACMS operations. ‡
To guarantee optimal solution.

where F = {Fσ1 , Fσ2 , · · · , FσN } is the optimal solution
indicating the original DNA sequence, σi
is the fragment
index, and φ(Fσi , Fσi+1 ) is the similarity measure between the
fragments Fσi and Fσi+1 . Here, the set X is collection of DNA
fragments {Fσj }N
j=1, where N is the number of fragments. In
this example we have M = N . For this problem the CSF
A : F → {0, 1} is deﬁned on the set F as A(F ) > 0 iff all
the fragments in F are unique. The CSF denoted as

N

1,

if

Fσi = ∅,

(24)

A(F ) =

i=1
T

0, Otherwise.



the DNA
We perform the DFA of a small section of

(E. coli)
sequence of bacterium Escherihia Coli
[18].
The original
represented as
the DNA is
section of
T ACT AGCAAT ACGCT T GCGT T CGGT . We consider
N = 10 fragments each with 8 bases, as follows: F1 =
ACGCTTGC, F2 = TTGCGTTC, F3 = ACTAGCAA, F4 =
CGTTCGGT, F5 = AGCAATAC, F6 = TACTAGCA, F7 =
AATACGCT, F8 = CTTGCGTT, F9 = ATACGCTT, and
F10 = CTAGCAAT. Using the proposed method, we obtain
the optimal solution F = {F6F3F10F5F7F9F1F8F2F4}. It
can be shown that by imposing a second constraint using an
upper bound [22], we achieve Ne ≥ 454. Solving the DFA
problem to optimality with the imposition of these additional
constraints is not possible using the traditional DP. The results
are shown in Table II.

TABLE II
COMPARISON OF PERFORMANCE OF THE MSDP, ES, AND SA
ALGORITHMS.

PROPOSED
ALGORITHM
OPTIMAL

ADC BA [4, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1]T
DFA-1 †

[6, 3, 10, 5, 7, 9, 1, 8, 2, 4]T

EXHAUSTIVE
SEARCH
OPTIMAL
[4, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1]T
[6, 3, 10, 5, 7, 9, 1, 8, 2, 4]T

SIMULATED
ANNEALING
SUBOPTIMAL
[4, 4, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1]T
[6, 3, 10, 5, 2, 8, 4, 7, 9, 1]T

VII. CONCLUSION

Constrained discrete optimization problems with the objec-
tive function that satisﬁes the optimality principle and place
no conditions on the constraints are NP-Hard. In general, such
problems arise in many areas of science, engineering, ﬁnance,
and management. We propose a multi-survivor dynamic pro-
gramming framework that solves these problems to optimality

with worst-case complexity reduction from either O(K N ) or
O(N ! ) to O(NeN l), where Ne and l are constants that depend
on the constraints.

ACKNOWLEDGMENT

The authors would like to thank National Instruments for

the ﬁnancial support extended for this work.

REFERENCES

[1] R. Bellman, “The theory of dynamic programming,” Bulletin of the
American Mathematical Society, vol. 60, no. 6, pp. 503–515, Nov. 1954.

[2] W. Nocedal, “Numerical optimization,” Springer, 2nd Edition, 2006.
[3] C. H. Papadimitriou, “On the complexity of integer programming,” J.

ACM, vol. 28, no. 4, pp. 765–768, Oct. 1981.

[4] A. Ghasempour and H. Amindavar, “Fixed channel assignment using
new dynamic programming approach in cellular radio networks,” Com-
puter and Electrical Engineering, Elsevier, vol. 31, no. 4, pp. 303–333,
June-July 2005.

[5] ——, “Channel assignment for cellular radio using extended dynamic
programming,” International Journal of Electronics and Communica-
tions (AE ¨U), Elsevier, vol. 59, no. 7, pp. 401–409, Nov. 2005.

[6] D. R. Morrison, S. H. Jacobson, J. J. Sauppe, and E. C. Sewell, “Branch-
and-bound algorithms,” Discret. Optim., vol. 19, pp. 79–102, Feb. 2016.
[7] B. Kolman, R. Busby, and S. Ross, “Discrete mathematical structures,”

Prentice Hall, 1999.

[8] M. L. Fisher, “The lagrangian relaxation method for solving integer
programming problems,” Manage. Sci., vol. 50, pp. 1861–1871, Dec.
2004.

[9] S. Lin, N. Meng, and W. Li, “Optimizing constraint solving via dynamic
programming,” in Proc. of the Twenty-Eighth IJCAI 2019, 7 2019, pp.
1146–1154.

[10] B. Plancher, Z. Manchester, and S. Kuindersma, “Constrained unscented

dynamic programming,” 09 2017, pp. 5674–5680.

[11] I. Z. Ahmed, H. Sadjadpour, and S. Youseﬁ, “Single-user mmwave
massive MIMO: Svd-based adc bit allocation and combiner design,”
SPCOM-2018, pp. 357–361, July 2018.

[12] M. Ziegelmann, Constrained shortest paths and related problems -

constrained network optimization., Jan. 2007.

[13] E. Altman, Constrained markov decision processes. Taylor & Francis,

1999.

[14] P. Geibel, “Reinforcement learning for mdps with constraints,” Machine

Learning: ECML 2006, pp. 646–653, 2006.

[15] V. Boyd, Convex optimization.

New York, NY, USA: Cambridge

University Press, 2004.

[16] N. Dale, C++ plus data structures, 5th ed. USA: Jones and Bartlett

Publishers, Inc., 2011.

[17] C. Watkins and P. Dayan, “Technical note: Q-learning,” Machine Learn-

ing, vol. 8, no. 3, pp. 279–292, May 1992.

[18] M. Bocicor, G. Czibula, and I. Czibula, “A reinforcement

learning
approach for solving the fragment assembly problem,” ISSNASC-2011,
pp. 191–198, Sep. 2011.

[19] K.-W. Huang, J.-L. Chen, C.-S. Yang, and C.-W. Tsai, “A memetic
particle swarm optimization algorithm for solving the DNA fragment
assembly problem,” NCA, vol. 26, no. 3, pp. 495–506, April 2015.
[20] D. Henderson, S. Jacobson, and A. Johnson, “The theory and practice
of simulated annealing,” Handbook of Metaheuristics, pp. 287–319, 04
2006.

[21] I. Z. Ahmed, H. Sadjadpour, and S. Youseﬁ, “ADC bit allocation for
massive MIMO using modiﬁed dynamic programming,” ANTS-2019, pp.
1–6, Dec. 2019.

[22] W. J. Cook, In pursuit of the traveling salesman: mathematics at the

limits of computation. Princeton University Press, 2012.

[23] J. Shendure, S. Balasubramanian, G. M. Church, W. Gilbert, J. Rogers,
J. A. Schloss, and R. H. Waterston, “Dna sequencing at 40: past, present
and future,” Nature, vol. 568, no. 7752, 2019.

[24] F. Sanger, A. R. Coulson, G. F. Hong, D. F. Hill, and G. B. Petersen,
“Nucleotide sequence of bacteriophage lambda dna,” Journal of Molec-
ular Biology, vol. 162, no. 4, pp. 729–773, Dec. 1982.

[25] T. F. Smith and M. S. Waterman, “Identiﬁcation of common molecular
subsequences,” Journal of Molecular Biology, vol. 147, no. 1, pp. 195–
197, Mar. 1981.

