Machine learning manuscript No.
(will be inserted by the editor)

Learning programs by learning from failures

Andrew Cropper · Rolf Morel

0
2
0
2

v
o
N
5
2

]
I

A
.
s
c
[

3
v
9
5
2
2
0
.
5
0
0
2
:
v
i
X
r
a

the date of receipt and acceptance should be inserted later

Abstract We describe an inductive logic programming (ILP) approach called learning
from failures. In this approach, an ILP system (the learner) decomposes the learning
problem into three separate stages: generate, test, and constrain. In the generate stage,
the learner generates a hypothesis (a logic program) that satisﬁes a set of hypothesis con-
straints (constraints on the syntactic form of hypotheses). In the test stage, the learner
tests the hypothesis against training examples. A hypothesis fails when it does not entail
all the positive examples or entails a negative example. If a hypothesis fails, then, in the
constrain stage, the learner learns constraints from the failed hypothesis to prune the
hypothesis space, i.e. to constrain subsequent hypothesis generation. For instance, if a
hypothesis is too general (entails a negative example), the constraints prune generali-
sations of the hypothesis. If a hypothesis is too speciﬁc (does not entail all the positive
examples), the constraints prune specialisations of the hypothesis. This loop repeats un-
til either (i) the learner ﬁnds a hypothesis that entails all the positive and none of the
negative examples, or (ii) there are no more hypotheses to test. We introduce Popper, an
ILP system that implements this approach by combining answer set programming and
Prolog. Popper supports inﬁnite problem domains, reasoning about lists and numbers,
learning textually minimal programs, and learning recursive programs. Our experimen-
tal results on three domains (toy game problems, robot strategies, and list transforma-
tions) show that (i) constraints drastically improve learning performance, and (ii) Popper
can outperform existing ILP systems, both in terms of predictive accuracies and learning
times.

1 Introduction

Inductive logic programming (ILP) [45] is a form of machine learning. Given examples
of a target predicate and background knowledge (BK), the ILP problem is to induce a

A. Cropper
University of Oxford
E-mail: andrew.cropper@cs.ox.ac.uk

R. Morel
University of Oxford
E-mail: rolf.morel@cs.ox.ac.uk

 
 
 
 
 
 
2

Andrew Cropper, Rolf Morel

hypothesis which, with the BK, correctly generalises the examples. A key characteristic
of ILP is that it represents the examples, BK, and hypotheses as logic programs (sets of
logical rules).

Compared to most machine learning approaches, ILP has several advantages [18].
ILP systems can generalise from small numbers of examples, often a single example [40].
Because hypotheses are logic programs, they can be read by humans, crucial for explain-
able AI and ultra-strong machine learning [42]. Finally, because of their symbolic nature,
ILP systems naturally support lifelong and transfer learning [15], which is considered es-
sential for human-like AI [36].

The fundamental problem in ILP is to efﬁciently search a large hypothesis space
(the set of all hypotheses). A popular ILP approach is to use a set covering algorithm
to learn hypotheses one clause at-a-time [54, 46, 7, 63, 1]. Systems that implement this
approach are often efﬁcient because they are example-driven. However, these systems
tend to learn overly speciﬁc solutions and struggle to learn recursive programs [8, 18].
An alternative, but increasingly popular, approach is to encode the ILP problem as an
answer set programming (ASP) problem [12, 38, 60, 34, 29]. Systems that implement this
approach can often learn optimal and recursive programs and can harness state-of-the-
art ASP solvers, but often struggle with scalability, especially in terms of the problem
domain size.

In this paper, we describe an ILP approach called learning from failures (LFF). In this
approach, the learner (an ILP system) decomposes the ILP problem into three separate
stages: generate, test, and constrain. In the generate stage, the learner generates a hy-
pothesis (a logic program) that satisﬁes a set of hypothesis constraints (constraints on
the syntactic form of hypotheses). In the test stage, the learner tests a hypothesis against
training examples. A hypothesis fails when it does not entail all the positive examples or
entails a negative example. If a hypothesis fails, then, in the constrain stage, the learner
learns hypothesis constraints from the failed hypothesis to prune the hypothesis space,
i.e. to constrain subsequent hypothesis generation.

Compared to other approaches that employ a generate/test/constrain loop [37], a
key idea in this paper is to use theta-subsumption [51] to translate a failed hypothesis
into a set of constraints. For instance, if a hypothesis is too general (entails a negative
example), the constraints prune generalisations of the hypothesis. If a hypothesis is too
speciﬁc (does not entail all the positive examples), the constraints prune specialisations
of the hypothesis. This loop repeats until either (i) the learner ﬁnds a solution (a hypoth-
esis that entails all the positive examples and none of the negative examples), or (ii)
there are no more hypotheses to test. Figure 1 illustrates this loop.

Example 1 (Learning from failures) To illustrate our approach, consider learning a last/2
hypothesis to ﬁnd the last element of a list. For simplicity, assume an initial hypothesis

Learning programs by learning from failures

3

Predicate declarations Hypothesis constraints

GENERATE

learned
constraints

logic
program

CONSTRAIN

TEST

Examples

failure

Background
knowledge

Fig. 1: The generate, test, and constrain loop.

space H1:

H1 =

h1 =
h2 =
h3 =
h4 =
h5 =

h6 =

h7 =

h8 =

(cid:8)
(cid:8)
(cid:8)
(cid:8)
(cid:8)
§

§

§

(cid:9)

last(A,B):- head(A,B).
last(A,B):- head(A,B),empty(A).
(cid:9)
last(A,B):- tail(A,C),head(C,B).
last(A,B):- reverse(A,C),head(C,B).
last(A,B):- head(A,B),reverse(A,C),head(C,B).
last(A,B):- tail(A,C),head(C,B).
last(A,B):- reverse(A,C),head(C,B). ª
last(A,B):- tail(A,C),head(C,B).
last(A,B):- tail(A,C),tail(C,D),head(D,B). ª
last(A,B):- reverse(A,C),tail(C,D),head(D,B).
last(A,B):- tail(A,C),reverse(C,D),head(D,B). ª

(cid:9)

(cid:9)

(cid:9)











Also assume we have the positive (E+) and negative (E−) examples:

E+ =

last([l,a,u,r,a],a).
last([p,e,n,e,l,o,p,e],e). ª

§

E− =

last([e,m,m,a],m).
last([j,a,m,e,s],e). ª

§

In the generate stage, the learner generates a hypothesis:

last(A,B):- head(A,B).

h1 =

(cid:8)

(cid:9)

In the test stage, the learner tests h1 against the examples and ﬁnds that it fails because it
does not entail any positive example and is therefore too speciﬁc. In the constrain stage,
the learner learns hypothesis constraints to prune specialisations of h1 (h2 and h5) from
the hypothesis space. The hypothesis space is now:

h3 =
h4 =

h6 =

h7 =

h8 =

(cid:9)

last(A,B):- tail(A,C),head(C,B).
last(A,B):- reverse(A,C),head(C,B).
(cid:9)
last(A,B):- tail(A,C),head(C,B).
last(A,B):- reverse(A,C),head(C,B). ª
last(A,B):- tail(A,C),head(C,B).
last(A,B):- tail(A,C),tail(C,D),head(D,B). ª
last(A,B):- reverse(A,C),tail(C,D),head(D,B).
last(A,B):- tail(A,C),reverse(C,D),head(D,B). ª

(cid:8)
(cid:8)
§

§

§






H2 =






4

Andrew Cropper, Rolf Morel

In the next generate stage, the learner generates another hypothesis:

last(A,B):- tail(A,C),head(C,B).

h3 =

(cid:8)

(cid:9)

The learner tests h3 against the examples and ﬁnds that it fails because it entails the
negative example last([e,m,m,a],m) and is therefore too general. The learner learns
constraints to prune generalisations of h3 (h6 and h7) from the hypothesis space. The
hypothesis space is now:

H3 = 


h4 =

h8 =

last(A,B):- reverse(A,C),head(C,B).
last(A,B):- reverse(A,C),tail(C,D),head(D,B).
last(A,B):- tail(A,C),reverse(C,D),head(D,B). ª

(cid:9)

(cid:8)
§






The learner generates another hypothesis (h4), tests it against the examples, ﬁnds that
it does not fail, and returns it.



Whereas many ILP approaches iteratively reﬁne a clause [54, 46, 57, 7, 63, 1] or reﬁne
a hypothesis [61, 8, 4, 22], our approach reﬁnes the hypothesis space through learned
hypothesis constraints. In other words, LFF continually builds a set of constraints. The
more constraints we learn, the more we reduce the hypothesis space. By reasoning about
the hypothesis space, our approach can drastically prune large parts of the hypothesis
space by testing a single hypothesis.

We implement our approach in Popper1, a new ILP system which combines ASP and
Prolog. In the generate stage, Popper uses ASP to declaratively deﬁne, constrain, and
search the hypothesis space. The idea is to frame the problem as an ASP problem where
an answer set (a model) corresponds to a program, an approach also employed by other
recent ILP approaches [12, 38, 34, 60]. By later learning hypothesis constraints, we elim-
inate answer sets and thus prune the hypothesis space. Our ﬁrst motivation for using
ASP is its declarative nature, which allows us to, for instance, deﬁne constraints to en-
force Datalog and type restrictions, constraints to prune recursive hypotheses that do
not contain base cases, and constraints to prune generalisations and specialisations of a
failed hypothesis. Our second motivation is to use state-of-the-art ASP systems [32] to
efﬁciently solve our complex constraint problem. In the test stage, Popper uses Prolog
to test hypotheses against the examples and BK. Our main motivation for using Prolog
in this stage is to learn programs that use lists, numbers, and large domains. In the con-
strain stage, Popper learns hypothesis constraints (in the form of ASP constraints) from
failed hypotheses to prune the hypothesis space, i.e. to constrain subsequent hypothesis
generation. To efﬁciently combine the three stages, Popper uses ASP’s multi-shot solving
[33] to maintain state between the three stages, e.g. to remember learned conﬂicts on
the hypothesis space.

To give a clear overview of Popper, Table 1 compares Popper to Aleph [63], a clas-
sical ILP system, and Metagol [22], ILASP3 [37], and ∂ ILP [28], three state-of-the-art
ILP systems based on Prolog, ASP, and neural networks respectively. Compared to Aleph,
Popper can learn optimal and recursive programs2. Compared to Metagol, Popper does

1 Popper is named after Karl Poppper, whose idea of falsiﬁcation [53] inspired our approach, as it did
Shapiro’s MIS approach [61]. In fact, one can view our approach as Popper’s idea of falsiﬁcation, where
a failure is a refutation/falsiﬁcation. In other words, in our approach, a learner deduces what hypotheses
cannot be true and prunes them from the hypothesis space, leaving only hypotheses not yet refuted.

2 Aleph can learn recursive programs but struggles because it requires examples of both the base and

inductive cases.

Learning programs by learning from failures

5

not need metarules [24], so can learn programs with any arity predicates. Compared
to ∂ ILP, Popper supports non-ground clauses as BK, so supports large and inﬁnite do-
mains. Compared to ILASP3, Popper does not need to ground a program, so scales better
as the domain size grows (Section 5.2). Compared to all the systems, Popper supports
hypothesis constraints, such as disallowing the co-occurrence of predicate symbols in a
program, disallowing recursive hypotheses that do not contain base cases, or preventing
subsumption redundant hypotheses.

Aleph

Metagol

ILASP3

∂ ILP

Popper

Hypotheses
Language bias
Predicate invention
Noise handling
Recursion
Optimality
Hypothesis constraints

Normal
Modes
No
Yes
Partly
No
No

ASP

Deﬁnite
Metarules Modes
Yes
Partly
Yes
No
Yes
Yes
Yes
Yes
No
No

Datalog
Templates
Partly
Yes
Yes
Yes
No

Deﬁnite
Declarations
No
No
Yes
Yes
Yes

Table 1: A simpliﬁed comparison of ILP systems. Aleph can learn recursive programs but
struggles because it requires examples of both the base and inductive cases. Metagol
supports automatic predicate invention, whereas ILASP3 and ∂ ILP support prescriptive
predicate invention [37], where the arity and argument types of an invented predicate
must be speciﬁed by the given language bias.

ILASP3 [37] is the most similar ILP approach and also employs a generate/test/con-
strain loop. We discuss in detail the differences between ILASP3 and Popper in Section
2.6 but brieﬂy summarise them now. ILASP3 learns ASP programs and can handle noise,
whereas Popper learns Prolog programs and cannot currently handle noise. ILASP3 pre-
computes every rule in the hypothesis space and therefore struggles to learn rules with
many body literals (Section 5.1). By contrast, Popper does not pre-compute every rule,
which allows it to learn rules with many body literals. With each iteration, ILASP3 ﬁnds
the best hypothesis it can. If the hypothesis does not cover one of the examples, ILASP3
ﬁnds a reason why and then generates constraints to guide subsequent search3. The con-
straints are boolean formulas over the rules in the hypothesis space, an approach that
requires a set of pre-computed rules and the computation of which can be very expensive.
Another way of viewing ILASP3 is that it uses a counter-example guided [62] approach
and translates an uncovered example e into a constraint that is satisﬁed if and only if e
is covered. By contrast, the key idea of Popper is that when a hypothesis fails, Popper
uses theta-subsumption [51] to translate the hypothesis itself into a set of hypothesis con-
straints to rule out generalisations and specialisations of it, which does not need a set of
pre-computed rules and which is substantially quicker to compute.

Overall our speciﬁc contributions in this paper are:

– We deﬁne the LFF problem, determine the size of the LFF hypothesis space, deﬁne
hypothesis generalisations and specialisations based on theta-subsumption and show
that they are sound with respect to optimal solutions (Section 3).

3 This statement covers the noiseless ILASP3 setting. Things are slightly more complicated in noisy
tasks where examples are given penalties and ILASP3 may return a hypothesis that does not cover all
examples, but is optimal with respect to the penalties.

6

Andrew Cropper, Rolf Morel

– We introduce Popper, an ILP system that learns deﬁnite programs (Section 4). Pop-
per support types, learning optimal (textually minimal) solutions, learning recursive
programs, reasoning about lists and inﬁnite domains, and hypothesis constraints.
– We experimentally show (Section 5) on three domains (toy game problems, robot
strategies, and list transformations) that (i) constraints drastically reduce the hy-
pothesis space, (ii) Popper scales well with respect to the optimal solution size, the
number of background relations, the domain size, the number of training examples,
and the size of the training examples, and (iii) Popper can substantially outperform
existing ILP systems both in terms of predictive accuracies and learning times.

2 Related work

2.1 Inductive program synthesis

The goal of inductive program synthesis is to induce a program from a partial speciﬁca-
tion, typically input/output examples [61]. This topic interests researchers from many
areas of computer science, notably machine learning (ML) and programming languages
(PL). The major4 difference between ML and PL approaches is the generality of solutions
(synthesised programs). PL approaches often aim to ﬁnd any program that ﬁts the spec-
iﬁcation, regardless of whether it generalises. Indeed, PL approaches rarely evaluate the
ability of their systems to synthesise solutions that generalise, i.e. they do not measure
predictive accuracy [31, 52, 2, 30, 58]. By contrast, the major challenge in ML is learning
hypotheses that generalise to unseen examples. Indeed, it is often trivial for an ML sys-
tem to learn an overly speciﬁc solution for a given problem. For instance, an ILP system
can trivially construct the bottom clause [46] for each example. Because of this major
difference, in the rest of this section, we focus on ML approaches to inductive program
synthesis. We ﬁrst, however, brieﬂy cover two PL approaches, which share similarities to
our learning from failures idea.

Neo [30] synthesises non-recursive programs using SMT encoded properties and a
three staged loop. Neo inherently requires SMT encoded properties for domain speciﬁc
functions (i.e. its background knowledge). For instance, their property for head, taking
an input list and returning an out put list, is the formula input.size ≥ 1∧ out put.size =
1 ∧ out put.ma x ≤ input.ma x. Neo’s ﬁrst stage builds up partially constructed pro-
grams. Its second stage uses SMT-based deduction on the properties of a partial program
to detect inconsistency. The third stage determines related partial programs who must
be inconsistent and can therefore be pruned. As it typically uses over-approximate prop-
erties, Neo can fail to detect inconsistency with the examples, in which case no programs
get pruned. In contrast, our approach does not need any properties of background predi-
cates. We only check whether a hypothesis entails the examples, always pruning special-
isations and/or generalisations when the hypothesis fails. Neo cannot synthesise recur-
sive programs, nor is it guaranteed to synthesise optimal (textually minimal) programs.
By contrast, Popper can learn optimal and recursive logic programs.

ProSynth [58] takes as input a set of candidate Datalog rules and returns a subset of
them. ProSynth learns constraints that disallow certain clause combinations, e.g. to pre-
vent clauses that entail a negative example from occurring together. Popper differs from
ProSynth in several ways. ProSynth takes as input the full hypothesis space (the set of

4 Minor differences include the form of speciﬁcation and noise handling.

Learning programs by learning from failures

7

candidate rules). By contrast, Popper does not fully construct the hypothesis space. This
difference is important because it is often infeasible to pre-compute the full hypothesis
space. For instance, the largest number of candidate rules considered in the ProSynth
experiments is 1000. By contrast, in our ﬁrst two experiments (Section 5.1), the hypoth-
esis spaces contain approximately 106 and 1016 rules. ProSynth provides no guarantees
about solution size. By contrast, Popper is guaranteed to learn an optimal (smallest) so-
lution (Theorem 1). Moreover, whereas ProSynth synthesises Datalog programs, Popper
additionally learns deﬁnite programs, and thus supports learning programs with inﬁnite
domains.

2.2 Inductive logic programming

There are various ML approaches to inductive program synthesis, including neural ap-
proaches [6, 26, 27]. We focus on inductive logic programming (ILP) [45, 16]. As with
other forms of ML, the goal of an ILP system is to learn a hypothesis that correctly gen-
eralises given training examples. However, whereas most forms of ML represent data
(examples and hypotheses) as tables, ILP represents data as logic programs. Moreover,
whereas most forms of ML learn functions, ILP learns relations.

Rather than reﬁne a clause [54, 46, 57, 7, 63, 1], or a hypothesis [61, 8, 4, 22], our
approach reﬁnes the hypothesis space through learned hypothesis constraints. In other
words, in our approach continually builds a set of constraints. The more constraints
we learn, the more we reduce the hypothesis space. By reasoning about the hypothesis
space, our approach can drastically prune large parts of the hypothesis space by testing
a single hypothesis.

Atom [1] learns deﬁnite programs using SAT solvers and also learns constraints.
However, because it builds on Progol [46], and thus employs inverse entailment, Atom
struggles to learn recursive programs because it needs examples of both the base and
step cases of a recursive program. For the same reason, Atom struggles to learn optimal
solutions. By contrast, Popper can learn recursive and optimal solutions because it learns
programs rather than individual clauses.

2.3 Recursion

Learning recursive programs has long been considered a difﬁcult problem in ILP [47].
Without recursion, it is often difﬁcult for an ILP system to generalise from small num-
bers of examples [23]. Indeed, many popular ILP systems, such as FOIL [54], Progol
[46], TILDE [7], and Aleph [63] struggle to learn recursive programs. The reason is that
they employ a set covering approach to build a hypothesis clause by clause. Each clause
is usually found by searching an ordering over clauses. A common approach is to pick
an uncovered example, generate the bottom clause [46] for this example, the logically
most speciﬁc clause that entails the example, and then to search the subsumption lattice
(either top-down or bottom-up) bounded by this bottom clause. Systems that implement
this approach are often efﬁcient because the hypothesis search is example-driven. How-
ever, these systems tend to learn overly speciﬁc solutions and struggle to learn recursive
programs [8, 18]. To overcome this limitation, Popper searches over logic programs (sets
of clauses), a technique used by other ILP systems [8, 4, 38, 22, 28, 34].

8

2.4 Optimality

Andrew Cropper, Rolf Morel

There are often multiple (sometimes inﬁnite) hypotheses that explain the data. Deciding
which hypothesis to choose is a difﬁcult problem. Many ILP systems [46, 63, 7, 59] are
not guaranteed to learn optimal solutions, where optimal typically means the smallest
program or the program with the minimal description length. The claimed advantage
of learning optimal solutions is better generalisation. Recent meta-level ILP approaches
often learn optimal solutions, such as programs with the fewest clauses [49, 22, 34] or
literals [12, 38]. Popper also learns optimal solutions, measured as the total number of
literals in the hypothesis.

2.5 Language bias

ILP approaches use a language bias [50] to restrict the hypothesis space. Language bias
can be categorised as syntactic bias, which restricts the syntax of hypotheses, such as the
number of variables allowed in a clause, and semantic bias, which restricts hypotheses
based on their semantics, such as whether they are functional, irreﬂexive, etc.

Mode declarations [46] are a popular language bias [7, 63, 59, 11, 12, 4, 1, 38]. Mode
declarations state which predicate symbols may appear in a clause, how often they may
appear, the types of their arguments, and whether their arguments must be ground. We
do not use mode declarations. We instead use a simple language bias which we call pred-
icate declarations (Section 3), where a user needs only state whether a predicate symbol
may appear in the head or/and body of a clause. Predicate declarations are almost iden-
tical to determinations in Aleph [63]. The only difference is a minor syntactic one. In
addition to predicate declarations, a user can provide other language biases, such as type
information, as hypothesis constraints (Section 2.7).

Metarules [24] are another popular syntactic bias used by many ILP approaches [56,
66, 2, 34], including Metagol [49, 20, 22] and, to an extent5, ∂ ILP [28]. A metarule is a
higher-order clause which deﬁnes the exact form of clauses in the hypothesis space. For
instance, the chain metarule is of the form P(A, B) ← Q(A, C), R(C, B), where P, Q, and
R denote predicate variables, and allows for instantiated clauses such as last(A,B):-
reverse(A,C),head(C,B). Compared with predicate (and mode) declarations, metarules
are a much stronger inductive bias because they specify the exact form of clauses in the
hypothesis space. However, the major problem with metarules is determining which ones
to use [24]. A user must either (i) provide a set of metarules, or (ii) use a set of metarules
restricted to a certain fragment of logic, e.g. dyadic Datalog [24]. This limitation means
that ILP systems that use metarules are difﬁcult to use, especially when the BK contains
predicate symbols with arity greater than two. If suitable metarules are known, then, as
we show in Appendix A, Popper can simulate metarules through hypothesis constraints.

2.6 Answer set programming

Much recent work in ILP uses ASP to learn Datalog [29], deﬁnite [48, 34, 17], normal
[59, 12, 4], and answer set programs [38]. ASP is a declarative language that supports
language features such as aggregates and weak and hard constraints. Most ASP solvers

5 ∂ ILP uses program templates to essentially generate sets of metarules.

Learning programs by learning from failures

9

only work on ground programs [32]6. Therefore, a major limitation of most pure ASP-
based ILP systems is the intrinsic grounding problem, especially on large domains, such
as reasoning about lists or numbers – most ASP implementations do not support lists
nor real numbers. For instance, ILASP [38] can represent real numbers as strings and
delegate the reasoning to Python via Clingo’s scripting feature [32]. However, in this
approach, the numeric computation is performed when grounding the inputs, so the
grounding must be ﬁnite. Difﬁculty handling large (or inﬁnite) domains is not speciﬁc to
ASP. For instance, ∂ ILP uses a neural network to induce programs, but only works on BK
formed of a ﬁnite set of ground atoms. To overcome this grounding limitation, Popper
combines ASP and Prolog. Popper uses ASP to generate deﬁnite programs, which allows
it to reason about large and inﬁnite problem domains, such as reasoning about lists and
real numbers.

ILASP3 [37] is a pure ASP-based ILP system that also employs a constrain loop.
ILASP3 learns unstratiﬁed ASP programs, including programs with choice rules and
weak and hard constraints, and can handle noise. By contrast, Popper learns Prolog
programs, including programs operating over lists and real numbers, but cannot handle
noise. ILASP3 pre-computes every clause in the hypothesis space deﬁned by a set of given
mode declarations. As we show in Experiment 1 (Section 5.1), this approach struggles
to learn clauses with many body literals. By contrast, Popper does not pre-compute ev-
ery clause, which allows it to learn clauses with many body literals. With each iteration,
ILASP3 ﬁnds the best hypothesis it can. If the hypothesis does not cover one of the ex-
amples, ILASP3 ﬁnds a reason why and then generates constraints to guide subsequent
search7. The constraints are boolean formulas over the rules in the hypothesis space, an
approach that requires a set of pre-computed rules. This approach can be very expensive
to compute because in the worst-case ILASP3 may need to consider every hypothesis to
build a constraint (although this worst-case scenario is unlikely). Another way of viewing
ILASP3 is that it uses a counter-example guided [62] approach and translates an uncov-
ered example e into a constraint that is satisﬁed if and only if e is covered. By contrast,
when a hypothesis fails, Popper translates the hypothesis itself into a set of hypothesis
constraints. Popper’s constraints do not reason about speciﬁc clauses (because we do not
pre-compute the hypothesis space), but instead reason about the syntax of hypotheses
using theta-subsumption and are therefore quick to compute. Another subtle difference
is how often the constrain loop is employed in ILASP3 and Popper. ILASP3’s constraint
loop requires at most |E| iterations, where |E| is the number of ILASP examples, which
are partial interpretations. Because ILASP3’s examples are partial interpretations [38],
it is possible to represent multiple atomic examples in a single partial interpretation ex-
ample. In fact, each learning task in this paper can be represented as a single ILASP
positive example [38]. If represented this way, ILASP3 will generate at most one con-
straint (which will be satisﬁed if and only if a hypothesis covers the example). For this
reason, ILASP3 performs much better if the examples are split into one (partial interpre-
tation) example per atomic example. By contrast, the constraint loop of Popper is not
bound by the number of examples but by the size of the hypothesis space.

6 A notable exception is Alpha Solver [67].
7 This statement covers the noiseless ILASP3 setting. Things are slightly more complicated in noisy
tasks where examples are given penalties and ILASP3 may return a hypothesis that does not cover all
examples, but is optimal with respect to the penalties. Since Popper does not yet support noise, we only
consider the noiseless ILASP3 setting.

10

Andrew Cropper, Rolf Morel

2.7 Hypothesis constraints

Constraints are fundamental to our idea. Many ILP systems allow a user to constrain the
hypothesis space though clause constraints [46, 63, 7, 1, 38]. For instance, Progol, Aleph,
and TILDE allow for a user to provide constraints on clauses that should not be violated.
Popper also allows a user to provide clause constraints. Popper additionally allows a
user to provide hypothesis constraints (or meta-constraints)8, which are constraints over
a whole hypothesis (a set of clauses), not an individual clause. As a trivial example, sup-
pose you want to disallow two predicate symbols p/2 and q/2 from both simultaneously
appearing in a program (in any body literal in any clause). Then, because Popper reasons
at the meta-level, this restriction is trivial to express:

:- body_literal(_,p,2,_), body_literal(_,q,2,_).

This constraint prunes hypotheses where the predicate symbols p/2 and q/2 both appear
in the body of a hypothesis (possibly in different clauses). The key thing to notice is the
ease, uniformity, and succinctness of expressing constraints. We introduce our full meta-
level encoding in Section 4.

Declarative hypothesis constraints have many advantages. For instance, through hy-
pothesis constraints, Popper can enforce (optional) type, metarule, recall, and function-
ality restrictions. Moreover, hypothesis constraints allow us to prune recursive programs
without a base case and subsumption redundant programs. Finally, and most impor-
tantly, hypothesis constraints allow us to prune generalisations and specialisations of
failed hypotheses, which we discuss in the next section.

Athakravi et al. [3] introduce domain-dependent constraints, which are constraints
on the hypothesis space provided as input by a user. INSPIRE [60] also uses predeﬁned
constraints to remove redundancy from the hypothesis space (in INSPIRE’s case, each
hypothesis is a single clause). Popper also supports such constraints but goes further by
learning constraints from failed hypotheses.

3 Problem setting

We now deﬁne our problem setting.

3.1 Logic preliminaries

We assume familiarity with logic programming notation [41] but we restate some key
terminology. All sets are ﬁnite unless otherwise stated. A clause is a set of literals. A clausal
theory is a set of clauses. A Horn clause is a clause with at most one positive literal. A
Horn theory is a set of Horn clauses. A deﬁnite clause is a Horn clause with exactly one
positive literal. A deﬁnite theory is a set of deﬁnite clauses. A Horn clause is a Datalog
clause if it contains no function symbols and every variable that appears in the head of
the clause also appears in the body of the clause. A Datalog theory is a set of Datalog
clauses. Simultaneously replacing variables v1, . . . , vn in a clause with terms t1, . . . , tn is
a substitution and is denoted as θ = {v1/t1, . . . , vn/tn}. A substitution θ uniﬁes atoms A

8 The term hypothesis constraint is also used in existing work [64,13] as an optional set of constraints

on acceptable hypotheses, but without any further explanation.

Learning programs by learning from failures

11

and B when Aθ = Bθ . We will often use program as a synonym for theory, e.g. a deﬁnite
program as a synonym for a deﬁnite theory.

3.2 Problem setting

Our problem setting is based on the ILP learning from entailment setting [55]. Our goal
is to take as input positive and negative examples of a target predicate, background
knowledge (BK), and to return a hypothesis (a logic program) that with the BK entails
all the positive and none of the negative examples. In this paper, we focus on learning
deﬁnite programs. We will generalise the approach to non-monotonic programs in future
work.

ILP approaches search a hypothesis space, the set of learnable hypotheses. ILP ap-
proaches restrict the hypothesis space through a language bias (Section 2.5). Several
forms of language bias exist, such as mode declarations [46], grammars [10] and metarules
[24]. We use a simple language bias which we call predicate declarations. A predicate
declaration simply states which predicate symbols may appear in the head (head decla-
rations) or body (body declarations) of a clause in a hypothesis:

Deﬁnition 1 (Head declaration) A head declaration is a ground atom of the form
head_pred(p,a) where p is a predicate symbol of arity a.

Deﬁnition 2 (Body declaration) A body declaration is a ground atom of the form body_pred(p,a)
where p is a predicate symbol of arity a.

Predicate declarations are almost identical to Aleph’s determinations [63] but with a
minor syntactical difference because determinations are of the form:

determination(TargetName/Arity,BackgroundName/Arity).

A declaration bias D is a pair (Dh, Db) of sets of head (Dh) and body (Db) declarations.
We deﬁne a declaration consistent clause:

Deﬁnition 3 (Declaration consistent clause) Let D = (Dh, Db) be a declaration bias
and C = h ← b1, b2, . . . , bn be a deﬁnite clause. Then C is declaration consistent with D
if and only if:

– h is an atom of the form p(X 1, . . . , X n) and head_pred(p,n) is in Dh
– every bi is a literal of the form p(X 1, . . . , X n) and body_pred(p, n) is in Db
– every X i is a ﬁrst-order variable

Example 2 (Declaration consistency) Let D be the declaration bias:

({head_pred(targ,2)}, {body_pred(head,2), body_pred(tail,2)})

Then the following clauses are all consistent with D:

targ(A,B):- head(A,C).
targ(A,A):- head(B,A).
targ(A,B):- head(A,C),tail(C,B).

By contrast, the following clauses are inconsistent with D:

targ(A):- head(A,C).
targ(A,B):- targ(A,B).
tail(A,B):- reverse(A,C),tail(C,B).

12

Andrew Cropper, Rolf Morel

We deﬁne a declaration consistent hypothesis:

Deﬁnition 4 (Declaration consistent hypothesis) A declaration consistent hypothesis
H is a set of deﬁnite clauses where each C ∈ H is declaration consistent with D.

Example 3 (Declaration consistent hypothesis) Let D be the declaration bias:

({head_pred(targ,2)}, {body_pred(head,2), body_pred(tail,2)})

Then two declaration consistent hypotheses are:

h1 :

h2 :

targ(A,B):- head(A,B)
(cid:9)
targ(A,B):- head(A,B).
targ(A,B):- tail(A,C),head(C,B). ª

(cid:8)
§

In addition to a declaration bias, we restrict the hypothesis space through hypothesis
constraints. We ﬁrst clarify what we mean by a constraint:

Deﬁnition 5 (Constraint) A constraint is a Horn clause without a head, i.e. a denial.
We say that a constraint is violated if all of its body literals are true.

Rather than deﬁne hypothesis constraints for a speciﬁc encoding (e.g. the encoding we
use in Section 4), we use a more general deﬁnition:

Deﬁnition 6 (Hypothesis constraint) Let L be a language that deﬁnes hypotheses,
i.e. a meta-language. Then a hypothesis constraint is a constraint expressed in L .

Example 4 In Section 4, we introduce a meta-language for deﬁnite programs. In our
encoding, the atom head_literal(Clause,Pred,Arity,Vars) denotes that the clause
Clause has a head literal with the predicate symbol Pred, is of arity Arity, and has the
arguments Vars. An example hypothesis constraint in this language is:

:- head_literal(_,p,2,_).

This constraint states that a predicate symbol p of arity 2 cannot appear in the head of
any clause in a hypothesis.

Example 5 In our encoding, the atom body_literal(Clause,Pred,Arity,Vars) de-
notes that the clause Clause has a body literal with the predicate symbol Pred, is of
arity Arity, and has the arguments Vars. An example hypothesis constraint in this lan-
guage is:

:- head_literal(_,p,2,_), body_literal(_,p,2,_).

This constraint states that the predicate symbol p cannot appear in the body of a clause
if it appears in the head of a clause (not necessarily the same clause).

We deﬁne a constraint consistent hypothesis:

Deﬁnition 7 (Constraint consistent hypothesis) Let C be a set of hypothesis con-
straints written in a language L . A set of deﬁnite clauses H is consistent with C if, when
written in L , H does not violate any constraint in C.

We now deﬁne our hypothesis space:

Learning programs by learning from failures

13

Deﬁnition 8 (Hypothesis space) Let D be a declaration bias and C be a set of hypothe-
sis constraints. Then the hypothesis space HD,C is the set of all declaration and constraint
consistent hypotheses. We refer to any element in HD,C as a hypothesis.

We deﬁne the LFF problem input:

Deﬁnition 9 (LFF problem input) Our problem input is a tuple (B, D, C, E+, E−) where

– B is a Horn program denoting background knowledge
– D is a declaration bias
– C is a set of hypothesis constraints
– E+ is a set of ground atoms denoting positive examples
– E− is a set of ground atoms denoting negative examples

Note that C, E+, and E− can be empty sets (but E+ and E− cannot both be empty). We as-
sume that no predicate symbol in the body of a clause in B appears in a head declaration
of D. In other words, we assume that the BK does not depend on any hypothesis.

For convenience, we deﬁne different types of hypotheses, mostly using standard ILP

terminology [50]:

Deﬁnition 10 (Hypothesis types) Let (B, D, C, E+, E−) be an input tuple and H ∈ HD,C
be a hypothesis. Then H is:

– Complete when ∀e ∈ E+ H ∪ B |= e
– Consistent when ∀e ∈ E−, H ∪ B 6|= e
– Incomplete when ∃e ∈ E+, H ∪ B 6|= e
– Inconsistent when ∃e ∈ E−, H ∪ B |= e
– Totally incomplete when ∀e ∈ E+, H ∪ B 6|= e

We deﬁne a LFF solution, i.e. our problem output:

Deﬁnition 11 (LFF solution) Given an input tuple (B, D, C, E+, E−), a hypothesis H ∈
HD,C is a solution when H is complete and consistent.

Conversely, we deﬁne a failed hypothesis:

Deﬁnition 12 (Failed hypothesis) Given an input tuple (B, D, C, E+, E−), a hypothesis
H ∈ HD,C fails (or is a failed hypothesis) when H is either incomplete or inconsistent.

There may be multiple (sometimes inﬁnite) solutions. We want to ﬁnd the smallest so-
lution:

Deﬁnition 13 (Hypothesis size) The function size(H) returns the total number of lit-
erals in the hypothesis H.

We deﬁne an optimal solution:

Deﬁnition 14 (Optimal solution) Given an input tuple (B, D, C, E+, E−), a hypothesis
H ∈ HD,C is an optimal solution when two conditions hold:

– H is a solution
– ∀H ′ ∈ HD,C , such that H ′ is a solution, size(H) ≤ size(H ′)

14

Andrew Cropper, Rolf Morel

3.3 Hypothesis space

The purpose of LFF is to reduce the size of the hypothesis space through learned hy-
pothesis constraints. The size of the unconstrained hypothesis space is a function of a
declaration bias and additional bounding variables:

Proposition 1 (Hypothesis space size) Let D = (Dh, Db) be a declaration bias with a
maximum arity a, v be the maximum number of unique variables allowed in a clause,
m be the maximum number of body literals allowed in a clause, and n be the maximum
number of clauses allowed in a hypothesis. Then the maximum number of hypotheses in the
unconstrained hypothesis space is:

n

Xj=1

|Dh|va
(cid:129)

m
i=1
P
j

(cid:0)

|Db|v a
i

(cid:1)

‹

Proof Let C be an arbitrary clause in the hypothesis space. There are |Dh|va ways to
deﬁne the head literal of C. There are |Db|va ways to deﬁne a body literal in C. The body
ways to choose k body literals. We bound the
of C is a set of literals. There are

number of body literals to m, so there are
literals. Therefore, there are |Dh|va
of deﬁnite clauses. Given n clauses, there are
m

|Db|v a
P
i

m
i=1

P

(cid:0)

hypothesis. Therefore, there are
at most n clauses.

P

n
j=1

|Dh|v a

P

(cid:0)

m
i=1

|Db|v a
i

ways to choose at most m body

(cid:1)

(cid:0)
ways to deﬁne C. A hypothesis is a set
(cid:1)
n
ways to choose k clauses to form a
k
i=1 (|Db |va
(cid:1)
(cid:0)
i )
j

ways to deﬁne a hypothesis with

(cid:1)

|Db|v a
k

(cid:0)

(cid:1)

As this result shows, the hypothesis space is huge for non-trivial inputs, which motivates
using learned constraints to prune the hypothesis space.

3.4 Generalisations and specialisations

To prune the hypothesis space, we learn constraints to remove generalisations and special-
isations of failed hypotheses. We reason about the generality of hypotheses syntactically
through θ -subsumption (or subsumption for short) [51]:

Deﬁnition 15 (Clausal subsumption) A clause C1 subsumes a clause C2 if and only if
there exists a substitution θ such that C1θ ⊆ C2.

Example 6 (Clausal subsumption) Let C1 and C2 be the clauses:

C1 = f(A,B):- head(A,B)
C2 = f(X,Y):- head(X,Y),odd(Y).

Then C1 subsumes C2 because C1θ ⊆ C2 with θ = {A/X , Y /B}.

If a clause C1 subsumes a clause C2 then C1 entails C2 [50]. However, if C1 entails C2
then it does not necessarily follow that C1 subsumes C2. Subsumption is therefore weaker
than entailment. However, whereas checking entailment between clauses is undecidable
[9], checking subsumption between clauses is decidable, although, in general, deciding
subsumption is a NP-complete problem [50].

Midelfart [43] extends subsumption to clausal theories:

Learning programs by learning from failures

15

Deﬁnition 16 (Theory subsumption) A clausal theory T1 subsumes a clausal theory
T2, denoted T1 (cid:22) T2, if and only if ∀C2 ∈ T2, ∃C1 ∈ T1 such that C1 subsumes C2.

Example 7 (Theory subsumption) Let h1, h2, and h3 be the clausal theories:

h1 =
h2 =

h3 =

(cid:8)
(cid:8)
§

f(A,B):- head(A,B).
f(A,B):- head(A,B),odd(B).
f(A,B):- head(A,B).
f(A,B):- reverse(A,C),head(C,B). ª

(cid:9)

(cid:9)

Then h1 (cid:22) h2, h3 (cid:22) h1, and h3 (cid:22) h2.

Theory subsumption also implies entailment:

Proposition 2 (Subsumption implies entailment) Let T1 and T2 be clausal theories. If
T1 (cid:22) T2 then T1 |= T2.

Proof Follows trivially from the deﬁnitions of clausal subsumption (Deﬁnition 15) and
theory subsumption (Deﬁnition 16).

We use theory subsumption to deﬁne a generalisation:

Deﬁnition 17 (Generalisation) A clausal theory T1 is a generalisation of a clausal the-
ory T2 if and only if T1 (cid:22) T2.

We likewise deﬁne our notion of a specialisation:

Deﬁnition 18 (Specialisation) A clausal theory T1 is a specialisation of a clausal theory
T2 if and only if T2 (cid:22) T1.

In the next section, we use these deﬁnitions to deﬁne constraints to prune the hypothesis
space.

3.5 Learning constraints from failures

In the test stage of LFF, a learner tests a hypothesis against the examples. A hypothesis
fails when it is incomplete or inconsistent. If a hypothesis fails, a learner learns hypothesis
constraints from the different types of failures. We deﬁne two general types of constraints,
generalisation and specialisation, which apply to any clausal theory, and show that they
are sound in that they do not prune solutions. We also deﬁne an elimination constraint,
which, under certain assumptions, allows us to prune programs that generalisation and
specialisation constraints do not, and which we show is sound in that it does not prune
optimal solutions. We describe these constraints in turn.

3.5.1 Generalisations and specialisations

To illustrate generalisations and specialisations, suppose we have positive examples E+,
negative examples E−, background knowledge B, and a hypothesis H. First consider the
outcomes of testing H against E−:

16

Andrew Cropper, Rolf Morel

Outcome

Description

Nnone

Nsome

H is consistent, i.e. H entails no negative example

H is inconsistent, i.e. H entails at least one negative example

Formula

∀e ∈ E−, H ∪ B 6|= e
∃e ∈ E−, H ∪ B |= e

Suppose the outcome is Nnone, i.e. H is consistent. Then we cannot prune the hypothesis
space.

Suppose the outcome is Nsome, i.e. H is inconsistent. Then H is too general so we can
prune generalisations (Deﬁnition 17) of H. A constraint that only prunes generalisations
is a generalisation constraint:

Deﬁnition 19 (Generalisation constraint) A generalisation constraint only prunes gen-
eralisations of a hypothesis from the hypothesis space.

Example 8 (Generalisation constraint) Suppose we have the negative examples E− and
the hypothesis h:

E− =

last([a,n,n],a)

h =

last(A,B):- head(A,B).

(cid:8)

(cid:9)

(cid:8)

(cid:9)

Because h entails a negative example, it is too general, so we can prune generalisations
of it, such as h1 and h2:

h1 =

h2 =

last(A,B):-head(A,B).
last(A,B):-tail(A,C),head(C,B). ª
last(A,B):-head(A,B).
last(A,B):-tail(A,C),head(C,B),head(A,B). ª

§

§

We show that pruning generalisations of an inconsistent hypothesis is sound in that it
only prunes inconsistent hypotheses, i.e. does not prune consistent hypotheses:

Proposition 3 (Generalisation soundness) Let (B, D, C, E+, E−) be a problem input,
H ∈ HD,C be an inconsistent hypothesis, and H ′ ∈ HD,C be a hypothesis such that H ′ (cid:22) H.
Then H ′ is inconsistent.

Proof Follows from Proposition 2.

Now consider the outcomes9 of testing H against E+:

Outcome

Description

Pall

Psome

Pnone

H is complete, i.e. H entails all positive examples

H is incomplete, i.e. H does entail all positive examples

H is totally incomplete, i.e. H entails no positive examples

Formula

∀e ∈ E+, H ∪ B |= e
∃e ∈ E+, H ∪ B 6|= e
∀e ∈ E+, H ∪ B 6|= e

Suppose the outcome is Pall, i.e. H is complete. Then we cannot prune the hypothesis
space.

Suppose the outcome is Psome, i.e. is incomplete. Then H is too speciﬁc so we can
prune specialisations (Deﬁnition 18) of H. A constraint that only prunes specialisations
of a hypothesis is a specialisation constraint:

Deﬁnition 20 (Specialisation constraint) A specialisation constraint only prunes spe-
cialisations of a hypothesis from the hypothesis space.

9 The outcomes are not mutually exclusive.

Learning programs by learning from failures

17

Example 9 (Specialisation constraint) Suppose we have the positive examples E+ and the
hypothesis h:

E+ =

last([b,o,b],b)
last([a,l,i,c,e],e) ª

§

h =

last(A,B):- head(A,B).

(cid:8)

(cid:9)

Because h entails the ﬁrst example but not the second it is too speciﬁc. We can therefore
prune specialisations of h, such as h1 and h2:

h1 =
h2 =

(cid:8)
(cid:8)

last(A,B):- head(A,B),empty(A).
(cid:9)
last(A,B):- head(A,B),tail(A,C).

(cid:9)

We show that pruning specialisations of an incomplete hypothesis is sound because it
only prunes incomplete hypotheses, i.e. does not prune complete hypotheses:

Proposition 4 (Specialisation soundness) Let (B, D, C, E+, E−) be a problem input, H ∈
HD,C be an incomplete hypothesis, and H ′ ∈ HD,C be a hypothesis such that H (cid:22) H ′. Then
H ′ is incomplete.

Proof Follows from Proposition 2.

3.5.2 Eliminations

Suppose the outcome is Pnone, i.e. H is totally incomplete. Then H is too speciﬁc so, as
with Psome, we can prune specialisations of H. However, because H is totally incomplete
(i.e does not entail any positive example), under certain assumptions, we can prune
more. If H is totally incomplete then there is no need for H to appear in a complete and
separable hypothesis:

Deﬁnition 21 (Separable) A separable hypothesis G is one where no predicate symbol
in the head of a clause in G occurs in the body of clause in G.

Note that separable programs include recursive programs.

Example 10 (Non-separable hypothesis) The following hypothesis is non-separable be-
cause f1/2 appears in the head and body of the program:

f(A,B):- f1(A,C),head(C,B).
f1(A,B):- tail(A,C),tail(C,B). ª

§

The following hypothesis is non-separable because last/2 appears in the head and body
of the program:

last(A,B):- head(A,B),tail(A,C),empty(C).
last(A,B):- tail(A,C),last(C,B).

§

ª

In other words, if H is totally incomplete and does not entail any positive example, then
no specialisation of H can appear in an optimal separable solution. We can therefore
prune separable hypotheses that contain specialisations of H. We call such a constraint
an elimination constraint:

Deﬁnition 22 (Elimination constraint) An elimination constraint only prunes separa-
ble hypotheses that contain specialisations of a hypothesis from the hypothesis space.

18

Andrew Cropper, Rolf Morel

Example 11 (Elimination constraint) Suppose we have the positive examples E+ and the
hypothesis h:

E+ =

last([b,o,b],b)
last([a,l,i,c,e],e) ª

§

h =

last(A,B):- tail(A,C),head(C,B).

(cid:8)
Because h does not entail any positive example there is no reason for h (nor its specialisa-
tions) to appear in a separable hypothesis. We can therefore prune separable hypotheses
which contain specialisations of h, such as:

(cid:9)

h1 =

h2 =

h3 =

last(A,B):-head(A,B).
last(A,B):-tail(A,C),head(C,B). ª
last(A,B):-head(A,B).
last(A,B):-tail(A,C),head(C,B),odd(B). ª
last(A,B):-head(A,B),even(B).
last(A,B):-tail(A,C),head(C,B),odd(B). ª

§

§

§

Elimination constraints are not sound in the same way as the generalisation and spe-
cialisation constraints because they prune solutions (Deﬁnition 11) from the hypothesis
space.

Example 12 (Elimination solution unsoundness) Suppose we have the positive examples
E+ and the hypothesis h1:

E+ =

last([j,i,m],m)
last([a,l,i,c,e],e) ª

§

h1 =

(cid:8)

last(A,B):- head(A,B).

(cid:9)

Then an elimination constraint would prune the complete hypothesis h2:

h2 =

last(A,B):- head(A,B).
last(A,B):- reverse(A,C),head(C,B). ª

§

However, for separable deﬁnite programs, elimination constraints are sound with re-
spect to optimal solutions, i.e. they only prune non-optimal solutions from the hypothesis
space. To show this result, we ﬁrst introduce a lemma:

Lemma 1 Let (B, D, C, E+, E−) be a problem input, D = (Dh, Db) be head and body dec-
larations, H1 ∈ HD,C be a totally incomplete hypothesis, H2 ∈ HD,C be a complete and
separable hypothesis such that H1 ⊂ H2, and H3 = H2 \ H1. Then H3 is complete.

Proof By assumption, no predicate symbol in Dh occurs in the body of a clause in B, H2
(since H2 is separable), nor H1 (since H1 ⊂ H2), i.e. no clause in a hypothesis depends
on another, so we can reason about entailment using single clauses. Since H1 is totally
incomplete, it holds that ∀e ∈ E+, ¬∃C ∈ H1, {C} ∪ B |= e. Since H2 is complete, it holds
that ∀e ∈ E+, ∃C ∈ H2, {C} ∪ B |= e. Therefore, it is clear that ∀e ∈ E+, ∃C ∈ H2, C 6∈
H1, {C} ∪ B |= e, which implies ∀e ∈ E+, H2 \ H1 ∪ B |= e, and thus H3 is complete.

We use this result to show that elimination constraints are sound with respect to optimal
solutions:

Proposition 5 (Elimination optimal soundness) Let (B, D, C, E+, E−) be a problem in-
put, D = (Dh, Db) be head and body declarations, H1 ∈ HD,C be a totally incomplete hy-
pothesis, H2 ∈ HD,C be a hypothesis such that H1 (cid:22) H2, and H3 ∈ HD,C be a separable
hypothesis such that H2 ⊂ H3. Then H3 is not an optimal solution.

Learning programs by learning from failures

19

Proof Assume that H3 is an optimal solution. This assumption implies that (i) H3 is
a solution, and (ii) there is no hypothesis H4 ∈ HD,C such that H4 is a solution and
size(H4) < size(H3). Let H4 = H3 \ H2. Since H1 is totally incomplete and H1 (cid:22) H2 then,
by Proposition 2, H2 is totally incomplete. By assumption, H3 is complete and since H4 =
H3 \ H2 and H2 is totally incomplete then, by Lemma 1, H4 is complete. Because H3 is
consistent, then, by the monotonicity of deﬁnite programs, H4 is consistent (i.e removing
clauses can only make a deﬁnite program more speciﬁc). Therefore, H4 is complete and
consistent and is a solution. Since H4 = H3 \ H2 and H2 ⊂ H3, then size(H4) < size(H3).
Therefore, condition (ii) cannot hold, which contradicts the assumption and completes
the proof.

This proof relies on a hypothesis H being (i) a deﬁnite program and (ii) separable. Con-
dition (i) is clear because the proof relies on the monotonicity of deﬁnite programs. To
illustrate condition (ii), we give a counter-example to show why we cannot use elimina-
tion constraints to prune non-separable hypotheses:

Example 13 (Non-elimination for non-separable hypotheses) Suppose we have the posi-
tive examples E+ and the hypothesis h:

E+ =

last([a,l,a,n],n)
last([t,u,r,i,n,g],g) ª

§

h =

last(A,B):- head(A,B),tail(A,C),empty(C).

(cid:8)

(cid:9)

Then h is totally incomplete so there is no reason for h to appear in a separable hypoth-
esis. However, h can still appear in a recursive hypothesis, where the clauses depend on
each other, such as h2:

h2 =

§

last(A,B):- head(A,B),tail(A,C),empty(C).
last(A,B):- tail(A,C),last(C,B).

ª

3.5.3 Constraints summary

To summarise, combinations of these different outcomes imply different combinations
of constraints, shown in Table 2. In the next section we introduce Popper, which uses
these constraints to learn deﬁnite programs.

Outcome

Nnone

Nsome

Pall
Psome
Pnone

n/a
Specialisation
Specialisation, Elimination

Generalisation
Specialisation, Generalisation
Specialisation, Elimination, Generalisation

Table 2: The constraints we can learn from testing a hypothesis. The Pall and Nnone out-
comes denote that we have found a solution.

20

4 Popper

Andrew Cropper, Rolf Morel

Popper implements the LFF approach and works in three separate stages: generate, test,
and constrain. Algorithm 1 sketches the Popper algorithm which combines the three
stages. To learn optimal solutions (Deﬁnition 14), Popper searches for programs of in-
creasing size. We describe the generate, test, and constrain stages in detail, how we use
ASP’s multi-shot solving [33] to maintain state between the three stages, and then prove
the soundness and completeness of Popper.

Algorithm 1 Popper

def popper(e+, e−, bk, declarations, constraints, max_vars, max_literals, max_clauses):

num_literals = 1
while num_literals ≤ max_literals:

program = generate(declarations, constraints, max_vars, num_literals, max_clauses)
if program == 'space_exhausted':

num_literals += 1
continue

outcome = test(e+, e−, bk, program)
if outcome == ('all_positive', 'none_negative')

return program

constraints += learn_constraints(program, outcome)

return {}

1
2
3
4
5
6
7
8
9
10
11
12

The generate step of Popper takes as input (i) predicate declarations, (ii) hypoth-
esis constraints, and (iii) bounds on the maximum number of variables, literals, and
clauses in a hypothesis, and returns an answer set which represents a deﬁnite program,
if one exists. The idea is to deﬁne an ASP problem where an answer set (a model) corre-
sponds to a deﬁnite program, an approach also employed by other recent ILP approaches
[12, 38, 34, 60]. In other words, we deﬁne a meta-language in ASP to represent deﬁnite
programs. Popper uses ASP constraints to ensure that a deﬁnite program is declaration
consistent and obeys hypothesis constraints, such as enforcing type restrictions or disal-
lowing mutual recursion. By later adding learned hypothesis constraints, we eliminate
answer sets, and thus reduce the hypothesis space. In other words, the more constraints
we learn, the more we reduce the hypothesis space.

Figure 2 shows the base ASP program to generate programs. The idea is to ﬁnd
an answer set with suitable head and body literals, which both have the arguments
(Clause,Pred,Arity,Vars) to denote that there is a literal in the clause Clause, with
the predicate symbol Pred, arity Arity, and variables Vars. For instance, head_literal(0,p,2,(0,1))
denotes that clause 0 has a head literal with the predicate symbol p, arity 2, and vari-
ables (0,1), which we interpret as (A,B). Likewise, body_literal(1,q,3,(0,0,2))
denotes that clause 1 has a body literal with the predicate symbol q, arity 3, and vari-
ables (0,0,2), which we interpret as (A,A,C). Head and body literals are restricted by
head_pred and body_pred declarations respectively. Table 3 shows examples of the cor-
respondence between an answer set and a deﬁnite program, which we represent as a
Prolog program.

Learning programs by learning from failures

21

% possible clauses
allowed_clause(0..N-1):- max_clauses(N).

% variables
var(0..N-1):- max_vars(N).

% clauses with a head literal
clause(Clause):- head_literal(Clause,_,_,_).

%% head literals
0 {head_literal(Clause,P,A,Vars): head_pred(P,A), vars(A,Vars)} 1:-

allowed_clause(Clause).

%% body literals
1 {body_literal(Clause,P,A,Vars): body_pred(P,A), vars(A,Vars)} N:-

clause(Clause), max_body(N).

% variable combinations
vars(1,(Var1,)):- var(Var1).
vars(2,(Var1,Var2)):- var(Var1),var(Var2).
vars(3,(Var1,Var2,Var3)):- var(Var1),var(Var2),var(Var3).

Fig. 2: Popper base ASP program. The head_literal literals are bounded from 0 to 1, i.e
for each possible clause there can be at most 1 head literal. The body_literal literals
are bounded from 1 to N , where N is the maximum number of literals allowed in a
clause, i.e. for each clause with a head literal, there has to be at least 1 but at most N
body literals.

Answer set

Prolog program

{head_literal(0,f,2,(0,1)),body_literal(0,empty,(1,))}

f(A,B):-empty(B).

{head_literal(0,f,2,(0,1)),body_literal(0,head,2,(1,0))}

f(A,B):-head(B,A).

{head_literal(0,f,2,(0,1)),body_literal(0,tail,2,(0,1)),
body_literal(0,tail,2,(0,2))}

f(A,B):-tail(A,B),tail(A,C).

{head_literal(0,connected,2,(0,1)),body_literal(0,edge,2,(0,1)),
head_literal(1,connected,2,(0,1)),body_literal(1,edge,2,(0,2)),
body_literal(1,connected,(2,1))}

connected(A,B):-edge(A,B).
connected(A,B):-edge(A,C),connected(C,B).

{head_literal(0,last,2,(0,1)),body_literal(0,tail,2,(0,2)),
body_literal(0,empty,1,(2,)),body_literal(0,head,2,(0,1)),
head_literal(1,last,2,(0,1)),body_literal(1,tail,2,(0,2)),
body_literal(1,last,2,(2,1))}

last(A,B):-tail(A,C),empty(C),head(A,B).
last(A,B):-tail(A,C),last(C,B).

Table 3: The correspondence between an answer set and a deﬁnite program represented
as a Prolog program.

4.0.1 Validity, redundancy, and efﬁciency constraints

Popper uses hypothesis constraints (in the form of ASP constraints) to eliminate an-
swer sets, i.e. to prune the hypothesis space. Popper uses constraints to prune invalid
programs. For instance, Figure 3 shows constraints speciﬁcally for recursive programs,
such as preventing recursion without a base case. Popper also uses constraints to re-
duce redundancy. For instance, Popper prunes subsumption redundant programs, such

22

Andrew Cropper, Rolf Morel

as pruning the following program because the ﬁrst clause subsumes the second:

h =

p(A):- q(A).
p(A):- q(A),r(A). ª

§

Finally, Popper uses constraints to improve efﬁciency (mostly by removing redundancy).
For instance, Popper uses constraints to use variables in order, which prunes the program
p(B):- q(B) because we could generate p(A):- q(A).

recursive:- recursive(Clause).

recursive(Clause):- head_literal(Clause,P,A,_), body_literal(Clause,P,A,_).

has_base:- clause(Clause), not recursive(Clause).

% need multiple clauses for recursion
:- recursive(_), not clause(1).

% prevent recursion without a basecase
:- recursive, not has_base.

Fig. 3: Constraints used by Popper to prune invalid recursive programs.

4.0.2 Language bias constraints

Popper supports optional hypothesis constraints to prune the hypothesis space. Figure
4 shows example language bias constraints, such as to prevent singleton variables and
to enforce Datalog restrictions (where head variables must appear in the body). Declar-
ative constraints have many beneﬁts, notably the ease to deﬁne them. For instance, to
add simple types to Popper requires the single constraint shown in Figure 4. Through
constraints, Popper also supports the standard notions of recall and input/output10 ar-
guments of mode declarations [46]. Popper also supports functional and irreﬂexive con-
straints, and constraints on recursive programs, such as disallowing left recursion or
mutual recursion. Finally, as we show in Appendix A, Popper can also use constraints to
impose metarules, clause templates used by many ILP systems [24], which ensures that
each clause in a program is an instance of a metarule.

4.0.3 Hypothesis constraints

As with many ILP systems [46, 63, 3, 38, 60], Popper supports clause constraints, which
allow a user to prune speciﬁc clauses from the hypothesis space. Popper additionally
supports the more general concept of hypothesis constraints (Deﬁnition 6), which are de-
ﬁned over a whole program (a set of clauses) rather than a single clause (also employed
in previous work [3]). For instance, hypothesis constraints allow us to prune recursive

10 An input argument speciﬁes that, at the time of calling a predicate, the corresponding argument
must be instantiated, which is useful when inducing Prolog programs where literal order matters.

Learning programs by learning from failures

23

head_var(Clause,Var):- head_literal(Clause,_,_,Vars), var_member(Var,Vars).

body_var(Clause,Var):- body_literal(Clause,_,_,Vars), var_member(Var,Vars).

% prevent singleton variables
:- clause_var(Clause,Var), #count{P,Vars: var_in_literal(Clause,P,Vars,Var)} == 1.

% head vars must appear in the body
:- head_var(Clause,Var), not body_var(Clause,Var).

%% type matching
var_type(Clause,Var,Type):-

var_in_literal(Clause,P,Vars,Var),
var_pos(Var,Vars,Pos),
type(P,Pos,Type).

:- clause_var(Clause,Var), #count{Type : var_type(Clause,Var,Type)} > 1.

Fig. 4: Optional language bias constraints used by Popper.

programs that do not contain a base case clause (Figure 3), to prune left recursive or mu-
tually recursive programs, or to prune programs which contain subsumption redundancy
between clauses.

As a toy example, suppose you want two disallow two predicate symbols p/2 and q/2
from both appearing in a program. Then this hypothesis constraint is trivial to express
with Popper:

:- body_literal(_,p,2,_), body_literal(_,q,2,_).

As we show in Appendix A, Popper can simulate metarules through hypothesis con-
straints. We are unaware of any other ILP system that supports hypothesis constraints,
at least with the same ease and ﬂexibility as Popper.

4.1 Test

In the test stage, Popper converts an answer set to a deﬁnite program and tests it against
the training examples. As Table 3 shows, this conversion is straightforward, except if
input/output argument directions are given, in which case Popper orders the body liter-
als of a clause. To evaluate a hypothesis, we use a Prolog interpreter. For each example,
Popper checks whether the example is entailed by the hypothesis and background knowl-
edge. We enforce a timeout to halt non-terminating programs. If a hypothesis fails, then
Popper identiﬁes what type of failure has occurred and what constraints to generate
(using the failures and constraints from Section 3.5).

4.2 Constrain

If a hypothesis fails, then, in the constrain stage, Popper derives ASP constraints which
prune hypotheses, thus constraining subsequent hypothesis generation. Speciﬁcally, we

24

Andrew Cropper, Rolf Morel

describe how we transform a failed hypothesis (a deﬁnite program) to a hypothesis con-
straint (an ASP constraint written in the encoding from Section 4). We describe the
generalisation, specialisation, and elimination constraints that Popper uses, based on
the deﬁnitions in Section 3.5. As our experiments consider a version of Popper without
constraint pruning, we also describe the banish constraint, which prunes one speciﬁc hy-
pothesis. To distinguish between Prolog and ASP code, we represent the code of deﬁnite
programs in typewriter font and ASP code in bold typewriter font.

4.2.1 Encoding atoms

In our encoding, the atom f(A,B) is represented as either head_literal(Clause,f,2,(V0,V1))
or body_literal(Clause,f,2,(V0,V1)). The constant 2 is the predicate’s arity and the
variable Clause indicates that the clause index is undetermined. Two functions encode
atoms into ASP literals. The function encodeHead encodes a head atom and encodeBody
encodes a body atom. The ﬁrst argument speciﬁes the clause the atom belongs to. The
second argument is the atom. Variables of the atom are converted to variables in our ASP
encoding by the encodeVar function.

encodeHead(C l ause, Pred(Var0, . . . , Vark)) :=

head_literal(C l ause,Pred,k + 1,(encodeVar(Var0), . . . ,encodeVar(Vark)))

encodeBody(C l ause, Pred(Var0, . . . , Vark)) :=

body_literal(C l ause,Pred,k + 1,(encodeVar(Var0), . . . ,encodeVar(Vark)))

For instance, using the term Cl as a clause variable, calling encodeHead(Cl, f(A,B)) re-
turns the ASP literal head_literal(Cl,f,2,(V0,V1)). Similarly, calling encodeBody(Cl, f(A,B))
returns body_literal(Cl,f,2,(V0,V1)).

4.2.2 Encoding clauses

We encode clauses by building on the encoding of atoms. Let Cl be a clause index vari-
able. Consider the clause last(A,B):- reverse(A,C),head(C,B). The following ASP
literals encode where these atoms occur in a single clause:

head_literal(Cl,last,2,(V0,V1))
body_literal(Cl,reverse,2,(V0,V2))
body_literal(Cl,head,2,(V2,V1))

An ASP solver will instantiate the variables V0, V1, and V2 with indices representing vari-
ables of hypotheses, e.g. 0 for A, 1 for B, etc. Note that the above encoding allows for
V0 = V1 = V2 = 0, where all the variables are A. To ensure that variables are distinct we
need to impose the inequality V0!=V1 and V0!=V2 and V1!=V2. The function assertDistinct
generates such inequalities, one between each pair of variables it is given. The function
encodeClause implements both the straightforward translation and the variable distinct-
ness assertion:

encodeClause(C l ause, (head:-body1, . . . , bodym)) :=

encodeHead(C l ause, head),encodeBody(C l ause, body1), . . . ,
encodeBody(C l ause, bodym),
assertDistinct(vars(head) ∪ vars(body1) ∪ . . . ∪ vars(bodym))

Learning programs by learning from failures

25

As clauses can occur in multiple hypotheses, it is convenient to refer to clauses by iden-
tiﬁers. The function clauseIdent maps clauses to unique ASP constants11. We use the ASP
literal included_clause(cl,id) to represent that a clause with index cl includes all lit-
erals of a clause identiﬁed by id. The inclusionRule function generates an inclusion rule,
an ASP rule whose head is true when the literals of the provided clause occur together
in a clause:

inclusionRule(head:-body1, . . . , bodym) :=

included_clause(Cl,cl auseI d ent(head:-body1, . . . , bodym)):-

encodeClause(Cl, (head:-body1, . . . , bodym)).

Suppose that clauseIdent(last(A,B):- reverse(A,C),head(C,B)) = id1. Then the rule
obtained by inclusionRule(last(A,B):- reverse(A,C),head(C,B)) is:

included_clause(Cl,id1 ):-

head_literal(Cl,last,2,(V0,V1)),
body_literal(Cl,reverse,2,(V0,V2)),
body_literal(Cl,head,2,(V2,V1)),
V0!=V1,V0!=V2,V1!=V2.

Note that included_clause(cl,id) being true does not mean that other literals do not
occur in the clause. For example, if a clause with index 0 encoded the clause last(A,B):-
reverse(A,C),head(C,B),tail(C,A), then included_clause(0,id1 ) would also hold.
In our encoding, clause_size(cl,m) is only true when clause cl has exactly m body
literals. Hence when literals included_clause(0,id1 ) and clause_size(0,2) are both
true, the clause with index 0 exactly encodes last(A,B):- reverse(A,C),head(C,B).
The function exactClause derives a pair of ASP literals checking that a clause occurs
exactly:

exactClause(C l ause, (head:-body1, . . . , bodym)) :=

included_clause(C l ause,cl auseI d ent(head:-body1, . . . , bodym)),
clause_size(C l ause,m)

4.2.3 Generalisation constraints

Given a hypothesis H, by Deﬁnition 17, any hypothesis that includes all of H’s clauses ex-
actly is a generalisation of H. We use this fact to deﬁne function generalisationConstraint,
which converts a set of clauses into ASP encoded clause inclusion checking rules as well
as a generalisation constraint (Deﬁnition 19). We use exactClause to impose that a clause
is not specialised. Each clause is given its own ASP variable, meaning that the clauses
can occur in any order.

generalisationConstraint({Clause0, . . . , Clausen−1}) :=

inclusionRul e(Clause0)
. . .
inclusionRul e(Clausen−1)
:- exactClause(Cl0, Clause0), . . . ,exactClause(Cln-1, Clausen−1).

Figure 5 illustrates generalisationConstraint deriving both an inclusion rule and a gener-
alisation constraint.

11 Even though the examples use increasing numbers in the identiﬁers, clauseIdent can be any injective
function, i.e. always mapping a clause to the same unique identiﬁer.

26

Andrew Cropper, Rolf Morel

h =

last(A,B):- reverse(A,C),head(C,B).

(cid:8)

included_clause(Cl,id1):-

head_literal(Cl,last,2,(V0,V1)),
body_literal(Cl,reverse,2,(V0,V2)),
body_literal(Cl,head,2,(V2,V1)),
V0!=V1,V0!=V2,V1!=V2.

(cid:9)

:-

included_clause(Cl0,id1),
clause_size(Cl0,2).

Fig. 5: ASP encoded inclusion rule and generalisation constraint for the hypothesis h.

4.2.4 Specialisation constraints

Given a hypothesis H, by Deﬁnition 18, any hypothesis which has every clause of H
occur, where each of these clauses may be specialised, and includes no other clauses,
is a specialisation of H. The function specialisationConstraint uses this fact to derive an
ASP encoded specialisation constraint (Deﬁnition 20) alongside inclusion rules. When
included_clause(cl,id) is true, additional atoms can occur in the clause cl. The literal
not clause(n) ensures that no additional clause is added to the n distinct clauses of
the provided hypothesis.

specialisationConstraint({Clause0, . . . , Clausen−1}) :=

inclusionRul e(Clause0)
. . .
inclusionRul e(Clausen−1)
:- included_clause(Cl0 ,clauseIdent(Clause0)), . . . ,
included_clause(Cln-1 ,clauseIdent(Clausen−1)),
assertDistinct({Cl0, . . . , Cln-1}),not clause(n).

We illustrate why asserting that specialised clauses are distinct is necessary. Consider the
hypotheses h1 and h2:

h1 =

last(A,B):- head(A,B).
last(A,B):- sumlist(A,B). ª

§

h2 =

§

last(A,B):- head(A,B),sumlist(A,B).
last(A,B):- member(A,B).

ª

The ﬁrst clause of h2 specialises both clauses in h1, yet h2 is not a specialisation of h1.
According to Deﬁnition 18, each clause needs to be subsumed by a provided clause. Note
that specialisationConstraint only considers hypotheses with at most n clauses. It is not
possible for one of these clauses to be non-specialising, as each of the original n clauses
is required to be specialised by a distinct clause.

Figure 6 illustrates a specialisation constraint derived by specialisationConstraint.

4.2.5 Elimination constraints

By Proposition 5, given a totally incomplete hypothesis H, any separable hypothesis
which includes all of H’s clauses, where each clause may be specialised, cannot be an
optimal solution. We add the following code to the Popper encoding to detect separable
hypotheses:

Learning programs by learning from failures

27

h =

rev(A,B):- head(A,B).
rev(A,B):- tail(A,C),head(C,B). ª

§

included_clause(Cl,id2):-

head_literal(Cl,rev,2,(V0,V1)),
body_literal(Cl,head,2,(V0,V1)),
V0!=V1.

included_clause(Cl,id3):-

head_literal(Cl,rev,2,(V0,V1)),
body_literal(Cl,tail,2,(V0,V2)),
body_literal(Cl,head,2,(V2,V1)),
V0!=V1,V0!=V2,V1!=V2.

:-

included_clause(Cl0,id2),
included_clause(Cl1,id3),
Cl0!=Cl1,not clause(2).

Fig. 6: ASP encoded inclusion rules and specialisation constraint for the hypothesis h.

non_separable:-

head_literal(_,P,A,_),
body_literal(_,P,A,_).

separable:-

not non_separable.

The function eliminationConstraint uses this fact to derive an ASP encoded elimina-
tion constraint (Deﬁnition 22). As in specialisationConstraint, included_clause(cl,id) is
used to allow additional literals in clauses, ensuring that provided clauses are specialised.
However, eliminationConstraint does not require that every clause is a specialisation of
a provided clause. Instead, all that is required is that the hypothesis is separable.

eliminationConstraint({Clause0, . . . , Clausen−1}) :=

inclusionRul e(Clause0)
. . .
inclusionRul e(Clausen−1)
:- included_clause(Cl0 ,clauseIdent(Clause0)), . . . ,
included_clause(Cln-1 ,clauseIdent(Clausen−1)),
separable.

Figure 7 illustrates an elimination constraint derived by eliminationConstraint.

h =

last(A,B):- tail(A,C),head(C,B).

(cid:8)

(cid:9)

included_clause(Cl,id4):-

head_literal(Cl,last,2,(V0,V1)),
body_literal(Cl,tail,2,(V0,V2)),
body_literal(Cl,head,2,(V2,V1)),
V0!=V1,V0!=V2,V1!=V2.

:-

included_clause(Cl0,id4),
separable.

Fig. 7: ASP encoded inclusion rule and elimination constraint for the hypothesis h.

28

Andrew Cropper, Rolf Morel

4.2.6 Banish constraints

In the experiments we compare Popper against a version of itself without constraint prun-
ing. To do so we need to remove single hypotheses from the hypothesis space. We intro-
duce the banish constraint for this purpose. To prune a speciﬁc hypothesis, hypotheses
with different variables should not be pruned. We accomplish this condition by chang-
ing the behaviour of the encodeVar function. Normally encodeVar returns ASP variables
which are then grounded to indices that correspond to the variables of hypotheses. In-
stead, by the following deﬁnition, encodeVar directly assigns the corresponding index for
a hypothesis variable:

encodeVar = { A 7→ 0; B 7→ 1; C 7→ 2; . . . }

For a banish constraint no additional literals in clauses are allowed, nor are additional
clauses. The below function banishConstraint ensures both conditions when converting
a hypothesis to an ASP encoded banish constraint. That provided clauses occur non-
specialised is ensured by exactClause. The literal not clause(n) asserts that there are
no more clauses than the original number.

banishConstraint({Clause0, . . . , Clausen−1}) :=

inclusionRul e(Clause0)
. . .
inclusionRul e(Clausen−1)
:- exactClause(Cl0, Clause0), . . . ,exactClause(Cln-1, Clausen−1),

not clause(n).

Figure 8 illustrates a banish constraint derived by banishConstraint.

h =

f(A):- head(A,B),one(B).
f(A):- tail(A,B),empty(B). ª

§

included_clause(Cl,id5):-

head_literal(Cl,f,1,(0,)),
body_literal(Cl,head,2,(0,1)),
body_literal(Cl,one,1,(1,)).

included_clause(Cl,id6):-

head_literal(Cl,f,1,(0,)),
body_literal(Cl,tail,2,(0,1)),
body_literal(Cl,empty,1,(1,)).

:-

included_clause(Cl0,id5),
clause_size(Cl0,2),
included_clause(Cl1,id6),
clause_size(Cl1,2),
not clause(2).

Fig. 8: ASP encoded inclusion rules and banish constraint for the hypothesis h.

4.3 Popper loop and multi-shot solving

A naive implementation of Algorithm 1, such as performing iterative deepening on the
program size, would duplicate grounding and solving during the generate step. To im-
prove efﬁciency, we use Clingo’s multi-shot solving [33] to maintain state between the

Learning programs by learning from failures

29

three stages. The idea of multi-shot solving is that state of the solving process for an ASP
program can be saved to help solve modiﬁcations of that program. The essence of the
multi-shot cycle is that a ground program is given to an ASP solver, yielding an answer
set, who’s processing leads to a (ﬁrst-order) extension of the program. Only this exten-
sion then needs grounding and adding to the running ASP instance, which means that
the running solver may, for example, maintain learned conﬂicts.

Popper uses multi-shot solving as follows. The initial ASP program is the encoding
described in Section 4. Popper asks Clingo to ground the initial program and prepare
for its solving. In the generate stage, the solver is asked to return an answer set, i.e. a
model, of the current program. Popper converts such an answer set to a deﬁnite program
and tests it against the examples. If a hypothesis fails, Popper generates ASP constraints
using the functions in Section 4.2 and adds them to the running Clingo instance, which
grounds the constraints and adds the new (propositional) rules to the running solver. We
employ a hard constraint on the program size that reasons about an external atom [33]
size(N). Initially, programs need to consist of just one literal. When there are no more
answer sets, we increment the program size. Every time we increment the program size,
e.g. from N to N +1, we add a new atom size(N+1) and a new constraint enforcing this
program size. Only the new constraint is ground at this point. We disable the previous
constraint by setting the external atom size(N) to false. The solver knows which parts
of the search space (i.e. hypothesis space) have already been considered and will not
revisit them. This loop repeats until either (i) Popper ﬁnds an optimal solution, or (ii)
there are no more hypotheses to test.

4.4 Worked example

To illustrate Popper, reconsider the example from the introduction of learning a last/2
hypothesis to ﬁnd the last element of a list. For simplicity, assume an initial hypothesis
space H1:

H1 =

h1 =
h2 =
h3 =
h4 =
h5 =

h6 =

h7 =

h8 =

(cid:8)
(cid:8)
(cid:8)
(cid:8)
(cid:8)
§

§

§

h9 = 









(cid:9)

(cid:9)

(cid:9)

last(A,B):- head(A,B).
last(A,B):- head(A,B),empty(A).
(cid:9)
last(A,B):- tail(A,C),head(C,B).
last(A,B):- reverse(A,C),head(C,B).
last(A,B):- head(A,B),reverse(A,C),head(C,B).
last(A,B):- tail(A,C),head(C,B).
last(A,B):- reverse(A,C),head(C,B). ª
last(A,B):- tail(A,C),head(C,B).
last(A,B):- tail(A,C),tail(C,D),head(D,B). ª
last(A,B):- reverse(A,C),tail(C,D),head(D,B).
last(A,B):- tail(A,C),reverse(C,D),head(D,B). ª
last(A,B):- head(A,B).
last(A,B):- reverse(A,C),tail(C,D),head(D,B).
last(A,B):- tail(A,C),reverse(C,D),head(D,B).

(cid:9)











Also assume we have the positive (E+) and negative (E−) examples:

E+ =

last([l,a,u,r,a],a).
last([p,e,n,e,l,o,p,e],e). ª

§

E− =

last([e,m,m,a],m).
last([j,a,m,e,s],e). ª

§

30

Andrew Cropper, Rolf Morel

To start, Popper generates the simplest hypothesis:

last(A,B):- head(A,B).

h1 =

(cid:8)

(cid:9)

Popper then tests h1 against the examples and ﬁnds that it fails because it does not entail
any positive example and is therefore too speciﬁc. Popper then generates a specialisation
constraint to prune specialisations of h1:

included_clause(Cl,id1):-

head_literal(Cl,last,2,(V0,V1)),
body_literal(Cl,head,2,(V0,V1)),
V0!=V1.

:-

included_clause(Cl0,id1),
not clause(1).

Popper adds this constraint to the meta-level ASP program which prunes h2 and h5 from
the hypothesis space. In addition, because h1 does not entail any positive example (is
totally incomplete), Popper also generates an elimination constraint:

:-

included_clause(Cl0,id1),
separable.

Popper adds this constraint to the meta-level ASP program which prunes h9 from the
hypothesis space. The hypothesis space is now:

h3 =
h4 =

h6 =

h7 =

h8 =

(cid:9)

last(A,B):- tail(A,C),head(C,B).
last(A,B):- reverse(A,C),head(C,B).
(cid:9)
last(A,B):- tail(A,C),head(C,B).
last(A,B):- reverse(A,C),head(C,B). ª
last(A,B):- tail(A,C),head(C,B).
last(A,B):- tail(A,C),tail(C,D),head(D,B). ª
last(A,B):- reverse(A,C),tail(C,D),head(D,B).
last(A,B):- tail(A,C),reverse(C,D),head(D,B). ª

(cid:8)
(cid:8)
§

§

§






H2 =






Popper generates another hypothesis (h3) and tests against the examples and ﬁnds that
it fails because it entails the negative example last([e,m,m,a],m) and is therefore too
general. Popper then generates a generalisation constraint to prune generalisations of
h3:

included_clause(Cl,id2):-

head_literal(Cl,last,2,(V0,V1)),
body_literal(Cl,tail,2,(V0,V2)),
body_literal(Cl,head,2,(V2,V1)),
V0!=V1,V0!=V2,V1!=V2.

:-

included_clause(Cl0,id2),
clause_size(Cl0,2).

Learning programs by learning from failures

31

Popper adds this constraint to the meta-level ASP program which prunes h6 and h7 from
the hypothesis space. The hypothesis space is now:

H3 = 


h4 =

h8 =

last(A,B):- reverse(A,C),head(C,B).
last(A,B):- reverse(A,C),tail(C,D),head(D,B).
last(A,B):- tail(A,C),reverse(C,D),head(D,B). ª

(cid:9)

(cid:8)
§








Finally, Popper generates another hypothesis (h4), tests it against the examples, ﬁnds
that it does not fail, and returns it.

4.5 Correctness

We now show the correctness of Popper. However, we can only show this result for when
the hypothesis space only contains decidable programs, e.g. Datalog programs. When
the hypothesis space contains arbitrary deﬁnite programs, then the results do not hold
because checking for entailment of an arbitrary deﬁnite program is only semi-decidable
[65]. In other words, the results in this section only hold when every hypothesis in the
hypothesis space is guaranteed to terminate12.

We ﬁrst show that Popper’s base encoding (Figure 2) can generate every declaration

consistent hypothesis (Deﬁnition 4):

Proposition 6 The base encoding of Popper has a model for every declaration consistent
hypothesis.

Proof Let D = (Dh, Db) be a declaration bias, Nvar be the maximum number of unique
variables, Nbod y be the maximum number of body literals, Ncl ause be the maximum num-
ber of clauses, H be any hypothesis declaration consistent with D and these parameters,
and C be any clause in H. Our encoding represents the head literal ph(H1, . . . , Hn) of
C as a choice literal head_literal(i,ph ,n,(H1,. . . ,Hn)) guarded by the condition
head_pred(ph ,n) ∈ Dh, which clearly holds. Our encoding represents a body literal
pb(B1, . . . , Bm) of C as a choice literal body_literal(i,pb ,m,(B1,. . .,Bm)) guarded
by the condition body_pred(pb ,m) ∈ Db, which clearly holds. The base encoding only
constrains the above guesses by three conditions: (i) at most Nvar unique variables per
clause, (ii) at least 1 and at most Nbod y body literals per clause, and (iii) at most Ncl ause
clauses. As both the hypothesis and the guessed literals satisfy the same conditions, we
conclude there exists a model representing H.

We show that any hypothesis returned by Popper is a solution (Deﬁnition 11):

Proposition 7 (Soundness) Any hypothesis returned by Popper is a solution.

Proof Any returned hypothesis has been tested against the training examples and con-
ﬁrmed as a solution.

To make the next two results shorter, we introduce a lemma to show that Popper never
prunes optimal solutions (Deﬁnition 14):

12 In practice, such as in our experiments on learning list transformation programs, we enforce a time-
out when testing programs, i.e. we assume that every solution terminates before the timeout.

32

Andrew Cropper, Rolf Morel

Lemma 2 Popper never prunes optimal solutions.

Proof Popper only learns constraints from a failed hypothesis, i.e. a hypothesis that is
incomplete or inconsistent. Let H be a failed hypothesis. If H is incomplete, then, as
described in Section 4.2, Popper prunes specialisations of H. Proposition 4 shows that
a specialisation constraint never prunes complete hypotheses, and thus never prunes
optimal solutions. If H is inconsistent, then, as described in Section 4.2, Popper prunes
generalisations of H. Proposition 3 shows that a generalisation constraint never prunes
consistent hypotheses, and thus never prunes optimal solutions. Finally, if H is totally
incomplete, then, as described in Section 4.2, Popper uses an elimination constraint to
prune all separable hypotheses that contain H. Proposition 5 shows that an elimination
constraint never prunes optimal solutions. Since Popper only uses these three constraints,
it never prunes optimal solutions.

We now show that Popper returns a solution if one exists:

Proposition 8 (Completeness) Popper returns a solution if one exists.

Proof Assume, for contradiction, that Popper does not return a solution, which implies
that (1) Popper returned a hypothesis that is not a solution, or (2) Popper did not return
a solution. Case (1) cannot hold because Proposition 7 shows that every hypothesis re-
turned by Popper is a solution. For case (2), by Proposition 6, Popper can generate every
hypothesis so it must be the case that (i) Popper did not terminate, (ii) a solution did not
pass the test stage, or (iii) that every solution was incorrectly pruned. Case (i) cannot
hold because Proposition 1 shows that the hypothesis space is ﬁnite so there are ﬁnitely
many hypotheses to generate and test. Case (ii) cannot hold because a solution is by
deﬁnition a hypothesis that passes the test stage. Case (iii) cannot hold because Lemma
2 shows that Popper never prunes optimal solutions. These cases are exhaustive, so the
assumption cannot hold, and thus Popper returns a solution if one exists.

We show that Popper returns an optimal solution if one exists:

Theorem 1 (Optimality) Popper returns an optimal solution if one exists.

Proof By Proposition 8, Popper returns a solution if one exists. Let H be the solution
returned by Popper. Assume, for contradiction, that H is not an optimal solution. By
Deﬁnition 14, this assumption implies that either (1) H is not a solution, or (2) H is a
non-optimal solution. Case (1) cannot hold because H is a solution. Therefore, case (2)
must hold, i.e. there must be at least one smaller solution than H. Let H ′ be an optimal
solution, for which we know size(H ′) < size(H). By Proposition 6, Popper generates
every hypothesis, and Popper generates hypotheses of increasing size (Algorithm 1),
therefore the smaller solution H ′ must have been considered before H, which implies that
H ′ must have been pruned by a constraint. However, Lemma 2 shows that H ′ could not
have been pruned and so cannot exist, which contradicts the assumption and completes
the proof.

5 Experiments

We now evaluate Popper. Popper learns constraints from failed hypotheses to prune the
hypothesis space to improve learning performance. We therefore claim that, compared to

Learning programs by learning from failures

33

unconstrained learning, constraints can improve learning performance. One may think
that this improvement is obvious, i.e. constraints will deﬁnitely improve performance.
However, it is unclear whether in practice, and if so by how much, constraints will im-
prove learning performance because Popper needs to (i) analyse failed hypotheses, (ii)
generate constraints from them, and (iii) pass the constraints to the ASP system, which
then needs to ground and solve them, which may all have non-trivial computational
overheads. Our experiments therefore aim to answer the question:

Q1 Can constraints improve learning performance compared to unconstrained learning?

To answer this question, we compare Popper with and without the constrain stage. In
other words, we compare Popper against a brute-force generate and test approach. To do
so, we use a version of Popper with only banish constraints enabled to prevent repeated
generation of a failed hypothesis. We call this system Enumerate.

Proposition 1 shows that the size of the learning from failures hypothesis space is a
function of many parameters, including the number of predicate declarations, the num-
ber of unique variables in a clause, and the number of clauses in a hypothesis. To explore
this result, our experiments aim to answer the question:

Q2 How well does Popper scale?

To answer this question, we evaluate Popper when varying (i) the size of the optimal
solution, (ii) the number of predicate declarations, (iii) the number of constants in the
problem, (iv) the number of unique variables in a clause, (v) the maximum number of
literals in a clause, and (vi) the maximum number of clauses allowed in a hypothesis.

We also compare Popper against existing ILP systems. Our experiments therefore aim

to answer the question:

Q3 How well does Popper perform compared to other ILP systems?

To answer this question, we compare Popper against Aleph [63], Metagol, ILASP2i [39],
and ILASP3 [37]. It is, however, important to note that a direct comparison of ILP sys-
tems is difﬁcult because different systems excel at different problems and often employ
different biases. For instance, directly comparing the Prolog-based Metagol against the
ASP-based ILASP is difﬁcult because Metagol is often used to learn recursive list manip-
ulation programs, such as string transformations and sorting algorithms, whereas ILASP
does not support explicit lists because the ASP system Clingo [32], on which ILASP is
built, disallows explicit lists. Likewise, Aleph and ILASP3 support noise, whereas Metagol
and Popper do not. Moreover, because ILP systems have many learning parameters, it
is often possible to show that there exist some parameter settings for which system X
can perform better than system Y on a particular problem. Overall, a direct comparison
between ILP systems is difﬁcult, so a reader should not interpret the results as system X
is better than system Y.

5.1 Buttons

The purpose of this ﬁrst experiment is to evaluate how well Popper scales when vary-
ing the optimal solution size13. We therefore need a problem where we can control the

13 Note that, in this experiment, increasing the optimal solution size almost always also increases the
size of the hypothesis space for the considered ILP systems.

34

Andrew Cropper, Rolf Morel

optimal solution size. We consider a problem loosely based on the IGGP game buttons
and lights [19]. The problem is purposely simple: given p buttons, learn which n buttons
need to be pressed to win. For instance, for n = 3, a solution could be:

win(A):- button6(A),button4(A),button7(A)

The variable A denotes the player and buttonp denotes that player A pressed buttonp.

In this experiment, we ﬁx p, the number of buttons, and vary n, the number of buttons

that need to be pressed, which directly corresponds to the optimal solution size.

5.1.1 Materials

We consider two variations of the problem where p = 20 and p = 200, which we name
small and big respectively. We compare Popper, Enumerate, Metagol, ILASP2i, ILASP3,
and Aleph. To compare the systems, we try to use settings so that each system searches
approximately the same hypothesis space. However, ensuring that the systems search
identical hypothesis spaces is near impossible. For instance, Metagol performs automatic
predicate invention and so considers a different hypothesis space to the other systems.
The exact language biases used are in Appendix B.

ILASP settings. We asked Mark Law, the ILASP author, for advice on how best to solve
this problem with ILASP2i and ILASP314. We run both ILASP2i and ILASP3 with the same
settings so we simply refer to both as ILASP. We run ILASP with the ‘no constraints’, ‘no
aggregates’, ‘disable implication’, ‘disable propagation’, and ‘simple contexts’ ﬂags. We
tell ILASP that each BK relation is positive, which prevents it from generating body liter-
als using negation. We also make the problem propositional and use context-dependent
examples [39] where the context-dependent BK for each example contains the buttons
pressed in that example. We initially tried to run ILASP with at most ten body literals
(‘-ml=10’ and ‘–max-rule-length=11’) but when given this parameter ILASP would not
terminate in the time limit because it pre-computes every rule in the hypothesis space.
Therefore, for each number of buttons n, we set the maximum number of body literals
to n (‘-ml=n’ and ‘–max-rule-length=n+1’), to ensure that ILASP terminates on some of
the problems.

Metagol settings. Metagol needs metarules (Section 2.5) to guide the proof search. We
provide Metagol with the following two metarules:

P(A):- Q(A).
P(A):- Q(A),R(A).

Popper and Enumerate settings. We set Popper and Enumerate to use at most 1 unique
variable, at most 1 clause, and at most n body literals. These settings match those im-
posed by Metagol’s metarules and somewhat ILASP’s propositional representation. We
restrict the clause to have at most n body literals to match ILASP’s settings. When allowed
up to ten body literals, Popper performs almost identically.

14 Mark suggested an alternative representation that corresponds to learning the negation of the con-
cept, which would have been much more suitable for ILASP. However, this alternative different represen-
tation requires NAF which not all of the other systems support.

Learning programs by learning from failures

35

Aleph settings. We also set the maximum number of nodes to be search to be 5000. As
with Popper, Enumerate, and ILASP, we increase the maximum clause length for Aleph
for each value n.

5.1.2 Methods

For each n in {1, 2, . . . , 10}, we generate 200 positive and 200 negative examples. A pos-
itive example is a player that has pressed the correct n buttons. To generate a positive
example we sample without replacement n integers from the set {1, . . . , p} which corre-
spond to the n buttons that must be pressed. We additionally sample extra buttons that
are also pressed, but which are not necessarily pressed in all the positive examples. A
negative example is a player that has not pressed the correct n buttons. To generate a
negative example we sample without replacement at most n−1 buttons from the set that
must be pressed. We then sample other buttons that should not be pressed. By including
all n negative examples with n − 1 correct buttons we guarantee that there is only one
correct solution. We measure learning time as the time to learn a solution. We enforce
a timeout of one minute per task. We repeat each experiment ten times and plot the
standard error.

5.1.3 Results

Figure 9 shows that Popper clearly outperforms Enumerate on both datasets. On the
small dataset (p = 20), Enumerate only learns a program for when three buttons must
be pressed (n = 3). On the large dataset (p = 200), Enumerate only learns a program for
when one button must be pressed (n = 1). By contrast, on both datasets, Popper learns
a program for when ten buttons must be pressed (n = 10), i.e. a program with ten body
literals. Moreover, Popper always learns a solution comfortably within the time limit.
This result strongly suggests that the answer to Q1 is yes, constraints can drastically
improve learning performance.

60

40

20

)
s
d
n
o
c
e
s
(

e
m

i
t

i

g
n
n
r
a
e
L

Popper
Enumerate
Metagol
ILASP2i
ILASP3
Aleph

60

40

20

)
s
d
n
o
c
e
s
(

e
m

i
t

i

g
n
n
r
a
e
L

0

1

2

3

4

5

6

7

8

9

10

0

1

2

3

4

5

6

7

8

9

10

Number of pressed buttons (n)

Small BK (p=20)

Number of pressed buttons (n)

Big BK (p=200)

Fig. 9: Buttons experiment.

Popper outperforms Metagol on both datasets. For the small dataset, the largest pro-
gram that Metagol learns is for when n = 4, which takes 50 seconds to learn, compared

36

Andrew Cropper, Rolf Morel

to one second for Popper. For the big dataset, the largest program that Metagol learns is
for when n = 3, which takes 57 seconds to learn, compared to eight seconds for Popper.
Metagol struggles because of its inefﬁcient search. Metagol performs iterative deepen-
ing over the number of clauses allowed in a solution [49]. However, if a clause or literal
fails during the search, Metagol does not remember this failure, and will retry already
failed clauses and literals at each depth (and even multiple times as the same depth). By
contrast, if a clause fails, Popper learns constraints from the failure so it never tries that
clause (or its specialisations) again.

Popper outperforms ILASP2i and ILASP3 on both datasets. ILASP2i only learns pro-
grams with four (small dataset) and one (big dataset) body literals. ILASP3 only learns
programs with four (small dataset) and one (big dataset) body literals. ILASP2i and
ILASP3 both struggle on this problem because they pre-compute every clause in the hy-
pothesis space, which means that they struggle to learn clauses with many body literals.
By contrast, Popper can learn programs with ten body literals on both datasets.

Aleph outperforms Popper on the small dataset when n > 8. However, on the big

dataset, Popper outperforms Aleph when n > 3.

Overall, the results from this experiment suggest that (i) the answer to question Q1
is certainly yes, constraints improve learning performance, (ii) the answer to Q2 is that
Popper scales well in terms of the number of body literals in a solution and the number of
background relations, and (iii) the answer to Q3 is that Popper can outperform other ILP
systems when varying the optimal solution size and the number of background relations.

5.2 Robots

The purpose of this second experiment is to evaluate how well Popper scales with respect
to the domain size (i.e. the constant signature). We therefore need a problem where we
can control the domain size. We consider a robot strategy learning problem [21]. There
is a robot in a n × n grid world. Given an arbitrary start position, the goal is to learn
a general strategy to move the robot to the topmost row in the grid. For instance, for
a 10 × 10 world and the start position (2, 2), the goal is to move to position (2, 10).
The domain contains all possible robot positions. We therefore vary the domain size by
varying n, the size of the world. The optimal solution is a recursive strategy for keep
moving upwards until you are at the top row. To reiterate, we purposely ﬁx the optimal
solution so that the only variable in the experiment is the domain size (i.e. the grid world
size), which we progressively increase to evaluate how well the systems scale.

5.2.1 Materials

We consider two representations: a representation for Popper, Enumerate, Metagol, and
Aleph, and then a representation designed to help ILASP solve the problem. When given
the Prolog representation, neither ILASP2i nor ILASP3 could solve any of the prob-
lems because of the grounding problem. In both representations, we provide as BK four
dyadic relations, move_right, move_left, move_up, and move_down, that change the state,
e.g. move_right((2,2),(3,2)), and four monadic relations, at_top, at_bottom, at_left, and
at_right, that check the state. The exact language biases used can be found in Appendix
C.

Learning programs by learning from failures

37

Prolog representation. In the Prolog representation, an example is an atom of the form
f (s1, s2), where s1 and s2 represent start and end states. A state is a pair of discrete
coordinates (x, y) denoting the column (x) and row ( y) position of the robot.

ILASP representation. When given the Prolog representation, neither ILASP2i nor ILASP3
could solve any of the problems in this experiment because of the grounding problem.
We therefore asked Mark Law to help us design a more suitable representation. In this
representation, an example is an atom of the form f (s2) where s2 represents the end
state. Each example is a distinct ILASP example (a partial interpretation) with its own
context, where the start state is given in the context as start_state(s1). This representation
alleviates the grounding problem of the Prolog representation.

ILASP2i and ILASP3 settings. We run both ILASP2i and ILASP3 with the same settings, so
we again refer to both as ILASP. We run ILASP with the ‘no constraints’, ‘no aggregates’,
’disable implication’, ’disable propagation’, and ’simple contexts’ ﬂags. We tell ILASP that
each BK relation is positive, anti_reﬂexive, and symmetric. We also employ a set of ‘bias
constraints’ to reduce the hypothesis space. We also restrict some of the recall values for
the BK relations. We set ILASP to use at most four unique variables and at most three
body literals (‘-ml=3’ and ‘–max-rule-length=4’). The full language bias restrictions can
be found in the appendix C.

Metagol settings. We provide Metagol with the metarules in Figure 10. These metarules
constitute an almost15 complete set of metarules for a singleton-free fragment of monadic
and dyadic Datalog [24].

P(A):-Q(A).
P(A):-Q(A),R(A).
P(A):-Q(A,B),R(B).
P(A):-Q(A,B),P(B).
P(A):-Q(A,B),R(A,B).

P(A,B):-Q(B,A).
P(A,B):-Q(A,B),R(A,B).
P(A,B):-Q(A),R(A,B).
P(A,B):-Q(A,B),R(B).
P(A,B):-Q(A,C),R(C,B).
P(A,B):-Q(A,C),P(C,B).

Fig. 10: The metarules used by Metagol in the robot and list transformation experiments.

Popper settings. We allow Popper and Enumerate to use at most four unique variables
per clause and at most three body literals (which match the ILASP settings), and at most
three clauses.

Aleph settings. We set the maximum variable depth and clause length to six and set the
maximum number of search nodes to 30000.

15 It is impossible to generate a ﬁnite and complete set of metarules for a singleton-free fragment of
monadic and dyadic Datalog [24].

38

5.2.2 Methods

Andrew Cropper, Rolf Morel

We run the experiment with an n × n grid world for each n in {10, 20, . . . , 100}. To
generate examples, for start states, we uniformly sample positions that are not at the top
of the world. For the positive examples, the end state is the topmost position, e.g. (x, n)
where n is the grid size. For negative examples, we randomly sample start and end states
and reject the example if it is a positive example. To ensure that there are some negative
examples with the topmost position, in 25% of the examples we set the end position to
be the topmost row of column y, but ensure that the start position is not y. We sample
with replacement 20 positive and 20 negative training examples, and 1000 positive and
1000 negative testing examples. The default predictive accuracy is therefore 50%. We
measure predictive accuracies and learning times. We enforce a timeout of one minute
per task. If a system fails to learn a solution in the given time then it only achieves default
predictive accuracy (50%). We repeat each experiment ten times and plot the standard
error.

5.2.3 Results

Figure 11 shows the results. Popper achieves the best predictive accuracy out of all the
systems. Enumerate is the second best performing system, although it is does not always
learn the optimal solution. Popper is substantially quicker than Enumerate (on average
about 40 times quicker) and is the fastest of all the systems. The learning time of Popper
slightly decreases as the grid size grows. The reason for this is twofold. First, when the
grid world is small, there are often many small programs that cover some of the positive
examples but none of the negative examples, such as:

f(S1,S2):- move_up(S1,S3),move_up(S3,S2).

Because they cover some of the examples, Popper cannot completely rule them out. How-
ever, as the grid size grows, these smaller programs are less likely to cover the examples
because the examples are more spread out over the grid. Second, solutions have either
ﬁve or six literals, with smaller solutions becoming more likely with increasing world
size. These reasons explain why the predictive accuracy of Enumerate improves as the
grid size grows. The reason that the learning time of Popper does not increase is that the
domain size has no inﬂuence on the size of the learning from failures hypothesis space
(Proposition 1). The only inﬂuence the grid size has is any overhead in executing the
induced Prolog program on larger grids. This result suggests that Popper can scale well
with respect to the domain size.

Popper outperforms Metagol in all cases. For a small 10x10 grid world, Metagol
learns the optimal solution and does so quicker than Popper (Metagol takes 1 second
compared to Popper which takes 9 seconds). However, as the grid size grows, Metagol’s
performance quickly degrades. For a grid size greater than 20, Metagol almost always
times out before ﬁnding a solution. The reason is that Metagol searches for a hypothesis
by inducing and executing partial programs over the examples. In other words, Metagol
uses the examples to guide the hypothesis search. As the grid size grows, there are more
partial programs to construct, so its performance suffers. Note that when Metagol learns
a solution, it is always an accurate solution.

Popper outperforms ILASP2i and ILASP3 both in terms of predictive accuracies and
learning times. ILASP3 cannot learn any solutions in the given time, even for the 10x10

Learning programs by learning from failures

39

100

)

%

(

y
c
a
r
u
c
c
a

e
v
i
t
c
i
d
e
r
P

90

80

70

60

50

Popper
Enumerate
Metagol
ILASP2i
ILASP3
Aleph

60

40

20

)
s
d
n
o
c
e
s
(

e
m

i
t

i

g
n
n
r
a
e
L

10

20

30

40

50

60

70

80

90

100

0
10

20

30

40

50

60

70

80

90

100

Robot world size

(a) Predictive accuracies

Robot world size

(b) Learning times

Fig. 11: Robots experimental results when varying the world size, which corresponds to
the domain size.

world. ILASP2i initially learns solutions in the given time limit, but struggles as the grid
size grows. Note that when ILASP2i learns a solution, it is always an accurate solution.
ILASP2i outperforms ILASP3 because once ILASP2i ﬁnds a solution it terminates. By
contrast, ILASP3 ﬁnds one hypothesis schema that guarantees coverage of the example
(which, in this special case, also implies ﬁnding a solution), then carries on to ﬁnd al-
ternative hypothesis schemas. The extra work done by ILASP3 is needed when learning
general ASP programs, but in this special case (where there no ILASP negative examples)
it is unnecessary and computationally expensive. We refer the reader to Law’s thesis [37]
for a detailed comparison of ILASP2i and ILASP316.

Popper outperforms Aleph. For small grid worlds, Aleph sometimes learns programs
that generalise to the training set (such as move up three times). But as the grid size
grows, Aleph struggles because it struggles to learn recursive programs.

Overall, the results from this experiment suggest that (i) the answer to question Q1
is certainly yes, constraints improve learning performance, (ii) the answer to Q2 is that
Popper scales well in terms of the domain size, and (iii) the answer to Q3 is that Popper
can outperform other ILP systems when varying the domain size.

5.3 List transformation problem

The purpose of this third experiment is to evaluate how well Popper performs on difﬁcult
(mostly recursive) list transformation problems. Learning recursive programs has long
been considered a difﬁcult problem in ILP [47] and most ILP and program synthesis
systems cannot learn recursive programs. Because ILASP2i and ILASP3 do not support
lists, we only compare Popper, Enumerate, Metagol, and Aleph.

5.3.1 Materials

We evaluate the systems on the ten list transformation tasks shown in Table 4. These tasks
include a mix of monadic (e.g. evens and sorted), dyadic (e.g. droplast and finddup),

16 We thank Mark Law for this explanation.

40

Andrew Cropper, Rolf Morel

and triadic (dropk) target predicates. The tasks also contain a mix of functional (e.g. last
and len) and relational problems (e.g. finddup and member). These tasks are extremely
difﬁcult for ILP systems. To learn solutions that generalise, an ILP system needs to support
recursion and large domains. As far as we are aware, no existing ILP system can learn
optimal solutions for all of these tasks without being provided with a strong inductive
bias17.

We give each system the following dyadic relations head, tail, decrement, geq and
the monadic relations empty, zero, one, even, and odd. We also include the dyadic rela-
tion increment in the len experiment. We had to remove this relation from the BK for
the other experiments because when given this relation Metagol runs into inﬁnite re-
cursion18 on almost every problem and could not ﬁnd any solutions. We also include
member/2 in the ﬁnd duplicate problem. We also include cons/3 in the addhead, dropk,
and droplast experiments. We exclude this relation from the other experiments because
Metagol does not easily support triadic relations. The exact language biases used can be
found in Appendix D.

Metagol settings. For Metagol, we use almost the same metarules as in the previous robot
experiment (Figure 10). However, when given the inverse metarule P(A, B) ← Q(B, A),
Metagol could not learn any solution, again because of inﬁnite recursion. To aid Metagol,
we therefore replace the inverse metarule with the identity metarule, i.e. P(A, B) ←
Q(A, B). In addition, when we ﬁrst ran the experiment with randomly ordered examples,
we found that Metagol struggled to ﬁnd solutions for all the problems (except member).
The reason is that Metagol is sensitive to the order of examples because it uses the ex-
amples in the order they are given to induce a hypothesis. Therefore, to aid Metagol, we
provide the examples in increasing size (i.e. the length of the input lists).

Popper and Enumerate settings. We set Popper and Enumerate to use at most ﬁve unique
variables, at most ﬁve body literals, and at most two clauses. In Section 5.5, we evaluate
how sensitive Popper is to these parameters. For each BK relation, we also provide both
systems with simple types and argument directions (whether input or output). Because
Popper and Enumerate can generate non-terminating Prolog programs, we set both sys-
tems to use a testing timeout of 0.1 seconds per example. If a program times out, we
view it as a failure.

Aleph settings. We give Aleph identical mode declarations and determinations to Popper
and Enumerate. We set the maximum variable depth and clause length to six and set the
maximum number of search nodes to 30000.

5.3.2 Methods

For each problem, we generate 10 positive and 10 negative training examples, and 1000
positive and 1000 negative testing examples. The default predictive accuracy is therefore

17 As mentioned in Section 2.3, some inverse entailment methods [46] might sometimes learn solutions
for them. However, these approaches need an example to learn the base case of a recursive program and
then an example to learn the inductive case. Moreover, these approaches would not be guaranteed to
learn the optimal solution. Metagol could possibly learn solutions for them if given the exact metarules
needed, but that requires that you know the solution before you try to learn it.
18 Because Metagol induces hypotheses by partially constructing and evaluating hypotheses, it is very
difﬁcult to impose a timeout on a particular hypothesis, which we can easily do with Popper.

Learning programs by learning from failures

41

Name

Description

Example solution

addhead

Prepend the head three times

addhead(A,B):−head(A,C),cons(C,A,D),cons(C,D,E),cons(C,E,B).

dropk

Drop the ﬁrst k elements

droplast

Drop the last element

dropk(A,B,C):−one(B),tail(A,C).
dropk(A,B,C):−tail(A,D),decrement(B,E),dropk(D,E,C).

droplast(A,B):−tail(A,B),empty(B).
droplast(A,B):−tail(A,C),droplast(C,D),head(A,E),cons(E,D,B).

evens

Check all elements are even

finddup

Find duplicate elements

evens(A):−empty(A).
evens(A):−head(A,B),even(B),tail(A,C),evens(C).

ﬁnddup(A,B):−head(A,B),tail(A,C),member(B,C).
ﬁnddup(A,B):−tail(A,C),ﬁnddup(C,B).

last

Last element

len

Calculate list length

member

Member of a list

sorted

Check list is sorted

last (A,B):−tail(A,C),empty(C),head(A,B).
last (A,B):−tail(A,C), last (C,B).

len(A,B):−empty(A),zero(B).
len(A,B):−tail(A,C),len(C,D),succ(D,B).

member(A,B):−head(A,B).
member(A,B):−tail(A,C),member(C,B).

sorted(A):−tail(A,B),empty(B).
sorted(A):−head(A,B),tail(A,C),head(C,D),geq(D,B),sorted(C).

threesame

First three elements are identical

threesame(A):−head(A,B),tail(A,C),head(C,B),tail(C,D),head(D,B).

Table 4: Example solutions for the list transformation problems.

50%. Each list is randomly generated and has a maximum length of 50. We sample the
list elements uniformly at random from the set {1, 2, . . . , 100}. We measure the predictive
accuracy and learning times. We enforce a timeout of ﬁve minutes per task. We repeat
each experiment 10 times and plot the standard error.

5.3.3 Results

Table 5 shows that Popper equals or outperforms Enumerate on all the tasks in terms
of predictive accuracies. When a system has 50% accuracy, it means that the system
has failed to learn a program in the given amount of time, and so achieves the default
accuracy. Table 6 shows that Popper substantially outperforms Enumerate in terms of
learning times. For instance, whereas it takes Enumerate 159 seconds to ﬁnd an evens
program, it takes Popper only four seconds. Table 7 decomposes the learning times of
Popper.

Table 5 shows that Popper equals or outperforms Metagol on all the tasks in terms
of predictive accuracies, except the finddup problem, where Metagol has a 2% higher
predictive accuracy. Table 5 also shows that Aleph struggles to learn solutions to these
problems. The exceptions are addhead and threesame, which do not need recursion.

Overall, the results from this experiment suggest that (i) the answer to question Q1
is again yes, constraints improve learning performance, and (ii) Popper can outperform
other ILP systems when learning complex and recursive list transformation programs.

42

Andrew Cropper, Rolf Morel

Name

Popper

Enumerate Metagol

Aleph

addhead
dropk
droplast
evens
finddup
last
len
member
sorted
threesame

100 ± 0
100 ± 0
100 ± 0
100 ± 0
98 ± 0
100 ± 0
100 ± 0
100 ± 0
100 ± 0
99 ± 0

100 ± 0
50 ± 0
50 ± 0
100 ± 0
50 ± 0
50 ± 0
50 ± 0
100 ± 0
50 ± 0
99 ± 0

n/a
n/a
n/a
50 ± 0
100 ± 0
100 ± 0
50 ± 0
100 ± 0
50 ± 0
99 ± 0

90 ± 10
50 ± 0
50 ± 0
50 ± 0
50 ± 0
50 ± 0
50 ± 0
50 ± 0
68 ± 2
99 ± 0

Table 5: List transformation predictive accuracies. We round accuracies to integer values.
The error is standard error.

Name

Popper

Enumerate Metagol

Aleph

addhead
dropk
droplast
evens
finddup
last
len
member
sorted
threesame

0.5 ± 0
0.8 ± 0
3 ± 0.1
4 ± 0.1
36 ± 2
2 ± 0.1
12 ± 0.3
0.4 ± 0.1
23 ± 1
0.2 ± 0.1

2 ± 0
300 ± 0
300 ± 0
159 ± 0.1
300 ± 0
300 ± 0
300 ± 0
7 ± 0
300 ± 0
0.4 ± 0.2

n/a
n/a
n/a
300 ± 0
2 ± 0.5
0.7 ± 0.2
300 ± 0
0.3 ± 0
300 ± 0
0.9 ± 0.3

103 ± 49
3 ± 0.2
300 ± 0
1 ± 0
1 ± 0.1
1 ± 0.1
1 ± 0
0.9 ± 0.1
0.8 ± 0
0.5 ± 0

Table 6: List transformation learning times. We round times over 1 second to the nearest
second. The error is standard error. Note that although Aleph is sometimes faster than
Popper, it only learns accurate solutions for addhead and threesame.

Name

Time

Grounding

Solving

addhead
dropk
droplast
evens
finddup
last
len
member
sorted
threesame

0.5 ± 0
0.8 ± 0
3 ± 0.1
4 ± 0.1
36 ± 2
2 ± 0.1
12 ± 0.3
0.4 ± 0.1
23 ± 1
0.2 ± 0.1

0.1 ± 0
0.3 ± 0
0.4 ± 0.1
1 ± 0
25 ± 1
1 ± 0
7 ± 0.2
0.1 ± 0
12 ± 0.9
0 ± 0

0.2 ± 0
0.1 ± 0
1 ± 0
1 ± 0.1
7 ± 0.5
0.5 ± 0
2 ± 0.1
0.1 ± 0
8 ± 0.6
0 ± 0

Table 7: Decomposition of Popper learning times. The unaccounted time (time not
grounding or solving) is mostly the overhead of testing the induced Prolog programs.

5.4 Scalability

Our buttons experiment (Experiment 5.1) showed that Popper scales well in the size of
the optimal solution size and the number of background relations. Our robot experiment
(Experiment 5.2) showed that Popper scales well in the size of the domain. The purpose
of this experiment is to evaluate how well Popper scales in terms of the (i) number of

Learning programs by learning from failures

43

examples and (ii) the size of examples. To do so, we repeat the last experiment from
Section 5.3, where Popper and Metagol achieved similar performance.

5.4.1 Materials

We use the same materials as Section 5.3.

5.4.2 Settings

We run two experiments. In the ﬁrst experiment we vary the number of examples. In the
second experiment we vary the size of the examples (the size of the input list). For each
experiment, we measure the predictive accuracy and learning times averaged over 10
repetitions.

Number of examples. For each n in {1000, 2000, . . . , 10000}, we generate n positive and
n negative training examples, and 1000 positive and 1000 negative testing examples and
each element is a random integer from the range 1 to 1000.

Example size. For each s in {50, 100, 150, . . . , 500}, we generate 10 positive and 10 neg-
ative training examples, and 1000 positive and 1000 negative testing examples, where
each list is of length s and each element is a random integer from the range 1 to 1000.

5.4.3 Results

Figure 12 shows the results when varying the number of training examples. The predic-
tive accuracies of Popper and Metagol are almost identical until around 10,000 examples.
Given this many examples, Metagol struggles to ﬁnd a solution in one minute and even-
tually converges on the default predictive accuracy (50%). By contrast, Popper does not
struggle to ﬁnd a solution, even given 20,000 examples. Figure 12 shows the learning
times of both systems. The learning time of Popper increases linearly simply because of
the overhead of testing hypotheses on more examples. The results from this experiment
suggest that the answer to Q2 is that Popper scales well with respect the number of
examples.

Figure 13 shows the results when varying the size of the input (i.e. the size of the
input list). Popper outperforms Metagol in all cases. The mean learning times of Popper
for examples of length 50 and 500 are both less than a second. The reason is that Popper
only uses the examples to test a hypothesis, so any increase in running time simply
comes from executing the hypotheses using Prolog. By contrast, Metagol’s performance
drastically degrades as the size of the examples grows. The mean learning times for
Metagol for examples of length 50 and 500 are 20 and 54 seconds respectively. The
reason is that Metagol uses the examples to search for a hypothesis by inducing and
executing partial programs over the examples. These results suggest that the answer to
Q3 is yes and the answer to Q2 is that Popper scales well with respect to the size of
examples.

44

100

)

%

(

y
c
a
r
u
c
c
a

e
v
i
t
c
i
d
e
r
P

90

80

70

60

50

)
s
d
n
o
c
e
s
(

e
m

i
t

i

g
n
n
r
a
e
L

60

40

20

0

Andrew Cropper, Rolf Morel

Popper
Metagol

5,000

10,000

15,000

20,000

Number of examples

(b) Learning times

Popper
Metagol

5,000

10,000

15,000

20,000

Number of examples

(a) Predictive accuracies

Fig. 12: The experimental results for the last task when varying the number of training
examples.

100

)

%

(

y
c
a
r
u
c
c
a

e
v
i
t
c
i
d
e
r
P

90

80

70

60

50

Popper
Metagol

100

200

300

400

500

Example size

(a) Predictive accuracies

)
s
d
n
o
c
e
s
(

e
m

i
t

i

g
n
n
r
a
e
L

60

40

20

0

Popper
Metagol

100

200

300

400

500

Example size

(b) Learning times

Fig. 13: The experimental results for the last task when varying the size (list length) of
training examples.

5.5 Sensitivity

The learning from failures hypothesis space (Proposition 1) is a function of the number
of predicate declarations and three other variables:

– the maximum number of unique variables in a clause
– the maximum number of body literals allowed in a clause
– the maximum number of clauses allowed in a hypothesis

The purpose of this experiment is to evaluate how sensitive Popper is to these parame-
ters. To do so, we repeat the len experiment from Section 5.3 with the same BK, settings,
and method, except we run three separate experiments where we vary the three afore-
mentioned parameters.

Learning programs by learning from failures

45

5.5.1 Results

Figure 14 shows the experimental results. The results show that Popper is sensitive to the
maximum number of unique variables, which has a strong inﬂuence on learning times.
This result follows from Proposition 1 because more variables implies more ways to form
literals in a clause. Somewhat surprisingly, doubling the number of variables from 4 to
8 has little difference on performance, which suggests that Popper is robust to imperfect
parameters. The results show that Popper is mostly insensitive to the maximum number
of body literals in a clause. The main reason is that Popper does not pre-compute every
possible clause in the hypothesis space, which is, for instance, the case with ILASP2i
and ILASP3. The results show that Popper scales linearly with the maximum number of
clauses. Overall these results suggest that Popper scales well with the maximum number
of body literals, but can struggle with very large values for the maximum number of
unique variables and clauses.

Popper

60

40

20

)
s
d
n
o
c
e
s
(

e
m

i
t

i

g
n
n
r
a
e
L

Popper

5

4

3

2

1

)
s
d
n
o
c
e
s
(

e
m

i
t

i

g
n
n
r
a
e
L

0

4

6

8

10

12

14

0
20

40

60

80

100

Maximum number of variables

Maximum number of literals

(a)

(b)

)
s
d
n
o
c
e
s
(

e
m

i
t

i

g
n
n
r
a
e
L

60

40

20

0

Popper

20

40

60

80

100

Maximum number of clauses
(c)

Fig. 14: The experimental results for the len task when varying the maximum number
of unique variables (a), maximum body literals in a clause (b), and maximum number
of clauses (c).

6 Conclusions and limitations

We have described an ILP approach called learning from failures which decomposes the
ILP problem into three separate stages: generate, test, and constrain. In the generate
stage, the learner generates a hypothesis that satisﬁes a set of hypothesis constraints (Def-
inition 6). In the test stage, the learner tests a hypothesis against training examples. If
a hypothesis fails, then, in the constrain stage, the learner learns hypothesis constraints
from the failed hypothesis to prune the hypothesis space, i.e. to constrain subsequent
hypothesis generation. In Section 3.5, we introduced three types of constraints based
on theta-subsumption: generalisation, specialisation, and elimination and proved their
soundness in that they do not prune optimal solutions (Deﬁnition 14). This loop repeats
until either (i) the learner ﬁnds an optimal solution, or (ii) there are no more hypothe-
ses to test. We implemented this approach in Popper, an ILP system that learns deﬁnite
programs. Popper combines ASP and Prolog to support types, learning optimal solutions,
learning recursive programs, reasoning about lists and inﬁnite domains, and hypothesis
constraints. We evaluated our approach on three diverse domains (toy game problems,

46

Andrew Cropper, Rolf Morel

robot strategies, and list transformations). Our experimental results show that (i) con-
straints drastically reduce the hypothesis space, (ii) Popper scales well with respect to the
optimal solution size, the number of background relations, the domain size, the number
of training examples, and the size of the training examples, and (iii) Popper can substan-
tially outperform existing ILP systems both in terms of predictive accuracies and learning
times.

6.1 Limitations and future work

Popper, as implemented in this paper, has several limitations that future work should
address.

6.1.1 Features

Non-observational predicate learning. Unlike some ILP systems [46, 35], Popper does not
support non-observational predicate learning (non-OPL) [46], where examples of the
target predicates are not directly given. Future work should address this limitation.

Predicate invention. Predicate invention has been shown to help reduce the size of target
programs, which in turns reduces sample complexity and improves predictive accuracy
[14, 25]. Popper does not currently support predicate invention. There are two straight-
forward ways to support predicate invention. Popper could mimic Metagol by imposing
metarules to restrict the form of clauses in a hypothesis and to guide the invention of
new predicate symbols – which is easy to do because, as we show in Appendix A, Pop-
per can simulate metarules through hypothesis constraints. Alternatively Popper could
mimic ILASP by supporting prescriptive predicate invention [37], where the arity and (in
ILASP’s case, argument types) are pre-speciﬁed by the user. Most of the results in this
paper should extend to both approaches.

Negation. Popper learns deﬁnite programs and tests them using Prolog. Popper can also
trivially learn Datalog programs and test them using ASP. In future work, we want to
consider learning other types of programs. For instance, most of our pruning techniques
(except the elimination constraint) should extend to learning non-monotonic programs,
such as Datalog with stratiﬁed negation.

Noise. Most ILP systems handle noisy (misclassiﬁed) examples (Table 1). Popper does
not currently support noisy examples. We can address this issue by relaxing when to ap-
ply learned hypothesis constraints and by maintaining the best hypotheses tested during
the learning, i.e. the hypothesis which entails the most positive and the fewest negative
examples. However, noise handling will likely increase learning times and future work
should explore this trade-off.

6.1.2 Better search

An advantage of decomposing the learning problem is that it allows for a variety of
algorithms and implementations, where each stage can be improved independently of
the others. For instance, any improvement to the Popper ASP encoding that generates

Learning programs by learning from failures

47

programs would have a major inﬂuence on learning times because it would reduce the
number of programs to test. Likewise, we can also optimise the testing step. Future work
should consider better search techniques.

6.1.3 Better constraints

Hypothesis constraints are central to our idea. Popper uses both predeﬁned and learned
constraints to improve performance. Popper uses predeﬁned constraints to prune redun-
dant programs from the hypothesis space (Section 4), such as recursive programs with-
out a base case and subsumption redundant program. Popper also learns constraints
from failures. We think the most promising direction for future work is to improve both
types of constraints (predeﬁned and learned).

Types. Like many ILP systems [46, 7, 63, 38, 28], Popper supports simple types to prune
the hypothesis space. However, more complex types, such as polymorphic types, can
achieve better pruning for programs over structured data [44]. For instance, polymor-
phic types would allow us to distinguish between using a predicate on a list of integers
and on a list of characters. Reﬁnement types [52], i.e. types annotated with restricting
predicates, could allow a user to specify stronger program properties (other than exam-
ples), such as requiring that a reverse program provably has the property that the lengths
of the input and output are the same. In future work we want to explore whether we
can express such complex types as hypothesis constraints.

Learned constraints. The constraints described in Section 3.5 prune specialisations and
generalisations of a failed hypothesis. However, we have only brieﬂy analysed the prop-
erties of these constraints. We showed that these constraints are sound (Propositions 3
and 4) in that they do not prune optimal solutions. We have not, however, considered
their completeness, in that they prune all non-optimal solutions. Indeed, our elimination
constraint, for the special case of separable deﬁnite programs, prunes hypotheses that the
generalisation and specialisation constraints miss. In other words, the theory regarding
which constraints to use is yet to be developed, and there may be many more constraints
to be learned from failed hypotheses, all of which should drastically improve learning
performance. By contrast, reﬁnement operators for clauses [61, 57, 50] and theories [50,
43, 5] have been studied in detail in ILP. Therefore, we think that this paper opens a
new direction of research into identifying and analysing different constraints that we
can learn from failed hypotheses.

Acknowledgements

We foremost thank Mark Law for all of his help in writing this paper, including ﬁnding
suitable ILASP representations for the experiments, for answering our many questions
on the ILASP systems, and for suggesting much of the text on ILASP3. We thank Tobias
Kaminski, Sebastijan Dumanˇci´c, and Richard Evans for extremely valuable feedback on
the paper. We also thank one of the anonymous reviewers for suggesting a much more
efﬁcient constraint encoding that reduced Popper’s learning times in the experiments by
almost a half.

48

References

Andrew Cropper, Rolf Morel

1. John Ahlgren and Shiu Yin Yuen. Efﬁcient program synthesis using constraint satisfaction in induc-

tive logic programming. J. Machine Learning Res., 14(1):3649–3682, 2013.

2. Aws Albarghouthi, Paraschos Koutris, Mayur Naik, and Calvin Smith. Constraint-based synthesis of
datalog programs. In J. Christopher Beck, editor, Principles and Practice of Constraint Programming
- 23rd International Conference, CP 2017, Melbourne, VIC, Australia, August 28 - September 1, 2017,
Proceedings, volume 10416 of Lecture Notes in Computer Science, pages 689–706. Springer, 2017.
3. Duangtida Athakravi, Dalal Alrajeh, Krysia Broda, Alessandra Russo, and Ken Satoh. Inductive learn-
ing using constraint-driven bias. In Jesse Davis and Jan Ramon, editors, Inductive Logic Programming
- 24th International Conference, ILP 2014, Nancy, France, September 14-16, 2014, Revised Selected Pa-
pers, volume 9046 of Lecture Notes in Computer Science, pages 16–32. Springer, 2014.

4. Duangtida Athakravi, Domenico Corapi, Krysia Broda, and Alessandra Russo. Learning through
hypothesis reﬁnement using answer set programming.
In Gerson Zaverucha, Vítor Santos Costa,
and Aline Paes, editors, Inductive Logic Programming - 23rd International Conference, ILP 2013, Rio de
Janeiro, Brazil, August 28-30, 2013, Revised Selected Papers, volume 8812 of Lecture Notes in Computer
Science, pages 31–46. Springer, 2013.

5. Liviu Badea. A reﬁnement operator for theories. In Céline Rouveirol and Michèle Sebag, editors,
Inductive Logic Programming, 11th International Conference, ILP 2001, Strasbourg, France, September
9-11, 2001, Proceedings, volume 2157 of Lecture Notes in Computer Science, pages 1–14. Springer,
2001.

6. Matej Balog, Alexander L. Gaunt, Marc Brockschmidt, Sebastian Nowozin, and Daniel Tarlow. Deep-
coder: Learning to write programs. In 5th International Conference on Learning Representations, ICLR
2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net, 2017.
7. Hendrik Blockeel and Luc De Raedt. Top-down induction of ﬁrst-order logical decision trees. Artif.

Intell., 101(1-2):285–297, 1998.

8. Ivan Bratko. Reﬁning complete hypotheses in ILP.

In Saso Dzeroski and Peter A. Flach, editors,
Inductive Logic Programming, 9th International Workshop, ILP-99, Bled, Slovenia, June 24-27, 1999,
Proceedings, volume 1634 of Lecture Notes in Computer Science, pages 44–55. Springer, 1999.

9. Alonzo Church. A note on the entscheidungsproblem. J. Symb. Log., 1(1):40–41, 1936.

10. William W. Cohen. Grammatically biased learning: Learning logic programs using an explicit an-

tecedent description language. Artif. Intell., 68(2):303–366, 1994.

11. Domenico Corapi, Alessandra Russo, and Emil Lupu.

Inductive logic programming as abductive
search. In Manuel V. Hermenegildo and Torsten Schaub, editors, Technical Communications of the
26th International Conference on Logic Programming, ICLP 2010, July 16-19, 2010, Edinburgh, Scot-
land, UK, volume 7 of LIPIcs, pages 54–63. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik,
2010.

12. Domenico Corapi, Alessandra Russo, and Emil Lupu.

Inductive logic programming in answer set
programming.
In Stephen Muggleton, Alireza Tamaddoni-Nezhad, and Francesca A. Lisi, editors,
Inductive Logic Programming - 21st International Conference, ILP 2011, Windsor Great Park, UK, July
31 - August 3, 2011, Revised Selected Papers, volume 7207 of Lecture Notes in Computer Science, pages
91–97. Springer, 2011.

13. Vítor Santos Costa, Ashwin Srinivasan, Rui Camacho, Hendrik Blockeel, Bart Demoen, Gerda
Janssens, Jan Struyf, Henk Vandecasteele, and Wim Van Laer. Query transformations for improv-
ing the efﬁciency of ILP systems. J. Machine Learning Res., 4:465–491, 2003.

14. Andrew Cropper. Playgol: Learning programs through play.

In Sarit Kraus, editor, Proceedings of
the Twenty-Eighth International Joint Conference on Artiﬁcial Intelligence, IJCAI 2019, Macao, China,
August 10-16, 2019, pages 6074–6080. ijcai.org, 2019.

15. Andrew Cropper. Forgetting to learn logic programs. In The Thirty-Fourth AAAI Conference on Artiﬁ-
cial Intelligence, AAAI 2020, New York, NY, USA, February 7-12, 2020, pages 3676–3683. AAAI Press,
2020.

16. Andrew Cropper and Sebastijan Dumancic. Inductive logic programming at 30: a new introduction.

CoRR, abs/2008.07912, 2020.

17. Andrew Cropper and Sebastijan Dumancic. Learning large logic programs by going beyond entail-
ment. In Christian Bessiere, editor, Proceedings of the Twenty-Ninth International Joint Conference on
Artiﬁcial Intelligence, IJCAI 2020, pages 2073–2079. ijcai.org, 2020.

18. Andrew Cropper, Sebastijan Dumancic, and Stephen H. Muggleton. Turning 30: New ideas in induc-
tive logic programming. In Christian Bessiere, editor, Proceedings of the Twenty-Ninth International
Joint Conference on Artiﬁcial Intelligence, IJCAI 2020, pages 4833–4839. ijcai.org, 2020.

19. Andrew Cropper, Richard Evans, and Mark Law. Inductive general game playing. Machine Learning,

109(7):1393–1434, 2020.

Learning programs by learning from failures

49

20. Andrew Cropper, Rolf Morel, and Stephen Muggleton. Learning higher-order logic programs. Ma-

chine Learning, 109(7):1289–1322, 2020.

21. Andrew Cropper and Stephen H. Muggleton. Learning efﬁcient logical robot strategies involving
composable objects. In Qiang Yang and Michael J. Wooldridge, editors, Proceedings of the Twenty-
Fourth International Joint Conference on Artiﬁcial Intelligence, IJCAI 2015, Buenos Aires, Argentina,
July 25-31, 2015, pages 3423–3429. AAAI Press, 2015.
and

22. Andrew

Muggleton.

Stephen

Metagol

Cropper

system.

H.

https://github.com/metagol/metagol, 2016.

23. Andrew Cropper, Alireza Tamaddoni-Nezhad, and Stephen H. Muggleton. Meta-interpretive learn-
ing of data transformation programs. In Katsumi Inoue, Hayato Ohwada, and Akihiro Yamamoto,
editors, Inductive Logic Programming - 25th International Conference, ILP 2015, Kyoto, Japan, August
20-22, 2015, Revised Selected Papers, volume 9575 of Lecture Notes in Computer Science, pages 46–59.
Springer, 2015.

24. Andrew Cropper and Sophie Tourret.

Logical reduction of metarules. Machine Learning,

109(7):1323–1369, 2020.

25. Sebastijan Dumancic, Tias Guns, Wannes Meert, and Hendrik Blockeel. Learning relational represen-
tations with auto-encoding logic programs. In Sarit Kraus, editor, Proceedings of the Twenty-Eighth
International Joint Conference on Artiﬁcial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019,
pages 6081–6087. ijcai.org, 2019.

26. Kevin Ellis, Lucas Morales, Mathias Sablé-Meyer, Armando Solar-Lezama, and Josh Tenenbaum.
Learning libraries of subroutines for neurally-guided bayesian program induction. In NeurIPS 2018,
pages 7816–7826, 2018.

27. Kevin Ellis, Maxwell I. Nye, Yewen Pu, Felix Sosa, Josh Tenenbaum, and Armando Solar-Lezama.
Write, execute, assess: Program synthesis with a REPL. In Hanna M. Wallach, Hugo Larochelle, Alina
Beygelzimer, Florence d’Alché-Buc, Emily B. Fox, and Roman Garnett, editors, Advances in Neural
Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019,
NeurIPS 2019, 8-14 December 2019, Vancouver, BC, Canada, pages 9165–9174, 2019.

28. Richard Evans and Edward Grefenstette. Learning explanatory rules from noisy data. J. Artif. Intell.

Res., 61:1–64, 2018.

29. Richard Evans, José Hernández-Orallo, Johannes Welbl, Pushmeet Kohli, and Marek J. Sergot. Mak-

ing sense of sensory input. CoRR, abs/1910.02227, 2019.

30. Yu Feng, Ruben Martins, Osbert Bastani, and Isil Dillig. Program synthesis using conﬂict-driven
learning.
In Jeffrey S. Foster and Dan Grossman, editors, Proceedings of the 39th ACM SIGPLAN
Conference on Programming Language Design and Implementation, PLDI 2018, Philadelphia, PA, USA,
June 18-22, 2018, pages 420–435. ACM, 2018.

31. John K. Feser, Swarat Chaudhuri, and Isil Dillig. Synthesizing data structure transformations from
input-output examples. In David Grove and Steve Blackburn, editors, Proceedings of the 36th ACM
SIGPLAN Conference on Programming Language Design and Implementation, Portland, OR, USA, June
15-17, 2015, pages 229–239. ACM, 2015.

32. Martin Gebser, Roland Kaminski, Benjamin Kaufmann, and Torsten Schaub. Clingo = ASP + control:

Preliminary report. CoRR, abs/1405.3694, 2014.

33. Martin Gebser, Roland Kaminski, Benjamin Kaufmann, and Torsten Schaub. Multi-shot ASP solving

with clingo. Theory Pract. Log. Program., 19(1):27–82, 2019.

34. Tobias Kaminski, Thomas Eiter, and Katsumi Inoue. Exploiting answer set programming with exter-
nal sources for meta-interpretive learning. Theory Pract. Log. Program., 18(3-4):571–588, 2018.
35. Nikos Katzouris, Alexander Artikis, and Georgios Paliouras. Online learning of event deﬁnitions.

TPLP, 16(5-6):817–833, 2016.

36. Brenden M. Lake, Tomer D. Ullman, Joshua B. Tenenbaum, and Samuel J. Gershman. Building

machines that learn and think like people. CoRR, abs/1604.00289, 2016.

37. Mark Law. Inductive learning of answer set programs. PhD thesis, Imperial College London, UK, 2018.
In
38. Mark Law, Alessandra Russo, and Krysia Broda.
Eduardo Fermé and João Leite, editors, Logics in Artiﬁcial Intelligence - 14th European Conference,
JELIA 2014, Funchal, Madeira, Portugal, September 24-26, 2014. Proceedings, volume 8761 of Lecture
Notes in Computer Science, pages 311–325. Springer, 2014.

Inductive learning of answer set programs.

39. Mark Law, Alessandra Russo, and Krysia Broda.

Iterative learning of answer set programs from

context dependent examples. Theory Pract. Log. Program., 16(5-6):834–848, 2016.

40. Dianhuan Lin, Eyal Dechter, Kevin Ellis, Joshua B. Tenenbaum, and Stephen Muggleton. Bias re-
formulation for one-shot function induction.
In Torsten Schaub, Gerhard Friedrich, and Barry
O’Sullivan, editors, ECAI 2014 - 21st European Conference on Artiﬁcial Intelligence, 18-22 August
2014, Prague, Czech Republic - Including Prestigious Applications of Intelligent Systems (PAIS 2014),
volume 263 of Frontiers in Artiﬁcial Intelligence and Applications, pages 525–530. IOS Press, 2014.

50

Andrew Cropper, Rolf Morel

41. John W Lloyd. Foundations of logic programming. Springer Science & Business Media, 2012.
42. Donald Michie. Machine learning in the next ﬁve years. In Derek H. Sleeman, editor, Proceedings of
the Third European Working Session on Learning, EWSL 1988, Turing Institute, Glasgow, UK, October
3-5, 1988, pages 107–122. Pitman Publishing, 1988.

43. Herman Midelfart. A bounded search space of clausal theories. In Saso Dzeroski and Peter A. Flach,
editors, Inductive Logic Programming, 9th International Workshop, ILP-99, Bled, Slovenia, June 24-
27, 1999, Proceedings, volume 1634 of Lecture Notes in Computer Science, pages 210–221. Springer,
1999.

44. Rolf Morel, Andrew Cropper, and C.-H. Luke Ong. Typed meta-interpretive learning of logic pro-
In Francesco Calimeri, Nicola Leone, and Marco Manna, editors, Logics in Artiﬁcial Intel-
grams.
ligence - 16th European Conference, JELIA 2019, Rende, Italy, May 7-11, 2019, Proceedings, volume
11468 of Lecture Notes in Computer Science, pages 198–213. Springer, 2019.

45. Stephen Muggleton. Inductive logic programming. New Generation Comput., 8(4):295–318, 1991.
46. Stephen Muggleton. Inverse entailment and progol. New Generation Comput., 13(3&4):245–286,

1995.

47. Stephen Muggleton, Luc De Raedt, David Poole, Ivan Bratko, Peter A. Flach, Katsumi Inoue, and
Ashwin Srinivasan. ILP turns 20 - biography and future challenges. Machine Learning, 86(1):3–23,
2012.

48. Stephen H. Muggleton, Dianhuan Lin, Niels Pahlavi, and Alireza Tamaddoni-Nezhad. Meta-
interpretive learning: application to grammatical inference. Machine Learning, 94(1):25–49, 2014.
49. Stephen H. Muggleton, Dianhuan Lin, and Alireza Tamaddoni-Nezhad. Meta-interpretive learning of
higher-order dyadic Datalog: predicate invention revisited. Machine Learning, 100(1):49–73, 2015.
50. Shan-Hwei Nienhuys-Cheng and Ronald de Wolf. Foundations of Inductive Logic Programming.

Springer-Verlag New York, Inc., Secaucus, NJ, USA, 1997.

51. G.D. Plotkin. Automatic Methods of Inductive Inference. PhD thesis, Edinburgh University, August

1971.

52. Nadia Polikarpova, Ivan Kuraj, and Armando Solar-Lezama. Program synthesis from polymorphic
reﬁnement types. In Chandra Krintz and Emery Berger, editors, Proceedings of the 37th ACM SIGPLAN
Conference on Programming Language Design and Implementation, PLDI 2016, Santa Barbara, CA,
USA, June 13-17, 2016, pages 522–538. ACM, 2016.

53. Karl Popper. The logic of scientiﬁc discovery. Routledge, 2005.
54. J. Ross Quinlan. Learning logical deﬁnitions from relations. Machine Learning, 5:239–266, 1990.
55. Luc De Raedt. Logical and relational learning. Cognitive Technologies. Springer, 2008.
56. Luc De Raedt and Maurice Bruynooghe. Interactive concept-learning and constructive induction by

analogy. Machine Learning, 8:107–150, 1992.

57. Luc De Raedt and Maurice Bruynooghe. A theory of clausal discovery.

In Ruzena Bajcsy, editor,
Proceedings of the 13th International Joint Conference on Artiﬁcial Intelligence. Chambéry, France,
August 28 - September 3, 1993, pages 1058–1063. Morgan Kaufmann, 1993.

58. Mukund Raghothaman, Jonathan Mendelson, David Zhao, Mayur Naik, and Bernhard Scholz.

Provenance-guided synthesis of datalog programs. PACMPL, 4(POPL):62:1–62:27, 2020.
59. Oliver Ray. Nonmonotonic abductive inductive learning. J. Applied Logic, 7(3):329–340, 2009.
60. Peter Schüller and Mishal Benz. Best-effort inductive logic programming via ﬁne-grained cost-based
hypothesis generation - the inspire system at the inductive logic programming competition. Machine
Learning, 107(7):1141–1169, 2018.

61. Ehud Y. Shapiro. Algorithmic Program DeBugging. MIT Press, Cambridge, MA, USA, 1983.
62. Armando Solar-Lezama, Christopher Grant Jones, and Rastislav Bodík. Sketching concurrent data
structures. In Rajiv Gupta and Saman P. Amarasinghe, editors, Proceedings of the ACM SIGPLAN 2008
Conference on Programming Language Design and Implementation, Tucson, AZ, USA, June 7-13, 2008,
pages 136–148. ACM, 2008.

63. A. Srinivasan. The ALEPH manual. Machine Learning at the Computing Laboratory, Oxford University,

2001.

64. Ashwin Srinivasan and Ravi Kothari. A study of applying dimensionality reduction to restrict the
size of a hypothesis space. In Stefan Kramer and Bernhard Pfahringer, editors, Inductive Logic Pro-
gramming, 15th International Conference, ILP 2005, Bonn, Germany, August 10-13, 2005, Proceedings,
volume 3625 of Lecture Notes in Computer Science, pages 348–365. Springer, 2005.

65. Sten-Åke Tärnlund. Horn clause computability. BIT, 17(2):215–226, 1977.
66. William Yang Wang, Kathryn Mazaitis, and William W. Cohen. Structure learning via parameter
learning. In Jianzhong Li, Xiaoyang Sean Wang, Minos N. Garofalakis, Ian Soboroff, Torsten Suel,
and Min Wang, editors, Proceedings of the 23rd ACM International Conference on Conference on In-
formation and Knowledge Management, CIKM 2014, Shanghai, China, November 3-7, 2014, pages
1199–1208. ACM, 2014.

Learning programs by learning from failures

51

67. Antonius Weinzierl. Blending lazy-grounding and CDNL search for answer-set solving. In Marcello
Balduccini and Tomi Janhunen, editors, Logic Programming and Nonmonotonic Reasoning - 14th In-
ternational Conference, LPNMR 2017, Espoo, Finland, July 3-6, 2017, Proceedings, volume 10377 of
Lecture Notes in Computer Science, pages 191–204. Springer, 2017.

A Popper metarule theory constraints

A.1 Metarules

Let M be an arbitrary metarule, i.e. a second-order Horn clause which quantiﬁes over predicate symbols.
For example, P(A,B):-Q(A,C),R(C,B) is known as the chain metarule. All letters are quantiﬁed variables,
with P, Q, and R being second-order, i.e. needing to be substituted for by predicate symbols.

A.2 From a metarule to literals

Let M = head:-body1, . . . , bodym be a metarule. We use the clause encoding function encodeSizedClause
from section 4.2.2 to derive an encoding of a metarule.

Example 14 Consider M = P(A,B):-Q(A,C),R(C,B). Its encoding, encodeSizedClause(Clause, M ), is

head_literal(Clause,P,2,(V0,V1)),
body_literal(Clause,Q,2,(V0,V2)),body_literal(Clause,R,2,(V2,V1)),
V0!=V1,V0!=V2,V1!=V2,clause_size(Clause,2)

A.3 Asserting metarule conformance

Let Ms be a set of metarules. For each clause of a metarule conformant program, the clause must be an
instance of one of the metarules in Ms. A clause C is an instance of metarule M ∈ M s if there exists
substitution θ such that M θ = C .

We introduce two rules to ensure every clause of a generated program is an instance of at least one
metarule. The ﬁrst rule identiﬁes when there exists some metarule for which the clause is an instance.
The second rule is a constraint expressing that every clause of a program must be identiﬁed as being an
instance of at least one metarule.
For each M ∈ Ms, generate the following rule of the ﬁrst kind:

meta_clause(Clause):-encodeSizedClause(Clause, M ).

The second rule is:

:-clause(Clause),not meta_clause(Clause).

B Language biases in buttons experiment

B.1 ILASP2i and ILASP3

#modeh(1,f, (positive)).
#modeb(1,button1, (positive)).
...
#modeb(1,button20, (positive)).

52

Andrew Cropper, Rolf Morel

B.2 Popper and Enumerate

max_vars(1).
max_clauses(1).
head_pred(f,1).
body_pred(button1,1).
...
body_pred(button20,1).

B.3 Aleph

:- aleph_set(i,6).
:- aleph_set(clauselength,2).
:- aleph_set(nodes,5000).
:- modeh,f(+var)).
:- modeb(*,button1(+var)).
:- determination(f/1,button1/1).
:- modeb(*,button2(+var)).
...
:- determination(f/1,button20/1).

B.4 Metagol

metarule(unary1, [P,Q], [P,A], [[Q,A]]).
metarule(unary2, [P,Q,R], [P,A], [[Q,A],[R,A]]).
body_pred(button1/1).
...
body_pred(button20/1).

C Language biases in robots experiment

C.1 ILASP2i and ILASP3

#modeh(f(var(state)), (positive)).
#modeh(start_state(var(state)), (positive)).
#modeb(3,move_up(var(state),var(state)), (anti_reflexive,symmetric,positive)).
#modeb(3,move_down(var(state),var(state)), (anti_reflexive,symmetric,positive)).
#modeb(3,move_left(var(state),var(state)), (anti_reflexive,symmetric,positive)).
#modeb(3,move_right(var(state),var(state)), (anti_reflexive,symmetric,positive)).
#modeb(3,at_top(var(state)), (positive)).
#modeb(3,at_bottom(var(state)), (positive)).
#modeb(3,at_left(var(state)), (positive)).
#modeb(3,at_right(var(state)), (positive)).
#modeb(1,start_state(var(state)), (positive)).

#bias(":- occurs(V, X), #false : occurs(V, Y), Y != X.").
#bias("occurs(X, f(X)) :- head(f(X)).").
#bias("occurs(X, start_state(X)) :- head(start_state(X)).").
#bias("occurs(X, start_state(X)) :- body(start_state(X)).").
#bias("occurs(X, at_top(X)) :- body(at_top(X)).").

Learning programs by learning from failures

53

#bias("occurs(X, at_bottom(X)) :- body(at_bottom(X)).").
#bias("occurs(X, at_left(X)) :- body(at_left(X)).").
#bias("occurs(X, at_right(X)) :- body(at_right(X)).").
#bias("occurs(X, move_up(X, Y)) :- body(move_up(X, Y)).").
#bias("occurs(X, move_left(X, Y)) :- body(move_left(X, Y)).").
#bias("occurs(X, move_right(X, Y)) :- body(move_right(X, Y)).").
#bias("occurs(X, move_down(X, Y)) :- body(move_down(X, Y)).").
#bias("occurs(X, move_up(Y, X)) :- body(move_up(Y, X)).").
#bias("occurs(X, move_left(Y, X)) :- body(move_left(Y, X)).").
#bias("occurs(X, move_right(Y, X)) :- body(move_right(Y, X)).").
#bias("occurs(X, move_down(Y, X)) :- body(move_down(Y, X)).").

C.2 Popper and Enumerate

max_vars(4).
max_body(3).
max_clauses(3).
head_pred(f,2).
body_pred(f,2).
body_pred(at_top,1).
body_pred(at_bottom,1).
body_pred(at_left,1).
body_pred(at_right,1).
body_pred(move_left,2).
body_pred(move_right,2).
body_pred(move_up,2).
body_pred(move_down,2).
direction(f,0,in).
direction(f,1,out).
direction(move_left,0,in).
direction(move_right,0,in).
direction(move_up,0,in).
direction(move_down,0,in).
direction(move_left,1,out).
direction(move_right,1,out).
direction(move_up,1,out).
direction(move_down,1,out).
direction(at_top,0,in).
direction(at_bottom,0,in).
direction(at_left,0,in).
direction(at_right,0,in).

C.3 Aleph

:- aleph_set(i,6).
:- aleph_set(clauselength,6).
:- aleph_set(nodes,50000).
:- modeh,f(+state,-state)).
:- modeb(*,move_up(+state,-state)).
:- modeb(*,move_down(+state,-state)).
:- modeb(*,move_left(+state,-state)).
:- modeb(*,move_right(+state,-state)).
:- modeb(*,at_top(+state)).
:- modeb(*,at_bottom(+state)).

54

Andrew Cropper, Rolf Morel

:- modeb(*,at_left(+state)).
:- modeb(*,at_right(+state)).
:- determination(f/2,move_up/2).
:- determination(f/2,move_down/2).
:- determination(f/2,move_left/2).
:- determination(f/2,move_right/2).
:- determination(f/2,at_top/1).
:- determination(f/2,at_bottom/1).
:- determination(f/2,at_left/1).
:- determination(f/2,at_right/1).

C.4 Metagol

body_pred(move_right/2).
body_pred(move_left/2).
body_pred(move_up/2).
body_pred(move_down/2).
body_pred(at_top/1).
body_pred(at_bottom/1).
body_pred(at_left/1).
body_pred(at_right/1).
metarule([P,Q], [P,A], [[Q,A]]).
metarule([P,Q], [P,A], [[Q,A]]).
metarule([P,Q,R], [P,A], [[Q,A,B],[R,B]]).
metarule([P,Q], [P,A], [[Q,A,B],[P,B]]).
metarule([P,Q,R], [P,A], [[Q,A,B],[R,A,B]]).
metarule([P,Q], [P,A,B], [[Q,A,B]]).
metarule([P,Q,R], [P,A,B], [[Q,A,B],[R,A,B]]).
metarule([P,Q,R], [P,A,B], [[Q,A],[R,A,B]]).
metarule([P,Q,R], [P,A,B], [[Q,A,B],[R,B]]).
metarule([P,Q,R], [P,A,B], [[Q,A,C],[R,C,B]]).
metarule([P,Q], [P,A,B], [[Q,A,C],[P,C,B]]).
metarule([P,Q], [P,A,B], [[Q,B,A]]).

D Language biases in lists experiment

D.1 Popper and Enumerate

For each list transformation problem, we have a speciﬁc bias to specify the target relations, such as the
following bias for the finddup problem:

head_pred(f,2).
type(f,0,list).
type(f,1,element).
direction(f,0,in).
direction(f,1,out).
body_pred(f,2).

For all the problems we include the following biases:

max_vars(5).
max_body(5).
max_clauses(2).
body_pred(head,2).
body_pred(tail,2).

Learning programs by learning from failures

55

body_pred(geq,2).
body_pred(empty,1).
body_pred(even,1).
body_pred(odd,1).
body_pred(one,1).
body_pred(zero,1).
body_pred(decrement,2).
body_pred(increment,2). % ONLY FOR SORTED
body_pred(element,2). % ONLY FOR FIND DUPLICATE
body_pred(cons,2). % ONLY FOR ADDHEAD, DROPK, DROPLAST
type(cons,0,element).
type(cons,1,list).
type(cons,2,list).
direction(cons,0,in).
direction(cons,1,in).
direction(cons,2,out).
type(head,0,list).
type(head,1,element).
direction(head,0,in).
direction(head,1,out).
type(tail,0,list).
type(tail,1,list).
direction(tail,0,in).
direction(tail,1,out).
type(empty,0,list).
direction(empty,0,in).
type(element,0,list).
type(element,1,element).
direction(element,0,in).
direction(element,1,out).
type(increment,0,element).
type(increment,1,element).
direction(increment,0,in).
direction(increment,1,out).
type(decrement,0,element).
type(decrement,1,element).
direction(decrement,0,in).
direction(decrement,1,out).
type(geq,0,element).
type(geq,1,element).
direction(geq,0,in).
direction(geq,1,in).
type(even,0,element).
direction(even,0,in).
type(odd,0,element).
direction(odd,0,in).
type(one,0,element).
direction(one,0,in).
type(zero,0,element).
direction(zero,0,out).

D.2 Aleph

For each list transformation problem, we have a speciﬁc bias to specify the target relations, such as the
following bias for the finddup problem:

:- modeh,f(+list,-element)).
:- modeb(*,f(+list,-element)).

56

Andrew Cropper, Rolf Morel

For all the problems we include the following biases (we we replace f/2 in the determinations with the
correct arity of the target predicate):

Note that increment is only given in the sorted experiment, element is only given in the finddupli

experiment, and cons is only given in the addhead, dropk, and droplast experiments.

:- aleph_set(i,6).\\
:- aleph_set(clauselength,6).\\
:- aleph_set(nodes,30000).\\
:- modeb,head(+list,-element)).
:- modeb(*,tail(+list,-list)).
:- modeb(*,geq(+element,+element)).
:- modeb(*,empty(+list)).
:- modeb(*,even(+element)).
:- modeb(*,odd(+element)).
:- modeb(*,one(+element)).
:- modeb(*,zero(-element)).
:- modeb(*,decrement(+element,-element)).
:- modeb(*,increment(+element,-element)).
:- modeb(*,element(+list,-element)).
:- modeb(*,cons(+element,+list,-list)).

D.3 Metagol

body_pred(head/2).
body_pred(tail/2).
body_pred(geq/2).
body_pred(empty/1).
body_pred(even/1).
body_pred(odd/1).
body_pred(one/1).
body_pred(zero/1).
body_pred(decrement/2).
body_pred(increment/2). % ONLY FOR SORTED
body_pred(member/2). % ONLY FOR FIND DUPLICATE

metarule([P,Q], [P,A], [[Q,A]]).
metarule([P,Q], [P,A], [[Q,A]]).
metarule([P,Q,R], [P,A], [[Q,A,B],[R,B]]).
metarule([P,Q], [P,A], [[Q,A,B],[P,B]]).
metarule([P,Q,R], [P,A], [[Q,A,B],[R,A,B]]).
metarule([P,Q], [P,A,B], [[Q,A,B]]).
metarule([P,Q,R], [P,A,B], [[Q,A,B],[R,A,B]]).
metarule([P,Q,R], [P,A,B], [[Q,A],[R,A,B]]).
metarule([P,Q,R], [P,A,B], [[Q,A,B],[R,B]]).
metarule([P,Q,R], [P,A,B], [[Q,A,C],[R,C,B]]).
metarule([P,Q], [P,A,B], [[Q,A,C],[P,C,B]]).
metarule([P,Q], [P,A,B], [[Q,A,B]]).

