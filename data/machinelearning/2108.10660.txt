1
2
0
2

g
u
A
4
2

]

G
L
.
s
c
[

1
v
0
6
6
0
1
.
8
0
1
2
:
v
i
X
r
a

Data Aggregation for Reducing Training Data in
Symbolic Regression

Lukas Kammerer[0000−0001−8236−4294], Gabriel Kronberger[0000−0002−3012−3189],
and Michael Kommenda

Josef Ressel Center for Symbolic Regression
Heuristic and Evolutionary Algorithms Laboratory
University of Applied Sciences Upper Austria, Hagenberg, Austria
lukas.kammerer@fh-hagenberg.at

Abstract. The growing volume of data makes the use of computation-
ally intense machine learning techniques such as symbolic regression with
genetic programming more and more impractical. This work discusses
methods to reduce the training data and thereby also the runtime of
genetic programming. The data is aggregated in a preprocessing step be-
fore running the actual machine learning algorithm. K-means clustering
and data binning is used for data aggregation and compared with ran-
dom sampling as the simplest data reduction method. We analyze the
achieved speed-up in training and the eﬀects on the trained models’ test
accuracy for every method on four real-world data sets. The performance
of genetic programming is compared with random forests and linear re-
gression. It is shown, that k-means and random sampling lead to very
small loss in test accuracy when the data is reduced down to only 30%
of the original data, while the speed-up is proportional to the size of the
data set. Binning on the contrary, leads to models with very high test
error.

Keywords: Symbolic Regression · Machine Learning · Sampling

1

Introduction

One of the ﬁrst tasks in data-based modeling of systems is collection and selection
of data with which a meaningful model can be learned. One challenge is to pro-
vide the right amount of data – w.r.t. both instances and features. There should
be enough data to compensate noise and train a suﬃciently complex model, but
not too much to unnecessarily slow down the training. With the growing volume
of data, especially the latter becomes more and more an issue when working
with computationally intensive algorithms like genetic programming (GP).

An intuitive idea to keep the training data small is outlined in Figure 1.
Instead of using all training data, only a few representative instances are ex-
tracted ﬁrst and then used for the training. Ideally, these few instances retain all

1 The ﬁnal publication is available at https://link.springer.com/chapter/10.

1007%2F978-3-030-45093-9_46

 
 
 
 
 
 
2

Kammerer et al.

y

3

2

1

0

-1

-2

-2

-1

0
x

1

2

-2

-1

1

2

0
x

Fig. 1. Schematic outline of extracting a data set of representative instances (right)
out of original noisy data (left).

information that are necessary to train a well-generalizing model. This idea has
been already applied for support vector machines for classiﬁcation [9] and re-
gression tasks [3]. In this previous work, the authors heuristically selected those
instances, which are likely to determine the support vectors and therefore the
SVM model. Another proposed approach for speeding up GP’s evaluation is to
use only a small random sample in every evaluation [5]. Kugler et al. [6] sug-
gested to aggregate similar instances together before training a neural network.
Grouping together instances should cancel out noise and shrink the data set,
which is similar to the initially mentioned idea.

This paper builds on the idea of Kugler et al. [6] and uses clustering al-
gorithms for aggregating and reducing training instances. The applied methods
are random sampling, data binning and k-means clustering. The new, aggregated
data are then used for training with diﬀerent machine learning algorithms, with
a focus on symbolic regression with GP. The trade-oﬀ between speed-up and
loss in prediction accuracy due to potential removal of information is analyzed.
We test how much we can reduce data so that we still can train accurate and
complex models.

2 Aggregation Methods

All three aggregation methods require a predeﬁned number of instances, which
should be generated out of the original data. The ﬁrst one, random sampling
without replacement, serves as lower baseline. It will show, how much data can
be removed without losing relevant information for modeling.

In data binning, the training data are aggregated based on the target variable.
Similar to a histogram, instances with target values in ﬁxed ranges are grouped
together into bins. The range is determined by the minimum/maximum of the
original target values and the predeﬁned number of bins. To reduce the instances
in a bin to one single instance, we use the median for all of the features. Binning
should provide an equal target value distribution and reduce noise and variance

Data Aggregation in Symbolic Regression

3

[6]. However, binning also implies a ”many-to-one mapping” between features
and target variable, which incurs a loss of information in cases where interactions
of features are relevant.

K-means clustering searches k cluster centroids that minimize the sum of the
Euclidean distance between each point and its closest centroid. In this work, the
calculated centroids are used as new training data, while in usual applications,
k-means is used as unsupervised learning algorithm to separate the data into k
groups. We deliberately consider both features and target values when aggregat-
ing the data because it is assumed that information about variable interactions
is retained in contrast to data binning. The most common algorithm for deter-
mining the centroids is the heuristic Lloyd’s algorithm [7], is infeasible for larger
data sets with high k, since its runtime complexity is linear to the number of
instances and k – especially when the goal is actually to speed up the overall
modeling process. For our experiments, we use the mini-bach k-means algorithm
[10], which reduces the runtime of the preprocessing from days to a few minutes
with comparable results.

3 Experimental Setup

This work focuses on the the eﬀect of the described aggregation methods on
symbolic regression with GP. We use the algorithm framework described by
Winkler [13], in which the prediction error of mathematical formulas in syntax
tree representation as individuals is minimized. The algorithm implementation
applies strict oﬀspring selection with gender-speciﬁc selection [1], a separate
numerical optimization of constants in the formula [5] and explicit linear scaling
[4]. Since we focus on the eﬀect of preprocessing on symbolic regression, we
use a standard parameter setting which has shown in our experience to provide
good results. GP’s maximum selection pressure was set to 100, the mutation
rate to 20% and the population size to 300. The trees are build with a grammar
of arithmetic and trigonometric symbols, as well as exponential and logarithm
functions. The tree size is limited at most 50 symbols and a maximum depth
of 30. The crossover operator is subtree swapping and mutation operators are
point mutation, tree shaking, changing single symbols and replacing/removing
branches [1]. We use for all experiments the HeuristicLab framework1 [11].

Random forests (RF) [2] and linear regression (LR) are run on the same data
sets in order to provide comparability of the achieved results. Linear regression
serves as a lower bound, as the resulting linear models have low complexity and
all relations in the data sets are nonlinear. Random forests are used as a rough
indicator, which accuracy values are achievable on diﬀerent data sets, as this
algorithm has shown to be both fast and often very accurate. The settings for
RF were set train 50 trees and sample from 30% of instances and 50% of features
for each tree.

This work uses four real-world data sets: The Chemical-I data set (711 train-
ing instances, 57 features) [12], the Tower data set [12] (3136 training instances,

1 https://dev.heuristiclab.com

4

Kammerer et al.

25 features), the SARCOS data set [8] (44 500 training instances, 21 features)and
the puma8NH data set (6144 training instances, 8 features) from the Delve repos-
itory2. The data sets are split into training and test data set according to the
cited papers. The data sets are normalized to a mean of zero and a standard
deviation of 1 in the training data, which is especially important for the k-means
algorithm, which uses the Euclidean distance.

To analyze the tradeoﬀ between accuracy and speed-up, the training data are
reduced stepwise, starting from a reduction to one percent up to 50 percent of
the original training data size. For each of these steps, ten reduced training data
sets are generated. The three machine learning algorithms are then run on each
of these reduced data sets. Figure 2 outline the estimation of the generalization
error, where we evaluate the trained models on the not-aggregated test data. The
generalization error is measured with Pearson’s R2 coeﬃcient, which describes
the correlation between actual target values predictions in the interval [0, 1].

Repeat ten times per reduction rate

Training
Data

Aggregation

New Training
Data

LR, GP, RF

Model

Test Data

R2 (Test)

Fig. 2. Experiment workﬂow of reducing data for each data set and reduction rate.

4 Results

Figure 3 shows, that the speed-up of k-means clustering and sampling is pro-
portional to the reduction rate – how much the data has been reduced relative
to the original size. This is expected, as GP spends most of its time evaluat-
ing individuals. The computational eﬀort of evaluations increases proportionally
with larger numbers of training instances, because every instance’s prediction
has to be calculated in every evaluation. However, the proportional speed-up
also indicates, that algorithm dynamics such as the earlier convergence due to
preprocessing can be ruled out. The runtime for the preprocessing step itself is
neglected, because it made up at most three minutes (for the large Sarcos data
set) per run, which is only a very small fraction of the runtime of GP. Figure
3 also excludes the runtime for RF and LR because both methods took only
seconds to ﬁnish in all experiments.

While data binning and k-means led to similar execution times, GP runs
with preceding data binning were slightly faster. This is most likely due to a loss

2 https://www.dcc.fc.up.pt/~ltorgo/Regression/puma.html

Data Aggregation in Symbolic Regression

5

Original

Sampling

K-Means

Binning

1d 04h

14h 00m

00h 00m

(b) Tower

(c) puma8NH

8d 16h

5d 19h

2d 21h

50

00h 00m

5

50

20

30

40
10
Reduction in %
(e) Sarcos

20

30

40
10
Reduction in %

(d) Chemical-I

i

e
m
T
n
o
i
t
u
c
e
x
E

i

e
m
T
n
o
i
t
u
c
e
x
E

16h 45m

11h 15m

05h 45m

00h 00m

03h 00m

01h 30m

00h 00m

5

Fig. 3. Median execution of GP for diﬀerent rates of reduction of the original data set.

of information about the relations in the data. Fewer relations in the training
data make the search for a model, which ﬁts the training data well, easier and
therefore faster although it degrades its test errors. Table 1 shows that data
binning yielded throughout worse models regarding test accuracy.

K-means clustering and random sampling produced very similar results, as
listed in Table 1. In both cases, the loss in prediction accuracy is small when
the data is reduced to 30%, 40% or 50% of the original data in comparison to
runs with the original data. The only diﬀerence is the more stable behavior of
k-means preprocessing when the training data is reduced to a size of 20% or less
of the original data set size. The small diﬀerence between preprocessing with
k-means and data binning can be explained with the small number of instances,
with which each centroid is computed – e.g. if the training data is reduced to
50%, each centroid is the center of only two similar instances on average. This
leaves little space for improvements over random sampling. However, all methods
failed to yield meaningful models when the training data are reduced to only 1%
of their original size.

When compared to RF and LR, GP achieves in most experiments similar
accuracy as random forests. However, when the data is strongly reduced to only
30% or less of the original data, GP tends to have less loss in test accuracy
than RF. Figure 4 describes the median R2 results of all three algorithms with
diﬀerently reduced data for each data set. Modeling results on the original data

6

Kammerer et al.

Table 1. Test R2 median and interquartile range for symbolic regression with GP.

Original
Sampling

K-Means

Binning

Chemical-I
.863 (.02)
.002 (.00)
.431 (.36)
.396 (.36)
.728 (.21)
.787 (.08)
.836 (.01)
.834 (.02)
.018 (.04)
.523 (.15)
.704 (.13)
.806 (.06)
.828 (.03)
.853 (.04)
.848 (.02)
.009 (.01)
.253 (.30)
.345 (.21)
.578 (.13)
.673 (.05)
.699 (.05)
.718 (.08)

Sarcos
.949 (.00)
.928 (.01)
.946 (.00)
.947 (.00)
.948 (.00)
.948 (.00)
.947 (.00)
.949 (.00)
.943 (.01)
.948 (.00)
.948 (.00)
.948 (.00)
.948 (.00)
.948 (.00)
.947 (.00)
.504 (.45)
.866 (.01)
.893 (.01)
.892 (.01)
.899 (.01)
.898 (.01)
.897 (.01)

Tower
.937 (.01)
.390 (.31)
.907 (.02)
.919 (.02)
.925 (.01)
.933 (.00)
.934 (.01)
.936 (.00)
.729 (.14)
.918 (.01)
.926 (.00)
.933 (.01)
.932 (.00)
.932 (.00)
.931 (.00)
.378 (.37)
.313 (.35)
.700 (.27)
.806 (.05)
.853 (.03)
.872 (.05)
.883 (.02)

puma8NH
.684 (.00)
.369 (.06)
.572 (.04)
.632 (.02)
.657 (.00)
.668 (.01)
.675 (.01)
.677 (.01)
.480 (.11)
.596 (.07)
.596 (.09)
.656 (.05)
.665 (.01)
.672 (.01)
.680 (.00)
.021 (.03)
.189 (.31)
.532 (.05)
.530 (.07)
.576 (.05)
.630 (.03)
.648 (.01)

1
5
10
20
30
40
50
1
5
10
20
30
40
50
1
5
10
20
30
40
50

set are shown on the left. The results for data, that was reduced to 1%, as well
as the binning results are not shown in Figure 4 since they would degrade the
axis scale.

5 Conclusion

The experimental results show, that the original training data can be reduced
to only 30% of the original size while still achieving only slightly worse test
accuracy. While data binning led to unusable models regarding test accuracy,
there is no noticeable diﬀerence in the resulting modeling accuracy between k-
means and random sampling. Depending on the actual application, whether a
higher loss in accuracy is acceptable, k-means might only be useful if the data is
reduced to 5-20%, as less variance among test errors compared to random sam-
pling was observed in this range. Otherwise, it is more convenient to use random
sampling instead of the additional eﬀort of implementing k-means clustering in
the modeling process. The impact of data reduction was smaller for GP than for
RF, which underlines the stability and the generalization capabilities of symbolic
regression.

Data Aggregation in Symbolic Regression

7

RF Test
Training

GP Test
Training

Orig.

1.0

Sampling

LR Test
Training

K-Means

0.9

2
R

0.8

1.0

0.8

0.6

0.4

2
R

1.00

0.75

2
R

0.50

0.25

0.00

1.000

0.975

2
R

0.950

0.925

0.900

Orig.

5

(a) Tower

(b) puma8NH

(c) Chemical-I

30

20

10
40
Reduction in %

50

5

30

20

10
40
Reduction in %

50

(d) Sarcos

Fig. 4. Median R2 values of the generated models.

8

Kammerer et al.

The speed-up for GP is proportional to the data reduction ratio, how much
the original data was reduced to. While the proposed reduction methods might
not be suitable for a ﬁnal model in most applications due to the (even slight)
loss in accuracy, random sampling as preprocessing step might be a suitable tool
for speeding up early experimental phases and meta parameter tuning.

Acknowledgements. The authors gratefully acknowledge support by the Aus-
trian Research Promotion Agency (FFG) within project #867202, as well as the
Christian Doppler Research Association and the Federal Ministry of Digital and
Economic Aﬀairs within the Josef Ressel Centre for Symbolic Regression

References

1. Aﬀenzeller, M., Winkler, S., Wagner, S., Beham, A.: Genetic Algorithms and Ge-
netic Programming - Modern Concepts and Practical Applications, Numerical In-
sights, vol. 6. CRC Press, Chapman & Hall (2009)

2. Breiman, L.: Random forests. Machine learning 45(1), 5–32 (2001)
3. Guo, G., Zhang, J.S.: Reducing examples to accelerate support vector regression.

Pattern Recognition Letters 28(16), 2173–2183 (2007)

4. Keijzer, M.: Scaled symbolic regression. Genetic Programming and Evolvable Ma-

chines 5(3), 259–269 (2004)

5. Kommenda, M., Kronberger, G., Aﬀenzeller, M., Winkler, S., Feilmayr, C., Wag-
ner, S.: Symbolic regression with sampling. In: 22nd European Modeling and Sim-
ulation Symposium EMSS. pp. 13–18 (2010)

6. Kugler, C., Hochrein, T., Dietl, K., Heidemeyer, P., Bastian, M.: Softsensoren
in der Kunststoﬀverarbeitung: Qualit¨atssicherung f¨ur die Compoundierung und
Extrusion. SKZ - Forschung und Entwicklung, Shaker Verlag GmbH (2015)

7. Lloyd, S.: Least squares quantization in pcm. IEEE transactions on Information

Theory 28(2), 129–137 (1982)

8. Pagie, L., Hogeweg, P.: Evolutionary consequences of coevolving targets. Evolu-

tionary computation 5(4), 401–418 (1997)

9. Rychetsky, M., Ortmann, S., Ullmann, M., Glesner, M.: Accelerated training of
support vector machines. In: IJCNN’99. International Joint Conference on Neural
Networks. Proceedings (Cat. No. 99CH36339). vol. 2, pp. 998–1003. IEEE (1999)
10. Sculley, D.: Web-scale k-means clustering. In: Proceedings of the 19th international

conference on World wide web. pp. 1177–1178. ACM (2010)

11. Wagner, S., Aﬀenzeller, M.: Heuristiclab: A generic and extensible optimization
environment. In: Adaptive and Natural Computing Algorithms, pp. 538–541.
Springer (2005)

12. White, D.R., McDermott, J., Castelli, M., Manzoni, L., Goldman, B.W., Kron-
berger, G., Ja´skowski, W., O’Reilly, U.M., Luke, S.: Better gp benchmarks: commu-
nity survey results and proposals. Genetic Programming and Evolvable Machines
14(1), 3–29 (2013)

13. Winkler, S.: Evolutionary System Identiﬁcation: Modern Concepts and Practical
Applications. Schriften der Johannes Kepler Universit¨at Linz, Universit¨atsverlag
Rudolf Trauner (2009)

