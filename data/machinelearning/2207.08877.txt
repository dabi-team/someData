2
2
0
2

l
u
J

8
1

]

G
L
.
s
c
[

1
v
7
7
8
8
0
.
7
0
2
2
:
v
i
X
r
a

Prior Knowledge Guided Unsupervised Domain
Adaptation

Tao Sun1, Cheng Lu2, and Haibin Ling1

1Stony Brook University

2XPeng Motors

{tao,hling}@cs.stonybrook.edu, luc@xiaopeng.com

Abstract. The waive of labels in the target domain makes Unsupervised
Domain Adaptation (UDA) an attractive technique in many real-world
applications, though it also brings great challenges as model adaptation
becomes harder without labeled target data. In this paper, we address
this issue by seeking compensation from target domain prior knowledge,
which is often (partially) available in practice, e.g., from human exper-
tise. This leads to a novel yet practical setting where in addition to
the training data, some prior knowledge about the target class distri-
bution are available. We term the setting as Knowledge-guided Unsu-
pervised Domain Adaptation (KUDA). In particular, we consider two
specific types of prior knowledge about the class distribution in the tar-
get domain: Unary Bound that describes the lower and upper bounds of
individual class probabilities, and Binary Relationship that describes the
relations between two class probabilities. We propose a general rectifi-
cation module that uses such prior knowledge to refine model generated
pseudo labels. The module is formulated as a Zero-One Programming
problem derived from the prior knowledge and a smooth regularizer. It
can be easily plugged into self-training based UDA methods, and we
combine it with two state-of-the-art methods, SHOT and DINE. Em-
pirical results on four benchmarks confirm that the rectification module
clearly improves the quality of pseudo labels, which in turn benefits the
self-training stage. With the guidance from prior knowledge, the perfor-
mances of both methods are substantially boosted. We expect our work
to inspire further investigations in integrating prior knowledge in UDA.
Code is available at https://github.com/tsun/KUDA.

Keywords: Unsupervised Domain Adaptation, Class Prior

1

Introduction

Deep neural networks have shown significant performance improvement in a va-
riety of vision tasks [8,30,23,12]. However, such performance highly relies on
massive annotated data, which is often expensive to obtain. Unsupervised Do-
main Adaptation (UDA) addresses this issue by transferring a predictive model
learned from a labeled source domain to an unlabeled target domain [25,38,40].
Despite the advancement made in recent years, UDA remains a challenging task
due to the absence of labels in the target domain. On the other hand, in many

 
 
 
 
 
 
2

Sun et al.

Fig. 1. (Left) Knowledge-guided Unsupervised Domain Adaptation (KUDA). In addi-
tion to target data, some prior knowledge about target class distribution is available.
(Right) two types of prior knowledge considered in the paper.

real-world applications, prior knowledge about the target domain is often readily
available. In particular, some information about class distribution is often avail-
able without bothering labeling specific target samples. For example, botanists
can estimate the proportion of wild species within a reserve using historical infor-
mation; economists can tell whether vans are more possessed than other vehicles
based on the local industrial structure; etc. Such prior knowledge may provide
valuable clues that are complementary to the unlabeled training data, and can be
especially beneficial when there exists a large distribution shift between source
and target domains. In fact, prior knowledge has been used to compensate the
deficiency of labeled data [33,14], but its systematical integration into UDA so-
lutions remains under-explored.

Inspired by the above observation, in this paper we study a novel setting of
UDA, named Knowledge-guided Unsupervised Domain Adaptation (KUDA), as
illustrated in Fig. 1. Specifically, in addition to target training samples Dt, a
collection of prior knowledge K on target class distribution pt(y) is accessible.
In particular, we consider two types of prior knowledge: Unary Bound that de-
scribes the lower and upper bounds of individual class probability p(c)
(e.g., the
probability of ‚Äúsquare‚Äù is between 0.1 and 0.3), and Binary Relationship that
describes the relations between probabilities of two classes, p(c1)
(e.g.,
there are more ‚Äútriangles‚Äù than ‚Äúsquares‚Äù). The task of KUDA is to adapt a
predictive model learned from a source domain to a target domain under the
guidance from such prior knowledge. It is worth mentioning that there can be
many other types of prior knowledge which may help to improve UDA perfor-
mance, and we choose unary and binary statistics over the class distribution for
their generality and accessibility in practice.

and p(c2)

t

t

t

Prior knowledgeSourceTargetUnlabeled dataHypothesisOpen APILabeled dataTarget data ùíütPrior knowledge ùí¶Unary BoundBinary Relationshiphuman expertise,          historical observation,relevant data,‚Ä¶ ùëùùë°(ùëñ)‚àíùëùùë°(ùëó)‚â•ùõø(ùëñ,ùëó)ùúà(ùëó)‚â§ùëùùë°(ùëó)‚â§ùúá(ùëó)Prior Knowledge Guided Unsupervised Domain Adaptation

3

To incorporate the prior knowledge into domain adaptation, we propose a
novel rectification module to refine model generated pseudo labels. We formulate
the rectification procedure using prior knowledge as a Zero-One Programming
(ZOP) [41] problem, where its optimal solution returns the updated pseudo
labels. Moreover, smooth regularization is applied to maintain consistency of
pseudo labels in neighboring samples. This module can be easily integrated into
self-training-based UDA methods. To validate its effectiveness, we choose two
recent state-of-the-art UDA methods, SHOT [18] and DINE [19], and improve
them with the rectification module.

The experimental validation is conducted on four commonly used UDA bench-
marks, two of which have a large label distribution shift by design. The results
confirm that the rectification module improves the quality of pseudo labels and
hence benefits the self-training stage. Consequently, the performances of two
methods under the guidance of prior knowledge, named respectively kSHOT
and kDINE, are substantially boosted compared with the vanilla versions. Our
work demonstrates that it is important to consider target class prior knowledge,
especially when the domain gap is large.

In summary, we make the following contributions:

‚Äì We study a novel and practical setting of Knowledge-guided Unsupervised
Domain Adaptation (KUDA), where prior knowledge about target class dis-
tribution available in addition to unlabeled training samples.

‚Äì We introduce a general rectification module that refines pseudo labels with
the guidance from prior knowledge. It can be easily plugged into self-training
based UDA methods.

‚Äì Extensive experiments on both standard and label-shifted benchmarks val-
idate that incorporating prior knowledge can significantly boost the perfor-
mance of adapted models, reducing the reliance on target training data.

2 Related Work

Incorporating Prior Knowledge. There has been a long history of incorporat-
ing prior knowledge into machine learning tasks. Using prior knowledge removes
or reduces the reliance on training data. The knowledge can be expressed in var-
ious forms, such as statistical descriptions from other data or human expertise,
inductive biases, physical models, etc. The most related one to our work is target
prior, where the distribution of target variable p(y) is known [33,14]. In [24], the
class distribution prior conditioned on certain inputs is captured by generalized
expectation. Zhu et al. [46] employ class priors to set thresholds on the propa-
gation of labels. Wang et al. [39] assume that a parametric target prior model
pŒ∑(y) can be obtained from relevant subjects yet having no correspondence with
training data. Inductive biases have been widely used in deep neural networks.
A canonical one is translation equivariance through convolutions [10,37,13]. Lin
et al. [20] add geometric priors based on Hough transform in line detection.
Physical models of image formation have been integrated into the tasks of image
decomposition [1], rain image restoration [17], day-night adaptation [15], etc.

4

Sun et al.

Domain Adaptation Settings. Domain Adaptation (DA) presents under many
different settings. In the vanilla Unsupervised Domain Adaptation (UDA) [45,29,3,35],
only labeled data from a source domain and unlabeled data from a target domain
are available. Since no labeled target data is available, UDA can be a challeng-
ing task when the domain gap is large. Semi-supervised DA (SSDA) [32,11,16]
assumes a few labeled target data is available, which often greatly boosts per-
formance compared with UDA. Active DA [5,28,42] further selects the most
informative samples to query their labels from the oracle. Then human-defined
criteria like uncertainty and diversity can be injected to measure the informative-
ness of samples. SSDA and Active DA can be viewed as incorporating additional
instance-level label information compared with UDA. Another line is to reduce
the information released by source domain, usually due to some privacy issues.
Source-data free UDA [18,9,4,2] assumes only a trained model is offered by the
source domain while source data are inaccessible. To conceal model details, the
black-box source model [21,43,19] is further studied.
Our study. Our proposed KUDA methods incorporate class distribution-level
information and is complementary to all of the above-mentioned settings. It is
the first work along this direction, and we expect to see further studies to explore
richer prior knowledge for UDA or to extend the idea to general DA scenarios.

3 Knowledge-guided UDA

i )}ns‚àí1

i , ys
i)}nt‚àí1
i=0

Preliminaries. In this paper, we focus on C-way classification problem for UDA
tasks. We use X and C = {0, 1, . . . , C ‚àí 1} to denote the input space and the
label space respectively. In a vanilla UDA task, we are given labeled samples
Ds = {(xs
from a source domain PS(X , C), and unlabeled samples
i=0
Dt = {(xt
from a target domain PT (X , C). The goal of UDA is to learn a
labeling function ft = ht ‚ó¶ gt : X ‚Üí C for target domain, where gt is the feature
extractor and ht is the label predictor.
Prior Knowledge of Target Class Distribution. The class distribution of
target domain, pt(y), is an important quantity while inaccessible in UDA. One
way is to estimate it from model predictions on unlabeled target data [22]. How-
ever, this can often be unreliable when the domain gap is large. The deficiency
of labeled target samples can be compensated with prior knowledge, e.g., from
human expertise. In fact, it is often possible to obtain some information about
class distribution without bothering labeling specific target samples in real-world
applications. Table 1 lists two types of prior knowledge considered in this paper.
Unary Bound describes the lower and upper bounds of individual class probabil-
ity p(c)
, and Binary Relationship describes the relations between probabilities of
two classes, p(c1)
. Both statistics over the class distribution are general
and easy to obtain in practice. Other types of prior knowledge beyond these can
be similarly defined in terms of three or more probabilities.
Setting of KUDA. We study a novel and realistic setting termed Knowledge-
guided Unsupervised Domain Adaptation (KUDA). In KUDA, in addi-
tion to Ds and Dt, we have access to some prior knowledge K about the target

and p(c2)

t

t

t

Prior Knowledge Guided Unsupervised Domain Adaptation

5

Table 1. Two types of prior knowledge considered in the paper.

Knowledge Type

Formulation

Unary Bound (UB)

Binary Relationship (BR)

K =

K =

(cid:110)(cid:16)

(cid:110)(cid:16)

ŒΩ(c) ‚â§ p(c)
p(c1)
t ‚àí p(c2)

t ‚â§ ¬µ(c)(cid:17)(cid:12)
(cid:12)
(cid:12)c ‚àà C
t ‚â• Œ¥(c1,c2)(cid:17)(cid:12)
(cid:12)
(cid:12)c1, c2 ‚àà C

(cid:111)

(cid:111)

class distribution pc
t . Such prior knowledge may provide valuable clues that are
complementary to the unlabeled training data, and can be especially beneficial
when there exists a large distribution shift between source and target domains.
In particular, we assume that K can be expressed in a collection of inequality
constraints as listed in Tab. 1. The goal is to learn an optimal target labeling
function ft under the guidance from the prior knowledge K.

4 Method

4.1 Rectify Pseudo Labels with Prior Knowledge

Let us consider a general situation. Suppose we have a model predicted class
probability matrix P ‚àà Rnt√óC of target data. The pseudo label of the i-th
sample can be obtained via ÀÜyt
i = arg max pi, where pi is the i-th row of P . This
procedure can be equivalently expressed in a more compact form using one-hot
label representation li and its matrix form L (i.e., li is the i-th row of L)

ÀÜL = arg max

‚ü®L, P ‚ü©,

s.t.

L

Ô£±
Ô£≤

(cid:80)

c Li,c = 1, ‚àÄi ‚àà [nt]

Ô£≥

Li,c ‚àà {0, 1}, ‚àÄc ‚àà C, i ‚àà [nt]

(1)

i

where ‚ü®¬∑, ¬∑‚ü© is the inner product of two matrices, and [nt] ‚âú {0, 1, . . . , nt ‚àí 1}.
For the optimal solution ÀÜL of Eq. 1, ÀÜLi,ÀÜyt

= 1 and ÀÜLi,c = 0 ‚àÄc Ã∏= ÀÜyt
i .

t

Without any prior knowledge, the optimal li is assigned independently for
each target sample. The empirical class probability ÀÜp(c)
i Li,c/nt is expected
to be close to p(c)
. However, this is often violated when the model predictions
are noisy. When the prior knowledge K about pt is available, we can use it to
rectify pseudo labels so that ÀÜpt is more compliant with pt.
Hard constraint form. Given the inequalities listed in Tab. 1, we plug in ÀÜpt and
add the constraints to the optimization problem in Eq. 1. Then the optimization
problem in hard constraint form can be formulated as:

t = (cid:80)

‚Äì Unary Bound.

ÀÜL = arg max

‚ü®L, P ‚ü©,

s.t.

L

Ô£±

Ô£¥Ô£¥Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥Ô£¥Ô£¥Ô£≥

(cid:80)

c Li,c = 1 ‚àÄi ‚àà [nt]

Li,c ‚àà {0, 1},
(cid:80)
‚àí (cid:80)

i Li,c ‚â• ntŒΩ(c),

i Li,c ‚â• ‚àínt¬µ(c),

‚àÄc ‚àà C, i ‚àà [nt]

‚àÄc ‚àà C

‚àÄc ‚àà C

(2)

6

Sun et al.

‚Äì Binary Relationship.

ÀÜL = arg max

‚ü®L, P ‚ü©, s.t.

L

Ô£±
Ô£¥Ô£≤

Ô£¥Ô£≥

(cid:80)

c Li,c = 1 ‚àÄi ‚àà [nt]

Li,c ‚àà {0, 1},
(cid:80)

‚àÄc ‚àà C, i ‚àà [nt]
i (Li,c1 ‚àí Li,c2) ‚â• ntŒ¥(c1,c2),

(3)

‚àÄc1, c2 ‚àà C

Eq. 2 and Eq. 3 are Zero-One Programming problems [41], and can be solved with
standard solvers [7]. However, using hard constraint form is not favored. When
these constraints are inconsistent, the optimization problem becomes infeasible.
Soft constraint form. To overcome the drawbacks of hard constraint form, we
convert prior knowledge into soft constraints by introducing slack variables:

)

‚àÄc ‚àà C

‚àÄc ‚àà C

(4)

(5)

‚Äì Unary Bound.

ÀÜL = arg max

‚ü®L, P ‚ü© ‚àí M

(cid:88)

(Œæ(ŒΩ)

c + Œæ(¬µ)

c

s.t.

Ô£±

Ô£¥Ô£¥Ô£¥Ô£¥Ô£≤
Ô£¥Ô£¥Ô£¥Ô£¥Ô£≥

L

(cid:80)

c
c Li,c = 1 ‚àÄi ‚àà [nt]

‚àÄc ‚àà C, i ‚àà [nt]

Li,c ‚àà {0, 1},
c = max (cid:0)0, ‚àí (cid:80)
Œæ(ŒΩ)
c = max (cid:0)0, (cid:80)
Œæ(¬µ)

i Li,c + ntŒΩ(c)(cid:1) ,

i Li,c ‚àí nt¬µ(c)(cid:1) ,

‚Äì Binary Relationship.

ÀÜL = arg max

‚ü®L, P ‚ü© ‚àí M

L

(cid:88)

c1,c2

Œæc1,c2

(cid:80)

c Li,c = 1 ‚àÄi ‚àà [nt]

s.t.

Ô£±
Ô£¥Ô£≤

Ô£¥Ô£≥

Li,c ‚àà {0, 1},
Œæc1,c2 = max (0, ‚àí (cid:80)

‚àÄc ‚àà C, i ‚àà [nt]

i(Li,c1 ‚àí Li,c2 ) + ntŒ¥(c1,c2)),

‚àÄc1, c2 ‚àà C

In both Eq. 4 and Eq. 5, M is a pre-defined non-negative constant. When
M is large enough, their solutions will be the same as those of Eq. 2 and Eq. 3
respectively, providing the hard constraints from prior knowledge are satisfiable.
When M = 0, Eq. 4 and Eq. 5 will degenerate to the vanilla problem in Eq. 1.
Smooth regularization. Previous optimization problems utilize prior knowl-
edge about class distribution to refine pseudo labels. However, this solely relies
on the model predicted probability matrix P without considering the data dis-
tribution in the feature space. In classification tasks, it is expected that the label
prediction is locally smoothed. Hence, we add a smooth regularization that en-
forces the pseudo label of neighboring samples to be consistent.

i ‚àà St, let its nearest neighbor in Dt \ St be xt

We select a subset of target samples St ‚äÜ Dt whose model predictions are
uncertain. For each xt
ki. The
smooth regularization is a collection of equality constraints, R = {(li = lki)|xt
i ‚àà
St}. Converting these equalities into soft constraints is non-trivial as it will
bring second-order terms in the objective. Instead, we directly add them as hard
constraints to the optimization problem in Eq. 4 and Eq. 5.

Prior Knowledge Guided Unsupervised Domain Adaptation

7

Fig. 2. Illustration of how our proposed rectification module is integrated into SHOT
and DINE to get knowledge-guided SHOT and DINE. This can be easily extended to
other self-training based UDA methods in a similar manner.

4.2 Knowledge-guided UDA Methods

Our proposed rectification module is general, and can be easily plugged into self-
training based UDA methods. To validate its effectiveness, we choose two recent
UDA algorithms, SHOT [18] and DINE [19]. This leads to knowledge-guided
SHOT and DINE, dubbed as kSHOT and kDINE, respectively. The frameworks
are illustrated in Fig. 2. It should be noted that the main purpose of this part
is to demonstrate the benefits of considering class prior knowledge through our
rectification module, rather than simply extending the two algorithms.
Knowledge-guide SHOT. SHOT [18] is a state-of-the-art self-training based
UDA method. It assumes a source-data free setting, i.e., only the source hypothe-
sis is available during adaptation. Then both self-supervised pseudo-labeling and
mutual information maximization are exploited to fine-tune the feature extrac-
tor module of the source hypothesis. Since only target samples are involved, it
provides us a convenient platform to observe how prior knowledge affects the
performance of adapted models. The full objective is

i,ÀÜyt

i), ÀÜyt

i ) ‚àí Œ±Lim

Lshot = E(xt

i )‚Ñìce(ht ‚ó¶ gt(xt
where ‚Ñìce is the cross entropy loss, Lim is the Information Maximization loss [6,34],
and Œ± is a hyper-parameter. A critical step is to obtain the pseudo label ÀÜyt
i . SHOT
uses the distances between samples and class centroids in the feature space to re-
fine model predictions. While this improves the quality of pseudo labels to some
extent, their empirical distribution could still be very different from the ground-
truth, as shown in Fig. 5. We show how prior knowledge can be incorporated to
alleviate this issue.

(6)

We plug the rectification module into SHOT. After obtaining pseudo labels
L(shot) (i.e., the one-hot representation of ÀÜyt) and feature-to-centroid distances

Source hypothesisTarget dataPseudo labelrectification modulekSHOTkDINESource API serviceTarget dataSelf-supervisedpseudo-labeling Cross-entropy lossAdaptive label smoothing (teacher)Self-distillation loss8

Sun et al.

from SHOT, we convert the distances into class probabilities using softmax as

P = softmax(‚àíD)

(7)

where D ‚àà Rnt√óC, Di,k = df (gt(xt
the k-th class centroid.

i), ck), df is some distance metric and ck is

Let the optimal solution of the Zero-One Programming in Eq. 4 and Eq. 5

under prior knowledge K and smooth regularization R be

L‚àó = S(P, K, R)

(8)

i

i|l(shot)

Ã∏= l(pk0)
i

S(P, ‚àÖ, ‚àÖ) returns exactly the same pseudo labels as L(shot). Given prior knowl-
edge K, we first obtain L(pk0) = S(P, K, ‚àÖ). Then we create a subset St =
{xt
} that consists of all samples whose pseudo label changed.
After that the smooth regularization R can be constructed using St. Finally, we
obtain L(pk1) = S(P, K, R) and use L(pk1) as ÀÜyt to update model with Eq. 6.
Knowledge-guide DINE. DINE [19] is a very recent algorithm that assumes
only black-box source models (e.g., source API service) are available during adap-
tation. It first distills knowledge from the source predictor to a target model,
and then fine-tunes the distilled model with target data. Two kinds of structural
regularization, including interpolation consistency training [44] and mutual in-
formation maximization [34], are applied. The objective is

Ldine = Ext

i

Dkl

(cid:0)P tch(xt

i)‚à•ft(xt

i)(cid:1) + Œ≤Lmix ‚àí Lim

(9)

where Dkl denotes the Kullback-Leibler divergence, Lmix and Lim are two regu-
larizers, and Œ≤ is a trade-off parameter. To obtain the teacher prediction P tch(xt
i),
the authors propose to revise the predictions of source model with adaptive label
smoothing, and maintain an exponential moving average (EMA) prediction.

Given prior knowledge K, we aim to rectify the teacher prediction P tch(xt
i)
to be more compliant with the ground-truth. We adopt a similar strategy as in
kSHOT. The pseudo labels of DINE are obtained by ÀÜy(dine)
i).
Let the corresponding one-hot representation be l(dine)
i) as
the i-th row of P , and obtain L(pk0) = S(P, K, ‚àÖ). Then we create a subset
S t = {xt
} to construct the smooth regularization R. Finally, we
obtain L(pk1) = S(P, K, R). The new objective function is

. We take P tch(xt

= arg max P tch(xt

Ã∏= l(pk0)
i

i|l(dine)

i

i

i

(cid:32)

Lkdine = Ext

i

Dkl

P tch(xt

i) + Àúl(pk1)
2

i

(cid:33)

(cid:13)
(cid:13)
ft(xt
(cid:13)
i)
(cid:13)
(cid:13)

+ Œ≤Lmix ‚àí Lim

(10)

where Àúl(pk1)

i

= 0.9 ¬∑ l(pk1)

i

+ 0.1/C is the smoothed label.

5 Experiments

5.1 Experimental Setup

Datasets. We report our results on both standard UDA benchmarks and bench-
marks designed with label distribution shift. Office-Home is an image classi-
fication dataset with 65 classes from four environments: Artistic (A), Clip Art

Prior Knowledge Guided Unsupervised Domain Adaptation

9

Table 2. Classification accuracies (%) on Office-Home RS-UT and Office.

Method K œÉ

SHOT ‚Äì

‚Äì

R

P R

Office-Home RS-UT
R C
C P

C C

R P

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

77.0 50.3 75.9 47.0 64.3 64.6 63.2 94.0 90.1 74.7 98.4 74.3 99.9 88.6

P Avg. A

DA

WD

AD

WW

AW

DAvg.

Office

T
O
H
S
k

UB 0.0 78.8 51.3 79.1 49.8 71.3 69.7 66.6 97.6 98.5 75.0 99.0 76.2 99.8 91.0
UB 0.1 78.3 51.7 79.0 48.6 71.6 69.4 66.4 96.7 97.2 75.5 98.7 76.5 99.8 90.7
UB 0.5 76.7 50.6 77.3 48.4 68.4 67.3 64.8 93.9 92.8 75.7 97.7 75.2 99.7 89.2
UB 1.0 76.3 50.0 76.9 48.4 66.7 65.8 64.0 93.7 92.4 75.5 97.7 75.5 99.7 89.1
UB 2.0 76.4 50.0 76.0 47.9 65.3 64.1 63.3 93.7 92.4 75.0 97.7 75.2 99.7 89.0
78.6 51.6 78.7 49.3 70.1 68.8 66.2 96.9 97.1 74.0 98.8 76.1 99.8 90.5
BR ‚Äì

(C), Product (P), and Real-world (R). Office [31] contains 31 classes of of-
fice objects from three domains: Amazon (A), DSLR (D) and Webcam (W).
VisDA-2017 [27] is a large-scale Synthetic-to-Real dataset with 12 categories
of objects. Office-Home RS-UT [36] is a subset of Office-Home created with
Reverse-unbalanced Source and Unbalanced Target manner. Both source and
target label distributions are long-tailed. The majority classes in source domain
are minority ones in target domain. Hence, it has a big label distribution shift.
DomainNet [26] is a large UDA benchmark. We use the subset [36] of 40-
commonly seen classes from four domains: Clipart (C), Painting (P), Real (R),
Sketch (S). It has a natural label distribution shift.
Creating prior knowledge. We create prior knowledge from ground-truth
labels of target training data, {yt
i=0 , for experimental purposes only. The
noisiness and completeness of the prior knowledge are discussed in Sec. 5.3. Let
qc = (cid:80)
i = c]/nt be the empirical probability of the c-th class.

i }nt‚àí1

I[yt

i

‚Äì Unary Bound. We create UB as (cid:8)(qc ¬∑ (1 ‚àí œÉ) ‚â§ p(c)

t ‚â§ qc ¬∑ (1 + œÉ))|c ‚àà C(cid:9),
where œÉ is hyper-parameter controlling the tightness of the bounds. In the
experiments, we choose œÉ ‚àà {0.0, 0.1, 0.5, 1.0, 2.0}.

‚Äì Binary Relationship. We first sort all classes based on qc in descending
0, cq
order. Assuming the corresponding indexes are [cq
C‚àí1]. Then we
(cq
create BR as (cid:8)(p(cq
‚â• 0)|i ‚àà {0, 1, ¬∑ ¬∑ ¬∑ , C ‚àí 2}(cid:9). We simply take
i )
t ‚àí p
t
the right hand to be 0, which makes them relatively loose constraints and
more easily available in practice.

1, ¬∑ ¬∑ ¬∑ , cq

i+1)

Implementation details. We solve the optimization problem of the rectifi-
cation module with Gurobi Optimizer [7]. Both kSHOT and kDINE are based
on the official Pytorch implementations by the authors. We use a pretrained
ResNet-101 [8] backbone for VisDA-2017, and ResNet-50 [8] for others. To fairly
compare with SHOT and DINE, we adopt the same hyper-parameters as used in
the original papers. We run every task for 3 times and report the mean evaluation
values. For standard UDA benchmarks, we report the accuracy. For benchmarks
with label distribution shift (i.e., Office-Home RS-UT and DomainNet), we re-
port per-class average accuracy, in consistent with previous works [36,29].

10

Sun et al.

Table 3. Classification accuracies (%) on Office-Home and VisDA-2017.

Method K œÉ

SHOT ‚Äì

‚Äì

A

C A

P A

R C

A C

P C

R P

A P

C P

R R

A R

C R

P Avg.

(cid:1)

(cid:1)
57.1 78.1 81.5 68.0 78.2 78.1 67.4 54.9 82.2 73.3 58.8 84.3 71.8

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

Office-Home

VisDA

82.9

T
O
H
S
k

UB 0.0 58.2 80.0 82.9 71.1 80.3 80.7 71.3 56.8 83.2 75.5 60.3 86.6 73.9 86.1
85.8
UB 0.1 58.1 79.2 83.2 70.4 80.0 80.7 71.4 56.5 83.0 75.6 60.8 86.0 73.7
UB 0.5 57.4 79.1 82.1 69.4 78.1 79.5 69.3 55.2 81.8 74.0 60.2 85.1 72.6
83.9
83.0
UB 1.0 57.0 79.0 82.1 68.6 77.8 79.3 68.4 55.1 81.7 73.5 59.3 84.8 72.2
UB 2.0 56.4 78.7 82.1 68.3 77.8 79.3 67.9 54.2 81.7 73.3 58.7 84.8 71.9
82.6
83.6
57.4 78.8 82.9 70.7 80.0 80.5 70.8 55.0 82.8 74.6 59.9 86.0 73.3
BR ‚Äì

Table 4. Classification accuracies (%) on DomainNet.

Method K œÉ R

C R

P R

S C

R C

P C

S P

R P

C P

S S

R S

C S

P Avg.

SHOT

‚Äì

‚Äì

(cid:1)

(cid:1)
79.4 75.4 72.8 88.4 74.0 75.5 89.8 77.7 76.2 88.3 80.5 70.8 79.1

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

T
O
H
S
k

UB 0 83.6 77.5 75.3 91.5 76.4 77.0 91.7 82.3 76.3 89.7 80.2 70.3 81.0
UB 0.1 82.2 77.6 75.2 89.5 76.8 76.9 91.2 81.7 76.9 88.5 79.4 70.1 80.5
UB 0.5 80.3 77.2 73.5 88.8 75.4 75.6 89.0 78.4 76.6 88.3 78.9 70.4 79.4
UB 1.0 79.9 76.8 72.9 88.8 73.7 75.3 88.6 77.6 76.4 88.0 80.0 69.9 79.0
UB 2.0 79.2 76.3 73.1 88.8 75.4 75.5 88.6 77.8 76.2 87.9 80.1 71.1 79.2
82.1 76.8 74.3 89.1 73.7 76.4 91.7 80.6 75.9 88.8 79.1 70.2 79.9
BR ‚Äì

5.2 Results

Results of kSHOT. Tables 2,4 list results of kSHOT on two benchmarks with
label distribution shift. In UB(œÉ = 0), it improves the accuracy by +3.4% on
Office-Home RS-UT and +1.9% on DomainNet. As œÉ grows, the prior knowledge
becomes less informative, and consequently the improvements reduce. Interest-
ingly in BR where only the relative order of class probabilities is known, it still
improves +3.0% on Office-Home RS-UT. Since this dataset is manually created
to be long-tailed, and class distributions of two domains are reversed version
of each other, having prior knowledge about target class distribution would be
very helpful. This conforms to our experimental results. Results on three stan-
dard benchmarks are listed in Tables 2,3. Using prior knowledge consistently
improves on them. Similar trends on œÉ can be observed. Compared with previ-
ous benchmarks, the phenomenon of label distribution shift is less severe. Still
prior knowledge can be helpful to correct mistaken pseudo labels during training.
Results of kDINE. Since using vanilla label smoothing is sub-optimal to the
adaptive label smoothing used in DINE [19], the true performance gain from
prior knowledge could be reduced. To make a fair comparison, we also provide
results when replacing l(pk1)
in Eq. 10, and term it as DINE‚àó. As
i
can be seen in Tables 6,7, DINE‚àó indeed performs worse than DINE. Neverthe-
less, incorporated with prior knowledge, kDINE achieves much higher accuracy,
and even better performance than DINE.
Results for PDA. We further evaluate on Office-Home for Partial-set DA
(PDA), where there are totally 25 classes (the first 25 classes in alphabetical

with the l(dine)

i

Prior Knowledge Guided Unsupervised Domain Adaptation

11

Table 5. Classification accuracies
(%) on Office-Home for PDA.

Table 6. Classification accuracies (%) on Office.

Method K œÉ

:A :C :P :R Avg.

SHOT ‚Äì

‚Äì

78.9 65.2 82.9 90.3 79.3

kSHOT

UB 0.0 85.4 74.1 94.2 93.6 86.8
84.9 72.3 90.2 92.2 84.9
BR ‚Äì

DINE ‚Äì
DINE‚àó ‚Äì

‚Äì
‚Äì

77.6 59.2 82.7 85.2 76.2
73.1 54.8 80.0 83.9 73.0

kDINE

UB 0.0 82.1 66.4 91.3 91.7 82.9
79.7 63.3 88.2 89.5 80.2
BR ‚Äì

E
N
D
k

I

Method K œÉ A

DA

WD

AD

WW

AW

DAvg.

DINE ‚Äì
DINE‚àó ‚Äì

‚Äì
‚Äì

(cid:1)

(cid:1)

(cid:1)

(cid:1)
91.6 86.8 72.2 96.2 73.3 98.6 86.4
90.6 86.5 70.6 95.2 72.0 99.3 85.7

(cid:1)

(cid:1)

UB 0.0 94.7 92.2 71.0 96.8 72.6 99.8 87.9
UB 0.1 93.6 91.2 71.0 96.5 72.1 99.5 87.3
UB 0.5 91.7 88.3 70.4 95.2 71.6 99.3 86.1
UB 1.0 90.6 86.4 70.6 95.2 72.3 99.3 85.8
UB 2.0 90.6 86.5 70.7 95.2 72.0 99.3 85.7
93.4 91.1 70.5 96.4 72.1 99.5 87.2
BR ‚Äì

Table 7. Classification accuracies (%) on Office-Home.

Method K œÉ A

C A

P A

R C

A C

P C

R P

A P

C P

R R

A R

C R

P Avg.

DINE
DINE‚àó

‚Äì
‚Äì

‚Äì
‚Äì

(cid:1)

(cid:1)

(cid:1)

(cid:1)
52.2 78.4 81.3 65.3 76.6 78.7 62.7 49.6 82.2 69.8 55.8 84.2 69.7
51.8 76.0 79.6 63.1 75.1 76.5 60.4 48.5 80.7 69.4 55.9 83.5 68.4

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

kDINE

UB 0.0 54.8 78.6 81.7 67.1 78.3 79.6 66.8 52.3 82.5 72.0 58.1 85.4 71.4
UB 0.1 55.0 78.8 81.1 66.4 77.7 79.2 66.4 51.8 82.3 71.5 58.0 84.9 71.1
UB 0.5 52.9 76.7 79.9 64.5 76.3 77.8 63.8 51.0 80.9 70.5 57.1 84.2 69.6
UB 1.0 52.3 76.0 79.6 63.5 75.2 76.5 62.1 49.0 80.7 69.9 56.4 83.4 68.7
UB 2.0 51.8 76.0 79.6 63.0 75.1 76.5 60.8 49.2 80.7 69.6 55.5 83.5 68.4
54.2 79.4 81.5 66.8 78.6 79.2 65.6 50.9 82.6 71.4 58.1 85.3 71.1
BR ‚Äì

order) in the target domain and 65 classes in the source domain. This thus can
be viewed as an extreme situation where class probabilities of the rest 40 classes
are all zero. Table 5 lists the results averaged over tasks with the same target
domain (e.g., the :A column averages over C‚ÜíA, P‚ÜíA and R‚ÜíA). As can be
seen, using prior knowledge significantly improves in this situation.

5.3 Analysis

How prior knowledge guides UDA? To see why prior knowledge is helpful,
we consider the following two aspects:

‚Äì Ambiguous samples. As illustrated Fig. 3 (left), our rectification module
updates pseudo labels globally to match prior knowledge. This in effect moves
decision boundaries in the feature space. The pseudo labels of ambiguous
samples lying near the boundaries could be corrected during this process.
Figure 3 (center) plots the accuracies of three set of pseudo labels, L(shot),
L(pk0) and L(pk1), during the training process of kSHOT with UB(œÉ = 0.0)
on Office A‚ÜíW. Clearly using prior knowledge obtains more accurate pseudo
labels. This in turn benefits the subsequent self-training stage.

‚Äì Label distribution. Figure 5 plots distributions of ground-truth labels and
pseudo labels on Office-Home RS-UT P‚ÜíC in one seudo-labeling step. The
accuracy of pseudo labels is ‚àº 55%. As can be seen, the distribution of L(shot)

12

Sun et al.

Fig. 3. (Left) Prior knowledge rectifies the pseudo label of ambiguous samples; (center)
accuracies of pseudo labels before and after rectification using prior knowledge during
the training of kSHOT on Office A‚ÜíW; (right) convergence curves on Office A‚ÜíW
for comparison methods (S.R. is short for Smooth Regularization).

Fig. 4. Using noisy prior knowledge in kSHOT on (left) Office-Home RS-UT and (cen-
ter) Office; (right) using partial prior knowledge in kSHOT on Office-Home RS-UT.

severely deviates from the ground-truth. In contrast, distributions of pseudo
labels after rectification with prior knowledge are better compliant with the
ground-truth. Figure 6 plots distributions of network predictions throughout
the training process. The vanilla SHOT method hardly improves the label
distribution after adaptation, whereas using prior knowledge drives it to be
more similar to the ground-truth distribution in kSHOT.

Noisiness of the prior knowledge. In practice, the prior knowledge might
contain some level of noises. To study its effects, we manually add noises to
the estimated class prior qc. For UB, uniform noises are added through Àúqc =
qc + U(‚àíqcœï, qcœï), where œï ‚àà [0, 1] controls the noise level. The noises have been
centered to ensure that Àúqc is a valid probability. Then Àúqc is used to create the
unary bound discussed in Sec. 5.1. For BR, after sorting all classes based on
qc, we randomly swap neighboring classes. Suppose the index of class ck in the
sorted order is Ick , uniform noises are added through ÀúIck = Ick +U(‚àíœÜ, œÜ), where
œÜ controls the neighborhood size. Then we sort all classes based on the noisy
indexes ÀúIck , and use the resorted order to create binary relationship. Figure 4 (left
and center) shows that under moderate noises, incorporating prior knowledge is
still helpful and improves over the SHOT baseline.
Completeness of the prior knowledge. Until then, the prior constraints
are assumed to cover every class. It is straightforward to generalize to partial
constraints. We randomly select a portion of constraints that corresponds to the

02468101214epoch859095100Accuracy (%)L(shot)L(pk0)L(pk1)02468101214epoch859095100Accuracy (%)UBBRUB (w/o S.R.)BR (w/o S.R.)SHOT0.00.10.20.30.40.60.81.0UB noise 626364656667Accuracy (%)UBBRSHOT012346810BR noise 0.00.10.20.30.40.60.81.0UB noise 8788899091Accuracy (%)012346810BR noise 65(64)605040302010# Constraints6364656667Accuracy (%)UB-majUB-minUB-rndBR-majBR-minBR-rndPrior Knowledge Guided Unsupervised Domain Adaptation

13

Fig. 5. Prior knowledge rectifies distribution of pseudo labels in one pseudo-labeling
step of kSHOT (Office-Home RS-UT P‚ÜíC).

Fig. 6. Label distributions of network (ft) predictions in SHOT (upper) and kSHOT
(lower) (Office-Home RS-UT P‚ÜíC).

major (maj.), minor (min) or random (rnd) classes. Figure 4 (right) present the
results under different number of selected constraints. Partial constrains imply
less prior information, but still can benefit UDA training. Note that BR-rnd
reduces the performance most, partially because the randomly selected binary
relationship constraints hardly form the complete order of a subset of classes.
Estimating class prior from partial data. Table 9 presents the experimental
results when estimating qc from partial target data in kSHOT with UB(œÉ = 0.0)
on VisDA-2017. As sampling ratio reduces, the estimation error (relative de-
viations from using full data) increases. Nevertheless, even when the average
estimation error is about 15.5% at a sampling ratio of 0.5%, using prior knowl-
edge still improves over SHOT by +1.16% (82.9% ‚Üí 84.06%).
Effects of smooth regularization. Table 8 presents the ablation study on
smooth regularization. Generally, using smooth regularization achieves compa-
rable or better performance. The penalty depends on |St| = (cid:80)
Ã∏= l(pk0)
],
i
and varies across different tasks. In UB with large œÉ, the prior knowledge is not
informative, hence |St| is small. We underline cases where using smooth regular-
ization increases the accuracy significantly. The amount of improvement is most
significant on tasks like R‚ÜíP, C‚ÜíR, C‚ÜíP. Comparing two types of prior knowl-

I[l(shot)
i

i

ground-truthL(shot)L(pk1)-UB(=0.0)L(pk1)-UB(=0.1)L(pk1)-UB(=0.5)L(pk1)-UB(=1.0)L(pk1)-UB(=2.0)L(pk1)-BRground-truthepoch=0epoch=4epoch=8epoch=12epoch=14epoch=0epoch=4epoch=8epoch=12epoch=1414

Sun et al.

Table 8. Ablating Smooth Regularization (S.R.) in
kSHOT on Office-Home RS-UT.

K œÉ R

P R

C P

R P

C C

R C

P Avg.

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

UB 0.0 77.9 52.0 78.8 50.0 70.3 68.9 66.3
UB 0.1 77.9 51.4 78.7 49.7 70.5 68.4 66.1
UB 0.5 76.6 50.5 77.0 48.4 67.7 67.3 64.6
UB 1.0 76.5 50.1 76.7 48.1 66.4 65.3 63.8
UB 2.0 76.4 49.9 75.8 47.8 65.1 64.2 63.2
77.9 51.2 78.1 49.2 69.0 67.6 65.5
BR ‚Äì

UB 0.0 78.8 51.3 79.1 49.8 71.3 69.7 66.6
UB 0.1 78.3 51.7 79.0 48.6 71.6 69.4 66.4
UB 0.5 76.7 50.6 77.3 48.4 68.4 67.3 64.8
UB 1.0 76.3 50.0 76.9 48.4 66.7 65.8 64.0
UB 2.0 76.4 50.0 76.0 47.9 65.3 64.1 63.3
78.6 51.6 78.7 49.3 70.1 68.8 66.2
BR ‚Äì

Fig. 7. Effects of constant M
(by a scalar nt) in kSHOT
on Office-Home for PDA (aver-
aged over 12 tasks).

.

R
.
S

/
o
w

.

R
.
S

/
w

Table 9. Estimating class prior from partial target data in kSHOT on VisDA-2017.

Sampling ratio

0.5% 1%

5%

10% 50% 100%

Max. est. err (%)
Avg. est. err (%)
Avg. acc (%)

47.5
15.5
84.06

25.2
12.0
84.76

11.2
5.4
85.77

9.6
3.4
85.93

4.1
1.9
86.12

0.0
0.0
86.13

edge, it is more helpful in BR. Since BR only tells the order of class probabilities,
adding smooth regularization provides complementary information.
Choice of constant M . The prior knowledge is considered to be reliable, hence
we expect the prior constraints to be satisfied in the rectified pseudo labels. To
achieve this, M need to be some large constant in Eq. 4,5. Figure 7 shows how M
affects the performance on Office-Home under PDA setting in kSHOT. When M
is very small, the method degenerates to SHOT. When M is larger than some
threshold (e.g., 10‚àí3 ¬∑ nt), all soft constraints will in fact be satisfied. In our
experiments, we use M = 10 ¬∑ nt for all tasks in both kSHOT and kDINE.

6 Conclusions

We present a new yet realistic setting termed Knowledge-guided Unsupervised
Domain Adaptation (KUDA). In KUDA, in addition to labeled source data and
unlabeled target data, we have access to some prior knowledge about target label
distribution. We present a novel rectification module that refines pseudo labels
using prior knowledge through solving a constrained optimization problem. Then
we integrate it into two representative self-training based methods, SHOT and
DINE. Extensive experiments show that using prior knowledge can significantly
improve the performance. We expect our work to inspire further investigations
along the direction.

-6-5-4-3-2-101log10(M)75808590Accuracy (%)UBBRSHOTPrior Knowledge Guided Unsupervised Domain Adaptation

15

Table A.1. Classification accuracies (%) on VisDA-2017.

Method

SHOT

K

‚Äì

œÉ aero. bike bus

car horse knife moto. pers. plant sktb. train truck Avg.

‚Äì

94.3 88.5 80.1 57.3 93.1 94.9 80.7 80.3 91.5 89.1 86.3 58.2 82.9

kSHOT

UB
UB
UB
UB
UB
BR

0.0 95.7 88.7 81.4 73.4 94.7 94.2 88.1 82.5 93.4 91.1 87.2 63.1 86.1
0.1 96.1 90.2 80.7 71.5 96.0 91.3 85.7 83.5 94.5 91.3 87.1 61.5 85.8
0.5 95.2 89.6 79.7 59.6 94.8 90.7 82.0 86.2 92.7 90.2 86.8 59.8 83.9
1.0 94.8 88.3 79.1 56.8 93.8 92.8 80.6 82.7 91.0 90.9 86.2 59.0 83.0
2.0 94.6 87.7 78.9 55.9 93.4 94.8 80.2 81.4 89.3 89.9 86.1 58.6 82.6
‚Äì 96.3 89.2 79.7 58.0 94.2 92.7 81.1 81.1 92.2 90.9 88.7 59.2 83.6
UB+BR 0.5 95.8 89.1 81.1 60.2 95.1 91.5 84.3 82.7 93.4 91.4 88.7 59.8 84.4
UB+BR 1.0 96.2 89.1 79.7 58.0 94.2 92.6 81.1 81.1 92.2 90.9 88.7 59.3 83.6

Table A.2. Classification accuracies (%) on Office-Home for partial-set DA.

Method K œÉ A

C A

P A

R C

A C

P C

R P

A P

C P

R R

A R

C R

P Avg.

SHOT

‚Äì

‚Äì

(cid:1)

(cid:1)
64.8 85.2 92.7 76.3 77.6 88.8 79.7 64.3 89.5 80.6 66.4 85.8 79.3

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

kSHOT

UB 0.0 74.1 94.4 94.3 84.3 93.1 93.0 85.3 73.4 93.5 86.7 74.7 95.0 86.8
72.2 92.9 92.8 82.3 89.8 90.9 83.6 69.6 92.6 86.0 71.7 93.3 84.8
BR ‚Äì

DINE
DINE‚àó

‚Äì
‚Äì

‚Äì
‚Äì

58.1 83.4 89.2 78.0 80.0 80.6 74.2 56.6 85.9 80.6 62.9 84.8 76.2
54.9 80.8 87.3 70.3 75.2 78.8 70.9 51.2 85.7 78.1 58.3 84.1 73.0

kDINE

UB 0.0 65.5 91.4 92.3 80.2 89.3 91.2 81.6 64.4 91.6 84.5 69.3 93.2 82.9
62.5 89.2 91.1 77.3 85.0 87.2 78.5 60.3 90.3 83.4 67.1 90.3 80.2
BR ‚Äì

A Combining Two Types of Prior Knowledge

In the paper, we considered two types of prior knowledge, Unary Bound and
Binary Relationship. The two knowledge may have some overlapping. For ex-
ample, it is possible to infer BR from UB when the unary bounds are tight,
and vice versa. Nevertheless, when the bounds are not tight, one knowledge may
provide complementary information for the other. Table A.1 lists results when
combining UB and BR together in kSHOT on VisDA-2017. UB(œÉ = 0.5)+BR
performs slightly better than both UB(œÉ = 0.5) and BR. UB(œÉ = 1.0)+BR is
on par with BR as UB(œÉ = 1.0) is not informative.

B Visualization of Standard Deviations

For all tables and figures in the paper, we report the mean evaluation results of
three repeated experiments with different random seeds. Figure A.1 visualizes
the standard deviations on Office-Home of comparison methods. As can be seen,
the performances are stable to different initializations.

C More Detailed Results

Table A.2 presents the detailed results on Office-Home for partial-set DA. Ac-
curacies per class on VisDA-2017 are listed in Tab. A.1.

16

Sun et al.

Fig. A.1. Visualization of standard deviations on Office-Home.

D Effects of Label Smoothing in kDINE

DINE [19] distillates knowledge from the source predictor to a target model. As
mentioned in [19], using label smoothing for the teacher probability is superior
to using one-hot encoding. To show its effect in kDINE, we compare a variant
of kDINE without label smoothing. The objective function is

(cid:32)

kdine = Ext
L‚àó

i

Dkl

P tch(xt

i) + l(pk1)
2

i

(cid:33)

(cid:13)
(cid:13)
ft(xt
(cid:13)
i)
(cid:13)
(cid:13)

+ Œ≤Lmix ‚àí Lim

(A.1)

i

Compared with Eq. 10 of the paper, the smoothed label Àúl(pk1)
is replaced with
the one-hot label l(pk1)
. We term this variant as kDINE‚àó. For a fair comparison
with DINE, we also replace l(pk1)
with l(dine)
in Eq. A.1 and term it as DINE‚àó‚àó.
i
Table A.3 shows that using one-hot labels indeed degrades the performance in
both DINE‚àó‚àó and kDINE‚àó. Nevertheless, with class prior knowledge, kDINE‚àó
still achieves much better accuracies than DINE‚àó‚àó. This verifies the effectiveness
of considering prior knowledge and our proposed rectification module.

i

i

E Analysis of Prior Knowledge in kDINE

In Fig. 5 of the paper, we show that prior knowledge rectifies distribution of
pseudo labels in kSHOT. To see how prior knowledge is helpful in kDINE, let

ACAPARCACPCRPAPCPRRARCRP607080Accuracy (%)SHOTkSHOT-UB(=0.0)ACAPARCACPCRPAPCPRRARCRP50607080Accuracy (%)DINEkDINE-UB(=0.0)Prior Knowledge Guided Unsupervised Domain Adaptation

17

Table A.3. Classification accuracies (%) on Office-Home.

Method K œÉ A

C A

P A

R C

A C

P C

R P

A P

C P

R R

A R

C R

P Avg.

DINE
DINE‚àó
DINE‚àó‚àó

‚Äì
‚Äì
‚Äì

‚Äì
‚Äì
‚Äì

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)
52.2 78.4 81.3 65.3 76.6 78.7 62.7 49.6 82.2 69.8 55.8 84.2 69.7
51.8 76.0 79.6 63.1 75.1 76.5 60.4 48.5 80.7 69.4 55.9 83.5 68.4
51.3 75.4 79.2 62.7 74.6 75.8 59.8 48.1 80.2 68.9 55.7 83.1 67.9

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

kDINE

kDINE‚àó

UB 0.0 54.8 78.6 81.7 67.1 78.3 79.6 66.8 52.3 82.5 72.0 58.1 85.4 71.4
UB 0.1 55.0 78.8 81.1 66.4 77.7 79.2 66.4 51.8 82.3 71.5 58.0 84.9 71.1
UB 0.5 52.9 76.7 79.9 64.5 76.3 77.8 63.8 51.0 80.9 70.5 57.1 84.2 69.6
UB 1.0 52.3 76.0 79.6 63.5 75.2 76.5 62.1 49.0 80.7 69.9 56.4 83.4 68.7
UB 2.0 51.8 76.0 79.6 63.0 75.1 76.5 60.8 49.2 80.7 69.6 55.5 83.5 68.4
54.2 79.4 81.5 66.8 78.6 79.2 65.6 50.9 82.6 71.4 58.1 85.3 71.1
BR ‚Äì

UB 0.0 54.8 78.4 81.4 66.8 77.6 79.2 67.0 51.6 82.4 71.8 58.0 85.2 71.2
UB 0.1 54.4 78.0 80.9 66.5 76.9 78.9 66.0 51.1 82.1 71.4 57.7 84.7 70.7
UB 0.5 52.9 76.2 79.5 64.4 75.7 77.3 63.2 50.6 80.5 70.3 56.7 84.0 69.3
UB 1.0 52.1 75.4 79.2 63.2 74.9 75.9 61.6 48.9 80.3 69.8 56.0 83.2 68.4
UB 2.0 51.7 75.4 79.2 62.7 74.6 75.8 60.6 48.9 80.2 69.4 55.5 83.1 68.1
54.2 78.7 81.4 66.2 78.1 78.6 65.0 50.9 82.3 71.1 57.5 85.0 70.7
BR ‚Äì

Fig. A.2. K-L divergences between ground-truth target class distribution and mean
teacher probabilities during training on (left) Office-Home P‚ÜíA and (right) Office
A‚ÜíW. (See text for details.)

us consider the K-L divergences between the mean teacher probability and the
ground-truth target class distribution. The divergences for DINE and kDINE

(cid:16)

Ext

(cid:2)P tch(xt

i)(cid:3) (cid:13)
(cid:13)
(cid:13)pt(y)

(cid:17)

i

and Dkl

are Dkl
tively. Divergences for DINE‚àó, DINE‚àó‚àó and kDINE‚àó can be similarly defined.
Figure A.2 plots these divergences on two domain adaption tasks at a step of gen-
erating teacher probability. Clearly using prior knowledge leads to much smaller
divergences, which may benefit the distillation stage.

, respec-

i

i

i)+Àúl(pk1)
P tch(xt
2

(cid:19)

(cid:21) (cid:13)
(cid:13)
(cid:13)pt(y)

(cid:18)

(cid:20)

Ext

References

1. Baslamisli, A.S., Le, H.A., Gevers, T.: Cnn based learning using reflection and
retinex models for intrinsic image decomposition. In: CVPR. pp. 6674‚Äì6683 (2018)
2. Chen, D., Wang, D., Darrell, T., Ebrahimi, S.: Contrastive test-time adaptation.

In: CVPR. pp. 295‚Äì305 (2022)

02468epoch0.020.040.060.080.10K-L divergence02468epoch0.000.020.040.06K-L divergenceDINEDINE*DINE**kDINEkDINE*18

Sun et al.

3. Chen, L., Chen, H., Wei, Z., Jin, X., Tan, X., Jin, Y., Chen, E.: Reusing the
task-specific classifier as a discriminator: Discriminator-free adversarial domain
adaptation. In: CVPR. pp. 7181‚Äì7190 (2022)

4. Ding, N., Xu, Y., Tang, Y., Xu, C., Wang, Y., Tao, D.: Source-free domain adap-

tation via distribution estimation. In: CVPR. pp. 7212‚Äì7222 (2022)

5. Fu, B., Cao, Z., Wang, J., Long, M.: Transferable query selection for active domain

adaptation. In: CVPR. pp. 7272‚Äì7281 (2021)

6. Gomes, R., Krause, A., Perona, P.: Discriminative clustering by regularized infor-

mation maximization. NeurIPS (2010)

7. Gurobi Optimization, LLC: Gurobi Optimizer Reference Manual. https://www.

gurobi.com (2022)

8. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.

In: CVPR. pp. 770‚Äì778 (2016)

9. Huang, J., Guan, D., Xiao, A., Lu, S.: Model adaptation: Historical contrastive
learning for unsupervised domain adaptation without source data. NeurIPS (2021)
10. Kayhan, O.S., Gemert, J.C.v.: On translation invariance in cnns: Convolutional
layers can exploit absolute spatial location. In: CVPR. pp. 14274‚Äì14285 (2020)
11. Kim, T., Kim, C.: Attract, perturb, and explore: Learning a feature alignment
network for semi-supervised domain adaptation. In: ECCV. pp. 591‚Äì607 (2020)
12. LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. nature 521(7553), 436‚Äì444

(2015)

13. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W.,
Jackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural
Computation 1(4), 541‚Äì551 (1989)

14. Lefort, R., Fablet, R., Boucher, J.M.: Weakly supervised classification of objects

in images using soft random forests. In: ECCV. pp. 185‚Äì198 (2010)

15. Lengyel, A., Garg, S., Milford, M., van Gemert, J.C.: Zero-shot day-night domain

adaptation with a physics prior. In: ICCV. pp. 4399‚Äì4409 (2021)

16. Li, B., Wang, Y., Zhang, S., Li, D., Keutzer, K., Darrell, T., Zhao, H.: Learn-
ing invariant representations and risks for semi-supervised domain adaptation. In:
CVPR. pp. 1104‚Äì1113 (2021)

17. Li, R., Cheong, L.F., Tan, R.T.: Heavy rain image restoration: Integrating physics
model and conditional adversarial learning. In: CVPR. pp. 1633‚Äì1642 (2019)
18. Liang, J., Hu, D., Feng, J.: Do we really need to access the source data? source
hypothesis transfer for unsupervised domain adaptation. In: ICML. pp. 6028‚Äì6039
(2020)

19. Liang, J., Hu, D., Feng, J., He, R.: Dine: Domain adaptation from single and

multiple black-box predictors. In: CVPR. pp. 8003‚Äì8013 (2022)

20. Lin, Y., Pintea, S.L., Gemert, J.C.v.: Deep hough-transform line priors. In: ECCV.

pp. 323‚Äì340 (2020)

21. Lipton, Z., Wang, Y.X., Smola, A.: Detecting and correcting for label shift with

black box predictors. In: ICML. pp. 3122‚Äì3130 (2018)

22. Liu, X., Guo, Z., Li, S., Xing, F., You, J., Kuo, C.C.J., El Fakhri, G., Woo, J.:
Adversarial unsupervised domain adaptation with conditional and label shift: Infer,
align and iterate. In: ICCV. pp. 10367‚Äì10376 (2021)

23. Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic

segmentation. In: CVPR. pp. 3431‚Äì3440 (2015)

24. Mann, G.S., McCallum, A.: Simple, robust, scalable semi-supervised learning via

expectation regularization. In: ICML. pp. 593‚Äì600 (2007)

25. Pan, S.J., Yang, Q.: A survey on transfer learning. TKDE 22(10), 1345‚Äì1359 (2009)

Prior Knowledge Guided Unsupervised Domain Adaptation

19

26. Peng, X., Bai, Q., Xia, X., Huang, Z., Saenko, K., Wang, B.: Moment matching

for multi-source domain adaptation. In: ICCV. pp. 1406‚Äì1415 (2019)

27. Peng, X., Usman, B., Kaushik, N., Hoffman, J., Wang, D., Saenko, K.: Visda: The
visual domain adaptation challenge. arXiv preprint arXiv:1710.06924 (2017)
28. Prabhu, V., Chandrasekaran, A., Saenko, K., Hoffman, J.: Active domain adap-
tation via clustering uncertainty-weighted embeddings. In: ICCV. pp. 8505‚Äì8514
(2021)

29. Prabhu, V., Khare, S., Kartik, D., Hoffman, J.: Sentry: Selective entropy optimiza-
tion via committee consistency for unsupervised domain adaptation. In: CVPR.
pp. 8558‚Äì8567 (2021)

30. Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object de-

tection with region proposal networks. NeurIPS (2015)

31. Saenko, K., Kulis, B., Fritz, M., Darrell, T.: Adapting visual category models to

new domains. In: ECCV. pp. 213‚Äì226 (2010)

32. Saito, K., Kim, D., Sclaroff, S., Darrell, T., Saenko, K.: Semi-supervised domain

adaptation via minimax entropy. In: ICCV. pp. 8050‚Äì8058 (2019)

33. Schapire, R.E., Rochery, M., Rahim, M., Gupta, N.: Incorporating prior knowledge

into boosting. In: ICML. pp. 538‚Äì545 (2002)

34. Shi, Y., Sha, F.: Information-theoretical learning of discriminative clusters for un-

supervised domain adaptation. In: ICML (2012)

35. Sun, T., Lu, C., Zhang, T., Ling, H.: Safe self-refinement for transformer-based

domain adaptation. In: CVPR. pp. 7191‚Äì7200 (2022)

36. Tan, S., Peng, X., Saenko, K.: Class-imbalanced domain adaptation: an empirical

odyssey. In: ECCV Workshops. pp. 585‚Äì602 (2020)

37. Urban, G., Geras, K.J., Kahou, S.E., Aslan, O., Wang, S., Caruana, R., Mohamed,
A., Philipose, M., Richardson, M.: Do deep convolutional nets really need to be
deep and convolutional? In: ICLR (2017)

38. Wang, M., Deng, W.: Deep visual domain adaptation: a survey. Neurocomputing

312, 135‚Äì153 (2018)

39. Wang, Z., Lyu, S., Schalk, G., Ji, Q.: Learning with target prior. NeurIPS (2012)
40. Wilson, G., Cook, D.J.: A survey of unsupervised deep domain adaptation. ACM

TIST 11(5), 1‚Äì46 (2020)

41. Wolsey, L.A.: Integer programming. John Wiley & Sons (2020)
42. Xie, B., Yuan, L., Li, S., Liu, C.H., Cheng, X., Wang, G.: Active learning for

domain adaptation: An energy-based approach. In: AAAI. pp. 8708‚Äì8716 (2022)

43. Zhang, H., Zhang, Y., Jia, K., Zhang, L.: Unsupervised domain adaptation of

black-box source models. arXiv preprint arXiv:2101.02839 (2021)

44. Zhang, H., Cisse, M., Dauphin, Y.N., Lopez-Paz, D.: mixup: Beyond empirical risk

minimization. In: ICLR (2018)

45. Zhang, Y., Liu, T., Long, M., Jordan, M.: Bridging theory and algorithm for do-

main adaptation. In: ICML. pp. 7404‚Äì7413 (2019)

46. Zhu, X., Ghahramani, Z., Lafferty, J.D.: Semi-supervised learning using gaussian

fields and harmonic functions. In: ICML. pp. 912‚Äì919 (2003)

