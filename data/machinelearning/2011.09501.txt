GRAPHSPY: Fused Program Semantic-Level Embedding via Graph Neural
Networks for Dead Store Detection

Yixin Guo, Pengcheng Li, Yingwei Luo, Xiaolin Wang, Zhenlin Wang
Peking University, Alibaba Research US, Peking University, Peking University, Michigan Technological University
yixinguo@pku.edu.cn, landy0220@gmail.com, lyw@pku.edu.cn, wxl@pku.edu.cn, zlwang@mtu.edu

0
2
0
2

v
o
N
8
1

]

G
L
.
s
c
[

1
v
1
0
5
9
0
.
1
1
0
2
:
v
i
X
r
a

Abstract

Production software oftentimes suffers from the issue of
performance inefﬁciencies caused by inappropriate use of
data structures, programming abstractions, and conservative
compiler optimizations. It is desirable to avoid unnecessary
memory operations. However, existing works often use a
whole-program ﬁne-grained monitoring method with incred-
ibly high overhead. To this end, we propose a learning-aided
approach to identify unnecessary memory operations intel-
ligently with low overhead. By applying several prevalent
graph neural network models to extract program semantics
with respect to program structure, execution order and dy-
namic states, we present a novel, hybrid program embedding
approach so that to derive unnecessary memory operations
through the embedding. We train our model with tens of thou-
sands of samples acquired from a set of real-world bench-
marks. Results show that our model achieves 90% of accu-
racy and incurs only around a half of time overhead of the
state-of-art tool.

Introduction
Production software oftentimes suffers from various kinds of
performance inefﬁciencies. Some inefﬁciencies are induced
by programmers during design (e.g., poor data structure se-
lection) and implementation (e.g., use of heavy-weight pro-
gramming abstractions). Others are compiler induced, e.g.,
not inlining hot functions. Identifying and eliminating in-
efﬁciencies in programs are important not only for com-
mercial developers, but also for scientists writing compute-
intensive codes for simulation, analysis, or modeling. Per-
formance analysis tools, such as gprof (Graham, Kessler,
and McKusick 1982), HPCToolkit (Adhianto et al. 2010),
and vTune (VTu 2013), attribute running time of a program
to code structures at various granularities (usage analysis).
However, such tools are incapable of identifying unneces-
sary memory operations (wastage analysis).

Dead stores are one type of unnecessary memory opera-
tions. A dead store happens when two consecutive store in-
structions to the same memory location are not intervened
by a load instruction for the same location. Fig. 1 shows an
example in the Hmmer program from the SPECCPU bench-
mark suite. The source code ﬁrst writes, then reads and ﬁ-
nally writes mc[k], showing no dead stores. But in the as-
sembly code in Listing 2, the value of mc[k] is held in a

Figure 1: A dead store example in the Hmmer program.

register, which is reused (read) in the comparison on line 4.
The memory location 0x4(%rsi) is written ﬁrst on line 2
and then on line 6. Hence, line 2 is a dead store.

Whole-program ﬁne-grained monitoring is a means to
monitor execution at microscopic details. It monitors each
binary instruction instance, including its operator, operands,
and run-time values in registers and memory. A key advan-
tage of microscopic program-wide monitoring is that it can
identify redundancies irrespective of the user-level program
abstractions. Prior works (Chabbi and Mellor-Crummey
2012; Wen, Chabbi, and Liu 2017) have shown that the
ﬁne-grained proﬁling techniques can effectively identify
dead stores and offer detailed guidance. However, micro-
scopic analysis incurs unacceptable cost in practical use. It
is reported that the state-of-the-art (the best-paper awardee)
takes up to 150× run-time slowdown (Su et al. 2019).

To this end, we propose a learning-aided approach that
assists in ﬁnding out the procedures that highly likely have
dead stores and then employ the ﬁne-grained monitoring
tool for these suspicious targets, rather than whole-program
ﬁne-grained monitoring. As a result, our approach reduces
the running time overhead of the state-of-art tool by 71×.

We formulate this prediction problem as a graph-level
task. A procedure is represented by a graph. We embed a
procedure through a graph neural network and feed the em-
bedding to a classiﬁer to predict whether dead stores ex-
ist. Unfortunately, procedure or program embedding is of
an utmost challenge because a program involves many syn-
tactic and semantic factors, including the control ﬂow, data
ﬂow, input-sensitivity, context-sensitivity, execution state,

 
 
 
 
 
 
architecture-speciﬁc instructions, etc.

The basic building blocks of a procedure are the so-called
basic blocks. By tokenizing a basic block into a set of words,
we use word2vec (Mikolov et al. 2013) to embed each word
and average them as an embedding for representing a ba-
sic block. Viewing every basic block as a node, an intra-
procedural syntactic structure, i.e. control ﬂow graph (CFG)
connects all basic blocks as a graph according to control ﬂow
semantics, for example by low-level JMP instructions. In
order to capture the intra-procedural structure information,
we apply the gated graph neural network (Li et al. 2016)
(GGNN) onto CFGs through the message-passing neural
network framework.

However, intra-procedural structure information cannot
envision dead stores caused across procedure boundaries. In
order to make the prediction more precisely, inter-procedural
structure information needs to be additionally embedded by
dynamically proﬁling a calling context tree (Ammons, Ball,
and Larus 1997). A calling context tree reveals the relations
between procedures. We apply the GGNN onto it to capture
inter-procedural structure information.

In addition to program structure semantics, we embed dy-
namic value semantics by taking snapshots of memory ad-
dresses and associated values stored during program execu-
tion. The snapshots of memory states characterize data de-
pendency between basic blocks within a procedure or pro-
cedures, i.e., data ﬂow graph. The embedding of the data
ﬂow graph enhances the prediction precision by encoding
the input-sensitivity, data ﬂow, and execution state.

Finally, convolutional neural networks are employed to
extract common relative positional information between ba-
sic blocks in a CFG. It is observed that the relative posi-
tional information is common across different architectures
and compilation options. With this embedding, our model
trained for a speciﬁc conﬁguration is capable to detect dead
stores for different platforms and options.

In summary, this paper makes the following contributions:

• We present a novel approach called GRAPHSPY, which is
inspired by the success of graph neural networks, for de-
tecting dead stores with low overhead. As far as we know,
this is the ﬁrst work that applies GNNs for dead store de-
tection.

• We present a hybrid embedding approach that embeds
both intra- and inter-procedural structure semantics with
static CFGs and dynamic calling context trees.

• We explore a CNN-based embedding approach to detect
dead stores across different micro-architectures and com-
pilation options.

• We present an embedding-based data ﬂow graph that cap-
tures program value semantics by sampling memory and
register states with negligible overhead.

• We evaluate our approach on a set of real-world bench-
marks. The achieved average prediction accuracy is as
high as 90%, and the reduced time overhead doubles the
state-of-art monitoring tool.

Graph Neural Networks
The objective of Graph Neural Network is to learn the node
representation and graph representation for predicting node
attributes or attributes of the entire graph. A Graph Neural
Network (GNN) (Scarselli et al. 2009) structure G = (V, E)
consists of a set of node V and a set of edge E. Each
node v ∈ V is annotated with an initial node embedding
by x ∈ RD and a hidden state vector ht
v often
equals to x). A node updates its hidden state by aggregating
its neighbor hidden states and its own state at the previous
time step. In total, T steps of state propagation are applied
onto a GNN. In the t-th step, node v gathers its neighbors’
states to an aggregation as mt
v, as shown in Eq. 1. Then the
aggregated state is combined with node v’s previous state
ht−1
through a neural network called g, as shown in Eq. 2.
v
f can be an arbitrary function, for example a linear layer,
representing a model with parameters θ.

v ∈ RD (h0

mt

v =

(cid:88)

f (ht

v; θ)

(u,v)∈E

(1)

)

v; ht−1
v

v = g(mt
ht

(2)
Gated Graph Neural Network (GGNN) (Li et al. 2016) is
an extension of GNN by replacing g in Eq. 2 with the Gated
Recurrent Unit (GRU) (Chung et al. 2014) function as shown
in Eq. 3. The GRU function lets a node memorize history
long-term dependency information, as it is good at dealing
with long sequences by propagating the internal hidden state
additively instead of multiplicatively.

v = GRU(mt
ht

v; ht−1
v

)

(3)

Following GGNN, quite a few different extensions to
GNN were developed by applying various deep learning
techniques. Graph convolution network (GCN) (Kipf and
Welling 2016) was proposed by adding convolutional lay-
ers to update node embeddings. Graph attention network
(GAT) (Velickovic et al. 2018) leverages the attention mech-
anism to formalize the spatial and time sequential infor-
mation. GraphSAGE (Hamilton, Ying, and Leskovec 2017)
adopts an aggregating function to merge the node and its
neighbor nodes. For better graph representation learning,
two prevalent frameworks Message Passing Neural Net-
work (MPNN) (Gilmer et al. 2017) and Graph Network
(GN) (Battaglia et al. 2018) were proposed. MPNN has a
message passing phase and a readout phase. The message
passing phase runs several steps to capture the information
from neighbor nodes. The readout phase computes an em-
bedding for the whole graph.

Program Representation and Embedding
We now present the overview of the proposed approach.
First, provided a procedure we construct a CFG from its bi-
nary code and employ a static structure-aware embedding
approach to encode the intra-procedural structure semantics.
Second, we proﬁle run-time calling context trees to embed
inter-procedural structure semantics and dynamically take
program snapshots to capture memory states including reg-
ister values and memory values to embed value semantics.

Figure 2: Overview of the program representation using fused static and dynamic embeddings based upon GNN.

Finally, a CNN model is employed to embed relative posi-
tional information for a CFG. Putting together these embed-
dings as a whole embedding, we predict if the target pro-
cedure exists dead stores. Fig. 2 shows the diagram of the
overview of the proposed approach using fused static and
dynamic embedding.

Static Intra-Procedural Structure Embedding
An assembly code can be compiled from a source code. An
assembly code is speciﬁc to a processor architecture, for ex-
ample x86-64. It is a ﬂat proﬁle of instructions, Insi(i ∈
1 . . . m). Each instruction Insi is composed of a series of
tokens, ti(i ∈ 1 . . . n). These tokens are of many types, in-
cluding operators and operands. Some instructions are com-
pute operations with respect to register values (e.g., ADD,
SUB). Some instructions move values between registers and
memory (e.g., LOAD, STORE). Others represent conditional
branch or jump to other locations (e.g., JZ, JMP).

A basic block Bi(i ∈ 1 . . . K) is composed of a sequence
of instructions without any control ﬂow statements. It has
only one entry and one exit statement. When the program
pointer jumps from a source to a target block, we connect an
edge from the source to the target. Viewing the basic blocks
as nodes and the connections as edges, we form a control
ﬂow graph (CFG). For instance, for x86 direct branches,
there are only two possible target blocks for a given source
block, which we can refer to as the true block and false
block. Fig. 3 shows a procedure named set i and its ac-
cording CFG, where it is observed that each basic block has
only one entry and one exit and a basic block may have mul-
tiple following basic blocks.

A CFG represents intra-procedure program structure se-
mantic, so we attempt to embed a CFG into a feature map.
First, we apply the word2vec (Mikolov et al. 2013) model
to encode every token in an instruction inside a basic block.
Then we average out token embeddings as an embedding of
an instruction, and ﬁnally derive a whole embedding of a ba-
sic block by averaging the embeddings of instructions. Eq. 4
depicts the embedding process.

∀k, ebbk =

(cid:80)m

j=0{eInsj =

(cid:80)n

i=0 word2vec(ti)
n

}

m

(4)

Once we have embedded every basic block, we formalize
a graph of embeddings. We start to run the GGNN model

through the message-passing neural network model. The ag-
gregate function for each node to compute the state vector is
computed using a gated recurrent unit (GRU), as shown in
Eq. 3. GRU is especially good at capturing long-time de-
pendency between the executions of basic blocks within a
procedure. We embed it from the assembly without any ac-
tual executions, therefore this type of embedding is static
and takes no cost for the run-time execution.

Abstract Syntax Tree (AST) (I. Neamtiu and Hicks 2005)
is an intermediate representation of a binary generated in the
process of compilation from the source code to binary code.
It uses context-free grammar parsing rules that partially in-
clude the grammars and execution orders of a binary. By
contrast, we choose to construct a CFG from the assembly
code, because one of the beneﬁts is that it is typically less
stylish and tighter to program semantics. For example, pro-
grams that are syntactically different but semantically equiv-
alent tend to correspond to similar assembly codes. More-
over, the assembly code often embrace more architecture-
speciﬁc characteristics than AST so that the embedding en-
codes architecture level information.

Dynamic Inter-Procedural Structure Embedding
CFGs represent only intra-procedural structure semantic,
rather than whole-program structure. Call graph captures
inter-procedural structure information, i.e., caller-callee re-
lations. Nevertheless, call graph only expresses static struc-
ture information that may not reﬂect actual calling sequence
of function calls. An alternative is to proﬁle calling context
tree (CCT)s (Ammons, Ball, and Larus 1997), which is the
actual function-call sequence during program execution.

In CCT proﬁles, data (e.g., function call) is collected with
respect to each stack frame. CCTs comprise the merged call-
stacks from all functions invoked during the course of pro-
gram execution, with each frame in the stack represented
as a node in the tree, and with common preﬁxes merged.
Typically, each call stack in the CCT is rooted at main.
A CCT can differentiate a function called in different ways
from different contexts with different parameters and global
states. Furthermore, when time measurement data is aggre-
gated across threads, the aggregated time obscures problems
occurring on a speciﬁc subset of CCTs.

Fig. 3 compares the static call graph and dynamic calling
context tree constructed from the same code. In the upper

Figure 3: Examples of a control-ﬂow graph and the comparison between a call graph and a calling-context tree.

call graph, there is only one instance for any single proce-
dure and the caller-callee relations are formed statically, for
example from cmp(x) to set 0(). While in the bottom
CCT example, two instances of cmp() exist with different
input actual parameters, one of which is called by sub(7)
and the other calling set i().

In addition to the CCT proﬁles, we periodically take pro-
gram snapshots during program execution which are sets of
values that occur over the course of the execution. We call
every program snapshot, i.e. a set of values, as a program
memory state, which is deﬁned as a set of general-purpose
registers and memory addresses and associated values. Dif-
ferent than registers, memory addresses are indexed by a 64-
bit integer and hence extremely widely spread. In theory,
we should include all values of registers and entire mem-
ory address space for a program memory state. However,
it takes unacceptable space and time cost to proﬁle entire
memory address space. Instead, for a program snapshot, we
record general-purpose register values and only memory val-
ues stored within this execution. These values are lightly ob-
tainable with negligible overhead via a binary instrumenta-
tion tool called DynamoRIO (Bruening 2004).

We associate program memory states to every function
instance in CCT proﬁles, thus each function instance has a
set of memory-state related values. As embedded for every
basic block in the previous section, we use the word2vec
model to embed the memory values of a function instance in
a CCT proﬁle. After that, we run the GGNN model again on
the CCT graph to propagate memory state semantics across
procedure boundaries to formalize a CCT embedding.

Program memory states characterize memory value se-
mantics, i.e., which functions load and store which mem-
ory addresses. Because dead stores may happen between two
function instances, the GNN propagation of memory states
in the CCT aides in capturing these dead store cases. We
call the embedding of a CCT as inter-procedural structure
semantics and memory value semantics.

Relative Positional Information Embedding
It is always desirable to train a generalized model for dif-
ferent micro-architectures and compilation options. Convo-

lutional neural networks (CNNs) are leveraged to learn rel-
ative positional information between basic blocks in a CFG.
It is observed that the relative positional information be-
tween basic blocks are commonly shared by different micro-
architectures and compilation options.

Fig. 4 shows three CFGs and their according adjacency
matrices, which could be converted mutually by making mi-
nor changes. Each of the three CFGs has a rectangle, show-
ing a relative positional relation of four basic blocks. As is
shown, the rectangle framed share similarities, i.e., the nu-
meric matrix of this rectangle in (a) is (1, 1, 1, 0, 1, 1). In-
terestingly, this numeric relation invariance holds for differ-
ent architectures and options. Consider (b) and (c) as the
resulting adjacency matrices for different architectures and
options. In (b), a new node is added into its adjacency ma-
trix, but the spatially relative positions of those nodes of the
corresponding rectangle stay the same and so does its nu-
meric matrix. Thus, the numeric relation invariance holds
for the transformation. In (c), the added node seems break-
ing the numeric matrix. But when removing the second row,
the numeric matrix stays the same as (1, 1, 1, 0, 1, 1). That
said, the numeric relation invariance holds. It is just like cap-
turing the spatial information in a image, so we use CNNs.
CNN may learn this type of numeric relation invariance.
When building binaries with different options for different
architectures, the relative positional relations between ba-
sic blocks are oftentimes similar. By CNN embedding, our
model desires to exploit a one-ﬁts-all solution. Additionally,
using CNN can save time overhead since the computation
of CNNs upon adjacency matrices is a lot faster compar-
ing to traditional graph feature extraction algorithms. More-
over, CNNs could be added to inputs with varying sizes,
so it is able to model graphs of different sizes without pre-
processing such as padding.

gA = Maxpooling(Resnet(A))

(5)

As shown in Eq. 5, we apply the Resnet (He et al. 2016)
model onto the adjacency matrices to encode the relative po-
sitional information. A MaxPooling layer is added after the
last layer of the Resnet network to reduce high dimensional
data to low dimension. We use an 11-layer Resnet with 3

Binary
505.mcf
508.namd
510.parest
520.omnetpp
523.xalancbmk
526.blender
544.nab
557.xz

#Functions
67
92
18694
7451
12613
36782
287
355

#BBs
799
1199
275693
56217
145245
314951
7030
4685

Data Volume
2.26GB
460MB
10.51GB
4.08GB
4.33GB
31.91GB
259MB
813MB

Table 1: Benchmark statistics.

Dynamic proﬁles are obtained for calling context trees
and memory-state values using the binary instrumentation
tool DynamoRIO (Bruening 2004). As is all known SPEC-
CPU benchmark suite (SPEC 2017) is a golden standard
used to evaluate software system performance. We run in-
teger programs from the benchmark suite with the reference
input and sample program execution with for a few times.
Each sample records one million instructions continuously.
Our tool attaches to the running process, fast forwards to the
regions of interest and outputs desired proﬁling memory-
state data. Table 1 shows the statistics of programs used,
including the number of functions, number of basic blocks
and, more importantly, raw data ﬁle volume that contains
raw data of instructions, CFGs, memory values, CCT pro-
ﬁles, and label data.

Tools. For dataset collection, two proﬁling tools were im-
plemented and one existing tool is utilized. In order to ob-
tain the ground truth data, i.e., dead stores of all binaries,
we made our best efforts to carefully implement the state-
of-the-art ﬁne-grained monitoring tool, CIDetector (Su
et al. 2019) based on DynamoRIO. CIDetector monitors
every memory load and store instruction. We attribute all
found dead stores to every procedure of every binary. Each
procedure corresponds to a data sample since we are predict-
ing on a per-procedure basis. The procedure is labeled as 1
(true) if it has dead stores, 0 (false) otherwise.

A binary analysis tool called angr (Shoshitaishvili et al.
2016) is utilized to construct CFGs by taking as input the
assembly code and outputting a CFG for every single proce-
dure. A simple proﬁling tool was implemented to dump call-
ing context trees and memory states based on DynamoRIO.
By distinguishing two micro-architectures, x86-64 and
ARM (AArch64) and compiling with two separate options,
GCC -O2 and GCC -O3, we compose four conﬁgurations:
x86-O2, x86-O3, ARM-O2, and ARM-O3. We shufﬂe the
samples from all binaries with any single conﬁguration and
take a fraction as training and testing datasets, as shown in
Table 2. The size ratio of true samples over false samples is
around 1:1, for a balance of distribution.

Additionally, we create a hybrid conﬁguration by mixing
samples from four basic conﬁgurations. This conﬁguration
is used to train a uniﬁed model that aims to work for any
compilation option or micro-architecture.

Alternative models. BERT (Vaswani et al. 2017) makes
use of the attention mechanism to learn contextual rela-
tions between words in a sentence. BERT is an alternative to

Figure 4: Relative positional modeling.

residual blocks. A denotes an adjacency matrix. gA is the
ﬁnal embedding.

Fused Static and Dynamic Embedding
Putting together all aforementioned embeddings, a single ﬁ-
nal program embedding is derived for the target procedure
(Eq. 6). Finally, we run the embedding through an MLP to
check if the target procedure exists dead stores (Eq. 7). Fig. 2
summarizes the overview of the entire approach.

gprog = Dense(gA (cid:107) gintra (cid:107) ginter)

go = MLP(gprog)

(6)

(7)

When the target procedure is predicted to be suspicious,
we apply the state-of-art ﬁne-grained monitoring tool to
carefully scan the target procedure line-by-line. As a result,
the tool outputs the memory locations where it assures that
dead stores happen. In this way, our model gets rid of a num-
ber of procedures that do not have dead stores, therefore, a
substantial amount of time and space overhead for checking
these procedures may be saved.

Evaluation

In this section, we answer the following questions:

• What is the prediction accuracy by our model for any sin-

gle machine and compilation conﬁguration?

• What is the cross-platform prediction accuracy of a uni-
ﬁed model targeting at different architectures and op-
tions?

• What is time and space overhead improvement in contrast

to the state-of-the-art ﬁne-grained monitoring tool?

• What is the performance comparison of the proposed ap-

proach to other popular models?

Experimental Setup
Dataset. The proposed approach is composed of two types
of inputs, static assembly code and dynamic program pro-
ﬁles. In order to collect static assembly, we compile source
code for a binary through the GCC compiler and then disas-
semble the binary by using GNU binary utilities.

Conﬁg.
x86-O2
x86-O3
ARM-O2
ARM-O3
Hybrid

Training Validation
13,999
13,271
13,633
13,408
40,978

13,781
13,660
13,633
13,136
28,320

Test
13,782
13,660
13,063
13,138
28,323

Total
41,562
40,591
39,760
39,682
97,621

Table 2: Dataset sizes of different conﬁgurations.

word2vec to encode a basic block and memory states. CNN-
based models are alternatives to Resnet to encode relative
positional information. We measure the accuracy results of
using word2vec, Resnet (7 or 11 layers), BERT, or CNN-
based models alone and the accuracy results by combining
some of them, and make a comparison with GRAPHSPY.
Hyper-parameters. We show only the values of all hyper-
parameters used in the ﬁnal experiments. The learning rate
used is 0.0001 and the batch size is 64. We use the word2vec
models in two places for basic block embedding and mem-
ory value embedding. The dimension of the former embed-
ding is 60 and the latter 30. GGNN is also used for CFGs
and CCTs. The output dimension and number of steps are
70 and 10 for CFGs, and 50 and 5 for CCTs. The output di-
mension of Resnet is 40. We also tuned these parameters for
a wide range, which will be given in Appendix.
Platform. All deep learning tasks were performed on 8
Nvidia Tesla V100 GPU (Nvidia-Inc. 2017) cards of the
Volta architecture. Each has 5120 streaming cores, 640 ten-
sor cores and 32GB memory capacity. The CPU host is Intel
Xeon CPU 8163 2.50GHz, running Linux kernel 5.0. All the
other non-deep learning tasks were run on the host.

Prediction Results
Fig. 5 measures three metrics, precision, recall rate and ac-
curacy for each conﬁguration and the hybrid conﬁguration.
The precision metric is computed as
T P +F P , the recall rate
T P +F N +F P +T N , where
T P +F N , and the accuracy as
as
T P denotes true positive, F P false positive, F N false neg-
ative, and T N true negative. Both the precision and recall
rate metrics demonstrate the capability of picking just the
true samples from all samples.

T P +T N

T P

T P

Clearly, all measurements are beyond 80%, which just
conﬁrms the efﬁcacy of the proposed model for different
conﬁgurations. On average, we achieve 88.14% of precision,
88.55% of recall rate and 88.08% of accuracy, respectively.
In particular, the results for ARM is uniformly better than
those for x86. The high prediction accuracy, together with
50-50 distributed true samples and false samples, implies
that the proposed model is capable to rule out false samples
for dead store detection. Hence, we may save up to half of
the checking overhead by CIDetector for omitting those
samples (i.e. procedures). We will present memory overhead
reduction and time saving in the next section.

It is worth noting that we achieve as high as accuracy of
90.02% in the hybrid conﬁguration. We trained the model
with samples from different architectures and options, and
test for samples from different conﬁgurations as well. Re-

Figure 5: Prediction results for different and hybrid conﬁgu-
rations.

sults demonstrate that the proposed model has a great poten-
tial to be a uniﬁed model that performs well across different
architectures and compilation options, therefore we would
argue that the proposed model can be a one-ﬁts-all solution.

Overhead Results

Taking ARM-O3 as an example, we measure time saving and
memory overhead reduction by GRAPHSPY. We apply the
uniﬁed model trained from the hybrid conﬁguration to ﬁnd
out dead stores for all binaries on ARM-O3. CIDetector
runs through a binary by ﬁltering those procedures that do
not have dead stores. Compared with whole-program mon-
itoring, GRAPHSPY improves upon CIDetector by an
average speedup of 1.65×, with a maximum of 1.89×, as
shown by Fig. 6. Since CIDetector incurs up to 150×
time overhead of the native run, the proposed approach de-
creases the time overhead of CIDetector by a maximum
of 71× of the time of native run (i.e., 150 - 150/1.89). In the
mean time, memory cost incurred is reduced as well. Fig. 6
shows that the proposed approach reduces 40% of the mem-
ory overhead incurred by CIDetector.

Model Comparison Results

Table 3 compares GRAPHSPY with alternative models.
Clearly, the word2vec model achieves good accuracy of
up to 83.05% when used alone. By contrast, BERT per-
forms worse with accuracy of 57.4%. It is believed that
BERT would potentially perform better. However, its in-
credibly long training time prevents from being more tuned
in a limited time period. Despite competitive accuracy re-
sults obtained by only using one model, combining them to-
gether absolutely enhances the results further. For example,
word2vec + GGNNcf g + Resnet11 enhances the accuracy
to 87.03% on x86-O3, as opposed to 79.08% by only using
word2vec. As a result, GRAPHSPY achieves the highest ac-
curacy of 92.56% with a combination of word2vec, Resnet,
GGNN for CFGs and GGNN for CCTs.

Figure 6: Time saving and memory reduction over CIDetector.

Model
word2vec
BERT
CNN3
Resnet7
Resnet11
w2v + GGNNcf g
BERT + GGNNcf g
w2v + GGNNcf g + Res11
BERT + GGNNcf g + Res11
GRAPHSPY

ARM-O3
0.7640/0.8305
0.6133/0.5740
0.4026/0.8402
0.4712/0.8067
0.5706/0.7910
0.8756/0.7763
0.5489/0.7610
0.8198/0.8246
0.4272/0.8428
0.9070/0.9256

x86-O3
0.7105/0.7908
0.6910/0.4580
0.3820/0.8446
0.3698/0.8469
0.4549/0.8071
0.7664/0.7969
0.3066/0.7940
0.7584/0.8234
0.3333/0.8703
0.8415/0.8668

Table 3: Comparison among different models.

Related Work

GNNs for program embedding. GNNs have attracted in-
creasing attention to program representation, partly because
many graph structures implicitly existing inside a program
code, e.g., abstract syntax tree (AST), CFG and data ﬂow
graph, make GNNs highly applicable for program embed-
ding (Allamanis et al. 2017). Prior studies (Lu et al. 2019;
Shi et al. 2020) use the intermediate representation (IR) or
AST to construct CFGs to feed to a gated graph neural net-
work for program classiﬁcation and data prediction tasks.
Due to the inherent difference between syntax and seman-
tics, models learned from static code can be imprecise at
capturing semantic properties (Wang, Su, and Singh 2018).
Our model constructs CFGs from the assembly code for a
representation of program structure information. By it, ar-
chitecture speciﬁc details can be embedded by using instruc-
tions rather than generic intermediate representation.

Wang et al. (Wang, Su, and Singh 2018; Wang and Su
2020) embeds programs from dynamic execution traces or
symbolic execution traces, which capture accurate program
semantics, thus offering beneﬁts that reason over syntactic
representations. However, the quality of the model requires
heavy execution proﬁling. Our dynamic model embeds dy-

namic program states from calling context trees and sam-
pled memory addresses, which is very lightweight but brings
sufﬁcient semantics. Furthermore, our model uses convolu-
tional neural networks to embed relative positional informa-
tion of basic blocks in CFGs, which is quite unique.

Shi et al. (Shi et al. 2020) builds graphs by taking instruc-
tions as nodes and value dependency between instructions as
edges, and also takes program snapshots of memory values
for dynamic embedding. However, it involves no any inter-
procedure information and incurs overly much memory and
computation overhead.

There are also several works learning from program rep-
resentation to conduct program repair (Wang, Su, and Singh
2018; Wang and Su 2020), bug detection (Dinella et al.
2020), program classiﬁcation (Lu et al. 2019), cache replace-
ment (Li and Gu 2020; Liu et al. 2020), heap memory wise
program veriﬁcation (Li et al. 2016), and code similarity de-
tection (Yu et al. 2020). Our work is the ﬁrst to apply GNNs
for dead store detection.

Memory wastage analysis. Usage analysis and wastage
analysis are two sister problems. Traditional performance
analysis tools, such as gprof
(Graham, Kessler, and
McKusick 1982), HPCToolkit (Adhianto et al. 2010), and
vTune (VTu 2013) focus on the former, i.e., attributing run-
ning time of a program to code structures at various granu-
larities. In parallel, wastage analysis tells how many com-
putation and memory operations are unnecessary, for ex-
ample, dead store detection (Chabbi and Mellor-Crummey
2012), redundant load checking (Su et al. 2019), run-time
value numbering (Wen et al. 2018) and value locality explo-
ration (Wen, Chabbi, and Liu 2017). Unfortunately, existing
checking tools have limited applicability because of as high
as up to 150× overhead. Our work focuses upon dead store
detection and improves the high overhead by a great margin.

Conclusion
In this paper, we have presented a new learning aided ap-
proach namely GRAPHSPY built upon graph neural net-
works to detect dead stores with reduced overhead. As far as
we know, it is the ﬁrst work that applies GNNs for dead store
detection. We have designed a novel embedding approach
that embeds intra- and inter-procedural structure semantics
and dynamic memory value semantics to enhance the preci-
sion of detection. To detect dead stores across platforms and
compilation options, we have presented a CNN-based ap-
proach for embedding relative positional information. Upon
the evaluation over a set of real-world programs, results turn
out that GRAPHSPY achieves as high as 90% of accuracy.

References

Intel VTune Ampliﬁer XE
2013.
http://software.intel.com/en-us/articles/intel-vtune-
ampliﬁer-xe.

2013.

Adhianto, L.; Banerjee, S.; Fagan, M.; Krentel, M.; Marin,
G.; Mellor-Crummey, J.; and Tallent, N. R. 2010. HPC-
TOOLKIT: Tools for Performance Analysis of Optimized
Parallel Programs Http://Hpctoolkit.Org. Concurrency and
Computation : Practice Experience 22(6): 685–701. ISSN
1532-0626.

Allamanis, M.; Barr, E. T.; Devanbu, P. T.; and Sutton, C. A.
2017. A Survey of Machine Learning for Big Code and Nat-
uralness. CoRR abs/1709.06182. URL http://arxiv.org/abs/
1709.06182.

Ammons, G.; Ball, T.; and Larus, J. R. 1997. Exploit-
ing Hardware Performance Counters with Flow and Context
Sensitive Proﬁling. In Proceedings of the ACM SIGPLAN
Conference on Programming Language Design and Imple-
mentation, 85–96.
Battaglia, P. W.; Hamrick, J. B.; Bapst, V.; Sanchez-
Gonzalez, A.; Zambaldi, V. F.; Malinowski, M.; Tacchetti,
A.; Raposo, D.; Santoro, A.; Faulkner, R.; G¨ulc¸ehre, C¸ .;
Song, H. F.; Ballard, A. J.; Gilmer, J.; Dahl, G. E.; Vaswani,
A.; Allen, K. R.; Nash, C.; Langston, V.; Dyer, C.; Heess,
N.; Wierstra, D.; Kohli, P.; Botvinick, M.; Vinyals, O.; Li,
Y.; and Pascanu, R. 2018. Relational inductive biases, deep
learning, and graph networks. CoRR abs/1806.01261. URL
http://arxiv.org/abs/1806.01261.

Bruening, D. 2004. DynamoRIO: Efﬁcient, Transparent,
and Comprehensive Runtime Code Manipulation.
https:
//dynamorio.org/.

Chabbi, M.; and Mellor-Crummey, J. 2012. DeadSpy:
In Proceed-
A Tool to Pinpoint Program Inefﬁciencies.
ings of the Tenth International Symposium on Code Gen-
eration and Optimization, CGO ’12, 124–134. New York,
ISBN
NY, USA: Association for Computing Machinery.
9781450312066.
doi:10.1145/2259016.2259033. URL
https://doi.org/10.1145/2259016.2259033.
Chung, J.; G¨ulc¸ehre, C¸ .; Cho, K.; and Bengio, Y. 2014.
Empirical Evaluation of Gated Recurrent Neural Networks
on Sequence Modeling. CoRR abs/1412.3555. URL http:
//arxiv.org/abs/1412.3555.

Dinella, E.; Dai, H.; Li, Z.; Naik, M.; Song, L.; and Wang,
K. 2020. HOPPITY: Learning graph transformations to de-
tect and ﬁx bugs in programs. In International Conference
on Learning Representations. URL https://openreview.net/
forum?id=SJeqs6EFvB.
Gilmer, J.; Schoenholz, S. S.; Riley, P. F.; Vinyals, O.; and
Dahl, G. E. 2017. Neural Message Passing for Quantum
Chemistry. CoRR abs/1704.01212. URL http://arxiv.org/
abs/1704.01212.
Graham, S. L.; Kessler, P. B.; and McKusick, M. K. 1982.
gprof: a call graph execution proﬁler (with retrospective). In
Best of PLDI, 49–57.
Hamilton, W.; Ying, Z.; and Leskovec, J. 2017.
Induc-
tive Representation Learning on Large Graphs. In Guyon,
I.; Luxburg, U. V.; Bengio, S.; Wallach, H.; Fergus, R.;
Vishwanathan, S.; and Garnett, R., eds., Advances in Neu-
ral Information Processing Systems 30, 1024–1034. Cur-
ran Associates, Inc. URL http://papers.nips.cc/paper/6703-
inductive-representation-learning-on-large-graphs.pdf.
He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016. Deep Residual
Learning for Image Recognition. 770–778. doi:10.1109/
CVPR.2016.90.
I. Neamtiu, J. F.; and Hicks, M. 2005. Understanding source
code evolution using abstract syntax tree matching. ACM
SIGSOFT Software Engineering Notes 30: 1–5.
Kipf, T. N.; and Welling, M. 2016.
Semi-Supervised
Classiﬁcation with Graph Convolutional Networks. CoRR
abs/1609.02907. URL http://arxiv.org/abs/1609.02907.
Li, P.; and Gu, Y. 2020. Learning Forward Reuse Distance.
ArXiv abs/2007.15859.
Li, Y.; Zemel, R.; Brockschmidt, M.; and Tarlow, D. 2016.
Gated Graph Sequence Neural Networks. In Proceedings of
ICLR’16. URL https://www.microsoft.com/en-us/research/
publication/gated-graph-sequence-neural-networks/.
Liu, E. Z.; Hashemi, M.; Swersky, K.; Ranganathan, P.; and
Ahn, J. 2020. An Imitation Learning Approach for Cache
Replacement. arXiv preprint arXiv:2006.16239 .
Lu, M.; Tan, D.; Xiong, N.; Chen, Z.; and Li, H. 2019.
Program Classiﬁcation Using Gated Graph Attention Neu-
CoRR
ral Network for Online Programming Service.
abs/1903.03804. URL http://arxiv.org/abs/1903.03804.
Mikolov, T.; Chen, K.; Corrado, G. S.; and Dean, J.
2013. Efﬁcient Estimation of Wor Representations in Vector
Space. URL http://arxiv.org/abs/1301.3781.
Nvidia-Inc. 2017. Nvidia Tesla V100 GPU Architec-
ture. https://images.nvidia.com/content/volta-architecture/
pdf/volta-architecture-whitepaper.pdf.
Scarselli, F.; Gori, M.; Tsoi, A. C.; Hagenbuchner, M.; and
Monfardini, G. 2009. The Graph Neural Network Model.
IEEE Transactions on Neural Networks 20(1): 61–80.
Shi, Z.; Swersky, K.; Tarlow, D.; Ranganathan, P.; and
Hashemi, M. 2020.
Learning execution through neu-
In International Conference on Learn-
ral code fusion.
ing Representations. URL https://openreview.net/forum?id=
SJetQpEYvB.

Shoshitaishvili, Y.; Wang, R.; Salls, C.; Stephens, N.;
Polino, M.; Dutcher, A.; Grosen, J.; Feng, S.; Hauser, C.;
Kruegel, C.; and Vigna, G. 2016. SoK: (State of) The Art
of War: Offensive Techniques in Binary Analysis. In IEEE
Symposium on Security and Privacy.
SPEC.
Http://www.spec.org/benchmarks.html#cpu.

Benchmarks.

SPEC

2017.

CPU

Su, P.; Wen, S.; Yang, H.; Chabbi, M.; and Liu, X. 2019.
Redundant Loads: A Software Inefﬁciency Indicator.
In
Proceedings of the 41st International Conference on Soft-
ware Engineering, ICSE ’19, 982–993. IEEE Press. doi:
10.1109/ICSE.2019.00103. URL https://doi.org/10.1109/
ICSE.2019.00103.

Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,
L.; Gomez, A. N.; Kaiser, L.; and Polosukhin, I. 2017. At-
tention Is All You Need. CoRR abs/1706.03762. URL
http://arxiv.org/abs/1706.03762.
Velickovic, P.; Cucurull, G.; Casanova, A.; Romero, A.; Li`o,
P.; and Bengio, Y. 2018. Graph Attention Networks. ArXiv
abs/1710.10903.

Wang, K.; and Su, Z. 2020. Blended, Precise Semantic
Program Embeddings. PLDI 2020, 121–134. New York,
NY, USA: Association for Computing Machinery.
ISBN
doi:10.1145/3385412.3385999. URL
9781450376136.
https://doi.org/10.1145/3385412.3385999.

Wang, K.; Su, Z.; and Singh, R. 2018. Dynamic Neu-
In Inter-
ral Program Embeddings for Program Repair.
national Conference on Learning Representations. URL
https://openreview.net/forum?id=BJuWrGW0Z.

Wen, S.; Chabbi, M.; and Liu, X. 2017. REDSPY: Ex-
ploring Value Locality in Software. In Proceedings of the
Twenty-Second International Conference on Architectural
Support for Programming Languages and Operating Sys-
tems, ASPLOS ’17, 47–61. New York, NY, USA: Associa-
tion for Computing Machinery. ISBN 9781450344654. doi:
10.1145/3037697.3037729. URL https://doi.org/10.1145/
3037697.3037729.

Wen, S.; Liu, X.; Byrne, J.; and Chabbi, M. 2018. Watch-
ing for Software Inefﬁciencies with Witch 53(2): 332–347.
ISSN 0362-1340.
doi:10.1145/3296957.3177159. URL
https://doi.org/10.1145/3296957.3177159.

Yu, Z.; Cao, R.; Tang, Q.; Nie, S.; Huang, J.; and Wu, S.
2020. Order Matters: Semantic-Aware Neural Networks for
In The Thirty-Fourth
Binary Code Similarity Detection.
AAAI Conference on Artiﬁcial Intelligence, AAAI 2020, The
Thirty-Second Innovative Applications of Artiﬁcial Intelli-
gence Conference, IAAI 2020, The Tenth AAAI Symposium
on Educational Advances in Artiﬁcial Intelligence, EAAI
2020, New York, NY, USA, February 7-12, 2020, 1145–1152.
AAAI Press. URL https://aaai.org/ojs/index.php/AAAI/
article/view/5466.

