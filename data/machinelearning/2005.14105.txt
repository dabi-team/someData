Provably Good Solutions to the Knapsack Problem
via Neural Networks of Bounded Size*

Christoph Hertrich† and Martin Skutella
Institute of Mathematics, Technische Universit¨at Berlin
hertrich@math.tu-berlin.de
martin.skutella@tu-berlin.de

1
2
0
2

n
a
J

4

]

G
L
.
s
c
[

2
v
5
0
1
4
1
.
5
0
0
2
:
v
i
X
r
a

Abstract

The development of a satisfying and rigorous mathematical
understanding of the performance of neural networks is a
major challenge in artiﬁcial intelligence. Against this back-
ground, we study the expressive power of neural networks
through the example of the classical NP-hard Knapsack Prob-
lem. Our main contribution is a class of recurrent neural net-
works (RNNs) with rectiﬁed linear units that are iteratively
applied to each item of a Knapsack instance and thereby com-
pute optimal or provably good solution values. We show that
an RNN of depth four and width depending quadratically on
the proﬁt of an optimum Knapsack solution is sufﬁcient to
ﬁnd optimum Knapsack solutions. We also prove the follow-
ing tradeoff between the size of an RNN and the quality of the
computed Knapsack solution: for Knapsack instances con-
sisting of n items, an RNN of depth ﬁve and width w com-
putes a solution of value at least 1 − O(n2/
w) times the
optimum solution value. Our results build upon a classical
dynamic programming formulation of the Knapsack Problem
as well as a careful rounding of proﬁt values that are also at
the core of the well-known fully polynomial-time approxi-
mation scheme for the Knapsack Problem. A carefully con-
ducted computational study qualitatively supports our the-
oretical size bounds. Finally, we point out that our results
can be generalized to many other combinatorial optimization
problems that admit dynamic programming solution meth-
ods, such as various Shortest Path Problems, the Longest
Common Subsequence Problem, and the Traveling Salesper-
son Problem.

√

1

Introduction

Deep learning and neural networks (NNs) are at the heart
of some of the greatest advances in modern computer sci-
ence. They enable huge breakthroughs in applications like
computer vision, translation, speech recognition, and au-
tonomous driving, to name just a few; see, e.g., LeCun,
Bengio, and Hinton (2015). While numerous computational
studies present impressive empirical proof of neural net-
works’ computational power, we are still far away from a
more rigorous theoretical explanation of these observations.
Apart from the popular applications named above, it
has been shown that NNs have high potential for practi-

*A short version of this paper appears in the proceedings of

AAAI 2021.

†Supported by DFG-GRK 2434 Facets of Complexity.

cally solving combinatorial optimization (CO) problems or
empirically improving classical solution methods (Bengio,
Lodi, and Prouvost 2018). For example, Yang et al. (2018)
and Xu et al. (2020) utilize NNs in order to empirically en-
hance dynamic programming, a very classical CO method.
While the methods used in these papers indeed provide fast
and empirically near-optimal solutions, their use of NNs
makes it virtually impossible to give theoretical optimality
or worst-case approximation guarantees. Motivated by this
imbalance, and focusing on the Knapsack Problem, which is
a prime example of CO problems that can be solved via dy-
namic programming, we investigate the following question:

Which neural network size is theoretically sufﬁcient to ﬁnd
solutions of provable quality for the Knapsack Problem?

We give an answer to this question by presenting a class of
carefully constructed NNs with provable quality guarantees
and support our size bounds by a computational study. Fi-
nally, we argue that our approach is not at all speciﬁc for the
Knapsack Problem, but can be generalized to many other CO
problems, e.g., various Shortest Path Problems, the Longest
Common Subsequence Problem, and the Traveling Salesper-
son Problem.

The Knapsack Problem. The Knapsack Problem consti-
tutes one of the oldest and most studied problems in Com-
binatorial Optimization (CO). Given a set of items with cer-
tain proﬁt and size values, as well as a Knapsack capacity,
the Knapsack Problem asks for a subset of items with max-
imum total proﬁt such that the total size of the subset does
not exceed the capacity.

The Knapsack Problem is one of Karp’s 21 original NP-
complete problems (Karp 1972) and has numerous applica-
tions in a wide variety of ﬁelds, ranging from production and
transportation, over ﬁnance and investment, to network se-
curity and cryptography. It often appears as a subproblem at
the core of more complex problems; see, e.g., Martello and
Toth (1990); Kellerer, Pferschy, and Pisinger (2004). This
fact substantiates the Knapsack Problem’s prominent impor-
tance as one of the key problems in CO. In particular, the
Knapsack Problem is frequently being used as a testbed for
measuring the progress of various exact and heuristic solu-
tion approaches and computational methods such as, e.g., in-
teger programming, constraint programming, or evolution-

 
 
 
 
 
 
ary algorithms. In integer programming, for example, the
Knapsack Problem and so-called ‘Knapsack Inequalities’
play a central role, both with respect to theory as well as
in the development of modern computational methods; see,
e.g., Bertsimas and Weismantel (2005); Fischetti and Lodi
(2010). The Knapsack Problem is therefore a natural and
important object of study in order to advance our theoretical
understanding of neural networks and get closer to a rigor-
ous explanation of their stunning success in so many appli-
cations, including miscellaneous optimization problems.

Related work. The idea of using neural networks (NNs)
to practically solve CO problems became popular with the
work of Hopﬁeld and Tank (1985). Hopﬁeld NNs are spe-
cial versions of recurrent neural networks (RNNs) that ﬁnd
solutions to optimization problems by converging towards a
minimum of an energy function. Smith (1999) reviews this
early stream of research. While most authors mainly focus
on the Traveling Salesperson Problem (TSP), Ohlsson, Pe-
terson, and S¨oderberg (1993) study a so-called mean ﬁeld
NN for (generalizations of) the Knapsack Problem and em-
pirically assess the quality of its solutions.

While there has been less research at the intersection of
CO and NNs in the 2000s, modern advances in the area
of deep learning have boosted the interest in this direction
again. Bengio, Lodi, and Prouvost (2018) review these de-
velopments from a practical perspective. Common appli-
cations include speeding up solvers for mixed-integer lin-
ear programs, for instance, by automatically learning on
which variables to branch in branch-and-bound algorithms;
see Lodi and Zarpellon (2017) for a survey. Machine learn-
ing has also been applied to modeling aspects of CO, as
reviewed by Lombardi and Milano (2018), and to several
speciﬁc CO problems, where the TSP is often one of them
(Vinyals, Fortunato, and Jaitly 2015; Bello et al. 2016;
Khalil et al. 2017; Nowak et al. 2017; Emami and Ranka
2018; Kool, van Hoof, and Welling 2019). The different
methods used by these authors include feedforward and
recurrent neural networks, reinforcement learning, atten-
tion mechanisms, pointer networks, graph embeddings, and
graph neural networks. For example, Bello et al. (2016) uti-
lize an RNN trained by reinforcement learning and present
a computational study demonstrating their approach’s em-
pirical effectiveness for the TSP and the Knapsack Problem.
Particularly related to our work, Yang et al. (2018) and Xu
et al. (2020) use NNs to speed up dynamic programming al-
gorithms for CO problems. The key difference to our work,
however, is that NNs are used as heuristics in these papers,
making it virtually impossible to give any meaningful worst-
case performance guarantees.

The recent success of deep neural networks has also trig-
gered a lot of research on their expressivity. As we do in
this paper, many authors focus on the simple but practi-
cally powerful model of feedforward NNs with activations
in the form of rectiﬁed linear units (ReLU). Since Glo-
rot, Bordes, and Bengio (2011) corroborated their empirical
success, such ReLU NNs have been established as a stan-
dard model in Machine Learning within the past decade.

ReLU NNs can compute any continuous piecewise linear
function (Goodfellow et al. 2013; Arora et al. 2018). This
fact implies universal approximation properties. A variety
of results has been achieved on depth vs. width tradeoffs
(Telgarsky 2015; Eldan and Shamir 2016; Telgarsky 2016;
Hanin and Sellke 2017; Liang and Srikant 2017; Safran and
Shamir 2017; Yarotsky 2017; Arora et al. 2018; Nguyen,
Mukkamala, and Hein 2018; Hanin 2019). Closely related
are investigations concerning the number and structure of
linear regions that NNs with certain size and depth may
have (Montufar et al. 2014; Pascanu, Montufar, and Bengio
2014; Raghu et al. 2017; Hanin and Rolnick 2019). Serra,
Tjandraatmadja, and Ramalingam (2018) use mixed-integer
programming for precisely counting the number of such re-
gions. Mukherjee and Basu (2017) prove size lower bounds
to represent Boolean functions with NNs of limited depth.

Our contribution. We present a rigorous mathematical
study on the expressivity of NNs through the example of
the NP-hard Knapsack Problem. To this end, we show that
there is a class of feedforward ReLU NNs of bounded size
that compute provably good solutions to the NP-hard Knap-
sack Problem. In Section 3, we ﬁrst present such an NN of
depth O(n) and width O((p∗)2) that always ﬁnds the exact
value of an optimum Knapsack solution. Here, n is the num-
ber of items in the Knapsack instance, and p∗ is an a priori
known upper bound on the value of an optimum solution.
More precisely, the optimum solution value is found by iter-
atively applying an RNN of depth four and width O((p∗)2)
to the n items of a Knapsack instance. As p∗ can, e.g., be
chosen as the total size of all items, the RNN’s width is
pseudo-polynomially bounded in the input size of the Knap-
sack instance. Due to the Knapsack Problem’s NP-hardness,
however, there is no polynomial-size NN that always ﬁnds
the optimum solution value, unless P = NP.

In Section 4, we prove that the width of the NNs can be
drastically decreased while still obtaining solution values of
provable quality in the worst case. We construct an RNN of
depth ﬁve and ﬁxed width w which, when applied iteratively
to the n items of a Knapsack instance, always produces a
solution value of at least 1 − O(n2/
w) times the optimum
solution value. In particular, an ε-approximate solution value
can be guaranteed by choosing width w ∈ O(n4/ε2). The
dependence of the width on ε is unavoidable, unless P = NP.
To the best of our knowledge, our results establish the ﬁrst
rigorous tradeoff between the size of neural networks for CO
problems and their worst-case solution quality.

√

Even though we cannot show theoretical lower bounds
beyond what is directly implied by NP-hardness, we pro-
vide empirical evidence for the quadratic dependence on p∗
(and 1/ε) in Section 5.

The idea behind our construction of the NNs is to mimic
the classical dynamic program for the Knapsack Problem.
More precisely, the output neurons of the RNN can be seen
as elements of the dynamic programming state space while
the hidden neurons and the network itself implement the re-
cursive dynamic programming formula. Here, the main tech-
nical difﬁculty is to always ﬁlter out the correct entries of the

previous state space (input neurons) needed in the recursive
formula. In addition, our NNs of ﬁxed width rely on a sub-
tle variant of the rounding procedure that turns the pseudo-
polynomial dynamic program into a fully polynomial-time
approximation scheme for the Knapsack Problem.

In this paper, the Knapsack Problem mainly serves as a
prominent showcase for a novel approach to the rigorous
analysis of neural networks’ expressivity. This approach is
by no means speciﬁc for the Knapsack Problem. In Sec-
tion 6, we discuss how it can be applied to NNs for other
combinatorial optimization problems that can be solved via
dynamic programming. In Particular, we establish similar re-
sults for the Longest Common Subsequence Problem, the
Single-Source and All-Pairs Shortest Path Problems, as well
as the NP-hard Traveling Salesperson Problem and the Con-
strained Shortest Path Problem. For the latter problem one
can show similar results on the tradeoff between the size of
NNs and their solution quality.

2 Preliminaries
Neural networks with rectiﬁed linear units. We use def-
initions and notations similar to Shalev-Shwartz and Ben-
David (2014, Chapter 20). A feedforward neural network
with rectiﬁed linear units, abbreviated by ReLU NN, or sim-
ply NN, is a ﬁnite directed acyclic graph (V, E), equipped
with arc weights wuv ∈ R, for each (u, v) ∈ E, and node
biases bv ∈ R, for each node v ∈ V \ V0. Here, V0 is the
set of nodes with in-degree zero. The nodes in V are called
neurons. The depth k is the length of a longest path in the
graph. In the following we suppose that neurons are grouped
into layers V = V0 ·∪ V1 ·∪ · · · ·∪ Vk such that the layer index
strictly increases along each arc.1 Further, we assume that V0
and Vk are precisely the sets of neurons with in-degree and
out-degree zero, respectively. Consequently, they are called
input neurons and output neurons, respectively. Neurons in
V \ (V0 ∪ Vk) are called hidden neurons. Let n(cid:96) = |Vl| be
the number of neurons in the (cid:96)-th layer. The width and size of
the NN are deﬁned to be max{n1, . . . , nk−1} and (cid:80)k−1
(cid:96)=1 n(cid:96),
respectively.

Every NN computes a function Rn0 → Rnk as follows.
Given an input vector x ∈ Rn0 , we associate an activa-
tion a(v) with every neuron v ∈ V \ V0 and an output o(v)
with every neuron v ∈ V \ Vk. First, the output values o(v),
v ∈ V0, of the n0 input neurons equal the n0 components of
input vector x. Second, the activation of a neuron v ∈ V \V0
is the weighted sum of outputs of all predecessors plus its
bias, that is, a(v) = bv + (cid:80)
u : (u,v)∈E wuvo(u). Third, for
each hidden neuron v ∈ V \ (V0 ∪ Vk), the output is deter-
mined by o(v) = σ(a(v)), where σ is the so-called activa-
tion function. In this paper, σ is always the rectiﬁer function
σ(z) = max{0, z}. Neurons having this activation function
are called rectiﬁed linear units (ReLUs). Finally, the output
vector y ∈ Rnk consists of the nk activation values a(v) of

1Some authors only allow connections between successive lay-
ers. One can create such a structure by adding additional neurons
propagating the values of neurons from former layers through the
network. For our purposes, however, it is convenient to omit this
restriction.

-1
1

x1

x2

-1

1

y

Figure 1: An NN with two input neurons, labeled x1 and
x2, one hidden neuron, labeled with the shape of the rec-
tiﬁer function, and one output neuron, labeled y. The arcs
are labeled with their weights and all biases are zero. The
network has depth 2, width 1, and size 1. It computes the
function x (cid:55)→ y = x2 − max{0, x2 − x1} = min{x1, x2}.

1
−
i
h

yi

RNN
cell

xi

i
h

yi+1

RNN
cell

xi+1

Figure 2: Basic structure of an (unfolded) RNN.

the nk output neurons v ∈ Vk. Figure 1 gives an example,
which will also be used as a subnetwork in later sections.

Since feedforward NNs have a ﬁxed input size, a com-
mon way of handling sequential inputs of arbitrary length
is to use recurrent neural networks (RNNs). This type of
NNs has become very popular, e.g., for tasks in language or
speech processing. Essentially, an RNN is a feedforward NN
that is used repeatedly for every piece of the input sequence
and maintains a hidden state by passing (part of) its output
in each step as an additional input to the next step. More
precisely, in the i-th step, the input of the RNN consists of
the i-th input vector xi, as well as, the previous hidden state
vector hi−1. In the same manner as a feedforward NN de-
scribed above, it then computes the i-th output vector yi, as
well as, the new hidden state vector hi. The basic structure
of an RNN is shown in Figure 2. Sometimes it holds that
yi = hi, that is, the i-th output is actually equal to the i-th
hidden state.

Notations and Algorithms for the Knapsack Problem.
An instance of the Knapsack Problem consists of n items
1, 2, . . . , n, where each item i ∈ [n] comes with a given
proﬁt pi ∈ N and size si ∈ ]0, 1], together with a Knap-
sack that can hold any subset M ⊆ [n] of items of total
size (cid:80)
i∈M si at most 1. The task is to ﬁnd such a sub-
set M ⊆ [n] that maximizes the total proﬁt (cid:80)
i∈M pi. Here
and in the following, we use N := {1, 2, 3, . . . } to denote
the natural numbers (without zero), and for every k ∈ N, we
let [k] := {1, 2, . . . , k}.

We outline a classical dynamic programming formulation
for the Knapsack Problem. Let p∗ be an upper bound on the
optimum solution value, e.g., p∗ = (cid:80)n
i=1 pi. For i ∈ [n]
and p ∈ [p∗], let

f (p, i) := min

(cid:110)(cid:88)

j∈M

sj

(cid:12)
(cid:12)
(cid:12) M ⊆ [i],

(cid:88)

j∈M

(cid:111)

pj ≥ p

be the minimum size of a subset of the ﬁrst i items with
total proﬁt at least p. With f (p, i) := 0 for p ≤ 0 and
f (p, 0) := +∞ for p ∈ [p∗], the values of f can be com-
puted recursively by

f (p, i) = min(cid:8)f (p, i − 1), f (p − pi, i − 1) + si

(cid:9)

(1)

for i ∈ [n], p ∈ [p∗], where the ﬁrst option corre-
sponds to not using the i-th item, while the second op-
tion corresponds to using it. The optimum solution value is
max{p ∈ [p∗] | f (p, n) ≤ 1}, and the optimum subset can
easily be found by backtracking. The runtime of the dy-
namic program is O(np∗), thus pseudo-polynomial in the
input size.

Due to NP-hardness of the Knapsack Problem, one can-
not expect to ﬁnd an exact algorithm with polynomial run-
ning time. However, by carefully downscaling and rounding
the proﬁt values in the dynamic program, for each ε > 0,
one can achieve a feasible solution with guaranteed proﬁt
of at least 1 − ε times the optimal proﬁt, while the running
time can be bound polynomially in the input size and 1/ε.
Such a class of algorithms with arbitrary good approxima-
tion guarantees is called a fully polynomial-time approxi-
mation scheme (FPTAS). For more details, we refer to the
books by Hochbaum (1997), Vazirani (2001), or Williamson
and Shmoys (2011).

Usually, the Knapsack Problem is deﬁned with integer
size values si ∈ N and some Knapsack capacity S ∈ N,
bounding the total size of chosen items. Dividing all item
sizes by S transforms such an instance into an instance of
the type considered here. For the case of integral item sizes,
there is also a pseudo-polynomial dynamic programming
formulation parameterized by the size instead of the proﬁt
values; see, e.g., Kleinberg and Tardos (2006, Section 6.4).
Our construction in Section 3 can analogously be applied
to this formulation. This variant, however, does not eas-
ily extend to an FPTAS. We therefore stick to the variant
parametrized by the proﬁt values as introduced above.

3 An Exact RNN for the Knapsack Problem
In this section we introduce the DP-NN, an NN that exactly
executes the dynamic program described in Section 2. In
fact, the DP-NN is an RNN that receives the items one by
one and computes the state space of the dynamic program
for the items seen so far.

Like the dynamic program in Section 2, the DP-NN re-
quires a ﬁxed upper bound p∗ on the optimal objective value
of the Knapsack Problem. We relax this condition in Sec-
tion 4, when we investigate how the FPTAS for the Knap-
sack Problem can be implemented as an NN.

In the i-th step, the DP-NN receives p∗ + 2 inputs, namely
f (p, i − 1) for p ∈ [p∗], as well as pi and si. It computes p∗
output values, namely f (p, i) for p ∈ [p∗]. Hence, overall
it has p∗ + 2 input neurons and p∗ output neurons. Figure 3
illustrates the recurrent structure of the NN, which computes
the state space of the dynamic program.

In the following it is very important to distinguish ﬁxed
parameters of the NN from activation and output values of
neurons that depend on the particular Knapsack instance. We

)
1
−

i
,
·
(
f

DP-NN

)
i
,
·
(
f

DP-NN

pi

si

pi+1

si+1

Figure 3: Recurrent structure of the DP-NN to solve the
Knapsack Problem.

fin(p)

min

fout(p)

fin(p − pin)

+

sin

Figure 4: Desirable architecture for computing fout(p), p ∈
[p∗], from the inputs. However, the existence of an edge
(nonzero weight) depends critically on the input value pin,
which is not allowed.

(cid:9) for p ∈ [p∗]

denote the latter by bold symbols in order to make the differ-
ence visible. Moreover, in order to make the recurrent struc-
ture of our NN obvious, we do not use the index i in the
following description of the network. Instead, we denote the
n0 = p∗ + 2 input values by fin(p) for p ∈ [p∗], as well as
pin and sin. The p∗ output values are denoted by fout(p) for
p ∈ [p∗]. The goal is to implement the recursion
fout(p) = min(cid:8)fin(p), fin(p − pin) + sin
in an NN; cp. (1). It consists of an addition and taking a min-
imum, which are both simple operations for an NN. Hence,
ideally, we would like to have an architecture as depicted in
Figure 4 for computing fout(p) for every p ∈ [p∗]. The prob-
lem with this is, however, that the decision which compo-
nent of fin is accessed in order to compute the sum with sin
depends on the input value pin. Since we aim for an archi-
tecture that is ﬁxed and works for general input values pin,
we have to extend our construction as depicted in Figure 5.
As we do not know the value of pin in advance, we connect
every input neuron fin(p − p(cid:48)), p(cid:48) ∈ [p − 1], to the unit that
computes the sum fin(p − pin) + sin. Since we only want to
take the value fin(p − pin) into account, we need to add an
additional unit that disables those connections if p(cid:48) (cid:54)= pin.

fin(p)

min

fout(p)

fin(p − p(cid:48))

+

p(cid:48) ?= pin

pin

sin

Figure 5: High-level idea how the DP-NN computes fout(p)
for p ∈ [p∗] from the inputs.

Due to the integrality of the proﬁt values, this additional
unit can be realized with two hidden layers and a con-
stant number of neurons for every value of p ∈ [p∗] and
p(cid:48) ∈ [p − 1], as we show in Appendix A. Computing the
minimum adds a third hidden layer. Hence, the DP-NN has
depth four while width and size are in O((p∗)2). Unfolding
the RNN and viewing it as a single feedforward NN execut-
ing the whole dynamic program results in depth O(n) and
size O(n(p∗)2). In Appendix A we provide a detailed con-
struction of the DP-NN and prove the following theorem.

Theorem 1. For a Knapsack instance with capacity S = 1,
si ∈ ]0, 1], and pi ∈ N, for i ∈ [n], with an upper bound p∗
on the optimal solution value, the corresponding dynamic
programming values f (p, i), i ∈ [n], p ∈ p∗, can be exactly
computed by iteratively applying the DP-NN n times.

Observe that due to the NP-hardness of the Knapsack
Problem, the dependence of the network size on p∗ cannot
be avoided if exact results are desired.

4 Smaller RNNs with Provable
Approximation Guarantees

In order to overcome the drawback due to the dependence
of the network width on p∗, we provide a construction,
called FPTAS-NN, that uses less neurons, at the cost of los-
ing optimality. Instead, we prove an approximation ratio
(i.e., a worst-case bound) for the solution value computed
by the FPTAS-NN. As in the standard Knapsack FPTAS
(Hochbaum 1997; Vazirani 2001; Williamson and Shmoys
2011), the idea of this construction is to round the proﬁt
values if p∗ becomes too large for an exact computation.
Our approximation result can be interpreted as a tradeoff be-
tween the width of the NN and the quality of the Knapsack
solution obtained.

i = (cid:80)i

Let P ∈ N be a ﬁxed number. The FPTAS-NN computes
values g(p, i) for every p ∈ [P ] and i ∈ [n]. These values
are similar to the values f (p, i) of the previous section, there
is, however, one major difference. Let p∗
j=1 pj be the
total proﬁt of the ﬁrst i items. As soon as p∗
i exceeds P , we
can no longer store a required size value for every possible
proﬁt value but have to round proﬁts instead. The granular-
ity we want to use for rounding is di := max{1, p∗
i /P }. We
construct the FPTAS-NN to compute values g(p, i), p ∈ [P ],
i ∈ [n], such that we can guarantee the existence of a sub-
set of [i] that has size at most g(p, i) and proﬁt at least p di.
Moreover, this is done in such a way that the optimal so-
lution cannot have a considerably higher proﬁt value. That
is, we prove a worst-case approximation guarantee for the
solution found by the FPTAS-NN.

In addition to the values of g, the FPTAS-NN must also
propagate the current total proﬁt value p∗
i through the net-
work in order to determine the rounding granularity in each
step. Hence, in the i-th step, it receives P + 3 inputs, namely
g(p, i − 1) for p ∈ [P ], p∗
i−1, pi, and si. It computes P + 1
outputs, namely g(p, i) for p ∈ [P ] and p∗
i . Figure 6 illus-
trates the recurrent structure of this NN.

As in Section 3, we use bold symbols in order to dis-
tinguish input, activation, and output values that depend on

)
1
−

i
,
·
(
g

p∗
i−1

FPTAS-NN

)
i
,
·
(
g

p∗
i

FPTAS-NN

pi

si

pi+1

si+1

Figure 6: Recurrent structure of the FPTAS-NN for the
Knapsack Problem.

the concrete Knapsack instance from ﬁxed parameters of the
network. We again drop the index i in order to make the re-
current structure obvious. We denote the n0 = P + 3 input
parameters by gin(p), for p ∈ [P ], as well as p∗
in, pin, and
sin. The P + 1 output values are denoted by gout(p), for
p ∈ [P ], and p∗
out. Similar to the DP-NN in Section 3, the
basic idea is to implement a recursion of the type
(cid:9) for p ∈ [P ],
gout(p) = min(cid:8)gin(p(1)), gin(p(2)) + sin
where the ﬁrst argument of the minimum represents the op-
tion of not using item i, while the second one corresponds to
using it. Notice, however, that p(1) and p(2) cannot simply
be calculated as p and p − pin, respectively, since we may
have to round with different granularities in two successive
steps. Therefore, the rough structure of the FPTAS-NN is as
follows: ﬁrst, p∗
in and pin are used in order to calculate the
old and new rounding granularities dold = max{1, p∗
in/P }
and dnew = max{1, (p∗
in + pin)/P }. Since this computa-
tion consists of maxima and weighted sums only, it can eas-
ily be achieved by an NN with one hidden layer. Second,
the granularities are used in order to select gin(p(1)) and
gin(p(2)) from the inputs. Below we give some more de-
tails on how this is being done. The value of p(2) also de-
pends on pin. Third, the ﬁnal recursion is established as in
the DP-NN. In addition to gout(p), for p ∈ [P ], we also out-
put p∗
in + pin in order to keep track of the rounding
granularities in subsequent steps. An overview of the entire
network structure is given in Figure 7.

out = p∗

Suppose we use the network for processing the i-th
item. For each p ∈ [P ] we want to determine a (prefer-
ably small) value gout(p) such that
there is a subset
of [i] of total proﬁt at least p dnew and total size at most
gout(p). For each p(cid:48) ∈ [P ], we know that there is a
least p(cid:48)dold and to-
subset of [i − 1] of total proﬁt at
tal size at most gin(p(cid:48)). We have two options: ignoring
item i or using it. If we ignore it, then each p(1) with
p(1)dold ≥ p dnew allows us to choose gout(p) = gin(p(1)).
then each p(2)
If we do use the i-th item, however,
with the property p(2)dold + pin ≥ p dnew allows us to
choose gout(p) = gin(p(2)) + sin. Hence, we want
to
choose p(1) and p(2) as small as possible such that
these properties are fulﬁlled. Therefore, the units labeled
‘Select gin(p(1))’ and ‘Select gin(p(2))’ in Figure 7 are con-
structed by setting all other connections to zero except for

gin(P )

·

·

·

gin(1)

p∗
in

Com-
pute
dold

Com-
pute
dnew

+

pin

Select
gin(p(1))

Select
gin(p(2))

+

min

gout(p)

sin

p∗

out

Figure 7: High-level idea how the FPTAS-NN computes
gout(p), p ∈ [P ], and p∗

out from the inputs.

those belonging to the smallest values of p(1) and p(2)
satisfying the above properties. Similar to how we com-
puted fin(p − pin) in the previous section, this requires two
hidden layers and O(P 2) neurons in total.

In total, the FPTAS-NN has depth 5. The ﬁrst hidden layer
computes the rounding granularities, two hidden layers are
required to select gin(p(1)) and gin(p(2)) and a ﬁnal hidden
layer computes the minimum in the actual recursion. The
width and size of the FPTAS-NN are in the order of O(P 2).
Unfolding the RNN and viewing it as a single feedforward
NN executing the whole FPTAS results in depth O(n) and
size O(nP 2).

In Appendix B we provide a formal description of the
FPTAS-NN as well as proofs of the following two theorems.
The ﬁrst one ensures that the FPTAS-NN produces only fea-
sible Knapsack solutions, while the second one shows that
the FPTAS-NN indeed provides a fully polynomial-time ap-
proximation scheme to solve the Knapsack Problem.

Theorem 2. Suppose the FPTAS-NN is applied to a Knap-
sack instance with capacity S = 1, si ∈ ]0, 1], and pi ∈ N,
for i ∈ [n]. For every i ∈ [n] and every p ∈ [P ], if
g(p, i) ≤ 1, then there exists a subset of [i] with proﬁt at
least pdi and size at most g(p, i).
Theorem 3. For a Knapsack instance with capacity S = 1,
si ∈ ]0, 1], pi ∈ N, for i ∈ [n], and for ε ∈ ]0, 1], set
P := (cid:100)n2/ε(cid:101). Let pOPT be the proﬁt of the optimal solution
and pNN = max{pdn | g(p, n) ≤ 1} be the best possible
proﬁt found by the FPTAS-NN. Then pNN ≥ (1 − ε)pOPT.

Theorem 3 implies a tradeoff between the width of the NN
and the precision of the Knapsack solution in the following
sense. For achieving an approximation ratio of 1 − ε, an NN
of width O(P 2) = O(n4/ε2) is required. In other words,
the FPTAS-NN with ﬁxed width w achieves a worst-case
approximation ratio of 1 − O(n2/

w).

√

Observe that, assuming P (cid:54)= NP, it is clear that the size of
the NN must grow if ε tends to zero. Hence, complexity the-
ory implies that a width-quality trade-off cannot be avoided.
Still, it remains as an open question whether the growth rates
implied by our construction are best possible.

5 Empirical Evidence for Quadratic Width
While the running time of the classical Knapsack dynamic
program depends only linearly on p∗, the width of the
DP-NN is O((p∗)2). In our construction, the quadratic factor
arises from dynamically ﬁnding fin(p − pin) in a hard-coded
network, as explained in Section 3. For similar reasons, the
width of the FPTAS-NN grows with 1/ε2 instead of 1/ε.

The natural question to ask is whether this quadratic de-
pendence can be avoided by a different construction. While
this question remains open from a purely theoretical point of
view, in this section, we provide empirical evidence that the
quadratic factor might indeed be necessary due to inherent
properties of ReLU feedforward NNs.

For details about the experimental setup, including used
soft- and hardware, random data generation and systematic
of seeds, training and testing setup, hyperparameters, as well
as, the source code, please refer to Appendix D. Here we
only include the necessary information to understand the key
ﬁndings.

Similar to the DP-NN of Section 3, we train an NN with
three hidden layers and variable width to execute one step of
the Knapsack dynamic program, that is, to map fin, pin, and
sin to fout, for random Knapsack instances. For the 25 differ-
ent values {3, 6, 9, . . . , 75} of p∗, we increase the width in
steps of 25 until a mean squared error (MSE) loss of at most
0.005 is reached. The threshold 0.005 is carefully chosen
such that NNs with reasonable width are empirically able to
achieve it. In Appendix C, we also show that other thresh-
olds yield similar results. Figure 8 shows for each value of
p∗ the required width to achieve an MSE of at most 0.005.

In order to statistically test whether a quadratic depen-
dence is more likely than a linear relation, we use linear re-
gression. Assuming the required width is given by a function
width = a0 + a1p∗ + a2(p∗)2 + noise,
the resulting least squares regression curve can be seen in
Figure 8. Testing the null hypothesis a2 = 0 against the
alternative a2 (cid:54)= 0, we obtain a p-value of 1.1 %, which we
judge to be signiﬁcant evidence that a quadratic relation is
more likely than a linear one.

Of course, one should take this result with a grain of salt
since the superlinear relation might have multiple reasons.
For instance, it is unclear, whether the difﬁculty to train
larger networks has a stronger effect than the expressivity
of ReLU NNs. Still, we ﬁnd that this computational study
supports our theoretical size bounds.

6 Neural Networks for Other CO Problems
In this section we demonstrate that our approach is by no
means bound to the Knapsack Problem. In fact, for many
other CO problems it is possible to convert a dynamic pro-
gramming solution method into a provably correct NN. For
certain NP-hard CO problems, a dynamic programming so-
lution even implies the existence of a fully polynomial-
time approximation scheme (Woeginger 2000). This, in turn,
might shed light on the tradeoff between size of correspond-
ing NNs and their solution quality, as for the Knapsack Prob-
lem in Section 4. In the following we provide several exam-
ples in order to support these claims.

with n = |V | is O(n3), which can naturally be parallelized
into O(n) rounds. Since the best known NNs for computing
the minimum of n numbers require O(log n) depth (Arora
et al. 2018), there exists an NN executing the Bellman-Ford
algorithm with depth O(n log n) and size O(n3 log n). Ob-
serve that in each round i ∈ [n], the computation mapping
the values f (i − 1, v), v ∈ V , to f (i, v), v ∈ V , is the same.
Therefore, this NN can also be seen as an RNN of depth
O(log n) and size O(n2 log n) that is applied n times.

All-Pairs Shortest Path Problem. Third, recall that the
All-Pairs Shortest Path Problem can be solved by comput-
ing the (n − 1)-th min-plus matrix power of the length ma-
trix (cuv)u,v∈V , see, e.g., Leighton (1991, Section 2.5.4). By
repeated squaring, this can be achieved with only O(log n)
min-plus matrix multiplications. For a single multiplication
it is required to compute O(n2) times in parallel the min-
imum of n numbers. One of these minimum computations
requires depth O(log n) and size O(n log n). Putting them
in parallel to execute one min-plus matrix product results in
depth O(log n) and size O(n3 log n). Note that the whole
execution consists of O(log n) repetitions of the same pro-
cedure, namely squaring a matrix in the min-plus sense.
Hence, this can again be viewed as an RNN with depth
O(log n) and size O(n3 log n) that is applied O(log n)
times. Unfolding results in a single feedforward NN with
depth O(log2 n) and size O(n3 log2 n) for solving the All-
Pairs Shortest Path Problem.

Constrained Shortest Path Problem. Next, consider a
common generalization of the Shortest Path Problem and the
Knapsack Problem, namely the NP-hard Constrained Short-
est Path Problem. Here, in addition to a (nonnegative) length
matrix (cuv)u,v∈V , the input graph is also equipped with
a (nonnegative) resource matrix (ruv)u,v∈V . The task is to
ﬁnd a minimum length path P from a source vertex s to any
other vertex, but this time subject to a resource constraint
(cid:80)
(u,v)∈P ruv ≤ R for a given resource limit R. An exten-
sive overview of solution approaches to this problem can be
found, e.g., in the dissertation by Ziegelmann (2001). Simi-
lar to the Knapsack Problem, there exist two natural pseudo-
polynomial dynamic programs, one of them parametrized by
length values and the other one by resource values. Both can
be implemented on an NN by combining the ideas from Sec-
tion 3 with the NN for the Bellmann-Ford algorithm above.
We showcase this for the variant parametrized by the length
values. This dynamic program recursively calculates val-
ues f (c, v) representing the minimum amount of resource
needed for a path from s to v with length at most c by
f (c, v) = min(cid:8)f (c − 1, v), minu∈V \{v}{f (c − cuv, u) + ruv}(cid:9).
For ﬁxed c, u, and v, the term f (c − cuv, u) + ruv can
be calculated by a similar construction as we computed
fin(p − pin) + sin in Section 3. Assuming an upper bound c∗
on the optimal objective value, this can be achieved with
constant depth and O(c∗) width. Hence, it remains to com-
pute a minimum of at most n numbers in order to com-
pute f (c, v). Thus, each single value f (c, v) can be com-
puted with depth O(log n) and size O(nc∗ log n). We have

Figure 8: Required network width to achieve a mean squared
error of at most 0.005 as a function of p∗.

Longest Common Subsequence. First, consider the prob-
lem of ﬁnding the length of the longest common subse-
quence of two ﬁnite integer sequences x1, x2, . . . , xm and
y1, y2, . . . , yn. A standard dynamic programming proce-
dure, see, e.g., Cormen et al. (2001, Section 15.4), com-
putes values f (i, j) equal to the length of the longest com-
mon subsequence of the partial sequences x1, x2, . . . , xi and
y1, y2, . . . , yj by applying the recursion

f (i, j) =

(cid:26) f (i − 1, j − 1) + 1

if xi = yj,
max(cid:8)f (i − 1, j), f (i, j − 1)(cid:9) if xi (cid:54)= yj.

Since the sequence consists of integers, the check whether
xi equals yj can be performed similarly to checking whether
p(cid:48) = pin in Section 3. The remainder of the recursion only
consists of maxima and sums. Hence, computing f (i, j)
from f (i − 1, j − 1), f (i − 1, j), f (i, j − 1), xi, and yj
can be realized via an NN of constant size. These basic units
can be plugged together in a two-dimensional way for com-
puting all values f (i, j), i ∈ [m], j ∈ [n]. The resulting
NN can be seen as a two-dimensional RNN of constant size
that is applied in an m by n grid structure, an architecture
introduced by Graves, Fern´andez, and Schmidhuber (2007).
Unfolding the RNN results in a feedforward NN of depth
O(m + n) and size O(mn) for computing the length of the
longest common subsequence.

Single-Source Shortest Path Problem. As a second ex-
ample, we consider the Bellman-Ford algorithm for the
Single-Source Shortest Path Problem, see, e.g., Kleinberg
and Tardos (2006, Section 6.8). If (cuv)u,v∈V is the length
matrix of a graph with vertex set V and s ∈ V is the source
vertex, this algorithm recursively computes values f (i, v)
determining the shortest possible length of a path from s
to v using at most i arcs by

f (i, v) = min
u∈V

{f (i − 1, u) + cuv}.

Since this recursion consists only of sums and minima, it can
be easily implemented in an NN. The sequential time com-
plexity of the Bellman-Ford algorithm on complete digraphs

010203040506070p*100200300400widthRequired width for MSE loss 0.005ObservationsQuadratic Regression Lineprocedure to convert dynamic programs into ReLU NNs.
Ideally, one could exactly classify the type of dynamic
programs that guarantee the existence of a corresponding
ReLU NN. Similar in spirit, Woeginger (2000) classiﬁes
dynamic programs that guarantee the existence of a fully
polynomial-time approximation scheme.

to compute O(nc∗) of these values, but for ﬁxed c, all these
values can be computed in parallel. Therefore, the whole
dynamic program can be executed on an NN with depth
O(c∗ log n) and a total size of O(n2(c∗)2 log n). This is
pseudo-polynomial, which is the best we can hope for due
to the NP-hardness of the problem. Moreover, similar to
the Knapsack Problem, this dynamic program can be turned
into an FPTAS by downscaling and rounding the length val-
ues. This observation can be used to obtain a width-quality
tradeoff for the Constrained Shortest Path Problem similar
to what we have shown in Section 4.

Traveling Salesperson Problem. Finally, consider the
Bellman-Held-Karp algorithm for solving the (asymmetric)
Traveling Salesperson Problem (TSP), see Bellman (1962);
Held and Karp (1962). Given a (complete, directed) graph
with vertex set V and distances cuv from vertex u ∈ V to
vertex v ∈ V , the TSP asks for the shortest round-trip visit-
ing each vertex exactly once. Choosing an arbitrary starting
vertex s ∈ V , the Bellman-Held-Karp algorithm recursively
computes values f (T, v) for each T ⊆ V \ {s}, v ∈ T ,
corresponding to the length of the shortest s-v-path visiting
exactly the nodes in T ∪ {s} by the formula

f (T, v) = min

u∈T \{v}

{f (T \ {v}, u) + cuv} .

The length of the shortest TSP tour is then given by
minu∈V \{s} {f (V \ {s}, u) + cus}. While the sequential
time complexity of this algorithm on digraphs with n = |V |
is O(n22n), in an NN we can compute the values of f for
all T with equal cardinality in parallel. As before, comput-
ing the minimum introduces an additional factor of log n
in the depth and size of the network. Hence, in total, the
TSP can be solved with an NN of depth O(n log n) and size
O(n22n log n). In particular, a polynomially deep NN suf-
ﬁces to solve the NP-hard (asymmetric) TSP.

7 Conclusions and Future Work
An obvious open problem is to improve the obtained bounds
on the required width of our neural network constructions.
In particular, an interesting question is whether meaningful
lower bounds beyond those immediately implied by the NP-
hardness of the Knapsack Problem can be obtained, as sug-
gested by our experimental results.

Notice that our networks only output the solution value
but not the corresponding solution, i.e., subset of items. It
is easy to see that, as for the dynamic program solving the
Knapsack Problem, the subset of items can be obtained in
a straightforward way via backtracking. On the other hand,
notice that it is impossible for a ReLU NN (without thresh-
old gates) to output (the characteristic vector of) the op-
timum subset of items: while the function computed by a
ReLU NN is piecewise linear and continuous (Goodfellow
et al. 2013; Arora et al. 2018), already inﬁnitesimal changes
of the input (i.e., the proﬁt values of items) might change the
optimum subset of items.

Another interesting direction for future research is to gen-
eralize our results of Section 6 by describing a general

References
Arora, R.; Basu, A.; Mianjy, P.; and Mukherjee, A. 2018.
Understanding Deep Neural Networks with Rectiﬁed Linear
Units. In International Conference on Learning Represen-
tations.

Bellman, R. 1962. Dynamic programming treatment of the
travelling salesman problem. Journal of the ACM 9(1): 61–
63.

Bello, I.; Pham, H.; Le, Q. V.; Norouzi, M.; and Bengio, S.
2016. Neural Combinatorial Optimization with Reinforce-
ment Learning. arXiv:1611.09940 .

Bengio, Y.; Lodi, A.; and Prouvost, A. 2018. Machine
Learning for Combinatorial Optimization: a Methodological
Tour d’Horizon. arXiv:1811.06128 .

Bertsimas, D.; and Weismantel, R. 2005. Optimization over
Integers. Dynamic Ideas.

Cormen, T. H.; Leiserson, C. E.; Rivest, R. L.; and Stein, C.
2001. Introduction to algorithms. MIT press, second edition.

Eldan, R.; and Shamir, O. 2016. The power of depth for
In Conference on Learning
feedforward neural networks.
Theory, 907–940.

Emami, P.; and Ranka, S. 2018. Learning Permutations with
Sinkhorn Policy Gradient. arXiv:1805.07010 .

Fischetti, M.; and Lodi, A. 2010. On the knapsack closure
of 0-1 Integer Linear Programs. Electronic Notes in Discrete
Mathematics 36: 799–804.

Glorot, X.; Bordes, A.; and Bengio, Y. 2011. Deep sparse
rectiﬁer neural networks. In Proceedings of the fourteenth
international conference on artiﬁcial intelligence and statis-
tics, 315–323.

Goodfellow, I.; Warde-Farley, D.; Mirza, M.; Courville, A.;
and Bengio, Y. 2013. Maxout Networks. In International
Conference on Machine Learning, 1319–1327.

Graves, A.; Fern´andez, S.; and Schmidhuber, J. 2007. Multi-
In International
dimensional recurrent neural networks.
Conference on Artiﬁcial Neural Networks, 549–558.

Hanin, B. 2019. Universal function approximation by
deep neural nets with bounded width and ReLU activations.
Mathematics 7(10): 992.

Hanin, B.; and Rolnick, D. 2019. Complexity of Linear Re-
In International Conference on
gions in Deep Networks.
Machine Learning, 2596–2604.

Hanin, B.; and Sellke, M. 2017. Approximating con-
tinuous
functions by ReLU nets of minimal width.
arXiv:1710.11278 .

Held, M.; and Karp, R. M. 1962. A dynamic programming
approach to sequencing problems. Journal of the Society for
Industrial and Applied Mathematics 10(1): 196–210.

Hochbaum, D. S. 1997. Various Notions of Approximations:
In Hochbaum, D. S., ed.,
Good, Better, Best, and More.
Approximation Algorithms for NP-hard Problems, 346–446.
PWS Publishing Co.

Hopﬁeld, J. J.; and Tank, D. W. 1985. “Neural” computation
of decisions in optimization problems. Biological Cybernet-
ics 52(3): 141–152.
Karp, R. M. 1972. Reducibility among combinatorial prob-
lems. In Miller, R. E.; and Thatcher, J. W., eds., Complexity
of Computer Computations, 85–103. Springer.
Kellerer, H.; Pferschy, U.; and Pisinger, D. 2004. Knapsack
Problems. Springer.
Khalil, E.; Dai, H.; Zhang, Y.; Dilkina, B.; and Song, L.
2017. Learning Combinatorial Optimization Algorithms
In Guyon, I.; Luxburg, U. V.; Bengio, S.;
over Graphs.
Wallach, H.; Fergus, R.; Vishwanathan, S.; and Garnett, R.,
eds., Advances in Neural Information Processing Systems
30, 6348–6358.
Kleinberg, J.; and Tardos, E. 2006. Algorithm Design. Pear-
son Education.
Kool, W.; van Hoof, H.; and Welling, M. 2019. Attention,
Learn to Solve Routing Problems! In International Confer-
ence on Learning Representations.
LeCun, Y.; Bengio, Y.; and Hinton, G. 2015. Deep learning.
Nature 521: 436–444.
Introduction to parallel algorithms
Leighton, F. T. 1991.
and architectures: Arrays · trees · hypercubes. Morgan-
Kaufmann.
Liang, S.; and Srikant, R. 2017. Why deep neural networks
for function approximation? In International Conference on
Learning Representations.
Lodi, A.; and Zarpellon, G. 2017. On learning and branch-
ing: a survey. TOP 25(2): 207–236.
Lombardi, M.; and Milano, M. 2018. Boosting combinato-
rial problem modeling with machine learning. In Proceed-
ings of the 27th International Joint Conference on Artiﬁcial
Intelligence, 5472–5478.
Martello, S.; and Toth, P. 1990. Knapsack Problems: Algo-
rithms and Computer Implementations. John Wiley & Sons.
Montufar, G. F.; Pascanu, R.; Cho, K.; and Bengio, Y.
2014. On the Number of Linear Regions of Deep Neu-
ral Networks. In Ghahramani, Z.; Welling, M.; Cortes, C.;
Lawrence, N. D.; and Weinberger, K. Q., eds., Advances in
Neural Information Processing Systems 27, 2924–2932.
Mukherjee, A.; and Basu, A. 2017. Lower bounds over
Boolean inputs for deep neural networks with ReLU gates.
arXiv:1711.03073 .
Nguyen, Q.; Mukkamala, M. C.; and Hein, M. 2018. Neural
Networks Should Be Wide Enough to Learn Disconnected
Decision Regions. In International Conference on Machine
Learning, 3737–3746.
Nowak, A.; Villar, S.; Bandeira, A. S.; and Bruna, J. 2017.
Revised Note on Learning Algorithms for Quadratic Assign-
ment with Graph Neural Networks. arXiv:1706.07450 .
Ohlsson, M.; Peterson, C.; and S¨oderberg, B. 1993. Neural
Networks for Optimization Problems with Inequality Con-
straints: The Knapsack Problem. Neural Computation 5(2):
331–339.

Pascanu, R.; Montufar, G.; and Bengio, Y. 2014. On the
number of inference regions of deep feed forward networks
with piece-wise linear activations. In International Confer-
ence on Learning Representations.
Raghu, M.; Poole, B.; Kleinberg, J.; Ganguli, S.; and Dick-
stein, J. S. 2017. On the Expressive Power of Deep Neural
Networks. In International Conference on Machine Learn-
ing, 2847–2854.
Safran, I.; and Shamir, O. 2017. Depth-width tradeoffs in
approximating natural functions with neural networks. In In-
ternational Conference on Machine Learning, 2979–2987.
Serra, T.; Tjandraatmadja, C.; and Ramalingam, S. 2018.
Bounding and Counting Linear Regions of Deep Neural
Networks. In International Conference on Machine Learn-
ing, 4565–4573.
Shalev-Shwartz, S.; and Ben-David, S. 2014. Understanding
machine learning: From theory to algorithms. Cambridge
University Press.

Smith, K. A. 1999. Neural Networks for Combinatorial Op-
timization: A Review of More Than a Decade of Research.
INFORMS Journal on Computing 11(1): 15–34.
Telgarsky, M. 2015. Representation Beneﬁts of Deep Feed-
forward Networks. arXiv:1509.08101 .
Telgarsky, M. 2016. Beneﬁts of depth in neural networks. In
Conference on Learning Theory, 1517–1539.
Vazirani, V. V. 2001. Approximation Algorithms. Springer.
Vinyals, O.; Fortunato, M.; and Jaitly, N. 2015. Pointer
Networks.
In Cortes, C.; Lawrence, N. D.; Lee, D. D.;
Sugiyama, M.; and Garnett, R., eds., Advances in Neural In-
formation Processing Systems 28, 2692–2700.
Williamson, D. P.; and Shmoys, D. B. 2011. The design of
approximation algorithms. Cambridge University Press.
Woeginger, G. J. 2000. When does a dynamic programming
formulation guarantee the existence of a fully polynomial
time approximation scheme (FPTAS)? INFORMS Journal
on Computing 12(1): 57–74.
Xu, S.; Panwar, S. S.; Kodialam, M. S.; and Lakshman, T. V.
2020. Deep Neural Network Approximated Dynamic Pro-
gramming for Combinatorial Optimization. In AAAI Con-
ference on Artiﬁcial Intelligence, 1684–1691.
Yang, F.; Jin, T.; Liu, T.-Y.; Sun, X.; and Zhang, J. 2018.
Boosting Dynamic Programming with Neural Networks for
In Asian Conference on Ma-
Solving NP-hard Problems.
chine Learning, 726–739.
Yarotsky, D. 2017. Error bounds for approximations with
deep ReLU networks. Neural Networks 94: 103–114.
Ziegelmann, M. 2001. Constrained Shortest Paths and Re-
lated Problems. Ph.D. thesis, Universit¨at des Saarlandes
Saarbr¨ucken.

A Detailed Construction of the DP-NN
In this section we formally describe the DP-NN and prove
its correctness.

(cid:9)

Note that for size values larger than the Knapsack capac-
ity, which is equal to 1 by our deﬁnition, we do not re-
ally care how large they actually are. Therefore, we deﬁne
˜f (p, i) = min{f (p, i), 2} to be the values of the dynamic
program truncated at 2. In other words, we replace all values
in the interval [2, +∞] by 2. Note that the recursion
˜f (p, i) = min(cid:8) ˜f (p, i − 1), ˜f (p − pi, i − 1) + si

(2)
is still valid with starting values ˜f (p, i) = 0 for p ≤ 0 and
˜f (p, 0) = 2 for p ∈ [p∗]. Instead of computing the actual
values of f , the DP-NN computes the values of ˜f .

The DP-NN has three hidden layers. After the n0 = p∗+2
input neurons fin(p) for p ∈ [p∗], pin, and sin, the ﬁrst
hidden layer consists of n1 = 2p∗ neurons whose outputs
are denoted by o(+)
(k) and o(−)
(k) for k ∈ [p∗]. Its role
is to detect whether k = pin. If yes, then both o(+)
(k)
and o(−)
(k) should be zero, otherwise at least one of them
should be large (i.e., at least 2). In the second hidden layer,
we have n2 = p∗(p∗ − 1)/2 neurons, denoted by o2(p, k)
for p ∈ [p∗] and k ∈ [p − 1]. A neuron in this layer should
output fin(p − pin) if k = pin and zero otherwise. This
way, the sum (cid:80)p−1
k=1 o2(p, k) equals fin(p − pin). The third
hidden layer has n3 = p∗ neurons, denoted by o3(p) for
p ∈ [p∗]. It is used for computing the minimum of fin(p)
and sin + fin(p − pin) as in Figure 1. Finally, the n4 = p∗
output values are denoted by fout(p) for p ∈ [p∗]. The fol-
lowing equations deﬁne the DP-NN.

1

1

1

1

(k) = σ(2(pin − k)),

o(+)
1
o(−)
(k) = σ(2(k − pin)),
1
o2(p, k) = σ(fin(p − k) − o(+)

1

(k) − o(−)

1

(k)),

(cid:18)

(cid:18)

o3(p) = σ

fin(p) −

sin +

(cid:88)p−1
k=1

o2(p, k)

(cid:19)(cid:19)

fout(p) = fin(p) − o3(p),

k ∈ [p∗],

(3a)

k ∈ [p∗],

(3b)
p ∈ [p∗], k ∈ [p − 1],
(3c)

, p ∈ [p∗],

p ∈ [p∗].

(3d)

(3e)

Our next goal is to prove Theorem 1, which states that the
DP-NN indeed solves the Knapsack Problem exactly. We do
so by going through the NN layer by layer and show what
the individual layers do.

As mentioned, the role of the ﬁrst hidden layer is to de-
tect the input value of pin and to provide a large value for
every k that is not equal to pin. The following lemma fol-
lows immediately from the construction and the properties
of the rectiﬁer function σ.
Lemma 4. Let pin ∈ N. Then, for every k ∈ [p∗], it holds
that o(+)
(k) = 0 if and only if k = pin, and
o(+)
1

1
(k) + o(−)

(k) ≥ 2 otherwise.

(k) + o(−)

1

1

The role of the second layer is to compute fin(p − pin),
which is needed in the dynamic program. The main difﬁ-
culty of this step is that it depends on the input pin which
neuron to access. Therefore, this is computed for every pos-
sible value k of pin and set to zero if k (cid:54)= pin. The following
lemma explains how this is established.

Lemma 5. Let pin ∈ N and fin(p) ∈ ]0, 2] for every p ∈
[p∗]. Then, for every p ∈ [p∗] and every k ∈ [p − 1], it holds
that o2(p, k) = fin(p − pin) if and only if k = pin, and
o2(p, k) = 0 otherwise.

1

Proof. If k = pin, we obtain from Lemma 4 that o(+)
(k) +
o(−)
(k) = 0. Thus, due to nonnegativity of fin(p − k), we
1
obtain o2(p, k) = σ(fin(p−k)) = fin(p−k) = fin(p−pin).
(k) +
(k) ≥ 2. Thus, due to fin(p − k) ≤ 2, we ob-
(k) ≤ 0, which implies

If k (cid:54)= pin, we obtain from Lemma 4 that o(+)

o(−)
1
tain fin(p − k) − o(+)
o2(p, k) = 0.

(k) − o(−)

1

1

1

The purpose of the third layer is to help calculating
the ﬁnal minimum. More precisely, it computes how much
fout(p) should be smaller than fin(p) in the following way.
Lemma 6. Let pin ∈ N, sin ∈ ]0, 1], and fin(p) ∈ ]0, 2] for
every p ∈ [p∗]. Then o3(p) = max{0, fin(p)−sin} for every
p ∈ [pin] and o3(p) = max{0, fin(p)−(fin(p−pin)+sin)}
for every p ∈ {pin + 1, pin + 2, . . . , p∗}.

Proof. If p ≤ pin, we obtain from Lemma 5 that
(cid:80)p−1
k=1 o2(p, k) = 0. If p > pin, Lemma 5 implies
(cid:80)p−1
k=1 o2(p, k) = fin(p − pin). Thus, the claim follows by
construction of the third layer and deﬁnition of σ.

Now, after we have investigated the functionality of each

of the hidden layers, we are able to prove Theorem 1.

Proof of Theorem 1. Using Lemma 6, we obtain that
fout(p) = min{fin(p), sin} if p ≤ pin and fout(p) =
min{fin(p), fin(p − pin) + sin} if p > pin. The claim fol-
lows due to the Recursion (2) with the respective starting
values.

B Detailed Construction of the FPTAS-NN

In this section we formally describe the FPTAS-NN and
prove that it provides provable approximation guarantees.

As for the DP-NN, we truncate the values of g at 2,
that is, instead of any value larger than 2 including +∞,
we just use the value 2. The FPTAS-NN is applied to a
Knapsack instance in the following way. Using the initial-
ization g(p, 0) = 2 for p ∈ [P ] and p∗
0 = 0, for i = 1, . . . , n,
we feed the inputs gin(p) = g(p, i − 1) for p ∈ [P ], p∗
in =
p∗
i−1, pin = pi, and sin = si into the network and store the
outputs as g(p, i) = gout(p) for p ∈ [P ] and p∗

i = p∗

out.

The FPTAS-NN has four hidden layers. After the n0 =
P + 3 input neurons gin(p) for p ∈ [P ], p∗
in, pin, and sin,
the ﬁrst hidden layer consists of n1 = 2 neurons oold
and
1
onew
1 which help to compute the rounding granularities dold
and dnew. They are deﬁned as follows:

oold
1 = σ

onew
1 = σ

dold = oold
dnew = onew

(cid:19)

− 1

(cid:18) p∗
in
P
(cid:18) p∗
in + pin
P
1 + 1,
1 + 1.

,

(cid:19)

− 1

,

(4a)

(4b)

(4c)
(4d)

1

1

and onew

The granularities dold and dnew are just afﬁne transfor-
mations of oold
. Hence, they do not form an own
hidden layer, because we do not apply the ReLU activation
function there. The correct functionality of the ﬁrst layer is
ensured by the following lemma.
Lemma 7. The ﬁrst layer of the FPTAS-NN correctly com-
putes the rounding granularities dold = max{1, p∗
P } and
dnew = max{1, p∗
}.
Proof. This follows from the fact that σ(x − 1) + 1 =
max{0, x − 1} + 1 = max{1, x}, where x equals either
P or p∗
p∗
in
Hence, in the i-th step, if we feed the inputs p∗

i−1
and pin = pi into the network, dold and dnew equal di−1
and di, respectively.

in = p∗

in+pin
P

in+pin
P

in

.

In the second hidden layer, we have a total of
n2 = 2P 2 + 2P hidden neurons, denoted by
o(1+)
[P ] with
2
p ≤ k, as well as, o(2+)
(p, k)
for p, k ∈ [P ] with p ≥ k, deﬁned as follows:

∈
(p, k) and o(2−)

(p, k) and o(1−)

for p, k

(p, k)

2

2

2

o(1+)
2

o(1−)
2

o(2+)
2

o(2−)
2

(p, k) = σ(2P (pdnew − kdold)),

p, k ∈ [P ], p ≤ k,

(4e)

(p, k) = σ(2P ((k − 1)dold − pdnew) + 2),

p, k ∈ [P ], p ≤ k,

(4f)

(p, k) = σ(2P (pdnew − kdold − pin)),

p, k ∈ [P ], p ≥ k,

(4g)

(p, k) = σ(2P ((k − 1)dold + pin − pdnew) + 2), p, k ∈ [P ], p ≥ k.

(4h)

For a ﬁxed p ∈ [P ], let p(1) and p(2) be the small-
est possible integers with p(1)dold ≥ pdnew and
p(2)dold + pin ≥ pdnew, respectively. The task of the
the values p(1) and p(2), as
second layer is to detect
formalized by the following two lemmas.
Lemma 8. For each p, k ∈ [P ] with p ≤ k, we have
o(1+)
(p, k) = 0 if and only if k = p(1). Oth-
2
erwise, we have o(1+)

(p, k) + o(1−)

(p, k) + o(1−)

(p, k) ≥ 2.

2

2

2

Proof. Obviously, it holds that o(1+)
(p, k) = 0 if and only
if kdold ≥ pdnew. On the other hand, using that dold and
dnew are integer multiples of 1

P , we obtain

2

o(1−)
2

(p, k) = 0

⇔ (k − 1)dold ≤ pdnew −

1
P

⇔ (k − 1)dold < pdnew
⇔ no integer k(cid:48) < k satisﬁes k(cid:48)dold ≥ pdnew.

This proves the ﬁrst part of the claim. The second part fol-
lows because, again, dold and dnew are integer multiples of
P and, hence, o(1+)
1
(p, k) is an integer multi-
ple of 2.

(p, k) + o(1−)

2

2

Lemma 9. For each p, k ∈ [P ] with p ≥ k, we have
o(2+)
(p, k) = 0 if and only if k = p(2). Oth-
2
erwise, we have o(2+)

(p, k) + o(2−)

(p, k) + o(2−)

(p, k) ≥ 2.

2

2

2

Proof. Analogous to Lemma 8.

The third hidden layer consists of n3 = P 2 + P
neurons o(1)
3 (p, k) for p, k ∈ [P ] with p ≤ k, as well as
o(2)
3 (p, k) for p, k ∈ [P ] with p ≥ k. Moreover, we have
again helping variables that do not form an own hidden
layer because they are only afﬁne transformations of the
previous layers, namely h(1)(p) and h(2)(p) for p ∈ [P ].

3 (p, k) = σ(2 − gin(k) − o(1+)
o(1)

2

(p, k) − o(1−)

2

(p, k)), p, k ∈ [P ], p ≤ k,

3 (p, k) = σ(gin(k) − o(2+)
o(2)

2

(p, k) − o(2−)

2

(p, k)),

h(1)(p) = 2 −

P
(cid:88)

k=p

o(1)
3 (p, k),

h(2)(p) =

p
(cid:88)

k=1

o(2)
3 (p, k),

(4i)

p, k ∈ [P ], p ≥ k,
(4j)

p ∈ [P ],

(4k)

p ∈ [P ].

(4l)

The idea of this layer is to compute gin(p(1)) and gin(p(2)),
as the following two lemmas show.
Lemma 10. For each p ∈ [P ], if p(1) ≤ P , we have
h(1)(p) = gin(p(1)). If p(1) > P , we have h(1)(p) = 2.

3 (p, p(1)) = 2 − gin(p(1)) and o(1)

Proof. Note that p(1) is never smaller than p. If p ≤ p(1) ≤
P , then o(1)
3 (p, k) = 0 for
each k (cid:54)= p(1) by Lemma 8. If p(1) > P , then o(1)
3 (p, k) =
0 for each k. Thus, the claim follows by the deﬁnition of
h(1).

Lemma 11. For each p ∈ [P ], if p(2) ≥ 1, we have
h(2)(p) = gin(p(2)). If p(2) ≤ 0, we have h(2)(p) = 0.

Proof. We ﬁrst show that p(2) is never larger than p by prov-
ing that pdold + pin ≥ pdnew. If dnew = 1, then also
dold = 1 holds and this statement is true. Otherwise, we
and dold ≥ p∗
have dnew = p∗
P . Hence, we obtain
p(dnew − dold) ≤ ppin
P ≤ pin. Therefore, in any case,
pdold + pin ≥ pdnew follows, and thus also p(2) ≤ p.

in+pin
P

If 1 ≤ p(2) ≤ p, then it follows that o(2)

3 (p, p(2)) =
3 (p, k) = 0 for each k (cid:54)= p(2) by Lemma 9.
3 (p, k) = 0 holds for each k. Thus, the

gin(p(2)) and o(2)
If p(2) ≤ 0, then o(2)
claim follows by the deﬁnition of h(2).

in

The fourth hidden layer is used to compute the minimum
in the recursion and consists of n4 = P neurons o4(p) for
p ∈ [P ]. Finally, we output the P values gout(p) for p ∈ [P ],
as well as p∗

out = p∗

in + pin.

o4(p) = σ(h(1)(p) − (sin + h(2)(p))), p ∈ [P ], (4m)
(4n)
(4o)

gout(p) = h(1)(p) − o4(p),

p ∈ [P ],

out = p∗
p∗

in + pin.

The following lemma ensures that the output value gout(p)
is indeed computed by the desired recursion, provided that
h(1) and h(2) are computed properly.
Lemma 12. For each p ∈ [P ], we have gout(p) =
min{h(1)(p), sin + h(2)(p)}.

Proof. This ﬁnal layer of the FPTAS-NN is constructed ex-
actly like the NN in Figure 1.

Equations (4a) to (4o) fully deﬁne the FPTAS-NN. We
have shown several lemmas concerning the functionality of
the individual layers. Now we turn towards the proofs of
Theorems 2 and 3.

Proof of Theorem 2. We show that the claim even holds for
all values of p and i with g(p, i) < 2 and not only for those
with g(p, i) ≤ 1.

We use induction on i. For the induction start (i = 0),
nothing is to show due to the initialization g(p, 0) = 2 for
all p ∈ [P ]. For the induction step, suppose the claim is valid
for all steps up to i − 1.

Fix some p ∈ [P ]. By Lemma 12, the output g(p, i) =
gout(p) in the i-th step equals min{h(1)(p), sin + h(2)(p)}.
In the following, we distinguish two cases. Recall that p(1)
and p(2) are the smallest possible integers with p(1)dold ≥
pdnew and p(2)dold + pin ≥ pdnew, respectively.

Case 1: h(1)(p) ≤ sin + h(2)(p). This implies g(p, i) =
h(1)(p). If h(1)(p) = 2, nothing is to show. Otherwise, by
Lemma 10, we have p(1) ≤ P with p(1)dold ≥ pdnew and
g(p, i) = h(1)(p) = gin(p(1)) = g(p(1), i − 1). By induc-
tion, we obtain that there exists a subset of [i − 1] with size
at most g(p, i) and proﬁt at least p(1)dold. Hence, using the
same items yields a subset of [i] with size at most g(p, i) and
proﬁt at least pdnew. Thus, the claim is proven in this case.
Case 2: h(1)(p) > sin + h(2)(p). This implies g(p, i) =
sin + h(2)(p). Note that this can only happen if h(2)(p) < 2
because h(1)(p) has at most value 2. First, suppose p(2) ≤
0. This implies pi = pin ≥ pdnew. Hence, by using just
item i, we obtain a subset of proﬁt at least pdnew and size at
most si = sin ≤ sin + h(2)(p) = g(p, i), and we are done.
Second, if p(2) ≥ 1, then Lemma 11 implies that g(p, i) =
sin + h(2)(p) = sin + gin(p(2)) = si + g(p(2), i − 1). By
induction, we obtain that there exists a subset of [i − 1] with
size at most g(p, i) − si and proﬁt at least p(2)dold. Hence,
adding item i to this subset yields a subset of [i] with size at
most g(p, i) and proﬁt at least p(2)dold + pi ≥ pdnew. Thus,
the claim is also proven in this case.

Proof of Theorem 3. Let M OPT be an optimal solution
to the Knapsack instance and M OPT
= M OPT ∩ [i]
be the subset of [i] chosen by the optimal solution. Let
sOPT
=
i
(cid:80)
. The idea of the proof

j∈M OPT
i
pj be the proﬁt of M OPT

sj be the size of M OPT

and pOPT
i

= (cid:80)

i

i

i

j∈M OPT
i

is that in each step, we lose at most a proﬁt of di com-
pared to the optimal solution. Formally, we prove the fol-
lowing claim by induction on i: for every i ∈ [n], and every
p ≤

− i we have g(p, i) ≤ sOPT

(cid:109)

.

(cid:108) pOPT
i
di

i

The induction start is settled by extending the claim to
i = 0, for which it is trivial. For the induction step, sup-
pose the claim is valid for all steps up to i − 1. Fix a value
− i. Let again p(1) and p(2) be the smallest pos-
p ≤
sible integers with p(1)di−1 ≥ pdi and p(2)di−1 + pi ≥ pdi,
respectively. We distinguish two cases.

(cid:108) pOPT
i
di

(cid:109)

Case 1: i /∈ M OPT, i.e., the optimal solution does not use

item i. Observe that

pdi ≤

(cid:25)

(cid:19)

di

− i

(cid:18)(cid:24) pOPT
i
di
≤ pOPT
− (i − 1)di
i
= pOPT
i−1 − (i − 1)di
≤ pOPT
i−1 − (i − 1)di−1
(cid:18)(cid:24) pOPT
(cid:25)
i−1
di−1

≤

− (i − 1)

(cid:19)

di−1.

Hence, we obtain

p(1) ≤

(cid:25)

(cid:24) pOPT
i−1
di−1

− (i − 1)

(5)

p∗
i−1
di−1

by the deﬁnition of p(1). In particular, p(1) ≤
≤ P by
the deﬁnition of di−1. Therefore, Lemmas 10 and 12 imply
g(p, i) ≤ g(p(1), i − 1). Due to Inequality (5), it further fol-
lows by induction that g(p, i) ≤ g(p(1), i − 1) ≤ sOPT
i−1 =
sOPT
, which settles the induction step in this case.
i

Case 2: i ∈ M OPT, i.e., the optimal solution uses item i.

Observe that

pdi ≤

(cid:25)

(cid:19)

di

− i

(cid:18)(cid:24) pOPT
i
di
≤ pOPT
− (i − 1)di
i
= pOPT
i−1 + pi − (i − 1)di
≤ pOPT
i−1 + pi − (i − 1)di−1
(cid:18)(cid:24) pOPT
i−1
di−1

− (i − 1)

≤

(cid:19)

(cid:25)

di−1 + pi.

Hence, we obtain

p(2) ≤

(cid:25)

(cid:24) pOPT
i−1
di−1

− (i − 1)

(6)

by the deﬁnition of p(2). If p(2) ≤ 0, Lemmas 11 and 12
imply g(p, i) ≤ si ≤ sOPT
. If p(2) ≥ 0, Lemmas 11 and 12
imply g(p, i) ≤ g(p(2), i − 1) + si. Due to Inequality (6), we
can further conclude by induction that g(p, i) ≤ g(p(2), i −
1) + si ≤ sOPT
, which ﬁnalizes the induction
step.

i−1 + si = sOPT

i

i

Figure 9: Required network width to achieve a mean squared
error of at most 0.0025 as a function of p∗.

Figure 10: Required network width to achieve a mean
squared error of at most 0.00375 as a function of p∗.

Now, using the claim we have just proven by induction,
≤ 1. Therefore,

− n, n

(cid:17)

(cid:109)

≤ sOPT
n

(cid:16)(cid:108) pOPT
dn

we obtain that g
it holds that

pNN ≥

(cid:25)

(cid:18)(cid:24) pOPT
dn

(cid:19)

− n

dn ≥ pOPT − ndn.

(7)

If dn = 1, that is, p∗ ≤ P , then we have for all i ∈ [n]
that di = 1. Hence, in each step and for each p ∈ [P ], we
have p(1) = p and p(2) = p − pi. Therefore, by Lemmas 10–
12, the FPTAS-NN behaves like the DP-NN from Section 3
that executes the exact dynamic program and the theorem
follows.

Otherwise, if dn > 1, we have dn = p∗

P . Since there must
n , we obtain pOPT ≥ p∗
n
. Together with (7), this

exist one item with proﬁt at least p∗
P ≤ n2pOPT
and, hence, ndn = np∗
P
implies pNN
pOPT ≥ 1 − n2
P ≥ 1 − ε.

C Experiments with other MSE Thresholds
In order to show that our experimental results in Section 5
do not depend on the particular choice of the MSE threshold,
we conducted the experiments with other thresholds than
0.005 as well. In Figures 9 and 10 you can see the results
for the thresholds 0.0025 and 0.00375, respectively. One can
clearly observe that a quadratic dependence seems to be rea-
sonable in these cases, too. Testing the null hypothesis that
the dependence is actually linear against the alternative of a
quadratic relation yields p-values of 0.12 % and 0.0046 %,
respectively, which is, again, a signiﬁcant indication of a
quadratic dependence.

D Detailed Experimental Setup
Hard- and software. All our experiments were conducted
on a machine with an Intel Core i5-8500 6-Core 64-bit CPU
and 15.5 GB RAM, using the openSUSE Leap 15.1 Linux
distribution. We use Python 3.8.5 with Numpy 1.19.1, Ten-
sorﬂow 2.2.0 in CPU-only mode, and Statsmodels 0.11.1 for
regression and statistical tests.

Generation of random Knapsack instances. For a given
value of p∗ we sample a set of items of total proﬁt (cid:80) pi = p∗
in the following way: the proﬁt of the i-th item is always
chosen uniformly at random among all integer values be-
tween 1 and p∗ − (cid:80)i−1
i(cid:48)=1 pi(cid:48). This is repeated until all prof-
its sum up to p∗. We chose this procedure in order to make
it likely to have both, very proﬁtable and less proﬁtable
items within one instance. Finally, we shufﬂe the order of
the items. For each item, we then pick a size value uni-
formly in the interval [0, 1] and normalize these values such
that their sum equals a uniformly at random chosen value
(cid:80) si ∈ ]1, 2[. We certainly want (cid:80) si > 1, because oth-
erwise all items would ﬁt into the Knapsack. On the other
hand, (cid:80) si < 2 makes sense, because in our DP-NN (com-
pare Section 3), we use 2 as a placeholder for +∞.

Preparation of the training set. Since we can generate
arbitrarily many random Knapsack instances, we use an inﬁ-
nite training set and never train on the same data point twice.
A Knapsack instance with n items yields n training points,
namely one for each step of the dynamic program. In or-
der to avoid having the n training points belonging to one
instance in successive order, we generate training points be-
longing to several instances and shufﬂe them.

Neural network architecture. For a given value p∗ and
width w, the corresponding neural network used consists of
an input layer with p∗ + 2 neurons (corresponding to the p∗
values of the previous dynamic programming state, as well
as, the scalar proﬁt and size values), three hidden layers with
w neurons each and ReLU activations, as well as an output
layer with p∗ neurons (corresponding to the new state of the
dynamic programming) without further activation function.
That way, we choose the same depth as in the DP-NN (Sec-
tion 3), but do not employ the speciﬁc knowledge about the
widths of the three hidden layers. As in the DP-NN, each
layer is not only connected to the previous layer, but also
receives direct connections from the input layer. In total, by
our results of Section 3 and Appendix A, this architecture is

0510152025p*50100150200250widthRequired width for MSE loss 0.0025ObservationsQuadratic Regression Line01020304050p*100200300400500widthRequired width for MSE loss 0.00375ObservationsQuadratic Regression Linetheoretically able to exactly represent the dynamic program-
ming transition function if w ≥ p∗(p∗ − 1)/2.

Training and testing a speciﬁc network. For a given
value p∗ and width w, we train the neural network archi-
tecture described above as follows. We train in epochs of
1000 batches with batch size 32 using mean squared error
(MSE) loss and the Adam optimizer, which is a robust stan-
dard choice. It makes sense to use MSE loss as it punishes
errors in both directions equally hard and large errors harder
than small errors. All other (hyper-)parameters are left to
the default settings of Tensorﬂow, which empirically works
quite well for our problem type and size. It takes between 8
and 30 seconds to train one epoch with our machine setup.
We train until there are two successive epochs without im-
provement in training loss, which empirically happens after
10 to 80 epochs. Using a test set that is randomly generated
in the same way as the training set, we evaluate the trained
network on 1000 batches of size 32 each. The resulting mean
squared error is our ﬁnal result for the given values of p∗
and w.

Finding the required width. For a given value p∗ and
a given MSE threshold, we always train networks with in-
creasing widths 25, 50, 75, . . . in steps of 25 as described
above until a network achieves a test MSE less or equal to
the threshold.

Seed generation.
In order to ensure reproducibility of our
experiments, each time before we train and test an NN with
given value p∗ and width w, we reset the random seeds of
both Numpy and Tensorﬂow to 257 · p∗ + w, where 257
is just an arbitrary prime number. Note that these packages
only guarantee the same result of random experiments if the
same package versions are used.

Regression and statistical tests. For each of the three
threshold values 0.005 (Section 5), as well as, 0.0025 and
0.00375 (Appendix C), we ﬁnd the required width for
achieving the respective threshold for 25 different values
of p∗. With the help of the ordinary least squares (OLS)
regression utility of the Statsmodels package, we ﬁnd a
quadratic regression line for the p∗-width relation in each
of the three cases. The output of the OLS automatically con-
tains the reported p-values for testing whether the coefﬁcient
of the quadratic term is zero.

Source Code. The source code is publicly available
at
https://github.com/ChristophHertrich/neural-knapsack.
There, the ﬁle README.md explains how the code can be
used to reproduce the experiments of this paper.

