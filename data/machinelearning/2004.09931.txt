Knowledge Refactoring for Inductive Program Synthesis

Sebastijan Dumanˇci´c
KU Leuven, Belgium

Tias Guns
KU Leuven, Belgium

Andrew Cropper
Oxford, United Kingdom

0
2
0
2

v
o
N
4
2

]
I

A
.
s
c
[

3
v
1
3
9
9
0
.
4
0
0
2
:
v
i
X
r
a

Abstract

Humans constantly restructure knowledge to use it more efﬁ-
ciently. Our goal is to give a machine learning system similar
abilities so that it can learn more efﬁciently. We introduce
the knowledge refactoring problem, where the goal is to re-
structure a learner’s knowledge base to reduce its size and to
minimise redundancy in it. We focus on inductive logic pro-
gramming, where the knowledge base is a logic program. We
introduce Knorf, a system which solves the refactoring prob-
lem using constraint optimisation. A key feature of Knorf is
that, rather than simply removing knowledge, it also intro-
duces new knowledge through predicate invention. We eval-
uate our approach on two domains: building Lego structures
and real-world string transformations. Our experiments show
that learning from refactored knowledge can improve predic-
tive accuracies fourfold and reduce learning times by half.

1

Introduction

According to the seminal work of Rumelhart and Norman
(1976), humans exhibit three modes of learning. Learning by
accretion is an everyday kind of learning which merely in-
crements a person’s knowledge base with new facts. Learn-
ing by tuning involves changes in the categories people use
for interpreting new information. For instance, the process
of tuning specialises a child’s interpretation of the word
‘doggie’ from all animals to dogs only. Restructuring de-
vises new memory structures and organisation of already
stored knowledge, which in turn allows for better accessi-
bility of the acquired knowledge. This restructuring ability
is the most signiﬁcant mode and is what separates well-
performing individuals from others (Karmiloff-Smith 1992;
Stern 2005).

The key to effective restructuring is ﬁnding appropriate
abstractions. As a running example, consider building Lego
structures. Figure 1 (top) shows two structures built using
. Building
only two types of bricks: short
the structures using only these two types of bricks is com-
plex and requires 29 and 18 bricks respectively. However, as
Figure 1 (bottom) shows, by introducing new types of bricks
through restructuring, such as a pillar and a horizontal brick

and long

Copyright © 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

Figure 1: Complex Lego arcades (top, built with only two
) become easier to build
distinct Lego bricks:
after new, useful types of bricks are introduced (bottom).
The complexity is measured as the number of pieces needed
for the construction.

and

of various lengths, we can build the same structures using
only 7 and 11 pieces respectively. In other words, by ﬁnd-
ing suitable abstractions, we can make the structures, and
potentially future structures, easier and faster to build.

The importance of abstraction in AI is well-known (Saitta
and Zucker 2013). However, the majority of learning AI
agents merely accumulate knowledge, which is a problem
because purely accumulating knowledge can be detrimental
to learning performance (Srinivasan, King, and Bain 2003;
Cropper 2020). In other words, as knowledge is a form of in-
ductive bias in machine learning (Mitchell 1997), increasing
the amount of knowledge increases the hypothesis space and
consequently makes ﬁnding the target hypothesis more difﬁ-
cult. The challenge is, therefore, to choose a learner’s induc-
tive bias (knowledge) so that the hypothesis space is large
enough to contain the target hypothesis, yet small enough to
be efﬁciently searched.

This paper aims to tackle the inductive bias problem by
(i) reducing the size of the knowledge base, and (ii) re-
structuring it to make it easier to learn from. Rather than
only adding or removing knowledge (De Raedt et al. 2008;
Lin et al. 2014; Cropper 2020), we argue that the human-like
ability to restructure knowledge can provide a better induc-
tive bias to a learner and thus improve performance. We call
this problem knowledge refactoring. The idea is similar to
program refactoring, where the goal of a programmer is to
identify a good set of support functions to make a program
more compact and reusable.

 
 
 
 
 
 
To restructure knowledge, we must explicitly store it. This
requirement eliminates non-symbolic learning approaches
which dissipate knowledge in the parameters of a model. We
therefore use symbolic learning approaches, speciﬁcally in-
ductive program synthesis (Shapiro 1983), which learns pro-
grams from input-output examples. We focus on inductive
logic programming (ILP) (Muggleton and De Raedt 1994),
which represents background knowledge (BK) as a logic
program and which has strong foundations in knowledge
representation.

Our speciﬁc contributions are:

• We introduce the knowledge refactoring problem: revis-
ing a learner’s knowledge base (a logic program) to re-
duce its size and minimise redundancy. Our key idea is
to automatically identify useful substructures via predi-
cate invention. The challenge lies in efﬁciently identifying
substructures that lead to smaller programs. We tackle this
challenge by casting the problem of knowledge refactor-
ing as a constraint optimisation problem over a large set
of candidate invented predicates.

• We introduce Knorf, a system that refactors knowledge
bases by searching for new, reusable pieces of knowledge.
A key feature of Knorf is that, rather than simply remov-
ing knowledge, it also introduces new knowledge through
predicate invention (Stahl 1993).

• We evaluate our approach on two domains: building Lego
structures and real-word string transformations. Our ex-
periments show that learning from refactored knowledge
can substantially improve predictive accuracies of an ILP
system and reduce learning times.

2 Related Work
Redundancy elimination. Reducing redundancy is useful
in many areas of AI, such as to improve SAT efﬁciency
(Heule et al. 2015). In machine learning, irrelevant and re-
dundant knowledge is detrimental to learning performance
(Srinivasan, Muggleton, and King 1995; Srinivasan, King,
and Bain 2003; Cropper and Tourret 2020). Much work fo-
cuses on removing redundant literals or clauses from a log-
ical theory (Plotkin 1971). Theory minimisation approaches
try to ﬁnd a minimum equivalent formula to a given input
propositional formula (Hemaspaandra and Schnoor 2011)
and also introduce new formulas. By contrast, we focus
on ﬁrst on ﬁrst-order (Horn) logic. Forgetting approaches
(Cropper 2020) try to remove clauses from the knowledge
base to improve learning performance. Our work is different
because we (i) restructure knowledge, and (ii) introduce new
knowledge through predicate invention.

Theory reﬁnement. Theory reﬁnement (Wrobel 1996)
aims to improve the quality of a theory. Theory revision ap-
proaches (De Raedt 1992; Ad´e, Malfait, and De Raedt 1994;
Richards and Mooney 1995) revise a program so that it en-
tails missing answers or does not entail incorrect answers.
Theory compression (De Raedt et al. 2008) approaches se-
lect a subset of clauses such that the performance is mini-
mally affected with respect to certain examples. By contrast,
our approach does not consider examples: we only con-
sider the knowledge base. Theory restructuring changes the

Unfolded clause

Folded clause

Figure 2: Construction of the pillar (left) can be simpliﬁed
by abstracting (or folding in LP) the procedure for construct-
ing the vertical piece in the middle (right).

structure of a logic program to optimise its execution or its
readability (Wrobel 1996). For instance, FENDER (Sommer
1995) restructures a theory with intra- and inter-construction
operators (Muggleton 1995). The authors claim that their ap-
proach leads to a theory that is deeper, more modular, and
possibly easier to understand and maintain. By contrast, our
goal is to restructure a theory by reducing the number of
unnecessary predicate symbols in it and by introducing new
ones. Moreover, we formulate the refactoring problem as a
COP.

Predicate invention. Knorf supports predicate invention
(Stahl 1993), the automatic introduction of new auxiliary
predicates. In contrast to the existing approaches which in-
vent predicates before (Cropper 2019; Hocquette and Mug-
gleton 2020) or during (Muggleton, Lin, and Tamaddoni-
Nezhad 2015) learning, Knorf invents them after learning
through refactoring. Three approaches are especially rele-
vant to us. Alps (Dumanˇci´c et al. 2019) invents predicates
by compressing a knowledge base formed of facts. By con-
trast, Knorf considers and deﬁnite clauses with more than
one literal. EC (Dechter et al. 2013) learns programs such
that they are compressible, but does not revise previously
invented abstractions, while Knorf does. EC2 (Ellis et al.
2018), building upon EC, locally searches for small changes
to a functional program to increase an optimisation function.
Our approach differs because (i) we work in a purely logical
setting, (ii) we preserve the semantics of the original pro-
gram, and (iii) we solve the refactoring problem as a COP.

3 Problem Description
To introduce the knowledge refactoring problem, we ﬁrst
provide essential preliminaries on logic programming (LP)
(Sterling and Shapiro 1986), after which we show how
knowledge refactoring can aide inductive program synthe-
sis.

Logic Programming
A deﬁnite logic program is a set of deﬁnite clauses of the
form head :- cond1, ..., condN . A clause states that
head is true if all conditions are true. The head and condi-
tions are atoms or their negations (jointly called literals),
i.e., structured terms that represent relations between ob-
jects. In the Lego example, place( ,Po,E,E(cid:48)) is an atom,
consisting of a predicate place/4, which places a brick of
at a position Po in a world with the state E, re-
the type
sulting in a new state E(cid:48). Assume a one-dimensional world
with Lego pieces and a cursor indicating the current position
(Figure 2). The clause:

1 pillar(X,Y,E,E(cid:48)) :-
place(
place( ,Z,E1,E2), place( ,Z,E2,E3),
place( ,Z,E3,E4), left(Z,Y),
,X,E4,E(cid:48)).
place(

,X,E,E1), right(X,Z),

provides instructions for constructing a pillar at the position
X: place a horizontal brick on position X, move the cursor
to the position right of X, put three bricks on top of each
other, move the cursor back to the starting position and place
another horizontal brick (Figure 2, left).

A key concept in LP is (un)folding (Tamaki and Sato
1984). Intuitively, given a set of clauses S, the fold(P,S)
operation replaces every occurrence of the body of clause c
∈ S, up to variable renaming, in program P with its head.
For instance, folding the clause 1 with the clause:

2

ver(X,E,E(cid:48)) :-

place( ,X,E,E1), place( ,X,E1,E2),
place( ,X,E2,E(cid:48)).

results in the clause:

3

pillar(X,Y,E,E(cid:48)) :-

,X,E,E1), right(X,Z),

place(
ver(Z,E1,E2), left(Z,Y),
place(

,X,E2,E(cid:48)).

The unfold(P) operation essentially inlines all functions:
for every clause c in program P which deﬁnes a predicate
that is used in the body of another clause, it replaces every
occurrence of the head of c in P with its body. For instance,
unfolding the clause 3 with the clause 2 results in the clause
1. We assume that every inlined clause is removed from the
program after unfolding.

3.1 Knowledge Refactoring Problem
Consider our running example of constructing arcade struc-
tures (Figure 1). The predicates in the logic program have
different roles:

• Primitive predicates represent user-provided primitive
knowledge that cannot be further decomposed, e.g.
place/4, right/2 and left/2.

• Task predicates deﬁne solutions to tasks we want to solve

or have solved, e.g. arcade structures.

• Support predicates represent useful abstractions, e.g.
ver/3. They help us better structure a program but can
be unfolded from a program without changing its seman-
tics with respect to the task predicates. We denote support
clauses in blue throughout the paper.

Our refactoring problem takes as input a space of possible
support predicates. We restrict support clauses by their size.
The size of a clause c, size(c), is the number of literals in
c (including the head atom). We deﬁne the support clause
space:
Deﬁnition 1 (Support clause space). A clause c is in the
support clause space S of a program P if (i) the head predi-
cate of c does not appear in P , and (ii) the predicates in the
body of c are in P or other support clauses.
When we refactor a program, we want to preserve the se-
mantics of the original program with respect to complex
predicates. We reason about the restricted consequences of
a program:

Deﬁnition 2 (Restricted consequences). Let T be a set
of predicate symbols and P be a logic program. The con-
sequences of P restricted to T is MT (P ) = {a|a ∈
atoms(P ), P |= a, the predicate symbol of a is in T }.
We also want to reduce the size of the original program. The
function size(P ) denotes the total number of literals in the
logic program P . We deﬁne the knowledge refactoring prob-
lem:
Deﬁnition 3 (Knowledge refactoring). Let P be a logic
program, T be a set of task predicate symbols, and S be a
set of support clauses. Then the refactoring problem is to
ﬁnd P (cid:48) ⊆ fold(unfold(P ), S) such that (i) MT (P (cid:48)) ==
MT (P ), and (ii) size(P (cid:48)) < size(P ).
This deﬁnition provides conditions for refactoring: it should
yield support clauses that, once folded into a program, (i)
preserve the semantics of the original program, and (ii) lead
to the smaller program. Refactoring therefore produces a
lossless compression of the unfolded program, with respect
to the main predicates. Importantly, it leaves the construction
of the support clauses open as there are many valid ways to
do so. We detail this aspect when discussing the implemen-
tation of the system.

m

3.2 Beneﬁt of Refactoring
To show the potential beneﬁts of refactoring, imagine an
ILP system that enumerates all programs in the hypothe-
sis space, a common approach when inducing functional
programs
(Balog et al. 2017; Ellis et al. 2018). Ignoring
ﬁrst-order variables for simplicity, the size of the hypothe-
sis space is at most (cid:0)pl
(cid:1) where p is the number of predicate
symbols allowed in a hypothesis, l is the maximal number of
literals in the body of a clause in a hypothesis, and m is the
maximum number of clauses in a hypothesis. According to
the Blumer bound (Blumer et al. 1987), given two hypothe-
sis spaces of different sizes, and assuming that the target hy-
pothesis is in both spaces, searching the smaller space will
result in fewer errors compared to the larger one. This result
implies that we can improve the performance of an ILP sys-
tem by either reducing the number of predicate symbols p
or the size of the target program n. By refactoring we can
reduce (i) p by removing redundant predicate symbols and
also by limiting the number of predicate symbols allowed
in the BK, and (ii) m and l by restructuring the BK so that
we can express the target hypothesis (program) using fewer,
or shorter, clauses. We argue that refactoring is especially
important in a lifelong learning setting where a system con-
tinuously learns thousands of new concepts, i.e. where p can
be very large.

4 Knorf: A Knowledge Refactoring System
4.1 Syntactic Refactoring
The refactoring problem (Deﬁnition 3) requires that the
refactored program is (in a restricted form) semantically
equivalent to the original program. However, checking this
requirement is intractable in practice because we need to
check that two programs produce the same output for every
possible input, which could be inﬁnite. To make the problem

Figure 3: To identify candidate support clauses, Knorf ﬁrst unfolds the original program. Then, Knorf constructs candidates
from subparts of the unfolded program. To obtain more complex support clauses, Knorf ﬁrst constructs alternative foldings of
the given program, using the previously constructed candidates, and repeats the same procedure.

tractable, Knorf uses a weaker criterion of syntactic equiv-
alence:

Deﬁnition 4 (Syntactical equivalence). A program P is
syntactically equivalent to the program P (cid:48) if unfold(P ) =
unfold(P (cid:48)).
Note that two syntactically equivalent programs are neces-
sarily semantically equivalent, while the opposite does not
hold.

As Knorf searches for the syntactically equivalent refac-
toring, it constructs the support clause space by extracting
subsets of body literals from the unfolded original program.
We now introduce concepts necessary to construct the sup-
port clause space.

Deﬁnition 5 (Connected clause). A clause C is connected
if it cannot be partitioned into two non-empty clauses C1
and C2 such that the variables in C1 are disjoint from C2, i.e,
(cid:64)C1, C2 ⊆ C such that C1 (cid:54)= C2, vars(C1) ∩ vars(C2) = ∅.
For instance, the clause h(X,Y) :- p(X,Y), q(Z) is not a
connected clause because the variables can be partitioned in
two disjoined subsets, {X,Y} and {Z}.

Deﬁnition 6 (Clausal power-set). A clausal power-set of
the clause c, P(c), is the power-set of the literals in the body
of c, excluding the empty set.

For instance, a clausal power-set of the clause h(X,Y)
:- a(X,Y),b(Y,Z),c(Z).
{b(Y,Z)},
{c(Z)},{a(X,Y),b(Y,Z)}, {a(X,Y),c(Z)}, {b(Y,Z),c(Z)},
{a(X,Y),b(Y,Z),c(Z)}}.

{{a(X,Y)},

is

Deﬁnition 7. (Connected clausal power-set) A connected
clausal power-set of the clause c, C(c), is the maximal subset
of P(c) such at every s ∈ C(c) is connected: C(c) = {e ∈
P(c)| connected(c)}. In other words, only those subsets of
literals of c that are connected.

Continuing on the previous example, the connected clausal
power-set removes {a(X,Y),c(Z)} from the clausal power-
set because the variables {X,Y} are disjoint from {Z}.

With these concepts in place, we deﬁne the space of sup-

port clauses.

Deﬁnition 8 (Space of support clauses). A clause is in the
support clause space S i
j of a program P when (i) it has at
least i and at most j literals in the body, (ii) the set of literals
in the body is in (cid:83)
c∈P C(c) (up to variable renaming), and
(iii) the head predicate symbol is unique and does not appear
in P .

Knorf solves the refactoring problem by transforming it to
a constraint optimisation problem (COP) (Rossi, Beek, and
Walsh 2006), where the goal is to ﬁnd an optimal set of sup-
port clauses. Given (i) a set of decision variables, (ii) a prob-
lem description in terms of constraints, and (iii) an objective
function, a COP solver ﬁnds an assignment to decision vari-
ables that satisﬁes all speciﬁed constraints and maximises or
minimises the objective function1.

Knorf minimises both size and redundancy:

Deﬁnition 9 (Syntactic redundancy). A logic program T
has syntactic redundancy if there are two clauses c1, c2 ∈ T
such that c1 (cid:54)= c2, u1 ∈ C(c1), u2 ∈ C(c2), size(u1) > 1,
size(u2) > 1, and u1 and u2 are the same up to the variable
renaming.

In other words, two clauses have a common subset of body
literals.cp k Though minimising program size should imply
the removal of redundancy, we notice empirically that min-
imising both better guides the search to good solutions, e.g.
within a certain time limit

4.2 Decision Variables: Support Clauses

Knorf solves the refactoring problem as a subset selection
problem over the space of support clauses (Deﬁnition 8).
In principle, the support clause space S i
j is inﬁnite, even
with upper-bounded length of clauses, as any number of
support predicates can be introduced. To avoid this issue,
we introduce an incremental procedure to construct S i
j with
clauses of ﬁxed length. The procedure repeatedly applies
two steps, candidate extraction and folding, starting from
the unfolded program P. The unfolded program contains
only primitives (in Figure 3 left, this results in clauses plac-
ing only

pieces).

and

The candidate extraction step constructs support clauses
from the connected power-sets of the clauses from the un-
folded program P, (cid:83)
c∈P C(c), with at least i and at most
j literals. More speciﬁcally, Knorf turns each element of
(cid:83)
c∈P C(c) into a support clause by creating a new predicate
symbol in the head. These support clauses are expressed in
terms of primitive predicates. In the Lego example, taking
i = 1 and j = 2 would result in some of the candidates
illustrated in Figure 3, middle.

The folding step folds the extracted support clauses into
the (unfolded) program.This step essentially rewrites the

1We use the CP-SAT solver (Perron and Furnon 2019).

InitialprogramUnfoldedprogramcandidateenumeration...foldingAlternativefoldingslevel1...candidateenumeration...foldingAlternativefoldingslevel2...program such that the bodies of its clauses are made of sup-
port predicates (a single clause can have multiple foldings).
In the Lego example, this results in the simpliﬁed construc-
tion of the pillar structure (Figure 3, middle). To obtain more
complex support clauses, Knorf repeats the same two steps
but starts from the folded program.

Knorf repeats these two steps until each clause in the
program has only one body literal. The result of this pro-
cedure is a hierarchy of support clauses, each one building
on simpler support clauses. We refer to these steps as levels
of refactoring; the folding the unfolded program yields level
one refactoring, folding again yields level two refactoring,
and so on.

Each enumerated support clause candidate k is associated
with a Boolean variable sck indicating whether the support
clause is selected. Each folding of the clause i is associated
with a Boolean variable fi
n indicating that a particular fold-
ing is selected as a part of the refactored program.

Pruning Support Clauses The incremental candidate
enumeration procedure described above still results in many
candidates because each clause can be expressed in many
ways, given a set of support clauses. We further prune the
support clause space by (i) eliminating singleton clauses,
and (ii) removing clauses that cannot reduce the program
size.

We remove support clauses with singleton variables, i.e.
clauses with a variable that only appear once. For instance,
the clause:

4

sup(X,E) :-

place( ,X,E,E1), place( ,X,E1,E(cid:48)).
is removed because E(cid:48) appears only once. Adding E(cid:48) as the
last argument in the head would make the clause valid. As
we focus on inductive program synthesis problems, ignoring
singleton clauses is not sacriﬁcing expressivity because sin-
gleton variables are essentially variables that are never used.
We also remove support clauses that cannot reduce the
size of the program. For instance, let c be a support clause
and usage(c, T) be the number of clauses in the program
T which can be folded with c. This means that in the best
case, we can replace usage(c, T)×(size(c)−1) literals
in the program (i.e., every occurrence of the body of c) by
usage(c, T)×1 uses of the head of the support clause c
and the addition of a clause c to the theory T. Hence, if it is
the case that this inequality holds:

usage(c, T)×(size(c)−1) ≤ usage(c, T) + size(c)

Then we know that the use of this candidate support clause
will never lead to a reduction in the program size (our overall
goal). We remove candidate support clauses that violate this
inequality.

4.3 Constraints: Valid Refactoring
Each clause in the unfolded program has multiple possi-
ble foldings, grouped in different levels due to the support
clause generation process. The refactored program should
replace the original clauses with one of the possible fold-
ings. Hence, Knorf enforces a constraint stating that at least
one of the foldings of the clause i should be formed by the
chosen support clauses.

We group the foldings of the clause i per level and add an
additional level indicator li
d. For reasons that will become
obvious later, the level indicator li
d is a Boolean variable
which is set to true if the selected folding of the clause
i comes from the level d. This results in constraints of the
form:

max levels
(cid:95)

d=1

(cid:32)

(cid:32)

(cid:33)(cid:33)

li
d ∧

(cid:95)

fi
n

n

.

Knorf forces that one level of refactoring is chosen for each
clause by imposing the following constraint:

max levels
(cid:88)

d=1

li
d = 1.

This level variable will be part of the objective, where
higher levels are typically better.

To decide whether a folding fi

n can be constructed, the
solver needs to know which support clauses are needed for
that particular folding. For instance, to construct the top
folding at the level 1 in Figure 3, we need the following
(assume that the selection of these
pieces:
support clauses is indicate with the variables scp, scr and
scq). To ensure this connection, Knorf enforces the con-
straint stating that the folding fi
n can be constructed only if
all the necessary pieces are selected as a part of the solution:

, and

,

,

fi
n ⇔ (scp ∧ scr ∧ scq) .

Finally, candidates extracted from level L depend on the
candidates from the level L − 1 (i.e., the bodies of support
clauses from level L are composed from the predicates intro-
duced by the support clauses at level L − 1). Knorf imposes
the constraint directly materialising this dependency – if the
support clause sck is selected as a part of the solution, then
all support clauses deﬁning the predicates in the body of the
clause sck (assume scl and scm ) also have to be a part of
the solution

sck ⇒ (scl ∧ scm).

For instance, one needs

and

bricks to make

.

4.4 Objective: Size and Redundancy
Knorf searches for the smallest refactored program, syn-
tactically equivalent to the original program, with the least
redundancy. The size of the refactored program equals the
number of literals in it, i.e., the size of the selected foldings
and support clauses. To guide a COP solver towards small
refactored program, Knorf minimises the following objec-
tive function

L
(cid:88)

F d(cl)
(cid:88)

(cid:88)

size(fcl

n ) ∗ fcl

n ∗ lcl
d

(cid:88)

+

size(sc) ∗ sc

cl∈T
(cid:124)

d=1

n=1

(cid:123)(cid:122)
size of selected foldings

(cid:125)

sc∈Si
j
(cid:124)
(cid:125)
(cid:123)(cid:122)
size of selected support clauses

where L is the maximal number of level and F d(cl) is the
number of foldings of the clause cl at level d.

The level indicators introduced in Section 4.3 are impor-
tant to measure the program size correctly. Assume that the
selected folding of a certain (unfolded) clause is at the level
3. As any folding at level 3 is constructed from support pred-
icates introduced at level 2, at least one folding at level 2 is

possible to construct. But any folding from level 2, if the
selected one is at level 3, should not contribute to the size
of the refactored program. The level indicators ensure that
only the selected folding contributes to the program size by
multiplying the size of folding from lower levels by 0.

To minimise the redundancy between clauses, Knorf
keeps track of all foldings that share literals in the body. We
then introduce a new Boolean variable (e.g., ri) indicating
whether more than one folding (e.g., corresponding to vari-
ables fi
m) with such redundancy can be constructed
m > 1(cid:1) .

n and fk

ri ⇔ (cid:0)fi

n + fk

Knorf introduces such constraint for all found redundancies
and adds the sum over r variables to the objective function.

5 Experiments
We argue that an ILP system can learn better from refactored
BK. Our experiments therefore aim to answer the question:

Q: Can an ILP system learn better with refactored BK?

By better, we ask whether it can solve more tasks, learn with
higher predictive accuracies, or learn in less time. To answer
this question, we compare the performance of state-of-the-
art ILP system Metagol (Cropper and Muggleton 2016) with
and without refactored BK.

Lifelong learning. To evaluate the usefulness of refactor-
ing, we focus on a lifelong learning scenarios in which a
learner continuously learns to perform new tasks by contin-
uously adding programs to its BK. This allows us to eval-
uate the beneﬁt of refactoring over BKs with various sizes.
To generate the BK in this setting, we use Playgol (Crop-
per 2019)2, an ILP system that generates BK automatically.
Playgol learns in two phases. In the ﬁrst play phase, Play-
gol solves randomly generated tasks that are similar to the
user-provided target tasks. In the second build phase, Play-
gol solves the user-provided tasks, using the solutions to
the play tasks as BK. We refer to the play tasks as back-
ground tasks and generate BKs with n background tasks,
n ∈ {200, 400, . . . , 4000}

Systems. We evaluate Metagol when learning to solve
user-provided tasks from (i) the generated BK (No refac-
toring), (ii) the BK after refactoring, i.e. after Knorf has
refactored it (Refactoring), and (iii) the BK refactored with
a simple form of refactoring that replaces very redundancy
in a program with a new predicate symbol and represents the
redundancy with an additional clause (No redundancy).

Experiment setting. To build the support clause space,
we set the minimum and maximum length of support clauses
to 2 and 3 respectively. We impose no limit on the number
of layers. When solving the COP, we impose a timeout of
90 minutes. If refactoring takes longer, we stop the search
and take the best solution found so far. We additionally im-
pose a constraint that the refactored BK cannot have more
predicates than the original BK. We give Metagol a learning
timeout of 60 seconds per task. We repeat each experiment

2The original work performs simple deduplication of clauses.
To fully verify the usefulness of refactoring, we have disabled this
step.

10 times, and plot the means and 95% conﬁdence intervals.
All experiments are run on a CPU with 3.20 GHz and 16 Gb
RAM. We have allowed CP-SAT so use 8 parallel threads.

5.1 Experiment 1 - Lego

Our ﬁrst experiment is on learning to build Lego structures
in a controlled environment (Cropper 2020).

Materials We consider a Lego world with a base dimen-
sion of 6 × 1 on which bricks can be stacked. We only con-
sider 1×1 bricks of a single colour. A training example is an
atom f (s1, s2), where f is the target predicate and s1 and
s2 are initial and ﬁnal states respectively. A state describes
a Lego structure as a list of integers. The value k at index
i denotes that there are k bricks stacked at position i. The
goal is to learn a program to build the Lego structure from
a blank Lego board (a list of zeros). We generate training
examples by generating random ﬁnal states. The learner can
move along the board using the actions left and right; can
place a Lego brick using the action place brick; and can use
the ﬂuents at left and at right and their negations to deter-
mine whether it is at the leftmost or rightmost board posi-
tion.

Method The background tasks were generated with a
Lego board of size 2 to 4. We randomly generate 1000 target
tasks for a Lego board of size 6. We measure the percentage
of tasks solved (tasks where the Metagol learns a program)
and learning times (total time need to solve all target tasks).

Results The results (Figure 4a) show that refactoring helps
Metagol to maintain the performance when confronted with
large BK. With refactored BK, Metagol’s performance de-
creases less with the increase of background tasks. The re-
sults also show that refactoring slightly degrades the ability
to solve tasks when BK is small. The likely explanation is
that smaller BK has less chance for redundancy and, thus,
refactoring is eliminating predicates that Metagol could use
to solve tasks. When the BK is large (≥ 1000 background
tasks), refactoring improves the ability to solve tasks. These
results appear to corroborate existing results (Cropper 2020)
which show that simple forgetting can improve learning per-
formance but only when learning from lots of BK. Fig-
ure 4b also shows that refactoring reduces learning times
by approximately 20%. Interestingly, refactoring by replac-
ing redundancies (No redundancy) consistently reduces total
learning times, but does not improve performance for a large
BK.

Figure 6a shows that refactoring drastically reduces the
size of the BK. Both the number of literals and the num-
ber of predicates in the refactored BK is only a fraction of
their number in the original BK. This suggests that much of
the raw BK obtained by Playgol can be represented using a
shared set of a-priori unknown support clauses.

5.2 Experiment 2 - String Transformations

Our second experiment is on real-world string transforma-
tions.

(a)

(b)

(a)

(b)

(a) Lego

(b) Strings

Figure 4: With refactoring, Metagol
solves more Lego tasks and does so in
less than time than without refactoring.

Figure 5: With refactoring, Metagol
solves more string transformation tasks
and does so in less than time than with-
out refactoring.

Figure 6: Refactoring reduces (shown as
refactored/original) the number of predicates
and literals in the program

Materials We use 130 string transformation tasks from
(Cropper 2019). Each task has 10 examples. An example
is an atom f (x, y) where f is the task name and x and
y are input and output strings respectively. The goal is to
learn to map the inputs to the outputs, such as to map
the full name of a person (input) to its initials (output),
e.g. ’Alan Turing’ (cid:55)→ ’A.T.’. We provide as BK the binary
predicates mk uppercase, mk lowercase, skip, copy, write,
and the unary predicates is letter, is uppercase, is space,
is number.

Method We follow the procedure described in (Cropper
2019) to obtain the play tasks and thus BK. For each of
the 130 tasks, we sample uniformly without replacement 5
examples as training examples and use the remaining 5 as
test examples. We measure predictive accuracy and learning
times (total time needed to solve all target tasks).

Results The results (Figure 5a) show that refactoring
drastically improves predictive accuracies. When learn-
ing from unrefactored BK and BK with redundancies re-
moved, Metagol’s performance quickly deteriorates because
Metagol’s search space increases exponentially in the size
of the BK. By contrast, when given refactored BK, Metagol
has higher predictive accuracy in all cases, eventually four
times higher than without refactored BK. Moreover, the re-
sults shows that refactoring reduces learning times by a
third. Interestingly, the gain in performance does not come
from the reduced number of predicates, as both refactored
and unrefactored programs have equal number of predicates,
though overall program size decreases (Figure 6b). Rather,
the performance gains (both in accuracy and speed) come
from better structured knowledge.

Solver Behaviour Figure 7 shows the reduction of the BK
size during a typical refactoring process for three different
BK sizes. Regardless of the size, the solver is able to ﬁnd
a good solution (within 10% of ﬁnal size) within a minute.
It takes between 2-21 min to reach a solution within 1% of
the ﬁnal size, depending on the number of background tasks.
Though the solver ﬁnd the best solution within an hour, for
most of the runs it continues searching for a better solution
until timeout. This indicates two things: (1) we could have
obtained equally good solutions with a more restrictive time-

Figure 7: Despite the timeout of 90 min, the solver can
quickly ﬁnd a good solution and ﬁnds the best solution
within an hour. Note that axes follow power scale.

out, and (2) the encoding of a problem could be improved as
the solver currently spends most of the time ﬁnding small
improvements.

6 Conclusion
The main claim of this work is that the structure of an
agent’s knowledge can signiﬁcantly inﬂuence its learning
abilities: more knowledge results in larger hypothesis spaces
and makes learning more difﬁcult. Focusing on inductive
logic programming, we introduced a problem of knowl-
edge refactoring – rewriting an agent’s knowledge base, ex-
pressed as a logic program, by removing the redundancies
and minimising its size. We also introduced Knorf, a system
that performs automatic knowledge refactoring by formulat-
ing it as a constraint optimisation procedure. We evaluated
the proposed approach on two inductive program synthe-
sis domains: building Lego structures and real-world string
transformations. Our experimental results show that learn-
ing from the refactored knowledge base results can increase
predictive accuracies in fourfold and reduced learning times
substantially.

Limitations and Future Work We have used one ILP
system that already performs predicate invention. It would

01251020304560Time (min) (e-2)0.000.010.050.100.200.501.00Normalised solution quality (e-3)2.37.320.5100020003000Background taskstime needed to reach quality within 1% of the final solutionbe interesting to see how effective refactoring is when a sys-
tem that does not perform predicate invention. We have fo-
cused on eliminating redundancy to improve performance
of an ILP system. However, there are many other properties
that we may want to optimise, such as modularity or read-
ability. Finally, we have not tackled the question of when to
refactor? Refactoring too often is likely to have negative ef-
fect on learning times. We will investigate the strategies for
detecting the need for refactoring in future work.

References
Ad´e, H.; Malfait, B.; and De Raedt, L. 1994. Ruth: an ilp
theory revision system. In Ra´s, Z. W., and Zemankova, M.,
eds., Methodologies for Intelligent Systems, 336–345. Berlin,
Heidelberg: Springer Berlin Heidelberg.
Balog, M.; Gaunt, A. L.; Brockschmidt, M.; Nowozin, S.; and
Tarlow, D. 2017. Deepcoder: Learning to write programs. In
ICLR. OpenReview.net.
Blumer, A.; Ehrenfeucht, A.; Haussler, D.; and Warmuth,
M. K. 1987. Occam’s razor. Inform. Proc. Lett. 24:377–380.
Cropper, A., and Muggleton, S. H. 2016. Metagol system.
https://github.com/metagol/metagol.
Cropper, A., and Tourret, S. 2020. Logical reduction of
metarules. Machine Learning 109(7):1323–1369.
Cropper, A. 2019. Playgol: Learning programs through play.
In Proceedings of the Twenty-Eighth International Joint Con-
ference on Artiﬁcial Intelligence, (IJCAI-19), 6074–6080.
Cropper, A. 2020. Forgetting to learn logic programs.
In
The Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence,
AAAI 2020, 3676–3683. AAAI Press.
De Raedt, L.; Kersting, K.; Kimmig, A.; Revoredo, K.; and
Toivonen, H. 2008. Compressing probabilistic prolog pro-
grams. Machine learning 70(2):151–168.
De Raedt, L. 1992. Interactive Theory Revision: An Inductive
Logic Programming Approach. GBR: Academic Press Ltd.
Dechter, E.; Malmaud, J.; Adams, R.; and Tenenbaum, J.
2013. Bootstrap learning via modular concept discovery. In
Proceedings of the Twenty-Third International Joint Confer-
ence on Artiﬁcial Intelligence.
Dumanˇci´c, S.; Guns, T.; Meert, W.; and Blockeel, H. 2019.
Learning relational representations with auto-encoding logic
In Proceedings of the 28th International Joint
programs.
Conference on Artiﬁcial Intelligence, IJCAI 2019, 6081–
6087.
Ellis, K.; Morales, L.; Sabl´e-Meyer, M.; Solar-Lezama, A.;
2018. Learning libraries of subrou-
and Tenenbaum, J.
tines for neurally-guided bayesian program induction.
In
Advances in Neural Information Processing Systems 31: An-
nual Conference on Neural Information Processing Systems
2018, NeurIPS 2018, 3-8 December 2018, Montr´eal, Canada,
7816–7826.
Hemaspaandra, E., and Schnoor, H. 2011. Minimization for
generalized boolean formulas. In Walsh, T., ed., IJCAI 2011,
Proceedings of the 22nd International Joint Conference on
Artiﬁcial Intelligence, Barcelona, Catalonia, Spain, July 16-
22, 2011, 566–571. IJCAI/AAAI.
Heule, M.; J¨arvisalo, M.; Lonsing, F.; Seidl, M.; and Biere,
A. 2015. Clause elimination for SAT and QSAT. J. Artif.
Intell. Res. 53:127–168.
Hocquette, C., and Muggleton, S. H.
2020. Complete
bottom-up predicate invention in meta-interpretive learning.

In Bessiere, C., ed., Proceedings of the Twenty-Ninth Interna-
tional Joint Conference on Artiﬁcial Intelligence, IJCAI 2020,
2312–2318. ijcai.org.
Karmiloff-Smith, A. 1992. Beyond modularity. MIT Press.
Lin, D.; Dechter, E.; Ellis, K.; Tenenbaum, J. B.; and Mug-
gleton, S. 2014. Bias reformulation for one-shot function
induction. In ECAI 2014, 525–530.
Mitchell, T. M. 1997. Machine learning. McGraw Hill series
in computer science. McGraw-Hill.
Muggleton, S., and De Raedt, L. 1994.
Inductive logic
programming: Theory and methods. JOURNAL OF LOGIC
PROGRAMMING 19(20):629–679.
Muggleton, S. H.; Lin, D.; and Tamaddoni-Nezhad, A. 2015.
Meta-interpretive learning of higher-order dyadic Datalog:
predicate invention revisited. Machine Learning 100(1):49–
73.
Muggleton, S. 1995. Inverse Entailment and Progol. New
Generation Computing, Special issue on Inductive Logic Pro-
gramming 13(3-4):245–286.
Perron, L., and Furnon, V. 2019. Or-tools.
Plotkin, G. 1971. Automatic Methods of Inductive Inference.
Ph.D. Dissertation, Edinburgh University.
Richards, B. L., and Mooney, R. J. 1995. Automated re-
ﬁnement of ﬁrst-order horn-clause domain theories. Machine
Learning 19(2):95–131.
Rossi, F.; Beek, P. v.; and Walsh, T. 2006. Handbook of Con-
straint Programming (Foundations of Artiﬁcial Intelligence).
USA: Elsevier Science Inc.
Rumelhart, D. E., and Norman, D. A. 1976. Accretion, tuning
and restructuring: Three modes of learning.
Saitta, L., and Zucker, J.-D. 2013. Abstraction in artiﬁcial
intelligence and complex systems. Springer.
Shapiro, E. 1983. Algorithmic program debugging. MIT
Press.
Sommer, E. 1995. FENDER: an approach to theory restruc-
turing (extended abstract). In Machine Learning: ECML-95,
8th European Conference on Machine Learning, Heraclion,
Crete, Greece, April 25-27, 1995, Proceedings, volume 912
of Lecture Notes in Computer Science, 356–359. Springer.
Srinivasan, A.; King, R. D.; and Bain, M. 2003. An empirical
study of the use of relevance information in inductive logic
programming. J. Mach. Learn. Res. 4:369–383.
Srinivasan, A.; Muggleton, S. H.; and King, R. D. 1995.
Comparing the use of background knowledge by inductive
logic programming systems. In Proceedings of the 5th Inter-
national Workshop on Inductive Logic Programming, 199–
230. Department of Computer Science, Katholieke Univer-
siteit Leuven.
Stahl, I. 1993. Predicate invention in ilp – an overview.
In Proceedings of the 6th European Conference on Machine
Learning, ECML’93, 311–322.
Sterling, L., and Shapiro, E. 1986. The Art of Prolog. Cam-
bridge, MA: MIT Press.
Stern, E. 2005. Knowledge restructuring as a powerful mech-
anism of cognitive development : how to lay an early founda-
tion for conceptual understanding in formal domains.
Tamaki, H., and Sato, T. 1984. Unfold/fold transformation
of logic programs. In T¨arnlund, S., ed., Proceedings of the
Second International Logic Programming Conference, Upp-
sala University, Uppsala, Sweden, July 2-6, 1984, 127–138.
Uppsala University.

Wrobel, S. 1996. First-order theory reﬁnement. In Advances
in Inductive Logic Programming, 14–33.

