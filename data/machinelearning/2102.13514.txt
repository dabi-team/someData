1
2
0
2

b
e
F
4
2

]
L
P
.
s
c
[

1
v
4
1
5
3
1
.
2
0
1
2
:
v
i
X
r
a

Learning to Make Compiler Optimizations
More Effective

Rahim Mammadli
Department of Computer Science
Technical University of Darmstadt
rahim.mammadli@tu-darmstadt.de

Felix Wolf
Department of Computer Science
Technical University of Darmstadt
felix.wolf@tu-darmstadt.de

Marija Selakovic
Department of Computer Science
Technical University of Darmstadt
m.selakovic89@gmail.com

Michael Pradel
Department of Computer Science
University of Stuttgart
michael@binaervarianz.de

Abstract
Because loops execute their body many times, compiler de-
velopers place much emphasis on their optimization. Never-
theless, in view of highly diverse source code and hardware,
compilers still struggle to produce optimal target code. The
sheer number of possible loop optimizations, including their
combinations, exacerbates the problem further. Today’s com-
pilers use hard-coded heuristics to decide when, whether,
and which of a limited set of optimizations to apply. Often,
this leads to highly unstable behavior, making the success
of compiler optimizations dependent on the precise way a
loop has been written. This paper presents LoopLearner,
which addresses the problem of compiler instability by pre-
dicting which way of writing a loop will lead to efficient
compiled code. To this end, we train a neural network to
find semantically invariant source-level transformations for
loops that help the compiler generate more efficient code.
Our model learns to extract useful features from the raw
source code and predicts the speedup that a given trans-
formation is likely to yield. We evaluate LoopLearner with
1,895 loops from various performance-relevant benchmarks.
Applying the transformations that our model deems most
favorable prior to compilation yields an average speedup
of 1.14x. When trying the top-3 suggested transformations,
the average speedup even increases to 1.29x. Comparing the
approach with an exhaustive search through all available
code transformations shows that LoopLearner helps to iden-
tify the most beneficial transformations in several orders of
magnitude less time.

1 Introduction
The optimization techniques used in modern compilers are
continuously improving. In view of the increasing complex-
ity of hardware and software, the effectiveness of compiler
optimizations becomes crucial in achieving satisfactory sys-
tem performance. However, despite the tremendous progress
of compiler technology, the optimizations a compiler applies
are usually limited to a fixed set of program transformations.

1

Furthermore, compiler developers manually design optimiza-
tion heuristics that control program compilation and opti-
mization. Writing these heuristics requires expert knowledge
and is one of the most difficult and time-consuming tasks in
compiler development. This is why compiler optimizations
are not guaranteed to produce optimal output, and in fact,
they may even degrade performance in some cases.

A recent study by Gong et al. [23] illustrates the challenges
compiler developers face today. Looking at how source-level
loop transformations affect performance, the authors ob-
served that compilers are not only far from producing opti-
mal code, but are also highly unstable: given semantically
equivalent variants of the same piece of code, compilers
produce target code that differs significantly in terms of per-
formance. As a result of this “compiler instability”, as Gong
et al. named the problem, programmers are left without any
guidance as to which variant of the source code to feed into
the compiler. To maximize performance, a programmer may
choose to deal with compiler instability by (a) systemati-
cally trying as many semantically equivalent code variants
as possible and measure which performs best, or (b) learning
through experience which variant works best for a given
compiler. Since the first option is very time consuming and
the second option requires expert knowledge of the underly-
ing compiler, both strategies are of limited use in practice.
To mitigate the problem of compiler instability, we
present LoopLearner, a learning-based approach that pre-
dicts semantics-preserving transformations of a loop that
will improve the performance of the compiled program.
Given a loop and a search space of such transformations,
LoopLearner predicts which transformation or sequence
of transformations will yield the best-performing target
code with a given compiler. The search space explored by
LoopLearner consists of around 3,000 sequences of transfor-
mations, composed of five basic optimizations, their combi-
nations, and different parametrizations. We focus on loops
for two reasons. First, optimizing loops is important because
the loop body is repeatedly executed, not seldom thousands
of times, which in total accounts for a significant fraction

 
 
 
 
 
 
of the overall execution time. Second, loop transformations
are one of the major optimizations supported by modern
compilers, which is why loops are at the core of compiler
instability.

We envision LoopLearner to be useful in multiple scenar-
ios. First, it can assist developers in deciding how to write a
loop. By predicting which variant of a loop yields the best
performance, developers can make an informed decision, in-
stead of relying on their intuition. Second, the approach can
guide an automated pre-processing step that applies code
transformations before handing the code over to the com-
piler. Such pre-processing does not require any developer
attention and mitigates the problem of compiler instabil-
ity without the need to change the compiler itself. And, of
course, one could also integrate our predictive model directly
into the compiler to improve its stability. In the second and
third usage scenario, LoopLearner’s predictions complement
the built-in optimization heuristics of the compiler by pre-
senting the code in a way that will make best use of these
heuristics.

We define the problem of predicting the best transfor-
mation for a loop as a regression problem: based on the
source code of a given loop, LoopLearner learns to predict
the speedup that a certain transformation is likely to yield.
After training the model with tens of thousands of examples,
we query the model for each transformation to determine
which one gives the highest performance improvement. To
effectively learn the performance benefits of transforma-
tions on specific code, we need a suitable encoding of both
inputs. LoopLearner encodes source code as a sequence of
tokens, and we compare different representations of individ-
ual tokens. To encode transformations, we present a novel,
compact representation that ensures that similar transfor-
mations have a similar representation. LoopLearner uses a
convolutional neural network architecture, which has been
proven as very effective on compositional data.

One of the key challenges in choosing among the available
code optimizations is the large space of possible transforma-
tions. A naive approach could apply each transformation,
then run the compiled code, and measure its execution time.
Unfortunately, this approach takes significant time, in par-
ticular, because reliable performance measurements require
executing the code repeatedly. Instead of executing trans-
formed code, LoopLearner queries a predictive model once
per transformation. Since querying our neural model is very
fast and because queries for different transformations can be
run in batches, our approach reduces the effort for finding a
suitable transformation by multiple orders of magnitude.

Prior learning-based work on improving optimizing com-
pilers aims at finding suitable compiler heuristics, includ-
ing the work by Yuki et al. [57], who predict optimal loop
tiling sizes, Stephenson and Amarasinghe [53], who deter-
mine the best loop unrolling factor, and Simon et al. [52],

who construct compiler heuristics automatically. Our ap-
proach differs those approaches in several ways. One differ-
ence is that we consider a much larger space of optimiza-
tions, that is, nearly 3,000 combinations of five common loop
optimizations—unrolling, unroll and jam, tiling, distribution,
and interchange, including variations of their parameters.
Another distinctive feature of our approach is that it rea-
sons about source-level transformations to be applied before
passing a program to the compiler, instead of optimization
decisions taken in the compiler. Finally, LoopLearner in-
volves neither the manual design nor the pre-selection of
any features. Instead, we feed the source code as-is into a
neural network that learns how to identify suitable features
on its own. Cummins et al. [18] also train a neural model that
predicts from raw code how to support code optimization.
However, their model focuses on a small set of optimization
parameters used in the compiler, e.g., whether to map a ker-
nel to the CPU or the GPU, whereas we consider a larger
space of transformations applied before passing code to the
compiler.

To evaluate LoopLearner we use an extensive collection of
nested loops from the empirical study by Gong et al. [23]. To
train the model, we consider all transformations the study
used to create loop mutations. In total, the data set amounts
to around 70,000 data points, originating from 1,895 unique
loops from 18 benchmarks and almost 3,000 unique trans-
formations. One transformation consists of a sequence of
one or more loop transformations and their parameters. We
find that our model has a precision of 73% when predict-
ing speedups. Furthermore, by ranking all transformations
based on their predicted performance improvements and by
applying the top-1 transformation, LoopLearner achieves a
speedup of 1.14x, on average across all loops. If the developer
or tool tries the top-3 suggested transformations and picks
the best one, the average speedup increases even to 1.29x.

In summary, this paper makes the following contributions:

• Learning-based approach to mitigate compiler instabil-
ity. We are the first to systematically mitigate the prob-
lem of compiler instability through a learned model
that predicts source-to-source transformations likely
to make compiler optimizations more effective. The
deep learning-based model automatically extracts fea-
tures from a given loop, without any manual feature
engineering.

• Search space. The approach scales to a large search
space consisting of thousands of transformations. The
search space is built from five common and semanti-
cally invariant loop transformations, applied alone or
in sequence, and their several parameters.

• Empirical evidence. We empirically demonstrate that
applying the transformation our model deems most fa-
vorable yields an average speedup of 1.14x (for the best

2

predicted transformation) or 1.29x (when considering
the top-3 predictions).

The remainder of this paper is organized as follows. Sec-
tion 2 summarizes the problem of compiler instability de-
scribed by Gong et al. [23]. Section 3 presents our approach
to the selection of beneficial loop transformations. Section 4
discusses experimental settings and results. Finally, we dis-
cuss related work in Section 5 and review our results in
Section 6.

2 Background
The attribute stable characterizes a compiler that produces
the same performance for any semantically equivalent vari-
ant of a program. In their study, Gong et al. [23] evaluate the
stability of modern compilers by applying several source-
to-source transformations to obtain semantically equivalent
code variants and by measuring the variation in their execu-
tion time. To illustrate the effect of program transformations
on compiler stability, consider the example in Listing 1. The
first loop is extracted from function Regclass in the SPEC
CPU2000 benchmark suite. After unrolling the loop with
a factor of two, yielding the second loop in the listing, the
Clang compiler generates output that is, on average, 1.19x
faster than the original loop.

/* original loop */
for ( Class = 0; Class < 256; ++ Class ){

if ( opnd [1 +( Class >> 3 & 31)] & 1 <<( Class & 7)){

I32 cf = Perl_fold [ Class ];
opnd [1 +( cf >> 3 & 31)] |= 1 <<( cf & 7);

}

}

/* unrolled , factor = 2 */
for ( Class = 0; Class <= 255; Class += 2) {

if ( opnd [1 +( Class >> 3 & 31)] & 1 <<( Class & 7)){

I32 cf = Perl_fold [ Class ];
opnd [1 +( cf >> 3 & 31)] |= 1 <<( cf & 7);

}
if ( opnd [1 +( Class +1 >> 3 & 31)] & 1 <<( Class +1 & 7)){

I32 cf = Perl_fold [ Class +1];
opnd [1 +( cf >> 3 & 31)] |= 1 <<( cf & 7);

}

}
Listing 1. Original and unrolled loop in function Regclass
from the 253.perlbmk program in the SPEC CPU2000 bench-
mark suite.

Gong et al. quantify compiler stability using the follow-
ing two metrics: intra-compiler and inter-compiler stability.
The first metric, which is the focus of this paper, measures
the stability of a single compiler, while the second metric
measures the stability across multiple compilers. Although
the authors of the study concede that building a perfectly
stable compiler is almost impossible, they show that modern
compilers have ample potential for improvement in this di-
rection. Specifically, they demonstrate that applying source-
level transformations prior to compilation can significantly
reduce the performance gap between variants of a loop. A

Table 1. Loop transformations and their parameters.

Transformation Parameters

Unroll factor ∈ {2, 4, 8}

Unrolling
Unroll-and-jam Loop level, unroll factor ∈ {2, 4}
Tiling
Interchange
Distribution

Loop level, tile size ∈ {8, 6, 32}
Lexicographical permutation number
No parameters

problem not addressed by prior work is which out of many
possible transformations to apply to a given piece of code.
The purpose of our work is to address the problem of
intra-compiler instability, by learning code transformations
that should be applied to maximize the performance of the
compiler output. We train our model on the same source code
examples and transformations used in the original study by
Gong et al. Each loop transformation consists of a sequence
of well-known base transformations, which are listed in
Table 1. To ensure that transformations produce semantically
equivalent output for every loop, the space of considered
transformations is limited to sub-sequences of the following
sequences:

• interchange → unroll-and-jam → distribution → un-

rolling

• interchange → tiling → distribution → unrolling

In total, this space consists of almost 3,000 unique transfor-
mations (i.e., sub-sequences), each of them combining base
transformations with different parameters. The number of
transformations applied to a specific loop is much smaller
(37, on average), because only some transformations can be
applied in a semantics-preserving way. Yet, as we show in
Section 4.6, exhaustively exploring the performance impact
of all transformations is still rather expensive.

3 Approach
In this section, we describe the LoopLearner approach, which
mitigates the problem of compiler instability by predicting
loop transformations that enable the compiler to produce
efficient target code. We start with a rough overview and
potential usage scenarios, before we define our learning prob-
lem. Afterwards, we discuss preprocessing steps applied to
the data, before showing which encoding methods we exper-
imented with. Next, we introduce our deep-neural-network
(DNN) architecture and discuss design decisions made while
building it. Finally, we specify the set of hyperparameters
used to train the neural model.

3.1 Overview
Figure 1 illustrates our approach on a high level. The input
to our network is a loop and a transformation that may be
applied to it. We assume that the transformation is valid and
does not affect the semantics of the program. For the dataset

3

used in the evaluation, which we borrowed from Gong et
al. [23], these properties are ensured using the polyhedral
optimizer Polyopt/C 1 and the dependence analyzer Candl 2.
As a first step, we tokenize the loop with the help of a lexer.
The resulting sequence of tokens is then encoded using one
of the methods discussed in Section 3.6. To feed the trans-
formation into the model, the approach encodes it into a
compact, similarity-preserving representation presented in
Section 3.7. Given both the code and the transformation,
the model predicts the speedup, i.e., the ratio of the original
loop’s execution time divided by the execution time obtained
by applying the transformation. Hence, having a set of valid
transformations that can be applied to a given loop, our neu-
ral network can be used to rank them by their predicted
speedup. Given a ranked list of transformations, the user or
a tool can then apply the transformation that is expected to
produce the highest speedup.

3.2 Interpreting Predictions
To interpret the predictions of our model, we start by speci-
fying a speedup threshold, which is a hyperparameter used
to classify the prediction as either advantageous, disadvan-
tageous, or neutral. Formally, let 𝑝 be the prediction of the
model, 𝑎 be the actual performance, and 𝑡 be a speedup
threshold with 𝑡 > 1. Then, the prediction is assigned to one
of three classes:

• advantageous, if 𝑝 > 𝑡
• disadvantageous, if 𝑝 < 1 − (𝑡 − 1)
• neutral, if 1 − (𝑡 − 1) ≤ 𝑝 ≤ 𝑡

A prediction is considered to be accurate if:

(𝑝 > 1 ∧ 𝑎 > 1) ∨ (𝑝 ≤ 1 ∧ 𝑎 ≤ 1)

Since our solution is intended to achieve speedup and
avoid slowdown, we value a high precision rate for speedup
predictions. Therefore, increasing 𝑡 (i.e., the range where
the model predicts neutral) allows us to focus on clearer
predictions of speedups and slowdowns, which is likely to
increase precision but to reduce recall.

3.3 Usage Scenarios
A programmer or a tool facing the problem of choosing the
best transformation for a given loop has multiple options.
The first option involves applying no transformations and
relying on the compiler to determine and apply the best set of
optimizations. The second option is to test the performance
of the loop with 𝑘 different transformations and choose the
one producing the highest speedup. As discussed earlier,
the number of transformations, their combinations, and the
number of parameters that each of them accepts can result in
a very high number of distinct transformations applicable to
a given loop. Therefore, in most real-life scenarios measuring

1http://web.cse.ohio-state.edu/~pouchet.2/software/polyopt
2http://icps.u-strasbg.fr/people/bastoul/public_html/development/candl

4

the performance of a loop with all possible transformations
is not feasible. It can, however, be feasible to evaluate 𝑘
transformations if 𝑘 is a relatively small number.

To aid the programmer or tool in choosing the best set
of transformations for a given loop we consider two usage
scenarios of LoopLearner:

• If evaluating the performance of loops with and with-
out applying transformations is prohibitively expen-
sive, we propose using LoopLearner in a static scenario.
This scenario implies applying the best advantageous
transformation if such a transformation exists.

• If evaluating the performance of up to 𝑘 mutations of
loops is feasible, LoopLearner can be used in a dynamic
scenario, which involves applying the top-𝑘 advan-
tageous transformations and measuring their actual
performance. If none of the transformations results
in actual speedup, the original loop is left untouched.
Otherwise, the programmer or a tool chooses the trans-
formation resulting in the highest speedup.

3.4 Definition of the Learning Problem
The task of predicting a speedup achievable by applying a
given transformation to the loop can be viewed as a regres-
sion problem. Specifically, given a dataset {(𝐿𝑖,𝑇𝑖 ) → 𝑆𝑖 }𝑁
𝑖=1,
where 𝑁 is the size of the dataset, 𝑆𝑖 is the speedup or slow-
down resulting from applying the transformation 𝑇𝑖 to the
loop 𝐿𝑖 , our goal is to learn an approximation of the function
𝑓 (𝐿,𝑇 ) = 𝑆. To this end, we train a neural network 𝑓𝑝 to
minimize the mean squared error as our loss function:

L =

1
𝑁

𝑁
∑︁

𝑖=1

(𝑓𝑝 (𝐿𝑖,𝑇𝑖 ) − 𝑆𝑖 )2

3.5 Preprocessing
The input given to LoopLearner is a set of loops, each ex-
tracted into a separate file from a larger program. As dis-
cussed in Section 2, our dataset is based on loops used in the
study by Gong et al. Their technique for extracting loops
can be easily applied to other programs as well. Before train-
ing the model, we preprocess the data as follows. For each
loop in the original program, we extract tokens from the
source code, such that a token is represented as a pair (𝑡, 𝑣),
where 𝑡 is its syntactic type and 𝑣 is the value, i.e., a string
representation of the token in the source code.

For many learning tasks where the input data is a sequence
of variable length it is common to select the maximum length
beforehand. The input sequences of smaller lengths are then
padded to the maximum length which makes it possible to
vectorize the computations. To avoid long training times and
be able to initialize the building blocks of our neural network,
we exclude sequences of tokens longer than 250. In this way,
we are able to achieve good model efficiency (Section 4.5)
while keeping 90% of the loops from the original dataset.

Figure 1. High-level overview of LoopLearner.

3.6 Encoding of Source Code
To feed the data to the neural network, we have to encode
both the sequences of tokens and the transformations. The
quality of encoding strongly impacts both the achievable
level of accuracy and the generalization capability of the
trained model. We have experimented with multiple methods
of encoding the sequences of tokens. Here we describe an
interesting subset of these methods and their differences.

Some encoding methods are based on the frequency of
tokens in the code corpus used for training. Specifically, we
compute the following three frequency maps:

• 𝐹𝑡𝑜𝑘𝑒𝑛𝑠 : Token → N, which assigns a frequency to

each token in the code corpus,

• 𝐹𝑖𝑑𝑠 : Identifier → N, which assigns a frequency to

each identifier in the code corpus,

• 𝐹𝑠𝑡𝑑𝑇 𝑜𝑘𝑒𝑛𝑠

: Identifier → N, which assigns a fre-
quency to each token that is neither an identifier nor
a literal.

Table 2 gives an overview of the six encoding methods we

consider and which we explain in detail in the following.

Fixed encoding. This encoding uses a one-hot encoding
of the top 𝑛 most popular tokens in 𝐹𝑡𝑜𝑘𝑒𝑛𝑠 and assigns a
special unknown token to all other tokens. This method is
easy to implement, but has several disadvantages. First, the
size of the encoding increases linearly with the size 𝑛 of the
vocabulary, resulting in a increasing learning times. Next, all
the words outside the vocabulary are encoded with the same
unique token, which may result in a loss of vital information.
Finally, this method does not discriminate between different
types of tokens, i.e., keywords, identifiers, literals, etc. are
all encoded as equidistant points in space.

Basic encoding. This encoding is based on a one-hot en-
coding of all tokens in 𝐹𝑠𝑡𝑑𝑇 𝑜𝑘𝑒𝑛𝑠 , i.e., the set of standard
tokens defined by the language, but not identifiers and liter-
als. For literals, the encoding converts integer literals to base
10 and assigns special id and unknown tokens to identifiers
and other tokens, respectively. In contrast to the fixed en-
coding, this method encodes the tokens based on their type.
The reason for handling integers specially is that we observe
integers to sometimes influence optimization decisions, e.g.,
in loop headers. In contrast, other literals, e.g., characters
and floating-point values, are assumed not to influence the

5

prediction accuracy and are therefore encoded as a special
unknown token. Omitting these tokens completely would
change the structure of the code and potentially inhibit the
performance of the neural network. The main disadvantage
of this method is that it uses the same vector representation
for all identifiers and thus hinders the learning capability of
the network.

Type-based encoding. This encoding is similar to basic,
except that it replaces identifiers with the types of the cor-
responding variables for the most common data types: int,
double, long, float, struct, char, short. While this method
preserves the data type of many variables, all identifiers
sharing the same data type get identical vector represen-
tations, which prevents the network from distinguishing
them.

Renaming encoding. This encoding is also similar to ba-
sic, except that each unique identifier is encoded as a one-
hot vector of size 𝑚, where 𝑚 defines the maximum number
of distinct identifier representations possible. The mapping
from variable name to one-hot vector can be seen as a con-
sistent renaming. This mapping is determined randomly, so
as to prevent the order of the appearance of the identifiers
from affecting the encoding.

Since the majority of unique tokens are identifier names,
and because it is impractical to encode all identifiers, we
use 𝐷𝑖 to calculate the minimum number of identifiers we
would need to encode to cover a given percentage of tokens
in the source code and store it in dictionary 𝐼𝑐𝑜𝑣, where every
integer percentage 𝑝 maps to the number of identifiers we
would need to encode. Based on these statistics we devise
various methods of encoding the data:

Complex encoding. This encoding uses 𝐹𝑖𝑑𝑠 to compute
a minimal set of identifiers that covers at least c% of all
occurrences of identifiers across the code corpus. Based on
this set of frequent identifiers, the encoding preserves all
frequent identifiers and only abstracts the remaining ones
as unknown. Each integer literal is converted to a one-hot
vector of size 64, based on the logarithm of its value. This is
done to pass the scale of the literal to the network. In contrast
to the fixed encoding and similar to the basic encoding, this
method distinguishes among different token types, but also
manages to cover a high number of unique identifiers.

 1.15 Expected speedup Tokens Loop  Lexer Sequence Encoder Encoded tokens     Transformation Sequence Transformation Encoder Compact encoding    Table 2. Encoding methods for tokens.

Encoding

Standard
tokens

Identifiers

Literals

One-hot encode top-n tokens, rest as unknown

One-hot All as id

Fixed
Basic
Type of the identifier
Type-based One-hot
One-hot
Renaming
Consistent mapping to one-hot vectors
One-hot One-hot encoding of top c%, rest as id
Complex

Keep integers, rest as unknown
Keep integers, rest as unknown
Keep integers, rest as unknown
One-hot encoding log(n) of inte-
gers, rest as unknown

FastText

Learned embeddings of size 100

The first five methods above encode tokens as one-hot vec-
tors based on pre-calculated statistics. However, they all
share the same disadvantages: the size of the vocabulary
might become very large for big code corpora, and the to-
kens outside of the vocabulary are all represented as a single
special unknown token. The following encoding addresses
these limitations.

FastText encoding. In natural language processing, an
embedding [1, 33, 34, 36] is a mapping of words to a vec-
tor of real numbers with a much lower dimension. It is a
popular language modeling and feature learning technique
already used for learning effective source-code representa-
tions [9, 47]. In our approach, we apply the FastText em-
bedding technique [34] to source code. We build FastText
embeddings using all the sequences of token values in our
training data. The size of the embedding vector is set to
100 and the model is trained for 100 epochs. Once this pre-
training step is complete, we train our model by encoding
token sequences with the help of the learned vector map-
pings for token values. FastText is especially suitable for
source code because many variable names are combinations
of multiple words, for example, array_size, viewCount, etc.
Fasttext handles such names by not only learning embed-
dings for the tokens in the vocabulary but by also calculating
embeddings for previously unseen words. This is done by
breaking words into smaller sequences, calculating vector
representations of each and using them to reconstruct the
encoding of the whole word.

3.7 Encoding of Code Transformations
To enable our model to learn effective transformations, we
need to encode nearly 3,000 unique transformations with
varying numbers of training samples for each transformation.
A naïve approach is to use a one-hot encoding for all trans-
formations. However, in this case, the size of the encoding
vector would be very large and less popular transformations
would not have enough associated data points for the train-
ing process to be successful. Furthermore, a one-hot encod-
ing does not capture similarities between transformations,
that is, all transformations are represented as equidistant

Figure 2. Vector encoding of transformations.

points in space, although some are much more similar than
others. Another approach is to select only the most popu-
lar transformations and to one-hot encode them. While this
allows us to train the model on the most common trans-
formations, it has certain disadvantages. For example, by
picking the 50 most popular transformations and ignoring
the rest, we would lose 73% of our data and therefore prevent
our model from learning many beneficial transformations.
To address the aforementioned points, we present compact
encodings of code transformations, where each sequence of
transformations is represented as a feature vector. The encod-
ing exploits the fact that transformations can only be applied
in particular orders that preserve the semantics of the origi-
nal program (Section 2). Because the set of transformations
included in a sequence of transformations is sufficient to
uniquely specify the sequence, the features in the encoding
indicate the presence or absence of a particular transforma-
tion and the set of its parameters. We formally define the
encoding as follows.

Definition 3.1 (Compact encoding of transformations). We
encode a sequence of transformations 𝑇 as a concatenation
of vectors 𝑇1, .. , 𝑇𝑘 , where each 𝑇𝑖 represents a vector encod-
ing for transformation 𝑖. The size of a vector 𝑇𝑖 is equal to
a maximum number of different parameterizations of trans-
formation i. The first element in 𝑇𝑖 indicates whether 𝑖 is
applied, while the subsequent elements indicate which pa-
rameter of 𝑖 is enabled. For the transformations considered
in this work, we define the size of subvectors 𝑇𝑖 as follows:

• 𝑠𝑖𝑧𝑒 (𝑇𝑢𝑛𝑟𝑜𝑙𝑙 ) = 4
• 𝑠𝑖𝑧𝑒 (𝑇𝑢𝑛𝑟𝑜𝑙𝑙 𝑗𝑎𝑚) = 7
• 𝑠𝑖𝑧𝑒 (𝑇𝑡𝑖𝑙𝑖𝑛𝑔) = 13

6

unr.f = 2f = 4f = 84  4713302unr.jam.tilinginterchangedistrib.0/13.8 DNN Architecture
To train a model that predicts beneficial transformations for
a loop, we consider two different network architectures: re-
current and convolutional. Recurrent neural networks (RNN)
have been designed to recognize patterns in sequences of
data, such as text or numerical times series. The main prop-
erty of RNNs is the internal memory used to keep outputs
of the previous steps, which is then fed as input to the cur-
rent step. In contrast, convolutional neural networks (CNN)
are suitable for hierarchical data. The most distinctive prop-
erty of CNNs are their convolutional layers, which perform a
mathematical convolution operation on the input data. Con-
volutional layers consist of feature matrices that learn to rec-
ognize features in the input. Stacking convolutional layers
on top of each other allows the later layers to learn increas-
ingly complex features, which makes CNNs so powerful for
any task involving compositional data.

The advantage of recurrent neural networks is that they
process sequences of arbitrary length. However, vanishing
gradients and increased computational demand for the train-
ing process makes it harder to train the network with very
long input sequences. While convolutional neural networks
lack the ability to process sequences of variable length, they
excel on datasets of compositional data. Since the source
code is not only sequential but also highly compositional,
CNNs are a good fit for this task. Our experimental evalua-
tion shows that convolutional networks have a higher level
of accuracy compared to recurrent networks. This is why
we decided to choose CNNs as our default architecture.

Specifically, we adopted ideas from DenseNet [31], a well-
known design from the field of computer vision. However,
we custom-tailored the DenseNet architecture to fit our learn-
ing problem. Figure 3 further illustrates the architecture of
our model. The inputs to our model are encoded tokens of a
loop and encoded transformations. Because our input is com-
positional along a single dimension, we use one-dimensional
convolutions instead of the two-dimensional variants used
in the original DenseNet. The building blocks of our neural
network are dense layers which learn to extract features
from the source code. As further illustrated in Figure 4, each
dense layer consists of two convolutional layers and the in-
puts of each dense layer are concatenated with the outputs
of previous layers and fed into subsequent layers. Eventually,
the model performs average-pooling on the outputs of the
final convolutional layer, concatenates the results with the
transformation vector, and passes the concatenated vector
into a fully connected layer, which is used to predict the
expected speedup.

3.9 Training
We feed training samples in batches of 256 into the network
and use the stochastic gradient descent method to train the
network for 300 epochs. The initial learning rate of 0.001 is

7

Figure 3. Prediction process for a sequence of tokens and
transformations. The encoded sequence of tokens is first
passed into the feature extractor. The results are concate-
nated with the encoded vector of transformations and passed
to the fully connected layer which predicts the speedup.

Figure 4. The dense layer of the DNN consists of two con-
volutional layers. The outputs of the dense layer are concate-
nated with the inputs and passed on to the next layer.

• 𝑠𝑖𝑧𝑒 (𝑇𝑖𝑛𝑡𝑒𝑟𝑐ℎ𝑎𝑛𝑔𝑒 ) = 30
• 𝑠𝑖𝑧𝑒 (𝑇𝑑𝑖𝑠𝑡𝑟𝑖𝑏𝑢𝑡𝑖𝑜𝑛) = 2

Figure 2 illustrates the compact encoding of loop transfor-
mations. The final size of the encoding vector is 56. The first
four elements are reserved for the 𝑇𝑢𝑛𝑟𝑜𝑙𝑙 subvector. The first
element in 𝑇𝑢𝑛𝑟𝑜𝑙𝑙 has a value of 0 or 1, indicating whether
unrolling is part of the transformation (0-no, 1-yes). The
next three elements are used to encode the unrolling fac-
tor. For example, if unrolling is applied with factor 2, then
the first two elements of 𝑇𝑢𝑛𝑟𝑜𝑙𝑙 would have value 1 and the
remaining ones would be set to 0. We encode other transfor-
mations in a similar fashion, taking into account all possible
combinations of their parameters.

1	for	2	(	3	int	4	i	5	=	6	0	.	.	.	250	}	unr.	unr.jam	tiling	interchange	distrib.	Encoded	Transformation	Encoded	Tokens					Fully	Connected	Layer			Prediction	Feature	Extractor														Dense	Layers								x	6			    Dense LayerDense Layerconv1conv2InputOutputdropped to a third of its value in epochs 100 and 200, and
a momentum factor of 0.9 is used for optimization. We clip
the gradients with the absolute value above 10 to avoid the
exploding gradients problem. At the end of every epoch, we
evaluate the model and save the best-performing model.

3.10 Implementation
The code is parsed and tokenized by using the lexer com-
ponent of the Python pycparser3 library, a parser for the C
language. To build and train the models we use the PyTorch
framework, version 0.4.14. We implement LoopLearner as an
extensible framework that takes as input the following key
parameters:

• sequence encoding: fixed, basic, type-based, renaming,

complex, or fasttext

• transformation encoding: one-hot or compact
• model type: recurrent or convolutional

This allows easy plugin of new types of encodings and

neural network architectures.

4 Evaluation
Our evaluation focuses on the following questions.

• How effective is LoopLearner at predicting beneficial

loop transformations? (Sections 4.2, 4.3, and 4.7)

• What speedups do LoopLearner’s predictions enable?

(Section 4.4)

• How efficient is LoopLearner? (Section 4.5)
• How does the approach compare to exhaustively try-

ing all loop transformations? (Section 4.6)

• What is the influence of the speedup threshold? (Sec-

tion 4.8)

4.1 Experimental Setup
Our dataset is built from 1,895 base loops extracted by prior
work [23] from various benchmarks, software libraries, and
machine-learning kernels written in C. Extracting each loop
into a standalone program that replicates the data envi-
ronment of the original benchmark program, applying se-
quences of transformations, and measuring their perfor-
mance yields a dataset of roughly 70,000 (loop, transfor-
mation, speedup) triples. The loops are compiled with the
GNU GCC compiler, using the -O3 flag, and executed on an
Intel Xeon E5-1630 v3 processor.

We split the dataset into a training and a validation set by
randomly selecting 80% of all loops and their associated trans-
formations for training, and the remainder for validation. By
splitting by loop, we ensure that the evaluation measures
how well the approach performs on previously unseen loops.
Unless explicitly stated otherwise, we use speedup thresh-
old 𝑡 = 1.0. We trained our models on a single server with
two Intel(R) Xeon(R) Gold 6126 2.60GHz CPUs, 64GBs of

3https://github.com/eliben/pycparser
4https://pytorch.org/docs/0.4.1/

8

main memory, two NVIDIA GeForce GTX 1080 Ti GPUs,
and Ubuntu 16.04 LTS operating system. For the purpose of
training any given model, a single GPU was used at a time.

the

4.2 Overall Accuracy of Predictions
4.2.1 Metrics. We first measure
accuracy of
LoopLearner’s predictions across all loops and transfor-
mations in the validation set. Let 𝑇 be the set of all (loop,
transformation) pairs. Let 𝑇 + ⊆ 𝑇 and 𝑇 − ⊆ 𝑇 be the
subset of all pairs known to cause a speedup and slowdown,
respectively. Let 𝑃 + ⊆ 𝑇 and 𝑃 − ⊆ 𝑇 be the subset of all
the pairs predicted to result in a speedup and slowdown,
respectively. We consider the following metrics:

• Total accuracy (%) is the percentage of elements out of

𝑇 that are in (𝑃 + ∩ 𝑇 +) ∪ (𝑃 − ∩ 𝑇 −).

• Speedup recall (%) is the percentage of elements out of

𝑇 + that are in 𝑃 + ∩ 𝑇 +.

• Speedup precision (%) is the percentage of elements out

of 𝑃 + that are in 𝑃 + ∩ 𝑇 +.

• Slowdown recall (%) is the percentage of elements out

of 𝑇 − that are in 𝑃 − ∩ 𝑇 −.

• Slowdown precision (%) is the percentage of elements

out of 𝑃 − that are in 𝑃 − ∩ 𝑇 −.

We calculate the last four metrics alongside the total accu-
racy for two reasons. First, our dataset is imbalanced—more
than 80% of transformations result in slowdown and there-
fore high total prediction accuracy alone does not necessarily
imply high accuracy for both speedups and slowdowns. Sec-
ond, the recall and precision metrics help understand how
well the approach performs in a particular usage scenario.
For example, speedup precision shows how often a predicted
speedup indeed improves the loop’s performance. We also
show the F1 score (harmonic mean of precision and recall).

4.2.2 Results. Table 3 summarizes the results. To under-
stand the influence of different encodings and models, we
report results for different variants of LoopLearner. The best
result for each metric is highlighted in bold font. Overall, the
approach predicts beneficial loop transformations with high
accuracy (up to 88%). Comparing speedup and slowdown
predictions, the model is particularly effective at predicting
that a transformation will cause a slowdown (95% recall, 92%
precision), but also provides reasonable results for speedups
(55% recall, 66% precision).

Comparison of source code encodings. Remarkably,
fixed encoding achieves the highest accuracy on the train-
ing set and relatively good accuracy on the validation set,
while also being the easiest to implement. We attribute this
result to the higher dimensionality of the input data. Since
each token is represented as a vector in space R1001, that
is, each of the top 1,000 most common tokens and a special
unknown token get unique representations, it is quite easy
for the network to learn to differentiate between distinct

Table 3. Overall accuracies achieved by employing different encoding methods. Training accuracy reflects the highest achieved
accuracy on the training set. All other values refer to the validation set.

Sequence Encoding

Training

Validation

Transformation Encoding: Compact

Accuracy (%)

Speedup (%)
Precision

Recall
Model: CNN

F1

Recall

Slowdown (%)
Precision

Fixed(n=1,000)
Basic
Type-based
Renaming(m=40)
Complex(c=70%)
Complex(c=80%)
FastText

92.5
90.0
89.8
88.8
92.1
92.0
92.0

Transformation Encoding: One-hot

FastText

89.2

Transformation Encoding: Compact

FastText

84.8

87.6
84.0
84.0
84.0
87.9
87.7
88.1

87.1

84.0

55.9
7.7
4.3
11.1
57.0
58.2
54.8

63.0
54.8
56.4
51.7
64.1
62.9
66.1

59.2
13.5
7.9
18.3
60.4
60.5
59.9

Model: CNN

43.0

65.3

51.8

Model: RNN

4.4

56.0

8.1

93.7
98.8
99.4
98.0
93.8
93.4
94.6

95.6

99.3

F1

92.7
91.2
91.2
91.1
92.9
92.7
93.0

91.7
84.7
84.3
85.1
91.9
92.1
91.6

89.7

92.5

84.3

91.2

tokens. However, apart from the size of the input data, the
disadvantage of using fixed encoding when compared to
more advanced methods is that the gap between the training
and validation set accuracy for this method is also quite high,
which means it tends to overfit the training data while not
performing as well on the validation set. The reason is that
the top 1,000 most common tokens are extracted from the
training set, which is likely to be somewhat different from
the validation set.

Although the accuracy achieved by the “basic” encoding
is roughly that of other encodings, the speedup prediction
results show a significant weakness of the “basic” encoding.
The model achieves only 7.7% speedup recall, because cru-
cial information is lost when discarding identifier names,
float literals, and char literals during encoding. As shown
by the results of the “type-based” encoding, replacing identi-
fier names with type information does not make the model
any more accurate. Consistently abstracting variable names
into generic names (“renaming”) slightly improves the re-
sults, but still offers only low speedup prediction results. The
main take-away of these results is that identifier names and
literal values are helpful in learning-based program analy-
sis, a finding in line with other work on name-based and
learning-based analysis [39, 47].

The “complex” encoding method achieves fairly high
training- and validation-set accuracy. The substantially
higher accuracy compared to “basic” encoding confirms the
importance of encoding identifier names. However, compar-
ing the two variants of “complex”, which keep 70% and 80%
of all identifiers, respectively, shows that adding another 10%
of less common identifier names does not raise the accuracy
any further. We believe that after a certain point, increas-
ing the size of the encoding vector by adding rare identifier
names does not benefit the accuracy of the trained model and
can actually be harmful, since it is likely that the model will

learn to overfit the training samples based on the occurrence
of rare identifiers.

The “FastText” encoding achieves the highest overall vali-
dation accuracy, showing that pre-training general-purpose
token embeddings before passing them into a task-specific
model is beneficial. The difference between training accuracy
and validation accuracy is at a minimum when using the
“FastText” encoding, i.e., there is only little overfitting. Since
we obtain the best overall accuracy the “FastText” encoding,
this encoding is the default in the remainder of the section.

Comparison of transformation encodings. Compar-
ing our compact encoding of transformations with a naive
one-hot encoding of transformations shows that the compact
encoding is beneficial. In particular, it enables the model to
predict otherwise missed speedups. We attribute this result
to the fact that the dense encoding makes it easier for the
model to generalize across similar transformations, as those
are encoded into similar vectors.

Comparison of neural architectures. We compare our
default CNN-based neural architecture to a recurrent neural
network with two layers of gated recurrent units and a size
similar to the CNN architecture. The comparison shows the
CNN model to be clearly more effective, in particular in
predicting speedups.

4.3 Effectiveness of Top-k Predictions per Loop
4.3.1 Metrics. To better understand how effective
LoopLearner is for individual
loops, we evaluate the
effectiveness of those 𝑘 transformations per loop that
LoopLearner predicts to have the highest speedups. Let 𝐿
be the set of all the loops, let 𝐿+ ⊆ 𝐿 be the subset of the
loops for which there exists at least one transformation that
produces a speedup, let 𝑃 (𝑙)
𝑜 be the set of transformations
that can be applied to the loop 𝑙 ∈ 𝐿 ordered by the predicted

9

Table 4. Top-1, top-3 and top-5 accuracy of the network on
the validation set and the corresponding values for precision,
recall, and the mean speedup achieved in both static and
dynamic mode of execution.

Top

Total

Speedup

k Acc. (%) Recall (%) Precision (%) Static Dynamic
1
3
5

1.235x
1.285x
1.290x

1.144x
N/A
N/A

73.05
75.18
75.89

39.46
40.61
41.00

64.91
79.95
83.38

performance from highest to lowest, let 𝑃 (𝑙)
(𝑘) ⊆ 𝑃 (𝑙)
𝑜 be
𝑜
𝑜𝑠 (𝑘) ⊆ 𝑃 (𝑙)
the first 𝑘 transformations in this set, let 𝑃 (𝑙)
(𝑘)
𝑜
be the subset of transformations that are predicted to be
advantageous, and let 𝐿𝑠𝑝 ⊆ 𝐿 be the subset of the loops for
which 𝑃 (𝑙)
𝑜𝑠 (1) ≠ ∅. Then, to measure the top-k effectiveness
of our model we calculate:

• Total accuracy (%) is the percentage of loops 𝑙 ∈ 𝐿 for
which at least one of the predictions for transforma-
tions in 𝑃 (𝑙)
𝑜

(𝑘) is correct.

• Speedup recall (%) is the percentage of loops 𝑙 ∈ 𝐿+ for
𝑜𝑠 (𝑘) produces

which at least one transformation in 𝑃 (𝑙)
a speedup.

• Speedup precision (%) is the percentage of loops 𝑙 ∈
𝐿𝑠𝑝 for which at least one transformation in 𝑃 (𝑙)
𝑜𝑠 (𝑘)
produces a speedup.

4.3.2 Results. Table 4 shows the results (the last two
columns are described later). We find that the approach
achieves an accuracy of 65% when considering only the
top-most prediction for a loop, and of 83% within the top-5
predictions. The precision of speedups ranges between 73%
and 76% percent, i.e., when the model predicts a speedup,
then the code indeed performs faster in most cases. The
reason why the validation accuracy for top-1 predictions is
lower than the overall accuracy is that the distribution of
the numbers of possible transformations across the loops
is non-uniform. Some loops have a much higher number of
valid transformations than others, and for some loops the
top-1 prediction is more likely to be accurate than for others.

4.4 Speedups Achieved due to LoopLearner
4.4.1 Metrics. We evaluate the speedups obtained by ap-
plying the transformations suggested by LoopLearner in
both the static and the dynamic usage scenario (Section 3.3).
The speedups in the static scenario show the performance
improvement that can be immediately achieved when apply-
ing LoopLearner’s top suggested transformations, while the
dynamic scenario shows the potential speedup attainable
when validating LoopLearner’s predictions. We compute the
following two metrics:

• Speedup geometric mean (static) is defined only for
𝑘 = 1 and is the geometric mean of speedups across all

10

loops 𝑙 ∈ 𝐿𝑠𝑝 achieved when applying transformation
𝑃 (𝑙)
𝑜𝑠 (1).

• Speedup geometric mean (dynamic) is the geometric
mean of speedups across all loops 𝑙 ∈ 𝐿𝑠𝑝 achieved
when applying the transformation with the best per-
formance out of 𝑃 (𝑙)
𝑜𝑠 (𝑘), or 1.0 if none of the top-𝑘
transformations results in speedup.

4.4.2 Results. The last two columns of Table 4 shows the
speedups for both scenarios. We find that LoopLearner en-
ables significant speedups in both cases, with a 1.14x speedup
when simply using the top-1 prediction, and an 1.29x speedup
when choosing the best from the top-5 predictions. Because
in the dynamic scenario, the transformed loops are executed
to measure their performance, the mean speedup is guaran-
teed to be at least as high as in the static scenario.

4.5 Efficiency of LoopLearner
We summarize the execution time for different phases of our
approach when running on either CPU or GPU in Table 5.
Before training our model we learn FastText embeddings,
which takes about 20 seconds on our dataset using 32 worker
threads. By far the most computationally demanding part
of our approach is training the neural network. With hy-
perparameter settings discussed earlier it takes around 6
hours and 40 minutes to complete the training. However,
we believe this time can be brought down substantially by
using higher batch sizes along with more memory-efficient
implementations of the DenseNet architecture. Moreover,
the training step, despite being the most time-consuming, is
only performed once and afterwards the resulting model is
ready to be deployed.

Because a high number of transformations can be applied
to a given loop, our model must be executed many times
before it is possible to decide which transformation is the
most beneficial. During prediction, the most computationally
intensive part is the feature extractor, which processes the
token sequences of a loop. Fortunately, it is sufficient to run
the feature extractor for any given loop only once. Then, the
fully connected layer can be used to evaluate many possible
transformations in a batch. As can be observed in Table 5, it
takes less than 20 milliseconds to evaluate 1,000 transforma-
tions for a single loop on a CPU and less than 2 milliseconds
for the same task on a GPU. We believe that these results
show that it is practical to implement LoopLearner as an
automated pre-processing step before giving code to the
compiler.

4.6 Comparison with Exhaustive Search
An alternative to querying LoopLearner for transformations
that are likely to improve the performance of a loop is exhaus-
tive search through all possible sequences of transformations.
By measuring the performance impact of each sequence of
transformations, that alternative approach is guaranteed to

Table 5. Time requirements of the different phases of our
approach.

Approach phase
Time (CPU) Time (GPU)
Learning embeddings
20 seconds N/A
Training (1 epoch)
N/A
Evaluation (single pass)
N/A
N/A
Full training (300 epochs)
Evaluating 1 transformation
13.0 ms
13.5 ms
Evaluating 100 transformations
Evaluating 1,000 transformations 15.9 ms

60 seconds
20 seconds
6.6 hours
1.6 ms
1.6 ms
1.7 ms

always find the best-performing representation of a loop.
The downside is that it is very time-consuming, as repeat-
edly executing different variants of a loop takes time. The
following explores the trade-off between time spent on find-
ing beneficial transformations and time saved during the
loop executions.

Time to find beneficial transformations. It takes
about 10 hours to exhaustively measure the runtime of all
mutations in our dataset. This time is based on executions of
individual loops extracted from their original program [23],
and it excludes the time required for extracting the loops. In
contrast, predicting the speedup of transformations across all
loops using our model takes less than 2 seconds. LoopLearner
hence reduces the time taken to select a suitable transforma-
tion by multiple orders of magnitude.

Time savings due to optimized loops. We compare
LoopLearner and exhaustive search w.r.t. the speedup ob-
tained across all loops for which the respective approach
suggests applying a transformation. For LoopLearner, those
are all loops for which at least one transformation is pre-
dicted to yield a speedup. For exhaustive search, those are all
loops that actually have at least one such transformation. In-
tuitively, the speedup hence indicates what benefits to expect
when following the suggestions of the two approaches. As
shown in Table 4, LoopLearner’s static usage scenario yields
a speedup of 1.144x. In contrast, exhaustive search yields a
speedup of 1.286x. That is, following the top-most sugges-
tion of the model without validating its performance impact
results in lower but still relevant speedups. LoopLearner’s
dynamic usage scenario shows a different picture. By con-
sidering the top-5 suggestions of the model, the obtained
speedup of 1.290x even exceeds that of exhaustive search.
The reason is that exhaustive search also reveals various
transformations that yield very small speedups, i.e., trans-
formations that are less relevant in practice. Intuitively, the
top-5, dynamic scenario can be seen as an exhaustive search
within a much reduced space of only the five most promising
transformations.

Overall, we conclude that LoopLearner provides a practi-
cal alternative to exhaustive search, allowing developers

or automated tools to quickly identify the most beneficial
loop optimizations. In particular, the dynamic mode identi-
fies many of those transformations that yield a significant
speedup, without paying the cost of exhaustively measuring
the performance impact of all transformations for all loops.

4.7 Successful Combinations of Transformations
To better understand for which transformations the model’s
predictions are more or less accurate, Table 6 shows results
for individual sequences of transformations. The abbrevi-
ations for the transformations are as in Table 1. The last
two columns show the number of loops in the validation
set to which a sequence of transformation applies, and what
percentage of the validation set this number comprises (i.e.,
coverage). The results show that the accuracy varies across
transformations. For example, tiling followed by unrolling
has a relatively low validation accuracy, but a high training
accuracy, which indicates that the model has likely overfit
the training data for this transformation sequence. We also
observe that for some under-represented combinations of
transformations, the model fails to identify a single speedup.
By observing the results for individual transformation se-
quences, one might decide to ignore some sequences when
deploying LoopLearner.

4.8 Influence of Speedup Threshold
So far in our evaluation we defined the speedup threshold
as being equal to 1. However, as mentioned earlier, this hy-
perparameter can be used to adjust the precision and recall
of the trained model. To show the effects of tuning this hy-
perparameter, we evaluate the speedup precision and recall
on the validation set as we increase the speedup threshold
from 1.0 to 1.5. Figure 5 shows that, predictably, increas-
ing the speedup threshold will result in higher precision of
speedup predictions but also reduce the recall percentage.
Lower value settings for this hyperparameter might be suit-
able for a more optimistic approach with high tolerance for
speedup mispredictions. On the other hand, higher values
guarantee a lower number of mispredictions but are also
likely to disregard advantageous transformations producing
smaller speedups.

5 Related Work
Since many compiler bugs are triggered by optimiza-
tions [14], several techniques search for optimization-related
compiler bugs via differential testing [35, 56]. Barany [8] com-
pare the code generated by different compilers to find opti-
mizations performed by one but missed by another compiler.
Similarly, Nagai et al. [43, 44] propose testing the validity
of arithmetic optimizations using randomly generated pro-
grams. Instead of searching for bugs in the implementation

11

Table 6. Performance of the neural network on different sequences of transformations. Precision and recall for speedup are
calculated on the validation set.

Accuracy (%)

Speedup (%)

Transformation Sequence
unrolling
tiling
tiling -> unrolling
unroll-and-jam -> unrolling
interchange
interchange -> unrolling
interchange -> unroll-and-jam
interchange -> unroll-and-jam -> unrolling
interchange -> tiling -> unrolling
interchange -> tiling
distribution
distribution -> unrolling
tiling -> distribution -> unrolling
tiling -> distribution
interchange -> distribution
interchange -> distribution -> unrolling
interchange -> tiling -> distribution
interchange -> tiling -> distribution -> unrolling

Training
66.75
80.44
82.76
71.00
90.15
93.69
92.37
92.91
94.52
93.28
69.47
74.64
85.45
81.62
96.55
98.13
97.51
98.82

Validation
60.30
71.08
66.14
69.25
89.40
89.37
91.02
92.81
93.15
93.26
54.55
55.56
78.53
69.49
77.78
84.62
94.92
94.92

Recall
35.49
14.20
10.68
27.33
50.98
43.88
53.28
54.15
20.65
22.22
63.64
41.18
17.07
7.14
0.00
20.00
0.00
0.00

Precision
70.33
53.33
45.67
87.23
78.79
88.41
77.71
83.19
72.52
67.92
53.85
63.64
63.64
16.67
0.00
100.00
0.00
0.00

Loop Coverage
%
Count
100.00
379
41.16
156
41.16
156
12.14
46
12.14
46
12.14
46
12.14
46
12.14
46
11.61
44
11.61
44
5.80
22
5.80
22
4.22
16
4.22
16
1.32
5
1.32
5
1.06
4
1.06
4

validating candidate programs, for every program. In con-
trast, LoopLearner learns a model once, which then predicts
code transformations suitable for the given program without
the need to execute or validate candidate programs. A dif-
ference to the work by Cooper et al. [16], which also looks
for sequences of code transformations, is that their work
optimizes in which order to apply transformations, whereas
our work predicts whether applying any transformation will
be beneficial, and if yes, which sequence of transformations
to choose.

Monsifrot et al. [42] use decision trees to learn the behav-
ior of loop unrolling optimizations to decide which loop to
unroll. Stephenson and Amarasinghe [53] propose a super-
vised learning algorithm to predict unroll factors. Yuki et al.
[57] train a neural network to predict loop tiling sizes. Simon
et al. [52] automatically learn effective inlining heuristics us-
ing decision trees and static code features. Machine learning
has been also applied to predict an effective application order
of compiler optimizations [7, 22, 40, 46]. Park et al. [46] use
a graph-based intermediate representation to train a model
that predicts optimization sequences that will benefit a given
program. Martins et al. [40] propose a clustering approach
for grouping similar functions, reducing the search space
resulting from the combination of optimizations previously
suggested for the functions in each group. Ashouri et al. [7]
cluster compiler optimizations to predict the speedup of se-
quences of optimizations that belong to the same cluster. All
the above approaches differ from our work by tuning opti-
mization decisions made inside the compiler, whereas we

Figure 5. The effect of the speedup threshold on the
validation-set speedup precision and recall.

of compiler optimizations, our work improves the effective-
ness of optimizations by tailoring loops to the optimization
decisions made by the compiler.

Superoptimization tries to find the best program among all
semantics-preserving variants of a given program [41] and
can, e.g., be addressed as a stochasitic search problem [50].
Bunel et al. [13] propose a learning-based approach to im-
prove superoptimization by predicting the distribution of
code transformations to sample from. Another search-based
approach for finding suitable optimizations is evolutionary
search, e.g., to tune the order of optimizations [16, 17], to de-
cide which optimizations to enable [30], or to apply random
code mutations that reduce energy consumption [51]. All
of the above approaches search the optimization space for
a specific program and pay the cost, e.g., for executing and

12

1.01.11.21.31.41.5Speedup threshold20406080100Percentage (%)RecallPrecisionpresent a pre-processing step that makes optimizations more
efficient without changing the compiler itself. Another dif-
ference is that the above methods rely on manually designed
features.

Recent work by Cummins et al. [18, 19] also proposes a
deep neural network that learns optimization heuristics over
raw code, similar to our work. Their work focuses on heuris-
tics for two optimization problems: predicting the optimal
execution device and the thread coarsening factor. Our work
differs in at least two ways. First, LoopLearner learns effec-
tive transformation sequences from a much larger corpus
of transformations. Second, LoopLearner trains a convolu-
tional neural network, whereas Cummins et al. build upon a
recurrent neural network. Another technique optimizes the
memory layout of matrices to enable faster sparse matrix
multiplication [60]. While also being based on convolutional
neural networks, their approach takes a matrix as the input,
whereas LoopLearner reasons about the code to optimize.

Machine learning has been used to address various
programming-related problems in an end-to-end manner [2],
including code completion [11, 45, 49], bug detection [27, 37,
47], and bug fixing [25, 26, 38]. Recurrent neural networks
have been applied to token sequences, for example, to find
fixes for syntax errors [10], to identify code that suffers from
a specific kind of vulnerability [37], to predict the types of
variables [28], or to represent code for code search [24]. An
alternative to recurrent neural networks are convolutional
networks, which we also use in this paper. Others have used
convolutional networks to localize bugs [32] and to sum-
marize code [4]. We address a different prediction problem,
and we are, to the best of our knowledge, the first to adopt
the DenseNet architecture [31] to code. Several techniques
train models using a graph-based code representation, e.g.,
abstract syntax trees [54, 58], paths through abstract syntax
trees [5, 6, 21], control flow graphs [20], execution trees [29],
and other graph-based code representations [3, 9, 12, 55].
Other models of code build on conditional random fields [48],
memory networks [15], or manually modeled features [59].
We build upon a token sequence-based representation in-
stead, because it is conceptually simple and makes training
efficient, while providing accurate predictions.

6 Conclusion
We present LoopLearner, a novel technique to address the
program of compiler instability. Given the source code of a
loop, LoopLearner suggests a semantically invariant trans-
formation that will likely allow the compiler to produce
more efficient code. Following its recommendations prior to
compilation results in an average speedup of 1.14x. Almost
three quarters (73%) of the suggested transformations yield
positive speedups. Trying the top-3 recommendations and
choosing the best one raises the average speedup even to
1.29x. We envision the approach to be used either as a tool

13

to guide programmers or as a pre-processor run before or as
part of the compiler. Different from most earlier work, our
approach leverages deep learning and does not require any
manual selection of source code features. In addition, we
consider a much larger set of transformations—3,000 combi-
nations of five common loop optimizations in our case. Our
model needs to be trained once per compiler and platform,
an effort that is likely to pay off in view of the typical lifetime
of either of the two.

Acknowledgments
This work was supported by the Graduate School CE within
the Centre for Computational Engineering at Technische
Universität Darmstadt, the Hessian LOEWE initiative within
the Software-Factory 4.0 project, European Research Council
(ERC, grant agreement 851895), and the German Research
Foundation within the ConcSys and Perf4JS projects.

References
[1] Rami Al-Rfou, Bryan Perozzi, and Steven Skiena. 2013. Polyglot: Dis-
tributed word representations for multilingual nlp. arXiv preprint
arXiv:1307.1662 (2013).

[2] Miltiadis Allamanis, Earl T Barr, Premkumar Devanbu, and Charles
Sutton. 2018. A survey of machine learning for big code and natural-
ness. ACM Computing Surveys (CSUR) 51, 4 (2018), 81.

[3] Miltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. 2017.
Learning to Represent Programs with Graphs. CoRR abs/1711.00740
(2017). arXiv:1711.00740 http://arxiv.org/abs/1711.00740

[4] Miltiadis Allamanis, Hao Peng, and Charles A. Sutton. 2016. A Con-
volutional Attention Network for Extreme Summarization of Source
Code. In ICML. 2091–2100.

[5] Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. 2018.
code2vec: Learning Distributed Representations of Code. CoRR
arXiv:1803.09473 (2018).

[6] Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. 2018. A
General Path-Based Representation for Predicting Program Properties.
In PLDI.

[7] Amir H. Ashouri, Andrea Bignoli, Gianluca Palermo, Cristina Silvano,
Sameer Kulkarni, and John Cavazos. 2017. MiCOMP: Mitigating the
Compiler Phase-Ordering Problem Using Optimization Sub-Sequences
and Machine Learning. ACM Trans. Archit. Code Optim. 14, 3, Article
29 (Sept. 2017), 28 pages. https://doi.org/10.1145/3124452

[8] Gergö Barany. 2018. Finding missed compiler optimizations by dif-
ferential testing. In Proceedings of the 27th International Conference on
Compiler Construction, CC 2018, February 24-25, 2018, Vienna, Austria.
82–92.

[9] Tal Ben-Nun, Alice Shoshana Jakobovits, and Torsten Hoefler. 2018.
Neural Code Comprehension: A Learnable Representation of Code
Semantics. In Advances in Neural Information Processing Systems 31,
S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi,
and R. Garnett (Eds.). Curran Associates, Inc., 3585–3597.

[10] Sahil Bhatia and Rishabh Singh. 2016. Automated Correction for
Syntax Errors in Programming Assignments using Recurrent Neural
Networks. CoRR abs/1603.06129 (2016).

[11] Pavol Bielik, Veselin Raychev, and Martin T. Vechev. 2016. PHOG:

Probabilistic Model for Code. In ICML. 2933–2942.

[12] M. Brockschmidt, M. Allamanis, A. L. Gaunt, and O. Polozov. 2018.
Generative Code Modeling with Graphs. ArXiv e-prints (2018).
arXiv:1805.08490 [cs.LG]

[13] Rudy Bunel, Alban Desmaison, M. Pawan Kumar, Philip H. S. Torr,
and Pushmeet Kohli. 2017. Learning to superoptimize programs. In
5th International Conference on Learning Representations, ICLR 2017,
Toulon, France, April 24-26, 2017, Conference Track Proceedings. https:
//openreview.net/forum?id=r1rz6U5lg

[14] Junjie Chen, Wenxiang Hu, Dan Hao, Yingfei Xiong, Hongyu Zhang,
Lu Zhang, and Bing Xie. 2016. An Empirical Comparison of Compiler
Testing Techniques. In Proceedings of the 38th International Conference
on Software Engineering (Austin, Texas) (ICSE ’16). ACM, New York,
NY, USA, 180–190. https://doi.org/10.1145/2884781.2884878

[15] Min-je Choi, Sehun Jeong, Hakjoo Oh, and Jaegul Choo. 2017. End-to-
End Prediction of Buffer Overruns from Raw Source Code via Neural
Memory Networks. CoRR abs/1703.02458 (2017).

[16] Keith D. Cooper, Philip J. Schielke, and Devika Subramanian. 1999.
Optimizing for Reduced Code Space using Genetic Algorithms. In Pro-
ceedings of the ACM SIGPLAN 1999 Workshop on Languages, Compilers,
and Tools for Embedded Systems (LCTES’99), Atlanta, Georgia, USA,
May 5, 1999. 1–9. https://doi.org/10.1145/314403.314414

[17] Keith D. Cooper, Devika Subramanian, and Linda Torczon. 2002. Adap-
tive Optimizing Compilers for the 21st Century. The Journal of Super-
computing 23, 1 (2002), 7–22. https://doi.org/10.1023/A:1015729001611
[18] Chris Cummins, Pavlos Petoumenos, Zheng Wang, and Hugh Leather.
2017. End-to-End Deep Learning of Optimization Heuristics. In 26th
International Conference on Parallel Architectures and Compilation Tech-
niques, PACT 2017, Portland, OR, USA, September 9-13, 2017. 219–232.
https://doi.org/10.1109/PACT.2017.24

[19] Chris Cummins, Pavlos Petoumenos, Zheng Wang, and Hugh Leather.
2017. Synthesizing benchmarks for predictive modeling. In CGO. 86–
99.

[20] Daniel DeFreez, Aditya V. Thakur, and Cindy Rubio-González. 2018.
Path-Based Function Embedding and its Application to Specification
Mining. CoRR abs/1802.07779 (2018).

[21] Jacob Devlin, Jonathan Uesato, Rishabh Singh, and Pushmeet Kohli.
2017. Semantic Code Repair using Neuro-Symbolic Transformation
Networks. CoRR abs/1710.11054 (2017). arXiv:1710.11054 http://arxiv.
org/abs/1710.11054

[22] Grigori Fursin, Yuriy Kashnikov, Abdul Wahid Memon, Zbigniew
Chamski, Olivier Temam, Mircea Namolaru, Elad Yom-Tov, Bilha
Mendelson, Ayal Zaks, Eric Courtois, et al. 2011. Milepost gcc: Ma-
chine learning enabled self-tuning compiler. International Journal of
Parallel Programming 39, 3 (2011), 296–327.

[23] Zhangxiaowen Gong, Zhi Chen, Justin Szaday, David Wong, Zehra
Sura, Neftali Watkinson, Saeed Maleki, David Padua, Alexander Vei-
denbaum, Alexandru Nicolau, and Josep Torrellas. 2018. An Empirical
Study of the Effect of Source-level Loop Transformations on Compiler
Stability. Proc. ACM Program. Lang. 2, OOPSLA, Article 126 (Oct. 2018),
29 pages. https://doi.org/10.1145/3276496

[24] Xiaodong Gu, Hongyu Zhang, and Sunghun Kim. 2018. Deep Code

Search. In ICSE.

[25] Rahul Gupta, Soham Pal, Aditya Kanade, and Shirish Shevade. 2017.
DeepFix: Fixing Common C Language Errors by Deep Learning. In
AAAI.

[26] Jacob Harer, Onur Ozdemir, Tomo Lazovich, Christopher P. Reale, Re-
becca L. Russell, Louis Y. Kim, and Sang Peter Chin. 2018. Learning to
Repair Software Vulnerabilities with Generative Adversarial Networks.
In Advances in Neural Information Processing Systems 31: Annual Con-
ference on Neural Information Processing Systems 2018, NeurIPS 2018,
3-8 December 2018, Montréal, Canada. 7944–7954.

[27] Jacob A. Harer, Louis Y. Kim, Rebecca L. Russell, Onur Ozdemir,
Leonard R. Kosta, Akshay Rangamani, Lei H. Hamilton, Gabriel I.
Centeno, Jonathan R. Key, Paul M. Ellingwood, Marc W. McConley,
Jeffrey M. Opper, Sang Peter Chin, and Tomo Lazovich. 2018. Auto-
mated software vulnerability detection with machine learning. CoRR
abs/1803.04497 (2018). arXiv:1803.04497 http://arxiv.org/abs/1803.

14

04497

[28] V. Hellendoorn, C. Bird, E. T. Barr, and M. Allamanis. 2018. Deep

Learning Type Inference. In FSE.

[29] Jordan Henkel, Shuvendu K. Lahiri, Ben Liblit, and Thomas W. Reps.
2018. Code vectors: understanding programs through embedded ab-
stracted symbolic traces. In Proceedings of the 2018 ACM Joint Meeting
on European Software Engineering Conference and Symposium on the
Foundations of Software Engineering, ESEC/SIGSOFT FSE 2018, Lake
Buena Vista, FL, USA, November 04-09, 2018. 163–174.

[30] Kenneth Hoste and Lieven Eeckhout. 2008. Cole: compiler optimization
level exploration. In Sixth International Symposium on Code Generation
and Optimization (CGO 2008), April 5-9, 2008, Boston, MA, USA. 165–174.
https://doi.org/10.1145/1356058.1356080

[31] Gao Huang, Zhuang Liu, Laurens van der Maaten, and Kilian Q. Wein-
berger. 2017. Densely Connected Convolutional Networks. In Proceed-
ings of the IEEE Conference on Computer Vision and Pattern Recognition.
2261–2269.

[32] Xuan Huo, Ming Li, and Zhi-Hua Zhou. 2016. Learning Unified Fea-
tures from Natural and Programming Languages for Locating Buggy
Source Code. In Proceedings of the Twenty-Fifth International Joint
Conference on Artificial Intelligence, IJCAI 2016, New York, NY, USA,
9-15 July 2016. 1606–1612.

[33] Armand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze,
Hérve Jégou, and Tomas Mikolov. 2016. Fasttext. zip: Compressing
text classification models. arXiv preprint arXiv:1612.03651 (2016).
[34] Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov.
2016. Bag of tricks for efficient text classification. arXiv preprint
arXiv:1607.01759 (2016).

[35] Vu Le, Mehrdad Afshari, and Zhendong Su. 2014. Compiler Valida-
tion via Equivalence Modulo Inputs. In Proceedings of the 35th ACM
SIGPLAN Conference on Programming Language Design and Implemen-
tation (Edinburgh, United Kingdom) (PLDI ’14). ACM, New York, NY,
USA, 216–226. https://doi.org/10.1145/2594291.2594334

[36] Jiwei Li and Dan Jurafsky. 2015. Do multi-sense embeddings im-
prove natural language understanding? arXiv preprint arXiv:1506.01070
(2015).

[37] Zhen Li, Shouhuai Xu Deqing Zou and, Xinyu Ou, Hai Jin, Sujuan
Wang, Zhijun Deng, and Yuyi Zhong. 2018. VulDeePecker: A Deep
Learning-Based System for Vulnerability Detection. In NDSS.
[38] Fan Long and Martin Rinard. 2016. Automatic patch generation by
learning correct code. In Proceedings of the 43rd Annual ACM SIGPLAN-
SIGACT Symposium on Principles of Programming Languages, POPL
2016, St. Petersburg, FL, USA, January 20 - 22, 2016. 298–312.

[39] Rabee Sohail Malik, Jibesh Patra, and Michael Pradel. 2019. NL2Type:
Inferring JavaScript Function Types from Natural Language Informa-
tion. In ICSE.

[40] Luiz G. A. Martins, Ricardo Nobre, João M. P. Cardoso, Alexandre C. B.
Delbem, and Eduardo Marques. 2016. Clustering-Based Selection for
the Exploration of Compiler Optimization Sequences. ACM Trans.
Archit. Code Optim. 13, 1, Article 8 (March 2016), 28 pages. https:
//doi.org/10.1145/2883614

[41] Henry Massalin. 1987. Superoptimizer: a look at the smallest program.
In ACM SIGARCH Computer Architecture News, Vol. 15. IEEE Computer
Society Press, 122–126.

[42] Antoine Monsifrot, François Bodin, and Rene Quiniou. 2002. A Ma-
chine Learning Approach to Automatic Production of Compiler Heuris-
tics. In Proceedings of the 10th International Conference on Artificial Intel-
ligence: Methodology, Systems, and Applications (AIMSA ’02). Springer-
Verlag, London, UK, UK, 41–50. http://dl.acm.org/citation.cfm?id=
646053.677574

[43] Eriko Nagai, Hironobu Awazu, Nagisa Ishiura, and Naoya Takeda. 2019.
Random Testing of C Compilers Targeting Arithmetic Optimization.
(04 2019).

[59] Gang Zhao and Jeff Huang. 2018. DeepSim: deep learning code func-
tional similarity. In Proceedings of the 2018 ACM Joint Meeting on
European Software Engineering Conference and Symposium on the Foun-
dations of Software Engineering, ESEC/SIGSOFT FSE 2018, Lake Buena
Vista, FL, USA, November 04-09, 2018. 141–151.

[60] Yue Zhao, Jiajia Li, Chunhua Liao, and Xipeng Shen. 2018. Bridging
the gap between deep learning and sparse matrix format selection. In
Proceedings of the 23rd ACM SIGPLAN Symposium on Principles and
Practice of Parallel Programming, PPoPP 2018, Vienna, Austria, February
24-28, 2018. 94–108. https://doi.org/10.1145/3178487.3178495

[44] Eriko Nagai, Atsushi Hashimoto, and Nagisa Ishiura. 2014. Reinforcing
Random Testing of Arithmetic Optimization of C Compilers by Scaling
up Size and Number of Expressions. IPSJ Trans. System LSI Design
Methodology 7 (2014), 91–100.

[45] Tung Thanh Nguyen, Anh Tuan Nguyen, Hoan Anh Nguyen, and
Tien N. Nguyen. 2013. A statistical semantic language model for
source code. In Joint Meeting of the European Software Engineering
Conference and the ACM SIGSOFT Symposium on the Foundations of
Software Engineering, ESEC/FSE’13, Saint Petersburg, Russian Federation,
August 18-26, 2013. 532–542.

[46] Eunjung Park, John Cavazos, and Marco A. Alvarez. 2012. Using
Graph-based Program Characterization for Predictive Modeling. In
Proceedings of the Tenth International Symposium on Code Generation
and Optimization (San Jose, California) (CGO ’12). ACM, New York,
NY, USA, 196–206. https://doi.org/10.1145/2259016.2259042

[47] Michael Pradel and Koushik Sen. 2018. DeepBugs: A learning approach
to name-based bug detection. PACMPL 2, OOPSLA (2018), 147:1–147:25.
https://doi.org/10.1145/3276517

[48] Veselin Raychev, Martin T. Vechev, and Andreas Krause. 2015. Predict-
ing Program Properties from "Big Code".. In Principles of Programming
Languages (POPL). 111–124.

[49] Veselin Raychev, Martin T. Vechev, and Eran Yahav. 2014. Code com-
pletion with statistical language models. In ACM SIGPLAN Conference
on Programming Language Design and Implementation, PLDI ’14, Edin-
burgh, United Kingdom - June 09 - 11, 2014. 44.

[50] Eric Schkufza, Rahul Sharma, and Alex Aiken. 2013. Stochastic Super-
optimization. In Conference on Architectural Support for Programming
Languages and Operating Systems (ASPLOS). ACM, 305–316.

[51] Eric M. Schulte, Jonathan Dorn, Stephen Harding, Stephanie Forrest,
and Westley Weimer. 2014. Post-compiler software optimization for
reducing energy. In Architectural Support for Programming Languages
and Operating Systems, ASPLOS ’14, Salt Lake City, UT, USA, March 1-5,
2014. 639–652. https://doi.org/10.1145/2541940.2541980

[52] Douglas Simon, John Cavazos, Christian Wimmer, and Sameer Kulka-
rni. 2013. Automatic Construction of Inlining Heuristics Using Ma-
chine Learning. In Proceedings of the 2013 IEEE/ACM International
Symposium on Code Generation and Optimization (CGO) (CGO ’13).
IEEE Computer Society, Washington, DC, USA, 1–12. https://doi.org/
10.1109/CGO.2013.6495004

[53] Mark Stephenson and Saman Amarasinghe. 2005. Predicting Un-
roll Factors Using Supervised Classification. In Proceedings of the In-
ternational Symposium on Code Generation and Optimization (CGO
’05). IEEE Computer Society, Washington, DC, USA, 123–134. https:
//doi.org/10.1109/CGO.2005.29

[54] Martin White, Michele Tufano, Christopher Vendome, and Denys
Poshyvanyk. 2016. Deep learning code fragments for code clone
detection. In ASE. 87–98.

[55] Xiaojun Xu, Chang Liu, Qian Feng, Heng Yin, Le Song, and Dawn Song.
2017. Neural Network-based Graph Embedding for Cross-Platform
Binary Code Similarity Detection. In CCS. 363–376.

[56] Xuejun Yang, Yang Chen, Eric Eide, and John Regehr. 2011. Finding
and Understanding Bugs in C Compilers. In Proceedings of the 32Nd
ACM SIGPLAN Conference on Programming Language Design and Im-
plementation (San Jose, California, USA) (PLDI ’11). ACM, New York,
NY, USA, 283–294. https://doi.org/10.1145/1993498.1993532

[57] Tomofumi Yuki, Lakshminarayanan Renganarayanan, Sanjay Rajopad-
hye, Charles Anderson, Alexandre E. Eichenberger, and Kevin O’Brien.
2010. Automatic Creation of Tile Size Selection Models. In Proceedings
of the 8th Annual IEEE/ACM International Symposium on Code Gener-
ation and Optimization (Toronto, Ontario, Canada) (CGO ’10). ACM,
New York, NY, USA, 190–199. https://doi.org/10.1145/1772954.1772982
[58] Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, Kaixuan Wang,
and Xudong Liu. 2019. A Novel Neural Source Code Representation
based on Abstract Syntax Tree. In ICSE.

15

