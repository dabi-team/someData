2
2
0
2

y
a
M
0
1

]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[

1
v
1
8
6
5
0
.
5
0
2
2
:
v
i
X
r
a

Accelerating reactive-ﬂow simulations using vectorized
chemistry integration

Nicholas J. Curtisa, Kyle E. Niemeyerb,∗, Chih-Jen Sunga

aDepartment of Mechanical Engineering, University of Connecticut, Storrs, CT 06269,
USA
bSchool of Mechanical, Industrial, and Manufacturing Engineering, Oregon State
University, Corvallis, OR 97331, USA

Abstract

The high cost of chemistry integration is a signiﬁcant computational bot-
tleneck for realistic reactive-ﬂow simulations using operator splitting. Here
we present a methodology to accelerate the solution of the chemical kinetic
ordinary diﬀerential equations using single-instruction, multiple-data vector
processing on CPUs using the OpenCL framework. First, we compared sev-
eral vectorized integration algorithms using chemical kinetic source terms
and analytical Jacobians from the pyJac software against a widely used inte-
gration code, CVODEs. Next, we extended the OpenFOAM computational ﬂuid
dynamics library to incorporate the vectorized solvers, and we compared the
accuracy of a fourth-order linearly implicit integrator–both in vectorized form
and a corresponding method native to OpenFOAM—with the community stan-
dard chemical kinetics library Cantera. We then applied our methodology
to a variety of chemical kinetic models, turbulent intensities, and simulation
scales to examine a range of engineering and scientiﬁc scale problems, in-
cluding (pseudo) steady-state as well as time-dependent Reynolds-averaged
Navier–Stokes simulations of the Sandia ﬂame D and the Volvo Flygmotor
bluﬀ-body stabilized, premixed ﬂame. Subsequently, we compared the per-
formance of the vectorized and native OpenFOAM integrators over the studied
models and simulations and found that our vectorized approach performs up
to 33–35

faster than the native OpenFOAM solver with high accuracy.

×

Keywords: Reactive-ﬂows, Chemical kinetics, ODE integration,

∗Corresponding author
Email address: kyle.niemeyer@oregonstate.edu (Kyle E. Niemeyer)

Preprint submitted to Computer Physics Communications

May 13, 2022

 
 
 
 
 
 
Vectorization, SIMD, CFD

1. Introduction

Developers of next-generation combustion devices have increasingly turned
to new operating regimes—e.g., low-temperature combustion [1]—to achieve
higher eﬃciencies and reduced emissions. Computational reactive-ﬂow mod-
eling has been used to rapidly develop these new combustion concepts into
functional prototypes [2], but accurately predicting combustion processes at
these regimes depends on realistic chemical kinetics models. This places a
large computational burden on reactive-ﬂow modeling, since solving the ordi-
nary diﬀerential equations (ODEs) governing chemical kinetics can dominate
the overall cost of simulations. For example, in a study of n-dodecane spray
injection, a high-resolution large-eddy simulation (LES) using a 54-species
skeletal model and up to 22 million cells took around 48,000 CPU hours
(or about 20 days of wall-clock time) to complete a single realization of just
2 ms after start of injection [3]. Large model size and high numerical stiﬀ-
ness further increase computational cost, and unfortunately chemical kinetic
models relevant to transportation or power-generation applications exhibit
these characteristics [4].

Many strategies have been developed to reduce the cost of using real-
istic, detailed chemical kinetic models in reactive-ﬂow simulations [4, 5].
Skeletal reduction methods aim to remove unimportant species and reactions
from a chemical kinetic model while maintaining ﬁdelity to the base detailed
model [6–9]. In addition, species with similar thermochemical properties may
also be lumped together [10–12], time-scale methods can be used to reduce
numerical stiﬀness [13–16], and tabulation/interpolation methods reuse pre-
viously computed results to accelerate simulations [17–19]. Often, several of
these techniques are combined to achieve better performance [20–22], or are
even applied dynamically throughout a simulation to achieve greater local
computational savings [23–25].

In addition to methods that reduce or approximate the base chemical ki-
netic model, performance can be increased by improving the ODE integration
algorithms used to solve the chemical-kinetic equations. Some researchers
have developed new integration algorithms speciﬁcally for eﬃciently solving
chemical kinetics [16, 26, 27], while others have examined the performance
of existing algorithms for use in reactive-ﬂow simulations [28–33]. Further,

2

several codes have recently been developed for analytically evaluating the
chemical-kinetic Jacobian matrix [34–36], which may be used to improve the
performance of implicit ODE integration schemes [4].

In recent years, high-performance computing hardware has been evolving
from a homogeneous, CPU-based paradigm to one dominated by hetero-
geneous processing architectures. In particular, single-instruction multiple-
thread (SIMT) processors have become widely available, such as graphics
processing units (GPUs), and many studies have leveraged their high ﬂoating-
operation throughput to accelerate chemical-kinetics integration. Early work
used GPUs to evaluate chemical-kinetic source terms or factorize the Jaco-
bian matrix, but found signiﬁcant speedups only for large chemical kinetic
models [37, 38]. Later, several studies implemented GPU-based explicit in-
tegration techniques to achieve order-of-magnitude or more speedups when
integrating non-stiﬀ or moderately-stiﬀ chemical kinetics [28, 30, 39]. Fur-
ther work followed that developed GPU-based implicit integration schemes,
but these exhibited decreased performance with increasing numerical stiﬀness
due to thread divergence [40–42].

In contrast, vectorization based on the single-instruction multiple-data
(SIMD) paradigm, like that found on modern CPUs, has not been as ex-
tensively investigated for use in chemical-kinetic integration, though SIMD
vectorization has been used for ODE integration in related contexts [43–
45]. Che et al. [46] used loop-unrolling/rearrangement, aligned arrays, and
OpenMP [47] compilation directives (i.e., #pragmas) to achieve SIMD vector-
ization for accelerating an LES solver on the Intel Xeon Phi Many Integrated
Core (MIC) co-processor. Stone et al. [33] used the OpenCL [48] framework
to vectorize a linearly implicit Rosenbrock integration method [49] on the
CPU, GPU, and MIC architectures.
In addition, we developed the open-
source platform pyJac that can generate vectorized, OpenCL-based chemical
kinetic source term and Jacobian evaluation codes [35].

In this work, we describe a method to implement SIMD-based vectorized
ODE integration methods—coupled with vectorized, analytical chemical ki-
netic Jacobian and source-term evaluations—for use in realistic reactive-ﬂow
simulations. Our primary focus is ﬁnding the acceleration and performance
scaling achievable by the vectorized methods, so we examine these in appli-
cations with diﬀerent turbulent and chemical time scales, mesh resolutions,
and chemical-kinetic model sizes to assess their performance in a variety of
engineering and scientiﬁc contexts. To do so, we extended the open-source
computational ﬂuid dynamics (CFD) code OpenFOAM [50] to use the vector-

3

ized methods.

Our goal here is to demonstrate the signiﬁcant reduction in computational
cost achievable by fully vectorized chemical-kinetic integration on CPUs with-
out compromising accuracy, rather than to perform high-ﬁdelity studies with
the aim of investigating the combustion physics involved. Although the open-
source nature of OpenFOAM is advantageous for these purposes—allowing
modiﬁcation to enable the vectorized ODE integration methods—it lacks
some commonly used models (e.g., multi-component and mixture-averaged
species transport [51]) and boundary conditions (e.g., Navier–Stokes Char-
acteristic Boundary Conditions [52, 53]). It has to be pointed out that the
impact of the interaction of errors from computational grid size, subgrid
models, numerical schemes, and chemical kinetic model selection on the accu-
racy of reactive-ﬂow simulations is not well understood. For instance, Cocks
et al. [54] demonstrated that four diﬀerent numerical schemes (as provided
by industry, research, and open-source CFD codes) are unable to produce
consistent reactive-ﬂow LES solutions for the commonly used Volvo bluﬀ-
body stabilized ﬂame [55–57], even when using the same computational grid,
subgrid, and chemistry models. Similarly, Rochette et al. [58] found that
the numerical scheme and chemical kinetic model have a large eﬀect on the
agreement of the solution with experimental data used in a reactive-ﬂow LES
solution of the Volvo bluﬀ-body stabilized ﬂame problem. The focus of this
work is not model validation, so we will use only built-in OpenFOAM numeri-
cal schemes, subgrid models, and boundary conditions—substituting in our
vectorized ODE solver—to simulate selected reactive-ﬂow problems, demon-
strating that the techniques developed here can further aid the development
of standard models in OpenFOAM.

The rest of this article is organized as follows. Section 2 describes the
numerical methods and software used in this study. Subsequently, Section 3
ﬁrst veriﬁes the vectorized solvers against a typical implicit integration algo-
rithm, then conﬁrms their coupling to the CFD code OpenFOAM [50]. Then,
Section 4 presents two case studies that compare the performance of the
vectorized solvers with those built into OpenFOAM: Sandia ﬂame D [59–61] in
Section 4.1 and the Volvo Flygmotor bluﬀ-body ﬂame [55–57] in Section 4.2.
Finally, in Section 6 we identify and discuss directions for future eﬀorts.

4

2. Numerical methods and software

2.1. pyJac code-generation platform

pyJac [35] is an open-source software package that generates code for
evaluating the chemical-kinetic source terms and analytical Jacobian matrix
for a variety of execution, data-ordering, and matrix-format patterns. For
full details, we direct readers to our prior work focusing on pyJac [34, 35];
however, here we highlight key points relevant to this work. When using the
constant-pressure assumption1, the resulting thermochemical state vector in
pyJac is

Φ = (cid:8)T, V, n1, n2, . . . , nNsp−1
where T is the temperature of the gas mixture, V is the volume, ni is the
moles of species i, and Nsp is the number of species in the model. The last
species in the model is typically the bath gas—N2 in this study—and omitted
from the state vector, as it is calculated implicitly via the ideal gas equation
of state:

(cid:9) ,

(1)

n =

P V
T

R

=

Nsp
(cid:88)

i=1

ni ,

(2)

where n is the total number of moles of the gas mixture and
versal gas constant. The moles of the last species in the model nNsp
calculated as

R

is the uni-
is then

nNsp =

P V

T −

R

Nsp−1
(cid:88)

i=1

ni .

(3)

This formulation explicitly conserves mass in pyJac, and also ensures that
the system of equations is not overconstrained [36].

Given a thermochemical state vector, pyJac can evaluate the chemical

kinetic source rates

dΦ
dt

= f (Φ) =

(cid:26) dT
dt

,

dV
dt

dn1
dt

,

dn2
dt

,

, . . . ,

(cid:27)

dnNsp−1
dt

,

(4)

which form the autonomous chemical kinetic ODEs. In addition, pyJac can

1In this context, “constant pressure” refers to the solution of chemical kinetics within a
reaction sub-step of an operator-splitting scheme, rather than a general constant-pressure
reactive-ﬂow simulation.

5

calculate the analytical chemical kinetic Jacobian

i,j =

J

∂fi
∂Φj

,

i, j = 1, . . . , Nsp + 1 .

(5)

Although pyJac can evaluate the Jacobian in a sparse-matrix format
(e.g., compressed row storage), we used a dense-matrix format to simplify
implementing linear-algebra operations; extending this eﬀort to use a sparse
matrix is a goal for future studies. We used pyJac to generate an explicit
“shallow”-vectorization, as described in Section 2.2, using a vector width
of eight double-precision ﬂoating-point operations1, and “C” (or row-major)
data ordering.

2.2. OpenCL and vectorization

The parallel programming standard OpenCL [48] provides a common in-
terface to execute vectorized code on a variety of diﬀerent platforms (e.g.,
CPU, GPU, MIC). For a detailed overview of diﬀerent vectorization patterns
and their applications to diﬀerent hardware platforms for integrating chem-
ical kinetic ODEs, we refer the reader to past works [35, 40, 42, 62]. Here
we will discuss only the so-called “shallow”-vectorization pattern for SIMD
processors (e.g., CPUs) using OpenCL.

This method groups together the thermochemical state vectors of several

chemical kinetic ODE systems:

Φvec =

(cid:110)

{

Φ1,1, Φ2,1, . . . , ΦNv,1

,

}

Φ1,2, Φ2,2, . . . , ΦNv,2
{
(cid:8)Φ1,Nsp+1, Φ2,Nsp+1, . . . , ΦNv,Nsp+1

, . . . ,

}

(cid:9)(cid:111)

,

(6)

where Nv is the number of elements in the vector, also known as the vector
width, and Φj,i is the ith component of the thermochemical state vector
(Eq. (1)) for the jth state.

These modiﬁed state vectors can be loaded into OpenCL vector data
types, e.g., double8, allowing ﬂoating-point math operations to be performed

1If the OpenCL vector width is longer than that implemented on the underlying hard-
ware, the vector operation is implicitly converted to multiple smaller vector operations,
similar to loop-unrolling optimizations.

6

concurrently over the vector (by specialized vector processors present on all
modern CPUs), thus accelerating computations. The OpenCL runtime (e.g.,
as supplied by Intel [63]) then transforms the OpenCL code into vectorized
operations using the vector-instruction set present on the device.

2.3. accelerInt ODE integration library

Eﬃciently and accurately integrating the autonomous chemical kinetic
ODEs is critical to simulating reactive ﬂows. Integration advances the source
rates—described in Section 2.1—from an initial time ti to a ﬁnal time tf :

dΦ
dt

= f (Φ) ,

ti

t

≤

≤

tf .

(7)

We have implemented several previously developed vectorized OpenCL-
based ODE integration methods [33] in the accelerInt software library [42]:
a fourth-order explicit Runge–Kutta method and several third- and fourth-
order linearly implicit Rosenbrock methods [49, 64, 65]. Table 1 lists the
OpenCL-based solvers available in accelerInt, as well as their orders, solver
types, and references.

Solver name Order Solver type

Reference(s) Short name

Rosenbrock
Rosenbrock
RODAS
RODAS
RKF45

3
4
3
4
4

Linearly implicit
Linearly implicit
Linearly implicit
Linearly implicit
Explicit

[64, 65]
[49]
[64, 65]
[49]
[66]

ROS3
ROS4
RODAS3
RODAS4
RKF45

Table 1: List of vectorized OpenCL integration methods incorporated
into accelerInt.

Runge–Kutta methods include both implicit and explicit solvers, and are
widely used to solve systems of stiﬀ and non-stiﬀ ODEs. A Runge–Kutta
method with s stages may be written as

Φ (tn+1) = Φ (tn) +

s
(cid:88)

i=1

biki ,

(8)

7

where each stage is computed as

(cid:32)

ki = h f

Φ (tn) +

(cid:33)

aijkj

,

s
(cid:88)

j=1

(9)

where h is the time-step size, and aij and bi are method coeﬃcients that
deﬁne the algorithm.

The explicit solver included in accelerInt is a ﬁve-stage, fourth-order-
accurate embedded Runge–Kutta–Fehlberg method (RKF45) [66]. Explicit
Runge–Kutta methods are obtained when the coeﬃcient matrix aij in Eq. (9)
is strictly lower triangular (i.e., aii = 0). While explicit integration methods
are eﬃcient for non-stiﬀ problems, they are only conditionally stable and
perform poorly for stiﬀ problems where the step size h is limited by stability
concerns rather than the desired accuracy.

Implicit Runge–Kutta methods result from a fully populated coeﬃcient
matrix aij, resulting in a system of non-linear equations that are typically
solved via Newton–Raphson iteration. This technique requires the repeated
evaluation and factorization of the chemical-kinetic Jacobian matrix
As such, implicit methods cost more per integration step, but their improved
stability typically makes them more eﬃcient for solving stiﬀ ODEs.
Im-
plicit methods commonly reuse the Jacobian matrix (and its factorization)
for multiple time steps to reduce the computational overhead.

J

(see Eq. (5)).

Rosenbrock (ROS and RODAS)1 methods are more similar in structure
to Runge–Kutta methods than to fully implicit techniques. They solve a
linearized form of Eq. (8) and are therefore known as “linearly implicit” tech-
niques. An s-stage Rosenbrock method is formulated as

(cid:32)

ki = hf

Φ (tn) +

(cid:33)

i−1
(cid:88)

αijkj

Φ (tn+1) = Φ (tn) +

j=1
s
(cid:88)

biki ,

i=1

+ h

J

i
(cid:88)

j=1

γijkj,

i = 1, . . . , s

(10)

(11)

where αij, γij, and bi are the method parameters. Typically Rosenbrock
methods are constructed with γ11 = . . . = γss = γ, a constant parameter,

1Here we adopt the naming convention of Hairer and Wanner [49].

8

such that only one LU decomposition must be performed per time step [49].
To avoid solving a linear system and performing matrix-vector multipli-

cation at each stage of the method [49, 67], Eq. (10) may be transformed:

(cid:19)

(cid:18) 1
hγii

I

− J

(cid:32)

ui = f

Φ (tn) +

(cid:33)

aijuj

+

i−1
(cid:88)

j=1

i
(cid:88)

j=1

cij
h

uj,

i = 1, . . . , s (12)

Φ (tn+1) = Φ (tn) +

s
(cid:88)

j=1

mjuj ,

(13)

where Γ = (γij) is an intermediate matrix constructed from the γij values,

i
(cid:88)

ui =

γijkj ,

j=1
aij = αijΓ−1 ,
cij = γI
mj = bjΓ−1 .

−

Γ−1 , and

(14)

(15)
(16)
(17)

Directly using the Jacobian matrix in Rosenbrock solvers avoids the need
for Newton iteration, making these methods particularly well-suited for SIMD
and SIMT vectorization due to the low levels of divergence between vector
lanes/threads [29]. However, ROS solvers are formulated around using an
exact (analytical) Jacobian, since a ﬁnite-diﬀerence Jacobian may impact
the solver’s order and convergence [49, 68]. Further, the Jacobian must now
be evaluated/factorized at each step, adding to the cost per time step. W-
methods may be a suitable technique to avoid these costs, since they are
formulated around using an inexact Jacobian [49]; these should be investi-
gated for vectorized ODE integration in the future.

These Runge–Kutta and Rosenbrock solvers, coupled with OpenCL source-
rate/Jacobian evaluation code generated by the latest version of pyJac [35],
form the basis of the accelerated ODE integration techniques used here.

2.4. OpenFOAM

OpenFOAM [50] is an open-source C++ library capable of solving a variety
of continuum mechanics problems, and is designed to allow straightforward
extension and implementation of custom solvers. In this work, we extend the

9

OpenFOAM applications for solving reactive-ﬂow CFD problems to incorpo-
rate the vectorized ODE integration techniques outlined in Section 2.3. The
reactive-ﬂow solver reactingFoam supports using a variety of boundary con-
ditions, models, solution techniques, and turbulence descriptions, including
Reynolds-averaged Navier–Stokes (RANS) and LES simulations. For com-
prehensive details on these models and their implementation in OpenFOAM
we refer readers to dedicated articles on these topics [50, 69–71]. Here we
focus on the models relevant to incorporating accelerInt into OpenFOAM for
solving chemical kinetic ODEs.

2.4.1. Chemistry solvers

OpenFOAM has a number of built-in solvers for integrating the chemical
kinetic ODEs, including C++ implementations of the third- and fourth-order
linearly implicit Rosenbrock solvers in accelerInt. However, the imple-
mentations diﬀer in a number of key aspects. First, and most obviously,
the diﬀerence in programming languages results in diﬀerent execution pat-
terns: serial evaluation in OpenFOAM vs. vectorized/batched integration in
accelerInt. Second, the ROS4 solver in OpenFOAM uses a diﬀerent set of
method coeﬃcients [68] than those used in accelerInt [49]. Third, OpenFOAM
v6.x includes an analytical Jacobian evaluation code1, but it uses a diﬀer-
ent state vector composed of the species concentrations, temperature, and
pressure (which is assumed constant, as in pyJac). Finally, OpenFOAM does
not employ the explicit mass-conservation formulation employed by pyJac,
i.e., the concentration of the last species in the model is solved for directly
in OpenFOAM.

We created a new chemistry model for OpenFOAM by extending the base
class BasicChemistryModel: BatchedChemistryModel. This new model
performs the chemical-kinetic integration of the thermochemical state vectors
for the domain (or sub-domain, in the case of runs parallelized with the mes-
sage passing interface, MPI [72]) in a single batched call to the accelerInt
library, instead of evaluating them sequentially as in the base OpenFOAM code.
The accelerInt library returns the updated thermochemical state vectors
for the domain, as well as the ﬁnal internal integration time step taken for

1Previous versions of OpenFOAM used a semi-analytical approach, where most Jacobian
values were computed analytically but the temperature derivatives were evaluated using
ﬁnite diﬀerences. The fully analytical Jacobian was introduced on the OpenFOAM-Dev
channel in June 2018, and is built into OpenFOAM v6.x.

10

each cell in the domain. The time-step values are used as an initial time step
for the next ODE integration of this cell (as in the BasicChemistryModel1
used in the OpenFOAM code), as well as to adaptively limit the overall CFD
time-step size for certain OpenFOAM solvers (e.g., chemFoam).

2.4.2. Turbulent combustion model

OpenFOAM implements multiple turbulent combustion models for simulat-
ing turbulence-chemistry interactions in reactive-ﬂow simulations, ranging
from a simple inﬁnitely fast chemistry model to the more-complex ﬂame
surface density formulation [73]. We selected the eddy-dissipation concept
(EDC) [74] as a robust and relatively computationally expensive combustion
model to demonstrate the performance of the vectorized ODE solvers. EDC
is a commonly used technique for modeling turbulence-chemistry interaction,
and has been applied to a large variety of combustion problems [75–77]. Con-
ceptually, EDC is based upon the idea of the turbulent energy cascade [74]
and involves both a ﬁne-scale reactor and its non-reacting surroundings [75].
EDC models molecular mixing between the ﬁne scales and their surroundings
by mass transfer between the two. When using a detailed chemical kinetic
model, the ﬁne-scale reactor is typically treated as a perfectly stirred reactor
and solved to equilibrium, imposing signiﬁcant computational overhead [78].
The mean reaction rate for species i in the EDC model [74, 75], Ri, is

given by2

Ri =

ρ
τ ∗

γ2
Lχ
γ2
Lχ

(cid:0)Y i

Y ∗
i

(cid:1) ,

1

−

−
are the ﬂuid mean and ﬁne-
where ρ is the mean ﬂuid density; Y i and Y ∗
i
structure mass fractions of species i, respectively; τ ∗ and γL are the ﬁne-
structure residence time and dimensionless length fraction, respectively; and
χ is the fraction of ﬁne-structure regions that interact with the rest of the
ﬂuid, typically assumed to be unity [75].

(18)

1Technically, this re-use takes place in the StandardChemistryModel in OpenFOAM,
the BasicChemistryModel corresponding to our own

the sub-class of

which is
BatchedChemistryModel implementation.

2Here we only consider Magnussen’s 2005 EDC model [74]. OpenFOAM implements
other versions of the EDC model (Bösenhofer et al. [75] provided a good overview of the
available versions), but the version selected does not aﬀect the derivation of Ri, as the
chemical kinetic model is only responsible for evaluating the thermodynamic components
of Eq. (20).

11

By deﬁnition, for the concentration of species i we have

[Ci] = ρ

Yi
Wi

=

ni
V

,

and

ρYi = Wi

ni
V
where Wi is the molecular weight of species i and the volume V is that of
the corresponding CFD cell. Combining Eq. (19) with Eq. (18) gives the
mean reaction rate in terms of species moles (the species state variable used
in pyJac):

(19)

,

Ri =

1
τ ∗

γ2
Lχ
γ2
Lχ

Wi
V

(ni

n∗
i ) .

1

−
are the mean and ﬁne-structure moles of species i, respec-
where ni and n∗
i
tively. Both nNsp
, the numbers of moles of the last species in
the model in the mean and ﬁne structures, respectively, are calculated us-
ing Eq. (3) to be consistent with pyJac.

and n∗

Nsp

−

(20)

3. Veriﬁcation

In this section, we will verify the accuracy of the vectorized ODE solvers
in two contexts. First, we will directly compare the vectorized solvers imple-
mented in accelerInt against the commonly used high-order implicit solver
CVODEs [79–81], to verify their accuracy and examine their relative perfor-
mance. Then, we will compare the accuracy of the vectorized ROS4 solver
coupled to OpenFOAM (using the methods described in Section 2.4) and the
same ROS4 solver natively implemented in OpenFOAM to a reference chemi-
cal kinetics code Cantera [82] for constant-pressure homogeneous ignition
problems.

3.1. accelerInt veriﬁcation

To verify the new solvers, we sampled 100,000 thermochemical conditions
from a previously generated database [83], created using constant-pressure
partially stirred reactor simulations [34] with the GRI-Mech 3.0 [84] chemical
kinetic model, which consists of 53 species and 325 reactions. The database
covers a pressure range of 1–25 atm and a range of temperatures and com-
positions from a cold unburned CH4/air mixture to states of ignition and

12

equilibrium. These conditions were integrated using CVODEs [79–81] with
tight integration tolerances (absolute tolerance of 10−20, relative tolerance of
10−15) for a single global time step of 10−6 sec to form a reference solution.
We then used the OpenCL solvers to integrate the same initial values
to the same end time, varying the tolerances given to the adaptive time-
stepping algorithm over 10−4, 10−5, . . . , 10−15. We set both the relative and
absolute tolerances for the OpenCL solvers to this tolerance value for the
veriﬁcation eﬀort; in general these can be (and often are) diﬀerent, e.g., as
in the computation of the reference CVODEs solution.

The error of each initial value problem (IVP) was then measured as

Ej

(cid:107)

(cid:107)

=

(cid:13)
(cid:13)
(cid:13)
(cid:13)

y◦
i,j(t)
−
|
10−10 + 10−6

yi,j(t)
|
y◦
i,j(t)
|

× |

(cid:13)
(cid:13)
(cid:13)
(cid:13)2

,

(21)

i,j(t) is the ith component of the solution computed by CVODEs for
where y◦
the jth IVP and yi,j(t) is the solution computed by the solver being tested.
The “tolerances” used for calculating the weighted reference solution com-
ponents in Eq. (21) are for normalization purposes only, and are selected
solely because they are the tolerances that will be used for the reactive-ﬂow
test-case (Section 4.2.2). The error over all IVPs was then calculated using
the inﬁnity norm

=

E

(cid:107)

(cid:107)

Ej
(cid:107)

∞ = max
(cid:107)

j

Ej
|

|

.

(22)

The tested solvers used the same vectorization settings described in Sec-
tion 2.1. Figure 1 shows the work-precision diagram for the accelerInt
solvers: the vertical axis shows the error (as measured by Eqs. (21) and (22))
for the solvers over the various tolerances tested, while the horizontal axis
shows the mean CPU runtime (averaged over ﬁve individual runs) on a sin-
gle core of an Intel® Xeon® X5650 CPU (with SSE4.2 vector instructions),
using v16.1.1 of the Intel OpenCL runtime [63]. We omitted RKF45 from
this test, as the stiﬀness of the chemical kinetic ODEs caused prohibitive
computational costs; this solver will be examined in future work for less-stiﬀ
problems.

For loose tolerances (10−4–10−6), the tested solvers all exhibit similar
performance and error. However, for intermediate tolerances (10−7–10−11,
marked in grey on Fig. 1) the ROS3 solver consistently has the lowest error
compared with the reference solution; the fourth-order solvers (ROS4, RODAS4)
tend to be slightly faster for a minor increase in error in this region. The

13

Figure 1: Work-precision diagram for the implicit OpenCL solvers in accelerInt.
The vertical axis shows the error norm computed by Eqs. (21) and (22), while
the horizontal axis shows the mean runtime of the solver, measured in ms. The
region marked in grey corresponds to “intermediate” tolerances, ranging from
10−7–10−11 (with equal absolute and relative tolerances in the adaptive time-
stepping algorithm).

14

105106107CPUTime(ms)10−610−410−2100102kEkROS4RODAS4ROS3RODAS3higher accuracy of the ROS3 solver in this region is likely due to using a
diﬀerent set of method coeﬃcients (see Table 1). At strict tolerances, i.e.,
less than 10−11, the ROS4 solver is both faster and more accurate than the
third-order methods, while the RODAS4 solver is the most accurate for the
strictest tolerance of 10−15.

3.2. Constant-pressure ignition in OpenFOAM

To verify the coupling of the accelerInt solvers to the OpenFOAM chem-
istry model (see Section 2.4), we ran a series of constant-pressure homoge-
neous ignition problems over initial temperatures of T0 = 850, 1100, and
1500 K, initial pressures of P0 = 1, 10, and 25 atm, and equivalence ratios
of φ = 0.5, 1.0, and 1.5 in air, using the GRI-Mech 3.0 chemical kinetic
model [84] and CH4 as the fuel. These conditions cover low-, intermediate-
, and high-temperature ignition, as well as lean, stoichiometric, and rich
fuel-air mixtures to test the accuracy of the solvers over diﬀerent chemical
kinetic regimes. To test the relative accuracy of the various solvers, the ig-
nition problems were simulated to near chemical equilibrium (post-ignition)
with both accelerInt and the built-in OpenFOAM integrators. The values
of the thermochemical-state vectors for each solver were sampled 10 times,
equally distributed over the entire simulated time span (excluding the ini-
tial state); Fig. 2a shows an example of the time sampling. We compared
the sampled values of both approaches with a reference solution computed
using the open-source, community chemical kinetics code Cantera1 [82]. In
this example we used the fourth-order linearly implicit Rosenbrock solver
(ROS4) in both OpenFOAM and accelerInt, and set the absolute and relative
integration tolerances to 10−10 and 10−6, respectively, for the OpenFOAM and
accelerInt solvers, and to 10−20 and 10−15 for Cantera.

Figure 2 compares the values of the temperature and species mass frac-
tions of CH4, OH, and NO for several initial conditions, showing that all three
solvers agree qualitatively. To quantify this comparison, the supremum and
mean L2 norms of the (ﬁltered) relative error between the tested solvers and

1Cantera internally uses CVODEs for ODE integration.

15

Cantera were calculated respectively as

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)
(cid:13)∞

,

|

(cid:107)

×

×

(cid:13)
(cid:13)
(cid:13)
(cid:13)

Φ◦
|
1
|

(24)

(23)

E
(cid:107)

E
(cid:107)

(cid:13)
(cid:13)
(cid:13)
(cid:13)2

mean =

∞ =
(cid:107)

i (tj)
−
10−10 + Φ◦
1
Ns (Nsp + 1)

Φi (tj)
|
i (tj)
|
Φ◦
i (tj)
|
−
10−10 + Φ◦
1
|
where Ns is the total number of sampled points, Nsp + 1 is the size of the
thermochemical state vector used in OpenFOAM (i.e., the temperature and all
species concentrations), Φi (tj) is the ith entry of the state vector calculated
by either the built-in OpenFOAM or coupled accelerInt ROS4 solver at the
jth sampled point, and Φ◦

i (tj) the reference value calculated by Cantera.

Φi (tj)
|
i (tj)

(106) versus

Table 2 shows the values of these norms for both solvers; the coupled
accelerInt solver agrees much better with the reference solution computed
by Cantera than the built-in OpenFOAM solver. Although the computed error
(105)–
norms for OpenFOAM are several orders of magnitudes larger (i.e.,
(1) for accelerInt), this does not imply that the
O
built-in OpenFOAM ROS4 solver is grossly inaccurate; indeed, a visual com-
parison of the solutions over the entire simulation (Figs. 2a to 2c) show no
easily discernible discrepancies. Instead, this diﬀerence largely results from
more-accurate predictions of ignition delay time on the part of accelerInt.
For instance, Fig. 2d shows the predicted mass fraction of NO during ignition
for the stoichiometric case with an initial pressure of 25 atm and tempera-
ture of 850 K. The OpenFOAM solver predicts ignition about 1.8 ms later than
either accelerInt or Cantera, a mere 0.21 % diﬀerence. Nonetheless, we
conclude that the coupled accelerInt ROS4 solver is more accurate than the
corresponding built-in OpenFOAM implementation.

(10−1)–

O

O

O

Solver

E
mean
(cid:107)
(cid:107)
4.68
OpenFOAM
accelerInt 3.39

105
10−1

×
×

E
(cid:107)
9.49
8.12

∞
(cid:107)

×
×

106
100

Table 2: The ﬁltered mean and supremum relative error norms com-
paring the computed solutions of the built-in OpenFOAM and coupled
accelerInt ROS4 solvers to those of Cantera for the homogeneous
constant-pressure ignition problems.

16

(a) The predicted temperature traces at P0 =
25 atm, T0 = 850 K, and CH4/air of φ = 1.5. The
vertical dashed lines show the points at which the
solution was sampled for error evaluation.

(b) The CH4 mass-fraction proﬁles predicted by the
various solvers at P0 = 10 atm, T0 = 1100 K, and
CH4/air of φ = 1.0

(c) The OH mass-fraction proﬁles predicted by the
various solvers at P0 = 25 atm, T0 = 1500 K, and
CH4/air of φ = 0.5

(d) A zoomed-in look at the NO mass-fraction pro-
ﬁles predicted by the various solvers during the igni-
tion event, for P0 = 25 atm, T0 = 850 K, and CH4/
air of φ = 1.0.

Figure 2: Comparison of constant-pressure homogeneous ignition problem with various
solvers using GRI-Mech 3.0. The plotted points for the built-in OpenFOAM and coupled
accelerInt ROS4 solvers were thinned somewhat for visibility.

17

0.00.51.0Time(s)100015002000Temperature(K)CanteraaccelerIntOpenFOAM0.0000.0050.0100.0150.020Time(s)10−1510−1210−910−610−3YCH4CanteraaccelerIntOpenFOAM0.000000.000020.000040.000060.00008Time(s)10−1310−1010−710−4YOHCanteraaccelerIntOpenFOAM0.860.880.90Time(s)10−2110−1610−1110−610−1YNOCanteraaccelerIntOpenFOAM4. Case studies

After verifying the accuracy of the accelerInt solvers, we next compare
the performance of the built-in OpenFOAM and accelerInt ROS4 solvers on
realistic reactive-ﬂow simulations: the Sandia ﬂame D and the Volvo Flygmo-
tor bluﬀ-body stabilized ﬂame. Our objective in both cases is to determine
the potential speedup oﬀered by the vectorized solver.

4.1. Sandia ﬂame D

The Sandia Flame D [59–61] is a well-characterized piloted CH4/air jet
ﬂame with a turbulent Reynolds number of Ret = 22000. OpenFOAM v5.x
(the 2017 release from the OpenFOAM foundation [85]) and later include a
case modeling this ﬂame as a tutorial, providing a relatively inexpensive but
more-realistic proving ground for the coupled accelerInt solvers. Table 3
and Table 4 list the operating conditions and key dimensions of the case,
and Fig. 3c shows a schematic of the conﬁguration superimposed over the
simulation mesh.

Source

Jet

Coﬂow

Pilot

Composition CH4/Air: 25/75 %† Dry air
0.9 m/s
Velocity
291 K
Temperature
0.993 atm 0.993 atm
Pressure

49.6 m/s
294 K
0.993 atm

Equil.‡
11.4 m/s
1880 K

Table 3: Operating conditions for the Sandia Flame D case.

† The jet composition is measured by percent volume.
‡ Equilibrium state of CH4/air at φ = 0.7.

The mesh for this case, pictured in Fig. 3a,

is fully orthogonal with
5170 cells, ranging in size from roughly 5 mm on a side to 0.72 mm tall
near the wall. The solution domain is a thin three-dimensional wedge, with
axi-symmetric boundary conditions on the front and back faces, and zero-
gradient/total-pressure boundary conditions on the outlet. The case, as pack-
aged with OpenFOAM, uses second-order interpolation and gradient schemes
for all variables, but a strongly limited scheme (tending towards ﬁrst-order)
for divergence calculations. In addition, the simulation uses a standard k–ε

18

Dimension

Value

Djet, inner
Dpilot, inner
Dpilot, outer
Dwall, outer
Exit

7.2 mm
7.7 mm
18.2 mm
18.9 mm

30 mm

30 mm

×

Table 4: Diameter of the jet, pilot, and wall, and exit-plane dimensions for the Sandia
Flame D case.

RANS model to model turbulence and a pseudo-transient, ﬁrst-order time-
stepping scheme to initially advance to a steady-state solution.

We modiﬁed the baseline case slightly to better suit the purposes of this
study. First, we substituted the full GRI-Mech 3.0 chemical kinetic model [84]
for the 36-species skeletal methane model originally used in OpenFOAM. Sec-
ond, the base OpenFOAM case uses a tabulated dynamic adaptive chemistry
scheme [18, 19] to accelerate the solution process; we disabled this to directly
compare the performance and accuracy of the ODE solvers. Finally, after
reaching steady state, we switched the time-stepping scheme to the second-
order implicit method, set the minimum reacting temperature to 500 K, and
ran the case for an additional 10 ms of simulated time using a CFD time step
of ∆t = 10−6 sec.

Using this case, we tested the performance of the various OpenFOAM and
accelerInt solvers. Our goal here is to demonstrate the performance en-
hancement achievable through vectorized chemical kinetic integration, using
available Intel CPUs; though dated, the AVX2 instruction set remains broadly
relevant for CPUs that do not support the newer AVX-512 set. We ran the
performance studies on 10 cores of an Intel E5-2690 V3 CPU, with AVX2 vec-
tor instructions, 128 Gbit of RAM, and v16.1.1 of the Intel OpenCL runtime.
We used OpenFOAM version 6.x with v2.1.0 of the OpenMPI library [86],
compiled with gcc v5.4.0 [87]. We instrumented the reactingFoam solver
with the MPI proﬁling library IPM v2.0.6 [88] by placing proﬁling sections
(via MPI_PControl) around the calls to the turbulent combustion model,
ODE integration, and other key parts of the CFD time step (e.g., convection
evaluation). Section S1 of the Supplemental Material compares in detail the
predicted results for the diﬀerent solvers; here, we focus on the computational
cost/performance.

19

(a) The mesh for the Sandia Flame D case. The red line denotes
where we sampled the solution for validation.

(b) The steady-state temperature proﬁle in K, as solved by the
base OpenFOAM fourth-order Rosenbrock ODE integrator.

(c) A close-up view of the inlet to the domain. The jet and pilot
ﬂames are marked in blue and green, respectively. The sample
lines are marked in red, as in Fig. 3a

Figure 3: The mesh and steady-state temperature proﬁle of the Sandia Flame D case.

20

Figure 4: Total CPU hours spent evaluating chemistry in the Sandia Flame D case. AI is
accelerInt and OF is OpenFOAM.

Figure 4 shows the total wall-clock execution time (over all 10 processors)
spent by each solver integrating the chemical kinetic ODEs. The accelerInt
solver spends just 10.2 and 31.1 h solving chemistry for the steady-state and
time-dependent cases, respectively, while both the OpenFOAM solvers take over
100 h in all cases. The slowest integration method is the OpenFOAM Seulex
solver, which takes over 923 h to complete the time-dependent solution. The
chemistry evaluation time includes time spent idle due to the poor load bal-
ancing of chemistry present in most OpenFOAM simulations1.

Table 5 compares the speedups of the solvers, reported against the OpenFOAM

×

ROS4 solver as the baseline. The accelerInt ROS4 solver performs 12.0–
faster than the OpenFOAM equivalent. In addition, the OpenFOAM Seulex
14.8
solver runs roughly 2
slower than the OpenFOAM ROS4 solver in both cases.
Finally, the accelerInt solver spends 94–96 % in chemistry integration,
while both OpenFOAM methods use over 99 % of the runtime solving chemistry.

×

1OpenFOAM uses a simple static decomposition of the domain, which is to say there is

no chemistry load-balancing occurring.

21

OF(ROS4)AI(ROS4)OF(Seulex)0200400600800CPU-time(hours)Steady-stateTime-dependentSolver

AI (ROS4)

OF (ROS4) OF (Seulex)

Steady-state
Time-dependent
Chemistry time

12.0
14.8

–
–
93.9–95.8 % 99.3–99.6 % 99.7–99.9 %

0.53
0.50

×
×

×
×

Speedups of the chemistry solvers (AI

is
Table 5:
accelerInt and OF is OpenFOAM), normalized by the
OpenFOAM ROS4 solver and the percent of total execution
time spent integrating the chemical-kinetic ODEs.

4.2. Volvo bluﬀ-body stabilized ﬂame

Next, we will use the Volvo Flygmotor bluﬀ-body stabilized premixed
ﬂame experiment [55–57] as a second test case. We simulated a reacting
case, and used this to study the speedup of the coupled accelerInt solver
compared to the built-in OpenFOAM method.

4.2.1. Case description

The Volvo Flygmotor bluﬀ-body stabilized premixed ﬂame experiments
include many phenomena found in practical combustors, such as anchored
ﬂames, recirculation regions, and shear layers [55–57]. The computational
domain is relatively simple and inexpensive to simulate, though, and it is
a well-studied test case for non-swirling turbulent ﬂames [54, 58, 89–92].
Furthermore, experimental velocity, turbulence statistics, and temperature
measurements are available for two inlet velocities and temperatures for val-
idation purposes [55–57]. Section S2 of the Supplemental Material contains
a validation of our setup using the non-reacting simulated velocity and tur-
bulence statistics, compared with available experimental data; we did not
include this in the main text, since our main focus is computational perfor-
mance of the reacting solver.

Figure 5a shows the computational domain we used here, which omits the
fuel injection, seeding, and ﬂow-straightener parts upstream of the bluﬀ body.
Instead, we set steady inﬂow boundary conditions at 5D—where D = 40 mm
is the bluﬀ-body height—upstream of the trailing edge of the bluﬀ body, as
used in previous studies [54, 90, 93]. The domain extends 0.662 m down-
stream of the trailing edge of the bluﬀ body, where we used wave-transmissive
outﬂow conditions as suggested in previous work [90, 92, 93]. The domain is

22

2D wide in the span-wise direction; the front and back faces of the domain
use periodic boundary conditions to reduce computational eﬀort [54, 93]. The
walls of the domain use adiabatic and no-slip boundary conditions. Table 6
lists the inlet conditions, based on the available experimental conditions [94].
We developed the computational mesh (shown in Fig. 5b) based on rec-
ommendations from previous studies [54, 93]; it uses hexagonal cells nomi-
nally 2 mm large and a maximum wall-normal distance of 0.3 mm. Grading
clusters the cells near the walls and bluﬀ-body edges, as well as the shear
layers downstream of the bluﬀ body; the domain is as isotropic as possible
elsewhere, resulting in a total of 2,365,000 mesh cells.

Parameter

Non-reactive Reactive

Pressure
Temperature
Ubulk

1 bar
288 K
16.6 m/s

1 bar
288 K
17.3 m/s

Table 6: Inlet conditions for non-reactive and reactive cases [93], selected to match the
available archived experiment data [94]. Ubulk is the bulk inlet velocity.

To simulate this case we used the OpenFOAM solver reactingFoam with the
LES turbulence model, along with a Smagorinsky subgrid scale model [95]. A
second-order accurate central-diﬀerencing scheme discretized the Laplacian
terms, while the solver used a second-order bounded cell-based Green-gauss
method for gradient calculations. We used a second-order weakly-limited cen-
tral scheme to calculate the velocity advection divergence and strong limiting
for turbulent kinetic energy, species, and energy scalars. The solver advanced
in time with a blended ﬁrst- and second-order Crank–Nicolson scheme, and
we handled pressure-velocity coupling with the PISO (pressure-implicit with
split operator) algorithm [96]. Using a fully implicit second-order time-
stepping method (along with an unlimited velocity advection scheme) was
possible with multiple outer corrector steps—i.e., the PIMPLE algorithm in
place of PISO—to avoid breakup of the ﬂow due to pressure-velocity decou-
pling. However, this would require multiple solutions of the chemical kinetic
ODEs at each step of the simulation, and consequentially make completing a
single time step using the OpenFOAM ODE solvers take longer than the largest
available time reservation on the computing cluster we used here. Hence,
we used the blended time stepping and weakly limited velocity advection
schemes instead.

23

(a) Schematic of the computational domain for the Volvo bluﬀ-body stabilized ﬂame
case. All distances are in meters.

(b) A close up of the computational mesh near the bluﬀ body. The cells are gradually
stretched from a maximum wall-normal distance of 0.3 mm near the walls and bluﬀ
body to a nominal mesh size of 2 mm.

Figure 5: The computational (a) domain and (b) mesh for the Volvo bluﬀ-body stabilized
ﬂame case.

24

  0.04   0.2 0.682  0.12  0.084.2.2. Results

We ran the performance studies on 96 cores (i.e., four nodes with 2
12
cores on each) of an Intel E5-2690 V3 CPU, with AVX2 vector instructions,
128 GB of RAM, and using the Intel OpenCL runtime v16.1.1. We used
OpenFOAM version 6.x [97] with v2.1.0 of the OpenMPI library [86], com-
piled with gcc v5.4.0 [87]. We instrumented the reactingFoam solver
with the MPI-proﬁling library IPM v2.0.6 [88] by placing proﬁling sections
(via MPI_PControl calls) around the calls to the turbulent combustion model,
ODE integration, and other key parts of the CFD time step (e.g., convec-
tion evaluation). The absolute and relative tolerances of the OpenFOAM and
accelerInt ROS4 solvers were 10−10 and 10−6, respectively.

×

Although the Volvo bluﬀ-body reactive ﬂame experiments used a lean
propane-air mixture (overall global equivalence ratio of φ = 0.6), here we
chose a stoichiometric CH4/air combustion case for this study. Previous
studies have shown mixed agreement between simulated and experimental
results using OpenFOAM on this conﬁguration [54, 92]. Considering the many
potential sources of error in a reactive-ﬂow simulation [58]—e.g., the quality
of chemical kinetic model, the turbulence-chemistry interaction model, and
the numerical solver itself [54]—we opted to focus on the performance of the
ODE integration algorithms instead of a detailed comparison of the reactive-
ﬂow case to the experimental data (as done for the non-reactive case as shown
in the Supplemental Material). While we expect that these results could be
reproduced for, e.g., the UCSD propane model [98] with 57 species and 268
reactions, we prefer to simply use the comparably sized GRI-Mech 3.0 [84]
for our demonstration.

We initialized the reactive-ﬂow case using a RANS simulation with the
coarse (4 mm nominal cell size) mesh and the base OpenFOAM ROS4 integra-
tor. A two-step methane model [99] ignited the ﬂame via a spherical high-
temperature kernel placed behind the bluﬀ body. After the ﬂame stabilized
and attached to the bluﬀ body, we ran the RANS simulation using the two-
step methane model for a single ﬂow-through time to develop the temperature
ﬁeld. Next, we mapped the RANS solution onto the same coarse mesh using
the full GRI-Mech 3.0 model with the numerical schemes and LES setup de-
10−7 s such that the
scribed above; we reduced the CFD time-step size to 3
maximum Courant number remained under 0.05, and set a minimum reacting
temperature threshold of 550 K. As species transport is more relevant in the
reactive case, we used the Sutherland transport model in OpenFOAM, and de-

×

25

termined species coeﬃcients by a non-linear least squares ﬁt [100, 101] to the
species viscosities versus temperature relation obtained from Cantera [82].
For the reactive case, the OpenFOAM ROS4 solver proved too slow to ad-
vance the solution in a reasonable time frame, so the accelerInt solver
was used instead to run the coarse LES mesh for a full ﬂow-through time
to develop the solution. Next, the coarse solution was mapped onto the
ﬁner grid described in Section 4.2.1 and run for 3 ms of simulated time us-
ing the accelerInt ROS4 solver to obtain baseline timing and solution data.
Figure 6 shows an instantaneous snapshot of the temperature ﬁeld on the
ﬁner LES grid. For the ﬁne mesh however, the OpenFOAM ROS4 solver was
incapable of ﬁnishing more than a single CFD time step in the maximum
allotted time reservation (6 h) on the computing cluster used here, with each
step taking on average, 3.02–3.80 h of wall-clock time1; in contrast, we note
that a single time step using the accelerInt solver took only an average of
6.5 min of wall-clock time. Thus, simulating the entire 3 ms duration with
the OpenFOAM solver would have required the completion of over 10,000 indi-
vidual job submissions. To get around this issue, 150 evenly spaced solution
points were selected throughout the 3 ms duration, from each of which the
solution was computed for a single CFD time step using the OpenFOAM ROS4
solver for comparison with accelerInt.

Figure 6: Instantaneous temperature contour of the reactive case on the ﬁner LES grid.

The IPM library provides the total wall-clock execution time spent in

1Here, the mean wall-clock time per CFD step is normalized by the total number
of MPI ranks in the simulation such that it can be directly compared to the maximum
time-reservation on the cluster. The mean wall-clock times per CFD step later reported
in Table 7 do not have this normalization applied.

26

user-designated MPI proﬁling sections for each MPI rank in the simulation
over a single job run. Therefore, the computational time spent in, e.g.,
solving the chemical kinetic ODEs for each individual CFD time step cannot
be obtained directly. Instead, we normalized the total wall-clock execution
time by the number of CFD time steps completed in a run, and averaged the
normalized wall-clock time per CFD time step over the total number of runs
(150 for the OpenFOAM solver, and 175 for accelerInt).

Region

ODE solution

Load balancing

Total

Quantity

Time
Speedup
% of total

Time
Speedup
% of total

Time
Speedup
% of total

accelerInt

OpenFOAM

±
±
±

±
±
±

1.900
31.06
18.79
7.11
35.82
81.06
9.10
34.48

×

58.95

0.192 h
5.27
3.32 % 20.86
0.77 h
254.34
5.59
12.89 % 78.06
0.94 h
313.76
5.25

×

±
±
100 %

×

8.05 h

2.93 %
28.60 h

±
–

±

±
–

±

11.64 %
35.28 h

±
–
100 %

Table 7: The mean wall-clock execution time per CFD time step,
speedup, and percent of total runtime spent in ODE integration and
load balancing for both the accelerInt and OpenFOAM ROS4 ODE inte-
gration solvers averaged over ten runs. The times are reported in CPU
hours per step, and were run on 96 Intel E5-2690 V3 CPU cores with
AVX2 vector instructions.

×

faster (with a variation of ±1.87

Table 7 presents the average wall-clock execution time per CFD time
step for the accelerInt and OpenFOAM solvers. The accelerInt ROS4 solver
performs, on average, 32.65
depending
on the run) in solving the chemical kinetic ODEs than the corresponding
OpenFOAM approach. In addition, OpenFOAM poorly balances the load of the
chemistry integration, with both the accelerInt and OpenFOAM chemistry
solvers spending upwards of 75 % of the total computational time waiting on
the solution of the chemical kinetic ODEs from other MPI ranks. OpenFOAM
uses a simple static decomposition of the domain to distribute the compu-
tational cells to the various MPI ranks; hence, if a majority of the cells on
an MPI rank are considered “non-reactive” (i.e., the temperature of the cell
is less than the 550 K threshold) the CPU core will sit idle during chem-

×

27

istry integration. A stiﬀness-based chemical kinetic load balancing scheme
(e.g., as implemented by Kodavasal et al. [102]) could further improve the
computational eﬃciency of reactive-ﬂow simulations in OpenFOAM, and merits
future investigation. Finally, Table 7 shows that the bluﬀ-body simulation in
OpenFOAM using the accelerInt solver spends 35.82
less time wait-
ing due to poor chemical kinetic load balancing, while the overall simulation
is 34.48

faster.

5.25

5.59

×

±

±

×

5. Lessons learned

Our strategy for vectorizing chemistry integration focused on building
a solver based on extended versions of existing models in OpenFOAM. This
consisted of

• existing turbulence-combustion interaction models (e.g., EDC, partially

stirred reactor [PaSR]) to enable proﬁling via IPM [88];

• a batched chemistry model, based on the StandardChemistryModel
class in OpenFOAM that additionally enables optional IPM proﬁling, that
(1) scans the list of cells to determine the list of interacting cells based
on the temperature cut-oﬀ, (2) converts the state variables to the form
expected by pyJac, (3) passes the complete list of reacting cells to the
accelerInt solver(s), and (4) ﬁnally converts state variables for the
integration back to the native OpenFOAM format and stores them in the
appropriate buﬀers;

• three solvers (each with optional IPM proﬁling):

– testODE, used to verify the accuracy of the accelerInt solvers
when converting to and from the OpenFOAM state variables (as
compared to Cantera),

– chemFoam, used to verify the accelerInt solver(s) coupling to

OpenFOAM (i.e., integrating the system of equations), and

– reactingFoam, used to enforce the explicit mass conservation in
pyJac’s state variables, and enable the coupling to accelerInt
for production simulations.

This strategy allowed us to vectorize chemistry integration while modifying
little of OpenFOAM itself. Instead, almost all the logic for enabling alternate

28

models and solvers was contained in the reactingFoamIPM module. Simul-
taneously, because we built the reactingFoamIPM module against existing
OpenFOAM classes, we had to implement few new features there, instead us-
ing calls to the parent class wherever possible. For example, a call to the
IPM-proﬁling-enabled PaSR class’s correction method just required placing
MPI_Pcontrol calls around a call to the base PaSR class’s correction method.
Thus, we did not need to vectorize OpenFOAM itself—the OpenCL code was
entirely contained within the accelerInt and pyJac libraries.

We pursued an OpenCL-based strategy here to vectorize code, with the
intent of supporting portability to diﬀerent platforms. However, in practice,
we found that this led to frequent problems involving segmentation faults
during compiling, program crashes, incorrect compiled code, and more, in ad-
dition to the associated increase in complexity of the source code. Ultimately,
this limited the utility of our approach. Moving forward, we recommend ex-
amining a pure OpenMP-based implementation to enable broad adoption;
OpenMP version 5.0 [47, 103] might also support oﬄoading calculations to
GPUs.

6. Conclusions

This work adapted several previously developed linearly implicit and ex-
plicit OpenCL-vectorized ODE integration methods [33] into the accelerInt
library [104]. We veriﬁed the accuracy of these solvers for the solution of the
chemical kinetic ODEs (using source-rate and analytical Jacobian evalua-
tion codes from the pyJac code-generation platform [35]) for a variety of
cases in this eﬀort. We developed OpenFOAM-based models of the Sandia
Flame D [59–61] stabilized jet ﬂame and Volvo bluﬀ-body stabilized pre-
mixed ﬂame [105]. Furthermore, we used a vectorized solver to accelerate
chemical-kinetic integration of these reactive simulations, resulting in large
performance improvements.

The major contributions of this work are

• Incorporating vectorized chemical kinetic ODE integration methods
(provided by the accelerInt and pyJac libraries) into a publicly avail-
able OpenFOAM solver [106];

• Achieving signiﬁcant speedups (33–35

) via the vectorized solvers over
built-in OpenFOAM integration methods on the same hardware (an Intel
Xeon CPU with AVX2 vector instructions); and

×

29

• Proﬁling the solution of realistic reactive-ﬂow simulations in OpenFOAM,

demonstrating the need for chemical kinetic load-balancing.

Future extensions to this work should focus on a few key aspects. First,
this study has demonstrated that one of the largest bottlenecks of realis-
tic reactive-ﬂow simulations in OpenFOAM is the poor chemical kinetic load
balancing based on static decomposition. Over 75 % of the overall computa-
tional time is wasted using either the accelerInt or native OpenFOAM solvers
due to this issue. A number of chemical kinetic load balancing algorithms ex-
ist [107, 108], but the stiﬀness-based load-balancing technique of Kodavasal
et al. [102] seems particularly promising.

More generally, this work has shown that vectorized, linearly implicit
ODE integration (paired with analytical Jacobian evaluation) can greatly
accelerate reactive-ﬂow simulations. Developing vectorized sparse linear al-
gebra/matrix factorization codes would be an excellent—while challenging—
extension of this work, further speeding up the integration of larger detailed
chemical models. More advanced integration algorithms should also be inves-
tigated; W-methods [49] are particularly promising for their ability to re-use
previously evaluated Jacobians and LU-factorizations without needing New-
ton iteration.

We also found challenges in the OpenCL-based programming approach,
which we originally pursued for portability. Moving forward, we recommend
using pure OpenMP for vectorization, which should avoid substantially in-
creasing source complexity and also may enable oﬄoading of calculations to
GPUs.

Acknowledgments

This material is based upon work supported by the National Science
Foundation under grants ACI-1534688 (Curtis and Sung) and ACI-1535065
(Niemeyer). We would also like to thank Christopher Stone of Computational
Science and Engineering, LLC for making available the OpenCL integrators
used in this study.

Appendix: Availability of material

The vectorized ODE integration methods used in this work are available
in version 2.0-beta of the accelerInt library [104], while pyJac-v2.0 [109]

30

provides the chemical kinetic source terms and Jacobian evaluation. The
OpenFOAM case modeling the Volvo bluﬀ-body ﬂame is available for download
via GitHub [105], and the coupled OpenFOAM/accelerInt solver (with IPM-
based proﬁling) is also made available for public use [106]. Finally, the data,
ﬁgures, and plotting scripts used to generate this paper are similarly available
for public use [110].

References

[1] S. Imtenan, M. Varman, H. Masjuki, M. Kalam, H. Sajjad, M. Arbab,
I. R. Fattah, Impact of low temperature combustion attaining strate-
gies on diesel engine emissions for diesel and biodiesels: A review, En-
ergy Convers. Manag. 80 (2014) 329–356. doi:10.1016/j.enconman.
2014.01.020.

[2] C. K. Westbrook, Y. Mizobuchi, T. J. Poinsot, P. J. Smith, J. Warnatz,
Computational combustion, Proc. Combust. Inst. 30 (2005) 125–157.
doi:10.1016/j.proci.2004.08.275.

[3] A. A. Moiz, M. M. Ameen, S.-Y. Lee, S. Som, Study of soot produc-
tion for double injections of n-dodecane in CI engine-like conditions,
Combust. Flame 173 (2016) 123–131. doi:10.1016/j.combustflame.
2016.08.005.

[4] T. Lu, C. K. Law, Toward accommodating realistic fuel chemistry in
large-scale computations, Prog. Energy Comb. Sci. 35 (2009) 192–215.
doi:10.1016/j.pecs.2008.10.002.

[5] T. Turányi, A. S. Tomlin, Analysis of Kinetic Reaction Mech-
anisms, Springer-Verlag, Berlin Heidelberg, 2014. doi:10.1007/
978-3-662-44562-4.

[6] T. Lu, C. K. Law, Linear time reduction of large kinetic mechanisms
with directed relation graph: n-heptane and iso-octane, Combust.
Flame 144 (2006) 24–36. doi:10.1016/j.combustflame.2005.02.015.

[7] P. Pepiot-Desjardins, H. Pitsch, An eﬃcient error-propagation-based
reduction method for large chemical kinetic mechanisms, Combust.
Flame 154 (2008) 67–81. doi:10.1016/j.combustflame.2007.10.020.

31

[8] V. Hiremath, Z. Ren, S. B. Pope, A greedy algorithm for species selec-
tion in dimension reduction of combustion chemistry, Combust. Theor.
Model. 14 (2010) 619–652. doi:10.1080/13647830.2010.499964.

[9] K. E. Niemeyer, C. J. Sung, M. P. Raju, Skeletal mechanism genera-
tion for surrogate fuels using directed relation graph with error propa-
gation and sensitivity analysis, Combust. Flame 157 (2010) 1760–1770.
doi:10.1016/j.combustflame.2009.12.022.

[10] T. Lu, C. K. Law, Diﬀusion coeﬃcient reduction through species
Combust. Flame 148 (2007) 117–126. doi:10.1016/j.

bundling,
combustflame.2006.10.004.

[11] S. S. Ahmed, F. Mauß, G. Moréac, T. Zeuch, A comprehensive and
compact n-heptane oxidation model derived using chemical lumping,
Phys. Chem. Chem. Phys. 9 (2007) 1107–1126. doi:10.1039/b614712g.

[12] P. Pepiot-Desjardins, H. Pitsch,

An automatic chemical
lump-
large chemical kinetic mecha-
ing method for the reduction of
nisms, Combust. Theor. Model. 12 (2008) 1089–1108. doi:10.1080/
13647830802245177.

[13] U. Maas, S. B. Pope, Simplifying chemical kinetics:

intrinsic low-
dimensional manifolds in composition space, Combust. Flame 88 (1992)
239–264. doi:10.1016/0010-2180(92)90034-M.

[14] S.-H. Lam, D. A. Goussis, The CSP method for simplying kinetics,
Int. J. Chem. Kinet. 26 (1994) 461–486. doi:10.1002/kin.550260408.

[15] T. Lu, Y. Ju, C. K. Law, Complex CSP for chemistry reduction
and analysis, Combust. Flame 126 (2001) 1445–1455. doi:10.1016/
S0010-2180(01)00252-8.

[16] X. Gou, W. Sun, Z. Chen, Y. Ju, A dynamic multi-timescale method
for combustion modeling with detailed and reduced chemical kinetic
mechanisms, Combust. Flame 157 (2010) 1111–1121. doi:10.1016/j.
combustflame.2010.02.020.

[17] S. B. Pope, Computationally eﬃcient implementation of combustion
chemistry using in situ adaptive tabulation, Combust. Theor. Model.
1 (1997) 41–63. doi:10.1080/713665229.

32

[18] Z. Ren, Y. Liu, T. Lu, L. Lu, O. O. Oluwole, G. M. Goldin, The
use of dynamic adaptive chemistry and tabulation in reactive ﬂow
simulations, Combust. Flame 161 (2014) 127–137. doi:10.1016/j.
combustflame.2013.08.018.

[19] Z. Li, M. T. Lewandowski, F. Contino, A. Parente, Assessment of on-
the-ﬂy chemistry reduction and tabulation approaches for the simula-
tion of moderate or intense low-oxygen dilution combustion, Energy Fu-
els 32 (2018) 10121–10131. doi:10.1021/acs.energyfuels.8b01001.

[20] T. Lu, C. K. Law,

Strategies for mechanism reduction for large
hydrocarbons: n-heptane, Combust. Flame 154 (2008) 153–163.
doi:10.1016/j.combustflame.2007.11.013.

[21] K. E. Niemeyer, C. J. Sung, Mechanism reduction for multicomponent
surrogates: A case study using toluene reference fuels, Combust. Flame
161 (2014) 2752–2764. doi:10.1016/j.combustflame.2014.05.001.

[22] K. E. Niemeyer, C. J. Sung, Reduced chemistry for a gasoline surrogate
valid at engine-relevant conditions, Energy Fuels 29 (2015) 1172–1185.
doi:10.1021/ef5022126.

[23] L. Liang, J. Stevens, J. T. Farrell, A dynamic adaptive chemistry
scheme for reactive ﬂow computations, Proc. Combust. Inst. 32 (2009)
527–534. doi:10.1016/j.proci.2008.05.073.

[24] H. Yang, Z. Ren, T. Lu, G. M. Goldin, Dynamic adaptive chemistry
for turbulent ﬂame simulations, Combust. Theor. Model. 17 (2013)
167–183. doi:10.1080/13647830.2012.733825.

[25] N. J. Curtis, K. E. Niemeyer, C. J. Sung, An automated target species
selection method for dynamic adaptive chemistry simulations, Com-
bust. Flame 162 (2015) 1358–1374. doi:10.1016/j.combustflame.
2014.11.004.

[26] D. R. Mott, E. S. Oran, B. van Leer, A quasi-steady-state solver for
the stiﬀ ordinary diﬀerential equations of reaction kinetics, Journal of
Computational Physics 164 (2000) 407–428. doi:10.1006/jcph.2000.
6605.

33

[27] M. A. Hansen, J. C. Sutherland, Dual timestepping methods for de-
tailed combustion chemistry, Combust. Theor. Model. 21 (2017) 329–
345. doi:10.1080/13647830.2016.1235728.

[28] Y. Shi, W. H. Green, H.-W. Wong, O. O. Oluwole, Accelerating multi-
dimensional combustion simulations using GPU and hybrid explicit/
implicit ODE integration, Combust. Flame 159 (2012) 2388–2397.
doi:10.1016/j.combustflame.2012.02.016.

[29] C. P. Stone, F. Bisetti, Comparison of ODE solvers for chemical kinet-
ics and reactive CFD applications, in: AIAA 52nd Aerospace Sciences
Meeting (National Harbor, MD), 2014. doi:10.2514/6.2014-0822,
AIAA Paper No. 2014-0822.

[30] K. E. Niemeyer, C. J. Sung, Accelerating moderately stiﬀ chemical
kinetics in reactive-ﬂow simulations using GPUs, J. Comput. Phys.
256 (2014) 854–871. doi:10.1016/j.jcp.2013.09.025.

[31] A. Imren, D. Haworth, On the merits of extrapolation-based stiﬀ ODE
solvers for combustion CFD, Combust. Flame 174 (2016) 1–15. doi:10.
1016/j.combustflame.2016.09.018.

[32] N. J. Curtis, K. E. Niemeyer, C. J. Sung, An investigation of GPU-
based stiﬀ chemical kinetics integration methods, Combust. Flame 179
(2017) 312–324. doi:10.1016/j.combustflame.2017.02.005.

[33] C. P. Stone, A. T. Alferman, K. E. Niemeyer, Accelerating ﬁnite-rate
chemical kinetics with coprocessors: comparing vectorization methods
on GPUs, MICs, and CPUs, Comput. Phys. Comm. 226 (2018) 18–29.
doi:10.1016/j.cpc.2018.01.015.

[34] K. E. Niemeyer, N. J. Curtis, C. J. Sung, pyJac: analytical Jacobian
generator for chemical kinetics, Comput. Phys. Comm. 215 (2017)
188–203. doi:10.1016/j.cpc.2017.02.004.

[35] N. J. Curtis, K. E. Niemeyer, C. J. Sung, Using SIMD and SIMT
vectorization to evaluate sparse chemical kinetic Jacobian matrices and
thermochemical source terms, Combustion and Flame 198 (2018) 186–
204. doi:10.1016/j.combustflame.2018.09.008.

34

[36] M. A. Hansen, J. C. Sutherland, On the consistency of state vectors
and Jacobian matrices, Combust. Flame 193 (2018) 257–271. doi:j.
combustflame.2018.03.017.

[37] K. Spaﬀord, J. Meredith, J. Vetter, J. Chen, R. Grout, R. Sankaran,
Accelerating S3D: A GPGPU case study,
in: Euro-Par 2009 Parallel
Process. Workshops, LNCS 6043, Springer-Verlag, Berlin, Heidelberg,
2010, pp. 122–131. doi:10.1007/978-3-642-14122-5_16.

[38] Y. Shi, W. H. Green, H.-W. Wong, O. O. Oluwole, Redesigning com-
bustion modeling algorithms for the graphics processing unit (GPU):
Chemical kinetic rate evaluation and ordinary diﬀerential equation
integration, Combust. Flame 158 (2011) 836–847. doi:10.1016/j.
combustflame.2011.01.024.

[39] K. E. Niemeyer, C. J. Sung, C. G. Fotache, J. C. Lee, Turbulence-
chemistry closure method using graphics processing units: a prelimi-
nary test, in: Fall 2011 Technical Meeting of the Eastern States Section
of the Combust. Institute, 2011. doi:10.6084/m9.figshare.3384964.

[40] C. P. Stone, R. L. Davis, Techniques for solving stiﬀ chemical kinetics
on graphical processing units, J. Propul. Power 29 (2013) 764–773.
doi:10.2514/1.B34874.

[41] F. Sewerin, S. Rigopoulos, A methodology for the integration of stiﬀ
chemical kinetics on GPUs, Combust. Flame 162 (2015) 1375–1394.
doi:10.1016/j.combustflame.2014.11.003.

[42] N. J. Curtis, K. E. Niemeyer, C. J. Sung, An investigation of GPU-
based stiﬀ chemical kinetics integration methods, Combustion and
Flame 179 (2017) 312–324. doi:10.1016/j.combustflame.2017.02.
005.

[43] A. Kroshko, R. J. Spiteri, Eﬃcient SIMD solution of multiple systems
of stiﬀ IVPs, J. Comput. Sci 4 (2013) 377–385. doi:10.1016/j.jocs.
2012.08.017.

[44] J. C. Linford, A. Sandu, Chemical kinetics on multi-core SIMD archi-

tectures, in: Proc. 9th Int. Conf. Comput. Sci., 2009.

35

[45] J. C. Linford, J. Michalakes, M. Vachharajani, A. Sandu, Automatic
generation of multicore chemical kernels, IEEE Trans. Parallel Distrib.
Syst. 22 (2011) 119–131. doi:10.1109/TPDS.2010.106.

[46] Y. Che, M. Yang, C. Xu, Y. Lu, Petascale scramjet combustion simula-
tion on the Tianhe-2 heterogeneous supercomputer, Parallel Comput.
77 (2018) 101–117. doi:10.1016/j.parco.2018.06.004.

[47] L. Dagum, R. Menon, OpenMP: an industry standard API for shared-
memory programming, Comput. Sci. & Engineering, IEEE 5 (1998)
46–55. doi:10.1109/99.660313.

[48] J. E. Stone, D. Gohara, G. Shi, OpenCL: A parallel programming
IEEE Des. Test 12

standard for heterogeneous computing systems,
(2010) 66–73. doi:10.1109/MCSE.2010.69.

[49] E. Hairer, G. Wanner, Solving Ordinary Diﬀerential Equations II: Stiﬀ
and Diﬀerential-Algebraic Problems, 2 ed., Springer-Verlag, Berlin,
1996. doi:10.1007/978-3-642-05221-7.

[50] H. G. Weller, G. Tabor, H. Jasak, C. Fureby, A tensorial approach to
computational continuum mechanics using object-oriented techniques,
Comput. Phys. 12 (1998) 620–631. doi:10.1063/1.168744.

[51] R. J. Kee, G. Dixon-Lewis, J. Warnatz, M. E. Coltrin, J. A. Miller,
A Fortran computer code package for the evaluation of gas-phase mul-
ticomponent transport properties, Technical Report, Sandia National
Laboratories Report SAND86-8246, 1986.

[52] M. Baum, T. Poinsot, D. Thévenin, Accurate boundary conditions for
multicomponent reactive ﬂows, J. Comput. Phys. 116 (1995) 247 – 261.
doi:10.1006/jcph.1995.1024.

[53] N. Okong’o, J. Bellan, Consistent boundary conditions for multicom-
ponent real gas mixtures based on characteristic waves, J. Comput.
Phys. 176 (2002) 330 – 344. doi:10.1006/jcph.2002.6990.

[54] P. A. Cocks, M. C. Soteriou, V. Sankaran,

Impact of numerics on
the predictive capabilities of reacting ﬂow LES, Combust. Flame 162
(2015) 3394–3411. doi:10.1016/j.combustflame.2015.04.016.

36

[55] A. Sjunnesson, C. Nelsson, E. Max, LDA measurements of velocities
and turbulence in a bluﬀ body stabilized ﬂame,
in: Fourth Interna-
tional Conference on Laser Anemometry – Advances and Application,
volume 3, Cleveland, OH, 1991, pp. 83–90.

[56] A. Sjunnesson, S. Olovsson, B. Sjoblom, Validation rig - a tool for
ﬂame studies, in: International Symposium on Air Breathing Engines,
10th, Nottingham, England, 1991, pp. 385–393.

[57] A. Sjunnesson, P. Henrikson, C. Lofstrom, CARS measurements and
visualization of reacting ﬂows in a bluﬀ body stabilized ﬂame, in: 28th
Joint Propulsion Conference and Exhibit, AIAA, 1992. doi:10.2514/
6.1992-3650, AIAA Paper No. 92-3650.

[58] B. Rochette, F. Collin-Bastiani, L. Gicquel, O. Vermorel, D. Vey-
nante, T. Poinsot, Inﬂuence of chemical schemes, numerical method
and dynamic turbulent combustion modeling on LES of premixed tur-
bulent ﬂames, Combust. Flame 191 (2018) 417–430. doi:10.1016/j.
combustflame.2018.01.016.

[59] R. Barlow, J. Frank, Eﬀects of turbulence on species mass fractions
in methane/air jet ﬂames, Twenty-Seventh International Symposium
on Combustion 27 (1998) 1087–1095. doi:10.1016/S0082-0784(98)
80510-9.

[60] R. Barlow, J. Frank, A. Karpetis, J.-Y. Chen, Piloted methane/air
jet ﬂames: Transport eﬀects and aspects of scalar structure, Com-
bust. Flame 143 (2005) 433–449. doi:https://doi.org/10.1016/j.
combustflame.2005.08.017.

[61] C. Schneider, A. Dreizler, J. Janicka, E. Hassel, Flow ﬁeld mea-
surements of stable and locally extinguishing hydrocarbon-fuelled jet
ﬂames, Combust. Flame 135 (2003) 185–190. doi:doi.org/10.1016/
S0010-2180(03)00150-0.

[62] M. Bauer, S. Treichler, A. Aiken, Singe: Leveraging warp specialization
for high performance on GPUs, SIGPLAN Not. 49 (2014) 119–130.
doi:10.1145/2692916.2555258.

37

[63] Intel® Corporation, OpenCL™ drivers and runtimes

In-
tel® architecture, https://software.intel.com/en-us/articles/
opencl-drivers#latest_CPU_runtime, 2018.

for

[64] A. Sandu, J. Verwer, J. Blom, E. Spee, G. Carmichael, F. Potra,
Benchmarking stiﬀ ODE solvers for atmospheric chemistry problems
II: Rosenbrock solvers, Atmospheric Environ. 31 (1997) 3459–3472.
doi:10.1016/S1352-2310(97)83212-8.

[65] H. Zhang, A. Sandu, FATODE: A library for forward, adjoint, and
tangent linear integration of odes, SIAM J. Sci. Comput. 36 (2014)
C504–C523. doi:10.1137/130912335.

[66] E. Hairer, S. P. Nørsett, G. Wanner, Solving Ordinary Diﬀerential
Equations I: Nonstiﬀ Problems, Springer Berlin Heidelberg, Berlin,
Heidelberg, 1993. doi:10.1007/978-3-540-78862-1.

[67] P. Kaps, S. W. H. Poon, T. D. Bui, Rosenbrock methods for stiﬀ ODEs:
A comparison of Richardson extrapolation and embedding technique,
Comput. 34 (1985) 17–40. doi:10.1007/BF02242171.

[68] L. F. Shampine, Implementation of Rosenbrock methods, ACM Trans.

Math. Softw. 8 (1982) 93–113. doi:10.1145/355993.355994.

[69] D. A. Lysenko, I. S. Ertesvåg, K. E. Rian, Numerical simulation of
non-premixed turbulent combustion using the eddy dissipation concept
and comparing with the steady laminar ﬂamelet model, Flow, Turbul.
Combust. 93 (2014) 577–605. doi:10.1007/s10494-014-9551-7.

[70] C. Fureby, Philos. Trans. Royal Soc. A: Math., Phys. Eng. Sci. 367

(2009) 2957–2969. doi:10.1098/rsta.2008.0271.

[71] The OpenFOAM Foundation, OpenFOAM v6 user guide, 2018. URL:
https://cfd.direct/openfoam/user-guide-v6/, [Online; accessed
12/02/18].

[72] Message Passing Interface Forum, MPI: A message-passing interface
standard, version 3.0, https://www.mpi-forum.org/docs/mpi-3.0/
mpi30-report.pdf, 2012.

38

[73] H. Weller, G. Tabor, A. Gosman, C. Fureby, Application of a ﬂame-
wrinkling LES combustion model to a turbulent mixing layer, vol-
ume 27, 1998, pp. 899–907. doi:10.1016/S0082-0784(98)80487-6.

[74] B. F. Magnussen, The eddy dissipation concept–a bridge between sci-
in: ECCOMAS thematic conference on compu-

ence and technology,
tational combustion, 2005, pp. 21–24.

[75] M. Bösenhofer, E.-M. Wartha, C. Jordan, M. Harasek, The eddy dissi-
pation concept—analysis of diﬀerent ﬁne structure treatments for clas-
sical combustion, Energies 11 (2018) 1902. doi:10.3390/en11071902.

[76] M. J. Evans, P. R. Medwell, Z. F. Tian, Modeling lifted jet ﬂames in
a heated coﬂow using an optimized eddy dissipation concept model,
Combust. Sci. Tech. 187 (2015) 1093–1109. doi:10.1080/00102202.
2014.1002836.

[77] Z. Li, A. Cuoci, A. Sadiki, A. Parente, Comprehensive numerical study
of the Adelaide jet in hot-coﬂow burner by means of RANS and detailed
chemistry, Energy 139 (2017) 555–570. doi:10.1016/j.energy.2017.
07.132.

[78] B. F. Magnussen, Modeling of NOx and soot formation by the eddy
dissipation concept, in: International Flame Research Foundation First
Topic Oriented Technical Meeting, 1989, pp. 17–19.

[79] E. Banks, A. M. Collier, A. C. Hindmarsh, R. Serban, C. S. Wood-
ward, SUNDIALS v2.7.0, http://computation.llnl.gov/projects/
sundials-suite-nonlinear-differential-algebraic-equation-solvers/
download/sundials-2.7.0.tar.gz, 2016.

[80] P. N. Brown, G. D. Byrne, A. C. Hindmarsh, VODE: a variable-
coeﬃcient ODE solver, SIAM J. Sci. Stat. Comput. 10 (1989) 1038–
1051. doi:10.1137/0910062.

[81] A. C. Hindmarsh, P. N. Brown, K. E. Grant, S. L. Lee, R. Serban,
D. E. Shumaker, C. S. Woodward, SUNDIALS: Suite of nonlinear and
diﬀerential/algebraic equation solvers, ACM Trans. Math. Softw. 31
(2005) 363–396. doi:10.1145/1089014.1089020.

39

[82] D. G. Goodwin, H. K. Moﬀat, R. L. Speth, Cantera: An object-
oriented software toolkit for chemical kinetics, thermodynamics, and
transport processes, http://www.cantera.org, 2018. doi:10.5281/
zenodo.1174508, version 2.4.0.

[83] N. J. Curtis, K. E. Niemeyer, ch4_pasr_data.bin, Figshare, 2016.

doi:10.6084/m9.figshare.4007418.v2.

[84] G. P. Smith, D. M. Golden, M. Frenklach, N. W. Moriarty, B. Eiteneer,
M. Goldenberg, C. T. Bowman, R. K. Hanson, S. Song, W. C. Gardiner,
V. V. Lissianski, Z. Qin, GRI-Mech 3.0, http://www.me.berkeley.
edu/gri_mech/, 1999.

[85] The OpenFOAM Foundation, OpenFOAM v5.0, 2017. URL: https://
openfoam.org/download/5-0-source/, [Online; accessed 12/02/18].

[86] E. Gabriel, G. E. Fagg, G. Bosilca, T. Angskun, J. J. Dongarra, J. M.
Squyres, V. Sahay, P. Kambadur, B. Barrett, A. Lumsdaine, R. H.
Castain, D. J. Daniel, R. L. Graham, T. S. Woodall, Open MPI:
Goals, concept, and design of a next generation MPI implementation,
in: Recent Advances in Parallel Virtual Machine and Message Passing
Interface, Springer Berlin Heidelberg, 2004, pp. 97–104. doi:10.1007/
978-3-540-30218-6_19.

[87] R. M. Stallman, GCC Developer Community, Using The GNU Com-
piler Collection: A GNU Manual For GCC Version 4.3.3, CreateSpace,
Paramount, CA, 2009.

[88] D. Skinner, Performance monitoring of parallel scientiﬁc applications,

Technical Report, 2005. doi:10.2172/881368.

[89] C. Fureby, S.-I. Moller, Large eddy simulation of reacting ﬂows applied
to bluﬀ body stabilized ﬂames, AIAA J. 33 (1995) 2339–2347. doi:10.
2514/3.12989.

[90] N. Zettervall, K. Nordin-Bates, E. Nilsson, C. Fureby, Large eddy
simulation of a premixed bluﬀ body stabilized ﬂame using global
and skeletal reaction mechanisms, Combust. Flame 179 (2017) 1–22.
doi:10.1016/j.combustflame.2016.12.007.

40

[91] S. Möller, E. Lundgren, C. Fureby, Large eddy simulation of unsteady
combustion, 26th International Symposium on Combustion 26 (1996)
241–248. doi:10.1016/S0082-0784(96)80222-0.

[92] C. Y. Lee, S. Cant, Large-eddy simulation of a bluﬀ-body stabilised
turbulent premixed ﬂame using the transported ﬂame surface density
approach, Combust. Theor. Model. 21 (2017) 722–748. doi:10.1080/
13647830.2017.1293849.

[93] A. Comer, 3rd model validation for propulsion workshop overview and
validation cases, https://community.apan.org/cfs-file/__key/
widgetcontainerfiles/3fc3f82483d14ec485ef92e206116d49-g-_
2D00_tM6tEO4PkenM5KsnY8ctg-page-0cases/MVP3_5F00_
Validation_5F00_Case_5F00_20180608.pdf,
01-08-19.

Accessed:

2018.

[94] A. Comer, Model validation for propulsion workshop - experimen-
tal data archives, 2016. URL: https://community.apan.org/wg/
afrlcg/mvpws/p/experimental-data, accessed: 01-08-19.

[95] J. Smagorinsky, General circulation experiments with the primitive
equations, Mon. Weather Review 91 (1963) 99–164. doi:10.1175/
1520-0493(1963)091<0099:GCEWTP>2.3.CO;2.

[96] R. I. Issa, Solution of the implicitly discretised ﬂuid ﬂow equations by
operator-splitting, Journal of Computational Physics 62 (1986) 40–65.
doi:10.1016/0021-9991(86)90099-9.

[97] H. Weller, C. Greenshields, W. Bainbridge,

OpenFOAM v6,
https://openfoam.org/release/6/, 2018. Note: Commit 00e347 on the
OpenFOAM-6 GitHub repository.

[98] Mechanical and Aerospace Engineering (Combustion Research), Uni-
versity of California at San Diego, Chemical-kinetic mechanisms for
combustion applications, http://combustion.ucsd.edu, 2018. San
Diego Mechanism web page.

[99] B. Franzelli, E. Riber, L. Y. Gicquel, T. Poinsot, Large eddy simulation
of combustion instabilities in a lean partially premixed swirled ﬂame,
Combust. Flame 159 (2012) 621–637. doi:10.1016/j.combustflame.
2011.08.004.

41

[100] E. Jones, T. Oliphant, P. Peterson, et al., SciPy: Open source scien-
tiﬁc tools for Python, 2001–. URL: http://www.scipy.org/, [Online;
accessed 12/02/18].

[101] P. Virtanen, R. Gommers, T. E. Oliphant, M. Haberland, T. Reddy,
D. Cournapeau, E. Burovski, P. Peterson, W. Weckesser, J. Bright, S. J.
van der Walt, M. Brett, J. Wilson, K. J. Millman, N. Mayorov, A. R. J.
Nelson, E. Jones, R. Kern, E. Larson, C. J. Carey, İ. Polat, Y. Feng,
E. W. Moore, J. VanderPlas, D. Laxalde, J. Perktold, R. Cimrman,
I. Henriksen, E. A. Quintero, C. R. Harris, A. M. Archibald, A. H.
Ribeiro, F. Pedregosa, P. van Mulbregt, SciPy 1.0 Contributors, SciPy
1.0: fundamental algorithms for scientiﬁc computing in Python, Nature
Methods 17 (2020) 261–272. doi:10.1038/s41592-019-0686-2.

[102] J. Kodavasal, K. Harms, P. Srivastava, S. Som, S. Quan, K. Richards,
M. García, Development of a stiﬀness-based chemistry load bal-
ancing scheme, and optimization of input/output and communica-
tion, to enable massively parallel high-ﬁdelity internal combustion
engine simulations, J. Energy Resour. Technol. 138 (2016) 052203.
doi:10.1115/1.4032623.

[103] OpenMP Architecture Review Board, OpenMP Application Pro-
gram Interface version 5.2, 2021. URL: https://www.openmp.org/
wp-content/uploads/OpenMP-API-Specification-5-2.pdf.

[104] N. J. Curtis, K. E. Niemeyer, accelerInt v2.0-beta, 2019. URL:
https://github.com/SLACKHA/accelerInt/tree/rewrite. doi:10.
5281/zenodo.5963906.

[105] N. J. Curtis, bluffbody_LES—an implementation of a Volvo Flygmo-
tor AB bluﬀ-body reacting ﬂow simulation for OpenFOAM with a vec-
torized ODE solver, https://github.com/arghdos/bluffbody_LES,
2019. doi:10.5281/zenodo.2574941.

[106] N. J. Curtis,
7b46091,

reactingFoamIPM-beta, Zenodo [software],

ver-
https://github.com/arghdos/

sion
reactingFoamIPM. doi:10.5281/zenodo.5963888.

2019. URL:

[107] D. L. Flowers, S. M. Aceves, A. Babajimopoulos, Eﬀect of charge
non-uniformity on heat release and emissions in PCCI engine combus-

42

tion, in: SAE Technical Paper Series, 2006-01-1363, SAE International,
2006. doi:10.4271/2006-01-1363.

[108] Y. Shi, S. L. Kokjohn, H.-W. Ge, R. D. Reitz, Eﬃcient multidimen-
sional simulation of HCCI and DI engine combustion with detailed
chemistry, in: SAE Technical Paper Series, 2009-01-0701, SAE Inter-
national, 2009. doi:10.4271/2009-01-0701.

[109] N. J. Curtis, K. E. Niemeyer, pyJac v2.0, 2019. URL: https://
github.com/SLACKHA/pyJac-v2. doi:10.5281/zenodo.5964176.

[110] N. J. Curtis, K. E. Niemeyer, C. J. Sung, Data, plotting scripts,
and ﬁgures for “Accelerating reactive-ﬂow simulations using vectorized
chemistry integration”, Zenodo [dataset], 2022. doi:10.5281/zenodo.
5963861.

43

