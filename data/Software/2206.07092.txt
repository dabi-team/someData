2
2
0
2

y
a
M
4
2

]

C
D
.
s
c
[

1
v
2
9
0
7
0
.
6
0
2
2
:
v
i
X
r
a

Optimization Heuristics for Cost-Efﬁcient
Long-Term Cloud Portfolio Allocations Under
Uncertainty

Maximilian Kiessler
Faculty of Computer Science
University of Vienna
Vienna, Austria
max.kiessler@gmail.com

Valentin Haag
Faculty of Computer Science
University of Vienna
Vienna, Austria
valentin.haag94@gmail.com

Benedikt Pittl
Faculty of Computer Science
University of Vienna
Vienna, Austria
benedikt.pittl@univie.ac.at

Erich Schikuta
Faculty of Computer Science
University of Vienna
Vienna, Austria
erich.schikuta@univie.ac.at

Abstract—Today’s cloud infrastructure landscape offers a
broad range of services to build and operate software appli-
cations. The myriad of options, however, has also brought along
a new layer of complexity. When it comes to procuring cloud
computing resources, consumers can purchase their virtual ma-
chines from different providers on different marketspaces to form
so called cloud portfolios: a bundle of virtual machines whereby
the virtual machines have different technical characteristics and
pricing mechanisms. Thus, selecting the right server instances
for a given set of applications such that the allocations are cost
efﬁcient is a non-trivial task.

the
In this paper we propose a formal speciﬁcation of
cloud portfolio management problem that takes an application-
driven approach and incorporates the nuances of the commonly
encountered reserved, on-demand and spot market types. We
present two distinct cost optimization heuristics for this stochastic
temporal bin packing problem, one taking a naive ﬁrst ﬁt
strategy, while the other is built on the concepts of genetic
algorithms. The results of the evaluation show that the former
optimization approach signiﬁcantly outperforms the latter, both
in terms of execution speeds and solution quality.

Index Terms—Cloud Economics, Resource Portfolio Optimiza-
tion, Cloud Decision Support, Stochastic Temporal Bin Packing

I. INTRODUCTION

The ever-increasing relevance of cloud computing has
brought along a paradigm shift
in terms of how modern
software applications are developed and operated. While these
advancements have certainly made reliable high-performance
infrastructure more accessible, they have also added an ad-
ditional layer of complexity. Heterogeneous cloud portfolio
management, where the virtual machines are purchased from
different marketspaces, is now concerned with the challenging
task of ﬁnding cost-efﬁcient resource allocations for a given
set of applications.

Nowadays, well-known cloud service providers such as
Amazon1 commonly offer three different types of market-
the reserved, on-
places for computational resources,
demand and spot marketspace. The reserved instance type

i.e.

1https://aws.amazon.com/de/ec2/

offers steep discounts, but also requires longer-term commit-
ments, as they must be purchased by the client for a prede-
ﬁned time period. On-demand instances, on the other hand,
are characterized by their ﬂexibility since providers usually
employ a pay-per-use billing method for this type of service.
This ﬂexibility, however, incurs a higher price in comparison
to the other types. Finally, on the spot marketplace one can
ﬁnd excess compute resources that are heavily discounted.
However, instances of this type may be revoked at the service
provider’s discretion and are therefore only suitable for highly
fault-tolerant workloads.

The heterogeneous nature of cloud markets is not the only
complexity driver for this cost optimization problem. An
aspect not to be neglected is the fact that applications typically
are time-bound. That is, a cost-efﬁcient resource allocation
must be found over a longer temporal horizon and not only
for a single point in time. Furthermore, applications rarely
show a constant resource requirement. It is more common that
workloads experience periods of high as well as low demands.
To our knowledge, scientiﬁc literature does not yet provide a
cloud portfolio optimization model that combines the concepts
of heterogeneous marketplaces, variable resource demands, as
well as the temporal character of workloads. However, all three
aspects can be considered to be of integral importance to a
realistic depiction of the problem, as well as any derived cost-
optimization approach. Thus, with this paper we contribute to
this ﬁeld by

(i) establishing a formal problem speciﬁcation that incor-
porates the aforementioned relevant features of cloud
portfolio management, and by

(ii) proposing and evaluating two distinct optimization
heuristics for creating cost-efﬁcient portfolio allocations.

The paper at hand is part of our research on an autonomous
Cloud Portfolio Manager as depicted in ﬁgure 1. It is an entity
that creates for a bundle of requested resources an optimal
cloud portfolio by purchasing them from different providers
as well as marketspaces. A precondition for creating such
an overarching system is the determination of appropriate

 
 
 
 
 
 
algorithms for creating cloud portfolios. Hence, in this paper
we analyze two different cloud portfolio algorithms.

Fig. 1: Portfolio manager creating optimal cloud portfolios
by purchasing resources from different providers and mar-
ketspaces

The structure of the paper is as follows: In section II we give
an overview of related work. Section III is lays out the exact
mathematical model for the problem formulation. Section IV
presents the two novel algorithmic optimization heuristics, and
in section V the results of the empirical evaluation are outlined.
The conclusions of the research work and future directions are
discussed in section VI.

II. STATE OF THE ART
One of the key challenges of cloud portfolio management
is the heterogeneous nature of the relevant marketspaces. In
literature the spot market has received comparatively more
research attention than the on-demand and reserved ones. This
can be attributed to the fact that, depending on the respective
cloud service provider, spot instances can offer signiﬁcant
optimization potential, due to their unique and dynamic pricing
mechanisms. Sharma et al., for instance, focused on preemtible
servers and utilized concepts from the domain of ﬁnancial
modelling to construct cost-efﬁcient cloud portfolios while
also adhering to the speciﬁc requirements of the applications
that needed to be served [1]. However, since spot instances
are preemptible they require special mitigation procedures to
avoid the loss of data upon sudden revocation. Jangjaimon
and Tzeng tried to address this problem by proposing a
sophisticated checkpointing mechanism [2]. The process of
checkpointing, i.e. regularly persisting a recoverable state for
computational workloads,
is quite common when working
with transient cloud servers, as also pointed out by Tang et
al. In their work the authors propose a biding strategy for
spot instances based on the concepts of a constrained Markov
decision process. Their research focused on the EC2 Spot
market of Amazon Web Services (AWS) and aimed to provide
a balanced approach between cost-optimization and revoca-
tion mitigation [3]. However, as mentioned by Baughman et
al., AWS revised the pricing mechanism of its preemptible
servers in 2017. The currently active schema makes prices
less volatile, meaning that instead of having high price peaks
according to the ﬂuctuating supply and demand, the curve is
now ﬂattened [4]. Based on this overhauled pricing mechanism
of EC2 spot instances, Zhou et al. developed a long-term price
prediction and dynamic task reallocation system. However,

their scheduling system again only focuses on the spot market
and does not take into account a heterogeneous cloud portfolio
[5].

Mireslami et al., on the other hand, incorporated on-demand
and reserved instances in their provisioning approach. How-
ever, besides the fact that the authors did not consider the
spot market, their model also lacks a sophisticated tempo-
ral component and thus is not suitable for long-term task
scheduling [6]. Li et al. do include time-bound constraints in
their dynamic bin packing approach, however, while they do
assume that the size of an item may vary from one to another,
they do not model the capacity requirements as a random
variable. Furthermore, they also do not fully incorporate the
heterogeneous nature of cloud markets [7]. Nodari et al.
also do not pay attention to the spot market, but
instead
put an emphasis on reserved and on-demand instances in
their stochastic model, to which they apply the concepts of
inventory theory [8]. In the research of Haussmann et al. a
cost model was presented that incorporated volatile as well as
secure instance types. Their research showed that preemptible
spot instances can contribute to signiﬁcantly lower cost in the
domain of high performance parallel computing [9]. However,
while their model does consider varying execution times, it too
is not suitable for long-term job scheduling. Alenizi et al. try
to capture the time-bounded nature of workﬂows by making
the remaining expected execution time an integral part of their
model. Their approach, however, again only considers reserved
and on-demand instances. Further, it also does not consider
various starting times of workﬂows and thus is more geared
towards dynamic ad hoc resource allocations [10]. Shen et al.
do consider separate arrival and departure times for workﬂows
in their job scheduling model, but also do not incorporate
all three of the aforementioned cloud markets. Further, their
integer programming problem formulation only considers non-
ﬂuctuating resource demands for the individual workﬂows
[11]. A more holistic approach to cloud portfolio management
was taken by Pittl et al., who showed that heterogeneous
portfolios tend to be more cost-efﬁcient. Furthermore, they
also pointed out
the importance of right-sizing the server
instances to the capacity requirements of the workloads [12].
The task of right-sizing is also highly relevant to the closely-
related domain of energy-efﬁcient data center operations. For
this ﬁeld Hwang and Pedram proposed a portfolio-based
optimization approach with a probabilistic model, where the
assigned workloads have resource demands that are charac-
terised by a normal distribution [13]. Martinovic et al. also
use a problem formulation based on probabilities rather than
deterministic aspects. They then applied a stochastic bin pack-
ing approach to ﬁnd efﬁcient server allocations [14]. Fatima et
al. evaluated a particle swarm optimization algorithm against
other approaches in a scenario where the server capacities
are assumed to be variable [15]. Wu et al., on the other
hand, used a more traditional genetic algorithm concept in
their proposed solution for physical and virtual server instance
consolidation [16]. De Cauwer et al. assumed deterministic
resource demands for their tasks, which arguably is a less

plausible depiction of reality. However, they also introduced
a temporal component to their problem formulation. Instead
of simply ﬁnding efﬁcient server consolidation schemes for
a single point in time, they added time as another resource
dimensions. This better captures the true nature of many
computational workloads, which often do not run indeﬁnitely,
but rather have a predeﬁned lifespan [17].

As has been shown, while one can ﬁnd extensive research
on the subject of cloud cost optimization, very little work has
been done on long-term allocations. Long-term cost-efﬁcient
cloud portfolio management does require to put an emphasis
on the temporal component that is inherent to such a problem.
Some research tries to capture this time-bound characteristic
[7], [9]–[11], [17], however, to the best of our knowledge
their scientiﬁc literature does not yet provide optimization
approaches that adequately capture this constraint, while also
incorporating the heterogeneous nature of cloud markets. As
mentioned,
the research by Pittl et al. performs a more
holistic analysis of resource management, i.e. procurement
options from reserved, on-demand as well as spot markets are
considered, but it can be argued that it does not appropriately
address the uncertain nature of capacity demands [12]. As
pointed out, researcher that already previously incorporated
stochastic problem formulations in their models [8], [14], is
not suited for the task of long-term resource allocations in
heterogeneous cloud market environments.

Based on our past research on resource optimization tech-
niques [18], [19] and cloud market analysis [20], [21] we
try to close this gap. That is, our model not only considers
reserved, on-demand and spot instances, it also puts an em-
phasis on long-term resource allocations. The proposed model
and the derived optimization approaches support ﬁne-grained
task scheduling over a longer planning horizon, which allows
to properly make use of reserved instances. Furthermore, our
application driven approach is based on the assumption of
uncertain resource requirements and thus also adds a stochastic
notion to the problem formulation.

III. PROBLEM FORMULATION

The problem formulation for cost-efﬁcient cloud portfolio
management presented in this section uses the notation as
deﬁned in table I.

In the scope of this work a cloud portfolio is deﬁned as
a set of cloud instances I that are necessary to host a set
of applications A. The optimization problem,
is
then concerned with ﬁnding a cost-efﬁcient allocation of these
applications and instances.

in short,

Applications running in the cloud are typically charac-
terized by their resource demands. Following the proposed
approach of Hwang and Pedram these capacity requirements
are assumed to be ﬂuctuating and are therefore represented
by an expected demand mean µa and corresponding standard
deviation σa [13]. Furthermore, it is assumed that workloads
have varying life spans, which is denoted by the starting
time Sa and ﬁnishing time Fa of an application. Note that
Sa < Fa must apply. Since spot instances are only suitable

TABLE I: Notation for Problem Formulation

Parameter

Description

I
A
T
xait
Sa
Fa
Ua
µa
σa
Ri
Ci
Bi
Ei
Oi
Dit
Qmin

A set of selected cloud instances (hosts)
A set of applications
A set of time slots for which to optimize
Variable denoting assignments of apps to instances
The starting time of app a
The ﬁnishing time of app a
Indicates if app a is preemptible
The expected resource demand of app a
The std. deviation of the resource demand of app a
The resource capacity of instance i
The cost of instance i for one time slot
The ﬁrst available time slot of an instance
The last available time slot of an instance
Marks instances as suitable for non-preemptible apps
Aggregated resource demand of instance i at time t
The desired quality of service

for very fault-tolerant processes, the binary variable Ua is used
to denote whether or not an application can be assigned to such
a preemptible server instance.

Ua =

(cid:40)

1
0

if a is preemptible
else

(1)

An instance i ∈ I has a predeﬁned resource capacity Ri
(e.g. CPU, RAM). Moreover, each type of instance is also
associated with a certain price per time unit Ci. The total cost
incurred by a single host is based on the price per time slot
and the overall up-time. The up-time of an instance is given
by its starting time Bi and ending time Ei, where Bi < Ei
again must hold true. To denote if an instance is considered to
be a spot (preemptible) type, the binary parameter Oi is used.

Oi =

(cid:40)
1
0

if i is only suitable for preemptible apps
else

(2)

The aggregated demand of all applications assigned to
instance i ∈ I at time slot t ∈ T is represented by the
parameter Dit. This aggregated demand is also a random
variable and thus one can only evaluate the probability with
which an instance stays within the designated capacity limits.
The proposed model assumes that one can specify a desired
minimum quality of service, denoted by Qmin. In case the
probability that the aggregated demand Dit stays below the
provided capacity of the instance Ri does not satisfy the
minimum quality of service Qmin for time slot t, then the
allocation is invalid.

To formally model the application and instance assignments,
while also considering the temporal restrictions of the problem,
the approach suggested by Dell’Amico et al. is used. The
variable x denotes which hosting instance an application has

been assigned to at a speciﬁc point in time. The resource
demands of an application a ∈ A are considered to be 0 for
any time slot t ∈ T if t < Sa or t > Fa [22].

xait =

(cid:40)

1
0

if a is assigned to i at time slot t
else

(3)

The cloud portfolio management problem can now be

deﬁned as follows:

min

(cid:88)

i∈I

Ci ∗ (Ei − Bi)

(4)

s.t.

(cid:88)

i∈I
(cid:88)

xait = 1

∀a ∈ A, ∀t ∈ [Sa, Fa]

(5)

xait ∗ Ua ≥ Oi

∀a ∈ A, ∀t ∈ [Sa, Fa]

(6)

i∈I
P (Dit < Ri) ≥ Qmin
xait ∈ {0, 1}
Ua ∈ {0, 1}
Oi ∈ {0, 1}
Qmin ∈ [0, 1]

∀i ∈ I, ∀t ∈ [Bi, Ei]

(7)

(8)

(9)

(10)

(11)

Constraint 5 states that the optimization approach needs to
assign each application to an instance. At any given point
in the up-time of an application, only one instance can be
the dedicated host. Constraint 6 requires the selected host
to be from a suitable marketspace. Furthermore, equation 7
stipulates that for each time slot an instance is active, the
probability that the resource demand stays within the capacity
limits of the respective instance is at least the predeﬁned
quality of service. This constraint is based on the approach
proposed by Hwang and Pedram [13] and assumes applications
with load proﬁles that do not show any correlation and have
a normal distribution. With constraints 8 to 11 the auxiliary
variables are bound to a valid range.

IV. OPTIMIZATION APPROACHES

The cloud portfolio optimization problem, as modeled in
section III, is in essence a multi-dimensional packing problem.
Such problems are NP-hard and thus complex to solve [23].
While exact algorithms for much simpler variations of the bin
packing problem have been proposed in literature - for instance
by Martello and Vigo [24] - a complete enumeration of all
possible solutions is often not computationally feasible. Hence,
in this work we present two distinct optimization heuristics,
which try to ﬁnd good approximations of optimal solutions.

A. The Greedy Optimization Approach

The ﬁrst of the two presented optimization heuristics in-
corporates principles from the well-known ﬁrst ﬁt decreasing
(FFD) approach [25], as well as the proposed portfolio man-
agement strategy by Hwang and Pedram [13]. The algorithm
outlined in the following, which has been named Efﬁcient

Resource Inference for Cloud Hosting (ERICH), consists of
4 stages:

Stage 1: The algorithm expects sets of preemptible and
non-preemptible applications, as well as all possible instance
types from the three respective marketspaces as input. In
the initialization phase applications are sorted according to
increasing starting dates and non-increasing resource demand
standard deviations. This is based on the proposed idea by
Hwang and Pedram, who suggested that grouping together
workloads with similar resource demand deviation may lead to
overall reduced capacity needs [13]. Furthermore, the various
instance types are sorted by cost per time slot for the provided
capacity in an increasing order, ensuring that the algorithm
chooses cost-efﬁcient hosts ﬁrst.

Stage 2: According to the ﬁrst ﬁt decreasing approach,
the algorithm tries to ﬁt all non-preemptible applications into
reserved instances. For each application, it is ﬁrst checked
if a suitable host, i.e. one covering the entire life cycle of
the application while also providing the required capacity,
already exists in the constructed portfolio. If it does, then the
application is assigned to said instance. In case no candidate
host exists, a new one is allocated based off the ﬁrst instance
type satisfying the application’s requirements.

Stage 3: Although reserved instances usually provide steep
discounts compared to the on-demand marketspace, the fact
that they have a minimum allocation period means that stage
2 may result
in a cost-inefﬁcient portfolio. To achieve a
potentially higher packing density the algorithm iterates over
each allocated reserved instance. During each iteration, a new
temporary portfolio without the respective reserved instance
is created. Applications from the removed reserved host are
then assigned to on-demand instances following the same ﬁrst
ﬁt decreasing approach as described in stage 2. If the newly
created portfolio is more cost efﬁcient, than it replaces the old
one in the next iteration.

Stage 4: In the ﬁnal step, the algorithm is concerned with
ﬁnding well-ﬁtting allocations for all preemptible applications.
Preemptible workloads may be assigned to multiple hosts
during their life cycle, which is why the optimization approach
allocates these applications not as a whole, but rather on a
individual time slot basis. That is, the algorithm ﬁrst ﬁnds
all time steps for which a suitable candidate hosts exists and
assigns the app to these instances for the respective periods. In
case there are still some assignment gaps in the schedule of the
workload the algorithm proceeds with allocating new instances
from the input set of spot hosts. This approach ensures that
preemptible applications ﬁll up any left-over capacity before
new bins are opened. When following these scheme one may
need to consider if the applications require a checkpointing
mechanism similar to what has been discussed in related
literature [2], [3].

Algorithm 2 outlines the above described approach in a
condensed form. The evaluation whether or not an application
ﬁts into an instance is performed based on equation 7.

Algorithm 1: Efﬁcient Resource Inference for Cloud
Hosting
Input: A set of non-preemptible apps A1; A set of

Algorithm 2: Genetic Optimization of Resource
Groupings
Input: A set of non-preemptible apps A1; A set of

preemptible apps A2; A set of reserved instance
types RES; A set of on-demand instance types
ON ; A set of spot instance types SP OT

preemptible apps A2; A set of reserved instance
types RES; A set of on-demand instance types
ON ; A set of spot instance types SP OT

Result: Packing pattern portf olio
sort applications A1 and A2 by increasing start time
and non-increasing σa
sort RES, ON and SP OT by increasing Ci per Ri
and time slot
portf olio ← empty allocation variable
forall a ∈ A1 do

assign a to portf olio (FFD) while only
considering RES instances

end
forall i ∈ reserved instances from portf olio do

tmp portf olio ← copy of portf olio without
instance i
forall a ∈ i do

reinsert a into tmp portf olio (FFD) including
ON instances

end
if total cost of tmp portf olio < total cost of
portf olio then

portf olio ← tmp portf olio

end

end
forall a ∈ A2 do

assign a to portf olio without allocating new
instances
gaps ← consecutive time slots where a is not yet
assigned to portf olio
forall gap ∈ gaps do

assign a to portf olio for time slots in gap by
allocating SP OT hosts

end

end

Fig. 2: Greedy Algorithm ERICH

B. The Evolutionary Optimization Approach

The application of genetic algorithms (GA) to bin packing
scenarios is not a new notion. In fact, GAs have proven to be
well suited to tackle the complex nature of such combinatorial
optimization problems [26]–[29]. Their ﬂexible framework
built around genetic operators that can be adapted to the
problem at hand means that GAs allow for a very efﬁcient and
targeted search in the problem space. The algorithm presented
here has been named Genetic Optimization of Resource Group-
ings (GEORG). In the following its most essential building
blocks and genetic operators are presented.

Encoding Scheme: For bin packing problems the grouping
of items and their respective bins is an essential piece of
information, which is also relevant to the individual genetic

Result: List of packing patterns (portfolios)

population

population ← use semi-random heuristic to create
initial population
while termination criteria are not met do

parents ← ﬁtness-based selection of individuals
from population
of f spring ← apply temporal biased crossover for
each tuple in parents
of f spring ← repair broken chromosomes in
of f spring after crossover
of f spring ← apply domination mutation operator
to random of f spring
of f spring ← repair broken chromosomes in
of f spring after mutation
population ← ﬁtness-based merge of of f spring
and current population

end

Fig. 3: Genetic Algorithm GEORG

operators of a GA [27]. Falkenauer has proposed an encoding
scheme, in which the chromosome is an array of bins, each
holding a set of items. However, this approach is not well
suited for the temporal component of the problem speciﬁca-
tion. Thus, we propose a temporal group encoding, in which
each locus of the chromosome corresponds to a speciﬁc time
step, with the allele being a set of instances running at the
respective point in time. Every host is then mapped to a set
of applications, which are assigned to the respective instance
at this time slot.

Population Initialization: To ensure a high degree of
genetic diversity while also providing initial individuals with
comparatively high ﬁtness, a hybrid approach is taken for the
creation of an initial set of solutions. Fifty percent of the time
applications are assigned in a manner that reduces the number
of allocated instances and therefore the overall cost. In the
remaining cases, the assignment is at random.

Fitness Evaluation: To evaluate the ﬁtness of an individual,

i.e. the quality of a solution, equation 4 is used.

Crossover: In each generation a group of individuals is
selected based on the ﬁtness proportionate roulette wheel
method. The crossover is then applied to a set of two in-
dividuals (parents) in order to yield a new offspring. We
propose a biased temporal crossover operator that is built on
the concepts presented by Quiroz-Castellanos et al. [28] and
promotes the transmission of well-ﬁtting genetic material to
the next generation. For each time step (gene), active instances
are sorted in decreasing order based on their average rate of

capacity utilization and cost per time slot. A partial solution
is created by zip-merging the instances of both parents. The
ranked partial solution is pruned by eliminating hosts of
already assigned applications. Instances that result in packing
patterns violating the constraints of the problem formulation
are ignored in the crossover process of further time steps.
The culling of instances may break the chromosome, since
applications may end up being partially or fully without
any host assignments. To repair the chromosome, a simple
heuristic is applied to reinsert any applications that are now
considered to be free.

Mutation: The mutation operator is applied to newly cre-
ated offspring at random. Its goal is to introduce new genetic
characteristics to individuals of the population, while also
following a targeted approach to enhance the overall ﬁtness.
Martello and Toth [30] introduced the concept of dominance,
which can be used to replace a subset of items with an
item of larger or equal size. This approach has already been
employed in the context of genetic algorithms by other re-
searchers [27], [28]. As Quiroz-Castellanos et al. also pointed
out, the ﬂexibility gained by only having to reinsert smaller
items can ultimately lead to a tighter packing pattern and an
overall better solution. Since random chance determines which
items are initially chosen to perform a dominance check, the
design allows for the introduction of new variations of genetic
material, while also potentially improving the already existing
solution [28].

The deﬁnition of the dominance criterion needs to be
slightly adapted to be applied to the cloud portfolio optimiza-
tion problem with its temporal component. Furthermore, in-
stead of comparing entire allocations, i.e. instances, with each
other, the dominance deﬁnition used in the following focuses
on the application level. An application a that is intended to
be hosted by instance i ∈ I for the time slots [Sd, Fd] is
said to dominate a partition of apps P from instance i if the
time span denoted by [Sd, Fd] encompasses all assignments
slots of the partition for the respective host. Furthermore, the
expected resource demands of the dominating application must
be greater than the aggregated capacity requirements of all
elements of the dominated partition. In fact, the probability
that the resource demands of the dominating app exceed those
of the dominated workloads must be greater than ﬁfty percent.
The depictions in ﬁgure 4 and 5 show the application level
resource requirements over a horizon of three time steps. The
bold lines indicate the expected resource demands, while the
dotted ones showcase the deviations.

Figure 4 depicts a set of three applications and a set of
three partitions. Each individual application in A2 dominates
the respective partition of A1 in the same color. The above
listed criteria for dominance are fulﬁlled in all dimensions,
i.e. capacity and time. For instance, application i1 clearly has
a higher expected resource demand than partition p1. At the
same time, i1 also dominates p1 in the temporal dimension.
The application i2 matches the starting and ﬁnishing times of
partition p2 exactly. This is in accordance with the temporal
dominance criterion. It further also has a higher expected

Fig. 4: Fulﬁlled Temporal Dominance Criterion

Note. Figure inspired by Falkenauer.

resource demand and thus it can be said that i2 dominates p2.
The partition p3 consists of two applications, with a combined
expected resource demand that is less than that of i3. Since
i3 also covers at least the same time slots as p3 it can be
said that i3 dominates p3. The mutation operator now could
replace one of the dominated partitions and yield a tighter
packing pattern. Figure 5 shows a scenario, in which non of
the selected applications dominates any partition. For instance,
while i1 certainly has a higher expected resource demand,
it does not cover the entire live span of partition p1. On
the other hand i2 may cover the same time period as p2,
but has the same expected resource demands. Hence, it too
cannot be considered as a dominating application. In the case
of application i3, the deviations from the expected capacity
requirements are signiﬁcant. Therefore, the probability that i3
experiences higher resource demands than what is the expected
aggregated distribution for partition p3 is quite low. Besides,
the temporal constraints is not satisﬁed either, which means
that i3 cannot be considered to dominate p3.

Fig. 5: Unfulﬁlled Temporal Dominance Criterion

Note. Figure inspired by Falkenauer.

The temporal dominance criterion is checked against parti-
tions of applications of size two for the respective candidate
instance, as otherwise the computational efforts might become

unfeasible [28]. In case the dominance criterion holds true, the
unassigned application is swapped with the partition. Similar
to the crossover operator, this procedure may leave certain
applications unassigned, meaning that
the chromosome no
longer represents a valid solution. In such a case the same
aforementioned insertion heuristic is now again used to repair
the corrupted individual, as otherwise the genetic algorithm
would not be able to continue its process.

Insertion Heuristic: Equation 5 of the problem speciﬁca-
tion essentially requires that each application must be assigned
an appropriate host for all relevant time slots. During the
crossover and mutation processes this constraint might end up
being violated, resulting in a broken chromosome. Preemptible
applications might have multiple gaps in their packing pattern,
where no valid assignment
the
insertion heuristic follows a naive ﬁrst-ﬁt approach, where for
each assignment gap of an orphaned application a candidate
instance from the existing chromosome is selected. If no
candidate host exists, then a new random instance is created to
host the respective application. The component of randomness
to this rather simple heuristic is intended to mitigate the risk
of premature converges on local optima by ensuring that the
genetic diversity is kept at an adequate level.

is available. In any case,

Termination: Commonly encountered stopping criteria can
be employed, such as a maximum number of processed gener-
ations or a certain threshold when it comes to the convergence
level of the ﬁtness scores among individuals in the population
[31].

V. EVALUATION

The proposed optimization heuristics have been empirically
evaluated with synthetic data. The algorithms were imple-
mented using Python 3.9 and the tests were run on a Windows
machine with an Intel Core i7-4770 processor (3.4 GHz base
clock, 3.9 GHz turbo) and 16 GB of DDR3 memory at 1600
MHz.

A. Data Set Description

With the problem at hand, there are multiple dimensions
which contribute to the difﬁculty of a particular test set. As is
usually the case for bin packing optimization algorithms, the
greater the number of items to be assigned the more challeng-
ing a task becomes. However, due to the temporal component
of the problem formulation the number of allocation periods
for which to ﬁnd suitable assignments must not be neglected.
It was therefore thought to be imperative that the variety in
the data reﬂects these difﬁculty attributes.

While the data was synthetically created, careful attention
was paid to crafting realistic scenarios. That is, the expected
price discounts for spot and reserved instances relative to
on-demand ones are based on real-world observations. Fur-
thermore, the price to capacity relations are also modeled
according to commonly encountered offerings of popular
cloud service providers. Table II summarizes the key resource
demand and allocation characteristics of the application data
sets. Note that the columns Non-pre. and Pre. list the number

TABLE II: Summary of Application Data Sets

App.
Set

apps 1
apps 2
apps 3
apps 4
apps 5
apps 6

Non-
Pre.

Pre. Avg.
Res.
Dem.

Std.
Res.
Dem.

Avg.
Res.
Dev.

14
59
10
42
7
41

6
41
10
58
13
59

3.27
3.0
3.02
3.1
3.12
2.78

1.71
2.62
2.01
2.57
2.69
1.97

0.53
0.53
0.71
0.5
0.6
0.49

Std.
Res.
Dev.

0.48
0.74
0.63
0.59
0.56
0.57

Avg.
Alloc.
Periods

43.15
63.93
212.2
237.16
2758.55
2871.74

Std.
Alloc.
Periods

33.4
43.94
167.88
171.57
1996.98
2055.67

of non-preemptible and preemptible applications that each data
set holds. The table further describes the expected average
resource demands (Avg. Res. Dem.) as well as the deviations
from this average within the data set (Std. Res. Dem.). More-
over, the column Avg. Res. Dev. highlights the mean resource
demand deviations that are assumed for applications. With
column Std. Res. Dev. the ﬂuctuations of these deviations
within the data set are described. Furthermore, table II also
lists the average allocation periods.

These samples were combined with the instance type data
sets described in table III. Each instance type data set in-
cluded ﬁve hundred different types from which the algorithms
could choose. Table III describes the mean capacities of the
instance types, as well as the average prices per market
the high deviations of
to note that
space. It
the cost levels highlight the great price diversity found in
the data sets. The following six unique test cases were cre-
ated: case 1 (apps 1, types 1), case 2 (apps 2, types 1),
case 3 (apps 3, types 2), case 4 (apps 4, types 2), case 5
(apps 5, types 3) and case 6 (apps 6, types 3). The full
data sets are available publicly2.

is important

TABLE III: Summary of Instance Type Data Sets

Instance
Type
Set

Avg.
Cap.

Std.
Cap.

types 1
types 2
types 3

9.60
10.32
9.79

8.77
11.40
9.91

Avg.
Res.
Prc.

2.27
2.16
2.41

Std.
Res.
Prc.

2.85
2.38
3.80

Avg.
On.
Prc.

3.10
3.13
3.10

Std.
On.
Prc.

2.16
2.57
2.41

Avg.
Spot
Prc.

2.53
3.15
2.33

Std.
Spot
Prc.

2.21
4.84
1.74

B. Results

The evaluation was conducted with three quality criteria in
mind, i.e. execution speed, packing density and overall cost of
the constructed cloud portfolios. In the following the results
are discussed.

Since wall clock time was chosen as the evaluation metric
the test cases for the evaluation of the execution speeds were
run a total of 10 times to eliminate any potential side effects

2https://gitlab.com/MFJK/optimization-heuristics-for-cost-efﬁcient-cloud-

resource-allocations

of background tasks. As can be seen in ﬁgure 6, the execution
speeds for the greedy optimization approach ERICH was
signiﬁcantly better across the board. Its deterministic character
resulted in more or less static runtime performance. The little
variations in the execution speeds can be explained by the
expected noise caused by various background tasks on the
host machine.

Fig. 7: Execution Speed GEORG

Another relevant performance indicator for the proposed
optimization heuristics is the packing density. In this work the
utilization rate of an instance is deﬁned as the total expected
resource demand of all assigned applications over the relevant
time slots, relative to the absolute capacity provided for the
same time period. The results shown in ﬁgure 8 clearly show
the dominance of ERICH over GEORG in terms of the average
packing density of the allocation instances. It is important to
note that the deﬁnition of the utilization rate focuses solely on
the expected resource demands of the individual applications.
The resource demand deviations relevant
to the proposed
stochastic component of the model are not included in this
metric. Therefore, the yield packing density can be considered
adequately high.

Fig. 8: Instance Utilization Rates

Figure 9 depicts the data for the weighted utilization rate.
Instead of simply taking the average utilization rate over all
instances within a portfolio, this metric puts an emphasis on
those instances with longer allocation periods. The higher the

Fig. 6: Execution Speed ERICH

However, the execution speed of the GA, which can be seen
in ﬁgure 7, has proven to be highly volatile, which can be
attributed to the fact that the individual genetic operators are
heavily inﬂuenced by randomness. Furthermore, the overall
runtime for each individual test case is signiﬁcantly higher
than the corresponding evaluation result for ERICH. The
processing time required by GEORG is at times more than
ﬁve-fold higher. The most signiﬁcant factor that contributes to
this is likely the crossover operator described. The temporal
component of the problem speciﬁcation requires a substantial
amount of evaluations to be performed to yield a single
offspring. Furthermore,
the
crossover results in certain applications not being assigned to
any hosts, in which case the insertion heuristic has to reinsert
these applications. The same reasoning can be applied to the
mutation operator.

it can easily be the case that

However, while the execution speed certainly is an in-
teresting evaluation criterion, especially in the context of
bin packing heuristics,
it cannot be considered the single
most important quality aspect. In fact, since the focus of
this research lies on ﬁnding cost-efﬁcient long-term cloud
resource assignments it is not expected that the presented
approaches are applied in dynamic reallocation scenario. That
is, the heuristics are best suited to assist the decision process
when initially setting up a portfolio of cloud instances for
a given set of applications. Since no continuous monitoring
and optimization of resource usage patterns are required, the
execution speeds can be considered to be of lesser relevance.
Important is that the problem space is broadly explored.

number of time slots for which an instance is assigned to the
portfolio, the more it contributes to the overall utilization rate.
However, the conclusion that the greedy optimization approach
yields tighter-packed portfolios remains unchallenged.

Fig. 9: Weighted Instance Utilization Rates

Figure 10 depicts the overall performance of the algorithms
in terms of the cost incurred by the resulting packing patterns.
Note that the graph shows the results on a logarithmic scale.
What can be seen is that ERICH, similar to the analysis of the
execution speeds and packing density, outperforms the genetic
algorithm substantially in each and every of the evaluated
test cases. However, the variance within the population of the
genetic algorithm is quite high, indicating that the problem
space is actually searched rather broadly. Nonetheless, the
much simpler approach of the greedy bin packing algorithm
shows to be better suited for the evaluated test cases. This
can likely be explained by the fact that it acts more target
driven in its search for cost-efﬁcient instance types. For the
GA, in order to preserve the genetic diversity, a less direct
approach was chosen. The crossover operator does not per se
assign new instances. Rather, it serves as a smart selection
mechanism, merging well-ﬁtting allocations from individuals.
New instances are allocated by the insertion heuristic, which is
applied to repair broken chromosome. This mechanism, how-
ever, relies on a simple semi-random ﬁrst ﬁt decreasing logic
and is not geared towards selecting cost-efﬁcient instances.

However, that is not to say that the GA did not work as
intended. Figure 11 depicts the ﬁtness level over multiple
generations for the data set case 6. Starting from an initial
population (generation 0) with a very high degree of genetic
diversity, the average ﬁtness score continuously improves as
the generations progress. In the end, the average cost has been
cut by more than half by the time generation 10 has been
processed. As has been shown in section II related work in the
ﬁeld of cloud cost optimization often operates under drastically
different assumptions. Therefore, the proposed algorithms are
not compared to already existing approaches. Instead,
the
initial population of the genetic algorithm serves as a baseline

Fig. 10: Overall Portfolio Cost

comparison for the quality of the yielded solutions of both
heuristics. As mentioned, the GA’s population uses a semi-
random ﬁrst ﬁt mechanism for ﬁnding allocations. Since both
algorithms produce results with notably lower costs compared
to the initial population, it can be said that either approach
signiﬁcantly improves upon the solutions one would yield from
such simple and unplanned allocations of resources.

Fig. 11: Cost per Generation for Data Set case 6

VI. CONCLUSION

In a world where cloud deployment strategies become ever
increasingly popular, ﬁnding cost-efﬁcient resource alloca-
tions is a highly relevant
industry problem. In this paper
we have presented a formal model for the domain of cloud
portfolio management, following an application-centered long-
term optimization approach considering uncertain resource
demands and incorporating heterogeneous marketplaces. The
speciﬁcation falls into the category of bin packing problems
and is characterized by its temporal and stochastic nature. To

the best of our knowledge current literature does not pro-
vide comprehensive solutions to such long-term probabilistic
resource allocation problems. With our research we try to
close this gap, while also providing optimization approaches
employable by those who wish to ﬁnd initial cost-efﬁcient
cloud portfolio allocations over a longer time horizon.

Two distinct optimization heuristics have been developed
for this NP-hard problem, one following a traditional ﬁrst
ﬁt approach, while the other is built on top of the frame-
work of genetic algorithms. The GA uses genetic operators
speciﬁcally adapted to the problem at hand, using a temporal
biased crossover and a mutation procedure that incorporates
a temporal dominance criterion as deﬁned by us. However,
although the genetic algorithm does explore the broad problem
space quite thoroughly, the evaluation has shown that it is
signiﬁcantly outperformed in terms of execution, packing
density and overall cost-efﬁciency.

In future research we plan to extend the problem speciﬁca-
tion and tweak the optimization heuristics. For instance, we
consider it relevant to also look at scenarios where the resource
demand of the applications are correlated. Furthermore, in
future iterations we also intend to incorporate resource demand
load proﬁles for applications that may change over time. That
is, in the current model it is assumed that an application’s
resource demand is characterized by a normal distribution.
More research is necessary to determine the affects on opti-
mization heuristics in case these capacity requirements change
over time.

REFERENCES

[1] P. Sharma, D. Irwin, and P. Shenoy, “Portfolio-driven resource man-
agement for transient cloud servers,” Proceedings of
the ACM on
Measurement and Analysis of Computing Systems, vol. 1, no. 1, pp.
1–23, 2017.

[2] I. Jangjaimon and N.-F. Tzeng, “Effective cost reduction for elastic
clouds under spot instance pricing through adaptive checkpointing,”
IEEE Transactions on Computers, vol. 64, no. 2, pp. 396–409, 2013.

[3] S. Tang, J. Yuan, and X.-Y. Li, “Towards optimal bidding strategy for
amazon ec2 cloud spot instance,” in 2012 IEEE Fifth International
Conference on Cloud Computing.

IEEE, 2012, pp. 91–98.

[4] M. Baughman, S. Caton, C. Haas, R. Chard, R. Wolski, I. Foster,
and K. Chard, “Deconstructing the 2017 changes to AWS spot market
pricing,” in Proceedings of
the 10th Workshop on Scientiﬁc Cloud
Computing, 2019, pp. 19–26.

[5] A. C. Zhou, J. Lao, Z. Ke, Y. Wang, and R. Mao, “Farspot: Optimizing
monetary cost for hpc applications in the cloud spot market,” IEEE
Transactions on Parallel and Distributed Systems, 2021.

[6] S. Mireslami, L. Rakai, M. Wang, and B. H. Far, “Dynamic cloud
resource allocation considering demand uncertainty,” IEEE Transactions
on Cloud Computing, vol. 9, no. 3, pp. 981–994, 2019.

[7] Y. Li, X. Tang, and W. Cai, “Dynamic bin packing for on-demand cloud
resource allocation,” IEEE Transactions on Parallel and Distributed
Systems, vol. 27, no. 1, pp. 157–170, 2015.

[8] A. Nodari, J. K. Nurminen, and C. Fr¨uhwirth, “Inventory theory applied
to cost optimization in cloud computing,” in Proceedings of the 31st
Annual ACM Symposium on Applied Computing, 2016, pp. 470–473.
[9] J. Haussmann, W. Blochinger, and W. Kuechlin, “Cost-optimized parallel
computations using volatile cloud resources,” in International Con-
ference on the Economics of Grids, Clouds, Systems, and Services.
Springer, 2019, pp. 45–53.

[10] A. Alenizi, R. Ammar, R. Elfouly, and M. Alsulami, “Cost minimization
algorithm for provisioning cloud resources,” in 2020 IEEE International
Symposium on Signal Processing and Information Technology (ISSPIT).
IEEE, 2020, pp. 1–6.

[11] S. Shen, K. Deng, A. Iosup, and D. Epema, “Scheduling jobs in the
cloud using on-demand and reserved instances,” in European conference
on parallel processing. Springer, 2013, pp. 242–254.

[12] B. Pittl, W. Mach, and E. Schikuta, “Cost-evaluation of cloud portfolios:

An empirical case study.” in CLOSER, 2019, pp. 132–143.

[13] I. Hwang and M. Pedram, “Portfolio theory-based resource assignment
in a cloud computing system,” in 2012 IEEE Fifth International Con-
ference on Cloud Computing.

IEEE, 2012, pp. 582–589.

[14] J. Martinovic, M. H¨ahnel, W. Dargie, and G. Scheithauer, “A stochastic
bin packing approach for server consolidation with conﬂicts,” in Oper-
ations Research Proceedings 2019. Springer, 2020, pp. 159–165.
[15] A. Fatima, N. Javaid, T. Sultana, W. Hussain, M. Bilal, S. Shabbir,
Y. Asim, M. Akbar, and M. Ilahi, “Virtual machine placement via bin
packing in cloud data centers,” Electronics, vol. 7, no. 12, p. 389, 2018.
[16] G. Wu, M. Tang, Y.-C. Tian, and W. Li, “Energy-efﬁcient virtual ma-
chine placement in data centers by genetic algorithm,” in International
conference on neural information processing. Springer, 2012, pp. 315–
323.

[17] M. De Cauwer, D. Mehta, and B. O’Sullivan, “The temporal bin packing
problem: an application to workload management
in data centres,”
in 2016 IEEE 28th International Conference on Tools with Artiﬁcial
Intelligence (ICTAI).
IEEE, 2016, pp. 157–164.

[18] E. Schikuta, H. Wanek, and I. Ul Haq, “Grid workﬂow optimization
regarding dynamically changing resources and conditions,” Concurrency
and Computation: Practice and Experience, vol. 20, no. 15, pp. 1837–
1849, 2008. [Online]. Available: https://onlinelibrary.wiley.com/doi/abs/
10.1002/cpe.1317

[19] B. Pittl, W. Mach, and E. Schikuta, “A negotiation-based resource
allocation model in iaas-markets,” in 2015 IEEE/ACM 8th International
Conference on Utility and Cloud Computing (UCC), 2015, pp. 55–64.
[20] ——, “Bazaar-extension: A cloudsim extension for simulating negotia-
tion based resource allocations,” in 2016 IEEE International Conference
on Services Computing (SCC), 2016, pp. 427–434.

[21] W. Mach and E. Schikuta, “A generic negotiation and re-negotiation
framework for consumer-provider contracting of web services,” in
Proceedings of
the 14th International Conference on Information
Integration and Web-Based Applications and Services, ser. IIWAS ’12.
New York, NY, USA: Association for Computing Machinery, 2012, p.
348–351. [Online]. Available: https://doi.org/10.1145/2428736.2428800
[22] M. Dell’Amico, F. Furini, and M. Iori, “A branch-and-price algorithm for
the temporal bin packing problem,” Computers & Operations Research,
vol. 114, p. 104825, 2020.

[23] C. Chekuri and S. Khanna, “On multidimensional packing problems,”
SIAM journal on computing, vol. 33, no. 4, pp. 837–851, 2004.
[24] S. Martello and D. Vigo, “Exact solution of the two-dimensional ﬁnite
bin packing problem,” Management science, vol. 44, no. 3, pp. 388–399,
1998.

[25] E. Coffman Jr, M. Garey, and D. Johnson, “Approximation algorithms
for bin packing: A survey,” Approximation algorithms for NP-hard
problems, pp. 46–93, 1996.

[26] C. Reeves, “Hybrid genetic algorithms for bin-packing and related
problems,” Annals of Operations Research, vol. 63, no. 3, pp. 371–396,
1996.

[27] E. Falkenauer, “A hybrid grouping genetic algorithm for bin packing,”

Journal of heuristics, vol. 2, no. 1, pp. 5–30, 1996.

[28] M. Quiroz-Castellanos, L. Cruz-Reyes, J. Torres-Jimenez, C. G´omez,
H. J. F. Huacuja, and A. C. Alvim, “A grouping genetic algorithm with
controlled gene transmission for the bin packing problem,” Computers
& Operations Research, vol. 55, pp. 52–64, 2015.

[29] K. Kang, I. Moon, and H. Wang, “A hybrid genetic algorithm with a
new packing strategy for the three-dimensional bin packing problem,”
Applied Mathematics and Computation, vol. 219, no. 3, pp. 1287–1299,
2012.

[30] S. Martello and P. Toth, “Lower bounds and reduction procedures for
the bin packing problem,” Discrete applied mathematics, vol. 28, no. 1,
pp. 59–70, 1990.

[31] M. Safe, J. Carballido, I. Ponzoni, and N. Brignole, “On stopping
criteria for genetic algorithms,” in Brazilian Symposium on Artiﬁcial
Intelligence. Springer, 2004, pp. 405–413.

