2
2
0
2

y
a
M
7
2

]
E
S
.
s
c
[

1
v
7
3
1
4
1
.
5
0
2
2
:
v
i
X
r
a

Digital Sovereignty and Software Engineering
for the IoT-laden, AI/ML-driven Era

Christian Berger, christian.berger@gu.se

May 30, 2022

Abstract

Today’s software engineering already needs to deal with challenges
originating from the multidisciplinarity that is required to realize IoT
products: Many variants consist of sensor/actuator-powered systems
that already today use AI/ML systems to better cope with the unstruc-
turedness of their intended operational design domain (ODD), while,
at the same time, such systems need to be monitored, diagnosed, main-
tained, and evolved using cloud-powered dashboards and data analyt-
ics pipelines that process, aggregate, and analyze countless data points
preferably in real-time. This position paper discusses selected aspects
related to Digital Sovereignty from a software engineering’s perspec-
tive for the IoT-laden, AI/ML-driven era: While we can undeniably
expect more and more beneﬁts from such solutions, a speciﬁc light
shall be shed in particular on challenges and responsibilities at design-
and operation-time that, at minimum, prepare for and enable or, even
better, preserve and extend digital sovereignty from a software engi-
neering’s perspective.

1

Introduction

Our societies are growingly embracing the beneﬁts and opportunities of
Internet-of-Things (IoT)- and AI/ML-powered aspects of our lives. Visi-
bly are we knowingly dependent on our smartphones to enable a more and
more digitalized lifestyle that is characterized by use cases, which shifted
from pure amusement and entertainment like playing games or watching
movies to seeing beneﬁts from IoT-enabled digital workﬂows for intelligent
power grid management or personalized health advises powered by intelli-
gent wearables for example. However, also invisibly did our societies enrich
our daily life with IoT-powered devices or cyber-physical systems to replace
human workforce in logistics centers by using robot-powered shelves or mon-
itor waste water ﬂows in pipes in metropolitan areas to better plan mainte-
nance activities. We are more and more enjoying the beneﬁts of IoT-devices
and cyber-physical systems powered by growingly complex AI/ML-systems,

1

 
 
 
 
 
 
and can expect an even more prosperous future with further applications
like self-driving vehicles, driverless goods logistics even for the “last mile”,
robotic assistance for care-taking, and further application scenarios that
beneﬁt from connectivity (cf. Giaimo et al., [1], Mallozzi et al., [2]).

2 Today’s Expectations on

Full-Stack IoT-Software Engineers

Today’s software engineers are part of interdisciplinary engineering teams
that design, realize, systematically validate and verify, and operate growingly
complicated solutions for IoT-systems.

An IoT system can be understood as a cyber-
physical system (CPS) that may contain one or
multiple sensors and possibly some actuators to
sense and interact within its operational design do-
main (ODD), while also being (continuously) con-
nected with the Internet and hence, having ac-
cess to computationally and functionally powerful
cloud-backends.

Open vacancy announcements to hire engineers for creating solutions
based on the aforementioned deﬁnition of IoT also emphasize the capability
for the successful candidate to contribute as full-stack software engineer
who not only masters one aspect of the complete system but preferably all
aspects: The user- and IoT-facing cloud front-end, the operational cloud
back-end, and the IoT unit itself, ie., the software stack on a sensor or
robotic unit that may even contain AI/ML-powered components. Already
this high-level description indicates a large variety of methods and tools to:

1. Design, implement, train, and validate the AI/ML-components, and

2. Design, implement, test, package, and deploy a growing amount of

microservices in scalable cloud-environments, and

3. Design, implement, test, package, deploy, and tune embedded software
stacks exploiting silicon-accelerated functionalities–oftentimes under
computational, connectivity, and memory constraints, and

4. Designing, monitoring, automating, and accelerating the necessary en-

gineering pipelines (ie., GitOps) that trigger complex processes:

(a) CI/CD pipelines to integrate and test the software change with
the distributed software stack, including the preparations for tar-
get deployment

2

(b) ML pipelines that evaluate changes in an ML-model’s network
architecture, or in the underlying training and validation datasets
to calculate changes in key performance indicators (KPIs) for the
AI/ML-components

(c) Planning and preparing data-driven experiments that are also
known as continuous experimentation (CX), where the popula-
tion of IoT-unit under monitoring may be split into sub-populations
to systematically evaluate the performance of the latest software
changes (cf. Giaimo and Berger, [3])

The aforementioned items clearly indicate that today’s software engi-
neering challenges to develop and improve IoT-systems are manifold and in
industry oftentimes realized with a broad variety of diﬀerent tools. Using
domain-speciﬁc languages (DSLs) to describe workﬂow steps on a high ab-
straction level to feed tools that deal with the lower level technical complexi-
ties and that automate the artifact transformation processes are unavoidably
necessary. Best practices have in recent years started to emerge even across
industries to exchange ideas, concepts, and process metrics like in Google’s
DORA reports.1

Latest trends for artifact transformation processes are not only focusing
on the data-driven CI/CD aspects but started to also cover growing amounts
of the operational environment. Key ideas therein are infrastructure-as-code
as well as software-deﬁned X (where X can be network, storage, computation,
. . . ) that relate to an increased degree of abstraction to hide hardware intri-
cacies and dependencies. The clear goal is to replace them with software en-
tities that can be captured and described in software artifact transformation
processes to accomplish an even higher level of end-to-end automation from
software change during the development phase to deployment into the tar-
get platforms for the actual operations phase. Companies have realized that
fully formalized, automated, and rapid data-driven CI/CD/CX-pipelines be-
hind GitOps are a key-diﬀerentiating way-of-working that not only sets high
performing companies apart from the average (cf. Google DORA report1),
but that also enables innovation potential and capabilities for future product
enhancements and business opportunities.

3 Upcoming Challenges and Responsibilities for

Full-Stack IoT-Software Engineers

As we have seen in the introduction in Sec. 1, IoT-systems and IoT-powered
solutions growingly permeate our societies and daily lives in visible and in-
visible ways so that we are becoming more and more dependent on their
uninterrupted and fault-tolerant operation. Hence, software engineers do

1Cf. https://www.devops-research.com/research.html

3

not only face today’s challenges from (a) growing functional complexities
motivated by the trend to include AI/ML-components to tackle an ODD’s
unstructuredness, (b) continuous pressure to embrace adaptability in soft-
ware and system architectures (cf. Zavala et al., [4]) motivated by scalability
expectations for large software stacks that shall exploit silicon-powered com-
putation accelerators, and (c) traceable, data-driven validation and veriﬁca-
tion from code changes to explanations for unexpected behavioral patterns
in a system’s ODD.

Software engineers who operate with these aforementioned growingly
software and system architectures, as well as their underlying artifact trans-
formation processes face knowingly and unknowingly design decision that
may impact and constrain future design possibilities in the on-going society’s
digitalization transformation. Hence, the awareness of such impact and con-
straints must be raised–to, at minimum, preserve the space of future design
possibilities, or, even better, extend the possibilities and opportunities while
striving for fair, inclusive, and equal data-driven decision making in both,
products and engineering processes.

Sovereignty originates from the Latin word superanus via the French
word souverainet´e and is literally expressing a power relationship2. Under-
lying ideas have lately been carried over to modern times and found their
way into the Berlin Declaration on Digital Society and Value-Based Digital
Government 3 that state: “Digital sovereignty is key in ensuring the abil-
ity of citizens and public administrations to make decisions and act in a
self-determined manner in the digital world.” Hence, within software engi-
neering, it can be derived:

Dealing with digital sovereignty in software engi-
neering relates to near-term decision making for
products and processes during a software system’s
development as well as its operations that may im-
pact or constrain the long-term self-determinism
of the decision making for this software system.

Based on the aforementioned deﬁnition, a selection of examples are pre-

sented and discussed in the following.

Open Source is a very apparent example that comes to mind when think-
ing about preserving self-determinism of the decision making process for
digital goods. A clear aspect for individuals and corporations relates to
the decision in near-term what type of open source license shall be used as
the variety ranges from permissive to “copy-left”4: Some licenses like MIT
allow not only to take and do with a 3rd party software whatever one is

2Cf. Encyclopedia Britannica, https://www.britannica.com/topic/sovereignty
3Cf. https://ec.europa.eu/newsroom/dae/document.cfm?doc_id=75984
4Cf. https://choosealicense.com

4

preferring, while others like GPL requires changes to be shared back with
the community. Both scenarios may make sense from an individual’s or
corporation’s strategy but clearly constrain the future self-determinism of
the decision making as replacing a 3rd party’s software component later is
causing potentially unwanted eﬀort.

Open Data can be considered as open source software’s sibling. EU’s
Directive 2019/1024 states that “. . . data is open if it can be freely used, re-
used and shared by anyone for any purpose”. Hence, next to the open source
licenses for software, there are licenses for data such as Creative Commons5
that follow a similar spirit as the previous topic.

Data that is used for training an AI/ML component is apparently also
a potential source for constraining the future self-determinism of the deci-
sion making about the own software system as designing unknowingly bi-
ased training and validation datasets, as well as lacking an understanding
about their representativeness and completeness for working with AI/ML-
pipelines: What data is collected and, maybe more important, what data
is not collected? While these aspects are hard problems to describe, model,
and measure, correcting a potentially skewed dataset as well as the AI/ML-
powered IoT-unit based on this later during operations is challenging.

3rd party software components constitute in many software systems to-
day already a signiﬁcant part to avoid re-inventing the wheel and to allow
focusing on the core and diﬀerentiating aspects of a software system. How-
ever, the inclusion of such 3rd party software can take place in various ways:
(a) The external software can simply be linked with the own system as part
of a dependency installation, or (b) it can be included as a traceable soft-
ware asset by code cloning (for instance, copying a header-only C++ library
into the own project), or (c) by re-implementing a required functionality.
The potentially constraining decision in such cases is related to the update
and release frequency of the external software and how this shall be incor-
porated with the own software system: Are there diﬀerent release channels
such as stable and edge available? What are the long-term project vision
and ideas for the external software project? How active, responsive, and
inclusive is the developer community around the external project? How are
vulnerabilities and bugs handled in general?

Cloud infrastructure has already become a diﬀerentiating success factor
for companies to scale depending on varying workloads for web systems for
example. Apparently, outsourcing computing and storage infrastructure to
large cloud operators allows individuals and corporations to focus on core
competencies for the own software systems on the one hand. However, it
is also very clear on the other hand that there is the risk for a tech lock-in
potentially threatening the self-determinism of the decision making in the
long-term when moving from one cloud operator to another or even back

5Cf. https://creativecommons.org/choose/

5

to on premise. This trend is gaining further relevance with the recent rise
of serverless computing where even the cloud operators provide the com-
plete management of the resource provisioning and adaptive scaling so that
software engineers can primarily focus on a system’s functionality without
having to worry what particular virtual machine type or storage backend
needs to be chosen. While this trend is aligning even with infrastructure-
as-code or software-deﬁned X, the possibilities of a cloud operator and its
plans for future adjustments are inﬂuenced by its commercial design drivers,
which potentially constrain the future self-determinism of the own decision
making for the own software system.

Development environments are lately also beneﬁtting from advancements
in AI/ML-assisted coding: While modern integrated development environ-
ments (IDEs) support code completion based on automatically created and
maintained API indexes, recent approaches like GitHub Copilot6 push this
even further to let developers describe in prose (ie., by code comments in
plain English) what is needed in the current part of the source code and
the “AI-pair programmer” is generating the matching and functional code
that is adapted to the syntactical context surrounding the code fragment.
While this appears to be a helpful initiative at ﬁrst sight, there are various
aspects that potentially threaten future self-determinism of the own deci-
sion making for the own software system: (a) On what corpus were such
AI-pair programmers trained in terms of algorithmic design (style, perfor-
mance, legal license), or (b) the increased emphasis to fully understand the
auto-generated code fragments that were generated and included into the
own code base that needs to be maintained in upcoming refactorings, or (c)
the auto-generated code is following a certain implementation design like
functional or imperative programming that may be in conﬂict with the own
design, or (d) the auto-generated code may be even non-optimized and for
resource-constrained IoT environments and such auto-generated fragments
would have to be replaced later to meet realtime constraints.

Digital twins of IoT-units are considered a promising cloud-supported
companion to monitor and diagnose a physical unit such as an IoT-system.
While such digital twins allow for data analysis by using data collected from
the past to be used for AI/ML components, current ideas also consider
digital twins to be part of the functionality of an IoT-unit to, for instance,
conduct “what-if” analyses like cloud-based route planning for self-driving
vehicles by using traﬃc ﬂow information from other self-driving vehicles
nearby. The underlying models for such digital twins are inherently based
either on data collected in the past or by being based on assumptions of
the systems and their operational context. While the former is constrained
by the design decision for its perception system to “understand” an IoT’s
surrounding, the latter may apparently be unknowningly based on false

6Cf. https://copilot.github.com

6

assumptions at design time and hence, potentially limiting the future self-
determinism of the own decision making.

4 Conclusions and Future Research

In this position paper, today’s expectations for software engineers working
with AI/ML-powered IoT-units were described and discussed. Based on the
already demanding expectation on such full-stack IoT-software engineers,
selected upcoming challenges and responsibilities for these full-stack IoT-
software engineers were presented. These examples underlined that aware-
ness for dealing with digital sovereignty in software engineering must be
raised as near-term decision making for these connected, cyber-physical sys-
tems during their development as well as later during their operations may
impact or constrain the long-term self-determinism of the decision making
for such IoT-systems. Hence, future research must focus on methods to ex-
plicate this responsibility for digital sovereignty in software system design
and operations.

References

[1] F. Giaimo, H. Andrade, and C. Berger, “Continuous experimentation
the
and the cyber–physical
Journal of Systems
industrial perspective,”
literature and the
and Software,
[Online]. Available:
p. 110781,
https://www.sciencedirect.com/science/article/pii/S016412122030193X

systems challenge: An overview of

vol. 170,

2020.

[2] P. Mallozzi, P. Pelliccione, A. Knauss, C. Berger, and N. Mohammadiha,
“Autonomous vehicles: state of the art, future trends, and challenges,”
Automotive Systems and Software Engineering, pp. 347–367, 2019.

[3] F. Giaimo and C. Berger, “Continuous Experimentation for Automotive
Software on the Example of a Heavy Commercial Vehicle in Daily
Operation,” in Software Architecture:
14th European Conference,
Italy, September 14–18, 2020, Proceedings.
ECSA 2020, L’Aquila,
Berlin, Heidelberg: Springer-Verlag, 2020, p. 73–88. [Online]. Available:
https://doi.org/10.1007/978-3-030-58923-3 5

[4] E. Zavala, X. Franch, J. Marco, and C. Berger, “Adaptive monitoring
for autonomous vehicles using the haﬂoop architecture,” Enterprise In-
formation Systems, vol. 15, no. 2, pp. 270–298, 2021.

7

