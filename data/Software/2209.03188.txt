2
2
0
2

p
e
S
6

]

R
C
.
s
c
[

1
v
8
8
1
3
0
.
9
0
2
2
:
v
i
X
r
a

Avast-CTU Public CAPE Dataset

Branislav Bošanský1,2, Dominik Kouba2, Ondˇrej Maˇnhal2, Thorsten Sick1,
Viliam Lisý1,2, Jakub Kˇroustek1, Petr Somol1

1Avast Software
{branislav.bosansky, thorsten.sick, viliam.lisy, jakub.kroustek, petr.somol}
@avast.com

2Artiﬁcial Intelligence Center, Dept. of Computer Science,
Faculty of Electrical Engineering, Czech Tecnical University in Prague
{branislav.bosansky, dominik.kouba, ondrej.manhal, viliam.lisy}@fel.cvut.cz

1 Introduction

Millions of new malicious software emerge every day worldwide 1 threatening to compromise consumer
devices, stealing private data, and/or cause ﬁnancial losses 2. These new threats put increasing pressure
on malware-detection software to continuously improve detection capabilities in order to provide
reliable protection to the users.

There is a plethora of methods for detecting malicious samples (e.g., see surveys [19, 13]).
Broadly speaking, we can distinguish two main categories: (1) detecting the samples based on their
static features and (2) detecting the samples based on a behavioral analysis. The static features
typically consist of considering the whole sample (e.g., as an image [9]) and/or properties of its
most important parts (e.g., by examining in details header of a Windows portable executable (PE)
ﬁle) [18]. The behavioral analysis consists of executing (or simulating the execution) of the sample
and logging performed actions in order to determine whether these actions have characteristics of
malicious behavior [13]. The main advantage of the ﬁrst approach is the computational efﬁciency
since extracting static features from the ﬁle itself can be much faster compared to the (simulated)
execution. On the other hand, the main disadvantage of the static approach is the inability to reliably
distinguish malicious samples from benign samples in case the sample is encrypted and/or the clean
ﬁle is altered in a minor way to exhibit malicious behavior. The methods relying on behavioral analysis
can discover malicious behavior even in encrypted samples, however, they require signiﬁcantly more
resources to run or simulate the instructions of the analyzed sample. In either case, the growing
number of new, previously unseen samples makes the usage of automated decision/classiﬁcation
methods of artiﬁcial intelligence (AI) and machine learning (ML) inevitable in the malware-detection
domain.

Framing the problem of malware detection as an AI/ML problem reveals interesting and unique
properties of the domain that are less prevalent in other domains. These properties, among others,
include:

Available at https://github.com/avast/avast-ctu-cape-dataset.
1See, for example, statistics at https://portal.av-atlas.org/malware/statistics
2https://cybersecurityventures.com/hackerpocalypse-cybercrime-report-2016/

1

 
 
 
 
 
 
• the constantly changing distribution of evaluated data – changes are induced by authors of new

benign software as well as active attempts of malware authors to avoid the detection

• noisy and uncertain labels – determining the ground-truth label can be extremely costly in some
cases in time and the required level of expertise of the human analyst performing the evaluation;
therefore, there can be considerable noise in labels in large-scale datasets [7]

• focus on the performance of the classiﬁers under very low false-positive rates [11] – since many
malware-detection systems operate using a layered architecture (e.g., see [17]), a false negative
on one layer can be resolved by a different decision-making module / machine-learning classiﬁer
on a different layer. On the other hand, a false positive is reported immediately. Due to a large
number of clean ﬁles, the false-positive rate of the classiﬁer has to be as low as ≈ 10−4.

The presence of such unique properties of the malware-detection domain from the AI/ML perspective
requires the researchers to focus speciﬁcally on these domains. To do so, it is important to have
enough data that exhibit these unique features and allow researchers to develop and evaluate new
methods that improve the detection capabilities of new models and advance the state of the art.

While several datasets for malware-detection problems were published over the past years [1, 16, 5],
the focus was primarily on static features of malicious samples. Malware-detection datasets focusing
on behavioral data are scarce. A few existing exceptions include a dataset of features extracted from
API Calls [8, 4] or statistics based on the ﬁrst few seconds of execution [15]. However, the existing
dynamic datasets offer only a limited viewpoint on the behavior of the samples. On the other hand,
there are public sandbox projects [12, 2] that create a high-ﬁdelity virtual environment for executing
analyzed samples and as a result, they provide detailed analyses of the execution of the sample,
including a complete tree of spawned processes, all API calls with all parameters, memory dump, etc.
Unfortunately, to the best of our knowledge, there is no such publicly available rich behavioral dataset
of malicious samples. Therefore, our main contribution is collecting and releasing the ﬁrst version of
AVAST-CTU PUBLIC CAPE DATASET consisting of JSON reports produced by CAPEv2 sandbox.

The released dataset contains 48, 976 malicious samples classiﬁed into 10 different malware
families. The majority of the samples were collected mainly throughout the years from 2017 to 2019
and their counts vary in malware-family assignment and time. Such a dataset offers a representative
subsample of actual malware data throughout a longer period of time. It can be used for classical
supervised training of ML models but also for studying changes in data distribution over time (known
as the concept drift), or trying to ﬁnd the least costly parts of the reports to provide sufﬁciently accurate
and robust classiﬁer (e.g., using mainly static features to mimic the performance of the classiﬁer that
also uses behavioral features).

In this paper, we describe the dataset, provided metadata, and give a baseline classiﬁer for

classifying samples into malware families when data are split according to time.

2 CAPEv2 Sandbox

CAPEv2 is an open-source sandbox [2] for execution analysis of samples that started as a fork of
the original Cuckoo sandbox in 2019 and it is still actively developed and maintained at the time of
collecting the reports. It further extends the monitoring and execution capabilities of the Cuckoo
sandbox, including unpacking and/or capturing payload that provides more detailed information
about executed samples and, for example, allows detection based on Yara signatures.

The actual execution of the samples and collection of the reports was performed at the Czech
Technical University in Prague in July and August 2021, we used the recent version of CAPEv2 sandbox
at that time. We ran the collection on 3 separate physical machines, each hosting 4 guest virtual

2

Figure 1: Histogram of months in which the samples in the dataset have been collected for the ﬁrst
time. The ﬁrst month (2017-01) contains also all older samples.

machines that executed malware samples and were monitored by CAPE. These virtual machines were
conﬁgured as follows:

• Windows 7 operating system was installed together with MS Ofﬁce

• the virtual machines were altered to mimic a real personal computer3, hence

– a collection of typical popular applications was installed, including Google Chrome, Firefox,

Adobe Reader, Spotify

– private key was generated and stored in a standard location

– at least one password was stored in Chrome

– a collection of publicly available documents and images were downloaded and stored in

typical locations

– external Internet connection was allowed

3 Data Description

The purpose of the dataset is to allow researchers to work with detailed and rich behavioral data
collected from several malware families over an extended period of time. We ﬁrst describe the
metadata followed by the structure of the samples themselves.

3.1 Metadata

The dataset consists of 48, 976 samples. For each sample, we provide:

• sha256 of the sample for the identiﬁcation,

3Setup was prepared such that it passed Paﬁsh test, https://github.com/a0rtega/pafish.

3

Figure 2: The histogram of sizes (in MBs) of full JSON reports produced by CAPEv2 on samples in our
dataset.

• classiﬁcation to a malware family,

• type of the malware sample,

• date of detection of the ﬁle.

All of them were classiﬁed as malicious, however, they belong to different malware families. Labeling
these samples and assigning a particular malicious PE into a malware family is not an easy task as
some code can be shared by various families thus causing possible noise in labels. According to the
records in Avast systems, the classiﬁcation of these samples into 10 different malware families was as
follows:

Adload
704

Emotet HarHar
14, 429

655

Lokibot
4, 191

njRAT Qakbot
4, 895
3, 372

Swisyn
12, 591

Trickbot Ursnif
1, 343
4, 202

Zeus
2, 594

Table 1: Number of samples in the dataset according to the malware family.

Moreover, the samples are one of 6 types:

"banker", "trojan", "pws", "coinminer", "rat", "keylogger"

The samples were collected mainly throughout the years 2017 and 2019 (see Figure 1 for the histogram
of years and months in which the samples were detected) thus offering a signiﬁcant spread over time
for studying changes in families and the changes in data distribution.

3.2 Dataset

The dataset itself consists of JSON reports produced by the CAPE sandbox. For each analyzed sample,
there is a full JSON report of the CAPE sandbox, stored as a plain JSON in a ﬁle identiﬁed by the
sha256 of the analyzed sample. The full JSON ﬁles contain all gathered information, including all
information about the started processes and system calls, all the generated (dumped) binaries, and
also (if any) existing detections based on YARA language [3].

Although the key purpose for releasing the dataset is to allow AI/ML researchers to develop and
test new methods and classiﬁers, we are not providing any transformation of JSON reports into any
vector representation. The main reason is that there exist methods that can take the JSON as an input

4

without any transformation (e.g., using hierarchical multi-instance learning (HMIL) paradigm [14] or
treating JSONs as text documents [6]). We follow the ﬁrst approach and use HMIL models to train a
classiﬁer that takes JSONs as input.

However, the presence of some keys in the full reports can leak true labels and (e.g., detection
based on YARA) thus invalidate using full reports directly for training ML models. Moreover, the size
of the full reports can be prohibitively large – in a few cases, the size of the full report is more than
800 MBs (see Figure 2 for a full histogram of sizes of full reports).

Therefore, besides the set of full reports, we have also created a set of reduced reports. We generate
these reduced reports by restricting the original JSON to two keys containing enough information for
training an ML classiﬁer. These keys are:

• behavior → summary that contains a summary of the behavioral analysis, including accessed

ﬁles, registry keys, mutexes, and API calls,

• static → pe that contains static properties of the executed sample.

An example of such a reduced report can be seen in Figure 3. In the following section, we introduce
two baseline HMIL models that take these reduced JSON ﬁles as input and their task is to predict the
correct malware family.

5

{

"behavior": {

"summary": {
"keys": [

"HKEY\_LOCAL\_MACHINE\\System\\CurrentControlSet\\Control\\Nls\\CustomLocale",
...],

"resolved\_apis": [

"kernel32.dll.GetCurrentProcessorNumber",
"kernel32.dll.GetNativeSystemInfo",
...],

"executed\_commands": [

"\"C:\\Users\\comp\\AppData\\Local\\Temp\\FFFF450D574E5E5706FB.exe\"",
"\"C:\\Users\\comp\\AppData\\Local\\Microsoft\\Windows\\spcmachine.exe\""],

"write\_keys": [],
"files": [

"C:\\Windows\\SysWOW64\\kernel32.dll",
"C:\\Windows\\Globalization\\Sort,
...],

...
"mutexes": [
"PEMB40",
"PEM868",
"Global\\I5C3A8244",
"Global\\M5C3A8244",
...]

}

},
"static": {
"pe": {

"icon\_hash": null,
"sections": [

{

},

"raw\_address": "0x00001000",
"name": ".text",
"characteristics": "IMAGE\_SCN\_CNT\_CODEIMAGE_SCN_MEM_EXECUTEIMAGE\_SCN\_MEM\_READ",
"virtual\_size": "0x00002786",
"virtual\_address": "0x00001000",
"size\_of\_data": "0x00003000",
"entropy": "5.83",
"characteristics\_raw": "0x60000021"

...
"peid\_signatures": null,
"entrypoint": "0x00403600",
"exports": [],
"overlay": null,
"digital\_signers": [],
"imphash": "4e77bf5b96ea24734ed70b788b9fb7c8",
"reported\_checksum": "0x00000000",
"icon": null,
"guest\_signers": {

"aux\_error": true,
"aux\_sha1": null,
"aux\_timestamp": null,
"aux\_valid": false,
"aux\_signers": [],
"aux\_error\_desc": "No signature found. SignTool Error File not valid
C\\Users\\comp\\AppData\\Local\\Temp\\FFFF450D574E5E5706FB.exe"

},
"actual\_checksum": "0x0002a738",
"imports": [

{

"dll": "USER32.dll",
"imports": [

{

"name": "GetFocus",
"address": "0x404024"

}
...],

"versioninfo": [],

"resources": [

{

"name": "RT\_STRING",
"filetype": null,
"offset": "0x000210a0",
"language": "LANG\_NORWEGIAN",
"sublanguage": "SUBLANG\_NORWEGIAN\_BOKMAL",
"size": "0x00000024",
"entropy": "0.55"

}],

"pdbpath": null,
"osversion": "6.0",
"icon\_fuzzy": null,
"imagebase": "0x00400000",
"imported\_dll\_count": 4,
"timestamp": "1995-11-19 14:43:13"

}

}}

}

Figure 3: Shortened example of a JSON output of CAPEv2 analysis of a malicious sample.

4 Baseline Performance of a Machine Learning Classiﬁer

As indicated above, we are using hierarchical multi-instance learning (HMIL) models [14] to train
classiﬁers that given a reduced JSON input predict the malware family of this sample.

To train and test the accuracy of the baseline model, we split the dataset into a train and test
part. Following the practice of other malware-detection datasets [1], we suggest researchers make
the train-test split according to some date – in our baseline case, all samples before 2019/08/01 are
considered to be a part of the training set (37, 512 samples (≈ 76%)), all samples that appeared later
are considered to be a part of the test set (11, 464 samples (≈ 24%)). As we shall see, such a train-test
split according to time is important as it takes into consideration the signiﬁcant concept drift present
in malware data.

We have created two HMIL models:

• a reduced model that considers complete reduced JSON reports as described in the previous

section

• a static reduced model that considers only the static part of the reduced JSON reports.

For training the HMIL models, we have used a public library written in Julia Mill.jl [10] together
with JsonGrinder.jl [10] (the jupyter notebooks demonstrating the training of the baseline models
are part of the released dataset). We have used the default setting while creating the model for the
reports (i.e., the size of the inner dense layers (set to 32), the aggregation function (set to meanmax
aggregation function), and the activation function (set to relu). Using 200 training steps, each with
randomly sampled minibatch of size 500 and ADAM optimizer, the trained reduced model achieved an
accuracy of 99.5% on training data and 94.5% on testing data. The complete results, i.e., the accuracy
per different malware families, are shown in Table 2.

True \ Pred.
Adload
Emotet
HarHar
Lokibot
Qakbot
Swisyn
Trickbot
Ursnif
Zeus
njRAT

Adload

Emotet

HarHar

Lokibot

Qakbot

Swisyn

Trickbot

Ursnif

100.00
0.06
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.00
86.54
0.00
0.15
0.00
0.00
0.15
0.00
1.39
0.00

0.00
0.00
98.55
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.00
0.48
0.00
95.33
0.25
0.00
0.22
0.20
0.00
0.18

0.00
0.00
0.00
0.00
99.24
0.00
0.00
0.20
0.00
0.00

0.00
0.03
0.00
0.00
0.00
99.88
0.00
0.00
0.00
0.00

0.00
3.09
0.00
0.15
0.00
0.00
98.58
0.00
0.00
0.00

0.00
2.30
0.00
0.00
0.00
0.02
0.15
94.02
0.00
0.18

Zeus

0.00
7.28
0.00
0.15
0.51
0.02
0.52
4.18
95.83
0.37

njRAT

0.00
0.23
1.45
4.23
0.00
0.07
0.37
1.39
2.78
99.26

Table 2: The confusion matrix of predictions on testing data for the HMIL model trained on reduced
JSON reports. The ground-truth labels are provided in rows, the predictions are provided in columns,
and every cell represents a percentage of samples having the true label (the row label) being classiﬁed
as the label in the column.

To conﬁrm the importance of behavioral data, we have trained also a static model that considers
only the static part of the reduced JSON reports. Using the same parameters (i.e., the parameters
for the model and the training process), the trained model reached an accuracy of 96.7% on training
data. However, the model does not generalize in the face of the concept drift and the accuracy of the
model on the testing data was (at best) around 63%. From the details in Table 3 it is clear that mainly
malware families Emotet and Qakbot were exhibiting a signiﬁcant change in static characteristics
such that the model was not able to detect it on the testing set (only 2.35% of correctly predicted
Emotet samples and 35.63% of Qakbot samples, respectively). Finally, note that without the time split,

7

True \ Pred.
Adload
Emotet
HarHar
Lokibot
Qakbot
Swisyn
Trickbot
Ursnif
Zeus
njRAT

Adload

Emotet

HarHar

Lokibot

Qakbot

Swisyn

Trickbot

Ursnif

60.00
0.00
0.00
0.00
0.00
0.02
0.00
1.79
0.00
0.00

0.00
2.35
0.00
0.15
54.45
0.00
0.90
20.92
5.56
0.74

0.00
0.00
98.55
0.00
0.00
0.00
0.00
0.00
0.00
0.00

0.00
29.13
0.00
90.07
4.33
0.05
16.47
1.59
2.78
13.44

0.00
1.70
0.00
0.29
35.62
0.00
0.30
0.20
0.00
0.00

0.00
0.00
0.00
0.00
0.00
99.72
0.00
0.00
0.00
0.00

20.00
57.30
0.00
0.73
0.51
0.14
68.49
1.59
0.00
0.74

20.00
6.46
0.00
0.29
4.07
0.02
4.49
70.32
7.64
4.60

Zeus

0.00
1.79
0.00
0.58
1.02
0.02
0.60
2.99
82.64
4.97

njRAT

0.00
1.28
1.45
7.88
0.00
0.02
8.76
0.60
1.39
75.51

Table 3: The confusion matrix of predictions on testing data for the static HMIL model trained on
reduced JSON reports. The ground-truth labels are provided in rows, the predictions are provided in
columns, and every cell represents a percentage of samples having the true label (the row label) being
classiﬁed as the label in the column.

i.e., if all data were randomly split into training and testing sets regardless of the time stamp, the
average accuracy of the static reduced model was well above 95%. This demonstrates the necessity
of considering a time split since otherwise, the model will leverage easily identiﬁable features that,
however, do not generalize over time and thus are not really solving the malware-detection problem.

5 Discussion and Conclusions

The released dataset presents a unique collection of detailed behavioral data collected from malicious
samples over an extensive period of time. We have shown that the released data contain enough
information so that a reasonably accurate classiﬁer can be trained, however, we believe that the
released dataset offers a variety of new research opportunities.

Given the long period over which the samples were collected, the dataset should be useful for
studying concept drift and changes in malicious behavior. Connected to this, a challenge is to train
a classiﬁer to identify the malicious behavior (or attribution to a speciﬁc malware family) in a way
robust to concept drift by identifying generic techniques and tactics that may be hidden in the full list
of system calls of complete behavioral logs.

References

[1] H. S. Anderson and P. Roth. Ember: an open dataset for training static pe malware machine

learning models. arXiv preprint arXiv:1804.04637, 2018.

[2] A. Brukhovetskyy and K. O’Reilly. CAPE Sandbox v2.1 Book. https://capev2.readthedocs.

io/en/latest/index.html, 2022. (Accessed on 08/01/2022).

[3] M. Cohen. Scanning memory with yara. Digital Investigation, 20:34–43, 2017.

[4] A. S. de Oliveira and R. J. Sassi. Behavioral Malware Detection Using Deep Graph Convolutional

Neural Networks. 11 2019.

[5] R. Harang and E. M. Rudd. Sorel-20m: A large scale benchmark dataset for malicious pe

detection, 2020.

8

[6] C. Jindal, C. Salls, H. Aghakhani, K. Long, C. Kruegel, and G. Vigna. Neurlux: Dynamic Malware

Analysis Without Feature Engineering. CoRR, abs/1910.11376, 2019.

[7] R. J. Joyce, D. Amlani, C. Nicholas, and E. Raff. MOTIF: A large malware reference dataset with

ground truth family labels. CoRR, abs/2111.15031, 2021.

[8] Y. Ki, E. Kim, and H. K. Kim. A novel approach to detect malware based on api call sequence

analysis. International Journal of Distributed Sensor Networks, 11(6):659101, 2015.

[9] Q. Le, O. Boydell, B. Mac Namee, and M. Scanlon. Deep learning at the shallow end: Malware

classiﬁcation for non-domain experts. Digital Investigation, 26:S118–S126, 2018.

[10] S. Mandlik, M. Racinsky, V. Lisy, and T. Pevny. Mill.jl and JsonGrinder.jl: automated differentiable

feature extraction for learning from raw JSON data, 2021.

[11] D.-G. Marculet, R. Benchea, and D. T. Gavrilut. Methods for training neural networks with zero
false positives for malware detection. In 2019 21st International Symposium on Symbolic and
Numeric Algorithms for Scientiﬁc Computing (SYNASC), pages 230–236, 2019.

[12] D. Oktavianto and I. Muhardianto. Cuckoo malware analysis. Packt Publishing Ltd, 2013.

[13] O. Or-Meir, N. Nissim, Y. Elovici, and L. Rokach. Dynamic malware analysis in the modern era—a

state of the art survey. 52(5), sep 2019.

[14] T. Pevný and P. Somol. Discriminative models for multi-instance problems with tree-structure.

CoRR, abs/1703.02868, 2017.

[15] M. Rhode, P. Burnap, and K. Jones. Early-stage malware prediction using recurrent neural

networks. Computers & Security, 77:578–594, 2018.

[16] R. Ronen, M. Radu, C. Feuerstein, E. Yom-Tov, and M. Ahmadi. Microsoft malware classiﬁcation

challenge. arXiv preprint arXiv:1802.10135, 2018.

[17] S. K. Shaukat and V. J. Ribeiro. Ransomwall: A layered defense system against cryptographic
ransomware attacks using machine learning. In 2018 10th International Conference on Commu-
nication Systems & Networks (COMSNETS), pages 356–363, 2018.

[18] M. Sikorski and A. Honig. Practical malware analysis: the hands-on guide to dissecting malicious

software. no starch press, 2012.

[19] J. Singh and J. Singh. A survey on machine learning-based malware detection in executable

ﬁles. Journal of Systems Architecture, 112:101861, 2021.

9

