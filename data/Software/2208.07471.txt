On the Adoption and Effects of Source Code Reuse
on Defect Proneness and Maintenance Effort

Giammaria Giordano,1 Gerardo Festa,1 Gemma Catolino,2
Fabio Palomba,1 Filomena Ferrucci,1 Carmine Gravino1
1Software Engineering (SeSa) Lab, Department of Computer Science - University of Salerno, Italy
2Jheronimus Academy of Data Science – Tilburg University, ’s-Hertogenbosch, Netherlands
giagiordano@unisa.it, g.festa22@studenti.unisa.it, g.catolino@tilburguniversity.edu
fpalomba@unisa.it, fferrucci@unisa.it, gravino@unisa.it

2
2
0
2

g
u
A
5
1

]
E
S
.
s
c
[

1
v
1
7
4
7
0
.
8
0
2
2
:
v
i
X
r
a

Abstract—Context. Software reusability mechanisms, like in-
heritance and delegation in Object-Oriented programming, are
widely recognized as key instruments of software design. These
are used to reduce the risks of source code being affected by
defects, other than to reduce the effort required to maintain and
evolve source code. Previous work has traditionally employed
source code reuse metrics for prediction purposes, e.g., in the
context of defect prediction.

Objective. However, our research identiﬁes two noticeable
limitations of current literature. First, still little is known on
the extent
to which developers actually employ code reuse
it is still unclear how these
mechanisms over time. Second,
mechanisms may contribute to explain defect-proneness and
maintenance effort during software evolution. We aim at bridging
this gap of knowledge, as an improved understanding of these
aspects might provide insights into the actual support provided
by these mechanisms, e.g., by suggesting whether and how to use
them for prediction purposes.

Method. We propose an exploratory study aiming at (1)
assessing how developers use inheritance and delegation during
software evolution; and (2) statistically analyze the impact of
inheritance and delegation on fault proneness and maintenance
effort. The study will be conducted on the commits of 17 Java
projects of the DEFECTS4J dataset.

Index Terms—Software Reuse; Quality Metrics; Software

Maintenance and Evolution; Empirical Software Engineering.

I. INTRODUCTION

Software reusability is the design principle that allows
developers to reuse part of the existing code to implement
new features [1], [2]. This practice is widely recognized as
one of the key assets of software development, as developers
may have multiple beneﬁts, such as the reduction of evolution
time, effort, and cost, other than of the risks of source code
being affected by defects [3], [4], [5].

When it turns to Object-Oriented programming languages,
many software reuse mechanisms have been provided over
time. Design patterns [6], [7], third-party libraries [8], [9],
and programming abstractions [10] are examples of these
mechanisms. Focusing on JAVA, two very well-known types
of programming abstractions are provided to developers: in-
heritance and delegation [11]. The former allows a class to
take the properties and attributes of another class, establishing
a hierarchical relation between them. The latter refers to when
a class invokes an instance of another class to carry out
operations without performing any other type of action.

The importance of these mechanisms has been remarked
multiple times by researchers. Already in early 90s, Chidamber
and Kemerer [12] included the Depth of Inheritance Tree
(DIT), i.e., a metric that measures the number of classes that
inherit from another class, in their Object-Oriented metrics
suite. Later on, several other metrics capturing various aspects
of inheritance [13], [14], [15] and delegation [16], [17], [18]
were proposed, along with best and bad practices on how
to use reusability mechanisms [19], [20], [21], [22]. On the
empirical standpoint, a noticeable amount of investigations
targeted the role of inheritance and delegation in keeping
source code quality under control. For instance, researchers
have been studying the relation between these mechanisms
and other Object-Oriented metrics [23], [24], [25], design
patterns [26], [27], code complexity [28], and source code
maintainability [29], [30], [31].

Perhaps more interestingly, inheritance and delegation met-
rics have been often employed in the context of predictive
models for software maintenance and evolution. The key
example is defect prediction [32], [33], where researchers
assessed how reusability mechanisms may contribute to the
prediction of future source code defects [34], [35], [36],
[37], [38]. Similarly, the contribution of inheritance and del-
egation has been experimented for predicting maintenance
effort change [39], [40], code smells [41], [42], software
vulnerabilities [43], and infrastructure-as-code quality [44].

Despite the availability of a large body of knowledge on
how inheritance and delegation mechanisms contribute to the
prediction of source code attributes, most of the prediction
models deﬁned so far made a strong assumption: developers
make use of reusability principles while evolving source code.
On the one hand, the extent to which these mechanisms
are used in practice might have a notable impact on their
contribution to prediction models. On the other hand, it is
unclear how the relation between reusability and source code
attributes varies over time and, therefore, whether inheritance
and delegation mechanisms should still be considered for
prediction purposes as the system evolves.

In this registered report, we propose the methodology we
plan to use to ﬁll the limitations of current research with
respect
to the adoption of reusability practices and their
evolutionary effects on two speciﬁc source code attributes such

1

 
 
 
 
 
 
as defect proneness and maintenance effort. We select these
attributes as they represent two interesting use cases to assess
reusability mechanisms. First, these mechanisms are indeed
supposed to reduce fault proneness and maintenance effort [3],
[4], [5]. Second, a number of prediction models targeted the
early location of defects and estimation of the effort required
to perform evolutionary tasks [39], [45], [40].

Our study will focus on JAVA projects, as Java (1) offers
mechanisms that encourage the use of inheritance and del-
egation [46], [47] and (2) is still among the most popular
programming languages used in industry.1 To conduct our
experiment, we will ﬁrst mine the DEFECTS4J dataset
to
extract commit-level information on the adoption of reusability
mechanisms. Then, we will develop statistical models to
assess the contribution of reusability mechanisms on defect
proneness—as indicated by the number of defects over time—
and maintenance effort—as indicated by the code churn of
commits.

Our work has an exploratory connotation, as we do not
start with predeﬁned hypotheses but plan to develop a set of
hypotheses after the execution of the study, based on the results
achieved. All the collected data and the scripts developed in
the context of our research will be made publicly available for
the research community.

II. BACKGROUND AND RELATED WORK

We ﬁrst describe the most widely used paradigms in the
Object-Oriented programming languages for reusing code: in-
heritance and delegation. Then, we survey the related literature
targeting code reusability and its impact on source code.

A. Inheritance and Delegation

In JAVA there are two ways to deﬁne a hierarchical depen-

dency between two classes:

‘extends’. Given two classes A and B, A is deﬁned as
super-class of B if B inherits variables or methods by A.
In JAVA to establish this super-class – sub-class relation the
sub-class must indicate it through the keyword “extends”.
‘implements‘. Given a class A, and an interface B, we will
claim that A inherits from B if A implements the interface
B. In JAVA this mechanism is provided using the keyword
“implements”. In particular, when a class A inherits using
an interface, it must provide a concrete implementation of
methods deﬁned as a blueprint on interface.
These deﬁnitions recall the concept of reusability in terms
of speciﬁcation inheritance, implementation inheritance, and
delegation [48]. From a practical point of view, the ﬁrst one
refers to the possibility of replacing an object A with an object
B using a combination of two principles:

• Strict Inheritance. When a sub-class A exposes behavior
and properties of super-class B without making any
changes [48].

1Programming language ranking - Year 2021: https://www.tiobe.com/

tiobe-index/

• The Liskov Substitution Principle. According to Liskov
and Wing [49], given two classes A and B, A is a sub-
class of B if is possible to substitute the object B with
the object A every time that the object B was expected.
The implementation inheritance occurs when a class in-
directly reuses a super-class source code. The sub-class can
wholly or partially override methods and/or properties and
replace the super-class’s original behavior with its own. How-
ever, the implementation inheritance by deﬁnition violates the
encapsulate principle because a sub-class could accidentally
invoke methods or use some proprieties of the super-class in
a wrong manner [48]. To avoid this, it is possible to substitute
the implementation inheritance with the delegation in some
cases. With this mechanism, a class A does not inherit anything
from another class B, but A invokes methods of B directly by
declaring itself a variable of type B.

B. Related Work

Source code reusability has been the subject of several
researches in the last decades. These touched various angles
of the problem, by introducing novel metrics to capture inher-
itance relations [12], [13], [14], [15] and delegation [16], [17],
[18], deﬁning best design practices to exploit the beneﬁts of
reusability [19], [20], or identifying a number of source code
quality issues that reusability can cause, e.g., code smells [21],
[22], [50]. While the scope of our work targets inheritance and
delegation mechanisms, it is worth mentioning the existence
of close research areas such as the analysis of design patterns
[51], [52] and third-party libraries [53].

Reusability and code quality. As for the themes of our
exploratory study, Albalooshi and Mahmood [28] conducted
an empirical analysis on the implementation inheritance by
considering three programming languages like C++, PYTHON,
and JAVA. As a result, the authors found that the mechanisms
of JAVA to deﬁne inheritance tend to degrade source code
quality. Goel and Bathia [54] obtained similar results by
analyzing the impact of multilevel inheritance on the reusabil-
ity considering three C++ projects. They found a negative
correlation between the use of inheritance and the quality of
source code in terms of maintainability. Other research efforts
targeted the effect of inheritance and delegation on various
aspects of source code quality. Chhikara et al. [23] conducted
a case study on one small-scale software project, reporting on
the correlation between inheritance metrics and other metrics
belonging to the Chidamber and Kemerer suite. Chawla and
Nath [24] took a closer look at how inheritance and delegation
metrics may impact software coupling, concluding that these
metrics can be useful to assess code quality. Similar ﬁndings
were reported by Abreu et al. [25]. Additional experiments
were conducted to assess the relation between reusability and
design patterns [26], [27] and code complexity [28]: all these
studies converged toward the relevance of inheritance and
delegation. More recently, we carried out a study to investigate
the evolution of inheritance and delegation and their impact
on the severity of code smells [30]. The results revealed that
inheritance and delegation tend to increase over time, but not

2

in a statistically signiﬁcant manner. However, increasing the
adoption of these mechanisms tends to decrease code smells’
severity.

The potential beneﬁts of reusability have led researchers
to use inheritance and delegation metrics within prediction
models. In this respect, most of the defect prediction models
include reusability as a feature [32]. Perhaps more importantly,
these metrics have been sometimes shown to signiﬁcantly
contribute to the predictions of those models: for instance,
Jureczko and Madeyski [55] showed that the Depth of In-
heritance Tree metric is among the best predictors of source
code defectiveness. These results were later conﬁrmed by other
software maintenance and evolution researches [56], [57].

Reusability and maintenance effort. From an empirical
side, Prechelt et al. [31] carried out two experiments to investi-
gate the relation between inheritance metrics and maintenance
effort estimation. Their results revealed that maintaining a low
level of inheritance depth positively impacts the (decrease of)
developer’s effort to maintain source code. Similarly, Daly et
al. [29] showed that as the inheritance depth level increases,
so does the effort of developers to maintain code.

In terms of maintenance effort estimation, researchers have
been mainly looking at process-level information (e.g., team
data and measurements of the development activities), at-
tempting to provide indications in terms of direct and indirect
estimations of entire projects under maintenance [58]. Besides
that, researchers have been also working on effort prediction of
maintenance activities, which revolves around the prediction
of the effort spent in performing speciﬁc activities such as code
review [59] and bug ﬁxing time [60], [61]. The contribution
provided by reusability metrics to those models are, however,
unclear. Recently, Nagappan et al. [40] and Liu et al. [62]
proposed the use of code churn, i.e., the amount of lines of
code modiﬁed within commits, as an alternative metric of
maintenance effort which better aligns with the actual effort
spent by developers while performing evolutionary tasks.

Our work. With respect to the papers discussed above, ours
has multiple differences. In the ﬁrst place, most of previous
work analyzed reusability by relying on the computation of
metrics, e.g., DIT; as further elaborated in Section IV, we
plan to operationalize reusability by means of speciﬁcation
inheritance, implementation inheritance, and delegation, being
able to better map the employment of reuse mechanisms over
time. In the second place, we plan to conduct a ﬁne-grained
analysis where the evolution and impact of reusability will be
investigated at commit-level. Furthermore, we plan to address
a key limitation of most previous work proposing prediction
models: the contribution of code reuse to their capabilities
indeed assumes that developers make use of reusability mech-
anisms. As such, our evolutionary study will provide more
detailed insights into the potential beneﬁts brought by inheri-
tance and delegation to state-of-the-art prediction models.

III. RESEARCH QUESTIONS AND OBJECTIVES
The goal of the study aims at investigating how the use
of reusability mechanisms evolves over time and assessing

their impact on fault-proneness and code churn. The purpose is
to understand whether those mechanisms can provide devel-
opers with an indication of source code quality variation—
considering the fault-proneness and effort
to ﬁx faults of
a project. The quality focus is on the reusability in terms
of implementation inheritance, speciﬁcation inheritance, and
delegation and their evolution within software projects. We
conduct the analysis from both practitioners and researchers
(perspective). The ﬁrst one is interested in understanding
whether the reusability mechanism can be suitable for monitor-
ing the quality of a system. The latter is to have more evidence
about inheritance and delegation mechanisms when monitoring
the source code quality. The context of our investigation will
be JAVA projects publicly available. Based on the goal of our
study, we formulate three main research questions.

RQ1. How does the use of source code reusability mecha-
nisms vary during software evolution?

The ﬁrst research question aims at understanding the use
of source code reusability mechanisms by developers during
software evolution. More speciﬁcally, the goal of RQ1 is that
of providing insights on the evolution of reuse mechanisms
that might later be exploited to better interpret the ﬁndings
of RQ2 and RQ3. In other terms,
the patterns observed
in the context of this research question will be also useful
to understand the effects of inheritance and delegation on
defect-proneness and code churn, e.g., should we identify
an exponential growth in the adoption of delegation,
this
would potentially make this mechanism more relevant for
software evolution, hence inﬂuencing more the amount of code
churn required to apply modiﬁcations. Since we intend to
analyze three mechanisms for REUSABILITY, i.e., speciﬁcation
inheritance, implementation inheritance, and delegation [48],
that can impact differently on software evolution, we will
consider three sub-research questions:

RQ11. How does the use of implementation inheritance vary

during software evolution?

RQ12. How does the use of the speciﬁcation inheritance vary

during software evolution?

RQ13. How does the use of delegation vary during software

evolution?

Once the evolution of reusability mechanisms is analyzed,
we plan to investigate how the evolution might affect code
quality, measured in terms of fault-proneness.

RQ2. How do source code reusability mechanisms impact
fault-proneness over time?

Finally, we plan to assess the impact of reusability mechanisms
on the maintenance effort required to ﬁx faults. Among the
various direct and indirect metrics available in literature [58],
we will operationalize maintenance effort through code churn,
that is, the amount of lines of code modiﬁed within a commit.

3

Fig. 1: Overview of the methodology applied to address our research questions.

This is an indirect metric that can proxy the actual effort spent
by developers when maintaining source code [58], [63], [64].

RQ3. How do source code reusability mechanisms impact
code churn?

The above research questions will be addressed by employ-
ing statistical tests and models (see details in Section IV-C). To
design and report on the empirical study to be performed, we
will follow the guidelines proposed by Wohlin et al. [65] and
ACM/SIGSOFT Empirical Standards2. All the experimental
material (e.g., datasets, scripts) will be publicly available in
an online appendix.

IV. RESEARCH METHODOLOGY
Figure 1 overviews the methodology we intend to exploit to
address our research questions, as detailed in the next sections.

A. Dataset

We plan to perform an empirical analysis on JAVA projects
provided by DEFECTS4J, which collects information on 835
bugs provided by 17 real JAVA projects. According to the
ofﬁcial documentation3 each bug collected into the dataset is
characterized by the following properties:

1) It is ﬁxed in a single commit, meaning that the bug

resolution never refers to more than one commit;

2) It is minimized, meaning that Defects4J maintainers man-
ually remove commits that do not provide information
about the introduction of bugs or ﬁxing activity (e.g.,
commits where refactoring activities are done);

3) The ﬁxing activities modify the source code. This means
that the bug introduction can be caused by several factors,
e.g., wrong parameters in conﬁguration ﬁles and prob-
lems in the production class. However, the corresponding
ﬁxing only concerns changing the source code.

2Available at: https://github.com/acmsigsoft/EmpiricalStandards
3https://github.com/rjust/defects4j

There are multiple reasons leading to the selection of
this dataset. First, it enables the investigation of the impact
of reuse mechanisms in a noise-free environment. Indeed,
we can provide more precise insights into the actual role
played by inheritance and delegation which would not be
possible through larger software repository mining studies
where the existence of uncontrolled conditions, e.g., tangled
changes [66], may bias the conclusions provided. Secondly,
despite the defects being carefully selected, those defects are
of different types and nature, therefore representing various
defects affecting real-world software systems [67]. Last but
not least, Defects4J has been widely used in literature (e.g.,
[68], [69]), hence representing a valuable asset that enables
us to build additional knowledge on a state-of-the-art dataset
- this would also be useful for other researchers interested in
building on top of our work.

As mentioned in Section II, little has been done to analyze
code reuse mechanisms over time and how those may con-
tribute to explaining fault-proneness and maintenance efforts
during software evolution. For this reason, we intend to ﬁll
the gap by analyzing code reuse mechanisms from a low
granularity perspective,
i.e., commits. We plan to analyze
over 9,000 commits. Table I reports statistics of the projects
included in the Defects4J dataset. In particular, for each project
the table provides (i) the numbers of defects, (ii) the IDs
of ﬁxed and unﬁxed defects, (iii) process metrics such as
numbers of commits, numbers of pull request, and number
of contributors; and (iv) its minimum and maximum LOC.

B. Data Extraction Procedure

To answer our research questions, we need to quantify the
reusability in terms of implementation inheritance, speciﬁca-
tion inheritance, and delegation. To this end, we plan to use a
tool already validated in our previous work [30]. In particular,
the tool computes those metrics following these patterns:

4

PyDrillerSource CodeModule -  CK MetricsModule - InhMetricsDatasetDatasetDatasetData IntegrationRQ2. How do source code reusability mechanisms  impact fault-proneness  over time?RQ3. How do source code  reusability mechanisms impact code churn?RQ1. How does the use of source code reusability mechanisms vary during software evolution?Reusability Metrics Evolution Building a Statistical ModelBuilding a Statistical ModelDefects4JProject Name
JFreeChart
Commons-Cli
Closure-Compiler
Commons-Codec
Commons-Collections
Commons-Compress
Commons-Csv
Gson
Jackson-Core
Jackson-Databind
Jackson-Dataformat-XML
JSoup
Commons-JXPath
Commons-Lang
Commons-Math
Mockito
Joda-Time

Number of Bugs
26
39
174
18
4
47
16
18
26
112
6
93
22
64
106
38
26

Active Bug Ids
1-26
1-5,7-40
1-62,64-92,94-176
1-18
25-28
1-47
1-16
1-18
1-26
1-112
1-6
1-93
1-22
1,3-65
1-106
1-38
1-20,22-27

Deprecated bug Ids
None
6
63,93
None
1-24
None
None
None
None
None
None
None
None
2
None
None
21

Pull Request
22
8
6
9
37
9
8
151
2
19
3
43
8
92
68
7
2

Contributors
24
42
472
40
62
67
37
125
63
198
26
99
17
174
48
246
77

Stars
866
255
6,5k
364
551
231
281
21,2k
2.1k
3,1k
497
9,6k
18
2,3k
451
13,1k
4,8k

Forks
355
154
1,1k
207
389
210
220
4,1k
690
1,2k
189
2k
40
176
71
2,3k
922

Commits
4218
1169
17,962
2,244
3,729
3,602
1,796
1,668
2,124
6,578
1,318
1,693
601
6,859
7,004
5,787
2,196

Branches
3
4
76
7
8
9
4
14
21
22
19
3
4
8
17
16
6

LOC
250k - 290k
5k - 16k
60k - 60k
48k - 34k
49k - 60k
129k - 91k
166k - 166k
68k - 70k
33k - 66k
98k - 235k
59k - 117k
39k - 34k
46k - 26k
160k - 190
58k - 63k
73k - 94k
103k - 164k

TABLE I: Characteristics of the projects considered in the study. Information concerned with the ‘Active Bug IDs’ and ‘LOC’
are provided in a range reporting the minimum and maximum values observed over the history of the projects.

Speciﬁcation Inheritance. Given a class A, the tool considers
the speciﬁcation inheritance as the arithmetical sum of each
interface used by A. For instance, suppose that A inherits
methods from two interfaces B and C, and C in turn
inherits methods from another interface D. In this case, the
speciﬁcation inheritance for A is 3.

Implementation Inheritance. Suppose that A is a sub-class
of B, the tool considers the implementation inheritance as
the arithmetical sum of each method in B called by some
method in A. For example, suppose that A is a class with N
methods, and B a class with just one method call bar().
To increase the number of implementation inheritance by
one, one of the methods in A must invoke bar().

Delegation. Given a class A, the tool considers the delegation
metric as the arithmetical sum of each non-primitive variable
(i.e., variables different from int, double, String,
and so on) or variables that do not have a binding type
provided by external libraries (e.g., Checkbox offered by
javax.swing framework). For each variable,
the tool
veriﬁes if it is only used to invoke external objects.

To answer research questions RQ2 and RQ3, we plan
to collect information on bugs and code churns. Defects4J
contains information on bugs at commit level, while we will
consider PYDRILLER, an automatic static analysis tool that
can analyze GIT repositories, to extract information about
commits, developers, modiﬁcations, diffs, and source code 4.

C. Experimental Plan

For the sake of comprehensibility, we present the empirical

analysis we plan to perform for each research question.

1) RQ1. Analysis of the evolution of reusability mechanisms
over time. To answer this research question we will ana-
lyze the behavior of the reusability metrics (implementa-
tion inheritance, speciﬁcation inheritance and delegation)
during the evolution. In particular, we plan to employ
basic statistical analysis, and visualize results using plots.
the impact on fault-proneness of
reusability mechanisms over time. Moving on RQ2, we

2) RQ2. Analysis of

4https://pydriller.readthedocs.io/en/latest/intro.html

plan to build a statistical model to verify how reusability
metrics impact the variability of bugs in the source code.

3) RQ3. Analysis of the impact on maintenance effort of
reusability mechanisms over time. Also for RQ3, we plan
to verify how reusability
to build a statistical model
metrics impact the maintenance effort to ﬁx a bug.

The statistical models will be devised as follows.

Independent Variables. According to our previous consider-
ations, we will use as independent variables the reusability
metrics, i.e., implementation inheritance, speciﬁcation inher-
itance, and delegation.

Response Variable. The number of bugs represents our re-
sponse variable. However, since our goal is to understand the
variability of them, we plan analyzing whether the number of
bugs between two commits is stable, or increase/decrease.
In particular, it will be considered “stable” if we do not
identify any changes in terms of the number of bugs between
the commit I and the commit I+1. It will be considered as
“increase” (“decrease”) if we identify a positive (negative)
value as a result of the subtraction between the numbers of
bugs on the commit I+1 and the numbers of bugs on the
commit I.

Control Variables. Conscious that bugs variation could de-
pend on other external factors, we will consider two sets of
metrics as control variables. On the one hand, we will con-
sider the following Chidamber and Kemerer (CK) metrics
[12]: DIT (Depth of Inheritance Tree), NOC (Number Of
Children), LOC (Lines of Code), LCOM (Lack of Cohesion
of Methods), WMC (Weighted Methods per Class), RFC
(Response for a Class) and CBO (Coupling Between Ob-
jects). On the other hand, we will also take into account the
Code Churns. It is important to mark that although NOC and
DIT are also metrics related to code reuse, we will include
them with the intent of comparing their statistical power
to the adoption mechanisms estimated by our reusability
metrics. However, we plan to assess the presence of possible
multi-collinearity when performing the statistical modeling
due to the presence of those related metrics. We will rely
on previous guidelines provided by the literature [70], [71].

5

Choosing Statistical Model. To address RQ2, we will use a
Multinomial Log-Linear Model [72]. This model generalizes
logistic regression to multi-class problems, so it perfectly
ﬁts our case. In particular, as already done in our previous
work [30], we plan to use R for running the analysis using
the function MULTINOM available in the package NNET5—
that ﬁts the model via neural networks. Finally, as for RQ3,
given the nature of the response variable, i.e., code churn,
we will use a different statistical model, i.e., Generalized
Linear Model [73] using GLM function.
Additional analysis. The inﬂuence of the reuse metrics on
introducing defects might not necessarily be directly measur-
able. For instance, previous work [74], [75], [76] reported
inheritance might negatively impact program compre-
that
in turn, can negatively contribute to the
hension, which,
defect-proneness of source code. In other words, the value
of reuse metrics can be sneakier, representing a co-occurring
phenomenon rather than directly responsible for introducing
defects. For this reason, besides interpreting the statistical
codes provided by the statistical models, we will also (1) com-
pute the number of cases in which defect-inducing commits
involved the variation of inheritance and delegation metrics
and (2) manually analyze those cases to better understand
the way these metrics can directly impact the introduction
of defects. Such an additional analysis will therefore provide
more qualitative insights into how reuse mechanisms can
impact defect-proneness.

D. Publication of generated data

All the material of our study, e.g., scripts will be publicly
available in an online repository (e.g., GitHub) to guarantee
the replicability of our work and possible reuse for future
investigations by other researchers.

V. THREATS TO VALIDITY

In this subsection, we discuss possible threats to validity

and the strategies we will adopt to mitigate them.

Construct Validity. These threats refer to a possible mismatch
between the theory and the observation. Therefore, the se-
lection of the dataset represents a crucial point. We plan to
use Defects4J, which has been already widely used by the
research community in several studies (e.g., [77][78] [79])
and that will reduce possible bias due to the presence of
uncontrolled conditions, e.g., tangled changes [66], allowing
us to investigate the impact of reuse mechanisms on defect-
proneness and maintenance effort more precisely. A second
threat to validity relates to the selection of the metric used
to operationalize maintenance effort. We plan to use code
churn [63]: we are aware that this metric can only proxy
the actual effort spent when maintaining source code, yet this
choice is required in our case because of the unavailability of
precise data regarding the maintenance effort in our dataset.
The tool we plan to use to extract metrics, e.g., reusability
or CK metrics, represents another potential threat to validity.

5https://cran.r-project.org/web/packages/nnet/nnet.pdf

We will use tools already validated and used by the research
community [30], [80]. Finally, as mentioned in Section IV-A,
in Defects4j a single bug can be introduced by multiple factors,
but its resolution will always occur within a JAVA ﬁle. Thus, to
avoid possible threats to contraction validity, we will discard
commits that introduced bugs caused by issues not involving
source code. This allows focusing only on defects introduced
and resolved through changes to the source ﬁles.

Internal Validity. These threats refer to factors that can impact
the study results. In our context, the threat concerns the metrics
we intend to exploit to build the statistical models. Besides our
hypothesis, we will use control variables —previously shown
to be signiﬁcant for source code quality [81], [82], [23], [29]—
thus guaranteeing the reliability of our results.

Conclusion Validity. Threats related to this area refer to the
selection and the use of the statistical test. In particular, for
addressing RQ2 we will use the Multinomial Logistic Linear
Model [72]. As for RQ3, we will apply the Generalized
Linear Model [73]. These choices come from the nature
of our response variables,
i.e., multiclass and continuous,
respectively. Moreover, the research community used this type
of model in similar contexts [30], [83], [84].

External validity. Threats in this category concern the gener-
alizability of the results. Our work employs statistical analysis
to seek relations between the employment of reuse mecha-
nisms and source code maintainability, operationalized with
defect-proneness and code churn metrics. The target of the
work will be composed of 17 JAVA projects with over 9,000
commits coming from the DEFECTS4J dataset. As such, our
work is based on the analyses conducted on a sample, hence
our generalization strategy can be identiﬁed within the sample-
based generalization strategies proposed by Wieringa and
Daneva [85]. In particular, among those strategies, the “sta-
tistical learning” seems to be the most appropriate. Wieringa
and Daneva [85] reported that the “descriptions of statistical
sample phenomena can be used to predict similar phenom-
ena in new samples. [...]. The goal
to generalize
to a population, but to generalize to the next few cases”.
This strategy is basically in line with the generalizing by
similarity principle described by Ghaisas et al. [86]. When
contextualizing those strategies in our case, it is likely that
similar results might be obtained in projects having similar
characteristics with respect to those analyzed in our work (see
Table I). Therefore, we cannot claim the generalizability of
our ﬁndings to projects having different properties or even
written in different programming languages. Replications in
these contexts would still be desirable.

is not

VI. CONCLUSION

This research will focus on understanding how inheritance
and delegation mechanisms evolve over time and their impact
on code quality, e.g., variability of bugs, at the commit level. In
particular, we will conduct this study on over 9,000 commits
provided by 17 Java projects reclaimed from Defects4J. We
ﬁrst plan to analyze the evolution of reusability metrics at the

6

commit level. Then we will construct two different statistical
models for assessing whether reusability metrics—combined
with additional factors—impact bugs variability and the time
to ﬁx bugs in terms of code churn.

ACKNOWLEDGMENT
Gemma is partially supported by the European Commission
grant no. 825040 (RADON). Fabio is supported by the Swiss
National Science Foundation through the SNF Project No.
PZ00P2 186090 (TED).

REFERENCES

[1] J. M. Bieman and J. X. Zhao, “Reuse through inheritance: A quantitative
study of c++ software,” ACM SIGSOFT Software Engineering Notes,
vol. 20, no. SI, pp. 47–52, 1995.

[2] N. Soundarajan and S. Fridella, “Inheritance: From code reuse to
reasoning reuse,” in International Conference on Software Reuse (Cat.
No. 98TB100203).

IEEE, 1998, pp. 206–215.
[3] S. Singh, S. Singh, and G. Singh, “Reusability of the software,” Inter.
journal of computer applications, vol. 7, no. 14, pp. 38–41, 2010.
[4] B. M. Lange and T. G. Moher, “Some strategies of reuse in an object-
oriented programming environment,” in Proceedings of the SIGCHI
conference on Human factors in computing systems, 1989, pp. 69–73.
[5] A. Sharma, P. Grover, and R. Kumar, “Reusability assessment for
software components,” ACM SIGSOFT Software Engineering Notes,
vol. 34, no. 2, pp. 1–6, 2009.

[6] A. De Lucia, V. Deufemia, C. Gravino, and M. Risi, “Design pattern
recovery through visual language parsing and source code analysis,”
Journal of Systems and Software, vol. 82, no. 7, pp. 1177–1193, 2009.
[7] E. Gamma, R. Helm, R. Johnson, and J. Vlissides, “Design patterns: Ab-
straction and reuse of object-oriented design,” in European Conference
on Object-Oriented Programming. Springer, 1993, pp. 406–431.
[8] A. Zaimi, A. Ampatzoglou, N. Triantafyllidou, A. Chatzigeorgiou,
A. Mavridis, T. Chaikalis, I. Deligiannis, P. Sfetsos, and I. Stamelos,
“An empirical study on the reuse of third-party libraries in open-
source software development,” in Balkan Conference on Informatics
Conference, 2015, pp. 1–8.

[9] P. Salza, F. Palomba, D. Di Nucci, A. De Lucia, and F. Ferrucci, “Third-
party libraries in mobile apps,” Empirical Software Engineering, vol. 25,
no. 3, pp. 2341–2377, 2020.

[10] I. Sommerville, “Software engineering 9th edition,” ISBN-10, vol.

137035152, p. 18, 2011.

[11] K. Arnold, J. Gosling, and D. Holmes, The Java programming language.

Addison Wesley Professional, 2005.

[12] S. R. Chidamber and C. F. Kemerer, “A metrics suite for object oriented
design,” IEEE Transactions on software engineering, vol. 20, no. 6, pp.
476–493, 1994.

[13] K. M. Breesam, “Metrics for object-oriented design focusing on class
inheritance metrics,” in Inter. conference on dependability of computer
systems (DepCoS-RELCOMEX’07).

IEEE, 2007, pp. 231–237.

[14] S. Mal and K. Rajnish, “New quality inheritance metrics for object-
oriented design,” International Journal of Software Engineering and Its
Applications, vol. 7, no. 6, pp. 185–200, 2013.

[15] K. Rajnish and V. Bhattacherjee, “Class inheritance metrics-an analytical
and empirical approach,” INFOCOMP Journal of Computer Science,
vol. 7, no. 3, pp. 25–34, 2008.

[16] O. Cherkaoui, A. Obaid, A. Serhouchni, and N. Simoni, “Qos metrics
tool using management by delegation,” in IEEE Network Operations and
Management Symposium, vol. 3.

IEEE, 1998, pp. 836–839.

[17] M. J. Munro, “Product metrics for automatic identiﬁcation of” bad
smell” design problems in java source-code,” in IEEE International
Software Metrics Symposium (METRICS’05).
IEEE, 2005, pp. 15–15.
[18] M. VanHilst and E. B. Fernandez, “Reverse engineering to detect secu-
rity patterns in code,” in International Workshop on Software Patterns
and Quality. Information Processing Society of Japan. Citeseer, 2007.
[19] S. Haeﬂiger, G. Von Krogh, and S. Spaeth, “Code reuse in open source
software,” Management science, vol. 54, no. 1, pp. 180–193, 2008.
[20] B. Jalender, A. Govardhan, and P. Premchand, “Designing code level
reusable software components,” International Journal of Software Engi-
neering & Applications, vol. 3, no. 1, p. 219, 2012.

[21] M. Mantyla, J. Vanhanen, and C. Lassenius, “A taxonomy and an initial
empirical study of bad smells in code,” in International Conference on
Software Maintenance (ICSM).

IEEE, 2003, pp. 381–384.

[22] F. Palomba, G. Bavota, M. Di Penta, R. Oliveto, D. Poshyvanyk, and
A. De Lucia, “Mining version histories for detecting code smells,” IEEE
Transactions on Software Engineering, vol. 41, no. 5, pp. 462–489, 2014.
[23] A. Chhikara, R. Chhillar, and S. Khatri, “Evaluating the impact of
different types of inheritance on the object oriented software metrics,”
International Journal of Enterprise Computing and Business Systems,
vol. 1, no. 2, pp. 1–7, 2011.

[24] S. Chawla and R. Nath, “Evaluating inheritance and coupling metrics,”
International Journal of Engineering Trends and Technology (IJETT),
vol. 4, no. 7, pp. 2903–2908, 2013.

[25] F. B. e Abreu and W. Melo, “Evaluating the impact of object-oriented
design on software quality,” in Proceedings of the 3rd international
software metrics symposium.

IEEE, 1996, pp. 90–99.

[26] A. Ampatzoglou, A. Chatzigeorgiou, S. Charalampidou, and P. Avgeriou,
“The effect of gof design patterns on stability: a case study,” IEEE
Transactions on Software Engineering, vol. 41, no. 8, pp. 781–802, 2015.
[27] B. Huston, “The effects of design pattern application on metric scores,”

Journal of Systems and Software, vol. 58, no. 3, pp. 261–269, 2001.

[28] F. Albalooshi and A. Mahmood, “A comparative study on the effect of
multiple inheritance mechanism in java, c++, and python on complexity
and reusability of code,” International Journal of Advanced Computer
Science and Applications, vol. 8, no. 6, pp. 109–116, 2017.

[29] J. Daly, A. Brooks, J. Miller, M. Roper, and M. Wood, “Evaluating
inheritance depth on the maintainability of object-oriented software,”
Empirical Software Engineering, vol. 1, no. 2, pp. 109–132, 1996.
[30] G. Giordano, A. Fasulo, G. Catolino, F. Palomba, F. Ferrucci, and
C. Gravino, “On the evolution of inheritance and delegation mechanisms
and their impact on code quality,” in IEEE Inter. Conference on Software
Analysis, Evolution and Reengineering (SANER), 2022, pp. 1–12.
[31] L. Prechelt, B. Unger, M. Philippsen, and W. Tichy, “A controlled
experiment on inheritance depth as a cost factor for code maintenance,”
Journal of Systems and Software, vol. 65, no. 2, pp. 115 – 126, 2003.
[32] T. Hall, S. Beecham, D. Bowes, D. Gray, and S. Counsell, “A systematic
literature review on fault prediction performance in software engineer-
ing,” IEEE Transactions on Software Engineering, vol. 38, no. 6, pp.
1276–1304, 2011.

[33] S. Hosseini, B. Turhan, and D. Gunarathna, “A systematic literature
review and meta-analysis on cross project defect prediction,” IEEE
Transactions on Software Engineering, vol. 45, no. 2, pp. 111–147, 2017.
[34] V. R. Basili, L. C. Briand, and W. L. Melo, “A validation of object-
oriented design metrics as quality indicators,” IEEE Transactions on
software engineering, vol. 22, no. 10, pp. 751–761, 1996.

[35] Y. Singh, A. Kaur, and R. Malhotra, “Empirical validation of object-
oriented metrics for predicting fault proneness models,” Software quality
journal, vol. 18, no. 1, pp. 3–35, 2010.

[36] P. Yu, T. Systa, and H. Muller, “Predicting fault-proneness using oo
metrics. an industrial case study,” in European Conference on Software
Maintenance and Reengineering.

IEEE, 2002, pp. 99–107.

[37] D. Di Nucci, F. Palomba, G. De Rosa, G. Bavota, R. Oliveto, and
A. De Lucia, “A developer centered bug prediction model,” IEEE
Transactions on Software Engineering, vol. 44, no. 1, pp. 5–24, 2017.
[38] F. Palomba, M. Zanoni, F. A. Fontana, A. De Lucia, and R. Oliveto,
“Toward a smell-aware bug prediction model,” IEEE Transactions on
Software Engineering, vol. 45, no. 2, pp. 194–218, 2017.

[39] G. Catolino, F. Palomba, F. A. Fontana, A. De Lucia, A. Zaidman,
and F. Ferrucci, “Improving change prediction models with code smell-
related information,” Empirical Software Engineering, vol. 25, no. 1, pp.
49–95, 2020.

[40] N. Nagappan and T. Ball, “Use of relative code churn measures to
predict system defect density,” in International conference on Software
engineering, 2005, pp. 284–292.

[41] F. Arcelli Fontana, M. V. M¨antyl¨a, M. Zanoni, and A. Marino, “Com-
paring and experimenting machine learning techniques for code smell
detection,” Empirical Software Engineering, vol. 21, no. 3, pp. 1143–
1191, 2016.

[42] D. Di Nucci, F. Palomba, D. A. Tamburri, A. Serebrenik, and A. De Lu-
cia, “Detecting code smells using machine learning techniques: are we
there yet?” in International conference on software analysis, evolution
and reengineering (SANER).

IEEE, 2018, pp. 612–621.

[43] Y. Shin, A. Meneely, L. Williams, and J. A. Osborne, “Evaluating
complexity, code churn, and developer activity metrics as indicators of
software vulnerabilities,” IEEE transactions on software engineering,
vol. 37, no. 6, pp. 772–787, 2010.

7

[44] S. Dalla Palma, D. Di Nucci, F. Palomba, and D. A. Tamburri, “Within-
project defect prediction of infrastructure-as-code using product and
process metrics,” IEEE Transactions on Softw. Engineer., pp. 1–1, 2021.
[45] L. Pascarella, F. Palomba, and A. Bacchelli, “Fine-grained just-in-time
defect prediction,” Jour. of Syst. and Softw., vol. 150, pp. 22–36, 2019.
[46] I. D. Craig, “Inheritance and delegation,” in Object-Oriented Program-

ming Languages: Interpretation. Springer, 2007, pp. 83–128.

[47] E. Tempero, H. Y. Yang, and J. Noble, “What programmers do with
inheritance in java,” in European Conference on Object-Oriented Pro-
gramming. Springer, 2013, pp. 577–601.

[48] B. Bruegge and A. H. Dutoit, Object-Oriented Software Engineering

Using UML, Patterns, and Java, 3rd ed. USA: Prentice Hall, 2009.

[49] B. H. Liskov and J. M. Wing, “A behavioral notion of subtyping,”
ACM Transactions on Programming Languages and Systems (TOPLAS),
vol. 16, no. 6, pp. 1811–1841, 1994.

[50] M. Fowler, Refactoring:

improving the design of existing code.

Addison-Wesley Professional, 2018.

[51] F. A. Fontana, S. Maggioni, and C. Raibulet, “Design patterns: a survey
on their micro-structures,” Journal of Software: Evolution and Process,
vol. 25, no. 1, pp. 27–52, 2013.

[52] C. Zhang and D. Budgen, “A survey of experienced user perceptions
about software design patterns,” Information and Software Technology,
vol. 55, no. 5, pp. 822–835, 2013.

[53] X. Zhan, T. Liu, L. Fan, L. Li, S. Chen, X. Luo, and Y. Liu, “Research
on third-party libraries in android apps: A taxonomy and systematic
literature review,” IEEE Transactions on Software Engineering, 2021.

[54] B. M. Goel and P. K. Bhatia, “Analysis of reusability of object-oriented
systems using object-oriented metrics,” ACM SIGSOFT Software Engi-
neering Notes, vol. 38, no. 4, pp. 1–5, 2013.

[55] M. Jureczko and L. Madeyski, “Towards identifying software project
clusters with regard to defect prediction,” in International conference
on predictive models in software engineering, 2010, pp. 1–10.

[56] P. D. Singh and A. Chug, “Software defect prediction analysis using
machine learning algorithms,” in Inter. Conf. on Cloud Computing, Data
Science & Engineering-Conﬂuence.

IEEE, 2017, pp. 775–781.

[57] M. Jureczko and D. Spinellis, “Using object-oriented design metrics to
predict software defects,” Models and Methods of System Dependability.
Oﬁcyna Wydawnicza Politechniki Wrocławskiej, pp. 69–81, 2010.
[58] H. Wu, L. Shi, C. Chen, Q. Wang, and B. Boehm, “Maintenance effort
estimation for open source software: A systematic literature review,” in
IEEE international conference on software maintenance and evolution
(ICSME), 2016, pp. 32–43.

[59] R. Mishra and A. Sureka, “Mining peer code review system for
computing effort and contribution metrics for patch reviewers,” in IEEE
Workshop on mining unstructured data.

IEEE, 2014, pp. 11–15.

[60] P. Anbalagan and M. Vouk, “On predicting the time taken to correct bug
reports in open source projects,” in IEEE International Conference on
Software Maintenance, 2009, pp. 523–526.

[61] G. Bougie, C. Treude, D. M. German, and M.-A. Storey, “A comparative
exploration of freebsd bug lifetimes,” in IEEE Working Conference on
Mining Software Repositories (MSR).

IEEE, 2010, pp. 106–109.

[62] J. Liu, Y. Zhou, Y. Yang, H. Lu, and B. Xu, “Code churn: A neglected
metric in effort-aware just-in-time defect prediction,” in ACM/IEEE
International Symposium on Empirical Software Engineering and Mea-
surement (ESEM), 2017, pp. 11–19.

[63] J. C. Munson and S. G. Elbaum, “Code churn: A measure for estimating
the impact of code change,” in Proceedings. International Conference on
Software Maintenance (Cat. No. 98CB36272).
IEEE, 1998, pp. 24–31.
[64] S. McIntosh, B. Adams, T. H. Nguyen, Y. Kamei, and A. E. Hassan, “An
empirical study of build maintenance effort,” in 2011 33rd International
Conference on Software Engineering (ICSE).
IEEE, 2011, pp. 141–150.
[65] C. Wohlin, P. Runeson, M. H¨ost, M. C. Ohlsson, B. Regnell, and
A. Wessl´en, Experimentation in software engineering. Springer Science
& Business Media, 2012.

[66] K. Herzig, S. Just, and A. Zeller, “The impact of tangled code changes
on defect prediction models,” Empirical Software Engineering, vol. 21,
no. 2, pp. 303–336, 2016.

[67] V. Sobreira, T. Durieux, F. Madeiral, M. Monperrus,

and
M. de Almeida Maia, “Dissection of a bug dataset: Anatomy of 395

patches from defects4j,” in 2018 IEEE 25th International Conference
on Software Analysis, Evolution and Reengineering (SANER).
IEEE,
2018, pp. 130–140.

[68] M. Martinez, T. Durieux, R. Sommerard, J. Xuan, and M. Monperrus,
“Automatic repair of real bugs in java: A large-scale experiment on the
defects4j dataset,” Empirical Software Engineering, vol. 22, no. 4, pp.
1936–1964, 2017.

[69] T. Durieux, M. Martinez, M. Monperrus, R. Sommerard, and J. Xuan,
“Automatic repair of real bugs: An experience report on the defects4j
dataset,” 2015.

[70] P. Allison, “When can you safely ignore multicollinearity,” Statistical

horizons, vol. 5, no. 1, pp. 1–2, 2012.

[71] M. G. Lieberman and J. D. Morris, “The precise effect of multicollinear-
ity on classiﬁcation prediction,” Multiple Linear Regression Viewpoints,
vol. 40, no. 1, pp. 5–10, 2014.

[72] H. Theil, “A multinomial extension of the linear logit model,” Interna-

tional economic review, vol. 10, no. 3, pp. 251–259, 1969.

[73] J. J. Faraway, Extending the linear model with R: generalized linear,
Chapman and

mixed effects and nonparametric regression models.
Hall/CRC, 2016.

[74] J. Feigenspan, S. Apel, J. Liebig, and C. Kastner, “Exploring software
measures to assess program comprehension,” in 2011 International Sym-
posium on Empirical Software Engineering and Measurement.
IEEE,
2011, pp. 127–136.

[75] B. Katzmarski and R. Koschke, “Program complexity metrics and
programmer opinions,” in 2012 20th IEEE international conference on
program comprehension (ICPC).

IEEE, 2012, pp. 17–26.

[76] P. F. Mihancea and R. Marinescu, “Discovering comprehension pitfalls
in class hierarchies,” in 2009 13th European Conference on Software
Maintenance and Reengineering.

IEEE, 2009, pp. 7–16.

[77] V. Sobreira, T. Durieux, F. Madeiral, M. Monperrus,

and
M. de Almeida Maia, “Dissection of a bug dataset: Anatomy of
395 patches from defects4j,” in International Conference on Software
Analysis, Evolution and Reengineering, SANER.
IEEE Computer
Society, 2018, pp. 130–140.

[78] J. Jiang, Y. Xiong, and X. Xia, “A manual inspection of defects4j bugs
and its implications for automatic program repair,” Sci. China Inf. Sci.,
vol. 62, no. 10, pp. 200 102:1–200 102:16, 2019.

[79] A. Perera, “Using defect prediction to improve the bug detection
capability of search-based software testing,” in IEEE/ACM Inter. Conf.
on Automated Software Engineering (ASE), 2020, pp. 1170–1174.
[80] D. Spadini, M. Aniche, and A. Bacchelli, “Pydriller: Python framework
for mining software repositories,” in ACM Joint Meeting on European
Software Engineering Conference and Symposium on the Foundations
of Software Engineering, 2018, pp. 908–911.

[81] D. A. Tamburri, F. Palomba, and R. Kazman, “Success and failure in
software engineering: A followup systematic literature review,” IEEE
Transactions on Engineering Management, 2020.

[82] G. Succi, W. Pedrycz, S. Djokic, P. Zuliani, and B. Russo, “An empirical
exploration of the distributions of the chidamber and kemerer object-
oriented metrics suite,” Empirical Software Engineering, vol. 10, no. 1,
pp. 81–104, 2005.

[83] G. Catolino, F. Palomba, D. A. Tamburri, and A. Serebrenik, “Under-
standing community smells variability: A statistical approach,” in Inter-
national Conference on Software Engineering: Software Engineering in
Society, 2021, p. 77–86.

[84] S. Lambiase, G. Catolino, D. A. Tamburri, A. Serebrenik, F. Palomba,
and F. Ferrucci, “Good fences make good neighbours? on the impact
of cultural and geographical dispersion on community smells,” in
IEEE/ACM International Conference on Software Engineering: Software
Engineering in Society (ICSE-SEIS). ACM, 2022, p. to appear.
[85] R. Wieringa and M. Daneva, “Six strategies for generalizing software
engineering theories,” Science of computer programming, vol. 101, pp.
136–152, 2015.

[86] S. Ghaisas, P. Rose, M. Daneva, K. Sikkel, and R. J. Wieringa,
“Generalizing by similarity: Lessons learnt from industrial case studies,”
in 2013 1st International Workshop on Conducting Empirical Studies in
Industry (CESI).

IEEE, 2013, pp. 37–42.

8

