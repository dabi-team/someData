e-GenIA3: An AgentSpeak extension for empathic agents

Joaquin Taverner1,âˆ—, Emilio Vivancos1, and Vicente Botti1
1Valencian Research Institute for Artiï¬cial Intelligence, Universitat Polit`ecnica de Val`encia, Spain
âˆ— Corresponding author: Joaquin Taverner (joataap@dsic.upv.es)

August 2, 2022

Abstract

2
2
0
2

g
u
A
1

]

A
M

.
s
c
[

1
v
7
3
7
0
0
.
8
0
2
2
:
v
i
X
r
a

In this paper, we present e-GenIA3 an extension of AgentSpeak to provide support to the development
of empathic agents. The new extension modiï¬es the agentâ€™s reasoning processes to select plans according to
the analyzed event and the aï¬€ective state and personality of the agent. In addition, our proposal allows a
software agent to simulate the distinction between self and other agents through two diï¬€erent event appraisal
processes: the empathic appraisal process, for eliciting emotions as a response to other agents emotions,
and the regular aï¬€ective appraisal process for other non-empathic aï¬€ective events. The empathic regulation
process adapts the elicited empathic emotion based on intrapersonal factors (e.g., the agentâ€™s personality and
aï¬€ective memory) and interpersonal characteristics of the agent (e.g., the aï¬€ective link between the agents).
The use of a memory of past events and their corresponding elicited emotions allows the maintaining of an
aï¬€ective link to support long-term empathic interaction between agents.

Keywordsâ€” Empathy, aï¬€ective computing, empathic regulation, appraisal, multi-agent systems

1

Introduction

Computer systems that are oriented to the paradigm of human-machine interaction are becoming more relevant in society.
Systems of this type are progressively becoming more complex and require higher level abstractions and metaphors to
describe capabilities and characteristics that cannot be explained by classical lower level speciï¬cations. Endowing
software agents with aï¬€ective abilities, particularly empathic abilities, is one of the metaphors that will make it possible
to improve the simulation of human aï¬€ective behavior and to transform the human-machine interaction paradigm by
making it more human-oriented. Empathy is a concept that has evolved over the years, whose meaning refers to a wide
range of aï¬€ective and cognitive competencies that are fundamental in the development of the human being as a social
being [32]. These competencies allow one â€œto put oneself in othersâ€™ shoesâ€ and to understand and share their feelings and
thoughts, which generates a series of pro-social behaviours aimed at improving their well-being [13]. In any empathic
interaction, we can distinguish two actors: the target actor, who is the person or agent that suï¬€ers the eï¬€ect of an action
or situation, and the observer, who is the person (or agent) that perceives that action or situation and feels empathy for
the target person.

Diï¬€erent theoretical approaches that try to explain the cognitive processes related to empathy have been proposed
in psychology, sociology, philosophy, ethology, and neuroscience. The most recent theoretical approaches provide a
conceptualization of empathy from a perspective derived from appraisal theories that relate the emergence of emotions
to a cognitive appraisal of an event [21, 36]. Under this perspective, empathy arises from the appraisal of the perception
of a situation or an emotion in others [30,78]. Moreover, according to several authors, empathy is aï¬€ected by a regulation
process that modulates the empathic response to an event according to diï¬€erent factors, including intrapersonal (e.g.,
personality) and interpersonal (e.g., aï¬€ective bond or social tie with the target) factors [10, 13, 16].

For years, the inherent characteristics of human aï¬€ective behavior have been the subject of research in the ï¬eld of
aï¬€ective computing [51]. In this ï¬eld, there has been a growing trend towards the development of models to simulate
empathy [50, 80]. Most of these models use the agent-oriented paradigm. Empathic agents have been shown in multiple
experiments to improve the user experience in human-machine interactions [46, 47, 61].
In general, these models are
designed to be implemented ad hoc making the agent speciï¬cation programmer and domain dependent.

This paper presents e-GenIA3, an extension of the syntax, semantics, and the reasoning cycle of the well-known
agent-oriented language AgentSpeak [56] to support the development of agents with empathic abilities implemented on
the GenIA3 architecture [2]. Our model is based on recent empathic appraisal theories to elicit empathic emotions when
a software agent perceives or is aware of an emotion or a situation in other agents or humans. In addition, our empathic
agent model has an emotion regulation process that adapts emotions to diï¬€erent intrapersonal and interpersonal factors.
The rest of this paper is organized as follows. In Section 2, theoretical frameworks supporting aï¬€ective states and
empathy along with a discussion of proposals made in aï¬€ective computing to simulate aï¬€ective and empathic capabilities
are presented. Section 3 describes the GenIA3 architecture. Section 4 introduces e-GenIA3, an AgentSpeak extension to
facilitate the development of agents with empathic abilities. In Section 5 a default design for all the processes described
in Section 4 is presented. Finally, the main conclusions and some future works are presented in Section 6.

1

 
 
 
 
 
 
2 Related work

For years, the area of aï¬€ective computing [51] has been working to design models to understand and simulate non-rational
behaviors such as aï¬€ective behaviors [39, 50, 73]. These models generally include diï¬€erent constructs such as aï¬€ective
states, personality, or empathy that come from diï¬€erent branches of psychology, ethology, philosophy, and sociology.
Over the years, diï¬€erent theorist have tried to provide an answer to the phenomenon of aï¬€ective states, which involves
constructs such as emotions and moods. One of the most recognized theories is the appraisal theory [21,36], according to
which, when a stimulus is received, an appraisal process occurs, resulting in an emotion. Emotion is generally considered
to be a quick response to certain stimuli with short duration. Appraisal theory is based on the existence of diï¬€erent
variables known as Appraisal Variables. Diï¬€erent authors diï¬€er in the number and type of Appraisal Variables involved
in the emotion generation process. For example, K.R. Scherer [65] proposed a model in which twenty-two Appraisal
Variables were deï¬ned, while A. Ortony, G. Clore, and A. Collins [48] proposed a more simpliï¬ed model, known as
OCC, with only eight Appraisal Variables. However, appraisal theory is not the only theory that has been developed
to explain the phenomenon of emotion. Basic emotion theories relate events to a limited number of emotions. For
example, the basic theory of emotions proposed by P. Ekman [19] uses six basic emotions: Happiness, Surprise, Fear,
Anger, Disgust, and Sadness. In contrast to these basic emotion theories, the constructivist theories advocate for a more
universal concept of emotion. Constructivism holds the existence of an unlimited number of emotions which can present
cross-cultural diï¬€erences [63]. One of the most recognized constructivists is J.A. Russell who proposed the Circumplex
Model of Aï¬€ect [62]. According to Russell, emotions can be expressed in a two-dimensional space that is composed of
the dimensions of Pleasure and Arousal. This theory is in line with the ï¬ndings of neuroscience made in recent years [53].
More recent theories suggest the need to use models with more dimensions, such as Dominance or Novelty, to better
explain the diï¬€erences between emotions [44, 66].

On the other hand, it is generally accepted that, in contrast to emotions, moods are unfocused and diï¬€use aï¬€ective
states that have a longer duration (from minutes to days) and a lower intensity than emotions [6]. The variation in mood
duration is sometimes attributed to the time the mood spends in transitioning to a neutral state or equilibrium state [31].
Both the equilibrium state and the speed of transition may vary depending on the individualâ€™s aï¬€ective characteristics.
Moreover, it should be considered that both emotions and mood are inï¬‚uenced by personality [64]. Empirical evidence
suggests that personality is involved in emotion regulation processes making individuals more or less prone to certain
emotions or moods [18, 76]. One of the most recurrent theories of personality is the OCEAN model [42]. This model
deï¬nes personality through ï¬ve dimensions: Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism.
These ï¬ve dimensions have an eï¬€ect on the aï¬€ective states that can be elicited in an individual. Apparently, the most
evident relationships arise when relating positive aï¬€ective states to Extraversion and when relating negative aï¬€ective
states to Neuroticism [17].

Finally, empathy is a construct that is used in diï¬€erent domains, such as psychology, ethology, sociology, or philosophy,
to describe a variety of psychological attitudes that enable the development of social individuals, encompassing a large
number of emotional, ethical, moral, and social aspects [11, 49].
In general terms, empathy is an ability that allows
humans to understand and feel the aï¬€ective state of others, resulting in behavior directed toward mutual understanding.
Several authors consider empathy to be a fundamental ability that allows the establishment and maintenance of social
bonds [33,59,67]. Empathy also plays a fundamental role in our society, aï¬€ecting both morality and mutual understanding
and promoting relationships and collaborations through the exchange of experiences, needs, and desires [13, 40].

In its earlier deï¬nition, empathy was described as an innate instinct that produces a self-awareness in the experience
and awareness of the target in the observer without any perspective-taking, associative, or cognitive process [24, 70].
This concept evolved over the years in diï¬€erent theories until the discovery of mirror neurons [60], which established a
relationship between perception and action allowing a greater understanding of how imitation and empathy are produced
in the brain and are related to emotion experiences [20, 35]. Based on this relationship between perception and action,
S.D. Preston and F. De Waal [55] proposed a theory of empathy known as the Perception Action Model (PAM). According
to the PAM, when the observer perceives an emotion in the target, he/she can experience the same emotion automatically
and not consciously, producing a matching of mental states between the observer and the target [54]. The PAM is used
as a basis for explaining the evolution of higher-level cognitive processes related to cognitive empathy. For example, De
Waal proposes the The Russian Doll model [15]. This model uses the analogy of a Russian doll, stratifying the empathic
processes in diï¬€erent layers. The inner layers represent the most primitive mechanisms of empathy related to the PAM
such as mimicry or emotional contagion. The top layers represent higher level processes such as perspective-taking.
Nonetheless, contemporary theories argue that, if empathy was an automatic process resulting from direct perception
as suggested by the PAM, then humans would be constantly empathizing [14, 30]. However, there are situations in
which empathy is inhibited. This inhibition is produced by an adaptation resulting from a cognitive process known
as empathic regulation. For instance, professionals in psychiatry are able to distance themselves from the patientâ€™s
emotions [29]. Factors that inï¬‚uence empathy regulation have been widely discussed in academia [14, 15, 55, 78].
In
general, these regulation factors can be grouped into three categories: i) factors related to the internal characteristics
of the observer such as personality, mood, age, life experiences, or gender [26]; ii) situative context factors such as the
existence of more than one target suï¬€ering diï¬€erent experiences, which makes it diï¬ƒcult to empathize [14]; and iii)
factors concerning the level of relationship between the observer and the target [14]. This last category encompasses
diï¬€erent interpersonal factors such as: similarity, which are the perceived similarities between the observer and the
target (e.g., gender, personality, mood, or age); familiarity, which is related to the observer â€™s previous experiences with
the target in similar situations; and the level of relationship [14] (or social tie [4]) between the observer and the target
derived from the interactions they have over time [16] (henceforth referred to as aï¬€ective link in order to facilitate the
reading of this paper).

2

New advances address the phenomenon of empathy from an appraisal theory perspective [10,13,30,77,78]. Under this
perspective, empathy is related to higher-level cognitive processes such as other-oriented perspective-taking, self-oriented
perspective-taking, and Theory of Mind [77] (which holds that people are able to understand the mental states of others
thanks to a system of rules based on their own experiences [23, 29]). These cognitive processes require the observer
to have knowledge of aï¬€ective and non-aï¬€ective information about the target (e.g., beliefs, desires, and goals) [28]. In
addition, empathy does not always requires the observer to perceive the targetâ€™s aï¬€ective states but is described as a
process of higher-level understanding of the targetâ€™s situation that allows the emergence of other aï¬€ective experiences
(e.g., when we rejoice because someone has achieved a goal) [3, 49].

2.1 Empathy in software agents

The relationship of empathy with social behavior and interpersonal relationships has aroused the interest of many
researchers who focuses on the areas of human behavior simulation and human-machine interaction [37, 47, 68]. Systems
that are capable of simulating aï¬€ective and empathic abilities have been used in diï¬€erent contexts and have proved to
be more reliable and more credible [1, 12, 50]. Most of these proposals are focused on the agent-oriented programming
(OAP) paradigm to develop agents with empathic abilities. For example, in the study conducted in [46], a robot with
empathic abilities was used in an educational environment. The study determined that the empathic robot was able to
elicit and maintain the social engagement of the participants of the experiment. Similarly, the experiments conducted
with empathic agents in [47] showed that participants had a better perception of the agent when it displayed empathic
emotions. Also, the research performed in [61] showed that agents with empathic abilities increased the involvement and
sociability of participants. Therefore, considering these results, it is not surprising that, in the search for improvement
in the simulation of human behavior and human-machine interaction, diï¬€erent proposals for computer systems with
empathic abilities have appeared over the years. For example, Â¨O.N. YalÂ¸cÄ±n and S. DiPaola [79] introduced a model of an
empathic agent, based on The Russian Doll model, composed of three layers. In the bottom layer, the communication
competence contains the processes related to the recognition and the expression of emotions. The middle layer represents
emotion regulation processes. Finally, the top layer, called cognitive mechanisms, includes Theory of Mind and appraisal.
Another interesting approach is proposed in [58]. Authors present a model for an empathic agent that was based
on the perception of the targetâ€™s emotion to simulate an empathic interaction. The system has a perception layer that
recognizes human emotional facial expressions. Then, the system makes an estimation of the empathic emotion by means
of a regulation process that uses the agentâ€™s personality and mood as regulation factors. They use the mapping proposed
in [43] to establish the relationship of personality and mood in a two-dimensional space that is based on Pleasure and
Arousal.

Other models focus more on the simulation of empathy through the simulation of high-level cognitive processes. For
instance, the model presented in [61], which also relies on the theory of De Vignemont and Singer to deï¬ne the empathic
process [14], focuses on the self-projection appraisal based on OCC to elicit the empathic emotion. The appraisal process
is based on a set of predeï¬ned rules that deï¬ne the relationship of events to desirability. The elicited emotion is adapted
by using the aï¬€ective link, similarity, mood, and personality in an empathic regulation process. Similarity is obtained
by comparing the intensity and valence of both the perceived and the elicited emotions. Personality is composed of
a set of thresholds for each emotion. However, these factors only aï¬€ect the intensity of the emotion elicited in the
empathic appraisal. Another example of the simulation of cognitive processes can be found in [47] in which a model of
an embodied empathic dialogue agent is presented. The purpose of this agent was to simulate an empathic interaction
with human users. The agent deduced the userâ€™s emotions through the dialogue using a perspective-taking strategy and
then responded by showing the same emotion. The agent was able to regulate the intensity of the empathic emotion
based on a preset degree of empathy between the agent and the user. Experiments conducted with the agent showed
that participants had a better perception of the agent when it displayed empathic emotions.

Diï¬€erent authors have emphasized the need to consider the inclusion of long-term interactions to improve the sim-
ulation of empathic interactions [38, 50]. However, not much work has been done on this topic. For instance, in [37] a
model of empathy based on emotion recognition is proposed. The system is based on a robot called iCat that interacts
with children while playing chess. The iCat maintains the actions that children perform in chess moves in its memory
and uses this information to determine the next move taking into account the childrenâ€™s emotions.

From what has been explained above, it can be deduced that most of the models of agents with empathic abilities
use three fundamental processes: i) a perception process, in which an emotion or situation is perceived; ii) an empathic
appraisal process, in which an empathic emotion is elicited; and iii) an empathic regulation process, in which the empathic
emotion is adapted to diï¬€erent regulation factors. Unfortunately, most of the works described above propose ad hoc
methods to simulate a certain level of aï¬€ective and empathic abilities, making the agent speciï¬cation highly dependent on
the programmer and diï¬ƒcult to generalize to other domains. The use of a commonly-used agent-oriented programming
language can help to improve the development of empathic agents. In addition, these languages generally include support
for processes such as perception, multi-agent communication, and rational behavior. One of the most well-known agent-
oriented programming languages is AgentSpeak [56]. AgentSpeak is a language that is based on the logic programming
paradigm for developing agents using a BDI (beliefs, desires, and intentions) architecture. In a BDI architecture, agents
are deï¬ned as intentional systems where an agent is provided with a set of mental attitudes. BDI agents are composed
of a set of beliefs, desires and intentions. Beliefs represent the information that the agent has about the state of its
environment. Desires are goals that the agent wants to achieve. Intentions are commitments made by the agent, i.e.
those goals that the agent selects to achieve. The BDI architecture provides the basis for the development of agents based
on practical reasoning. Practical reasoning is an inference process through which agents evaluate and weigh their options
taking into consideration the context of the practical situation in which they are involved and their knowledge about

3

the environment. The result of this inference process is the modiï¬cation, deletion, or addition of beliefs and intentions,
altering the mental state of the agent. There are some approaches that have used the BDI model to design agents with
aï¬€ective capacities [2,9]. For example, in [27] an appraisal process based on the OCC model for eliciting emotions in BDI
agents is proposed. Another interesting proposal is presented in [1], in which a logical formalization for emotion elicitation
in BDI agents based on OCC theory is presented. In the same way, a formal extension of the KARO framework [45]
is proposed in [69] to elicit emotions in BDI agents following the OCC theory. Regarding empathy and social abilities,
FAtiMA, an architecture for the development of aï¬€ective BDI agents, is proposed in [41]. This architecture uses an
appraisal model based on the OCC theory for the development of empathic agents. Another interesting approach can be
seen in [9] in which an embodied virtual agent model with empathic abilities known as EMMA (Empathic MultiModal
Agent) is presented. In that model, an agent is essentially composed of a reasoning module and an empathic module.
The reasoning module is based on the BDI architecture [57]. The empathic module has a facial expression recognition
system and an empathetic appraisal process that is based on the De Vignemont and Singer theory [14]. To estimate
the empathic emotion, the agent attempts to internally mimic the recognized facial expression using a set of patterns
called Action Units (UAs). Subsequently, the emotion is regulated in an emotion regulation process that is based on the
Pleasure-Arousal-Dominance (PAD) model [44]. This process modiï¬es the PAD components of emotions by means of a
set of regulation factors that include similarity, mood, and deservedness (which represents the degree to which the target
deserves or does not deserve the event).

Although there are several proposals extending AgentSpeak with diï¬€erent features [7, 8, 75], there are very few
proposals that use it when deï¬ning aï¬€ective or empathic agents. For instance, in [34], an empathic agent model based on
AgentSpeak is presented for the resolution of conï¬‚icts of interest in interactions between agents. However, this approach
focuses on utility-based functions to ï¬nd solutions that are mutually acceptable, but no aï¬€ective characteristic of the
agents is considered in the utility functions. One of the most signiï¬cant eï¬€orts to allow the use of aï¬€ective agents in
AgentSpeak is the GenIA3 architecture [2]. GenIA3 is a general-purpose architecture that extends AgentSpeak providing
a platform that is easily adaptable to diï¬€erent theories of emotion in order to facilitate the development of aï¬€ective agents.
GenIA3 adds new processes for the management of aï¬€ective states, which are described in detail in Section 3. However,
before the work presented here, this architecture did not provide the necessary support to the development of agents
with empathic abilities.

3 The GenIA3architecture

The GenIA3 architecture implements an extension of the syntax and operational semantics of the agent-oriented language
AgentSpeak [56]. This architecture is based on a modular design that can be easily adapted both to diï¬€erent psychological
and neuroscience theories and to diï¬€erent domain-speciï¬c aï¬€ective characteristics (e.g. personality or mood). To this
end, GenIA3 uses general components (described below) to integrate the aï¬€ective processes and characteristics with in
the cognitive process of a BDI agent. GenIA3 oï¬€ers a ï¬‚exible approach that allows aï¬€ective processes to inï¬‚uence the
agentâ€™s behavior by, for example, modifying goal priorities and/or generating new intentions. In GenIA3, an agent is
deï¬ned with its own personality, mood, and concerns (i.e., interests, motivations, ideals, or standards). This factors will
inï¬‚uence the agentâ€™s behavior by prioritizing its goals or generating new goals. The agentâ€™s concerns together with the
desirability of an event are used for the agent to decide whether the event is aï¬€ective or not. Additionally, the agent also
categorizes events and plans as aï¬€ective using the annotation affective relevant (see Section 4.3 for the deï¬nition
of annotations in AgentSpeak). Plans can also be deï¬ned using the agentâ€™s personality proï¬le or the aï¬€ective state (or
aï¬€ective states) as preconditions for triggering the plans. One of the main advantages of this architecture is the ability
to prioritize the aï¬€ective or the BDI reasoning cycles. In contrast to other aï¬€ective agent architectures such as FAtiMA,
GenIA3 facilitates the establishment of a balance between the aï¬€ective and the rational reasoning cycles. One of the
personality parameters of a GenIA3 agent is the rationality level, which can be speciï¬ed by the programmer or estimated
automatically from the values of the personality. This parameter allows to establish the priority ratio between the agentâ€™s
practical reasoning processes and the aï¬€ective processes. GenIA3 also allows to specify how, the changes that occur in
the agentâ€™s aï¬€ective state, generate behaviors through an explicit and integrated coping model (see [2] for more details
about the coping process of GenIA3).

The reasoning BDI cycle of GenIA3 works as follows: ï¬rst, in the process message (ProcMsg) step, all of the pending
messages received by the agent are processed; then, the select event (SelEv) step selects one event to be processed taking
into account all of the perceptions, messages, and stacked events. Next, the relevant plans (RelPl) step retrieves all
of the relevant plans considering the selected event; these plans are used to generate a list of applicable plans in the
applicable plans (ApplPl) step. From this list, one applicable plan is selected in the select applicable plan (SelAppl)
step. Then, in the add intended means (AddIM) step, all of the intended means are added to the set of intentions; the
select intention (SelInt) step selects one intention to be executed from the set. The selected intention is executed in the
execute intention (ExcInt) step. Finally, the executed intention is cleared from the set of intentions in the clear intention
(ClrInt) step.

GenIA3 introduced a new aï¬€ective cycle that consist of ï¬ve steps (dark gray shaded boxes in Figure 5) the event
appraisal (Appr) step in which the selected event is appraised; the aï¬€ect adaptation (AffAd) step in which the agentâ€™s
mood is modiï¬ed to adapt the mood according to the result of the appraisal emotion; the select coping strategies (Selcs)
step in which the coping strategies are selected according to the agentâ€™s mood; and the cope (Cope) step, in which
the coping strategies are executed. In addition, GenIA3 incorporates an aï¬€ective state decay process (AsDecay) that
continuously shifts the mood toward an equilibrium state to simulate real mood change in humans. The rate at which
the mood moves to the equilibrium state can be set by the user. Finally, GenIA3 modiï¬ed the AgentSpeakâ€™s rational cycle

4

Figure 1: Participants involved in an empathic event.

to add two new steps: the aï¬€ective modulation of beliefs (AffModB) step in which beliefs are modiï¬ed according to the
agentâ€™s mood; and the evaluate expectations (EvalExp) step, which includes the possibility to add temporal expectations
to agents [72]. GenIA3 allows to modify the agentâ€™s behavior to simulate aï¬€ective behaviors. For this purpose, GenIA3
modiï¬es the selection of applicable plans, considering the agentâ€™s rationality level. GenIA3 uses two separate sets of
applicable plans: a set of applicable plans R selected by the BDI practical reasoning cycle, which considers the beliefs
and desires and intentions of the agent; and a set of applicable plans A that, in addition to beliefs, desires, and intentions,
also consider, agentâ€™s concerns and aï¬€ective characteristics such as personality, emotion, or mood. Subsequently, the
ï¬nal applicable plan is selected, in the select applicable plan (SelAppl) step, using the equation:

applicable plan = arg max
pâˆˆ(R âˆª A)

(cid:26)Priority(p) Â· rl,

Priority(p) Â· (1 âˆ’ rl ),

if p âˆˆ R
if p /âˆˆ R

(1)

that considers the priorities Priority(p) of the plan p âˆˆ (R âˆª A) and the rationality level rl of the agent.
To facilitate the development of aï¬€ective agents, GenIA3 incorporates a default design that can be adapted by
advanced users interested in customizing the behavior of the agent. In this default design, the user can choose between
two diï¬€erent appraisal models: a model based on OCC theory [48] that uses the appraisal variables deï¬ned in [39]
(i.e., desirability, likelihood, and causal attribution) using a numerical approach; and a model based on Schererâ€™s theory
using fuzzy logic to deï¬ne the appraisal rules [74]. GenIA3 also oï¬€ers the possibility of selecting between two models
of representation of aï¬€ective states: a model based on the PAD [44] described in [2]; and a multidimensional culturally
adapted representation of emotions presented in [73]. Finally, in this default design, the personality is deï¬ned by the
OCEAN model [42].

4 e-GenIA3 an AgentSpeak extension for empathic agents

In this section, we present e-GenIA3 an extension of the syntax, semantics, and the reasoning cycle of an AgentSpeak
agent to support the development of agents with empathic abilities. This extension allows emotions and empathy to have
an eï¬€ect on the practical reasoning of the agent. Emotions and empathy will be involved in an aï¬€ective cycle that will
aï¬€ect that will aï¬€ect the agentâ€™s reasoning processes. To do that, we have extended the GenIA3 architecture with a new
syntax and semantics to facilitate the emergence of empathy in software agents. e-GenIA3 includes the three fundamental
processes identiï¬ed in the literature on empathic agents discussed in Section 2.1: perception, empathic appraisal, and
empathic regulation (see Figure 5). The perception process is an intrinsic part of AgentSpeak. However, we have added
a new process to diï¬€erentiate empathic aï¬€ective events from other aï¬€ective events, the event classiï¬cation (EvClass)
process. This process consists of two phases. In the ï¬rst phase, an event is perceived following the process described
in [8]. In the second phase, the event is evaluated to determine whether or not it is an aï¬€ective event. This second phase
deï¬nes the agentâ€™s cognitive ability to maintain a sense of self as distinct from the target agent to elicit a target-oriented
empathic emotion. This cognitive ability is simulated using two diï¬€erent appraisal processes: one for empathic events
(EmphAppr) and the other for non-empathic aï¬€ective events (Appr). On the other hand, empathic appraisal is composed
of a self-projection appraisal, which evaluates the event using the agentâ€™s own beliefs, concerns, and aï¬€ective memory.
The empathic regulation process (EmphReg) adapts the empathic emotion to the agentâ€™s aï¬€ective characteristics (e.g.,
mood or personality) and the knowledge that the agent has about the target (e.g., aï¬€ective link or trust level). Finally,
the emotion selection process (EmSel) selects the most appropriate emotion.

4.1 A simple example

From the theories of empathy previously cited, it can be assumed that, for empathy to occur, there must be at least two
actors: one who suï¬€ers in a situation (the target) and another who perceives the situation and reacts empathetically
(the observer or empathic agent). To make the reading more convenient, we illustrate the problem with an example. Let
us assume a more general scenario with three actors: Marshall, Lily, and Barney. At one point in time Marshall slaps
Barney in the face. This event causes Barney to become sad. Lily, who is in the same room, sees the entire scene and
empathizes with Barney and feels sorry for what has happened to him.

In this scenario, there are basically two interactions: ï¬rst, Marshall performs an action directed to Barney; second,
Lily perceives what has happened to Barney. Three diï¬€erent roles of agents can be identiï¬ed in these interactions.
Marshall, the agent that performs the action, henceforth known as the subject agent; Barney, the agent that receives the
consequences of the action, henceforth known as the target agent; and Lily, who perceives the action, henceforth known
as the observer agent, and that can potentially empathize with the target of the event.

5

TargetSubjectActionObserverMarshallBarneyLilySlapFigure 2: e-GenIA3 agent conï¬guration.

4.2 Formalization of an empathic agent

In [56], the agent-oriented language AgentSpeak semantics is deï¬ned using an operational semantics formalism. This
operational semantics deï¬nes the structure and the conï¬guration of the agent program and the transitions derived from
its internal reasoning. In this section, we extend this operational semantics to deï¬ne the new e-GenIA3 conï¬guration for
empathic agents.

Figure 2 shows the new conï¬guration of a e-GenIA3 agent. The dark gray shaded attributes are the ones that
GenIA3 added to the original conï¬guration proposed for AgentSpeak in [7]. The light gray shaded attributes represent
the new components of e-GenIA3 to add information that is relevant to the development of empathic agents. In this
new conï¬guration, an agent is deï¬ned by a tuple (cid:104)ag, C, M, T, s, Mem, Ta, O, ast(cid:105), where:

â€“ ag is the set of attributes that constitute the agent deï¬ned by the tuple (cid:104)P, ps, cc, bs(cid:105), where:

â€“ P is the agentâ€™s personality represented by the tuple (cid:104)tr, rl, cs(cid:105), where:

â€“ tr is a set of personality traits. Each personality trait is a value representing the level that the agent
has of that personality trait. For example, when using the OCEAN model, ï¬ve personality traits are
deï¬ned, one for each component of the OCEAN model.

â€“ rl is a value representing the agentâ€™s rationality level. The higher the rationality level, the higher the
priority of plans activated in a rational BDI cycle, making the agent more rational. However, the lower
the rationality level, the higher the priority of plans activated by the aï¬€ective cycle, making the agent
more emotional.

â€“ cs is the agentâ€™s set of coping strategies. These coping strategies relate aï¬€ective states and beliefs to a

set of intentions that will be included in the agentâ€™s agenda.

â€“ ps and bs represent the set of plans and the set of beliefs of the agent, respectively.

â€“ cc is the set of concerns of the agent that represents the motivations, standards, ideals and/or interests of

the agent.

â€“ C is the current circumstance represented by a tuple composed of: I, which is the set of intentions {i, i(cid:48), Â· Â· Â· };
E, which is a set of events composed of a set of tuples (cid:104)triggering event te, intention i(cid:105); and A, which is a set of
actions {a, a(cid:48), Â· Â· Â· }.

â€“ M are the communication parameters represented by the tuple (cid:104)In, Out, SI(cid:105), where In and Out represent the list
of input and output messages, respectively and SI is a set of suspended intentions composed by a set of tuples
(cid:104)message identiï¬er mid, intention i(cid:105). Each message msj is composed of the message identiï¬er mid, the identiï¬er
of the agent which sent the message id (i.e., the sender agent), the illocutionary force ilf, and the message content
cnt.

â€“ T is the temporary information of the current rational cycle consisting of a tuple containing: an applicable plan
Ï, a particular intention Î¹, the sets of relevant plans R, the set of applicable Ap plans composed of a set of plans
{p, p(cid:48), Â· Â· Â· }, and the event Îµ that triggered the rational cycle represented by a tuple (cid:104)triggering event te, intention i(cid:105).

â€“ s is the current step of the rational cycle where:

s âˆˆ {ProcMsg, AffModB, EvalExp, SelEv, RelPl,

ApplPl, SelAppPl, AddIm, SelInt, ExcInt, CrlInt}

(2)

â€“ Mem is the aï¬€ective memory that, in the original GenIA3 architecture, consists of a set of events. In e-GenIA3,
it consists of a set of aï¬€ective events ae. An aï¬€ective event ae is deï¬ned as a tuple (cid:104)event Îµ, aï¬€ective value av(cid:105),
where the aï¬€ective value av is an attribute that represents the emotion that the event Îµ produced in the agent.

â€“ Ta represents the temporal information of the aï¬€ective cycle and is composed of: Ub, which is a tuple containing
the set of beliefs that are going to be added to the belief base Ba, the set of beliefs that are going to be removed
from the belief base Br, and the identiï¬er of the step st of the cycle in which the beliefs are going to be added or
removed; Av, which is the set of appraisal variables; Cs, which is the set of coping strategies to be executed; Ae,

6

ğœ€âƒ—eâŸ¨ag,     C,     M,     T,     s,     Mem,     Ta,     O,     astâŸ©   âŸ¨P,ps,cc,bs âŸ© âŸ¨I,E,A âŸ© âŸ¨In,Out,SI âŸ© âŸ¨ğœŒ,ğœ„,R,Ap,ğœ€ âŸ© {ae,aeâ€™,â€¦} âŸ¨Ub,Av,Cs,Ae,Ee,Fe,ğœ âŸ©    âŸ¨tr,rl,cs âŸ© {i,iâ€™,â€¦}     {a,aâ€™,â€¦}      {p,pâ€™,â€¦}                  âŸ¨ ,av âŸ©  âŸ¨Ba,Br,st âŸ©      {âŸ¨te,i âŸ©,âŸ¨teâ€™,iâ€™ âŸ©,â€¦} {msj,msjâ€™,â€¦} {âŸ¨mid,i âŸ©,âŸ¨midâ€™,iâ€™ âŸ©,â€¦} p,ğœƒâŸ¨te,i âŸ©                     âŸ¨mid,id,ilf,cnt âŸ©                      {  ,   â€™,â€¦}          {âŸ¨id,al,ğœ âŸ©,âŸ¨idâ€™,alâ€™,ğœ âŸ©,â€¦}âƒ—eâƒ—eâƒ—Ïƒâƒ—Ïƒâƒ—Ïƒwhich is the set of emotions that can be elicited by the appraisal process; Ee, which is the set of empathic emotions
that can be triggered by the empathic appraisal process; Fe, the ï¬nal emotion (or emotions) resulting from the
emotion selection process; and (cid:126)Ïƒ, which represents the current mood of the agent. The emotions contained in Fe
will be the ones considered as active in the aï¬€ective cycle. Emotions and mood are represented by a n-dimensional
vector (cid:126)e. For example, for the PAD model, this vector will have three components (i.e. one for each dimension).

â€“ O is a new component which is added to represent the information that the empathic agent knows about other
agents in the environment. This information is composed of a set of tuples each of which corresponds to one agent
in the environment. Each tuple contains the agent identiï¬er id, the aï¬€ective link al that the empathic agent has
with the agent identiï¬ed by id, and the id agentâ€™s mood (cid:126)Ïƒ. This tuple can be extended in the future to contain
more knowledge about agents in the environment, such as their concerns, goals, beliefs, or trust level. The aï¬€ective
link is a value that indicates the aï¬€ective link between both agents. The greater the aï¬€ective link value, the greater
the relationship between the agents. Negative aï¬€ective links indicate enmity between the agents. The aï¬€ective
link can be modiï¬ed due to the interactions between the agents.

â€“ ast is the current step of the aï¬€ective cycle, where:

ast âˆˆ {EvClass, Appr, EmphAppr, EmReg,

EmphReg, EmSel, AffAd, SelCs, Cope}

(3)

4.3 Extending the AgentSpeak language to identify the actors of an empathic

interaction

In AgentSpeak, an agent is deï¬ned as a set of beliefs and a set of plans. The knowledge contained in the belief base
may not necessarily be complete or accurate, since the environment may be very large and may experience changes that
the agent has not perceived. On the other hand, plans contain basic actions that the agent can perform to change its
environment. Plans are composed of a triggering event, a context, and a set of sequential instructions that may include:
updates to the belief base, actions, or goals. Triggering events refer to the addition or deletion of beliefs or goals. In
AgentSpeak, both beliefs and goals are deï¬ned as atomic formulas [56]. An atomic formula representing a belief or a
goal is composed of a predicate and a set (possibly empty) of n terms of a ï¬rst order logic:

predicate(term1, term2, Â· Â· Â· , termn)

(4)

For example, the triggering event time(cloudy) is composed of the predicate â€˜timeâ€™ and the term â€˜cloudyâ€™.
In [75] and [7], the concept of annotation was added to AgentSpeak to provide the ability to express properties

associates with events and beliefs. The syntax for an atomic formula with annotation in AgentSpeak is:

where each ai represents the ith annotation deï¬ned as:

predicate (term1, term2, Â· Â· Â· , termn) [a1, a2, Â· Â· Â· , am]

ai = functori

(cid:0)term(cid:48)

i,1, term(cid:48)

i,2, Â· Â· Â· , term(cid:48)

i,n

(cid:1)

(5)

(6)

where an atom (called functor) is followed by a number of terms (called arguments). term(cid:48)

i,j is the jth term of the

annotation ai.

This extension of the language provides more expressiveness to AgentSpeak allowing diï¬€erent types of properties to
be deï¬ned. For example, we can add one annotation to an event to represent the sources of the event. The keyword that
we use to represent this annotation is â€sourceâ€. For example, in the triggering event:

time (cloudy) [source(Marshall)]

the annotation source(Marshall) indicates that the source of the triggering event is the agent Marshall.
In general, there are three possible sources for an event:

â€“ perceptions, which represent the information that the agent perceives from its environment. Perceptions are

represented by the annotation source(percept).

â€“ mental notes, which represent beliefs that the agent acquires or deduces by itself, such as memories or changes in

the agentâ€™s state. The mental notes are expressed through the annotation source(self).

â€“ communications, which is the information that comes from another agent of the system as a consequence of a

communication act.

In our proposal, we have extended AgentSpeak with new annotations that allow the events with relevant information
for empathy to be contextualized for its simulation. As we discussed in Section 2, the empathic regulation process is
aï¬€ected by a set factors that include interpersonal factors related to the target agent such as the aï¬€ective link, concerns,
goals, similarity, or trust level. Therefore, to elicit an empathic emotion, it is necessary to identify the target agent when
an event occurs. This information can be implicit in the semantics of the event, in which case the agent may deduce the

7

target of the action through an inference process, or it can be explicitly incorporated into the syntax of the triggering
event. We have used this second approach because it simpliï¬es the agentâ€™s programming by easily identifying the subject
and the target of an event. We have extended the representation of a triggering event to explicitly include the agents
involved in an action (i.e., subject and target agents) without modifying the original syntax of the atomic formula of
AgentSpeak. This has been achieved using two annotations to identify the agents participating in the action represented
by the triggering event: the subject annotation, which identiï¬es the subject agent that performs the action; and the
target annotation, which identiï¬es the target agent receiving the consequences of the action. Following this deï¬nition,
a triggering event will be represented by the structure:

predicate (term1, term2, Â· Â· Â· , termn)
[subject(subject
id), target(target

id), a3, a4, Â· Â· Â· , an]

(7)

id and target

where subject

id are the identiï¬ers of the subject agent and the target agent, respectively. Note that,
the order in which the annotations are deï¬ned is not relevant since the annotations can be written in any order. By
adding these new annotations, it is now possible to identify the agents involved in any action. Based on the example of
Section 4.1, we can use the following expression to specify the triggering event â€œMarshall has slapped Barneyâ€:

slap[subject(Marshall),target(Barney)]

This event has a predicate â€œslapâ€ and two annotations: subject(Marshall) and target(Barney). Moreover, we
propose adding an optional annotation to include the value of the interaction. The interaction value of a triggering
event is an optional number that is associated with the triggering event in the range of [âˆ’1, 1], which identiï¬es if the
interaction is good (positive interaction value), bad (negative interaction value), or neutral (interaction value equals 0)
for the agent that receives the action. The interaction value is used to update the aï¬€ective link between the agents. A
positive interaction value indicates that the interaction has a positive eï¬€ect on the aï¬€ective state of the target agent,
improving the aï¬€ective link that the target agent has with the subject agent. A negative interaction value has a negative
impact in the agentâ€™s aï¬€ective state and decreases the aï¬€ective link. An interaction value equal to 0 denotes that the
interaction has a neutral eï¬€ect on the aï¬€ective state of the agent. Therefore, it has no eï¬€ect on the aï¬€ective link. Note
that, if necessary, the interaction value can also be deduced automatically by the agent through the appraised emotion
(for instance, considering the level of pleasure of the generated emotions) or through an internal inference process.

We have introduced new functions to handle the annotations that will be used in Section 4.4 to formalize the new
internal processes of the aï¬€ective cycle of an agent. First, the function to obtain the subject agent of a triggering event
te is deï¬ned as:

getSubject(te) :=

self,

ï£±

ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£³

termi,

null,

if âˆƒ ai âˆˆ teannots : functori =
â€˜subjectâ€™and termi (cid:54)= ag id
if âˆƒ ai âˆˆ teannots : functori =
â€˜subjectâ€™and termi = ag id
otherwise

(8)

where teannots is the set of annotations associated to the triggering event te, ai is the ith annotation of the set of
annotations teannots, functor is the functor of the annotation ai, termi is the term of the annotation ai, â€˜subjectâ€™ is
a keyword that identiï¬es the subject annotation, and ag id is the agentâ€™s identiï¬er. If termi is equal to the ag id, it
indicates that the triggering event comes from the agent itself. If termi is not the ag id, it indicates that the triggering
event comes from another agent. Finally, if there is no â€˜subjectâ€™ annotation, it indicates that this triggering event
comes from an unknown subject.

Similarly, the target of a triggering event te is obtained through the function:

getTarget(te) :=

ï£±
ï£²

termi,

ï£³

null,

if âˆƒ ai âˆˆ teannots : functori =
â€˜targetâ€™
otherwise

where â€˜targetâ€™ is a keyword that identiï¬es the target agent annotation.
Finally, to obtain the interaction value of the triggering event te, we deï¬ne the function:

getIV(te) :=

ï£±
ï£²

termi,

ï£³

0,

if âˆƒ ai âˆˆ teannots :
functori = â€˜InteractionValueâ€™
otherwise

(9)

(10)

where â€˜InteractionValueâ€™ is a keyword that identiï¬es the annotation that contains the interaction value.

8

agent

â†’ init beliefs [concerns] [personality] [others info] init goals plans

others info â†’ â€˜others__:â€™ â€˜[â€™ other ( â€˜,â€™ other )* â€˜]â€™
other
ag id

â†’ ag id â€˜:â€™ â€˜[â€™ list attr â€˜]â€™
â†’ <ATOM>

list attr
attr label
personality â†’ â€˜personality__:â€™ â€˜{â€™ list traits [â€˜,â€™ rat level] [â€˜,â€™ coping strats] â€˜}â€™â€˜.â€™

â†’ ( attr label â€˜:â€™ ( <NUMBER> | <ATOM> ) (â€˜,â€™ ( <NUMBER> | <ATOM> ) )*
â†’ <ATOM>

list traits â†’ â€˜[â€™ trait ( â€˜,â€™ trait )* â€˜]â€™
trait
trait label â†’ <ATOM>

â†’ trait label â€˜:â€™ <NUMBER>

Figure 3: Simpliï¬ed extension of the agentâ€™s syntax including the new extension of e-GenIA3.

mas

â†’ â€˜MASâ€™ <ID> â€˜{â€™ [infrastructure] [environment]

[execcontrol] [w matrix] â€˜}â€™

w matrix

â†’ â€˜w_matrix__:â€™ w weights ( â€˜,â€™ w weights )*
â†’ â€˜[â€™ trait label â€˜:â€™ list weights â€˜]â€™
w weights
â†’ <ATOM>
trait label
list weights â†’ â€˜[â€™ weight ( â€˜,â€™ weight )* â€˜]â€™

weight
em label

â†’ em label â€˜:â€™ <NUMBER>
â†’ <ATOM>

Figure 4: Simpliï¬ed extension of the MAS project syntax including the new extension of e-GenIA3.

4.4 Extending the AgentSpeak agent conï¬guration

The syntax of AgentSpeak was presented in [8] using the EBNF (Extended Backus-Naur Form) notation [5]. This syntax
was later extended by the GenIA3 architecture to allow the development of aï¬€ective agents [2, 71, 72]. In the original
EBNF syntax of GenIA3, an agent (agent) is deï¬ned by the set of initial beliefs (init beliefs), concerns (concerns),
personality (personality), initial goals (init goals), and plans (plans). We have extended this syntax to incorporate
some new attributes to the agent conï¬guration. Figure 3 and 4 shows the extension of the EBNF syntax1. We have added
a new attribute to represent the knowledge that the agent has about other agents (others knowledge). To represent
this knowledge, we use a set consisting of the agentâ€™s identity (ag id) and a list of attributes associated with that agent
(list attr). The list of attributes is deï¬ned as a set of tuples consisting of the attribute label (attr label) and its
value. One of the most important attributes is the aï¬€ective link that represents the aï¬€ective proximity or relationship
between the agents. In our default design the aï¬€ective link is represented as a value ranging from [-1,1], but it can be
easily modiï¬ed to use other values such as fuzzy values. Following the example described in Section 4.1, let us assume
that agent Marshall has an aï¬€ective link with agent Barney of âˆ’0.5 and an aï¬€ective link with agent Lily of 0.9. To
represent this knowledge, the following sentences must be added to agent Marshallâ€™s deï¬nition:

others__: [ Lily: [ affective_link: 0.9 ],
Barney: [ affective_link: -0.5 ] ]

Note that the affective link is not the only attribute that can be represented. The number of attributes could be

increased to represent more information such as trust level or the other agentsâ€™ goals, concerns, and beliefs.

On the other hand, in GenIA3, the agentâ€™s personality is deï¬ned by the keyword â€œpersonality

:â€ followed by some
attributes: the traits (traits), which are deï¬ned as a list containing a value for each personality trait; and optionally,
the rationality level (rat level), which is deï¬ned as a numerical value representing how rational the agent is; and
the coping strategies (coping strats), which are deï¬ned as a list of plans that will be used by the agent to deal with
aï¬€ective events. We have modiï¬ed the deï¬nition of the personality traits in e-GenIA3 to make it more user friendly.
Now, the personality traits are deï¬ned using a trait label (trait label) followed by the numeric value for that trait.
For example, let us suppose that the agent Marshall has an Extraversion level of 0.9 and a Neuroticism level of 0.1. We
can express this using the new syntax as follows:

personality__:

{ [ extraversion: 0.9,

neuroticism: 0.1 ] }

Finally, we have introduced a new attribute Ï‰ (em weights) to the multi-agent system (MAS) project. Ï‰ represents
a correlation matrix between the personality traits tr âˆˆ P and all of the possible emotion types t âˆˆ Ae âˆª Ee, where Ae
is the set of emotions that can be elicited by the appraisal process and Ee is the set of empathic emotions that can be
triggered by the empathic appraisal process. For each pair of values (tr, t), a weight p representing how the personality
trait tr inï¬‚uences the emotion type t can be speciï¬ed, but many of these weights will be zero. Therefore, the set of
weights of the emotions can be viewed as the set of correlations between emotions and personality traits: the greater the

1Deï¬nitions of non-terminal syntactic symbols that have not been described in this section are detailed in [8] and [2].

9

Table 1: Example of a personality / emotion correlation matrix.

Emotions Extraversion Neuroticism
Anger
Sadness

0.8
0.7

0.5
0.6

Figure 5: New conï¬guration of both aï¬€ective and rational processes. White boxes represent the original
processes proposed for an AgentSpeak agent; dark gray shaded boxes are the original processes of the GenIA3
architecture; dashed lines indicate processes that have been redesigned in e-GenIA3; light gray shaded boxes
represent the new processes of e-GenIA3.

correlation between the personality trait tr and the emotion type t, the greater the value of p. For example, considering
that the trait of Extraversion E is related to positive emotions and Neuroticism N does not have a very high relation
with positive emotions [22], for the Happiness emotion, the Extraversion weight (Ï‰Happiness,E) will be greater than the
weight of the Neuroticism for the Happiness emotion (Ï‰Happiness,N ).

To deï¬ne the syntax of the Ï‰ matrix, we use the keyword â€œw matrix

:â€ followed by one or more weights
(w weights). These weights are deï¬ned as a label that identiï¬es the personality trait (trait label) followed by a
list of weights (list weights). This list of weights is composed of one or more emotion labels (em label) followed by
a number that represents the correlation between that personality trait and that emotion. For instance, let us consider
the following example in which a personality / emotion correlation matrix is deï¬ned based on the variables Extraversion
and Neuroticism and the emotions Anger and Sadness (as proposed in [74]). Table 1 shows the correlation matrix. The
values of this correlation matrix are based on the results obtained from the experiments presented in [22]. The deï¬nition
of the Ï‰ matrix using the proposed syntax is:

w_matrix__: [ extraversion: [ Anger: 0.5,

Sadness: 0.6 ],

neuroticism: [ Anger: 0.8,

Sadness: 0.7 ] ]

This correlation matrix is deï¬ned in the conï¬guration ï¬le (i.e., MAS project ï¬le) of the multiagent system and is
common to all agents deï¬ned in that environment. Note that, in the default design of GenIA3, the OCEAN personality
model is used, but the architecture also allows the use of other personality models with numeric or fuzzy variables as
presented in [71]. Through our extension of AgentSpeak, the programmer can clearly deï¬ne both the personality of the
agent and the knowledge that the agent has about other agents. On the one hand, instead of establishing one threshold
for each emotion, as seen in previous approaches, our model allows the relationship between diï¬€erent personality traits
and emotions to be deï¬ned using a correlation matrix Ï‰. Therefore, just by varying the personality traits we can deï¬ne
agents with diï¬€erent aï¬€ective behaviors. On the other hand, in our proposal, each agent could have its own aï¬€ective link
matrix, thus allowing the implementation of asymmetric relationships between agents. This diï¬€erence in the aï¬€ective
links between agents represents what happens in human societies in real life. In addition, the aï¬€ective link between two
agents can dynamically vary according to the interaction value and the emotion generated when the agents interact with
each other. This allows the simulation of aï¬€ective behavior in long-term interactions between agents.

4.5 A new rational cycle for an empathic BDI agent
We have redesigned the GenIA3 architecture by adding new processes to enable the development of empathic agents.
Figure 5 shows the new conï¬guration of e-GenIA3. We have introduced ï¬ve new steps to the aï¬€ective cycle and we have
proposed a new formalization of the transitions between these steps using the operational semantics described in [52].
This operational semantics consists of a set of rules that deï¬ne the transitions between diï¬€erent conï¬gurations of an
AgentSpeak agent.

To make readability more convenient, we have adopted the syntax proposed in [75]. Following this syntax, if ag is
the set of attributes that deï¬ne an agent, we will refer to the personality component P of ag as agP . We will also refer
to the empathic agent whose aï¬€ective cycle we are describing as empathic agent. In addition, we will use emph ag id
as the empathic agent identiï¬er.

10

ApprAffAdSelcsAsDecayCopeRelPlExecIntClrIntSelApplSelIntAddIMApplPlSelEvProcMsgAffModBEvalExpEventEvClassEmphApprEmphRegEmRegEmSelRational processesAffective processes4.5.1 Event classiï¬cation

The event classiï¬cation (EvClass) step evaluates the triggering event te component of the current event TÎµ to determine
whether the event is aï¬€ectively relevant by a Boolean function of degree n:

where X = {True, False} is a Boolean domain. This function is deï¬ned by default as:

affRelEv(te) := X n â†’ X

affRelEv(te) :=

ï£±
ï£²

True,

ï£³

False,

if âˆƒ ai âˆˆ teannots : functori =
â€˜affective relevantâ€™
otherwise

(11)

(12)

where te is the triggering event, teannots is the set of annotations of te, ai is the ith annotation of the set of annotations

teannots, and functori represents the functor of the annotation ai.

Furthermore, this step also performs the dissociation between events that should be evaluated in the aï¬€ective cycle
and those that should be evaluated in the empathic cycle allowing the distinction between the self from the target. As
discussed in Section 2, this distinction between self and target is essential in the development of empathy since it allows
an agent to diï¬€erentiate its own emotions from emotions produced by the perception of others. For an event, we have
designed four transition rules in this step. The ï¬rst rule (EvClass1) is applied to events that are not aï¬€ectively relevant
and either have nothing to do with the empathic agent (e.g., the target are other agents) or events whose target is the
empathic agent but without a subject agent (e.g., environmental events):

Â¬affRelEv(te) âˆ§ (tg (cid:54)= emph ag id âˆ¨ (tg = emph ag id âˆ§ sbj âˆˆ {null, self}))
(cid:104)ag, C, M, T, s, Mem, Ta, O, EvClass(cid:105) â†’ (cid:104)ag, C, M, T, s, Mem, Ta, O, EvClass(cid:105)

(EvClass1)

where: TÎµ = (cid:104)te, i(cid:105) , TÎµ is the Îµ component of the tuple T

following the syntax presented in [75] (see Figure 2).

tg = getTarget(te)

sbj = getSubject(te)

If this rule is evaluated as true, the empathic agent will remain in the state EvClass waiting for a new event. For
example, let us assume that Lily is the empathic agent. At a certain point, in time Lily perceives the event time(cloudy).
The function affRelEv evaluates the event obtaining the value false as a result because this event is not relevant for the
aï¬€ective cycle. The function getTarget also evaluates the event and returns the value null since there is no annotation
indicating a target agent at the event. Therefore, the event does not have any aï¬€ective impact on Lily, and the aï¬€ective
cycle is not started. Lily will remain in the event classiï¬cation step waiting for a new event.

The second rule (EvClass2) deals with events that are not aï¬€ectively relevant but that have some level of social

interaction between the empathic agent and the subject agent.

Â¬affRelEv(te) âˆ§ tg = emph ag id âˆ§ sbj /âˆˆ {null, self}
(cid:104)ag, C, M, T, s, Mem, Ta, O, EvClass(cid:105) â†’ (cid:104)ag, C, M, T, s, Mem, Ta, O(cid:48), EvClass(cid:105)

(EvClass2)

where: TÎµ = (cid:104)te, i(cid:105)

tg = getTarget(te)

sbj = getSubject(te)

iv = getIV(te)
O(cid:48) = (cid:8)..., (cid:10)id, al(cid:48), (cid:126)Ïƒ(cid:11) , ...(cid:9) , where id = sbj
al(cid:48) = updateAl(al, iv), where (cid:104)id, al, (cid:126)Ïƒ(cid:105) âˆˆ O and
id = sbj

When this rule is evaluated as true, the aï¬€ective link that the empathic agent has with the subject agent is updated

by the function updateAl.

Continuing with the example, suppose that Lily (the empathic agent) has an aï¬€ective link of 0.5 with Marshall. At

a certain point in time, Marshall says hello to Lily by the event:

hello[subject(Marshall),target(Lily),

interaction value(0.2)]

(Example 1)

In this event, Marshall is the subject agent. As a result of this interaction, Lily will increase her aï¬€ective link with
Marshall by using the interaction value 0.2. As in the previous rule, Lily will remain in the event classiï¬cation step
waiting for a new event.

11

The last two rules refer to events that are aï¬€ectively relevant and, therefore, will trigger the aï¬€ective cycle. It is in
these rules where the distinction between self and target occurs. This distinction is crucial because it allows an agent to
diï¬€erentiate its own emotions from emotions produced by the perception of others. The EvClass3 rule is evaluated as
true when aï¬€ective events are directed towards other agents:

affRelEv(te) âˆ§ tg /âˆˆ {emph ag id , null}
(cid:104)ag, C, M, T, s, Mem, Ta, O, EvClass(cid:105) â†’ (cid:104)ag, C, M, T, s, Mem, Ta, O(cid:48), EmphAppr(cid:105)

(EvClass3)

where: TÎµ = (cid:104)te, i(cid:105)

tg = getTarget(te)

iv = getIV(te)
O(cid:48) = (cid:8)..., (cid:10)id, al(cid:48), (cid:126)Ïƒ(cid:11) , ...(cid:9) , where id = tg
al(cid:48) = updateAl(al, iv), where (cid:104)id, al, (cid:126)Ïƒ(cid:105) âˆˆ O and
id = tg

If an event is aï¬€ectively relevant and the target agent is another agent, the event is considered an empathic event.
Therefore, the aï¬€ective cycle is started, and the empathic appraisal step processes the empathic event. For example,
when Lily receives the event:

slap[subject(Marshall),target(Barney),

affective relevant,interaction value(-0.5)]

(Example 2)

The function affRelEv evaluates the event as aï¬€ectively relevant and identiï¬es that the target of the triggering event
is Barney. Therefore, the aï¬€ective cycle of agent Lily moves to the appraisal (Appr) step in which the event is evaluated
by means of an empathic appraisal. In this appraisal step, Lily infers how Barney feels, and she generates an empathic
emotion directed towards Barney.

Finally, the rule EvClass4 deals with aï¬€ectively relevant events that are received by the empathic agent:

affRelEv(te) âˆ§ tg = emph ag id
(cid:104)ag, C, M, T, s, Mem, Ta, O, EvClass(cid:105) â†’ (cid:104)ag, C, M, T, s, Mem, Ta, O, Appr(cid:105)

(EvClass4)

where: TÎµ = (cid:104)te, i(cid:105)

tg = getTarget(te)

When this rule is evaluated as true, the empathic agent performs a self-appraisal process of the event obtaining an

emotion as a result. Following the previous example, when Lily receives the event:

slap[subject(Marshall),target(Lily),

affective relevant,interaction value(-0.5)]

(Example 3)

this event is directed toward Lily (i.e., Lily is the target agent). Therefore, Lily will evaluate this event through a

self-appraisal process in the appraisal (Appr) step.

4.5.2 Appraisal

In the appraisal step, the values of the appraisal variables Av for the event Îµ are determined by the self-appraisal process
deï¬ned by the function:

Appraisal(Îµ, bs, cc, Av, Mem, Ap) := {[(xid, xv)] : xv =

DeriveAV(xid, Îµ, bs, cc, Mem, Ap), âˆ€(xid, xv) âˆˆ Av}

(13)

where bs are the agentâ€™s beliefs, cc are the agentâ€™s concerns, Av is a list of tuples (identiï¬er, value) containing the
set of appraisal variables, Mem is the aï¬€ective memory, Ap are the applicable plans, xid is the identiï¬er of an appraisal
variable, xv is the value of the appraisal variable, and DeriveAV is a function that returns the value of each appraisal
variable deï¬ned as:

DeriveAV(id, Îµ, bs, cc, Mem, Ap) :=

[id, Îµ, bs, cc, Mem, Ap] (cid:55)â†’ Î»

(14)

where Î» represents the value of the appraisal variable. Note that this function calculates a diï¬€erent value for each

appraisal variable.

12

To determine the derived emotions from the appraisal variables, we have deï¬ned the DeriveEm function as:

where Av represents the set of appraisal variables and Ae represents the set of appraised emotions deï¬ned as a set

of vectors. Therefore, this function establishes a mapping between the set of appraisal variables and emotions.

The transition rule for the appraisal step of the aï¬€ective cycle has been deï¬ned as:

DeriveEm(Av) := Av (cid:55)â†’ Ae

(15)

True
(cid:104)ag, C, M, T, s, Mem, Ta, O, Appr(cid:105) â†’ (cid:104)ag, C, M, T, s, Mem, Ta(cid:48), O, EmReg(cid:105)

(Appr1)

where: Ta(cid:48)
Ta(cid:48)

Av = Appraisal(TÎµ, agbs, agcc, TaAv, Mem, TAp)
Ae = DeriveEm(Ta(cid:48)

Av)

For instance, continuing with the event of Example 3, Lily appraises the slap event eliciting the emotion sadness

with high intensity.

Once the appraisal ï¬nishes, the next step in the aï¬€ective cycle is the emotion regulation (EmReg) step.

4.5.3 Emotion regulation

The emotion regulation step adapts the appraised emotion based on diï¬€erent factors such as the mood or personality
of the agent. This regulation process aï¬€ects the probability and intensity of emotions. For example, if the aï¬€ective
link between two agents is high, the probability and intensity of emotions should be increased. The process of emotion
regulation is established by the EmphRegulation function deï¬ned as:

EmRegulation(tr, Ï‰, (cid:126)Ïƒ, Ae) :=

(cid:8)(cid:2)(cid:126)e(cid:48)(cid:3) : (cid:126)e(cid:48) = Ï•1 (tr, Ï‰, (cid:126)Ïƒ, (cid:126)e) âˆ€(cid:126)e âˆˆ Ae(cid:9)

(16)

where tr are the personality traits of the agent, Ï‰ is the personality/emotion correlation matrix, (cid:126)Ïƒ is the agentâ€™s
current mood, Ae is the set of appraised emotions and Ï•1 is a function that adapts the emotionâ€™s vector (cid:126)e to the regulation
process.

Thanks to this regulation of the emotion process, each agent can face an event in a diï¬€erent way depending on his/her

personality or mood.

The transition rule for this step is deï¬ned as follows:

true
(cid:104)ag, C, M, T, s, Mem, Ta, O, EmReg(cid:105) â†’ (cid:104)ag, C, M, T, s, Mem, Ta(cid:48), O, EmSel(cid:105)

(EmSel1)

where: Ta(cid:48)

Ae = EmRegulation(agP , Ta(cid:126)Ïƒ, TaAe)

Following the previous example in which Lily appraised the sadness emotion with high intensity, if Lilyâ€™s personality
has a high component of extraversion, she is more prone to positive emotions. Therefore, the emotion regulation process
will reduce the intensity of the emotion, producing the emotion sadness with medium intensity.

Once the regulation of the possible emotions has been performed, the next step of the non-empathic aï¬€ective cycle

will be the emotion selection (EmSel) step.

4.5.4 Empathic appraisal

When the target of an aï¬€ective event is another agent, the event is appraised by the empathic appraisal process. This
empathic appraisal process is a self-projection appraisal that allows an empathic agent to understand another agentâ€™s
emotion or situation. Similarly to the previously deï¬ned self-appraisal step, the empathic appraisal is deï¬ned by the
formula:

EmphAppraisal(Îµ, bs, cc, Av, Mem, Ap, O) := {[(xid, xv)] :
xv = DeriveAV(xid, Îµ, bs, cc, Mem, Ap, O), âˆ€(xid, xv) âˆˆ Av}

(17)

where bs is the set of beliefs, cc is the set of concerns, Mem is the aï¬€ective memory, Ap are the applicable plans, xid
is the identiï¬er of an appraisal variable, xv is the value of an appraisal variable, Av is a list of tuples (identiï¬er, value)
one for each appraisal variable, O is the target information, and DeriveAV follows the deï¬nition of Equation 14. that
returns the value of each appraisal variable. Note that the beliefs and concerns may be either those of the empathic agent
or those of the target agent. In addition, both the number and type of appraisal variables and the function DeriveAV
of the empathic process can be diï¬€erent from the self-appraisal process. Empathic emotions can also be distinct from
self-appraisal and are elicited through function DeriveEmphEm:

DeriveEmphEm(Av) := Av (cid:55)â†’ Ee

(18)

13

where Av represents the set of appraisal variables and Ee represents the set of empathic emotions deï¬ned as a set of

vectors.

The transition rule for the empathic appraisal step of the aï¬€ective cycle has been deï¬ned as:

T rue
(cid:104)ag, C, M, T, s, Mem, Ta, O, EmphAppr(cid:105) â†’ (cid:104)ag, C, M, T, s, Mem, Ta(cid:48), O, EmphReg(cid:105)

(EmphAppr1)

where: Ta(cid:48)
Ta(cid:48)

Av = EmphAppraisal(TÎµ, agbs, agcc, TaAv, Mem, TAp)
Ee = DeriveEmphEm(TaAv)

For example, when Lily perceives the event described in Example 2, Lily evaluates the event slap through a self-

projection appraisal and elicits the emotion sorry for with high intensity towards Barney.

Once the empathic appraisal generates the set of empathic emotions, the empathic regulation (EmphReg) process will

adapt the empathic emotions using the mood and personality of the empathic agent.

4.5.5 Empathic regulation

The empathy regulation step adapts the empathic emotion according to diï¬€erent factors such as the mood Ta(cid:126)Ïƒ or
personality agP of the agent and the aï¬€ective link Oal between the empathic agent and the target agent. This regulation
process allows the empathic response to be personalized to diï¬€erent target agents. For example, if the aï¬€ective link
between the empathic agent and the target agent is high, the probability and intensity of the empathic emotions will be
higher. The process of empathic regulation is established by the EmphRegulation function deï¬ned as:

EmphRegulation (tr, Ï‰, O, (cid:126)Ïƒ, Ee) :=
(cid:8)(cid:2)(cid:126)e(cid:48)(cid:3) : (cid:126)e(cid:48) = Ï•2 (tr, Ï‰, O, (cid:126)Ïƒ, (cid:126)e) âˆ€(cid:126)e âˆˆ Ee(cid:9)

(19)

where tr are the personality traits of the agent, Ï‰ is the personality/emotion correlation matrix, O represents the
knowledge that the empathic agent knows about the target agent, (cid:126)Ïƒ is the agentâ€™s current mood, and Ï•2 is a function
that modiï¬es the emotion vector.

The transition rule for the empathic regulation is deï¬ned as:

true
(cid:104)ag, C, M, T, s, Mem, Ta, O, EmphReg(cid:105) â†’ (cid:104)ag, C, M, T, s, Mem, Ta(cid:48), O(cid:48), EmSel(cid:105)

(EmphReg1)

where: Ta(cid:48)

Ee = EmphRegulation(TÎµ, agPtr , O, Ta(cid:126)Ïƒ, TaEe)

TÎµ = (cid:104)te, i(cid:105)
iv = getIV(te)
O(cid:48) = (cid:8)..., (cid:10)id, al(cid:48), (cid:126)Ïƒ(cid:11) , ...(cid:9) , where id = tg
al(cid:48) = updateAl(al, iv), where (cid:104)id, al, (cid:126)Ïƒ(cid:105) âˆˆ O and
tg = getTarget(te)

Following the previous example, let us suppose that Lily has a low positive aï¬€ective link with Barney (e.g., 0.3). Let
us recall that Lilyâ€™s personality makes her prone to positive emotions. In addition, when Lily perceives the event, she
has a positive mood (e.g., happiness). The empathic emotion regulation process will reduce the intensity of the empathic
emotion and the result will be the emotion sorry for with weak intensity.

Once the regulation of the possible empathic emotions has been performed, the following step is the emotion selection

(EmSel) step.

4.5.6 Emotion selection

In the emotion selection step of the aï¬€ective cycle, the ï¬nal emotion F e that the agent is going to simulate is selected
by the function SelEmotion(Îµ, Ae, Ee, P ). This function has as parameters an event Îµ, the list of appraised emotions
Ae, the list of empathic emotions Ee, and the agent personality P . The user can adapt this SelEmotion function to
diï¬€erent environments and situations considering the agent personality, intensity or probability of the emotions, and
other aï¬€ective characteristics.

The transition rule for the emotion selection step is deï¬ned as follows:

T rue
(cid:104)ag, C, M, T, s, M em, T a, O, EmSel(cid:105) â†’ (cid:104)ag, C, M, T, s, Mem(cid:48), T a(cid:48), O, AffAd(cid:105)

(EmSel1)

where: Ta(cid:48)

Fe = SelEmotion(TaAe, TaEe)

ae = (cid:10)TÎµ, Ta(cid:48)
Mem(cid:48) = Mem âˆª ae

Fe

(cid:11)

14

This step calculates the ï¬nal emotion Ta(cid:48)

Fe. Therefore, the aï¬€ective memory Mem can be updated to store the event
TÎµ with the emotion Ta(cid:48)
Fe resulting from this event appraisal. This mechanism allows the agent to maintain a memory
of past events and the emotion that each event produced, supporting the maintaining of long-term interactions between
agents.

For instance, when Lily evaluates the event of Example 3, the self-appraisal process produces two emotions as a
result: sadness with high intensity, and fear with medium intensity. Let us suppose that after the emotion regulation
process the intensity of those emotions is not modiï¬ed. If the user has deï¬ned the SelEmotion function to select the
emotion with the highest intensity, the empathic agent will elicit the sadness emotion.
The next process of the empathic aï¬€ective cycle is the aï¬€ect adaptation (AffAd).

4.5.7 Aï¬€ect adaptation

In the AffectAdaptation step, the mood of the agent is updated by the function AffectAdaptation, which is deï¬ned
as follows:

AffectAdaptation (tr, Ï‰, (cid:126)Ïƒ, Fe) := (cid:8)(cid:126)Ïƒ(cid:48) : (cid:126)Ïƒ(cid:48) = Ï•3 (tr, Ï‰, Fe, (cid:126)Ïƒ)(cid:9)

(20)

where Fe is the ï¬nal emotion selected by the emotion selection process. Ï•3 is a function that, similarly to Ï•1 and

Ï•2 in Equations 16 and 19, modiï¬es the mood vector (cid:126)Ïƒ to adjust it to the emotion produced by the event.

The transition rule for this step is deï¬ned as:

T rue
(cid:104)ag, C, M, T, s, Mem, Ta, O, AffAd(cid:105) â†’ (cid:104)ag, C, M, T, s, Mem, Ta(cid:48), P, O, SelCs(cid:105)

(Aï¬€Ad1)

where: Ta(cid:48)

(cid:126)Ïƒ = affectAdaptation(agP , Ta(cid:126)Ïƒ, TaFe)

Since emotions and mood are expressed as vectors in the same representation space, the selected emotion will â€œattractâ€
the mood to a greater or lesser extent depending on the agentâ€™s personality. As a result, the mood of the agent will be
modiï¬ed. Continuing with the previous example in which the selected emotion was sadness with high intensity, let us
assume that Lilyâ€™s mood is happiness with a low intensity. The emotion will attract the mood, and, as a result, the new
mood will be sadness with a low intensity.

Once the mood of the agent is updated, the next state of the aï¬€ective cycle will be the select coping strategy process.
In this process, a coping strategy from the current set of applicable coping strategies will be used to create a plan that
ï¬nally allows the agent to express its empathy: in its voice tone, in its speech, in its face, . . .

5 Default design

To facilitate the use of e-GenIA3, we propose a default design in which there is a default deï¬nition of the previous
presented functions, based on the psychological theories introduced in Sections 3 and 4. In this default design, emotions
and mood are represented as vectors (cid:126)Ïƒ in a representation space based on the PAD model [44]. The personality is deï¬ned
by the OCEAN model. The appraisal model is based on the OCC model [48] and follows the deï¬nition presented in [2].
The appraisal function evaluates the event, when this event implies the addition or deletion of a belief. Then the values
of the appraisal variables are estimated considering both the information contained in the event itself and the agentâ€™s
beliefs, desires, intentions, expectations, and concerns. This default design uses the appraisal variables: desirability,
which considers the value of the agentâ€™s concerns about the event; likelihood, which considers the probability of the
event; and causal attribution, which is the agent that produces the event (i.e. the subject agent) but it can also be self, if
it is an internal event or null if it comes from the environment (see [2] and [74] for more details on how this process work).
The function DeriveAV in Equation 14 estimates the value of the appraisal variables as follow. For the desirability, this
function evaluates if the event is an addition or deletion event, then compares the functor of the event with the agent
concerns and estimates the desirability value. For example, if the agent is concerned about passing an exam, the function
for estimating the value of the concern may be V = Score/MaxScore, where Score is the score of the agentâ€™s exam and
MaxScore is the maximum possible score. To obtain the value of the appraisal variable likelihood, a special annotation
(n) is used for events. Finally, to obtain the value for the causal attribution, the Equation 8, referring the function
prob
getSubject, is used. In our default design, EmphAppraisal and DeriveEmphEm (Equation 18) functions follow the same
philosophy as Appraisal and DeriveEm functions (Equations 13 and 15) presented above. Note that, in this function,
the appraised beliefs and concerns to be those of the agent itself or of the target agent allowing the simulation of diï¬€erent
levels of empathy and Theory of Mind. In addition, the number and type of emotions that can be triggered by empathic
appraisal, may diï¬€er from the emotions of aï¬€ective appraisal. For example, by triggering emotions such as â€happy forâ€
or â€sorry forâ€ proposed in the OCC model [48]. These two emotions are used in the default design.

In our default design, the DeriveEm function, Equation 15, can elicit ï¬ve emotions (i.e., hope, joy, fear, sadness,
and guilt) using the OCC theory as proposed in [39]. These emotions can be subsequently represented in a PAD space,
considering the mapping proposed in [25] (or to a Pleasure-Arosual (PA) space, considering the model proposed in [73]).
For more details see [2].

Once the emotion is obtained and represented as a vector (cid:126)Ïƒ, the emotion regulation process adapts this vector (cid:126)Ïƒ

through the function Ï•1 (Equation 16). This function is deï¬ned as:

15

where Ïˆ((cid:126)v) is a weighting factor resulting from the formula:

Ï•1 (tr, Ï‰, (cid:126)Ïƒ, (cid:126)e) := Ïˆ((cid:126)Ïƒ) Â· (cid:126)Ïƒ + (cid:126)e

Ïˆ((cid:126)v) :=

(cid:80)

iâˆˆtr Î²i Â· Ï‰t((cid:126)v),i
(cid:80)
jâˆˆtr Ï‰t((cid:126)v),j

(21)

(22)

where Î²i is the value of the ith personality trait, t((cid:126)v) is a function that returns the most probable aï¬€ective label for a
vector (cid:126)v (the description of function t((cid:126)v) can be found at [74] and [73]), and Ï‰t((cid:126)Ïƒ),i represents the value of the correlation
matrix Ï‰ for the aï¬€ective label t((cid:126)Ïƒ) and the ith personality trait.

The empathic regulation function Ï•2, proposed in Ecuation 19, is deï¬ned in the default design as:

Ï•2 (tr, Ï‰, O, (cid:126)Ïƒ, (cid:126)e) := (Ïˆ((cid:126)e) Â· (cid:126)e + Ïˆ((cid:126)Ïƒ) Â· (cid:126)Ïƒ) Â· al

(23)

where al represents the aï¬€ective link.
The emotion selection (SelEmotion) function is based on the intensity and probability of emotions according to the

following deï¬nition:

SelEmotion(Ae, Ee) := arg max
iâˆˆAeâˆªEe

arg max
c

(cid:98)P (C = c | Î±i) Â· Î´i

(cid:18)

(cid:19)

(24)

where Î±i and Î´i represent the angle and the intensity of the ith emotion vector (as deï¬ned in [73]), respectively.
For the aï¬€ect adaptation, Equation 20, the deï¬nition in the default design is:

Finally, the function for updating the aï¬€ective link (updateAl) is deï¬ned as:

Ï•3 (tr, Ï‰, Fe, (cid:126)Ïƒ) := {(cid:126)Ïƒ Â· Ïˆ((cid:126)Ïƒ) + (cid:126)e Â· Ïˆ((cid:126)e)}

updateAl(al, iv) := al + Ï• Â· iv

(25)

(26)

where iv is the interaction value, Ï• is a weighting factor, and al and represent the current value of the aï¬€ective link.

6 Conclusions

Empathy is a key element in social interactions aï¬€ecting human aï¬€ective states and behaviours and provides a basis for
long-term relationships. Several proposals have been made from the area of aï¬€ective computing to simulate aï¬€ective
and empathic abilities. These proposals are generally based on theoretical models from psychology, sociology, and
neuroscience using agent-oriented approaches. However, these proposals are designed ad hoc, generating agent programs
that are highly dependent on the domain and the programmer, making these proposals very diï¬ƒcult to understand,
share, and re-use. In this paper, we have presented e-GenIA3 a generic architecture for the development of empathic
agents. We have proposed a formalization of the syntax, semantics, and the reasoning cycle of AgentSpeak to support the
development of agents with empathic abilities. e-GenIA3 formalizes the three main processes identiï¬ed in the literature:
perception, empathic appraisal, and empathic regulation. After perceiving an empathic event, the empathic appraisal
process elicits a set of empathic emotions. These empathic emotions are then adapted by the empathic regulation process
according to the knowledge that the agent has about the target agent. We have modiï¬ed the aï¬€ective cycle that was
incorporated to AgentSpeak by GenIA3adding new processes and functionalities to allow the elicitation of empathic
emotions. We have formalized our extension using the same operational semantics formalism used by AgentSpeak and
GenIA3. This operational semantics deï¬nes the structure and the conï¬guration of the agent allowing the use of diï¬€erent
psychological theories. The formalization of all of the transitions guarantees the validity of our proposal.

The new aï¬€ective cycle is divided into two diï¬€erent appraisal processes: one for eliciting empathic emotions induced
by the perception of an emotion or situation in a target agent; and another for eliciting emotions based on self-directed
or environmental events. This division of the aï¬€ective process allows the agent to be able to maintain a sense of self that
is distinct from the target agent.

The use of the aï¬€ective link representing the aï¬€ective proximity or social tie between two agents allows the per-
sonalization of the empathic response based on the target agent. In addition, a correlation matrix represents how each
personality trait of the agent inï¬‚uences the emotion that will be elicited. Finally, in our proposal, agents maintain a
memory of past events and the emotion that the past events produced in the agent. This aï¬€ective memory, combined
with the possibility of establishing and modifying the aï¬€ective links with other agents, allows the simulation of person-
alized long-term interactions, which are crucial in aï¬€ective interactions in human beings. All of these characteristics of
our empathic agent model will produce software agents that are more realistic when modelling human organizations.

We are currently considering increasing the agentâ€™s knowledge of other agents by adding new structures to store the
beliefs, goals, and concerns of other agents using state-of-the-art approaches of Theory of Mind. Moreover, the aï¬€ective
link can be complemented maintaining a level of trust in other agents. This will improve the perspective-taking process
so that the agent can evaluate perceived situations using more knowledge about the target agent.

16

Acknowledgments

This work is partially supported by the Spanish Government project PID2020-113416RB-I00 and TAILOR, a project
funded by EU Horizon 2020, under GA No 952215.

References

[1] Carole Adam, Andreas Herzig, and Dominique Longin. A logical formalization of the occ theory of emotions.

Synthese, 168(2):201â€“248, 2009.

[2] Bexy Alfonso, Emilio Vivancos, and Vicente Botti. Toward formal modeling of aï¬€ective agents in a BDI architecture.

ACM Transactions on Internet Technology (TOIT), 17(1), 2017.

[3] Paul J Argott, Dawn Buï¬ƒngton Townsend, and Claire L Poulson. Acquisition and generalization of complex

empathetic responses among children with autism. Behavior analysis in practice, 10(2):107â€“117, 2017.

[4] Giuseppe Attanasi, Astrid Hopfensitz, Emiliano Lorini, and FrÂ´edÂ´eric Moisan. Social connectedness improves co-

ordination on individually costly, eï¬ƒcient outcomes. European Economic Review, 90:86â€“106, 2016.

[5] John W Backus, Friedrich L Bauer, Julien Green, Charles Katz, John McCarthy, Peter Naur, Alan J Perlis, Heinz
Rutishauser, Klaus Samelson, Bernard Vauquois, et al. Revised report on the algorithmic language algol 60. The
Computer Journal, 5(4):349â€“367, 1963.

[6] Christopher Beedie, Peter Terry, and Andrew Lane. Distinctions between emotion and mood. Cognition & Emotion,

19(6):847â€“878, 2005.

[7] Rafael H Bordini and Jomi F HÂ¨ubner. A java-based interpreter for an extended version of agentspeak. University

of Durham, Universidade Regional de Blumenau, 256, 2007.

[8] Rafael H Bordini, Jomi Fred HÂ¨ubner, and Michael Wooldridge. Programming multi-agent systems in AgentSpeak

using Jason, volume 8. John Wiley & Sons, 2007.

[9] Hana Boukricha, Ipke Wachsmuth, Maria Nella Carminati, and Pia Knoeferle. A computational model of empathy:
Empirical evaluation. In 2013 Humaine Association Conference on Aï¬€ective Computing and Intelligent Interaction,
pages 1â€“6. IEEE, 2013.

[10] Malissa A Clark, Melissa M Robertson, and Stephen Young. â€œI feel your painâ€: A critical review of organizational

research on empathy. Journal of Organizational Behavior, 40(2):166â€“192, 2019.

[11] Benjamin MP Cuï¬€, Sarah J Brown, Laura Taylor, and Douglas J Howat. Empathy: A review of the concept.

Emotion Review, 8(2):144â€“153, 2016.

[12] Mehdi Dastani and John-Jules Ch. Meyer. Agents with emotions. International Journal of Intelligent Systems,

25(7):636â€“654, 2010.

[13] Mark H Davis. Empathy: A social psychological approach. Routledge, 2018.

[14] Frederique De Vignemont and Tania Singer. The empathic brain: how, when and why? Trends in cognitive sciences,

10(10):435â€“441, 2006.

[15] Frans BM De Waal. The â€˜russian dollâ€™model of empathy and imitation. On being moved: From mirror neurons to

empathy, pages 35â€“48, 2007.

[16] Jean Decety and Philip L Jackson. The functional architecture of human empathy. Behavioral and cognitive

neuroscience reviews, 3(2):71â€“100, 2004.

[17] Douglas Derryberry and Marjorie A Reed. Temperament and attention: Orienting toward and away from positive

and negative signals. Journal of Personality and Social Psychology, 66(6):1128â€“1139, 1994.

[18] Panteleimon Ekkekakis. Aï¬€ect, mood, and emotion. Measurement in sport and exercise psychology, 321, 2012.

[19] Paul Ekman. An argument for basic emotions. Cognition & Emotion, 6(3-4):169â€“200, 1992.

[20] PF Ferrari, M Gerbella, G CoudÂ´e, and S Rozzi. Two diï¬€erent mirror neuron networks: the sensorimotor (hand)

and limbic (face) pathways. Neuroscience, 358:300â€“315, 2017.

[21] Nico H Frijda, Peter Kuipers, and Elisabeth Ter Schure. Relations among emotion, appraisal, and emotional action

readiness. Journal of Personality and Social Psychology, 57(2):212, 1989.

[22] Desire Furnes, Hege Berg, Rachel M Mitchell, and Silke Paulmann. Exploring the eï¬€ects of personality traits on

the perception of emotions from prosody. Frontiers in psychology, 10:184, 2019.

[23] Helen L Gallagher and Christopher D Frith. Functional imaging of â€˜theory of mindâ€™. Trends in cognitive sciences,

7(2):77â€“83, 2003.

[24] Joanna Ganczarek, Thomas HÂ¨unefeldt, and Marta Olivetti Belardinelli. From â€œEinfÂ¨uhlungâ€ to empathy: exploring

the relationship between aesthetic and interpersonal experience. Springer, 2018.

[25] Patrick Gebhard. Alma: a layered model of aï¬€ect. In Proceedings of the fourth international joint conference on
Autonomous agents and multiagent systems, pages 29â€“36. Association for Computing Machinery, New York, NY,
United States, 2005.

17

[26] Ezequiel Gleichgerrcht and Jean Decety. Empathy in clinical practice: how individual dispositions, gender, and
experience moderate empathic concern, burnout, and emotional distress in physicians. PloS one, 8(4):e61526, 2013.

[27] Joao Gluz and Patricia A Jaques. A probabilistic formalization of the appraisal for the occ event-based emotions.

Journal of Artiï¬cial Intelligence Research, 58:627â€“664, 2017.

[28] Alvin Goldman. Two routes to empathy. Empathy: Philosophical and psychological perspectives, pages 31â€“44, 2011.

[29] Grit Hein and Tania Singer. I feel how you feel but not always: the empathic brain and its modulation. Current

opinion in neurobiology, 18(2):153â€“158, 2008.

[30] Cecilia Heyes. Empathy is not in our genes. Neuroscience & Biobehavioral Reviews, 95:499â€“507, 2018.

[31] Peter Hilpert, Timothy R Brick, Christoph FlÂ¨uckiger, Matthew J Vowels, Eva Ceulemans, Peter Kuppens, and
Laura Sels. What can be learned from couple research: Examining emotional co-regulation processes in face-to-face
interactions. Journal of Counseling Psychology, 67(4):475, 2020.

[32] Martin L Hoï¬€man. Interaction of aï¬€ect and cognition in empathy. Emotions, cognition, and behavior, pages 103â€“131,

1984.

[33] Martin L Hoï¬€man. Empathy and prosocial behavior. Handbook of emotions, 3:440â€“455, 2008.

[34] Timotheus Kampik, Juan Carlos Nieves, and Helena Lindgren. Empathic autonomous agents.

In International

Workshop on Engineering Multi-Agent Systems, pages 181â€“201. Springer, 2018.

[35] Claus Lamm, Markus RÂ¨utgen, and Isabella C Wagner. Imaging empathy and prosocial emotions. Neuroscience

letters, 693:49â€“53, 2019.

[36] Richard S Lazarus and Richard S Lazarus. Emotion and adaptation. Oxford University Press, 1991.

[37] Iolanda Leite, Ginevra Castellano, AndrÂ´e Pereira, Carlos Martinho, and Ana Paiva. Empathic robots for long-term

interaction. International Journal of Social Robotics, 6(3):329â€“341, 2014.

[38] Iolanda Leite, Carlos Martinho, and Ana Paiva. Social robots for long-term interaction: a survey. International

Journal of Social Robotics, 5(2):291â€“308, 2013.

[39] Stacy C Marsella and Jonathan Gratch. Ema: A process model of appraisal dynamics. Cognitive Systems Research,

10(1):70â€“90, 2009.

[40] Abigail A Marsh. The neuroscience of empathy. Current opinion in behavioral sciences, 19:110â€“115, 2018.

[41] Samuel Mascarenhas, Manuel GuimarËœaes, Rui Prada, Pedro A Santos, JoËœao Dias, and Ana Paiva. Fatima toolkit-
toward an accessible tool for the development of socio-emotional agents. ACM Transactions on Interactive Intelligent
Systems (TiiS), 2021.

[42] Robert R McCrae and Oliver P John. An introduction to the ï¬ve-factor model and its applications. Journal of

Personality, 60(2):175â€“215, 1992.

[43] Albert Mehrabian. Analysis of the big-ï¬ve personality factors in terms of the pad temperament model. Australian

journal of Psychology, 48(2):86â€“92, 1996.

[44] Albert Mehrabian. Pleasure-arousal-dominance: A general framework for describing and measuring individual

diï¬€erences in temperament. Current Psychology, 14(4):261â€“292, 1996.

[45] John-Jules Ch Meyer. Reasoning about emotional agents. International journal of intelligent systems, 21(6):601â€“619,

2006.

[46] Mohammad Obaid, Ruth Aylett, Wolmet Barendregt, Christina Basedow, Lee J Corrigan, Lynne Hall, Aidan Jones,
Arvid Kappas, Dennis KÂ¨uster, Ana Paiva, et al. Endowing a robotic tutor with empathic qualities: Design and
pilot evaluation. International Journal of Humanoid Robotics, 15(06):1850025, 2018.

[47] Magalie Ochs, David Sadek, and Catherine Pelachaud. A formal model of emotions for an empathic rational dialog

agent. Autonomous Agents and Multi-Agent Systems, 24(3):410â€“440, 2012.

[48] Andrew Ortony, Gerald L Clore, and Allan Collins. The cognitive structure of emotions. Cambridge University

Press, 1990.

[49] Mark D Packard and Thomas A Burnham. Do we understand each other? toward a simulated empathy theory for

entrepreneurship. Journal of Business Venturing, 36(1):106076, 2021.

[50] Ana Paiva, Iolanda Leite, Hana Boukricha, and Ipke Wachsmuth. Empathy in virtual agents and robots: a survey.

ACM Transactions on Interactive Intelligent Systems (TiiS), 7(3):1â€“40, 2017.

[51] Rosalind Wright Picard. Aï¬€ective Computing. The MIT Press, 1997.

[52] Gordon D Plotkin. A structural approach to operational semantics. Technical Report DAIMI FN-19. Computer

Science Department, Aarhus University. Reprinted in J. Log. Algebr. Program, 1981.

[53] Jonathan Posner, James A Russell, and Bradley S Peterson. The circumplex model of aï¬€ect: An integrative
approach to aï¬€ective neuroscience, cognitive development, and psychopathology. Development and Psychopathology,
17(3):715â€“734, 2005.

[54] Stephanie D Preston. A perception-action model for empathy. Empathy in mental illness, 1:428â€“447, 2007.

[55] Stephanie D Preston and Frans BM De Waal. Empathy: Its ultimate and proximate bases. Behavioral and brain

sciences, 25(1):1â€“20, 2002.

18

[56] Anand S Rao. Agentspeak (l): Bdi agents speak out in a logical computable language. In European workshop on

modelling autonomous agents in a multi-agent world, pages 42â€“55. Springer, 1996.

[57] Anand S Rao, Michael P Georgeï¬€, et al. Bdi agents: From theory to practice. In Proceedings of the First International

Conference on Multiagent Systems, volume 95, pages 312â€“319. AAAI, 1995.

[58] Zeeshan Rasool, Naoki Masuyama, Md Nazrul Islam, and Chu Kiong Loo. Empathic interaction using the com-
putational emotion model. In 2015 IEEE Symposium Series on Computational Intelligence, pages 109â€“116. IEEE,
2015.

[59] Helen Riess. The science of empathy. Journal of patient experience, 4(2):74â€“77, 2017.

[60] Giacomo Rizzolatti, Luciano Fadiga, Vittorio Gallese, and Leonardo Fogassi. Premotor cortex and the recognition

of motor actions. Cognitive brain research, 3(2):131â€“141, 1996.

[61] SÂ´ergio Hortas Rodrigues, Samuel Mascarenhas, JoËœao Dias, and Ana Paiva. A process model of empathy for virtual

agents. Interacting with Computers, 27(4):371â€“391, 2015.

[62] James A Russell. A circumplex model of aï¬€ect. Journal of Personality and Social Psychology, 39(6):1161, 1980.

[63] James A Russell, Maria Lewicka, and Toomas Niit. A cross-cultural study of a circumplex model of aï¬€ect. Journal

of Personality and Social Psychology, 57(5):848, 1989.

[64] Cheryl L Rusting and Randy J Larsen. Extraversion, neuroticism, and susceptibility to positive and negative aï¬€ect:

A test of two theoretical models. Personality and individual diï¬€erences, 22(5):607â€“612, 1997.

[65] Klaus R Scherer. Studying the emotion-antecedent appraisal process: An expert system approach. Cognition &

Emotion, 7(3-4):325â€“355, 1993.

[66] Klaus R Scherer. Towards a prediction and data driven computational process model of emotion. IEEE Transactions

on Aï¬€ective Computing, 12(2):279â€“292, 2019.

[67] Elizabeth Segal. Social empathy. Columbia University Press, 2018.

[68] Geneva Smith and Jacques Carette. What lies beneath-a survey of aï¬€ective theory use in computational models of

emotion. TechRxiv, Preprint. https://doi.org/10.36227/techrxiv.18779315.v1, 2022.

[69] Bas R Steunebrink, Mehdi Dastani, John-Jules Ch Meyer, et al. A logic of emotions for intelligent agents.

In
Proceedings of the National Conference on Artiï¬cial Intelligence, volume 22, page 142. Menlo Park, CA; Cambridge,
MA; London; AAAI Press; MIT Press; 1999, 2007.

[70] Karsten Stueber. Empathy. International Encyclopedia of Ethics, 2013.

[71] Joaquin Taverner, Bexy Alfonso, Emilio Vivancos, and Vicent J Botti. Modeling personality in the aï¬€ective agent

architecture GenIA3. In ICAART (1), pages 236â€“243. Scitepress, 2018.

[72] JoaquÂ´Ä±n Taverner, Bexy Alfonso, Emilio Vivancos, and Vicente J Botti. Integrating expectations into Jason for

appraisal in emotion modeling. In IJCCI (ECTA), pages 231â€“238. Scitepress, 2016.

[73] Joaquin Taverner, Emilio Vivancos, and Vicente Botti. A multidimensional culturally adapted representation of
emotions for aï¬€ective computational simulation and recognition. IEEE Transactions on Aï¬€ective Computing, 2020.

[74] Joaquin Taverner, Emilio Vivancos, and Vicente Botti. A fuzzy appraisal model for aï¬€ective agents adapted to

cultural environments using the pleasure and arousal dimensions. Information Sciences, 546:74â€“86, 2021.

[75] Renata Vieira, Â´Alvaro F Moreira, Michael Wooldridge, and Rafael H Bordini. On the formal semantics of speech-
act based communication in an agent-oriented programming language. Journal of Artiï¬cial Intelligence Research,
29:221â€“267, 2007.

[76] Li Wang, Zhanbiao Shi, and Huanhuan Li. Neuroticism, extraversion, emotion regulation, negative aï¬€ect and positive
aï¬€ect: The mediating roles of reappraisal and suppression. Social Behavior and Personality: an international
journal, 37(2):193â€“194, 2009.

[77] Henry M Wellman. Theory of mind: The state of the art. European Journal of Developmental Psychology, 15(6):728â€“

755, 2018.

[78] Joshua D Wondra and Phoebe C Ellsworth. An appraisal theory of empathy and other vicarious emotional experi-

ences. Psychological review, 122(3):411, 2015.

[79] Â¨Ozge Nilay YalÂ¸cÄ±n and Steve DiPaola. A computational model of empathy for interactive agents. Biologically inspired

cognitive architectures, 26:20â€“25, 2018.

[80] Â¨Ozge Nilay YalÂ¸cÄ±n and Steve DiPaola. Modeling empathy: building a link between aï¬€ective and cognitive processes.

Artiï¬cial Intelligence Review, pages 1â€“24, 2019.

19

