e-GenIA3: An AgentSpeak extension for empathic agents

Joaquin Taverner1,∗, Emilio Vivancos1, and Vicente Botti1
1Valencian Research Institute for Artiﬁcial Intelligence, Universitat Polit`ecnica de Val`encia, Spain
∗ Corresponding author: Joaquin Taverner (joataap@dsic.upv.es)

August 2, 2022

Abstract

2
2
0
2

g
u
A
1

]

A
M

.
s
c
[

1
v
7
3
7
0
0
.
8
0
2
2
:
v
i
X
r
a

In this paper, we present e-GenIA3 an extension of AgentSpeak to provide support to the development
of empathic agents. The new extension modiﬁes the agent’s reasoning processes to select plans according to
the analyzed event and the aﬀective state and personality of the agent. In addition, our proposal allows a
software agent to simulate the distinction between self and other agents through two diﬀerent event appraisal
processes: the empathic appraisal process, for eliciting emotions as a response to other agents emotions,
and the regular aﬀective appraisal process for other non-empathic aﬀective events. The empathic regulation
process adapts the elicited empathic emotion based on intrapersonal factors (e.g., the agent’s personality and
aﬀective memory) and interpersonal characteristics of the agent (e.g., the aﬀective link between the agents).
The use of a memory of past events and their corresponding elicited emotions allows the maintaining of an
aﬀective link to support long-term empathic interaction between agents.

Keywords— Empathy, aﬀective computing, empathic regulation, appraisal, multi-agent systems

1

Introduction

Computer systems that are oriented to the paradigm of human-machine interaction are becoming more relevant in society.
Systems of this type are progressively becoming more complex and require higher level abstractions and metaphors to
describe capabilities and characteristics that cannot be explained by classical lower level speciﬁcations. Endowing
software agents with aﬀective abilities, particularly empathic abilities, is one of the metaphors that will make it possible
to improve the simulation of human aﬀective behavior and to transform the human-machine interaction paradigm by
making it more human-oriented. Empathy is a concept that has evolved over the years, whose meaning refers to a wide
range of aﬀective and cognitive competencies that are fundamental in the development of the human being as a social
being [32]. These competencies allow one “to put oneself in others’ shoes” and to understand and share their feelings and
thoughts, which generates a series of pro-social behaviours aimed at improving their well-being [13]. In any empathic
interaction, we can distinguish two actors: the target actor, who is the person or agent that suﬀers the eﬀect of an action
or situation, and the observer, who is the person (or agent) that perceives that action or situation and feels empathy for
the target person.

Diﬀerent theoretical approaches that try to explain the cognitive processes related to empathy have been proposed
in psychology, sociology, philosophy, ethology, and neuroscience. The most recent theoretical approaches provide a
conceptualization of empathy from a perspective derived from appraisal theories that relate the emergence of emotions
to a cognitive appraisal of an event [21, 36]. Under this perspective, empathy arises from the appraisal of the perception
of a situation or an emotion in others [30,78]. Moreover, according to several authors, empathy is aﬀected by a regulation
process that modulates the empathic response to an event according to diﬀerent factors, including intrapersonal (e.g.,
personality) and interpersonal (e.g., aﬀective bond or social tie with the target) factors [10, 13, 16].

For years, the inherent characteristics of human aﬀective behavior have been the subject of research in the ﬁeld of
aﬀective computing [51]. In this ﬁeld, there has been a growing trend towards the development of models to simulate
empathy [50, 80]. Most of these models use the agent-oriented paradigm. Empathic agents have been shown in multiple
experiments to improve the user experience in human-machine interactions [46, 47, 61].
In general, these models are
designed to be implemented ad hoc making the agent speciﬁcation programmer and domain dependent.

This paper presents e-GenIA3, an extension of the syntax, semantics, and the reasoning cycle of the well-known
agent-oriented language AgentSpeak [56] to support the development of agents with empathic abilities implemented on
the GenIA3 architecture [2]. Our model is based on recent empathic appraisal theories to elicit empathic emotions when
a software agent perceives or is aware of an emotion or a situation in other agents or humans. In addition, our empathic
agent model has an emotion regulation process that adapts emotions to diﬀerent intrapersonal and interpersonal factors.
The rest of this paper is organized as follows. In Section 2, theoretical frameworks supporting aﬀective states and
empathy along with a discussion of proposals made in aﬀective computing to simulate aﬀective and empathic capabilities
are presented. Section 3 describes the GenIA3 architecture. Section 4 introduces e-GenIA3, an AgentSpeak extension to
facilitate the development of agents with empathic abilities. In Section 5 a default design for all the processes described
in Section 4 is presented. Finally, the main conclusions and some future works are presented in Section 6.

1

 
 
 
 
 
 
2 Related work

For years, the area of aﬀective computing [51] has been working to design models to understand and simulate non-rational
behaviors such as aﬀective behaviors [39, 50, 73]. These models generally include diﬀerent constructs such as aﬀective
states, personality, or empathy that come from diﬀerent branches of psychology, ethology, philosophy, and sociology.
Over the years, diﬀerent theorist have tried to provide an answer to the phenomenon of aﬀective states, which involves
constructs such as emotions and moods. One of the most recognized theories is the appraisal theory [21,36], according to
which, when a stimulus is received, an appraisal process occurs, resulting in an emotion. Emotion is generally considered
to be a quick response to certain stimuli with short duration. Appraisal theory is based on the existence of diﬀerent
variables known as Appraisal Variables. Diﬀerent authors diﬀer in the number and type of Appraisal Variables involved
in the emotion generation process. For example, K.R. Scherer [65] proposed a model in which twenty-two Appraisal
Variables were deﬁned, while A. Ortony, G. Clore, and A. Collins [48] proposed a more simpliﬁed model, known as
OCC, with only eight Appraisal Variables. However, appraisal theory is not the only theory that has been developed
to explain the phenomenon of emotion. Basic emotion theories relate events to a limited number of emotions. For
example, the basic theory of emotions proposed by P. Ekman [19] uses six basic emotions: Happiness, Surprise, Fear,
Anger, Disgust, and Sadness. In contrast to these basic emotion theories, the constructivist theories advocate for a more
universal concept of emotion. Constructivism holds the existence of an unlimited number of emotions which can present
cross-cultural diﬀerences [63]. One of the most recognized constructivists is J.A. Russell who proposed the Circumplex
Model of Aﬀect [62]. According to Russell, emotions can be expressed in a two-dimensional space that is composed of
the dimensions of Pleasure and Arousal. This theory is in line with the ﬁndings of neuroscience made in recent years [53].
More recent theories suggest the need to use models with more dimensions, such as Dominance or Novelty, to better
explain the diﬀerences between emotions [44, 66].

On the other hand, it is generally accepted that, in contrast to emotions, moods are unfocused and diﬀuse aﬀective
states that have a longer duration (from minutes to days) and a lower intensity than emotions [6]. The variation in mood
duration is sometimes attributed to the time the mood spends in transitioning to a neutral state or equilibrium state [31].
Both the equilibrium state and the speed of transition may vary depending on the individual’s aﬀective characteristics.
Moreover, it should be considered that both emotions and mood are inﬂuenced by personality [64]. Empirical evidence
suggests that personality is involved in emotion regulation processes making individuals more or less prone to certain
emotions or moods [18, 76]. One of the most recurrent theories of personality is the OCEAN model [42]. This model
deﬁnes personality through ﬁve dimensions: Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism.
These ﬁve dimensions have an eﬀect on the aﬀective states that can be elicited in an individual. Apparently, the most
evident relationships arise when relating positive aﬀective states to Extraversion and when relating negative aﬀective
states to Neuroticism [17].

Finally, empathy is a construct that is used in diﬀerent domains, such as psychology, ethology, sociology, or philosophy,
to describe a variety of psychological attitudes that enable the development of social individuals, encompassing a large
number of emotional, ethical, moral, and social aspects [11, 49].
In general terms, empathy is an ability that allows
humans to understand and feel the aﬀective state of others, resulting in behavior directed toward mutual understanding.
Several authors consider empathy to be a fundamental ability that allows the establishment and maintenance of social
bonds [33,59,67]. Empathy also plays a fundamental role in our society, aﬀecting both morality and mutual understanding
and promoting relationships and collaborations through the exchange of experiences, needs, and desires [13, 40].

In its earlier deﬁnition, empathy was described as an innate instinct that produces a self-awareness in the experience
and awareness of the target in the observer without any perspective-taking, associative, or cognitive process [24, 70].
This concept evolved over the years in diﬀerent theories until the discovery of mirror neurons [60], which established a
relationship between perception and action allowing a greater understanding of how imitation and empathy are produced
in the brain and are related to emotion experiences [20, 35]. Based on this relationship between perception and action,
S.D. Preston and F. De Waal [55] proposed a theory of empathy known as the Perception Action Model (PAM). According
to the PAM, when the observer perceives an emotion in the target, he/she can experience the same emotion automatically
and not consciously, producing a matching of mental states between the observer and the target [54]. The PAM is used
as a basis for explaining the evolution of higher-level cognitive processes related to cognitive empathy. For example, De
Waal proposes the The Russian Doll model [15]. This model uses the analogy of a Russian doll, stratifying the empathic
processes in diﬀerent layers. The inner layers represent the most primitive mechanisms of empathy related to the PAM
such as mimicry or emotional contagion. The top layers represent higher level processes such as perspective-taking.
Nonetheless, contemporary theories argue that, if empathy was an automatic process resulting from direct perception
as suggested by the PAM, then humans would be constantly empathizing [14, 30]. However, there are situations in
which empathy is inhibited. This inhibition is produced by an adaptation resulting from a cognitive process known
as empathic regulation. For instance, professionals in psychiatry are able to distance themselves from the patient’s
emotions [29]. Factors that inﬂuence empathy regulation have been widely discussed in academia [14, 15, 55, 78].
In
general, these regulation factors can be grouped into three categories: i) factors related to the internal characteristics
of the observer such as personality, mood, age, life experiences, or gender [26]; ii) situative context factors such as the
existence of more than one target suﬀering diﬀerent experiences, which makes it diﬃcult to empathize [14]; and iii)
factors concerning the level of relationship between the observer and the target [14]. This last category encompasses
diﬀerent interpersonal factors such as: similarity, which are the perceived similarities between the observer and the
target (e.g., gender, personality, mood, or age); familiarity, which is related to the observer ’s previous experiences with
the target in similar situations; and the level of relationship [14] (or social tie [4]) between the observer and the target
derived from the interactions they have over time [16] (henceforth referred to as aﬀective link in order to facilitate the
reading of this paper).

2

New advances address the phenomenon of empathy from an appraisal theory perspective [10,13,30,77,78]. Under this
perspective, empathy is related to higher-level cognitive processes such as other-oriented perspective-taking, self-oriented
perspective-taking, and Theory of Mind [77] (which holds that people are able to understand the mental states of others
thanks to a system of rules based on their own experiences [23, 29]). These cognitive processes require the observer
to have knowledge of aﬀective and non-aﬀective information about the target (e.g., beliefs, desires, and goals) [28]. In
addition, empathy does not always requires the observer to perceive the target’s aﬀective states but is described as a
process of higher-level understanding of the target’s situation that allows the emergence of other aﬀective experiences
(e.g., when we rejoice because someone has achieved a goal) [3, 49].

2.1 Empathy in software agents

The relationship of empathy with social behavior and interpersonal relationships has aroused the interest of many
researchers who focuses on the areas of human behavior simulation and human-machine interaction [37, 47, 68]. Systems
that are capable of simulating aﬀective and empathic abilities have been used in diﬀerent contexts and have proved to
be more reliable and more credible [1, 12, 50]. Most of these proposals are focused on the agent-oriented programming
(OAP) paradigm to develop agents with empathic abilities. For example, in the study conducted in [46], a robot with
empathic abilities was used in an educational environment. The study determined that the empathic robot was able to
elicit and maintain the social engagement of the participants of the experiment. Similarly, the experiments conducted
with empathic agents in [47] showed that participants had a better perception of the agent when it displayed empathic
emotions. Also, the research performed in [61] showed that agents with empathic abilities increased the involvement and
sociability of participants. Therefore, considering these results, it is not surprising that, in the search for improvement
in the simulation of human behavior and human-machine interaction, diﬀerent proposals for computer systems with
empathic abilities have appeared over the years. For example, ¨O.N. Yal¸cın and S. DiPaola [79] introduced a model of an
empathic agent, based on The Russian Doll model, composed of three layers. In the bottom layer, the communication
competence contains the processes related to the recognition and the expression of emotions. The middle layer represents
emotion regulation processes. Finally, the top layer, called cognitive mechanisms, includes Theory of Mind and appraisal.
Another interesting approach is proposed in [58]. Authors present a model for an empathic agent that was based
on the perception of the target’s emotion to simulate an empathic interaction. The system has a perception layer that
recognizes human emotional facial expressions. Then, the system makes an estimation of the empathic emotion by means
of a regulation process that uses the agent’s personality and mood as regulation factors. They use the mapping proposed
in [43] to establish the relationship of personality and mood in a two-dimensional space that is based on Pleasure and
Arousal.

Other models focus more on the simulation of empathy through the simulation of high-level cognitive processes. For
instance, the model presented in [61], which also relies on the theory of De Vignemont and Singer to deﬁne the empathic
process [14], focuses on the self-projection appraisal based on OCC to elicit the empathic emotion. The appraisal process
is based on a set of predeﬁned rules that deﬁne the relationship of events to desirability. The elicited emotion is adapted
by using the aﬀective link, similarity, mood, and personality in an empathic regulation process. Similarity is obtained
by comparing the intensity and valence of both the perceived and the elicited emotions. Personality is composed of
a set of thresholds for each emotion. However, these factors only aﬀect the intensity of the emotion elicited in the
empathic appraisal. Another example of the simulation of cognitive processes can be found in [47] in which a model of
an embodied empathic dialogue agent is presented. The purpose of this agent was to simulate an empathic interaction
with human users. The agent deduced the user’s emotions through the dialogue using a perspective-taking strategy and
then responded by showing the same emotion. The agent was able to regulate the intensity of the empathic emotion
based on a preset degree of empathy between the agent and the user. Experiments conducted with the agent showed
that participants had a better perception of the agent when it displayed empathic emotions.

Diﬀerent authors have emphasized the need to consider the inclusion of long-term interactions to improve the sim-
ulation of empathic interactions [38, 50]. However, not much work has been done on this topic. For instance, in [37] a
model of empathy based on emotion recognition is proposed. The system is based on a robot called iCat that interacts
with children while playing chess. The iCat maintains the actions that children perform in chess moves in its memory
and uses this information to determine the next move taking into account the children’s emotions.

From what has been explained above, it can be deduced that most of the models of agents with empathic abilities
use three fundamental processes: i) a perception process, in which an emotion or situation is perceived; ii) an empathic
appraisal process, in which an empathic emotion is elicited; and iii) an empathic regulation process, in which the empathic
emotion is adapted to diﬀerent regulation factors. Unfortunately, most of the works described above propose ad hoc
methods to simulate a certain level of aﬀective and empathic abilities, making the agent speciﬁcation highly dependent on
the programmer and diﬃcult to generalize to other domains. The use of a commonly-used agent-oriented programming
language can help to improve the development of empathic agents. In addition, these languages generally include support
for processes such as perception, multi-agent communication, and rational behavior. One of the most well-known agent-
oriented programming languages is AgentSpeak [56]. AgentSpeak is a language that is based on the logic programming
paradigm for developing agents using a BDI (beliefs, desires, and intentions) architecture. In a BDI architecture, agents
are deﬁned as intentional systems where an agent is provided with a set of mental attitudes. BDI agents are composed
of a set of beliefs, desires and intentions. Beliefs represent the information that the agent has about the state of its
environment. Desires are goals that the agent wants to achieve. Intentions are commitments made by the agent, i.e.
those goals that the agent selects to achieve. The BDI architecture provides the basis for the development of agents based
on practical reasoning. Practical reasoning is an inference process through which agents evaluate and weigh their options
taking into consideration the context of the practical situation in which they are involved and their knowledge about

3

the environment. The result of this inference process is the modiﬁcation, deletion, or addition of beliefs and intentions,
altering the mental state of the agent. There are some approaches that have used the BDI model to design agents with
aﬀective capacities [2,9]. For example, in [27] an appraisal process based on the OCC model for eliciting emotions in BDI
agents is proposed. Another interesting proposal is presented in [1], in which a logical formalization for emotion elicitation
in BDI agents based on OCC theory is presented. In the same way, a formal extension of the KARO framework [45]
is proposed in [69] to elicit emotions in BDI agents following the OCC theory. Regarding empathy and social abilities,
FAtiMA, an architecture for the development of aﬀective BDI agents, is proposed in [41]. This architecture uses an
appraisal model based on the OCC theory for the development of empathic agents. Another interesting approach can be
seen in [9] in which an embodied virtual agent model with empathic abilities known as EMMA (Empathic MultiModal
Agent) is presented. In that model, an agent is essentially composed of a reasoning module and an empathic module.
The reasoning module is based on the BDI architecture [57]. The empathic module has a facial expression recognition
system and an empathetic appraisal process that is based on the De Vignemont and Singer theory [14]. To estimate
the empathic emotion, the agent attempts to internally mimic the recognized facial expression using a set of patterns
called Action Units (UAs). Subsequently, the emotion is regulated in an emotion regulation process that is based on the
Pleasure-Arousal-Dominance (PAD) model [44]. This process modiﬁes the PAD components of emotions by means of a
set of regulation factors that include similarity, mood, and deservedness (which represents the degree to which the target
deserves or does not deserve the event).

Although there are several proposals extending AgentSpeak with diﬀerent features [7, 8, 75], there are very few
proposals that use it when deﬁning aﬀective or empathic agents. For instance, in [34], an empathic agent model based on
AgentSpeak is presented for the resolution of conﬂicts of interest in interactions between agents. However, this approach
focuses on utility-based functions to ﬁnd solutions that are mutually acceptable, but no aﬀective characteristic of the
agents is considered in the utility functions. One of the most signiﬁcant eﬀorts to allow the use of aﬀective agents in
AgentSpeak is the GenIA3 architecture [2]. GenIA3 is a general-purpose architecture that extends AgentSpeak providing
a platform that is easily adaptable to diﬀerent theories of emotion in order to facilitate the development of aﬀective agents.
GenIA3 adds new processes for the management of aﬀective states, which are described in detail in Section 3. However,
before the work presented here, this architecture did not provide the necessary support to the development of agents
with empathic abilities.

3 The GenIA3architecture

The GenIA3 architecture implements an extension of the syntax and operational semantics of the agent-oriented language
AgentSpeak [56]. This architecture is based on a modular design that can be easily adapted both to diﬀerent psychological
and neuroscience theories and to diﬀerent domain-speciﬁc aﬀective characteristics (e.g. personality or mood). To this
end, GenIA3 uses general components (described below) to integrate the aﬀective processes and characteristics with in
the cognitive process of a BDI agent. GenIA3 oﬀers a ﬂexible approach that allows aﬀective processes to inﬂuence the
agent’s behavior by, for example, modifying goal priorities and/or generating new intentions. In GenIA3, an agent is
deﬁned with its own personality, mood, and concerns (i.e., interests, motivations, ideals, or standards). This factors will
inﬂuence the agent’s behavior by prioritizing its goals or generating new goals. The agent’s concerns together with the
desirability of an event are used for the agent to decide whether the event is aﬀective or not. Additionally, the agent also
categorizes events and plans as aﬀective using the annotation affective relevant (see Section 4.3 for the deﬁnition
of annotations in AgentSpeak). Plans can also be deﬁned using the agent’s personality proﬁle or the aﬀective state (or
aﬀective states) as preconditions for triggering the plans. One of the main advantages of this architecture is the ability
to prioritize the aﬀective or the BDI reasoning cycles. In contrast to other aﬀective agent architectures such as FAtiMA,
GenIA3 facilitates the establishment of a balance between the aﬀective and the rational reasoning cycles. One of the
personality parameters of a GenIA3 agent is the rationality level, which can be speciﬁed by the programmer or estimated
automatically from the values of the personality. This parameter allows to establish the priority ratio between the agent’s
practical reasoning processes and the aﬀective processes. GenIA3 also allows to specify how, the changes that occur in
the agent’s aﬀective state, generate behaviors through an explicit and integrated coping model (see [2] for more details
about the coping process of GenIA3).

The reasoning BDI cycle of GenIA3 works as follows: ﬁrst, in the process message (ProcMsg) step, all of the pending
messages received by the agent are processed; then, the select event (SelEv) step selects one event to be processed taking
into account all of the perceptions, messages, and stacked events. Next, the relevant plans (RelPl) step retrieves all
of the relevant plans considering the selected event; these plans are used to generate a list of applicable plans in the
applicable plans (ApplPl) step. From this list, one applicable plan is selected in the select applicable plan (SelAppl)
step. Then, in the add intended means (AddIM) step, all of the intended means are added to the set of intentions; the
select intention (SelInt) step selects one intention to be executed from the set. The selected intention is executed in the
execute intention (ExcInt) step. Finally, the executed intention is cleared from the set of intentions in the clear intention
(ClrInt) step.

GenIA3 introduced a new aﬀective cycle that consist of ﬁve steps (dark gray shaded boxes in Figure 5) the event
appraisal (Appr) step in which the selected event is appraised; the aﬀect adaptation (AffAd) step in which the agent’s
mood is modiﬁed to adapt the mood according to the result of the appraisal emotion; the select coping strategies (Selcs)
step in which the coping strategies are selected according to the agent’s mood; and the cope (Cope) step, in which
the coping strategies are executed. In addition, GenIA3 incorporates an aﬀective state decay process (AsDecay) that
continuously shifts the mood toward an equilibrium state to simulate real mood change in humans. The rate at which
the mood moves to the equilibrium state can be set by the user. Finally, GenIA3 modiﬁed the AgentSpeak’s rational cycle

4

Figure 1: Participants involved in an empathic event.

to add two new steps: the aﬀective modulation of beliefs (AffModB) step in which beliefs are modiﬁed according to the
agent’s mood; and the evaluate expectations (EvalExp) step, which includes the possibility to add temporal expectations
to agents [72]. GenIA3 allows to modify the agent’s behavior to simulate aﬀective behaviors. For this purpose, GenIA3
modiﬁes the selection of applicable plans, considering the agent’s rationality level. GenIA3 uses two separate sets of
applicable plans: a set of applicable plans R selected by the BDI practical reasoning cycle, which considers the beliefs
and desires and intentions of the agent; and a set of applicable plans A that, in addition to beliefs, desires, and intentions,
also consider, agent’s concerns and aﬀective characteristics such as personality, emotion, or mood. Subsequently, the
ﬁnal applicable plan is selected, in the select applicable plan (SelAppl) step, using the equation:

applicable plan = arg max
p∈(R ∪ A)

(cid:26)Priority(p) · rl,

Priority(p) · (1 − rl ),

if p ∈ R
if p /∈ R

(1)

that considers the priorities Priority(p) of the plan p ∈ (R ∪ A) and the rationality level rl of the agent.
To facilitate the development of aﬀective agents, GenIA3 incorporates a default design that can be adapted by
advanced users interested in customizing the behavior of the agent. In this default design, the user can choose between
two diﬀerent appraisal models: a model based on OCC theory [48] that uses the appraisal variables deﬁned in [39]
(i.e., desirability, likelihood, and causal attribution) using a numerical approach; and a model based on Scherer’s theory
using fuzzy logic to deﬁne the appraisal rules [74]. GenIA3 also oﬀers the possibility of selecting between two models
of representation of aﬀective states: a model based on the PAD [44] described in [2]; and a multidimensional culturally
adapted representation of emotions presented in [73]. Finally, in this default design, the personality is deﬁned by the
OCEAN model [42].

4 e-GenIA3 an AgentSpeak extension for empathic agents

In this section, we present e-GenIA3 an extension of the syntax, semantics, and the reasoning cycle of an AgentSpeak
agent to support the development of agents with empathic abilities. This extension allows emotions and empathy to have
an eﬀect on the practical reasoning of the agent. Emotions and empathy will be involved in an aﬀective cycle that will
aﬀect that will aﬀect the agent’s reasoning processes. To do that, we have extended the GenIA3 architecture with a new
syntax and semantics to facilitate the emergence of empathy in software agents. e-GenIA3 includes the three fundamental
processes identiﬁed in the literature on empathic agents discussed in Section 2.1: perception, empathic appraisal, and
empathic regulation (see Figure 5). The perception process is an intrinsic part of AgentSpeak. However, we have added
a new process to diﬀerentiate empathic aﬀective events from other aﬀective events, the event classiﬁcation (EvClass)
process. This process consists of two phases. In the ﬁrst phase, an event is perceived following the process described
in [8]. In the second phase, the event is evaluated to determine whether or not it is an aﬀective event. This second phase
deﬁnes the agent’s cognitive ability to maintain a sense of self as distinct from the target agent to elicit a target-oriented
empathic emotion. This cognitive ability is simulated using two diﬀerent appraisal processes: one for empathic events
(EmphAppr) and the other for non-empathic aﬀective events (Appr). On the other hand, empathic appraisal is composed
of a self-projection appraisal, which evaluates the event using the agent’s own beliefs, concerns, and aﬀective memory.
The empathic regulation process (EmphReg) adapts the empathic emotion to the agent’s aﬀective characteristics (e.g.,
mood or personality) and the knowledge that the agent has about the target (e.g., aﬀective link or trust level). Finally,
the emotion selection process (EmSel) selects the most appropriate emotion.

4.1 A simple example

From the theories of empathy previously cited, it can be assumed that, for empathy to occur, there must be at least two
actors: one who suﬀers in a situation (the target) and another who perceives the situation and reacts empathetically
(the observer or empathic agent). To make the reading more convenient, we illustrate the problem with an example. Let
us assume a more general scenario with three actors: Marshall, Lily, and Barney. At one point in time Marshall slaps
Barney in the face. This event causes Barney to become sad. Lily, who is in the same room, sees the entire scene and
empathizes with Barney and feels sorry for what has happened to him.

In this scenario, there are basically two interactions: ﬁrst, Marshall performs an action directed to Barney; second,
Lily perceives what has happened to Barney. Three diﬀerent roles of agents can be identiﬁed in these interactions.
Marshall, the agent that performs the action, henceforth known as the subject agent; Barney, the agent that receives the
consequences of the action, henceforth known as the target agent; and Lily, who perceives the action, henceforth known
as the observer agent, and that can potentially empathize with the target of the event.

5

TargetSubjectActionObserverMarshallBarneyLilySlapFigure 2: e-GenIA3 agent conﬁguration.

4.2 Formalization of an empathic agent

In [56], the agent-oriented language AgentSpeak semantics is deﬁned using an operational semantics formalism. This
operational semantics deﬁnes the structure and the conﬁguration of the agent program and the transitions derived from
its internal reasoning. In this section, we extend this operational semantics to deﬁne the new e-GenIA3 conﬁguration for
empathic agents.

Figure 2 shows the new conﬁguration of a e-GenIA3 agent. The dark gray shaded attributes are the ones that
GenIA3 added to the original conﬁguration proposed for AgentSpeak in [7]. The light gray shaded attributes represent
the new components of e-GenIA3 to add information that is relevant to the development of empathic agents. In this
new conﬁguration, an agent is deﬁned by a tuple (cid:104)ag, C, M, T, s, Mem, Ta, O, ast(cid:105), where:

– ag is the set of attributes that constitute the agent deﬁned by the tuple (cid:104)P, ps, cc, bs(cid:105), where:

– P is the agent’s personality represented by the tuple (cid:104)tr, rl, cs(cid:105), where:

– tr is a set of personality traits. Each personality trait is a value representing the level that the agent
has of that personality trait. For example, when using the OCEAN model, ﬁve personality traits are
deﬁned, one for each component of the OCEAN model.

– rl is a value representing the agent’s rationality level. The higher the rationality level, the higher the
priority of plans activated in a rational BDI cycle, making the agent more rational. However, the lower
the rationality level, the higher the priority of plans activated by the aﬀective cycle, making the agent
more emotional.

– cs is the agent’s set of coping strategies. These coping strategies relate aﬀective states and beliefs to a

set of intentions that will be included in the agent’s agenda.

– ps and bs represent the set of plans and the set of beliefs of the agent, respectively.

– cc is the set of concerns of the agent that represents the motivations, standards, ideals and/or interests of

the agent.

– C is the current circumstance represented by a tuple composed of: I, which is the set of intentions {i, i(cid:48), · · · };
E, which is a set of events composed of a set of tuples (cid:104)triggering event te, intention i(cid:105); and A, which is a set of
actions {a, a(cid:48), · · · }.

– M are the communication parameters represented by the tuple (cid:104)In, Out, SI(cid:105), where In and Out represent the list
of input and output messages, respectively and SI is a set of suspended intentions composed by a set of tuples
(cid:104)message identiﬁer mid, intention i(cid:105). Each message msj is composed of the message identiﬁer mid, the identiﬁer
of the agent which sent the message id (i.e., the sender agent), the illocutionary force ilf, and the message content
cnt.

– T is the temporary information of the current rational cycle consisting of a tuple containing: an applicable plan
ρ, a particular intention ι, the sets of relevant plans R, the set of applicable Ap plans composed of a set of plans
{p, p(cid:48), · · · }, and the event ε that triggered the rational cycle represented by a tuple (cid:104)triggering event te, intention i(cid:105).

– s is the current step of the rational cycle where:

s ∈ {ProcMsg, AffModB, EvalExp, SelEv, RelPl,

ApplPl, SelAppPl, AddIm, SelInt, ExcInt, CrlInt}

(2)

– Mem is the aﬀective memory that, in the original GenIA3 architecture, consists of a set of events. In e-GenIA3,
it consists of a set of aﬀective events ae. An aﬀective event ae is deﬁned as a tuple (cid:104)event ε, aﬀective value av(cid:105),
where the aﬀective value av is an attribute that represents the emotion that the event ε produced in the agent.

– Ta represents the temporal information of the aﬀective cycle and is composed of: Ub, which is a tuple containing
the set of beliefs that are going to be added to the belief base Ba, the set of beliefs that are going to be removed
from the belief base Br, and the identiﬁer of the step st of the cycle in which the beliefs are going to be added or
removed; Av, which is the set of appraisal variables; Cs, which is the set of coping strategies to be executed; Ae,

6

𝜀⃗e⟨ag,     C,     M,     T,     s,     Mem,     Ta,     O,     ast⟩   ⟨P,ps,cc,bs ⟩ ⟨I,E,A ⟩ ⟨In,Out,SI ⟩ ⟨𝜌,𝜄,R,Ap,𝜀 ⟩ {ae,ae’,…} ⟨Ub,Av,Cs,Ae,Ee,Fe,𝜎 ⟩    ⟨tr,rl,cs ⟩ {i,i’,…}     {a,a’,…}      {p,p’,…}                  ⟨ ,av ⟩  ⟨Ba,Br,st ⟩      {⟨te,i ⟩,⟨te’,i’ ⟩,…} {msj,msj’,…} {⟨mid,i ⟩,⟨mid’,i’ ⟩,…} p,𝜃⟨te,i ⟩                     ⟨mid,id,ilf,cnt ⟩                      {  ,   ’,…}          {⟨id,al,𝜎 ⟩,⟨id’,al’,𝜎 ⟩,…}⃗e⃗e⃗σ⃗σ⃗σwhich is the set of emotions that can be elicited by the appraisal process; Ee, which is the set of empathic emotions
that can be triggered by the empathic appraisal process; Fe, the ﬁnal emotion (or emotions) resulting from the
emotion selection process; and (cid:126)σ, which represents the current mood of the agent. The emotions contained in Fe
will be the ones considered as active in the aﬀective cycle. Emotions and mood are represented by a n-dimensional
vector (cid:126)e. For example, for the PAD model, this vector will have three components (i.e. one for each dimension).

– O is a new component which is added to represent the information that the empathic agent knows about other
agents in the environment. This information is composed of a set of tuples each of which corresponds to one agent
in the environment. Each tuple contains the agent identiﬁer id, the aﬀective link al that the empathic agent has
with the agent identiﬁed by id, and the id agent’s mood (cid:126)σ. This tuple can be extended in the future to contain
more knowledge about agents in the environment, such as their concerns, goals, beliefs, or trust level. The aﬀective
link is a value that indicates the aﬀective link between both agents. The greater the aﬀective link value, the greater
the relationship between the agents. Negative aﬀective links indicate enmity between the agents. The aﬀective
link can be modiﬁed due to the interactions between the agents.

– ast is the current step of the aﬀective cycle, where:

ast ∈ {EvClass, Appr, EmphAppr, EmReg,

EmphReg, EmSel, AffAd, SelCs, Cope}

(3)

4.3 Extending the AgentSpeak language to identify the actors of an empathic

interaction

In AgentSpeak, an agent is deﬁned as a set of beliefs and a set of plans. The knowledge contained in the belief base
may not necessarily be complete or accurate, since the environment may be very large and may experience changes that
the agent has not perceived. On the other hand, plans contain basic actions that the agent can perform to change its
environment. Plans are composed of a triggering event, a context, and a set of sequential instructions that may include:
updates to the belief base, actions, or goals. Triggering events refer to the addition or deletion of beliefs or goals. In
AgentSpeak, both beliefs and goals are deﬁned as atomic formulas [56]. An atomic formula representing a belief or a
goal is composed of a predicate and a set (possibly empty) of n terms of a ﬁrst order logic:

predicate(term1, term2, · · · , termn)

(4)

For example, the triggering event time(cloudy) is composed of the predicate ‘time’ and the term ‘cloudy’.
In [75] and [7], the concept of annotation was added to AgentSpeak to provide the ability to express properties

associates with events and beliefs. The syntax for an atomic formula with annotation in AgentSpeak is:

where each ai represents the ith annotation deﬁned as:

predicate (term1, term2, · · · , termn) [a1, a2, · · · , am]

ai = functori

(cid:0)term(cid:48)

i,1, term(cid:48)

i,2, · · · , term(cid:48)

i,n

(cid:1)

(5)

(6)

where an atom (called functor) is followed by a number of terms (called arguments). term(cid:48)

i,j is the jth term of the

annotation ai.

This extension of the language provides more expressiveness to AgentSpeak allowing diﬀerent types of properties to
be deﬁned. For example, we can add one annotation to an event to represent the sources of the event. The keyword that
we use to represent this annotation is ”source”. For example, in the triggering event:

time (cloudy) [source(Marshall)]

the annotation source(Marshall) indicates that the source of the triggering event is the agent Marshall.
In general, there are three possible sources for an event:

– perceptions, which represent the information that the agent perceives from its environment. Perceptions are

represented by the annotation source(percept).

– mental notes, which represent beliefs that the agent acquires or deduces by itself, such as memories or changes in

the agent’s state. The mental notes are expressed through the annotation source(self).

– communications, which is the information that comes from another agent of the system as a consequence of a

communication act.

In our proposal, we have extended AgentSpeak with new annotations that allow the events with relevant information
for empathy to be contextualized for its simulation. As we discussed in Section 2, the empathic regulation process is
aﬀected by a set factors that include interpersonal factors related to the target agent such as the aﬀective link, concerns,
goals, similarity, or trust level. Therefore, to elicit an empathic emotion, it is necessary to identify the target agent when
an event occurs. This information can be implicit in the semantics of the event, in which case the agent may deduce the

7

target of the action through an inference process, or it can be explicitly incorporated into the syntax of the triggering
event. We have used this second approach because it simpliﬁes the agent’s programming by easily identifying the subject
and the target of an event. We have extended the representation of a triggering event to explicitly include the agents
involved in an action (i.e., subject and target agents) without modifying the original syntax of the atomic formula of
AgentSpeak. This has been achieved using two annotations to identify the agents participating in the action represented
by the triggering event: the subject annotation, which identiﬁes the subject agent that performs the action; and the
target annotation, which identiﬁes the target agent receiving the consequences of the action. Following this deﬁnition,
a triggering event will be represented by the structure:

predicate (term1, term2, · · · , termn)
[subject(subject
id), target(target

id), a3, a4, · · · , an]

(7)

id and target

where subject

id are the identiﬁers of the subject agent and the target agent, respectively. Note that,
the order in which the annotations are deﬁned is not relevant since the annotations can be written in any order. By
adding these new annotations, it is now possible to identify the agents involved in any action. Based on the example of
Section 4.1, we can use the following expression to specify the triggering event “Marshall has slapped Barney”:

slap[subject(Marshall),target(Barney)]

This event has a predicate “slap” and two annotations: subject(Marshall) and target(Barney). Moreover, we
propose adding an optional annotation to include the value of the interaction. The interaction value of a triggering
event is an optional number that is associated with the triggering event in the range of [−1, 1], which identiﬁes if the
interaction is good (positive interaction value), bad (negative interaction value), or neutral (interaction value equals 0)
for the agent that receives the action. The interaction value is used to update the aﬀective link between the agents. A
positive interaction value indicates that the interaction has a positive eﬀect on the aﬀective state of the target agent,
improving the aﬀective link that the target agent has with the subject agent. A negative interaction value has a negative
impact in the agent’s aﬀective state and decreases the aﬀective link. An interaction value equal to 0 denotes that the
interaction has a neutral eﬀect on the aﬀective state of the agent. Therefore, it has no eﬀect on the aﬀective link. Note
that, if necessary, the interaction value can also be deduced automatically by the agent through the appraised emotion
(for instance, considering the level of pleasure of the generated emotions) or through an internal inference process.

We have introduced new functions to handle the annotations that will be used in Section 4.4 to formalize the new
internal processes of the aﬀective cycle of an agent. First, the function to obtain the subject agent of a triggering event
te is deﬁned as:

getSubject(te) :=

self,






termi,

null,

if ∃ ai ∈ teannots : functori =
‘subject’and termi (cid:54)= ag id
if ∃ ai ∈ teannots : functori =
‘subject’and termi = ag id
otherwise

(8)

where teannots is the set of annotations associated to the triggering event te, ai is the ith annotation of the set of
annotations teannots, functor is the functor of the annotation ai, termi is the term of the annotation ai, ‘subject’ is
a keyword that identiﬁes the subject annotation, and ag id is the agent’s identiﬁer. If termi is equal to the ag id, it
indicates that the triggering event comes from the agent itself. If termi is not the ag id, it indicates that the triggering
event comes from another agent. Finally, if there is no ‘subject’ annotation, it indicates that this triggering event
comes from an unknown subject.

Similarly, the target of a triggering event te is obtained through the function:

getTarget(te) :=




termi,



null,

if ∃ ai ∈ teannots : functori =
‘target’
otherwise

where ‘target’ is a keyword that identiﬁes the target agent annotation.
Finally, to obtain the interaction value of the triggering event te, we deﬁne the function:

getIV(te) :=




termi,



0,

if ∃ ai ∈ teannots :
functori = ‘InteractionValue’
otherwise

(9)

(10)

where ‘InteractionValue’ is a keyword that identiﬁes the annotation that contains the interaction value.

8

agent

→ init beliefs [concerns] [personality] [others info] init goals plans

others info → ‘others__:’ ‘[’ other ( ‘,’ other )* ‘]’
other
ag id

→ ag id ‘:’ ‘[’ list attr ‘]’
→ <ATOM>

list attr
attr label
personality → ‘personality__:’ ‘{’ list traits [‘,’ rat level] [‘,’ coping strats] ‘}’‘.’

→ ( attr label ‘:’ ( <NUMBER> | <ATOM> ) (‘,’ ( <NUMBER> | <ATOM> ) )*
→ <ATOM>

list traits → ‘[’ trait ( ‘,’ trait )* ‘]’
trait
trait label → <ATOM>

→ trait label ‘:’ <NUMBER>

Figure 3: Simpliﬁed extension of the agent’s syntax including the new extension of e-GenIA3.

mas

→ ‘MAS’ <ID> ‘{’ [infrastructure] [environment]

[execcontrol] [w matrix] ‘}’

w matrix

→ ‘w_matrix__:’ w weights ( ‘,’ w weights )*
→ ‘[’ trait label ‘:’ list weights ‘]’
w weights
→ <ATOM>
trait label
list weights → ‘[’ weight ( ‘,’ weight )* ‘]’

weight
em label

→ em label ‘:’ <NUMBER>
→ <ATOM>

Figure 4: Simpliﬁed extension of the MAS project syntax including the new extension of e-GenIA3.

4.4 Extending the AgentSpeak agent conﬁguration

The syntax of AgentSpeak was presented in [8] using the EBNF (Extended Backus-Naur Form) notation [5]. This syntax
was later extended by the GenIA3 architecture to allow the development of aﬀective agents [2, 71, 72]. In the original
EBNF syntax of GenIA3, an agent (agent) is deﬁned by the set of initial beliefs (init beliefs), concerns (concerns),
personality (personality), initial goals (init goals), and plans (plans). We have extended this syntax to incorporate
some new attributes to the agent conﬁguration. Figure 3 and 4 shows the extension of the EBNF syntax1. We have added
a new attribute to represent the knowledge that the agent has about other agents (others knowledge). To represent
this knowledge, we use a set consisting of the agent’s identity (ag id) and a list of attributes associated with that agent
(list attr). The list of attributes is deﬁned as a set of tuples consisting of the attribute label (attr label) and its
value. One of the most important attributes is the aﬀective link that represents the aﬀective proximity or relationship
between the agents. In our default design the aﬀective link is represented as a value ranging from [-1,1], but it can be
easily modiﬁed to use other values such as fuzzy values. Following the example described in Section 4.1, let us assume
that agent Marshall has an aﬀective link with agent Barney of −0.5 and an aﬀective link with agent Lily of 0.9. To
represent this knowledge, the following sentences must be added to agent Marshall’s deﬁnition:

others__: [ Lily: [ affective_link: 0.9 ],
Barney: [ affective_link: -0.5 ] ]

Note that the affective link is not the only attribute that can be represented. The number of attributes could be

increased to represent more information such as trust level or the other agents’ goals, concerns, and beliefs.

On the other hand, in GenIA3, the agent’s personality is deﬁned by the keyword “personality

:” followed by some
attributes: the traits (traits), which are deﬁned as a list containing a value for each personality trait; and optionally,
the rationality level (rat level), which is deﬁned as a numerical value representing how rational the agent is; and
the coping strategies (coping strats), which are deﬁned as a list of plans that will be used by the agent to deal with
aﬀective events. We have modiﬁed the deﬁnition of the personality traits in e-GenIA3 to make it more user friendly.
Now, the personality traits are deﬁned using a trait label (trait label) followed by the numeric value for that trait.
For example, let us suppose that the agent Marshall has an Extraversion level of 0.9 and a Neuroticism level of 0.1. We
can express this using the new syntax as follows:

personality__:

{ [ extraversion: 0.9,

neuroticism: 0.1 ] }

Finally, we have introduced a new attribute ω (em weights) to the multi-agent system (MAS) project. ω represents
a correlation matrix between the personality traits tr ∈ P and all of the possible emotion types t ∈ Ae ∪ Ee, where Ae
is the set of emotions that can be elicited by the appraisal process and Ee is the set of empathic emotions that can be
triggered by the empathic appraisal process. For each pair of values (tr, t), a weight p representing how the personality
trait tr inﬂuences the emotion type t can be speciﬁed, but many of these weights will be zero. Therefore, the set of
weights of the emotions can be viewed as the set of correlations between emotions and personality traits: the greater the

1Deﬁnitions of non-terminal syntactic symbols that have not been described in this section are detailed in [8] and [2].

9

Table 1: Example of a personality / emotion correlation matrix.

Emotions Extraversion Neuroticism
Anger
Sadness

0.8
0.7

0.5
0.6

Figure 5: New conﬁguration of both aﬀective and rational processes. White boxes represent the original
processes proposed for an AgentSpeak agent; dark gray shaded boxes are the original processes of the GenIA3
architecture; dashed lines indicate processes that have been redesigned in e-GenIA3; light gray shaded boxes
represent the new processes of e-GenIA3.

correlation between the personality trait tr and the emotion type t, the greater the value of p. For example, considering
that the trait of Extraversion E is related to positive emotions and Neuroticism N does not have a very high relation
with positive emotions [22], for the Happiness emotion, the Extraversion weight (ωHappiness,E) will be greater than the
weight of the Neuroticism for the Happiness emotion (ωHappiness,N ).

To deﬁne the syntax of the ω matrix, we use the keyword “w matrix

:” followed by one or more weights
(w weights). These weights are deﬁned as a label that identiﬁes the personality trait (trait label) followed by a
list of weights (list weights). This list of weights is composed of one or more emotion labels (em label) followed by
a number that represents the correlation between that personality trait and that emotion. For instance, let us consider
the following example in which a personality / emotion correlation matrix is deﬁned based on the variables Extraversion
and Neuroticism and the emotions Anger and Sadness (as proposed in [74]). Table 1 shows the correlation matrix. The
values of this correlation matrix are based on the results obtained from the experiments presented in [22]. The deﬁnition
of the ω matrix using the proposed syntax is:

w_matrix__: [ extraversion: [ Anger: 0.5,

Sadness: 0.6 ],

neuroticism: [ Anger: 0.8,

Sadness: 0.7 ] ]

This correlation matrix is deﬁned in the conﬁguration ﬁle (i.e., MAS project ﬁle) of the multiagent system and is
common to all agents deﬁned in that environment. Note that, in the default design of GenIA3, the OCEAN personality
model is used, but the architecture also allows the use of other personality models with numeric or fuzzy variables as
presented in [71]. Through our extension of AgentSpeak, the programmer can clearly deﬁne both the personality of the
agent and the knowledge that the agent has about other agents. On the one hand, instead of establishing one threshold
for each emotion, as seen in previous approaches, our model allows the relationship between diﬀerent personality traits
and emotions to be deﬁned using a correlation matrix ω. Therefore, just by varying the personality traits we can deﬁne
agents with diﬀerent aﬀective behaviors. On the other hand, in our proposal, each agent could have its own aﬀective link
matrix, thus allowing the implementation of asymmetric relationships between agents. This diﬀerence in the aﬀective
links between agents represents what happens in human societies in real life. In addition, the aﬀective link between two
agents can dynamically vary according to the interaction value and the emotion generated when the agents interact with
each other. This allows the simulation of aﬀective behavior in long-term interactions between agents.

4.5 A new rational cycle for an empathic BDI agent
We have redesigned the GenIA3 architecture by adding new processes to enable the development of empathic agents.
Figure 5 shows the new conﬁguration of e-GenIA3. We have introduced ﬁve new steps to the aﬀective cycle and we have
proposed a new formalization of the transitions between these steps using the operational semantics described in [52].
This operational semantics consists of a set of rules that deﬁne the transitions between diﬀerent conﬁgurations of an
AgentSpeak agent.

To make readability more convenient, we have adopted the syntax proposed in [75]. Following this syntax, if ag is
the set of attributes that deﬁne an agent, we will refer to the personality component P of ag as agP . We will also refer
to the empathic agent whose aﬀective cycle we are describing as empathic agent. In addition, we will use emph ag id
as the empathic agent identiﬁer.

10

ApprAffAdSelcsAsDecayCopeRelPlExecIntClrIntSelApplSelIntAddIMApplPlSelEvProcMsgAffModBEvalExpEventEvClassEmphApprEmphRegEmRegEmSelRational processesAffective processes4.5.1 Event classiﬁcation

The event classiﬁcation (EvClass) step evaluates the triggering event te component of the current event Tε to determine
whether the event is aﬀectively relevant by a Boolean function of degree n:

where X = {True, False} is a Boolean domain. This function is deﬁned by default as:

affRelEv(te) := X n → X

affRelEv(te) :=




True,



False,

if ∃ ai ∈ teannots : functori =
‘affective relevant’
otherwise

(11)

(12)

where te is the triggering event, teannots is the set of annotations of te, ai is the ith annotation of the set of annotations

teannots, and functori represents the functor of the annotation ai.

Furthermore, this step also performs the dissociation between events that should be evaluated in the aﬀective cycle
and those that should be evaluated in the empathic cycle allowing the distinction between the self from the target. As
discussed in Section 2, this distinction between self and target is essential in the development of empathy since it allows
an agent to diﬀerentiate its own emotions from emotions produced by the perception of others. For an event, we have
designed four transition rules in this step. The ﬁrst rule (EvClass1) is applied to events that are not aﬀectively relevant
and either have nothing to do with the empathic agent (e.g., the target are other agents) or events whose target is the
empathic agent but without a subject agent (e.g., environmental events):

¬affRelEv(te) ∧ (tg (cid:54)= emph ag id ∨ (tg = emph ag id ∧ sbj ∈ {null, self}))
(cid:104)ag, C, M, T, s, Mem, Ta, O, EvClass(cid:105) → (cid:104)ag, C, M, T, s, Mem, Ta, O, EvClass(cid:105)

(EvClass1)

where: Tε = (cid:104)te, i(cid:105) , Tε is the ε component of the tuple T

following the syntax presented in [75] (see Figure 2).

tg = getTarget(te)

sbj = getSubject(te)

If this rule is evaluated as true, the empathic agent will remain in the state EvClass waiting for a new event. For
example, let us assume that Lily is the empathic agent. At a certain point, in time Lily perceives the event time(cloudy).
The function affRelEv evaluates the event obtaining the value false as a result because this event is not relevant for the
aﬀective cycle. The function getTarget also evaluates the event and returns the value null since there is no annotation
indicating a target agent at the event. Therefore, the event does not have any aﬀective impact on Lily, and the aﬀective
cycle is not started. Lily will remain in the event classiﬁcation step waiting for a new event.

The second rule (EvClass2) deals with events that are not aﬀectively relevant but that have some level of social

interaction between the empathic agent and the subject agent.

¬affRelEv(te) ∧ tg = emph ag id ∧ sbj /∈ {null, self}
(cid:104)ag, C, M, T, s, Mem, Ta, O, EvClass(cid:105) → (cid:104)ag, C, M, T, s, Mem, Ta, O(cid:48), EvClass(cid:105)

(EvClass2)

where: Tε = (cid:104)te, i(cid:105)

tg = getTarget(te)

sbj = getSubject(te)

iv = getIV(te)
O(cid:48) = (cid:8)..., (cid:10)id, al(cid:48), (cid:126)σ(cid:11) , ...(cid:9) , where id = sbj
al(cid:48) = updateAl(al, iv), where (cid:104)id, al, (cid:126)σ(cid:105) ∈ O and
id = sbj

When this rule is evaluated as true, the aﬀective link that the empathic agent has with the subject agent is updated

by the function updateAl.

Continuing with the example, suppose that Lily (the empathic agent) has an aﬀective link of 0.5 with Marshall. At

a certain point in time, Marshall says hello to Lily by the event:

hello[subject(Marshall),target(Lily),

interaction value(0.2)]

(Example 1)

In this event, Marshall is the subject agent. As a result of this interaction, Lily will increase her aﬀective link with
Marshall by using the interaction value 0.2. As in the previous rule, Lily will remain in the event classiﬁcation step
waiting for a new event.

11

The last two rules refer to events that are aﬀectively relevant and, therefore, will trigger the aﬀective cycle. It is in
these rules where the distinction between self and target occurs. This distinction is crucial because it allows an agent to
diﬀerentiate its own emotions from emotions produced by the perception of others. The EvClass3 rule is evaluated as
true when aﬀective events are directed towards other agents:

affRelEv(te) ∧ tg /∈ {emph ag id , null}
(cid:104)ag, C, M, T, s, Mem, Ta, O, EvClass(cid:105) → (cid:104)ag, C, M, T, s, Mem, Ta, O(cid:48), EmphAppr(cid:105)

(EvClass3)

where: Tε = (cid:104)te, i(cid:105)

tg = getTarget(te)

iv = getIV(te)
O(cid:48) = (cid:8)..., (cid:10)id, al(cid:48), (cid:126)σ(cid:11) , ...(cid:9) , where id = tg
al(cid:48) = updateAl(al, iv), where (cid:104)id, al, (cid:126)σ(cid:105) ∈ O and
id = tg

If an event is aﬀectively relevant and the target agent is another agent, the event is considered an empathic event.
Therefore, the aﬀective cycle is started, and the empathic appraisal step processes the empathic event. For example,
when Lily receives the event:

slap[subject(Marshall),target(Barney),

affective relevant,interaction value(-0.5)]

(Example 2)

The function affRelEv evaluates the event as aﬀectively relevant and identiﬁes that the target of the triggering event
is Barney. Therefore, the aﬀective cycle of agent Lily moves to the appraisal (Appr) step in which the event is evaluated
by means of an empathic appraisal. In this appraisal step, Lily infers how Barney feels, and she generates an empathic
emotion directed towards Barney.

Finally, the rule EvClass4 deals with aﬀectively relevant events that are received by the empathic agent:

affRelEv(te) ∧ tg = emph ag id
(cid:104)ag, C, M, T, s, Mem, Ta, O, EvClass(cid:105) → (cid:104)ag, C, M, T, s, Mem, Ta, O, Appr(cid:105)

(EvClass4)

where: Tε = (cid:104)te, i(cid:105)

tg = getTarget(te)

When this rule is evaluated as true, the empathic agent performs a self-appraisal process of the event obtaining an

emotion as a result. Following the previous example, when Lily receives the event:

slap[subject(Marshall),target(Lily),

affective relevant,interaction value(-0.5)]

(Example 3)

this event is directed toward Lily (i.e., Lily is the target agent). Therefore, Lily will evaluate this event through a

self-appraisal process in the appraisal (Appr) step.

4.5.2 Appraisal

In the appraisal step, the values of the appraisal variables Av for the event ε are determined by the self-appraisal process
deﬁned by the function:

Appraisal(ε, bs, cc, Av, Mem, Ap) := {[(xid, xv)] : xv =

DeriveAV(xid, ε, bs, cc, Mem, Ap), ∀(xid, xv) ∈ Av}

(13)

where bs are the agent’s beliefs, cc are the agent’s concerns, Av is a list of tuples (identiﬁer, value) containing the
set of appraisal variables, Mem is the aﬀective memory, Ap are the applicable plans, xid is the identiﬁer of an appraisal
variable, xv is the value of the appraisal variable, and DeriveAV is a function that returns the value of each appraisal
variable deﬁned as:

DeriveAV(id, ε, bs, cc, Mem, Ap) :=

[id, ε, bs, cc, Mem, Ap] (cid:55)→ λ

(14)

where λ represents the value of the appraisal variable. Note that this function calculates a diﬀerent value for each

appraisal variable.

12

To determine the derived emotions from the appraisal variables, we have deﬁned the DeriveEm function as:

where Av represents the set of appraisal variables and Ae represents the set of appraised emotions deﬁned as a set

of vectors. Therefore, this function establishes a mapping between the set of appraisal variables and emotions.

The transition rule for the appraisal step of the aﬀective cycle has been deﬁned as:

DeriveEm(Av) := Av (cid:55)→ Ae

(15)

True
(cid:104)ag, C, M, T, s, Mem, Ta, O, Appr(cid:105) → (cid:104)ag, C, M, T, s, Mem, Ta(cid:48), O, EmReg(cid:105)

(Appr1)

where: Ta(cid:48)
Ta(cid:48)

Av = Appraisal(Tε, agbs, agcc, TaAv, Mem, TAp)
Ae = DeriveEm(Ta(cid:48)

Av)

For instance, continuing with the event of Example 3, Lily appraises the slap event eliciting the emotion sadness

with high intensity.

Once the appraisal ﬁnishes, the next step in the aﬀective cycle is the emotion regulation (EmReg) step.

4.5.3 Emotion regulation

The emotion regulation step adapts the appraised emotion based on diﬀerent factors such as the mood or personality
of the agent. This regulation process aﬀects the probability and intensity of emotions. For example, if the aﬀective
link between two agents is high, the probability and intensity of emotions should be increased. The process of emotion
regulation is established by the EmphRegulation function deﬁned as:

EmRegulation(tr, ω, (cid:126)σ, Ae) :=

(cid:8)(cid:2)(cid:126)e(cid:48)(cid:3) : (cid:126)e(cid:48) = ϕ1 (tr, ω, (cid:126)σ, (cid:126)e) ∀(cid:126)e ∈ Ae(cid:9)

(16)

where tr are the personality traits of the agent, ω is the personality/emotion correlation matrix, (cid:126)σ is the agent’s
current mood, Ae is the set of appraised emotions and ϕ1 is a function that adapts the emotion’s vector (cid:126)e to the regulation
process.

Thanks to this regulation of the emotion process, each agent can face an event in a diﬀerent way depending on his/her

personality or mood.

The transition rule for this step is deﬁned as follows:

true
(cid:104)ag, C, M, T, s, Mem, Ta, O, EmReg(cid:105) → (cid:104)ag, C, M, T, s, Mem, Ta(cid:48), O, EmSel(cid:105)

(EmSel1)

where: Ta(cid:48)

Ae = EmRegulation(agP , Ta(cid:126)σ, TaAe)

Following the previous example in which Lily appraised the sadness emotion with high intensity, if Lily’s personality
has a high component of extraversion, she is more prone to positive emotions. Therefore, the emotion regulation process
will reduce the intensity of the emotion, producing the emotion sadness with medium intensity.

Once the regulation of the possible emotions has been performed, the next step of the non-empathic aﬀective cycle

will be the emotion selection (EmSel) step.

4.5.4 Empathic appraisal

When the target of an aﬀective event is another agent, the event is appraised by the empathic appraisal process. This
empathic appraisal process is a self-projection appraisal that allows an empathic agent to understand another agent’s
emotion or situation. Similarly to the previously deﬁned self-appraisal step, the empathic appraisal is deﬁned by the
formula:

EmphAppraisal(ε, bs, cc, Av, Mem, Ap, O) := {[(xid, xv)] :
xv = DeriveAV(xid, ε, bs, cc, Mem, Ap, O), ∀(xid, xv) ∈ Av}

(17)

where bs is the set of beliefs, cc is the set of concerns, Mem is the aﬀective memory, Ap are the applicable plans, xid
is the identiﬁer of an appraisal variable, xv is the value of an appraisal variable, Av is a list of tuples (identiﬁer, value)
one for each appraisal variable, O is the target information, and DeriveAV follows the deﬁnition of Equation 14. that
returns the value of each appraisal variable. Note that the beliefs and concerns may be either those of the empathic agent
or those of the target agent. In addition, both the number and type of appraisal variables and the function DeriveAV
of the empathic process can be diﬀerent from the self-appraisal process. Empathic emotions can also be distinct from
self-appraisal and are elicited through function DeriveEmphEm:

DeriveEmphEm(Av) := Av (cid:55)→ Ee

(18)

13

where Av represents the set of appraisal variables and Ee represents the set of empathic emotions deﬁned as a set of

vectors.

The transition rule for the empathic appraisal step of the aﬀective cycle has been deﬁned as:

T rue
(cid:104)ag, C, M, T, s, Mem, Ta, O, EmphAppr(cid:105) → (cid:104)ag, C, M, T, s, Mem, Ta(cid:48), O, EmphReg(cid:105)

(EmphAppr1)

where: Ta(cid:48)
Ta(cid:48)

Av = EmphAppraisal(Tε, agbs, agcc, TaAv, Mem, TAp)
Ee = DeriveEmphEm(TaAv)

For example, when Lily perceives the event described in Example 2, Lily evaluates the event slap through a self-

projection appraisal and elicits the emotion sorry for with high intensity towards Barney.

Once the empathic appraisal generates the set of empathic emotions, the empathic regulation (EmphReg) process will

adapt the empathic emotions using the mood and personality of the empathic agent.

4.5.5 Empathic regulation

The empathy regulation step adapts the empathic emotion according to diﬀerent factors such as the mood Ta(cid:126)σ or
personality agP of the agent and the aﬀective link Oal between the empathic agent and the target agent. This regulation
process allows the empathic response to be personalized to diﬀerent target agents. For example, if the aﬀective link
between the empathic agent and the target agent is high, the probability and intensity of the empathic emotions will be
higher. The process of empathic regulation is established by the EmphRegulation function deﬁned as:

EmphRegulation (tr, ω, O, (cid:126)σ, Ee) :=
(cid:8)(cid:2)(cid:126)e(cid:48)(cid:3) : (cid:126)e(cid:48) = ϕ2 (tr, ω, O, (cid:126)σ, (cid:126)e) ∀(cid:126)e ∈ Ee(cid:9)

(19)

where tr are the personality traits of the agent, ω is the personality/emotion correlation matrix, O represents the
knowledge that the empathic agent knows about the target agent, (cid:126)σ is the agent’s current mood, and ϕ2 is a function
that modiﬁes the emotion vector.

The transition rule for the empathic regulation is deﬁned as:

true
(cid:104)ag, C, M, T, s, Mem, Ta, O, EmphReg(cid:105) → (cid:104)ag, C, M, T, s, Mem, Ta(cid:48), O(cid:48), EmSel(cid:105)

(EmphReg1)

where: Ta(cid:48)

Ee = EmphRegulation(Tε, agPtr , O, Ta(cid:126)σ, TaEe)

Tε = (cid:104)te, i(cid:105)
iv = getIV(te)
O(cid:48) = (cid:8)..., (cid:10)id, al(cid:48), (cid:126)σ(cid:11) , ...(cid:9) , where id = tg
al(cid:48) = updateAl(al, iv), where (cid:104)id, al, (cid:126)σ(cid:105) ∈ O and
tg = getTarget(te)

Following the previous example, let us suppose that Lily has a low positive aﬀective link with Barney (e.g., 0.3). Let
us recall that Lily’s personality makes her prone to positive emotions. In addition, when Lily perceives the event, she
has a positive mood (e.g., happiness). The empathic emotion regulation process will reduce the intensity of the empathic
emotion and the result will be the emotion sorry for with weak intensity.

Once the regulation of the possible empathic emotions has been performed, the following step is the emotion selection

(EmSel) step.

4.5.6 Emotion selection

In the emotion selection step of the aﬀective cycle, the ﬁnal emotion F e that the agent is going to simulate is selected
by the function SelEmotion(ε, Ae, Ee, P ). This function has as parameters an event ε, the list of appraised emotions
Ae, the list of empathic emotions Ee, and the agent personality P . The user can adapt this SelEmotion function to
diﬀerent environments and situations considering the agent personality, intensity or probability of the emotions, and
other aﬀective characteristics.

The transition rule for the emotion selection step is deﬁned as follows:

T rue
(cid:104)ag, C, M, T, s, M em, T a, O, EmSel(cid:105) → (cid:104)ag, C, M, T, s, Mem(cid:48), T a(cid:48), O, AffAd(cid:105)

(EmSel1)

where: Ta(cid:48)

Fe = SelEmotion(TaAe, TaEe)

ae = (cid:10)Tε, Ta(cid:48)
Mem(cid:48) = Mem ∪ ae

Fe

(cid:11)

14

This step calculates the ﬁnal emotion Ta(cid:48)

Fe. Therefore, the aﬀective memory Mem can be updated to store the event
Tε with the emotion Ta(cid:48)
Fe resulting from this event appraisal. This mechanism allows the agent to maintain a memory
of past events and the emotion that each event produced, supporting the maintaining of long-term interactions between
agents.

For instance, when Lily evaluates the event of Example 3, the self-appraisal process produces two emotions as a
result: sadness with high intensity, and fear with medium intensity. Let us suppose that after the emotion regulation
process the intensity of those emotions is not modiﬁed. If the user has deﬁned the SelEmotion function to select the
emotion with the highest intensity, the empathic agent will elicit the sadness emotion.
The next process of the empathic aﬀective cycle is the aﬀect adaptation (AffAd).

4.5.7 Aﬀect adaptation

In the AffectAdaptation step, the mood of the agent is updated by the function AffectAdaptation, which is deﬁned
as follows:

AffectAdaptation (tr, ω, (cid:126)σ, Fe) := (cid:8)(cid:126)σ(cid:48) : (cid:126)σ(cid:48) = ϕ3 (tr, ω, Fe, (cid:126)σ)(cid:9)

(20)

where Fe is the ﬁnal emotion selected by the emotion selection process. ϕ3 is a function that, similarly to ϕ1 and

ϕ2 in Equations 16 and 19, modiﬁes the mood vector (cid:126)σ to adjust it to the emotion produced by the event.

The transition rule for this step is deﬁned as:

T rue
(cid:104)ag, C, M, T, s, Mem, Ta, O, AffAd(cid:105) → (cid:104)ag, C, M, T, s, Mem, Ta(cid:48), P, O, SelCs(cid:105)

(AﬀAd1)

where: Ta(cid:48)

(cid:126)σ = affectAdaptation(agP , Ta(cid:126)σ, TaFe)

Since emotions and mood are expressed as vectors in the same representation space, the selected emotion will “attract”
the mood to a greater or lesser extent depending on the agent’s personality. As a result, the mood of the agent will be
modiﬁed. Continuing with the previous example in which the selected emotion was sadness with high intensity, let us
assume that Lily’s mood is happiness with a low intensity. The emotion will attract the mood, and, as a result, the new
mood will be sadness with a low intensity.

Once the mood of the agent is updated, the next state of the aﬀective cycle will be the select coping strategy process.
In this process, a coping strategy from the current set of applicable coping strategies will be used to create a plan that
ﬁnally allows the agent to express its empathy: in its voice tone, in its speech, in its face, . . .

5 Default design

To facilitate the use of e-GenIA3, we propose a default design in which there is a default deﬁnition of the previous
presented functions, based on the psychological theories introduced in Sections 3 and 4. In this default design, emotions
and mood are represented as vectors (cid:126)σ in a representation space based on the PAD model [44]. The personality is deﬁned
by the OCEAN model. The appraisal model is based on the OCC model [48] and follows the deﬁnition presented in [2].
The appraisal function evaluates the event, when this event implies the addition or deletion of a belief. Then the values
of the appraisal variables are estimated considering both the information contained in the event itself and the agent’s
beliefs, desires, intentions, expectations, and concerns. This default design uses the appraisal variables: desirability,
which considers the value of the agent’s concerns about the event; likelihood, which considers the probability of the
event; and causal attribution, which is the agent that produces the event (i.e. the subject agent) but it can also be self, if
it is an internal event or null if it comes from the environment (see [2] and [74] for more details on how this process work).
The function DeriveAV in Equation 14 estimates the value of the appraisal variables as follow. For the desirability, this
function evaluates if the event is an addition or deletion event, then compares the functor of the event with the agent
concerns and estimates the desirability value. For example, if the agent is concerned about passing an exam, the function
for estimating the value of the concern may be V = Score/MaxScore, where Score is the score of the agent’s exam and
MaxScore is the maximum possible score. To obtain the value of the appraisal variable likelihood, a special annotation
(n) is used for events. Finally, to obtain the value for the causal attribution, the Equation 8, referring the function
prob
getSubject, is used. In our default design, EmphAppraisal and DeriveEmphEm (Equation 18) functions follow the same
philosophy as Appraisal and DeriveEm functions (Equations 13 and 15) presented above. Note that, in this function,
the appraised beliefs and concerns to be those of the agent itself or of the target agent allowing the simulation of diﬀerent
levels of empathy and Theory of Mind. In addition, the number and type of emotions that can be triggered by empathic
appraisal, may diﬀer from the emotions of aﬀective appraisal. For example, by triggering emotions such as ”happy for”
or ”sorry for” proposed in the OCC model [48]. These two emotions are used in the default design.

In our default design, the DeriveEm function, Equation 15, can elicit ﬁve emotions (i.e., hope, joy, fear, sadness,
and guilt) using the OCC theory as proposed in [39]. These emotions can be subsequently represented in a PAD space,
considering the mapping proposed in [25] (or to a Pleasure-Arosual (PA) space, considering the model proposed in [73]).
For more details see [2].

Once the emotion is obtained and represented as a vector (cid:126)σ, the emotion regulation process adapts this vector (cid:126)σ

through the function ϕ1 (Equation 16). This function is deﬁned as:

15

where ψ((cid:126)v) is a weighting factor resulting from the formula:

ϕ1 (tr, ω, (cid:126)σ, (cid:126)e) := ψ((cid:126)σ) · (cid:126)σ + (cid:126)e

ψ((cid:126)v) :=

(cid:80)

i∈tr βi · ωt((cid:126)v),i
(cid:80)
j∈tr ωt((cid:126)v),j

(21)

(22)

where βi is the value of the ith personality trait, t((cid:126)v) is a function that returns the most probable aﬀective label for a
vector (cid:126)v (the description of function t((cid:126)v) can be found at [74] and [73]), and ωt((cid:126)σ),i represents the value of the correlation
matrix ω for the aﬀective label t((cid:126)σ) and the ith personality trait.

The empathic regulation function ϕ2, proposed in Ecuation 19, is deﬁned in the default design as:

ϕ2 (tr, ω, O, (cid:126)σ, (cid:126)e) := (ψ((cid:126)e) · (cid:126)e + ψ((cid:126)σ) · (cid:126)σ) · al

(23)

where al represents the aﬀective link.
The emotion selection (SelEmotion) function is based on the intensity and probability of emotions according to the

following deﬁnition:

SelEmotion(Ae, Ee) := arg max
i∈Ae∪Ee

arg max
c

(cid:98)P (C = c | αi) · δi

(cid:18)

(cid:19)

(24)

where αi and δi represent the angle and the intensity of the ith emotion vector (as deﬁned in [73]), respectively.
For the aﬀect adaptation, Equation 20, the deﬁnition in the default design is:

Finally, the function for updating the aﬀective link (updateAl) is deﬁned as:

ϕ3 (tr, ω, Fe, (cid:126)σ) := {(cid:126)σ · ψ((cid:126)σ) + (cid:126)e · ψ((cid:126)e)}

updateAl(al, iv) := al + ϕ · iv

(25)

(26)

where iv is the interaction value, ϕ is a weighting factor, and al and represent the current value of the aﬀective link.

6 Conclusions

Empathy is a key element in social interactions aﬀecting human aﬀective states and behaviours and provides a basis for
long-term relationships. Several proposals have been made from the area of aﬀective computing to simulate aﬀective
and empathic abilities. These proposals are generally based on theoretical models from psychology, sociology, and
neuroscience using agent-oriented approaches. However, these proposals are designed ad hoc, generating agent programs
that are highly dependent on the domain and the programmer, making these proposals very diﬃcult to understand,
share, and re-use. In this paper, we have presented e-GenIA3 a generic architecture for the development of empathic
agents. We have proposed a formalization of the syntax, semantics, and the reasoning cycle of AgentSpeak to support the
development of agents with empathic abilities. e-GenIA3 formalizes the three main processes identiﬁed in the literature:
perception, empathic appraisal, and empathic regulation. After perceiving an empathic event, the empathic appraisal
process elicits a set of empathic emotions. These empathic emotions are then adapted by the empathic regulation process
according to the knowledge that the agent has about the target agent. We have modiﬁed the aﬀective cycle that was
incorporated to AgentSpeak by GenIA3adding new processes and functionalities to allow the elicitation of empathic
emotions. We have formalized our extension using the same operational semantics formalism used by AgentSpeak and
GenIA3. This operational semantics deﬁnes the structure and the conﬁguration of the agent allowing the use of diﬀerent
psychological theories. The formalization of all of the transitions guarantees the validity of our proposal.

The new aﬀective cycle is divided into two diﬀerent appraisal processes: one for eliciting empathic emotions induced
by the perception of an emotion or situation in a target agent; and another for eliciting emotions based on self-directed
or environmental events. This division of the aﬀective process allows the agent to be able to maintain a sense of self that
is distinct from the target agent.

The use of the aﬀective link representing the aﬀective proximity or social tie between two agents allows the per-
sonalization of the empathic response based on the target agent. In addition, a correlation matrix represents how each
personality trait of the agent inﬂuences the emotion that will be elicited. Finally, in our proposal, agents maintain a
memory of past events and the emotion that the past events produced in the agent. This aﬀective memory, combined
with the possibility of establishing and modifying the aﬀective links with other agents, allows the simulation of person-
alized long-term interactions, which are crucial in aﬀective interactions in human beings. All of these characteristics of
our empathic agent model will produce software agents that are more realistic when modelling human organizations.

We are currently considering increasing the agent’s knowledge of other agents by adding new structures to store the
beliefs, goals, and concerns of other agents using state-of-the-art approaches of Theory of Mind. Moreover, the aﬀective
link can be complemented maintaining a level of trust in other agents. This will improve the perspective-taking process
so that the agent can evaluate perceived situations using more knowledge about the target agent.

16

Acknowledgments

This work is partially supported by the Spanish Government project PID2020-113416RB-I00 and TAILOR, a project
funded by EU Horizon 2020, under GA No 952215.

References

[1] Carole Adam, Andreas Herzig, and Dominique Longin. A logical formalization of the occ theory of emotions.

Synthese, 168(2):201–248, 2009.

[2] Bexy Alfonso, Emilio Vivancos, and Vicente Botti. Toward formal modeling of aﬀective agents in a BDI architecture.

ACM Transactions on Internet Technology (TOIT), 17(1), 2017.

[3] Paul J Argott, Dawn Buﬃngton Townsend, and Claire L Poulson. Acquisition and generalization of complex

empathetic responses among children with autism. Behavior analysis in practice, 10(2):107–117, 2017.

[4] Giuseppe Attanasi, Astrid Hopfensitz, Emiliano Lorini, and Fr´ed´eric Moisan. Social connectedness improves co-

ordination on individually costly, eﬃcient outcomes. European Economic Review, 90:86–106, 2016.

[5] John W Backus, Friedrich L Bauer, Julien Green, Charles Katz, John McCarthy, Peter Naur, Alan J Perlis, Heinz
Rutishauser, Klaus Samelson, Bernard Vauquois, et al. Revised report on the algorithmic language algol 60. The
Computer Journal, 5(4):349–367, 1963.

[6] Christopher Beedie, Peter Terry, and Andrew Lane. Distinctions between emotion and mood. Cognition & Emotion,

19(6):847–878, 2005.

[7] Rafael H Bordini and Jomi F H¨ubner. A java-based interpreter for an extended version of agentspeak. University

of Durham, Universidade Regional de Blumenau, 256, 2007.

[8] Rafael H Bordini, Jomi Fred H¨ubner, and Michael Wooldridge. Programming multi-agent systems in AgentSpeak

using Jason, volume 8. John Wiley & Sons, 2007.

[9] Hana Boukricha, Ipke Wachsmuth, Maria Nella Carminati, and Pia Knoeferle. A computational model of empathy:
Empirical evaluation. In 2013 Humaine Association Conference on Aﬀective Computing and Intelligent Interaction,
pages 1–6. IEEE, 2013.

[10] Malissa A Clark, Melissa M Robertson, and Stephen Young. “I feel your pain”: A critical review of organizational

research on empathy. Journal of Organizational Behavior, 40(2):166–192, 2019.

[11] Benjamin MP Cuﬀ, Sarah J Brown, Laura Taylor, and Douglas J Howat. Empathy: A review of the concept.

Emotion Review, 8(2):144–153, 2016.

[12] Mehdi Dastani and John-Jules Ch. Meyer. Agents with emotions. International Journal of Intelligent Systems,

25(7):636–654, 2010.

[13] Mark H Davis. Empathy: A social psychological approach. Routledge, 2018.

[14] Frederique De Vignemont and Tania Singer. The empathic brain: how, when and why? Trends in cognitive sciences,

10(10):435–441, 2006.

[15] Frans BM De Waal. The ‘russian doll’model of empathy and imitation. On being moved: From mirror neurons to

empathy, pages 35–48, 2007.

[16] Jean Decety and Philip L Jackson. The functional architecture of human empathy. Behavioral and cognitive

neuroscience reviews, 3(2):71–100, 2004.

[17] Douglas Derryberry and Marjorie A Reed. Temperament and attention: Orienting toward and away from positive

and negative signals. Journal of Personality and Social Psychology, 66(6):1128–1139, 1994.

[18] Panteleimon Ekkekakis. Aﬀect, mood, and emotion. Measurement in sport and exercise psychology, 321, 2012.

[19] Paul Ekman. An argument for basic emotions. Cognition & Emotion, 6(3-4):169–200, 1992.

[20] PF Ferrari, M Gerbella, G Coud´e, and S Rozzi. Two diﬀerent mirror neuron networks: the sensorimotor (hand)

and limbic (face) pathways. Neuroscience, 358:300–315, 2017.

[21] Nico H Frijda, Peter Kuipers, and Elisabeth Ter Schure. Relations among emotion, appraisal, and emotional action

readiness. Journal of Personality and Social Psychology, 57(2):212, 1989.

[22] Desire Furnes, Hege Berg, Rachel M Mitchell, and Silke Paulmann. Exploring the eﬀects of personality traits on

the perception of emotions from prosody. Frontiers in psychology, 10:184, 2019.

[23] Helen L Gallagher and Christopher D Frith. Functional imaging of ‘theory of mind’. Trends in cognitive sciences,

7(2):77–83, 2003.

[24] Joanna Ganczarek, Thomas H¨unefeldt, and Marta Olivetti Belardinelli. From “Einf¨uhlung” to empathy: exploring

the relationship between aesthetic and interpersonal experience. Springer, 2018.

[25] Patrick Gebhard. Alma: a layered model of aﬀect. In Proceedings of the fourth international joint conference on
Autonomous agents and multiagent systems, pages 29–36. Association for Computing Machinery, New York, NY,
United States, 2005.

17

[26] Ezequiel Gleichgerrcht and Jean Decety. Empathy in clinical practice: how individual dispositions, gender, and
experience moderate empathic concern, burnout, and emotional distress in physicians. PloS one, 8(4):e61526, 2013.

[27] Joao Gluz and Patricia A Jaques. A probabilistic formalization of the appraisal for the occ event-based emotions.

Journal of Artiﬁcial Intelligence Research, 58:627–664, 2017.

[28] Alvin Goldman. Two routes to empathy. Empathy: Philosophical and psychological perspectives, pages 31–44, 2011.

[29] Grit Hein and Tania Singer. I feel how you feel but not always: the empathic brain and its modulation. Current

opinion in neurobiology, 18(2):153–158, 2008.

[30] Cecilia Heyes. Empathy is not in our genes. Neuroscience & Biobehavioral Reviews, 95:499–507, 2018.

[31] Peter Hilpert, Timothy R Brick, Christoph Fl¨uckiger, Matthew J Vowels, Eva Ceulemans, Peter Kuppens, and
Laura Sels. What can be learned from couple research: Examining emotional co-regulation processes in face-to-face
interactions. Journal of Counseling Psychology, 67(4):475, 2020.

[32] Martin L Hoﬀman. Interaction of aﬀect and cognition in empathy. Emotions, cognition, and behavior, pages 103–131,

1984.

[33] Martin L Hoﬀman. Empathy and prosocial behavior. Handbook of emotions, 3:440–455, 2008.

[34] Timotheus Kampik, Juan Carlos Nieves, and Helena Lindgren. Empathic autonomous agents.

In International

Workshop on Engineering Multi-Agent Systems, pages 181–201. Springer, 2018.

[35] Claus Lamm, Markus R¨utgen, and Isabella C Wagner. Imaging empathy and prosocial emotions. Neuroscience

letters, 693:49–53, 2019.

[36] Richard S Lazarus and Richard S Lazarus. Emotion and adaptation. Oxford University Press, 1991.

[37] Iolanda Leite, Ginevra Castellano, Andr´e Pereira, Carlos Martinho, and Ana Paiva. Empathic robots for long-term

interaction. International Journal of Social Robotics, 6(3):329–341, 2014.

[38] Iolanda Leite, Carlos Martinho, and Ana Paiva. Social robots for long-term interaction: a survey. International

Journal of Social Robotics, 5(2):291–308, 2013.

[39] Stacy C Marsella and Jonathan Gratch. Ema: A process model of appraisal dynamics. Cognitive Systems Research,

10(1):70–90, 2009.

[40] Abigail A Marsh. The neuroscience of empathy. Current opinion in behavioral sciences, 19:110–115, 2018.

[41] Samuel Mascarenhas, Manuel Guimar˜aes, Rui Prada, Pedro A Santos, Jo˜ao Dias, and Ana Paiva. Fatima toolkit-
toward an accessible tool for the development of socio-emotional agents. ACM Transactions on Interactive Intelligent
Systems (TiiS), 2021.

[42] Robert R McCrae and Oliver P John. An introduction to the ﬁve-factor model and its applications. Journal of

Personality, 60(2):175–215, 1992.

[43] Albert Mehrabian. Analysis of the big-ﬁve personality factors in terms of the pad temperament model. Australian

journal of Psychology, 48(2):86–92, 1996.

[44] Albert Mehrabian. Pleasure-arousal-dominance: A general framework for describing and measuring individual

diﬀerences in temperament. Current Psychology, 14(4):261–292, 1996.

[45] John-Jules Ch Meyer. Reasoning about emotional agents. International journal of intelligent systems, 21(6):601–619,

2006.

[46] Mohammad Obaid, Ruth Aylett, Wolmet Barendregt, Christina Basedow, Lee J Corrigan, Lynne Hall, Aidan Jones,
Arvid Kappas, Dennis K¨uster, Ana Paiva, et al. Endowing a robotic tutor with empathic qualities: Design and
pilot evaluation. International Journal of Humanoid Robotics, 15(06):1850025, 2018.

[47] Magalie Ochs, David Sadek, and Catherine Pelachaud. A formal model of emotions for an empathic rational dialog

agent. Autonomous Agents and Multi-Agent Systems, 24(3):410–440, 2012.

[48] Andrew Ortony, Gerald L Clore, and Allan Collins. The cognitive structure of emotions. Cambridge University

Press, 1990.

[49] Mark D Packard and Thomas A Burnham. Do we understand each other? toward a simulated empathy theory for

entrepreneurship. Journal of Business Venturing, 36(1):106076, 2021.

[50] Ana Paiva, Iolanda Leite, Hana Boukricha, and Ipke Wachsmuth. Empathy in virtual agents and robots: a survey.

ACM Transactions on Interactive Intelligent Systems (TiiS), 7(3):1–40, 2017.

[51] Rosalind Wright Picard. Aﬀective Computing. The MIT Press, 1997.

[52] Gordon D Plotkin. A structural approach to operational semantics. Technical Report DAIMI FN-19. Computer

Science Department, Aarhus University. Reprinted in J. Log. Algebr. Program, 1981.

[53] Jonathan Posner, James A Russell, and Bradley S Peterson. The circumplex model of aﬀect: An integrative
approach to aﬀective neuroscience, cognitive development, and psychopathology. Development and Psychopathology,
17(3):715–734, 2005.

[54] Stephanie D Preston. A perception-action model for empathy. Empathy in mental illness, 1:428–447, 2007.

[55] Stephanie D Preston and Frans BM De Waal. Empathy: Its ultimate and proximate bases. Behavioral and brain

sciences, 25(1):1–20, 2002.

18

[56] Anand S Rao. Agentspeak (l): Bdi agents speak out in a logical computable language. In European workshop on

modelling autonomous agents in a multi-agent world, pages 42–55. Springer, 1996.

[57] Anand S Rao, Michael P Georgeﬀ, et al. Bdi agents: From theory to practice. In Proceedings of the First International

Conference on Multiagent Systems, volume 95, pages 312–319. AAAI, 1995.

[58] Zeeshan Rasool, Naoki Masuyama, Md Nazrul Islam, and Chu Kiong Loo. Empathic interaction using the com-
putational emotion model. In 2015 IEEE Symposium Series on Computational Intelligence, pages 109–116. IEEE,
2015.

[59] Helen Riess. The science of empathy. Journal of patient experience, 4(2):74–77, 2017.

[60] Giacomo Rizzolatti, Luciano Fadiga, Vittorio Gallese, and Leonardo Fogassi. Premotor cortex and the recognition

of motor actions. Cognitive brain research, 3(2):131–141, 1996.

[61] S´ergio Hortas Rodrigues, Samuel Mascarenhas, Jo˜ao Dias, and Ana Paiva. A process model of empathy for virtual

agents. Interacting with Computers, 27(4):371–391, 2015.

[62] James A Russell. A circumplex model of aﬀect. Journal of Personality and Social Psychology, 39(6):1161, 1980.

[63] James A Russell, Maria Lewicka, and Toomas Niit. A cross-cultural study of a circumplex model of aﬀect. Journal

of Personality and Social Psychology, 57(5):848, 1989.

[64] Cheryl L Rusting and Randy J Larsen. Extraversion, neuroticism, and susceptibility to positive and negative aﬀect:

A test of two theoretical models. Personality and individual diﬀerences, 22(5):607–612, 1997.

[65] Klaus R Scherer. Studying the emotion-antecedent appraisal process: An expert system approach. Cognition &

Emotion, 7(3-4):325–355, 1993.

[66] Klaus R Scherer. Towards a prediction and data driven computational process model of emotion. IEEE Transactions

on Aﬀective Computing, 12(2):279–292, 2019.

[67] Elizabeth Segal. Social empathy. Columbia University Press, 2018.

[68] Geneva Smith and Jacques Carette. What lies beneath-a survey of aﬀective theory use in computational models of

emotion. TechRxiv, Preprint. https://doi.org/10.36227/techrxiv.18779315.v1, 2022.

[69] Bas R Steunebrink, Mehdi Dastani, John-Jules Ch Meyer, et al. A logic of emotions for intelligent agents.

In
Proceedings of the National Conference on Artiﬁcial Intelligence, volume 22, page 142. Menlo Park, CA; Cambridge,
MA; London; AAAI Press; MIT Press; 1999, 2007.

[70] Karsten Stueber. Empathy. International Encyclopedia of Ethics, 2013.

[71] Joaquin Taverner, Bexy Alfonso, Emilio Vivancos, and Vicent J Botti. Modeling personality in the aﬀective agent

architecture GenIA3. In ICAART (1), pages 236–243. Scitepress, 2018.

[72] Joaqu´ın Taverner, Bexy Alfonso, Emilio Vivancos, and Vicente J Botti. Integrating expectations into Jason for

appraisal in emotion modeling. In IJCCI (ECTA), pages 231–238. Scitepress, 2016.

[73] Joaquin Taverner, Emilio Vivancos, and Vicente Botti. A multidimensional culturally adapted representation of
emotions for aﬀective computational simulation and recognition. IEEE Transactions on Aﬀective Computing, 2020.

[74] Joaquin Taverner, Emilio Vivancos, and Vicente Botti. A fuzzy appraisal model for aﬀective agents adapted to

cultural environments using the pleasure and arousal dimensions. Information Sciences, 546:74–86, 2021.

[75] Renata Vieira, ´Alvaro F Moreira, Michael Wooldridge, and Rafael H Bordini. On the formal semantics of speech-
act based communication in an agent-oriented programming language. Journal of Artiﬁcial Intelligence Research,
29:221–267, 2007.

[76] Li Wang, Zhanbiao Shi, and Huanhuan Li. Neuroticism, extraversion, emotion regulation, negative aﬀect and positive
aﬀect: The mediating roles of reappraisal and suppression. Social Behavior and Personality: an international
journal, 37(2):193–194, 2009.

[77] Henry M Wellman. Theory of mind: The state of the art. European Journal of Developmental Psychology, 15(6):728–

755, 2018.

[78] Joshua D Wondra and Phoebe C Ellsworth. An appraisal theory of empathy and other vicarious emotional experi-

ences. Psychological review, 122(3):411, 2015.

[79] ¨Ozge Nilay Yal¸cın and Steve DiPaola. A computational model of empathy for interactive agents. Biologically inspired

cognitive architectures, 26:20–25, 2018.

[80] ¨Ozge Nilay Yal¸cın and Steve DiPaola. Modeling empathy: building a link between aﬀective and cognitive processes.

Artiﬁcial Intelligence Review, pages 1–24, 2019.

19

