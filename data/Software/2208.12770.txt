2
2
0
2

g
u
A
6
2

]
I

N
.
s
c
[

1
v
0
7
7
2
1
.
8
0
2
2
:
v
i
X
r
a

1

A Latency-driven Availability Assessment for
Multi-Tenant Service Chains

Luigi De Simone, Member, IEEE, Mario Di Mauro, Senior Member, IEEE, Roberto Natella,
Fabio Postiglione

Abstract—Nowadays, most telecommunication services adhere to the Service Function Chain (SFC) paradigm, where network
functions are implemented via software. In particular, container virtualization is becoming a popular approach to deploy network
functions and to enable resource slicing among several tenants. The resulting infrastructure is a complex system composed by a huge
amount of containers implementing different SFC functionalities, along with different tenants sharing the same chain. The complexity of
such a scenario lead us to evaluate two critical metrics: the steady-state availability (the probability that a system is functioning in long
runs) and the latency (the time between a service request and the pertinent response). Consequently, we propose a latency-driven
availability assessment for multi-tenant service chains implemented via Containerized Network Functions (CNFs). We adopt a
multi-state system to model single CNFs and the queueing formalism to characterize the service latency. To efﬁciently compute the
availability, we develop a modiﬁed version of the Multidimensional Universal Generating Function (MUGF) technique. Finally, we solve
an optimization problem to minimize the SFC cost under an availability constraint. As a relevant example of SFC, we consider a
containerized version of IP Multimedia Subsystem, whose parameters have been estimated through fault injection techniques and load
tests.

Index Terms—Availability; Reliability; Queueing Model; Container Virtualization; IP Multimedia Subsystem; Redundancy Optimization;
Multi-State Systems; Universal Generating Function; Network Function Virtualization.

✦

1 INTRODUCTION

requirements, both in terms of steady-state availability (the
probability that a system is functioning in long runs, i.e.,
when stationary conditions are reached) and latency (the
time between a service request and the pertinent response).

T ODAY, service providers conceive modern network

From a technological point of view, we are witnessing
the adoption of Containarized Network Functions (CNFs) to
implement VNFs [9], [10]. Differently from traditional virtu-
alization technology, containers are a lightweight solution,
as they do not emulate a full computer machine, and do
not run a dedicated operating system. Moreover, containers
can be quickly deployed and orchestrated using dedicated
management platforms (e.g., Docker [11]). Remarkably,
lightweight containers allow designers to achieve a great
ﬂexibility, in terms of a ﬁne-grained allocation of resources
among various tenants. On the other hand, the complexity
of managing a huge number of container replicas could
negatively affect the computational cost of many availability
techniques. In addition, exploiting containerized solutions
in real-time environments requires a particular attention to
achieve the low latency objectives. It is the case of IMS,
whose latency must be below few tens of milliseconds
[12]–[15]. Therefore, there is a need for new assessment
techniques that are computationally efﬁcient, and that can
address both high availability and low latency constraints.

infrastructures by taking into account cloud-centric
paradigms such as Network Function Virtualization (NFV),
which remodels classic network nodes (routers, switches,
ﬁrewalls, and others) as virtual entities called Virtualized
Network Functions (VNFs). VNFs can be chained to realize
Service Function Chains (SFCs), which represent the mod-
ern way of composing and providing new services quickly
and ﬂexibly, especially when coupled with the Software De-
ﬁned Networking [1]–[3]. Many applications adopt the SFC
paradigm [4], [5] with some examples shown in Fig. 1: the
Data Center domain (upper panel), where the chain is made
of systems such as Intrusion Detection, Firewall, and Router
in charge of processing the data ﬂow between a Server and
the Internet; the cellular domain (middle panel), where the
mobile trafﬁc is managed by a chain including: enhanced
Node-B (e-NB) to handle the radio link, and Signal and
Packet Gateways (S-GW, P-GW) to manage the signaling
and the data content, respectively; IP Multimedia Subsystem
(IMS) (lower panel) which relies on a chain of network
nodes providing multimedia services. Across such domains,
virtualization enables a ﬂexible and efﬁcient resource uti-
lization, since resources can be allocated and shared among
several service providers (tenants) at a ﬁne grain. Examples
of multi-tenant commercial and standard-based solutions
1) A novel latency-driven modeling approach for a
include: softwarized chains in the Evolved Packet Core
Containerized Network Function (CNF), a three-layered
domain [6], software-based IMS shared among different
(Software, Docker, Infrastructure layers) structure represent-
providers [7], and the Gateway Core Network (GWCN)
ing the elementary block of a service chain, and which has
for infrastructure sharing among different providers [8]. All
been modeled in terms of a Multi-State System (MSS). The
the aforementioned systems must satisfy quality-of-service
Copyright © 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including
reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of
any copyrighted component of this work in other works by sending a request to pubs-permissions@ieee.org.

Aimed at dealing with the aforementioned concerns, in

this work we advance:

 
 
 
 
 
 
&-03-0

4)&542&

670-.*88

9/:+-0

%!

%!

!"#$

&"’(

2"’(

2"<&<6

&"<&<6

4"<&<6

=&&

4;+-0;-+

)*+*,<-;+-0
)/?*7;

)*+*,
#-+./01

>/A78-
)/?*7;

>:8+7?-@7*
#-+./01

4>&
)/?*7;

Fig. 1. Examples of domains embracing the Service Chains paradigm:
Data Center (upper panel), Mobile Network (middle panel), IP Multime-
dia Subsystem (lower panel).

MSS formalism is helpful to encode the interplay among
the various nested layers in a containerized node, in terms
of failures and repair actions. To take into account latency,
literature,
which is typically neglected in the technical
we enhance this representation with a delay model, based
on queues with non-exponential service times and time-
varying serving facilities ruled by the failure/repair process.

2) A technique for the efﬁcient analysis of service
chains composed by several interconnected CNFs, based
on the Universal Generating Function (UGF) technique. This
paper extends our previous work on a multidimensional
version of UGF (MUGF) [17] that supports multi-tenant
service chains, where different operators (or tenants) share
the same infrastructure. In this work, we revised the MUGF
technique to take into account the novel latency-based met-
ric, in order to support the analysis over a chain of CNFs.

3) A detailed case study on a containerized multi-
tenant IP Multimedia Subsystem (cIMS) platform, a ser-
vice chain-like infrastructure crucial to manage multimedia
content within the 5G core network. The case study shows
the feasibility of the proposed approach in the context of a
relevant use case. In particular, it presents an extensive set
of experiments on the Clearwater cloud-based IMS platform
[18], through i) load test experiments, to estimate the em-
pirical service times, and ii) fault injection experiments, to
estimate repair times. Remarkably, fault injection techniques
turned out to be useful when empirical data are lacking, and
revealed that time-to-recovery is much longer than what is
typically assumed by most model-based studies.

The rest of the paper is organized as follows: Section 2
discusses relevant work on availability assessment in cloud
environments. In Section 3 we provide an overview of the
IMS case study, with a discussion about its containerized
deployment. In Section 4 we present the availability and
queueing models of a CNF, being the elementary struc-
ture of a service chain. In Section 5 we address the chain
availability concern through the MUGF technique and the
related optimization problem. Section 6 presents the testbed
and offers details about the experimental trials. Section 7
concludes the paper. For the sake of readability, Table 1
summarizes the notation adopted across the paper.

TABLE 1
Notation

2

m

ℓ
CNF(m,ℓ)

i; k

ηi

η
N (m,ℓ)

gi,η

γ

gη

δη

pη
∆(t)
W c(t)
Ac(wc)
J c
u(m)(z); uc(z)

ΩS , ΩD, ΩI

λC , λD, λI

µC , µD, µI

αi

βm

(Containerized) IMS tier (P,S,I,H)

CNF redundancy index

Parallel CNF ℓ associated to tier m

Tenant i; number of tenants using the cIMS

Number of working containerized instances controlled by tenant i

CNF State vector

Number of states of CTMC performance model of CNF ℓ of tier m

Capacity level exposed by CNF for tenant i in state η

Serving capacity

Capacity level vector in state η

Mean delay performance vector in state η

Steady-state probability of being in state η

Vector stochastic process including all tenants mean delays per CNF

Maximum tolerated value for the mean CSD

Steady-state availability of the cIMS

Number of states of the cIMS

MUGF for tier m; MUGF for the cIMS

State spaces of software, docker, infrastructure layers

Failure rate of containerized instances, docker, and infrastructure layers

Repair rate of containerized instances, docker, and infrastructure layers

Arrival rate of requests at tenant i

Service rate of requests at tier m

2 RELATED WORK

Availability issues represent a hot topic when dealing with
softwarized networks, where the presence of virtualized en-
tities (e.g. hypervisors, containerized environments, etc.)
pose new intriguing challenges for telecom operators that
are called for adhering to strict Service Level Agreements
(SLAs) [19]–[22]. Due to the vastness of the topic, techni-
cal studies adopt different angles to face the availability
problems, including: designing available virtualized infras-
tructures to manage trafﬁc problems [23], [24], optimizing
the allocation of virtualized infrastructures to maximize the
resiliency [25], [26], optimizing the availability scheduling of
virtual resources [27], [28], managing the state of virtualized
services in resiliency problems [29], [30]. On the other hand,
in our work we mainly focus on a modeling methodology
for the availability issues in softwarized networks. Thus, we
are going to explore some afﬁne literature more in detail, by
highlighting the main differences with our work.

Fan et al. [31] faced an availability problem concerning
the optimal deployment of an SFC infrastructure. In partic-
ular, their aim is to ﬁnd the minimum number of backup
VNFs that guarantees a desired availability level. A similar
problem is tackled by Kong et al. [32], where a heuristic
algorithm has been conceived to maximize the availability
of an SFC through an optimal distribution of backup VNFs
across primary and backup paths. Alameddine et al. [33]
focused on virtual machine redundancy in a multi-tenant
environment by adopting an optimal primary/backup logic.
All of these works did not consider, or only partially con-
sidered, a failure/repair model that is instead accurately
examined in our availability setting.

Other studies focused on more compact formalisms to
model network availability aspects. It is the case of Sebastio
et al. [34], where an availability assessment of exemplary
containerized architectures is faced through the Stochastic
Reward Networks (SRNs) framework. An SRN-based ap-

proach has been proﬁtably adopted also by Bruneo [35],
where a stochastic model to typify some aspects of an
Infrastructure-as-a-Service framework has been considered.
Similarly, a technique relying on Stochastic Petri Networks
(SPNs) has been exploited by Sousa et al. [36], where an
availability analysis of cloud-based deployments has been
carried out. Interestingly, both SRN/SPN and the proposed
MUGF rely on a common underlying Markov model. While
MUGF prefers an open analytical approach, SRN/SPN of-
fers a more compact representation (through the formalism
of places, arcs, tokens) that can be more convenient for
some users. However, in the case of multi-tier systems such
as SFCs, as further discussed in this paper, having the
underlying Markov model hidden by the SPN/SRN hinders
the computation of the availability.

Another track of works exploits the UGF methodology,
which, although historically adopted to cope with availabil-
ity issues in the ﬁeld of industrial systems, has found fertile
ground in networking management. Some examples include
the work by Sun et al. [37], where a UGF-based technique is
assessed for modeling physical and virtual system failures,
and Yu et al. [38], where the UGF has been applied in the
ﬁeld of service requests in cloud scenarios. Both studies
focused on single-tenant environments, not calling for the
application of a multidimensional form of UGF.

In the present paper, by exploiting the properties of
the multidimensional UGF (MUGF) at ﬁrst conceived by
our previous work [17], we propose a new availability
assessment method for multi-tenant environments. A set of
clear novelties emerge with respect to the original proposal.
First, in this work we consider a containerized infrastructure
(in place of a traditional virtualized architecture considered
in previous work [17]), which is reﬂected in the three-
layered structure of our model, where the containers do not
embed an OS and are deployed on top of the Docker con-
tainer manager. This model directly translates into a novel
experimental testbed (missing in the previous work [17]),
based on the Clearwater project, a realistic cIMS deployment
which allows to estimate the value of key quantities such
as repair rates, call setup latencies, and mean service times.
Moreover, in this work each tenant is modeled in accordance
to a sophisticated queueing model (there was no queueing
model in the previous work [17]), which allows to analyze
the call setup delay (CSD), a critical latency metric for 5G
networks as speciﬁed by ETSI [12]. Finally, the MUGF struc-
ture (in particular, series and parallel operators) is totally
different from the one introduced in previous work due to
the different metric adopted: the number of sessions in [17],
and the CSD in this new proposal.

We remark that, from a scalability viewpoint, the MUGF
technique exhibits interesting results compared to other
methods in similar ﬁelds. For example, Petri net structures
(e.g., SPN/SRN), beyond requiring very speciﬁc tools to
be solved, can suffer when dealing with large and nested
systems, as also highlighted by Peterson [39] and Herzog
[40]. In particular, SRNs offer a system state representa-
tion in terms of the “token” distributions (a.k.a. markings),
where each marking is representative of a particular state of
the system at a given time t. On one hand, this approach
provides a comfortable interface to automatically specify
the token distribution by hiding technical details about

3

!"#"
!"#$%$&’

%)"

%)"

$%&"’(
!%()#$%$&’

%

)

*++"

)"*+,(+-.
!*%%’

*++"

,$/"

/-01
!$+&’

)"*+&
!,-.%’

01

Fig. 2. Overview of the Clearwater IMS.

!"#

$%&’&()

’%&’&()

,%&’&()

9’’

!"2

-

*
%
!

,
$

+
"

#

$

&
*
)
(
’
&
%

$
#
#

"
!

*#+)’,$),-./01

*2+)’,$),-./01

*=+)’,$),-./01

*B+)’,$),-./01

*F+)’,$),-./01

*>+)’,$),-./01

*3+)4/56101789::$)71;<

*C+)4/56101789::$)71DE<

*G+)@1DHI7J1)@1D17.<)

*#?+)’,$)@/-A/-A *#>?+)

*#2+)’,$)@/-A/-A *#>?+)

*##+)’,$)@/-A/-A *#>?+)

*#B+)’,$)@/-A/-A *#>?+)

Fig. 3. IMS (single domain) call setup, where the Call Setup Delay metric
is represented on the left.

the underlying state model. On the other hand, such an
approach does not allow to easily retrieve the MSS state
distribution which is needed by the analytical formulation
of the MUGF.

Yet, the classic Continuous-Time Markov Chain (CTMC)
representation would lead to a space state explosion, since
it requires the entire cIMS to be modeled (monolithic ap-
proach), whereas the MUGF uses a combination of perfor-
mance distributions of single nodes to achieve the cIMS
performance distribution (decomposition approach).

3 CONTAINERIZED IMS CASE STUDY
In this study we present the proposed approach in the
context of a cIMS case study, based on Clearwater [18],
a real IMS product that fully leverages containers and
cloud computing technology. The cIMS consists of a chain
of softwarized functions running within containers. Such
containers are managed by a container engine (in our case
Docker) which is installed on a physical machine (a node). In
turn, the nodes can be replicated to form a tier, in order
to achieve higher performance and availability. Figure 2
shows a sketch of the Clearwater IMS characterized by
the following functions: Bono, which is the P-CSCF (Proxy-
Call Session Control Function), and acts as anchor point for
clients relying on the Session Initiation Protocol (SIP); Sprout
simultaneously acts as S-CSCF (Serving-CSCF) in charge of
managing SIP registrations, and as I-CSCF (Interrogating-
CSCF) for handling associations between UEs and a speciﬁc
S-CSCF; Homestead represents the HSS (Home Subscriber
Server) for users authentication; Ralf acts as CTF (Charg-
ing Trigger Function), for charging and billing operations;
Homer manages service setting documents per user, acting as
XML Document Management Server (XDMS). A red dashed
rectangle in Fig. 2 indicates the mandatory functions of the
cIMS architecture that we consider in our analysis.

Software Layer

Containerized Instances

"η1

Tenant 1

#$

!

…

!

…

!

. . .

#%

Docker Layer

CNF Model

Tenant K

"ηK

!

…

!

…

!

Infrastructure Layer (OS + HW)

Fig. 4. A CNF hosting K tenants. Each tenant can be represented
through a M/G/γηi queueing model managing a set of containerized
instances in the Software layer. Quantities αi and β are the arrival and
service rates, respectively. The Docker layer manages containers. The
Infrastructure layer embodies the host OS and the hardware.

The IMS is called to satisfy real-time constraints such as
delay, jitter, packet loss. In this regard, a metric called Call
Setup Delay (CSD) has been elected as a critical Key Perfor-
mance Indicator (KPI) [13]–[15], being strongly related to the
end-user experience. Formally, CSD is a time-based metric
deﬁned as the time interval between Invite message sent
from the caller and the received Ringing message (code 180)
[16], and well approximates the average time that user re-
quests spend in the cIMS (due to the processing time needed
by each node to handle the requests), where the propagation
delays are neglected. Figure 3 shows a simpliﬁed scenario
of a SIP call ﬂow (IMS single domain), where the CSD is
accordingly represented as a vertical double arrow between
the initial sent message, (1) SIP Invite, and the last received
message, (13) SIP Ringing.

3.1 Containerized Network Function Model

The network functions of a service chain can be deployed in
dedicated containers, and decoupled from the underlying
infrastructure, according to a three-layer structure:

•

Software layer: Its role is to run application software
that implements the business logic of the service
chain, to be deployed as containers (for example, in
our testbed, the Bono and the Sprout applications).
We assume that a CNF hosts containers of the same
type;

• Docker layer: Its role is to provide a run-time support
(e.g., a service daemon) to build, run, and manage
OS containers; this layer is also exploited in other
container management technologies, such as Linux
Container Daemon and Rocket;
Infrastructure layer: It represents the underlying phys-
ical layer that, for the sake of simplicity, includes only
the operating system (OS) and the hardware (HW)
components (e.g., CPU, RAM, etc.).

•

A single CNF represents the elementary block of each tier
of the service chain (i.e., a node in the system that includes
the three layers). As it will be clear in the following, a cIMS
tier can be made of several redundant CNFs (typically, of
one and the same type), in order to increase capacity and
to meet performance and availability objectives. A stylized

4

representation of a CNF is depicted in Fig. 4, where the i-th
tenant (i = 1, . . . , K) manages ηi containerized instances.
For each tenant, a containerized instance can manage, in
turn, a number of service requests amounting to γ (serving
capacity), at the same time. In practice, a containerized
instance is supposed to be composed of processes, each one
handling a single request. The serving capacity represents
the number of requests handled by each tenant. The re-
sulting queueing model of a single CNF for tenant i is an
inﬁnite queue M/G/γηi as in Fig. 4, where γηi depends on
the actual working conditions of CNF (see the forthcoming
Sect. 4.2 for more details). Moreover, all tenants share the
Docker and Infrastructure layers, as typical of modern cloud
deployments. Note that Fig. 4 represents the system from a
conceptual perspective, as in its actual implementations the
load among container instances is balanced by communica-
tion mechanisms (such as message queues, or DNS-based
load balancing) managed by the underlying Docker and
infrastructure layers.

4 CNF MODELING

In this section, we analyze the behavior of a single CNF
according to a double perspective. The ﬁrst one concerns the
availability characterization of a CNF in terms of a multi-
state model, where the failure/repair behaviors of the three
layers (Software, Docker, and Infrastructure) are represented
and evaluated (Sect. 4.1). The second one pertains to the
latency characterization by means of CNF queueing mod-
eling (Sect. 4.2). The CNF availability model and the CNF
queueing model can both be applied on a given CNF con-
ﬁguration, in order to get an assessment of its availability
and latency. These results will be used in the next section
for capacity planning of the service chain.

4.1 CNF availability model

The stochastic behavior (in terms of failure and repair
actions) of the three CNF layers can be captured through
the concept of state. A state reﬂects a particular condition
(e.g. up/down) of: one or more containerized instances
(belonging to the Software layer), the Docker layer, the
Infrastructure layer. Accordingly, the CNF model of Fig. 4
can be translated in terms of the transition-state diagram
reported in Fig. 5, where a state is labeled with a K-
K
dimensional vector η = (η1, ..., ηK) ∈
i=1{0, . . . , ni} and
ηi ∈ {0, 1, ..., ni} represents the number of working con-
tainer instances that belong to tenant i. The initial state
vector (n1, ..., nK) represents a fully-working system that
runs the maximum number of container instances per tenant
(reported in red in Fig. 5). As faults occur, the system
moves to states with lower values in the vector. In the
worst case, all container instances are failed (all values in
the vector are zero). Similarly, as container instances are
recovered, the system moves to states with higher values
in the vector. For instance, the vector (n1, ..., ni − 1, ..., nK)
indicates a state where one-out-of-ni container instances
of the i-th tenant is failed. All the failure interarrivals are
supposed to be independent and identically distributed (iid)
random variables according to an exponential distribution
with parameter λCi. The duration of a repair action of a

Q

(n1 - 2, n2,…, nK)

.  .  .

%$"#

(n1 - *)!"#

$"’

(n1 - 1, n2,…, nK)

(n1 - 1, n2 - 1,…, nK)

$"#

n1!"#

(n2 - *)!"’

$"#

n1!"#

$"’

(n1, n2,…, nK)

5

.  .  .

(0, 0,…, nK - nK + 1)

()$ "&

!"&

!+

!+

!,

!,

(n1, n2 - 1,…, nK)

%$"’

(n1, n2 - 2,…, nK)

(0, 0,…, 0)

!+

nK!"&

$"&

n2!"’

$"-.#

(n2 - *)!"’

.

.

.

(*$ "#

!"#

(n1, n2,…, nK - 1)

(n1,…, nK – 1 -1, nK - 1)

.  .  .

(n1 - n1 + 1, 0,…, 0)

!nK-1"!"-. #

(nK - *)!"&

%$"&

(n1, n2,…, nK - 2)

.  .  .

!"#

$+

!,

$"#

$,

!+

!+

!,

!,

Fig. 5. Transition-state diagram of CNF multi-state model. States are labeled with a vector that represents, for each tenant 1 . . . K, how many
container instances are available. The state vector (n1, ..., nK ) in red indicates a fully-working system that runs the maximum number of container
instances per tenant. States DLF and ILF indicate Docker and Infrastructure layers failures, respectively.

failed containerized instance is assumed to be an exponen-
tial random variable with parameter µCi. All the failure and
repair times are supposed to be independent of each other.
Thus, the transition rates are proportional to the number of
container instances that can fail and that can be recovered at
each state. The state Docker Layer Failure (DLF) indicates the
Docker failure condition which, in turn, causes the failure of
all the containerized instances, and the corresponding state
vector is (0, ..., 0)D. For Docker too, failure interarrivals are
supposed to be iid according to an exponential distribution
with parameter λD, and independent from containerized
instances failures. The duration of a repair action of this
layer is assumed to be an exponential random variable with
parameter µD. When Docker restarts, all the containerized
instances are assumed to be restarted. Such a condition is
taken into account by the transition from DLF state to initial
(completely working system) state with rate µD.

The state Infrastructure Layer Failure (ILF) is associated
with a crash of HW/OS part provoking a failure of the entire
system. Again, in this case the state vector is (0, ..., 0)I.
Also for the Infrastructure layer, failure interarrivals are sup-
posed to be iid according to an exponential distribution with
parameter λI , and independent from upper layers failures.
The duration of a repair action of this layer is assumed to be
an exponential random variable with parameter µI . Similar
to the previous case, when Infrastructure is restored, both
Docker and Software layers are restored. Such a condition is
taken into account by the transition from ILF state to initial
(completely working system) state with rate µI .

It is useful to highlight that, the assumptions on the
considered repair rates stem from the fact that mean-time-
to-repairs (namely 1/µ) are approximately constant over
time. It is especially valid for the software infrastructures
(as in our case) where repair actions are meant to be reboot
actions, as also conﬁrmed by credited literature [41]–[43].

To derive the steady-state availability, we formally

model the CNF as a Multi-State System (MSS). Let ΩS =
K
i=1{0, 1, . . . , ni} be the state space of the Software layer,
being {0, 1, . . . , ni} the state space of the tenant i, i =
Q
1, . . . , K; let ΩD = {0, 1}D and ΩI = {0, 1}I be the state
spaces of Docker and Infrastructure layers, respectively,
where 0 indicates the failure condition whereas 1 refers to
the working condition. Thus, the state space of the overall
CNF is Ω = ΩS × ΩD × ΩI .

Moreover, we deﬁne the capacity level gi,η exposed by the

CNF for tenant i in state η as

gi,η = γ · ηi,

(1)

where γ has been previously deﬁned as the serving capacity
of a containerized instance for each tenant. Since the capac-
ity of CNF can vary over time due to failures, the capacity
level gi,η is time-varying. The set including all possible
capacity levels gη = (g1,η, ..., gK,η) for each CNF is

i=1
Y

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

G =

γ · η

(

K

η ∈

{0, . . . , ni}

∪{(0, . . . , 0)D, (0, . . . , 0)I },

)

(2)
where (0, . . . , 0)D and (0, . . . , 0)I refer to the capacity levels
of the DLF and ILF states, respectively. The total number of
states in Fig. 5 is

K

N = |Ω| =

(ni + 1) + 2.

(3)

To characterize

the

ful

to introduce the structure

i=1
Y
considered MSS,

is use-
it
function ϕ : Ω →

η

η ∈

K
i=1{0, . . . , ni}

(
ﬁned as follows:

Q

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

∪ {(0, . . . , 0)D, (0, . . . , 0)I } de-

)

xD = 1, xI = 1

η,
(0, . . . , 0)D, xD = 0, xI = 1
(0, . . . , 0)I , xI = 0,

(4)

ϕ(η, xD, xI ) =






 
 
 
 
where xD ∈ ΩD and xI ∈ ΩI . It is a deterministic func-
tion [60] useful to specify the relation between the states
of single elements (layers) and the state of the overall
system (CNF). Now, the MSS of the CNF is completely
described by the state space Ω, the serving capacity lev-

els

η

η ∈

K
i=1{0, . . . , ni}

∪ {(0, . . . , 0)D, (0, . . . , 0)I },

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(

Q

)
and the structure function ϕ. Let now be X(t) =
(X1(t), . . . , XK(t)) a ΩS-valued stochastic process which
denotes the failure-repair process of the Software layer;
XD(t) a ΩD-valued stochastic process which denotes the
failure-repair process of Docker layer; XI (t) a ΩI -valued
stochastic process which denotes the failure-repair process
of Infrastructure layer, all deﬁned for t ≥ 0. Each of the
above processes is Markovian on its state space, being all
the underlying random variables exponentially distributed
and independent of each other. Thus, the stochastic pro-
cess {ϕ(X(t), XD(t), XI (t)), t ≥ 0} is represented by the
transition-state diagram in Fig. 5. Moreover, the CNF capac-
ity level at time t ≥ 0 is expressed in terms of the vector
stochastic process

G(t) = (G1(t), ..., GK (t)) = γ ·ϕ(X(t), XD(t), XI (t)), (5)

with values in G, and with (state) probability vector p(t)
at time t collecting all the state probabilities pη(t), being
pη(t) = Pr{G(t) = gη}. We note that G(t) is a CTMC
process described by a transition-state diagram equal to
the one in Fig. 5, except that each state vector must be
multiplied by γ.

We see that G(t): i) has a ﬁnite state space with cardi-
nality N given by (3); ii) is irreducible, since every state
is reachable from every other state (see Fig. 5); iii) is
homogeneous since its inﬁnitesimal generator matrix Q has
constant elements (given constant parameters of failure and
repair random variables). From the above properties, G(t)
is an ergodic CTMC with a unique steady-state probability
vector p = limt→∞ p(t), with p(t) given by the solution of

dp(t)
dt

= p(t)Q,

(6)

along with the normalization condition

η pη(t) = 1.

Again, p is a vector collecting the state-state probability

pη for each state η, that is given by:

P

pη = lim
t→∞

pη(t) = lim
t→∞

Pr{G(t) = gη}.

(7)

the

(discrete)

random vector G =
Accordingly,
(G1, ..., GK) ∈ G corresponds to the asymptotic behavior
of G(t) (in the limit of t → ∞) and admits values in the
set (2) with probabilities (7). In conclusion, the set of pairs
{pη, gη} determines the steady-state behavior of a CNF in
terms of serving capacity.

4.2 CNF Queueing model

Our queueing model reﬂects the typical behavior of real
systems, where the requests arriving to the CNF are served
according to a queue characterized by non-exponential ser-
vice times. As regards the choice of the queueing model
system, we lie not so far from technical literature where

6

SIP-based servers are characterized through M/M/1 or
M/M/k inﬁnite queueing systems (see [44]–[48]) with a
ﬁxed number of servers. Such models are based on the
exponential assumption of service times that, in the ﬁeld of
network communications, might be quite unrealistic. In our
work, indeed, we are able to directly measure the service
times across our testbed (see Sect. 6.1), and we ﬁnd out
that the empirical distribution of service times is not well
ﬁtted by an exponential distribution. Accordingly, we adopt
an M/G/Gi(t) model accounting also for the time-varying
number of servers due to the failure/repair process for each
tenant i. For a given state of the model, Gi(t) = γηi and
thus M/G/Gi(t) is equivalent to M/G/γηi.

Furthermore, we want to highlight an important rela-
tionship between queueing and failure/repair models in
terms of time scales. As observed in [55],
in the ﬁeld
of communication networks it is possible to distinguish
various and different time scales, such as the failure time
scales (FTS) and the service time scales (STS). The former
governs the failure/repair processes, and the latter governs
the typical queueing metrics (e.g. the service times). When a
time scale completely dominates another one, it is possible
to neglect the transient effects produced by the dominated
time scale. In service chains such as the cIMS, FTS ≫ STS,
since FTS is in the order of thousands of hours, while STS
is in the order of milliseconds (see also the parameters in
Table 2). Thus, a decoupling between FTS and STS can
be reasonably assumed. This behavior leads to claim that,
given a state η, tenant queues reach their steady-states very
quickly compared to the occurrence of faults. In summary,
for each state η, we use a steady-state M/G/γηi queue
model for tenant i to derive the delay model of a CNF.

We assume that call setup requests arriving to tenant i
follow an arrival Poisson process (a common assumption
literature [49]–[51]) with parameter αi. Let
in technical
1/β be the mean value of service times derived from the
experiments, that we suppose to be one and the same for
all requests and tenants. Now, since no closed forms are
available to evaluate the mean delay introduced by the
M/G/γηi model to requests, we proceed in two steps:
i) we derive the mean delay for M/M/γηi; ii) then, we
compute the mean delay for the M/G/γηi model by using
the approximating formula known as the Kingman’s law of
congestion (see [52], [53]), that exploits the coefﬁcients of
variation of the measured service times.

Along with the ﬁrst step, according to [54], the mean
number of requests (or jobs) νi,η for the M/M/γηi model
for tenant i in state η is:

E[νi,η] = γηi · ρi,η + ρi,η

(γηi · ρi,η)γηi
γηi!

πi,η
(1 − ρi,η)2 ,

(8)

where utilization factor amounts to:

ρi,η =

αi
β · γηi

,

and

πi,η =

γηi−1

"

Xh=0

(γηi · ρi,η)h
h!

+

(γηi · ρi,η)γηi
γηi!

−1

1
1 − ρi,η #

.

By virtue of Little’s law, the mean delay is

E[di,η] =

E[νi,η]
αi

.

(9)

In the second step, since the ﬁrst and second moments of
service times distribution are ﬁnite, we apply the Kingman’s
approximation to derive the mean delay introduced by the
considered M/G/γηi system (say δi,η) of tenant i in state η,
namely

δi,η ≈ E[di,η] ·

1 + CV 2
s
2

,

(10)

being CVs the coefﬁcient of variation of the empirical service
time1. As pointed by Whitt (see [57]), such an excellent
approximation can be considered a special case of Allen-
Cunneen approximation [58]. Obviously, δi,η increases as
γηi reduces due to failures. On the other hand, δi,η decreases
as γηi increases by virtue of repair actions. It is worth
noting that, the Kingman’s approximation can be easily
generalized also to the case of generic arrival times, with
a little modiﬁcation of eq. (10) which can be rewritten as:
s )/2, being CV 2
δi,η ≈ E[di,η] · (CV 2
a the coefﬁcient
of variation of the distribution of the arrivals.

a + CV 2

Being BK the Cartesian product of a set B for itself K
times, to characterize the MSS describing the delay model,
it is useful to introduce the structure function ϕ∆ : Ω →
{R+ ∪ {+∞}}K deﬁned as follows:

ϕ∆(η, xD, xI ) =






(δ1,η, . . . , δK,η) , xD = 1, xI = 1
xD = 0, xI = 1
(+∞, . . . , +∞),
xI = 0,
(+∞, . . . , +∞),

(11)

where δi,η is given by (10), i = 1, . . . , K, and where the in-
ﬁnite delay arises when there are no working containerized
instances. The mean delays introduced by a single CNF at
time t ≥ 0 is the vector stochastic process

∆(t) = (∆1(t), ..., ∆K (t)) = ϕ∆(X(t), XD(t), XI (t)).

(12)
Similarly to the stochastic process G(t) in (5), ∆(t) is an
ergodic CTMC, and the random vector ∆ = (∆1, . . . , ∆K)
corresponds to the asymptotic behavior of ∆(t) as t → ∞.
Given δη = (δ1,η, ..., δK,η) the mean delays vector for each
state η, the set of pairs {pη, δη} determines exhaustively
the steady-state performance behavior of the CNF in terms
of mean delay, being pη given by (7).

5 MODELING OF THE CNF SERVICE CHAIN

Based on the CNF modeling from the previous section
(which represents an individual CNF in the service chain),
we here build a model for the whole service chain of
multiple CNFs. Two important aspects emerge. First, the
chain is made of tiers connected in series (e.g., see Fig. 6 in the
context of the cIMS). Thus, the entire chain is supposed to
be working when every tier m in the chain is working (e.g.,
m ∈ {P, S, I, H} for the cIMS, where P, S, I, H, indicate for
brevity P-CSCF, S-CSCF, I-CSCF, HSS, respectively). Second,
each tier m consists of redundant CNFs connected in parallel,

1. Such an approximation holds either for individual queues and for

open non-Markovian network of queues (see [52], [56]).

7

in order to improve performance and availability. We re-
mark that a tier m acts as a logical entity, by dividing the load
among the replicas in the tier, according to the ﬂow dispersion
hypothesis (any CNF is able to handle service requests - see
[59]). Every replica includes all of the three layers of the
CNF structure (Software, Docker, and Infrastructure).

We denote with CNF(m,ℓ) the ℓ-th parallel CNF associ-

ated to tier m (ℓ = 1, . . . , Lm).

i

Now, we start to evaluate the mean CSD introduced
by tier m, where each CNF(m,ℓ)
is modeled as an
M/G/G(m,ℓ)
(t) queue for tenant i. Indeed, tier m is given
by Lm parallel CNFs (see Fig. 6), and can be analyzed as
a single M/G/G(m)
(t) queue as consequence of the ﬂow
dispersion hypothesis. Similarly to the vector stochastic
process deﬁned in (12), let

i

K (t)
(cid:17)

∆(m)(t) =

∆(m)
1

(t), ..., ∆(m)

(13)

(cid:16)

be the vector stochastic process containing the mean CSD
introduced by tier m for each tenant. Remarkably, ∆(m)
(t) is
the stochastic process describing the M/G/G(m)
(t) queue,
that can be computed like in Section 4.2, by replacing γηi
with G(m)
(t) in equations from (8) to (10).
Since the call ﬂow traverses the service chain, the overall
mean CSD is the sum of mean CSDs introduced by each
single tier, namely

ℓ=1 G(m,ℓ)

(t) =

P

Lm

i

i

i

i

∆c(t) = (∆c

1(t), ..., ∆c

K(t)) =

∆(m)(t).

(14)

m
X

Similarly to the derivation of {pη, δη} previously ob-
tained for a single CNF, ∆(m)(t) and ∆c(t) are ergodic
CTMCs, and ∆(m) and ∆c correspond to their asymptotic
behaviors as t → ∞. More technical details about the
derivation of ∆(m)(t) and ∆c(t) (obtained by introducing
the series and parallel structure functions) are provided in
the Appendix A.

Accordingly, given δ(m)

η =

1,η , ..., δ(m)
δ(m)
tier m in state η, and p(m)
(cid:16)

K,η

(cid:17)

the mean

η

η

η =

η , δ(m)
p(m)

=
delays vector of
limt→∞ Pr{∆(m)(t) = δ(m)
η } the corresponding limiting
represents the
probability, the set of pairs
steady-state mean CSD distribution of tier m. Likewise,
n
given δc
1,η, ..., δc
δc
the mean delays vector of
K,η
η = limt→∞ Pr{∆c(t) = δc
system in state η, and pc
η} the
(cid:16)
η, δc
pc
corresponding limiting probability, the set of pairs
η
is the steady-state mean CSD distribution of the entire
(cid:9)
service chain.
Lm
ℓ=1 N (m,ℓ) be the number of states of
tier m for each parallel CNF ℓ, with N (m,ℓ) given by (3), the
number of states corresponding to the service chain is

Letting J (m) =

Q

o

(cid:17)

(cid:8)

J c =

J (m).

(15)

Ym∈{P,S,I,H}

We consider the multi-tenant infrastructure as available
when every operator (or tenant) guarantees a mean CSD less
than a (maximum) tolerated value for its customers.

1 (t), ..., W c

Let W c(t) = (W c

K (t)) be a K-dimensional
vector containing the maximum tolerated values per tenant
i at time t. The instantaneous availability Ac [t, W c(t)] is
deﬁned (see [59], [60]) as the probability that mean CSD

Containerized IMS Infrastructure

P-CSCF

S-CSCF

I-CSCF

HSS

CNF(P,1)

CNF(S,1)

CNF(I,1)

CNF(H,1)

whole service chain. For each state η, vector δc
η collects all
the exponents of z1, . . . , zK , while pc
η is the multiplicative
coefﬁcient. Such quantities are used in (17) to compute the
steady-state availability Ac(wc) of the multi-tenant chain.

8

CNF(P,2)

CNF(S,2)

CNF(I,2)

CNF(H,2)

.

.

.

.

.

.

.

.

.

.

.

.

CNF(P,L

)
P

CNF(S,L

)
S

CNF(I,L

)
I

CNF(H,L

)

H

Fig. 6. Multi-tenant cIMS system, where parallel CNFs are introduced
for redundancy purposes. CNF(m,ℓ) refers to parallel CNF ℓ (ℓ =
1, . . . , Lm) of tier m, with m ∈{P-CSCF, S-CSCF, I-CSCF, HSS}.

of the service chain for each tenant i (at t > 0) is not greater
than W c

i (t), i = 1, ..., K, viz.

Ac [t, W c(t)] = Pr{∆c

i (t) − W c

i (t) ≤ 0, ∀i = 1, ..., K}.

(16)
Given constant maximum values W c(t) = wc =
(wc
K), the steady-state availability Ac (wc) can be de-
rived from (16) for t → ∞, as

1, ..., wc

Ac(wc) =

pc
η · 1

i,η ≤ wc
δc

i , ∀i = 1, ..., K

,

(17)

Xη∈Ωc

(cid:0)

(cid:1)

where 1(·) amounts to 1 if condition holds true and 0
otherwise, and Ωc =

m ΩLm .

5.1 Steady-state availability using the MUGF technique

Q

The Multidimensional Universal Generating Function
(MUGF) technique [17] provides an efﬁcient method to eval-
uate the steady-state availability of (17). Being the MUGF a
special case of probability generating function of a multi-
variate random variable, the steady-state distribution of an
MSS can be expressed through a polynomial-shape form.
More precisely, the MUGF of the steady-state mean CSD
distribution pertaining to the tier m is

u(m)(z) =

p(m)
η

K

δ(m)
i,η
i

z

,

(18)

Xη∈ΩLm
a function of the vector indeterminate z = (z1, . . . , zK).

i=1
Y

From the generating functions theory, the sum of mul-
tivariate independent random variables has a generating
function given by the product of the generating functions
of single variables. Accordingly, by recalling that mean CSD
of the service chain is the sum of mean CSDs introduced by
each tier, the MUGF uc(z) is the product of the MUGFs of
single tiers computed by (18), viz.

uc(z) =

p(m)
η

K

i=1
Y

Xη∈ΩLm

m 
Y


δ(m)
i,η
i

z

.



(19)

Thus, uc(z) represents a polynomial-shape function in
z1, . . . , zK . The uc(z) can be easily computed by combining
the individual MUGFs through products and sums. The
resulting expression of uc(z) provides the mean CSD vector
η and the corresponding steady-state probabilities pc
δc
η of the



5.2 Redundancy optimization of the service chain

The proposed availability assessment method is useful to
solve network design problems, such as the selection of
an optimal conﬁguration that satisfy a given availability
objective. The problem of practical interest is to identify the
conﬁguration(s) minimizing the number of CNF replicas for
each tier of the service chain.

We denote with the vector ℓ a conﬁguration of the multi-
tenant service chain, that is, the number Lm of replicas for
each tier m. In the case of the cIMS, m ∈ {P, S, I, H},
and ℓ = (LP , LS, LI , LH). Obviously, this approach can be
easily applied to other SFC architectures by changing the
set of elements belonging to the chain itself (namely the
components in the series availability model).

We deﬁne C(m,ℓ) as the cost of parallel CNF ℓ belonging
to tier m. Thus, the cost of the conﬁguration ℓ of the multi-
tenant service chain is

Lm

Cc(ℓ) =

C(m,ℓ).

(20)

m
X

Xℓ=1
By considering dmax the maximum tolerated value for
the mean CSD for each tenant (which is typically provided
by international standards, such as for the IMS [71]), namely
wc = (dmax, . . . , dmax), the steady-state availability of the
conﬁguration ℓ, in terms of mean CSD, is given by (17), viz.

Ac(wc, ℓ) =

pc
η · 1

δc
i,η ≤ dmax, ∀i = 1, ..., K

.

(21)

η∈J c
X

(cid:0)

(cid:1)

Given an availability constraint A0 (for example, A0 =
0.99999 also known as “ﬁve nines” availability), we deﬁne
the set of conﬁgurations satisfying such a constraint as Lc =
{ℓ : Ac(wc, ℓ) ≥ A0}.

Then, the system conﬁgurations with minimum deploy-
ment cost which satisfy the availability constraint A0 are
provided by solving the following optimization problem:

ℓ∗ = arg min

ℓ∈Lc

Cc(ℓ).

(22)

In summary, the optimization problem (22) contains ele-
ments both from availability and queueing models, where
the latter allows to estimate the latency introduced by
a chain. Indeed, the ﬁrst step consists in computing the
steady-state availability of chains, deﬁned in terms of la-
tency (see (21)), and in building the set of conﬁgurations Lc
guaranteeing the given availability constraint. The second
step consists in identifying the conﬁguration(s) minimizing
the cost (20) represented by the solution(s) of (22).

The process allowing to build various conﬁgurations
relies on a greedy stage. By starting from a baseline con-
ﬁguration with 1 CNF per tier, the routine automatically
adds 1 CNF per node up to a given threshold and evaluates
the conﬁguration availability. Since it is impossible to know
beforehand which is the number of CNFs needed to obtain
at least one solution, we set a conﬁgurable threshold value

 
 
 
 
 
 
 
 
(namely, an integer number of CNFs) which represents the
maximum number of CNFs a node can host. Obviously,
depending on failure/repair parameters, it may happen
that a given availability target (i.e., ﬁve nines) is never
reached. In such a case, the network designer must relax
the availability constraint (i.e. four nines). Once the routine
has terminated its run, it produces a set of possible con-
ﬁgurations, and it will choose the one (ℓ∗) satisfying the
required condition. Interestingly, our routine allows to retain
also the (sub-optimal) conﬁgurations, to leave the network
designer the possibility of choosing a different setting (e.g.
a conﬁguration with Ac(wc) = 0.99998, which is barely far
from the ﬁve nines requirement).

6 EXPERIMENTAL RESULTS

This section consists of two parts: the ﬁrst one contains a
detailed description of the testbed deployed to derive real-
istic parameters such as: repair rates of various components
by adopting fault injection techniques, mean service times
employed by containerized software instance to manage
cIMS requests, mean call setup delays experimented by
multimedia calls. The second part pertains to the availability
assessment performed through MUGF technique by exploit-
ing the estimated parameters.

6.1 The cIMS testbed

We deploy from scratch an experimental testbed aimed at
validating the proposed technique in a realistic NFV-based
environment. Our testbed is composed of hardware and
software technologies commonly adopted in cloud data-
centers such as: operating systems based on Linux ker-
nel 4.4.0, Docker engines (version 19.03.5) running on 16-
Core 1.80GHz Intel Xeon machines with 64GB RAM, two
500GB SATA HDD, four 1-Gbps Intel Ethernet NICs, and
one NetApp Network Storage Array with 32TB of storage
space and 4GB of SSD cache. The hosts are connected to
a 1-Gbps Ethernet network switch. The testbed includes 4
machines (each of which equipped with the aforementioned
HW/SW), and relies on Clearwater (release 130), an open-
source platform (later embodied in a commercial product
[18]) which allows emulating a fully working IMS architec-
ture in a container-based environment. We deploy the IMS
functionalities (Bono, Sprout, Homestead) on top of Docker
as depicted in Fig. 7. For each CNF we manage two different
tenants. We use an external machine equipped with SIPp
tool [76] (as a workload generator) and with HAproxy [77]
to perform trafﬁc balancing among all instances of Bono.

As in our previous studies [10], [62], we adopt fault
injection to emulate faults and to measure the recovery times,
in order to estimate representative model parameters. To
assure the occurrence of failures, we emulate faults through
the injection of their effects, which is also referred to as
error or failure injection in some studies [63], [64]. In our
experiments, we injected the following three types of faults.
Software layer faults: responsible for software crashes
of the CNF upper layer which embeds the speciﬁc IMS
service logic. Typically, such faults include race condition
bugs, resource exhaustion due to software aging bugs, I/O
and exception handling bugs [75]. The Clearwater IMS is no

9

Fig. 7. The deployed cIMS architecture.

exception, as a number of such failures have been reported
by users on its issue tracker and mailing lists [74]. We inject
these faults by forcing the abrupt termination of a container.
Docker layer faults: similarly for the containers, the
Docker engine is affected by software faults related to tim-
ing, resource management, and other environmental condi-
tions. Both academic research and end-users report recur-
ring failures in Docker and in similar management software
[65], [72], [73], causing the unavailability of containers along
with virtual networks and storage volumes. We inject these
faults by forcing the termination of container management
services (i.e., the dockerd process) that, in turn, results in
the termination of all containers running on top.

Infrastructure layer faults: software and hardware faults
related to the crash of the hypervisor and the underlying
physical infrastructure, respectively [10], [72]. In turn, these
faults cause the unavailability of Docker and the whole set
of containers. We inject these faults by forcing the abrupt
shutdown of the machine.

We performed 30 fault injection experiments per CNF
and per fault type, amounting to 360 experiments in total.
Each fault injection experiment takes about 10 minutes both
for the software layer and for the Docker engine, whereas it
takes about 15 minutes for the infrastructure layer. Before
injecting faults, we wait for an initial warm-up period
(400 seconds) to let the system to reach a regime level.
We automate fault injection experiments through ad-hoc
routines developed to manage operations such as: start/stop
fault injection, trigger the shutdown and the recovery of
containers and hosts, collect metrics for each CNF through
SNMP protocol as detailed in the following.

• P-CSCF: we analyze the number of SIP events (SIP
messages) successfully passed to a Bono worker
thread per unit time, reported in the SNMP object
bonoQueueSuccessFailSuccesses.

•

time,

• S-CSCF: we analyze the number of

success-
ful outgoing SIP transactions (INVITE messages)
per unit
reported in the SNMP object
sproutSCSCFOutgoingSIPTransactionsSuccesses.
I-CSCF: we
suc-
over
cessful
the
SNMP object
sproutICSCFSessionEstablishmentSuccesses.
• HSS: we analyze the number of enqueued Mem-
cached requests per unit time, reported in the SNMP

of
attempts

the
request

reported in

terminating

number

analyze

period,

the

10

s
e
s
s
e
c
c
u
S
n
e
m
h
s

t

i
l

b
a

i

t
s
E
n
o
s
s
e
S
F
C
S
C

I
t

u
o
r
p
s

120

100

80

60

40

20

0

0

100

200

300
time [s]

400

500

600

s
e
s
s
e
c
c
u
S
n
e
m
h
s

t

i
l

b
a

i

t
s
E
n
o
s
s
e
S
F
C
S
C

I
t

u
o
r
p
s

120

100

80

60

40

20

0

0

100

200

300
time [s]

400

500

600

s
e
s
s
e
c
c
u
S
t
n
e
m
h
s

i
l

i

b
a
t
s
E
n
o
s
s
e
S
F
C
S
C

I
t
u
o
r
p
s

120

100

80

60

40

20

0

0

100

200

300

400

500

600

700

800

900

time [s]

(a) Software layer fault.

(b) Docker layer fault.

(c) Infrastructure layer fault.

Fig. 8. Sprout I-CSCF under fault injection.

0.6

0.5

0.4

0.3

0.2

0.1

y
c
n
e
u
q
e
r
f

e
v
i
t
a
e
R

l

0

0

P-CSCF (Bono)

0.002

0.004
0.006
Service time [s]

0.008

0.01

0.6

0.5

0.4

0.3

0.2

0.1

y
c
n
e
u
q
e
r
f

e
v
i
t
a
e
R

l

0

0

S-CSCF (S-Sprout)

0.01

0.02

0.03

Service time [s]

0.04

0.05

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

y
c
n
e
u
q
e
r
f

e
v
i
t
a
e
R

l

0

0

I-CSCF (I-Sprout)

HSS (Homestead)

0.6

0.5

0.4

0.3

0.2

0.1

y
c
n
e
u
q
e
r
f

e
v
i
t
a
e
R

l

0.05

0.1
Service time [s]

0.15

0

0

0.005

0.01

0.015
Service time [s]

0.02

0.025

Fig. 9. Empirical service time distribution of Clearwater nodes (from the left: P-CSCF, S-CSCF, I-CSCF, HSS).

object homesteadCacheQueueSizeCount.

We use the aforementioned metrics to estimate the re-
covery time of the cIMS, in line with the previous NFV de-
pendability benchmark study [10]. We measure the recovery
time as the period during which a CNF is unavailable: it
starts at a given fault injection time when the considered
metric drops to zero, and it ends when the metric raises up
to its regime value after recovery is completed. Each metric
is evaluated at the output of a ﬁve-sample moving average
ﬁlter, introduced to smooth ﬂuctuations occurring during
recovery. We consider the recovery procedure as completed
when the metric overcomes a given threshold set to 90% of
the fault-free metric level [78].

For instance, the recovery times of Sprout I-CSCF CNF
after different injections are shown in panel of Figs. 8.
Precisely, Fig. 8a, Fig. 8b, Fig. 8c report the recovery time in
the presence of a Software layer fault, a Docker layer fault,
and an infrastructure layer fault, respectively. We note that
the differences between the curves is due to the typical vari-
ability of the experiments. Moreover, it is possible to receive
a slightly different amount of trafﬁc across executions, since
load balancing cannot be perfectly uniform across replicas.
The panel of Figs. 9 reports the service times distributions
that we measure for each cIMS node. We remarked that
these empirical distributions of service times are important
to analyze the latency, namely to derive the coefﬁcients of
variation for each CNF to be used in (10).

Interestingly, our fault injection trials provided unex-
pected ﬁndings on the failure and recovery behavior of con-
tainerized network functions. Precisely, most studies adopt
too simplistic assumptions about the containers time-to-
recovery, by only considering the time to perform a restart

action on a container (in the order of few seconds for a Linux
container on a modern hardware machine). In contrast, our
experiments reveal a longer time (in the order of minutes) to
restore performance. A critical factor is represented by the
restart of application software. Since the IMS is developed
in the Java language, a new instance of the JVM needs
to be allocated and initialized. Moreover, the application
itself needs to manage allocations and data initialization
(e.g., to start a thread pool). Afterwards, the performance is
gradually restored, due to enqueueing and caching effects.

6.2 Availability assessment of cIMS

We perform a steady-state availability assessment of cIMS
through the MUGF technique supported by the experimen-
tal data. Let us assume that: i) each CNF composing the
system in Fig. 6 exhibits one and the same availability
model namely, we suppose identical failure/repair param-
eters for each CNF), and, ii) all nodes exhibit one and the
same cost amounting to 1, or equivalently, C(m,ℓ) = 1,
∀ℓ ∈ {1, ..., Lm}, with m ∈ {P, S, I, H}. Needless to say,
the considered assumptions can be easily tailored across
a variety of scenarios where network providers operate
with different costs and performance features. Let us refer
to an exemplary setting with K = 2 network providers
(tenants), where the ﬁrst one has n1 = 2 containerized
instances, and the second one has n2 = 3 containerized
instances. As a result, the MSS model of the CNF can be
directly derived from the transition-state diagram depicted
in Fig. 10 with a number of different states amounting to
N = (n1 + 1)(n2 + 1) + 2 = 14 according to (3). The steady-
state probability distribution of a single CNF can be directly

 
 
 
 
TABLE 2
Input parameters

TABLE 3
Steady-state Availability under 12 conﬁgurations

11

Parameter
1/λC
1/λD
1/λI
1/µC
1/µD
1/µI
α1
α2
1/βP
1/βS
1/βI
1/βH
CVP
CVS
CVI
CVH
dmax

Description
mean time for container failure†
mean time for docker failure†
mean time for infrastructure failure†
mean time for container repair‡
mean time for docker repair‡
mean time for infrastructure repair‡
IMS request arrival rate at tenant 1‡
IMS request arrival rate at tenant 2‡
P-CSCF empirical mean service time per request‡
S-CSCF empirical mean service time per request‡
I-CSCF empirical mean service time per request‡
HSS empirical mean service time per request‡
P-CSCF coefﬁcient of variation (Kingman’s approx.)‡
S-CSCF coefﬁcient of variation (Kingman’s approx.)‡
I-CSCF coefﬁcient of variation (Kingman’s approx.)‡
HSS coefﬁcient of variation (Kingman’s approx.)‡
Maximum tolerated CSD

Value
1258 hours
2516 hours
60000 hours
30 s
60 s
5 min
100 s−1
200 s−1
1.1 · 10−3 s
7.2 · 10−3 s
4.1 · 10−2 s
4.6 · 10−3 s
0.7538
0.9826
0.5581
0.4631
50 ms

† From scientiﬁc literature
‡ From experiments

obtained by solving the system of differential equations (6)
for t → ∞, as detailed in Appendix B.

Table 2 summarizes the input parameters adopted for
the assessment, where: failure and repair rates have been, in
part, derived from the deployed testbed, and, in part, chosen
according to the technical literature (see [34], [66]–[70]). Let
us provide clariﬁcations about some parameters estimated
through the testbed. First, the presence of multiple contain-
ers does not dramatically affect the infrastructure reboot
ruled by the µI parameter. Such a situation is commonly
encountered in practice, where the network designer adopts
some strategies to control the parameter variability (i.e.,
smart allocation of hardware resources, snapshots usage,
CPU pinning).

Moreover, the α parameters are inﬂuenced by the capac-
ity of the system. We calibrated the workload generator to
run new subscribers and to generate trafﬁc such that the
system approaches its capacity, without degrading latency
and without saturating CPU and memory. This scenario as-
sumes that the number of containers in the system is scaled
according to the workload, which is typical for services
deployed on cloud computing infrastructures. Again, the
empirical service times distributions (Figs. 9) are evaluated
by analyzing the service rates of each node. From such data,
we also derive the coefﬁcient of variation per node, useful to
obtain the Kingman’s approximation (10). Finally, the dmax
value is a pessimistic estimate chosen in accordance to the
ITU-T standard speciﬁcations [71], where acceptable values
are in the order of seconds, since they account for prop-
agation delays in geographic networks that are obviously
negligible in our testbed.

In keeping with the “ﬁve nines” availability requirement,
we set A0 = 1 − 10−5 and solve the optimization problem
(22). A routine in Mathematica® (available upon request)
computes the MUGF (19) and serves to ﬁnally evaluate
the steady-state availability of cIMS expressed through (17).
Then, the routine selects, among all feasible conﬁgurations,
the one(s) exhibiting the minimum cost.

Table 3 reports the results of our experimental evalua-
tion, where 12 exemplary conﬁgurations have been shown.
The optimal conﬁguration is ℓ∗
, which exhibits a steady-
state availability amounting to Ac(wc) = 0.999992, with

Conﬁg.
ℓ∗
ℓ1
ℓ2
ℓ3
ℓ4
ℓ5
ℓ6
ℓ7
ℓ8
ℓ9
ℓ10
ℓ11

Redundancy Level
[CN F (P ) = 2, CN F (S) = 1, CN F (I) = 3, CN F (H) = 2]
[CN F (P ) = 2, CN F (S) = 2, CN F (I) = 2, CN F (H) = 2]
[CN F (P ) = 2, CN F (S) = 3, CN F (I) = 2, CN F (H) = 2]
[CN F (P ) = 3, CN F (S) = 3, CN F (I) = 2, CN F (H) = 3]
[CN F (P ) = 1, CN F (S) = 1, CN F (I) = 3, CN F (H) = 3]
[CN F (P ) = 1, CN F (S) = 1, CN F (I) = 2, CN F (H) = 1]
[CN F (P ) = 2, CN F (S) = 1, CN F (I) = 2, CN F (H) = 1]
[CN F (P ) = 2, CN F (S) = 2, CN F (I) = 2, CN F (H) = 1]
[CN F (P ) = 3, CN F (S) = 3, CN F (I) = 3, CN F (H) = 1]
[CN F (P ) = 2, CN F (S) = 2, CN F (I) = 3, CN F (H) = 2]
[CN F (P ) = 2, CN F (S) = 2, CN F (I) = 2, CN F (H) = 4]
[CN F (P ) = 2, CN F (S) = 3, CN F (I) = 2, CN F (H) = 4]

Cc(ℓ)
8
8
9
11
8
5
6
7
10
9
10
11

Ac(wc)
0.999992
0.999944
0.999944
0.999945
0.999984
0.999919
0.999927
0.999936
0.999994
0.9999999
0.999968
0.999968

a cost amounting to Cc(ℓ∗) = 8 CNFs. Such a conﬁgu-
ration is obtained by considering (see the second column
of Table 3 where CNF(m) denotes the number of CNFs for
tier m): 2 redundant CNFs for P-CSCF and HSS, 3 CNF
replicas for I-CSCF, and no redundancy for the S-CSCF.
For the sake of clarity, we want to highlight that the same
cost and availability values are obtained by exchanging the
redundancy role of P-CSCF, S-CSCF, and HSS. This is due
to the fact that the most critical network function turns
to be the I-CSCF, in view of its higher service time (see
pertinent values in Table 2). By exploring the remaining
conﬁgurations, we can observe other interesting facts. Con-
ﬁguration ℓ1 is obtained as a rearrangement of ℓ∗
, where
replicas have been differently distributed across the network
functions (obviously, this results in the same cost). But, as
can be noticed, this redistribution does not allow to meet
the desired high availability requirement. In conﬁguration
ℓ2, the redundancy of S-CSCF is empowered by 2 replicas
w.r.t. ℓ∗
, whereas one less replica is considered for I-CSCF.
Also in this case, the steady-state availability ﬁxes on “four
nines”, and the overall conﬁguration cost increases to 9.
Interestingly, conﬁgurations ℓ1 and ℓ2 exhibit the same
value of availability even if an additional S-CSCF replica
characterizes ℓ2 w.r.t. ℓ1. This behavior can be ascribed
to the high efﬁciency of S-CSCF in handling IMS requests
(see 1/βS value in Table 2), translating in a very scarce
sensitivity in improving its availability when the number
of the corresponding CNF replicas exceeds the value of 2.

Even adding one more replica to P-CSCF and to HSS
w.r.t. ℓ2, the steady-state high availability target is not
reached, and the whole cost jumps to 11 (conﬁguration
ℓ3). Again, such a behavior can be ascribed to the weak-
ness introduced by I-CSCF. This notwithstanding, in case
we preserve a high redundancy degree for I-CSCF with 3
replicas (as occurs for the optimal conﬁguration ℓ∗
), the
availability target remains unsatisfactory if two nodes are
not replicated at all as shown in ℓ4. Thus, guaranteeing a
strong redundancy degree for the I-CSCF it is not enough.

A set of “cheap” conﬁgurations includes ℓ5 - ℓ7, whose
costs range from 5 to 7. They show that when a more
relaxed availability constraint (e.g. “four nines”) has to
be satisﬁed, it might be no necessary to add many CNF
replicas. A limiting case is given by ℓ5, whose availability
value amounts to 0.999919 at a very cheap cost of 5. In
contrast, the “ﬁve nines” requirement is met by ℓ8 which
cannot be the optimal conﬁguration since its cost amounts
to 10 (more expensive than ℓ∗
). Furthermore, conﬁguration

uc(z) = 0.9997 z1

0.0255z2

0.0255 + 2.649 × 10−5 z1

0.0255 z2

0.0255 + 8.773 × 10−11 z1

0.0255 z2

0.0255

+ 1.135 × 10−29 z1
+ 1.061 × 10−44 z1
+ 3.498 × 10−49 z1
+ 2.142 × 10−58 z1

0.0304z2
0.0587z2
0.0450z2
0.0418z2

0.0329 + 4.013 × 10−34 z1
0.0329 + 2.121 × 10−44 z1
0.0589 + 2.867 × 10−74 z1
0.0570 + 1.654 × 10−75 z1

0.0417z2
0.0255z2
0.0416z2
0.0281z2

0.0329 + · · · + . . .
0.0329 + · · · + . . .
0.0589 + · · · + . . .
0.0137 + · · · + . . .

12

(24)

S9

(0,3)

S11

$%"#

!"#

%"’

!!"’

S6

(0,2)

S12

(2,3)

&! "’

(1,3)

!"#

%"’

%"#

&!"’

$!"#

$%"#

(1,2)

$%"’

S8

$!"’

%"’

%"#

(2,2)

$!"#

$!"#

S10

$%"’

$!"’

(2,1)

S7

%"#

&% "’

!"’

$%"’

$!"’

(0,1)

S3

&%"’

!"’

$%"#

!"#

S2

$% "#

S5

(1,1)

!"’

!"#

&%"’

(1,0)

%"#

"!"#

S4

(2,0)

!(

!(

!)

!)

!(

(0,0)

S1

!)

(0,0)
DLF

SD

(0,0)
ILF

SI

!(

!(

!)

!)

%(

%)

Fig. 10. Transition-state diagram of the CNF with two tenants.

ℓ9 is obtained by adding one more replica to S-CSCF w.r.t.
ℓ∗
. In such a case, cost increases by one, but, the steady-
state availability jumps to 0.9999999, a very challenging
value sometimes required by mission-critical services. Inter-
estingly, ℓ9 exhibits a greater availability value than ℓ8, but
at a cheaper cost (amounting to 9). This behavior depends
on the fact that in ℓ8 no redundant CNF is allocated to HSS,
and conﬁrms that the best trade-off between availability
and costs can be obtained through smart allocation of CNF
replicas among the tiers. Finally, conﬁgurations ℓ10 and ℓ11
report two cases of CNF redundancy greater than 3 (for a
tier). Precisely, ℓ10 can be considered as an enhancement of
conﬁguration ℓ1 with 2 more replicas on HSS tier. Likewise,
ℓ11 is derived by ℓ2 adding 2 more CNFs to the HSS. In both
cases, we do not observe any signiﬁcant improvement in the
availability values (both amounting to 0.999968 for ℓ10 and
ℓ11) which are still far from the ﬁve nines availability target.
Even, the costs of ℓ10 and ℓ11 increase by two units with
respect to ℓ1 and ℓ2, respectively. Once again, we can notice
that a wrong redundancy strategy contributes to make the
costs grow but not the availability values.
In (24) we report the MUGF of cIMS system in the optimal
conﬁguration ℓ∗
, where most terms have been suppressed
due to space constraints. The ﬁrst term has a coefﬁcient
equal to 0.9997, which is the steady-state probability for
a state corresponding to a mean CSD equal to 0.0255 s
for both tenants, as indicated by the exponents of z1 and
z2. Moreover, the terms in red refer to states where one
or both mean CSD values do not respect the mean CSD
constraint dmax, namely are greater than 50 ms, and their
coefﬁcient does not contribute to the value of the steady-
state availability of cIMS according to (17).

From a computational complexity perspective, it is use-
ful to highlight that the MUGF approach mitigates by far

the computational load required by monolithic approaches
which attempt to ﬁnd the steady-state probability distri-
bution of a single CTMC describing the whole system
without decomposing it in simpler subsystems. Indeed, as
regards the proposed example with N (m,ℓ) = N = 14,
the state space of a single cIMS CTMC model amounts
to J c = 14Pm∈{P,S,I,H} Lm (by virtue of (15)). In partic-
ular, the optimization problem (22) requires to solve rm
systems of equations whose number ranges from 144 to
J c, being r the maximum redundancy level considered
in the optimization algorithm. For instance, the optimal
conﬁguration ℓ∗ = (2, 1, 3, 2) requires the solution of a
system with 142+1+3+2 = 148 equations. Conversely, our
approach requires three steps: i) we ﬁnd the steady-state
distribution of the CTMC of a single CNF with 14 states
(namely we need to solve a system of 14 equations for each
tier as detailed in Appendix B); ii) we compute the steady-
state distribution of the mean CSD due to tier m, for each m,
and the corresponding MUGF by (18); iii) we combine the
distributions computed in step ii) to obtain the mean CSD
probability distribution of cIMS. Then, we get the steady-
state availability (17). To compute the MUGF corresponding
to the optimal conﬁguration for the cIMS, we need about
360 s on a PC equipped with an Intel Quad-Core Xeon E5
CPU@3.7GHz.

6.3 Limitations

This work presented an availability model for multi-tenant
service chains, tailored to the recent architectural trend to-
wards containerized services. Although our efforts to match
real systems (e.g., non-exponential service times assump-
tions, parameters from real-world experiments, etc.), some
limitations necessarily remain: i) for the sake of simplicity,
in our model we consider CNFs having the same perfor-
mance, but in real architectures, they might slightly differ.
This notwithstanding, this assumption holds for many sys-
tems (including our cIMS case study), where all of the CNFs
have been developed using the same software technology,
have been assigned the same amount of resources (e.g.,
in terms of virtual CPUs), and share the same underlying
layers (Docker and Infrastructure) in a cloud-based deploy-
ment; ii) some parameters (e.g., the failure rates) are derived
from the technical literature rather than from experiments,
due to the large observation scale of failure events (up
to some years). The other parameters are estimated using
well-assessed fault injection techniques; iii) we assume
exponential distributions for failure/repair times: such an
assumption is the most common and accepted across the
technical literature, and in our work, it is necessary to
manage complications arising from the joint availability
and queueing modeling. Moreover, our proposed method
sacriﬁces some high-level expressiveness achieved by other

approaches (e.g., SPN/SRN), in order to beneﬁt from visi-
bility on the underlying analytical model. For example, this
occurs in the eq. (18) where the MUGF expression of the
mean delay distribution pertaining to the tier m is made
explicit in terms of the pair (pη, δη). Beneﬁting from such a
decomposition, the MUGF of the overall chain can be easily
evaluated through a simple product as shown in eq. (19).
Finally, we note that the MUGF method is intended to be
applied “one-shot”, using a ﬁxed set of parameters, reﬂect-
ing the expected workload, mean time to failure, mean time
to repair, etc. This typically reﬂects the SLA-based approach
of service providers, which are called to guarantee speciﬁc
performance levels by ﬁxing some constraints. When such
constraints are violated, the SLA must be renegotiated,
implying that the MUGF method has to be run again in
order to return the best conﬁguration guaranteeing the new
performance level.

7 CONCLUSION
We propose an availability assessment approach to ﬁt
the modern Service Function Chain paradigm adopting: a
Multi-State System model to represent the complex hard-
ware and software stack in Containerized Network Func-
tions; a queueing model, to include latency aspects; an
extended version of multidimensional UGF technique, to
efﬁciently analyze an infrastructure running several CNFs
over multiple tenants, by combining their steady-state prob-
ability distributions through algebraic procedures.

We used an experimental fault-injection testbed to esti-
mate parameters for the model, such as the repair rates of
CNF layers and the service rates of containerized instances.
The proposed approach allowed us to efﬁciently solve the
availability optimization problem within few minutes.

This work might be extended in several directions such
as: i) considering more and different service chains (e.g.
mobile/broadband networks, data center chains) where the
network manager is typically interested at ﬁnding the best
redundant chain conﬁguration at a minimal cost; ii) differ-
entiating (by priority or importance) the requests entering a
chain, so as to deploy a service chain able to satisfy Quality-
of-Service constraints, as well.

REFERENCES

[1] G. Davoli, W. Cerroni, C. Contoli, F. Foresta, F. Callegati, “Im-
plementation of service function chaining control plane through
OpenFlow,” in Proc. IEEE NFV-SDN, 2017, pp.1–4.

[2] M. Gharbaoui, C. Contoli, G. Davoli, G. Cuffaro, B. Martini,
F. Paganelli, W. Cerroni, P. Cappanera, P. Castoldi, “Experimenting
latency-aware and reliable service chaining in Next Generation
Internet testbed facility,” in Proc. IEEE NFV-SDN, 2018, pp.1–4.
[3] D. Borsatti, G. Davoli, W. Cerroni, C. Contoli, F. Callegati, “Per-
formance of Service Function Chaining on the OpenStack Cloud
Platform,” in Proc. IEEE CNSM, 2018, pp.432–437.
IETF, “Service Function Chaining (SFC) Use Cases,” [Online].
https://tools.ietf.org/id/draft-liu-sfc-use-cases-03.html.
IETF, “Service Function Chaining Use Cases in Mobile Net-
works,” [Online]. https://tools.ietf.org/id/draft-haeffner-sfc-use-
case-mobility-00.html.

[4]

[5]

[6] NEC

White

“NEC

Paper,
core

virtualized
[Online].

[8] ETSI, “TS 123-251,” [Online]. https://www.etsi.org/deliver/etsi ts/123200 123299/123251/13.01.00 60/ts 123251v130100p.pdf.
[9] Cziva, R. & Pezaros, D. Container network functions: Bringing

13

NFV to the network edge. IEEE Commun. Mag. . 55, 24-31 (2017)

[10] D. Cotroneo, L. De Simone, and R. Natella, “NFV-Bench: A
Dependability Benchmark for Network Function Virtualization
Systems,” IEEE Trans. Netw. Service Manag., vol. 14, no. 4, pp. 934–
948, 2017.

[11] Docker

Inc.,

Docker

Platform.

[Online]

https://www.docker.com/resources/what-container.

[12] ETSI, “TS 101-563,” [Online]. https://www.etsi.org/deliver/etsi ts/101500 101599/101563/01.03.01 60/ts 101563v010301p.pdf.
[13] A. Elnashar, M.A. El-Saidny, and M. Mahmoud, “Practical Per-
formance Analyses of Circuit-Switched Fallback and Voice Over
LTE,” IEEE Trans. Veh. Technol., vol. 66, no. 2, pp. 1748–1759, 2017.
[14] J. E. Vargas Bautista, S. Sawhney, M. Shukair, I. Singh, V. K. Govin-
daraju, S. Sarkar, “Performance of CS Fallback from LTE to
UMTS,” IEEE Commun. Mag., vol. 51, no. 9, pp. 136–143, 2013.
[15] H. Nemati, A. Singhvi, N. Kara and M. E. Barachi, “Adaptive
SLA-based elasticity management algorithms for a virtualized IP
multimedia subsystem,” in Proc. IEEE Globecom, 2014, pp. 7-11.
[16] K. Al-Begain, A. Ali, Multimedia Services and Applications in Mission

Critical Communication Systems. Hershey (PA), IGI Global, 2017.

[17] M. Di Mauro, M. Longo and F. Postiglione, “Availability Eval-
uation of Multi-tenant Service Function Chaining Infrastructures
by Multidimensional Universal Generating Function,” IEEE Trans.
Services Comput., vol. 14, no. 5, pp. 1320-1332, 2021.
Project,

2018
https://clearwater.readthedocs.io/en/stable/.

[18] Clearwater

[Online].

[19] B. Tola, G. Nencioni, B. E. Helvik, Y. Jiang, “Modeling and Evalu-
ating NFV-Enabled Network Services under Different Availability
Modes,” in Proc. DRCN. IEEE, 2019, pp.1–5.

[20] B. Tola, Y. Jiang, B. E. Helvik, “Failure process characteristics of
cloud-enabled services,” in Proc. IEEE RNDM, 2017, pp.1–7.
[21] B. Tola, G. Nencioni, B. E. Helvik, “Network-Aware Availability
Modeling of an End-to-End NFV-enabled Service,” IEEE Trans.
Netw. Service Manag., vol. 16, no. 4, pp. 1389–1403, 2019.

[22] L. Qu, C. Assi, K. Shaban, M. J. Khabbaz, “A Reliability-Aware
Network Service Chain Provisioning With Delay Guarantees in
NFV-Enabled Enterprise Datacenter Networks,” IEEE Trans. Netw.
Service Manag., vol. 14, no. 3, pp. 554–568, 2017.

[23] S. Sharma, A. Engelmann, A. Jukan, and A. Gumaste, “VNF Avail-
ability and SFC Sizing Model for Service Provider Networks,” in
IEEE Access, vol. 8, pp. 119768–119784, 2020.

[24] M. Wang, B. Cheng, S. Wang, and J. Chen, “Availability- and
Trafﬁc-Aware Placement of Parallelized SFC in Data Center Net-
works,” IEEE Trans. Netw. Service Manag., vol. 18, no. 1, pp. 182-
194, 2021.

[25] A. Alleg, T. Ahmed, M. Mosbah, and R. Boutaba, “Joint Diversity
and Redundancy for Resilient Service Chain Provisioning,” IEEE
J. Sel. Areas Commun., vol. 38, no. 7, pp. 1490-1504, 2020.

[26] S. Yang, F. Li, S. Trajanovski, R. Yahyapour, and X. Fu, “Recent
Advances of Resource Allocation in Network Function Virtualiza-
tion,” in IEEE Transactions on Parallel and Distributed Systems,
vol. 32, no. 2, pp. 295-314, 2021.

[27] R. Kang, F. He, and E. Oki, “Robust Virtual Network Function
Allocation in Service Function Chains with Uncertain Availability
Schedule,” IEEE Trans. Netw. Service Manag., vol. 18, no. 3, pp.2987-
3005, 2021.

[28] S. Yang, F. Li, R. Yahyapour, and X. Fu, “Delay-Sensitive and
Availability-Aware Virtual Network Function Scheduling for
NFV,” IEEE Trans. Services Comput., 2019.

[29] S. G. Kulkarni, G. Liu, K. K. Ramakrishnan, M. Arumaithurai,
T. Wood, and X. Fu, “REINFORCE: Achieving Efﬁcient Failure
Resiliency for Network Function Virtualization-Based Services,”
IEEE/ACM Trans. Netw., vol. 28, no. 2, pp. 695-708, 2020.

[30] S. G. Kulkarni, K. K. Ramakrishnan, and T. Wood, “Managing
State for Failure Resiliency in Network Function Virtualization,”
in Proc. IEEE LANMAN, 2020, pp.1–6.

[31] J. Fan, C. Guan, Y. Zhao, and C. Qiao, “Availability-aware map-
ping of service function chains,” in Proc. IEEE INFOCOM, 2017,
pp. 1–9.

packet

evolved
https://networkbuilders.intel.com/docs/vEPC white paper w.cover ﬁnal.pdf.

[7] Ericsson
vices
https://www.ericsson.com/en/reports-and-papers/ericsson-technology-review/articles/virtualizing-network-services---the-telecom-cloud.

[33] H. A. Alameddine, S. Ayoubi, and C. Assi, “An efﬁcient surviv-
able design with bandwidth guarantees for multi-tenant cloud
networks,” IEEE Trans. Netw. Service Manag., vol. 14, no. 2, pp. 357–
372, 2017.

“Virtualizing
telecom

ser-
[Online].

Review,
the

network

vEPC,”

cloud,”

-

-

[32] J. Kong, I. Kim, X. Wang, Q. Zhang, H. C. Cankaya, W. Xie,
T. Ikeuchi, and J. P. Jue, “Guaranteed-availability network function
virtualization with network protection and VNF replication,” in
Proc. IEEE GLOBECOM, 2017.

[34] S. Sebastio, R. Ghosh, and T. Mukherjee, “An availability analy-
sis approach for deployment conﬁgurations of containers,” IEEE
Trans. Services Comput., vol. PP, no. 99, pp. 1–1, 2018.

[35] D. Bruneo, “A Stochastic Model to Investigate Data Center Perfor-
mance and QoS in IaaS Cloud Computing Systems, ” IEEE Trans.
Parallel Distrib. Syst., vol. 25, no. 3, pp. 560–569, 2014.

[36] E. Sousa, F. Lins, E. Tavares, P. Cunha, and P. Maciel, “A modeling
approach for cloud infrastructure planning considering depend-
ability and cost requirements,” IEEE Trans. Syst., Man, Cybern.,
vol. 45, no. 4, pp. 549–558, 2015.

[37] P. Sun, D. Wu, X. Qiu, L. Luo, and H. Li, “Performance analysis of
cloud service considering reliability,” in Proc. IEEE QRS-C, 2016,
pp. 339–343.

[38] S. Yu, H. Chen, and Y. Xiang, “Maximal Service Proﬁt in MAS-
Based Cloud Computing Considering Service Security,” in Lecture
Notes in Electrical Engineering, vol 355. Springer, 2015.

[39] J. L. Peterson Petri Net Theory and the Modeling of Systems. USA,

Prentice Hall, 1981.

[40] U. Herzog, “Formal Methods for Performance Evaluation,” in

Lecture Notes in Computer Science, vol 2090. Springer, 2001.

[41] K. S. Trivedi, Probability and Statistics with Reliability, Queuing and

Computer Science Applications. John Wiley & Sons, 2016.

[42] K. S. Trivedi, J. K. Muppala, S. P. Woolet, B. R. Haverkort, “Com-
posite performance and dependability analysis,” Performance Eval-
uation, vol. 14, no. 3-4, pp. 197–215, 1992.

[43] K. S. Trivedi, A. Bobbio, “Reliability and Availability Analysis in
Practice,” Handbook of Advanced Performability Engineering. Springer,
Cham, 2021.

[44] M. Guida, M. Longo, F. Postiglione, K. S. Trivedi, and X. Yin,
“Semi-Markov models for performance evaluation of failure-
prone IP multimedia subsystem core networks,” Proc. Inst. Mech.
Eng. O J. Risk Reliab., vol. 3, pp. 290–301, 2013.

[45] H. Shulzrinne, S. Narayanan, J. L. Doyle, “SIPstone - benchmark-

ing SIP server performance”, Tech. Rep., 2002.

[46] S. V. Subramanian, R. Dutta, “Measurements and Analysis of
M/M/1 and M/M/c Queuing Models of the SIP Proxy Server,” in
Proc. IEEE ICCCN, 2009, pp. 1-7.

[47] S. V. Subramanian, R. Dutta, “A study of performance and scal-
ability metrics of a SIP proxy server – a practical approach,” in
Journ. of Comp. System and Science, vol. 77, no. 5, pp. 884–897, 2011.
[48] M. Di Mauro, A. Liotta, “Statistical Assessment of IP Multimedia
Subsystem in a Softwarized Environment: a Queueing Networks
Approach,” IEEE Trans. Netw. Service Manag., vol. 16, no. 4,
pp. 1493–1506, 2019.

[49] C. Shen, H. Schulzrinne, and E. Nahum, “Session Initiation Pro-
tocol (SIP) Server Overload Control: Design and Evaluation,” in
IPTComm 2008. LNCS, vol 5310, pp.149-173, 2008.

[50] T. Eyers, H. Schulzrinne, “Predicting Internet telephone call setup

delay,” in Internet Telephony Workshop, 2000

[51] G. Faraci, G. Schembra, “An Analytical Model to Design and
Manage a Green SDN/NFV CPE Node,” IEEE Trans. Netw. Service
Manag., vol. 12, no. 3, pp. 435–450, 2015.

[52] T. Kimura, “Approximations for multi-server queues: System in-
terpolations,” in Queueing Systems, vol. 17, no. 3, pp. 347–382, 1994.
[53] N. Gans, G. Koole, A. Mandelbaum,“Telephone Call Centers:
Tutorial, Review, and Research Prospects,” in Manufacturing &
Service Operations Management, vol. 5, no. 2, pp. 79–141, 2003.
[54] L. Kleinrock, Queueing systems, vol.2: computer applications. New

York, John Wiley & Sons, 1976.

[55] W. Whitt, Stochastic-Process Limits: An Introduction to Stochastic-
Process Limits and Their Application to Queues. N.Y., Springer, 2001.
[56] W. Whitt,“The queueing network analyzer,” in Bell Syst. Techn. J.,

vol. 62, pp. 2779–2815, 1983.

[57] W. Whitt,“Approximations for the GI/G/m queue,” in Production

and Operations Management, vol. 2, pp. 114–161, 1993.

[58] A. O. Allen, Probability, Statistics, and Queueing Theory. Academic

Press, Inc., San Diego, 2 ed., 1990.

[59] G. Levitin and A. Lisnianski, Multi-state system reliability: assess-

ment, optimization and applications. Singapore, WS, 2003.

[60] G. Levitin, “A Universal Generating Function in the Analysis of
Multi-state Systems,” in: Handbook of Performability Engineer-
ing, Springer London, 2008.

14

[61] I. A. Ushakov, “A universal generating function,” Sov. Journ. of

Comp. System and Science, vol. 24, no. 5, pp. 37–49, 1986.

[62] D. Cotroneo, A.K. Iannillo, R. Natella, and S. Rosiello, “Depend-
ability Assessment of the Android OS through Fault Injection,”
IEEE Trans. Rel., doi=10.1109/TR.2019.2954384, pp. 1–16, 2019.
[63] R. Natella, D. Cotroneo, H. & Madeira, “Assessing dependability
with software fault injection: A survey,” ACM Computing Surveys
(CSUR). 48, 1-55 (2016)

[64] A. Avizienis, J. Laprie, B. Randell,& C. Landwehr, “Basic concepts
and taxonomy of dependable and secure computing,” IEEE Trans.
Dependable Secure Comput.. 1, 11-33 (2004)

[65] M. Torquato and M. Vieira, “An Experimental Study of Software
Aging and Rejuvenation in Dockerd,” in Proc. IEEE EDCC, 2019,
pp.1–6.

[66] R. d. S. Matos, P. R. M. Maciel, F. Machida, D. S. Kim, and
K. S. Trivedi, “Sensitivity analysis of server virtualized system
availability,” IEEE Trans. Rel., vol. 61, no. 4, pp. 994–1006, 2012.
[67] D. A. Patterson, and J. L. Hennessy, Computer Organization and

Design. Morgan Kaufmann, 4th ed., 2011.

[68] M. Kleppmann, Designing Data-Intensive Applications: The Big Ideas
Behind Reliable, Scalable, and Maintainable Systems. O’Reilly Media,
1st ed., 2017.

[69] D. Ford, F. Labelle, F. Popovici, M. Stokely, V. A. Truong, L. Bar-
roso, C. Grimes, S. Quinlan “Availability in globally distributed
storage systems ,” in Proc. Usenix, 2010, pp.61–74.

[70] J. Bai, X. Chang, F. Machida, K. S. Trivedi, and Z. Han, “Analyzing
Software Rejuvenation Techniques in a Virtualized System: Service
Provider and User Views,” IEEE Access, vol. 8, pp. 6448–6459, 2020.
service
End-to-end
[Online].
4G mobile

[71] ITU-T,
for
https://www.itu.int/rec/T-REC-G.1028/en.

quality
networks,”

“G.1028

voice

over

of

:

[72] F. Machida, J. Xiang, K. Tadano, and Y. Maeno, “Aging-related
Bugs in Cloud Computing Software,” in Proc. IEEE ISSRE, 2012,
pp. 287–292.

[73] R. Matos, J. Araujo, V. Alves, and P. Maciel, “Experimental eval-
uation of software aging effects in the Eucalyptus elastic block
storage,” in Proc. IEEE SMC, 2012, pp. 1103–1108.

[74] Clearwater
using
https://github.com/Metaswitch/clearwater-mailing-list-archives/blob/master/2016-October.txt

VM
[Online].

project.
a

memory.

(bono)

(2016)

ibcf

up

lot

of

[75] M. Grottke and K. S. Trivedi, “Fighting bugs: Remove, retry,
replicate, and rejuvenate,” Computer, vol. 40, no. 2, pp. 107–109,
2007.

[76] Gayraud, Richard and Jacques, Olivier and Day, Robert
[Online].

(2019) SIPp HomePage.

and Wright, Charles P..
http://sipp.sourceforge.net/

[77] Willy

Tarreau.
http://www.haproxy.org/

(2019) HAProxy HomePage.

[Online].

[78] K. Kanoun and L. Spainhower, Dependability benchmarking for

computer systems. Wiley Online Library, 2008, vol. 72.

Luigi De Simone (Ph.D.) is a postdoctoral researcher at the University
of Naples Federico II, Italy. His research interests include dependabil-
ity benchmarking, fault injection testing, virtualization reliability and its
application on safety-critical systems.

Mario Di Mauro (Ph.D.) is an assistant professor at the University of
Salerno, Italy. His main ﬁelds of interest include: network performance,
network security and availability characterization, data analysis for novel
telecommunication infrastructures.

Roberto Natella (Ph.D.) is an assistant professor at the University of
Naples Federico II, Italy. His research interests include dependability
benchmarking, software fault injection, software aging and rejuvenation,
and their application in OS and virtualization technologies.

Fabio Postiglione (Ph.D.) is an associate professor of statistics at
the University of Salerno, Italy. His research interests include statisti-
cal characterization of degradation processes, reliability and availability
modeling of complex systems, and Bayesian methods.

(25)

(26)

,

APPENDIX A
We introduce two operators (namely series and parallel structure functions) to formally derive ∆(m)(t) and ∆c(t). For the
sake of simplicity, let us start to deﬁne the parallel structure function:

15

Accordingly, the mean CSD introduced by tier m ∈ {P, S, I, H} is:

ψp : ΩLm → RK ∪ (+∞, . . . , +∞).

∆(m)(t) = ψp
X (m,Lm)(t), X (m,Lm)

X (m,1)(t), X (m,1)
(cid:16)
D

D
(t), X (m,Lm)
I

(t), X (m,1)
I

(t), . . . ,

(t)

=

(cid:17)

∆(m)
1
(cid:16)

(t), ..., ∆(m)

K (t)
(cid:17)

where X (m,Lm)(t) denotes the ΩS-valued failure/repair process of the Software layer, X (m,Lm)
valued failure/repair process of the Docker layer, and X (m,Lm)
Infrastructure layer. Finally, ∆(m)
like in Section 4.2, by replacing γηi with G(m)

(t) denotes the ΩD-
D
(t) denotes the ΩI -valued failure/repair process of the
(t) queue, that can be computed

(t) is the stochastic process describing the M/G/G(m)

(t) in equations from (8) to (10).

(t) =

Lm

I

i

i

ℓ=1 G(m,ℓ)

i

i

It is now useful to recall that, since the call ﬂow traverses the cIMS chain, the overall mean CSD is the sum of mean

CSDs introduced by each single tier.

Accordingly, by introducing Ltot =

P

Thus, the overall mean delay ∆c(t) = (∆c

∆c(t) =

∆(m)(t) = ψs

Xm∈{P,S,I,H}

P

m∈{P,S,I,H} Lm, we deﬁne the series structure function:
ψs : ΩLtot → RK ∪ (+∞, . . . , +∞).
1(t), ..., ∆c
X (P,1)(t), X (P,1)
(cid:16)

K (t)) introduced by the cIMS is given by:
D (t), X (P,1)

(t), . . . , X (P,LP )(t), X (P,LP )

D

I

X (H,1)(t), X (H,1)

D

(t), X (H,1)
I

(t), . . . , X (H,LH )(t), X (H,LH )

D

(27)

(t), X (P,LP )
I

(t), . . . ,

(t), X (H,LH )
I
(t), X (m,Lm)
I

(t)

(t)

(cid:17)
.

(28)

(cid:17)

=

Xm∈{P,S,I,H}

ψp

X (m,1)(t), X (m,1)
(cid:16)

D

(t), X (m,1)
I

(t), . . . , X (m,Lm)(t), X (m,Lm)

D

APPENDIX B
Let p1(t), . . . , p12(t) be the state probabilities corresponding to states S1, . . . , S12, and pI (t) and pD(t) the state probabilities
corresponding to states SI and SD, respectively, as shown in Fig. 10.

According to (6), by assuming one and the same model for each CNF composing the cIMS system, all the state
probabilities at time t can be derived by solving the system of 14 differential equations (29), representative of the 14-
12
i=1 pi(t) + pD(t) + pI(t) = 1, and the assumption that the node is initially
state MSS in Fig. 10, with the constraint
working.

P

16

dpI (t)
dt
dpD(t)
dt
dp1(t)
dt
dp2(t)
dt
dp3(t)
dt
dp4(t)
dt
dp5(t)
dt
dp6(t)
dt
dp7(t)
dt
dp8(t)
dt
dp9(t)
dt
dp10(t)
dt
dp11(t)
dt
dp12(t)
dt

=−µIpI (t) + λI

12
i=1 pi(t) + pD(t)

=−(µD + λI )pD(t) + λD

P

12
i=1 pi(t)

=−(2µC1 + 3µC2 + λD + λI )p1(t) + λC1p2(t) + λC2 p3(t)

P

=2µC1p1(t) − (λC1 + µC1 + 3µC2 + λD + λI )p2(t) + 2λC1 p4(t) + λC2p5(t)

=3µC2p1(t) − (λC2 + 2µC1 + 2µC2 + λD + λI )p3(t) + λC1 p5(t) + 2λC2p6(t)

=µC1p2(t) − (2λC1 + 3µC2 + λD + λI )p4(t) + λC2p7(t)

=3µC2p2(t) + 2µC1p3(t) − (λC1 + λC2 + µC1 + 2µC2 + λD + λI )p5(t) + 2λC1p7(t) + 2λC2 p8(t)

(29)

=2µC2p3(t) − (2λC2 + 2µC1 + µC2 + λD + λI )p6(t) + λC1 p8(t) + 3λC2p9(t)

=3µC2p4(t) + µC1 p5(t) − (2λC1 + λC2 + 2µC2 + λD + λI )p7(t) + 2λC2p10(t)

=2µC2p5(t) + 2µC1p6(t) − (λC1 + 2λC2 + µC1 + µC2 + λD + λI )p8(t) + 2λC1p10(t) + 3λC2p11(t)

=µC2p6(t) − (3λC2 + 2µC1 + λD + λI )p9(t) + λC1p11(t)

=2µC2p7(t) + µC1 p8(t) − (2λC1 + 2λC2 + µC2 + λD + λI )p10(t) + 3λC2p12(t)

=µC2p8(t) + 2µC1p9(t) − (λC1 + 3λC2 + µC1 + λD + λI )p11(t) + 2λC1p12(t)

=µC2p10(t) + µC1p11(t) + µDpD(t) + µI pI(t) − (2λC1 + 3λC2 + λD + λI )p12(t)






The steady-state probability distribution p of the CNF in Fig. 10 can be hence derived by considering the limit for
t → ∞ of the solution of system (29). Alternatively, p can be can be simply determined by nullifying the derivative terms
in system (29), and solving it along with the constraint

12
i=1 pi + pD + pI = 1.

P

