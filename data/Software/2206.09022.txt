2
2
0
2

n
u
J

7
1

]

G
L
.
s
c
[

1
v
2
2
0
9
0
.
6
0
2
2
:
v
i
X
r
a

Designing MacPherson Suspension Architectures
using Bayesian Optimization(cid:63) (cid:63)(cid:63)

Sinnu Susan Thomas1, Jacopo Palandri2, Mohsen Lakehal-ayat2, Punarjay
Chakravarty3, Friedrich Wolf-Monheim2, and Matthew B. Blaschko1

1 ESAT-PSI, KU Leuven, Kasteelpark Arenberg 10, 3001 Leuven, Belgium
sinnu.thomas,matthew.blaschko@kuleuven.be
https://www.esat.kuleuven.be/psi
2 Ford Research & Innovation Center, S¨usterfeldstraße 200, 52072 Aachen, Germany
jpalandr, mlakehal,fwolf5@ford.com
https://www.ford.de/
3 Ford Greenﬁeld Labs, 3251 Hillview Ave, Palo Alto, CA 94304, USA
pchakra5@ford.com
https://www.ford.com/

Abstract. Engineering design is traditionally performed by hand: an
expert makes design proposals based on past experience, and these pro-
posals are then tested for compliance with certain target speciﬁcations.
Testing for compliance is performed ﬁrst by computer simulation using
what is called a discipline model. Such a model can be implemented by a
ﬁnite element analysis, multibody systems approach, etc. Designs pass-
ing this simulation are then considered for physical prototyping. The
overall process may take months, and is a signiﬁcant cost in practice.
We have developed a Bayesian optimization system for partially au-
tomating this process by directly optimizing compliance with the tar-
get speciﬁcation with respect to the design parameters. The proposed
method is a general framework for computing a generalized inverse of
a high-dimensional non-linear function that does not require e.g. gradi-
ent information, which is often unavailable from discipline models. We
furthermore develop a two-tier convergence criterion based on (i) con-
vergence to a solution optimally satisfying all speciﬁed design criteria,
or (ii) convergence to a minimum-norm solution. We demonstrate the
proposed approach on a vehicle chassis design problem motivated by
an industry setting using a state-of-the-art commercial discipline model.
We show that the proposed approach is general, scalable, and eﬃcient,
and that the novel convergence criteria can be implemented straightfor-
wardly based on existing concepts and subroutines in popular Bayesian
optimization software packages.

Keywords: Bayesian Optimization · Suspension Design · ADAMS MSC
Car.

(cid:63) Supported by Ford through the Ford-KU Leuven Alliance.
(cid:63)(cid:63) Copyright ©2019 for this paper by its authors. Use permitted under Creative Com-

mons License Attribution 4.0 International (CC BY 4.0).

 
 
 
 
 
 
2

1

Thomas et al.

Introduction

The handling stability, running quality, and vehicle ride comfort is the criteria
used by the passenger for assessing on-road vehicles. The handling attributes are
determined by the way the forces at the tire contact patch inﬂuence the vehicle
dynamics. The suspension is a complex multi-body system that connects and
transmits the force between the vehicle body and the wheel. The forces can be
due to a driver command such as a steering wheel, gas pedal or brake input, but
also to road surface unevenness, aerodynamic forces, vibrations of the engine
and drive-line, and non-uniformity of the tire/wheel assembly.

The desired behavior of the vehicle can be achieved by optimizing the design
of the front suspension, which comprises a large number of design variables. One
of the most popular suspension systems is the MacPherson strut [14,15], which
is deployed in a large number of vehicles for its simple structure, good overall
performance, package eﬃciency and relatively low cost as shown in Fig.1.

Fig. 1: MacPherson Suspension Design [14,15]

In this work, we develop a Bayesian optimization strategy for determining
parameters of a MacPherson suspension system that optimizes desired perfor-
mance characteristics of an automobile. In contrast to the industry standard of
hand designed parameters, we aim to achieve partial automation of the design
process by employing a multibody dynamics simulation model and allowing the
Bayesian optimization to iteratively explore the design space without human
intervention.

1.1 Applications of Bayesian Optimization

Inverse problems are generally the problem of ﬁnding the properties of the model
using indirect measurements such as ﬁnding an inverse shortest path and inverse
minimum spanning tree problems [28]. Vito et al. [27] formulated the problem
of ﬁnding the best solution as a linear inverse problem given some loss function
and hypothesis space. This problem can also be solved using the regularized least

Designing MacPherson Suspension Architectures

3

squares algorithm. These types of problems are ill-posed problems [30]. They are
often solved using Bayesian approaches. In the proposed approach, the design of
the suspension of the vehicle is framed as the inverse problem and the inverse
problem is solved using Bayesian Optimization.

Bayesian Optimization (BO) creates a surrogate model of the black-box ob-
jective function and ﬁnds the optimum of an unknown objective function from
which samples can be obtained [16,4]. BO has been studied in many ﬁelds for
the optimization of unknown functions. The tuning of the hyper-parameters,
regularization terms, and optimization parameters in machine learning needs a
lot of expert experience, but with the help of the tractable posterior distribution
induced by the Gaussian Processes [23] leads to the eﬃcient use of the informa-
tion gathered from the past experiences, enabling optimal choices for the next
parameters. The performance of the BO is highly dependent on the choice of
acquisition function made to ﬁnd the best-observed value. [18,13] have proposed
convergence criteria for several acquisition functions in order to avoid unwanted
evaluations.

Several methods exist in the literature for designing suspension architectures.
Yu and Yu [31] formulated the problem of optimal vehicle suspension design with
the quarter-car vehicle dynamic model using a genetic algorithm (GA). The two
objectives of the optimization are to minimize the average suspension displace-
ment and to minimize the maximum bouncing acceleration of the sprung mass [3]
restricted to a number of constraints. An objective function is formulated as the
sum of absolute magnitude of sprung mass (chassis) acceleration and absolute
magnitude of average sprung mass displacement. The authors have considered
some constraints in the problem formulation such as the maximum amplitude of
sprung mass acceleration should not be less than 1g (9.8m/s2), human beings
feel motion sickness when vibration at a natural frequency is less than 1Hz, and
the absolute value of the relative displacement between the sprung and unsprung
mass should be less than 13 cm. Zhang et al. [32] proposed the design of suspen-
sion parameters of ﬂexible multibody vehicle model using the ADAMS software
and GA. A ﬂexible multibody model having 44 degrees of freedom is compared
with the multi-rigid bodies having 33 degrees of freedom. ADAMS is a tool used
by the leading manufacturers to design parameters for complex design and op-
timization. ADAMS and GA carries the simulation analysis until the algorithm
converges. Yao et al. [29] modeled a sedan MacPherson front suspension with
ADAMS and studied the relationship between the wheel alignment parameters
and tire wear when wheel hops. Afkar et al. [1] modeled a double wishbone sus-
pension system using ADAMS and then optimized geometric parameters using
a GA. Similarly, the authors in [20] optimized several hard points of the front
suspension using the INSIGHT module of ADAMS to optimize toe and camber
angle characteristics. Dye and Lankarani [7] used a neural network to ﬁt tire
test data under varying tire pressures and steady state conditions. Hurel et al.
[9] developed a non-linear two-dimensional mathematical quarter-car model of
MacPherson suspension. This model considered both the vertical motion of the
chassis and the rotation and translation for the unsprung mass (wheel assem-

4

Thomas et al.

bly). Zhang et al. [33] studied the geometric relationship between the structural
parameter of the double wishbone front suspension and alignment parameters of
the steering wheel. Liu et al. [10] studied the hardpoints of the double wishbone
suspension of a Formula SAE car using correlation theory. Tao et al. [25] used a
Gaussian process modeling method to design vehicle suspension parameters us-
ing a multi-disciplinary optimization architecture, and experiments were carried
out for a front MacPherson suspension and a rear strut suspension system on a
Altair Motion View vehicle model. The Gaussian process models are ﬁtted with
multidisciplinary optimization and eﬃciencies are computed.

In automobile manufacturing, whether ride and handling characteristics have
been achieved is quantiﬁed through statistics of a kinematic curve. The design
process can be time intensive as an engineer has to manually input a particular
set of hard-points, pass it through the simulation tool (which can take several
minutes to process), observe the kinematic curves, and then repeat the whole
process to reﬁne the design. Thus, generating one design that meets the desired
kinematic constraints in current standard practice can take multiple weeks and
consume signiﬁcant manpower.

The main novel contributions of this paper are as follows:

– Bayesian optimization is applied to the design of the front suspension of a

vehicle.

– Finding the geometric locations of the hardpoints of the suspension from the
desired target characteristics is formulated as a generalized-inverse problem.
– We develop novel convergence criteria in the context of the generalized-

inverse problem.

– We verify the validity of the approach in several suspension design settings,

empirically validating the predicted convergence characteristics.

2 Suspension Design using Bayesian Optimization

2.1 Bayesian Optimization

BO is a derivative free optimization approach for global optimization of an ex-
pensive black-box function f . It is a class of sequential-model based optimization
algorithms that uses past evaluations of the function to ﬁnd the next point to
sample. For a minimization problem,

y∗ = arg min
y∈Y

f (y),

(1)

if f is expensive, then there is a strong need to reduce the number of evaluations.
Since the objective function is unknown, according to Bayesian theory the func-
tion is treated as random and a prior belief is placed over the function values, and
as more values are observed, the posterior is updated based on the observation
likelihood. These models use diﬀerent types of acquisition functions to determine
the next point to be evaluated based on the current posterior distribution over
functions.

Designing MacPherson Suspension Architectures

5

The surrogate model used for this optimization is a Gaussian Processes (GP).
). For n
A GP is characterized by its mean µ(y), and co-variance function k(y, y
data points, the function f1;n = f (y1), . . . , f (yn) can be characterized using
a multivariate Gaussian distribution as

(cid:48)

f1:n = N (µ (y1:n), K),

where K is a n × n kernel matrix given by






K =

k(y1, y1) . . . k(y1, yn)
. . .
k(yn, y1) . . . k(yn, yn)

...

...

(2)

(3)




 ,

for some positive deﬁnite kernel such as a Gaussian or Matern kernel [21].

An acquisition function proposes which points should be selected next to
determine the minimizer of the function, and they trade oﬀ between exploita-
tion and exploration. Exploitation means the acquisition function selects points
where the mean of the GP is low and exploration means the acquisition function
selects points where the variance of the GP is high. Various acquisition functions
are used for Bayesian models, including maximum probability of improvement
(MPI), expected improvement (EI), conﬁdence bounds (CB) criteria.

Maximum Probability of Improvement evaluates f (y) at the point most likely

to improve than the minimal value of f (y+) observed so far [4]

M P I(y) = P (f (y) ≥ f (y+) + ξ),
(cid:18) µ(y) − f (y+) − ξ
σ(y)

= Φ

(cid:19)

,

(4)

where f (y+) is the best observed value of the function so far, µ(y) is the posterior
mean of y under the GP, σ(y) is the posterior standard deviation, and ξ is
a parameter used to drive exploration, which is usually very small. Φ is the
cumulative distribution function of a standard normal variable.

Expected Improvement evaluates f (y) at the point where the expectation of
the improvement in f (y+) under the current estimate of the GP is the highest
[22]

EI(y) = E [max{0 , f (y+) − f (y)}],

= (−µ(y) + f (y+) + ξ) Φ

(cid:18) −µ(y) + f (y+) + ξ
σ(y)

(cid:19)

+

σ(y) φ

(cid:18) −µ(y) + f (y+) + ξ
σ(y)

(cid:19)

,

(5)

where φ is the probability density function of a standard normal variable.

The basic algorithm of Bayesian Optimization [19] is given in Algorithm 1.

6

Thomas et al.

Algorithm 1 Bayesian Optimization

Initial Design:

Dninit = {(yi, xi)}ninit
i=1 ,
nmax function evaluation

Results:

Estimated min:fmin = min(x1, . . . , xnmax ).
Estimated minimum point:

ymin = argmin(x1, . . . , xnmax ).

(6)

for n = ninit to nmax do

Update GP: f (y)|Dn ∼ GP ( ˆf (y), K(y, y
Optimize acquisition function:

(cid:48)

)),

ynext = argmax

αn(y).

y∈Y

Find f at ynext to obtain xnext.
Add data to previous design: Dn+1 = Dn ∪ {ynext, xnext}.

end for

2.2 Generalized Inverse Problems using Bayesian Optimization

Automotive engineers use mechanical discipline models to design the suspension
of the vehicle, which is computationally expensive and may involve a design
cycle spanning several days or weeks. Operating characteristics of the vehicle
suspension components depend upon the suspension architecture, selection of
components and the locations at which the components are attached to each
other and the vehicle body. The suspension geometry includes the arrangement
of suspension components and the location of hard-points, which are locations at
which suspension components are attached to the vehicle’s body. For a given set
of vehicle suspension components, the suspension geometry will determine the
kinematic characteristics of the vehicle suspension which includes wheel attitude
and suspension travel. Kinematic characteristics are traditionally derived from
a multi-body dynamic modeling/simulation of an entire suspension system sub-
jected to spindle input loads such as may be performed by commercially available
multi-body dynamic (MBD) software. Given a set of hard-point locations and
corresponding kinematic curves we learn the relationship between the hard-point
locations and kinematic curves using BO. This work predicts a set of kinematic
curves corresponding to hard-points for MacPherson strut suspension. Predict-
ing the kinematic curves corresponding to hard-points can reduce the amount
of time required to select hard-points for a MacPherson strut suspension design
process from multiple weeks to less than one day.

Statistics of kinematic curves of the vehicle form our representation of the
desired vehicle characteristics. We denote the set of possible statistics as X where
X ⊆ Rd. This paper addresses the design of suspension hardpoints Y where

Designing MacPherson Suspension Architectures

7

Y ⊂ Rm is a bounded domain for a given target x ∈ X . It is a well deﬁned task
for the engineers to design target characteristics X from the suspension design
parameters Y. Consider the equation

x = g(y).

(7)

We formulated this problem as an inverse problem for g : Y → X , ﬁnd a value
y such that g(y) ≈ x.

In general the above problem is ill-posed: there may be multiple y satisfying
g(y) = x for a given x or none. The existence of the solution can be restored by
solving for the minimum norm solution

g†(x) := arg min
y∈Y

(cid:107)g(y) − x(cid:107)2
,
(cid:125)
(cid:123)(cid:122)
(cid:124)
=:f (y)

(8)

where g† deﬁnes a generalized inverse of g [2]. We optimize the desired suspen-
sion design parameters using Bayesian Optimization (BO) where g is set to be
computed by the multi-body dynamic software MSC ADAMS [17], and Bayesian
optimization is used to minimize f with respect to y.

2.3 Convergence criteria

It is well known that Bayesian optimization converges under fairly general condi-
tions to a global optimizer over a bounded domain [18,4,5]. That the algorithm
will converge towards an optimum indicates that, when the requested design
characteristics x are feasible, i.e.

arg min
y∈Y

(cid:107)g(y) − x(cid:107)2 = 0,

we may simply specify a convergence criterion that terminates when

(cid:107)g(y+) − x(cid:107)2 < ε,

(9)

(10)

for some prespeciﬁed tolerance ε > 0. However, it may not be the case that
the requested design characteristics x lie in the image of Y under g. Consider
the example where passenger comfort and acceleration must simultaneously be
unrealistically high: such constraints can contradict each other. In such a case it
may be that for a given tolerance,

arg min
y∈Y

(cid:107)g(y) − x(cid:107)2 > ε,

(11)

and the optimization will never terminate. We therefore develop an additional
termination criterion in the sequel.

Bayesian optimization is typically presented without termination criteria, or
with the assumption that there is a ﬁxed budget of optimization iterations [8].
However, two main optimization dependent termination strategies have been
proposed: (i) thresholding the acquisition function [18,13], and (ii) terminating

8

Thomas et al.

when two sequential parameter vectors diﬀer by a small amount [12]. We con-
sider here the strategy of thresholding the acquisition function, as this has been
analyzed from the perspective of regret minimization, which implies a bound on
the convergence rate of the optimization [18,24].

Theorem 1 ([21], Sec. 2.9). Let σn(f (y)) denote the predictive variance of a
Gaussian process regression model at y given a dataset of size n. The predictive
variance of using a dataset of only the ﬁrst n − 1 training points is denoted
σn−1(f (y)):

σn(f (y)) ≤ σn−1(f (y)).

(12)

Furthermore, for a covariance function that is strictly positive deﬁnite (i.e. the
rank of the covariance matrix is equal to its size), the variance will be strictly
decreasing over a bounded domain Y.

It is well known that Bayesian optimization with expected improvement will
converge to an optimum [5, Theorem 2]. This leads us to the following proposi-
tion:

Proposition 1 (Termination of Expected Improvement). The following
convergence criterion applied to Algorithm 1 will terminate:

max
y∈Y

EI(y) ≤ ε,

for a ﬁxed ε > 0.

Proof. From [5, Theorem 2], we have that

f (y+) − arg min
y∈Y

f (y),

is in expectation decreasing in the number of iterations, meaning that

− µ((y)) + f (y+) + ξ,

(13)

(14)

(15)

is decreasing. Furthermore, inspecting the formula for EI(y), we see that Φ and
φ are bounded. From Theorem 1, we have that σ(y) is decreasing, and the result
(cid:117)(cid:116)
follows.

When the maximum expected improvement is small, by deﬁnition, we believe
under the posterior GP model that the solution will not improve by a large
amount when observing a new point, and we are close to a minimum norm
solution. Furthermore, due to the quantiﬁcation of uncertainty in the Gaussian
process model, we may set a threshold on the acquisition function such that this
second termination criterion becomes active when it is highly probable that no
solution with near-zero norm exists.

Designing MacPherson Suspension Architectures

9

3 Case Studies

We implemented the inverse problem of ﬁnding the suspension design using BO
[26] in Python 3.7.3. The LBGFS algorithm with multiple restarts was used for
optimizing the acquisition function. All the experiments were conducted on a
workstation with two Intel Xeon CPUs and 64G memory. MSC ADAMS 18.1
was used as the discipline model, and takes several minutes per call. The problem
becomes

y∗ = argmin

(cid:107)ADAM S(y) − x(cid:107)2,

(16)

y∈Y

for a desired set of vehicle characteristics x. We optimize the positions of Inner
Tie Rod Ball and Outer Tie Rod Ball of the MacPherson front suspension archi-
tecture. We compare the convergence of Bayesian optimization using acquisition
function EI to that of the commercial HEEDS Sherpa optimization software,
which is commonly used in automotive design [6,11].

A classic suspension design problem is the tuning of the bump and roll steer
performance, which is strictly related to the placement of the tie rod. Bump
steer is a measure of the suspension toe angle with respect to suspension vertical
travel and is measured in deg/m. In roll steer the wheel travel is generated by
applying a roll angle to the vehicle body. Tie rod connects the steering to the
steering knuckle on each front wheel. A tie rod is made of two components: inner
and outer tie rod ends. This problem is relevant as the toe attitude of the wheel
is a function of its vertical motion and is related to crucial vehicle attributes
such as vehicle stability, cornering performance, and steering feel. Indeed, since
the position of the outer tie rod deﬁnes the lever arm to the kingpin axis, the
outer tie rod location determines how the forces are transmitted from the contact
patch through the suspension and ultimately to the driver operating the steering
wheel.

3.1 Optimization of one hardpoint

We optimized the position of Outer Tie Rod Ball as the ﬁrst case study. This
hardpoint has large eﬀect on the performance of the bump steer and roll steer.
We show the result of two targets such as bump steer and roll steer from the
entire set of target characteristics. We achieved the convergence criterion of

(cid:107)ADAM S(y) − x(cid:107)2 ≤ 0.001

(17)

in 210 iterations. The proposed design of a single hardpoint outperforms the
design of the HEEDS software (Fig. 7). The acquisition function converges as
shown in Fig. 2, and the norm per iteration is shown in Figs. 4-6. We have also
compared to a numerical gradient based optimization method using the MAT-
LAB fmincon function (Fig. 5). Fig. 7 shows that the BO approach converges
more quickly than the competing techniques.

Figs. 8(a)-8(c), show the points in the design space explored using HEEDS,
fmincon, and Bayesian optimization. The axes of the scatter plots are normalized
in the range [0, 1] with respect to the input domain of the hardpoints.

10

Thomas et al.

Fig. 9 show the convergence of the optimized target characteristics towards
the desired bump steer using HEEDS, fmincon, and Bayesian optimization. The
optimized targets are normalized such that the target performance is labeled as
zero and is shown with a red line. All three methods converge to similar targets,
but fmincon converges with a non-zero error.

3.2 Optimization of two hardpoints

The complexity in the design increases with the increase in the number of hard-
points to be optimized. We optimized the position of Inner Tie Rod Ball and
Outer Tie Rod Ball in the second case-study. The norm as a function of the
iteration number for HEEDS, fmincon, and BO is shown in Figs. 10, 11, and 12,
respectively. The convergence in the BO based approach is faster compared to
HEEDS, as shown in Fig. 13. The normalized scatter plots for each of the hard-
points is shown in Figs. 14 and 15. Fig. 16 shows the convergence to the target
bump steer for all three methods.

4 Conclusion

The performance of automotive design in terms of ride comfort and vehicle
dynamics has a direct impact on passenger experience and customer satisfaction.
The suspension system is an important automotive system that carries the entire
load of the vehicle and also responsible for a smooth ride. This paper primarily
focuses on designing the geometry of the MacPherson front suspension system
to satisfy desired kinematic performance metrics using the MSC ADAMS Car
model. Bayesian optimization is used to optimize the coordinate values of hard-
points of the front suspension. Conventionally, optimization of suspension design
has been done using HEEDS software in the automobile industry. Our results
demonstrate that the proposed approach is able to optimize the parts of the
suspension eﬃciently to enhance the comfort ride. The results of some case
studies were described to highlight the performance of some commonly used
algorithms with the proposed approach. It performs slightly better than the close
source licensed HEEDS software commonly used in the automotive industry, and
substantially better than optimization with a ﬁnite diﬀerence approximation
to the gradient. Furthermore, we have two convergence criteria, based on the
norm or on the acquisition function, which in contrast to HEEDS, allows us to
determine when global convergence criteria are satisﬁed.

Designing MacPherson Suspension Architectures

11

Fig. 2: Acquisition Function for 1 HP. Fig. 3: Acquisition Function for 2 HP.

Fig. 4: Convergence (HEEDS) 1HP.

Fig. 5: Convergence (fmincon) 1HP

Fig. 6: Convergence (BO) 1HP.

Fig. 7: Comparison of diﬀerent conver-
gence plots in 1HP case.

Fig. 8: Scatter plots for Outer Tie Rod Ball in 1HP case (a) HEEDS. (b)nonlinear
programming solver. (c) proposed approach.

12

Thomas et al.

Fig. 9: Performance of Bumpsteer in 1HP case (a) HEEDS. (b) nonlinear pro-
gramming solver. (c) proposed approach.

Fig. 10: Convergence (HEEDS) 2HP.

Fig. 11: Convergence (fmincon) 2HP.

Fig. 12: Convergence (BO) 2HP.

Fig. 13: Comparison of diﬀerent conver-
gence plots in 2HP case.

Designing MacPherson Suspension Architectures

13

Fig. 14: Scatter plots
HEEDS. (b)nonlinear programming solver. (c) proposed approach.

Inner Tie Rod Ball

for

in 2HP case

Fig. 15: Scatter plots
HEEDS. (b)nonlinear programming solver. (c) proposed approach.

for Outer Tie Rod Ball

in 2HP case

(a)

(a)

Fig. 16: Performance of Bumpsteer in 2HP case (a) HEEDS. (b) nonlinear pro-
gramming solver. (c) proposed approach.

14

Thomas et al.

References

1. Afkar, A., Mahmoodi-Kaleibar, M., Paykani, A.: Geometry Optimization of Double
Wishbone Suspension System via Genetic Algorithm for Handling Improvement.
Journal of Vibroengineering 14(2) (June 2012)

2. Ben-Israel, A., Greville, T.N.E.: Generalized Inverses: Theory and Applications.

CMS Books in Mathematics, Springer (2006)

3. Blundell, M., Harty, D.: The Multibody Systems Approach to Vehicle Dynamics.

Butterworth-Heinemann (2014)

4. Brochu, E., Cora, V.M., De Freitas, N.: A Tutorial on Bayesian Optimization of
Expensive Cost Functions, With Application to Active User Modeling and Hierar-
chical Reinforcement Learning. arXiv preprint arXiv:1012.2599 (2010)

5. Bull, A.D.: Convergence Rates of Eﬃcient Global Optimization Algorithms. Jour-

nal of Machine Learning Research 12, 2879–2904 (2011)

6. Chase, N., Sidhu, R., Averill, R.: A New Method for Eﬃcient Global Optimization
of Large Systems using Sub-models: HEEDS COMPOSE Demonstrated on a Crash
Optimization Problem. In: LS-DYNA user forum (2012)

7. Dye, J., Lankarani, H.: Hybrid Simulation of a Dynamic Multibody Vehicle Sus-
pension using Neural Network Modeling Fit of Tire Data. In: Proc. ASME 42th
International Design Engineering Technical Conferences and Computers and In-
formation in Engineering Conference, North Carolina. pp. 1–4 (August 2016)
8. Frazier, P.I.: A Tutorial on Bayesian Optimization. CoRR abs/1807.02811 (2018)
9. Hurel, J., Mandow, A., Garc´ıa-Cerezo, A.: Nonlinear Two-Dimensional Modeling
of a MacPherson Suspension for Kinematics and Dynamics Simulation. In: Proc.
IEEE 12th International Workshop on Advanced Motion Control, Bosnia. pp. 1 –6
(March 2012)

10. Liu, X., Luo, J., Wang, Y., Guo, H., Wang, X.: Analysis for Suspension Hardpoint
of Formula SAE Car Based on Correlation Theory. Research Journal of Applied
Sciences, Engineering and Technology 6(24), 4569–4574 (12 2013)

11. Locci, C., Matas, E., Oberhumer, K.: Acoustic Optimization of a Muﬄer through

the Sherpa Algorithm. Tech. rep., SAE Technical Paper (2019)

12. Lorenz, R., Monti, R.P., Violante, I.R., Faisal, A.A., Anagnostopoulos, C.,
Leech, R., Montana, G.: Stopping Criteria for Boosting Automatic Experimen-
tal Design using Real-time fMRI with Bayesian Optimization. arXiv preprint
arXiv:1511.07827 (2015)

13. Ma, X., Rannen Triki, A., Berman, M., Sagonas, C., Cali, J., Blaschko, M.B.: A
Bayesian Optimization Framework for Neural Network Compression. In: Proceed-
ings of the International Conference on Computer Vision (ICCV) (2019)

14. Macpherson, E.S.: Vehicle Wheel Suspension System (1953), US Patent 2,624,592
15. Macpherson, E.S.: Wheel Suspension for Motor Vehicles (1953), US Patent

2,660,449

16. Mockus, J.: On Bayesian Methods for Seeking the Extremum. In: Proc. IFIP Tech-

nical Conference. pp. 400–404. Springer-Verlag (1974)

17. MSC Software: ADAMS: Multibody Dynamics Simulation Software. https://www.

mscsoftware.com/product/adams (2014)

18. Nguyen, V., Gupta, S., Rana, S., Li, C., Venkatesh, S.: Regret for Expected Im-
provement over the Best-Observed Value and Stopping Condition. In: Proc. 9th
Asian Conference on Machine Learning. vol. 77, pp. 279–294 (Nov 2017)

19. No`e, U., Husmeier, D.: On a New Improvement-Based Acquisition Function for

Bayesian Optimization. arXiv preprint arXiv:1808.06918 (2018)

Designing MacPherson Suspension Architectures

15

20. Qian, L., Shi, Q.: Optimization of Wheel Positioning Parameters of Automotive
Front Suspension Based on ADAMS. In: Proc. International Conference on Infor-
mation Computing and Applications. pp. 821–827. Springer (September 2012)
21. Rasmussen, C.E., Williams, C.K.I.: Gaussian Processes for Machine Learning. MIT

Press (2005)

22. Singh, P.: Bayesian Optimization for Machine Learning. Tech. rep., San Diego

State University (2018)

23. Snoek, J., Larochelle, H., Adams, R.P.: Practical Bayesian Optimization of Ma-
chine Learning Algorithms. In: Advances in Neural Information Processing Sys-
tems. pp. 2951–2959 (2012)

24. Srinivas, N., Krause, A., Kakade, S., Seeger, M.: Gaussian Process Optimization
in the Bandit Setting: No Regret and Experimental Design. In: Proceedings of the
27th International Conference on International Conference on Machine Learning.
pp. 1015–1022 (2010)

25. Tao, S., Shintani, K., Bostanabad, R., Chan, Y.C., Yang, G., Meingast, H., Chen,
W.: Enhanced Gaussian Process Metamodeling and Collaborative Optimization
for Vehicle Suspension Design Optimization. In: Proc. ASME 43rd International
Design Engineering Technical Conferences and Computers and Information in En-
gineering Conference, Ohio. pp. 1–12 (August 2017)

26. The GPyOpt authors: GPyOpt: A Bayesian Optimization Framework in Python.

http://github.com/SheﬃeldML/GPyOpt (2016)

27. Vito, E.D., Rosasco, L., Caponnetto, A., Giovannini, U.D., Odone, F.: Learning
from Examples as an Inverse Problem. Journal of Machine Learning Research
6(May), 883–904 (2005)

28. Yang, C., Zhang, J.: Two General Methods for Inverse Optimization Problems.

Applied Mathematics Letters 12(2), 69–72 (1999)

29. Yao, X.J., Xu, C.Y., Ma, T.Q., Zhang, X.T.: MacPherson Suspension Simulation
Analysis Method Based on ADAMS. In: Materials, Mechanical Engineering and
Manufacture. Applied Mechanics and Materials, vol. 268, pp. 860–865. Trans Tech
Publications (3 2013)

30. Ye, N., Roosta-Khorasani, F., Cui, T.: Optimization Methods for Inverse Problems,

pp. 121–140. Springer International Publishing (2019)

31. Yu, H., Yu, N.: Application of Genetic Algorithms to Vehicle Suspension Design.

Tech. rep., The Pennsylvania State University, University park (2003)

32. Zhang, J., Sun, Y., Gao, R.: Optimal Design of Suspension Parameters of Flexi-
ble Multibody Vehicle Model Based on ADAMS Software and Improved Genetic
Algorithms. In: Proc. ASME 8th Biennial Conference on Engineering Proceedings
Systems Design and Analysis, Italy. pp. 1–6 (July 2006)

33. Zhang, J., Pei, J., Zhang, J.: The Optimization Study of the Front Suspension
Structure Parameters for the Mine Truck Based on ADAMS/CAR. In: Proc. In-
ternational Conference on Vehicle, Mechanical and Electrical Engineering. pp. 1–9
(July 2016)

