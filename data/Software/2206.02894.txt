2
2
0
2

n
u
J

6

]

R
C
.
s
c
[

1
v
4
9
8
2
0
.
6
0
2
2
:
v
i
X
r
a

ğ´ğ‘†ğ´ğ‘ƒ: Reconciling Asynchronous Real-Time Operations and
Proofs of Execution in Simple Embedded Systems

Adam Caulfield
Rochester Institute of Technology

Norrathep Rattanavipanon
Prince Songkla University

Ivan De Oliveira Nunes
Rochester Institute of Technology

ABSTRACT
Embedded devices are increasingly ubiquitous and their importance
is hard to overestimate. While they often support safety-critical
functions (e.g., in medical devices and sensor-alarm combinations),
they are usually implemented under strict cost/energy budgets,
using low-end microcontroller units (MCUs) that lack sophisticated
security mechanisms. Motivated by this issue, recent work devel-
oped architectures capable of generating Proofs of Execution (PoX)
for the correct/expected software in potentially compromised low-
end MCUs. In practice, this capability can be leveraged to provide
â€œintegrity from birthâ€ to sensor data, by binding the sensed result-
s/outputs to an unforgeable cryptographic proof of execution of
the expected sensing process. Despite this significant progress, cur-
rent PoX schemes for low-end MCUs ignore the real-time needs of
many applications. In particular, security of current PoX schemes
precludes any interrupts during the execution being proved. We
argue that lack of asynchronous capabilities (i.e., interrupts within
PoX) can obscure PoX usefulness, as several applications require
processing real-time and asynchronous events. To bridge this gap,
we propose, implement, and evaluate an Architecture for Secure
Asynchronous Processing in PoX (ğ´ğ‘†ğ´ğ‘ƒ). ğ´ğ‘†ğ´ğ‘ƒ is secure under full
software compromise, enables asynchronous PoX, and incurs less
hardware overhead than prior work.

1 INTRODUCTION
Embedded (aka IoT or â€œsmartâ€) devices are increasingly popular
worldwide and are becoming pervasive in all sorts of environments:
from homes and offices to public spaces and industrial facilities.
Not surprisingly, they are also increasingly targeted by exploits and
malware. In particular, low-end micro-controller units (MCUs) are
designed with strict cost, size, and energy limitations. Thus, it is
hard to offer any concrete security guarantees for tasks performed
by these MCUs, due to their lack of sophisticated security features,
akin to those available to higher-end application processors, such
as the ones used in smartphones or general-purpose controllers,
e.g., Alexa or Nest. As these low-end MCUs become ubiquitous
(especially in safety-critical settings), exploits that corrupt their in-
tegrity, e.g., to forge a sensed value or â€œlieâ€ about having performed
some expected actuation, become a significant threat.

Over the past decade, this problem was recognized and explored
by the research community [25]. Previous results considered poten-
tial unauthorized software modifications/compromises in low-end
devices and proposed methods to remotely verify the binary cur-
rently installed in a low-end MCU: a well known security service
referred to as Remote Attestation (RA) [4, 10, 17, 23]. While RA
can prove that a remote low-end MCU is currently installed with
the proper software binary, it does not provide any proofs about
the correct execution of this binary (or parts thereof, i.e., functions

within the binary). Therefore, recent work has focused on enhanc-
ing RA architectures with the ability to prove the correct execution
of the attested software [11], i.e., to generate Proofs of eXecution
(PoX). The PoX capability, in turn, was shown to be a fundamental
building block to provide additional guarantees, such as control- &
data-flow attestation [12, 14]. We discuss both RA and PoX in more
detail in Section 2.

In addition, PoX can be used as a means to create sensors and
actuators that â€œcan not lieâ€ even under the assumption that the MCU
software implementing the sensing task may be compromised [11].
This is because PoX enables generation of unforgeable proofs for
the proper execution of software tasks, including their interaction
with analog peripherals via General Purpose Input/Output (GPIO)
interfaces. As these proofs also bind the execution to any generated
outputs (e.g., sensed values), they serve as a cryptographic proof for
the integrity of the sensing process as a whole, including peripheral
configuration, acquisition, and processing of the raw data.

Despite these advances, thus far PoX has assumed that executa-
bles must run atomically and therefore do not process interrupts.
As a consequence, tasks that require handling asynchronous inputs
and events (e.g., the arrival of network packets or expiring timers),
cannot benefit from PoX. On the other hand, most real embedded
applications depend on interrupts to process asynchronous events
due to real-time needs. Therefore, we pose a natural question:

Are secure proofs of execution attainable for executables that
must process asynchronous and real-time events/inputs?

In this paper we set out to answer this question by designing
ğ´ğ‘†ğ´ğ‘ƒ: an Architecture for Secure Asynchronous Processing in PoX .
At a high level, the proposed design introduces two new features
to an existing PoX architecture (APEX [11]), namely Ephemeral
Immutability and Integrity for (1) the interrupt vector table (IVT);
and (2) interrupt service routines (ISRs). These features are achieved
through the selective linking of relevant ISR binaries into specific
protected (and attested) memory locations; attestation of IVT; and
minimal (formally verified) additional hardware support. As we
discuss in the remainder of this paper, these features are sufficient to
enable secure PoX that can also handle asynchronous events/inputs
through the use of MCU interrupts. Our evaluation shows that
ğ´ğ‘†ğ´ğ‘ƒ reduces the hardware overhead of existing PoX and incurs
no additional run-time or storage/memory overhead.

2 PRELIMINARIES
2.1 Scope of Low-End MCUs
This paper focuses on tiny CPS/IoT sensors and actuators, or hy-
brids thereof. These are some of the smallest and weakest devices
based on low-power single-core MCUs with small program and
data memory (e.g., Atmel AVR ATMega, TI MSP430), with 8- and

 
 
 
 
 
 
16-bit CPUs running at 1-16MHz, with â‰ˆ 64 KBytes of address-
able memory. SRAM is used as data memory, normally ranging
between 4 and 16KBytes, while the rest of the address space is
available for program memory. Such devices usually run software
atop â€œbare metalâ€, execute instructions in place (physically from
program memory), and lack memory management units (MMU) or
privilege levels to support virtual memory or secure micro-kernels.

2.2 Remote Attestation (RA)
RA allows a trusted verifier (Vrf) to detect unauthorized binary
modifications (e.g., malware infections) on an untrusted remote
device, called a prover (Prv) by remotely measuring the latterâ€™s
software state. Per Fig. 1, RA is typically realized as a challenge-
response protocol with the following steps:
1)- Vrf sends an attestation request containing a challenge (Chal)
to Prv. This request might also contain a token derived from a
secret that allows Prv to authenticate Vrf.
2)- Prv receives the attestation request and computes an authenti-
cated integrity check over a predefined memory region (e.g., program
memory) and Chal.
3)- Prv returns the result to Vrf.
4)- Vrf receives the result from Prv, and checks whether it corre-
sponds to a valid memory state.

Verifier (Vrf)

Prover (Prv)

(1) Request

(3) Response

(2) Authenticated
Integrity Check
(e.g., MAC)

(4) Verify
Response

Figure 1: RA interaction

The authenticated integrity check is usually realized as a Message
Authentication Code (MAC) or a digital signature over Prv memory.
However, these cryptographic primitives require Prv to have a
unique secret key (K) either shared with Vrf (MAC-s), or for which
Vrf knows the public key (signatures). This K must reside in secure
storage, and not be accessible to any (potentially compromised)
software running on Prv, except for trusted attestation code itself.
Since most RA threat models assume a fully compromised software
state on Prv, secure storage implies some level of hardware support.
RA architectures fall into three categories depending on the level
of hardware support: software-based, hardware-based, and hybrid.
Security of software-based attestation [22, 29â€“31] relies on strong
assumptions about precise timing and constant communication
delays, which are unrealistic in the IoT/CPS ecosystem. Hardware-
based methods [24, 27, 28] rely on dedicated hardware components,
e.g., TPMs [33], Intel SGX [19], or ARM TrustZone [3]. However,
the cost of such hardware is prohibitive for low-end MCU-s. Hybrid
RA [4, 10, 17] aims to achieve security equivalent to hardware-
based mechanisms, with low(er) hardware cost. It implements the
authenticated integrity ensuring function in software, while re-
lying on minimal hardware support to assure that this software
implementation executes properly and securely.

2.3 Proofs of Execution (PoX)
PoX augments RAâ€™s capability by proving to Vrf that: (1) the ex-
pected executable is stored in program memory, (2) this code has

2

indeed executed, and (3) any claimed outputs were produced by its
timely and authentic execution.

The first PoX architecture targeting low-end MCU-s was recently
proposed in APEX [11]. APEX implements a hardware module con-
trolling the value of a 1-bit flag called ğ¸ğ‘‹ ğ¸ğ¶, which cannot be
written by any software. A value ğ¸ğ‘‹ ğ¸ğ¶ = 1 indicates to Vrf that
attested code must have executed successfully, between the time
when the challenge Chal was received from Vrf (recall the RA
protocol from Section 2.2) and the time when the RA measurement
occurs (via authenticated integrity ensuring function). Similarly,
when it receives an attestation reply with ğ¸ğ‘‹ ğ¸ğ¶ = 0, Vrf can con-
clude that execution of said code did not occur, or that execution (or
its output) was tampered with. In APEX, the RA measurement cov-
ers: (i) the ğ¸ğ‘‹ ğ¸ğ¶ flag; (ii) the region where this executionâ€™s output
is saved (output region â€“ ğ‘‚ğ‘…); and (iii) the executable itself (stored
in the executable region â€“ ğ¸ğ‘…). Thus, security of the underlying RA
architecture guarantees that the contents of these memory regions
cannot be forged/spoofed to something different from their values
at the time of the attestation computation. In turn, APEX considers
a code to execute properly (and sets ğ¸ğ‘‹ ğ¸ğ¶ = 1) if and only if:
1)- Execution is atomic and uninterrupted, from the first instruc-
tion (legal entry ğ¸ğ‘…ğ‘€ğ¼ ğ‘ ), to the last instruction (legal exit ğ¸ğ‘…ğ‘€ğ´ğ‘‹ );
2)- Neither the executable (ğ¸ğ‘…), nor its outputs ğ‘‚ğ‘… are modified in
between the execution and subsequent RA computation;
3)- During execution, data-memory (including ğ‘‚ğ‘…) is not modified,
by other means except for the ER execution, e.g., no modifications
by other software or Direct Memory Access controllers.

From these conditions, ğ¸ğ‘‹ ğ¸ğ¶ = 1 assures that memory contents
(of ğ¸ğ‘… and ğ‘‚ğ‘…) are consistent between ğ¸ğ‘…â€™s code execution and
subsequent RA. It also assures that ğ¸ğ‘…â€™s execution has integrity, e.g.,
it can not be corrupted by malicious interruptions that could alter its
control-flow or its variables in data memory. ğ¸ğ‘… and ğ‘‚ğ‘… locations
and sizes are configurable, allowing for PoX of arbitrary code and
output sizes. APEX implementation builds atop the formally verified
hybrid RA architecture VRASED [10] and APEX hardware module
is itself formally verified to adhere to a set of specifications. The
conjunction of these properties are proven sufficient to imply a
security notion (stated using a cryptographic security game [21])
for unforgeable proofs of execution. For brevity, we do not overview
APEX proofs and refer the interested reader to [11].

As explained above, APEX mandates the absence of interrupts
to guarantee that no untrusted interrupt sources and respective
(potentially malicious) ISRs can interfere with the intended behavior
of the executable (located in ğ¸ğ‘…). However, this also limits the types
of executable behaviors for which PoX is possible. In particular,
it prevents provable executions from leveraging any interrupts.
In this work, we remedy this issue by enabling selected trusted
ISRs, implementing intended asynchronous behavior, to be a part
of provable executions without compromising PoX security.

3 APPLICATION EXAMPLES
Consider that Prv is a simple MCU implementing a syringe pump
that allows remote physicians to monitor and deliver medication to
patients over a network, e.g., as described in [20]. Given the safety-
critical and real-time nature of this application, it is paramount to
verify that the execution of operations in Prv happens as expected,
e.g., that Prv injects an accurate and timely dosage to the patient;

otherwise, it may lead to under/overdose, affecting the patientâ€™s
well-being. Such an execution can be implemented as follows:
(1)- Start injecting medication at a fixed rate;
(2)- Set up a timer interrupt according to the dosage to be injected;
(3)- Enter sleep/low-power mode;
(4)- Wake up once the timer expires and stop the injection.

To verify the correct execution of these steps, one may choose
to implement Prv using an MCU equipped with a PoX architecture
such as APEX (see Section 2). However, doing so poses a challenge
since this execution strictly depends on an asynchronous event (i.e.,
the expiring timer in step (4)), which in turn relies on a timer-based
interrupt during execution. Unfortunately, to ensure the integrity
of execution, APEX prohibits interrupts during the execution of
the software being proved. Therefore, it can not be used directly to
provide security/safety guarantees in this example.

To enable APEX PoX for this application, one simple workaround
is to modify Prv software as follows: instead of going to sleep and
waking up based on the timer interrupt, the device uses the CPU
to countdown, i.e., it busy-waits for the expected period.

Doing so eliminates the need for a timer interrupt during exe-
cution and thus allows this application to benefit from APEX PoX.
Nonetheless, this workaround has important drawbacks. First, it
imposes an unnecessary power consumption by requiring the pro-
cessor to actively wait and check for the critical event. This is a
significant burden for battery-powered devices (e.g., portable in-
sulin pumps). Aside from the power consumption issue, in case of
an emergency, the patient may choose to abort Prv execution, e.g.,
by pressing a physical â€œcancelâ€ button or by sending a network
command to â€œabortâ€. However, since the CPU is fully occupied and
no interrupts are allowed during execution, Prv software has no
way to detect/receive and process such asynchronous safety-critical
command(s). This illustrates why these approaches do not satisfy
this applicationâ€™s safety-critical and real-time requirements.

On the other hand, simply removing the PoX atomicity require-
ment from APEX opens the door for vulnerabilities. For example,
after infecting Prv, malware may trigger an interrupt while the
medication is being injected to increase the timer expiration value
or, more generally, tamper with this execution by manipulating
stored variables/parameters/data or its control-flow.

Aside from this example, it is not hard to find similar settings
where the same real-time needs are applicable (e.g., industrial, au-
tomotive, etc). This general need motivates our work on the design
of a secure PoX architecture that supports interrupts and thus can
process asynchronous events/inputs.

4 ğ´ğ‘†ğ´ğ‘ƒ DESIGN
MCUs process asynchronous events by either (1) busy-waiting, i.e.,
actively checking in software; or (2) via hardware interrupts. As
discussed in Section 3, (1) is, in many cases, not a viable approach.
To prevent abuse from software external to ğ¸ğ‘…, APEX treats any
interrupt as a violation. It sets ğ¸ğ‘‹ ğ¸ğ¶ = 0 whenever the respective
hardware signal (namely ğ‘–ğ‘Ÿğ‘) is set, indicating an incoming inter-
rupt during ğ¸ğ‘…â€™s execution. We design ğ´ğ‘†ğ´ğ‘ƒ to improve PoX with
the ability to:
(1)- define which interrupts (and respective ISRs) are allowed and
trusted as a part of ğ¸ğ‘… behavior.

Figure 2: ğ´ğ‘†ğ´ğ‘ƒ System Architecture
(2)- assure that the integrity of these allowed/trusted ISR(s) can be
checked by Vrf as a part of the PoX result.
(3)- guarantee that no other untrusted/unauthorized interrupt can
occur during (or tamper with) ğ¸ğ‘… execution without Vrf detection.
Fig. 2 presents ğ´ğ‘†ğ´ğ‘ƒ architecture at a high level. ğ´ğ‘†ğ´ğ‘ƒ mandates
that ISR binaries that are a part of ğ¸ğ‘… behavior be placed (linked)
within the ğ¸ğ‘… memory region. As in Fig. 2, after compilation &
linking, ğ¸ğ‘… is composed of both the main program and all ISRs
relevant to ğ¸ğ‘… execution.

With that, instead of checking for the value of the ğ‘–ğ‘Ÿğ‘ to deter-
mine whether or not â€œsome interrupt has happenedâ€, ğ´ğ‘†ğ´ğ‘ƒ can
check the program counter (ğ‘ƒğ¶) value. If a trusted/authorized inter-
rupt occurs, by construction ğ‘ƒğ¶ will remain inside ğ¸ğ‘… and ğ´ğ‘†ğ´ğ‘ƒ
will keep ğ¸ğ‘‹ ğ¸ğ¶ = 1 (valid PoX). If an untrusted/unauthorized in-
terrupt occurs, ğ‘ƒğ¶ must leave ğ¸ğ‘…. ğ´ğ‘†ğ´ğ‘ƒ will treat the latter as a
violation and set ğ¸ğ‘‹ ğ¸ğ¶ = 0. As the size of ğ¸ğ‘… is configurable (by
setting the values of parameters ğ¸ğ‘…ğ‘€ğ¼ ğ‘ and ğ¸ğ‘…ğ‘€ğ´ğ‘‹ ), ğ¸ğ‘… size can
be adjusted to fit the binaries of the main program + intended ISRs.
Furthermore, when an interrupt is triggered, the MCU fetches
the address of an ISR from the IVT based on the hardware trigger
source (e.g, GPIO, network/UART, timer, etc). Therefore, as a part
of PoX, it is paramount to ensure that the contents of IVT (i.e., the
addresses of functions that get called due to each type of interrupt)
are also attested and that the content of IVT remains consistent
from the time when ğ¸ğ‘… execution happens until when it is measured
by the subsequent attestation (recall the interplay between PoX and
RA discussed in Section 2).

4.1 Adversary Model
We consider an adversary that controls Prv entire software state, in-
cluding code and data. It can modify any writable memory and read
any memory that is not explicitly protected by hardware-enforced
access controls. Modifications to program memory can change in-
structions to modify the executable behavior whereas modifications
to data memory can corrupt intermediate computation results or
induce deviation from a programâ€™s intended control-flow. Finally,
the adversary can attempt to change memory to program arbitrary
interrupts before, during, or after a PoX.

4.2 ğ´ğ‘†ğ´ğ‘ƒ Details
To enable processing of selected interrupts as a part of the PoX,
ğ´ğ‘†ğ´ğ‘ƒ modifies APEX atomicity requirements. We here go over

3

these requirements, as well as ğ´ğ‘†ğ´ğ‘ƒ modifications in detail. APEX
verified properties are specified in Linear Temporal Logic (LTL),
which is particularly useful for specifying and verifying sequen-
tial systems. LTL extends common logic statements with temporal
quantifiers. In addition to propositional connectives, such as con-
junction (âˆ§), disjunction (âˆ¨), negation (Â¬), and implication (â†’), LTL
includes temporal quantifiers, thus enabling sequential reasoning.
In this paper, we consider the following two LTL quantifiers:
â€¢ Xğœ™ â€“ neXt ğœ™: holds if ğœ™ is true at the next system state.
â€¢ Gğœ™ â€“ Globally ğœ™: holds if for all future states ğœ™ is true.

Atomicity and Uninterruptibility of ğ¸ğ‘… execution, as required

by APEX, are formalized in LTL statements 1, 2, and 3, per [11].

G : { (ğ‘ƒğ¶ âˆˆ ğ¸ğ‘…) âˆ§ Â¬(X(ğ‘ƒğ¶) âˆˆ ğ¸ğ‘…) â†’ ğ‘ƒğ¶ = ğ¸ğ‘…ğ‘€ğ´ğ‘‹ âˆ¨ Â¬X(ğ¸ğ‘‹ ğ¸ğ¶) }

G : {Â¬(ğ‘ƒğ¶ âˆˆ ğ¸ğ‘…) âˆ§ (X(ğ‘ƒğ¶) âˆˆ ğ¸ğ‘…) â†’ X(ğ‘ƒğ¶) = ğ¸ğ‘…ğ‘€ğ¼ ğ‘ âˆ¨ Â¬X(ğ¸ğ‘‹ ğ¸ğ¶) }

G : { (ğ‘ƒğ¶ âˆˆ ğ¸ğ‘…) âˆ§ ğ‘–ğ‘Ÿğ‘ â†’ Â¬ğ¸ğ‘‹ ğ¸ğ¶ }

(1)

(2)

(3)

The G quantifier, surrounding all statements, requires them to
hold at all times. LTL 1 enforces that the only way for ğ¸ğ‘… exe-
cution to terminate without setting ğ¸ğ‘‹ ğ¸ğ¶ = 0 is through its last
instruction: ğ‘ƒğ¶ = ğ¸ğ‘…ğ‘€ğ´ğ‘‹ . This is specified by checking the rela-
tion between current and next ğ‘ƒğ¶ values. If the current ğ‘ƒğ¶ value is
within ğ¸ğ‘… and next ğ‘ƒğ¶ value is outside ğ¸ğ‘…, then either current ğ‘ƒğ¶
value is the address of ğ¸ğ‘…ğ‘€ğ´ğ‘‹ , or ğ¸ğ‘‹ ğ¸ğ¶ is set to 0 in the next cycle.
Similarly, LTL 2 uses X quantifier to enforce that the only way for
ğ‘ƒğ¶ to enter ğ¸ğ‘… is through the very first instruction: ğ¸ğ‘…ğ‘€ğ¼ ğ‘ . This
prevents ğ¸ğ‘… execution from starting at some point in the middle of
ğ¸ğ‘…, thus ensuring that ğ¸ğ‘… always executes in its entirety. Finally,
LTL 3 enforces that ğ¸ğ‘‹ ğ¸ğ¶ is set to zero if an interrupt happens
during ğ¸ğ‘… execution, by checking the ğ‘–ğ‘Ÿğ‘ signal. To enable selected
interrupts to be triggered securely, ğ´ğ‘†ğ´ğ‘ƒ removes LTL 3 and adds
two new requirements [AP1] and [AP2].

[AP1]: IVT Immutability & Integrity - the memory region
containing the IVT cannot be modified from the start of ğ¸ğ‘… exe-
cution until the end of attestation. This property ensures that the
attestation result correctly portrays the addresses of all ISR(s) that
could have been called and processed during ğ¸ğ‘… execution. Without
this property, an adversary could modify IVT to cause an interrupt
to jump to arbitrary locations within ğ¸ğ‘… leading to violations to ğ¸ğ‘…
intended control-flow (and therefore ğ¸ğ‘… execution integrity). This
new ğ´ğ‘†ğ´ğ‘ƒ property is formally specified in LTL 4, based on signals
that indicate a memory write to IVT by either the CPU or DMA.

G : { [ğ·ğ‘€ğ´ğ‘’ğ‘› âˆ§ (ğ·ğ‘€ğ´ğ‘ğ‘‘ğ‘‘ğ‘Ÿ âˆˆ ğ¼ğ‘‰ğ‘‡ ) ]âˆ¨
[ğ‘Šğ‘’ğ‘› âˆ§ (ğ·ğ‘ğ‘‘ğ‘‘ğ‘Ÿ âˆˆ ğ¼ğ‘‰ğ‘‡ ) ] â†’ Â¬ğ¸ğ‘‹ ğ¸ğ¶ }

(4)

In LTL 4, ğ‘Šğ‘’ğ‘› is a CPU signal that indicates that a CPU memory
write is happening to the address in the ğ·ğ‘ğ‘‘ğ‘‘ğ‘Ÿ signal. ğ·ğ‘€ğ´ğ‘’ğ‘› and
ğ·ğ‘€ğ´ğ‘ğ‘‘ğ‘‘ğ‘Ÿ serve the same purpose for detecting writes by DMA to
specific locations. ğ¸ğ‘‹ ğ¸ğ¶ is set to 0 whenever there is a CPU write
or DMA access to IVT.

Fig. 3 depicts a Verilog FSM implemented and verified to comply
with LTL 4 ([AP1]). The FSM has two states: ğ‘…ğ‘¢ğ‘› and ğ‘ğ‘œğ‘¡ğ¸ğ‘¥ğ‘’ğ‘.
The FSM transitions to the ğ‘ğ‘œğ‘¡ğ¸ğ‘¥ğ‘’ğ‘ state and outputs ğ¸ğ‘‹ ğ¸ğ¶ = 0
whenever a violation happens, i.e., whenever ğ¼ğ‘‰ğ‘‡ is modified. It
transitions back to ğ‘…ğ‘¢ğ‘› when ğ¸ğ‘…â€™s execution is restarted (ğ‘ƒğ¶ =
ğ¸ğ‘…ğ‘€ğ¼ ğ‘ ).

4

ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’

ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’

ğ‘…ğ‘¢ğ‘›

ğ‘ƒğ¶ = ğ¸ğ‘…ğ‘€ğ¼ ğ‘ âˆ§
Â¬[ğ‘Šğ‘’ğ‘› âˆ§ (ğ·ğ‘ğ‘‘ğ‘‘ğ‘Ÿ âˆˆ ğ¼ğ‘‰ğ‘‡ ) ]âˆ§
Â¬[ğ·ğ‘€ğ´ğ‘’ğ‘› âˆ§ (ğ·ğ‘€ğ´ğ‘ğ‘‘ğ‘‘ğ‘Ÿ âˆˆ ğ¼ğ‘‰ğ‘‡ ) ]

[ğ‘Šğ‘’ğ‘› âˆ§ (ğ·ğ‘ğ‘‘ğ‘‘ğ‘Ÿ âˆˆ ğ¼ğ‘‰ğ‘‡ ) ]âˆ¨
[ğ·ğ‘€ğ´ğ‘’ğ‘› âˆ§ (ğ·ğ‘€ğ´ğ‘ğ‘‘ğ‘‘ğ‘Ÿ âˆˆ ğ¼ğ‘‰ğ‘‡ ) ]

ğ‘ğ‘œğ‘¡ğ¸ğ‘¥ğ‘’ğ‘

Figure 3: Verified FSM for LTL 4 for IVT Immutability.

[AP2]: ISR Immutability - trusted/authorized ISR binaries can-
not be modified between the start of ğ¸ğ‘… execution until attestation
is completed. This is required to ensure that the attestation result
correctly reflects the behavior implemented by the ISRs as a part
of ğ¸ğ‘…. Without this property, the adversary could overwrite an
authorized ISR arbitrarily, modifying its behavior without detection
by Vrf. Since APEX already enforces ğ¸ğ‘… immutability between exe-
cution and attestation, ğ´ğ‘†ğ´ğ‘ƒ reuses this support by simply placing
(linking) the trusted ISR binaries to be within ğ¸ğ‘….

ASAP Security Argument: Let ğ¸ğ‘… contain a program composed
of a main task and its trusted ISR(s) which can be asynchronously
executed due to their respective interrupt triggers. Once execution
starts (ğ‘ƒğ¶ = ğ¸ğ‘…ğ‘€ğ¼ ğ‘ ), APEX ensures that the PoX result will reflect
ğ¸ğ‘‹ ğ¸ğ¶ = 1 iff: (1) ğ¸ğ‘… is not modified until both its execution and
subsequent attestation are over; (2) no external execution: ğ‘ƒğ¶ stays
within ğ¸ğ‘… until it reaches ğ¸ğ‘…ğ‘€ğ´ğ‘‹ (LTL 1); and (3) ğ‘‚ğ‘… is not modified
in between execution and attestation completion. Per [AP1], IVT
is also immutable after ğ¸ğ‘… execution starts (otherwise ğ´ğ‘†ğ´ğ‘ƒ sets
ğ¸ğ‘‹ ğ¸ğ¶ = 0) and is attested. Hence, the PoX result includes a report
detailing which code section is executed due to each interrupt source
in the system (i.e., the IVT configuration). Finally, due to [AP2], ISRs
relevant to ğ¸ğ‘… execution are all contained within ğ¸ğ‘…, making them
immutable and attested. Therefore, the PoX result allows Vrf to check
that all IVT entries that point to an address within ğ¸ğ‘… correspond to
the entry point of an intended/expected ISR binary. Additionally, any
execution of an unauthorized/untrusted ISR requires jumping outside
ğ¸ğ‘…, which sets ğ¸ğ‘‹ ğ¸ğ¶ = 0 (per LTL 1), resulting in an invalid PoX.

5 IMPLEMENTATION & EVALUATION
We implemented ğ´ğ‘†ğ´ğ‘ƒ on OpenMSP430: an open-source design
for the MSP430 architecture, which represents the targeted class
of devices discussed in Section 2.1. ğ´ğ‘†ğ´ğ‘ƒ builds on top of APEX,
which in turn relies on VRASED RA architecture. As shown in
Fig. 2, ğ´ğ‘†ğ´ğ‘ƒ is implemented within the module labeled HW-Mod. Its
features are attained by small hardware modifications. ğ´ğ‘†ğ´ğ‘ƒ is
publicly available at [1].

To achieve [AP1] IVT Immutability, the hardware is extended
with the module shown in Fig. 3, used to detect any writes to IVT. In
OpenMSP430, IVT is stored in a fixed physical location, i.e., in the
last 32-byte of addressable memory: from the base address 0xFFE0
to last address 0xFFFF.

To selectively link trusted ISRs, as required by [AP2] ISR Im-
mutability, we implement ğ¸ğ‘… linking as in Fig. 4. In it, a sample
â€œdummy functionâ€ executes a loop, and one ISR is implemented to
write to GPIO PORT5 when any asynchronous signal is received
from GPIO PORT1 (e.g., a button press). The header of these func-
tions assigns them with the section label â€œexec.bodyâ€. This label in

(a) Linker Example

(b) Software Example

Figure 4: Software and Linking to achieve ISR immutability

(a) Authorized interrupt in ASAP

(b) Unauthorized interrupt in ASAP

(c) Any interrupt in APEX
Figure 5: Comparison: interrupt handling in ğ´ğ‘†ğ´ğ‘ƒ vs. APEX

conjunction with a modified linker script for MSP430 allows for
these functions to be placed inside ğ¸ğ‘… region. Labels â€œexec.startâ€ and
â€œexec.leaveâ€ are used to determine ğ¸ğ‘… entry point (ğ¸ğ‘…ğ‘€ğ¼ ğ‘ ) and exit
point (ğ¸ğ‘…ğ‘€ğ´ğ‘‹ ). In this example, these functions are named startER()
and exitER(). startER() simply calls â€œdummy functionâ€ (i.e., the pro-
gramâ€™s behavior) and exitER() simply returns, i.e., concludes the
provable execution. These functions have section labels â€œexec.startâ€
and â€œexec.leaveâ€ so that they can be identified and placed at the
beginning and end of ğ¸ğ‘… by the linker script shown in Fig. 4(a).

With this design in place, experiments were conducted to demon-
strate the differences between APEX and ğ´ğ‘†ğ´ğ‘ƒ when processing
interrupts during ğ¸ğ‘… execution. Fig. 5 shows simulation wave-forms
for three cases including APEX and ğ´ğ‘†ğ´ğ‘ƒ. In each figure, the fol-
lowing signals are depicted over time: ğ¸ğ‘…ğ‘€ğ¼ ğ‘ , ğ¸ğ‘…ğ‘€ğ´ğ‘‹ , ğ¸ğ‘‹ ğ¸ğ¶, ğ‘–ğ‘Ÿğ‘
(interrupt request signal), and ğ‘ƒğ¶.

Fig. 5(a) shows the behavior of ğ´ğ‘†ğ´ğ‘ƒ in the instance that a legiti-
mate and authorized interrupt occurs (i.e., its corresponding ISR lies
within ER) while executing ER. As shown, ğ¸ğ‘… is currently executing,
as the ğ‘ƒğ¶ value is between ğ¸ğ‘…ğ‘€ğ¼ ğ‘ and ğ¸ğ‘…ğ‘€ğ´ğ‘‹ . As the signal ğ‘–ğ‘Ÿğ‘
is set, indicating an interrupt, ğ‘ƒğ¶ jumps from the main program at
0ğ‘¥ğ¸1ğ´ğ¶ to the ISR first instruction at 0ğ‘¥ğ¸1ğµ0. Since the destination
is still within the range of the ğ¸ğ‘…, the ğ¸ğ‘‹ ğ¸ğ¶ signal is unaffected and

5

(a) Total extra Look-Up Tables (LUTs)

(b) Total extra registers

Figure 6: Overhead comparison between APEX and ğ´ğ‘†ğ´ğ‘ƒ

remains 1. As a result, a subsequent attestation would convey to
Vrf that execution was successful and untampered with. Fig. 5(b)
shows the behavior of ğ´ğ‘†ğ´ğ‘ƒ under the influence of an external
interrupt that has not been authorized to be a part of ğ¸ğ‘… behavior
and therefore not linked within ğ¸ğ‘…. In this scenario, initially ğ‘ƒğ¶ is
also within ğ¸ğ‘…. However, once the external interrupt is handled, ğ‘ƒğ¶
jumps to the ISR located outside of ğ¸ğ‘… (at 0ğ‘¥ğ¸0ğ·6). In accordance
with LTLs 1 and 2, ğ¸ğ‘‹ ğ¸ğ¶ is set to 0. In APEX, shown in Fig. 5(c),
any ğ‘–ğ‘Ÿğ‘ causes ğ¸ğ‘‹ ğ¸ğ¶ = 0, regardless of the ğ‘ƒğ¶ value or whether or
not the ISR is located within ğ¸ğ‘… and a part of the executable behav-
ior. This illustrates ğ´ğ‘†ğ´ğ‘ƒ ability to separate trusted and untrusted
interrupts and handle trusted interrupts while keeping PoX secure
against untrusted ones.

To demonstrate ğ´ğ‘†ğ´ğ‘ƒ practicality, we synthesized and imple-
mented its RTL design on an Artix-7 FPGA (Basys3 prototyping
board). We note that a hardware design that is synthesizable on
FPGA can also be used to manufacture an Application-Specific-
Integrated-Circuit (ASIC) for large-scale usage. Below we report
on ğ´ğ‘†ğ´ğ‘ƒ costs based on this prototype.

Hardware and Memory Overhead. To evaluate ğ´ğ‘†ğ´ğ‘ƒ hard-
ware overhead, we compare it to APEX in Fig. 6. Similar to related
work [10, 11, 13, 15, 16], we consider the hardware overhead in
terms of additional Look-up Tables (LUTs) and registers. The in-
crease in LUTs is an estimate of the additional chip cost and size
required for combinatorial logic, while the number of extra reg-
isters indicates additional states required by the sequential logic
in ğ´ğ‘†ğ´ğ‘ƒ FSMs. Fig. 6 shows that ğ´ğ‘†ğ´ğ‘ƒ utilizes 24 less LUTs and 3
less registers than APEX. As [AP2] reuses existent ğ¸ğ‘… protection
to ensure immutability of ISRs, it incurs no additional hardware
overhead. Additionally, APEX requires monitoring the ğ‘–ğ‘Ÿğ‘ signal,
which is propagated into several sub-modules to enforce LTL 3.
Because this is no longer required in ğ´ğ‘†ğ´ğ‘ƒ, there is a reduction in
the register and LUT utilization, despite the need for an additional
2-state FSM to enforce [AP1].

Runtime Overhead. Neither ğ´ğ‘†ğ´ğ‘ƒ nor APEX incur additional
execution time for the tasks being proved, as no instrumentation
or additional instructions are required. This is because relevant
runtime security properties and control of the ğ¸ğ‘‹ ğ¸ğ¶ flag are im-
plemented by hardware that runs in parallel with the CPU (as in
Fig. 2). Linking in [AP2] is static and done at compilation time.

Verification Cost. We verified ğ´ğ‘†ğ´ğ‘ƒ on a 64-bit Ubuntu 18.04
machine with an Intel i7 3.6GHz CPU using NuSMV [8] model-
checker to show it adheres to the new property and still maintains
all other guarantees required by APEX. ğ´ğ‘†ğ´ğ‘ƒ verification takes
â‰ˆ150s for a total of 21 LTL properties and requires 96MB of RAM.

additional verified hardware support, on top of that already pro-
vided by APEX. Our experimental results show ğ´ğ‘†ğ´ğ‘ƒ feasibility
and affordability, even on some of the lowest-end MCUs.

REFERENCES
[1] â€œASAP source code,â€ https://github.com/RIT-CHAOS-SEC/ASAP.
[2] T. Abera et al., â€œC-flat: Control-flow attestation for embedded systems software,â€

in ACM CCS, 2016.

[3] Arm Ltd., â€œArm TrustZone,â€ 2018. [Online]. Available: https://www.arm.com/

products/security-on-arm/trustzone

[4] F. Brasser et al., â€œTytan: Tiny trust anchor for tiny devices,â€ in DAC. ACM, 2015.
[5] X. Carpent et al., â€œERASMUS: Efficient remote attestation via self-measurement

for unattended settings,â€ in DATE, 2018.

[6] â€”â€”, â€œReconciling remote attestation and safety-critical operation on simple iot

devices,â€ in DAC, 2018.

[7] â€”â€”, â€œRemote attestation of iot devices via SMARM: Shuffled measurements

against roving malware,â€ in IEEE HOST, 2018.

[8] A. Cimatti et al., â€œNusmv 2: An opensource tool for symbolic model checking,â€ in

CAV, 2002.

[9] V. Costan et al., â€œSanctum: Minimal hardware extensions for strong software

isolation,â€ in {USENIX} Security, 2016.

[10] I. De Oliveira Nunes et al., â€œVRASED: A verified hardware/software co-design

for remote attestation,â€ USENIX Security, 2019.

[11] â€”â€”, â€œAPEX: A verified architecture for proofs of execution on remote devices

under full software compromise,â€ in USENIX Security, 2020.

[12] â€”â€”, â€œDialed: Data integrity attestation for low-end embedded devices,â€ DAC,

2021.

[13] â€”â€”, â€œOn the toctou problem in remote attestation,â€ in ACM CCS, 2021.
[14] â€”â€”, â€œTiny-cfa: A minimalistic approach for control flow attestation using verified

proofs of execution.â€ in DATE, 2021.

[15] G. Dessouky et al., â€œLo-fat: Low-overhead control flow attestation in hardware,â€

in DAC, 2017.

[16] â€”â€”, â€œLitehax: Lightweight hardware-assisted attestation of program execution,â€

in ICCAD, 2018.

[17] K. Eldefrawy et al., â€œSmart: Secure and minimal architecture for (establishing

dynamic) root of trust,â€ in NDSS, 2012.

[18] A. Ibrahim et al., â€œSeED: secure non-interactive attestation for embedded devices,â€

in ACM WiSec, 2017.

[19] Intel, â€œIntel Software Guard Extensions (Intel SGX).â€ [Online]. Available:

https://software.intel.com/en-us/sgx

[20] M. R. Islam et al., â€œDesign and implementation of low cost smart syringe pump

for telemedicine and healthcare,â€ in ICREST, 2019.

[21] J. Katz and Y. Lindell, Introduction to modern cryptography. CRC press, 2014.
[22] R. Kennell et al., â€œEstablishing the genuinity of remote computer systems,â€ in

USENIX Security, 2003.

[23] P. Koeberl et al., â€œTrustLite: A security architecture for tiny embedded devices,â€

in EuroSys, 2014.

[24] X. Kovah et al., â€œNew results for timing-based attestation,â€ in IEEE S&P â€™12, 2012.
[25] B. Kuang et al., â€œA survey of remote attestation in internet of things: Attacks,

countermeasures, and prospects,â€ Computers & Security, 2022.

[26] J. McCune et al., â€œFlicker: An execution infrastructure for tcb minimization,â€ in

EuroSys, 2008.

[27] J. Petroni et al., â€œCopilot â€” A coprocessor-based kernel runtime integrity monitor,â€

in USENIX Security, 2004.

[28] D. Schellekens et al., â€œRemote attestation on legacy operating systems with

trusted platform modules,â€ Science of Comp. Programming, 2008.

[29] A. Seshadri et al., â€œSWATT: Software-based attestation for embedded devices,â€ in

IEEE S&P â€™04, 2004.

[30] â€”â€”, â€œPioneer: verifying code integrity and enforcing untampered code execution

on legacy systems,â€ in ACM SOSP, 2005.

[31] â€”â€”, â€œSAKE: software attestation for key establishment in sensor networks,â€ in

DCOSS, 2008.

[32] Z. Sun et al., â€œOat: Attesting operation integrity of embedded devices,â€ in IEEE

S&P, 2020.

[33] TCG, â€œTrusted platform module (tpm),â€ 2017. [Online]. Available: http:
//www.trustedcomputinggroup.org/work-groups/trusted-platform-module/

ğ´ğ‘†ğ´ğ‘ƒ verified implementation totals 2155 lines in the Verilog HDL.

6 RELATED WORK
RA & Interrupts. One important security property of RA (see Sec-
tion 2) is temporal consistency, i.e., guaranteeing that an RA result
always reflects an instantaneous snapshot of Prv attested memory.
Lack thereof allows malware to escape detection by copying and/or
erasing itself during RA. Temporal consistency is usually achieved
by enforcing atomic (uninterruptible) RA execution. However, since
RA is often used in safety-critical and/or real-time settings [6], the
atomicity requirement might interfere with the MCU applications.
To address this issue, SMARM [7] allows RA to be interruptible by
using probabilistic malware detection. Meanwhile, ERASMUS [5]
and SeED [18] are based on periodic self-measurements in order
to detect transient malware that infects Prv and leaves before the
next RA instance. RATA [13] actively monitors writes to program
memory to detect such attacks. We note that these efforts should
not be confused with interruptable PoX. RA by itself does not pro-
vide any runtime guarantees (see Section 2) but rather serves as a
building block for more expressive proofs such as PoX.

Proof of Execution (PoX). Prior work has focused on pro-
viding PoX in high-end devices. Flicker [26] leverages TPM and
hardware extensions to implement a PoX functionality on Intel
and AMD computers. Sanctum [9] implements PoX in Intel-SGX-
like devices by instrumenting enclaved code to output information
about its own execution to a remote Vrf. Both of these approaches
rely on complex hardware that is unavailable in low-end embedded
systems. Thus far, APEX [11] is the only PoX architecture designed
for simple MCUs. However, in order to successfully produce an
unforgeable proof, APEX requires execution to run without inter-
ruptions, precluding its usefulness on interrupt-based applications.
Control-Flow & Data-Flow Attestation (CFA/DFA). The goal
of CFA [2, 15] is to measure the exact control flow path taken during
execution on Prv. The result of this measurement can convey to
Vrf the order in which instructions of some specific binary have
executed on Prv. DFA [16, 32] augments CFA with the ability to
detect data-only attacks. Recent work [12, 14], built on top of APEX
to obtain CFA and DFA in low-end MCUs. As such, they are also
limited to APEXâ€™s uninterruptability requirement and can not pro-
cess asynchronous inputs during execution/CFA/DFA. We believe
that our work addresses this limitation.

7 CONCLUSION
This work is motivated by much needed integrity assurance for
execution in safety-critical edge devices, which are often imple-
mented with low-power and low-cost MCUs. Existing mechanisms
for producing unforgeable proofs of execution in low-end MCUs re-
quire executables not to handle interrupts, precluding their uses in
many real-time/mission-critical settings. To address this issue, we
proposed ğ´ğ‘†ğ´ğ‘ƒ: the first architecture able to generate PoX for soft-
ware that implements interrupts within its behavior. ğ´ğ‘†ğ´ğ‘ƒ extends
the original APEX PoX architecture to securely convey information
about the ephemeral immutability and integrity of the IVT and
relevant ISRs. We show that these two properties are sufficient to
realize ğ´ğ‘†ğ´ğ‘ƒ securely and that they can be obtained through the
appropriate linking of ISRs into protected memory and minimal

6

