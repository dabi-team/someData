2
2
0
2

y
a
M
3
2

]

G
L
.
s
c
[

1
v
7
1
1
1
1
.
5
0
2
2
:
v
i
X
r
a

PyRelationAL: A Library for Active Learning
Research and Development

Paul Scherer∗
University of Cambridge
paul.scherer@cl.cam.ac.uk

Thomas Gaudelet
Relation Therapeutics
thomas@relationrx.com

Alison Pouplin∗
Technical University of Denmark
alpu@dtu.dk

Suraj M S
Relation Therapeutics
suraj@mssuraj.com

Jyothish Soman
Relation Therapeutics
jyothish@relationrx.com

Lindsay Edwards
Relation Therapeutics
lindsay@relationrx.com

Jake P. Taylor-King
Relation Therapeutics
jake@relationrx.com

Abstract

In constrained real-world scenarios where it is challenging or costly to generate
data, disciplined methods for acquiring informative new data points are of fun-
damental importance for the efﬁcient training of machine learning (ML) models.
Active learning (AL) is a subﬁeld of ML focused on the development of meth-
ods to iteratively and economically acquire data through strategically querying
new data points that are the most useful for a particular task. Here, we introduce
PyRelationAL, an open source library for AL research. We describe a modular
toolkit that is compatible with diverse ML frameworks (e.g. PyTorch, Scikit-Learn,
TensorFlow, JAX). Furthermore, to help accelerate research and development in
the ﬁeld, the library implements a number of published methods and provides API
access to wide-ranging benchmark datasets and AL task conﬁgurations based on
existing literature. The library is supplemented by an expansive set of tutorials,
demos, and documentation to help users get started. We perform experiments on
the PyRelationAL collection of benchmark datasets and showcase the considerable
economies that AL can provide. PyRelationAL is maintained using modern soft-
ware engineering practices — with an inclusive contributor code of conduct — to
promote long term library quality and utilisation.

1

Introduction

Machine learning (ML) models, particularly those using deep learning, play an increasing role in
modern scientiﬁc research and broader society due to strong performance across tasks and domains.
However, the success of such learning algorithms has often been fueled by large annotated datasets
and well designed inductive biases. Unfortunately, many important domains — such as chemistry,
biology, and medicine — operate in low data regimes [1], wherein the amount of data is relatively
small compared to the rich and complex representations of each entity of interest. This problem can
be attributed to the staggering cost and resources required to label a sufﬁcient number of entities for
effective learning [2, 3, 4]. For instance, labelling all pairwise combinations of the ∼4,000 FDA-
approved drugs for synergistic effects at a single dose pair would require ∼8 million experiments per

Preprint. Under review.
∗Work performed while the author was at Relation Therapeutics.

 
 
 
 
 
 
phenotypic readout; this would require specialized equipment and could reasonably be considered
experimentally infeasible.

Active learning (AL) is a machine learning paradigm where the aim is to develop methods, or
strategies, to improve model performance in a data-efﬁcient manner. Intuitively, an AL strategy
seeks to sample data points economically such that the resulting model performs as well as possible
under budget constraints. This is typically achieved via an interactive process whereby the model
can sequentially query samples based on current knowledge and uncertainties. AL is also known
as query learning in the computational learning theory literature [5] and is a concept that has come
in and out of focus over the last decades. Notions in AL can be related to research in Bayesian
optimization [6] and reinforcement learning [7], both aiming to strategically explore some space
to improve on a performance metric. Recently, there has been a renewed interest in AL, especially
in combination with advances in deep learning, to address various real-world applications [8, 9].
Notably, applications in medicine have seen growing interest both from academic and industrial
institutes [2, 3, 10, 11, 12].

Here, we introduce PyRelationAL, an open source Python library for the rapid, reliable and re-
producible construction of AL pipelines and strategies. The design is modular and allows easy
implementation of AL strategies within a consistent framework. PyRelationAL enables the reproduc-
tion of existing research, the application to new domains, and the design of new methods. We include
a plethora of published methods as part of PyRelationAL to help users get started and facilitate
development around popular state of the art methods. Historically, the open source ML libraries that
have played a major role in the fast paced advancement of ML have adopted a practical researcher-
ﬁrst ethos coupled with ﬂexible design principles [13, 14, 15, 16, 17, 18, 19] . Our intention is for
PyRelationAL to have a similar transformative impact for AL research.

We summarise PyRelationAL’s main contributions as follows:

• A modular toolkit to rapidly construct AL pipelines and strategies.

• A ﬁrst-party interface to various popular ML frameworks through our generic ML manager

(e.g. PyTorch, Sci-kit Learn, JAX, TensorFlow).

• Implementation of existing AL strategies for reproduction, modiﬁcation and extensions.

• Collection of synthetic and real world benchmark datasets and AL task conﬁgurations for

evaluating AL strategies horizontally across domains [9, 20, 21].

2 Active learning primer

Notations Let X denote a state space whereby each element x ∈ X can be associated to a label
y ∈ Y. We further denote by F the space of functions mapping f : X (cid:55)→ Y. For a given ML
architecture, we denote by FΘ ⊂ F the subset of function mappings having this architecture and
parameters in Θ, which is deﬁned by the model’s hyperparameters. The world, W ⊂ X × Y, is
deﬁned by a canonical mapping ω ∈ F that associates to each state a unique label. We assume
we have initially access to a set of observations L0 ⊂ W from the world. We denote by U0 ⊂ X
the set of elements that are not observed in L0. The task we are faced with is to approximate
the canonical mapping function ω from a subset of observations of W, i.e. ﬁnd f ∈ F such that
∀x ∈ X , f (x) ≈ ω(x).

Table 1: Description of key symbols used throughout document.

Symbol
X
Y
F
ω : X (cid:55)→ Y
FΘ ⊂ F

Description
Complete state space
Corresponding label space
Space of functions mapping f : X → Y
Canonical map we wish to learn
Subset of F representable using chosen numerical method

W ⊂ X × Y The world deﬁned as a state-label pairing
Observations at round k
Unlabelled samples at round k.

Lk ⊂ W
Uk ⊂ X

2

Supervised learning To address this task in the supervised ML paradigm, one ﬁrst deﬁnes a
function space FΘ, through various inductive biases and hyperparameter tuning. Then one typically
searches for a function fˆθ ∈ FΘ, with parameters ˆθ ∈ Θ, that best approximate ω.

In contrast, in the AL paradigm the function space FΘ is largely assumed to be
Active learning
ﬁxed, but the practitioner can iteratively increase the size of the dataset by strategically querying the
labels for some unlabelled elements in X . At the kth iteration, we denote by Lk the dataset and by Uk
the set of unlabelled elements. The goal of an AL strategy is to identify a query set Qk ⊂ Uk that
carries the most information for approximating ω. In other words, the AL practitioner looks to add
new observations strategically to identify a smaller space FΘ,k+1 of functions that are compatible
(cid:9), whereby the queries’ labels are provided by an oracle, e.g.
with Lk+1 = Lk
human annotators or laboratory experiments. We then update Uk+1 = Uk \ Qk for the next iteration.
Access to the oracle is costly, thus AL typically operates under a budget constraint limiting the total
number of possible queries.

(cid:83) (cid:8) (q, ω(q)) , q ∈ Qk

Uk

Lk

k ← k + 1

I(x), x ∈ Uk

Fθ,k

Qk

Figure 1: Generic pipeline for pool based AL scenarios following notations introduced in Section
2. The solid lines indicate the internal operations within an AL iteration. In practice the constrain
operation is done through training the model(s) on Lk. The optional dependency of the informa-
tiveness scoring on Fθ,k is represented by the dotted line. The dashed line represents the update
step based on external information provided by the oracle. The colors indicate the correspondence
with the different modules in PyRelationAL: the data manager handling label tracking and updating,
the model manager handling training and uncertainty estimation, and the AL strategy deﬁning the
informativeness measure and selection criteria. These components are detailed in Section 4.

The general framing described above, and illustrated in Figure 1, is sometimes referred to as pool-
based AL [5], where Uk deﬁnes the pool at the kth iteration. This is arguably the most common
framing of the AL problem. However, there exist variations whereby at each iteration Uk is not a
ﬁnite set but either a generative process or a stream of unlabelled observation. These are known as
membership query and stream based AL, respectively [5]. All framings share the same core problem:
identifying unlabelled observations that are most informative to improving our solution to the task. In
our exposition, we will principally focus on pool-based AL unless otherwise speciﬁed.

A critical question underpinning AL is how to measure the informativeness of each state in X . A
number of heuristics have been proposed in the past which can broadly be split into two categories:
1.) uncertainty-based category and 2.) diversity-based category. These are not mutually exclusive as
the two notions can be combined to positive effect [5, 22, 23]. The former relies on some measure of
uncertainties of the predictions obtained from the set of functions FΘ,k at each iteration. In practice,
FΘ,k can be deﬁned intrinsically by the class of ML models (e.g. Gaussian processes or Bayesian
neural networks) or a subset of it can be obtained using heuristics such as ensembling [24, 25, 26] or
Bayesian inference approximation methods like MCDropout [27]. Various informativeness scores
can be computed from the uncertainty estimates (see Table 3) and used to select the query set Qk.
In contrast, diversity-based heuristics rely on a distance measure d : X × X (cid:55)→ R+, which can
depend on FΘ,k, to score states in Uk with respect to elements in Lk. The choice of informativeness
measure is an important challenge of AL as well as the choice of query selection strategy from the
informativeness scores.

3

ScoreLabel by oracleSelectConstrainA standard approach to select Qk is to greedily pick the highest scoring elements such that

Qk = argmax

Q⊂Uk
|Q|=mk

I(q),

(cid:88)

q∈Q

where I : X (cid:55)→ R denotes an information measure that typically would depend on FΘ,k, and mk
corresponds to the number of queries desired at round k. However, for mk > 1, this selection strategy
can lead to a redundant query set as each query therein is selected independently of the others. The
sub-ﬁeld of batch AL is concerned with this issue and developing strategies to ensure some notion of
diversity in the query [5, 22, 28]. For instance, BatchBALD [29] relies on minimising the mutual
information between pairs of queries in Qk.

Table 2: Open source libraries for AL and features available. (*) ModAL can work with models
deﬁned in Keras and PyTorch via additional libraries such as Skorch [30] which provides them with
an interface akin to Scikit-learn estimators. (†) Scikit-activeml lists a future update for regression
strategies as does ALiPY. (‡) Google’s AL playground has utilities for deﬁning a dataset compatible
with the sample strategies, as well as sample datasets to test this utility, but no veriﬁcation on whether
these datasets have been used for active learning in literature nor utilities for setting up AL task
conﬁgurations.

Name (Year)

Google Active
Learning
(2019)
JCLAL [31]
(2016)
scikit-activeml [32]
(2021)
AliPy [33]
(2019)
LibAcT [34]
(2017)
CardinAL [35]
(2022)
BAAL [36]
(2020)
ModAL [37]
(2018)
PyRelationAL
(2022)

Main ML
framework

Additional ML
frameworks
ofﬁcially supported

Strategies
Classiﬁcation

Strategies
Regression

Bayesian
approximation

Explicit data
managing

Datasets Licence

Keras/TF

None

Weka/
MULAN

None

Scikit-learn None

Generic

NA

Scikit-learn None

Scikit-learn None

PyTorch

Scikit-learn

Scikit-learn Keras/PyTorch*

Generic/
PyTorch

Scikit-learn/TF/
Keras/Jax

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Yes

Yes

No

No

No†

No†

No

No

Yes

Yes

Yes

No

No

No

No

No

No

Yes

No

Yes

No

Yes

No

Yes

Yes

No

Yes

Yes

Yes

Yes‡

Apache 2.0

No

No

No

No

No

No

No

GPL 3.0

BSD-3-Clause

BSD-3-Clause

BSD-2-Clause

Apache 2.0

Apache 2.0

MIT

Yes

Apache 2.0

3 Design principles and positioning within the ML and AL infrastructure

ecosystem

AL pipelines can appear under various scenarios such as pool-, streaming-, or membership query-
based sampling. All three involve complex interactions with the underlying labelled training data, the
learning algorithm, and the AL strategies. Similarly AL strategies can evolve from simple sequential
uncertainty sampling approaches to complex agents that leverage several informative measures and
query selection algorithms in conjunction [5, 23].

PyRelationAL was developed under careful consideration of features available within the existing AL
ecosystem, coupled with our vision to create a researcher-ﬁrst imperative style library for AL research
and development. To accommodate the growing complexity, advancements in new ML infrastructures
and encourage user construction of complex AL pipelines and strategies, we strove to make writing of
data managers, ML models, and AL strategies as intuitive and productive as possible. This is achieved
through a modular framework which we describe in Section 4. To encourage the immediate use,
study, and extension of existing strategies we have implemented various informativeness measures
and query strategies that can be composed arbitrarily to re-implement or devise novel AL methods
in classiﬁcation and regression tasks in our tutorials and examples. Furthermore, in recognition
of increasing use of deep learning models within AL pipelines, we provide modules that allow
approximate Bayesian inference with point estimate models such as MCDropout [27].

There are a number of open source libraries dedicated to AL whose features are summarised in Table
2. As the table shows, most libraries are tied to a particular ML framework with speciﬁc strategies

4

revolving around the available ML model types, all with differing levels of coverage both across
classiﬁcation and regression tasks. Each library comes with different goals in mind and they should
be appreciated for addressing different needs in open source research. ModAL [37] is an excellent
modular python library for AL built with Scikit-learn as a basis for models. Its design emphasis on
modularity and extensibility makes it the most similar to our work. Yet we differ to this and other
libraries by making the user explicitly care about the dataset and how the model, strategy and oracle
can interact with it through a data manager (see Section 4), controlling all aspects of AL pipeline as
well as the function of the strategy. The ﬂexible nature of our modules may be seen as a limitation
that incurs additional development overhead compared to other libraries but we believe this trade-off
is practical and useful to researchers exploring new approaches. As we outline in Section 5, another
important contribution of our library is an API for downloading selected datasets and constructing
AL benchmarks or tasks. As such we believe that PyRelationAL offers a compelling and complete
set of features that is complementary and additive to the existing ML and the AL tools ecosystem. In
the next section we describe how our modules enable quick development of AL with the practical
ﬂexibility to create novel pipelines and strategies.

4 PyRelationAL framework design

PyRelationAL decomposes the steps discussed in the Section 2 in three primary modules, as illustrated
in Figure 1: a data manager, a ML manager, and an AL strategy. Figure 2 provides schematic of these
modules using Universal Modelling Language (UML) diagrams to highlight the major attributes and
methods of each module. Appendix B showcases a use case of PyRelationAL through a full coding
example.

Figure 2: Universal Modelling Language (UML) diagrams of the three constitutive modules of
PyRelationAL.

Data manager This module is designed to work with any PyTorch Dataset object, which in turn
can be used ﬂexibly with other numerical libraries through custom collate functions, as illustrated in
PyRelationAL suite of examples. The job of the data manager is multi-faceted: it stores the dataset,
keeps track of data subsets, handles the creation of dataloaders for each subset, and ﬁnally interacts
with the oracle to update after each loop. Note that, the validation set and test set are considered
external to the AL loop and can be used for model selection and evaluation purposes.

In our theoretical framing, this second major component deﬁnes Fθ,k from which
ML manager
uncertainties can be estimated and used as basis for query selection. In practice this module manages
the life-cycle of the learning algorithm from instantiation to evaluation, through training and uncer-
tainty estimation. While PyRelationAL natively offers multiple ML managers using PyTorch and
PyTorch Lightning [38] as a training engine, we demonstrate through tutorials and examples that any
ML framework can be interfaced with PyRelationAL using our ML manager interface.

AL strategy The crux of an AL iteration is the strategy which relies on a notion of informativeness
I and a selection criterion to deﬁne Qk at each iteration k (see Figure 3 for pool-based AL). Note
that in some AL strategies, the informativeness notion and the selection criterion are not separable.

5

Data manager-PyTorch dataset-Labelled indices-Unlabelled indices-Validation indices-Test indices-Data loader creation-Indices updatetrain indicesML manager-Model hyperparameters-Training configuration-Current trained model-Instantiation-Training-Performance evaluation-Uncertainty estimationAL strategy-Data manager-ML manager-Informativeness -Sample selectionUk

Qk

Figure 3: Illustration of the ﬂow of the active learning strategy during one iteration in the pool-based
AL framing. The unlabelled set is fed to the active learning strategy which typically would ﬁrst
score each sample according to its notion of informativeness before selecting a query set based on its
selection strategy given the samples and their scores.

Table 3: List of informativeness measures implemented in PyRelationAL currently. The task column
indicates whether the corresponding informativeness measure is deﬁned for classiﬁcation, regression,
or is agnostic (Any) to the ML task being performed.

Name
Entropy
Least conﬁdence
Margin conﬁdence
Ratio conﬁdence
Greedy score
Upper conﬁdence bound
Expected improvement
Bayesian active learning by disagreement Classiﬁcation/Regression
Thompson sampling
Representative sampling
Relative distance

Task
Classiﬁcation
Classiﬁcation/Regression
Classiﬁcation
Classiﬁcation
Regression
Regression
Regression

Regression
Any
Any

Ref.
[39, 5]
[40, 5]
[41, 5]
[41]
[42]
[42]
[42]
[43]
[44]
[45]
[46]

The informativeness measure is often task-dependent; for instance, uncertainty measures are computed
differently for continuous and categorical targets. Table 3 gives the list of informativeness measures
from the literature that are implemented in PyRelationAL and Appendix A provides more details
and discussion around the various measures. Note that all individual informativeness measure can
be combined together. For instance, the Upper Conﬁdence Bound (UCB) score for regression as
deﬁned in [42] is a linear combination of the greedy score and least conﬁdence score for regression
tasks, with trade-off controlled by a hyperparameter. The ﬁnal step is to select Qk from Uk based on
a chosen criteria combined with the informativeness scores.

5 Benchmark datasets and AL tasks

A core part of ML research and development is the translation of theory to practice typically in
the form of evaluating a proposed method empirically against a range of established or challenging
benchmark datasets and tasks. The practice of empirically evaluating on established datasets and tasks
has become so ubiquitous that all major ML frameworks such as PyTorch, TensorFlow, SciKit-Learn
come with interfaces for downloading common benchmarks. The rapid progress of ML research in
images, text, and graphs can be attributed at least partially to easy access to pre-processed benchmark
datasets [47, 48, 49, 50].

However, despite a multitude of papers, surveys, and other libraries for AL methods there is no
established set of datasets evaluating AL strategies. To further complicate matters the same datasets
can be processed to pose different AL tasks such as cold and warm starts as described in Konyushkova
et al. [20] and Yang and Loog [21] to provide different challenges to strategies. In other words, a
benchmark for AL has to be considered from the characteristics of the dataset and the circumstances
of the initial labelling.

Due to these challenges, AL papers have a tendency to test and apply proposed methods using
different splits of the same datasets with little overlap agreement across papers — as noted in several
reviews [9, 21, 64]. This makes it difﬁcult to assess strategies horizontally across a range of common

6

InformativenessSelectionAL strategyTable 4: Selection of datasets made available in the PyRelationAL library along with information on
whether the ML task is a classiﬁcation or regression, whether it is real-world or synthetic dataset, and
the raw source of our implementation or the paper from which we constructed the dataset if it was
not available publicly. We also give the licence of each dataset curated and extend our permissive
Apache 2.0 licence (see section 6) to synthetic datasets generated with our code as well as the task
conﬁgurations. Our selection was strongly based on their prior reference in related AL literature.

Name

ML Task

Type

Source

Use in AL literature Licence

Classiﬁcation Real
CreditCard
Classiﬁcation Real
StriatumMini
Classiﬁcation Real
Breast
Classiﬁcation Real
Glass
Classiﬁcation Real
Parkinsons
Classiﬁcation
SynthClass1
Classiﬁcation
SynthClass2
GaussianClouds
Classiﬁcation
Checkerboard2x2 Classiﬁcation
Checkerboard4x4 Classiﬁcation
Diabetes
Concrete
Energy
Power
Airfoil
WineQuality
Yacht

Regression
Regression
Regression
Regression
Regression
Regression
Regression

Synthetic
Synthetic
Synthetic
Synthetic
Synthetic
Real
Real
Real
Real
Real
Real
Real

[51]
[52, 53, 20]
[55]
[55]
[59, 55]
[21]
[61]
[20]
[20]
[20]
[62, 55]
[63, 55]
[65, 55]
[67, 55]
[55]
[68, 55]
[55]

[20]
[20, 54]
[56, 21, 9]
[57, 58, 9]
[60, 21, 9]
[21]
[61, 21]
[20, 21]
[20]
[20]
[56, 9]
[64]
[66]
[66, 64]
[64]
[64]
[66, 64]

DbCL 1.0
GPLv3
CC BY 4.0
CC BY 4.0
CC BY 4.0
Apache 2.0
Apache 2.0
Apache 2.0
Apache 2.0
Apache 2.0
CC BY 4.0
CC BY 4.0
CC BY 4.0
CC BY 4.0
CC BY 4.0
CC BY 4.0
CC BY 4.0

datasets and identify regimes under which a given strategy shows success or failure. This issue
is exacerbated by publication bias which favours the reporting of positive results — as noted in
Settles [5]. To help alleviate this issue we have collected a variety of datasets for both classiﬁcation
and regression tasks as used in AL literature and make these available through PyRelationAL, see
Table 4. The datasets are either real world datasets or synthetic datasets taken from seminal AL
literature [20, 51, 9, 21, 64, 66]. The synthetic datasets were typically devised to pose challenges
to speciﬁc strategies. Another selection criteria was their permissive licensing, such as the Creative
Commons Attribution 4.0 International License granted on the recently updated UCI archives [55],
or the licenses through the Open Data Commons initiative.

Each of the datasets can be downloaded and processed into PyTorch Dataset objects through a simple
API. Furthermore, we provide additional facilities to turn them into PyRelationAL DataManager
objects that emulate cold and warm start AL initialisations with arbitrary train-validation-test splits
and canonical splits (where applicable) for pain-free benchmarking.

In Figure 4, we show the performance curves over query iterations using a Gaussian process classiﬁer
with 5 different budgeted AL strategies on the Checkerboard2x2 dataset from Konyushkova et al.
[20]. Our intent with this example is ﬁrst to show drastic economies that can be obtained with
active learning in early stages of labelling (i.e. AL is useful!) and secondly how dramatically these
curves may change based on the task conﬁguration within a dataset. We show the importance of the
initial AL task conﬁgurations within datasets and demonstrate that there is no free-lunch amongst the
AL strategies. Such results motivate the collection of datasets and task conﬁgurations, as well our
modular approach to constructing methods so that researchers can modify and study the behaviours of
novel strategies quickly. We provide a more comprehensive comparative analysis across the currently
available datasets in Table 4 with details on the experimental setup as used here in Appendix C.

6 Maintaining PyRelationAL

We consider AL as an important tool and a growing domain of research interest, particularly as ML
research focus intensiﬁes towards tasks in low-data regimes such as biomedicine. Hence, we adopt
modern open source software engineering practices in order to promote robustness and reliability of

7

(a) Cold start

(b) Warm start

Figure 4: Performance curves over serial query iterations of selected active learning strategies on
the Checkerboard2x2Dataset from Konyushkova et al. [20]. The left ﬁgure shows the balanced
accuracy given a cold start task conﬁguration, the right ﬁgure shows the performance given a warm
start conﬁguration.

the package whilst maintaining an open policy towards contributions over the long term vision we
have for the project.

Open sourcing, package indexing, and contributing PyRelationAL is made available open
source under a permissive Apache 2.0 licence with stable releases made on the Python Package
Index (PyPI) for easy installation. To introduce new users to the package we created an extensive set
of examples, tutorials, and supplementary materials linked through the main README including
developer setups for contributors. We follow an inclusive code of conduct for contributors and users to
facilitate fair treatment and guidelines for contributing. Furthermore, a contributors guide is provided
describing the expected workﬂows, testing, and code quality expectations for pull requests into the
package.

Documentation All modules are accompanied by restructured text (ResT) docstrings and comments
to maintain documentation of the library. This approach maintains an up to date reference of the API,
which is compiled and rendered via Sphinx to be hosted on Read The Docs for every update accepted
into the main branch. In addition to the API reference, our documentation website is accompanied by
various supplementary tutorials, examples, and information about AL within the library to help get
users started and advanced users to extend the library to ﬁt their needs and research endeavours.

Code quality, testing and continuous integration To ensure consistent code quality throughout
the package, we ensure that source code is PEP 8 compliant via a linter that is checked automatically
before a pull request can be approved. We make pre-commit hooks available that can format the
code using tools, such as the Black package. All important modules and classes are extensively
tested through unit tests to ensure consistent behaviour. Code coverage reports are available on the
repository as a measure of the health of the package. A continuous integration setup ensures that any
update to the code base is tested across different environments and can be installed reliably.

7 Conclusion

PyRelationAL supports popular modelling frameworks and ﬂexibly accounts for the various com-
ponents within an AL pipeline. We provide detailed documentation and various tutorials across
use cases. Furthermore, we adopt modern software practices with an inclusive code of conduct as
discussed in Section 6 to foster a productive, sustainable and healthy growth of the library and the
community around it. We endeavoured to release PyRelationAL as both a tool to help practitioners
perform research but also help newcomers join the community and make novel contributions to the
ﬁeld. We therefore believe PyRelationAL offers a compelling set of features that are additive and
beneﬁcial to the AL community

8

References

[1] Thomas Gaudelet, Ben Day, Arian R Jamasb, Jyothish Soman, Cristian Regep, Gertrude Liu,
Jeremy B R Hayter, Richard Vickers, Charles Roberts, Jian Tang, David Roblin, Tom L Blundell,
Michael M Bronstein, and Jake P Taylor-King. Utilizing graph machine learning within drug
discovery and development. Brieﬁngs in Bioinformatics, 22(6), 05 2021. bbab159.

[2] Justin S Smith, Ben Nebgen, Nicholas Lubbers, Olexandr Isayev, and Adrian E Roitberg. Less
is more: Sampling chemical space with active learning. The Journal of Chemical Physics,
148(24):241733, 2018.

[3] Mohammed Abdelwahab and Carlos Busso. Active learning for speech emotion recognition
using deep neural network. In 2019 8th International Conference on Affective Computing and
Intelligent Interaction (ACII), pages 1–7. IEEE, 2019.

[4] Steven CH Hoi, Rong Jin, Jianke Zhu, and Michael R Lyu. Batch mode active learning and its
application to medical image classiﬁcation. In Proceedings of the 23rd International Conference
on Machine Learning, pages 417–424, 2006.

[5] Burr Settles. Uncertainty sampling.

In Active Learning, Synthesis Lectures on Artiﬁcial

Intelligence and Machine Learning, pages 11–21. Morgan & Claypool Publishers, 2012.
[6] Eric Brochu, Vlad M Cora, and Nando De Freitas. A tutorial on bayesian optimization of
expensive cost functions, with application to active user modeling and hierarchical reinforcement
learning. arXiv preprint arXiv:1012.2599, 2010.

[7] Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction. MIT press,

2018.

[8] Pengzhen Ren, Yun Xiao, Xiaojun Chang, Po-Yao Huang, Zhihui Li, Brij B Gupta, Xiaojiang
Chen, and Xin Wang. A survey of deep active learning. ACM Computing Surveys (CSUR),
54(9):1–40, 2021.

[9] Xueying Zhan, Huan Liu, Qing Li, and Antoni B. Chan. A comparative survey: Benchmarking
for pool-based active learning. In Zhi-Hua Zhou, editor, Proceedings of the Thirtieth Interna-
tional Joint Conference on Artiﬁcial Intelligence, IJCAI-21, pages 4679–4686. International
Joint Conferences on Artiﬁcial Intelligence Organization, 8 2021. Survey Track.

[10] Brian Hie, Bryan D Bryson, and Bonnie Berger. Leveraging uncertainty in machine learning

accelerates biological discovery and design. Cell Systems, 11(5):461–477, 2020.

[11] Paul Bertin, Jarrid Rector-Brooks, Deepak Sharma, Thomas Gaudelet, Andrew Anighoro,
Torsten Gross, Francisco Martinez-Pena, Eileen L Tang, Cristian Regep, Jeremy Hayter, et al.
Recover: sequential model optimization platform for combination drug repurposing identiﬁes
novel synergistic compounds in vitro. arXiv preprint arXiv:2202.04202, 2022.

[12] Arash Mehrjou, Ashkan Soleymani, Andrew Jesson, Pascal Notin, Yarin Gal, Stefan Bauer,
and Patrick Schwab. GeneDisco: A Benchmark for Experimental Design in Drug Discovery.
arXiv:2110.11875 [cs, stat], October 2021. arXiv: 2110.11875.

[13] Adam Paszke, Sam Gross, Francisco Massa, et al. Pytorch: An imperative style, high-
performance deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-
Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32,
pages 8024–8035. Curran Associates, Inc., 2019.

[14] François Chollet et al. Keras. https://keras.io, 2015.
[15] James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal
Maclaurin, George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao
Zhang. JAX: composable transformations of Python+NumPy programs, 2018.

[16] Jonathan Heek, Anselm Levskaya, Avital Oliver, Marvin Ritter, Bertrand Rondepierre, Andreas
Steiner, and Marc van Zee. Flax: A neural network library and ecosystem for JAX, 2020.
[17] Dustin Tran, Matthew D. Hoffman, Rif A. Saurous, Eugene Brevdo, Kevin Murphy, and
David M. Blei. Deep probabilistic programming. In International Conference on Learning
Representations, 2017.

[18] Jacob R Gardner, Geoff Pleiss, David Bindel, Kilian Q Weinberger, and Andrew Gordon
Wilson. Gpytorch: Blackbox matrix-matrix gaussian process inference with gpu acceleration.
In Advances in Neural Information Processing Systems, 2018.

9

[19] Du Phan, Neeraj Pradhan, and Martin Jankowiak. Composable effects for ﬂexible and acceler-

ated probabilistic programming in numpyro. arXiv preprint arXiv:1912.11554, 2019.

[20] Ksenia Konyushkova, Raphael Sznitman, and Pascal Fua. Learning active learning from data.

Advances in Neural Information Processing Systems, 30, 2017.

[21] Yazhou Yang and Marco Loog. A benchmark and comparison of active learning for logistic

regression. Pattern Recognition, 83:401–415, 2018.

[22] Klaus Brinker. Incorporating diversity in active learning with support vector machines. In
Proceedings of the Twentieth International Conference on International Conference on Machine
Learning, ICML’03, page 59–66. AAAI Press, 2003.

[23] Robert (Munro) Monarch. Human-In-the-Loop Machine Learning: Active Learning and

Annotation for Human-Centered AI. Manning Publications Co. LLC, 2021.

[24] Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and Scalable Pre-
dictive Uncertainty Estimation using Deep Ensembles. arXiv:1612.01474 [cs, stat], November
2017. arXiv: 1612.01474.

[25] David Cohn, Les Atlas, and Richard Ladner. Improving generalization with active learning.

Machine Learning, 15(2):201–221, May 1994.

[26] H. S. Seung, M. Opper, and H. Sompolinsky. Query by committee. In Proceedings of the Fifth
Annual Workshop on Computational Learning Theory, COLT ’92, page 287–294, New York,
NY, USA, 1992. Association for Computing Machinery.

[27] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing
model uncertainty in deep learning. In International Conference on Machine Learning, pages
1050–1059. PMLR, 2016.

[28] Yuhong Guo and Dale Schuurmans. Discriminative batch mode active learning. In Proceedings
of the 20th International Conference on Neural Information Processing Systems, NIPS’07, page
593–600, Red Hook, NY, USA, 2007. Curran Associates Inc.

[29] Andreas Kirsch, Joost Van Amersfoort, and Yarin Gal. Batchbald: Efﬁcient and diverse batch
acquisition for deep bayesian active learning. Advances in Neural Information Processing
Systems, 32, 2019.

[30] Marian Tietz, Thomas J. Fan, Daniel Nouri, Benjamin Bossan, and skorch Developers. skorch:

A scikit-learn compatible neural network library that wraps PyTorch, July 2017.

[31] Oscar Reyes, Eduardo Pérez, María del Carmen Rodríguez-Hernández, Habib M. Fardoun, and
Sebastián Ventura. Jclal: A java framework for active learning. Journal of Machine Learning
Research, 17(95):1–5, 2016.

[32] Daniel Kottke, Marek Herde, Tuan Pham Minh, Alexander Benz, Pascal Mergard, Atal Rogh-
man, Christoph Sandrock, and Bernhard Sick. scikitactiveml: A library and toolbox for active
learning algorithms. Preprints, 2021.

[33] Ying-Peng Tang, Guo-Xiang Li, and Sheng-Jun Huang. ALiPy: Active learning in python.
Technical report, Nanjing University of Aeronautics and Astronautics, January 2019. available
as arXiv preprint https://arxiv.org/abs/1901.03802.

[34] Yao-Yuan Yang, Shao-Chuan Lee, Yu-An Chung, Tung-En Wu, Si-An Chen, and Hsuan-Tien
Lin. libact: Pool-based active learning in python. Technical report, National Taiwan University,
October 2017. available as arXiv preprint https://arxiv.org/abs/1710.00379.

[35] Alexandre Abraham and Léo Dreyfus-Schmidt. Cardinal, a metric-based active learning

framework. Software Impacts, 12:100250, 2022.

[36] Parmida Atighehchian, Frédéric Branchaud-Charron, and Alexandre Lacoste. Bayesian active
learning for production, a systematic study and a reusable library. CoRR, abs/2006.09916, 2020.

[37] Tivadar Danka and Peter Horvath. modal: A modular active learning framework for python.

arXiv preprint arXiv:1805.00979, 2018.

[38] William Falcon, Jirka Borovec, Adrian Wälchli, et al. Pytorchlightning/pytorch-lightning: 0.7.6

release, May 2020.

10

[39] Ido Dagan and Sean P. Engelson. Committee-based sampling for training probabilistic clas-
siﬁers. In Proceedings of the Twelfth International Conference on International Conference
on Machine Learning, ICML’95, page 150–157, San Francisco, CA, USA, 1995. Morgan
Kaufmann Publishers Inc.

[40] David D. Lewis and Jason Catlett. Heterogeneous uncertainty sampling for supervised learning.
In William W. Cohen and Haym Hirsh, editors, Machine Learning Proceedings 1994, pages
148–156. Morgan Kaufmann, San Francisco (CA), 1994.

[41] Tobias Scheffer, Christian Decomain, and Stefan Wrobel. Active hidden markov models for
information extraction. In Proceedings of the 4th International Conference on Advances in
Intelligent Data Analysis, IDA ’01, page 309–318, Berlin, Heidelberg, 2001. Springer-Verlag.
[42] George De Ath, Richard M Everson, Alma AM Rahat, and Jonathan E Fieldsend. Greed is
good: Exploration and exploitation trade-offs in bayesian optimisation. ACM Transactions on
Evolutionary Learning and Optimization, 1(1):1–22, 2021.

[43] Neil Houlsby, Ferenc Huszár, Zoubin Ghahramani, and Máté Lengyel. Bayesian active learning

for classiﬁcation and preference learning. arXiv preprint arXiv:1112.5745, 2011.

[44] Daniel J Russo, Benjamin Van Roy, Abbas Kazerouni, Ian Osband, Zheng Wen, et al. A tutorial
on thompson sampling. Foundations and Trends in Machine Learning, 11(1):1–96, 2018.
[45] Hieu T. Nguyen and Arnold Smeulders. Active learning using pre-clustering. In Proceedings
of the Twenty-First International Conference on Machine Learning, ICML ’04, page 79, New
York, NY, USA, 2004. Association for Computing Machinery.

[46] Sanjoy Dasgupta and Daniel Hsu. Hierarchical sampling for active learning. In Proceedings of
the 25th International Conference on Machine Learning, ICML ’08, page 208–215, New York,
NY, USA, 2008. Association for Computing Machinery.

[47] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei.

ImageNet: A Large-Scale

Hierarchical Image Database. In Computer Vision and Pattern Recognition, 2009.

[48] Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix
Hill, Omer Levy, and Samuel Bowman. Superglue: A stickier benchmark for general-purpose
language understanding systems. Advances in Neural Information Processing Systems, 32,
2019.

[49] Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele
Catasta, and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs.
Advances in Neural Information Processing Systems, 33:22118–22133, 2020.

[50] Kexin Huang, Tianfan Fu, Wenhao Gao, Yue Zhao, Yusuf Roohani, Jure Leskovec, Connor W
Coley, Cao Xiao, Jimeng Sun, and Marinka Zitnik. Therapeutics data commons: Machine learn-
ing datasets and tasks for drug discovery and development. arXiv preprint arXiv:2102.09548,
2021.

[51] Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson, and Gianluca Bontempi. Calibrating
probability with undersampling for unbalanced classiﬁcation. In 2015 IEEE Symposium Series
on Computational Intelligence, pages 159–166, 2015.

[52] Aurélien Lucchi, Yunpeng Li, and Pascal Fua. Learning for structured prediction using approxi-
mate subgradient descent with working sets. In 2013 IEEE Conference on Computer Vision and
Pattern Recognition, pages 1987–1994, 2013.

[53] Aurélien Lucchi, Yunpeng Li, Kevin Smith, and Pascal Fua. Structured image segmentation
using kernelized features. In European conference on computer vision, pages 400–413. Springer,
2012.

[54] Ksenia Konyushkova, Raphael Sznitman, and Pascal V. Fua. Introducing geometry in active
learning for image segmentation. 2015 IEEE International Conference on Computer Vision
(ICCV), pages 2974–2982, 2015.

[55] Dheeru Dua and Casey Graff. UCI machine learning repository, 2017.
[56] Neil Houlsby, Ferenc Huszár, Zoubin Ghahramani, and Máté Lengyel. Bayesian active learning

for classiﬁcation and preference learning. arXiv preprint arXiv:1112.5745, 2011.

[57] Wenbin Cai, Ya Zhang, and Jun Zhou. Maximizing expected model change for active learning
in regression. In 2013 IEEE 13th International Conference on Data Mining, pages 51–60, 2013.

11

[58] Bo Du, Zengmao Wang, Lefei Zhang, Liangpei Zhang, Wei Liu, Jialie Shen, and Dacheng Tao.
Exploring representativeness and informativeness for active learning. IEEE Transactions on
Cybernetics, 47(1):14–26, 2017.

[59] Max A. Little, Patrick E. McSharry, Stephen J. Roberts, Declan AE Costello, and Irene M.
Moroz. Exploiting nonlinear recurrence and fractal scaling properties for voice disorder
detection. BioMedical Engineering OnLine, 6(1):23, Jun 2007.

[60] Sicheng Xiong, Javad Azimi, and Xiaoli Z. Fern. Active learning of constraints for semi-
supervised clustering. IEEE Transactions on Knowledge and Data Engineering, 26(1):43–54,
2014.

[61] Sheng-Jun Huang, Songcan Chen, and Zhi-Hua Zhou. Multi-label active learning: Query
type matters. In Proceedings of the 24th International Conference on Artiﬁcial Intelligence,
IJCAI’15, page 946–952. AAAI Press, 2015.

[62] Bradley Efron, Trevor Hastie, Iain Johnstone, and Robert Tibshirani. Least angle regression.

The Annals of Statistics, 32(2):407 – 499, 2004.

[63] I.-C. Yeh. Modeling of strength of high-performance concrete using artiﬁcial neural networks.

Cement and Concrete Research, 28(12):1797–1808, 1998.

[64] Dongrui Wu. Pool-based sequential active learning for regression. IEEE Transactions on Neural

Networks and Learning Systems, 30(5):1348–1359, 2019.

[65] Athanasios Tsanas and Angeliki Xifara. Accurate quantitative estimation of energy performance
of residential buildings using statistical machine learning tools. Energy and Buildings, 49:560–
567, 2012.

[66] Robert Pinsler, Jonathan Gordon, Eric Nalisnick, and José Miguel Hernández-Lobato. Bayesian
batch active learning as sparse subset approximation. Advances in Neural Information Process-
ing Systems, 32, 2019.

[67] Pınar Tüfekci. Prediction of full load electrical power output of a base load operated combined
cycle power plant using machine learning methods. International Journal of Electrical Power
& Energy Systems, 60:126–140, 2014.

[68] Paulo Cortez, António Cerdeira, Fernando Almeida, Telmo Matos, and José Reis. Modeling
wine preferences by data mining from physicochemical properties. Decision Support Systems,
47(4):547–553, 2009. Smart Business Networks: Concepts and Empirical Evidence.

[69] Armen Der Kiureghian and Ove Ditlevsen. Aleatory or epistemic? does it matter? Structural

Safety, 31(2):105–112, 2009.

[70] Claude Elwood Shannon. A mathematical theory of communication. The Bell System Technical

Journal, 27:379–423, 1948.

[71] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel,
P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher,
M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine
Learning Research, 12:2825–2830, 2011.

[72] Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian processes for machine

learning, volume 2. MIT Press, 2006.

[73] Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian Nowozin, Joshua
Dillon, Balaji Lakshminarayanan, and Jasper Snoek. Can you trust your model’s uncertainty?
evaluating predictive uncertainty under dataset shift. Advances in Neural Information Processing
Systems, 32, 2019.

[74] Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassiﬁed and out-of-distribution

examples in neural networks. arXiv preprint arXiv:1610.02136, 2016.

[75] Zoubin Ghahramani. Probabilistic machine learning and artiﬁcial intelligence. Nature,

521(7553):452–459, 2015.

[76] Wesley J. Maddox, Timur Garipov, Pavel Izmailov, Dmitry Vetrov, and Andrew Gordon Wilson.
A Simple Baseline for Bayesian Uncertainty in Deep Learning. Curran Associates Inc., Red
Hook, NY, USA, 2019.

12

A Informativeness measures

In this section, we provide more details about each type of informativeness measure discussed in the
main and described some of the speciﬁc scores mentioned in Table 3.

A.1 Uncertainty-based informativeness scores

As discussed in Section 4, a large number of informativeness measures rely on some estimate of
prediction uncertainties. The underlying rationale is that regions of the world are highly uncertain
because they are poorly represented in the training data. Improving coverage through sampling
uncertain data regions can enable signiﬁcant global performance gains. While this makes intuitive
sense, it ignores subtleties about the nature of uncertainties which can be decomposed in epistemic
and aleatoric components [69]. The former is understood as coming from modelling errors while the
latter is inherent to the world, corresponding to natural variations or measurement noise. Aleatoric
uncertainties are irreducible and, in practice, it is extremely difﬁcult to tease out the two uncer-
tainty components from each other. This means that uncertainty-based informativeness scores can
overestimate the information gain that a sample would provide.

In the following, we detail a few of the scores that fall under this category.

Entropy is a well-established notion in information theory that quantiﬁes the uncertainty of a
probability distribution over possible outcomes [70]. It is used as an informativeness measure
for classiﬁcation tasks where the probability distribution is deﬁned over the ﬁnite set of labels Y.
Speciﬁcally, it is deﬁned as

I(x) = −

(cid:88)

y∈Y

pFθ,k (y|x) log (cid:0)pFθ,k (y|x)(cid:1) .

Least conﬁdence
deﬁned differently for each task. In regression tasks, we have

can be used both for regression and classiﬁcation tasks, although the score is

I(x) = VarFθ,k [Y |x] ,
where Y denotes a random variable in Y. Hence, to each sample x it associates the variance across
the predictions from the set of functions Fθ,k.

In classiﬁcation tasks, the least conﬁdence score is deﬁned as

I(x) = 1 − max
y∈Y

pFθ,k (y|x) .

Margin conﬁdence was introduced for classiﬁcation tasks and measures uncertainty as the differ-
ence between the highest and second highest probabilities associated to labels in Y derived from our
predictions on a given sample. The smaller that difference, the higher the uncertainty. In equation,
this gives

y0 = argmax

y∈Y

pFθ,k (y|x) ,

y1 = argmax
y∈Y\{y0}

pFθ,k (y|x) ,

I(x) = 1 − (cid:0)pFθ,k (y0|x) − pFθ,k (y1|x)(cid:1) .

Ratio conﬁdence
that the uncertainty is expressed as a ratio between the two probabilities

is a score similar to margin conﬁdence, the only difference comes from the fact

y0 = argmax

y∈Y

pFθ,k (y|x) ,

pFθ,k (y|x) ,

y1 = argmax
y∈Y\{y0}
pFθ,k (y1|x)
pFθ,k (y0|x)

I(x) =

.

13

Greedy score This is a simple score used for regression tasks where greater values in Y are of
higher interest. For instance, we would be more interested in reliably identifying highly synergistic
pairs of drugs. The score is deﬁned as

I(x) = EFθ,k [Y |x] .

Upper conﬁdence bound UCB comes from the reinforcement learning (RL) literature and corre-
sponds to a trade-off, controlled by an hyperparameter λ, between the greedy score and the least
conﬁdence score. It is formally deﬁned as

I(x) = EFθ,k [Y |x] + λ

(cid:113)

VarFθ,k [Y |x],

where Y denotes a random variable in Y.

Similarly to the greedy score, it is deﬁned for continuous label values and assumes that greater values,
known as rewards in RL, are more relevant to the problem.

A.2 Diversity-based informativeness scores

Rather than rely on some estimate of uncertainties, diversity-based scores aim to increase the diversity
of the training set, querying samples that are far from the current labelled set according to a selected
distance metric. Methods can differ on the choice of distance metric and on the space where distances
are computed. The ambient space is often used but can have some limitations due to noisy or
redundant features or suffer from the curse of dimensionality in high-dimensional space. As such,
researchers have proposed to compute distances in lower dimensional spaces either obtained from
dimensionality reduction techniques or from intermediary latent spaces derived from a trained model.
We discuss below two generic types of approaches that are built-in PyRelationAL.

Relative distance sampling computes the minimum distance from an unlabelled sample to the
labelled samples

I(x) = min
l∈L

d (φ(x), φ(l)) ,

where φ : X (cid:55)→ Rm an embedding function projecting samples into a latent space and d : Rm×Rm (cid:55)→
R+ represents the chosen distance metric in the latent space. Note that φ is simply the identity function
when computing distances in the ambient space. The coreset approach, as deﬁned in [12], would be
classiﬁed in this category in PyRelationAL, where the latent space representation of a point is deﬁned
by the associated penultimate activations in a neural network.

Representative sampling does not explicitly deﬁne an informativeness scores. Instead, it groups
the current unlabelled set into a ﬁxed number of clusters and selects representative samples from each
cluster to form the query set. Note that this can be quite expensive to compute when the unlabelled
set is large as it requires all-to-all pairwise distances, and can beneﬁt from extracting ﬁrst a subset of
the unlabelled set based on some other criteria.

B Use case study: coding example

In this section, we will walk through a simple coding example to showcase PyRelationAL building
blocks and how to simply create an AL pipeline with them.

First, we need to deﬁne our dataset of interest, deﬁned in Listings 1. For this example we outline
how one can outline their own custom datasets. We use the diabetes dataset from Scikit-Learn
[71] package which contains data for 442 patients, each described by 10 features (such as age, sex,
and bmi) and associated with a scalar score quantifying the disease’s progression, or stage. The
distribution of these scores is shown in Figure 5.

1 import torch
2 from sklearn.datasets import load_diabetes
3 from torch.utils.data import Dataset
4

5

14

6 class DiabetesDataset(Dataset):
7

8

9

10

11

12

13

14

15

16

17

18

19

20

def __init__(self):

# Load the diabetes dataset
diabetes_X, diabetes_y = load_diabetes(

return_X_y=True

)
self.x = torch.FloatTensor(diabetes_X)
self.y = torch.FloatTensor(diabetes_y)

def __len__(self):

return self.x.shape[0]

def __getitem__(self, idx):

return self.x[idx], self.y[idx]

Listing 1: Creating a pytorch dataset for a regression task using the Diabetes dataset from scikit-learn.

Figure 5: Distribution of the diabetes progression score in the dataset considered.

We then wrap the dataset into a PyRelationAL data manager (see Listings 2), randomly splitting the
data into train, validation, and test sets (lines 9-16) and taking a portion of the train set as our initial
labelled set (lines 17-21).

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

from pyrelational.data import GenericDataManager

def get_data_manager(
batch_size=10,
hit_ratio_at=5,

):

ds = DiabetesDataset()
train_ds, valid_ds, test_ds = \
torch.utils.data.random_split(

ds,
[400, 22, 20],

)
train_indices = train_ds.indices
valid_indices = valid_ds.indices
test_indices = test_ds.indices
labelled_indices = (

train_indices[:labelled_size]

15

19

20

21

22

23

24

25

26

27

28

29

30

31

if not labelled_size is None
else None

)

return GenericDataManager(

ds,
train_indices=train_indices,
validation_indices=valid_indices,
test_indices=test_indices,
labelled_indices=labelled_indices,
loader_batch_size=batch_size,
hit_ratio_at=hit_ratio_at,

)

Listing 2: Deﬁning a PyRelationAL data manager for the dataset.

Second, we deﬁne a simple multi-layer perceptron model (see Listings 3) to predict diabetes progres-
sion based on the input features describing each patient.

1 import torch
2 import torch.nn as nn
3 import torch.nn.functional as F
4

5
6 class DiabetesRegression(nn.Module):
7

def __init__(self, dropout=0):

8

9

10

11

12

13

14

15

16

17

super(DiabetesRegression, self).__init__()
self.layer_1 = nn.Linear(10, 5)
self.layer_2 = nn.Linear(5, 1)
self.elu = nn.ELU()
self.dropout = nn.Dropout(dropout)

def forward(self, x):

x = self.dropout(self.elu(self.layer_1(x)))
x = self.dropout(self.layer_2(x))
return x

Listing 3: A simple MLP regression pytorch model.

We then deﬁne a PyRelationAL ML manager to wrap around the PyTorch model in Listings 4,
overriding the methods train (lines 20-36) and test (lines 38-48). We’ll use ensembling as a way
to estimate prediction uncertainties, hence we use PyRelationAL’s GenericEnsembleModel as a
base class. The base class handles instantiation of an ensemble of models of size governed by the
n_estimators parameter (line 11).

1 import torch
2 import torch.nn as nn
3 from pyrelational.models import GenericEnsembleModel
4

5
6 class TorchModuleWrapper(GenericEnsembleModel):
7

def __init__(self,

8

9

10

11

12

13

14

15

16

17

model_class,
model_config,
trainer_config,
n_estimators= 5,

):

super(TorchModuleWrapper, self).__init__(

model_class,
model_config,
trainer_config,
n_estimators,

16

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

)

def train(self, train_loader, val_loader=None):

models = self.init_model()
criterion = nn.MSELoss()
self.current_model = []
for model in models:

optimizer = torch.optim.Adam(

model.parameters(),
lr=self.trainer_config["lr"]

)
for _ in range(self.trainer_config["epochs"]):

for x, y in train_loader:
optimizer.zero_grad()
out = model(x)
loss = criterion(out, y)
loss.backward()
optimizer.step()
self.current_model.append(model)

def test(self, loader):

with torch.no_grad():

tst_loss, cnt = 0, 0
for model in self.current_model:

model.eval()
for x, y in loader:

tst_loss += torch.square(

model(x) - y

).sum()
cnt += x.size(0)

return {"test_loss": tst_loss/cnt}

Listing 4: Deﬁning a torch model wrapper for PyRelationAL.

The last piece is the AL strategy. Here, we implement an (cid:15)-greedy strategy (see Listings 5), borrowed
from the reinforcement learning literature, that interpolates between a random strategy, that selects
patients for labelling at random, and a greedy strategy, that selects patients whose diabetes is predicted
to be most advanced, and who might be in need of more care.

regression_greedy_score,

1 import torch
2 import numpy as np
3 from pyrelational.informativeness import (
4
5 )
6 from pyrelational.strategies.generic_al_strategy import (
7
8 )
9

GenericActiveLearningStrategy,

10
11 class EpsilonGreedyStrategy(GenericActiveLearningStrategy):
def __init__(self, data_manager, model, eps=0.05):
12

13

14

15

16

17

18

19

20

21

22

23

24

super(EpsilonGreedyStrategy, self).__init__(

data_manager,
model,

)
assert 0 <= eps <= 1,

"epsilon should be a float between 0 and 1"

self.eps = eps

def active_learning_step(self, num_annotate):

num_annotate = min(num_annotate, len(self.u_indices))
self.model.train(self.l_loader, self.valid_loader)
output = self.model(self.u_loader)

17

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

scores = regression_greedy_score(x=output)
ixs = torch.argsort(

scores, descending=True

).tolist()
greedy_annotate = int((1-self.eps)*num_annotate)
ixs = [self.u_indices[i] \

for i in ixs[: greedy_annotate]]

remaining_u_indices = list(

set(self.u_indices) - set(ixs)

)
random_annotate = np.random.choice(

remaining_u_indices,
num_annotate-greedy_annotate,
replace=False,

)
return ixs + random_annotate.tolist()

Listing 5: Implements an (cid:15)-greedy strategy, whereby a percentage of the samples to annotate are
selected randomly while the remaining are selected greedily.

We now have everything ready to setup and run the AL pipeline (see Listings 6). Line 1 of the snippet
deﬁnes a PyRelationAL data manager, line 2 create the PyRelationAL model. Both are then used
to instantiate the strategy on line 8. On line 13, we estimate maximum theoretical performances
that would be achieved if all the train set was available. Line 14 then performs an iterative AL loop
whereby 25 patients from the unlabelled pool are added to the labelled set at each iteration.

5

4

1 data_manager = get_data_manager()
2 model = TorchModuleWrapper(
DiabetesRegression,
3
{"dropout": 0.12},
{"epochs":100, "lr":3e-4},
n_estimators=10,

6
7 )
8 strategy = EpsilonGreedyStrategy(
9

data_manager=data_manager,
model=model,
eps=0.05

10

11
12 )
13
14 strategy.full_active_learning_run(num_annotate=25)

Listing 6: Running the strategy.

C Comparative analysis on selected strategies and datasets in PyRelationAL

In this section we perform a simple empirical comparative analysis of selected serial active learning
strategies constructed with the informativeness measures in Table 3 across the current datasets in
PyRelationAL. Serial active learning strategies perform one instance queries at each query loop
iteration such that

Qk = argmax

q∈Uk

I(q),

and the strategy is mainly driven by the choice of informativeness measure I(·). We remind that our
aim here is to show the different components at play when creating AL experiments and assessing
the resulting performances of strategies rather than advocating for any method.

Inspired by Konyushkova et al. [20] and Yang and Loog [21], we assess our strategies on each dataset
in two AL task conﬁgurations with respect to the ML task type.

• Cold-start classiﬁcation: 1 observation for each class represented in the training set is

labelled and the rest unlabeled.

18

• Warm-start classiﬁcation: a randomly sampled 10 percent of the training set is labelled,

the rest is unlabelled.

• Cold-start regression: the two observations with highest euclidean pairwise distance in the

train set are labelled, the rest is unlabelled.

• Warm-start regression: a randomly sampled 10 percent of the training set is labelled, the

rest is unlabelled.

Experimental setup For each dataset, we use a 5-fold cross-validation setup (stratiﬁed for classiﬁ-
cation task). We generate a warm and cold start initialisation for each of these splits to set up an AL
experiment. A single observation is queried at the end of each AL iteration, i.e. referred to the oracle
for labelling. For small datasets (<300 observations in the training split) we run the query loop until
all available observations in the training set are labelled. For larger datasets we set a maximum query
budget of 250 iterations.

For the sake of simplicity, we used the same Gaussian process classiﬁer (GPC) for each of the
experiments on classiﬁcation datasets and the same Gaussian process regressor (GPR) for the
regression datasets. Both GPC and GPR utilise a RBF kernel. The model is trained anew at each
AL query iteration. For both models, the prior is assumed to be constant and zero. The parameters
of the kernel are optimized by maximizing the log marginal likelihood with the LBFGS algorithm.
Details of the GPR implementation can be found in Algorithm 2.1 of Rasmussen and Williams
[72]. The GPC implements the logistic link function based on Laplace approximation. Details of its
implementation can be found in Algorithms 3.1, 3.2, and 5.1 of Rasmussen and Williams [72].

At each query iteration, we record the model’s balanced accuracy score for classiﬁcation datasets and
mean square error (MSE) for regression datasets on the respective hold-out test sets. We aggregate
the performance curves over the AL iterations showing the mean performance and 95% conﬁdence
intervals over the data splits as displayed in Figures 6 and 7. We also aggregate the area under each
AL iteration performance curve (shortened to IPAUC), this is a single number where higher numbers
denote better performance of the strategy in classiﬁcation and lower numbers are better in regression.
We report the mean IPAUC score and standard deviations over all the curves. Obviously, different
metrics can be used for the "performance" in the IPAUC score.

Active learning strategies To keep the performance curves from being too cluttered in this paper,
we report the performance on a chosen few strategies. For classiﬁcation tasks, we use the 1) random
acquisition, 2) least conﬁdence, 3) margin conﬁdence, 4) entropy, and 5) representative sampling
strategies. For regression tasks, we use the 1) random acquisition, 2) least conﬁdence, 3) BALD, 4)
expected improvement, and 5) representative sampling strategies. These represent a small sample
of methods coming from different families of AL approaches based on uncertainty sampling and
diversity sampling techniques [5, 23].

All experiments were run on a single workstation with an Intel(R) Xeon(R) E5-1650 v3 CPU clocked
at 3.50GHz and 64GB memory. All experimental scripts for replicating the experiments can be found
in the supplementary materials alongside the library code base.

Results and discussion First and foremost, as can be seen in the AL performance curves of Figures
6 and 7, considerable performance gains can be made economically via AL. We can see comparable
results for models with far less annotated observations than those using the full dataset. The gains
are especially obvious in cold start settings as shown by the results obtained for the Glass dataset in
Figure 6c. However, we can also see that certain strategies bring beneﬁts later on such as the BALD
strategy in warm start Airfoil dataset (Figure 7b). As Tables 5 through 8 show, in equally many cases
AL does not bring any tangible beneﬁts compared to the baseline of randomly acquiring labels for
samples.

Assessment of the active learning strategies requires consideration of several factors acting in
conjunction: the dataset, the model class used, the way under which uncertainty is measured from
the model (if relevant for the informativeness measure), and obviously the strategy itself. Below we
discuss some of these considerations with reference to the results across Tables 5 to 8 and Figures 6
and 7.

The dataset and associated ML task have an effect on the AL performance through the model
as a task may be too simple to solve for a model — as is evident by the saturated and largely

19

non-differentiable IPAUC scores in SynthClass1 and SynthClass2 for the GPC. The converse may
also be true as demonstrated by the GPC’s inability to effectively improve its scores in the high
dimensional StriatumMini dataset. In these cases, the choice of AL strategy does little to change
performances. Properties of the dataset and model have strong effects on the query suggestions of the
informativeness measures. Uncertainty sampling methods can often be myopic and focus heavily on
samples near the decision boundary for discriminative models [5]. This is helpful in datasets where
representative instances have been labelled and the uncertainty sampling techniques may exploit the
models uncertainty around classiﬁcation boundaries to perform queries. On the other hand one can
imagine how this may be detrimental in regression datasets with many outliers far away from majority
of the dataset density that may be selected for annotation by uncertainty sampling techniques and
waste query budget. This is why random acquisition is such a good baseline for pool based sampling
scenarios as it naturally favours dense areas of the input space, whilst still having an element of
exploration to overcome initial label bias [23].

The choice of model affects strategies that utilise its notion of uncertainty to form informativeness
measures. For example, the Gaussian process estimators we have utilised for the experiments provide
principled measures of uncertainty. Meanwhile, a neural network can output class probabilities which
can then be used to derive uncertainty estimates for informativeness measures. However, this is
generally considered a poor uncertainty measure. Neural networks tend to produce pathologically
overconﬁdent predictions and struggle to quantify their uncertainty when applied on corrupted or
previously unseen data [73, 74]. Bayesian modelling [75] as we have done with the GPs provides
a theoretically rigorous approach to perform probabilistic inference also for deep neural networks.
Seemingly these Bayesian neural networks (BNNs) combine the best of both worlds - the modelling
complexity of a deep model augmented with uncertainty estimates through probabilistic inference
over the weights of the neural network. Unfortunately the high computational cost of performing
proper Bayesian inference restricts our use to using approximations. Many approximate Bayesian
inference methods exist — such as MCDropout [27] and SWAG [76] — and each bring their own
strengths, limitations, and hyperparameters that one can consider when assessing their downstream
effects on AL strategies. Strategies designed to operate on committees and ensembles of models
such as query-by-disagreement and query-by-committee algorithms work on similar principles and
the collective of models gives rise informativeness measures whose quality and characteristics are
dependent on its members.

As outlined in section 4 AL strategies can be deﬁned through compositions of informativeness
measures and query selection algorithms. Ultimately, the choice of strategy should be aligned with
the objective of the practitioner. One objective of the active learning strategy can be to exploit model
uncertainty to reduce classiﬁcation error. This is useful for ﬁne-tuning a model’s classiﬁcation bound-
ary and here uncertainty sampling techniques — such as the least conﬁdence, margin, and entropy —
succeed when ample representative data points are available as in the warm start conﬁguration of
Checkerboard2x2 in Figure 4b. Conversely, if the objective is to initially explore the input feature
space, the serial uncertainty sampling strategies we have created can struggle immensely compared
to random sampling baseline in Checkerboard2x2 cold start conﬁguration in Figure 4a. This occurs
as the myopic uncertainty sampling technique focuses its querying budget on reﬁning the model’s
classiﬁcation boundary between the two initially labelled instances instead of exploring across its
region of identically labelled areas diagonally across the plane. This can be overcome by adapting the
query selection algorithm to balance the maximal informativeness coming from the informativeness
function with another exploration utility measure. This interplay with informativeness measures,
query selection, and their compositions — along with the considerations we have discussed above —
give rise to the plethora of active learning strategies in literature and many yet unexplored avenues of
research.

20

Table 5: IPAUC scores on balanced accuracy scores on a cold-start task conﬁgurations. Highest mean
scores are bolded.

Classiﬁcation cold start IPAUC (balanced accuracy)

Random sampling Least conﬁdence Margin

Entropy

Representativeness

UCIParkinsons
UCIGlass
UCISeeds
StriatumMini
GaussianClouds
Checkerboard2x2
Checkerboard4x4
BreastCancer
SynthClass1
SynthClass2

0.7202±0.0752
0.9275±0.0250
0.8885±0.0318
0.4980±0.0000
0.5087±0.0068
0.7253±0.0366
0.5110±0.0086
0.8741±0.0145
0.9799±0.0148
0.9718±0.0093

0.7471±0.0928
0.9307±0.0277
0.8842±0.0329
0.4980±0.0000
0.5190±0.0150
0.6996±0.0066
0.5377±0.0138
0.8774±0.0181
0.9800±0.0149
0.9918±0.0019

0.7422±0.1000
0.9418±0.0203
0.8839±0.0346
0.4980±0.0000
0.5352±0.0325
0.6918±0.0087
0.5388±0.0103
0.8765±0.0201
0.9800±0.0151
0.9924±0.0023

0.7343±0.1030
0.9307±0.0278
0.8797±0.0310
0.4980±0.0000
0.5416±0.0250
0.6835±0.0109
0.5335±0.0076
0.8782±0.0185
0.9798±0.0150
0.9922±0.0022

0.6876±0.0639
0.7689±0.0372
0.8522±0.0454
0.4980±0.0000
0.4833±0.0152
0.5570±0.0409
0.4965±0.0120
0.6011±0.0160
0.9739±0.0122
0.7295±0.2045

Table 6: IPAUC scores on balanced accuracy scores on a warm-start task conﬁgurations. Highest
mean scores are bolded.

Classiﬁcation warm start IPAUC (balanced accuracy)

Random sampling Least conﬁdence Margin

Entropy

Representativeness

UCIParkinsons
UCIGlass
UCISeeds
StriatumMini
GaussianClouds
Checkerboard2x2
Checkerboard4x4
BreastCancer
SynthClass1
SynthClass2

0.7645±0.0753
0.9198±0.0470
0.8804±0.0524
0.4980±0.0000
0.6339±0.0067
0.7731±0.0228
0.5330±0.0153
0.8942±0.0133
0.9772±0.0058
0.9959±0.0002

0.7520±0.0749
0.9300±0.0487
0.8832±0.0473
0.4980±0.0000
0.6385±0.0097
0.9410±0.0249
0.5787±0.0214
0.9043±0.0152
0.9708±0.0082
0.9960±0.0000

0.7510±0.0751
0.9294±0.0476
0.8801±0.0495
0.4980±0.0000
0.6385±0.0097
0.9410±0.0249
0.5787±0.0215
0.9043±0.0152
0.9708±0.0082
0.9960±0.0000

0.7363±0.0692
0.9085±0.0430
0.8839±0.0482
0.4980±0.0000
0.6371±0.0111
0.9391±0.0285
0.5749±0.0195
0.9043±0.0152
0.9708±0.0082
0.9960±0.0000

0.7341±0.1007
0.7592±0.0581
0.8830±0.0477
0.4980±0.0000
0.6313±0.0053
0.7522±0.0607
0.5192±0.0149
0.8353±0.0307
0.9721±0.0105
0.9957±0.0006

Table 7: IPAUC scores on mean square error on a cold-start task conﬁgurations. The lowest average
mean square error is highlighted in bold.

SynthReg1
SynthReg2
UCIConcrete
UCIEnergy
UCIPower
WineQuality
UCIYacht
UCIAirfoil
Diabetes

Random sampling
3.8077±1.0611
13.3700±2.6140
1466.6133±71.6872
353.9005±30.3188
195496.1115±592.6507
26.3305±0.5950
191.1043±106.0610
11981.1223±248.5694
74877.8421±28927.1300

Regression cold start IPAUC (MSE)

Least conﬁdence
2.6635±0.5459
0.0695±0.0636
1472.8128±62.5106
289.1917±15.2118
198241.1702±733.1015
29.4237±0.4255
77.5529±5.6734
11891.0634±163.4600
14171.5626±2047.0813

BALD (Greedy)
2.6635±0.5459
0.0695±0.0636
1472.8371±62.4894
289.9866±16.1892
197934.2773±481.0792
29.6481±0.3058
77.5529±5.6734
11941.9477±120.2786
14171.5626±2047.0813

Expected Improvement
3.9732±1.6982
0.9258±0.7598
1474.8031±62.7577
368.2726±40.6429
195277.5576±874.4688
26.2508±0.7875
100.2691±32.6666
12129.1591±250.5744
42432.5783±8133.3468

Representativeness
19.5705±8.7593
500323.3267±95982.3408
1481.3249±63.4108
512.3891±25.3077
202216.1389±115.2624
30.1553±0.5857
257.9830±81.8572
14119.5660±290.1798
257918.0641±78686.9622

Table 8: IPAUC scores on mean square error on a warm-start task conﬁgurations. The lowest average
mean square error is highlighted in bold.

SynthReg1
SynthReg2
UCIConcrete
UCIEnergy
UCIPower
WineQuality
UCIYacht
UCIAirfoil
Diabetes

Random sampling
0.0922±0.1831
15.1984±7.6929
1418.5645±88.1003
264.0951±21.3812
148798.2169±1249.1972
22.2955±0.6630
84.8051±46.0703
9407.7984±329.1265
78962.3416±10136.6245

Regression warm start IPAUC (MSE)

Least conﬁdence
0.0138±0.0276
1.3826±0.8757
1424.9998±103.5379
189.2541±16.0807
151130.8620±1005.3887
24.3891±0.5978
38.1764±11.7308
8881.8400±265.1430
17453.1527±3539.8087

BALD (Greedy)
0.0138±0.0276
1.3826±0.8757
1424.9998±103.5379
189.2541±16.0807
151087.9637±1039.0975
24.3565±0.5937
38.1764±11.7308
8882.0060±266.4904
17453.1527±3539.8087

Expected Improvement
0.2684±0.5361
2.8461±2.5169
1429.0867±101.5682
257.9486±18.4998
148664.4422±1016.8802
22.7723±0.6329
154.5418±67.1644
9449.2188±160.0512
51879.1983±12366.5705

Representativeness
1.1291±2.2483
142.2482±120.9354
1426.0738±104.0563
352.7991±19.1642
152460.5149±1267.7397
24.3539±0.5861
178.9344±72.3744
10990.5605±270.7223
234665.9027±52643.9754

21

(a) Airfoil cold start

(b) Aifoil warm start

(c) Energy cold start

(d) Energy warm start

Figure 6: Plots of AL strategy performance on selected classiﬁcation datasets,

(a) Airfoil cold start

(b) Aifoil warm start

(c) Energy cold start

(d) Energy warm start

Figure 7: Plots of AL strategy performance on selected regression datasets.

22

