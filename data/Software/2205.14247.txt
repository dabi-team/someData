Ainur: A Framework for Repeatable End-to-End
Wireless Edge Computing Testbed Research

Manuel Olguín Muñoz∗

, Seyed Samie Mostafavi†
School of Electrical Engineering & Computer Science
KTH Royal Institute of Technology, Sweden
Email: {∗molguin, †ssmos, ‡vnmo, §jamesgr}@kth.se

, Vishnu N. Moothedath‡

, James Gross§

2
2
0
2

y
a
M
1
3

]
I

N
.
s
c
[

2
v
7
4
2
4
1
.
5
0
2
2
:
v
i
X
r
a

Abstract—Experimental research on wireless networking in
combination with edge and cloud computing has been the subject
of explosive interest in the last decade. This development has
been driven by the increasing complexity of modern wireless
technologies and the extensive softwarization of these through
projects such as a Open Radio Access Network (O-RAN). In
this context, a number of small- to mid-scale testbeds have
emerged, employing a variety of technologies to target a wide
array of use-cases and scenarios in the context of novel mobile
communication technologies such as 5G and beyond-5G. Little
work, however, has yet been devoted to developing a standard
framework for wireless testbed automation which is hardware-
agnostic and compatible with edge- and cloud-native technologies.
Such a solution would simplify the development of new testbeds
by completely or partially removing the requirement for custom
management and orchestration software.

In this paper, we present the ﬁrst such mostly hardware-
agnostic wireless testbed automation framework, Ainur. It is
designed to conﬁgure, manage, orchestrate, and deploy workloads
from an end-to-end perspective. Ainur is built on top of cloud-
native technologies such as Docker, and is provided as FOSS
to the community through the KTH-EXPECA/Ainur repository
on GitHub. We demonstrate the utility of the platform with a
series of scenarios, showcasing in particular its ﬂexibility with
respect to physical link deﬁnition, computation placement, and
automation of arbitrarily complex experimental scenarios.

I. INTRODUCTION

Experimental research in the area of wireless networking
has received ever increasing attention over the last years,
driven, on the one hand, by the complexity of modern net-
worked systems and corresponding applications. On the other,
networked systems are more and more based on software
instead of dedicated hardware, which allows experimental
testbeds to be rededicated simply through an update as system
versions evolve — in contrast to the redeployment of hardware
necessitated 10–15 years ago. The complexity of these sys-
tems, as well as their softwarization are expected to continue
growing, driving in turn an expanding interest in testbed-based
experimental research in wireless systems.

Over the last years, several small- to mid-scale testbeds have
emerged that leverage a large degree of freedom with respect
to hardware and software, for example the 1) COSMOS,
2) POWDER, and 3) Drexel Grid Software-Deﬁned Radio
(SDR) testbeds. COSMOS (Cloud enhanced Open Software
deﬁned MObile wireless testbed for city-Scale deployment) is
a testbed spanning an area of roughly 1 square mile (2.6 km2)
featuring SDRs, mm-wave equipment, optical ﬁbers, cloud

integration, and compute for core network functionality and
application data processing [1, 2]. It contains over 200 rooftop,
intermediate, and mobile nodes, and is controlled and managed
by a central node. COSMOS relies on the ORBIT Management
Framework (OMF) (originally developed for ORBIT [3]), and
employs the OMF Experiment Description Language (OEDL),
a domain-speciﬁc imperative language based on Ruby, for
experiment development and deﬁnition.

POWDER (Platform for Open Wireless Data-driven Ex-
perimental Research) promises research on wireless and mo-
bile networks with a level of programmability down to the
waveform [4]. The testbed spans a 15 km2 area and features
about 15 ﬁxed programmable radio nodes, based on off-the-
shelves SDRs and featuring edge-like compute capabilities and
integration with cloud resources, which interact with 50 mobile
nodes. POWDER experiments are deﬁned and developed in
proﬁles, which correspond to Virtual Machine (VM) images
containing the necessary software and conﬁgurations. These
proﬁles are deﬁned through using Resource Speciﬁcation
(RSpec)1 documents.

Finally, the Drexel Grid SDR Testbed features SDRs that
connect either over-the-air, through a channel emulator, or
over a combination of the two,
to facilitate realistic and
reproducible experimentation [5]. Primarily intended for SDR-
centric research, it does not integrate any core, cloud or edge
components. However, the testbed extensively employs the
LinuX Containers (LXC) runtime for the deployment of both
experimental code and SDR software, which affords users
great freedom when it comes to development of experiments.
Experimentation is key to to fully understanding the impli-
cations of next-generation wireless systems, cloud, and edge
computing paradigms, and thus more of these testbeds are
sure to emerge in the near future. Yet, little work has so far
been devoted to general-purpose, hardware-agnostic software
frameworks for the management and automation of such sys-
tems. Existing platforms implement their own, ad-hoc software
solutions which are not compatible with other testbeds, and in
many cases are not even compatible with reigning cloud-native
standards. This is, for instance, the case with COSMOS and
POWDER; their reliance on domain-speciﬁc languages limits
their integration with cloud-native solutions, which generally
build upon general-purpose languages such as Python and Go.

1https://groups.geni.net/geni/wiki/GENIExperimenter/RSpecs

 
 
 
 
 
 
These testbeds further leverage virtualization technology based
on VMs instead of more lightweight and edge-compatible
solutions such as containers.

To the best of our knowledge, CloudRAFT [6] is the only
work to tackle (to a certain extent) this challenge. CloudRAFT
corresponds to a cloud-based framework for mobile network
experimentation, with a focus on simplifying the management
of testbed resources. The goal of this project is to integrate,
coordinate, share, and improve upon existing testbeds, and
employs pre-built VMs containing the necessary software
for experiments. Although it provides some automation for
testbed resource provisioning and experiment execution, its
focus is largely rather on the sharing and partitioning of testbed
systems. Testbeds currently working with CloudRAFT include
a variety of domain-speciﬁc setups, including an SDR-based
testbed as a well as a ground vehicular robot for mobility-
related experimentation.

In this work, we present our solution to the challenge of
testbed automation: Ainur, a framework for wireless testbed
automation with a speciﬁc focus on end-to-end experimental
research in the context of edge-computing using cloud- and
edge-native technologies. Ainur is designed to deploy exper-
imental runs from a workload perspective by conﬁguring the
physical testbed, initializing all involved software components,
deploying and executing the experimental workload, collecting
logs and data, and ﬁnally gracefully degrading the system. The
framework allows for dynamic, software-deﬁnition of physical
and logical links, network topology, cloud and edge computing
resources, as well as experimental workload deployment and
orchestration. It heavily leverages cloud-native technologies,
such as Docker containers, in order to supports a wide variety
of different testbed hardware setups and experimental conﬁg-
urations and workloads, as well as to be as easily extendable
as possible. Furthermore, we make Ainur available to the
community as Free and Open Source Software (FOSS). It
can be obtained from the KTH-EXPECA/Ainur repository on
GitHub [7], released under an Apache version 2.0 license.

The rest of this paper is structured as follows. Section II
presents the framework as well as the key concepts and
technologies supporting its design and architecture. This sec-
tion also discusses brieﬂy the assumptions made about the
underlying hardware on which the framework is set to run,
and we present an overview of our experimental testbed. Next,
Section III describes two demonstration procedures through
which we will showcase the ﬂexibility and potential of this
tool for the automatic, repeatable, end-to-end experimentation
in the context of wireless testbeds. Finally, in Section IV we
summarize our contributions and conclude this paper.

II. THE AINUR FRAMEWORK

Ainur is designed as an end-to-end wireless network testbed
management framework, fully ﬂexible in terms of the commu-
nication network stack, computation hosts, and the distributed
application deployed on top. The core goal of the framework
is to facilitate the creation of the desired communication
and computation elements to discover their implications to

Fig. 1: Layered structure of an Ainur experiment

the performance of end-to-end distributed applications. Ainur
achieves this by offering a Python Application Programming
Interface (API) which is used to describe an end-to-end
experiment in a procedural manner, and we plan to eventually
provide toolkits for declarative conﬁguration of experiments.
Conceptually, in Ainur, an experiment is decomposed into
a layered structure, consisting of 1) the distributed application
(workload); 2) computation hosts; and 3) communication
networks connecting the hosts. In Figure 1, the workload
is represented by a client-server process pair. These could
correspond, for instance,
to the emulation of an inverted
pendulum and a matching controller. However, Ainur makes
no assumptions about the nature of the workloads deployed
on the framework, and virtually any process or combination
of processes can be used.

Hosts correspond to either bare-metal machines or cloud
instances on Amazon Web Services (AWS) Elastic Compute
2 (EC2). Users are free to combine and interconnect these
in any conﬁguration. Ainur can provision wired networks
over Ethernet, and supports a number of software-deﬁned
wireless communication stacks, currently including WiFi, 4G
Long-Term Evolution (LTE), and 5G. To realize these various
wireless communication protocols,
the
testbed is equipped with Universal Software Radio Peripheral
(USRP) SDRs and some computation hosts dedicated to signal
processing and/or radio management.

is assumed that

it

To collect data from workloads, Ainur conﬁgures both
a shared, distributed, storage location which all processes
can reach, as well as a logging service which automatically
captures structured and unstructured data from the standard
output of workload processes. The logging service additionally
collects data from the other two layers, and the resulting
dataset could, for instance, be analyzed to relate the perfor-
mance of the control loop to the quality of the wireless link.

A. Ainur Software Stack

To realize our vision for an automated, ﬂexible, cloud-
native, and workload-agnostic framework for cloud and edge
computing experimentation, we built Ainur on top of a com-
bination of well-established tools and frameworks. Below we
brieﬂy touch on the most important of these:

Fig. 2: Lifecycle of an experimental run in Ainur. Blocks in orange are optional.

Fig. 3: Network structure assumed by Ainur.

Python: Ainur is built on-top of Python 3.8. We chose this
language for its ﬂexibility, ease of prototyping, and
for the extensive ecosystem of third-party cloud-native
frameworks and libraries.

Ansible: One of the “cloud-native frameworks” mentioned
above, Red Hat Ansible is a powerful Python framework
for bare-metal conﬁguration, provisioning, and automa-
tion. We use it extensively in Ainur for conﬁguration of
network interfaces and services on managed hosts.
Containers: We leverage Docker containers to great extent
for the virtualization and orchestration of workloads, as
well as the encapsulation and management of complex
network conﬁgurations. See Section II-C for more details.
AWS and boto3: Ainur employs the Amazon boto3 li-
brary for Python to directly interface with AWS EC2 and
deploy, conﬁgure, and manage remote cloud instances.

OpenAirInterface (OAI): OAI is an open-source project that
implements 3GPP technology on general purpose x86
computing hardware and off-the-shelf SDRs like the
USRP [8]. Ainur can deploy, conﬁgure, and manage OAI
software components that implement 4G LTE and 5G
New Radio (NR).

Mango Communications 802.11: Finally, the Mango Com-
munications project implements real-time 802.11 (WiFi)

MAC and PHY in Xilinx Field-Programmable Gate Ar-
rays (FPGAs). It can be used on a variety of hardware
platforms including USRP SDRs, and is employed in
Ainur to provision end-to-end WiFi links.

B. Main Software Components

Ainur follows a layered architecture which closely mimics
the conceptual layers of the TCP/IP stack. Components are
deployed in bottom-up order, starting with the establishment of
physical links, through the establishment of Internet Protocol
(IP) connectivity and deployment of links to the cloud, and
ending with the distribution and initialization of workloads
on top of a container orchestration layer. The architectural
modules of the framework can broadly be classiﬁed according
to the below categories:
Conﬁguration Layer: The lowest layer of Ainur, it handles
parsing of conﬁguration ﬁles describing experimental
scenarios. Optional, as it is only needed when Ainur is
running experiments described in a declarative manner.

Logging layer: This layer handles logging across all layers of
the system to a central repository. Concretely, it manages
the conﬁguration and lifecycle of a Fluentd server to
which any component
in the network can send logs.
Currently,
the two main components relying on this
scaffolding are the physical layer and the workloads.

Physical Layer: Creates and deploys the underlying physical
connections of the workload data network. This layer
interacts with hardware such as managed switches and
SDRs (and their associated computation hosts) to create
links between the desired workload hosts. These links
correspond to ethernet, WiFi, and even an entire software-
deﬁned 4G LTE and 5G networks.

Cloud Layer: Handles integration with cloud services (cur-
rently, AWS EC2). Only deployed in the case of an
experiment requiring cloud instances,
it manages the
instantiation and conﬁguration of remote cloud resources.
IP Layer: Conﬁgures and establishes IP layer connectivity
of packets between hosts in the experimental setup,
both local and cloud. This includes assigning valid IP
addresses to hosts, establishing Virtual Private Network
(VPN) routes to cloud instances through a pair of pre-
conﬁgured VPN gateways, and conﬁguring routing tables
to ensure any two hosts in the workload network can
communicate with each other.

Workload Layer: Finally, this layer deploys, scales, and or-
chestrates containerized workloads, as well as conﬁgures
a shared, distributed storage for workloads to store data.
This components leverages Docker Swarm to spin up
and manage workload containers on desired hosts. It
also establishes overlay networks abstracting away the
physical topology and allowing containers to interconnect
through dynamically assigned hostnames.

As a ﬁnal point,

network stack can run on general-purpose processors. They
can thus be containerized and distributed across multiple hosts.
the automation of logging is another
advantage of using containers and an orchestration framework.
Ainur employs the Fluentd uniﬁed layer for log collection.
It natively integrates with Docker containers and allows for
the automatic collection of text data from the standard output
and error streams of processes executing inside containers. It
automatically decouples data sources from containers running
on different systems and allows Ainur to collect and classify
the logs from any components of the network, whether on the
wireless stack or workload.

D. General assumptions

Ainur makes a number of assumptions about its execution
environment. Apart from generic ones regarding the presence
of necessary authentication information for remote access to
local and remote hosts and services, the framework assumes
a split network architecture such as the one depicted in
Figure 3. Ainur runs in a dedicated control host and the
management plane resides in a physically distinct network
from the workload data. This is a key requirement to be able
to reconﬁgure the physical links in the workload data network
without disrupting management trafﬁc. Also assumed is the
existence of VPN gateways to the cloud, time synchronization,
and conﬁgured hostname lookups (possibly using a Domain
Name System (DNS) service).

C. Containerization

E. Obtaining Ainur

Containers are a key cloud-native technology for the vir-
tualization and sandboxing of arbitrary processes [9]. They
allow for easy packaging of software in predeﬁned, consistent,
and conﬂict-free execution environments, including all nec-
essary dependencies. Containers are lightweight and portable
compared to VM-based virtualization, making them an ideal
solution for the distribution, deployment, and orchestration of
software in distributed computing environments. They deploy
quickly and are very conﬁgurable, while abstracting away the
complexities and delays that come with in creating, managing,
and moving (potentially huge) VM disk images.

Ainur

leverages containerization extensively across the
framework, in order to 1) deploy and orchestrate workloads,
2) support a wide spectrum of different physical layer con-
ﬁgurations out-of-the-box, as well as allow for easy exten-
sion to new ones, and 3) support automated collection of
logs. Workloads in the framework are deployed packaged in
Docker containers, orchestrated through docker-compose
and Docker Swarm. This allows the framework to remain
mostly agnostic to the nature of the workloads, and thus
support a wide ranged of different applications and system
architectures. It also allows for easy deployment to different
compute nodes in the network, without having to take into
consideration details such as required libraries and versions.
As expressed above, Ainur also leverages containers for the
communication stack. With the advent of Open Radio Access
Network (O-RAN) and SDRs, all components of the wireless

The framework is released as Free and Open Source Soft-
ware under a permissive Apache license. It can be down-
loaded from the Ainur repository [7] of the KTH-EXPECA
organization on GitHub. Given the software’s complexity,
the repository also includes detailed documentation on its
requirements, conﬁguration, deployment, and execution, as
well as links to external resource containing information and
guides about related concepts and services.

III. DEMO

In this demo, we will show the ﬂexibility of Ainur for
running end-to-end experimental workloads on both the Edge
and the Cloud. This will be done interactively, and members of
the audience will be invited to propose testbed conﬁgurations.
Figure 4 illustrates the possible conﬁgurations for the
testbed. Workloads are deployed on client hosts, and com-
putation is ofﬂoaded either to an edge server (cloudlet), or to
AWS EC2 instances on the cloud. Communication between
the client- and server-sides of the workload will occur over
one of three possible physical link layer setups:
WiFi: an SDR is conﬁgured as an IEEE 802.11n access point,
and client hosts connect to it using on-board WiFi.
4G LTE: an SDR is conﬁgured as an 4G LTE base station,
and another is conﬁgured as an 4G LTE User Equipment
(UE). Together these radios act as an LTE bridge between
the client-side and the server-side of the network, and all
client-server trafﬁc is routed through them.

Fig. 4: The possible workload ofﬂoading setups and physical layer conﬁgurations used in the demo. Not pictured, in Phy
Option 2: 1) SDR processing hosts; and 2) additional base-station host for the Core Network and Evolved Node B (eNodeB).

(a) Workload 1: MNIST image classiﬁer

(b) Workload 2: inverted pendulum NCS

Fig. 5: Demonstration workloads

Ethernet: connects everything through plain ethernet.

The number of workload instances (and therefore client
hosts) deployed in each execution of this demonstration will
range from 1 to 10. Workloads deployed to the cloud will be
able to target any of AWS’s datacenters.

We will employ two different workloads for this demon-
stration, illustrated in Figure 5. The ﬁrst of these (Figure 5a)
consists of a proof-of-concept web application which imple-
ments a simple classiﬁer to identify hand-drawn digits from
the widely-used Modiﬁed National Institute of Standards and
Technology (MNIST) dataset [10]. The application consists
of a client with a web interface, and a Hyper-Text Transfer
Protocol (HTTP) server which responds to requests from
the client and performs the actual image recognition. This
workload is intended to showcase in an interactive manner

the effects of placing computation at different points of the
network, and how Ainur simpliﬁes these deployments.

The second workload (Figure 5b) corresponds to a Net-
worked Control System (NCS) balancing an inverted pendu-
lum, implemented on a software framework for the emulation
of NCSs using cloud-native technologies [11]. It consists of an
emulation of the physical inverted pendulum system plant and
a software-implemented proportional-differential controller.
These components communicate with each other over the User
Datagram Protocol (UDP). This workload will be used to
showcase the utility of Ainur for automating the execution of
batches of experiments potentially including multiple different
clients, servers, and physical layers.

A. Testbed Setup

This demonstration will be performed on a testbed con-
sisting of 1) 10 Raspberry Pi 4 Model B boards, acting as
client-side workload hosts; 2) a Raspberry Pi 4 Model B acting
as VPN gateway for the workload network; 3) a Raspberry Pi 4
Model B acting as VPN gateway for the management network,
as well as hosting the necessary Network Time Protocol (NTP)
and DNS server software; 4) a i386 workstation, acting
as an edge-side workload host; 5) a conﬁgurable number
of AWS EC2 cloud instances acting as cloud servers; and
ﬁnally 6) a separate i386 workstation hosting the Fluent
server and on which Ainur is deployed as well. These nodes
are interconnected using a combination of managed switches,
SDRs, and VPN gateways; please refer to Figure 3 for an
architectural overview of this setup.

B. Demo Procedure

1) Workload 1: Participants will be asked to choose 1) a
location to ofﬂoad computation to (local (i.e. no ofﬂoading),
edge, or any AWS datacenter); and 2) a physical layer for the
ﬁrst hop of the network (WiFi, 4G LTE, or Ethernet). Through
the Ainur command line, we will deploy a single client-server

We have described its general architecture, which follows
a layered design mimicking the network stack layers the
framework directly interacts with, as well as the underlying
assumptions about its deployment environment and speciﬁc
requirements for its deployment.

Finally, we have outlined a demonstration which showcases
the ﬂexibility and power of the framework by deploying
two different workloads to our testbed. We show how Ainur
deployment of these to different points in the network, as well
as how the framework makes possible repeatable, large-scale
experimentation in distributed systems.

We believe our framework represents an important step
towards repeatable, replicable, yet low-access barrier end-to-
end wireless testbed experimentation. It has been released as
FOSS and can be found on GitHub [7].

REFERENCES
[1] Dipankar Raychaudhuri et al. “Challenge: COSMOS: A City-
Scale Programmable Testbed for Experimentation with Ad-
vanced Wireless”. In: Proceedings of the 26th Annual Inter-
national Conference on Mobile Computing and Networking.
Association for Computing Machinery, 2020.
Jiakai Yu et al. “COSMOS: Optical Architecture and Proto-
typing”. In: 2019 Optical Fiber Communications Conference
and Exhibition (OFC). 2019, pp. 1–3.

[2]

[4]

[3] M. Ott et al. “ORBIT testbed software architecture: supporting
experiments as a service”. In: First International Conference
on Testbeds and Research Infrastructures for the DEvelopment
of NeTworks and COMmunities. 2005, pp. 136–145.
Joe Breen et al. “POWDER: Platform for Open Wireless
Data-driven Experimental Research”. In: Proceedings of the
14th International Workshop on Wireless Network Testbeds,
Experimental Evaluation and Characterization (WiNTECH).
Sept. 2020.

[5] Kapil R. Dandekar et al. “Grid Software Deﬁned Radio Net-
work Testbed for Hybrid Measurement and Emulation”. In:
2019 16th Annual IEEE International Conference on Sensing,
Communication, and Networking (SECON). 2019, pp. 1–9.

[6] Sabarish Krishna Moorthy et al. “CloudRAFT: A Cloud-
based Framework for Remote Experimentation for Mobile
Networks”. In: 2022 IEEE 19th Annual Consumer Communi-
cations Networking Conference (CCNC). 2022, pp. 1–6.
[7] Ainur GitHub Repository. URL: https : / / github . com / KTH -

EXPECA/Ainur.

[8] Florian Kaltenberger et al. “OpenAirInterface: Democratizing
innovation in the 5G Era”. In: Computer Networks 176 (2020),
p. 107284. ISSN: 1389-1286. URL: https://www.sciencedirect.
com/science/article/pii/S1389128619314410.

[9] Dirk Merkel et al. “Docker: lightweight linux containers for
consistent development and deployment”. In: Linux journal
2014.239 (2014), p. 2.

[10] Li Deng. “The MNIST Database of Handwritten Digit Images
for Machine Learning Research [Best of the Web]”. In: IEEE
Signal Processing Magazine 29.6 (2012), pp. 141–142.
[11] Manuel Olguín Muñoz et al. “CLEAVE: Scalable and Edge-
Native Benchmarking of Networked Control Systems”. In:
Proceedings of the 5th International Workshop on Edge Sys-
tems, Analytics and Networking. Association for Computing
Machinery, 2022, pp. 37–42.

Fig. 6: Screenshot of the user interface of demo workload
1. After deciding on placement of the compute backend and
the type of physical
layer connecting client and backend,
participants will use this interface to interact with the system.

pair according to the speciﬁcations. Next, participants will be
able to access the client web interface and interact with the
server by requesting classiﬁcation of images from the MNIST
database. The server will respond to these, and the assigned
labels will be visible on the web interface together with timing
statistics for each request, see Figure 6.

2) Workload 2: Participants will be asked to specify the
full, arbitrarily complex, experimental scenario, including the
number of clients, physical layers (single or multiple, and
which clients are on each physical
link), and ofﬂoading
conﬁguration (number of instances on the edge vs. on the
cloud, which AWS datacenters to deploy to). Conﬁguration
will be speciﬁed through a YAML ﬁle, which will then be
parsed by Ainur for the automatic execution of the scenario.

IV. CONCLUSION

In this paper, we have introduced the Ainur framework
for repeatable end-to-end testbed automation in the context
of wireless networking and edge computing research. The
framework simpliﬁes the execution and veriﬁcation of end-
to-end experimentation in these testbeds by automating the
1) establishment of physical links between hosts, including the
conﬁguration of complex wireless systems such as 4G LTE
and 5G; 2) provisioning of and connection to remote cloud
instances; 3) initialization of IP layer connectivity between
hosts; 4) collection of logs and data; and 5) deployment,
scaling, and lifecycle management of containerized processes.

