Hydra: Hybrid Server Power Model

Nigel Bernard1, Hoa Nguyen1, Aman Chandan2, Savyasachi Jagdeeshan2,
Namdev Prabhugaonkar2, Rutuja Shah2, Hyeran Jeon1
1University of California Merced, 2San Jose State University

2
2
0
2

l
u
J

0
2

]

C
D
.
s
c
[

1
v
7
1
2
0
1
.
7
0
2
2
:
v
i
X
r
a

Abstract—With the growing complexity of big data workloads
that require abundant data and computation, data centers
consume a tremendous amount of power daily. In an effort
to minimize data center power consumption, several studies
developed power models that can be used for job scheduling
either reducing the number of active servers or balancing
workloads across servers at their peak energy efﬁciency points.
Due to increasing software and hardware heterogeneity, we
observed that there is no single power model that works the best
for all server conditions. Some complicated machine learning
models themselves incur performance and power overheads and
hence it is not desirable to use them frequently. There are no
power models that consider containerized workload execution.
In this paper, we propose a hybrid server power model, Hy-
dra, that considers both prediction accuracy and performance
overhead. Hydra dynamically chooses the best power model
for the given server conditions. Compared with state-of-the-art
solutions, Hydra outperforms across all compute-intensity levels
on heterogeneous servers.

Index Terms—Server Power Model, Containerized Workloads,

Deep Learning

I. INTRODUCTION

In 2020, data centers in the USA consumed 91 billion
electricity units (kW/h) yielding $13 billion per year for
electricity bills in the business sector. Some of the world’s
largest data centers can each contain many tens to thousands
of computing devices and require more than 100 megawatts of
power capacity, which is enough to power around 80,000 U.S.
households. The signiﬁcance of maximum energy efﬁciency in
data centers cannot be overstated.

To reduce such an excessive data center power usage,
several solutions have been proposed. Some studies demon-
strated dynamic load control algorithms that either reduces the
number of active servers by consolidating workloads to fewer
servers [1] or balances the loads across servers such that all
servers can run under the peak energy efﬁciency point [2].
Most of these studies used either CPU utilization or linear
or polynomial power prediction models to ﬁnd the migration
triggering point. The server power prediction models use CPU
utilization as the main or even the only parameter as CPU
utilization is known to be highly correlated with overall system
power consumption. However, under increasing heterogeneity
in both software and hardware [3], there is no single model
that rules all possible server conﬁgurations. For example,
unlike many conventional analytical models assumed, CPU
is no longer the only signiﬁcant power consumer in server
systems. In big data era, heavy memory usage is an in-
evitable computing pattern. Likely, accelerators and virtualized
computing environments have notable impacts towards server

Fig. 1: Prediction Errors w.r.t. Memory Intensity

power consumption. Therefore,
utilization-based server power management is questionable.

the effectiveness of CPU-

Figure 1 shows the prediction accuracy of three CPU-
utilization-based power models with regarding to memory
intensity of applications in root mean square error (RMSE).
The models are brought from a power modeling study in cloud
simulation frameworks [4]. The models use the linear, the
square, and the square root of CPU utilization to the following
model for power prediction, where α value is 1, 2, 1/2 for
linear, square, and square root models, respectively.

Server P ower = Pmin + (Pmax − Pmin) × U tilα

CP U

Across all the models, the error rate raises almost exponen-
tially as the memory intensity increases, where the averaged
power prediction error for the high memory intensive applica-
tions is greater than 30 Watts, which is not negligible.

To accommodate the hardware heterogeneity, some studies
included non-compute components such as memory, storage,
and network for the power modeling [5]–[7]. However, it is not
easy to include new parameters to existing analytical models
and ﬁnd the optimal weight values, which requires signiﬁcant
engineering efforts. Furthermore, adding more parameters to
the existing analytical models is not a scalable solution given
the ever-increasing system heterogeneity. For a hassle-free
model development, some recent studies adopted machine
learning algorithms [8], [9]. To reﬂect non-linear impact of
various system parameters towards server power consumption,
some other researchers used deep learning algorithms [10]–
[12]. These studies used tens of system parameters and the
corresponding server power values collected for days even
months of time to train a power prediction model. These mod-
els show superior accuracy than many conventional models.
However, given the inherent compute intensity of machine
learning algorithms, machine learning-based power models
themselves may cause performance and power overhead. Our
experiments show that a deep learning model takes at least

05101520253035123RMSEMem IntensityLinear ModelSquare ModelSquare Root Modellow                                high 
 
 
 
 
 
25× longer latency and consumes 3 ∼ 50× more power than
a polynomial model. Therefore, the usage of those compute-
heavy power models should be carefully determined so that
the models can be used only when necessary.

To mitigate the aforementioned limitations of existing power
models, we propose a novel hybrid server power model
namely Hydra that tackles both the accuracy deﬁciencies of
conventional analytical models and the computational over-
head of machine learning-based models. Hydra incorporates
a lightweight server workload classiﬁer that selects the best
power model that considers both performance overhead and
prediction accuracy. In our experiments conducted in a small-
scale data center that consists of heterogeneous servers, Hydra
showed the superior prediction accuracy and less performance
overhead for various workload sets consisting of different
compute and memory intensity compared to several state-of-
the-art power models.

II. RELATED WORK AND MOTIVATION

A. Machine Learning for Server Power Prediction

Shen et al. [8] used recurrent neural network (RNN) for
the server power prediction, especially by using long short-
term memory (LSTM) algorithm. They used LSTM for future
power of different time granularity: immediate (next second)
and further future (next 30 seconds). Li et al. [11] used
recursive auto-encoder (RAE) to predict server power by using
power history data, per-server system counters, and total power
draw of a data center. Lin et al. [12] evaluated four artiﬁcial
neural network (ANN) power models including time window
back propagation neural network (TWBPNN) that considers
both power history and system parameters. They used 16
system parameters. Most of the studies did not clearly reveal
the correlation between the parameters and server power. Also,
all of them used bare-metal workload executions that are
not common in data centers today. Unlike these studies, we
provide a clear correlation between system parameters and
the server power consumption, which enables to extract the
minimum number of parameters and we consider containerized
execution, which is more realistic to the current data center
conﬁguration.

B. Why Do We Need Another Power Model?

Though server power modeling has been extensively stud-
ied, due to the increasing heterogeneity in both hardware and
software, the effectiveness of existing models would be dimin-
ished. For example, we already showed with Figure 1 that CPU
utilization-based server power models derive high error rate as
workloads’ memory intensity increases. Virtualized workload
executions with containers also drops accuracy of existing
power models. Figure 2 shows the results when ﬁve instances
of an application are executed with a ﬁxed interval (a) without
container and (b) with container. Some parameters show clear
impact of each application instance with staircase-patterned
increasing graph (i.e., CPU freq. in both containerized and
uncontainerized executions). But, for some other parameters
such as software interrupts and cache miss ratio, it is hard to

(a) Un-containerized Execution

(b) Containerized Execution

Fig. 2: System Param Correlation with/without Container
while increasing the number of streamcluster from PARSEC
instances from 1 to 5 (Y-axis : parameter, x-axis : time).

tell when new application instance is invoked, due to shared
helper processes used by containers, which lead to a much
loose correlation between individual workloads and server
power consumption.

Some studies used processor-provided power proﬁlers in-
stead of power models, such as Intel’s RAPL. RAPL power
values are known to be highly accurate in newer CPUs. How-
ever, according to our experiments, RAPL data does not reﬂect
server power consumption because it only shows the processor
power. Figure 3 shows the ratio of server power to RAPL
measurements while running different type workloads on two
different Intel CPUs. In each pair of graphs, the left shows
wall power-to-RAPL ratio during the workload execution and
the right shows the relation between the wall power and
RAPL. If RAPL can substitute server power models, any of
the following two conditions should be satisﬁed: 1) the left
graphs show a consistent value, 2) the right graphs show a clear
trend line. However, none of the results show such relation.
The irregularity is more severe with non-compute workloads
and older CPU models. Though some studies explored ways
to predict server power model by using RAPL result as a
parameter [13], given the high irregularity between the server
and RAPL power, we believe it is not effective to use RAPL
to predict server power model. Therefore, we believe a new
server power model is needed that can easily scale with
increasing heterogeneity.

III. HYDRA, THE SERVER POWER MODEL

The proposed power model, Hydra, considers not only ac-
curacy but also performance overhead by selecting an optimal
model for the given server condition rather than sticking to
one certain model every time. To use the optimal model,

Un‐Containerized Execution of Streamcluster1~56001100160021001285582109136163190217CPU Frequency0102030125497397121145169193217CPU Util182000018400001860000188000019000001316191121151181211Shared Mem Usage01000200030004000125497397121145169193217Software Interrupts00.511.5125497397121145169193217Cache Miss Ratio300350400125497397121145169193217# ProcessesContainerized Execution of Streamcluster1~5600110016002100122436485106127148169CPU Frequency010203012039587796115134153172CPU Util18500002050000225000024500000100200Shared Mem Usage01000200030000100200Software Interrupts00.511.50100200Cache Miss Ratio3003504000100200# of Processes(a) Intel Xeon Cascade Lake-SP Silver-4214

(b) Intel Xeon Sandy Bridge-EP E5-2620

Fig. 3: Wall Power vs. RAPL measurements on Two CPU
Generations

(a) Compute-intensive Workloads (Concurrent executions of
CPU Stress Tests of Stress-NG benchmark suite)

(b) Non-compute-intensive Workloads (Concurrent executions
of canneal, streamcluster, swaptions, and raytrace of PARSEC
benchmark suite)

Fig. 4: System Parameters (x-axis) Correlation with Server
Power (y-axis in Watt): Gray dots - real measurements. Black
lines - trend lines. CORRE - Pearson’s correlation.

Hydra implements 1) a power model selector that monitors
the current system statistics of the target server, classiﬁes the
server condition to be mapped to one (or multiple) candidate
power models that show good accuracy in similar conditions,
and chooses one power model that has the lightest performance
overhead, and 2) a power predictor that estimates the server
power consumption by feeding the system statistics to the
selected power model.

Power Model Selector: Though more complex models
may show better accuracy regardless the system conditions, as
we also consider performance overhead, it is not that simple to
ﬁnd the best power model. For example, a lightweight CPU-

utilization-based analytical model may derive good-enough
accuracy when the server runs mostly compute-intensive work-
loads, while a complex machine learning model may be
required when the server runs a combination of various types
of workloads at the cost of performance. Likely, for machine
learning models, different algorithms show diverse accuracy
for different server conditions. For example, RNN would be
better for the servers that show regular patterns over time
while fully-connected deep neural network (DNN) may be
better for those that cannot clearly expect workload types and
scheduling times. Therefore, we propose to develop a power
model selector that identiﬁes a power model that will show the
best accuracy for the given server condition with the lightest
performance overhead. As the selector itself should not incur
extra performance overhead, we use a lightweight regression
model. While different algorithms may work better depending
on server power pattern and candidate power models, we
chose to use a random forest model that is trained with over
2K workload datasets (containing system statistics and power
measurements for various compute intensities) as it showed
superior selection accuracy than other tested algorithms such
as decision tree and k-nearest neighbor models in our experi-
ments. The random forest model chooses one of the candidate
power models based on current system statistics. Note that
system statistics themselves (e.g., CPU utilization and memory
usage) are not sufﬁcient to select the best power model because
in many cases server conditions are not clearly distinguishable
with one or two system stats and individual models show
diverse accuracy for different server conditions.

Server Power Predictor: Though types of power models
can vary, we used two extreme models, an analytical model
for the minimal overhead and a machine learning model for
the best accuracy. For the analytical model, we examined
various existing models and chose the linear model because
the model showed comparable accuracy with the best per-
formance as shown in Figure 1. For the machine learning
model, it is important to carefully identify an algorithm that
well represents the server power from system parameters. To
understand the diverging contributions of individual system
components towards the server power, we examined 28 system
statistics and the server power consumption while running
two distinctive sets of workloads. The system statistics were
collected by using two Linux commands, perf and psutil.
Figure 4(a) shows the statistics of representative parameters
while running compute-intensive workloads and Figure 4(b)
shows the same statistics of non-compute-intensive work-
loads. For the compute-intensive workloads, we used Stress-
NG benchmark suite, while, for the non-compute-intensive
workloads, we ran four applications of PARSEC benchmark
suite concurrently that have high misses per kilo instructions
(MPKI). All workloads were containerized to make the conﬁg-
uration realistic to server systems. In each graph, y-axis is the
server power consumption and x-axis is the scale of the target
system parameter. The numbers in the graph are Pearson’s
correlation coefﬁcient between the parameter and the server
power consumption. The gray dots are real measurements and

RAPL vs. Wall (Gimbap: CPU)00.511.522.5154107160213266Wall‐to‐RAPL RatioTime01234180159238317396475Wall‐to‐RAPL RatioTime(a) Compute-intensive(b) Non-compute-intensive0204060801000100200RAPL (PKG + DRAM) (W)Wall Power (W)0501001500100200RAPL (PKG + DRAM) (W)Wall Power (W)RAPL vs. Wall (kraken: CPU)01234514895142189236283Wall‐to‐RAPL RatioTime0501001500100200RAPL (PKG + DRAM) (W)Wall Power (W)02461124247370493616739Wall‐to‐RAPL RatioTime0501001500100200RAPL (PKG + DRAM) (W)Wall Power (W)(a) Compute-intensive(b) Non-compute-intensiveParams cpu0501001502001000150020002500CPU Frequency05010015020002000000040000000Shared Mem Usage05010015020000.20.40.6Cache Miss Ratio050100150200340360380400# Processes0501001502000200004000060000Software InterruptsCORRE = 0.74CORRE = 0.83CORRE = ‐0.32CORRE = 0.83CORRE = 0.73CORRE = 0.47050100150200050100150CPU Util0501001500500010000Software Interrupts050100150100015002000CPU Frequency050100150051015CPU Util050100150189500001900000019050000Shared Mem Usage050100150340350360370# Processes05010015000.51Cache Miss RatioParams memCORRE = 0.64CORRE = 0.78CORRE = 0.95CORRE = 0.67CORRE = 0.84CORRE = 0.86Parameter
CPU Frequency
User Time
CPU Util
Interrupts
S/W Interrupts
Processes
Cache Miss Ratio
Virtual Mem Usage
System Calls
Instructions
Shared Mem Usage

Description
Frequency of the CPU
Time spent by the CPU in user space
Percentage of CPU used
Number of Interrupts
Number of Software Interrupts
Number of processes in the system
Cache miss ratio
Percentage of virtual memory used
Number of System Calls
Number of instructions executed
Number of bytes used in shared memory

TABLE I: Selected System Stats Used for Power Model

the black lines show trend line of the measurements.

As can be seen, the relations show signiﬁcantly different
shapes depending on the workloads type. For the compute-
intensive workload, the power shows almost linear relation
with CPU frequency, while that of non-compute-intensive
workloads is represented the best with a ﬁve-degree polyno-
mial model. Likely, non-compute-intensive workloads show
high correlation with shared memory usage (correlation is
over 95%), while compute-intensive workloads show almost
no correlation between the shared memory usage of the
server power consumption. While all these parameters show
strong correlation (over 70%) with server power in either of
the workload types, there are no two parameters that show
exactly matching behaviors. To accommodate such diverse
contributions of all these parameters across different workload
types, we believe a more scalable solution is needed. To reﬂect
non-linear relations of these tens of parameters, we propose
to use a fully-connected DNN model.

Model Structure: We evaluated various fully-connected
DNN structures with Talos tool [14] and designed the ﬁnal
version to have six hidden layers with 16, 32, 64, 32, 16, and
8 neurons per layer, which derived the best accuracy.

Model Inputs: From the experiments, we observed that
not all 28 system parameters show strong correlation with
the server power consumption. Due to weak correlation, some
parameters only degrade model accuracy. Thus, we identiﬁed
the parameters that show strong correlation with the power
consumption. We selected 11 parameters that show higher than
70% correlation as listed in Table I.

Model Outputs: We observed that servers exhibit different
idle and peak power consumption due to different size of
computing resources, energy-proportionality of processors,
and so on. To tackle the server heterogeneity, we propose
to predict power scale factors rather than absolute power
values. The power scale factor indicates the relative power
level out of the maximum power range (between idle power
and peak power), which is calculated as (P owercurrent −
P oweridle)/(P owermax − P oweridle). Once the power
model predicts the power scale factor, we compute the pre-
dicted absolute power from it based on individual servers’ idle
and max power values.

IV. EVALUATION

We used 13 workloads for our evaluation and data collection
from PARSEC and SPLASH benchmark suites. We also used
stress micro-benchmarks from Linux Stress-NG to evaluate on
various compute intensity conditions. We tested the models on

Model
Analytical
DNN
RNN
Hydra
RAE [11]
TWBPNN [12]

Latency (ms)
< 0.001
0.025
1.003
0.07
0.039
0.092

Power (Watt)
< 0.2
9.52
11.55
5.64
0.61
9.42

TABLE II: Per-Model Overheads: Idle power of the tested
server is 237.58 Watt

Fig. 5: Prediction Accuracy w.r.t. Compute Intensity

two types of servers each uses different Intel Xeon CPU gen-
eration: Cascade Lake-SP (32 cores) with 384KB L1, 12 MB
L2, 16.5 MB L3 and Sandy Bridge-EP (24 cores) with 32KB
L1, 256KB L2, 20 MB L3. We compared the performance
of our approach with RAE [11] and TWBPNN [12], as well
as a simple LSTM-based RNN model that uses past 30 power
values for prediction. All models were trained with our system
parameters. We tried to match the parameters as close to those
in original papers.

The performance and power overheads of individual models
are summarized in Table II. The prediction accuracy for
different compute intensities is plotted in Figure 5. The over-
head and accuracy are measured while running the workloads
with long-tail job distribution with mixed compute intensities.
Hydra’s overhead is the averaged overhead that includes the
execution of model selector and the selected power model.
RNN showed the longest execution time due to its sequential
execution model while the analytical model showed almost
negligible performance overhead. Hydra showed less perfor-
mance and power overhead than most of the other machine
learning models except for RAE. But, the prediction accuracy
of RAE was over 10% worse than Hydra because RAE
does not consider server heterogeneity, while Hydra is trained
with power scale factors with more system parameters. Hydra
showed superior overall accuracy thanks to the dynamic model
selection.

V. DISCUSSION

Due to limited space, we show results of Hydra that uses
only two candidate power models. However, Hydra pursues
higher scalability and ﬂexibility. There are no limitations
of the number of candidate power models. The extended
Hydra will be able to support various emerging workloads
and hardware components that were not well supported with
earlier power models. By selecting the lightest power model
at run time, Hydra can be integrated to OS schedulers such
that data centers’ overall power consumption can be reduced

020406080100RNNRAETWBPNNAnalyticalDNNHydraRNNRAETWBPNNAnalyticalDNNHydraRNNRAETWBPNNAnalyticalDNNHydraRNNRAETWBPNNAnalyticalDNNHydra50% compute75% compute100% computeAvgError Rate (%)through power-aware job assignment without expensive hard-
ware power meters integrated to every server. The power
models also can be updated at runtime by integrating a power
meter per server type, collecting system statistics and power
measurements, and invoking transfer-learning thread regularly.
We will discuss these ideas in the extended full-length paper.
VI. CONCLUSION

Due to increasing system heterogeneity, there is no one
outperforming power model. Our proposed hybrid prediction
model dynamically chooses the best power model with the
consideration of prediction accuracy and model’s performance
overhead. Our simple combination of an analytical and a DNN
model showed superior performance and accuracy for various
compute intensity.

REFERENCES

[1] A. Verma, G. Dasgupta, T. K. Nayak, P. De, and R. Kothari, “Server
workload analysis for power minimization using consolidation,” in
USENIX ATC, 2009.

[2] D. Wong, “Peak efﬁciency aware scheduling for highly energy propor-

tional servers,” in ISCA, 2016.

[3] C. Delimitrou and C. Kozyrakis, “Paragon: Qos-aware scheduling for

heterogeneous datacenters,” in ASPLOS, 2013.

[4] A. T. Makaratzis, K. M. Giannoutakis, and D. Tzovaras, “Energy

modeling in cloud simulation frameworks,” FGCS, 2018.

[5] S. Roy, A. Rudra, and A. Verma, “An Energy Complexity Model for

Algorithms,” ITCS, 2013.

[6] B. Tudor and Y. Teo, “On Understanding the Energy Consumption of

ARM-based Multicore Servers,” SIGMETRICS, 2013.

[7] R. Ge, X. Feng, and K. W. Cameron, “Modeling and Evaluating Energy-
Performance Efﬁciency of Parallel Processing on Multicore based Power
Aware Systems,” IPDPS, 2009.

[8] Z. Shen, X. Zhang, B. Xia, Z. Liu, and Y. Li, “Multi-granularity
power prediction for data center operations via long short-term memory
network,” in IPDPS, 2019.

[9] Z. Shen, X. Zhang, B. Liu, B. Xia, Z. Liu, Y. Li, and S. Long, “Pcp-
2lstm: Two stacked lstm-based prediction model for power consumption
in data centers,” in CBD, 2019.

[10] Y.-F. Hsu, H. Kuwahara, K. Matsuda, and M. Matsuoka, “Toward a
workload allocation optimizer for power saving in data centers,” in IC2E,
2019.

[11] Y. Li, H. Hu, Y. Wen, and J. Zhang, “Learning-based power prediction

for data centre operations via deep neural networks,” in E2DC, 2016.

[12] W. Lin, G. Wu, X. Wang, and K. Li, “An artiﬁcial neural network
approach to power consumption model construction for servers in cloud
data centers,” IEEE TSUSC, 2020.

[13] K. N. Khan, Z. Ou, M. Hirki, J. K. Nurminen, and T. Niemi, “How
much power does your server consume? estimating wall socket power
using rapl measurements,” CSRD, 2016.

[14] “Talos Hyperparam serach,” https://pypi.org/project/talos/, accessed:

2021-01-21.

