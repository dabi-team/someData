HSF-DOC-2022-01
May 17, 2022
Copyright (C) 2022 CERN, Princeton and Fermilab, licence CC-BY-4.0

The HEP Software Foundation Community

The HEP Software Foundation

Contact editors:

Graeme A Stewart, CERN (graeme.andrew.stewart@cern.ch)
Peter Elmer, Princeton University (Peter.Elmer@cern.ch)
Elizabeth Sexton-Kennedy, Fermilab (sexton@fnal.gov)

Abstract: The HEP Software Foundation was founded in 2014 to tackle common problems of software
development and sustainability for high-energy physics. In this paper we outline the motivation for
the founding of the organisation and give a brief history of its development. We describe how the
organisation functions today and what challenges remain to be faced in the future.

2
2
0
2

y
a
M
7
1

]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[

1
v
3
9
1
8
0
.
5
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
Contents

1 History

2 HSF Activities

3 Outcomes and Conclusions

References

1 History

1

2

3

5

Over the past 50 years, the experimental particle, nuclear and astroparticle physics communities have
iteratively evolved a signiﬁcant amount of community structure. This was a natural result of the
growing size, scale and time duration of the experiments and the centralisation of facilities at large
laboratories. National, and now international, collaborations are typically required to build, operate
and maintain the large detectors used in these experiments. No single university or laboratory can
provide all of the necessary expertise and required eﬀort. The largest collaborations have grown from
100s of collaborators in the 1990s to 1000s at (for example) the Large Hadron Collider (LHC) at CERN.
This community has also developed a broad ecosystem of methodologies and technologies that are used
to build successive experiments and upgrades to existing experiments. While a speciﬁc instrument
can necessarily only be used for a single experiment at any given time, the large commonalities in
methodology should permit the development of research software which can be used widely in the
community for diﬀerent projects. Despite this, much of the software development remained somewhat
siloed within individual experiments or, at most, one or another host laboratory, with only a few
exceptions.

This is not to say that in the history of HEP there was no common software. CERNLIB [1]
was a foundation library written in the Fortran era and used by many experiments. Elements of it
have been rewritten in C++ and constitute some of the most widely used software packages in the
ﬁeld. Projects such as ROOT, Geant4, and various generators have eﬀectively acted as common glue
for many experiments. However in the software layers above these foundation and toolkit libraries,
redundant solutions that are diﬃcult to evolve and sustain over time (years or decades for large
experiments!) are common. To a large extent, software speed, performance and eﬃciency had been
ignored previously, because the costs due to ineﬃcient software could be ignored in the past. Software
is as much an intellectual product as well as a tool, thus a new approach was needed.

First steps in the direction of collaborating on modernising, in 2011-2012, led to the formation
of a cross-experiment “Concurrency Forum” [2] to discuss the speciﬁc software challenges brought by
changes in microprocessor technology (multi-core, wide vectors, GPUs). Driven initially by CERN and
Fermilab, the forum demonstrated community interest in wider software collaborations. By 2014-2015,
a number of colleagues involved in HEP software for many years were discussing a more ambitious
and broader scope for research software collaborations in HEP. This eventually led to the formation
of the High-Energy Physics (HEP) Software Foundation (HSF). The driving motivations for

– 1 –

this initiative were that the physics upgrades anticipated in the coming decades, particularly the High-
Luminosity LHC [3], would put enormous pressure on the software used in HEP; that much of our
software was already decades old; the changes in microprocessor technology brought new challenges
to the table; and that there was an urgent need to train new talent and to attract investment to the
ﬁeld, which could be better supported when common, multi-experiment, eﬀorts were promoted. More
generally, additional community structure which promotes research software collaborations, not tied
to single experiments or laboratories, has greater potential to enhance the longer term sustainability
of the software.

The very ﬁrst workshop [4] attempted to build on the community experience within the large
experiments, however there was too much discussion of “governance” questions. Individual experi-
ments need to operate a large well-integrated detector, manage pooled resources (such as computing
and storage) and at the end of the day produce scientiﬁc publications signed by the entire collabo-
ration. Thus governance questions within experiments are critical. This top-down approach was less
obvious for the envisioned research software collaborations, which can be more “ecosystem-like”. It
also made engaging experiments of very diﬀerent sizes more challenging. By the end of the workshop
most participants had concluded that a diﬀerent structure was needed. Subsequent workshops, one in
North America and one in Europe to aid inclusivity [5, 6], brought together many HEP experiments,
HEP speciﬁc software projects and other non-HEP organisations, such as the Apache Software Foun-
dation and the Software Sustainability Institute. Here, the principle of a “do-ocracy” was enshrined,
to encourage activity from the bottom-up, with developers leading, which was a far more productive
approach to community building.

From these early workshops the idea was born of preparing a Community White Paper (CWP),
laying out the roadmap for software and computing in HEP in the 2020s. As a way to fortify these
community-led eﬀorts, the Worldwide LHC Computing Grid (WLCG) gave a formal charge to the
HSF to prepare this paper [7]. Many individuals volunteered and the US National Science Foundation
was an early investor with dedicated funding to help organise and carry out CWP workshops [8, 9].
These workshops were focal points of an intense year of identifying key domain areas and potential
solutions for the ﬁeld and setting up working groups who would prepare topic-speciﬁc white papers.
This approach was able to greatly broaden the involvement of key individuals and solidiﬁed the active
communities around the HSF. Once the working groups had produced their domain-speciﬁc white
papers, an editorial team took charge of synthesising a uniﬁed single version of the white paper, which
was published with extremely wide community support, 310 signing authors from 124 institutes [10].
The CWP was not the only activity happening in the HSF at this time. Particularly where there
was an identiﬁed gap between diﬀerent communities, be these inter-experiment, between projects, or
even between theory and experiment, the HSF was ideally placed to bridge gaps and bring diﬀerent
people together. Workshops on analysis ecosystems [11] and on computational aspects of event genera-
tors [12] were notable examples. In addition the HSF was a natural forum for considering more radical
software developments and their potential, gathering experiment and expert feedback on progress and
possibilities [13].

2 HSF Activities

While much of the early HSF activity was focused on software community building through the CWP,
working groups were started where common topics were obviously identiﬁed within the community,
e.g., in the domain of packaging and distributing HEP software stacks. These groups brought together
experts and interested parties and focused around technical discussions.

– 2 –

In the wake of the CWP it was clear that this model would work very well for the areas of most
concern for the future, so the model was broadened and, over a few years, eight working groups were
established with about 3 conveners in each case, appointed annually and with a nomination system
that allows both stakeholder (experiment, institution) input and bottom-up volunteers for running
these groups. In order to marshall these activities it was necessary to have some critical amount of
binding eﬀort, so the decision of CERN management to allow signiﬁcant (0.5 FTE) time from one
person to the HSF was crucial and has had a key multiplication eﬀect.

Where these groups are involved in areas that are ‘traditional’, e.g., detector simulation or recon-
struction, there is a strong involvement with ongoing developments in the experiments and in well
established software projects. The focus is the exchange of ideas and discussions of common problems.
In a number of cases the HSF had identiﬁed topics of interest that were simply not covered elsewhere
in the ﬁeld and then the HSF working group has had a further leading and catalysing eﬀect. This
is particularly the case for the use of Python in HEP, led by the PyHEP working group; and for
computational aspects of physics event generators, led by the Generators working group [14].

In addition to being a focus for the exchange of ideas and techniques, when WGs identify a concrete
topic where a paper can usefully be prepared, the HSF is a natural place for organising pan-experiment
input and encouraging some standardisation (e.g., in analysis level metadata or in detector conditions
data access). This has been recognised by more formal bodies outside the HSF, such as WLCG and the
LHCC, who often ask the HSF to marshall community inputs for updates on development activities
and reviews of development plans. This is an important point in terms of recognising the contribution
of the organisation. In turn, this fosters recognition for the contribution of our individual members
and helps their careers to advance.

This engagement with strategic bodies in the ﬁeld, where the HSF advocates for software invest-
ment [15], leads the HSF to work in tandem with other funded software R&D projects in HEP, where
the HSF will support funding applications and then work with these projects, enhancing their connec-
tion to the community and the impact of their work. Practically projects can contribute through the
working groups closest to their R&D areas.

The HSF also engages with other like minded bodies and collaborates on regular series of meetings
regarding accelerator programming or software and computing for nuclear physics and also organises
itself as an umbrella organisation, with CERN, to run Google Summer of Code for HEP software
projects and experiments.

In the past the HSF organised face-to-face workshops and the intention is to restart such activ-
ities once the pandemic passes, but in the meantime virtual workshops have played a role. In some
circumstances these can even have a greater impact, with the PyHEP workshops in 2020 and 2021
registering more than 1000 participants [16, 17]. In large part this reﬂects a strong didactic element
in the Python area. This thread is reﬂected also in that the HSF, together with IRIS-HEP, SIDIS,
The Carpentries and the ROOT project [18–22], has put a strong emphasis on training activities [23]
and now runs regular training events in fundamental software skills and in C++ programming. This
is seen as a critical activity in the ﬁeld and attempts are now also being made to have these activities
as feeders to encourage trainees to be involved in software development and training.

3 Outcomes and Conclusions

Contrary to initial ideas, the HSF has not, by and large, run software projects themselves - without
actually having resources to disburse it is better to allow such projects to be independent and work with
the HSF as is useful. That said, HSF events have proved to be fertile ground for people from diﬀerent

– 3 –

backgrounds to meet (e.g., nuclear and astroparticle physics) and even to start common software
projects that then take on a life of their own. Fostering funded projects has led to new investment
in software R&D in HEP and a higher recognition of the importance of promoting excellent software
developers in their careers; this is a major success that was a direct outcome of the CWP process.

The HSF has now established itself as a recognised part of the HEP software landscape where
it links strategic bodies to the community of software developers. It remains a challenge to continue
to build the next generation of HEP software developers and make them feel involved and part of
an organisation like the HSF, but work to improve training and engage younger colleagues through
the working group process is hoped to improve this. Looking forward to post-pandemic activities,
where face-to-face interactions can happen again, will also help to continue to build HEP software
communities.

– 4 –

References

[1] CERN Program Library. url: https://en.wikipedia.org/wiki/CERN_Program_Library.
[2] Forum on Concurrent Programming Models and Frameworks. url:

https://concurrency.web.cern.ch/concurrency/index.html.

[3] The High-Luminosity LHC project. url:

https://home.cern/science/accelerators/high-luminosity-lhc.

[4] HEP Software Collaboration meeting. Apr. 2014. url:

https://indico.cern.ch/event/297652/.

[5] HEP Software Foundation Workshop (SLAC). Jan. 2015. url:

https://indico.cern.ch/event/357737/.

[6] HEP Software Foundation Workshop (LAL). May 2016. url:

https://indico.cern.ch/event/496146/.

[7] Charge for Producing a HSF Community White Paper. July 2016. url:
https://hepsoftwarefoundation.org/assets/CWP-Charge-HSF.pdf.

[8] HEP Software Foundation Workshop (SDSC). Jan. 2017. url:

https://indico.cern.ch/event/570249/.

[9] HEP Software Foundation Workshop (LAPP). June 2017. url:

https://indico.cern.ch/event/613093/.

[10] Johannes Albrecht et al. “A Roadmap for HEP Software and Computing R&D for the 2020s”.
In: Computing and Software for Big Science 3.1 (Mar. 2019), p. 7. issn: 2510-2044. doi:
10.1007/s41781-018-0018-8. url: https://doi.org/10.1007/s41781-018-0018-8.
[11] HEP Analysis Ecosystem Workshop. url: https://indico.cern.ch/event/570249/.
[12] Physics Event Generator Computing Workshop. url:

https://indico.cern.ch/event/751693/.

[13] HEP Software Community Meeting on GeantV R&D. url:

https://indico.cern.ch/event/570876/.

[14] Andrea Valassi et al. “Challenges in Monte Carlo Event Generator Software for

High-Luminosity LHC”. In: Computing and Software for Big Science 5.1 (May 2021), p. 12.
issn: 2510-2044. doi: 10.1007/s41781-021-00055-1. url:
https://doi.org/10.1007/s41781-021-00055-1.

[15] Graeme A Stewart. The Importance of Software and Computing to Particle Physics. Dec.
2018. doi: 10.5281/zenodo.2413005. url: https://doi.org/10.5281/zenodo.2413005.

[16] PyHEP 2020 (virtual) Workshop. July 2020. url: https://indico.cern.ch/e/pyhep2020.
[17] PyHEP 2021 (virtual) Workshop. July 2021. url: https://indico.cern.ch/e/pyhep2021.
Institute for Research and Innovation in Software for High Energy Physics (IRIS-HEP). url:
https://iris-hep.org/.

[18]

[19] Software Institute for Data-Intensive Sciences. url: https://sidis.web.cern.ch/.
[20] The Carpentries. url: https://carpentries.org/.

– 5 –

[21] R. Brun and F. Rademakers. “ROOT: An object oriented data analysis framework”. In:
Nucl. Instrum. Meth. A389 (1997), pp. 81–86. doi: 10.1016/S0168-9002(97)00048-X.

[22] ROOT Data Analysis Framework. url: https://root.cern/.

[23] Sudhir Malik et al. “Software Training in HEP”. In: Computing and Software for Big Science

5.1 (Oct. 2021), p. 22. issn: 2510-2044. doi: 10.1007/s41781-021-00069-9. url:
https://doi.org/10.1007/s41781-021-00069-9.

– 6 –

