Classiﬁcation of Natural Language Processing
Techniques for Requirements Engineering

Liping Zhao, Waad Alhoshan, Alessio Ferrari, Keletso J. Letsholo

2
2
0
2

r
p
A
8

]
L
C
.
s
c
[

1
v
2
8
2
4
0
.
4
0
2
2
:
v
i
X
r
a

Abstract—Research in applying natural language processing
(NLP) techniques to requirements engineering (RE) tasks spans
more than 40 years, from initial efforts carried out in the
1980s to more recent attempts with machine learning (ML)
and deep learning (DL) techniques. However,
in spite of the
progress, our recent survey shows that there is still a lack of
systematic understanding and organization of commonly used
NLP techniques in RE. We believe one hurdle facing the industry
is lack of shared knowledge of NLP techniques and their usage
in RE tasks. In this paper, we present our effort to synthesize
and organize 57 most frequently used NLP techniques in RE.
We classify these NLP techniques in two ways: ﬁrst, by their
NLP tasks in typical pipelines and second, by their linguist
analysis levels. We believe these two ways of classiﬁcation are
complementary, contributing to a better understanding of the
NLP techniques in RE and such understanding is crucial to the
development of better NLP tools for RE.

Index Terms—Requirements Engineering (RE), Natural Lan-

guage Processing (NLP), NLP Tasks, NLP Techniques

I. INTRODUCTION

Research in developing natural language processing (NLP)
support for requirements engineering (RE), or NLP4RE for
short, dates back to the early 1980s and has seen a continuous
ﬂow of contributions in the past 40 years [1]–[4]. However, in
spite of huge improvements and advances in NLP in the last
20 years [5], [6], and great progress in NLP4RE research in
the last 10 years, the uptake of NLP technologies in RE, and
their industrial penetration, is still limited and fragmented [7],
[8]. Thus large gaps remain between NLP4RE research and
its practical application [8].

A recent survey [8] cites insufﬁcient industrial evaluation
of NLP4RE research, the lack of shared RE-speciﬁc language
resources, and the lack of technology know-how in NLP
among the reasons for these gaps. As a ﬁrst step to close
these gaps, this paper aims to classify the NLP techniques
commonly used in RE so that they are easy to understand. We
believe that a better understanding of the NLP techniques in
RE is not only crucial to the development of better NLP tools
for RE, but also to their industrial adoption. In particular, the
paper lays foundations for establishing a common terminology
and vocabulary of the NLP techniques through the following
contributions:

L. Zhao is with the University of Manchester, Manchester, UK
W. Alhoshan is with Al-Imam Mohammed ibn Saud Islamic University,

Riyadh, Saudi Arabia

A. Ferrari is with Consiglio Nazionale delle Ricerche, CNR-ISTI, Pisa,

Italy

K.J. Letsholo is with Higher Colleges of Technology, Abu Dhabi, UAE

• We extract and synthesize 57 commonly used NLP tech-

niques in RE for NLP4RE research and practice.

• We systematically classify these techniques in two ways:
by their tasks typically performed in NLP pipelines and
then by their linguistic analysis capability.

The paper is organized as follows. Sect. II provides a brief
history of NLP for RE, as the background and motivation for
this paper. Sect. III describes how we extract and synthesize
the common set of NLP techniques for RE. Sect. IV and
Sect. V present our classiﬁcation of these techniques. Sect. VI
concludes the paper.

II. BACKGROUND: 40 YEARS OF NLP4RE

As a background to this paper, we provide a brief history of
NLP4RE. We ﬁrst point to some notable contributions in RE
that use traditional NLP techniques, and then outline the recent
application of machine learning (ML) and deep learning (DL)
in RE. However, the focus of this paper is on NLP techniques,
not ML and DL techniques.

A. Traditional NLP for RE

The relationship between NLP and RE is well established
and widely discussed, with supporters and detractors [1], [7],
[9], [10]. Pioneering researchers in the ﬁeld are Chen [11]
and Abbott [12], who, in the early 1980s, proposed using
syntactic features of English sentences for database modeling
and program design. Abbott’s approach was subsequently
adapted to a program design tool by Berry et al. [13]. These
works were mostly based on extracting relevant entities from
the requirements text through simple syntactic rules, assuming
that NL requirements were expressed in some constrained,
is rarely the case in
predictable format, which, however,
practice [14].

After these pioneering works, the beginning of 1990s saw
some serious attempts to develop NLP4RE tools, introducing
techniques to account for the complexity and variety of NL.
Two well-known NLP tools, ﬁndphrases by Aguilera and
Berry [15] and OICSI by Rolland and Proix [16], were the
results of these efforts. Both tools were still oriented to the
extraction task [8], also referred as abstraction [10], and used
lexical afﬁnity and semantic cases, respectively, two tech-
niques that are far more sophisticated than those previously
used.

For the remaining 1990s right up to the beginning of 2000s,
a succession of NL tools had been proposed, among which
were AbstFinder by Goldin and Berry [17], NL-OOPS by
Mich [18], Circe by Ambriola and Gervasi [19], CM-Builder

 
 
 
 
 
 
by Harmain and Gaizauskas [20]. These works normally use
traditional rule-based NLP techniques, and are oriented to term
extraction and model generation. Other tools, such as QuARS
by Fabbrini et al. [21], and ARM by Wilson et al. [22],
focus on defect detection and mostly use dictionary-based
techniques.

The early 2000s appeared to be a period of experimentation
of new NLP techniques and new ideas addressing other tasks
and phases of the RE process. Information retrieval (IR)
techniques were used to improve requirements tracing [23],
statistical NLP techniques were applied to identify “shallow
knowledge” from requirements text [2], and to tracing rela-
tionships between requirements [24].

Since the late 2000s, NLP4RE has become a full-ﬂedged
research area, attracting researchers from the wider RE com-
munity. A large number of tools have since been developed,
among which are SREE (Tjong and Berry [25]) for ambiguity
detection and aToucan (Yue et al. [26]) for model generation.
Further developments include tools detection of defects [27],
smells [28] and equivalent requirements [29].

Given the increasing need to make software systems trust-
worthy, accountable, legally compliant, as well as security-
and privacy-aware, NLP has been largely applied also to legal
in the ﬁeld of
documents [30] and privacy policies [31],
RE and Law. Finally, to support agile software development,
requirements expressed in the form of user stories have been
identiﬁed as an interesting area of application for NLP [32].

B. Machine Learning and Deep Learning for RE

Following the development of successful statistical NLP
methods based on ML in the 1990s [5], [33], ML techniques
have become increasingly important to NLP. The advantages of
the ML-based approaches over the traditional, rule-based NLP
approaches are effectiveness, considerable savings in terms of
expert manpower, and straightforward portability to different
domains [34].

In RE, the earliest adoption of ML to NLP can be traced
to a study by Cleland-Huang et al. [35], published in 2007,
in which the authors presented an approach for automati-
cally detecting and classifying non-functional requirements
(NFRs) from requirements documents. The approach uses a
set of weighted indicator terms to classify requirements; a
probability value of each indicator term is computed by a
probability function similar to Na¨ıve Bayes [36], to estimate
the likelihood of an input requirement being classiﬁed into a
certain NFR category. The development of this approach thus
marked the beginning of the work on ML-based approaches
for RE and, as a seminal work in this area, this approach has
been frequently used as the baseline to assess the performance
of new techniques [7], [37].

With the recent widespread availability of NL content
relevant to RE, such as feedback from users in app stores and
social media, and developers’ comments in discussion forums
and bug tracking systems, we have observed a rising interest
in using ML techniques to support data-driven RE [38] and
crowd-based RE [39]. These areas aim to leverage information

available from stakeholders’ implicit and explicit feedback,
including diverse sources as app reviews [40], issue tracking
systems [41], Twitter [42] or user fora [43], to improve RE
activities such as requirements elicitation and prioritization.
Most of the works use ML techniques, as these can be effec-
tively exploited when the task can be reduced to a classiﬁcation
problem, and a large amount of data is available. The analysis
of different forms of feedback can be regarded as the main
trend of the last years in NLP4RE research [8].

However, several other RE tasks have proﬁted from ML and
even DL techniques, for example: glossary extraction, with the
usage of unsupervised learning [44] and convolutional neural
networks [45]; requirements classiﬁcation with the early works
from Casamayor et al. [46] and developments from Kurtanovic
and Maalej [37]; requirements tracing [47], [48], which can be
regarded as the ﬁeld where ML/DL have been more widely
experimented for traditional requirements, especially due to
the inherent nature of the problem, which entails ﬁnding
relevant relationship (i.e., trace links) within a large amount
of potential ones.

With the advent of DL and transfer learning in particular,
initial experiments have been carried out in RE with promising
results. In particular, DL-based approaches have been proposed
to classify software requirements into FR or NFR [49], to
discovery requirements from open source issue reports [50]
and to extract and classify requirements from software project
contracts [51]. We predict that research in developing DL-
based approaches for RE tasks will grow rapidly in the coming
years, overtaking the work on ML-based approaches.

III. METHOD

The main source of the literature used for our data collection
is the set of 404 NLP4RE studies identiﬁed in our systematic
review [8]1, which covers the studies up to 2019. We then
performed a complementary targeted review to identify recent
publications, to ﬁnd more recent techniques emerging in the
last 2 years. This complementary review focused on the major
RE and software engineering conferences (i.e., RE, REFSQ
and ICSE) and journals (i.e., REJ, JSS, ASE, DKE, IST,
and TSE). Based on this updated literature, we extract NLP
techniques.

To help us identify and extract NLP techniques from
each paper, we followed this deﬁnition: ”An NLP technique
is a practical method, approach, process, or procedure for
performing a particular NLP task, such as POS tagging,
parsing or tokenizing [8].” Our data extraction resulted in a
large collection of diverse terms and phrases. To synthesize
different terms and phrases into a coherent set of standard
terms, we consulted many books written by NLP experts (e.g.,
[52]–[54]). This process gave rise to a total of 57 different
NLP techniques. Table I and Table II summarize these 57
techniques.

1The references of these papers are made available by Zhao et al. at:

https://github.com/waadalhoshan/NLP4RE.

ID
1

Name
Part-of-Speech (POS) Tagging

2

3

4

5

6

7
8

9

10

11

12

13

14

15

16

17

18

Term Extraction

Keyword Searching

Chunking

Named Entity Recognition (NER)

Semantic Role Labelling (SRL)

Temporal Tagging
Dependency Parsing

Constituency Parsing

Link Grammar

Semantic Parsing

Sentiment Analysis

Text Annotation

Semantic Annotation

Topic Modelling

Summarization

Latent Dirichlet Allocation (LDA)

Latent Semantic Indexing (LSI)

19

Semantic Patterns

20

21

22
23

24

25

26

27

28
29

30

Case Grammar

Semantic Frames

Knowledge Graph
Bag-of-Words (BOW)

Word Frequency

Term Frequency-Inverse Document
Frequency (TF-IDF)
Co-location Analysis

Term-Document Matrix

Character Counting
Concordance

Cosine Similarity

TABLE I
LIST OF NLP TECHNIQUES (PART 1)

Explanation
POS Tagging (or Tagging) processes a sequence of words, and attaches a POS tag to each word.
Parts of speech are also known as word classes or lexical categories.
The process of extracting the most relevant words and expressions from text. Related terms:
Keyword Extraction, Word Extraction
The technique of ﬁnding strings that match a pattern. Related terms: Term Matching, Word
Matching
Chunking (or text chunking) is a type of shallow parsing that analyses a sentence by ﬁrst
identifying its constituent parts (nouns, verbs, adjectives, etc.) and then links them to higher
order units that have discrete grammatical meanings (noun groups or phrases, verb groups, etc.).
Related term: Shallow Parsing.
Subtask of information extraction that is based to ﬁnd and classify named entities in a certain
text into pre-deﬁned categories or class such as the names of persons, organizations, locations,
etc. Related terms: Entity Identiﬁcation, Concept Extraction.
The process of detecting the semantic arguments linked with the predicate or verb of a sentence
and their classiﬁcation into their speciﬁc roles. Related Term: Semantic parsing, semantic trees,
shallow parsing, and shallow semantic analysis.
The task of ﬁnding phrases with temporal meaning within the context of a larger document.
Dependency parsing is the process of analyzing the grammatical structure of a sentence based on
the dependencies between the words in a sentence. Related terms: Syntactic Patterns, Syntactic
Structure
The process of analyzing the sentences by breaking down it into sub-phrases also known as
constituents. These sub-phrases belong to a speciﬁc category of grammar like NP (noun phrase)
and VP(verb phrase). Related terms: Phrase Parsing, Phrase Detection, Phrasal Verb Extraction
Builds relations between pairs of words, rather than constructing constituents in a phrase structure
hierarchy.
The task of converting a natural language utterance to a logical form: a machine-understandable
representation of its meaning.
The process of computationally identifying and categorizing opinions expressed in a piece of
text
The practice and the result of adding a note or gloss to a text, which may include highlights or
underlining, comments, footnotes, tags, and links.
The process of attaching to a text document or other unstructured content, metadata about
concepts (e.g., people, places, organizations, products or topics) relevant to it.
A type of statistical model for discovering the abstract ”topics” that occur in a collection of
documents
The practice of breaking down long publications into manageable paragraphs or sentences.
The procedure extracts important information while also ensuring that the paragraph’s sense
is preserved.
The process of analysing relationships between a set of documents and the terms they contain
by producing a set of concepts related to the documents and terms.
A mathematical practice that helps classify and retrieve information on particular key terms and
concepts using singular value decomposition (SVD). Related Term: Latent Semantic Analysis
(LSA)
Semantic patterns are generated based on common matching concepts. The top matching concepts
of each word are considered. One semantic pattern can relate to several concepts and a single
semantic clique can contain several semantic patterns.
A system of linguistic analysis, focusing on the link between the valence, or number of subjects,
objects, etc., of a verb and the grammatical context it requires.
A coherent structure of concepts that are related such that without knowledge of all of them,
one does not have complete knowledge of one of the either.
A way of storing data that resulted from an information extraction task.
A representation that turns arbitrary text into ﬁxed-length vectors by counting how many times
each word appears. This process is often referred to as vectorization.
How often a word appears in a document, divided by how many words there are. Related Terms:
Term Frequency, Domain Term Frequency
A statistical measure that evaluates how relevant a word is to a document in a collection of
documents.
A Co-location is an expression consisting of two or more words that correspond to some
conventional way of saying things.
A mathematical matrix that describes the frequency of terms that occur in a collection of
documents.
Counts the number of characters in a line of text, page or group of text.
An alphabetical list of the words (especially the important ones) present in a text, usually with
citations of the passages in which they are found.
A metric used to measure how similar the documents are irrespective of their size.

ID
31
32

Name
Lexical Afﬁnity
Similarity Distance

33

34

35

36

37
38

39

40
41
42
43

44
45

46

47

48

49

50

51
52
53

54

55

56
57

Document Similarity

Lexical Similarity

Regular Expression

Lexical Patterns

Generation Rules
Stemming

Lemmatization

Stop-Word Removal
Noise Removal
Punctuation Removal
Lowercasing

Camel Case Splitting
Tokenization

Sentence Segmentation

n-gram

Word Embedding

Contextualized word embedding

Sentence and document Embed-
ding
GloVe
FastText
Textual Entailment Recognition

Homonym Detection

Synonym Detection

Coreference Resolution
Anaphora Resolution

TABLE II
LIST OF NLP TECHNIQUES (PART 2)

Explanation
Assigns to arbitrary words a probabilistic ’afﬁnity’ for a particular category.
Determines the minimum number of single character edits required to change one word to
another.
Computing the similarity between two text documents by transforming the input documents into
real-valued vectors.
Provides a measure of the similarity of two texts based on the intersection of the word sets of
same or different languages.
A special series of strings for describing a a text pattern for the purpose of searching or replacing
the described items.
Words or chuck of text that occurs in language with high frequency and the meaning of the
parts are sometime different than the meaning of the whole.
Generation rules to produce meaningful sentences in Natural Language.
A crude heuristic process that chops off the ends of words in the hope of achieving this goal
correctly most of the time, and often includes the removal of derivational afﬁxes.
Use a vocabulary and morphological analysis of words, normally aiming to remove inﬂectional
endings only and to return the base or dictionary form of a word, which is known as the lemma.
Words which are ﬁltered out before or after processing of natural language data (text).
Removing characters digits and pieces of text that can interfere with your text analysis.
Removing puncuatations marks.
Converting all your data to lowercase helps in the process of preprocessing and in later stages
in the NLP application, when you are doing parsing.
Split CamelCase string to individual strings.
The process of breaking a stream of text into words, phrases, symbols, or other meaningful
tokens. Related terms: Word Segmentation
Split a document into sentences, each containing a list of tokens. Related terms: Sentence
Splitting
A representation of a text using a sequence of N words or N characters (character n-gram),
where N can be any number. Thus we can have 1-gram (unigram), 2-gram (bigram), 3-gram
(trigram), etc.
One of the most popular technique to learn word embeddings using shallow neural network.
Word embeddings are vector representations of a particular word. Related terms: Word2Vec
A neural model that learns a generic embedding function for variable length contexts of target
words. Related terms: Context2Vec
A generalized word2vec method, for representing documents as a vector. Related term: Doc2Vec

An alternative to word2vec for the representation of the distributed words.
An alternative to word2vec, FastText represents each word as a bag of character n-gram.
Deciding, given two text fragments, whether the meaning of one text is entailed (can be inferred)
from another text.
Detecting the words that are pronounced the same as each other (e.g., ”maid” and ”made”) or
have the same spelling (e.g., ”lead weight” and ”to lead”).
Finding a a word or phrase that means exactly or nearly the same as another word or phrase in
a text.
Finding all expressions that refer to the same entity in a discourse.
Resolving what a pronoun, or a noun phrase refers to in a discourse.

IV. CLASSIFYING NLP TECHNIQUES BY TASKS

We ﬁrst classify the NLP techniques based on their text pro-
cessing tasks. Figure 1 depicts the relationship between NLP
techniques, NLP tasks, NLP resources, and tools. We deﬁne a
NLP task as a piece of text processing work that can be done
by means of one or more NLP techniques, supported by some
NLP tools and resources. A list of frequently performed NLP
tasks in RE are desribed below:

• Part-of-Speech (POS) Tagging: To associate words
with part-of-speech (POS) tags to distinguish between
nouns, verbs, adjectives, adverbs, etc. The input unit is a
sentence, as context words (i.e., neighbouring ones) are
normally used to infer the POS of a word.

• Semantic Tagging: To extract useful bits of information

(words, terms, relations, etc.) from the text.

• Syntactic Analysis: To analyze the syntactic structure
of a sentence to represent the relationship between its
components. Different representation structures can be
used, such as the parse tree, or the dependency parsing
graph.

• Semantic Analysis: To identify and label semantically
relevant components and relations in the text. These
entails identifying the meaning of a certain word or
phrase in a context and the relationship between words
or terms.

• Frequency Analysis: To analyze the frequencies of
words or terms in a certain context and to produce
probabilistic data.

• Similarity Analysis: To calculate the numerical estimates
of similarity between text elements, for example to iden-
tify semantic relatedness, synonyms, or to support topic

related constituents (i.e., sub-phrases). These representations
(i.e., syntax) carry meaning in most languages, because the the
arrangement of words or sub-phrases in a sentence contributes
to meaning [55].

Semantic. A NLP technique at this level may focus on
the meanings of individual words (e.g., dictionary deﬁnitions
of words and word-sense disambiguation), or compositional
semantics, which looks at the interactions among word-level
meanings in sentences (e.g., semantic role labeling). Semantic
analysis thus can be divided into word-level semantic and
sentence-level semantic (groups of words or sentence-level).
Semantic role labelling [56] and Case Grammar [57], [58] are
among the examples of semantic analysis techniques.

Discourse. A NLP technique at this level focuses on the
properties of the text as a whole that convey meaning by
making connections between component sentences. Several
types of discourse processing can occur at this level, two of
the most common being anaphora resolution and coreference
resolution [55].

Pragmatic. This is the highest level of NLP. To reach this
level, NLP techniques need to be able to achieve human-like
language understanding, the ultimate goal of natural language
understanding (NLU). This entails inferring extra meaning
from texts that is not actually encoded in them [55] and
understanding narratives according to different contexts and
with respect to different actors and their intentions [33]. This
requires NLP tools to have world knowledge and human
intelligence, and the ability to project semantics and sentics
dynamically [33]. Pragmatic analysis appears to be the most
challenging NLP curve to jump [33].

It is assumed that humans normally produce or comprehend
language by utilizing all of these levels [59]. These levels thus
represent the competence of a NLP tool: The more levels of
analysis the tool supports, the stronger or more capable the
tool; the more higher-levels of analysis the tool supports, the
more advance the tool.

Table IV classiﬁes the NLP techniques based on these levels.
As the table shows, we have not found any techniques for the
phonetic level analysis, as NLP techniques have been largely
use to deal with texts (including requirements documents [60],
app reviews, tweets, social media posts and usage data [7],
[9], [38], [61], [62], legal documents [30], and privacy poli-
cies [31]). In addition, we have not found any techniques for
pragmatic analysis either. This is because NLP4RE research
has so far focused on text processing of documents and has not
reached the level of natural language understanding (NLU).

VI. CONCLUSION

This paper presents 57 commonly used NLP techniques in
RE and organizes them in two different ways: by their NLP
tasks and by their analysis levels. The organization provides
a knowledge base for sharing these techniques. A user of this
knowledge base can query each NLP technique progressively:
Through Table I and Table II, the user can ask: What technique
is it? Does it work at the word-level or sentence-level of
text processing? Based on Table III, the user can ask: Which

Fig. 1. Relationship between NLP techniques and NLP Tasks.

modelling.

• Rule-Based Analysis: To use grammar rules, semantic

rules or patterns to analyse the syntax of a text.

• Text Normalization: To convert the words into their orig-
inal form and remove unnecessary words or characters
from the text.

• Text Segmentation: To break down a text into a sequence

of individual sentences or words.

• Text Normalization: To reduce the words to a stan-
dardised format, with the removal of stop words, and
reduction of typographical forms (e.g., upper case, camel
case) to a unique form.

Table III presents the classiﬁcation results of the NLP

techniques for RE based on these tasks.

V. CLASSIFYING NLP TECHNIQUES BY LINGUISTIC
ANALYSIS LEVELS

Here, we classify the NLP techniques by levels of linguistic
analysis. According to Liddy [55], linguistic analysis can be
performed at the following seven levels:

Phonology. This level deals with the interpretation of

speech sounds within and across words.

Morphology. This is the lowest level of text analysis. At
this level, a NLP technique analyzes the smallest parts of
words that carry meaning, which are composed of morphemes,
including preﬁxes, roots and sufﬁxes of words.

Lexical. A NLP technique at this level can interpret the
meaning of individual words to gain word-level understanding
[55]. Lexical analysis may require a lexicon or dictionary,
which may be quite simple, with only the words and their POS
tags, or may be increasingly complex and contain information
on the semantic class of the word, its arguments etc. [55].

Syntactic. A NLP technique at this level focuses on an-
alyzing the words in a sentence through the grammatical
structure of the sentence. This requires both a grammar
and a parser [55]. There are two general types of parser:
dependency and constituency [52]. The dependency parser
produces a syntactic representation of a sentence based on the
dependencies between the words in the sentence, whereas the
constituency parser represents a sentence as a parse tree of

TABLE III
CLASSIFYING NLP TECHNIQUES BY TASKS.

NLP Tasks

Explanation

Part-of-Speech Tagging

Semantic Tagging

Syntactic Analysis

Semantic Analysis

Associate words with part-of-speech (POS) tags
to distinguish between nouns, verbs, adjectives,
adverbs, etc.

Extract useful bits of information (words, terms,
relations, etc.) from the text.

Construct a syntactic structure representing the
relationship between the logical components in
a stream of text, such as the parse tree, or the
dependency parsing graph.

Identify and label semantically relevant compo-
nents and relations in the text.

NLP Techniques

Part-of-Speech (POS) Tagging

Term Extraction, Term Matching, Chunking, Concept Extrac-
tion, Named Entity Recognition (NER), Semantic Role Labelling
(SRL), Temporal Tagging

Dependency Parsing, Constituency Parsing, Link Grammar

Semantic Parsing, Sentiment Analysis, Text Annotation, Semantic
Annotation, Topic Modelling, Summarization, Latent Dirichlet
Allocation (LDA), Latent Semantic Indexing (LSI), Semantic
Patterns, Case Grammar, Semantic Frames, Knowledge Graph,
Textual Entailment Recognition (TER), Homonym Detection,
Synonym Detection, Coreference Resolution, Anaphora Resolu-
tion

Frequency Analysis

Similarity Analysis

Rule-Based Analysis

Text Normalization

Text Segmentation

Text Representation

Analyse the frequency of occurrence of lexical
elements (e.g., words and characters) and groups
of elements (e.g., phrases and multiwords) in a
given text.

Bag-of-Words (BOW), Word Frequency, Term Frequency (TF),
Term Frequency & Inverse Document Frequency (TF-IDF), Co-
location Analysis, Term-Document Matrix, Character Counting,
Concordance

Calculate numerical values of the similarity be-
tween text elements, such as to identify semantic
relatedness.

Use rules or patterns to analyse the syntax or
semantics of a text or transform the text.

Convert the words into their original form and
remove unnecessary words or characters from
the text.

Break down a text into a sequence of individual
tokens (i.e., words or sentences).

Represent words, sentences or documents using
vectors of real numbers.

Cosine Similarity, Lexical Afﬁnity, Similarity Distance, Document
Similarity, Lexical Similarity

Regular Expression, Lexical Patterns, Generation Rules

Stemming, Lemmatization, Stop-Word Removal, Noise Removal,
Punctuation Removal, Lowercasing, Camel Case Splitting

Tokenization, Sentence Segmentation

N-gram, Word2Vec, Context2Vec, Doc2Vec, GloVe, FastText

text processing task does this technique support? What are
the alternative techniques for the same task? From Table IV,
the user can ask: What level of language analysis does this
technique provide? What are the techniques for performing
other levels of analysis? The answers to these questions can
help the user to decide if a speciﬁc technique is relevant to
the task at hand.

Our future work will

improve this knowledge base as

follows:

• To show the relationship between a given technique and
other techniques. For example, for text normalization,
what techniques can I use together? in what order? For
text representation, which technique is better for my case?
• To provide information on the available NLP tools that

support each technique.

REFERENCES

[1] K. Ryan, “The role of natural language in requirements engineering,”
in [1993] Proceedings of the IEEE International Symposium on Re-
quirements Engineering.

IEEE, 1993, pp. 240–242.

[2] P. Sawyer, P. Rayson, and K. Cosh, “Shallow knowledge as an aid
to deep understanding in early phase requirements engineering,” IEEE
Transactions on Software Engineering, vol. 31, no. 11, pp. 969–981,
2005.

[3] V. Berzins, C. Martell, P. Adams et al., “Innovations in natural lan-
guage document processing for requirements engineering,” in Monterey
Workshop. Springer, 2007, pp. 125–146.

[4] D. Berry, R. Gacitua, P. Sawyer, and S. F. Tjong, “The case for dumb re-
quirements engineering tools,” in International Working Conference on
Requirements Engineering: Foundation for Software Quality. Springer,
2012, pp. 211–217.

[5] J. Hirschberg and C. D. Manning, “Advances in natural
processing,” Science, vol. 349, no. 6245, pp. 261–266, 2015.

language

[6] G. Goth, “Deep or shallow, nlp is breaking out,” Communications of

the ACM, vol. 59, no. 3, pp. 13–16, 2016.

[7] F. Dalpiaz, A. Ferrari, X. Franch, and C. Palomares, “Natural language
processing for requirements engineering: The best is yet to come,”
IEEE software, vol. 35, no. 5, pp. 115–119, 2018.

[8] L. Zhao, W. Alhoshan, A. Ferrari, K. J. Letsholo, M. A. Ajagbe, E.-
V. Chioasca, and R. T. Batista-Navarro, “Natural language processing
(nlp) for requirements engineering (re): A systematic mapping study,”
ACM Computing Surveys, in press, 2021.

[9] A. Ferrari, F. Dell’Orletta, A. Esuli, V. Gervasi, and S. Gnesi, “Nat-
ural language requirements processing: a 4D vision,” IEEE Software,
vol. 34, no. 06, pp. 28–35, 2017.

[10] D. M. Berry, “Evaluation of tools for hairy requirements and software
engineering tasks,” in 2017 IEEE 25th International Requirements
Engineering Conference Workshops (REW).
IEEE, 2017, pp. 284–
291.

[11] P. P.-S. Chen, “English sentence structure and entity-relationship
diagrams,” Information Sciences, vol. 29, no. 2, pp. 127–149, 1983.
[Online]. Available: https://www.sciencedirect.com/science/article/pii/
0020025583900142

TABLE IV
CLASSIFYING NLP TECHNIQUES BY LEVELS OF ANALYSIS.

Analysis Level

Explanation

NLP Techniques

Morphology

This is the lowest level of text analysis, dealing with the smallest
parts of words that carry meaning. All the techniques used for
text normalization belong to this category.

Stemming, Lemmatization, Stop-Word Removal, Noise Re-
moval, Punctuation Removal, Lowercasing, Camel Case Split-
ting

Lexical

Syntactic

Semantic
(Word-Level)

This is the word-level of text analysis, interpreting the meaning
of individual words to gain word-level understanding. All the
techniques used for frequency analysis belong to this category. In
addition, Tokenization and n-gram should also be in this category.

This level focuses on analyzing the words in a sentence through
the grammatical structure of the sentence. All the techniques used
for syntactic analysis belong to this category. In addition, the
techniques used for text segmentation and Regular Expression for
Rule-Based Analysis should also belong to this category.

We split the semantic level into word-level semantic and sentence-
level semantic. The word-level semantic focuses on the meanings
of individual words (e.g., dictionary deﬁnitions of words and
word-sense disambiguation). Most techniques used for semantic
tagging and similarly analysis belong to this level. In addition,
apart from n-gram, the techniques used for text representation
belong to this category.

BOW, TF, TF-IDF, Co-location Analysis, Term-Document
Matrix, Character Counting, Concordance, n-gram

POS Tagging, Dependency Parsing, Constituency Parsing,
Link Grammar, Regular Expression, Tokenization, Sentence
Segmentation

Term Extraction, Keyword Searching, Chunking, NER, Tem-
poral Tagging, Lexical Patterns, Cosine Similarity, Lexical
Afﬁnity, Similarity Distance, Document Similarity, Lexical
Similarity, Word2Vec, Context2Vec, Doc2Vec, GloVe, Fast-
Text

Semantic
(Sentence-Level)

Discourse

This level deals with the compositional semantics, which looks
at the interactions among word-level meanings in sentences (e.g.,
semantic role labeling). Most techniques used for semantic analy-
sis belong to this category. In addition, SRL and most techniques
for disambiguation should also belong to this category.

Semantic Parsing, Sentiment Analysis, Text Annotation, Se-
mantic Annotation, Topic Modelling, SRL, Summarization,
LDA, LSI, Semantic Patterns, Case Grammar, Semantic
Frames, Knowledge Graph, TER, Homonym Detection, Syn-
onymy Detection

This level focuses on the properties of the text as a whole
that convey meaning by making connections between component
sentences. Only three techniques belong to this category.

Coreference Resolution, Anaphora Resolution, Generation
Rules

[12] R. J. Abbott, “Program design by informal english descriptions,”
Communications of the ACM, vol. 26, no. 11, pp. 882–894, 1983.
[13] D. M. Berry, N. Yavne, and M. Yavne, “Application of program
design language tools to abbott’s method of program design by
language descriptions,” Journal of Systems and
informal natural
Software, vol. 7, no. 3, pp. 221–247, 1987. [Online]. Available:
https://www.sciencedirect.com/science/article/pii/0164121287900446

[14] G. Booch, R. A. Maksimchuk, M. W. Engle, B. J. Young, J. Connallen,
and K. A. Houston, “Object-oriented analysis and design with applica-
tions,” ACM SIGSOFT software engineering notes, vol. 33, no. 5, pp.
29–29, 2008.

[15] C. Aguilera and D. M. Berry, “The use of a repeated phrase
ﬁnder in requirements extraction,” Journal of Systems and Software,
vol. 13, no. 3, pp. 209–230, 1990.
[Online]. Available: https:
//www.sciencedirect.com/science/article/pii/0164121290900976
[16] C. Rolland and C. Proix, “A natural language approach for requirements
engineering,” in International Conference on Advanced Information
Systems Engineering. Springer, 1992, pp. 257–277.

[17] L. Goldin and D. M. Berry, “Abstﬁnder, a prototype natural language
text abstraction ﬁnder for use in requirements elicitation,” Automated
Software Engineering, vol. 4, no. 4, pp. 375–412, 1997.

[18] L. Mich, “Nl-oops: from natural language to object oriented require-
ments using the natural language processing system lolita,” Natural
language engineering, vol. 2, no. 2, pp. 161–187, 1996.

[19] V. Ambriola and V. Gervasi, “On the systematic analysis of natural
language requirements with Circe,” Automated Software Engineering,
vol. 13, no. 1, pp. 107–167, 2006.

[20] H. M. Harmain and R. Gaizauskas, “Cm-builder: an automated nl-based
case tool,” in Proceedings ASE 2000. Fifteenth IEEE International
Conference on Automated Software Engineering.
IEEE, 2000, pp.
45–53.

[21] F. Fabbrini, M. Fusani, S. Gnesi, and G. Lami, “The linguistic approach
to the natural language requirements quality: beneﬁt of the use of an
automatic tool,” in Proceedings 26th Annual NASA Goddard Software
Engineering Workshop.

IEEE, 2001, pp. 97–105.

of requirement speciﬁcations,” in Proceedings of the 19th international
conference on Software engineering, 1997, pp. 161–171.

[23] J. H. Hayes, A. Dekhtyar, and J. Osborne, “Improving requirements
tracing via information retrieval,” in Proceedings. 11th IEEE Interna-
tional Requirements Engineering Conference, 2003.
IEEE, 2003, pp.
138–147.

[24] J. Cleland-Huang, B. Berenbach, S. Clark, R. Settimi, and E. Ro-
manova, “Best practices for automated traceability,” Computer, vol. 40,
no. 6, pp. 27–35, 2007.

[25] S. F. Tjong and D. M. Berry, “The design of sree—a prototype potential
ambiguity ﬁnder for requirements speciﬁcations and lessons learned,”
in International Working Conference on Requirements Engineering:
Foundation for Software Quality. Springer, 2013, pp. 80–95.
[26] T. Yue, L. C. Briand, and Y. Labiche, “atoucan: an automated frame-
work to derive uml analysis models from use case models,” ACM
Transactions on Software Engineering and Methodology (TOSEM),
vol. 24, no. 3, pp. 1–52, 2015.

[27] A. Ferrari, G. Gori, B. Rosadini, I. Trotta, S. Bacherini, A. Fantechi,
and S. Gnesi, “Detecting requirements defects with nlp patterns:
an industrial experience in the railway domain,” Empirical Software
Engineering, vol. 23, no. 6, pp. 3684–3733, 2018.

[28] H. Femmer, D. M. Fern´andez, S. Wagner, and S. Eder, “Rapid quality
assurance with requirements smells,” Journal of Systems and Software,
vol. 123, pp. 190–213, 2017.

[29] D. Falessi, G. Cantone, and G. Canfora, “Empirical principles and an
industrial case study in retrieving equivalent requirements via natu-
ral language processing techniques,” IEEE Transactions on Software
Engineering, vol. 39, no. 1, pp. 18–44, 2011.

[30] A. Sleimi, N. Sannier, M. Sabetzadeh, L. Briand, and J. Dann, “Au-
tomated extraction of semantic legal metadata using natural language
processing,” in 2018 IEEE 26th International Requirements Engineer-
ing Conference (RE).

IEEE, 2018, pp. 124–135.

[31] J. Bhatia, T. D. Breaux, and F. Schaub, “Mining privacy goals from
privacy policies using hybridized task recomposition,” ACM Transac-
tions on Software Engineering and Methodology (TOSEM), vol. 25,
no. 3, pp. 1–24, 2016.

[22] W. M. Wilson, L. H. Rosenberg, and L. E. Hyatt, “Automated analysis

[32] M. Robeer, G. Lucassen, J. M. E. Van Der Werf, F. Dalpiaz, and

S. Brinkkemper, “Automated extraction of conceptual models from
user stories via nlp,” in 2016 IEEE 24th international requirements
engineering conference (re).

IEEE, 2016, pp. 196–205.

[33] E. Cambria and B. White, “Jumping nlp curves: A review of natural
language processing research,” IEEE Computational intelligence mag-
azine, vol. 9, no. 2, pp. 48–57, 2014.

[34] F. Sebastiani, “Machine learning in automated text categorization,”
ACM computing surveys (CSUR), vol. 34, no. 1, pp. 1–47, 2002.
[35] J. Cleland-Huang, R. Settimi, X. Zou, and P. Solc, “Automated clas-
siﬁcation of non-functional requirements,” Requirements engineering,
vol. 12, no. 2, pp. 103–120, 2007.

[36] D. D. Lewis, “Naive (bayes) at forty: The independence assumption in
information retrieval,” in European conference on machine learning.
Springer, 1998, pp. 4–15.

[37] Z. Kurtanovi´c and W. Maalej, “Automatically classifying functional
and non-functional requirements using supervised machine learning,”
in 2017 IEEE 25th International Requirements Engineering Conference
(RE).

Ieee, 2017, pp. 490–495.

[38] W. Maalej, M. Nayebi, T. Johann, and G. Ruhe, “Toward data-driven
requirements engineering,” IEEE Software, vol. 33, no. 1, pp. 48–54,
2015.

[39] E. C. Groen, N. Seyff, R. Ali, F. Dalpiaz, J. Doerr, E. Guzman, M. Hos-
seini, J. Marco, M. Oriol, A. Perini et al., “The crowd in requirements
engineering: The landscape and challenges,” IEEE software, vol. 34,
no. 2, pp. 44–52, 2017.

[40] W. Maalej, Z. Kurtanovi´c, H. Nabil, and C. Stanik, “On the automatic
classiﬁcation of app reviews,” Requirements Engineering, vol. 21, no. 3,
pp. 311–331, 2016.

[41] T. Merten, M. Falis, P. H¨ubner, T. Quirchmayr, S. B¨ursner, and
B. Paech, “Software feature request detection in issue tracking sys-
tems,” in 2016 IEEE 24th International Requirements Engineering
Conference (RE).

IEEE, 2016, pp. 166–175.
[42] E. Guzman, M. Ibrahim, and M. Glinz, “A little bird told me: Mining
tweets for requirements and software evolution,” in 2017 IEEE 25th
International Requirements Engineering Conference (RE).
IEEE,
2017, pp. 11–20.

[43] I. Morales-Ramirez, F. M. Kifetew, and A. Perini, “Speech-acts based
analysis for requirements discovery from online discussions,” Informa-
tion Systems, vol. 86, pp. 94–112, 2019.

[44] C. Arora, M. Sabetzadeh, L. Briand, and F. Zimmer, “Automated
extraction and clustering of requirements glossary terms,” IEEE Trans-
actions on Software Engineering, vol. 43, no. 10, pp. 918–945, 2016.
[45] J. Winkler and A. Vogelsang, “Automatic classiﬁcation of requirements
based on convolutional neural networks,” in 2016 IEEE 24th In-
ternational Requirements Engineering Conference Workshops (REW).
IEEE, 2016, pp. 39–45.

[46] A. Casamayor, D. Godoy, and M. Campo, “Identiﬁcation of non-
functional requirements in textual speciﬁcations: A semi-supervised
learning approach,” Information and Software Technology, vol. 52,
no. 4, pp. 436–445, 2010.

[47] J. Guo, J. Cheng, and J. Cleland-Huang, “Semantically enhanced soft-
ware traceability using deep learning techniques,” in 2017 IEEE/ACM
39th International Conference on Software Engineering (ICSE).
IEEE,
2017, pp. 3–14.

[48] H. Sultanov and J. H. Hayes, “Application of reinforcement learning
to requirements engineering: requirements tracing,” in 2013 21st IEEE
International Requirements Engineering Conference (RE).
IEEE,
2013, pp. 52–61.

[49] T. Hey, J. Keim, A. Koziolek, and W. F. Tichy, “NoRBERT: Transfer
learning for requirements classiﬁcation,” in 2020 IEEE 28th Interna-
tional Requirements Engineering Conference (RE).
IEEE, 2020, pp.
169–179.

[50] M. Li, L. Shi, Y. Yang, and Q. Wang, “A deep multitask learning
approach for requirements discovery and annotation from open forum,”
in 2020 35th IEEE/ACM International Conference on Automated
Software Engineering (ASE).

IEEE, 2020, pp. 336–348.

[51] S. Gonz´alez-Carvajal and E. C. Garrido-Merch´an, “Comparing bert
against traditional machine learning text classiﬁcation,” arXiv preprint
arXiv:2005.13012, 2020.

[52] D. Jurafsky, Speech & language processing. Pearson Education India,

2000.

[53] S. Bird, E. Klein, and E. Loper, Natural language processing with
” O’Reilly

Python: analyzing text with the natural language toolkit.
Media, Inc.”, 2009.

[54] D. Sarkar, Text Analytics with python. Springer, 2016.
[55] E. D. Liddy, “Natural language processing,” in Encyclopedia of Library

and Information Science. NY. Marcel Decker, Inc., 2001.

[56] D. Gildea and D. Jurafsky, “Automatic labeling of semantic roles,”

Computational linguistics, vol. 28, no. 3, pp. 245–288, 2002.

[57] C. J. Fillmore et al., “Frame semantics and the nature of language,”
in Annals of the New York Academy of Sciences: Conference on the
origin and development of language and speech, vol. 280, no. 1. New
York, 1976, pp. 20–32.

[58] C. J. Fillmore, M. R. Petruck, J. Ruppenhofer, and A. Wright,
“Framenet in action: The case of attaching,” International journal of
lexicography, vol. 16, no. 3, pp. 297–332, 2003.

[59] G. G. Chowdhury, “Natural language processing,” Annual review of
information science and technology, vol. 37, no. 1, pp. 51–89, 2003.
[60] A. Ferrari, G. O. Spagnolo, and S. Gnesi, “Pure: A dataset of public re-
quirements documents,” in 2017 IEEE 25th International Requirements
Engineering Conference (RE).

IEEE, 2017, pp. 502–505.

[61] A. Ferrari, L. Zhao, and W. Alhoshan, “Nlp for requirements engineer-
ing: Tasks, techniques, tools, and technologies,” in Proceedings of the
43rd IEEE/ACM International Conference on Software Engineering.
IEEE, 2021.

[62] W. Maalej, M. Nayebi, and G. Ruhe, “Data-driven requirements
engineering-an update,” in 2019 IEEE/ACM 41st International Con-
ference on Software Engineering: Software Engineering in Practice
(ICSE-SEIP).

IEEE, 2019, pp. 289–290.

[63] I. Tenney, D. Das, and E. Pavlick, “Bert rediscovers the classical nlp

pipeline,” arXiv preprint arXiv:1905.05950, 2019.

[64] M. Nayebi, “Eye of the mind: image processing for social coding,”
in Proceedings of the ACM/IEEE 42nd International Conference on
Software Engineering: New Ideas and Emerging Results, 2020, pp.
49–52.

[65] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.
Gomez, L. Kaiser, and I. Polosukhin, “Attention is all you need,” arXiv
preprint arXiv:1706.03762, 2017.

[66] F. Movahedi, J. L. Coyle, and E. Sejdi´c, “Deep belief networks for
electroencephalography: A review of recent contributions and future
outlooks,” IEEE journal of biomedical and health informatics, vol. 22,
no. 3, pp. 642–652, 2017.

[67] Y. Yu, M. Li, L. Liu, Y. Li, and J. Wang, “Clinical big data and
deep learning: Applications, challenges, and future outlooks,” Big Data
Mining and Analytics, vol. 2, no. 4, pp. 288–305, 2019.

[68] S. Cornegruta, R. Bakewell, S. Withey, and G. Montana, “Modelling
radiological language with bidirectional long short-term memory net-
works,” arXiv preprint arXiv:1609.08409, 2016.

[69] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” nature, vol. 521,

no. 7553, pp. 436–444, 2015.

[70] X. Deng, Y. Li, J. Weng, and J. Zhang, “Feature selection for text
classiﬁcation: A review,” Multimedia Tools and Applications, vol. 78,
no. 3, pp. 3797–3816, 2019.

[71] A. K. Uysal and S. Gunal, “The impact of preprocessing on text
classiﬁcation,” Information Processing & Management, vol. 50, no. 1,
pp. 104–112, 2014.

[72] Y. Wang, L. Shi, M. Li, Q. Wang, and Y. Yang, “A deep context-wise
method for coreference detection in natural language requirements,” in
2020 IEEE 28th International Requirements Engineering Conference
(RE).

IEEE, 2020, pp. 180–191.

[73] A. Sainani, P. R. Anish, V. Joshi, and S. Ghaisas, “Extracting and
classifying requirements from software engineering contracts,” in 2020
IEEE 28th International Requirements Engineering Conference (RE).
IEEE, 2020, pp. 147–157.

[74] S. J. Pan and Q. Yang, “A survey on transfer learning,” IEEE Transac-
tions on knowledge and data engineering, vol. 22, no. 10, pp. 1345–
1359, 2009.

[75] C. C. Aggarwal and C. Zhai, “A survey of text classiﬁcation algo-

rithms,” in Mining text data. Springer, 2012, pp. 163–222.

[76] F. Pereira, T. Mitchell, and M. Botvinick, “Machine learning classiﬁers
and fmri: a tutorial overview,” Neuroimage, vol. 45, no. 1, pp. S199–
S209, 2009.

[77] R. Wagland, A. Recio-Saucedo, M. Simon, M. Bracher, K. Hunt,
C. Foster, A. Downing, A. Glaser, and J. Corner, “Development and
testing of a text-mining approach to analyse patients’ comments on
their experiences of colorectal cancer care,” BMJ quality & safety,
vol. 25, no. 8, pp. 604–614, 2016.

[78] K. Shameer, K. W. Johnson, B. S. Glicksberg, J. T. Dudley, and P. P.
Sengupta, “Machine learning in cardiovascular medicine: are we there
yet?” Heart, vol. 104, no. 14, pp. 1156–1164, 2018.

[79] M. Li, Y. Yang, L. Shi, Q. Wang, J. Hu, X. Peng, W. Liao, and
G. Pi, “Automated extraction of requirement entities by leveraging
lstm-crf and transfer learning,” in 2020 IEEE International Conference
on Software Maintenance and Evolution (ICSME).
IEEE, 2020, pp.
208–219.

[80] C. Palomares, C. Quer, and X. Franch, “Requirements reuse and
requirement patterns: a state of the practice survey,” Empirical Software
Engineering, vol. 22, no. 6, pp. 2719–2762, 2017.

[81] C. Arora, M. Sabetzadeh, A. Goknil, L. C. Briand, and F. Zimmer,
“Change impact analysis for natural language requirements: An nlp
approach,” in 2015 IEEE 23rd International Requirements Engineering
Conference (RE).

IEEE, 2015, pp. 6–15.

[82] S. Ezzini, S. Abualhaija, C. Arora, M. Sabetzadeh, and L. Briand,
“Using domain-speciﬁc corpora for improved handling of ambiguity in
requirements,” in In Proceedings of the 43rd International Conference
on Software Engineering (ICSE’21), Madrid 25-28 May 2021, 2021.
[83] C. Boufaied, M. Jukss, D. Bianculli, L. C. Briand, and Y. I. Parache,
“Signal-based properties of cyber-physical systems: Taxonomy and
logic-based characterization,” Journal of Systems and Software, vol.
174, p. 110881, 2021.

[84] W. Martin, F. Sarro, Y. Jia, Y. Zhang, and M. Harman, “A survey of app
store analysis for software engineering,” IEEE transactions on software
engineering, vol. 43, no. 9, pp. 817–847, 2016.

[85] E. Guzman, L. Oliveira, Y. Steiner, L. C. Wagner, and M. Glinz,
“User feedback in the app store: a cross-cultural study,” in 2018
IEEE/ACM 40th International Conference on Software Engineering:
Software Engineering in Society (ICSE-SEIS).
IEEE, 2018, pp. 13–
22.

[86] C. Stanik, M. Haering, and W. Maalej, “Classifying multilingual user
feedback using traditional machine learning and deep learning,” in
2019 IEEE 27th International Requirements Engineering Conference
Workshops (REW).
IEEE, 2019, pp. 220–226.

[87] G. Lucassen, M. Robeer, F. Dalpiaz, J. M. E. Van Der Werf, and
S. Brinkkemper, “Extracting conceptual models from user stories with
visual narrator,” Requirements Engineering, vol. 22, no. 3, pp. 339–358,
2017.

[88] A. Khan, B. Baharudin, L. H. Lee, and K. Khan, “A review of
machine learning algorithms for text-documents classiﬁcation,” Journal
of advances in information technology, vol. 1, no. 1, pp. 4–20, 2010.
[89] P. H. Swain and H. Hauska, “The decision tree classiﬁer: Design and
potential,” IEEE Transactions on Geoscience Electronics, vol. 15, no. 3,
pp. 142–147, 1977.

[90] G. Forman et al., “An extensive empirical study of feature selection
metrics for text classiﬁcation.” J. Mach. Learn. Res., vol. 3, no. Mar,
pp. 1289–1305, 2003.

[91] C. Cortes and V. Vapnik, “Support-vector networks,” Machine learning,

vol. 20, no. 3, pp. 273–297, 1995.

[92] J. Natt och Dag, B. Regnell, P. Carlshamre, M. Andersson, and
J. Karlsson, “A Feasibility Study of Automated Natural Language
Requirements Analysis in Market-Driven Development,” Requirements
Engineering, vol. 7, no. 1, pp. 20–33, Apr. 2002. [Online]. Available:
https://doi.org/10.1007/s007660200002

[93] B. Gleich, O. Creighton, and L. Kof, “Ambiguity detection: Towards a
tool explaining ambiguity sources,” in International Working Confer-
ence on Requirements Engineering: Foundation for Software Quality.
Springer, 2010, pp. 218–232.

[94] J. Brownlee,
Machine
supervised-and-unsupervised-machine-learning-algorithms/,
online; accessed 17 August 2020.

forecasting:
series
https://machinelearningmastery.com/
2016,

“Deep
learning mastery,”

learning

time

and

[95] T. Hastie, R. Tibshirani, and J. Friedman, “Overview of supervised
learning,” in The elements of statistical learning. Springer, 2009, pp.
9–41.

[96] F. Dalpiaz, D. Dell’Anna, F. B. Aydemir, and S. C¸ evikol, “Re-
quirements classiﬁcation with interpretable machine learning and de-
pendency parsing,” in 2019 IEEE 27th International Requirements
Engineering Conference (RE).

IEEE, 2019, pp. 142–152.

[98] K. Dave, S. Lawrence, and D. M. Pennock, “Mining the peanut gallery:
Opinion extraction and semantic classiﬁcation of product reviews,” in
Proceedings of the 12th international conference on World Wide Web,
2003, pp. 519–528.

[99] N. K. Conroy, V. L. Rubin, and Y. Chen, “Automatic deception detec-
tion: Methods for ﬁnding fake news,” Proceedings of the Association
for Information Science and Technology, vol. 52, no. 1, pp. 1–4, 2015.
[100] J. A. Sidey-Gibbons and C. J. Sidey-Gibbons, “Machine learning in
medicine: a practical introduction,” BMC medical research methodol-
ogy, vol. 19, no. 1, pp. 1–18, 2019.

[101] A. Agarwal, M. Mittal, A. Pathak, and L. M. Goyal, “Fake news
detection using a blend of neural networks: an application of deep
learning,” SN Computer Science, vol. 1, no. 3, pp. 1–9, 2020.
[102] W. Jin, H. H. Ho, and R. K. Srihari, “Opinionminer: a novel machine
learning system for web opinion mining and extraction,” in Proceedings
of the 15th ACM SIGKDD international conference on Knowledge
discovery and data mining, 2009, pp. 1195–1204.

[103] J. Harding, Qualitative data analysis: From start to ﬁnish. Sage, 2018.
[104] B. Kitchenham and S. Charters, “Guidelines for performing systematic

literature reviews in software engineering,” 2007.

[105] F. Fabbrini, M. Fusani, S. Gnesi, and G. Lami, “An automatic quality
evaluation for natural language requirements,” in Proceedings of the
Seventh International Workshop on Requirements Engineering: Foun-
dation for Software Quality REFSQ, vol. 1, 2001, pp. 4–5.

[106] S. Abualhaija, C. Arora, M. Sabetzadeh, L. C. Briand, and E. Vaz,
“A machine learning-based approach for demarcating requirements in
textual speciﬁcations,” in 2019 IEEE 27th International Requirements
Engineering Conference (RE).

IEEE, 2019, pp. 51–62.

[107] N. H. Bakar, Z. M. Kasirun, and N. Salleh, “Feature extraction
approaches from natural language requirements for reuse in software
product lines: A systematic literature review,” Journal of Systems and
Software, vol. 106, pp. 132–149, 2015.

[108] R. Santos, E. C. Groen, and K. Villela, “An overview of user feedback
classiﬁcation approaches,” in Joint Proceedings of REFSQ-2019
Workshops, Doctoral Symposium, Live Studies Track, and Poster Track
co-located with the 25th International Conference on Requirements
Engineering: Foundation for Software Quality (REFSQ 2019), Essen,
Germany, March 18th, 2019, ser. CEUR Workshop Proceedings,
P. Spoletini, P. M¨ader, D. M. Berry, F. Dalpiaz, M. Daneva,
A. Ferrari, X. Franch, S. Gregory, E. C. Groen, A. Herrmann,
A. Hess, F. Houdek, O. Karras, A. Koziolek, K. Lauenroth,
C. Palomares, M. Sabetzadeh, N. Seyff, M. Trapp, A. Vogelsang, and
T. Weyer, Eds., vol. 2376. CEUR-WS.org, 2019. [Online]. Available:
http://ceur-ws.org/Vol-2376/NLP4RE19 paper11.pdf

[109] C. F. Baker, C. J. Fillmore, and J. B. Lowe, “The berkeley framenet
project,” in 36th Annual Meeting of the Association for Computational
Linguistics and 17th International Conference on Computational Lin-
guistics, Volume 1, 1998, pp. 86–90.

[110] C. J. Fillmore, C. R. Johnson, and M. R. Petruck, “Background to
framenet,” International journal of lexicography, vol. 16, no. 3, pp.
235–250, 2003.

[111] N. Yu, M. Zhang, and G. Fu, “Transition-based neural rst parsing
with implicit syntax features,” in Proceedings of the 27th International
Conference on Computational Linguistics, 2018, pp. 559–570.
[112] A. Ferrari, G. Lipari, S. Gnesi, and G. O. Spagnolo, “Pragmatic
ambiguity detection in natural language requirements,” in 2014 IEEE
1st International Workshop on Artiﬁcial Intelligence for Requirements
Engineering (AIRE).

IEEE, 2014, pp. 1–8.

[113] A. Ferrari and A. Esuli, “An nlp approach for cross-domain ambiguity
detection in requirements engineering,” Automated Software Engineer-
ing, vol. 26, no. 3, pp. 559–598, 2019.

[114] C. D. Manning, M. Surdeanu, J. Bauer, J. R. Finkel, S. Bethard,
and D. McClosky, “The stanford corenlp natural language processing
toolkit,” in Proceedings of 52nd annual meeting of the association for
computational linguistics: system demonstrations, 2014, pp. 55–60.

[115] D. Jurafsky and J. Martin, Speech and Language Processing: An In-
troduction to Natural Language Processing, Computational Linguistics,
and Speech Recognition (Draft), 12 2020, vol. 3.

[116] T. Sanders and W. Spooren, “Discourse and text structure,” Handbook

of cognitive linguistics, pp. 916–941, 2007.

[97] B. Pang, L. Lee, and S. Vaithyanathan, “Thumbs up? sentiment classiﬁ-
cation using machine learning techniques,” arXiv preprint cs/0205070,
2002.

[117] E. D. Liddy, “Anaphora in natural language processing and information
retrieval,” Information processing & management, vol. 26, no. 1, pp.
39–52, 1990.

[139] D. Martens and W. Maalej, “Towards understanding and detecting fake
reviews in app stores,” Empirical Software Engineering, vol. 24, no. 6,
pp. 3316–3355, 2019.

[140] D. Falessi, J. Roll, J. L. Guo, and J. Cleland-Huang, “Leveraging his-
torical associations between requirements and source code to identify
impacted classes,” IEEE Transactions on Software Engineering, vol. 46,
no. 4, pp. 420–441, 2018.

[141] J. Frattini, M. Junker, M. Unterkalmsteiner, and D. Mendez, “Automatic
extraction of cause-effect-relations from requirements artifacts,” in
2020 35th IEEE/ACM International Conference on Automated Software
Engineering (ASE).
IEEE, 2020, pp. 561–572.

[142] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “Imagenet:
A large-scale hierarchical image database,” in 2009 IEEE conference
on computer vision and pattern recognition.
Ieee, 2009, pp. 248–255.
[143] W. Yin, J. Hay, and D. Roth, “Benchmarking zero-shot text classiﬁ-
cation: Datasets, evaluation and entailment approach,” arXiv preprint
arXiv:1909.00161, 2019.

[144] E. Arisoy, T. N. Sainath, B. Kingsbury, and B. Ramabhadran, “Deep
neural network language models,” in Proceedings of the NAACL-HLT
2012 Workshop: Will We Ever Really Replace the N-gram Model? On
the Future of Language Modeling for HLT, 2012, pp. 20–28.
[145] B. Chiu, A. Korhonen, and S. Pyysalo, “Intrinsic evaluation of word
vectors fails to predict extrinsic performance,” in Proceedings of the 1st
workshop on evaluating vector-space representations for NLP, 2016,
pp. 1–6.

[146] Y. Shi, Y. Zheng, K. Guo, L. Zhu, and Y. Qu, “Intrinsic or extrinsic
evaluation: An overview of word embedding evaluation,” in 2018
IEEE International Conference on Data Mining Workshops (ICDMW).
IEEE, 2018, pp. 1255–1262.

[147] U. Kamath, J. Liu, and J. Whitaker, Deep learning for NLP and speech

recognition. Springer, 2019, vol. 84.

[148] S. Landolt, T. Wambsganss, and M. S¨ollner, “A taxonomy for deep
learning in natural language processing.” Hawaii International Con-
ference on System Sciences, 2021.

[149] H. N. Mhaskar and T. Poggio, “Deep vs. shallow networks: An
approximation theory perspective,” Analysis and Applications, vol. 14,
no. 06, pp. 829–848, 2016.

[150] I. Sutskever, O. Vinyals, and Q. V. Le, “Sequence to sequence learning
with neural networks,” arXiv preprint arXiv:1409.3215, 2014.
[151] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee,
and L. Zettlemoyer, “Deep contextualized word representations,” arXiv
preprint arXiv:1802.05365, 2018.

[152] A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever, “Improving

language understanding by generative pre-training,” 2018.

[153] J. Howard and S. Ruder, “Universal language model ﬁne-tuning for

text classiﬁcation,” arXiv preprint arXiv:1801.06146, 2018.

[118] M. Binkhonain and L. Zhao, “A review of machine learning algorithms
for identiﬁcation and classiﬁcation of non-functional requirements,”
Expert Systems with Applications: X, vol. 1, p. 100001, 2019.
[119] ——, “Dealing with imbalanced class, short text and high dimension-
ality problems in machine learning-based requirements classiﬁcation:
Method development and evaluation,” Under review, 2021.

[120] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training
of deep bidirectional transformers for language understanding,” arXiv
preprint arXiv:1810.04805, 2018.

[121] T. Young, D. Hazarika, S. Poria, and E. Cambria, “Recent trends in
deep learning based natural language processing,” ieee Computational
intelligenCe magazine, vol. 13, no. 3, pp. 55–75, 2018.

[122] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G.
Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski
et al., “Human-level control through deep reinforcement learning,”
nature, vol. 518, no. 7540, pp. 529–533, 2015.

[123] T. Mikolov, K. Chen, G. Corrado, and J. Dean, “Efﬁcient estimation of
word representations in vector space,” arXiv preprint arXiv:1301.3781,
2013.

[124] K. Kowsari, K. Jafari Meimandi, M. Heidarysafa, S. Mendu, L. Barnes,
and D. Brown, “Text classiﬁcation algorithms: A survey,” Information,
vol. 10, no. 4, p. 150, 2019.

[125] D. S. Cruzes and T. Dyba, “Recommended steps for thematic synthesis
in software engineering,” in 2011 international symposium on empirical
software engineering and measurement.

IEEE, 2011, pp. 275–284.

[126] I. Hussain, L. Kosseim, and O. Ormandjieva, “Using linguistic knowl-
edge to classify non-functional requirements in srs documents,” in
International Conference on Application of Natural Language to In-
formation Systems. Springer, 2008, pp. 287–298.

[127] H. Yang, A. De Roeck, V. Gervasi, A. Willis, and B. Nuseibeh,
“Analysing anaphoric ambiguity in natural language requirements,”
Requirements engineering, vol. 16, no. 3, p. 163, 2011.

[128] E. Knauss, S. Houmb, K. Schneider, S. Islam, and J. J¨urjens, “Support-
ing requirements engineers in recognising security issues,” in Interna-
tional Working Conference on Requirements Engineering: Foundation
for Software Quality. Springer, 2011, pp. 4–18.

[129] L. Yi, W. Zhang, H. Zhao, Z. Jin, and H. Mei, “Mining binary
constraints in the construction of feature models,” in 2012 20th IEEE
International Requirements Engineering Conference (RE).
IEEE,
2012, pp. 141–150.

[130] M. Riaz, J. King, J. Slankas, and L. Williams, “Hidden in plain sight:
Automatically identifying security requirements from natural language
artifacts,” in 2014 IEEE 22nd international requirements engineering
conference (RE).

IEEE, 2014, pp. 183–192.
[131] E. Knauss and D. Ott, “(semi-) automatic categorization of natural
language requirements,” in International Working Conference on Re-
quirements Engineering: Foundation for Software Quality. Springer,
2014, pp. 39–54.

[132] A. Mahmoud and G. Williams, “Detecting, classifying, and tracing non-
functional software requirements,” Requirements Engineering, vol. 21,
no. 3, pp. 357–381, 2016.

[133] Z. S. H. Abad, O. Karras, P. Ghazi, M. Glinz, G. Ruhe, and K. Schnei-
der, “What works better? a study of classifying requirements,” in 2017
IEEE 25th International Requirements Engineering Conference (RE).
IEEE, 2017, pp. 496–501.

[134] M. Lu and P. Liang, “Automatic classiﬁcation of non-functional
requirements from augmented app user reviews,” in Proceedings of
the 21st International Conference on Evaluation and Assessment in
Software Engineering, 2017, pp. 344–353.

[135] C. Li, L. Huang, J. Ge, B. Luo, and V. Ng, “Automatically classifying
user requests in crowdsourcing requirements engineering,” Journal of
Systems and Software, vol. 138, pp. 108–123, 2018.

[136] Z. S. H. Abad, V. Gervasi, D. Zowghi, and B. H. Far, “Supporting
analysts by dynamic extraction and classiﬁcation of requirements-
related knowledge,” in 2019 IEEE/ACM 41st International Conference
on Software Engineering (ICSE).

IEEE, 2019, pp. 442–453.

[137] J. A. Khan, Y. Xie, L. Liu, and L. Wen, “Analysis of requirements-
related arguments in user forums,” in 2019 IEEE 27th International
Requirements Engineering Conference (RE).
IEEE, 2019, pp. 63–74.
[138] W. Zheng, H. Lu, Y. Zhou, J. Liang, H. Zheng, and Y. Deng, “ifeed-
back: exploiting user feedback for real-time issue detection in large-
scale online service systems,” in 2019 34th IEEE/ACM International
Conference on Automated Software Engineering (ASE).
IEEE, 2019,
pp. 352–363.

