1

2
2
0
2

l
u
J

0
3

]
L
P
.
s
c
[

1
v
5
1
3
0
0
.
8
0
2
2
:
v
i
X
r
a

Implementing and Verifying Release-Acquire Transactional
Memory (Extended Version)

SADEGH DALVANDI, University of Surrey, UK
BRIJESH DONGOL, University of Surrey, UK

Transactional memory (TM) is an intensively studied synchronisation paradigm with many proposed imple-
mentations in software and hardware, and combinations thereof. However, TM under relaxed memory, e.g.,
C11 (the 2011 C/C++ standard) is still poorly understood, lacking rigorous foundations that support verifiable
implementations. This paper addresses this gap by developing TMS2-ra, a relaxed operational TM specification.
We integrate TMS2-ra with RC11 (the repaired C11 memory model that disallows load-buffering) to provide a
formal semantics for TM libraries and their clients. We develop a logic, TARO, for verifying client programs
that use TMS2-ra for synchronisation. We also show how TMS2-ra can be implemented by a C11 library,
TML-ra, that uses relaxed and release-acquire atomics, yet guarantees the synchronisation properties required
by TMS2-ra. We benchmark TML-ra and show that it outperforms its sequentially consistent counterpart
in the STAMP benchmarks. Finally, we use a simulation-based verification technique to prove correctness of
TML-ra. Our entire development is supported by the Isabelle/HOL proof assistant.

Additional Key Words and Phrases: Weak Memory, Transactional Memory, C11, Verification, Refinement

1 INTRODUCTION

The advent and proliferation of architectures implementing relaxed memory models has resulted
in many new challenges in the development of concurrent programs. In the context of the C/C++
relaxed memory model defined by C111, over a decade’s worth of research has resulted in rigorous
semantic foundations [Batty et al. 2016, 2011; Kang et al. 2017; Lahav et al. 2017; Lee et al. 2020;
Paviotti et al. 2020], and more recently, logics for reasoning about the correctness of concurrent
programs [Dalvandi et al. 2020a, 2022; Doherty et al. 2019; Doko and Vafeiadis 2017; He et al.
2016; Kaiser et al. 2017; Kang et al. 2017; Lahav and Vafeiadis 2015; Vafeiadis and Narayan 2013;
Wright et al. 2021]. These works have provided the background necessary to develop high-level
abstractions and concurrency libraries over relaxed-memory architectures. Recent works have
included reimplementations of concurrent data structures [Dalvandi and Dongol 2021; Dongol et al.
2018b; Emmi and Enea 2019; Krishna et al. 2020; Raad et al. 2019a], including those with relaxed
specifications that aim to exploit the additional behaviours allowed by relaxed memory.

Our aim for this paper is to implement and verify synchronisation abstractions, fine-tuned for
C11, in the form of transactional memory (TM) libraries, which provide reusable foundations for
high-performance, yet easy to manage concurrency control [Guerraoui and Kapalka 2010; Herlihy
and Moss 1993; Shavit and Touitou 1997]. Implementations include those in software (as STM
libraries) and hardware (Intel-RTM and Armv9). Other variations include hybrid TM that combine
software and hardware TMs and implementations that are natively supported by the compiler (e.g.,
the continued C++ TM Lite development). In addition to supporting general-purpose concurrency,
TM has also been used to develop transactional concurrent objects and data structures [Assa et al.
2020, 2021; Bronson et al. 2010; Lesani et al. 2022]. Intel’s persistent memory development kit
(PMDK) [Scargall 2020] extensively promotes the transactional paradigm (though multi-threaded

1C11 refers to the 2011 ISO specification of C/C++.

Authors’ addresses: Sadegh Dalvandi, m.dalvandi@surrey.ac.uk, University of Surrey, Guildford, UK; Brijesh Dongol,
b.dongol@surrey.ac.uk, University of Surrey, Guildford, UK.

2022. 2475-1421/2022/12-ART1 $15.00
https://doi.org/

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

 
 
 
 
 
 
1:2

Sadegh Dalvandi and Brijesh Dongol

transactions are not directly supported by PMDK’s transactions). These prior works have assumed
SC transactions, i.e., that transactional access provide the same guarantees as sequentially consistent
memory. Our focus is the verification of STMs implemented as a programming language library
with relaxed, release, acquire and release-acquire accesses providing a pathway towards simplified
development of transactional objects (including concurrent data structures) for relaxed memory.
TM implementations provide fine-grained interleaving (for efficiency) that execute with an
illusion of atomicity (for correctness). A completed transaction may be committed or aborted so
that all or none of its effects are externally visible. TM implementations are designed to satisfy
a variety of correctness conditions such as (strict) serialisability, opacity, and snapshot isolation,
which restrict ordering possibilities of completed transactions. TM has been extensively studied
for sequentially consistent (SC) architectures [Lamport 1979], but implementations over relaxed
memory are limited.

Prior works on relaxed memory transactions (e.g., [Chong et al. 2018; Dongol et al. 2018a])
have focussed on foundations of hardware transactions and their interaction with relaxed memory
models, e.g., the expected isolation guarantees, reordering possibilities etc. The work of Chong et
al [Chong et al. 2018] also provides for semantics of native C++ transactions. However, native TM
support in C++ is still in a state of flux [Spear et al. 2020; Zardoshti et al. 2019] and the underlying
designs have changed since the original works by Chong et al [Chong et al. 2018]. Moreover,
these semantics are presented in an axiomatic (aka declarative) style, which cannot be used to
verify TM implementations, where we require operational descriptions of correctness. Therefore,
our point of departure is a separate set of works on TM specifications, in particular the TMS2
specification [Doherty et al. 2013], which has been used extensively as a TM specification for
standard (i.e., SC) architectures.

More recent works have taken steps towards C++ implementations, including native support of
TM within C++ [Zardoshti et al. 2019] and STMs implemented using C++ relaxed memory [Ro-
driguez and Spear 2020]. However, Zardoshti et al. [2019] do not describe interactions with the C11
relaxed memory model, while Rodriguez and Spear [Rodriguez and Spear 2020] focus on data race
freedom and privatisation guarantees. Neither of these works have a formal semantics, nor are
they supported by a verification methodology. (See §7 for a more comprehensive survey of related
works.)

Our work addresses several gaps in the current state-of-the-art of transactions for C/C++. We
work with RC11, i.e., the repaired C11 memory model [Lahav et al. 2017]. The RC11 memory model
disallows program-order and reads-from cycles, and hence disallows load-buffering behaviour.
This restriction greatly simplifies reasoning and variants of RC11 are supported by a number of
different logics [Dalvandi et al. 2020a; Dalvandi and Dongol 2021; Dalvandi et al. 2022; Dang et al.
2022; Kaiser et al. 2017; Lahav and Vafeiadis 2015]. Logics that address the full C11 memory model
(allowing load buffering) have also been developed, but proofs in these logics are limited to small
litmus tests [Svendsen et al. 2018; Wright et al. 2021].

We develop: (i) a reusable specification of TM that provides well-defined guarantees to those
developing client programs; (ii) techniques for verifying client programs in C11 that use such
TM abstractions; (iii) implementations of TM in C11, including their rigorous verification; and
(iv) mechanisation of the verification described above in the theorem prover Isabelle/HOL. We
discuss these contributions in more detail below.

Correctness specifications. To enable verification, we start with the TMS2 specification [Doherty
et al. 2013]. TMS2 implies the TMS1 specification, which is known to be both necessary and
sufficient for observational refinement (of client programs) [Attiya et al. 2018]. The main difference
between TMS1 and TMS2 is that TMS1 allows aborted transactions to observe different serialization

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:3

orders [Lesani et al. 2012]. In contrast, TMS2, like opacity [Guerraoui and Kapalka 2010], ensures
strict serializability of the committed transactions and furthermore that aborted transactions are
consistent with the serialisation order. Although more restrictive than TMS1, TMS2 has been shown
to be a robust correctness condition that is useful in practice, providing a specification for a number
of TM implementations under SC [Armstrong and Dongol 2017; Armstrong et al. 2017; Derrick
et al. 2018; Doherty et al. 2016].

Under relaxed memory, the TMS2 specification is inadequate since it does not provide any of the
client-side guarantees required by relaxed memory libraries [Dalvandi and Dongol 2021; Dongol
et al. 2018b; Raad et al. 2019a, 2018]. Such client-side guarantees are required under relaxed memory
since writes in one thread are not guaranteed to be propagated to other threads unless the library
is properly synchronised (cf. the message passing litmus tests [Alglave et al. 2014]).

Our first contribution is the adaptation of TMS2 to address this issue. In particular, our specifi-
cation, TMS2-ra, provides a flexible meaning of correctness, allowing a client to specify relaxed,
releasing, acquiring and release-acquiring transactions (see §3), mimicking the memory annotations
of C11 atomics [Batty et al. 2011]. This provides greater flexibility in TM design; we develop a
model in which these different types of transactions co-exist within the same TM system.

Client verification. Our second contribution (see §5) is a verification technique for relaxed-
memory client programs that use TMS2-ra. In particular, we prove correctness of several variations
of the message passing litmus test, synchronised through TMS2-ra transactions, to show that
TMS2-ra behaves as expected. In particular, we show how different client-side guarantees are
achieved depending on the type of synchronisation guarantee (relaxed, releasing or acquiring)
guaranteed by the transaction in question.

Our verification framework includes a new logic, TARO, capable of efficiently reasoning about the
views of a client programs [Dalvandi et al. 2022; Kaiser et al. 2017]. This means that the correctness
of programs can be established using a standard Owicki-Gries reasoning framework [Dalvandi
et al. 2020a; Dalvandi and Dongol 2021; Owicki and Gries 1976].

Implementation, benchmarking and verification. Our third contribution is the implementation and
full verification of an STM algorithm that uses C11 relaxed/release-acquire atomics and implements
TMS2-ra. Our implementation is an adaptation of Dalessandro et al’s Transactional Mutex Lock
(TML) [Dalessandro et al. 2010], which presents a simple mechanism for synchronising transactions
optimised for read-heavy workloads. TML is synchronised using a single global lock, and allows
multiple concurrent read-only transactions, but at most one writing transaction, i.e., a writing
transaction causes all other concurrent transactions to abort.

Interestingly, our adapted algorithm, which we call TML-ra, allows more concurrency than TML
by exploiting the parallelism afforded by relaxed and release-acquire C11 atomics. Moreover, a
writing transaction does not force other read-only transactions to abort, allowing greater read/write
parallelism (see §4). We show that this theoretical speedup manifests in real implementations and
TML-ra outperforms its SC counterpart in all STAMP benchmarks (see §4.3).

We use a simulation-based verification method for the C11 memory model [Dalvandi and Dongol
2021] to prove correctness of TML-ra. This proof establishes a refinement between TML-ra and
TMS2-ra, which ensures that all observable behaviours of TML-ra are observable behaviours of
TMS2-ra. Thus, if a client program 𝐶 is proved correct when it uses TMS2-ra, then 𝐶 will also be
correct if we replace calls to TMS2-ra in 𝐶 by calls to TML-ra.

Mechanisation. Our fourth contribution is the mechanisation of all proofs presented in the
paper in the Isabelle/HOL proof assistant (available as supplementary material). This includes
the operational semantics of C11 integrated with TMS2-ra, soundness of all TARO rules, the use

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:4

Sadegh Dalvandi and Brijesh Dongol

Thread 𝜏1 Thread 𝜏2
1 : 𝑑 := 5;
2 : 𝑓 := 1;

3 : do 𝑟1 ← 𝑓

until 𝑟1 = 1;

4 : 𝑟2 ← 𝑑;
{𝑟2 = 0 ∨ 𝑟2 = 5}
(a) Unsynchronised MP

Thread 𝜏1
1 : 𝑑 := 5;
2 : 𝑓 :=R 1;

Thread 𝜏2
3 : do 𝑟1 ←A 𝑓
until 𝑟1 = 1;

4 : 𝑟2 ← 𝑑;

{𝑟2 = 5}
(b) Synchronised MP

Fig. 1. Message passing (MP) in C11

of TARO to prove several client programs that use TMS2-ra, and finally the proof of simulation
between TMS2-ra and TML-ra.2

Overview. This paper is structured as follows. We describe our requirements for relaxed and
release-acquire transactions in §2. We formalise this semantics in §3 via the TMS2-ra specification,
and describe its integration with a view-based semantics for RC11 with release-acquire atom-
ics [Dalvandi et al. 2020a]. In §4, we provide an examplar implementation and benchmarking results
for TML-ra. In §5, we present our logic for reasoning about release-acquire transactional memory,
which provides a method of reasoning about client programs that use the TMS2-ra specification.
Finally, in §6, we present a proof of correctness of TML-ra via refinement w.r.t. TMS2-ra.

2 TRANSACTIONAL GUARANTEES IN C11

A TM specification in a relaxed memory setting has two distinct sets of goals. The first set must
guarantee the expected behaviours of transactions, e.g., serializability, opacity etc. The second must
provide client-side guarantees, e.g., release-acquire synchronisation, observational refinement etc.
We consider both in our TMS2-ra specification (see Fig. 4).

2.1 Release-acquire synchronisation

Prior to detailing the design choices of TMS2-ra, we recap the basics of release-acquire synchroni-
sation in C11, including a recently developed timestamp-based operational semantics, which is the
semantics assumed by TMS2-ra.

The fragment of C11 we focus on is the RC11-RAR fragment. The first “R” denotes the repairing
model [Lahav et al. 2017], which precludes ‘thin-air’ behaviour by disallowing memory operations
within a thread to be reordered. The “RAR” refers to the fact that the model includes release-acquire
as well as relaxed atomics [Dalvandi et al. 2020b; Doherty et al. 2019]. 3 For the remainder of this
paper, we simply write C11 to refer to RC11-RAR.

We explain the main ideas behind release-acquire synchronisation using the message passing
(MP) litmus test in Figs. 1a and 1b. It comprises two shared variables: 𝑑 (for data) and 𝑓 (for a flag),
both of which are initially 0. Under SC, the postcondition of the program is 𝑟2 = 5 because the loop
in thread 𝜏2 only terminates after 𝑓 has been updated to 1 in thread 𝜏1, which in turn happens after
𝑑 is set to 5. Therefore, the only possible value of 𝑑 that thread 𝜏2 can read is 5.

However, in Fig. 1a, all read/write accesses of 𝑑 and 𝑓 are relaxed, and hence the program can
only establish the weaker postcondition 𝑟2 = 0 ∨ 𝑟2 = 5 since it is possible for thread 𝜏2 to read 0
for d at line 4. In particular, reading 1 for 𝑓 does not guarantee that thread 𝜏2 will read 5 for 𝑑.

2Our development may be found in [Dalvandi and Dongol 2022].
3Note that extending this model to include other types of C11 synchronisation (e.g., SC fences) and relaxations that allow
intra-thread ordering is possible [Wright et al. 2021], but these extended models are not so interesting for the purposes of
this paper, and the additional complexity that they induce detracts from our main contributions.

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:5

Thread 𝜏1
1 : 𝑑 := 5;
2 : TxBegin(R)
3 : TxWrite(𝑓 , 1) ;
4 : TxEnd ;

Thread 𝜏2
5 : do
TxBegin(A, {r1})
6 :
TxRead(𝑓 , 𝑟1) ;
7 :
TxEnd ;
8 :
9 : until 𝑟1 = 1
10 : 𝑟2 ← 𝑑

{𝑟2 = 5}

Thread 𝜏1
1 : 𝑑1 := 5;
2 : TxBegin(RX, ∅) ;
3 : TxWrite(𝑑2, 10) ;
4 : TxWrite(𝑓 , 1) ;
5 : TxEnd ;

Thread 𝜏2
6 : TxBegin(RX, {r1, r2})
7 : TxRead(𝑓 , 𝑟1) ;
8 : if 𝑟1 = 1 then
9 :
10 : TxEnd;
11 : 𝑟3 ← 𝑑1;

TxRead(𝑑2, 𝑟2) ;

{𝑟1 = 1 ⇒ 𝑟2 = 10 ∧ 𝑟3 ∈ {0, 5}}

(a) Transactional MP

(b) Relaxed transactions

Thread 𝜏1
1 : 𝑑1 := 5;
2 : TxBegin(R, ∅)
3 : TxWrite(𝑓 , 1) ;
4 : TxEnd;

Thread 𝜏2
5 : 𝑑2 := 10;
6 : TxBegin(RA, {r2})
7 : TxRead(𝑓 , 𝑟2) ;
8 : if 𝑟2 = 1 then
9 :
10 : TxEnd;
{𝑟3 = 2 ⇒ 𝑠1 = 5 ∧ 𝑠2 = 10}
(c) Extended transactional MP

TxWrite(𝑓 , 2)

Thread 𝜏3
11 : TxBegin(A, {r3})
12 : TxRead(𝑓 , 𝑟3) ;
13 : TxEnd ;
14 : if 𝑟3 = 2 then
𝑠1 ← 𝑑1
15 :
𝑠2 ← 𝑑2
16 :

Fig. 2. Transactional memory client interactions

This anomaly is corrected in Fig. 1b where the highlighted code depicts the necessary changes.
In particular, we introduce a release annotation (line 2) as well as an acquire annotation (line 3),
which together induces a happens-before relation if the read of 𝑓 at line 3 reads from the write at
line 2 (see [Batty et al. 2011]). This in turn ensures that thread 𝜏2 sees the most recent write to 𝑑 at
line 1. We explain how relaxed accesses and release-acquire synchronisation is formalised by the
operational semantics in §3.1.

2.2 Transactional message passing

We now describe the guarantees provided by our transactional model in the context of a client
program. Like standard reads and writes in C11, we allow transactions to be combined with a
synchronising annotation, which may be one of relaxed (RX), releasing (R), acquiring (A), or release-
acquiring (RA). These annotations dictate whether or not transaction induces a client-side happens
before. In particular, client-side happens-before is induced from thread 𝜏1 to thread 𝜏2 if (i) a read
in transaction 𝑡2 executed by 𝜏2 reads-from a write in transaction 𝑡1 executed by 𝜏1, (ii) 𝑡1 contains
a release annotation (either R or RA), and (iii) 𝑡2 contains an acquire annotation (either A or RA).
We illustrate the implications of these annotations via the examples in Fig. 2, where the highlights
are used to identify the transactions. We assume that a client provides a transaction with a set of
registers that it may use when the transaction begins (see §3).

Fig. 2a describes a transactional variation of MP. Thread 𝜏1 comprises a (non-transactional)
relaxed write on 𝑑 followed by a transactional write of the flag, 𝑓 . Thread 𝜏2 contains a transactional
read of 𝑓 within a loop that terminates if 𝜏2 reads 1 for 𝑓 . After the loop terminates, 𝜏2 performs a
(non-transactional) relaxed read of 𝑑. In this example, like Fig. 1b, the release and acquire annotations
induce a happens-before relation from 𝜏1 to 𝜏2 and hence ensure that the read of 𝑑 in 𝜏2 does not
return the stale value, 0.

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:6

Sadegh Dalvandi and Brijesh Dongol

Fig. 2b describes a program that uses a relaxed transaction. The postcondition of the program
considers the case where the transaction in 𝜏1 occurs before the transaction in 𝜏2 since the an-
tecedent assumes that 𝑟1 = 1, i.e., the read of 𝑓 at line 7 reads the write of 𝑓 at line 4. In this example,
both transactions are relaxed, and hence, the ordering of transactions above does not induce a
happens before from 𝜏1 to 𝜏2. Thus, the read of 𝑑1 at line 11 is not guaranteed to see the write of 𝑑1
at line 1, i.e., the final value of 𝑟3 is either 0 or 5. However, since the write and read of 𝑑2 occurs
within the transactions of 𝜏1 and 𝜏2, respectively, if 𝑟1 = 1, then 𝜏2 is guaranteed to read 10 for 𝑑2.
Finally, Fig. 2c demonstrates a program with an RA transaction. The antecedent of the program’s
postcondition implies that the transaction in 𝜏3 occurs after the transaction in 𝜏2, which in turn
occurs after the transaction in 𝜏1. Here, the transaction annotations ensure that the writes to
𝑑1 and 𝑑2 (at lines 1 and 5) performed by the client are seen by the client reads at lines 15 and
16. This is because the transaction in 𝜏2 (annotated by RA) is guaranteed to synchronise with
the transaction in 𝜏1 (annotated by R), and similarly, the transaction in 𝜏2 (annotated by A) is
guaranteed to synchronise with the transaction in 𝜏2 (annotated by RA). Note that if the transaction
in 𝜏2 was only releasing, then 𝜏1 and 𝜏2 would not synchronise, and the read at line 15 may return
either 0 or 5. Yet, the read at line 16 would still be guaranteed to return 10 for 𝑑2 since 𝜏2 and 𝜏3
synchronise. If the transaction in 𝜏2 was only acquiring, then 𝜏2 and 𝜏3 would not synchronise.
In this case, although 𝜏1 and 𝜏2 have synchronised, neither of the reads at lines 15 and 16 are
guaranteed to return the new writes at lines 1 and 5.

Deciding a transaction’s synchronisation flag ultimately comes down to the needs of a client
program, much like memory_order parameters on atomic_compare_exchange instructions in
C11 [cppreference.com 2022]. Client programs that require message passing through transactions
would use release-acquire, while others may only require relaxed annotations.

3 RELEASE-ACQUIRE TM SPECIFICATION

With the basic requirements for release-acquire and transactional synchronisation in place, we
work towards a formal TM specification. Our specification will be closely tied to an operational
semantics for C11 with timestamped writes and per-thread views [Dalvandi et al. 2020a; Dolan
et al. 2018; Kaiser et al. 2017; Kang et al. 2017; Podkopaev et al. 2016] (see §3.1). We integrate this
model with a TM specification in §3.3.

3.1 View-based operational semantics
As discussed above, in our model, the C11 relaxed memory state is formalised by timestamped writes.
Instead of mapping each location to a value, the state contains a set of writes writes ⊆ Write,
where Write = Loc × Val × TS represents a write to a location Loc with value Val and 𝑇 𝑆 ˆ= Q is
the set of possible timestamps. If 𝑤 ∈ Write and 𝑤 = (𝑥, 𝑣, q), then we let loc(𝑤) ˆ= 𝑥, val(𝑤) ˆ= 𝑣,
tst(𝑤) ˆ= q, be the functions that extract the location, value and timestamp of 𝑤, respectively.

A view is a mapping from a location to a write of that location, i.e., View ˆ= Loc → Write. To
define the allowable reads by each thread to each location, the state also records a thread view for
each thread define by a function

tview : TId → View
where TId ˆ= N is the set of thread identifiers. A thread may read from any write whose timestamp
is no smaller than the thread’s current view. Thus, the observable values (OV ), i.e., the set of values
that thread 𝜏 can read for location 𝑥 is

OW 𝜏 (𝑥) ˆ= (cid:8)w ∈ writes loc(w) = 𝑥 ∧ tst(w) ≥ tst(tview𝜏 (𝑥))(cid:9)
OV 𝜏 (𝑥) ˆ= {val(w) | w ∈ OW 𝜏 (𝑥)}

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:7

𝑑

𝑓

0, 0

𝜏2

0, 0

𝜏1

𝑑

𝑓

𝜏2

0, 0

𝜏1

0, 0

5, 1

𝜎0

𝜎1

𝑑

𝑓

0, 0

5, 1

𝜏2

0, 0

𝜏1
1R ,1

𝜎2

𝑑

𝑓

0, 0

5, 1

𝜏2

0, 0

𝜏1
1R ,1

𝜎3

Fig. 3. Synchronised message passing views

A write may be introduced at any timestamp greater than the thread’s current view (with a caveat
that ensures atomicity of read-modify-writes, see [Dalvandi et al. 2020a; Doherty et al. 2019] for
details).

Finally, to formalise release-acquire synchronisation, a state in the timestamp model also includes

a notion of a modification view,

mview : Write → View
which is a function that records the thread view of the executing thread when a new write is
introduced to writes. In particular, if thread 𝜏 introduces a new write w to writes and tview𝜏 is
updated to 𝑣𝑖𝑒𝑤 in this new state, then mview is also updated so that mvieww = 𝑣𝑖𝑒𝑤 in the new
state. This information is used to update thread views in case release-acquire synchronisation
occurs.

Formally, when threads synchronise, a new view is calculated using ⊗, which is defined as

follows. Given 𝑉1, 𝑉2 ∈ View, we have

𝑉1 ⊗ 𝑉2 ˆ= 𝜆𝑥 . if tst(𝑉2(𝑥)) ≤ tst(𝑉1(𝑥)) then 𝑉1(𝑥) else 𝑉2(𝑥)
which constructs a new view by taking the write with the larger timestamp for each location 𝑥.

Example 1 (Synchronised MP). Consider Fig. 3, which depicts a possible execution of the program
in Fig. 1b. Each “𝑣, 𝑖” represents a “value, timestamp” pair for the location in question. The initial
state is 𝜎0, where the views of threads 𝜏1 and 𝜏2 are both the initial writes. State 𝜎1 occurs after
executing line 1, where the view of 𝜏1 is updated to the new write on 𝑑. Similarly, 𝜎2 occurs
after executing line 2. Note that the new write is tagged with a release annotation. Moreover,
the operational semantics guarantees that in 𝜎2, we have 𝜎2.mview( 𝑓 ,1,1) (𝑑) = (𝑑, 5, 1), i.e., the
modification view of the write (𝑓 , 1, 1) returns (𝑑, 5, 1) for 𝑑 (since this was the thread view of 𝜏1
for 𝑑 when the write at line 2 occurred).

Finally, 𝜎3 depicts the state after execution of line 3, where the read returns the value 1 for
𝑓 . In this case, the thread view of 𝜏2 for 𝑓 is updated to the new read. More importantly, due to
release-acquire annotations the semantics enforces that the thread view of 𝜏2 for 𝑑 in 𝜎3 is also
updated to the new modification view, i.e., 𝜎2.mview(𝑓 ,1,1) (𝑑). Thus, after state 𝜎3, 𝜏2 will no longer
be able to return the stale value 0 for 𝑑.

The key difference in execution of the unsynchronised example (Fig. 1a) is that the read at line 3
does not update tview𝜏2(𝑑). Hence, for the state of Fig. 1a analogous to 𝜎3, the view of 𝜏2 for 𝑑
will remain at the initial write, allowing it to return a stale value.

3.2 TMS2
First, we consider the TMS2 specification, which is our TMS2-ra specification without any client-
side release-acquire guarantees. This is given by the unhighlighted components of Fig. 4, which

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:8

Sadegh Dalvandi and Brijesh Dongol

correspond precisely to the internal actions of TMS2 [Doherty et al. 2013].4 Note that each action
of Fig. 4 is atomic and guarded by the conditions defined in pre. If all the conditions in pre hold
the transition is enabled, and the corresponding action atomically updates the state according to
the assignments and functions in eff. If some condition in pre does not hold then the transition is
blocked. We use ⊓ to denote a non-deterministic choice (see [Lynch 1996] for details).

TMS2 is a close operational approximation of opacity [Guerraoui and Kapalka 2010]. The dif-
ferences between TMS2 and opacity are minor [Lesani et al. 2012], and much of the discussion
below applies equally to opacity. TMS2 (and opacity) distinguishes between completed and live
transactions, where completed transaction may either be committed or aborted. TMS2 guarantees
the existence of a total order ≺ over all transactions such that:

(1) if transaction 𝑡1 executes TxEnd before 𝑡2 executes TxBegin, then 𝑡1 ≺ 𝑡2;
(2) for any transaction 𝑡, if ≺↓𝑡 is the strict downclosure of 𝑡 w.r.t. ≺ and 𝑚 is the memory

obtained by applying the committed transactions in ≺↓𝑡 in order, then
• all internal reads in 𝑡 for a variable 𝑥 are consistent with the last write to 𝑥 in 𝑡, and
• all external reads of 𝑡 are consistent with 𝑚.

Note that conditions (1) and (2) together imply strict serialisability of the transactions. Condition (2)
additionally ensures that no transaction reads from an aborted or live transaction since all external
writes can be explained by the prior writes of committed transactions only. Moreover, reads of
all transactions (including aborted and live transactions) never return a spurious value, i.e., each
non-aborting read can be explained by prior committed transactions.

The existence of the total order mentioned above is guaranteed by the TMS2 specification as
follows. Each transaction 𝑡 comprises a local read set, rdSet𝑡 , local write set, wrSet𝑡 , and variable,
status𝑡 that is used to model control flow within a transaction. If the status of 𝑡 is NOTSTARTED, 𝑡
may transition to status READY if a thread 𝜏 executes TxBegin𝜏 . Once ready, 𝜏 may execute some
number of TxRead and TxWrite operations, or TxEnd, which sets the status of 𝑡 (the transaction
that 𝜏 is executing) to COMMITTED. Note that if transaction 𝑡 is READY, it may transition to status
ABORT at any time. Moreover, in some circumstances, 𝑡 may be forced to abort because all other
transitions of 𝑡 are blocked. For example, if 𝑡 is a writing transaction and 𝑡’s read set is not a subset
of last (𝑀), then 𝑡 must abort.

To ensure read/write consistency, TMS2 uses a sequence of memories 𝑀, where a memory is a
mapping from locations to values. A transaction 𝑡 records the earliest memory it can read from by
setting beginIdx𝑡 to the last index of 𝑀 when 𝑡 executed TxBegin𝜏 . Moreover, each committing
writing transaction 𝑡 constructs a new memory 𝑁 = last (𝑀) ⊕ wrSet𝑡 which is the memory last (𝑀)
overwritten with the write set of 𝑡. It then appends 𝑁 to the end of 𝑀 (see TxEndWR).

We differentiate between internal reads TxReadInt and external reads TxReadExt, by whether
the read location 𝑥 is in the write set of the executing transaction, 𝑡. An internal read of 𝑥 simply
returns the value of 𝑥 in the write set of 𝑡. An external read of 𝑥 non-deterministically picks a
memory index 𝑖. This read is enabled iff 𝑖 is a valid index (i.e., is between beginIdx𝑡 and the last
memory index, |𝑀 | − 1) and the read set of 𝑡 is consistent with 𝑀𝑖 (i.e., the memory at index 𝑖). In
case an external read occurs, the read set is updated and the value read is returned. This means
that all external reads in 𝑡 are validated with respect to some memory snapshot between beginIdx𝑡
and the maximum memory index. Note that it is possible for two different reads to validate w.r.t.
different memory snapshots.

TMS2 prescribes a lazy write-back strategy via TxWrite, where writes are cached in a local write
set until the commit occurs (as described above). However, as we shall see, this does not preclude

4TMS2-ra, like TMS2 is presented as an I/O automaton [Lynch 1996]. For simplicity, we eschew the external actions, but
they can easily be included to formalise the TM interface.

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:9

implementations that use eager write-backs, where writes occur in memory at the time of writing
(see [Derrick et al. 2018]). In fact, the TML-ra algorithm, our main case study in this paper, is such
an eager algorithm (see §4).

We split the commit phase into two cases: read-only (modelled by TxEndRO) and writing (modelled
by TxEndWR). Since all reads are validated at the time of reading, a read-only transaction can simply
commit the transaction. On the other hand, the writing transaction must ensure its reads are valid
w.r.t. the last memory snapshot. The effect of this transition is to install a new memory snapshot as
described above.

The final component of 𝑡 is a local set regs𝑡 that is used to keep track of the set of registers that
the transaction has written to. A client provides the set of registers to be used by each transaction
when the transaction begins. These registers are set to a special value ⊥ when a transaction aborts
to ensure that no value read by 𝑡 is seen outside 𝑡.

3.3 TMS2-ra

We now discuss the release-acquire extensions of TMS2-ra, as defined by the I/O automata algorithm
in Fig. 4, including the highlighted components. The key extension of TMS2-ra is its ability to
synchronise client threads, thus allowing it to cope with the examples in Fig. 2. Formally, this is
achieved by ensuring TMS2-ra synchronises the thread view of the client whenever transactional
release-acquire synchronisation occurs.

We introduce two new local variables in transaction 𝑡. Namely, synctype𝑡 , which records the
type of synchronisation of 𝑡, and seenIdxs𝑡 , which records the set of all memory indices seen
by 𝑡 that are either releasing or release-acquiring. We also introduce a new thread local variable
txview, which records the transaction thread view of 𝜏. The transaction thread view is similar to
thread view introduced in §3.1. The difference here is in the definition of View. In this context the
View is a function that maps the threads to memory indexes of 𝑀. The transaction view of 𝜏 is
the smallest memory in 𝑀 that can be read by any transaction 𝑡 that was begun by thread 𝜏. We
also introduce two global variables. Namely 𝑆, which is a sequence recording the type of each
committed writing transaction that installs each new memory in 𝑀, and 𝑉 which is a sequence of
modification views for each new memory in 𝑀. Thus, in TMS2-ra, memory 𝑀𝑖 has synchronisation
type 𝑆𝑖 , and modification view 𝑉𝑖 .

The transactional operations of TMS2 are modified as follows. In TxBegin𝑡 , we take as input the
type of synchronisation transaction 𝑡 is to perform, and store this value in synctype𝑡 . Another
input to TxBegin𝑡 is 𝑚, an index to a visible memory 𝑀. We also initialise seenIdxs𝑡 to the empty
set. In TxReadExt𝑡 (𝑥, 𝑖), i.e., a transition for external read of 𝑥 from memory index 𝑖, we record the
index 𝑖 in seenIdxs𝑡 if the memory 𝑀𝑖 is releasing or release-acquiring.

When a transaction ends (for both read-only and writing transactions), if the transaction is
acquiring or release-acquiring and seenIdxs𝑡 is non-empty, we construct a new view nv to be the
maximum modification view for each transaction in seenIdxs𝑡 using the function view. We use this
to synchronise the client thread’s view by updating tview𝜏 to tview𝜏 ⊗ nv. For a writing transaction,
we record this new view of the client in 𝑉 so that any future transactions that synchronise with
this new transaction does so with respect to this view. Finally, once a transaction ends, it updates
txview to the largest index in seenIdxs.

We demonstrate the interaction of TMS2-ra and a client program by considering the views of
three possible executions of the programs in Fig. 5. Unlike the trace considered in Fig. 3, we only
show the most critical transitions. The memory sequence 𝑀 of TMS2-ra is clear from the figures.
We represent 𝑆 by the superscripts on each state of 𝑀, and the modification views 𝑉 by the dotted
arrows (

) from each state of 𝑀.

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:10

Sadegh Dalvandi and Brijesh Dongol

TxBeginV𝜏 ( sflag , 𝑚 ,regSet)
pre status𝑡 = NOTSTARTED

txn𝜏 = ⊥
𝑚 ∈ OM𝜏
eff wrSet𝑡 :=∅
rdSet𝑡 :=∅
beginIdx𝑡 := 𝑚
seenIdxs𝑡 :=∅
synctype𝑡 :=sflag
regs𝑡 :=regSet
txn𝜏 :=𝑡
status𝑡 :=READY

TxWrite𝜏 (𝑥, 𝑣)
pre status𝑡 = READY

txn𝜏 = 𝑡

eff wrSet𝑡 :=wrSet𝑡 ∪{𝑥 ↦→ 𝑣 }

TxReadInt𝜏 (𝑥, 𝑟 )
pre status𝑡 = READY

𝑥 ↦→ 𝑣 ∈ wrSet𝑡
𝑟 ∈ regs𝑡
txn𝜏 = 𝑡

eff 𝑟 :=𝑣

TxReadExt𝜏 (𝑥, 𝑖, 𝑟 )
pre status𝑡 = READY
𝑥 ∉ dom(wrSet𝑡 )
beginIdx𝑡 ≤ 𝑖 < |𝑀 |
rdSet𝑡 ⊆ 𝑀𝑖
txn𝜏 = 𝑡

TxEndRO𝜏
pre status𝑡 = READY
wrSet𝑡 = ∅
txn𝜏 = 𝑡

eff status𝑡 :=COMMIT

if synctype𝑡 ∈ {A, RA} ∧ seenIdxs𝑡 ≠ ∅
then

let nv = view(seenIdxs𝑡 ,V) in
tview𝜏 := tview𝜏 ⊗ nv

txn𝜏 :=⊥
txview𝜏 := max(seenIdxs𝑡 )

TxEndWR𝜏
pre status𝑡 = READY
wrSet𝑡 ≠ ∅
rdSet𝑡 ⊆ last (𝑀)
txn𝜏 = 𝑡

eff 𝑀:= 𝑀 · (last (𝑀) ⊕ wrSet𝑡 )

status𝑡 :=COMMIT
if synctype𝑡 ∈ {A, RA} ∧ seenIdxs𝑡 ≠ ∅
then

let nv = view(seenIdxs𝑡 ,V) in

𝑉 := 𝑉 · (tview𝜏 ⊗ nv)
tview𝜏 := tview𝜏 ⊗ nv

else 𝑉 := 𝑉 · tview𝜏
𝑆:= 𝑆 · synctype𝑡
txn𝜏 :=⊥
txview𝜏 := max(seenIdxs𝑡 )

Abort𝜏
pre status𝑡 = READY

eff rdSet𝑡 :=rdSet𝑡 ∪ {𝑥 ↦→ 𝑀𝑖 (𝑥)}

txn𝜏 = 𝑡

if 𝑆𝑖 ∈ {R, RA}
then seenIdxs𝑡 := seenIdxs𝑡 ∪ {𝑖}
𝑟 :=𝑀𝑖 (𝑥)

eff ∀𝑠 ∈ regs𝑡 . 𝑠:=⊥

txn𝑡 :=⊥
status𝑡 :=ABORT

TxRead𝜏 (𝑥, 𝑟 ) =

TxReadInt𝜏 (𝑥) ⊓

(cid:46)

𝑖 TxReadExt𝜏 (𝑥, 𝑖, 𝑟 )

TXBegin𝜏 (sflag, regSet) =
TxEnd𝜏 = TxEndRO𝜏 ⊓ TxEndWR𝜏

(cid:46)

𝑚 TXBeginV𝜏 (sflag, 𝑚, regSet)

where
𝑀 : seq(Loc → Val), initially 𝑀 = ⟨(𝜆𝑣 ∈ Loc.0)⟩
𝑉 : seq(Loc → TS), initially 𝑉 = ⟨(𝜆𝑣 ∈ Loc.0)⟩
OM𝜏 = {𝑛 | 𝑛 ≥ txview𝜏 ∧ 𝑛 ≤ |𝑀 | − 1}

𝑆 : seq{RX, R, A, RA}, initially 𝑆 = ⟨RX⟩
view(Idxs, Vf ) = 𝜆𝑙 ∈ Loc. maxWr{Vf 𝑖 (𝑙) | 𝑖 ∈ Idxs}

Fig. 4. TMS2-ra specification: highlighted components are extensions necessary for client synchronisation
for C11 transactions. We assume that the transactions are executed by thread 𝜏. Moreover, let 𝑄 · 𝑎 be the
sequence 𝑄 appended with element 𝑎 and 𝑓 ⊕ 𝑔 be the function 𝑓 overridden by function 𝑔. Finally, let maxWr
be a function that returns the write with the largest timestamp in the given set of writes.

Fig. 5a represents part of an execution of the program in Fig. 2a. In the execution depicted, we
assume that all of thread 𝜏1 executes before 𝜏2. Here, 𝜎2 is the state after executing line 4, where

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:11

𝑀

𝑑

𝜏2

{𝑓 ↦→ 0}RX

{𝑓 ↦→ 1}R

0, 0

𝜏1

5, 1

𝑀
{𝑓 ↦→ 0}RX

{𝑓 ↦→ 1}R

𝑑

𝜏2

0, 0

𝜏1

5, 1

𝜎2 (after executing
line 4)

𝜎3 (after executing
line 8)

𝜏2

𝜏1

𝑑1

(cid:27)RX

0, 0

𝑀
(cid:26)𝑓 ↦→ 0,
𝑑2 ↦→ 0
(cid:26)𝑓 ↦→ 1,
𝑑2 ↦→ 10
𝜎2 (after executing
line 5)

5, 1

(cid:27)RX

𝜏2

𝜏1

𝑑1

(cid:27)RX

0, 0

𝑀
(cid:26)𝑓 ↦→ 0,
𝑑2 ↦→ 0
(cid:26)𝑓 ↦→ 1,
𝑑2 ↦→ 10
𝜎3 (after executing
line 10)

5, 1

(cid:27)RX

(a) Views for transactional MP (Fig. 2a)

(b) Views for relaxed transactions (Fig. 2b)

𝑀
(cid:8)𝑓 ↦→ 0(cid:9)RX

(cid:8)𝑓 ↦→ 1(cid:9)R

𝑑1

𝑑2

0, 0

0, 0

5, 1

𝜏3

𝜏2

𝜏1

𝑀
(cid:8)𝑓 ↦→ 0(cid:9)RX

𝑑1

𝑑2

0, 0

0, 0

(cid:8)𝑓 ↦→ 1(cid:9)R

5, 1

10, 1

𝜏3

𝜏2

𝜏1

𝑀
(cid:8)𝑓 ↦→ 0(cid:9)RX

𝑑1

𝑑2

0, 0

0, 0

𝜏3

𝜏2

(cid:8)𝑓 ↦→ 1(cid:9)R

5, 1

10, 1

𝜏1

𝜎2 (after executing line 4)

(cid:8)𝑓 ↦→ 2(cid:9)RA
𝜎4 (after executing line 10)
(c) Views for release-acquire transaction chain (Fig. 2c)

(cid:8)𝑓 ↦→ 2(cid:9)RA
𝜎5 (after executing line 13)

Fig. 5. Views for the transaction-based client program from Fig. 2

𝜏1 has introduced a new write to 𝑑 and then executed its (releasing) transaction, introducing a
new memory snapshot whose modification view becomes the new write of 𝑑 (since 𝜏1’s thread
view is at this new write). Then, when 𝜏2 executes its (acquiring) transaction that reads 1 from 𝑓 , it
synchronises with the latest memory snapshot, causing 𝜏2’s thread view to be the new write of 𝑑 as
well. This is analogous, as required, to the way in which views are updated in C11 (see Fig. 3).

Fig. 5b represents a part execution of the program in Fig. 2b. Again, we assume a complete
execution of thread 𝜏1 followed by 𝜏2. State 𝜎2 is the state after executing line 5, where 𝜏1 has
introduced a new write to 𝑑1. Now consider the state 𝜎3 (the state after execution of line 10), where
𝜏1 introduces a new memory snapshot in 𝑀 with annotation RX and modification view pointing to
the new write on 𝑑1. When 𝜏2 continues execution, its transaction must be ordered after the latest
memory snapshot, but this will not induce a release-acquire synchronisation. This means that 𝜏2’s
view of 𝑑2 will not be updated. However, since 𝜏2’s transaction occurs after 𝜏1’s transaction, 𝜏2
is guaranteed to read 10 for 𝑑2. Note that the transaction executed by 𝜏2 is a read-only relaxed
transaction, the view of 𝜏2 of the client variable (𝑑1) is unchanged. However, 𝜏2’s view of the
transactional memory (not shown in the diagrams) will be updated to the new memory state
{𝑓 ↦→ 1, 𝑑2 ↦→ 10}.

Finally, Fig. 5c represents part of an execution of Fig. 2c comprising the complete execution of
𝜏1, 𝜏2 then 𝜏3 in order. State 𝜎2 represents the state after executing line 4, where the modification
view of the newly installed memory is consistent with the view of the executing thread 𝜏1. Then,
in 𝜎4 (the state after execution of line 10), we have a new write on 𝑑2 with value 10 and a further
new snapshot that synchronises with the snapshot {𝑓 ↦→ 1}R causing the thread view of 𝜏2 and
the modification view of the new snapshot to be updated to the last writes of 𝑑1 and 𝑑2. Next, in 𝜎5,
when 𝜏3 executes its transaction, this transaction is guaranteed to synchronise with {𝑓 ↦→ 2}RA,

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:12

Sadegh Dalvandi and Brijesh Dongol

TxBegin𝜏 (sflag, 𝑚, regSet)

𝛾 .status𝑡 = NOTSTARTED

𝑚 ∈ 𝑣𝑚𝑒𝑚𝑠𝜏
𝛾 .txn𝜏 = ⊥
beginIdx𝑡 := 𝑚, seenIdxs𝑡 := ∅, rdSet𝑡 := ∅,
wrSet𝑡 := ∅, synctype𝑡 := sflag, regs𝑡 := regSet,
status𝑡 = READY, txn𝜏 := 𝑡

lst, 𝛾, 𝛽

𝜏 lst, 𝛾








, 𝛽








TxWrite𝜏 (𝑙, 𝑣)

𝛾 .status𝑡 = READY
𝜏 lst, 𝛾 (cid:2)wrSet𝑡 := 𝛾 .wrSet𝑡 ∪ {𝑙 ↦→ 𝑣 }(cid:3) , 𝛽

𝛾 .txn𝜏 = 𝑡

lst, 𝛾, 𝛽

𝛾 .status𝑡 = READY

𝛾 .txn𝜏 = 𝑡

𝑟 ∈ 𝛾 .regs𝑡

(𝑙 ∈ dom(𝛾 .wrSet𝑡 ) ∨ (𝛾 .beginIdx𝑡 ≤ 𝑖 ∧ 𝛾 .rdSet𝑡 ⊆ 𝛾 .M𝑖 ))
𝑣 = if 𝑙 ∉ dom(𝛾 .wrSet𝑡 ) then 𝛾 .M𝑖 (𝑙) else 𝛾 .wrSet𝑡 (𝑙)

seenIdxs′ = if 𝑙 ∉ dom(𝛾 .wrSet𝑡 ) ∧ 𝛾 .𝑆𝑖 ∈ {R, RA}

then 𝛾 .seenIdxs𝑡 ∪ {𝑖} else 𝛾 .seenIdxs𝑡

TxRead𝜏 (𝑙, 𝑟 )

rdSet′ = if 𝑙 ∉ dom(𝛾 .wrSet𝑡 ) then 𝛾 .rdSet𝑡 ∪ {𝑙 ↦→ 𝑣 } else 𝛾 .rdSet𝑡
𝜏 lst [𝑟 := 𝑣], 𝛾 (cid:2)rdSet𝑡 := rdSet′, seenIdxs𝑡 := seenIdxs′(cid:3) , 𝛽

lst, 𝛾, 𝛽

𝛾 .status𝑡 = READY

𝛾 .txn𝜏 = 𝑡

𝛾 .wrSet𝑡 = ∅

tview′ = if 𝛾 .rdSet𝑡 ≠ ∅ ∧ 𝛾 .synctype𝑡 ∈ {A, RA} ∧ 𝛾 .seenIdxs𝑡 ≠ ∅

TxEndRO𝜏

then 𝛽.tview𝜏 ⊗ view(𝛾 .seenIdxs𝑡 , 𝛾 .𝑉 ) else 𝛽.tview𝜏

lst, 𝛾, 𝛽

𝜏 lst, 𝛾

(cid:20)status𝑡 := COMMITTED,
txview𝜏 := max(𝛾 .seenIdxs𝑡 )

(cid:21)

, 𝛽 [tview𝜏 := tview′]

𝛾 .status𝑡 = READY

𝛾 .txn𝜏 = 𝑡

𝛾 .wrSet𝑡 ≠ ∅

𝑖 = |𝛾 .M |

S′ = 𝛾 .synctype𝑡

𝑚𝑒𝑚′ = (last (𝛾 .M) ⊕ 𝛾 .wrSet𝜏 )

tview′ = if 𝛾 .rdSet𝑡 ≠ ∅ ∧ 𝛾 .synctype𝑡 ∈ {A, RA} ∧ 𝛾 .seenIdxs𝑡 ≠ ∅

TxEndWR𝜏

then 𝛽.tview𝜏 ⊗ view(𝛾 .seenIdxs𝑡 , 𝛾 .𝑉 ) else 𝛽.tview𝜏

lst, 𝛾, 𝛽

𝜏 lst, 𝛾

status𝑡 := COMMITTED, M𝑖 := 𝑚𝑒𝑚′
S𝑖 := S′, V𝑖 := tview′
txview𝜏 := max(𝛾 .seenIdxs𝑡 )















, 𝛽 [tview𝜏 := tview′]

TxAbort𝜏

𝛾 .status𝑡 = READY

𝛾 .txn𝜏 = 𝑡

lst ′ = 𝜆𝑟 ∈ Reg. if 𝑟 ∈ 𝛾 .regs𝑡 then ⊥ else lst (𝑟 )

lst, 𝛾, 𝛽

𝜏 lst ′, 𝛾 (cid:2)status𝑡 := ABORTED(cid:3) , 𝛽

Fig. 6. Operational semantics for TMS2-RA

causing 𝜏3’s view to be updated to the latest writes of 𝑑1 and 𝑑2, which is inherited from the
modification view of {𝑓 ↦→ 2}RA.

3.4 Modular operational semantics

To reason about clients that use abstract TMS2-ra transactions in a modular fashion, we use
configurations that are triples (lst, 𝛾, 𝛽), where lst : Reg → Val denotes the local register state, 𝛾 is
the TMS2-ra state (which includes all transactional variables described in Fig. 4) and 𝛽 is the C11
state of the client (see [Dalvandi et al. 2020a, 2022], §A).

The transition relation for transactional operations is given in Fig. 6. These follow the automata-
style description given in Fig. 4, but make state components that are affect more precise. The most

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:13

Init: glb := 0
TxBegin(regSet)
𝐵1 : regs := regSet
𝐵2 : hasRead := false ;
𝐵3 : do loc ←A glb;
𝐵4 : until 𝑒𝑣𝑒𝑛(loc)
TxWrite(𝑥, 𝑣)
𝑊1 : if 𝑒𝑣𝑒𝑛(loc) then
𝑊2 :
𝑊3 :
𝑊4 :
else loc := loc + 1;
𝑊5 :
𝑊6 : 𝑥 :=R 𝑣; // WRITE OK

𝑟1 ← CASRA (glb, loc, loc + 1)
if ¬𝑟1 then

∀𝑠 ∈ regs. 𝑠 := ⊥; return; // ABORT

TxEnd
𝐸1 : if 𝑜𝑑𝑑 (loc) then
glb :=R loc + 1;
𝐸2 :

if 𝑟 ∈ regs then

𝑟 ←A 𝑥;
if ¬hasRead ∧ 𝑒𝑣𝑒𝑛(loc) then
𝑟1 ← CASRA (glb, loc, loc)
if 𝑟1 then

TMRead(𝑥, 𝑟 )
𝑅1 :
𝑅2 :
𝑅3 :
𝑅4 :
𝑅5 :
𝑅6 :
𝑅7 :
𝑅8 :
𝑅9 :
𝑅10 :
return; // READ OK
𝑅11 :
𝑅12 : ∀𝑠 ∈ regs. 𝑠 := ⊥; // ABORT

hasRead := 𝑡𝑟𝑢𝑒;
return; // READ OK

𝑟1 ← glb;
if 𝑟1 = loc then

else

Fig. 7. TML-ra: A release-acquire transactional mutex lock. For simplicity, the thread id is omitted

interesting aspect of these rules is the interaction between a releasing writing transaction and
subsequent committing reading transaction.

Note that each releasing writing transaction sets 𝑆𝑖 (where 𝑖 is last index in 𝑀 at the time of
writing) to either R or RA. Additionally, the view of the thread at the time of writing is recorded
in 𝑉𝑖 . A later transaction with an acquiring annotation calculates a new view using the function
view as defined in Fig. 4 and updates, among other components, the executing thread’s view in 𝛽.
This means that, as expected, if there is a release-acquire synchronisation through a transactional
memory library, then the client’s view will be updated to match the synchronisation that occurs.

4 A C11 STM IMPLEMENTATION

In this section, we develop a release-acquire version of a transactional mutex lock, that we call
TML-ra, based on an SC implementation by Dalessandro et al [Dalessandro et al. 2010]. Our
algorithm is provided in Fig. 7, where the highlights indicate the fragments of code that we have
introduced or modified. The grey highlights represent code additional to Dalessandro et al’s original
implementation, and the blue highlights represent the necessary release-acquire synchronisation.
We first discuss the core features of TML (§4.1), then discuss the extensions introduced in TML-ra
to optimise for C11 release-acquire synchronisation (§4.2). We present the benchmarking results
for both algorithms in §4.3. In §6, we present a proof that TML-ra implements TMS2-ra, i.e., any
observation a client program makes when it uses TML-ra is a possible observation when it uses
TMS2-ra.

4.1 TML

TML is synchronised using a single global counter glb, initialised to 0, where glb is even iff no
writing transaction is currently executing.

A transaction begins by taking a snapshot of glb in local variable loc and only begins if the

value read is even.

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:14

Sadegh Dalvandi and Brijesh Dongol

A write operation checks that loc is even and if so, it attempts to increment glb using the
CAS at line 𝑊2. If this CAS succeeds, it increments loc (line 𝑊5), then immediately updates the
location 𝑥 (line 𝑊6). If the CAS fails, the transaction aborts. Note that if loc is odd then the current
transaction “owns” the lock, meaning that lines 𝑊2-𝑊5 can be bypassed.

A read operation (ignoring lines 𝑅3-𝑅7 for now) reads the given location into the given register
𝑟 (line 𝑅2). At lines 𝑅9 and 𝑅10 it checks that glb is consistent with loc. If so, the read succeeds,
otherwise, the transaction aborts.

A transaction ends by checking whether the current transaction is a writing transaction. This can
be determined by checking whether loc is odd since a writing transaction must have incremented
glb via the CAS at line 𝑊2 and loc via the write at line 𝑊5 making both their values odd. Therefore,
a writing transaction must increment glb to make it even again.

4.2 TML-ra

We now describe the necessary modifications to TML and the synchronisation induced by TMS2-ra.
We assume that transactions in TML-ra are all release-acquiring and hence we omit the transaction
annotation in TxBegin.

We assume all accesses to shared variables are either relaxed (e.g., the read at line 𝑅9), releasing
(e.g., the write at line 𝐸2), acquiring (e.g., the read at line 𝐵2) or release-acquiring (e.g., the CAS
at line 𝑅4). Additionally, we introduce a new local variable hasRead, initially set to false and a
code path 𝑅3-𝑅7, which is followed if a transaction performs a read without having previously
performed a read or a write. We explain the purpose of this code path in more detail below.

Transaction synchronisation. Recall that TMS2-ra requires that transactions are consistent w.r.t.
a single memory snapshot and that external reads of a transaction synchronise with some memory
snapshot. This may not occur in a relaxed memory context without adequate synchronisation. In
particular, a writing transaction must perform a releasing write to glb at line 𝐸2 so that if a later
transaction reads from this write, it synchronises with all of the writes performed by the writing
transaction. To ensure this, we require the read of glb at line 𝐵3 as well as the CAS operations at
lines 𝑊2 and 𝑅4 to be acquiring. Note that this also guarantees release-acquire client synchronisation.
The second key synchronisation is between 𝑊6 performed by a writing transaction 𝑡𝑤 and 𝑅2
performed by a (different) reading transaction 𝑡𝑟 . Suppose that both 𝑡𝑤 and 𝑡𝑟 are live. If 𝑡𝑟 happens
to read the write written at 𝑊6, it must now abort because 𝑡𝑟 ’s snapshot of glb will be inconsistent
with the latest value of glb installed by the 𝑡𝑤. The release-acquire synchronisation between 𝑊6
and 𝑅1 ensures that this will happen, i.e., 𝑡𝑟 will see the new glb written by 𝑡𝑤, causing the test at
𝑅10 to fail and 𝑡𝑟 to abort.

Causal linearizability. The design of TML-ra ensures that all transactions, including read-only
transactions are causally linearizable [Doherty et al. 2018], which is a condition that additionally
guarantees compositionality (or locality [Herlihy and Wing 1990; Sela et al. 2021]) of concurrent
objects. This notion of compositionality is that of Herlihy and Wing [Herlihy and Wing 1990].
In particular, under SC memory, given a history comprising several concurrent objects, if the
history restricted to each object is linearizable, then the history as a whole is linearizable. In a
relaxed memory setting, Doherty et al [Doherty et al. 2018] have shown that linearizability alone is
insufficient to guarantee compositionality, and it is necessary to induce a “happens-before” relation
when a specification induces a particular linearization.

The happens-before required by causal linearizability is naturally achieved for writing transac-
tions via the CAS at line 𝑊2. For a read-only transaction, we introduce the CAS at line 𝑅4, which
installs a new write to glb without changing its value. All transactions that follow the CAS at line
𝑅4 will be causally ordered after the reading transaction. Such a CAS must only be performed once,

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:15

Fig. 8. Results of STAMP benchmarks for TML-ra and TML-sc

thus we introduce a local variable hasRead, which is set to true if the CAS succeeds so that later
reads from the same transaction can avoid the code path from 𝑅3-𝑅7.

Note that the conditions necessary to guarantee causal linearizability (and hence composition-
ality) could have been introduced at the level of TMS2-ra. However, there are questions about
whether the notion of compositionality introduced by Herlihy and Wing [Herlihy and Wing 1990]
are appropriate in a relaxed memory context [Raad et al. 2019a]. Therefore we leave out the causal
linearizability conditions in TMS2-ra to avoid over-constraining the specification.

4.3 Benchmarking

We implemented two versions of the TML algorithm: TML-ra (see Fig. 7) and TML-sc (the SC
counterpart [Dalessandro et al. 2010]) and benchmarked both using the STAMP benchmarking
suite [Minh et al. 2008]. Each experiment was repeated 20 times to rule out external loads on the
test machine and an average of these times was taken. The results of the six benchmarks that we
ran with STAMP are presented in Fig. 8. TML-ra is equivalent to or outperforms TML-sc in almost
all cases, with a maximum improvement of 20%. On average, TML-ra performs 8.2% better than
TML-sc.

Unsurprisingly, since TML optimises read-heavy workloads, its performance degrades under
high write contention, and this is consistent with prior results [Dalessandro et al. 2010]. However,
it is interesting that the degradation of TML-ra is not as severe as TML-sc for the Intruder and
SSCA2 benchmarks.

TML-ra theoretically allows more parallelism than TML-sc since a read-only transaction 𝑡𝑟
is not forced to abort if a writing transaction 𝑡𝑤 executes after 𝑡𝑟 ’s first read operation - 𝑡𝑟 must
only aborts if it sees 𝑡𝑤’s 𝑔𝑙𝑏 update, or one of 𝑡𝑤’s writes. Both Intruder and SSCA2 have a large
number of short transactions; SSCA2 additionally has small read/write sets [Minh et al. 2008]. Here,
TML-ra may be able to exploit the theoretical parallelism. In the single-threaded case, TML-ra
executes far fewer heavyweight CASs.

As with prior results, we see that for the read-heavy benchmark Genome, the performance of

both TML-ra and TML-sc improves as the number of threads increases.

5 TARO: A LOGIC FOR RELEASE-ACQUIRE TM

The development of view-based operational semantics for various fragments of C11 [Dalvandi et al.
2020a; Kaiser et al. 2017; Kang et al. 2017] has provided foundations for several logics for reasoning
about C11 programs. These include separation logics [Kaiser et al. 2017; Svendsen et al. 2018]

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:16

Sadegh Dalvandi and Brijesh Dongol

(cid:8)[𝑑 = 0]𝜏1 ∧ [𝑑 = 0]𝜏2 ∧ [𝑓 = 0]𝜏1 ∧ [𝑓 = 0]𝜏2

(cid:9)

Thread 𝜏1
(cid:8)¬[ ˆ𝑓 ≈ 1]𝜏2 ∧ [𝑑 = 0]𝜏1
1 : 𝑑 := 5;
(cid:8)¬[ ˆ𝑓 ≈ 1]𝜏2 ∧ [𝑑 = 5]𝜏1
2 : TxBegin(R, ∅)
(cid:26)¬[ ˆ𝑓 ≈ 1]𝜏2 ∧ [𝑑 = 5]𝜏1
∧ Rel𝜏1

(cid:9)

(cid:9)

(cid:27)

3 : TxWrite(𝑓 , 1) ;
(cid:26)¬[ ˆ𝑓 ≈ 1]𝜏2 ∧ [𝑑 = 5]𝜏1
∧ Rel𝜏1 ∧ ( ˆ𝑓 , 1) ∈ WS𝜏1

(cid:27)

4 : TxEnd;
(cid:8)true(cid:9)

Thread 𝜏2
5 : do
(cid:8)⟨ ˆ𝑓 = 1⟩[𝑑 = 5]𝜏2
(cid:9)
6 : TxBegin(A, {r1})
(cid:8)⟨ ˆ𝑓 = 1⟩[𝑑 = 5]𝜏2 ∧ WS𝜏2 = ∅ ∧ Acq𝜏2
7 : TxRead(𝑓 , 𝑟1) ;
(cid:40)
⟨ ˆ𝑓 = 1⟩[𝑑 = 5]𝜏2 ∧ WS𝜏2 = ∅ ∧ Acq𝜏2
∧ ( ˆ𝑓 , 𝑟1) ∈ RS𝜏2 ∧ (𝑟1 = 1 ⇒ [𝑑 𝑆

(cid:9)

= 5]𝜏2)

(cid:41)

8 : TxEnd ;
(cid:8)⟨ ˆ𝑓 = 1⟩[𝑑 = 5]𝜏2 ∧ (𝑟1 = 1 ⇒ [𝑑 = 5]𝜏2)(cid:9)
9 : until 𝑟1 = 1
(cid:8)[𝑑 = 5]𝜏2
10 : 𝑟2 ← 𝑑
(cid:8)𝑟2 = 5(cid:9)

(cid:9)

{𝑟2 = 5}

Fig. 9. Proof outline for transactional MP from Fig. 2a

and extensions to Owicki-Gries reasoning [Dalvandi et al. 2020a, 2022; Lahav and Vafeiadis 2015;
Wright et al. 2021]. Our point of departure is the Owicki-Gries encoding for RC11 RAR [Dalvandi
et al. 2020a], which is the fragment of C11 that we focus on in this paper.5

A key benefit of the logic in [Dalvandi et al. 2020a] is that it enables reuse of standard Owicki-
Gries proof decomposition rules and straightforward mechanisation in Isabelle/HOL [Dalvandi
et al. 2020b, 2022]. As we shall see, we maintain these benefits in the context of C11 with release-
acquire transactions. Our reasoning framework, called TARO, like Dalvandi et al [Dalvandi et al.
2020a; Dalvandi and Dongol 2021] uses view-based assertions to abstractly describe the system
state, allowing reasoning about the current view of a thread, and view transfer from one thread to
another through release-acquire synchronisation. TARO introduces additional assertions to enable
reasoning about transactional views.

5.1 View-based assertions

In this section, we discuss the assertions and proof rules of TARO abstractly. The proof rules can be
used to reason syntactically about a program without having to understand the low-level operational
semantics of the C11 model. Our operational semantics is an extension of prior works [Dalvandi
et al. 2020a; Kaiser et al. 2017; Kang et al. 2017] that include an encoding of TMS2-ra.

To motivate TARO, consider the proof outline in Fig. 9 for the transactional message passing
program from Fig. 2a. We use ‘ˆ’ to distinguish transactional locations in a proof. For the program
in Fig. 9, we have a transactional location ˆ𝑓 .

5.1.1 View assertions. The proof outline contains three assertions from [Dalvandi et al. 2020a]
describing the views that each thread may have of the system state. Recall (§3.1), that we can define
the set of values that a thread can see in each state using the function 𝑂𝑉 .

• A definite value assertion, denoted [𝑥 = 𝑣]𝜏 , holds iff thread 𝜏 sees the last write to location 𝑥

and this write has value 𝑣. Thus, [𝑥 = 𝑣]𝜏 ⇒ 𝑂𝑉𝜏 (𝑥) = {𝑣 }.

5These frameworks are based on models that assume top-level parallelism only. Therefore, our framework similarly
re assumes top-level paralellism. This model can be extended to support dynamic parallelism, but such extensions are
uninteresting for the purposes of this paper.

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:17

• A possible value assertion, denoted [𝑥 ≈ 𝑣]𝜏 , which holds iff when 𝜏 can see a write to 𝑥 with

value 𝑣. [𝑥 ≈ 𝑣]𝜏 is shorthand for 𝑣 ∈ 𝑂𝑉𝜏 (𝑥).

• A conditional value assertion, denoted ⟨𝑦 = 𝑢⟩[𝑥 = 𝑣]𝜏 , which holds iff an acquiring read of 𝑦
by 𝜏 that returns the value 𝑢 is guaranteed to induce a release-acquire synchronisation so
that [𝑥 = 𝑣]𝜏 holds after this read.

Example 2. Consider the third state, i.e., 𝜎2 in Fig. 3. There, we have [𝑑 = 5]𝜏1 ∧ [𝑓 = 1]𝜏1 as well
as [𝑓 ≈ 0]𝜏2 ∧ [𝑓 ≈ 1]𝜏2. Moreover, we have ⟨𝑓 = 1⟩[𝑑 = 5]𝜏2.

We ask the interested reader to consult [Dalvandi et al. 2020a, 2022] for further details of these

assertions.

5.1.2 Transactional assertions. As alluded to above, TARO introduces several new assertions to
describe the transactional state. These assertions are, in general, local to the transaction being
executed, and hence, stable under the execution of other threads. Fig. 9 contains the following
transaction local assertions:

• Rel𝜏 , which holds iff 𝜏 is executing a releasing or release-acquiring transaction.
• Acq𝜏 , which holds iff 𝜏 is executing an acquiring or release-acquiring transaction.
• ( ˆ𝑥, 𝑣) ∈ WS𝜏 (and ( ˆ𝑥, 𝑣) ∈ RS𝜏 ), which holds iff 𝜏 is executing a transaction whose write set

(resp. read set) contains a write to (resp. read of) ˆ𝑥 with value 𝑣.

• [𝑥 𝑆

= 𝑣]𝜏 , which holds iff 𝜏 is executing a transaction such that committing this transaction

results in the definite value assertion [𝑥 = 𝑣]𝜏 (see above).

In addition, we include a number of assertions This section provides the formal definition for
the assertion language used in the verification of client programs that use TMS2-RA (See §5.1).
The assertion language presented here is heavily inspired by the view-based assertion language
presented in [Dalvandi et al. 2020a].

A memory 𝑖 is visible to a transaction executed by a thread 𝜏 iff 𝑖 is greater than the transaction
thread view of 𝜏 (txview𝜏 ) and is less than the maximum index of the memory (|𝑀 | − 1). We define
the set of visible memories OM𝑡 to be:

OM𝜏 = {𝑛 | 𝑛 ≥ txview𝜏 ∧ 𝑛 ≤ |𝑀 | − 1}

• A transactional definite observation assertion, denoted [ ˆ𝑥 = 𝑣]𝑡 , holds iff for all memory
versions 𝑖, where 𝑖 is greater than or equal to beginIdx𝑡 , the value of M𝑖 (𝑥) is 𝑣. Formally,
for a transactional state 𝛾:

[ ˆ𝑥 = 𝑣]𝜏 (𝛾)

ˆ= ∀𝑖 ∈ 𝛾 .OM𝜏 . 𝛾 .M𝑖 ( ˆ𝑥) = 𝑣

These are lifted to client-object states (𝛾, 𝛽) in the normal manner, e.g., [ ˆ𝑥 = 𝑣]𝜏 (𝛾, 𝛽) = [ ˆ𝑥 =
𝑣]𝜏 (𝛾)

• A transactional possible observation assertion, denoted [ ˆ𝑥 ≈ 𝑣]𝜏 , holds iff there exists a

memory version 𝑖 that has value 𝑣 for ˆ𝑥. Formally:

[ ˆ𝑥 ≈ 𝑣]𝜏 (𝛾)

ˆ= ∃𝑖 ∈ 𝛾 .OM𝜏 . 𝛾 .M𝑖 ( ˆ𝑥) = 𝑣

• A transactional conditional observation assertion, denoted ⟨ ˆ𝑦 = 𝑢⟩[𝑥 = 𝑣]𝜏 , holds iff an
acquiring transactional read of 𝑦 by 𝜏 that returns a value 𝑢 is guaranteed to induce a release-
acquire synchronisation so that [𝑥 𝑆
= 𝑣]𝜏 holds in the client state after the reading transaction
successfully commits. Formally:

⟨ ˆ𝑦 = 𝑢⟩[𝑥 = 𝑣]𝜏 (𝛾, 𝛽)

ˆ= ∀𝑖 ∈ 𝛾 .OM𝜏 . 𝛾 .M𝑖 ( ˆ𝑦) = 𝑢 ⇒

𝛾 .V𝑖 (𝑥) = 𝛽.𝑙𝑎𝑠𝑡 (𝑥) ∧ val(𝛽.last (𝑥)) = 𝑣 ∧ 𝛾 .S𝑖

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:18

Sadegh Dalvandi and Brijesh Dongol

where 𝑙𝑎𝑠𝑡 (𝑥) is the last write to 𝑥 in the modification order. It is important to note that this
assertion is over two states: transaction state 𝛾 and client state 𝛽, explaining transfer of infor-
mation across two threads using the transactional memory. In particular, the transactional
view 𝑉𝑖 for the memory index 𝑖 must see the last write to 𝑥 in the client state 𝛽. This means
that the thread that committed the transaction writing the value 𝑢 to ˆ𝑦 did so when it saw
the last write to 𝑥.

Example 3. Returning to our transactional MP example (Fig. 9), the precondition of line 1 contains
assertions ¬[ ˆ𝑓 ≈ 1]𝜏2 and [𝑑 = 0]𝜏1, which ensure that, prior to executing line 1, thread 𝜏2 cannot
see the value 1 for ˆ𝑓 and thread 𝜏1 must see the value 0 for 𝑑, respectively. In the postcondition
of line 2, [𝑑 = 0]𝜏1 changes to [𝑑 = 5]𝜏1 since 𝜏1 performs a write to 𝑑 with value 5. The other
view-based assertions in 𝜏1 are similar. We explain the transactional assertions involving Rel and
WS below.

Now consider the assertions in thread 𝜏2. The precondition of line 6 (which is also the precondition
of line 5) contains a conditional value assertion ⟨ ˆ𝑓 = 1⟩[𝑑 = 5]𝜏2. This assertion ensures that, if
𝜏2 reads the value 1 for ˆ𝑓 via an acquiring (or release-acquiring) transaction, and this transaction
successfuly commits, then its view is guaranteed to be updated so that [𝑑 = 5]𝜏2 holds. In a
transactional setting, we establish this fact in three steps.

(1) After executing line 7, we use ⟨ ˆ𝑓 = 1⟩[𝑑 = 5]𝜏2 to establish that 𝑟1 = 1 ⇒ [𝑑 𝑆

= 5]𝜏2 holds.
Note that 𝑟2 stores the value 1 returned by a transactional read of ˆ𝑓 . Thus, ⟨ ˆ𝑓 = 1⟩[𝑑 = 5]𝜏2 is
transformed into an implication after the execution of line 7. The assertion [𝑑 𝑆
= 5]𝜏2 is a new
assertion introduced in TARO, which states that if the transaction executed by 𝜏2 commits,
then [𝑑 = 5]𝜏2 holds in the post-state.

(2) If the transaction sucessfully commits (line 8), we use 𝑟1 = 1 ⇒ [𝑑 𝑆

= 5]𝜏2 to establish
𝑟1 = 1 ⇒ [𝑑 = 5]𝜏2 in the postcondition. Recall that all registers used by a transaction are set
to ⊥ when a transaction aborts, so if 𝜏2 reaches line 9 by aborting the transaction, then this
assertion is trivially true.

(3) We use 𝑟1 = 1 ⇒ [𝑑 = 5]𝜏2 to establish [𝑑 = 5]𝜏2 after the do-until loop, using the guard

𝑟1 = 1 at line 9.

Finally, we use [𝑑 = 5]𝜏2 in the precondition of line 10 to establish the postcondition 𝑟2 = 5. This is
because [𝑑 = 5]𝜏2 guarantees that the only value 𝜏2 can read for 𝑑 is 5.

5.2 TARO: Transactional Owicki-Gries Reasoning

Now that we have introduced the assertions used by TARO, we now review the Owicki-Gries proof
obligations. As discussed above, the use of view-based assertions allows us to use the standard
Owicki-Gries theory. Regardless, we review the theory in the context of our language, which
supports (abstract) TM operations. Formally, we model programs as a labelled transition system,
given by the syntax in Fig. 10.

A command (of type ACom) is either a local assignment 𝑟 := Exp, a store to a shared location
𝑥 :=[R] Exp, a load from a shared location 𝑟 ←[A] 𝑥, a compare-and-swap 𝑟 ← CAS[RX] [R] [A] (𝑥, 𝑢, 𝑣),
or a transactional operation. The annotations RX, R and A are optional, as indicated by the brackets
‘[’ and ‘]’. Thus, for example, both 𝑥 := 𝑒 and 𝑥 :=R 𝑒 are valid load commands; the former is relaxed
and the latter is releasing. A CAS may be annotated to be relaxed, or release and/or acquire. Note
that a CAS returns a boolean to indicate whether or not the compare-and-swap has been success-
ful. TxBegin([RX] [R] [A]), TxRead(𝑥, 𝑟 ), TxWrite(𝑥, 𝑣) and TxEnd are transactional operations, as
defined by the TMS2-ra automata in Fig. 4.

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:19

𝑢, 𝑣 ∈ Val ˆ= N

𝑥, 𝑦, . . . ∈ Loc

𝑟, 𝑟1, 𝑟2 . . . ∈ Reg

𝜏, 𝜏1, 𝜏2, . . . ∈ TId ˆ= N

𝑖, 𝑗, 𝑘, . . . ∈ Label

𝑒 ∈ Exp ::= 𝑣 | 𝑟 | 𝑒+𝑒 | · · ·
𝐵 ∈ BExp ::= true | 𝐵 ∧ 𝐵 | · · ·
𝛼 ∈ ACom ::= 𝑟 := Exp | 𝑥 :=[R] Exp | 𝑟 ←[A] 𝑥 | 𝑟 ← CAS[RX] [R] [A] (𝑥, 𝑢, 𝑣) |

TxBegin([RX] [R] [A], 2Reg) | TxRead(𝑥, 𝑟 ) | TxWrite(𝑥, 𝑣) | TxEnd

𝑙𝑠 ∈ LCom ::= 𝛼 goto 𝑗 | if 𝐵 goto 𝑗 elseto 𝑘

Π ∈ Prog ˆ= TId × Label → LCom

Fig. 10. Language syntax

We use a program counter variable 𝑝𝑐 : TId → 𝐿𝑎𝑏𝑒𝑙 to model control flow, and model a program
Π as a function mapping each pair (𝜏, 𝑖) of thread identifier and label to the labelled statement
(in LCom) to be executed. A labelled statement may be (i) a plain statement of the form 𝛼 goto 𝑗,
comprising an atomic statement 𝛼 to be executed and the label 𝑗 of the next statement; or (ii) a
conditional statement of the form if 𝐵 goto 𝑗 elseto 𝑘 to accommodate branching, which proceeds
to label 𝑗 if 𝐵 holds and to 𝑘, otherwise. We assume a designated label, 𝜄 ∈ Label, representing the
initial label; i.e., each thread begins execution with pc(𝜏) = 𝜄. Similarly, 𝜁 ∈ Label represents the
final label.

We let Assertion be the set of assertions that use view-based expressions. We model program
annotations via an annotation function, ann ∈ Ann = TId × Label → Assertion, associating each
program point (𝜏, 𝑖) with its associated assertion. A proof outline is a tuple (in, ann, fin), where
in, fin ∈ Assertion are the initial and final assertions.

Definition 1 (Validity). A proof outline (in, ann, fin) is valid for a program Π iff each of the
following holds:

Initialisation For all 𝜏 ∈ TId, in ⇒ ann(𝜏, 𝜄).
Finalisation (∀𝜏 ∈ TId. ann(𝜏, 𝜁 )) ⇒ fin
Local correctness For all 𝜏 ∈ TId and 𝑖 ∈ Label, either:

• Π(𝜏, 𝑖) = 𝛼 goto 𝑗 and (cid:8)ann(𝜏, 𝑖)(cid:9) 𝛼 (cid:8)ann(𝜏, 𝑗)(cid:9); or
• Π(𝜏, 𝑖) = if 𝐵 goto 𝑗 elseto 𝑘 and both ann(𝜏, 𝑖) ∧ 𝐵 ⇒ ann(𝜏, 𝑗) and ann(𝜏, 𝑖) ∧ ¬𝐵 ⇒

ann(𝜏, 𝑘) hold.

Stability For all 𝜏1, 𝜏2 ∈ TId such that 𝜏1 ≠ 𝜏2 and 𝑖1, 𝑖2 ∈ Label if Π(𝜏1, 𝑖1) = 𝛼 goto 𝑗, then

(cid:8)ann(𝜏2, 𝑖2) ∧ ann(𝜏1, 𝑖1)(cid:9) 𝛼 (cid:8)ann(𝜏2, 𝑖2)(cid:9)

Intuitively, Initialisation (resp. Finalisation) ensures that the initial (resp. final) assertion of each
thread holds at the beginning (resp. end); Local correctness establishes validity for each thread;
and Stability ensures that each (local) thread annotation is interference-free under the execution of
other threads [Owicki and Gries 1976].

To support Owicki-Gries reasoning, we have proved a number of high-level rules, extending
those of Dalvandi et al. [Dalvandi et al. 2020a; Dalvandi and Dongol 2021] to cope with transactional
assertions from §5.1 and the transactional commands. For instance, the following rules are used in
the proof of transactional message passing. A number of other rules are provided as part of our
Isabelle/HOL development.

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:20

Sadegh Dalvandi and Brijesh Dongol

Lemma 1. Suppose 𝜏1 ≠ 𝜏2. Then each of the following holds:

(cid:8)true(cid:9) TxWrite𝜏 (𝑥, 𝑣) (cid:8)( ˆ𝑥, 𝑣) ∈ WS𝜏 (cid:9)
(cid:8)(𝑥, 𝑢) ∈ WS𝜏1 ∧ Rel𝜏1 ∧ [ ˆ𝑥 (cid:48) 𝑢]𝜏2 ∧ [𝑦 = 𝑣]𝜏1
(cid:9) TxEnd𝜏2
(cid:110)
(cid:8)(𝑥, _) ∉ WS𝜏 ∧ 𝐴𝑐𝑞𝜏 ∧ ⟨ ˆ𝑥 = 𝑢⟩[𝑦 = 𝑣]𝜏 (cid:9) TxRead𝜏 (𝑥, 𝑟 )
(cid:110)

(cid:111)

( ˆ𝑥, 𝑟 ) ∈ RS𝜏 ∧ (𝑟 = 𝑢 ⇒ [𝑦 𝑆

= 𝑣]𝜏 )

TxEnd𝜏 (cid:8)𝑟 = 𝑢 ⇒ [𝑦 = 𝑚]𝜏 (cid:9)

(cid:9)

(cid:8)⟨ ˆ𝑥 = 𝑢⟩[𝑦 = 𝑣]𝜏2
( ˆ𝑥, 𝑟 ) ∈ RS𝜏 ∧ (𝑟 = 𝑢 ⇒ [𝑦 𝑆

= 𝑣]𝜏 )

(cid:111)

The rules in Lemma 1 have been verified in Isabelle/HOL w.r.t. the operational semantics. Once
proved, they can be used to show validity of proof outlines such as those in Fig. 9 without having
to consult the operational semantics.

Theorem 1. The proof outline in Fig. 9 is valid.

This theorem has been verified in Isabelle/HOL, and it makes extensive use of generic proof rules
such as the ones proved in Lemma 1. In particular, given such lemmas, like in previous works [Bila
et al. 2022; Dalvandi et al. 2020a; Dalvandi and Dongol 2021; Dalvandi et al. 2022], Isabelle/HOL is
automatically able to find and apply the appropriate proof rule using the built-in sledgehammer
tool [Böhme and Nipkow 2010]. This automation has been key to scaling mechanised verification of
proof outlines in view-based logics. For example, the proofs of TML-RA (see §6) requires verification
of complex invariants and proof outlines, and these proofs make use of the proof rules developed
in prior work [Dalvandi et al. 2020a]. Similarly, TARO can be applied to verify more complex
porgrams that use transactions, for instance if one were to develop transactional data structures.
Interestingly, because transactions provide isolation guarantees, many of the proofs are simplified
since the stability checks for in-flight transactions become trivial.

The proof outlines for the programs in Figs. 2b and 2c are provided in Appendix E.

6 PROVING CORRECTNESS OF TML-RA

We now turn to the question of correctness of TML-ra with respect to the TMS2-ra specification.

6.1 Refinement and Simulation for Weak Memory

Since we have an operational semantics with an interleaving semantics over weak memory
states, the development of our refinement theory closely follows the standard approach under
SC [de Roever and Engelhardt 1998]. Suppose 𝑃 is a program with initialisation Init. An execution
of 𝑃 is defined by a possibly infinite sequence Δ0 Δ1 Δ2 . . . such that
(1) each Δ𝑖 is a 4-tuple (𝑃𝑖, ls𝑖, 𝛾𝑖, 𝛽𝑖 ) comprising a program to be executed, local state, global library

state and global client state, and

(2) (𝑃0, ls0, 𝛾0, 𝛽0) = (𝑃, lsInit, 𝛾Init, 𝛽Init), and
(3) for each 𝑖, we have Δ𝑖 =⇒ Δ𝑖+1, where =⇒ is the transition relation of the program (as defined

by the operational semantics).

Let LVar𝑃 be the set of local variables corresponding to a program 𝑃. If 𝑃 is a client, a client trace
corresponding to an execution Δ0 Δ1 Δ2 . . . is a sequence ct ∈ Σ∗
𝑃 such that ct𝑖 = (𝜋2(Δ𝑖 ) |𝑃, 𝜋4(Δ𝑖 )),
where 𝜋𝑛 is a projection function that extracts the 𝑛th component of a given tuple and ls |𝑃 restricts
the given local state ls to the variables in LVar𝑃 . Thus, each ct𝑖 is the global client state compo-
nent of Δ𝑖 . After such a projection, the concrete implementation may contain (finite or infinite)
stuttering [de Roever and Engelhardt 1998], i.e., consecutive states in which the client state is
unchanged. We let rem_stut (ct) be the function that removes all stuttering from the trace ct, i.e.,
each consecutively repeating state is replaced by a single instance of that state. We let TrSF (𝑃)

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:21

denote the set of stutter-free traces of a program 𝑃, i.e., the stutter-free traces generated from the
set of all executions of 𝑃.

Below we refer to the client that uses the abstract object as the abstract client and the client that
uses the object’s implementation as the concrete client. The notion of contextual refinement that
we develop ensures that a client is not able to distinguish the use of a concrete implementation in
place of an abstract specification. In other words, each thread of the concrete client should only be
able to observe the writes (and updates) in the client state (i.e., 𝛾 component) that the thread could
already observe in a corresponding of the client state of the abstract client. First we define trace
refinement for weak memory states.
Definition 2 (State and Trace Refinement). We say a concrete client state (ls, 𝛽𝐶 ) is a refinement
of an abstract client state (als, 𝛽𝐴), denoted (ls, 𝛽𝐶 ) ≤ (als, 𝛽𝐴) iff ls = als and for all threads 𝜏 and
𝑥 ∈ GVar, we have 𝛽𝐶 .OW 𝜏 (𝑥) ⊆ 𝛽𝐴.OW 𝜏 (𝑥). We say a concrete client trace ct is a refinement of
an abstract client trace at, denoted ct ≤ at, iff ct𝑖 ≤ at𝑖 for all 𝑖.

This now leads to a natural trace-based definition of contextual refinement.

Definition 3 (Program Refinement). A concrete program 𝑃𝐶 is a refinement of an abstract program
𝑃𝐴, denoted 𝑃𝐶 ≤ 𝑃𝐴, iff for any (stutter-free) client trace ct ∈ TrSF (𝑃𝐶 ) there exists a (stutter-free)
client trace at ∈ TrSF (𝑃𝐴) such that ct ≤ at.

Finally, we obtain a notion of contextual refinement for abstract objects. We let 𝑃 [𝑂] be the client
program calling operations from object 𝑂. Note that 𝑂 may be an abstract object, in which case
execution of each method call follows the abstract object semantics, or a concrete implementation.
Definition 4 (Contextual refinement). We say a concrete object 𝐶𝑂 is a contextual refinement of
an abstract object 𝐴𝑂 iff for any client program 𝑃, we have 𝑃 [𝐶𝑂] ≤ 𝑃 [𝐴𝑂].

Here, we use a simulation-based proof method, which is a standard technique from the literature
that establishes refinement between TMS2-ra and TML-ra. The difference in a relaxed memory
setting is that the refinement relation is between more complex configurations of the form (ls, 𝛾, 𝛽),
where ls describes the local state, 𝛾 is the client state and 𝛽 is a state of the TM in question. In
particular, a simulation relation, 𝑅, relates triples Γ𝐴 ˆ= (als, 𝛾𝐴, 𝛽𝐴) of the abstract system with
triples Γ𝐶 ˆ= (ls, 𝛾𝐶, 𝛽𝐶 ) of the concrete system.

The definition below assumes a reflexive relation 𝛾𝐶 −tview𝜏−−−−−→ 𝛾 ′

𝐶 for each thread 𝜏 that arbitrarily

advances the thread view of 𝜏 (for one or more locations).
Definition 5 (Forward simulation). For an abstract object 𝐴𝑂 and a concrete object 𝐶𝑂, for a client
program 𝑃, we say 𝑅(Γ𝐴, Γ𝐶 ) ˆ= 𝑅𝑉 ((als, 𝛽𝐴), (ls, 𝛽𝐶 )) ∧ 𝑅𝑂 ((als |𝐴𝑂, 𝛾𝐴), (ls |𝐶𝑂, 𝛾𝐶 )) is a forward
simulation between 𝐴 and 𝐶 iff each of the following holds:
Client observation.

𝑅𝑉 ((als, 𝛽𝐴), (ls, 𝛽𝐶 )) = als |𝑃 = ls |𝑃 ∧ (∀𝜏 ∈ TId, 𝑥 ∈ Loc. 𝛽𝐴.tview(𝑡, 𝑥) ≤ 𝛽𝐶 .tview(𝑡, 𝑥))

Thread view stability. For any thread 𝜏,

𝑅𝑂 ((als |𝐴𝑂, 𝛾𝐴), (ls |𝐶𝑂, 𝛾𝐶 )) ∧ (𝛾𝐶 −tview𝜏−−−−−→ 𝛾 ′

𝐶 ) ⇒ 𝑅𝑂 ((als |𝐴𝑂, 𝛾𝐴), (ls |𝐶𝑂, 𝛾 ′

𝐶 ))

Initialisation. For any concrete initial state Γ0

𝐶 , there exists an abstract initial state Γ0

𝐴 such that

𝑅(Γ0

𝐴, Γ0
𝐶 ).

Preservation. For any concrete states Γ𝐶 , Γ′

𝐶 such that 𝐶 can take an atomic transition from Γ𝐶 to

Γ′
𝐶 , if Γ𝐴 is an abstract state such that 𝑅(Γ𝐴, Γ𝐶 ), then either
• 𝑅(Γ𝐴, Γ′
• there exists a transition of 𝐴 from Γ𝐴 to some state Γ′

𝐶 ), or

𝐴 such that 𝑅(Γ′

𝐴, Γ′

(stuttering step)
𝐶 ). (non-stuttering

step)

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:22

Sadegh Dalvandi and Brijesh Dongol

Initialisation and preservation are standard components of a forward simulation. Client observation
is necessary in a relaxed memory context to ensure that the client-side observations of the concrete
system are possible observations of the abstract system. In particular, if an abstract object specifies
a particular client-side synchronisation, then this synchronisation must also be present in the
concrete implementation (see [Dalvandi and Dongol 2021]). Thread view stability guarantees that
the 𝑅𝑂 component of the refinement relation is preserved when the thread view in the library is
shifted forward, e.g., due to synchronisation within a client.

Note that Definition 5 only guarantees preservation of safety. To additionally preserve liveness,
further progress guarantees are required in an implementation [Dongol and Groves 2016; Gotsman
and Yang 2011]. We leave liveness preservation through refinement for future work since notions
of fairness and progress of weak memory models is still at the early stages [Lahav et al. 2021].

Theorem 2. If 𝑅 is a forward simulation between 𝐴𝑂 and 𝐶𝑂, then for any client 𝑃 we have

𝑃 [𝐶𝑂] ≤ 𝑃 [𝐴𝑂].

6.2 Forward Simulation for TML-ra

Perhaps the most technically challenging aspect of this paper is the proof of Theorem 3 below,
which ensures the correctness of TML-ra w.r.t. TMS2-ra.

This section describes the simulation relation used to prove refinement between TML-ra and
TMS2-RA. Validity of the forward simulation itself has been verified using Isabelle/HOL. The
refinement relation

𝑅((als, 𝛾𝐴, 𝛽𝐴), (𝑙𝑠, 𝛾𝐶, 𝛽𝐶 ))

ˆ= 𝑅𝑉 ((als, 𝛽𝐴), (ls, 𝛽𝐶 )) ∧ (1) ∧

(∀𝑡 . (2) ∧ (3) ∧ (4) ∧ (5) ∧ (6) ∧ (7) ∧ (8) ∧ (9))

The first conjunct (1) in the refinement relation 𝑅 states that the value of the last write to glb divided
by 2 (wc(𝑛) ˆ= 𝑛 ÷ 2) is equal to the last version of history written to M.

wc(𝛾𝐶 .lastval(𝑔𝑙𝑏)) = |𝛾𝐴.M |
(1)
The next conjunct, (2), states that the last value written to any location 𝑙 in 𝛾𝐶 is either the value of
𝑙 in the last abstract memory index or in the write set of the executing transaction

∀𝑙 . 𝑙 ≠ glb ⇒ 𝛾𝐶 .lastval(𝑙) ∈ {𝛾𝐴.M|𝛾𝐴.M | (𝑙), 𝛾𝐴.wrSet𝑡 (𝑙)}

(2)

where lastval(𝑥) is a function that returns the value of the last write written to a location 𝑥.

The next conjunct (3) is an on-the-fly simulation relation (i.e. the transaction has begun and is
not committed or aborted) and states that for all threads 𝜏 if transaction 𝑡 (𝛾𝐴.txn𝜏 = 𝑡) is on-the-fly,
the value of wc(𝛾𝐶 .𝑙𝑜𝑐𝜏 ) will be greater than or equal to beginIdx𝑡 and the read set of 𝑡 will be
consistent with memory verison wc(𝛾𝐶 .𝑙𝑜𝑐𝜏 ):

𝛾𝐴.beginIdx𝑡 ≤ wc(𝑙𝑠.𝑙𝑜𝑐𝑡 ) ∧ 𝛾𝐴.rdSet𝑡 ⊆ 𝛾𝐴.Mwc(𝑙𝑠.𝑙𝑜𝑐𝑡 )

Conjunct (4) states that if the value of 𝑙𝑠.𝑙𝑜𝑐𝑡 is even then write set of 𝛾𝐴 must be empty:

even(𝑙𝑠.𝑙𝑜𝑐𝑡 ) ⇒ 𝛾𝐴.wrSet𝑡 = ∅

(3)

(4)

Also if a transaction 𝑡 that has already written to a location then the write set of 𝛾𝐴 is not empty:
𝑙𝑠.hasWritten𝑡 ⇒ 𝛾𝐴.wrSet𝑡 ≠ ∅

(5)

If a transaction has not read any location yet in the concrete state, then the read set of the abstract

state should be empty:

¬𝑙𝑠.hasRead𝑡 ⇒ 𝛾𝐴.rdSet𝑡 = ∅

(6)

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:23

If there is a write in the write set of the abstract state, then the value should match the value of

the last write written to that location by the concrete implementation:

(7)
The value of a visible write of thread 𝜏 to variable 𝑔𝑙𝑏 divided by two is a visible memory by

∀𝑙 ∈ dom(𝛾𝐴.wrSet𝑡 ). 𝛾𝐴.wrSet𝑡 (𝑙) = 𝛾𝐶 .lastval(𝑙)

thread 𝜏 of the abstract state:

(8)
All seen memory indices by the abstract transaction 𝑡 are less the value of thread view of 𝑔𝑙𝑏 for

∀𝑤 ∈ 𝛾𝐶 .𝑂𝑊𝜏 (𝑔𝑙𝑏). wc(val(𝑤)) ∈ 𝛾𝐴.𝑣𝑚𝑒𝑚𝑠𝜏

thread 𝜏 divided by 2:

∀𝑖 ∈ 𝛾𝐴.seenIdxs𝑡 . 𝑖 ≤ wc(val(𝛾𝐶 .tview𝜏 (𝑔𝑙𝑏)))

Theorem 3. 𝑅 is a forward simulation between TMS2-ra and TML-ra.

Proof. This theorem has been verified in Isabelle/HOL.

(9)

□

7 RELATED WORK

Verifying C11 programs. There are now several different approaches to program verification
that support different aspects of the C11 relaxed memory model using pen-and-paper proofs
(e.g., [Alglave and Cousot 2017; Doko and Vafeiadis 2017; Lahav and Vafeiadis 2015; Turon et al.
2014]), model checking (e.g., [Abdulla et al. 2019; Kokologiannakis et al. 2019]), specialised tools
(e.g., [Krishna et al. 2020; Summers and Müller 2018; Svendsen et al. 2018; Tassarotti et al. 2015]),
and generalist theorem provers (e.g., [Dalvandi et al. 2020a]). These cover a variety of (fragments
of) memory models and proceed via exhaustive state space exploration, separation logics, or Hoare-
style calculi. A related approach to TARO that uses a view-based semantics for persistent x86-TSO
has been developed by Bila et al. [2022].

Another series of works has focussed on semantics that support the relaxed dependencies that are
allowed by C11 [Jagadeesan et al. 2020; Kang et al. 2017; Lee et al. 2020; Paviotti et al. 2020]. These
have been followed more recently by logics and verification over this semantics [Svendsen et al.
2018; Wright et al. 2021]. However, relaxed dependencies produce high levels of non-determinism,
making verification significantly more complex. We consider a verification framework that supports
relaxed dependencies and STMs to be a topic for future research.

More recent works include robustness of C11-style programs, which aims to show “adequate
synchronisation” so that the relaxed memory executions reduce to executions under stronger
memory models [Margalit and Lahav 2021]. Such reductions, although automatic, are limited to
finite state systems, and a small number of threads. Furthermore, it is currently unclear how they
would handle client-library synchronisation or relaxed (non-SC) specifications.

Correctness conditions under relaxed memory. Following the extensive literature on the semantics
of relaxed memory architectures, a natural next question has been the development of library
abstractions for relaxed memory. One aim has been to ensure observational refinement and com-
positionality of the implemented objects. A series of works have considered reforumulations of
linearizability [Doherty et al. 2018; Dongol et al. 2018b; Raad et al. 2019a] by presenting suitable
weakenings fine-tuned to the underlying memory model. This includes extensions of linearizability,
e.g., so that it is defined in terms of axiomatic (aka declarative) relaxed memory models [Dongol
et al. 2018b; Raad et al. 2019a] and those that are based on the more abstract concept of execution
structures [Doherty et al. 2018]. Recent works have covered verification of relaxed memory concur-
rent data structures that have been developed to satisfy the conditions described above [Dalvandi
and Dongol 2021; Krishna et al. 2020; Raad et al. 2019a], but none of these cover transactions.

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:24

Sadegh Dalvandi and Brijesh Dongol

Khyzha and Lahav [2022] have recently developed notions of abstraction for crash resilient
libraries, providing correctness conditions (extending linearizability) that ensure contextual refine-
ment for concurrent objects executed over the PSC (persistent sequential consistency) model. They
do so by exposing the internal synchronisation mechanisms that are used to implement an object
in the history (in addition to the invocations and responses). Our work differs since we consider
transactional memory libraries as opposed to concurrent objects, use a different memory model and
focus on verification of contextual refinement directly. Nevertheless, in future work, it would be
interesting to see if their methods provide an alternative method for specifying concurrent object
and transactional memory libraries in C11.

Several papers have revisited transaction semantics in the context of relaxed memory mod-
els [Chong et al. 2018; Dongol et al. 2018a, 2019; Raad et al. 2019b]. Raad et al have considered
relaxed memory and snapshot isolation [Raad et al. 2018, 2019b], which is a weaker condition that
serializability (and hence opacity and TMS2). The question of whether snapshot isolation can be
fully exploited by implementations in a relaxed memory setting remains a topic of future research,
with most transactional implementations aiming to support at least serializability [Zardoshti et al.
2019]. Dongol et al. [2018a] and Chong et al. [2018] have provided axiomatic atransactional se-
mantics integrated with relaxed memory models, focussing on hardware memory models and
hardware transactions. Chong et al. [2018] additionally propose a model for C11 transactions, but
these models are focussed on transactions within the compiler, as opposed to STMs. Finally, the
axiomatic models proposed in these earlier works [Chong et al. 2018; Dongol et al. 2018a] are not
suitable for operational verification, e.g., as supported by TARO, where we require an operational
semantics as provided by TMS2-ra.

Another set of works has focussed on distributed (relaxed) transactions [Beillahi et al. 2021a,b;
Xiong et al. 2020]. Although there are analogues between transactions in distributed systems and
relaxed memory, constraints such as replication consistency and session order are not factors in
shared memory, and hence the underlying issues are fundamentally different. Xiong et al. [2020]
describe a taxonomy of distributed transactional models supported by an operational semantics.
It would be interesting to investigate whether TARO can be adapted to cope with client-object
systems in their models.

Relaxed memory TM implementations. There is a set of recent works on implementing TM
algorithms in C11 [Spear et al. 2020; Zardoshti et al. 2019]. The focus here has been real-world
implementability of STMs via compiler support. Since the focus is on benchmarks and real-world
workflows, these works neither consider a formal semantics nor provide a verification framework.
Our work can thus be seen as providing a formal basis to support to these efforts. In particular, we
show how the serialisability specifications assumed by Spear et al. [2020]; Zardoshti et al. [2019]
can be relaxed, without impacting correctness, while improving performance.

8 CONCLUSIONS

In this paper, we have presented a new approach to release-acquire transactions for RC11 RAR (a
fragment of C11 that supports relaxed as well as release-acquire atomics). We have developed a
new TM specification, TMS2-ra, that extends TMS2 to a relaxed memory context by describing the
interactions between transactions and their clients. We implement TMS2-ra by TML-ra, which is
an adaptation of an existing eager algorithm, TML. We show that TML-ra outperforms TML-sc
using the STAMP benchmarks.

Our second set of contributions covers the verification of release-acquire TM implementations. We
focus on proofs at two levels: (i) correctness of client programs that use TMS2-ra, and (ii) correctness
of implementations of TMS2-ra. For (i), we have developed a logic, TARO, extending [Dalvandi

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:25

and Dongol 2021], and used this logic to prove that TMS2-ra does indeed guarantee the desired
client-side synchronisation properties. For (ii), we have applied a simulation method, simular
to [Dalvandi and Dongol 2021] and proved a forward simulation between TML-ra and TMS2-ra.
All proofs for (i) and (ii) as well as all meta-level soundness results are fully mechanised in the
Isabelle/HOL proof assistant, providing a high level of assurance to our results.

Our motivation for using TML as the main implementation case study was to start with a simple
algorithm with an existing proof in SC [Derrick et al. 2018]. TML performs a global synchronisation
through a CAS on a single location, which degrades performance on write-heavy workloads.
For improved scalability, there are more sophisticated algorithms like TL2 [Dice et al. 2006] that
offer per-location locking as well as hybrid TM implementations [Matveev and Shavit 2015] that
combine hardware and software TM. TMS2 is known to be a sufficient abstraction for hybrid TMs in
SC [Armstrong and Dongol 2017], so it is likely that TMS2-ra also provides a basis for developing
and verifying relaxed and release-acquire versions of these more sophisticated algorithms. We
leave such studies for future work.

ACKNOWLEDGMENTS

The authors would also like to thank the anonymous referees for their valuable comments and
helpful suggestions. Dalvandi and Dongol are supported by EPSRC Grant EP/R032556/1. Dongol is
additionally supported by EPSRC Grant EP/V038915/1, EPSRC Grant EP/R025134/2, ARC Grant
DP190102142 and VeTSS.

REFERENCES

P. A. Abdulla, J. Arora, M. F. Atig, and S. N. Krishna. 2019. Verification of programs under the release-acquire semantics. In

PLDI, K. S. McKinley and K. Fisher (Eds.). ACM, 1117–1132. https://doi.org/10.1145/3314221.3314649

J. Alglave and P. Cousot. 2017. Ogre and Pythia: an invariance proof method for weak consistency models. In POPL,

G. Castagna and A. D. Gordon (Eds.). ACM, 3–18.

J. Alglave, L. Maranget, and M. Tautschnig. 2014. Herding Cats: Modelling, Simulation, Testing, and Data Mining for Weak

Memory. ACM Trans. Program. Lang. Syst. 36, 2 (2014), 7:1–7:74.

A. Armstrong and B. Dongol. 2017. Modularising Opacity Verification for Hybrid Transactional Memory. In FORTE (LNCS,

Vol. 10321), A. Bouajjani and A. Silva (Eds.). Springer, 33–49.

A. Armstrong, B. Dongol, and S. Doherty. 2017. Proving Opacity via Linearizability: A Sound and Complete Method. In

FORTE (LNCS, Vol. 10321), A. Bouajjani and A. Silva (Eds.). Springer, 50–66.

G. Assa, H. Meir, G. Golan-Gueta, I. Keidar, and A. Spiegelman. 2020. Nesting and composition in transactional data structure

libraries. In PPoPP ’20, R. Gupta and X. Shen (Eds.). ACM, 405–406. https://doi.org/10.1145/3332466.3374514

G. Assa, H. Meir, G. Golan-Gueta, I. Keidar, and A. Spiegelman. 2021. Using Nesting to Push the Limits of Transactional
Data Structure Libraries. In OPODIS (LIPIcs, Vol. 217), Q. Bramas, V. Gramoli, and A. Milani (Eds.). Schloss Dagstuhl -
Leibniz-Zentrum für Informatik, 30:1–30:17. https://doi.org/10.4230/LIPIcs.OPODIS.2021.30

H. Attiya, A. Gotsman, S. Hans, and N. Rinetzky. 2018. Characterizing Transactional Memory Consistency Conditions Using

Observational Refinement. J. ACM 65, 1 (2018), 2:1–2:44.

M. Batty, A. F. Donaldson, and J. Wickerson. 2016. Overhauling SC atomics in C11 and OpenCL. In POPL. ACM, 634–648.
M. Batty, S. Owens, S. Sarkar, P. Sewell, and T. Weber. 2011. Mathematizing C++ concurrency. In POPL, T. Ball and M. Sagiv

(Eds.). ACM, 55–66.

S. M. Beillahi, A. Bouajjani, and C. Enea. 2021a. Checking Robustness Between Weak Transactional Consistency Models. In

ESOP (LNCS, Vol. 12648), N. Yoshida (Ed.). Springer, 87–117. https://doi.org/10.1007/978-3-030-72019-3_4

S. M. Beillahi, A. Bouajjani, and C. Enea. 2021b. Robustness Against Transactional Causal Consistency. Log. Methods Comput.

Sci. 17, 1 (2021). https://lmcs.episciences.org/7149

E. Vafeiadi Bila, B. Dongol, O. Lahav, A. Raad, and J. Wickerson. 2022. View-Based Owicki-Gries Reasoning for Persistent x86-
TSO. In ESOP (Lecture Notes in Computer Science, Vol. 13240), I. Sergey (Ed.). Springer, 234–261. https://doi.org/10.1007/978-
3-030-99336-8_9

S. Böhme and T. Nipkow. 2010. Sledgehammer: Judgement Day. In IJCAR (LNCS, Vol. 6173). Springer, 107–121.
N. G. Bronson, J. Casper, H. Chafi, and K. Olukotun. 2010. Transactional predication: high-performance concurrent sets and
maps for STM. In PODC, A. W. Richa and R. Guerraoui (Eds.). ACM, 6–15. https://doi.org/10.1145/1835698.1835703

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:26

Sadegh Dalvandi and Brijesh Dongol

N. Chong, T. Sorensen, and J. Wickerson. 2018. The semantics of transactions and weak memory in x86, Power, ARM, and

C++. In PLDI, J. S. Foster and D. Grossman (Eds.). ACM, 211–225. https://doi.org/10.1145/3192366.3192373

cppreference.com. 2022. std::atomic_compare_exchange. https://en.cppreference.com/w/cpp/atomic/atomic_compare_

exchange Accessed 18 July, 2022.

L. Dalessandro, D. Dice, M. L. Scott, N. Shavit, and M. F. Spear. 2010. Transactional Mutex Locks. In Euro-Par (2) (LNCS,

Vol. 6272). Springer, 2–13.

S. Dalvandi, S. Doherty, B. Dongol, and H. Wehrheim. 2020a. Owicki-Gries Reasoning for C11 RAR. In ECOOP (LIPIcs,
Vol. 166), R. Hirschfeld and T. Pape (Eds.). Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 11:1–11:26. https:
//doi.org/10.4230/LIPIcs.ECOOP.2020.11

S. Dalvandi, S. Doherty, B. Dongol, and H. Wehrheim. 2020b. Owicki-Gries Reasoning for C11 RAR (Artifact). Dagstuhl

Artifacts Ser. 6, 2 (2020), 15:1–15:2. https://doi.org/10.4230/DARTS.6.2.15

S. Dalvandi and B. Dongol. 2021. Verifying C11-style weak memory libraries. In PPoPP, J. Lee and E. Petrank (Eds.). ACM,

451–453. https://doi.org/10.1145/3437801.3441619

S. Dalvandi and B. Dongol. 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Artifact). https:

//doi.org/10.5281/zenodo.6899919

S. Dalvandi, B. Dongol, S. Doherty, and H. Wehrheim. 2022. Integrating Owicki-Gries for C11-Style Memory Models into

Isabelle/HOL. J. Autom. Reason. 66, 1 (2022), 141–171. https://doi.org/10.1007/s10817-021-09610-2

H.-H. Dang, J. Jung, J. Choi, D.-T. Nguyen, W. Mansky, J. Kang, and D. Dreyer. 2022. Compass: strong and compositional
library specifications in relaxed memory separation logic. In PLDI, R. Jhala and I. Dillig (Eds.). ACM, 792–808. https:
//doi.org/10.1145/3519939.3523451

W. P. de Roever and K. Engelhardt. 1998. Data Refinement: Model-oriented Proof Theories and their Comparison. Cambridge

Tracts in Theoretical Computer Science, Vol. 46. Cambridge University Press.

J. Derrick, S. Doherty, B. Dongol, G. Schellhorn, O. Travkin, and H. Wehrheim. 2018. Mechanized proofs of opacity: a
comparison of two techniques. Formal Aspects Comput. 30, 5 (2018), 597–625. https://doi.org/10.1007/s00165-017-0433-3
D. Dice, O. Shalev, and N. Shavit. 2006. Transactional Locking II. In DISC (Lecture Notes in Computer Science, Vol. 4167),

S. Dolev (Ed.). Springer, 194–208. https://doi.org/10.1007/11864219_14

S. Doherty, B. Dongol, J. Derrick, G. Schellhorn, and H. Wehrheim. 2016. Proving Opacity of a Pessimistic STM. In OPODIS
(LIPIcs, Vol. 70), P. Fatourou, E. Jiménez, and F. Pedone (Eds.). Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik,
35:1–35:17.

S. Doherty, B. Dongol, H. Wehrheim, and J. Derrick. 2018. Making Linearizability Compositional for Partially Ordered
Executions. In iFM (LNCS, Vol. 11023), C. A. Furia and K. Winter (Eds.). Springer, 110–129. https://doi.org/10.1007/978-3-
319-98938-9_7

S. Doherty, B. Dongol, H. Wehrheim, and J. Derrick. 2019. Verifying C11 programs operationally. In PPoPP, Jeffrey K.

Hollingsworth and Idit Keidar (Eds.). ACM, 355–365.

S. Doherty, L. Groves, V. Luchangco, and M. Moir. 2013. Towards formally specifying and verifying transactional memory.

Formal Asp. Comput. 25, 5 (2013), 769–799.

M. Doko and V. Vafeiadis. 2017. Tackling Real-Life Relaxed Concurrency with FSL++. In ESOP. 448–475.
S. Dolan, KC Sivaramakrishnan, and A. Madhavapeddy. 2018. Bounding Data Races in Space and Time. In PLDI (Philadelphia,

PA, USA) (PLDI 2018). ACM, New York, NY, USA, 242–255.

B. Dongol and L. Groves. 2016. Contextual Trace Refinement for Concurrent Objects: Safety and Progress. In ICFEM (Lecture
Notes in Computer Science, Vol. 10009), K. Ogata, M. Lawford, and S. Liu (Eds.). 261–278. https://doi.org/10.1007/978-3-
319-47846-3_17

B. Dongol, R. Jagadeesan, and J. Riely. 2018a. Transactions in relaxed memory architectures. PACMPL 2, POPL (2018),

18:1–18:29.

B. Dongol, R. Jagadeesan, and J. Riely. 2019. Modular transactions: bounding mixed races in space and time. In PPoPP, J. K.

Hollingsworth and I. Keidar (Eds.). ACM, 82–93. https://doi.org/10.1145/3293883.3295708

B. Dongol, R. Jagadeesan, J. Riely, and A. Armstrong. 2018b. On abstraction and compositionality for weak-memory

linearisability. In VMCAI (LNCS, Vol. 10747). Springer, 183–204.

M. Emmi and C. Enea. 2019. Weak-consistency specification via visibility relaxation. Proc. ACM Program. Lang. 3, POPL

(2019), 60:1–60:28. https://doi.org/10.1145/3290373

A. Gotsman and H. Yang. 2011. Liveness-Preserving Atomicity Abstraction. In ICALP (Lecture Notes in Computer Science,
Vol. 6756), L. Aceto, M. Henzinger, and J. Sgall (Eds.). Springer, 453–465. https://doi.org/10.1007/978-3-642-22012-8_36

R. Guerraoui and M. Kapalka. 2010. Principles of Transactional Memory. Morgan & Claypool Publishers.
M. He, V. Vafeiadis, S. Qin, and J. F. Ferreira. 2016. Reasoning about Fences and Relaxed Atomics. In PDP. IEEE Computer

Society, 520–527.

M. Herlihy and J. E. B. Moss. 1993. Transactional Memory: Architectural Support for Lock-Free Data Structures. In ISCA,

A. J. Smith (Ed.). ACM, 289–300.

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:27

M. Herlihy and J. M. Wing. 1990. Linearizability: A Correctness Condition for Concurrent Objects. ACM TOPLAS 12, 3

(1990), 463–492.

R. Jagadeesan, A. Jeffrey, and J. Riely. 2020. Pomsets with preconditions: a simple model of relaxed memory. Proc. ACM

Program. Lang. 4, OOPSLA (2020), 194:1–194:30. https://doi.org/10.1145/3428262

J.-O. Kaiser, H.-H. Dang, D. D., O. Lahav, and V. Vafeiadis. 2017. Strong Logic for Weak Memory: Reasoning About Release-
Acquire Consistency in Iris. In ECOOP (LIPIcs, Vol. 74), P. Müller (Ed.). Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik,
17:1–17:29.

J. Kang, C.-K. Hur, O. Lahav, V. Vafeiadis, and D. Dreyer. 2017. A promising semantics for relaxed-memory concurrency. In

POPL. ACM, 175–189.

A. Khyzha and O. Lahav. 2022. Abstraction for Crash-Resilient Objects. In ESOP (Lecture Notes in Computer Science, Vol. 13240),

Ilya Sergey (Ed.). Springer, 262–289. https://doi.org/10.1007/978-3-030-99336-8_10

M. Kokologiannakis, A. Raad, and V. Vafeiadis. 2019. Model checking for weakly consistent libraries. In PLDI, K. S. McKinley

and K. Fisher (Eds.). ACM, 96–110. https://doi.org/10.1145/3314221.3314609

S. Krishna, M. Emmi, C. Enea, and D. Jovanovic. 2020. Verifying Visibility-Based Weak Consistency. In ESOP (LNCS,

Vol. 12075), P. Müller (Ed.). Springer, 280–307. https://doi.org/10.1007/978-3-030-44914-8_11

O. Lahav, E. Namakonov, J. Oberhauser, A. Podkopaev, and V. Vafeiadis. 2021. Making weak memory models fair. Proc. ACM

Program. Lang. 5, OOPSLA (2021), 1–27. https://doi.org/10.1145/3485475

O. Lahav and V. Vafeiadis. 2015. Owicki-Gries Reasoning for Weak Memory Models. In ICALP (LNCS, Vol. 9135), M. M.

Halldórsson, K. Iwama, N. Kobayashi, and B. Speckmann (Eds.). Springer, 311–323.

O. Lahav, V. Vafeiadis, J. Kang, C.-K. Hur, and D. Dreyer. 2017. Repairing sequential consistency in C/C++11. In PLDI. ACM,

618–632.

L. Lamport. 1979. How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs. IEEE Trans.

Computers 28, 9 (1979), 690–691.

S.-H. Lee, M. Cho, A. Podkopaev, S. Chakraborty, C.-K. Hur, O. Lahav, and V. Vafeiadis. 2020. Promising 2.0: global
optimizations in relaxed memory concurrency. In PLDI, A. F. Donaldson and E. Torlak (Eds.). ACM, 362–376. https:
//doi.org/10.1145/3385412.3386010

M. Lesani, V. Luchangco, and M. Moir. 2012. Putting Opacity in Its Place. In WTTM.
M. Lesani, L. Xia, A. Kaseorg, C. J. Bell, A. Chlipala, B. C. Pierce, and S. Zdancewic. 2022. C4: verified transactional objects.

Proc. ACM Program. Lang. 6, OOPSLA (2022), 1–31. https://doi.org/10.1145/3527324

N. A. Lynch. 1996. Distributed Algorithms. Morgan Kaufmann.
R. Margalit and O. Lahav. 2021. Verifying Observational Robustness against a C11-Style Memory Model. Proc. ACM Program.

Lang. 5, POPL, Article 4 (Jan. 2021), 33 pages. https://doi.org/10.1145/3434285

A. Matveev and N. Shavit. 2015. Reduced Hardware NOrec: A Safe and Scalable Hybrid Transactional Memory. In ASPLOS,

Ö. Ö., K. Ebcioglu, and S. Dwarkadas (Eds.). ACM, 59–71. https://doi.org/10.1145/2694344.2694393

C. C. Minh, J. Chung, C. Kozyrakis, and K. Olukotun. 2008. STAMP: Stanford Transactional Applications for Multi-
Processing. In IISWC, D. Christie, A. Lee, O. Mutlu, and B. G. Zorn (Eds.). IEEE Computer Society, 35–46. https:
//doi.org/10.1109/IISWC.2008.4636089

S. S. Owicki and D. Gries. 1976. An Axiomatic Proof Technique for Parallel Programs I. Acta Inf. 6 (1976), 319–340.
M. Paviotti, S. Cooksey, A. Paradis, D. Wright, S. Owens, and M. Batty. 2020. Modular Relaxed Dependencies in Weak Memory
Concurrency. In ESOP (LNCS, Vol. 12075), P. Müller (Ed.). Springer, 599–625. https://doi.org/10.1007/978-3-030-44914-8_22
A. Podkopaev, I. Sergey, and A. Nanevski. 2016. Operational Aspects of C/C++ Concurrency. CoRR abs/1606.01400 (2016).

arXiv:1606.01400

A. Raad, M. Doko, L. Rozic, O. Lahav, and V. Vafeiadis. 2019a. On library correctness under weak memory consistency:
specifying and verifying concurrent libraries under declarative consistency models. Proc. ACM Program. Lang. 3, POPL
(2019), 68:1–68:31. https://doi.org/10.1145/3290381

A. Raad, O. Lahav, and V. Vafeiadis. 2018. On Parallel Snapshot Isolation and Release/Acquire Consistency. In ESOP (LNCS,

Vol. 10801), A. Ahmed (Ed.). Springer, 940–967. https://doi.org/10.1007/978-3-319-89884-1_33

A. Raad, O. Lahav, and V. Vafeiadis. 2019b. On the Semantics of Snapshot Isolation. In VMCAI (LNCS, Vol. 11388), C. Enea

and R. Piskac (Eds.). Springer, 1–23. https://doi.org/10.1007/978-3-030-11245-5_1

M. Rodriguez and M. F. Spear. 2020. Brief Announcement: On Implementing Software Transactional Memory in the C++
Memory Model. In PODC, Y. Emek and C. Cachin (Eds.). ACM, 224–226. https://doi.org/10.1145/3382734.3405746
S. Scargall. 2020. Programming Persistent Memory: A Comprehensive Guide for Developers. APress. https://doi.org/10.1007/978-

1-4842-4932-1_8

G. Sela, M. Herlihy, and E. Petrank. 2021. Brief Announcement: Linearizability: A Typo. In PODC, A. Miller, K. Censor-Hillel,

and J. H. Korhonen (Eds.). ACM, 561–564. https://doi.org/10.1145/3465084.3467944

N. Shavit and D. Touitou. 1997. Software Transactional Memory. Distributed Computing 10, 2 (1997), 99–116.

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:28

Sadegh Dalvandi and Brijesh Dongol

M. Spear, H. Boehm, V. Luchangco, M. L. Scott, and M. Wong. 2020. Transactional Memory Lite Support in C++. Technical

Report. isocpp.

A. J. Summers and P. Müller. 2018. Automating Deductive Verification for Weak-Memory Programs. In TACAS (LNCS,

Vol. 10805), D. Beyer and M. Huisman (Eds.). Springer, 190–209.

K. Svendsen, J. Pichon-Pharabod, M. Doko, O. Lahav, and V. Vafeiadis. 2018. A Separation Logic for a Promising Semantics.

In ESOP (LNCS, Vol. 10801), A. Ahmed (Ed.). Springer, 357–384.

J. Tassarotti, D. Dreyer, and V. Vafeiadis. 2015. Verifying read-copy-update in a logic for weak memory. In PLDI, D. Grove

and S. Blackburn (Eds.). ACM, 110–120. https://doi.org/10.1145/2737924.2737992

A. Turon, V. Vafeiadis, and D. Dreyer. 2014. GPS: navigating weak memory with ghosts, protocols, and separation. In

OOPSLA, A. P. Black and T. D. Millstein (Eds.). ACM, 691–707.

V. Vafeiadis and C. Narayan. 2013. Relaxed separation logic: A program logic for C11 concurrency. In OOPSLA. 867–884.
D. Wright, M. Batty, and B. Dongol. 2021. Owicki-Gries Reasoning for C11 Programs with Relaxed Dependencies. 13047

(2021), 237–254. https://doi.org/10.1007/978-3-030-90870-6_13

S. Xiong, A. Cerone, A. Raad, and P. Gardner. 2020. Data Consistency in Transactional Storage Systems: A Centralised
Semantics. In ECOOP (LIPIcs, Vol. 166), R. Hirschfeld and T. Pape (Eds.). Schloss Dagstuhl - Leibniz-Zentrum für Informatik,
21:1–21:31. https://doi.org/10.4230/LIPIcs.ECOOP.2020.21

P. Zardoshti, T. Zhou, P. Balaji, M. L. Scott, and M. F. Spear. 2019. Simplifying Transactional Memory Support in C++. ACM

Trans. Archit. Code Optim. 16, 3 (2019), 25:1–25:24. https://doi.org/10.1145/3328796

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:29

𝑎 ∈ {𝑟𝑑 (𝑥, 𝑣), 𝑟𝑑A (𝑥, 𝑣)}

𝑤 ∈ 𝛾 .OW 𝜏 (𝑥)

val(𝑤) = 𝑣

tview′ = if 𝛾 .rel(𝑤) ∧ 𝑎 = 𝑟𝑑A (𝑥, 𝑣) then 𝛾 .tview𝜏 ⊗ 𝛾 .mview𝑤 else 𝛾 .tview𝜏 [𝑥 := 𝑤]

𝛾 𝑎

𝜏 𝛾 [tview𝜏 := tview′]

Read

Write

RMW-RA

𝑎 ∈ {𝑤𝑟 (𝑥, 𝑣), 𝑤𝑟 R (𝑥, 𝑣)}
writes′ = 𝛾 .writes ∪ {(𝑥, 𝑣, 𝑞)}
𝛾 𝑎

tst(𝑤) < 𝑞
𝑏 = (𝑎 = 𝑤𝑟 R (𝑥, 𝑣))
𝜏 𝛾 [tview𝜏 := tview′, mview(𝑥,𝑣,𝑞) := tview′, writes := writes′, rel := 𝛾 .rel[𝑤 := 𝑏]]

tview′ = 𝛾 .tview𝜏 [𝑥 := (𝑥, 𝑣, 𝑞)]

w ∈ 𝛾 .OW 𝜏 (𝑥) \ 𝛾 .cvd

fresh𝛾 (𝑥, 𝑞)

𝑎 = 𝑟𝑚𝑤 RA (𝑥, 𝑢, 𝑣)

w ∈ 𝛾 .OW 𝜏 (𝑥) \ 𝛾 .cvd

writes′ = 𝛾 .writes ∪ {(𝑥, 𝑣, 𝑞)}

val(w) = 𝑢

fresh𝛾 (𝑥, 𝑞)
cvd′ = 𝛾 .cvd ∪ {(𝑥, 𝑣, 𝑞)}

tst(𝑤) < 𝑞

tview′ = if 𝛾 .rel(𝑤) then 𝛾 .tview𝜏 [𝑥 := (𝑥, 𝑣, 𝑞)] ⊗ 𝛾 .mview𝑤 else 𝛾 .tview𝜏 [𝑥 := (𝑥, 𝑣, 𝑞)]

𝛾 𝑎

𝑡 𝛾

(cid:20)tview𝜏 := tview′, mview(𝑥,𝑣,𝑞) := tview′,
writes := writes′, cvd := cvd′, rel := 𝛾 .rel[(𝑥, 𝑣, q) := true]

(cid:21)

Fig. 11. Memory semantics for reads, writes and updates, where fresh𝛾 (𝑥, 𝑞) holds iff there is no write in
𝛾 .writes on 𝑥 with timestamp 𝑞, i.e., (𝑥, _, 𝑞) ∉ 𝛾 .writes

A RC11 RAR OPERATIONAL SEMANTICS

We now briefly review the C11 operational semantics (introduced by [Dalvandi et al. 2020a]) used
in our framework.

Component State. Here we detail the C11 state as modelled by the operational semantics. The
first state component is writes which is the set of all global writes to shared locations. Each global
write is represented by a tuple (𝑥, 𝑣, 𝑞), where 𝑥 is a shared location, 𝑞 is a rational number used as
a timestamp, and 𝑣 is the value written by the global write. The writes to each variable are totally
ordered by timestamps.

For any write 𝑤 = (𝑥, 𝑣, 𝑞), we have var(𝑤) = 𝑥, tst(𝑤) = 𝑞 and val(𝑤) = 𝑣. The state needs
to record the writes that are observable by each thread. A function tview𝑡 is included in the state
to record the viewfront of thread 𝑡 (i.e. the latest write that a thread has seen so far). All the writes
with a timestamp greater than or equal to the timestamp of the viewfront of thread 𝑡 are 𝑜𝑏𝑠𝑒𝑟𝑣𝑎𝑏𝑙𝑒
by the thread. Another component of the state is a function mview𝑤 that records the viewfront of
write 𝑤, which is set to be the viewfront of the thread that executed 𝑤 at the time of 𝑤’s execution.
mview𝑤 is used to compute a new value for tview𝑡 if a thread 𝑡 synchronizes with 𝑤. The state
also must record If a global write is 𝑟𝑒𝑙𝑒𝑎𝑠𝑖𝑛𝑔. This is recorded by a function rel𝑤 which returns
true if 𝑤 is releasing or false otherwise. Finally, the state maintains a variable cvd ⊆ writes. The
semantics assumes that each update action occurs in the modification order immediately after
the write that it reads from to preserve the atomicity of updates. To prevent any newer write to
intervene between any update and the write that it reads from, we add all the writes read by an
update operation to the the covered set cvd so newer writes should never interact with covered
writes.

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:30

Sadegh Dalvandi and Brijesh Dongol

Initialisation. The initial state 𝛾 Init is defined as follows.

𝛾 Init.writes ˆ= {(𝑥, 0, 0) | 𝑥 ∈ Loc}

𝛾 Init.cvd ˆ= ∅
𝛾 Init.rel ˆ= 𝜆(𝑥, 0, 0). false
𝛾 Init.tview𝜏 ˆ= 𝜆𝑥 ∈ Loc. (𝑥, 0, 0)
𝛾 Init.mview𝑤 ˆ= 𝜆𝑥 ∈ Loc. (𝑥, 0, 0)

Transition semantics. The transition relation of our semantics for global reads and writes is given

in Fig. 11 [Dalvandi et al. 2020a].

Read transition by thread 𝜏. Assume that 𝑎 is either a relaxed or acquiring read to variable
𝑥, 𝑤 is a write to 𝑥 that 𝑡 can observe (i.e., (𝑤, 𝑞, 𝑣) ∈ 𝛾 .OW 𝜏 (𝑥)), and the value read by 𝑎 is the
value written by 𝑤. Each read causes the viewfront of 𝑡 to be updated. For an unsynchronised
read, tview𝑡 is simply updated to include the new write. A synchronised read causes the executing
thread’s view of the executing component and context to be updated. In particular, for each variable
𝑥, the new view of 𝑥 will be the later (in timestamp order) of either tview𝑡 (𝑥) or mview𝑤 (𝑥).

Write transition by thread 𝑡. A write transition must identify the write (𝑤, 𝑣, 𝑞) after which
𝑎 occurs. This 𝑤 must be observable and must not be covered — the second condition preserves the
atomicity of read-modify-write (RMW) updates. We must choose a fresh timestamp 𝑞′ ∈ Q for 𝑎,
which for a C11 state 𝛾 is formalised by fresh𝛾 (𝑞, 𝑞′) = 𝑞 < 𝑞′ ∧ ∀𝑤 ′ ∈ 𝛾 .writes. 𝑞 < tst(𝑤 ′) ⇒
𝑞′ < tst(𝑤 ′). That is, 𝑞′ is a new timestamp for variable 𝑥 and that (𝑎, 𝑞′, 𝑣 ′) occurs immediately
after (𝑤, 𝑣, 𝑞). The new write is added to the set writes.

We update 𝛾 .tview𝑡 to include the new write, which ensures that 𝑡 can no longer observe any
writes prior to (𝑎, 𝑣 ′, 𝑞′). Moreover, we set the viewfront of (𝑎, 𝑣 ′, 𝑞′) to be the new viewfront of 𝑡 in
𝛾 together with the thread viewfront of the environment state 𝛽. If some other thread synchronises
with this new write in some later transition, that thread’s view will become at least as recent
as 𝑡’s view at this transition. Since mview keeps track of the executing thread’s view of both the
component being executed and its context, any synchronisation through this new write will update
views across components.

Update (aka RMW) transition by thread 𝑡. These transitions are best understood as a combi-
nation of the read and write transitions. As with a write transition, we must choose a valid fresh
timestamp 𝑞′, and the state component writes is updated in the same way. State component mview
includes information from the new view of the executing thread 𝑡. As discussed earlier, in Update
transitions it is necessary to record that the write that the update interacts with is now covered,
which is achieved by adding that write to cvd. Finally, we must compute a new thread view, which
is similar to a Read transition, except that the thread’s new view always includes the new write
introduced by the update.

B TMS2-RA OPERATIONAL SEMANTICS

This section presents further details of the operational semantics from §3.3 of TMS2-RA as formalised
in our Isabelle/HOL development.

Component State. Here we present the transactional state of TMS2-RA which builds on the earlier
semantics of TMS2 [Doherty et al. 2013]. The state space of TMS2-RA extends the state space
of TMS2 and comprises several components. The first component is M which is a sequence that
keeps track of memory snapshots (memory states). The status of each transaction 𝑡 is stored in

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:31

status𝑡 which can have any of the following values: NOTSTARTED, READY, COMMITTED, ABORTED.
Each transaction 𝑡 also has a write set (wrSet𝑡 ) and a read set (rdSet𝑡 ) where the writes and reads
performed by the transaction are stored. For each transaction 𝑡 there is also a beginIdx𝑡 variable
which is set to the most recent memory version when the transaction begins. We extend the TMS2
state space with a number of new components. The seenIdxs𝑡 variable stores the memory version
of all the reads performed by the transaction. V𝑖 is the memory modification view of a stored memory
𝑖 (0 ≤ 𝑖 ≤ |M | − 1). Memory modification view of memory 𝑖 is an snapshot of the transaction’s
client thread view at the time of commiting taht memory. S𝑖 indicates that if the transaction that
committed memory version 𝑖 was releasing.

Initialisation. The initial state 𝛾 Init is defined as follows:

𝛾 Init.M ˆ= ⟨(𝜆𝑙 ∈ 𝐿𝑜𝑐. 0)⟩
𝛾 Init.𝑉 ˆ= ⟨(𝜆𝑙 ∈ 𝐿𝑜𝑐. 𝛽 Init.tview𝑡 (𝑙))⟩
𝛾 Init.S ˆ= ⟨false⟩
𝛾 Init.status𝑡 ˆ= NOTSTARTED
𝛾 Init.rdSet𝑡 ˆ= ∅
𝛾init .wrSet𝑡 ˆ= ∅
𝛾 Init.seenIdxs𝑡 ˆ= ∅
𝛾 Init.beginIdx𝑡 ˆ= 0

where 𝛽 Init is the initial state of the client program.

Transition semantics of TMS2-RA. The transition relation of our TMS2-RA semantics for various

transactional operations is given in Fig. 6 and explained below.

TxBegin operation by transaction 𝑡. A transaction starts with a TxBegin operation and
should specify if it is a relaxed or releasing/acquiring transaction. The TxBegin operation takes 𝑎
and 𝑟 and sets the value of synctype𝑡 accordingly. It also sets the value beginIdx𝑡 to be the latest
memory version at the time of begining the transaction and changes the status𝑡 to READY. Values
of seenIdxs𝑡 , rdSet𝑡 , and wrSet𝑡 are set to empty.

TxWrite operation by transaction 𝑡. Assuming that 𝑙 is a location and 𝑣 is a value and
status𝑡 = READY, TxWrite operation of transaction 𝑡 adds the 𝑙 ↦→ 𝑣 pair to the write set of
transaction 𝑡 (i.e. wrSet𝑡 ). Other state components remain unchanged.

TxRead operation by transaction 𝑡. The transactional read operation (TxRead) reads the
value (𝑣) of location 𝑙 from the transaction 𝑡’s write set (wrSet𝑡 ) if the transaction 𝑡 has previously
wrote to the location 𝑙 (𝑙 ∈ dom(wrSet𝑡 )). In this case the state will remain unchanged.

If 𝑡 has not previously written to 𝑙 (𝑙 ∉ dom(wrSet𝑡 )) then the value of 𝑙 will be read from a
memory version 𝑖 where 𝑖 is greater than or equal to beginIdx𝑡 and the rdSet𝑡 is consistent with
that memory version (i.e. rdSet𝑡 ⊆ M𝑖 ). In this case version 𝑖 will be added to seenIdxs𝑡 and
the transaction’s read set (rdSet𝑡 ) is also updated to include the 𝑙 ↦→ 𝑣. seenIdxs is particularly
important for synchronisation if the transaction is acquiring.

TxEndRO operation by transaction 𝑡. A read-only transaction is committed by TxEndRO. If
a transaction is read-only (wrSet𝑡 = ∅) then it updates status𝑡 of the transaction state (𝛾) to be
COMMITTED and will leave the rest of the state unchanged. If the transaction was set to be acquiring

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:32

Sadegh Dalvandi and Brijesh Dongol

by TxBegin (isAcq𝑡 = 𝑇𝑟𝑢𝑒) and the transaction’s read set is not empty (rdSet𝑡 ≠ ∅) then the
client’s thread view (𝛽.tview𝑡 ) may also get synchronised as well.

TxEndWR operation by transaction 𝑡. A writer transaction is committed by TxEndWR. Simil-
lar to a read-only transaction, a writer transaction (wrSet𝑡 ≠ ∅) will set 𝑠𝑡𝑎𝑡𝑢𝑠𝑡 to COMMITTED.
A writer transaction also add a new memory version 𝑖 to M where 𝑖 is equal to the size of 𝛾 .M
meaning that the new memory version is added to the end of M sequence. The new memory
version is obtained by overrwriting the latest memory version in 𝛾 .M with the transaction’s write
set: 𝑚𝑒𝑚′ = last (𝛾 .M) ⊕ wrSet𝑡 ). The function 𝑙𝑎𝑠𝑡 is defined as 𝑙𝑎𝑠𝑡 (𝑚) ˆ= 𝑚 |𝑚 |−1. The memory
modification view (𝑉𝑖 ) of the new memory version 𝑖 and the updated thread view of the clinet state
(tview𝑡 ) is going to be the same and determined by tview′. The value of tview′ is determined in
the same way as explained for TxEndRO.

TxAbort operation by transaction 𝑡. If transaction 𝑡 aborts, TxAbort will set status𝑡 to
ABORTED. At this point, other transaction operations (except TxBegin) cannot be executed. The
client state 𝛽 will remain unchanged.

C FORWARD SIMULATION IMPLIES OBSERVATIONAL REFINEMENT

We have already shown that there exists a forward simulation between TMS2-ra and TML-ra. In
this section, we show that if there exists a forward simulation between an abstract TM specification
𝐴𝑂 and a concrete implementation 𝐶𝑂 as defined in Definition 5, then for any client 𝑃, 𝑃 [𝐶𝑂] is a
contextual refinement of 𝑃 [𝐴𝑂] (𝑃 [𝐶𝑂] ≤ 𝑃 [𝐴𝑂]).

Theorem 2. If 𝑅 is a forward simulation between 𝐴𝑂 and 𝐶𝑂, then for any client 𝑃 we have

𝑃 [𝐶𝑂] ≤ 𝑃 [𝐴𝑂].

Proof. Assume ft is a full trace of 𝑃 [𝐶𝑂], where for each 𝑖, ft𝑖 is a triple is of the form (ls𝑖, 𝛾𝑖, 𝛽𝑖 ).
We show that there exists a full trace aft of 𝑃 [𝐴𝑂] such that 𝜉 (ft) ≤ 𝜉 (aft) (see Definition 2), where
𝜉 (ft) projects the full trace to the client trace, i.e., for each 𝑖, 𝜉 (ft)𝑖 = (ls𝑖 |𝑃, 𝛽𝑖 ) (and similarly 𝜉 (aft)),
and additionally removes any stuttering.

The proof is by induction over prefixes ft ′ of ft.
For the base case, ft ′ = ⟨(lsInit, 𝛾 Init

𝐶 , 𝛽 Init

“Initialisation” of Definition 5 there exists a (alsInit, 𝛾 Init

𝐶 )⟩ is a trace containing just the initial state of 𝐶. By

𝑅((alsInit, 𝛾 Init

𝐶 ))
Moreover, by “Client observation” of Definition 5, we have alsInit
and locations 𝑥, 𝛽 Init
𝜉 (ft) ≤ 𝜉 (aft).

𝐶 .OW (𝜏, 𝑥) ⊆ 𝛽 Init

𝐴 , 𝛽 Init

|𝑃 and for all threads 𝜏
𝐴 .OW (𝜏, 𝑥). Thus, for 𝜉 (ft) there exists an aft such that

|𝑃 = lsInit

For our inductive hypothesis, assume the result holds for ft ′, i.e., there exists an abstrace pre-
fix aft ′ of an abstract trace aft of 𝑃 [𝐴𝑂] such that 𝜉 (ft ′) ≤ 𝜉 (aft ′). Moreover, we assume that
𝑅(last (aft ′), last (ft ′)). Suppose ft ′′ = ft ′ · ⟨(ls, 𝛾𝐶, 𝛽𝐶 )⟩ where (ls, 𝛾𝐶, 𝛽𝐶 ) is generated by a concrete
step from last (ft ′). There are three possibilites based on the step taken by the concrete program.
• The first case is when the concrete program takes a library step and ft ′′ is the program
trace after the execution of the library step, because we already proved 𝐶𝑂 ≤ 𝐴𝑂 then
by preservation rule of Definition 5 we know that there exists an abstract trace aft ′′ =
aft ′ · ⟨(als, 𝛾𝐴, 𝛽𝐴)⟩ such that 𝑅((als, 𝛾𝐴, 𝛽𝐴), (ls, 𝛾𝐶, 𝛽𝐶 )). Moreover using “Client observation”
of Definition 5, we have 𝜉 (ft ′′) ≤ 𝜉 (aft ′′).

• The next case is when the concrete program takes a non-synchronising client step. Since
the abstract and concrete takes the same non-synchronising step, the abstract and concrete

𝐴 , 𝛽 Init
𝐴 ), (lsInit, 𝛾 Init

𝐴 ) such that
𝐶 , 𝛽 Init

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:33

library states remain unchanged, thus 𝑅𝑂 ((als |𝐴𝑂, 𝛾𝐴), (ls |𝐶𝑂, 𝛾𝐶 )). Moreover, the thread view
and local state of both abstract and concrete programs will be updated in the same way,
thus we also have 𝑅𝑉 ((als, 𝛽𝐴), (ls, 𝛽𝐶 )). Finally, by the client observation property and the
refinement relation 𝑅 are preserved. Since we match the concrete step at the abstract level,
we have 𝜉 (ft ′′) ≤ 𝜉 (aft ′′).

• The last case is when the concrete program takes a synchronising client step. Like the un-
synchronising case, the abstract and concrete client steps are identical and they both update
the thread view and local state of the client in the same way, thus 𝑅𝑉 ((als, 𝛽𝐴), (ls, 𝛽𝐶 )).
Thus, we have 𝜉 (ft ′′) ≤ 𝜉 (aft ′′). We must now show that the refinement relation holds in
the post-state. As opposed to the previous case, the synchronising client step potentially
updates the library state by advancing the library thread view for the executing thread, 𝜏.
However, this is equivalent to moving the library view forward using the “Thread view
stability” property of Definition 5. Thus, we have 𝑅𝑂 ((als |𝐴𝑂, 𝛾𝐴), (ls |𝐶𝑂, 𝛾𝐶 )).

□

D SELECTION OF TARO PROOF RULES

We present a selection of TARO proof rules that we use in our examples. The full development [Dal-
vandi and Dongol 2022] contains many other rules, but we do not present all of these, since they
are less interesting. Note that 𝑧 below is a client variable.

D.1 Assertions over TxBegin

(1) (cid:8)¬[ ˆ𝑥 ≈ 𝑢]𝜏 (cid:9) TxBegin_ (_, _) (cid:8)¬[ ˆ𝑥 ≈ 𝑢]𝜏 (cid:9)
(2) (cid:8)⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 (cid:9) TxBegin_ (_, _) (cid:8)⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 (cid:9)
(3) (cid:8)[𝑧 = 𝑢]𝜏 (cid:9) TxBegin_(_, _) (cid:8)[𝑧 = 𝑢]𝜏 (cid:9)
(4) (cid:8)true(cid:9) TxBegin𝜏 (R, _) (cid:8)𝑅𝑒𝑙𝜏 (cid:9)
(5) (cid:8)true(cid:9) TxBegin𝜏 (A, _) (cid:8)𝐴𝑐𝑞𝜏 (cid:9)
(6) (cid:8)( ˆ𝑦, 𝑣) ∈ WS𝜏 ′ ∧ 𝜏 ≠ 𝜏 ′(cid:9) TxBegin𝜏 (_, _) (cid:8)( ˆ𝑦, 𝑣) ∈ WS𝜏 ′ (cid:9)

D.2 Assertions over TxRead

(1) (cid:8)¬[ ˆ𝑥 ≈ 𝑢]𝜏 (cid:9) TxRead_(_, _) (cid:8)¬[ ˆ𝑥 ≈ 𝑢]𝜏 (cid:9)
(2) (cid:8)[ ˆ𝑥 = 𝑢]𝜏 ′ (cid:9) TxRead𝜏 (_, _) (cid:8)𝑠𝑡𝑎𝑡𝑢𝑠𝜏 = READY ⇒ [ ˆ𝑥 = 𝑢]𝜏 ′ (cid:9)
(3) (cid:8)WS𝜏 = ∅(cid:9) TxRead𝜏 ( ˆ𝑥, 𝑟 ) (cid:8)( ˆ𝑥, 𝑟 ) ∈ RS𝜏 (cid:9)
(4) (cid:8)( ˆ𝑥, 𝑟 ) ∉ WS𝜏 (cid:9) TxRead𝜏 ( ˆ𝑥, 𝑟 ) (cid:8)[ ˆ𝑥 ≈ 𝑟 ]𝜏 (cid:9)
(5) (cid:8)[ ˆ𝑥 = 𝑢]𝜏 ∧ ˆ𝑥 ∉ dom(WS𝜏 )(cid:9) TxRead𝜏 ( ˆ𝑥, 𝑟 ) (cid:8)𝑟 = 𝑢(cid:9)
(6) (cid:8)( ˆ𝑦, 𝑣) ∈ WS𝜏 (cid:9) TxRead_(_, _) (cid:8)( ˆ𝑦, 𝑣) ∈ WS𝜏 (cid:9)
(7) (cid:8)( ˆ𝑦, 𝑣) ∈ RS𝜏 ′ ∧ 𝜏 ≠ 𝜏 ′(cid:9) TxRead𝜏 (_, _) (cid:8)( ˆ𝑦, 𝑣) ∈ RS𝜏 ′ (cid:9)

D.3 Assertions over TxWrite

(1) (cid:8)¬[ ˆ𝑥 ≈ 𝑢]𝜏 (cid:9) TxWrite_ (_, _) (cid:8)¬[ ˆ𝑥 ≈ 𝑢]𝜏 (cid:9)
(2) (cid:8)[𝑧 = 𝑢]𝜏 (cid:9) TxWrite_ (_, _) (cid:8)[𝑧 = 𝑢]𝜏 (cid:9)
(3) (cid:8)true(cid:9) TxWrite𝜏 ( ˆ𝑦, 𝑣) (cid:8)( ˆ𝑦, 𝑣) ∈ WS𝜏 (cid:9)

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:34

Sadegh Dalvandi and Brijesh Dongol

(4) (cid:8)⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 ∧ 𝑤 ≠ 𝑢(cid:9) TxWrite𝜏 ( ˆ𝑦, 𝑤) (cid:8)⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 (cid:9)
(5) (cid:8) ˆ𝑥 ≠ ˆ𝑦 ∧ ( ˆ𝑦, 𝑣) ∈ WS𝜏 (cid:9) TxWrite_ ( ˆ𝑥, _) (cid:8)( ˆ𝑦, 𝑣) ∈ WS𝜏 (cid:9)

D.4 Assertions over TxEnd

(1) (cid:8)⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 ′ ∧ WS𝜏 = ∅(cid:9) TxEnd𝜏 (cid:8)⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 ′ (cid:9)

(cid:26)( ˆ𝑥, 𝑢) ∈ WS𝜏 ∧ ¬[ ˆ𝑥 ≈ 𝑢]𝜏 ′ ∧
[𝑧 = 𝑣]𝜏 ∧ 𝑅𝑒𝑙𝜏 ∧ 𝜏 ≠ 𝜏 ′

(cid:27)

(2)

TxEnd𝜏 (cid:8)𝑠𝑡𝑎𝑡𝑢𝑠𝜏 = COMMITTED ⇒ ⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 ′ (cid:9)

(3) (cid:8)⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 ∧ ( ˆ𝑥, 𝑢) ∉ WS𝜏 ∧ 𝑅𝑒𝑙𝜏 (cid:9) TxEnd𝜏 (cid:8)⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 (cid:9)
(4) (cid:8)⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 ′ (cid:9) TxEnd𝜏 (cid:8)𝑠𝑡𝑎𝑡𝑢𝑠𝜏 = ABORTED ⇒ ⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 ′ (cid:9)

(cid:26)⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 ∧ ( ˆ𝑥, 𝑢) ∈ RS𝜏 ∧
𝐴𝑐𝑞𝜏 ∧ WS𝜏 = ∅

(cid:27)

(5)

TxEnd𝜏 (cid:8)𝑠𝑡𝑎𝑡𝑢𝑠𝜏 = COMMITTED ⇒ [𝑧 = 𝑣]𝜏 (cid:9)

(6) (cid:8)¬[ ˆ𝑥 ≈ 𝑢]𝜏 ′ ∧ ( ˆ𝑥, 𝑢) ∉ WS𝜏 (cid:9) TxEnd𝜏 (cid:8)¬[ ˆ𝑥 ≈ 𝑢]𝜏 ′ (cid:9)
(7) (cid:8)[𝑦 = 𝑣]𝜏 (cid:9) TxEnd𝜏 (cid:8)[𝑦 = 𝑣]𝜏 (cid:9)
(8) (cid:8)[𝑥 ≈ 𝑢]𝜏 ′ ∧ ¬𝐴𝑐𝑞𝜏 (cid:9) TxEnd𝜏 (cid:8)[𝑥 ≈ 𝑢]𝜏 ′ (cid:9)
(9) (cid:8)( ˆ𝑦, 𝑣) ∈ WS𝜏 ′ (cid:9) TxEnd𝜏 (cid:8)( ˆ𝑦, 𝑣) ∈ WS𝜏 ′ (cid:9)

D.5 Assertions over client actions

(1) (cid:8)⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 ′ (cid:9) 𝑟 ←𝜏 𝑧 ′ (cid:8)⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 ′ (cid:9)
(2) (cid:8)⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 ∧ 𝑧 ≠ 𝑧 ′(cid:9) 𝑧 ′ :=𝜏 𝑚 (cid:8)⟨ ˆ𝑥 = 𝑢⟩[𝑧 = 𝑣]𝜏 (cid:9)

E ADDITIONAL EXAMPLES

This section provides the full proof outline for two additional examples. The proof outline presented
in Fig. 13 includes two new assertions that were not introduced previously:

• Memory-value assertion: A memory-value assertion, denoted as M [ ˆ𝑥, 𝑣]𝑖 , holds iff the

value of location 𝑥 in memory version 𝑖 is 𝑣.

M [ ˆ𝑥, 𝑣]𝑖 ˆ= 𝑖 ∈ dom(M) ∧ M𝑖 ( ˆ𝑥) = 𝑣

• Never-written assertion: A never-written assertion, denoted as 𝑁𝑊 [ ˆ𝑥, 𝑣], holds iff none

of the recorded memories in M has the value 𝑣 for location 𝑥.

𝑁𝑊 [ ˆ𝑥, 𝑣] ˆ= ∀𝑖 ∈ dom(M). ¬M [ ˆ𝑥, 𝑣]𝑖

A selection of proof rules over memory-value and never-written predicates are given below.
(1) (cid:8)M [ ˆ𝑥, 𝑢]𝑖 (cid:9) TxBegin𝜏 (_, _)(cid:8)M [ ˆ𝑥, 𝑢]𝑖 (cid:9)
(2) (cid:8)M [ ˆ𝑥, 𝑢]𝑖 (cid:9) TxRead𝜏 (_, _) (cid:8)M [ ˆ𝑥, 𝑢]𝑖 (cid:9)
(3) (cid:8)M [ ˆ𝑥, 𝑢]𝑖 (cid:9) TxWrite𝜏 (_, _)(cid:8)M [ ˆ𝑥, 𝑢]𝑖 (cid:9)
(4) (cid:8)( ˆ𝑥, 𝑢) ∈ WS𝜏 ∧ |M | = 𝑛(cid:9) TxEnd𝜏 (cid:8)𝑠𝑡𝑎𝑡𝑢𝑠𝜏 = COMMITTED ⇒ M [ ˆ𝑥 = 𝑢]𝑛(cid:9)
(5) (cid:8)M [ ˆ𝑥 = 𝑣]𝑖 ∧ 𝑖 < |M | − 1(cid:9) TxEnd𝜏 (cid:8)M [ ˆ𝑥 = 𝑣]𝑖 (cid:9)

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:35

TxRead𝜏 ( ˆ𝑦, 𝑟 ) (cid:8)𝑠𝑡𝑎𝑡𝑢𝑠𝜏 = READY ⇒ 𝑟 = 𝑛(cid:9)

M [ ˆ𝑥 = 𝑢]𝑖−1 ∧ M [ ˆ𝑥 = 𝑣]𝑖 ∧
M [ ˆ𝑦 = 𝑙]𝑖−1 ∧ M [ ˆ𝑦 = 𝑛]𝑖 ∧
𝑢 ≠ 𝑣 ∧ 𝑙 ≠ 𝑛 ∧ 𝑖 = |M | − 1 ∧
txn𝜏 = 𝑡 ∧ 𝑏𝑒𝑔𝑖𝑛𝐼𝑛𝑑𝑒𝑥𝑡 = 𝑖 − 1 ∧
( ˆ𝑥, 𝑣) ∈ RS𝜏 ∧ WS𝜏 = ∅

(6)











(7) (cid:8)𝑁𝑊 [ ˆ𝑥, 𝑣](cid:9) TxBegin𝜏 (_, _) (cid:8)¬[ ˆ𝑥 ≈ 𝑣]𝜏 ′ (cid:9)
(8) (cid:8)𝑁𝑊 [ ˆ𝑥, 𝑣](cid:9) TxBegin𝜏 (_, _) (cid:8)𝑁𝑊 [𝑥, 𝑣](cid:9)
(9) (cid:8)𝑁𝑊 [ ˆ𝑥, 𝑣](cid:9) TxRead𝜏 (_, _) (cid:8)𝑁𝑊 [𝑥, 𝑣](cid:9)
(10) (cid:8)𝑁𝑊 [ ˆ𝑥, 𝑣](cid:9) TxWrite𝜏 (_, _) (cid:8)𝑁𝑊 [ ˆ𝑥, 𝑣](cid:9)
(11) (cid:8)𝑁𝑊 [ ˆ𝑥, 𝑣] ∧ ( ˆ𝑥, 𝑣) ∉ WS𝜏 (cid:9) TxEnd𝜏 (cid:8)𝑁𝑊 [ ˆ𝑥, 𝑣](cid:9)
Theorem 4. The proof outlines in Fig. 12 and Fig. 13 are valid.

Proof. This theorem has been verified in Isabelle/HOL.

□

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

1:36

Sadegh Dalvandi and Brijesh Dongol

(cid:8)∀𝜏 ∈ {𝜏1, 𝜏2, 𝜏3}. [ ˆ𝑓 = 0]𝜏 ∧ [𝑑1 = 0]𝜏 ∧ [𝑑2 = 0]𝜏 (cid:9)

Thread 𝜏1
(cid:8)[ ˆ𝑓 (cid:48) 1]𝜏2 ∧ [𝑑1 = 0]𝜏1 ∧ ¬tf
1 : 𝑑1 := 5;
(cid:8)[ ˆ𝑓 (cid:48) 1]𝜏2 ∧ [𝑑1 = 5]𝜏1 ∧ ¬tf
2 : TxBegin(R, ∅)
(cid:26)[ ˆ𝑓 (cid:48) 1]𝜏2 ∧ [𝑑1 = 5]𝜏1 ∧
Rel𝜏1 ∧ ¬tf
1
3 : TxWrite(𝑓 , 1) ;
(cid:26)[ ˆ𝑓 (cid:48) 1]𝜏2 ∧ [𝑑1 = 5]𝜏1 ∧
Rel𝜏1 ∧ ( ˆ𝑓 , 1) ∈ WS𝜏1 ∧ ¬tf
4 : ⟨TxEnd, tf
1 := true⟩ ;
(cid:8)⟨ ˆ𝑓 = 1⟩[𝑑1 = 5]𝜏2 ∧ tf

(cid:27)

(cid:9)

1

1

(cid:9)

(cid:9)

1

1

(cid:27)





(cid:27)

1) ∧

1)(cid:9)
1)(cid:9)

Thread 𝜏2
(cid:8)𝑃 (0) ∧ ( [ ˆ𝑓 ≈ 1]𝜏2 ⇒ tf
5 : 𝑑2 := 10;
(cid:8)𝑃 (10) ∧ ( [ ˆ𝑓 ≈ 1]𝜏2 ⇒ tf
6 : TxBegin(RA, {r2})
(cid:26)𝑃 (10) ∧ ( [ ˆ𝑓 ≈ 1]𝜏2 ⇒ tf
Acq𝜏2 ∧ Rel𝜏2 ∧ WS𝜏2 = ∅
7 : TxRead(𝑓 , 𝑟2) ;
𝑃 (10) ∧

(𝑟2 = 1 ⇒ [𝑑1
Acq𝜏2 ∧ Rel𝜏2 ∧

WS𝜏2 = ∅ ∧ ( ˆ𝑓 , 𝑟2) ∈ RS𝜏2

8 : if 𝑟2 = 1 then
𝑆

= 5]𝜏2 ∧ tf
𝑃 (10) ∧ [𝑑1
𝑟2 = 1 ∧ Acq𝜏2 ∧ Rel𝜏2 ∧

WS𝜏2 = ∅ ∧ ( ˆ𝑓 , 𝑟2) ∈ RS𝜏2

9 :

𝑆
= 5]𝜏2 ∧ tf

TxWrite(𝑓 , 2)

1 ∧

1) ∧

1 ∧

(cid:33)

∧

𝑆
= 5]𝜏2 ∧ tf
𝑃 (10) ∧ [𝑑1
𝑟2 = 1 ∧ Acq𝜏2 ∧ Rel𝜏2 ∧
WS𝜏2 = {( ˆ𝑓 , 2)} ∧
( ˆ𝑓 , 𝑟2) ∈ RS𝜏2




𝑃 (10) ∧ Acq𝜏2 ∧ Rel𝜏2 ∧
(𝑟2 ≠ 1 ⇒ WS𝜏2 = ∅) ∧
(cid:32)
𝑆
𝑟2 = 1 ⇒ [𝑑1
= 5]𝜏2 ∧
tf
( ˆ𝑓 , 𝑟2) ∈ RS𝜏2

10 : TxEnd ;
⟨ ˆ𝑓 = 2⟩[𝑑2 = 10]𝜏3 ∧
(cid:18)𝑟2 ≠ 1 ⇒

1 ∧ ( ˆ𝑓 , 2) ∈ WS𝜏2




























1 ⇒ [ ˆ𝑓 (cid:48) 1]𝜏3 ∧ [ ˆ𝑓 (cid:48) 2]𝜏3)

1 ⇒ [ ˆ𝑓 (cid:48) 1]𝜏3 ∧ [ ˆ𝑓 (cid:48) 2]𝜏3)

Thread 𝜏3
⟨ ˆ𝑓 = 2⟩[𝑑1 = 5]𝜏3 ∧

⟨ ˆ𝑓 = 2⟩[𝑑2 = 10]𝜏3 ∧

(¬tf

11 : TxBegin(A, {r3})
⟨ ˆ𝑓 = 2⟩[𝑑1 = 5]𝜏3 ∧

⟨ ˆ𝑓 = 2⟩[𝑑2 = 10]𝜏3 ∧
(¬tf

∧WS𝜏3 = ∅ ∧ Acq𝜏3

12 : TxRead(𝑓 , 𝑟3) ;
⟨ ˆ𝑓 = 2⟩[𝑑1 = 5]𝜏3 ∧
⟨ ˆ𝑓 = 2⟩[𝑑2 = 10]𝜏3 ∧
(cid:18)¬tf




1 ⇒
[ ˆ𝑓 (cid:48) 1]𝜏3 ∧ [ ˆ𝑓 (cid:48) 2]𝜏3

(cid:19)

∧

WS𝜏3 = ∅ ∧
( ˆ𝑓 , 𝑟3) ∈ RS𝜏3 ∧ Acq𝜏3 ∧
(cid:32)𝑟3 = 2 ⇒
[𝑑1


13 : TxEnd ;
(cid:8)𝑟3 = 2 ⇒ [𝑑1 = 5]𝜏3 ∧ [𝑑2 = 10]𝜏3
14 : if 𝑟3 = 2 then

𝑆
= 5]𝜏3 ∧ [𝑑2

𝑆
= 10]𝜏3

(cid:33)

(cid:9)

(cid:9)

15 :

(cid:8)[𝑑1 = 5]𝜏3 ∧ [𝑑2 = 10]𝜏3
𝑠1 ← 𝑑1
(cid:8)𝑠1 = 5 ∧ [𝑑2 = 10]𝜏3
𝑠2 ← 𝑑2
(cid:8)𝑠1 = 5 ∧ 𝑠2 = 10(cid:9)
(cid:8)𝑟3 = 2 ⇒ 𝑠1 = 5 ∧ 𝑠2 = 10(cid:9)

16 :

(cid:9)

(cid:19)




[ ˆ𝑓 (cid:48) 2]𝜏1 ∧ [ ˆ𝑓 (cid:48) 2]𝜏3



1 ∧ ⟨ ˆ𝑓 = 2⟩[𝑑1 =𝜏3 5]

{𝑟3 = 2 ⇒ 𝑠1 = 5 ∧ 𝑠2 = 10}
Fig. 12. Proof outline for extended transactional MP, where 𝑃 (𝑘) ˆ= [𝑑2 = 𝑘]𝜏2 ∧ ⟨ ˆ𝑓 = 1⟩[𝑑1 = 42]𝜏2 ∧ [ ˆ𝑓 (cid:48)
2]𝜏1 ∧ [ ˆ𝑓 (cid:48) 2]𝜏3

(cid:18)𝑟2 = 1 ⇒
tf

∧



(cid:19)

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

Implementing and Verifying Release-Acquire Transactional Memory (Extended Version)

1:37

(cid:27)

(cid:27)

Thread 𝜏1
(cid:26)𝑁𝑊 [ ˆ𝑓 , 1] ∧ 𝑁𝑊 [ ˆ𝑑2, 10]
∧[𝑑1 = 0]𝜏1 ∧ |M | = 0
1 : 𝑑1 := 5;
(cid:26)𝑁𝑊 [ ˆ𝑓 , 1] ∧ 𝑁𝑊 [ ˆ𝑑2, 10]
∧[𝑑1 = 5]𝜏1 ∧ |M | = 0
2 : TxBegin(RX, ∅) ;
¬[ ˆ𝑓 ≈ 1]𝜏2 ∧ ¬[ ˆ𝑑2 ≈ 10]𝜏2


∧[𝑑1 = 5]𝜏1 ∧ ¬Rel𝜏1
∧ status𝜏1 = 𝑅


∧¬Acq𝜏1 ∧ |M | = 0


3 : TxWrite(𝑑2, 10) ;
( ˆ𝑑2, 10) ∈ WS𝑡 ∧ ¬[ ˆ𝑓 ≈ 1]𝜏2

∧¬[ ˆ𝑑2 ≈ 10]𝜏2 ∧ [𝑑1 = 5]𝜏1
∧¬Rel𝜏1 ∧ status𝜏1 = 𝑅∧

¬Acq𝜏1 ∧ |M | = 0

4 : TxWrite(𝑓 , 1) ;
( ˆ𝑓 , 1) ∈ WS𝜏1 ∧ ( ˆ𝑑2, 10) ∈ WS𝜏1

∧¬[ ˆ𝑓 ≈ 1]𝜏2 ∧ ¬[ ˆ𝑑2 ≈ 10]𝜏2
∧[𝑑1 = 5]𝜏1 ∧ ¬Rel𝜏1∧

status𝜏1 = 𝑅 ∧ ¬Acq𝜏1 ∧ |M | = 0

5 : TxEnd ;
(cid:8)true(cid:9)









Thread 𝜏2
M [ ˆ𝑓 = 0]0 ∧ M [ ˆ𝑑2 = 0]0∧
(status𝜏1 = 𝐶 ⇒ M [ ˆ𝑓 = 1]1 ∧ M [ ˆ𝑑2 = 10]1)∧
(status𝜏1 = 𝐶 ⇒ ([ ˆ𝑓 ≈ 0]𝑡 ∨ [ ˆ𝑓 ≈ 1]𝑡 ))∧
(status𝜏1 = 𝐶 ⇒ ([ ˆ𝑑2 ≈ 0]𝑡 ∨ [ ˆ𝑑2 ≈ 10]𝑡 ))∧
(∀𝑣.𝑣 ∉ {0, 5} ⇒ ¬[𝑑1 ≈𝜏2 𝑣])∧
(status𝜏1 ≠ 𝐶 ⇒ [ ˆ𝑓 = 0]𝑡 ∧ [ ˆ𝑑2 = 0]𝑡 )∧
𝑊 𝑆𝑡 = ∅∧
(∀𝑖.𝑖 ≠ 0 ∧ 𝑖 ≤ |M | ⇒ ¬M [ ˆ𝑑2 = 0]𝑖 )∧
(∀𝑖.𝑖 ≠ 1 ∧ 𝑖 ≤ |M | ⇒ ¬M [ ˆ𝑓 = 1]𝑖 )


6 : TxBegin(RX, {r1, r2})

M [ ˆ𝑓 = 0]0 ∧ M [ ˆ𝑑2 = 0]0∧
(status𝜏1 = 𝐶 ⇒ M [ ˆ𝑓 = 1]1 ∧ M [ ˆ𝑑2 = 10]1)∧
(status𝜏1 = 𝐶 ⇒ ([ ˆ𝑓 ≈ 0]𝜏1 ∨ [ ˆ𝑓 ≈ 1]𝜏1))∧
(status𝜏1 = 𝐶 ⇒ ([ ˆ𝑑2 ≈ 0]𝜏1 ∨ [ ˆ𝑑2 ≈ 10]𝜏1))∧
(∀𝑣.𝑣 ∉ 0, 5 ⇒ ¬[𝑑1 ≈𝜏2 𝑣])∧
(status𝜏1 ≠ 𝐶 ⇒ [ ˆ𝑓 = 0]𝜏1 ∧ [ ˆ𝑑2 = 0]𝜏1)∧
𝑊 𝑆𝜏1 = ∅∧
(∀𝑖.𝑖 ≠ 0 ∧ 𝑖 ≤ |𝑀 | ⇒ ¬M [ ˆ𝑑2 = 0]𝑖 )∧
(∀𝑖.𝑖 ≠ 1 ∧ 𝑖 ≤ |𝑀 | ⇒ ¬M [ ˆ𝑓 = 1]𝑖 ) ∧ ¬𝐴𝑐𝑞𝜏1











7 : TxRead(𝑓 , 𝑟1) ;

M [ ˆ𝑓 = 0]0 ∧ M [ ˆ𝑑2 = 0]0∧
(𝑟 1 = 1 ⇒ status𝜏1 = 𝐶)∧
(𝑟 1 = 1 ⇒ ( ˆ𝑓 , 1) ∈ 𝑅𝑆𝜏1)∧
(𝑟 1 = 1 ⇒ M [ ˆ𝑓 = 1]1 ∧ M [ ˆ𝑑2 = 10]1)∧
(∀𝑣.𝑣 ∉ 0, 5 ⇒ ¬[𝑑1 ≈𝜏2 𝑣])∧
𝑊 𝑆𝜏1 = ∅∧
(∀𝑖.𝑖 ≠ 0 ∧ 𝑖 ≤ |𝑀 | ⇒ ¬M [ ˆ𝑑2 = 0]𝑖 )∧
(∀𝑖.𝑖 ≠ 1 ∧ 𝑖 ≤ |𝑀 | ⇒ ¬M [ ˆ𝑓 = 1]𝑖 ) ∧ ¬𝐴𝑐𝑞𝜏1







8 : if 𝑟1 = 1 then










M [ ˆ𝑓 = 0]0 ∧ M [ ˆ𝑑2 = 0]0
∧M [ ˆ𝑓 = 1]1 ∧ M [ ˆ𝑑2 = 10]1
∧𝑟 1 = 1 ∧ ( ˆ𝑓 , 1) ∈ 𝑅𝑆𝜏1∧
(∀𝑣.𝑣 ∉ 0, 5 ⇒ ¬[𝑑1 ≈𝜏2 𝑣])∧
𝑊 𝑆𝜏1 = ∅∧
(∀𝑖.𝑖 ≠ 0 ∧ 𝑖 ≤ |𝑀 | ⇒ ¬M [ ˆ𝑑2 = 0]𝑖 )∧
(∀𝑖.𝑖 ≠ 1 ∧ 𝑖 ≤ |𝑀 | ⇒ ¬M [ ˆ𝑓 = 1]𝑖 ) ∧ ¬𝐴𝑐𝑞𝜏1 ∧ status𝜏1 = 𝐶







TxRead(𝑑2, 𝑟2) ;
9 :
(𝑟 1 = 1 ⇒ 𝑟 2 = 10)∧

(∀𝑣.𝑣 ∉ 0, 5 ⇒ ¬[𝑑1 ≈𝜏2 𝑣])∧
𝑊 𝑆𝜏1 = ∅ ∧ ¬𝐴𝑐𝑞𝜏1


10 : TxEnd ;
(cid:26)(∀𝑣.𝑣 ∉ 0, 5 ⇒ ¬[𝑑1 ≈𝜏2 𝑣])∧
(status𝜏2 = 𝐶 ∧ 𝑟 1 = 1 ⇒ 𝑟 2 = 10)





(cid:27)

11 : 𝑟3 ← 𝑑1;
(cid:8)(status𝜏2 = 𝐶 ∧ 𝑟1 = 1 ⇒ 𝑟2 = 10 ∧ 𝑟3 ∈ {0, 5})(cid:9)

{status𝜏2 = 𝐶 ∧ 𝑟1 = 1 ⇒ 𝑟2 = 10 ∧ 𝑟3 ∈ {0, 5}}
Fig. 13. Proof outline for relaxed transactions where 𝐶 and 𝑅 are shorthand for COMMITTED and READY,
respectively.

Proc. ACM Program. Lang., Vol. 1, No. OOPSLA, Article 1. Publication date: December 2022.

