2
2
0
2

y
a
M
7
1

]
E
S
.
s
c
[

1
v
1
0
2
8
0
.
5
0
2
2
:
v
i
X
r
a

A Multi-level Methodology for Behavioral
Comparison of Software-Intensive Systems

Dennis Hendriks1,2(cid:63), Arjan van der Meer1,3∗, and Wytse Oortwijn1∗

1 ESI (TNO), Eindhoven, The Netherlands
dennis.hendriks@tno.nl
2 Radboud University, Nijmegen, The Netherlands
dennis.hendriks@ru.nl
3 Capgemini Engineering, Eindhoven, The Netherlands

Abstract. Software-intensive systems constantly evolve. To prevent soft-
ware changes from unintentionally introducing costly system defects, it
is important to understand their impact to reduce risk. However, it is in
practice nearly impossible to foresee the full impact of software changes
when dealing with huge industrial systems with many conﬁgurations and
usage scenarios. To assist developers with change impact analysis we in-
troduce a novel multi-level methodology for behavioral comparison of
software-intensive systems. Our fully automated methodology is based
on comparing state machine models of software behavior. We combine ex-
isting complementary comparison methods into a novel approach, guid-
ing users step by step though relevant diﬀerences by gradually zooming
into more and more detail. We empirically evaluate our work through a
qualitative exploratory ﬁeld study, showing its practical value using mul-
tiple case studies at ASML, a leading company in developing lithography
systems. Our method shows great potential for preventing regressions in
system behavior for software changes.

Keywords: Cyber-Physical Systems · Software Behavior · State Ma-
chines · Behavioral Comparison · Change Impact Analysis

1

Introduction

Software-intensive systems, e.g., cyber-physical systems, become more and more
complex. They often employ a component-based software architecture to manage
their complexity. Over the years such systems continuously evolve by adding new
features and addressing defects, more and more layers are built on top of each
other [10], and components that are not well-maintained become legacy [12,18].
Changing the software is often considered risky as any change can potentially
break a system. If a software change leads to a system defect, then the impact
can be tremendous due to system downtime and productivity loss [18]. This may

(cid:63) This research is carried out as part of the Transposition project under the responsibil-
ity of ESI (TNO) in co-operation with ASML. The research activities are supported
by the Netherlands Ministry of Economic Aﬀairs and TKI-HTSM.

 
 
 
 
 
 
even lead to software engineers becoming afraid to make changes for which they
can’t properly foresee the impact on (other parts of) the system.

To reduce the risks, it is essential to understand the impact of software
changes. However, for large complex industrial code bases consisting of tens of
millions of lines of code, no single person has the complete overview. This makes
it diﬃcult to understand the impact of software changes on the overall system
functionality [4]. This is especially true when the system can behave diﬀerently
for diﬀerent conﬁgurations and usage scenarios [28].

It is thus important that: 1) software developers understand how the system
currently behaves for diﬀerent conﬁgurations and usage scenarios, and 2) they
understand how software changes impact that system behavior.

To address these needs, in this paper we introduce a novel multi-level method-
ology for behavioral comparison of (large) software-intensive systems. The power
of our methodology is that it quickly guides users to relevant diﬀerences. This
avoids the laborious and error-prone practice of looking into many thousands of
lines of code, or plough through gigabytes of execution logs. Our method is fully
automated, making it possible to consider huge (sub-)systems, for which due to
their sheer size it is practically impossible to compare their behavior manually.
Our methodology is based on comparing state machine models rather than
source code or execution logs, which makes it generally applicable. State ma-
chines can compactly and intuitively represent system behavior as a collection
of software function calls and the order in which they are called. Such models
are general and can be obtained by any means of model learning or construction.
Methods to compare state machines can be divided into two classes that
complement each other [27]. Language-based methods compare state machines in
terms of their allowed sequences of function calls, while structure-based methods
compare them in terms of their states and transitions.

However, two important things are missing in literature: 1) a single auto-
mated method integrating these individual methods to allow large-scale indus-
trial application, and 2) an approach to inspect the resulting diﬀerences at vari-
ous levels of detail, and step by step zoom in on relevant diﬀerences, to manage
the complexity of huge systems. Our methodology tackles both these challenges.
Our methodology takes any number of sets of state machines representing
software behavior of, e.g., diﬀerent software versions, diﬀerent conﬁgurations or
diﬀerent usage scenarios. We automatically compare the provided sets by com-
paring the languages and structures of their state-machine models. The com-
parison results can be inspected at six levels of abstraction, ranging from very
high-level diﬀerences to very detailed ones. Users are guided through the diﬀer-
ences in a step by step fashion tailored to allow them to zoom in on relevant
behavioral diﬀerences, wasting no time on irrelevant ones.

We empirically evaluate the practical potential of our methodology through a
qualitative exploratory ﬁeld study [17,22]. Using multiple case studies at ASML,
a leading company in developing lithography systems, we demonstrate that our
approach can be applied to large industrial (sub-)systems, provides developers

and architects insight into their behavioral diﬀerences, and allows them to ﬁnd
unintended regressions. The company wants to broadly adopt our work.

The remainder of this paper is organized as follows. In Section 2 we introduce
the concepts, deﬁnitions and methods on which we build our methodology. Sec-
tion 3 introduces our methodology, both conceptually and formally. We evaluate
our methodology in Section 4, before concluding in Section 5.

2 Background

2.1 Software Behavior

Programming languages typically have a notion of function, procedure or method.
The behavior of software implemented in such languages can then be seen as all
the calls to or invocations of these functions, and the constraints on the order
in which they may be called.

Large systems often employ a component-based software architecture to man-
age their complexity. The many components are independent units of develop-
ment and deployment, encapsulate functionality and allow for re-use [13,23,26].
Functions may then be called internally within a component and to communicate
between components connected via interfaces, e.g., remote procedure calls.

2.2 State Machines

We consider software behavior in terms of sequences of discrete events, e.g., the
start and end of function calls. We deﬁne an alphabet Σ to be a ﬁnite set of
events of interest. A trace t ∈ Σ∗ represents a single ﬁnite execution, with ∗
the Kleene star. The length of t is denoted by |t| and its i-th event by ti for
1 ≤ i ≤ |t|. An execution log is a set of observed traces, and can for instance be
obtained by explicit logging or through sniﬃng tools.

A state machine or automaton compactly and intuitively represents multi-
ple executions. We deﬁne a Non-deterministic Finite Automaton (NFA) A =
(S, Σ, ∆, I, F ) as a 5-tuple, with S a ﬁnite set of states, Σ a ﬁnite set of events
(the alphabet), ∆ ⊆ S × Σ × S a set of transitions, I ⊆ S a set of initial states,
and F ⊆ S a set of accepting states. Deterministic Finite Automata (DFAs) are
a sub-class of NFAs allowing for each source state and event only a single target
state. An NFA can be determinized to a DFA [24].

A trace t ∈ Σ∗ is accepted by an NFA A = (S, Σ, ∆, I, F ) iﬀ there exists a
sequence (s0, t1, s1), (s1, t2, s2), ... , (s|t|−1, t|t|, s|t|) ∈ ∆∗ with s0 ∈ I and s|t| ∈ F .
Traces that are not accepted are rejected. The language L(A) of an NFA A is the
set of all its accepted traces, i.e., L(A) = {t ∈ Σ∗ | A accepts t}. The behavior
presence predicate B(A) indicates whether A has any behavior, i.e., B(A) =
(L(A) (cid:54)= ∅). State machines can be minimized to a representation with the least
number of states possible, while still accepting the same language [7,15]. Given
two NFAs A1 and A2, union and intersection are deﬁned as operations that
reﬂect the eﬀect on their resulting languages, i.e., L(A1 ∪ A2) = L(A1) ∪ L(A2)
and L(A1 ∩ A2) = L(A1) ∩ L(A2), respectively [19].

A (minimal) state machine can be obtained from an execution log through
model learning, e.g., using state machine learning algorithms [3,5,11,6] or through
active automata learning [5,8]. Their details are beyond the scope of this paper.

2.3 State Machine Comparison

There are various ways to compare state machines. Walkinshaw et al. diﬀerenti-
ate two perspectives: language-based and structure-based comparisons [27].

The language perspective considers to which extend the languages of state
machines overlap. Two state machines A1, A2 are language equivalent (=L) iﬀ
they accept exactly the same language, i.e., A1 =L A2 ⇔ L(A1) = L(A2). A
state machine A1 is related by language inclusion (≤L) to state machine A2 iﬀ
the language of A1 is included in that of A2, i.e., A1 ≤L A2 ⇔ L(A1) ⊆ L(A2).
Various other types of well-known binary equivalence and inclusion relations
exist [25], as well as non-binary ones such as precision and recall [20,27]. We
use language equivalence and inclusion as these are commonly used in automata
theory, are suﬃcient to capture the order of function calls, and can be easily ex-
plained even to engineers without a formal background. For ﬁnite state machines
these relations can be computed on their ﬁnite structures [2].

Language-based comparison considers the externally observable behavior of
state machines. Complementary to it, structure-based comparison considers the
overlap of their internal representations in terms of states and transitions.

Walkinshaw et al. deﬁne the LTSDiﬀ algorithm [27] that takes two state
machines and computes a diﬀ state machine: a compact representation of their
diﬀerences. An example is shown in Figure 1. A diﬀ state machine is a regular
state machine with its states and transitions annotated to represent diﬀerence
information, i.e. ‘unchanged’ (black), ‘added’ (green) and ‘removed’ (red).

The algorithm has three steps: 1) Compute similarity scores for all possible
pair-wise combinations of states from the two NFAs being compared. A local
score considers only the overlap in directly connected incoming and outgoing
transitions of the states. It is extended to a global score by recursively considering
all context, using an attenuation factor to ensure closer-by context counts more
towards the score than further away context. 2) Use the scores to heuristically
compute a matching between states of the two NFAs based on landmarks, a
percentage of the highest scoring pairs that score at least some factor better
than any other pairs, with a fallback to the initial states. The most obviously
equivalent state pairs are matched ﬁrst and these are then used to match the
surrounding areas, rejecting any remaining conﬂicting state pairs. The next-best
remaining state pair is then selected and matched, etc, until no state pairs are
left to consider. 3) Use the matching to compute the diﬀ state machine.

The LTSDiﬀ algorithm has the advantage that it does not require states to be
reachable from initial states, does not require state machines to be deterministic

d

a

c

b

a

e

x

b

d

a

e

c

b

(a) Source NFA

(b) Target NFA

(c) Diﬀ NFA

Fig. 1. Source and target NFAs and their structural diﬀerences as a diﬀ NFA.

or minimal, does not rely on state labels, and that it produces relatively small
diﬀs in practice, unlike some other approaches [21,14,16,9].

For a more extensive overview of alternative approaches to compare the lan-
guage and structure of state machines, see the work of Walkinshaw et al. [27].

3 Behavioral Comparison Methodology

The language and structure-based state machine comparison approaches are
complementary. However, to the best of our knowledge there is no work that
fully exploits the complementary nature of these approaches, to provide intu-
itive insights into the behavioral impact of changes for industrial-scale software-
intensive systems. Our methodology takes advantage of their complementary
nature in a novel way, to allow handling the complexity of such scale.

As input our methodology takes any number of model sets representing, e.g.,
diﬀerent software versions, conﬁgurations or usage scenarios. They contain state
machines that represent behaviors of a number of entities representing, e.g., soft-
ware functions or components. Formally, let E be a ﬁnite set of (behavioral) en-
tities and N the set of all NFAs. A model set S ∈ E → N is a complete mapping
of entities to models (NFAs). An incomplete mapping can be made complete us-
ing (∅, ∅, ∅, ∅, ∅) as NFA for unmapped entities. As input our methodology takes
a ﬁnite entities set E and a ﬁnite set of model sets S = {S1, ..., Sn} ⊆ E → N .
Figure 2 shows the model sets that we use as a running example. For model
set S4 (e.g., conﬁguration 4) there is no model for entity E4 (e.g., function 4).
If these models were obtained through model learning on execution logs, no
behavior was observed for function 4 using conﬁguration 4.

Our methodology compares the states machines of all input model sets. The
results are represented at six levels of abstraction (Figure 3). The ﬁrst three

S1

S2

S3

S4

E1

E2

E3

E4

b

c

d

a

d

b

c

b

f

e

f

a

d

b

c

e

e

b

c

f

f

d

e

b

f

a

d

b

d

b

c

c

a

b

f

e

f

a

d

b

d

b

c

e

c

c

a

b

f

Fig. 2. The input state machines for the running example, for entities E1 through E4
(rows) and model sets S1 through S4 (columns). S4(E4) = (∅, ∅, ∅, ∅, ∅).

Model sets

Level 1
Variants

Level 2
Variant
relations

Level 3
Variant
diﬀerences

Level 4
Variants

Models

Level 5
Variant
relations

Level 6
Variant
diﬀerences

L

L

L

L

L / S

S

Fig. 3. Methodology overview: six levels of detail to inspect comparison results.

levels focus on model sets and the last three on individual (models of) entities
within them. For both model sets and models, the ﬁrst level considers diﬀerent
behavioral variants, the second level relates the variants, and the third level
elaborates on variant diﬀerences. Users are guided step by step through the
levels, by gradually zooming in to more detail, letting them focus on relevant
diﬀerences. Levels 1 – 5 contain information from the language perspective (L),
while levels 5 and 6 contain information from the structural perspective (S).
Next, we further elaborate on each of the six levels.

3.1 Level 1: Model Set Variants

Level 1 provides the highest level overview. It shows whether model sets have the
same behavior, i.e., their entity models are language equivalent. Two model sets
Si, Sj ∈ S have the same behavior, denoted Si =L Sj, iﬀ ∀e∈E Si(e) =L Sj(e).

We compare model sets against each other and determine unique model set
behavior variants. Variants are formally deﬁned to be equivalence classes of S
under =L, so that S/=L is the set of all variants. For presentational clarity we
enumerate and refer to diﬀerent variants of S in alphabetical order: A, B, etc.
We choose a structural representative for each behavioral equivalence class.

Figure 4a shows the level 1 result for our running example. Model sets S1
and S2 have the same behavior for all four functions and thus get variant A,
even though their models for E4 are structurally diﬀerent. Model sets S3 and S4
get variants B and C as they diﬀer from the other model sets (and each other).
Level 1 thus provides a very high level overview of which model sets have
the same or diﬀerent behavior, and how few or many variants there are. We can
see whether this matches our expectations. Depending on the use case, we may
be satisﬁed already after looking at these results. For instance, if we want to
know whether diﬀerent conﬁgurations have the same behavior, and if they all
have the same variant, we can already conclude that there are no diﬀerences in
their behavior. If we do go to the other levels, we can ignore model set S2 as
it has the same behavior as S1. In fact, from the language perspective we can
focus on (representatives of) model set variants, each representing one or more
models with the same behavior, rather than on individual model sets. Finally,
in Figure 4a variants are colored using shades of blue like a heat map. In case of
many model sets this may reveal patterns, as we will see in Section 4.

3.2 Level 2: Model Set Variant Relations

Level 1 provides us with model set variants that each have diﬀerent behavior.
Level 2 provides more details. It considers whether the behavior of one model

G (4)

˜1
E (4)

˜2
A (4)

˜1
˜2
D (4)

B (4)

˜1
I (4)
˜1

+1

H (3)

+1
C (3)
˜1

˜1

S1 A
S2 A
S3 B
S4 C

(a) Level 1

S1 S2 S3 S4
E1 A A A A
E2 A A B C
E3 A A B B
E4 A A A −

+1

˜2

F (3)

(b) Level 2

F (13)

+3

E (10)

D (2)

+7 -1
B (4)

+2

+7 -1
A (4)

+2

+8 -1
C (6)

+2

2
= 2

S1 S2 S3 S4
3
3
= 2
=

S1 = 0
S2
S3
S4

(c) Level 3

b

d

c

e

c

(d) Level 4

(e) Level 5 (E2)

(f) Level 6 (B → C)

Fig. 4. Behavioral comparison methodology output for the running example: complete
levels 1 – 4, level 5 for E2, and level 6 for E2 variants B → C.

set variant is completely included in the behavior of another variant, i.e., it
has less behavior. Formally, for two model sets Si, Sj ∈ S, Si is related to Sj
by language inclusion, denoted Si ≤L Sj, iﬀ ∀e∈E Si(e) ≤L Sj(e). Given that
all model set variants have diﬀerent behavior, Si thus has less behavior for at
least one entity. Partially ordered set (S/=L, ≤L) can be extended into a ﬁnite
lattice by computing unions (as supremum) and intersections (as inﬁmum) of
representatives of model set variants until a ﬁxed point is reached. The union or
intersection of two model sets constitutes the per-entity pairwise combination of
their entity models, using state machine union or intersection, respectively.

Figure 4b shows the level 2 lattice for our running example. The variants
from level 1 are indicated by ellipses containing the variant and number of
entity models that have behavior. The extra variants computed to complete
the lattice are indicated by diamonds. Arrows indicate inclusion relations, e.g.,
the behavior of variant D is included in that of variants A and B (and E, I
and G, by transitivity). The arrows are labeled with the number of entities
with diﬀerent present behavior (e.g., ˜1) and the number of entities with newly
present behavior (e.g., +1). Formally, for model set variants Si, Sj and Si ≤L Sj,
these are computed by |{e ∈ E | B(Si(e)) ∧ B(Sj(e)) ∧ Si(e) (cid:54)=L Sj(e)}| and
|{e ∈ E | ¬B(Si(e)) ∧ B(Sj(e))}|, respectively.

Level 2 provides information on which variants have more or less behavior
than other variants, whether variants are closely related (direct arrow) or less
closely related (via several arrows), and it has quantitative information on the

models within the model sets by means of the labels on the arrows. As for level 1,
we can check whether this conforms to our expectations, or not. For instance, if
we compare two software versions and we only added new functionality (e.g., new
entities), we would reasonably expect the behavior of the old software version to
be included in that of the new software version, and we can check whether that
is indeed the case. If this is all that we want to know, we can stop here and we
don’t need to proceed to level 3.

3.3 Level 3: Model Set Variant Diﬀerences

Level 2 shows us the quantitative diﬀerences between model sets via the arrow
labels. However, some model set variants are not directly related by an inclusion
arrow (e.g., variants A and B). The number of entities with diﬀerent behavior
between them can’t be determined from the lattice, as simply summing labels
(e.g., ˜1, +1) could count the same entity multiple times. Level 3 provides more
details, showing the number of entities with diﬀerent behavior between all input
model sets. That is, for model sets Si, Sj ∈ S it shows |{e ∈ E | Si(e) (cid:54)=L Sj(e)}|.
Figure 4c shows the level 3 matrix for our running example. Rows and
columns are labeled with the input model sets. Cells indicate the number of
entities with diﬀerent behavior. As language (in)equality is a symmetric and re-
ﬂexive relation, only the upper-right part of the matrix is ﬁlled, and the diagonal
is labeled with ‘=’ symbols. As expected, model sets S1 and S2 have zero entities
with diﬀerent behavior, as they have the same model set variant. Model sets S1
(variant A) and S4 (variant C) have three entities with diﬀerent behavior.

Level 3 provides more detailed quantitative information. It shows not just
whether model sets are diﬀerent, and how many model sets have diﬀerences, but
also how diﬀerent they are. The diagonal is colored gray as it is not relevant.
Numbered cells are colored like a heat map based on a gradient from green
(no entities with diﬀerences) via yellow and orange to red (most entities with
diﬀerences). In case of many model sets this may again reveal patterns, as we
will see in Section 4. Similarly to the previous levels, we can check whether all
information matches our expectations, and whether we want to proceed to level
4, or not.

3.4 Level 4: Model Variants

Levels 1 – 3 focus on model sets. Level 4 zooms in even further and considers the
(entity) models within the model sets. Similar to how level 1 identiﬁes model set
variants, level 4 identiﬁes model variants for each entity. Formally, for an entity
e ∈ E, let Se = {S(e) | S ∈ S}. We consider equivalence classes Se/=L for each
e ∈ E and enumerate and represent them in alphabetical order: A, B, etc. Note
that variants are determined per entity and thus variant A of one entity does
not necessarily have the same behavior as variant A of another entity.

Figure 4d shows the level 4 matrix for our running example. The cells indicate
the behavior variant of the model for the corresponding entity (row) in the
corresponding model set (column).

Level 4 is the ﬁrst level to provide details on which entities diﬀer between
model sets. This provides a high level overview of the behavior variants for entity

models, similar to how level 1 provides it for model sets. We can see the variants,
how many there are, for which models sets, and whether this is expected or not.
Depending on the use case, we may again stop at this level if it answers our
questions, e.g., in case of checking for regressions if each entity has only a single
behavior variant. Otherwise, we can reduce the number of entities to consider for
subsequent levels, e.g., skip the ones without regressions (only a single variant,
no diﬀerences). Furthermore, we may then focus only on unique entity model
variants instead of all individual entity models. Finally, the matrix cells are
again colored using shades of blue like a heat map. Models without behavior are
indicated as a red cell labeled ‘−’ to make them stand out. Here too, in case of
many model sets this may reveal patterns, as we will see in Section 4.

3.5 Level 5: Model Variant Relations

Level 5 shows relations between entity model variants of level 4, similar to how
level 2 shows relations between model set variants of level 1. Formally, for an
entity e ∈ E we have a partially ordered set (Se/=L, ≤L), which we extend to a
ﬁnite lattice using unions and intersections, similar to level 2.

Figure 4e shows the level 5 lattice for our running example, for entity E2.
We use a representative model for each entity model variant (set of equivalent
models). The node shapes and arrows are as in level 2. The node labels now
indicate the number of transitions of the model, and the arrow labels indicate
the number of added (e.g., +7) and removed transitions (e.g., -1). These are based
on the structural comparison that we use and will explain further for level 6. In
our example, the behavior of variant B is included in the behavior of variant C.
Level 5 provides information on which entity model variants have more or less
behavior, how closely they are related, and the amount of changes between them.
As for previous levels, we can check whether this conforms to our expectations,
or not. We can also use it to decide what to inspect in more detail in level 6.

3.6 Level 6: Model Variant Diﬀerences

Level 6 is the last level. It shows all structural diﬀerences between two entity
model variants of level 5 as a diﬀ NFA, computed with the LTSDiﬀ algorithm.
Figure 4f shows the level 6 diﬀ NFA for our running example, for variants B
and C of entity E2. Variant C (from model set S4) has two extra transitions in
its state machine, and this is clearly visible as two green arrows in this ﬁgure.

Level 6 provides the most detailed behavioral diﬀerences. Diﬀ NFAs show
diﬀerences in terms of states and transitions within models. As with the other
levels, we can check whether this matches our expectations, or not.

4 Evaluation

We perform an empirical evaluation of our methodology through an exploratory
ﬁeld study [17,22]. To gain some ﬁrst evidence of both its practical potential and
its ability to handle large systems, we perform three case studies at ASML. The
ﬁrst two case studies provide some preliminary evidence of our methodology’s
practical value, by showing the beneﬁts of all six of its levels, as well as ﬁnding a

regression. The third case study shows that our methodology can be applied to a
large industrial system, providing insights into its behavior. We have completely
automated our approach, in a (for now) company-internal prototype tool.

ASML develops photolithography systems for the semiconductor industry.
These systems process wafers (thin circular slices of silicon) in batches (lots).
Multiple circuits (dies) are produced on a single wafer. After the wafer’s height
proﬁle is measured, a light source exposes the chip pattern onto a wafer through
a projection mask (a reticle). A reticle may contain a full-sized pattern (full
ﬁeld ) or a smaller one (narrow ﬁeld ). Computational lithography software uses
the measurements to compensate for nano-scale imperfections during exposure.
In this section the start of function call f is denoted as f ↑ and its end as f ↓.

4.1 Case Study 1: Legacy Component Technology Migration

For the ﬁrst case study, we look at a relatively small computational lithography
component, developed and maintained by two engineers. It is internally imple-
mented using legacy end-of-life technology and is migrated to new technology,
without changes to its external interface. The engineers thus expect to see the
same external behavior in communications with the other components, and we
apply our approach to see whether this is indeed the case.

We observe six executions, using three diﬀerent test sets for both the legacy
and new implementations. The integration test set contains integration tests.
The overruling and veriﬁcation test sets both test diﬀerent conﬁguration options
and functionality of the component. Each test set contains multiple tests. For
reasons of conﬁdentially we do not explain the test sets in more detail.

For each observed execution, we obtain an execution log capturing the com-
ponent’s runtime communications with other components. The log for each ex-
ecution is split into separate logs for each of the functions in the component’s
external interface. We use model learning [6] to obtain six model sets (one for
each execution), with 11 interface functions of the component as entities. The
model sets together contain 46 models with behavior, with 2 to 578 states per
model, and a sum total of 1,330 states.

We discuss the results of applying our approach, per level.

Level 1 (Figure 5a): Only for integration there are diﬀerences in behavior
between the legacy and new implementations. As the other two test sets show no
diﬀerences, they do not need further inspection. Given that we then have only
two model sets left, we skip levels 2 and 3, and proceed directly to level 4.

Level 4 (Figure 5b): We see the 11 functions, anonymized for conﬁdentiality
reasons, and their behavioral variants. Only 6 out of 11 entities show diﬀerences
in behavior, to be inspected in more detail. Given that they all have only two
variants per entity, we skip level 5 and proceed directly to level 6.

Level 6 (Figures 5c and 5d): Figure 5c shows the diﬀ NFA for function
‘apply’ (abbreviated to ‘a’), for variant A to variant B. The ﬁgure shows that
the new implementation involves only the start and end of this function. The
legacy implementation has more behavior, as within the ‘apply’ function it has
30 calls (with returns) to a ‘log’ function. In the ﬁgure, only the ﬁrst and last

legacy new

apply A
ﬁnalize A
get status1 A
get status2 A
initialize1 A
initialize2 A
model A
prepare A
set context A
terminate1 A
terminate2 A

B
B
A
A
B
A
B
B
A
B
A

a↓

a↑

a↓

log↑

log↓

p↑

[8]

log↓

log↑

[56]

[4]

p↓

[64]

x↓

x↓

p↑

[14]
x↑

(b) Level 4
(integration)

(c) Level 6
(apply, A → B)

(d) Level 6
(prepare, A → B)

integration legacy A
integration new
B
overruling legacy C
overruling new
C
veriﬁcation legacy D
veriﬁcation new
D

(a) Level 1

Fig. 5. First results for case study 1: complete level 1, level 4 for the integration test
set, and level 6 with variants A vs B for functions ‘apply’ and ‘prepare’.

of these calls (with their returns) are shown, and the remaining sequence of
56 transitions, representing 28 calls and their returns, is abbreviated to ‘[56]’.
Figure 5d shows the diﬀ NFA for function ‘prepare’ (abbreviated to ‘p’), for
variant A to variant B. For reasons of conﬁdentiality and presentational clarity
again several sequences of transitions are abbreviated. Here, the ﬁgure shows that
the legacy implementation invokes the ‘log’ function 4 and 32 times, indicated
as ‘[8]’ and ‘[64]’, respectively, while the new implementation does not.

Having inspected the diﬀerences for only two entities, it appears that all ‘log’
function calls are missing in the new implementation. The component engineers
conﬁrmed that indeed for the new implementation the component was not yet
hooked up to the logging framework. Our approach clearly shows this regression.
To look for other diﬀerences in behavior, we remove all ‘log’ function calls
and returns from the models of the legacy implementation. To do so, we rename
all ‘log’ function call and return events to ε and apply weak-language normal-
ization [19]. We then apply our approach again.

Level 1 (Figure 6): Looking at the new results for level 1, we immediately
see that there are no more observed diﬀerences in behavior for the legacy and
new implementations, for all three test sets. We don’t see any further regressions
in behavior, and we don’t have to go to further levels.

Given that this component has quite a good test
set with adequate coverage, our approach is applied
as an extra safety net that complements traditional
testing, akin to diﬀerential testing [4]. As any change
in the (order of) communications with other compo-
nents will show up in our models and comparisons,
it is like having assertions for all external commu-
nications. Both engineers ﬁnd this valuable. They
would like to apply our methodology also for larger
and more complex technology migrations, where they
foresee even more value.

integration legacy A
integration new
A
overruling legacy B
B
overruling new
veriﬁcation legacy C
C
veriﬁcation new

Fig. 6. New results
case study 1: level 1.

for

4.2 Case Study 2: Test Coverage

The second case study considers again the same component and three test sets
from the ﬁrst case study, but from a diﬀerence angle. Instead of comparing the
legacy and new implementation, we compare the three test sets against each
other. The goal is to see how the behaviors of the diﬀerent test sets diﬀer, and
whether one or more test sets are perhaps superﬂuous. We use the versions of
the input models from the ﬁrst case study where the ‘log’ function is completely
removed. We discuss the results of applying our methodology, per level:

Level 1 (Figure 7a): The three tests sets have diﬀerent behavior (A – C).
Level 2 (Figure 7b): The integration test set (variant A) has behavior for
all 11 functions, and the other two test sets (B, C) for 5 fewer functions, i.e., 6
functions. Also, integration (A) includes all the behavior of the other two test
sets, while veriﬁcation (C) diﬀers from overruling (B) by only one function. As
all variants are (transitively) related in the lattice, we skip level 3.

Level 4 (Figure 7c): We clearly see which 5 functions are only used during
the integration tests. The component engineers expect this diﬀerence, as for
overruling and veriﬁcation these 5 functions are stubbed internally and are thus
not externally visible. Also, for the veriﬁcation tests only the ‘model’ function
has diﬀerent behavior. We inspect this further in level 5.

Level 5 (Figure 7d): The behavior of the ‘model’ function for variant B
(veriﬁcation) is included in that of variant A (integration and overruling), which
has one additional transition. We inspect this further in level 6.

Level 6 (Figure 7e): Here we see the diﬀ NFA for function ‘model’ (abbrevi-
ated to ‘m’), for variant B to variant A, following the arrow in the level 5 lattice.
For conﬁdentiality and presentational clarity we annotate other arrows with [n]
to abbreviate n transitions in sequence. The one extra transition of function
variant A is clearly visible. There it is possible to return to the initial state ear-
lier on, skipping part of the behavior of the state machine. The engineers again
expect this, as some functionality is not activated depending on the component
conﬁguration.

n
r

e

g

r

r

t

t i o
a
e
v
o
A
A

i n
apply A
ﬁnalize A

u li n
e
v
A
A
get status1 A − −
A
get status2 A
initialize1 A − −
initialize2 A − −
B
model A
A
prepare A
set context A
A
terminate1 A − −
terminate2 A − −

A
A
A

A

A (11)

+5

B (6)

˜1
C (6)

integration A
overruling B
veriﬁcation C

(a) Level 1

(b) Level 2

(c) Level 4

n

t i o

g
r i ﬁ

a

c

m↑

m↓

[8]

[14]

m↓

A (45)

+1

B (44)

[8]

[2]

[4]

[4]

[2]

(d) Level 5
(model)

(e) Level 6
(model, B → A)

Fig. 7. Results for case study 2: complete levels 1, 2 and 4, level 5 for function ‘model’,
and level 6 for function ‘model’ variants B vs A.

The comparison results suggest that since the integration test set covers more
behavior than the other two test sets, those other two test sets can be removed.
This would be a valid conclusion, if one only considers function call order, as
we do for our methodology. However, functions could have diﬀerent behavior
for diﬀerent arguments. If this results in a diﬀerence in which functions are
called or in what order they are called, then our approach will highlight such
diﬀerences. If however for diﬀerent conﬁgurations there are diﬀerences in which
paths though a state machine are taken for which argument values, while each
path is still taken for some argument value, this would not be visible with our
current approach. The diﬀerent test sets that we consider do indeed test diﬀerent
conﬁgurations using diﬀerent argument values, and hence they do add value and
can not simply be removed. Fully taking the inﬂuence of argument values into
account is considered future work.

In any regard, our methodology provides insight into the behavioral diﬀer-
ences for the various conﬁgurations and functional scenarios considered by the
diﬀerent test sets. This can be automatically obtained even by engineers who
are not domain experts.

4.3 Case Study 3: System Behavior Matching Recipe

For the third case study, we investigate how recipes containing information on
the number of wafers and used reticles relate to the system behavior. ASML’s
customers can specify their own recipes to conﬁgure their lithography systems
for their purposes, e.g., to create CPU or memory chips. The software running on
the systems will exhibit diﬀerent behavior for diﬀerent recipes, and thus software
behavior is a lens to look at system behavior.

Figure 8 shows the recipes that we consider for this case study. For reasons
of conﬁdentially, we don’t explain the origin of these recipes and we consider
only the details relevant for this case study. There are six lots, each with their
own recipe. Lots 1 and 2 have ﬁve wafers each and the other lots have 15 wafers
each. There are two reticles, X and Y. For lot 1, reticle X is used 96 times, one
for each die. Lot 5 uses both reticles. Exposure can be done using full ﬁeld or
narrow ﬁeld, where narrow ﬁeld leads to more exposures (125 rather than 96).
We consider the behavior of the exposure sub-system, i.e., 32 software com-
ponents involved in the high-level exposure control. Observing the system exe-
cution for about an hour as it initializes and processes lots, we obtain a single
execution log capturing all observed inter-component communications. This log
is split into multiple logs, one for each of the 85 exposures (one per wafer and for

Wafers
Reticle
Field

Lot 1
5
96*X
Full

Lot 2
5
96*Y
Full

Lot 3
15
96*X
Full

Lot 4
15
96*Y
Full

Lot 5
15
124*X, 1*Y
Narrow

Lot 6
15
125*X
Narrow

Fig. 8. Case study 3: recipes for the diﬀerent lots.

104

103

102

101

s
e
t
a
t
s

f
o

r
e
b
m
u
N

100

1

500

1,000

1,500

2,000

2,386

Input models (sorted by number of states)

Fig. 9. Case study 3: sizes of the input models with behavior.

lot 5 twice per wafer as it uses two reticles). The exposure logs are further split
into separate logs for each of the components, containing only their interactions
with the other components. We use model learning [6] to obtain 85 model sets
(one per exposure), containing models of the 32 components (entities). Model
sets may lack a certain component model if that component did not interact
with other components during the corresponding exposure. Figure 9 shows the
sizes of the input models in number of states. The 85 model sets together contain
2,386 models with behavior, with 2 to 7,070 states per model, and a sum total
of 495,505 states, making this a large case study.

We apply our methodology and discuss the results level by level, skipping

levels 2 and 5 as they are less relevant for this case study.

1-1 A
1-2 B
1-3 B
1-4 B
1-5 B

2-1 A
2-2 B
2-3 B
2-4 C
2-5 B

3-1 A
3-2 B
3-3 B
3-4 B
3-5 B
3-6 B
3-7 B
3-8 B
3-9 B
3-10 B
3-11 C
3-12 B
3-13 B
3-14 B
3-15 B

4-1 D
4-2 B
4-3 B
4-4 B
4-5 B
4-6 B
4-7 B
4-8 B
4-9 B
4-10 B
4-11 B
4-12 B
4-13 E
4-14 B
4-15 B

5-1A F
5-1B G
5-2B H
5-2A I
5-3A J
5-3B G
5-4B H
5-4A I
5-5A J
5-5B G
5-6B H
5-6A I
5-7A K
5-7B G
5-8B H
5-8A I

5-9A K
5-9B G
5-10B H
5-10A I
5-11A K
5-11B G
5-12B H
5-12A I
5-13A K
5-13B L
5-14B H
5-14A I
5-15A K
5-15B L

6-1 M
6-2 N
6-3 N
6-4 N
6-5 N
6-6 N
6-7 N
6-8 N
6-9 O
6-10 N
6-11 N
6-12 N
6-13 N
6-14 N
6-15 O

Fig. 10. Results for case study 3: level 1.

Level 1 (Figure 10): We discuss multiple observations based on patterns
that are visible in level 1. Diﬀerent gradient colors are used for presentational
clarity.

a) First exposure of a lot: For lots 1 – 4, the main behavior variant is variant B.
The ﬁrst exposures of these lots however all have diﬀerent behavior (A, D).
b) Changes during a lot: For lots 2 – 4 we also see diﬀerent behavior for some

exposures later during the lot (C, E).

c) Reticle swaps: All exposures of lots 5 (F – L) have behavior diﬀerent than the
other lots (A – E, M – O). Lot 5 is the only lot where two reticles are used
per wafer, and thus reticles must be swapped regularly. To minimize the
number of swaps, the system uses an ‘XYYX’ pattern for every two wafers
(ﬁrst wafer reticle ‘X’, ﬁrst wafer reticle ‘Y’, second wafer reticle ‘Y’, second
wafer reticle ‘X’). These patterns of four exposures are clearly visible in the
model set variants (J – G – H – I, K – G – H – I).

d) Full ﬁeld vs narrow ﬁeld : The diﬀerence between lots 1 and 3 compared to
lot 6 is the use of full vs narrow ﬁeld. The behavior for lots 1 and 3 (A – C)
and lot 6 (M – O) diﬀer, but they have similar structure (mostly the same
variant, ﬁrst exposure and some exposures during the lot are diﬀerent).

Level 3 (Figure 11): We elaborate on each of the four observations using the

results for level 3.

a) First exposure of a lot: For lots 1 – 4, we mainly see regular behavior (dark
green, 0 components with diﬀerent behavior). For the ﬁrst exposures of these
lots we do see diﬀerences (yellow lines, mainly 2 or 3 components).

b) Changes during a lot: For lots 2 – 4 we again see diﬀerences for some ex-
posures later during the lot (light green and yellow lines, mainly 1 or 2
components).

c) Reticle swaps: The reticle swaps are again very much visible for lot 5 (vertical

orange, red and light green lines in a repeating pattern of 4 columns).
d) Full ﬁeld vs narrow ﬁeld : Observe the diﬀerences between thick-border en-
closed areas left and right of the ﬁgure. These full ﬁeld (lots 1 + 3) vs narrow
ﬁeld (lot 6) diﬀerences seem to be caused by a single component.

Level 4 (Figure 12): The observations are detailed even further using the

results for level 4.

a) First exposure of a lot: The diﬀerences in ﬁrst exposures of lots 1 – 4 can be
attributed primarily to components C1 and C21, and for lot 4 also to C28.
b) Changes during a lot: The changes for exposures during lots 2 – 4 can be

attributed to components C4, C9 and C28.

c) Reticle swaps: The reticle swap diﬀerences concern many components. For
several components (e.g., C2, C6, C9) we again see the ‘XYYX’ reticle swap
pattern. For some other components (e.g., C3, C4) we see a ‘VWVW’ pattern
instead, relating to ﬁrst vs second exposure of a wafer.

d) Full ﬁeld vs narrow ﬁeld : Indeed only one component (C9) causes the full
ﬁeld (lots 1 + 3) vs narrow ﬁeld (lot 6) diﬀerences (variants A/B vs G).

1
-
1

2
-
1

3
-
1

4
-
1

5
-
1

1
-
2

2
-
2

3
-
2

4
-
2

5
-
2

1
-
3

2
-
3

3
-
3

4
-
3

5
-
3

6
-
3

7
-
3

8
-
3

9
-
3

0
1
-
3

1
1
-
3

2
1
-
3

3
1
-
3

4
1
-
3

5
1
-
3

1
-
4

2
-
4

3
-
4

4
-
4

5
-
4

6
-
4

7
-
4

8
-
4

9
-
4

0
1
-
4

1
1
-
4

2
1
-
4

3
1
-
4

4
1
-
4

5
1
-
4

X
1
-
5

Y
1
-
5

Y
2
-
5

X
2
-
5

X
3
-
5

Y
3
-
5

Y
4
-
5

X
4
-
5

X
5
-
5

Y
5
-
5

Y
6
-
5

X
6
-
5

X
7
-
5

Y
7
-
5

Y
8
-
5

X
8
-
5

X
9
-
5

Y
9
-
5

Y
0
1
-
5

X
0
1
-
5

X
1
1
-
5

Y
1
1
-
5

Y
2
1
-
5

X
2
1
-
5

X
3
1
-
5

Y
3
1
-
5

Y
4
1
-
5

X
4
1
-
5

X
5
1
-
5

Y
5
1
-
5

1
-
6

2
-
6

3
-
6

4
-
6

5
-
6

6
-
6

7
-
6

8
-
6

9
-
6

0
1
-
6

1
1
-
6

2
1
-
6

3
1
-
6

4
1
-
6

5
1
-
6

= 2 2 2 2 0 2 2 3 2 0 2 2 2 2 2 2 2 2 2 3 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 4 2 2 11 18 25 3 13 18 25 3 13 18 25 3 13 18 25 3 13 18 25 3 13 18 25 3 13 19 25 3 13 19 1 3 3 3 3 3 3 3 4 3 3 3 3 3 4
= 0 0 0 2 0 0 1 0 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 2 0 0 1 0 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 2 0 0 1 0 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 2 0 0 1 0 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 2 2 3 2 0 2 2 2 2 2 2 2 2 2 3 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 4 2 2 11 18 25 3 13 18 25 3 13 18 25 3 13 18 25 3 13 18 25 3 13 18 25 3 13 19 25 3 13 19 1 3 3 3 3 3 3 3 4 3 3 3 3 3 4
= 0 1 0 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 1 0 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 1 3 1 1 1 1 1 1 1 1 1 0 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 3 1 1 14 17 24 2 12 17 24 2 12 17 24 2 12 17 24 2 12 17 24 2 12 17 24 2 12 18 24 2 12 18 4 2 2 2 2 2 2 2 1 2 2 2 2 2 1
= 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 2 2 2 2 2 2 2 2 2 3 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 4 2 2 11 18 25 3 13 18 25 3 13 18 25 3 13 18 25 3 13 18 25 3 13 18 25 3 13 19 25 3 13 19 1 3 3 3 3 3 3 3 4 3 3 3 3 3 4
= 0 0 0 0 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 0 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 1 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 3 1 1 14 17 24 2 12 17 24 2 12 17 24 2 12 17 24 2 12 17 24 2 12 17 24 2 12 18 24 2 12 18 4 2 2 2 2 2 2 2 1 2 2 2 2 2 1
= 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 3 3 3 3 3 3 3 3 3 3 3 5 3 3 12 18 25 4 14 18 25 4 14 18 25 4 14 18 25 4 14 18 25 4 14 18 25 4 14 19 25 4 14 19 2 4 4 4 4 4 4 4 3 4 4 4 4 4 3
= 0 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 0 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 2 0 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 2 2 13 18 24 2 11 18 24 2 11 18 24 2 11 18 24 2 11 18 24 2 11 18 24 2 11 17 24 2 11 17 4 2 2 2 2 2 2 2 3 2 2 2 2 2 3
= 0 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 13 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 17 24 1 11 18 24 1 11 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 25 17 12 3 25 17 12 3 25 17 12 2 25 17 12 2 25 17 12 2 25 17 12 2 25 17 12 2 25 11 13 13 13 13 13 13 13 14 13 13 13 13 13 14
= 10 17 24 0 10 17 24 0 10 17 24 0 10 17 24 0 10 17 24 0 10 17 24 2 10 17 24 2 18 17 17 17 17 17 17 17 17 17 17 17 17 17 17
= 24 16 10 0 24 16 10 0 24 16 10 0 24 16 10 0 24 16 10 0 24 16 11 0 24 16 11 25 24 24 24 24 24 24 24 24 24 24 24 24 24 24
= 11 17 24 0 11 17 24 0 10 17 24 0 10 17 24 0 10 17 24 0 10 18 24 0 10 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 24 16 11 0 24 16 11 1 24 16 11 1 24 16 11 1 24 16 11 1 24 16 11 1 24 13 11 11 11 11 11 11 11 12 11 11 11 11 11 12
= 10 17 24 0 10 17 24 0 10 17 24 0 10 17 24 0 10 17 24 2 10 17 24 2 18 17 17 17 17 17 17 17 17 17 17 17 17 17 17
= 24 16 10 0 24 16 10 0 24 16 10 0 24 16 10 0 24 16 11 0 24 16 11 25 24 24 24 24 24 24 24 24 24 24 24 24 24 24
= 11 17 24 0 10 17 24 0 10 17 24 0 10 17 24 0 10 18 24 0 10 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 24 16 11 1 24 16 11 1 24 16 11 1 24 16 11 1 24 16 11 1 24 13 11 11 11 11 11 11 11 12 11 11 11 11 11 12
= 10 17 24 0 10 17 24 0 10 17 24 0 10 17 24 2 10 17 24 2 18 17 17 17 17 17 17 17 17 17 17 17 17 17 17
= 24 16 10 0 24 16 10 0 24 16 10 0 24 16 11 0 24 16 11 25 24 24 24 24 24 24 24 24 24 24 24 24 24 24
= 10 17 24 0 10 17 24 0 10 17 24 0 10 18 24 0 10 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 24 16 10 0 24 16 10 0 24 16 10 0 24 16 10 0 24 13 11 11 11 11 11 11 11 12 11 11 11 11 11 12
= 10 17 24 0 10 17 24 0 10 17 24 2 10 17 24 2 18 17 17 17 17 17 17 17 17 17 17 17 17 17 17
= 24 16 10 0 24 16 10 0 24 16 11 0 24 16 11 25 24 24 24 24 24 24 24 24 24 24 24 24 24 24
= 10 17 24 0 10 17 24 0 10 18 24 0 10 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 24 16 10 0 24 16 10 0 24 16 10 0 24 13 11 11 11 11 11 11 11 12 11 11 11 11 11 12
= 10 17 24 0 10 17 24 2 10 17 24 2 18 17 17 17 17 17 17 17 17 17 17 17 17 17 17
= 24 16 10 0 24 16 11 0 24 16 11 25 24 24 24 24 24 24 24 24 24 24 24 24 24 24
= 10 17 24 0 10 18 24 0 10 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 24 16 10 0 24 16 10 0 24 13 11 11 11 11 11 11 11 12 11 11 11 11 11 12
= 10 17 24 2 10 17 24 2 18 17 17 17 17 17 17 17 17 17 17 17 17 17 17
= 24 16 11 0 24 16 11 25 24 24 24 24 24 24 24 24 24 24 24 24 24 24
= 10 18 24 0 10 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 24 16 10 0 24 13 11 11 11 11 11 11 11 12 11 11 11 11 11 12
= 11 18 24 0 19 18 18 18 18 18 18 18 18 18 18 18 18 18 18
= 24 16 11 25 24 24 24 24 24 24 24 24 24 24 24 24 24 24
= 10 18 3 1 1 1 1 1 1 1 2 1 1 1 1 1 2
= 24 13 11 11 11 11 11 11 11 12 11 11 11 11 11 12
= 19 18 18 18 18 18 18 18 18 18 18 18 18 18 18
= 2 2 2 2 2 2 2 3 2 2 2 2 2 3
= 0 0 0 0 0 0 1 0 0 0 0 0 1
= 0 0 0 0 0 1 0 0 0 0 0 1
= 0 0 0 0 1 0 0 0 0 0 1
= 0 0 0 1 0 0 0 0 0 1
= 0 0 1 0 0 0 0 0 1
= 0 1 0 0 0 0 0 1
= 1 0 0 0 0 0 1
= 1 1 1 1 1 0
= 0 0 0 0 1
= 0 0 0 1
= 0 0 1
= 0 1
= 1
=

1-1
1-2
1-3
1-4
1-5
2-1
2-2
2-3
2-4
2-5
3-1
3-2
3-3
3-4
3-5
3-6
3-7
3-8
3-9
3-10
3-11
3-12
3-13
3-14
3-15
4-1
4-2
4-3
4-4
4-5
4-6
4-7
4-8
4-9
4-10
4-11
4-12
4-13
4-14
4-15
5-1X
5-1Y
5-2Y
5-2X
5-3X
5-3Y
5-4Y
5-4X
5-5X
5-5Y
5-6Y
5-6X
5-7X
5-7Y
5-8Y
5-8X
5-9X
5-9Y
5-10Y
5-10X
5-11X
5-11Y
5-12Y
5-12X
5-13X
5-13Y
5-14Y
5-14X
5-15X
5-15Y
6-1
6-2
6-3
6-4
6-5
6-6
6-7
6-8
6-9
6-10
6-11
6-12
6-13
6-14
6-15

Fig. 11. Results for case study 3: level 3.

6-15
6-14
6-13
6-12
6-11
6-10
6-9
6-8
6-7
6-6
6-5
6-4
6-3
6-2
6-1
5-15Y
5-15X
5-14X
5-14Y
5-13Y
5-13X
5-12X
5-12Y
5-11Y
5-11X
5-10X
5-10Y
5-9Y
5-9X
5-8X
5-8Y
5-7Y
5-7X
5-6X
5-6Y
5-5Y
5-5X
5-4X
5-4Y
5-3Y
5-3X
5-2X
5-2Y
5-1Y
5-1X
4-15
4-14
4-13
4-12
4-11
4-10
4-9
4-8
4-7
4-6
4-5
4-4
4-3
4-2
4-1
3-15
3-14
3-13
3-12
3-11
3-10
3-9
3-8
3-7
3-6
3-5
3-4
3-3
3-2
3-1
2-5
2-4
2-3
2-2
2-1
1-5
1-4
1-3
1-2
1-1

−
−
−
−
−
−
−
−
−
−
−
−
−
−
A
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
A
−
−
−
−
−
−
−
−
−
−
−
−
−
−
A
−
−
−
−
−
−
−
−
−
−
−
−
−
−
A
−
−
−
−
A
−
−
−
−
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

B

C
A
C

B

C
A
C
A
C
A
C
A
C
A
C
A
C
A
C
A
C
A
C
A
C
A
C
A
C

A
A
B
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

G
G
G
G
G
G
G
G
G
G
G
G
G
G
G

F

C

C
D

F

C

C
D
D
C

C
D
D
C

C
D
D
C

C
D
D
E

C
D
D
E

C
D
D
C

A
A
B
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

1
C

2
C

3
C

4
C

5
C

6
C

7
C

8
C

9
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

C

B
A
B

C

B
A
B

C

B
A
B

C

B
A
B

C

B
A
B

C

B
A
B

C

B
A
B

C

B

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

0
1
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

1
1
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

2
1
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

3
1
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
−
A
A
−
−
A
A
−
−
A
A
−
−
A
A
−
−
A
A
−
−
A
A
−
−
A
A
−
−
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

4
1
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

C

B
A
D
C

B
A
D
C

B
A
D
C

B
A
D
C

B
A
D
C

B
A
D
C

B
A
D
C

B

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

5
1
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

6
1
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

7
1
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

8
1
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

9
1
C

−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−

0
2
C

B

B

B

B

B

B

B

B

B

B

B

B

B

B
A

C

B

B

C

C

B

B

C

C

B

B

C

C

B

B

C

C

B

B

C

C

B

B

C

C

B

B

C

C
A

B

B

B

B

B

B

B

B

B

B

B

B

B

B
A

B

B

B

B

B

B

B

B

B

B

B

B

B

B
A

B

B

B

B
A

B

B

B

B
A

1
2
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

2
2
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
−
A
A
−
−
A
A
−
−
A
A
−
−
A
A
−
−
A
A
−
−
A
A
−
−
A
A
−
−
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

3
2
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

C

B
A
D
C

B
A
D
C

B
A
D
C

B
A
D
C

B
A
D
C

B
A
D
C

B
A
D
C

B

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

4
2
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

5
2
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A
A
B

B
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

6
2
C

−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
A
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−

7
2
C

B
A
A
A
A
A
B
A
A
A
A
A
A
A
A

C
A
A
C

C
A
A
C

C
A
A
C

C
A
A
C

C
A
A
C

C
A
A
C

C
A
A
C

C
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
B

A
A
A
A
B
A
A
A
A
A
A
A
A
A
A

A
B
A
A
A

A
A
A
A
A

8
2
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
−
A
A
−
−
A
A
−
−
A
A
−
−
A
A
−
−
A
A
−
−
A
A
−
−
A
A
−
−
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

9
2
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B
A
B

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

0
3
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

1
3
C

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A
A
A
A
A
A
A
A
A
A
A

A
A
A
A
A

A
A
A
A
A

2
3
C

Fig. 12. Results for case study 3: level 4. The component names have been anonymized
for conﬁdentially reasons.

...

l↑

l↓

l↓

i↑

i↓

q↑

l↑

q↓

q↑

q↓

l↑

l↓

...

l↑

Fig. 13. Results for case study 3: excerpt of level 6 (C21, A → B).

Level 6 (Figure 13): For reasons of conﬁdentiality, we focus only on the
ﬁrst exposure of a lot diﬀerences. We inspect level 6 for variants A and B of
component C21. Figure 13 shows a part of the diﬀ state machine, with ‘l’ a
logging function, ‘i’ a function to get some information, and ‘q’ a query function.
For conﬁdentiality reasons we don’t explain the functions in more detail. The
upper and lower paths indicate that both versions can skip the calls to ‘q’. The
only diﬀerence is that variant A (ﬁrst wafer, in red) calls ‘i’ before calling ‘q’,
while variant B (other wafers, in green) does not. The company’s domain experts
are well aware of such ‘ﬁrst wafer eﬀects’.

The system behavior diﬀers between wafers, and by going through the levels
of our methodology we obtain progressive insights into these behavioral diﬀer-
ences and how they relate to the recipes. This allows engineers to understand
how diﬀerent conﬁgurations inﬂuence the system behavior, e.g., which compo-
nents are aﬀected by reticle swaps or full ﬁeld vs narrow ﬁeld, and in what way
they behave diﬀerently. While the input contains a large number of state ma-
chines, with an even larger number of states, our methodology allows engineers
to step by step zoom in on parts of this behavior, thus making it suitable to
analyze this large system.

Our approach has many potential applications. For instance, understanding
how certain conﬁgurations aﬀect the system behavior is key when changing the
system behavior. Junior engineers can understand the system and its conﬁgu-
rations without having to rely on domain experts. Domain experts can check
whether their mental views conform to reality, and adapt their mental views if
they turn out to be outdated or incomplete. Furthermore, if certain conﬁgura-
tions have no eﬀect at all on the system behavior, they could be removed from
the system to avoid having to consider them when changing the system.

5 Conclusions and Future Work

We contribute a novel multi-level methodology for behavioral comparison of
software-intensive systems. It integrates multiple existing complementary meth-
ods to automatically compare the behavior of state machines. Our methodology
takes advantage of their complementary nature in a novel way, using six levels
with progressive detail to handle the complexity of large industrial systems.

Our qualitative exploratory ﬁeld study suggests that our approach allows one
to inspect the behavioral diﬀerences of large systems, and that it has practical

value for getting insight into system behavior for various conﬁgurations and
scenarios, and preventing regressions. However, a more rigorous and quantitative
evaluation of our methodology is still needed.

Our work is generically applicable as it works on state machines, which are
widely used and understood in both computer science and industry. We plan to
research the generality of our approach by also applying it at other companies
with software-intensive systems that have suitable state machine models [1], and
make the company-internal prototype tool publicly available.

Other future work includes extensions beyond comparing NFAs to consider
also Extended Finite Automata and Timed Automata as input to our approach,
and adding actionable insights beyond merely behavioral diﬀerences to further
support change impact analysis. Our methodology could also be applied to dif-
ferent use cases such as diagnosis of unstable tests and ﬁeld issues.

Acknowledgments The authors would like to thank ASML for making this work
possible and for supporting it.

References

1. Bera, D., Schuts, M., Hooman, J., Kurtev, I.: Reverse Engineering Models of Soft-
ware Interfaces. Computer Science and Information Systems 18(3), 657–686 (2021).
https://doi.org/10.2298/CSIS200131013B

2. Cleaveland, R., Sokolsky, O.: Equivalence and Preorder Checking for Finite-State
Systems. Handbook of Process Algebra pp. 391–424 (2001). https://doi.org/10.
1016/B978-044482830-9/50024-2

3. Gold, E.M.: Language Identiﬁcation in the Limit. Information and control 10(5),

447–474 (1967). https://doi.org/10.1016/S0019-9958(67)91165-5

4. Gulzar, M.A., Zhu, Y., Han, X.: Perception and Practices of Diﬀerential Testing. In:
2019 IEEE/ACM 41st International Conference on Software Engineering: Software
Engineering in Practice (ICSE-SEIP). pp. 71–80. IEEE (2019). https://doi.org/
10.1109/ICSE-SEIP.2019.00016

5. De la Higuera, C.: Grammatical Inference: Learning Automata and Gram-
https://doi.org/10.1017/

(2010).

mars. Cambridge University Press
CBO9781139194655

6. Hooimeijer, B., Geilen, M., Groote, J.F., Hendriks, D., Schiﬀelers, R.: Constructive
Model Inference: Model Learning for Component-Based Software Architectures. In:
International Conference on Software Technologies (2022), to appear

7. Hopcroft, J.: An n log n algorithm for minimizing states in a ﬁnite automaton.
In: Theory of machines and computations, pp. 189–196. Elsevier (1971). https:
//doi.org/10.1016/B978-0-12-417750-5.50022-1

8. Howar, F., Steﬀen, B.: Active Automata Learning in Practice. In: Machine Learn-
ing for Dynamic Software Analysis: Potentials and Limits, pp. 123–148. Springer
(2018). https://doi.org/10.1007/978-3-319-96562-8_5

9. Kelter, U., Schmidt, M.: Comparing state machines. In: Proceedings of the 2008
international workshop on Comparison and versioning of software models. pp. 1–6
(2008). https://doi.org/10.1145/1370152.1370154

10. Klusener, S., Mooij, A., Ketema, J., Van Wezep, H.: Reducing Code Duplication by
Identifying Fresh Domain Abstractions. In: 2018 IEEE International Conference on
Software Maintenance and Evolution (ICSME). pp. 569–578. IEEE (2018). https:
//doi.org/10.1109/ICSME.2018.00020

11. Lang, K.J., Pearlmutter, B.A., Price, R.A.: Results of the Abbadingo One DFA
Learning Competition and a New Evidence Driven State Merging Algorithm. In:
International Colloquium on Grammatical Inference. pp. 1–12. Springer (1998).
https://doi.org/10.1007/BFb0054059

12. Lehman, M.M.: Programs, Life Cycles, and Laws of Software Evolution. Proceed-
ings of the IEEE 68(9), 1060–1076 (1980). https://doi.org/10.1109/PROC.1980.
11805

13. McIlroy, M.D., Buxton, J., Naur, P., Randell, B.: Mass Produced Software Compo-
nents. In: Proceedings of the 1st international conference on software engineering,
Garmisch Partenkirchen, Germany. pp. 88–98 (1968)

14. Nejati, S., Sabetzadeh, M., Chechik, M., Easterbrook, S., Zave, P.: Matching and
Merging of Statecharts Speciﬁcations. In: 29th International Conference on Soft-
ware Engineering (ICSE’07). pp. 54–64. IEEE (2007). https://doi.org/10.1109/
ICSE.2007.50

15. Paige, R., Tarjan, R.E.: Three Partition Reﬁnement Algorithms. SIAM Journal on

Computing 16(6), 973–989 (1987). https://doi.org/10.1137/0216062

16. Quante, J., Koschke, R.: Dynamic Protocol Recovery. In: 14th Working Conference
on Reverse Engineering (WCRE 2007). pp. 219–228. IEEE (2007). https://doi.
org/10.1109/WCRE.2007.24

17. Runeson, P., H¨ost, M.: Guidelines for conducting and reporting case study research
in software engineering. Empirical Software Engineering 14(2), 131–164 (2009).
https://doi.org/10.1007/s10664-008-9102-8

18. Schuts, M., Hooman, J., Vaandrager, F.: Refactoring of Legacy Software using
Model Learning and Equivalence Checking: an Industrial Experience Report. In:
International Conference on Integrated Formal Methods. pp. 311–325. Springer
(2016). https://doi.org/10.1007/978-3-319-33693-0_20

19. Sipser, M.: Introduction to the Theory of Computation. Cengage Learning, 3rd

edn. (2013)

20. Sokolova, M., Lapalme, G.: A systematic analysis of performance measures for
classiﬁcation tasks. Information processing & management 45(4), 427–437 (2009).
https://doi.org/10.1016/j.ipm.2009.03.002

21. Sokolsky, O., Kannan, S., Lee, I.: Simulation-Based Graph Similarity. In: Interna-
tional Conference on Tools and Algorithms for the Construction and Analysis of
Systems. pp. 426–440. Springer (2006). https://doi.org/10.1007/11691372_28
22. Storey, M.A., Ernst, N.A., Williams, C., Kalliamvakou, E.: The Who, What, How
of Software Engineering Research: A Socio-Technical Framework. Empirical Soft-
ware Engineering 25(5), 4097–4129 (2020). https://doi.org/10.1007/s10664-
020-09858-z

23. Szyperski, C., Gruntz, D., Murer, S.: Component Software: Beyond Object-

Oriented Programming. Pearson Education, 2nd edn. (2002)

24. Van Glabbeek, R., Ploeger, B.: Five Determinisation Algorithms. In: Interna-
tional Conference on Implementation and Application of Automata. pp. 161–170.
Springer (2008). https://doi.org/10.1007/978-3-540-70844-5_17

25. Van Glabbeek, R.J.: The Linear Time — Branching Time Spectrum II. In:
International Conference on Concurrency Theory. pp. 66–81. Springer (1993).
https://doi.org/10.1007/3-540-57208-2_6

26. Vitharana, P.: Risks and Challenges of Component-based Software Development.
Communications of the ACM 46(8), 67–72 (2003). https://doi.org/10.1145/
859670.859671

27. Walkinshaw, N., Bogdanov, K.: Automated Comparison of State-Based Software
Models in terms of their Language and Structure. ACM Transactions on Software
Engineering and Methodology (TOSEM) 22(2), 1–37 (2013). https://doi.org/
10.1145/2430545.2430549

28. Yang, N., Cuijper, P., Schiﬀelers, R., Lukkien, J., Serebrenik, A.: An Interview
Study of how Developers use Execution Logs in Embedded Software Engineer-
ing. In: 2021 IEEE/ACM 43rd International Conference on Software Engineer-
ing: Software Engineering in Practice (ICSE-SEIP). pp. 61–70. IEEE (2021).
https://doi.org/10.1109/ICSE-SEIP52600.2021.00015

