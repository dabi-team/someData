2
2
0
2

l
u
J

8
1

]

B
D
.
s
c
[

1
v
9
6
3
8
0
.
7
0
2
2
:
v
i
X
r
a

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

1

PERFCE: Performance Debugging on
Databases with Chaos Engineering-Enhanced
Causality Analysis

Zhenlan Ji, Pingchuan Ma, Student Member, IEEE, and Shuai Wang, Member, IEEE

Abstractâ€”Debugging performance anomalies in real-world databases is challenging. Causal inference techniques enable qualitative and
quantitative root cause analysis of performance downgrade. Nevertheless, causality analysis is practically challenging, particularly due to
limited observability. Recently, chaos engineering has been applied to test complex real-world software systems. Chaos frameworks like
Chaos Mesh mutate a set of chaos variables to inject catastrophic events (e.g., network slowdowns) to â€œstressâ€ software systems. The
systems under chaos stress are then tested using methods like differential testing to check if they retain their normal functionality (e.g.,
SQL query output is always correct under stress). Despite its ubiquity in the industry, chaos engineering is now employed mostly to aid
software testing rather for performance debugging.
This paper identifies novel usage of chaos engineering on helping developers diagnose performance anomalies in databases. Our
presented framework, PERFCE, comprises an offline phase and an online phase. The offline phase learns the statistical models of the
target database system, whilst the online phase diagnoses the root cause of monitored performance anomalies on the fly. During the
offline phase, PERFCE leverages both passive observations and proactive chaos experiments to constitute accurate causal graphs and
structural equation models (SEMs). When observing performance anomalies during the online phase, causal graphs enable qualitative
root cause identification (e.g., high CPU usage) and SEMs enable quantitative counterfactual analysis (e.g., determining â€œwhen CPU
usage is reduced to 45%, performance returns to normalâ€). PERFCE notably outperforms prior works on common synthetic datasets, and
our evaluation on real-world databases, MySQL and TiDB, shows that PERFCE is highly accurate and moderately expensive.

Index Termsâ€”Performance Debugging, Causality, Root Cause Analysis, Database.

âœ¦

1 INTRODUCTION

Performance anomalies of databases is severe, since
databases are critical infrastructures that support daily
operations and businesses. Service outages or performance
defects can result in a negative user experience, a decline in
sales, and even brand damage. Google, for instance, assesses
page speed for ranking websites [1]. According to reports,
every 100ms of latency would cost Amazon 1% in revenue [2],
and every 0.5s of additional load delay for Google search
results would result in a 20% loss in traffic [3].

Database performance diagnosis is difficult. Modern
databases often entail complex resource management, and
dependencies between modules of a (distributed) database
may introduce subtle performance bottlenecks, degrading
system performance. Diagnosing such performance issues
empirically is cumbersome and error-prone, especially as
typical (distributed) databases on the cloud or in containeriza-
tion environments may be exposed to hundreds of potentially
influencing key performance indicators (KPIs).
Usage Scenario. We show an illustrative example in Fig. 1,
which contains three KPIs. Filesystem IO X1 and CPU usage
X2, as two causes, influence the database query processing
time Y . A developer, Bob, observes a processing time spike
(5.1s) and wonders the root cause of this spike. He manually

â€¢ Zhenlan Ji, Pingchuan Ma and Shuai Wang are with the Department of
Computer Science and Engineering, Hong Kong University of Science and
Technology, Hong Kong SAR.
E-mail: {zjiae,pmaab,shuaiw}@cse.ust.hk

Manuscript received April 19, 2005; revised August 26, 2015.

Fig. 1. Motivating example of performance debugging.

checks all performance metrics and identifies that the spike
is due to high CPU usage.
Ideal Solution. The given scenario is usually human-
intensive. As disclosed by database vendors [4], a burst of
performance anomalies may last only a few minutes, whereas
human-intensive diagnoses can take tens of minutes, which
is time consuming and error-prone. Ideally, Bob wishes to
obtain a causal graph and a counterfactual oracle, derived
from KPI causal relations (see Fig. 1(a)) for performance

Processing Time ğ‘ŒCPU Usage ğ‘‹(cid:2870)Filesystem IO ğ‘‹(cid:2869)ğ‘‹(cid:2869)ğ‘‹(cid:2870)ğ‘Œ0.11%3.24%1.5s0.28%6.77%1.6s0.77%4.77%2.0s3.64%20.32%2.8s77.31%51.10%4.1s54.88%91.93%4.6ssteady statuschaos exp.normal processing time (ğ‘Œ<4)abnormal processing time (ğ‘Œ>4)(b)offline datacollectionfromtwoscenariosğ‘‹(cid:2869)ğ‘‹(cid:2870)ğ‘Œ13.28%24.83%2.9s60.17%87.31%5.1s(c)data observed in theonline phaseğ‘‹(cid:2869)ğ‘‹(cid:2870)ğ‘Œ(cid:3552)22.83%87.31%4.9s (-0.2)60.17%29.69%3.7s (-2.4)(d)data simulated in counterfactual analysisreal-world metriccounterfactual metric(a)causal relations of KPIs(formingthecausalgraphandthecounterfactualoracle) 
 
 
 
 
 
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

debugging. Bob would first backwardly traverse the causal
graph and scope all ancestors of the node denoting pro-
cessing time Y . These ancestors, as in Fig. 1(a), represent
(in)direct causes of performance downgrades. Then, Bob
would inquire the oracle (the inquiry is often dubbed as a
â€œcounterfactual queryâ€) whether the performance downgrade
can be resolved if a particular cause were changed to a given
extent: a counterfactual change that can fix performance
downgrade forms the root cause. Considering the table in
Fig. 1(d), where Bob submits two counterfactual queries
(yellow cells) to the oracle and receives YË† after such coun-
terfactual changes. Bob observes that when X1 (filesystem
IO) resumes normal (i.e., its mean value, 22.83% in our case),
processing time YË† remains elevated (first row in Fig. 1(d)).
When X2 (CPU usage) drops to its mean value 29.69%,
YË† returns to normal (second row in Fig. 1(d)). Thus, Bob
attributes this spike to high CPU usage.

Practical Challenge. Establishing an accurate causal graph
and a counterfactual oracle are long-standing challenges
in causality analysis. Existing works primarily employ off-
the-shelf causal discovery algorithms or hand-coded rules
to identify causal graphs from observational data (e.g.,
events related to infrastructure, storage, networks). Then,
a predictive model is trained on causal relations to support
counterfactual analysis. However, we deem that existing
works are insufficient for systematic, in-depth performance
diagnosis due to limited observability. Data samples of real-
life performance downgrades are rare. Therefore, the causal
graph learned from mostly normal data (the â€œsteady statusâ€
in Fig. 1(b)) may be biased and unsuitable for analyzing
performance downgrades. Moreover, the predictive model
rarely considers bias due to confounders, leading to erro-
neous counterfactual predictions [5], [6].

Our Solution. We adopt chaos engineering (CE), an emerg-
ing engineering practice that aids testing complex software
systems. We expand the common usage of CE to create
sufficient and authentic abnormal data, denoting system
events causing performance anomalies (see â€œchaos exp.â€ in
Fig. 1(b)). This enables learning high-quality causal graphs
and oracles. In the offline phase, we would launch CE to
learn the causal graph and the associated structural equation
model (SEM) of the database. In addition to data passively
collected in mundane steady status, we proactively collect
abnormal data incurred by CE (â€œchaos exp.â€ in Fig. 1(b)) to
learn an accurate and comprehensive causal graph. Moreover,
we use CE for active intervention, facilitating estimation of
SEM under (latent) confounders. In the online phase, when an
anomaly is observed (Fig. 1(c)), we collect the ancestors of
the abnormal processing time Y on the causal graph and use
the learned SEM to diagnose the root cause of the anomaly
by answering counterfactual queries.

Main Results. This paper presents an automated framework,
PERFCE, that delivers the aforementioned performance diag-
nosis using CE-enhanced causality analysis. PERFCE uses an
industrial-strength chaos framework, Chaos Mesh [7], to es-
tablish causal graphs and SEMs with high quality. Evaluation
using synthetic datasets shows that PERFCE offers highly
accurate causality analysis. Moreover, we evaluate PERFCE
by setting up MySQL and a distributed database TiDB [8] on
the Kubernetes [9] container environments. For this setup,

2

human evaluations (involving two database engineers and
five academy researchers) show that PERFCE can reliably
diagnose performance defects incurred by various system
resources, outperforming existing works in nearly all settings.
In sum, we make the following contributions:
â€¢ This work, for the first time, introduces the usage of CE
in the context of causality analysis. Combining passive
observations and proactive CE achieves comprehensive
observability, enabling qualitative root cause identifica-
tion and quantitative counterfactual analysis with high
accuracy.

â€¢ We design PERFCE to conduct automated performance
anomaly diagnosis for complex databases. PERFCE incor-
porates a set of design principles and optimizations to
deliver an effective diagnosis with moderate cost.

â€¢ Our evaluation of synthetic datasets and real-world (dis-
tributed) databases hosted on containerization environ-
ments subsumes different practical and complex scenarios.
Under all scenarios, PERFCE enables accurate debugging
of performance anomalies.

2 PRELIMINARY
We introduce performance debugging in Sec. 2.1 and for-
mulate causality analysis in Sec. 2.2. We introduce CE, an
emerging success paradigm in testing complex (distributed)
software in Sec. 2.3.

2.1 Database Performance Diagnosis

Database developers and users, when observing unexpected
performance behaviors, may often wish to identify relevant
information to debug the anomalies. Depending on the
accessible information, we classify performance debugging
into two categories:
Blackbox Debugging: Localizing KPIs. From a holistic view,
todayâ€™s database performance downgrades are primarily due
to abnormal system components, such as kernel, network,
or pod failure in container clusters [10]. Blackbox debug-
ging is therefore becoming the mainstream in performance
debugging, where users do not need to access database
internals. For instance, a developer may wonder what causes
an intermittently slow SQL query [4], and the end goal is to
find KPIs like high CPU usage or low disk throughput, that
are the root causes of the slow query.

Blackbox debugging of database performance defects is a
demanding, yet unsolved problem. Runtime environments
often comprise hundreds of KPIs (e.g., our evaluated con-
tainer clusters have at most 254 KPIs, see Sec. 5), making
it challenging to flag root cause KPIs. Statistical debugging
(SD) [11], [12], [13] can identify KPIs correlated to anomalies.
Nevertheless, as frequently quoted, correlation does not
imply causation and SD is fundamentally limited in its
applicability and accuracy. A promising trend is to launch
causality analysis [14], [15] to construct causal relations
between KPIs. Identifying root cause KPIs is thus recast to
predict KPIs that manifest a major causation with anomalies
based on the causality graph.
Whitebox Debugging: Localizing Program Components. In
general, software bugs can also result in performance anoma-
lies. This â€œwhiteboxâ€ scenario assumes that programmers can
monitor software internals, which often need to instrument

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

the software to monitor execution behaviors. Typical debug
approaches include software profiling [16], [17], visualiza-
tion [18], and program analysis techniques like program
slicing [19], delta debugging, and statistical debugging [11],
[12], [13], [20], [21]. Often, the end goal is to isolate buggy
program components that represent performance bottlenecks.
Whitebox vs. Blackbox. We clarify that whereas whitebox
performance debugging is widespread in conventional soft-
ware debugging, its use in database contexts is uncommon,
if even possible. This may be primarily due to the high
complexity of database systems, and the lack of access to
the underlying software internals for commercial products.
Accordingly, this paper presents PERFCE, a blackbox per-
formance debugging tool toward real-world (distributed)
databases where traditional program analysis or tracing
techniques are hardly possible. Understanding performance
anomalies is important for production databases [4], [14],
[22]. PERFCE is designed based on the observation that
existing causality-based approaches are of limited accuracy
and comprehensiveness in real-world usage (see Sec. 3). The
next section formulates causality analysis in performance
debugging.

2.2 Causality Analysis

Qualitative Csaulity Analysis. A desiderata in performance
debugging is to automatically identify the root cause and
also provide actionable suggestions for repair. In Fig. 1,
developers may anticipate to know that abnormal CPU
usage causes the processing time spike. This denotes a
qualitative view of performance debugging enabled by
causality analysis, which flags one or several KPIs Xi deemed
as the root causes of the performance defects. With causality
graph defined below, qualitative analysis is straightforward.

Definition 1 (Causal Graph). A causal graph (a.k.a., Bayesian
network) is a directed acyclic graph (DAG) G = (V, E). Each
node X represents a random variable and each edge X â†’ Y
encodes their cause-effect relationships, which denotes that X is a
direct cause of Y . We use P aG(X) to denote the parent nodes of
X in G.

With causal graph, identifying root causes of anomalies
is recast to identify the cause-effect relationships from graph
ancestors and descendants. Particularly, given an abnormal
KPI Y , a common approach is to backtrack the ancestors of
Y and identify the most ancestral abnormal KPI Xi of Y as
the root cause [15].
Quantitative Causality Analysis. Developers may also de-
mand quantitative performance debugging, which is often
referred to as counterfactual analysis. Let X1, X2, Y denote
filesystem I/O, CPU usage and processing time. When
observing X1 = x1, X2 = x2 in a particular time point, de-
velopers would wish to know E(Y | X1 = x1, do(X2 = xâˆ—
2)),
where the do(Â·) operator, a counterfactual query, represents
an intervention over value of a variable like X2. The
formulation estimates the processing time in a counterfac-
tual world which can be interpreted as â€œwe have observed
X1 = x1, X2 = x2 in the real world, if X2 were xâˆ—
2, then what
would Y be?â€

Counterfactual analysis in causality analysis [23], [24]
can address how a quantitative counterfactual change of

3

a KPI impacts outcomes of interest, such as processing
time. In addition to causal graphs, counterfactual analysis
entails building the structural equation model (SEM) of the
underlying distribution [25].
Definition 2 (SEM). A SEM M is defined as follows:

1) A set of exogenous variables U , representing the factors

outside the model;

2) A set of observed endogenous variables V ; each variable X is
functionally dependent on UX âˆª P aG(X) where UX âŠ† U .
3) A set of deterministic functions fX âˆˆ F such that each

fX : P aG(X) Ã— UX â†’ X computes the value of X.
A counterfactual query do(X = x) simulates interven-
tions, by deleting the edges between X and its parent nodes
from the causal graph in SEM. The target variable X is
replaced with a constant such that X = x, while the rest of
the model are unchanged [23], [24].

To obtain SEM, we need to: 1) obtain the causal graph
and then 2) estimate each function fX âˆˆ F from data.
Overall, these two steps are often referred to as structure
learning and parameter learning in causality analysis [26].
Given observational data, structure learning recovers causal
graphs, where underlying cause-effect relations are inferred
from graph ancestors/descendants. Then, fX of every non-
root variable X can be learned by training a regression
model from historical data. For instance, fY in Fig. 1 can
be estimated by regressing Y on X1, X2 using collected
historical data.

Fig. 2. Using CE to aid software testing.

2.3 Chaos Engineering (CE)

As large-scale, distributed systems evolve, traditional soft-
ware testing methods, which primarily mutate program
inputs, become less powerful. CE is the discipline of testing
a system to ensure it can sustain turbulent conditions in pro-
duction [27]. In a cloud/container scenario, typical turbulent
conditions may include infrastructure, pod, network, and
application failures. CE typically takes three steps to uncover
software bugs:
â‘  Defining Steady State. CE often begins by defining
testing oracles, often known as â€œsteady states,â€ as easily
measurable outputs (rather than internal states) of a system
that indicate normal behaviors. Accordingly, CE would make
the important hypothesis such that a steady state will persist
in both a control group and the experimental group subjected to
CE stress.

ChaosMesh/ChaosMonkey/Facebook Storm/â€¦queryoutputconsistencyexperimentalgroupcontrolgrouppickchaosvariables:network;disk;RAM;â€¦throughputsâ€¦generalchaosframeworksdomain-specificsteadystates(i.e.,testingoracles)checkconsistencylinearizabilityJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

Steady states may subsume throughput and query out-
puts, by considering domain specific demands. For instance,
SQLSmith [28] compares the outputs of one database (when it
is being stressed by CE) and MySQL. The steady state in this
scenario is defined such that the SQL execution outputs are
consistent between two databases. Knowledgeable audiences
may notice that this setup expands the standard â€œdifferential
testingâ€ procedure [29], [30], [31], in which the experimental
group must act consistently with the reference even while
the former group is under the stress of CE.
â‘¡ Picking Chaos Variables. Typically, CE comprises a collec-
tion of chaos variables, each of which denotes a critical, low-
level factor that may induce various failures in infrastructure,
network, and systems. For instance, modern CE frameworks
like Chaos Mesh [7] are deeply coupled with containerization
environments like Kubernetes [9], and its offered chaos
variables subsume a comprehensive set of failures that may
occur in Kubernetes clusters (e.g., container-kill, pod-kill).
To clarify a potential confusion, chaos variables are not the
same as KPIs; usually there are considerably more KPIs
than chaos variables. Mutating each chaos variable (e.g.,
an IO-concerned chaos variable) may influence many KPIs
(e.g., average I/O time), and several chaos variables may
simultaneously influence the same KPI as well. See Sec. 5
about our mutated chaos variables.
â‘¢ Launching CE and Testing. Once properly defining â‘ 
and â‘¡, the next step is to launch CE and test the target
system, looking for the steady stateâ€™s inconsistency between
the reference group and the target system (experimental
group) under CE. Findings at this step can be wrapped up
for debugging and error fix.

3 MOTIVATION & LITERATURE REVIEW

This section discusses key technical challenge of causality
analysis and review existing works. We then illustrate the
synergistic effect of integrating causality analysis with CE.

Fig. 3. Three typical local structures in a causal graph.

Challenges in Rule-Based Causality Analysis. Existing
causal-based performance debugging can be categorized
into rule-based construction and learning-based construction.
However, the accuracy of estimated causal graphs by both
methods remain questionable. First, rule-based construction
is highly dependent on expert knowledge and human-
intensive, which may not be always correct with respect to
rigorous mathematical properties of causal relationships [42].
In fact, rule-based methods usually aim at a specific ap-
plication with limited types of metrics, e.g., Sage [14], one
state-of-the-art work, only supports latency-related KPIs.
Challenges
Causality Analy-
Learning-Based
sis. Learning-based causality construction is generally
superior than rule-based methods. Recent works [15], [34],
[36] use learning-based approaches to creating causal graphs
for performance debugging. This allows more flexible

in

4

causality inference with broader applications. Nevertheless,
in performance debugging, it is challenging to construct
SEM for qualitative/quantitative causality analysis. The
key issue is the limited observability. Overall, data collected
during normal database execution suffer from selection bias,
where abnormal data, denoting performance anomalies, are
rare or absent. According to our observation, a considerable
proportion of KPIs (e.g., a KPI denoting failed queries,
known as Failed Query OPM) are unchanged or change
negligibly during normal database execution. This hinders
learning plausible causal relations. With this regard, existing
works often process a huge amount of logs [4], thereby
subsuming possible (anomaly) data at the best effort.
Challenges Owing to Confounders. Despite above chal-
lenges of forming causal graphs, we find that existing
rule-/learning-based approaches neglect one key influen-
tial factorâ€”confoundersâ€”in causality analysis due to lim-
ited observability. Confounders, either observable or non-
observable (called â€œlatent confoundersâ€), are ubiquitous and
hinder causality analysis. For instance, software input size
Z may simultaneously increase filesystem I/O X1 and the
overall processing time Y . The resulting causality model
that regresses Y on X1 is biased and inaccurate. When Z is
observed (i.e., Fig. 3(b)), we may employ a doubly robust
estimator [5] to debias. For realistic settings where Z is not
observed (Z is a latent confounder, as in Fig. 3(c)), it is
impossible to estimate an unbiased model from data [6]. The
state-of-the-art (SOTA) works either assume the absence
of confounders [14] (as in Fig. 3(a)) or assume that all
confounders are observable [36], as in Fig. 3(b). As our
evaluation shows (Sec. 6.3), neglecting observable/latent
confounders impede causality analysis accuracy.
Existing Works. Table 1 compares PERFCE with existing
works conceptually and technically. We categorize each work
in terms of either rule-based or learning-based causality
analysis. As aforementioned, rule-based methods are often
limited to specific domains and metrics; Sage [14] and
Groot [41] manually defined several rules to constitute causal
graphs. As shown in the last column of Table 1, they only
support limited KPIs (e.g., network latency-related KPIs)
specified in the manual rules. Sieve [35] uses Granger causal-
ity tests to discover causal relations between time series. It
evaluates if one time series can forecast another, which is not
necessarily the true causality. Most learning-based methods
train causal graphs using offline data collected during normal
execution; such passively collected observations (e.g., system
logs) are often biased.

Moreover, given a causal graph, most works rate the
contribution of identified causes using heuristics pertaining
to graphical structures, e.g., PageRank-based solutions add
heuristically-designed â€œweightsâ€ to graph edges. We clarify
that such heuristics-based methods can hardly provide
meaningful quantitative relations between the root cause
and performance anomalies, preventing developers from
comprehending how the root cause leads to an anomaly.
Methods based on graph traversal begin with abnormal KPI
nodes and backtrack via their ancestors to identify the root
cause. Sage [14] applies predictive models to quantify the
influence of a possible cause. Sage is the only attempt for
quantitative counterfactual analysis. Sage, however, only
supports quantitative analysis of network latency-related

ğ‘‹ğ‘‹ğ‘Œğ‘Œğ‘ğ‘a) w/o confounderb) observable confounderc) latent confounderğ‘‹ğ‘‹ğ‘Œğ‘Œğ‘ğ‘ğ‘‹ğ‘‹ğ‘Œğ‘Œğ‘ğ‘JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

5

Tool

Scope

Venue

TABLE 1
Comparing existing works and PERFCE. CA stands for counterfactual analysis and CE stands for chaos engineering.
Has General
KPI Support?
(cid:37)
(cid:33)
(cid:37)
(cid:37)
(cid:33)
(cid:33)
(cid:33)
(cid:37)
(cid:37)
(cid:33)

Causal Graph
Generation
Learning with offline data
N/A
Learning with offline data
Granger causality test
Learning with offline data
N/A
N/A
Hand-coded rule
Hand-coded rule
CE-enhanced learning

Root Cause
Analysis
Graph Traversal
Actual Cause [33]
Graph Traversal
Graph Comparison
Linear Regression
PageRank [38]
BCM [39]
CVAE [40]
PageRank [38]
DML + CE-enabled IV

Has Counterfactual
Analysis?
(cid:37)
(cid:37)
(cid:37)
(cid:37)
(cid:37)
(cid:37)
(cid:37)
(cid:33)
(cid:37)
(cid:33)

INFOCOMâ€™14
SIGMODâ€™16
ICSOCâ€™19
ASPLOSâ€™19
SIGMODâ€™20
IPCCCâ€™20
VLDBâ€™20
ASPLOSâ€™21
ASEâ€™21
NA

CauseInfer [15]
DBSherlock [32]
MicroScope [34]
Sieve [35]
ExplainIt [36]
FluxInfer [37]
iSQUAD [4]
Sage [14]
Groot [41]
PERFCE

Blackbox
Blackbox
Blackbox
Blackbox
Blackbox
Blackbox
Blackbox
Blackbox
Whitebox
Blackbox

KPIs, as it primarily focuses on cloud microservices. Due to
limited observability, Sage may be biased in regards to the
prevalence of confounders.
PERFCE. CE is currently used to stress software systems
and aid in-house (differential) testing. This paper views CE
as a nearly â€œout-of-the-boxâ€ option for enhancing causality
analysis. CE readily introduces negative impacts on software
performance. Its chaos variables often influence hundreds of
KPIs, forming a wealth of training data for learning-based
causality analysis. PERFCE exhibits general KPI support,
not limited to a few domain-specific instances. Also, instead
of passively collecting system logs for training, PERFCE
benefits from active intervention (by mutating chaos variables)
to achieve comprehensive observability and develop more
accurate SEMs. In addition, PERFCE, for the first time,
delivers quantitative counterfactual analysis in the presence
of (latent) confounders with arbitrary KPIs. PERFCE uses
double machine learning (DML) [43] to address observable
confounders, while CE allows the use of instrumental
variable (IV) [44] to overcome latent confounders.

Note that this research uses the domain-general CE frame-
work (as shown in Fig. 2). We do not require those domain-
specific â€œsteady statesâ€ (Fig. 2). We show that CE is not
limited to assist in-house testing, and together with causality
analysis, it can largely boost performance debugging of
(distributed) databases.

4 DESIGN OF PERFCE
Fig. 4 depicts PERFCEâ€™s workflow. PERFCE composes offline
learning and online diagnose phases. During the offline
phase, PERFCE adopts Chaos Mesh [7], an industry-standard
CE framework integrated in cloud container environments.
We use Chaos Mesh to launch CE toward the target databases
to collect training data for constructing SEM (Sec. 4.1). CE
enables active intervention, resulting in high-quality SEM.
PERFCE considers both observable and latent confounders
(see Fig. 3). We present configuration details of Chaos Mesh
in Sec. 5. With the learned SEM and a performance anomaly
occurred during the online database execution, PERFCE can
identify the root cause KPIs. Furthermore, PERFCE allows
the user to issue counterfactual queries toward the localized
root causes and obtain quantitative fix, such as reducing
CPU usage below 45%. We discuss the details at this step in
Sec. 4.2.
Application Scope. PERFCE debugs real-world database
performance anomalies. Modern databases are complex
and prone to performance issues. In evaluation, we assess

PERFCE using synthetic test suites and real-world databases
(MySQL and TiDB). These test suites/databases were also
evaluated by existing works. We deploy MySQL and TiDB in
Kubernetes [9] clusters; Kubernetes is the de facto container
management system. Other databases can also be integrated
into Kubernetes and analyzed by PERFCE.

We also assume the databases have KPI monitoring utili-
ties. Designing performance monitoring is orthogonal to this
research, and our focus is to analyze the monitored anomalies.
There are several performance monitoring tools integrated in
Kubernetes [45], [46]. See details about monitoring in Sec. 5.

4.1 Offline CE-Enhanced SEM Learning Phase

CE Usage. It is a long-standing problem in causal inference to
learn high-quality SEM from observational data. The validity
of output SEMs is dependent on a set of assumptions. In
performance diagnosis, these assumptions are frequently
violated, posing considerable hurdles to subsequent causality
analysis. This work employs CE in SEM learning. In â‘  and
â‘¡, we explain how CE enables accurate and comprehensive
SEM learning. In â‘¢, we detail the operations for generating
training data using CE.
â‘  Improving Observability on Normal Data. One famous
assumption is faithfulness, which guarantees d-separation
on causal graphs when conditional independence on the
joint probability distribution (detected in observational data)
exists [42]. This assumption helps us refute causal relations in
the absence of correlations. However, the lack of correlations
may be simply due to insufficient data, which is frequent in
this research. Since many database KPIs remain unchanged
or vary only little in daily usage, we can hardly establish
meaningful causal relations on them. Existing research has
to either ignore these KPIs or collect abnormal behaviors
manually from logs to explore causal relations at the best
effort. Manual data collection is costly, domain-specific, and
less scalable. PERFCE uses Chaos Mesh to form an active
intervention during causal learning, as it systematically
mutates chaos variables to achieve extensive observability on
possible value ranges and causality among KPIs. For instance,
mutating a chaos variable, network loss probability (which
ranges from 0% to 100%), can affect many network-related
KPIs, such as â€œnetwork duration of request.â€ Mutating chaos
variables in de facto CE frameworks can influence hundreds
of KPIs. Thus, CE improves observability on the normal
states of KPIs, leading to more comprehensive and accurate
causal learning.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

6

Fig. 4. PERFCE overview.

â‘¡ Improving Observability on Anomalies. Furthermore, CE
allows for triggering anomalies offline by heavily mutating
certain chaos variables. By inspecting real-world perfor-
mance anomalies, we find that many basic performance
anomalies (e.g., â€œI/O Saturationâ€) are outcomes of the
I/O-concerned chaos variable. Moreover, some complex
performance anomalies (e.g., â€œWorkload Spikeâ€) can be
simulated by combining chaos variables. This way, we not
only augment the comprehensiveness of observed normal
data (as in â‘ ), but also largely enrich the knowledge of
anomaly data. This would mitigate OOD (out-of-distribution)
faced by previous works, since online anomaly data was
rarely seen in offline training data collected by previous
research.
â‘¢ Collecting Training Data. To collect offline training data, in
addition to constant queries emitted by workload simulators
(such as the TPC-C benchmark [47]), we also use a set of
chaos variables to stress the target databases. Among the
chaos variables included in our experiments (see details in
Sec. 5), some, when enabled, directly inject faults to the target
databases. When generating training data, we enable each of
them and record how KPIs change. Other chaos variables are
configurable, allowing us to mutate their values to determine
the extent of their impact on databases. When generating
training data, for each of them, we divide its valid input
range equally into three to five thresholds (depending on the
sensitivity of this chaos variable; less sensitive variables are
mutated for five times and vice versa). We mutate each chaos
variable using all of its thresholds, and we collect the KPI
changes for each iteration. KPIs are initially used to learn the
structure of the causal graph, and then chaos variables and
KPIs are used together to learn the SEMâ€™s parameters (see
details in the following paragraphs).

Causal Graph Structure Learning. Once gathered offline
training data, we first learn causal graphs. Causal graph
structure learning generates a DAG, where each node denotes
one KPI, and each edge represents causality relations of
a KPI pair. This enables qualitative causal analysis, such
that given a performance anomaly monitored during the
online phase (denoting a node on the DAG), we collect
its ancestors to form the potential root causes (see details
in Sec. 4.2). Previous work like CauseInfer [15] has relied
heavily on constraint-based algorithms (e.g., the PC algo-
rithm [42]), which returns an incomplete causal graph with
undirected edges (CPDAG) and arbitrarily assign directions
to undirected edges. In PERFCE, we aim to harness the
power of score-based algorithms to learn a causal graph that
maximizes a predefined score over observational data, with
all edges in the resulting graph being directed. In particular,

we employ a two-stage technique based on BLIP [48] to
learn causal graphs. To begin, for each variable, we identify
its possible parent sets with local scores; then, we use a
global structure optimization algorithm to identify the causal
graph that maximizes the global score, which is computed
using cached local scores in the first stage. According to
the literatures [49], BLIP produces empirically much better
results than the PC algorithm [42] employed in previous
works. Nevertheless, PERFCE is not bounded with BLIP;
we use it as it is one recent work that offers off-the-shelf
implementation with good engineering quality. Users can
replace BLIP with other algorithms whenever needed [42],
[49].
Causal Graph Parameter Learning. Given the DAG repre-
senting causal graph structures, we further conduct parame-
ter learning to assign relationships toward each edge of the
DAG. This step enables quantitative counterfactual analysis.
Considering the sample case in Fig. 1, given filesystem I/O
X1 = x1 and CPU usage X2 = x2, quantitative causality
analysis infers the consequent processing time Y . For this
simple case, we can directly train a predictive model that
predicts Y given X1 and X2. However, such methods are not
suitable when X1 and X2 has a causal relationship (X1 forms
a confounder). For example, heavy filesystem I/O itself may
result in poor CPU usage, as processes may be blocked while
waiting for I/O. In this case, X1 is an observable confounder
of X2. We start to analyze a potential solution by assuming
linear causal relations and will extend to general cases later.
Consider the following relations:

X2 = Î¸1X1 + b1 + Ïµ1
Y = Î¸2X1 + Î¸3X2 + b2 + Ïµ2

(1)

(2)

Ë† X2 + b2

Ë† X1 + Î¸3

where Î¸1,2,3 denote linear coefficients describing the effect
of X1 on X2, X1 on Y and X2 on Y , respectively; b1, b2 are
the constant terms of the linear model and Ïµ1, Ïµ2 denote the
zero-mean noise (or disturbance) introduced by exogenous
variables. A naive solution is to construct a sophisticated
Ë† for learning
machine learning estimator Î¸2
the regression function Î¸2X1 + Î¸3X2. However, as pointed
out in [43], such naive estimator does not converge to the
true regression function due to regularization bias and the
bias also exists in general settings. In other words, since
our observations on X2 are actually dependent on X1,
Ë† learned from data cannot precisely predict
Ë† X1 + Î¸3
Î¸2
Y given arbitrary (counterfactual) X1 and X2, where X1, X2
are independent. We now introduce how PERFCE handles
observable and latent confounders.
Observable Confounders. To handle observable con-
founders, we adopt double machine learning [43], a popular

Ë† X2 + b2

ChaosMeshchaosvariablesYstructural equation model (SEM)endogenous var.KPImonitoringexogenous var.network,disk,pod,â€¦Y=ğ‘ƒğ‘ğº(Y)	+UY1.performanceanomalyobservationonlineperformancediagnosisphaseofflineSEMlearningphasedatabaseKPImonitoring2.rootcauseKPI3.counterfactualqueries4.quantitativefixdatabaseaddressconfoundersactiveinterventionJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

Ë† X1 + b1

Ë† Ïµ1Ë† to derive the unbiased estimation Î¸3

strategy in causality analysis. In short, double machine
Ë† from data
learning first estimates an unbiased Î¸1
and obtains the first residual Ïµ1Ë† = X2 âˆ’ X2Ë† . Then, it uses
X1 to regress Y as YË† and obtains the second residual
Ë† Ïµ1Ë† = Y âˆ’ YË† . Recall that Ïµ2 is zero-mean, and we
Ïµ2Ë† + Î¸3
eventually use the first residual Ïµ1Ë† to regress the second
Ë† . With
residual Ïµ2Ë† + Î¸3
Ë† can be estimated accordingly by using X to regress
Ë† , Î¸2
Î¸3
Ë† X2 + b2. Note that this pipeline (for augmenting
Î¸2X1 + Î¸3
linear regression) is extensible to arbitrary functions. Particu-
larly, deep learning models can be used to perform non-linear
regression and model more flexible causal relations.
Latent Confounders. The above technique is still based on
the premise that all confounders (i.e., X1 in our example) are
observable. It cannot be extended to a more complex setting
with latent confounders, which pervasively exist in real-
world settings. Overall, the presence of latent confounders
makes counterfactual predictions technically challenging, if
not impossible, as we have no method of disentangling the
effect of X1 from the causal relationship between X2 and
Y . We note that none of existing works reviewed in Table 1
ever consider latent confounders, or they simply assume the
absence of latent confounders.

Fig. 5. Counterfactual predictions with an IV.

A commonly-used tactic, namely instrumental variable
(IV), can be introduced to address such difficult scenarios,
in which we need to learn a regression function under the
influence of an â€œinterventional distributionâ€ [44]. Consider
Fig. 5, where IV is introduced to serve the cause of treatment
(i.e., X2), whose effect on the outcome (i.e., Y ), if any, are
propagated with X2.

It is unclear how prior works can leverage IV, given they
primarily collect system logs in a passive manner. In contrast,
PERFCE novelly uses CE to form the IV, which has a direct
influence on the CPU usage X2 and an indirect effect on
processing time Y via X2. We clarify that CE is proper to
form IV: CE typically mutates low-level chaos variables (e.g.,
CPU, network) by injecting failures. Thus, it is reasonable
to assume the causal relationships between CE (through
the mutated chaos variables) and the influenced â€œhigh-levelâ€
KPIs are indirect, allowing for the use of IV. To illustrate, we
will revisit the linear case and show how it is generalized into
arbitrary function forms. Considering the following linear
form:

X2 = f (X1) + Î¸1IV + b1
Y = h(X1) + Î¸2X2 + b2

(3)

(4)

where f (X1) and h(X1) denote two unknown arbitrary
(zero-mean) functions of X1 on X2 and Y , respectively. Note
that here X1 denotes an unseen exogenous variable (latent
confounder). Î¸1,2 denote linear coefficients describing the
effect of IV on X2 and X2 on Y , respectively. b1, b2 are the
constant terms of the linear model. The procedure of using
IV also comprises a two-stage regression [50]. First, we use

Ë† IV + b1

7
Ë† . Here, we
IV to regress X2 and obtain X2Ë† = Î¸1
obtain the residual as the effect of latent confounders on X2:
f (X1)Ë† = X2 âˆ’ X2Ë† . Then, in the second stage, we use the
estimated X2Ë† to regress Y = h(X1) + Î¸2X2Ë† + b2 + Î¸2f (X1)Ë†
.
Recall that f (X1), h(X1) is zero-mean. We obtain unbiased
Ë† . By doing this, we recover the cause-
estimation of Î¸2
Ë† , which allows us to infer
effect relation as Y = Î¸2
counterfactual queries.

Ë† X2 + b2

Ë† , b2

Note that for generalizability, PERFCE uses a popular
IV framework, DeepIV [6], to enable counterfactual analysis
with deep learning models. This enables to approximate
arbitrary non-linear function forms. We refer readers to [6]
for full details.

4.2 Online Root Cause Analysis

Algorithm 1: Root Cause Analysis (RCA)

Input: Observed KPIs x = (x1, Â· Â· Â· , xn), KPI of Interest Y , SEM M
Output: Ordered Potential Root Causes X = {Xi, Â· Â· Â· }

1 y â† xY ; // observed KPI of interest
2 XC = {Xa | Xa is an ancestor of Y on M }; //initialize candidates
3 foreach Xa âˆˆ XC do

âˆ€jÌ¸=a
ââ

âŸ
Xj = xj , do(Xa = E [Xa])];

âŸ

4

5

yË† â† E[Y |
sa â† PDFY (yË†) âˆ’ PDFY (y);
assign sa as Xaâ€™s blame;

6
7 end
8 X â† {Xa | Xa âˆˆ XC , sc > 0};
9 rank X by blames;
10 return X

Workflow. Alg. 1 outlines the workflow of conducting root
cause analysis for performance anomalies encountered dur-
ing the online phase. x stands for a vector of KPIs currently
being observed by the database monitoring utility, and Y
denotes a KPI of interest specified by users (e.g., Y can be
the query processing time). M denotes the SEM learned in
the offline phase.

Suppose Y be the performance anomaly KPI, denoting
that the database is under high load. Alg. 1 first extracts
the current observation of Y = y from the vector x (line
1). Then, it backwardly traverses the causal graph M to
find all ancestors of Y . These ancestors are candidates of
root causes to the abnormal Y (line 2). For each candidate,
Alg. 1 computes the blame of the candidate (lines 3â€“7).
Here, a counterfactual expectation is predicted under an
intervention to the current candidate Xa (line 4; see details
shortly). Overall, it estimates â€œhow would Y become if Xa
were back to normal?â€ where â€œback to normalâ€ is defined
as Xa = E [Xa] (E [Xa] is the average value of Xa), and
we retain all other KPIs in the vector x (line 4). Let the
estimated Y be yË†, we diff the probability density of the
current KPI value y and the estimated counterfactual KPI
value yË† to compute the blame score of Xa (lines 5â€“6), where
PDFY represents the probability density function of random
variable Y . By ranking causes with their blames, Alg. 1
prioritizes usersâ€™ attention to the most influential root cause
KPIs. We elaborate on computing counterfactual predictions
and probability densities as follows.
Counterfacutal Prediction. Performing counterfactual pre-
dictions is difficult, given the complexity of causal structures.

ğ‘‹ğ‘‹2ğ‘Œğ‘Œğ¼ğ¼ğ¼ğ¼ğ‘‹ğ‘‹1JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

Algorithm 2: Counterfactual Prediction

Input: Observed KPIs x = (x1, Â· Â· Â· , xn), KPI of Interest Y ,

Candidate Cause Xa, SEM M
Output: Counterfactual Prediction yË†

8

1 xË† â† x;
2 xaË† â† E[Xa];
3 XD = {Xd | Xd is a descendant of Xa on M };
4 sort XD in the topological order on M ;
5 foreach Xd âˆˆ XD do
Total TE â†
6

âˆ‘ï¸

Xp âˆˆP a(Xd ) (E[Xd | do(Xp = xpË† )] âˆ’ E[(]Xd | do(Xp = xp)]);

xdË† â† xd+Total TE;
if Xd is Y then break;

7

8
9 end
10 return xYË†

As noted on line 4 of Alg. 2, we proceed the counterfactual
predictions as follows:

yË† = E[Y |

âˆ€jÌ¸=a
ââ

âŸ
Xj = xj, do(Xa = E [Xa])]

âŸ

(5)

which estimates the conditional expectation of Y given the
currently observed KPIs x and an intervention on one KPI,
Xa while keeping the remaining KPIs (j Ì¸= a) unchanged.
When Xa is a simple direct cause of Y , estimating Eqn. 5 is
straightforward: we can simply add the average treatment
effect (ATE) of Xa on Y to the currently observed y. Formally,

yË† = y +(E[Y | do(Xa = E[Xa])]âˆ’E[Y | do(Xa = xa)]) (6)

where the second operand (in the parentheses) of the addition
represents the ATE of Xa on Y , which can be further
computed using the SEM learned in the offline phase. For
instance, suppose we have obtained the unbiased estimation
Ë† . Then, the ATE of X1 on Y can be
of Î¸2 in Eqn. 2 as Î¸2
computed as Î¸2

Ë† Ã— (E[X1] âˆ’ x1).

However, in general cases where Xa is an ancestor of
Y , counterfactual changes on Xa may influence other KPIs,
whose changes may propagate to Y as well. To systematically
model the effect of Xa on Y , we recursively update all
Xaâ€™s descendants on the causal graph with respect to the
counterfactual change and estimate yË†. Alg. 2 outlines the
procedure. We use xË† to maintain the counterfactual values
of KPIs (line 1) and update xaË† to its mean value (line 2).
With do(Xa = E[Xa]), only the descendants of Xa will be
modified. Therefore, we estimate each of its descendants
in topological order (lines 3â€“9) such that a descendant is
updated when only all its ancestors have been updated to the
counterfactual values. For each descendant Xd, we compute
the total treatment effect (Total TE) as the sum of its parentsâ€™
treatment effects on Xd (line 6) and derive the counterfactual
Xd accordingly (line 7). When Y is updated, we terminate
the procedure and return xYË† as the counterfactual prediction
of Y given the intervention of do(Xa = E[Xa]).
Probablistic Modeling. In general, the distribution of Xk is
unknown and computing PDFY (y) is technically infeasible.
It is common to assume a prior distribution family for Xk,
and therefore, estimating the parameters from observations
and computing PDFY (y) with closed form PDF becomes
feasible. For instance, when normal distribution is assumed,
we can estimate its parameters (i.e., mean and variance)
via maximum likelihood estimations, and with estimated
parameters, the corresponding PDF is attainable. Having

Fig. 6. Modeling KPI with different techniques.

that said, given the diversity of real-world KPIs, our pre-
liminary study shows that neither Gaussian distribution nor
a more general beta distribution can plausibly estimate the
underlying distribution. For instance, when the underlying
distribution is of multiple modals (i.e., multiple peaks), sim-
ply assuming normal or beta distributions would apparently
undermine the estimation. We employ Gaussian KDE (kernel
density estimation) [51], [52] to perform non-parametric
approximation of the underlying distribution. We present a
sample comparison in Fig. 6 where we apply both Gaussian
KDE and normal distribution on a typical KPI (i.e., â€œCurrent
QPSâ€) collected from MySQL. It can be observed that our
approach achieves a reasonably good approximation to
underlying distributions of KPIs, while normal distribution
fails to capture the statistical multi-modality in the empirical
data. We note that we have observed consistently good
performance when using Gaussian KDE across other KPIs.

5 IMPLEMENTATION

TABLE 2
Chaos variables used in our implementation.

Category

Stress (2)

I/O (2)

Network (5)

Pod (1)
Time (1)
Location (1)

Variable
CPU
Memory
Latency
Error
Loss
Latency
Bandwidth
Corrupt
Duplicate
Fault
TimeOffset
Location

Description
increase the load of CPU.
increase the load of memory.
delay file system calls.
returns an error for filesystem calls.
randomly drop network packets.
increase the latency of network.
set bandwidth limit and buffer.
randomly corrupt network packets.
randomly duplicate network packets.
specify which type of pod fault is injected on pods.
specify the length of time offset.
specify which pods the anomaly is triggered on.

We implement PERFCE with about 2K lines of Python
code. During the offline phase, PERFCE employs an industry-
strength CE framework, Chaos Mesh (ver. 2.1.3). Chaos
Mesh is commonly deployed on Kubernetes clusters, en-
abling CE on cloud containerization environments. Here,
we configure Chaos Mesh with about 3000 lines of yaml.
Therefore, (distributed) databases that are currently deployed
in Kubernetes clusters can be analyzed. Moreover, by being
integrated with Kubernetes, PERFCE is agnostic to the
underlying DBMSs (e.g., MySQL, PostgreSQL and TiDB).
Also, we clarify that the technical solution of PERFCE is
not specifically designed for Kubernetes clusters. PERFCE is
general to conduct performance debugging of other scenarios
(e.g., databases deployed on a single machine). We adopt
Kubernetes given its good integration with Chaos Mesh and
the popularity (and technical challenge) of analyzing cloud,

0100020003000400050006000Current QPS0.00000.00050.00100.00150.00200.00250.0030Probability DensityGaussian KDENormalReal FrequencyJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

distributed databases. We list all employed chaos variables
in Table 2. For the MySQL experiments, we use the first three
categories (as MySQL is not a distributed setup). We use all
categories for the TiDB experiments.

Type

Workload (43)

MySQL
Memory (23)

MySQL
Internals (28)

Node
Resources (18)

TABLE 3
MySQL KPIs used in our implementation.
KPI
Current QPS, MySQL.Connections {Conn/Max Used Conn/Max Conn},
MySQL.Questions, MySQL.Client Thread Activity {Peak Threads -
Connected/Peak Threads Running/Avg Threads Running}, MySQL.Abor-
ted Connections {attempts/timeouts}, MySQL.Slow Queries, MySQL.
Handlers, MySQL.Transaction Handlers, Top Command Counters.
MySQL.Thread {Thread Cache Size/Threads Cached/Threads Created},
MySQL.Internal Mem {InnoDB Buffer Pool Data/InnoDB Log Buffer-
Size/Additional Mem Pool Size/InnoDB Dictionary Size/Key Buffer-
Size/Query Cache Size/Ada Hash Index Size/TokuDB Cache Size},
MySQL.Query Cache {Free Mem/Query Cache Size/Hits/Inserts/Not-
Cached/Prunes/Queries in Cache/}, MySQL.Table Open Cache Status -
{Openings/Hits/Misses/Misses Due to Overflow/Table Open Cache -
Hit Ratio}.
MySQL.File Openings, MySQL.Open Files {Open Files/Open Files Limit/
InnoDB Open Files}, MySQL.Open Tables {Open Tables/Table Open -
Cache}, MySQL.Temporary Objects Created Tmp {Tables/DIsk Tables/
Files}, MySQL.Select Types {Full Join/Full Range Join/Range/Scan/
Range Check}, MySQL.Sorts {Rows/Range/Merge Passes/Scan},
MySQL.Table Definition Cache {Open Table Definitions/Table -
Definitions Cache Size/Opened Table Definitions}, MySQL.Table -
Locks {immediate/waited}, MySQL.Network Traffic {Inbound/Outbound},
MySQL.Network Usage Hourly {Received/Sent}, MySQL.Query Duration.
Node.IO Activity {Page In/Page Our}, Node.Memory Distribution -
{Free/Total}, Node.CPU Usage { Load/ Load Max Core Utilization},
Node.Network Traffic {Inbound/Outbound}, Node.Swap Activity {In -
Reads/Out Writes}, Node.Disk Latency.

Database Selection. We instantiate PERFCE for performance
diagnosis of MySQL and TiDB. We deploy MySQL on Kuber-
netes, where we create MySQL with single instance. Note that
this setup is consistently adopted in prior works [32]. We also
deploy TiDB on Kubernetes. TiDB is a popular distributed
database, which is generally more complex than the MySQL
experiments due to much larger KPI size. To deploy TiDB, we
follow its recommended test configuration [53], deploying
a basic test TiDB cluster with one PD pod, one TiDB pod
and three TiKV pods on a 3-node Kubernetes cluster. Here,
PD, TiDB, and TiKV serve as manager, interface, and storage
components of the cluster, respectively. In Kubernetes, a pod
denotes the minimal unit of an application. For the 3-node
Kubernetes cluster, one node works as the control-plane, and
other two nodes work as worker.

KPI Monitoring. PERFCE uses Grafana [45] with the
Prometheus [46] backend to monitor KPIs. This is a popular
solution for event monitoring in Kubernetes. Table 3 charac-
terizes all 112 monitored KPIs in our MySQL experiments. As
for the TiDB experiments, 254 KPIs are involved. Audiences
can refer to [54] for information about these KPIs (note that
there are multiple KPIs under each â€œPanel Nameâ€ at [54]).
PERFCE records each KPIâ€™s value every one second.

Offline Training. Sec. 4.1 explains that PERFCE extends the
codebase of BLIP [48] to learn causal graphs. We adopt
BLIP due to its SOTA performance and high engineering
quality. We extend its codebase with 112 extra lines of
Python code. PERFCE is orthogonal to particular causal
graph learning algorithms. We leave it as one future work
to explore leveraging other SOTA algorithms like REAL [49]
and ML4C [55]. We employ EconML [56] to perform double
machine learning and DeepIV [6] to estimate the parameters
of causal relationships, where random forest models and neu-
ral networks (Multi Layer Perception) are jointly employed
for regression. We present model details in Supplementary
Material [?].

9

6 EVALUATION
This section evaluates PERFCE on MySQL in Sec. 6.1, and
studies the scalability of PERFCE on a large distributed
DBMS, TiDB in Sec. 6.2. We also compare PERFCEâ€™s counter-
factual analysis with standard machine learning models on
synthetic data in Sec. 6.3.
Processing Time. For the MySQL evaluation, it takes about
50 minutes for causal graph structure learning, and takes
about 8 minutes for causal graph parameter learning. After
that, to analyze one performance anomaly of MySQL (in-
cluding both quantitative and qualitative), PERFCE takes
less than one minute. As for TiDB, PERFCE takes about 1.3
hour for causal graph learning, and about 40 minutes for
parameter learning. Then, each anomaly analysis takes 3
to 5 minutes (depends on the number of involved KPIs).
Evaluating each synthetic dataset takes several seconds to
finish. We clarify that parameter inference uses one Nvidia
GeForce RTX 3090 GPU and the causal graph construction
(using BLIP) is performed on a Intel Xeon CPU E5-2683
with 256 GB RAM; we use 64 cores at this step. Thus, while
PERFCEâ€™s exact processing time may vary across machines,
we find its overall speed as encouraging, especially with
GPUs and CPU parallels.

6.1 Evaluation of MySQL

Environment and Data Collection. We setup a MySQL
instance on the Kubernetes framework, execute queries
in TPC-C using BenchBase [57] for 12 hours, in which
there are 40 minutes under chaos experiments. We use
mysql-exporter [58] to collect relevant KPIs. Then, in the
online phase, we follow the method in DBSherlock [32]
to simulate performance anomalies, as reported in Table 4.
These anomalies are simulated in accordance with different
key components in MySQL. We create a total of 12 anomaly
instances that affect the KPI of interest (i.e., Query Duration).
We use a total of 79 KPIs. We have already reported the KPIs
in Table 3.
Baselines. We re-implement CauseInfer [15], FluxInfer [37],
and ExplainIt [36] as three baseline methods. They are all
reviewed in Table 1. For CauseInfer [15], we also implement
a variant of CauseInfer (CauseInfer+CE), by augmenting
the causal discovery process of CauseInfer with our CE
module. Regarding other relevant research works reviewed
in Table 1, we exclude from comparing with methods that do
not feature general KPI supports. We also omit comparison
with DBSherlock [32] and iSQUAD [4], which require labeling
normal and abnormal regions for data collected during the
offline phase.
Evaluation. PERFCE and the three baseline methods yield
a list of KPIs ranked by their likelihood of being the perfor-
mance anomalyâ€™s root causes. For each anomaly experiment,
we collect the top-5 KPIs. For the methods that provide fewer
than five KPIs, we collect all returned KPIs. At this step,
we invite seven experts, including two database engineers
and five academy researchers with expertise in databases, to
pick a subset of KPIs from the KPIs that are recommended
by at least one method. We illustrate one question posed to
our participants in Fig. 7. Experts are first educated with
the application scenario of database performance debugging
(root cause analysis) and the meaning of KPIs. Then, they

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

10

TABLE 4
Taxonomy of performance anomalies used in the MySQL experiment.

Component
Client

Database

I/O

Network

Memory
CPU

Anomaly
Workload Spike
Database Backup
Database Restore
Flush Log
Flush Table
I/O Saturation
I/O Latency
I/O Fault
Network Delay
Network Partition
Memory Stress
CPU Stress

Description
invoke BenchBase to launch additional queries.
invoke mysqldump.
dump the pre-dumped history table back into database.
invoke mysqladmin to flush all logs.
invoke mysqladmin to flush all tables.
invoke stress-ng to increase disk usage.
invoke Chaos Mesh to launch I/O delays.
invoke Chaos Mesh to inject I/O faults.
invoke Chaos Mesh to increase network latency.
invoke Chaos Mesh to inject network partition faults.
invoke Chaos Mesh to increase memory usage.
invoke Chaos Mesh to increase CPU usage.

TABLE 5
Comparison of different methods. #Anomaly denotes number of
anomalies in this component. We highlight the best and second best
methods in each component.

Component
(#Anomaly)

Client
(1)

Database
(4)

I/O
(4)

Network
(2)

Memory
(1)

CPU
(1)

Overall
(13)

Metric PERFCE CauseInfer CauseInfer+CE FluxInfer ExplainIt

Top-1 AS
Top-3 AS
Top-5 AS
MAP@R
NDCG

Top-1 AS
Top-3 AS
Top-5 AS
MAP@R
NDCG

Top-1 AS
Top-3 AS
Top-5 AS
MAP@R
NDCG

Top-1 AS
Top-3 AS
Top-5 AS
MAP@R
NDCG

Top-1 AS
Top-3 AS
Top-5 AS
MAP@R
NDCG

Top-1 AS
Top-3 AS
Top-5 AS
MAP@R
NDCG

Top-1 AS
Top-3 AS
Top-5 AS
MAP@R
NDCG

0.71
0.81
0.83
0.43
0.89

0.43
0.36
0.44
0.13
0.51

0.89
0.83
0.77
0.48
0.73

0.85
0.88
0.89
0.33
0.98

1.00
1.00
1.00
0.17
1.00

0.57
0.57
0.57
0.11
0.57

0.71
0.68
0.70
0.29
0.72

0.00
0.00
0.00
0.00
0.00

0.00
0.15
0.10
0.02
0.12

0.39
0.27
0.16
0.10
0.23

0.43
0.24
0.14
0.08
0.22

1.00
0.33
0.33
0.08
0.31

0.00
0.00
0.00
0.00
0.00

0.26
0.19
0.13
0.06
0.17

0.00
0.00
0.00
0.00
0.00

0.18
0.30
0.27
0.09
0.37

0.21
0.42
0.36
0.18
0.35

0.14
0.33
0.29
0.09
0.29

0.86
0.90
0.77
0.72
0.96

0.00
0.00
0.00
0.00
0.00

0.21
0.34
0.30
0.15
0.34

0.86
0.86
0.69
0.36
0.81

0.43
0.29
0.29
0.11
0.38

0.18
0.14
0.26
0.10
0.27

0.14
0.07
0.21
0.06
0.21

0.86
0.29
0.40
0.29
0.54

0.29
0.76
0.66
0.50
0.74

0.36
0.29
0.34
0.16
0.39

0.00
0.29
0.17
0.03
0.16

0.00
0.05
0.09
0.01
0.09

0.00
0.06
0.16
0.03
0.14

0.00
0.07
0.14
0.03
0.12

0.00
0.00
0.20
0.03
0.16

0.00
0.00
0.11
0.03
0.09

0.00
0.06
0.14
0.02
0.12

as sufficient to produce reasonable KPIs to assist developers
in identifying the root cause. Empirical results also show
that CE offers a general augmentation toward causality-
based approaches. As in Table 5, after being augmented
with CE, CauseInfer manifests much better performance
in most settings (6.7%/14.7% improvement on the overall

Fig. 7. Example of human evaluation questions.

are asked to comprehend the detailed implementation of
the root cause (Fig. 7 (b)) before selecting KPIs that are
believed to be closely related to each anomalyâ€™s root cause
# vote
(Fig. 7 (c)). Lastly, each KPI is assigned a score as
# participant
for a given anomaly; the higher score indicates the higher
consensus for this KPI being the true root cause, from the
human expertâ€™s perspective. The average completion time is
45 minutes. The details of the human evaluation is presented
in Supplementary Material [?].
Metric. With the scores collected from human evaluation, we
consider the following metrics for comparison. First, we com-
pute the average score (AS) of top-1/3/5 KPIs suggested by
each method. In addition, we also employ two metrics over
the ranked KPIs provided by each method, MAP@R (Mean
Average Precision) and NDCG (Normalized Discounted
Cumulative Gain), that are widely-used in recommendation
systems to evaluate the accuracy of the ranked list given user
preferences.
Result Overview. We report the results of Top-1/3/5 Aver-
age Score (AS), MAP@R and NDCG in Table 5. We observe
that PERFCE substantially outperforms existing methods for
nearly all settings. For instance, its overall NDCG is 84.6%
higher than the second best method, FluxInfer. It provides
the best root causes for five out of six anomaly components
compared to baseline methods. In short, we consider PERFCE

Workload Spike1.Implementation(rootcause):wegreatlyincreasethenumberofclientssimulatedbyBenchBasetoconnecttoMySQL.2.Description:thisanomalywilldrasticallyincreasethenumberofconnectionstotheMySQLserver,thenincreasetheworkloadontheserver.Thisisreflectedintheincreasednumberofqueriesprocessedbytheserver,moreIOactivity,andincreasednetworktraffic.3.Impactonqueryduration:inthiscase,thequerydurationismuchlargerthanthenormalaveragevalue.pMySQL_Transaction_Handlers__commitpMySQL_Handlers__external_lockpCurrent_QPSpMySQL_Network_Traffic__Outboundp...(a) anomaly name(b) anomaly description(c) possible KPIJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

NDCG/MAP@R scores, respectively) and provides better
root causes compared to its original version.
Error Analysis. PERFCE exhibits sub-optimal performance
in a few settings. We find that PERFCE only recommends one
KPIs for the anomaly triggered by memory stress (5th compo-
nent in Table 5) and CPU stress (6th component). Therefore,
AS is computed using the only KPI. For memory stress,
PERFCE recommends â€œNode.Memory Distribution Freeâ€,
which is voted by all human experts and thus assigned a
score of 1. Thus, its Top-1/3/5 AS and NDCG are com-
puted as 1.00. However, experts also annotate some other
useful albeit less important KPIs with lower scores (e.g.,
â€œMySQL.Query Cache Memory Free Memoryâ€). As a result,
when a method (such as CauseInfer) recommends more
KPIs besides â€œNode.Swap Activity Swap Inâ€, it will gain a
higher MAP score. We inspect the cause of this inaccuracy
and find that it is primarily due to inaccurate counterfactual
analysis over a lengthy causal chain (with 11 hops on
causal graphs), where regression errors are accumulated
and propagated, resulting in inaccurate estimations.

In another case where an anomaly was triggered by
CPU stress (6th component in Table 5), PERFCE also fails to
suggest several highly relevant KPIs. We find that it is due to
the inaccurate causal graph, where the causal relationships
between the KPI of interest (i.e., â€œQuery Durationâ€) and
many CPU-related KPIs are incorrectly missed. In turn,
the performance of baseline methods (e.g., CauseInfer and
ExplainIt) downgrades as well. Given the inherent difficulty
of causal structure learning, we anticipate that PERFCE users
will incorporate their domain knowledge to revise certain
spurious edges and improve the quality of causal graphs.
In particular, we find that when four edges are revised,
PERFCEâ€™s performance is improved from 0.11 to 0.27 on the
MAP@R score and from 0.57 to 0.61 on the NDCG score,
respectively.

TABLE 6
Statistics of generated causal graphs. #Node and #Edge denotes the
number of non-isolated nodes/edges in the causal graphs. BIC denotes
Bayesian Information Criterion.

Method
PERFCE w/o CE
PERFCE
Improvement

#Node
64
78
+22%

#Edge
63
89
+42%

BIC
-614055.5
-584910.3
+6%

Accuracy
0.73
0.87
+16%

Plausibility of Causal Graph. We report the statistics of
causal graphs generated by PERFCE and its ablated versions
(PERFCE w/o CE) that excludes the CE module in Table 6.
Here, the BIC score is a standard metric for assessing
the â€œfitnessâ€ of causal graphs on observational data. We
also measure Accuracy: a metric examining if the pairwise
correlations are properly represented in the causal graph in
terms of d-separations and d-connections. We refer readers
to [59] for the full details of these evaluation metrics. The two
metrics are computed using the unseen data collected during
the online phase. For both metrics, a greater value indicates
a better fitness with online data. We interpret the overall
results as encouraging: 78 out of 79 KPIs (after excluding
constantly unchanged KPIs) are not isolated in the causal
graph, and 26 additional edges are identified compared to
the ablated version. Furthermore, PERFCE manifests a high
degree of agreement with the unseen online data, with an

11

accuracy of 0.87. The improvements in the BIC score further
demonstrates the effectiveness of CE. We supply the full
graph in Supplementary Material [?]. Overall, we consider
that the PERFCEâ€™s causal discovery can learn a plausible
causal graph, and CE facilitates learning causal graph with
much better quality.

6.2 Scalability Evaluation on TiDB

Environment. We also evaluate PERFCE on a distributed
database, TiDB. As noted in Sec. 5, we host TiDB on a Ku-
bernetes cluster, which has three TiKV pods (tikv-0,1,2),
one TiDB pod (tidb), and one PD pod (pd). As mentioned
in Sec. 5, 254 KPIs are involved in the TiDB scenario, which
is much larger than that of MySQL. Therefore, we view this
evaluation as appropriate to benchmark the scalability of
PERFCE on real-world distributed databases. We present
two case studies in particular in this section: we setup
two anomalies to TiDB, namely tidb-pod-failure and
network-loss. tidb-pod-failure injects a failure di-
rectly to the TiDB pod and makes it temporally unavailable.
tikv-0-network-loss randomly drops 80% packets that
are sent to a specific KV pod (i.e., tikv-0).

TABLE 7
Top-10 KPIs suggested by PERFCE for answering tidb-pod-failure.

Rank

KPI Family

1-5

6, 9

7, 8

10

Lock
Resolve OPS

Statement
OPS

CPS By
Instance (OK)

KV Cmd
OPS

Interpretation
The number of TiDB operations that resolve
locks. When a TiDB pod fails, TiDB-related
operations would decrease.
The number of different SQL statements
executed per second by TiDB pod. When a
TiDB pod fails, it would be unable to
execute statements.
The succeed command statistics on each TiDB
instance. When a TiDB pod fails, the number
of succeed commands would decrease.
The number of executed KV commands emitted
by TiDB pod. When a TiDB pod fails, it
would be unable to execute statements.

Case 1: In tidb-pod-failure, we inject a failure to the
TiDB pod. Then, we observe that the duration of the request
launched by PD pod (i.e., â€œHandle Requests Durationâ€)
becomes abnormal and ask PERFCE to diagnose this anomaly.
In short, we group the top-10 KPIs suggested by PERFCE and
use TiDBâ€™s official documentation to comprehend each of
them. As shown in Table 7, while the target KPI (PDâ€™s request
duration) is not directly relevant to TiDB pod failure, we find
that all top-10 KPIs suggested by PERFCE are highly relevant
to the root cause. All of these KPIs indicate exactly different
activities performed by the failed TiDB pod. Therefore, we
interpret the outputs of PERFCE as reasonable and highly
informative: when users are provided with these KPIs, it
should be accurate to assume that they can easily identify
the anomalyâ€™s root cause.
Case 2: In tikv-0-network-loss, a notable proportion
of network packets are dropped, reducing the overall per-
formance of the database. In particular, we observe that the
duration of command completion, â€œCompleted Commands
Duration (seconds)â€, is abnormal, and we apply PERFCE
for root cause analysis. We group and present the results
of PERFCE in Table 8. We find the outputs of PERFCE as
valuable. Note that the affected TiKV pod (tikv-0) can only
serve limited functionality, while other pods (tikv-1,2)

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

12

TABLE 8
Top-10 KPIs suggested by PERFCE for answering
tikv-0-network-loss.

Rank

KPI Family

1, 3, 7

TiKV
Write
Leader

2, 4-6,
10

TiKV
Resource

8, 9

Duration

Interpretation
The number of leaders that are writing on each
TiKV instance. When network packets to a TiKV
pod are constantly lost, writes on this TiKV pod
would decrease and writes on other pods would
increase.
The usage of resources (e.g., CPU and memory)
on each TiKV instance. When network packets
to a TiKV pod is constantly lost, it would process
less requests thus uses less resources, while
others are responsible for more requests and
use more resources.
The duration for processing different activities.
When network packets to a TiKV pod is constantly
lost, the duration of completing different
activities would increase.

would serve extra responsibility instead. Therefore, the
decrease of workload on tikv-0 and the surge of workload
on tikv-1,2 are reasonable, and it should provide enough
hints for users to investigate the detailed status of tikv-0.

(RF) models, which treat counterfactual analysis as a regres-
sion problem. The MLP model consists of three hidden layers
and uses the Adam optimizer [60] with default parameters.
The RF model consists of 300 estimators with the maximal
depth of seven. We report MSE (mean squared error; lower is
better) and R2 (coefficient of determination; higher is better)
of each method on the dataset generated by each DGP model.

TABLE 10
MSE and R2 on synthetic data. LS stands for local structure. Best
metrics are highlighted .

LS

(a)

(b)

(c)

Î¸

MSE

R2

MSE

R2

MSE

R2

Metric
mean
std
mean
std
mean
std
mean
std
mean
std
mean
std

PERFCE MLP
0.0020
0.0003
0.0011
0.0003
0.9914
0.9988
0.0063
0.0018
0.0030
0.0002
0.0022
0.0003
0.9875
0.9988
0.0093
0.0019
0.3758
0.0174
0.2098
0.0302
-0.8258
0.9382
1.9738
0.0936

RF
0.0109
0.0020
0.9522
0.0297
0.0176
0.0072
0.9282
0.0463
0.1029
0.0960
0.1540
1.2979

6.3 Evaluation on Counterfactual Analysis

In addition to the evaluation conducted on real-world
DBMSs, we also seek to determine if PERFCE yields plausible
counterfactual analysis results under complex causal graphs.
However, collecting or labeling the ground-truth outcomes
of quantitative counterfactual changes in real-world DBMSs
is highly difficult, if not impossible (therefore we use human
evaluation to assess the accuracy of PERFCE in Sec. 6.1).
Hence, we use synthetic data to compare PERFCE and other
baselines, which is common setup when evaluating causal
inference algorithms.

Table 10 reports the results. PERFCE excels in all settings.
In particular, on LS (c), the most challenging setting, the MLP
model largely overfits the data, resulting in unsatisfactory
and unstable performance. We interpret such downgrade as
reasonable; the MLP model cannot distinguish the effects
of X1, X2 on Y from the data generated by the DGP
models under LS (c). The same reason leads to the similar
performance downgrade on the RF models. However, in
contrast to the MLP and RF models, we observe that PERFCE
correctly estimates the effects of X2 on Y across all settings,
even in the presence of latent confounders, as in LS (c).

TABLE 9
DGP models for generating synthetic data. LS stands for local structure.

7 DISCUSSION

LS (see Fig. 3)

(a)
no confounder

(b)
observable confounder

(c)
latent confounder

Formulation
X1 âˆ¼ Uniform(âˆ’1, 1)
X2 âˆ¼ Uniform(âˆ’1, 1)
Y = Î¸1(X1) + Î¸2(X2) + Ïµ, Ïµ âˆ¼ Uniform(âˆ’1, 1)
X1 âˆ¼ Uniform(âˆ’1, 1)
X2 = Î¸1(X1) + Î·, Î· âˆ¼ Uniform(âˆ’1, 1)
Y = Î¸2(X1) + Î¸3(X2) + Ïµ, Ïµ âˆ¼ Uniform(âˆ’1, 1)
IV âˆ¼ Uniform(âˆ’1, 1)
X1 âˆ¼ Uniform(âˆ’1, 1) (unobserved)
X2 = Î¸1(X1) + Î¸2(IV ) + Î·, Î· âˆ¼ Uniform(âˆ’1, 1)
Y = Î¸3(X1) + Î¸4(X2) + Ïµ, Ïµ âˆ¼ Uniform(âˆ’1, 1)

DGP Model. As a common setup, we formulate a set of DGP
(Data Generating Process) models [56] used in this evaluation
in Table 9. Note that these models correspond to the graphical
forms (in which we illustrate confounders) in Fig. 3. We use
the linear form of Î¸ and employ different random states to
generate 100 datasets for each DGP model. In sum, we have
a total of 300 (3 Ã— 100) DGP models for evaluation. Then,
for each DGP model, we train the model with 5,000 data
samples and craft 1,000 counterfactual queries for evaluation.
Each counterfactual query answers the treatment effects of
changing X2 = x2 to X2 = xâ€²
2 when X1 = x1, where
x1, x2, xâ€²
2 are generated randomly and the ground-truth
treatment effects are generated by the specification of Y
in DGP models.
Baseline & Metric. As two baseline methods, we employ
standard Multi Layer Perception (MLP) and Random Forest

Enhance Structure Learning with Human Knowledge. As
shown in Sec. 6.1, flaws in causal graphs may undermine
the accuracy of PERFCE. In Error Analysis of Sec. 6.1, we
further illustrate the applicability of incorporating expert
knowledge to improve the accuracy of PERFCE: we enhance
the CPU caseâ€™s MAP@R score from 0.11 to 0.27 and the
NDCG score from 0.57 to 0.61. As a practical future work, we
anticipate that PERFCE can be improved by encoding prior
knowledge [61] from users to assist in the causal structure
learning phase. We leave it for future exploration.
Limitation on Achieved Observability. While we have
primarily improved the observability of causality analysis
with chaos engineering, there are still gaps between the
achieved observability (using chaos experiments) and real-
world anomalies. We assume that it is often impossible to
avoid encountering real-world performance anomalies that
do not exist in the collected offline training data. This would
result in the infamous OOD problems and inaccuracies
in the counterfactual analysis. In particular, we find that
when the counterfactual analysis is performed on a lengthy
causal chain, errors propagate and lead to incorrect outcomes
of PERFCE. Currently, we collect KPIs when mutating a
limited collection of chaos variables; note that these chaos
variables are offered by to test general-purpose distributed
systems. We see it as demanding for CE frameworks tailored

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

for databases, allowing for more comprehensive, database-
specific, and anomaly-oriented data collection.
Quantative Evaluation of Counterfactual Analysis. For
real-world database scenarios, it is generally impossible to
prepare the ground-truth results of quantitative counterfac-
tual analysis. Evaluating real-world counterfactual analysis
is a long-lasting problem in the field of causality analysis.
In this work, we employ human evaluations to collect the
ground-truth in the form of order relationships (as we assign
each KPI a score based on its votes of human experts).
This makes end-to-end quantitative comparison of different
methods practically feasible. Looking ahead, we plan to
explore developing testbeds for counterfactual analysis in
database KPIs, where controlled experiments (with which
we can collect the ground-truth of counterfactual analysis)
become possible.
Capturing Temporal Characteristics of KPIs. As is (often
implicitly) assumed by most works in this field [15], [34],
[36], every observation of KPIs is independent and identically
distributed (iid), making causality analysis practical feasible.
This research shares the same underlying assumption about
KPI with prior works. In reality, KPIs may however manifest
temporal characteristics. Therefore, current assumptions may
result in missing edges during causal structure learning and
inaccurate estimations in counterfactual analysis. Neverthe-
less, given that the theory and tools of causal discovery and
causal inference on time series are mainly understudied, we
leave it for future research the consideration of the temporal
properties of KPIs when conducting counterfactual analysis.

8 RELATED WORK

Theoretical Causality Analysis. Causality analysis is the
foundation of scientific discovery with applications in the
field of economics and clinical trails [44]. Identifying qual-
itative (i.e., SEM structure learning) and quantitative (i.e.,
SEM parameter learning) causal relationships is challenging.
Typically, causal discovery algorithms are applied to learn
a causal graph that encodes causal relationships among a
set of variables. The methods for causal discovery include
constraint-based methods [42], [49], score-based [48], [62],
gradient-based [63] and supervision-based [64]. Without
clear qualitative causal relationships, causal inference (i.e.,
identifying quantitative causal relationships) is infeasible
or inaccurate. The methods for causal inference is diverse.
For instance, Halpern and Pearl proposed actual causality
that quantifies the blame of an event to the outcome [33].
Rubin proposed potential outcomes framework [65], [66]. In
essence, it computes the difference on an individual when
a hypothetical intervention is enforced versus an individual
without the intervention. PERFCE uses Rubinâ€™s framework;
because it is more suitable when KPIs are modeled as random
variables and ATE (average treatment effect) naturally allows
for propagating influence over causal paths.
SE Applications of Causality Analysis. Recently, it has been
witnessed a number of researches that applied causality
analysis to address problems in software engineering [67],
[68], [69], [70], [71]. These tools usually focus on analyzing
how program inputs, configurations or behaviors impacts
the software (e.g., execution time or crash) where causal
relationships are known and clear. Then, causal inference

13

(such as actual causality techniques) can be smoothly ap-
plied to diagnose software faults or failures. However, in
distributed systems (e.g., database, microservices), causal
relationships among numerical KPIs are unknown and
presumably complicated (e.g., latent confounders). Such
scenarios necessitate causal discovery before performing
causal inference. Nevertheless, limited observability on
such systems further hinders the ability of standard off-
the-shelf causal discovery algorithms to comprehensively
identify causal relationships. As a result, root cause analysis
for such scenarios is inherently difficult and challenging
and cannot be handled by existing tools. To address this
challenge, PERFCE harnesses the power of chaos engineering
to improve the quality of causality analysis.

9 CONCLUSION

We have presented PERFCE, a database performance
anomaly diagnosis framework. PERFCE adopts chaos en-
gineering, an emerging engineering practice for stressing
complex software systems. PERFCE novelly employs Chaos
Mesh for augmenting causality-based performance debug-
ging. PERFCE features high-quality qualitative root cause
identification and quantitative counterfactual analysis. PER-
FCE addresses observable and latent confounders in causality
analysis. Our evaluation over MySQL, TiDB, and synthetic
datasets shows that PERFCE offers accurate performance
diagnosis, and it outperforms existing works across nearly
all settings.

REFERENCES

[1]

[2]

[3]

â€œHow slow database queries can negatively impact your
business,â€ https://wire19.com/how-slow-database-queries-can-
negatively-impact-your-business, 2019.
â€œAmazon found every 100ms of
them 1% in
sales,â€ https://www.gigaspaces.com/blog/amazon-found-every-
100ms-of-latency-cost-them-1-in-sales, 2019.
â€œMarissa mayer at web 2.0,â€ http://glinden.blogspot.com/2006/11/marissa-
mayer-at-web-20.html, 2006.

latency cost

[4] M. Ma, Z. Yin, S. Zhang, S. Wang, C. Zheng, X. Jiang, H. Hu, C. Luo,
Y. Li, N. Qiu et al., â€œDiagnosing root causes of intermittent slow
queries in cloud databases,â€ Proceedings of the VLDB Endowment,
vol. 13, no. 8, pp. 1176â€“1189, 2020.

[6]

[5] P. R. Rosenbaum and D. B. Rubin, â€œThe central role of the propen-
sity score in observational studies for causal effects,â€ Biometrika,
vol. 70, no. 1, pp. 41â€“55, 1983.
J. Hartford, G. Lewis, K. Leyton-Brown, and M. Taddy, â€œDeep iv:
A flexible approach for counterfactual prediction,â€ in International
Conference on Machine Learning. PMLR, 2017, pp. 1414â€“1423.
â€œChaos mesh: A powerful chaos engineering platform for kuber-
netes,â€ https://chaos-mesh.org/, 2022.
â€œTiDB,â€ https://github.com/pingcap/tidb, 2022.
â€œKubernetes,â€ https://kubernetes.io/, 2022.

[8]
[9]
[10] â€œPod,â€ https://kubernetes.io/docs/concepts/workloads/pods/,

[7]

2022.

[11] J. A. Jones and M. J. Harrold, â€œEmpirical evaluation of the tarantula
automatic fault-localization technique,â€ in Proceedings of the 20th
IEEE/ACM international Conference on Automated software engineering,
2005, pp. 273â€“282.

[12] B. Liblit, M. Naik, A. X. Zheng, A. Aiken, and M. I. Jordan, â€œScalable
statistical bug isolation,â€ in Proceedings of the 2005 ACM SIGPLAN
conference on Programming language design and implementation, 2005,
pp. 15â€“26.

[13] C. Liu, L. Fei, X. Yan, J. Han, and S. P. Midkiff, â€œStatistical debug-
ging: A hypothesis testing-based approach,â€ IEEE Transactions on
software engineering, vol. 32, no. 10, pp. 831â€“848, 2006.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

14

[14] Y. Gan, M. Liang, S. Dev, D. Lo, and C. Delimitrou, â€œSage: practical
and scalable ml-driven performance debugging in microservices,â€
in Proceedings of the 26th ACM International Conference on Architec-
tural Support for Programming Languages and Operating Systems, 2021,
pp. 135â€“151.

[15] P. Chen, Y. Qi, P. Zheng, and D. Hou, â€œCauseinfer: Automatic
and distributed performance diagnosis with hierarchical causality
graph in large distributed systems,â€ in IEEE INFOCOM 2014-IEEE
Conference on Computer Communications.
IEEE, 2014, pp. 1887â€“1895.
[16] M. Attariyan, M. Chow, and J. Flinn, â€œX-ray: Automating {Root-
Cause} diagnosis of performance anomalies in production soft-
ware,â€ in 10th USENIX Symposium on Operating Systems Design and
Implementation (OSDI 12), 2012, pp. 307â€“320.

[17] X. Zhao, K. Rodrigues, Y. Luo, D. Yuan, and M. Stumm, â€œ{Non-
Intrusive} performance profiling for entire software stacks based
on the flow reconstruction principle,â€ in 12th USENIX Symposium
on Operating Systems Design and Implementation (OSDI 16), 2016, pp.
603â€“618.

[18] C.-P. Bezemer, J. Pouwelse, and B. Gregg, â€œUnderstanding software
performance regressions using differential flame graphs,â€ in 2015
IEEE 22nd International Conference on Software Analysis, Evolution,
and Reengineering (SANER).

IEEE, 2015, pp. 535â€“539.

[19] E. Soremekun, L. Kirschner, M. B Â¨ohme, and A. Zeller, â€œLocating
faults with program slicing: an empirical analysis,â€ Empirical
Software Engineering, vol. 26, no. 3, pp. 1â€“45, 2021.

[20] G. Jin, A. Thakur, B. Liblit, and S. Lu, â€œInstrumentation and
sampling strategies for cooperative concurrency bug isolation,â€
in Proceedings of the ACM international conference on Object oriented
programming systems languages and applications, 2010, pp. 241â€“255.
[21] Z. Zuo, L. Fang, S.-C. Khoo, G. Xu, and S. Lu, â€œLow-overhead and
fully automated statistical debugging with abstraction refinement,â€
in Proceedings of the 2016 ACM SIGPLAN International Conference on
Object-Oriented Programming, Systems, Languages, and Applications,
2016, pp. 881â€“896.

[22] M. K. Aguilera, J. C. Mogul, J. L. Wiener, P. Reynolds, and A. Muthi-
tacharoen, â€œPerformance debugging for distributed systems of
black boxes,â€ ACM SIGOPS Operating Systems Review, vol. 37, no. 5,
pp. 74â€“89, 2003.

[23] J. Pearl and T. Verma, â€œA theory of inferred causation,â€ in
Proceedings of the Second International Conference on Principles of
Knowledge Representation and Reasoning, 1991, pp. 441â€“452.

[24] A. Balke and J. Pearl, â€œProbabilistic evaluation of counterfactual
queries,â€ in Probabilistic and Causal Inference: The Works of Judea Pearl,
2022, pp. 237â€“254.

[25] J. Pearl, â€œThe do-calculus revisited,â€ in Proceedings of the Twenty-
Eighth Conference on Uncertainty in Artificial Intelligence, 2012, pp.
3â€“11.

[26] C. Meek and D. Heckerman, â€œStructure and parameter learning for
causal independence and causal interaction models,â€ in Proceedings
of the Thirteenth conference on Uncertainty in artificial intelligence, 1997,
pp. 366â€“375.

[27] â€œPrinciples of chaos engineering,â€ https://principlesofchaos.org,

2022.

[28] â€œSqlsmith,â€ https://github.com/anse1/sqlsmith, 2021.
[29] M. Rigger and Z. Su, â€œTesting database engines via pivoted query
synthesis,â€ in 14th USENIX Symposium on Operating Systems Design
and Implementation (OSDI 20), 2020, pp. 667â€“682.

[30] K. Kallas, F. Niksic, C. Stanford, and R. Alur, â€œDiffStream: Differen-
tial output testing for stream processing programs,â€ Proceedings of
the ACM on Programming Languages, vol. 4, no. OOPSLA, pp. 1â€“29,
2020.

[31] T. Sotiropoulos, S. Chaliasos, V. Atlidakis, D. Mitropoulos, and
D. Spinellis, â€œData-oriented differential testing of object-relational
mapping systems,â€ in 2021 IEEE/ACM 43rd International Conference
on Software Engineering (ICSE).

IEEE, 2021, pp. 1535â€“1547.

[32] D. Y. Yoon, N. Niu, and B. Mozafari, â€œDbsherlock: A performance
diagnostic tool for transactional databases,â€ in Proceedings of the
2016 International Conference on Management of Data, 2016, pp. 1599â€“
1614.

[33] J. Y. Halpern and J. Pearl, â€œCauses and explanations: A structural-
model approach. part i: Causes,â€ The British journal for the philosophy
of science, 2020.

[35] Y. Gan, Y. Zhang, K. Hu, D. Cheng, Y. He, M. Pancholi, and C. De-
limitrou, â€œSeer: Leveraging big data to navigate the complexity of
performance debugging in cloud microservices,â€ in Proceedings of
the twenty-fourth international conference on architectural support for
programming languages and operating systems, 2019, pp. 19â€“33.
[36] V. Jeyakumar, O. Madani, A. Parandeh, A. Kulshreshtha, W. Zeng,
and N. Yadav, â€œExplainit!â€“a declarative root-cause analysis engine
for time series data,â€ in Proceedings of the 2019 International
Conference on Management of Data, 2019, pp. 333â€“348.

[37] P. Liu, S. Zhang, Y. Sun, Y. Meng, J. Yang, and D. Pei, â€œFluxinfer:
Automatic diagnosis of performance anomaly for online database
system,â€ in 2020 IEEE 39th International Performance Computing and
Communications Conference (IPCCC).

IEEE, 2020, pp. 1â€“8.

[38] Y. Li, â€œToward a qualitative search engine,â€ IEEE Internet Computing,

vol. 2, no. 4, pp. 24â€“29, 1998.

[39] B. Kim, C. Rudin, and J. A. Shah, â€œThe bayesian case model:
A generative approach for case-based reasoning and prototype
classification,â€ Advances in neural information processing systems,
vol. 27, 2014.

[40] K. Sohn, H. Lee, and X. Yan, â€œLearning structured output repre-
sentation using deep conditional generative models,â€ Advances in
neural information processing systems, vol. 28, 2015.

[41] H. Wang, Z. Wu, H. Jiang, Y. Huang, J. Wang, S. Kopru, and T. Xie,
â€œGroot: An event-graph-based approach for root cause analysis in
industrial settings,â€ in 2021 36th IEEE/ACM International Conference
on Automated Software Engineering (ASE).
IEEE, 2021, pp. 419â€“429.
[42] P. Spirtes, C. N. Glymour, R. Scheines, and D. Heckerman, Causation,

prediction, and search. MIT press, 2000.

[43] V. Chernozhukov, D. Chetverikov, M. Demirer, E. Duflo, C. Hansen,
W. Newey, and J. Robins, â€œDouble/debiased machine learning for
treatment and causal parameters,â€ arXiv preprint arXiv:1608.00060,
2016.

[44] J. Pearl, Causality. Cambridge university press, 2009.
[45] â€œGrafana,â€ https://grafana.com, 2021.
[46] â€œPrometheus,â€ https://prometheus.io, 2021.
[47] T. P. P. Council, â€œTpc-c benchmark,â€ https://www.tpc.org/tpcc,

2022.

[48] M. Scanagatta, C. P. de Campos, G. Corani, and M. Zaffalon, â€œLearn-
ing bayesian networks with thousands of variables,â€ Advances in
neural information processing systems, vol. 28, 2015.

[49] R. Ding, Y. Liu, J. Tian, Z. Fu, S. Han, and D. Zhang, â€œReliable
and efficient anytime skeleton learning,â€ in Proceedings of the AAAI
Conference on Artificial Intelligence, vol. 34, no. 06, 2020, pp. 10 101â€“
10 109.

[50] J. D. Angrist, G. W. Imbens, and D. B. Rubin, â€œIdentification of
causal effects using instrumental variables,â€ Journal of the American
statistical Association, vol. 91, no. 434, pp. 444â€“455, 1996.

[51] M. Rosenblatt, â€œRemarks on some nonparametric estimates of a
density function,â€ The Annals of Mathematical Statistics, vol. 27, no. 3,
pp. 832â€“837, 1956.

[52] E. Parzen, â€œOn estimation of a probability density function and
mode,â€ The annals of mathematical statistics, vol. 33, no. 3, pp. 1065â€“
1076, 1962.
[53] â€œTiDB-config,â€

https://docs.pingcap.com/tidb-in-

kubernetes/stable/get-started, 2022.

[54] PingCAP, â€œTidb kpis,â€ https://docs.pingcap.com/tidb/stable/grafana-

overview-dashboard, 2022.

[55] H. Dai, R. Ding, Y. Jiang, S. Han, and D. Zhang, â€œMl4c: Seeing
causality through latent vicinity,â€ arXiv preprint arXiv:2110.00637,
2021.

[56] â€œEconml: A python package for ml-based heterogeneous treatment
effects estimation,â€ https://github.com/microsoft/EconML, 2022.
[57] D. E. Difallah, A. Pavlo, C. Curino, and P. CudrÂ´e-Mauroux,
â€œOltp-bench: An extensible testbed for benchmarking relational
databases,â€ PVLDB, vol. 7, no. 4, pp. 277â€“288, 2013. [Online].
Available: http://www.vldb.org/pvldb/vol7/p277-difallah.pdf
mysql

[58] â€œExporter

metrics,â€

server

for

https://github.com/prometheus/mysqld exporter, 2022.
[59] â€œPgmpy,â€ https://pgmpy.org/metrics/metrics.html, 2022.
[60] D. P. Kingma and J. Ba, â€œAdam: A method for stochastic optimiza-

tion,â€ arXiv preprint arXiv:1412.6980, 2014.

[34] J. Lin, P. Chen, and Z. Zheng, â€œMicroscope: Pinpoint performance
issues with causal graphs in micro-service environments,â€ in
International Conference on Service-Oriented Computing.
Springer,
2018, pp. 3â€“20.

[61] C. MEEK, â€œCasual inference and causal explanation with back-
ground knowledge,â€ in Proceedings of the Eleventh Conference on
Uncertainty in Artificial Intelligence. Morgan Kaufmann, 1995, pp.
403â€“410.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

15

[62] I. Tsamardinos, L. E. Brown, and C. F. Aliferis, â€œThe max-min hill-
climbing bayesian network structure learning algorithm,â€ Machine
learning, vol. 65, no. 1, pp. 31â€“78, 2006.

[63] X. Zheng, B. Aragam, P. K. Ravikumar, and E. P. Xing, â€œDags with
no tears: Continuous optimization for structure learning,â€ Advances
in Neural Information Processing Systems, vol. 31, 2018.

[64] P. Ma, R. Ding, H. Dai, Y. Jiang, S. Wang, S. Han, and D. Zhang,
â€œMl4s: Learning causal skeleton from vicinal graphs,â€ in Proceedings
of the 28th ACM SIGKDD Conference on Knowledge Discovery & Data
Mining, 2022.

[65] D. B. Rubin, â€œCausal inference using potential outcomes: Design,
modeling, decisions,â€ Journal of the American Statistical Association,
vol. 100, no. 469, pp. 322â€“331, 2005.

[66] â€”â€”, â€œEstimating causal effects of treatments in randomized and
nonrandomized studies.â€ Journal of educational Psychology, vol. 66,
no. 5, p. 688, 1974.

[67] A. Fariha, S. Nath, and A. Meliou, â€œCausality-guided adaptive
interventional debugging,â€ in Proceedings of the 2020 ACM SIGMOD
International Conference on Management of Data, 2020, pp. 431â€“446.

[68] C. Dubslaff, K. Weis, C. Baier, and S. Apel, â€œCausality in config-
urable software systems,â€ arXiv preprint arXiv:2201.07280, 2022.

[69] B. Johnson, Y. Brun, and A. Meliou, â€œCausal testing: understanding
defectsâ€™ root causes,â€ in Proceedings of the ACM/IEEE 42nd Interna-
tional Conference on Software Engineering, 2020, pp. 87â€“99.

[70] R. Krishna, M. S. Iqbal, M. A. Javidian, B. Ray, and P. Jamshidi,
â€œCadet: Debugging and fixing misconfigurations using counterfac-
tual reasoning,â€ arXiv preprint arXiv:2010.06061, 2020.

[71] C.-H. Hsiao, S. Narayanasamy, E. M. I. Khan, C. L. Pereira, and
G. A. Pokam, â€œAsyncclock: Scalable inference of asynchronous
event causality,â€ ACM SIGPLAN Notices, vol. 52, no. 4, pp. 193â€“205,
2017.

