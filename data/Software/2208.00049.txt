2
2
0
2

l
u
J

9
2

]
S
M

.
s
c
[

1
v
9
4
0
0
0
.
8
0
2
2
:
v
i
X
r
a

NFFT.jl: GENERIC AND FAST JULIA IMPLEMENTATION OF THE
NONEQUIDISTANT FAST FOURIER TRANSFORM

TOBIAS KNOPP˚, MARIJA BOBERG˚ , AND MIRCO GROSSER˚

Abstract. The non-equidistant fast Fourier transform (NFFT) is an extension of the famous fast
Fourier transform (FFT), which can be applied to non-equidistantly sampled data in time/space or
frequency domain. It is an approximative algorithm that allows to control the approximation error
in such a way that machine precision is reached while keeping the algorithmic complexity in the
same order as a regular FFT. The NFFT plays a major role in many signal processing applications
and has been intensively studied from a theoretical and computational perspective. The fastest
CPU implementations of the NFFT are implemented in the low-level programming languages C and
C++ and require a compromise between code generalizability, code readability, and code eﬃciency.
The programming language Julia promises new opportunities in optimizing these three conﬂicting
goals. In this work we show that Julia indeed allows to develop an NFFT implementation, which
is completely generic, dimension-agnostic and requires about 2–3 times less code than other famous
libraries while still being one of the fastest NFFT implementations developed to date.

Key words. Nonequidistant Fast Fourier Transform, Fast Implementation, Multi-Threading,

Julia

AMS subject classiﬁcations. 65T50, 65T40, 65Y05, 68N01

1. Introduction. The Fourier transform plays an important role in many math-
ematical applications in particular those involving signal processing. Convolutions in
time/spatial domain can be expressed as multiplications in frequency domain, which
is often faster and allows to invert convolutions in analytical form. In practice, sig-
nals are usually discrete and of ﬁnite length such that the discrete Fourier transform
(DFT) needs to be applied. It maps a number of N samples in time/spatial domain
to N samples in frequency domain and requires OpN 2q operations, which is often
too expensive to apply the DFT in its ordinary form. The fast Fourier transform
(FFT) [5] allows to carry out the DFT in only OpN log N q operations and enables
many applications, for which the DFT would be too expensive. Its high impact in
various applications makes the FFT one of the most important numerical algorithms
developed in the 20th century. One of the fastest FFT software libraries is the FFTW
[9], which is used in most scientiﬁc applications.

An important limitation of the FFT is that it requires the input and ouput signals
to be equidistantly sampled. This makes it unusable for some important applications,
e.g.
in optical coherence tomography [10] and magnetic resonance imaging [7, 16].
In this work we focus on the case, where the signal in one domain is sampled in
In such cases, simple interpolation, to map from non-
a non-equidistant manner.
equidistant to equidistant points, leads to large numerical errors, which intuitively can
be explained by the fact that local (interpolation) errors lead to global errors in the
reciprocal domain. This motivated the development of the non-equidistant fast Fourier
transform (NFFT), which allows to keep the approximation error below the ﬂoating
point precision and thus can be used like an exact algorithm in most circumstances. It
was developed in the 1990s and 2000s by various researchers [6, 3, 1, 25, 27, 19] with a
special focus on developing error bounds that allow to predict the approximation error
in dependence of NFFT hyperparameters. One important ingredient of the NFFT is
the use of a window function, which is convolved with the irregular data and sampled
at equidistant points. In the past, several window functions have been proposed, of

˚University Medical Center Hamburg-Eppendorf and Hamburg University of Technology, Ham-

burg, Germany (t.knopp@uke.de, http://www.tuhh.de/ibi).

1

 
 
 
 
 
 
2

T. KNOPP, M. BOBERG, M, GROSSER

which the Kaiser-Bessel function provides the highest accuracy, since it is well localized
in time/spatial and frequency domain. Quite recently, new error bounds have been
derived for diﬀerent window functions [21] including the Kaiser-Bessel window [20].

Beside this theoretical work, there is also a strong demand for high-quality fast
software packages implementing the NFFT. While the algorithm itself has a rather
simple mathematical notation, a straight forward textbook implementation would
suﬀer from suboptimal performance and be orders of magnitude slower than a tuned
software library. For this reason, several high-performance NFFT libraries like NFFT3
[12] and FINUFFT [2] have been developed in the past. NFFT3 was developed in
the late 2000s, is written C and supports multi-threading. In addition to the NFFT
it oﬀers algorithms for the non-equidistant fast cosine transform (NDCT) and the
non-equidistant fast sine transform (NDST). Two important features of NFFT3 are
the ability to apply the algorithm to arbitrary dimensional signals and the ability to
cache window function evaluations for faster computation. FINUFFT was developed
in the late 2010s, is written in C++ and provides two major innovations: First, it uses
a new window function that can be evaluated in a fast manner. Second, it uses a new
multi-threading approach for the adjoint NFFT using a block-partitioning strategy.
In combination with highly tuned C++ code, these two innovations make FINUFFT
one of the fastest NFFT implementations developed to date. The NFFT has also been
implemented on graphical processing units (GPU) [24, 17, 13, 28, 23], which can give
additional speedups over CPU implementations but is not in the scope of the current
paper.

When developing a new NFFT software library, there is a certain design space to

be explored. An implementation can

1. be generic, i.e. allowing for diﬀerent ﬂoating point types (Float32/Float64),
2. be dimension-agnostic,
3. allow changing the window function,
4. allow changing the precomputation strategy,
5. be fast/multi-threaded,
6. be readable/maintainable,
7. be re-usable/binding friendly.

Since not all of these goals can be achieved at the same time, certain compromises
must be made, which also depend on the programming language being used. Both
NFFT3 and FINUFFT are implemented in C/C++ and made the following design
decisions:

‚ Both libraries are partly generic, i.e. they allow for Float32 and Float64
ﬂoating point types. To avoid manual code duplication, the number type
is deﬁned using a C macro allowing for automatic code copies and textual
replacements. In fact, most of the NFFT3 code is written in macro form to
avoid code duplication.

‚ It is diﬃcult to achieve a fast and dimension-independent implementation in
C at the same time. This is because a static dimension, known at compile
time, allows the compiler to generate much more eﬃcient machine code. In
particular nested for loops slow down code execution signiﬁcantly if they
are emulated in a dimension-agnostic fashion during runtime. Both libraries
solve this problem by independent and redundant implementation of speciﬁc
dimensions (NFFT3: 1D–5D, FINUFFT: 1D–3D). NFFT3 has an additional
dynamic and slow fallback for higher dimensions while FINUFFT is restricted
to 1D–3D. Thus, speed and dimension-agnosticity can be combined in C but
this decreases the code readability/maintainability.

NFFT.jl: GENERIC AND FAST IMPLEMENTATION OF THE NFFT

3

‚ Hardcoding the window function can lead to additional speedups since it
avoids a dynamic dispatch in a hot code path. For this reason the window
function is a compile time option in NFFT3 while it is hardcoded in FIN-
UFFT.

The purpose of this work is to develop a new NFFT package that makes less trade-
oﬀs than its C/C++ counterparts. Our package, named NFFT.jl, is implemented in
the programming language Julia [4], which was ﬁrst published in 2012 and has since
then been developed into a popular programming language for scientiﬁc computing.
Julia code can be both high-level like Matlab/Python and low-level like C/C++. The
resulting machine code is usually as fast as comparable C/C++ machine code. This
is achieved by a proper language design and the use of a just-in-time (JIT) compiler
that allows to dynamically generate eﬃcient machine code during runtime. Nowadays,
Julia also supports multi-threading, which originates back to the prototype published
in [14].

This paper outlines the key implementation aspects of NFFT.jl and makes an
in-depth performance analysis compared to NFFT3 and FINUFFT. Since the archi-
tecture of NFFT.jl is rather ﬂexible, we were able to implement several features that
are only available in either NFFT3 or FINUFFT. This allows us to compare and
benchmark certain implementation strategies within the same code base. We also
make algorithmical improvements to the strategies proposed in [2], making NFFT.jl
one of the fastest NFFT implementation developed to date.

2. Mathematical Description. We start with a mathematical description of
the NFFT. Throughout this work, we stick to a multi-dimensional formulation and
keep the notation close to the one used in [12]. Before discussing the NFFT, we
ﬁrst introduce the underlying mathematical transform to be computed: the non-
equidistant discrete Fourier transform (NDFT).

2.1. NDFT. We let N P p2NqD be the size of the NDFT in the equidistant sam-
pling domain and D P N be its dimensionality1. We further use the multi-dimensional
index set
(2.1)

"

IN :“

n P ZD : ´

Nd
2

ď nd ď

Nd
2

´ 1, d “ 1, 2, . . . , D

“ ZD X

*

„

Dź

d“1

˙

,

´

Nd
2

,

Nd
2

representing all equidistant sampling points. The corresponding signal is denoted by
fn P C, n P IN . In the frequency domain, the signal is sampled at non-equidistant
sampling points kj “ pkd,jqD
d“1 P TD, j “ 1, . . . , J with J P N and T :“ r´1{2, 1{2q.
The resulting Fourier coeﬃcients are denoted by ˆfj P C, j “ 1, . . . , J. The (direct)
NDFT is then deﬁned as

(2.2)

ˆfj :“

fn e´2πi n¨kj ,

j “ 1, . . . , J

(equidistant to non-equidistant),

nPIN

where n ¨ kj is the standard inner product between the two sampling points. This
transformation is also known as the type-2 NDFT [2].

Remark 2.1. There are diﬀerent conﬂicting deﬁnitions of the NDFT that con-
sider the input signal to be sampled either in frequency [12] or in spatial domain [8].
Although we largely follow the notation of [12] we decided to switch frequency and

1We note that the restriction to even N is common in the NFFT literature. Some implementa-

tions such as FINUFFT also allow for odd N .

ÿ

4

T. KNOPP, M. BOBERG, M, GROSSER

spatial domain in order to make the NDFT consistent with the DFT, which is com-
monly deﬁned to map from spatial to frequency domain. We note that this change
only aﬀects notation and that the computations remain the same.

The NDFT has an associated adjoint that can be expressed as

(2.3)

yn :“

Jÿ

j“1

ˆfj e2πi n¨kj , n P IN

(non-equidistant to equidistant).

This is also named the type-1 NDFT [2] and it is related to the backward DFT. On
purpose, we used the new variable yn instead of fn since the adjoint NDFT is in
general not the inverse of the NDFT. This only holds true for special cases, i.e. for
equidistant sampling nodes and when introducing a suitable normalization factor.

The algorithmic complexity for a direct computation of the NDFT and its adjoint
D
is OpJ|IN |q where |IN | :“
d“1 Nd. This is because it requires two nested for loops,
one over the J sampling points kj and one over the |IN | equidistant sampling points
n.

ś

2.2. NFFT. We next introduce the fast realization of the NDFT. There are
diﬀerent approaches for accelerating the NDFT all having in common to use some
sort of approximation to enable the usage of one or several ordinary FFTs. In this
work, we consider the most popular and widely used approach, which uses discrete
convolutions to grid the non-equidistant signal to an equidistant signal enabling FFT
usage. The basic idea of this approach is to exploit the convolution theorem, which
states that a convolution in frequency domain corresponds to a multiplication in
spatial domain. To exploit this, one introduces an artiﬁcial convolution in the non-
equidistant sampling domain with a window function ˆϕ. This is corrected in the
equidistant sampling domain by dividing by the window’s inverse Fourier transform
ϕ, i.e. applying a deconvolution. The key point is that the artiﬁcial convolution
allows to switch from equidistant to non-equidistant sampling points and makes it
possible to ﬁrst use the FFT to switch domains and then apply the regridding. The
grid on which the FFT is applied is chosen to be larger than the grid on which the
equidistant input signal is sampled. To this end, a so-called oversampling factor σ ą 1
is introduced and an oversampled grid of size ĂN “ σN is considered. σ impacts the
accuracy of the NFFT and in practice it is chosen in the range r1.25, 2s with 2 being
the common default value. Smaller values decrease the accuracy of the NFFT but
reduce the memory requirement and are therefore commonly used for large transforms
of high dimensionality.

In summary, the NFFT consists of three steps:

1. deconvolution in equidistant domain
2. fast Fourier transform
3. convolution to map from equidistant to non-equidistant domain

2.2.1. Direct NFFT. We next provide a short derivation of the NFFT and
start with the D-dimensional window function ˆϕ : RD Ñ R, which is based on a
one-dimensional version ˆϕBase : R Ñ R using the tensor product
¸

˜

(2.4)

ˆϕpkq “ ˆϕpk1, . . . , kDq “

ˆϕBase

d“1

Dź

rNd
m

kd

.

Here, m ! Nd is the second hyperparameter of the NFFT that controls the width
of the window function. The window function ˆϕ is chosen in such a way that it is

NFFT.jl: GENERIC AND FAST IMPLEMENTATION OF THE NFFT

5

even and well localized in spatial and frequency domain. Due to the tensor product
structure of ˆϕ, its inverse Fourier transform ϕ can be expressed as a tensor product
as well:

(2.5)

ϕpnq “ ϕpn1, . . . , nDq “

Dź

d“1

m
rNd

ϕBase

˙

nd

.

ˆ

m
rNd

Moreover, ϕ is real because of the even symmetry of ˆϕ. Finally, we require ϕpnq ‰ 0
for n P IN , which is fulﬁlled for the commonly used window functions.

The ansatz for deriving the NFFT is based on the inverse Fourier transform

(2.6)

ϕpnq “

ż

RD

ˆϕpkqe2πi n¨kd k “

ż

ÿ

rPZD

TD

ˆϕpk ` rqe2πi n¨pk`rqd k.

When considering n P ZD we can exploit the periodicity of the complex exponential
(e2πi n¨pk`rq “ e2πi n¨k) and introduce the one-periodization of the window function
˜ϕpkq :“

rPZD ˆϕpk ` rq yielding

ř

ϕpnq “

ż

TD

˜ϕpkqe2πi n¨kd k.

Applying the substitution k Ñ k ´ k1 results in

ż

(2.7)

ϕpnq “

TD

˜ϕpk ´ k1qe2πi n¨pk´k1qd k1.

Dividing by ϕpnq and e2πi n¨k yields

(2.8)

e´2πi n¨k “

ż

TD

1
ϕpnq

˜ϕpk ´ k1qe´2πi n¨k1

d k1.

Now we approximate the integral on the right hand side using a rectangular quadrature
rule with ĂN “ σN sampling nodes yielding

(2.9)

e´2πi n¨k «

1
|I ĂN |ϕpnq

ÿ

lPI ĂN

˜ϕpk ´ l m

ĂN qe´2πi n¨pl m

ĂN q

where m denotes the element-wise division. This means, we can approximate a com-
plex exponential sampled at any k P TD using a sum of shifted complex exponentials.

Inserting the approximation (2.9) into the NDFT (2.2) yields

(2.10)

ÿ

ˆfj «

˜ϕpkj ´ l m

ĂN q

ÿ

lPI ĂN

nPIN
looooooooooooooooooomooooooooooooooooooon
looooooooooooooooooooooooooooooooomooooooooooooooooooooooooooooooooon

DFT

e´2πi n¨pl m

ĂN q

.

fn
|I ĂN |ϕpnq
loooomoooon
deconvolution

convolution

One can see that the convolution (last step) allows to use the FFT (second step) since
ĂN are now equidistant. To correct for the convolution, the
the sampling nodes l m
inner part ﬁrst applies a deconvolution.

Until now, we have not yet made the algorithm any faster than a direct evaluation
of the NDFT since the convolution requires OpJ|I ĂN |q operations. In order to do so,

6

T. KNOPP, M. BOBERG, M, GROSSER

we need to exploit that the window function ˆϕ is well localized and thus close to
zero for most of the evaluations performed during the convolution. To exploit this
d“1 and deﬁne the truncated
formally, we truncate ˆϕ at ˘m m
window function

ĂN with m “ pmqD

(2.11)

ˆψpkq :“

#

ˆϕpkq

for k P

ś

D

d“1r´ m
ĂNd

, m
ĂNd

q

0

otherwise

ś

with support supp ˆψ “
ˆϕBase truncated to r´1, 1q.
ř

D

d“1r´ m
ĂNd

In the same way ˆψBase is deﬁned to be
Instead of ˆψ, we require its one-periodization ˜ψpkq :“

, m
ĂNd

q.

ˆψpk ` rq. Replacing ˜ϕpkq by ˜ψpkq in (2.10) yields

rPZD

(2.12)

ˆfj «

ÿ

lPI ĂN ,mpkj q

˜ψpkj ´ l m

ĂN q

ÿ

nPIN

fn
|I ĂN |ϕpnq

e´2πi n¨pl m

ĂN q,

with the multi-index set

(2.13)

I ĂN ,mpkq :“

!
l P I ĂN : Dp P Z p´m m

ĂN ď k ´ l m

ĂN ` p1 ă m m

)
ĂN q

,

d“1. This is the set of indices l for which kj ´ l m

ĂN P suppp ˜ψq and
where 1 “ p1qD
in turn other indices can be dropped without changing the result of the computation.
rNd elements of I ĂN .
It has at most 2mD elements, which is much less than the
In particular, the number of elements is independent of ĂN . For the implementation
described in section 3 we require an alternative formulation of the index set I ĂN ,mpkq,
which separates the individual dimensions:

D
d“1

ś

I ĂN ,mpkq “

Dź

d“1

IĂNd,mpkdq with IĂN ,mpkq “ tωn,mpk, (cid:96)q : (cid:96) P t1, . . . , 2muu.

Here, the function ωĂN ,m : T ˆ t1, . . . , 2mu Ñ IĂN with

ωĂN ,mpk, (cid:96)q “ pr

rN pk mod 1q ´ m ` (cid:96) ´ 1s mod rN q ´

rN
2

allows to calculate the index set directly taking account the index wrap due to the
periodization of the window function ˜ψ.

The direct NFFT is summarized in Algorithm 2.1:
1. In the ﬁrst step, the deconvolution is applied. To this end, the input data fn
is divided by the inverse Fourier transform of the window function ϕpnq for
each n P INNN . The output of the deconvolution is stored in a new temporary
, which is deﬁned on the ﬁne grid I ĂN . The ﬁrst step of
vector g “ pgnqnPI ĂN
the NFFT thus also applies the zero padding necessary for the in-place FFT
in the second step of the algorithm.

2. In the second step, an ordinary D-variate FFT is applied. It operates in-place
but to keep the mathematical notation sound, we introduce the output vector
ˆg “ pˆglqlPI ĂN

.

3. In the third step, the discrete convolution is applied.

NFFT.jl: GENERIC AND FAST IMPLEMENTATION OF THE NFFT

7

Algorithm 2.1 Direct NFFT
Input: D, m P N, N , ĂN P 2ND, with ĂN “ σN and σ ą 1,

non-equidistant sampling points kj P TD, j “ 1, . . . , J,
equidistantly sampled signal fn P C, n P IN

#

1: for n P I ĂN do
fn
|I ĂN |ϕpnq
0

gn “

2:

3: end for
4: for l P I ĂN do
ˆgl “
5:

ÿ

gne´2πin¨pl m

ĂN q

for n P IN
for n P I ĂN zIN

Ź Deconvolution

Ź FFT

nPI ĂN

6: end for
7: for j “ 1, . . . , J do
ˆgl
8:

ˆfj “

ÿ

˜ψpkj ´ l m

ĂN q

Ź Convolution

lPI ĂN ,mpkj q

9: end for

Output:
Complexity: Op|I ĂN | log |I ĂN | ` mDJq

non-equidistantly sampled signal ˆfj P C, j “ 1, . . . , J

2.2.2. Adjoint NFFT. The adjoint NFFT is based on the same idea as the

direct NFFT. Inserting (2.9) into (2.3) and replacing ˜ϕ by ˜ψ yields
¨

˛

(2.14)

yn «

1
|I ĂN |ϕpnq

ÿ

lPIN

˚
˝

ÿ

ĂN q
looooooooooooooooooomooooooooooooooooooon

˜ψpkj ´ l m

(cid:124)
ĂN ,m

ˆfj

jPI

plq

‹
‚

e2πi n¨pl m

ĂN q

.

looooooooooooooooooooooooooooooomooooooooooooooooooooooooooooooon

convolution

looooooooooooooooooooooooooooooooooooooomooooooooooooooooooooooooooooooooooooooon

adjoint DFT

deconvolution

Here, the index set I

(cid:124)
ĂN ,m

plq is deﬁned as

(2.15)
(cid:124)
ĂN ,m

I

!
j P t1, . . . , Ju : Dp P Z p´m m

plq :“

ĂN ď kj ´ l m

ĂN ` p1 ă m m

)
ĂN q

and again allows to perform the inner convolution over only a subset of the original
indices. One can also see that the adjoint NFFT applies the three steps in reverse to
the direct NFFT. The adjoint NFFT is summarized in Algorithm 2.2:

1. In the ﬁrst step, the non-equidistantly sampled signal ˆfj is convolved with
the one-periodic window function ˜ψ yielding the equidistantly sampled signal
plq at which ˜ψ is
ˆgl. The sum is restricted again to the subset of indices I
non-zero. However, the adjoint convolution needs a diﬀerent evaluation order
than indicated by the summation. The reason is that it is very in-eﬃcient to
plq during the summation. Instead, one uses two for loops:
determine I
the inner looping over l P I ĂN ,mpkjq and the outer looping over the sampling
points kj, j “ 1, . . . , J. This change of evaluation order means that the direct
and the adjoint convolution have a very similar structure. The only diﬀerence

(cid:124)
ĂN ,m

(cid:124)
ĂN ,m

8

T. KNOPP, M. BOBERG, M, GROSSER

Algorithm 2.2 Adjoint NFFT
Input: D, m P N, N , ĂN P 2ND, with ĂN “ σN and σ ą 1,

non-equidistant sampling points kj P TD, j “ 1, . . . , J,
non-equidistantly sampled signal ˆfj P C, j “ 1, . . . , J

1: for l P I ĂN do
ÿ
ˆgl “
2:

jPI

(cid:124)
ĂN ,m

plq

ˆfj

˜ψpkj ´ l m

ĂN q

3: end for
4: for n P I ĂN do
gn “
5:

ÿ

ˆgle2πin¨pl m

ĂN q

lPI ĂN

6: end for
7: for n P INNN do
yn “ gn
8:
9: end for

|I ĂN |ϕpnq

Ź Convolution

Ź adjoint FFT

Ź Deconvolution

Output:
Complexity: Op|I ĂN | log |I ĂN | ` mDJq

equidistantly sampled signal yn P C

is that the summation over l has no data dependency for the direct transform
while the adjoint transform needs to perform additive vector updates on ˆg,
which cannot be performed concurrently for diﬀerent nodes kj.

2. The second step is a D-variate adjoint FFT.
3. The third step is the deconvolution. Similar to the direct transform, only the

subset of g on the grid IN needs to be considered in this step.

2.2.3. Matrix-Vector Notation. The NFFT can be written in matrix-vector
notation, which is helpful for conceptual understanding and also can be used for
actual implementations (see discussion about GPU implementations in section 6). In
matrix-vector form, the NFFT can be expressed as

ˆf “ Af “ BF Df

where A “

`

e´2πi n¨kj

˘

j“1,...,J;nPIN
´

P CJˆ|IN | is the NDFT matrix, f “ pfnqnPIN P
¯
ˆfj
P CJ is the output vector. The ﬁrst NFFT

J

C|IN | is the input vector, and ˆf “
step is the multiplication with the generalized diagonal matrix

j“1

ˆ

D “

δl,n

˙

1
|I ĂN |ϕpnq

P R|I ĂN |ˆ|IN |

lPI ĂN ;nPIN

where δ is the Kronecker symbol. The second step is the application of the Fourier
matrix

´

F “

e´2πi n¨pl m

¯

ĂN q

P C|I ĂN |ˆ|I ĂN |.

nPI ĂN ;lPI ĂN

The last step is the multiplication with the sparse matrix

(2.16)

B “

´
˜ψpkj ´ l m

¯
ĂN q

P RJˆ|I ĂN |

j“1,...,J;lPI ĂN

NFFT.jl: GENERIC AND FAST IMPLEMENTATION OF THE NFFT

9

having at most p2mqDJ non-zero entries. The adjoint NFFT in matrix-vector form
is obtained by reversing the order of the three matrices and applying the adjoint
operator to each step individually:

y “ AH ˆf “ D(cid:124)F HB(cid:124) ˆf

2.2.4. Algorithmic Complexity. The algorithmic complexity of the direct

NFFT and its adjoint is

Op

|I ĂN |
loomoon
deconvolution

` |I ĂN | log |I ĂN |
loooooomoooooon
FFT

` p2mqDJ
looomooon

convolution

q “ Op|I ĂN | log |I ĂN | ` mDJq
ˆ

ˆ

“ O

|IN | log |IN | ` log

˙

˙

J

.

1
ε

Here, we assumed in the last step that σ is constant (e.g. σ “ 2), and that the accuracy
ε improves exponentially with the kernel parameter m. The latter is fulﬁlled for all
commonly used window functions.

Beside this theoretical consideration, the actual performance of the NFFT and
its individual steps highly depends on the dimensionality and the size of the problem.
The deconvolution step is the cheapest one and can usually be neglected in terms of
computation time. In the most common setting (J « |IN |), the FFT is the second
fastest operation and the convolution is the primary bottleneck being up to one order
of magnitude slower. This is the reason, why NFFT implementations usually put
most eﬀorts into optimizing the convolution as much as possible. However, in sparse
sampling settings (J ! |IN |) the FFT can become a dominant factor if the convolution
is done properly. In multi-threading applications it is thus important to parallelize
all parts of the NFFT. Otherwise even the deconvolution can become a bottleneck.

3. Implementation. After formulating the NFFT and its adjoint in mathemat-
ical notation we next focus on our software package NFFT.jl. Looking back to the
design goals sketched in the introduction we put the highest priority on a generic,
dimension-agnostic and fast/multi-threaded implementation. The second most im-
portant property is to keep the code readable and maintainable. Finally, we also
want our implementation to be ﬂexible and allow to change window functions and
precomputation strategies with low eﬀort. Reusability in diﬀerent programming lan-
guages was not a top priority during the design of NFFT.jl but we sketch potential
strategies for using NFFT.jl in programming languages other than Julia in section 6.

3.1. Example Usage. A typical example usage of NFFT.jl for a 2D transfor-

mation is outlined below:

1 using NFFT
2
3 D = 2
4 J = 32*32
5 N = (32, 32)
6 k = rand(D, J) .- 0.5
7
8 p = NFFTPlan(k, N; m=4, σ=2)
9
10 f = randn(Complex{Float64}, N)
11 fHat = p * f
12 y = adjoint(p) * fHat

# dimensionality
# number of sampling points
# input signal size
# sampling points in [-0.5,0.5]^D

# create the NFFT plan

# signal to be transformed
# compute direct NFFT
# compute adjoint NFFT

10

T. KNOPP, M. BOBERG, M, GROSSER

For simplicity, the input signal and the sampling nodes are initialized with random
numbers. Based on the signal size N (line 5) and the sampling nodes k (line 6), an
NFFTPlan object is created in line 8. The constructor takes care of allocating all nec-
essary memory for temporary arrays and performing precomputations to make later
transformations as fast as possible. This precomputation approach is very common in
scientiﬁc programming. The actual NFFT’s are applied in line 11 (direct) and 12 (ad-
joint). Since the NFFT can be interpreted as a matrix-vector multiplication, NFFT.jl
uses the method * to express the transformation. The method adjoint creates a lazy
wrapper type that allows * to call the adjoint transformation. In this way the syntax
is very close to the mathematical notation. The chosen interface also matches the
common naming scheme and coding pattern used for linear transformations in the
Julia ecosystem.

In our example, the output vector was allocated within the * method. To avoid

this allocation one can use the interface

1 mul!(fHat, p, f)
2 mul!(y, adjoint(p), fHat)

which allows to pass the output vector as the ﬁrst argument. Internally, * is imple-
mented as a small wrapper around mul!. Again, mul! is a standard method in Julia
to express in-place linear transformations. Finally, there is also a high-level interface

1 nfft(k, f; m=4, σ=2)
2 nfft_adjoint(k, N, fHat; m=4, σ=2)

that automatically creates a plan before calling the low-level NFFT functions. This
is convenient if the NFFT is applied only once.

3.2. Memory Management. NFFTPlan is a struct holding several temporary

arrays required by the NFFT. In particular it holds:

‚ the temporary vector ˆg.
‚ the forward and backward plan of the inner FFT.
‚ diﬀerent index and data vectors related to the convolution (see subsection 3.7)

and the deconvolution (see subsection 3.5).

The concrete number of data that the plan holds depends on the precomputation
strategy (see subsection 3.7.4). Furthermore, the block-partitioning strategy discussed
in section subsection 3.7.2 also needs additional memory.

3.3. Generic Types. One important design goal of NFFT.jl is the ability to use
diﬀerent number types. In Julia, this can be done by introducing a type parameter T,
which can be any ﬂoating point number type. We restrict all real data types (like the
input nodes k and the precomputed window function entries) to be of type T while
complex values like the input and output vectors of the NFFT are of type Complex{T}.
This forcing of a common number type is important for optimal performance, as the
need for type promotion is removed. The type T is encoded in the NFFTPlan type and
allows the JIT compiler to generate dedicated machine code for each number type.
Index types are all stored as 64-bit integers, which is the native integer number type
In principle a ﬂexibilization of the index type is straight
on most modern CPU’s.
forward but this will only be considered if the current restriction to 64-bit integers
poses a real problem.

3.4. Dimension-Agnostic Implementation. The second important design
goal of NFFT.jl is to be dimension-agnostic. This is achieved by an integer parameter

NFFT.jl: GENERIC AND FAST IMPLEMENTATION OF THE NFFT

11

D, which allows to encode the dimension in the NFFTPlan. This ensures the genera-
tion of dedicated machine code for each dimension. For instance, the signal size N is
stored as a ﬁxed size tuple N::NTuple{D,Int64}. Besides these storage aspects, the
real challenge is to implement the actual calculations in a dimension-agnostic way.
Two possible solutions to tackle this challenge are:

1. Write dedicated implementations for each dimension D.
2. Implement multi-dimensional loops using iterators that treat D as a runtime

parameter.

The ﬁrst solution ensures maximum performance but leads to code duplication. This is
problematic since code changes need to be done in all copies of the code thus increasing
the maintainability cost. The second solution can be implemented with less code and
without any duplication but it has the downside of being much slower because the
compiler cannot emit fast machine code. Because of these downsides we considered
neither of these two solutions. Instead, we exploit that Julia’s architecture enables
the implementation of fast and generic dimension-agnostic Cartesian iterators. During
the development of Julia, two diﬀerent Cartesian iterator types have been established.
The ﬁrst option named CartesianIndices is iterator-based and allows to iterate over
a D-dimensional array A with

1 for i in CartesianIndices(A)
2
3 end

A[i] = ...

Since the dimension D is a parameter of the array A, the JIT compiler is able to generate
eﬃcient code for CartesianIndices-based for loops. The second option, which was
developed much earlier, is a macro-based solution available in the Base.Cartesian
module. A dimension-agnostic loop using Base.Cartesian is formulated as

1 @nloops $D i A begin
2
3 end

@nref $D A i = ...

and generates the following code for D = 3:

1 for i_3 = axes(A, 3)
2

for i_2 = axes(A, 2)

for i_1 = axes(A, 1)

A[i_1, i_2, i_3] = ...

end

3

4

5

end

6
7 end

This looks exactly like a hand-written implementation for a given dimensionality
with the important diﬀerence, that the code is automatically specialized for the array
dimension D. In NFFT.jl, we mainly use the CartesianIndices-based solution, since
it is easier to read and maintain. However, in cases, where more ﬂexibility and control
is needed, we use the Base.Cartesian macros. In particular, we use it in situations
where the inner and the outer for loop is handled diﬀerently, which allows to apply
multi-threading only to the outer for loop.

3.5. Deconvolution. The deconvolution (and its adjoint) is a simple element-
wise operation. Due to oversampling, the input and output array don’t have the same

12

T. KNOPP, M. BOBERG, M, GROSSER

size but the iteration only runs over IN . To this end, we use Base.Cartesian and
multi-thread the most outer for loop.

One important implementation detail of the deconvolution is to take the indices
of the later FFT into account. The FFT is usually deﬁned with a sum running from
0 to rNd ´ 1 while the FFT within the NFFT needs to be performed on the grid
ĂNd
2 ´ 1. Accordingly, an fftshift needs to be
I ĂN with indices running from ´
performed. To avoid having to perform an extra step, we integrate the index mapping
into the deconvolution step and thus only need to touch each point once.

ĂNd
2 to

The primary bottleneck of the deconvolution is the evaluation of the function ϕ.
While this can often be neglected because the convolution is much more expensive,
there are situations, such as 1D transforms with J ! |IN |, where the deconvolution
can become a bottleneck. Therefore we perform two optimizations:

1. We cache ϕ so that it can be reused when applying many NFFTs to diﬀerent
data. Here we can exploit the tensor product structure of ϕ and cache the
vectors

βtensor
d

“

˘

`

βtensor
nd,d

,

βtensor
nd,d “

ndPINd

During the deconvolution we can then calculate

m ϕBase

1
´

¯ ,

d “ 1, . . . , D.

nd

m
ĂNd
1
|I ĂN |ϕpnq on the ﬂy using:

1: for nD P IND do
γD Ð βtensor
2:
nD,D
for nD´1 P IND´1 do
3:
γD´1 Ð γD βtensor
¨ ¨ ¨
for n1 P IN1 do

nD´1,D´1

γ1 Ð γ2 βtensor
gn Ð fnγ1

n1,1

4:
5:
6:
7:
8:
9:

end for
¨ ¨ ¨
end for

10:
11:
12: end for

ř

D
d“1 Nd memory (and evaluations of ϕ) in comparison to

Here, we used the assignment notation Ð to indicate that the temporary vari-
ables γd are updated during the loop. This form of precomputation requires
D
only
d“1 Nd,
which would be required for a full precomputation. During the actual decon-
volution, there is no real downside, since there is just one additional multi-
plication in the inner loop, which in practice is not necessary slower since the
bottleneck is the load and store operation acting on gn and fn in line 8. For
completeness NFFT.jl also has an option for full precomputation, which is
useful in the GPU prototype we sketch in section section 6.

ś

2. While the number of evaluations of ϕ is greatly reduced in the multi-dimen-
sional case, we observed a measurable inﬂuence for 1D transformations. We
|I ĂN |ϕpnq by approximating ϕ with
therefore optimize the precomputation of
a Chebyshev polynomial, which is much faster to evaluate than our default
window (Kaiser-Bessel).

1

3.6. Fast Fourier Transform. The FFT is usually not part of the NFFT im-
plementation itself. Instead one uses an existing high-performance FFT library. We

NFFT.jl: GENERIC AND FAST IMPLEMENTATION OF THE NFFT

13

chose the FFTW.jl package, which is a wrapper around the popular FFTW library [9].
An alternative is to use the binary compatible implementation from Intel’s Math Ker-
nel Library (MKL), which can be changed via a runtime switch. Right now, NFFT.jl
is hardcoded to use FFTW/MKL, while in principle it is possile to make this step
exchangable using the interface package AbstractFFTs.jl.

The FFTW package provides a planner interface to split oﬀ precomputations and
preallocations.
In NFFT.jl, the FFTWPlan is integrated into the NFFTPlan, which
separates planning from computation. Since FFTW requires a dedicated plan for
forward and backward transformation, both plans are precomputed and stored in
the NFFTPlan. The number of FFTW threads is matched to the number of threads
used for the convolution and deconvolution within the NFFT. FFTW allows to use
if mul-
the thread-pool of the Julia runtime, which enables nested parallelism, i.e.
tiple NFFT/FFT are called in parallel from diﬀerent threads, there will be no over-
commitment breaking down the performance.

3.7. Convolution. The most important and most challenging operation of any
NFFT implementation is the convolution. While the mathematical formula looks
straight forward, there can be slowdowns of more than one order of magnitude between
textbook implementations and optimized ones. We next outline the most important
aspects that should be taken into account.

3.7.1. Loop Optimization. To discuss the details of the implementation, we

recapitulate the convolution steps, which are given by

(3.1)

direct convolution:

ˆfj “

ÿ

ˆgl

˜ψpkj ´ l m

ĂN q,

j “ 1, . . . , J

(3.2)

adjoint convolution:

ˆgl “

lPI ĂN ,mpkj q
ÿ
ˆfj

jPI

(cid:124)
ĂN ,m

plq

˜ψpkj ´ l m

ĂN q,

l P I ĂN

Since the direct and adjoint transform have a very similar structure, we can share
most of the concepts and code discussed in this section. The operations (3.1) and
(3.2) can either be memory bound because of the access to ˆgl, ˆfj and kj or compu-
ĂN q. In subsection 3.7.2 and
tational bound because of the calculation of ˜ψpkj ´ l m
subsection 3.7.3 we discuss how to prevent cache misses, which substantially accel-
erates memory access time. In subsection 3.7.4 we discuss diﬀerent precomputation
strategies for accelerating the computation of ˜ψpkj ´ l m

ĂN q.

When both aspects are carefully taken into account one can perform additional
loop optimizations. While these are often applied automatically, appropriately written
code is required for the compiler to do so. The ﬁrst optimization is the usage of an
(immutable) ﬁxed-size array. This allows the compiler to allocate arrays on the stack
and keep them in CPU registers. Furthermore, it enables loop unrolling and allows
the compiler to use SIMD (single instruction multiple data) instructions for parallel
processing on a single core. In Julia it is possible to create ﬁxed-size arrays during
runtime using tuple types. We therefore create D ﬁxed-size vectors

´

¯

2m

˜ψlocal
d,j

:“

˜ψlocal
(cid:96),d,j
ˆ

(cid:96),d,j :“ ˜ψBase
˜ψlocal

,

d “ 1, . . . , D

(cid:96)“1
´
1
rNdkd,j ´ ωĂNd,mpkd,j, (cid:96)q
m

¯˙

14

T. KNOPP, M. BOBERG, M, GROSSER

and calculate (3.1) by
(3.3)

2mÿ

2mÿ

ˆfj “

˜ψlocal

(cid:96)D,D,j

(cid:96)D“1

(cid:96)D´1“1

˜ψlocal

(cid:96)D´1,D´1,j ¨ ¨ ¨

˜ψlocal

(cid:96)1,1,j ˆgl,

l “

´
ωĂNd,mpkd,j, (cid:96)dq

¯

D

d“1

.

2mÿ

(cid:96)1“1

The nested product calculation in (3.3) exploits the tensor product structure of the
window function and results in a very simple inner loop (over (cid:96)1), which can be fully
optimized by the compiler.

Remark 3.1. Local caching of the window function using the vectors ˜ψlocal

should
not be confused with precomputation of ˜ψ, which is discussed in subsection 3.7.4. This
is because the local vector ˜ψlocal
is calculated right before the convolution. Hence it is
a local computation trick, which helps the compiler to generate very eﬃcient machine
code. On the other hand, this caching can make precomputation unnecessary for larger
dimensions. This is because the calculation of all non-zero entries of the B matrix –
which might require an expensive window evaluation – has an arithmetic complexity
of OpmDq while the sum in (3.3) requires OpmDq operations. With increasing D, the
caching operation becomes negligible even for expensive window functions.

d,j

d,j

3.7.2. Block-Partitioning Motivation. The non-equidistant nature of the
sampling points kj implies that there is no natural ordering of the sampling points
in multiple dimensions. This means that subsequent sampling points kj, kj`1 can
have a large distance in TD. If this is the case, they interact with largely separated
regions in the vector ˆg. Computational-wise, this leads to cache misses and degrades
performance. This is especially a problem when using multiple threads, where cache
misses can be avoided if closely located points are processed on the same CPU core.
A second and much more severe issue comes up within the adjoint convolution
step. The direct convolution accesses ˆg only for reading, which can be done con-
currently without changing the result of the computation. The adjoint, however,
performs in-place additions acting on ˆg and results in race conditions when carried
out in parallel. Locking the access to ˆg using a mutex could solve this problem but
basically results in a serial execution since the access to ˆg is a large portion of the
computation time.
In practice, it even degrades the performance, since the CPU
pipeline cannot be optimally used because of the unpredictable locking of the access
to ˆg.

Both of the aforementioned issues have been tackled in NFFT3 [26] and FIN-
UFFT [2]. Ref. [26] proposed node sorting and 1D block-partitioning as independent
concepts for the NFFT3 library. Sorting is done with respect to the index l that is
obtained by ﬂooring ĂN d kj ´ m1 to I ĂN . Block-partitioning is performed by split-
ting ˆg in its 1D in-memory representation into T regions, where T is the number of
threads. Then, all points acting on a speciﬁc block are determined and used during
the actual computation. This approach achieves close to linear speedup with the
number of threads when the density of the sampling points is close to uniform. It,
however, yields sub-optimal scaling for non-uniform sampling density since the load is
not well-balanced. This issue was solved in [2] where a more general block-partitioning
strategy was proposed. The ﬁrst idea is to use multi-dimensional blocks, which im-
proves the data locality. The second idea is to use a ﬁxed number of points per block
yielding better load balancing. Decoupling the number of blocks from the number of
threads (i.e. use more blocks than threads) ensures that a single long-lasting thread
does not slow down the entire computation.

In NFFT.jl we followed the approach proposed in [2] with the main diﬀerence that

NFFT.jl: GENERIC AND FAST IMPLEMENTATION OF THE NFFT

15

our blocks are smaller and all have the same size. For reference, we also implement a
regular convolution without block-partitioning, which can be used to investigate the
performance gains of block-partitioning. To the best of our knowledge, both NFFT3
and FINUFFT use no block-partitioning in the direct convolution but only in the
adjoint convolution. We apply the concept to both operations.

3.7.3. Block-Partitioning Implementation. We next describe block-parti-
tioning formally. The basic idea is to split the domain TD into P P 2ND equally sized
blocks

Rp :“

˙

„

Dź

d“1

pd
Pd

,

pd ` 1
Pd

, p P IP

(3.4)

Ť

such that
pPIP
the nodes kj in a block Rp by

Rp “ TD. Based on this we can collect the indices j “ 1, . . . , J of

(3.5)

Γp :“ tj P t1, . . . , Ju : kj P Rpu .

Instead of iterating over j “ 1, . . . , J with a single for loop, we can now use two nested
for loops:

1. an outer for loop over the blocks p P IP .
2. an inner for loop over the node indices j P Γp.

U
We next partition the index set I ĂN into P blocks of size Q “
, where the
ceiling is performed in an element-wise fashion. Then, we calculate those indices
l P I ĂN which could be necessary in the convolution for the nodes in the block p. This
is the index set

Q
ĂN m P

I block
p,m :“

which has |Q ` 2m| entries.

ď

I ĂN ,mpkq

kPRp

Having deﬁned the index set I block

p,m we have everything in place to deﬁne the block-
partitioned convolution. We start with the direct convolution, which is summarized
in Algorithm 3.1. The outer loop of the algorithm runs over the blocks (line 1). For
P CQ`2m is created and the data from
each block p, a local cache ˆqp “ pˆqn,pqnPI block
ˆg is copied to ˆq (lines 2–4). Then, the inner loop over all nodes within Γp is carried
out. This loop initializes ˆfj with zero (line 6) and then performs the inner convolution
over I ĂN ,mpkjq where now the local cache ˆq is used instead of ˆg (lines 7–9). Multi-
threading the direct block-partitioned convolution is straight forward. The outer for
loop over the blocks is run in parallel (indicated by parfor) and does not need to take
data dependencies into account.

p,m

The block-partitioned implementation of the adjoint convolution is summarized
in Algorithm 3.2. In the ﬁrst step (lines 1–3), ˆg is initialized with zeros. Then, the
main outer loop over the blocks p is initiated. It ﬁrst initializes the local caches ˆq with
zero (lines 5–7). Then, for each node index j in Γp all summands acting on the local
block ˆq are added at the appropriate location (lines 9–11). Afterwards, the local cache
needs to be added to the global vector ˆg (lines 14–16). To multi-thread the block-
partitioned adjoint convolution, ﬁrst the initial loop initializing ˆg with zero is run in
parallel. Then, the main outer for loop over the blocks is multi-threaded. As a matter
of fact, the data dependency caused by the in-place addition now needs to be taken
into account. The ﬁrst loop in lines 8–12 is unproblematic, since ˆq is thread-local and

16

T. KNOPP, M. BOBERG, M, GROSSER

Algorithm 3.1 Block-Partitioned Convolution
1: parfor p P IP do
2:
3:
4:
5:

for l P I block
ˆql,p Ð ˆgn

p,m do

end for
for j P Γp do
ˆfj Ð 0
for l P I ĂN ,mpkjq do
ˆfj Ð ˆfj ` ˆql,p

6:
7:

˜ψpkj ´ l m

ĂN q

8:
9:
end for
10:
11: end parfor

end for

Ź for each block

Ź init block

Ź for each node in block

Ź inner convolution

the inner loop is run in series. However, the second loop (lines 14–16), needs to be
locked with a mutex, since otherwise diﬀerent threads would simultaneously update
values in ˆg. While this locking could potentially slowdown computation, we note
that in practice, the ﬁrst loop (lines 8–12) has a much higher workload and therefore
observed only a small scaling penalty. This is in full agreement with the observations
made in [2].

Algorithm 3.2 Block-Partitioned Adjoint Convolution
1: parfor l P I ĂN do
ˆgl Ð 0
2:
3: end parfor
4: parfor p P IP do
5:
6:
7:
8:
9:

end for
for j P Γp do

for l P I block
ˆql,p Ð 0

p,m do

for l P I ĂN ,mpkjq do
ˆql,p Ð ˆql,p ` ˆfj

˜ψpkj ´ l m

ĂN q

end for

end for
lock

10:
11:
12:
13:
14:
15:
16:
end lock
17:
18: end parfor

for l P I block

p,m do
ˆgl Ð ˆgl ` ˆql,p

end for

Ź init output array

Ź for each block

Ź init block

Ź for each node in block
Ź inner convolution

Ź critical section

Ź add to output array

Remark 3.2. In practice, the sets I block

p,m and I ĂN ,mpkjq can be calculated eﬃciently.
Both represent structured blocks within I ĂN that can be represented by just start/end
indices in each dimension.
In some cases, an index wrap needs to be taken into
account. This wrapping can be implemented eﬃciently by precalculating the wrapping
indices for each block. In the actual implementation, all indices are shifted to positive
indices with an additional index oﬀset that needs to be taken into account during the
calculation. The loop over I ĂN ,mpkjq can be implemented without wrapping since ˆq
contains extra padding, i.e. wrapping only needs to be taken into account in the for
loop in lines 2–4 of the direct convolution and lines 14–16 of the adjoint convolution.

NFFT.jl: GENERIC AND FAST IMPLEMENTATION OF THE NFFT

17

3.7.4. Window precomputation. Next we discuss diﬀerent strategies to avoid
large computational cost of the window function evaluation. In the literature (e.g.
[18] and [2]), we found the following options:

1. No precomputation

One can directly evaluate the window during the application of the convolu-
tion. Depending on the window, this can lead to very slow runtimes if the
window evaluation is expensive.

2. Full precomputation

Another common strategy is to compute all window entries prior to the trans-
formation. There are diﬀerent variants for this, either one can keep the in-
dexing logic the same and just use the cached window entry if needed. Al-
ternatively one can go one step further and represent the entire convolution
as a multiplication with a sparse matrix B, see (2.16). This requires storing
the indices of the non-zero entries in B.
3. Tensor product based precomputation

The tensor product approach is similar to full computation but calculates the
window function in each direction separately. This is basically the same as
using the local caches ˜ψlocal
d,j with the exception that the caches are stored
globally for all nodes kj. Pulling all window entries into the inner sum, as
full precomputation would do, is in many situations slower, since it increases
the memory bandwidth, while the local tensor caching approach (with and
without precomputation) is CPU bound.

4. Linear interpolation based precomputation

A common pattern to speed up the evaluation of the window function is linear
interpolation. To this end, during precomputation a lookup table

(3.6)

˜ψlinear :“

¯

´
˜ψlinear
s

S´1

s“0

with

˜ψlinear
s

:“ ˜ψBase

˙

ˆ

s
S ´ 1

is created where S is the number sampling points. During convolution one
then needs to perform the look-up
¯˙
ˆ

˜ψBase

´
rNdkd,j ´ ld

1
m

« ˜ψlinear
˜s

` α p ˜ψlinear

˜s`1 ´ ˜ψlinear

˜s

q

where

´

ˇ
ˇ
ˇ
ˇ

S ´ 1
m

κ “

rNdkd,j ´ ld

¯ˇ
ˇ
ˇ
ˇ ,

˜s “ tκu , α “ κ ´ tκu .

When choosing S ´ 1 to be a multiple of m (i.e. S “ mY ` 1, Y P N), it
is possible to perform the calculation of κ, ˜s, α only once and increase ˜s with
a constant oﬀset when iterating ld through the index set IĂNd,m. The error
of the linear interpolation depends on S, i.e. the larger S, the smaller is the
error. NFFT3 provides experimentally determined values for S, which keep
the window approximation error for speciﬁc m below the entire NFFT error.
For instance, for the Kaiser-Bessel window they can be written as

S “ m2cminpm,8q ` 1, C “ pcmq8

m“1 “

`

3

7

9

14

17

20

23

˘
24

.

Performance-wise it turns out that this method works well for small m ă 5
but larger m require very large look-up tables. For instance, m “ 8 and the

18

T. KNOPP, M. BOBERG, M, GROSSER

Kaiser-Bessel window requires 134217729 entries (1 GB in double precision).
This large amount of memory makes the operation much slower for large m
since the look-up table does not ﬁt into cache anymore and the convolution
basically needs to run over the entire look-up table with a spacing of S´1
m in
2m steps.

5. Polynomial approximation based precomputation

An alternative window approximation was proposed in [2]. It uses piecewise
polynomial approximation with a high polynomial degree. The idea is to split
the window into 2m parts and perform polynomial approximation indepen-
˘
“
dently on each interval
, (cid:96) “ 1, . . . , 2m by setting
´1 ` p(cid:96) ´ 1q{m, ´1 ` (cid:96){m
up the Vandermonde matrix V and the corresponding sampling vector b:
˙
z

ˆˆ

˙

V “

´

ˆ

ϑ
Θ ´ 1

1
2

`

ˆ

b(cid:96) “

˜ψBase

´1 `

ϑ“0,...,Θ´1;z“0,...,Z´1

˙˙˙

ˆ

1
m

(cid:96) ´ 1 `

ϑ
Θ ´ 1

,

Θ´1

ϑ“0

.

The polynomial coeﬃcients µ(cid:96) “ pµz,(cid:96)qZ´1
z“0 are then calculated by solving
µ(cid:96)Ñ min. The reason to consider the
the least-squares problem }V µ(cid:96) ´ b(cid:96)}2
least-squares problem is that we apply oversampling and choose more sam-
pling points than the polynomial degree Θ “ 2Z, which leads smaller errors.
We thus are in the approximation setting and not the interpolation setting.
During convolution the polynomial approximation uses the lookup

˜ψBase

ˆ

1
m

´
rNdkd,j ´ ωĂNd,mpkd,j, (cid:96)q
]

Y
rNdkd,j

¯˙

«

Z´1ÿ

z“0

µz,(cid:96) ζ z,

(cid:96) “ 1, . . . , 2m

rNdkd,j ´

´ 1

where ζ “
2 . By using 2m intervals, the position ζ is
the same for all intervals and therefore only the weights µz,(cid:96) need to change
when iterating through (cid:96) “ 1, . . . , 2m.
Our polynomial approximation implementation is slightly diﬀerent then the
one implemented in FINUFFT. In particular we sample the window function
equidistantly on the real line, while FINUFFT uses a sampling of a square
in the complex space, which is taylored to the speciﬁc window function used
in FINUFFT. In our experiments a polynomial degree of Z ´ 1 “ 2m ´ 1 is
suﬃcient to keep the window function approximation error below the NFFT
error, while [2] reported 2m ` 3 to be necessary. This might be due to the
diﬀerent sampling when setting up the approximation problem or the diﬀerent
window function being used.
In contrast to FINUFFT, which hardcodes
the polynomial coeﬃcients for a speciﬁc set of m/σ in a C ﬁle generated
by a Matlab script, NFFT.jl setups the coeﬃcients µz,(cid:96) on the ﬂy during
precomputation.

Table 1 summarizes the memory requirement for the diﬀerent precomputation op-
tions. The least memory is required for no precomputation followed by polynomial
approximation, which eﬀectively always requires less than or equal to 512 entries tak-
ing into account that machine precision is reached for m “ 8. Full and tensor product
precomputation are more expensive since they have a per node cost. For D ą 1
tensor precomputation requires much less memory then full precomputation. Linear
interpolation is diﬃcult to classify, since it can require less memory than full/tensor

NFFT.jl: GENERIC AND FAST IMPLEMENTATION OF THE NFFT

19

Table 1
Memory requirement for diﬀerent window function precomputation strategies.

Precomputation Memory [# values]
-
No
p2mqDJ
Full
2mDJ
Tensor
S “ mY ` 1
Linear
2p2mq2
Polynomial

precomputation for small m and large J but also require more memory for large m
and small J.

We implemented all precomputation strategies except for no precomputation in
NFFT.jl. They can be changed by passing the precompute option to the NFFTPlan
and setting it to one of the enum values FULL, TENSOR, LINEAR, or POLYNOMIAL. The
reason for not implementing no precomputation is that an eﬃcient implementation of
this option with exchangeable window function requires making the window function
a type parameter of the NFFTPlan. Since direct evaluation is known to be slower
than polynomial interpolation even for cheap windows (see the discussion in [2]), we
refrained from implementing no precomputation to avoid an increase in software com-
plexity. Tensor product precomputation is combined with polynomial approximation
in NFFT.jl, i.e. the precomputation is accelerated with polynomial approximation
when using the TENSOR option.

Having a look at the two reference libraries, NFFT3 supports the ﬁrst four pre-

computation strategies, while FINUFFT supports only polynomial approximation.

, m
ĂNd

, m
ĂNd

3.7.5. Window Size Considerations. We deﬁned the truncated window func-
tion ˆψ to have a support of r´ m
q along dimension d. This means that the sum
ĂNd
within the convolution has p2mqD non-zero summands. When considering the support
r´ m
s, as commonly done in the literature, one needs to consider the special case
ĂNd
ĂN and in turn the sum has
that a node kj lies exactly on the grid speciﬁed by l m
p2m ` 1qD summands. In principle one could switch between p2m ` 1qD and p2mqD
by checking if kj lies on the grid. But this would actually harm the performance,
since an if statement in a hot loop would need to dynamically switch between p2mqD
and p2m ` 1qD, which could lead to CPU pipeline ﬂushes.

Our solution mitigates the problem with the potential downside of a slightly higher
error. This, however, is very unlikely since kj would need to match a grid point exactly
in ﬂoating point precision. An alternative to our approach is implemented in NFFT3.
It considers p2m ` 2qD points and uses ˆϕ instead of ˆψ during window evaluation.
This has the advantage that no unnecessary multiplications with zero are carried out,
which would happen if ˆψ is sampled outside of its support.
In turn, this method
can lower the approximation error of the NFFT. In section 5, we investigate how
much p2m ` 2qD points improves the accuracy and whether it is better to instead use
p2mqD points and increment m, which results in the same number of operations but
a diﬀerent window shape.

4. Materials and Methods. In the remainder of the manuscript an extensive
evaluation of NFFT.jl is carried out. Both accuracy and performance are investigated
and compared to NFFT3 and FINUFFT.

In all examples J “ |IN | random sampling points kj P TD are chosen. This is a

20

T. KNOPP, M. BOBERG, M, GROSSER

Fig. 1. Relative error of NFFT.jl for diﬀerent precomputation strategies, an oversampling
factor of σ “ 2 and window size parameters m “ 3, . . . , 10. Left shows the error of the direct
transform while right shows the error of the adjoint transform.

typical yet challenging use case and in particular the random nodes can be considered
to be the worst-case scenario an NFFT implementation needs to tackle. We use 1D–
3D datasets with N1D “ 218 “ 262144, N2D “ p512, 512q(cid:124), N3D “ p64, 64, 64q(cid:124).
The oversampling parameter is chosen to be σ “ 2 while the kernel size parameter
m is chosen between 3 and 10. For NFFT.jl and NFFT3, the Kaiser-Bessel window
(Kaiser-Bessel function for ϕ and the corresponding Fourier transform for ˆϕ) is chosen.
FINUFFT uses the exponential of semicircle kernel.

All computations were performed on a computer with 1024 GB of main memory
and an AMD EPYC 7702 CPU. NFFT.jl was used in version 0.13. FINUFFT (v2.0.4)
and NFFT3 (v3.5.2) were applied using the Julia wrapper packages FINUFFT.jl and
NFFT3.jl. Julia was used in version 1.7.3. FFTW is used by all libraries and the same
option (FFTW MEASURE) was used such that the FFT computation time is the same.
This has been veriﬁed by inspecting the inner NFFT timings, which can be accessed
for all libraries. Benchmarks are performed by repeating the same computation several
times (with a 120 seconds threshold) and using the minimum time of all runs. This
can be viewed as an estimate for the lower bound that is reached with hot CPU caches
and no other workload aﬀecting the computation. The accuracy of the NFFT and its
adjoint are determined by calculating the relative error }fNDFT´fNFFT}2
where fNDFT
is the result vector when applying the NDFT and fNFFT is the result vector of the
NFFT.

}fNDFT}2

The code for the entire analysis can be accessed in the benchmark directory of the
NFFT.jl GitHub repository, which can be found at: https://github.com/JuliaMath/
NFFT.jl.

5. Results.

5.1. Accuracy Analysis. We start the evaluation by looking at the accuracy of
the NFFT.jl for the 2D dataset. The relative error of the direct and adjoint transform
is shown for diﬀerent precomputation strategies of the window function, an oversam-
pling factor of σ “ 2 and m “ 3, . . . , 10 in Figure 1. First of all one can see that
the error decreases exponentially with the kernel parameter m. For the Kaiser-Bessel
window the optimum accuracy is reached at m “ 8 at which point the error saturates.
When comparing the diﬀerent precomputation strategies one cannot observe any dif-
ference. This is remarkable since FULL does not apply a window approximation, while
TENSOR (in NFFT.jl), LINEAR and POLYNOMIAL do. It also shows that by a proper
selection of the window approximation parameters it is possible to keep this approx-
imation error below the other approximation errors of the NFFT. Accuracy-wise, it
thus does not matter which precomputation strategy is used.

4681010−1410−1210−1010−810−6mRelativeErrorNFFTFULLTENSORLINEARPOLYNOMIAL4681010−1010−5mNFFTHNFFT.jl: GENERIC AND FAST IMPLEMENTATION OF THE NFFT

21

Fig. 2. Relative error of NFFT.jl compared to NFFT3 and FINUFFT for an oversampling
factor of σ “ 2 and window size parameters m “ 3, . . . , 10. Left shows the error of the direct
transform while right shows the error of the adjoint transform.

We next compare the accuracy between NFFT.jl, NFFT3 and FINUFFT. FIN-
UFFT does not allow to directly set the parameters σ and m but instead uses a
parameter ε, which is used to derive σ and m. By reading the source code and en-
abling debugging information, it was possible to select ε such that, for a ﬁxed value
σ “ 2, the desired values of m were obtained. The accuracy comparison is shown in
Figure 2. In a ﬁrst qualitative comparison, one can see that the errors are very simi-
lar with NFFT3 being slightly more accurate than NFFT.jl, and NFFT.jl being more
accurate than FINUFFT. When looking at the quantitative values, the mean relative
error ratio is 1.376 between NFFT.jl and NFFT3 and 2.901 between FINUFFT and
NFFT3. Here, only m “ 3, . . . , 7 have been considered since starting from m “ 8
all three libraries reach the same accuracy bounded by the machine precision. The
diﬀerences in accuracy can be explained as follows. FINUFFT uses a diﬀerent window
function, which is not as accurate as the Kaiser-Bessel window used in the other two
implementations. The diﬀerence between NFFT.jl and NFFT3 is caused by NFFT.jl
using a window of size 2m while NFFT3 uses a window of size 2m ` 2, which leads to
a slightly lower window truncation error. However, the accuracy gain by increasing
m by one – resulting in a window size of 2pm ` 1q “ 2m ` 2 – is much greater than
the gain when using 2m ` 2 points without changing the shape of the window. This
justiﬁes the choice of 2m convolution points taken by NFFT.jl and FINUFFT.

5.2. Block-Size Investigation. We next take a closer look at the convolution
and investigate the block-partitioning performance within NFFT.jl. Figure 3 shows
the runtime performance of the direct and the adjoint NFFT for diﬀerent block sizes,
diﬀerent dimensionalities (1D–3D), POLYNOMIAL precomputation, and diﬀerent num-
bers of threads (1–8). The block sizes are chosen in such a way, that the largest value
(1D: 219, 2D: p1024, 1024q(cid:124), 3D: p128, 128, 128q(cid:124)) corresponds to the usage of one
block only. This edge case results in no parallelization and thus leads to sub-optimal
performance in the multi-threaded cases. When choosing smaller block sizes also the
single-threaded performance is improved for all dimensionalities since this allows for
better usage of CPU caches. For all dimensionalities, one can see that the performance
degrades when choosing the blocks too small since in that case, the administration
overhead for the blocks becomes too high. The optimum block size diﬀers for diﬀerent
numbers of threads and the direct and adjoint transform. It ranges from 103 to 105
in 1D, from 64 to 128 in 2D, and from 16 to 32 in 3D. Based on that we set the
default value to 4096 (1D), p64, 64q(cid:124) (2D), and p16, 16, 16q(cid:124) (3D) in NFFT.jl. For
higher dimensions the block size is set to one.

In addition to the block-partitioning performance (solid), the ﬁgure also shows
the performance of the regular convolution (dashed). For the adjoint transform the

4681010−1010−5mRelativeErrorNFFTNFFT.jlNFFT3FINUFFT4681010−1010−5mNFFTH22

T. KNOPP, M. BOBERG, M, GROSSER

Fig. 3. Runtime performance of NFFT.jl for block-partitioned (solid) and regular (dashed)
convolution, 1D–3D transformations, and 1–8 threads. Left shows the runtime of the direct trans-
formation while right shows the runtime of the adjoint transformation.

latter is only available for single-threading. One can see that the block-partitioned
convolution outperforms the regular convolution in all cases when considering an
optimal block size. This shows that block-partitioning should not only be used for
the adjoint but also for the direct NFFT.

5.3. Performance Analysis. A performance comparison of NFFT.jl, NFFT3,
and FINUFFT for 1D–3D and running on a single thread is shown in Figure 4. In
addition to the runtime performance (columns 1–2) also the precomputation time
(column 3) is shown. All times are calculated for m “ 3, . . . , 8 and plotted versus the
relative error. We use this representation, since it allows to make comparisons even
if the accuracy of diﬀerent implementations diﬀers.

The runtime of NFFT.jl is shown for both POLYNOMIAL and TENSOR pre-com-
putation. One can see that the runtime performance is usually a little bit higher
for TENSOR with the downside of a larger precomputation time. This trade-oﬀ is
more prominent for the 1D and 2D transform whereas in 3D the runtimes are very
close while the precomputation times are almost negligibly small compared to the
transformation time. As a result, we decided to make POLYNOMIAL the default option
since it provides good performance and uses less memory.

When comparing the diﬀerent libraries one can see that the performance varies for

1021042−6.252−5.00Runtime/sNFFT,1D1021042−62−3NFFTH,1D1011021032−62−52−4Runtime/sNFFT,2D1011021032−62−3NFFTH,2D1thread2threads4threads8threads1011022−42−2BlockSizeRuntime/sNFFT,3D1011022−42−220BlockSizeNFFTH,3DNFFT.jl: GENERIC AND FAST IMPLEMENTATION OF THE NFFT

23

Fig. 4. Single-threading performance of NFFT.jl with the TENSOR and the POLYNOMIAL

precomputation strategy compared to NFFT3 (with TENSOR) and FINUFFT.

diﬀerent dimensionality and diﬀerent accuracy. For instance, NFFT3 and FINUFFT
are closeby in the 1D performance with NFFT3 being faster for high accuracy and be-
ing slower for low accuracy. NFFT.jl is faster in 1D and 2D with both precomputation
options. TENSOR precomputation is slightly faster than POLYNOMIAL precomputation.
In 3D, NFFT3 is slower than the other libraries while FINUFFT and NFFT.jl have
a very similar performance.

When looking at the precomputation time one can see that FINUFFT is fastest
for all dimensionalities. This is most important for 1D and 2D transforms, where the
precomputation is larger or in the same order as the transforms itself.

The multi-threading performance of NFFT.jl, NFFT3, and FINUFFT is com-
pared in Figure 5 for the 2D data (m “ 4 and σ “ 2). The upper two plots show the
runtime for t “ 1, . . . , 8 threads. One can see that all libraries speedup computation
by adding more threads although the parallel eﬃciency (lower two plots) drops with
increasing threads. The parallel eﬃciency is deﬁned as the ratio between actual and
theoretically possible speedup. It is in a similar range for all three libraries with a
slightly higher value for NFFT3. This might be due to the lock required in NFFT.jl’s
and FINUFFT’s block-partitioning implementation, which is not required in NFFT3’s
implementation.

6. Discussion. The aim of this work was to introduce the software package
NFFT.jl, which is written in pure Julia and combines high-performance with a ﬂexible
architecture. The use of Julia is not an implementation detail but, on the contrary,
enables us to make less compromises in the implementation, which would neither be
possible in high-level languages like Matlab and Python, nor in low-level languages

10−1210−1010−810−60.000.010.020.030.040.050.06Runtime/sNFFT,1D10−1210−1010−810−60.000.010.020.030.04NFFTH,1D10−1210−1010−810−60.000.020.040.060.08Precompute,1D10−1010−50.000.050.100.15Runtime/sNFFT,2D10−1010−50.000.050.100.15NFFTH,2D10−1010−50.000.050.100.15Precompute,2D10−1010−50.00.51.01.52.02.5RelativeErrorRuntime/sNFFT,3DNFFT.jl/POLYNFFT.jl/TENSORNFFT3FINUFFT10−1010−50.00.51.01.52.0RelativeErrorNFFTH,3D10−1010−50.000.050.100.150.200.25RelativeErrorPrecompute,3D24

T. KNOPP, M. BOBERG, M, GROSSER

Fig. 5. Multi-threading performance of NFFT.jl with the TENSOR and the POLYNOMIAL
precomputation strategy compared to NFFT3 (with TENSOR) and FINUFFT. Shown is the speedup
and the parallel eﬃciency for t “ 1, 2, 4, 8 threads.

like C/C++. Along these lines, our work can also be understood as a showcase of how
Julia enables new possibilities in scientiﬁc computing that are challenging to achieve
with classical tools. The highlight of NFFT.jl is a completely generic implementation
which is both number-type and dimension-agnostic.

A comparison of code complexity is not really possible since it also depends on
the programmers experience in a certain programming language, whether a code base
is found to be complex. Even a comparison of code size is diﬃcult, since the number
of characters also depends on the verbosity of keywords used in a given language.
Keeping that in mind we counted memory used by the source code of the core NFFT
algorithm for all three libraries. It is 184 KB for the kernel/nfft directory of NFFT3
and 246 KB for the src directory of FINUFFT. The latter, however, contains 106
KB of generated code, which we would not count as source code yielding 140 KB
eﬀectively.
In contrast, the src directory of NFFT.jl has 74 KB of source code.
This shows that Julia allows for using less code for achieving the same or even more
functionality than its C/C++ counterparts.

The performance of NFFT.jl was found to be the same or better than NFFT3
and FINUFFT. NFFT.jl was faster in both the 1D and the 2D examples and was at
the same speed as FINUFFT for the 3D example. Regarding precomputation time,
NFFT.jl was only slightly slower than FINUFFT and much faster than NFFT3 for
the POLYNOMIAL precomputation. NFFT.jl with TENSOR precomputation was slower
than POLYNOMIAL but still much faster than NFFT3, which is due to our polynomial
window approximation being applied during precomputation.

Beside the benchmark between diﬀerent NFFT software libraries we also made
some general ﬁndings on NFFT implementation strategies. First of all we compared
the use of 2m and 2m ` 2 sampling points for the window function and found that

24680.020.040.060.08Runtime/sNFFTNFFT.jl/POLYNFFT.jl/TENSORNFFT3FINUFFT24680.0250.0500.0750.1000.125NFFTH24680.000.250.500.751.00#threadsEfficiencyNFFT24680.000.250.500.751.00#threadsNFFTHNFFT.jl: GENERIC AND FAST IMPLEMENTATION OF THE NFFT

25

the gain in accuracy by the two additional points sampled outside the support of ˆψ
are not worth the additional accuracy, since it is more eﬀective to instead increase
the window parameter m itself, which increases the width of the window. Moreover,
we investigated diﬀerent block sizes and found dimension-dependent value ranges for
which the NFFT reaches highest performance. Since the optimum block-size is highly
dependent on the transform size, the number of used threads, and the CPU, we plan to
develop an optimization mode, where the optimum block size is automatically chosen
based on online-benchmarks, similar to the FFTW MEASURE option in FFTW.

One principle downside of NFFT.jl compared to its C/C++ counterparts is that
the latter are currently more binding-friendly than the former. We note, however,
that Julia can be embedded in C and therefore it is possible to integrate NFFT.jl in
every programming language that allows to call C code. While this still requires a
full Julia installation there is also the possibility to statically compile Julia code into
a shared library using PackageCompiler.jl. We note, however, that static compilation
of Julia code is still actively being worked on and will likely evolve in future versions
of the language.

An important future step for the NFFT.jl project is to exploit GPU implemen-
tations written in Julia. Right now, there is a prototype implementation named
CuNFFT.jl, which is fully functional and required only 125 lines of code. This is
achieved by using the FULL precomputation operation and uploading the entire sparse
matrix onto the GPU. For optimum performance, one however, would need to write
custom kernels and use a similar block-partitioning strategy as we did in the CPU
implementation.

NFFT.jl is already a feature-rich NFFT library that is used in diﬀerent contexts
[22, 11, 15]. During the write-up of this paper, we focused on ﬁxing performance
bottlenecks and streamlining the interface of the core algorithm. This does not imply,
that NFFT.jl is feature complete yet. One important extension would be the im-
plementation of the NNFFT (also named type-3 NFFT), which has non-equidistant
sampling points in both domains. Another missing feature are the fast versions of the
non-equidistant cosine and sine transforms (NFCT and NFST). Application oriented
tools – like quadrature weights for the non-equidistant sampling points – are also in
the scope of NFFT.jl. Those are implemented in the package NFFTTools.jl, which is
one layer lower in the package graph and can in principle be also used in combination
with other NFFT Julia packages such as NFFT3.jl and FINUFFT.jl.

7. Conclusion. In conclusion, this work has outlined how the scientiﬁc program-
ming language Julia can be used to implement a very ﬂexible software package for
NFFT computation. Our implementation is completely type- and dimension-agnostic
and still uses less code than established packages. We implemented state-of-the-art
acceleration techniques taken from two established NFFT libraries and showcased
their performance characteristic in 1D–3D examples.

[1] C. Anderson and M. D. Dahleh, Rapid computation of the discrete Fourier transform, SIAM

REFERENCES

Journal on Scientiﬁc Computing, 17 (1996), pp. 913–919.

[2] A. H. Barnett, J. Magland, and L. af Klinteberg, A parallel nonuniform fast Fourier
transform library based on an “exponential of semicircle” kernel, SIAM Journal on Scien-
tiﬁc Computing, 41 (2019), pp. C479–C504.

[3] G. Beylkin, On the fast Fourier transform of functions with singularities, Applied and Com-

putational Harmonic Analysis, 2 (1995), pp. 363–381.

[4] J. Bezanson, A. Edelman, S. Karpinski, and V. B. Shah, Julia: A fresh approach to nu-

merical computing, SIAM review, 59 (2017), pp. 65–98.

26

T. KNOPP, M. BOBERG, M, GROSSER

[5] J. W. Cooley and J. W. Tukey, An algorithm for the machine calculation of complex Fourier

series, Mathematics of computation, 19 (1965), pp. 297–301.

[6] A. Dutt and V. Rokhlin, Fast Fourier transforms for nonequispaced data, SIAM Journal on

Scientiﬁc computing, 14 (1993), pp. 1368–1393.

[7] J. A. Fessler, On nuﬀt-based gridding for non-cartesian MRI, Journal of magnetic resonance,

188 (2007), pp. 191–195.

[8] J. A. Fessler and B. P. Sutton, Nonuniform fast fourier transforms using min-max inter-

polation, IEEE transactions on signal processing, 51 (2003), pp. 560–574.

[9] M. Frigo and S. G. Johnson, The design and implementation of FFTW3, Proceedings of the
IEEE, 93 (2005), pp. 216–231. Special issue on “Program Generation, Optimization, and
Platform Adaptation”.

[10] D. Hillmann, G. Huttmann, and P. Koch, Using nonequispaced fast Fourier transformation
to process optical coherence tomography signals, in European Conference on Biomedical
Optics, Optical Society of America, 2009, p. 7372 0R.

[11] R. D. Jacobsen, M. Nielsen, and M. G. Rasmussen, Generalized sampling in julia, arXiv

preprint arXiv:1607.04091, (2016).

[12] J. Keiner, S. Kunis, and D. Potts, Using NFFT 3—a software library for various nonequi-
spaced fast fourier transforms, ACM Transactions on Mathematical Software (TOMS), 36
(2009), pp. 1–30.

[13] F. Knoll, A. Schwarzl, C. Diwoky, and D. K. Sodickson, gpuNUFFT - an open source
GPU library for 3D regridding with direct Matlab interface, in International Society for
Magnetic Resonance in Medicine: Scientiﬁc Meeting & Exhibition, 2014, pp. 4297–4297.

[14] T. Knopp, Experimental multi-threading support for the julia programming language, in Pro-
ceedings of the First Workshop for High Performance Technical Computing in Dynamic
Languages, IEEE Press, 2014, pp. 1–5.

[15] T. Knopp and M. Grosser, MRIReco.jl: An MRI reconstruction framework written in julia,

Magnetic resonance in medicine, 86 (2021), pp. 1633–1646.

[16] T. Knopp, S. Kunis, and D. Potts, A note on the iterative MRI reconstruction from nonuni-

form k-space data, International journal of biomedical imaging, 2007 (2007).

[17] S. Kunis and S. Kunis, The nonequispaced FFT on graphics processing units, Pamm, 12

(2012), pp. 7–10.

[18] S. Kunis and D. Potts, Time and memory requirements of the nonequispaced ﬀt, Sampling

Theory in Signal and Image Processing, 7 (2008), pp. 77–100.

[19] D. Potts, G. Steidl, and M. Tasche, Fast Fourier transforms for nonequispaced data: A

tutorial, Modern sampling theory, (2001), pp. 247–270.

[20] D. Potts and M. Tasche, Continuous window functions for NFFT, Advances in Computa-

tional Mathematics, 47 (2021), pp. 1–34.

[21] D. Potts and M. Tasche, Uniform error estimates for nonequispaced fast Fourier transforms,

Sampling Theory, Signal Processing, and Data Analysis, 19 (2021), pp. 1–42.

[22] A. Schutz, A. Ferrari, D. Mary, ´E. Thi´ebaut, and F. Soulez, Large scale 3D image recon-
struction in optical interferometry, in 2015 23rd European Signal Processing Conference
(EUSIPCO), IEEE, 2015, pp. 474–478.

[23] Y.-h. Shih, G. Wright, J. And´en, J. Blaschke, and A. H. Barnett, cuFINUFFT: a
load-balanced GPU library for general-purpose nonuniform FFTs, in 2021 IEEE Inter-
national Parallel and Distributed Processing Symposium Workshops (IPDPSW), IEEE,
2021, pp. 688–697.

[24] T. S. Sørensen, T. Schaeffter, K. Ø. Noe, and M. S. Hansen, Accelerating the noneq-
uispaced fast Fourier transform on commodity graphics hardware, IEEE Transactions on
Medical Imaging, 27 (2008), pp. 538–547.

[25] G. Steidl, A note on fast Fourier transforms for nonequispaced grids, Advances in computa-

tional mathematics, 9 (1998), pp. 337–352.

[26] T. Volkmer, OpenMP parallelization in the NFFT software library, Preprint, (2012), https:

//www-user.tu-chemnitz.de/„potts/paper/openmpNFFT.pdf.

[27] A. F. Ware, Fast approximate Fourier transforms for irregularly spaced data, SIAM review,

40 (1998), pp. 838–856.

[28] S.-C. Yang, H.-J. Qian, and Z.-Y. Lu, A new theoretical derivation of NFFT and its imple-
mentation on GPU, Applied and Computational Harmonic Analysis, 44 (2018), pp. 273–
293.

