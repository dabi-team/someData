Software Tools for Decoding
Quantum Low-Density Parity Check Codes

Lucas Berent ∗

Lukas Burgholzer‡
∗Chair for Design Automation, Technical University of Munich, Germany
‡Institute for Integrated Circuits, Johannes Kepler University Linz, Austria
†Software Competence Center Hagenberg GmbH, Hagenberg, Austria
lukas.burgholzer@jku.at

Robert Wille∗†

lucas.berent@tum.de

robert.wille@tum.de

2
2
0
2

p
e
S
2

]
h
p
-
t
n
a
u
q
[

1
v
0
8
1
1
0
.
9
0
2
2
:
v
i
X
r
a

ABSTRACT
Quantum Error Correction (QEC) is an essential field of research
towards the realization of large-scale quantum computers. On the
theoretical side, a lot of effort is put into designing error-correcting
codes that protect quantum data from errors, which inevitably hap-
pen due to the noisy nature of quantum hardware and quantum bits
(qubits). Protecting data with an error-correcting code necessitates
means to recover the original data, given a potentially corrupted
data set—a task referred to as decoding. It is vital that decoding
algorithms can recover error-free states in an efficient manner.
While theoretical properties of recent QEC methods have been
extensively studied, good techniques to analyze their performance
in practically more relevant settings is still a widely unexplored
area. In this work, we propose a set of software tools that allows
to numerically experiment with so-called Quantum Low-Density
Parity Check codes (QLDPC codes)—a broad class of codes, some of
which have recently been shown to be asymptotically good. Based
on that, we provide an implementation of a general decoder for
QLDPC codes. On top of that, we propose an efficient heuristic
decoder that tackles the runtime bottlenecks of the general QLDPC
decoder while still maintaining comparable decoding performance.
These tools eventually allow to confirm theoretical results around
QLDPC codes in a more practical setting and showcase the value of
software tools (in addition to theoretical considerations) for inves-
tigating codes for practical applications. The resulting tool, which
is publicly available at https://github.com/lucasberent/qecc under
the MIT license, is meant to provide a playground for the search
for “practically good” quantum codes.

1 INTRODUCTION
Current quantum computing research orbits around a central chal-
lenge, which is the physical realization of quantum computers.
The main roadblock towards constructing universal, large-scale
quantum computers is a fundamental problem that all quantum
architectures suffer from: errors. Quantum systems are extremely
susceptible to noise, which diminishes accuracy of computations
and currently renders general quantum algorithms unusable in
practice. Analogously to classical computing, Quantum Error Cor-
rection (QEC, [1]) evolves around designing methods that allow to
protect quantum computers against noise and to reduce errors that
inevitably happen in quantum systems in order to facilitate the
realization of fault-tolerant quantum computers.

Quantum Error-Correcting Codes (QECCs)—designed to ward
quantum systems by adding redundancy—are a main driver to-
wards the goal of tackling noisy quantum hardware and achieving
fault tolerance. This is due to results which state that with suitable
QECCs it is possible to build arbitrarily large quantum comput-
ers in a fault-tolerant way. A problem with current QEC methods
is that due to the added redundancy, the overall systems grow

too large to actually build them. Recently, Quantum Low-Density
Parity Check codes (QLDPC codes)—a particular class of quantum
error-correcting codes—have become the center of attention as they
have good theoretical properties that promise applicability for large
quantum systems.

A central task in these endeavours is to efficiently recover a state
that is encoded with a code and has potentially been corrupted—also
referred to as decoding. Inefficient decoding leads to a bad overall
performance of QEC techniques. On the one hand, decoders need
to be fast so that the overall QEC performance is not diminished
by the time it takes to decode. On the other hand, they need to
be able to correct as many errors as possible without introducing
additional errors.

Theoretical (asymptotic) properties of QLDPC codes, i.e., how
much overhead they introduce and how many errors they can
correct, have been studied thoroughly. This culminated in the con-
struction of asymptotically good quantum codes [2]–[5], i.e., codes
whose good properties are preserved with increasing system size.
However, when viewed in a practical setting, i.e., with finite pa-
rameters (as opposed to asymptotic scaling), most codes are widely
unexplored. Good theoretical properties do not necessarily imply
that the codes also perform well for practical sizes (as also remarked
in [6]). Hence, investigations of codes with practical parameters are
essential for future research towards fault-tolerant quantum com-
puting. In order to conduct such investigations around quantum
codes and decoders, corresponding software tools are needed.

In this work, we propose such a set of software tools that allows
to numerically experiment with the class of QLDPC codes that—to
date—has mostly been explored theoretically. Particularly focus-
ing on the problem of decoding QLDPC codes, we demonstrate
how the resulting tool set can be employed to confirm theoretical
results around QLDPC codes. To this end, we implement a very
general decoder that, in principle, can be applied to any QLDPC
code (based on the theoretical concepts provided in [7]) and an-
alyze its runtime and decoding performance. On top of that, we
propose a heuristic—based on ideas for decoding topological quan-
tum codes—that tackles the inherent runtime bottleneck identified
in the general decoder while still maintaining comparable decod-
ing performance. In an effort to continuously extend the amount
of open source software tools for QEC, the resulting tool is made
publicly available at https://github.com/lucasberent/qecc.

The rest of this paper is structured as follows: Section 2 covers
the fundamental notions of QEC. Then, Section 3 reviews related
work and the main motivation. The general decoder provided as
part of the proposed tool set is presented in Section 4 and Section 5
discusses the implementation of the proposed heuristic. Based on
that, Section 6 summarizes the conducted numerical evaluations.
Finally, a short summary and an outlook on future directions are
given in Section 7.

 
 
 
 
 
 
Lucas Berent, Lukas Burgholzer, and Robert Wille

Figure 1: Tanner graph of the Hamming code

2 BACKGROUND
To keep this work self-contained, this section covers the fundamen-
tal notions around ECCs and QEC.

2.1 Error-Correcting Codes
An Error-Correcting Code (ECC) is a mechanism that adds redundan-
cies to data to protect it from errors. A decoding algorithm (decoder)
tries to recover the original data from the (possibly erroneous) en-
coded one.

In the following, data is simply viewed as binary vectors. In-
tuitively, a binary linear code C of length 𝑛 can be seen as a
set of vectors, called codewords, which all fulfill the same set of
constraints (checks). Data vectors of length 𝑘 are encoded by assign-
ing a codeword 𝑥 ∈ C (of length 𝑛) to each of them. Subsequently,
when errors occur, the checks of C are used to gain information on
which error occurred in order to correct it accordingly. The checks
compute the parity of a subset of elements 𝑣𝑖 of a vector 𝑣.
It is convenient to view a code C as a bipartite graph

T (C) := (𝑉 = 𝑉𝑄 ∪ 𝑉𝐶, 𝐸),
called the Tanner graph of C, where 𝑉𝐶 denotes the set of check
vertices and 𝑉𝑄 the bit (or data) vertices. Naturally, the set of bit
vertices correspond to binary vectors and each check vertex checks
if incident bits 𝑣𝑖 have even parity.
Example 1. The length seven Hamming code is an example of a
binary linear code that encodes vectors of length four into vectors of
length seven. Fig. 1 depicts the Tanner graph of the Hamming code
that has three check vertices (depicted as squares) and seven bit
vertices (depicted as circles). For example, the left-most check (𝑐0)
computes the parity of the bit vertices 𝑣0, 𝑣3, 𝑣5, 𝑣6.

Since the codewords are exactly the vectors that fulfill all checks,
it is crucial to determine whether a given vector is a codeword or
not in order to detect and correct errors. To check if a vector 𝑣 is a
codeword, each bit node of T (C) is assigned an element 𝑣𝑖 ∈ {0, 1}
of 𝑣. Each check vertex 𝑐 𝑗 computes the parity of its neighbours.
If all checks are satisfied, i.e., the parity of the neighbours of each
check is even, 𝑣 is a codeword.

Example 2. Consider again Example 1 and let 𝑥 = (1, 0, 0, 0, 0, 0, 0)
and 𝑐0 be defined as above. Then, 𝑥 is not a codeword, since

𝑐0 : 1 + 0 + 0 + 0 ≠ 0 (mod 2).
Recall that if a vector 𝑣 is a codeword, all checks are satisfied. If
any of the checks fails (computes an odd parity), it is indicated that
an error 𝜀 occurred. The checks that are not satisfied constitute the
syndrome of the error. To correct an error 𝜀, an estimate vector ˜𝜖
that can be used to recover a codeword (an error-free state) has to
be found. This process is called decoding. Decoding algorithms are
vital for error-correction, since the overall protection capability of
a code depends on how well decoders can correct errors and how
efficiently an estimate for a given syndrome can be found.

Figure 2: Tanner graph of the Steane code

2.2 Quantum Error Correction
In classical computing, a fundamental unit of information is a bit,
which is protected by an ECC against bit flip errors (flipping 1 to
0 and vice versa). The quantum analogue of a bit is a qubit [1],
which can assume arbitrary, complex linear combinations of 0
and 1 (superposition). The state |𝜓 ⟩ of a single qubit is described
as |𝜓 ⟩ = 𝛼0 |0⟩ + 𝛼1 |1⟩, where 𝛼0, 𝛼1 ∈ C and |𝛼0| + |𝛼1| = 1. It can
be shown that errors on qubits are equivalent to combinations of
bit flips and phase flips, where a bit flip is analogous to the classical
case and a phase flip on a qubit changes the sign of its |1⟩ amplitude.
Bit flips and phase flips correspond to applying an 𝑋 or a 𝑍 operator,
respectively, where 𝑋 and 𝑍 are the well-known Pauli operators.
Example 3. The following equations showcase how 𝑋 and 𝑍 op-
erate on simple quantum states:

𝑋 |0⟩ = |1⟩ , 𝑋 |1⟩ = |0⟩
𝑍 |0⟩ = |0⟩ , 𝑍 |1⟩ = − |1⟩

(1)

(2)

Since quantum errors are combinations of 𝑋 and 𝑍 errors, it
is natural to consider a combination of two classical codes, each
protecting against one type of error. This is the main idea behind
a broad class of codes ubiquitous in quantum computing called
Calderbank-Shor-Steane codes (CSS codes, [8], [9]).

Analogously to a classical code, a CSS code C can be represented
as a Tanner graph T (C). The Tanner graph of a CSS code has two
sets of check vertices, one for 𝑍 errors and one for 𝑋 errors.

Example 4. Fig. 2 depicts the Tanner graph of the Steane code,
which is a CSS code whose 𝑋 and 𝑍 check components each corre-
spond to a Hamming code (as illustrated before in Fig. 1).

The considered noise model assumes independent and identically
distributed (i.i.d.) 𝑋 and 𝑍 errors, hence the two components can be
decoded independently and analogously to each other by finding
an estimate for a given syndrome. Thus, without loss of generality,
we consider 𝑋 errors only in the following discussion. A Quantum
Low-Density Parity Check (QLDPC) code is a CSS code such that
each bit is involved in a constant number of checks and each check
involves a constant number of bits. This property renders QLDPC
codes a promising candidate for practical applications, even for
large code lengths.

3 MOTIVATION
Recently, theoretical results around QLDPC codes have accumu-
lated in several breakthroughs around asymptotically good quan-
tum codes [2]–[5]. These mostly theoretical results beg the question
of practical applicability of such codes, e.g., whether they can be
constructed and decoded efficiently for practical instance sizes. In
fact, investigating the potential of these codes for practical appli-
cations has hardly been done yet and necessitates corresponding
(software) tools. In this work, we take a step towards closing this
gap. To this end, this section briefly reviews related work and re-
maining open problems before the remainder of this paper describes
corresponding solutions.

Software Tools for Decoding Quantum Low-Density Parity Check Codes

3.1 Related Work
Very recently, a generalized QLDPC decoder based on ideas of the
Union-Find decoder for topological codes was proposed [7]. While
the authors show theoretical decoding performance guarantees
and conduct numerical simulations for a QLDPC code, no publicly
available implementation is known and extensive numerical exper-
iments on variants of the decoder and investigations around the
practical runtime performance are still open.

Following the vast amount of research recently proposed in the
domain of QEC, industrial research has also started to show interest
in QEC and has acknowledged the importance of practical investiga-
tions. Most recent endeavors towards that include FlamingPy [10]
and Qiskit QEC (available at github.com/qiskit-community/qiskit-
qec), which support toric codes but do not support the generalized
QLDPC decoder. Furthermore, several tools [11]–[15] have been
used to numerically decode and evaluate quantum codes. Although
some are publicly available, most of them focus on surface codes and
none include the recently proposed generalized QLDPC decoder.

3.2 Considered Problem
Since theoretical results around QLDPC codes have shown their
promising properties, investigations of these codes in more practical
settings (as opposed to asymptotic regimes) are of great importance.
Central prerequisites for this are software tools to facilitate the pos-
sibilities of research in this direction. In this work, we are proposing
tools with a focus on the decoding problem for modern QLDPC
codes. Decoding algorithms need to correct errors well and in a
highly efficient manner, which naturally makes it a hard problem.
In fact, decoders with sub-optimal performance have been iden-
tified as the main bottleneck of the QLDPC paradigm in QEC, as
the general algorithm known from classical LDPC codes does not
perform too well on QLDPCs [16].

As a first step towards a comprehensive set of tools and methods,
we focus on the decoding problem of QLDPC codes and provide
implementations of a general QLDPC decoder in the form of an
efficient, extendable, and openly available software tool set. On
top of that and to tackle inefficient runtime of current decoding
algorithms, we additionally propose an algorithm to decode QLDPC
codes with improved runtime performance. Both considerations
are described in the following sections.

4 SOFTWARE TOOLS

FOR DECODING QLDPC CODES

While a decoder (based on ideas of decoding topological quantum
codes) that, in principle, works for any QLDPC code has been
proposed in [7], no software tools are available that implement
this decoder and, hence, allow to perform broad numerical studies
on QLDPC codes. In the following, we describe our endeavours to
change this situation. First, Section 4.1 settles the technical details
that build the basis for the proposed software tools. Based on that,
Section 4.2 describes the implementation of the recently proposed
general decoder for QLDPC codes. Afterwards, Section 4.3 discusses
the main advantages and disadvantages of the resulting decoder.

4.1 Technical Details
A CSS code C is defined by two Parity Check Matrices (PCMs)
𝐻𝑋 ∈ F𝑚×𝑛
, such that

and 𝐻𝑍 ∈ F𝑙×𝑛

2

2

(a) Syndrome 𝜎 (𝑥).

(b) A grown component K0.

(c) A valid estimate ˜𝑥 for K0.
Figure 3: Example of UF decoding on the Steane code.

𝐻𝑋 𝐻𝑇

(3)
𝑍 = 0.
Such a code encodes 𝑘 = 𝑛 −𝑟𝑎𝑛𝑘 (𝐻𝑋 ) −𝑟𝑎𝑛𝑘 (𝐻𝑍 ) logical qubits
into 𝑛 physical ones. Note that a PCM 𝐻 can be seen as an adjacency
matrix of T (C), with rows corresponding to check vertices and
columns to bit vertices. An entry 𝐻𝑖 𝑗 is set to one if and only if bit 𝑗
occurs in the parity check defined by 𝑐𝑖 .

Concerning the possible errors that occur, we consider inde-
pendent Pauli noise, where each data bit is affected by an error
with a certain probability. For a CSS code of length 𝑛, an error is
represented as a binary vector 𝜀 = (𝑥, 𝑧) ∈ F𝑛

2 × F𝑛
2 .

A CSS code has a set of stabilizers which is a set of errors that have
no effect on the encoded data. From Eq. (3) it follows that an error 𝑥
is a stablizer iff it is in the rowspace of 𝐻𝑋 , i.e., a linear combination
of 𝐻𝑋 ’s rows. The syndrome of an error 𝑥, is 𝜎 (𝑥) = 𝐻𝑍 𝑥 ∈ F𝑙
2.

Given a syndrome 𝜎 (𝑥) of an error, the goal of the decoder is
to find an estimate ˜𝑥 that is equivalent to 𝑥 up to stabilizer, i.e., to
find ˜𝑥 such that 𝑥 + ˜𝑥 is in the rowspace of 𝐻𝑋 . For simplicity, we
assume that the syndrome can be inferred without any additional
error being introduced during the process. In the following, an
𝑋 -error 𝑥 ∈ F𝑛
2 is identified with the qubit vertices 𝑣 ∈ 𝑉𝑄 it sets
to one. Similarly, the syndrome 𝜎 (𝑥) of an error is identified with
the set of check vertices 𝑐𝑖 ⊆ 𝑉𝑐 triggered by 𝑥.

Tanner graphs are a central data structure for working with
QLDPC codes. To this end, some graph theoretic notions and func-
tions are needed. For any graph 𝐺 = (𝑉 , 𝐸) and a vertex 𝑣 ∈ 𝑉 ,
𝑁 (𝑣) ⊆ 𝑉 denotes the neighbours of 𝑣, i.e., the vertices connected
to 𝑣. The interior 𝐼𝑛𝑡 (𝑊 ) of a set of vertices 𝑊 contains vertices
whose neighbours are also in 𝑊 , i.e., 𝑣 ∈ 𝐼𝑛𝑡 (𝑊 ) iff 𝑁 (𝑣) ⊆ 𝐼𝑛𝑡 (𝑊 ).

Example 5. The concepts described above are illustrated in Fig. 3
(the respective captions can be ignored for now). To this end, Fig. 3a
again shows the Tanner graph of the Steane code with the check
node 𝑐1 marked red. Its neighbours 𝑁 (𝑐1) are exactly the bit vertices
also marked red in Fig. 3b. The interior of the marked vertices
consists of 𝑐1 together with the vertex highlighted in green as
shown in Fig. 3c.

4.2 Implementation of a

General QLDPC Decoder

The technical details introduced above allow to describe the imple-
mentation of a decoder that can in principle decode any QLDPC
code (based on the theoretical concepts provided in [7]). This gen-
eral QLDPC decoder uses ideas of the Union-Find decoder for topo-
logical codes [17] and reduces the decoding problem of QLDPC
codes to a combinatorial problem on the Tanner graph of the code.

Algorithm 1 Generalized QLDPC Decoder [7]

Algorithm 2 Union-Find Decoding Heuristic

Lucas Berent, Lukas Burgholzer, and Robert Wille

1: Input: 𝜎 (𝑥) ⊆ 𝑉𝐶 of some error 𝑥.
2: Output: Estimate ˜𝑥 s.t. 𝜎 ( ˜𝑥) = 𝜎 (𝑥)
3: Initialize K = 𝜎 (𝑥)
4: while K contains invalid clusters do
Grow K𝑖 by adding 𝑁 (𝑣), ∀𝑣 ∈ K𝑖
5:

6: for K𝑖 ⊆ K do
7:

Find valid correction ˜𝑥𝑖 ⊆ Int(K𝑖 ) with 𝜎 ( ˜𝑥𝑖 ) = 𝜎 (𝑥) ∩ K𝑖

The general structure of the algorithm is sketched in Algorithm 1.
In the following, an implementation of the algorithm is discussed.
Let T = (𝑉 = 𝑉𝑄 ∪ 𝑉𝐶, 𝐸) denote the Tanner graph of a QLDPC
code. Given a syndrome 𝜎 (𝑥) ⊆ 𝑉𝐶 of some error, the decoder
grows clusters (sets of nodes) K𝑖 ⊆ 𝑉 around syndrome nodes until
all clusters are valid (Line 5). A cluster K𝑖 is valid if an estimate ˜𝑥𝑖
can be found that covers the syndrome occurring in K𝑖 . Formally,
a cluster K𝑖 is defined to be valid iff there exists a set of nodes ˜𝑥𝑖 ⊆
𝑉𝑄 ∩𝐼𝑛𝑡 (K𝑖 ) such that 𝜎 ( ˜𝑥𝑖 ) = 𝜎 (𝑥) ∩ K𝑖 . When all grown clusters
K𝑖 are valid, an overall estimate ˜𝑥 whose syndrome matches 𝜎 (𝑥) is
computed by looking for local corrections ˜𝑥𝑖 inside each K𝑖 (Line 7).
Example 6. Consider again Fig. 3, which suffices to illustrates the
main idea of the generalized QLDPC decoder. Assume that check 𝑐1
fails. First (Fig. 3a), the syndrome 𝜎 (𝑥) = 𝑐1 is initialized as the first
(and only) cluster K0. Then, K0 is grown (Fig. 3b). The nodes of K0
are marked. The decoder can find a correction ˜𝑥 = (0, 1, 0, 0, 0, 0, 0),
as there is a qubit node in 𝐼𝑛𝑡 (K0) covering the syndrome (Fig. 3c).

4.3 Discussion
The advantages of the algorithm are clearly its generality which
implies that it can be applied for any QLDPC code. Furthermore,
the algorithm has a rather simple formulation as it is formalized as
a graph problem. Moreover, the authors of [7] proved correction
guarantees for several classes of codes. More specifically, the de-
coder can successfully decode all sufficiently low-weight errors for
hyperbolic QLDPC codes of arbitrary dimension [18], [19], toric
codes [20], and locally testable codes [21]–[23]. On a practical
note, the proposed implementation only requires the formulation
of codes in terms of parity-check matrices, which is very general
and therefore ensures compatibility with a broad range of codes
and easy extendability. The main bottlenecks of this decoder are
the procedures for checking validity and finding corrections which,
essentially, can be reduced to Gaussian elimination [7]. Overall,
Algorithm 1 thus has worst-case runtime complexity 𝑂 (𝑛4).

5 UNION-FIND DECODING HEURISTIC
In order to tackle the runtime complexity of the decoder discussed
above, in this section, we propose decoding heuristic based on ideas
borrowed from a decoder for topological quantum codes [17] that
improves the runtime of the general QLDPC decoder by a quadratic
factor and show how it can be implemented on top of the proposed
software package.

5.1 General Ideas
In order to achieve an efficient runtime performance, a dedicated
data structure, called Union-Find (UF, also called disjoint-set data
structure, [24]), is employed to represent clusters of nodes. This
data structure accelerates two of the main routines in the general

1: Input: 𝜎 (𝑥) ⊆ 𝑉𝐶
2: Output: Estimate ˜𝑥 ⊆ 𝑉𝑄 s.t. 𝜎 ( ˜𝑥) = 𝜎 (𝑥)
3: Initialize K = 𝜎 (𝑥)
4: Init A = ∅
5: while K ≠ ∅ do
6:

8:

9:

7:

For all K𝑖 ∈ K grow K𝑖 by its neighbourhood
Use Union to merge clusters grown together
Replace each cluster representative 𝑢𝑖 by its root using Find
Update boundary lists
Add valid clusters to A
10:
11: procedure Erasure procedure(A)
12:

⊲ Local Decoding

Compute 𝐼𝑛𝑡 (K𝑖 )
Take a bit node 𝑣 𝑗 ∈ 𝐼𝑛𝑡 (K𝑖 )
Add 𝑣 𝑗 to the estimate ˜𝑥𝑖 for K𝑖
Remove checks 𝑐𝑘 adjacent to 𝑣 𝑗 by removing 𝑁 (𝑐𝑘 )

13:

14:

15:

decoder considered above: determining the cluster a node belongs
to (the Find function) and efficiently merging two separate clusters
(the Union function).

The Union-Find data structure consists of a list of disjoint sets
of vertices (of T ). Each disjoint set is represented as a tree (UF tree)
rooted at a dedicated node 𝑟𝑖 . The overall data structure can then
be seen as list of root nodes—each identifying a UF tree. Because of
the tree-like representation, the operations of determining which
UF tree a given node belongs to (Find), and merging two disjoint
UF trees (Union) can be computed efficiently.

It is important to emphasize that the proposed algorithm is a
heuristic, since there is no (theoretical) guarantee it can correct a
certain number of errors for general QLDPC codes. However, the
runtime performance is considerably reduced by a factor of 𝑂 (𝑛2).
Therefore, the proposed heuristic presents an interesting step in
the direction of highly efficient decoding algorithms and allows to
trade-off decoding performance for runtime.

5.2 Implementation
Using the idea of the generalized QLDPC decoder and the UF data-
structure as sketched above, Algorithm 2 sketches the implemen-
tation of the proposed approach. Based on the UF data structure,
clusters grown in the Tanner graph T are represented as UF trees.
The algorithm maintains a list K = { 𝑟0, . . . , 𝑟ℓ } of root nodes 𝑟𝑖
corresponding to the grown clusters K𝑖 . As the algorithm grows
clusters in T by adding the neighbouring vertices (in T ) of bound-
ary nodes to a cluster (Line 6), it may happen that two clusters
are grown together, i.e., share a common node. The Find function
is used to determine which cluster a node belongs to and consec-
utively Union is used to efficiently compute the union of two UF
trees, i.e., merge two clusters into one (Line 7). Once all clusters are
valid, a procedure to compute an estimate ˜𝑥𝑖 is computed for each
cluster K𝑖 (Line 11).

To maintain low runtime, some further implementation details
have to be considered. The algorithm grows clusters in T until all
are valid, i.e., until each cluster K𝑖 , 𝐼𝑛𝑡 (K𝑖 ) contains a possible
correction. The validity check determines for each cluster whether
there exists neighbours of check nodes that are not in the boundary.
To avoid recomputation of the boundary in each step (which would
contribute to a quadratic factor in the runtime), a precomputed

Software Tools for Decoding Quantum Low-Density Parity Check Codes

list of boundary vertices is stored at the root node of each UF tree.
The boundary list of a cluster K𝑖 contains nodes of the cluster that
share an edge with a node not in the cluster. Thus a book keeping
step is needed that recomputes the boundary list for each K𝑖 after
the growth step (Line 9).

Moreover, similar to [17], it is necessary to replace each vertex
representing a cluster by its root node in K. Merging of clusters
might cause that this produces duplicates. Thus, a lookup table
indicating which root is present in K is added. To avoid duplicate
root nodes, the decoder can simply check whether a root is already
present, and if so not add it again to K.

The main cost of growing clusters and is dominated by the
the Find and Union functions. Using weighted Union (appending
smaller to larger clusters) and path compression (when calling Find,
appending all nodes encountered directly as children of the root
node) leads to an almost linear worst-case time complexity since
both functions have a worst-case complexity of 𝑂 (𝑛𝛼 (𝑛)) where
𝛼 is the inverse Ackermann function [25]. Checking validity and
finding estimates for each cluster requires quadratic worst-case
runtime, since for each cluster a valid estimate is computed iter-
atively from the nodes inside the cluster. Overall the worst-case
runtime is in 𝑂 (𝑛2)—a considerable improvement compared to the
general QLDPC decoder.

6 NUMERICAL EVALUATIONS
The ideas presented in the previous sections have been implemented
in C++ with easy-to-use Python bindings as an interface. The result-
ing implementation is available at https://github.com/lucasberent/
qecc. Based on that, we investigate the runtime scaling as well as the
decoder performance of both presented decoders. Additionally, we
study the impact of different variants of growth on the performance
of the decoding performance. As mentioned above, in all of our
investigations, we assume independent and identically distributed
Pauli noise, perfect syndrome measurements, and focus on 𝑋 errors
only. To construct the codes, we used a publicly available tool [12].
The codes and all numerical data is made publicly available along
with the source code. All numerical simulations were conducted on
a machine equipped with a 16 core Intel Xenon(R) W-1370P 3.6GHz
processor and 128GiB RAM, running Ubuntu 20.04 LTS.

6.1 Runtime Performance
In a first series of evaluations, the runtime of the general QLDPC
decoder and the proposed heuristic was investigated. To this end, we
ran Monte Carlo simulations for decoding toric codes of increasing
sizes under different levels of physical noise (physical X-error rate,
per). Fig. 4 depicts the obtained average runtimes for the general
QLDPC decoder (GD) and the heuristic (UFH). Note that each data
point corresponds to the average runtime to decode 103 samples.
The results confirm the discussion in Section 4.3 on the bottleneck
of the general QLDPC decoder—the use of Gaussian elimination.
This is the dominating factor here since the degree of the Tanner
graph is small. The experimental data shows a scaling in 𝑂 (𝑛2) for
our implementation, the considered code, and noise model.

The data clearly confirms the drastic performance benefit of
the heuristic. For small code sizes the runtime behaves almost
constantly. For code sizes 𝑛 larger than roughly 103, linear scaling
can be observed while maintaining low runtimes even for large
code sizes. For instance, for code sizes of 𝑛 = 3000 with 𝑝 = 0.01,

Figure 4: Average runtime of the general QLDPC decoder
and the heuristic to decode 103 samples for toric codes with
increasing length 𝑛.

the heuristic takes several seconds to decode 103 samples, while
the general QLDPC decoder needs several minutes.

6.2 Decoding Performance
In addition to the runtime behaviour, the decoding performance of
the general QLDPC decoder and the proposed heuristic was studied
on a medium-sized QLDPC code. More specifically, we conducted
simulations in which errors with increasing physical error rate were
sampled and the fraction of failed runs with respect to the code
dimension (the so-called Word-Error Rate, WER) was investigated
for a [[1024, 18]] lifted product code [6].

We used a simulation procedure that is constituted of repeated

runs of the following steps for a code with parameters [[𝑛, 𝑘]]:

(1) Sample a Pauli error 𝑥 ∈ F𝑛
2 .
(2) Compute the syndrome 𝜎 (𝑥).
(3) Apply the decoder to get ˜𝑥.
(4) Compute 𝑥 ′ = 𝑥 + ˜𝑥.
(5) Check if 𝑥 ′ is a stabilizer. If yes, then return success otherwise

return failure.

The fraction of failed runs is called the block error rate, 𝑃𝐿. In
order to factor out the number of encoded qubits 𝑘, the Word-Error
Rate (WER) 𝑃𝑊 defined as

𝑃𝑊 = 1 − (1 − 𝑃𝐿)1/𝑘 .
was used to evaluate the decoding performance. For small logical er-
ror rates it holds that 𝑃𝑊 ≈ 𝑃𝐿/𝑘. The growth procedure in Line 6 of
Algorithm 2 offers some degrees of freedom for different variants of
how this growth is realized. In our evaluation we compared several
different variants of growth. The first one (AG), where all clusters
are grown in each growth step (also valid ones) is motivated by the
original formulation [7] and underpinned by theoretical results that
guarantee correctability bounds for the general QLDPC decoder.
The other two variants grow only a single cluster in each growth
step, either the smallest one (SSG) or a random one (SRG). Single
smallest cluster growth has been demonstrated to be beneficial for
topological codes [17].

The results of the investigations around the decoding perfor-
mance are summarized in Fig. 5. Every data point was obtained by

Lucas Berent, Lukas Burgholzer, and Robert Wille

ACKNOWLEDGEMENTS
The authors would like to thank Richard Kueng and James Wootton
for fruitful discussions in the early stages of this project and for
insightful comments on a first version of this paper, respectively.
This work received funding from the European Research Council
(ERC) under the European Union’s Horizon 2020 research and inno-
vation program (grant agreement No. 101001318), was part of the
Munich Quantum Valley, which is supported by the Bavarian state
government with funds from the Hightech Agenda Bayern Plus,
and has been supported by the BMWK on the basis of a decision
by the German Bundestag through project QuaST, as well as by the
BMK, BMDW, and the State of Upper Austria in the frame of the
COMET program (managed by the FFG).

REFERENCES
[1] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Informa-

tion. Cambridge University Press, 2010.
N. P. Breuckmann and J. N. Eberhardt, “Balanced product quantum codes,”
IEEE Trans. on Inf. Theory, vol. 67, no. 10, pp. 6653–6674, 2021.
P. Panteleev and G. Kalachev, “Asymptotically good quantum and locally
testable classical LDPC codes,” in Symp. on Theory of Computing, 2022, pp. 375–
388.
A. Leverrier and G. Zémor, Quantum tanner codes, 2022. arXiv: 2202.13641.
I. Dinur, M.-H. Hsieh, T.-C. Lin, and T. Vidick, Good quantum LDPC codes with
linear time decoders, 2022. arXiv: 2206.07750.
P. Panteleev and G. Kalachev, “Degenerate quantum LDPC codes with good
finite length performance,” Quantum, vol. 5, p. 585, 2021.
N. Delfosse, V. Londe, and M. E. Beverland, “Toward a union-find decoder for
quantum LDPC codes,” IEEE Trans. on Inf. Theory, vol. 68, no. 5, pp. 3187–3199,
2022.
A. R. Calderbank and P. W. Shor, “Good quantum error-correcting codes exist,”
Physical Review A, vol. 54, no. 2, p. 1098, 1996.
A. M. Steane, “Simple quantum error-correcting codes,” Physical Review A,
vol. 54, no. 6, p. 4741, 1996.
I. Tzitrin et al., “Fault-tolerant quantum computation with static linear optics,”
PRX Quantum, vol. 2, no. 4, p. 040 353, 2021.
J. Roffe, D. R. White, S. Burton, and E. Campbell, “Decoding across the quantum
low-density parity-check code landscape,” Physical Review R, vol. 2, no. 4,
p. 043 423, 2020.
J. Roffe, LDPC: Python tools for low density parity check codes, 2022. [Online].
Available: https://pypi.org/project/ldpc/.

[13] O. Higgott, Pymatching: A python package for decoding quantum codes with

minimum-weight perfect matching, 2021. arXiv: 2105.13082.
C. Gidney, “Stim: A fast stabilizer circuit simulator,” Quantum, vol. 5, p. 497,
2021.

[14]

[15] O. Higgott and N. P. Breuckmann, Improved single-shot decoding of higher

dimensional hypergraph product codes, 2022. arXiv: 2206.03122.
D. Poulin and Y. Chung, “On the iterative decoding of sparse quantum codes,”
qic, vol. 8, no. 10, pp. 987–1000, 2008.
N. Delfosse and N. H. Nickerson, “Almost-linear time decoding algorithm for
topological codes,” Quantum, vol. 5, p. 595, 2021.
L. Guth and A. Lubotzky, “Quantum error correcting codes and 4-dimensional
arithmetic hyperbolic manifolds,” Journal of Mathematical Physics, vol. 55, no. 8,
p. 082 202, 2014.
V. Londe and A. Leverrier, Golden codes: Quantum {LDPC} codes built from
regular tessellations of hyperbolic 4-manifolds, 2017. arXiv: 1712.08578.
A. Y. Kitaev, “Fault-tolerant quantum computation by anyons,” Annals of Physics,
vol. 303, no. 1, pp. 2–30, 2003.
A. Leverrier, V. Londe, and G. Zémor, “Towards local testability for quantum
coding,” Quantum, vol. 6, 2022.

[23]

[22] M. B. Hastings, “Decoding in hyperbolic spaces: Quantum LDPC codes with
linear rate and efficient error correction,” Quantum Information & Computation,
vol. 14, no. 13, pp. 1187–1202, 2014.
A. Leverrier, J.-P. Tillich, and G. Zémor, “Quantum expander codes,” in Founda-
tions of Computer Science, 2015, pp. 810–824.
T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein, Introduction to Algo-
rithms, Third Edition, 3rd. The MIT Press, 2009.
R. E. Tarjan, “Efficiency of a good but not linear set union algorithm,” jacm,
vol. 22, no. 2, pp. 215–225, 1975.

[25]

[24]

[2]

[3]

[4]
[5]

[6]

[7]

[8]

[9]

[10]

[11]

[12]

[16]

[17]

[18]

[19]

[20]

[21]

Figure 5: Decoding performance of the proposed heuristic
using different variants of growth and the general QLDPC
decoder on a [[1024, 18]] lifted product code.

105 samples. Since the growth variants of the proposed heuristic
where a single cluster is grown in each step (a random one or the
smallest one) perform very similarly, only the single smallest cluster
growth is depicted.

In summary, the overall WER of both the general decoder and
the proposed heuristic is rather high for the considered physical
error rates. This matches results from [7], where the authors demon-
strate that the general QLDPC decoder only outperforms a belief-
propagation decoder for very low physical error-rates. Interestingly,
all growth variants of the proposed heuristic perform very simi-
larly. Furthermore, the heuristic performs nearly equivalently to
the general QLDPC decoder in the considered scenario.

7 CONCLUSION
Motivated by several recent theoretical breakthrough results around
QLDPC codes, this work provides a set of software tools for inves-
tigations in more practical settings. The central aspect studied in
this work is the decoding of QLDPC codes. The proposed solution
encompasses an open-source implementation of a general QLDPC
decoder and allows to conduct numerical evaluations on a large
variety of codes to investigate the runtime as well as the decoding
performance of this algorithm. On top of that, we proposed an algo-
rithm that aims to address the runtime bottlenecks of the general
decoder while still maintaining comparable decoding performance.
Both solutions have been evaluated with regard to their runtime as
well as decoding performance—confirming theoretical results and
showcasing promising future directions.

In the future, it would be interesting to improve the decod-
ing performance—for both the original decoder and the proposed
heuristic—for instance by considering more sophisticated growth
procedures. Especially ones that consider edge weights and hence
weighted growth, or a combination with a pre-decoder. Moreover,
taking more realistic noise models into account is a crucial next step.
Furthermore, it would be desirable to prove decoding performance
bounds for families of codes for the proposed heuristic analytically.

