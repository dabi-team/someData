CoFHEE: A Co-processor for
Fully Homomorphic Encryption Execution

Mohammed Nabeel1, Deepraj Soni2, Mohammed Ashraf1, Mizan Abraha
Gebremichael3, Homer Gamil2, Eduardo Chielle1, Ramesh Karri2, Mihai
Sanduleanu3 and Michail Maniatakos1

1 New York University Abu Dhabi, Abu Dhabi, UAE
2 New York University, New York, USA
3 Khalifa University, Abu Dhabi, UAE

Abstract. The migration of computation to the cloud has raised privacy concerns
as sensitive data becomes vulnerable to attacks since they need to be decrypted for
processing. Fully Homomorphic Encryption (FHE) mitigates this issue as it enables
meaningful computations to be performed directly on encrypted data. Nevertheless,
FHE is orders of magnitude slower than unencrypted computation, which hinders
its practicality and adoption. Therefore, improving FHE performance is essential
for its real world deployment. In this paper, we present a year-long eﬀort to design,
implement, fabricate, and post-silicon validate a hardware accelerator for Fully
Homomorphic Encryption dubbed CoFHEE. With a design area of 12mm2, CoFHEE
aims to improve performance of ciphertext multiplications, the most demanding
arithmetic FHE operation, by accelerating several primitive operations on polynomials,
such as polynomial additions and subtractions, Hadamard product, and Number
Theoretic Transform. CoFHEE supports polynomial degrees of up to n = 214 with a
maximum coeﬃcient sizes of 128 bits, while it is capable of performing ciphertext
multiplications entirely on chip for n ≤ 213. CoFHEE is fabricated in 55nm CMOS
technology and achieves 250 MHz with our custom-built low-power digital PLL design.
In addition, our chip includes two communication interfaces to the host machine:
UART and SPI. This manuscript presents all steps and design techniques in the ASIC
development process, ranging from RTL design to fabrication and validation. We
evaluate our chip with performance and power experiments and compare it against
state-of-the-art software implementations and other ASIC designs. Developed RTL
ﬁles are available in an open-source repository.
Keywords: Data Privacy · Encrypted Computation · Fully Homomorphic Encryp-
tion · Hardware Accelerator · ASIC.

1

Introduction

The proliferation of cloud services have intensiﬁed the user dependency on outsourced
computation. While standard encryption schemes like AES and RSA protect data in
transit and data at rest, they cannot protect data in use, since they require data decryption
before processing; thus, sensitive data is exposed during computation. High-proﬁle attacks
in cloud services [BYZ13] have shown that access control is not suﬃcient. The advent of
Fully Homomorphic Encryption (FHE) in 2009 [Gen09] came as a solution for the problem
of data in use as it enables computation to be performed directly in the encrypted domain
without the need for decryption.

Although promising from a security and privacy standpoint, FHE is multiple orders of
magnitude slower than unencrypted computation, a characteristic that hinders its adoption

2

CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution

in the industry. Much progress has been done in the last decade through improvements in
FHE schemes and their software implementation. However, software-only performance of
FHE computation is still too slow for the majority of applications. In recent years, hardware
acceleration of encrypted computation is becoming a means to improve its practicality.
Several works have been proposed using GPUs [DDS14] and FPGAs [CRPS12] for FHE
acceleration. Furthermore, ASIC accelerators demonstrated signiﬁcant speedups compared
to software solutions [GH11] [DÖS14]. While ASIC is the ﬁnal goal of FHE acceleration
as it enables silicon tailored and optimized for encrypted computation, a fabricated chip
targeting FHE computation is yet to be seen.
Contributions: In this work, we present the process of designing, implementing, and
validating CoFHEE, the ﬁrst silicon-proven ASIC accelerator for FHE. CoFHEE targets
ciphertext multiplications, the slowest arithmetic operation in FHE. Towards that end,
we develop an architecture to accelerate polynomial multiplications, since it is the main
constituent of ciphertext multiplications. CoFHEE has special units for Number Theoretic
Transform (NTT) and a Processing Element (PE) capable of performing several arithmetic
operations. CoFHEE chip has been fabricated using 55nm CMOS Globalfoundries and has
been successfully brought up. This paper presents a comprehensive report from the initial
speciﬁcation to post-silicon validation, presenting implementation challenges and lessons
learned. CoFHEE will be open sourced, and its architecture as well as its functional units
can serve as a components for future work towards the design of FHE co-processors and
accelerators.

2 Preliminaries

2.1 Fully homomorphic encryption

Homomorphic encryption is a special type of encryption that enables performing meaningful
computations directly on encrypted data. It can be understood as the functional equivalent
of Eq. 1, where f (·) is a function over plaintexts and F (·) is its equivalent over ciphertexts,
Dk(·) and Ek(·) are respectively the decryption and encryption functions for a given key
k, and R(·) is a function that provides randomness for Ek(·) from ciphertexts ca and cb.
Although functionally equivalent to Eq. 1, homomorphic encryption enables equivalent
computation on the encrypted domain without the need for any decryption function during
computation.

F (ca, cb) = Ek(f (Dk(ca), Dk(cb)), R(ca, cb))

(1)

While there are several types of homomorphic encryption, Fully Homomorphic En-
cryption (FHE) possesses at least two orthogonal homomorphic operations allowing any
number of arbitrary computations. FHE was introduced in 2009 [Gen09] and it is deemed
as the "holy grail" of cryptography. It has seen much progress since its inception with
the development of new encryption schemes such as BFV [FV12], BGV [BGV14], CGGI
[CGGI16], and CKKS [CKKS17].

2.2 BFV encryption scheme

The Brakerski/Fan-Vercauteren (BFV) scheme is an FHE scheme based on the Ring-
Learning With Errors (RLWE) problem [LPR13]. It works over two polynomial rings,
one for the plaintext space and another for the ciphertext space. The plaintext space is
deﬁned over the polynomial ring P = Zt[x]/(xn + 1), while the ciphertext space in deﬁned
over C = Zq[x]/(xn + 1), where n is the polynomial degree, and t, q, and xn + 1 are the
plaintext, ciphertext, and polynomial moduli, respectively. BFV is supported by several

Mohammed Nabeel et al.

3

Table 1: Table of recommended encryption parameters (log q) assuming access to a classical
computer only (BKZ.sieve) or a quantum computer (BKZ.qsieve) for diﬀerent polynomial
degrees n and security levels λ [ACC+18].

cost
model

BKZ.sieve

BKZ.qsieve

λ
128
192
256
128
192
256

210
27
19
14
25
17
13

211
54
37
29
51
35
27

n

213
218
152
118
202
141
109

212
109
75
58
101
70
54

214
438
305
237
411
284
220

215
881
611
476
827
571
443

libraries and frameworks, such as ALCHEMY [CPS18], Cingulata [CDS15], E3 [CMTM18],
nGraph-HE2 [BCCW19], Palisade [PRRC20], Ramparts [ACTD+19], and SEAL [SEA21].

2.2.1 Ciphertext multiplication

The Homomorphic Encryption Security Standard deﬁnes the basic primitives of BFV
[ACC+18]. Out of those primitives, the homomorphic multiplication of ciphertexts
(EvalMult) is the slowest operation, and therefore, the main candidate for hardware
acceleration. In order to understand ciphertext multiplication, we ﬁrst need to understand
encryption. Let m be a plaintext in the plaintext space (m ∈ P), kp = (kp1, kp2) be an
encryption key in the ciphertext space C, and c = (c1, c2) ∈ C be an encryption of m with
key kp; the encryption function E(kp, m) → c deﬁnes a map from P to C. The ciphertext
c is composed of two polynomials c1 and c2, which are computed according to Eqs. 2 and
3, where u is a random polynomial from the set {−1, 0, 1}, e1 and e2 are small random
polynomials from a discrete Gaussian distribution, and ∆ = bq/tc is a scaling factor.

c1 = kp1 · u + e1 + ∆m mod q
c2 = kp2 · u + e2 mod q

(2)

(3)

The ciphertext multiplication cc = ca · cb ⇔ (cc1, cc2, cc3) = (ca1, ca2) · (cb1, cb2) is
calculated by evaluating the tensor in Eq. 4. The term t/q is a scaling factor, while
the remaining operations are polynomial multiplications and additions. The polynomial
addition is a simple operation with linear time complexity. However, a naive implementation
of polynomial multiplication has quadratic time complexity. More eﬃcient algorithms
using the Number Theoretic Transform (NTT) with nega-cyclic convolutions have been
proposed [CT65, GS66], reducing the time complexity to O(n log n).

(cc1, cc2, cc3) =

(cid:16)j t(ca1 · cb1)

m

q

q

,

j t(ca1 · cb2 + ca2 · cb1)
q

m

q

,

j t(ca2 · cb2)
q

m

(cid:17)

q

(4)

The parameters n, t, and q are application-speciﬁc. For eﬃcient computations, n is
deﬁned as a power of two. Typical values for n are 212, 213, and 214 [KL15, DGBL+16,
CLR17, CGM21, GCB+22]. The parameter q is deﬁned based on the selected n and
desired security level. Table 1 presents the recommended encryption parameters against
classical and quantum computers.

2.2.2 Residue Number System

As one can see, the coeﬃcient size log q is usually larger than 64 bits, making computations
on 64-bit processors ineﬃcient. To cope with that, q is usually broken into smaller qi using

4

CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution

Table 2: CoFHEE’s basic operations. [·]: memory address function, n: polynomial degree,
~x and ~y: polynomials, ~ω: twiddle factors, q: modulus, n−1: inverse of n, ~t: temporary
values, δ: length (in words), (cid:31): source address, (cid:26): output/destination address.
Inputs
n−1
q
•

n [~x]
•
•

Comments

Command

[~ω]
•

(cid:31) (cid:26)

[~t]
•

NTT

[~y]

δ

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

•

iNTT

•

PMODADD •

•

•

•

•

•

PMODMUL

PMODSQR

PMODSUB

CMODMUL

PMUL

MEMCPY

MEMCPYR

•

•

•

•

•

•

•

•

•

•

•

•

Performs NTT on ~x.
Performs inverse NTT
on ~x.
Pointwise modular
addition of ~x and ~y.
Pointwise mod. multi-
plication of ~x and ~y.
Pointwise modular
squaring of ~x.
Pointwise mod. sub-
traction of ~x and ~y.
Mod. multiplication
of ~x by a constant.
Pointwise multiplica-
tion of ~x and ~y.
Memory-to-memory
data transfer.
Memory data transfer
in bit-reverse.

the Residue Number System (RNS). In RNS, a large number is represented by its value
modulo several coprime moduli following the Chinese Remainder Theorem. This eﬀectively
breaks each polynomial into several polynomials with smaller coeﬃcients. In the case of
ciphertexts, each pair of polynomials (c1, c2) is broken into several pair of polynomials
(c11, c21), (c12, c22 ), (c13 , c23 ), ..., called towers. During ciphertext multiplication, each tower
operates independently, and Eq. 4 must be applied to all towers individually.

3 CoFHEE speciﬁcations

3.1 Native polynomial word size and operations

CoFHEE supports polynomial degrees of up to 214 in powers of two and modulus size up
to 128 bits, while it is optimized to work with a polynomial degree n = 213. These values
oﬀer a trade-oﬀ between maximizing performance of FHE applications [KL15, DGBL+16,
CLR17, CGM21, GCB+22] and minimizing CoFHEE’s area.

As CoFHEE is mainly a hardware accelerator for polynomial multiplication, it supports
all the high-level operations needed for this operation. These operations can be divided
into two types: compute operations and memory operations. Compute operations are
NTT, inverse NTT, and a set of pointwise operations, namely: Normal and modular
multiplication, modular squaring, modular multiplication by a constant, and modular
addition and subtraction. CoFHEE provides an ISA to execute any of these operations when
relevant polynomials are loaded into the memory. Meanwhile, memory operations copy the
data from one memory to another. Although compute operations run sequentially similar
to memory operations, both types can run simultaneously. The operations supported by
CoFHEE are listed in Table 2.

Mohammed Nabeel et al.

5

3.2 Clock frequency

CoFHEE’s frequency is deﬁned by the critical path of the design as well as the technology
node targeted. The critical path can be either in the computation unit due to a complex
data path or it can be in the memory as a consequence of memory read latency. While the
former can be reduced with pipelining, memory read latency is ﬁxed for the technology
node and memory size used. As expected, CoFHEE’s critical path is in the memory read
for loading data from the memory to the computation unit. For the technology node
targeted, i.e., Globalfoundries (GF) 55nm low power enhanced (LPE) process, the memory
read path is around 4ns, which translates to a clock frequency of 250 Mhz.

3.3 I/O

CoFHEE provides SPI and UART interfaces for external host communication. These
interfaces are used for loading polynomials, triggering the required operation and reading
back the result. SPI and UART are chosen mainly for their simplicity in implementation
as well as the ability to communicate from an external PC. One can always replace these
interfaces with faster ones such as PCI-express or HSIC (High-Speed Inter-Chip). CoFHEE
includes an additional UART interface that sends the start address of the result polynomial
to the external host once the triggered operation is done. In addition, CoFHEE provides
an interrupt to the external host as a way of signaling the completion of the triggered
operation. Other IOs in CoFHEE are clock, reset, voltage supplies, bias voltages, bias
currents, PLL controls, and debugging IOs. The clock input provides reference clock for
the PLL, reset is active low asynchronous, voltage supplies for digital are 3.3V for the IO
pads and 1.2V for the core standard cells and memories.

4 CoFHEE system design

4.1 Memory vs. compute

The chip area available for CoFHEE’s design is 12mm2, which is quite limited. As the
FHE application performs operation on big polynomial with large coeﬃcient size, CoFHEE
needs a large area to perform operation on big numbers and store big polynomials. It is not
possible to completely ﬁt all the required operands in this chip to perform any real-world
application. Hence, CoFHEE only stores subset of data to perform computationally
intensive operations.

We select to perform ciphertext multiplication on CoFHEE without any interaction from
an external interface, as ciphertext multiplication is the slowest FHE operation. Ciphertext
multiplication requires four polynomials and twiddle factors as input. Hence, it requires
ﬁve memories to store the input data. Ciphertext multiplication also requires two memories
to store internal calculations. The size of each of this memory is shown in Table 4. Total
memory area is the sum of dual-port memories, single-port memories for storing the data,
and for loading ARM instructions. This totals to around 9.8mm2. In the remaining area,
we ﬁt Processing Elements (PE), Multiplier Data Mover and Controller (MDMC), Direct
Memory Access controller (DMA), General Purpose Conﬁguration registers (GPCFG), and
an ARM Cortex-M0 with its own memory. Table 5 shows a representative subset of the 35
Conﬁguration Registers in CoFHEE. Our conﬁguration registers map to the 0x4002_0000
– 0x4002_FFFF memory range. In our design, the memory base address follows the ARM
Cortex M series memory map convention for memory and peripheral addresses.

For the design area available, we opted for a system architecture with 1 PE, 3 dual-
port and 5 single-port SRAMs. This selection of units enables support of ciphertext
multiplication fully on chip. In addition, dual-port memories enable computation with an
Initiation Interval II = 1 clock cycle. II is deﬁned as the number of clock cycles needed

6

CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution

to feed new operands to the computation units. If the polynomial coeﬃcients are stored
in a single-port SRAM, we cannot fetch two operands and store another two operands in
the same cycle. Hence, we choose to use dual-port SRAMs as it is possible to fetch/write
two operands per memory in the same cycle at a cost in area. Dual-port SRAMs takes
almost 2 times the area compared to single-port SRAMs. Therefore, we limit the number
of dual-port SRAMs to three, as two are required for computation to enable loading of
operands and storing of the results in the same cycle, and one serves as a buﬀer for loading
the next polynomial to go under NTT. DMA is used to move the next polynomial from
a single-port SRAM to the third dual-port memory while NTT is happening, adding no
extra latency.

4.2 Processing Elements (PE)

A processing element is a basic processing unit. CoFHEE’s PE supports modular mul-
tiplication, modular addition, and modular subtraction. Each of these operations has a
initiation interval of one. Modular addition and subtraction have a latency of one clock
cycle while modular multiplication completes in ﬁve clock cycles. We use a Barrett multi-
plier to implement multiplication and modular reduction due to its pipelining capabilities.
The pipeline depth is chosen such that the critical path matches the memory read latency.
In addition, a Barrett multiplier enables normal multiplication as it is possible to bypass
the modular reduction at the end. Our PE operates in four distinct modes deﬁned by
the mode selection input. The operations modes are: (1) Modular Multiplication, (2)
Modular Addition, (3) Modular Subtraction, and (4) Butterﬂy operation. The butterﬂy
operation is an atomic computational unit of NTT. It is executed by performing modular
multiplication followed by modular addition and modular subtraction. We implement
the butterﬂy operation using radix 2. Using the four modes, CoFHEE’s PE executes all
compute operations mentioned in Table 2 while occupying 6% of the design area. Normal
and modular multiplication, as well as modular squaring work on mode (1). Diﬀerent
bits in the operation command set ﬂags to, for example, bypass the modular reduction,
enabling a variety of similar operations to use the same hardware.

4.3 Multiplier Data Mover and Controller (MDMC)

The sequence of commands to be executed is stored in the command FIFO. As the name
implies, command FIFO is a queue that stores commands for execution. It decodes the
command and triggers the MDMC for the requested operation and provides the memory
base addresses of input operands and output result. When running compute operations,
the MDMC fetches data from memory and forwards to the PE on every clock cycle until
the operation is completed. Once the data is processed, the MDMC stores the data back
to the output memory. For NTT and iNTT, the MDMC needs to forward three input data
and store two output data per cycle. Thus, we can fetch two polynomial coeﬃcients from
one memory (dual-port) and a twiddle factor from another (single-port) in a single clock
cycle. Then after computing the butterﬂy operation, the MDMC stores the two outputs in
the output memory (dual-port). Once an NTT stage completes, the output memory acts
as input memory and vice-versa. This continues until the NTT/iNTT is ﬁnalized. The
MDMC performs complex operations which runs for thousands of clock cycles. For that
reason, it employs a ﬁnite state machine (FSM) to maintain internal information about
the ongoing operation.

Mohammed Nabeel et al.

7

Table 3: Input/output ports. →: direction.

Table 4: Area and timing estimations.

Pin Name

→ Description

CLK

in

HOST_IRQ

out

nPORESET
SPIS_CLK
SPIS_CS

in
in
in

SPIS_MISO

out

SPIS_MOSI

in

UARTM_TX out

UARTM_RX

in

UARTS_TX

out

Reference clock
to PLL
External host
interrupt
Active low reset
SPI IO clock
SPI Chip select
SPI MISO inter-
face for host read
SPI MOSI line
for host write
UART TX line
for host read
UART RX line
for host write
UART TX line
for debug and
compute done

Module

3 DP SRAMs
4 SP SRAMs
PE
CM0 SRAM
AHB
GPCFG
ARM CM0
MDMC
SPI
DMA
UART
GPIO
Others
Total

(ns)

Area Delay
(mm2)
5.3506
3.2036
0.6394
0.4062
0.0747
0.0534
0.0354
0.0273
0.0202
0.0075
0.0065
0.0035
0.0063
9.8345

4.22
4.19
5.65
6.13
5.76
7.03
5.24
4.16
7.74
7.17
5.66
6.73
-
-

4.4 System description

4.4.1 Interconnect

CoFHEE requires single memory transfers as well as burst memory operations. In ad-
dition, the data sizes range from 32 to 128 bits. The interconnect should provide this
ﬂexibility. Thus, we implement a parameterized Advanced High-Performance Bus (AHB)
lite interconnect [ARM01] as it supports the required bus transfer operations and has low
area utilization.

4.4.2 Execution modes

There are three ways to execute the basic operations supported by CoFHEE (Table 2):
1) The simplest option is for the external host to directly trigger the MDMC to perform
the commands through a conﬁguration register write. This mode is slow as there are
delays imposed by the communication interface when writing to the conﬁguration register.
2) Another possibility is to use the command FIFO, where the external host preloads
the sequence of commands to be executed and waits for an interrupt issued by CoFHEE
signaling that the queue is empty. As soon as the ﬁrst command is written to the queue,
the command FIFO sends it to the MDMC. The MDMC starts the operation and once it
completes, it sends a signal to the command FIFO. The process repeats until all commands
have been executed. The command FIFO guarantees the execution of a single command
at a time in a predeﬁned order. Thus, it requires less control logic and avoids complicated
out-of-order executions. In addition, the command FIFO gives the ﬂexibility to execute
diﬀerent complex operations as combinations of basic instructions. We deﬁned the length
of the queue to be 32 commands, as it is more than suﬃcient for our target applications.
The host can continuously load more commands while the queue is not full. 3) For a faster
and ﬂexible sequencing and execution of commands, we introduce a third mode, which
utilizes a 32-bit ARM Cortex M0 (CM0) along with a dedicated instruction memory. In
this mode, the processor is used instead of the command FIFO. One can write complex

8

CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution

Table 5: Subset of CoFHEE Conﬁguration Registers.

Register Name

Description

UARTMTX_PAD_CTL IO pad control for primary UART TX
UARTMRX_PAD_CTL IO pad control for primary UART RX
UARTSTX_PAD_CTL
SPIMOSI_PAD_CTL
SPIMISO_PAD_CTL
SPICLK_PAD_CTL
SPICSN_PAD_CTL
HOSTIRQ_PAD_CTL
UARTM_BAUD_CTL
UARTS_BAUD_CTL
UARTM_CTL
UARTS_CTL
SIGNATURE
Q
N
INV_POLYDEG
BARRETTCTL1
BARRETTCTL2
FHECTL1
FHECTL2
FHECTL3
PLLCTL
COMMANDFIFO
DBG_REG

IO pad control for secondary UART TX
SPI data in pad control
SPI data out pad control
SPI clock pad control
SPI chip select pad control
IO pad control for Host Interrupt
Baud control for primary UART
Baud control for secondary UART
Primary UART control
Secondary UART control
Stores Chip ID
Modulus q
Polynomial degree n
n−1 mod q
barrettk = 2 · log n
barrett constant = 2barrettk/q
Command FIFO select and n
Trigger bits for diﬀerent commands
Select or bypass PLL clock
Control bits required for the PLL
Trigger bits for diﬀerent commands
Debug register

Bit
Size
32
32
32
32
32
32
32
32
32
32
32
32
32
128
128
128
32
160
32
32
32
32
32
32

subroutines and sequence of operations in embedded C, then compile and preload it in
CM0’s instruction memory for later execution.

4.4.3 NTT considerations

As discussed earlier, for a 2× performance improvement of NTT, the input and output
polynomials are stored in dual-port memories. In addition, there is a third dual-port
memory to store the next polynomial to go under NTT. If the next polynomial is in
a single-port memory, DMA is used to transfer polynomial coeﬃcients to the available
dual-port memory while NTT operates on the current polynomial. This is possible since
the bus architecture allows the MDMC, DMA, and ARM CM0 to access memories in
parallel. Once NTT completes, the dual-port memories switch tasks; the one containing
the next polynomial participates in the NTT, while the memory containing the output
uses DMA to oﬄoad the result to a single-port memory and load the next polynomial
for NTT. This process happens transparently in the background without performance
degradation due to data movement.

4.4.4 Architecture

Fig. 1 shows CoFHEE’s top architecture. The PE is connected to the MDMC, which in
turn has a direct connection to the command FIFO and communicates with the memories
using the AHB lite interconnect. The AHB lite interconnect connects all IPs and ensures
reliable data movement with variable data sizes. The MDMC performs memory reads and

Mohammed Nabeel et al.

9

Figure 1: Top Level Architecture.

writes for computation; DMA transfer data from one memory to another; and the external
interfaces communicate with the host.

As FHE polynomials are large, most of the design area is dedicated to memories.
The memory size is deﬁned by the polynomial degree, as it indicates the number of
coeﬃcients, and the coeﬃcient size. Although CoFHEE’s architecture can support any
polynomial degree, the chip area available for fabrication is limited to 12mm2. Considering
this limitation in area, the targeted technology node (55nm), and common encryption
parameters used in FHE applications (Section 2.2.1), we can achieve our goal of performing
ciphertext multiplication on chip for a maximum polynomial degree n = 213 with 128-bit
coeﬃcient sizes. A 128-bit coeﬃcient size is the largest coeﬃcient we can ﬁt in CoFHEE
given design area limitations and the need for 3 dual-port and 4 single-port memories.
According to Table 1, secure ciphertext moduli q range from 109 bits for 256-bit post-
quantum security to 218 bits for 128-bit classical computer security. When log q > 128 bits,
the polynomial coeﬃcients must be broken into smaller coeﬃcients using RNS, a common
technique used in FHE computation (Section 2.2.2). For n = 214, CoFHEE can perform
NTT on chip with II = 2, as single-port memories have to be used in the computation.
However, while polynomial multiplications and ciphertext multiplications are also possible,
they require back-and-forth data movement with the host, as it is not possible to ﬁt all
data on chip. Larger polynomial (n > 214) on the other hand are too large even for the
NTT operation and, therefore, CoFHEE does support them. Nevertheless, such larger
polynomials are not commonly used in FHE application due to their higher overheads
(Section 2.2.1).

4.5 Pre-silicon veriﬁcation

We veriﬁed the functionality of our RTL design using both simulation and FPGA-based
validation. The simulation was performed using Synopsys VCS at the top-level. A python
script is used to calculate the modulus following the equation q = 2k · n + 1, where k ≥ 1 is
an arbitrary constant. In addition, the script ﬁnds twiddle factors, generate random input
polynomial coeﬃcients, and calculate expected results. We use random coeﬃcient values
modulo q for our test polynomials since the 128-bit operand range cannot be exhaustively
tested. These values are then ported to the verilog testbench, where they are loaded and
the result from the design is compared against the expected result. Moreover, for our FPGA
design, we implemented a scaled-down version of CoFHEE, as n = 213 is incompatible
with the available resources of our FPGAs. Speciﬁcally, the maximum polynomial degree
that could be supported on a Digilent Nexys 4 is n = 212 running at 10 MHz.

10

CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution

4.6 Synthesis

CoFHEE’s RTL code is synthesized using a 55nm standard cell library from Globalfoundries
and a clock constraint of 250 Mhz. SPI IO timing is constrained to meet 50 Mhz of interface
speed. There is no speciﬁc IO timing constraint set for UART as it is an asynchronous
interface. Following standard practices, the standard cell library used for synthesis was
the one characterized for the worst voltage (1.08V), temperature (125C), resistance, and
capacitance. Synthesizing with such a library ensures that we can achieve the target
frequency in various operating conditions. For synthesis, we use the Synopsys Design
Compiler (DC). In Table 4, we presents the area and timing estimations of the major
CoFHEE blocks after synthesis. Other than memory, the largest design is the PE, followed
by AHB and conﬁguration registers. Post-synthesis there are many blocks with critical
timing path much higher than the target clock period of 4ns. This is because synthesis
setup uses restricted standard cell library with no access to faster library cells such as
the ones with lower threshold voltage Vt. As these paths are long combinational paths,
they easily meet timing in the backend, where all the standard cell libraries are used. In
this condition, paths starting from memory become the critical path due to memory read
latency (around 3.1ns).

5 CoFHEE front-end design

5.1 Modular multiplier

Modular multiplication involves normal multiplication followed by a modular reduction of
the product. There are few popular ways to implement modular multipliers; interleaved
multiplier, Barrett multiplier, and Montgomery multiplier [MVOV18]. Barrett is selected
for our implementation as there is no need to transform the arguments, as required for
Montgomery [BGV93]. It has II of one and the target frequency can be achieved by
pipelining a single Barrett design where as for the interleaved multiplier, to achieve II
of one, one needs to increase the number of such multipliers linearly, thus increasing the
design area and the number of nets in the design.

5.2 NTT

The Number Theory Transform (NTT) is the generalized Discrete Fourier Transform
(DFT). It is an integral part of FHE algorithms for accelerating polynomial multiplications
over ﬁnite ﬁelds. Without NTT, polynomial multiplications have quadratic complexity
O(n2). NTT converts polynomials to a domain that reduces the complexity of polynomial
multiplications to linear O(n). A polynomial multiplication in the NTT domain is simply a
coeﬃcient-wise multiplication of two polynomials. Nevertheless, NTT has a time complexity
of O(n log n), therefore, the complete polynomial multiplication including NTT has this
complexity. There are several algorithms for NTT [CT65, GS66]; CoFHEE implements the
Cooley-Tukey algorithm [CT65] as shown in Algorithm 1. Each of the log n stages of NTT
computes n/2 butterﬂy operations. The butterﬂy operation is discussed in Section 4.2.

5.3 Polynomial Multiplication

Polynomial multiplication over rings is the main operation in ciphertext multiplication
for RLWE-based FHE. This operation can be divided into two parts: (1) Multiplication
and (2) Reduction. 1) For the ﬁrst part, we use NTT to reduce the complexity of the
operation from O(n2) to O(n log n), as discussed in Section 5.2. 2) The second part reduces
the polynomial over the polynomial modulus. This operation is avoided using Negative
Wrapped Convolution (NWC). NWC requires the 2nth primitive root of unity and reduces

Mohammed Nabeel et al.

11

Algorithm 3 Ciphertext Multiplication
Input: (A0(x), A1(x)) ∈ Zq[x]/xn + 1
Input: (B0(x), B1(x)) ∈ Zq[x]/xn + 1
Input: nth roots of unity ~ω ∈ Zq
Input: 2nth roots of unity ~ψ ∈ Zq
Output: Yi(x) ∈ Zq[x]/xn + 1 ∀i ∈ [0, 2]
(cid:5) Y0(x) = A0(x) × B0(x)
(cid:5) Y1(x) = A0(x) × B1(x) + A1(x) × B0(x)
(cid:5) Y2(x) = A1(x) × B1(x)

0(x)

0(x) • B0

0 (x) • ~ψ−1), ~ω)

0(x) = NTT((B0(x) • ~ψ), ~ω)
1: B0
0(x) = NTT((A0(x) • ~ψ), ~ω)
2: A0
0 (x) = A0
3: Y 0
4: Y0(x) = iNTT((Y 0
1(x) = NTT((B1(x) • ~ψ), ~ω)
5: B0
01(x) = A0
0(x) • B0
6: Y 0
1(x) = NTT((A1(x) • ~ψ), ~ω)
7: A0
2 (x) = A0
8: Y 0
9: Y2(x) = iNTT((Y 0
1(x) • B0
10(x) = A0
10: Y 0
01(x) + Y 0
1 (x) = Y 0
11: Y 0
12: Y1(x) = iNTT((Y 0
13: return (Y0(x), Y1(x), Y2(x))

0(x)
10(x)
1 (x) • ~ψ−1), ~ω)

2 (x) • ~ψ−1), ~ω)

1(x) • B0

1(x)

1(x)

Algorithm 1 Number Theory Transform
Input: polynomial (~x)
Input: roots of unity (~ω)
Input: modulus (q)
Output: polynomial (~x)
1: idx = 0
2: for i ← n/2; i >= 2;i = i >> 1 do
for j ← 0; j < n/2;j = j + i do
3:
4:
5:
6:
7:
8:
9:
10:
11:
12: end for

m = twiddle * ~x[k+i]
m = reduceq(m)
~x[k+i] = reduceq(~x[k] - m)
~x[k] = reduceq(~x[k] + m)

twiddle = ~ω[idx++]
for k ← j; k < j + i; k = k + 1 do

end for

end for

Algorithm 2 Polynomial Multiplication
Input: A(x), B(x) ∈ Zq[x]/xn + 1
Input: nth roots of unity ~ω ∈ Zq
Input: 2nth roots of unity ~ψ ∈ Zq
Output: Y (x) ∈ Zq[x]/xn + 1
(cid:5) Y (x) = A(x) × B(x)

1: A0(x) = NTT((A(x) • ~ψ), ~ω)
2: B0(x) = NTT((B(x) • ~ψ), ~ω)
3: Y 0(x) = A0(x) • B0(x)
4: Y (x) = iNTT((Y 0(x) • ~ψ−1), ~ω)
5: return Y (x)

the polynomial degree to n − 1 over the polynomial xn + 1. Algorithm 2 describes the
polynomial multiplication operation supported by CoFHEE.

5.4 Ciphertext-ciphertext multiplication

The ciphertext multiplication is the slowest operation in FHE computation. We discuss it
in detail in Section 2.2.1. Algorithm 3 describes this operation as handled by CoFHEE.
Two ciphertexts (polynomial pairs) are passed as input. The ciphertext polynomials are
multiplied following Eq. 4. Each polynomial is used twice in polynomial multiplications.
Nevertheless, we only need one NTT operation per polynomial as they can stay in the
NTT domain during the polynomial multiplication and addition. At the end, we can
convert back from the NTT domain using the iNTT operation. The entire ciphertext
multiplication in CoFHEE utilizes 4 NTT operations, 4 Hadamard products, 1 pointwise
addition, and 3 iNTT operations.

6 CoFHEE back-end

This section covers CoFHEE’s physical design aspects. Table 8 summarizes the stages and
EDA tools utilized. CoFHEE’s total die area including the seal ring is 15mm2. We use
inline pads placed on all four sides of the chip. Table 9 provides additional information
about signal and power/ground pads. The synthesized netlist and constraints is obtained

12

CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution

Table 6: Optimization scenarios and analysis types.

Scenario
std_max_ss_nominal_max_1p08v_125c_cmax
std_max_tt_nominal_max_1p20v_25c_cmax
std_min_ﬀ_nominal_min_1p32v_m40c_cmin
std_min_tt_nominal_max_1p20v_25c_cmin
std_min_ﬀf_nominal_min_1p32v_125c_cmin

Analysis Type

setup

hold

from Synopsys Design Compiler. This is fed to IC compiler in order to create a design
milkyway database. We use the provided parasitic corners and timing libraries to deﬁne
various scenarios for timing optimizations, as detailed in Table 6. In addition, we create
an Uniﬁed Power File (UPF) to specify the power intent and deal with power and ground
connections more easily. CoFHEE achieves an operational frequency of 250 Mhz at the
slowest corner in the ﬁnal layout. In Table 7 we show the physical parameters with respect
to our layout after multiple iterations.

6.1 Floor Planning

The die dimensions are 3660µm × 3842µm. Fig. 2a shows the design’s ﬂoorplan, which we
focused on maximizing the use of available silicon. The corner pads overlaps the memories
at three corners. These overlapping regions within corner pads are empty, thus they do
not cause any DRC/LVS concerns at the same time maximise the available silicon for logic
gates and memories. There is a phase-locked loop (PLL) placed at the upper right corner of
the chip. The associated 10 pads are also placed in this corner. This includes AVDD/AVSS
pads which are the PLL power and ground pads. There are four bias voltage and four bias
current pads that are used to bias the PLL to operate in the designed operation range.
Overall we have 68 memories, of which 48 (16x2096) are dual-port, and 16 (32x8192) plus
4 (32x4096) are single-port. There are 47 IO pads including power and signal pads. We
use two special pads to generate Power On Control (POC), an important signal to stabilize
IOs. In addition, there are two pads for VDD (core power supply), VSS (core ground),
and IO power/ground (DVDD/DVSS). Furthermore, in this stage we place edge cells at
the boundaries and well tap cells throughout the layout in a staggered fashion according
to the foundry speciﬁcations in order to avoid latchup violations.

6.2 Power Planning

Our power network consists of 4 pairs of VDD/VSS rings around the core region. Of the
eight metal layers, the top two (BA and BB) are used for rings. Fig. 2f captures these rings
from the layout. All the power and ground pads are connected to these rings with multiple
connections, as shown in Fig. 2d. Multiple power and ground straps in BA, BB, M5,
and M4 runs over the entire core region at diﬀerent pitches of 30µm (BA/BB) and 50µm
(M4/M5). M1 rails are connected directly to M4 straps through stacked vias. Fig. 2b
shows a high-level picture of our power/ground network. This involves power rings, straps,
standard cell power rails and connection to pad and memory pins. Fig. 2e shows how
the straps are connected to each other in the power network until M4 that delivers power
to the standard cell rails through stacked vias. This connection, shown in Fig. 2g, helps
avoiding power straps in M2 that may create standard cell pin access issues. A smaller
pitch makes the power structure more robust but reduces signal routing resources, while a
wider pitch weakens the power structure but provides more resources for signal routing.
The pitches were decided after multiple iterations analysing the routing congestion, IR
drop and eﬀective resistance. One of the challenges in power network synthesis (PNS) is to
ensure delivering power in all channels between the memories. PNS ﬂow was modiﬁed to

Mohammed Nabeel et al.

13

Table 7: Layout physical parameters.
Value
Parameter
45 %
IU (Initial Utilization)
FU (Final Utilization)
59 %
8,941,959 µm2
MA (Macro Area)
120 u
HIO (IO PAD Height)
10 u
CIO (Core to IO spacing)
A (Aspect ratio)
1.05
1,963,585 µm2
CA (std cell Area)
3400 u
CW (Core Width)
3582 u
CH (Core Height)
3660 u
DW (Die Width)
3842 u
DH (Die Height)

Table 8: Stages and EDA tools.

Stage

Place and Route

Interconnect para-
sitic extraction
Static timing ana-
lysis
GDS merging and
layout modiﬁcation
Physical veriﬁca-
tion

Tool
Synopsys
IC compiler
Synopsys
STAR-RCXT
Synopsys
Prime-Time-SI
Cadence
Virtuoso
Cadence PVS
System

Table 9: Design statistics.

Parameter
Width
Height
Signal pads
PG pads
PLL bias pads
Memories
clock name
CTS synth. corner
Levels
Sinks
Clock tree buﬀers
Global Skew
Longest Ins. delay
Shortest Ins. delay

Value
3660
3842
26
11
8
68
HCLK
slow
26
18413
464
240 ps
2.079 ns
1.838 ns

Layer

Table 10: Redundant via statistics.
total multi-
cut (%)
(#)
98.70
21,945
99.49
21,844
99.80
22,035
99.76
26,455
99.51
2,450
99.78
1,393

multi-
cut (#)
21,659
21,732
21,991
26,391
2,438
1,390

V1
V2
V3
V4
WT
WA

ensure that every memory channel is delivered power and ground properly. The memory
Power Ground (PG) pins runs on M4 on top of them. The connections to these memories’
power/ground pins are made by dropping vias from M5 straps running over them. The
PLL needs four bias voltages and four bias currents in addition to the PG pads AVDD
and AVSS. Connecting the PLL to these pads is also performed at this stage. An abstract
view of the PLL is generated from the PLL layout and annotated in the top-level chip for
this purpose.

6.3 Place and Route

The design is then taken through place and route. Placement optimization is done in one
slow and one typical corner. Special variables are enabled in order to prevent cell clustering
and, as a consequence, congestion hot spots. Proper non-buﬀer blockages are added in
the narrow channels between memories. This prevents the insertion of combinational and
sequential cells in the channels and, thus, avoid causing either timing, congestion, or bad
clock tree synthesis. Few iterations are performed between placement, memory, and IO
pad placement to arrive at the ﬁnal ﬂoorplan. Fig. 2h shows the module placement. Clock
tree synthesis follows placement and optimization. All the clock trunk nets are routed with
double width double spacing as per standard design ﬂow. We have restricted the usage of
clock buﬀers and inverters to avoid very low and very high driving strength buﬀers. Very
low drivings strength buﬀers are more susceptible to small changes in load and very high
driving strengths are power hungry and may aﬀect dynamic IR drop. Fig. 2c presents
clock network routing. Signal routing and post-route optimization follows. Redundant

14

CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution

Table 11: Design statistics through PnR.

Parameter
Standard cells
Sequential cells
Buﬀer/Inverter cells
Std. Cell Utilization
Signal nets
HVT cells
RVT cells
LVT cells

Initial
225,797
18,686
22,561
45%
257,856

Place
376,853
18,686
89,072
54%
398,340
100% 13.75%
0%
17%
0% 69.25%

CTS Route
379,921
18,686
92,379
59%
401,510
13.4%
12%
74.6%

378,957
18,686
91,372
56.5%
401,407
13.5%
12.1%
74.4%

via insertion is performed in order to improve yield. Decap and standard cell ﬁllers are
inserted before streaming out GDS from IC compiler.

Table 9 provides the details of clock tree QOR for the main clock. The clock tree was
built in the slow process corner for around 18k sinks and achieved skew of 240ps with 2ns
latency. In Table 10, we present the percentage of redundant vias for various via layers.
We were able to achieve more than 98% conversion of single to multi-cut vias for the lower
via layers V1, V2, V3, V4, yet a lower percentage was achieved for higher layers. Likewise,
in Table 11, we present design statistics over various stages in the Place & Route (PnR).
We remark that the standard cell count increases as the design moves from initial to ﬁnal
routing stages, primarily due to buﬀers/inverters inserted in the design to ﬁx design rule
violations, clock tree synthesis, and timing issues. Our design started with 100% HVT
cells and ended up with 13.4%, as HVT cells were swapped with RVT and LVT cells to
address timing and DRV ﬁxes (Table 11).

6.4 Sign-Oﬀ Analysis

The design GDS obtained from IC compiler is merged with standard cell, memory, and
IO pad GDS. Seal ring is added on top and metal ﬁll insertion procedure follows. Metal
ﬁll insertion is done in Mentor-Calibre and resulting GDS is merged with design GDS to
obtain the ﬁnal GDS. Sign-oﬀ DRC/LVS is then performed on this GDS using Cadence
PVS. Design parasitic extraction is done using STARRC-XT and the resulting SPEF along
with design netlist is fed to Synopsys Primetime-SI for static timing analysis. The ﬁnal
DRC/LVS and timing clean GDS is sent to MOSIS for further checks before releasing to
Globalfoundries.

6.5 PLL design

Silicon area, power consumption, range of operation, and timing uncertainty are among the
metrics that dictate the choices of a PLL architecture as well as implementation strategies.
For a given jitter performance, analog implementations require a loop ﬁlter with a big
capacitor making the overall PLL size large. On the other hand, a digital PLL provides
an alternative with signiﬁcantly smaller silicon area. Moreover, a digital implementation
results in a low power implementation. In addition, a wide range of operation is essential
to run the chip at diﬀerent frequencies. This enables reusing the PLL in diﬀerent designs,
avoiding PLL redesign. In this work, a compact, low power, and wide tuning range All
Digital PLL (ADPLL) has been implemented. The block diagram of the proposed ADPLL
is shown in Fig. 3a, while the layout is presented in Fig. 3b. It is a dual-loop architecture
with dedicated frequency and phase-locking loops. The Frequency-Locking Loop (FLL)
is a feedback loop which forces the frequency diﬀerence between the input signal and
the oscillator output down to the capture range of the phase-locking loop. Similarly, the

Mohammed Nabeel et al.

15

(a) Floorplan.

(b) Power network.

(c) Clock network.

(d) Power pad connections.

(e) Power straps (zoomed in).

(f) Power ring (zoomed in).

(g) Power connection to stan-
dard cell rails from M4.

(h) Module placement. AHB (peach), Cortex
M0 (green), DMA (yellow), MDMC (purple),
Multiplier pool (red), and SPIM (blue).

Figure 2: Backend results.

Phase-Locking Loop (PLL) forces the phase error between input signal and the oscillator
output to zero.

The capture range of the phase detector (PD) is a few percent of the reference
clock frequency which is much smaller than the required tuning range of the ADPLL.
Consequently, a frequency-locking mechanism is required to pull the frequency of the local
oscillator close to the operating frequency such that the PD with its narrow pull-in range
can assume responsibility. The choice of the frequency detector architecture used is based
on the requirements that it should be easily interfaced with digital loop ﬁlters and allow a
wide range of operation. A digitized Phase and Frequency Detector (PFD) with Successive
Approximation Register (SAR) algorithm [RF96][Mur16][Rus78] is employed to generate
the appropriate digital control word to switch the required current value.

The phase-locking loop consists of a modiﬁed Alexander (Bang-Bang) phase detector
[Ale75][LKR04] and an all-digital loop ﬁlter in order to detect the phase error and generate

16

CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution

(a) Block diagram.

(b) Layout implemented in GF 55nm.

Figure 3: Proposed ADPLL design.

an appropriate control signal. The main requirements on the choice of the phase detector
architecture originate from the need to use an all-digital loop ﬁlter, as it is compact, can
easily be integrated with ASIC designs, and ported between technology nodes. For these
reasons, the phase detector should generate outputs which enable a digital implementation.
In this design, a modiﬁed version of the widely used Bang-Bang phase detector (BBPD)
is proposed. BBPD, also known as the early-late detection method, utilizes three data
samples taken by three consecutive clock edges to determine whether a data transition is
present or not, and if the clock leads or lags the data. In the absence of data transitions,
all three samples are equal, and no action is taken.

The loop ﬁlters in the FLL and PLL produce, respectively, digital control values from
the instantaneous phase and frequency error signals generated by the frequency and phase
detectors. The outputs of the loop ﬁlters are used to allow the appropriate amount of
supply current to the oscillator in order to correct for possible frequency or phase errors.
Since the oscillator frequency is controlled by current switching, segmented decoding is
employed to avoid potential discontinuities and glitches. This is achieved by implementing
a combination of binary and unary weighted current sources. To avoid any conﬂict between
the frequency and phase correcting loops, a digital lock detector is used. We implement
the ADPLL in GF 55nm CMOS technology. It occupies an active area of 0.05mm2 and
consumes 350µW from a supply of 1.1V .

7 CoFHEE post-silicon validation

7.1 CoFHEE API

CoFHEE exposes assembly-like instructions for loading/storing data from/to the host,
performing NTT, iNTT, normal and modular coeﬃcient-wise multiplication, addition,
subtraction, and squaring, and memory-to-memory data transfer, as listed in Table 2.
Composed operations such as polynomial multiplication or ciphertext multiplication build
on top of the atomic ones.

CoFHEE’s design is optimized for n = 213. Nevertheless, it supports any n ≤ 214,
assuming that n is a power of two. It can perform NTT, polynomial multiplications,
and ciphertext multiplications on chip with II = 1, without requiring back-and-forth
communication to the host during the computation for any n ≤ 213. In the case of n = 214,
CoFHEE can perform NTT on chip with II = 2, as single-port memories need to be used
for computation, while polynomial and ciphertext multiplications require back-and-forth
communication.

Mohammed Nabeel et al.

17

The maximum coeﬃcient size supported by CoFHEE is 128 bits. Additions and
subtractions take 1 cycle and multiplication takes 4 cycles, independently of the coeﬃcient
size. Coeﬃcients larger than 128 bits must be broken using RNS, similarly to how it is
done in software, to ﬁt in CoFHEE.

7.2 Validation

CoFHEE is packaged in a 48-pin QFN, and connects to a breadboard via QFN to the
DIP adapter for chip bring-up and testing. For interfacing with a host computer, we
use a UMFT230XA development board that features an FTDI chip for USB-to-UART
conversion. The UMFT230XA board provides a 3.3V supply for CoFHEE’s IO pad, as
well as a clock output which is used as reference clock for the PLL and also can be used as
the clock source of the chip when PLL is bypassed. Moreover, the required 1.2V supply
was generated using a DC-DC adjustable step-down module that converts the 5V source
of the UMFT230XA board. In addition, an USB-to-UART breakout is used to receive
the computation complete signal from CoFHEE. For the power measurement, a Tektronix
MSO 5204B oscilloscope is used with current probe. Our post-silicon validation setup is
shown in Fig. 4. It conﬁrms that the fabricated chip is fully functional.

8 Experimental results

8.1 Power and latency

We measure latency and power for several operations supported by CoFHEE using n =
{212, 213}. Table 12 summarizes the ﬁndings. Peak power is observed during NTT, while
Hadamard and iNTT takes lesser power. Inverse NTT involves multiplication with a
constant (n−1) and the decimation in frequency operation. Its average power is lower as
the constant multiplication consumes less power and reduces the average. For the same
reason, iNTT takes more cycles than NTT to execute. To summarize, CoFHEE needs a
power supply with peak power rating of around 30 mA and average power of around 25
mA to run polynomial multiplication in a fraction of a millisecond.

8.2 Comparison to CPU

We compare CoFHEE against a software implementation in terms of execution time
and power consumption using a ciphertext multiplication without relinearization. We
use one instance of CoFHEE fabricated in GF 55nm operating at 250 MHz. For the
software implementation, we use the Microsoft SEAL 3.7 library [SEA21] running on an
AMD Ryzen 7 5800h (TSMC 7nm FinFET) at 3.8 Ghz with 16 GB of RAM on Ubuntu
20.04 LTS, and we collect the power measures using powertop. We set n = {212, 213}
and log q = {109, 218} bits, which provide a security level of 128 bits against classical
computers. Fig. 5 presents the results.

For (n, log q) = (212, 109), SEAL breaks the 109-bit modulus into three smaller moduli
of 36, 36, and 37 bits using RNS for faster computation in the native 64-bit architecture.
Each of these three towers must perform the ciphertext multiplication according to Eq. 4.
For the same operation, CoFHEE natively supports 128 bits, therefore, it requires only
one tower. As shown in Fig. 5a, the software implementation takes 2.1ms to operate on
the three towers, while CoFHEE needs 0.84ms to ﬁnalize the ciphertext multiplication.
Regarding power (Fig. 5b), CoFHEE is two orders of magnitude more eﬃcient as it
requires 22.9mW of power, while the software implementation uses 1.47W .

When (n, log q) = (213, 218), the software implementation uses ﬁve towers of around 44
bits (43 + 43 + 44 + 44 + 44 = 218) and CoFHEE requires two towers (109 + 109 = 218).
For the ﬁve < 64-bit towers, SEAL spends 8.5ms, while CoFHEE takes 3.58ms to operate

18

CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution

Table 12: Performance for n = {212, 213}.
Frequency: 250 MHz.

Algorithm

Latency

(cc)

(µs)

Power (mW )
peak
avg.

PolyMul
Hadamard
NTT
iNTT

n = 212

83,777
4,627
24,841
29,468

335.1
18.5
99.4
117.9

n = 213

PolyMul
Hadamard
NTT
iNTT

179,045
9,235
53,535
62,770

716.2
36.9
214.1
251.1

22.9
17.4
24.5
19.9

21.2
16.4
24.4
18.3

30.4
24.1
30.4
27.2

29.7
23.7
29.7
23.9

Figure 4: CoFHEE’s validation and
experimental setup.

(a) Time for all towers.

(b) Power.

Figure 5: Comparison between CoFHEE and a software implementation performing a
ciphertext multiplication for n = {212, 213} without relinearization.

on the two < 128-bit towers. Power readings are 21.2mW for CoFHEE and 2.32W for
the software implementation. It is expected an ASIC design to be more eﬃcient than a
general purpose processor. Nevertheless, CoFHEE is so with an inferior technology node
and much smaller design footprint. Given comparable conditions to commercial devices,
we anticipate CoFHEE’s eﬃciency to increase manifold.

9 Related Work

FHE acceleration has become a major research interest in the recent years. So far, many
diﬀerent approaches have been proposed, consequently leading to a state-of-the-art that is
comprised of FHE acceleration solutions that are based on software, GPU, FPGA, and ASIC
[JLK+20], [RLPD20a], [MÖS19], [HS20], [RCK+21], [CA16], [CRS16], [BDH21]. Each
method has demonstrated considerable advantages, however due to hardware diﬀerences,
establishing an accurate comparison point between each technology is not feasible, therefore
we focus on ASIC designs in our discussion. Table 13 summarizes existing works on ASIC.
In addition, there are also works that have focused on the acceleration of polynomial
multiplications using ASIC designs, however they do not focus in FHE applications.

Mohammed Nabeel et al.

19

Table 13: Related work of ASIC designs of FHE accelerators. n stands for the maximum
polynomial degree, while log q represents the maximum modulus size natively supported
by the hardware (i.e. without requiring RNS).

Design

CoFHEE
[TCH+21]
[FSK+21]
[TAA+19]

Node
(nm)
55
32
14/12
32

n

214
212
214
212

log q Area
(mm2)
(bits)
12
128
57.1
32
151.4
32
-
32

Area
(kgates)
-
-
-
6.54

Freq.
(M hz)
250
-
1000
-

Power
(W )
2.3 · 10−2
2.3 · 10−2
1.8 · 102
-

Fab.

(cid:108)
(cid:109)
(cid:109)
(cid:109)

While some may focus on diﬀerent variants of homomorphic encryption such as PHE and
SHE, many works focus purely on developing an acceleration method without taking into
account the application the method can potentially be applied to [AARK18] [BNR18]
[DL17] [AK16] [KWL16] [WLYS12] [SKF+11] [KVV10].

One of the most recent works produced by Tan et al. presents a scalable and parallel de-
sign for NTT-based polynomial multiplication [TCH+21]. The implementation is designed
with a variable number of reconﬁgurable PEs, which allows its optimization according to
the constraint parameters of the targeted hardware platform. The authors also manage to
minimize the memory access conﬂicts and achieve a very high utilization rate by proposing
addressing and scheduling schemes. In order to evaluate their proposal, they implement
the design using 32nm technology, and select a 32-bit prime q, and polynomial degrees of
n = 210 and n = 212.

Tan et al. also present another scalable architecture for polynomial multiplication
[TAA+19]. This work manages to achieve full utilization of the processing elements
using a conﬂict-free memory management scheme, however the implementation is focused
towards improving the performance of the bootstrapping algorithm. The proposed design
is implemented using 32nm technology.

Another work proposed by Feldmann et al. focuses on developing an accelerator for
the execution of FHE programs [FSK+21]. The solution can be described as a wide-vector
processor with novel functional units deeply specialized to FHE primitives like modular
arithmetic, NTT, and structured permutations. As the authors explain, the biggest issue
in this design is not the throughput but the data movement, therefore their primary goal
was to minimize the movement of data. However, there are limited information about the
backend process of the design, and whether the proposed architecture can be placed on real
silicon without routing congestion, as well as power and clock issues. The programming
API is not clear either, since the focus is more on architecture exploration and less on
getting a real chip.

CoFHEE uses a 128-bit multiplier while [FSK+21] uses 32-bit multipliers. Furthermore,
[FSK+21] has two multipliers, two adders, and one NTT unit which provides faster
performance compared to CoFHEE. Our chip can divide in less towers of RNS, which leads
to a more compact relinearization in terms of memory usage. It is also important to note
that a considerable diﬀerence between the two works is their node technology. While our
work is fabricated and silicon proven in 55nm, Feldman’s design targets 14/12nm technology
which makes comparison across nodes diﬃcult to accurately perform. Nevertheless, to the
best of our knowledge, CoFHEE is the only FHE accelerator to be proven in silicon.

20

CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution

10 Discussion

10.1 CoFHEE scalability

To support operations on higher polynomial degrees n ≥ 214 with II = 1, CoFHEE needs
more area for memories, which increase linearly to the polynomial degree. As the memory
size increases, memory read latency increases, which leads to a minor reduction in clock
frequency. However, if the goal is to improve performance for a particular n, there are a
few options: 1) We could perform more than one one butterﬂy per cycle. For that, one
has to duplicate the multiplier pool and add more memories to increase parallel accesses
of operands. For NTT with II = 1, two dual-port memories and one multiplier pool are
required. Doubling this improves throughput by close to, but less than 2× as one can split
the polynomial of degree n into two smaller polynomials of degree n/2, perform NTT on
these smaller polynomials in parallel, recombine them and perform the last stage of NTT of
the original polynomial. This eﬀectively means that log(n)−1 stages operate with II = 0.5,
while the last stage has II = 1. 2) Another approach is to increase the number of memories
and processing units available. The former increases the number of polynomials on chip,
enabling more complex scheduling methods which reduce communication costs with the
host. With more memories and processing units, parallel operations on non-dependent data
is also possible. Combined better scheduling and parallel processing, doubling CoFHEE’s
resources would more than double the throughput.

CoFHEE’s AHB interface connects to scalable and ﬂexible components. It supports up
to 16 controllers, memories, and peripherals and, with ARM Cortex M0, it has 28 bits for
addressing internal memory. Hence, it is possible to increase the total memory size from 1
MB (currently used) to 256 MB. For faster communication, UART or SPI can be replaced
with protocols such as Peripheral Component Interconnect Express.

10.2 Lessons Learned
Using the AHB bus to fetch operands and load them to the computation unit avoids
complex muxing structures [RLPD20b] that come from non trivial addressing of operands
and twiddle factors in every NTT stage. During NTT, CoFHEE’s address generation unit
generates the relevant addresses for operands and twiddle factors at every cycle and issues
a bus transaction.

Although the addition of dual-port memories improves the throughput signiﬁcantly,
their area is 2× the area of single-port memories of same size. Therefore, it is important
to minimize the number of dual-port memories without aﬀecting throughput. In CoFHEE,
the number of dual-port memories is three. Thus, two of them can be used for computation,
while the third is used along with DMA to buﬀer the next polynomial for execution.

While separate twiddle factors have been used for NTT and iNTT in previous works
[RLPD20b], CoFHEE uses the same twiddle factors for both operations by combining
MDMC and DMA operations. Thus, it reduces the required chip area for FHE acceleration.

11 Conclusion

In this work, we present a year-long eﬀort to design, implement, and validate CoFHEE,
an accelerator for Fully Homomorphic Encryption targeting ciphertext multiplications.
CoFHEE is a 12mm2 design fabricated in 55nm technology node and it supports polynomial
degrees of up to n ≤ 214, while optimized for n = 213, being capable of performing ciphertext
multiplications entirely on chip. Our fabricated chip reaches a frequency of 250 Mhz with
our custom-built low-power digital PLL design. CoFHEE’s design is highly scalable and
can be easily expanded to support higher polynomial degrees, more polynomials on chip,
and more processing units given a larger design area. This paper presents all required
steps for a fully functional silicon, from the RTL design to fabrication and validation.

Mohammed Nabeel et al.

21

Resources

CoFHEE’s RTL ﬁles will be made available at github.com/cofhee. A copy of the
fabricated chip can be shipped to interested researchers (20 chips available).

References

[AARK18] S. Asif, O. Andersson, J. Rodrigues, and Y. Kong. 65-nm cmos low-energy rns
modular multiplier for elliptic-curve cryptography. IET Computers Digital
Techniques, 12(2):62–67, 2018.

[ACC+18] Martin Albrecht, Melissa Chase, Hao Chen, Jintai Ding, Shaﬁ Goldwasser,
Sergey Gorbunov, Shai Halevi, Jeﬀrey Hoﬀstein, Kim Laine, Kristin Lauter,
Satya Lokam, Daniele Micciancio, Dustin Moody, Travis Morrison, Amit Sahai,
and Vinod Vaikuntanathan. Homomorphic encryption security standard.
Technical report, HomomorphicEncryption.org, Toronto, Canada, November
2018.

[ACTD+19] David W. Archer, José Manuel Calderón Trilla, Jason Dagit, Alex Mal-
ozemoﬀ, Yuriy Polyakov, Kurt Rohloﬀ, and Gerard Ryan. Ramparts: A
programmer-friendly system for building homomorphic encryption applica-
tions. In Proceedings of the 7th ACM Workshop on Encrypted Computing &
Applied Homomorphic Cryptography, WAHC’19, page 57–68, New York, NY,
USA, 2019. Association for Computing Machinery.

[AK16]

[Ale75]

[ARM01]

Shahzad Asif and Yinan Kong. Highly parallel modular multiplier for elliptic
curve cryptography in residue number system. Circuits, Systems, and Signal
Processing, 36, 05 2016.

J. D. Alexander. Clock recovery from random binary signals. Electronics
Letters, 11:541–542, 1975.

ARM.
2001.
IHI0033A_AMBA_AHB-Lite_SPEC.pdf.

AMBA 3 AHB-Lite Protocol Speciﬁcation.

page 72,
https://www.eecs.umich.edu/courses/eecs373/readings/ARM_

[BCCW19] Fabian Boemer, Anamaria Costache, Rosario Cammarota, and Casimir
Wierzynski. Ngraph-he2: A high-throughput framework for neural network
inference on encrypted data. In Proceedings of the 7th ACM Workshop on En-
crypted Computing & Applied Homomorphic Cryptography, WAHC’19, page
45–56, New York, NY, USA, 2019. Association for Computing Machinery.

[BDH21]

[BGV93]

[BGV14]

[BNR18]

Jonathan Bradbury, Nir Drucker, and Marius Hillenbrand. Ntt software
optimization using an extended harvey butterﬂy. Cryptology ePrint Archive,
2021.

Antoon Bosselaers, René Govaerts, and Joos Vandewalle. Comparison of three
modular reduction functions. In Annual International Cryptology Conference,
pages 175–186. Springer, 1993.

Zvika Brakerski, Craig Gentry, and Vinod Vaikuntanathan. (leveled) fully
homomorphic encryption without bootstrapping. ACM Transactions on
Computation Theory (TOCT), 6(3):1–36, 2014.

Richard Boateng Nti and Kwangki Ryoo. Asic design of low area rsa crypto-
core based on montgomery multiplier. International Journal of Engineering
and Technology, 7:278–283, 08 2018.

22

CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution

[BYZ13]

[CA16]

[CDS15]

[CGGI16]

Chimere Barron, Huiming Yu, and Justin Zhan. Cloud computing security
case studies and research. In World Congress on Engineering, pages 1287–1291,
2013.

Alessandro Cilardo and Domenico Argenziano. Securing the cloud with
reconﬁgurable computing: An fpga accelerator for homomorphic encryption.
In 2016 Design, Automation & Test in Europe Conference & Exhibition
(DATE), pages 1622–1627. IEEE, 2016.

Sergiu Carpov, Paul Dubrulle, and Renaud Sirdey. Armadillo: A compilation
chain for privacy preserving applications. In Proceedings of the 3rd Interna-
tional Workshop on Security in Cloud Computing, SCC ’15, page 13–19, New
York, NY, USA, 2015. Association for Computing Machinery.

Ilaria Chillotti, Nicolas Gama, Mariya Georgieva, and Malika Izabachène.
Faster fully homomorphic encryption: Bootstrapping in less than 0.1 seconds.
In Jung Hee Cheon and Tsuyoshi Takagi, editors, Advances in Cryptology
– ASIACRYPT 2016, pages 3–33, Berlin, Heidelberg, 2016. Springer Berlin
Heidelberg.

[CGM21]

Eduardo Chielle, Homer Gamil, and Michail Maniatakos. Real-time private
membership test using homomorphic encryption. In 2021 Design, Automation
Test in Europe Conference Exhibition (DATE), pages 1282–1287, 2021.

[CKKS17]

Jung Hee Cheon, Andrey Kim, Miran Kim, and Yongsoo Song. Homomorphic
encryption for arithmetic of approximate numbers. In ASIACRYPT, pages
409–437. Springer, 2017.

[CLR17]

Hao Chen, Kim Laine, and Peter Rindal. Fast private set intersection from
homomorphic encryption. In Proceedings of the 2017 ACM SIGSAC Confer-
ence on Computer and Communications Security, CCS ’17, page 1243–1255,
New York, NY, USA, 2017. Association for Computing Machinery.

[CMTM18] Eduardo Chielle, Oleg Mazonka, Nektarios Georgios Tsoutsos, and Michail
Maniatakos. E3: A framework for compiling c++ programs with encrypted
operands. Cryptology ePrint Archive, Report 2018/1013, 2018. Online: https:
//eprint.iacr.org/2018/1013, GitHub repository: https://github.com/
momalab/e3.

[CPS18]

Eric Crockett, Chris Peikert, and Chad Sharp. Alchemy: A language and
compiler for homomorphic encryption made easy. In Proceedings of the 2018
ACM SIGSAC Conference on Computer and Communications Security, CCS
’18, page 1020–1037, New York, NY, USA, 2018. Association for Computing
Machinery.

[CRPS12] David Bruce Cousins, Kurt Rohloﬀ, Chris Peikert, and Rick Schantz. An
update on sipher (scalable implementation of primitives for homomorphic
encryption)—fpga implementation using simulink. In 2012 IEEE Conference
on High Performance Extreme Computing, pages 1–5. IEEE, 2012.

[CRS16]

[CT65]

David Bruce Cousins, Kurt Rohloﬀ, and Daniel Sumorok. Designing an
fpga-accelerated homomorphic encryption co-processor. IEEE Transactions
on Emerging Topics in Computing, 5(2):193–206, 2016.

James W. Cooley and John W. Tukey. An algorithm for the machine calcula-
tion of complex fourier series. Mathematics of Computation, 19(90):297–301,
1965.

Mohammed Nabeel et al.

23

[DDS14] Wei Dai, Yarkın Doröz, and Berk Sunar. Accelerating ntru based homomorphic
encryption using gpus. In 2014 IEEE High Performance Extreme Computing
Conference (HPEC), pages 1–6. IEEE, 2014.

[DGBL+16] Nathan Dowlin, Ran Gilad-Bachrach, Kim Laine, Kristin Lauter, Michael
Naehrig, and John Wernsing. Cryptonets: Applying neural networks to
encrypted data with high throughput and accuracy. Technical Report MSR-
TR-2016-3, February 2016.

[DL17]

[DÖS14]

Jinnan Ding and Shuguo Li. A modular multiplier implemented with truncated
multiplication. IEEE Transactions on Circuits and Systems II: Express Briefs,
65(11):1713–1717, 2017.

Yarkın Doröz, Erdinç Öztürk, and Berk Sunar. Accelerating fully homomor-
phic encryption in hardware. IEEE Transactions on Computers, 64(6):1509–
1521, 2014.

[FSK+21] Axel Feldmann, Nikola Samardzic, Aleksandar Krastev, Srini Devadas, Ron
Dreslinski, Karim Eldefrawy, Nicholas Genise, Chris Peikert, and Daniel
Sanchez. F1: A fast and programmable accelerator for fully homomorphic
encryption (extended version). arXiv preprint arXiv:2109.05371, 2021.

[FV12]

Junfeng Fan and Frederik Vercauteren. Somewhat practical fully homomorphic
encryption. IACR Cryptology ePrint Archive, 2012:144, 2012.

[GCB+22] Gamze Gürsoy, Eduardo Chielle, Charlotte M. Brannon, Michail Maniatakos,
and Mark Gerstein. Privacy-preserving genotype imputation with fully ho-
momorphic encryption. Cell Systems, 13(2):173–182.e3, 2022.

[Gen09]

[GH11]

[GS66]

[HS20]

Craig Gentry. A fully homomorphic encryption scheme, volume 20. Stanford
university Stanford, 2009.

Craig Gentry and Shai Halevi. Implementing gentry’s fully-homomorphic
encryption scheme. In Annual international conference on the theory and
applications of cryptographic techniques, pages 129–148. Springer, 2011.

W. M. Gentleman and G. Sande. Fast fourier transforms: For fun and proﬁt.
In Proceedings of the November 7-10, 1966, Fall Joint Computer Conference,
AFIPS ’66 (Fall), page 563–578, New York, NY, USA, 1966. Association for
Computing Machinery.

Hsuan-Jui Hsu and Ming-Der Shieh. Vlsi architecture of polynomial multipli-
cation for bgv fully homomorphic encryption. In 2020 IEEE International
Symposium on Circuits and Systems (ISCAS), pages 1–4. IEEE, 2020.

[JLK+20] Wonkyung Jung, Eojin Lee, Sangpyo Kim, Keewoo Lee, Namhoon Kim,
Chohong Min, Jung Hee Cheon, and Jung Ho Ahn. Heaan demystiﬁed: Accel-
erating fully homomorphic encryption through architecture-centric analysis
and optimization. arXiv preprint arXiv:2003.04510, 2020.

[KL15]

[KVV10]

Miran Kim and Kristin Lauter. Private genome analysis through homomorphic
encryption. BMC medical informatics and decision making, 15, December
2015.

M. Knezevic, F. Vercauteren, and I. Verbauwhede. Faster interleaved modular
multiplication based on barrett and montgomery reduction methods. IEEE
Transactions on Computers, 59(12):1715–1721, 2010.

24

CoFHEE: A Co-processor for Fully Homomorphic Encryption Execution

[KWL16]

[LKR04]

S. Kuang, K. Wu, and R. Lu. Low-cost high-performance vlsi architecture
for montgomery modular multiplication. IEEE Transactions on Very Large
Scale Integration (VLSI) Systems, 24(2):434–443, 2016.

Jri Lee, Kenneth S. Kundert, and Behzad Razavi. Analysis and modeling
of bang-bang clock and data recovery circuits. IEEE Journal of Solid-State
Circuits, 39:1571–1580, 2004.

[LPR13]

Vadim Lyubashevsky, Chris Peikert, and Oded Regev. On ideal lattices and
learning with errors over rings. J. ACM, 60(6), nov 2013.

[MÖS19]

Ahmet Can Mert, Erdinç Öztürk, and Erkay Savaş. Design and implementa-
tion of encryption/decryption architectures for bfv homomorphic encryption
scheme. IEEE Transactions on Very Large Scale Integration (VLSI) Systems,
28(2):353–362, 2019.

[Mur16]

Boris Murmann. The successive approximation register adc: a versatile
building block for ultra-low- power to ultra-high-speed applications. IEEE
Communications Magazine, 54(4):78–83, 2016.

[MVOV18] Alfred J Menezes, Paul C Van Oorschot, and Scott A Vanstone. Handbook of

applied cryptography. CRC press, 2018.

[PRRC20] Yuriy Polyakov, Kurt Rohloﬀ, Gerard W. Ryan, and Dave Cousins. PAL-
ISADE lattice cryptography library user manual (v.1.10.6), 2020. https:
//palisade-crypto.org/documentation.

[RCK+21] Brandon Reagen, Woo-Seok Choi, Yeongil Ko, Vincent T Lee, Hsien-Hsin S
Lee, Gu-Yeon Wei, and David Brooks. Cheetah: Optimizing and accelerating
homomorphic encryption for private inference. In 2021 IEEE International
Symposium on High-Performance Computer Architecture (HPCA), pages
26–39. IEEE, 2021.

[RF96]

Annamaria Rossi and Giona Fucili. Nonredundant successive approximation
register for a/d converters. Electronics Letters, 32:1055–1057, 1996.

[RLPD20a] M. Sadegh Riazi, Kim Laine, Blake Pelton, and Wei Dai. Heax: An architec-
ture for computing on encrypted data. In Proceedings of the Twenty-Fifth
International Conference on Architectural Support for Programming Lan-
guages and Operating Systems, ASPLOS ’20, page 1295–1309, New York, NY,
USA, 2020. Association for Computing Machinery.

[RLPD20b] M. Sadegh Riazi, Kim Laine, Blake Pelton, and Wei Dai. HEAX: An Archi-
tecture for Computing on Encrypted Data. arXiv:1909.09731 [cs], January
2020. arXiv: 1909.09731.

[Rus78]

H. Russell. An improved successive-approximation register design for use in
a/d converters. IEEE Transactions on Circuits and Systems, 25(7):550–554,
1978.

[SEA21]

Microsoft SEAL (release 3.7).
September 2021. Microsoft Research, Redmond, WA.

https://github.com/Microsoft/SEAL,

[SKF+11] Kazuo Sakiyama, Miroslav Knežević, Junfeng Fan, Bart Preneel, and Ingrid
Verbauwhede. Tripartite modular multiplication. Integration, 44:259–269, 09
2011.

Mohammed Nabeel et al.

25

[TAA+19] Weihang Tan, Aengran Au, Benjamin Aase, Shuhong Aao, and Yingjie Lao.
An eﬃcient polynomial multiplier architecture for the bootstrapping algorithm
In 2019 IEEE International
in a fully homomorphic encryption scheme.
workshop on signal processing systems (SiPS), pages 85–90. IEEE, 2019.

[TCH+21] Weihang Tan, Benjamin M Case, Gengran Hu, Shuhong Gao, and Yingjie
Lao. An ultra-highly parallel polynomial multiplier for the bootstrapping
algorithm in a fully homomorphic encryption scheme. Journal of Signal
Processing Systems, 93(6):643–656, 2021.

[WLYS12]

S. Wang, W. Lin, J. Ye, and M. Shieh. Fast scalable radix-4 montgomery
modular multiplier. In 2012 IEEE International Symposium on Circuits and
Systems (ISCAS), pages 3049–3052, 2012.

