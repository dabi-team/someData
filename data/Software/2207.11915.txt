Parallelism Resource of Numerical Algorithms.
Version 1

Valentina N. Aleeva, Rifkhat Zh. Aleev

July 26, 2022

2
2
0
2

l
u
J

5
2

]

C
C
.
s
c
[

1
v
5
1
9
1
1
.
7
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
Abstract

The paper is devoted to an approach to solving a problem of the efficiency
of parallel computing. The theoretical basis of this approach is the concept
of a Q-determinant. Any numerical algorithm has a Q-determinant. The Q-
determinant of the algorithm has clear structure and is convenient for imple-
mentation. The Q-determinant consists of Q-terms. Their number is equal to
the number of output data items. Each Q-term describes all possible ways to
compute one of the output data items based on the input data.

We also describe a software Q-system for studying the parallelism resource
of numerical algorithms. This system enables to compute and compare the
parallelism resources of numerical algorithms. The application of the Q-system
is shown on the example of numerical algorithms with different structures of
Q-determinants. Furthermore, we suggest a method for designing of parallel
programs for numerical algorithms. This method is based on a representation
of a numerical algorithm in the form of a Q-determinant. As a result, we can
obtain the program using the parallelism resource of the algorithm completely.
Such programs are called Q-effective.

The results of this research can be applied to increase the implementation
efficiency of numerical algorithms, methods, as well as algorithmic problems on
parallel computing systems.

CCS Concepts: • Theory of computation → Models of computation;
Concurrency; Parallel computing models; Design and analysis of al-
gorithms; Parallel algorithms; • Software and its engineering → Soft-
ware creation and management; Software development techniques;
Flowcharts; • Computing methodologies → Parallel computing method-
ologies; Parallel algorithms; Symbolic and algebraic manipulation; Symbolic
and algebraic algorithms; Linear algebra algorithms;

Additional Key Words and Phrases: Q-term of algorithm, Q-determinant of
algorithm, representation of algorithm in form of Q-determinant, Q-effective im-
plementation of algorithm, parallelism resource of algorithm, software Q-system,
Q-effective program, Q-effective programming

1

Introduction

There is a considerable difference in the computational power of parallel com-
puting systems and its use. The existence of this fact is of great importance for
parallel computing. One of the reasons for the above difference is an inadequate
implementation of algorithms on parallel computing systems. In particular, it
can be if the parallelism resource of the algorithm is used incompletely. So, the
computing resources of a parallel computing system can not be used enough
when implementing the algorithm.

We will give a brief overview of some researches of the parallelism resource

of numerical algorithms and its implementation.

First, we note [30, 29] where there is a very important and developed re-
search of the parallel structure of algorithms and programs for their implemen-
tation on parallel computing systems. These papers contain definitions and
studies of the graphs of algorithms. These researches are adapted in the open
encyclopedia AlgoWiki [7, 8]. However, the papers using these studies do not
consider any software for studying the parallelism resource of algorithms.

Second, we note there are proposed several approaches to the development
of parallel programs. This led to the creation of various parallel programming
languages and other tools. The T-system [20] is one of these developments.
It provides a programming environment with support for automatic dynamic
parallelization of programs. However, it cannot be asserted that the creation
of parallel programs using the T-system makes full use of the parallelism re-
source of the algorithm. The parallel program synthesis is another approach
to creating parallel programs. This approach is to construct new parallel algo-
rithms using the knowledge base of parallel algorithms to solve more complex
problems. The technology of fragmented programming, its implementation lan-
guage, and the programming system LuNA are developed on the basis of the
parallel programming synthesis method [1]. This approach does not solve the
problem of research and use of the parallelism resource of algorithm, despite
the fact that it is universal. To overcome resource limitations, the author of the
paper [15] suggests methods for constructing parallel programs using a func-
tional programming language independent of computer architecture. However,
there isn't shown that the created programs use the entire parallelism resource
of algorithms.

Third. There are many studies on the development of parallel programs
that take into account the specifics of algorithms and architecture of parallel

1

computing systems. Examples of such studies are [31, 17, 25, 22, 32, 18, 24].
These studies improve the efficiency of implementing specific algorithms or im-
plementing algorithms on parallel computing systems of a particular architec-
ture. However, they don't provide a general universal approach.

Fourth. Perhaps the above review is not complete. However, we have
previously noted that the parallelism resource of algorithms by realization on
parallel computing systems is often not used completely. So, it appears that
there is currently no solution to the problem for the research and use of the
parallelism resource of algorithms. Therefore, the results of this paper can be
considered as one of the solutions to this problem.

The concept of a Q-determinant is the theoretical basis of the research of this
paper. We describe the development of a software system called the Q-system to
research the parallelism resource of numerical algorithms. We will also describe
how to develop a program that uses the parallelism resource of the numerical
algorithm completely. In addition, we suggest a programming technology called
Q-effective programming to improve the efficiency of parallel computing based
on the results obtained. This paper continues and summarizes the results of
studies presented in [4, 6, 2, 5, 3].

2 The concept of a Q-determinant

We describe a mathematical model of the concept of a Q-determinant.

2.1 Expressions

Let B = \{ b1, b2, . . . \}  be a finite or countable set of variables, and Q be a finite
set of operations. Suppose that all operations of Q are 0ary (constants), unary,
or binary. For example,

Q = \{ +,  - , \cdot , / (arithmetical operations),

\vee , \wedge , \neg  (logical operations),

=, <, \leq , >, \geq , \not = (comparison operations)\} .

Every expression w has the nesting level T w.

Definition 1. By induction, we define the expression, its nesting level and its
subexpressions. We also relate the nesting level and operations.

1. The constants and elements of the set B are expressions and have zero

nesting level.

2. If w is an expression, then (w) is an expression and T w = T (w) also.

3. Let w be an expression, T w = i  -  1 (i \geq  1) and f \in  Q is an unary
operation. Then f (w) is an expression and T f (w) = i. We call w the
subexpression of the (i  -  1)th nesting level of the expression f (w) and f
the operation of the ith nesting level.

4. Let w and v be an expressions, T w = i, T v = j and g \in  Q be a binary
operation. Then g(w, v) is an expression and T g(w,v) = k, where k =
max\{ i, j\} +1. We call w and v the subexpressions of the expression g(w, v)

2

with nesting levels i and j, respectively, and g the operation of the kth
nesting level.

Example 1. We point out some expressions and their nesting levels.

1. w1 = b1 \cdot  (b2 + b3)/b4 and T w1 = 3;

2. w2 = ((b1 + b2) \leq  (b3 \cdot  b4)) \vee  \neg (b5 \leq  b6) and T w2 = 3;

3. w3 = ((b1 \geq  b3) \wedge  ((b2  -  b4) \not = 0)) \wedge  (b5 = 0) and T w3 = 4.

Definition 2. We call an expression a chain of length n if it is the result of
some associative operation from Q on expressions whose number is n. As usual,
we can write a chain without parentheses.

Example 2. Examples of chains are the following:

1. b1 + b2 + b3 + b4 is a chain of length 4;

2. (b1 + b2) \cdot  (b4  -  b7) \cdot  (b2 + b4) is a chain of length 3;

3. (b1 \leq  b2) \vee  (b3 \geq  b5) \vee  \neg (b2 \leq  b4) is a chain of length 3.
We interpret the expressions into the real number field \BbbR .

Definition 3. Let bi \in  B. Then the assignment of the variable bi of a specific
value from \BbbR  is called the interpretation of the variable bi.

Definition 4. We say that the interpretation of the expression is specified if
the interpretation of all variables in the expression is specified.

If the interpretation of the expression is specified, then we can find the value

of the expression.

Example 3. As an example, to find the values of the expressions, consider the
expressions from Example 1. First, we interpret the variables

bi = i for every i \in  \{ 1, 2, . . . , 6\} .

1. We have

w1 = b1 \cdot  (b2 + b3)/b4 = 1 \cdot  (2 + 3)/4 = 5/4.

So, the value of w1, under this interpretation, is 5/4.

2. We get

w2 = ((b1 + b2) \leq  (b3 \cdot  b4)) \vee  \neg (b5 \leq  b6) =
= ((1 + 2) \leq  (3 \cdot  4)) \vee  \neg (4 \leq  6) =

= (3 \leq  12) \vee  \neg (4 \leq  6).

The value of w2 is true.

3. Finally,

w3 = ((b1 \geq  b3) \wedge  ((b2  -  b4) \not = 0)) \wedge  (b5 = 0) =
= ((1 \geq  3) \wedge  ((2  -  4) \not = 0)) \wedge  (5 = 0) =

= ((1 \geq  3) \wedge  ( - 2 \not = 0)) \wedge  (5 = 0).

Therefore, the value of w3 is false.

3

2.2 Q-terms and their values

Often some additional data have an influence on expressions. We call this
data parameters. More exactly, let's define the notion of parameters. In the
standard sense of mathematical logic [10, Section 16], a set of parameters is a
set of free variables of expression, cf. [11, Section 1.2]. So, we clarify our idea
of parameters.

Definition 5. We keep the following agreements.

1. Let N be a set of parameters. Then N = \emptyset  or N = \{ n1, . . . , nk\} , where
k \geq  1, and ni is equal to any positive integer for every i \in  \{ 1, . . . , k\} .

2. If N = \{ n1, . . . , nk\} , then as

\=N = (\=n1, . . . , \=nk),

we denote the k-tuple, where \=ni is some given value of the parameter ni
for every i \in  \{ 1, . . . , k\} .

3. By \bigl\{  \=N \bigr\}  we denote the set of all possible k-tuples \=N .

Now we introduce the concept of an unconditional Q-term.

Definition 6. If N = \emptyset , then we say that every expression w over B and Q is
an unconditional Q-term.

Let N \not = \emptyset  and V be a set of all expressions over B and Q. Suppose that
we have a map w : \bigl\{  \=N \bigr\}  \rightarrow  V \cup  \emptyset . Then this map w is called an unconditional
Q-term.

Thus, for N = \emptyset  the concept of an unconditional Q-term and an expression
If N \not = \emptyset , then for every \=N \in  \bigl\{  \=N \bigr\}  we have w( \=N )
over B and Q coincide.
is either some expression over B and Q, or w( \=N ) = \emptyset , meaning that w( \=N ) is
undefined.
Example 4. Examples of unconditional Q-terms are

1. b1 + b2 \cdot  b3  -  b4, here N = \emptyset ;

2. | b1 + b2 + \cdot  \cdot  \cdot  + bn| , here N = \{ n\} ;

3. (b1 = 0) \wedge  (b3 = 0) \wedge  \cdot  \cdot  \cdot  \wedge  (b1+2\cdot n1 = 0) \wedge  ((b2 \cdot  b4 \cdot  \cdot  \cdot  \cdot  \cdot  b2+2\cdot n2 ) > 0), and

here N = \{ n1, n2\} .

Definition 7. If N = \emptyset , then finding the value of an expression w is finding the
value of an unconditional Q-term w under any interpretation of the variables of
B.

If N \not = \emptyset  and w( \=N ) \not = \emptyset , then w( \=N ) is an expression over B and Q. We
can find the value of the expression w( \=N ). Certainly, we omit the value of
w( \=N ) = \emptyset . Hence, we have finding the value of an unconditional Q-term w
under any interpretation of the variables of B.

Definition 8. If N = \emptyset , then the nesting level of the expression w is the nesting
level T w of the unconditional Q-term w.

If N \not = \emptyset , then the nesting level of the unconditional Q-term w is the partial
function T w : \bigl\{  \=N \bigr\}  \rightarrow  T w( \=N ), where T w( \=N ) is the nesting level of the expression
w( \=N ) for w( \=N ) \not = \emptyset . Also, we don't define the nesting level of the unconditional
Q-term w, if w( \=N ) = \emptyset .

4

Definition 9. Let N = \emptyset  and w be an unconditional Q-term. Suppose that the
expression w over B and Q has a value of a logical type under any interpretation
of the variables of B.

Then the unconditional Q-term w is called the unconditional logical Q-term.
Let N \not = \emptyset  and w be an unconditional Q-term. If the expression w( \=N ) for
every \=N \in  \{  \=N \}  has a value of a logical type under any interpretation of the
variables of B, then the unconditional Q-term w is called the unconditional
logical Q-term.

Definition 10. Let u1, . . . , ul be unconditional logical Q-terms, w1, . . . , wl are
unconditional Q-terms. We denote

(\widehat u, \widehat w) = \{ (ui, wi)\} i\in \{ 1,...,l\} 

and call a conditional Q-term of length l.

We describe finding the value of a conditional Q-term (\widehat u, \widehat w) under the in-

terpretation of the variables of B.

Definition 11. Let N = \emptyset . We find the values of the expressions ui, wi for
i \in  \{ 1, . . . , l\} . Under this finding of the values we can find a pair ui0 , wi0 such
that ui0 has the value true. Therefore, we can find the value of wi0. Then we
suppose that (\widehat u, \widehat w) has the value wi0. Otherwise, we suppose that the value of
(\widehat u, \widehat w) under the interpretation of the variables of B is not determined.
Let N \not = \emptyset  and \=N \in  \bigl\{  \=N \bigr\} . We find the expressions ui( \=N ), wi( \=N ) for i \in 
\{ 1, . . . , l\} . Under this finding of the values we can find a pair ui0 ( \=N ), wi0 ( \=N )
such that ui0( \=N ) has the value true. Therefore, we can find the value of wi0( \=N ).
Then we suppose that (\widehat u, \widehat w) has the value wi0 ( \=N ). Otherwise, we suppose that
the value of (\widehat u, \widehat w) for \=N and under this interpretation of the variables of B is
not determined.

Definition 12. Let (\widehat u, \widehat w) = \{ (ui, wi)\} i\in \{ 1,2,... \}  be a countable set of pairs of
unconditional Q-terms. Assume that \{ (ui, wi)\} i\in \{ 1,...,l\}  is a conditional Q-term
for any l < \infty . Then we call (\widehat u, \widehat w) a conditional infinite Q-term.

Finally, we determine the value of a conditional infinite Q-term (\widehat u, \widehat w) under

the interpretation of the variables of B.

Definition 13. Let N = \emptyset . First of all, we find the values of the expressions
ui, wi for i \in  \{ 1, 2, . . . \} . Under this finding of the values we can find a pair
ui0, wi0 such that ui0 has the value true. Therefore, we can find the value of
wi0 . Then we suppose that (\widehat u, \widehat w) has the value wi0. Otherwise, we suppose
that the value of (\widehat u, \widehat w) under the interpretation of the variables of B is not
determined.
Let N \not = \emptyset  and \=N \in  \bigl\{  \=N \bigr\} . First of all, we find the values of the expressions
ui( \=N ), wi( \=N ) for i \in  \{ 1, 2, . . . \} . Under this finding of the values we can find
a pair ui0( \=N ), wi0( \=N ) such that ui0( \=N ) has the value true. Therefore, we can
find the value of wi0( \=N ). Then we suppose that (\widehat u, \widehat w) has the value wi0( \=N ).
Otherwise, we suppose the value of (\widehat u, \widehat w) for \=N and under the interpretation
of the variables of B is not determined.

Remark 1. If it does not matter whether a Q-term is unconditional, conditional
or conditional infinite, then we call it a Q-term.

5

2.3 The concept of a Q-determinant of an algorithm

Consider an algorithmic problem

\vec{}y = F (N, B),

(1)

where N is a set of dimension parameters of the problem, B is a set of input data,
\vec{}y = (y1, . . . , ym) is a set of output data, yi /\in  B for every i \in  \{ 1, . . . , m\} , the
integer m is either a constant or the value of a computable parameter function
N under the condition N \not = \emptyset , cf. [11, p. 4] and [12, p. 7--8].

We introduce the concept of a Q-determinant of an algorithm.

Definition 14. Let \scrA  be an numerical algorithm for solving an algorithmic
problem \vec{}y = F (N, B) and M = \{ 1, . . . , m\} .

Suppose that the algorithm \scrA  consists in finding for every i \in  M the value

of yi when the value of a Q-term fi is found. Then the set of Q-terms

\{ fi |  i \in  M \} 

is called the Q-determinant of the algorithm \scrA . Also a system of equations

yi = fi for all i \in  M

(2)

(3)

is called a representation of the algorithm \scrA  in the form of a Q-determinant.

2.4 The concept of the Q-effective implementation of an

algorithm

It is very important how an algorithm is computed.

Definition 15. Let the algorithm \scrA  be represented in the form of a Q-deter-
(3)). The process of computing the Q-
minant yi = fi for all i \in  M (cf.
terms fi for all i \in  M is called an implementation of the algorithm \scrA .
If
an implementation of the algorithm is such that two or more operations are
performed simultaneously, then it will be called a parallel implementation.

We describe a very important implementation of the algorithm \scrA .
For that we need some partition of the set M .

Definition 16. More exactly, suppose that U , C and I form a partition of the
set M = \{ 1, . . . , m\}  with empty terms, that is:

1. U \cup  C \cup  I = M ;

2. U \cap  C = U \cap  I = C \cap  I = \emptyset ;

3. besides, one or two subsets of U , C, and I may be empty.

Definition 17. For the partition above, we can associate U , C and I with the

6

subsets of the set of Q-terms \{ fi\} i\in M such that:

(1) for every i \in  U we have a Q-term fi that is an unconditional, and

fi = wi;

(2) for every i \in  C we have a Q-term fi that is a conditional, and

fi = \bigl\{ \bigl( ui

j, wi
j

\bigr) \bigr\} 

j\in \{ 1,...,l(i)\} 

, where l(i) is either a constant or

(4)

a value of a computable function of N if N \not = \emptyset ;

(3) for every i \in  I we have a Q-term fi that is a conditional infinite, and

fi = \bigl\{ \bigl( ui

j, wi
j

\bigr) \bigr\} 

j\in \{ 1,2,... \} 

.

Remark 2. If the operations form a chain, then they can be performed in arbi-
trary order including a doubling scheme. For example, the doubling scheme for
computing the chain

a1 + a2 + a3 + a4 + a5 + a6 + a7 + a8

is the following. First, we compute

c1 = a1 + a2, c2 = a3 + a4, c3 = a5 + a6, and c4 = a7 + a8

simultaneously. Then

d1 = c1 + c2 and d2 = c3 + c4

simultaneously. After that,

e = d1 + d2.

Definition 18. Now we describe the promised implementation of the algorithm
\scrA  that are called the Q-effective implementation of the algorithm \scrA .

First, N = \emptyset . Let us have an interpretation of the variables of B.

We compute the expressions

W = \bigl\{ wi(i \in  U ); ui

j, wi

j(i \in  C, j \in  \{ 1, . . . , l(i)\} );

j, wi
ui

j(i \in  I, j \in  \{ 1, 2, . . . \} )\bigr\}  (5)

simultaneously, in parallel.

We say that the operation is ready to perform if we have already computed
the values of all its operands. When computing each of the expressions
of W (cf. (5)), we perform the operations as soon as they are ready to
be executed. If several operations of a chain are ready for execution, then
their computations are performed according to the doubling scheme.
If for any i \in  C \cup  I and j \in  \{ 1, 2, . . . \}  we have the expression ui
value false, then the computation of the corresponding expression of wi
terminated.

j with the
j is

If for any i \in  C \cup  I and j \in  \{ 1, 2, . . . \}  the computation of some pair
of expressions (ui
j) has a consequence that the value of one of two
expressions is not defined, then the computation of the other expression
is terminated.

j, wi

7

, wi
j0

) leads to the determination of their values and ui
j0

If for any i \in  C \cup  I the computation of a certain pair of expressions
(ui
is true, then
j0
the computation of expressions ui

j, wi
Computation of identical expressions W and their identical subexpressions
may not be duplicated.

j is terminated for any j \not = j0.

Now, N \not = \emptyset . Let us have an interpretation of the variables of B and specified

\=N \in  \{  \=N \} .
We get the set of expressions

W ( \=N ) = \bigl\{ wi( \=N )(i \in  U ); ui

j( \=N ), wi
j( \=N ), wi
ui
The expressions from W ( \=N ) can be computed by analogy with computa-
tions of the expressions from W (cf. (5)).

j( \=N )(i \in  I, j \in  \{ 1, 2, . . . \} )\bigr\} .

j( \=N )(i \in  C, j \in  \{ 1, . . . , l(i)\} );

(6)

Remark 3. The definition of the Q-effective implementation shows it is the
most parallel implementation of the algorithm. In other words, the Q-effective
implementation uses the parallelism resource of the algorithm completely, cf 2.6.

2.5 The concept of a realizable implementation of an al-

gorithm

It is very important how we can realize an implementation of an algorithm.

Definition 19. Let the algorithm \scrA  be represented in the form of a Q-deter-
minant yi = fi for all i \in  M (cf. (3)). An implementation of the algorithm
\scrA  is called realizable if it is such that a finite number of operations must be
performed simultaneously.

There are algorithms such that the Q-effective implementation is not realiz-

able.

Example 5. Compute the sum of a series

\infty 
\sum 

S =

k=1

( - 1)k 1
k

with a given accuracy \epsilon  < 1.

The Q-determinant of the algorithm for computing S consists of one condi-

tional infinite Q-term (cf. (2)).

Namely, the representation of the algorithm for computing S in the form of

a Q-determinant is written as

S = \bigl\{ \bigl(  1

2 < \epsilon ,  - 1\bigr)  , \bigl(  1

\bigr)  , . . . ,

3 < \epsilon ,  - 1 + 1
2
\Bigl(  1
k < \epsilon ,  - 1 + 1

2  -  \cdot  \cdot  \cdot  + ( - 1)k - 1 1

k - 1

\Bigr) 

, . . . \bigr\} .

As the countable set of division operations is ready to be performed simultane-
ously, then the Q-effective implementation isn't realizable.

To perform the Q-effective implementation, we specify some conditions on

the Q-determinant.

8

Theorem 1. Let the algorithm \scrA  be represented in the form of a Q-determinant
yi = fi for all i \in  M . Then the Q-effective implementation of the algorithm \scrA 
is realizable, if one of the following three conditions is satisfied.

1. We have I = \emptyset .

2. We have I \not = \emptyset , N = \emptyset , and for every r \in  \{ 1, 2, . . . \}  the set of operations
j is finite for all i \in  I, and

of the nesting level r for the expressions ui
j \in  \{ 1, 2, . . . \} .

j, wi

3. We have I \not = \emptyset , N \not = \emptyset , and for every r \in  \{ 1, 2, . . . \}  the set of operations
j( \=N ) is finite for all

of the nesting level r for the expressions ui
i \in  I, j \in  \{ 1, 2, . . . \} , and \=N \in  \{  \=N \} .

j( \=N ), wi

Proof. Consider condition 1. Let I = N = \emptyset . Since I = \emptyset , executing the
Q-effective implementation requires to compute a finite set of expressions

W = \bigl\{ wi(i \in  U ); ui

j, wi

j(i \in  C, j \in  \{ 1, . . . , l(i)\} )\bigr\}  .

So, it is necessary to perform a finite number of operations simultaneously.

Let N \not = \emptyset . In this case, when executing the Q-effective implementation for

any \=N \in  \{  \=N \} , it is necessary to compute a finite set of expressions

W ( \=N ) = \bigl\{ wi( \=N )(i \in  U ); ui

j( \=N ), wi

j( \=N )(i \in  C, j \in  \{ 1, . . . , l(i)\} )\bigr\}  .

Again, it is necessary to perform a finite number of operations simultaneously.
Now we consider condition 2. It follows that for expressions W (cf. (5)) the
set of operations of the nesting level r is finite for all r \in  \{ 1, 2, . . . \} . Therefore,
it is necessary to perform a finite number of operations under the Q-effective
implementation simultaneously.

So, the Q-effective implementation of the algorithm \scrA  is realizable.
Consideration of condition 3 is similar to condition 2.

Remark 4. We examined a considerable number of numerical algorithms and
came to the conclusion that almost all of them have the realizable Q-effective
implementation.

2.6 The concept of the parallelism resource of an algo-

rithm

Requirements. We hold the following conditions and notations.

1. The algorithm \scrA  is represented in the form of a Q-determinant yi = fi

for all i \in  M (cf. (3)).

2. The values of the Q-terms fi for all i \in  M is determined under any

interpretation of the variables of B and any \=N \in  \{  \=N \}  if N \not = \emptyset .

3. The Q-effective implementation of the algorithm \scrA  is realizable.

4. Let N = \emptyset  and I \not = \emptyset . Then under a given interpretation of the variables
such that the

of B for any i \in  I there is a pair of expressions ui
ji
value of ui
ji

is equal to true, and the value of wi
ji

, wi
ji
is defined.

9

Note that ji depends on the interpretation of the variables of B. We
introduce the notation

\widetilde W = \bigl\{ wi(i \in  U ); ui

j, wi

j(i \in  C, j \in  \{ 1, . . . , l(i)\} ); ui
ji

, wi
ji

(i \in  I)\bigr\}  .

5. Let N \not = \emptyset  and I \not = \emptyset . Then under a given interpretation of the variables
( \=N ),
of B, for any \=N \in  \{  \=N \} , and i \in  I there is a pair of expressions ui
ji
( \=N ) is equal to true, and the value of
wi
ji
wi
ji
Note that ji depends on \=N and the interpretation of the variables of B.
We introduce the notation

( \=N ) such that the value of ui
ji
( \=N ) is defined.

\widetilde W ( \=N ) = \bigl\{ wi( \=N )(i \in  U ); ui

j( \=N ), wi

j( \=N )(i \in  C, j \in  \{ 1, . . . , l(i)\} );

ui
ji

( \=N ), wi
ji

( \=N )(i \in  I)\bigr\} .

Definition 20. We define the characteristics of the parallelism resource of the
algorithm \scrA :

D\scrA  is the algorithm height and P\scrA  is the algorithm width.

If N = \emptyset , then

D\scrA  =

\left\{ 

max
w\in W
max
w\in \widetilde W

T w if I = \emptyset ,

T w if I \not = \emptyset ;

(7)

if Ow

r is the number of operations of the nesting level r of the expression w, then

P\scrA  = max

1\leq r\leq D\scrA 

\sum 

w\in W

Ow
r .

If N \not = \emptyset , then

D\scrA ( \=N ) =

\left\{ 

max
w( \=N )\in W ( \=N )
max
w( \=N )\in \widetilde W ( \=N )

T w( \=N ) if I = \emptyset ,

T w( \=N ) if I \not = \emptyset ;

(8)

(9)

if Ow( \=N )
r
w( \=N ), then

is the number of operations of the nesting level r of the expression

P\scrA ( \=N )= max

1\leq r\leq D\scrA ( \=N )

\sum 

Ow( \=N )
r

.

w( \=N )\in W ( \=N )

(10)

In these formulas, W and W ( \=N ) have the same meaning as in formulas (5)

and (6), respectively.

Remark 5. We would like to note some important features of D\scrA  and P\scrA .

1. D\scrA  and P\scrA  depend on N if N \not = \emptyset .

10

 
 
  
  
2. D\scrA  and P\scrA  don't depend on the interpretation of the variables of B if

I = \emptyset .

3. D\scrA  and P\scrA  depend on the interpretation of the variables of B if I \not = \emptyset .

4. The values of D\scrA  and P\scrA  estimate the parallelism resource of the algo-
rithm \scrA . More exactly, D\scrA  characterizes the execution time of the Q-
effective implementation of the algorithm, and P\scrA  characterizes the num-
ber of processors required to execute the Q-effective implementation.

3 The Q-determinants, realizabilities, and the
parallelism resources of some numerical algo-
rithms

In this section, we consider three algorithms: the scalar product, the Gaussian
elimination, and solving a system of grid equations by the Jacobi method. We
would like to point out the reasons for choosing these algorithms.

First. Although the computation of the scalar product of vectors is very simple,
this computation is very common and is an inseparable part of many
algorithms. So, it seems to us that the consideration is very useful and
important.

The Q-determinant consists of one unconditional Q-term.

Second. It is quite clear that the Gaussian elimination in various forms is one
of the bases of numerical mathematics, but even of all mathematics.

In this case, the Q-determinant consists of n conditional Q-terms of length
n!, where n is an integer.

Third. The solving a system of grid equations by the Jacobi method is a well-
known iterative method. We need to consider the Jacobi method, because
the number of iterations is a very important characteristic of many nu-
merical algorithms.

Now the Q-determinant consists of a finite number of conditional infinite
Q-terms.

Thus, in our opinion, we will consider very important methods with different
structures of Q-determinants.

3.1 The scalar product of vectors

3.1.1 The Q-determinant of the scalar product

Consider the algorithm \scrS  for computing the scalar product of vectors.

\vec{}a1 = (a1

1, . . . , a1

n) and \vec{}a2 = (a2

1, . . . , a2
n)

(\vec{}a1, \vec{}a2) =

n
\sum 

i=1

a1
i a2
i .

11

(11)

Q-determinant. In this case N = \{ n\} , B = \{ a1
|  i \in  \{ 1, . . . n\} \} , and
\vec{}y = \{ (\vec{}a1, \vec{}a2)\} . Now we note that the equation (11) is the representation of the
algorithm \scrS  in the form of a Q-determinant. So, the Q-determinant consists of
one unconditional Q-term.

i , a2
i

3.1.2 Realizability and the parallelism resource of the scalar product

Let log x be the binary logarithm of the number x, and \lceil x\rceil  be the ceiling of x,
i.e., the least integer greater than or equal to the number x.

Proposition 1. The Q-effective implementation of the algorithm \scrS  is realizable.

For the algorithm \scrS  we have

D\scrS  = \lceil log n\rceil  + 1 and P\scrS  = n.

Proof. Indeed, since I = \emptyset , then the Q-effective implementation of the algorithm
\scrS  is realizable by Theorem 1.

In this case, we must use the doubling scheme. Therefore, the definitions of

height and width for the algorithm \scrS  are completely obvious.

3.2 The Gauss--Jordan method for solving a system of lin-

ear equations

It is well known the Gauss--Jordan method (the Gaussian elimination) is uni-
versal.

For simplicity, suppose that a n \times  n matrix A is invertible (has a nonzero

determinant).

Let \vec{}x = (x1, . . . , xn)T , \vec{}b = (a1,n+1, . . . , an,n+1)T be column vectors, and

\=A = [aij] be an augmented matrix of the system. Therefore,

In this case

A\vec{}x = \vec{}b.

N = \{ n\} , B = \{ aij |  i \in  \{ 1, . . . n\} , j \in  \{ 1, . . . n + 1\} \} , and
\vec{}y = \{ xi |  i \in  \{ 1, . . . n\} \} .

3.2.1 The Q-determinant of the Gauss--Jordan method

There are many variants of algorithms for implementation of the Gauss--Jordan
method.

Consider one of them that denote by \scrG . This algorithm has n steps.

Step 1. We must select the leading element. If a11 \not = 0, then a11 is the leading
element and j1 = 1. Otherwise, if a1j = 0 for j < j1 \leq  n and a1j1 \not = 0,
then a1j1 is the leading element. So, the first non-zero element in the first
row of the matrix A is the leading element.
Then we get the updated augmented matrix \=Aj1 = [aj1

ij ] by the rule

aj1
1j =

a1j
a1j1

,

aj1
ij = aij  - 

a1j
a1j1

aij1

12

for every i \in  \{ 2, . . . , n\}  and j \in  \{ 1, . . . , n + 1\} .

The nesting level of the right-hand sides of the equations is at most 3.

More exactly, for every n \in  \{ 2, 3, . . . \}  and j \in  \{ 1, . . . , n+1\}  the expression

a1j
a1j1

has the nesting level 1, and for every i \in  \{ 2, . . . , n\}  the expression

aij  - 

a1j
a1j1

aij1

has the nesting level 3.

Step k \in  \{ 2, . . . , n\} . After step k  -  1 we get an augmented matrix \=Aj1...jk - 1 .

\not = 0, then aj1...jk - 1

We must select the leading element.
If aj1...jk - 1
is the leading element and jk = 1. Other-
k1
wise, if aj1...jk - 1
is the
leading element. So, the first nonzero element in kth row of the matrix
\=Aj1...jk - 1 is the leading element.
Now we obtain the next augmented matrix

= 0 for j < jk \leq  n and aj1...jk - 1

\not = 0, then aj1...jk - 1

kjk

kjk

k1

kj

by rule

\=Aj1...jk =

\Bigl[ 
aj1...jk
ij

\Bigr] 
i\in \{ 1,...,n\} ,
j\in \{ 1,...,n+1\} 

aj1...jk
kj

=

aj1...jk - 1
kj
aj1...jk - 1
kjk

,

aj1...jk
ij

= aj1...jk - 1
ij

 - 

aj1...jk - 1
kj
aj1...jk - 1
kjk

aj1...jk - 1
ijk

for every i \in  \{ 1, . . . , n\} , i \not = k, and j \in  \{ 1, . . . , n + 1\} .

By induction, the nesting level of the right-hand sides of the equations is
at most 3k.

More exactly, for every n \in  \{ 2, 3, . . . \}  and j \in  \{ 1, . . . , n+1\}  the expression

aj1...jk - 1
kj
aj1...jk - 1
kjk

has the nesting level 3(k  -  1) + 1 = 3k  -  2, and for every i \in  \{ 1, . . . , n\} ,
i \not = k the expression

aj1...jk - 1
ij

 - 

aj1...jk - 1
kj
aj1...jk - 1
kjk

aj1...jk - 1
ijk

has the nesting level 3k.

13

As a result, we get a system of equations Aj1...jn\vec{}x = \vec{}bj1...jn after step n,

where

Aj1...jn =

\Bigl[ 

aj1...jn
ij

\Bigr] 

i\in \{ 1,...,n\} ,
j\in \{ 1,...,n+1\} 

,

\vec{}bj1...jn = (aj1...jn

1,n+1 , . . . , aj1...jn

n,n+1)T .

Moreover, for every i \in  \{ 1, . . . , n\} 

aj1...jn
iji

= 1

and for every i \in  \{ 1, . . . , n\} , j \in  \{ 1, . . . , n\} , and j \not = ji

Hence, for every i \in  \{ 1, . . . , n\} 

aj1...jn
ij

= 0.

xji = aj1...jn
i,n+1

that is the solution of our system.

We also note that for every n \in  \{ 2, 3, . . . \} 

T w =

\Biggl\{ 

3n
3n  -  2

for w = aj1...jn
i,n+1 , if i \in  \{ 1, . . . , n  -  1\} ;
for w = aj1...jn
n,n+1.

(12)

The n-tuple (j1, . . . , jn) determines the choice of leading elements. This is
the permutation of elements of the set \{ 1, . . . , n\} . The number of such permu-
tations is n!. We number these permutations by positive integers from 1 to n!.
So, each permutation has own serial number.

Denote by

\left\{ 

Lj1 =

true
j1 - 1
\bigwedge 

(a1j = 0)

if j1 = 1,

if j1 \not = 1

j=1

and for every l \in  \{ 2, . . . , n\} 

\left\{ 

Ljl =

true
jl - 1
\bigwedge 

(aj1...jl - 1

lj

if jl = 1,

= 0)

if jl \not = 1.

j=1

We have the parameter set N = \{ n\}  and M = \{ 1, . . . , n\}  as in (1) and (2).

Further, let p be a serial number of permutation (j1, . . . , jn). Then

wjl

p = aj1...jn

l,n+1

for every l \in  \{ 1, . . . , n\}  and

up = Lj1 \wedge  (a1j1 \not = 0) \wedge 

\Biggl(  n
\bigwedge 

\Bigl( 

l=2

Ljl \wedge 

\Bigl( 

aj1...jl - 1
ljl

\Bigr) \Bigr) 

\not = 0

\Biggr) 

are unconditional Q-terms.

14

(13)

(14)

   
   
   
   
Q-determinant. Finally, we have the set

\Bigl\{ 

xj =

(u1, wj

1), . . . , (un!, wj

n!)

\Bigr\} 

j\in \{ 1,...,n\} 

(15)

is the representation of the algorithm \scrG  in the form of a Q-determinant.

Hence, the Q-determinant consists of n conditional Q-terms of length n!.

3.2.2 Realizability and the parallelism resource of the Gauss--Jordan

method

Lemma 1. The Q-effective implementation of the algorithm \scrG  is realizable.

Proof. Since I = \emptyset , then the Q-effective implementation of the algorithm \scrS  is
realizable by Theorem 1.

We need two auxiliary Lemmas. First of all, we define an additional function

mn as follows:

mn(0) = n,

for every k \in  \{ 0, 1, . . . , n  -  2\} 

mn(k + 1) =

\biggr\rceil 

\biggl\lceil  mn(k)
8

+ n  -  (k + 1).

Lemma 2. For every k \in  \{ 0, 1, . . . , n  -  1\} 

mn(k) \geq  mn - 1(k) \geq  mn(k)  -  2.

Proof. We prove by induction on k.

For k = 0,

mn(0) = n > mn - 1(0) = n  -  1 > mn(0)  -  2 = n  -  2,

that we need.

By the inductive assumption,

From that,

mn(k) \geq  mn - 1(k) \geq  mn(k)  -  2.

\biggr\rceil 

\biggl\lceil  mn(k)
8

\geq 

\biggr\rceil 

\biggl\lceil  mn - 1(k)
8

\geq 

\biggl\lceil  mn(k)  -  2
8

\biggr\rceil 

.

Then
\biggl\lceil  mn(k)
8

\biggr\rceil 

Hence,

+ n  -  (k + 1) \geq 

\biggr\rceil 

\biggl\lceil  mn - 1(k)
8

+ n  -  (k + 1) \geq 

\biggl\lceil  mn(k)  -  2
8

\biggr\rceil 

+ n  -  (k + 1).

\biggl\lceil  mn(k)
8
\biggl\lceil  mn - 1(k)
8

\biggr\rceil 

\biggr\rceil 

+ n  -  (k + 1) = mn(k + 1),

+ n  -  (k + 1) = mn - 1(k + 1) + 1,

\biggl\lceil  mn(k)  -  2
8

\biggr\rceil 

+ n  -  (k + 1) \geq 

\biggr\rceil 

\biggl\lceil  mn(k)
8

 -  1 + n  -  (k + 1) = mn(k + 1)  -  1.

15

From that, it follows

mn(k + 1) \geq  mn - 1(k + 1) \geq  mn(k + 1)  -  2,

that we need.

Lemma 3. Let p0 be a serial number of the permutation (n, n  -  1, . . . , 1). For
every n \geq  2 the nesting level

T up0 = 3n  -  1.

Moreover, for every p \in  \{ 1, . . . , n!\}  the nesting level

T up \leq  3n  -  1.

Proof. By formula (14), for every p \in  \{ 1, . . . , n!\}  the nesting level T up of the
Q-term up does not exceed the nesting level T up0 of the Q-term up0. So we
should only determine T up0 .

The nesting level of the Q-term up0 is equal to

T up0 = 3n  -  2 + \lceil log mn(n  -  1)\rceil  .

Hence, it is sufficient to prove

We prove it by induction on n. For n = 2 we have

mn(n  -  1) = 2.

m2(1) =

\biggr\rceil 

\biggl\lceil  2
8

+ 1 = 2.

By the inductive assumption, there is mn - 1(n  -  2) = 2. By Lemma 2,

mn(n  -  2) \geq  mn - 1(n  -  2) \geq  mn(n  -  2)  -  2.

So,

Then

Since

then

mn(n  -  2) \geq  2 \geq  mn(n  -  2)  -  2 or 2 \leq  mn(n  -  2) \leq  4.

\biggr\rceil 

\biggl\lceil  2
8

+ 1 \leq 

\biggl\lceil  mn(n  -  2)
8

\biggr\rceil 

+ 1 \leq 

\biggr\rceil 

\biggl\lceil  4
8

+ 1.

\biggl\lceil  mn(n  -  2)
8

\biggr\rceil 

+ 1 = mn(n  -  1),

mn(n  -  1) = 2 and T up0 = 3n  -  1.

Proposition 2. The Q-effective implementation of the algorithm \scrG  is realizable.

For the algorithm \scrG 

for n \geq  2.

D\scrG  = 3n and P\scrG  \geq 

3
2

(n + 1)!

16

Proof. We obtain realizability by Lemma 1.
From (12) and (13) the nesting level

T wj

p \leq  3n

for every p \in  \{ 1, . . . , n!\}  and j \in  \{ 1, . . . , n\} , and for some p and j

T wj

p = 3n.

So, the height of the considered algorithm \scrG  is

D\scrG  = 3n.

Finally, we estimate the width of the algorithm \scrG . The number of operations
of the first nesting level of the set of expressions W ( \=N ) (cf. (6)) of the algorithm
\scrG  is

n
\sum 

k=1

((k + n + 1)(n  -  1)!) =

3
2

(n + 1)n! =

3
2

(n + 1)!.

Therefore, the width of the considered algorithm \scrG  is

P\scrG  \geq 

3
2

(n + 1)!.

Remark 6. If the algorithm \scrB  implements the Gauss--Jordan method, and the
leading elements satisfy the conditions

| a1j1|  = max
1\leq j\leq n

| a1j| 

and for every l \in  \{ 2, . . . , n\} 

\bigm| 
\bigm| aj1...jl - 1
\bigm| 

ljl

\bigm| 
\bigm| 
\bigm|  =

max
1\leq j\leq n
j /\in \{ j1,...,jl - 1\} 

\bigm| 
\bigm| aj1...jl - 1
\bigm| 

lj

\bigm| 
\bigm| 
\bigm|  ,

then D\scrB  = 3n also. The proof is similar to the proof for the algorithm \scrG .

3.3 Solving a system of grid equations by

the Jacobi method

In this subsection we consider some method for solving a system of grid equa-
tions. This method has two sources: the classical iterative Jacobi method for
solving a system of linear equations (see also 5.2.3 on page 60) and a system
of grid equations for numerical solving the Poisson equation, for example, [23,
Chapter 5, § 1].

Therefore, this method may be called as the Jacobi method for solving a
system of grid equations. We would also like to note that this method is a
model for us, and many similar considerations can be used in other cases. As
we will not consider the practical application of this method, then we will not
pay attention to its convergence and other similar topics.

17

3.3.1 The Q-determinant of the Jacobi method

Suppose we have a five-point system of linear equations

ukj =

fkj + akjuk - 1,j + bkjuk,j - 1 + ckjuk+1,j + dkjuk,j+1
ekj

(k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} ),

where ukj are the values of the grid function, akj, bkj, ckj, dkj, ekj, fkj are con-
stants for every k \in  \{ 1, . . . , K\}  and j \in  \{ 1, . . . , J\} . As usual, we set

u0j = uk0 = uK+1,j = uk,J+1 = 0.

Let the algorithm \scrJ  implement the Jacobi method for solving this system.
For every n \in  \{ 1, 2, . . . \} 

un
kj =

fkj + akjun - 1

k - 1,j + bkjun - 1
ekj

k,j - 1 + ckjun - 1

k+1,j + dkjun - 1

k,j+1

,

kj are the initial approximate values of the grid function and un

where u0
kj are
the approximate values of the grid function obtained at the iteration step n for
all k \in  \{ 1, . . . , K\}  and j \in  \{ 1, . . . , J\} .

Let

Vn = \bigl\{ un

kj |  k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} \bigr\} 

be the set of values of the grid function at the nth iteration step.

We express Vn - 1 in terms of Vn - 2. Then we can express Vn in terms of
Vn - 2. Moreover, for all k \in  \{ 1, . . . , K\}  and j \in  \{ 1, . . . , J\}  we can represent un
kj
by the elements from

\bigl\{ un - 2

sl

|  (s, l) \in  I2(k, j)\bigr\}  ,

where for all k \in  \{ 1, . . . , K\}  and j \in  \{ 1, . . . , J\} 

I2(k, j) = \{ (s, l) |  | s  -  k|  + | l  -  j|  \leq  2\}  .

Continuing this process, for every k \in  \{ 1, . . . , K\}  and j \in  \{ 1, . . . , J\}  we can
represent un

kj by the elements from

\bigl\{ u0

sl |  (s, l) \in  In(k, j)\bigr\}  ,

where for all k \in  \{ 1, . . . , K\}  and j \in  \{ 1, . . . , J\} 

In(k, j) = \{ (s, l) |  | s  -  k|  + | l  -  j|  \leq  n\}  .

Let \epsilon  be a given accuracy. Suppose the iterative process is finished if

vn =

\bigwedge 

(| un

kj  -  un - 1

kj

|  < \epsilon )

k\in \{ 1,...,K\} ,
j\in \{ 1,...,J\} 

takes the value true. We can represent the expression vn through the set V0.
Further, note that vn and un
kj are the Q-terms for every k \in  \{ 1, . . . , K\} , j \in 
\{ 1, . . . , J\} , and n \in  \{ 1, 2, . . . , \} . Also

N = \{ K, J\}  and B = \bigl\{ u0

sl |  s \in  \{ 1, . . . , K\} , l \in  \{ 1, . . . , J\} \bigr\}  .

18

Q-determinant. The Q-determinant of the algorithm \scrJ  consists of KJ condi-
tional infinite Q-terms, and the representation in the form of a Q-determinant
is

ukj = \bigl\{ (v1, u1

kj), (v2, u2

kj), . . . , (vn, un

kj), . . . \bigr\}  ,

(16)

where k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} , and n \in  \{ 1, 2, . . . \} .

3.3.2 Realizability and the height of the Jacobi method

Lemma 4. The Q-effective implementation of the algorithm \scrJ  is realizable.

If the integer n0 is such that the value of vn0 is true, then the height of the

algorithm J is

D\scrJ  = 5n0 + 3 + \lceil log KJ\rceil .

Proof. The Q-effective implementation of the algorithm \scrJ  is realizable by The-
orem 1 (Statement (3)) because we have a finite set of operations for every
nesting level.

If for some n0 the value of vn0 is true, then performing the Q-effective im-
kj should be taken as a

plementation should be completed, and the value of un0
solution ukj.

Since N \not = \emptyset , the height of the algorithm \scrJ  should be computed by the

formula (9) for the case I \not = \emptyset . In this case,

\widetilde W ( \=N ) =

\Bigl\{ 

vn0; Vn0 =

\Bigl\{ 

un0
kj |  k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} 

\Bigr\} \Bigr\} 

.

Taking into account the formula for calculating vn0 , we have

T vn0 = 5n0 + 3 + \lceil log KJ\rceil .

Thus, the maximum nesting level of the expressions of the set \widetilde W ( \=N ) is equal to

5n0 + 3 + \lceil log KJ\rceil .

Therefore, the height of the algorithm \scrJ  is

D\scrJ  = 5n0 + 3 + \lceil log KJ\rceil .

Remark 7. It seems to us that the determination of the integer n0 from Lemma
It is possible that this is
4 is a very difficult problem in the general case.
an unsolvable problem because it presupposes too much input data: the sets
\{ akj\} k,j, \{ bkj\} k,j, \{ ckj\} k,j, \{ dkj\} k,j, \{ ekj\} k,j, and \{ fkj\} k,j. However, it is worth
noting that the integer n0 from Lemma 4 can be found in [23, Chapter 5, § 1,
p. 382] for the numerical solution of the Poisson equation which is an important
case.

3.3.3 Performing the Q-effective implementation of the algorithm \scrJ 

We describe the process of performing the Q-effective implementation of the
algorithm \scrJ  , which is divided into stages.

19

Stage 1. As in 3.3.1, performing the Q-effective implementation begins with

the computation of a set of Q-terms

V1 = \bigl\{ u1

kj |  k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} \bigr\} 

\Bigl\{ 

\Bigr\} 

u0
kj |  k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} 

using V0 =
. For that, the number
of operations is 4KJ at the first nesting level, at the second nesting level
is 2KJ, at each of the nesting levels 3, 4, 5 is KJ.

Stage 2. Now we can compute Q-terms

v1 and V2 = \bigl\{ u2

kj |  k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} \bigr\}  .

Their computations must be performed simultaneously.
The number of operations for the computation of v1 is KJ at each of the
first three levels of nesting. After that, we have a chain of conjunctions
of length KJ, computed by the doubling scheme. To do this, we use two
levels of nesting.

The computation of V2 is similar to the computation of V1.

Stage p \geq  3 can be described as follows. Since we computed Vp - 1, then we can

continue the computation of Q-terms v1,. . . ,vp - 2.

Simultaneously, we can begin to compute Q-terms

vp - 1 and Vp =

up
kj |  k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} 

\Bigl\{ 

\Bigr\} 

.

Once again, the number of operations for the computation of vp - 1 is KJ
at each of the first three levels of nesting. After that, we have a chain of
conjunctions of length KJ, computed by the doubling scheme. To do this,
we use two levels of nesting.

The computation of Vp is similar to the computation of V1.

Lemma 5. Every stage of the process for performing the Q-effective implemen-
tation of the algorithm \scrJ  has five levels of nesting.

Proof. Based on the above, every stage p has five levels of nesting, because we
compute

Vp =

on the base of

\Bigl\{ 

up
kj |  k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} 

\Bigr\} 

Vp - 1 =

\Bigl\{ 

up - 1
kj

|  k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} 

\Bigr\} 

.

20

3.3.4 The width of the Jacobi method

Remark 8. It is very important to point out the following. If we have only one
stage, then the consideration doesn't make sense, since stage 2 is the beginning
of the computation of v1.

So we only consider p \geq  2 stages.

Lemma 6. Suppose that we execute stage p of the process for performing the
Q-effective implementation of the algorithm \scrJ  .

1. If p \geq  1, then under the computation of

Vp =

\Bigl\{ 

up
kj |  k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} 

\Bigr\} 

we must execute the following number of operations:

4KJ for the first nesting level;

2KJ for the second nesting level;

KJ for the nesting levels 3, 4, and 5.

2. If p \geq  2 and KJ \geq  4, then under the computation of vp - 1 we must execute

the following number of operations:

KJ for the nesting levels 1, 2, and 3;

\lfloor KJ/2\rfloor  for the fourth nesting level;

\lfloor KJ/4\rfloor  for the fifth nesting level.

3. Assume that p \geq  3 and KJ \geq  25p - 8. Let l \in  \{ 1, 2, 3, 4, 5\}  be a nesting
level. Then for every t \geq  2 under the computation of vp - t we must execute
the following number of operations:

\biggl\lfloor 

KJ
22+l \times  32t - 2

\biggr\rfloor 

.

In particular, if p \geq  3 and KJ \geq  25p - 8, then

\biggl\lfloor 

KJ
22+l \times  32p - 3

\biggr\rfloor 

operations on the nesting level l \in  \{ 1, 2, 3, 4, 5\}  to compute v1.

Proof. The first and second stages (p \in  \{ 1, 2\} ) differ from the others.

1. In stage 1, we compute V1 =

u1
kj |  k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} 

. For

\Bigl\{ 

\Bigr\} 

that, we must execute the following number of operations:

4KJ for the first nesting level;

2KJ for the second nesting level;

KJ for the nesting levels 3, 4, and 5.

21

\Bigl\{ 

\Bigr\} 

2. In stage 2, we compute V2 =

and
an expression v1. To compute V2, we must have as many operations as
in stage 1 for V1. To compute the expression v1, we must execute the
following numbers of operations:

u2
kj |  k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} 

KJ for the nesting levels 1, 2, and 3;

\lfloor KJ/2\rfloor  for the fourth nesting level;

\lfloor KJ/4\rfloor  for the fifth nesting level.

3. Now we consider the case p \geq  3. First, note:

(a) it is clear that to compute

Vp =

\Bigl\{ 

up
kj |  k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} 

\Bigr\} 

we need as many operations as in stage 1 for V1;

(b) also, the computation of the expression vp - 1 is needed the same num-
ber of operations as in stage 2 for v1, because we are just beginning
the computation of vp - 1.

Therefore, we must consider the computation of vp - t for t \geq  2. We fix
t \geq  2. We started computing vp - t in stage p  -  t + 1. By Statement 2, we
must use the following number of operations:

KJ for the nesting levels 1, 2, and 3;

\lfloor KJ/2\rfloor  for the fourth nesting level;

\lfloor KJ/4\rfloor  for the fifth nesting levels

under the computation of vp - t in stage p  -  t + 1.
We use the doubling scheme for the computation of vp - t. Therefore, in
stage p  -  t + 2 we must execute the following number of operations:

\lfloor KJ/8\rfloor  for the first nesting;

\lfloor KJ/16\rfloor  for the second nesting;

\lfloor KJ/32\rfloor  for the third nesting;

\lfloor KJ/64\rfloor  for the fourth nesting level;

\lfloor KJ/128\rfloor  for the fifth nesting levels.

Thus, for the computation of vp - t we need

\biggr\rfloor 

\biggl\lfloor  KJ
22+l

operations for the nesting level l \in  \{ 1, 2, 3, 4, 5\}  in stage p  -  t + 2.

For every q \in  \{ 0, 1, . . . , t  -  2\}  we should determine the number of opera-
tions for the nesting level l \in  \{ 1, 2, 3, 4, 5\}  in stage p  -  t + 2 + q. We have
already considered the case q = 0. By the inductive assumption, under
the computation of vp - t we have used the following number of operations

\biggl\lfloor  KJ

\biggr\rfloor 

22+l \times  32q

22

for the nesting level l \in  \{ 1, 2, 3, 4, 5\}  in stage p  -  t + 2 + q.
Since we use the doubling scheme for the computation of vp - t again, then
in stage p  -  t + 2 + (q + 1) we must execute the following number of
operations:

\lfloor KJ/(8 \times  32q \times  32)\rfloor  for the first nesting level;
\lfloor KJ/(16 \times  32q \times  32)\rfloor  for the second nesting level;
\lfloor KJ/(32 \times  32q \times  32)\rfloor  for the third nesting level;
\lfloor KJ/(64 \times  32q \times  32)\rfloor  for the fourth nesting level;
\lfloor KJ/(128 \times  32q \times  32)\rfloor  for the fifth nesting level.

Hence, for the computation of vp - t we need

\biggl\lfloor 

KJ
22+l \times  32q+1

\biggr\rfloor 

operations for the nesting level l \in  \{ 1, 2, 3, 4, 5\}  in stage p  -  t + 2 + (q + 1).

Finally, we make an important remark. Our considerations make no sense
if the number operations is less than 1. Indeed, we have the least number
of operations

\biggl\lfloor 

KJ
22+5 \times  32p - 3

\biggr\rfloor 

=

\biggr\rfloor 

\biggl\lfloor  KJ
25p - 8

for the nesting level 5 under the computation of v1. Since we have KJ \geq 
25p - 8 by the assumption of Statement 3, our considerations are correct.

Now we want to consider the cases when the computation of v1 stops in
stage p \in  \{ 2, 3\} . It should be noted that stopping in stage 1 is impossible by
Remark 8.

Lemma 7. Suppose that we have executed p stages of the process to perform
the Q-effective implementation of the algorithm \scrJ  .

1. If we stop computing of v1 in stage p = 2, then

KJ \in  \{ 1, 2, . . . , 7\} 

and the width of the algorithm \scrJ  is equal to

P\scrJ  (K, J) = 5 \cdot  KJ.

2. If we stop computing of v1 in stage p = 3, then

KJ \in  \{ 8, 9, . . . , 255\} 

and the width of the algorithm \scrJ  is equal to

P\scrJ  (K, J) = 5 \cdot  KJ +

\biggr\rfloor 

\biggl\lfloor  KJ
8

= 5 \cdot  KJ + t,

where KJ \in  \{ 8t, 8t + 1, . . . , 8t + 7\}  for t \in  \{ 1, 2, . . . , 31\} .

23

In particular, the width P\scrJ  (K, J) is a strictly increasing function of KJ for
KJ \in  \{ 1, . . . , 255\} .

Proof. The process for performing the Q-effective implementation of the algo-
rithm \scrJ  is described in the proof of Lemma 6.

1. We execute

KJ,

\biggl\lfloor  KJ
2

\biggr\rfloor 

\biggl\lfloor  KJ
4

,

\biggr\rfloor 

operations according to the nesting level.

Let KJ \not = 1. Then the stopping criterion is that one of the numbers
\lfloor KJ/2\rfloor , or \lfloor KJ/4\rfloor  is equal to 1, i.e.,

\biggr\rfloor 

\biggr\rfloor 

\biggl\lfloor  KJ
2
\biggl\lfloor  KJ
4

= 1 \Leftarrow \Rightarrow  2 \leq  KJ \leq  3;

= 1 \Leftarrow \Rightarrow  4 \leq  KJ \leq  7.

It is clear that the width of the algorithm \scrJ  is equal to

P\scrJ  (K, J) = 5 \cdot  KJ.

2. There are

\biggl\lfloor  KJ
8

\biggr\rfloor 

\biggl\lfloor  KJ
16

,

\biggr\rfloor 

\biggl\lfloor  KJ
32

,

\biggr\rfloor 

\biggl\lfloor  KJ
64

,

\biggr\rfloor 

\biggr\rfloor 

\biggl\lfloor  KJ
128

,

operations according to the nesting levels.

The stopping criterion is that one of these numbers is equal to 1, i.e.,

\biggr\rfloor 

\biggr\rfloor 

\biggr\rfloor 

\biggl\lfloor  KJ
8
\biggl\lfloor  KJ
32
\biggl\lfloor  KJ
128

= 1 \Leftarrow \Rightarrow  8 \leq  KJ \leq  15;

= 1 \Leftarrow \Rightarrow  32 \leq  KJ \leq  63;

= 1 \Leftarrow \Rightarrow  128 \leq  KJ \leq  255.

Hence, for every KJ \in  \{ 8, 9, . . . , 255\} 

\biggr\rfloor 

\biggr\rfloor 

\biggl\lfloor  KJ
16
\biggl\lfloor  KJ
64

= 1 \Leftarrow \Rightarrow  16 \leq  KJ \leq  31;

= 1 \Leftarrow \Rightarrow  64 \leq  KJ \leq  127;

\biggr\rfloor 

\biggl\lfloor  KJ
8

= t \Leftarrow \Rightarrow  KJ \in  \{ 8t, 8t + 1, . . . , 8t + 7\} .

So, the width of the algorithm \scrJ  is equal to

P\scrJ  (K, J) = 5 \cdot  KJ +

\biggr\rfloor 

\biggl\lfloor  KJ
8

= 5 \cdot  KJ + t

if KJ \in  \{ 8t, 8t + 1, . . . , 8t + 7\}  for t \in  \{ 1, 2, . . . , 31\} .

24

Table 1: The width of the algorithm \scrJ  for KJ \in  \{ 1, 2, . . . , 255\} 

For KJ \in  \{ 1, 2, . . . , 7\}  we have

P\scrJ  (K, J) = 5KJ.

For KJ \in  \{ 8, 9, . . . , 255\}  we have

P\scrJ  (K, J) = 5 \cdot  KJ + t

if KJ \in  \{ 8t, 8t + 1, . . . , 8t + 7\}  for t \in  \{ 1, 2, . . . , 31\} .

Remark 9. Consequently, we fully studied the width of the algorithm \scrJ  for
KJ \in  \{ 1, 2, . . . , 255\} . Thus, we should consider the case when KJ \geq  256. In
addition, by Lemma 7, we can suppose that we execute p \geq  4 stages of the
process to perform the Q-effective implementation of the algorithm \scrJ  .

Lemma 8. Suppose we have executed p stages of the process to perform the
Q-effective implementation of the algorithm \scrJ  .

If the stop for computing v1 occurs in stage p \geq  4, then

KJ \in  \{ 8 \times  32p - 3, 8 \times  32p - 3 + 1, . . . , 256 \times  32p - 3  -  1\} 

and the width of the algorithm \scrJ  is equal to

P\scrJ  (K, J) = 5 \cdot  KJ +

\biggr\rfloor 

\biggl\lfloor  KJ
8

+

\biggl\lfloor  KJ

\biggr\rfloor 

8 \times  32

+ \cdot  \cdot  \cdot  +

\biggl\lfloor  KJ

8 \times  32p - 3

\biggr\rfloor 

.

Proof. The process for performing the Q-effective implementation of the algo-
rithm \scrJ  is described in the proof of Lemma 6.

If we stop computing of v1 in stage p, then for the computation of the
expression v1 we need to execute the following numbers of operations in stage
p:

\lfloor KJ/(8 \times  32p - 3)\rfloor  for the first nesting level;
\lfloor KJ/(16 \times  32p - 3)\rfloor  for the second nesting level;
\lfloor KJ/(32 \times  32p - 3)\rfloor  for the third nesting level;
\lfloor KJ/(64 \times  32p - 3)\rfloor  for the fourth nesting level;
\lfloor KJ/(128 \times  32p - 3)\rfloor  for the fifth nesting level.

25

The stopping criterion is that one of these numbers is equal to 1, i.e.,

\biggl\lfloor  KJ

8 \times  32p - 3

\biggl\lfloor  KJ

16 \times  32p - 3

\biggl\lfloor  KJ

32 \times  32p - 3

\biggl\lfloor  KJ

\biggl\lfloor 

64 \times  32p - 3
KJ
128 \times  32p - 3

\biggr\rfloor 

\biggr\rfloor 

\biggr\rfloor 

\biggr\rfloor 

\biggr\rfloor 

= 1 \Leftarrow \Rightarrow  8 \times  32p - 3 \leq  KJ \leq  16 \times  32p - 3  -  1;

= 1 \Leftarrow \Rightarrow  16 \times  32p - 3 \leq  KJ \leq  32 \times  32p - 3  -  1;

= 1 \Leftarrow \Rightarrow  32 \times  32p - 3 \leq  KJ \leq  64 \times  32p - 3  -  1;

= 1 \Leftarrow \Rightarrow  64 \times  32p - 3 \leq  KJ \leq  128 \times  32p - 3  -  1;

= 1 \Leftarrow \Rightarrow  128 \times  32p - 3 \leq  KJ \leq  256 \times  32p - 3  -  1.

Hence, for every KJ \in  \{ 8 \times  32p - 3, 8 \times  32p - 3 + 1, . . . , 256 \times  32p - 3  -  1\}  we obtain

\biggl\lfloor  KJ

\biggr\rfloor 

= t \Leftarrow \Rightarrow 

8 \times  32p - 3
\Leftarrow \Rightarrow  KJ \in  \{ (8 \times  32p - 3)t, (8 \times  32p - 3)t + 1, . . . , (8 \times  32p - 3)(t + 1)  -  1\} .

Under the process for performing the Q-effective implementation of the algo-
rithm \scrJ  , the computation of v1 stops first. Further stages of the computations
have the same number of operations. So, we can only consider the computation
of v1.

Consequently, the width of the algorithm \scrJ  is equal to

P\scrJ  (K, J) = 5 \cdot  KJ +

\biggr\rfloor 

\biggl\lfloor  KJ
8

+

\biggl\lfloor  KJ

\biggr\rfloor 

8 \times  32

+ \cdot  \cdot  \cdot  +

\biggl\lfloor  KJ

8 \times  32p - 3

\biggr\rfloor 

.

This completes the proof of Lemma 8.

Proposition 3. Suppose that KJ \geq  256. More exactly,

KJ \in  \{ 8 \times  32p - 3, 8 \times  32p - 3 + 1, . . . , 256 \times  32p - 3  -  1\} 

for a suitable p \in  \{ 4, 5, . . . \} . Furthermore,

KJ = a + 8b0 + (8 \times  32)b1 + (8 \times  322)b2 + \cdot  \cdot  \cdot  + (8 \times  32p - 4)bp - 4 + (8 \times  32p - 3)bp - 3,

where

a \in  \{ 0, 1, . . . , 7\} ,
bi \in  \{ 0, 1, . . . , 31\}  for every i \in  \{ 0, 1, . . . , p  -  4\} ,

bp - 3 \in  \{ 1, 2, . . . , 31\} .

Then the width of the algorithm \scrJ  is equal to

P\scrJ  (K, J) = 5 \cdot  KJ + c0 + c1 + \cdot  \cdot  \cdot  + cp - 3,

(17)

where for every i \in  \{ 0, 1, . . . , p  -  3\} 

ci = bi + 32bi+1 + \cdot  \cdot  \cdot  + 32p - 3 - ibp - 3.

26

Also, we have the following recurrence formula:

cp - 3 = bp - 3

and for every i \in  \{ p  -  3, p  -  4, . . . , 1\} 

ci - 1 = bi - 1 + 32ci.

Proof. We apply Lemma 8. We should compute
\biggl\lfloor  KJ
8

\biggl\lfloor  KJ

8 \times  32

, . . . ,

\biggr\rfloor 

\biggr\rfloor 

,

\biggl\lfloor  KJ

8 \times  32p - 3

\biggr\rfloor 

.

Then

\biggr\rfloor 

\biggl\lfloor  KJ
8

= c0 = b0 + 32b1 + 322b2 + \cdot  \cdot  \cdot  + 32p - 4bp - 4 + 32p - 3bp - 3,

similarly, we get for every i \in  \{ 1, . . . , p  -  3\} 

\biggl\lfloor  KJ

\biggr\rfloor 

8 \times  32i

= ci = bi + 32bi+1 + \cdot  \cdot  \cdot  + 32p - 3 - ibp - 3;

in particular, we have

\biggl\lfloor  KJ

\biggr\rfloor 

8 \times  32p - 3

= cp - 3 = bp - 3.

Furthermore, it is obvious that

for every i \in  \{ p  -  3, p  -  4, . . . , 1\} .

ci - 1 = bi - 1 + 32ci

Remark 10. From Proposition 3 we obtain that the width of the algorithm \scrJ 
depends only on the product KJ. Therefore, we can write P\scrJ  (KJ) instead of
P\scrJ  (K, J) without loss of generality.

Corollary 1. Suppose that for p \geq  4
KJ = a + 8b0 + (8 \times  32)b1 + (8 \times  322)b2 + \cdot  \cdot  \cdot  + (8 \times  32p - 4)bp - 4 + (8 \times  32p - 3)bp - 3,

where

Then

a \in  \{ 0, 1, . . . , 7\} ,
bi \in  \{ 0, 1, . . . , 31\}  for every i \in  \{ 0, 1, . . . , p  -  4\} ,

bp - 3 \in  \{ 1, 2, . . . , 31\} .

P\scrJ  (KJ + 1) =

= P\scrJ  (KJ) +

\left\{ 

5
6
l + 6

p + 4

if a \in  \{ 0, 1, . . . , 6\} ;
if a = 7 and b0 \in  \{ 0, 1, . . . , 30\} ;
if a = 7, b0 = \cdot  \cdot  \cdot  = bl - 1 = 31,
bl \in  \{ 0, 1, . . . , 30\}  for some l \in  \{ 1, . . . , p  -  3\} ;
if a = 7 and b0 = \cdot  \cdot  \cdot  = bp - 3 = 31.

In particular, the width P\scrJ  (KJ) is a strictly increasing function of KJ.

27

       
       
Proof. There are four cases.

1. The first case is a \in  \{ 0, 1, . . . , 6\} . Then for every i \in  \{ 0, 1, . . . , p  -  3\}  we

have

By Proposition 3

\biggr\rfloor 

\biggl\lfloor  KJ + 1
8 \times  32i

=

\biggl\lfloor  KJ

8 \times  32i

\biggr\rfloor 

.

P\scrJ  (KJ + 1) = P\scrJ  (KJ) + 5.

2. In the second case, we have

Then

a = 7 and b0 \in  \{ 0, 1, . . . , 30\} .

\biggr\rfloor 

\biggl\lfloor  KJ + 1
8

=

\biggr\rfloor 

\biggl\lfloor  KJ
8

+ 1

and for every i \in  \{ 1, 2 . . . , p  -  3\} 

\biggr\rfloor 

\biggl\lfloor  KJ + 1
8 \times  32i

=

\biggl\lfloor  KJ

8 \times  32i

\biggr\rfloor 

.

By Proposition 3

P\scrJ  (KJ + 1) = P\scrJ  (KJ) + 5 + 1 = P\scrJ  (KJ) + 6.

3. In the third case, we have

a = 7, b0 = \cdot  \cdot  \cdot  = bl - 1 = 31 and bl \in  \{ 0, 1, . . . , 30\} 

for some l \in  \{ 1, . . . , p  -  3\} . Then

KJ = 7 + 31 \bigl( 8 + \cdot  \cdot  \cdot  + (8 \times  32l - 1)\bigr)  +

+ (8 \times  32l)bl + \cdot  \cdot  \cdot  + (8 \times  32p - 3)bp - 3,

KJ + 1 = 0 + 0 \bigl( 8 + \cdot  \cdot  \cdot  + (8 \times  32l - 1)\bigr)  +

+ (8 \times  32l)(bl + 1) + \cdot  \cdot  \cdot  + (8\times 32p - 3)bp - 3 =

= (8 \times  32l)(bl + 1) + \cdot  \cdot  \cdot  + (8 \times  32p - 3)bp - 3.

By Proposition 3

P\scrJ  (KJ) = 5 \cdot  KJ + c0 + c1 + \cdot  \cdot  \cdot  + cp - 3,

where for every i \in  \{ l, . . . , p  -  3\} 

ci = bi + 32bi+1 + \cdot  \cdot  \cdot  + 32p - 3 - ibp - 3

and for every i \in  \{ 0, . . . , l  -  1\} 

ci = 31 + 32 \cdot  31 + \cdot  \cdot  \cdot  + 32l - 1 - i \cdot  31 + 32l - ibl + . . .

+ 32p - 3 - ibp - 3 =

= 31(1 + 32 + \cdot  \cdot  \cdot  + 32l - 1 - i) + 32l - i(bl + \cdot  \cdot  \cdot  + 32p - 3 - lbp - 3) =

= 31 \cdot 

32l - i  -  1
32  -  1

+ 32l - i(bl + \cdot  \cdot  \cdot  + 32p - 3 - lbp - 3) =

= (32l - i  -  1) + 32l - i(bl + \cdot  \cdot  \cdot  + 32p - 3 - lbp - 3).

28

Again, by Proposition 3

P\scrJ  (KJ + 1) = 5 \cdot  (KJ + 1) + c\prime 

0 + c\prime 

1 + \cdot  \cdot  \cdot  + c\prime 

p - 3,

where for every i \in  \{ l + 1, . . . , p  -  3\} 

c\prime 
i = bi + 32bi+1 + \cdot  \cdot  \cdot  + 32p - 3 - ibp - 3 = ci,
l = (bl + 1) + 32bl+1 + \cdot  \cdot  \cdot  + 32p - 3 - lbp - 3 = cl + 1,
c\prime 

and for every i \in  \{ 0, . . . , l  -  1\} 

i = 0 + 32 \cdot  0 + \cdot  \cdot  \cdot  + 32l - 1 - i \cdot  0 + 32l - i(bl + 1) + . . .
c\prime 

+ 32p - 3 - ibp - 3 =

= 32l - i + 32l - i(bl + \cdot  \cdot  \cdot  + 32p - 3 - lbp - 3) = ci + 1.

So, we obtain

P\scrJ  (KJ + 1) = 5 \cdot  (KJ + 1) + (c\prime 

0 + \cdot  \cdot  \cdot  + c\prime 

l - 1) + c\prime 

l + (c\prime 

l + \cdot  \cdot  \cdot  + c\prime 

p - 3) =

= (5KJ + 5) + ((c0 + 1) + \cdot  \cdot  \cdot  + (cl - 1 + 1)) + (cl + 1)+
+ (cl + \cdot  \cdot  \cdot  + cp - 3) =
= (5KJ + c0 + c1 + \cdot  \cdot  \cdot  + cp - 3) + 5 + (l + 1) =
= P\scrJ  (KJ) + l + 6.

4. Finally, we consider the case

a = 7 and b0 = \cdot  \cdot  \cdot  = bp - 3 = 31.

Then

KJ = 7 + 31 \bigl( 8 + \cdot  \cdot  \cdot  + (8 \times  32p - 3)\bigr)  =
= 7 + (31 \cdot  8) \bigl( 1 + \cdot  \cdot  \cdot  + 32p - 3\bigr)  =

= 7 + (31 \cdot  8) \cdot 

32p - 2  -  1
32  -  1

= 7 + 8 \cdot  (32p - 2  -  1) = 8 \times  32p - 2  -  1,

KJ + 1 = 8 \times  32p - 2.

By Proposition 3

P\scrJ  (KJ) = 5 \cdot  KJ + c0 + c1 + \cdot  \cdot  \cdot  + cp - 3,

for every i \in  \{ 0, . . . , p  -  3\} 

ci = 31 + 32 \cdot  31 + \cdot  \cdot  \cdot  + 32p - 3 - i \cdot  31 =
= 31(1 + 32 + \cdot  \cdot  \cdot  + 32p - 3 - i) =

= 31 \cdot 

32p - 2 - i  -  1
32  -  1

= 32p - 2 - i  -  1.

29

So, we have

P\scrJ  (KJ) = 5 \cdot  (8 \times  32p - 2  -  1) + (32p - 2  -  1) + \cdot  \cdot  \cdot  + (32  -  1) =

= 40 \cdot  32p - 2  -  5  -  (p  -  2) + 32 \bigl( 1 + \cdot  \cdot  \cdot  + 32p - 3\bigr)  =

= 40 \cdot  32p - 2  -  p  -  3 + 32 \cdot 

= 40 \cdot  32p - 2  -  p  -  3 + 31 \cdot 

32p - 2  -  1
32  -  1
32p - 2  -  1
31

= 40 \cdot  32p - 2  -  p  -  3 + (32p - 2  -  1) +

= 41 \cdot  32p - 2  -  p  -  4 +

32p - 2  -  1
31

.

Again, by Proposition 3

=

=

+

32p - 2  -  1
31
32p - 2  -  1
31

=

P\scrJ  (KJ + 1) = 5 \cdot  (KJ + 1) + c\prime 

0 + c\prime 

1 + \cdot  \cdot  \cdot  + c\prime 

p - 2,

for every i \in  \{ 0, . . . , p  -  2\} 

i = 0 + 32 \cdot  0 + \cdot  \cdot  \cdot  + 32p - 3 - i \cdot  0 + 32p - 2 - i \cdot  1 = 32p - 2 - i.
c\prime 

So, we obtain

P\scrJ  (KJ + 1) = 5 \cdot  (8 \times  32p - 2) + 32p - 2 + 32p - 3 + \cdot  \cdot  \cdot  + 320 =

= 41 \cdot  32p - 2 +

32p - 2  -  1
31

= P\scrJ  (KJ) + p + 4.

3.3.5 The width of the Jacobi method for KJ = 2s

Here we consider the case when KJ = 2s. The width formula of the algorithm
\scrJ  from Proposition 3 is quite complicated and inconvenient to compute in some
cases.

At the same time, it is obvious that the computations are simpler if KJ = 2s.

Lemma 9. Suppose that we execute stage p of the process to perform the Q-
effective implementation of the algorithm \scrJ  .

1. If p \geq  1, then under the computation of

Vp =

\Bigl\{ 

up
kj |  k \in  \{ 1, . . . , K\} , j \in  \{ 1, . . . , J\} 

\Bigr\} 

we must execute the following number of operations:

4KJ = 22+s for the first nesting level;
2KJ = 21+s for the second nesting level;
KJ = 2s for the nesting levels 3, 4, and 5.

30

2. If p \geq  2 and s \geq  2, then under the computation of vp - 1 we must execute

the following number of operations:

KJ = 2s for the nesting levels 1, 2, and 3;

KJ/2 = 2s - 1 for the fourth nesting level;
KJ/4 = 2s - 2 for the fifth nesting level.

3. Assume that p \geq  3 and s \geq  5p  -  8. Let l \in  \{ 1, 2, 3, 4, 5\}  be a nesting level.
Then for every t \geq  2 under the computation of vp - t we must execute the
following number of operations:

KJ

22+l \times  32t - 2 = 2s - l - 5p+13.

In particular, if p \geq  3 and s \geq  5p  -  8, then we use

KJ

22+l \times  32p - 3 = 2s - l - 5t+8

operations on the nesting level l \in  \{ 1, 2, 3, 4, 5\}  to compute v1.

Proof. This lemma is a particular case of Lemma 6. Since for every q \in 
\{ 0, 1, . . . , s\}  we get

\biggr\rfloor 

\biggl\lfloor  KJ
2q

= 2s - q,

then the proof is trivial.

Lemma 10. Suppose that KJ = 2s and we have executed p \geq  3 stages of the
process for performing the Q-effective implementation of the algorithm \scrJ  .

1. For each stage, we have the most number of operations on the first nesting

level, and each of the other nesting levels has fewer operations.

2. Furthermore, on the first nesting level, the total number of operations is

P (2s, p) = 5 \cdot  2s + 2s+12 - 5p \cdot 

25p - 10  -  1
31

.

Proof. The first statement is a direct consequence of Lemma 9.

Indeed, we get

P (2s, p) = 4KJ + KJ +

KJ
8

+ \cdot  \cdot  \cdot  +

KJ

8 \times  32p - 3 = 5 \cdot  2s +

p - 3
\sum 

i=0

2s
8 \times  32i =

= 5 \cdot  2s +

p - 3
\sum 

i=0

2s - 3 - 5i = 5 \cdot  2s +

p - 3
\sum 

i=0

2s - 3 - 5i =

= 5 \cdot  2s + 2s+12 - 5p

= 5 \cdot  2s + 2s+12 - 5p

p - 3
\sum 

i=0

p - 3
\sum 

i=0

2s - 3 - 5i - s - 12+5p =

25(p - 3 - i) = 5 \cdot  2s + 2s+12 - 5p

p - 3
\sum 

l=0

25l =

= 5 \cdot  2s + 2s+12 - 5p \cdot 

25(p - 2)  -  1
25  -  1

= 5 \cdot  2s + 2s+12 - 5p \cdot 

31

25p - 10  -  1
31

.

(18)

Lemma 11. Suppose that KJ = 2s \geq  8. Also

s \equiv  r

(mod 5) for the suitable r \in  \{  - 2,  - 1, 0, 1, 2\} .

In the process of performing the Q-effective implementation of the algorithm \scrJ  ,
the computation of v1 stops in stage

p = 2 +

s  -  r
5

= 2 +

\Bigr] 

\Bigl[  s
5

\geq  3,

and on the first nesting level of stage p we have

P (2s, p) = 5 \cdot  2s + 22+r \cdot 

2s - r  -  1
31

.

operations.

Proof. Under the computation of v1, there exists a stage p such that on one of
its nesting levels we have only one operation. After that, the computation of v1
finishes.

Let us describe the process of computing a Q-term v1 at the necessary stage

p. By Lemma 9, we obtain

2s+12 - 5p, 2s+11 - 5p, 2s+10 - 5p, 2s+9 - 5p, 2s+8 - 5p

operations according to the nesting levels. The stopping criterion is that one of
these numbers is equal to 1, i.e.,

for some r \in  \{  - 2,  - 1, 0, 1, 2\} . Hence,

2s+10 - r - 5p = 1

s = 5(p  -  2) + r \Leftarrow \Rightarrow  p =

s + 10  -  r
5

= 2 +

s  -  r
5

= 2 +

\Bigr] 

\Bigl[  s
5

\geq  3,

and

s \equiv  r

(mod 5).

From this we obtain the total number of operations on the first nesting level

by the equality (18):

P (2s, p) = 5 \cdot  2s + 2s+12 - 5p \cdot 

= 5 \cdot  2s + 2s+12 - s - 10+r \cdot 

=

25p - 10  -  1
31
2s+10 - r - 10  -  1
31

for r \in  \{  - 2,  - 1, 0, 1, 2\}  and s \equiv  r (mod 5).

= 5 \cdot  2s + 22+r \cdot 

2s - r  -  1
31

Proposition 4. Suppose that KJ = 2s \geq  8. The width of the algorithm \scrJ  is
equal to

2s - r  -  1
31

(19)

P\scrJ  (2s) = 5 \cdot  2s + 22+r \cdot 

for r \in  \{  - 2,  - 1, 0, 1, 2\}  and r \equiv  s (mod 5).

32

Proof. As in the proof of Lemma 8, we can only consider the computation of
v1.

By Lemma 11, the computation of v1 stops at the stage

p = 2 + 2 +

\Bigr] 

\Bigl[  s
5

\geq  3.

On the first nesting level of this stage, we obtain the largest number of operations
by Lemma 10.

Thus, the width of the algorithm \scrJ  is equal to

P\scrJ  (2s) = P (2s, p) = 5 \cdot  2s + 22+r \cdot 

2s - r  -  1
31

for r \in  \{  - 2,  - 1, 0, 1, 2\}  such that

r \equiv  s

(mod 5).

Remark 11. It is interesting to consider the case p = 3. Obviously,

Then

p = 3 \Leftarrow \Rightarrow  s \in  \{ 3, 4, 5, 6, 7\} .

s  -  r = 5

for r \in  \{  - 2,  - 1, 0, 1, 2\}  such that r \equiv  s (mod 5).

It follows that the width of the algorithm \scrJ  is equal to

P\scrJ  (2s) = 5 \cdot  2s + 22+r \cdot 
\left\{ 

25  -  1
31

= 5 \cdot  2s + 22+r =

=

5 \cdot  8 + 20 = 41
5 \cdot  16 + 21 = 82
5 \cdot  32 + 22 = 164
5 \cdot  64 + 23 = 328
5 \cdot  128 + 24 = 656

for 2s = 8;
for 2s = 16;
for 2s = 32;
for 2s = 64;
for 2s = 128.

Remark 11 is easily generalized as a corollary of Proposition 4.

Corollary 2. Suppose that KJ = 25q - 2 \geq  8 and the width of the algorithm \scrJ 
is equal to

P\scrJ  (25q - 2) = 5 \cdot  25q - 2 +

25q  -  1
31

.

Then

for t \in  \{ 0, 1, 2, 3, 4\} .

P\scrJ  (25q - 2+t) = 2t \cdot  P\scrJ  (25q - 2)

Proof. It is a direct generalization of the consideration in Remark 11.

By this Corollary we easy make the following table.
Now we estimate the width of the algorithm \scrJ  . More exactly, we would like

to estimate the fraction

in the equality (19).

2s - r  -  1
31

33

       
       
Table 2: The width of the algorithm \scrJ  for KJ = 2s

s

0
P\scrJ  (2s) 5

1
2
10 20

s

4

5
3
P\scrJ  (2s) 41 82 164
10
5252

9
2626

8

6
328

7
656

11

12

10504 21008

s

P\scrJ  (2s) 1313

Corollary 3. Suppose that s \geq  8, r \equiv  s (mod 5) for r \in  \{  - 2,  - 1, 0, 1, 2\} . Also

d(s) = 41 \cdot  2s - 3.

Then

Furthermore,

2s - r - 5 <

2s - r  -  1
31

< 2s - r - 4  -  1.

(20)

41 \cdot  2s - 3 < P\scrJ  (2s) < 21 \cdot  2s - 2  -  22+r \leq  21 \cdot  2s - 2  -  1 < 6 \cdot  2s \Leftarrow \Rightarrow 
\Leftarrow \Rightarrow  d(s) < P\scrJ  (2s) < d(s) + 2s - 3  -  22+r \leq  d(s) + 2s - 3  -  1 < 6 \cdot  2s.

Proof. We note the following very trivial result. If a > b > c > 0, then

a
b

<

a  -  c
b  -  c

.

Therefore, for every q \in  \{ 2, 3, . . . \} 

25q  -  1 + 1
31 + 1

<

25q  -  1
31

<

25q  -  1  -  15
31  -  15

\Leftarrow \Rightarrow  25(q - 1) <

25q  -  1
31

< 25q - 4  -  1.

By Proposition 4

P\scrJ  (2s) = 5 \cdot  2s + 22+r \cdot 

2s - r  -  1
31

.

How in Remark 11, we get

s  -  r = 5q and q \geq  2

2s - r - 5 <

2s - r  -  1
31

< 2s - r - 4  -  1.

for s \geq  8. Hence,

Now

5 \cdot  2s + 22+r \cdot  2s - r - 5 < P\scrJ  (2s) < 5 \cdot  2s + 22+r(2s - r - 4  -  1) \Leftarrow \Rightarrow 
\Leftarrow \Rightarrow  5 \cdot  2s + 2s - 3 < P\scrJ  (2s) < 5 \cdot  2s + 2s - 2  -  22+r \leq  5 \cdot  2s + 2s - 2  -  1 \Leftarrow \Rightarrow 
\Leftarrow \Rightarrow  2s - 3(40 + 1) < P\scrJ  (2s) < 2s - 2(20 + 1)  -  22+r \leq  2s(20 + 1)  -  1 \Leftarrow \Rightarrow 
\Leftarrow \Rightarrow  41 \cdot  2s - 3 < P\scrJ  (2s) < 21 \cdot  2s - 2  -  22+r \leq  21 \cdot  2s - 2  -  1.

34

We have

Also

21 \cdot  2s - 2  -  1 < 24 \cdot  2s - 2 = 6 \cdot  2s.

21 \cdot  2s - 2 = 42 \cdot  2s - 3 = 41 \cdot  2s - 3 + 2s - 3 = d(s) + 2s - 3,

then the proof is complete.

3.3.6 The width estimations of the Jacobi method for the general

case

Remark 12. The width formula of the algorithm \scrJ  from Proposition 3 is rather
complicated and not always convenient for computations. At the same time,
the width formula of the algorithm \scrJ  from Proposition 4 is more suitable for
computations. We will try to obtain the width estimations for the algorithm
\scrJ  for the general case using the formula from Proposition 4. By Lemma 7 and
Table 1 (p. 25) we can consider the case KJ \geq  257.

So, we fix the integer s such that

2s - 1 < KJ < 2s

for the suitable s \geq  9.
Then by Lemma 8

P\scrJ  (2s - 1) < P\scrJ  (KJ) < P\scrJ  (2s).

Lemma 12. Suppose that KJ = 2s - 1 \geq  28. Also

s \equiv  r

(mod 5) for the suitable r \in  \{  - 2,  - 1, 0, 1, 2\} .

Under performing the Q-effective implementation of the algorithm \scrJ  , the com-
putation of v1 stops at the stage

p = 2 +

p  -  1 = 1 +

s  -  r
5
s  -  r
5

= 2 +

= 1 +

\Bigr] 

\Bigr] 

\Bigl[  s
5
\Bigl[  s
5

for r \in  \{  - 1, 0, 1, 2\} ;

for r =  - 2.

If r \in  \{  - 1, 0, 1, 2\} , then on the first nesting level of stage p we have

P (2s - 1, p) = 5 \cdot  2s - 1 + 21+r \cdot 

2s - r  -  1
31

operations.

In the case r =  - 2, then on the first nesting level of stage p  -  1 we have

P (2s - 1, p  -  1) = 5 \cdot  2s - 1 + 24 \cdot 

2s - 3  -  1
31

operations.

Proof. We should consider the stopping criterion when KJ = 2s - 1. By Lemma
11,

s  -  1 = 5(q  -  2) + t for q = 2 +

and t \in  \{  - 2,  - 1, 0, 1, 2\} .

\biggr] 

\biggl[  s  -  1
5

35

Hence,

Since

then

5(q  -  2) + t + 1 = s = 5(p  -  2) + r \Leftarrow \Rightarrow  t + 1  -  r = 5(p  -  q).

 - 2 + 1  -  2 \leq  t + 1  -  r \leq  2 + 1 + 2 \Leftarrow \Rightarrow   - 3 \leq  t + 1  -  r \leq  5,

More exactly,

t + 1  -  r \in  \{ 0, 5\} .

t = r  -  1 and q = p for r \in  \{  - 1, 0, 1, 2\} ;

t = 2 and q = p  -  1 for r =  - 2.

So, we obtain two cases.

q = p. By the equality (18)

P (2s - 1, p) = 5 \cdot  2s - 1 + 2(s - 1)+12 - 5q \cdot 

= 5 \cdot  2s - 1 + 2s+11 - 5p \cdot 

= 5 \cdot  2s - 1 + 2s+11 - s - 10+r \cdot 

=

25q - 10  -  1
31
25p - 10  -  1
31
2s+10 - r - 10  -  1
31

=

=

= 5 \cdot  2s - 1 + 21+r \cdot 

2s - r  -  1
31

.

q = p  -  1. In this case r =  - 2 and t = 2, and by the equality (18) we obtain

P (2s - 1, p  -  1) = 5 \cdot  2s - 1 + 22+2 \cdot 

2(s - 1) - 2  -  1
31

= 5 \cdot  2s - 1 + 24 \cdot 

2s - 3  -  1
31

.

Lemma 13. Suppose that

s \equiv  r

p = 2 +

(mod 5) for the suitable r \in  \{  - 2,  - 1, 0, 1, 2\} ,
s  -  r
5

\Bigl[  s
5

= 2 +

\Bigr] 

.

If r \in  \{  - 1, 0, 1, 2\} , then

P (2s, p)  -  P (2s - 1, p) = 5 \cdot  2s - 1 + 21+r \cdot 

2s - r  -  1
31

.

In the case r =  - 2, we have on the first nesting level of stage p  -  1

P (2s, p)  -  P (2s - 1, p  -  1) = 5 \cdot  2s - 1 + 24 \cdot 

2s - 3  -  1
31

.

36

Proof. Let r \in  \{  - 1, 0, 1, 2\} . By the equality (18) and Lemma 12 we get

P (2s, p)  -  P (2s - 1, p  -  1) = 5 \cdot  2s + 22+r \cdot 

2s - r  -  1
31

 - 

 -  5 \cdot  2s - 1  -  21+r \cdot 

=

2s - r  -  1
31
2s - r  -  1
31

= 5 \cdot  2s - 1 + (22+r  -  21+r)

=

Moreover, we can compute more exactly

= 5 \cdot  2s - 1 + 21+r \cdot 

2s - r  -  1
31

.

P (2s, p)  -  P (2s - 1, p) = 5 \cdot  2s - 1 +

\left\{ 

8 \cdot 

4 \cdot 

2 \cdot 

2s - 2  -  1
31
2s - 1  -  1
31
2s  -  1
31

2s+1  -  1
31

if r = 2;

if r = 1;

if r = 0;

if r =  - 1.

If r =  - 2, then

P (2s, p)  -  P (2s - 1, p  -  1) = 5 \cdot  2s + 20 \cdot 

2s+2  -  1
31

 -  5 \cdot  2s - 1  -  24 \cdot 

2s - 3  -  1
31

=

= 5 \cdot  2s - 1 +

= 5 \cdot  2s - 1 +

= 5 \cdot  2s - 1 +

2s+2  -  1  -  2s+1 + 16
31

=

2s+1 + 15
31

=

16 \cdot  (2s - 3  -  1) + 31
31
2s - 3  -  1
31

.

=

= 5 \cdot  2s - 1 + 1 + 16 \cdot 

Lemma 14. Suppose that

s \equiv  r

(mod 5) for the suitable r \in  \{  - 2,  - 1, 0, 1, 2\} ,
s  -  r
5
d(s  -  1) = 41 \cdot  2s - 4 (cf. Corollary 3).

p = 2 +

\Bigl[  s
5

= 2 +

\Bigr] 

,

If r \in  \{  - 1, 0, 1, 2\} , then

41 \cdot  2s - 4 < P (2s - 1, p)  -  P (2s - 1, p) < 21 \cdot  2s - 3  -  21+r \leq 

\leq  21 \cdot  2s - 3  -  1 < 6 \cdot  2s - 1 \Leftarrow \Rightarrow 

\Leftarrow \Rightarrow  d(s  -  1) < P (2s - 1, p)  -  P (2s - 1, p) < d(s  -  1) + 2s - 4  -  21+r.

In the case r =  - 2, we have on the first nesting level of stage p  -  1

41 \cdot  2s - 4 < P (2s, p)  -  P (2s - 1, p  -  1) < 21 \cdot  2s - 3  -  16 \Leftarrow \Rightarrow 
\Leftarrow \Rightarrow  d(s  -  1) < P (2s - 1, p)  -  P (2s - 1, p) < d(s  -  1) + 2s - 4  -  16.

37

          
          
Proof. Let r \in  \{  - 1, 0, 1, 2\} . By the inequality (20) from Corollary 3 and Lemma
13

5\cdot 2s - 1+21+r\cdot 2s - r - 5 < P (2s - 1, p) - P (2s - 1, p) < 5\cdot 2s - 1+21+r\cdot (2s - r - 4 - 1) \Leftarrow \Rightarrow 
\Leftarrow \Rightarrow  5 \cdot  2s - 1 + 2s - 4 < P (2s - 1, p)  -  P (2s - 1, p) < 5 \cdot  2s - 1 + 2s - 3  -  21+r \Leftarrow \Rightarrow 
\Leftarrow \Rightarrow  2s - 4(5 \cdot  23 + 1) < P (2s - 1, p)  -  P (2s - 1, p) < 2s - 3(5 \cdot  22 + 1)  -  21+r \Leftarrow \Rightarrow 
\Leftarrow \Rightarrow  41 \cdot  2s - 4 < P (2s - 1, p)  -  P (2s - 1, p) < 21 \cdot  2s - 3  -  21+r \leq  21 \cdot  2s - 3  -  1.

Also

21 \cdot  2s - 3  -  1 < 24 \cdot  \cdot 2s - 3 = 6 \cdot  2s - 1.

In the case r =  - 2, we obtain by the inequality (20) and Lemma 13

5\cdot 2s - 1 +24 \cdot 2s - 3 - 5 < P (2s, p) - P (2s - 1, p - 1) < 5\cdot 2s - 1 +24(2s - 3 - 4  - 1) \Leftarrow \Rightarrow 
5 \cdot  2s - 1 + 2s - 4 < P (2s, p)  -  P (2s - 1, p  -  1) < 5 \cdot  2s - 1 + 2s - 3  -  16 \Leftarrow \Rightarrow 

41 \cdot  2s - 4 < P (2s, p)  -  P (2s - 1, p  -  1) < 21 \cdot  2s - 3  -  16.

Proposition 5. Let s \geq  9 be the integer such that

2s - 1 < KJ < 2s.

Also, suppose that

s \equiv  r

(mod 5) for the suitable r \in  \{  - 2,  - 1, 0, 1, 2\} ,
s  -  r
5
d(s  -  1) = 41 \cdot  2s - 4 (cf. Corollary 3).

p = 2 +

\Bigl[  s
5

= 2 +

\Bigr] 

,

Let r \in  \{  - 1, 0, 1, 2\} . Then

P (2s - 1, p) = 5 \cdot  2s - 1 + 21+r \cdot 

2s - r  -  1
31

< P\scrJ  (KJ) <

< 5 \cdot  2s + 22+r \cdot 

2s - r  -  1
31

= P (2s, p),

in addition,

P (2s, p)  -  P (2s - 1, p) = 5 \cdot  2s - 1 + 21+r \cdot 

2s - r  -  1
31

,

41 \cdot  2s - 4 < P (2s - 1, p)  -  P (2s - 1, p) <
< 21 \cdot  2s - 3  -  21+r \leq  21 \cdot  2s - 3  -  1 < 6 \cdot  2s - 1 \Leftarrow \Rightarrow 
\Leftarrow \Rightarrow  d(s  -  1) < P (2s - 1, p)  -  P (2s - 1, p) < d(s  -  1) + 2s - 4  -  21+r.

In the case r =  - 2, we have

P (2s - 1, p  -  1)=5 \cdot  2s - 1 +

2s+1  -  16
31

< P\scrJ  (KJ) < 5 \cdot  2s +

2s+2  -  1
31

=P (2s, p),

38

in addition,

P (2s, p)  -  P (2s - 1, p  -  1) = 5 \cdot  2s - 1 + 24 \cdot 

2s - 3  -  1
31

,

41 \cdot  2s - 4 < P (2s - 1, p)  -  P (2s - 1, p) < 21 \cdot  2s - 3  -  16 < 6 \cdot  2s - 1 \Leftarrow \Rightarrow 
\Leftarrow \Rightarrow  d(s  -  1) < P (2s - 1, p)  -  P (2s - 1, p) < d(s  -  1) + 2s - 4  -  16.

Proof. The statement of Proposition is hold by Lemmas 8, 12--14.

3.4 Final Theorem

Theorem 2. Suppose that \scrS  (the scalar product), \scrG  (the Gauss--Jordan) and
\scrJ  (the Jacobi) are previously analyzed algorithms.

1. The Q-effective implementation of each algorithm \scrS , \scrG , and \scrJ  is realiz-

able.

2. For the height and width of these algorithms, we have the following.

Scalar Product. For the algorithm \scrS 

D\scrS  = \lceil log n\rceil  + 1 and P\scrS  = n.

Gauss--Jordan. For the described algorithm \scrG 

D\scrG  = 3n and P\scrG  \geq 

3
2

(n + 1)!

for n \geq  2.

Jacobi. For the described algorithm \scrJ 

D\scrJ  = 5n0 + 3 + \lceil log KJ\rceil  if n0 such that the value of vn0 is true.

If KJ \in  \{ 1, 2, . . . , 255\} , then the width of \scrJ  is equal to

P\scrJ  = 5KJ + \lfloor KJ/8\rfloor .

If KJ \geq  256, then for a suitable p \geq  4 we have

KJ = a + 8b0 + (8 \times  32)b1 + \cdot  \cdot  \cdot  + (8 \times  32p - 3)bp - 3,

where a \in  \{ 0, . . . , 7\} , bi \in  \{ 0, . . . , 31\}  for every i \in  \{ 0, 1, . . . , p  -  4\} ,
and bp - 3 \in  \{ 1, 2, . . . , 31\} . Then the width of the algorithm \scrJ  is equal
to

P\scrJ  = 5 \cdot  KJ + c0 + c1 + \cdot  \cdot  \cdot  + cp - 3,

where for every i \in  \{ 0, 1, . . . , p  -  3\} 

ci = bi + 32bi+1 + \cdot  \cdot  \cdot  + 32p - 3 - ibp - 3.

Proof. It follows from Propositions 1, 2, and 3, Lemmas 4 and 7.

Remark 13. Note that for the algorithm \scrJ  , the case KJ = 2s is considered in
3.3.5. In this case, we obtain a simpler value for the width of the algorithm \scrJ  .
Furthermore, in 3.3.6 we estimate the width of the algorithm \scrJ  from the width
values for powers of 2, see Proposition 5. It seems to us that these results can
be very useful for estimating the width behavior for large KJ.

39

4 The Q-system

In this section, we describe the development of a software system, called the
Q-system, to study the parallelism resources of numerical algorithms that can
be computed and compared.

4.1 Theoretical foundation of the Q-system

The concept of a Q-determinant makes it possible to use the following methods
for studying the parallelism resource of numerical algorithms.

1. A method for constructing the Q-determinant of the algorithm.

2. A method of obtaining the Q-effective implementation of the algorithm.

3. A method for computing the characteristics of the parallelism resource of

the algorithm.

4. A method for comparing the characteristics of the parallelism resource of

algorithms.

4.1.1 A method of constructing the Q-determinant of the algorithm

Flowcharts of algorithms are well known and often used. Here we construct the
Q-determinants of the algorithms using flowcharts of the algorithms.

We use the following blocks of the flowchart.

1. Terminal. It displays input from the external environment or output to

the external environment.

2. Decision.

It displays a switching type function that has one input and
several alternative outputs, one and only one of which can be activated
after computing the condition defined in the block.

3. Process. It displays a data processing function.

4. Data.

Limitations and Clarifications. There are some limitations and clarifica-
tions for the used flowcharts. The flowchart has two terminal blocks, one
of which is ``Start"" means the beginning of the algorithm, and the other
``End"" is the end of the algorithm. The ``Start"" block has one outgoing
flowline and has no incoming flowline. The ``End"" block has one incoming
flowline and no outgoing flowline. The ``decision"" block has two outgoing
flowlines, one of which corresponds to the transfer of control if the block
condition is true, and the other if it is false. The condition uses one com-
parison operation. Its operands don't contain operations. The ``process""
block contains one assignment of a variable value. There is no more than
one operation to the right of the assignment sign. So, block chains are
used for groups of operations. We divide the ``data"" blocks into the blocks
``Input data"" and ``Output data"".

40

Construction of the Q-determinant. To construct the Q-determinant of
the algorithm, we analyze the flowchart for fixed values of the dimension
parameters of the algorithmic problem \=N = \{ \=n1, . . . , \=nk\}  if N \not = \emptyset . We
investigate the features of the algorithms in which the Q-determinants
contain various types of Q-terms.

If the Q-determinant of the algorithm has unconditional Q-terms, then
the passage through the flowchart should be carried out sequentially in
accordance with the execution of the algorithm.
For every i \in  U expressions wi if N = \emptyset  and wi( \=N ) if N \not = \emptyset  are obtained
as values of unconditional Q-terms fi (cf. (4)). They are formed using
the contents of the ``process"" blocks involved in the computation of fi for
every i \in  U .

Suppose that the Q-determinant contains conditional Q-terms. The pas-
sage through the block ``decision"" with a condition on the input data
generates a branching.

j, wi
j if N = \emptyset  and ui

Then each branch is processed separately. As a result of processing one
branch, for every i \in  C and suitable j \in  \{ 1, . . . , l(i)\}  we obtain the pairs
of expressions (ui

j( \=N )) if N \not = \emptyset  (cf. (4)).

j) if N = \emptyset  and (ui

j( \=N ), wi

j, wi

j if N = \emptyset  and wi

j( \=N ) if N \not = \emptyset  are obtained by the condi-
The expressions ui
tions of the ``decision"" blocks that contain the input data. The expressions
j( \=N ) if N \not = \emptyset  are formed using the contents of the
wi
``process"" blocks. As soon as the first branch is processed, the flowchart
handler returns to the nearest block, where the branching occurred and
continues processing with the opposite condition. After all branches are
processed, for all i \in  C and j \in  \{ 1, . . . , l(i)\}  we obtain the pairs of expres-
j( \=N )) if N \not = \emptyset  for all conditional
j( \=N ), wi
sions (ui
Q-terms fi, where i \in  C (cf. (4)).
Conditional infinite Q-terms are contained in the Q-determinants of iter-
ative numerical algorithms. By limiting the number of iterations, we can
reduce the case of the Q-determinant with conditional infinite Q-terms to
the case of the Q-determinant with conditional Q-terms. We will use the
parameter L for the number of iterations. This parameter can take any
integer positive values. We denote the value of the parameter L by \=L.
The value \=L determines the length of the Q-terms fi for every i \in  I.

j) if N = \emptyset  and (ui

4.1.2 A method of obtaining the Q-effective implementation of the

algorithm

By the Q-effective implementation of the algorithm, we mean the simultaneous
computation of the expressions W if N = \emptyset  (cf. (5)) and the expressions W ( \=N )
if N \not = \emptyset  (cf. (6)) and operations are executed as soon as their operands are
computed.

If N = \emptyset  and I \not = \emptyset , then instead of the expressions W we use the expressions

W ( \=L) = \bigl\{ wi(i \in  U ); ui

j, wi

j(i \in  C, j \in  \{ 1, . . . , l(i)\} );

j, wi
ui

j(i \in  I, j \in  \{ 1, . . . , \=L\} )\bigr\} .

(21)

41

If N \not = \emptyset  and I \not = \emptyset , then in place of the expressions W ( \=N ) we use the expressions

W ( \=N , \=L) = \bigl\{ wi( \=N )(i \in  U ); ui

j( \=N )(i \in  C, j \in  \{ 1, . . . , l(i)\} );

j( \=N ), wi
j( \=N ), wi
ui

j( \=N )(i \in  I, j \in  \{ 1, . . . , \=L\} )\bigr\} .

(22)

The method of obtaining the Q-effective implementation of the algorithm is to
compute the nesting levels of the operations included in the expressions:

1. W if N = \emptyset  and I = \emptyset ;

2. W ( \=L) if N = \emptyset  and I \not = \emptyset ;

3. W ( \=N ) if N \not = \emptyset  and I = \emptyset ;

4. W ( \=N , \=L) if N \not = \emptyset  and I \not = \emptyset .

4.1.3 A method for computing the characteristics of the parallelism

resource of the algorithm

Computation of the parallelism resource characteristics of the algorithm \scrA  is
performed according to the following rules.

1. If N = \emptyset  and I = \emptyset , then the height and width of the algorithm \scrA  are
independent of the parameters N and L. The height of the algorithm is
denoted by D\scrA  and is computed by the formula (7). The width of the
algorithm is denoted by P\scrA  and is computed by the formula (8).

2. If N = \emptyset  and I \not = \emptyset , then the height and width of the algorithm \scrA  depend
on the parameter L. The value of the algorithm height is denoted by
D\scrA ( \=L) and is computed by the formula

D\scrA ( \=L) = max
w\in W ( \=L)

T w.

(23)

The value of the algorithm width is denoted by P\scrA ( \=L) and is computed
by the formula

P\scrA ( \=L) = max

1\leq r\leq D\scrA ( \=L)

\sum 

Ow
r

w\in W ( \=L)

(24)

r is the number of operations of the nesting level r of the expression

if Ow
w.

3. If N \not = \emptyset  and I = \emptyset , then the height and width of the algorithm \scrA  depend
on the parameters of N . The value of the algorithm height is denoted by
D\scrA ( \=N ) and is computed by the formula (9). The value of the algorithm
width is denoted by P\scrA ( \=N ) and is computed by the formula (10).

4. If N \not = \emptyset  and I \not = \emptyset , then the height and width of the algorithm \scrA  depend
on the parameters N and L. The value of the algorithm height is denoted
by D\scrA ( \=N , \=L) and is computed by the formula

D\scrA ( \=N , \=L) =

max
w( \=N )\in W ( \=N , \=L)

T w( \=N ).

(25)

42

The value of the algorithm width is denoted by P\scrA ( \=N , \=L) and is computed
by the formula

P\scrA ( \=N , \=L) =

max
1\leq r\leq D\scrA ( \=N , \=L)

\sum 

Ow( \=N )
r

w( \=N )\in W ( \=N , \=L)

(26)

if Ow( \=N )
r
w( \=N ).

is the number of operations of the nesting level r of the expression

4.1.4 A method for comparing the characteristics of the parallelism

resource of algorithms

Suppose that the algorithms \scrA  and \scrB  solve the same algorithmic problem. This
method compares the height and width of the algorithms \scrA  and \scrB  if the algo-
rithms satisfy one of the following four sets of conditions.

N = \emptyset  and I = \emptyset . The values D\scrA , P\scrA , D\scrB , and P\scrB  are defined.
N = \emptyset  and I \not = \emptyset . The values of D\scrA ( \=L) and P\scrA ( \=L) are defined if \=L is an element
of some set V\scrA (L). The values of D\scrB ( \=L) and P\scrB ( \=L) are defined if \=L is an
element of some set V\scrB (L). Besides, V\scrA (L) \cap  V\scrB (L) \not = \emptyset .

N \not = \emptyset  and I = \emptyset . The values of D\scrA ( \=N ) and P\scrA ( \=N ) are defined if \=N is an ele-
ment of some set V\scrA (N ). The values of D\scrB ( \=N ) and P\scrB ( \=N ) are defined if
\=N is an element of some set V\scrB (N ). Besides, V\scrA (N ) \cap  V\scrB (N ) \not = \emptyset .
N \not = \emptyset  and I \not = \emptyset . The values of D\scrA ( \=N , \=L) and P\scrA ( \=N , \=L) are defined if ( \=N , \=L)
is an element of some set V\scrA (N, L). The values of D\scrB ( \=N , \=L) and P\scrB ( \=N , \=L)
are defined if ( \=N , \=L) is an element of some set V\scrB (N, L). Besides,
V\scrA (N, L) \cap  V\scrB (N, L) \not = \emptyset .

By this method, we can perform the following computations.

N = \emptyset  and I = \emptyset . We find

\Delta D = D\scrA   -  D\scrB ,
\Delta P = P\scrA   -  P\scrB .

N = \emptyset  and I \not = \emptyset . We get

\Delta D =

\Delta P =

\sum 

(D\scrA ( \=L)  -  D\scrB ( \=L)),

\=L\in (V\scrA (L)\cap V\scrB (L))
\sum 

(P\scrA ( \=L)  -  P\scrB ( \=L)).

\=L\in (V\scrA (L)\cap V\scrB (L))

N \not = \emptyset  and I = \emptyset . We find

\Delta D =

\Delta P =

\sum 

(D\scrA ( \=N )  -  D\scrB ( \=N )),

(P\scrA ( \=N )  -  P\scrB ( \=N )).

\=N \in (V\scrA (N )\cap V\scrB (N ))
\sum 

\=N \in (V\scrA (N )\cap V\scrB (N ))

43

N \not = \emptyset  and I \not = \emptyset . Finally,

\Delta D =

\Delta P =

\sum 

(D\scrA ( \=N , \=L)  -  D\scrB ( \=N , \=L)),

( \=N , \=L)\in (V\scrA (N,L)\cap V\scrB (N,L))
\sum 

( \=N , \=L)\in (V\scrA (N,L)\cap V\scrB (N,L))

(P\scrA ( \=N , \=L)  -  P\scrB ( \=N , \=L)).

As a result, we can make the following conclusions.

\Delta D < 0. Then the height of the algorithm \scrA  is less than the height of the

algorithm \scrB .

\Delta D = 0. Then the algorithms \scrA  and \scrB  have the same height.

\Delta D > 0. Then the height of the algorithm \scrA  is greater than the height of the

algorithm \scrB .

\Delta P < 0. Then the width of the algorithm \scrA  is less than the width of the algo-

rithm \scrB .

\Delta P = 0. Then the algorithms \scrA  and \scrB  have the same width.

\Delta P > 0. Then the width of the algorithm \scrA  is greater than the width of the

algorithm \scrB .

4.2 A software implementation of the Q-system

The Q-system consists of two subsystems: for generating the Q-determinants
of numerical algorithms and for computing the parallelism resources of numer-
ical algorithms. The first subsystem realizes a method for constructing the
Q-determinant of an algorithm based on its flowchart. Other methods for study-
ing the parallelism resource of numerical algorithms are realized in the second
subsystem.

4.2.1 Subsystem for generating the Q-determinants of numerical al-

gorithms

This subsystem is .NET application in object-oriented programming language
C\#. Microsoft Visual Studio was used as a development environment. We used
the data-interchange format JSON to describe the input and output data of the
subsystem. In accordance with the JSON format, the flowchart is a description
of the Vertices blocks and the Edges connections. The Vertices blocks are identi-
fied by the number Id, the type Type and the text content Content. Type values
of blocks Vertices:

(0) 0 is block ``Start"",

1. 1 is block ``End"",

2. 2 is block ``process"",

3. 3 is block ``decision"",

4. 4 is block ``Input data"",

44

5. 5 is block ``Output data"".

The Edges connectors are determined by the numbers of the starting From and
ending To blocks and the type of connector Type. The Type values of connectors
Edges are the following:

(0) 0 is pass by condition ``false"",

1. 1 is pass by condition ``true"",

2. 2 is normal connection.

In Fig. 1 there is a flowchart in the JSON format of an algorithm that
implements the Gauss--Seidel method for solving systems of linear equations. We
use the following notation in this flowchart: A is a coefficient matrix of a system
of linear equations, X is an unknown column, B is a column of constant terms,
X0 is an initial approximation, e is an accuracy of computations, iterations is a
restriction on the number of iterations.

Output File

j, wi

j( \=N ), wi

j) if N = \emptyset  or (ui

j is an unconditional Q-term. The expressions ui

Let us describe the structure of the output file of this subsystem. For every i \in  C
a conditional Q-term fi (cf. (4)) determines l(i) lines of the file, where l(i) is the
length of the Q-term. Each of these lines contains the identifier of the output
variable computed using this Q-term, an equal sign, and one pair of expressions
j( \=N )) if N \not = \emptyset  for some j \in  \{ 1, . . . , l(i)\} . Here,
(ui
for every j \in  \{ 1, . . . , l(i)\}  Q-terms, such that ui
j is an unconditional logical
Q-term, and wi
j if N = \emptyset ,
j( \=N ) if N \not = \emptyset  are described in the JSON format and separated
j( \=N ), wi
or ui
by semicolons. The description of the conditional infinite Q-term is similar to
the description of the conditional Q-term, since the length of the conditional
infinite Q-term is limited by the value of the parameter L. For every i \in  U an
unconditional Q-term fi (cf. (4)) determines one line of the file. In this case,
there is no logical Q-term, so a space is used instead. Thus, the output file
contains the representation of the algorithm in the form of a Q-determinant for
fixed parameters of dimension N and a limited number of iterations L.

j, wi

In Fig. 2 there is the output file for one iteration of the Gauss--Seidel method
if a matrix A is of order 2. The following notation is used for description of
expressions in the JSON format: op is an operation, fO is the first operand
(firstOperand), sO is the second operand (secondOperand), od is the operand.

All variables in the flowchart are divided into four categories:

1. dimension parameters of an algorithmic problem,

2. input,

3. output,

4. internal variables that don't belong to the first three categories.

For example, we have the following categories for the flowchart in Fig. 1:

first category is n;

45

Figure 1: The flowchart in the JSON format of an algorithm that implements
the Gauss--Seidel method

second category are the variables \{ A(i, j), B(i), X0(i) |  i, j \in  \{ 1, . . . , n\} \} , e,

iterations;

third category are the variables X(i) for all i \in  \{ 1, . . . , n\} ;

fourth category are the variables it, i, newX(i) for all i \in  \{ 1, . . . , n\} , j, D,

norm.

Further, we describe the work process for each of the categories of variables.

Each of the categories of variables is stored in its own collection.

46

Figure 2: The output file of the subsystem for generating the Q-determinants
of numerical algorithms for the Gauss--Seidel method

First category. The user inputs the values of the variables of the first category

on request of the program.

The collection of dimension parameters stores the following pair for every
dimension parameter: the identifier of dimension parameter and its value.

Second category. All variables of the second category, with the exception of
the variable iterations, have no values, since the program constructs the
Q-determinants depending on the identifiers of the input variables. To
limit the number of iterations, the variable iterations is used, and the user
inputs its value on request of the program. This value is assigned to the
variable static int iterations.

The collection of input variables contains the identifiers of input variables.

Third and fourth categories. The values of the variables of the third and

fourth categories change when processing the flowchart.

The output and internal variable collections store the following pair for
every such variable: the variable identifier and its value.

Now let's move on to processing blocks of the flowchart according to the

JSON format (p. 44).

We do several steps.

First. We are looking for blocks of type 4. These blocks include the identifiers
of input variables and the dimension parameters of the algorithmic prob-
lem. The identifiers of the dimension parameters are enclosed in square
brackets and separated by commas (see. Fig. 1). They are extracted from
blocks of type 4, and the user is prompted to input their values. The
identifier of the dimension parameter and the entered value are written to
the dimension parameters collection. Also the identifiers of input variables
are extracted from blocks of type 4. Indices are added to the identifiers
if input variables depend on the dimension parameters. The resulting in-
put variables are written to the collection of input variables. If there is

47

an identifier iterations, then the user is prompted to input the number of
iterations.

The identifiers of output variables are extracted from blocks of type 5.
Indices are added to the identifiers if output variables depend on the di-
mension parameters. The resulting output variables and their values 0 of
type string are written to the output variable collection.

For example, suppose the user inputs the value of the dimension parameter
n = 2 under processing a flowchart of an algorithm that implements the
Gauss--Seidel method (see. Fig. 1). Then a pair of (n, 2) will be written
to the collection of dimension parameters. The variables A(i, j), B(i),
X0(i) for all i, j \in  \{ 1, 2\} , e, iterations will be written to the collection of
input variables. The pairs (X(1), 0) and (X(2), 0) will be written to the
collection of output variables.

Passage from 0-block to 1-block. After that we pass from a block with type
0 to a block with type 1 along the flowchart. The description of the
flowchart determines the order of passing blocks. Blocks of types 2 and 3
are processed during the passage.

Processing 2-block. First, we analyze the right-hand side of the assignment
operator when processing a block of type 2. The following options are
possible: a number, a variable of any category with or without indexes, a
unary or binary operation.

If there is an operation, then the operands are analyzed. The following
options are possible for operands: a number, a variable of any category
with or without indices. We compute the values of all available indices
and determine the category of variables.

Further, we determine the indices values of the variable to the left of
the assignment operator, depending on their availability. Then we should
determine the category of the obtained variable. A variable can be either
output or internal. It is also possible that the variable does not belong to
any category. In this case, we consider it as a new internal variable.

The result of the analysis of a block with type 2 is to compute the value
to the right of the assignment operator and write it to the directory as the
value of the variable to the left of the assignment operator. If the value
to the right of the assignment operator depends on input variables, then
it is formed as an expression in the JSON format. In this case, we use
the same format as the format of expression description in the output file
(see. Fig. 2). After passing through the flowchart, the output variable
identifiers and the corresponding unconditional Q-terms will be in the
output variables catalog.

Processing 3-block. When processing a block of type 3, the comparison op-
eration and each operand are determined. The following options for
operands are possible: number, variable of any category with or with-
out indexes. We compute the values of all obtained indices and determine
the category of variables.
If the condition has no input variables, then
it is computed and control is transferred to the next block depending on
the computed value of 1 (true), or 0 (false). Suppose that the condition

48

contains input variables. Then, at the first pass through the block, the
control is transferred to the next block by the value of 1. Also, during
the second pass through the block, the control is transferred to the next
block by the value of 0. Let's say we don't have an input variable iter-
ations. Under the transfer of the control by the value of 1, we add the
condition as a conjunctive term to the resulting logical Q-term. Under
the transfer of the control by the value of 0, we add the negation of the
condition as a conjunctive term to the resulting logical Q-term.
If the
input variable iterations exists, then the logical Q-term is formed from the
condition of the last 3-block with input variables only without taking into
account iterations.

Branching. It arises if we have blocks of type 3 with input variables in the
conditions. We process one branch in one pass along the flowchart. After
processing the branch, the identifiers of output variables and the corre-
sponding pairs of expressions

(ui

j, wi

j) (i \in  C \cup  I) if N = \emptyset  or (ui

j( \=N ), wi

j( \=N )) (i \in  C \cup  I) if N \not = \emptyset 

for some j \in  \{ 1, . . . , l(i)\}  are written to the output file, as shown in Fig. 2.
In practice, sometimes we have to cancel the output of the processing
branch results in the output file. To implement this feature, the internal
variable empout is used. By default, the value of the variable empout is
set to 1, and it is assigned the value 0 in case if it is necessary to cancel
the output to the output file.

Exhaustion of branches. Now we describe the procedure for exhausting branches.
A branch is determined by a sequence of 3-blocks with conditions contain-
ing input variables, as well as ways to exit blocks by the value of 1 or 0.
The branch collection stores information about processed branches. After
processing the next branch, the collection stores the sequence of pairs, con-
sisting of Id branch block numbers and output values from 1 or 0 blocks.
The pairs in the collection are followed in order of processing the blocks.
If we have the first pass through the flowchart, then we record information
concerning the first processed branch. Suppose that the last pair in the
branch collection has an output value of 1 from the block. Then we change
this value to 0 and get a new pair P . Otherwise, we delete the pairs with
the output value 0 from the last to the pair with the exit from the block
equal to 1. Deletion ends when there are either no such pairs or a block
with an output value of 1 is found. If all pairs are deleted, it means that
all branches are processed. In this case, the processing of the flowchart is
completed. If the collection is not empty, then the last pair has a block
with an output value of 1. We change this value to 0 and get a new pair P .
Now the new branch appears as a subsequence of pairs of the processed
branch ending in P and its extension according to the flowchart. As a
result, new items can be written to the branch collection after the pair P .

4.2.2 The subsystem for computing the parallelism resource of nu-

merical algorithms

The subsystem includes a database, server and client applications.

49

To develop the database, the database management system PostgreSQL was

used. The database contains two entities: Algorithms and Determinants.

Entity Algorithms has the following attributes.

1. A primary key, i.e., an algorithm identifier.

2. An algorithm name.

3. Algorithm description.

4. The number of Q-determinants loaded into the database and corre-

sponding to different values of the parameters N and L.

Entity Determinants has the following attributes.

1. A primary key, i.e., an identifier of the Q-determinant.

2. An unique algorithm identifier.

3. Values of dimension parameters N if N \not = \emptyset , otherwise 0.

4. The Q-determinant according to (5), (21), (6), and (22), where

(5) if N = \emptyset  and I = \emptyset ;
(21) if N = \emptyset  and I \not = \emptyset ;
(6) if N \not = \emptyset  and I = \emptyset ;
(22) if N \not = \emptyset  and I \not = \emptyset .

5. The value of D\scrA  according to (7), (23), (9), and (25), where

(7) if N = \emptyset  and I = \emptyset ,
(23) if N = \emptyset  and I \not = \emptyset ,
(9) if N \not = \emptyset  and I = \emptyset ,
(25) if N \not = \emptyset  and I \not = \emptyset .

6. The value of P\scrA  according to (8), (24), (10), and (26), where

(8) if N = \emptyset  and I = \emptyset ,
(24) if N = \emptyset  and I \not = \emptyset ,
(10) if N \not = \emptyset  and I = \emptyset ,
(26) if N \not = \emptyset  and I \not = \emptyset .

7. The value of the parameter L (the number of iterations) if I \not = \emptyset ,

otherwise 0.

We have developed a server application for interacting with database entities.

This application implements the following methods.

1. Recording a new algorithm.

2. Updating algorithm information.

3. Obtaining a list of algorithms with complete information about them.

4. Comparing the characteristics of the parallelism resource of two algorithms

that solve the same algorithmic problem.

5. Removing an algorithm along with its Q-determinants.

50

6. Loading a new Q-determinant and computed characteristics of the paral-

lelism resource.

7. Obtaining a list of Q-determinants.

8. Downloading a Q-determinant.

9. Removing a Q-determinant.

Now we describe the process of interacting with the database.

Converting of Q-determinants for the database. The database should

contain the Q-determinant of the algorithm in the form of one of the
following sets of expressions in the JSON format:

1. W (cf. (5)) if N = \emptyset  and I = \emptyset ,
2. W ( \=L) (cf. (21)) if N = \emptyset  and I \not = \emptyset ,
3. W ( \=N ) (cf. (6)) if N \not = \emptyset  and I = \emptyset ,
4. W ( \=N , \=L) (cf. (22)) if N \not = \emptyset  and I \not = \emptyset .

We have a description of the representation of the algorithm obtained by
the subsystem for generating Q-determinants (cf. p. 45). Therefore, we
have developed special software to convert an initial description into a
format for the database.

The Q-effective implementation and the parallelism resource. Also,

we have developed and implemented an original algorithm for methods of
obtaining the Q-effective implementation of the algorithm and comput-
ing the characteristics of the parallelism resource of the algorithm. The
algorithm is as follows.

1. The input is the Q-determinant of the algorithm \scrA  as a set of ex-

pressions.

2. Then we transform the Q-determinant into a special data structure.

3. When creating this data structure, we get an array of lists.

4. The number of array lists is equal to the number of nesting levels
of all operations of the set of expressions of the Q-determinant. (cf.
p. 51).

5. All operations of one nesting level are contained in one list.

Creating a special data structure is performed as follows.

1. For numbers and variables, the algorithm returns an empty array.

2. If the array of the operand of the unary operation is obtained, the
algorithm adds a new list to this array containing this unary opera-
tion.

3. If arrays of operands of a binary operation are obtained, then the
algorithm joins these arrays into one array and adds a new list to it
containing this binary operation.

51

4. The algorithm get its own array of lists for each expression of the
set of expressions of the Q-determinant. After that, the algorithm
joins the arrays of all expressions of the set of expressions of the
Q-determinant into one array.

Here, the join of arrays is getting a single array of lists, in which each list is
formed as a result of combining lists of source arrays containing operations
of the same nesting level. The resulting array of lists gives an idea of the
execution plan of the Q-effective implementation of the algorithm, namely,
points out the order of operations. In this case, the value of D\scrA  is equal
to the length of the array, and P\scrA  is equal to the size of the largest list in
the array.

Comparing the characteristics of the parallelism resource. We have

developed and implemented an original algorithm to perform a method
for comparing the parallelism resource characteristics of two algorithms.
Several Q-determinants of the algorithm can be loaded into the database.
Moreover, in the database, each Q-determinant corresponds to its set of
values of the dimension parameters \=N and the number of iterations \=L of
the algorithm. In particular, the database contains the value \=N = 0 if
N = \emptyset , and the value \=L = 0 if I = \emptyset . An algorithm for comparing the
parallelism resource characteristics of the algorithms \scrA  and \scrB  is as follows.

1. The input data is the identifiers of the algorithms \scrA  and \scrB .

2. The comparison algorithm is performed in three stages.

(i) At the first stage, the identifiers of pairs of Q-determinants of
the algorithms \scrA  and \scrB  are determined, which correspond to the
same values of \=N and \=L. First, for the algorithms \scrA  and \scrB , the
identifiers of all Q -determinants loaded into the database are
determined. Then, the algorithm finds the values \=N and \=L cor-
responding to the obtained identifiers of Q-determinants. Next,
pairs of the identifiers of the algorithms \scrA  and \scrB  are analyzed
and pairs for which the corresponding values of \=N and \=L are the
same. As a result, pairs of the identifiers of Q-determinants of
the algorithms \scrA  and \scrB  with the corresponding identical values
\=N and \=L will be obtained. The resulting pairs of the identi-
fiers of Q-determinants are written into a two-dimensional array
so that the first row of the array contains the identifiers of Q-
determinants of the algorithm \scrA , and the second row of the array
contains the identifiers of Q-determinants of the algorithm \scrB .
(ii) In the second stage, we determine the data for the comparison.
This is done as follows. We use the identifiers of Q-determinants
written in a two-dimensional array from (i). By these identi-
fiers, the attribute values are determined for comparison, that
is, the height values D\scrA ( \=N , \=L) and D\scrB ( \=N , \=L) or the width val-
ues P\scrA ( \=N , \=L) and P\scrB ( \=N , \=L). The obtained attribute values are
written to another two-dimensional array of the same size into
places corresponding to the identifiers of their Q-determinants.
(iii) The third stage finishes the comparison. If the two-dimensional
data array obtained in the second stage is empty, a message will

52

be displayed that the comparison is not possible. This situation
arises when the algorithms \scrA  and \scrB  don't have Q-determinants
in the database with the same values \=N and \=L. Otherwise, it-
erates over the columns of a two-dimensional data array. When
iterating over columns in each of the columns, the value of the
second row is subtracted from the value of the first row, and
the results are summed. The result will be a value \Delta D or \Delta P
(p. 43).

3. The obtained values of \Delta D and \Delta P allow us to make a conclusion
about the relationship between the characteristics of the parallelism
resource of the algorithms \scrA  and \scrB  (p. 44).

The Q-system is open for viewing information. Therefore, to eliminate unau-

thorized access to information editing, an authentication method was used.

Now we describe the client application. It manages the database by calling

server application methods.

The main page. This page of the client application contains the table with the
query results of all the algorithms recorded in the database. There is also
an login interface for authorized users to add, edit and delete algorithms.
Interface elements allow any user to select algorithms for comparison and
get the result of their comparison. In addition, the main page shows the
number of Q-determinants written to the database for each algorithm.

Access from the main page. Hence, we can go to the page containing the
query results for all Q-determinants for the selected algorithm.
It con-
tains for each Q-determinant the values of the dimension parameters \=N ,
the number of iterations \=L, the values of the parallelism resource character-
istics D( \=N , \=L) and P ( \=N , \=L)). The interface enables any user to download
any Q-determinant into a file. Authorized users can also use the interface
to add and remove Q-determinants.

Approximation of the parallelism resource characteristics. For this we
are developing the functionality of the Q-system for the characteristics
of the parallelism resource D( \=N , \=L) and P ( \=N , \=L). The interface uses the
sum sign (\sum ) to access the developed version of this functionality. We
also test and study the functionality of the Q-system for graphical repre-
sentation of the function obtained by approximating the characteristics of
the parallelism resource D( \=N , \=L) and P ( \=N , \=L)).

4.3 The results of the trial operation of the Q-system

The Q-system is available at

https://qclient.herokuapp.com

For the trial operation of the Q-system, we used numerical algorithms with
various structures of Q-determinants. Namely, we consider Q-determinants hav-
ing the following structures.

Q-determinants consisting of unconditional Q-terms. The following al-

gorithms have such Q-determinants.

53

1. Algorithm for computing the scalar product of vectors without using

the doubling scheme.

2. Algorithm for computing the scalar product of vectors with using the

doubling scheme.

3. Dense matrix multiplication algorithm without the doubling scheme.

4. Dense matrix multiplication algorithm with the doubling scheme.

Q-determinants consisting of conditional Q-terms. The following

algorithms have such Q-determinants.

1. An algorithm for implementing the Gauss--Jordan method for solving

systems of linear equations.

2. An algorithm for finding the maximum element in a sequence of num-

bers.

3. An algorithm for solving a quadratic equation without using the

unary negative ( - ) operation.

4. An algorithm for solving a quadratic equation using the unary neg-

ative ( - ) operation.

Q-determinants consisting of conditional infinite Q-terms. Such Q-de-
terminants have the algorithms for implementing the Gauss--Seidel and
Jacobi methods for solving systems of linear equations.

We have performed the following steps for each of the algorithms.

1. Writing the name and description of the algorithm to the database.

2. Constructing the flowchart of the algorithm subject to limitations from

4.1.1.

3. A text description of the flowchart in the JSON format.

4. Using the first subsystem of the Q-system, obtaining representations of
the algorithm in the form of a Q-determinant for several values of \=N if
N \not = \emptyset  and for several values of \=L if I \not = \emptyset . The singular representation of
the algorithm in the form of a Q-determinant was obtained when N = \emptyset 
and I = \emptyset .

5. Converting the obtained Q-determinants to the format for the database
and writing them to the database along with the corresponding values of
\=N and \=L.

6. After that, the Q-system computed and stored in the database for each
Q-determinant the values of the parallelism resource characteristics.

(a) If N = \emptyset  and I = \emptyset , then the height and width functions of the

algorithm are constants.

(b) Otherwise, the height and width functions of the algorithm are stored
in a database in a table form. In this regard, the first version of the
functionality of the Q-system for approximating the height and width
functions was developed. This enables us to estimate these functions
for different values of \=N and \=L.

54

We obtained some practical results during the trial operation of the Q-

system.

1. The Q-system shows that the height of the algorithm for implementing
the Gauss-Jordan method is 3n, where n is the matrix size of a system of
linear equations. This estimate confirms Theorem 2 (see p. 39).

2. The Q-system enables us to compare the height and width of any two
algorithms that solve the same algorithmic problem. Comparison of dense
matrix multiplication algorithms with the doubling scheme and without
the doubling scheme allows us to conclude that the width of the algorithms
is the same, but the height of the second algorithm is greater. Thus, we
can suppose that the Q-effective implementation of the algorithm with
the doubling scheme will be faster. At the same time, to execute the Q-
effective implementations of these algorithms, the same amount of com-
puter system resources (computing cores, processors) will be required.

We made a considerable number of improvements and changes to the Q-
system during its trial operation. Now we can declare the operation of the
system quite reasonable (acceptable) for further use. It can also be said that
the trial operation of the Q-system pointed the correctness of the solutions
developed for its creation. Certainly, the Q-system will be tested further.

5 A method of designing parallel programs for
the Q-effective implementations of algorithms

5.1 Method description

It is well known that the flowchart of a numerical algorithm enables us to develop
a sequential program. Similarly, we can also develop a parallel program using the
Q-determinant of a numerical algorithm. This idea is the basis of the proposed
method. We use the following arguments.

1. We can construct the Q-determinant for any numerical algorithm.

2. We can describe the Q-effective implementation of the algorithm.

3. We can immediately create the program code if the Q-effective implemen-

tation of the algorithm is realizable.

The concept model of a Q-determinant (see Section 2) are called the basic
model. This model allows us to study only machine-independent properties of
algorithms. We extend the basic model to take into account the features of im-
plementing algorithms on real parallel computing systems. A new model of the
concept of a Q-determinant is obtained by adding models of parallel computing:
PRAM [19] for shared memory and BSP [27] for distributed memory. We use
an extended model of the concept of a Q-determinant to propose a method for
designing parallel programs for the Q-effective implementations of algorithms.

The method consists of the following stages.

1. Construction of the Q-determinant of an algorithm.

55

2. Description of the Q-effective implementation of the algorithm.

3. Development of a parallel program for the realizable Q-effective imple-

mentation of the algorithm.

In the first and second stages of the method, we use the basic model of
the concept of a Q-determinant, and in the third stage, an extended model. A
program are called Q-effective if it is designed by this method. Also, the process
of designing a Q-effective program will be called Q-effective programming. A
Q-effective program uses the parallelism resource of the algorithm completely,
because it performs the Q-effective implementation of the algorithm. So, it has
the highest parallelism among programs that implement the algorithm. This
means that a Q-effective program uses more resources of a computer system
than programs that perform other implementations of the algorithm, i.e., it
is most effective. A Q-effective program can be used for parallel computing
systems with shared or distributed memory.

Development of a parallel program for the Q-effective implementation of the
algorithm is the third stage of our method. For shared memory, a description
of the Q-effective implementation of the algorithm for developing a Q-effective
program is sufficient. For distributed memory, we should add a description of
the distribution of computing between computing nodes. If we use distributed
memory, then our research is limited to the principle of ``master-slave"" [16]. For
example, this principle is often used for cluster computing systems. We describe
the principle of ``master-slave"" as follows. To compute we use one ``master""
computing node and several ``slave"" computing nodes. The node ``master"" is
denoted by M , and the set of ``slave"" nodes by S. The computational process
is divided into several supersteps.

Superstep 1 initialization. Superstep ends with barrier synchronization.

Superstep 2 each node of S receives a task for computation from the node M .

Superstep 3 each node of S performs the computation without exchange with

other nodes.

Superstep 4 all nodes of S send the computation results to the node M . Su-

perstep ends with barrier synchronization.

Superstep 5 in the node M , the computation results are combined.

Superstep 6 completion, conclusion of results.

The supersteps 2--5 can be repeated.

To develop a Q-effective program, we should use parallel programming tools.
Now OpenMP technology is most widely used for organizing parallel computing
In this study, this technol-
on multiprocessor systems with shared memory.
ogy are used in the development of Q-effective programs for shared memory
computing systems. The MPI technology is the de facto standard for parallel
programming on distributed memory. In this study, this technology are used
in the development of Q-effective programs for distributed memory computing
systems.

56

5.2 Examples of application of the method for some algo-

rithms

We show the use of this method for algorithms that have the Q-determinants
In particular, we describe the development
with Q-terms of various types.
features of Q-effective programs using distributed memory in the third stage.

5.2.1 Dense matrix multiplication algorithm with

the doubling scheme

We describe this algorithm by stages of the proposed method.

Stage 1. If we have two matrices

A = [aij]i=1,...,n
j=1,...,k

and B = [bij] i=1,...,k
j=1,...,m

,

then the result is the matrix

C = [cij] i=1,...,n
j=1,...,m

,

where for every i \in  \{ 1, . . . , n\}  and j \in  \{ 1, . . . , m\} 

cij =

k
\sum 

s=1

aisbsj.

(27)

So, the algorithm of matrix multiplication is represented in the form of
a Q-determinant. The Q-determinant consists of nm unconditional Q-
terms.

Stage 2. The Q-effective implementation of the algorithm of matrix multi-
plication is that all Q-terms \sum k
s=1 aisbsj for every i \in  \{ 1, . . . , n\}  and
j \in  \{ 1, . . . , m\}  must be computed simultaneously. Since all multiplication
operations are ready to be performed, they must be performed simulta-
neously. The result will be the chains that are formed by the addition
operation. The number of these chains is equal to nm. Each chain is
computed by the doubling scheme. Thus, the Q-effective implementation
of the algorithm is realizable.

Stage 3. We got a description of the Q-effective implementation in the second
stage. Further, we use this description to develop a Q-effective program for
shared memory. To develop a Q-effective program for distributed memory,
you need to add a description of the distribution of computing between the
computing nodes of the computing system. For this we use the principle
of ``master-slave"". Each Q-term \sum k
s=1 aisbsj for every i \in  \{ 1, . . . , n\}  and
j \in  \{ 1, . . . , m\}  is computed on a separate computational node of S. If the
number of nodes of S is less than the number of Q-terms, then nodes of
S can compute several Q-terms. The nodes of S receive information from
the node M to compute Q-terms \sum k
s=1 aisbsj for every i \in  \{ 1, . . . , n\}  and
j \in  \{ 1, . . . , m\} . The result of computing each Q-term is transmitted to
the ``master"" node M .

Examples of designing Q-effective programs for performing the matrix mul-

tiplication algorithm are described in 5.3.

57

5.2.2 The Gauss--Jordan method for solving systems of linear equa-

tions

We describe the algorithm for the Gauss--Jordan method also by stages of the
proposed method.

Stage 1. Previously, we constructed the Q-determinant of the algorithm \scrG  for
implementing the Gauss--Jordan method, see p. 15 in 3.2.1. It consists of
n conditional Q-terms of length n! and

xj = \{ (u1, wj

1), . . . , (un!, wj

n!)\}  for all j \in  \{ 1, . . . , n\} 

is a representation of the algorithm \scrG  in the form of a Q-determinant.

Stage 2. By definition of the Q-effective implementation all unconditional Q-

terms

\{ ui, wj

i \}  for every i \in  \{ 1, . . . , n!\}  and j \in  \{ 1, . . . , n\} 

should be computed simultaneously. Therefore, two computational pro-
cess should be carried out at the same time: the parallel computation
of matrices \=Aj1 , \=Aj1j2 , . . . , \=Aj1j2...jn for all possible values of the numbers
j1, j2, . . . , jn, as well as the parallel computation of Q-terms ui for ev-
ery i \in  \{ 1, . . . , n!\} . The leading elements of the matrix for each step
of the algorithm are determined by computing Q-terms ui for every i \in 
\{ 1, . . . , n!\} . The computation of matrices \=Aj1, \=Aj1j2, . . . , \=Aj1j2...jn and Q-
terms ui stops if they do not correspond to the leading elements.

The first round of computations. We begin to compute the matrices
\=Aj1 for every j1 \in  \{ 1, . . . , n\}  and Q-terms ui for every i \in  \{ 1, . . . , n!\} 
simultaneously. The computations of ui for every i \in  \{ 1, . . . , n!\}  are
started from subexpressions

Lj1 \wedge  (a1j1 \not = 0) for every j1 \in  \{ 1, . . . , n\} ,

because only their operations are ready for execution. There exists
a unique integer j1 \in  \{ 1, . . . , n\}  such that a subexpression

Lj1 \wedge  (a1j1 \not = 0)

has the value true. Let r1 be such a value of j1. Further, we finish the
computation of \=Aj1, \=Aj1j2, . . . , \=Aj1j2...jn and ui for all i \in  \{ 1, . . . , n!\} 
if j1 isn't equal to r1.

The second round of computations. We begin to compute matrices
\=Ar1j2 for every j2 \in  \{ 1, . . . , n\}  \setminus  \{ r1\}  and Q-terms ui for every i \in 
\{ 1, . . . , n!\}  with j1 = r1 simultaneously. Under the computation of
ui for every i \in  \{ 1, . . . , n!\}  with j1 = r1 we should find the values of
subexpressions

Lj2 \wedge  (ar1
2j2

\not = 0) for every j2 \in  \{ 1, . . . , n\}  \setminus  \{ r1\} ,

because only their operations are ready for execution. There exists
a unique integer j2 \in  \{ 1, . . . , n\}  \setminus  \{ r1\}  such that a subexpression

Lj2 \wedge  (ar1
2j2

\not = 0)

58

has the value true. Let r2 be such a value of j2. Further, we finish
the computation of \=Ar1j2, . . . , \=Ar1j2...jn and ui for all i \in  \{ 1, . . . , n!\} 
if j2 isn't equal to r2.

The next n  -  3 rounds of computations are executed similarly.

In conclusion we need to compute a single matrix

\=Ar1...rn - 1jn for jn /\in  \{ r1, r2, . . . , rn - 1\} ,

as the parameter jn has a single value. Let rn be such a value of jn.

The result is

xrj = ar1...rn

j,n+1 for every j \in  \{ 1, . . . , n\} ,

this is the solution to the original system of linear equations.

Thus, the Q-effective implementation of the algorithm \scrG  for the Gauss-
Jordan method is realizable.

Stage 3. We obtained a description of the Q-effective implementation of the
algorithm \scrG  for the Gauss-Jordan method in the second stage. Further, we
use this description to develop a Q-effective program for shared memory.
To develop a Q-effective program for distributed memory, you need to
add a description of the distribution of computing between the computing
nodes of the computing system. For this we use the principle of ``master-
slave"".

We have to compute each of matrices

\bigl\{  \=Aj1 |  j1 \in  \{ 1, . . . , n\} \bigr\} 

and the corresponding logical Q-term ui for a suitable i \in  \{ 1, . . . , n!\}  in its
own node of S. If the number of nodes of S is less than n, then the nodes
of S should perform computations for several values of j1. The nodes
of S get information from the node M to compute matrices \=Aj1 for any
j1 \in  \{ 1, . . . , n\}  and the corresponding Q-terms ui for any i \in  \{ 1, . . . , n!\} .
The computation results of r1 and \=Ar1 are transferred to the node M .
The nodes of S get information from the node M to compute matrices
\=Ar1j2 for every j2 \in  \{ 1, . . . , n\}  \setminus  \{ r1\}  and the corresponding Q-terms ui
for every i \in  \{ 1, . . . , n!\} . We have to compute each of matrices

\bigl\{  \=Ar1j2 |  j2 \in  \{ 1, . . . , n\}  \setminus  \{ r1\} \bigr\} 

and the corresponding logical Q-term ui for a suitable i \in  \{ 1, . . . , n!\}  in
its own node of S. The computation results of r1 and \=Ar1 are transferred
to the node M . The next n  -  2 rounds of computations are executed
similarly.

Examples of designing Q-effective programs for performing the algorithm \scrG 

for the Gauss--Jordan method are described in 5.3.

59

5.2.3 The Jacobi method for solving systems of linear equations

At the end, we describe the algorithm for the Jacobi method according to the
stages of the proposed method. It should be noted that this method differs from
the Jacobi method for solving systems of grid equations in the subsection 3.3.
Although, of course, they are closely related, as we pointed out at the beginning
of the subsection 3.3.

Stage 1. We construct the Q-determinant of the algorithm for implementing

the Jacobi method for solving a system of linear equations

A\vec{}x = \vec{}b, where A = [aij]i,j=1,...,n and aii \not = 0 for every i \in  \{ 1, . . . , n\} ,
\vec{}x = (x1, . . . , xn)T and \vec{}b = (a1,n+1, . . . , an,n+1)T .

Let \vec{}x0 be an initial approximation. Then the iteration process can be
written as

xk+1
i =

bi
aii

 - 

\sum 

j\not =i

aij
aii

xk
j for every i \in  \{ 1, . . . , n\}  and k \in  \{ 0, 1, . . . \} .

A sufficient (but not necessary) condition for the convergence of this
method is that the matrix A is strictly diagonally dominant, i.e.,

| aii|  >

\sum 

j\not =i

| aij|  .

In many cases, the stopping criterion is the condition

\| \vec{}xk+1  -  \vec{}xk\|  < \epsilon ,

where \epsilon  is a computation accuracy.

Q-determinant. The Q-determinant of the algorithm consists of n con-
ditional infinite Q-terms. A representation of the algorithm in the form
of a Q-determinant is written as

xi = \bigl\{ (\| \vec{}x1  -  \vec{}x0\|  < \epsilon , x1

i ), . . . , (\| \vec{}xk  -  \vec{}xk - 1\|  < \epsilon , xk

i ), . . . \bigr\} 

(28)

for all i \in  \{ 1, . . . , n\} .

Stage 2. For convenience, we denote

ul = \| \vec{}xl  -  \vec{}xl - 1\|  < \epsilon 

for every l \in  \{ 1, 2, . . . \} . Then a representation of the algorithm in the
form of a Q-determinant (cf. (28)) is

xi = \bigl\{ (u1, x1

i ), (u2, x2

i ), . . . , (uk, xk

i ), . . . \bigr\} 

for all i \in  \{ 1, . . . , n\} .

We describe the Q-effective implementation of the considered algorithm.

60

Firstly, we should compute Q-terms x1
i

for all i \in  \{ 1, . . . , n\}  simulta-
neously. Then we should compute Q-terms u1 and x2
for all i \in 
i
\{ 1, . . . , n\}  simultaneously. If the value of u1 is true, then we should
finish the computation, since we get the solution with the given ac-
curacy, i.e., n-tuple

\bigl\{ xi = x1

i

\bigr\} 

i\in \{ 1,...,n\} 

is the solution of a system of linear equations by the Jacobi method.

Further, for k \geq  2, we continue to compute Q-terms uk and xk+1

for
If the value of uk is true, then
all i \in  \{ 1, . . . , n\}  simultaneously.
we should finish the computation, since we get the solution with the
given accuracy, i.e., n-tuple

i

\bigl\{ xi = xk

i

\bigr\} 

i\in \{ 1,...,n\} 

is the solution of a system of linear equations by the Jacobi method.

Thus, the Q-effective implementation of the algorithm for the Jacobi
method is realizable.

Stage 3. We got a description of the Q-effective implementation of the algo-
rithm for the Jacobi method in the second stage. Further, we use this
description to develop a Q-effective program for shared memory. To de-
velop a Q-effective program for distributed memory, you need to add a
description of the distribution of computing between the computing nodes
of the computing system. For this we use the principle of ``master-slave"".

We describe the process of implementing the algorithm for distributed
memory. Every component of the vector \vec{}xk for any k \in  \{ 1, 2, . . . \}  is
computed on a separate node of S. If the number of nodes of S is less
than n, then the nodes of S should perform the computations for several
components of the vector \vec{}xk for any k \in  \{ 1, 2, . . . \} .

Firstly, the nodes of S receive information from the ``master"" node M
i for every i \in  \{ 1, . . . , n\} . The result of the

to compute Q-terms x1
computation is \vec{}x1, passed to the node M .

After that, the nodes of S receive information from the node M to com-
i for every i \in  \{ 1, . . . , n\} . The node M computes the
i for all i \in  \{ 1, . . . , n\} 

pute Q-terms x2
value of \| \vec{}x1  -  \vec{}x0\|  < \epsilon . At the same time, x2
are computed on the nodes of S simultaneously.

The next iterations are executed similarly.

Examples of designing Q-effective programs for performing the algorithm for

the Jacobi method are described in 5.3.

5.3 Designing Q-effective programs

Several works contain application of the method for designing Q-effective pro-
In these works, there is an experimental study of the developed Q-
grams.
effective programs for algorithms with Q-determinants of various structures.
Further, we describe given works in detail.

61

The research was performed on the supercomputer ``Tornado"" at South Ural
State University. The programming language C++ was used in the development
of programs.

Shared memory. We used one computing node with 24 computing cores. For

development of programs the technology OpenMP was used.

Distributed memory. We used several computing nodes. The technologies of

MPI and OpenMP were used for development of programs.

Developed Q-effective programs can use the parallelism resource of algorithms
completely. However, there were insufficient resources of the computer system
for use all parallelism under computational experiments. Under these condi-
tions, the dynamic characteristics of the programs were evaluated. The program
acceleration is computed by the formula

S =

T1
Tp

,

where T1 is the execution time of the program on one computational core, Tp is
the execution time of the program on p computational cores. The effectiveness
of the program was computed by the formula

E =

S
p

,

where S is the acceleration of the program, p is the number of computational
cores used.

Multiplication algorithms for dense and sparse matrices were investigated in
[28]. The CSR format is used to store sparse matrices. Fig. 3 and fig. 4 show
Q-effective programs for the dense matrix multiplication algorithm for shared
and distributed memory.

Figure 3: The Q-effective program for the dense matrix multiplication algorithm
for shared memory

62

Figure 4: The Q-effective program for the dense matrix multiplication algorithm
for distributed memory

Also fig. 5 and fig. 6 show Q-effective programs for the sparse matrix mul-
tiplication algorithm for shared and distributed memory.
Fig. 7 and fig. 8
show the acceleration of Q-effective programs for the dense and sparse matrix
multiplication algorithms for shared and distributed memory. Finally, fig. 9
and fig. 10 show the efficiency of Q-effective programs for the dense and sparse
matrix multiplication algorithms for shared and distributed memory. Here the
experimental results for matrices of size 30000 \times  30000 are used.

In [26] considers the Gauss-Jordan method for solving systems of linear equa-
tions. In [14] there were the results of a study of the Jacobi method for solving
systems of linear equations. The method of designing Q-effective programs was
tested on algorithms with small and large parallelism resources. For example,
in [9], a sweep method was considered for solving a system of linear three-point
equations, which has a small parallelism resource. Thus, in this case, distributed
memory should not be used, because it can lead to reduced performance. Also,
in [9] considered the Fourier method for solving a system of difference equations,
which has a large parallelism resource. Therefore, it can be effectively imple-
mented on distributed memory by the principle of ``master-slave"". It should be
noted the study of the practical application of designing Q-effective programs
shows that the principle of ``master-slave"" is inappropriate for some algorithms,
since the interchange between computing nodes increases. The Jacobi method
for solving a system of five-point difference equations [13] is an acceptable ex-
ample for this statement.

63

Figure 5: The Q-effective program for the sparse matrix multiplication algo-
rithm for shared memory

There is also some interest in testing the method of designing Q-effective
programs for algorithms with complex Q-determinants. For example, such algo-
rithms implement the Gauss--Jordan method [26] and the Gauss--Seidel method
to solve a system of linear equations [21]. These algorithms have complex
but well-structured Q-determinants. Many other well-known algorithms have
similar properties. Well-structured Q-determinants make it easy to create Q-
effective programs for these algorithms.

5.4 Some ideas about designing Q-effective programs

A further development of the model of the Q-determinant concept can be the
addition of parallel computing models for computing systems with other ar-
chitectural features. Also, to create Q-effective programs, it is possible to use
various programming languages and parallel programming technologies. So, for
one numerical algorithm, there is a potentially infinite set of Q-effective pro-

64

Figure 6: The Q-effective program for the sparse matrix multiplication algo-
rithm for distributed memory

grams. All of them execute the Q-effective implementation of the algorithm,
this is the fastest implementation of the algorithm from a formal point of view.
It is quite possible, there is not the best of all Q-effective programs for given
algorithm in terms of performance. But each of these programs is the most
effective in the computing infrastructure for which it was created.

6 Application of Q-effective programming

Here we consider the application of the mentioned results to increase the effi-
ciency of the implementation of algorithmic problems. Suppose that for solving
an algorithmic problem we can use the set of numerical methods \scrM  with set of
parameters N . Also for every M \in  \scrM  we can use the class of numerical algo-

65

Figure 7: The acceleration of Q-effective programs for the matrix multiplication
algorithm for shared memory

Figure 8: The acceleration of Q-effective programs for the matrix multiplication
algorithm for distributed memory

rithms \scrA (M ). Then the process of developing an effective program for solving
given algorithmic problem is as follows.

Choice of the algorithm A\ast (M ) \in  \scrA (M ) for every M \in  \scrM  with the min-

imum value of the height using the Q-system.

Choice of the algorithm A \in  \{ A\ast (M ) |  M \in  \scrM \}  with the minimum value

of the height.

Development a Q-effective program for the algorithm A.

The described process is called Q-effective programming in the broad sense.
So, in the broad sense the main statements of the technology of Q-effective
programming are the following.

Description of the algorithmic problem.

66

Figure 9: The efficiency of Q-effective programs for the matrix multiplication
algorithm for shared memory

Figure 10: The efficiency of Q-effective programs for the matrix multiplication
algorithm for distributed memory

Description of the methods for solving the algorithmic problem.

Description of the classes of numerical algorithms for the implementation of

each of the methods.

Investigation of the parallelism resources of algorithms from the selected

classes with the help of the Q-system.

Choice of the algorithm with the best height in these classes.

Development of a Q-effective program for the selected algorithm.

7 Conclusion

Now we can come to the following conclusions regarding the presented research
results based on the concept of a Q-determinant.

67

1. Detection and evaluation of the existing parallelism of any numerical al-

gorithm is possible.

2. Defining a admissible way for executing this parallelism is also possible.

Finally, we can argue that there is a real opportunity to obtain the effective
implementations of numerical algorithms for real parallel computing systems,
as well as to increase the efficiency of the implementation of methods and algo-
rithmic problems using numerical algorithms.

Acknowlegments

The reported study was funded by RFBR according to the research project no.
17-07-00865 a. The work was supported by Act 211 Government of the Russian
Federation, contract no. 02.A03.21.0011.

References

[1] Darkhan Akhmed-Zaki, Danil Lebedev, Victor Malyshkin, and Vladislav
Perepelkin. Automated construction of high performance distributed pro-
grams in luna system. In Victor Malyshkin, editor, Parallel Computing
Technologies. PaCT 2019, volume 11657 of Lecture Notes in Computer
Science (LNCS), pages 3--9. Springer, Cham, 2019.

[2] Valentina Aleeva. Designing a parallel programs on the base of the con-
ception of q-determinant. In Vladimir Voevodin and Sergey Sobolev, ed-
itors, Supercomputing. RuSCDays 2018, volume 965 of Communications
in Computer and Information Science (CCIS), pages 565--577. Springer,
Cham, 2019.

[3] Valentina Aleeva, Ekaterina Bogatyreva, Artem Skleznev, Mikhail
Sokolov, and Artemii Shuppa. Software q-system for the research of the
resource of numerical algorithms parallelism. In Vladimir Voevodin and
Sergey Sobolev, editors, Supercomputing. RuSCDays 2019, volume 1129
of Communications in Computer and Information Science (CCIS), pages
641--652. Springer, Cham, 2019.

[4] Valentina N. Aleeva. Analysis of parallel numerical algorithms. Preprint
590, Computing Center of the Siberian Branch of the Academy of Sciences
of the USSR, Novosibirsk, USSR, 1985. (in Russian).

[5] Valentina N. Aleeva and Rifkhat Zh. Aleev. High-performance comput-
ing using the application of the q-determinant of numerical algorithms.
In Proceedings 2018 Global Smart Industry Conference (GloSIC), Global
Smart Industry Conference (GloSIC), pages 1--8. IEEE, 2018.

[6] Valentina N. Aleeva, Ilya S. Sharabura, and Denis E. Suleymanov. Soft-
ware system for maximal parallelization of algorithms on the base of the
conception of q-determinant. In Victor Malyshkin, editor, Parallel Com-
puting Technologies. PaCT 2015, volume 9251 of Lecture Notes in Com-
puter Science (LNCS), pages 3--9. Springer, Cham, 2015.

68

[7] Open encyclopedia of parallel algorithmic features, 2020.

[8] Alexander Antonov, Jack Dongarra, and Vladimir Voevodin. Algowiki
project as an extension of the top500 methodology. Supercomputing Fron-
tiers and Innovations, 5(1):4--10, 2018.

[9] Lyudmila A. Bazhenova. Application of the method of designing a q-
effective program for solving the system of grid equations. Master's the-
sis, School of Electronic Engineering and Computer Science, 2018.
(in
Russian).

[10] Yurii L. Ershov and Evgeny A. Palyutin. Mathematical Logic. Mir,

Moscow, 1984.

[11] Michael R. Garey and David S. Johnson. Computers and Intractability: A
Guide to the Theory of NP-Completeness. W. H. Freeman and Co., San
Francisco, 1979.

[12] Donald E. Knuth. The Art of Computer Programming, volume 1 of Fun-
damental Algorithms. Addison Wesley Longman Publishing Co., Inc.,
Massachusetts, 3rd edition, 1998.

[13] Anna S. Kondakova. Development of a q-effective program for solving
five-point difference equations by the method of simple iteration and the
study of its dynamic characteristics. Master's thesis, School of Electronic
Engineering and Computer Science, 2019. (in Russian).

[14] Yulia E. Lapteva. Q-effective implementation of the jacobi method for
solving slae on the supercomputer ``tornado susu"". Master's thesis, School
of Electronic Engineering and Computer Science, 2017. (in Russian).

[15] Alexander I. Legalov, Vladimir S. Vasilyev, Ivan V. Matkovskii, and
Mariya S. Ushakova. A toolkit for the development of data-driven func-
tional parallel programmes. In Leonid Sokolinsky and Mikhail Zymbler,
editors, Parallel Computational Technologies. PCT 2018, volume 910 of
Communications in Computer and Information Science (CCIS), pages
16--30. Springer, Cham, 2018.

[16] Joseph Y-T. Leung and Hairong Zhao. Scheduling problems in master-
slave model. Annals of Operations Research, 159(1):215--231, 2008.

[17] Yan Li, Wanfeng Dou, Kun Yang, and Shoushuai Miao. Optimized data
I/O strategy of the algorithm of parallel digital terrain analysis. In Craig
Douglas and Guo Yucheng, editors, 2014 13th International Symposium
on Distributed Computing and Applications to Business, Engineering and
Science, Distributed Computing and Applications to Business, Engineer-
ing and Science (DCABES), pages 34--37. IEEE, 2014.

[18] Sergey A. Matveev, Rishat R. Zagidullin, Alexander P. Smirnov, and Eu-
gene E. Tyrtyshnikov. Parallel numerical algorithm for solving advection
equation for coagulating particles. Supercomputing Frontiers and Innova-
tions, 5(2):43--54, 2018.

69

[19] William F. McColl. General purpose parallel computing.

In Alan M.
Gibbons and Paul Spirakis, editors, Lectures on Parallel Computation.
Proc. 1991 ALCOM Spring School on Parallel Computation, Cambridge
International Series on Parallel Computation, pages 333--387. Cambridge
University Press, 1993.

[20] Alexander Moskovsky, Vladimir Roganov, and Sergei Abramov. Paral-
lelism granules aggregation with the T-system. In Victor Malyshkin, edi-
tor, Parallel Computing Technologies. PaCT 2007, volume 4671 of Lecture
Notes in Computer Science (LNCS), pages 293--302, Berlin, Heidelberg,
2007. Springer-Verlag.

[21] Anton D. Necheporenko. Development of a q-effective program for solving
slae by the gauss--seidel method. Master's thesis, School of Electronic
Engineering and Computer Science, 2018. (in Russian).

[22] Valma Prifti, Redis Bala, Igli Tafa, Denis Saatciu, and Julian Fejzaj.
The time profit obtained by parallelization of quicksort algorithm used
In Proceedings of 2015 Science and Information
for numerical sorting.
Conference (SAI), Science and Information Conference (SAI), pages 897--
901. IEEE, 2015.

[23] Aleksander A. Sammarskii and Alexei A. Goolin. Numerical Methods.
Nauka. Main Editorial Bord for Physical and Mathematical Literature,
Moscow, 1989. (in Russian).

[24] Alexey V. Setukha, Vladimir A. Aparinov, and Andrey A. Aparinov.
Supercomputer modeling of parachute flight dynamics. Supercomputing
Frontiers and Innovations, 5(3):121--125, 2018.

[25] Dmitry Suplatov, Vladimir Voevodin, and Vytas \v Svedas. Robust enzyme
design: bioinformatic tools for improved protein stability. Biotechnology
journal, 10(3):344--355, 2015.

[26] Denis E. Tarasov. Q-effective co-design of realization of the gauss--jordan
method on the supercomputer ``tornado susu"". Master's thesis, School of
Electronic Engineering and Computer Science, 2017. (in Russian).

[27] Leslie G. Valiant. A bridging model for parallel computation. Communi-

cations of the ACM, 33(8):103--111, 1990.

[28] Nikolai V. Val'kevich. Q-effective implementation of the algorithm for
matrix multiplication on a supercomputer ``tornado susu"". Master's the-
sis, School of Electronic Engineering and Computer Science, 2017.
(in
Russian).

[29] Valentin V. Voevodin and Vladimir V. Voevodin. The V-ray technol-
ogy of optimizing programs to parallel computers.
In Lubin Vulkov,
Jerzy Wa\'sniewski, and Plamen Yalamov, editors, Numerical Analysis and
Its Applications. WNAA 1996, volume 1196 of Lecture Notes in Com-
puter Science (LNCS), pages 546--556, Berlin, Heidelberg, 1997. Springer-
Verlag.

70

[30] Valentin V. Voevodin and Vladimir V. Voevodin. Parallel computing.

BHV-Petersburg, St.Petersburg, 2002. (in Russian).

[31] Qinglin Wang, Jie Liu, and Xiantuo Tang 2014 Feng Wang 2014 Guitao
Fu 2014 Zuocheng Xing. Accelerating embarrassingly parallel algorithm
on intel mic. In 2014 IEEE International Conference on Progress in In-
formatics and Computing, Progress in Informatics and Computing (PIC),
pages 213--218. IEEE, 2014.

[32] Jiaxin You, Hongda Kezhang, Huimin Liang, and Bin Xiao. Research on
parallel algorithms for calculating static characteristics of electromagnetic
relay. In 2016 IEEE 11th Conference on Industrial Electronics and Appli-
cations (ICIEA), Industrial Electronics and Applications (ICIEA), pages
1421--1425. IEEE, 2016.

71

