ICEBOAT: An Interactive User Behavior Analysis Tool for
Automotive User Interfaces

2
2
0
2

g
u
A
6
2

]

C
H
.
s
c
[

1
v
5
1
7
2
1
.
8
0
2
2
:
v
i
X
r
a

Patrick Ebel
ebel@cs.uni-koeln.de
University of Cologne
Cologne, Germany

Christoph Lingenfelder
christoph.lingenfelder@mercedes-benz.com
MBition GmbH
Berlin, Germany

ABSTRACT
In this work, we present ICEBOAT an interactive tool that enables
automotive UX experts to explore how users interact with In-Vehicle
Information Systems (IVISs). Based on large naturalistic driving
data continuously collected from production line vehicles, ICEBOAT
visualizes drivers’ interactions and driving behavior on different
levels of detail. Hence, it allows to easily compare different user
flows based on performance- and safety-related metrics.

CCS CONCEPTS
• Human-centered computing → Field studies; Visualization
toolkits.

KEYWORDS
Human-Computer Interaction, In-Vehicle Information System, De-
sign Tools, Naturalistic Driving Data, Data Visualization

ACM Reference Format:
Patrick Ebel, Kim Julian Gülle, Christoph Lingenfelder, and Andreas Vo-
gelsang. 2022. ICEBOAT: An Interactive User Behavior Analysis Tool for
Automotive User Interfaces. In The Adjunct Publication of the 35th Annual
ACM Symposium on User Interface Software and Technology (UIST ’22 Ad-
junct), October 29-November 2, 2022, Bend, OR, USA. ACM, New York, NY,
USA, 3 pages. https://doi.org/10.1145/3526114.3558739

1 INTRODUCTION
In modern vehicles, large center stack touchscreens have become
an integral part of the driver-vehicle interaction. Today’s IVISs
offer a variety of functions that are increasingly similar to those of
tablets and smartphones. Therefore, IVISs are now subject to the
same high demands when it comes to usability.

To keep pace with this rapid development and to continuously
develop interfaces that are well received by the customers, there is
an increased need for data-driven support in the automotive UX
design [2, 4, 9]. Whereas websites and apps track every interaction

UIST ’22 Adjunct, October 29-November 2, 2022, Bend, OR, USA
© 2022 Patrick Ebel. ACM 2022. This is the author’s version of the work. It is posted
here for your personal use. Not for redistribution. The definitive Version of Record was
published in the Adjunct Publication of the 35th Annual ACM Symposium on User
Interface Software and Technology, October 29-November 2, 2022, Bend, OR, USA.
ACM ISBN 978-1-4503-9321-8/22/10. . . $15.00
https://doi.org/10.1145/3526114.3558739

Kim Julian Gülle
k.guelle@campus.tu-berlin.de
TU Berlin
Berlin, Germany

Andreas Vogelsang
vogelsang@cs.uni-koeln.de
University of Cologne
Cologne, Germany

a user makes and design decisions are made in consideration of con-
version rates, time on task, or error rates [6], the decision-making
process for the design of IVISs is more complex. During manual and
partially automated driving, the driver must monitor the driving
situation at all times [8], making driving the primary task. Hence,
the interaction with IVISs is only the secondary task. While inter-
acting with IVISs drivers need to distribute their attention between
the primary driving task and the secondary touchscreen task. This
behavior is correlated with an increased crash risk [1]. Thus, the
metrics used to compare different designs or the basis on which to
decide which features to prioritize are substantially different from
what we are used to in web or app development [5]. Automotive
UX experts have to consider the interdependencies between driving
behavior, interaction behavior, and glance behavior [7].

In previous research [2, 4], we identified needs and potentials to
support the automotive design process by providing feature usage
statistics, user flow analyses, and context-dependent visualizations.
Based on these findings, we developed three standalone hierarchical
user behavior visualizations that proved their usefulness in a user
study [3]. However, to leverage the potential of such visualization
they need to be integrated into the product design process.

Therefore, this work in progress presents ICEBOAT, an Inter-
aCtive UsEr BehaviOr Analysis Tool that enables UX experts to an-
alyze in-vehicle user flows and driving-related performance metrics
interactively based on continuously collected data from produc-
tion line vehicles. The contribution of this work is twofold: First,
we conducted semi-structured interviews to gather insights from
practitioners on how large-scale field user interaction data needs to
be integrated into their design process. Second, using a co-design
approach we build an interactive web app that allows UX experts
to analyze drivers’ touchscreen interactions on different levels of
granularity.

2 METHODOLOGY
We develop ICEBOAT by following a user-centric design approach.
First, we conducted 4 interviews to elicit initial requirements. The
participants had at least 5 years of relevant professional experi-
ence and have been with our research partner for more than 5
years. Therefore, we consider them knowledgeable regarding the
automotive-specific design processes. After an initial introduction,
we presented the visualizations introduced by Ebel et al. [3]. We

 
 
 
 
 
 
UIST ’22 Adjunct, October 29-November 2, 2022, Bend, OR, USA

Ebel et al.

Figure 1: The ICEBOAT system architecture.

then asked the interviewees how they would improve these visu-
alizations and how they envision an interactive tool that would
benefit their daily work. After eliciting the requirement, we de-
signed a first prototype of the ICEBOAT tool. We improve this
prototype continuously based on the user feedback we get in co-
design sessions.

3 ICEBOAT
ICEBOAT is an interactive tool that enables automotive UX experts
to explore how users interact with IVIS. Based on large naturalistic
driving data collected continuously from production line vehicles, it
provides various options to analyze drivers’ interaction and driving
behavior. The system architecture is shown in Figure 1.

ICEBOAT’s UI provides users with two different options to start
their analysis: They can either choose (1) Manual Input or (2) Task
Recording. When using the manual input option, users are asked to
define the task they want to analyze by selecting the first and last
UI element out of a searchable drop-down list. To ease this process,
users can also access the concept database using a separate web
interface and search for the respective UI elements. The concept
database contains all interactive UI elements of the IVIS software
and further information like the application (e.g. navigation, cli-
mate, etc.) they belong to, the screen on which they are placed, or
the function that they trigger. However, as there are thousands of
different UI elements, the users are not necessarily aware of all
respective identifiers. Therefore, we developed the task recording
input option. It enables users with limited knowledge to playfully
define the task they are interested in. Users can click through an

emulated version of the IVIS, similar to what is displayed to drivers
on the center stack touchscreen in the car. Once they find a task
that they want to analyze, they can record the corresponding inter-
actions. The emulation environment then outputs a file containing
the identifiers of the respective UI elements. As of now, this file
can then be uploaded to ICEBOAT which uses the first and last
interaction of the recorded sequence as the start and end of a task.
After the users define the task they want to analyze, ICEBOAT
extracts all relevant interaction sequences from the customer data.
The data used for the analysis is collected Over-The-Air (OTA) from
all production line vehicles of our research partner that are equipped
with the most recent software architecture. The In-vehicle Logging
Mechanism collects touchscreen interactions from the UI interface
and driving-related data from the vehicle bus. This information
is continuously sent to the Big Data Platform where it is further
processed such that it serves the needs of ICEBOAT. After sequence
extraction, the data is enhanced with additional information from
the concept database and user flow statistics are calculated. Finally,
the results are computed and visualized according to the three levels
introduced by Ebel et al. [3]: the Task Level View, Flow Level View,
and Sequence Level View.

In the course of the initial study, we found that users use the
Task Level View as a reference to which they come back after they
went into the other views for more detailed analyses [3]. We, there-
fore, choose this view as the entry point of the visual exploration
journey. The visualization hierarchy then unfolds dynamically as
users dive deeper into more specific analyses. In the Task Level
View, the interaction data is aggregated and visualized in form of

Interactive User Flow ExplorationTask RecordingManual InputSequence MappingStatisticsComputationBig Data PlatformConcept DatabaseIn-Vehicle Logging MechanismUX ExpertsConcept Database Web AccesscICEBOAT

UIST ’22 Adjunct, October 29-November 2, 2022, Bend, OR, USA

an adapted Sankey diagram, allowing users to easily assess which
interactions drivers performed to solve the chosen task. Users can
also choose between various filtering options allowing them to, for
example, only show data for the most prominent user flows, specific
software versions, or car models. If users are further interested in
how different flows that belong to the same task compare, they can
choose the respective flows and define a metric of their choice used
for comparison. The Flow Level View then shows the distribution
of interaction sequences according to the chosen metric in form
of boxplots. The underlying datapoints are visualized next to the
boxplot. Each dot represents one interaction sequence. If users are
interested in a specific sequence, (e.g. an outlier with a very long
interaction time) and the driving situation in which the interactions
took place, they can click on the visualization and are re-directed
to the Sequence Level View. This view shows an overlay of the re-
spective touchscreen interactions and driver glances. Furthermore,
driving-related signals like the vehicle speed and steering wheel
angle are visualized. This allows users to better judge the specific
situation as in-vehicle interactions are highly context-sensitive and
need to be evaluated based on the driving situation.

4 CONCLUSION AND FUTURE WORK
In this work in progress, we introduce ICEBOAT, an interactive
user behavior analysis tool for automotive user interfaces. ICE-
BOAT processes telematics data that is continuously collected from
production line vehicles. The tool enables UX experts not only
to evaluate how drivers interact with the in-vehicle touchscreen
but also allows them to analyze user interactions in light of the
driving situation. The proposed implementation is based on previ-
ous research [3, 4] and represents the current result of an ongoing
co-design process. In future iterations, we aim to introduce new
visualizations, implement functionalities that allow users to save
analyses, and introduce more metrics and filters. The final tool will
be evaluated in an extensive usability study.

5 ACKNOWLEDGEMENTS
We want to thank Fabian Ober for his work on the user flow record-
ing option.

REFERENCES
[1] Thomas A. Dingus, Feng Guo, Suzie Lee, Jonathan F. Antin, Miguel Perez, Mindy
Buchanan-King, and Jonathan Hankey. 2016. Driver Crash Risk Factors and
Prevalence Evaluation Using Naturalistic Driving Data. Proceedings of the National
Academy of Sciences 113, 10 (March 2016), 2636–2641. https://doi.org/10.1073/
pnas.1513271113

[2] Patrick Ebel, Florian Brokhausen, and Andreas Vogelsang. 2020. The Role and
Potentials of Field User Interaction Data in the Automotive UX Development
Lifecycle: An Industry Perspective. In 12th International Conference on Auto-
motive User Interfaces and Interactive Vehicular Applications (AutomotiveUI ’20).
Association for Computing Machinery, New York, NY, USA, 141–150. https:
//doi.org/10.1145/3409120.3410638

[3] Patrick Ebel, Christoph Lingenfelder, and Andreas Vogelsang. 2021. Visual-
izing Event Sequence Data for User Behavior Evaluation of In-Vehicle Infor-
mation Systems. In 13th International Conference on Automotive User Interfaces
and Interactive Vehicular Applications. ACM, Leeds United Kingdom, 219–229.
https://doi.org/10.1145/3409118.3475140

[4] Patrick Ebel, Julia Orlovska, Sebastian Hünemeyer, Casper Wickman, Andreas
Vogelsang, and Rikard Söderberg. 2021. Automotive UX Design and Data-Driven
Development: Narrowing the Gap to Support Practitioners. Transportation Research
Interdisciplinary Perspectives 11 (Sept. 2021), 100455. https://doi.org/10.1016/j.trip.
2021.100455

[5] Catherine Harvey and Neville A. Stanton. 2016-04-19, 2016. Usability Evaluation

for In-Vehicle Systems. CRC Press, Boca Raton, Florida, United States.

[6] Rochelle King, Elizabeth F. Churchill, and Caitlin Tan. 2017. Designing with Data:
Improving the User Experience with A/B Testing (1st ed.). O’Reilly Media, Inc.,
Sebastopol, California, United States.

[7] Sheila Klauer, Thomas Dingus, T Neale, J. Sudweeks, and D Ramsey. 2006. The
Impact of Driver Inattention on Near-Crash/Crash Risk: An Analysis Using the
100-Car Naturalistic Driving Study Data. Technical Report. U.S. Department of
Transportation, National Highway Traffic Safety Administration / Virginia Tech
Transportation Institute, 3500 Transportation Research Plaza (0536) Blacksburg,
Virginia 24061.

[8] On-Road Automated Driving (ORAD) committee. 2021. Taxonomy and Defini-
tions for Terms Related to Driving Automation Systems for On-Road Motor Vehicles.
Technical Report. SAE International. https://doi.org/10.4271/J3016_202104
[9] Julia Orlovska, Casper Wickman, and Rikard Söderberg. 2018. Big Data Usage Can
Be a Solution for User Behavior Evaluation: An Automotive Industry Example.
Procedia CIRP 72 (2018), 117–122. https://doi.org/10.1016/j.procir.2018.03.102

