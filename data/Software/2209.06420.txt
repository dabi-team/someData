2
2
0
2

p
e
S
5
1

]

A
N
.
h
t
a
m

[

2
v
0
2
4
6
0
.
9
0
2
2
:
v
i
X
r
a

Robust ab initio solution of the cryo-EM reconstruction
problem at low resolution with small data sets

Aaditya V. Rangan and Leslie Greengard ∗

September, 2022

Abstract

Single particle cryo-electron microscopy has become a critical tool in structural biology over
the last decade, able to achieve atomic scale resolution in three dimensional models from hun-
dreds of thousands of (noisy) two-dimensional projection views of particles frozen at unknown
orientations. This is accomplished by using a suite of software tools to (i) identify particles
in large micrographs, (ii) obtain low-resolution reconstructions, (iii) reﬁne those low-resolution
structures, and (iv) ﬁnally match the obtained electron scattering density to the constituent
atoms that make up the macromolecule or macromolecular complex of interest.

Here, we focus on the second stage of the reconstruction pipeline: obtaining a low resolution
model from picked particle images. Our goal is to create an algorithm that is capable of ab
initio reconstruction from small data sets (on the order of a few thousand selected particles).
More precisely, we seek an algorithm that is robust, automatic, able to assess particle quality,
and fast enough that it can potentially be used to assist in the assessment of the data being
generated while the microscopy experiment is still underway.

1 Introduction

In single-particle cryo-electron microscopy (cryo-EM), a puriﬁed preparation of particles (proteins
or macro-molecular complexes) is frozen in a thin sheet of ice, with each particle held in an un-
known orientation. Using a weak scattering approximation, the image obtained can be viewed as a
noisy projection of the particle’s electron scattering density, which we denote by F (x), with optical
aberrations modeled by what is called a contrast transfer function (CTF) [1, 2]. The task at hand
is to take the individual particle images, determine their orientations, and recover a high resolution
characterization of F (x). This is typically accomplished through the Fourier slice theorem [3, 4],
which states that the two-dimensional Fourier transform of each projection image is a slice through
ˆF (k), the three-dimensional Fourier transform of F (x) (modulated by the CTF).

The speciﬁc slice obtained from a single image is determined by the orientation of the individual
particle. With many particles at many distinct orientations, ˆF (k) is well-sampled and F (x) can
be obtained through the inverse Fourier transform. Thus, if the orientations are known, the recon-
struction problem is linear and easily solved. The orientations, however, are not known, and the
reconstruction problem is both nonlinear and non-convex. In practice, not only are the orientations
unknown, but the particles must be correctly centered in order to invoke the Fourier slice theorem.
The unknown displacement vector must also be learned for each particle image. We postpone a
proper discussion of the mathematics to section 2 and the appendices (Supporting Information).

From an experimental perspective, the initial stages of cryo-EM involve some hours of imaging,
resulting in the collection of multiple micrographs, each containing a number of particle images.
After suﬃciently many micrographs are collected, the next steps typically involve particle picking
(identifying individual particles in the micrographs), class averaging (ﬁnding particles that appear

∗Center for Computational Mathematics, Flatiron Institute and Courant Institute, NYU

1

 
 
 
 
 
 
to have the same orientation and taking the average in order to improve the signal-to-noise ratio)
and molecular reconstruction, with the goal of producing a low- to medium-resolution molecule for
further analysis and processing.

Despite recent advances in sample preparation, imaging and analysis, the cost of data collection
can still be quite signiﬁcant, and the availability of microscope time is a limited resource. A single
hour of imaging might only produce 100-200 micrographs which, in turn, could yield only a few
thousand high quality picked-particle images. A full day of imaging might be required to produce
many thousands of micrographs and the hundreds of thousands of particles required to obtain atomic
level resolution. In order for the picked-particle images to be useful, they must meet certain criteria:
each should contain a single well-centered particle with a minimum of clutter, and the full set must
cover a wide variety of viewing angles, suﬃcient to determine the full three-dimensional structure.
Assuming that these criteria are met, these images (hopefully the least noisy and cleanest projection
views) can then be used in downstream analyses. If the sample or the images are not of suﬃcient
quality, it may be necessary to terminate the current experiment and repeat with a new sample,
hoping to produce higher-quality particle images the next time.

To reduce the time and cost of such experiments, there are many quality-control tasks that would

be useful to carry out as early as possible. These include:

1. determining whether any picked-particle image contains a reasonably well-centered and isolated

molecule.

2. estimating the viewing angles of the images (and checking that the range of viewing angles is

suﬃcient to reconstruct the molecule).

3. estimating the displacements/shifts required to more precisely center the images.

4. estimating the image quality and the number of particles that will be needed to reconstruct

the desired molecule at the desired resolution.

5. estimating the molecular structure itself at low-resolution (which feeds back to the estimates

1-4)

In current practice, many of these issues are addressed after carrying out class averaging, which
typically requires dozens of particles per class and tens of thousands of picked particles.

In this paper, we describe an algorithm which can serve as a complement to more standard
strategies. Our algorithm operates on a relatively small set of picked-particle images (say, a few
thousand), and attempts to directly reconstruct (without class averaging) a low-resolution version
of the imaged molecule, along with estimates of the viewing-angles, shifts and quality of the images
involved. As we demonstrate below, our method is signiﬁcantly faster, more accurate and more
reliable than a number of existing de-novo reconstruction algorithms. We hope that it is robust
enough to permit the assessment of data quality as the experiment is being carried out. Moreover,
our algorithm runs quickly and automatically with no ‘tuning’ required, allowing for multiple small
pools of approximately 1000 picked-particles to be independently assessed without supervision (each
corresponding to ∼ 30 micrographs). This would help set the stage for more robust statistical
validation techniques such as bootstrap or jack-knife estimation.

At its core, our algorithm is a modiﬁcation of the simplest expectation-maximization method.
We use the framework of classical iterative reﬁnement - alternating between a reconstruction step
and an alignment step. In the reconstruction step, we use the current estimate of the viewing angles
for each particle/image and their displacements to approximate the molecule. In the alignment step,
we use the current estimate of the molecule to better ﬁt the viewing angles and displacements for
each image. We will refer to this approach as alternating minimization (AM).

It is well-known that standard AM does poorly in this setting; an initialization with randomized
viewing angles typically fails to converge to a useful low-resolution approximation of the molecule.
To address these issues and to guide AM to a better structure, we introduce two changes: (i) we
compress and denoise the individual images by computing their two-dimensional Fourier transform

2

on a polar grid and focusing on carefully selected rings in the transform domain with maximal
information content, and (ii) we increase the entropy of the viewing-angle distribution used during
the reconstruction step (in a manner to be described in detail). These modiﬁcations both reduce
the computational cost and improve the robustness of AM in the low-resolution low-image-number
regime.

In the numerical experiments below, we show that our modiﬁed method (alternating minimization
with entropy maximization and principal modes or ‘EMPM’) performs surprisingly well on several
published data sets. Our reconstructions are often on par with the best results one could expect
from an ‘oracle-informed’ AM (i.e., standard AM starting with the ‘ground-truth’ viewing-angles
and displacements for each image). Moreover, our results are similar to (or better than) what one
might expect from a reconstruction using ‘optimized’ Bayesian inference (i.e., using a ground-truth
informed estimated noise level). Importantly, our strategy is eﬃcient, running about twenty times
faster than standard Bayesian inference or the de-novo reconstruction in the widely used, open source
package Relion [5, 6, 7].

We have not attempted a direct comparison to other de-novo reconstruction approaches such
as the stochastic gradient descent approach in cryoSPARC [8], the neural network approach in
cryoDRGN [9], or the recent low-resolution reconstruction pipeline in Aspire [10] Our method is
currently implemented for multi-core CPUs, but we believe it should be straightforward to implement
on GPUs as well, and to integrate into Relion and other well-developed software packages for cryo-
EM.

In the remainder of this paper, we brieﬂy summarize the EMPM method and demonstrate its
performance on a variety of data sets. The details of our method, as well as some additional
motivating examples, are deferred to the Supporting Information.

2 Overview of the EMPM iteration

Our general goal is to solve the following problem: given a set of NA picked particle images (2D
projections) from a handful of micrographs (each with their own CTF), estimate the unknown
viewing-angles τj ∈ SO(3) and displacements δj ∈ R2 for each image, as well as the underlying
volume ˆF (k), where k ∈ R3 denotes a point in the Fourier transform domain.
In addition to
determining the volume ˆF (k), we would also like an estimate of the viewing-angle distribution µτ
and displacement distribution µδ (taken across the images). If the estimates of the volume ˆF (k)
and the distributions µτ , µδ are accurate estimates of the ground truth, they will clearly be useful
for quality control, determining (for example) whether the experimental conditions are suitable for
larger scale data collection and subsequent high resolution reconstruction.

The main tool we employ is a form of alternating minimization (AM), which carries out some

number of iterations of the following two step procedure:

Reconstruction: Given the estimated viewing-angles {τ estim

} for NA
2d picked-particle images { ˆAj}, reconstruct the 3D molecular volume ˆF estim (using the Fourier
slice theorem and least squares inversion of the Fourier transform).

} and displacements {δestim

j

j

Alignment: Given the reconstruction of the 3D molecule ˆF estim, update the estimates {τ estim

} and

j

{δestim
j

}.

In a standard AM scheme, the reconstruction step solves for ˆF estim using a least-squares proce-
} and {δestim
} using some kind of maximum-likelihood
dure, and the alignment step assigns the {τ estim
procedure (see sections A.18 and A.22 in the Supporting Information). While there are many more
sophisticated strategies for molecular reconstruction (see, for example, [8, 9]), we focus on AM for
a few reasons: ﬁrst and foremost is its simplicity, transparency and ease of automation. AM has
modular steps, few parameters, and is easily interpretable.

j

j

At the same time, however, standard AM does have serious limitations. First, it can be compu-
tationally expensive, particularly if a broad range of frequencies and/or translations are considered

3

in the alignment step. Second, AM can fail to converge to the correct solution, especially during the
initial iterations, when the initial guess is far from the true molecule.

To address these two issues, we propose a modiﬁed version of AM which we refer to as alternating
minimization with entropy-maximization and principal modes (EMPM). The two main modiﬁcations
we introduce are:

Maximum entropy alignment: We use both the traditional maximum likelihood alignment strat-
egy, which ﬁnds the best estimate for each image from the current molecular reconstruction,
and its opposite. That is, we also use a ‘maximum-entropy’ alignment strategy:
for each
uniformly chosen viewing angle, we ﬁnd the experimental image which best matches the cor-
responding projection from the current structure. The subsequent reconstruction step makes
use of this uniform distribution of viewing angles whether or not it corresponds to the true
distribution. Use of this counter-intuitive step is important in stabilizing our low resolution
reconstruction from a small set of images (see section A.22 in the Supporting Information).

Principal-mode projection: Each image is transformed onto a polar grid in Fourier space. The
data on each circle in the transform domain at a ﬁxed modulus |k| will be referred to as a
Fourier ring. Rather than considering all Fourier rings when comparing 2D projections and
image data, we consider only a handful of carefully-chosen combinations of such rings, which we
refer to as principal modes. This yields signiﬁcant compression of the data (and computational
eﬃciency) while retaining information useful for alignment (see section A.13 in the Supporting
Information).

In the EMPM pipeline, we ﬁrst estimate the principal-modes using the images themselves. Using
these ‘empirical’ principal modes, we proceed with AM, alternating between maximum-likelihood
and maximum-entropy alignment. Once a preliminary volume estimate has been obtained, we use
that estimate to recalculate the principal modes. We then restart AM using the new principal images
and, again, alternate between maximum-likelihood and maximum-entropy alignment until we have
a ﬁnal volume estimate. The algorithm is summarized below (see Supporting Information for a more
detailed description):

1. Use the experimental images ˆAj to calculate ‘empirical’ principal modes U empir.

2. Compute the principal images, deﬁned to be the projection of the images onto principal modes,

P (U empir, ˆAj).

3. Set random initial viewing angles τ empir

j

and set initial displacements δempir

j

to 0.

4. Carry out 32 iterations of EMPM on the principal images.

(a) Reconstruct ˆF empir using τ empir

j

and δempir

j

.

(b) Use maximum-likelihood alignment to update τ empir
(c) Reconstruct ˆF empir using τ empir

and δempir

.

j

j

j

and δempir

j

.

(d) Use maximum-entropy alignment to update τ empir

j

and δempir

j

.

5. Use ˆF empir to calculate ‘estimated’ principal modes U estim.

6. Set initial viewing angles τ estim

j

= τ empir
j

and displacements δestim

j

= δempir
j

.

7. Carry out 32 iterations of EMPM on the new principal images P (U estim, ˆAj).

(a) Reconstruct ˆF estim using τ estim
(b) Use maximum-likelihood alignment to update τ estim
(c) Reconstruct ˆF estim using τ estim

and δestim

and δestim

.

.

j

j

j

j

j

and δestim

j

.

4

(d) Use maximum-entropy alignment to update τ estim

j

and δestim

j

.

j

and δestim

Note that, each time we update the displacements δempir
, we bound the maximum permitted
j
displacement magnitude by δmax (typically δmax ∼ 0.1 in our dimensionless units). In our studies
with small amounts of moderately noisy experimental data, we have observed that the EMPM
strategy is more eﬀective than Bayesian inference or maximum-likelihood alignment alone - even with
probabilistic alignment where a distribution of viewing angles is assigned to each image. Roughly
speaking, we believe this is due the fact that the incorrect viewing angles assigned in the maximum-
entropy step are washed out by destructive interference, while the correctly assigned ones reinforce
the true structure. One simple model problem which illustrates these points is discussed in the
Supporting Information (see sections B and C). It is worth repeating, however, that we only propose
this approach for obtaining a low-resolution initial guess. Existing reﬁnement methods are still
crucial for high resolution.

Once we have run our EMPM algorithm, we have the estimated volume ˆF estim(k) as output.
Using ˆF estim(k) as an approximation of ˆF (k), we can readily compute other quantities that may be
of interest, such as estimates of the true viewing angle distribution in the data set and other types of
correlations. We will use these quantities in our numerical experiments below to compare the results
of EMPM to other methods, such as Relion’s de-novo molecular reconstruction and full Bayesian
inference.

2.1 Templates, correlations, and ranks
For each centered molecular reconstruction ˆF , and set of Euler angles τ = (α, β, γ), we deﬁne the
inner product X and normalized inner product ˆX of the reconstruction with the “ground-truth”
model ˆF true by

X (τ ; ˆF , ˆF true) = (cid:104)R(τ ) ◦ ˆF , ˆF true(cid:105)

ˆX (τ ; ˆF , ˆF true) =

X (τ ; ˆF , ˆF true)
(cid:107) ˆF (cid:107) · (cid:107) ˆF true(cid:107)

.

(1)

(2)

Here (α, β) denotes the viewing angle of an image with α the azimuthal angle and β the polar angle.
γ is the ﬁnal in-plane rotation (see section A.6). R(τ ) ◦ ˆF is the volume obtained from ˆF using the
rotation (the element of SO(3)) deﬁned by τ . We deﬁne the volumetric correlation Z( ˆF , ˆF true) by

Z( ˆF , ˆF true) = max

τ

ˆX (τ ; ˆF , ˆF true).

(3)

This measurement Z( ˆF , ˆF true) represents the optimal correlation (over all alignments) between the
two volumes ˆF and ˆF true.

In order to compare our results with Relion’s de-novo reconstruction, we will also need to calculate

the ‘masked’ correlation Z mask(F, F true), deﬁned as:

X mask(τ ; F, F true) = (cid:104)R(τ ) ◦ F · G, F true(cid:105)

ˆX mask(τ ; F, F true) =

X mask(τ ; F, F true)
(cid:107)F · G(cid:107) · (cid:107)F true(cid:107)

Z mask(F, F true) = max

τ

ˆX mask(τ ; F, F true),

(4)

(5)

(6)

where G is a sharp spherical mask (i.e., the indicator-function of a ball centered at the origin) with
a radius determined by the support of F true.

We will also need to deﬁne inner products and correlations of single images and volumetric slices.
For this, given a Fourier space volume ˆF , we generate noiseless 2D projections (in the Fourier domain)
that incorporate the CTF, which we refer to as templates. We denote these by ˆS(τ, δ; CT F ; ˆF ), where

5

τ is the speciﬁc set of Euler angles and δ is the displacement. When assuming the displacement is
zero, we will write these templates as ˆS(τ ; CT F ; ˆF ), Formally, we have
(cid:104) ˆSl ◦ R(τ ) ◦ ˆF

ˆS(τ ; CT F ; ˆF )

:= CT F (k) (cid:12)

(k).

(7)

(cid:105)

where CT F (k) is the given pointwise value of the CTF in Fourier space and ˆSl denotes taking the
equatorial slice in the Fourier domain. These CTF-modulated templates are used to calculate the
inner products:

X (τ, δ; ˆAj; CT Fj; ˆF ) = (cid:104) ˆS(τ ; CT Fj; ˆF ) , T (−δ, k) (cid:12) ˆAj (cid:105),

(8)

where T (+δ, k) = eiδ·k is the Fourier signature of displacement by the vector δ. These are used, in
turn, to calculate the correlations:

ˆX (τ, δ; ˆAj; CT Fj; ˆF ) =

X (τ, δ; ˆAj; CT Fj; ˆF )
(cid:107) ˆS(τ ; CT Fj; ˆF )(cid:107) · (cid:107) ˆAj(cid:107)

.

For convenience, we generally reduce this to a function of the viewing direction ˆk = (α, β), the ﬁrst
two components of τ , alone:

Z(α, β; ˆAj; CT Fj; ˆF ) = max
γ,δ

ˆX (τ, δ; ˆAj; CT Fj; ˆF ).

(9)

The parameters γ and δ are associated with a particular choice of α and β implicitly through the
arg max. When the context is clear, we will often abuse notation and refer to the correlations in (9)
by Z(α, β; ˆAj).

Finally, for each image ˆAj and a set of NS templates deﬁned by the viewing directions (αl, βl), l =

1, . . . , NS, we can order the values

Z(αl, βl; ˆAj; CT Fj; ˆF ), l = 1, . . . , NS.

This yields what we will refer to as the template rank for the image.

Conversely, for each template deﬁned by (αl, βl), one can order the values

Z(αl, βl; ˆAj; CT Fj; ˆF ), j = 1, . . . , NA.

(10)

(11)

This deﬁnes the image rank for that template. Using the terminology of linear algebra, we can deﬁne
the NS × NA matrix Z with

Zlj = Z(αl, βl; ˆAj).
Template-ranking then corresponds to sorting the rows of Z while image-ranking corresponds to
sorting the columns.

3 Results

We will consider a number of examples in this paper, drawn from the electron-microscopy image
archive (EMPIAR) - namely, trpv1, the capsaicin receptor (the transient receptor potential cation
channel subfamily V member 1) [EMPIAR-10005, emd-5778], rib80s, the Plasmodium falciparum
80S ribosome bound to emetine [EMPIAR-10028, emd-2660], ISWINCP, the ISWI-nucleosome com-
plex [EMPIAR-10482, emd-9718], ps1, the pre-catalytic spliceosome [EMPIAR-10180], MlaFEDB, a
bacterial phospholipid transporter [EMPIAR-10536, emd-22116], LetB1, the lipophilic envelope-
spanning tunnel B protein from E. coli [EMPIAR-10350, emd-20993], TMEM16F, a Calcium-
activated lipid scramblase and ion channel in digitonin with calcium bound [EMPIAR-10278, emd-
20244], and LSUbl16dep, L17-Depleted 50S Ribosomal Intermediates, using an average of the pub-
lished major classes as a reference [EMPIAR-10076]. To limit the number of picked particles, we

6

carry out our numerical experiments on subsets of NA = 1024 images, spanning a small number
NCTF of micrographs.

We set K = 48 as the bandlimit for our low-resolution reconstruction, corresponding to a ‘best’
possible resolution of about 20˚A. With these image pools, we construct a variety of diﬀerent ‘reference
volumes’ for ˆF (k).

Ground truth: First, we center and restrict the published volume to the band-limit K. This

deﬁnes our ‘ground truth’ volume ˆF true(k).

Oracle: Next, we measure the correlations Z(τ ; ˆAj; CT Fj; ˆF true) for a suﬃciently sampled set of
Euler angles τ and displacements and use maximum-likelihood to align the images to ˆF true(k).
This assigns ‘ground-truth’ viewing angles τ true
to each image. More
precisely, we start by calculating Z using a small displacement disc of δlocal = 0.03, and
then iterate multiple times, with δmax = 0.25 until the correlation between the reconstructed
and true volumes plateaus (this usually takes less than 8 iterations). We then take the ﬁnal
. Given these ground-truth-based
viewing angles and displacements to deﬁne τ true
j
viewing angles and displacements, we use a least-squares reconstruction to compute ˆF Oracle(k).

and displacements δtrue

and δtrue

j

j

j

Oracle-AM: Starting with the ground-truth viewing angles and displacements, as well as ˆF Oracle(k),
we apply standard AM, iterating until the resulting volume converges (this, again, usually
requires less than 8 iterations). We deﬁne this ﬁnal volume to be ˆF OAM(k). We expect the
volume ˆF OAM to be close to the best reconstruction one could realistically achieve with standard
AM.

Oracle-Bayesian: Next, we apply Bayesian inference reconstruction (as described in [7, 11]). This
reconstruction depends on (i) the initial starting volume, (ii) the estimated noise level σBI,
(iii) the resolution K and range of displacements δmax considered, and (iv) the error tolerance
used when calculating the integrals required for estimating the posterior described in [7]. We
ﬁx K = 48 and δmax = 0.10 and set the error tolerance to the same value used in the rest
of our numerical experiments (typically (cid:15)tol = 0.01). To create a reference volume associated
with the ground truth, we use ˆF true as the initial starting volume. The resulting volume –
denoted by ˆF OBI(k; σBI) – will depend on the noise-estimate σBI. Note that, when σBI → 0
we will have ˆF OBI(k; σBI) → ˆF OAM(k), and when σBI → ∞ we will have ˆF OBI(k; σBI) converge
to a spherically-symmetric distribution.
In our experience the quality of the reconstructed
volume depends quite sensitively on the choice of σBI. To build a good noise-estimate, we scan
over several values of log(σBI) ∈ [−5, . . . , 0], choosing the σBI for which ˆF OBI(k; σBI) has the
highest correlation with ˆF true after the ﬁrst iteration. Fixing σopt
BI to be this optimal value,
BI ) after iterating to convergence. Thus, ˆF OBI is close to the
we deﬁne ˆF OBI(k) := ˆF OBI(k, σopt
best reconstruction possible using Bayesian inference, assuming that the optimal estimated
noise-level σBI is known ahead of time.

In addition to the above reference volumes, we also create several de-novo molecular reconstruc-
tions. RDN and EMPM below are oracle-free, while for Bayesian inference we use the optimal noise
level estimate σopt
BI

from above.

Bayesian Inference: We run the Bayesian inference reconstruction described in [7, 11] to produce
ˆF BI(k). As mentioned above, this reconstruction depends on (i) the initial starting volume,
(ii) the estimated noise-level σBI, (iii) the resolution K and the range of displacements δmax
considered, (iv) the error-tolerance used when computing the integrals in the posterior, and
(v) the number of iterations applied. We ﬁx the noise level σopt
BI to be the value obtained in
the Oracle-Bayesian method above. We ﬁx the resolution at K = 48, set δmax = 0.10, set the
error-tolerance to the same (cid:15)tol used in the other methods, and set the number of iterations
at 16. For the initial starting volume we assign each of the available images a viewing angle
randomly and uniformly, and then use a least-squares reconstruction to generate a ‘random’

7

initial starting volume. While random, this starting volume has roughly the same diameter
and bandwidth as the true molecule. We use the same procedure when initializing our strategy
below.

RDN: We run Relion’s de-novo molecular reconstruction algorithm (RDN) - a variant of Bayesian
inference - to produce ˆF RDN.
(For speed, RDN uses only subsets of images in its internal
iterations.) We use the parameters listed in section D in the Supporting Information. We
set the parameter --particle diameter to be commensurate with the true molecular diameter,
rounded up to the nearest 50˚A.

EMPM: We carry out the reconstruction using the strategy described in the Methods section
above, and discussed in more detail in the Supporting Information to produce ˆF EMPM(k). In
addition to setting the maximum frequency K and displacement δlocal, many of the computed
quantities require a numerical tolerance (cid:15)tol (see section A). We ﬁx K = 48, and scan over
(cid:15)tol ∈ [0.001, 0.010] and δlocal ∈ [0.01, 0.10]. Our strategy begins with the same random initial
viewing-angles for each image as used for Bayesian inference. As we shall see below (see, e.g.,
Fig. 3), our results are quite robust, provided that (cid:15)tol ≤ 0.01 and δlocal ≥ 0.01 or so.

For trpv1, as well as rib80s and ISWINCP, the data sets are quite clean. The ﬁrst NA = 1024
picked-particle images are well-centered, devoid of clutter and of high quality. Consequently, many of
the reconstructions we attempted were successful and RDN reconstruction was also able to achieve
Z mask > 0.5. For ps1, LSUbl16dep, MlaFEDB, LetB1, and TMEM16F, however, the individual
images are not quite as clean. In the case of ps1 and TMEM16F, many of the images are particularly
noisy. For LSubl16dep (and to a lesser extent ps1), a notable fraction of the images are poorly
centered. For MlaFEDB (and to a lesser extent TMEM16F), many of the images appear to contain
fragments of other particles. For LetB1, the viewing-angle distribution for the images is highly
concentrated around the equator. Our reconstructions for these molecules are not as successful.
Nevertheless, we still recover volumes that are comparable in quality to Bayesian inference with an
optimal estimated noise-level, and usually better than RDN reconstruction (all at a fraction of the
computational time).

Results for four molecules are shown in Fig. 1. Focusing on trpv1 for the moment, we see that
ˆF EMPM captures the coarse features of ˆF true, and is not too diﬀerent from ˆF OAM in terms of overall
quality. Even though ˆF EMPM is a coarse estimate of ˆF true, the reconstruction process has recovered a
signiﬁcant amount of information regarding the viewing-angles of each image. To illustrate this point,
we compare the image-template correlations (see Eq. 9) estimated from ˆF EMPM with the ‘ground-
truth’ image-template correlations measured from ˆF true. For each molecule of interest, three panels
are presented in Fig. 2. The left-most subplot is a scatterplot of the image-template correlations.
That is, for each image ˆAj and each template (αl, βl), we compute a point in two-dimensions with
coordinates

(Z(αl, βl; ˆAj; CT Fj; ˆF EMPM), Z(αl, βl; ˆAj; CT Fj; ˆF true)).

With NA = 1024 images and NT = 993 templates, this yields a data set with about one million
points. The color in the heatmap corresponds to the log-density of the joint-distribution at that
location (see adjacent colorbar). Note that there is a signiﬁcant correlation between the estimated-
and ground-truth-image-template-correlations. In the middle subplot for each molecule, we show a
scatterplot of the template ranks for each image (see (10)), rescaled to [0, 1] and aggregated over all
images. In the right-most subplot, we show a scatterplot of the image ranks for each template (see
(11)), rescaled to [0, 1] and aggregated over all templates. Once again, the scatterplots are presented
as heatmaps, with color corresponding to log-density.

This view of the data sheds light on the diﬀerences between maximum-likelihood and maximum-
entropy alignment. Recall that, in standard maximum-likelihood alignment, one assigns τ est
(for a
particular image ˆAj) to the template with the highest template rank. By contrast, in maximum-
entropy alignment, one does the reverse: assigning the image with highest image rank to each
sampled template direction. It is interesting to note that the estimated and ground-truth image

j

8

In this ﬁgure, we plot level sets from the volumes ˆF true, ˆF Oracle, ˆF OAM, and ˆF OBI, as well
Figure 1:
as one of the ˆF EMPM reconstructions (left to right, respectively). From the top down, the panels
correspond to trpv1, rib80s, ISWINCP and ps1.

9

Figure 2:
In this ﬁgure we illustrate the correspondence between estimated and ground-truth
viewing angles for the reconstructions shown in Fig 1. Three panels are shown for each molecule
of interest. The left-most subplot is a scatterplot of the image-template correlations. The middle
subplot is a scatterplot of the template ranks aggregated over all images, and the right-most subplot
is a scatterplot of the image ranks aggregated over all templates. All are presented as heatmaps, with
color corresponding to the log-density of the joint-distribution. (See text for further explanation.)

ranks are typically more tightly correlated than the estimated and ground-truth template ranks. We
believe that this phenomenon contributes to the success of our strategy. Indeed, when the estimated
and ground-truth template ranks are highly correlated (as for ISWINCP), the maximum-likelihood
alternating minimization method (i.e., Bayesian inference with noise-level 0) succeeds, performing
roughly as well as our strategy. However, when the estimated and ground-truth template ranks are
poorly correlated (as for ps1), then maximum-likelihoood alternating minimization does very poorly,
often converging to a volume that is worse than random.

The illustrations in Figs. 1 and 2 are obtained using just one trial of ˆF EMPM. We have carried
out extensive simulations and these results are fairly typical, with qualitatively similar results with
repeated runs. For illustration, we show the values of the volumetric correlations collected over
multiple trials in Fig. 3. The values of Z mask( ˆF EMPM, ˆF true) shown in magenta are taken over a range
of values of (cid:15)tol ∈ [0.001, 0.010], and δlocal ∈ [0.01, 0.10]. We did not see a large correlation between
either (cid:15)tol or δlocal and Z mask, provided that (cid:15)tol is suﬃciently small and δlocal is suﬃciently large
(i.e., (cid:15)tol ≤ 0.01 and δlocal ≥ 0.01). Note that, for these data sets, our strategy reliably produces
reconstructions that are similar in quality to ˆF OAM. Finally, we remark that a higher-quality low-
resolution reconstruction can help improve the results of subsequent reﬁnement. As an example,
we use Relion’s relion refine to produce a medium-resolution reconstruction from the ﬁrst 8192
images of this dataset using two diﬀerent initial-volumes. First, we set the initial volume to Relion’s
de-novo reconstruction ˆF RDN (referenced in blue in Fig. 3). Second, we set the initial volume to
the EMPM reconstruction ˆF EMPM shown in Fig. 1. Fig. 4 illustrates the Fourier shell correlations
(FSCs) between the resulting medium-resolution reconstructions and the published ˆF true. Note
that the higher-quality initial volume ˆF EMPM results in a better medium-resolution reconstruction.
Moreover, as we shall discuss below, better low-resolution reconstructions can be useful for other
quality-control tasks in the cryo-EM pipeline.

We have focused here on a subset of the proteins listed above. Addition results are deferred to

the Supporting material.

Remark 1 We have implemented our strategy in Matlab, using standard (double precision) libraries.
Even for our relatively naive implementation, the total computation time for each of our trials is
30 − 50 minutes on a desktop workstation. By comparison, the de-novo reconstruction method within

10

trpv1rib80sISWINCPps1corr (EMPM)corr (EMPM)rank (EMPM)rank (EMPM)rank (EMPM)rank (EMPM)rank (EMPM)rank (EMPM)rank (EMPM)rank (EMPM)Figure 3:
In this ﬁgure we illustrate the aligned correlation Z mask between our various reconstruc-
tions and the ground-truth for trpv1, rib80s, ISWINCP, and ps1 (see text). The diﬀerent horizontal
bars indicate the values of Z mask for diﬀerent reconstruction strategies (coded by color) with diﬀerent
trials from the same strategy adjacent to one another (sorted by Z mask).

11

OB-itEMPMOAMOracleOB-itEMPMOAMOracleOB-itEMPMOAMOracleOracleOAMEMPMOB-itFigure 4:
In this ﬁgure we show the Fourier shell correlation (FSC) associated with a medium-
resolution reconstructions produced using Relion’s relion refine applied to the ﬁrst NA = 8192
images from the trpv1 dataset (i.e., the ﬁrst NA picked-particles from the MRC 1901 ﬁle). We run
this reconstruction twice: once using as initial volume the RDN reconstruction ˆF RDN obtained using
the ﬁrst 1024 images and once using as initial volume the EMPM reconstruction ˆF EMPM. We plot
the FSC curve obtained by comparing the reconstructed volume with the published ground-truth
ˆF true. The blue (lower) curve is from the RDN initialization and the magenta (higher) curve is from
the EMPM initialization.

12

Relion typically requires 20 − 25 hours on the same machine, while a trial of Bayesian inference
(also in Matlab) requires 36 − 48 hours. It is also worth noting that, when constructing ˆF BI, we
chose the optimal noise-estimate σopt
BI . Scanning over multiple values of σBI would require additional
computation time. In summary, we believe that our strategy has the potential to be extremely eﬃcient,
especially when properly optimized.

3.1 On-the-ﬂy particle rejection

Focusing on the ps1 data set, we now consider whether our algorithm can be used to curate par-
ticles from small samples. As shown in Figs. 2 and 11, the estimated image-template correlations
Z(α, β; ˆAj; CT Fj; ˆF EMPM) are often quite strongly correlated with the true image-template correla-
tions Z(α, β; ˆAj; CT Fj; ˆF true). Motivated by this observation, we deﬁne:

QEMPM
j

= max

t

Z(αt, βt; ˆAj; CT Fj; ˆF EMPM), Qtrue

j = max

t

Z(αt, βt; ˆAj; CT Fj; ˆF true)

j

as a proxy for the
to be the maximum image-template correlation for each image. We can use QEMPM
. We see from Figs. 2 and 11 that Qj typically lies in the interval [0.1, 0.4].
‘true image-quality’ Qtrue
It is reasonable to conjecture that those images with a low estimated quality do not align well to the
reconstructed molecule and could be discarded when attempting to reconstruct the molecule. To
investigate this hypothesis, we perform a numerical experiment with the ﬁrst 1024 · 8 = 8192 images
in the EMPIAR data set, dividing these images into 8 batches of NA = 1024. For each batch we
produce a reconstruction, using our strategy above. The Z mask for these single-batch runs are shown
as magenta-dots in the ‘IND’ column of Fig. 5. The average Z mask for these single-batch runs is
∼ 0.67 (magenta line), with relatively little variation.

j

Next, we use the estimated image-quality Qj to sort the images into octiles (each with 1024
images). Those with the lowest quality scores deﬁne the ﬁrst octile and those with the highest
quality scores deﬁne the eighth octile. We now perform a reconstruction for each octile separately,
with the Z mask shown in light-pink-dots. Note that the ﬁrst few octiles produce reconstructions that
are quite a bit worse than the typical reconstructions shown in the 1K column. It is interesting
to note that, for this image pool, using exclusively the highest quality octile results in a poor
reconstruction, since the highest quality images are concentrated around a small subset of viewing-
angles. The result obtained using all NA = 8192 images together is shown as the dark-purple dot
in the ‘1st’ column. We then show successive reconstructions using diﬀerent quality cut-oﬀs. Using
the top seven octiles (7168 images), we obtain the improved Z mask shown as a dark-purple dot in
the ‘2nd’ column. Using the top six octiles, we get the dark purple dot in the ‘3rd’ column, and so
forth. In short, excluding the worst images improves the reconstruction quality, but excluding too
many images causes the quality to drop, presumably as a result of losing the coverage from noisier
projection directions.

3.2 Molecules with poor performance on small data sets

While our results can be considered moderately successful for many of the molecules, our recon-
structions for LetB1, LSUbl17dep and MlaFEDB using 1024 particles are typically quite mediocre.
For LetB1 and LSUbl17dep, diﬀerent runs of EMPM yielded reconstructions that were quite vari-
able. We suspect that this inconsistency stems from some underlying heterogeneity in the data set
itself (see [12]). For MlaFEDB, on the other hand, diﬀerent trials of EMPM yielded reconstructions
ˆF EMPM that were not close to ˆF true, but were often quite close to one another. This consistency
across trials suggests that the structures observed in the typical reconstruction might actually exist
in the image pool we are using. A recurring motif in the reconstructions is that of a cylindrical
shape with a disjoint structure oﬀ to one side. In this case, we suspect that the image pool contains
artifacts that are at least partially responsible for the mediocre performance of EMPM (as well as
BI and RDN) for this molecule.

13

Figure 5:
In this ﬁgure we illustrate the potential for improving reconstruction quality by curating
the image-pool. For this example we use the ps1 molecule, and consider the ﬁrst 1024 · 8 = 8192
images. First we divide these images into batches of NA = 1024, and produce multiple reconstruc-
tions (magenta, leftmost column). The average Z mask for these reconstructions is ∼ 0.67 (magenta
line). Next, we use the individual estimates of image-quality (see text) to divide the images into 8
‘octiles’. We perform a reconstruction using the images within each octile (light-pink). Note that
those images of poorest quality (i.e., in the ﬁrst few octiles) produce an inferior reconstruction. For
this image-pool the images with the very best quality (i.e., in the ﬁnal octile) tend to be attributed
to a small subset of viewing-angles; a reconstruction using only those images is also of rather poor
quality. We then perform a reconstruction using all the images except those below a particular octile
(dark purple). Thus, the reconstruction using all 8192 images is shown in dark-purple within the
‘1st’ column. The reconstruction using the 8192 − 1024 = 7168 images which exclude those in the
ﬁrst octile is shown in dark-purple within the ‘2nd’ column. Note that excluding the worst images
improves the reconstruction-quality. As the number of excluded images grows the number of images
used for the reconstruction shrinks; the dark-purple circles are not much higher than the light-pink
circles when the octile-index is large.

14

Reconstruction from curated image poolsINDIndependent batchesLowest quality octileHighest quality octileAlloctilesTop7octilesTop6octilesTop2octiles…..4 Discussion

As demonstrated above, our EMPM iteration (a modiﬁcation of alternating-minimization) can pro-
duce a reasonable low-resolution reconstruction from a small set of raw images. It appears to be
more robust than some currently used de-novo molecular reconstruction techniques, and at least
as accurate as Bayesian inference (with an optimally chosen estimated noise level). In addition, as
noted above, EMPM produces useful estimates of image quality and viewing angle distribution –
even when the image pool only contains a few thousand images. These estimates could play a role
in online quality-control: identifying poor images to be discarded or possibly terminating imaging
sessions that seem to be yielding poor quality data.

Because EMPM does not require any ﬁne-tuning of parameters, it should be straightforward to
incorporate into existing software pipelines. We believe that the maximum entropy step in EMPM
eﬀectively prevents spurious clustering of assigned viewing-angles, so that strong correlation between
volumes reconstructed from diﬀerent subsets of images can be interpreted as an indication that the
data set is of high quality.

We have also shown that EMPM is eﬃcient - our MATLAB implementation requires less than
5% of the computation time of RDN and Bayesian inference. Moreover, the reduction to principal
modes, as well as the various alignment and reconstruction steps can all be performed in parallel.
We hope to integrate the algorithm into existing, widely-used, high-quality software pipelines in the
near future.

References

[1] Jacqueline L S Milne, Mario J. Borgnia, Alberto Bartesaghi, Erin E H Tran, Lesley A. Earl,
David M. Schauder, Jeﬀrey Lengyel, Jason Pierson, Ardan Patwardhan, and Sriram Subrama-
niam. Cryo-electron microscopy - A primer for the non-microscopist. FEBS Journal, 280:28–45,
2013.

[2] Yifan Cheng, Nikolaus Grigorieﬀ, Pawel A. Penczek, and Thomas Walz. A primer to single-

particle cryo-electron microscopy. Cell, 161:439–449, 2015.

[3] C. L. Epstein. Introduction to the Mathematics of Medical Imaging. SIAM, 2008.

[4] F. Natterer. The Mathematics of Computerized Tomography. SIAM, 2001.

[5] Dari Kimanius, Bjorn O Forsberg, Sjors HW Scheres, and Erik Lindehl. Accelerated cryo-EM
structure determination with parallelisation using GPUs in RELION-2. eLife, 5:e18722, 2016.

[6] D. Kimanius, L. Dong, G. Sharov, T. Nakane, and Scheres S.H.W. New tools for automated

cryo-em single-particle analysis in relion-4.0. Biochem, 478:4169–4185, 2021.

[7] Sjors H W Scheres. A Bayesian view on cryo-EM structure determination. J. Mol. Biol.,

415:406–418, 2012.

[8] A. Punjani, J.L. Rubinstein, D.J. Fleet, and M.A. Brubaker. cryoSPARC: algorithms for rapid

unsupervised cryo-EM structure determination. Nat. Methods, 14:290–296, 2017.

[9] E.D. Zhong, T. Bepler, B. Berger, and J.H. Davis. Cryodrgn: reconstruction of heterogeneous

cryo-em structures using neural networks. Nature Methods, 18:176–185, 2021.

[10] Aspire software, 2022. http://spr.math.princeton.edu.

[11] Sjors H W Scheres. RELION: Implementation of a Bayesian approach to cryo-EM structure

determination. J. Struct. Biol., 180(3):519–530, 2012.

15

[12] J.H. Davis, Y.Z. Tan, B. Carragher, C.S. Potter, D. Lyumkis, and J.R. Williamson. Modular

assembly of the bacterial large ribosomal subunit. Cell, 167:1610–1622, 2016.

[13] R Bracewell. The Fourier Transform and Its Applications. McGraw-Hill, 3rd edition, 1999.

[14] Zh. Zhao and A. Singer. Rotationally invariant image representation for viewing direction

classiﬁcation in cryo-EM. J. Struct. Biol., 186:153–166, 2014.

[15] A. Barnett, L. Greengard, A. Pataki, and M. Spivak. Rapid solution of the cryo-EM recon-
struction problem by frequency marching. SIAM J. Imaging Sci., 10(3):1170–1195, 2017.

[16] Aaditya Rangan, Marina Spivak, Joakim And´en, and Alex Barnett. Factorization of the trans-

lation kernel for fast rigid image alignment. Inverse Problems, 36(2), 2020.

[17] Zh. Zhao, Y. Shkolnisky, and A. Singer. Fast steerable principal component analysis. IEEE

Trans. Comput. Imaging, 2(1):1–12, 2016.

[18] A H Barnett, J F Magland, and L af Klinteberg. A parallel non-uniform fast Fourier transform

library based on an “exponential of semicircle” kernel, 2019.

[19] F J Sigworth. A maximum-likelihood approach to single-particle image reﬁnement. J. Struct.

Biol., 122(3):328–39, 1998.

[20] S H W Scheres, M Valle, P Grob, E Nogales, and J.-M. Carazo. Maximum likelihood reﬁnement
of electron microscopy data with normalization errors. J. Struct. Biol., 166(2):234–240, 2009.

[21] F. J. Sigworth, Doerschuk P.C., J.-M. Carazo, and S.H.W. Scheres. An introduction to
maximum-likelihood methods in Cryo-EM. In Methods in Enzymology. Cryo-EM, Part B: 3D
reconstruction, pages 263–294. Academic Press., 2010.

[22] Dmitry Lyumkis, Axel F. Brilot, Douglas L. Theobald, and Nikolaus Grigorieﬀ. Likelihood-
based classiﬁcation of cryo-EM images using FREALIGN. J. Struct. Biol., 183(3):377–388,
2013.

[23] W. Baxter, R. Grassucci, Haixiao Gao, and J. Frank. Determination of signal-to-noise ratios
and spectral snrs in cryo-em low-dose imaging of molecules. Journal of structural biology, 166
2:126–32, 2009.

[24] Aaditya V Rangan. Radial-recombination for rigid rotational alignment of images and volumes.

Inverse Problems (submitted), 2022.

[25] Tamir Bendory, Ariel Jaﬀe, William Leeb, Nir Sharon, and Amit Singer. Super-resolution
multi-reference alignment. Information and Inference: A Journal of the IMA, 11(2):533–555,
02 2021.

[26] Noam Janco and Tamir Bendory. An accelerated expectation-maximization algorithm for multi-

reference alignment. IEEE Transactions on Signal Processing, 70:3237–3248, 2022.

[27] Amelia Perry, Jonathan Weed, Afonso S. Bandeira, Philippe Rigollet, and Amit Singer. The
sample complexity of multireference alignment. SIAM Journal on Mathematics of Data Science,
1(3):497–517, 2019.

16

A Supporting Information

Various aspects of the EMPM iteration are described here in greater detail. We begin with the
discretization of images and volumes in the Fourier domain, and the techniques used for image
alignment and volumetric reconstruction. Many of the techniques used require some speciﬁcation of
a ‘global tolerance’ (cid:15)tol, which could be considered a user-speciﬁed parameter. In practice, it appears
to be suﬃcient to set it to 10−2, corresponding to two digits of accuracy. In our experiments, we
actually scan over (cid:15)tol ∈ [0.001, 0.01] but ﬁnd that the quality of the reconstruction does not improve
markedly for smaller values of (cid:15)tol.
In short, EMPM is not limited by the global tolerance, but
presumably by the experimental error and the structural features of the nonconvex landscape over
which we are trying to optimize.

A.1 Manipulating images in the Fourier domain

We use x, k ∈ R2 to represent spatial position and frequency, respectively.
these vectors can be represented as:

In polar-coordinates

x = (x cos θ, x sin θ)

k = (k cos ψ, k sin ψ),

for appropriately chosen angles θ and ψ.

Deﬁnition 1 The Fourier transform of a two-dimensional function A ∈ L2(R2) is deﬁned as

ˆA(k) :=

(cid:90) (cid:90)

R2

A(x)e−ik·x dx .

We recover A from ˆA using the inverse Fourier transform:

A(x) =

(cid:90) (cid:90)

1
(2π)2

R2

ˆA(k)e+ik·x dk .

The inner-product between two functions A, B ∈ L2(R2) is written as

(cid:104)A, B(cid:105) =

(cid:90) (cid:90)

R2

A(x)†B(x) dx ,

where z† is the complex conjugate of z ∈ C. We will also use Plancherel’s theorem [13],

(cid:104)A, B(cid:105) =

1
(2π)2 (cid:104) ˆA, ˆB(cid:105) ,

∀A, B ∈ L2(R2) .

(12)

(13)

(14)

(15)

(16)

(17)

We will ignore the factors of 2π associated with the Fourier transform when they are not relevant.
We represent any given picked-particle image as a function A ∈ L2(R2), with values corresponding
to the image intensity at each location. As a consequence of Plancherel’s theorem, any inner-product
between A and another image (or 2D function) B can be calculated in either real or frequency
space, the latter of which is often more convenient when aligning images to projections of a volume
[14, 15, 16].

Abusing notation slightly, we will refer to A(k) and ˆA(k) in polar coordinates as:

A(x, θ)
ˆA(k, ψ)

:= A(x) = A(x cos θ, x sin θ)
:= ˆA(k) = ˆA(k cos ψ, k sin ψ).

(18)

(19)

With this notation each ˆA(k, ψ) for ﬁxed k and ψ ∈ [0, 2π) corresponds to a ‘ring’ in frequency space
with radius k.

17

A.2 Rotation and translation

Using the notation above, a rotation R(γ) of an image A by angle γ ∈ [0, 2π) can be represented as:

Since rotation commutes with the Fourier transform, we have:

R(γ) ◦ A(x, θ) := A(x, θ − γ).

(cid:92)[R(γ) ◦ A](k, ψ) = R(γ) ◦ ˆA(k, ψ) = ˆA(k, ψ − γ).

(20)

(21)

In this manner, a rotation of any image by +γ can be represented as an angular-shift of each
image-ring by ψ → ψ − γ.

Likewise, a translation T (δ) of an image A by the shift vector δ ∈ R2 can be represented as:

In the Fourier domain, this action can be expressed as

T (δ) ◦ A(x) := A(x − δ).

where the translation kernel (cid:98)T (δ, k) is

(cid:98)T (δ, k) (cid:12) ˆA(k),

(cid:98)T (δ, k) := e−iδ·k.

(22)

(23)

(24)

A.3 Fourier-Bessel coeﬃcients

Over the course of our molecular reconstructions, we calculate many image-image inner products (see
section 2.1). To ease the computational burden associated with these calculations, it is convenient
to use the Fourier-Bessel basis [14, 17, 15, 16].

To deﬁne the Fourier-Bessel coeﬃcients of an image, recall that each image-ring ˆA(k, ψ) (for

ﬁxed k) is a 2π-periodic function of ψ, which can itself be represented as a Fourier series in ψ:

ˆA(k, ψ) =

+∞
(cid:88)

q=−∞

a(k; q)eiqψ,

for q ∈ Z. The Fourier-Bessel coeﬃcients a(k; q) of the image ring ˆA(k, ψ) are given by

a(k; q) =

1
2π

(cid:90) 2π

0

ˆA(k, ψ)e−iqψ dψ .

(25)

(26)

These coeﬃcients can be represented in a more traditional fashion by recalling that the Bessel
function Jq(kx) can be written as:

Jq(kx) =

1
2π

(cid:90) 2π

0

e−ikx cos(ψ+π/2)−iqψ dψ ,

which, when combined with the deﬁnition of the Fourier transform, implies that:

(cid:90) (cid:90)

(cid:90) (cid:90)

(cid:90) (cid:90)

a(k; q) =

=

=

(cid:90) 2π

A(x, θ)

1
2π
A(x, θ)ei(θ+π/2) 1
2π

0

e−ikx cos(ψ−θ)−iqψ dψ xdx dθ

(cid:90) 2π

0

e−ikx cos(ψ+π/2)−iqψ dψ xdx dθ

A(x, θ)ei(θ+π/2)Jq(kx)xdx dθ ,

18

(27)

(28)

(29)

(30)

which is the inner product between the original image (in real space) and a Bessel function.

Note that, using the Fourier-Bessel representation of an image, the rotation Rγ can now be

represented as:

Rγ ˆA(k, ψ) = ˆA(k, ψ − γ)

=

=

+∞
(cid:88)

q=−∞

+∞
(cid:88)

q=−∞

a(k; q)eiq(ψ−γ)

a(k; q) · e−iqγeiqψ,

(31)

(32)

(33)

such that the Fourier-Bessel coeﬃcients of the rotated image ring Rγ ◦ ˆA(k, ·) are given by the
original Fourier-Bessel coeﬃcients a(k; q), each multiplied by the phase-factor e−iqγ. Note that
(33) easily allows for arbitrary rotations by any γ, requiring only a pointwise multiplication by the
appropriate phase factor. This observation allows for the eﬃcient alignment of one image to another
(see [15, 16]).

A.4 Image discretization

We denote by Ω(1) and Ω(K) the ball of radius 1 and K, respectively, in either real or frequency
space:

Ω(1) := {x ∈ R2 such that (cid:107)x(cid:107) ≤ 1}, Ω(K) := {k ∈ R2 such that (cid:107)k(cid:107) ≤ K},

(34)

and we will assume that all the images considered are supported in Ω(1). The support constraint
A(x) ⊆ Ω(1) implies that the representation ˆA(k) will have a bandlimit of 1, so that ˆA can be
accurately reconstructed from its values sampled on a frequency grid with spacing O(1) [18].

We also assume that any relevant signal within the images has a maximum eﬀective spatial-
frequency magnitude of K; i.e., that the salient features of ˆA are concentrated in k ∈ ΩK. Conse-
quently, we expect that the inversion

A(x) ≈

1
(2π)2

(cid:90) (cid:90)

ΩK

ˆA(k)eik·x dk

(35)

accurately reconstructs A to the resolution associated with K (ignoring high frequency ringing
artifacts). When these assumptions hold we won’t lose much accuracy when applying these trans-
formations in a discrete setting (as discussed below).

Note that the largest K that we can reasonably expect to attain is related to the number of pixels
‘N ’ in the original image. More speciﬁcally, once we assume that A(x) is supported in x ∈ Ω(1), the
pixel-spacing will be ∆x = 2/N , implying the Nyquist spatial-frequency is given by π/∆x = N π/2.
Since we are using NA picked-particle images Aj to produce a low-resolution estimate of the
imaged molecule (denoted F below), we will typically choose K to be signiﬁcantly smaller than
N π/2, often in the range of K ∼ 50. Given the pixel spacing, this corresponds to a low-resolution
reconstruction with approximately 20˚Aresolution. Additionally, the fact that x ≤ 1 implies that
the Bessel coeﬃcients a(k, q) will be concentrated in the range |q| (cid:46) k, meaning that the Bessel
coeﬃcients a(k, q) across all k ∈ [0, K] will be concentrated in q ∈ [−Q/2, +Q/2 − 1] for Q =
O(K) = O(N ).

With the notation above, we can consider an N × N image as a discrete set of pixel-averaged

samples within [−1, +1]2:

An1,n2 =

1
∆x2

(cid:90) (n1+1)∆x

(cid:90) (n2+1)∆x

n1∆x

n2∆x

A(x1, x2) dx2dx1

(36)

19

for indices n1, n2 ∈ {0, . . . , N − 1}. We approximate the Fourier transform ˆA at any k ∈ R2 via the
simple summation:

ˆA(k) = (∆x)2

N −1
(cid:88)

N −1
(cid:88)

n2=0

n1=0

An1,n2e−ik·xn1,n2 ,

(37)

where xn1,n2 is the appropriately-chosen pixel-center ∆x (cid:0)n1 + 1
(cid:1). Because we have assumed
that the image is suﬃciently well sampled (i.e., that ˆA contains little relevant frequency-content
above the Nyquist-frequency K), we expect the simple sum above to be accurate.

2 , n2 + 1

We will typically evaluate ˆA(k) for k on a polar-grid, with k- and ψ-values corresponding to
suitable quadrature nodes, using the non-uniform FFT (NUFFT) to compute ˆA(k, ψ) at those nodes
(see [18, 16]). The quadrature in k corresponds to a set of R nodes: k1, . . . , kR and radial weights
w1, . . . , wR so that

2

(cid:90) K

0

g(k)kdk ≈

R
(cid:88)

r=1

g(kr)wr

(38)

to high accuracy for a smooth function g(k). The exact radial quadrature nodes we select are usually
those inherited from a volumetric grid (see section A.6 below). For convenience, we will sometimes
refer to the weight function w(k) as some continuous interpolant of the quadrature-weights, with
w(kr) = wr. The Q angular-nodes ψ0, . . . , ψQ−1 are equispaced in the periodic interval [0, 2π), with
a spacing of ∆ψ = 2π/Q, and ψq(cid:48) = q(cid:48)∆ψ. These equispaced ψ-nodes allow for spectrally accurate
trapezoidal quadrature in the ψ-direction, and we approximate the Fourier-Bessel coeﬃcients of each
image-ring ˆA(k, ψ) as follows:

a(k, q) ≈

Q−1
(cid:88)

q(cid:48)=0

ˆA(k, ψq(cid:48)) exp (−iqψq(cid:48)) ∆ψ,

(39)

with the index q considered periodically in the interval [−Q/2 − 1, . . . , +Q/2] (so that, e.g., the
q-value of Q − 1 corresponds to the q-value of −1).

A.5 Inner products

The inner-product between an image A and a rotated and translated version of image B is denoted
by:

X (γ, δ; A, B)

:= (cid:104)R(γ) ◦ A, T (δ) ◦ B(cid:105),

and (ignoring factors of 2π) is approximated by:

X (γ, δ; ˆA, ˆB) ≈

(cid:90) (cid:90)

Ω(K)

(cid:104)
R(γ) ◦ ˆA(k)

(cid:105)†

(cid:104)
(cid:98)T (δ, k) (cid:12) ˆB(k)

(cid:105)

·

dk.

The expression X can be thought of as a bandlimited inner product.

(40)

(41)

A.6 Volume notation

We use x, k ∈ R3 to represent spatial position and frequency, respectively. In spherical coordinates,
the vector k is represented as:

k = k · ˆk, with ˆk = (cos φ sin θ, sin φ sin θ, cos θ),

(42)

with polar angle θ and azimuthal angle φ representing the unit vector ˆk on the surface of the sphere
S2.

20

Using a right-handed basis, a rotation about the third axis by angle α is represented as:





Rz(α) =

+ cos α − sin α 0
+ sin α + cos α 0
1

0

0



 ,

and a rotation about the second axis by angle β is represented as:





Ry(β) =

+ cos β 0 + sin β
1
− sin β 0 + cos β

0

0



 .

(43)

(44)

A rotation R(τ ) of a vector k ∈ R3 can be represented by the vector of Euler angles τ = (α, β, γ):

R(τ ) · k = Rz(α) ◦ Ry(β) ◦ Rz(γ) · k.

(45)

We represent a given volume as a function F ∈ L2(R3), with values corresponding to the intensity
at each location x ∈ Ω(1). We will refer to ˆF (k) in spherical coordinates as ˆF (k, ˆk). With this
notation, each ˆF (k, ·) corresponds to a ‘shell’ in frequency-space with radius k. The rotation of any
volume R(τ ) ◦ ˆF (k, ˆk) corresponds to the function ˆF (k, R(τ −1) · ˆk), where τ −1 corresponds to the
vector of Euler angles τ −1 = (−γ, −β, −α).

A.7 Spherical harmonics
Using the notation above, we can represent a volume ˆF (k, ˆk) as:

ˆF (k, ˆk) =

+∞
(cid:88)

m=+l
(cid:88)

l=0

m=−l

f (k; l, m)Y m

l (ˆk),

where Y m

l (ˆk) represents the spherical harmonic of degree l and order m:

l (θ, φ) = Z m
Y m

l e+iφP m

l (cos θ),

with P m
ization constant:

l

representing the usual (unnormalized) associated Legendre function, and Z m
l

(cid:115)

Z m

l =

2l + 1
4π

×

(l − |m|)!
(l + |m|)!

.

The coeﬃcients f (k; l, m) deﬁne the spherical harmonic expansion of the k-shell ˆF (k, ·).
Given a rotation τ = (α, β, γ), we can represent the rotated volume ˆG := R(τ ) ˆF as:

gm1
l =

m2=+l
(cid:88)

m2=−l

e−im1γdl

m1,m2

(β)e−im2αf m2

l

,

(46)

(47)

the normal-

(48)

(49)

where dl
β.

m1,m2

(β) represents the Wigner d-matrix of degree l associated with the second Euler angle

A.8 Volume discretization

As with our discretization of images, we assume that the volume F (x) is supported in Ω(1), and
that the relevant frequency content is contained in Ω(K).

We then discretize the radial component of Ω(K) ∈ R3 using a Gauss-Jacobi quadrature for
k built with a weight-function corresponding to a radial weighting of k2dk; the number of radial
quadrature nodes R will be of the order O(K). On each of the k-shells, we build a quadrature for

21

ˆk that discretizes the polar-angle β using a legendre-quadrature on [0, π], and the azimuthal-angle
α using a uniform periodic grid in [0, 2π), with associated weights designed for integration on the
surface of the sphere; the total number of spherical-shell-quadrature-nodes T (kr) for any particular
kr need only be O(k2

Each of the k-shells ˆF (kr, ·) can be accurately described using spherical harmonics of order
l = O(kr). Thus, the number of spherical-harmonic coeﬃcients required for each shell ˆF (kr, ·) is
r ). The total number of spherical-harmonic coeﬃcients required to approximate ˆF (k, ˆk) over
O(k2
Ω(K) is O(K 3), with a maximum degree of L = O(K). The associated maximum order will be
M = 1 + 2L, which is also O(K).

r ) [15].

A.9 Template generation
Given any volume ˆF (k), we can generate templates eﬃciently using the techniques described in [15],
which make use of the spherical harmonic representation f (k; l, m). For our purposes, we generate
the templates described in Eq. 7 for a collection of viewing directions (αt, βt), for t ∈ {1, . . . , T }.
The particular choice of the third Euler angle (γt) for each of the templates is dictated by the
strategy for template generation in [15], and does not play an important role, since it corresponds to
an in-plane rotation of the relevant slice. We discretize the set of viewing directions to correspond
with the ˆk discretization on the largest k-shell in our volumetric (spherical) quadrature grid: that
is, T := T (kR). These viewing directions will be used to enumerate the templates (i.e., NS = T ).
Each of the templates are stored on a polar or Fourier-Bessel grid identical to those used to store
the images.

Image noise model

A.10
We assume that each of the picked-particle images ˆAj is a noisy version of a ‘signal’ corresponding
to a 2-dimensional projection of some (unknown) molecular electron-density-function F true:

ˆAsignal(k) = T (+δtrue

j

, k) (cid:12) ˆS(τ true

j

; CT F ; ˆF )(k),

(50)

j

and δtrue

correspond to the true (but unknown) viewing-angle and displacement associated
where τ true
with image ˆAj. In this context we say the image’s ‘true viewing direction’ is deﬁned by the ﬁrst two
Euler angles in τ true

, namely the azimuthal and polar angles αtrue

and β true

.

j

j

j

j

We will model the noise in real space as independent and identically distributed (iid), with a
variance of σ2 on a unit scale in two-dimensional real space. This is a simple model of detector noise
[19, 20, 21, 22], and does not take into account more complicated features, such as structural noise
associated with image preparation (see [23]). We assume that the image values are the sum of the
signal plus noise:

An1,n2 = A(xn1,n2) = Asignal
n1,n2

+ Anoise
n1,n2

,

(51)

where the signal and noise are represented by the arrays Asignal
n1,n2
each entry in Anoise
n1,n2
pixel, we expect the variance of each Anoise
n1,n2
assume that each element of the noise array Anoise
n1,n2

, respectively. Because
corresponds to an average over the area-element ∆x2 associated with a single
to scale inversely with ∆x2. That is to say, we’ll
is drawn from the standard normal distribution
, with zero mean and a variance of σ2/∆x2. With these assumptions, downsampling the
N
image by averaging neighboring pixels will correspond to an increase in the eﬀective pixel-size and
a simultaneous reduction in the variance of the noise associated with each (now larger) pixel.

and Anoise
n1,n2

0, σ2
∆x2

(cid:16)

(cid:17)

Given the assumptions above, ˆA will be modeled by:

ˆA(k) = ˆAsignal(k) + ˆAnoise(k),

(52)

where ˆAnoise is now complex and iid. Because the noise-term Anoise is real, the noise-term ˆAnoise will
be complex, with the conjugacy constraint that ˆAnoise(+k) = ˆAnoise(−k)†.

22

A.11 Variance Scaling

ˆσ2
wr∆ψ .

We deﬁne ˆσ2 = π2σ2
∆x2 as the variance on a unit scale in two-dimensional frequency space. We expect
ˆσ2
that the noise term ˆAnoise(k) integrated over any area element ∆k2 will have a variance of
∆k2 .
Recalling our polar quadrature described above, we typically sample k along R radial quadrature
nodes k1, . . . , kR and Q angular quadrature nodes ψ0, . . . , ψQ−1, with radial and angular weights wr
and ∆ψ, respectively. In this quadrature scheme, each quadrature node krq = (kr, ψq) is associated
with the area element wr∆ψ, which approximates the ‘kdk’ integration weight. Consequently, we
expect that the noise term ˆAnoise(krq) evaluated at (kr, ψq) on our polar quadrature grid will have
a variance of

Given the radially-dependent variance associated with each degree of freedom in the images, we
√
will typically consider rescaled images ˆA(kr, ψq)
wr∆ψ, rather than the raw image values ˆA(kr, ψq).
Fro simplicity, we will often write this as ˆA(k)(cid:112)w(k), where we assume that ∆ψ is the same for
every k-value, and w(k) is some functional interpolant of the quadrature weights with w(kr) = wr.
This rescaling allows us to equate the standard vector 2-norm with the L2 integral (up to quadrature
error):

r=R
(cid:88)

q=Q
(cid:88)

r=1

q=1

(cid:107) ˆA(kr, ψq) · (cid:112)wr∆ψ(cid:107)2 ≈

(cid:90) k=K

(cid:90) ψ=2π

k=0

ψ=0

(cid:107) ˆA(k, ψ)(cid:107)2kdkdψ.

This rescaling will allow our deﬁnition of the radial objective function below to correspond to a
standard log-likelihood (see (55) in section A.14). In a similar fashion, the least-squares formulation
we will use for volume reconstruction corresponds to a maximum-likelihood estimate, with similar
properties holding for the inner products used for alignment (see sections A.18 and A.22 below).

A.12 Radial Principal Modes

In these sections, we brieﬂy review the notion of radial principal modes for image compression,
described in [24]. The premise is simple: given an image ˆA(k, ψ), not all the frequency rings ˆA(k, ·)
are equally useful. By selecting the appropriate linear combinations of frequency rings, we can
compress the images while retaining information useful for alignment. We choose the coeﬃcients
of this linear combination by solving an eigenvalue problem, which is why we refer to these linear
combinations as principal modes.

This strategy has two beneﬁts. The ﬁrst is to make the overall computation more eﬃcient;
rather than retaining all R ≈ 50 radial quadrature nodes, we can often compress the majority of
relevant information into a smaller number of principal modes (typically 10-16). The second beneﬁt
is that, by retaining only those principal modes which are useful for alignment, we explicitly avoid
those degrees of freedom within the original images that are dominated by noise and not useful
for alignment. The same set of modes can be used for the experimental images and the estimated
volumes. We make use of this compression for both the alignment and reconstruction steps of our
EMPM iteration.

A.13 Principal image rings and principal volume shells

(cid:124)
Let us assume that we are given a unit vector u = [u1, u2, . . . , uR]
combination [u(cid:124) ˆA](ψq) as:

∈ RR. We deﬁne the linear

[u(cid:124) ˆA](ψq) =

R
(cid:88)

r=1

ur ˆA(kr, ψq)(cid:112)wr∆ψ,

(53)

wr∆ψ is designed to equalize the variances associated with the diﬀerent

where the rescaling factor
k-values (see section A.11).

√

In a moment, we will choose our u to be one of the eigenvectors of an R × R matrix, and we will
refer to the linear combination [u(cid:124) ˆA](ψq) as the ‘principal image ring’ associated with u. Note that,

23

based on our noise model, we assume that the image noise is iid across image-rings. Consequently,
the variance of the noise [u(cid:124) ˆAnoise](ψq) is equal to (cid:80)
r ˆσ2, which is equal to (cid:107)u(cid:107)2 ˆσ2. Because u is
a unit vector, this last expression is simply ˆσ2, which is the same as the variance of any individual
term ˆAnoise(kr, ψq) for any particular kr. Moreover, if we consider two orthonormal vectors u1 and
(cid:124) ˆAnoise](ψq) will be independent random variables, each drawn from
u2, then [u1
N (0, ˆσ2).

(cid:124) ˆAnoise](ψq) and [u2

r u2

The same strategy can be used to deﬁne a principal volume shell [u(cid:124) ˆF ](ˆk) as:

[u(cid:124) ˆF ](ˆk) =

R
(cid:88)

r=1

ur ˆF (kr, ˆk)(cid:112)wr∆ψ,

(54)

using the same weights as those used for the principal image rings. In most situations, we will assume
that the angular discretization ∆ψ is uniform across all the image rings, allowing us to ignore the
√

∆ψ factor in the rescaling-factor above.

A.14 Choice of principal modes

To select the actual principal modes used above, we construct the following objective function for
the vector u:

C(u; F, µτ , µδ, µCT F ) =

(cid:90)

· · ·

(cid:90) (cid:13)
(cid:13)
2
(cid:13)u(cid:124) ˆS(τ, δ; CT F, F ) − u(cid:124) ˆS(τ (cid:48), δ(cid:48); CT F (cid:48), F )
(cid:13)
(cid:13)
(cid:13)
(cid:0)δ(cid:48)(cid:1) dµCT F (CT F )dµCT F (CT F (cid:48)),

·

(55)

dψdµτ (τ ) dµτ (τ (cid:48)) dµδ (δ) dµδ

where ˆS(τ, δ; CT F ; F ) is the usual noiseless image template associated with viewing-angle τ , dis-
placement δ and the contrast-transfer-function CT F (k). The integral in (55) is taken over the
distributions of viewing angle, displacement and CTF function (i.e., µτ , µδ and µCT F , respectively).
Given a volume F , as well as distributions µτ , µδ and µCT F , the objective function C(u) is (up
to an aﬃne transformation) equal to the negative log-likelihood of mistaking one noiseless principal
image ring (constructed using principal-vector u) for a randomly rotated version of another (also
constructed using u). Those vectors u for which C(u) is high correspond to linear combinations of
frequencies which are useful for alignment (i.e. for which the typical principal image rings look very
diﬀerent from one another). Conversely, those vectors u for which C(u) is low correspond to linear
combinations of frequencies which are not useful for alignment (i.e., for which the typical principal
image rings look quite similar to one another).

The objective function C(u) is quadratic in u, which means that it can be optimized by ﬁnding

the dominant eigenvector of the Hessian C := ∂uuC, deﬁned as the R × R matrix:

C(u) = u(cid:124) · C · u.

Moreover, the corresponding eigenvalue will be equal to the objective function C for that eigenvector.
To actually compute the Hessian C in practice, we use one of two strategies.

A.15 Empirical principal modes

At ﬁrst, when we have no good estimate of either F or the distributions µτ , µδ or µCT F , we simply
use the images Aj themselves to form a Monte Carlo estimate of the integral in (55). This boils
down to the following simple approximation:

C(u)empir =

1
N 2
A

(cid:88)

j,j(cid:48)

(cid:90) (cid:90) (cid:90) (cid:13)
(cid:13)u(cid:124)R(γ) ˆAj − u(cid:124)R(γ(cid:48)) ˆAj(cid:48)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

dψdγdγ(cid:48),

(56)

where we have replaced the noiseless images ˆS(τ, δ; CT F ; F ) and ˆS(τ, δ; CT F ; F ) in the integrand
of Eq. 55 with randomly selected images ˆAj and ˆAj(cid:48) from the original image pool, and used the

24

empirical distribution of the images themselves to stand in for the unkown µτ , µδ and µCT F (after
averaging over the in-plane rotations associated with γ and γ(cid:48)). The associated kernel C empir then
reduces to:

C(r, r(cid:48))empir ∝

√

wrwr(cid:48) ·






1
NA

(cid:88)

(cid:88)

j

q

aj(kr, q)†aj(kr(cid:48), q) −



(cid:88)



j

1
N 2
A



† 

a(kr, 0)



(cid:88)



j

a(kr(cid:48), 0)





 .


(57)

A.16 Estimated principal modes

Once we have a reasonable estimate of the imaged volume F estim, we can use it (along with the
) to calculate C estim via (55). In practice, we typically
current estimated distributions µestim
is an isotropic Gaussian centered at the origin with a standard
assume that µestim
deviation estimated using the current δestim
. With these assumptions the associated kernel C estim
j
can be computed analytically from the spherical harmonic coeﬃcients f (k; l, m):

is uniform and µestim

and µestim

δ

δ

τ

τ

C estim

r,r(cid:48) ∝ +

(cid:112)

WrWr(cid:48) ·

(cid:34)+∞
(cid:88)

m=+l
(cid:88)

(cid:35)
f (kr; l, m)†f (kr(cid:48); l, m)

· E+(kr, kr(cid:48))

l=0

m=−l

(cid:112)

−

WrWr(cid:48) · (cid:2)f (kr; 0, 0)†f (kr(cid:48); 0, 0)(cid:3) · E−(kr) · E−(kr(cid:48)),

as Q → ∞, where the CTF-modulated weight Wr takes the form:

(cid:112)

Wr =

√

wr
NA

(cid:88)

j

CT Fj(kr),

and the terms E+ and E− denote

E+(kr, kr(cid:48)) = exp

(cid:18)

−

σ2
δ
2

(cid:2)k2

r + k2
r(cid:48)

(cid:19)
(cid:3)

· exp (cid:0)krkr(cid:48)σ2

δ

(cid:1) ,

and

E−(kr) = ˜kr

(cid:114) π
2

exp

(cid:16)

−˜k2
r

(cid:17) (cid:16)

I−1/2(˜k2

r ) − I+1/2(˜k2
r )

(cid:17)

,

(58)

(59)

(60)

(61)

(62)

where ˜kr = krσδ/2, and Iq refers to the modiﬁed Bessel function of ﬁrst kind of order q.

A.17 Multiple principal modes

We select the principal modes u1, . . . , uH to be the dominant H eigenvectors of the kernel C. We
typically choose H such that the (H + 1)-th eigenvalue of C is less than the global tolerance times
the ﬁrst (dominant) eigenvalue of C. When we set the global tolerance to be (cid:15)tol ∼ 1e − 2 in
our numerical experiments below, this selection criterion typically corresponds to selecting 12 − 16
principal modes from C empir, and slightly fewer (10 − 14) from C estim.

We will refer to the matrix U as the collection of H principal modes:

and refer to the collection of respective principal images as U (cid:124) ˆA:

U = (cid:2) u1 u2

· · ·

uH

(cid:3) ,

U (cid:124) ˆA = (cid:2) u1
(cid:104)

such that

(cid:124) ˆA u2

(cid:124) ˆA · · ·

(cid:124) ˆA (cid:3) ,

uH

(cid:105)
U (cid:124) ˆA

(h, ψ) =

(cid:104)
uh

(cid:105)
(cid:124) ˆA

(ψ).

25

(63)

(64)

We use the same convention for principal volumes:

U (cid:124) ˆF = (cid:2) u1

(cid:124) ˆF u2

(cid:124) ˆF · · ·

(cid:124) ˆF (cid:3) ,

uH

such that

(cid:104)

U (cid:124) ˆF

(cid:105)

(h, ˆk) =

(cid:104)
uh

(cid:124) ˆF

(cid:105)

(ˆk).

(65)

We will also refer to the Bessel and spherical harmonic representations of the principal images and
principal volumes as U (cid:124)a and U (cid:124)f , respectively.

A.18 Volume reconstruction

Most approaches to estimating molecular volumes in cryo-em involve some kind of reconstruction
process which is performed multiple times (over the course of iterative reﬁnement). For standard
AM, the inputs to the reconstruction process are the collection of NA picked particle images ˆAj(k)
and associated CTF-functions CT Fj(k), along with estimates of the viewing angles τ estim
and dis-
placements δestim

. The output is the estimate ˆF estim(k).

j

j

In our case, we will make use of both the standard least-squares reconstruction, as well as a
more computationally eﬃcient approximate Fourier inversion which we refer to as ‘quadrature-back-
propagation’ (section A.20 below).

A.19 Least-squares reconstruction

The standard strategy for reconstruction typically involves solving a linear system in a least-squares
sense. In real-space this least-squares system looks like:






P SD1(x) (cid:63) T (+δ1) ◦ {S ◦ R(τ1)◦}
...
P SDNA(x) (cid:63) T (+δNA) ◦ {S ◦ R(τNA)◦}






 · F (x) ≈









A1(x)
...
ANA (x)

whereas in the Fourier domain it is written as:








CT F1(k) (cid:12) T (+δ1, k) (cid:12)

(cid:110) ˆSl ◦ R(τ1)◦

(cid:111)

...

CT FNA (k) (cid:12) T (+δNA, k) (cid:12)

(cid:110) ˆSl ◦ R(τNA )◦
(cid:111)








· ˆF (k) ≈






ˆA1(k)
...
ˆANA (k)






or, more conveniently,








CT F1(k) (cid:12)

CT FNA(k) (cid:12)

(cid:111)

(cid:110) ˆS ◦ R(τ1)◦
...
(cid:111)
(cid:110) ˆS ◦ R(τNA )◦








· ˆF (k) ≈






T (−δ1, k) (cid:12) ˆA1(k)
...
T (−δNA, k) (cid:12) ˆANA (k)




 .

(66)

In this expression, the NA viewing angles τj and displacements δj are assumed to be given as input,
as are the image- or micrograph-speciﬁc CTF functions CT Fj(k) and images ˆAj(k). The unknown
(to be determined) is the volume ˆF (k).

This least-squares problem is standard in maximum-likelihood estimation, and versions of this
problem are solved in many software packages, often via conjugate gradient iteration applied to the
normal equations.

As written, the least-squares problem above has a block-structure: diﬀerent k values are inde-
pendent from one another. Thus, the problem can be solved by determining the k-shell ˆF (k, ˆk)
from the k-rings ˆAj(k, ψ) for one k value at a time. However, the problem stated in (66) is slightly
misleading, as the residuals for each of the k values are not directly comparable due to the fact that

26

diﬀerent k-shells have diﬀerent variances associated with them (see section A.11). To account for
this, we rewrite (66) as:








(cid:112)w(k) · CT F1(k) (cid:12)

(cid:111)
(cid:110) ˆSl ◦ R(τ1)◦

...

(cid:112)w(k) · CT FNA(k) (cid:12)

(cid:111)
(cid:110) ˆSl ◦ R(τNA)◦








· ˆF (k) ≈






(cid:112)w(k) · T (−δ1, k) (cid:12) ˆA1(k)
...
(cid:112)w(k) · T (−δNA, k) (cid:12) ˆANA (k)




 , (67)

where the function w(kr) is the radial quadrature weight. With this formulation, the residual
(calculated using the standard vector 2-norm) is (up to a quadrature error) equal to an integral
representing the log-likelihood that the volume ˆF (k) could have produced the observed images
ˆAj(k) (under the assumptions about the noise-model described in section A.10).

A.20 Principal-mode least-squares reconstruction

The same general methodology above can be applied to the principal images directly. To describe the
modiﬁed least-squares system, we ﬁrst deﬁne the low-rank decomposition of the radial component
of the CTF-functions. Let CT F (k, j) correspond to the radial component of the CTF-function
CT Fj(k). Using the discretized analog of a functional SVD we represent CT F (k, j) by

CT F (k, j) =

(cid:88)

h(cid:48)

h(cid:48)(k) · σ(cid:48)
u(cid:48)

h(cid:48)v(cid:48)

h(cid:48)(j),

(68)

which we can truncate at rank H (cid:48) in accordance with the global tolerance. In the numerical exper-
iments we present below, the image pools typically span 30 or so micrographs, usually resulting in
H (cid:48) about 2 − 3.

Using this H (cid:48)-rank decomposition of the CTF-array (across the image pool), we can approxi-

mately represent the noiseless principal images as follows:

CT Fj(k) (cid:12)

(cid:110) ˆSl ◦ R(τj) ◦ ˆF

(cid:111)

(k) ≈

H (cid:48)
(cid:88)

h(cid:48)=1

h(cid:48)(j)σ(cid:48)
v(cid:48)

h(cid:48) · u(cid:48)

h(cid:48)((cid:107)k(cid:107)) (cid:12)

(cid:110) ˆSl ◦ R(τj) ◦ ˆF

(cid:111)

(k).

(69)

After using the radial principal modes to compress both this approximation and the associated
component of the right hand side of (67), we obtain:

H (cid:48)
(cid:88)

h(cid:48)=1

h(cid:48)(j)σ(cid:48)
v(cid:48)

h(cid:48) · uh

(cid:124) (cid:104)

u(cid:48)
h(cid:48)(k) (cid:12)

(cid:110) ˆSl ◦ R(τj) ◦ ˆF

(cid:111)

(cid:105)
(k)

= uh

(cid:124) (cid:104)

(cid:105)
T (−δj, k) (cid:12) ˆA(k)

.

(70)

By deﬁning the CTF-modulated principal volume:

ˆG(k, ˆk; h(cid:48), ˆF ) = U (cid:124) ·

(cid:104)

h(cid:48)(k) (cid:12) ˆF (k, ˆk)
u(cid:48)

(cid:105)

,

we can now write the compressed least-squared problem as:
(cid:111)
(cid:110) ˆS ◦ R(τ1)◦







v(cid:48)
h(cid:48)(1)

H (cid:48)
(cid:88)

h(cid:48)=1

σ(cid:48)
h(cid:48)






...

(cid:110) ˆS ◦ R(τNA )◦

(cid:111)

v(cid:48)
h(cid:48)(NA)






· ˆG(k; h(cid:48), ˆF ) ≈

U (cid:124) (cid:104)

(cid:105)

T (−δ1, k) (cid:12) ˆA1(k)
...
(cid:105)
T (−δNA, k) (cid:12) ˆANA (k)

U (cid:124) (cid:104)













,

(71)

where the radial reweighting of (cid:112)w(k) in (67) is accounted for by our deﬁnition of U (cid:124). Note that,
when H (cid:48) = H = R the equation above is equivalent to (67). However, when H (cid:48) < R and H < R
this will correspond to a projected version of (67).

27

Note also that, with this representation, we need not actually solve for ˆF (k). Instead, we can
use the principal images (on the right hand side) to solve the above problem (in a least-squares
sense) for the collection of CTF-modulated principal volumes ˆG(k; h(cid:48), ˆF ). Solving (71) can be less
computationally costly than solving (67) when the total number of degrees of freedom within the
various ˆG is less than the total number of degrees of freedom within ˆF (i.e., when H × H (cid:48) < R).
Even when this is not the case, the CTF-modulated principal volumes ˆG (the solution to (71)) can
still be more accurate (in terms of comparison to the ground truth) than the solution ˆF to (67). We
see this improvement most acutely when the principal mode reduction U (cid:124) eﬀectively removes noise
from the images ˆAj (e.g., if there are many frequency rings which contain little to no information).
We remark that, when dealing with least-squares reconstruction and principal mode reduction,
‘the diagram commutes’. That is, because the principal mode projection U (cid:124) is orthonormal, the
principal mode projection U (cid:124) (cid:110)
(i.e., the principal projection of the full volume which
solves the original least-squares problem in (67)) will be the same as the solution (cid:80)
h(cid:48) v(cid:48)σ(cid:48) ˆG to the
principally-projected least-squares problem in (71), provided of course that the H (cid:48)-rank decomposi-
tion of the CTF-array is accurate (e.g., if H (cid:48) is taken to R). Thus, if H × H (cid:48) is indeed larger than R,
then instead of solving (71), we can obtain ˆG more easily by just solving the original least-squares
problem for ˆF and then projecting down to the CTF-modulated principal volumes ˆG.

CT F · ˆF

(cid:111)

Note also that, due to linearity, the noiseless images associated with the CTF-modulated principal
volumes ˆG will approximately equal the noiseless principal images associated with the volume ˆF ,
with errors controlled by the truncation H (cid:48) of the CTF-values. That is to say, a principal mode
compression of (69) can be written as:

U (cid:124) (cid:104)

CT Fj(k) (cid:12)

(cid:110) ˆS ◦ R(τj) ◦ ˆF

(cid:111)

(cid:105)
(k)

≈

H (cid:48)
(cid:88)

h(cid:48)=1

h(cid:48)(j)σ(cid:48)
v(cid:48)

h(cid:48) ·

(cid:110) ˆS ◦ R(τj) ◦ ˆG(k; h(cid:48), ˆF )

(cid:111)

(k). (72)

This relationship can be used to align the principal images U (cid:124) ˆAj directly to the solution ˆG, without
necessarily needing to reconstruct ˆF (see section A.22).

In our experience, an accurate
Reconstruction via quadrature back propagation (QBP)
approximation of the solution to the least-squares problem above can require a signiﬁcant amount
of computation time when the conjugate gradient method requires many iterations to converge. As
a more eﬃcient (but typically less accurate) alternative, we employ a slightly diﬀerent strategy. We
refer to this alternative as ‘quadrature-back-propagation’ (QBP).

The basic observation underlying QBP is that, assuming that there was no image noise and no

CTF-attenuation, then the volume and images would solve:






ˆSl ◦ R(τ1)◦
...
ˆSl ◦ R(τNA )◦


 · ˆF =







T (−δ1, k) (cid:12) ˆA1(k)
...
T (−δNA , k) (cid:12) ˆANA (k)






with each template ˆSl ◦ R(τj) ◦ ˆF corresponding to a cross-section of the volume ˆF (k). Each of
these cross-sections can be viewed as a sample of the overall volume ˆF (k), with values given by
the appropriate entry on the right-hand-side of the equation above. With suﬃciently many cross-
sectional samples, a functional representation of the volume ˆF can be reconstructed via quadrature
in the spherical harmonic basis via a spherical harmonic transform. That is, we have the approximate
formula

f (k; l, m) ≈

(cid:88)

(cid:104)

wp

l (ˆkp)
Y m

(cid:105)†

ˆF (k, ˆkp) ∀ l, (cid:107)m(cid:107), l(cid:48), (cid:107)m(cid:48)(cid:107) ≤ L.

where {ˆkp, wp} correspond to a quadrature rule on the sphere. The number of such nodes is of the
order [O(k)]2 on the spherical k-shell. (Equispaced points in the azimuthal direction and Legendre

p

28

points in the polar angle, for example, are spectrally accurate.) Because the data points will not
generally coincide with the necessary quadrature nodes, we interpolate from the given data to the
nodes in some local neighborhood. A simple rule would be to take the local average over all data
points that lie within some distance of the node. Note that this strategy is not iterative and is
typically an order of magnitude (or so) faster than a least-squares reconstruction.

In the absence of image-noise, the error in the reconstruction of f (k; l, m) will come from the
‘interpolation error’ associated with interpolating from the cross-sectional sample data to the quadra-
ture nodes. When the image-noise is nonzero and the interpolation regions are ﬁxed in size, then the
approximation to ˆF (k, ˆkp) will exhibit two sources of error. In addition to the interpolation error,
there is a sampling error due to the image noise at each cross-sectional sample-point. In practice, we
generally choosing the local neighborhood of the quadrature nodes to be suﬃciently large to contain
roughly O(101−2) sample points. This is usually suﬃcient for two digits of accuracy (coinciding with
our usual global error tolerance).

The above strategy can easily be generalized to deal with image-speciﬁc CTF-values. The QBP
approach above essentially treats each sample within the local interpolation region of each quadrature
node as a noisy observation of ˆF (k, ˆkp). The average can be thought of as a local maximum-likelihood
estimate. Since diﬀerent data points might correspond to diﬀerent CTF functions, we can simply
compute the CTF-weighted local averages instead. This strategy coincides with the CTF-weighting
of Bayesian inference described in [7, 11].

A.21 Remark regarding further template compression

If the ranks H and H (cid:48) are both suﬃciently small (e.g., 2 − 4 and 1 − 2, respectively), then the
dimensionality of the space of CTF-modulated principal templates (as measured via the numerical
rank) is very small, and usually quite a bit smaller than the actual number of principal templates (i.e.,
the number of viewing-directions). This would allow for additional compression, using a reduced set
of ‘basis’-templates (which span the space of templates) rather than the actual templates themselves.
In our numerical experiments we do not implement this compression because our H and H (cid:48) are
typically too large for it to be eﬃcient.

A.22

Image alignment

Just as for the reconstruction step, image alignment is often performed multiple times during molec-
ular reﬁnement. For standard AM, the inputs to the alignment process are the estimated molec-
ular volume ˆF estim(k), as well as the picked-particle images ˆAj(k) and associated CTF-functions
for the
CT Fj(k). The outputs are the estimated viewing angles τ estim
various images.

and displacements kestim

j

j

In our case we will make use of both the standard maximum-likelihood alignment, as well as a

more stable ‘maximum-entropy’ alignment (described below).

A.23 Alignment via maximum likelihood
For this, we calculate the quantities X , ˆX and Z, described in section 2.1, for a collection of
T = O(K 2) viewing directions αt and βt corresponding to our spherical shell quadrature grid for ˆk
at k = kR ≈ K. For each of these viewing-directions (αt, βt), we consider a range of O(K) values for
γ in [0, 2π). For the displacements, we typically limit them to lie in a small disk of radius δlocal ∼ 0.01
or so, taking advantage of the low numerical rank of the set of translation-operators within this disk
[16, 24].

Given the correlations Z(αt, βt; ˆAj), a common strategy for updating the viewing angles τ estim
and displacements δestim
(referred to as ‘maximum-likelihood’ alignment), involves selecting the τ estim
(and, as a result, the δestim
) for each image j to maximize Z(αt, βt) over the T viewing directions
for that particular image j. In the ideal situation where the image formation model is accurate, this
choice corresponds to the viewing-angle that is most likely to have produced the particular image

j

j

j

j

29

ˆAj, given that the molecule is indeed ˆF estim. In practice we do not deﬁne τ estim
to be the very best
α and β for each image, instead randomly selecting an αt and βt for which Z(αt, βt) is within the
top 5th-percentile of its values for that image [15]. The results of our numerical-experiments are
quite insensitive to this value of 5%; any choice from 1% to ∼ 10% achieves similar performance for
maximum-likelihood alternating minimization.

j

Let us deﬁne the function Sort[·] which maps lists of real-numbers to lists of positive integers such
that, for any vector a ∈ RL, the value of Sort[a]l is the (integer) rank of al (ranging from 1, . . . , L
as it stands within the entries of a). As noted in section 2.1, we can see that the template ranks are
obtained by applying Sort[·] to each ‘column’ of the array Z(αt, βt; ˆAj) (ﬁxing j), while the image
ranks are obtained by applying Sort[·] to each ‘row’ of the same array (ﬁxing t). The maximum-
likelihood alignment described above depends on the template ranks, while the maximum-entropy
alignment (described below) depends on the image ranks.

A.24 Alignment via maximum-entropy

The maximum-likelihood alignment described above can be thought of as a ‘greedy’ algorithm which
selects the estimated viewing angles for each image without consideration of the choices made for the
other images. As a result of this greedy strategy, the estimated viewing angle distribution (across all
τ estim
) is not controlled, and can end up becoming quite far from the true viewing-angle distribution
j
(until the volume used to generate the templates is suﬃciently accurate).

To avoid this phenomenon, one can choose the τ estim

while constraining the distribution of es-
timated viewing angles in some way. A simple special case of this strategy is to constrain the
distribution of estimated viewing angles to be uniform. We refer to such an alignment strategy as
In practice we implement this
‘maximum-entropy’ alignment (referring to the entropy of µestim
maximum-entropy alignment as follows:

).

τ

j

1. Declare all the images ‘unassigned’.
2. Deﬁne a list of NA uniformly distributed viewing-directions ˆkj = (αj, βj) on the sphere. (This
is typically done by cycling through a randomly-permuted list of the T viewing-angles (αt, βt)
until NA viewing-directions have been selected).

3. Step through the list of viewing directions. For each viewing-direction (deﬁned by a particular
α and β), assign the image ˆAj that has not previously been assigned and which maximizes
Z(α, β; ˆAj) (over the unused image-indices j). When assigning an image ˆAj to a particular
implicitly via
viewing direction α, β, we set the in-plane rotation γ estim
the arg max (see the deﬁnition of Z in Eq 9).

and displacement δestim

j

j

Note that the third step of this procedure uses the image ranks for each template (rather than
the template ranks for each image).
In some cases the image ranks and template ranks contain
similar information (see, e.g., the results for ISWINCP in Fig 2). However, it is more typical for the
image ranks to be more informative than the template ranks (see the other case studies in Figs. 2
and 11).

Intuition might suggest that maximum-entropy alignment is a reasonable strategy if the true
viewing angle distribution is known to be uniform, and not otherwise. Nevertheless, as illustrated
in the main text, our EMPM iteration still often produces results that are signiﬁcantly better than
maximum-likelihood alignment, even for cryo-EM data where the true viewing angle distribution is
rather nonuniform. We study this behavior in some detail for simpliﬁed models in sections B and C
below.

B Multi-Reference Alignment (MRA)

Multi-Reference Alignment (MRA) is an abstraction of the cryo-EM molecular reconstruction prob-
lem, reduced to a two-dimensional setting.

30

In this context the image displacements and CTF-modulation are typically ignored, and we as-
sume (i) the imaged molecule itself is translationally invariant in the x3-direction, and (ii) the imaged
molecule is only observed from the x3-axis. Because of (i), the function F (x) will be determined by
F (x1, x2), and ˆF (k) will be restricted to the equatorial-plane, as denoted by ˆF (k, ψ). Additionally,
due to (ii), each ‘image’ ˆAj will be a noisy version of ˆF (k, ψ), subject to an unknown in-plane
rotation γj:

ˆAj(k, ψ) = [R(γj) ◦ ˆF ](k, ψ) + noise = ˆF (k, ψ − γj) + noise.
If we further assume that the true volume ˆF involves only a single k-shell, then each image is
restricted to a single k-ring, and can be considered a periodic function on [0, 2π].

The MRA problem has been well studied [25, 26, 27], and can be used to gain insight into the
behavior of many reconstruction strategies. It can be used, for example, to investigate the sensitivity
of Bayesian inference (BI) to mismatches between the estimated and true noise levels (see Fig 6).

C Multi-Slice Alignment (MSA)

An ‘orthogonal’ sub-problem to MRA, which we refer to as Multi-Slice Alignment (MSA), can be de-
scribed as follows. As in MRA, we ignore displacements and the CTF and assume that the volume is
invariant in the x3-direction. However, in MSA, we assume that the imaged molecule is only observed
from the equatorial plane. With this assumption the images will correspond to projections of F (x)
onto one-dimensional lines in the x1-x2-plane (i.e., samples of the two-dimensional Radon transform
of F (x1, x2)). Thus, retaining the notation ˆAj, each image corresponds to a one-dimensional slice
of ˆF (k, ψ), expressed as a function of k ∈ R for a speciﬁc (but unknown) ψj:

ˆAj(k) = ˆF (|k|, ψj) + noise if k > 0, or ˆF (|k|, ψj + π) + noise if k < 0.

To simplify the scenario further, we restrict each image to the ray of positive k:

ˆAj(k) = ˆF (k, ψj) + noise

for k > 0.

If we further assume that the true volume F can take on arbitrary complex values, and that ˆF
involves only a single k-shell, then ˆF corresponds to a closed-curve in C, written as the function
ˆG(ψ), parametrized by ψ. Each image is now simply a point, corresponding to a noisy observation
of ˆG(ψ). If we assume that the true volume ˆF involves a discrete set of R k-values {k1, . . . , kR},
then ˆG will be a closed curve in CR (once again parametrized by ψ), and each image will be a vector
in CR corresponding to a noisy observation of ˆG(ψj). An example illustrating the MSA problem for
R = 1 is shown in Fig 7.

Numerical experiments: We believe that MSA can be a useful testbed for studying the perfor-
mance of various strategies for cryo-EM reconstruction. As a simple example, let R ≡ 1 above and
deﬁne ˆGtrue : [0, 2π) → C using a ﬁxed number of Fourier modes:

ˆGtrue(ψ) =

+Q
(cid:88)

q=−Q

gtrue(q) · exp(iqψ),

with the shape of ˆGtrue determined by the 2Q + 1 coeﬃcients gtrue
generate ˆGtrue randomly by drawing each of the gtrue
variance 1.

q

q

. In the experiments below, we
from a (complex) Gaussian distribution with

Having drawn a particular ˆGtrue, we sample this molecule at NA points, producing a collection

of simulated data points ˆAj deﬁned by:

ˆAj = ˆGtrue(ψj) + (cid:15)j,

31

where the ψj are drawn independently and uniformly from [0, 2π), and each (cid:15)j is an independent
complex random variable drawn from a normal distribution with variance σ.

Now, given the collection of NA images { ˆAj}, we can try to reconstruct ˆGtrue using the strategies
discussed in the main text. Due to the simplicity of MSA, much of the apparatus described in
the main text simpliﬁes dramatically. For example, reconstruction involves a subsampled and/or
non-uniform Fourier transform, and alignment involves calculating the distance between each image
point and the curve ˆG as a function of ψ.

Many features of this toy problem are expected. For example, when σ = 0 the images lie exactly
on the curve ˆGtrue.
If we begin the alignment process with an initial guess ˆGinit = ˆGtrue for the
(up to a global
molecule, then each image will be aligned exactly to its correct viewing-angle ψtrue
phase-shift). Subsequent reconstruction steps will produce ˆGestim = ˆGtrue, so long as the number
of observed points NA is at least as large as the number of modes 1 + 2Q, and the reconstruction
operator is well-conditioned (i.e., if the image-points are not too closely clumped together). Put more
simply, if σ = 0 and NA ≥ 1 + 2Q then, generically speaking, a maximum-likelihood alternating
minimization starting with ˆGinit = ˆGtrue as an initial-function will be stable.

j

However, even in this simple scenario (i.e., with σ = 0), if we were to attempt maximum-likelihood
alternating minimization with a diﬀerent initial function then we are not guaranteed to converge to
ˆG. Indeed, if NA is not too large, there will typically be many diﬀerent functions with the same
bandlimit of Q that pass close to the observed points ˆAj. Which of these functions we converge to
will depend on the details of the reconstruction process. The situation becomes more complicated
once we add image noise; when σ > 0 even an initial guess of ˆGinit = ˆGtrue will not necessarily lead
to convergence to a function ˆGestim that is close to ˆGtrue.

To probe this phenomenon, we perform a set of numerical-experiments. We initialize our recon-

struction with a function of the form:

ˆGinit := λ · ˆGtrue + (1 − λ) · ˆGrand,

where ˆGrand is a random function drawn the same way as (but independent from) ˆGtrue, and λ is a
parameter describing how close ˆGinit is to the ground truth. Given a particular ˆGinit, we perform
the reconstruction, iterating until the resulting ˆGestim converges. For each trial we can then measure
the error E between ˆGestim and ˆGtrue.

In order to reward trials where ˆGestim and ˆGtrue are close to one another, even if they are
parametrized diﬀerently, we deﬁne the error E as follows: First we deﬁne d( ˆGestim ← ˆGtrue(ψ))
to be the distance between ˆGtrue(ψ) (i.e., a point in C) and the curve ˆGestim. We then deﬁne
the error E( ˆGestim ← ˆGtrue) as the integral of d2( ˆGestim ← ˆGtrue(ψ)) over ψ. Similarly, we deﬁne
d( ˆGtrue ← ˆGestim(ψ)) to be the distance between ˆGestim(ψ) and the curve ˆGtrue, and deﬁne the error
E( ˆGtrue ← ˆGestim) as the integral of d2( ˆGtrue ← ˆGestim) over ψ. Finally, we deﬁne the overall error
E = max(E( ˆGtrue ← ˆGestim), E( ˆGestim ← ˆGtrue)) to be the larger of the two.

Figure 8 illustrates the average E (accumulated over 512 random trials) for three diﬀerent recon-
struction strategies across a range of λ and σ values. On the left we show the results for Bayesian
inference, where we set the estimated noise level equal to the true noise level (i.e., σ) when re-
constructing the molecule. Note that Bayesian inference is quite accurate when the initial guess is
accurate (i.e., when λ = 1). However, when λ < 1 and there is a mismatch between the initial guess
and the true function, Bayesian inference typically performs quite poorly.

Similarly, we can apply standard maximum-likelihood alternating minimization (AM). This is
equivalent to Bayesian inference with an estimated noise level of 0. The results for AM are identical
to those shown on the left when σ = 0. However, as soon as a little image noise is added (σ > 0),
AM typically converges to a ˆGestim which is wildly diﬀerent from ˆGtrue, with errors that are an order
of magnitude larger than those shown for Bayesian inference (which was run with an estimated
noise-level of σ). We do not display the (large) errors observed for standard AM.

In the middle, we show the results for a simple alternating minimization scheme using maximum-
entropy alignment at each step. On the right we show the results for our preferred EMPM strategy:
namely, alternating between maximum-likelihood and maximum-entropy alignment. Note that,

32

while our preferred strategy is less accurate than Bayesian inference when σ is small and ˆGinit = ˆGtrue,
it is more accurate in this regime when σ > 0 and λ < 1.

Figure 9 illustrates the results of a similar numerical experiment, where the images are drawn
from a non-uniform distribution of viewing angles. For this numerical experiment, we consider
viewing angle distributions of the form exp(β cos(ψ))/(2πI0), controlled by a parameter β. When
β = 0 the viewing angle distribution is uniform, and as β increases, the viewing angle distribution
becomes more and more sharply peaked around ψ = 0. Results for λ = 0 are shown in Fig 9. The
results with β = 0 are the same (in distribution) as the λ = 0 scenario in Fig 8. Note that EMPM
is typically more accurate than Bayesian inference in this regime.

D Relion De-Novo parameters:

When using Relion’s de-novo molecular reconstruction, we use the following parameters.

--sgd ini iter 50
--sgd fin iter 50
--sgd ini resol 35
--sgd ini subset 100
--sgd
--ctf
--sym C1
--zero mask
--pool 3
--skip gridding
--healpix order 1
--offset step 2

--sgd inbetween iter 200
--sgd write iter 20
--sgd fin resol 15
--sgd fin subset 500
--denovo 3dref
--K 1
--flatten solvent
--dont combine weights via disc
--pad 1
--oversampling 1
--offset range 8
--j 6

Additionally, we set the --particle diameter to be commensurate with the true molecule diam-

eter (rounded up to the nearest 50 or 100˚A).

33

Figure 6:
In this ﬁgure we illustrate the typical errors observed when using Bayesian inference to
tackle the MRA problem. For this numerical experiment we set ˆGtrue to be a random function with
Q = 8 (i.e., 1 + 2Q = 17 degrees of freedom). The real (red) and imaginary (blue) parts of ˆGtrue are
uniformly distributed in [0, 2π]. We vary the true
shown on the left. We set NA = 2048, with ψtrue
noise-level (horizontal) and the estimated noise-level (vertical). On the right-hand-side we show the
L2-error between ˆGtrue and ˆGestim. We calculate ˆGestim via bayesian-inference, starting with a random
function with the same number of degrees of freedom as ˆGtrue, and iterating until convergence. The
L2-error on the right is scaled so that ‘1’ corresponds to the error between ˆGtrue and a constant
function with the same mean. Note that when the true noise-level is moderate (e.g., around 0.5)
there is only a narrow range of estimated noise-levels which admit accurate reconstructions (i.e.,
when σestim is close to σtrue). Outside this narrow band the reconstruction can be quite poor, even
when σestim is only 20% higher or lower than σtrue.

j

34

σtrueσBIj

Figure 7:
In this ﬁgure we illustrate the MSA problem with a single shell at k = 1. In the ﬁrst
subplot we show one example of a function ˆGtrue(ψ) plotted as a closed curve in C (black). NA = 32
images are sampled from ˆG(ψ), with each ψtrue
drawn independently from a uniform distribution on
). The true noise-level used when generating
[0, 2π] (circles, colored periodically according to ψtrue
the images is σtrue = 0.5. Starting with the ground-truth ˆGinit = ˆGtrue, we apply Bayesian inference
(BI) with the estimated noise level σBI set to equal σtrue. The resulting ˆGBI are shown in the
second subplot, with early iterations in cyan and later iterations in magenta. We also apply the
EMPM strategy, again starting with the ground-truth; the resulting ˆGEMPM are shown in the third
subplot. Errors for BI (black) and EMPM (gray) are shown in the fourth sub-plot. Note that the
error for EMPM oscillates as the iterations themselves alternate between maximum-likelihood- and
maximum-entropy-alignment. In Fig 8 below we use as the error for EMPM the higher of the two
alternating values. The data here correspond to one trial with σ = 0.5 and λ = 1 in Fig 8.

j

35

EMPMIn this ﬁgure we illustrate the recovery of Bayesian inference (left), maximum-entropy
Figure 8:
alternating minimization (center) and EMPM as applied to the MSA problem (see text). For each
trial in this numerical experiment we deﬁne the true molecule using a ˆG constructed with Q = 8,
corresponding to 1 + 2Q = 17 degrees of freedom (each of the coeﬃcients of ˆG are drawn indepen-
dently from a normal distribution). We sample NA = 32 images from ˆG (i.e., roughly 2 times the
number of modes) and add noise with a magnitude given by σ ranging from 0 to 1 (deﬁned relative
to the norm of ˆG) (horizontal). For each noise level σ we perform each reconstruction starting with
an initial function of the form λ · ˆG + (1 − λ) · ˆGnoise, with ˆGnoise drawn randomly (and independently
from ˆG) and λ ranging between 0 and 1 (vertical). For each value of (σ, λ), we simulate 512 ran-
domly generated trials; the heatmaps above average over these trials. Bayesian inference (left) is run
with estimated noise level equal to the true noise level. In the middle, we show results for a simple
alternating-minimization using only maximum-entropy alignment, rather than maximum-likelihood.
(Maximum-likelihood-based AM fared even more poorly.) On the right we show the results for
EMPM, with the error measured at the ﬁnal maximum-entropy alignment step (which is typically
higher than the error after the last maximum-likelihood alignment step).

Figure 9: As in Fig 8, we compare various reconstruction methods for the MSA problem, but here
we focus on viewing angle distribution. For this, we introduce a new parameter β ∈ [0, 3], where
β controls the nonuniformity of the viewing angle, with samples ψj drawn from the distribution:
exp(β · cos(ψ))/(2πI0(β)). Examples of this distribution (multiplied by 2π) are shown on the far
right. When β = 0 the viewing angles are uniformly distributed (cyan). When β = 1 the viewing
angle distribution ranges in density (from highest to lowest) by a factor of e2. When β = 3 the
viewing angle distribution ranges in density by a factor of e6, and is mostly supported in an interval
with diameter ∼ π (magenta). We ﬁx λ ≡ 0 (i.e., we start with a random function), and illustrate
the errors using the same scale as in Fig 8, this time varying β along the vertical axis. The horizontal
axis refers to the noise level as in Fig. 8.

36

σσσError (EMPM)Error (EMPM)Figure 10: This ﬁgure (analogous to Fig. 1) plots level sets from the reconstructions using var-
ious Level sets from the volumes ˆF true, ˆF Oracle, ˆF OAM, ˆF OBI, ˆF OBI, and ˆF EMPM (left to right) for
LSUbl16dep, MlaFEDB, LetB1 and TMEM16F.

37

Figure 11: The correspondence between estimated and ground-truth viewing angles for the recon-
structions shown in Fig 10. Three panels are shown for each molecule of interest. The left-most
subplot is a scatterplot of the image-template correlations. The middle subplot is a scatterplot of the
template ranks aggregated over all images, and the right-most subplot is a scatterplot of the image
ranks aggregated over all templates. All are presented as heatmaps, with color corresponding to the
log-density of the joint-distribution. This ﬁgure is the analog of Fig. 2 for LSUbl16dep, MlaFEDB,
LetB1 and TMEM16F.

38

LSUbl17MlaFEDBLetB1TMEM16Fcorr (EMPM)corr (EMPM)rank (EMPM)rank (EMPM)rank (EMPM)rank (EMPM)corr (EMPM)corr (EMPM)rank (EMPM)rank (EMPM)rank (EMPM)rank (EMPM)Figure 12: As in Fig. 3. we illustrate the aligned correlation Z mask between our various reconstruc-
tions and the ground-truth. Here we examine reconstructions for LSUbl16dep, MlaFEDB, LetB1
and TMEM16F. The diﬀerent horizontal bars indicate the values of Z mask for diﬀerent reconstruc-
tion strategies (coded by color) with diﬀerent trials from the same strategy adjacent to one another
(sorted by Z mask).

39

OB-itOB-itOB-itOB-itEMPMEMPMEMPMEMPMOAMOAMOAMOAMOracleOracleOracleOracle