2
2
0
2

y
a
M
6

]
L
P
.
s
c
[

2
v
6
3
6
2
0
.
5
0
2
2
:
v
i
X
r
a

Implementing Choreography Extraction

Lu´ıs Cruz-Filipe1, Kim S. Larsen1, Fabrizio Montesi1, and Larisa
Saﬁna2

1University of Southern Denmark
{lcf,kslarsen,fmontesi}@imada.sdu.dk
2INRIA, larisa.saﬁna@inria.fr

Abstract

Choreographies are global descriptions of interactions among concur-
rent components, most notably used in the settings of veriﬁcation and
synthesis of correct-by-construction software. They require a top-down
approach: programmers ﬁrst write choreographies, and then use them
to verify or synthesize their programs. However, most software does not
come with choreographies yet, which prevents their application. To attack
this problem, previous work investigated choreography extraction, which
automatically constructs a choreography that describes the behaviour of
a given set of programs or protocol speciﬁcations.

We propose a new extraction methodology that improves on the state
of the art: we can deal with programs that are equipped with state and
internal computation and time complexity is dramatically better. We also
implement this theory and show that, in spite of its theoretical exponen-
tial complexity, it is usable in practice. We discuss the data structures
needed for an eﬃcient implementation, introduce some optimisations, and
perform a systematic practical evaluation.

1

Introduction

The standard way of specifying the behaviour of a system of communicating
processes is to describe their individual behaviours. Some important questions
about these systems are “Is it free from deadlocks?” and “Is it free from live-
locks?”. Answering these questions is undecidable in general. To answer these
these and other similar questions, we can study a more general problem: what
does the system do? In particular, what are the communications that the sys-
tem will enact? In this paper, we develop an automatic procedure that answers
this question and that is eﬃcient enough in practice.

As an example, consider the following (pseudocode) speciﬁcation of a simple
single sign-on scenario inspired by the OpenID protocol [26].
It describes a
network with three processes: a user (u) tries to access a third-party web service

1

 
 
 
 
 
 
(w) by verifying their identity at an authentication service (a). The processes
interact by using primitives for sending and receiving values (send and recv),
and choosing from and oﬀering alternative behaviours (choose and offer).

Program for u

Program for a

Program for w

procedure X:

send cred to a
offer to a:

procedure X:

recv c from u
if check(c):

OK: recv token from w
KO: call X

choose OK at u
choose OK at w

procedure X:
offer to a:

OK: send t to u
KO: call X

else:

choose KO at u
choose KO at w
call X

call X

call X

call X

To answer the question of what this system does, we can use choreographic
languages—languages that describe the behaviour of an entire system from a
global viewpoint. Examples of such languages are Message Sequence Charts [17],
the W3C Web Services Choreography Description Language [29], and the Busi-
ness Process Modelling Notation [24]. In the language that we use in this article,
the behaviour of the system above can be given as the following choreography.

def X = u.cred -> a.c;

if a.check(c) then a -> u[ok ]; a -> w[ok ]; w.t -> u.token

else a -> u[ko]; a -> w[ko]; X

in X

Here, -> denotes a communication from the left- to the right-hand process. This
choreography describes the global protocol: the authentication service receives
the user’s credentials, and then decides whether the user should get a session
token (t) from the web service, or reattempt authentication (by reinvoking pro-
cedure X).

The general problem of synthesising a representative choreography from a
set of process speciﬁcations is called choreography extraction (extraction for
short) [5]. Extraction is a hard problem, since it requires predicting how con-
current processes can communicate with each other. Approaching this problem
with brute force leads to the typical case explosion for static analysis of concur-
rent programs [25]. Extraction is also connected to deadlock-freedom: any sys-
tem that can be represented by a choreography is necessarily deadlock-free [10];
however, some systems are deadlock-free but cannot be extracted to a choreog-
raphy [7]. The state-of-the-art implementation of extraction [19] has worst-case
super-factorial complexity. This limits the feasibility of thorough testing, and to
date the practical limits of extraction are still largely unexplored and unclear.

2

Contribution

In this article, we present a simple yet eﬀective choreography extraction proce-
dure, whose correctness and eﬃciency are systematically tested in practice. We
revisit and expand on the key ideas that we previously presented in [7], where
we informally described an extraction algorithm. We formally deﬁne this algo-
rithm and prove its main properties. In this process, we also made some small
improvements and extensions. Then, we introduce an implementation of our al-
gorithm and carry out the ﬁrst thorough and systematic testing of choreography
extraction in the literature.

Our contribution is three-fold.

Theory. Our theory for choreography extraction focuses on simplicity. The
languages for choreographies and processes respectively build upon Core Chore-
ographies and Stateful Processes, which have been previously proposed as lan-
guages for foundational studies on choreographies: they are designed to be
minimalistic, yet representative of the choreographic approach and Turing com-
plete [10, 13].

We extend the process language with an abstract operational semantics that
overapproximates the possible executions of a network (a system of processes).
This abstract semantics allows us to construct a ﬁnite graph that represents
the (abstract) execution space of a system. Choreography extraction can then
be formulated as a procedure that reconstructs a choreography by following
paths in this graph. Our extraction also helps in debugging:
if a potential
deadlock is present, we pinpoint it with a special term (1). Choreographies that
are successfully extracted guarantee deadlock-freedom. The soundness of our
approach is proven in terms of strong bisimilarity [27].

Using our theory as foundation, we design an algorithm that is signiﬁcantly
it consists of only two phases

simpler and more eﬃcient than previous work:
(the construction of the graph and its visit) and has better complexity.

Implementation The design of our implementation includes choosing ade-
quate data structures, optimising substeps, parallelisation, and proving all these
choices correct. An example is devising an eﬃcient decision procedure for guar-
anteeing the absence of livelocks. As a result, we obtain an implementation that
successfully manages our test suite (described next) in reasonable time.

Evaluation Designing a test suite for extraction poses a major challenge: we
cannot simply generate random networks since nearly none of them will be ex-
tractable (it is very unlikely that randomly-generated processes have matching
communication actions throughout execution). In order to ensure that we gener-
ate extractable networks, we rely on a compilation procedure for choreographies
that has been proven formally correct [12].

Speciﬁcally, by generating choreographies and compiling them, we obtain a
ﬁrst set of networks that are guaranteed to be extractable. This set is then

3

extended to a more comprehensive test suite by applying additional transfor-
mations that simulate realistic software development: we devised an automatic
tool that simulates the typical changes (both correct and incorrect) that are
introduced when a programmer edits a local process program, and then tried to
extract choreographies from the edited networks. This provides information on
how quickly our program fails for unextractable networks.

Our test suite represents the ﬁrst systematic and comprehensive approach
to the evaluation of extraction. Thus, we believe it to be a useful reference also
for the future design and implementations of new extraction algorithms.

1.1 Related Work

Most works on choreographic languages focus on the inverse (and simpler) op-
eration to extraction: Endpoint Projection (EPP), the translation of chore-
ographies into distributed implementations [2, 16]. EPP supports a top-down
development methodology: developers ﬁrst write choreographies and then exe-
cute the output mechanically generated by EPP. However, there are scenarios
where this methodology is not applicable:

• The analysis or use of “legacy code”, i.e., code that was not generated
by EPP. This might be code that was developed previously, or new code
written in a technology that does not adopt EPP. With legacy code, EPP
is not helpful.

• Code updates: the programs generated by EPP are typically updated
locally later on (for conﬁguration or optimisations, for example). Since
the original choreography is not automatically updated, rerunning EPP
loses these changes. Also, we lose the information on what the system
is actually doing, since the original choreography does not represent it
anymore.

To attack these issues, researchers started investigating choreography ex-
traction, which is the topic of this article [5, 18, 19]. Extraction still represents
a green ﬁeld of research. Early attempts developed theories based on session
types [18], linear logic [5], or communicating automata [19]. The theory in [19]
comes with an implementation, which is the state of the art in the area. How-
ever, the proposed algorithm does not focus on eﬃciency, nor simplicity:
it
consists of several complex phases, one of which has worst-case super-factorial
complexity. This limits the feasibility of thorough testing, and indeed the im-
plementation has been tested on small selected examples, which tell us little
about its applicability on a larger scale and its correctness. The choreographic
language in [19] is diﬀerent than ours, for example it cannot capture inter-
nal computation and it has internal threads (which we represent as separate
processes). Nevertheless, many of the manually-written examples in [19] can be
reformulated in our framework. These reformulations are included in the testing
of our implementation, and some of them beneﬁt greatly from our parallelisation
of extraction.

4

2 Networks, Choreographies, and Extraction

We introduce the languages that we use in this work to model process networks
and choreographies. These languages are very similar to those studied in [10],
where the interested reader can ﬁnd a formal treatment of these calculi, as well
as statements and proofs of the most relevant properties.

Syntactically, there are minor diﬀerences due to the goal of obtaining a
process language closer to real implementation languages, as depicted by the
example in the introduction. These changes are inspired by the languages dis-
cussed in [9]. Semantically, the reduction semantics for these calculi is also
extended with labels in order to allow for a formalisation of the link between
choreographies and their process implementations as a bisimilarity.

2.1 Networks

Process networks, or simply networks, represent systems of concurrent commu-
nicating processes. Each process has an internal memory where values can be
stored, identiﬁed by variables. Our model of networks is a calculus, which we
call Stateful Processes (SP), parameterised on sets of process names, expres-
sions, labels, variables, and procedure names. We assume these sets to be ﬁxed,
as they are immaterial for our presentation. We abstract from the concrete
language of expressions, which models internal computation and is orthogonal
to our development, assuming only that: expressions can contain values v and
variables; and evaluation of expressions always terminates and returns a value.
To simplify the presentation, we use p, q, . . . to range over process names,
e, e(cid:48), e1, . . . to range over expressions, (cid:96), (cid:96)(cid:48), (cid:96)1, . . . to range over labels, x, x(cid:48), y, y1, . . .
to range over variables, and X, Y, X (cid:48), Y1, . . . to range over procedure names.
Networks are ranged over by N, N (cid:48), N1, M, . . ..

Syntax. Formally, a network is a map from a ﬁnite set of process names to
processes of the form def {Xi = Bi}i∈I in B, where each Bi and B are process
behaviours. We denote by p1 (cid:46) P1 | · · · | pn (cid:46) Pn the network N that maps
each process name pi to the process term Pi, i.e., N (pi) = Pi for all i ∈ [1, n],
and every other process name to 0. Note that the order of processes in this
representation is immaterial. The network mapping all process names to 0 is
denoted 0.

In def {Xi = Bi}i∈I in B, behaviour B is the main behaviour of the process,
and {Xi = Bi}i∈I is a set of procedure deﬁnitions, assigning each Xi to the
corresponding behaviour Bi (the body of the procedure). Behaviours are syn-
tactically deﬁned by the grammar in Figure 1. We use P, P (cid:48), P1, . . . to range
over processes and B, B(cid:48), B1, . . . to range over behaviours. We also write Dp for
the set of all procedure deﬁnitions at p, and we often abbreviate p (cid:46) def Dp in B
to p (cid:46)Dp B, or simply p (cid:46) B if Dp is clear from the context.

Term 0 is the behaviour of a process that has terminated.
Term X is a procedure call, i.e., the invocation of the procedure called X in
the process executing the behaviour. Procedure calls are executed by replacing

5

B ::= 0 | X | q!e; B | p?x ; B | q⊕(cid:96); B | p&{(cid:96)1 : B1, . . . , (cid:96)n : Bn} | if e then B1 else B2

Figure 1: Syntax of Stateful Processes.

them with their deﬁnition.

Term q!e; B is a send action, which evaluates expression e, sends the resulting
value to process q, and continues as B. Dually, term p?x ; B receives a value
from process p, stores it in a local variable x, and continues as B.

Term q ⊕ (cid:96); B sends to q the selection of a behaviour labelled by (cid:96) (labels are
constants), and then proceeds as B. Selections are received by the branching
term p&{(cid:96)1 : B1, . . . , (cid:96)n : Bn}, which models the oﬀering of diﬀerent possible
behaviours: the process executing this term waits to receive from p the selection
of one of the labels (cid:96)i in (cid:96)1, . . . , (cid:96)n, and then proceeds with the associated
behaviour Bi.

Term if e then B1 else B2 is the standard conditional term. It evaluates the
Boolean expression e and proceeds as B1 if the result is true, and as B2 otherwise.
Networks are expected to satisfy some well-formedness conditions, corre-

sponding to usual requirements in practice:

• processes do not contain subterms that attempt self-communication (for

example, p (cid:46) p?x is not allowed);

• all expressions in guards of conditionals evaluate to true or false;

• all procedure calls refer to procedures deﬁned in the enclosing process;

• all deﬁned procedures are distinct, i.e., in def {Xi = Bi}i∈I in B, Xi (cid:54)= Xj

for every i (cid:54)= j ∈ I.

Note that we do not require procedure calls to be guarded.

Example 1. The example network from the introduction can be formalised as
follows.

u (cid:46) def X = a!cred ; a&{ok : w?token, ko : X}

in X

| a (cid:46) def X = u?cred ; if check (cred ) then (u ⊕ ok ; w ⊕ ok ) else (u ⊕ ko; w ⊕ ko; X)

in X

| w (cid:46) def X = a&{ok : u!token, ko : X}

in X

This corresponds precisely to the example written earlier, but now using the
formal language of SP. We follow the usual practice of omitting trailing 0 terms
(cid:47)
in behaviours.

The inductive deﬁnition of process behaviours gives rise to a notion of context

in the usual way [28], by allowing the terminal 0 to be replaced by a hole.

6

λ ::= p.v -> q | p -> q[(cid:96)] | p : then | p : else

Figure 2: Reduction labels for reductions in Stateful Processes

p (cid:46)Dp q!e; B1 | q (cid:46)Dq p?x ; B2, σ

p v

e ↓σ
p.v -> q
−−−−→ p (cid:46)Dp B1 | q (cid:46)Dq B2, σ[(cid:104)q, x(cid:105) (cid:55)→ v]

s-com

1 ≤ j ≤ n

s-sel

p (cid:46)Dp q ⊕ (cid:96)j ; B | q (cid:46)Dq p&{(cid:96)1 : B1, . . . , (cid:96)n : Bn}, σ

p -> q[(cid:96)]
−−−−−→ p (cid:46)Dp B | q (cid:46)Dq Bj, σ

e ↓σ

p true

p (cid:46)Dp if e then B1 else B2, σ

p:then
−−−→ p (cid:46)Dp B1, σ

e ↓σ

p false

p (cid:46)Dp if e then B1 else B2, σ

p:else
−−−→ p (cid:46)Dp B2, σ

s-then

s-else

N, σ λ−→ N (cid:48), σ(cid:48)
N | M, σ λ−→ N (cid:48) | M, σ(cid:48)

s-par

N (cid:22) M M, σ λ−→ M (cid:48), σ(cid:48) M (cid:48) (cid:22) N (cid:48)
N, σ λ−→ N (cid:48), σ(cid:48)

s-struct

Figure 3: Semantics of Stateful Processes.

Semantics. The semantics of SP is given in terms of labelled reductions of the
form N, σ λ−→D N (cid:48), σ(cid:48), where σ is a state function (which, given a process and
a variable, returns the value stored in that variable in the process’s memory)
and λ is a reduction label. The syntax of reduction labels is given in Figure 2.
The role of labels is to identify the action that has been performed; this will be
useful later to state and prove results about the extraction algorithm.

In realistic implementations, the state of each process’s memory would be
stored locally with each process. The formulation chosen here is trivially equiv-
alent, but using a global state function simpliﬁes the formulation of some of our
later results, as in other works on choreographies [13, 12].

The semantics of SP is deﬁned by the rules in Figure 3. Two processes can
synchronise when they refer to each other. In rule s-com, an output at p directed
at q synchronises with the dual input action at q – intention to receive from
p. The communicated value (v) is obtained by evaluating expression e locally
at the sender p taking into account the memory state σ, denoted e ↓σ
p v, and
stored in the corresponding variable x at q in the reductum. The label in the
reduction summarises the observable part of the communication.

Rule s-sel follows the same intuition, but for a label selection – where p
selects between diﬀerent possible behaviours oﬀered at q by sending the appro-
priate label.

7

X = BX ∈ Dp
p (cid:46)Dp X (cid:22) p (cid:46)Dp BX

s-unfold

Figure 4: Structural precongruence in Stateful Processes.

Rules s-then and s-else model conditionals in the expected way, while rule
s-par allows for reductions involving only a subset of processes in the network.
Rule s-struct closes reductions under a structural precongruence relation
(cid:22), generated by closing the rule in Figure 4 under reﬂexivity, transitivity, and
context. This rule allows procedure calls to be replaced by their deﬁnition
anywhere inside a process’s behaviour.

Lemma 1 (Determinism of SP). Let N be a network, σ be a state, and λ
be a reduction label. For any networks N1 and N2 and states σ1 and σ2, if
N, σ λ−→D Ni, σi for each i = 1, 2, then σ1 = σ2 and there exists a network N (cid:48)
such that Ni (cid:22) N (cid:48) for i = 1, 2.

Proof (sketch). First observe that labels uniquely identify the process(es) in-
volved in the reduction: this is trivially the case for rules s-com, s-sel, s-then
and s-else, and rules s-par and s-struct preserve this property.

Furthermore, the action(s) being executed must be the head action(s) in
each participating process, possibly after unfolding a behaviour consisting of a
procedure call: once again, this is trivially the case for the rules that execute
reductions, and preserved by s-par and s-struct (in the latter case, because
structural congruence cannot change the head action of a process unless it is a
procedure call).

Therefore the label of the reduction uniquely determines the resulting state;
and the resulting networks may diﬀer only in the procedure calls that have been
unfolded in each process. If N, σ λ−→ N1, σ1 and N, σ λ−→ N2, σ2, it thus follows
that σ1 = σ2, and that N1 (cid:22) N (cid:48) and N2 (cid:22) N (cid:48) for the network N (cid:48) obtained
from N1 by unfolding all procedure calls that have been unfolded in N2 and vice
versa.

2.2 Core Choreographies

Networks deﬁne the local actions that each process should perform, as in Ex-
ample 1, but they can be hard to read and error-prone to write: each process
can have a diﬀerent structure, because they carry out interactions with diﬀerent
other processes at diﬀerent times, yet we must ensure that each action aiming
at interacting with another process is going to be matched eventually by a com-
patible action at that process. Conversely, choreographies are speciﬁcations on
a higher level of abstraction that make the ﬂow of interactions easy to read and
write, instead of focusing on the local view of each process.

8

C ::= 0 | p.e -> q.x ; C | p -> q[(cid:96)]; C | if p.e then C1 else C2 | X

Figure 5: Syntax of Core Choreographies

We express choreographies using a minimalistic formal language (but still
expressive enough to capture relevant practical examples from the literature, as
we show later). Like networks, choreographies range over sets of process names,
expressions, labels, and procedure names, with the same conventions as above.
We call the choreography language in this work Core Choreographies (CC).

Syntax. A choreography is a term of the form def {Xi = Ci}i∈I in C, where:
C is the main body of the choreography; and {Xi = Ci}i∈I is a set of procedure
deﬁnitions, mapping each recursion variable Xi (the name of the procedure) to
the respective choreography body Ci, for some ﬁnite set of indices I. Chore-
ography bodies are deﬁned inductively by the grammar in Figure 5. We often
abuse terminology and refer to choreography bodies as “choreographies”, when
no confusion can arise.

Term 0 is the terminated choreography, and again we typically omit it in

examples when it is the trailing term of a non-terminated choreography.

The next two terms both model systems that execute an interaction and

proceed as C. There are two kinds of interactions.

• In a value communication p.e -> q.x , process p evaluates expression e and
sends the result to process q, which stores it in its variable x, replacing the
value previously stored there. We abstract from the concrete language of
expressions e, which models internal computation and is orthogonal to our
development, assuming only that: expressions can contain values v and
variables; and evaluation of expressions always terminates and returns a
value.

• In a selection p -> q[(cid:96)], p selects (cid:96) among the set of branches oﬀered by q.

We use η to range over interactions, when we do not need to distinguish between
value communications and label selections.

In a conditional if p.e then C1 else C2, p evaluates the (Boolean) expression
e and checks whether the result is true or false to decide whether the system
proceeds as C1 or C2, respectively.

Finally, term X is a procedure call. Intuitively, executing X corresponds to

executing the body of the procedure with name X.

As for networks, we often omit the ﬁrst part of choreography terms that
have the empty set as the set of procedure deﬁnitions, i.e., we simply write C
instead of def ∅ in C.

We assume that all choreographies are well-formed, meaning that:

• there are no self-communications, i.e., p and q are distinct in every subterm

of the form p.e -> q.x or p -> q[(cid:96)];

9

p.e -> q.x ; C, σ

e ↓σ
p v
p.v -> q
−−−−→D C, σ[(cid:104)q, x(cid:105) (cid:55)→ v]

c-com

e ↓σ

p true

if p.e then C1 else C2, σ

p:then
−−−→D C1, σ

c-then

p -> q[(cid:96)]; C, σ

p -> q[(cid:96)]
−−−−−→D C, σ

e ↓σ

p false

if p.e then C1 else C2, σ

p:else
−−−→D C2, σ

c-sel

c-else

C1 (cid:22)D C2 C2, σ λ−→D C (cid:48)
C1, σ λ−→D C (cid:48)

2, σ(cid:48) C (cid:48)
1, σ(cid:48)

2 (cid:22)D C (cid:48)
1

c-struct

Figure 6: Semantics of Core Choreographies

• all expressions in guards of conditionals evaluate to true or false;

• all procedure calls are guarded in procedure deﬁnitions, i.e., there is no
procedure deﬁnition of the form X = Y for some variables X and Y ;

• all deﬁned procedures are distinct, i.e., in def {Xi = Ci}i∈I in C, Xi (cid:54)= Xj

for every i (cid:54)= j ∈ I.

As before, from the inductive deﬁnition of choreographies we deﬁne contexts

in the usual way [28].

Semantics. The semantics of CC is given by labelled reductions C, σ λ−→D
C (cid:48), σ(cid:48), with labels λ as in SP. The reduction rules are given in Figure 6. The
ﬁrst four rules formalise the above informal description of the involved syntactic
terms, and follow the same intuitions as the corresponding rules for SP.

Rule c-struct closes reductions under a structural precongruence (cid:22)D that
allows procedure calls to be unfolded and non-interfering actions to be executed
in any order. The main rules deﬁning this relation are given in Figure 7; the
missing rules close this relation under reﬂexivity, transitivity, and context.

The key idea behind (cid:22)D is illustrated by rule c-eta-eta, which swaps com-
munications between disjoint sets of processes (modeling concurrency). In this
rule, pn(C) denotes the set of process names that appear in C. Rules c-eta-cond
and c-cond-cond are similar, as well as rule c-cond-eta, which is dual to c-eta-cond.
Rule c-unfold allows procedure calls to be replaced by the corresponding deﬁ-
nition.

Since all rules except for c-unfold are reversible, one is often working with
choreographies C1 and C2 such that C1 (cid:22)D C2 and C2 (cid:22)D C1. In this case, we
write simply C1 ≡ C2.

Example 2. We can write the client authentication protocol in the introduction
as a choreography in the following way, where a -> u, w[(cid:96)] is a shortcut for
a -> u[(cid:96)]; a -> w[(cid:96)]. For presentation purposes, we write each procedure deﬁnition

10

pn(η) ∩ pn(η(cid:48)) = ∅
η; η(cid:48); C (cid:22)D η(cid:48); η; C

c-eta-eta

p /∈ pn(η)
if p.e then (η; C1) else (η; C2) (cid:22)D η; if p.e then C1 else C2

c-eta-cond

p /∈ pn(η)
η; if p.e then C1 else C2 (cid:22)D if p.e then (η; C1) else (η; C2)

c-cond-eta

p (cid:54)= q

if p.e then (if q.e (cid:48) then C1 else C2) else (if q.e (cid:48) then C (cid:48)

1 else C (cid:48)
2)

(cid:22)D
if q.e (cid:48) then (if p.e then C1 else C (cid:48)

1) else (if p.e then C2 else C (cid:48)
2)

c-cond-cond

X = CX ∈ D
X (cid:22)D CX

c-unfold

Figure 7: Structural precongruence in Core Choreographies

as a separate equation, and abuse notation by identifying the main body with
procedure main.

X = u.pwd -> a.x ;

if a.ok(x ) then (a -> u, w[ok ]; w.t -> u.x )
else (a -> u, w[ko]; X)

main = X

Here, u sends a password to a. If this password is correct, a notiﬁes u and w,
and w sends an authentication token t to u. Otherwise, a notiﬁes u and w that
authentication failed, and a new attempt is made (by recursively invoking X).
This choreography can be obtained from the network in Example 1 by the
(cid:47)

extraction algorithm deﬁned in later sections.

2.3 EndPoint Projection

Choreographies satisfying some realisability conditions can be translated au-
tomatically into networks by a transformation known as EndPoint Projection
(EPP). We summarise this procedure, as it is a key ingredient to stating sound-
ness of extraction.

Intuitively, EPP is deﬁned by translating each choreography action into its
local counterparts. For example, a communication action p.e -> q.x is projected
as q!e for process p, as p?x for process q, and as a no-op for any other process.
The interesting case (where realisability plays a role) is the case of conditionals:
for any process other than p, if p.e then C1 else C2 must be projected as a unique
behaviour. This is dealt with by a partial operator called merging [2, 12]. Two

11

[[p.e -> q.x ; C]]r =






q!e; [[C]]r
p?x ; [[C]]r
[[C]]r

if r = p
if r = q
o.w.

[[p -> q[(cid:96)]; C]]r =






q ⊕ (cid:96); [[C]]r
p&{(cid:96) : [[C]]r}
[[C]]r

if r = p
if r = q
o.w.

[[if p.e then C1 else C2]]r =

(cid:40)

if e then [[C1]]r else [[C2]]r
[[C1]]r (cid:116) [[C2]]r

if r = p
o.w.

[[0]]r = 0

[[X]]r = X

Figure 8: Endpoint Projection of choreography bodies.

behaviours are mergeable if every place where they diﬀer is protected by a label
selection.

The key rule deﬁning merge is that for branching terms:

p&{(cid:96)i : Bi | i ∈ J} (cid:116) p&{(cid:96)i : B(cid:48)

i | i ∈ K} =
i) | i ∈ J ∩ K} ∪ {(cid:96)i : Bi | i ∈ J \ K} ∪ {(cid:96)i : B(cid:48)

p& ({(cid:96)i : (Bi (cid:116) B(cid:48)

i | i ∈ K \ J})

The remaining rules extend this operator homomorphically, e.g., (q!e; B1) (cid:116)
(q!e; B2) = q!e; (B1 (cid:116) B2). Merge is undeﬁned for two behaviours that start
with diﬀerent actions, e.g., q!e; B and q?x ; B(cid:48).

The EPP of a choreography body for process r, denoted [[C]]r, is deﬁned in
Figure 8. This extends to a choreography def {Xi = Ci}i∈I in C by deﬁning, for
each r, Dr = {Xi = [[Ci]]r}i∈I and [[C]] as the function mapping each process r
to def Dr in [[C]]r. If this is deﬁned for every r, the choreography is said to be
projectable.1

Example 3. The network in Example 1 is the EPP of the choreography in
Example 2.

3 Extraction from SP

In this section, we develop the theory of extracting a choreography from a net-
work. In a nutshell, the idea is to execute the network symbolically (abstracting
from the actual values that are communicated, for example) and use the trace
of the execution to write down a choreography. Since network reduction is
non-deterministic and networks may have inﬁnite behaviour, this poses some
challenges even to ensure termination.

We divide this presentation in two parts. First, we focus on the fragment of
SP without recursive deﬁnitions, which we use to discuss the intuition behind
our extraction algorithm in a simple setting. We present extraction for this

1In practice, some static analysis is performed to optimise the projection of procedure invo-
cations so that [[X]]r = 0 if r cannot be involved in the execution of X [10]. This optimisation
does not aﬀect our results.

12

fragment, and formally state and prove its soundness. In the second part, we
extend the construction to deal with inﬁnite behaviour.

3.1 The ﬁnite case

In this section we focus on ﬁnite SP, the fragment of SP without recursive deﬁ-
nitions. Formally, networks in SP are well-formed networks where all processes
are of the form def ∅ in B; in particular, B cannot contain any procedure calls.
We start by formalising our intuitive notion of “executing a network symboli-
cally” by means of a rewriting relation over a language of extended choreography
bodies.

Deﬁnition 1. An extended choreography body is a term written in the gram-
mar of Figure 5 using the additional constructs ([N ]), where N is a network in
ﬁnite SP, and 1, which stands for a deadlocked system.

Deﬁnition 2. We generate a rewriting relation (cid:32) on extended choreography
bodies by the rules

([0]) (cid:32) 0

([p (cid:46) q!e; Bp | q (cid:46) p?x ; Bq | N (cid:48)]) (cid:32) p.e -> q.x ; ([p (cid:46) Bp | q (cid:46) Bq | N (cid:48)])
([p (cid:46) q ⊕ (cid:96)k ; Bp | q (cid:46) p&{(cid:96)1 : Bq1, . . . , (cid:96)n : Bqn } | N (cid:48)]) (cid:32) p -> q[(cid:96)k ]; ([p (cid:46) Bp | q (cid:46) Bqk | N (cid:48)])

([p (cid:46) if e then B1 else B2 | N (cid:48)]) (cid:32) if p.e then ([p (cid:46) B1 | N (cid:48)]) else ([p (cid:46) B2 | N (cid:48)])

([N ]) (cid:32) 1, if no other rule applies

closed under choreography contexts.

Extraction operates by ﬁnding an action or a pair of matching actions in
a network and replacing them by the corresponding choreography action. In
general, there may be diﬀerent options for these choices, making extraction
nondeterministic.

Example 4. We illustrate this rewriting system with three example networks.

• Consider the network N1 deﬁned as p (cid:46) q!e | q (cid:46) p?x | r (cid:46) s!e (cid:48) | s (cid:46) r?y.

There are two sequences of extraction steps from N1, namely

([N1]) (cid:32) p.e -> q.x ; ([r (cid:46) s!e (cid:48) | s (cid:46) r?y])

(cid:32) p.e -> q.x ; r.e (cid:48) -> s.y; ([0])
(cid:32) p.e -> q.x ; r.e (cid:48) -> s.y; 0

and ([N1]) (cid:32) r.e (cid:48) -> s.y; ([p (cid:46) q!e | q (cid:46) p?x ])

(cid:32) r.e (cid:48) -> s.y; p.e -> q.x ; ([0])
(cid:32) r.e (cid:48) -> s.y; p.e -> q.x ; 0

Observe that the resulting choreographies can be rewritten into each other
by Rule c-eta-eta (Figure 6).

13

• Consider now the network N2 deﬁned as p (cid:46) Bp | q (cid:46) Bq, where Bp =
if e then q ⊕ l; q!1 else q ⊕ r; q?x and Bq = p&{l : p?y, r : p!2 }. The only
sequence of extraction steps from N2 is

([N2]) (cid:32) if p.e then ([p (cid:46) q ⊕ l; q!1 | q (cid:46) Bq]) else ([p (cid:46) q ⊕ r; q?x | q (cid:46) Bq])

(cid:32) if p.e then p -> q[l]; ([p (cid:46) q!1 | q (cid:46) p?y]) else p -> q[r]; ([p (cid:46) q?x | q (cid:46) p!2 ])
(cid:32) if p.e then (p -> q[l]; p.1 -> q.y; ([0])) else (p -> q[r]; q.2 -> p.x ; ([0]))
(cid:32) if p.e then (p -> q[l]; p.1 -> q.y; 0) else (p -> q[r]; q.2 -> p.x ; 0)

• We now introduce an example involving the deadlocked term. Consider the
network N3 deﬁned as p (cid:46) q!1 ; r!2 | q (cid:46) p?x ; r!3 | r (cid:46) if e then p?y else q?y.
Again, there are two possible sequences of extraction steps from N3, but
both include a deadlocked term in the result.

([N3]) (cid:32) p.1 -> q.x ; ([p (cid:46) r!2 | q (cid:46) r!3 | r (cid:46) if e then p?y else q?y])

(cid:32) p.1 -> q.x ; if r.e then ([p (cid:46) r!2 | q (cid:46) r!3 | r (cid:46) p?y]) else ([p (cid:46) r!2 | q (cid:46) r!3 | r (cid:46) q?y])
(cid:32) p.1 -> q.x ; if r.e then (p.2 -> r.y; ([q (cid:46) r!3 ])) else (q.3 -> r.y; ([p (cid:46) r!2 ]))
(cid:32) p.1 -> q.x ; if r.e then (p.2 -> r.y; 1) else (q.3 -> r.y; 1)

Alternatively, we can ﬁrst rewrite the conditional on r.

([N3]) (cid:32) if r.e then ([p (cid:46) q!1 ; r!2 | q (cid:46) p?x ; r!3 | r (cid:46) p?y]) else ([p (cid:46) q!1 ; r!2 | q (cid:46) p?x ; r!3 | r (cid:46) q?y])

(cid:32) if r.e then (p.1 -> q.x ; ([p (cid:46) r!2 | q (cid:46) r!3 | r (cid:46) p?y])) else (p.1 -> q.x ; ([p (cid:46) r!2 | q (cid:46) r!3 | r (cid:46) q?y]))
(cid:32) if r.e then (p.1 -> q.x ; p.2 -> r.y; ([q (cid:46) r!3 ])) else (p.1 -> q.x ; q.3 -> r.y; ([p (cid:46) r!2 ]))
(cid:32) if r.e then (p.1 -> q.x ; p.2 -> r.y; 1) else (p.1 -> q.x ; q.3 -> r.y; 1)

Note that the resulting extended choreographies can again be rewritten into
each other (using rules c-cond-eta and c-eta-cond).
(cid:47)

Indeed, non-determinism of extraction is of no practical consequence.

Lemma 2. If ([N ]) (cid:32)∗ C1 and ([N ]) (cid:32)∗ C2, then C1 ≡ C2.
Proof. This follows by induction from the fact that (cid:32) has the diamond prop-
erty. To see that this is the case, observe that, if N (cid:32) T1 and N (cid:32) T2 with
T1 (cid:54)= T2, then these two rewrites cannot use the ﬁrst or last rules in the deﬁni-
tion of (cid:32), and the choreography actions introduced in T1 and T2 cannot share
process names. Therefore we can continue the reduction from T1 by adding
the choreography action in T2, obtaining T (cid:48)
1, and we can continue the reduction
from T2 by adding the choreography action from T1, obtaining T (cid:48)
1 and
T (cid:48)
2 diﬀer only in the choreography actions at the top, which can be exchanged
by one of the precongruence rules for CC, as in the previous example.

2. Then T (cid:48)

The converse also holds:

if N can be extracted to a choreography, then it

can be extracted to any structurally congruent choreography.

Lemma 3. If ([N ]) (cid:32)∗ C1 and C1 (cid:22) C2, then ([N ]) (cid:32)∗ C2.

14

Proof. By induction on the derivation of C1 (cid:22) C2. If this derivation consists
of a single step, then it is an application of one of the rules in Figure 7, and
that rule cannot be c-unfold.
It follows immediately that the thesis holds.
Otherwise the thesis follows immediately from the induction hypothesis.

There is one important design option to consider when extracting a choreog-
raphy from a process implementation: what to do with actions that cannot be
matched, i.e., processes that get stuck. There are two alternatives: restrict ex-
traction to lock-free networks (networks where all processes eventually progress,
in the sense of [1]), so that it becomes a partial relation; or extract stuck pro-
cesses to a new choreography term 1, with the same semantics as 0. We choose
the latter option for debugging reasons. Speciﬁcally, practical applications of
extraction may annotate 1 with the code of the deadlocked processes, giving the
programmer a chance to see exactly where the system is unsafe, and attempt at
ﬁxing it manually. Better yet: since the code to unlock deadlocked processes in
process calculi can be eﬃciently synthesised [1], our method may be integrated
with the technique in [1] to suggest an automatic system repair.

Remark 1. If ([N ]) (cid:32) C and C does not contain 1, then N is lock-free. How-
ever, even if C contains 1, N may still be lock-free: the code causing the deadlock
may be dead code in a conditional branch that is never chosen during execution.
Other kinds of liveness issues, e.g., livelocks and starvation, are not possible in
ﬁnite SP, but will be relevant later when dealing with recursion.

In order to relate a network with its extracted choreography, we use the
standard notion of bisimilarity, noting that transition labels for choreographies
and networks are the same.

Deﬁnition 3. A binary relation R between choreographies and networks is a
bisimulation if:

• If C R N and C

µ
−→ C (cid:48), then there exists N (cid:48) such that N

µ
−→ N (cid:48) and

C (cid:48) R N (cid:48).

• If C R N and N

µ
−→ N (cid:48), then there exists C (cid:48) such that C

µ
−→ C (cid:48) and

C (cid:48) R N (cid:48).

C is bisimilar to N , written C ∼ N , if there exists a bisimulation R such

that C R N .

Extraction is sound: it yields a choreography that is bisimilar to the original

network. Also, for ﬁnite SP, it behaves as an inverse of EPP.

Theorem 1. Let N be a ﬁnite SP. Then:

(i) If there exists a choreography C such that ([N ]) (cid:32) C, then C ∼ N .

(ii) If N = [[C]] for some choreography C, then ([N ]) (cid:32) C.

Proof.

15

(i) We show that the relation R deﬁned by C R N if ([N ]) (cid:32) C is a bisimu-
lation by induction on the size of C. We detail one representative case.
Suppose that C is p.e -> q.x ; C (cid:48), whence N is of the form p (cid:46) q!e; Bp | q (cid:46)
p?x ; Bq | N (cid:48).
The case when either C or N reduces by making a reduction labelled by
p.v -> q
p.v -> q
−−−−→∅ C (cid:48), σ(cid:48) and N, σ
p.v -> q is trivial, since both C, σ
−−−−→ p (cid:46)
Bp | q (cid:46) Bq | N (cid:48), σ(cid:48) (assuming that e ↓σ
p v), and the latter network extracts
to C (cid:48)
Suppose that C, σ λ−→∅ C (cid:48)(cid:48), σ(cid:48) for some other label λ. Due to the way
structural congruence is deﬁned, and since there are no procedure deﬁni-
tions, it follows that also C (cid:48), σ λ−→∅ C (cid:48)(cid:48)(cid:48), σ(cid:48), and that C (cid:48)(cid:48) (cid:22)∅ p.e -> q.x ; C (cid:48)(cid:48)(cid:48).
Since p (cid:46) Bp | q (cid:46) Bq | N (cid:48) (cid:32) C (cid:48), by the induction hypothesis, p (cid:46) Bp | q (cid:46)
Bq | N (cid:48), σ λ−→ p (cid:46) Bp | q (cid:46) Bq | N (cid:48)(cid:48), σ(cid:48); but λ cannot involve p or q, so
also p (cid:46) q!e; Bp | q (cid:46) p?x ; Bq | N (cid:48), σ λ−→ p (cid:46) q!e; Bp | q (cid:46) p?x ; Bq | N (cid:48)(cid:48), σ(cid:48).
The latter network extracts to p.e -> q.x ; C (cid:48)(cid:48)(cid:48), and Lemma 3 allows us to
conclude that p (cid:46) q!e; Bp | q (cid:46) p?x ; Bq | N (cid:48)(cid:48) (cid:32) C (cid:48)(cid:48).
The case where N, σ λ−→ N (cid:48)(cid:48), σ is similar, using Lemma 2.

(ii) By structural induction on C. We detail one representative case.

Suppose that C is p.e -> q.x ; C (cid:48). Then [[C]] can be written as p (cid:46)
q!e; Bp | q (cid:46) p?x ; Bq | N (cid:48), where [[C (cid:48)]] = p (cid:46) Bp | q (cid:46) Bq | N (cid:48), and the thesis
follows trivially by the induction hypothesis.

As we show later, the second part of this theorem does not hold in the

presence of recursive deﬁnitions.

The deﬁnition of (cid:32) is convenient for ﬁnite SP: it is simple, and easy to anal-
yse. However, when we add the possibility of inﬁnite behaviour, it will in general
not be the case that a network can be rewritten to a choreography in ﬁnitely
many steps. Therefore, we now restate extraction by means of constructing and
analysing a particular graph. This alternative method, which is the hallmark of
our development, is easily seen to be equivalent to the previous deﬁnition – but
it can be extended to the whole language of SP.

We start by introducing an abstract semantics for networks, N α−→D N (cid:48),
deﬁned as in Figure 3 with the following two diﬀerences: (i) the state σ is re-
moved, and (ii) the rules for value communication and conditionals are replaced
by those in Figure 9. In particular, conditionals are nondeterministic in this
semantics.

Labels α in the abstract semantics are like λ, but the labels for communi-
cations now contain expressions and the variable for storing the result (see the
new rule s-com); in all omitted rules, the label is the same as before. We write
N ˜α−→∗ N (cid:48) for N α1−→D · · · αn−−→D N (cid:48).

Deﬁnition 4. Let N be a network. The Abstract Execution Space (AES) of N
is the directed graph obtained by considering all possible abstract reduction paths

16

p (cid:46)Dp q!e; B1 | q (cid:46)Dq p?x ; B2

p.e -> q.x
−−−−−−→ p (cid:46)Dp B1 | q (cid:46)Dq B2
s-then

s-com

p (cid:46)Dp if e then B1 else B2

p.e:then
−−−−−→ p (cid:46)Dp B1

p (cid:46)Dp if e then B1 else B2

p.e:else
−−−−→ p (cid:46)Dp B2

s-else

Figure 9: Abstract semantics for Stateful Processes. Besides these rules, the
semantics includes all other rules in Figure 3 with the state removed.

from N . Its vertices are all the networks N (cid:48) such that N ˜α−→∗ N (cid:48), and there is
an edge between two vertices N1 and N2 labelled α if N1

α−→D N2.

A Symbolic Execution Graph (SEG) for N is a subgraph of its AES that
contains N and such that each vertex N (cid:48)
(cid:54)= 0 has either one outgoing edge
labelled by an interaction η or two outgoing edges labelled p.e : then and p.e : else,
respectively.

Intuitively, the AES of N represents all possible evolutions of N (each such
evolution is a path in this graph). A SEG ﬁxes the order of execution of ac-
tions, but still abstracts from the state (and thus considers both branches of
conditionals). If N is a network in ﬁnite SP, these graphs are trivially ﬁnite.

Example 5. We revisit the networks in Example 4.

• Network N1 in the example has the following AES.

p (cid:46) q!e | q (cid:46) p?x | r (cid:46) s!e (cid:48) | s (cid:46) r?y

p.e -> q.x

r.e (cid:48) -> s.y

r (cid:46) s!e (cid:48) | s (cid:46) r?y

p (cid:46) q!e | q (cid:46) p?x

r.e (cid:48) -> s.y

p.e -> q.x

0

This AES admits two SEGs, namely the two paths from the top node to
the bottom node. Reading the labels of this path, one obtains the two
choreographies that can be extracted from this network.

• Network N2 illustrates how conditionals are treated. This network’s AES,

17

(cid:116)
(cid:116)
(cid:42)
(cid:42)
(cid:42)
(cid:42)
(cid:116)
(cid:116)
which coincides with its SEG, is the following.

p (cid:46) if e then q ⊕ l; q!1 else q ⊕ r; q?x | q (cid:46) p&{l : p?y, r : p!2 }

p.e:then

p.e:else

p (cid:46) q ⊕ l; q!1 | q (cid:46) p&{l : p?y, r : p!2 }

p -> q[l]

p (cid:46) q ⊕ r; q?x | q (cid:46) p&{l : p?y, r : p!2 }

p (cid:46) q!1 | q (cid:46) p?y

p -> q[r]

p (cid:46) q?x | q (cid:46) p!2

p.1 -> q.y

q.2 -> p.x

p (cid:46) 0 | q (cid:46) 0

Again, reading the labels on the edges of this graph, one obtains the chore-
ography if p.e then (p -> q[l]; p.1 -> q.y) else (p -> q[r]; q.2 -> p.x ), which
describes the global behaviour of the original network.

• Finally, network N3 gives the following AES.

p (cid:46) q!1 ; r!2 | q (cid:46) p?x ; r!3 | r (cid:46) if e then p?y else q?y

r.e:then

r.e:else

p (cid:46) q!1 ; r!2 | q (cid:46) p?x ; r!3 | r (cid:46) p?y

p.1 -> q.x

p (cid:46) q!1 ; r!2 | q (cid:46) p?x ; r!3 | r (cid:46) q?y

p.1 -> q.x

p (cid:46) r!2 | q (cid:46) r!3 | r (cid:46) if e then p?y else q?y

p.1 -> q.x

r.e:then

r.e:else

p (cid:46) r!2 | q (cid:46) r!3 | r (cid:46) p?y

p (cid:46) r!2 | q (cid:46) r!3 | r (cid:46) q?y

p.2 -> r.y

p (cid:46) 0 | q (cid:46) r!3 | r (cid:46) 0

q.3 -> r.y

p (cid:46) r!2 | q (cid:46) 0 | r (cid:46) 0

18

(cid:115)
(cid:115)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:41)
(cid:41)
(cid:117)
(cid:117)
(cid:114)
(cid:114)
(cid:15)
(cid:15)
(cid:44)
(cid:44)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:116)
(cid:116)
(cid:42)
(cid:42)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
There are two SEGs for this AES:

p (cid:46) q!1 ; r!2 | q (cid:46) p?x ; r!3 | r (cid:46) if e then p?y else q?y

r.e:then

r.e:else

p (cid:46) q!1 ; r!2 | q (cid:46) p?x ; r!3 | r (cid:46) p?y

p (cid:46) q!1 ; r!2 | q (cid:46) p?x ; r!3 | r (cid:46) q?y

p.1 -> q.x

p.1 -> q.x

p (cid:46) r!2 | q (cid:46) r!3 | r (cid:46) p?y

p (cid:46) r!2 | q (cid:46) r!3 | r (cid:46) q?y

p.2 -> r.y

q.3 -> r.y

p (cid:46) 0 | q (cid:46) r!3 | r (cid:46) 0

p (cid:46) r!2 | q (cid:46) 0 | r (cid:46) 0

and

p (cid:46) q!1 ; r!2 | q (cid:46) p?x ; r!3 | r (cid:46) if e then p?y else q?y

p.1 -> q.x

p (cid:46) r!2 | q (cid:46) r!3 | r (cid:46) if e then p?y else q?y

p (cid:46) r!2 | q (cid:46) r!3 | r (cid:46) p?y

p (cid:46) r!2 | q (cid:46) r!3 | r (cid:46) q?y

r.e:then

r.e:else

p.2 -> r.y

q.3 -> r.y

p (cid:46) 0 | q (cid:46) r!3 | r (cid:46) 0

p (cid:46) r!2 | q (cid:46) 0 | r (cid:46) 0

Both SEGs end in deadlocked networks, in line with the fact that N3 cannot
be extracted to a choreography. Representing these networks by 1 and read-
ing the labels on the edges in these graphs allows us to reconstruct the ex-
tracted extended choreographies p.1 -> q.x ; if r.e then (p.2 -> r.y; 1) else (q.3 -> r.y; 1)
and if r.e then (p.1 -> q.x ; p.2 -> r.y; 1) else (p.1 -> q.x ; q.3 -> r.y; 1).

(cid:47)

As these examples illustrate, there is a strong connection between these
graphs and the previous deﬁnition of extraction: each rule in Deﬁnition 2 natu-
rally corresponds to an edge, except for the ﬁrst (which characterises terminated
networks) and the last (which characterises deadlocked networks). Therefore,
each particular sequence of steps extracting a choreography corresponds to a
SEG, and conversely.

Lemma 4. The AES for any network in ﬁnite SP is a directed acyclic graph
(DAG).

Proof. Since there are no procedure calls, every reduction strictly decreases the
size of the network (measured by the number of nodes in its abstract syntax
tree). Therefore no network can ever reduce to itself in any number of steps,
and as such no AES can have loops.

19

(cid:116)
(cid:116)
(cid:42)
(cid:42)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:117)
(cid:117)
(cid:41)
(cid:41)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
As a consequence, every SEG for a network in ﬁnite SP is also a DAG.

Deﬁnition 5. Let S be a SEG for a network. The extended choreography body
extracted from node N , ([N ])S, is deﬁned inductively as follows.

• ([0])S = 0

• If N has no descendants and N (cid:54)= 0, then ([N ])S = 1.

• If N has one descendant N (cid:48) and the edge from N to N (cid:48) has label η, then

([N ])S = η; ([N ])(cid:48)

S.

• If N has two descendants N (cid:48) and N (cid:48)(cid:48) and the edges from N to those
nodes are labelled p.e : then and p.e : else, respectively, then ([N ])S =
if p.e then ([N ])(cid:48)

S else ([N ])(cid:48)(cid:48)
S.

Example 6. The (extended) choreographies informally presented in the previous
example correspond exactly to the (extended) choreographies extracted from the
(cid:47)
given SEGs.

As the examples suggest, this new notion of extraction coincides precisely

with the old one.

Lemma 5. Let N be a network.

(i) If S is a SEG for N , then ([N ]) (cid:32)∗ ([N ])S.

(ii) For every choreography body C, if ([N ]) (cid:32)∗ C, then there exists a SEG S

for N such that ([N ])S = C.

Proof.

(i) Straightforward by induction on the deﬁnition of ([N ])S, since every case
in its deﬁnition corresponds directly to a rule in the deﬁnition of (cid:32).

(ii) The sequence of reductions in ([N ]) (cid:32)∗ C deﬁnes a graph S as follows:

• an application of the ﬁrst or last rule does not add anything to the

graph;

• an application of the second or third rule generates an edge from the
network on the left to the reductum network on the right, labelled
with the choreography action that is introduced by the rule;

• an application of the fourth rule generates two edges from the network
on the left to each reductum network on the right, labelled by the
appropriate conditional label.

It is immediate to check that S is a SEG for N , and that ([N ])S = C.

20

3.2 Adding recursion

Formulating extraction in terms of SEGs allows us to extend it to networks
with recursive deﬁnitions. The tricky step is deﬁning the AES: abstract exe-
cutions of a network can be inﬁnite, and due to recursion unfolding there are
in general inﬁnite possible future states of a network with truly recursive def-
initions. Deﬁning extraction from such inﬁnite graphs would be problematic
already, since choreographies are ﬁnite; furthermore, we are interested in com-
puting extracted choreographies, which requires at least building a SEG.

To ensure ﬁniteness, we restrict the applications of rule s-unfold in the

abstract semantics (Figure 9).

(i) Rule s-unfold can only be applied inside a derivation occurring in the ﬁrst

premise of rule s-struct.

(ii) If rule s-unfold is applied to process p inside a derivation proving N (cid:22) M ,

then N (p) is a procedure call.

(iii) If rule s-unfold is applied to process p inside a derivation using rule

s-struct, then process p appears in the label λ of the reduction.

In other words: we only allow unfolding recursive deﬁnitions in order to execute
a reduction that would otherwise not be enabled.

With these restrictions, the AES and SEGs for a network are deﬁned as
in the ﬁnite case. However, these graphs no longer need to be DAGs, since a
network may evolve into itself after some reductions.

Example 7. Consider the network

p (cid:46) q!e; X | q (cid:46) Y | r (cid:46) Z

where procedures X, Y , and Z are deﬁned at p, q, and r, respectively, as

X = q!e; q&{l : q!e; X, r : 0}
Y = p?x ; p?x ; r?y; if (x = y) then p ⊕ l; Y else p ⊕ r; 0
Z = q!e (cid:48); Z

This network generates the AES in Figure 10. Since execution of this net-
(cid:47)

work is deterministic, the same graph is also its SEG.

The key insight to deﬁne extraction in this case is that the deﬁnitions of
recursive procedures are extracted from the loops in the SEG, rather than from
the recursive deﬁnitions in the source network.

Deﬁnition 6. Let S be a SEG for a network N . A loop node is a node n in
S such that: (i) n has more than one incoming edge or (ii) n is the initial node
labelled N and n has at least one incoming edge.

The DAG-iﬁcation of S is the graph SD deﬁned as follows.

21

p (cid:46) q!e; X | q (cid:46) Y | r (cid:46) Z

p.e -> q.x

p (cid:46) X | q (cid:46) p?x ; r?y; if (x = y) then p ⊕ l; Y else p ⊕ r; 0 | r (cid:46) Z

p (cid:46) q&{l : q!e; X, r : 0} |
q (cid:46) r?y; if (x = y) then p ⊕ l; Y else p ⊕ r; 0 | r (cid:46) Z

p.e -> q.x

q -> p[l]

r.e (cid:48) -> q.y

q.(x=y):then

p (cid:46) q&{l : q!e; X, r : 0} |
q (cid:46) if (x = y) then p ⊕ l; Y else p ⊕ r; 0 | r (cid:46) Z

q.(x=y):else

p (cid:46) q&{l : q!e; X, r : 0} | q (cid:46) p ⊕ r; 0 | r (cid:46) Z

q -> p[r]

p (cid:46) q&{l : q!e; X, r : 0} | q (cid:46) p ⊕ l; Y | r (cid:46) Z

p (cid:46) 0 | q (cid:46) 0 | r (cid:46) Z

Figure 10: The AES and SEG for the network in Example 7.

• The nodes of SD are all the nodes of S together with new nodes Xn for

each loop node n.

• For each edge in S from n to n(cid:48), SD contains one edge with source n and
target Xn(cid:48), if n(cid:48) is a loop node, and source n and target n(cid:48), otherwise.

Lemma 6. Graph SD is a DAG.

Proof. Suppose there is a cycle n1, n2 . . . , nk = n1 in S. If one of n1, . . . , nk
is the initial node, then this path is no longer a path in SD by construction.
Otherwise, one of these nodes must have at least two incoming edges (since all
nodes are accessible from the initial node), which again implies that it is no
longer a path in SD.

From the root node of each connected component of SD, we can extract a
choreography as before, adding the rule ([Xn])SD = Xn where Xn is a procedure
name.

Deﬁnition 7. The choreography extracted from N , ([N ])S is deﬁned as follows.
• The set of procedure deﬁnitions is {Xn(cid:48) = ([n(cid:48)])SD | n(cid:48) is a loop node in S}.
• The main choreography is Xn, if the starting node n is a loop node, and

([N ])SD , otherwise.

Example 8. Consider the SEG in Figure 7. To extract a choreography, we
split the topmost node into two nodes; the new node is labelled with a procedure
identiﬁer X, which is the target of the upgoing arrow in the ﬁgure. Thus, X is
extracted to

p.e -> q.x ; p.e -> q.x ; r.e (cid:48) -> q.y; if q.(x = y) then q -> p[l]; X else q -> p[r]; X

22

(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:15)
(cid:47)
(cid:47)
and the extracted choreography itself is simply X.

The body of X is not projectable (the branches for r are not mergeable,
(cid:47)

cf. [10]), but it faithfully describes the behaviour of the original network.

The procedure in Deﬁnition 7 always terminates, but sometimes it extracts
incomplete choreographies that lack some behaviours from the original network.
We illustrate the possible problems with some examples.

Example 9. Consider the network N deﬁned as p (cid:46) X | q (cid:46) Y | r (cid:46) Z | s (cid:46) W ,
where the recursive procedures X, Y , Z, and W are as follows.

X = q!e; X

Y = p?x ; Y

Z = s!e (cid:48); Z

W = r?y; W

The AES for N is:

p (cid:46) X | q (cid:46) Y | r (cid:46) Z | s (cid:46) W

p.e -> q.x

r.e (cid:48) -> s.y

There are two SEGs for this AES:

p (cid:46) X | q (cid:46) Y | r (cid:46) Z | s (cid:46) W

and

p (cid:46) X | q (cid:46) Y | r (cid:46) Z | s (cid:46) W

p.e -> q.x

r.e (cid:48) -> s.y

which extract to choreographies consisting of a call to procedure X, deﬁned as
X = p.e -> q.x ; X and X = r.e (cid:48) -> s.y; X, respectively, none of which captures
(cid:47)
all the behaviours of N .

Example 10. A similar situation may occur if there are processes with ﬁnite
the network p (cid:46) X | q (cid:46) Y | r (cid:46) s!e (cid:48) | s (cid:46) r?y
behaviour (no procedure calls):
where X = q!e; X and Y = p?x ; Y can be extracted to the choreography Z, with
(cid:47)
Z = p.e -> q.x ; Z, where r and s never communicate.

Both these examples exhibit a form of starvation: there is a loop involving
some processes that can reduce (as can be seen in the AES), but they are not
allowed to do so in a particular SEG. Example 9 is particularly relevant, since
there is no SEG where all involved processes reduce.

In order to avoid such situations, we change the deﬁnitions of AES and SEG
slightly. We annotate all processes in networks with either ◦ (unmarked) or
• (marked). In the initial network, all processes are unmarked. Processes are
marked when they are involved in a reduction; the marking is reset when all
processes are marked.

To make this formal, we extend the semantics to annotated networks as fol-
lows. Let N and N (cid:48) be annotated networks, and N − and N (cid:48)− be the underlying
networks obtained by erasing the annotations. Then N α−→D N (cid:48) if:

• N − α−→D N (cid:48)−;
• all processes in N (cid:48) are unmarked iﬀ all unmarked processes in N appear

in α;

23

(cid:47)
(cid:47)
(cid:111)
(cid:111)
(cid:47)
(cid:47)
(cid:111)
(cid:111)
• otherwise, a process is marked in N (cid:48) iﬀ it is marked in N or it appears in

α.

Deﬁnition 8. A SEG for a network N is valid if all its loops include a node
where all processes are unmarked.

A network N extracts to a choreography C if C can be constructed (as in

Deﬁnition 7) from a valid SEG for N .

In a valid SEG, every process is guaranteed to reduce at least once inside

every loop.

Example 11. The AES for the annotated network N in Example 9 is:

r.e (cid:48) -> s.y

p◦ (cid:46) X | q◦ (cid:46) Y | r◦ (cid:46) Z | s◦ (cid:46) W

p.e -> q.x

r.e (cid:48) -> s.y

p.e -> q.x

p• (cid:46) X | q• (cid:46) Y | r◦ (cid:46) Z | s◦ (cid:46) W

p◦ (cid:46) X | q◦ (cid:46) Y | r• (cid:46) Z | s• (cid:46) W

p.e -> q.x

r.e (cid:48) -> s.y

This AES now has the following two SEGs:

p◦ (cid:46) X | q◦ (cid:46) Y | r◦ (cid:46) Z | s◦ (cid:46) W

p◦ (cid:46) X | q◦ (cid:46) Y | r◦ (cid:46) Z | s◦ (cid:46) W

r.e (cid:48) -> s.y

p.e -> q.x

p.e -> q.x

r.e (cid:48) -> s.y

p• (cid:46) X | q• (cid:46) Y | r◦ (cid:46) Z | s◦ (cid:46) W

p◦ (cid:46) X | q◦ (cid:46) Y | r• (cid:46) Z | s• (cid:46) W

Observe that the self-loops from the AES are discarded because they do not go
through a node where all processes are unmarked.

From these SEGs, we can extract two deﬁnitions for X:

X = p.e -> q.x ; r.e (cid:48) -> s.y; X

and

X = r.e (cid:48) -> s.y; p.e -> q.x ; X

and both of these deﬁnitions correctly capture all behaviours of the network. (cid:47)

Validity implies, however, that there are some non-deadlocked networks that
are not extractable, such as p (cid:46) X | q (cid:46) Y | r (cid:46) Z where X = q!e; X, Y = p?x ; Y
and Z = p?y; Z, for which there is no valid SEG. This is to be expected, since
deadlock-freedom is undecidable in SP.

In practice, there are situations where livelocks are acceptable, namely in
the presence of a service that is designed to be used only when necessary. In
Section 5.3 we brieﬂy discuss how to deal with such cases.

3.3 Soundness and completeness

Since extraction ignores the deﬁnition of procedures, it is simple to ﬁnd coun-
terexamples to the second part of Theorem 1.

Example 12. Consider the very simple choreography

def X := p.e -> q.x ; p.e -> q.x ; X in p.e -> q.x ; X .

24

(cid:116)
(cid:116)
(cid:42)
(cid:42)
(cid:51)
(cid:51)
(cid:63)
(cid:63)
(cid:107)
(cid:107)
(cid:95)
(cid:95)
(cid:10)
(cid:10)
(cid:10)
(cid:10)
(cid:74)
(cid:74)
(cid:74)
(cid:74)
Its projection is the network

p (cid:46) def X := q!e; q!e; X in q!e; X | q (cid:46) def X := p?x ; p?x ; X in p?x ; X

which extracts to the choreography def X := p.e -> q.x ; p.e -> q.x ; X in X.

(cid:47)

We show that the ﬁrst part of this result still holds, from which it follows
that the analogue of Lemma 2 also applies. This proof is divided into several
steps.

Throughout this section, let N be a network, def D in C be the choreography
extracted from N for a particular SEG G, and σ be a state. We consider the
(possibly inﬁnite) sequences {λi}i∈I , {Ci}i∈I , and {σi}i∈I deﬁned as:

• C0 = C;
• σ0 = σ;
• for each i, λi is the label of the reduction executing the head action in
Ci (the only action that can be executed without applying any of the
structural congruence rules other than c-unfold);

• for each i, Ci+1 and σi+1 are the only choreography and state such that

Ci, σi

λi−→D Ci+1, σi+1;

• I = {0, . . . , n} if Cn is 0 for some n, and N otherwise.

Observe that Ci+1 and σi+1 are well-deﬁned, since the semantics of CC com-
pletely determines these terms given Ci, σi, and λi.

Lemma 7. There exists a sequence {ni}i∈I in G such that there is an edge

λ(cid:48)
i−→ ni+1, where λ(cid:48)

ni
for SP.

i is the label corresponding to λi in the abstract semantics

Proof. By induction on i. We take n0 to be the starting node in the construction
of G. By construction of C, for each i, there must be an outgoing edge labelled
with λ(cid:48)

i, and we deﬁne ni+1 as the target of that edge.

Lemma 8. There exists a sequence of networks {Ni}i∈I such that N0 = N and
Ni, σi

λi−→ Ni+1, σi+1.

λ0...λi−1
−−−−−−→∗ Ni, σi, where Ni is the
Proof. We prove by induction that N0, σ0
network labelling the node ni deﬁned in the previous lemma. This trivially
holds for i = 0. Now assume by induction hypothesis that it holds for i − 1.
Given how SEGs are constructed, λ(cid:48)
i is an abstraction of an action that Ni−1
can execute, and the only possible action corresponding to it is λi (since the
details missing in the abstraction are uniquely deﬁned by σi−1, and they coincide
for choreographies and networks). The semantics of SP guarantees that there
λi−→ N (cid:48), σ(cid:48). Since the abstract
exist unique N (cid:48) and σ(cid:48) such that Ni−1, σi−1
and concrete semantics act in the same way on networks, N (cid:48) = Ni; and since
an inspection of the rules for the semantics of CC and SP establishes that
σ(cid:48) = σi.

25

Lemma 9. For every i ∈ I and reduction label λ, Ci, σi can execute a reduction
labelled by λ iﬀ Ni, σi can execute a reduction labelled by λ.

λ−→D C (cid:48), σ(cid:48) for some C (cid:48) and σ(cid:48). Let j ≥ i be the
Proof. Assume that Ci, σ0
minimal index such that λ and λj share process names. Since structural pre-
congruence can only exchange actions that do not share process names and the
semantics of CC only allows one action for each process at each point, it imme-
diately follows that λ = λj. Furthermore, since no action in λi, . . . , λj−1 shares
process names with λ, it follows that the behaviour of the processes involved in
λ is unchanged in Ni, . . . , Nj and that σi(p) = σj(p) for every such process p.
Since Nj, σj can execute λ and the conditions for executing an action are local
λ−→ N (cid:48), σ(cid:48) for
to the processes involved in that action, this implies that Ni, σi
some network N (cid:48) – the same argument as in previous proofs implies that the
resulting state must be σ(cid:48).
Now assume that Ni, σi

λ−→ N (cid:48), σ(cid:48) for some N (cid:48) and σ(cid:48). Since the processes
involved in λ cannot participate in any other reductions, λ is enabled in all
nodes of G until an edge labelled by its abstract counterpart is traversed – in
other words, Ni, . . . , Nj can all execute λ for the least j ≥ i such that λ = λj.
Furthermore, such a j must exist due to the fairness conditions imposed by
Deﬁnition 8: since G is a valid SEG, either execution of Ni terminates (in which
case λ must have been executed) or there is a loop in the SEG, and every process
in the network must reduce at least once inside that loop (and again λ must
be executed in that loop). Since λ shares no process names with any actions in
λi, . . . , λj−1, it also follows that Ci can execute it, and as before the resulting
state must be σ(cid:48). We thus conclude that Ci, σi

λ−→D C (cid:48), σ(cid:48) for some C (cid:48).

The next lemma is a property of CC not directly related to extraction.

0, . . . , λ(cid:48)

Lemma 10. Let ˜λ(cid:48) = λ(cid:48)
j be a (ﬁnite) sequence of reduction labels
˜λ(cid:48)
D C (cid:48), σ(cid:48). Then there exist n ∈ N and a permutation π :
−→∗
such that C, σ
{0, . . . , n} → {0, . . . , n} such that λ(cid:48)
i = λ(π(i)) for i = 0, . . . , j. Furthermore, π
can be obtained by repeatedly transposing consecutive pairs of labels that share
no process names.

Proof (sketch). This result is a corollary of the proof of conﬂuence of CC from [13],
although it has not been stated in this form before. Conﬂuence is proved by
ﬁrst showing that executing two independent actions in any order always yields
the same result. This is extended by induction to sequences of actions, where
the inductive case is split according to whether both sequences start with the
same action.

The current lemma follows from observing that we can choose a large enough
n such that all actions in ˜λ(cid:48) occur in λ0, . . . , λn. Unfolding the proof of conﬂu-
ence as described above iteratively applies a transposition of consecutive inde-
pendent actions to λ0, . . . , λn, until this sequence starts with λ(cid:48)
j. The
composition of these transpositions yields the permutation π.

0, . . . , λ(cid:48)

26

0, . . . , λ(cid:48)

Lemma 11. Let ˜λ(cid:48) = λ(cid:48)
j be a (ﬁnite) sequence of reduction labels
˜λ(cid:48)
−→∗ N (cid:48), σ(cid:48). Then there exist n ∈ N and a permutation π :
such that N, σ
{0, . . . , n} → {0, . . . , n} such that λ(cid:48)
i = λ(π(i)) for i = 0, . . . , j. Furthermore, π
can be obtained by repeatedly transposing consecutive pairs of labels that share
no process names.

0, . . . , λ(cid:48)

Lemma 12. Let ˜λ(cid:48) = λ(cid:48)
j be a preﬁx of any sequence of reduction labels
obtained by repeatedly transposing consecutive elements of λ that share no pro-
cess names. Then there exist a choreography C (cid:48), a network N (cid:48) and a state σ(cid:48)
˜λ(cid:48)
−→ N (cid:48), σ(cid:48). Furthermore, the actions that

˜λ(cid:48)
−→D C (cid:48), σ(cid:48) and N, σ

such that C, σ
C (cid:48) and N (cid:48) can execute coincide.

Proof. By induction on the number of transpositions applied. If this number
is 0, then this is simply Lemma 9.

i, λ(cid:48)

i+1 coincides with the result of executing λ(cid:48)

Assume by induction hypothesis that the thesis holds for {λ(cid:48)

i}i∈I obtained
by applying n transpositions to consecutive actions in λ, and suppose that
λ(cid:48)
i and λ(cid:48)
i+1 share no process names. Note that the thesis holds for the se-
for j < i the
quence obtained by swapping these two labels for any j (cid:54)= i:
sequence λ(cid:48) is unchanged, while conﬂuence ensures that the result of executing
λ(cid:48)
0, . . . , λ(cid:48)
i for both
C and N . But as observed before, a reduction does not change the possible
actions of processes not involved in it. Since λi and λi+1 do not share any such
λ(cid:48)
0,...,λ(cid:48)
−−−−−−−−−−→D C (cid:48)(cid:48), σ(cid:48)(cid:48), then the executable actions in C (cid:48)(cid:48)
processes, if C, σ
are those that were already available in the previous step, together with any
actions unblocked by λi+1. Furthermore, the latter actions remain unchanged
after executing λi. A similar reasoning applies to the executable actions in N (cid:48)(cid:48),
λ(cid:48)
0,...,λ(cid:48)
−−−−−−−−−−→ N (cid:48)(cid:48), σ(cid:48)(cid:48). Since the set of executable actions before
where N, σ
and after executing λi+1 and λi coincide, the actions executable by C (cid:48)(cid:48) and N (cid:48)(cid:48)
are deﬁned in the same way, and therefore must also coincide.

0, . . . , λ(cid:48)

i+1, λ(cid:48)

i−1,λ(cid:48)

i−1,λ(cid:48)

i+1

i+1

Theorem 2. If C is a choreography extracted from a network N , then N ∼ C.

Proof. Let N be a network, C be a choreography extracted from N , and σ be a
state. Deﬁne a relation R ⊆ C × N , where C = {C (cid:48) | C, σ →∗ C (cid:48)σ(cid:48) for some σ(cid:48)}
˜λ(cid:48)
−→∗
and N = {N (cid:48) | N, σ →∗ N (cid:48), σ(cid:48) for some σ(cid:48)}, as follows: C (cid:48)RN (cid:48) if C, σ
D
˜λ(cid:48)
−→∗ N (cid:48), σ(cid:48) for some sequence of actions ˜λ(cid:48).
C (cid:48), σ(cid:48) and N, σ

D C (cid:48), σ(cid:48) and N, σ

We show that R is a bisimulation. Assume that C (cid:48)RN (cid:48). Then there exists
˜λ(cid:48)
˜λ(cid:48)
a sequence of actions ˜λ(cid:48) such that C, σ
−→∗ N (cid:48), σ(cid:48). By
−→∗
Lemma 10, ˜λ(cid:48) can be obtained from ˜λ by repeatedly permuting two consecutive
independent actions and taking an initial segment of the result. By Lemma 12,
the actions that C (cid:48) and N (cid:48) can execute are therefore the same. For each such
action α, we can again apply Lemmas 10 and 12 to the sequence ˜λ(cid:48); α to conclude
that, if C (cid:48), σ(cid:48) α−→D C (cid:48)(cid:48), σ(cid:48)(cid:48), then there exists N (cid:48)(cid:48) such that N (cid:48), σ(cid:48) α−→ N (cid:48)(cid:48), σ(cid:48)(cid:48);
conversely, if N (cid:48), σ(cid:48) α−→ N (cid:48)(cid:48), σ(cid:48)(cid:48), then applying Lemmas 11 and 12 yields that
C (cid:48), σ(cid:48) α−→D C (cid:48)(cid:48), σ(cid:48)(cid:48) for some C (cid:48)(cid:48).

27

4

Implementation

We now describe an implementation of the algorithm presented in Section 3,
with emphasis on the interesting technical details. The main challenge is com-
puting a valid SEG for the input network eﬃciently, or determining in reasonable
time that none exists; we follow the idea, given previously, of lazily expanding
the relevant parts of the AES until a valid SEG is found or we can safely conclude
that none exists.

4.1 Overview

The extraction algorithm is implemented in a depth-ﬁrst manner, starting with
a single node (the initial network, properly annotated), on which we call a
method, buildGraph, graphically described in Figure 11. This method builds
a list of all actions that the network can execute: a communication (of either a
value or a label) between two processes, or the execution of a conditional at a
process. This list includes actions that require unfolding procedure calls. Then,
the method tries to complete the SEG assuming that the ﬁrst action in the list
is executed, returning true if this succeeds. If this step fails, the next action in
the list is considered. If no action leads to success, buildGraph returns false.
Actions are processed by two diﬀerent methods, depending on their type.
In the case of communications, method buildCommunication (see Figure 12)
computes the network resulting from executing the action, and checks whether
there exists a node in the graph containing it. In the aﬃrmative case, it checks
whether adding an edge to that node creates a valid loop; if so, the edge is
added and the method returns true; otherwise, the method returns false. If
no such node exists, a fresh node is added with an edge to it from the current
node, and buildGraph is called recursively on the newly created node.

The case of conditionals is more involved, since two branches need to be
created successfully. Method buildConditional (Figure 13) starts by treating
the then case, much as described above, except that in case of success (by
closing a loop or by building a new node and receiving true from the recursive
invocation of buildGraph) it does not return, but moves to the else branch.
If this branch also succeeds, the method returns true; if it fails, then it returns
false and deletes all edges and nodes created in the then branch from the
graph: this step is essential for soundness of the method deciding loop validity
(see Section 4.2).

Edges created by buildCommunication and buildConditional are as in
Deﬁnition 4. In the network(s) in target node(s), we unfold exactly those pro-
cedure calls necessary for the action labelling the edge to be executed and update
the annotations.

If the main call to buildGraph returns true, the graph created is a valid SEG
for the given network. We then proceed to computing a choreography according
to Deﬁnition 7. Method unrollGraph is called to identify and split nodes corre-
sponding to procedure calls. Finally, we extract the main choreography and all
procedure deﬁnitions from the relevant nodes recursively by reading the edges of

28

START

N = 0?

no

next action?

none

cond

false

yes

com

buildCommunication

buildConditional

false

result?

true

unrollGraph

buildChoreographyBody

yes

more?

no

choreography

Figure 11: Graphical depiction of buildGraph.

29

START

yes

reductum
in graph?

no

valid loop?

no

false

yes

true

buildGraph

false

result?

true

Figure 12: Graphical depiction of buildCommunication.

the SEG as an abstract syntax tree, AST (method buildChoreographyBody).

4.2 Recognising bad loops

The critical part of buildGraph is deciding when a loop can be closed. Deﬁni-
tion 8 requires all paths that form a loop to include a node where all processes
are unmarked. Checking this directly is extremely ineﬃcient, as it requires re-
traversing a large part of the graph; instead, we reduce this problem to list
membership. In order to do this, we enhance the graph structure in diﬀerent
ways, so they are not simply networks anymore. We describe each addition
below.

Choice-free networks.
In order to best structure our explanation of our
method, we ﬁrst consider the simpliﬁed case where processes do not use the
conditional operator. We construct the SEG iteratively by maintaining a set
of unexplored nodes. Whenever an unexplored node is examined, the possible
reductions lead to new terms, and, by keeping all created nodes in a search
structure, we can determine with a simple lookup if we have created a network
that already exists in the graph we have built so far, and get a reference to that
node in the SEG. Thus, we do not recreate the node and we form a loop.

Forming a loop, we need to check if the loop contains an all-white node,
and we handle this as follows. Since we stop our search and start backtracking
when we discover a loop, we conceptually have a path from the start node to
our current node at all times, and the path behaves in a stack-like manner.
We introduce an explicit stack as an auxiliary data structure. Each node on
the current path has a pointer to its entry on the stack. An item on the stack
contains a counter of how many white nodes can be found further down on the

30

START

yes

then
reductum
in graph?

no

valid loop?

no

false

yes

yes

else
reductum
in graph?

no

buildGraph

false

result?

true

buildGraph

valid loop?

no

false

yes

clear then nodes

false

result?

true

true

Figure 13: Graphical depiction of buildConditional.

31

stack. This information can easily be maintained as we push and pop elements
in connection with running the backtracking algorithm. When we encounter a
loop, we follow the pointer to the node’s associated stack item and check the
counter, c. The loop just found has at least one white node if and only if the
counter of the top item on the stack is strictly greater than c.

Choice paths. The soundness of the strategy described above relies on the
fact that, while building the graph, no new edges are added between existing
nodes that make it possible to close a loop bypassing the edge where the marking
was erased. This is automatically guaranteed when a communication action is
selected (the corresponding node only has one outgoing reduction), but not in
the case of conditionals.

Using the method outlined in Section 4.2, following a path from an else
branch, we may arrive at a node somewhere on the then branch. Basing our
decision of loop validity on the counter may give an incorrect result, since we
may enter into some location on the then branch after the all-white node. Thus,
the counters would indicate that the loop was valid, but, in fact, no all-white
node was encountered on the else branch.

To avoid this problem, we restrict edge creation so that we can only add an
edge to an existing node if that node is a “predecessor” of the current node with
respect to conditionals, i.e., it was not generated while expanding a diﬀerent
branch of a conditional statement. We do this by annotating each node with
a choice path: a string that represents the sequence of conditional branches on
which the node depends. The initial node has an empty choice path, nodes
generated from a communication action inherit their parent’s choice path, and
nodes generated from a conditional get their parent’s choice path appended with
a 0 or 1 for then and else branch, respectively.

We use choice paths in our algorithm for building a SEG (buildGraph) as
follows. Whenever buildGraph checks whether a node with the target network
already exists in the graph, we now additionally require the node with the target
network to have a choice path that is a preﬁx of the current node’s (the node
on which buildGraph has been invoked); otherwise, we proceed as if no such
node exists (and create a new node).

4.3 Well-formedness

Until this point, we have assumed networks to be well-formed (Section 2.1).
While most networks that are not well-formed are not extractable (some pro-
cesses are deadlocked and therefore there is no valid SEG), this may still take
a long time to detect. Therefore, we have added an initial check that the net-
work we are trying to extract is well-formed (before calling buildGraph), and
immediately fail in case it is not. Having this check also allows us to assume
that the network is well-formed throughout the remainder of execution, which
is relevant for some later optimisations.

32

4.4 Guardedness of procedure calls

Many previous works on process calculi require procedure calls to be guarded
(preceded by a communication action or a conditional), in order to avoid situ-
ations such as def X = X in X. Our language has no such restriction; however,
by deﬁnition, a network containing a process whose behaviour unfolds inﬁnitely
to a procedure call has no valid SEG: such a process would be either livelocked
in a loop or non-terminated in a leaf.

To detect these situations, our implementation includes a preprocessing
check to ensure that no deﬁnition of a procedure accessible from the main be-
haviour of a process can unfold to a self-call. For example, we do allow def X =
X in 0 and def {X = Y, Y = q!;X} in X, but not def {X = Y, Y = X} in X.
Having this previous check again simpliﬁes the building of the graph, since we
know in advance that we cannot get into inﬁnite loops by repeatedly unfolding
a behaviour until we meet an action.

4.5 Complexity

Before discussing optimizations and performance on test cases, we end this
section with a discussion of the worst-case computational complexity of our
method. The starting point is the size of the AES for an annotated network.

Lemma 13. The AES for an annotated network of size n has at most e 2n
vertices.

e

Proof. Let N be a network with p processes of sizes n1 through np, where the
size of a process is the number of nodes in an abstract syntax tree representing
the syntactical term. Let n = (cid:80)p

i=1 ni denote the size of N .

Since recursive deﬁnitions are unfolded only when they occur at the top of a
behaviour, a process of size ni can give rise to at most ni diﬀerent terms when
all possible reductions are considered. Thus, N can reduce to at most (cid:81)p
i=1 ni
diﬀerent terms. Since the reductions give rise to the edges in the graph, this is
also an upper bound on the number of edges, so the graph is sparse. By the
AM-GM inequality, (cid:81)p
i=1 ni is maximised when all the ni are equal, where it
evaluates to

(cid:17)p

.

(cid:16) n
p

We now consider annotations. Since each process is either marked or un-
marked, there are at most 2p annotations for each network, giving a total upper
bound of 2p( n
p )p = ( 2n
p )p diﬀerent nodes in the AES. This expression attains its
e , giving the upper bound of e 2n
maximum when p = 2n
Next we consider the extraction of the enhanced SEG from the AES.

e nodes in the AES.

Theorem 3. Extraction from a network of size n with c conditionals terminates
in time O(2cne 2n

e ).

Proof. For networks without conditionals, we develop a network of size at most
e 2n
e , as outlined in Sections 4.2 and bounded in Lemma 13. However, adding the

33

choice path as part of the node identity, as outlined in Section 4.2, the number
of possible diﬀerent nodes is increased by a factor 2c, representing all possible
choice paths, where c is the number of conditionals in the network – which is
of course (much) smaller than n. Look-up for a node to check if it is new has
time complexity worst-case logarithmic in the size of the set of nodes, using any
standard dictionary implementation, i.e., O(log(2ce 2n
e )) ⊆ O(n), plus a check
for term identity which is also O(n). Clearly maintaining the auxiliary stack
takes constant time in each step, and with the stack available, we can check
for bad loops in constant time as well. Thus, the overall time complexity is
O(n2ce 2n

e ).

As mentioned in the introduction, our method avoids the factorial time com-
plexity of previous work. Exponential time is better than factorial, but we may
perform even better in practice. Algorithmically, all the required work stems
from traversals of the AES, so any reduction in its (explored) size will lead to
proportional runtime improvements. We point out that in the algorithms pro-
posed above, instead of ﬁrst computing the entire AES and then a valid SEG,
we compute the relevant parts of the AES lazily as we need them. Thus, parts
of the AES that are never explored while computing a valid SEG are never
generated.

5 Extensions and optimisations

We now discuss some extensions and optimisations to the original algorithm.
Some of these changes aim at making make the implementation more eﬃcient
in situations that may occur often enough to warrant consideration; others ex-
tend the domain of extractable choreographies, and were motivated by practical
applications.

5.1 Parallelisation

In our ﬁrst testing phase (see Section 6), we took the benchmarks from [19] and
wrote them as networks. This translation was done by hand, ensuring that the
network represented the same protocol as the communicating automata in the
original work. Of these, 3 benchmarks (alternating 2-bit, alternating 3-bit and
TPMContract) were not implemented. The ﬁrst uses group communications,
an extension described in [7] that is not implemented; the two last require local
threads, and are not representable in our formalism. (We discuss this in the
conclusions.)

Several benchmarks are parallel compositions of two instances of the same
network. They exhibit a very high degree of parallelism, visibly slowing down
extraction. However, very simple static analysis can easily improve performance
in such instances. We deﬁne the network’s communication graph as the undi-
rected graph whose nodes are processes, and where there is an edge between
p and q if they ever interact. The connected components of this graph can be

34

Table 1: Empirical evaluation of the eﬀect of parallelising extraction (all times
in ms).

Test name

sequential
double

single

ratio

single

parallel
double

ratio

single

from [19]
double

Bargain
Cloud system
Filter collaboration
Health system
Logistic
Running example
Sanitary agency

1.7
8.3
4.0
6.0
1.0
7.7
6.0

10.0
83.0
123.3
80.3
34.7
143.3
61.0

5.88
10.0
30.83
13.39
34.70
18.61
10.17

3.0
8.6
5.0
7.3
5.3
5.7
8.0

3.7
8.3
4.7
11.7
16.7
6.7
7.3

1.23
0.96
0.93
1.59
3.14
1.17
0.92

103
140
118
17
276
184
241

161
432
178
1702
2155
22307
3165

ratio

1.56
3.08
1.51
100.12
7.81
121.23
13.13

extracted independently, and the choreographies obtained composed in parallel
at the end.

Theoretically, this requires adding a parallel composition constructor at the
top level of a choreography, which is straightforward. In practice, this trivial
preprocessing drastically reduces the computation time:
for the (very small)
benchmarks from [19], doubling the size of the network already corresponds to
a increase in computation time of up to 35 times, while splitting the network in
two and extracting each component in sequence keeps this factor under 2, since
the independent components can be extracted in parallel.

We report our empirical evaluation in Table 1. These numbers are purely
indicative: due to the very small size of these examples, we did not attempt
to make a very precise evaluation. We measured the extraction time for all
benchmarks, and computed the ratio between each benchmark containing a du-
plicate network and the non-duplicated one. This was done with the original,
sequential, algorithm, and with the parallelised one. All execution times were
averaged over three runs. The values themselves are not directly comparable to
those from [19], since the network implementations are substantially diﬀerent,
but the ratios show the advantages of our approach: even without paralleli-
sation, our ratios are substantially lower, in line with the better asymptotical
complexity of our method shown in [7]. (Note that the examples from [19] where
the ratio is lowest are the smallest ones, where the execution time is dominated
by the setup and command-line invocation of the diﬀerent programs used.)

5.2 Extraction strategies

The performance of our implementation depends on the choice of the network
action, in cases where there are several possible options: expanding a commu-
nication generates one descendant node, but expanding a conditional generates
two descendant nodes that each need to be processed. On the other hand, if the
choreography contains cyclic behaviour, diﬀerent choices of actions may impact
the size of the extracted loops (and thus also execution time).

35

In order to control these choices, we deﬁne execution strategies: heuristics
that guide the choice of the next action to pick. Strategies either take into
account the syntactic type of the action (e.g., prioritise interactions) or the
semantics of bad loops (prioritise unmarked processes), or combine them with
diﬀerent priorities (prioritise unmarked processes and break ties by preferring
interactions). We also include a basic strategy that picks a random action.

All strategies are implemented in the same way: in buildGraph, we choose
from the list of possible actions that the network in the current node according
to the chosen criterion.

Our implementation includes the following strategies. The abbreviations in

parenthesis are used in captions of graphics.

Random (R) Choose a random action.

LongestFirst (L) Prioritise the process with the largest body.

ShortestFirst (S) Prioritise the process with the smallest body.

InteractionsFirst (I) Prioritise interactions.

ConditionalsFirst (C) Prioritise conditionals.

UnmarkedFirst (U) Prioritise actions involving unmarked processes.

UnmarkedThenInteractions (UI) Prioritise actions involving unmarked pro-

cesses, and as secondary criterion prioritise interactions.

UnmarkedThenSelections (US) Prioritise unmarked processes, as a secondary
criterion prioritise selections, and afterwards value communications.

UnmarkedThenConditionals (UC) Prioritise unmarked processes, and as sec-

ondary criterion prioritise conditionals.

UnmarkedThenRandom (UR) Prioritise unmarked processes, in random order.

We remark that UnmarkedFirst and UnmarkedThenRandom are diﬀerent strate-

gies: UnmarkedFirst does not distinguish among actions involving unmarked
processes, so they come in the order of the processes involved in the network.
By contrast, UnmarkedThenRandom chooses randomly from the list of possible
actions, in principle contributing towards more fairness among processes.

From the results in the next section, we see that LongestFirst and ShortestFirst
perform signiﬁcantly worse than all other strategies, while Random and UnmarkedFirst
in general give the best results. However, we remark that comparing the per-
formances of diﬀerent strategies was not an objective of this work, as it would
require a dedicated test suite. We leave it as interesting future work.

36

5.3 Livelocks

Several examples in [19] include processes that oﬀer a service, and as such may
be inactive throughout a part (or the whole) of execution. This is the case in
our Example 7: process r provides a value to q whenever it is needed, but q
might stop requesting values during execution. Our extraction algorithm does
not allow for this behaviour: when a loop is closed, every process must either
be terminated or reduce inside the loop.

In order to allow for services, we added a parameter to the extraction method
containing a list of services (in our example, r), which are not required to reduce
Intuitively, we ignore the annotations in these processes when
inside loops.
deciding whether a loop is valid.
In the implementation, these processes are
marked initially, and are not unmarked when the marking is erased.

5.4 Clever backtracking

Our strategy of building the SEG in a depth-ﬁrst fashion requires that, on
failure, we backtrack and explore diﬀerent possible actions. This leads to a
worst-case behaviour where all possible execution paths need to be explored,
in the case that no choreography can be extracted from the original network.
However, a closer look at why a particular branch leads to deadlock allows us
to avoid backtracking in some instances: network execution is conﬂuent, so if
we reach a deadlocked state, then every possible execution reaches such a state,
and extraction must fail. It is only when extraction fails because of attempting
to close an invalid loop that backtracking is required.

To implement this reﬁnement, the return type of all methods that try to
build an edge of the SEG was changed to a 3-element set. If a method succeeds,
it returns ok (corresponding to true); if it fails due to reaching a deadlock, it
returns fail (corresponding to false); and if it fails due to trying to close an
invalid loop, it returns badloop. In recursive calls, these values are treated as
follows:

• if the caller is processing a communication or the else branch of a condi-

tional, they are propagated upwards;

• if the caller is processing the then branch of a conditional, fail and badloop
are propagated upwards, while ok signals that the else branch can now
be treated.

For buildGraph, a method call returning ok or fail is also propagated up-
wards, while badloop signals that a diﬀerent possible action should be tried. If
all possible actions return badloop, then buildGraph returns fail. This is sound:
due to conﬂuence, any action that could have been executed before that would
make it possible to close a loop from this node can also be executed from this
node.

This optimisation is crucial to get a practical implementation in the case of
unextractable networks. Most of the failure tests (Section 6.3) did not terminate
before this change, while they now fail in time comparable to that of success.

37

6 Practical evaluation

In order to evaluate the performance of our implementation, we developed a
three-stage plan.

Phase 1. We focused on the test cases from [19], in order to ensure that our tool
covered at least those cases. Since these cases are simple, we veriﬁed
their correctness by hand.

Phase 2. We generated 1050 random choreographies and their projections by
varying four diﬀerent parameters (see details below), and applied our
tool to the projected networks.
In this way, we tested whether we
can extract networks that are direct projections of choreographies –
these should correspond to the majority of (extractable) practical ap-
plications. Soundness can be checked by testing that the extracted
choreography is bisimilar to the original one.

Phase 3. We proposed a model for the typical changes (correct or incorrect)
introduced when a programmer modiﬁes a process directly, and tried
to extract choreographies from the resulting networks. This yielded
information about how quickly our program fails when a network is
unextractable; as a side result, we also got information about how often
some types of protocol errors can slip through undetected, that is, the
network is still extractable, but it implements a diﬀerent protocol than
the original.

We deliberately did not generate any networks directly. We claim that such
tests are not very meaningful for two reasons: ﬁrst, they do not correspond
to realistic scenarios; second, randomly generated networks are nearly always
unextractable. We believe our test suite is comprehensive enough to model most
situations with practical relevance.

All tests reported in this section were performed on a computer running
Arch Linux, kernel version 5.14.8, with an AMD Ryzen 9 3950x as CPU and 50
GB RAM as available memory for the Java Virtual Machine.

6.1 Comparison with the literature

Our ﬁrst testing phase used the benchmarks from [19]. As described in Sec-
tion 5.1, the networks corresponding to those examples were written by hand.
These tests were done simply as a proof-of-concept, as their simplicity means
that the measured execution times are extremely imprecise. As discussed ear-
lier, three test cases were not implementable; all others succeeded. The results
(using strategy InteractionsFirst) are reported in Table 1.

6.2 Reverse projection

In the second phase, we generate large-scale tests to check the scalability of
our implementation. Our tests consist of randomly-generated choreographies

38

Table 2: Parameters for the choreographies generated for testing.
ifs

parameter

processes

Test set

size

defs # tests

size
processes
ifs (ﬁnite)
ifs (varying procedures)
procedures (ﬁxed ifs)

k ∈ [1..42]
k ∈ [1..20]
k ∈ [1..4]
(cid:104)j, k(cid:105) ∈ [0..5] × [0..3]
k ∈ [1..15]

50k
500
50
200
20

6
5k
6
5
5

0
0
10k
j
8

0
0
0
5k
k

total

420
200
40
240
150

1050

characterised by four parameters: number of processes, total number of actions,
number of those actions that should be conditionals, and a number of proce-
dures.

Then, we generate ten choreographies for each set of parameters as follows:
ﬁrst, we determine how many actions and conditionals each procedure deﬁni-
tion (including main) should have by uniformly partitioning the total number
of actions and conditionals. Then we generate the choreography sequentially
by randomly choosing the type of the next action so that the probability dis-
tribution of conditional actions within each procedure body is uniform. For
each action, we randomly choose the process(es) involved, again with uniform
distribution, and assigned fresh values to any expression or label involved. At
the end, we randomly choose whether to end with termination or a procedure
call. Finally, we apply rules for swapping conditionals (rules c-cond-eta and
c-cond-cond from Figure 7) to obtain ineﬃcient representations of choreogra-
phies where code is duplicated in both branches of a conditional. (This actually
increases the number of conditionals in a choreography from at most 50 to over
8000 in some cases.)

This method may generate choreographies with dead code (if some proce-
dures are never called). Therefore there is a post-check that determines whether
every procedure is reachable from main (possibly dependent on the results of
some conditional actions); if this is not the case, the choreography is rejected,
and a new one is generated.

A randomly generated choreography with conditional actions is typically
unprojectable, so we amend it (see [10]) to make it projectable. In general, this
increases the size of the choreography. Finally, we apply projection to obtain
the networks for our second test suite.

The parameters for generation are given in Table 2. The upper bounds were
determined by our hardware limitations. Four of the generated ﬁles contained
tests that were too large to extract, and were removed from the ﬁnal test set.

Results. We report on the most interesting tests. The ﬁrst test shows that,
predictably, for choreographies consisting of only communications, the extrac-
tion time is nearly directly proportional to the network size (with a small over-
head from needing to work with larger objects), except when using strategies

39

1

·104

L
S

0.5

0

)
c
e
s
m

(

e
m
T

i

I
R

)
c
e
s
m

(

e
m
T

i

600

400

200

0

0

1,000

2,000

0

1,000

2,000

Number of actions

Number of actions

Figure 14: Execution time vs. length for networks consisting only of commu-
nications. The omitted strategies essentially perform as InteractionsFirst,
since there are no other types of actions and no recursive procedures.

that need to compute the size of each process term. We could enrich the net-
works with this information in order to make these strategies more eﬃcient, but
since they perform poorly in general, we did not pursue this approach.

The second test is similar, but varying the number of processes (which makes
for a greater number of possible actions at each step) while keeping the size con-
stant. Our results show that execution time grows linearly with the number of
processes for InteractionFirst and Random. The behaviour of LongestFirst
and ShortestFirst is more interesting, as the time for computing the length
of the behaviours dominates for small numbers of processes.

The third test introduces conditionals. Our results show that execution time
varies with the total number of conditionals in the network, rather than with
the number of conditionals in each process. Figure 16 (left) exhibits the worst-
case exponential behaviour of our algorithm, and also suggests that delaying
conditionals is in general a better strategy. Figure 16 (right) shows the number
of nodes created in the SEG, illustrating that execution time is not directly
proportional to this value.

The behaviour when recursive procedures also occur is shown in Figure 17,

where we ﬁx the number of procedures to 5.

The ﬁnal tests introduce variations in the number of procedures. The results
of these tests are too complex to allow for immediate conclusions. Figure 18
shows what happens when we vary the number of procedures for choreographies
without conditionals. Although the number of procedures potentially inﬂuences
the number of loops in the AES, this dependency is likely too complex to be
visible in the test results.

When we vary the number of procedures in more complex scenarios, the

picture is even less clear, and we omit a discussion of these results.

40

L
S

)
c
e
s
m

(

e
m
T

i

300

200

I
R

200

150

100

50

)
c
e
s
m

(

e
m
T

i

0

50
Number of processes

100

0

50
Number of processes

100

Figure 15: Execution time vs. number of processes, with constant total number
of actions.

·105

L
C
I
R

)
c
e
s
m

(

e
m
T

i

4

2

0

·105

L
C
I
R

d
e
t
a
e
r
c

s
e
d
o
N

8

6

4

2

0

0

50,000

1 · 105

0

50,000

1 · 105

Total #ifs in network

Total #ifs in network

Figure 16: Execution time (left) and number of nodes (right) vs. total number of
conditionals, for networks consisting only of conditionals. The omitted strategies
essentially perform as InteractionsFirst or ConditionalsFirst.

41

)
c
e
s
m

(

e
m
T

i

60

40

20

0

L
C
I
R

0

2

4

6

Total #ifs in network

)
c
e
s
m

(

e
m
T

i

80

60

40

20

0

U
UR
UI
UC

0

2

4

6

Total #ifs in network

Figure 17: Execution time vs. total number of conditionals for networks includ-
ing 5 recursive procedures.

C
I
R

10

8

6

4

)
c
e
s
m

(

e
m
T

i

U
UR
UI
UC

)
c
e
s
m

(

e
m
T

i

10

8

6

4

0

5

10

15

0

5

10

15

Number of procedures

Number of procedures

Figure 18: Execution time vs. number of procedures, no conditionals.

42

In order to obtain conﬁrmation of the correctness of our algo-
Correctness.
rithm and its implementation, we performed an additional veriﬁcation at this
point. We implemented a naive similarity checker that tests whether a chore-
ography C1 can simulate another choreography C2 as follows: we keep a set of
pairs R, initially containing only the pair (cid:104)C1, C2(cid:105). At each step, we choose a
pair (cid:104)C, C (cid:48)(cid:105) from R and compute all actions α and choreographies Cα such that
C can reach Cα by executing α. For each such action α, we check that C (cid:48) can
execute α, compute the resulting choreography C (cid:48)
α, and add the pair (cid:104)Cα, C (cid:48)
α(cid:105)
to R. If C (cid:48) cannot execute α, the checker returns false. When all pairs in R
have been processed, the checker returns true.

We then check, for each test, that the original choreography and the one

obtained by extraction can simulate each other.

Lemma 14. If C1 and C2 can simulate each other, then there is a bisimulation
between C1 and C2.

Proof. We ﬁrst observe that the ﬁnal set R computed by the algorithm is always
the same, regardless of the order in which pairs are picked.

Let R12 and R21 be the sets built when checking that C2 simulates C1 and
that C2 simulates C1, respectively. We show by induction on the construction of
R12 that R−1
12 ⊆ R21. Initially this holds, since R12 = {(cid:104)C1, C2(cid:105)} and (cid:104)C2, C1(cid:105) is
initially in R21. Suppose (cid:104)C, C (cid:48)(cid:105) ∈ R12 is selected for processing. By induction
hypothesis, (cid:104)C (cid:48), C(cid:105) ∈ R21. For every α such that C can execute α and move to
Cα, there is a unique choreography C (cid:48)
α such that C (cid:48) can execute α and move to
α. Therefore, in the step where (cid:104)C (cid:48), C(cid:105) is selected from R21, every such pair
C (cid:48)
(cid:104)C (cid:48)
α, Cα(cid:105) is added to R21, hence it is in the ﬁnal set. Thus, after extending R12
with all the pairs obtained from (cid:104)C, C (cid:48)(cid:105), the thesis still holds.

By reversing the roles of C and C (cid:48), we also establish that R−1

21 ⊆ R12. There-
21 . It then follows straightforwardly that R12 is a bisimulation

fore R12 = R−1
between C1 and C2.

Given that bisimulation is in general undecidable and that we did not make
any eﬀort to make a clever implementation, our program often runs out of re-
sources without terminating. Still, it ﬁnished in about 5% of the tests (those
of smaller size), always with a positive result. While this may not sound im-
pressive, it is unlikely that errors in the implementation would only show up
in larger tests, and this result increases our conﬁdence in the soundness of the
implementation.

6.3 Fuzzer and unroller

In the third testing phase, we changed the networks obtained by choreography
projection using two diﬀerent methods. The ﬁrst method (the fuzzer ) applies
transformations that are semantically incorrect, and typically result in unex-
tractable networks (modelling programmer errors). The second method (the
unroller ) applies transformations that are semantically correct, and result in

43

networks that are bisimilar to the original and should be extractable (modelling
alternative implementations of the same protocol).

The fuzzer. For the fuzzer, we considered the following transformations:
adding an action; removing an action; and switching the order of two actions.
The ﬁrst two always result in an unextractable network, whereas the latter may
still give an extractable network that possibly implements a diﬀerent protocol.
Our fuzzer takes two parameters d and s, randomly chooses one process
in the network, deletes d actions in its deﬁnition and switches s actions with
the following one. The probability distribution of deletions and swaps is uni-
form (all actions have the same probability of being deleted of swapped). We
made the following conventions: deleting a conditional preserves only the then
branch; deleting a branching term preserves only the ﬁrst branch oﬀered; swap-
ping a conditional or branching with the next action switches it with the ﬁrst
action in the then/ﬁrst branch; and swapping the last action in a behaviour
with the next one amounts to deleting that action. Deleting a conditional re-
sults in an extractable network that implements a subprotocol of the original
one, while other deletions yield unextractable networks. Exchanges of commu-
nication actions may yield extractable networks, but with a diﬀerent extracted
choreography; all other types of exchanges break extractability.

We did not implement adding a random action, as this is covered in our
tests: adding an unmatched send from p to q can be seen as removing a receive
at q from p from a choreography that includes that additional communication.
We restricted fuzzing to one process only since in practice we can assume that
processes are changed one at a time. We applied three diﬀerent versions of
fuzzing to all our networks: one swap; one deletion; and two swaps and two
deletions. The results are summarised in Table 3.

The diﬀerences in the percentages in the ﬁrst row are due to memory running
out in some cases, but they are small enough as to be statistically irrelevant.
In later rows, most networks are unextractable; the interesting observation here
is that strategies prioritising actions that involve two processes and unmarked
processes tend to fail faster.

The unroller. Projections of choregraphies are intuitively easy to extract
because their recursive procedures are all synchronised (they come from the
same choreography).
In practice, this is not necessarily the case: programs
often include “loops-and-a-half”, where it is up to the programmer to decide
where to place the duplicate code; and sometimes procedure deﬁnitions can be
if X = p.e -> q.x ; p.e (cid:48) -> q.x ; p.e (cid:48)(cid:48) -> r.y; X,
locally optimised. For example:
then in the extracted implementation of q the deﬁnition of Xq can simply be
p?x ; X.

Our unroller models these situations by choosing one process and randomly
unfolding some procedures, as well as shifting the closing point of some loops.
These transformations are always correct, so they should yield extractable net-
works, but extraction time may be larger and there may be higher chance for

44

Table 3: Extracting fuzzed networks: for each strategy we report on the per-
centage of unextractable networks (%) and the average and median times to fail
in those cases (ms). We highlight the best and worst values in each column in
green and red, respectively.

Strategy

d = 0, s = 1

d = 1, s = 0

avg med %

avg med

d = 2, s = 2
% avg med

%

45
45
43
43
46
45
42
44
45
44

R
L
S
I
C
U
UI
US
UC
UR

384
1171
1627
400
451
368
394
358
414
370

10
13
13
11
9
10
10
10
10
10

99
99
99
99
99
99
99
99
99
99

198
1080
1163
175
226
192
185
185
208
204

18
85
124
19
21
17
21
19
18
17

100
100
100
100
100
100
100
100
100
100

85
664
696
73
106
98
94
94
104
80

9
44
45
15
9
10
12
11
13
9

bad loops. We generated 240 tests, which we were all able to extract, and com-
pared the extraction times for the original and unrolled networks. In Table 4
we report the average and median ratios for each extraction strategy.

The table shows that unrolling slows down the extracter somewhat, but in
a very asymmetric way: for most networks the changes are minor (shown by
the median around 1), while for a few there are very large changes in either
direction. An analysis of the raw data shows that:

• there is no general trend – in some cases the unrolled network is fastest

to extract, in other cases it is slower;

• in most cases the ratio is close to 1 (and in many exactly 1, due to the

fact that execution times are rounded to the nearest millisecond);

• ratios vary from as low as 0.0003 to as high as 1505.

7 Conclusions and Discussion

We have presented an eﬃcient algorithm for extracting choreographies from
network speciﬁcations, improving the original conference presentation in [7]. We
have successfully implemented this algorithm, developed the ﬁrst comprehensive
test suite for evaluating this kind of algorithms, and used the test suite to
evaluate our implementation. Our results are very encouraging compared to
previous work [19], and open the door to interesting future developments. We
discuss some of them.

45

Table 4: Extracting unrolled networks: for each strategy we report the aver-
age and the median of the ratio between the time needed to extract unrolled
networks and the time needed to extract the original networks.

Strategy Average Median

R
L
S
I
C
U
UI
US
UC
UR

6.20
1.54
4.82
5.24
1.95
9.12
4.70
2.17
3.88
2.47

1
1
1
1.07
1.06
1.03
1
1
1
1

More expressive communications and processes.
In real-world contexts,
values stored and communicated by processes are typed, and the receiver pro-
cess can also specify how to treat incoming messages [9]. This means that
communication actions now have the form p.e -> q.f , where f is the function
consuming the received message, and systems may deadlock because of typing
errors. Our construction applies without changes to this scenario – any require-
ments regarding type checking, for example, will also be necessary for deﬁning
the semantics of the process calculus.

Choreographic Programming and Multiparty Session Types. Chore-
ographic languages like ours are used in choreographic programming, a pro-
gramming paradigm where choreographies are programs that can be compiled
to distributed implementations [20, 10, 21]. Our extraction algorithm can be
applied to several existing languages for networks, modulo minor syntactic dif-
ferences [9, 10, 11, 21]. For some of these languages, our algorithm can be
applied only to fragments of them; we point out some of the features for future
work in the next paragraphs.

Choreographies have also been advocated for the speciﬁcation of communi-
cation protocols. Most notably, multiparty session types use choreographies to
deﬁne types used in the veriﬁcation of process calculi [15]. While there are mul-
tiple variants of multiparty session types, the one used most in practice so far
is almost identical to a simpliﬁcation of SP. In this variant, each pair of partici-
pants has a dedicated channel, and communication actions refer directly to the
intended sender/recipient as in SP (see the theory of [4, 22, 3, 6], for example,
and the practical implementations in [14, 23, 20]). To obtain multiparty session
types from SP (and CC), we just need to: remove the capability of storing values
at processes; replace message values with constants (representing types, which
could also be extended to subtyping in the straightforward way); and make con-

46

ditionals nondeterministic (since in types we abstract from the precise values
and expression used by the evaluator). These modiﬁcations do not require any
signiﬁcant change to our approach since our AES already abstracts from data
and, thus, our treatment of the conditional is already nondeterministic. For
reference, we can simply treat the standard construct for an internal choice at
a process p – p (cid:46) B1 ⊕ B2 – as syntactic sugar for a local conditional such as
p (cid:46) if coinﬂip then B1 else B2.

Asynchrony. Our process calculus is not expressive enough to model exam-
ples from [19] that use the pattern of asynchronous exchange.

Example 13. The network p (cid:46) q!e; q?x | q (cid:46) p!e (cid:48); p?y is deadlocked in SP, but
would run without errors in an asynchronous context: both p and q can send
(cid:47)
their respective values, becoming ready to receive each other’s messages.

Asynchronous semantics for SP and CC have been described in [8]. For
SP, we add a FIFO queue for each pair of processes. Communications now
synchronise with these queues: send actions append a message in the queue of
the receiver, and receive actions remove the ﬁrst message from the queue of the
receiver.

In order to extract asynchronous exchanges, we do not need full asynchrony
at the choreography level. Rather, we can restrict ourselves to a new primitive
called a multicom [11]: a list of communication actions with distinct receivers,
written (˜η). Using multicoms, the program in Example 13 can be extracted
as (cid:0) p.e -> q.x , q.e (cid:48) -> p.y (cid:1). The theory of this extension has been discussed
brieﬂy in [7], but implementing it is outside of the scope of this work.

Process spawning. Another useful construct is the capability to spawn new
processes at runtime [2, 9]. This feature would suﬃce, for example, to represent
the remaining examples from [19], as well as many more complex examples. Hav-
ing such a construct breaks the fundamental premise of our algorithm, namely
that SEGs are ﬁnite. Studying how the theory and implementation could be
adapted to this extension is a challenging future direction.

Extraction strategies. We also believe that extraction strategies have unex-
plored potential, but a full study of their impact goes beyond the scope of this
work. An interesting direction could be to develop more complex heuristics, for
example such that the choice of action to be consumed takes into account the
shape of the network and the partial graph built so far.

Acknowledgments

All authors were supported in part by the Independent Research Fund Denmark,
Natural Sciences, grant DFF-7014-00041. Larsen was supported in part by
the Independent Research Fund Denmark, Natural Sciences, grant DFF-0135-
00018B. Montesi was supported in part by Villum Fonden, grant 29518, and

47

the Independent Research Fund Denmark, Technology and Production, grant
DFF-4005-00304.

48

References

[1] Marco Carbone, Ornela Dardha, and Fabrizio Montesi. Progress as com-
positional lock-freedom. In eva K¨uhn and Rosario Pugliese, editors, Procs.
COORDINATION, volume 8459 of LNCS, pages 49–64. Springer, 2014.

[2] Marco Carbone, Kohei Honda, and Nobuko Yoshida.

Structured
communication-centered programming for web services. ACM Trans. Pro-
gram. Lang. Syst., 34(2):8:1–8:78, 2012.

[3] Marco Carbone, Sam Lindley, Fabrizio Montesi, Carsten Sch¨urmann, and
Philip Wadler. Coherence generalises duality: A logical explanation of mul-
tiparty session types. In Jos´ee Desharnais and Radha Jagadeesan, editors,
Procs. CONCUR, volume 59 of LIPIcs, pages 33:1–33:15. Schloss Dagstuhl
– Leibniz-Zentrum fuer Informatik, 2016.

[4] Marco Carbone and Fabrizio Montesi. Deadlock-freedom-by-design: multi-
party asynchronous global programming. In Roberto Giacobazzi and Rad-
hia Cousot, editors, Procs. POPL, pages 263–274. ACM, 2013.

[5] Marco Carbone, Fabrizio Montesi, and Carsten Sch¨urmann. Choreogra-

phies, logically. Distributed Comput., 31(1):51–67, 2018.

[6] Mario Coppo, Mariangiola Dezani-Ciancaglini, Nobuko Yoshida, and Luca
Padovani. Global progress for dynamically interleaved multiparty sessions.
Math. Struct. Comput. Sci., 26(2):238–302, 2016.

[7] Lu´ıs Cruz-Filipe, Kim S. Larsen, and Fabrizio Montesi. The paths to chore-
ography extraction. In Javier Esparza and Andrzej S. Murawski, editors,
Procs. FOSSACS, volume 10203 of LNCS, pages 424–440, 2017.

[8] Lu´ıs Cruz-Filipe and Fabrizio Montesi. On asynchrony and choreographies.
In Massimo Bartoletti, Laura Bocchi, Ludovic Henrio, and Sophia Knight,
editors, Procs. ICE, volume 261 of EPTCS, pages 76–90, 2017.

[9] Lu´ıs Cruz-Filipe and Fabrizio Montesi. Procedural choreographic program-
ming. In Ahmed Bouajjani and Alexandra Silva, editors, Procs. FORTE,
volume 10321 of LNCS, pages 92–107. Springer, 2017.

[10] Lu´ıs Cruz-Filipe and Fabrizio Montesi. A core model for choreographic

programming. Theor. Comput. Sci., 802:38–66, 2020.

[11] Lu´ıs Cruz-Filipe, Fabrizio Montesi, and Marco Peressotti. Communications
in choreographies, revisited. In Hisham M. Haddad, Roger L. Wainwright,
and Richard Chbeir, editors, Procs. SAC, pages 1248–1255. ACM, 2018.

[12] Lu´ıs Cruz-Filipe, Fabrizio Montesi, and Marco Peressotti. Certifying chore-
ography compilation. In Antonio Cerone and Peter Csaba ¨Olveczky, editors,
Procs. ICTAC, volume 12819 of LNCS, pages 115–133. Springer, 2021.

49

[13] Lu´ıs Cruz-Filipe, Fabrizio Montesi, and Marco Peressotti. Formalising a
turing-complete choreographic language in coq. In Liron Cohen and Cezary
Kaliszyk, editors, Procs. ITP, volume 193 of LIPIcs, pages 15:1–15:18.
Schloss Dagstuhl - Leibniz-Zentrum f¨ur Informatik, 2021.

[14] Kohei Honda, Aybek Mukhamedov, Gary Brown, Tzu-Chun Chen, and
Nobuko Yoshida. Scribbling interactions with a formal foundation.
In
Raja Natarajan and Adegboyega K. Ojo, editors, Procs. ICDCIT, volume
6536 of LNCS, pages 55–75. Springer, 2011.

[15] Kohei Honda, Nobuko Yoshida, and Marco Carbone. Multiparty asyn-
chronous session types. J. ACM, 63(1):9, 2016. Also: POPL, pages 273–
284, 2008.

[16] Hans H¨uttel, Ivan Lanese, Vasco T. Vasconcelos, Lu´ıs Caires, Marco Car-
bone, Pierre-Malo Deni´elou, Dimitris Mostrous, Luca Padovani, Ant´onio
Ravara, Emilio Tuosto, Hugo Torres Vieira, and Gianluigi Zavattaro. Foun-
dations of session types and behavioural contracts. ACM Comput. Surv.,
49(1):3:1–3:36, 2016.

[17] Intl. Telecommunication Union. Recommendation Z.120: Message Se-

quence Chart, 1996.

[18] Julien Lange and Emilio Tuosto. Synthesising choreographies from local
session types. In Maciej Koutny and Irek Ulidowski, editors, Procs. CON-
CUR, volume 7454 of LNCS, pages 225–239. Springer, 2012.

[19] Julien Lange, Emilio Tuosto, and Nobuko Yoshida. From communicating
machines to graphical choreographies. In Sriram K. Rajamani and David
Walker, editors, Procs. POPL, pages 221–232. ACM, 2015.

[20] Fabrizio Montesi. Choreographic Programming. Ph.D. Thesis, IT University

of Copenhagen, 2013.

[21] Fabrizio Montesi. Introduction to Choreographies. Cambridge University

Press, 2022. Accepted for publication.

[22] Fabrizio Montesi and Nobuko Yoshida. Compositional choreographies. In
Pedro R. D’Argenio and Hern´an C. Melgratti, editors, Procs. CONCUR,
volume 8052 of LNCS, pages 425–439. Springer, 2013.

[23] Nicholas Ng and Nobuko Yoshida. Pabble: parameterised scribble. Serv.

Oriented Comput. Appl., 9(3–4):269–284, 2015.

[24] Object Management Group. Business Process Model and Notation. http:

//www.omg.org/spec/BPMN/2.0/, 2011.

[25] Peter W. O’Hearn. Experience developing and deploying concurrency anal-
ysis at Facebook. In Andreas Podelski, editor, Procs. SAS, volume 11002
of LNCS, pages 56–70. Springer, 2018.

50

[26] OpenID. OpenID speciﬁcations, 2021. http://openid.net/developers/

specs/.

[27] Davide Sangiorgi. Introduction to Bisimulation and Coinduction. Cam-

bridge University Press, 2011.

[28] Davide Sangiorgi and David Walker. The Pi-Calculus – a theory of mobile

processes. Cambridge University Press, 2001.

[29] W3C WS-CDL Working Group. Web services choreography de-
1.0.
http://www.w3.org/TR/2004/

version

scription
language
WD-ws-cdl-10-20040427/, 2004.

51

