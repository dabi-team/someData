2
2
0
2

r
a

M
8
2

]
h
p
-
p
m
o
c
.
s
c
i
s
y
h
p
[

1
v
8
3
0
5
1
.
3
0
2
2
:
v
i
X
r
a

Accelerating innovation with software abstractions
for scalable computational geophysics

Mathias Louboutin*,1, Philipp Witte2, Ali Siahkoohi1, Gabrio Rizzuti3,
Ziyi Yin1, Rafael Orozco1 and Felix J. Herrmann1
1 Georgia Institute of Technology, 2 Microsoft Research, 3 Utrecht University

1 Summary

We present the SLIM open-source software framework for computational geophysics, and more
generally, inverse problems based on the wave-equation (e.g., medical ultrasound). We developed a
software environment aimed at scalable research and development by designing multiple layers of
abstractions. This environment allows the researchers to easily formulate their problem in an abstract
fashion, while still being able to exploit the latest developments in high-performance computing.
We illustrate and demonstrate the beneﬁts of our software design on many geophysical applications,
including seismic inversion and physics-informed machine learning for geophysics(e.g., loop unrolled
imaging, uncertainty quantiﬁcation), all while facilitating the integration of external software.
2

Introduction

Software development for exploration geophysics has been traditionally driven by performance.
Though this has resulted in very efﬁcient code, the usability and portability of these codes has been
compromised as a result of the absence of user-level design. Abstractions and user interfaces at a
high level have been developed in recent decades to facilitate research and development. A number
of such interfaces are available, ranging from programming languages, e.g., Python [1], Julia [2], and
Matlab, to domain-speciﬁc languages (DSLs), including RVL [3], Firedrake [4], and Devito [5, 6].
Additionally, there has been a community initiative towards open-source codes and reproducibility,
led by Madagascar [7]. These efforts have brought attention to the need for user abstraction to easily
translate mathematics into code without having to manually refactor thousands of lines of code.

Motivated by this background, we introduce our fully open-source software SLIM framework based
on high-level abstractions and separation of concerns. Our software design relies on three principles:
(1) A high-level abstraction that represents the mathematical problem at hand; (2) Scalability with
vertical integration of high-performance software and DSLs; (3) Inter-operability through the adoption
of language standards (object oriented, multiple dispatch, inheritence, . . . ). In the following, we will
detail these three points, highlighting their importance and implementation. We will follow with some
illustrations of the integration with external software to demonstrate how research and development
can be eased and potentially accelerated by these design principles.
3 Software design

The fundamental objective of a scientiﬁc software framework is to provide users with an interface
that allows them to express their own scientiﬁc problems. In particular, the interface should provide
abstractions to deﬁne the problem as closely as possible to its mathematical formulation. With this
design philosophy, research and development turnaround time can be drastically reduced with quick
prototyping and testing of new ideas and algorithms. Our software framework is grounded in this idea
and led to the development of legacy software [8, 9] adopted by industry for real-world application.
Based on these ideas and modern programming paradigms, we designed a high-level framework that
encapsulates the mathematical deﬁnition of geoscientiﬁc problems at every level. These different
levels are handled through the vertical integration of domain-speciﬁc languages (DSLs). At the lowest
level, Devito provides a symbolic DSL for the deﬁnition of wave-equation and a just-in-time compiler
to target the available hardware with near-optimal performance. On top of Devito, we developed

 
 
 
 
 
 
JUDI, a linear algebra DSL for wave-equation based modeling and inversion. Finally, we created a
machine learning framework that allows us to integrate Devito propagators and JUDI Linear Operators
into machine learning (ML) frameworks (PyTorch and Flux) opening the door to ML-augmented
geophysical inverse problems and uncertainty quantiﬁcation (UQ). Finally, throughout these different
layers, we committed to follow language standards allowing easy interfacing and integration with
external software and frameworks.
4 Wave-equation based inversion

Linear operators are at the core of applied geophysics. Some relevant examples include data ﬁltering
tools such as Fourier-based f-k ﬁlters, the Radon transform, NMO corrections to traditional imaging
operator such as Kirchhoff migration, post-stack migration and wave-equation based inversion where
the discrete wave-equation is a linear operator. One of the ﬁrst frameworks for abstract matrix-
free linear algebra was sPOT[10], later extended to wave-equation based inversion and distributed
computing for waveﬁeld reconstruction [11]. While its adoption was limited by its implementation in
Matlab, such user oriented abstraction laid the ground for modern abstracted frameworks such as
JOLI[12] in Julia and pyLops in Python [13].

Similarly, wave-equation based inversion can be trivially formulated as simple least-squares optimiza-
tion problem for the non-linear wave-equation represented as an abstract matrix A(m) parametrized
by the model parameter m:

minimize
m

Φ(m) =

nsX

i=1

||PrA(m)−1P>

s qi − di||2
2,

Building on modern software solutions JUDI [14, 15] provides a high-level interface allowing to
deﬁne a solver for this problem with a few lines of code. For example, FWI using Gauss-Newton
updates at each iteration can be summarized in as little as ﬁve lines (Listing 1).

1
2
3
4
5
6
7
8
9
10

# Gauss - Newton method
F = judiModeling ( model , srcGeom , recGeom )
J = judiJacobain (F , q )
for j =1: maxiter

d_pred = F * q
fhistory_GN [ j ] = .5 f0 * norm ( d_pred - d_obs ) ^2
# Gauss - Newton update
p = lsqr (J , d_pred - d_obs )
model0 . m .= proj ( model0 . m . - reshape (p , model0 . n ) )

end

Listing 1: FWI with Gauss-Newton updates using JUDI. The complete example is available and
reproducible in the JUDI github repository.

In addition to offering a high-level, mathematical interface to the wave-equation and related linear
operators, JUDI builds on multiple layers of abstractions while still providing computational perfor-
mance that is comparable to the state-of-the-art[6]. JUDI integrates Devito as a backend for the actual
wave-equation solves. Devito is a stencil DSL [5, 6] that offers a symbolic user-level interface to the
underlying numerical solver. This symbolic interface allows the user to easily and mathematically
deﬁne generic partial differential equations (PDEs), such as the acoustic, tilted-transverse-isotropic
(TTI), or elastic wave-equations. The underlying software then provides a code generation framework
than can generate highly-performant code for numerous architectures, (CPU, GPUs, ARM, POWER).
Its ease of use and high-level interface have contributed to its adoption in the oil-and-gas industry
for production and research at scale [16]. We summarize the vertical integration of the different
technologies (compiler, Devito, JUDI, . . . ) in Figure 1, which highlights the different levels of
abstraction. The 2007 BP TTI dataset, for example, can be setup and processed with RTM within
days. The results are shown in Figure 2.

4.1

Interoperability

While a proper separation of concerns can lead to highly usable, portable, and performant software,
another important aspect to consider is interoperability, namely the ability to integrate software from
different sources and organizations. We now describe how the design of our software framework

2

Figure 1: Schematics of the vertical integration in JUDI that enables at scale inversion through layers
of abstractions.

Figure 2: 2D RTM on the 2007 BP TTI model with a marine acquisition. This RTM was run on a
GPU without moving off to the CPU at any time using randomized trace estimation as an extension
of JUDI [17, 18].

allows for easy interfacing with external frameworks. One major drawback of proprietary and
low-level software is the limited capability to interface and interact with external software. Through
open-source code development, and committing to language-speciﬁc standards (such as proper usage
of types, hierarchy, inheritance, etc.) in Julia and Python, we enable seamless interoperability with
external software and frameworks. This greatly increases the ability to perform research, which
involves being able to easily test and combine different ideas. For instance, we combine core Julia
packages, our numerical optimization toolbox SlimOptim.jl [19], a constrained optimization software
SetIntersectionProjection.jl [20], and COFII’s wave-equation propagators [16], in order to setup a full
waveform inversion (FWI) exercise. We were able to perform FWI, in parallel, on the Marmousi-II
model by taking advantage of the best technology available. Additionally, this demonstrative example,
and in general JUDI (or COFII), can trivially be deployed in the cloud using once again dedicated
software abstractions [16, 21].

Since different software modules can be pieced together with minimal effort, it greatly aids the
development and testing of new research. This ﬂexibility allows, for instance, the integration of
machine learning into conventional algorithm pipelines in a plug-and-play fashion. In the following
section, we provide some notable examples of this approach.
5 Machine learning
Thanks to recent theoretical and practical advances, deep learning has seen a wide adoption in various
geophysical applications ranging from processing (e.g., denoising, multiple removal) to inverse

3

1
2
3
4
5
6
7
8
9
10
11

function objective (F , velocity , d_obs )

J = jacobian (F , velocity )
d_pred = F * velocity # Forward modeling with COFFI
G = J ' * ({ d_pred . - d_obs ) # Gradient with COFII
f = .5 f0 * norm ( d_pred . - d_obs ) ^2 # Misfit
return f , G

end
# Projection on TV + bounds , Se t I n t e r s e c t i o n P r o j e c t i o n . jl
prj = setup_projection (...)
# Projected Quasi - Newton (l - BFGS ) with SlimOptim . jl
sol = pqn (x - > objective (F , x , d_obs ) , vec ( v2 ) , prj ) ;

Listing 2: Projected Quasi-Newton FWI with multiple software packages. The complete example can
be found here

problems and seismic interpretation [e.g., 22–24]. One of the core challenges in the adoption of deep
learning for seismic applications is the integration of existing codes (e.g. seismic propagators) into
deep-learning frameworks based on automatic differentiation (AD). To be able to differentiate through
networks that contain both standard PyTorch/Tensorﬂow layers, as well as third party functions,
such as a forward modeling kernel, the third party code must have manually implemented gradients
and must be properly integrated into the deep learning framework. Our high-level linear algebra
abstraction framework, which sits on top of our Devito-based propagators, facilitates this integration,
as deep learning frameworks like PyTorch or Flux are already able to backpropagate through a linear
operator (namely by applying its adjoint to the data residual). This allows us to implement deep
neural networks in Flux, in which we can combine standard deep learning layers with external third
party functions, e.g. convolutional layers with migration/demigration operators. This capability has
enabled various research projects in our group, including surface-related multiple elimination [25],
dispersion attenuation [26], and ML-augmented imaging and uncertainty quantiﬁcation [27, 28].
We show in the following two examples of machine learning for exploration geophysics that take
advantage of these high-level abstractions to interface PDE solvers (JUDI, Devito) with deep learning
frameworks.

5.1 Seismic imaging with deep priors and uncertainty quantiﬁcation

Since we can integrate Devito’s highly optimized wave-equation solvers with the PyTorch deep
learning library, we propose to use deep priors [29] to regularize seismic imaging, where we reparam-
eterize the seismic image as the output of an untrained convolutional neural network (CNN). This
approach acts as a regularization in the image space [29–31], which exploits the inductive bias of
the CNN in representing images without noisy artifacts [29]. We perform Bayesian inference via a
gradient-based Markov chain Monte Carlo (MCMC) algorithm [32], where each iteration requires
differentiating the action of the linearized Born scattering operator on the CNN output with respect to
the CNN’s weights. In order to have access to the automatic differentiation utilities of PyTorch, we
expose Devito’s matrix-free implementations for the migration operator and its adjoint to PyTorch
via Devito4PyTorch [33]. This is exempliﬁed in Listing 3. Figure 3 summarizes the results of seismic
imaging and uncertainty quantiﬁcation with this approach, which are borrowed from Siahkoohi et al.
[34].

(a)

(b)

(c)

Figure 3: Imaging a 2D subset of the Parihaka [35] dataset with deep priors [34]. (a) LSRTM
without any regularization. (b) The conditional (posterior) mean estimate, using the deep prior as
regularization. (c) Normalized pointwise standard deviation.

4

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

def d eep _prior _i ma ging ( d_obs , n , maxiter =1000) :

# PyTorch Integrated Devito Jacobian .
J = ForwardBornLayer ( model , geometry )
# Initialize deep prior CNN with random input .
G = deep_prior_net ()
z = torch . randn ([1 , 1 , n [1] , n [2]])
# Setup pSGLD MCMC sampler .
optim , samples = pSGLD ( G . parameters () , lr =0.001) , []
for i in range ( maxitr ) :

# Compute predicted perturbation model and data .
x = G ( z )
d_pred = J ( x )
# Compute the negative log - posterior .
nlp = n_log_posterior ( d_pred , d_obs , G . parameters () )
# Compute the gradient w . r . t . the CNN weights ,
nlp . backward ()
# Sample with pSGLD .
optim . step ()
samples . append ( x . detach () . numpy () )

return samples

Listing 3: Seismic imaging and uncertainty quantiﬁcation with PyTorch and Devito as a wave-equation
solver.

5.2 Loop-unrolled seismic imaging

Another set of applications that are enabled by the proper integration of abstract seismic modeling
operators into deep learning frameworks are loop-unrolled optimization algorithms such as the
learned primal-dual reconstruction [36, 37]. These are special types of networks that follows the
general structure of gradient-based optimization algorithms, in which conventional gradients are
augmented by additional neural network layers. Using our integration of JUDI operators into Flux via
the JUDI4Flux package [38], we apply the loop-unrolled network architecture from [39] to seismic
imaging. Every iteration of the loop-unrolled algorithm consists of computing the (conventional)
gradient of the LS-RTM objective function g, using the forward and adjoint linearized Born scattering
operator, followed by the application of a shallow CNN (Listing 4). The network takes a single
simultaneous (super-) shot record as the input and predicts an LS-RTM (or true) image. We train the
network in a supervised fashion, in which we minimize the misﬁt between the predicted image and the
true image (whereas in reality, one would train with available LS-RTM images). Figure 4 shows the
output of the loop-unrolled gradient descent algorithm, Listing 4, after training the network for 2000
iterations on a training dataset of 2,000 data-image pairs. The example is not meant to represent a
realistic scenario (as the true images which were used in the training process are obviously unknown),
but serve as a proof of concept on how to augment physical models with data-driven approaches. The
complete example and additional variations are available at LoopUnrolledSeismicImaging.

5.3 End-to-end inversion for geological carbon storage monitoring

Finally, we show that we can easily build a framework for seismic monitoring of geological carbon
storage that integrates PDE solvers, deep learning models and physical constraints. These monitoring
problems rely on three different types of physics [40]: ﬂuid-ﬂow physics, rock physics and wave
physics. Given time-lapse seismic data collected over multiple years, we jointly invert for the rocks
intrinsic permeability which can be used to recover the CO2 concentration. By leveraging our
high-level abstractions and AD, we can directly differentiate through all three physics solvers which
map permeability to seismic data and minimize a fully coupled data misﬁt objective function. At
each iteration, given an estimate of the permeability K, we model seismic data where the subsurface
velocity is translated from the solution of the ﬂuid-ﬂow simulation. We can then compute the standard
data misﬁt and use automatic differentiation to compute the permeability update. Because each step
is abstracted, we can easily swap each physical solver with a different one, such as replacing the
ﬂuid-ﬂow solver by a trained Fourier Neural Operator (FNO) for computational efﬁciency [41]. We
show in Figure 5 that we can recover the permeability from seismic measurements using a pre-trained
FNO in place of a ﬂuid-ﬂow solver.

5

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

function lo o p_ u nro lled_lsrtm ( d_obs , n ; maxiter =10)

x = randn ( Float32 , n [1] , n [2] , 1 , 1)
nx , ny , nc , nb = size ( x )
s = randn ( Float32 , nx , ny , 5 , nb ) # memory term
for j =1: maxiter

g = adjoint ( J ) *( J * vec ( x ) - d_obs )
g = reshape ( Flux . normalise ( g ) , nx , ny , 1 , 1)
u = cat (x , g , s , dims =3)
u = bn1 ( conv1 ( u ) ) ; u = bn2 ( conv2 ( u ) ) ; u = bn3 ( conv3 ( u ) ) ;
s = relu .( u [: , : , 2:6 , :])
dx = u [: , : , 1:1 , :]
x += dx

end
return vec ( x )

end

Listing 4: Example of a physics-augmented neural network for seismic imaging. The network consists
of 10 iterations of a loop-unrolled gradient descent algorithm, in which the conventional LS-RTM
gradient g is augmented through convolution layers. The input into the network is the observed
seismic data and the output is the predicted image.

Figure 4: Loop-unrolled LSRTM on a test 2D slice of the 2D overthrust model. (a) True image, (b)
RTM of simultaneous shot and (c) loop-unrolling of.

6

1
2
3
4
5
6
7
8
9
10
11

opt = RMSprop ()
for j =1: maxiter

theta = params ( K )
grads = gradient ( theta ) do

c = S ( K ) ; v = R ( c ) ; d_pred = F ( v )
return 0.5 f0 * norm ( d_pred - d_obs ) ^2 f0

end
for p in theta

update !( opt , p , grads [ p ])

end

end

Listing 5: Example of an end-to-end coupled inversion for seismic monitoring of geological carbon
storage. A pre-trained FNO S is used as a surrogate for ﬂuid-ﬂow simulation. In each iteration, we
calculating the seismic data misﬁt, compute the gradient with respect to input permeability, K, via
AD, and update it according to an optimizer opt.

Figure 5: End-to-end inversion of CO2 concentration from seismic measurements. In order to
obtain this end-to-end result, the three operators representing the ﬂuid-ﬂow modeling, rock property
modeling, wave modeling, and their derivatives are integrated by combining AD and manually deﬁned
gradients.

6 Conclusions

Through this paper, we have introduced a software design philosophy aimed at enabling research and
development at scale in geoscience, with the potential to generalize to any inverse problem such as
medical imaging. We demonstrated through carefully chosen example that high-level abstractions
allow to express complex problem in a clear and representative way without incurring additional
computational costs. Our software framework already allows for a wide range of application,
including industry scale inversion and cutting-edge physics-informed deep learning for geophysics.
We intend to build additional capabilities to tackle modern computing environment such as Cloud
computing, task dedicated accelerators (i.e TPUs) and non-convex optimization.

7 Acknowledgment

This research was carried out with the support of Georgia Research Alliance and partners of the
ML4Seismic Center. We thank J. Washbourne at CVX for the fruitful discussions on open source
software development and interoperability.

7

References

[1] Guido van Rossum and Fred L. Drake. Python 3 Reference Manual. CreateSpace, Scotts Valley,

CA, 2009. ISBN 1441412697.

[2] Jeff Bezanson, Alan Edelman, Stefan Karpinski, and Viral B Shah. Julia: A fresh approach
to numerical computing. SIAM Review, 59(1):65–98, 2017. doi: 10.1137/141000671. URL
https://epubs.siam.org/doi/10.1137/141000671.

[3] Anthony D. Padula, Shannon D. Scott, and William W. Symes. A software framework for
abstract expression of coordinate-free linear algebra and optimization algorithms. ACM Trans.
Math. Softw., 36(2), apr 2009. ISSN 0098-3500. doi: ricevector. URL https://doi.org/ricevector.

[4] Florian Rathgeber, David A. Ham, Lawrence Mitchell, Michael Lange, Fabio Luporini, Andrew
T. T. Mcrae, Gheorghe-Teodor Bercea, Graham R. Markall, and Paul H. J. Kelly. Firedrake:
Automating the ﬁnite element method by composing abstractions. ACM Trans. Math. Softw., 43
(3), dec 2016. ISSN 0098-3500. doi: 10.1145/2998441. URL https://doi.org/10.1145/2998441.

[5] M. Louboutin, M. Lange, F. Luporini, N. Kukreja, P. A. Witte, F. J. Herrmann, P. Velesko, and
G. J. Gorman. Devito (v3.1.0): an embedded domain-speciﬁc language for ﬁnite differences
and geophysical exploration. Geoscientiﬁc Model Development, 12(3):1165–1187, 2019. doi:
10.5194/gmd-12-1165-2019. URL https://www.geosci-model-dev.net/12/1165/2019/.

[6] Fabio Luporini, Mathias Louboutin, Michael Lange, Navjot Kukreja, Philipp Witte, Jan Hück-
elheim, Charles Yount, Paul H. J. Kelly, Felix J. Herrmann, and Gerard J. Gorman. Ar-
chitecture and performance of devito, a system for automated stencil computation. ACM
Trans. Math. Softw., 46(1), apr 2020.
ISSN 0098-3500. doi: 10.1145/3374916. URL
https://doi.org/10.1145/3374916.

[7] Madagascar, 2017. URL http://www.ahay.org/wiki/Main_Page.

[8] Tim T.Y. Lin and Felix J. Herrmann. The student-driven hpc environment at slim. In Inaugural

Full-Waveform Inversion Workshop, 08-09 2015. (Natal, Brazil).

[9] Curt Da Silva and Felix J. Herrmann. A uniﬁed 2d/3d large scale software environ-
ment for nonlinear inverse problems. ACM Transactions on Mathematical Software, 2019.
URL https://slim.gatech.edu/Publications/Public/Journals/ACMTOMS/2019/dasilva2017uls/
dasilva2017uls.html.

[10] Ewout van den Berg and Michael P. Friedlander. Spot: A linear-operator toolbox for matlab. In

SCAIM, University of British Columbia, 2009. SCAIM Seminar, SCAIM Seminar.

[11] Nameet Kumar.

Parallelizing operations with ease using parallel

spot, 2010.
https://slim.gatech.edu/Publications/Public/Conferences/SINBAD/2010/Fall/

URL
kumar2010SINBADpoe/kumar2010SINBADpoe_pres.pdf.

[12] Henryk Modzelewski, Mathias Louboutin, Ziyi (Francis) Yin, and Rafael Orozco.
group/joli.jl: v0.7.16, January 2022. URL https://doi.org/10.5281/zenodo.5933224.

slim-

[13] Matteo Ravasi and Ivan Vasconcelos. Pylops—a linear-operator python library for scalable
algebra and optimization. SoftwareX, 11:100361, 2020.
ISSN 2352-7110. doi: https://
doi.org/10.1016/j.softx.2019.100361. URL https://www.sciencedirect.com/science/article/pii/
S2352711019301086.

[14] Philipp A. Witte, Mathias Louboutin, Navjot Kukreja, Fabio Luporini, Michael Lange, Gerard J.
Gorman, and Felix J. Herrmann. A large-scale framework for symbolic implementations of
seismic inversion algorithms in julia. Geophysics, 84(3):F57–F71, 03 2019. doi: 10.1190/
geo2018-0174.1. URL https://slim.gatech.edu/Publications/Public/Journals/Geophysics/2019/
witte2018alf/witte2018alf.pdf. (Geophysics).

[15] Mathias Louboutin, Philipp Witte, Ziyi Yin, Henryk Modzelewski, and Carlos da Costa. slim-

group/judi.jl: v2.6.4, January 2022. URL https://doi.org/10.5281/zenodo.5893940.

8

[16] John Washbourne, Sam Kaplan, Miguel Merino, Uwe Albertin, Anusha Sekar, Chris Manuel,
Scott Mishra, Matthew Chenette, and Alex Loddoch. Chevron optimization framework for
imaging and inversion (COFII) – An open source and cloud friendly Julia language framework
for seismic modeling and inversion, pages 792–796. 2021. doi: 10.1190/segam2021-3594362.1.
URL https://library.seg.org/doi/abs/10.1190/segam2021-3594362.1.

[17] Mathias Louboutin and Felix J. Herrmann. Ultra-low memory seismic inversion with random-
ized trace estimation. In SEG Technical Program Expanded Abstracts, pages 787–791, 09
2021. doi: 10.1190/segam2021-3584072.1. URL https://slim.gatech.edu/Publications/Public/
Conferences/SEG/2021/louboutin2021SEGulm/louboutinp.html. (IMAGE, Denver).

[18] Mathias Louboutin. slimgroup/timeprobeseismic.jl, October 2021. URL https://doi.org/10.

5281/zenodo.5605055.

[19] Mathias Louboutin and Felix Herrmann. slimgroup/slimoptim.jl: v0.1.6, August 2021. URL

https://doi.org/10.5281/zenodo.5196691.

[20] Bas Peters and Felix J Herrmann. Algorithms and software for projections onto intersec-
tions of convex and non-convex sets with applications to inverse problems. arXiv preprint
arXiv:1902.09699, 2019.

[21] Mathias Louboutin, Ziyi (Francis) Yin, and Felix Herrmann. slimgroup/judi4cloud.jl: First

public release, March 2022. URL https://doi.org/10.5281/zenodo.6386831.

[22] Guoyin Zhang, Zhizhang Wang, and Yangkang Chen. Deep learning for seismic lithology

prediction. Geophysical Journal International, 215(2):1368–1387, 2018.

[23] Benfeng Wang, Ning Zhang, Wenkai Lu, and Jialin Wang. Deep-learning-based seismic data

interpolation: A preliminary result. Geophysics, 84(1):V11–V20, 2019.

[24] Fangshu Yang and Jianwei Ma. Deep-learning inversion: A next-generation seismic velocity

model building method. Geophysics, 84(4):R583–R599, 2019.

[25] Ali Siahkoohi, Dirk J. Verschuur, and Felix J. Herrmann. Surface-related multiple elimination
with deep learning. In SEG Technical Program Expanded Abstracts, pages 4629–4634, 09
2019. doi: 10.1190/segam2019-3216723.1. URL https://slim.gatech.edu/Publications/Public/
Conferences/SEG/2019/siahkoohi2019SEGsrm/siahkoohi2019SEGsrm.html.

[26] Ali Siahkoohi, Mathias Louboutin, and Felix J. Herrmann. The importance of transfer learn-
ing in seismic modeling and imaging. Geophysics, 2019. doi: 10.1190/geo2019-0056.1.
URL https://slim.gatech.edu/Publications/Public/Journals/Geophysics/2019/siahkoohi2019itl/
siahkoohi2019itl.html.

[27] Ali Siahkoohi, Mathias Louboutin, and Felix J. Herrmann. Neural network augmented wave-
equation simulation. Technical Report TR-CSE-2019-1, Georgia Institute of Technology, 09
2019. URL https://slim.gatech.edu/Publications/Public/TechReport/2019/siahkoohi2019TRnna/
siahkoohi2019TRnna.html.

[28] Ali Siahkoohi, Gabrio Rizzuti, and Felix J. Herrmann. A deep-learning based bayesian ap-
proach to seismic imaging and uncertainty quantiﬁcation. In EAGE Annual Conference Pro-
ceedings, 1 2020. URL https://slim.gatech.edu/Publications/Public/Conferences/EAGE/2020/
siahkoohi2020EAGEdlb/siahkoohi2020EAGEdlb.html.

[29] V. Lempitsky, A. Vedaldi, and D. Ulyanov. Deep Image Prior. In 2018 IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pages 9446–9454, June 2018. doi: 10.1109/
CVPR.2018.00984.

[30] Zezhou Cheng, Matheus Gadelha, Subhransu Maji, and Daniel Sheldon. A Bayesian Perspective
on the Deep Image Prior. In The IEEE Conference on Computer Vision and Pattern Recognition
(CVPR), pages 5443–5451, June 2019.

[31] Sören Dittmer, Tobias Kluth, Peter Maass, and Daniel Otero Baguer. Regularization by
architecture: A deep prior approach for inverse problems. Journal of Mathematical Imaging
and Vision, 62(3):456–470, 2020.

9

[32] Max Welling and Yee Whye Teh. Bayesian Learning via Stochastic Gradient Langevin
In Proceedings of the 28th International Conference on Machine Learning,
ISBN 9781450306195.

Dynamics.
ICML’11, pages 681–688, Madison, WI, USA, 2011. Omnipress.
doi: 10.5555/3104482.3104568. URL https://dl.acm.org/doi/abs/10.5555/3104482.3104568.

[33] Ali Siahkoohi and Mathias Louboutin. slimgroup/devito4pytorch: Initial release, March 2021.

URL https://doi.org/10.5281/zenodo.4610087.

[34] Ali Siahkoohi, Gabrio Rizzuti, and Felix J Herrmann. Deep bayesian inference for seismic

imaging with tasks. arXiv preprint arXiv:2110.04825, 2021.

[35] WesternGeco. Parihaka 3D PSTM Final Processing Report. Technical Report New Zealand

Petroleum Report 4582, New Zealand Petroleum & Minerals, Wellington, 2012.

[36] Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom
Schaul, Brendan Shillingford, and Nando De Freitas. Learning to learn by gradient descent by
gradient descent. Advances in neural information processing systems, 29, 2016.

[37] Jonas Adler and Ozan Öktem. Learned primal-dual reconstruction. IEEE transactions on

medical imaging, 37(6):1322–1332, 2018.

[38] Philipp A. Witte, Mathias Loubouting, and Felix J. Herrmann. Judi4ﬂux: Seismic modeling for

deep learning, December 2019. URL https://doi.org/10.5281/zenodo.4301018.

[39] Jonas Adler and Ozan Öktem. Solving ill-posed inverse problems using iterative deep neural

networks. Inverse Problems, 33(12):124007, 2017.

[40] Dongzhuo Li, Kailai Xu, Jerry M Harris, and Eric Darve. Coupled time-lapse full-waveform in-
version for subsurface ﬂow problems using intrusive automatic differentiation. Water Resources
Research, 56(8):e2019WR027032, 2020.

[41] Zongyi Li, Nikola Kovachki, Kamyar Azizzadenesheli, Burigede Liu, Kaushik Bhattacharya,
Andrew Stuart, and Anima Anandkumar. Fourier neural operator for parametric partial differen-
tial equations, 2020.

10

