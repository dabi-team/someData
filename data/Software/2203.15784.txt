2
2
0
2

r
a

M
6
2

]

C
H
.
s
c
[

1
v
4
8
7
5
1
.
3
0
2
2
:
v
i
X
r
a

Implementation of An Automated Learning System for
Non-experts

Phoenix X. Huang1 Zhiwei Zhao1 Chao Liu1 Jingyi Liu1 Wenze Hu1 Xiaoyu Wang1

1Lighthouse

Abstract Automated machine learning systems for non-experts could be critical for industries to adopt
articial intelligence to their own applications. This paper detailed the engineering system
implementation of an automated machine learning system called YMIR, which completely
relies on graphical interface to interact with users. After importing training/validation data
into the system, a user without AI knowledge can label the data, train models, perform data
mining and evaluation by simply clicking buttons. The paper described: 1) Open implemen-
tation of model training and inference through docker containers. 2) Implementation of
task and resource management. 3) Integration of Labeling software. 4) Implementation of
HCI (Human Computer Interaction) with a rebuilt collaborative development paradigm. We
also provide subsequent case study on training models with the system. We hope this paper
can facilitate the prosperity of our automated machine learning community from industry
application perspective. The code of the system has already been released to GitHub1.

1 Introduction

Many AutoML techniques such as NAS and HPO have greatly simplied the task of nding the best
models and hyper parameters for machine learning problems, and contribute to the wide adoption
of ML in various elds. However, in industrial settings, modeling is only one of many factors
which aect the eciency and simplicity of a machine learning development process. A systematic
approach that manages and automates the entire pipeline could be a key to land AutoML into in
more application areas.

In ready to use AutoML systems such as Google Cloud AutoML, Amazon SageMaker Autopilot
etc. , a model development pipeline is simplied to three steps: upload data, train model and
deployment. While this simplied process achieves the goal of producing models, in actual use
cases, the model development processes are almost always iterative, either because the raw data
arrives in batches, or the labeling cost is too prohibitive that labeling has to be done in batches. In
these settings, the time spent repeating non-training steps is usually much longer than training the
models, rendering an automated pipeline more valuable than only automating the model training
step itself.

YMIR2 is a machine learning platform that simplies and automates the production grade
machine learning processes in industrial settings. The system enables non-expert users to develop
AI models through a no-code style GUI. To achieve this goal, YMIR denes its own generic model
training and inference task protocols to support dierent algorithm implementations for various
machine learning problems, its own task management and resource allocation framework to better
organize and track machine learning tasks for multiple parallel projects, as well as its own GUI
to emphasis an active learning based iterative machine learning development pipeline. Our case
study in appendix shows that this platform can be used by non-experts to train and iterate models
for production purposes, which helps wide adoption of AI to new application elds.

1https://github.com/industryessentials/ymir
2YMIR denotes You Mine In Recursive

AutoML Conference 2022

¬© 2022 the authors, released under CC BY 4.0

 
 
 
 
 
 
Data: ùê∑ùëéùë°ùëéùë†ùë¢ùëùùëíùëüùë†ùëíùë° ;
Result: Application Specic Model ùëÄùëú
ùê¥ùëêùëêùëá ‚Üê ùê¥ ;
ùëÄ0 ‚Üê Empty model or pretrained model ;
ùê∑0 ‚Üê Empty, ùê¥ùëêùëê0 ‚Üê 0, ùëñ ‚Üê 0 ; /* Initialize data, accuracy, iteration index */
while ùê¥ùëêùëêùëñ ‚â§ ùê¥ùëêùëêùëá ;
/* Continue if the model accuracy is not sufficient */
do

/* The whole available data */

/* Target model accuracy */

if User Interrupts The Process ;
then

ùëÄùëú ‚Üê ùëÄùëñ;
Break;

/* Terminated by user */

else

ùëëùëñ ‚Üê Data mining output with ùëÄùëñ and ùê∑ùëéùë°ùëéùë†ùë¢ùëùùëíùëüùë†ùëíùë° if ùëñ > 0, otherwise Initial Data ;
Label ùëëùëñ ;
/* Label the mined data */
ùê∑ùëñ+1 ‚Üê ùê∑ùëñ ‚à™ ùëëùëñ ;
/* Update training data */
ùëÄùëñ+1 ‚Üê Model trained on ùê∑ùëñ+1 ;
/* Update model */
ùê¥ùëêùëêùëñ+1 ‚Üê Evaluate ùëÄùëñ+1 ;
/* Evaluate model */

end
ùëÄùëú ‚Üê ùëÄùëñ+1, ùëñ ‚Üê ùëñ + 1 ;

end

/* Update model */

Figure 1: Model development process in YMIR system. Left: In algorithm format. Right: In the diagram

format.

It is noted that while the high-level concept design of YMIR is introduced in [Huang et al., 2021],
this paper emphasis on the engineering design principles as well as implementation details. The
appendix includes case studies showing its eectiveness in speeding up the AI model development
process.

2 Industrial AI Model Development Process

YMIR is developed under the data-centric principle with focuses on ecient model and data
iterations. As is shown in Figure 1, YMIR denes an iterative model development process as
following steps:

1. Solution Design: This stage focuses on converting the business needs into an existing type
of modeling problem. Taking computer vision as an example, the modeling problem could be
image classication, object detection, segmentation, or a combination of multiple techniques.

2. Data Preparation: Data preparation mainly refers to the process of collecting and pre-processing
data for a target technical solution. Data collection is usually performed iteratively until the
resulting technical solution meets the application requirements.

3. Model Training: Commonly known as "modeling", this is the step of exploring and analyzing
prepared data through analytical tools, methods and techniques to discover input-output rela-
tionships and internal connections to inform decisions for business purposes. The result of this
process is usually one or more machine learning models. The model training process is also
iterative followed by data updates, until the model accuracy meets application requirements.

4. Model Evaluation: This step evaluates performances of the models obtained from the model
training step. Dierent from only using key metrics such as accuracy or sensitivity as diagnostic
measures, which are usually computed on validation data while training the model, this process
may involve more in-depth analysis of the results on testing datasets, such as model bias or
metrics on sub-groups of the validation/testing sets.

5. Data Mining: This stage focuses on nding the best data that improves the current models. On
many applications this is a necessary step because the modeled events are usually rare events in
the source dataset, and the cost of blindly labeling all the data could be prohibitive.

6. Model Deployment: Trained and evaluated model needs to be applied to production data or
newly acquired data to generate predictions which provide the high-value information for
business purpose. The model usually is usually optimized in terms of computational cost in this
step, to save the eventual cost of running them on real data.

2

Processes 2 through 5 are repeated for improved model accuracy, while process 1 and 6 are
separate procedures which are typically performed oine. In following sections, we focus on the
implementation of process 2 through 5. Figure 1 illustrated the iteration logic in both algorithm
format and graph format for better understanding.

Figure 2: YMIR decomposed into engineering layers. YMIR-HCI guides user operations and assists
users to develop AI model more eciently; YMIR-Web UI provides UI controls for users to
visualize/operate dataset and tasks; YMIR-Application: this layer maintains the relationship
among user/task/assets, as well as permissions; YMIR-Controller manages task framework
and tracks the progress of individual task. The infra layer manages all infrastructure resources,
data storage solution, etc.

3 System Implementation

In YMIR, the pipeline introduced above is implemented through four key components, which
are shown in Table 1 and Figure 2: 1) YMIR-TMI implements model related operations including
training, testing and data mining. 2) YMIR-Controller implements task and resource management.
3) YMIR-Labeling implements data labeling and connects to data labeling services through open
interfaces. 4) YMIR-HCI implements front-end user interface for the platform.

3.1 YMIR-TMI

3.1.1 Design Principle. The focus of the YMIR platform is on data management and process control.
When it comes to the TMI services, we decouple these services from the platform and treat them
as plug and play black boxes. While YMIR provides default TMI dockers, users and third-party
developers have the freedom to write and integrate their own related algorithms, as long as the
corresponding docker images is compatible with the dened protocol.

YMIR interacts with TMI services in the following way:

‚Ä¢ The YMIR platform, in conjunction with the TMI services, fullls the whole development re-
quirements. a. the YMIR platform extracts the metadata for TMI services from docker images
(descriptions, congurations, etc.) b. The YMIR platform provides input data to TMI services,
and collects results when those service jobs are completed. c. The YMIR platform catches the
exceptions and errors generated during the operation of TMI services. d. The YMIR platform

3

Modules

Function Description

YMIR-TMI

Open design of model Training/Mining/Inference (TMI) services through docker
containers. Adding a new TMI related algorithm can be achieved by replacing the
corresponding docker image.

YMIR-
Controller

Implementation of task and resource management. It decomposes ML tasks into
atomic operations. Resource sharing, task progress monitoring and task orchestra-
tion are done by scheduling on top of these operations.

YMIR-Labeling

Open API for integration of data labeling softwares.

YMIR-HCI

Design of Human Computer Interaction (HCI). The graphical interface aims at
implementing a rebuilt collaborative development paradigm, which guides users
through the model and data iteration process. User actions as well as operation
outputs together with key metrics are recorded, which makes the process trackable.
The system improves the eciency of data iteration and model production by
interactive guidance through the whole process.

Table 1: Main Engineering Components of YMIR

collects the real-time status of TMI services (whether a service is running normally, its progress
or real-time logs, etc.)

‚Ä¢ A TMI service is decoupled from the YMIR platform. The service is responsible for the correctness

on the implementation of corresponding model and data methodologies.

‚Ä¢ The YMIR platform is not aware of the internal dependencies of these services.

‚Ä¢ There is no dependency between the YMIR platform and the versions of these services.

3.1.2 Implementation. The TMI services are encapsulated into separated docker images, and the YMIR
platform follows the life-cycle described in Section 2 to invoke these services. YMIR instantiates
TMI services and interact with them following principles described in 3.1.1. In the following we
explain TMI service registration and the service runtime.

1. Service registration. A service is available only after it is registered in YMIR. The availability

ends when the service is logged o. For a registered service, the user should make sure:

(a) The YMIR platform is aware of the metadata associated with this service.

(b) The docker image which implements the specic task is ready to be instantiated.

2. Service runtime: The system can instantiate one or more services after the service is registered.
Unless exited with errors, the respective service keeps in the runtime until the job is nished.
TMI instances in runtime period have the following characteristics.

(a) Dierent TMI instances do not interfere with each other. There is no communication

between instances, either.

(b) YMIR has real-time access to the operational status of these instances.

4

Flow Direction
YMIR reads from TMI services. A description of the TMI service itself, and the

Notes

list of key congurable parameters.

Logs

Interaction

Name
Metadata When the TMI
service is regis-
tered.
During the oper-
ation of the TMI
instance.
During the run-
time of a TMI in-
stance.

Status
Moni-
toring

Input

Before the TMI
instance runs.

Generated by the TMI instance,
read and logged by YMIR.

Generated by the TMI instance
(written to a location-specic
le using a dened format),
read by YMIR
Generated by YMIR (placed in a
specic path and mounted at
boot time) and read by the TMI
instance

Output

After the TMI
instance is com-
pleted

Generated by the TMI instance
(written to a specic location
using a dened format) and
read by YMIR.

The runtime logs generated by the TMI instance
are only stored by YMIR and do not need to be
understood.
Monitoring information generated by the TMI
instance about its latest status.

For the training service: training set, test set,
pre-trained model, service parameter prole; For
mining service: model, candidate set, service
parameter prole; For the inference service:
model, set of images to be inferred, service
parameter prole.
For the training service: model, result
parameters le; For mining service: mining
result les; For inference service: inference
result les.

Table 2: Summary of the data exchange between YMIR system and TMI services.

(c) YMIR is notied when a instance nishes running or exits with errors.

Table 2 summarizes data exchange between the YMIR platform and TMI services instances.
The life cycle of TMI services is illustrated in Fig 3. It consists of multiple stages.

Figure 3: Overview of the TMI service life cycle.

Instantiation start-up. YMIR follows the listed steps below to start a TMI service:

5

1. The user chooses a service (docker image) to start with, and sets up necessary congurations

for the service.

(a) For the task of model training, the conguration of training sets and testing sets is mandatory.
YMIR allows users to congure their pre-trained models for initialization if there is any.

(b) For the task of data mining or inference, only the target mining dataset or the dataset for

inference is needed.

2. YMIR platform reads assets congured in Step 1 and hosts them in predened locations.

3. The TMI instance (docker container) starts its main process, taking the datasets, models and

conguration les from predened locations.

Instance status monitoring. When the main process of the instance starts, the YMIR platform
interacts with this instance in two ways. 1. All standard and error outputs generated by the instance
are logged to a le. 2. The latest status and progress of the instance is written to a status monitoring
le, and changes to this le are logged by the YMIR platform.

End of instance. If the instance executes all operations and returns a true value, the YMIR
platform will consider it as a successful run. For these instances, the YMIR platform stores the
results and updates the status of the tasks. If the instance exited unexpectedly or the return value
is not true, the YMIR platform marks the task as a failure and archives the intermediate results (if
any). If the user chooses to manually stop this instance during the execution of an instance, the
YMIR platform sends a docker stop command to this instance, collects any intermediate results
that may exist, and marks this task as broken.

3.2 YMIR-Controller: Implementation of Task and Resource Management

In YMIR, machine learning tasks are decomposed into smaller granular atomic-level tasks, which
can be reorganized to achieve reuse of resources, progress monitoring at a smaller granularity. Task
parallelization also benets from the design.

3.2.1 Task Scheduling. The task scheduling component manages to connect a series of subtasks to
It supports tasks parallelization if there are enough

implement the task dened by the user.
resources to support these tasks.

1. Data preparation subtask. The dataset preparation stage is separated, and only one copy of
this original data of the image is kept, and the original content of the image is calculated using
sha256() as the identier of the image, which is reused in other tasks to avoid multiple copies of
the original data, taking up storage space and task time, etc.

2. Dataset processing. Filtering, merging, taking intersection and merging of datasets, etc., will

generate a new dataset after completion, which can also be reused by other tasks

3. GPU resource allocation. When the data is processed, before using GPU resources for training,
the GPU ID used is stored from the task layer perspective, and the GPU resources are released
when the task is completed or failed. Thus, the GPU resources are allocated in an on-demand
fashion.

4. TMI execution. TMI services run respective jobs given all related resources are ready .

3.2.2 Assets Replica Management. The target speed of data caching layer for data acquisition is within

100ms. It is organized as:

6

(a) Hash ID

(b) Caching

Figure 4: (a):Each YMIR asset has a unique ID. (b) Workow of YMIR caching.

1. Original le parsing and verication. Get the hash_id of the image content, and support reading
the corresponding PASCAL, VOC, YOLO and other common data formats, where the hash_id is
used for image de-duplication and subsequent identication of the image. At the same time, it
can support dierent strategies to ignore unknown tags, abort unknown tags, etc. to provide
more information for later data analysis.

2. Extract key information, compress and store. After the data is obtained, it will be compressed
and serialized using Protocol Buer, and git will be called to store it, thus compressing the
storage disk space, and also allowing to retrace the version record information.

3. Cache the data. The hash _id is stored in an array, while other information such as image
annotation is placed in a chain table with the head pointer of the chain table as hash _id. hash
_id represents both the image itself and the nodes of the chain table, the array can be used for
fast paging, and the chain table ensures O(1) to nd the details of the image. Since the check
phase has been de-duplicated in the previous stage, there is no problem of conict

3.2.3 Task progress tracking. Background The process of synchronizing task progress information
through command, application and web UI layers is implemented in actively push mechanism. The
logic of updating task progress is as follows.

1. YMIR-TMI and YMIR-Command write task progress to monitor.txt

2. YMIR-Monitor component polls task progress via task_monitor, and posts to application layer.

3. YMIR-Application layer receives task progress message, and pushes the progress to web UI

through the protocol tunnel, and displays it on the interface.

Functional design and implementation

1. YMIR-Monitor collector in controller layer is responsible for collecting task progress informa-
tion (user-id, task-id, percent, state code, state message, error message, timestamp, etc.) from
monitor.txt

2. YMIR-Monitor collector sends the signal of task progress that has changed since last updated
time. The dispatcher service at the app level posts this signal to a dedicated API at a certain
interval. This signal is formed by the task id, state code, percent, etc.

3. web clients connect to the name-space of the current user via socketio.

To post a progress message, the event dispatcher:

1. Create a message subscription group x for the Redis stream, with only one consumer

7

2. Create an API interface to the controller to receive information about tasks that have changed
in the meantime, and put them into the Redis stream queue as a list when they are received

3. When the message subscription group x detects a change in the queue, it reads all messages
from it at once, groups them by user-id and task-id, nds the latest task status corresponding to
each task-id, pushes it to the namespace corresponding to the user-id using socketio, and writes
the latest task status to the db via the API. If the write process fails, the categorized messages
are rewritten back to the queue, and if the write process is successful, the original messages are
deleted.

Web UI subscribes to the event dispatcher service for individual user messages (connected to
the namespace corresponding to the user-id) via socketio. The received messages are displayed to
web users.

3.3 YMIR-Labeler: Integration of Labeling Software

Similar to YMIR-TMI system, the YMIR-Labeler component is also open-designed to support easily
integration of external labeling tools. The whole life-circle of a labeling task is described in Figure
5. It includes following functionalities:

Figure 5: YMIR labeling task life circle.

Functionalities

‚Ä¢ Data labeling support for various vision tasks such as classication/detection/segmentation, etc.

‚Ä¢ Pre-annotation using a pre-trained model to improve labeling eciency.

‚Ä¢ Dataset synchronization between the labeling system and YMIR.

‚Ä¢ YMIR is able to distribute tasks and retrieval results from the labeling platform.

The open design allows YMIR to use dierent labeling systems which may have their own
merits for a specic task. As long as the dened communication interface is implemented, a third
party labeling platform can be used by YMIR in a plug-and-play fashion.

With an unlabeled dataset already in YMIR, the labeling task can be simply activated by clicking
the [New Annotation Task] button in YMIR‚Äôs task management page. Users will be redirected to
the annotation task creation page to input necessary labeling congurations and instructions. Once
a labeling task is successfully created, one can check the corresponding progress by simply visit
YMIR‚Äôs task management page. YMIR is implemented to keep communicating with the labeling
software and collect all the annotation results once the task is completed.

8

Figure 6: YMIR System: Guided Interactive Model Development Pipeline.

3.4 YMIR-HCI: Iteration Pipeline Centered Design.

Figure 6 shows the screenshot of the project page for model development. A pipeline composed
of connected buttons resembling an actual model iteration process dened in Figure 1 (a) is put
on the most prominent area of this page (see section "Project Helmet Detection" which includes
connected actionable items such as labeling, training, data mining, etc.

This pipeline gives users a clear view of the steps needed for performing one model iteration,
progress of the current iteration and overall status of the running step. While providing high level
information and actionable links to more details, this visual pipeline gives user the implication
that model iteration is an important aspect of actual ML development project. This impression
also helps inexperienced users realize that in application-oriented ML projects, developing a high
quality dataset is equally if not more important than changing the model architectures or tuning
the model training hyper parameters.

After a step is nished successfully, YMIR will guide the user to start the next step by highlighting
the button automatically, following the logic specied in Figure 1. The next step can also be
congured to get triggered automatically, though we notice that many users prefer to inspect the
results before proceeding to the next step.

YMIR also provides a project view page, to facilitate users develop multiple ML projects in

parallel. More screenshots of YMIR UI are listed in Appendix.

4 Limitation and Broader Impact

The system only supports training vision models. As a model production application, it should not
have negative social or ethic impacts.

5 Conclusions

This paper introduces the engineering implementations of a machine learning system that uses
a rebuilt development pipeline to involve non-experts into ML development process. We hope
this project can facilitate the prosperity of our automated machine learning community from an
industry application perspective.

9

References

[Huang et al., 2021] Huang, P. X., Hu, W., Brendel, W., Manmohan, C., Li, L.-J., and Wang, X. (2021).
Ymir: A rapid data-centric development platform for vision applications. In Proceedings of the
Data-Centric AI Workshop at NeurIPS.

10

6 Appendix I: Case study, Developing AI models without AI Experts

This appendix presents a case study conducted with a ML modeling team that uses YMIR to improve
their eciency on solving real world problems.

For a time span of 2 weeks, a group of 1 ML engineer and 2 data annotators teamed up to
try iterating models using YMIR. Before using YMIR, the ML engineer usually iterates 2 models a
month, each with 2 iterations. Now, the 3 people group iterated 4 models only using two weeks.
On average, the ML engineer reported signicantly less time spent on iterating these models, from
0.3 month per model to 0.05 month. The ML engineer got extra ‚Äôfree‚Äô time by using YMIR, which
were spent on developing new algorithms and planning on new model development projects.

Figure 7: (a) Original ML dev pipeline. Most of the steps are done by ML engineers. (b) New dev

pipeline with YMIR, which enables non-experts to develop models.

Comparison and analysis of dierent model development processes.
Figure 7(a) shows the regular process of algorithm development by professionals aka ML
engineers. The main operations of these engineers are model training, visualization, optimization,
and mining, all of which needs to be done by using code. After the mining step, the selected data is
handed over to the labeling group for labeling, and the training starts again after the mined dataset
is labeled.

Disadvantages of traditional ML development workow.

‚Ä¢ Switching between dierent algorithm tasks usually takes time, and when the data is fully labeled,
the algorithm sta has other work at hand to nish, which makes the prepared data idle waiting
for engineer‚Äôs availability.

‚Ä¢ Switching between dierent operations requires code implementation, and the eciency of

development depends on the coding level of the specic engineer.

‚Ä¢ The algorithm development process cannot be tracked. If many algorithms are developed in
parallel, the algorithm developer needs to manually check the status of each task. Depending
on the developer‚Äôs work style, this could be a major loss of productivity that can be boosted by
automatic tools.

Advantages of traditional ML development work ow.

‚Ä¢ High exibility in algorithm development, allowing selection of the most appropriate algorithm

model based on project requirements.

11

Project Solution DesignLabel Rule DesignLabelingTrainingOptimizingVisualizationMiningLabelingTrainingModel AssessmentMiningProject Solution DesignLabel Rule DesignWork done by ML engineers.Work done by non experts.(a)(b)‚Ä¢ Multiple tools can be used to tune the algorithm, such as adjusting the model training parameters,
visualizing and analyzing the model output, and adjusting the training and labeling strategies
based on the model visualization results.

‚Ä¢ Use analysis tools to monitor model training curves, identify problems early and correct them.
This may save computational resources, and avoid wasting time on problematic datasets to
produce low performing models.

Figure 7(b) shows the model development process with YMIR. It can be observed that the
majority of the operations are performed by the annotators, and the algorithm sta only reviews
the model after it is trained and then moves his/her time on to the next task.

Advantages of using YMIR for development

‚Ä¢ Switching between tasks and operations is simple and can be done with a single mouse click.

‚Ä¢ Data that has been annotated can immediately be used in the next step without waiting for the

ML engineer to start the job manually.

‚Ä¢ One operator can develop multiple algorithms at the same time.

‚Ä¢ Reduce the knowledge requirement of algorithm development, so that people with no development

experience can train and iterate models according to the operation documents.

‚Ä¢ Avoid tedious code operation switching, and development eciency is less sensitive to the

technical capability of the developer.

‚Ä¢ The entire model iteration process is recorded and trackable through the platform. The iteration
history can be useful for further investigation of model related issues, such as analyzing the
source of bias and fairness problems. It can also be used to spot, share and promote best practices
when dealing similar tasks.

7 Appendix II: Screenshots of YMIR system UI

12

Figure 8: YMIR System - Project List View

Figure 9: YMIR System - Start a Labeling Task

13

Figure 10: YMIR System - Start a Training Task

Figure 11: YMIR System - Start a Data Mining Task

14

Figure 12: YMIR System - Model Verication

15

