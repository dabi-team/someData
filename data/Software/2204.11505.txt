2
2
0
2

r
p
A
5
2

]

Y
S
.
s
s
e
e
[

1
v
5
0
5
1
1
.
4
0
2
2
:
v
i
X
r
a

Oﬄine and online monitoring of scattered
uncertain logs using uncertain linear dynamical
systems(cid:63)

Bineet Ghosh1

and Étienne André2

1 The University of North Carolina at Chapel Hill, NC, The United States of America
2 Université de Lorraine, CNRS, Inria, LORIA, F-54000 Nancy, France

Abstract. Monitoring the correctness of distributed cyber-physical sys-
tems is essential. We address the analysis of the log of a black-box cyber-
physical system. Detecting possible safety violations can be hard when
some samples are uncertain or missing. In this work, the log is made
of values known with some uncertainty; in addition, we make use of an
over-approximated yet expressive model, given by a non-linear exten-
sion of dynamical systems. Given an oﬄine log, our approach is able to
monitor the log against safety speciﬁcations with a limited number of
false alarms. As a second contribution, we show that our approach can
be used online to minimize the number of sample triggers, with the aim
at energetic eﬃciency. We apply our approach to two benchmarks, an
anesthesia model and an adaptive cruise controller.

Keywords: oﬄine monitoring, online monitoring, energy-aware monitoring,
cyber-physical systems, formal methods

1

Introduction

The pervasiveness of distributed cyber-physical systems is highly increasing, ac-
companied by associated safety concerns. Formal veriﬁcation techniques usually
require a (white-box) model, which is not often available, because some compo-
nents are black-box, or because the entire system has no formal model. In addi-
tion, formal veriﬁcation techniques for cyber-physical systems are often subject
to state space explosion, often preventing a satisfactory scalability. Therefore,
monitoring, as a lightweight yet feasible veriﬁcation technique, can bring prac-
tical results of high importance for larger models.

(cid:63) This is the author version of the manuscript of the same name published in the
proceedings of the 42nd International Conference on Formal Techniques for Dis-
tributed Objects, Components, and Systems (FORTE 2022). The ﬁnal version is
available at www.springer.com. This work is partially supported by the ANR-NRF
French-Singaporean research program ProMiS (ANR-19-CE25-0015), and the Na-
tional Science Foundation (NSF) of the United States of America under grant num-
ber 2038960.

 
 
 
 
 
 
x

x

t

x

t

x

t

x

t

x

t

t

(a) Full

(b) Monitored

(c) Extrapo.

(d) Extrapo.

(e) Violation

(f) Uncertain

Fig. 1: Monitoring at discrete time steps

Monitoring aims at analyzing the log of a concrete system, so as to deduce
whether a speciﬁcation (e.g., a safety property) is violated. Monitoring can be
done oﬄine (i.e., after the system execution, assuming the knowledge of the
entire log), or online (at runtime, assuming a partial log). When the log is an
aperiodic timed sequence of valuations of continuous variables, with a logging
not occurring at every discrete time step, and when the system under monitoring
is a black box, a major issue is: how to be certain that, in between two discrete
valuations, the speciﬁcation was not violated at another discrete time step at
which no logging was performed? For example, consider a system for which
a logging at every discrete time step would yield the log depicted in Fig. 1a.
Assume the logging was done at only some time steps, given in Fig. 1b, due to
some sensor faults, or to save energy with only a sparse, scattered logging. How
to be certain that, in between two discrete samples, another discrete sample (not
recorded) did not violate the speciﬁcation? For example, by just looking at the
discrete samples in Fig. 1b, there is no way to formally guarantee that the unsafe
zone (i.e., above the red, dashed line) was never reached by another discrete
sample which was not recorded. In many practical cases, a piecewise-constant
or linear approximation (see, e.g., Figs. 1c and 1d, where the large blue dots
denote actual samples, while the small green dots denote reconstructed samples
using some extrapolation) is arbitrary and not appropriate; even worse, it can
yield a “safe” answer, while the actual system could actually have been unsafe at
some of the missing time steps. On the contrary, assuming a completely arbitrary
dynamics will always yield “potentially unsafe”—thus removing the interest of
monitoring. For example, from the samples in Fig. 1b, without any knowledge
of the model, one can always envision the situation in Fig. 1e, which shows the
variable x crossing the unsafe region (dashed) at some unlogged discrete time
step—even though this is unlikely if the dynamics is known to vary “not very
fast”.

Contributions In this work, we address the problem of performing monitoring
over a set of scattered and uncertain samples. First, we cope with uncertainties
from the sensors by allowing for uncertain samples, given by zonotopes over
the continuous variables; that is, at each logged timestamp, the log gives not
a constant value for the continuous variables, but a zonotope. A simple case of
an uncertain log over a single variable x is depicted in Fig. 1f in the form of
simple intervals. The timestamp at each discrete sample of the log is however
supposed to be constant (i.e., a single point). Second, to over-approximate the

2

system behavior, and in the spirit of the “model-bounded monitoring” proposed
in [WAH22a], we use an extension of linear dynamical systems, extended with
uncertainty, i.e., allowing uncertainty in the dynamics matrix [LP15]. Having
some over-approximated knowledge of the system is a natural assumption in
practice: when monitoring a car, one generally knows an upper-bound on its
maximum speed, or on its maximum acceleration (perhaps depending on its
current speed). To cope with the liberal dynamics of our extension of linear
dynamical systems, we use a recent technique [GD21b], that performs an eﬃcient
reachability analysis for such uncertain linear dynamical systems. The use of such
an over-approximation of the actual system is the crux of our approach, allowing
us to discard unlikely behaviors, such as the unlikely safety violation depicted
in Fig. 1e.

Our ﬁrst main contribution is to propose a new rigorous analysis technique
for oﬄine monitoring of safety properties over scattered uncertain samples, us-
ing uncertain linear systems as an over-approximation of the system. This over-
approximation allows us to extrapolate the behavior since the latest known sam-
ple, and to rule out safety violations at some missing discrete samples. Note that
our approach uses some discrete analysis as underlying reachability computation
technique, and will not however guarantee the absence of safety violations at ar-
bitrary (continuous) timestamps; its main advantage is to oﬀer formal guarantees
in the context of missing discrete samples for a given logging granularity.

Our second main contribution focuses on energy-eﬃcient online monitoring.
For each recorded sample, we run a reachability analysis, and we derive the
smallest next discrete time step t in the future at which the safety property may
be violated depending on the latest known sample and the over-approximated
model dynamics. In a context in which monitoring simply observes the behavior
and does not lead to corrective actions, any sample before t is useless because we
know from the over-approximated model dynamics that no safety violation can
happen before t. Therefore, we can schedule the next sample at time t, which
reduces the number of discrete samples, and therefore the energy consumption
and bandwidth use. We show that our method is correct, i.e., we can safely
discard discrete samples without missing any unsafe behavior.

We show the practical applicability of our approach on two benchmarks: an

anesthesia model, and an adaptive cruise controler.

Outline We review related works in Section 2. We recall uncertain linear dy-
namical systems in Section 3. We introduce our (oﬄine and online) monitoring
frameworks in Section 4, and run experiments in Section 5. We draw perspectives
in Section 6.

2 Related works

Monitoring Monitoring complex systems, and notably cyber-physical systems,
[MN04; BKZ17; Bar+18;
drew a lot of attention in the last decades, e.g.,
WAH22a; MCW21]. While the main drawback of monitoring is a lack of for-
mal guarantees on the global behavior of a system, its advantage is a much more

3

scalable eﬃciency compared to techniques such as model checking. In addition,
monitoring can be performed on black-box systems, the source code (and there-
fore a model) of which is unavailable. In parallel to monitoring speciﬁcations
using signal temporal logics (see e.g., [DFM13; Jak+18; QD20]), monitoring us-
ing automata-based speciﬁcations drew recent attention. Complex, quantitative
extensions of automata were studied in the recent years: after timed pattern
matching on timed regular expressions [Ulu+14] was proposed by Ulus et al.,
Waga et al. proposed a technique for timed pattern matching [WAH16; WHS17;
WHS18; Wag19] (with an additional work by Bakhirkin et al. [Bak+18]) and
then for parametric timed pattern matching [AHW18; WA19; WAH22b], with
application to oﬄine monitoring. Then, techniques for pattern matching were
lifted to monitoring against complex speciﬁcation making use of timing param-
eters and data parameters [WAH19].

In [WAH22a], we proposed model-bounded monitoring: instead of monitor-
ing a black-box system against a sole speciﬁcation, we use in addition a (lim-
ited, over-approximated) knowledge of the system, to eliminate false positives.
This over-approximated knowledge is given in [WAH22a] in the form of a linear
hybrid automaton (LHA) [HPR94], an extension of ﬁnite-state automata with
continuous variables; their ﬂow in each location (“mode”) is given as a linear
constraint over derivatives; location invariants and transition guards are given
by linear constraints over the system variables. We use in [WAH22a] both an ad-
hoc implementation, and another one based on PHAVerLite [Fre08; BZ19]. In
this work, we share with [WAH22a] the principle of using an over-approximation
of the model to rule out some violation of the speciﬁcation. However, we con-
sider here a diﬀerent formalism, and we work on discrete samples. In terms of
expressiveness of the over-approximated model:

1. our approach can be seen as less expressive than [WAH22a], in the sense
that we have a single (uncertain) dynamics, as opposed to LHAs, where a
diﬀerent dynamics can be deﬁned in each mode; this also allows us to propose
a simpler (therefore more eﬃcient) analysis, as each new sample allows us
to restart from an exact basis, while in [WAH22a] at each new sample, the
system (from an algorithmic point of view) can be in “diﬀerent modes at the
same time”;

2. conversely, our dynamics is also signiﬁcantly more expressive than the LHA
dynamics of [WAH22a]; we consider not only the class of linear dynamical
systems, but even ﬁt into a special case of non-linear systems, by allowing
uncertainy in the model dynamics—this is what makes our model an over-
approximation of the actual behavior.

In addition, we also allow for uncertain logs, coping with sensor uncertainties—
not considered in [WAH22a]. We also propose a new ad-hoc implementation
based on [GD21b].

In [MP16; MP18], a monitor is constructed from a system model in diﬀeren-
tial dynamic logic [Pla12]. The main diﬀerence between [MP16; MP18] and our
approach relies in the system model: in [MP16; MP18], the compliance between
the model and the behavior is checked at runtime, while our model is assumed

4

to be an over-approximation of the behavior—which is by assumption compliant
with the model.

Reachability in linear dynamical systems In [ALK11], given a continuous time
linear system with input, the system is discretized and reachable sets for consec-
utive time intervals are computed. At each step, the state transition matrix is
expressed using the Peano-Baker series. The series is then numerically approx-
imated iteratively using Riemann sums. Then a zonotope-based convex hull is
computed over-approximating the result of all possible matrices in the uncertain
matrix. In [CR11], Combastel and Raka extend an existing algorithm based on
zonotopes so that it can eﬃciently propagate structured parametric uncertain-
ties. As a result, they provide an algorithm for computation of envelopes enclos-
ing the possible states and/or outputs of a class of uncertain linear dynamical
systems. In [LP15], given an uncertain linear dynamical system ˙x = Λux, Lal et
al. provide a sampling interval δ > 0, given an (cid:15) > 0, s.t. the piecewise bilinear
function, approximating the solution by interpolating at these sample values, is
within (cid:15) of the original trajectory. [GD19] identiﬁes a class of uncertainties by a
set of suﬃcient conditions on the structure of the dynamics matrix Λu. For such
classes of uncertainties, the exact reachable set of the linear dynamical system
can be computed very eﬃciently. But this method is not applicable for arbitrary
classes of uncertainties. In [GD21b], given an uncertain linear dynamical system,
we provide two algorithms to compute reachable sets. The ﬁrst method is based
on perturbation theory, and the second method leverages a property of linear
systems with inputs by representing them as Minkowski sums. In [GD21a], given
an uncertain linear dynamical system, we provide an algorithm to compute sta-
tistically correct over-approximate reachable sets using Jeﬀries Bayes Factor.
Note that uncertain linear dynamical systems are a special subset of non-linear
systems. Thus, uncertain linear dynamical systems can also be modelled as a
non-linear system. Some additional works that deal with computing reachable
sets of non-linear systems are [CÁS13; TD13; CSÁ14; Dug+15; Alt15; Kon+15;
CS16].

3 Preliminaries

In this section, we layout the notations and deﬁnitions used in the rest of the
paper.

Formal analysis of safety critical systems requires a precise mathematical
model of the system, such as linear dynamical systems. But in reality, the pre-
cise, exact model is almost never available—parameter variations, sensor and
measurement errors, unaccounted parameters are few such causes that make the
availability of a precise model impossible. Presence of such uncertainties in the
model makes the safety analysis of these systems, using traditional methods,
useless. Thus, for the analysis to be indeed useful, the safety analysis must con-
sider all possible uncertainties. In [LP15], the authors provide a model, known
as uncertain linear dynamical systems, to capture such uncertainties. Consider
the following example of an uncertain linear dynamical system.

5

Example 1 ([GD19, Example 1.1]). Let a discrete linear dynamical system x+ =
(cid:3) and α represents either the modeling uncertainty or a
Λx, where Λ = (cid:2) 1 α
parameter, assuming 2 ≤ α ≤ 3. Note that any safety analysis assuming a ﬁxed
value of α will render the analysis useless—for the safety analysis to be indeed
sound, it must consider all possible values of α, and they cannot be enumerated.

0 2

Intuitively, uncertain linear dynamical systems model the uncertainties in the
system by representing all possible dynamics matrices of the system—clearly,
this forms a special class of non-linear dynamical systems. To perform safety
analysis of uncertain linear dynamical systems, these works provide reachable
set computation techniques that account for all possible uncertainties.

Deﬁnition 1 (Uncertain linear dynamical systems ([GD19, Deﬁni-
tion 2.4])). An uncertain linear dynamical system is denoted as

x+ = Λx

(1)

where Λ ⊂ Rn×n is the uncertain dynamics matrix.

Deﬁnition 2 (Reachable set of an uncertain linear dynamical systems
([GD19, Deﬁnitions 2.3 and 2.4])). Given an initial set θ0 and time step
t ∈ Z, the reachable set of an uncertain linear dynamical system is deﬁned as:

RS(Λ, θ0, t) = θt = { θ | θ = ξA(θ0, t), A ∈ Λ}.

where ξA(θ0, t) = Atθ0. An alternative deﬁnition is:

RS(Λ, θ0, t) = θt =

(cid:91)

A∈Λ

ξA(θ0, t).

(2)

(3)

Note that uncertain linear dynamical systems are capable of modelling sys-
tems with parameters or when the system dynamics is not perfectly known—
the system has modelling uncertainties. [LP15; GD19; GD21b; GD21a] propose
various algorithms to compute reachable sets of these systems that account for
uncertainties. In this work, we leverage a recently proposed reachable set compu-
tation technique, given in [GD21b], to propose our oﬄine and online monitoring
algorithm, primarily due to its eﬃciency vis-à-vis our setting.

Given an initial set θ0 ⊂ Rn and given a time step t, we denote by θt ⊂ Rn
the reachable set of the system (given by Eq. (1)) at time step t. Next, we deﬁne
a log of the system with uncertainties.

Deﬁnition 3 (Log). Given an uncertain linear dynamical system as in
Eq. (1), a ﬁnite length (uncertain) log of the system is deﬁned as follows:
(cid:96) = {(ˆθt, t) | θt ⊆ ˆθt, t ≤ H} where H is a given time bound.

Each tuple (ˆθt, t) is called a sample. Observe that our samples are not neces-
sarily reduced to a point. The length of log (cid:96)—number of samples in (cid:96)—is given
by |(cid:96)|. Given a log (cid:96), the k-th sample of (cid:96) is given as (cid:96)k = (ˆθtk , tk), where ˆθtk is
an over-approximation of the system at time step tk. Note that the length of a

6

log is not necessarily equal to H, but |(cid:96)| ≤ H: therefore, our logs are scattered, in
the sense that they do not necessarily contain a sample for each t ∈ {1, . . . , H}.
We further note that the uncertainties in the logs, arising from the sensor uncer-
tainties of the logging system, are independent of the uncertainties in the system
modelling (Deﬁnition 1). We assume that each sample of the log contains the
true state of the system at a given time step. Note that this generally holds in
practice: the physical sensors (such as used in medical devices, cars, etc.) record
values within an error tolerance, thus giving a range of values containing the
actual value.

We call a log (cid:96) accurate if it satisﬁes the following condition: ∀1 ≤ k ≤
|(cid:96)| : ˆθtk = θtk . Given an uncertain linear dynamical system, x+ = Λx with an
initial set θ0 ⊂ Rn, an over-approximate reachable set of x+ at time step t is
overReach(Λ, θ0, t), such that θt ⊆ overReach(Λ, θ0, t). We use the technique
proposed in [GD21b] to compute overReach(Λ, θ0, t) in this work.

4 Monitoring using uncertain linear dynamical systems

as bounding model

In this section, we propose the two main contributions of this work:

1. Oﬄine monitoring: Given a log with uncertainties—arising, e.g., due to
faulty sensors—, we propose an algorithm to infer the safety of a system
as given in Eq. (1). We prove our method’s soundness.

2. Online monitoring: We propose a framework to infer safety of a system, as
in Eq. (1), that triggers the logging system to sample only when needed.
Note that, as we only consider the system at discrete time steps, the method
cannot be sound nor complete, i.e., there always exists a small possibility
that the system might violate the safety speciﬁcation in between two concrete
samples (this will be discussed in Section 6). However, our online method
is both sound and complete at the discrete time stamps, and under the
assumption that the samples are free from uncertainties. That is, our method
infers the system to be safe if and only if the actual behavior of the system
is safe at any discrete time stamp, when the logging system can generate
accurate samples of the system. Put it diﬀerently, we guarantee that skipping
some logging in the future using our method will not remove any sample
where a violation could have been observed.

4.1 Oﬄine monitoring

Our ﬁrst contribution addresses oﬄine monitoring: in this setting, we assume
full knowledge of the uncertain log, usually after an execution is completely over.
Before we propose our oﬄine algorithm, we illustrate the approach in Fig. 2a.
Consider two consecutive samples k and k + 1, marked in black, at time steps t
and t+5 respectively. The reachable sets, in blue, represent the over-approximate
behaviors possible by the system between time steps t and t + 5. Consider the

7

(a) Oﬄine

(b) Online

Fig. 2: (2a): Oﬄine Monitoring. Black: Two consecutive samples, k and k + 1,
at time steps t and t + 5 respectively. Blue: The over-approximate reachable set
computed from sample k using overReach(.). (2b): Online Monitoring. Blue:
Over-approximate reachable set computed, at each step, using overReach(.).

case where at time step t + 2 the over-approximate reachable set intersects with
the unsafe region. Once our algorithm detects a possible unsafe behavior, it
computes the intersection between the over-approximate reachable set (here,
the reachable set at time-step t + 2) and the unsafe set. Then it checks whether
the reachable set, given in the next sample (k + 1), is reachable from the unsafe
region—if yes, it infers unsafe; if not, it infers safe. Now, we formally propose
our oﬄine monitoring method in Algorithm 1 for a given log (cid:96) with uncertainty.

Description The for loop, starting in line 1, traverses through each sample, and
checks if the system can reach a possibly unsafe behavior between two consec-
utive samples (computed in lines 2 and 3), using over-approximate reachable
set computation. If the over-approximate reachable set between two consecutive
samples intersect with the unsafe set (line 6), we perform a reﬁnement as follows
(line 7–line 11): We compute the unsafe region (intersection between unsafe set
and over-approximate reachable set) in line 7, then check if we can reach the next
sample from the unsafe region (line 9–line 11). If the next sample is reachable
from the unsafe behavior, we conclude the system is unsafe (line 10–line 11).

Soundness and incompleteness Our proposed oﬄine monitoring approach is
sound at discrete time steps, but not complete—there might be cases where our
algorithm returns unsafe even though the actual system is safe. The primary
reason for its incompleteness is due to the fact that overReach(.) computes an
over-approximate reachable set. Formally:

If the actual system is
Theorem 1 (soundness at discrete time steps).
unsafe at some discrete time step, then Algorithm 1 returns unsafe. Equivalently,
if Algorithm 1 returns safe, then the actual system is safe at every discrete time
step.

Proof. Let the actual trajectory τ , between two samples k and k + 1, become
unsafe at time step tun. Therefore, the over-approximate reachable set, computed
by overReach(·) at time step tun, will also intersect with the unsafe set (due

8

𝑡sample𝑘=(,𝑡)𝑡+1𝑡+2𝑡+5Unsafe Setsample𝑘+1=(,𝑡+5)Unsafe Region𝑡+4𝑡𝑡+1𝑡+2𝑡+3Sample at this timestepUnsafe SetAlgorithm 1: Oﬄine monitoring

: An uncertain log (cid:96) of a system x+ = Λx, and an unsafe set U.
input
output : Return safe (resp. unsafe) if the actual system behavior is safe

(resp. potentially unsafe).

2

1 for k ∈ {1, . . . , |(cid:96)| − 1} do
(ˆθtk , tk) ← (cid:96)k ;
(ˆθtk+1 , tk+1) ← (cid:96)k+1 ;
t∆ = tk+1 − tk − 1 ;
/* Compute reachable set for all time steps between the two

// current sample
// next sample
// time gap between two samples

3

4

samples. Check if any of the sets intersects with the unsafe
set

*/

for p ∈ {1, . . . , t∆ − 1} do
if ˆθtk+p ∩ U (cid:54)= ∅ then

*/
/* Refinement process starts
ψ ← ˆθtk+p ∩ U ; // compute the unsafe region of the system
td = tk+1 − (tk + p) ;
ϑ ← overReach(Λ, ψ, td) ;
/* Check if the next sample is reachable from the unsafe

region

if ϑ ∩ ˆθtk+1 (cid:54)= ∅ then
return unsafe ;

the unsafe region

// the next sample is reachable from

*/

ˆθtk+p+1 ← overReach(Λ, ˆθtk+p, 1) ;

5

6

7

8

9

10

11

12

13 return safe ;

to soundness of overReach(·)). Note that the actual trajectory τ , originating
from the sample k, intersects the unsafe region at time step tun, and reaches the
sample k + 1. The reﬁnement module (Algorithm 1, line 7–line 11), using over-
approximate reachable sets will therefore infer the same, concluding the system
behavior to be unsafe.

4.2 Online monitoring

Given a time bound H, we propose our online monitoring method in Algorithm 2.

Description The online monitoring algorithm begins by sampling the system at
the initial time step, say 0, in line 1. As a sanity check, we conﬁrm if the initial
behavior of the system is safe in line 2. The for loop starting in line 2—where
each iteration corresponds to the set of actions for a time step t—performs the
following: At a given time step t, we compute the over-approximate reachable set
at the next time step t + 1 (line 6). If the computed over-approximate reachable
set intersects with the unsafe set, we sample the system at time step t+1 to check
if the actual behavior is also unsafe (line 5–line 9). If safe, we reset the behavior
(line 9); if unsafe, we return unsafe (line 8). Intuitively, this method samples

9

Algorithm 2: Online monitoring

: An uncertain system x+ = Λx, an unsafe set U, time bound H.

input
output : Return safe iﬀ the actual system behavior is safe.

1 ˆθ0 ← Sampling at time step 0 ;

/* Check whether the initial behavior is safe

// initial behavior of the system.
*/

2 if ˆθ0 ∩ U (cid:54)= ∅ then return unsafe ;
3 for t ∈ {1, 2, . . . , H − 1} do

4

5

6

7

8

9

ˆθt+1 ← overReach(Λ, ˆθt, 1) ;
next step

// over-approximate reachable set at

/* Check whether the over-approximate reachable set is unsafe */
if ˆθt+1 ∩ U (cid:54)= ∅ then

(cid:96)t+1 ← Sample at time step t + 1 ;
/* Check whether the actual reachable set is unsafe
if (cid:96)t+1 ∩ U (cid:54)= ∅ then
return unsafe ;

*/

ˆθt+1 = (cid:96)t+1 ;

// reset to actual behavior

10 return safe;

the actual system only when the over-approximate reachable set, computed by
overReach(.), intersects the unsafe set. This process is illustrated in Fig. 2b.

Soundness and completeness Our online monitoring algorithm is correct (safe
and complete) at discrete time steps, provided the samples are accurate—it re-
turns safe if and only if the actual behavior of the system is safe at all discrete
time steps, when accurate samples are obtained. Intuitively, we get the com-
pleteness from the fact that it returns unsafe if and only if the (accurate) sample
is unsafe. Formally:

Theorem 2 (correctness at discrete time steps). Algorithm 2 returns
safe iﬀ the actual behavior at all discrete time steps is safe.

Proof. The soundness proof—if the actual behavior is unsafe, Algorithm 2 infers
unsafe—is straightforward. Hence, we now argue the completeness—if the actual
behavior is safe, Algorithm 2 infers safe. Note that, Algorithm 2 infers the system
behavior as unsafe only when a sampled log (actual behavior) becomes unsafe:
therefore, if the samples are free from uncertainties (i.e., exact), Algorithm 2 is
complete.

Remark 1. While our aim is to consider continuous systems, note that, for
discrete-time systems, our approach is entirely correct (sound and complete),
without the restriction to “discrete time steps”, since we can ﬁnd a granularity
small enough for the discrete-time evolution. This is notably the case for sys-
tems where the behavior does not change faster than a given frequency (e.g., the
processor clock).

10

5 Case studies

We demonstrate the applicability and usability of our approach on two examples,
a medical device and an adaptive cruise control.

5.1

Implementation and environment

We implemented our online and oﬄine monitoring algorithms (Algorithms 1
and 2) in a Python-based prototype tool, named MoULDyS. Tool, models and raw
results are available through a public GitHub repository3.

Environment All our experiments were performed on a Lenovo ThinkPad Mo-
bile Workstation with i7-8750H CPU with 2.20 GHz and 32 GiB memory on
Ubuntu 20.04 LTS operating system (64 bit). Our tool uses numpy [Oli06],
scipy [Vir+20], mpmath [Joh+13] for matrix multiplications, [GD21b] to com-
pute overReach(.), and the Gurobi [Gur20] engine for visualization of the reach-
able sets.

Implementation details vis-à-vis Algorithms 1 and 2 The intersection checking
between two sets in Algorithms 1 and 2 has been implemented as an optimization
formulation in Gurobi. That is, given two sets, our implementation of intersection
check returns true iﬀ the two sets intersect. In other words, our intersection check
is exact. In contrast, computing the result of the intersection between two sets
adds an over-approximation in our implementation—given two sets, we compute
a box hull of the two sets and then compute intersection of the two box hulls.
Therefore, the only over-approximate operation we perform in Algorithms 1
and 2—apart from overReach(·)—is Algorithm 1 line 7.

Generating scattered uncertain logs for oﬄine monitoring At each time step,
the logging system may take a snapshot of the system evolution at that time
step; the logging occurs with a probability p (given). In other words, at each time
step, it records the evolution of the system with probability p. Clearly, due to the
probabilistic logging, this logger is not guaranteed to generate periodic samples.
We also do not assume that the samples logged by the logging system, at each
time step, are accurate—the logging system, due to sensor uncertainties, logs an
over-approximate sample of the system at that time step. In our experiments,
each log was generated statically from our bounding model (the uncertain linear
dynamical system) by simulating its evolution from an uncertain initial set (i.e.,
not reduced to a point). In the end, we get an uncertain log (as in Deﬁnition 3).

Logging system for online monitoring When the logging system is triggered, at
a time step, to generate a sample, the logging system records the evolution of
the system and sends it to the online monitoring algorithm. Similar to the oﬄine
logging system, we do not assume that the samples logged by the logging system

3 https://github.com/bineet-coderep/MoULDyS

11

are perfectly accurate—the logging system, due to sensor uncertainties, logs an
over-approximate sample of the system at that time step. That is, we use the
same method—as the oﬄine logging system—to generate logs (statically), but
unlike the oﬄine algorithm, the online algorithm uses the samples only when
required.

For both our case studies, all the generated logs are safe.

Research questions We consider the following research questions in our case
studies:

1. Eﬀect of logging probability (number of log samples) on the rate of false
alarms raised by the oﬄine monitoring—inferring a behavior as “potentially
unsafe” when the actual behavior is “safe”.

2. For oﬄine monitoring, does the size of the samples (in other words, volume
of the set obtained as sample), gathered at each step, have an impact on
the rate of false alarms? Put it diﬀerently, what is the eﬀect, vis-à-vis false
alarms, of the amount of the uncertainty in the log?

3. For online monitoring, how frequent is the logging system triggered to gen-

erate a sample?

4. For the same execution, how do the outcome (in terms of verdict on safety by
the monitoring algorithms) and the eﬃciency (in terms of number of samples
needed) of the oﬄine and online monitoring algorithms compare?

5.2 First benchmark: Anesthesia

We ﬁrst demonstrate our approach on an automated anesthesia delivery
model [GDM14]. The anesthetic drug considered in this model is propofol. Such
safety critical systems are extremely important to be veriﬁed formally before
they are deployed, as under or overdose of the anesthetic drug can be fatal to
the patient.

Model: The model as in [GDM14] has two components:

1. Pharmacokinetics (PK): models the change in concentration of the drug as

the body metabolizes it.

2. Pharmacodynamics (PD): models the eﬀect of drug on the body.

The PK component is further divided into three compartments:

1. ﬁrst peripheral compartment c1,
2. second peripheral compartment c2,
3. plasma compartment cp.

The PD component has one compartment, called ce. The set of state variables
of this system is [ cp c1 c2 ce ](cid:62). The input to the system is the infusion rate of
the drug (propofol) u. The complete state-space model of this system in given
in [GDM14, Equation 5].

Model parameters: The evolution of states—cp, c1, c2—is dependent on
several parameters, such as: the weight of the patient (weight), the ﬁrst order rate

12

Fig. 3: Oﬄine monitoring: We plot the change in concentration level of cp with
time. The volume of the samples increase from left to right, and the probability
of logging increases from bottom to top. The blue regions are the reachable
sets showing the over-approximate reachable sets as computed by the oﬄine
monitoring, the black regions are the samples from the log given to the oﬄine
monitoring algorithm, and the red dotted line represents safe distance level. Note
that although the top-row plots and the bottom left plots’ reachable sets seem
to intersect with the red line (unsafe set), the reﬁnement module infers them
to be unreachable, therefore concluding the system behavior as safe—unlike the
bottom-right plot.

.

constants between the compartments k10, k12, k13, k21 and k31. The evolution of
the state ce is dependent on the parameter kd, the rate constant between plasma
and eﬀect site.

Safety: The system is considered safe if the following concentration levels

are maintained at all time steps: cp ∈ [1, 6], c1 ∈ [1, 10], c2 ∈ [1, 10], ce ∈ [1, 8].

In this case study, we focus our attention on the eﬀect of perturbation, in the
weight of the patient (weight), on the concentration level of plasma compart-
ment cp. We assume that the weight of the patient has an additive perturbation
of ±0.8 kg in this case study—at each time step, the weight of the patient is

13

Probability of LoggingSize of the samplesFig. 4: Online monitoring: We plot the change in concentration level of cp with
time. The blue regions are the reachable sets showing the over-approximate
reachable sets as computed by the online monitoring, the black regions are the
samples generated when the logging system was triggered by the online monitor-
ing algorithm, and the red dotted line represents safe concentration levels. Left:
We apply our online monitoring to the anesthesia model. Right: We compare our
online and oﬄine algorithms. The green regions are the reachable sets showing
the over-approximate reachable sets between two consecutive samples from the
oﬄine logs, the magenta regions are the oﬄine logs, given as an input to the of-
ﬂine monitoring algorithm, generated by the logging system, and the red dotted
line represents safe concentration levels. The blue regions are the reachable sets
showing the over-approximate reachable sets as computed by the online moni-
toring, the black regions are the samples generated when the logging system was
triggered by the online monitoring algorithm, and the red dotted line represents
safe concentration levels.

.

weight + δw, δw ∈ [0, 0.8]. With perturbation in the weight, we want to infer
safety of this system using monitoring.

Clearly, monitoring of this system vis-à-vis safety is crucial. It is not practical
for a busy human doctor or a practitioner to monitor each patient continuously at
all time steps—monitoring, either oﬄine or online, provides them an eﬃcient way
to save their time and treat their patients without compromising their safety.

We now answer questions (1)-(4), using Figs. 3 and 4. In Fig. 3:

1. the plots in the bottom row have logging probability of 20%, and the plots

in top row have a logging probability of 40%;

2. the plots in left column and the right column have been simulated with
an initial set of [ [3,4] [3,4] [4,5] [3,4] ](cid:62), u ∈ [2, 5] and [ [2,4] [3,6] [3,6] [2,4] ](cid:62), u ∈
[2, 10] respectively.

That is, the volume of the samples increases from left to right. In Fig. 4, we
simulated the trajectory with an initial set [ [3,4] [3,4] [4,5] [3,4] ](cid:62), u ∈ [2, 5].
Following are the answers to questions (1)-(4) from Figs. 3 and 4:

14

Answer to Question 1. We answer this question by comparing two sets ﬁgures
in the left column and the right column of Fig. 3. For the left column, i.e.,
with smaller sample size: the bottom-left plot took 51.40 s and concluded the
system to be safe. The analysis in this plot invoked the reﬁnement module of the
oﬄine algorithm. But increasing the probability of logging, i.e., more number of
samples, as in the top-left plot, resulted in not invoking the reﬁnement module
at all, thus taking 32.92 s. For the right column, i.e., with larger sample size:
this analysis, as shown in the bottom-right column, took 1.73 s to complete,
and concluded the system behavior to be unsafe. The behavior of the system,
shown in top-right plot with 40% probability of logging, results in inferring the
behavior of the system as safe, by invoking the reﬁnement module several times.
Overall, this analysis, as shown in the top-right plot, took 35.93 s to complete,
and concluded the system behavior to be safe.

Answer to Question 2. We answer this question by comparing two sets ﬁgures in
the top row and the bottom row of Fig. 3. For the bottom row, i.e., with smaller
logging probability: Increasing the volume of the samples results in inferring the
behavior from safe (bottom-left plot) to unsafe (bottom-right plot), as per the
oﬄine monitoring algorithm. For the top row, i.e., with higher logging probability:
Increasing the volume of the samples results in not invoking the reﬁnement
module (top-left plot) to invoking the reﬁnement module several times (top-
right plot), as per the oﬄine monitoring algorithm.

Answer to Question 3. The result is given in Fig. 4 (left). Using our online
algorithm, we were able to prove safety of the system in 109.04 s. The online
algorithm triggered the logging system to generate samples for 83 time steps—
this is less than 5% of total time steps. We observe, as shown in Fig. 4 (left),
that the logging system is triggered more when the trajectory is closer to the
unsafe region.

Answer to Question 4. We compare our oﬄine and online algorithms, for 2 000
time steps, on the same trajectory. The result is given in Fig. 4 (right). Note
that, using our online algorithm, we were able to prove safety of the system in
107.99 s. The online algorithm triggered the logging system to generate samples
only 84 times. In contrast, the oﬄine algorithm, with a log size of 115 (5%
logging probability) stopped at the 35th sample, (wrongly) inferring the system
as unsafe, taking 71.37 s.

5.3 Second benchmark: Adaptive Cruise Control

We now apply our oﬄine and online monitoring algorithms to an adaptive cruise
control (ACC) model [Nil+16]. An adaptive cruise control behaves like an or-
dinary cruise control when there is no car in the sight of its sensor, and when
there is a car in its sight, it maintains a safe distance.

Model: The model as in [Nil+16] has the following state variables:

15

1. velocity of the vehicle v,
2. distance between the two vehicles h, and
3. velocity of the lead vehicle vL.

The state space of the system is given in [Nil+16, Equation 3]. The set of state
variables of this system is [ v h vL ](cid:62).

Model parameters: The model is dependent on two parameters:

1. acceleration of the lead vehicle aL, and
2. breaking force and torque applied to the wheels as a lumped net force F .

Note that the model is dependent of acceleration of the vehicle aL, which is very
hard to accurately measure due to sensor uncertainties. Similarly the torque F
applied to the wheels is also dependent of the coeﬃcient of friction of the ground.
To reﬂect such uncertainties, we consider aL ∈ [−0.9, 0.6] and F ∈ [−0.6, 2.46].
Safety: The system is considered safe if the distance between vehicles h >

0.5.

Consider an event of a car crash, where the log stored by the car before
the crash, is the only data available to analyze the crash; such an analysis might
beneﬁt police, insurance companies, vehicle manufacturers, etc. Using our oﬄine
algorithm one can ﬁgure out if the car might have shown unsafe behavior or not.
Similarly, consider a vehicle on a highway with a lead vehicle in its sight. The
ACC in such a case needs to continuously read sensor values to track several
parameters, such as acceleration of the lead vehicle, braking force, etc.—this
results in wastage of energy. Using our online monitoring algorithm, the car reads
sensor values only when there is a potential unsafe behavior. This intermittent
behavior will result in saving energy without compromising safety of the system.
With the aforementioned reasons for applying our oﬄine and online monitor-
ing, we apply our algorithms on the ACC model and answer questions (1)-(4).
We think that the answers to these questions will help the car designers to design
eﬃcient ACC models without compromising safety.

Next, we answer questions (1)-(4), using Figs. 5 and 6. In Fig. 5:

1. the plots in the bottom row have logging probability of 20%, and the plots

in top row have a logging probability of 40%;

2. the plots in left column and the right column have been simulated with an
initial set of [ [15,15.01] [3,3.03] [14.9,15] ](cid:62) and [ [15,15.1] [3,3.5] [14.9,15.1] ](cid:62) respec-
tively.

Fig.

In
[ [15,15.01] [3,3.03] [14.9,15] ](cid:62), u ∈ [2, 5].

simulated

4, we

the

trajectory with

an

initial

set

Following are the answers to questions (1)-(4) from Figs. 3 and 4:

Answer to Question 1. We answer this question by comparing two sets ﬁgures
in the left column and the right column of Fig. 5. For the left column, i.e.,
with smaller sample size: the bottom-left plot took 19.08 s and concluded the
system to be safe. This analysis in this plot invoked the reﬁnement module of
the oﬄine algorithm. But increasing the probability of logging, i.e., more number

16

Fig. 5: Oﬄine monitoring: We plot the change in distance h between the vehi-
cles with time. The volume of the samples increase from left to right, and the
probability of logging increases from bottom to top. The color coding is same as
Fig. 3.

of samples, as in the top-left plot, resulted in not invoking the reﬁnement module
at all, thus taking 16.5 s. For the right column, i.e., with larger sample size: The
analysis is similar to that of the left column. The bottom-right plot invoked the
reﬁnement module several times, thus taking 20.84 s, while the top-right plot
took 17.5 s, as it invoked the reﬁnement module a smaller number of times.

Answer to Question 2. We answer this question by comparing two sets ﬁgures
in the top row and the bottom row of Fig. 5. For the bottom row, i.e., with
smaller logging probability: Comparing the bottom-left and bottom-right shows
that increasing sample volume results in invoking the reﬁnement module more
frequently. A very similar behavior is seen by comparing the top row (i.e., with
higher logging probability).

Answer to Question 3. Using our online algorithm, we were able to prove safety
of the system in 104.58 s. The online algorithm triggered the logging system to
generate samples for 53 time steps—this is less than 3% of total time steps. This
is shown in Fig. 6 (left).

Answer to Question 4. We compare our oﬄine and online algorithm, for 2 000
time steps, on the same trajectory. The result is given in Fig. 6 (right). Note
that, using our online algorithm, we were able to prove safety of the system in

17

Probability of LoggingSize of the samplesFig. 6: Online monitoring: We plot the change in distance between two vehicle h
with time. The color coding is same as Fig. 4. Left: We apply our online moni-
toring to the ACC model. Right: We compare our online and oﬄine algorithms.
.

124.46 s. The online algorithm triggered the logging system to generate samples
only 50 times. In contrast, the oﬄine algorithm, with a log size of 281 (14%
logging probability) took 28.54 s to infer that the system is safe.

5.4 General observations

In this section, we provide general answers to questions (1)-(4) based on our
observations from the above two case studies. Following are the set of general
observations we made:

Answer to Question 1. Increasing the probability of logging reduces the chances
of inclusion of spurious behaviors due to over-approximate reachable set compu-
tation over longer time horizon. Therefore, it has a reduced chance of spuriously
inferring the system unsafe, also fewer chance of invoking the reﬁnement module
(as there are less spurious behaviors).

Answer to Question 2. Increasing the size of samples (due to uncertainties or
inherent nature of the system) results in increasing chances of invoking the re-
ﬁnement module more frequently. It also increases the chance of (wrongly) in-
ferring the system to be unsafe, as the reﬁnement module can in itself add to
the overapproximation.

Answer to Question 3. We observed that our online algorithm is able to prove
the system’s safety very eﬃciently with very few samples.

Answer to Question 4. We observed that for a given random log, the oﬄine
algorithm was unable to prove safety of the system, whereas our online algorithm
was able to prove safety of the system, using fewer samples, by intelligently
sampling the system only when needed. We also note that, though here we just
demonstrated the result for one random log, but our internal experiments showed
that the online algorithm always needed fewer samples to prove safety—which is

18

unsurprising, as it is designed to sample the system only when needed. This can
also result in energy saving, as sampling usually requires energy and bandwidth.

Reachable sets computation using Flow* As uncertain linear dynamical systems
are a special type of non-linear systems, Flow* [CÁS13] would have been a nat-
ural candidate to benchmark our oﬄine and online monitoring implementation
by comparing various methods to compute overReach(·). However, we ran into
the following issues:

1. To the best of our understanding, Flow* expects the model of the continuous
dynamics to be given as input, along with a discretization parameter. There-
fore, trying to encode the time-varying uncertainties in the system as state
variables will lead to discretization of the variables encoding uncertainties;
such discretization leads to undesired behavior, as those uncertain variables
will fail to capture the actual range of values that are possible at any time
step.

2. However, Flow* does allow time varying uncertainties, but only additive4.
Unfortunately, both our case studies require multiplicative uncertainties.

Still, we believe Flow* could be compared with our implementation when the
bounding model has a simpler dynamics than our uncertain linear dynamical
systems.

6 Conclusion

We presented a new approach for monitoring cyber-physical systems against
safety speciﬁcations, using the additional knowledge of an over-approximation
of the system expressed using an uncertain linear dynamic system. Our approach
assumes as ﬁrst input a log with exact (but scattered) timestamps and uncer-
tain variable samplings (in the form of zonotopes), and as second input an over-
approximated model, bounding the possible behaviors. The over-approximation
is modeled by uncertainty in the variables of the dynamics. In the oﬄine setting,
we are thus able to detect possible violations of safety properties, by extrapo-
lating the known samples with the over-approximated dynamics, and if needed
using a second reachability analysis to check whether the next sample is “com-
patible” with the possible unsafe behavior, i.e., can be reached from the unsafe
zone. In the online setting, we are capable of decreasing the number of samples,
triggering a sample only when there might be a safety violation in a near fu-
ture, based on the latest known sample and on the over-approximated model
dynamics—increasing the energetic eﬃciency. Our method is sound in the sense
that an absence of detection of violation by our method indeed guarantees the
absence of an actual violation at any discrete time step. In the online method,
provided the samples are accurate, our method is in addition complete, i.e., the
method outputs safe iﬀ the actual system is safe at all discrete time steps. Put
it diﬀerently, we guarantee that not triggering a sample at some time steps is
harmless and will not lead to missing a safety violation.

4 See example at https://flowstar.org/benchmarks/2-dimensional-ltv-system/

19

x

x

t

t

(a) Discrete samples

(b) Continuous behavior

Fig. 7: Incompleteness

Future works. On the log side, we considered ﬁxed timestamps, but uncertain
values for the continuous variables; in fact, the timestamps could also be uncer-
tain. This makes sense when the samples are triggered by sensors distributed
over a network, which can create delays and therefore timed uncertainty. This
was not considered in our approach, and is on our agenda.

The presence of an over-approximated model makes sense, as proposed
in [WAH22a]; in our setting of an over-approximated model given by an un-
certain linear dynamical system, some formal guarantees that this model indeed
represents an over-approximation of the actual system remain to be exhibited.
In addition, the assumption of the presence of an over-approximated model
is central to our work, and we used it in all our experiments, in the sense that
the logs were indeed instances of the over-approximated model. However, an
interesting future work will be to partially lift this assumption, by allowing the
log to (temporarily, locally) diﬀer from the over-approximated model, allowing
for more freedom. In that case, a special care must be made on the approach’s
soundness.

A possible threat to validity remains the enumeration of time steps in both
our algorithms (line 5 in Algorithm 1 and line 3 in Algorithm 2), which could slow
down the analysis for very sparse logs—even though this did not seem critical
in our experiments. Using skipping methods could help improving the eﬃciency
of our approach.

Another future work consists in increasing our guarantees, notably due to
the continuous nature of cyber-physical systems under monitoring. Indeed, even
with a rather ﬁne-grained sampling showing no speciﬁcation violation (e.g., in
Fig. 7a), it can always happen that the actual continuous behavior violated the
speciﬁcation (e.g., in Fig. 7b). While setting discrete time steps at a suﬃciently
ﬁne-grained scale will help to increase the conﬁdence in the results of our ap-
proach, no absolutely formal guarantee can be derived. Therefore, one of our
future works is to propose some additional conditions for extrapolating (contin-
uous) behaviors between consecutive discrete samples. Also, improving the scope
of our guarantees (in the line of, e.g., [DFS21]) is on our agenda.

Finally, in [WAH22a], the bounding model is given using linear hybrid au-
tomata, a formalism with a much more restricted dynamics than our approach,
but featuring modes, i.e., changes of dynamics guarded by some constraints over
the variables—which is not considered in our approach. Extending our approach
with modes (as in [WAH22a]) is on our agenda, yielding a very expressive bound-

20

ing model with dynamics beyond linear dynamics, and modes. However, this
poses some technical diﬃculties, as the intersection of a set of behaviors with
a guard (necessary to check a change of mode) is not proposed by the method
from [GD21b]. A future work will be to envision over-approximated intersec-
tions.

References

[AHW18]

[ALK11]

[Alt15]

[Bak+18]

[Bar+18]

[BKZ17]

Étienne André, Ichiro Hasuo, and Masaki Waga. “Oﬄine timed pattern
matching under uncertainty”. In: Proceedings of the 23rd International
Conference on Engineering of Complex Computer Systems (ICECCS
2018) (Dec. 12–14, 2018). Ed. by Anthony Widjaja Lin and Jun Sun.
Melbourne, Australia: IEEE Computer Society, 2018, pp. 10–20. doi:
10.1109/ICECCS2018.2018.00010 (cit. on p. 4).
Matthias Althoﬀ, Colas Le Guernic, and Bruce H. Krogh. “Reachable set
computation for uncertain time-varying linear systems”. In: Proceedings of
the 14th ACM International Conference on Hybrid Systems: Computation
and Control (HSCC 2011) (Apr. 12–14, 2011). Ed. by Marco Caccamo,
Emilio Frazzoli, and Radu Grosu. Chicago, IL, USA: ACM, 2011, pp. 93–
102. doi: 10.1145/1967701.1967717 (cit. on p. 5).
Matthias Althoﬀ. “An Introduction to CORA 2015”. In: Proceedings of the
1st and 2nd International Workshops on Applied veRiﬁcation for Contin-
uous and Hybrid Systems (ARCH@CPSWeek 2014 and ARCH@CPSWeek
2015) (Apr. 13, 2015). Ed. by Goran Frehse and Matthias Althoﬀ. Vol. 34.
EPiC Series in Computing. Seattle, WA, USA: EasyChair, 2015, pp. 120–
151. doi: 10.29007/zbkv (cit. on p. 5).
Alexey Bakhirkin, Thomas Ferrère, Dejan Nickovic, Oded Maler, and
Eugene Asarin. “Online Timed Pattern Matching Using Automata”. In:
Proceedings of the 16th International Conference on Formal Modeling
and Analysis of Timed Systems (FORMATS 2018) (Sept. 4–6, 2018).
Ed. by David N. Jansen and Prabhakar Pavithra. Vol. 11022. Lecture
Notes in Computer Science. Beijing, China: Springer, 2018, pp. 215–232.
doi: 10.1007/978-3-030-00151-3_13 (cit. on p. 4).
Ezio Bartocci, Jyotirmoy V. Deshmukh, Alexandre Donzé, Georgios E.
Fainekos, Oded Maler, Dejan Nickovic, and Sriram Sankaranarayanan.
“Speciﬁcation-Based Monitoring of Cyber-Physical Systems: A Survey on
Theory, Tools and Applications”. In: Lectures on Runtime Veriﬁcation
– Introductory and Advanced Topics. Ed. by Ezio Bartocci and Yliès
Falcone. Vol. 10457. Lecture Notes in Computer Science. Springer, 2018,
pp. 135–175. doi: 10.1007/978-3-319-75632-5_5 (cit. on p. 3).
David A. Basin, Felix Klaedtke, and Eugen Zalinescu. “The MonPoly
Monitoring Tool”. In: Proceedings of An International Workshop on Com-
petitions, Usability, Benchmarks, Evaluation, and Standardisation for
Runtime Veriﬁcation Tools (RV-CuBES 2017) (Sept. 15, 2017). Ed. by
Giles Reger and Klaus Havelund. Vol. 3. Kalpa Publications in Comput-
ing. Seattle, WA, USA: EasyChair, 2017, pp. 19–28 (cit. on p. 3).

21

[BZ19]

[CÁS13]

[CR11]

[CS16]

[CSÁ14]

[DFM13]

[DFS21]

[Dug+15]

[Fre08]

Anna Becchi and Enea Zaﬀanella. “Revisiting Polyhedral Analysis for
Hybrid Systems”. In: Proceedings of the 26th International Symposium
on Static Analysis (SAS 2019) (Oct. 8–11, 2019). Ed. by Bor-Yuh Evan
Chang. Vol. 11822. Lecture Notes in Computer Science. Porto, Portugal:
Springer, 2019, pp. 183–202. doi: 10 . 1007 / 978 - 3 - 030 - 32304 - 2 _ 10
(cit. on p. 4).
Xin Chen, Erika Ábrahám, and Sriram Sankaranarayanan. “Flow*: An
Analyzer for Non-linear Hybrid Systems”. In: Proceedings of the 25th
International Conference on Computer Aided Veriﬁcation (CAV 2013)
(July 13–19, 2013). Ed. by Natasha Sharygina and Helmut Veith.
Vol. 8044. Lecture Notes in Computer Science. Saint Petersburg, Rus-
sia: Springer, 2013, pp. 258–263. doi: 10.1007/978-3-642-39799-8_18
(cit. on pp. 5, 19).
Christophe Combastel and Sid-Ahmed Raka. “On Computing Envelopes
for Discrete-time Linear Systems with Aﬃne Parametric Uncertain-
ties and Bounded Inputs”. In: IFAC Proceedings Volumes 44.1 (2011),
pp. 4525–4533. doi: 10.3182/20110828-6-IT-1002.02585 (cit. on p. 5).
Xin Chen and Sriram Sankaranarayanan. “Decomposed Reachability
Analysis for Nonlinear Systems”. In: Proceedings of the 2016 IEEE Real-
Time Systems Symposium (RTSS 2016) (Nov. 29–Dec. 2, 2016). Porto,
Portugal: IEEE Computer Society, 2016, pp. 13–24. doi: 10.1109/RTSS.
2016.011 (cit. on p. 5).
Xin Chen, Sriram Sankaranarayanan, and Erika Ábrahám. “Under-
approximate ﬂowpipes for non-linear continuous systems”. In: Proceed-
ings of the Formal Methods in Computer-Aided Design (FMCAD 2014)
(Oct. 21–24, 2014). Lausanne, Switzerland: IEEE, 2014, pp. 59–66. doi:
10.1109/FMCAD.2014.6987596 (cit. on p. 5).
Alexandre Donzé, Thomas Ferrère, and Oded Maler. “Eﬃcient Robust
Monitoring for STL”. In: Proceedings of the 25th International Conference
on Computer Aided Veriﬁcation (CAV 2013) (July 13–19, 2013). Ed.
by Natasha Sharygina and Helmut Veith. Vol. 8044. Lecture Notes in
Computer Science. Saint Petersburg, Russia: Springer, 2013, pp. 264–
279. doi: 10.1007/978-3-642-39799-8_19 (cit. on p. 4).
Johann C. Dauer, Bernd Finkbeiner, and Sebastian Schirmer. “Monitor-
ing with Veriﬁed Guarantees”. In: Proceedings of the 21st International
Conference on Runtime Veriﬁcation (RV 2021) (Oct. 11–14, 2021). Ed.
by Lu Feng and Dana Fisman. Vol. 12974. Lecture Notes in Computer
Science. online: Springer, 2021, pp. 62–80. doi: 10.1007/978- 3- 030-
88494-9_4 (cit. on p. 20).
Parasara Sridhar Duggirala, Sayan Mitra, Mahesh Viswanathan, and
Matthew Potok. “C2E2: A Veriﬁcation Tool for Stateﬂow Models”. In:
Proceedings of the 21st International Conference on Tools and Algorithms
for the Construction and Analysis of Systems (TACAS 2015), Held as
Part of the European Joint Conferences on Theory and Practice of Soft-
ware (ETAPS 2015) (Apr. 11–18, 2015). Ed. by Christel Baier and Ce-
sare Tinelli. Vol. 9035. Lecture Notes in Computer Science. London, UK:
Springer, 2015, pp. 68–82. doi: 10.1007/978-3-662-46681-0_5 (cit. on
p. 5).
Goran Frehse. “PHAVer: Algorithmic Veriﬁcation of Hybrid Systems Past
HyTech”. In: International Journal on Software Tools for Technology

22

[GD19]

[GD21a]

[GD21b]

[GDM14]

[Gur20]

[HPR94]

[Jak+18]

[Joh+13]

[Kon+15]

[LP15]

Transfer 10.3 (May 2008), pp. 263–279. issn: 1433-2779. doi: 10.1007/
s10009-007-0062-x (cit. on p. 4).
Bineet Ghosh and Parasara Sridhar Duggirala. “Robust Reachable Set:
Accounting for Uncertainties in Linear Dynamical Systems”. In: ACM
Transactions on Embedded Computing Systems 18.5s (2019), 97:1–97:22.
doi: 10.1145/3358229 (cit. on pp. 5, 6).
Bineet Ghosh and Parasara Sridhar Duggirala. Reachability of Linear
Uncertain Systems: Sampling Based Approaches. Tech. rep. 2109.07638.
arXiv, 2021. arXiv: 2109.07638 [eess.SY] (cit. on pp. 5, 6).
Bineet Ghosh and Parasara Sridhar Duggirala. Robustness of Safety for
Linear Dynamical Systems: Symbolic and Numerical Approaches. Tech.
rep. 2109.07632. arXiv, 2021. arXiv: 2109 . 07632 [eess.SY] (cit. on
pp. 3–7, 11, 21).
Victor Gan, Guy Albert Dumont, and Ian Mitchell. “Benchmark Prob-
lem: A PK/PD Model and Safety Constraints for Anesthesia Delivery”.
In: Proceedings of the 1st and 2nd International Workshops on Applied
veRiﬁcation for Continuous and Hybrid Systems (ARCH@CPSWeek 2014
and ARCH@CPSWeek 2015) (Apr. 13, 2015). Ed. by Goran Frehse and
Matthias Althoﬀ. Vol. 34. EPiC Series in Computing. Seattle, WA, USA:
EasyChair, 2014, pp. 1–8. doi: 10.29007/8drm (cit. on p. 12).
LLC Gurobi Optimization. Gurobi Optimizer Reference Manual. 2020
(cit. on p. 11).
Nicolas Halbwachs, Yann-Éric Proy, and Pascal Raymond. “Veriﬁcation
of Linear Hybrid Systems by Means of Convex Approximations”. In: Pro-
ceedings of the First International Static Analysis Symposium (SAS 1994)
(Sept. 28–30, 1994). Ed. by Baudouin Le Charlier. Vol. 864. Lecture Notes
in Computer Science. Namur, Belgium: Springer, 1994, pp. 223–237. doi:
10.1007/3-540-58485-4_43 (cit. on p. 4).
Stefan Jakšić, Ezio Bartocci, Radu Grosu, Thang Nguyen, and Dejan
Ničković. “Quantitative monitoring of STL with edit distance”. In: For-
mal Methods in System Design 53.1 (2018), pp. 83–112. doi: 10.1007/
s10703-018-0319-x (cit. on p. 4).
Fredrik Johansson et al. mpmath: a Python library for arbitrary-precision
ﬂoating-point arithmetic (version 0.18). https : / / mpmath . org/. Dec.
2013 (cit. on p. 11).
Soonho Kong, Sicun Gao, Wei Chen, and Edmund M. Clarke. “dReach: δ-
Reachability Analysis for Hybrid Systems”. In: Proceedings of the 21st In-
ternational Conference on Tools and Algorithms for the Construction and
Analysis of Systems (TACAS 2015), Held as Part of the European Joint
Conferences on Theory and Practice of Software (ETAPS 2015) (Apr. 11–
18, 2015). Ed. by Christel Baier and Cesare Tinelli. Vol. 9035. Lecture
Notes in Computer Science. London, UK: Springer, 2015, pp. 200–205.
doi: 10.1007/978-3-662-46681-0_15 (cit. on p. 5).
Ratan Lal and Pavithra Prabhakar. “Bounded error ﬂowpipe computa-
tion of parameterized linear systems”. In: Proceedings of the 2015 Inter-
national Conference on Embedded Software (EMSOFT 2015) (Oct. 4–9,
2015). Ed. by Alain Girault and Nan Guan. Amsterdam, Netherlands:
IEEE, 2015, pp. 237–246. doi: 10.1109/EMSOFT.2015.7318279 (cit. on
pp. 3, 5, 6).

23

[MCW21]

[MN04]

[MP16]

[MP18]

[Nil+16]

[Oli06]

[Pla12]

[QD20]

[TD13]

[Ulu+14]

Konstantinos Mamouras, Agnishom Chattopadhyay, and Zhifu Wang.
“A Compositional Framework for Quantitative Online Monitoring over
Continuous-Time Signals”. In: Proceedings of the 21st International Con-
ference on Runtime Veriﬁcation (RV 2021) (Oct. 11–14, 2021). Ed. by Lu
Feng and Dana Fisman. Vol. 12974. Lecture Notes in Computer Science.
online: Springer, 2021, pp. 142–163. doi: 10.1007/978-3-030-88494-9_8
(cit. on p. 3).
Oded Maler and Dejan Nickovic. “Monitoring Temporal Properties of
Continuous Signals”. In: Proceedings of the Joint International Confer-
ences on Formal Modelling and Analysis of Timed Systems (FORMATS
2004) and Formal Techniques in Real-Time and Fault-Tolerant Systems
(FTRTFT 2004) (Sept. 22–24, 2004). Ed. by Yassine Lakhnech and Ser-
gio Yovine. Vol. 3253. Lecture Notes in Computer Science. Grenoble,
France: Springer, 2004, pp. 152–166. doi: 10.1007/978-3-540-30206-
3_12 (cit. on p. 3).
Stefan Mitsch and André Platzer. “ModelPlex: veriﬁed runtime validation
of veriﬁed cyber-physical system models”. In: Formal Methods in System
Design 49.1-2 (2016), pp. 33–74. doi: 10 . 1007 / s10703 - 016 - 0241 - z
(cit. on p. 4).
Stefan Mitsch and André Platzer. Veriﬁed Runtime Validation for Par-
tially Observable Hybrid Systems. Tech. rep. 2018. arXiv: 1811 . 06502
(cit. on p. 4).
Petter Nilsson, Omar Hussien, Ayca Balkan, Yuxiao Chen, Aaron D.
Ames, Jessy W. Grizzle, Necmiye Ozay, Huei Peng, and Paulo Tabuada.
“Correct-by-Construction Adaptive Cruise Control: Two Approaches”. In:
IEEE Transactions on Control Systems Technology 24.4 (2016), pp. 1294–
1307. doi: 10.1109/TCST.2015.2501351 (cit. on pp. 15, 16).
Travis E Oliphant. A guide to NumPy. Vol. 1. Trelgol Publishing USA,
2006 (cit. on p. 11).
André Platzer. “The Complete Proof Theory of Hybrid Systems”. In: Pro-
ceedings of the 27th Annual IEEE Symposium on Logic in Computer Sci-
ence (LICS 2012) (June 25–28, 2012). Dubrovnik, Croatia: IEEE Com-
puter Society, 2012, pp. 541–550. doi: 10.1109/LICS.2012.64 (cit. on
p. 4).
Xin Qin and Jyotirmoy V. Deshmukh. “Clairvoyant Monitoring for Signal
Temporal Logic”. In: Proceedings of the 18th International Conference
on Formal Modeling and Analysis of Timed Systems (FORMATS 2020)
(Sept. 1–3, 2020). Ed. by Nathalie Bertrand and Nils Jansen. Vol. 12288.
Lecture Notes in Computer Science. Vienna, Austria: Springer, 2020,
pp. 178–195. doi: 10.1007/978-3-030-57628-8_11 (cit. on p. 4).
Romain Testylier and Thao Dang. “NLTOOLBOX: A Library for Reach-
ability Computation of Nonlinear Dynamical Systems”. In: Proceedings
of the 11th International Symposium on Automated Technology for Veri-
ﬁcation and Analysis (ATVA 2013) (Oct. 15–18, 2013). Ed. by Dang Van
Hung and Mizuhito Ogawa. Vol. 8172. Lecture Notes in Computer Sci-
ence. Hanoi, Vietnam: Springer, 2013, pp. 469–473. doi: 10.1007/978-
3-319-02444-8_37 (cit. on p. 5).
Dogan Ulus, Thomas Ferrère, Eugene Asarin, and Oded Maler. “Timed
Pattern Matching”. In: Proceedings of the 12th International Conference
on Formal Modeling and Analysis of Timed Systems (FORMATS 2014)

24

[Vir+20]

[WA19]

[Wag19]

[WAH16]

[WAH19]

(Sept. 8–10, 2014). Ed. by Axel Legay and Marius Bozga. Vol. 8711. Lec-
ture Notes in Computer Science. Florence, Italy: Springer, 2014, pp. 222–
236. doi: 10.1007/978-3-319-10512-3_16 (cit. on p. 4).
Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland,
Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, War-
ren Weckesser, Jonathan Bright, Stéfan J. van der Walt, Matthew Brett,
Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nel-
son, Eric Jones, Robert Kern, Eric Larson, CJ Carey, İlhan Polat, Yu
Feng, Eric W. Moore, Jake Vand erPlas, Denis Laxalde, Josef Perktold,
Robert Cimrman, Ian Henriksen, E. A. Quintero, Charles R Harris, Anne
M. Archibald, Antônio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt,
and SciPy 1. 0 Contributors. “SciPy 1.0: Fundamental Algorithms for Sci-
entiﬁc Computing in Python”. In: Nature Methods 17 (2020), pp. 261–
272. doi: 10.1038/s41592-019-0686-2 (cit. on p. 11).
Masaki Waga and Étienne André. “Online Parametric Timed Pattern
Matching with Automata-Based Skipping”. In: Proceedings of the 11th
Annual NASA Formal Methods Symposium (NFM 2019) (May 7–9,
2019). Ed. by Julia Badger and Kristin Yvonne Rozier. Vol. 11460. Lec-
ture Notes in Computer Science. Houston, TX, USA: Springer, 2019,
pp. 371–389. doi: 10.1007/978-3-030-20652-9_26 (cit. on p. 4).
Masaki Waga.
“Online Quantitative Timed Pattern Matching with
Semiring-Valued Weighted Automata”. In: Proceedings of the 17th In-
ternational Conference on Formal Modeling and Analysis of Timed Sys-
tems (FORMATS 2019) (Aug. 27–29, 2019). Ed. by Étienne André and
Mariëlle Stoelinga. Vol. 11750. Lecture Notes in Computer Science. Am-
sterdam, The Netherlands: Springer, 2019, pp. 3–22. doi: 10.1007/978-
3-030-29662-9_1 (cit. on p. 4).
Masaki Waga, Takumi Akazaki, and Ichiro Hasuo. “A Boyer-Moore Type
Algorithm for Timed Pattern Matching”. In: Proceedings of the 14th In-
ternational Conference on Formal Modeling and Analysis of Timed Sys-
tems (FORMATS 2016) (Aug. 24–26, 2016). Ed. by Martin Fränzle and
Nicolas Markey. Vol. 9884. Lecture Notes in Computer Science. Québec,
QC, Canada: Springer, 2016, pp. 121–139. doi: 10.1007/978- 3- 319-
44878-7_8 (cit. on p. 4).
Masaki Waga, Étienne André, and Ichiro Hasuo. “Symbolic Monitoring
against Speciﬁcations Parametric in Time and Data”. In: Proceedings of
the 31st International Conference on Computer-Aided Veriﬁcation (CAV
2019), Part I (July 15–18, 2019). Ed. by Işil Dillig and Serdar Tasiran.
Vol. 11561. Lecture Notes in Computer Science. New York City, USA:
Springer, 2019, pp. 520–539. doi: 10 . 1007 / 978 - 3 - 030 - 25540 - 4 _ 30
(cit. on p. 4).

[WAH22a] Masaki Waga, Étienne André, and Ichiro Hasuo. “Model-Bounded Moni-
toring of Hybrid Systems”. In: ACM Transactions on Cyber-Physical Sys-
tems (2022). To appear (cit. on pp. 3, 4, 20).

[WAH22b] Masaki Waga, Étienne André, and Ichiro Hasuo. “Parametric Timed
Pattern Matching”. In: ACM Transactions on Software Engineering and
Methodology (2022). To appear (cit. on p. 4).
Masaki Waga, Ichiro Hasuo, and Kohei Suenaga. “Eﬃcient Online Timed
Pattern Matching by Automata-Based Skipping”. In: Proceedings of the
15th International Conference on Formal Modeling and Analysis of Timed

[WHS17]

25

[WHS18]

Systems (FORMATS 2017) (Sept. 5–7, 2019). Ed. by Alessandro Abate
and Gilles Geeraerts. Vol. 10419. Lecture Notes in Computer Science.
Berlin, Germany: Springer, 2017, pp. 224–243. doi: 10 . 1007 / 978 - 3 -
319-65765-3_13 (cit. on p. 4).
Masaki Waga, Ichiro Hasuo, and Kohei Suenaga. “MONAA: A Tool
for Timed Pattern Matching with Automata-Based Acceleration”. In:
Proceedings of the 3rd Workshop on Monitoring and Testing of Cyber-
Physical Systems (MT@CPSWeek 2018) (Apr. 10, 2018). Porto, Portu-
gal: IEEE, 2018, pp. 14–15. doi: 10.1109/MT-CPS.2018.00014 (cit. on
p. 4).

26

