Thought experiments in a quantum computer

Nuriya Nurgalieva1, Simon Mathis1, Lídia del Rio1 2, and Renato Renner1

1Institute for Theoretical Physics, ETH Zürich, 8093 Zürich, Switzerland
2Quantum Center, ETH Zurich, 8093 Zürich, Switzerland

We introduce a software package that allows users to design and run simulations
of thought experiments in quantum theory. In particular, it covers cases where several
reasoning agents are modelled as quantum systems, such as Wigner’s friend experiment.
Users can customize the protocol of the experiment, the inner workings of agents (includ-
ing a quantum circuit that models their reasoning process), the abstract logical system
used (which may or not allow agents to combine premises and make inferences about each
other’s reasoning), and the interpretation of quantum theory used by diﬀerent agents.
Our open-source software is written in a quantum programming language, ProjectQ, and
runs on classical or quantum hardware. As an example, we model the Frauchiger-Renner
extended Wigner’s friend thought experiment, where agents are allowed to measure each
other’s physical memories, and make inferences about each other’s reasoning.

Truth is a matter of the imagination.

Ursula K. Le Guin, The Left Hand of Darkness

Software available at https://github.com/jangnur/Quanundrum [1].

2
2
0
2

p
e
S
3
1

]
h
p
-
t
n
a
u
q
[

1
v
6
3
2
6
0
.
9
0
2
2
:
v
i
X
r
a

1

 
 
 
 
 
 
Figure 1: Quanundrum software structure. Our package can model quantum multi-agent scenarios
where agents reason about each other’s experiments and thoughts. Its modular components customize the
experimental setting (Protocol module), the inferences allowed given experimental observations (Interpreta-
tion module), how those inferences are logically combined and propagated (Consistency), and how agents’
brains are physically modeled (Agent). The program outputs the logical conclusions of all agents and whether
they are compatible.

1 Introduction

Let us summarize the main contributions of this work immediately, before describing the motivation
in detail in Section 1.2.

1.1 Contribution of this work

A modular tool to test multi-agent quantum thought experiments. We introduce a
software package, Quanundrum, to run quantum mechanical thought experiments where agents are
modeled as quantum systems and have to reason about each other’s experimental results (Figure 1).
Users can customize the following modules:

• Protocol module: speciﬁes the experimental setting, including number of agents and other
quantum systems, measurements and physical transformations carried out by diﬀerent agents,
and which chains of inferences we are interested in analysing.

• Agent module: speciﬁes agents’ physical memories and processors, deﬁning how abstract

reasoning is implemented as a physical process, e.g. as a quantum circuit.

• Interpretation module: deﬁnes the immediate inferences drawn from an experimental out-

come, which depends on the interpretation of quantum theory applied by an agent.

• Consistency module: deﬁnes the axioms of abstract logic that determine how inferences
are combined and how knowledge is propagated into complex reasoning; it also determines
the subjects that agents are allowed to reason about.

Structure of this manuscript. This paper introduces the conceptual idea of the software and its
main components. In Section 1.2 we motivate the need for software to simulate quantum thought

2

In Section 2, we detail how we physically model agents’ memories and reasoning
experiments.
processes. In Section 3, we look at how agents’s inferences are propagated and combined to complex
reasoning. We provide an application to the Frauchiger-Renner thought experiment in Section B,
and examples of simpler protocols in Appendix A. We discuss the implications of this work in
Section 4. For documented step-by-step examples and customization, we recommend assessing the
software directly.

Structure of the software repository. The open-source software package Quanundrum is pub-
licly available [1]. The software is written in ProjectQ [2], a free open-source quantum programming
language based on Python. In the repository, one can ﬁnd: installation instructions; instructions
on how to run and customize the software; Jupyter notebooks with examples: simple test scenarios
and the Frauchiger-Renner thought experiment [3] for two diﬀerent interpretations; explanations of
the experimental settings and conclusions; descriptions of the physical modelling of rational agents
as small quantum computers; and descriptions of the implementation of interpretations.

1.2 Motivation

In science and philosophy, thought experiments use an imag-
Thought experiments in physics.
inary setting to draw conclusions about our physical reality — in regimes that are technologically
or ethically unfeasible. For example Maxwell’s demon [4] thought experiment, which explores what
would happen if a being could access microscopic degrees of freedom of a gas — something un-
reachable at the time — led to conceptual and technological breakthroughs. The conclusion of
the thought experiment was a seeming violation of the second law of thermodynamics; inspired by
this inconsistency, Landauer’s principle [5] was developed, stating a minimum possible amount of
energy required to erase one bit of information to save the second law; the connections between
information theory and thermodynamics, with multiple applications in the quantum regime, stem
from this insight. Other famous examples include (but are not limited to) the twins paradox in
special relativity [6], Fermi’s paradox in cosmology, and, in quantum theory, Schrödinger’s cat [7]
and Wigner’s friend [8] scenarios.

Analysing thought experiments. Thought experiments have a similar structure to the plan-
ning of actual physical experiments: a particular situation in the scope of a theory is visualized; an
operation or a set of operations is carried out; we see what happens; ﬁnally, we draw a conclusion.
Thought experiments can be analised and criticized from diﬀerent angles: perhaps the setting is
not achievable in reality, and the experiment cannot be scaled to more realistic settings, rendering
the conclusions inconsequential; perhaps there are hidden assumptions that weaken the conclusions
of the experiment; sometimes the diﬀerent assumptions are coarse-grained in ways that make it
hard to identify the critical one. To achieve a deep understanding of the consequences of a thought
experiment, it is crucial to be able to specify in a modular way the diﬀerent components that go
into it: what theory is used, what is the experimental setting, what are the assumptions on the
underlying logical system, what relevant parts of the experiment could we be ignoring? For exam-
ple, in the case of Maxwell’s demon, it was crucial to realize that the demon’s knowledge about
the position and momentum of gas particles had to be physically stored somewhere (the demon’s
memory), which had been overlooked in the original proposal of the experiment.

3

1.3 Quantum thought experiments as programs

In quantum
Philosophical motivation: testing quantum theory and interpretations.
mechanics, thought experiments are used to prove theorems that tell us more about the underlying
structure of quantum theory, for example by ruling out diﬀerent interpretations and properties of the
theory [8–11]. Modelling these thought experiments as computer programs forces us to rigorously
specify what a given interpretation entails, and to test its consequences under diﬀerent scenarios. It
shifts the focus from sometimes vague philosophical considerations to concrete and mathematically
complete descriptions, which can be modelled explicitly. It can also allow us to understand which
interpretations result in distinct physical theories, and which aﬀect only the abstract reasoning of
agents. Finally, once an interpretation is implemented in code, it can be more easily tweaked and
re-tested in critical settings, which leads to faster development of consistent interpretations.

Practical motivation: quantum computing networks. From a more practical perspective,
we can envision a future where we would like to set up networks of quantum computers, and program
them to reason independently about events happening elsewhere in the network. The reasoning these
node computers conduct should be logically consistent, akin to the classical reasoning we are used to.
For example, the computers should not reach conﬂicting conclusions with regards to measurements’
outcomes, or should be free to conclude A ⇒ C from knowing the implications A ⇒ B and B ⇒ C.1

A yellow ﬂag for logical quantum networks. Surprisingly, these simple logical requirements
can prove to be diﬃcult to achieve in a quantum network. Taking one speciﬁc quantum mechanical
example, in a thought experiment introduced by Frauchiger and Renner in [3] (in the following
FR thought experiment) agents, who are allowed to reason about each other’s outcomes and are
also modelled as quantum systems, come to a logical contradiction.2 More generally, we have shown
that the traditional framework for agents reasoning in a multi-agent setting, namely, classical modal
logic [12], fails in quantum settings [13]. These conclusions are based on assumptions on how agents
are modelled, how they make predictions and inferences, and how these predictions and inferences
are combined.

Testing the boundaries of quantum network reasoning. This illustrates how thought ex-
periments are crucial to determine the boundaries of the reasoning programmed into nodes. For
example, a popular conservative view [14] is that, in order to avoid make false predictions, a local
quantum computer must not be allowed to reason about global protocols that include a future
measurement of its own memory. While this is not problematic for traditional quantum algorithms,
which typically end with a measurement, it could severely restrict the power and range of predictions
allowed to fully quantum computer networks. We hope that by carefully testing diﬀerent scenarios
we can ﬁnd weaker restrictions that avoid contradictions.

2 Physical models of agents: memory and reasoning

Classical multi-agent logic: a light example. Three logicians walk into a bar. “Does everyone
want a beer?” the bartender asks. Alice answers “I don’t know.” Then Bob says “I don’t know

1A, B and C here are any statements that can be made in such a quantum computer network; for example, “the
outcome of the measurement of a qubit S is a = 1”, or “it is going to rain tomorrow”. All the inferences are assumed
to be deterministic, that is, they hold true with probability 1.

2We detail this scenario in Section B.

4

1√
2

|0iR + 1√
2

|1iR

a

1√
2

|0iR + 1√
2

|1iR

•

|0iA

(b) Perspectives of Alice (top) and
Wigner (bottom).

(a) Thought experiment setup.

Figure 2: Wigner’s friend thought experiment [8]. An agent Alice holds in her lab a qubit R, initially
in state 1√
(|0iR + |1iR). Alice measures R in basis {|0iR, |1iR}, and records the outcome (0 or 1) into her
2
memory A, initially in the state |0iA. Outside her lab stands a second agent, Wigner, who reasons about the
state of the lab. Alice subjectively observes a single outcome a = 0 or a = 1 and models the measurement
as an irreversible transformation. In the neo-Copenhagen interpretation, Wigner can model Alice’s lab as
an isolated quantum system, and the joint evolution of R and her memory A as a unitary transformation: a
CNOT gate that coherently copies the measurement outcome to Alice’s memory A.

either.” Finally, Charlie shouts “Yes!” – and everyone gets their beer [15]. Charlie’s reasoning is
simple: they consider Alice’s point of view, and deduce that if Alice did not want a beer, she would
have answered with a deﬁnitive “No”, as not everyone would have wanted a beer. Considering then
Bob’s viewpoint, Charlie concludes that Bob also deduced that Alice wants a beer, and that his
reason for answering “I don’t know” was that Bob did want a beer, but was unsure of Charlie’s
wishes. This allows Charlie to correctly assess that both of their colleagues want a beer, and, given
that they also very much want a beer, correctly answer “Yes!”

In the previous example,
Physical modelling of memories, observation and reasoning.
Charlie observes their setting for a period of time, and reasons about their colleagues’ reasoning
based on those observations, and their internal model of how their colleagues reason (for example,
taking for granted that they are very rational and literal logicians). To model the physical im-
plementation of this situation, we’d have to specify explicitly: what physical systems implement
their abstract memories, how they write down observations into their memory, and how they reason
about these statements given the theory they are allowed to apply. If we were modelling agents in
the context of quantum theory, we could start by implementing their memories as quantum systems
represented by Hilbert spaces, and their reasoning processes as quantum channels on those Hilbert
spaces and those of the systems observed. In particular we can consider a dilation of all the relevant
systems so that we can look at unitary implementations of observation and reasoning processes.
This will be convenient to later model them as quantum circuits. We will detail in the following
how we model these diﬀerent aspects in the quantum case, for very simple idealizations.

2.1 Physical implementation of measurements and memory update rules

Quantum measurements in the lab. We provide a broad characterization of memory updates
in arbitrary physical theories in [16]; here we illustrate our approach through simple examples. To

5

measure the spin of the particle in the lab, one can use for example the Stern-Gerlach setup. To
experimentally realize it, we tune a magnetic ﬁeld that couples the spin to one of the position
degrees of freedom of the particle. The interaction Hamiltonian can be simpliﬁed to

ˆHint = g ˆSZspin ⊗ ˆXposition,

Hparticle = Hspin ⊗ Hposition,

g ∈ R,

where ˆSZ is the spin observable and ˆX is the position operator. This results in a momentum kick to
the particle, whose trajectory becomes entangled with its spin; this can be macroscopically observed
by installing a screen on the particle’s path. In other settings, an external degree of freedom, like
a pointer, takes the place of the position, so that measuring a quantum system corresponds to
entangling it with the pointer.

Memories as entangled pointers. Similarly, we can model an agent’s memory as a degree of
freedom akin to the pointer, which after the measurement becomes coherently correlated with the
measured system. In a simpliﬁed toy example, both the relevant part of the memory M and the
measured system S are qubits: the memory states |0iM and |1iM can encode the observed outcomes
0 and 1 respectively. Then, for a measurement of S in the computational basis {|0iS, |1iS}, the
memory update describing the process of the agent “observing the outcome and writing it down to
their memory” could be modelled as a CNOT gate between S and M . 3

Subjective view of measurements. Wigner’s friend [8] thought experiment (Figure 2) is a
canonical example for how agents can subjectively model each other’s measurements and memory
update processes. An agent Alice holds in her lab a qubit R, initially in state 1√
(|0iR + |1iR). Alice
2
measures R in the basis {|0iR, |1iR}, and records the outcome (0 or 1) in her memory A. From
Alice’s perspective, the joint state of R and her memory A after the measurement is either |0iR|0iA
or |1iR|1iA. Outside her lab stands a second agent, Wigner, who models Alice’s measurement
as a von Neumann interaction scheme [17], through which the state or the observed system R is
coherently copied to the memory A.
In the extreme case, Wigner could expand his description
of A to cover the whole lab as an isolated system, including all the lab elements that take part
in the measurement, the environment that may dissipate information, and all degrees of freedom
that can become correlated with the outcome. In this case, Wigner may be able to describe the
ﬁnal global state as an entangled state, like for instance 1√
(|00iRA + |11iRA). While Alice has
2
the subjective experience of observing a deﬁnite outcome, Wigner describes instead an entangled
state between her memory, the system measured, and the rest of her lab and environment, which
is sometimes summarized as ‘Wigner models Alice in a superposition of having seen 0 and 1’. We
will later explore more complex settings where agents apply quantum theory according to diﬀerent
interpretations; for now the key message is that in order to describe a measurement performed by
some agent, we must specify from whose perspective we want to model it.

2.2 Logical reasoning as quantum circuits

Circuits implement abstract logic. A summary of our approach is: initial beliefs of agents are
encoded in the initial states of their brains, and belief update, as governed by abstract logic rules,
is encoded as ﬁxed unitary evolutions on their brains, so that the ﬁnal brain state encodes their

3There is a discussion to be held about the role of decoherence in having the subjective experience of seeing a

single outcome. This is outside the scope of this paper, but we encourage it as a research direction.

6

q 1

q 2

3 |1iR
3 |0iR +
Alice’s outcome: |0iA

Qubit S: |0iS

Bob’s outcome: |0iB

•

•

H

•

(a) Experimental setup.

(b) Coherent view of the measurements and
preparations in the experiment.

Figure 3: A simple quantum inference setup. Alice measures a qubit R, and prepares another qubit
S in state |0iR or |+iR depending on her measurement outcome. Bob then measures S, obtains result
b ∈ {0, 1}, and has to reason about Alice’s outcome. On the right is a circuit version of the experiment (up
to the reasoning phase), from the perspective of an external agent Wigner who models both Alice and Bob
as coherent quantum systems with quantum memories A and B. Incidentally, this is the ﬁrst step of the
Frauchiger-Renner experiment.

updated beliefs. This unitary applies the logical machinery to arbitrary initial beliefs, much like a
program updates the state of a classical memory (or a tape in a Turing machine).

A simple experimental setting. To illustrate how we model reasoning, we introduce a simple
example of two agents (Figure 3a), where Bob has to reason about Alice’s outcome. Later we will
expand this example.

t = 1 Alice measures a qubit R, initially in state 1√
3

the result a in her memory.

|0iR +

q 2

3 |1iR, in basis {|0iR, |1iR}, and records

t = 2 Alice prepares a qubit S depending on her outcome: |0iS for outcome a = 0, and 1√
2

|1iS) for a = 1. She gives this qubit to Bob.

(|0iS +

t = 3 Bob measures system S in basis {|0iS, |1iS}, and records the result in his memory.

t = 4 Bob tries to guess what Alice’s outcome was at t = 1. He can say either “I am sure that

a = 0”, “I am sure that a = 1” or “I cannot guess her outcome with certainty.”

Abstract reasoning steps. First let’s see how we would reason in abstract about this experiment.
Suppose that Bob obtains outcome b = 1. What does that tell him about Alice’s outcome? Two
possible inferences are b = 1 ⇒ a = 0 and b = 1 ⇒ a = 1, In this case, it is easy to determine
which inference holds deterministically: if Alice had obtained outcome 0, she would have prepared
system S in state |0iS, and Bob could not have measured 1. Hence, the initial state must have
been |+iS, which means that Alice had obtained outcome 1, and Bob can make a certain inference
b = 1 ⇒ a = 1. On the other hand, if Bob obtains outcome b = 0, he cannot make a deterministic
retrodiction, as both options for the initial state |0iS and |+iS are compatible with his outcome.

Physical encoding of preparations and measurements. From the perspective of an external
agent (like Wigner) who models Alice and Bob as coherent quantum systems interacting with
qubits R and S, the ﬁrst three steps of the experiment can be modelled as a simple quantum

7

qubit measured: |ψiS

measurement
z}|{
•

Bob’s outcome: |0iB

inference: [b = 0 ⇒ a = 0]

inference: [b = 1 ⇒ a = 0]

inference: [b = 0 ⇒ a = 1]

inference: [b = 1 ⇒ a = 1]

|0iI 0,0
|0iI 1,0
|0iI 0,1
|1iI 1,1

Bob’s prediction: a = 0 |0iP 0

Bob’s prediction: a = 1 |0iP 1

•

•

•

•

•

•

UBob

(reasoning)

Figure 4: Modelling agents as coherent reasoning circuits. Our physical model of Bob, as a quantum
reasoning agent, has three main parts: a memory qubit B, where he stores the measurement outcome;
inference qubits {I b,a}b,a, which encodes the agent’s initial beliefs about the validity of diﬀerent inferences;
prediction qubits {P a}a that express his conclusions regarding Alice’s outcome. Each inference qubit I b,a is
initialized in state |1iI b,a if the inference b ⇒ a holds deterministically in this setting (from Bob’s perspective,
as explained later), and |0iI b,a otherwise. Bob’s measurement is modelled (by an external agent) as a CNOT
gate between the system measured and Bob’s outcome register. After performing the measurement, the
reasoning is modeled as a series of doubly-controlled gates that depend on the outcome and inference qubit
registers. They aﬀect the state of the prediction qubit: a ﬁnal state of |1iP a means “Bob guesses that Alice’s
outcome was a deterministically.” For the controlled gates, note that ◦ = X • X. In this case, and given the
way the inferences are initialized, only the last doubly-controlled gate (controlled on I 1,1) acts non-trivially
in practice. We denote Bob’s reasoning unitary by circuit UBob (dashed region).

circuit (Figure 3b), where the measurements are CNOTs, and Alice’s conditional preparation of S
is a Hadamard gate controlled on her memory register. It remains to model the last part of the
experiment: Bob’s reasoning.

Physical encoding of inferences and reasoning. Now we describe how an external agent (like
Wigner, who sees Bob as an evolving quantum system) could represent Bob’s reasoning process as
a quantum circuit.4 First we expand our model of Bob’s brain to include more quantum registers
and gates (Figure 4). In our model, Bob’s prior beliefs about the truth value of prepositions (like “if
I observe b = 1 I can conclude that a = 1” or “smoke implies ﬁre”) are encoded in the initial state of
some qubits in his brain, and can change depending on the experimental setting. On the other hand,
the abstract logical system used by Bob to process his beliefs and observations is implemented by
the unitary circuit. For example, a series of controlled gates implement the knowledge distribution
axiom, (B ∧ (B ⇒ A)) ⇒ A, and allow Bob to make predictions. We will now explain this model
in more detail. We dedicate an inference qubit I b,a to each possible inference b ⇒ a available to
an agent: the qubit is initialized in state |1iI b,a if Bob believes that the inference holds, and |0iI b,a
if it doesn’t. We will explain in Section 3 how to model Bob’s decision process to ﬁnd the truth
value of possible inferences and initialize these qubits; for now let us skip this step and assume
that Bob already concluded that according to the Born rule only the inference b = 1 ⇒ a = 1 is
true. We model this by initializing the corresponding qubit in state |1iI 1,1, and leaving the other

4How Bob models his own evolution depends on his interpretation of quantum theory; more on this in the next

section.

8

Qubit R:

q 1

3 |0iR +

q 2

3 |1iR

•

Alice’s actions

Alice’s outcome: |0iA

Qubit S: |0iS

Bob’s outcome: |0iB

inference: [b = 0 ⇒ a = 0]

inference: [b = 1 ⇒ a = 0]

inference: [b = 0 ⇒ a = 1]

inference: [b = 1 ⇒ a = 1]

|0iI 0,0
|0iI 1,0
|0iI 0,1
|1iI 1,1

Bob’s prediction: a = 0 |0iP 0

Bob’s prediction: a = 1 |0iP 1

•

H

•

Bob’s actions

•

•

•

•

•

•

Check

a

p1

p0

Figure 5: Simulation of the whole experiment. An external Wigner can now simulate the whole
experiment as a unitary circuit evolution, from Alice’s measurement and conditional state preparation to
Bob’s measurement and reasoning. To check the validity of Bob’s predictions, Wigner can measure the
registers A, P 0 and P 1, and see if the classical outcomes are compatible.

inference qubits in state |0iI b,a. The missing piece now is how Bob reaches a prediction about
Alice’s outcome: he must apply some logical reasoning to process the information present in his
list of true inferences and his measurement outcome register. In other words, we are looking for
a quantum version of applying the logical reasoning step “I observed b” ∧ “I know that b ⇒ a ”
⇒ “I conclude that a holds”, checking for all possible combinations of a and b. For this we equip
Bob with prediction qubits {P a}a, one for each possibility for Alice’s outcome a: a ﬁnal state of
|1iP a is interpreted as “Bob guesses that Alice’s outcome was a with certainty”. These qubits are
initialized to {|0iP a}a (which corresponds to “Bob cannot guess that Alice’s outcome was a with
certainty”). He applies this logical reasoning by performing sequential updates of prediction qubit,
each modelled as a Toﬀoli gate (a doubly-controlled gate) conditioned on his outcome register and
the corresponding inference qubit.

A note on complexity and robustness. We do not claim that this is the most compact way
to model reasoning processes; it is nevertheless an approach that generalizes well to more complex
settings, for example including more agents, each with a larger brain, processing more inferences,
observations and predictions. One advantage is that it is easier to then customize which inferences
are valid as a result of applying a diﬀerent physical theory, interpretation, or logical rule system.
The actual reasoning circuit (whose gates represent how agents process inferences) stays the same,
and we only need to initialize the inference qubits appropriately. This is akin to saying “the logical
structure used by each agent is stable, but they can instantiate each premise as true or false.”

Simulating the experiment and consistency checks. From the external agent’s perspective,
the simulation of the whole experiment consists of composing the circuits of the two previous steps:

9

Alice’s coherent measurement and state preparation of Figure 3b, and Bob’s coherent measurement
and reasoning of Figure 4. The result is in Figure 5. One way to check the consistency of Bob’s
reasoning is to measure his two prediction registers as well as Alice’s memory at the end, and see
if the classical outcomes are compatible. For example, we can repeat the experiment many times
and check that whenever Wigner measures on Bob’s prediction register p1 = 1, he also ﬁnds that
the outcome of measuring Alice’s memory is indeed a = 1. (For a more quantum ﬂavour, Wigner
could leave the circuit in a quantum state, and study quantum correlation measures between Bob’s
prediction qubits and Alice’s memory.) The only missing step is deciding how Bob initializes his
inference qubits.

3 Abstract reasoning: interpretation and logic

In our framework, each agent can decide which inferences are
Theories applied by agents.
valid, and initialize their inference qubits accordingly. To do this, agents apply a given theory
to the experimental setting. We employ theory as a broad concept that includes the version and
interpretation of quantum mechanics they apply, their assumptions about other agents, the logical
axioms they follow, and the information available to them about the experimental setting. Agents
can decide on the overall theory they apply before running the experiment. As such, these con-
siderations are processed before the experiment to obtain the list of valid inference rules, as we
will explain ahead. Their direct impact on the experiment is then simply the initialization of the
inference qubits to diﬀerent values.

3.1 Interpretations of quantum theory and inferences

Deﬁning interpretations. An interpretation of quantum theory determines what agents can
infer from experimental outcomes (for example “the global state has now collapsed”, “I know that
it has not collapsed, but I also know that Alice thinks it has”, “I am actually now entangled with
the system measured, and soon Bob will be entangled too”). In our software, a minimal description
of an interpretation deﬁnes two functions, which specify how to perform forward and backward
inference procedures. For each quantum measurement MB performed by an agent (say Bob) in
the course of the experiment, forward inference will compute what he can conclude about events
that will happen after MB (depending on his measurement result), and the backward inference
computes retrodictions about events that happened before MB.

In practice, this is applied to concrete experiments in the following way:
Inference mechanisms.
the protocol of the experiment speciﬁes which inferences we want to check (for example “Bob must
reason about the diﬀerent options for {b =⇒ a}a,b” in the previous example). For each of these
inferences, the program takes the interpretation used by the agent and automatically runs quantum
simulations of the relevant part of the experiment, from the perspective of the agent, and according
to their interpretation, to see if there are simulations compatible with the inference b =⇒ a; from
here it derives the list of inferences that the agent would consider valid. Which “portion of the
experiment” is relevant for the simulation is derived from the forward and backward inference rules
speciﬁed by each interpretation. For example, a many-worlds interpretation may ask us to simulate
and keep track of the global state evolution including several agents, while a collapse interpretation

10

Qubit R:

q 1

3 |0iR +

q 2

3 |1iR

•

Alice’s outcome: |0iA

|ψai

Qubit S: |0iS

project on a

•

H

•

Bob’s outcome: |0iB

b

In order to determine the validity of the various
Figure 6: Bob’s restricted quantum simulation.
possible inferences b =⇒ a, Bob runs a restricted quantum simulation of the experiment. As he needs to
reason about Alice’s outcomes, he simulates a measurement on her memory, and proceeds with independent
simulations with the post-measurement states corresponding to each of the outcomes a. After his measure-
ment at the end, he compares the likelihood of obtaining b ∧ a, and classically determines whether b =⇒ a
applies.

can be more economical on what it needs to reach predictions.
protocol, the software goes through the following steps to simulate it:

In summary, given a particular

1. Deﬁne each step of the protocol by specifying the action (e.g. measurement, preparation,

reasoning) and the domain of the action (agents and systems involved in the action).

2. Determine how many qubits to allocate to each agent (depending on the complexity of the

predictions they have to make) and other systems.

3. Initialize the inference qubits. For this, we run the function making the inference for each
agent, and ﬁll in classical inference tables. To apply the inference function, the reasoning
agent ﬁxes some of the outcomes and runs a restricted quantum simulation of some steps of
the experiment, in order to check the validity of possible inferences; they repeat this for every
possible outcome combination. We explain in more detail how these processes are modeled in
the examples ahead.

4. Initialize the inference qubits of all agents, run the protocol as a whole, and output the

predictions of all agents.

Example: Bob’s restricted quantum simulation. Still following our previous example, let
us see how Bob can make a restricted (quantum) simulation to initialize his inference qubits about
Alice’s outcome (Figure 6). In this simple case the exact interpretation of quantum mechanics is
not yet critical. Bob models Alice’s lab’s evolution, and projects the state to one of Alice’s memory
subspaces, corresponding to her possible outcomes a = 0, 1.

• In Bob’s simulation R is initialized in 1√
3

|0iR +

writes the result down to her memory, through a CNOT gate,

3 |1iR. Simulated Alice measures R and

q 2

1
√
3

|0iR|0iA +

r 2
3

|1iR|1iA.

Now Bob simulates a measurement in Alice’s memory, and projects the post-measurement
state onto the subspaces corresponding to the diﬀerent outcomes a = 0, 1 independently.

11

His simulation carries on further for each of Alice’s outcome options separately until Bob’s
measurement, where Bob also models his own memory as a qubit.

• Case a = 0: Bob continues with the post-measurement state corresponding to a = 0, |0iR|0iA.

1. Simulated Alice prepares S in state |0i and sends it to simulated Bob, who measures it,

coherently copying the result to his memory,

|0iR|0iA|0iS|0iB.

2. Bob can now measure simulated Bob’s memory. From this case Bob can conclude that

a = 0 =⇒ b = 0. To check the converse he must still inspect the other case.

• Case a = 1: Bob continues with the post-measurement state corresponding to a = 1, |1iR|1iA.

1. Simulated Alice prepares qubit S in state |+iS and sends it to simulated Bob, who

measures it,

1
√
2

|1iR|1iA|0iS|0iB +

1
√
2

|1iR|1iA|1iS|1iB.

2. Now Bob measures his simulated self’s memory, and concludes that a = 1 =⇒ (b =
0 ∨ b = 1). In other words, if he obtains b = 0, Alice could have measured a = 1; if he
gets b = 1, Alice could have measured a = 1 as well.

• Finally, Bob’s inference table {b =⇒ a}a,b is constructed by logically combining the analyses
of both cases. Bob concludes that the only certain inference is b = 1 ⇒ a = 1, so that
inference qubit will be initialized as |1iI 1,1, and the others as |0iI a,b. In conclusion, Bob can
now initialize his inference qubits as |xBiIB = |0001iIB

, like we saw in Figure 4.

Why running restricted simulations? In principle, these quantum simulations that agents
use to compute inferences could also be compiled in runtime, as a more involved subcircuit in the
brains of agents in the global experiment. We chose to split them into restricted pre-computations
simply for practical reasons, namely restricted quantum memory space in the NISQ era. Including
these quantum simulations as part of the global experiment would require us to expand the models
of each agent’s brain by a number of qubits that scales badly on the complexity of the protocol
(number of agents and experimental steps). In a future where we have access to large-scale quantum
computers, it would be interesting to run the full quantum experiment (including these inference
steps) in one go. As of late 2022, this does not seem feasible just yet.

Avoiding recursion issues. When an agent runs a quantum simulation to make inferences,
sometimes they may have to include themselves in the simulation, which in principle could lead to
recursion problems. Our design avoids recursion issues — at least in all the cases tested. For direct
examples, some of the simulations presented in Appendix B include a restricted model of the agent
running them. One technique for avoiding recursion is that the restricted quantum simulations
include projections of the simulated state into each possible outcome (as the agent is trying to infer
what happens when an outcome is observed); this already restricts the degrees of freedom modelled
in the simulation, and prevents potential recursion loops. The same can be applied to the agent’s

12

own inference qubits: they don’t need to be initialized (in the simulation) to the ﬁnal correct value,
but instead the agent can test what happens for diﬀerent initial values of the inference qubits. In
our examples, the simulated inference qubits can be safely left out of the simulations, or initialized
in an arbitrary state like |0i.

Currently available interpretations. As of September 2022, there are two interpretations
implemented in the package: neo-Copenhagen and collapse, which we describe brieﬂy here for
In [18], we discuss how the quantum mechanical thought experiments like FR or
completeness.
Wigner’s friend ﬁt into more interpretations, like Bohmian mechanics [19], QBism [20], relational
QM [21, 22], and various versions of many-worlds [23]. We encourage readers to implement other
such interpretations in this package.

In the Copenhagen interpretation [24–26] the modelling of nature
Copenhagen interpretation.
is split in two parts: the ﬁrst part, “observer”, is the observing system which acquires knowledge
by the way of carrying out the experiment, and also includes measuring devices; and the second
part is the observed system. The observer’s experiences are expressed in the ordinary (classical)
language of physics, while the observed system is described in the language of quantum mechan-
ics. The separation above is called the Heisenberg cut [27]. The cut can be understood as being
“objective”, if there is a fundamental property of nature ﬁxing it for all scenarios (conventional
Copenhagen), or “subjective” – when the placement of the cut is determined separately for each ob-
server (neo-Copenhagen [28]). In our implementation, we allow agents to model several other agents
as quantum systems, while still retaining classicality themselves. In other words, the Heisenberg
cuts of individual agents do not necessarily coincide: Alice can model Bob as a quantum system,
while considering herself classical, and Bob can do the reverse.

Objective collapse theories (GRW). Objective collapse theories [29] are an extension of the
existing formalism of quantum theory. They establish dynamics that govern macroscopic and mi-
croscopic processes in nature, by adding stochastic and non-linear terms to standard dynamical
equations; events of non-unitary collapse depend on phenomenological parameters. The current
experimental evidence provides lower and upper bounds on these parameters, which makes collapse
theories one of the few falsiﬁable interpretations in the short term [30–33]. In our implementation,
the relevant aspect that we take is that in objective collapse theories only one outcome is observed
(with some probability) and the post-measurement state collapses — this is an objective view shared
by all agents who use the interpretation, regardless of who performed the measurement. We imple-
ment these stochastic collapse theories through a tree class, where an instance of a tree encapsulates
a quantum experiment. The tree’s branches represent what happens after a measurement outcome
is observed and the corresponding probability (much like in settings where classical randomness
plays a role).

3.2 Combining inferences: logic

Knowledge distribution axiom. A key logical axiom needed for basic reasoning is the distri-
bution axiom [12, 34].5 It allows us to conclude that if an agent knows “A ⇒ B” and “B ⇒ C”,

5More precisely, this is only one of a set of axioms used in multi-agent epistemic settings. We do not review the
rest as they are not relevant to the implementation in this paper – if you want to learn more, consult our modal logic
analysis of FR in [13].

13

then they also know “A ⇒ C”. Formally, this is expressed as

where the knowledge operator Ki represents “agent i knows...”.

Ki(A ⇒ B) ∧ Ki(B ⇒ C) =⇒ Ki(A ⇒ C),

Transitivity of knowledge across agents. However, to be precise, an agent is not always
combining their knowledge directly – sometimes they reason from the viewpoint of a diﬀerent agent
j, which corresponds to stating that “agent i knows that agent j knows that...”. Then to use the
distribution axiom like above, we require an additional step of trusting the knowledge of another
agent as well as their own,

Ki(A ⇒ B) ∧ KiKj(B ⇒ C) =⇒ Ki(A ⇒ B) ∧ Ki(B ⇒ C) =⇒ Ki(A ⇒ C).
The condition KiKjφ =⇒ Kiφ holds trivially for classical multi-agent settings where all agents are
rational and have access to the same set of common knowledge (for example, “we all assume the
Born rule”, “the experimental protocol follows these steps”, “each agent only sees one outcome of a
measurement”, etc). However, in quantum scenarios this condition might not necessarily hold, for
example, due to the duality of perspectives we have seen in Wigner’s friend experiment. Wigner
may not want to adopt the knowledge of Alice, which he sees as more restricted: Alice doesn’t
consider that she is entangled with the system measured. Hence, agents in quantum settings require
additional constraints, which governs the way their knowledge can be combined. In [13, 16], we
called the set of these conditions trust relations.6 Conceptually, these conditions are related to the
original C assumption in the FR paradox [3], which postulates that agents reason from each other’s
viewpoints. Trust relations can restrict and disallow such reasoning for particular set of agents.

Trust structures. The trust structure currently implemented is the trivial one, where agents
trust each other irrespective of the actions they perform on each other. That is, the Consistency
module allows agents to combine the inferences of any two agents: it takes as arguments any two
inference tables encoding A =⇒ B and B =⇒ C, and returns the inference table with the
conclusions B =⇒ C. This can be reﬁned to restricted trust structures, for example by checking
which users provided the original inferences and whether they are allowed to combine them. As an
intuitive example, we could impose that only agents with commuting measurements could trust each
other. Yet this restriction may not be suﬃcient to avoid paradoxes: in the FR thought experiment
with the neo-Copenhagen interpretation, combining knowledge across commuting agents leads to
a contradiction (even when they don’t employ that trust structure fully and only reason about
adjacent agents). See Appendix B for a walk-through of the experiment.

4 Discussion

4.1 Applications and insights

Application: simple experimental settings. For examples of simple examples of experimental
settings, see Appendix A; all experiments are also available as open Jupyter notebooks. These are
useful as litmus tests of new proposals to avoid paradoxes. That is, suppose that the user wants to

6In retrospect, ‘trust’ was an unfortunate term. We now think of it as a relation that tells us ‘Alice believes that

she has a model for Bob’s reasoning, and tries to reason with that model from his perspective’.

14

avoid contradictions in complex thought experiments like FR, and tries to restrict the logical axioms
or to apply a bespoke interpretation (for example by disallowing any trust chains, or implementing
an extreme version of many worlds).
It is not suﬃcient to show that those settings avoid the
paradox: they should also allow agents to make standard inferences in very simple, everyday setups
(like Alice and Bob measure each half of a Bell state, and should predict each other’s outcomes).
The user can then test their interpretation and logical axioms in this kind of scenarios — and indeed
often those restrictions don’t allow Alice and Bob to make the simple predictions of this example
[13].

In Appendix B we model the whole FR experi-
Application: clarifying the FR experiment.
ment and explore diﬀerent variations on how agents choose to reason about each other. A common
criticism of the FR thought experiment is that Alice’s prediction of w = fail is undone by another
agent’s actions, and cannot be accessed after Wigner’s measurement, so there isn’t a direct contra-
diction. However, our implementation shows that a physical trace of Alice’s prediction (through
all the chains of reasoning) actually survives until the end of the experiment in the physical brain
of another agent (Ursula), and can be observed even by Wigner at the same time as his actual
outcome w = ok. We are not aware of examples of this kind of live multi-agent contradictions in
classical physics (and non-contextual theories in general). It is up to the community to decide if
this is problematic, and how to address it.

Foundational outlook: a platform for testing approaches. The package introduced here
allows us to build simple models of agents and their logical interactions in the context of thought
experiments in quantum settings. This includes a modular set of the priors that agents use to de-
rive their conclusions, which depends heavily on the interpretation of quantum mechanics that they
apply. For many decades, interpretations of quantum mechanics have been considered a somewhat
philosophical and abstract discussion. Implementing them in our software in a mathematically rigor-
ous way and testing them in diﬀerent thought experiments brings the philosophical disagreement to
a technical level, and provides additional motivation and tools for formalizing existing approaches.

Computational outlook: a test network of quantum computers. The transitivity of rea-
soning discussed here mimics the behaviour of information across components of a large quantum
computer, where diﬀerent parts of the machine might measure each other in a complicated sequence,
and still need to retain consistency of information stored in their respective quantum memories. Our
framework can serve as a good testing ground for the logical systems that can be implemented in
large-scale quantum devices.

4.2 Directions for future work

Trust structure compiler. A useful extension would be a “trust compiler”, that is a feature to
automatically compute and implement the trust relation structures of an experiment (from the input
‘protocol’, ‘interpretations for each agent’ and ‘general user-deﬁned conditions for trust’). We are
cautiously optimistic about the ease of implementation of this feature: we can write a beta program
that works well for familiar sets of conditions and experiments, but, like most things in quantum
foundations, it’s hard for us to predict whether it would be general enough to handle unexpected
rules. What if a user would like to test consistency of an interpretation of quantum mechanics under

15

a convoluted condition like “I cannot trust the knowledge of agents who will be measured in this
precise basis, in this time interval”? (The answer in this case is that it seems awfully ﬁne-tuned to
a given experiment and would probably not hold up in slightly modiﬁed thought experiments, and
that maybe the user should program it themselves.) It could also be a more sensible and general
condition for trust in quantum settings, but of a structure that we cannot yet predict,7 and would
not ﬁt our trust compiler’s output requirements.

Logical axioms compiler. More generally we should be able to take in a selection of arbitrary
logical axioms speciﬁed by the user [35, 36], and process them (together with the experimental
setting and agents’ speciﬁcations) into a ﬁnal trust structure and set of instructions for how each
agent makes their predictions. The problem here is again generality: the ﬁrst step is to identify
a framework general enough to cover many types of logical axioms, and standardized enough that
it could be coded into our “logical axioms compiler”. A good starting place is consulting with the
classical computational logic community [12, 37, 38] — however, we suspect that once again there
could be suggestions for new quantum axioms that wouldn’t ﬁt a previously standard speciﬁcation.
Once again, the solution is to generalize our base framework, when such promising axioms appear.

In the applications studied we focused on
Probabilistic predictions and quantum logic.
deterministic predictions. In principle the software has all the pieces in place to handle probabilistic
predictions, and we believe it would be straightforward to implement a judgement of contradictions
for ﬁnite probabilities. It should also be suitable to process and generalize some types of quantum
logic [39–42], as the agents’ memories, inferences and predictions are already encoded as quantum
states. We’ll welcome these extensions when there is suﬃcient interest.

More compact models for agents. We would like to ﬁnd more compact circuit models of agents;
these should still be robust and modular in complex settings, but not require as many qubits and
gates to run. Stating from a more economical basic agent model would facilitate later expanding
it to more complex information-processing systems. One simple option would be to allow for d-
dimensional quantum registers and not just qubits, which would allow us to use a smaller Hilbert
space over all fewer multiplexed gates. For example, suppose that Bob’s measurement has a total of
d outcomes (coherently copied to his d-dimension outcome register), and he has to make a prediction
about Alice’s k possible outcomes. The possible inferences could be encoded in d inference registers
{Ib} of dimension k + 1 each. Each of the registers’ initial state |aiIb
would encode “when Bob sees
to represent “In this case Bob cannot
outcome b he predicts that Alice obtains a”, with |a = 0iIb
make a sure prediction about Alice”. The total dimension of the inference registers would then
be dk+1 as opposed to 2dk of our original scheme. The unitary reasoning could be implemented
by d doubly multiplexed gates, controlled on the outcome and inference registers, and targeting
prediction registers. We have not yet tested the implications of this approach, for reasons detailed
ahead.

Libraries for quantum registers of arbitrary dimension. A technical implementation issue
for the above proposal is that ProjectQ, and most quantum programming languages, don’t allow
us to implement registers and gates of dimensions that are not of the form d = 2n — that is

7Given that most of our research focuses on ﬁnding such conditions, we’d venture that we are relatively well-

positioned to guess that it must be surprising.

16

that don’t correspond to a natural number n of qubits. One reason is that quantum programming
languages want the compilation of any program to be compatible with standard quantum hardware
implementations, which require qubit ‘assembly’ instructions to run. Therefore we would have to
write an extra library for ProjectQ to translate code written for d dimensions to the smallest number
of qubits necessary, which is a new research project on its own. With our current knowledge we
cannot guess if the compilation of the ﬁnal program, including this translation, would in the end be
more computationally eﬃcient than our current model.

More interpretations. We look forward to implementing more interpretations of quantum the-
ory: this would help us test not only the interpretations but also the generality and modularity
of the software. This is an open-source project and community input is very much appreciated, in
particular for this point — we may have a good insight into how Quanundrum works, but only the
reader knows the details of their personal interpretation of quantum theory.

In the long term we would like to
Dynamic experiments and quantum reference frames.
expand the Protocol model to cover dynamic experimental settings, where the order of operations
can (coherently) depend on previous outcomes. Another ambitious, long-term generalization would
be to cover cases where agents can have diﬀerent quantum reference frames (both abstract frames
and concrete quantum systems employed as references). This would be a step towards simulating
relativistic quantum thought experiments. As stepping stone, classical special relativity should be
easier to integrate in the package:
it would require us to rethink the applicability of the current
“forward and backward inference” functions, and to generalize them for predictions between any two
points in an arbitrary causal order structure.

Beyond quantum theory. All interpretations of quantum theory deﬁne in fact new physical
theories, which coincide in some regimes — typically, those that are experimentally accessible. For
example, in most interpretations, agents expect their measurement statistics to follow the Born rule,
and model the evolution of small isolated systems as unitary transformations on a Hilbert space. In
most of them, they can even model other agents as quantum systems evolving in an environment; the
diﬀerences between diﬀerent versions of quantum theory arise when agents consider what happens
globally when they perform measurements, the dynamics at very large scales, what hidden variables
the theory follows or even how it behaves in relativistic regimes. Our software package can handle
these diﬀerences; but what happens for completely diﬀerent theories, without the common quantum
basis? If we would like to simulate agents in Generalized Probabilistic Theories [16], for example,
we need ﬁrst a model for dynamics in the target theory, so that we could implement an analog
of the circuit version of each agent’s brain, according to the principles of that theory. For this, a
quantum programming language like ProjectQ may not be the most appropriate, although most of
the modular structure of Quanundrum and main components could be easily adapted.

Acknowledgements

We thank M. Iazzi and several anonymous conference referees for useful feedback. We acknowledge
support from the Swiss National Science Foundation through SNSF project No. 200021_188541
and through the the National Centre of Competence in Research Quantum Science and Technology
(QSIT). LdR further acknowledges support from the FQXi grant Consciousness in the Physical

17

World. LdR is grateful for the hospitality of Perimeter Institute where part of this work was carried
out. Research at Perimeter Institute is supported in part by the Government of Canada through
the Department of Innovation, Science and Economic Development and by the Province of Ontario
through the Ministry of Colleges and Universities.

Author contributions

This project started as an extra-curricular project of SM, back then a master student, proposed
and supervised by the remaining authors. All authors contributed equally for the ideas in the paper
and software. The software was designed by SM with input from the remaining authors, and later
revised by NN. All Jupyter notebooks and ﬁgures were produced by NN. NN and LdR wrote this
manuscript. LdR would like a cookie for drawing the circuits, but will settle for a more compliant
alternative to QCircuit.

18

Appendix

A Examples of simple protocols

Here we review examples of simple thought experiments where the reasoning of agents can be
modelled by small quantum simulations. These simple examples can be used as canaries: if a model
(with a physical theory, interpretation and set of logic rules) leads to contradictory conclusions by
agents, this suggests that the model has limited predictive power and is not widely applicable. Links
to pedagogical Jupyter notebooks are provided.

(a) Alice and Bob measure a Bell state. Alice
and Bob each have access to a half of a Bell state,
and measure their own qubit in the computational
basis. Alice should guess Bob’s outcome.

(b) Alice and Bob measure the same qubit.
Alice and Bob share a qubit in state |+i. Alice
measures it, and then tries to predict the outcome
of Bob’s subsequent measurement.

(c) Bob measures Alice. Alice measures a qubit
(in state |+i), and then tries to predict the outcome
of Bob’s future measurement. Bob reverses Alice’s
memory update and measures her memory.

Figure 7: Simplest test protocols. Here two agents measure a shared state and reason about each other’s
outcomes; there are no measurements of each other’s memories involved. These “tutorial” examples act as
simple tests of whether an interpretation was implemented correctly in Quanundrum and makes the expected
predictions in familiar settings.

A.1 Alice and Bob measure a Bell state [Jupyter notebook]

Setting. Alice and Bob share a Bell pair (|00iRS + |11iRS)/
proceeds as follows:

√

2 (Figure 7a). The experiment

19

a

•

Reasoning

|ψiSR





R

S

•

Alice’s meas. |0iA

[a = 0 ⇒ b = 0]

|0i

[a = 0 ⇒ b = 1]

|0i

[a = 1 ⇒ b = 0]

|0i

[a = 1 ⇒ b = 1]

|0i

Prediction b = 0 |0i

Prediction b = 1 |0i

Bob’s meas. |0iB

Figure 8: Alice and Bob measure a Bell state: Alice’s prediction-making. Alice and Bob have access
to qubits R and S respectively, which are initially prepared in Bell state |ψiSR = 1√
(|00iSR + |11iSR). Alice
2
measures qubit R, obtaining a classical outcome, which she writes down to her (classical) memory. For both
of her outcome options (a = 0 and a = 1) she runs the circuit. Neither the inference nor the prediction qubits
are initialized at that point. After Bob’s measurement of the system S, and looking up his measurement
outcome, she is able to see if there is any logical correlation of his outcome with her own result.

t = 1 Alice measures her qubit R in basis {|0iR, |1iR}, and records the result in her memory A.

t = 2 Alice makes a prediction about Bob’s outcome.

t = 3 Bob measures his qubit S in basis {|0iS, |1iS}, and records the result in his memory B.

Expected result.
that their outcomes are perfectly correlated.

In most interpretations of quantum theory we expect Alice to correctly guess

Running the protocol. After deﬁning the steps of agents as described above, we need to initialize
Alice’s predictions about Bob’s state. From Alice’s point of view, she runs the protocol with her
own outcomes being classical, and the inference and prediction qubits not initialized. Her circuit of
reasoning is pictured on Figure 8.

Forward reasoning. Using her knowledge of quantum theory, Alice can run a simulation of the
whole experiment (before step t1), and update her instruction registers to reﬂect the following: “if
my measurement outcome is 0, I should predict that Bob will obtain 0; if my measurement outcome
is 1, I should predict that Bob will obtain 1.” This can be economically encoded by initializing her
prediction qubit to |0i (the default prediction), setting her ﬁrst instruction qubit to |0i (“if I see 0,

20

I should not change my prediction”) and her second instruction qubit to |1i (“if I see 1, transform
the prediction”). When the experiment actually runs, one can simulate Alice’s reasoning by running
her circuit between steps t1 and t2, obtain her prediction, and correlate it with Bob’s outcome at
step t3. The protocol is run until Alice’s measurement, and each outcome is analyzed separately
by projecting the state into the subspace corresponding to Alice getting the said outcome. For
example, here the analysis would be carried out in the following way.

• Case a = 0:

1. RS is initialized in the Bell state 1√
2

result down to her memory,

|00iRS + 1√
2

|11iRS; Alice measures R and writes the

1
√
2

|00iRS|0iA +

1
√
2

|11iRS|1iA

2. The state is projected onto the subspace of Alice’s memory corresponding to a = 0,

|00iRS|0iA. 8

3. Bob measures the state

4. Now Alice can conclude that if she gets a = 0, Bob obtains b = 0.

|00iRS|0iA|0iB.

• Case a = 1:

1. RS is initialized in the Bell state 1√
2

result down to her memory,

|00iRS + 1√
2

|11iRS; Alice measures R and writes the

1
√
2

|00iRS|0iA +

1
√
2

|11iRS|1iA

2. The state is projected onto the subspace of Alice’s memory corresponding to a = 1,

|11iRS|1iA.

3. Bob measures the state, and writes the result down to his memory,

4. Now Alice can conclude that if she gets a = 1, Bob obtains b = 1.

|11iRS|1iA|1iB.

A.2 Alice and Bob make sequential measurements [Jupyter notebook]

This is an almost trivial experiment that is used as a quick test for new interpretations and logical
axioms.

8Any prediction qubits associated with Alice’s inference for a = 0 will also be captured in this subspace; here
we don’t add them explicitly to make the explanation simpler. For the full state, see the inference making function
output in the jupyter notebooks.

21

Setting. Alice and Bob have access to the same qubit R , initially in state |+iR (Figure 7b). The
experiment proceeds as follows:

t = 1 Alice measures system R in basis {|0iR, |1iR}, and records the result in her memory A.

t = 2 Bob measures system R in basis {|0iR, |1iR}, and records the result in his memory B.

t = 3 Alice and Bob reason about each other’s outcomes.

Expected result. According to most standard quantum interpretations, we should expect their
results to be the same, and them to be able to correctly guess each other’s outcome; this is also our
experience in the lab.

A.3 Bob measures Alice [Jupyter notebook]

Setting. Alice has access to a qubit R, and Bob has access to Alice’s memory (Figure 7c). The
initial state of R is 1√
(|0iR + |1iR). The experiment proceeds as follows:
2

t = 1 Alice measures system R in basis {|0iR, |1iR}, and records the result in her memory qubit A.

t = 2 Alice makes a prediction about Bob’s outcome at t = 4.

t = 3 Bob applies a CNOT gate on Alice’s lab, which is controlled on the state of the qubit R.

t = 4 Bob measures Alice’s memory A.

Expected result. According to the neo-Copenhagen interpretation, Alice’s prediction about
Bob’s outcome will be that he gets 0, as Alice’s memory qubit A starts out in the state |0iA.
According to the collapse interpretation, Alice cannot make a deterministic prediction about Bob’s
outcome at a later step; however, Bob’s measurement result corresponds to her state |0iA.

B Application: the Frauchiger-Renner thought experiment

We will now see an application of all the machinery described in the previous sections, by simulating
the Frauchiger-Renner thought experiment. Jupyter notebooks are available for the implementation
with the neo-Copenhagen interpretation and a collapse interpretation, and we recommend following
them. We will ﬁrst go through the interpretation with the neo-Copenhagen interpretation, and later
comment on the collapse version.

Global setting. The full thought experiment involves four agents, Alice, Bob, Ursula and Wigner,
and two qubits R and S (Figure 9). We start from the example we have followed in the main text
(with Alice, Bob, R and S), and introduce one new agent at the time. For full generality, we assume
that every agent may be modelled as a quantum reasoning agent of ni qubits (an outcome register
i, inference qubits Ii and prediction registers Pi), and a unitary reasoning circuit Ui. We assume
that the reasoning process of all agents is common knowledge (all agents know {Ui}i for all other
agents).

22

Figure 9: FR thought experiment [3]. The setting involves four agents: Alice, Bob, Ursula and Wigner,
and two qubit systems R and S. Alice measures system R and prepares system S based on her outcome.
The system S is then measured by Bob. Ursula and Wigner measure Alice’s and Bob’s labs respectively.
The agents are allowed to make predictions with certainty about each other’s outcomes.

B.1 Introducing Ursula: a meta agent who measures Alice

Ursula is an agent who stands outside of Alice’s lab and has (hypothetically) full quantum control
over all systems in that lab, including Alice’s memory.

Experimental setting. To the previous experiment, we add two more steps:

t = 2.9 Ursula reverses Alice’s unitary reasoning circuit (if present).

t = 3 Ursula measures part of Alice’s lab: qubit R and Alice’s output qubit register A. She measures

them in the Bell basis. For future convenience, we name two states of this basis9 as

|okiRA =

|failiRA =

r 1
2
r 1
2

(|0iR|0iA − |1iR|1iA)

(|0iR|0iA + |1iR|1iA).

t = 3.5 Ursula tries to guess what Bob’s guess was at time t = 2.5.

Ursula’s ﬁrst simulation. From Ursula’s perspective, the circuit representation of the experi-
ment up to her measurement is given in Figure 10. In addition, Ursula has her own reasoning circuit,
similar to Bob’s. In order to make accurate predictions, she will have to run several simulations. As
a ﬁrst step, she needs to initialize Bob’s inference qubits |xBiIB
: for this she puts herself in Bob’s
place, and runs the restricted simulation described in the previous section (Figure 6, with just Alice
, like we saw before. Note that even if we
and Bob). After this, she knows that |xBiIB = |0001iIB

9The other two basis states can be given any name — they don’t have overlap with the state of the experiment

and have probability zero.

23

Alice’s actions

Ursula’s actions

•

H

Qubit R:

q 1

3 |0iR +

q 2

3 |1iR

•

Alice’s outcome: |0iA

Alice’s brain: |xAiIA|0iPA

Qubit S: |0iS

Bob’s outcome: |0iB

Bob’s inference: |xBiIB

Bob’s prediction: a = 0 |0iP 0

B

Bob’s prediction: a = 1 |0iP 1

B

UAlice

U −1

Alice

= u

Bell

Bob’s actions

•

UBob

Figure 10: Global circuit, from Ursula’s perspective, up to Ursula’s measurement. Alice and Bob’s
brains are simulated by nA and nB qubits respectively, including inference and prediction registers. Ursula’s
task is to guess the content of Bob’s two prediction register, given the outcome u of her own measurement.
Note that Alice’s potential reasoning and predictions implemented through Alice’s reasoning circuit UAlice,
are reversed by Ursula. Bob’s reasoning circuit UBob is the one from Figure 4. Ursula’s measurement is in
the Bell basis.

have an explicit circuit for Alice’s reasoning, it should not aﬀect the outcomes of this simulation,
because it is reversed by U −1
. Next Ursula must relate the outcomes of her own measurement to
Alice
Bob’s predictions about Alice’s outcomes. We have two options to achieve this, which can be easily
implemented (Figure 11).

First option: large, direct quantum simulation. Ursula can run a simulation of the whole
experiment up to now, with Bob’s inference qubits initialized, and then measure the simulated Bob’s
prediction registers directly (Figure 11a). She compares the outcome u of her Bell measurement on
Alice’s lab to the outcomes p0
of Bob’s prediction registers. In this case, she’ll obtain the
B
result that whenever u =ok, then p0
B = 1; that is, Ursula concludes that when she measures
outcome “ok”, Bob will have predicted that a = 1.

and p1
B
B = 0, p1

Second option: shorter simulation of Bob’s memory. Alternatively Ursula can run a shorter
simulation to infer directly Bob’s measurement outcome b (Figure 11b). This is essentially a four-
qubit simulation, without modelling the inner circuits of Alice’s or Bob’s brains, so this method
is computationally much more economical for Ursula. From it, she learns the inference u =ok
=⇒ b = 1. The reader can see this directly from the joint state of qubits RASB after Alice’s
reasoning is undone,

|ψ(t = 3)iRASB =

=

1
√
3
r 2
3

(|00iRA|00iSB + |11iRA|00iSB + |11iRA|11iSB)

|failiRA|00iSB +

r 1
6

(|failiRA + |okiRA) |11iSB.

24

q 1

q 2

Qubit R:

3 |1iR
3 |0iR +
Alice’s outcome: |0iA

Alice’s brain: |xAiIA|0iPA

Qubit S: |0iS

Bob’s outcome: |0iB

Bob’s inference: |0001iIB

Bob’s pred. a = 0 |0iP 0

B

Bob’s pred. a = 1 |0iP 1

B

•

•

H

UAlice

1Alice

U −1

Alice

Bell

= u

•

UBob

p0
B

p1
B

(a) Simulating Bob’s quantum brain. Ursula reasons about Bob’s prediction (of Alice’s outcome) by including
Bob’s brain in her simulation, and measuring Bob’s prediction registers. From the correlations between outcomes
u, p0
B = 1 is valid: if Ursula obtains outcome “ok”, she knows

B, she ﬁnds that the inference u = ok =⇒ p1

B and p1

that Bob will have predicted a = 1.

q 1

q 2

Qubit R:

3 |1iR
3 |0iR +
Alice’s outcome: |0iA

Alice’s brain: |xAiIA|0iPA

Qubit S: |0iS

Bob’s outcome: |0iB

•

•

H

UAlice

1Alice

U −1

Alice

Bell

= u

•

b

(b) Shorter simulation, classical logic. Ursula only simulates Bob’s lab up to his measurement, and then
measures his simulated outcome registry directly to obtain the value of b. Through theoretical or statistical
analysis, Ursula concludes that u =ok =⇒ b = 1. Combining this classical inference with the previous inference
b = 1 =⇒ a = 1, Ursula obtains u =ok =⇒ a = 1.

Figure 11: Ursula’s restricted simulation. Ursula has two options to calculate the truth value of infer-
ences {u ⇒ a}a,b about Alice’s past outcome based on her own observations. Note that Ursula can safely
ignore Alice’s reasoning: her brain’s circuit UAlice is reversed by Ursula in the actual experiment (so Ursula
does not need to simulate it), and the initial state |xAiIA of Alice’s inference registers is irrelevant for either
simulation’s statistics.

Here the only outcome in B that has non-zero overlap with u =ok is b = 1. The price to pay for
this cheaper simulation is heavier reliance on classical logic axioms: Ursula must classically combine
u =ok =⇒ b = 1 with the previous inference b = 1 =⇒ a = 1 by using the knowledge distribution
axiom, to obtain u =ok =⇒ a = 1.10

In the software, the user can choose which version to run by specifying in the
The ﬁne print.
protocol the target registers of Ursula’s reasoning at time t = 3.5. In the ﬁrst case, Ursula reasons
, and in the shorter simulation she reasons about B. Formally, in the ﬁrst
about qubits P 0
B

and P 1
B

10Note that this diverges slightly from Ursula’s deduction in the original FR paper, where she waits until the end

to compute a prediction for Wigner’s outcome w directly.

25

Alice’s actions

Ursula’s actions

R:

q 1

3 |0iR +

q 2

3 |1iR

•

A’s outcome: |0iA

A’s brain: |xAiIA|0iPA

S: |0iS

B’s outcome: |0iB

B’s brain: |xBiIB |0iPB

•

H

UAlice

U −1

Alice

Bob’s actions
•

Bell

= u

Wigner’s actions

Bell

= w

UBob

U −1
Bob

Figure 12: Circuit of the full experiment, from Ursula and Wigner’s perspective. After Ursula’s
measurement, Wigner reverses Bob’s reasoning and measures his lab, obtaining outcome w. If u = w = ok
(which happens with probability 1/12), they reason about Alice’s past prediction of Wigner’s outcome.

simulation, the epistemic statement that Ursula reaches is KU ([u = ok] =⇒ KB[a = 1]). Through
the second option, she reaches KU ([u = ok] =⇒ [b = 1]) and KU (KB[b = 1 =⇒ a = 1]). Whether
she is allowed to combine those statements depends on the logical axioms and trust structures
applied by the user.

B.2 Introducing Wigner: a meta agent who measures Bob’s lab

Analogously to Ursula, Wigner is an agent who stands outside of Bob’s lab and has full quantum
control over all systems in that lab, including Bob’s memory.

Experimental setting. We add a few more steps to the protocol (Figure 12). Note that one of
the new steps speciﬁes Alice’s reasoning early in the experiment:

t = 3.9 Wigner reverses Bob’s unitary reasoning circuit (if present).

t = 4 Wigner measures part of Bob’s lab: qubit S and Bob’s output qubit register B. He measures

them in the Bell basis. Let us again name two states of this basis as

|okiSB =

|failiSB =

r 1
2
r 1
2

(|0iS|0iB − |1iS|1iB)

(|0iS|0iB + |1iS|1iB).

t = 1.6 Alice tries to guess the outcome w of Wigner’s measurement at t = 4.11

t = 5 Ursula and Wigner compare the outcomes of their measurements. If they were both “ok”, they
halt the experiment and try to guess Alice’s prediction at t = 1.5. Otherwise, they reset the
timer and all systems to the initial conditions, and repeat the experiment.

11The exact time stamp does not matter, only the relative order of operations.

26

q 1

3 |0iR +

q 2

3 |1iR

•

Alice’s outcome: |0iA

|ψai

Qubit S: |0iS

project on a

•

H

•

Bob’s outcome: |0iB

Bob’s brain: |xBiIB |0iPB

= w

Bell

UBob

1Bob

U −1
Bob

Figure 13: Alice’s restricted simulation.
In order to determine the validity of the various possible
inferences a =⇒ w, Alice runs a restricted simulation of the experiment. She simulates a measurement on
her memory and proceeds with independent simulations with the post-measurement states corresponding to
each of her outcomes. Alice could alternatively run a larger simulation including the reasoning circuits in
her own brain and Ursula’s undoing of those; this would lead to the same conclusion, a = 1 =⇒ w =fail.

Alice’s simulation. Alice will have to make a prediction about whether Wigner obtains w = ok
or w = fail, based on her observed outcome a ∈ {0, 1}. This means that other agents will model her
brain including two prediction qubits P ok and P fail, and four inference qubits {I a,w}a,w, initially
storing the truth values for the diﬀerent possibilities {a ⇒ w}a,w. Her reasoning circuit is identical
to Bob’s (one outcome qubit, four inference and two predictions, with the four doubly-controlled
gates). To initialize her inference qubits, Alice runs a restricted version of the experiment, and
similarly to the previous case, she has a few options for what to include in her simulation (for
example whether to include her own brain and Ursula’s measurement). Since in the simulation
Alice projects on the post-measurement state for each of her outcomes a, these options lead to the
same results; we present the simplest version in Figure 13. After running this simulation, Alice
concludes that a = 1 ⇒ w = fail, because for a = 1 she projects RA to |1iR|1iA, which leads to the
global evolution

|1iR |1iA |0iS |0iB |xBiIB |0iPB

CHAS −→|1iR |1iA |+iS |0iB |xBiIB |0iPB

CNOTSB −→|1iR |1iA

U −1

Bob UBob −→|1iR |1iA

|0iS|0iB + |1iS|1iB
√
2
|0iS|0iB + |1iS|1iB
√
2
{z
|failiSB

|

}

|xBiIB |0iPB

|xBiIB |0iPB .

All the other possible inferences are false. Therefore we conclude that her inference qubits start in
, with the last qubit corresponding to |1iI 1,fail. Note that other agents can
state |xAiIA = |0001iIA
put themselves in Alice’s shoes and run the same simulation.

Wigner and Ursula’s simulations. Now Wigner and Ursula have several options for the simu-
lations they run in order to conclude that if they observe u = w = ok then Alice will have predicted
w = fail with certainty. The computationally lighter option is to classically combine all the infer-
ences u = ok ⇒ b = 1, b = 1 ⇒ a = 1 and a = 1 ⇒ u = fail; they can do this if the user-speciﬁed
logical axioms allow for knowledge distribution among agents. An alternative that is computation-
ally heavier but does not rely so much on classical logic is to run larger simulations. The software

27

runs the following procedure automatically (we just need to specify which qubits agents are reason-
ing about). The circuit diagrams for every individual the simulation are quite large and repetitive,
so we are not drawing them, but here is a compressed description:

1. They simulate Alice’s reasoning (as per Figure 13), to ﬁnd the inference a = 1 ⇒ w = fail

initial states for her inference registers, |xAiIA = |0001iIA

.

2. Then they simulate Bob’s reasoning about Alice’s reasoning. That is, we think that Bob
wants to guess not Alice’s outcome a but the content of her two prediction registers PA. For
economical reasons, we can just focus on Bob’s thoughts about the one prediction qubit that
is relevant for the logical contradiction, P fail
In this case, Bob’s prediction qubits will
.12
be P Bob cannot guarantee that Alice predicted fail and P Bob knows that Alice predicted fail with certainty. To
follow Bob’s reasoning, they must simulate Bob simulating Alice, so that they can initialize
Bob’s inference registers. This is done through an expanded version of the circuit of Figure 6,
now including Alice’s brain explicitly. Instead of measuring Alice’s outcome registers, simu-
lated Bob measures her prediction registers (analogously to Figure 11a). One deterministic
conclusion of this simulation is b = 1 ⇒ pfail
A = 1, that is: when Bob observes b = 1 he knows
that Alice will have concluded that Wigner would obtain outcome w = fail. Now Ursula
and Wigner can initialize Bob’s inference qubits, in particular the qubit that encodes this
inference, |1ib=1⇒Bob knows that Alice predicted fail with certainty

A

.

I

3. Next they need to ﬁnd out Bob’s prediction given Ursula’s outcome u: Ursula runs a simulation
similar to Figure 11a; the diﬀerence is that now she measures Bob’s prediction registers that
store his conclusions about Alice’s prediction (not her outcome a). The conclusion is that
u = 1 ⇒ Bob knows that Alice predicted fail with certainty. Now Ursula can initialize her
own inference qubits with what she learned about Bob’s knowledge of Alice’s prediction,
including the critical |1iu=1⇒Ursula knows that Bob knows that Alice predicted fail with certainty

.

I

4. Finally we can run the whole experiment, with Alice, Bob and Ursula’s brains initialized.
We don’t need to model Wigner’s brain explicitly, just his outcome register W . At the
end we measure the registers storing w, u and Ursula’s predictions. We ﬁnd that whenever
u = w = ok, Ursula’s memory stores the chain of reasoning leading to Alice’s prediction that
w = fail.

12To reason about Alice’s two prediction qubits, we’d need to double Bob’s brain size (four prediction qubits
ok, P 1
fail} and eight possible inferences), which the software does automatically, but might get out of hand

{P 0
for practical simulations. Alternatively we can ﬁnd a compressed version by changing Bob’s inner circuitry.

fail, P 1

ok, P 0

28

References

[1] Nuriya Nurgalieva, Simon Mathis, Lídia del Rio, and Renato Renner. Quanundrum software

package, 10 2021. URL https://github.com/jangnur/QThought.

[2] Damian S. Steiger, Thomas Häner, and Matthias Troyer. ProjectQ: an open source software
framework for quantum computing. Quantum, 2(49):10–22331, 2018. DOI: 10.22331/q-2018-
01-31-49.

[3] Daniela Frauchiger and Renato Renner. Quantum theory cannot consistently describe the use
of itself. Nature Communications, 9(1):3711, 2018. ISSN 2041-1723. DOI: 10.1038/s41467-018-
05739-8.

[4] J. C. Maxwell. Theory of Heat. Longmans, Green and Co., 1871. ISBN 9781139057943.
[5] Rolf Landauer. Irreversibility and heat generation in the computing process. IBM journal of

research and development, 5(3):183–191, 1961. DOI: 10.1147/rd.53.0183.

[6] A. Einstein. Die Grundlage der allgemeinen Relativitätstheorie. Annalen der Physik, 354(7):

769–822, 1916. DOI: 10.1002/andp.19163540702.

[7] Erwin Schrödinger. An Undulatory Theory of the Mechanics of Atoms and Molecules. Physical

Review, 28(6):1049–1070, dec 1926. DOI: 10.1103/physrev.28.1049.

[8] Eugene P. Wigner. Remarks on the mind-body question. In I. J. Good, editor, The Scientist

Speculates. Heineman, 1961. DOI: 10.1007/978-3-642-78374-6_20.

[9] Lucien Hardy. Nonlocality for two particles without inequalities for almost all entangled states.

Phys. Rev. Lett., 71:1665–1668, Sep 1993. DOI: 10.1103/PhysRevLett.71.1665.

[10] Časlav Brukner. A no-go theorem for observer-independent facts. Entropy, 20(5):350, 2018.

DOI: 10.3390/e20050350.

[11] Simon Kochen and E.P. Specker. Logical structures arising in quantum theory.

in Addison,
J., L. Henkin, and A. Tarski (eds.), The theory of models, North-Holland, Amsterdam, pages
177–189, 1967. DOI: 10.2307/2274252.

[12] Saul A. Kripke.

Acta Philosophica Fen-
nica, 16:83–94, 1963. URL http://saulkripkecenter.org/wp-content/uploads/2019/03/
Semantical-Considerations-on-Modal-Logic-PUBLIC.pdf.

Semantical considerations on modal

logic.

[13] Nuriya Nurgalieva and Lídia del Rio. Inadequacy of modal logic in quantum settings. EPCTS,

287:267–297, 2019. DOI: 10.4204/EPTCS.287.16.

[14] Scott Aaronson.

It’s hard to think when someone Hadamards your brain. https://www.

scottaaronson.com/blog/?p=3975, September 2018.

[15] Julie Sedivy. Three logicians walk into a bar, 2011. URL https://languagelog.ldc.upenn.

edu/nll/?p=3451.

[16] V. Vilasini, Nuriya Nurgalieva, and Lidia del Rio. Multi-agent paradoxes beyond quantum

theory. 2019. DOI: 10.1088/1367-2630/ab4fc4.

[17] John von Neumann. Mathematical foundations of quantum mechanics. Princeton university

press, 1955. ISBN 978069117856. DOI: 10.1515/9781400889921.

[18] Nuriya Nurgalieva and Renato Renner. Testing quantum theory with thought experiments.
Contemporary Physics, 61(3):193–216, July 2020. DOI: 10.1080/00107514.2021.1880075.
[19] David Bohm. A Suggested Interpretation of the Quantum Theory in Terms of "Hidden"

Variables. I. Physical Review, 85(2):166–179, jan 1952. DOI: 10.1103/physrev.85.166.

[20] Christopher A. Fuchs, N. David Mermin, and Rüdiger Schack. An introduction to QBism with
an application to the locality of quantum mechanics. American Journal of Physics, 82(8):
749–754, aug 2014. DOI: 10.1119/1.4874855.

29

[21] Carlo Rovelli. Relational quantum mechanics. International Journal of Theoretical Physics, 35

(8):1637–1678, 1996. DOI: 10.1007/BF02302261.

[22] Carlo Rovelli. Half way through the woods. The cosmos of science, pages 180–223, 1997.
[23] Lev Vaidman. Probability and the Many-Worlds Interpretation of Quantum Theory. 2001.

DOI: 10.48550/arXiv.quant-ph/0111072.

[24] Niels Bohr. Atomic theory and the description of nature. Cambridge University Press, Cam-

bridge, 1934. ISBN 978-1107628052. DOI: 10.1119/1.1942160.

[25] Niels Bohr. On atoms and human knowledge. Daedalus, 87(2):164–175, 1958. URL https:

//www.jstor.org/stable/i20026434.

[26] Werner Heisenberg. The Representation of Nature in Contemporary Physics. 87(3):95–108,
Summer 1958. ISSN 0011-5266 (print), 1548-6192 (electronic). DOI: 10.2307/20026454.

[27] Harald Atmanspacher.
ity. World Futures:
10.1080/02604027.1997.9972639.

Cartesian cut, Heisenberg cut, and the concept of complex-
DOI:
Journal of General Evolution, 49(3-4):333–355, 1997.

[28] Časlav Brukner. On the quantum measurement problem. In Quantum [Un]Speakables II, pages
95–117. Springer International Publishing, November 2016. DOI: 10.1007/978-3-319-38987-
5_5.

[29] G.C. Ghirardi, A. Rimini, and T. Weber. A model for a uniﬁed quantum description of macro-
scopic and microscopic systems. In Quantum Probability and Applications II, pages 223–232.
Springer, 1985. DOI: 10.1007/BFb0074474.

[30] Marco Bilardello, Sandro Donadi, Andrea Vinante, and Angelo Bassi. Bounds on collapse
models from cold-atom experiments. Physica A: Statistical Mechanics and its Applications,
462:764–782, November 2016. DOI: 10.1016/j.physa.2016.06.134.

[31] M. Bilardello, A. Trombettoni, and A. Bassi. Collapse in ultracold bose josephson junctions.

Physical Review A, 95(3), March 2017. DOI: 10.1103/physreva.95.032134.

[32] Matteo Carlesso, Mauro Paternostro, Hendrik Ulbricht, Andrea Vinante, and Angelo Bassi.
Non-interferometric test of the continuous spontaneous localization model based on rotational
optomechanics. New Journal of Physics, 20(8):083022, August 2018. DOI: 10.1088/1367-
2630/aad863.

[33] Marko Toroš and Angelo Bassi. Bounds on quantum collapse models from matter-wave inter-
ferometry: calculational details. Journal of Physics A: Mathematical and Theoretical, 51(11):
115302, February 2018. DOI: 10.1088/1751-8121/aaabc6.

[34] Ronald Fagin, Joseph Y. Halpern, Yoram Moses, and Moshe Vardi. Reasoning about knowledge.

MIT press, 2004. ISBN 9780262061629. DOI: 10.7551/mitpress/5803.001.0001.
[35] Jaakko Hintikka. Knowledge and Belief. Ithaca: Cornell University Press, 1962.
[36] David Hilbert and Wilhelm Ackermann. Principles of Mathematical Logic. AMS Chelsea

Publishing, 1999. DOI: 10.1017/S003181910003446X.

[37] Alexandru Baltag and Bryan Renne. Dynamic epistemic logic. In Edward N. Zalta, editor,
The Stanford Encyclopedia of Philosophy. Metaphysics Research Lab, Stanford University, win-
ter 2016 edition, 2016. URL https://plato.stanford.edu/archives/win2016/entries/
dynamic-epistemic/.

[38] Hans Van Ditmarsch, Wiebe van Der Hoek, and Barteld Kooi. Dynamic epistemic logic, volume

337. Springer Science & Business Media, 2007. DOI: 10.1007/978-1-4020-5839-4.

[39] Alexander Wilce. Quantum logic and probability theory.

In Edward N. Zalta, editor, The

30

Stanford Encyclopedia of Philosophy. Metaphysics Research Lab, Stanford University, spring
2017 edition, 2017. URL https://plato.stanford.edu/entries/qt-quantlog/.

[40] Alexandru Baltag and Sonja Smets. Quantum logic as a dynamic logic. Synthese, 179(2):

285–306, Mar 2011. ISSN 1573-0964. DOI: 10.1007/s11229-010-9783-6.

[41] Enrico Beltrametti, Maria Luisa Dalla Chiara, Roberto Giuntini, Roberto Leporini, and
Giuseppe Sergioli. A quantum computational semantics for epistemic logical operators. part i:
Epistemic structures. 2016. DOI: 10.48550/arXiv.1602.07514.

[42] Enrico Beltrametti, Maria Luisa Dalla Chiara, Roberto Giuntini, Roberto Leporini, and
Giuseppe Sergioli. A quantum computational semantics for epistemic logical operators. part ii:
Semantics. 2016. DOI: 10.48550/arXiv.1602.07517.

31

