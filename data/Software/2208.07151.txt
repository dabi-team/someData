2
2
0
2

g
u
A
5
1

]
P
S
.
s
s
e
e
[

1
v
1
5
1
7
0
.
8
0
2
2
:
v
i
X
r
a

Dynamic Task Software Caching-assisted

Computation Ofﬂoading for Multi-Access Edge

1

Computing

Zhixiong Chen, Student Member, IEEE, Wenqiang Yi, Member, IEEE,

Atm S. Alam, Member, IEEE, and Arumugam Nallanathan, Fellow, IEEE

Abstract

In multi-access edge computing (MEC), most existing task software caching works focus on

statically caching data at the network edge, which may hardly preserve high reusability due to the

time-varying user requests in practice. To this end, this work considers dynamic task software caching

at the MEC server to assist users’ task execution. Speciﬁcally, we formulate a joint task software caching

update (TSCU) and computation ofﬂoading (COMO) problem to minimize users’ energy consumption

while guaranteeing delay constraints, where the limited cache size and computation capability of the

MEC server, as well as the time-varying task demand of users are investigated. This problem is proved

to be non-deterministic polynomial-time hard, so we transform it into two sub-problems according to

their temporal correlations, i.e., the real-time COMO problem and the Markov decision process-based

TSCU problem. We ﬁrst model the COMO problem as a multi-user game and propose a decentralized

algorithm to address its Nash equilibrium solution. We then propose a double deep Q-network (DDQN)-

based method to solve the TSCU policy. To reduce the computation complexity and convergence time,

we provide a new design for the deep neural network (DNN) in DDQN, named state coding and action

aggregation (SCAA). In SCAA-DNN, we introduce a dropout mechanism in the input layer to code

users’ activity states. Additionally, at the output layer, we devise a two-layer architecture to dynamically

aggregate caching actions, which is able to solve the huge state-action space problem. Simulation results

show that the proposed solution outperforms existing schemes, saving over 12% energy, and converges

with fewer training episodes.

Index Terms

Computation ofﬂoading, deep reinforcement learning, game theory, multi-access edge computing,

software caching

Zhixiong Chen, Wenqiang Yi, Atm S. Alam and Arumugam Nallanathan are with the School of Electronic Engi-
neering and Computer Science, Queen Mary University of London, London, U.K. (emails: {zhixiong.chen, w.yi, a.alam,
a.nallanathan}@qmul.ac.uk)

 
 
 
 
 
 
2

I. INTRODUCTION

With the development of wireless communications and the proliferation of smart end devices, a

large number of computation-intensive applications have emerged to bring powerful functions and

ultimate experience to users, such as augmented reality, object recognition, interactive gaming,

speech recognition, and natural language processing [1]. These applications require massive

computational resources and energy. However, the limited computing capability and battery

capacity of the mobile devices are generally difﬁcult to meet the computation requirements

while executing these applications [2]. To cope with it, multi-access edge computing (MEC)

has attracted signiﬁcant attention in industry and academia. MEC deploys cloud-computing

capabilities and storage resources within the network edge near to users, such as base stations

(BS) and access points (AP) [3]. It allows mobile users to ofﬂoad their computation tasks to the

network edge with higher computation capability.

A. Related Works

From the users’ perspective, a critical application regarding the MEC is computation ofﬂoading

(COMO) which is able to save energy and/or speed up the process of computation [4]. Emerging

research towards this direction mainly focus on the joint optimization of the resource allocation

and COMO policies. The authors in [5] developed an online binary task ofﬂoading algorithm to

reduce task execution delay in a cellular MEC system. In [6], the authors proposed a task

ofﬂoading and computing resource allocation approach by considering the heterogeneity in

the latency requirements of different tasks. The authors in [7] optimized a partial ofﬂoading

policy in a unmanned aerial vehicle-enabled MEC system to minimizing the task computing

delay of clients. [8] studied a joint partial task ofﬂoading, computation resource, and radio

resource allocation problem to maximize the task computing energy efﬁciency. In [9], the authors

investigated an energy consumption minimization problem subject to the latency requirement

by optimizing task ofﬂoading ratio, transmission power, and subcarrier & computing resource

allocation.

Computing a task requires both the user task data as the input parameters and the corresponding

code/task software that processes it. Take face recognition as an example; if a mobile phone needs

to identify whether a person is a legitimate user, it takes a photo (input parameters) and uses it

as the input data of the face recognition software. After computing, the software output whether

the person is a legitimate user, namely computing results. Existing literature on computation

3

ofﬂoading can be classiﬁed into two main scenarios: 1) The MEC server has unlimited storage

space that can store all task software for users [10], [11]. In this case, users only need to transmit

input parameters to the MEC server for task execution; and 2) The cache size of the MEC server

is limited and hence the server fails to cache all task software. Users need to upload both task

software and input parameters under this scenario [12]–[15]. Since the second scenario can be

used to characterize most applications in MEC, we consider the second scenario in this work. The

data uploading process and task execution process will generate substantial energy consumption

and delay. To improve the computing performance of MEC, caching task computing results at

the MEC server has been identiﬁed to reduce the frequency of repeated data transmission and

task computations [16]. It proactively caches some task computing results that may be reused

in future task execution [17], [18]. Although the task computing results caching technique can

reduce task execution delay and energy consumption to a certain degree, it is impractical since

the task computing results are hardly reusable. In general, computation tasks consist of input

parameters and the corresponding task software. The task software is ﬁxed and it can output

different computation results under different input parameters. To improve the reusability of

cached data, the task software caching technique was proposed to cache the task software at the

MEC server to assist the COMO.

Speciﬁcally, our previous work [14], [19], [20] integrated the task program caching mechanism

into the COMO technique and designed a model-based task program caching algorithm to

minimize the average energy consumption or latency for all time slots. The authors in [21]

investigated a single MEC server that assists a mobile user in executing a sequence of compu-

tation tasks and used the task program caching technique to reduce the computation delay and

energy consumption of the mobile user. The authors developed an MEC service pricing scheme

to coordinate with the service caching decisions and control wireless devices’ task ofﬂoading

behaviours in a cellular network to minimize task execution delay and cost [13]. The authors

in [12] provided a joint caching, computation, and communications mechanism to minimize

the weighted sum energy consumption subject to the caching and deadline constraints. In [22],

the authors investigated a joint COMO, content caching, and resource allocation problem in a

general MEC network to minimize the total execution latency of computation tasks.

4

B. Motivation and Contributions

Existing works on task computing results caching [17], [18] or task software caching-based

MEC [12]–[15], [19]–[22] statically cache data at the network edge, they prefer to cache data

that remains unchanged over a relatively long time. In fact, users’ demand for computation tasks

dynamically changes over time. The static caching policy cannot preserve the high reusability of

the cached data. Thus, it is important to design learning-based methods to predict the users’

task demand and adjust the cache memory dynamically for improving the reusable rate of

the cached data. Moreover, it is noted that most existing works in model-free learning-based

content caching design, like [23], [24], assumed that the task data size is homogeneous, while in

practice this assumption does not always hold. Thus, it is valuable to design a new task software

caching update (TSCU) and COMO algorithm which is capable of automatically adapting to

the heterogeneous size of task software and dynamically adjust the cache space in real-time

according to user requests.

Motivated by this, we consider the dynamic task software caching technique at an MEC

network. Speciﬁcally, the task software in the cache memory is updated periodically based on

the prediction of users’ task computation demand to assist users’ COMO. With the assistance of

task software caching, users can accomplish their tasks through either local computing, caching-

based COMO, or non-caching-based COMO. The main contributions of this paper are listed in

the following:

• We formulate a joint TSCU and COMO problem in a multi-channel wireless environment

to minimize the average energy consumption of mobiles users over each time slot while

satisfying the task execution delay tolerance. It is intractable to solve its optimal solution

due to the lack of user task request information and the complexity of addressing efﬁcient

wireless access coordination among multiple users for COMO. With the aid of the maximum

cardinality bin packing problem, we theoretically prove that the considered problem is non-

deterministic polynomial-time hard (NP-Hard).

• To tackle this NP-Hard problem, we ﬁrst decompose it into two distributed sub-problems,

i.e., the COMO problem at the user side and the TSCU problem at the MEC server side, and

solve them one by one. Since the COMO problem involving a combinatorial optimization

over the multi-dimensional discrete space is challenging, we reformulate it as a multi-user

COMO game, and theoretically prove the existence of the Nash equilibrium (NE) solution

5

of the COMO game. Based on detailed analysis, We then propose a decentralized algorithm

to address its NE solution with a convergence guarantee.

• For the second sub-problem, we propose a double deep Q-network (DDQN)-based method

to learning the optimal TSCU policy under unknown user task requests information. The

massive tasks with heterogeneous data size in the task library result in a high-dimension and

complex caching action space which intractable to solve. Moreover, directly using the user

request state as the deep neural network (DNN) input may improve the learning complexity.

These factors hinder the convergence of the DDQN. To cope with these challenges, we

proposed a state coding and action aggregation (SCAA) design for the DNN used in the

DDQN. Speciﬁcally, we devise a dropout mechanism in the ﬁrst two layers of the DNN to

code users’ requests instead of directly using them as input states. A two-layer architecture

as the output layer of the DNN dynamically aggregates task software caching action to

output the corresponding state-action value. This design effectively reduces the complexity

of the DDQN, leading to faster convergence than traditional DDQN algorithms.

• We conduct simulations to evaluate the performance of our proposed dynamic TSCU assisted

COMO approach. The results show that the proposed approach signiﬁcantly reduces the

users’ computation energy consumption. It outperforms the conventional caching update-

based COMO approaches. Moreover, the proposed scheme is capable to converge faster

than other reinforcement learning-based caching update approaches.

C. Organization

The remaining parts of this paper are organized as follows. In Section II, we illustrate the

system model and formulate the joint TSCU and COMO problem. In Section III, we propose

an efﬁcient scheme to solve the original problem. Section IV veriﬁes the effectiveness of the

proposed scheme by simulations. The conclusion is drawn in Section V. The code and dataset

are available at https://github.com/chfocus/DRL-MEC.

A. Network Model

II. SYSTEM MODEL

In this paper, we focus on a multi-user MEC network consisting of a BS and K users as shown

in Fig. 1(a), where the BS is equipped with an MEC server that can access the task library in

the cloud centre through an ideal backhaul link. The main notations used throughout this paper

TABLE I
NOTATION SUMMARY

6

Notation
K; F ; M Number of users; number of tasks; number

Deﬁnition

Notation
K; F ; M User set; task set; subchannel set

Deﬁnition

f L
k ; pk

B

µ(t)
k
b(t)
f
rk,t

of subchannels
User k’s CPU capability; user k’s transmit
power
Wireless transmission bandwidth

C; fC

If ; Df ;
Sf

User k’s task request in slot t
The caching state of the task f in slot t
The uplink transmission rate of user k in
slot t

αk,t
β(t)
f
Υk,t

MEC server’s cache size; MEC server’s
CPU capability
Input parameters’ size of task f ; data size
of the task f ’s software; computation load
of task f
User k’s COMO decision in slot t
Caching update decision of task f
Received interference of user k in slot t

are summarized in Table I. Let K = {1, 2, · · · , K} represents the user index set. It is assumed

that there are total F tasks in the task library, whose index set is denoted by F = {1, 2, · · · , F }.

We consider that the system operates in a sequence of T time slots with an equal length τ . The

index set of the time sequence is denoted by T = {1, 2, · · · , T }. The operation mechanism of the

system is shown in Fig. 1(b). At the beginning of each time slot, each user requests to execute

one task in the task library or does not request to execute any task. Similar to [25], [26], we

assume that each task must be accomplished before the end of the current slot, either by its local

computing or by the MEC server execution. Note that this assumption can be removed by setting

delay constraints for each user individually and letting the time slot length be long enough to

exceed the maximum delay constraint of users. Moreover, users’ tasks requiring multiple slots

to execute are usually inactive in practical system design because this can usually be satisﬁed

by modifying the time slot length. At the end of this time slot, the MEC server ﬁrst updates

its caching space, and then it caches the selected new task software to assist users’ COMO in

the next time slot. After obtaining the task software, the edge server installs the software (e.g.,

executable .EXE ﬁles), and run it based on different input parameters.

Each task f ∈ F can be described by a tuple of three parameters, i.e., hIf , Df , Sf i, where

If indicates the size of input parameters of task f , Df is the data volume of the software of

task f , and Sf denotes the computation load of task f , i.e., the necessary central processing
unit (CPU) cycles for executing task f . Let b(t)
f ∈ {0, 1} denote the caching state of task f in
time slot t, where b(t)
f = 1 represents that the software of task f is cached at the MEC server,
f = 0 otherwise. The caching state in time slot t is characterized by bt = {b(t)
b(t)
F }.
The cache size of the MEC server is denoted by C. Knowing that the cache size is limited, the

2 , · · · , b(t)

1 , b(t)

7

(a)

(b)

Fig. 1. Illustrating the studied system model: (a) shows the network structure, where one base station is equipped with an MEC
server is able to proactively cache selected task software and mobile device has three methods to execute their tasks; and (b)
offers the ﬂow chart of the operation mechanism in one time slot.

caching state in any time slot should satisfy

(1)

Xf ∈F

b(t)
f Df ≤ C, ∀t ∈ T .
1 , β(t)

2 , · · · , β(t)
The TSCU decision proﬁle in time slot t is βt = {β(t)
indicates the caching update decision for task f in the slot t, where β(t)
software of task f will be removed at the end of time slot t, β(t)
state of f will remain unchanged, and β(t)

F }. Let β(t)
f ∈ {−1, 0, 1}
f = −1 indicates that the
f = 0 denotes that the caching
f = 1 represents that the software of task f will be
added to the cache space in the slot (t + 1). Thus, the caching state of task f at the (t + 1)-th
time slot is b(t+1)

should satisfy β(t)

f . It is noted that β(t)

f because the MEC

f ≥ −b(t)

f + β(t)

= b(t)

f

f

server cannot remove uncached task software.

We denote the users’ request in time slot t as µt = {µ(t)
k ∈ F (F = {0} ∪ F ) denote the task request state of user k, where µ(t)
µ(t)
that user k requests nothing, and µ(t)
task f . We assume that µ(t)
k

K }. At time slot t, let
k = 0 represents
k = f (f ∈ F ) indicates that user k requests to execute the
(∀k ∈ K) evolves according to a ﬁrst-order (F + 1)-state Markov

2 , · · · , µ(t)

1 , µ(t)

chain [27] whose transition probability is unknown. That is to say, the users’ request in time

slot (t + 1) is only affected by the users’ request in slot t and there are (F + 1) possible options.

B. Communication Model

It is assumed that the total available bandwidth in the network is B Hz, which is equally divided

into M orthogonal wireless channels. The set of channels is denoted as M = {1, 2, · · · , M}.

8

In each time slot, each user can only use one channel to communicate with the BS. Such a

communication method is able to ensure that two users using orthogonal channels do not interfere

with each other. We use αk,t to denote the COMO decision of user k at the t-th time slot, where

αk,t = 0 indicates that user k accomplishes its task by its own computing. The αk,t = m (m ∈ M)

denotes that user k selects channel m to ofﬂoad its task to the MEC server for computing. We

denote the COMO decision of all users in time slot t as αt = {α1,t, α2,t, · · · , αK,t}. Let hk and pk

denote the channel gain and transmit power of user k, respectively. In this work, we investigate

the task ofﬂoading problem under a wireless interference model, in which code division multiple

access is deployed to enable multiple users to occupy the same spectrum resource simultaneously

for transmitting the information. Thus, the achievable uplink transmission rate of user k in slot

t is [28], [29]

rk,t =

B
M

log

1 +

(cid:18)

pkhk

,
pnhn + σ2 (cid:19)

n∈K\{k},αn,t=αk,t
P

(2)

where σ2 is the variance of complex white Gaussian channel noise. In fact, (2) characterizes the

minimal transmit rate of user k. The effective interference of user k induced by other users is less

than

n∈K\{k},αn,t=αk,t

pnhn and determined by the power control and code design [30], [31].

Due to the space limits, we investigate the computation ofﬂoading problem based the minimal

P

achievable transmit rate in (2), and do not consider the power control and code design. Note

that, our algorithms designed in the following is able to directly used in the effective channel

interference situations. Moreover, the joint channel code design, power control and computation

ofﬂoading problem to further improve the ofﬂoading performance and manage interference will

be a future direction for our work.

From (2), users may incur severe interference and low transmission rate when a large number

of users ofﬂoading theirs tasks through the same channel. As we discuss latter, this would

increase the energy consumption for users and forcing part of them to execute tasks by local

computing, and thus the number of users in the same channel would be limited.

C. Task Computing

In our model, we introduce the task software caching mechanism to assist COMO. The MEC

server proactively caches the selected task software from the task library and provides computing

service for users in the next slot. At the beginning of each time slot, users send their task requests

to the MEC server, and then the MEC server returns whether their request tasks are cached.

9

Based on this, when user k needs to execute task f , it is able to accomplish f through local

computing or caching-based task ofﬂoading if f is cached, otherwise through local computing

or non-caching-based task ofﬂoading. Similar to [25], [26], we ignore the information exchange

overhead of users acquire whether their task software is cached at the MEC server because it

is far small than the input parameters or task software uploading cost. In the following, we

elaborate these three methods:

1) Local Computing: When user k execute its requested task via the local CPU, we denote

the computing capability (i.e., CPU cycles per second) of user k (k ∈ K) as f L

k . Employing
the dynamic voltage and frequency scaling technique [2], user k can control the energy

consumption for local computing by adjusting the CPU frequency. Considering that user

k must ﬁnish the local task computing within the current time slot, the CPU frequency of

user k satisﬁes f L

k ≥ Sf /τ . Based on the realistic measurement result in [32], the energy
consumption is proportional to the square of the frequency of mobile device. Thus, the

energy consumption of user k executes task f by its own device is

EL

k,f = ζ(f L

k )2Sf ≥ ζ

S3
f
τ 2 ,

(3)

where ζ is the energy coefﬁcient of mobile devices, determined by the chip architecture.

Without loss of the generality, we set the CPU frequency as f L

k = Sf /τ , as this is the most
energy-efﬁcient CPU frequency under the deadline constraint. Consequently, The energy

consumption of user k executes task f by its own device is EL

k,f = ζ

S3
f
τ 2 .

2) Non-caching-based Task Ofﬂoading: In each time slot t, if user k ofﬂoads task f to the

MEC server for computing, and the MEC server did not cache the corresponding software

of task f , it needs to upload the input parameters and the corresponding software of task

f to the MEC server. In fact, this non-caching-based method is the pure task ofﬂoading

as illustrated in many existing works, e.g., [5]–[9]. Note that, as stated in [33], the MEC

server is also able to download the task software from the library each time the request is

made by the user k, while it only uploads the input parameters. However, the task software

acquiring process is time-consuming, especially during peak time. Thus, similar to many

existing works, e.g., [12]–[14], we do not allow the edge server to fetch remotely from

the library every time the task software is required. Let fC (fC ≫ f L

k , ∀k ∈ K) denote the

computing capability of the MEC server. The task execution delay can be expressed as
Sf
fC

If + Df
rk,t

T O
k,f,t =

+

,

(4)

10

where rk,t follows (2). The ﬁrst part in the right hand side (RHS) of Eq. (4) is the task

execution delay at the MEC server, the second part in the RHS of Eq. (4) represents the

data transmission delay. Considering that the task must be accomplished in the current time

slot, the delay should satisfy T O

k,f,t ≤ τ . The corresponding energy consumption of user k

for executing task f is

EO

k,f,t = pk

If + Df
rk,t

,

(5)

where rk,t is given in (2). Note that the energy consumption in (5) includes the transmit

energy consumption of both input parameters and the corresponding software.

3) Caching-based Task Ofﬂoading: When user k ofﬂoads the task f to the MEC server for

executing in slot t, and the MEC server already cached the software of task f , it only needs

to upload the input parameters and request the MEC server to compute the task f directly

and does not need to upload the corresponding software data. Thus, the execution delay

can be expressed as

T C
k,f,t =

Sf
fC

+

If
rk,t

.

(6)

Similar to the non-caching-based task ofﬂoading method, the execution delay of caching-

based task ofﬂoading also should satisfy T C

k,f,t ≤ τ . In addition, the corresponding energy

consumption is

EC

k,f,t = pk

If
rk,t

,

(7)

where EC

k,f,t only includes the transmit energy consumption of the input parameters. Thus,
this caching-based task ofﬂoading method has lower computational costs (both execution

delay and energy consumption) than the non-caching-based task ofﬂoading method. Con-

sequently, when user k ofﬂoads task f to the MEC server for computing and the software

of task f is already cached at the MEC server, there is no doubt that the users will select

the caching-based task ofﬂoading method for the task execution.

D. Problem Formulation

In this paper, we aim to minimize the average task execution energy consumption of all users

over each time slot under the constraint of task execution delay through jointly optimizing the

COMO decision and TSCU policy. Based on the above models and analysis, we formulate the

energy consumption of user k at the t-th time slot as

Ek,t =

Xf ∈F

1(µ(t)

k = f )

(cid:26) 1(αk,t = 0)EL

k,f + 1(αk,t ∈ M)

(1 − b(t)
(cid:16)

f )EO

k,f,t + b(t)

f EC

k,f,t

,

(8)

(cid:17) (cid:27)

where 1(·) is an indicator function, which is one if and only if the condition in the parentheses

is proper, otherwise it is zero. Eq. (8) corresponds to three cases: (i) when user k executes

11

the task f through its own device (i.e., αk,t = 0), its energy consumption is local computing
energy consumption, i.e., Ek,t = EL
and the software has not cached at the MEC server (i.e., αk,t ∈ M and b(t)
consumption is Ek,t = EO

k,f ; (ii) when user k executes the task f through COMO
f = 0), its energy
k,f,t which consists of the transmission energy consumption of input
parameters and software; (iii) when user k executes the task f through COMO and the software
has already cached at the MEC server (i.e., αk,t ∈ M and b(t)
Ek,t = EC

f = 1), its energy consumption is
k,f,t which only includes transmission energy consumption of input parameters. Note
that we assume that users will select the caching-based task ofﬂoading instead of the non-

caching-based task ofﬂoading when the corresponding task software has already been cached

at the MEC server because the caching-based task ofﬂoading method consumes lower energy.

Thus, we can formulate the problem as

P : min
αt,βt

lim
T →∞

T

t=1 Xk∈K

Ek,t

1
T X
(b(t)

s. t.

f + β(t)

f )Df ≤ C, ∀t ∈ T ,

Xf ∈F
1(αk,t ∈ M)

b(t)
f T C
(cid:16)
f + β(t)

b(t+1)
f

= b(t)

f , ∀f ∈ F , ∀t ∈ T ,

k,f,t + (1 − b(t)

f )T O

k,f,t

f ≥ −b(t)
β(t)

f , ∀f ∈ F , ∀t ∈ T ,

αk,t ∈ {0, 1, ..., M} , ∀k ∈ K, ∀t ∈ T ,

β(t)
f ∈ {−1, 0, 1} , ∀f ∈ F , ∀t ∈ T .

(9)

(9a)

≤ τ, ∀k ∈ K, ∀f ∈ F , ∀t ∈ T ,

(9b)

(cid:17)

(9c)

(9d)

(9e)

(9f)

In problem P, (9a) implies the cache size constraint of the MEC server. (9b) corresponds to

the users’ task execution delay restriction. (9c) reveals the TSCU regulations. (9d) indicates

that the MEC server cannot remove the uncached task software. (9e) represents the available

task computing methods, where αk,t = 0 indicate that user k executes its task through local

computing, and αk,t = m (m ∈ M) represents that user k ofﬂoads its task (caching-based
ofﬂoading if b(t)

f = 0) through channel m. (9f)
imposes restrictions on the TSCU decision. Problem P is intractable to directly solve since it

f = 1 and non-caching-based ofﬂoading if b(t)

involves interactive COMO and task software caching across different time slots and lacks user

request transition probabilities. We prove it is NP-hard in Lemma 1.

Lemma 1. Problem P that involves interactive COMO and TSCU across different time slots is

12

NP-hard.

Proof. See Appendix A.

III. PROPOSED COMPUTATION OFFLOADING AND TASK SOFTWARE CACHING UPDATE

ALGORITHM

Due to the intractability of the problem P, one cannot ﬁnd an effective algorithm to achieve

the optimal solution in polynomial time. In fact, the difﬁculty of solving problem P is mainly

from the interactive COMO and task software caching across different time slots, as well as the

lack of user request transition probabilities. To cope with these challenges, we decompose the

original problem into two subproblems, i.e., the COMO problem and the TSCU problem. First,

for any given task software caching state, we reformulate the COMO problem as a multi-user

COMO game and then we propose a decentralized algorithm to address its NE solution. After

that, we reformulate the TSCU problem as an Markov decision process (MDP) and use a DDQN

to learn the optimal TSCU policy.

A. Multi-user Computation Ofﬂoading Algorithm

Based on the formulation of problem P, the task ofﬂoading decision in any time slot t (i.e.,

αt) only affects the energy consumption in t, i.e., Ek,t, and does not related with other slots.

In addition, αt does not affect the task software caching decisions in any time slot. Inspired by

this, we focus on the COMO problem in a speciﬁc time slot t under any given task software

caching state bt, and design an efﬁcient algorithm to achieve the COMO decision. It is valuable

to note that this algorithm can be generalized to solve COMO decisions in any other time slot.

We decompose the task ofﬂoading problem in slot t from problem P as:

P1 : min
αt

ft (αt) =

Ek,t

Xk∈K

s. t. (9b), (9e).

(10)

Note that αt = {α1,t, α2,t, · · · , αK,t}, where αk,t (k ∈ K) has (M +1) value selections. Therefore,

the problem P1 is difﬁcult to solve because it involves a combinatorial optimization over the

multi-dimensional discrete space {0, 1, · · · , M}K. In the following, we transfer it to a potential

game and solve its NE solution.

13

Let α−k,t = {α1,t, · · · , αk−1,t, αk+1,t, · · · , αk,t} denote the task ofﬂoading decisions of all other

users except from user k. The user k is able to choose the optimal computation decision
k,t under any given α−k,t in polynomial time with complexity O(M + 1), where α∗
α∗
arg min
αk,t

k,t =
ft (αk,t, α−k,t). Therefore, we transfer the problem P1 to a multi-user cooperative strate-

gic game G = hK, {Λk,t}k∈K, ft(αt)i, in which the user set K is the game player set, Λk,t is

the strategy space of user k in time slot t which can be obtained by solving constraint (9b)

and (9e), and ft (αt) is the computing cost of user k (all users have the same computing cost).

The objective of game G is to achieve a NE solution α∗

t =

1,t, · · · , α∗
α∗

K,t

. That is to say, for

computation decision α∗

(cid:8)
t in slot t, no user has the ability to further decrease its computing cost

(cid:9)

through changing its decisions, i.e., ft(α∗

k,t, α∗

−k,t) ≤ ft(αk,t, α∗

−k,t), ∀k ∈ K, αk,t ∈ Λk,t.

For any user k (k ∈ K) in this game G, it would accomplish its task through task ofﬂoading

k,f ≥ (1 − b(t)
when its local computing cost is larger than task ofﬂoading cost, i.e., EL
S3
b(t)
f EC
f
τ 2 ≥ pk
Let Υk,t denote the interference of user k, which satisﬁes the following inequality:

k,f,t. By substituting (3), (5), and (7) into this inequation, we have ς

f )EO
If +(1−b(t)

k,f,t +
f )Df
.

rk,t

Υk,t =

pnhn ≤

Xn∈K\{k},αn,t=αk,t

pkhk
(t)
−b
f

pk τ 2M (If +Df
BζS3
f

Df )

2

− 1

− σ2.

(11)

In other words, for a given task ofﬂoading strategy αt, the user k is able to decrease the system

energy consumption when its received interference satisﬁes inequation (11). Therefore, if user k

received low interference, it decreases its computing cost through task ofﬂoading. Otherwise, it

accomplishes its task through local computing. Based on [29], the game G is a ordinal potential

game by constructing the potential function as follows.

K

1
2 X

k=1 Xn6=k

φ(αt) =

where

pkhkpnhn1(αn,t = αk,t)1(αk,t > 0) +

pkhkVk 1(αk,t = 0),

(12)

K

Xk=1

Vk =

pkhk
(t)
−b
f

pk τ 2M (If +Df
BζS3
f

2

Df )

− 1

− σ2

(13)

is the interference threshold of user k deﬁned according to (11). User k would accomplish its

task by task ofﬂoading when Υk,t ≤ Vk, otherwise by local computing. Note that the change

in the potential function (12) has the same sign (positive or negative) with the change in the

ft (αt). In Remark 1, we prove that the game G with the potential function φ(αt) is a ordinal

potential game and it has a NE solution.

Remark 1. The COMO game G with the potential function φ(αt) is a ordinal potential game

and is able to achieve a NE solution in ﬁnite number of iterations.

Proof. See Appendix B

Based on Remark 1, we develop a potential game-based multi-user COMO algorithm to address

a mutually satisfactory ofﬂoading decisions (i.e., the NE solution) for all users. The detailed steps

14

of COMO algorithm are summarized in Algorithm 1.

Algorithm 1 Multi-user Computation Ofﬂoading
1: Each user k ∈ K initialize its COMO decision αk,t = 0
2: repeat

3:

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

for Each user k ∈ K: do

Measure the interference Υk,t and calculate the transmission rate rk,t,
Compute the strategy space Λk,t by solving constraint (9b) and (9e),
Select the best ofﬂoading decision α∗

ft (αk,t, α−k,t)

k,t = arg min
αk,t∈Λk,t

if α∗

k,t 6= αk,t then
Send a request message to BS for updating its ofﬂoading decision

if Received the update message then

Update its COMO decision, i.e., αk,t = α∗
k,t

end if

end if

end for

14: until Receive an end message

15: return αt.

Through Algorithm 1, we achieve a NE solution for the COMO problem. Firstly, we initialize

the COMO decisions of all users to 0. Next, each user computes its available task ofﬂoading

decision set Λk,t based on constraints (9b) and (9e), and ﬁnds its optimal COMO decision α∗
Then, user k sends a update request message to the MEC server if α∗

k,t.
k,t 6= αk,t. When the MEC
server receives the update request messages from users, it randomly selects one user and then

sends the update permission message to this user. The user who receives the update permission

message updates its ofﬂoading decision, and the users who do not receive the update permission

message remain their ofﬂoading decisions. Finally, if the MEC server does not receive any update

request message from users, it sends the end messages to all users. When users receive the end

message, they ofﬂoad their tasks based on their ofﬂoading decisions. We analyze the convergence

behaviour of Algorithm 1 in Lemma 2.

Lemma 2. Game G can achieve a NE solution within

1
2 K 2∆2

max+K(∆maxVmax−∆minVmin)

ε∆min

iterations,

15

where ε is a positive number.

Proof. See Appendix C

B. Deep Reinforcement Learning-based Task Software Caching Update Algorithm

Up to now, we can ﬁnd a mutually satisfactory COMO decision for all users (represented

by α∗

t ) under any given MEC server’s caching state bt and user request state µt in any time
slot. In other words, we can compute the corresponding energy consumption of any caching

state bt under any given user request state µt since the COMO decision α∗
using Algorithm 1. Substitute α∗

t can be solved by
t into the original problem P, the original problem P can be

transformed to the TSCU problem as

P2 : min
βt

T

lim
T →∞

1
T X
t=1 Xk∈K
s. t. (9a), (9c), (9d), (9f).

Ek,t

b

where
Ek,t =

1(u(t)

k = f )

(cid:26) 1(α∗

k,t = 0)EL

k,f + 1(α∗

k,t ∈ M)

(1 − b(t)
(cid:16)

f )EO

k,f,t + b(t)

f EC

k,f,t

(cid:17) (cid:27)

Xf ∈F

b
Knowing that the TSCU decision βt depends on the caching state bt, it is complex to directly

solve βt. For ease of solving problem P2, we ﬁrst solve the optimal caching state bt+1 in time
slot t + 1, then obtain the caching update decision βt in slot t based on b(t)
optimal caching state problem is formulated as
1
T X
t=1 Xk∈K
b(t+1)
f Df ≤ C,

P2 : min
bt+1

f = b(t+1)

f + β(t)

lim
T →∞

. The

(16a)

Ek,t

(16)

s. t.

c

b

T

f

Xf ∈F
b(t+1)
f

∈ {0, 1} , ∀f ∈ F .

(16b)

For any time slot (t + 1), we can solve the optimal caching state bt+1 when the user request

µt+1 is given, e.g., we can solve the energy consumption of all caching state bt+1 and ﬁnd

the minimum one. However, the caching state bt+1 is given by the MEC server updates caching

space at the end of time slot t, and µt+1 is unknown at that time due to the unknown user request

transition probabilities. To tackle this challenge, we apply a DDQN to capture the features of

the users’ request model and predict the optimal task caching state of time slot (t + 1) based on

the system state of slot t. For the purpose of designing the DDQN algorithm, we reformulate

problem

P2 as an MDP and elaborate the state, action and reward in the below.

c

(14)

. (15)

16

• State: the state in time slot t is the user request state, i.e., St = µt ∈ (F + 1)K.
• Action: the action in time slot t is the caching state in slot (t+ 1), i.e., At = bt+1 ∈ {0, 1}F .
• Reward: we deﬁne the reward in time slot t as the saving value of energy consumption

in time slot (t + 1), i.e., Rt+1. The saving value of energy consumption is deﬁned as the

difference between non-caching-based computing cost and caching-based computing cost,

i.e., Rt+1 = ENC

t+1 − EC

ENC

t+1 =

Xk∈K Xf ∈F

t+1, where
1(u(t+1)
k

= f )

(cid:26) 1(αNC

k,t+1 = 0)EL

k,f + 1(αNC

k,t+1 ∈ M)EO

k,f,t+1(cid:27)

(17)

is the energy consumption when the MEC server’s caching state is empty, i.e., bt+1 = [0]F ,

EC

t+1 =

Xk∈K Xf ∈F

1(u(t+1)

k = f )

(cid:26) 1(αC

k,t+1 = 0)EL

k,f

+ 1(αC

k,t+1 ∈M)

(1−b(t+1)
f

(cid:16)

)EO

k,f,t+1+b(t+1)

f EC

k,f,t+1

(18)

(cid:17) (cid:27)

is the energy consumption when the caching state is bt+1, where αNC
decision when the caching space is empty, and αC
k,t+1 and αC

k,t+1 is the COMO
k,t+1 corresponds to the COMO decision
k,t+1 can be solved by Algorithm 1.

when the caching state is bt+1. Both αNC

The architecture of the applied DDQN is shown in Fig. 2, which includes two DNNs with

same structure: one is the main network, one is the target network. The DDQN aims to learn

the user request model and predict the optimal task software caching state in the next slot based

on the user request in the current slot. Instead of using a large Q table to list all possible states

and actions, the applied DDQN in this paper uses a DNN to avoid listing all possible states

and actions. To overcome the high-dimension and complex caching action space resulting from

massive tasks with heterogeneous data size and improve learning efﬁciency, we provide a new

design of the DNN, named state coding and action aggregation (SCAA). SCAA adopts a dropout

mechanism in the input layer to code users’ states and a two-layer architecture at the output

layer to aggregate caching actions dynamically. Fig. 3 shows the architecture of the proposed

SCAA-DNN of the DDQN. In the following part, we introduce the SCAA-DNN in detail.

In the input of the SCAA-DNN, the users’ task request is represented by the task order. For

example, µ(t)

k = f indicates that user k request to execute the f -th task in time slot t. The
conventional design [24] directly uses the state St = µt as the input variables of the DNN, the

tasks’ order number will inﬂuence the output of the DNN (i.e., the state-action value Q(St, At)).

In fact, the order number does not relate to the state-action value Q(St, At). In order to eliminate

17

Fig. 2. The DDQN training and inference process.

Fig. 3. The architecture of proposed SCAA in the DNN of
DDQN.

the inﬂuence of tasks’ order, we use Xt = {1(µ(t)
k ∈ F ) : k ∈ K} as the input of the DNN
instead of the state St. The ﬁrst layer of the DNN contains K neural cells, and the input of the
k-th cell is 1(µ(t)

k ∈ F ). Hence, for clarifying the task demands of users, we deﬁne the second
layer in the DNN contains F neural cells, in which the f -th cell corresponds to the f -th task. We

use w1 = {w1
and the second layer of the DNN, where w1

k,f : k ∈ K, f ∈ F} to denote the weights of connections between the ﬁrst layer
k,f denotes the weight of connection between the

k-th neural cell in the ﬁrst layer and the f -th neural cell in the second layer. The value of w1
k,f

is deﬁned as

w1

k,f = 


0,

w1

k,f ,

if µ(t)

k ∈ F and µ(t)
otherwise.

k

6= f,

(19)



If µ(t)
the second layers except from the µ(t)
of the k-th neural cell in the ﬁrst layer only as the input of the µ(t)
layer. If µ(t)
cells in the second layers will be remained, and µ(t)

k ∈ F , the connections between the k-th neural cell in the ﬁrst layer and neural cells in
k -th neural cell will be dropout. In other words, the output
k -th neural cell in the second
k = 0, all the connections between the k-th neural cell in the ﬁrst layer and neural
k does not affect the inputs of neural cells in

the second layer. Such a design implements the user requests state coding in actuality.

In the conventional DDQN [34], the number of neural cells in the output layer of the DNN

is equal to the number of all possible actions, in which each neural cell corresponds to one

action and output the corresponding state-action value, i.e., Q(St, At). However, for the caching

problem

P2, it is impractical due to the heterogeneous data size of task software and the large

number of tasks. The large number of tasks will produce a large number of possible caching

c

actions. Besides, it is difﬁcult to list all the possible actions due to the heterogeneous size of

task software. For example, we assume that the MEC server can cache 10 task software with the

18

same data size, and the task library has 50 tasks. The MEC server will have C 10

50 = 1.0272 ×1010
possible actions. If the data sizes of these tasks’ software are different, it is more complex to

combine all available caching actions. To tackle this challenge, we use a two-layer architecture

(TLA) as the output layer of the SCAA-DNN, shown in Fig. 3. The ﬁrst layer in the TLA contains

F neural cells, in which the f -th neural cell corresponds to task f . Let O = (O1, O2, · · · , OF )

denote the output of the ﬁrst layer of the TLA. Intuitively, Of represents the part of state-action

value of caching the task f -th software. The last layer of the TLA just has one neural cell which

does not have the activation unit and outputs the weighted sum of all input variables. We use

wL = (w1,L, · · · , wf,L, · · · , wF,L) to denote the weights of connections between the ﬁrst layer

and the last layer in the TLA, where wf,L is the weight of the connection between the f -th cell

in the ﬁrst layer and the last layer in the TLA. To identify the state-action value of a speciﬁc
action At = bt+1, we assign the value of At to wL, i.e., wf,L = b(t+1)
will output the predicted state-action value, i.e., Q(St, At) =

, ∀f ∈ F . Then, the DNN

f ∈F b(t+1)

f Of .

f

Remark 2. In practical caching scenarios, the large number of tasks in the library may produce a

P

high-dimension action space and complex network structure in the DDQN because the caching

action is a combination of caching some task software. It may result in many neural cells in the

output layer of the DNN used in the DDQN, hindering the convergence of the DDQN. Using

the proposed TLA, the complexity of the used neural network in the DDQN is signiﬁcantly

reduced, thus improving the convergence speed of the DDQN. Note that such a design also can

be used in other scenarios with high-dimension combined-action space.

About the training phase, the MEC server caches task software based on the ε-greedy policy

[35] at the end of time slot t, where the MEC server randomly cached task software with

probability ε or caches task software based on A∗

t = arg maxa Q(St, a) with probability (1 − ǫ).
At the beginning of slot (t+1), the users will generate task computing requests µt+1 and ﬁnd the

COMO decisions α∗

µt+1. Then, the users accomplish their tasks based on α∗
i.e., EC
empty (i.e., bt+1 = 0) and obtain the corresponding energy consumption, i.e., ENC
request state St in time slot t, the action At, the reward Rt+1 = ENC

t+1 through Algorithm 1 based on the caching state bt+1 and user request
t+1 and result in energy consumption,
t+1. To estimate the reward of the caching action At = bt+1, we set the caching state as
t+1. The user
t+1, and the state
St+1 in the next time slot will be stored in the experience memory and used as the training data

t+1 − EC

for the DDQN. Then, the DDQN samples a batch of data from the experience memory as the

19

training data, each data is in the form of hSt, At, Rt+1, St+1i.

Firstly, the DDQN assigns At to wL of the evaluation DNN, i.e., wf,L = b(t+1)

f

, ∀f ∈ F .

Then, the DDQN assigns values to the weights between the ﬁrst layer and second layer of the
evaluation DNN based on Eq. (19) and input Xt = {1(µ(t)
k ∈ F ) : k ∈ K}. Next, the evaluation
DNN accomplishes forward process and obtains the predicted state-action value, i.e., Q(St, At).

The training process should make Q(St, At) approximate the expected state-action value as

¯Q(St, At) = Rt+1 + γ max

a

Q(St+1, a)

(20)

where γ ∈ (0, 1) is discount factor. For computing the expected state-action value, we use the

target DNN in the DDQN to inference the value of maxa Q(St+1, a). To make the learning

process more stable, we use the Huber function [36] to quantify the loss instead of the square

error function. The loss function is deﬁned as follows.

Loss = 


1

2(Q(St, At) − ¯Q(St, At))2,
Q(St, At) − ¯Q(St, At)
− 1
2,

Q(St, At) − ¯Q(St, At)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

otherwise.

< 1

(21)

(cid:12)
Once the loss function value is calculated, we can train the evaluation DNN by using backward
(cid:12)
algorithm [37]. The detailed steps of the DDQN training algorithm are listed in Algorithm 2.



(cid:12)
(cid:12)

Algorithm 2 The Training Algorithm for DDQN
1: Initialize replay memory with capacity E, the weight copy frequency g

2: Initialize the evaluation DNN with random weights θ and copy θ to the target DNN

3: for time slot t = 1 : T do
4: With probability ǫ select a random caching state At otherwise select At = arg maxa Q(St, a) as the caching

state in slot t + 1
Use At as the caching state of the MEC server in time slot (t + 1) and compute the reward Rt+1
Store transition St, At, Rt+1, St+1 in experience memory
Sample random mini-batch of transitions St, At, Rt+1, St+1 from experience memory
Assign values to the weights between the ﬁrst layer and second layer based on Eq. (19).
Assign bt+1 to the weights of the TLA in the evaluation DNN.
Input Xt = {1(µ(t)
Perform a gradient descend step on loss function with respect to the DNN parameters

k ∈ F ) : k ∈ K} to the evaluation DNN and obtain Q(St, At)

Update the target DNN every g slots

5:

6:

7:

8:

9:

10:

11:

12:

13: end for

In the DDQN inference phase, we ﬁrst assign values to the weights between the ﬁrst layer

and second layer based on Eq. (19). Then, we input Xt = {1(µ(t)
k ∈ F ) : k ∈ K} to DNN
and forwards to the ﬁrst layer of TLA and output O = (O1, O2, · · · , OF ). Finally, we need ﬁnd

20

Algorithm 3 Algorithm for Solving the Optimal Action
Input: Ot, {Df : f ∈ F }
Output: The optimal caching state bt+1
1: bt+1 = [0]F , Ξ = [0]F ×C , Ξr = [0]F ×C;
2: for each f ∈ [1, F ] do
if f < F then
3:
4:
5:
6:
7:
8:
9:

Ξr(f, c) = 1(Df < c)
Ξ(f, c) = Ξr(f, c)Of

for each c ∈ [1, C] do
if f == 1 then

(Ξ(f − 1, c − aDf ) + aOf )

else

Ξr(f, c) = arg max
a∈{0,1}

Ξ(f, c) = Ξr(f, c)Of + Ξ(f − 1, c − Ξr(f, c)Df )

Ξr(F, C) = arg maxa∈{0,1}(Ξ(F − 1, C − aDF ) + aOF )
Ξ(F, C) = Ξr(F, C)OF + Ξ(F − 1, C − Ξr(F, C)DF )

else

end if

end for

10:
11:
12:
13:
14:
15:
16:
17: end for
18: bt+1(F ) = Ξr(F, C)
19: for each f = F − 1 : −1 : 1 do
bt+1(f ) = Ξr(f, C −
20:
21: end for
22: return bt+1

end if

P

f +1≤j≤F bt+1(j) ∗ Dj)

the optimal caching state in time slot (t + 1) (i.e., arg maxbt+1 Q(µt, bt+1)). We formulate the
optimal caching state problem as follows.

P2 : max

f

bt+1 Xf ∈F
s. t.

b(t+1)
f Of

b(t+1)
f Df ≤ C,

Xf ∈F
b(t+1)
f

∈ {0, 1} .

(22)

(22a)

(22b)

Problem

P2 is a typical Knapsack problem [38]. Below we introduce a recursive function to

derive the optimal solution. For ease of presentation, we ﬁrst deﬁne a F × C matrix Ξ, in which

f

Ξ(f, c) represents the optimal solution under the ﬁrst f tasks using a cache size of c. The value

of Ξ(f, c) is given by the following recursive function.

Ξ(f, c) = maxb(t+1)

f

(Ξ(f − 1, c − b(t+1)

f Df ) + b(t+1)

f Of ).

(23)

Through the above recursive function, the optimal solution of problem

P2 can be derived by

the argument of Ξ(F, C). For clarity, we conclude the detailed steps of solving optimal caching

f

state in Algorithm 3 whose time complexity is O(2F C + F ).

Once the optimal caching state bt+1 in time slot t + 1 is derived, the MEC server can calculate

21

At the beginning of time slot t

In time slot t

the MEC server orchestras the Users to 
perform the COMO game (running 
Algorithm 1) to solve the COMO policy

Users execute their tasks 
based the COMO policy 

If training?

At the end of time slot t

Yes

No

The MEC server performs the training 
algorithm (Algorithm 2) to update the cache 
and train the DDQN.

The MEC server performs the inference 
algorithm (Algorithm 4) to update the 
cache.

Fig. 4. An illustration for connections between the proposed algorithms and the system model.

the optimal TSCU policy in time slot t, i.e., β(t)

f . Then, the MEC server can update
its cache space and assist the COMO in time slot (t + 1). For clarity, we conclude the detailed

f = b(t+1)

f −b(t)

steps of the DDQN inference phase in Algorithm 4. In addition, for ease of understanding, Fig.

4 illustrates the connections between all algorithms and the physical system model.

Algorithm 4 The Inference Algorithm of DDQN
1: Assign values to the weights between the ﬁrst layer and second layer based on Eq. (19).
2: Input Xt = {1(µ(t)

k ∈ F ) : k ∈ K} to the ﬁrst layer of the DNN, then the DNN forwards to the ﬁrst layer of

TLA and output O = (O1, O2, · · · , OF )

3: Solve the optimal caching state in the next time slot using Algorithm 3
− b(t)
4: Calculate the optimal caching update policy based on β(t)

f = b(t+1)

f

f , ∀f ∈ F

IV. SIMULATION RESULTS

This section evaluates the proposed dynamic TSCU-based COMO scheme by comparing its

performances with the following baseline schemes. Note that these baselines for caching updates

do not include the COMO policy. For fairness, we add the COMO policy proposed in this work

to these baselines for forming TSCU assisted COMO schemes. Moreover, we use the COMO

policy proposed in this work as a baseline for illustrating the advantages of TSCU.

• The least recently used caching-based MEC (LRU-MEC) updates task software caching

based on LRU policy [39], in which the MEC server keeps the most recently requested task

software in the MEC server cache memory. When the cache storage is full, the cached task

software, which is requested least recently, will be replaced by the new task software.

• The least frequently used caching-based MEC (LFU-MEC) updates task software caching

based on LFU policy [39], in which the MEC server caches the task software with highest

request count which is calculated by the request information of past time slots. When the

cache storage is full, the cached task software, which is requested the least many times,

will be replaced by the new task software.

22

• The ﬁrst in ﬁrst out-based MEC (FIFO-MEC) update task software caching according to

FIFO policy [23].

• The local most popular caching-based MEC (LMP-MEC) updates the cache based on LMP

algorithm [24], which predicts the next request based on both long-term ﬁle popularity and

short-term temporal correlations in request sequences.

• MEC ofﬂoading: The MEC ofﬂoading scheme utilizes the proposed potential game-based

COMO algorithm to decide the executive method of users’ tasks under the empty task

software caching state of the MEC server. It only has two ways of task computing, i.e.,

local computing and non-caching based COMO.

In the simulations, the proposed scheme and benchmark schemes are implemented using

Python and Pytorch. It is assumed that K users are randomly distributed over a 200m×200m

single cell, and the BS is sited in the cell’s center. Similar with [28], [29], the channel gain is
modeled as hk,t = ρk(t)d−n

k where dk is the distance between user k and the BS, ρk(t) ∼ Exp(1)
is exponentially distributed with unit mean, which represents the small-scale fading channel

power gain from user k to the MEC server in slot t, and n is the path loss factor. According to the

realistic measurements in [32], we set the energy coefﬁcient ζ as 5×10−27. The input parameters

data size of each task, i.e., If , is uniform randomly selected in [1, Imax] Megabytes. The software

data size of each task, i.e., Df , is uniform randomly selected in [1, Dmax] Gigabytes. The

required CPU cycles for computing task k, i.e., Sf , is randomly selected in [1, Smax] Gigacycles.

The parameters chosen in the simulation are based on the parameter setting of a typical MEC

network [24], [27], [29]. Unless otherwise stated, the primary simulation environment settings

are summarized in Table II.

In terms of the user task request µ(t)

k , we use Pr[µ(t+1)
k = i] to denote the transition
probability from task i to j (i, j ∈ F ) of user k. Similar to [24] and [27], we assume that all

= j|µ(t)

k

users’ request transition probabilities follow the same request transition model as follows.

Pr[µ(t+1)

k = j|µ(t)

k = i] =

R,

(1 − R)

1/jδ
m=1 1/mδ ,
PF
(1 − R) 1
N ,

0,






i ∈ ¯F , j = 0,

i = 0, j ∈ F ,

j = (i + q)mod(F + 1), i ∈ F , q ∈ {1, 2, · · · , N},

otherwise.

(24)

Pr[µ(t+1)
k

= j|µ(t)

k = i] is parameterized by hR, δ, N i. Speciﬁcally, R is the transition prob-
ability of requesting nothing given any task request at the current time slot. The transition

23

probability of any task f ∈ F under no current ﬁle request is modeled as a Zipf distribution

which parameterized by δ. For any task i ∈ F , we assign a set of N neighboring tasks, i.e.,

N = {f ∈ F , f = (i + n) mod (F + 1), n = 1, 2, · · · N}. Then, the transition probability of

requesting any task f ∈ N under the current task request i ∈ F is modeled as the uniform

distribution. The transition probability of requesting any task f /∈ N under the current task

request i ∈ F is zero. It is worth mentioning we provide the transition probability in the

simulation parts to establish the environment. It does not mean the proposed solution relies

on the known transition model. In fact, the proposed solution is a model-free approach. In

the following results, we alter the transition probability parameters to verify that the proposed

solution has the ability to handle problems with different transition probabilities.

TABLE II
SIMULATION SETTINGS

Parameter
User number: K
Number of time slots: T
Transmission power of devices: pk
CPU capability of user k: fk
Cache size of the MEC server: C
Path loss factor: n
Dmax
Learning rate of DNN
Batch size
τ

Value
20
2000
0.5 W
1 GHz
2 GB
4
5
0.0001
8
5ms

Parameter
Task number: F
Wireless transmission bandwidth: B
White Gaussian noise variance: σ2
CPU capability of the MEC server: fC
The number of channels: M
Imax
Smax
Experience replay memory size: E
Discount factor: γ

Value
50
30 MHz
2 × 10−13
20 GHz
10
5
5
1000
0.9

In Fig. 5, the black solid curve represents the reduced energy consumption per training slot

of the proposed TSCU-based COMO scheme. The black dash line represents the counterpart

with conventional way that uses the user request µt as the input of the DNN, and all weights

between the ﬁrst and the second layer are connected. These two curves are plotted using the

moving average with a window equal 20. The blue dash curve shows the dynamics of the

system-wide energy consumption in one slot with the empty storage status of the MEC server.

We can see that the potential game-based COMO algorithm rapidly converge to a stable point,

i.e., the NE of the multi-user COMO game. Moreover, the reduced energy consumption (black

curve) increases as the training slots increase and reaches the maximum reduction value when

the learning process becomes stable. It is valuable to note that the proposed scheme can rapidly

converge to the maximum reduction value point (less than 1000 slots). Most existing DRL-

based caching works usually consume more than 104 training slots, like [23], [24]. Compared

with directly inputting users’ request state to the DNN, the proposed SCAA approach is able to

reduce the learning complexity and accelerate the convergence of the DDQN.

24

120

100

80

60

40

20

0

0

18

17.5

17

39%

15.9

16

16.1

5

10

15

20

Fig. 5. The energy consumption of users with respect to iteration
steps under the empty caching state of the MEC server.

Fig. 6. Comparison of the average energy consumption over
each time slot against different cache size of the MEC server.

In Fig. 6, we show that the impact of the MEC server’s cache size on the average energy

consumption over each time slot of the proposed scheme and the ﬁve baselines. We can see

that all schemes’ average energy consumption over each time slot, except the MEC ofﬂoading

scheme, is reduced with the increase of cache size. This reduction is because the larger cache

size allows the storage of more task software. Thus, the requested tasks will have a higher hit

rate at the MEC server, which means that more users can execute their tasks through a lower-cost

method, i.e., caching-based COMO. When the cache size is 0, the MEC server cannot cache any

task software, and all schemes only can execute tasks through non-caching based COMO or local

computing. There is no distinction between these schemes in this case. When the cache size is

big enough to cache all the task software (over 18GB), all schemes have the same performance.

In this case, the MEC serve can cache all task software in the task library. Thus, the users

can execute their tasks through local computing or caching-based COMO, and there is also no

difference between these schemes. However, in practical systems, the cache size of the MEC

server is limited and usually cannot cache all the task software. Speciﬁcally, when the cache

size is 8GB, the proposed scheme save around 39% energy than LMP-MEC scheme.

Fig. 7 plots the average energy consumption over each time slot of the six schemes versus

the number of tasks in the task library. We can observe that the average energy consumption

over each time slot of the caching-based schemes (i.e., LRU-MEC, LFU-MEC, FIFO-MEC,

LMP-MEC, and the proposed scheme) increased with the increase of task number. The range of

users’ task requests will be more expansive with the rise of task number, which may decrease

120

100

80

60

40

62%

20

0
10

19%

20

30

40

50

60

70

80

90

100

25

21%

25%

26

28

30

32

15

20

25

30

35

40

45

50

350

300

160

140

250

120

200

100

150

100

50

0
10

Fig. 7. Comparison of the average energy consumption over
each time slot against different task number.

Fig. 8. Comparison of the average energy consumption over
each time slot against different user number.

the prediction accuracy of the task software caching schemes and further decrease the reusable

of the cached task software. In addition, it also can be observed that the proposed scheme

outperforms the other schemes. When the task number is 10, the proposed scheme can save up

to 62% of energy than the best baseline (LMP-MEC). This beneﬁt comes from the more accurate

prediction of users’ task demand and the learned knowledge of computing energy consumption

about different users.

Fig. 8 shows that how the average energy consumption over each time slot varies with the

number of users under different environmental parameters δ. Compared with the best baseline

scheme (LMP-MEC), the proposed scheme achieves the lower average energy consumption over

each time slot across all user number conﬁgurations. Moreover, it is observed that the average

energy consumption over each time slot of the two schemes keeps decreasing with the increase of

δ. In fact, as δ increases, most of the user requests concentrate on a few tasks, and the remaining

tasks in the library have a very low probability of being requested. Thus, a large δ is able to

improve the prediction accuracy of the two task software caching schemes, and the cached task

software has a higher probability of being used. Besides, the proposed scheme saves over 25%

of energy when the user number exceeds 50 compared to the LMP-MEC scheme.

Fig. 9 plots the average energy consumption over each time slot of the proposed and LMP-

MEC scheme. We can see that the average energy consumption over each time slot of both

the proposed and LMP-MEC scheme keeps increasing along with the increase of Smax. Using

the LMP-MEC scheme as the baseline, the proposed scheme reduces energy consumption by

11.5% to 22% across the parameter setting of Smax. The reason is that the growth of Smax will

26

increase the average computation load of tasks, leading to the increases of the local computing

energy consumption and the execution delay of the ofﬂoaded tasks. The rise of execution delay at

the MEC server is likely to reduce the number of ofﬂoaded tasks, inducing the average energy

consumption growth over each time slot for both schemes. Besides, we can observe that the

average energy consumption over each time slot of both schemes decreased with the increase of

R. The number of users who request to execute tasks will decrease with the rise of R. That is

to say, the total number of tasks executed in a slot is likely to decline with the increase of R,

resulting in the growth of average energy consumption.

We reveal the impact of the parameter Dmax and N on the average energy consumption over

each time slot in Fig. 10. We can see that the average energy consumption over each time slot of

the proposed schemes keeps increasing along with the increase of Dmax. This phenomenon results

from that the growth of D max will increase the average size of the tasks’ software, reducing

the number of task software that are cached at the MEC server and increasing the transmission

delay and energy consumption of COMO. As the varying of D max , the proposed scheme is

able to save about 12%-16% energy compared with the best baseline, LMP-MEC. Besides, the

average energy consumption over each time slot of the proposed scheme increases along with

N. The reason is that the users’ task request range will be more expansive with the increase of

N, which will reduce the prediction accuracy of the task software caching schemes and further

increase the average energy consumption over each time slot. Moreover, the gap between N = 3

and N = 5 is larger than the gap between N = 5 and N = 10. When N increases to a large

number (around 5), every user has the same probability of requesting ﬁve tasks. The tasks that

all users may request is likely to cover the task library, and the request probability of each task

are approximate. In this case, the prediction accuracy may converge to a stable point. Thus, the

increment of energy consumption is small with the increase of N. In fact, when N increase to

a large value, the average energy consumption of all task software caching schemes will keep

stable.

V. CONCLUSION

In this paper, we have investigated a joint TSCU and COMO problem in a dynamic multi-user

MEC network to minimize the users’ task execution energy consumption while satisfying the task

execution delay constraint. Through detailed analysis, we have proposed to solve the problem

through two stages. Firstly, we reformulated the COMO problem as a multi-user COMO game

and proposed a decentralized COMO algorithm to obtain its NE solution under any task software

60

40

20

300

250

200

150

100

50

0

3

11.5%

22%

3

3.5

4

4

5

6

7

8

9

10

130

120

110

100

90

80

70

60

3

16%

27

12%

4

5

6

7

8

9

10

Fig. 9. Comparison of the average energy consumption over
each time slot against users’ request transition probability pa-
rameter R.

Fig. 10. Comparison of the average energy consumption over
each time slot against users’ request transition probability pa-
rameter N .

caching state. Then, we developed a DDQN-based TSCU algorithm to solve the optimal caching

update strategy for the MEC server. The proposed scheme can capture task popularity, inter-task

request correlation, users’ communication conditions and computing capabilities. Simulations

results show that the proposed method can rapidly converge to stable and precisely predict users’

future task demands and outperform the other benchmark approaches in energy consumption. In

future work, we will optimize the bandwidth usage, time delay, and energy consumption under

a practical MEC case with cloud-aided backhaul and asynchronous trafﬁc.

APPENDIX

A. Proof of Lemma 1

We prove that problem P is NP-hard via the restriction method [38]. Speciﬁcally, we show

that the problem P can be restricted to a maximum cardinality bin packing problem. For clarity,

we introduce the maximum cardinality bin packing problem [40]: Given K items with sizes sk,

k ∈ {1, 2, · · · , K}, and M bins of identical capacity Q, the objective is to assign a maximum

number of items to the ﬁxed number of bins without violating the capacity constraint.

The NP-hardness of the maximum cardinality bin packing problem has been proved in [40].

To prove that Problem P is NP-hard, let us show that P contains a maximum cardinality bin

packing problem as a special case. To this end, let us focus on one speciﬁc time slot t by setting

T = 1, and assume that both the caching state of the MEC server bt and the users’ task request

µt are known. Thus, problem P is restricted as the following problem.

P : max

−

Ek,t

(25)

b

αt

Xk∈K
s. t. (9b), (9e).

For problem

P, αk,t = 0 if and only if EL

k,f ≤ (1 − b(t)

f )EO

k,f,t + b(t)

f EC

select a channel to ofﬂoad its task. Inspired by this, we further restrict problem

b

k,f , otherwise user k will
P by setting

28

αk,t ∈ M to just consider users execute their tasks through COMO. Additionally, we regard all
users’ COMO cost as -1 (i.e., (1 − b(t)
a task µ(t)

f )EO
k ∈ F . For ease of proof, we introduce a binary variable α(t)
only if αk,t = m, otherwise is 0. Thus, we reformulate the restricted problem

k,f,t = −1) and each user request to execute
k,m = 1 if and

k,m, where α(t)

k,f,t + b(t)

f EC

b

P : max

e

αt Xk∈K Xm∈M
s. t.

α(t)
k,m ≤ 1,

Xm∈M

α(t)
k,m

α(t)
k,mpkhk ≤ Q,

Xk∈K
α(t)
k,m ∈ {0, 1} ,

P as follows.

b

(26)

(26a)

(26b)

(26c)

(27)

where the capacity Q is

Q =

pkhk
(t)
−b
f

pk τ 2(If +Df
BζS3
f

2

Df )

− 1

− σ2 + pkhk.

Note that (27) follows from (11). For the restricted problem

P, we regard the items and the

bins in the maximum cardinality bin packing problem as the users and channels in problem

e

P, respectively. The size of item k is sk = pkhk. The objective of problem

P is to assign

a maximum number of items to the ﬁxed number of bins and satisfy the capacity constraint.

e

Thus, if problem

P can be effectively solved, the maximum cardinality bin packing problem

can also be solved by a polynomial time algorithm. This manifests that the original problem P

e

can be reduced to a maximum cardinality bin packing problem. Therefore, we can conclude that

problem P is NP-hard.

B. Proof of Remark 1

For user k, when the COMO decisions of other users except user k (i.e., α−k,t) are given,

we use αk,t and α′

k,t to denote two different task ofﬂoading decisions of user k. Based on the

deﬁnition of ordinal potential game in [41], game G should satisfy

sgn[φ(αk,t, α−k,t) − φ(α′

k,t, α−k,t)] = sgn[ft(αk,t, α−k,t) − ft(α′

k,t, α−k,t)],

(28)

where sgn[·] is a signum function. For ease of proof, we ﬁrst derive the expression of φ(αk,t, α−k,t)

as follows.

φ(αk,t, α−k,t) =

1
2

K

Xk=1 Xn6=k

pkhkpnhn1(αn,t = αk,t)1(αk,t > 0) +

pkhkVk 1(αk,t = 0)

K

Xk=1

=

+

1
2 Xn6=k
1
2

K

Xl6=k Xn6=l,n6=k

pkhkpnhn1(αn,t = αk,t)1(αk,t > 0) +

29

plhlpkhk 1(αk,t = αl,t)1(αl,t > 0)
K

1
2 X

K

l6=k

plhlpnhn1(αn,t = αl,t)1(αl,t > 0) + pkhkVk1(αk,t = 0) +

plhlVl1(αl,t = 0)

= pkhk

pnhn1(αn,t = αk,t)1(αk,t > 0) +

Xn6=k

K

+ pkhkVk1(αk,t = 0) +
Below we discuss the relationship between φ(αk,t, α−k,t) − φ(α′
ft(α′

k,t, α−k,t) in three cases.

plhlVl1(αl,t = 0).

X

l6=k

Xl6=k

plhlpnhn1(αn,t = αl,t)1(αl,t > 0)

1
2

K

Xl6=k Xn6=l,n6=k

(29)

k,t, α−k,t) and ft(αk,t, α−k,t) −

1) αk,t > 0, α′

φ(αk,t, α−k,t) − φ(α′

k,t > 0. According to (29), we have
k,t, α−k,t) = pkhk

pnhn1(αn,t = αk,t) − pkhk

Xn6=k
Υk,t − Υ′

= pkhk

k,t

.

(cid:1)

pnhn1(αn,t = αk,t

′)

Xn6=k

(30)

Based on (8), we have

f (αk,t, α−k,t) − f (α′

k,t, α−k,t) =

(cid:0)

Xf ∈F

1(µ(t)

k = f )pk(If + Df − b(t)

f Df )(

1
rk,t

−

1
r′
k,t

).

(31)

According to the deﬁnition of uplink rate and channel interference in (2) and (11), sgn( 1
rk,t

−

1
r′
k,t

) = sgn(Υk,t − Υ′

k,t) is established. Hence, Eq. (28) is established in this case.

2) αk,t > 0, α′

φ(αk,t, α−k,t)−φ(α′

k,t = 0. Similarly, according to (29), we have
k,t, α−k,t) = pkhk(cid:18) Xn6=k

pnhn1(αn,t = αk,t)−Vk(cid:19)

Furthermore, according to (8), we have

= pkhk(Υk,t−Vk). (32)

f (αk,t, α−k,t) − f (α′

k,t, α−k,t) =

1(µ(t)

k = f )

pk

(cid:16)

Xf ∈F

According to the analysis of (11), we have sgn (Υk,t − Vk) = sgn(pk

Thus, Eq. (28) is established in this case.

If + Df − b(t)
rk,t

f Df

− ζ

S3
f
τ 2
f Df

rk,t

.
(cid:17)
− ζ

(33)

S3
f
τ 2 ).

If +Df −b(t)

3) αk,t = 0, α′

k,t > 0. This case is similar with case 2. Eq. (28) is also established in this case.

Summarize the above results, Eq. (28) is established in any case. Consequently, game G is a

ordinal potential game and can achieve a NE solution after ﬁnite number of iterations [41].

C. Proof of Lemma 2

For ease of presentation, we deﬁne ∆max = maxk∈K {pkhk}, ∆min = mink∈K {pkhk}, Vmax =

maxk∈K {Vk}, Vmin = mink∈K {Vk}. For the potential function, we have

φ(αt)

(a)
=

≤

1
2 X

K

1
2 X

K

k=1 Xn6=k
∆2

k=1 Xn6=k

pkhkpnhn1(αn,t = αk,t)1(αk,t > 0) +

K

k=1

X

pkhkVk1(αk,t = 0)

max1(αn,t = αk,t)1(αk,t > 0) +

∆maxVmax1(αk,t = 0)

K

k=1

X

≤

1
2

K 2∆2

max + K∆maxVmax,

where (a) follows from (12).

30

(34)

The COMO algorithm ﬁrst initializes the COMO decisions of all users as 0, the initial value

K
k=1 pkhkVk ≥ K∆minVmin. Thus, the value range of φ(αt) is less than
of φ(αt) is φ(0) =
1
2K 2∆2
max + K(∆maxVmax − ∆minVmin). In each iteration, there is one user to update its decision
to decrease the computing cost. Based on the deﬁnition of potential game, the decision update

P

also decreases the value of potential function. It is assumed that user k updates its ofﬂoading

decision αk,t to a better decision α′

k,t in one iteration, i.e., φ(αk,t, α−k,t) − φ(α′

k,t, α−k,t) > 0.

Below we analyze the decrement of φ(αt) in each iteration in three cases.

1) αk,t > 0 and α′

k,t > 0.
φ(αk,t, α−k,t)−φ(α′

k,t, α−k,t)

(a)
= pkhk

pnhn

1(αk,t = αn,t)−1(α′
(cid:16)

k,t = αn,t)

(cid:17)

Xn6=k

> 0.

(35)

where (a) follows from (30). Since the value of indicator function 1(·) is integer, we have

Xn6=k

pnhn

1(αk,t = αn,t) − 1(α′
(cid:0)

k,t = αn,t)

(cid:1)

≥ ∆min.

(36)

Consequently, φ(αk,t, α−k,t) − φ(α′

k,t, α−k,t) ≥ ∆2

min.

2) αk,t > 0, α′

k,t = 0.

φ(αk,t, α−k,t) − φ(α′

k,t, α−k,t)

(a)
= pkhk

(cid:16)Xn6=k

pnhn1(αn,t = αk,t) − Vk

> 0.

(37)

(cid:17)

where (a) follows from (32). Thus, there is a positive number ε =

n6=k pnhn1(αn,t =

αk,t) − Vk, subject to φ(αk,t, α−k,t) − φ(αk,t

′, α−k,t) = εpkhk ≥ ε∆min

P

3) αk,t = 0, α′

k,t > 0. Similar to case 2, there is a positive integer ε such that φ(αk,t, α−k,t) −

φ(α′

k,t, α−k,t) ≥ ε∆min.

Summarizing the above three cases, we have φ(αk,t, α−k,t) − φ(α′

k,t, α−k,t) ≥ ε∆min, where ε
is a positive number. That is to say, in each iteration, the potential function will decrease at least

ε∆min. Accordingly, the algorithm will terminate within

1
2 K 2∆2

max+K(∆maxVmax−∆minVmin)

ε∆min

iterations

and obtain a NE solution for COMO problem.

REFERENCES

[1] Y. Siriwardhana, P. Porambage, M. Liyanage, and M. Ylianttila, “A survey on mobile augmented reality with 5G mobile

edge computing: Architectures, applications, and technical aspects,” IEEE Commun. Surveys Tuts., vol. 23, no. 2, pp.

1160–1192, 2021.

31

[2] Y. Mao, C. You, J. Zhang, K. Huang, and K. B. Letaief, “A survey on mobile edge computing: The communication

perspective,” IEEE Commun. Surveys Tuts., vol. 19, no. 4, pp. 2322–2358, 2017.

[3] D. Sabella, A. Vaillant, P. Kuure, U. Rauschenbach, and F. Giust, “Mobile-edge computing architecture: The role of mec

in the internet of things,” IEEE Consum. Electron. Mag., vol. 5, no. 4, pp. 84–91, 2016.

[4] P. Mach and Z. Becvar, “Mobile edge computing: A survey on architecture and computation ofﬂoading,” IEEE Commun.

Surveys Tuts., vol. 19, no. 3, pp. 1628–1656, 2017.

[5] Z. Sun and M. R. Nakhai, “An online learning algorithm for distributed task ofﬂoading in multi-access edge computing,”

IEEE Trans. Signal Processing, vol. 68, pp. 3090–3102, 2020.

[6] H. A. Alameddine, S. Sharafeddine, S. Sebbah, S. Ayoubi, and C. Assi, “Dynamic task ofﬂoading and scheduling for

low-latency IoT services in multi-access edge computing,” IEEE J. Selected Areas Commun., vol. 37, no. 3, pp. 668–682,

2019.

[7] Z. Yu, Y. Gong, S. Gong, and Y. Guo, “Joint task ofﬂoading and resource allocation in UAV-enabled mobile edge

computing,” IEEE Internet Things J., vol. 7, no. 4, pp. 3147–3159, 2020.

[8] Q. Zhang, L. Gui, F. Hou, J. Chen, S. Zhu, and F. Tian, “Dynamic task ofﬂoading and resource allocation for mobile-edge

computing in dense cloud RAN,” IEEE Internet Things J., vol. 7, no. 4, pp. 3282–3299, 2020.

[9] M. Zhao, J.-J. Yu, W.-T. Li, D. Liu, S. Yao, W. Feng, C. She, and T. Q. Quek, “Energy-aware task ofﬂoading and resource

allocation for time-sensitive services in mobile edge computing systems,” IEEE Trans. Veh. Technol., vol. 70, no. 10, pp.

10 925–10 940, 2021.

[10] T. X. Tran and D. Pompili, “Adaptive bitrate video caching and processing in mobile-edge computing networks,” IEEE

Trans. Mobile Computing, vol. 18, no. 9, pp. 1965–1978, 2019.

[11] M. Chen and Y. Hao, “Task ofﬂoading for mobile edge computing in software deﬁned ultra-dense network,” IEEE J. Sel.

Areas Commun., vol. 36, no. 3, pp. 587–597, 2018.

[12] W. Wen, Y. Cui, T. Q. Quek, F.-C. Zheng, and S. Jin, “Joint optimal software caching, computation ofﬂoading and

communications resource allocation for mobile edge computing,” IEEE Trans. Veh. Technol., vol. 69, no. 7, pp. 7879–

7894, 2020.

[13] J. Yan, S. Bi, L. Duan, and Y.-J. A. Zhang, “Pricing-driven service caching and task ofﬂoading in mobile edge computing,”

IEEE Trans. Wireless Commun., vol. 20, no. 7, pp. 4495–4512, 2021.

[14] Z. Chen, Z. Zhou, and C. Chen, “Code caching-assisted computation ofﬂoading and resource allocation for multi-user

mobile edge computing,” IEEE Trans. Netw. Service Manag., vol. 18, no. 4, pp. 4517–4530, 2021.

[15] S. Bi, L. Huang, and Y.-J. A. Zhang, “Joint optimization of service caching placement and computation ofﬂoading in

mobile edge computing systems,” IEEE Trans. Wireless Commun., vol. 19, no. 7, pp. 4947–4963, 2020.

[16] W. Yi, Y. Liu, and A. Nallanathan, “Cache-enabled hetnets with millimeter wave small cells,” IEEE Trans. Commun.,

vol. 66, no. 11, pp. 5497–5511, Nov. 2018.

[17] H. Xing, J. Cui, Y. Deng, and A. Nallanathan, “Energy-efﬁcient proactive caching for fog computing with correlated task

arrivals,” in in Proc. SPAWC.

IEEE, 2019, pp. 1–5.

[18] X. Yang, Z. Fei, J. Zheng, N. Zhang, and A. Anpalagan, “Joint multi-user computation ofﬂoading and data caching for

hybrid mobile cloud/edge computing,” IEEE Trans. Veh. Technol., vol. 68, no. 11, pp. 11 018–11 030, 2019.

[19] Z. Chen and Z. Zhou, “Dynamic task caching and computation ofﬂoading for mobile edge computing,” in Proc. IEEE

GLOBECOM.

IEEE, 2020, pp. 1–6.

[20] Z. Chen, Z. Chen, and Y. Jia, “Integrated task caching, computation ofﬂoading and resource allocation for mobile edge

computing,” in Proc. IEEE GLOBECOM, 2019, pp. 1–6.

32

[21] S. Bi, L. Huang, and Y.-J. A. Zhang, “Joint optimization of service caching placement and computation ofﬂoading in

mobile edge computing systems,” IEEE Trans. Wireless Commun., vol. 19, no. 7, pp. 4947–4963, 2020.

[22] J. Zhang, X. Hu, Z. Ning, E. C.-H. Ngai, L. Zhou, J. Wei, J. Cheng, B. Hu, and V. C. Leung, “Joint resource allocation

for latency-sensitive services over mobile edge computing networks with caching,” IEEE Internet Things J., vol. 6, no. 3,

pp. 4283–4294, 2018.

[23] P. Wu, J. Li, L. Shi, M. Ding, K. Cai, and F. Yang, “Dynamic content update for wireless edge caching via deep

reinforcement learning,” IEEE Commun. Lett., vol. 23, no. 10, pp. 1773–1777, 2019.

[24] Y. Qian, R. Wang, J. Wu, B. Tan, and H. Ren, “Reinforcement learning-based optimal computing and caching in mobile

edge network,” IEEE J. Sel. Areas Commun., vol. 38, no. 10, pp. 2343–2355, 2020.

[25] J. Zhang, X. Hu, Z. Ning, E. C.-H. Ngai, L. Zhou, J. Wei, J. Cheng, B. Hu, and V. C. M. Leung, “Joint resource allocation

for latency-sensitive services over mobile edge computing networks with caching,” IEEE Internet Things J., vol. 6, no. 3,

pp. 4283–4294, 2019.

[26] R. Zheng, H. Wang, M. De Mari, M. Cui, X. Chu, and T. Q. S. Quek, “Dynamic computation ofﬂoading in ultra-dense

networks based on mean ﬁeld games,” IEEE Trans. Wireless Commun., vol. 20, no. 10, pp. 6551–6565, 2021.

[27] Y. Sun, Y. Cui, and H. Liu, “Joint pushing and caching for bandwidth utilization maximization in wireless networks,”

IEEE Trans. Commun., vol. 67, no. 1, pp. 391–404, 2019.

[28] T. S. Rappaport et al., Wireless communications: principles and practice.

prentice hall PTR New Jersey, 1996, vol. 2.

[29] X. Chen, L. Jiao, W. Li, and X. Fu, “Efﬁcient multi-user computation ofﬂoading for mobile-edge cloud computing,”

IEEE/ACM Trans. Netw., vol. 24, no. 5, pp. 2795–2808, 2016.

[30] M. Xiao, N. Shroff, and E. Chong, “A utility-based power-control scheme in wireless cellular systems,” IEEE/ACM Trans.

Netw., vol. 11, no. 2, pp. 210–221, 2003.

[31] M. Chiang, P. Hande, T. Lan, C. W. Tan, et al., “Power control in wireless cellular networks,” Found. Trends Netw., vol. 2,

no. 4, pp. 381–533, 2008.

[32] A. P. Miettinen and J. K. Nurminen, “Energy efﬁciency of mobile clients in cloud computing.” HotCloud, vol. 10, pp.

1–7, 2010.

[33] A. Bozorgchenani, D. Tarchi, and W. Cerroni, “On-demand service deployment strategies for fog-as-a-service scenarios,”

IEEE Commun. Letters, vol. 25, no. 5, pp. 1500–1504, 2021.

[34] H. Van Hasselt, A. Guez, and D. Silver, “Deep reinforcement learning with double Q-learning,” in in Proc AAAI, vol. 30,

no. 1, 2016.

[35] R. S. Sutton and A. G. Barto, Reinforcement learning: An introduction. MIT press, 2018.

[36] R. Agarwal, D. Schuurmans, and M. Norouzi, “An optimistic perspective on ofﬂine reinforcement learning,” in in Proc.

ICML, 2020, pp. 104–114.

[37]

I. Goodfellow, Y. Bengio, and A. Courville, Deep learning. MIT press, 2016.

[38] M. R. Garey and D. S. Johnson, Computers and intractability.

freeman San Francisco, 1979, vol. 174.

[39] G. Hasslinger, J. Heikkinen, K. Ntougias, F. Hasslinger, and O. Hohlfeld, “Optimum caching versus LRU and LFU:

Comparison and combined limited look-ahead strategies,” in in Proc. WiOpt, 2018, pp. 1–6.

[40] K.-H. Loh, B. Golden, and E. Wasil, “Solving the maximum cardinality bin packing problem with a weight annealing-based

algorithm,” in Operations Research and Cyber-Infrastructure. Springer, 2009, pp. 147–164.

[41] K. Yamamoto, “A comprehensive survey of potential game approaches to wireless networks,” IEICE Trans. Commun.,

vol. 98, no. 9, pp. 1804–1823, 2015.

