2
2
0
2

r
p
A
6
2

]
E
S
.
s
c
[

1
v
8
4
1
2
1
.
4
0
2
2
:
v
i
X
r
a

Morest: Model-based RESTful API Testing with Execution
Feedback

Yi Liu
Nanyang Technological University
Singapore

Yuekang Liâ€ 
Nanyang Technological University
Singapore

Gelei Deng
Nanyang Technological University
Singapore

Yang Liu
Nanyang Technological University
Singapore

Dandan Ji
Huawei Technologies Co., Ltd
China

Ruiyuan Wan
Huawei Cloud Computing
Technologies Co., Ltd
China

Shiheng Xu
Huawei Cloud Computing
Technologies Co., Ltd
China

Runchao Wu
Huawei Cloud Computing
Technologies Co., Ltd
China

Minli Bao
Huawei Cloud Computing
Technologies Co., Ltd
China

ABSTRACT
RESTful APIs are arguably the most popular endpoints for accessing
Web services. Blackbox testing is one of the emerging techniques
for ensuring the reliability of RESTful APIs. The major challenge
in testing RESTful APIs is the need for correct sequences of API
operation calls for in-depth testing. To build meaningful opera-
tion call sequences, researchers have proposed techniques to learn
and utilize the API dependencies based on OpenAPI specifications.
However, these techniques either lack the overall awareness of how
all the APIs are connected or the flexibility of adaptively fixing the
learned knowledge.

In this paper, we propose Morest, a model-based RESTful API
testing technique that builds and maintains a dynamically updating
RESTful-service Property Graph (RPG) to model the behaviors
of RESTful-services and guide the call sequence generation. We
empirically evaluated Morest and the results demonstrate that
Morest can successfully request an average of 152.66%-232.45%
more API operations, cover 26.16%-103.24% more lines of code, and
detect 40.64%-215.94% more bugs than state-of-the-art techniques.
In total, we applied Morest to 6 real-world projects and found
44 bugs (13 of them cannot be detected by existing approaches).
Specifically, 2 of the confirmed bugs are from Bitbucket, a famous
code management service with more than 6 million users.

KEYWORDS
RESTful service, model-based testing

â€ Corresponding author.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA
Â© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9221-1/22/05. . . $15.00
https://doi.org/10.1145/3510003.3510133

ACM Reference Format:
Yi Liu, Yuekang Li, Gelei Deng, Yang Liu, Ruiyuan Wan, Runchao Wu,
Dandan Ji, Shiheng Xu, and Minli Bao. 2022. Morest: Model-based RESTful
API Testing with Execution Feedback. In 44th International Conference on
Software Engineering (ICSE â€™22), May 21â€“29, 2022, Pittsburgh, PA, USA. ACM,
New York, NY, USA, 12 pages. https://doi.org/10.1145/3510003.3510133

1 INTRODUCTION
Representational state transfer (REST) has become a de-facto stan-
dard for Web service interactions since it was introduced in 2000 [21].
Web-based APIs which follow this standard are called RESTful
APIs and the web services providing the RESTful APIs are called
RESTful services. Nowadays, most web service providers, such as
Google [26], Twitter [27] and Amazon [25], expose RESTful APIs to
grant access to other applications or services. As the RESTful APIs
gain popularity, techniques for automatically testing them become
important. Based on whether the knowledge of the program inter-
nals is needed or not, these testing techniques can be categorized as
whitebox and blackbox techniques. Whitebox techniques are nor-
mally more effective but require source code [7]. On the contrary,
blackbox techniques only rely on a well-defined interface to con-
duct testing [11, 47]. In comparison to their whitebox counterparts,
blackbox techniques enjoy superior applicability considering that
a cloud service can be implemented with different programming
languages and may use third-party libraries whose source code is
not available. In this paper, we concentrate on the blackbox RESTful
API testing techniques.

One of the most challenging problems in testing RESTful APIs
is how to infer the correct sequences of calling the API operations
(aka, call sequences) where each API operation can be one of the
four basic types â€” create, read, update, and delete (CRUD). This is
because RESTful APIs are often organized sparsely to encapsulate
different micro services and fulfilling a single task can involve a
chain of API calls. Take the Petstore service [39] as an example,
it is a RESTful service for selling and ordering pets. In Petstore,
before calling the API to order a pet, APIs for creating the pet and
updating its status as â€œavailableâ€ must be invoked. Skipping any of

 
 
 
 
 
 
ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA

Yi Liu, Yuekang Li, Gelei Deng, Yang Liu, Ruiyuan Wan, Runchao Wu, Dandan Ji, Shiheng Xu, and Minli Bao

the prerequisite APIs will cause the ordering pet operation to fail,
preventing the coverage of deeper logic in the code. To address the
challenge of generating proper API call sequences, researchers have
proposed several testing techniques [11, 20, 47] which can infer the
dependencies between RESTful APIs to guide the test generation.
For the purpose of API dependency inference, these techniques
leverage API specifications such as OpenAPI [38], RAML [41] and
API Blueprint [6]. Among these API specifications, OpenAPI (aka,
Swagger) is becoming increasingly popular and gets adopted by
major IT companies (e.g., Google, Microsoft, and IBM).

Two most recent state-of-the-art blackbox RESTful API testing
techniques â€” Restler [11] and Resttestgen [47] use the Ope-
nAPI specifications of the target RESTful services to facilitate their
call sequence generation. On the one hand, both of them learn the
producer-consumer dependencies 1 between the APIs to enforce
the correct ordering of APIs in the generated call sequences. On
the other hand, the difference between Restler and Resttestgen
lies in how they utilize the learnt dependencies: â¶ For Restler, it
uses a bottom-up approach, which starts with testing single APIs
and then extends the API call sequences by heuristically appending
API calls. Although Restler can limit the search space with dy-
namic feedbacks (i.e., if certain combination of APIs fails to execute,
Restler avoids this pattern in the future), the search space for
extending the test sequences is still very large due to the lack of
overall awareness of how the APIs are connected. â· To gain such
awareness, Resttestgen proposes a top-down approach to con-
nect the APIs into an Operation Dependency Graph (ODG), where
APIs are nodes and their dependencies are edges. With the ODG
built, Resttestgen can then traverse it and aggregate the visited
API nodes to generate call sequences. In this sense, Resttestgen
can generate valid call sequences more efficiently. However, the
quality of the tests generated by Resttestgen might be hindered
since it heavily depends on the ODG, which may not reflect the
API behavior correctly due to some pitfalls (e.g., poorly written
OpenAPI specifications). In short, both the bottom-up and top-down
approaches have strengths and weaknesses, leaving the generation
of proper API call sequences an under-researched field.

In this paper, we propose Morest â€“ a blackbox RESTful API
testing technique with a dynamically updating RESTful-service
Property Graph (RPG). The workflow of Morest contains two ma-
jor procedures: building the RPG with the OpenAPI specifications
of the target RESTful service and the model-based testing with
dynamic updates of the RPG. The RPG is a novel representation of
RESTful services proposed in this paper which encodes API and
object schema information in the form of a mixed, edge-labeled,
attributed multigraph. Compared to ODG, RPG can model not only
the producer-consumer dependencies between APIs with more de-
tails but also the property equivalence relations between schemas,
which allows RPG to both describe more behaviors of the REST-
ful services and flexibly update itself with execution feedback. By
traversing the RPG, Morest can aggregate the visited APIs to build
meaningful call sequences. During the testing process, Morest
constantly collect the responses of the RESTful service and use
the dynamic information to update the RPG adaptively. With the

1If a resource in the response of an API A is used as an input argument of another API
B, then B depends on A.

updated RPG, Morest can then generate test sequences with better
quality for the next iteration of testing. In this sense, Morest enjoys
the benefits of both the bottom-up and top-down approaches while
avoiding their drawbacks by having both the overall awareness of
all APIs and the flexibility of making changes.

We empirically evaluated Morest on six RESTful services run-
ning in local environment. In our experiments, Morest outperforms
the state-of-the-art blackbox RESTful API testing tools, namely
Restler and Resttestgen with superior average code coverage
(26.16% and 103.24% respectively), average successfully requested
operations (152.66% and 232.45% respectively) and average number
of detected bugs (40.64% and 111.65% respectively). In total, we
applied Morest to six real-world projects and found 44 bugs (13
of them cannot be detected by existing approaches). In specific,
2 of the confirmed bugs are from Bitbucket, a famous Git code
management service with more than six million users [34].

Contribution. We summarize our contributions as follows:

â€¢ We propose a novel model called RESTful-service Property
Graph (RPG) for describing Web services and adopt it for
RESTful API testing.

â€¢ We develop a methodology for adaptively updating the RPG

for enhanced performance.

â€¢ We evaluate the performance of Morest and demonstrate
the superiority of Morest comparing to the state-of-the-
art techniques with 1,440 CPU Hours. To the best of our
knowledge, this is the first work to empirically compare
blackbox RESTful API testing techniques.

â€¢ We detect 44 bugs with Morest in 6 projects. We respon-
sibly disclose the bugs to the developers and 2 of them are
confirmed until the time of writing this paper.

â€¢ We release our datasets and implementation of Morest to

facilitate future research.

Currently, we have released the raw experimental data, the pro-
totype of Morest and the evaluated benchmarks on the com-
panion website of this paper. The link to the website is https:
//sites.google.com/view/restful-morest/home.

2 BACKGROUND & RUNNING EXAMPLE
2.1 Background

RESTful API. The REpresentational State Transfer (REST) archi-
tecture is is first proposed by Roy Fielding in 2000 [21]. A Web
API using the REST architecture is called a RESTful API. A Web
service providing RESTful APIs is called a RESTful service. One of
the fundamental constraints of REST architectural style is Uniform
Interface, which regulates the CRUD operations on the resources.
In modern Web API design practice, RESTful APIs often use HTTP
protocol as the transportation layer. Therefore, the CRUD opera-
tions of RESTful APIs can be mapped to the HTTP methods POST,
GET, PUT and DELETE respectively.

OpenAPI Specification. OpenAPI (previously known as Swag-
ger) defines a standard for describing RESTful APIs [38] and an
API document following this standard is called an OpenAPI spec-
ification. OpenAPI specifications contain the information of the
object schemas as well as the API endpoints, including but not lim-
ited to the available CRUD operations, input parameters as well as

Morest: Model-based RESTful API Testing with Execution Feedback

ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA

involve objects that are described by schemas. For example, the op-
eration getPetById returns responses with objects under the Pet
schema. Fig. 2 shows the OpenAPI specifications of the schemas.
Operation Dependency Graph In Resttestgen, Viglianisi et al.
propose to use Operation Dependency Graph (ODG) to model data
dependencies among operations which can be inferred from the
OpenAPI specifications [47]. The benefit of using ODG is that aggre-
gating operations by traversing the ODG can generate meaningful
call sequences. The ODG is a graph ğº = (ğ‘‰ , ğ¸) where ğ‘‰ is a set
of nodes and ğ¸ is a set of directed edges. For each node ğ‘£ âˆˆ ğ‘‰ , ğ‘£
corresponds to a unique operation in the OpenAPI specification.
The graph is said to contain a directed edge ğ‘’ where ğ‘’ = (ğ‘£2, ğ‘£1)
for ğ‘£1, ğ‘£2 âˆˆ ğ‘‰ and ğ‘£1 â‰  ğ‘£2, if and only if (iff) there exists a common
field in the response of ğ‘£1 and in the request parameter of ğ‘£2. Two
fields are common when they have the same name if they are of
atomic type (e.g., string or numeric) or when they are related to
the same schema if they are of a non-atomic type. Thus, following
this definition, ğ‘£2 â†’ ğ‘£1 means ğ‘£2 depends on ğ‘£1.

2.2 Running Example
Here we introduce a running example extracted from the Petstore
service [39], which can demonstrate the limitations of existing
approaches and aid in the explanation of Morestâ€™s strategies in
Section 3. Fig. 1 and 2 illustrate the OpenAPI specifications of the
Petstore service. The question is, given these specifications, how
to generate meaningful API call sequences. For this purpose, we
need to infer the dependencies among the APIs. Intuitively, the
definition of API dependencies in ODG (Â§ 2.1) can be applied here
(both Restler [11] and Resttestgen [47] follow this definition).
For the example in Fig. 1, we can get the following dependencies:

(1) findPetsByStatusâ†’getPetById
(2) findPetsByStatusâ†’getOrderById
(3) addPetâ†’findPetsByStatus

(4) addPetâ†’getPetById
(5) getPetByIdâ†’getOrderById
(6) placeOrderâ†’getOrderById

Note that some of the dependencies are infeasible: One example
is in dependency 2 where findPetsByStatus should not depend on
the status of the Order object returned by getOrderById because
the status of a pet and the status of an order are not the same. An-
other example is in dependency 4 where addPet should not depend
on getPetById although both of them use the Pet schema. While
there are infeasible dependencies, they cannot be safely filtered out
as yet because the current ODG model lacks the ability to describe
the relation between an API and a schema in detail and dynamic
execution feedbacks are needed to infer correct dependencies.

After the dependencies are acquired, we can then use them to
guide the call sequence generation. To start with, we can use a
bottom-up approach by testing single APIs first and then extend the
test sequences by appending more APIs one at a time. For example,
we can start with a new sequence: <getOrderById>. After a suc-
cessful call of getOrderById, we can feed the petId of the returned
Order object to getPetById according to dependency 5. Then the
sequence becomes <getOrderById, getPetById>. Similarly, we
can append findPetsByStatus to the sequence according to de-
pendency 1 and so on. In this process, we can identify the infeasible
dependencies and avoid using them in the future. For instance, we
can tell dependency 4 is faulty because if we try to append addPet
to <getOrderById, getPetById> according to dependency 4, the
addPet operation will always fail since the service refuses to create

(a)

(b)

Figure 1: The OpenAPI specification of Petstore APIsâˆ—
âˆ— For clarity, we omit some details in the YAML file.

(a)

(b)

Figure 2: The OpenAPI specification of Petstore Schemas âˆ—
âˆ— For clarity, we omit some details in the YAML file.

responses. These specifications can be stored as either YAML or
JSON files.

Fig. 1 shows a fragment of the OpenAPI specification for APIs
in the Petstore service [39]. In this example, five API endpoints are
specified and they are marked with grey background. We can see
that each API endpoint supports one or more CRUD operations,
which are specified by the operationId property. In total, six oper-
ations are described in Fig. 2, showing their input parameters and
responses. For an input parameter, it can be inside the request body
(body of addPet) or in the URL path 2 (petId of getPetById). For
a response, it contains the HTTP status code as well as the content
body. In addition, some operation parameters and responses may

2Some GET operations may involve the usage of query parameters and they are also
considered as serialized in the URL path.

swagger:"2.0"paths:/pet:post:operationId:"addPet"parameters:-name:"body"schema:"#/defs/Pet",â†’/pet/findByStatus:get:operationId:"findPetsByStatus",â†’parameters:-name:"status"type:"string"responses:"200":description:"success",â†’schema:"#/defs/Pet",â†’/pet/{petId}:get:operationId:"getPetById",â†’parameters:-name:"petId"type:"integer"responses:"200":schema:"#/defs/Pet",â†’/store/order:post:operationId:"placeOrder",â†’parameters:-name:"body"schema:"#/defs/Order",â†’/store/order/{orderId}:get:operationId:"getOrderById",â†’parameters:-name:"orderId"type:"integer"responses:"200":schema:"#/defs/Order",â†’delete:operationId:"deleteOrder",â†’parameters:-name:"orderId"type:"integer"Order:type:"object"properties:id:type:"integer"petId:type:"integer"status:type:"string"Pet:type:"object"properties:id:type:"integer"name:type:"string"status:type:"string"ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA

Yi Liu, Yuekang Li, Gelei Deng, Yang Liu, Ruiyuan Wan, Runchao Wu, Dandan Ji, Shiheng Xu, and Minli Bao

Figure 3: The workflow of Morest

an already existing pet. The limitation of the bottom-up approach
is that it lacks the overall awareness of how the APIs are connected
with each other. For example, it is hard to conduct Depth-First-
Search (DFS) when extending a sequence because the potential
length of the sequence is unknown and if it is very long, the risk of
getting stuck in a local optimal is high.

Alternatively, we can use ODG to facilitate the generation of
call sequences, which is a top-down approach. The call sequences
can be generated by traversing the ODG and chaining the visited
operations. Compared with the bottom-up approach, with ODG,
we can quickly generate call sequences without trial and error.
However, because some extracted dependencies (such as 2 and 4)
might be infeasible, the quality of the generated call sequences
can be affected. In other words, the top-down approach lacks the
flexibility of dynamically fixing the call sequences.

In summary, both the bottom-up and top-down approach have
their own strengths and weaknesses and they can complement each
other. Therefore, a new model is needed to both provide high level
guidance and perform self-updates. Following this observation,
we propose Morest, which leverages RESTful-service Property
Graph (RPG) to adopt the advantages of both approaches while
circumventing their disadvantages.

3 METHODOLOGY
Fig. 3 shows the detailed workflow of Morest. To test a RESTful
service, Morest first takes its OpenAPI specifications as input to
build the RPG â€” a novel representation of the relations among
RESTful APIs and the schemas (Â§ 3.1). After building the initial
RPG, Morest uses it to generate call sequences and replace the
API calls in the call sequences with actual requests (Â§ 3.2). Then
the generated test cases are fed to the target RESTful service and
Morest shall collect the responses. By analyzing the collected
responses, Morest reports the detected failures for bug analysis.
Moreover, Morest also uses the responses to refine the RPG by
adding missing edges and removing infeasible edges (Â§ 3.3). The
refined RPG is then used for generating more test sequences. This
marks the end of one iteration and Morest will keep testing the
target RESTful service and refining the RPG until the time budget
is reached.

3.1 Initial RPG Building
In Morest, we propose the concept of RPG to encode the CRUD
relations of operations, the relations of the schemas, and the data-
flow among the schemas and operations. The design of RPG is based

on the concept of property graph [42]. The definition of property
graph is as follows:

Definition 1 (Property Graph). A property graph is a directed,
edge-labeled, attributed multigraph ğº = (ğ‘‰ , ğ¸, ğœ†, ğœ‡) where ğ‘‰ is a set
of nodes (or vertices), ğ¸ is a set of directed edges, ğœ† : ğ¸ â†’ Î£ is an
edge labeling function assigning a label from the alphabet Î£ to each
edge and ğœ‡ : (ğ‘‰ âˆª ğ¸) Ã— ğ¾ â†’ ğ‘† is a function assigning key(from
K)-value(from S) pairs of properties to the edges and nodes.

Given the definition of property graph, RPG is defined as follows:
Definition 2 (RESTful-service Property Graph). A RPG is a

mixed,edge-labeled, attributed multigraph ğº = (ğ‘‰ , ğ¸, ğœ†, ğœ‡) with:

â€¢ ğ‘‰ = ğ‘‰ğ‘ ğ‘â„ğ‘’ğ‘šğ‘ âˆª ğ‘‰ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘›
â€¢ ğ¸ = ğ¸ğ‘œğ‘  âˆª ğ¸ğ‘ ğ‘œ âˆª ğ¸ğ‘ ğ‘  âˆª ğ¸ğ‘œğ‘œ
â€¢ ğœ† = ğœ†ğ‘ ğ‘œ âˆª ğœ†ğ‘ ğ‘ 
â€¢ ğœ‡ = ğœ‡ğ‘ ğ‘â„ğ‘’ğ‘šğ‘ âˆª ğœ‡ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘›

where ğ‘‰ğ‘ ğ‘â„ğ‘’ğ‘šğ‘ is a set of schema nodes, ğ‘‰ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘› is a set of operation
nodes, ğ¸ğ‘œğ‘  is a set of directed edges pointing from a node in ğ‘‰ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘›
to a node in ğ‘‰ğ‘ ğ‘â„ğ‘’ğ‘šğ‘, ğ¸ğ‘ ğ‘œ is a set of directed edges each of pointing from
a node in ğ‘‰ğ‘ ğ‘â„ğ‘’ğ‘šğ‘ to a node in ğ‘‰ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘›, ğ¸ğ‘ ğ‘  is a set of undirected
edges connecting two nodes in ğ‘‰ğ‘ ğ‘â„ğ‘’ğ‘šğ‘, ğ¸ğ‘œğ‘œ is a set of undirected edges
connecting two nodes in ğ‘‰ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘›, ğœ†ğ‘ ğ‘œ is a set of labeling functions
to label edges in ğ¸ğ‘ ğ‘œ , ğœ†ğ‘ ğ‘  is a set of labeling functions to label edges
in ğ¸ğ‘ ğ‘  , ğœ‡ğ‘ ğ‘â„ğ‘’ğ‘šğ‘ is a set of functions to assign properties to nodes in
ğ‘‰ğ‘ ğ‘â„ğ‘’ğ‘šğ‘, and ğœ‡ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘› is a set of functions to assign properties to
nodes in ğ‘‰ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘›

Note that RPG is not exactly a property graph because it is a
mixed graph while the latter is a directed graph and this is the only
difference. In the following of this paper, for simplicity, we use ğ‘œğ‘¥
to represent an element of ğ‘‰ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘›, ğ‘ ğ‘¥ to represent an element
of ğ‘‰ğ‘ ğ‘â„ğ‘’ğ‘šğ‘, ğ‘’ğ‘œğ‘  to represent an element of ğ¸ğ‘œğ‘  and so on.
Design & Rationale. Here we explain the details and rationale
for the design of RPG. â¶ The usage of ğ‘‰ğ‘ ğ‘â„ğ‘’ğ‘šğ‘ and ğ‘‰ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘›
are straight forward, we need them to represent the schemas and
operations. â· As for edges, the edges in ğ¸ğ‘œğ‘  and ğ¸ğ‘ ğ‘œ are directed to
represent whether an operation produces or consumes an object of
a schema. For example, the edge ğ‘’ğ‘œ1ğ‘ 1 = (ğ‘œ1, ğ‘ 1) means operation
ğ‘œ1 returns an object of schema ğ‘ 1 as its response. Correspondingly,
the edge ğ‘’ğ‘ 1ğ‘œ1 = (ğ‘ 1, ğ‘œ1) means operation ğ‘œ1 requires an object or
at least one property of the object of schema ğ‘ 1 in its parameter(s).
The edges in ğ¸ğ‘ ğ‘  represent the equivalence relation between two
properties from two different schemas. In the running example,
the property id in the Pet schema is referring to the same thing

Dynamic RPG UpdatingEdge AdditionEdge DeletionTest Case GenerationCall Sequence GenerationOperation Parameter GenerationInitial RPGPOSTcreateGETreadproperty:typeObjectTest SequencesFailures400200500Test CasesPOSTGETPUTDELGETPOSTPUTResponses200200200200200500400Â§3.3Â§3.2Â§3.1MorestRefined RPGPOSTcreateGETreadObjectproperty:typeInitial RPG BuildingNodes ExtractionEdge AnalysisMorest: Model-based RESTful API Testing with Execution Feedback

ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA

as the property petId in the Order schema. We denote the edge
connecting these two schemas as ğ‘’ğ‘ ğ‘ğ‘’ğ‘¡ ğ‘ ğ‘œğ‘Ÿğ‘‘ğ‘’ğ‘Ÿ = {ğ‘ ğ‘ğ‘’ğ‘¡ , ğ‘ ğ‘œğ‘Ÿğ‘‘ğ‘’ğ‘Ÿ }. The
edges in ğ¸ğ‘œğ‘œ are used to connect two operations if they are under
the same API endpoint. In the running example, the operation
getOrderById and the operation deleteOrder are connected by
this type of edge. â¸ Only the edges in ğ¸ğ‘ ğ‘œ and ğ¸ğ‘ ğ‘  are labeled by
functions in ğœ†. The labels for ğ¸ğ‘ ğ‘œ are vectors of property names
showing which exact properties of a schema are used as parameters
for an operation. Note that the empty vectors are ignored in Fig. 4.
The labels for ğ¸ğ‘ ğ‘  are vectors of tuples, where each tuple is pair of
properties with equivalence relations from two different schemas.
The edges in ğ¸ğ‘œğ‘œ requires no labelling since they can only indicate
two operations belong to the same API endpoint. The labelling for
ğ¸ğ‘œğ‘  is ignored for two reasons. First, labelling edges is an error-
prone process, especially when the OpenAPI specification is poorly
written, the more edges we label, the more errors we may introduce.
Second, comparing with the edges in ğ¸ğ‘ ğ‘œ , the edges in ğ¸ğ‘œğ‘  are less
important for successfully requesting API operations because the
former ones directly affect the input parameters of the operations.
â¹ Naturally, the functions to assign properties to the nodes (ğœ‡)
correspond to the process of parsing the OpenAPI specification and
extracting data from it.

With the OpenAPI specifications, Morest can build the initial
RPG consisting of nodes and edges together with their properties
or labels according to Def. 2. This initial RPG, like shown in Fig. 4a,
may contain false edges or miss some edges and Morest will refine
it with dynamically collected feedback later on.

RPG vs ODG. Here we compare the RPG model with the ODG
model. The first difference is that ODG has only the operation nodes
and their producer-consumer dependencies as edges while RPG
has more types of nodes and edges. The second difference is that
RPG allows nodes and edges to have properties and labels. Both
of the differences indicate that RPG can describe more details of
the RESTful services. The additional details captured by RPG can
help to generate longer call sequences and provide the information
needed for dynamic self-updating. For example, for the RPG shown
in Fig. 4b, the connection between the Pet and Order schemas
indicates that Order.petId refers to the same thing as Pet.id.
With this information, we can infer that the Order.petId can be
used to query getPetById and therefore generate the call sequence
(placeOrder, getPetById, findPetsByStatus), which cannot be
generated only with the dependencies between operations in an
ODG.

3.2 Test Case Generation
Here we introduce how Morest uses RPG for test case generation.
In general, this requires two steps: first, Morest traverses the RPG
and aggregates visited operations to form call sequences (Call Se-
quence Generation); second, Morest generates concrete inputs for
the APIs in the sequences to build test cases (Operation Parameter
Generation).
Call Sequence Generation. Algo. 1 shows how Morest gener-
ates call sequences where S is a set of call sequences and S =
(ğ‘œ, ğ‘œ1, ..., ğ‘œğ‘›) is a single call sequence made up of a vector of op-
erations. The function call_sequence_generation is the start of the
whole process.

(a) The Initial RPG

(b) The Refined RPG

Figure 4: The RESTful-service Property Graphs (RPGs) for
the Petstore running example.

In general, the idea of this algorithm is to visit every schema in
the RPG and collect the operations related to the schema to build up
call sequences. While accessing a schema, we can recursively tra-
verse other schemas which are connected to the current one, collect
the related operations to build new call sequences and concatenate
the new call sequences and the existing call sequences to build
longer sequences. After we have generated the call sequences, we
further apply a crud_filter to filter out the call sequences violating
the CRUD rules. A call sequence is said to violate the CRUD rule
if it encounters any of the two situations: for the same schema, a
delete operation appears on the sequence before another operation;
for the same schema, any of the read, update or delete operation
appears on the sequence before the first create operation.

In particular, when we visit a schema ğ‘  (line 8), we first need
to identify two sets of operations: the operations which produce
schema ğ‘  in their responses (ğ‘‚ğ‘œğ‘¢ğ‘¡ ) and the operations which con-
sume schema ğ‘  or its properties as their input parameters (ğ‘‚ğ‘–ğ‘›).
With ğ‘‚ğ‘œğ‘¢ğ‘¡ and ğ‘‚ğ‘–ğ‘›, we can use their Cartesian product to build a
set of call sequences (Sğ‘›ğ‘’ğ‘¤) with the length of two (line 16). Then,
if we already have a set of call sequences (S), we can try to concate-
nate them and the new call sequences to build longer sequences
(line 17). Two sequences can be concatenated if the last operation
of one of them is the same as the first operation of the other one

GETgetPetByIdPOSTaddPetGETfindPetsByStatusGETgetOrderByIdPOSTplaceOrderDELETEdeleteOrderPetid: int name: string status: stringOrderid: int petId: int status: string<status><status><petId>operation nodeschema nodeinfeasible edgedynamically added edgeLegendGETgetPetByIdPOSTaddPetGETfindPetsByStatusGETgetOrderByIdPOSTplaceOrderDELETEdeleteOrderPetid: int name: string status: stringOrderid: int petId: int status: string<status><petId><id><(Order.petId, Pet.id)>ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA

Yi Liu, Yuekang Li, Gelei Deng, Yang Liu, Ruiyuan Wan, Runchao Wu, Dandan Ji, Shiheng Xu, and Minli Bao

Algorithm 1: Call Sequence Generation

1 def call_sequence_generation(ğ‘‰ , ğ¸, ğœ†, ğœ‡):
2

S â† âˆ…;
for ğ‘  âˆˆ ğ‘‰ğ‘ ğ‘â„ğ‘’ğ‘šğ‘ do

S â† S âˆª ğ‘£ğ‘–ğ‘ ğ‘–ğ‘¡ (ğ‘ , âˆ…, ğ‘‰ğ‘ ğ‘â„ğ‘’ğ‘šğ‘, âˆ…);

S â† ğ‘ğ‘Ÿğ‘¢ğ‘‘_ğ‘“ ğ‘–ğ‘™ğ‘¡ğ‘’ğ‘Ÿ ( S);
return S;

7
8 def visit(ğ‘ , ğ‘‰ğ‘£ğ‘–ğ‘ ğ‘–ğ‘¡ğ‘’ğ‘‘_ğ‘ ğ‘â„ğ‘’ğ‘šğ‘, ğ‘‰ğ‘ ğ‘â„ğ‘’ğ‘šğ‘, S):
9

ğ‘‚ğ‘œğ‘¢ğ‘¡ â† {ğ‘œ âˆˆ ğ‘‰ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘› | (ğ‘œ, ğ‘ ) âˆˆ ğ¸ğ‘œğ‘  };
ğ‘‚ğ‘–ğ‘› â† {ğ‘œ âˆˆ ğ‘‰ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘› | (ğ‘ , ğ‘œ) âˆˆ ğ¸ğ‘ ğ‘œ };
if ğ‘‚ğ‘–ğ‘› = âˆ… âˆ¨ ğ‘‚ğ‘œğ‘¢ğ‘¡ = âˆ… then

return S;

if {ğ‘’ğ‘ ğ‘  âˆˆ ğ¸ğ‘ ğ‘  | ğ‘’ğ‘ ğ‘  = {ğ‘ , ğ‘ â€² } âˆ§ ğ‘ â€² â‰  ğ‘ , ğ‘ â€² âˆˆ ğ‘‰ğ‘ ğ‘â„ğ‘’ğ‘šğ‘ } = âˆ… then

return S;

ğ‘‰ğ‘£ğ‘–ğ‘ ğ‘–ğ‘¡ğ‘’ğ‘‘_ğ‘ ğ‘â„ğ‘’ğ‘šğ‘ â† ğ‘‰ğ‘£ğ‘–ğ‘ ğ‘–ğ‘¡ğ‘’ğ‘‘_ğ‘ ğ‘â„ğ‘’ğ‘šğ‘ âˆª {ğ‘  };
Sğ‘›ğ‘’ğ‘¤ = ğ‘‚ğ‘œğ‘¢ğ‘¡ Ã— ğ‘‚ğ‘–ğ‘›;
S â† ğ‘ğ‘œğ‘›ğ‘ğ‘ğ‘¡ ( S, Sğ‘›ğ‘’ğ‘¤ );
for ğ‘ â€² âˆˆ {ğ‘ â€² âˆˆ ğ‘‰ğ‘ ğ‘â„ğ‘’ğ‘šğ‘ | ( âˆƒ ğ‘’ğ‘ ğ‘ â€² âˆˆ ğ¸ğ‘ ğ‘  ) [ğ‘’ğ‘ ğ‘ â€² = {ğ‘ , ğ‘ â€² } âˆ§ ğ‘  â‰ 
ğ‘ â€²] âˆ§ ğ‘ â€² âˆ‰ ğ‘‰ğ‘£ğ‘–ğ‘ ğ‘–ğ‘¡ğ‘’ğ‘‘_ğ‘ ğ‘â„ğ‘’ğ‘šğ‘ } do

S â† S âˆª ğ‘£ğ‘–ğ‘ ğ‘–ğ‘¡ (ğ‘ â€², ğ‘‰ğ‘£ğ‘–ğ‘ ğ‘–ğ‘¡ğ‘’ğ‘‘_ğ‘ ğ‘â„ğ‘’ğ‘šğ‘, ğ‘‰ğ‘ ğ‘â„ğ‘’ğ‘šğ‘, S);

return S;

21
22 def concat(S, Sğ‘›ğ‘’ğ‘¤ ):
23

for S = (ğ‘œ1, ..., ğ‘œğ‘›) âˆˆ S do

for Sâ€² = (ğ‘œğ‘œğ‘¢ğ‘¡ , ğ‘œğ‘–ğ‘›) âˆˆ Sğ‘›ğ‘’ğ‘¤ do

if ğ‘œğ‘› = ğ‘œğ‘œğ‘¢ğ‘¡ then

S â† S âˆª { (ğ‘œ1, ..., ğ‘œğ‘›, ğ‘œğ‘–ğ‘›) };

if ğ‘œğ‘–ğ‘› = ğ‘œ1 then

S â† S âˆª { (ğ‘œğ‘œğ‘¢ğ‘¡ , ğ‘œ1, ..., ğ‘œğ‘›) };

return S;

30
31 def crud_filter(S):
for S âˆˆ S do
32

if not crud_valid(S) then
S â† S âˆ’ {S};

return S;

3

4

5

6

10

11

12

13

14

15

16

17

18

19

20

24

25

26

27

28

29

33

34

35

(line 22). After that, if the current schema node is connected to
another schema node which has not been visited in the current
iteration (line 19), we will visit that schema and repeat the same
process until we run out of schema nodes. Note that each schema
node is visited only once per iteration to avoid infinite loops.

In the running example, with the RPG in Fig. 4b, assume we are
now visiting the Pet node and the Order node is not visited yet. For
the Pet node, its ğ‘‚ğ‘œğ‘¢ğ‘¡ is {addPet, getPetById, findPetsByStatus}
and its ğ‘‚ğ‘–ğ‘› is { getPetById, findPetsByStatus}. The Cartesian
product of ğ‘‚ğ‘œğ‘¢ğ‘¡ and ğ‘‚ğ‘–ğ‘› can generate six new call sequences in-
cluding (getPetById, findPetsByStatus) etc. (line 16). Since we
do not have any existing call sequences so far, we do not need to
perform call sequence concatenation (line 17). Then, because the
Order node is connected to the Pet node and it has not been visited,
we will visit it and generate new call sequences similarly (line 19).
One of the newly generated call sequences for the Order node is
(placeOrder, getPetById) (line 16). Now, since we already have
generated some sequences when we visit the Pet node, we can
try to concatenate them with the newly generated call sequences
for the Order node (line 17). In this example, we can generate
the call sequence (placeOrder, getPetById, findPetsByStatus).
This demonstrates how Morest generates call sequences.

Note that, in some cases, there are standalone operations that are
not connected to any schemas. For clarity, we omit handling these
cases in the algorithm. But in our implementation, the standalone
operations are included as single-element call sequences.

Operation Parameter Generation. The generated call sequences
cannot be used directly for testing since they are just sequences of
operations without concrete parameter values. For a given oper-
ation, if its input parameters are not from the responses of other
operations on the same test sequences, they are decided as follows:
if the operation has been called correctly before, Morest assigns
a high chance of using the parameters of the last successful run,
else if the OpenAPI specifications have specified the valid ranges of
values for the operation, Morest has a high chance of selecting val-
ues from the valid ranges, otherwise, Morest will just use random
values. Given an object schema, MOREST recursively traverses the
schema to generate values for the object attributes according to
their parameter types. If the parameter is of a basic type (e.g., string
and int), we will concretize the value accordingly. If the parameter
is an object or a list, we will jump in and recursively deduce the
basic parameter type.

An important detail worth discussing is that the parameters for
a sequence of operations is not generated all at once. Instead, these
parameters are generated on the fly. Because if the input parameter
for an operation is based on the response of a previous operation,
we will need to wait for the previous operation to finish execution
to get the needed parameter values.

3.3 Dynamic RPG Updating
The initial RPG generated with the OpenAPI specifications may
contain errors. For example, the red lines in Fig. 4a are infeasible
edges, and the dashed lines in Fig. 4b are the missing edges for the
initial RPG. This is often due to ambiguities in the specifications. For
example, although a human can quickly recognize that the petId
property of Order refers to the same thing as the id property of
Pet, it is hard to use rules and heuristics to reconstruct this relation.
To address this problem, Morest dynamically fixes the RPG with
execution feedback.

Edge Addition In Morest, new edges are added to a RPG in three
scenarios: â¶ The most straightforward case is where the response
value of an API aligns with a certain schema but it is not docu-
mented in the specification. For example, in Fig. 1, the response of
the addPet operation is not documented. However, after addPet is
corrected during the testing, it will respond with the newly created
Pet object. Morest will notice that the properties of the object re-
turned by addPet matches the properties in the Pet schema. Then
Morest can add the edge (addPet,Pet) into ğ¸ğ‘œğ‘  . â· The edges of
ğ¸ğ‘ ğ‘  are added after the collection of execution feedback. For two
schema nodes ğ‘ 1 and ğ‘ 2 if both of them are related to an operation
node ğ‘œ, Morest makes the assumption that ğ‘ 1 and ğ‘ 2 share at least
one property in common but Morest cannot decide which property
is shared in the RPG building stage. During the execution of the
test cases, Morest may encounter some sequences involving both
the objects of ğ‘ 1 and the objects of ğ‘ 2. With the responses of these
sequences, Morest can compare the concrete values of properties
between the two types of objects. As far as the value of a property
from an object of ğ‘ 1 can match the value of multiple properties from

Morest: Model-based RESTful API Testing with Execution Feedback

ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA

Table 1: Open source RESTful services

4.1 Experiment Setup

Subjects
Petstore [39]

SpreeCommerce [7] 42,385
46,321
4,760
1,525
315,120

Bitbucket [10]
LanguageTool [7]
FeatureService [7]
Magento [7]

LoC Language Operation Endpoint Source
OpenAPI
20
989
EMB
35
Bitbucket
32
EMB
5
EMB
18
EMB
47

Java
Ruby
Java
Java
Java
PHP

18
31
23
5
11
39

an object of ğ‘ 2, the relation between ğ‘ 1 and ğ‘ 2 remains undecided.
Until we find a property whose value only matches with one prop-
erty from the other set of objects, we can tell that these two schemas
share this common property. For example, both Order and Pet con-
nect with getPetById (Fig. 4a). Morest can generate multiple test
cases with the sequence of (getOrderById, getPetById). Suppose
these test cases yield the following two pairs of orders and pets:
({id: 1, petId: 1, status: "succ"}, {id: 1, name: "cat",
status: "sold"}) and ({id: 2, petId: 4, status: "succ"},
{id: 4, name: "dog", status: "sold"}). After the generation
of the first pair of order and pet, Morest cannot infer the relation
since the id of the pet equals to both id and petId of the order.
Morest can only infer that Pet.id is equal to either Order.id
or Order.petId. Nevertheless, after the second pair is generated,
Morest can draw the conclusion of Pet.id equals to Order.petId.
â¸ The last scenario is where the edges belonging to ğ¸ğ‘ ğ‘œ and ğ¸ğ‘œğ‘  are
added based on the inferences used for building ğ¸ğ‘ ğ‘  . For example,
after Morest learns the fact that Pet.id equals to Order.petId, it
propagates this information to other nodes, say getPetById. Then,
Morest can link the petId parameter needed by getPetById with
the property Pet.id despite that they have different names. As a
result, Morest can add the edge (Pet, getPetById) to ğ¸ğ‘ ğ‘œ as shown
in Fig. 4b.

Edge Deletion For an operation, if its inputs are from other op-
erations on the same call sequence (i.e. not generated randomly)
and it fails to execute correctly after Î˜ tries, then the edge pointing
from the respective schema to this operation is temporarily recog-
nized as infeasible. Empirically, we find that increasing the value
of Î˜ can help to reduce the number of falsely deleted edges but the
overall performance is not affected too much since we are wasting
more time on the truly infeasible edges and even if a benign edge
is deleted, Morest always has the chance of adding it back.

4 IMPLEMENTATION & EVALUATION
We have implemented Morest based on Python 3.9.0 with 11,659
lines of code and conducted experiments to evaluate the perfor-
mance of Morest. We aim to answer the following research ques-
tions with the evaluation:
RQ1 (Coverage) How is the code coverage and operation explo-
ration capability of Morest?
RQ2 (Bug Detection) How is the bug detection capability of Mor-
est?
RQ3 (Ablation Study) How do RPG guidance and dynamic RPG
updating affect the performance of Morest separately?

Evaluation Datasets. We built the evaluation benchmark with
six open source RESTful services shown in Table 1. In this bench-
mark, four services were selected from the Evomaster Benchmark
(EMB) [7] 3. In addition, Petstore (the official demo of OpenAPI spec-
ification) and Bitbucket (a popular online version control system
with complicated business scenarios) were also included.

From Table 1, we can see that the target RESTful services are
diverse in sizes, features and are implemented with different pro-
gramming languages. Bitbucket is not strictly open source since it
is a commercial product. However, we have access to its released
.jar file to collect line coverage and conduct detailed bug analysis.
Evaluation Baselines. We use three state-of-the-art blackbox REST-
ful service testing techniques as baselines to study the performance
of Morest.
(1) Evomaster-bb: Evomaster [7] is a search-based whitebox
technique. In our evaluation, we disabled its code instrumenta-
tion (only works for Java programs) and database monitoring
modules to turn it into blackbox mode (named as Evomaster-
bb). It uses various heuristics to generate call sequences ac-
cording to the OpenAPI specifications. Thus, Evomaster-bb
represents the heuristic-based approach.

(2) Resttestgen: Resttestgen [47] is a blackbox technique
which generates Operation Dependency Graphs (ODGs) from
OpenAPI specifications to guide the call sequence generation.
Resttestgen represents the top-down approach.

(3) Restler: Restler is a blackbox technique which build call
sequences by appending new API operations according to exe-
cution feedback. Restler represents the bottom-up approach.

Evaluation Criteria. We use three criteria to evaluate Morest
and the baselines.
(1) Code Coverage: Code coverage can reflect the exploration
capability of the techniques. In the experiments, we use line
coverage since it is the finest granularity we can get with our
current tools (PHPCoverage [5] for PHP, CoverBand [1] for
Ruby and JaCoCo [2] for Java).

(2) Successfully Requested Operations: In HTTP, responses
with status code 2xx are successful responses [37]. We use
the number of successfully requested operations (SROs) as a
criterion because it can reflect whether a technique can gen-
erate valid requests to test deeper code logic of the RESTful
service and valid requests are partially the results of correct call
sequences.

(3) Bugs: The goal of testing is to expose bugs, so the number of
detected bugs is a necessary criterion. In the context of RESTful
service, a failure is considered to happen when an operation
returns 5xx status code and a bug can be related to many failures.
We manually classified the failures into unique bugs in the
experiments according to response bodies, server logs, etc.

Evaluation Settings. For the open source RESTful services, we
hosted them on a local machine and ran each technique with three
time budgets â€” 1, 4 and 8 hour(s). The purpose is to evaluate how
the performance of these techniques change over time. To the best

3We only use the open source services available in EMB up to the time of writing this
paper.

ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA

Yi Liu, Yuekang Li, Gelei Deng, Yang Liu, Ruiyuan Wan, Runchao Wu, Dandan Ji, Shiheng Xu, and Minli Bao

of our knowledge, the time budget of 8 hours is the longest time
budget used in RESTful service testing research. After each round,
we tear down and restore the environment (e.g., docker containers,
self-hosted virtual machines) to guarantee the consistence of all
RESTful services. In addition, we repeated all experiments for 5
times to mitigate randomness and applied Mann-Whitney U test
and ^ğ´12 [3, 46] calculation for statistical tests. Thus, we conducted
a total number of 1,440, i.e., 6 projects * 6 settings * 8 (hour time
budget for one round) * 5 repetitions, CPU hours of experiments.

4.2 Coverage (RQ1)
To comprehensively compare different approaches, Evomaster-
bb, Resttestgen, and Restler are directly adopted from the prior
work [7, 11, 47]. Besides, to avoid the side effect of service under test,
we wrap six evaluation subjects into docker image [19] and restore
the corresponding image after each round. Table 2 presents the
statistical results of five runs. As suggested by the prior work [28],
the Mann-Whitney U test (with the confidence threshold ğ›¼ = 0.05)
is adopted here. Overall, we summarize our findings as follows.

Fig. 5 and Table 2 depict that 4 Morest achieves competitive
performance regarding both code coverage and successfully re-
quested operations, significantly outperforming search-based, and
model-based approaches in 5/6 RESTful services (bold numbers
in Table 2). Fig. 6a demonstrates unique successfully requested
operations by each tool. We can figure out that Morest covers
the most operations by generating valid call sequences following
producer-consumer dependencies. Therefore, existing experimental
result demonstrates the exploration effectiveness of Morest re-
garding given coverage criteria (code coverage increased by 26.16%
- 103.24%, successfully requested operations improved by 152.66% -
232.45%). On the other hand, it presents the robustness of Morest
gained by RPG guidance and RPG updating fashion (experiment
results are statistically significant).

Further, we conduct an in-depth analysis of the generated test se-
quences by all approaches to figure out why all approaches achieve
the same number of successfully requested operations. Taking the
LanguageTool as an example, we find that all approaches could
not cover three operations getWords, addWord and deleteWord.
Two parameters, username and APIKey), in those operations are
labeled as required parameters (i.e., username and APIKey must be
filled in each request when testing those operations). However, we
observe that the implementation of LanguageTool is different from
descriptions in the OpenAPI specification. Specifically, in the im-
plementation of LanguageTool, username and APIKey could not be
filled simultaneously; otherwise, the server behaves unexpectedly
and throws 5xx responses. As a consequence, we could imply that
the gap between RESTful API specifications and actual implemen-
tation of RESTful service could affect the effectiveness of RESTful
API testing.

4.3 Bug Detection (RQ2)
Subsequently, we analyze the bug (defined in Section 4.1) discover-
ing the capability of each approach. Table 3 presents the statistical
results of the averaged bugs detection with running tools for 8

4Due to page limitation, we leave experiment result (code coverage and successfully
requested operations), for 1 hour and 4 hours, in our website [4].

hours each round. Since one bug can be detected several times
during testing, we only record the number of unique bugs for all
approaches. Overall, we summarize our findings as follows.

First, in those baselines, Evomaster-bb, Restler, and Resttest-
gen outperform each other in different subjects. We manually an-
alyze the test sequences generated by baseline and find that â¶
Restler could sufficiently explore all call sequences theoretically,
however, we have observed that massive invalid call sequences
make Restler inefficient;â· Evomaster-bb heuristically generates
redundant call sequences to make it inefficient;â¸ Resttestgen is
trapped by infeasible call sequences generated from the operation
dependency graph, which limit its performance.

Besides, as shown in Table 3, Morest detects the most bugs (bold
numbers in Table 3), and statistically outperforms other baselines
on testing RESTful API services. Specifically, Fig. 6b indicates that
Morest could detect unknown 13 bugs by existing approaches. It
not only shows the comparative performance in bug finding but
also the Morestâ€™s robustness.

Similarly to Section 4.2, we manually perform a comprehen-
sive study in LanguageTool to figure out why all approaches find
identical bugs. We find that due to the gap between RESTful API
specification and the actual implementation of RESTful service (see
detail description in Section 4.2), all approaches get 5xx responses
by following the parameterâ€™s specifications (e.g., word_size is de-
fined by the string type while implemented by the integer type)
in the LanguageToolâ€™s specification. This indicates that RESTful
API testing could help developers to identify the incompatibility be-
tween the RESTful API specifications and actual implementations.

Case Study. Two bugs, discovered by Morest, have been con-
firmed and fixed by the developers of BitBucket. We conduct a
case study to find out how Morest trigers those bugs. Bitbucket
is a Git-based source code repository hosting service owned by
Atlassian. Bitbucket Server [9] is the self-host service provided
by Atlassian that allows users to do unlimited API queries to the
target server. During the testing of Bitbucket, we identified the
following call sequence that triggers Internal Server Error with 500
status code. In particular, (1) create a project at /rest/.../projects
endpoint through POST operation. The project information can be
further retrieved by GET request on the same endpoint. (2) create
a repository in the project at /rest/.../{projectKey}/repos endpoint
through POST operation, where the {projectKey} parameter is de-
fined in the first step as a parameter. (3) A further GET query on
/rest/.../repos/{repositorySlug}/ commits with parameters {"path":
"test_string"} triggers internal server error. When debugging mode
is enabled, the bug message is printed out: "com.atlassian.bitbucket.
scm.CommandFailedException". In summary, both a project and a
repository should be created firstly to trigger this bug. With the RPG
guidance and dynamic RPG updating, Morest could adaptively
generate such call sequences.

4.4 Ablation Study (RQ3)
To investigate how RPG and dynamic RPG updating contributes to
boosting the testing effectiveness of Morest through high-level
guidance and adaptive updating, we perform a ablation study on
each component. To study the contributions separately, we imple-
ment two variants of Morest as following (1) Morest-NO-RPG by

Morest: Model-based RESTful API Testing with Execution Feedback

ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA

(a) PetStore

(b) SpreeCommerce

(c) BitBucket

(d) LanguageTool

(e) FeatureService

(f) Magento

Figure 5: Comparing with baselines in terms of code coverage (ğœ‡ğ¿ğ‘‚ğ¶)
Table 2: Performance of Morest over Evomaster-bb, Resttestgen, and Restler in terms of both the code coverage (ğœ‡ğ¿ğ‘œğ¶)
and successfully requested operations (SRO). We run this experiment 5 times (8 hours each time) and highlight statistically
significant results in bold. (We calculate the average increased number by (# ğ‘œ ğ‘“ Morest)âˆ’(# ğ‘œ ğ‘“ ğ‘ğ‘ğ‘ ğ‘’ğ‘™ğ‘–ğ‘›ğ‘’)

.)

# ğ‘œ ğ‘“ ğ‘ğ‘ğ‘ ğ‘’ğ‘™ğ‘–ğ‘›ğ‘’

Subjects

Petstore
SpreeCommerce
Bitbucket
LanguageTool
FeatureService
Magento
Average Increased (%)

Average Code Coverage (LoC)

Morest
ğœ‡ğ¿ğ‘‚ğ¶
763.20
7182.00
2552.60
935.00
360.00
45759.00
0.00

Evomaster-bb
^ğ´12
1.00
1.00
1.00
1.00
1.00
1.00
-

ğœ‡ğ¿ğ‘‚ğ¶
751.80
2428.80
721.80
932.80
205.00
26912.00
80.12

Resttestgen
^ğ´12
ğœ‡ğ¿ğ‘‚ğ¶
1.00
717.00
1.00
2036.00
1.00
457.00
1.00
930.8
1.00
152.00
1.00
24024.40
-
103.24

Restler

ğœ‡ğ¿ğ‘‚ğ¶
739.00
5753.80
1078.80
925.20
204.00
36933.00
26.16

^ğ´12
1.00
1.00
1.00
1.00
1.00
1.00
-

Average # of Successfully Requested Operations (SRO)
Restler

Morest Evomaster-bb Resttestgen
^ğ´12
1.00
1.00
1.00
0.50
1.00
1.00
-

ğœ‡ğ‘†ğ‘…ğ‘‚
14.00
1.00
2.00
1.00
6.00
8.00
184.42

ğœ‡ğ‘†ğ‘…ğ‘‚
13.00
1.00
2.00
1.00
4.40
6.00
232.45

ğœ‡ğ‘†ğ‘…ğ‘‚
20.00
18.40
15.00
1.00
18.00
18.60
0.00

^ğ´12
1.00
1.00
1.00
0.50
1.00
1.00
-

ğœ‡ğ‘†ğ‘…ğ‘‚
18.00
1.00
1.00
1.00
9.00
6.00
152.66

^ğ´12
1.00
1.00
1.00
0.50
1.00
1.00
-

Table 3: Comparing with baseline in terms of the num-
ber of detected bugs. (Values in bold indicate statistically
significant differences between Morest, Evomaster-bb,
Resttestgen, and Restler.)

Subjects

Petstore
SpreeCommerce
Bitbucket
LanguageTool
FeatureService
Magento
Average Increased (%)

Average Detected Bugs (#)
Morest Evomaster-bb Resttestgen
^ğ´12
1.00
1.00
1.00
0.50
0.67
1.00
-

ğœ‡#
0.00
0.00
0.00
3.00
11.60
6.00
111.65

ğœ‡#
3.80
0.00
0.00
3.00
6.00
1.00
215.94

ğœ‡#
9.00
3.00
2.00
3.00
12.00
14.60
0.00

^ğ´12
1.00
1.00
1.00
0.50
1.00
1.00
-

Restler
ğœ‡# ^ğ´12
1.00
8.00
1.00
0.00
1.00
0.00
0.50
3.00
1.00
10.00
1.00
10.00
-
40.64

disabling RPG guidance, (2) Morest-RPG-ONLY by removing the
dynamic RPG updating part. The results are averaged using five

runs (with time budget one hour) to avoid the statistics bias. Fig. 7a
presents normalized code coverage of baselines on our datasets
(To better visualization and understanding, we normalize the code
). Fig. 7b shows
coverage by ğ‘›ğ‘œğ‘Ÿğ‘šğ‘ğ‘™ğ‘–ğ‘§ğ‘’ğ‘‘_ğ‘ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘ğ‘”ğ‘’ =
the number of detected bugs.

ğ¿ğ‘‚ğ¶
ğ¿ğ‘‚ğ¶ (Morest)

In general, as shown in Fig. 7, we observe that Morest outper-
forms Morest-RPG-ONLY and Morest-NO-RPG on both code cov-
erage and bug detection. In specific, we take Petstore as an example.
To cover more operations related to the â€™Petâ€™ schema, an instance
of pet should be firstly created by addPet. However, Morest-NO-
RPG fails to generate such call sequences, which restricts further
exploration during testing. Additionally, properties named status,
within both â€™Orderâ€™ (refers to the status of order) and â€™Petâ€™ (refers
to the status of pet) schemas, leading to invalid producer-consumer

MORESTEVOMASTERRESTTESTGENRESTLER200300400500600700800Time Budget1 Hr4 Hrs8 HrsCode Coverage (LOC)MORESTEVOMASTERRESTTESTGENRESTLER200030004000500060007000Code Coverage (LOC)MORESTEVOMASTERRESTTESTGENRESTLER5001000150020002500Code Coverage (LOC)MORESTEVOMASTERRESTTESTGENRESTLER924926928930932934936938940Code Coverage (LOC)MORESTEVOMASTERRESTTESTGENRESTLER150200250300350Code Coverage (LOC)MORESTEVOMASTERRESTTESTGENRESTLER200002500030000350004000045000Code Coverage (LOC)ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA

Yi Liu, Yuekang Li, Gelei Deng, Yang Liu, Ruiyuan Wan, Runchao Wu, Dandan Ji, Shiheng Xu, and Minli Bao

4.5 Threats To Validity
The first internal threat comes from the choices of configurable
options in the design. Currently, we empirically set the values for
these options and the actual values of the options used in the ex-
periments can be found on our website [4]. Although the choice
of configurable options can affect the performance of Morest, the
experiment results can demonstrate that at least with the current
set of option values, Morest can outperform state-of-the-art tech-
niques. Therefore, we leave the fine-tuning of these options as
future work. Another internal threat is that the current RPG model
can only reflect the APIs documented in the OpenAPI specifica-
tions. For undocumented APIs, a possible solution is to infer their
related schemes in an online manner by analyzing the feedback of
the testing process. Another possible solution is to use client-side
analysis techniques [31, 32, 49] to generate traffic between clients
and servers and analyze the traffic to infer the correct usage of the
undocumented APIs. We leave the support of undocumented APIs
as future work.

The external threats mainly come from the experiment settings.
The testing techniques evaluated in the experiments are random
by nature. To mitigate the random factors, we repeated each exper-
iment for five times and conducted statistical tests. Therefore, the
experiment results are statistically sound. To address the general-
ity concern, we chose a diverse dataset consisting of six RESTful
services with various sizes and features. Moreover, we chose open
source RESTful services so we can perform in-depth experiment
result analyses via scrutinizing the code coverage and classifying
the detected failures into unique bugs. Last but not the least, to
improve the fairness for technique comparison, we gave each tech-
nique a generous time budget of 8 hours while in [11] the longest
time budget is 5-hour and in [47] the time budget is 0.5-hour.

5 RELATED WORK
Instead of discussing all related works, we focus on the RESTful
service testing techniques, SOAP service testing techniques and
model-based testing techniques.

Blackbox RESTful service testing techniques. Several black-
box techniques were proposed to generate meaningful call se-
quences. Resttestgen [47] builds Operation Dependency Graphs
(ODGs) with the OpenAPI specifications to model RESTful ser-
vices and crafts call sequences via graph traversal. The quality of
the generated call sequences is limited by the quality of the Ope-
nAPI specifications which directly affect ODG building. Meanwhile,
Restler [11] builds call sequences with a bottom-up approach
which starts with single operation call sequences and gradually
extend the call sequences by appending more operations after trial
and error. Comparing to these techniques, Morest can enjoy both
high-level guidance and the flexibility of dynamic adjustments to
achieve better performance.

Other than call sequence generation, some blackbox techniques
focus on improving the operation input parameter generation [22,
24, 44]. These techniques utilize predefined inter-parameter con-
straints, input grammar, or mutators to generate diverse input
parameters for the test cases. Input parameter generation is orthog-
onal to call sequence generation, we plan to adopt advanced input
parameter generation in the future.

(a) Successfully Requested Operations (SRO)

(b) Bug detection

Figure 6: Venn diagrams showing both successfully re-
quested operations (SRO) and bug detection that Morest,
Evomaster-bb, Resttestgen and Restler individually
and together.

(a) Normalized average code coverage

(b) Average unique bug detection

Figure 7: The performance of Morest, Morest-NO-RPG
and Morest-RPG-ONLY on both normalized average code
coverage (ğœ‡ğ¿ğ‘‚ğ¶) and bug detection.

dependencies in RPG. The performance of Morest-RPG-ONLY is
limited by such cases. Thus, we can infer that the RPG guidance
and dynamic RPG updating can both boost the effectiveness of the
RESTful API testing process.

Besides, as we can see from Fig. 7, Morest achieves better per-
formance other approaches regarding both code coverage and bug
detection. In particular, Morest generates call sequences with the
guidance of RPG and dynamically updates RPG to adaptively im-
prove call sequences to obtain higher code coverage, which increas-
ing the possibility to detect bugs.

00000005640004028MORESTEVOMASTERRESTTESTGENRESTLER000000013100700014PetStoreSpreeCommerceBitBucketLanguageToolFeatureServiceMagento100.0100.0100.0100.0100.0100.093.276.142.042.068.793.094.769.245.323.445.479.2PetStoreSpreeCommerceBitBucketLanguageToolFeatureServiceMagento9.03.02.03.012.014.61.20.00.03.011.011.00.00.00.03.011.64.8ToolMORESTMOREST-NO-RPGMOREST-RPG-ONLYMorest: Model-based RESTful API Testing with Execution Feedback

ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA

Whitebox RESTful service testing techniques. Evomaster [7]
is a whitebox RESTful service testing technique which instruments
the target RESTful service and monitors its database to collect use-
ful execution feedback and data to guide the evolutionary algorithm
based test case generation. Comparing to the the blackbox tech-
niques, on the one hand, Evomaster is more effective in testing
deeper logic inside the RESTful service since it can collect and use
more information about the target service to guide the test case
generation. On the other hand, Evomaster can only instrument
Java/Scala/Kotlin based RESTful services and requires access to
the database, limiting its application to closed source projects or
projects implemented with other programming languages.

SOAP Testing Techniques Simple Object Access Protocol (SOAP)
is a standards-based web service access protocol first proposed by
Microsoft. Some previous works focus on testing SOAP [18] based
web services [15â€“17]. Specifically, some of them use Web Services
Description Language (WSDL) specifications to guide the testing
process [12, 23, 30, 33, 35, 43]. Despite the similarities, REST is
proposed to address the shortcomings of SOAP and is gaining more
popularity in recent years [21]. The fundamental service interaction
models in REST and SOAP are different. Therefore, testing RESTful
services requires different strategies.

Model-based testing techniques. Besides the techniques for REST-
ful API and SOAP service testing, model-based testing techniques [13,
14, 36, 48, 49] are also related to Morest. In general, these tech-
niques use models, say a finite-state machine [29], to describe the
system-under-test and generate tests by covering different states
in the model [45]. In particular, Palulu [8] is a technique devel-
oped based on Randoop [40], which uses a call-sequence model
to quickly generate legal but behaviorally-diverse tests for Java
classes. Paluluâ€™s intuition of using a model to guide the generation
of valid API call sequences is similar to Morestâ€™s. However, the
difference is that the model used in Morest is tailored for RESTful
API and it is dynamically updated during testing.

6 CONCLUSION
In this paper, we propose Morest â€” a model-based blackbox REST-
ful API testing technique. Morest learns from the OpenAPI speci-
fications to build a RESTful-service Property Graph (RPG), which
encodes both schema and API operation information. Morest can
use RPG to provide high level guidance for call sequence generation
and continuously refine the RPG with execution feedback. We eval-
uated Morest on 6 open source RESTful services and the results
showed that Morest can significantly outperform state-of-the-art
techniques in both coverage and bug detection.

ACKNOWLEDGEMENTS
This research is partially supported by the National Research Foun-
dation, Prime Ministers Office, Singapore under its National Cy-
bersecurity R&D Program (Award No. NRF2018NCR-NCR005-0001),
NRF Investigatorship NRFI06-2020-0022-0001, the National Research
Foundation through its National Satellite of Excellence in Trustwor-
thy Software Systems (NSOE-TSS) project under the National Cyber-
security R&D (NCR) Grant award no. NRF2018NCR-NSOE003-0001.
This research is supported by the Ministry of Education, Singapore
under its Academic Research Fund Tier 3 (MOET32020-0004). Any

opinions, findings and conclusions or recommendations expressed
in this material are those of the author(s) and do not reflect the
views of the Ministry of Education, Singapore.

REFERENCES
[1] danmayer/coverband: Ruby production code coverage collection and reporting

(line of code usage). https://github.com/danmayer/coverband.

[2] jacoco/jacoco: Java code coverage library. https://github.com/jacoco/jacoco.
[3] Mannâ€“whitney u test - wikipedia. https://en.wikipedia.org/wiki/Mann%E2%80%

93Whitney_U_test.

[4] Morest. https://sites.google.com/view/restful-morest/home.
[5] Php code coverage for your web/selenium automation Â· tech adventures by tarun
lalwani. https://tarunlalwani.com/post/php-code-coverage-web-selenium/.
[6] api blueprint. API Blueprint. A powerful high-level API description language for

web APIs., 2020.

[7] Andrea Arcuri. Restful api automated test case generation with evomaster. ACM

Trans. Softw. Eng. Methodol., 28(1), January 2019.

[8] Shay Artzi, Michael D. Ernst, Adam Kie. Zun, Carlos Pacheco Jeff, and H. Perkins-
mit Csail. Finding the needles in the haystack: Generating legal test inputs for
object-oriented programs. In In M-TOOS, page 2006, 2006.

[9] Atlassian.
[10] Atlassian. Bitbucket, 2020.
[11] V. Atlidakis, P. Godefroid, and M. Polishchuk. Restler: Stateful rest api fuzzing.
In 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE),
pages 748â€“758, 2019.

[12] C. Bartolini, A. Bertolino, E. Marchetti, and A. Polini. Ws-taxi: A wsdl-based
testing tool for web services. In 2009 International Conference on Software Testing
Verification and Validation, pages 326â€“335, 2009.

[13] Matteo Biagiola, Filippo Ricca, and Paolo Tonella. Search based path and input
data generation for web application testing. In International Symposium on Search
Based Software Engineering, pages 18â€“32. Springer, 2017.

[14] Matteo Biagiola, Andrea Stocco, Filippo Ricca, and Paolo Tonella. Diversity-
based web test generation. In Proceedings of the 2019 27th ACM Joint Meeting on
European Software Engineering Conference and Symposium on the Foundations of
Software Engineering, pages 142â€“153, 2019.

[15] Mustafa Bozkurt, Mark Harman, and Youssef Hassoun. Testing web services: A

survey. 01 2010.

[16] G. Canfora and M. Di Penta. Testing services and service-centric systems: chal-

lenges and opportunities. IT Professional, 8(2):10â€“17, 2006.

[17] Gerardo Canfora and Massimiliano Di Penta. Service-Oriented Architectures
Testing: A Survey, pages 78â€“105. Springer Berlin Heidelberg, Berlin, Heidelberg,
2009.

[18] Francisco Curbera, Matthew Duftler, Rania Khalaf, William Nagy, Nirmal Mukhi,
and Sanjiva Weerawarana. Unraveling the web services web: an introduction to
soap, wsdl, and uddi. Internet Computing, IEEE, 6:86 â€“ 93, 04 2002.
[19] Docker. Docker: Empowering App Development for Developers, 2020.
[20] H. Ed-douibi, J. L. CÃ¡novas Izquierdo, and J. Cabot. Automatic generation of test
cases for rest apis: A specification-based approach. In 2018 IEEE 22nd International
Enterprise Distributed Object Computing Conference (EDOC), pages 181â€“190, 2018.
[21] Roy Thomas Fielding and Richard N. Taylor. Architectural Styles and the Design
of Network-Based Software Architectures. PhD thesis, 2000. AAI9980887.
[22] Patrice Godefroid, Bo-Yuan Huang, and Marina Polishchuk. Intelligent REST API
Data Fuzzing, page 725â€“736. Association for Computing Machinery, New York,
NY, USA, 2020.

[23] S. Hanna and M. Munro. Fault-based web services testing. In Fifth International
Conference on Information Technology: New Generations (itng 2008), pages 471â€“476,
2008.

[24] RenÃ¡ta HodovÃ¡n, Ãkos Kiss, and Tibor GyimÃ³thy. Grammarinator: a grammar-
based open source fuzzer. In Proceedings of the 9th ACM SIGSOFT international
workshop on automating TEST case design, selection, and evaluation, pages 45â€“48,
2018.

[25] Amazon Inc. Amazon, 2020.
[26] Google Inc. Google, 2020.
[27] Twitter Inc. Twitter, 2020.
[28] George Klees, Andrew Ruef, Benji Cooper, Shiyi Wei, and Michael Hicks. Evaluat-
ing fuzz testing. In Proceedings of the 2018 ACM SIGSAC Conference on Computer
and Communications Security, pages 2123â€“2138. ACM, 2018.

[29] D. Lee and M. Yannakakis. Testing finite-state machines: state identification and

verification. IEEE Transactions on Computers, 43(3):306â€“320, 1994.

[30] Yin Li, Zhi-an Sun, and Jian-Yong Fang. Generating an automated test suite by
variable strength combinatorial testing for web services. Journal of Computing
and Information Technology, 24:271â€“282, 11 2016.

[31] Yi Liu. Jsoptimizer: an extensible framework for javascript program optimization.
In Joanne M. Atlee, Tevfik Bultan, and Jon Whittle, editors, Proceedings of the 41st
International Conference on Software Engineering: Companion Proceedings, ICSE
2019, Montreal, QC, Canada, May 25-31, 2019, pages 168â€“170. IEEE / ACM, 2019.

ICSE â€™22, May 21â€“29, 2022, Pittsburgh, PA, USA

Yi Liu, Yuekang Li, Gelei Deng, Yang Liu, Ruiyuan Wan, Runchao Wu, Dandan Ji, Shiheng Xu, and Minli Bao

[32] Yi Liu, Jinhui Xie, Jianbo Yang, Shiyu Guo, Yuetang Deng, Shuqing Li, Yechang
Wu, and Yepang Liu. Industry practice of javascript dynamic analysis on wechat
mini-programs. In 35th IEEE/ACM International Conference on Automated Software
Engineering, ASE 2020, Melbourne, Australia, September 21-25, 2020, pages 1189â€“
1193. IEEE, 2020.

[33] C. Ma, C. Du, T. Zhang, F. Hu, and X. Cai. Wsdl-based automated test data
generation for web service. In 2008 International Conference on Computer Science
and Software Engineering, volume 2, pages 731â€“737, 2008.

[34] Clovity Marketing. Bitbucket Vs. GitHub: Who Holdâ€™s Your Companyâ€™s Future?,

2020.

[35] Evan Martin, Suranjana Basu, and Tao Xie. Automated robustness testing of web

services. 01 2006.

[36] Ali Mesbah, Arie Van Deursen, and Danny Roest. Invariant-based automatic
testing of modern web applications. IEEE Transactions on Software Engineering,
38(1):35â€“53, 2011.

[37] Mozilla. Http response status codes.
[38] OpenAPI. OpenAPI Specification, 2020.
[39] OpenAPI. Swagger Petstore, 2020.
[40] Carlos Pacheco, Shuvendu K. Lahiri, Michael D. Ernst, and Thomas Ball. Feedback-
directed random test generation. In Proceedings of the 29th International Confer-
ence on Software Engineering, ICSE â€™07, page 75â€“84, USA, 2007. IEEE Computer
Society.

[41] RAML. RAML: The simplest way to model APIs, 2020.

[42] Marko Rodriguez and Peter Neubauer. The graph traversal pattern. 04 2010.
[43] H. M. Sneed and S. Huang. Wsdltest - a tool for testing web services. In 2006
Eighth IEEE International Symposium on Web Site Evolution (WSEâ€™06), pages 14â€“21,
2006.

[44] Michael Sutton, Adam Greene, and Pedram Amini. Fuzzing: brute force vulnera-

bility discovery. Pearson Education, 2007.

[45] Mark Utting, Alexander Pretschner, and Bruno Legeard. A taxonomy of model-
based testing approaches. Softw. Test. Verif. Reliab., 22(5):297â€“312, August 2012.
[46] AndrÃ¡s Vargha and Harold D. Delaney. A critique and improvement of the
cl common language effect size statistics of mcgraw and wong. Journal of
Educational and Behavioral Statistics, 25(2):101â€“132, 2000.

[47] E. Viglianisi, M. Dallago, and M. Ceccato. Resttestgen: Automated black-box
testing of restful apis. In 2020 IEEE 13th International Conference on Software
Testing, Validation and Verification (ICST), pages 142â€“152, Los Alamitos, CA, USA,
oct 2020. IEEE Computer Society.

[48] Bing Yu, Lei Ma, and Cheng Zhang. Incremental web application testing using
In 2015 Third IEEE Workshop on Hot Topics in Web Systems and

page object.
Technologies (HotWeb), pages 1â€“6. IEEE, 2015.

[49] Yan Zheng, Yi Liu, Xiaofei Xie, Yepang Liu, Lei Ma, Jianye Hao, and Yang Liu.
Automatic web testing using curiosity-driven reinforcement learning. In 43rd
IEEE/ACM International Conference on Software Engineering, ICSE 2021, Madrid,
Spain, 22-30 May 2021, pages 423â€“435. IEEE, 2021.

