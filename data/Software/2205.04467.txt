2
2
0
2

y
a
M
9

]
E
S
.
s
c
[

1
v
7
6
4
4
0
.
5
0
2
2
:
v
i
X
r
a

SOFTWARE—PRACTICE AND EXPERIENCE
Softw. Pract. Exper. 2016; 00:1–20
Published online in Wiley InterScience (www.interscience.wiley.com). DOI: 10.1002/spe

Architectural Partitioning and Deployment Modeling on Hybrid
Clouds

Sreekrishnan Venkateswaran1 and Santonu Sarkar2*

1IBM Corporation, India 2BITS Pilani K.K.Birla Goa Campus, Goa India

SUMMARY

The hybrid cloud idea is increasingly gaining momentum because it brings distinct advantages as a hosting
platform for complex software systems. However, there are several challenges that need to be surmounted
before hybrid hosting can become pervasive and penetrative. One main problem is to architecturally partition
workloads across permutations of feasible cloud and non-cloud deployment choices to yield the best-
ﬁt hosting combination. Another is to predict the effort estimate to deliver such an advantageous hybrid
deployment.
In this paper, we describe a heuristic solution to address the said obstacles and converge on the ideal hybrid
cloud deployment architecture, based on properties and characteristics of workloads that are sought to be
hosted. We next propose a model to represent such a hybrid cloud deployment, and demonstrate a method to
estimate the effort required to implement and sustain that deployment. We also validate our model through
dozens of case studies spanning several industry verticals and record results pertaining to how the industrial
grouping of a software system can impact the aforementioned hybrid deployment model.
Copyright © 2016 John Wiley & Sons, Ltd.

Received . . .

KEY WORDS: Hybrid cloud; CLIC; Architectural Partitioning; Workload; Hybrid Deployment

Complexity

1. INTRODUCTION

Cloud Computing [17], speciﬁcally Infrastructure as a service (IaaS), is a paradigm that supplies on-
demand compute capability with consumptive billing [7]. The on-demand capability consists of a set
of infrastructure units over which software systems can be deployed; it can be, for example, a data
center comprising of several virtual servers, physical servers, ﬁrewalls, load balancers, and storage
drives exclusive dedicated for the software system. The deployment choice can also be a public
cloud service such as Amazon EC2 [1] that sells on-demand compute capability on an open market.
However, a public cloud customer has little control over the hardware and software infrastructure
of the compute resource that is provided. A private cloud (e.g. Nebula [9, 14]) on the other hand, is
typically smaller in scale and conﬁned within an organization. Compared to a public cloud, private
cloud users have more control over the cloud infrastructure.

Hybrid Cloud [23] combines a set of public clouds, private clouds, as well as high-performing
bare-metal infrastructure. It provides the beneﬁt of compute on demand like a public cloud; it also
provides better overall control over the compute infrastructure and offers superior performance like
a private cloud. Consider a large global enterprise with hundreds of applications developed over
several years hosted on geographically scattered infrastructure. Such a deployment can become
deﬁcient due to adhoc mix-and-match of hardware and software resources over a period of time.

∗Correspondence to: BITS Pilani K.K.Birla Goa Campus, Goa India-403726. Email: santonus@goa.bits-pilani.ac.in

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls [Version: 2010/05/13 v3.00]

 
 
 
 
 
 
2

SREEKRISHNAN ET AL.

If these applications can be transformed and redeployed on a hybrid cloud, the enterprise can
realize efﬁciency and cost savings that arise out of best ﬁtment of workloads with the underpinning
infrastructure. This has been observed and highlighted in a recent Gartner survey [8], which
predicted that the adoption of hybrid cloud as the preferred hosting model among enterprises
will triple from 2015 to 2017. However, the complexities involved in adopting hybrid cloud into
mainstream businesses are manyfold. One important issue is to achieve a judicious allocation
of workloads across different infrastructure platforms, since inefﬁcient partitioning of workloads
across the heterogeneous systems constituting the hybrid cloud can result in violation of the system’s
Service Level Agreements (SLAs). According to a Technology Business Research (TBR) market
survey report [15], there is a 32% gap between expected and actual evolution of cloud-hosted
workloads to hybrid environments across enterprises. This means that while the public and private
cloud markets have come of age, hybrid cloud maturity has not yet kept expected pace due to various
reasons.

In this paper, we propose a heuristic-driven methodology, developed from several real-life
cloud based deployments for customers across industries, to achieve an advantageous partitioning
of workloads across a hybrid cloud. We further propose a model to represent this partitioned
deployment and demonstrate how the complexity of such a deployment can be estimated in terms
of the required implementation effort.

This paper is organized as follows. Section 2 elaborates the problem description. In Section 3,
we ﬁrst describe a construct called the Cloud Line of Isolation and Control (CLIC) that we use as a
basic architecture partitioning mechanism. We then formulate a model in Section 3.2 and Section 3.3
that measures hybrid complexity and predicts deployment effort of classes of workloads that are
sought to be deployed. Section 3.2.1 presents results on how industrial characteristics affect hybrid
complexity. Section 4 validates our proposed hybrid deployment model using case studies from
four industries where we applied this technique to determine the contours of the hybrid deployment.
Section 5 describes the related work in this area. Finally we conclude the paper and highlight future
research directions.

2. PROBLEM DESCRIPTION

While hybrid cloud offers beneﬁts of deployment cost reduction, superior performance, and
improved security, a conﬂuence of heterogeneous compute platforms is seldom perfect; there are
several impediments to surmount before opportunities can be exploited.

One major problem confronting evolution to hybrid environments is that complex business
workloads that need to be deployed on hybrid clouds must be carefully partitioned. The partitioning
technique must identify the appropriate platform on which each workload must be deployed; else
the deployment will not correspond to minimalist complexity that will satisfy requirements, and
hence will be inefﬁcient and expensive. Hence the analysis and placement decision of workloads
must be taken apriori. This paper is devoted to addressing this problem space. We will elaborate on
this problem next.

2.1. Partitioning of Software Systems for Hybrid Environments: Major Challenges

As alluded to earlier, hybrid environments are composed of multiple cloud and traditional data
centers; the cloud is typically multi-vendor and heterogeneous, comprising of private, public and
community (”shared private”) deployments. While the deployment of future IT systems will turn
increasingly hybrid [8], the challenge is to arrive at a topology that results in the least cost of
ownership. There are many permutations of hybrid deployment architectures available that offer
varying degrees of control, isolation, security and performance. One or more of these permutations
is likely to offer the most advantageous ﬁtment depending on the characteristics of various categories
of component workloads.

The problem thus, is to design a deployment strategy for the service provider that apportions
different workloads of a business system across a hybrid infrastructure that satisﬁes various non-
functional requirements related to performance, security and availability, at the minimum cost of

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

ARCHITECTURAL PARTITIONING AND DEPLOYMENT MODELING ON HYBRID CLOUDS

3

ownership. A cloud deployment, at a high level, comprises of the cloud stack (which we refer to
as the “managing environment”), and the application workloads that run on target virtual machines
(which we call the “managed environment”). In this paper we focus on the complexity and effort in
constructing the managing environment.

An additional problem is to model the effort required to implement such a hybrid cloud based
deployment, which can then be used as a prediction tool for techno-commercial decisions spanning
architecture and business.

3. BUILDING A HYBRID DEPLOYMENT MODEL: A STRUCTURED APPROACH TO

HYBRID PARTITIONING

Software systems have different requirements on isolation and control. Some workload components
need heavy isolation and require high architectural control compared to others.

The desire for isolation translates to tolerance for other co-located tenants. The degree of required
isolation is a function of regulatory compliance requirements, performance guarantees, and security.
For instance, it is a common perception that security is more compromised if sensitive workloads
are hosted off-premise, which translates to a preference for storing sensitive data close to the client’s
ofﬁce, i.e. a requirement for stronger isolation

Architectural control, on the other hand, reﬂects the ability to customize the construction of
the cloud management system. It may be noted that the term architectural control in the context
of traditional software architecture [2] implies a set of constraints that an architect imposes on a
design so as to ensure that the architectural decisions are met. In this context, the degree of required
architectural control depends on the quantum of bespoke modiﬁcations that need to be incorporated
into the cloud infrastructure. It could arise out of the need to exercise code level control on the cloud
managing stack, the necessity to handle frequent change requests, or the need to perform heavy
duty integration with complex tools like sophisticated authentication systems, service monitoring
and management tools.

Note that the stipulation for a heavy isolation does not imply the necessity of high architectural

control, and vice versa. Therefore, we can treat them as orthogonal entities.

3.1. Cloud Line of Isolation & Control

In this section, we deﬁne the Cloud Line of Isolation and Control (CLIC) of a software system
(comprising of a set of workloads) as the boundary that separates those workload components
that demand strong isolation and control, from those that have relatively relaxed requirements.
Before explaining the CLIC and the motivation behind introducing it, we need to explain the cloud
deployment graph depicted in Figure 1. This graph plots the following variables:

The X-axis traces the degree of isolation required by the software systems that are to be deployed.
Assume that a set of infrastructure resource elements Ri,(0<i<N ) are hosting virtual machines for
M clients Cj,(0<j<M ). Let each infrastructure resource element Ri host K virtual machines V1 to
Vk. Let these K virtual machines run a set of workloads. If all these K virtual machines are owned
by the same client Cj, the workloads hosted on these machines are said to be isolated. If Ri is a
physical server, the isolation is at the host level; if Ri is a rack, it is a stringent rack level isolation;
if Ri implies a data center, then the isolation is even harder because the hosting facility itself needs
to be dedicated for the client in question. However, if no such tenancy requirements exist, there is a
little isolation demand on the hosted workload. Note that the question of isolation triggers the larger
“shared versus dedicated” question and not the “on-premise versus off-premise” question.

The Y-axis grades the degree of architectural control, which is the quantum of customization
needed to build the cloud. The need for architectural control can range from merely changing certain
conﬁguration parameters of a standard cloud like AWS, to introducing deep code-level changes
inside the cloud stack.

The set of feasible deployment models pertaining to each region is the third aspect, examples of

which are covered inside the boxes attached to each quadrant.

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

4

SREEKRISHNAN ET AL.

Figure 1. Hybrid Cloud Components Mapped to Zones of Varying Isolation & Control

The workloads of a client are ﬁrst plotted on this cloud deployment graph based on their
requirements on isolation and architectural control. Next, the CLIC line is used to help segment the
graph into quadrants, thus separating those workloads with high isolation and architectural control
requirements from the rest. The CLIC helps to quickly visualize a feasible high level approach to
designing the workload deployment architecture. The workload components to the left of the CLIC
are further trisected into three subcategories based on their isolation and control requirements.

3.1.1. Deployment Options As can be seen from Figure 1, there are various feasible deployment
options on both sides of the CLIC (see the text boxes embedded in the four quadrants) that are an
assemblage of clouds and traditional non-cloud based infrastructure. To explain this, we take a quick
tour of the graph.

We start with Quadrant #3, the most relaxed in terms of desire for architectural control, and
demand for isolation. Public virtual instances on multiple public clouds are generally sufﬁcient
to host these workload components. VMs that host these portions of the overall workload are
provisioned on physical servers that are shared with multiple customers. The cloud provider
manages the hypervisor; hence clients do not have control over the environment other than on their
virtual instances.

Quadrant #4 is harder in terms of isolation needs, but architectural control continues to be
relinquished to a large extent. An example hosting route is via private virtual machines on a public
cloud, where there is isolation at the server level. A private VM is deployed on a single-tenant
physical server. No other customer instance gets provisioned on that same physical server, thereby
assuring that this VM does not share resources with other clients. The virtualization is controlled by
the provider; the customer whose instances are provisioned on the dedicated server will not be able
to exert control on the managing environment.

Next is Quadrant #1, the region where workloads have low isolation requirements, but the client is
not ready to relinquish architectural control. A deployment architecture that satisﬁes this is hosted
private clouds. Such private clouds are owned, managed, and operated by external providers. An
example of a hosted private cloud provider is IBM Bluebox [10]. Several single-tenant hosted
options exist: off-premise private clouds, private clouds deployed on-premise, or private clouds
deployed in a collocation space attached to the data center that houses a public cloud where other
workload components of the system reside.

Finally, we arrive at Quadrant #2, the most stringent of the four zones. It falls on the right
side of the CLIC, and this usually calls for on-premise private clouds or traditional IT hosting.

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

ARCHITECTURAL PARTITIONING AND DEPLOYMENT MODELING ON HYBRID CLOUDS

5

However, depending on the degree of required isolation, one option is to use physical servers
on demand in a public cloud. These are single-tenant bare metal servers on multi-tenant public
clouds completely dedicated to a customer; no part of the server resources will be shared with other
customers. Hypervisors do not come attached with the physical servers, but the client has the option
to virtualize purchased servers and also to stand up a private cloud on top of the bare metal servers,
which provides a high degree of architectural control over the deployment.

3.2. Modeling the Hybrid Complexity Of Workloads

We now introduce the degree of hybrid complexity of the best-ﬁt deployment of a software system
based on workload characteristics. Encapsulating the complexity of the ideal hybrid deployment
of a software system in the form of a single metric is important due to two reasons: it becomes
possible to represent a deployment's complexity quantitatively, which can constitute an input for
architectural and business decisions; further it allows comparing the relative hybrid deployment
intricacies of two or more software systems and hence helps in estimating the implementation effort
and steady state delivery effort post service commencement. We will use the symbol H(w) to refer
to the aforementioned degree of hybrid complexity.

Table I. Empirical Observations of Effort Estimates to Deploy Singular Clouds

# Client’s IT Environment

Quadrant
(in
our
proposed
model)

of

#
Client
Deals
Analyzed

Average
Ci
Months)

(Person

Remarks

atop

1 All workloads

deployed
on hosted private clouds
(OpenStack
IBM
SoftLayer Cloud bare metal
or VMware vRealize Cloud
atop IBM SoftLayer Cloud
bare metal)
2 All workloads

deployed
on-premise on non-Cloud
environments (core banking
on main frames or industrial
backend software on high
performance
physical
servers)

3 All workloads

deployed
on public clouds (Amazon
AWS, Microsoft Azure or
IBM SoftLayer)

4 All workloads

deployed
on private VMs on public
clouds
(Amazon AWS
dedicated instances or IBM
SoftLayer private instances)

1

2

3

4

14

50

15

120

20

11

22

45

Much more complex than
savings
#3 or #4, but
accrued from cloud driven
developed
automation
by
available
leveraging
architectural control

The environment not being
software deﬁned, could not
exploit cloud-like efﬁcien-
cies, so labor to run the data
center was high. ’Toughest’
of the quadrants.

Retail cloud hosting with
no architectural control and
minimum isolation. Most
relaxed in terms of require-
ments
Infrastructure cost
is high
even though the hosting is
similar to #3

3.2.1. Empirical Study In order to characterize hybrid complexity, we observed 60 client cloud
deployments across different industries where the IT infrastructure was hosted on environments
where the architecture was singular and not hybrid. We then categorized these deals into 4 sets based
on the quadrants of Figure 1 in which they resided. For each of the four categories, we calculated
the average cost (Ci) to build and run the cloud managing environment. The deployment cost Ci
comprises of:

1. the cost of the BoM (Bill of Material) or the ’raw materials’ to deploy the solution; in this case
the hardware infrastructure and software/middleware licensing costs to implement the cloud
stack

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

6

SREEKRISHNAN ET AL.

2. the cost of the effort required to implement the overall hybrid cloud stack
3. the cost of managing the cloud stack during steady state operations for a one-year period, and
4. the cost of automating the process of making the target environment manageable. For
example, suppose that a particular business system for a given industry sector, demands
improved dependability, through the infrastructure monitoring tool Nagios† post provisioning.
In such a case, the cloud stack needs to ensure that every VM has the Nagios agent running
as a part of the deployment and sustenance exercise. Similarly, the service provider may also
needs to take care of patching, ticketing, anti-virus etc. Also, if provisioning needs to trigger
an approval workﬂow, the cloud stack needs to have that implemented.

All costs (including infrastructure charges) are depicted in units of person months of labor for ease
of comparative calculations. This cost will enjoy a return on investment in the form of savings
that will accrue in managing the target infrastructure due to introduction of cloud efﬁciency and
associated automation.

Note that we are considering the cloud stack, which is the managing environment and not the
managed environment, while computing the cost. So, in the case of public clouds (row #3 and row
#4 of Table I), the semantics of associated effort is slightly different from that for private clouds.
For the former, the effort is a combination of the labor required to provision the target infrastructure
via the public cloud provider's portal, develop any custom integration, and resolve cloud speciﬁc
steady state issues. Thus, row #3 of Table I does not include any BoM cost in column #5 since the
managing environment is built by the provider; row #4, however, includes a BoM component that is
equivalent to the differential between dedicated and shared virtual instances on the deployed public
cloud.

The result of our observations is a measure of how much each Quadrant of Figure 1 contributes
to the overall complexity of a hybrid deployment. The cost depicted in column 5 of Table I reveals
a 2:5:1:2 ratio across the four quadrants Q1:Q2:Q3:Q4.

This ratio essentially implies that the deployment cost of a workload is the least in Quadrant #3;
costs nearly double when deployed to Quadrant #4; and costs ﬁve times more when deployed to
Quadrant #2.

We also performed another set of studies to observe the movement of deployment cost (Ci) as a
function of the number of workloads in a given Quadrant. For this purpose, we collected 90 cloud
deployment solutions as follows:

• The chosen client cloud solutions were equally distributed across 6 industries, thus 15

deployments each from ﬁnance, healthcare, retail, airline, telecom, and manufacturing.

• They were chosen such that for solution k (k = 1 to 15) in each of the 6 industries, the

number of workloads to be deployed in Quadrant #1 was k.

• We then recorded the observed person month effort (we call it E(w)) to deploy the Quadrant

#1 cloud and sustain it for one year.
We normalized this cost as follows:

– In order to obtain the effort that is only due to the deployment environment, the work
to perform any customization was excluded. This corresponds to the cost of automation,
the last component of Ci listed earlier in this section.

– The service provider who is responsible for the deployment can have its own assets
(tools, methodology, tacit or documented knowledge, skilled personnel) which can
signiﬁcantly impact the deployment and sustenance effort. We quantiﬁed this as a unitary
metric called “asset leverage factor” x, 0 ≤ x ≤ 1 (smaller x means that the service
provider has better assets to reduce the deployment effort) and divided the observed
effort with this leverage factor. We did so, in order to obtain the effort number that is only
dependent only on the quadrant and the nature of the industry, without any inﬂuence of
the skill that the service provider possesses. The notion of this factor x will be described
later in this paper.

†https://www.nagios.org

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

ARCHITECTURAL PARTITIONING AND DEPLOYMENT MODELING ON HYBRID CLOUDS

7

Figure 2. δw across industries (essentially Wi beyond which effort starts plateauing)

The results of our experiment are summarized in Table II and graphically plotted in Figure 2. The
X-axis of Figure 2 marks the number of workloads to be deployed on the Quadrant #1 cloud for the
chosen deals. The normalized effort estimate to deploy the hosting cloud and to sustain it for one
year (in person months) forms the Y-axis. As can be seen, the effort estimate tends to an industry-
dependent plateau beyond a particular number of workloads, Wi. ‡ This value of Wi was recorded as
the ”CLIC Constant” or δw for that industry. The CLIC Constant (δw) thus decides the rate of growth
of the hybrid complexity inside any quadrant of the cloud deployment graph depicted in Figure 1.
As the number of workload components in a quadrant increases beyond the threshold dictated by
δw, the effort needed to deploy and sustain the portion of the hybrid cloud deployment associated
with that quadrant asymptotes to the maxima for that quadrant

Practitioners can repeat this experiment for other industries and decipher the respective δw based

on the dominant shape of the curve for the industry in question.

To understand the implications of δw, let us look at the graph plots for the health care and airline
industries in Figure 2. As can be seen, the δw for the health care industry is observed as being less
than that for the airline industry. This messages the fact that the cloud stack for the health care
is generally more complex to build than that for the latter, all other aspects (such as the number
of workloads, their inter-quadrant distribution and custom integration requirements) remaining the
same. Similarly, the δw for the ﬁnance industry is lesser than the δw for the retail industry. This
means that even with a smaller number of workloads on either side of the CLIC line, the hybrid
complexity of a banking solution can potentially be higher than a retail solution that has a relatively
larger number of workloads scattered across the four quadrants of Figure 1.

Table II. Empirical Observations to Determine δw

#

Industry

#Deployments Normalized Effort

1
Finance
2 Healthcare
3 Retail
4 Airline
5 Manufacturing
Telecom
6

15
15
15
15
15
15

Finance curve, Fig 2
Healthcare curve,Fig 2
Retail curve, Fig 2
Airline curve, Fig 2
Manufacturing curve, Fig 2
Telecom curve, Fig 2

δw

6
8
10
15
10
6

The results from the analysis performed in this section gives rise to the following four properties

that we will use to build a model for measuring hybrid complexity in the next section:

‡Though we focus on Q1 here, we also repeated this experiment for other quadrants and obtained similar results. We
don’t include such details for brevity.

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

8

SREEKRISHNAN ET AL.

1. The contribution of each side of the CLIC (Figure 1) to the hybrid complexity of the software

system in question is approximately equal.

2. The deployment costs (and hence the complexity) has a 2:5:1:2 ratio across the four quadrants

Q1:Q2:Q3:Q4.

3. The rate of growth of deployment costs (and hence the complexity) asymptotes to a certain
value as the number of workload components in the associated quadrant increase beyond the
threshold dictated by δw.

4. The aforementioned rate of growth and threshold depends on the industry or the sector that

the workload belongs to, which can be empirically determined.

3.2.2. Hybrid Complexity H(w)
We now build a model to quantify hybrid complexity.
In Figure 1, let W1 · · · W4 be the number of workload components in quadrants #1 to #4 respectively.
The number of workload components to the right of CLIC = Wi>CLIC = W2 and the number of
workload components to the left of CLIC = Wi<CLIC = W1 + W3 + W4.

This inter-quadrant distribution of Wi aims to minimize the total deployment and management

cost

where Ci is the deployment cost of the workloads in Quadrant #i as labeled in Figure 1. We deﬁne
the degree of hybrid complexity of the ideal deployment architecture (one that optimizes cost C) as
follows:

H(w) =

Wi>CLIC
2 × Wi>CLIC + δw

+

W1
5 × W1 + δw

+

W3
10 × W3 + δw

+

W4
5 × W4 + δw

; 0 ≤ H(w) ≤ 1

[1]

where δw is the CLIC Constant introduced in the previous section, which depends on the class
of the workload such as its industrial grouping. The H(w) of any software system lies between 0
and 1. The larger the value of H(w), the more hybrid is the deployment architecture of workload w
and more complex is the ensuing deployment. Recall that our empirical study placed the relative
costs across the four quadrants in the ratio 2 : 5 : 1 : 2. This was used to arrive at the constants in
the denominators of Equation 1; for example, the constant in the denominator of the third term
(2+5+1+2) or 0.1 as the number of workloads in Quadrant
is 10 because it should asymptote to
#3 increase beyond the threshold dictated by δw. Similarly, the constant in the denominator of the
fourth term is 5 because it should tend to
2+5+1+2 or 0.2 as the number of workloads in Quadrant
#4 increase beyond δw.

1

2

The assignment of workloads along the four quadrants of Figure 1 does not necessarily remain
constant; it could change as the attributes of the workload reshape over time. It is possible that the
demands on isolation and control are service-driven or business-driven dynamically. For instance,
consider a workload pertaining to incident ticket management. As the number of tickets of high
severity decrease below a threshold for a certain period of time, one may decide to relinquish some
notches from the existing level of architectural control. Consequently, this workload may be moved
to a public cloud from a private cloud. An example of a business-driven scenario is the willingness to
relax isolation requirements on a system during time intervals when commercial activity wanes, for
example, during the ﬁrst quarter of the year for retail vendors. In short, workloads could move from
one quadrant of Figure 1 to another as a function of time. Thus Equation 1 can be more generally
expressed as follows:

H(w, t) =

W(i>CLIC,t)
2 × W(i>CLIC,t) + δw

+

W1,t
5 × W1,t + δw

+

W3,t
10 × W3,t + δw

+

W4,t
5 × W4,t + δw

[2]

We will demonstrate the application of both Equation 1 and Equation 2 using case studies in
Section 4.

A note on the CLIC Constant before we end this subsection. One aspect that has to be taken
into account while determining δw is that industries often intersect. An e-commerce vendor might

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

ARCHITECTURAL PARTITIONING AND DEPLOYMENT MODELING ON HYBRID CLOUDS

9

generate revenue via the ﬁnancing route. Customers would potentially be allowed to purchase on
credit and maintain running accounts on which interest is levied. Such a retail enterprise, thus,
has workloads both in the retail sector and in the ﬁnance sector. The value of δw, thus, needs
to be chosen accordingly to the workload category rather than the industrial classiﬁcation of the
enterprise. The retail and ﬁnancial workload deployments in this example would thus be treated as
separate hybrid environments with different associated δws. The Government is another sector than
commonly spans industries. Government IT needs to serve departments touching the breadth of the
economic spectrum ranging from ﬁnance and health, to telecom and manufacturing. The value of
δw, thus, has to be chosen appropriately based on the workload's industrial grouping rather than the
enterprise's ofﬁcial industry classiﬁcation.

3.3. Predicting Hybrid Deployment & Sustenance Effort

Deploying and sustaining a hybrid cloud is a complex and time-consuming activity. Consequently,
the approach to estimate the hybrid cloud deployment and management effort has largely been
ad-hoc. We have observed that the hybrid complexity measure H(w) can play a signiﬁcant role
in improving the estimation of deployment and management effort. We attempt to model the
deployment and management effort (cid:98)E(w) of a set of workloads w constituting a software system
as:

(cid:98)E(w) = H(w) × K ×

[3]

x
y

(cid:98)E(w) in Equation 3, in effect, is inﬂuenced by the following:

1. A constant K, referred to as the complexity-to-effort constant, whose value is dependent on
the hybrid cloud deployment service provider, and is determined based on prior experience,
given the available level of skill and expertise of the service provider.

2. An asset leverage factor x (0 < x < 1), whose value depends on the quality of internally
available assets and tools that can be used to assist the service provider to automate the
deployment. The smaller the value of x, the more sophisticated is the assistant toolset to
automate the hybrid cloud deployment in question.

3. A custom work complexity factor y (0 < y < 1), whose value depends on custom work that
needs to be implemented around the hybrid deployment. This includes, for example, bespoke
workﬂows to integrate the hybrid deployment with service management tools, or custom code
development to fuse hybrid cloud authentication with pre-existing access directories. Lesser
the amount of required custom work, nearer y is to 1.

H(w) is a necessary, but not solely sufﬁcient component to calculate (cid:98)E(w) as shown in Equation
3. However, H(w) is the sole provider-independent component in the equation. The rest are either
service provider-speciﬁc (K and x) or depend on custom requirements of the hybrid cloud that is
being implemented (y).

To calculate K for the service provider applicable to our case, we randomly chose a set of hybrid
cloud solutions deployed over the past one year in the organization. For each deployment, we
computed its H(w) using Equation 1, and observed the actual effort E(w) expended to setup and
sustain the solution for one year. We then estimated the asset maturity within the organization for the
industry in question (x) and the custom effort required for the chosen deal (y). Next we determined
the value of K = E(w)
x for the deployment. We computed the overall K for the service provider
as the cumulative moving average of K across the set of deployments. The result of the calculation
is shown in Table III.

H(w) ∗ y

It is prudent to periodically ﬁne-tune the value of K as past deployment data accumulates, so
that currency is maintained on the epoch over which the cumulative moving average is being
captured. This is because the value of K is a function of time and can change as internal teams
and organizational processes mature. Similarly, it is necessary to re-calibrate x on a timely basis
since it can change as industry-speciﬁc reusable assets get built.

In Section 4, we will present data from twelve client case studies to evaluate the effort estimate
model proposed in Equation 3. The variance of observed results (E(w)) from what Equation 3
predicts ( (cid:98)E(w)) is presented in Table IV of Section 4.5.

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

10

SREEKRISHNAN ET AL.

3.4. Methodology to Converge on the Effort Estimate of Hybrid Deployments

We end this section by summarizing the methodology that we propose to converge on the effort
estimate of the ideal hybrid deployment of a software system:

1. Demarcate the set of workloads that require high levels of isolation and high levels of control;
in other words, draw the CLIC contour that determines the layout of the four quadrants in the
cloud deployment graph. Count the number of workloads to the right hand side of the CLIC
and compute WQ2.

2. For the workloads to the left hand side of the CLIC, further assess and separate them based

on isolation and control requirements, into WQ1, WQ3 and WQ4.

3. Identify the industrial grouping of the workload that empirically determines the rate of growth
of hybrid complexity as a function of the number of workloads, and ascertain the applicable
δw (see Figure 2).

4. Apply the values determined above to Equation 2 and deduce the hybrid complexity (H(w))

of deploying this software system on the best-ﬁt cloud topology.

5. Apply the H(w) determined above to Equation 3 to predict the effort estimate needed to

deploy and sustain the associated hybrid cloud environment.

Discovering H(w) (and the associated (cid:98)E(w)) to deploy and run a software system on the best-ﬁt

hybrid cloud brings the following beneﬁts:

1. It provides a high level view of the relative work and cost estimate to deploy these workloads,
and manage them during steady state operations. This in turn, yields a measure of the TCO
(total cost of ownership) of the hybrid deployment in question.

2. It can function as a tool to compare the relative hybrid deployment intricacies of two or more

software systems.

3. Designing a hybrid deployment is generally dependent on numerous variables, such as
performance SLAs, adherence to a set of regulatory compliance requirements, degree of
tolerance to workload collocation, as well as the perception of diminished security in off-
premise systems. H(w) encapsulates all of these complexities latent in a hybrid deployment
in the form of a single number. The ability to quantify the complexity in this manner allows
for easier business and architectural decisions.

4. EVALUATING THE HYBRID DEPLOYMENT MODEL: APPLICATION TO INDUSTRIAL

CASE STUDIES

In this section, we will evaluate the hybrid deployment model that we constructed above. We took
three real life client examples from four industries (for a total of twelve client deals) where we had
designed hybrid cloud deployment topologies. None of these client solutions were part of the data
set that was leveraged to construct our model. We applied our model to predict the hybrid cloud
deployment effort (cid:98)E in each case and also observed the actual work effort E that was incurred. The
results and the ensuing variance are presented at the end of this section in Table IV. For ease of
presentation, we chose and expanded one client example from each industry for a total of four case
studies in this section, but the results for all twelve deals that we observed are presented in Table IV.
Our ﬁrst case study is a software system from the retail industry, the second from ﬁnancial
services, the third from the health care sector, and the fourth from the airline industry. In each case,
we show how we performed a workload analysis, drew the CLIC line that helped derive the hybrid
deployment architecture, derived the hybrid deployment complexity H(w), and observed predicted
(cid:98)E(w) and actual E(w). We also present our observations regarding the CLIC constant δw.

In order to explain the deployment scenario, we consider an architecture reference model of
the industry associated with each example. A reference model for an industry provides sufﬁcient
information about the functional entities and their relationships in the given industry context, while
remaining abstract so that it does not delve into non-essential details of speciﬁc systems belonging
to the industry.

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

ARCHITECTURAL PARTITIONING AND DEPLOYMENT MODELING ON HYBRID CLOUDS

11

Figure 3. A Simpliﬁed Architecture Reference Model for Retail

4.1. Retail Sector

Let us consider a typical online retail system. We have considered a simpliﬁed version of the
reference model described in [5] and depicted that in Figure 3. Retail software can typically be
classiﬁed into two main categories [5]:

1. Front-end transactions before potential end-customers populate an item into the shopping cart.
This includes the e-commerce portal, operations on the retailer's catalogue, and analytics to
derive purchase recommendations. We call these ”above the shopping cart” processing.

2. Back-end processing after an item has been added to the shopping cart. This includes order
management, billing, and fulﬁllment. We call these ”below the shopping cart” processing.
Processing ”above the shopping cart” has to be production-grade, but action ”below the shopping
cart” is mission critical. The former includes the stage when customers browse and search the
retailer's catalogue, evaluate personalized recommendations, and manage accounts. The latter
commences after the customer checks out the purchase, and encompasses payment and delivery.

Big retailers are reluctant to move ”below the cart” processing off-premise to a public cloud
because this portion is built in a highly redundant fashion with clustered dedicated components
without single points of failure. It is difﬁcult to realize such deployment architectures on many
public clouds, but possible on private clouds where the retailer can exercise high degree of
architectural control. For example, a clustering solution that needs a dedicated network link to
carry heartbeats is hard to implement on a multi-tenant cloud. Or if workloads are sensitive to
regulation -– Payment Card Industry (PCI) compliance in this case -– it is easier to host them on
a private cloud over which the retailer can impose high levels of isolation. Retail systems also
maintain personal data such as customer credit card information and shipping addresses, which
are sought to be stored as close to on-premise as possible. Most retailers are, however, eager to
move functionality existing ”above the cart” to public clouds. In addition to being less mission
critical, these functions tend to be more customer focused. For instance, a typical retail business
provides users a personalized shopping experience, typically by leveraging social media and mobile
devices. Such system components are comfortable living off-premise. Additionally, modern retail
systems have a set of constituents that generate data-driven insights such as sales forecasts, type
and timing of promotions, and pricing strategies. These systems also thrive on public cloud based
infrastructure, where they heavily use MapReduce algorithms and leverage a service oriented design
where application services are exposed and consumed via published APIs.

Figure 4 depicts a deployment of our retailer case study. The workloads generally conform to,
but is a subset of the reference model shown in Figure 3. Workloads to the right of the CLIC (the
ones that fall in Quadrant #2 of the diagram depicted in Figure 1) comprise mainly of ”below the
shopping cart” software). The deployment options for these workloads are permutations of what is
articulated in the box superimposed on Quadrant #2 of Figure 1. In the context of this customer, the
choice was a combination of the following:

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

12

SREEKRISHNAN ET AL.

Figure 4. H(w, t=Apr-Dec)=0.29 for a Retail Software System

1. A traditional non-cloud infrastructure to hold legacy backend retail applications running on
mainframes. These were the applications that enabled ﬁnancial transactions and billing.
2. An OpenStack cloud region [18] deployed on-premise on the client's data center to host order
fulﬁllment applications deployed atop an Oracle Real Application Cluster (RAC) for high
availability and redundancy.

Workloads to the left of the CLIC in Figure 4 are spread across Quadrants #1, and #3. The main
workload in this category was the e-commerce frontend and a recommendations engine built around
a Hadoop Big Data framework. On the basis of the waxing and waning of commercial activity over
the past several years, this retailer concluded that during the busy months of the year they needed
architectural control at the hypervisor layer to stitch together a high availability (HA) model that
provided a low Mean Time to Recover (MTTR) and high Mean Time to Failure (MTTF). This was
realized by deploying a dedicated OpenStack cloud region on top of virtualized bare metal servers
on the IBM SoftLayer Public Cloud [11] as depicted in Figure 4.

During the lean months of the year (primarily the ﬁrst quarter from January to March), however,
availability requirements could be relaxed, and consequently, hypervisor-level control was not
needed. During this period, following Equation 2, workloads residing in Quadrant #1 of Figure 1,
can be allowed to move down to Quadrant #3. This resulted in a simpliﬁed hosting model of
wherein the workloads could be hosted on public cloud virtual instances on Amazon Web Services
(AWS) [4]. This scenario is shown in Figure 5. Note that there is inter-quadrant movement in this
case, but not across the CLIC line.

Development and test workloads reside in Quadrant #3 throughout the year, hosted on AWS
virtual machines [5]. The customer, thus, had four kinds of workloads as depicted in Figure 3, spread
across three quadrants. We applied Equation 2 to measure the hybrid deployment complexity of this
software system as a function of time. Note that we empirically observed δw for retail workloads as
10 in the industry plot in Figure 2.

For the partitioned deployment of Figure 4, we get, H(w, Apr-Dec) = 2
For the partitioned deployment of Figure 5, we get, H(w, Jan-Mar) = 2
These numbers quantify the hybrid deployment complexity that we predict for this retail business.
Note that if there are no workloads in Quadrant i for a hybrid deployment, the corresponding term in
Equation 1 (and Equation 2) becomes 0. Table IV translates the calculated hybrid complexity to cost
in terms of person month effort estimates; it also provides conclusions pertaining to the complexity
of this retail case study relative to other case studies that we discuss in this paper.

14 + 2
20 + 0 + 1
14 + 0 + 0 + 3

40 = 0.22.

20 = 0.29.

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

ARCHITECTURAL PARTITIONING AND DEPLOYMENT MODELING ON HYBRID CLOUDS

13

Figure 5. H(w, t=Jan-Mar)=0.22 for a Retail Software System

Figure 6. Simpliﬁed Architecture Reference Model for Bank

4.2. Banking Sector

We observed that the ﬁnancial industry has a natural afﬁnity to hybrid clouds. Enterprises prefer
mission critical and regulation sensitive workloads to run on private clouds where the business can
exercise architectural control. Less critical production workloads are migrated to public clouds. Let
us consider a generic banking sector reference architecture shown in Figure 6, which is a simpliﬁed
version of the banking reference model described in [13]. Further, consider Figure 7, which depicts
the infrastructure that applies to our case study. Figure 7 conforms to, but is a subset of, the reference
model shown in Figure 6, and explains the hybrid cloud deployment pattern that we designed to host
a bank's software system. There are four workloads in this case comprising of three sets:

1. Core banking applications are mission critical. Even a few minutes of downtime of these
workloads can translate to millions of dollars of revenue and brand image loss. These
applications transact with customer ﬁnancial records. Regulatory requirements demand
isolation for this ensemble of workloads; custom security requirements call for architectural
control as well. This portion of the bank's software, thus, ﬁrmly resides in Quadrant #4. These
workloads were hosted on an OpenStack-based private cloud [18] implemented on-premise
as shown in Figure 7.

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

14

SREEKRISHNAN ET AL.

Figure 7. H(w)=0.31 for a Banking Software System

2. Two workloads that reside in Quadrant #4 on the left hand side of the CLIC: An e-business
suite centered round the bank's web portal, and an application that generates mobile alerts
based on state changes reported by the core banking environment. These software components
were hosted on virtual private instances on the IBM SoftLayer Public Cloud [11]. As
discussed earlier, virtual private instances offer server level isolation for a customer.

3. A marketing campaign application that draws insight from social media interactions. Because
the analytics engine associated with this application was built around a Hadoop Big Data
engine, virtual instances on a public cloud offered the most advantageous deployment
infrastructure for this application.

The overall deployment architecture for the bank's software system is depicted in Figure 7. The
hybrid complexity was calculated by the application of Equation 1. Note that we have empirically
observed δw for ﬁnancial workloads as 6 in the industry plot in Figure 2.

H(w) =

1
8

+ 0 +

2
16

+

1
16

= 0.31

.

4.3. Health care Sector

Health care is being transformed by technology, cloud, and the Internet. The use cases are many and
varied: collaborative care without spatial boundaries, remote patient monitoring, medical imaging,
mobile-enabled hospital management systems, and innovative and predictive Systems of Insight.
Figure 8 shows the hybrid cloud deployment pattern relevant for a modern health care service.
The architecture reference model shown in this ﬁgure has been adapted from [19]. The case study
in question has workloads that constitute a subset of the aforementioned reference model and is
depicted in Figure 9. The client case study in question had four workloads:

1. A software system that queried and monitored the patient's cardiac parameters. This software
was an FDA Class-3§ system, thus sensitive to regulation. This system falls on the right side
of the CLIC and was hosted on a traditional non-cloud IT infrastructure.

2. A software suite built around analytics and social media to predict and prevent diseases based
on past diagnostic data, while also aiming to improve outcomes by measuring clinical results

§Food and Drug Administration (FDA) is the agency that regulates drugs and medical devices in the United States. A
device is classiﬁed as Class-3 by the FDA if its failure can be life threatening; hence devices under this category are
subject to the highest level of regulation.

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

ARCHITECTURAL PARTITIONING AND DEPLOYMENT MODELING ON HYBRID CLOUDS

15

Figure 8. Simpliﬁed Architecture Reference Model for Health Care

Figure 9. H(w)=0.25 for a Health Care Software System

on patients. The framework on which this workload depended, lent itself to being a natural
ﬁt for Quadrant #3. This part of the overall workload was hosted on virtual instances on the
Amazon Cloud [4].

3. A collaboration system to remotely connect doctors and patients. Given that the stakeholders
would be geographically separated, the communication needed to be rapid and secure. The
latter brought in requirements on isolation, best satisﬁed by deployment options associated
with Quadrant #4. This workload, thus, was hosted on single-tenant bare metal servers on the
IBM SoftLayer Public Cloud [11].

4. An archival system for storing medical images. This data was infrequently accessed and could
tolerate large retrieval access times. An off-site storage that was a replacement for tape drives
was the need, and hence this workload also falls on Quadrant #3. The storage solution chosen
in this case was Amazon Glacier services [3].

The overall deployment architecture for the health care provider's software system is depicted in
Figure 9. The hybrid complexity was calculated by the application of Equation 1. Note that we have
empirically observed δw for health care workloads as 8 in the industry plot in Figure 2.

H(w) =

1
10

+ 0 +

1
13

+

2
28

= 0.25

.

4.4. Airline Sector

Our fourth case study is from the aviation industry, which is part of the larger transportation sector.
Figure 10 describes a customer scenario where a mission critical airline reservation system that
falls on the right side of the CLIC was hosted on a secure dedicated on-premise private cloud.

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

16

SREEKRISHNAN ET AL.

Figure 10. H(w)=0.12 for an Airline Software System

The customer-engaging front-end portal that belonged to the left of the CLIC was deployed on the
Amazon Public Cloud [4].

The hybrid complexity was calculated by the application of Equation 1. Note that we have

empirically observed δw for the Airline sector as 15 in the industry plot in Figure 2.

H(w) =

1
17

+ 0 + 0 +

2
35

= 0.12

4.5. Evaluating the Hybrid Deployment Model with Results from the Case Studies

In this section, we use data from our case studies to evaluate our model expressed via Equation
1, Equation 2 and Equation 3. We apply the H(w) values we calculated for our case studies to
Equation 3 and record the effort estimate (cid:98)E(w) that it predicts. We then compare it with the actual
effort E(w) that was expended to deploy and sustain the hybrid cloud environment associated with
our case studies for a period of one year.

Table IV summarizes our ﬁndings. As mentioned earlier, we observed three application
deployments from each of the four chosen industries, so the table has data points from twelve
deployments. The inter-quadrant workload distribution for each client deployment is speciﬁed
within brackets in column #2. The four deployments highlighted in bold are the ones that we
described in detail earlier in this section. All the chosen deployments were performed by one service
provider organization.

Table III. Cloud Provider Speciﬁc Variables to Calculate (cid:98)E(w)

Industry

Retail
Finance
Health Care
Airline

K

150
150
150
150

x

0.8
0.6
0.8
0.7

To explain the calculations, let’s consider the retail case study that we discussed in Section 4.1
(row #1 of Table IV). As determined in Section 4.1, this client deployment yielded an H(w) of
0.29 resulting from the application of Equation 1. To apply Equation 3, we next need the two cloud
service provider speciﬁc parameters, K and x. These values are depicted in Table III, which contains
the K and x values for the cloud service provider organization applicable to our experiment. K was
empirically determined as described in Section 3.3, whereas x was estimated for each industry.

As can be seen from Section 4.1, the cloud service provider organization applicable to our case
had an empirically determined K value of 150, which implies that based on internal skills and

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

ARCHITECTURAL PARTITIONING AND DEPLOYMENT MODELING ON HYBRID CLOUDS

17

processes of the service provider, a 43 person month effort can implement and sustain a hybrid
deployment having an H(w) of 0.29, assuming lack of relevant reusable assets (x = 1) and absence
of custom requirements (y = 1). Our cloud service provider, however, has an asset leverage factor
of x = 0.8 for retail cloud deployments, which means that the availability of reusable assets from
similar earlier deals is relatively low. The custom-multiplier y for this retail deployment was 0.2,
which implies that the contractual custom requirements to make the deployment infrastructure
ready for the application deployment was high. If we apply these values to Equation 3 to obtain the
expected effort estimate, we get, (cid:98)E(w) = 0.29 ∗ 150 ∗ 0.8
0.2 = 174 Person Months. We also computed
the percentage variance between the predicted sizing numbers ( (cid:98)E(w)) and the actual values that we
observed post-deployment (E(w)), which in this case was 10% (the last column of the ﬁrst row in
Table IV).

Our post-deployment measurements thus reveal

that our method to determine the hybrid
complexity of client workloads and to forecast the associated effort estimate is a reasonably accurate
technique.

Table IV. Effort Estimate across Case Studies: Predicted versus Actual

#

Industry

H(w)

y

(cid:98)E(w)

| (cid:98)E(w) −
E(w)|

Retail (Case Study #1)
Retail (W1 = 1, W2 = 2, W3 = 2, W4 = 2)
Retail (W1 = 3, W2 = 3, W3 = 3, W4 = 2)
Finance (Case Study #2)
Finance (W1 = 4, W2 = 3, W3 = 5, W4 = 2)
Finance (W1 = 5, W2 = 2, W3 = 3, W4 = 5)
Health Care (Case Study #3)
Health Care (W1 = 4, W2 = 2, W3 = 4, W4 = 2)
Health Care (W1 = 5, W2 = 2, W3 = 3, W4 = 1)

1
2
3
4
5
6
7
8
9
10 Airline (Case Study #4)
11 Airline (W1 = 2, W2 = 1, W3 = 4, W4 = 0)
12 Airline (W1 = 0, W2 = 2, W3 = 5, W4 = 1)

0.29
0.38
0.48
0.31
0.62
0.77
0.25
0.50
0.47
0.12
0.21
0.23

0.2
1.0
0.8
0.2
0.3
0.4
0.5
0.6
0.3
0.3
0.5
0.7

174 person months
46 person months
72 person months
117 person months
186 person months
173 person months
60 person months
100 person months
188 person months
18 person months
44 person months
35 person months

10%
4%
13%
15%
15%
12%
12%
9%
2%
8%
5%
14%

Table V. Complexity of Non-Functional Requirements across Industries

Availability Biz Con-

Security Compliance Performance Complexity

tinuity

M
M
M
H
L
H

L
M
H
H
H
M

L
M
H
H
M
H

M
M
M
M
M
H

Quotient

8
10
12
13
10
13

δw
from
Table II

15
10
8
6
10
6

Industry

#
Deploy-
ments

Airline
Retail
Health Care
Finance
Manufacturing
Telecom

15
15
15
15
15
15

M
M
M
M
M
M

4.6. Validation of δw

We also performed an experiment, shown in Table V, to demonstrate that our observations and
conclusions on δw presented in Table II are intuitive as well. The deployments listed in Table V
are the same ones that we chose for our observations recorded in Table II (and hence Figure 2).
Each row of this table grades the non-functional requirements associated with an industry, which
we ascertained from actual application deployment data in that business grouping. Each cell is
rated High(H), Medium(M) or Low(L) having weights of 3, 2, and 1, respectively, that combine
to determine a complexity quotient for that industry. Note that each entry is the average of
the characteristics of all workloads in that client deployment. As seen in the table, compliance
requirements imposed on health care, ﬁnance and telecom industries are higher than say, the

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

18

SREEKRISHNAN ET AL.

manufacturing industry. Similarly, the performance requirements generally expected from telecom
workloads (that can have hundreds of millions of users) is more than for most other industries.
We make the reasonable assumption that the complexity quotient that we observed for the target
managed environment also applies to the hybrid cloud managing environment. It is logical that
the larger the value of the complexity quotient, the smaller should be the value of δw, which is
consistent with our observations. To take an example, Table V reveals that retail systems manifest
a lesser complexity quotient than ﬁnancial systems; they also empirically demonstrate a higher δw
than ﬁnancial systems. What this means is that, ﬁnancial workloads yield a larger value for H(w)
compared to retail workloads for a given number and spread of workloads across the four Quadrants
in Figure 1.
4.7. Threats to Validity

Like any other empirical study, it is important to highlight various threats to the validity while
placing conﬁdence in the results. In this section, we comment on the threats to validity of our results
under 3 different axes: construct validity, internal validity, and external validity [6].

Construct Validity implies that the dataset used for the experiment is correct. Our data is in
essence, meta-data compiled while working on hundreds of client deals. Also, the data used to
construct our model (Table I and Table II) does not overlap with the data leveraged to verify the
model (Table IV). Thus, while potential threats under this head are minimal, residual risks include
the possibility of wrongly determining K or x for the service provider in question, and errors while
empirically calculating δw. On the latter, our model, for the sake of simplicity, ignores the possibility
of a slight variation of δw across the four quadrants for a given industrial grouping, and this can
ripple into a slight error in predicting (cid:98)E(w) for some corner cases. It is also possible that the best
classiﬁcation of a given set of workloads is not the industry that it belong to, rather its phase in the
DevOps life cycle, for example, development-test. For such cases, the corresponding δw will need
to be experimentally deciphered by the practitioner as described in Figure 2.

Internal validity highlights the impacts of the experimental process, conditions, past history, or
relationships among inputs on the observed outcome. Our sample space spans across 60 and 90
independent cloud deployment projects as described in Table I and Table II, respectively. Also, these
projects have cross-geography, cross-industry and cross-provider spread. The tools, methodology
and the data collection mechanism used for executing these deployment projects are uniform and
free from any project speciﬁc biases.

We have attempted to establish external validity by applying our ﬁndings to twelve randomly
chosen case studies across 4 industries and calculating the variance of what we observed with what
our model predicted. The spread of industry domains in our chosen sample set has been done to
establish the generality of the approach. While we are conﬁdent of the general applicability of our
model, because of the sheer diversity of real life use cases, there could be occasional divergence
from what our model predicts. As we continue to test our model on new and more complex cloud
deployments, we may discover the need to render it more granular to maintain accuracy in the face
of wide adoption. We will continue to reﬁne our model with future work, whose contours we lay
out in Section 6.

5. RELATED WORK

While cloud computing has been in existence for nearly a decade and has gained attention of both
academia and practitioners, the notion of hybrid cloud which is an integration of private and public
clouds, is a recent phenomenon. As observed in [23], early versions of hybrid clouds aimed to
supplement local and private infrastructure with compute capabilities borrowed from the public
IaaS, but this approach does not provide a seamless integration across compute environments. With
the growing popularity of hybrid clouds, it is now all the more important that the public-private IaaS
integration is seamless and transparent to the user. In order to deploy a large enterprise software
intensive system on a hybrid cloud, the software architect must analyze and partition various
workloads of the system onto the hybrid infrastructure leveraging a methodology such as the one
we propose.

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

ARCHITECTURAL PARTITIONING AND DEPLOYMENT MODELING ON HYBRID CLOUDS

19

An approach by Zhang et al. [24] discusses a factoring algorithm that applies for Internet-based
applications with dynamic workloads. The mechanism detects and splits workloads to ’base’ and
’trespassing’ zones when encountering load spikes. The latter zone is assumed to contain requests
for a small number of unique data items that are best served on elastic public clouds Though this
work is not aimed towards a hybrid deployment, the approach attempts to partition workloads.

Smit et al. [22] proposes a code partitioning method for client-facing web applications that ﬁrst
annotates code based on characteristics such as sensitivity to mobility. The partitioning algorithm
takes these cues and apportions it onto public or private clouds.

Literature such as [21] propose improvements to decrease load imbalance in data-intensive
applications running on high-performance computing systems; their focus is on tuning the way data
is partitioned into chunks depending on execution times and the number of nodes in the system.

The approach described in [12] proposes a resource provisioning policy based on the workload
model so as to minimize failure. The work proposes a scheduling infrastructure that can suitably
allocate a workload to an infrastructure.

Kaviani et al. [16] propose a method to partition multi-tier web applications for hybrid clouds.
Dependencies across the tiers are modeled, which yields suggestions on the placement of application
and data tiers across public cloud or on-premise private clouds.

While literature such as [24, 22, 16] have explored workload partitioning for hybrid clouds, they
are attuned to certain categories of software systems, primarily Internet-facing web applications. We
present a more generic approach to architectural partitioning that is heuristically applicable across
wide categories of software systems across industries. We also go a step further and propose a
method to translate the architectural partitioning into deployment complexity and associated effort
estimates. Also, our semantic of what constitutes hybrid IT deployment is broader than prior art,
which only chooses between two alternatives: on-premise private clouds and off-premise public
clouds.

6. CONCLUSION AND FUTURE WORK

In this paper, we presented a heuristic approach to help solve the problem of rapidly determining the
best-ﬁt hybrid deployment architecture for a given complex software system. We introduced what
we call the Cloud Line of Isolation and Control (CLIC) that serves as a high-level deployment-
centric partitioning indicator to segment workloads based on their characteristics and requirements.
We went on to propose a mathematical model to represent hybrid deployments, and a metric to
measure the degree of hybrid complexity of categories of workloads. We then used this model to
develop a method to predict the effort estimate to deploy and sustain hybrid cloud environments.We
also drew industry-speciﬁc conclusions from data collected from various client deals across
industries.

We next evaluated our model using data from twelve case studies across four industries to which
we applied the hybrid cloud complexity model that we constructed. We measured the variance of
predicted and observed results and veriﬁed that our model is a reasonably accurate tool to forecast
the complexity and effort estimate to implement and run hybrid cloud environments.

Our approach however, has limitations. The generality of applicable workloads and the perfection
of partitioning are complementary variables, so there is a fundamental limit to the precision
with which both can be achieved simultaneously. In future, we plan to improve our approach by
enhancing the coverage of many deployment possibilities in a hybrid hosted environment. For
example, the four quadrants of Figure 1 can be reﬁned to nine (three on each axis rather than two);
and there can be multiple sub-CLIC lines that separate more of the resulting zones. Additionally,
δw, now generalized across the deployment quadrants, could be rendered quadrant-speciﬁc. And
what constitutes a workload can be laid out in a more granular fashion in terms of underpinning
servers, middleware tiers and application components. The equations that we have derived to
measure hybrid complexity can also correspondingly mature. Furthermore, our complexity and
effort estimate models are designed for the managing environment (the cloud stack) and not the
managed environment. The complexity of virtualizing and sustaining the managed environment

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

20

SREEKRISHNAN ET AL.

depends on the nature of workloads and the composition of the compute, storage and network
domains in the data center; it will also need to factor in aspects such as workload migration which
we have not considered in this paper.

The emerging area of Cloud Service Brokerage [20]

is expected to mitigate many
problems attendant with consuming hybrid IT. Cloud brokerage can create and support
constructs that abstract underpinning clouds,
thereby delivering an integrated hybrid IT
experience. We also intend to focus on this area for future research on hybrid Clouds.
REFERENCES

1. Amazon elastic compute cloud (amazon ec2). http://aws.amazon.com/ec2.
2. J. Aldrich, C. Omar, A. Potanin, and D. Li. Language based architectural control.

International Workshop on Aliasing, Capabilities and Ownership (IWACO), 2014.

In Proceedings of the

3. Amazon glacier services. https://aws.amazon.com/glacier/.
4. Amazon web services. http://aws.amazon.com/.
5. F. Aulkemeier, M. Schramm, M.-E. Iacob, and J. van Hillegersberg. A service-oriented e-commerce reference

architecture. Journal of Theoretical and Applied Electronic Commerce Research, 11(1):26–45, 2016.

6. T. D. Cook, W. Shadish, and D. Campbell. Experimental and Quasi-Experimental Designs for Generalized Causal

Inference. Houghton Mifﬂin, 2002.

7. M. D. de Assuncao, A. de Costanzo, and R. Buyya. Evaluating the cost-beneﬁt of using cloud computing to
extend the capacity of clusters. In Proc. of the 18th International Symposium on High Performance Parallel and
Distributed Computing (HPDC), pages 141–150. ACM, New York, NY, 2009.

8. J. M. Ed Anderson. Cloud adoption across vertical industries exhibits more similarities than differences. https:
//www.gartner.com/doc/2987617/survey-analysis-cloud-adoption-vertical. [Online;
accessed 2015].

9. J. Fontan, T. Vaizquez, L. Gonzalez, R. S. Montero, and I. M. Llorente. Opennebula: the open source virtual
In Open Source Grid and Cluster Soft, volume 72, pages 1318–1331,

machine manager for cluster computing.
2008.

10. IBM Bluebox. https://www.blueboxcloud.com/.
11. IBM Softlayer. http://www.softlayer.com/.
12. B. R. Javadi B, Abawajy J. Failure-aware resource provisioning for hybrid cloud infrastructure. Journal of Parallel

and Distributed Computing, pages 1318–1331, 2012.

13. M. Keen, R. Kaushik, K. S. Bhogal, A. Aghara, S. Simmons, R. DuLaney, S. Dube, and A. Allison. Case study:

Soa banking business pattern. IBM Redbooks, 2009.

14. J. McKendrick. Nasa’s nebula: a stellar example of private clouds in government.
15. J. Mirandi. Hybrid cloud customer research. Technical report, Technology Business Research, Inc, 2014.
16. E. W. Nima Kaviani and R. Lea. Partitioning of web applications for hybrid cloud deployment. Journal of Internet

Services and Applications, 2014.

17. NIST - National Institute of Standards and Technology, P. Mell, and T. Grance. The NIST deﬁnition of cloud

computing. Special Publication 800-145, 2011.

18. Openstack open source cloud computing software. https://www.openstack.org/.
19. N.

Orvis, M.

Healthcare

Hufnagel.

Terlep,

and

S.

SOA

reference

architecture.

http://www.omg.org/news/meetings/HC-WS/index.htm, April 2008.

20. D. Plummer. Cloud services brokerage: A must-have for most organizations, 2012.
21. C. Rosas, A. Sikora, JosepJorba, A. Moreno, and E. C¨ı¿½esar. Dynamic Tuning of the Workload Partition
In 14th International Conference on High Performance Computing and

Factor in Data-Intensive Applications.
Communications. IEEE, 2012.

22. M. Smit, M. Shtern, B. Simmons, and M. Litoiu. Partitioning applications for hybrid and federated clouds.

In

Conference of the Center for Advanced Studies on Collaborative Research, 2012.

23. B. Sotomayor, R. S. Montero, and I. Foster. Virtual infrastructure management in private and hybrid clouds. IEEE

Internet Computing, pages 14–22, Sept 2009.

24. H. Zhang, G. Jiang, K. Yoshihira, H. Chen, and A. Saxena.

Intelligent workload factoring for a hybrid cloud

computing model. In IEEE International Conference on Web Services (ICWS), 2009.

Copyright © 2016 John Wiley & Sons, Ltd.
Prepared using speauth.cls

Softw. Pract. Exper. (2016)
DOI: 10.1002/spe

