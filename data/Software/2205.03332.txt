The Supervisionary proof-checking kernel
Or: a work-in-progress toward proof-generating code

Dominic P. Mulligan
Systems Research Group, Arm Research
Cambridge, United Kingdom
dominic.mulligan@arm.com

Nick Spinale
Systems Research Group, Arm Research
Cambridge, United Kingdom
nick.spinale@arm.com

2
2
0
2

y
a
M
6

]

R
C
.
s
c
[

1
v
2
3
3
3
0
.
5
0
2
2
:
v
i
X
r
a

Some scene setting Interactive theorem proving software
is typically designed around a trusted proof-checking ker-
nel, the sole system component capable of authenticating
theorems. Untrusted automation procedures reside outside
of the kernel, and drives it to deduce new theorems via an
API. Kernel and untrusted automation are typically imple-
mented in the same programming languageâ€”the â€œmeta-languageâ€â€”
usually some functional programming language in the ML
family. This strategyâ€”introduced by Milner in his LCF proof
assistant [2]â€”is a reliability mechanism, aiming to ensure
that any purported theorem produced by the system is in-
deed entailed by the theory within the logic.

Changing tack, operating systems are also typically de-
signed around a trusted kernel, a privileged component re-
sponsible forâ€”amongst other thingsâ€”mediating interaction
betwixt user-space software and hardware. Untrusted pro-
cesses interact with the system by issuing kernel system
calls across a hardware privilege boundary. In this way, the
operating system kernel supervises user-space processes.
Though ostensibly very diï¬€erent, squinting, we see that
the two kinds of kernel are tasked with solving the same
task: enforcing system invariants in the face of interaction
with untrusted code. Yet, the two solutions to solving this
problem, employed by the respective kinds of kernel, are
very diï¬€erent. In this abstract, we explore designing proof-
checking kernels as supervisory software, where separa-
tion between kernel and untrusted code is enforced by priv-
ilege.

System interface Supervisionary is a proof-checking sys-
tem for Gordonâ€™s HOL, structured as supervisory software,
and provides a system interface to untrusted code simi-
lar to an operating systemâ€™s system call interface. Supervi-
sionary is implemented as a WebAssembly [1] (Wasm hence-
forth) host, allowing us to prototype rapidly.

We use Rust as our implementation language, rather than
a functional programming language. This entails no risk of
unsoundness providing our system interface is carefully de-
signed. In particular, the kernel manages various private
heaps within which kernel objects are allocated, correspond-
ing to the paraphenalia of any HOL implementationâ€”type-
formers, types, term constants, terms, and theoremsâ€”and

PriSCâ€™22, January 22, 2022, Philadelphia, PA, USA
2022.

never directly exposed to untrusted code. Kernel objects are
allocated in response to system calls like:

Term.Handle.AllocateApplication(left, right, out)

Here, both left and right are kernel handles, assumed
to point-to allocated terms, whilst out points-to a buï¬€er in
untrusted codeâ€™s memory. If neither left nor right dan-
gle, and the types of their referents match, a fresh handle is
generated which points-to a new HOL term application ob-
ject, with internal pointers to the functional- and argument-
terms. This handle is returned to the caller via the out pointer.
The manipulation and querying of kernel objects is per-
formed defensively by the kernel itself on behalf of untrusted
code. The kernel is careful to maintain invariants such as
the inductivity of its heaps, with nodes in the kernel object
graph pointing-to allocated objects at all times.

Space constraints prevent us from describing the entire
Supervisionary system interface for working with, and on,
kernel objects. However, note that theorems are also con-
structed in a similar way to terms, inductively building deriva-
tion trees. For example, the HOL symmetry rule is exposed
as:

Theorem.Handle.AllocateSym(pre, out)
Here, pre points-to an existing theorem object Î“ âŠ¢ ğ‘Ÿ = ğ‘ 
and after succeeding, passing obvious checks, out contains
a handle that points-to a newly-allocated theorem Î“ âŠ¢ ğ‘  = ğ‘Ÿ .
Note that one interesting consequence of this style of im-
plementation is the ability to provide concise speciï¬cations
of Supervisionaryâ€™s system interface functions. Essentially,
the Supervisionary kernel is a grand exercise in pointer ma-
nipulation, and as such our system call speciï¬cations can
be expressed as Hoare Triples, using Separation Logic [4] as
our assertion language. Writing h â†¦â†’trm Application(l, r)
to assert that the handle h points-to a term application (of
the term pointed-to by ğ‘™ to the term pointed-to by ğ‘Ÿ ), and
writing out â†¦â†’ b to assert that out points-to the Boolean
value b, we have:

{â„ â†¦â†’trm Application(l, r)}
Term.Handle.IsApplication(h, out)
{out â†¦â†’ True}

(Here, the triple {ğ‘ƒ }ğ¶{ğ‘„ } asserts that if the command ğ¶ ex-
ecutes in a state concordant with ğ‘ƒ then the command suc-
ceeds and produces a state concordant with ğ‘„.)

1

 
 
 
 
 
 
PriSCâ€™22, January 22, 2022, Philadelphia, PA, USA

Dominic P. Mulligan and Nick Spinale

Note that Supervisionary lacks any analogue of the tradi-
tional LCF meta-language. Kernel and automation are now
decoupled, and code written in any language can â€œdriveâ€ the
kernel, providing it produces binary-compatible executables.

We now turn to speculation around potential uses of Su-
pervisionary. Exploring what follows is still a work-in-progress.

Runtime veriï¬cation Given our use of Wasm, we could
extend our system interface by also implementing the Wasm
System Interface [5]â€”a POSIX-like interface for Wasm. This
would transform Supervisionary from a mere programmable
proof-checker into a general-purpose sandbox, capable of
executing arbitrary programs, albeit with an unusual inter-
face for constructing proofs.

But: what happens if we blur the lines between Supervision-

aryâ€™s interfaces for system access and proof-checking?

Untrusted code executing under Supervisionaryâ€™s super-
vision could be challenged to prove some theorem each time
it wished to open a ï¬le on the ï¬lesystem, or otherwise per-
form some side-eï¬€ect. These theorems could be correctness
or security-related theorems, corresponding to a prevailing
policy in force. Moreover, as Supervisionary is capable of
capturing the runtime state of untrusted code, these chal-
lenges can be HOL predicates that are functions of the rei-
ï¬ed runtime state of untrusted code, the kernel, and the ar-
guments, and name of, the invoked system call.

Two predicates of interest are ğœ†ğ‘˜.ğœ†ğ‘¢.ğœ†ğ‘ .âŠ¤ and ğœ†ğ‘˜.ğœ†ğ‘¢.ğœ†ğ‘ .âŠ¥.
Here, âŠ¤ and âŠ¥ are truth and falsity, and ğ‘˜, ğ‘¢, and ğ‘  the kernel
and untrusted code states, and packed system call metadata,
reiï¬ed as HOL data, at the point of invocation of the system
call. One can always prove {} âŠ¢ âŠ¤ and therefore ğœ†ğ‘˜.ğœ†ğ‘¢.ğœ†ğ‘ .âŠ¤
represents no restriction, whereas {} âŠ¢ âŠ¥ is never provable,
absent axioms, with ğœ†ğ‘˜.ğœ†ğ‘¢.ğœ†ğ‘ .âŠ¥ representing a â€œclosing oï¬€â€
of a system call. By making the challenge a function of the
system call name and arguments, this closing oï¬€ can be spe-
ciï¬c, banning a process from calling a particular system call,
or a system call with a particular set of arguments, allowing
us to mimic mechanisms like seccomp from Linux.

We can go further: metadata about the behaviour of a run-
ning process could be maintainedâ€”for example, a record of
the system calls invoked by a process, thus far. This record
could be used in forming security or correctness challenges,
for example by forcing untrusted code to prove that writes
to a socket only ever happen after a read, or reads and writes
on sockets satisfy some protocol. In short, HOL acts as lin-
gua franca between kernel and untrusted code, through which
arbitrarily complex policies may be expressed.

2

Jailing, wherein a process voluntarily sheds capabilities,
is common in existing operating systems. This can be cap-
tured in Supervisionary by allowing a process to dynami-
cally replace the prevailing policy, ğœ™, with a new policyğœ“ , af-
ter proving thatğœ“ is a reï¬nement of ğœ™: {} âŠ¢ âˆ€ğ‘˜.âˆ€ğ‘¢.âˆ€ğ‘ .ğœ“ ğ‘˜ ğ‘¢ ğ‘  âˆ’â†’
ğœ™ ğ‘˜ ğ‘¢ ğ‘ . Note that this expresses that the states described by
ğœ“ are a subset of those described by ğœ™.

Note that this idea shares some similarities with proof
carrying code, wherein binaries are accompanied with (skele-
ton) proofs of their adherence to some policy, and these
proofs checked by the operating system prior to execution [3].
However, the ideas sketched above generalise this: proofs
can be generated dynamically, as the program executes, and
could more aptly be called proof generating code. Pro-
cesses and the Supervisionary kernel work together to come
to a â€œmutual understandingâ€ that the behaviour of the pro-
cess is indeed concordant with the prevailing policy.

Restructuring proof-checking tools Existing tools in the
HOL family could be refactored around Supervisionary by
changing their kernels to act as frontends to the Supervi-
sionary kernel for untrusted automation routines. Arguably,
this increases the robustness of existing tools, enforcing sep-
aration by isolation, rather than module boundaries. More
interestingly, this also means that Supervisionary acts as a
mechanism for â€œtransportingâ€ deï¬nitions and theorems be-
tween systems within the wider HOL family: systems are
capable of referring to, and manipulating, kernel objects pro-
duced by other systems through Supervisionary kernel han-
dles. With this, we can also bootstrap a full theorem-proving
environment, with associated libraries of content, on top of
Supervisionary without writing it from scratch.

Our prototype acts as both programmable proof-checker
and general-purpose sandbox. The previous section high-
lighted that this idea can be used to enforce runtime prop-
erties of programs. But, we can also use this blurring to
import ideas from the operating systems community into
the design of proof-checking software itself. For example, li-
braries of mathematical theorems and deï¬nitions could be
presented to Supervisionaryâ€™s users via a hierarchical or tag-
based ï¬le-system, and explored with command-line tools in
an interactive shell atop the Supervisionary kernel.

Lastly Supervisionaryâ€™s dual interpretation as sandbox and
proof-checker blurs the boundary between static and run-
time veriï¬cation, and between proof-checker and sandbox.
Whilst proofs can be generated by executables themselves at
runtime, they could also be generated interactively by users,
prior to the execution of a program, or even generated for
use by a program by other programs.

For example, the operational semantics and instruction
decoding functionality of Wasm is clearly embeddable in
HOL [6]. Using this, properties of a program ğ‘ƒ to be exe-
cuted under Supervisionary could be established statically,
and registered with the kernel, perhaps interactively by a

The Supervisionary proof-checking kernel

PriSCâ€™22, January 22, 2022, Philadelphia, PA, USA

user or by another program executing before ğ‘ƒ executes.
This theorem can then be used by ğ‘ƒ in closing challenges
from Supervisionary, issued at runtime, tying the correct-
ness of ğ‘ƒ to its execution.

References
[1] Andreas Haas, Andreas Rossberg, Derek L. Schuï¬€, Ben L. Titzer,
Michael Holman, Dan Gohman, Luke Wagner, Alon Zakai, and
Bringing the web up to speed with We-
J. F. Bastien. 2017.
bAssembly.
the 38th ACM SIGPLAN Confer-
ence on Programming Language Design and Implementation, PLDI
2017, Albert Cohen and Martin T. Vechev (Eds.). ACM, 185â€“200.
https://doi.org/10.1145/3062341.3062363

In Proceedings of

[2] Robin Milner. 1972. Logic for Computable Functions: description of a

machine implementation.

[3] George C. Necula. 1997. Proof-Carrying Code. In Conference Record
of POPLâ€™97: The 24th ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages, Papers Presented at the Symposium, Paris,
France, 15-17 January 1997, Peter Lee, Fritz Henglein, and Neil D. Jones
(Eds.). ACM Press, 106â€“119. https://doi.org/10.1145/263699.263712
[4] John C. Reynolds. 2002. Separation Logic: A Logic for Shared Mutable
Data Structures. In 17th IEEE Symposium on Logic in Computer Science
(LICS 2002), 22-25 July 2002, Copenhagen, Denmark, Proceedings. IEEE
Computer Society, 55â€“74. https://doi.org/10.1109/LICS.2002.1029817
[5] The WebAssembly working group. 2021. The WebAssembly System

Interface (WASI). https://wasi.dev.

[6] Conrad Watt. 2018. Mechanising and verifying the WebAssembly spec-
iï¬cation. In Proceedings of the 7th ACM SIGPLAN International Confer-
ence on Certiï¬ed Programs and Proofs, CPP 2018, Los Angeles, CA, USA,
January 8-9, 2018, June Andronick and Amy P. Felty (Eds.). ACM, 53â€“
65. https://doi.org/10.1145/3167082

3

