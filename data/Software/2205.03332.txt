The Supervisionary proof-checking kernel
Or: a work-in-progress toward proof-generating code

Dominic P. Mulligan
Systems Research Group, Arm Research
Cambridge, United Kingdom
dominic.mulligan@arm.com

Nick Spinale
Systems Research Group, Arm Research
Cambridge, United Kingdom
nick.spinale@arm.com

2
2
0
2

y
a
M
6

]

R
C
.
s
c
[

1
v
2
3
3
3
0
.
5
0
2
2
:
v
i
X
r
a

Some scene setting Interactive theorem proving software
is typically designed around a trusted proof-checking ker-
nel, the sole system component capable of authenticating
theorems. Untrusted automation procedures reside outside
of the kernel, and drives it to deduce new theorems via an
API. Kernel and untrusted automation are typically imple-
mented in the same programming language—the “meta-language”—
usually some functional programming language in the ML
family. This strategy—introduced by Milner in his LCF proof
assistant [2]—is a reliability mechanism, aiming to ensure
that any purported theorem produced by the system is in-
deed entailed by the theory within the logic.

Changing tack, operating systems are also typically de-
signed around a trusted kernel, a privileged component re-
sponsible for—amongst other things—mediating interaction
betwixt user-space software and hardware. Untrusted pro-
cesses interact with the system by issuing kernel system
calls across a hardware privilege boundary. In this way, the
operating system kernel supervises user-space processes.
Though ostensibly very diﬀerent, squinting, we see that
the two kinds of kernel are tasked with solving the same
task: enforcing system invariants in the face of interaction
with untrusted code. Yet, the two solutions to solving this
problem, employed by the respective kinds of kernel, are
very diﬀerent. In this abstract, we explore designing proof-
checking kernels as supervisory software, where separa-
tion between kernel and untrusted code is enforced by priv-
ilege.

System interface Supervisionary is a proof-checking sys-
tem for Gordon’s HOL, structured as supervisory software,
and provides a system interface to untrusted code simi-
lar to an operating system’s system call interface. Supervi-
sionary is implemented as a WebAssembly [1] (Wasm hence-
forth) host, allowing us to prototype rapidly.

We use Rust as our implementation language, rather than
a functional programming language. This entails no risk of
unsoundness providing our system interface is carefully de-
signed. In particular, the kernel manages various private
heaps within which kernel objects are allocated, correspond-
ing to the paraphenalia of any HOL implementation—type-
formers, types, term constants, terms, and theorems—and

PriSC’22, January 22, 2022, Philadelphia, PA, USA
2022.

never directly exposed to untrusted code. Kernel objects are
allocated in response to system calls like:

Term.Handle.AllocateApplication(left, right, out)

Here, both left and right are kernel handles, assumed
to point-to allocated terms, whilst out points-to a buﬀer in
untrusted code’s memory. If neither left nor right dan-
gle, and the types of their referents match, a fresh handle is
generated which points-to a new HOL term application ob-
ject, with internal pointers to the functional- and argument-
terms. This handle is returned to the caller via the out pointer.
The manipulation and querying of kernel objects is per-
formed defensively by the kernel itself on behalf of untrusted
code. The kernel is careful to maintain invariants such as
the inductivity of its heaps, with nodes in the kernel object
graph pointing-to allocated objects at all times.

Space constraints prevent us from describing the entire
Supervisionary system interface for working with, and on,
kernel objects. However, note that theorems are also con-
structed in a similar way to terms, inductively building deriva-
tion trees. For example, the HOL symmetry rule is exposed
as:

Theorem.Handle.AllocateSym(pre, out)
Here, pre points-to an existing theorem object Γ ⊢ 𝑟 = 𝑠
and after succeeding, passing obvious checks, out contains
a handle that points-to a newly-allocated theorem Γ ⊢ 𝑠 = 𝑟 .
Note that one interesting consequence of this style of im-
plementation is the ability to provide concise speciﬁcations
of Supervisionary’s system interface functions. Essentially,
the Supervisionary kernel is a grand exercise in pointer ma-
nipulation, and as such our system call speciﬁcations can
be expressed as Hoare Triples, using Separation Logic [4] as
our assertion language. Writing h ↦→trm Application(l, r)
to assert that the handle h points-to a term application (of
the term pointed-to by 𝑙 to the term pointed-to by 𝑟 ), and
writing out ↦→ b to assert that out points-to the Boolean
value b, we have:

{ℎ ↦→trm Application(l, r)}
Term.Handle.IsApplication(h, out)
{out ↦→ True}

(Here, the triple {𝑃 }𝐶{𝑄 } asserts that if the command 𝐶 ex-
ecutes in a state concordant with 𝑃 then the command suc-
ceeds and produces a state concordant with 𝑄.)

1

 
 
 
 
 
 
PriSC’22, January 22, 2022, Philadelphia, PA, USA

Dominic P. Mulligan and Nick Spinale

Note that Supervisionary lacks any analogue of the tradi-
tional LCF meta-language. Kernel and automation are now
decoupled, and code written in any language can “drive” the
kernel, providing it produces binary-compatible executables.

We now turn to speculation around potential uses of Su-
pervisionary. Exploring what follows is still a work-in-progress.

Runtime veriﬁcation Given our use of Wasm, we could
extend our system interface by also implementing the Wasm
System Interface [5]—a POSIX-like interface for Wasm. This
would transform Supervisionary from a mere programmable
proof-checker into a general-purpose sandbox, capable of
executing arbitrary programs, albeit with an unusual inter-
face for constructing proofs.

But: what happens if we blur the lines between Supervision-

ary’s interfaces for system access and proof-checking?

Untrusted code executing under Supervisionary’s super-
vision could be challenged to prove some theorem each time
it wished to open a ﬁle on the ﬁlesystem, or otherwise per-
form some side-eﬀect. These theorems could be correctness
or security-related theorems, corresponding to a prevailing
policy in force. Moreover, as Supervisionary is capable of
capturing the runtime state of untrusted code, these chal-
lenges can be HOL predicates that are functions of the rei-
ﬁed runtime state of untrusted code, the kernel, and the ar-
guments, and name of, the invoked system call.

Two predicates of interest are 𝜆𝑘.𝜆𝑢.𝜆𝑠.⊤ and 𝜆𝑘.𝜆𝑢.𝜆𝑠.⊥.
Here, ⊤ and ⊥ are truth and falsity, and 𝑘, 𝑢, and 𝑠 the kernel
and untrusted code states, and packed system call metadata,
reiﬁed as HOL data, at the point of invocation of the system
call. One can always prove {} ⊢ ⊤ and therefore 𝜆𝑘.𝜆𝑢.𝜆𝑠.⊤
represents no restriction, whereas {} ⊢ ⊥ is never provable,
absent axioms, with 𝜆𝑘.𝜆𝑢.𝜆𝑠.⊥ representing a “closing oﬀ”
of a system call. By making the challenge a function of the
system call name and arguments, this closing oﬀ can be spe-
ciﬁc, banning a process from calling a particular system call,
or a system call with a particular set of arguments, allowing
us to mimic mechanisms like seccomp from Linux.

We can go further: metadata about the behaviour of a run-
ning process could be maintained—for example, a record of
the system calls invoked by a process, thus far. This record
could be used in forming security or correctness challenges,
for example by forcing untrusted code to prove that writes
to a socket only ever happen after a read, or reads and writes
on sockets satisfy some protocol. In short, HOL acts as lin-
gua franca between kernel and untrusted code, through which
arbitrarily complex policies may be expressed.

2

Jailing, wherein a process voluntarily sheds capabilities,
is common in existing operating systems. This can be cap-
tured in Supervisionary by allowing a process to dynami-
cally replace the prevailing policy, 𝜙, with a new policy𝜓 , af-
ter proving that𝜓 is a reﬁnement of 𝜙: {} ⊢ ∀𝑘.∀𝑢.∀𝑠.𝜓 𝑘 𝑢 𝑠 −→
𝜙 𝑘 𝑢 𝑠. Note that this expresses that the states described by
𝜓 are a subset of those described by 𝜙.

Note that this idea shares some similarities with proof
carrying code, wherein binaries are accompanied with (skele-
ton) proofs of their adherence to some policy, and these
proofs checked by the operating system prior to execution [3].
However, the ideas sketched above generalise this: proofs
can be generated dynamically, as the program executes, and
could more aptly be called proof generating code. Pro-
cesses and the Supervisionary kernel work together to come
to a “mutual understanding” that the behaviour of the pro-
cess is indeed concordant with the prevailing policy.

Restructuring proof-checking tools Existing tools in the
HOL family could be refactored around Supervisionary by
changing their kernels to act as frontends to the Supervi-
sionary kernel for untrusted automation routines. Arguably,
this increases the robustness of existing tools, enforcing sep-
aration by isolation, rather than module boundaries. More
interestingly, this also means that Supervisionary acts as a
mechanism for “transporting” deﬁnitions and theorems be-
tween systems within the wider HOL family: systems are
capable of referring to, and manipulating, kernel objects pro-
duced by other systems through Supervisionary kernel han-
dles. With this, we can also bootstrap a full theorem-proving
environment, with associated libraries of content, on top of
Supervisionary without writing it from scratch.

Our prototype acts as both programmable proof-checker
and general-purpose sandbox. The previous section high-
lighted that this idea can be used to enforce runtime prop-
erties of programs. But, we can also use this blurring to
import ideas from the operating systems community into
the design of proof-checking software itself. For example, li-
braries of mathematical theorems and deﬁnitions could be
presented to Supervisionary’s users via a hierarchical or tag-
based ﬁle-system, and explored with command-line tools in
an interactive shell atop the Supervisionary kernel.

Lastly Supervisionary’s dual interpretation as sandbox and
proof-checker blurs the boundary between static and run-
time veriﬁcation, and between proof-checker and sandbox.
Whilst proofs can be generated by executables themselves at
runtime, they could also be generated interactively by users,
prior to the execution of a program, or even generated for
use by a program by other programs.

For example, the operational semantics and instruction
decoding functionality of Wasm is clearly embeddable in
HOL [6]. Using this, properties of a program 𝑃 to be exe-
cuted under Supervisionary could be established statically,
and registered with the kernel, perhaps interactively by a

The Supervisionary proof-checking kernel

PriSC’22, January 22, 2022, Philadelphia, PA, USA

user or by another program executing before 𝑃 executes.
This theorem can then be used by 𝑃 in closing challenges
from Supervisionary, issued at runtime, tying the correct-
ness of 𝑃 to its execution.

References
[1] Andreas Haas, Andreas Rossberg, Derek L. Schuﬀ, Ben L. Titzer,
Michael Holman, Dan Gohman, Luke Wagner, Alon Zakai, and
Bringing the web up to speed with We-
J. F. Bastien. 2017.
bAssembly.
the 38th ACM SIGPLAN Confer-
ence on Programming Language Design and Implementation, PLDI
2017, Albert Cohen and Martin T. Vechev (Eds.). ACM, 185–200.
https://doi.org/10.1145/3062341.3062363

In Proceedings of

[2] Robin Milner. 1972. Logic for Computable Functions: description of a

machine implementation.

[3] George C. Necula. 1997. Proof-Carrying Code. In Conference Record
of POPL’97: The 24th ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages, Papers Presented at the Symposium, Paris,
France, 15-17 January 1997, Peter Lee, Fritz Henglein, and Neil D. Jones
(Eds.). ACM Press, 106–119. https://doi.org/10.1145/263699.263712
[4] John C. Reynolds. 2002. Separation Logic: A Logic for Shared Mutable
Data Structures. In 17th IEEE Symposium on Logic in Computer Science
(LICS 2002), 22-25 July 2002, Copenhagen, Denmark, Proceedings. IEEE
Computer Society, 55–74. https://doi.org/10.1109/LICS.2002.1029817
[5] The WebAssembly working group. 2021. The WebAssembly System

Interface (WASI). https://wasi.dev.

[6] Conrad Watt. 2018. Mechanising and verifying the WebAssembly spec-
iﬁcation. In Proceedings of the 7th ACM SIGPLAN International Confer-
ence on Certiﬁed Programs and Proofs, CPP 2018, Los Angeles, CA, USA,
January 8-9, 2018, June Andronick and Amy P. Felty (Eds.). ACM, 53–
65. https://doi.org/10.1145/3167082

3

