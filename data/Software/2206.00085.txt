Noname manuscript No.
(will be inserted by the editor)

Semantically-enhanced Topic Recommendation Systems for
Software Projects

Maliheh Izadi · Mahtab Nejati · Abbas
Heydarnoori

2
2
0
2

y
a
M
1
3

]
E
S
.
s
c
[

1
v
5
8
0
0
0
.
6
0
2
2
:
v
i
X
r
a

Received: date / Accepted: date

Abstract Software-related platforms such as GitHub and Stack Overﬂow, have enabled
their users to collaboratively label software entities with a form of metadata called topics.
Tagging software repositories with relevant topics can be exploited for facilitating various
downstream tasks. For instance, a correct and complete set of topics assigned to a repos-
itory can increase its visibility. Consequently, this improves the outcome of tasks such as
browsing, searching, navigation, and organization of repositories. Unfortunately, assigned
topics are usually highly noisy, and some repositories do not have well-assigned topics.
Thus, there have been efforts on recommending topics for software projects, however, the
semantic relationships among these topics have not been exploited so far.

In this work, we propose two recommender models for tagging software projects that
incorporate the semantic relationship among topics. Our approach has two main phases;
(1) we ﬁrst take a collaborative approach to curate a dataset of quality topics speciﬁcally
for the domain of software engineering and development. We also enrich this data with the
semantic relationships among these topics and encapsulate them in a knowledge graph we
call SED-KGraph. Then, (2) we build two recommender systems; The ﬁrst one operates only
based on the list of original topics assigned to a repository and the relationships speciﬁed in
our knowledge graph. The second predictive model, however, assumes there are no topics
available for a repository, hence it proceeds to predict the relevant topics based on both
textual information of a software project (such as its README ﬁle), and SED-KGraph.

We built SED-KGraph in a crowd-sourced project with 170 contributors from both
academia and industry. Through their contributions, we constructed SED-KGraph with 2234
carefully evaluated relationships among 863 community-curated topics. Regarding the rec-
ommenders’ performance, the experiment results indicate that our solutions outperform

M. Izadi
Intelligent Software Engineering Lab
Sharif University of Technology
E-mail: maliheh.izadi@sharif.edu

M. Nejati
She is currently a PhD student at the University of Waterloo, Canada.
E-mail: mbnejati@ce.sharif.edu, mahtab.nejati@uwaterloo.ca

A. Heydarnoori
E-mail: heydarnoori@sharif.edu

 
 
 
 
 
 
baselines that neglect the semantic relationships among topics by at least 25% and 23% in
terms of Average Success Rate and Mean Average Precision metrics, respectively. We share
SED-KGraph, as a rich form of knowledge for the community to re-use and build upon. We
also release the source code of our two recommender models, KGRec and KGRec+. 1

Keywords Recommender System · Topics · Tags · Semantic Relationships · Knowledge
Graph · Software Projects · GitHub

1 Introduction

Software engineers and developers explore Software Information Sites such as GitHub and
Stack Overﬂow to ﬁnd interesting software components tailored to their needs, to reuse
source code, to ﬁnd answers to their programming questions and many more. However, the
sheer number of software entities (projects, questions, etc.) hosted on these sites hinders ef-
ﬁcient searching, retrieving, navigating, and categorizing said entities. For instance, GitHub
currently hosts more than 240 million software projects. 2 Many of these projects share
common characteristics such as similar objectives and functionalities. With the continuous
growth of these platforms, more advanced automatic solutions are needed to improve ac-
cessibility of software projects. Existing techniques for better organization, documentation
or and retrieval of software entities include various types of recommender systems [30,31,
24,37,28,17,14,13], similar repository retrieval [19,23,33], and project clustering [8,34,
20,32]. Topics, also known as tags, are a form of concise yet highly valuable metadata,
that enrich software entities with human knowledge. Topics annotate an entity based on
its core concepts. A software topic encompasses the key features of a repository including
which category it belongs to, its main programming language, its intended audience, its user
interface, and more. Topics complement textual descriptions of repositories as they high-
light their main aspects with explicit and short tokens. Thus, topics can greatly help with
the visibility of relevant entities to user queries. Consequently, they are used for improving
organization and retrieval of software repositories.

Topics can convey information in two ways; explicitly as stand-alone sources of infor-
mation, and implicitly through their semantic connections to one other. The former has been
extensively exploited to build topic recommendation systems [30,7, 6, 14]. For the latter,
consider the topic angular which refers to an open-source web application framework. 3
As Angular provides functionality for front-end development, a programmer can almost
immediately relate this topic to the frontend or web-development topic. Thus, there ex-
ist implicit links between topics angular, frontend, and web-development. In practice,
repository owners -probably due to lack of motivation- neglect tagging their projects with
sufﬁcient topics. Implicit connections mentioned above, can be utilized to track missing in-
formation, complement such incomplete topic sets, and consequently, improve the visibility
of a given repository. They can also help recommendation systems suggest more accurate
topic lists. However, the semantic relationships among software engineering topics and their
impact on the performance of such predictive models are not properly explored yet. In this
study, we strive to build more advanced recommendation systems for predicting key topics
of software repositories through exploiting these relationships.

1 https://github.com/mahtab-nejati/KGRec
2 January 2022, https://github.com/search
3 https://angular.io/

2

As much as topics and the relationships among them appear enticing for improving au-
tomated information retrieval-based tasks, there are several challenges for employing them
in real-world scenarios, including the well-known tag explosion phenomenon [10] and the
problem we call tangled topics. As users are free to deﬁne topics in the free-format text,
they can create differently-written yet synonymous topics for any given concept, as well as
compound and personal topics. This freedom results in an explosion of tags. That is when
the set of topics exceedingly grows in number to the point that the sheer multitude of top-
ics defeats their intended purposes. Furthermore, inspecting topics assigned by users, we
came upon many tangled topics. These are compound topics that bundle multiple atomic
concepts into a single tag and treat this tag as a distinct concept. Note that compound top-
ics which communicate an atomic concept do exists, e.g., single-page-application is
an atomic topic which should not be further dissected to multiple topics. However, a com-
pound topic such as java-library can easily be broken down into its constituent atomic
concepts without losing any semantic content. The same can happen by adding adjectives
to the existing atomic topics, such as small-library or big-library and the situation
worsens when small-java-library is also considered a unique concept. Unfortunately,
some models redundantly recommend such topics together for a given repository. We be-
lieve that learning and recommending tangled topics adds no value when an entity is already
assigned their atomic constituent topics. As a result, to build an enhanced recommender sys-
tem, we need to address both tag explosion and tangled topics problems through carefully
assessing the input set of topics. In an attempt to resolve the above challenges and to col-
lect a set of quality topics, GitHub has commenced a crowd-sourced project to feature a set
of community-curated Software Engineering and Development (SED) topics. 4 At the time
of commencing this study, this project curated 389 topics over the course of almost three
years. This set of GitHub’s featured topics contain valuable explicit information, however,
semantic relationships among topics is missing. In this study, we take this seed as an initial
set for topic collection and build upon it through acquiring more high-quality topics, and
annotating them with semantic information based on human knowledge.

The next challenge is to properly store the high-quality SED topics along with their se-
mantic connections. Knowledge graphs are a viable solution for this problem. More speciﬁ-
cally, such relationships can be modeled in the form of relation triples (cid:104) subject, verb-phrase,
object (cid:105). Take the previous example, we can store two types of relations as (cid:104)angular, is-a,
framework(cid:105), and (cid:104)angular, provides-functionality, frontend(cid:105). Knowledge graphs have
been shown useful in different tasks such as information retrieval, recommendation, ques-
tion answering, and search results’ ranking [38]. As a prominent example, the Google’s
knowledge graph is used to enhance its search engine’s results. They have also been widely
used in domain-speciﬁc applications for medical, ﬁnancial, news, social networks, etc. pur-
poses [38] as well as software engineering [16,4]. A knowledge graph of SED topics can
improve performance of topic-dependent tasks based on the topics assigned to the entities.
In addition, such a knowledge graph can also be utilized as a structured knowledge base for
the community to query, navigate, and perform an exploratory search against. Hence, we
aim to store the semantic information along with our topics in a knowledge graph, which we
then feed into our predictive model to recommend better topics.

A domain-speciﬁc knowledge graph can be built automatically through processing do-
main knowledge, manually with the help of domain experts, or in a hybrid manner. In the
software engineering domain, there exist a few semi- or fully-automatic approaches to build
knowledge graphs [35,16,4,21,22]. Zhao et al. propose HDSKG using a semi-automatic

4 https://github.com/github/explore

3

approach to construct a knowledge graph of SED topics [35]. Although HDSKG aims to
minimize the manual effort that goes into the construction of a knowledge graph, it obses-
sively chunks noun-phrases. This leads to the introduction of numerous tangled topics in
this knowledge graph. Moreover, the knowledge scope acquired using fully-automatic ap-
proaches tends to be restricted to speciﬁc aspects/technologies such that the concepts can
be predetermined or easily extracted. Construction of a knowledge graph of SED topics at
the scope of this study is much more challenging due to the diversity of topics, their types
of relationships, and the different abstraction levels of topics. Not to mention the data spar-
sity on particular topics, and data scatteredness across the web and multiple sources which
cause duplicate, incomplete, and incorrect data [9]. Consequently, we take a mostly manual
approach in conjunction with automation techniques for facilitating knowledge acquisition
and evaluation.

In the ﬁrst phase of our approach, using the contributions of 170 SE experts from both
academia and industry, we acquire high-quality SED topics, extract their semantic relation-
ships, evaluate this information, and store them in a domain-speciﬁc knowledge graph we
call SED-KGraph. We developed an online platform on which we partially automated the
growth of SED-KGraph using the help of our contributors in multiple iterations. We expand
the set of GitHub’s featured topics to a more comprehensive and inclusive one. To guarantee
the consistency of SED-KGraph, we centrally coordinate the expansion of this knowledge
graph. In the second phase, we propose recommendation systems for two scenarios; (1)
KGRec, a topic recommender system to predict missing topics, the topics relevant to the
entities but not assigned to them by users. Correctly predicting the missing topics improves
the completeness of the set of topics assigned to each project, which has been shown as an
important factor in performance of solutions to topic-dependent tasks [12]. We build KGRec
purely based on SED-KGraph through the application of spreading activation techniques. (2)
Next, we build upon KGRec by adding a machine learning-based component to the model
and proposing KGRec+, a fully automated topic prediction model. KGRec+ works based on
both the projects’ textual data and the knowledge captured in SED-KGraph. We demonstrate
that the recommender systems based on KGRec outperform the ones based on TopFilter, the
state-of-the-art technique for relevant topic prediction [6], especially when the set of initial
topics assigned to the project is limited in number. Our contributions are as follows:

– We develop and evaluate two topic recommenders that outperform the competing ap-

proaches by 23% to 151% in terms of Mean Average Precision (MAP) score.

– We collaboratively augment the set of GitHub featured topics with 393 community-
suggested topics. Furthermore, we present SED-KGraph to capture the semantic re-
lationships among atomic and semantically unique SED topics to improve the per-
formance of topic recommenders. We engage 170 practitioners and researchers from
16 technology-based companies and 11 universities in the expansion and validation of
SED-KGraph. The resultant knowledge graph consists of 863 topics, 2234 veriﬁed rela-
tionships, and 13 relation types.

– We publicly share our two main software artifacts; the data component (SED-KGraph),
and the model component (KGRec, KGRec+) along with their source code for use by
the SE community. 5

In the following, we ﬁrst deﬁne the problem formally. Next, we present the approach in
section 3, experiments’ settings in section 4, and our results in section 5. Finally, we discuss
threats to the validity of this study, and review the related work around the study.

5 https://github.com/mahtab-nejati/KGRec

4

Fig. 1: Overall workﬂow of our proposed approach

2 Problem Deﬁnition

GitHub hosts millions of repositories S = {r1, r2, .., rn}, where ri denotes a single software
project. Each repository may contain various types of information such as a description,
README ﬁles, wiki pages, and source code ﬁles. Each project may include a set of topics
T = {t1,t2, ...,tm}, where m is the number of assigned topics to a repository. Our goal is to
(1) augment the initial set of topics assigned to a given repository ri, or (2) recommend a set
of topics from scratch for a given topic-less repository r j. In both cases, we aim to enhance
recommender models using semantic relationships among high-quality topics.

3 Approach

Our approach consists of two main phases; (1) acquire and store high-quality topics and
the semantic relationships among them, (2) build stronger recommenders exploiting the se-
mantic source of information. In the ﬁrst phase, we exploit explicit human knowledge in
the domain to procure rich input data for our topic prediction models. In the next phase,
we propose two recommenders; KGRec is a topic augmentation model which is used when
an initial set of topics is already assigned to a given project which we aim to extend, i.e.,
predict the missing topics only based on the original set. Finally, we stack this model on top
of a machine learning-based component, building KGRec+, an automated topic set recom-
mender system. KGRec+ eliminates the need for the initial set of topics and takes the textual
data on the project and SED-KGraph as input. Figure 1 depicts the overall workﬂow of our
approach. In the following, we provide more details on the proposed approach.

3.1 Phase 1: Knowledge Graph Construction

As part of our approach for building better recommender systems, we need to utilize high
quality software engineering topics and their semantic relationships. Knowledge graphs are
a viable solution to store such information in a structured format. In this section, we lay out

5

Acquire high-quality SE topicsExtract the relationships among these topicsBuild a knowledge graph of quality SE topics and the semantic information among them: SED-KGraphUse GitHub’s set of featured topics as the seed  setPhase 1: Extract and structure domain knowledge for feeding the modelsPhase 2: Develop and enhance topic recommender systemsKGRec (Topic augmentation): predict missing topics given the original set of topics of a repository using only SED-KGraphKGRec+ (Topic set recommendation): predict a set of topics from scratch using SED-KGraph and a repository’s informationFig. 2: Knowledge graph construction

the methodology through which we construct and evaluate such knowledge graph. We utilize
a crowd-sourcing technique to build the SED-KGraph in a two-step process. To this end,
we design an online platform for SED-KGraph’s growth through community contributions.
Throughout the process, individuals are involved in one of the two roles of maintainer or
contributor. The ﬁrst two authors take on the role of maintainers and the participants of the
second step are the contributors. Figure 2 demonstrates the overall process of knowledge
graph construction.

3.1.1 Initialization

Maintainers initialize SED-KGraph with a set of topics, relation types, and relationships
in a manual coding process [25]. They incorporate the triangular validation [25] process
in which coders cross-evaluate the coding results. To initialize SED-KGraph, maintainers
studied the 389 topics featured provided by GitHub and used it as the seed set. For each
topic, maintainers studied the information available on the GitHub about it, as well as the
top projects on GitHub (based on the number of stargazers) labeled with it. Moreover, main-
tainers also searched each topic online to glean more knowledge on them. They referenced
these projects to make sure their understanding of the topic matched with the usage of the
topic in the community.

After acquiring an overall insight to the topics, maintainers deﬁned the relationships
among them in a manual coding process. They ﬁrst discussed the possible types of relation-
ships among the topics and decided on four basic, yet strongly effective ones as a primary
set of relation types. Note that this decision was made with the conciseness feature in mind,
knowing that the primary set of relation types is not comprehensive. Yet, the maintainers
look to include as many distinct atomic topics as possible to cover the diverse range of SED
topics. Then, they deﬁned the relationships in an iterative manual coding process. In this
process, each maintainer iterated over the set of topics several times, each time deﬁning
and/or correcting the relationships. Maintainers also incorporated triangular validation into
the process to validate the relationships. They reviewed the relationships deﬁned by each

6

MaintainersSED-KGraphGitHub Featured Topicsalgorithmbackendtesting...ContributorsCrowd-SourcingPartially Objective Labeling TaskMaintainersFree-text SuggestionsRelation TypesTopicsRelationshipsSuggestion RefinementStage 1: KG InitializationStage 2: KG ExpansionEvaluationAquisitionManual CodingInitial KG DraftRelation TypesTopicsRelationshipsTriangular Validationother to validate their correctness and effectiveness. In case of a disagreement, maintainers
discussed their reasons for approving/disapproving of a relationship and made the ﬁnal de-
cision on the relationship’s correctness together. If a consensus was not made, they included
the relationships of conﬂict in the initial knowledge graph to allow the contributors to deliver
the ﬁnal verdict on the correctness of these relationships as a third jury.

3.1.2 Expansion

After establishing the ﬁrst draft of SED-KGraph, the deﬁned relationships needed to be
evaluated. Furthermore, acquiring the community’s knowledge on the topics and the rela-
tionships among them would help expand SED-KGraph into a more comprehensive knowl-
edge graph. Thus, during the Expansion step, two separate tasks run simultaneously: a)
Evaluation of the previously deﬁned relationships, and b) Acquisition of new community
knowledge on topics, relation types, and relationships among the topics. To facilitate this
step, we deployed an online platform through which contributors engage in evaluation and
expansion of the knowledge graph. Contributors review the relationships among topics and
submit their suggestions in free-text forms.

Evaluation: In the knowledge graph Expansion step, contributors validate the correctness of
the already deﬁned relationships in SED-KGraph. They evaluate all the relationships deﬁned
during the Initialization step and Acquisition task. We achieve this through a partially objec-
tive labeling task [1], a type of crowd-sourced labeling task in which the label of the subject
to the task is determined based on inter-rater agreement. That is, the subject (cid:104)relationship(cid:105)
is assigned the label (“True” or “False”) which the majority of raters (contributors) have
given the subject. Contributors validate the correctness of each relationship by labeling it
with “True” and disapprove of the relationship by labeling it with “False”. In the end, we
consider the relationships as “approved” and add them to SED-KGraph only if the majority
of the contributors who reviewed the relationship have labeled it with “True”. Otherwise, the
relationship is disposed of. Therefore, to determine the objective label for each relationship,
we need votes from at least three contributors.

Acquisition: The expansion of SED-KGraph solely depends on community contributions.
To expand SED-KGraph such that it covers the currently missing SED topics and the rela-
tionships among them, we ask the contributors to provide relationship suggestions for each
of the topics they review through free-text forms. We also allow for new topic and rela-
tion type deﬁnitions As contributors submit their suggestions in a free-format text, there
is a chance for tag explosion and/or tangled topics. Moreover, the semantic uniqueness of
the relation types and topics is also at risk, leading to redundancy/duplication. To mitigate
such occurrences, we implement policies and functionalities, some of which are described
in Section 4.6. Note that these policies were to help maintainers centrally coordinate the
knowledge graph. The maintainers inspected the suggestions to mitigate the possibility of
tag explosion and tangled topics, as well as to ensure the semantic uniqueness of the relation
types. Once a suggestion is made, it must be validated by at least three other contributors
before it is integrated into the knowledge graph.

7

Fig. 3: Spreading Activation

3.2 Phase 2: Automated Topic Recommendation

In this phase, we propose two topic prediction models for two different scenarios; topic aug-
mentation and topic set recommendation. We build these recommenders using the semantic
information obtained in the previous phase.

3.2.1 Topic Augmentation

We ﬁrst propose KGRec, a model that takes the topics already assigned to a software project
as input and recommends missing but relevant topics. We apply a spreading activation tech-
nique [5] on SED-KGraph to depth one. Spreading activation techniques operate on se-
mantic networks based on the Spreading Activation theory in semantic networks. Figure 3
displays an overview of the spreading activation effect. When a set of nodes are activated,
in the graph spreading activation computes the activation score of other nodes.

We ﬁrst annotate SED-KGraph with node weights computed based on the popularity of
the topic in the community and the degree of the topic node in SED-KGraph. Our intuitions
are; (1) if a topic is used frequently in the community, its a more useful and valuable topic,
and (2) a topic with a higher degree in SED-KGraph is related to more topics, and conse-
quently has a better chance of being relevant to more projects which might be assigned the
related topic. The weights are calculated as

Wt = 0.5 × (Pt + Dt ),

(1)

in which Wt denotes weight of the node corresponding to topic t. Pt and Dt are deﬁned as
below as a measure of popularity and degree of the topic t respectively:

Pt =

Dt =

log (nt + 1)

max
ti∈T

log (nti + 1)

log (dt + 1)

max
ti∈T

log (dti + 1)

(2)

where nt is the number of projects in the platform labeled with topic t, dt is the total degree
of topic t in SED-KGraph, and T is the set of topics in SED-KGraph.

To generalize the formulation of the approach such that it can apply to the KGRec+
t (here

model as well, consider that topic t is relevant to project p with the probability Pr p

8

Pr p
t = 1 since topics are already assigned to the projects). With I as the set of initial topics
assigned to project p and N(I) as the set of topics that are immediate neighbors to at least
one of the topics in I, we spread this probability to compute the relevance score of topic t
to project p along SED-KGraph edges using Equation 3. Then, the model sorts the list of
candidate topics by the Sp

t s and return the top-k ones as a list of recommendations.
tk ;t ∈ N(I)

Pr p

(3)

Sp
t = Wt × ∑
tk∈I

3.2.2 Topic Set Recommendation

Here, we assume that repositories are not labeled with any topic. We build upon KGRec and
propose KGRec+ as a stand-alone topic set recommender model. We feed the model with
textual data on the project, and it predicts a list of relevant topics for the project employing
two components, the machine learning-based component and the KGRec component. As the
ML-based component, for the machine learning-based component in our proposed model,
we use a multi-label Logistic Regression (LR) text classiﬁer [14]. The machine learning-
based component, trained with textual data of projects, predicts the Pr p
t for each topic. We
take the top-m topics with highest Pr p
t and feed them to the KGRec component as the set
I. The KGRec component operates on this set of topics as input and augments the list of m
topics with g more topics to return a list of k = m + g topics as the recommendations.

4 Experiment Settings

In this section, we present our experimental setting. We ﬁrst state the research questions of
this study, then review the dataset, evaluation metrics, and model setting. Next, we provide
an overview of our baselines, contributors’ information engaged in the construction of SED-
KGRaph, and the platform using which the graph was built.

4.1 Research Questions

We aim to augment topic recommender models for software projects. Thus, we answer the
following research questions:

– RQ1: What are the characteristics of our collaboratively-constructed knowledge graph,

SED-KGraph?

– RQ2: How accurately can we augment a set of initial topics assigned to a repository

utilizing SED-KGraph?

– RQ3: How accurate is our topic set recommender, KGRec+, as a stand-alone predictive

model?

4.2 Dataset

We use the dataset from Izadi et al.’s study [14], which contains cleaned textual data on
about 152K projects, along with their topics. The set of topics in the dataset contains 236 of
GitHub’s featured topics (on average, 2.46 topics assigned to each repository). The textual
data includes repositories’ descriptions, README ﬁles, and wikis. We take 80% of the
152K projects as the training set for our machine learning-based component and leave the
remaining 20% as the test set.

9

4.3 Evaluation Metrics

We report the Success Rate (SR) of the relationships in the partially objective labeling task
as a measure of the quality of the relationships deﬁned by the maintainers during knowledge
graph Initialization or suggested by the contributors during Acquisition. SR is the ratio of
the relationships labeled “True” over the set of all the relationships under evaluation. The
relationships labeled with “True” are considered successfully deﬁned. Thus, with NT as the
number of relations labeled as “True” and NF as the number of relations labeled as “False”,
the metric is deﬁned as

SR =

NT
(NT + NF )

.

(4)

We also report the Absolute Agreement Ratio over True Relationships (AARTR) as a
measure of the quality of the community-approved relationships. A relationship is abso-
lutely agreed upon if all the contributors label it with the same label (“True” or “False”).
Respectively, a true relationship is absolutely agreed upon if all the contributors label it with
“True”. Considering NAA
as the number of absolutely agreed true relationships and NT as
T
the total number of true relationships, we deﬁne AARTR as

AART R =

NAA
T
NT

.

(5)

Finally, to quantify the reliability of the contributors in the Evaluation step, we report
Average Rater-Objective Conformance Rate (AROCR). Rater-Objective Conformance Rate
(ROCR) is how the reliability of raters (contributors) is measured in a crowd-sourced par-
tially objective labeling task [1]. Considering NC
as the number of votes from Ri that con-
Ri
form with the ﬁnal objective label of the items (relationships) and NRi as the total number of
votes from Ri, the ROCR for rater Ri is calculated as

ROCRRi =

NC
Ri
NRi

,

(6)

AROCR for the labeling task is deﬁned as the average of ROCRRi over all raters who
contributed to the task. We select this metric since we engage a large number of contributors.
Moreover, not all of our contributors review all the relationships, which makes metrics such
as Cohen’s kappa an inadequate measure of reliability for our case.

To evaluate the recommender systems, we run all approaches on the test set (20% of
the projects in the dataset). However, since KGRec recommends “missing” topics, both as a
stand-alone model and as a component of KGRec+, automatically calculated classiﬁcation
metrics such as recall and precision are irrelevant to the purpose of this study. We support
this statement by evaluating two baseline approaches [7,14] both automatically against the
ground truth and manually through human evaluation, and list the results in Table 1. The
results show that since the ground truth does not contain the missing topics, the automated
evaluation of the recommendation lists does not serve justice to the merits of each model
in recommending missing topics. Therefore, we sample 50 projects from the test set and
evaluate the results through a human evaluation process with ﬁve experts. Three evaluators
validate the results for each project. We engage ﬁve Computer Science experts from both
academia and industry in this human evaluation process. For each sampled project, we ask
three evaluators to go through the content of the project and then determine whether the
recommended topics were relevant to the project. To avoid biasing our evaluators towards

10

Table 1: Automated vs. manual evaluation

Model

Di Sipio et al. [7]
Izadi et al. [14]

ASR@5 Evaluation Method
Automated
24.60%
30.00%

Manual
30.80%
50.80%

any one of the approaches, we shufﬂe the results from different approaches before anony-
mously presenting them to the evaluators. KGRec is evaluated against TopFilter, and the
ML+KGRec is evaluated against the ML+TopFilter as their goals are aligned. We also in-
clude evaluations on the machine learning-based components to investigate how KGRec can
improve a machine learning-based solution.

As a measure of practicality of the missing topic recommendation task, we report the
percentage of the test cases in the test set and in the test sample set for which each of the
approaches fails to recommend any topics. For this purpose, with NFC as the number of test
cases a model fails to return any recommendations for and NC as the total number of test
cases in the set, we deﬁne Failed Case Ratio (FCR) as

FCR =

NFC
NC

.

(7)

To quantify the quality of the recommendations, we report Average Success Rate @k
(ASR@k) to evaluate the performance of the topic recommendation approaches. We also
report Mean Average Precision @k (MAP@K) metric, a commonly-used measure for eval-
uating recommender systems that returns a ranked list of results. It captures how high suc-
cessful suggestions are positioned in the recommendation list as well as the number of suc-
cessful suggestions. Note that as FCR is already reported in the missing topic recommen-
dation task’s results, we only report the ASR and MAP over the set of test case samples for
which the KGRec or TopFilter components do return a list of recommendations. However,
reporting FCR for the automated topic recommendation task is irrelevant since the recom-
mendation list is never empty.

4.4 Model Settings

First, to calculate the topic weights (Wt ), we get the number of public repositories labeled
with each of the 863 topics in SED-KGraph through GitHub API calls. We then construct
the weighted graph and implement KGRec in a tailored Python script. The input data to the
machine learning-based components is repositories’ description, README ﬁles, and wiki
pages. We train the MNB [7] and LR [14] models from the python library, scikit-learn,
for 236 of the GitHub featured topics, as these are the topics with enough supporting in-
stances for training in the dataset. We set k to 5 as the length of recommendation lists. When
evaluating the KGRec+ models, as the average number of topics assigned to the projects is
2.46, we set m to three. Then, feeding these m topics to the KGRec component, we take
top- f = 2 topics from KGRec to make a full list of top-5 recommendations.

4.5 Baselines

TopFilter, the state-of-the-art approach for augmenting a repository’s topics list based on
its initial set, is an item-based collaborative ﬁltering approach [6]. In this approach, each

11

project is represented with the set of topics it is assigned in a project-topic matrix. For each
project, taking the set of topics assigned to the project, the model computes the similarity
of this topic set with the topic sets of all other projects in the dataset and takes the topics
assigned to the top-25 most similar projects (in terms of the set of topics assigned to the
project) as the candidate set of topics. Calculating a ranking metric deﬁned by the authors,
the model returns the top-k topics as recommendations. While the authors do not evaluate
TopFilter as a single component, we use this model as the baseline for our ﬁrst task (topic
augmentation). Moreover, we use MNB+TopFilter[6], Di Rocco et al.’s proposed method of
automating the topic recommendation task as one of the baselines to the second task (topic
set recommendation). We also compare our method against Izadi et al.’s [14] and Di Scipio et
al.’s [7] proposed methods for the automated topic set recommendation. To provide a more
comprehensive evaluation, we stack our model on Di Scipio et al.’s[7] proposed model.
Moreover, we combine Di Rocco et al.’s[6] and Izadi et al.’s[14] approaches together and
introduce it as another baseline.

4.6 Platform

To facilitate the knowledge graph Expansion step, we designed and deployed an online
platform. We automatically retrieved GitHub’s featured topics and presented them to con-
tributors for knowledge acquisition. Moreover, contributors performed CRUD operations on
topics, relation types, and relationships (collectively called knowledge graph entities) inde-
pendently. We implemented an alias checker component into the platform which gave con-
tributors a level of autonomy in introducing new knowledge graph entities into the knowl-
edge graph while maintaining its consistency and semantic uniqueness. The alias checker
checks whether the knowledge graph entities that are being introduced by the contributors
are already deﬁned in the knowledge graph and detects aliases based on the topics’ names,
deﬁnitions, and alias lists. This is done by measuring the edit distance of topic names and
aliases, as well as by computing the similarity of topic deﬁnitions. Once a topic is detected as
potentially duplicate, it is listed along with the pair causing the duplicate for maintainers to
check on them. Finally, we establish policies to guarantee contributors’ eligibility for evalu-
ation and expansion of SED-KGraph. The policies include tutorials before granting permis-
sion to perform CRUD operations, random checks on the suggestions and evaluations by
maintainers, and reliability checks based on the conformance of contributors’ answers with
the objective labels of relationships. This helps identify issues in the knowledge graph and
potentially detecting unreliable users. Figure 4 presents multiple screenshots of our online
platform.

4.7 Contributors’ Overview

In this section, we provide an overview of contributors. To engage contributors and en-
sure diversity, we sent out invitations to the technical teams of 30 local technology-based
companies active in a variety of SED-related ﬁelds including software engineering, cloud
computing, data science, network, blockchain, security, social media, e-commerce, digital
advertisement, entertainment, etc. We also invited the students of related programs includ-
ing Computer Engineering, Computer Science, Data Science, Software Engineering, IT, etc.
from 20 top local and international universities. The invitation was open for a total of seven
months, over which individuals could apply to participate in the study.

12

(a) Suggestion form

(b) Dashboard

Fig. 4: Online platform for acquiring quality topics and their semantic relationships

(c) Suggestion form

To improve the reliability, we disqualiﬁed (1) students with less than three years of aca-
demic experience and no industrial experience, and (2) practitioners with less than three
years of industrial experience who did not have at least three years of prior academic expe-
rience. Since the ﬁrst six months of knowledge graph Expansion required a central control
over the suggestions, the maintainers thoroughly reﬁned the suggestions every two months
and issued the reﬁned suggestions for evaluation. Therefore, the ﬁrst three snapshots of the
SED-KGraph were captured. We engaged the ﬁrst 50 applicants during the ﬁrst, the next 40
applicants in the second, and the next 30 applicants in the third two-months period of knowl-
edge graph Expansion, resulting in the three snapshots. Finally, the last 50 applicants were

13

Table 2: Overview of contributors’ information

Snapshot

Duration

Background

Total

Gender

Male

Female

Experience
(Academia, years)
Avg Min Max

Experience
(Industry, years)
Avg Min Max

#1

#2

#3

#4

2 Months

2 Months

2 Months

6 Months

Academia
Industry
All

Academia
Industry
All

Academia
Industry
All

Academia
Industry
All

25
25
50

13
27
40

12
18
30

18
32
50

15
21
36

10
13
23

5
17
22

7
15
22

10
4
14

3
14
17

7
1
8

11
17
28

3.24
3.92
3.58

5.08
7.81
6.73

5.83
7.94
7.1

4.21
5.46
5.01

3
3
3

3
0
0

4
4
4

3
2
2

5
10
10

10
16
16

10
15
15

9
8
9

0
1.92
0.96

0
5.85
3.95

0
4.56
2.74

0
3.11
1.99

0
1
0

0
1
0

0
2
0

0
1
0

0
9
9

0
10
10

0
14
14

0
6
6

engaged in a long-term (six months) snapshot for expansion of the knowledge graph (fourth
snapshot). Throughout the knowledge graph Expansion step, we eliminated and replaced
unreliable contributors, i.e., contributors with Rater-Objective Conformance Rate (ROCR,
deﬁned in Section 3.1.2) lower than 50%. The reliability checker functionality of the on-
line platform automatically applies this policy among others to assure the reliability of the
contributors.

In the end, 170 individuals have made contributions to the study from 16 companies
and 11 universities. The diversity of the contributors’ experience and expertise matched our
requirements, considering the wide range of topics in the knowledge graph, and allowed for
a fair evaluation and expansion process. Table 2 presents more details, including the average
years of experience in both industry and academia, on the contributors.

5 Results

In this section, we provided the results of our approach. We ﬁrst review the characteristics of
the constructed knowledge graph to answer RQ1. Then, we proceed to present the evaluation
results of the two recommender models to address RQ2 and RQ3.

5.1 SED-KGraph: Data Characteristics

This section ﬁrst summarizes the results of each step in the knowledge graph construction
process, followed by the characteristics of SED-KGraph. Table 3 summarizes the results
captured in each snapshot.

Initialization: The seed set of topics from GitHub’s project contained 389 topics from a
wide variety of areas in SED, and from different levels of abstraction, i.e., topics could
be as coarse-grained as ai or as ﬁne-grained as django. However, this set proved to be
inadequate in representing the ﬁnal goal of the study since many proper topics such as
web-development, and ui-ux were missing. Moreover, such an occurrence is inevitable
due to the constant emergence of new topics in the community. The maintainers identiﬁed

14

Table 3: Expansion and maintenance results.
(*) T and F indicate True and False labels.
(**) These topics and relationships are gradually added to and evaluated in the snapshot#4.

Snapshot

Topics

Rel
Types

Veriﬁed
Rels

#1
#2
#3
#4
Total

461
640
716
812
863

4
12
13
13
13

0
982
1548
1864
2234

Evaluation (Relationships)

T*

982
566
316
370
2234

F*

101
69
6
41
217

SR

AARTR

AROCR

0.907
0.891
0.981
0.900
0.911

0.887
0.744
0.877
0.754
0.828

0.791
0.726
0.891
0.780
0.789

Rels

Topics

Acquisition (Suggestions)
Rel
Types
8
1
0
0
9

635
322
39
372**
1368

179
76
15
51**
321

this issue while deﬁning the relationships and as a solution, augmented the seed set with
72 more topics in the process of constructing the ﬁrst draft of SED-KGraph, enlarging the
set to include 461 distinct topics. Having conciseness in mind, maintainers deﬁned four
primary relation types, namely is-a, is-used-in-ﬁeld, provides-functionality, and works-with.
The ﬁrst three relation types capture three determinative characteristics of a topic regarding
the topic’s scope. The last relation type connects the most closely intertwined yet differently
categorized topics together. At the end, the maintainers agreed on 995 relationships and
disagreed over a total of 88 of them (8.13%). This yielded 1083 relationships with the four
primary types among the 389 featured topics and the 72 augmented topics in the initial draft
of SED-KGraph.

Expansion Figure 5 illustrates a sample node and its relationships’ evolution over the knowl-
edge graph Expansion process in the SED-KGraph.

In the ﬁrst snapshot, we evaluated the initial draft of SED-KGraph. From the 995 rela-
tionships in the initial knowledge graph, (excluding the 88 that the maintainers disagreed
on) contributors labeled 963 as “True” but disapproved 32 relationships. Contributors also
rejected 69 of relationships already disapproved by the maintainers and accepted only 19 of
them. This yielded a success rate of 96.78% for the set of 995 relationships, 21.60% for the
set of 88 relationships, and 90.67% in total. Among the 982 approved relationships, 88.68%
were unanimously labeled as true relationships by the contributors and the AROCR was
79.12%. Contributors also contributed to the expansion of the knowledge graph by provid-
ing 838 new suggestions in total. Through reﬁnement of these suggestions, the maintainers
yielded 635 new and distinct relationships, introducing 179 topics and eight relation types
that were not previously deﬁned in SED-KGraph. This made the set of topics grow in size up
to 640. Table 4 includes the descriptions and examples of the community-suggested relation
types.

In the second snapshot, the 635 new relationships acquired during the ﬁrst snapshot
were subject to evaluation, from which 566 ones were approved of and 69 relationships
were deemed ineffective by the contributors. This yielded a success rate of 89.13% for the
Evaluation step. The AARTR dropped to 74.38% and the AROCR was 72.56%. The reason
for such a drop can be explained by the number of relation types and their granularity. The
number of relation types reaches 12, which adds to the complexity of the knowledge graph
and might confuse the contributors to some extent. In this snapshot, the contributors made
a total of 642 relationship suggestions. Upon inspection, the maintainers identiﬁed 322 of
these as distinct and new ones. The 322 new relationships introduced 76 new topics to the
knowledge graph, enlarging the set of topics to 716 distinct ones. Moreover, one new relation
type was introduced.

15

(a) The First Snapshot

(b) The Second Snapshot

(c) The Third Snapshot

(d) Legend

Fig. 5: Sample Node Expansion.

In the third snapshot, we evaluated the new 322 relationships acquired in the previous
snapshot from which only six were disapproved. Contributors veriﬁed the remaining 316
relationships, resulting in a success rate of 98.14%. As the knowledge graph became more
stable and the number of new suggestions dropped, the AARTR grows back to an 87.66%
and the AROCR is 89.02%. The contributors made a total of 53 relationship suggestions in
this two-months period. After reﬁnement, the maintainers acquired 39 new and distinct rela-
tionship suggestions. These suggestions introduced 15 new topics to the knowledge graph.

For the ﬁnal snapshot, maintainers identiﬁed 17 more topics, and acquired 81 new top-
ics added to GitHub’s feature topic list during the past few months. Maintainers gradually
injected these topics, without initializing their relationship set, into the knowledge graph.
We asked contributors to deﬁne new relationships for these topics. As a result of this ex-
tra knowledge acquisition step, contributors deﬁned 532 more relationships. Reﬁnement of
these suggested relationships resulted in a set of 372 relationships, introducing 51 more top-
ics. These acquired relationships were also gradually injected into the knowledge graph and
evaluated over the same six months. Therefore, for the fourth snapshot, a total of 411 rela-
tionships (acquired over the previous step and during the fourth step) were evaluated. This
resulted in 370 of the relationships under review getting accepted and 41 of them getting re-
jected, yielding a success rate of 90.02%. We terminated this long-term phase as the number
of suggested relationships and topics by the contributors gradually diminished.

16

libraryweb-developmentrestfrontendbackbonejsreactis-ais-used-in-fieldworks-withprovides-functionalityworks-withlibraryweb-developmentmvcrestfrontendbackbonejsreactis-ais-used-in-fieldis-based-onworks-withprovides-functionalityworks-withmit-licenselibraryweb-developmentmvcrestfrontendbackbonejsreactis-ais-used-in-fieldis-based-onworks-withprovides-functionalityworks-withhas-licenseStep
Init.

Relation Type
is-a

is-used-in-ﬁeld

provides-functionality

works-with

Iter#1

is-subset-of

is-based-on

is-focused-on

has-property

overlaps-with

provides-product

provided-by

maintained-by

Iter#2

has-license

Description
This is the most basic relation type that allows for
the categorization of the topics of the same type
together.
Relationships of this type map the topic to the
ﬁeld or area it is used in and allow for categoriza-
tion based on the application ﬁeld.
Relationships of this type map the topic to the
functionality (i.e., the functional purpose of the
topic) it provides and allow for categorization
based on the functionality of topics.
Relations of this type map the topic to its depen-
dencies or compatibility constraints. This relation
is a bidirectional one, i.e., it matches the topics
that work together.
This type of relation allows for hierarchical cate-
gorization of topics, putting the subject topic un-
der a broader concept (object topic).
Relationships of this type indicate that the cre-
ation or development of the subject topic was
achieved through use of the object topic.
Relationships of this type emphasize the concepts
that the subject topic is concerned with.
This type of relation connects the subject topic to
meta-data topics. The meta-data topics only in-
clude the well-known and widely used ones.
This is a bidirectional relation that links two top-
ics which share some common grounds but are
not necessarily interdependent.
This relation type connects the subject topic as a
provider to the products it provides. The provider
could be a company, a software system, a tool, or
any other entity that creates and provides another
entity as a product.
This is the inverse of the “provides-product” re-
lation type and keeps the provider and the product
connected when the provider is the topic of user’s
interest.
Relationships of this type connect the subject
topic to the authorities that maintain the subject
topic.
This relation type maps connects the subject topic
to its corresponding license.

Example
(django, is-a, framework)

(django,
web-development)

is-used-in-ﬁeld,

(django,
backend)

provides-functionality,

(django, works-with, python)

(deep-learning,
neural-network)

is-subset-of,

(archlinux, is-based-on, linux)

(agile,
flexibility)
(mysql,
open-source)

is-focused-on,

has-property,

(robotics, overlaps-with, ai)

(google,
flutter)

provides-product,

(atom, provided-by, github)

(html, maintained-by, w3c)

(backbonejs,
mit-license)

has-license,

Table 4: Relation types’ descriptions and examples

5.1.1 Resultant Knowledge Graph

SED-KGraph consists of 2234 relationships of 13 relation types among 863 distinct soft-
ware topics. Topics appear as both the subject and the object topic in relationships. The
topic web-development has the maximum number of appearances (78 relationships), while
the minimum number of appearances is one. While one might argue that such rare topics
should be eliminated from the knowledge graph, they can be among the useful topics fre-
quently used by the community. Examples of such topics are awesome, authorization,
and augmented-reality, each assigned to 3863, 1847, and 1628 projects on GitHub, mak-
ing them well-known topics in the community. They are also evidently important topics in

17

Fig. 6: Top 25 most frequent topics

Table 5: Relation type frequency

Relation Type
has-license
has-property
is-a
is-based-on
is-focused-on
is-subset-of
is-used-in-ﬁeld

Count
30
134
578
55
43
19
440

Relation Type
maintained-by
overlaps-with
provided-by
provides-functionality
provides-product
works-with

Count
6
7
25
429
18
450

the SED domain. Not to mention the topics denoting programming languages that fall un-
der the same circumstances are important topics when used as labels for software entities.
Moreover, we believe that dropping such topics hinders the effective expansion of SED-
KGraph. For SED-KGraph to remain valid and correct, it should be continuously expanded
as new ﬁelds and technologies are always at emergence. Such rarely present topics might
rise to popularity or be newly emergent ones that need to be well-established in the knowl-
edge graph through future contributions. Thus, we address this issue by assigning weights
to topics and relationships. Figure 6 presents the long-tail plot of the number of relationship
appearances per topic, for the 25 most recurrent ones. Moreover, Table 5 details the num-
ber of relationships in the knowledge graph per type of the relations. Notice how the four
primary relation types, is-a, is-used-in-ﬁeld, provides-functionality, and works-with, are the
most common relationships in the knowledge graph.

5.2 KGRec: Topic Augmentation Model

Table 6 summarizes the results from the missing topic recommendation task. As the FCR
values indicate, TopFilter [6] fails to make any recommendations for almost 50% of the test
cases, no matter the correctness of the recommendations. The reason behind this is mainly
the limited number of topics assigned to the projects in the dataset (2.46 topics on average
which is closer to reality). Any collaborative ﬁltering method suffers from the cold start
problem [26]. An average of 2.26 topics too indicates the data sparsity, i.e., there are limited
items (topics) assigned to projects, which in turn results in the cold start problem. This

18

0102030405060708090web-developmentframeworktooljavascriptprogramming-languageopen-sourcemobilefrontendsoftware-developmentuser-interfacecross-platformsoftware-development-processuser-experiencehtmlpythongame-developmentplatformlinuxbackendphpscientificcssdesktoplibrarycppRelationship CountTable 6: Topic augmentation results

Model

Di Rocco et al.[6]
KGRec (proposed)

Over Test Set
FCR
50.15%
2.06%

Over Sampled Test Set

FCR
ASR@5 MAP@5
10.31%
28.33%
46.00%
2.00% 47.32% 32.86%

Table 7: Automated topic set recommendation results

Model

Baselines

[7]
[6]
[14]
KGRec + [7]
[6] + [14]
KGRec+

Modiﬁed
Baselines
Proposed
Outperforming baselines by

ASR@5
30.80%
41.20%
50.80%
54.80%
58.40%
72.80%

MAP@5
27.07%
33.47%
48.93%
42.94%
55.05%
67.87%

+25% to +136% +23% to +151%

shortcoming of TopFilter is also pointed out as a limitation of the approach by Di Rocco et
al. [6]. Taking into account that the dataset is captured from a real-world setting, this raises
questions about the practicality of TopFilter. However, KGRec overcomes this limitation
and manages to make recommendations under such circumstances. To better understand
the magnitude of the improvements that KGRec brings forth, one must take the FCR into
account. The ASR measure for this task is only calculated over the set of test cases which the
approach under evaluation has managed to make recommendations for. That is, for TopFilter,
the ASR is calculated over 54% of the test cases, while for KGRec, it is calculated over 98%
of the test cases. Regardless, KGRec outperforms the baselines by +67% and +218% in
terms of ASR and MAP respectively. That is, KGRec performs considerably better over a
wider set of test cases, while the baseline has a high ratio of FCR.

5.3 KGRec+: Topic Set Recommendation Model

Table 7 presents the automated topic set recommendation’s results. Notice that reporting
FCR for this task is irrelevant since the machine learning-based components of the ap-
proaches always manage to make a list of recommendations, which compose part of the
ﬁnal recommendation lists. Therefore, FCR for each of the approaches values at zero in
such circumstances. To further evaluate KGRec+, we improve the baseline approaches by
combining them with each other or stacking KGRec on top of the approach. We include
the resultant models as modiﬁed baselines. The results indicate that not only KGRec+ out-
performs all the previously proposed baselines by at least 43.31% and 38.71% in terms of
ASR and MAP respectively, but it also yields better results than the modiﬁed and improved
versions of the baseline approaches. To be exact, KGRec+ outperforms all the approaches,
including the modiﬁed ones, by at least 25% and 23% in terms of ASR and MAP, respec-
tively.

5.4 Threats to Validity

In this section, we discuss the possible threats to the validity of this study and how we have
addressed these threats.

19

Internal Validity These threats correspond to the correctness of the relationships and the
subjectiveness of contributors and maintainers. We address the former by evaluating ev-
ery relationship through a partially objective labeling task in which at least three and up
to nine contributors validate the correctness of the relationships. As for the latter, aside
from the knowledge graph Initialization stage, the effect of maintainers’ personal experi-
ence and knowledge was minimized by limiting their role to ﬁxing consistency issues in
the suggestions from the community in the continuous second stage. The subjectiveness of
the contributors was also mitigated by engaging 170 experts as the contributors. To avoid
inaccurate votes, we also make it possible for contributors to only contribute to the topics
related to their expertise by skipping the unfamiliar topics. Another factor can be errors in
our code or in the libraries that we have used. To reduce this threat, we have double-checked
the source code. But there still could be experimental errors in the setup that we did not no-
tice. Therefore, we have released our code and dataset publicly, to enable other researchers
in the community to use/replicate it6.

External Validity These threats correspond to the generalizability and effectiveness of our
graph and recommenders. Through crowd-sourcing the expansion of SED-KGraph, we ad-
dress the generalizability and effectiveness concerns. We also validated the relationships in
multiple snapshots with the community, assuring their correctness and effectiveness. Al-
though we use GitHub’s featured set as the initial seed set, the resultant knowledge graph is
not restricted to any platform and can be re-used in other software-related platforms. Con-
tributors were indeed instructed to incorporate their knowledge of Software Engineering
while assessing/suggesting relationships and topics, irrespective of any speciﬁc SED plat-
form. As for the topic recommendation, the KGRec component only takes the initial set of
topics assigned to software projects as the input. Thus, it can be easily adapted for use on
any software-related platform and any software entity. For the KGRec+ model, as long as
proper textual information is available for a project, the model is able to recommend rele-
vant topics. Moreover, the machine learning-based component can be re-trained with textual
information of other software entities, making the model functional for the recommendation
of topics for those entities as well. Also for training, datasets were randomly split to avoid
introducing bias.

Construct Validity These threats correspond to the features and capabilities of the online
platform used for knowledge graph expansion, and the sensitivity of KGRec to its input.
We allowed for free-text topics and relation types in the suggestion forms to allow for the
expansion of the knowledge graph. This resulted in consistency issues, which maintainers
handled by reﬁning the suggestions. This concern is further handled in the ﬁnal version of
the platform through the use of specially designed features and policies. Moreover, KGRec
is sensitive to the correctness of the initial set of topics assigned to the project, such that
the inaccuracy misleads the model on SED-KGraph. This limitation calls for an accurate
machine learning-based component to be combined with KGRec. To address this threat,
we used a multi-class multi-label LR classiﬁer, which has been shown to exhibit the best
performance among similar machine learning-based approaches [14].

6 https://github.com/mahtab-nejati/KGRec

20

6 Related Work

We organize the related work as approaches on (1) topic recommendation for software
projects, (2) for other software entities, and ﬁnally studies on (3) knowledge graphs for
software engineering.

Topic Recommendation for Software Projects: There are several studies with a focus on
topic recommendation for software projects [30,31,24,2,37,28,29,17,7,14]. Sally presented
by Vargas-Baldrich et al. [24], is a tool for generating topics for Maven-based software
projects through analyzing their bytecode and the dependency relations among them. Their
approach, unlike ours, is limited in application due to being dependent on the programming
language. Cai et al. [2] proposed a graph-based cross-community approach calledGRETA,
for assigning topics to repositories. Their approach is to ﬁrst construct an Entity-Tag Graph
and for each queried project, take a random walk on a subset of the graph around the most
similar entities to the queried one to assign tags to the project. While they do propose a
graph-based approach, their graph fundamentally differs from ours in nature. Di Sipio et
al. [7], proposed using an MNB classiﬁer for classiﬁcation of about 134 GitHub topics. In
each top-k recommendation list, authors predict k −1 topics using text analysis and one topic
using a code analysis tool called GuessLang. TopFilter [6], the state of the art for missing
topic recommendation, is the most similar study to ours in terms of purpose (topic augmen-
tation task). Authors take an item-based collaborative approach for recommending missing
topics. Our experiments prove that their approach suffers from practicality issues, which
our proposed approach overcomes. Most recently, Izadi et al. [14], demonstrated the impact
of clean topics and proposed a multi-label Logistic Regression classiﬁer for recommending
topics. Our approach is orthogonal to this study, thus we incorporate their approach in this
work.

Topic Recommendation for other Software Entities: There are several pieces of research on
tag recommendation for other types of software entities such as questions on Stack Over-
ﬂow, Ask Ubuntu, and Ask Different [28,29,37,30,17,18]. The discussion around these tags
and their usability in the SE community have been so fortiﬁed that the Stack Overﬂow plat-
form has also developed a tag recommendation system of its own. These approaches mostly
employ word similarity-based and semantic similarity-based techniques. Xia et al. [30] fo-
cused on calculating the similarity based on the textual description. The authors propose
TagCombine for predicting tags for questions using a multi-label ranking method based on
OneVsRest Naive Bayes classiﬁers. Semantic similarity-based techniques [28,29,17] con-
sider text semantic information and perform signiﬁcantly better than the former approach.
Wang et al. [28,29], proposed ENTAGREC and ENTAGREC++ which uses a mixture model
based on LLDA to consider all tags together. Liu et al. [17], proposed FastTagRec, for tag
recommendation using a neural-network-based classiﬁcation algorithm and bags of n-grams
(bag-of-words with word order). As a possible future direction, our SE-based knowledge
graph and approach can also be utilized for recommending topics for these types of soft-
ware entities.

Knowledge Graphs for Software Engineering: Knowledge graphs have been utilized in
numerous studies to address different software engineering problems. In some cases, re-
searchers strive for a fully automated knowledge graph extraction approach from the avail-
able textual data. However, more often than not, these studies narrow the scope of their
knowledge graph’s content down to very speciﬁc aspects. In such cases, concept extraction

21

from the textual data can be achieved through use case-speciﬁc tailored solutions, especially
when the input data for knowledge graph construction is in a semi-structured or expected for-
mat [16,4, 21, 22,27] or in some extreme cases, the concepts are predeﬁned[36]. Some stud-
ies recognize that a fully-automated approach does not sufﬁce to their purpose, even in the
limited scope of knowledge they intend to model and opt for semi-automated solutions [15,
3]. HDSKG [35] is a framework for mostly-automated knowledge graph construction. The
authors applied their approach to the tagWiki pages on Stack Overﬂow in an attempt to
construct a domain-speciﬁc knowledge graph of SED topics. The authors claim HDSKG
includes 44, 800 unique concepts (topics) and 35, 279 relation triples of 9, 660 unique verb
phrases (relation types). While HDSKG can guarantee the lexical uniqueness of concepts
and verb phrases through applying text processing techniques, the semantic uniqueness
can not be promised. The lack of semantic uniqueness leads to tag explosion and redun-
dant/duplicate verb phrases and relationships, which can be well hidden since neither the
concepts nor the verb phrases are mapped to their semantically equivalent terms. Unfortu-
nately, neither the resultant knowledge graph nor the code base of this work are publicly
available. However, based on the sample nodes of HDSKG, its automatic method of extract-
ing noun phrases results in tangled topics such as small-java-library. This justiﬁes the
enormous number of extracted topics and relationships. While HDSKG can be used in con-
junction with our approach and replace the Acquisition process, the sheer multitude of the
concepts and verb phrases works to the detriment of integrity and consistency concerns. The
applicability of a knowledge graph of SED topics is highly sensitive to tag explosion and
tangle topics problems, a threat that semi-automated and fully-automated approaches fail to
mitigate. Especially with tangled topics as a concern while there are compound topics that
convey atomic concepts as SED topics, each of the approaches leans towards detecting one
and missing the other. Finally, some studies resort to fully-manual construction approaches
due to data scatteredness and sparsity [9] or make use of pre-constructed community-deﬁned
knowledge graphs for their purposes [11]. Consequently, we opted for a hybrid approach to
avoid pitfalls of each method described above, while obtaining high-quality topics and rela-
tionships as much as possible.

7 Conclusions and Future Work

We engaged 170 researchers and practitioners to collaboratively construct a software engi-
neering and development knowledge graph, SED-KGraph. To initialize the study, we ﬁrst
drafted a primary version, taking GitHub’s featured topics as the seed topic set. Through
their contributions, we constructed SED-KGraph with 2234 carefully evaluated relationships
among 863 community-curated topics. Our experiments yield that this model achieves re-
sults 1.7X and 3.2X higher regarding ASR@5 and MAP@5 respectively. We also built upon
this recommender system and added a machine learning-based component to the approach
to develop a stand-alone automated topic recommender system, KGRec+. The results show
that KGRec+ outperforms the state-of-the-art baseline approaches as well as the modiﬁed
and improved ones by at least +25% and +23% regarding ASR@5 and MAP@5 respec-
tively. We publicly share SED-KGraph, as a rich form of knowledge for the community to
re-use and build upon. Furthermore, we release the source code of our two recommender
models. In the future, we will invest in training contextual-based models to further improve
the performance of the recommenders. Moreover, we aim to study other applications of
SED-KGraph in different contexts such as search engines and information retrieval as well
as other information websites such as Stack Overﬂow.

22

Acknowledgements We would like to thank all the participants in constructing and evaluating our knowl-
edge graph, as well as assessing our recommender model.

Conﬂict of interest

The authors declare that they have no conﬂict of interest.

References

1. O. Alonso, C. Marshall, and M. Najork. Crowdsourcing a subjective labeling task: a human-centered
framework to ensure reliable results. Microsoft Res., Redmond, WA, USA, Tech. Rep. MSR-TR-2014–91,
2014.

2. X. Cai, J. Zhu, B. Shen, and Y. Chen. Greta: Graph-based tag assignment for github repositories. In
In Proceedings of the 40th Annual Computer Software and Applications Conference (COMPSAC), vol-
ume 1, pages 63–72. IEEE, 2016.

3. J. Cao, T. Du, B. Shen, W. Li, Q. Wu, and Y. Chen. Constructing a knowledge base of coding conventions

from online resources. pages 5–10, 07 2019.

4. D. Chen, B. Li, C. Zhou, and X. Zhu. Automatically identifying bug entities and relations for bug
analysis. In 2019 IEEE 1st International Workshop on Intelligent Bug Fixing (IBF), pages 39–43, 2019.
5. F. Crestani. Application of spreading activation techniques in information retrieval. Artiﬁcial Intelligence

Review, 11(6):453–482, 1997.

6. J. Di Rocco, D. Di Ruscio, C. Di Sipio, P. Nguyen, and R. Rubei. Topﬁlter: An approach to recommend
relevant github topics. In In Proceedings of the 14th International Symposium on Empirical Software
Engineering and Measurement (ESEM), ESEM ’20, New York, NY, USA, 2020. Association for Com-
puting Machinery.

7. C. Di Sipio, R. Rubei, D. Di Ruscio, and P. T. Nguyen. A multinomial na¨ıve bayesian (mnb) network
to automatically recommend topics for github repositories. In In Proceedings of the 24th International
Conference on Evaluation and Assessment in Software Engineering (EASE), pages 71–80. 2020.

8. J. Escobar-Avila, M. Linares-V´asquez, and S. Haiduc. Unsupervised software categorization using byte-
code. In In Proceedings of the 23rd International Conference on Program Comprehension (ICPC), pages
229–239. IEEE, 2015.

9. S. Fathalla and C. Lange. Eventskg: a knowledge graph representation for top-prestigious computer
In In Proceedings of the 10th International Conference on Computational

science events metadata.
Collective Intelligence (ICCCI), pages 53–63. Springer, 2018.

10. S. A. Golder and B. A. Huberman. Usage patterns of collaborative tagging systems. Journal of informa-

tion science, 32(2):198–208, 2006.

11. Z. Han, X. Li, H. Liu, Z. Xing, and Z. Feng. Deepweak: Reasoning common software weaknesses
via knowledge graph embedding. In In Proceedings of the 25th International Conference on Software
Analysis, Evolution and Reengineering (SANER), pages 456–466. IEEE, 2018.

12. C. Held, J. Kimmerle, and U. Cress. Learning by foraging: The impact of individual knowledge and

social tags on web navigation processes. Computers in Human Behavior, 28(1):34–40, 2012.

13. M. Izadi, K. Akbari, and A. Heydarnoori. Predicting the objective and priority of issue reports in software

repositories. Empirical Software Engineering, 27(2):1–37, 2022.

14. M. Izadi, A. Heydarnoori, and G. Gousios. Topic recommendation for software repositories using multi-

label classiﬁcation algorithms. Empirical Software Engineering, 26(5):1–33, 2021.

15. S. Karthik and N. Medvidovic. Automatic detection of latent software component relationships from
online q&a sites. In Proceedings of the 7th International Workshop on Realizing Artiﬁcial Intelligence
Synergies in Software Engineering, RAISE ’19, page 15–21. IEEE Press, 2019.

16. H. Li, S. Li, J. Sun, Z. Xing, X. Peng, M. Liu, and X. Zhao.

Improving api caveats accessibility by
mining api caveats knowledge graph. In In Proceedings of the 34th International Conference on Software
Maintenance and Evolution (ICSME), pages 183–193, 2018.

17. J. Liu, P. Zhou, Z. Yang, X. Liu, and J. Grundy. Fasttagrec: fast tag recommendation for software

information sites. Automated Software Engineering, 25(4):675–701, 2018.

18. S. K. Maity, A. Panigrahi, S. Ghosh, A. Banerjee, P. Goyal, and A. Mukherjee. Deeptagrec: A content-
cum-user based tag recommendation framework for stack overﬂow. In In Proceedings of the 41st Euro-
pean Conference on Information Retrieval (ECIR), pages 125–131. Springer, 2019.

23

19. C. McMillan, M. Grechanik, and D. Poshyvanyk. Detecting similar software applications. In In Pro-
ceedings of the 34th International Conference on Software Engineering (ICSE), pages 364–374. IEEE,
2012.

20. J. Reyes, D. Ram´ırez, and J. Paciello. Automatic classiﬁcation of source code archives by programming
language: A deep learning approach. In 2016 International Conference on Computational Science and
Computational Intelligence (CSCI), pages 514–519, 2016.

21. J. Sun, Z. Xing, R. Chu, H. Bai, J. Wang, and X. Peng. Know-how in programming tasks: From textual

tutorials to task-oriented knowledge graph. pages 257–268, 09 2019.

22. J. Sun, Z. Xing, X. Peng, X. Xu, and L. Zhu. Task-oriented api usage examples prompting powered by

programming task knowledge graph, 2020.

23. F. Thung, D. Lo, and L. Jiang. Detecting similar applications with collaborative tagging. In In Pro-
ceedings of the 28th International Conference on Software Maintenance (ICSM), pages 600–603. IEEE,
2012.

24. S. Vargas-Baldrich, M. Linares-V´asquez, and D. Poshyvanyk. Automated tagging of software projects
using bytecode and dependencies (n). In In Proceedings of the 30th International Conference on Auto-
mated Software Engineering (ASE), pages 289–294. IEEE, 2015.

25. S. Wagner and D. M. Fern´andez. Chapter 3 - analyzing text in software projects. In C. Bird, T. Menzies,
and T. Zimmermann, editors, The Art and Science of Analyzing Software Data, pages 39 – 72. Morgan
Kaufmann, Boston, 2015.

26. H. Wang, F. Zhang, J. Wang, M. Zhao, W. Li, X. Xie, and M. Guo. Ripplenet: Propagating user prefer-
ences on the knowledge graph for recommender systems. In Proceedings of the 27th ACM International
Conference on Information and Knowledge Management, CIKM ’18, page 417–426, New York, NY,
USA, 2018. Association for Computing Machinery.

27. L. Wang, X. Sun, J. Wang, Y. Duan, and B. Li. Construct bug knowledge graph for bug resolution. In In
Proceedings of the 39th International Conference on Software Engineering Companion (ICSE-C), pages
189–191. IEEE, 2017.

28. S. Wang, D. Lo, B. Vasilescu, and A. Serebrenik. Entagrec++: An enhanced tag recommendation system

for software information sites. Empirical Software Engineering, 23(2):800–832, 2018.

29. T. Wang, H. Wang, G. Yin, C. X. Ling, X. Li, and P. Zou. Tag recommendation for open source software.

Frontiers of Computer Science, 8(1):69–82, 2014.

30. X. Xia, D. Lo, X. Wang, and B. Zhou. Tag recommendation in software information sites. In 2013 10th

Working Conference on Mining Software Repositories (MSR), pages 287–296. IEEE, 2013.

31. D. L. Xin-Yu Wang, Xin Xia. Tagcombine: Recommending tags to contents in software information

sites. Journal of Computer Science and Technology, 30(5):1017, 2015.

32. Y. Yang, Y. Li, Y. Yue, Z. Wu, and W. Shao. Cut: A combined approach for tag recommendation in
software information sites. In F. Lehner and N. Fteimi, editors, Knowledge Science, Engineering and
Management, pages 599–612, Cham, 2016. Springer International Publishing.

33. Y. Zhang, D. Lo, P. S. Kochhar, X. Xia, Q. Li, and J. Sun. Detecting similar repositories on github. In
In Proceedings of the 24th International Conference on Software Analysis, Evolution and Reengineering
(SANER), pages 13–23. IEEE, 2017.

34. Y. Zhang, F. F. Xu, S. Li, Y. Meng, X. Wang, Q. Li, and J. Han. Higitclass: Keyword-driven hierarchical

classiﬁcation of github repositories. arXiv preprint arXiv:1910.07115, 2019.

35. X. Zhao, Z. Xing, M. A. Kabir, N. Sawada, J. Li, and S. Lin. Hdskg: Harvesting domain speciﬁc
knowledge graph from content of webpages. In In Proceedings of the 24th International Conference on
Software Analysis, Evolution and Reengineering (SANER), pages 56–67, 2017.

36. Y. Zhao, H. Wang, L. Ma, Y. Liu, L. Li, and J. Grundy. Knowledge graphing git repositories: A prelim-
inary study. In 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengi-
neering (SANER), pages 599–603, 2019.

37. P. Zhou, J. Liu, Z. Yang, and G. Zhou. Scalable tag recommendation for software information sites. In
In Proceedings of the 24th International Conference on Software Analysis, Evolution and Reengineering
(SANER), pages 272–282. IEEE, 2017.

38. X. Zou. A survey on application of knowledge graph.

Journal of Physics: Conference Series,

1487:012016, 03 2020.

24

