2
2
0
2

n
u
J

4

]

O
R
.
s
c
[

2
v
0
7
7
0
0
.
6
0
2
2
:
v
i
X
r
a

Winning the 3rd Japan Automotive AI Challenge -
Autonomous Racing with the Autoware.Auto
Open Source Software Stack

Zirui Zang†, Renukanandan Tumu†, Johannes Betz†, Hongrui Zheng†, and Rahul Mangharam†

Abstract—The 3rd Japan Automotive AI Challenge was an
international online autonomous racing challenge where 164
teams competed in December 2021. This paper outlines the
winning strategy to this competition, and the advantages and
challenges of using the Autoware.Auto open source autonomous
driving platform for multi-agent racing. Our winning approach
includes a lane-switching opponent overtaking strategy, a global
raceline optimization, and the integration of various tools from
Autoware.Auto including a Model-Predictive Controller. We
describe the use of perception, planning and control modules
for high-speed racing applications and provide experience-based
insights on working with Autoware.Auto. While our approach
is a rule-based strategy that is suitable for non-interactive
opponents, it provides a good reference and benchmark for
learning-enabled approaches.

Index Terms—autonomous systems, automobiles, intelligent

vehicles, model predictive control, path planning

I. INTRODUCTION

Autonomous Racing is an efﬁcient research and devel-
opment setting for safe autonomous vehicles. In everyday
driving, vehicles are designed to be as safe as possible.
Performance can be difﬁcult to measure in everyday driving
maneuvers, such as merging on the highway, or overtaking
slower trafﬁc. While performance can be difﬁcult to quantify
in these everyday scenarios, the hesitation or aggressiveness
of a vehicle in conducting these maneuvers can have a
signiﬁcant impact on safety. Too much hesitation, and the
vehicle may interrupt the ﬂow of trafﬁc, becoming a trafﬁc
hazard. Too agressive, and the vehicle may cause collisions
and reactionary behaviour from other drivers.

Autonomous racing, on the other hand, penalizes safe but
conservative policies so that the need for robust, adaptive
strategies is critical. Racing adversarial agents magniﬁes this
tension and is an useful setting for testing the limits of safety
and performance across the perception, planning and control
stack of autonomous vehicles. Since the track is known and
the sole objective of racing is to minimize laptime without
crashing, autonomous racing focuses on achieving this with
high speeds, high accelerations, and low reaction times. As
the opponent’s strategy is secret and cannot be obtained by
collecting data before the competition, driving decisions must
be made online with high levels of uncertainty in a dynamic
and adversarial environment.

†University of Pennsylvania, School of Engineering and Applied Sci-
ence, 19106 Philadelphia, PA, USA zzang, nandant, joebetz,
hongruiz, rahulm@seas.upenn.edu

Consequently, autonomous racing [1] has become popular
over the recent years. Competitions at full scale such as
Roborace or the Indy Autonomous Challenge [2], as well
as at small-scale such as F1TENTH [3], provide platforms
and benchmarks for evaluating autonomous driving software.
The community’s research interests are in two general rac-
ing contexts: achieving super-human performance in single-
vehicle racing, and performing intelligent overtaking maneu-
vers against adversarial opponents at the limits of dynamics.
In the ﬁrst area, approaches [4]–[6] usually form a time-
optimal, or curvature-optimal problem and solve for a global
race line. In the second area, approaches such as game theory
[7]–[9] or Reinforcement Learning [9]–[11] are used to ﬁnd
racing agents able to perform overtakes.

A. Japan Automotive AI Challenge

The 3rd Japan Automotive AI Challenge was a worldwide
competition hosted by the Society of Automotive Engineers
of Japan in December of 2021. The aim of the competition
in machine learning
is to help identify and train talent
applications for future mobility systems. The competition
pits teams against the clock in a multi-agent head-to-head
autonomous vehicle race. Each competitor takes control of a
car, which begins in last place in a lap around the Indianapolis
Motor Speedway (shown in Figure 1). The competitor is
given the ground truth localization of the ego car through
the Autoware.Auto GNSS localizer module. There are 5 NPC
(Non-Player Character / computer-controlled) cars ahead of
the ego, each following a predetermined path. All vehicles
in the race are identical to the Dallara IL-15s. The ego must
overtake all 5 NPC vehicles, and ﬁnish the lap in the shortest
time possible. Each collision with NPCs will add a penalty
of 5 seconds to the total time. The shortest time around
the circuit wins the competition. The event is held entirely
in simulation, using the LGSVL simulator [12], and each
team is given the Autoware.Auto software stack to ease the
development burden. During evaluation, the submission is
scored on the same track, but with the NPCs following a
path not known beforehand to the competitors.
This paper has three major contributions:
1) We provide a showcase on how to use and leverage and
open-source software stack for autonomous driving for
an autonomous racing competition.

2) We explain our approach on creating an opponent de-
tection algorithm, a lane switching overtaking strategy,

 
 
 
 
 
 
Fig. 1. Race Track: The Indianapolis Motor Speedway (top), Race Car:
Dallara IL-15 Model (bottom):

and the integration of the MPC vehicle controller to be
successful in the Japan AI challenge.

3) We provide insights on the racing strategy and explain
both advantages and gaps that need to be ﬁlled using
the Autoware.Auto open-source autonomous driving
software stack.

In the next sections we describe the adaptations necessary
to enable Autoware.Auto to be suitable for racing, and the
racing strategies we implemented that emerged as the winner.

II. METHODOLOGY

A. Autoware Open Source Stack

Autoware is the world leading open-source autonomous
driving software that combines implementations of percep-
tion, planning and control for autonomous vehicle develop-
ment into one coherent software platform (see Fig. 2). There
are two releases of this software, Autoware.AI, which runs
on Robot Operating System version 1 (ROS1), and the newer
Autoware.Auto, which runs on ROS2 (https://ros.org). Auto-
ware.Auto improves reproducibility and determinism across
different system levels, provides modular design, production-
grade code and review practices, as well as integrated testing.
Previously, Autoware.Auto was used to develop slow-speed
autonomous valet parking and cargo delivery services. This
competition uses Autoware.Auto for racing with speeds up
to 160km/h and for overtaking maneuvers at the limits of the
vehicle’s dynamics. To support reproducible environments,
docker containers with ROS2 Foxy and Autoware.Auto run-
ning on Ubuntu 20.04 are distributed to all participants.
The interface to the LGSVL simulator, as well as the basic
modules needed to get the simulated Dallara IL-15 running,
were all provided by Autoware.Auto.

Fig.3 shows the code structure of our implementation and
enhancements to Autoware.Auto. Our ROS nodes commu-
nicate with Autoware.Auto nodes within the ROS2 envi-
ronment, which is connected with the LGSVL simulation
through a LGSVL bridge.

Fig. 2. Overview of the Autoware.Auto software stack components

B. Opponent Detection

The ego car is equipped with a single front-mounted 3D Li-
DAR to perform obstacle avoidance. Raw LiDAR data is ﬁrst
ﬁltered by the ray-ground ﬁlter within the Autoware.Auto
framework, which uses the projection of rays to ﬁlter out
LiDAR points reﬂected by the ground. The LiDAR data is
then further cropped by 3D rectangular boundaries set in the
ego vehicle’s frame. In the X axis, we have set a limit from
-10 to 100 meters. The -10 meter look-back distance is to
detect obstacles in the left and right blind spots of the ego
vehicle. In the Y axis, the cropping is based on the current
lane the ego vehicle resides in, as we need to ﬁlter out the
detection from track boundary panels and walls. In the Z axis,
we crop the data between -0.5 to 0.9 meters to prevent ground
detection points from the banking of the track while the ego
car is turning. This is because the ray-ground ﬁlter will let
some ground points pass through if when the slope of the
ground plane is high. We directly use the ﬁltered point cloud
data in representing obstacles, which will be later classiﬁed
into different lanes.

In contrast to our simple approach, the obstacle avoidance
pipeline provided by Autoware.Auto is to ﬁrst combine ﬁl-
tered points into obstacle objects using euclidean clustering,
which groups points into clusters if they can be connected
by other points within a threshold distance. The obstacle

Fig. 3. Code Structure for the Race: Our code is integrated with Auto-
ware.Auto modules within ROS2 and communicates with the SVL Simula-
tion through a bridge.

lt < θe, lpre
for further opportunities to switch.

t < θe. Else, the ego vehicle will brake and look

When the current lane is the center, the ego vehicle has
both left and right lanes to choose from, otherwise, it will
prefer to choose to switch to the center lane. This is because
LiDAR detection can be unreliable on the farthest lanes if
the vehicle is not in the center, especially around corners
where ground ﬁltering is challenging. However, if it must
switch across the center lane to a further lane, e.g. left to
right directly, then it needs to have lcenter < θo. After each
lane switch is initiated, a pause ﬂag will be on for 10 seconds
to prevent additional lane switch signals for the vehicle to
settle in the new lane.

Globally Optimized Raceline - The globally optimized
raceline is prepared using the minimum curvature method
[13]. Compared to the centerline, an optimized raceline will
try to reduce curvature round turnings to allow minimum
speed loss while applying less steering. This involves cutting
from the outer lane to the inner lane when entering a turn
and back to the outer lane when exiting a turn. Maximizing
our stay on the optimized lane while effectively avoiding the
NPCs has direct impacts on the average speed of our vehicle.
Our strategy is that the ego vehicle will try to switch to
the optimized lane when we have 5 consecutive detections
where all l0, l1, l2 < θe. To avoid obstacles while on the
optimized lane, we keep track of the effective lane the ego
vehicle is currently in and follow a similar lane switching
logic as above.

D. Vehicle Control

Once we have the current or target

lane selection, a
trajectory publisher will publish correct waypoints based on
current localization. The trajectory publisher reads in pre-
pared waypoint ﬁles and segments out the correct waypoints
from each of the lanes.

The waypoint data are subscribed to by the Model-
Predictive Controller (MPC) module in the Autoware.Auto
framework. This MPC module is based on the ACADO
toolkit [14]. The MPC problem is speciﬁed as a Quadratic
Problem (QP), with constraints on the acceleration, steer-
ing, and speed. A kinematic bicycle model is used for the
vehicle. The MPC objective is to minimize the pose error
between the vehicle and the given reference trajectory over
the planning horizon. The module offers a choice of three
solvers: an unconstrained QP solver which uses an eigen-
decomposition, a second unconstrained QP solver which uses
a faster approximation of the eigen-decomposition, and the
qpOASES solver [15], [16]. The method we used was the
unconstrained solver with a faster approximation.

Using a changing reference trajectory posed challenges
when tuning the MPC, as we do not explicitly create splines
for the transition between lanes, instead, we just provide
waypoints from the selected lane and let the MPC optimize
a control sequence for the lane switch. The default tuning of
the Autoware.auto MPC controller place heavy weights on
positional and heading errors, which was meant to increase

Fig. 4. Inner, Center, Outer and Optimized Lanes: The optimized lane will
cut across the other three lanes when entering a turn.

objects will then be examined with the planned trajectory
for a potential collision. However, we saw a greater than
700 ms latency between the publishing of the ﬁltered LiDAR
point cloud and the publishing of the euclidean clustering
results on our machine. This high latency made control of the
vehicle unreliable, unable to catch overtaking opportunities,
and prone to crashes. Since the LiDAR signal rate is 10 Hz,
our computation time should be less than 100 ms to make the
best use of the LiDAR information. Therefore, we designed
a simple obstacle detection method for this race.

C. Overtaking Strategy using Lane Switching

In this race, the trajectories of the NPCs are based on the
inner, center and outer lanes on the racing track. In order
to overtake these NPCs with quick and safe maneuvers, we
prepared three lane-based racelines and a switching logic. We
also prepared a globally optimized raceline, which the ego
will switch to if it does not detect any nearby opponent. [4]
Fig.4 shows all four lanes when entering curve.

NPC Overtaking - Since the ego vehicle is always posi-
tioned behind all NPCs and in the outer lane when each race
is initiated, it must overtake all ﬁve NPCs to reach the front.
We prepared the inner, center and outer lanes by computing
equispaced offsets from the centerline of the track, which is
provided by the organizers.

The ﬁltered LiDAR point cloud is then classiﬁed into
the lanes by calculating the euclidean distance from each
LiDAR point to the nearest point on the centerline of each
lane. Separate sparse centerlines of each lane are prepared
to reduce computation. The number of LiDAR points within
each lane are simply counted to give lane occupancy values
l ∈ [l0, l1, l2]. The lane occupancy values from the previous
detection are also recorded as lpre ∈ [lpre
]. Two
thresholds θo, θe are deﬁned to determine whether the lane
is occupied or empty. A lane is marked as occupied only if
its lane occupancy value is greater than θo, and marked as
empty only if smaller than θe. The use of two values seems
redundant but it allows us to adjust the amount of empty
space ahead separately for switching out and into a particular
lane. The θe we use is 3 times smaller than θo to give more
readiness in the target lane.

, lpre
1

, lpre
2

0

The lane switch logic is as follows: The ego vehicle will
switch to target lane t from current lane s, if ls > θo and

control precision in low-speed parking movements. At high
speed, this leads to heading wobbles and large maneuvers
during lane transitions which sometimes cause loss of trac-
tion. Therefore, we tuned down about 25% of the weights for
position and heading and tuned up weights for longitudinal
velocity by 20 times to prioritize maintaining speed over
trajectory precision.

III. RESULTS

In the ﬁnal evaluation with unknown NPCs, our method
is able to complete the race without opponent contact in
99.5784 s, 0.32 s faster the 2nd place, with an average speed
of 41.33 m/s.

Compared to the long latency of the euclidean clustering
method, our simple lane-based obstacle avoidance algorithm
takes an average processing time of 20 ms. This helps us react
to LiDAR data as quickly as possible. With the peak speed
of more than 47 m/s, 20 ms of processing time translate to
roughly 0.94 m in distance where the vehicle cannot perform
any updated maneuver. As we can see, in a high-speed racing
scenario such as this competition, short processing time can
give rewarding advantages.

Fig. 5. LiDAR Point Classiﬁcation Examples: Visualization Plots (left),
Corresponding Simulation Screenshots (right). Points with different colors
belong to different lanes.

Two examples of in-race LiDAR point cloud classiﬁcations
are shown in Fig.5 with visualization plots on the left and
a live simulation view on the right. On the bottom is the
beginning position of the race. In the visualization plot, we
can see points colored in blue, cyan and magenta belong to
different lanes, and points that are ﬁltered out are colored in
red. On the top is a scenario where the ego car is blocked by
a leading car in the outer lane but unable to overtake due to

the middle lane being occupied as well. In this case, the car
will slow down to avoid a collision penalty and also make
space for other overtaking opportunities.

In Fig.6, we present two consecutive overtake examples
that happened in a training session. Cars are driving from the
right side and entering a left-turning curve. At the trajectory
plot at the top, we can see two shifts in the green curve
which is the control trajectory published by the trajectory
publisher. In lane change moment A, the ego car switched
from the optimized lane to the middle lane to perform an
overtake of an opponent vehicle. After the overtake, the ego
car should switch back to the optimized lane, which will
cut into the inner lane to minimize curvature. However, at
this time, in moment B, the inner lane was occupied. The
ego vehicle correctly detected the presence of the occupying
opponent and postponed the lane change until the inner lane
was cleared. We can also see the actual trajectory plotted
as the red curve and the control error plotted in the middle
graph, which shows smooth trajectory was calculated with
the Autoware.Auto MPC controller despite two sharp lane
switches. We have recorded a video from training session to
demonstrate lane switching overtakes.

During our experiments, a frequent fail case of this method
that we observed is when the target lane that the ego is
switching to can be blocked by another car that is a short
distance ahead. This is usually because the lidar detection
for the target lane is partially blocked by the opponent car in
front of the ego due to its close up distance. For example, at
lane change moment A in Fig.6, the ego is about to switch
to the center lane, but there is a blind zone in the center
lane blocked by the front car. If this happens, once the ego
switches to the center lane, it may have to brake hard to
avoid collision. A potential solutions to this scenario will be
to track the dynamic of the front car while they are visible.

IV. DISCUSSION

The Open Source Stack provided by Autoware provides a
great advantage in getting started with full-stack autonomous
vehicle development. In this race, it allowed us to focus on
the areas of perception, planning and control that mattered
the most for the race. The LiDAR pre-ﬁltering and MPC
control worked well. It also provided easy to use interfaces
between our code and the simulator.

While access to ready-made algorithms expedited devel-
opment,
there were a few areas in which the Autoware
stack was not sufﬁcient for autonomous racing. Many of
including the global and behavior
the existing modules,
planner, are speciﬁcally designed for low-speed applications
like valet parking. The default logic of collision avoidance is
to stop, which is not favored and can be dangerous in racing.
Instead, race cars need active planning to avoid obstacles and
search for opportunities for overtaking. The software stack
lacks hardware accelerated implementations of algorithms.
For example, the refresh frequency of the euclidean clustering
for LiDAR scans can be greatly improved with a GPU
implementation. While lower frequencies may be sufﬁcient

Fig. 6. Example Lane Switching Moments: Plot of Lanes and Trajectories (top), Plot of Control Error (center), Simulation and RVIZ Screenshots (bottom):
In moment A, the ego switch to the center lane to overtake the front opponent. In moment B, the ego car waits until the inner lane is clear to switch to
the globally optimized lane. The driving direction is from left to right.

for low-speed driving scenarios, they are not suitable for
higher-speed scenarios like those we encountered in the races.
Racing other opponents presents a challenge, namely that
of anticipating the next moves of the opponents. Some
related work has made signiﬁcant progress here, using game
theoretic approaches to predict opponent trajectories. Still
other approaches use data driven methods to identify mov-
ing obstacles, and their possible trajectories. Our algorithm
would perform better if we were able to anticipate the future
poses of our opponents, and use that information to execute
smoother and less reactive lane changes.
The heavily structured nature of

the race with non-
interactive opponents allowed our largely reactive algorithm
to be successful. These predeﬁned NPC trajectories meant
we could treat our opponents as simple moving obstacles,
which made our lane switching approach highly effective.
Using an optimized raceline provided us with the lap time
beneﬁt needed to win the challenge.

V. RELATED WORK

Here we cover recent work in autonomous racing and
overtaking. While much of the related work in planning
racelines is non-reactive, work on overtaking does assume
dynamic opponents.

A. Hierarchical Planning

We view the challenge as a hierarchical planning problem.
Globally, we aim to ﬁnd an optimized reference raceline that

can achieve minimal lap time if tracked ﬂawlessly. Locally,
we aim to ﬁnd a local plan that deviates from the global
plan in the presence of an obstacle, or dynamic opponents,
and tracks the global plan accurately otherwise. In the ﬁeld of
AR, there are numerous efforts on addressing this problem. In
the following discussion, we compare and contrast different
approaches both in global planning and local planning.

Global Planning - In Global Planning, we can roughly cat-
egorize approaches by the objective function used. First, lap
times are used as the optimization objective. In [6], [17], [18],
Evolutionary Algorithm (EA) based optimization is used.
Each approach parameterizes the search space differently,
and uses different EAs while maintaining the same overall
goal. In [13], [19]–[28], an Optimal Control Problem (OCP)
is formed, with different constraints in vehicle dynamics
and geometry limits to minimize lap times. Second, certain
geometric properties of the ﬁnal reference raceline have also
been parameterized as the optimization objective. In [4], [29],
[30], an optimization is formed to minimize the maximum,
or total curvature of the resulting reference raceline. Third,
some approaches also aim to mimic the driving behavior of
a race car driver geometrically. For example, [28], [31], [32].
Our global plan is generated following the approach in Christ
et al. [13], which is a minimum time approach.

Local Planning - In Local Planning, we can group dif-
ferent methods by their overall strategy. First, modifying the
global plan via optimization by including obstacles into the

constraint, or the objective of the problem. [33]–[39] all falls
into this category. These approaches either try to balance two
competing objectives in achieving higher speeds and being
reactive to obstacles, or perform mode switches to change
the weighting on the objective. Second, sampling multiple
dynamically feasible trajectories (motion primitives), and
selected via cost minimization. [7], [40]–[43] all generates
motion primitives with a series of randomly perturbed control
sequences, series of ﬁxed inputs, or dynamically feasible
splines with different goal points. A cost is usually assigned
to each of the primitives, and the one with lowest overall
cost is chosen. Our winning strategy for local planning can
be categorized into this group. In our approach, instead of
creating locally feasible primitives, we create global primi-
tives, and create the motion plans for switching between these
primitives with an MPC. Lastly, sampling in the free space
around the obstacle and construct an obstacle-free path in the
explored space. This type of approach is akin to a traditional
motion planning problem. [44]–[47] all uses variants of RRT
to ﬁnd collision free paths in the free space for racing.

B. Learning-based Planning

Alternatively, the problem could be considered holistically.
Many approaches provide end-to-end, or partially end-to-
end solutions to the planning problem. Instead of ﬁnding an
optimal global raceline, the lap time objective is formulated
as part of the reward function.

On one hand, Reinforcement Learning (RL) is used to train
an agent in an adversarial environment. DeepRacing [48]–
[50] provides solutions on three levels: pixel to control, pixel
to waypoints, and pixel to curves. [51], [52] uses A3C to
train racing agents. [53] learns state representation and uses
Q-learning to provide generalizable racing policies. [54], [55]
uses DDPG to train racing policies. SAC is also widely used
[11], [56]–[58]. [10], [59] ﬁrst learns a latent representation
of the world and learns through self-play.

On the other hand, Game Theoretic methods usually ab-
stract the planning problem into a sequential game and tries to
ﬁnd the best response, or minimize regret. [8], [9], [60]–[62]
uses Best Response or Iterated Best Response to ﬁnd best
action at each step, or seek an modiﬁed Nash equilibrium.
[7] builds an opponent prototype library and uses EXP3
to identify the opponent online. [63] plays a sequence of
coupled games in a receding horizon fashion. And ﬁnally
[64] uses local iterative DP to plan in Belief Space.

VI. CONCLUSION AND FUTURE WORK

We have shown the racing strategy used to create the
winning entry in the Third Japan Automotive AI Challenge.
Leveraging the Autoware.Auto open source autonomous driv-
ing software stack allowed us to create the perception, plan-
ning and control methods for autonomous racing in just a few
weeks. We demonstrated the usability and robustness of the
Autoware.Auto modules as well as potential improvements
and changes needed for high-speed, high-risk driving scenar-
ios in autonomous racing. Beyond this race, we will continue

to work with and develop for projects such as Autoware to
support open-source developments in the autonomous driving
industry.

REFERENCES

[1] J. Betz, H. Zheng, A. Liniger, U. Rosolia, P. Karle, M. Behl,
V. Krovi, and R. Mangharam, “Autonomous vehicles on the edge:
A survey on autonomous vehicle racing,” 2022. [Online]. Available:
https://arxiv.org/abs/2202.07008

[2] A. Wischnewski, M. Geisslinger, J. Betz, T. Betz, F. Fent, A. Heilmeier,
L. Hermansdorfer, T. Herrmann, S. Huch, P. Karle, F. Nobis,
¨Ogretmen, M. Rowold, F. Sauerbeck, T. Stahl, R. Trauth,
L.
M. Lienkamp, and B. Lohmann, “Indy autonomous challenge – au-
tonomous race cars at the handling limits,” 2022.

[3] M. OKelly, H. Zheng, D. Karthik, and R. Mangharam, “F1tenth:
An open-source evaluation environment for continuous control and
reinforcement learning,” in Proceedings of the NeurIPS 2019 Compe-
tition and Demonstration Track, ser. Proceedings of Machine Learning
Research, vol. 123. PMLR, 2020, pp. 77–89.

[4] A. Heilmeier, A. Wischnewski, L. Hermansdorfer,

J. Betz,
M. Lienkamp, and B. Lohmann, “Minimum curvature trajectory
planning and control for an autonomous race car,” Vehicle System
Dynamics, vol. 58, no. 10, pp. 1497–1527, Jun. 2019.

[5] N. D. Bianco, E. Bertolazzi, F. Biral, and M. Massaro, “Comparison
of direct and indirect methods for minimum lap time optimal control
problems,” Vehicle System Dynamics, vol. 57, no. 5, pp. 665–696,
Jun. 2018. [Online]. Available: https://doi.org/10.1080/00423114.2018.
1480048

[6] M. O'Kelly, H. Zheng, A. Jain, J. Auckley, K. Luong, and R. Mang-
haram, “TUNERCAR: A superoptimization toolchain for autonomous
racing,” in 2020 IEEE International Conference on Robotics and
Automation (ICRA).

IEEE, May 2020.

[7] A. Sinha, M. O’Kelly, H. Zheng, R. Mangharam, J. Duchi, and
R. Tedrake, “FormulaZero: Distributionally robust online adaptation
via ofﬂine population synthesis,” in Proceedings of
the 37th
International Conference on Machine Learning, ser. Proceedings of
Machine Learning Research, H. D. III and A. Singh, Eds., vol.
119. PMLR, 13–18 Jul 2020, pp. 8992–9004. [Online]. Available:
http://proceedings.mlr.press/v119/sinha20a.html

[8] G. Williams, B. Goldfain, P. Drews, J. M. Rehg, and E. A. Theodorou,
“Autonomous racing with autorally vehicles and differential games,”
ArXiv, vol.
[Online]. Available: https:
//arxiv.org/abs/1707.04540

abs/1707.04540, 2017.

[9] G. Notomista, M. Wang, M. Schwager, and M. Egerstedt, “Enhancing
game-theoretic autonomous car racing using control barrier functions,”
in 2020 IEEE International Conference on Robotics and Automation
(ICRA).

IEEE, May 2020.

[10] W. Schwarting, T. Seyde, I. Gilitschenski, L. Liebenwein, R. Sander,
S. Karaman, and D. Rus, “Deep Latent Competition: Learning to Race
Using Visual Control Policies in Latent Space,” arXiv:2102.09812
[cs], Feb. 2021, arXiv: 2102.09812.
[Online]. Available: http:
//arxiv.org/abs/2102.09812

[11] Y. Song, H. Lin, E. Kaufmann, P. Durr, and D. Scaramuzza,
“Autonomous Overtaking in Gran Turismo Sport Using Curriculum
Reinforcement Learning,” in 2021 IEEE International Conference
on Robotics and Automation (ICRA). Xi’an, China: IEEE, May
2021, pp. 9403–9409. [Online]. Available: https://ieeexplore.ieee.org/
document/9561049/

[12] G. Rong, B. H. Shin, H. Tabatabaee, Q. Lu, S. Lemke, M. Moˇzeiko,
E. Boise, G. Uhm, M. Gerow, S. Mehta, E. Agafonov, T. H. Kim,
E. Sterner, K. Ushiroda, M. Reyes, D. Zelenkovsky, and S. Kim, “SVL
Simulator: A High Fidelity Simulator for Autonomous Driving,” arXiv
e-prints, p. arXiv:2005.03778, May 2020.

[13] F. Christ, A. Wischnewski, A. Heilmeier, and B. Lohmann,
“Time-optimal
trajectory planning for a race car considering
variable tyre-road friction coefﬁcients,” Vehicle System Dynamics,
vol. 59, no. 4, pp. 588–612, Dec. 2019.
[Online]. Available:
https://doi.org/10.1080/00423114.2019.1704804

[14] B. Houska, H. Ferreau, and M. Diehl, “ACADO Toolkit – An Open
Source Framework for Automatic Control and Dynamic Optimization,”
Optimal Control Applications and Methods, vol. 32, no. 3, pp. 298–
312, 2011.

[15] H. J. Ferreau, C. Kirches, A. Potschka, H. G. Bock, and M. Diehl,
“qpOASES: a parametric active-set algorithm for quadratic program-
ming,” Mathematical Programming Computation, vol. 6, no. 4, pp.
327–363, Dec. 2014.
IV,
Documentation,”

Auto-
[16] Tier
ware
Avail-
able: https://web.archive.org/web/20220308221519/https://tier4.github.
io/autoware.iv/tree/main/control/mpc follower/

-
[Online].

follower
Mar.

description

“MPC

2022.

[17] M. Bevilacqua, A. Tsourdos, and A. Starr, “Particle swarm
in 2017
for path planning in a
IEEE International Instrumentation and Measurement Technology
Conference
[Online]. Available:
https://doi.org/10.1109/i2mtc.2017.7969735

IEEE, May 2017.

racing circuit

simulation,”

(I2MTC).

[18] J. Quadﬂieg, M. Preuss, and G. Rudolph, “Driving faster

than
a human player,” in Applications of Evolutionary Computation.
Springer Berlin Heidelberg, 2011, pp. 143–152. [Online]. Available:
https://doi.org/10.1007/978-3-642-20525-5 15

[19] D. Metz and D. Williams, “Near time-optimal control of racing
vehicles,” Automatica, vol. 25, no. 6, pp. 841–857, Nov. 1989.
[Online]. Available: https://doi.org/10.1016/0005-1098(89)90052-6

[20] D. P. Kelly and R. S. Sharp, “Time-optimal control of the race
car: a numerical method to emulate the ideal driver,” Vehicle System
Dynamics, vol. 48, no. 12, pp. 1461–1474, Aug. 2010. [Online].
Available: https://doi.org/10.1080/00423110903514236

[21] A. Rucco, G. Notarstefano, and J. Hauser, “An efﬁcient minimum-
time trajectory generation strategy for
two-track car vehicles,”
IEEE Transactions on Control Systems Technology, vol. 23,
no. 4, pp. 1505–1519,
[Online]. Available: https:
//doi.org/10.1109/tcst.2014.2377777

Jul. 2015.

[22] P. A. Theodosis and J. C. Gerdes, “Nonlinear optimization of
racecar using professional
[Online]. Available: https:

a
an autonomous
for
driving techniques.” ASME, 2012.
//doi.org/10.1115/dscc2012-movic2012-8620

racing line

[23] E. Pagot, M. Piccinini, and F. Biral, “Real-time optimal control of
an autonomous RC car with minimum-time maneuvers and a novel
kineto-dynamical model,” in 2020 IEEE/RSJ International Conference
on Intelligent Robots and Systems (IROS).
IEEE, Oct. 2020. [Online].
Available: https://doi.org/10.1109/iros45743.2020.9340640

[24] J. L. Vazquez, M. Bruhlmeier, A. Liniger, A. Rupenyan, and
J. Lygeros, “Optimization-based hierarchical motion planning for
autonomous racing,” in 2020 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS).
IEEE, Oct. 2020. [Online].
Available: https://doi.org/10.1109/iros45743.2020.9341731

[25] T. Herrmann, F. Christ,

J. Betz, and M. Lienkamp, “Energy
management strategy for an autonomous electric racecar using
optimal control,” in 2019 IEEE Intelligent Transportation Systems
Conference (ITSC).
IEEE, Oct. 2019. [Online]. Available: https:
//doi.org/10.1109/itsc.2019.8917154

[26] T. Herrmann, F. Passigato, J. Betz, and M. Lienkamp, “Minimum race-
time planning-strategy for an autonomous electric racecar,” in 2020
IEEE 23rd International Conference on Intelligent Transportation
Systems
[Online]. Available: https:
//doi.org/10.1109/itsc45102.2020.9294681

IEEE, Sep. 2020.

(ITSC).

[27] T. Herrmann, A. Wischnewski, L. Hermansdorfer, J. Betz, and
adaptive velocity optimization for
IEEE
limits of handling,”
at
[Online].

M. Lienkamp,
autonomous
Transactions on Intelligent Vehicles, pp. 1–1, 2020.
Available: https://doi.org/10.1109/tiv.2020.3047858

“Real-time
cars

electric

the

[28] S. Lovato and M. Massaro, “Three-dimensional ﬁxed-trajectory
road vehicles,” Vehicle
[Online]. Available:

approaches to the minimum-lap time of
System Dynamics, pp. 1–18, Aug. 2021.
https://doi.org/10.1080/00423114.2021.1969024

[29] F. Braghin, F. Cheli, S. Melzi, and E. Sabbioni, “Race driver model,”
Computers & Structures, vol. 86, no. 13-14, pp. 1503–1516, Jul. 2008.
[Online]. Available: https://doi.org/10.1016/j.compstruc.2007.04.028

[30] L. Cardamone, D. Loiacono, P. L. Lanzi, and A. P. Bardelli,
“Searching for the optimal racing line using genetic algorithms,”
the 2010 IEEE Conference on Computational
in Proceedings of
Intelligence and Games.
IEEE, Aug. 2010. [Online]. Available:
https://doi.org/10.1109/itw.2010.5593330

[31] P. A. Theodosis and J. C. Gerdes, “Generating a racing line for an
autonomous racecar using professional driving techniques,” in ASME
2011 Dynamic Systems and Control Conference and Bath/ASME

[32] P. W. Kuhn, “Methodology for

Symposium on Fluid Power and Motion Control, Volume 2. ASMEDC,
Jan. 2011. [Online]. Available: https://doi.org/10.1115/dscc2011-6097
the numerical calculation of
racing lines and the virtual assessment of driving behavior
for
training circuits for the automobile industry,” Transportation Research
Procedia, vol. 25, pp. 1416–1429, 2017.
[Online]. Available:
https://doi.org/10.1016/j.trpro.2017.05.167

[33] J. R. Anderson, B. Ayalew, and T. Weiskircher, “Modeling a
professional driver in ultra-high performance maneuvers with a hybrid
cost MPC,” in 2016 American Control Conference (ACC).
IEEE, Jul.
2016. [Online]. Available: https://doi.org/10.1109/acc.2016.7525209

[34] N. R. Kapania, J. Subosits, and J. C. Gerdes, “A sequential two-step
algorithm for fast generation of vehicle racing trajectories,” Journal
of Dynamic Systems, Measurement, and Control, vol. 138, no. 9, Jun.
2016. [Online]. Available: https://doi.org/10.1115/1.4033311

[35] J. Funke, M. Brown, S. M. Erlien, and J. C. Gerdes, “Collision
avoidance and stabilization for autonomous vehicles in emergency
scenarios,” IEEE Transactions on Control Systems Technology,
vol. 25, no. 4, pp. 1204–1216, Jul. 2017.
[Online]. Available:
https://doi.org/10.1109/tcst.2016.2599783

[36] J. K. Subosits and J. C. Gerdes, “From the racetrack to the
road: Real-time trajectory replanning for autonomous driving,” IEEE
Transactions on Intelligent Vehicles, vol. 4, no. 2, pp. 309–320, Jun.
2019. [Online]. Available: https://doi.org/10.1109/tiv.2019.2904390

[37] E. Alcal´a, V. Puig, and J. Quevedo, “LPV-MP planning for
autonomous racing vehicles considering obstacles,” Robotics and
Autonomous Systems, vol. 124, p. 103392, Feb. 2020.
[Online].
Available: https://doi.org/10.1016/j.robot.2019.103392

and A.

[38] D. Kalaria, P. Maheshwari, A. Jha, A.
“Local

Issar, D. Chakravarty,
global
on
S. Anwar,
Tovar,
racing,” in 2021 International
optimised path for autonomous
Conference
-
Workshop Opportunities and Challenges With Autonomous Racing.
https://linklab-uva.github.io/
[Online]. Available:
IEEE,
icra-autonomous-racing/contributed papers/paper8.pdf

and Automation

(ICRA 2021)

on Robotics

2021.

nmpc

[39] T. Br¨udigam, A. Capone, S. Hirche, D. Wollherr, and M. Leibold,
“Gaussian process-based stochastic model predictive control for over-
taking in autonomous racing,” 2021.

[40] G. Williams, P. Drews, B. Goldfain, J. M. Rehg, and E. A.
Theodorou, “Aggressive driving with model predictive path integral
control,” in 2016 IEEE International Conference on Robotics
and Automation (ICRA).
IEEE, May 2016. [Online]. Available:
https://doi.org/10.1109/icra.2016.7487277

[41] A. Liniger, A. Domahidi, and M. Morari, “Optimization-based
racing of 1:43 scale RC cars,” Optimal Control
autonomous
Applications and Methods, vol. 36, no. 5, pp. 628–647, Jul. 2014.
[Online]. Available: https://doi.org/10.1002/oca.2123

[42] A. Liniger and J. Lygeros, “A viability approach for fast recursive
feasible ﬁnite horizon path planning of autonomous RC cars,” in
Proceedings of the 18th International Conference on Hybrid Systems:
Computation and Control. ACM, Apr. 2015. [Online]. Available:
https://doi.org/10.1145/2728606.2728620

[43] T. Stahl, A. Wischnewski, J. Betz, and M. Lienkamp, “Multilayer
in dynamic
Systems
[Online]. Available:

graph-based trajectory planning for
2019
scenarios,”
Conference
https://doi.org/10.1109/itsc.2019.8917032

IEEE Intelligent Transportation
2019.
IEEE, Oct.

in
(ITSC).

race vehicles

[44] J. H. Jeon, R. V. Cowlagi, S. C. Peters, S. Karaman, E. Frazzoli,
P. Tsiotras, and K. Iagnemma, “Optimal motion planning with the
half-car dynamical model for autonomous high-speed driving,” in
2013 American Control Conference.
IEEE, Jun. 2013. [Online].
Available: https://doi.org/10.1109/acc.2013.6579835

[45] O. Arslan, K. Berntorp, and P. Tsiotras, “Sampling-based algorithms
for optimal motion planning using closed-loop prediction,” in 2017
IEEE International Conference on Robotics and Automation (ICRA).
IEEE, May 2017. [Online]. Available: https://doi.org/10.1109/icra.
2017.7989581

[46] S. Feraco, S. Luciani, A. Bonﬁtto, N. Amati, and A. Tonoli,
“A local
trajectory planning and control method for autonomous
vehicles based on the RRT algorithm,” in 2020 AEIT International
Conference of Electrical and Electronic Technologies for Automotive
(AEIT AUTOMOTIVE).
[Online]. Available:
https://doi.org/10.23919/aeitautomotive50086.2020.9307439

IEEE, Nov. 2020.

[47] A. Bulsara, A. Raman, S. Kamarajugadda, M. Schmid, and V. N.
Krovi, “Obstacle avoidance using model predictive control: An
implementation and validation study using scaled vehicles,” in SAE
Technical Paper Series.
SAE International, Apr. 2020. [Online].
Available: https://doi.org/10.4271/2020-01-0109

[48] T. Weiss and M. Behl, “DeepRacing: A framework for autonomous
racing,” in 2020 Design, Automation & Test in Europe Conference &
Exhibition (DATE).

IEEE, Mar. 2020.

[49] ——, “DeepRacing: A framework for autonomous

2020 Design, Automation & Test
Exhibition (DATE).
//doi.org/10.23919/date48585.2020.9116486

racing,” in
in Europe Conference &
IEEE, Mar. 2020. [Online]. Available: https:

[50] T. Weiss,

J. Chrosniak, and M. Behl, “Towards multi-agent
racing with the deepracing framework,” in 2021
autonomous
International Conference on Robotics and Automation (ICRA
2021) - Workshop Opportunities and Challenges With Autonomous
Racing.
IEEE, 2021. [Online]. Available: https://linklab-uva.github.
io/icra-autonomous-racing/contributed papers/paper5.pdf

[51] E. Perot, M. Jaritz, M. Toromanoff, and R. D. Charette, “End-
to-end driving in a realistic racing game with deep reinforcement
learning,” in 2017 IEEE Conference on Computer Vision and Pattern
Recognition Workshops
[Online].
Available: https://doi.org/10.1109/cvprw.2017.64

Jul. 2017.

(CVPRW).

IEEE,

[52] M. Jaritz, R. de Charette, M. Toromanoff, E. Perot, and F. Nashashibi,
“End-to-end race driving with deep reinforcement learning,” in 2018
IEEE International Conference on Robotics and Automation (ICRA).
IEEE, May 2018. [Online]. Available: https://doi.org/10.1109/icra.
2018.8460934

[53] T. de Bruin, J. Kober, K. Tuyls, and R. Babuska, “Integrating
state representation learning into deep reinforcement learning,” IEEE
Robotics and Automation Letters, vol. 3, no. 3, pp. 1394–1401, Jul.
2018. [Online]. Available: https://doi.org/10.1109/lra.2018.2800101

[54] A. Remonda, S. Krebs, E. Veas, G. Luzhnica, and R. Kern,
learning for autonomous racing
[Online]. Available:

“Formula rl: Deep reinforcement
using telemetry data,” Unpublished, 2019.
http://rgdoi.net/10.13140/RG.2.2.30678.09283

[63] A. Liniger and J. Lygeros, “A noncooperative game approach to au-
tonomous racing,” IEEE Transactions on Control Systems Technology,
vol. 28, no. 3, pp. 884–897, May 2020.

[55] J. Niu, Y. Hu, B. Jin, Y. Han, and X. Li, “Two-stage safe
reinforcement
in
learning for high-speed autonomous
2020 IEEE International Conference on Systems, Man, and
Cybernetics (SMC).
IEEE, Oct. 2020. [Online]. Available: https:
//doi.org/10.1109/smc42975.2020.9283053

racing,”

[56] E. Chisari, A. Liniger, A. Rupenyan, L. V. Gool, and J. Lygeros,
[Online].

racing in reality,” 2021.

“Learning from simulation,
Available: arXiv:2011.13332

[57] K. Guckiran and B. Bolat, “Autonomous car racing in simulation
environment using deep reinforcement learning,” in 2019 Innovations
in Intelligent Systems and Applications Conference (ASYU).
IEEE,
[Online]. Available: https://doi.org/10.1109/asyu48272.
Oct. 2019.
2019.8946332

[58] F. Fuchs, Y. Song, E. Kaufmann, D. Scaramuzza, and P. Durr,
“Super-human performance in gran turismo sport using deep
learning,” IEEE Robotics and Automation Letters,
reinforcement
vol. 6, no. 3, pp. 4257–4264, Jul. 2021.
[Online]. Available:
https://doi.org/10.1109/lra.2021.3064284

[59] A. Brunnbauer, L. Berducci, A. Brandst¨atter, M. Lechner, R. Hasani,
D. Rus, and R. Grosu, “Model-based versus model-free deep reinforce-
ment learning for autonomous racing cars,” 2021.

[60] Z. Wang, R. Spica, and M. Schwager, “Game Theoretic Motion
Planning for Multi-robot Racing,” in Distributed Autonomous Robotic
Systems, vol. 9. Springer, 2020, pp. 225–238. [Online]. Available:
http://link.springer.com/10.1007/978-3-030-05816-6 16

[61] M. Wang, Z. Wang, J. Talbot, J. C. Gerdes, and M. Schwager, “Game
theoretic planning for self-driving cars in competitive scenarios,”
in Robotics: Science and Systems XV, University of Freiburg,
Freiburg im Breisgau, Germany, June 22-26, 2019, A. Bicchi,
H. Kress-Gazit, and S. Hutchinson, Eds., 2019. [Online]. Available:
https://doi.org/10.15607/RSS.2019.XV.048

[62] ——, “Game-theoretic planning for self-driving cars in multivehicle
competitive scenarios,” IEEE Transactions on Robotics, pp. 1–13,
2021. [Online]. Available: https://doi.org/10.1109/tro.2020.3047521

[64] W. Schwarting, A. Pierson, S. Karaman, and D. Rus, “Stochastic
dynamic games in belief space,” IEEE Transactions on Robotics,
pp. 1–16, 2021. [Online]. Available: https://doi.org/10.1109/tro.2021.
3075376

