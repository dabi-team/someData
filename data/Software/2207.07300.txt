CC-Fuzz: Genetic algorithm-based fuzzing for stress
testing congestion control algorithms.

Devdeep Ray
Carnegie Mellon University
devdeepr@cs.cmu.edu

Srinivasan Seshan
Carnegie Mellon University
srini@cs.cmu.edu

2
2
0
2

l
u
J

5
1

]
I

N
.
s
c
[

1
v
0
0
3
7
0
.
7
0
2
2
:
v
i
X
r
a

ABSTRACT

Congestion control research has experienced a signiﬁcant in-
crease in interest in the past few years, with many purpose-
built algorithms being designed with the needs of speciﬁc
applications in mind. These algorithms undergo limited test-
ing before being deployed on the Internet, where they inter-
act with other congestion control algorithms and run across
a variety of network conditions. This often results in un-
foreseen performance issues in the wild due to algorithmic
inadequacies or implementation bugs, and these issues are
often hard to identify since packet traces are not available.

In this paper, we present CC-Fuzz, an automated conges-
tion control testing framework that uses a genetic search al-
gorithm in order to stress test congestion control algorithms
by generating adversarial network traces and trafﬁc patterns.
Initial results using this approach are promising - CC-Fuzz
automatically found a bug in BBR that causes it to stall per-
manently, and is able to automatically discover the well-
known low-rate TCP attack, among other things.

1 Introduction

Traditional congestion control algorithms (CCAs) were de-
signed with the core goals of high throughput and fairness,
while preventing congestion collapse. Unfortunately, tradi-
tional loss-based CCAs fall short in terms of meeting the
performance requirements for many emerging applications
and network environments. Recent research has shown a
signiﬁcant interest in designing new congestion control algo-
rithms for achieving speciﬁc performance goals, or improv-
ing general CCA performance. For example, SCReAM [1],
GoogCC [2], and Sprout [3] are designed for low latency
video streaming, with the key goal of achieving low end-to-
end delay. Some CCAs are designed to extract maximum
performance from special networking infrastructure avaiable
in data center settings, such as programmable NICs (Swift,
TIMELY), switches supporting AQM (DCTCP), and hybrid
optical-packet networks [4]. Other CCAs like Copa [5], Nim-
bus [6], and TCP-BBR [7] use complex network modeling
techniques in order to achieve dual goals of (1) low delay,
and (2) high throughput when competing with other ﬂows.

A signiﬁcant fraction of new CCAs are developed by the
academic community, where the opportunities for large scale

testing in the real-world are limited. In order to deploy a new
CCA on the Internet or in large-scale data centers, where
the packets traverse across a variety of network conditions
and encounter diverse cross trafﬁc patterns, it is important
to evaluate the robustness of a CCA and it’s implementation
across a wide range of scenarios. This is a challenging task in
an academic setting - many newly proposed CCAs are evalu-
ated using a combination of small scale deployment [8], and
local scenario-based emulation and simulation [9]. These
new CCAs are much more complex compared to traditional
loss-based CCAs like TCP-CUBIC and TCP-Reno, and the
tests typically performed at an academic scale can easily
miss situations where the algorithm fails to achieve it’s goals
(like high utilization, fairness, or low delay [10, 6]), or corner
cases where bugs in the CCA implementation are triggered.
In this paper, we describe the design of our testing frame-
work called “CC-Fuzz1”, and demonstrate the value of using
genetic search algorithms for exploring the search space of
link behavior and cross trafﬁc patterns in order to identify
issues with CCAs and their implementations, or inspire con-
ﬁdence in a CCA before it is deployed in the real-world. A
genetic algorithm is a search heuristic that is inspired from
the Darwinian theory of biological evaluation - the algorithm
maintains a pool of traces and on every iteration, each en-
tity in the population is assigned a ﬁtness score. The ﬁtness
scores are used to generate the next population generation
in a manner that is similar to natural selection. In our case,
the population entities are network traces, the ﬁtness scores
are based on the performance of a CCA for each trace, and
evolution involves modifying the traces in the population in
a manner such that eventually we ﬁnd traces that trigger poor
behavior in the CCA being tested (convergence).

CC-Fuzz has two modes - (1) Link mode aims to iden-
tify bottleneck packet transmission patterns, and (2) Trafﬁc
mode aims to identify cross trafﬁc patterns, that that result in
poor performance for the particular CCA being tested. We
believe these two approaches can trigger different behaviors,
since variations in the link rate model arbitrary delay jitter,
whereas the delay is bounded when injecting cross trafﬁc.
In order to generate realistic link behavior and cross traf-

1CC-Fuzz is a pun on Sisyphus. Wikipedia notes, “tasks that are
both laborious and futile are therefore described as Sisyphean” [11]

1

 
 
 
 
 
 
ﬁc, CC-Fuzz uses (1) heuristics during trace generation, and
(2) leverages the generality of genetic algorithms by using
carefully designed ﬁtness scores for imposing implicit con-
straints that are hard to model using heuristics. In Section 5,
we propose an alternate way to impose realism on network
traces as part of future work.

The current version of CC-Fuzz uses NS3-based [12] sim-
ulation in order to evaluate CCAs and assign ﬁtness scores
for the traces, and we evaluate the pre-deﬁned CCAs in NS3.
In the future, we plan to use emulation-based testing of CCA
implementations, since the versions of CCAs in NS3 can
sometimes differ from their real implementations. Our ﬁnd-
ings (§ 4) include:

1. BBR: CC-Fuzz is able to generate network traces that
cause BBR to permanently stall due to the way ACKs
and spurious retransmissions interact with each other
during a retransmission timeout. CC-Fuzz is also able
to generate trafﬁc patterns that trigger BBR to cause
high queuing delays.

2. CUBIC: CC-Fuzz is able to generate trafﬁc patterns
that trigger a NS3-speciﬁc implementation bug in CU-
BIC regarding CWND updates.

3. Reno: CC-Fuzz is able to generate trafﬁc patterns that

are similar to the TCP low-rate attack [13].

In the remainder of the paper, we discuss the design of CC-
Fuzz (§ 3) and present directions for future work (§ 5).

2 Motivation and Related Work

Newly proposed CCAs are often evaluated using metrics such
as throughput, delay and fairness across a range of simple
scenarios like testing a CCAs ability to track available band-
width at macroscopic time-scales, and coexist with other ﬂows
(e.g. by introducing competing ﬂows using various CCAs).
Past work has shown that commonly evaluated scenarios
often fail to catch surprising failure modes - In [10], the au-
thors use mathematical modeling to show that multiple BBR
ﬂows are unfair towards loss-based CCAs. In CCAC [14],
the authors argue that basic evaluation techniques are not
sufﬁcient for capturing every scenario that causes undesir-
able behavior, and propose a formal veriﬁcation technique
that can generate network behavior that satisfy queries about
CCA performance. Formal approaches are limited since they
analyze “theoretical models” of CCAs. This step can hide
key bugs and issues present in real implementations. In addi-
tion, formal techniques become intractable when the ﬁdelity
of the model is increased or when verifying properties over
long time periods (e.g. BBR’s minRTT probing behavior).

Fuzzing [15] is a widely used technique for discovering
vulnerabilities in code. TCPwn [16] uses model-based fuzzing
in order to identify manipulation attacks (e.g. dup ACK in-
jection, ACK storm, sequence desynchronization) on CCAs.
TCP-Fuzz [17] tests TCP stack implementations for bugs,
and ACT [18] uses state space exploration to generate par-
ticular numerical values of the state variables in the CCA
implementation that triggers buggy behavior.

2

Algorithm Genetic Algorithm Loop

procedure CC-FUZZ

TRACES ← Initial pool of traces
kElite ← Number of traces that live on unmodiﬁed.
kCrossover ← Count of new traces generated by
combining traces with high scores.

repeat

for trace ∈ TRACES do

SCORE(i) ← Score when CCA run with

TRACES(i)
ELITE ← Top kElite traces
CROSSOVER ← kCrossover traces that are

generated by combining traces

MUTATED ← len(TRACES) - kElite - kCrossover
traces generated by modiﬁying traces
TRACES ← ELITE + CROSSOVER + MUTATED

until convergence

Figure 1

Packetdrill [19] uses scripted tests to detect bugs in the
networking stack and for regression testing of CCAs. Pack-
etdrill has proven successful in catching many issues over
time, but it requires clearly laid out networking scenarios that
must be developed by hand - this can miss many situations.
The goal of CC-Fuzz is to ﬁnd realistic situations where
CCA performance suffers due to packet delivery timing and
losses automatically. We do not aim to ﬁnd protocol-level
bugs that are triggered by injecting spoofed packets - the
tools mentioned above can be used for low-level bug ﬁnding.
We are not aware of any existing system that automatically
generates network environments for stress-testing CCAs for
high level throughput and other performance objectives.

3 Design
CC-Fuzz explores the search space of network behavior and
cross trafﬁc by using a genetic algorithm for generating net-
work traces in order to identifying network behaviors that
cause the CCA to perform poorly. CC-Fuzz’s high level loop
is described in Figure 1. CC-Fuzz’s core components include
the following:

1. Trace Generator: Generates initial traces, and deﬁnes
functions for performing cross-overs between pairs of
traces, and mutating individual traces.

2. Scoring Function: Simulates or emulates the CCA’s
performance for a link or trafﬁc trace, and assigns a
score based on the property being evaluated (e.g. through-
put, delay, loss, or a combination).

3. Selection Algorithm: Selects trace pairs for generat-
ing cross-over traces for the next generation, and se-
lects traces that will be mutated before being added to
the next generation trace pool.

These components are discussed in further detail below.

3.1 Network Model

CC-Fuzz uses a simple network topology with two sources
(one source uses the CCA being tested, and the other source
generates cross trafﬁc) that are connected to a gateway with
high speed links. The gateway is connected to a sink via a
bottleneck link with a ﬁxed propagation delay. The gateway
consists of a ﬁxed-size drop-tail FIFO queue.

CC-Fuzz has two distinct modes -
1. Link Fuzzing: We generate bottleneck service curves
that deﬁne the rate at which packets are drained from
the bottleneck queue and transmitted over the link.
2. Trafﬁc Fuzzing: We generate trafﬁc traces that de-
termine the injection of cross trafﬁc into the bottleneck
queue, and the bottleneck transmission rate is ﬁxed.

We explore two different modes due to the following rea-
sons:

1. A ﬁxed rate link with variable cross trafﬁc cannot model
unbounded delays that can be caused by variable links
with a ﬁxed bottleneck buffer size.

2. Variable links with a ﬁxed bottleneck buffer size cannot
model loss with bounded delay, which can be caused
by queue-building cross trafﬁc.

3. A realistic link may exhibit aggregation and delay jit-
ter, and some degree of long-term temporal rate vari-
ation. On the other hand, realistic cross-trafﬁc can be
highly adversarial. Separating out link and trafﬁc fuzzing
enables us to model such constraints and makes the re-
sults easier to understand.

These two modes are quite general, but they do not capture
certain behaviors like random packet losses. We defer this
and other approaches like combining link and trafﬁc fuzzing
to future work (§ 5).

3.2 Link Fuzzing

Link fuzzing aims to generate bottleneck service curves that
trigger poor performance in the CCA being tested. We repre-
sent the service curve as a sequence of packet transmissions
(similar to the model used in MahiMahi [9]). This repre-
sentation lends itself well for modeling jitter, and imposing
high-level constraints on the service curve. For link fuzzing,
we ﬁx the total number of packets that can be serviced by the
link during a run (and thus, the average bandwidth).

Initial Trace Generation. In order to generate realistic
traces, but still cover a large portion of the search space, CC-
Fuzz distributes the packet transmissions over time using the
DISTPACKETS algorithm shown in Figure 2. The key idea is
to recursively divide packets by splitting the time length and
number of packets into two in each step, and ensuring that
in each step, the average rate for each division lies within a
multiplicative range of the average rate. This mechanism is
a heuristic that bounds the long term variation in the band-
width. Deeper in the recursion, when the time length drops
below a threshold (kAgg), the bound checks are relaxed in
order to allow arbitrary short-term rate variations to model
packet aggregation and jitter. In Figure 3, we show the dis-

3

Algorithm Packet Distribution Algorithm

procedure DISTPACKETS(num, start, end)

if num == 0 then return [ ]
if num == 1 then return [ start+end
rate ← num
loop

end−start

2

]

tsplit ← U(start, end)
numleft ← U(0, num)

(cid:46) U is uniform random sampling.

if end − start < kAgg then break
tsplit−start , rrate ← num - numleft
lrate ← numleft
if lrate > 2 × rate or rrate > 2 × rate then

end−tsplit

continue

if lrate < 0.5 × rate or rrate < 0.5 × rate then

continue

return DISTPACKETS(numleft, start, tsplit)

+ DISTPACKETS(num - numleft, tsplit, end)

Figure 2

tribution of service curves generated by this algorithm.

Evolution Mechanism Typical genetic algorithms have
two evolution mechanisms: mutations, and crossovers. Mu-
tation mechanisms choose entities that have the desired prop-
erties, and modify them in order to generate new entities for
populating the next generation. Crossover mechanisms pick
two or more traces that have the desired properties, and com-
bine them in some way for generating new entities.

When creating a new generation from a pool of link traces
from a previous generation, CC-Fuzz must ensure that the
same properties as that of the initial generation hold - other-
wise, the constraints we want to impose on the traces can be
violated to arbitrary extents after only a few generations. For
mutating a link trace, CC-Fuzz selects a random split point
in the trace, and redistributes packets (DISTPACKETS) on ei-
ther the left or the right side of the split point (chosen using
a coin toss). This preserves the properties of the trace from
the initial generation step. CC-Fuzz does not use crossovers
for link fuzzing, since there is no obvious way of combining
two independent service curves while maintaining the core
properties of the two subtraces(e.g. total packets transmitted,
rate variation heuristics). In order to generate easier to un-
derstand link traces, CC-Fuzz optionally supports trace an-
nealing. After evaluating a trace and before performing mu-
tations, CC-Fuzz applies Gaussian smoothing to the packet
timestamps. Over multiple generations, this reduces the link
variation in regions that are not relevant for triggering the
poor behavior.

3.3 Trafﬁc Fuzzing

CC-Fuzz uses the same algorithm (DISTPACKETS) for gen-
erating trafﬁc traces, with some modiﬁcations.

high delay or low utilization. For example, for quantify-
ing low utilization, CC-Fuzz calculates windowed through-
put for the run, and takes the average of the lowest 20% of
the windows. Compared to using the overall throughput, this
prevents the algorithm preferring traces that trigger poor be-
havior early on, improving trace diversity.

Trace Score. In order to model properties of the traces
that are hard to model during trace generation, each trace
can be assigned a score based on how well it satisﬁes the de-
sired properties. For example, CC-Fuzz scores trafﬁc traces
using the (negation of) total trafﬁc packets and the total traf-
ﬁc packets dropped in order to make the genetic algorithm
gravitate towards generating minimal trafﬁc vectors.

3.5 Selection Algorithm
Once the traces in a generation have been assigned scores,
we rank the traces from highest score to lowest score. We
ﬁrst pick kElite of the highest scored traces that make it to the
next generation unchanged. We assign a relative probability
1
rank to each trace and then choose kCrossover pairs of
of
traces according to these probabilities, and combine them for
generating crossover traces. The same probabilities (based
on rank) are used for picking traces that undergo mutation
for generating the rest of the traces in order to maintain a
constant population size.

3.6 Emulation vs. Simulation
Our current implementation of CC-Fuzz uses NS3-based sim-
ulation for evaluating a CCA’s performance for a link or traf-
ﬁc trace. An alternative is to use a network emulator like
MahiMahi. In either case, CC-Fuzz will test a combination
of the CCA implementation and the run-time framework,
ﬁnding failures in either system and their interactions.

The beneﬁt of emulation is the ability to test a real im-
plementation of a CCA. Unfortunately, emulating multiple
traces in parallel in a reproducible manner is challenging.
We need to ensure that the performance is not affected due
to CPU and memory bottlenecks, and that the start time of a
ﬂow is synchronized with the network trace. Otherwise, the
CCA behavior can be very different across generations for a
given trace, which can delay or even prevent convergence of
the genetic algorithm.

Simulation, on the other hand, will generate identical re-
sults across repeated runs, resulting in faster convergence. In
addition, for link rates in 10s of Mbps, simulation is likely to
be faster than real-time emulation, and the results of the sim-
ulation are not affected by machine load - this makes it easy
to massively parallelize the algorithm on a single machine.
The key drawback of simulation is that it does not test the
actual implementation, but a re-implementation in the simu-
lation framework (e.g. NS3). Tools like DCE [20] can miti-
gate this drawback by simulating real network stacks.

In addition, randomization in a CCA’s implementation can
also prevent convergence. In such cases, we need to modify
the CCA implementation so that the randomization is repeat-
able (ﬁx the random seed). This is much easier in a simulated

(a) 5 second interval.

(b) 50 millisecond interval.

Figure 3: Service curves generated using DISTPACKETS,
with an average rate of 12 Mbps and kAgg = 50 ms.

1. Trace generation heuristics: We eliminate the local

rate constraints, allowing bursty cross trafﬁc.

2. Crossover operation: By eliminating local rate con-
straints, we deﬁne the crossover operation as follows:
randomly choose a split point by packet count, ran-
domly select the left half of one trace and the right half
of the other trace around the split point, and combine
the two sets of timestamps.

In the case of trafﬁc fuzzing, it is desirable to generate
“minimal” trafﬁc injection vectors that induce poor behav-
ior in CCAs. For example, a large burst of cross trafﬁc
where many packets of the cross trafﬁc are lost will have
the same impact if the lost packets were never sent. In ad-
dition, cross trafﬁc arrives and departs the bottleneck queue
when the CCA under test is silent (e.g. when TCP is waiting
for ACKs after ﬁlling the CWND) has no impact.

In order to impose these properties, we allow a variable
number of cross trafﬁc packets up to a maximum limit. When
regenerating a portion of the trace during a mutation opera-
tion, the number of packets in that portion are changed ran-
domly. During a crossover operation, the number of trafﬁc
packets naturally change based on whether the trace on the
right side has more or less packets. This is combined with
a change to the scoring function (§ 3.4) in order to implic-
itly impose constraints like minimizing the number of cross-
trafﬁc packets required to trigger poor performance in the
CCA being tested.

3.4 Scoring Function
The scoring function is a key aspect of a genetic algorithm -
it determines which traces were successful in triggering spe-
ciﬁc performance behavior, and allows implicit modeling of
desirable properties in a link or trafﬁc trace. As part of cal-
culating the score for a trace, CC-Fuzz runs the CCA using
the link or trafﬁc trace (simulated using NS3. Emulation us-
ing tools like MahiMahi can also be used - comparison in
Section 3.6), and analyzes the queuing behavior. The score
assigned to each trace in a generation has two components:
performance score and trace score.

Performance Score. The performance score can be de-
signed for speciﬁc types of poor behavior like high loss rate,

4

020004000Time (ms)010002000300040005000Packet Count02040Time (ms)010203040Packet Countsetup as opposed to modifying kernel CCA code in an emu-
lated environment. In the future, we plan to explore the use
of emulation for CC-Fuzz.

4 Findings

In this section, we will discuss some interesting ﬁndings that
CC-Fuzz was able to automatically discover. For all of our
tests, we set the bottleneck bandwidth to 12 Mbps (average
bandwidth in the case of link fuzzing) and set the propaga-
tion delay of the bottleneck link to 20 ms. TCP-SACK and
delayed ACKs are enabled (Linux defaults), and min-RTO
is set to 1 second (as per RFC 6298/2.4, Linux uses 200
ms). We use a population size of 500, and use an island-
isolation [21] strategy with 20 islands for solution diversity,
where 10% of the traces migrate every 10 generations. Across
island generations, the best trace is preserved (kElite = 1),
30% of the traces are crossovers, and the rest are mutations.

4.1 BBR - Stuck Throughput

We tested NS3’s version of TCP-BBR with CC-Fuzz, and
after a few generations, it produced traces that triggered low
throughput for BBR where it get’s stuck permanently. One
such trace is shown in Figure 4a. For understanding the root
cause, we dug into NS3 code and generated various internal
logs from BBR’s code and from the NS3 TCP socket code.

BBR uses an 8-RTT gain cycle for estimating bandwidth,
where it sends at 1.25X the current bandwidth estimate for
the ﬁrst RTT, 0.75X on the second RTT and at 1X for the
rest of the gain cycle. Each RTT is considered as a probing
round. The measured rate in each probing round is processed
through a windowed max-ﬁlter that keeps the estimates from
the last 10 rounds of probing.

We found the root cause to be BBR’s mechanism for tim-
ing it’s bandwidth probing cycles in terms of RTT. For each
packet, the TCP send buffer tracks the number of bytes deliv-
ered when that packet was sent in the SKB. At the beginning
of a probing round, BBR records the number of bytes de-
livered so far. The probe ends when the prior delivered of
the packet most recently ACK (i.e. bytes delivered when the
ACKed packet was sent) exceeds the bytes delivered at the
beginning of the probing round.

Suppose a packet P (0) is transmitted at time T0, and is
lost. Fast retransmit will cause the ﬁrst retransmission to oc-
cur at some time T1 > T0 + RT T , and an RTO timer will
be set for T1 + minRT O. At T1 + minRT O, P (0) is re-
transmitted for the second time. Suppose P (i)...P (j) were
the last few packets sent before the second retransmission for
P (0), and the SACKs for these have not arrived yet. After
transmitting P (0) for the second time, P (i) will be transmit-
ted again (a spurious retransmission). Here, the prior deliv-
ered for P (i) is updated in the SKB for P (i) to the current
bytes delivered. If the SACK for the original transmission
of P (i) arrives right after the second transmission of P (i),
BBR will prematurely end the current probe cycle, since the
value of prior delivered for P (i) increased when the spurious

retransmission was sent, and now likely exceeds threshold at
which the current probing round was supposed to end. This
sequence of events is depicted in Figure 4c. Thus, BBR’s
rate sample is now incorrect, as it is using the time and bytes
delivered between the ACK for the original packet, and the
packet’s spurious retransmission, to calculate the rate. This
can result in a low value for the bandwidth sample. This
can repeat for the other packets P (i + 1)...P (j) that were
in-ﬂight when P (0) was transmitted the second time. If this
continues for 10 or more packets, the true bandwidth esti-
mates in the bandwidth max-ﬁlter expire, and BBR’s band-
width estimate becomes low. With a very low bandwidth
estimate, delayed ACKs can cause a positive feedback loop,
causing BBR to send slower and slower, stalling BBR indef-
initely. It is possible that this is the same issue being refer-
enced in [22].

CC-Fuzz was able to trigger this behavior with both, link
fuzzing and trafﬁc fuzzing. Figure 4b shows a link trace gen-
erated by CC-Fuzz that triggers the same bug. The trafﬁc
trace generated by CC-Fuzz is very easy to understand - CC-
Fuzz’s implicit constraints on trafﬁc traces generate a clean,
minimal trace. On the other hand, despite our trace anneal-
ing mechanism signiﬁcantly smoothing out the bandwidth
variations, the link trace is harder to reason about. In the fu-
ture, we plan to implement better heuristics and implicit con-
straints in order to generate easier to understand link traces
that trigger poor behavior.

In order to try and mitigate this behavior, we made BBR
trigger a minRTT probe when an RTO occurs - this slows
down BBR momentarily which allows BBR to receive the
in-ﬂight ACKs, and thus avoid the spurious retransmissions
that cause poor RTT-clocking for BBR’s bandwidth probes.
Figure 4d plots the average of the top 20 traces with the low-
est throughput in each generation. Our proposed ﬁx reduces
throughput a little bit, but avoids the permanent stalling be-
havior observed in BBR without the ﬁx.

4.2 TCP-CUBIC Incorrect CWND Update

When testing TCP-CUBIC, we discovered a bug in NS3’s
implementation of CUBIC’s window update during slow start.
When a packet is lost, and it’s retransmission triggered by
fast retransmit is also lost, the CCA goes into slow start af-
ter RTO. The sender performs a second retransmission for
the packet, and when the ACK for this is received, there is
a large jump in the cumulative ACK. CUBIC’s slow start
window-increase function is called with the large number of
segments ACKed. At this point, the CWND must only be
increased upto the slow-start threshold. In NS3, this check is
not performed, and the congestion window is increased by a
large value - causing CUBIC to send almost 1-RTO (1 sec-
ond in the case of NS3) worth of pending data, causing catas-
trophic losses. This leads to CUBIC going into slow start
again. As of commit 60e1e403, this bug is still present in
NS3. This computation is performed correctly in the Linux
kernel source code.

5

(a) CC-Fuzz trafﬁc trace that
causes BBR to get stuck.

(b) CC-Fuzz link trace that
causes BBR to get stuck.

(c) Timeline showing how
BBR’s bug is triggered.

(d) CC-Fuzz performance with
and without BBR patch.

(e) CC-Fuzz triggering high
delays in BBR with cross traf-
ﬁc.

Figure 4: Analyzing BBR with CC-Fuzz.

4.3 Other Findings

For TCP-Reno, CC-Fuzz was able to ﬁnd a trafﬁc trace sim-
ilar to the well-known low-rate TCP attack [13] for a single
ﬂow, where trafﬁc bursts cause the same packet sequence to
get lost after each retransmission, which triggers exponential
RTO back-off. This prevented Reno from ever ramping up
after the initial slow start phase. CC-Fuzz can also test CCAs
for goals other than low throughput, by just changing the per-
formance component of the scoring function. For example,
we ran trafﬁc fuzzing on BBR with the goal of inducing high
delays by setting the score function to the 10th percentile de-
lay. This caused CC-Fuzz to generate a trafﬁc vector that (1)
ﬁlls up the queue just before BBR starts, so that BBR cannot
see the true link RTT, and (2) injects trafﬁc right after BBR’s
slow start phase to accelerate queue-growth caused by BBR.
This is shown in Figure 4e.

5 Future Work

Realism Scoring. The current version of CC-Fuzz uses a
heuristic-based approach for generating realistic traces. In
the future, we plan to explore an alternate technique for gen-
erating realistic traces using aggregate performance across
multiple CCAs as a score function to quantify the realism
of a trace, assigning high scores to traces under which at
least a few algorithms perform well, and vice versa. Figure 5
shows the traces accepted and rejected by this mechanism.
Note how traces that have low bandwidth initially and higher
bandwidth later are rejected - such traces will naturally cause
low throughput in most CCAs.

In order to reduce the amount of computation required, the
realism score can be computed every few iterations instead
of every iteration, or can be computed for a single randomly
chosen CCA instead of all CCAs in each generation.

Diversity and Semantic Scoring. Currently, CC-Fuzz
tends to converge at a point where most traces trigger the
In order to ﬁnd other
easiest to induce performance bug.
bugs, an iterative process of ﬁxing the bug and retesting, or
deﬁning a score function that negatively weights the mani-
festation of that bug can be used. In the future, we plan to
explore techniques that automatically result in a diverse set
of bugs being found automatically by using machine learning
to classify different behavior and dropping traces that trigger
similar bugs across generations. We also plan to implement a

6

(a) Valid traces.

(b) Invalid traces.

Figure 5: Distribution of service curves according to real-
ism scores assigned by testing on multiple CCAs. The traces
were generated with DISTPACKETS, but without the local
rate constraints.

framework to translate logical speciﬁcations of performance
goals into score functions, so that the user does not have to
come up with complex score functions themselves in order
to make CC-Fuzz work.

Random Losses and Combined Fuzzing. Random packet
losses are common on wireless links. CC-Fuzz’s two modes,
link, and trafﬁc fuzzing, do not cover scenarios where ran-
dom losses occur without a corresponding queue build up.
In the future, we plan to explore loss fuzzing in order to in-
crease the testing coverage, and also explore combining link,
trafﬁc, and loss fuzzing into a single process. Combined
fuzzing will result in much more complex network traces
that include link variations, cross trafﬁc and loss - these are
harder to understand, and thus, it is harder to pin-point the
bug. We plan to address the challenge of generating easier to
understand network traces in order to aid debugging.

6 Conclusion
In this paper, we have presented the design of an automated
congestion control testing tool, CC-Fuzz. Our results are
highly promising with an initial prototype of CC-Fuzz are
ﬁnding both known and unknown issues with existing well-
tested CCAs. We believe that with further development, CC-
Fuzz could ﬁll an important gap in the development of new
CCAs by providing a simple way to identify settings in which
a particular CCA performs poorly.

024Time (s)0102030MbpsIngressEgressTrafficLink Rate024Time (s)0102030MbpsIngressEgressLink RateTime02040Generations200030004000Packets sentDefault BBRBBR (ProbeRTT on RTO)024Time (s)0100200Queuing Delay (ms)BBR FlowCross Traffic020004000Time (ms)010002000300040005000Packet Count020004000Time (ms)010002000300040005000Packet Count[19] Neal Cardwell, Yuchung Cheng, Lawrence Brakmo, Matt Mathis,

Barath Raghavan, Nandita Dukkipati, Hsiao-keng Jerry Chu, Andreas
Terzis, and Tom Herbert. packetdrill: Scriptable network stack
testing, from sockets to packets. In 2013 USENIX Annual Technical
Conference (USENIX ATC 13), pages 213–218, 2013.

[20] Hajime Tazaki, Frédéric Urbani, and Thierry Turletti. Dce cradle:
Simulate network protocols with real stacks. In Workshop on NS3
(WNS3), 2013.

[21] Darrell Whitley, Soraya Rana, and Robert B Heckendorn. The island
model genetic algorithm: On separability, population size and
convergence. Journal of computing and information technology,
7(1):33–47, 1999.

[22] BBR-Development. Question on strange bbr behavior. https:

//groups.google.com/g/bbr-dev/c/XUOKHJiAW80,
2022. [Online; accessed 23-June-2022].

7 References

[1] Ingemar Johansson and Zaheduzzaman Sarker. Self-clocked rate

adaptation for multimedia. Technical report, 2017.

[2] Gaetano Carlucci, Luca De Cicco, Stefan Holmer, and Saverio

Mascolo. Analysis and design of the google congestion control for
web real-time communication (webrtc). In Proceedings of the 7th
International Conference on Multimedia Systems, pages 1–12, 2016.

[3] Keith Winstein, Anirudh Sivaraman, and Hari Balakrishnan.

Stochastic forecasts achieve high throughput and low delay over
cellular networks. In 10th USENIX Symposium on Networked Systems
Design and Implementation (NSDI 13), pages 459–471, 2013.
[4] Matthew K Mukerjee, Christopher Canel, Weiyang Wang, Daehyeok

Kim, Srinivasan Seshan, and Alex C Snoeren. Adapting {TCP} for
reconﬁgurable datacenter networks. In 17th USENIX Symposium on
Networked Systems Design and Implementation (NSDI 20), pages
651–666, 2020.

[5] Venkat Arun and Hari Balakrishnan. Copa: Practical {Delay-Based}
congestion control for the internet. In 15th USENIX Symposium on
Networked Systems Design and Implementation (NSDI 18), pages
329–342, 2018.

[6] Prateesh Goyal, Akshay Narayan, Frank Cangialosi, Srinivas

Narayana, Mohammad Alizadeh, and Hari Balakrishnan. Elasticity
detection: A building block for internet congestion control. arXiv
preprint arXiv:1802.08730, 2018.

[7] Neal Cardwell, Yuchung Cheng, C Stephen Gunn, Soheil Hassas

Yeganeh, and Van Jacobson. Bbr: congestion-based congestion
control. Communications of the ACM, 60(2):58–66, 2017.

[8] Francis Y Yan, Jestin Ma, Greg D Hill, Deepti Raghavan, Riad S
Wahby, Philip Levis, and Keith Winstein. Pantheon: the training
ground for internet congestion-control research. In 2018 USENIX
Annual Technical Conference (USENIX ATC 18), pages 731–743,
2018.

[9] Ravi Netravali, Anirudh Sivaraman, Keith Winstein, Somak Das,
Ameesh Goyal, and Hari Balakrishnan. Mahimahi: A lightweight
toolkit for reproducible web measurement. ACM SIGCOMM
Computer Communication Review, 44(4):129–130, 2014.

[10] Ranysha Ware, Matthew K Mukerjee, Srinivasan Seshan, and Justine
Sherry. Modeling bbr’s interactions with loss-based congestion
control. In Proceedings of the internet measurement conference,
pages 137–143, 2019.

[11] Wikipedia contributors. Sisyphus — Wikipedia, the free

encyclopedia. https://en.wikipedia.org/w/index.
php?title=Sisyphus&oldid=1091831787, 2022. [Online;
accessed 23-June-2022].

[12] Gustavo Carneiro. Ns-3: Network simulator 3. In UTM Lab Meeting

April, volume 20, pages 4–5, 2010.

[13] Aleksandar Kuzmanovic and Edward W Knightly. Low-rate

tcp-targeted denial of service attacks: the shrew vs. the mice and
elephants. In Proceedings of the 2003 conference on Applications,
technologies, architectures, and protocols for computer
communications, pages 75–86, 2003.

[14] Venkat Arun, Mina Tahmasbi Arashloo, Ahmed Saeed, Mohammad
Alizadeh, and Hari Balakrishnan. Toward formally verifying
congestion control behavior. In Proceedings of the 2021 ACM
SIGCOMM 2021 Conference, SIGCOMM ’21, pages 1–16, New
York, NY, USA, 2021. Association for Computing Machinery.
[15] Michael Sutton, Adam Greene, and Pedram Amini. Fuzzing: brute

force vulnerability discovery. Pearson Education, 2007.

[16] Samuel Jero, Md Endadul Hoque, David R Choffnes, Alan Mislove,
and Cristina Nita-Rotaru. Automated attack discovery in tcp
congestion control using a model-guided approach. In NDSS, 2018.
[17] Yong-Hao Zou, Jia-Ju Bai, Jielong Zhou, Jianfeng Tan, Chenggang

Qin, and Shi-Min Hu. {TCP-Fuzz}: Detecting memory and semantic
bugs in {TCP} stacks with fuzzing. In 2021 USENIX Annual
Technical Conference (USENIX ATC 21), pages 489–502, 2021.

[18] Wei Sun, Lisong Xu, Sebastian Elbaum, and Di Zhao.

{Model-Agnostic} and efﬁcient exploration of numerical state space
of {Real-World}{TCP} congestion control implementations. In 16th
USENIX Symposium on Networked Systems Design and
Implementation (NSDI 19), pages 719–734, 2019.

7

