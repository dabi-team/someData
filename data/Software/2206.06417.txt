2
2
0
2

n
u
J

6
2

]

G
L
.
s
c
[

2
v
7
1
4
6
0
.
6
0
2
2
:
v
i
X
r
a

Image-based Treatment Effect Heterogeneity

Connor T. Jerzak
Institute for Analytical Sociology
Linköping University
Email: connor.jerzak@liu.se
Website: ConnorJerzak.com

Fredrik Johansson
Data Science and AI Division
Chalmers University of Technology
Email: fredrik.johansson@chalmers.se
Website: fredjo.com

Adel Daoud
Institute for Analytical Sociology
Linköping University
Email: adel.daoud@liu.se
Website: AdelDaoud.se
AI and Global Development Lab: global-lab.ai

Abstract

Randomized controlled trials (RCTs) are considered the gold standard for estimat-
ing the effects of interventions. Recent work has studied effect heterogeneity in
RCTs by conditioning estimates on tabular variables such as age and ethnicity.
However, such variables are often only observed near the time of the experiment
and may fail to capture historical or geographical reasons for effect variation. When
experiment units are associated with a particular location, satellite imagery can
provide such historical and geographical information, yet there is no method which
incorporates it for describing effect heterogeneity. In this paper, we develop such
a method which estimates, using a deep probabilistic modeling framework, the
clusters of images having the same distribution over treatment effects. We compare
the proposed methods against alternatives in simulation and in an application to
estimating the effects of an anti-poverty intervention in Uganda. A causal regular-
ization penalty is introduced to ensure reliability of the cluster model in recovering
Average Treatment Effects (ATEs). Finally, we discuss feasibility, limitations, and
the applicability of these methods to other domains, such as medicine and climate
science, where image information is prevalent. We make code for all modeling
strategies publicly available in an open-source software package.

1

Introduction

Field experiments in the social and health sciences help us understand the effects of interventions in
the natural habitat where people live (Banerjee et al., 2011). Their primary goal is often to identify the
average effect (ATE) of a treatment Ti on an outcome Yi over units i in a population. By collecting
tabular characteristics, Xi, such as age, sex, and income, researchers may estimate Conditional
Average Treatment Effects (CATEs) to analyze effects by sub-populations (Künzel et al., 2019; Balgi
et al., 2022), and thereby, to optimize treatments for each group. But, the features in Xi are often
measured only at baseline, just before the experiment is initiated. Thus, Xi tend to miss critical
historical and geographical characteristics for treatment optimization (Kino et al., 2021).

When units i are associated with a particular location, satellite images, Mi, can provide missing
historical and geographical context (Burke et al., 2021; Daoud et al., 2021). In contrast to covariates
measured during experiments, satellite imagery is routinely collected passively from space. These
data have been collected for parts of the world since the CORONA intelligence satellites of the 1950s

Preprint.

 
 
 
 
 
 
and for the entire world since the start of the Landsat mission in 1970s. The Landsat data are publicly
available, with revisiting time of ∼ 16 days. By combining satellite imagery with experimental data,
researchers can investigate not only the historical and geographical roots of effect variation, but they
can also analyze how an intervention might impact places outside the scope of the original study.
Such analysis are made possible as imagery can be obtained not only for the experimental setting but
also places not originally in the experiment and where no background covariates were measured. This
possibility would potentially increase the applicability of casual transportability to a considerable
degree (Pearl and Bareinboim, 2022). Nonetheless, despite the potential offered by images for causal
inference (Castro et al., 2020; Chalupka et al., 2016b,a, 2015; Schölkopf et al., 2021; Yi et al., 2020;
Ding et al., 2021; Paciorek, 2010; Kaddour et al., 2021b; Louizos et al., 2017; Pawlowski et al., 2020;
Lopez-Paz et al., 2017), it remains unclear how researchers should use these Mi for CATE analysis.
The two main interrelated challenges are that Mi is high-dimensional and often not annotated: thus,
a CATE analysis based on Mi could have poor interpretability.

In this article, we develop models which identify treatment effect heterogeneity in data from random-
ized controlled trials (RCTs) by analyzing satellite imagery collected independetly of the experiments.
The probabilistic models we develop employ Bayesian convolutional neural network arms (CNNs)
and categorical gates that allow us to directly model mixtures of image clusters with similar effects.
That is, our models estimate treatment effects for all units, conditional on treatment status, the images
Mi, and, if desired, accounting for available Xi through orthogonalization. (By residualizing, our
model will identify what additional CATE dynamics that stem from Mi, separately from Xi). The
models construct clusters that categorize units based on their Image-Type CATE similarity.

In the following sections, we develop our methods, show some properties analytically, and explore
others in simulated experiments. We demonstrate its usefulness by replicating the results of an RCT
study in Uganda—the Youth Opportunities Program (YOP) (Blattman et al., 2014). This study,
conducted in 2008, was designed to help the poor break unemployment cycles by assisting their
artisans and business activity. The government solicited young adults to participate in YOP, asking
them to form teams and compose a business plan. After screening these teams and their plans, the
government randomly assigned a one-time grant worth about $7,500 to each team. This amount
equals approximately their joint annual income. Most of the applicants where rural farmers, which
had low educational attainment (∼ eighth grade), earned less than $1 per day, and worked less than
twelve hours per week. As many RCTs like YOP, the researchers collected a set of baseline covariates,
but none of them capture past historical or geographical characteristics. Our replication analysis
demonstrates the beneﬁts, and limitations, of using Mi for CATE, as a complement to Xi.

While our contribution focuses on the use of satellite images in global poverty research, our methods
are designed such that they can be generalized to other forms of RCTs where complementary image
data is available. In the last few decades, there has been a rapid increase in the availability of imaging
technologies. Most notably, these technologies are readily available in medicine, epidemiology and
adjacent ﬁelds, using X-ray, positron emission, MRI, and ultrasound. We hypothesize that these
images are useful not only for estimating ATE (Castro et al., 2020; Lopez-Paz et al., 2017; Chalupka
et al., 2016b), but also for evaluating CATE. Nonetheless, more research is required to systematically
evaluate our models generalizability for these domains.

2 Background and Related Work

Conditional Average Treatment Effects with Tabular Data Let Yi(t) denote the potential out-
come (Rubin, 2005) of an intervention t ∈ {0, 1} for a unit of study i. For example, Yi(1) may
represent the poverty level in a household i following an aid intervention, and Yi(0) the level without
intervention. We may deﬁne the unit-level treatment effect as

Individual Treatment Effect: τi = Yi(1) − Yi(0).

When τi is greater than 0, the unit’s outcome is greater under treatment than otherwise. Without
conducting counterfactual inference (Pearl, 2009), the quantity τi cannot be identiﬁed, because only
either of the potential outcomes Yi(1) or Yi(0) are observed: a unit can only receive a single treatment
at a given time, and thus, the counterfactual remains unobserved. Assuming consistency Hernán MA
(2020), the observed outcome can be written, Yi = Yi(Ti) = Yi(1)Ti + Yi(0)(1 − Ti), where Ti
denotes the (random) treatment status of i. The ATE captures the population effect by averaging over

2

all unit-level effects:

Average Treatment Effect (ATE): τ = E[τi] = E[Yi(1) − Yi(0)].

The ATE is useful as it marginalizes over the heterogeneity present in a population to form an overall
assessment of an experiment. In an RCT, due to treatment randomization, ATE can be estimated
non-parametrically by the difference between treatment and control outcomes (Rubin, 2005),

(cid:98)τ Non-parametric = n−1
1

n
(cid:88)

i=1

Yi · Ti − n−1
0

n
(cid:88)

i=1

Yi · (1 − Ti),

where nt denotes the number of units in treatment group, t ∈ {0, 1}. Despite the importance of
aggregate quantities such as the ATE, it is useful to disaggregate average effects using based on
contextual information. Such a disaggregation is critical for not only scientiﬁc understanding but also
for policy (e.g., personalizing treatments (Greenland et al., 2020; Balgi et al., 2022)) and industry
applications (e.g., personalizing advertisement (Nabi et al., 2020)). This disaggregation can be a
function of any type of general pre-treatment data variable, Gi:

Conditional Average Treatment Effect (CATE): τ (g) = E[Yi(1) − Yi(0) | Gi = g],

The literature has primarily focused on conditioning sets which contain tabular data, Xi:

Tabular Conditional Average Treatment Effect: τ (x) = E[Yi(1) − Yi(0) | Xi = x],

where x ∈ RD denotes the vector of D pre-treatment covariates (Athey and Imbens, 2016; Athey
et al., 2019; Ding et al., 2016; Imai and Ratkovic, 2013; Shalit et al., 2017; Zhao et al., 2017; Luedtke
and van der Laan, 2016; Nie and Wager, 2021). For example, the generalized random forest is one
such recent machine-learning method (Athey et al., 2019) that has proven useful in a variety of applied
settings (Shiba et al., 2021; Daoud and Johansson, 2019). These methods are tailored for annotated
tabular data, but images are high-dimensional and often not annotated. These non-annotated image
features consists of image bands and pixels that may jointly induce effect heterogeneity. In the
remainder of this paper, we focus on improving the ability of investigators to understand treatment
effect heterogeneity in the context of unstructured high-dimensional image data.

Causal Inference with Image Data While most studies estimating causal effects use tabular data,
there is an increasing realization that image data provides a creative yet useful way to conduct
causal inference (Castro et al., 2020; Ramachandra, 2019; Daoud and Dubhashi, 2020). To this end,
there has been some methodological development, investigating how images should be integrated
to identify and estimate ATEs in the observational setting (Kallus, 2020; Kaddour et al., 2021a;
Pawlowski et al., 2020; Jerzak et al., 2022). Here, images are part of the adjustment set. Therefore,
most methodological development has focused on how to use images to proxy confounding variables;
less is known about how to use images for CATE estimation.

As discussed in §1, images may provide critical information for effect understanding. Like any tabular
information in Xi, images as a whole or through segments may modify effects. In the observational
setting, images Mi could both be part of the conditioning set and the effect modiﬁcation set. In the
RCT setting, Mi is not a confounder (and thus, unnecessary to identify ATE), since the treatment
was randomized. In both settings, one target estimand is the Image CATE,

Image CATE: τ (m) = E[Yi(1) − Yi(0) | Mi = m],

where m ∈ RW ×H×D is an an image, obtained from prior to the assignment of treatment, of width W ,
height H, and with D data channels. These data channels often correspond to reﬂectance information
from various bands. While Image and Tabular CATEs are both a subset of the general CATEs, there
are conceptual differences. First, by their nature, images are unstructured, high dimensional objects.
In RCT applications, every image will likely be unique as image effects act much as individual-level
treatment effects, where summarizing the quantity of interest becomes increasingly difﬁcult with
a growing number of units. Second, as unstructured, it may be unclear how to interpret the act of
conditioning on an image. We need a conceptual language and modeling strategy for understanding
“closeness” between images in the space of conditional effects. The rest of our article contributes to
establishing this conceptual language, focusing for the sake of clarity on the RCT setting.

3

3 Modeling Causal Effect Heterogeneity in Images

In experimental settings, CATEs may be estimated readily by function approximation. Perhaps the
simplest approach is to ﬁt a separate model, ˆYt(m), to observations of the potential outcome Y (t) of
each intervention—a so-called T-learner (Künzel et al., 2019). The CATE may then be estimated as
ˆτ (m) = ˆY1(m) − ˆY0(m). Shalit et al. (2017) found that learning a shared representation Φ used to
predict both treatment outcomes improved prediction quality and dubbed this approach TARNet.

Given any model of heterogeneity ˆτ , we can partition units by their predicted causal effect, creating
a clustering of inputs post hoc. Let C(ˆτ (m)) ∈ {1, 2, ..., K} denote a cluster labeling function
determined by the output of ˆτ , which partitions the space of effect sizes and, as a result, the space of
images. C may be constructed by uniform binning of ˆτ , quantile binning or, as in our experiments,
by k-means clustering. Then, the CATE with respect to the post-hoc clustering labels is

Prediction Cluster CATE: τ (c) = E[Yi(1) − Yi(0) | C(ˆτ (Mi)) = c],

In our experiments, we use the post-hoc clustering of TARNet’s ˆτ (Mi) estimates as baseline.

A drawback of the post-hoc model is that it compounds approximations to arrive at a small discrete
representation of treatment effect heterogeneity. If two similar images yield very different predictions
due to misestimation, they are likely to be placed in different clusters. Instead, we would prefer to
cluster images smoothly in a way which best approximates treatment effect heterogeneity. Moreover,
it is difﬁcult to quantify the aggregation of uncertainty in post-hoc clustering, especially as it may be
difﬁcult to propagate gradients through both the outcome and subsequent clustering model.

3.1 Probabilistic Effect Clustering Based on Image Type

With these observations in mind, we develop a modeling strategy for summarizing treatment effect
heterogeneity that is driven by image patterns which can be succinctly summarized for the purposes
of interpretability. To the best of our knowledge, this is the ﬁrst work to use images to summarize
causal effect heterogeneity, so we will strive for simplicity in our model and application.

The primary criteria our modeling strategy needs to fulﬁl are: (1) model potential outcomes and
treatment effects ﬂexibly and (2) identify interpretable image clusters with similar in-cluster effect
sizes, and different cross-cluster effects. Our target quantity of interest will be

Image-Type CATE: τ (z) = E[Yi(1) − Yi(0) | Zi = z],

where Zi ∈ {1, 2, ..., K} denotes the effect cluster of image Mi, where there are K total clusters.
We will search for assignments Zi of clusters to images that best explains treatment effect variation.
Perhaps the closest existing analogue to this quantity is the mixture of experts approach for CATEs in
the conjoint setting using linear models with interactions (Goplerud et al., 2022).

Because the treatment effects are decomposed by image type, there are only K quantities needed
to effectively summarize the heterogeneity accountable to images. Since human working memory
can track between 3 to 5 distinct chunks at any single time (Cowan, 2010), this summary of the
complex heterogeneity process stemming from images can in principle be represented in stakeholders’
mental processes, so long as the number of image effect types is reasonably small. This possibility
is important because it may facilitate the communication and effective implementation of future
treatment targeting decisions. With this substantive motivation in mind, we now discuss how we fulﬁl
the two modeling criteria in pursuit of understanding treatment effect heterogeneity with images.

Effect Mixture Based on Image Type We satisfy the ﬁrst criterion by allowing the baseline
potential outcome, Yi(0), to be estimated ﬂexibly as a function of the image. In particular, we let the
mean of the baseline potential outcome, conditional on the image, be parameterized by a Bayesian
convolutional neural network,

E[Yi(0) | Mi = m] = {µYi(0) | Mi = m} ∼ Bayesian CNN(m) .

We employ a Bayesian network, where convolutional and dense parameters are not deterministic, but
instead deﬁned according to a distribution. This will allow us to explicitly explore uncertainty in the
implied Image-Type CATEs. Use of Bayesian networks (or approximations thereof, e.g., dropout) has
also empirically been observed to help prevent overﬁtting (Gal and Ghahramani, 2016), an important

4

Mi

Zi

Yi(0)

τi

+

Yi(1)

i ∈ {1, ..., n}

Figure 1: Stylized schematic depiction of the probabilistic treatment heterogeneity model for images.
The gray circles denote observed random variables; the white circles denote latent variables; the
mixed gray/white nodes denote partially observed nodes (i.e. variables which are observed for some,
but not all, units). Square node denotes deterministic transformations that operate on the means for
each input node (see text). Zi denotes the image type generating a distribution over treatment effects.

property in the case of experiments implemented by governments or international organizations,
where the number of experimental units may be relatively small (∼ 103).
Having ﬂexibly deﬁned the baseline, we turn our attention to the Image-Type CATE estimand, using
two alternative models. Our ﬁrst model computes image type probabilities Pi using another Bayesian
network. Conditional on the image type Z = z, treatment effects are drawn assumed to be Normally
distributed with a unique mean µτ,z and variance σ2
τ,z indexed to that image type. We do not assume
that there is a single treatment effect per image type, but instead that there is a speciﬁc distribution
over treatment effects by image type. The cluster effect means and variances offer a complete
summarization of this distribution. The assumed probabilistic generative model for image-based
treatment effect heterogeneity is summarized in Figure 1 and deﬁned in full below

Generating the Image Type

{Pi | Mi = m} ∼ Bayesian CNN(m)
{Zi | Pi = p} ∼ Categorical(p)
↓
Generating the Treatment Effect Distributions
Image-Type Effect Cluster Model (§3.1): {τi | Zi = z} ∼ N (µτ,z, σ2
Image-Type Differential Effect Model (§3.1): {τi | Mi = m, Zi = z} ∼ Bayesian CNN(z)(m)

τ,z)

↓

Generating the Baseline Outcome, Yi(0)
{µYi(0) | Mi = m} ∼ Bayesian CNN(m) → {Yi(1) | µYi(0), τi, σ2
{Yi(0) | µi(0), σ2

Generating the Outcome under Treatment, Yi(1)
1,z} ∼ N (µYi(0) + τi, σ2

0,z} ∼ N (µYi(0), σ2

0,z)

1,z)

In this approach, the treatment effects decomposed by treatment type are variational parameters. By
the structure of the model outlined in Figure 1, we have conditional mean and variance (see A.1.1),

τ (z) = E[Yi(1) − Yi(0) | Zi = z] = µτ,z,

Var(Yi(1) − Yi(0) | Zi = z) = σ2

0,z + σ2

1,z + σ2

τ,z.

Besides the enhanced interpretability from summarizing image-derived effect heterogeneity in K
discrete clusters, there are other advantages to our modeling strategy. First, as it is probabilistic, we
can explore uncertainty not only in the treatment effects by also in the cluster assignment probabilities.
Second, the image type decomposition also may facilitate scientiﬁc inquiry: the image type serve
as natural generalization of the image, facilitating theorizing about the causal mechanisms at play.
Third, we can readily compute the gradients of the cluster probabilities with respect to the image in
order to identify how the image affects the typology (see §3.3).

Using the model outlined in Figure 1, we seek to learn the joint distribution of the model parameters
Θ and the image clustering, Z, given the observed dataset, D = {Yi(Ti), Mi, Ti}n

i=1:

Target Posterior: p(Z, Θ | D),

(1)

5

where Z = {Zi}n
the posterior in (1), we maximize the Evidence Lower Bound (ELBO) (Ranganath et al., 2014),

i=1. For additional details of how we model the uncertainties, see A.1. To estimate

maximize
q(Z, Θ|M, T)

Eq(Z, Θ|M, T)

(cid:2)log (cid:0)p(Y(T) | Z, Θ, M, T)(cid:1)(cid:3)

− DKL (q(Z, Θ | M, T) || p(Z, Θ | M, T)) .

We solve the problem approximiately using stochastic gradient descent with gradients passing
through discrete sampling nodes using re-paramerization techniques (Parmas and Sugiyama, 2021).
An additional beneﬁt of the approach proposed here, as opposed to post-hoc clustering, is that
uncertainty of the variational clustering model can be quantiﬁed using M -estimation theory (Westling
and McCormick, 2019). Also, choice of priors affects ﬁnite sample performance, so when possible,
we specify priors using empirically observable marginal information (e.g., the prior mean for the
cluster effects is set to ˆτ Non-parametric).
Differential Effects Based on Image Type The ﬁrst effect mixture model we introduced could
be useful to investigators because conditional effects can be succinctly summarized, but in some
circumstances, investigators may seek a more ﬂexible modeling strategy for Yi(1). In that case, the
distribution of treatment effects given the image type z is parameterized by a Bayesian CNN arm
indexed to z:

{τi | Mi = m, Zi = z} ∼ Bayesian CNN(z)(m)

In essence, the image type acts as a stochastic gate which determines which image patterns will be
used in predicting the treatment effect.

3.2 Encouraging Unbiased ATE Estimates via Causal Regularization

The modeling process just described involves selecting several parameters, such as the number of
clusters and even the kind of images used. Given the numerous possibilities involved, we propose
the addition of a causal regularization term to encourage all models to be equivalent in their implied
marginal effect (for discussion of causal regularization in a different context, see (Oberst et al., 2021)).
That is, by the Law of Total Expectation, the ATE τ satisﬁes

τ = E[Yi(1) − Yi(0)] =

K
(cid:88)

z=1

E(cid:2)Yi(1) − Yi(0) | Zi = z(cid:3) Pr(Zi = z) =

K
(cid:88)

z=1

τ (z) Pr(Zi = z),

a fact which gives rise to a natural estimator using the sample analogues of the theoretical quantities:
(cid:98)τ Model = (cid:80)K
z=1 (cid:98)τ (z)(cid:99)Pr(Zi = z), where the (cid:98)τ (z)’s are taken from the mixture components and the
(cid:99)Pr(Zi = z) term is estimated from the marginal cluster probabilities.
However, as noted, the ATE can also be estimated using the non-parametric difference-in-means
estimator described in §2, with estimation being, under minimal assumptions, consistent (Imbens and
Rubin, 2015). Thus, if the proposed heterogeneity model is consistent as well,

{(cid:98)τ Model

n→∞→ τ }, {(cid:98)τ Non-parametric

n→∞→ τ } ⇒ ((cid:98)τ Model − (cid:98)τ Non-parametric)2 n→∞→ 0

(2)

If the implied ATE from the model diverges too far from the non-parameteric estimator, the credibility
of the proposed model would be thereby reduced. Under additional modeling assumptions, we can
in fact re-parameterize the parametric model exactly so that (cid:98)τ Model=(cid:98)τ Non-parametric exactly (see A.2).
However, the exact re-parameterization forcing (cid:98)τ Model = (cid:98)τ Non-parametric involves similar problems
as found in the compositional statistics literature (e.g., ordering of clusters can affect the results
(Greenacre, 2021)), we instead incorporate a soft penalty that is invariant to the ordering of clusters:

Model ATE Equivalence Regularization Term: λ

(cid:32) K
(cid:88)

z=1

(cid:98)τ (z)(cid:99)Pr(Zi = z) − (cid:98)τ Non-parametric

(cid:33)2

We add this to the variational objective to encourage marginal effects to be equivalent regardless of
the parameterization of the model, using a non-parametric estimator for the ATE as a baseline.

6

3.3 Determination of Sensitivity Regions

One beneﬁt of the proposed probabilistic image-type heterogeneity decomposition is that we can
examine the model in order to assess how image information translates into the predicted effect
cluster. In particular, we take the derivative of the cluster probabilities with respect to pixels (i, w, h):

siwh =

D
(cid:88)

K
(cid:88)

d=1

z=1

(cid:12)
(cid:12)
(cid:12)
(cid:12)

∂ (cid:99)Pr(Zi = z | Mi = m)
∂ mwhd

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Large values of siwh reveal locations in the image that, if changed, would lead to the large changes
in the cluster probabilities; siwh can thus provide a basis for understanding how image information
translates into the effect typology. This sensitivity information is difﬁcult to compute for post-hoc
clustering methods, as the clustering of the ˆτi’s needs to solve a second optimization problem (as in
k-means) through which gradients w.r.t. the initial outcome model(s) may not be efﬁciently traced.

3.4 Policy Action Using the Image-based Heterogeneity Model

A major motivation for considering image-based CATEs is that we can readily generate predictive
distributions over treatment effects for contexts outside the experimental setting and where no tabular
covariates were measured by researchers. In this context, for a new out of sample point, i ∈ I(Out),
we form a predictive distribution over image treatment effects using

p(τi | Mi, D) =

K
(cid:88)

(cid:90)

z=1

p(τi | Zi = z; Θ = θ) · p(Zi = z | Mi; Θ = θ) · p(Θ = θ | D) dθ

We can use the predictive distribution over treatment effects to improve treatment targeting for
1 for the new dataset of size nO =
out-of-sample individuals. With a ﬁxed treatment budget of size nO
|I(Out)|, this policy can be written as Π({Mi}I(Out)) → {0, 1}nO
. There are many approaches to
this out-of-sample treatment targeting and we refer readers to that literature (Hitsch and Misra, 2018).

3.5 Distinguishing Image from Tabular Conditional Effects

In some contexts, like when tabular covariates are not measured or when we seek to generate
predictions for contexts without tabular covariates, it may be particularly useful to perform image-
type effect clustering directly using the images. However, when other tabular covariates are measured
for the sample and only that sample is of interest, researchers may seek to understand the heterogeneity
stemming from image information that is not redundant vis-à-vis tabular covariates.

For example, race is correlated with the image information of neighborhoods in the United States,
where minorities are concentrated in dense urban centers with little green space while more afﬂuent
non-minorities tend to live in green-space rich areas outside cities (Cucca, 2020). We might naturally
ask about the remaining heterogeneity after accounting for the heterogeneity due to key tabular
variables such as race. We therefore can perform the image clustering on the orthogonalized outcomes:

Yi(t)⊥ = Yi(t) − (cid:98)E[Yi(t)|Xi].
The resulting clusters, estimated using the modeling strategies in §3.1, then can be interpreted as
image effect clusters after accounting for the heterogeneity present in the measured tabular data.

4 Treatment Effect Cluster Recovery in Simulation

We now explore dynamics of the proposed methods via simulation, where true effects are known.

Design We generate image-based treatment effect heterogeneity using,

Hi = GN(max(fl(Mi))),

H +

i = | min{Hi}n
(cid:123)(cid:122)
Ensures τi > 0

i=1|
(cid:125)

(cid:124)

+ sign(Hi) · |Hi|1/γ
(cid:125)

(cid:123)(cid:122)
Generates bimodality as γ → ∞

(cid:124)

(3)

where fl(·) denotes the application of a l × l ﬁlter to the the image, max(·) denotes the global
maximum operation across the image, and GN(·) denotes a global normalization function scaling

7

the Hi values to have mean 0 and variance 1 across the image pool. The speciﬁc transformation
generating H +
is selected (1) to ensure all the treatment effects are in the same direction (i.e. all
i
positive) and (2) to generate heterogeneity in the effect distribution, with greater bimodality in the
treatment response as γ → ∞. We let γ = 2. We deﬁne the treatment and outcome:

Ti ∼ Binomial(0.5), Yi = TiH +

i + (cid:15)i,

with (cid:15)i ∼ N (0, ν · Var(H +
i )). The value of ν controls the extent to which the image is predictive
of the outcomes, where smaller values indicate stronger image heterogeneity signal. To explore
estimation dynamics, we vary ν ∈ {0.01, 0.1, 1}.

The ﬁlter used in the convolution function of Equation 3 is visualized in Figure A.1, along with high
and low responders from the set of images used in the simulation that we take from sub-Saharan
Africa. We have some degree of model misspeciﬁcation in our estimation model, as the way the data
is generated is distinct from the estimation model; given this misspeciﬁcation, we will examine the
degree to which our model will recover key properties of the image-based causal heterogeneity. A
visual depiction of the generative model for the simulation data is provided in Figure A.2.

Cluster Recovery Measure We compare the estimated effect clustering with an oracle baseline
from the true, in practice unknown, τi’s. In particular, we ﬁrst compute the oracle k-means clustering:
τ (z)Oracle = zth center from the oracle k-means applied to the true (in practice unknown) τi’s

The clustering quality measure then compares the oracle with estimated cluster means:

Cluster Recovery R2 = 1 −

(cid:80)K

z=1 minz(cid:48)((cid:98)τ (z) − τ (z(cid:48))Oracle)2
(cid:80)K
z(cid:48)(cid:48)=1(τ (z(cid:48)(cid:48))Oracle − τ Oracle)2

,

where τ Oracle denotes the mean across the oracle cluster centers. This measure is equivalent to the R2
in predicting the oracle cluster means from the estimated ones, where the ordering of the clusters has
been arranged so that each oracle center is compared to its nearest estimated counterpart.

Simulation Results We see in the left panel of Figure 2 one representative posterior distribution
over Yi(1) − Yi(0) given estimated cluster information. We ﬁnd that the estimated clusters capture the
bimodality present in the true distribution of τi’s. In the right panel, we see that the cluster recovery
measure for the Image-Type Differential Effects Model and TARNet clustering are similar in the
low residual variance setting. In the high residual variance setting, the TARNet clustering struggles
to recover the oracle cluster centers. The parsimonious Image-Type Effect Clustering Model here
performs best at recovering the clustering of the treatment effects across the noise range. In Figure
A.4, we see that the estimated ATEs are on average closer to the true value using the two image-type
models (which use Model ATE Equivalence Regularization) compared to the TARNet approach.

Figure 2: Left. Capturing the treatment effect heterogeneity. Right. Comparing our models.

5 Application to an Anti-Poverty Experiment in Uganda

Data In our application, we explore the effects of the anti-poverty experiment performed in Uganda
and described in §1. The treatment variable is random assignment of small teams to receive grants

8

123450.00.10.20.30.40.50.60.7Per Image Treatment EffectDensity||t^(1)t^(2)True p(Yi(1)-Yi(0) | Mi)p^ ( Yi(1)-Yi(0) | Z_i(Mi)=1 )p^ ( Yi(1)-Yi(0) | Z_i(Mi)=2 )0.010.050.200.500.60.70.80.91.0Cluster Recovery R2Post−hoc ClusteringImage Type Differential EffectsImage Type Effect ClusteringScaling of Non−image  Residual Variancefor business ventures. The outcome variable is an aggregate summary of skilled labor (see A.4.1)
measured at the end of the experiment (two years after treatment assignment). Outcome and treatment
data, available under CC0 1.0 license, are de-identiﬁed and were given voluntarily by subjects.

Pre-treatment image data is taken from Landsat. We use the Orthorectiﬁed ETM+ pan-sharpened
data product. This product is derived using satellite imagery captured between 1998 and 2001 (about
10 years pre-intervention) and is processed so as to contain minimal cloud-cover. Reﬂectance is
measured in the green, near-infrared, and short-wave infrared bands; resolution is 14.25 meters.

Empirical Results We ﬁt the Image-Type Effect Cluster Model (details in A.6). We set the cluster
number to two after ﬁnding that cluster probabilities become highly correlated with additional clusters.
We plot in Figure 3 the top images having highest mean cluster probabilities. For each image, we
also place a square around the top sensitivity regions as deﬁned in §3.3. We see that the cluster
treatment effect for cluster 1 is about 20% greater than cluster 2. This ﬁnding suggest that larger
treatment effects are present for places having harsher terrain and less developed transportation
network. This ﬁnding emerges when we plot the clustering on the land cover map of Uganda in
Figure A.5. Geographically, many of the low responders are found in the harsh mountainous northern
part of Uganda. We see in A.4 that the places having the most uncertainty in the cluster probabilities
are locations characterized dominated by water features. In addition, we orthogonalize the potential
outcomes using tabular information (see A.5), and the results remain similar: correlation between
raw and non-orthogonalized cluster probabilities is 0.88. Because our results remain similar after
orthogonalization, the Ugandian satellie images seem to supply independent CATE information that
the original experimantors were unable to assess. Consequently, what our CATE-image analysis
shows is that the causal effect of Ugandian youth groups is higher, if they also have live in historically
well-connected neighborhoods. This is logical, as skilled labor tends to thrive in such hotspots.

Figure 3: Top. High probability cluster 1 images. Bottom. High probability cluster 2 images.

6 Discussion and Conclusion

Limitations Our methods have certain limitations. First, they estimate heterogeneity clusters at the
image level, but not for smaller segments of an image. This within-image heterogeneity segmentation
would further improve interpretability. Second, our methods estimate heterogeneity with respect to an
assumed baseline (i.e. the control intervention). While the choice of baseline is clear in most settings,
in others, it may not be. In those unclear cases, the investigators may need to run the models using
different baselines, depending on their needs, and compare results.

Societal Impact As demonstrated in our analysis of the Ugandan anti-poverty experiment, our
method identiﬁes possible heterogeneity not originally detected because the investigators did not
have access to historical and geographical data—information imprinted in, for example, satellite
images. Thus, our satellite-based methods have the potential to contribute to policy by complementing
traditional RCT heterogeneity analysis based on tabular Xi. Other applications where image data is
omnipresent are precision agriculture, disaster relief, climate science, and medicine. More research
and considerations of fairness are required to evaluate our methods in these settings.

9

1Long: 32.33, Lat: 2.29t^1=0.7752Long: 33.42, Lat: 1.313Long: 31.48, Lat: 3.314Long: 32.34, Lat: 2.135Long: 32.41, Lat: 1.786Long: 34.13, Lat: 3.52t^2=0.6547Long: 34.12, Lat: 3.008Long: 34.14, Lat: 3.579Long: 31.45, Lat: 2.4410Long: 31.72, Lat: 3.65Observational Setting Using experimental data has the beneﬁt
that effect estimates are
confounding-free by design; effect heterogeneity can be studied independently of identiﬁcation.
Observational data are more plentiful but require adjustment (Rosenbaum et al., 2010). Our current
methodology is not designed for that setting. For our method to remain unbiased, factors causal of
the outcome would need to be well-captured by the image Mi and the induced clustering Zi. If a set
of variables provides exchangeability with respect to potential outcomes Yi(0), Yi(1) (Rosenbaum
and Rubin, 1983), it could be incorporated directly as input to the model of Yi(0). Doing the same for
τi would require conditioning on the clustering and on Mi, making the analysis more complicated.

Concluding Remarks
In this paper, we present principles and modeling strategies for analyzing
image-based treatment effect heterogeneity using probabilistic image-type models. We derive some
properties of this model and perform approximate inference using variational methods. Dynamics are
explored via simulation and an anti-poverty ﬁeld experiment from Uganda analyzed, where we seem
(cid:3)
to ﬁnd some evidence of novel heterogeneity dynamics.

References

Susan Athey and Guido Imbens. Recursive partitioning for heterogeneous causal effects. Proceedings

of the National Academy of Sciences, 113(27):7353–7360, 2016.

Susan Athey, Julie Tibshirani, and Stefan Wager. Generalized random forests. The Annals of Statistics,

47(2):1148–1178, 2019.

Sourabh Balgi, Jose M. Pena, and Adel Daoud. Personalized Public Policy Analysis in Social
Sciences using Causal-Graphical Normalizing Flows. Association for the Advancement of Artiﬁcial
Intelligence: AI for Social Impact track, February 2022. URL http://arxiv.org/abs/2202.
03281. arXiv: 2202.03281.

Abhijit Banerjee, Abhijit V Banerjee, and Esther Duﬂo. Poor economics: A radical rethinking of the

way to ﬁght global poverty. Public Affairs, 2011.

Christopher Blattman, Nathan Fiala, and Sebastian Martinez. Generating skilled self-employment in
developing countries: Experimental evidence from uganda. The Quarterly Journal of Economics,
129(2):697–752, 2014.

Marshall Burke, Anne Driscoll, David B. Lobell, and Stefano Ermon. Using satellite imagery to
understand and promote sustainable development. Science, 371(6535):eabe8628, March 2021.
ISSN 0036-8075, 1095-9203. doi: 10.1126/science.abe8628. URL https://www.sciencemag.
org/lookup/doi/10.1126/science.abe8628.

Daniel C. Castro, Ian Walker, Ben Glocker, Ian Walker, and Ben Glocker. Causality matters in
medical imaging. Nature Communications, 11(1):3673, July 2020. ISSN 2041-1723. doi: 10.1038/
s41467-020-17478-w. URL https://www.nature.com/articles/s41467-020-17478-w.
Bandiera_abtest: a Cc_license_type: cc_by Cg_type: Nature Research Journals Number: 1
Primary_atype: Reviews Publisher: Nature Publishing Group Subject_term: Computational
models;Data processing;Machine learning;Medical research;Predictive medicine Subject_term_id:
computational-models;data-processing;machine-learning;medical-research;predictive-medicine.

Krzysztof Chalupka, Pietro Perona, and Frederick Eberhardt. Visual Causal Feature Learning.
Technical Report arXiv:1412.2309, arXiv, June 2015. URL http://arxiv.org/abs/1412.
2309. arXiv:1412.2309 [cs, stat] type: article.

Krzysztof Chalupka, Tobias Bischoff, Pietro Perona, and Frederick Eberhardt. Unsupervised Dis-
covery of El Nino Using Causal Feature Learning on Microlevel Climate Data. Technical
Report arXiv:1605.09370, arXiv, May 2016a. URL http://arxiv.org/abs/1605.09370.
arXiv:1605.09370 [physics, stat] type: article.

Krzysztof Chalupka, Frederick Eberhardt, and Pietro Perona. Multi-Level Cause-Effect Systems. In
Proceedings of the 19th International Conference on Artiﬁcial Intelligence and Statistics, pages 361–
369. PMLR, May 2016b. URL https://proceedings.mlr.press/v51/chalupka16.html.
ISSN: 1938-7228.

10

Nelson Cowan. The magical mystery four: How is working memory capacity limited, and why?

Current directions in psychological science, 19(1):51–57, 2010.

Roberta Cucca. Spatial segregation and the quality of the local environment in contemporary cities.

In Handbook of Urban Segregation. Edward Elgar Publishing, 2020.

Adel Daoud and Devdatt Dubhashi. Statistical modeling: the three cultures. arXiv:2012.04570 [cs,

stat], December 2020. URL http://arxiv.org/abs/2012.04570. arXiv: 2012.04570.

Adel Daoud and Fredrik Johansson. Estimating treatment heterogeneity of international monetary

fund programs on child poverty with generalized random forest. 2019.

Adel Daoud, Felipe Jordan, Makkunda Sharma, Fredrik Johansson, Devdatt Dubhashi, Sourabh
Paul, and Subhashis Banerjee. Using satellites and artiﬁcial intelligence to measure health and
material-living standards in India. Technical Report arXiv:2202.00109, arXiv, December 2021.
URL http://arxiv.org/abs/2202.00109. arXiv:2202.00109 [cs, econ, q-ﬁn] type: article.

Mingyu Ding, Zhenfang Chen, Tao Du, Ping Luo, Josh Tenenbaum, and Chuang Gan. Dy-
namic Visual Reasoning by Learning Differentiable Physics Models from Video and Lan-
In Advances in Neural Information Processing Systems, volume 34, pages 887–899.
guage.
Curran Associates, Inc., 2021. URL https://proceedings.neurips.cc/paper/2021/hash/
07845cd9aefa6cde3f8926d25138a3a2-Abstract.html.

Peng Ding, Avi Feller, and Luke Miratrix. Randomization inference for treatment effect variation.
Journal of the Royal Statistical Society: Series B (Statistical Methodology), 78(3):655–671, 2016.

Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model
uncertainty in deep learning. In international conference on machine learning, pages 1050–1059.
PMLR, 2016.

Max Goplerud, Kosuke Imai, and Nicole E Pashley. Estimating heterogeneous causal effects of
high-dimensional treatments: Application to conjoint analysis. arXiv preprint arXiv:2201.01357,
2022.

Michael Greenacre. Compositional data analysis. Annual Review of Statistics and its Application, 8:

271–299, 2021.

Sander Greenland, Michael P Fay, Erica H Brittain, Joanna H Shih, Dean A Follmann, Erin E
Gabriel, and James M Robins. On causal inferences for personalized medicine: How hidden causal
assumptions led to erroneous causal claims about the d-value. The American Statistician, 74(3):
243–248, 2020.

Robins JM Hernán MA. Causal Inference: What If. Boca Raton: Chapman & Hall/CRC, 2020.

Günter J Hitsch and Sanjog Misra. Heterogeneous treatment effects and optimal targeting policy

evaluation. Available at SSRN 3111957, 2018.

Kosuke Imai and Marc Ratkovic. Estimating treatment effect heterogeneity in randomized program

evaluation. The Annals of Applied Statistics, 7(1):443–470, 2013.

Guido W Imbens and Donald B Rubin. Causal inference in statistics, social, and biomedical sciences.

Cambridge University Press, 2015.

Connor T Jerzak, Fredrik Johansson, and Adel Daoud. Estimating causal effects under image
confounding bias with an application to poverty in africa. arXiv preprint arXiv:2206.06410, 2022.

Jean Kaddour, Yuchen Zhu, Qi Liu, Matt J Kusner, and Ricardo Silva. Causal effect inference for

structured treatments. Advances in Neural Information Processing Systems, 34, 2021a.

Jean Kaddour, Yuchen Zhu, Qi Liu, Matt J. Kusner, and Ricardo Silva. Causal Effect Inference for

Structured Treatments. Advances in Neural Information Processing Systems, 34, 2021b.

Nathan Kallus. Deepmatch: Balancing deep covariate representations for causal inference using
adversarial training. In International Conference on Machine Learning, pages 5067–5077. PMLR,
2020.

11

Shiho Kino, Yu-Tien Hsu, Koichiro Shiba, Yung-Shin Chien, Carol Mita, Ichiro Kawachi, and Adel
Daoud. A scoping review on the use of machine learning in research on social determinants of
health: Trends and research prospects. SSM - Population Health, 15:100836, September 2021.
ISSN 2352-8273. doi: 10.1016/j.ssmph.2021.100836. URL https://www.sciencedirect.
com/science/article/pii/S2352827321001117.

Sören R Künzel, Jasjeet S Sekhon, Peter J Bickel, and Bin Yu. Metalearners for estimating heteroge-
neous treatment effects using machine learning. Proceedings of the national academy of sciences,
116(10):4156–4165, 2019.

David Lopez-Paz, Robert Nishihara, Soumith Chintala, Bernhard Scholkopf, and Leon Bot-
pages 6979–6987, 2017. URL https:

tou. Discovering Causal Signals in Images.
//openaccess.thecvf.com/content_cvpr_2017/html/Lopez-Paz_Discovering_
Causal_Signals_CVPR_2017_paper.html.

Christos Louizos, Uri Shalit, Joris M Mooij, David Sontag, Richard Zemel, and Max Welling. Causal
Effect Inference with Deep Latent-Variable Models. In Advances in Neural Information Processing
Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/
paper/2017/hash/94b5bde6de888ddf9cde6748ad2523d1-Abstract.html.

Alexander R Luedtke and Mark J van der Laan. Super-learning of an optimal dynamic treatment rule.

The international journal of biostatistics, 12(1):305–332, 2016.

Razieh Nabi, Joel Pfeiffer, Murat Ali Bayir, Denis Charles, and Emre Kıcıman. Causal inference in
the presence of interference in sponsored search advertising. arXiv preprint arXiv:2010.07458,
2020.

Xinkun Nie and Stefan Wager. Quasi-oracle estimation of heterogeneous treatment effects. Biometrika,

108(2):299–319, 2021.

Michael Oberst, Nikolaj Thams, Jonas Peters, and David Sontag. Regularizing towards causal
invariance: Linear models with proxies. In International Conference on Machine Learning, pages
8260–8270. PMLR, 2021.

Christopher J Paciorek. The importance of scale for spatial-confounding bias and precision of
spatial regression estimators. Statistical science: a review journal of the Institute of Mathematical
Statistics, 25(1):107, 2010.

Paavo Parmas and Masashi Sugiyama. A uniﬁed view of likelihood ratio and reparameterization
gradients. In International Conference on Artiﬁcial Intelligence and Statistics, pages 4078–4086.
PMLR, 2021.

Nick Pawlowski, Daniel C. Castro, and Ben Glocker. Deep Structural Causal Models for Tractable
Counterfactual Inference. arXiv:2006.06485 [cs, stat], October 2020. URL http://arxiv.org/
abs/2006.06485. arXiv: 2006.06485.

Judea Pearl. Causality. Cambridge university press, 2009.

Judea Pearl and Elias Bareinboim. External validity: From do-calculus to transportability across
populations. In Probabilistic and Causal Inference: The Works of Judea Pearl, pages 451–482.
2022.

Vikas Ramachandra. Causal inference for climate change events from satellite image time series

using computer vision and deep learning. arXiv preprint arXiv:1910.11492, 2019.

Rajesh Ranganath, Sean Gerrish, and David Blei. Black box variational inference. In Artiﬁcial

intelligence and statistics, pages 814–822. PMLR, 2014.

Paul R Rosenbaum and Donald B Rubin. The central role of the propensity score in observational

studies for causal effects. Biometrika, 70(1):41–55, 1983.

Paul R Rosenbaum, PR Rosenbaum, and Briskman. Design of observational studies, volume 10.

Springer, 2010.

12

Donald B Rubin. Causal inference using potential outcomes: Design, modeling, decisions. Journal

of the American Statistical Association, 100(469):322–331, 2005.

Bernhard Schölkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner,
Anirudh Goyal, and Yoshua Bengio. Towards Causal Representation Learning. arXiv:2102.11107
[cs], February 2021. URL http://arxiv.org/abs/2102.11107. arXiv: 2102.11107.

Uri Shalit, Fredrik D Johansson, and David Sontag. Estimating individual treatment effect: gen-
eralization bounds and algorithms. In International Conference on Machine Learning, pages
3076–3085. PMLR, 2017.

Koichiro Shiba, Adel Daoud, Hiroyuki Hikichi, Aki Yazawa, Jun Aida, Katsunori Kondo, and Ichiro
Kawachi. Heterogeneity in cognitive disability after a major disaster: A natural experiment study.
Science advances, 7(40):eabj2610, 2021.

T Westling and TH McCormick. Beyond prediction: A framework for inference with variational
approximations in mixture models. Journal of Computational and Graphical Statistics, 28(4):
778–789, 2019.

Kexin Yi, Chuang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Antonio Torralba, and Joshua B.
Tenenbaum. CLEVRER: CoLlision Events for Video REpresentation and Reasoning. Technical
Report arXiv:1910.01442, arXiv, March 2020. URL http://arxiv.org/abs/1910.01442.
arXiv:1910.01442 [cs] type: article.

Qingyuan Zhao, Dylan S Small, and Ashkan Ertefaie. Selective inference for effect modiﬁcation via

the lasso. arXiv preprint arXiv:1705.08020, 2017.

A Appendix

A.1 Supplementary Information for the Image-Type Probabilistic Models

A.1.1 Deriving the Conditional Distribution, Yi(1) − Yi(0)|Zi = z

Using the model outlined in §3.1, conditioning on τi, and exploiting Normality,

{Yi(1) − Yi(0) | Zi = z, τi} ∼ N (τi, σ2

0,z + σ2

1,z)

Integrating out τi:

p(Yi(1) − Yi(0) = di | Zi = z) =

=

(cid:90) ∞

−∞
(cid:90) ∞

p(Yi(1) − Yi(0) = di | Zi = z, τi) p(τi | Zi = z) dτi

(cid:113)

−∞

1
0,z + σ2

1,z)

2π(σ2

exp

(cid:26) −(di − τi)2
0,z + σ2
1,z)

2(σ2

(cid:27)

×

(cid:113)

1

2πσ2

τ,z

exp

(cid:26) −(τi − µτ,z)2
2σ2

τ,z

(cid:27)

dτi

=

(cid:113)

Therefore,

1
0,z + σ2

2π((σ2

1,z) + σ2

τ,z)

(cid:26)

exp

−(di − µτ,z)2
0,z + σ2

1,z) + σ2

τ,z)

2((σ2

(cid:27)

.

{Yi(1) − Yi(0) | Zi = z} ∼ N (cid:0)µτ,z, σ2

0,z + σ2

1,z + σ2
τ,z

(cid:1) .

A.1.2 Additional Modeling Details

The real representation of the uncertainties are all drawn from Gaussians with mean and variance
scaled indexed to z; the non-negativity of the variance is enforced through the softplus transformation
(where softplus(x) = log(1 + exp(x))).

13

A.2 Causal Regularization

In a simpliﬁed model where the distribution of each potential outcome, Yi(0) and Yi(1), is character-
ized by a Gaussian mixture with means µt,z for z ∈ {1, 2, ..., K}, Equation 2 can be made to hold
exactly through parameterization. In particular, we would like to solve:

Under this simpliﬁed model, (cid:98)τ (z) = (cid:98)µ1,z − (cid:98)µ0,z, so

(cid:80)K

z=1 (cid:98)τ (z)(cid:99)Pr(Z(M) = z) − (cid:98)τ = 0

(cid:80)K
((cid:98)µ1,z=1 − (cid:98)µ0,z=1)(cid:99)Pr(Z(M) = 1) + (cid:80)K

z=1((cid:98)µ1,z − (cid:98)µ0,z)(cid:99)Pr(Z(M) = z) − (cid:98)τ = 0

z=2((cid:98)µ1,z − (cid:98)µ0,z)(cid:99)Pr(Z(M) = z) − (cid:98)τ = 0

which implies

(cid:32)

(cid:98)µ0,z=1 = (cid:98)µ1,z=1 −

(cid:98)τ −

K
(cid:88)

z=2

((cid:98)µ1,z − (cid:98)µ0,z)(cid:99)Pr(Z(M) = z)

(cid:99)Pr(Z(M) = 1)−1.

(cid:33)

Thus, in some modeling contexts, the exact non-parameteric ATE can be recovered in the clustering
model by parametrization.

A.3 Simulation Details

Figure A.1: Illustration. In the center, we see the image pattern used in generating the heterogeneity
response in the simulation design of §4. In the left panel, we see an image having no regions of
strong similarity to the heterogeneity-generating pattern (leading to a low treatment effect); in the
right panel, we see an image with many regions of strong similarity to the heterogeneity-generating
pattern (leading to a high treatment effect).

14

Neighborhood with high similarity to heterogeneity-generating patternNo neighborhood of similarity to heterogeneity-generating pattern(cid:15)i

Mi

Yi(0)

Yi(1)

n

Figure A.2: Left panel. Stylized schematic depiction of the simulation model. Note that this model is
not the same as the probabilistic estimation model (i.e. we have some degree of misspeciﬁcation in
our probabilistic models).

Figure A.3: Illustration of the non-linear transformation used in the simulation in generating H +
i
from Hi.

Figure A.4: ATE recovery is improved with the two image-type cluster models ﬁt using the Model
ATE Equivalence Regularization Term.

15

−3−2−101232.53.03.54.04.5HiHi+0.010.050.200.500.00.10.20.30.4|ATE-ATE|Post−hoc ClusteringImage Type Differential EffectsImage Type Effect ClusteringScaling of Non−image  Residual VarianceA.4 Supplementary Analyses for the Application

A.4.1 Additional Data Description

Satellite data is obtained for the smallest geographic locality associated with a given experimental
unit. Place names were geo-referenced using OpenStreetMap data. When geo-referencing failed, we
use the geometric center for the layer associated with the geographic unit as our focal point for the
given unit. Satellite information was then obtained for a cube around focal points with side lengths of
5000 meters. For the skilled work outcome, we take the scaled sum of the log hours worked in the
last 7 days by experimental units in skilled or highly skilled trades.

A.4.2 Additional Analyses

Table 1: Correlation of estimated image cluster 1 probabilities with key tabular covariates.

Urban
Longitude
Latitude
Female indicator
Human capital score

Correlation
-0.27
0.31
-0.40
0.01
-0.01

A.5 Empirical Analysis with Orthogonalized Potential Outcomes

We orthogonalize outcomes by, in line with the original experimental analysis, ﬁtting a regression
model predicting the outcome using main treatment effects and interactions between treatment and
gender, treatment and baseline human capital, and treatment and baseline business capital (as well as
the main effect terms for the associated interaction). We ﬁnd a 0.88 correlation betweeh the cluster
probabilities using the orthogonalized and raw outcomes.

A.6 Model Implementation Details

In the implementation of our models using Bayesian CNN arms, we leave the number of hidden
layers, ﬁlter size, and so forth as parameters that can be set by investigators, although we seek to
keep the computational overhead low so as to increase the usefulness of these modeling strategies for
investigators having limited supercluster access.

In our application, we use four convolutional layers (ﬁlter size 3), separated by max pooling layers
(2×2). Each convolutional layer applies 96 ﬁlters. Bottleneck projection layers are used after each
convolutional layer, projecting the 96 dimensions down to 3 to keep the number of parameters
low. Batch normalization layers are used across the feature dimension before each projection or
convolution. The swish activation is used. We apply the Gumbel-Softmax to approximate the
random categorical sampling with inverse temperature set to 1. We set λ = 0.01. With this model
structure, each batch sample of 20 units takes about one second on a single Apple M1 GPU using
Metal-optimized tensorﬂow 2.8. The full simulations with 10 Monte Carlo iterations per design
setting take about 12 hours on this hardware.

16

Figure A.5: Location of the top 5 cluster 1 and 2 localities. A selection of the other experimental
units are displayed visually as well, with the color of the point related to the cluster probability.

Figure A.6: Images with most uncertainty in cluster probabilities from the main empirical analysis.

17

12345678910aLong: 32.77, Lat: 1.83bLong: 34.14, Lat: 3.57cLong: 31.39, Lat: 2.94dLong: 34.12, Lat: 3.02eLong: 31.59, Lat: 3.31Figure A.7: Top. High probability cluster 1 images using orthogonalized outcomes. Bottom. High
probability cluster 2 images using orthogonalized outcomes. Note that cluster labels are not identiﬁed
(so the cluster labels, “1” and “2”, should not be interpreted as meaningful).

Figure A.8: Location of the top 5 cluster 1 and 2 localities using the model ﬁt on tabular orthogonalized
outcomes. Correlation between cluster probabilities using the raw and orthogonalized outcomes is
0.88.

18

1Long: 33.76, Lat: 1.00t^1 ^ =-0.0332Long: 33.93, Lat: 1.433Long: 33.81, Lat: 1.474Long: 33.85, Lat: 1.255Long: 34.24, Lat: 3.686Long: 30.83, Lat: 3.11t^2 ^ =-0.0447Long: 34.12, Lat: 3.028Long: 31.46, Lat: 2.499Long: 33.01, Lat: 1.5210Long: 30.89, Lat: 3.0012345678910