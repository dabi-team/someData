6G-AUTOR: Autonomic CSI-Free Transceiver via Realtime On-Device
Signal Analytics(cid:63)

Shih-Chun Lina,∗, Chia-Hung Lina, K V S Rohita, Liang C. Chub

aIntelligent Wireless Networking Lab, Department of Electrical and Computer Engineering, North Carolina State University,
Raleigh, NC 27695, USA
bLockheed Martin Space Systems Company, Lockheed Martin Corporation

2
2
0
2

n
u
J

7

]
I

N
.
s
c
[

1
v
0
5
2
3
0
.
6
0
2
2
:
v
i
X
r
a

Abstract

Next-generation wireless systems aim at fulﬁlling diverse application requirements but fundamentally rely

on point-to-point transmission qualities. Aligning with recent AI-enabled wireless implementations, this pa-

per introduces autonomic radios, 6G-AUTOR, that leverage novel algorithm-hardware separation platforms,

softwarization of transmission (TX) and reception (RX) operations, and automatic reconﬁguration of RF

frontends, to support link performance and resilience. As a comprehensive transceiver solution, our design

encompasses several ML-driven models, each enhancing a speciﬁc aspect of either TX or RX, leading to

robust transceiver operation under tight constraints of future wireless systems. A data-driven radio man-

agement module was developed via deep Q-networks to support fast-reconﬁguration of TX resource blocks

(RB) and proactive multi-agent access. Also, a ResNet-inspired fast-beamforming solution was employed

to enable robust communication to multiple receivers over the same RB, which has potential applications

in realisation of cell-free infrastructures. As a receiver the system was equipped with a capability of ultra-

broadband spectrum recognition. Apart from this, a fundamental tool - automatic modulation classiﬁcation

(AMC) which involves a complex correntropy extraction, followed by a convolutional neural network (CNN)-

based classiﬁcation, and a deep learning-based LDPC decoder were added to improve the reception quality

and radio performance. Simulations of individual algorithms demonstrate that under appropriate training,

each of the corresponding radio functions have either outperformed or have performed on-par with the

benchmark solutions.

Keywords: Cell-free infrastructure, dynamic spectrum management, automatic modulation classiﬁcation,

intelligent radio, compressed spectrum sensing, LDPC decoder.

(cid:63)This work was supported by Lockheed Martin Space Systems Company, Lockheed Martin Corporation.
∗Corresponding author
Email addresses: slin23@ncsu.edu (Shih-Chun Lin), clin25@ncsu.edu (Chia-Hung Lin), vkanthe@ncsu.edu (K V S

Rohit), liang.c.chu@lmco.com (Liang C. Chu)

Preprint submitted to Ad Hoc Networks

June 8, 2022

 
 
 
 
 
 
1. Introduction

6G and beyond will provide global coverage and ubiquitous wireless services [1] by meeting strict per-

formance requirements for diverse industry verticals. As we move towards the higher generation standards,

communication constraints become more stringent. Also, with data-hungry applications breaking the bar-

riers between physical and virtual domains, it is imperative to develop innovative solutions that go beyond

merely utilizing data-driven approaches, built for solving speciﬁc communication tasks, for achieving superior

performance. Emerged AI/machine learning techniques or data-driven approaches, which can intelligently

manage wireless architectures, protocols, and operations through learning from sensory inputs will become

a promising enabler in the future. Notably, the European Telecommunications Standards Institute (ETSI)

initiated two industry speciﬁcation groups, experiential networked intelligence, and zero-touch network and

service management, working on closed-loop AI mechanisms for network supervisory assistant systems and

virtualized network operation automation without human intervention respectively. O-RAN ALLIANCE [2]

also commits to evolving wireless networks towards more open and smarter deployments by employing

similar technologies for autonomous networking and self-management.

Similarly, at PHY and MAC layers, there is a need to introduce Intelligent Radios [3] which enable re-

altime frontend reconﬁguration, and providing protection based on service requirements and environmental

conditions. Such intelligent autonomic radios employ algorithm-hardware separation to cater to the ever-

advancing hardware landscape. This is augmented with the data-driven machine learning models that can

replicate diﬀerent transceiver functions, so that pre-trained models replace the complex signal processing

involved to realize the same functions. An advantage of data-aided function replication is that the transmit-

ters and the receivers no longer need to determine the channel state information (CSI) or reference signals

(RS) during the whole process. Avoidance of CSI and RS signals provides an added computational beneﬁt

by eliminating the excessive overhead, compared to the traditional radio systems, that heavily rely on CSI

and RS for successful communication.

In line with the above requirement, in this paper, we propose an intelligent autonomic radio, 6G-AUTOR,

which employs the notion of incorporating algorithm-hardware separation into its design, where algorithms

themselves are modelled to be data-driven in nature. We introduce an AI-layer into the transceiver struc-

ture, which acts as an on-device repository to all machine learning models that are implemented on the

radio. Figure 1 shows a high level view of the transceiver working in half-duplex mode, where it will have

either of the transmission circuit or the receiver circuit active at a given time. Depending on the mode of

operation: transmission or reception, diﬀerent ML-models will be activated in the AI layer. Speciﬁcally,

our transceiver utilizes ML-enabled dynamic spectrum access to detect and identify suitable resource blocks

during transmission. During reception, it uses a deep learning (DL)-based compression spectrum sensing,

feature-based automatic modulation classiﬁer that employs a convolutional neural network (CNN) and yet

2

(a) Proposed transceiver as a transmitter

(b) Proposed transceiver as a receiver

Figure 1: Intelligent Transceiver with a modular AI layer.

another DL-based low-density parity-check (LDPC) decoder. Each algorithm that is developed to be a part

of the AI-layer has a dedicated function and is independent of other algorithms. For example, an automatic

modulation classiﬁcation block only interacts with the baseband data obtained from the receiver hardware,

and informs its classiﬁcation decision to the demodulation block. And it would not have any inﬂuence on

other functionalities of the radio, say, spectrum sensing. Similarly, several such disjoint algorithms can be

deployed on the common AI-layer, in order to replace complex signal processing functions with ML-based

solutions.

1.1. Algorithm-Hardware Separation

With the evolution towards 6G, the network deployments will get vastly dense and much more hetero-

geneous than existing infrastructures [4]. Aligning with this development, the underlying hardware cannot

aﬀord to remain quasi-static as with current standards [3]. The hardware-software co-design that is in use

today, cannot cater to such stringent requirements of the future.

In this light, there have been several

innovative approaches for increasing the eﬃciency of the hardware through advancements in MEMS/NEMS

technologies [5], and by using AI-enabled solutions [6].

Algorithm-hardware separation is an attempt to break free from the hardware-software co-design ap-

proach that has dictated the telecommunication development since its inception. This paradigm shift enables

in building systems that can undergo self-reconﬁguration based on the hardware capabilities. This results

in the building systems that are robust to changing underlying hardware, by being able to reconﬁgure the

software behaviour accordingly, automatically. Authors in [7] have recently proposed such an mechanism

to incorporate this novel approach into Internet of Vehicles security frameworks, where the emphasis was

on identifying hardware capabilities through iterative testing and machine learning-based decision making

process.

3

Our transceiver is built to support this algorithm-hardware separation, owing to the capability to dy-

namically reconﬁgure any data-driven module in real time. Each of the machine learning components, as

discussed in subsequent sections, consist of pre-trained neural network models, which are then deployed onto

the device for real-time inference. Due to this property, any modiﬁcation in the algorithms is as simple as

updating the model parameters in the AI layer.

1.2. Relevance to State-Of-The-Art

In our work, we propose real-time reconﬁgurability in radios by employing machine learning-based mod-

els to replicate RF functions, thereby creating a ﬂexibility of updating/upgrading the models dynamically.

This approach aligns with several promising technologies that are well investigated in the development of

5G and beyond systems, such as: dynamic spectrum management, cell-free communications and automatic

modulation classiﬁcation. For example, following the O-RAN structure presented in [2], in cell-free commu-

nications, several Open Distributed Units (O-DUs) (i.e., access points (APs) in 5G systems) controlled by a

Open Central Unit (O-CU) (i.e., central processing units (CPUs) in 5G systems) will be deployed to serve

users in a geographic coverage area using the same time-frequency resources coordinately as shown in ﬁgure

2, through appropriate dynamic spectrum management. As there are no cells and hence no boundary eﬀects

or handover issues, seamless connectivity with reduced transmission overheads can be provided to more users

compared to conventional cellular communications. Moreover, to support numerous users simultaneously,

static radio spectrum management approach to pre-allocate frequency resources to users is not practical

anymore [8]. Alternatively, dynamic spectrum management must be considered to maximize the spectrum

utilization rate by exploiting the occasionally idle spectrum. By doing so, it is plausible to support million

users with data-hungry applications in a geographic coverage area using the same time-frequency resources.

And this can be done computationally eﬃciently by utilizing the machine learning models to identify suit-

able resource blocks for transmission and reception. Automatic modulation classiﬁcation can then be used

at the receiver to classify the data into correct modulation type, without any CSI/RS exchange. As a

means to increase the end-to-end communication robustness, forward error correction may also be included

to compensate for any errors the wireless channel would have caused.

Also, with recent developments in 3GPP Standard Release 17, a new type of communication use case was

established: New Radio-Reduced Capacity or NR-RedCap device. This acts as an aggregate of 5G’s primary

use cases: eMBB, URLLC and mMTC, with certain relaxations such as tolerances to higher latencies, lower

throughputs and lower bandwidths [9]. RedCap devices are aimed towards an implementation primarily in

the ﬁeld of internet of things (IoT), wearables and video surveillance, where the maximum device bandwidth

is set at 20 MHz, minimum number of antennas is 1 and latency can extend to as high as 500ms (for video

surveillance only). Our proposed smart transceiver has automation built into it through machine learning

model-based inferences, where the models themselves were trained oﬄine. Since neither the model training

4

Figure 2: The considered cell-free communication system with dynamic spectrum management in Internet of battleﬁelds

scenarios. An O-CU controls multiple O-DUs in a geographic coverage area; an O-DU serves many users using the same

time-frequency resources for massive machine type communications.

nor complex signal processing occur on the receiver, our transceivers, even with single-input-single-output

(SISO) antenna conﬁguration, can be expected to work conveniently as a RedCap device.

Apart from civilian applications, our system aligns quite well with the tactical communication require-

ments as well. Considering the Internet of Battleﬁeld Things (IoBT) scenarios [10], the proposed transceiver

also can play an essential role to realize command, control, communication, and intelligence systems (C3I)

in a real-time manner. First, practical IoBT scenarios may have no ground infrastructure in the ﬁeld, which

makes them suitable for cell-free communications by employing unmanned aerial vehicle as temporal com-

munication infrastructure to serve soldiers and vehicles. Second, military actually owns and shares many

spectrum resources with the commercial market. The proposed spectrum recognition module can be used

to provide a non-interfering resource block to match the needs for military usages (when used inside a trans-

mitter). Third, the proposed receiver designs can even be used to perform blind eavesdropping attack to

obtain information from enemies without any prior knowledge [11]. Automatic modulation classiﬁcation is

a highly investigated topic for military applications with research in this ﬁeld aging greater than 2 decades.

Recently, the Department of Defense (DoD) announced $600 million in awards for B5G experimentation

and selected Hill Air Force Base in Utah to realize dynamic spectrum utilization. In March 2022, the DoD

has released a Request for Solutions contract that can provide solutions to addess the DoD Tactical Net-

work operations in the presence of 5G network infrastructure [12]. The DoD has also built prototypes to

test out dynamic spectrum management, by the acronym OSCAR (Operational Spectrum Comprehension,

Analytics and Response), in 5 aerial combat training ranges, to enable ﬂight emulation training [13]. These

snippets show case the importance of the concepts incorporated in this paper, in terms of their relevance to

state-of-the-art implementations in civilian and military applications.

5

(a) Transmitter with components displayed

(b) Receiver with components displayed

Figure 3: Intelligent Transceiver block diagram in detail.

1.3. System Model

Having introduced the our intelligent autonomic radio structure earlier, this section provides more in-

sights into the speciﬁcs of transmitter and receiver functions and the objectives we aim to achieve through

such an implementation. Figure 3 provides a detailed description of diﬀerent components involved in the

TX and RX modes of operation shown earlier in ﬁgure 1. As seen here, the AI-layer hosts diﬀerent models

during transmission and during reception. These data-driven models either augment the signal processing

tasks by eliminating large computation overheads or provide inferences that eliminate the need for certain

modules completely. In this section, we give a high level overview of diﬀerent data-driven functionalities

that our transceiver is capable of, which are detailed in subsequent sections.

When the transceiver acts as a transmitter, it follows the following data-ﬂow: (1) Obtains data from

higher layers, (2) process it to create a bit stream, (3) perform LDPC channel encoding, (4) modulate the

coded bits to create symbols, (5) symbols are passed to the RF frontend, where the DIRM (data-driven

intelligent resource management) module provides the resource block information for physical transmission,

(6) data is sent out using antennas.

6

When the transceiver acts as a receiver, the following operations occur: (1) data is captured using the

antenna, (2,3) it is then sent into the IUBR (intelligent ultra-broadband recognition) module, to perform

compressive spectrum sensing and reconstruct the original signal, along with identiﬁed carrier frequency, (4)

demodulation block performs a complex correntropy feature extraction on the reconstructed data, (5) AMC

(automatic modulation classiﬁcation) module takes the correntropy values and gives out the modulation

class as the output, (6) this is followed by a demodulation of based on the classiﬁcation result, and the

data is sent to the LDPC decoder (7) LDPC decoder provides relevant parameters to decoding, (8) decoder

performs the iterative decoding using a neural network decoder, and ﬁnally (9,10) the resulting message bits

are sent to higher layers after appropriate formatting.

It has to be noted that, there are few other components such as the matched ﬁltering, and synchronization

blocks were not displayed on the transceiver block diagram, but are an integral part of actual communication

realization.

Through this paper, we intend to contribute an intelligent autonomic radio which -

• incorporates a dedicated AI layer, which can host multiple machine learning models and can toggle

them from active to inactive state, depending on the mode of operation,

• showcases the capability to incorporate dynamic spectrum management and cell-free architecture by

leveraging the eﬀorts of data-driven, sometimes in conjunction with optimization-driven approaches,

to achieve high quality performance,

• builds machine learning based-algorithms to augment the complex processing overhead involved in

automatic modulation classiﬁcation and forward error correction using LDPC channel coding and

• adheres algorithm-hardware separation principles by enabling the aforementioned data-driven algo-

rithms to be reconﬁgurable in real-time.

The remaining article is structured as follows: Section 2 presents a solution for cross-layer resource

management problem to identify suitable resource blocks in multi-agent communication setup (DIRM).

Section 3 provides a means to sense the environment using compression spectrum sensing, which can be

utilized both on the transmitter and the receiver (IUBR). Section 4 elaborates on the ability to automatically

classify the received data into appropriate modulation schemes using feature extraction and CNN-model

classiﬁcation (AMC). Section 5 covers a mechanism to estimate the decoding parameters of the iterative

LDPC scheme to recover errors introduced by a wireless channel (LDPC-DL). Finally, in the last section,

we conclude our system design and provide next steps for future work.

7

2. Data-driven Intelligent Radio Management for Proactive Multi-Agent Access

We present our transmitter design for distributed cross-layer resource management for next generation

multi-agent communications.

2.1. Automatic Reconﬁguration and Access

Resource sensing and selection are two prerequisite steps in conventional multi-agent access, and re-

source selection can perform purely in a distributed manner based on the sensing results. The current 5G

speciﬁcation still relies on centralized management that collects all sensory information from devices [14],

signiﬁcantly limiting latency-strict applications. Our objective is to address the cross-layer resource man-

agement problem, where users employ distributed resource management without heavy overheads from a

centralized infrastructure.

Assuming that there are k ∈ {1, ..., K} users forming K/2 transceiver pairs in a virtual cell. Based on

the half-duplex assumption, we take that, at time slot t, half of the users will act as transmitters, and the

other users will act as receivers to perform one-side data transmission. At the next time slot t + 1, the

original receiver will become the transmitter and vice versa. At each time slot, all transmitters need to

choose a resource block (RB) from m ∈ {1, ..., M } RBs in the resource pool and decide on a transmit power

to maximize the sum rate of the virtual cell. To avoid the resource sensing process, each user is expected to

ﬁnish the above resource management distributively without knowing what the other users are choosing.

Considering user k(cid:48) that receives data from user k using RB m at time t, the signal-to-noise-plus-

interference-ratio (SINR) can be expressed as

Γk(cid:48)[m, t] =

w[m]σ2 + (cid:80)

P k[m, t] × ||hk

k(cid:48)[m, t]||2
i(cid:54)=k P i[m, t] × ||hi

k(cid:48)[m, t]||2

,

(1)

where h[m, t] is the channel eﬀect, w[m] is the bandwidth of the RB, and P k[m, t] stands for the transmit

power of transmitter k. Following 5G standards, the modulation and coding scheme will be decided according

to Γk(cid:48)[m, t]. Hence, the spectrum eﬃciency SE[m, t] of RB m at time slot t can also be inferred. The user-
plane received data bits of this pair can be computed as rk[t] = N data

sym [m, t] × SE[m, t], where N data

sym [m, t] is

the number of symbol in RB m at time t.

To maximize the sum rate of all transceiver pairs, we formulate multi-agent radio resource management

8

as the following optimization problem:

Find: I k[m, t], P k[m, t], ∀k

Maximize

(cid:88)

k

Subject to 0 ≤

rk[t]

M
(cid:88)

m=1

I k[m, t] ≤ 1, ∀k

M
(cid:88)

m=1

P k[m, t] ≤ Pmax, ∀k

(2a)

(2b)

(2c)

(2d)

Indicator function I k[m, t] ∈ {0, 1} describes user k’s selection of RB m at time t for communications.

Equation (2c) implies that a transmitter can only select one RB at any given time. Equation (2d) describes

that each user’s transmit power cannot exceed a pre-deﬁned power level.

2.2. The Data-Driven Intelligent Radio Management (DIRM)

We develop a reinforcement learning-based resource management strategy to solve the above optimiza-

tion. Each user can be regarded as an edge learner (i.e., agent) to learn how to choose RB and transmission

power autonomously, based on local observation to maximize the sum rate of the virtual cell. With the

network slicing ﬂexibility provided by software-deﬁned platforms (e.g., [15]), centralized training can be

conducted without any implementation issues. Well-trained weights can then be deployed in each user to

perform distributed radio resource management concurrently.

To employ reinforcement learning-based algorithm, we need to deﬁne the state, action, and reward

function to describe the interested problem as a Markov decision process ﬁrst. We have the state space with

local observation as:

st = {I k

T x[t], gk

Rx[t − 1], ˇgk

Rx[t − 1]} ∀k,

(3)

where I k

T x[t] ∈ {0, 1} is an indicator function that deﬁnes whether user k acts as a transmitter at time slot

t, gk

Rx[t − 1] and ˇgk
For the action space, each user should make decisions on RB and transmit power selections. Particularly,

Rx[t − 1] are the received power and interference power at the RB at time slot t − 1.

when a user acts as a receiver, it should choose a dummy RB to receive information. Also, we consider a

discrete power-level pool P = [−100, 5, 15, 23] for transmit power selection to ﬁx action space of each agent

with dimension (M + 1) × |P|. Finally, as for the reward design rt at time t, the sum of spectrum eﬃciency

is set as a reward. The single time slot reward can be extended to the reward of an episode by considering

discounted future reward factor γ, i.e.,

Total Reward =

T
(cid:88)

t=t(cid:48)

γt−t(cid:48)

rt.

9

(4)

To approximate the continuous state and infer the corresponding action to maximize the ﬁnal reward,

various NN-based approaches are available, such as wire-ﬁtter, deep Q-networks (DQN) and the novel

double Q-networks in [16]. To avoid overestimating future rewards, we employ the double Q-networks in

our algorithm.

A common approach to constructing the edge learner is to use Q-learning. Each edge learner will have

an independent DQN to be trained. Also, a target network (i.e., an accompanying neural network with the

same architecture as DQN) will be used in the training process of all edge learners. Moreover, we provide

ot = {st, (cid:15), e} as observations to edge learner to avoid non-stationary problems during training [17]. e is the

training episode number, and (cid:15) is the probability of random action selection. We obtain the best policy for

distributed radio resource management by updating each DQN’s weights with

rclQn(on

t , an

t ; θn) ← Qn(on

t , an

t ; θn) + α[yt − Qn(on

t , an

t ; θn)],

(5)

where yt = rt + γmaxa(cid:48)Qn(on

t+1, a(cid:48)

t; θn(cid:48)).

In Equation (5), each edge learner has a separate DQN Qn

parameterized by θn and a target DQN by θn(cid:48); both should be trained using this updating equation. Besides,

each agent maintains a memory buﬀer D in which they store the tuple ({on

t }, an

t , rt, {on

t+1}) to reuse the

training samples. Also, the popular (cid:15)-greedy based action selection with linear annealing mechanism is

employed to facilitate the training process. We summarize the entire DIRM of these centralized training

and distributed execution in Algorithm 1.

2.3. Numerical Results

We choose vehicular communications (5G NR mode 2) [14] given that vehicular communications are

often with more strict latency constraints. We adopt a well-known Manhattan grid model and use SUMO

[18] to generate realistic trajectories of vehicles to evaluate sidelink communications performance. The

SUMO step-size is set as 0.1 s, the maximum vehicle speed is 45 miles/hour, and other parameters are

listed in Fig. 4a. We use the urban path loss model and shadowing with 5.9 GHz band in Table 5.2.1-1

in [14]. We employ DQN hidden layers with the neuron numbers of 400, 200, and 150. We consider tanh

activation function, RMSProp optimizer with learning rate 1e−4, buﬀer size = 25, 000, mini-batch size =
200, discount factor γ = 0.995, target update counter ˆtup = 5, (cid:15)max = 1, (cid:15)min = 0.2, and 5, 000 training

episodes. The proposed DIRM is compared with the following schemes: Brute Force (Benchmark): a

centralized controller needs to perform an exhaustive search in all possible combinations of the RBs and

power allocations to ﬁnd the best pairs of actions that provide the best sidelink throughput. That is,
[(M + 1) × |P|]U = (4 × 4)6 = 16, 777, 216 possible combinations should be computed in each step. While

5G NR mode 2 does not expect any centralized controller, we have the controller in this optimal case to

provide the benchmark performance. Random Access (Naive Baseline): in the random action selection,

each agent chooses its action randomly from its possible action space of O((M + 1) × |P|).

10

Algorithm 1: Data-Driven Intelligent Radio Management (DIRM).

Input : Reward ri, action-value functions {Qn(·)}, minibatch size B, target networks updating

frequency Tup, annealing parameter δ.

Output: Access policies an

T +1 for all 1 ≤ n ≤ N .
1 compute annealing rate ξ = (τmax − τmin)/δT .

2 %% Deep reinforcement learners for proactive access.

3 initialize Q networks θn for all 1 ≤ n ≤ N randomly.

4 for i = 1 to T do

5

6

7

8

9

10

11

12

13

14

15

16

17

18

compute τ = max{τmin, ξT }.

for n = 1 to N do

observe the environment state si for on
i .
i = 1{τ ≤¯τ } argmaxa Qn(on
select an

i , a; θn)+ 1{τ >¯τ }U({an

i }) with uniform function U(·).

end

execute ai = ({an
observe state si+1 for on
store ({on

i }) and obtain ri and si+1.
i+1 for all 1 ≤ n ≤ N .
i+1}) in replay buﬀer D.

i }, ai, ri, {on

for n = 1 to N do

sample a random minibatch of B samples ({on

j }, aj, rj, {on

j+1}) from D.

set yj = rj + γ maxa(cid:48) Qn(on
update θn by minimizing the loss L(θn) = 1
B
n for every Tup as: θ(cid:48)
update target network θ(cid:48)

j+1, a(cid:48); θ(cid:48)

n).

(cid:80)
j
n ← θn.

(cid:0)yj − Qn(on

j , aj; θn)(cid:1)2

.

end

19 end

11

Manhattan grid

300m×200m

(with two-way streets)

Number of vehicles; vehicle speed

6; 45mph

Vehicle antenna height and gain

1.5m; 3dBi

Vehicle noise ﬁgure

Maximum vehicle association

9dB

400m

Number of RBs; RB bandwidth

3; 180kHz

Transmitted power proﬁle

{-100, 5, 15, 23}dBm

Noise power

Received SINR margin

-114dBm/Hz

(-5, 40)dB

Transmission time slot

1ms

(a) Vehicular environment setup.

Brute Force

(Benchmark)

DIRM

Random

Access

Testing duration

100 episodes = 100s

Data rates per vehicle pair

685Kbps

665.5Kbps

280Kbps

Collision rate

Link failure rate

0%

0%

0.7%

0.4%

31.9%

16.6%

(b) Multi-agent radio management.

Figure 4: Average system performance for vehicle PC5 sidelink.

Since the proposed distributed method examines vehicle PC5 sidelink without inheriting any carrier

sensing, we show its eﬀectiveness by showing total link collisions and failures. Fig. 4b shows the average

collision and link failure rates with 100 test episodes and ﬁxed SINR threshold Γmin = 10 dB. Brute

Force algorithm provides the performance upper bounds, i.e., the best average data rates and no collisions

or link failures during testing via time-demanding resource sensing and consequent centralized resource

management. The DIRM’s performance is very close to the optimal results no matter which performance

indicators. Our distributed algorithm does not access the information obtained from resource sensing, more

practical than the benchmark. Also, without sensing-information enhancement, Random Access gives

poor performances in all performance metrics, validating the superiority of our DIRM design.

3. Intelligent Ultra-Broadband Recognition (IUBR)

This section describes the proposed intelligent spectrum recognition algorithm, which can be used in

both transmitters and receivers to support cell-free communication with dynamic spectrum management.

Assuming that Ns subcarriers can be used for wireless data transmission in a geographic coverage area.

The goal of spectrum recognition is to identify occupy status of each subcarrier. As a result, receivers

can perform spectrum recognition to identify the subcarriers for following operations, such as automatic

12

modulation classiﬁcation, to receive information from transmitter successfully.

To realize eﬀective spectrum recognition, a straightforward way is performing Nyquist sampling to check

the signal power of each subcarrier. However, due to the wideband nature of B5G communication systems

(i.e., sub6GHz, mmWave, and THz bands), performing Nyquist sampling requires high-end ADC and large

volume storage to support extremely high sampling rate (may up to several THz) and consequent sampling

data, which is impractical for most communication scenarios. Alternatively, compressed sensing technique

can aid the on-device spectrum management by lowering the sampling rate signiﬁcantly. Speciﬁcally, the

compressed sensing mechanism can be divided into two parts: signal compression and signal reconstruction.

In the signal compression stage, original spectrum signal with size as Ns × 2 (i.e., real part and imaginary

part) will be condensed as under-sampled measurements with size as Nm × 2 by designing a sensing matrix

with the size as Ns ×Nm, where Nm << Ns. Then, in the signal reconstruction stage, a signal reconstruction

algorithm will be developed to reconstruct the original spectrum signal based on the above under-sampled

measurements. By doing so, the requirements of ADC and storage can be alleviated as only under-sampled

measurements should be obtained to perform the spectrum recognition.

3.1. Proposed Algorithm

Although compressed sensing technique can aid the spectrum recognition process, conventional recon-

struction algorithms often contain time-consuming iterations with remarkable computing complexity, being

not suitable for the considered on-device scenarios. Alternatively, DL-based reconstruction algorithms are

proposed, designing a function to map the under-sampled measurements to the corresponding original spec-

trum. However, we notice that existing DL-based solutions only focus on the reconstruction part of the

compressed sensing framework, employing random projections to generate under-sampled measurements

and casing consequent performance bottleneck.

We present our end-to-end solution [19] to perform joint design of signal compression and signal recon-

struction stages, providing superior performance compared to existing DL-based algorithms. The compres-

sion module contains a specially-designed layer to produce under-sampled measurements by making the

trainable weights act as the content of sensing matrix. Then the under-sampled measurements will be fed

into the reconstruction module for signal reconstruction.

There are two features of the proposed algorithm. First, one-dimensional fully convolutional neural net-

works are employed to perform eﬃcient compression and reconstruction. Due to the weight sharing property

of convolutional neural networks, the amount of trainable parameters is reduced signiﬁcantly compare to

conventional neural network to perform real-time spectrum analytics. Second, we introduce an end-to-end

learning framework to supervise the compression module. This enables designing a structured sensing ma-

trix in contrast to the random projection-sensing matrix employed in existing methods (i.e., unstructured

sensing matrix), for achieving better performance. Also, using this approach, as the compression module

13

GAN [20]

Proposed

sub6 GHz

THz

sub6 Ghz

THz

Machine learning performance metrics

MSE

0.0685

0.0187

0.0026

9.61e-04

Cosine Similarity

0.3370

0.4394

0.9951

0.9908

SSIM

0.3033

0.6289

0.8523

0.9386

Communication performance metrics

Pd

Pf

2.47e-04

0.0622

0.9

0.9449

0

2.68e-04

2.6e-04

0.0014

Table 1: The achieved performance is with SNR = 30 dB and compression rate = 0.125.

and the reconstruction module are presented as a joint end-to-end learning framework, the functionality of

the compression module can be evaluated by the overall reconstruction error (i.e., loss function). By doing so

using commonly used algorithms, such as backpropagation, we are able to adjust the trainable parameters in

the whole framework (both compression and reconstruction modules), to minimize the reconstruction error,

thereby realizing a dedicated design for sensing matrix. Consequently, as more informative under-sampled

measurements can be generated by the above design, the neural network architecture can be simpliﬁed to

enable fast on-device spectrum analytics.

3.2. Simulation Results

Here, we present the performance comparison between the proposed algorithm and state-over-the-art

generative adversarial network (GAN)-based spectrum recognition method [20]. We choose vehicular en-

vironment to test out the spectrum recognition methods. The continuous trajectories of vehicles are gen-

erated via SUMO transportation simulation platform [18] and each vehicle will perform vehicle-to-vehicle

or vehicle-to-infrastructure communications occasionally by building wireless connections on available sub-

carriers. Note that the considering simulations are challenging as the number of occupied subcarriers and

the power of built connections may vary signiﬁcantly according to the realistic trajectories generated from

SUMO platform. We ran the simulations on both sub6GHz and THz bands to demonstrate the eﬀectiveness

of the proposed algorithm. As shown in Fig. 1, the proposed algorithm outperforms GAN-based algorithm

in both machine learning performance and communication performance metrics, irrespective of the chosen

frequency band. Note that the proposed algorithm can oﬀer high detection rate and low false alarm rate

even in the scenario with high compression rate, making it a strong candidate for our use case.

14

4. Automatic Modulation Classiﬁcation (AMC) with Asynchronous Frontends

We propose an on-device AMC algorithm for smart receiver operations, which can detect modulation

schemes in practical asynchronours systems.

4.1. Time, Frequency, and Phase Oﬀsets

Considering a point-to-point communications system, the received signal r(t) can be expressed as

rclr(t) = h(t)

+∞
(cid:88)

j=−∞

ajg(t − jT0 − (cid:15)T0) + v(t),

(6)

where g(t) is the raised cosine ﬁlter, T0 the symbol period, h(t) the channel eﬀect, aj the transmitted symbol,

(cid:15)T0 ∈ [0, T0) the time oﬀset at the receiver, and v(t) ∼ S(α, β, γ, ξ) the additive noise following alpha-stable

distribution. α denotes the characteristic exponent, β the symmetry parameter, γ the dispersion parameter

similar to the variance in Gaussian distribution, and ξ the location parameter similar to the expectation in

Gaussian distribution. Furthermore, the channel eﬀect can be expressed as h(t) = Aej(wt+θ), where A > 0 is

the channel amplitude, θ ∈ [−π, π) the channel phase including both the channel phase and residual phase

oﬀset, and w the frequency oﬀset at the receiver. This alpha-stable distribution noise can model natural or

artiﬁcial impulsive noise, which is ignored in Gaussian noise. The Gaussian noise can be recognized as a

particular case of our considered alpha-stable noise.

Our goal is to develop a data-driven algorithm that automatically recognizes correct modulation type of

transmitter signals based only on the received asynchronous signal r(t) (having time, frequency and phase

oﬀsets) without prior knowledge. Assume perfect sampling is conducted on the aforementioned received

signal. Fig. 5 shows the constellations of diﬀerent signal modulations.

4.2. Low-Complexity On-Device Classiﬁer (LOC)

We develop a low-complexity modulation classiﬁer for on-device inference. Although conventional deep

learning algorithms can directly perform feature extraction, the required computation prohibits on-device

AI from executing such procedures. As an alternative, in the developed modulation classiﬁer, we conduct

feature extraction on the received data, through a cyclic correntropy calculation. This helps in generating

discriminating features for each modulation and at the same time, suppress non-Gaussian noise induced

from the channel. This dedicated pre-processing design is followed by a convolutional neural network that

can classify the discriminating features into appropriate modulation schemes.

For the cyclic correntropy pre-processing stage, a complex Gaussian kernel κσ is deﬁned such that,

κσ(r(t) − r(t + τ )) =

√

1
2πσ2

e− 1

2σ2 (r(t)−r(t+τ ))(r(t)−r(t+τ ))∗

.

15

(a) BPSK constellation.

(b) QPSK constellation.

(c) 8PSK constellation.

(d) 16QAM constellation.

Figure 5: Asynchronous oﬀsets on modulation constellations.

We then deﬁne the complex correntropy function Vr(t, τ ) as

(cid:104)
Vr(t, τ ) = E

κσ

(cid:0)r(t) − r(t + τ )(cid:1)(cid:105)
1
2πσ2

e− 1

,

(cid:104)
= E

√

2σ2 (r(t)−r(t+τ ))(r(t)−r(t+τ ))∗ (cid:105)
.

(7)

(8)

where E[·] is the expectation operator, σ denotes complex Gaussian kernel size. To deal with discrete-time

constellations after sampling, we can compute the discrete-version complex correntropy function by

V [m] =

(cid:80)N

n=m e− 1

2σ2 (x[n]−x[n−m])(x[n]−x[n−m])∗
√

(N − m + 1)

2πσ2

.

(9)

This completes the preprocessing and feature extraction, and the results will be used for ﬁnal modulation

classiﬁcation.

Since the feature sets obtained above are one dimensional sequences, a 1D-convolutional neural network

is a good ﬁt for such a dataset. We employed a Conv1D model from the TensorFlow library [21] to create

a 1D-CNN model and train it using synthesized data. The network consisted of two convolution layers,

followed by an average pooling layer to decrease the dimension of the features, and ended with a dense

layer which invoked a softmax operator on its input. The softmax operation results in an estimation of the

probability of the message belonging to a particular modulation class. For an input message y, if ˆy is the

predicted output, then the the loss function E was calculated and network parameters were updated using

stochastic gradient descent and backpropagation.

E = −

(cid:88)

(cid:88)

n

m

ynm log ˆynm,

16

Initial phaseOffset rotation11-1-1Modulus lengthInitial phaseOffset rotation11-1-1Modulus length-0.707-0.7070.7070.707Modulus lengthInitial phaseOffset rotation0.7070.707-0.707-0.707-1-111Modulus length1-11-1-33-33Initial phaseOffset rotationwhere m is a numerical (integer) representation of modulation class, and n represents the nth the training

set.

We summarize the whole LOC training process in Algorithm 2.

Algorithm 2: Low-Complexity On-Device Classiﬁer (LOC).

Input : Received I/Q data, i.e., I = {I1, I2, · · · , Im} and Q = {Q1, Q2, · · · , Qm}, m = 10000.

Output: Signal modulation scheme {ˆzi; 1 ≤ i ≤ m}.

1 %% Complex correntropy feature extraction.

2 set kernel σ and length l of complex correntropy features for modulation schemes (e.g., l = 2000).

3 for i = 1 to l do

4

5

Y1 = Y (1 : m − i + 1) = {y1, y2, · · · , ym−i+1} and Y2 = Y (i : m) = {yi, yi+1, · · · , ym}, where

Y = I + jQ = {y1, y2, · · · , ym}.
compute complex correntropy V [i] = 1

m−i+1

(cid:80)m−i+1
n=1

κσ(Y1[n] − Y2[n]), where κσ(·) is a

Gaussian kernel.

6 end

7 %% Identify the modulation scheme via 1D-CNN.

8 initialize weights W (0) and biases b(0) randomly.

9 for i = 1 to T do

10

compute the ﬁrst convolutional layer with input V and output C1, and the second

11

12

13

14

convolutional layer with output C2 and kernel size 100 via the forward-propagation method.

compute the pooling layer with output Cp by averaging C2, and the dense layer with output
K\1Cd and total K of modulation schemes.

get predicted output ˆzi = argmax1≤k≤K Pk for all 1 ≤ i ≤ m via a softmax classiﬁer with
normalized likelihood Pk = eCd[k]/ (cid:80)
compute the predicted error from cross-entropy loss L(W (i), b(i)).

j eCd[j].

update 1D-CNN using stochastic gradient decent and learning rate η via the back-propagation:



W (i+1) = W (i) − η ∂

∂W L (cid:0)W (i), b(i)(cid:1)

.



b(i+1) = b(i) − η ∂

∂b L (cid:0)W (i), b(i)(cid:1)

15 end

4.3. Numerical Results

We performed numerical veriﬁcation of the algorithm in two stages: simulation and over-the-air (OTA)

communication. In simulation, a training dataset was created using modulation scheme on a PC for BPSK,

QPSK and 16-QAM, with AWGN channel-based propagation at diﬀerent SNR values: 0, 2, 4, 6, 8, 10 dB

and possessing multipath: 1, 2, 4 paths. 50 messages were generated at random for each combination of

17

Figure 6: AMC classiﬁcation accuracy in simulation

(a) AMC accuracy for BPSK for OTA communication

(b) AMC accuracy for QPSK for OTA communication

Figure 7: AMC Performance

modulation and SNR values, to form the complete training dataset. Correntropy sequences of size 150 taps

were extracted from each modulated message, which passed as training data to 1D-CNN.

After successful oﬄine training, we pass randomly generated messages through a GNURadio-simulated

AWGN channel, at diﬀerent noise levels: 0, 100, 200, 300, 400, 500 (mV) and at varying normalized frequency

oﬀsets: 0, 0.005, 0.01, 0.03, 0.05 (with respect to the central frequency - 915 MHz). The resulting data

obtained at the receivers were passed through the feature extraction and a trained 1D-CNN to determine

the modulation classiﬁcation.

Figure 6 shows the classiﬁcation accuracy of the model for all three modulation schemes BPSK, QPSK

and 16-QAM.

In the second stage, wireless communication data was collected through over-the-air measurements using

two USRP 2901s placed in close proximity to each other. Now, the random generated data was passed over

a true wireless channel,through SDRs tuned to transmit and receive at a central frequency of 915 MHz, with

varying bandwidths: 0.4, 1, 2, 4, 5 MHz and varying RX antenna gain: 25, 15, 10, 8 dB. Transmit antenna

gain was maintained at a constant value of 25 dB. Figures 7a and 7b show the performance of AMC on

OTA data.

As the bandwidth increased, the correntropy features for BPSK and QPSK seemed very similar, which is

why the 1D-CNN model was unable to provide a 100% accuracy in QPSK modulation scheme. We hypoth-

esize that this similarity could be due to increased noise ﬂoor for higher bandwidths, as the classiﬁcation

through correntropy calculation has an inherent assumption that the noise is not too large compared to the

18

actual signal. At higher bandwidths, since this constraint cannot be guaranteed, the features may sometimes

seem indistinguishable for diﬀerent modulation schemes.

5. LDPC Decoder Parameter Estimation using Deep Learning

Low-Density Parity-Check codes have outstanding performance characteristics in terms of block error

rates against the channel SNR. While these codes have been around for a long time, their adoption into

the 5G standards have resulted in development of techniques that can mitigate the high computational

complexity of the algorithm using deep-learning methods [22] and by modifying the decoding architectures

to enable implementation on devices such as FPGAs [23]. Conventional method in LDPC decoding include

the iterative message passing algorithms such as sum-product (SP) or min-sum (MS) approach. There have

been a few eﬀorts in the direction of completely eliminating the iterative aspect by considering the coded

message at the receiver as a text and using convolutional neural networks for mapping the message to the

correct transmitted code [24]. Another approach adopted is to represent the decoding iterations in terms

of neural network layers and improve the performance of this neural network using parameter tuning. This

process involves attaching weights and biases to either the messages being passed or as normalization and

oﬀset components [22, 25].

LDPC codes are a form of soft-in soft-out linear codes, where the operation adds a certain number of

redundant bits to a binary message of size ‘k’ bits, resulting in a ‘N ’ bit codeword (N > k). This increases

the robustness to errors due to harsh channel environments.

5.1. Neural MS Decoder

In this paper, we have adopted the neural decoder model presented in [22], which has the following

characteristics:

• A neural network with N input nodes, representing N bits of encoded codeword.

• Each iteration in a conventional tanner-graph based decoder is unfolded into a hidden layer.

• Each hidden layer with size equal to number of edges in the protograph-LDPC parity check matrix,

as per the 5G standard [26].

• Within each hidden layer, a variable node and check node update are implemented.

• Weights and biases of every layer represent the normalization and oﬀset parameters of the decoder.

Consider an edge in the parity check matrix e = (v, c), where v represents a variable node and c represents

a check node. Then if E = {e = (v, c)} is a set of all edges, and if the LLR inputs into the neural network

19

Figure 8: Iteration-by-iteration training

are given as lv since each variable node corresponds to a code bit, then for ith hidden layer:

Variable node update for edge e: liv

e=(v,c) = lv +

(cid:88)

l(i−1)c
e(cid:48)

,

e(cid:48)=(v,c(cid:48)),c(cid:48)(cid:54)=c

Check node update for edge e: lic

e=(v,c) =

(cid:32)

(cid:81)

e(cid:48)=(v,c(cid:48)),v(cid:48)(cid:54)=v sgn (cid:0)liv

e(cid:48)

(cid:33)

(cid:1)

(10)

(11)

(cid:16)

×ReLU

αi

e × mine(cid:48)=(v,c(cid:48)),v(cid:48)(cid:54)=v

(cid:12)
(cid:12)liv
e(cid:48)

(cid:12)
(cid:12) − βi
e

(cid:17)
,

where αi, the normalization factor, is represented by weights of ith hidden layer and βi, the oﬀset factor, is

represented by bias of ith hidden layer.

For reducing the number of computations, we employed a parameter-sharing strategy where one value

of αi

e and βi

e = βi. This helps in
expanding the network for especially large message sizes, which would need many hidden layers for eﬀective

e is used within one hidden layer. That is, ∀ e ∈ E, we have αi

e = αi , βi

decoding, without linearly increasing the parameter count, thereby restricting the computational complexity

as the message size scales up.

5.2. Training the Neural MS Decoder

For the purposes of training, Basegraph BG2, deﬁned in [26] was chosen as the parity check matrix for

implementing the decoder. A lifting factor of Z = 16 was used over BG2. This results in a codeword of

size 52 × 16 = 832 bits. Random messages of size 832 bits were synthesized to use in training. A network

of 25 hidden layers was created and trained over the synthesized codewords. Cross-entropy was used a loss

function to train the neural network.

L = −

1
N

N
(cid:88)

v=1

xv log(ov) + (1 − xv) log(1 − ov),

(12)

20

where N is the number of bits, ov is output from the network and xv is the training label used to obtain ov.

In order to eliminate the problem of vanishing gradients in deep neural networks, an iteration-by-iteration

training was applied. In this operation, parameters in each layer are trained independently using gradient

descent and a cross-entropy loss. After the ﬁrst hidden layer is trained and its parameters are optimized,

second hidden layer would undergo training. However, the computation of LLR outputs during training

will now include both the trained ﬁrst layer and the second layer. Same principle is propagated over all the

layers. This implies that the network parameters are optimized by leveraging multiple layers at once, while

training only one layer at a time. This results in reduced complexity in computation and in eliminating

vanishing gradient problem. Figure 8 shows the data ﬂow when training the P th hidden layer using iteration-

by-iteration method.

Figure 9 shows the gradual reduction in loss values as the number of layers are increased. While the

network was originally built with 25 hidden layers, for a codeword of 832 bits, the network converged for less

than 10 layers. A trade-oﬀ between computation time and accuracy can be deduced from the loss values over

training epochs and multiple layers. Using a network with higher number of layers results in a proporational

increase in computation time, due to having to perform the iterative decoding process that many times.

However, higher the number of layers used, greater is the accuracy of prediction, since the corresponding

cross-entropy loss tends to be lower. Depending on the capability of the device under consideration, one may

choose to exploit this trade-oﬀ to implement eﬃcient and timely decoding. Since the decoding operations

are performed over a PC in our project, we chose to utilize the complete set of 25 layers in our inference

model. This layer count can be decreased to a smaller number when the algorithm has to be ported onto

low-complexity devices such as SDRs. This ﬂexibility, enabled due to iteration-by-iteration training, makes

this model relevant to algorithm-hardware design and for deploying in RedCap devices.

5.3. Numerical Results

Similar to the evaluation metrix used for AMC, veriﬁcation of LDPC decoding was executed in two stages:

simulation and OTA communication. Here, two modulation schemes were considered: BPSK and QPSK,

transmitted over a GNURadio-based AWGN channel with varying noise levels: 0, 200, 400, 500 mV, diﬀerent

frequency oﬀsets: 0, 0.005, 0.01, 0.03, 0.05 (with respect to central frequency of 915 MHz) and multiple paths:

1, 2, 4 paths. For OTA communication, BPSK and QPSK modulated data was considered, passing through

a wireless channel with bandwidths: 0.4, 1, 2 MHz with TX antenna gain at 25 dB and RX antenna gain

varying as 25, 15, 10, 8 dB. Figures 10a and 10b show that the LDPC decoder has suppressed most of the

errors that were induced by the channel, in simulation and over the air respectively.

21

Figure 9: Loss function vs hidden layers (Iterations)

(a) % of correct bits before and after LDPC decoding in simulation setup

(b) LDPC decoder performance in OTA setup - 1 MHz bandwidth

Figure 10: LDPC Decoder Performance

22

6. Conclusion and Future Work

This paper introduced intelligent autonomic radios with architecture that enables algorithm-hardware

separation, while providing a dedicated and scalable AI layer to accommodate data-driven machine learning

solutions to augment the classical signal processing blocks in PHY and MAC layers of the radio. We have

also provided a detailed use case involving the introduced components, by ﬁtting them into a transmitter

and a receiver data ﬂow, for providing a means of employing the proposed transceiver in an end-to-end

communication setup. As a future work, we are working towards improving the AMC algorithm performance

at large bandwidths.

It is important to maintain the complexity of our algorithm as hardware-friendly

as possible, while mitigating the correntropy assumption limitations at large bandwidths. We are also

considering an end-to-end system realization over software deﬁned radios, as a hardware proof of concept of

the introduced intelligent autonomic radio design. Apart from algorithm/hardware enhancement, another

potential future direction is to transform the current algorithms to be capable of self-reconﬁguration, based on

the underlying hardware utilized. This is expected to be accomplished by incorporating an operating system

(OS) that can mediate hardware status in real time to the algorithms. In such a scenario, algorithms would be

built as software over the OS. Alternatively, we are keen to explore the possibility of building containers over

the device representing the algorithms, whose resources can be modiﬁed based on the hardware capability

at the time. This would result in building a platform that would cater to 6G requirements as Functions-as-

a-service block.

References

[1] I. F. Akyildiz, A. Kak, S. Nie, 6g and beyond: The future of wireless communications systems, IEEE Access 8 (2020)

133,995–134,030. doi:10.1109/ACCESS.2020.3010896.

[2] O-RAN Alliance, O-RAN: Operator deﬁned open and intelligent radio access networks.

URL https://www.o-ran.org/

[3] K. B. Letaief, W. Chen, Y. Shi, J. Zhang, Y.-J. A. Zhang, The roadmap to 6g: Ai empowered wireless networks, IEEE

Communications Magazine 57 (8) (2019) 84–90. doi:10.1109/MCOM.2019.1900271.

[4] M. Giordani, M. Polese, M. Mezzavilla, S. Rangan, M. Zorzi, Toward 6g networks: Use cases and technologies, IEEE

Communications Magazine 58 (3) (2020) 55–61. doi:10.1109/MCOM.001.1900411.

[5] J. Iannacci, Towards future 6g from the hardware components perspective – a focus on the hardware-software divide, its

limiting factors and the envisioned beneﬁts in going beyond it, in: 2021 IEEE 4th 5G World Forum (5GWF), 2021, pp.

1–6. doi:10.1109/5GWF52925.2021.00008.

[6] E. C. Strinati, D. Belot, A. Falempin, J.-B. Dor´e, Toward 6g: From new hardware design to wireless semantic and goal-

oriented communication paradigms (2021). doi:10.48550/ARXIV.2107.01019.

URL https://arxiv.org/abs/2107.01019

[7] M. N. Aman, B. Sikdar, Ai based algorithm-hardware separation for iov security, in: 2021 IEEE Globecom Workshops

(GC Wkshps), 2021, pp. 1–6. doi:10.1109/GCWkshps52748.2021.9681992.

[8] Y.-C. Liang, Dynamic spectrum management: From cognitive radio to blockchain and artiﬁcial intelligence (2020). doi:

https://doi.org/10.1007/978-981-15-0776-2.

23

[9] S. N. K. Veedu, M. Mozaﬀari, A. Hoglund, E. A. Yavuz, T. Tirronen, J. Bergman, Y. P. E. Wang, Toward smaller and lower-

cost 5g devices with longer battery life: An overview of 3gpp release 17 redcap (2022). doi:10.48550/ARXIV.2203.05634.

URL https://arxiv.org/abs/2203.05634

[10] A. Kott, A. Swami, B. J. West, The internet of battle things, Computer 49 (12) (2016) 70–75. doi:10.1109/MC.2016.355.

[11] M. Pradhan, J. Noll, Security, privacy, and dependability evaluation in veriﬁcation and validation life cycles for military

iot systems, IEEE Communications Magazine 58 (8) (2020) 14–20. doi:10.1109/MCOM.001.2000342.

[12] Request for solutions(rfs)-task area 3-dynamic spectrum management@b5g tactical edge (Mar 2022[Online]).

URL https://sam.gov/opp/c9640c1d916b43ca995878bdb1464a5a/view

[13] Dod tests ai-powered spectrum management technology on aerial combat training ranges (Oct 2021[Online]).

URL https://www.airforcemag.com/dod-test-ai-powered-spectrum-management/

[14] 3GPP TR 38.886 v16.2.0, Release 16, 3rd Generation Partnership Project; Technical Speciﬁcation Group Radio Access

Network; V2X Services based on NR; UE radio transmission and reception (Oct. 2020).

[15] S.-C. Lin, K.-C. Chen, A. Karimoddini, Sdvec: Software-deﬁned vehicular edge computing with ultra-low latency, IEEE

Communications Magazine 59 (12) (2021) 66–72. doi:10.1109/MCOM.004.2001124.

[16] M. Ryu, Y. Chow, R. Anderson, C. Tjandraatmadja, C. Boutilier, Caql: Continuous action q-learning (2020). arXiv:

1909.12397, doi:10.48550/ARXIV.1909.12397.

[17] J. Foerster, et al., Stabilising experience replay for deep multi-agent reinforcement learning, in: PMLR International

conference on machine learning, 2017, pp. 1,146–1,155. doi:10.48550/ARXIV.1702.08887.

[18] C.-H. Lin, S.-C. Lin, C.-Y. Wang, T. Chase, A c-v2x platform using transportation data and spectrum-aware sidelink

access, in: 2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC), 2021. doi:10.1109/SMC52423.

2021.9659109.

[19] C.-H. Lin, S.-C. Lin, E. Blasch, Tulvcan: Terahertz ultra-broadband learning vehicular channel-aware networking,

in: 2021 IEEE Conference on Computer Communications Workshops (INFOCOM), 2021, pp. 1–6.

doi:10.1109/

INFOCOMWKSHPS51825.2021.9484613.

[20] X. Meng, H. Inaltekin, B. Krongold, End-to-end deep learning-based compressive spectrum sensing in cognitive radio

networks, in: ICC 2020-2020 IEEE International Conference on Communications (ICC), IEEE, 2020, pp. 1–6. doi:

10.1109/ICC40277.2020.9149195.

[21] Conv1d layer (2022 [Online]).

URL https://keras.io/api/layers/convolution_layers/convolution1d/

[22] J. Dai, K. Tan, Z. Si, K. Niu, M. Chen, H. V. Poor, S. Cui, Learning to decode protograph ldpc codes, IEEE Journal on

Selected Areas in Communications 39 (7) (2021) 1983–1999. doi:10.1109/JSAC.2021.3078488.

[23] J. Nadal, A. Baghdadi, Parallel and ﬂexible 5g ldpc decoder architecture targeting fpga, IEEE Transactions on Very Large

Scale Integration (VLSI) Systems 29 (6) (2021) 1141–1151. doi:10.1109/TVLSI.2021.3072866.

[24] Y. Ni, S. Peng, L. Zhou, X. Yang, Blind identiﬁcation of ldpc code based on deep learning, in: 2019 6th International

Conference on Dependable Systems and Their Applications (DSA), 2020, pp. 460–464. doi:10.1109/DSA.2019.00073.

[25] Q. Wang, S. Wang, H. Fang, L. Chen, L. Chen, Y. Guo, A model-driven deep learning method for normalized min-sum

ldpc decoding, in: 2020 IEEE International Conference on Communications Workshops (ICC Workshops), 2020, pp. 1–6.

doi:10.1109/ICCWorkshops49005.2020.9145237.

[26] 3GPP, Technical speciﬁcation group radio access network nr; multiplexing and channel coding (release 16) (2021).

24

