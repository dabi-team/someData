Robust Modeling and Controls for Racing on the Edge

Joshua Spisak1*, Andrew Saba1*, Nayana Suvarna2, Brian Mao3, Chuan Tian Zhang3, Chris Chang4,
Sebastian Scherer1, and Deva Ramanan1,5

2
2
0
2

y
a
M
2
2

]

O
R
.
s
c
[

1
v
1
4
8
0
1
.
5
0
2
2
:
v
i
X
r
a

Abstract— Race cars are routinely driven to the edge of
their handling limits in dynamic scenarios well above 200mph.
Similar challenges are posed in autonomous racing, where a
software stack, instead of a human driver, interacts within a
multi-agent environment. For an Autonomous Racing Vehicle
(ARV), operating at the edge of handling limits and acting safely
in these dynamic environments is still an unsolved problem.
In this paper, we present a baseline controls stack for an
ARV capable of operating safely up to 140mph. Additionally,
limitations in the current approach are discussed to highlight
the need for improved dynamics modeling and learning.

I. INTRODUCTION

While some Autonomous Vehicles (AVs) have been de-
ployed for public use, there are still edge cases that prevent
safe usage in everyday life. It can take thousands or millions
of hours of operations for these edge cases to be encountered.
Autonomous racing is an opportunity to face several of these
edge cases head-on. In particular,
the Indy Autonomous
Challenge (IAC) has held autonomous racing competitions
such as the fastest single agent lap as well as a 1v1 passing
competition. The IAC involves nine teams, making it the
largest full-scale vehicle autonomous racing competition in
the world. The competition is predicated on each team having
the same hardware available, focusing the competition on
algorithmic development to face the challenges of operating
on the edge of handling limits and pushing autonomous
capability to new levels. This paper outlines a controls
software stack capable of racing up to 140mph. Later, we
outline additional challenges and future opportunities to push
high speed performance to the handling limits of the vehicle.

A. Problem

In autonomous racing, operating at high speeds is a min-
imum barrier to entry. Not only must the vehicle be able to
move quickly, it must be able to react dynamically and stably.
This can be a challenge even for human drivers, with multiple
crashes occurring during the 2021 Indy 500 after drivers
lost control of their vehicle. During a race, a human driver
must be able to understand changing conditions such as track
temperature, small pieces of tire rubber collecting on parts
of the track, and gusts of wind disturbing the vehicle. They

1With Carnegie Mellon University jspisak, asaba, basti,

deva @andrew.cmu.edu

2With University of Pittsburgh nls71 @pitt.edu
3With
of

University

Waterloo

bmao, ben.zhang

@uwaterloo.ca

4With Massachusetts

@mit.edu

5With Argo AI
*Equal contribution

Institute

of

Technology

cwkchang

Fig. 1. AV-21 driving at 137mph on the Las Vegas Motor Speedway

must also understand their own vehicle’s changing conditions
such as tire pressure, temperature, and wear. Changes in
these conditions can cause loss of control and crashes. In
addition, a safe ARV must maintain a reaction time that
exceeds human capability — in the time it takes a human
driver to react, the vehicle can move several meters. These
challenges express themselves in similar ways to autonomy
software, where algorithms must be able to predict or react
stably to these dynamic conditions quickly.

B. Application to Urban Driving

Previous development in the autonomous vehicle space has
been focused on the urban environment in which vehicles
are at low dynamic loading. While racing vehicles move at
speeds in excess of 200mph, the maximum speed limit in
the United States is 85mph, and the maximum speed limit
world-wide is 130mph. Most trafﬁc moves slower than a
racing vehicle; still, trafﬁc related accidents are the number
eight cause of deaths worldwide and a third of these deaths
are caused by speeding [1]. Primary reasons for increased
crash risk at higher speeds include a longer stopping distance,
shorter reaction time, and bringing the vehicle to higher
dynamic load than they might experience normally or be
designed for making it more difﬁcult to control.

While urban vehicles do not experience the same dynamic
load as racing vehicles do at 200mph+, they can approach
similar limits, especially in adverse weather. They are also
subject to non-negligible disturbances, such as aerodynamic
effects at high speeds, potholes, and ice patches. Methods for
stable high-speed control should be able to handle these same
classes of disturbances and complex dynamics. Methods for
autonomous racing can also push the limits of autonomous

 
 
 
 
 
 
capability to minimize reaction time to dynamic adversarial
agents (such as a drunk drivers) as well as minimize stopping
distances to produce safer methods of transit with increased
speed and efﬁciency.

C. Content Overview

The results obtained in this paper were obtained using
a fairly simple architecture. Our localization utilized the
Novatel GNSS-INS system paired with robot localization
[2]. This, as well as a racing line, feed into a tracking
controller. This paper brieﬂy discusses an ofﬂine racing
line generation method, but we will primarily focus on the
tracking controller and an online modeling scheme that can
feed parameters to this controller in an online manner.

While the components used in this paper are not particu-
larly novel, this speciﬁc formulation of the lateral controller
combining pure-pursuit and LQR is,
to the best of the
authors’ knowledge, unique and different from any prior
formulations. The authors also believe there is value in
demonstrating capability at high speeds with simple tracking
frameworks, and describing the issues experienced during
deployment as well as possible solutions.

II. RACING LINE GENERATION

The racing line is represented spatially as a series of 2D
points (x, y). Due to the low road curvature of the oval
speedways we race on, it sufﬁces to decouple target speed
from the racing line, since we assume that the same target
speed is reasonable everywhere on the racing line as long as
the target speed is reasonably slower than the true operating
limits (over 200mph).

We constrain the racing line to be a closed Spiro spline
[3] interpolating a series of manually selected waypoints
(x, y). While the tracking controller is compatible with
any reasonably smooth racing line, the Spiro spline is a
particularly attractive spline family because:

• it exhibits G4-continuity, meaning that
derivative of curvature is continuous.

the second

• it is an efﬁcient approximation of the Minimum Vari-
ation Curve (MVC), which minimizes the integral of
curvature rate, i.e. steering effort.

These properties make the Spiro spline particularly effective
at minimizing instability in the downstream tracking con-
troller.

The manual selection of waypoints is up to user discre-
tion and depends on the use case. For example, in order
to generate a natural racing line (one where curvature is
generally minimized), a good choice of waypoints would
be the points where the vehicle is expected to drive closest
to the boundaries of the track, i.e. the apexes. However,
in order to generate a racing line that closely follows the
center of the track, one might choose waypoints solely from
the centerline. In order to ensure that the ﬁnal racing line
maintains a desired safety distance from the track boundaries,
it may be necessary to tweak these waypoints and generate
a new line multiple times.

Fig. 2. Stack and Controller Overview

III. TRACKING CONTROLLER

A. Overview

The tracking controller decomposes the tracking problem
into three different problems: lateral tracking, longitudinal
tracking, and gear shifting. Lateral tracking is concerned
with generating a steering angle that will converge the
vehicle to the path. This utilizes a combined pure-pursuit
LQR control scheme where the LQR controller is evaluated
relative to some look-ahead point. The longitudinal controller
is concerned with maintaining a particular velocity. The
gear shifting controller is concerned with selecting the best
gear to maintain the current speed. Most of the content in
this section will focus on the lateral tracking as that is the
most interesting and novel portion of the stack. The stack’s
architecture is described in Figure 2.

B. LQR

Given a continuous-time linear system of the form in
Equation 1 we can deﬁne a quadratic cost function such as
Equation 2 which is constrained by Equation 1. Equation 2
also has the constraints that Q = QT ≥ 0 and R = RT ≥ 0.
We can derive an optimal feedback policy that minimizes
the cost function in Equation 2 over the inﬁnite horizon
in time. Solving this problem is trivial and can done using
Matlab’s lqr function as well as many other available solvers
such as ones detailed in [4]. This resulting feedback policy
takes the form of Equation 3.

˙x(t) = Ax(t) + Bu(t)

J =

(cid:90) ∞

t=0

(cid:2)x(t)T Qx(t) + u(t)T Ru(t)(cid:3) dt

u∗(t) = K(t)x(t)

(1)

(2)

(3)

C. Dynamic Bicycle Model

We utilize a four state dynamic bicycle model from [5],
shown in Equation 4. As noted in III-A we decompose the
problem into separate lateral and longitudinal controllers,
the lateral controller reasons about the lateral position of
the vehicle and the yaw of the vehicle (y, ψ). The input
for this system is steering angle δ, and it assumes some
constant velocity Vx. Other parameters of the system include
Cαf , Cαr (cornering stiffness of the front and rear tires
respectively), lf , lr (length of the vehicle from the center
for gravity to the front and rear axles respectively). The

parameter Iz is the moment of inertia about the z axis, and
m is the mass of the vehicle.

0

0
0 −Vx − 2Cαf lf −2Cαrlr
0

mVx

2l2

1
f Cαf +2l2
IzVx

rCαr

0

−








(4)

1
− 2Cαf +2Cαr
mVx
0

A =

0
0



0

0 − 2lf Cαf −2lrCαr







˙y
¨y
˙ψ
¨ψ









= A

IzVx

y
˙y
ψ
˙ψ









+











δ

0
2Cαf
m
0
2lf Cαf
Iz

To utilize this model with the LQR formulation above,
the model is rephrased such that the state space is error with
respect to a target trajectory as shown in Equation 5. The
error term e1 is the lateral error of the vehicle from the
target trajectory and e2 being the yaw error of the vehicle
relative to the target trajectory.

1
− 2Cαf +2Cαr
mVx
0

A =

0
0



0

0 − 2lf Cαf −2lrCαr







= A









+





IzVx

e1
˙e1
e2
˙e2





˙e1
¨e1
˙e2
¨e2





0
2Cαf +2Cαr
m
0
2lf Cαf −2lrCαr
Iz







δ

0
2Cαf
m
0
2lf Cαf
Iz

0
− 2Cαf lf −2Cαrlr
mVx
1
f Cαf +2l2
IzVx

rCαr

2l2

−








(5)

y∗ ψ∗
˙y ψ

Given a target at some point along the trajectory with a
given (cid:2)x∗
˙ψ∗(cid:3) as well as the vehicle position
(cid:2)x y
˙ψ(cid:3), with all states speciﬁed in some
˙x
inertial frame excluding ˙x and ˙y which is the velocity of
the vehicle in the body frame, we can calculate the error
state as follows:







=







e1
˙e1
e2
˙e2







(x∗ − x) sin(−ψ∗) + (y∗ − y) cos(−ψ∗)
˙y + ˙x(ψ − ψ∗)
ψ − ψ∗
˙ψ − ˙ψ∗







(6)

This model makes several assumptions, including small
angle assumptions on the steering angle which hold well on
ellipsoidal tracks where we command a maximum steering
angle of approximately 0.1 [rad]. The model also assumes
constant velocity. A reformulation to a linear time-varying
model could allow for varying velocity, however for sim-
plicity we accept that assumption then mitigate this with a
series of feedback controllers derived at different velocities,
this is described in Section III-D. For greater detail on this
formulation of the dynamics see [5].

D. Pure Pursuit, LQR Tracking Algorithm

Given the model formulation in III-C and the LQR for-
mulation in III-B we can make a lateral tracking algorithm
by combining a pure-pursuit style look-ahead point and a
feedback mechanism like in Equation 3 generated using
LQR. The look-ahead point is queried simply by looking
for the point on the trajectory that is ahead of the vehicle a
given distance d away. To generate the feedback policy lqr
requires an A, B, Q and R matrix. The A and B matrix
can be obtained using the dynamics from Equation 5. The Q
and R matrices can be obtained empirically where the trace
of the Q matrix deﬁnes the weights on the error terms in
Equation 6, the R matrix deﬁnes the weight on the steering
angle essentially allowing us to dampen the steering.

To account for varying dynamics at different speeds
ranging
we have the concept of a velocity bracket
[ ˙xlow, ˙xhigh) such that
if the vehicles current velocity is
within that bracket it utilizes a particular parameter set p =
(Q(0,0), Q(1,1), Q(2,2), Q(3,3), R(0,0), R(1,1)). The algorithm
inputs a series of brackets which are assumed to cover
the range of velocities we expect
to cover or generally
the range [0, ∞) with no overlap between them. The look-
ahead distance is also varied a function of speed where
d = dbase + kv,d ˙x. These parameter sets can be deﬁned
empirically; however, we mostly tuned the dampening on
the steering angle, increasing it with speed.
The algorithm runs as follows. First,

initializes by
loading in all velocity brackets and the associated parameters.
It then generates the feedback policies K for each bracket
using the average velocity of the bracket (unless one of the
bounds is ∞ in which case it uses the lower velocity). Then
at each time step, given the current state of the vehicle and a
target trajectory it performs a look-ahead query on the target
trajectory to get the goal point. Using this goal point and the
current state an error state can be generated. Finally, with the
current vehicle velocity, it queries the velocity brackets for
the relevant feedback policy which is applied on the error
state to get the optimal steering angle. This algorithm is
summarized in Algorithm 1.

it

E. Longitudinal Control and Gear Shifting

The throttle and brake control utilizes a simple P control
scheme paired with a feed-forward term to account for drag.
This is expressed with in Algorithm 2 line 6, which returns
a command value. This command is then interpreted as
either a throttle or brake command depending on whether the
command is positive or negative. Supposing the command is
negative we also apply a scaling factor αbrake to the brake,
tuned assuming there is no scaling factor from the command
to throttle. We also apply smoothing on the throttle and
brake to prevent instantaneous acceleration or deceleration
that could make the vehicle unstable, parameterized simply
by an allowed rate of change with respect to time. This
pipeline is summarized in Algorithm 2.

The gear shifting strategy is based on a simple look
up table where given the current velocity of the vehicle
we can compute the optimal gearing. This gearing table

Algorithm 1: Lateral Tracking Algorithm
1 P ← {(v1,low, v2,low, K1), . . . , (vn,low, ∞, Kn)} ;
/* We assume parameters have been
loaded and the feedback policies
generated. */

2 dbase, kv,d ← loadParams();
3 while true do

x, y, ˙x, ˙y, ψ, ˙ψ ← getState();
τ ← getTrajectory();
d ← dbase + kv,d ∗ ˙x;
K ← getFeedbackMatrix( ˙x, P );
x∗, y∗, ψ∗, ˙ψ∗ ← lookahead(x, y, d, τ );
e ← errorMatrix (x, y, ˙x, ˙y, ψ, ˙ψ, x∗, y∗, ψ∗, ˙ψ∗);
u ← −Ke;
commandSteering(u);

11
12 end

was generated based on a model of the engine and track
parameters to maximize torque, the computation of which is
outside the scope of this paper.

Algorithm 2: Longitudinal Tracking Algorithm
1 kp, kfeed forward, αbrake, δthrottle, δbrake ← loadParams();
2 throttle previous, brake previous ← 0;
3 while true do

x, y, ˙x, ˙y, ψ, ˙ψ ← getState();
vtarget ← getTarget();
command ← kp(vtarget − ˙x) + kfeed forward ∗ vtarget;
throttle, brake ← 0 if command ≥ 0 then

throttle ← command;

else

brake ← −αbrakecommand;

end
throttle ←
smooth(throttle previous, throttle, δthrottle);
brake ← smooth(brake previous, brake, δbrake);
comamnd(throttle, brake);
throttle previous ← throttle;
brake previous ← brake;

16
17 end

4

5

6

7

8

9

10

4

5

6

7

8

9

10

11

12

13

14

15

Fig. 3. Top plot: cross-track error (CTE). Lower plot: Vehicle Velocity

Fig. 4. Top plot: cross-track error (CTE). Middle plot: Vehicle Velocity,
Lower plot: lanes and lane change maneuver.

F. Results

G. Discussion

The stack shown in Figure 2 was evaluated over several
performance laps at the Las Vegas Motor Speedway with
velocities ranging between 25 [m/s] and 60.5 [m/s]. We
experienced the worst performance at
the highest speed
targeting 60 [m/s]. We plot velocity and cross-track error
(CTE) for this portion of the evaluation in Figure 3. The
maximum CTE experience was 1.3 [m], experienced around
bends, while the mean absolute CTE was 0.42 [m]. We also
evaluate the controller on a lane-change task on the same
track at 25 [m/s]. The results are shown in Figure 4. The
maximum CTE experienced was 0.55 [m].

In this section we present a simple method to combine
pure-pursuit and an optimal-control method utilizing LQR.
While not a particularly complex optimal-control method, it
is able to stabilize the vehicle at high speeds with reasonable
cross-track error. We consider this simplicity to be a strength
of this algorithm. Classical controllers such as those de-
scribed in [6] are still utilized in autonomous racing as seen
in [7] which utilizes a pure-pursuit method as the low-level
controller and [8] which evaluates an adaptive pure-pursuit
method. However, more commonly Model Predictive Control
methods have been utilized which can have the beneﬁts of

Fig. 5. Dynamic Bicycle Model. lf and lr denote the distance between
the front and rear tires and the center of mass (CoM). Vx and Vf denote
the velocity at the CoM and front tire, respectively. ζf is the direction of
the front wheel velocity and δf is the current steering angle. Fr and Ff
are the lateral forces acting on the rear and front tires, respectively.

reasoning more explicitly about effects such as drag and
velocity control over time as in [9], or to further reason about
dynamic limits and uncertainty as in [10].

Our approach meets these somewhere in the middle: we
utilize a simple optimization scheme that yields a feedback
controller that can reason about vehicle dynamics without
employing receding horizon optimization. This results in
strongly guaranteed fast execution time, and stability at
high speeds as demonstrated in the results on vehicle at
140 [mph]. However, there are some shortcomings in this
approach in the empirical tuning of the look-ahead parame-
ters which can have a strong effect on performance. Future
work could include incorporating an optimized look-ahead
distance such as in [11] or [8]. Additionally this method
does not truly incorporate the ability to handle changing
conditions outside of feedback once disturbances occur. In
Section IV we discuss further opportunities to improve this
and other control frameworks.

IV. OPPORTUNITIES FOR IMPROVEMENT

Non-linear dynamics at

the edge of vehicle handling
necessitate complicated control regimes that still fall short
of matching and exceeding human driver performance [12].
While in [13] the authors claim performance that exceeds a
human driver, it must be noted that the ARV was driving
without the additional weight of a human and was limited
to speeds of up to 18m/s, whereas larger ARVs are racing at
speeds in excess of 77 [m/s] (173 [mph]) [14].

In the following sections, we will discuss the vehicle dy-
namics problems in more detail and present a modeling and
dynamics learning pipeline that can address these challenges.

A. Online Tire Modeling and Learning

At the core of our controller is the dynamic bicycle model,
a portion of which is shown in Figure 5. This model, for the
center of mass and for the front and rear tires, is centered
around three critical angles: ζ, or the direction of the velocity
vector; δ, or the current angle the tire or vehicle body is
pointing; and α, or slip angle, which is deﬁned as α = δ − ζ.
The slip angle is what is ultimately used to estimate the
lateral forces acting on the tire. The Pacejka tire model is
one of the most widely used empirical tire models due to its

Fig. 6. Proposed modeling pipeline. Vehicle state and sensor input is used to
estimate the friction coefﬁcients at the current time step. A separate module
uses vehicle state and sensors, track banking, and other agents locations to
adapt a model that predicts the drag and down forces on the vehicle. Since
drag and down forces can be estimated, this model can be trained in a self-
supervised fashion. Finally, this model is used by the controller to optimize
the candidate trajectories and predict future vehicle dynamics.

accuracy when compared to empirically measured data. Tire
forces are expressed as:

(cid:18)

F = D sin

C arctan (cid:0)Bα − E(Bα − arctan(Bα)(cid:1)

(cid:19)

µFz

(7)
where B is the stiffness factor, C is the shape factor, D is
the peak value, E is the curvature factor, α is the slip angle,
µ is the tire road friction coefﬁcient, and Fz is the vertical
tire force.

For computational costs and simplicity’s sake, our con-
troller utilizes a linear approximation of the Pacejka tire
model, which deﬁnes a cornering stiffness Cr and Cf for
the rear and front tires, respectively. With this, the lateral
forces are now deﬁned as Fr = Cr ∗ αr and Ff = Cf ∗ αf .
With our full state estimate and estimated slip angle, we
are capable of estimating the linear model parameters, are
not static and change over time due to tire degradation,
temperature, pressure, and other factors. This degradation is
even more severe under the context of racing where tires are
often pushed to their friction limits. Therefore, it would be
beneﬁcial to develop an estimation methodology to determine
tire model parameters online.

Similar ideas have been introduced before, including in
[15] and others. However, tire friction is only one part in a
larger dynamics model. For example, estimating friction does
not capture how wind or aerodynamic effects from other
vehicles impact performance. The authors in [16] address
this with a more holistic approach, using a Gaussian Process
Regression (GPR) model that is trained online to estimate the
error in the vehicle model. This allows for their controller
to reason about the overall dynamic state of the vehicle,
capturing more than just changes in friction potential from
the tires.

B. Aerodynamic Force Learning and Prediction

In addition to two RTK-GNSS systems, the AV-21 plat-
form is equipped with a wide range of sensors that capture
information about the tires, suspension, engine, and vehicle
loading. Instead of predicting total model error, a better

approach may be to predict individual components of the
dynamics model (see Figure 6). At the core of the proposed
approach is a module that learns to predict drag and down
forces, given a trajectory of controls. The model is trained
online asynchronously, with the vehicle state, sensors, bank
map of the track, engine torque curve, and current tracks
of other agents as inputs. Since drag and down force can
be estimated online from sensor data and the vehicle state
is continuously measured with high accuracy RTK-GPS, the
model can be trained online in a self supervised fashion. As
the controller optimizes the target trajectory, it can utilize
use the learned model’s predictions.

Through online adaptation, this approach is robust to novel
scenarios and conditions. Aerodynamics are notoriously dif-
ﬁcult to model and predict accurately, so online learning is
necessary to adapt to the environment and the current state of
the world. With this adaptation and learning, the controller
can become more aggressive, pushing the envelope further.

V. CONCLUSION
We have presented a baseline controls stack for an au-
tonomous race vehicle (ARV). This stack, while simple,
provides a robust baseline to expand and build upon moving
forward in future competitions and technical developments.
Additionally, we have also presented a concept modeling ap-
proach that can utilize vehicle and environment information
to better predict how vehicle dynamics will unroll. Finally,
future work will be focused on implementing and testing this
approach, to prepare for future races.

ACKNOWLEDGMENT

Andrew Saba and Deva Ramanan are supported by the

CMU Argo AI Center for Autonomous Vehicle Research.

Thank you to Matthew Travers for his continually helpful
advice and support. Finally, thank you to the entire MIT-Pitt-
RW Indy Autonomous Challenge team and team sponsors for
supporting the deployment of this work.

REFERENCES
[1] W. H. Organization, Global Status Report on Road
Safety 2018, en. World Health Organization, Jan.
2019, Google-Books-ID: uHOyDwAAQBAJ,
ISBN:
978-92-4-156568-4.

[2] T. Moore and D. Stouch, “A generalized extended
kalman ﬁlter implementation for the robot operating
the 13th International
system,” in Proceedings of
Conference on Intelligent Autonomous Systems (IAS-
13), Springer, Jul. 2014.

[3] R. L. Levien, “From spiral to spline: Optimal tech-
niques in interactive curve design,” Ph.D. dissertation,
University of California, Berkeley, USA, 2009.
[4] P. Benner, Z. Bujanovi´c, P. K¨urschner, and J. Saak,
“A numerical comparison of different solvers for
large-scale, continuous-time algebraic riccati equa-
tions and lqr problems,” en, SIAM Journal on Sci-
entiﬁc Computing, vol. 42, no. 2, A957–A996, Jan.
2020, ISSN: 1064-8275, 1095-7197. DOI: 10.1137/
18M1220960.

[5] R. Rajamani, Vehicle Dynamics and Control, ser. Me-
chanical Engineering Series. Springer US, 2005, ISBN:
[Online]. Available: https :
978-0-387-26396-0.
/ / books . google . com / books ? id =
N0cVzjChUccC.
J. M. Snider, “Automatic steering methods for au-
tonomous automobile path tracking,” en, p. 78,
[7] G. Hartmann, Z. Shiller, and A. Azaria, “Autonomous
head-to-head racing in the indy autonomous challenge
simulation race,” arXiv preprint arXiv:2109.05455,
2021.

[6]

[8] V. Sukhil and M. Behl, “Adaptive lookahead pure-
racing,” arXiv preprint

for

pursuit
autonomous
arXiv:2111.08873, 2021.

[9] C.

Jung, S. Lee, H. Seong, A. Finazzi, and
D. H. Shim, “Game-theoretic model predictive con-
trol with data-driven identiﬁcation of vehicle model
for head-to-head autonomous racing,” arXiv preprint
arXiv:2106.04094, 2021.

[11]

[10] A. Wischnewski, T. Herrmann, F. Werner, and B.
Lohmann, “A tube-mpc approach to autonomous
multi-vehicle racing on high-speed ovals,” IEEE
Transactions on Intelligent Vehicles, 2022.
J. Ahn, S. Shin, M. Kim, and J. Park, “Accurate
path tracking by adjusting look-ahead point in pure
pursuit method,” en, International Journal of Auto-
motive Technology, vol. 22, no. 1, pp. 119–129, Feb.
2021, ISSN: 1229-9138, 1976-3832. DOI: 10.1007/
s12239-021-0013-7.

[12] L. Hermansdorfer, J. Betz, and M. Lienkamp, Bench-
marking of a software stack for autonomous racing
against a professional human race driver, 2020. DOI:
10.48550/ARXIV.2005.10044.

[14] Polimove wins

[13] S. Srinivasan, S. N. G. N. Giles, and A. Liniger, “A
holistic motion planning and control solution to chal-
lenge a professional racecar driver,” IEEE Robotics
and Automation Letters, vol. 6, no. 4, pp. 7854–7860,
Oct. 2021. DOI: 10.1109/lra.2021.3101244.
at
the ﬁrst head-to-head
ces®, making history as
champion,
competition
autonomous
[Online]. Available: https : / /
Jan. 2022.
www . indyautonomouschallenge . com /
polimove - wins - the - autonomous -
challenge-at-ces.

autonomous

challenge

racecar

the

[15] L. Hermansdorfer, J. Betz, and M. Lienkamp, “A
concept for estimation and prediction of the tire-road
friction potential for an autonomous racecar,” in 2019
IEEE Intelligent Transportation Systems Conference
(ITSC), 2019, pp. 1490–1495. DOI: 10 . 1109 /
ITSC.2019.8917024.
J. Kabzan, L. Hewing, A. Liniger, and M. N. Zeilinger,
for au-
“Learning-based model predictive control
tonomous racing,” IEEE Robotics and Automation
Letters, vol. 4, no. 4, pp. 3363–3370, 2019. DOI: 10.
1109/LRA.2019.2926677.

[16]

