2
2
0
2

y
a
M
5
2

]

G
L
.
s
c
[

1
v
5
1
6
2
1
.
5
0
2
2
:
v
i
X
r
a

Autoformalization with Large Language Models

Yuhuai Wu1,2
†

Albert Q. Jiang3

Wenda Li3

Markus N. Rabe1

Charles Staats1

Mateja Jamnik3

Christian Szegedy1

1Google Research
2Stanford University
3University of Cambridge

Abstract

Autoformalization is the process of automatically translating from natural lan-
guage mathematics to formal speciﬁcations and proofs. A successful autoformal-
ization system could advance the ﬁelds of formal veriﬁcation, program synthesis,
and artiﬁcial intelligence. While the long-term goal of autoformalization seemed
elusive for a long time, we show large language models provide new prospects
towards this goal. We make the surprising observation that LLMs can correctly
translate a signiﬁcant portion (25.3%) of mathematical competition problems per-
fectly to formal speciﬁcations in Isabelle/HOL. We demonstrate the usefulness
of this process by improving a previously introduced neural theorem prover via
training on these autoformalized theorems. Our methodology results in a new
state-of-the-art result on the MiniF2F theorem proving benchmark, improving the
proof rate from 29.6% to 35.2%.

1 Introduction

Autoformalization refers to the task of automatically translating from natural language mathematics
to a formal language [48, 44]. The implication of a successful autoformalization tool is huge in
both practical and philosophical terms. It would reduce the currently excessive cost of formalization
efforts [27], and in the long-term it could connect the various research ﬁelds that automate aspects of
mathematical reasoning, such as automated theorem proving and computer algebra, to the vast body
of mathematical knowledge exclusively written up in natural language. Moreover, autoformalization
would be a true testament to machine understanding, grasping both the fuzziness of natural language
and the preciseness of formal language.

Recent advances in large language models [7, 9] showed promising capabilities of understanding
formal languages [8, 32]. However, the existing successes are limited to formal languages where
there exists a large body of corpus on the web (e.g., Python language). Formal mathematics data
is very scarce. For example, one of the largest formal mathematics libraries, the Archive of Formal
Proofs, is only 180MB in size, that is less than 0.18% of the training data for the large language
model Codex [8]. Moreover, unlike in the case of commonly used programming languages, where
natural language docstrings are broadly available, there is almost zero aligned data between nat-
ural language and formal mathematics. Therefore, it is unclear the recent successes can directly
contribute to the development of autoformalization.

In this work, we explore the prospects of autoformalization with large language models. To our
surprise, we ﬁnd that large language models already have a decent capability of formalizing natural

†Correspondence to Yuhuai Wu (yuhuai@google.com).

 
 
 
 
 
 
Case Study 1 Question:
"Prove that there is no function f from the set of non-negative integers into itself
such that f (f (n)) = n + 1987 for every n."

Codex Output:
theorem

fixes f :: "nat \<Rightarrow> nat"
assumes "\<forall> n. f (f n) = n + 1987"
shows False

Figure 1: Case study 1: An example of a perfect translation from natural language to Isabelle code.

language mathematics in an interactive theorem prover. See Figure 1 for a perfect autoformalization
example. The model not only translates into syntactically correct Isabelle code, but also grasps
the non-trivial reasoning in natural language. We randomly pick 150 formalizations and manually
evaluate their correctness. Among them, LLMs are capable of producing 38 perfect formalizations!
As an application, we further demonstrate that autoformalization can provide useful training data
for neural theorem provers. We use autoformalized statements as targets for proof search with a
neural theorem prover for Isabelle/HOL. After ﬁne-tuning our neural theorem prover on the proofs
it found, its success rate on the MiniF2F benchmark [54] increases signiﬁcantly, achieving a new
state-of-the-art result of 35.2% theorems proven.

2 Related Work

Early applications of machine learning in theorem proving include the works by Schulz [42] and
Urban [45], and later, directly guiding interactive proof assistants using machine learning tech-
niques [14]. The revolution of deep learning then kicked off a new wave of interest in the topic
starting with DeepMath [1, 33].

Several approaches have been suggested to address data scarcity: Imitation-free reinforcement learn-
ing was used to avoid the need for training on human proofs [31, 5, 14, 51]. Also, hindsight expe-
rience replay [2] was used to generate additional training data [4]. Hahn et al. [18], Schmitt et al.
[41], Kreber & Hahn [29] and Wu et al. [52] have shown that training on synthetic formulas can
be successful for temporal logics and inequalities. Rabe et al. [39] masked out different subexpres-
sions from formal mathematical statements and generated 100 training examples for each source
statement. Skip-tree data can also be used to improve the performance of neural theorem provers
[21].

Wang et al. [48] explored the use of supervised and unsupervised translation techniques for auto-
formalization. Supervised translation yielded interesting results, but relied on synthetic (natural-
looking) data that was generated by the Mizar theorem prover, while we rely on models trained via
self-supervised language modeling, not trained for this particular purpose.

3 Background

Formal Mathematics A few important and complex results of mathematics and computer sci-
ence have been formalized manually using interactive theorem provers, such as the four color the-
orem [15], the Kepler conjecture [19], the odd-order theorem [16] and the veriﬁcation of a micro-
kernel [27]. This gives us almost complete certainty about the correctness of proofs, which can be
of great value to resolve doubt about the correctness of complicated mathematical proofs or proving
certain properties of software used in safety-critical applications, such as aircraft components [28].

These projects relied on interactive theorem provers, such as Isabelle [50], Coq [11], HOL Light [22],
and Lean [12], which are essentially programming languages that enable users to enter their state-
ments and proofs in a formal language, and which can then be checked automatically for correctness.
Interactive theorem provers offer a limited amount of automation, but projects that formalize com-
plex problems typically span many years of tedious work by specialists. Only in narrow domains

2

like chip design and the veriﬁcation of drivers in operating systems has the automation of logic made
sufﬁcient progress to ﬁnd commercial applications.

Progress in autoformalization and the automation of proofs might eventually make mathematics a
universally available tool and enable a paradigm shift in science and the development of (safety-
critical) software. Our interest in formalizing mathematics, however, has an additional aspect. We
believe that autoformalization will serve a dual purpose and will not only accelerate the development
of tools for mathematical reasoning, but also provide a means to ground machine learning systems,
enabling a positive feedback loop between machine learning and formal systems (cf. [44]).

Large Language Models Our work relies heavily on large language models (LLMs), in particular
on PaLM [9] and Codex [8]. The training goal of these models is to predict the next word given some
preﬁx. This allows us to train these models on arbitrary text, which is available in vast quantities.
After training the models on hundreds of billions of words (cf. [24]), they are often able to generate
high-quality text. We can also give these models an arbitrary preﬁx (the prompt) that they are
then supposed to continue, which gives us some control over what they generate. This has been
demonstrated with news articles, conversations, summaries, jokes, and poems. LLMs have also been
evaluated on natural language word problems on datasets such as GSM8K [10] and MATH [23], and
have been shown to make progress on these benchmarks with increasing scale [9].

In-context Learning Large language models have shown a remarkable ability to learn patterns
and tasks within the current input (context) that they are given [7]: this is called in-context learning
or few-shot learning. For example, if we prompt a language model with a few pairs of English and
matching French sentences, and end with a new English sentence, then the language model is very
likely to pick up on the translation task and attempt a translation of the last English sentence. This
observation has been used, for example, to achieve strong translation performance without access to
large corpora of matching sentence pairs [20].

This allows us to specify the task of autoformalization simply by giving a couple of example formal-
izations. In Section 4 we will detail how exactly we use in-context learning for autoformalization.

4 Autoformalization for Mathematical Competition Problems

Inspired by the success of LLMs for synthesizing computer code by co-training on both natural
language and code on web-scale data, we explore the capabilities of LLMs to turn natural language
mathematics into formalized theorems for the interactive theorem prover Isabelle. This can be seen
as a machine translation task (cf. [49]) in which the input language is English and output language
is formal code used by the interactive proof assistant Isabelle [50].

We ﬁrst study autoformalization in a constrained setting – formalizing mathematical competition
problem statements. This setting has the advantage that most of the required background theory and
deﬁnition has been formalized in the current libraries of Isabelle, so that formalizations are often
possible without introducing additional deﬁnitions.

We start assessing LLMs’ abilities to do autoformalization with a case study. We manually pick
two interesting natural language mathematical statements, and prompt PaLM models of various
scales [9] as well as Codex [8] to translate them into a formal statement in Isabelle. Next, we
study a dataset in which we have human ground truth formalizations. The dataset is a subset of the
miniF2F [23] dataset consisting of 140 algebra problems and 120 number theory problems. Using
human formalizations as the reference, we compute the BLEU scores of the formalizations produced
by several LLMs. Lastly, we perform human evaluations on failure cases in autoformalization on
150 problems.

Note that many mathematical competition statements are often of the form in which one asks to ﬁnd
the answer to a certain problem, instead of proving a given proposition. However, formal mathemat-
ical statements are in the form of propositions, instead of questions. To transform a question into a
proposition, we append the ﬁnal answer after the question:

$Problem_Statement The ﬁnal answer is $Answer.

3

1
Natural language version: "Let z = 1+i
i=1 2( 1
√2
answer is 36." Translate the natural language version to an Isabelle version:
theorem

(
P

, ﬁnd (

i=1 2(zi2

P

))

1

·

zi2 )). The ﬁnal

fixes z::complex
assumes h0: "z = (Complex (1/sqrt 2) (1/sqrt 2))"
shows "(\<Sum>k::nat=1..12. (z^(k^2)))

* (\<Sum> k::nat=1..12. 1/(z^(k^2)))=36"

Natural language version: "Determine the value of ab if log8 a + log4 b2 = 5 and log8 b +
log4 a2 = 7. The ﬁnal answer is 512". Translate the natural language version to an Isabelle
version:

theorem

fixes a b ::real
assumes "(ln a) / (ln 8) + (ln (b^2)) / (ln 4) = 5"
"(ln b) / (ln 8) + (ln (a^2)) / (ln 4) = 7"

shows "a * b = 512"

Figure 2: The two few-shot examplars used in case studies: both examples are merely an illustra-
tion of a syntactical translation from from LATEXto Isabelle, without much sophistication in natural
language understanding or reasoning.

The format of the prompt we use to do autoformalization is:

Natural language version: $Natural_Language_Statement.
Translate the natural language version to an Isabelle version:

4.1 Mathematical Competition Datasets

MATH [23] contains in total 12,500 (7,500 training and 5,000 test) middle school and high
school mathematical competition problems. Problems are taken from past mathematical com-
petitions,
including AMC 10, AMC 12, AIME, and more, and many can be found at
http://aops.com/community/c3158_usa_contests. The dataset contains seven categories:
algebra, pre-algebra, intermediate algebra, number_theory, precalculus, probabil-
ity, geometry. Problem statements are written in LaTeX.

MiniF2F [54] is a recently introduced benchmark containing 488 mathematical competition state-
ments manually formalized by humans in three different formal languages. Its goal is to compare
and benchmark methods across different theorem provers for machine learning research. Some of
these problems come from the valid and test set of MATH algebra and number_theory, and oth-
ers come from previous International Mathematical Olympiad competitions or AoPS1. Note that the
Isabelle formalizations of the miniF2F benchmark were committed to the repository during March,
2022. According to the public information on the large language models, we think it is highly
unlikely these formalizations were included in the pre-training corpus.

4.2 Case Studies

Experimental setup For all our experiments, we use the standard greedy decoding (i.e., temper-
ature 0, p = 1) to obtain the autoformalizations. We randomly select two mathematical statements
for constructing the prompt. No prompt engineering / tuning is performed when constructing the
prompt. The examples are shown in Figure 2. The natural language problem statements used in the
case studies are taken from the miniF2F dataset. In the case studies below, we highlight the output
of language models in red to distinguish it from the prompt.

1https://artofproblemsolving.com/

4

Case Study 2 Question:
Natural Language version: "When all
the girls at Madeline’s school line up
in rows of eight, there are seven left
over. If instead they line up in rows of
four, how many are left over? The ﬁnal
answer is 3." Translate the natural lan-
guage version to an Isabelle version:

PaLM output:
theorem

fixes n::nat
assumes "n mod 8 = 7"
shows "n mod 4 = 3"

Case Study 3 Question:
Natural language version: "Let f be a linear
function for which f (6)
f (2) = 12. What is
f (2)? The ﬁnal answer is 30." Trans-
f (12)
−
late the natural language version to an Isabelle
version:

−

Codex output:
theorem

fixes f :: "real \<Rightarrow> real"
assumes "linear f"

"f 6 - f 2 = 12"

shows "f 12 - f 2 = 30"

Figure 3: Autoformalizations from natural language to Isabelle code. Left: Case study 2 – perfect
formalization by PaLM. Right: Case study 3 – incorrect formalization by Codex.

Case Study 1 (Figure 1) We study the example shown in Figure 1, in which we ask LLMs to
autoformalize an International Mathematical Olympiad problem2 in natural language. Surprisingly,
Codex is able to autoformalize the natural language statement as an Isabelle theorem perfectly, with
output given. This is surprising for the following reasons.

First of all, the amount of Isabelle code is very scarce on the internet. The entire AFP library, the
largest formal library that contains most of Isabelle proofs, is only 180MB in size. Even assuming
that all of this data was included in the training of Codex, this makes at most 0.18% of the pretraining
data on which Codex was trained. The fact that the model can write syntactically correct Isabelle
code at all is already fascinating.

Second, there is almost zero aligned data from natural language to Isabelle on the web. While some
Isabelle ﬁles have comments, they typically only give a very high level description of what the theory
being formalized is about. So either LLMs are able to transfer knowledge quite successfully between
natural language and formal mathematics, or the task was learned mostly via few-shot learning.

Last but not least, the model is capable of understanding and formalizing nontrivial reasoning. First,
the model is able to formalize the non-existence statement via proof-by-contradiction. To formalize
“there is no function f ...”, it assumes there is such a function, and aims to prove “False”. Second,
the model understands what it means by the phrase “to itself”, and correctly infers the domain of
function: f :: "nat \<Rightarrow> nat".

On the other hand, PaLM made some syntactic mistakes while getting most of the structure of the
proof correctly, with outputs shown in Appendix B.1.

Case Study 2 (Figure 3)
In the next example, we ask LLMs to autoformalize a grade school
mathematical word problem. Remarkably, PaLM and Codex are both capable of formalizing the
statement perfectly. This is surprising because formalizations of grade school math problems in
interactive theorem provers are rare (if they exist at all), as this type of mathematics is not of interest
to formal mathematicians. Even more, none of the examples in the prompt (see Figure 2) that we
provide are of this type. It is hence remarkable that the model is capable of extrapolating to this type
of statement, showing a great promise of using LLMs for autoformalization.

To study this problem in more depth, we probe PaLM models of various sizes (8B, 64B, 540B) with
outputs shown in Appendix B.2, and notice that scale is crucial for the LLMs ability to formalize.
We observe that the 8B and 64B models are incapable of formalizing this problem, but the largest
540B model is able to produce a correct formalization.

Case Study 3 (Figure 3)
In our third case study, Codex gives an incorrect formalization in Is-
abelle. The mathematical statement involves a concept of “linear function”, which the model fails to

2A problem from IMO 1987.

5

Table 1: BLEU scores between the autoformalized statements and human formalized ground truth.

Subject

Models

\
PaLM 8B
PaLM 64B
PaLM 540B
Codex

algebra

number_theory

31.49
43.13
50.30
57.13

22.10
31.43
36.16
43.33

formalize correctly. Codex assumes this is already a known concept in Isabelle, and made up a name:
linear f. Can the model learn to formalize such problems if the prompt contains an example that
explains the concept of a line? We explore this and give an afﬁrmative answer to the question (see
Appendix B.3). Once seeing a tangentially related problem that explains the concept of a “line”,
Codex is able to perfectly formalize a “linear function”. This shows the importance of the few shot
examples we include, and also how good a few-shot learners these models are!

Has the model memorized these formalizations? Whilst we do not have access to the training set
of Codex, we attempted to ﬁnd any occurrences of the formalizations produced in the case studies
on the internet. We Googled them in different variants and inspected the ﬁrst page of the search
results. We tried variants with and without an “Isabelle” preﬁx, with and without quotation marks
and other special characters, and also individual parts of it, such as “Isabelle "n mod 8 = 7"”,
but we did not ﬁnd any occurrences of related statements. We also tested that we are indeed able
to ﬁnd occurrences of Isabelle formalizations on the web with this methodology, using pieces of
formalizations picked from several websites, including the Archive of Formal Proofs. Hence, we
are conﬁdent that the model has not memorized the formalizations it generated.

4.3 BLEU for Model Comparisons

The miniF2F benchmark contains 140 algebra problems and 120 number theory problems from
the MATH dataset. For these problems, we have human ground truth formalizations in Isabelle,
which gives us an evaluation set with pairs of natural language statements (from MATH) and their
formalizations. We use this dataset to quantitatively compare different LLMs.

Given the observation about few shot learning in Case study 3, we decided to add more relevant ex-
amples to each subject to improve the quality of autoformalization. For each subject (i.e., algebra
and number_theory), we randomly sample 10 problems to construct the few shot prompt. The rest
of the problems are used for evaluation (i.e., 130 for algebra and 110 for number_theory. We
provide the prompt used in the Appendix A.1 and A.2.

We use PaLM models of varying sizes and Codex to perform the autoformalization, and compute the
BLEU scores of the formalizations, shown in Table 1. Conﬁrming our observation in Case study 2,
we see a clear trend that scaling improves translation, as the BLEU scores consistently improve
when we scale PaLM models from 8B to 540B, for both subjects. In addition, we see that the Codex
model is better at autoformalization measured by BLEU, possibly due to the fact that Codex was
trained on more formal data than PaLM.

4.4 Human Evaluation of Failure cases

To better understand LLMs’ ability to do autoformalization, we manually inspect Codex’s autofor-
malizations of 150 random problems from the MATH dataset [23]. 50 of the problem statements
are sampled from the algebra training set, 50 from number_theory and 50 from intermedi-
ate_algebra. For algebra and number_theory, we use their corresponding prompt as in the
last section, shown in Appendix A.1 and A.2. For intermediate_algebra, we use the prompt we
used for algebra (Appendix A.1). We classify the failure modes of these translations, shown in
Table 2.

We see that out of 150 problems, Codex is capable of translating 38 problems perfectly – a success
rate of 25.3%. The majority of the failures are due to the misalignment of informal and formal def-
initions. For example, when seeing the phrase “the greatest possible value”, the LLMs often fail to
align it with the function Greatest/Max in Isabelle. Another example is the failure to align the fac-

6

Table 2: Failure case study of 150 problems formalized by Codex.

Failure cases

Subjects

algebra

number_theory

inter_alg

\

Perfect translation
Incomplete/ill-formed/unclear prompt
Fail to align deﬁnitions or concepts
Inconsistent/missing assumption
Syntactical/type error
Missing deﬁnition in Isabelle
Wrong application of functions
Other

13
9
10
8
7
0
6
6

17
3
18
9
2
12
13
2

8
14
18
9
11
3
16
1

torial of n (i.e., !n) to fact n in Isabelle. Other common failure modes include the misapplication
of functions (e.g., applying a preﬁx function in an inﬁx way).

5 Autoformalization for Neural Theorem Proving

To demonstrate the usefulness of the formalized statements, we explore if one can improve neural
theorem provers by training the neural models on proofs of automatically translated theorems. In
this section, we combine autoformalization with expert iteration algorithms [3], and achieve a new
state of the art in miniF2F benchmark.

5.1 Expert Iteration with Autoformalization

The basic idea of expert iteration [3] is to iteratively generate a better dataset using the model, and
use the data to improve the model quality. This allows the model to generate an even better quality
of the dataset and hence a better model, forming a self-improvement cycle.

In neural theorem proving, one way to get better quality data is to use feedback from the proof
checker to run many proof searches (or generate multiple proofs) and check the proof attempts for
correctness. Newly found correct proofs can then be used as the new training data to improve the
neural prover [6, 37, 38]. The main critical ingredient that is needed is a set of problem statements
on which the model can perform proof search to obtain new training data. However, unlike in Polu
et al. [38], where one asks humans to manually formalize a set of problems to get formal statements,
here we use LLMs to autoformalize the theorems in order to kick off the self-improvement cycle.

A
−

More formally, denote a base neural theorem prover as M0. Let the set of autoformalized problems
. For each iteration i = 1 . . . N , we carry out the following procedure: use the language model
be
, collect the set of successful
1 with best-ﬁrst search to prove as many theorems as possible in
Mi
proofs Si, concatenate successful problems from all iterations with the formal mathematics problems
, and ﬁne-tune M0 on it for exactly one epoch to get a new model
to create the set
j
Mi. When we take the union of successful proofs from all past iterations, we perform deduplication
S
by problem statements, similar to Polu et al. [38].

i Si)

i = (

∪B

A

A

≤

5.2 Neural Theorem Provers

To demonstrate the effectiveness of the approach, we start with a recently introduced neural theorem
prover for Isabelle, Thor [26]. The Thor agent is ﬁne-tuned on the PISA dataset [25] (extraction
and interaction code under a BSD license), which consists of 2.49 million proof steps from the Is-
abelle/HOL library (under a BSD-style license) and the Archive of Formal Proofs (under various
licenses as described here). The model is trained with the objective to predict the next token in
a proof step, given the proof state and the last proof step. When the ground truth proof step con-
tains any of the keywords metis, meson, and smt, the model learns to predict a special token
<hammer>. In evaluation, whenever the special token is emitted, Thor invokes the proof method
Sledgehammer [36] in Isabelle with a 30 second timeout.

We use a pre-trained and ﬁne-tuned Thor agent as the base model (M0). The agent’s language model
uses Wang [47]’s implementation (under an Apache license 2.0) of a GPT-2 [40] style decoder-only

7

Table 3: Proof success rates on miniF2F.

Model

PACT [21]
FMSCL [38]
Base model (M0) [26]
After 1 expert iteration (M1)
After 2 expert iterations (M2)

valid

test

23.9% 24.6%
33.6% 29.6%
28.3% 29.9%
36.1% 34.0%
37.3% 35.2%

transformer [46] model with 700M non-embedding parameters. The model has 24 layers, 24 atten-
tion heads, a hidden dimension of 1536, and a vocabulary size of 50400. It uses the AdamW [35]
optimizer and is pre-trained on the GitHub + arXiv subsets of The Pile [13] for 200,000 steps, with
a context length of 2048 tokens. In pre-training a warmup strategy [17] raises the learning rate lin-
4 in 3,000 steps. Then a cosine learning rate scheduler [34] is used for the
early from 0 to 2
5. The training has a global batch
rest of the pre-training, with a ﬁnal learning rate of 1.2
10−
size of 32 sequences, or 65,536 tokens. For ﬁne-tuning the learning rate strategy is the same, with
4 and ﬁnal learning
10,000 warmup steps, 90,000 annealing steps, maximum learning rate 3
5. The global batch size is 144 sequences, or 294,912 tokens. The model’s evaluation
rate 3
loss reaches a minimum after 13,000 steps and that checkpoint is used.

10−

10−

10−

×

×

×

×

Machine speciﬁcation For experiments in this paper, we use a TPUv3 with 8 cores from Google
Cloud Platform. The Isabelle process has access to up to 32 CPU cores. Running all the experiments
in this paper requires a total of 3920 TPU hours. Of the 3920 TPU hours, 3200 are for running the
proof search on the autoformalized theorems, 240 are for training the model on the successful proofs,
and 480 are for evaluating the model on miniF2F.

5.3 Result

We use Codex with greedy decoding to formalize 3908 mathematical problems in algebra, inter-
mediate algebra, and number theory from the training set of MATH [23], with the same few shot
prompts used in Section 4.4. Out of them, 3363 of the autoformalized theorems are syntactically
correct. We then perform expert iteration on this dataset.

We start with a neural theorem prover (M0) as described in Section 5.2. In our ﬁrst iteration, M0
proves 782 theorems, with a success rate of 23.3% (out of 3363). This gives us a new set of veriﬁed
proofs to further train the neural theorem prover. We proceed to ﬁne-tune our neural theorem prover
in the fashion described in Section 5.1 to get a new prover (M1). This process is repeated in the
second iteration, giving us 1011 successful proofs from the autoformalized theorems (30.1%). We
ﬁne-tuned M0 again, but on the deduplicated concatenation of problems from PISA and successful
proofs found for the autoformalized theorems.

After each stage of ﬁne-tuning, we evaluate the neural theorem prover on miniF2F [54]. The results
are shown in Table 3. The base model (M0) has a success rate of 28.3% and 29.9% on the validation
and test fractions of miniF2F respectively. It can be observed that the ﬁrst expert iteration increases
the success rate of the neural prover by 7.8% and 4.1% to 36.1% and 34.0% on the valid and test
sets. The second iteration further improves them both by 1.2%, to 37.3% and 35.2%. By doing two
expert iterations on the autoformalized theorems, the neural prover achieves a success rate that is
5.6% higher than the previous state-of-the-art.

6 An Outlook on Autoformalizing Advanced Mathematics

So far, we focused on mathematical competition problems, in which we achieve signiﬁcant results
using autoformalization. Not only can LLMs autoformalize non-trivial theorems, the autoformalized
theorems can also improve neural prover performance. In this section, we take a peek into more
advanced mathematics. We hope to identify some of the limitations of our methods when it comes
to autoformalizing mathematics in the wild.

8

Question: An arbitrary product of compact spaces is compact.

Codex Output:
theorem

fixes X :: "’a set set"
assumes "\<forall>x \<in>X. compact x"
shows "compact (\<Prod> x \<in> X. x)"

Figure 4: A formalization for an advanced mathematical statement by Codex.

6.1 Autoformalization: from Natural Language to Isabelle

Autoformalization is extremely challenging in the sense that the model needs to (1) bridge the log-
ical gaps left in pen-and-paper proofs, (2) assume the implicit contexts and assumptions, and (3)
align informal deﬁnitions/concepts to formal ones. This task is further complicated considering the
context can change from time to time and the same mathematical object can be formalized in subtly
different ways. In this paper, we only deal with autoformalization of theorem statements, where
the model is mainly challenged by deﬁnition alignments. Compared to competition problems in
Section 4.4, advanced mathematical statements assume more context information that additionally
obscures the alignment.

Figure 4 shows a typical case where the model fails to align the informal deﬁnition to the formal
one. Based on the notation used, the model does not correctly distinguish between products of
numbers, products of sets, and products of topological spaces. In Isabelle, the correct conclusion
for the statement should be compact_space (product_topology X I), where I is an index set that
ought to have been introduced in the fixes and assumes sections.

6.2 Informalization: from Isabelle to Natural Language

So far, we explored one direction of translation: from natural language statement to formal statement
in Isabelle. The other direction, informalization, is also of great importance for two reasons: (1)
the informal texts are much easier for humans to comprehend and communicate, and (2) we can
align translated informal statements with formal ones to create data, and use the back-translation
techniques [43] to potentially boost the translator’s performance further. In this section, we explore
Codex’s capability of translating formal Isabelle statement to natural language.

A corpus of 38 formal-language theorems, lemmas, and deﬁnitions is selected by an Isabelle ex-
pert. These statements are automatically translated to informal mathematics using Codex; to see the
prompt we used and the results for all 38 examples, see Appendix A.3 and D.2. We present two
examples of informalization in Figure 5. Of the 38 examples, 36 were translated to a reasonably co-
herent statement, and 29 of these statements (76%) were more-or-less correct, giving a vastly better
success rate than the 25% success rate of formalization (Section 4.4). Our main conclusion is that
for advanced mathematics, the model is better at informalization than formalization, showing the
prospect of backtranslation style algorithms.

Note that the standard is more relaxed here since we assume a human reader will supply the obvious
context and correct mistakes when the intended meaning is obvious (intended by the hypothetical
human writer of these sentences). To illustrate, an example of a minor “acceptable” error: assum-
ing that “w, z are in the same connected component of the plane” when, in context, it is clear that
w, z should be assumed to be in the same connected component of the complement of a previously
speciﬁed curve. (The assumption as originally stated is trivial.) For an example of a major error:
almost-perfect translation of the Central Limit Theorem that omits the assumption of identical dis-
tributions.

9

lemma seteqI:

" [[Vx. x ∈A =⇒ x ∈B;

Vx. x ∈B =⇒ x ∈A ]]
=⇒ A = B"

Translate the Isabelle ver-
sion to a natural language
version:

Codex Output:
"If A and B are sets such
that A
A,
then A = B."

B and B

⊆

⊆

lemma topologyI:

" [[ V x y. [[ is_open T x; is_open T y ]] =⇒

is_open T (x ∩ y);

V M. ∀ m ∈ M. is_open T m =⇒

is_open T (S M)

]] =⇒ topology T"

Translate the Isabelle version to a natural language
version:

Codex Output:
"If T is a set and T is closed under ﬁnite intersec-
tions and arbitrary unions, then T is a topology."

Figure 5: Two perfect translations from Isabelle code to natural language by Codex.

7 Discussion

Promise of Autoformalization with LLMs We have seen that automated formalization of infor-
mally given natural language statements is generally possible, even with language models not trained
for this particular task. Also, automatically formalized statements are useful for training and improv-
ing the reasoning capabilities of automated neural provers. Our hope is that improved versions of
this methodology will be capable of enabling a positive feedback loop involving formalization and
formal reasoning that has the potential of reaching human level capabilities in both respects, as was
suggested by [44].

Limitations and future directions We use a static model for the formalization process. For large-
scale autoformalization, we will need to formalize larger theories, preferably without ﬁne tuning the
model, as training it could be cumbersome and resource consuming. However, in order to utilize
the newly added notions, the model would need to keep whole large theories in the current con-
text window, which exceeds those of the current LLMs. This limits our approach to the generation
of fairly small pieces of formal mathematics and the automatic formalization of entire theories in-
cluding their deﬁnitions will require new research ideas. One path towards this goal might be the
use of continuous training or expert iteration, cycle-consistency-based training [30, 48], or novel
uses of in-context learning. To generate larger theories we will also need neural networks that can
recall longer sequences (current LLMs are typically limited to a few thousand words). Retrieval-
augmented language models, such as the memorizing transformer [53] offer one path to overcome
this limitation.

Societal Impact While the potential of creating negative societal impact through formalizations is
small, the use of LLMs always comes with risks. For example, for deploying an autoformalization
tool using LLMs we would need to consider the inclusivity of variable and lemma names, and of the
attribution of scientiﬁc ideas.

References

[1] Alexander A. Alemi, François Chollet, Niklas Eén, Geoffrey Irving, Christian Szegedy, and
Josef Urban. Deepmath - deep sequence models for premise selection.
In Daniel D. Lee,
Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon, and Roman Garnett (eds.), Advances
in Neural Information Processing Systems 29: Annual Conference on Neural Information
Processing Systems 2016, December 5-10, 2016, Barcelona, Spain, pp. 2235–2243, 2016. URL
http://papers.nips.cc/paper/6280-deepmath-deep-sequence-models-for-premise-selection.

[2] Marcin Andrychowicz, Dwight Crow, Alex Ray, Jonas Schneider, Rachel Fong, Peter
Welinder, Bob McGrew, Josh Tobin, Pieter Abbeel, and Wojciech Zaremba. Hindsight
experience replay.
In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wal-
lach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett (eds.), Advances in Neural
Information Processing Systems 30: Annual Conference on Neural Information Processing

10

Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pp. 5048–5058, 2017. URL
https://proceedings.neurips.cc/paper/2017/hash/453fadbd8a1a3af50a9df4df899537b5-Abstract.html.

[3] Thomas Anthony, Zheng Tian, and David Barber.

Thinking fast and slow with deep
learning and tree search. In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M.
Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett (eds.), Advances in
Neural Information Processing Systems 30: Annual Conference on Neural Information Pro-
cessing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pp. 5360–5370, 2017. URL
https://proceedings.neurips.cc/paper/2017/hash/d8e1344e27a5b08cdfd5d027d9b8d6de-Abstract.html.

[4] Eser Aygün, Laurent Orseau, Ankit Anand, Xavier Glorot, Vlad Firoiu, Lei M. Zhang, Doina
Precup, and Shibl Mourad. Proving theorems using incremental learning and hindsight experi-
ence replay. CoRR, abs/2112.10664, 2021. URL https://arxiv.org/abs/2112.10664.

[5] Kshitij Bansal, Sarah M. Loos, Markus N. Rabe, and Christian Szegedy.

CoRR, abs/1905.10501, 2019.

Learning
URL

to reason in large theories without
http://arxiv.org/abs/1905.10501.

imitation.

[6] Kshitij Bansal, Sarah M. Loos, Markus N. Rabe, Christian Szegedy, and Stewart Wilcox.
Holist: An environment for machine learning of higher order logic theorem proving. In Kama-
lika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Con-
ference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA,
volume 97 of Proceedings of Machine Learning Research, pp. 454–463. PMLR, 2019. URL
http://proceedings.mlr.press/v97/bansal19a.html.

[7] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhari-
wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agar-
wal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh,
Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler,
Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCan-
dlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learn-
ers. In NeurIPS, 2020.

[8] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared
Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul
Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke
Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad
Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias
Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex
Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,
William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua Achiam, Vedant
Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie
Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and
Wojciech Zaremba. Evaluating large language models trained on code. CoRR, abs/2107.03374,
2021. URL https://arxiv.org/abs/2107.03374.

[9] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam
Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker
Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes,
Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson,
Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,
Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier
Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David
Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan,
Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai,
Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Kather-
ine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele
Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah
Fiedel. PaLM: Scaling language modeling with pathways. CoRR, abs/2204.02311, 2022. doi:
10.48550/arXiv.2204.02311. URL https://doi.org/10.48550/arXiv.2204.02311.

11

[10] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christo-
pher Hesse, and John Schulman. Training veriﬁers to solve math word problems. CoRR,
abs/2110.14168, 2021. URL https://arxiv.org/abs/2110.14168.

[11] Coq. The Coq Proof Assistant. http://coq.inria.fr. URL http://coq.inria.fr.

[12] Leonardo Mendonça de Moura, Soonho Kong, Jeremy Avigad, Floris van Doorn, and Jakob
von Raumer. The lean theorem prover (system description). In Amy P. Felty and Aart Middel-
dorp (eds.), Automated Deduction - CADE-25 - 25th International Conference on Automated
Deduction, Berlin, Germany, August 1-7, 2015, Proceedings, volume 9195 of Lecture Notes in
Computer Science, pp. 378–388. Springer, 2015. doi: 10.1007/978-3-319-21401-6\_26. URL
https://doi.org/10.1007/978-3-319-21401-6_26.

[13] Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason
Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. The Pile:
An 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:2101.00027,
2020.

[14] Thibault Gauthier, Cezary Kaliszyk, Josef Urban, Ramana Kumar, and Michael Norrish.
Tactictoe: Learning to prove with tactics. J. Autom. Reason., 65(2):257–286, 2021. doi:
10.1007/s10817-020-09580-x. URL https://doi.org/10.1007/s10817-020-09580-x.

[15] Georges Gonthier. The four colour theorem: Engineering of a formal proof. In Deepak Kapur
(ed.), Computer Mathematics, 8th Asian Symposium, ASCM 2007, Singapore, December 15-
17, 2007. Revised and Invited Papers, volume 5081 of Lecture Notes in Computer Science, pp.
333. Springer, 2007. doi: 10.1007/978-3-540-87827-8\_28.

[16] Georges Gonthier, Andrea Asperti, Jeremy Avigad, Yves Bertot, Cyril Cohen, François Garil-
lot, Stéphane Le Roux, Assia Mahboubi, Russell O’Connor, Sidi Ould Biha, Ioana Pasca, Lau-
rence Rideau, Alexey Solovyev, Enrico Tassi, and Laurent Théry. A machine-checked proof
of the odd order theorem. In Sandrine Blazy, Christine Paulin-Mohring, and David Pichardie
(eds.), Interactive Theorem Proving - 4th International Conference, ITP 2013, Rennes, France,
July 22-26, 2013. Proceedings, volume 7998 of Lecture Notes in Computer Science, pp. 163–
179. Springer, 2013. doi: 10.1007/978-3-642-39634-2\_14.

[17] Priya Goyal, Piotr Dollár, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola,
Andrew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training
imagenet in 1 hour. arXiv preprint arXiv:1706.02677, 2017.

[18] Christopher Hahn, Frederik Schmitt, Jens U. Kreber, Markus N. Rabe, and Bernd Finkbeiner.

Teaching temporal logics to neural networks. In ICLR, 2021.

[19] Thomas Hales, Mark Adams, Gertrud Bauer, Tat Dat Dang, John Harrison, Hoang Le Truong,
Cezary Kaliszyk, Victor Magron, Sean McLaughlin, Tat Thang Nguyen, et al. A formal proof
of the Kepler conjecture. In Forum of Mathematics, Pi, volume 5, pp. e2. Cambridge Univer-
sity Press, 2017.

[20] Jesse Michael Han, Igor Babuschkin, Harrison Edwards, Arvind Neelakantan, Tao Xu, Stanis-
las Polu, Alex Ray, Pranav Shyam, Aditya Ramesh, Alec Radford, and Ilya Sutskever.
Unsupervised neural machine translation with generative language models only. CoRR,
abs/2110.05448, 2021. URL https://arxiv.org/abs/2110.05448.

[21] Jesse Michael Han, Jason Rute, Yuhuai Wu, Edward Ayers, and Stanislas Polu. Proof artifact
co-training for theorem proving with language models. In International Conference on Learn-
ing Representations, 2022. URL https://openreview.net/forum?id=rpxJc9j04U.

[22] John Harrison. HOL Light: A tutorial introduction. In Mandayam K. Srivas and Albert John
Camilleri (eds.), Formal Methods in Computer-Aided Design, First International Conference,
FMCAD ’96, Palo Alto, California, USA, November 6-8, 1996, Proceedings, volume 1166 of
Lecture Notes in Computer Science, pp. 265–269. Springer, 1996.

[23] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn
Song, and Jacob Steinhardt. Measuring mathematical problem solving with the MATH dataset.
CoRR, abs/2103.03874, 2021. URL https://arxiv.org/abs/2103.03874.

12

[24] Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza
Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom
Hennigan, Eric Noland, Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia
Guy, Simon Osindero, Karen Simonyan, Erich Elsen, Jack W. Rae, Oriol Vinyals, and Laurent
Sifre. Training compute-optimal large language models. CoRR, abs/2203.15556, 2022. doi:
10.48550/arXiv.2203.15556. URL https://doi.org/10.48550/arXiv.2203.15556.

[25] Albert Q. Jiang, Wenda Li, Jesse Michael Han, and Yuhuai Wu. Lisa: Language models of

isabelle proofs. 6th Conference on Artiﬁcial Intelligence and Theorem Proving, 2021.

[26] Albert Q. Jiang, Szymon Tworkowski Wenda Li, Konrad Czechowski, Tomasz Odrzygó´zd´z,
Piotr Miło´s, Yuhuai Wu, and Mateja Jamnik. Thor: Wielding hammers to integrate lan-
guage models and automated theorem provers. arXiv preprint arXiv:2205.10893, 2022. URL
https://arxiv.org/abs/2205.10893.

[27] Gerwin Klein, Kevin Elphinstone, Gernot Heiser, June Andronick, David Cock, Philip Derrin,
Dhammika Elkaduwe, Kai Engelhardt, Rafal Kolanski, Michael Norrish, Thomas Sewell, Har-
vey Tuch, and Simon Winwood. seL4: formal veriﬁcation of an OS kernel. In Jeanna Neefe
Matthews and Thomas E. Anderson (eds.), Proceedings of the 22nd ACM Symposium on Op-
erating Systems Principles 2009, SOSP 2009, Big Sky, Montana, USA, October 11-14, 2009,
pp. 207–220. ACM, 2009. doi: 10.1145/1629575.1629596.

[28] Gerwin Klein, June Andronick, Matthew Fernandez, Ihor Kuz, Toby C. Murray, and Gernot
Heiser. Formally veriﬁed software in the real world. Commun. ACM, 61(10):68–77, 2018. doi:
10.1145/3230627. URL https://doi.org/10.1145/3230627.

[29] Jens U. Kreber and Christopher Hahn. Generating symbolic reasoning problems with trans-
former GANs. CoRR, abs/2110.10054, 2021. URL https://arxiv.org/abs/2110.10054.

[30] Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc’Aurelio Ranzato. Un-
In 6th International
ICLR 2018, Vancouver, BC, Canada, April
URL

supervised machine translation using monolingual corpora only.
Conference on Learning Representations,
30 - May 3, 2018, Conference Track Proceedings. OpenReview.net, 2018.
https://openreview.net/forum?id=rkYTTf-AZ.

[31] Gil Lederman, Markus N. Rabe, Sanjit Seshia, and Edward A. Lee. Learning heuristics for
quantiﬁed boolean formulas through reinforcement learning. In 8th International Conference
on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenRe-
view.net, 2020. URL https://openreview.net/forum?id=BJluxREKDB.

[32] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond,
Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cy-
prien de Masson d’Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl,
Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Rob-
son, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, and Oriol Vinyals. Competition-
level code generation with alphacode. DeepMind, 2022.

[33] Sarah M. Loos, Geoffrey Irving, Christian Szegedy, and Cezary Kaliszyk. Deep network
guided proof search. In Thomas Eiter and David Sands (eds.), LPAR-21, 21st International
Conference on Logic for Programming, Artiﬁcial Intelligence and Reasoning, Maun, Botswana,
May 7-12, 2017, volume 46 of EPiC Series in Computing, pp. 85–105. EasyChair, 2017. doi:
10.29007/8mwc. URL https://doi.org/10.29007/8mwc.

[34] Ilya Loshchilov and Frank Hutter.

SGDR: stochastic gradient descent with warm
In 5th International Conference on Learning Representations, ICLR 2017, Toulon,
restarts.
France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net, 2017. URL
https://openreview.net/forum?id=Skq89Scxx.

[35] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In 7th International
Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019.
OpenReview.net, 2019. URL https://openreview.net/forum?id=Bkg6RiCqY7.

13

[36] Lawrence Paulson and Jasmin Blanchette. Three years of experience with sledgehammer, a
practical link between automatic and interactive theorem provers. 02 2015. doi: 10.29007/tnfd.

[37] Stanislas Polu and Ilya Sutskever. Generative language modeling for automated theorem prov-

ing. CoRR, abs/2009.03393, 2020. URL https://arxiv.org/abs/2009.03393.

[38] Stanislas Polu, Jesse Michael Han, Kunhao Zheng, Mantas Baksys, Igor Babuschkin,
Formal mathematics statement curriculum learning, 2022. URL

and Ilya Sutskever.
https://arxiv.org/abs/2202.01344.

[39] Markus N. Rabe, Dennis Lee, Kshitij Bansal, and Christian Szegedy. Mathematical reasoning

via self-supervised skip-tree training. In ICLR, 2021.

[40] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al.

Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.

[41] Frederik Schmitt, Christopher Hahn, Markus N. Rabe, and Bernd Finkbeiner. Neural
circuit synthesis from speciﬁcation patterns.
In Marc’Aurelio Ranzato, Alina Beygelzimer,
Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan (eds.), Advances in Neural
Information Processing Systems 34: Annual Conference on Neural Information Processing
Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pp. 15408–15420, 2021. URL
https://proceedings.neurips.cc/paper/2021/hash/8230bea7d54bcdf99cdfe85cb07313d5-Abstract.html.

[42] Stephan Schulz. Learning search control knowledge for equational theorem proving. In Franz
Baader, Gerhard Brewka, and Thomas Eiter (eds.), KI 2001: Advances in Artiﬁcial Intelligence,
Joint German/Austrian Conference on AI, Vienna, Austria, September 19-21, 2001, Proceed-
ings, volume 2174 of Lecture Notes in Computer Science, pp. 320–334. Springer, 2001. doi:
10.1007/3-540-45422-5\_23.

[43] Rico Sennrich, Barry Haddow, and Alexandra Birch. Improving neural machine translation
models with monolingual data. In Proceedings of the 54th Annual Meeting of the Association
for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1:
Long Papers. The Association for Computer Linguistics, 2016. doi: 10.18653/v1/p16-1009.
URL https://doi.org/10.18653/v1/p16-1009.

[44] Christian Szegedy. A promising path towards autoformalization and general artiﬁcial intelli-
gence. In Christoph Benzmüller and Bruce R. Miller (eds.), Intelligent Computer Mathematics
- 13th International Conference, CICM 2020, Bertinoro, Italy, July 26-31, 2020, Proceedings,
volume 12236 of Lecture Notes in Computer Science, pp. 3–20. Springer, 2020. doi: 10.1007/
978-3-030-53518-6\_1. URL https://doi.org/10.1007/978-3-030-53518-6_1.

[45] Josef Urban. MPTP - motivation, implementation, ﬁrst experiments. J. Autom. Reason., 33

(3-4):319–339, 2004. doi: 10.1007/s10817-004-6245-1.

[46] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N.
Gomez, Lukasz Kaiser, and Illia Polosukhin.
In Is-
abelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus,
S. V. N. Vishwanathan, and Roman Garnett (eds.), Advances in Neural Information
Information Processing Sys-
Processing Systems 30: Annual Conference on Neural
tems 2017, December 4-9, 2017, Long Beach, CA, USA, pp. 5998–6008, 2017. URL
https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html.

Attention is all you need.

[47] Ben Wang. Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer Lan-
guage Model with JAX. https://github.com/kingoflolz/mesh-transformer-jax,
May 2021.

[48] Qingxiang Wang, Cezary Kaliszyk, and Josef Urban. First experiments with neural translation
of informal to formal mathematics. In Florian Rabe, William M. Farmer, Grant O. Passmore,
and Abdou Youssef (eds.), Intelligent Computer Mathematics - 11th International Conference,
CICM 2018, Hagenberg, Austria, August 13-17, 2018, Proceedings, volume 11006 of Lecture
Notes in Computer Science, pp. 255–270. Springer, 2018. doi: 10.1007/978-3-319-96812-4\
_22. URL https://doi.org/10.1007/978-3-319-96812-4_22.

14

[49] Qingxiang Wang, Chad Brown, Cezary Kaliszyk, and Josef Urban. Exploration of neural
machine translation in autoformalization of mathematics in mizar. In International Conference
on Certiﬁed Programs and Proofs, 2020.

[50] Makarius Wenzel, Lawrence C. Paulson, and Tobias Nipkow. The Isabelle framework.

In
Otmane Aït Mohamed, César A. Muñoz, and Soﬁène Tahar (eds.), Theorem Proving in Higher
Order Logics, 21st International Conference, TPHOLs 2008, Montreal, Canada, August 18-21,
2008. Proceedings, volume 5170 of Lecture Notes in Computer Science, pp. 33–38. Springer,
2008. doi: 10.1007/978-3-540-71067-7\_7.

[51] Minchao Wu, Michael Norrish, Christian Walder,

Learning to prove theorems from scratch with deep reinforcement

Tac-
learn-
In Marc’Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang,
in Neural
Information Process-
Information Processing Systems
URL

ticzero:
ing.
and Jennifer Wortman Vaughan (eds.), Advances
ing Systems 34:
Annual Conference on Neural
2021, NeurIPS 2021, December 6-14, 2021, virtual, pp. 9330–9342, 2021.
https://proceedings.neurips.cc/paper/2021/hash/4dea382d82666332fb564f2e711cbc71-Abstract.html.

and Amir Dezfouli.

[52] Yuhuai Wu, Albert Jiang, Jimmy Ba, and Roger Baker Grosse. INT: an inequality benchmark
for evaluating generalization in theorem proving. In 9th International Conference on Learning
Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021.
URL https://openreview.net/forum?id=O6LPudowNQm.

[53] Yuhuai Wu, Markus N Rabe, DeLesley Hutchins, and Christian Szegedy. Memorizing trans-
formers. In 10th International Conference on Learning Representations, ICLR 2022. OpenRe-
view.net, 2022.

[54] Kunhao Zheng, Jesse Michael Han, and Stanislas Polu. MiniF2F: a cross-system benchmark

for formal olympiad-level mathematics. arXiv preprint arXiv:2109.00110, 2021.

15

Appendix

A Few-shot Prompts

A.1 Prompt used to formalize algebra problems

Natural language version: "Simplify
Translate the natural language version to an Isabelle version:

−
(cid:1)

−
(cid:1)

(cid:17)

(cid:16)

(cid:0)

(cid:0)

1
2x

4
x

1

3x3
x

2

3. The ﬁnal answer is 18x8".

theorem

fixes x :: real
assumes h0 : "x \<noteq> 0"
shows "1/(4/x) * ((3*x^3)/x)^2 * (1/(1 / (2 * x)))^3 = 18 * x^8"

Natural language version: "For integers n, let

f (n) =

(cid:26)

n2

n2
4n

if n is odd,
if n is even.

1

−
Find f (f (f (f (f (4))))). The ﬁnal answer is 1". Translate the natural language version to an
Isabelle version:

−

theorem

fixes f :: "int \<Rightarrow> int"
assumes "\<forall>n. odd n \<longrightarrow> f n = n^2"

and "\<forall> n. even n \<longrightarrow> f n = n^2 - 4*n -1"

shows "f 4 = -1"

Natural language version: "The volume of a cone is given by the formula V = 1
3 Bh, where
B is the area of the base and h is the height. The area of the base of a cone is 30 square
units, and its height is 6.5 units. What is the number of cubic units in its volume? The ﬁnal
answer is 65". Translate the natural language version to an Isabelle version:

theorem

fixes b h v ::real
assumes "0 < b \<and> 0 < h \<and> 0 < v"

and "v = 1 / 3 * (b * h)"
and "b = 30"
and "h = 13 / 2"

shows "v = 65"

Natural language version: "If 3a + b + c =
abc. The ﬁnal answer is -56".
Translate the natural language version to an Isabelle version:

−

3, a + 3b + c = 9, a + b + 3c = 19, then ﬁnd

theorem

fixes a b c :: real
assumes "3 * a + b + c = -3"
and "a + 3 * b + c = 9"
and "a + b + 3 * c = 19"

shows "a * b * c = -56"

16

Natural language version: "If f (x) = 5x
The ﬁnal answer is 47

−

24 ". Translate the natural language version to an Isabelle version:

12, ﬁnd a value for x so that f −

1(x) = f (x + 1).

theorem

fixes x :: real and \<sigma>::"real \<Rightarrow> real"
assumes "bij \<sigma>"

and \<sigma>:"\<forall> x. \<sigma> x = 5 * x - 12"
and "\<sigma> (x + 1) = (inv \<sigma>) x"

shows "x = 47 / 24"

Natural language version: "What is the x-coordinate for the x-intercept of the line containing
the points (7, 4) and (6, 3)? The ﬁnal answer is 3". Translate the natural language version
to an Isabelle version:

theorem

fixes a b :: real

and f :: "real \<Rightarrow> real"
assumes h0 : "\<And>x. f x = a * x + b"

and h1 : "f 7 = 4"
and h2 : "f 6 = 3"

shows "f 3 = 0"

Natural language version: "Given 2a = 32 and ab = 125 ﬁnd ba. The ﬁnal answer is 243".
Translate the natural language version to an Isabelle version:

theorem

fixes a b :: real
assumes "2 powr a = 32"
and "a powr b = 125"
shows "b powr a = 243"

Natural language version: "Let

f (x) =

x2 + 9
3x

(cid:26)

if x <

5,
5.

−
≥ −

8 if x

−
If f (x) = 10, ﬁnd the sum of all possible values of x. The ﬁnal answer is 6". Translate the
natural language version to an Isabelle version:

theorem

fixes f :: "real \<Rightarrow> real"
assumes "\<forall> x < -5. f x = x^2 + 5"

and "\<forall> x \<ge> -5. f x = 3 * x -8"
shows "(\<Sum> k \<in> (f -‘ {10}). k) = 6"

Natural language version: "Simplify (9
3
(
−
the natural language version to an Isabelle version:

4i)

−

−

4i). The ﬁnal answer is 12". Translate

−

theorem

fixes q e :: complex
assumes h0 : "q = Complex (Re 9) (Im (-4))"
and h1 : "e = Complex (Re (-3)) (Im (-4))"

shows "q - e = 12"

Natural language version: "What is the minimum possible value for y in the equation y =
x2
Translate the natural language version to an Isabelle version:

6x + 13? The ﬁnal answer is 4".

−

theorem

fixes x y :: real
assumes h0 : "y = x^2 - 6 * x + 13"
shows "4 \<le> y"

17

A.2 Prompt used to formalize number theory problems

Natural language version: "If n is a positive integer such that 2n has 28 positive divisors
and 3n has 30 positive divisors, then how many positive divisors does 6n have? The ﬁnal
answer is 35". Translate the natural language version to an Isabelle version:

theorem

fixes n :: nat
assumes "n>0"

and "card ({k. k dvd (2*n)}) = 28"
and "card ({k. k dvd (3*n)}) = 30"
shows "card ({k. k dvd (6*n)}) = 35"

8 such
Natural language version: "Let n be the number of integers m in the range 1
that gcd(m, 8) = 1. What is the remainder when 3n is divided by 8? The ﬁnal answer is 1".
Translate the natural language version to an Isabelle version:

m

≤

≤

theorem

fixes n :: nat
assumes "n = card {k::nat. gcd k 8 = 1 \<and> 1\<le>k \<and> k < 8}"
shows "(3^n) mod 8 = (1::nat)"

Natural language version: "What is the remainder when 1 + 2 + 3 + 4 +
divided by 9? The ﬁnal answer is 1".
Translate the natural language version to an Isabelle version:

· · ·

+ 9 + 10 is

theorem

"(\<Sum> k< 11. k) mod 9 = (1::nat)"

Natural language version: "Cards are numbered from 1 to 100. One card is removed and the
values on the other 99 are added. The resulting sum is a multiple of 77. What number was
on the card that was removed? The ﬁnal answer is 45".
Translate the natural language version to an Isabelle version:

theorem

fixes x :: nat
assumes h0 : "1 \<le> x \<and> x \<le> 100"

and h1 : "77 dvd ((\<Sum>k::nat=0..100. k)-x)"

shows "x=45"

Natural language version: "Find 9−
between 0 and 99, inclusive.) The ﬁnal answer is 89 (mod 100)".
Translate the natural language version to an Isabelle version:

1 (mod 100), as a residue modulo 100. (Give an answer

theorem

fixes x::nat
assumes "x < 100"

and "x*9 mod 100 = 1"

shows "x = 89"

18

Natural language version:
(mod m) exists and 6−
Translate the natural language version to an Isabelle version:

"Suppose m is a two-digit positive integer such that 6−
62 (mod m). What is m? The ﬁnal answer is 43".

≡

1

1

theorem

fixes m x :: nat
assumes h0 : "10 \<le> m"
and h1 : "m \<le> 99"
and h2 : "(6 * x) mod m = 1"
and h3 : "(x - 6^2) mod m = 0"

shows "m = 43"

1 (mod 112). Express your answer as an integer from 0 to 112

Natural language version: "Find 24−
24b
ﬁnal answer is 116".
Translate the natural language version to an Isabelle version:

1 (mod 112). That is, ﬁnd the residue b for which
1, inclusive. The

−

≡

theorem

fixes b::int
assumes "\<forall>b::int. 0\<le>b \<and> b\<le>11^2 \<and> [b * 24 = 1]

(mod (11^2))"

shows "b = 116"

Natural language version: "Given that p

1

1−

·

2−

1 + 2−

1

·

3−

1 + 3−

1

4−

·

≥
1 +

7 is a prime number, evaluate

+ (p

−

· · ·

1

2)−

(p

·

−

1

1)−

(mod p).

The ﬁnal answer is 2 (mod p)".
Translate the natural language version to an Isabelle version:

theorem

fixes p :: nat
assumes "prime p"
and "7 \<le> p"

shows "(\<Sum> k \<in> {1..<p-1}. (inv_mod k p)* (inv_mod (k+1) p)) = 2"

Natural language version: "What is the remainder when 2000+2001+2002+2003+2004+
2005 + 2006 is divided by 7? The ﬁnal answer is 0". Translate the natural language version
to an Isabelle version:

theorem

"(2000 + 2001 + 2002 + 2003 + 2004 + 2005 + 2006) mod 7 = (0::nat)"

Natural language version: "One morning each member of Angela’s family drank an 8-ounce
mixture of coffee with milk. The amounts of coffee and milk varied from cup to cup, but
were never zero. Angela drank a quarter of the total amount of milk and a sixth of the total
amount of coffee. How many people are in the family? The ﬁnal answer is 5". Translate the
natural language version to an Isabelle version:

theorem

fixes x y n ::nat
assumes "x / 4 + y / 6 = (x + y) / n"

and "n\<noteq>0"
"x\<noteq>0" "y\<noteq>0"

shows "n = 5"

19

A.3 Prompt used for informalization

Isabelle version:

theorem

fixes z::complex
assumes h0: "z = (Complex (1/sqrt 2) (1/sqrt 2))"
shows "(\<Sum>k::nat=1..12. (z^(k^2)))

* (\<Sum> k::nat=1..12. 1/(z^(k^2))) =36"

Translate the Isabelle version to a natural language version:

1

i=1 2(zi2
(
(
·
Isabelle version:
P
P

))

1
i=1 2( 1

zi2 )). The ﬁnal answer is 36."

"Let z = 1+i
√2

, ﬁnd

theorem

fixes a b ::real
assumes "(ln a) / (ln 8) + (ln (b^2)) / (ln 4) = 5"
"(ln b) / (ln 8) + (ln (a^2)) / (ln 4) = 7"

shows "a * b = 512"

Translate the Isabelle version to a natural language version: "Determine the value of ab if
log8 a + log4 b2 = 5 and log8 b + log4 a2 = 7. The ﬁnal answer is 512".

B More on case Studies

B.1 Case Study 1

Here we show the output given by PaLM model 540B. The model got the most structure correctly,
but made some syntactical errors.

Question:
Natural language version: "Prove that there is no function f from the set of non-negative
integers into itself such that f (f (n)) = n+1987 for every n." Translate the natural language
version to an Isabelle version:

PaLM 540B Output:

theorem

fixes f :: "nat -> nat"
assumes "forall n::nat. f(f(n)) = n + 1987"
shows "false"

20

B.2 Case Study 2

We show below the output given by PaLM models of different sizes.

Question:
Natural Language version: "When all the girls at Madeline’s school line up in rows of eight,
there are seven left over. If instead they line up in rows of four, how many are left over? The
ﬁnal answer is 3."
Translate the natural language version to an Isabelle version:

PaLM 540B output:

theorem

fixes n::nat
assumes "n mod 8 = 7"
shows "n mod 4 = 3"

Question:
Natural Language version: "When all the girls at Madeline’s school line up in rows of eight,
there are seven left over. If instead they line up in rows of four, how many are left over? The
ﬁnal answer is 3."
Translate the natural language version to an Isabelle version:

PaLM 64B output:

theorem

fixes girls :: nat
assumes "(girls / 8) + 7 = girls"
shows "girls = 3"

Question:
Natural Language version: "When all the girls at Madeline’s school line up in rows of eight,
there are seven left over. If instead they line up in rows of four, how many are left over? The
ﬁnal answer is 3."
Translate the natural language version to an Isabelle version:

PaLM 8B output:

theorem

fixes a b ::real
assumes "(ln a) / (ln 8) + (ln (b^2)) / (ln 4) = 7"

"(ln b) / (ln 8) + (ln (a^2)) / (ln 4) = 3"}}

shows "a * b = 3"

21

B.3 Case Study 3

If we include the following example in the prompt in additional to the two examples shown in
Figure 2:

Natural language version: "What is the x-coordinate for the x-intercept of the line containing
the points (7, 4) and (6, 3)? The ﬁnal answer is 3". Translate the natural language version
to an Isabelle version:

theorem

fixes a b :: real

and f :: "real \<Rightarrow> real"
assumes h0 : "\<And>x. f x = a * x + b"

and h1 : "f 7 = 4"
and h2 : "f 6 = 3"

shows "f 3 = 0"

Then Codex was able to formalize the problem perfectly:

Question:
Natural language version: "Let f be a linear function for which f (6)
f (12)
Translate the natural language version to an Isabelle version:

f (2)? The ﬁnal answer is 30."

−

f (2) = 12. What is

−

Codex Output:

theorem

fixes a b :: real

and f :: "real \<Rightarrow> real"

assumes h0 : "\<And>x. f x = a * x + b"

and h1 : "f 6 - f 2 = 12"

shows "f 12 - f 2 = 30"

Note that this additional example in the prompt is only tangentially related. The phrase “linear
function” is not even mentioned. Instead, it shows an example how to formalize a line. But that is
sufﬁcient for the model to understand how to formalize a “linear function”.

C More Examples on Mathematical Competition Problems

C.1 Perfect Translations

Question:
Natural language version: "At what point does the line containing the points (1, 7) and
(3, 11) intersect the y-axis? Express your answer as an ordered pair. The ﬁnal answer is
(0,5)". Translate the natural language version to an Isabelle version:

Codex Output:

theorem

fixes a b :: real

and f :: "real \<Rightarrow> real"
assumes h0 : "\<And>x. f x = a * x + b"

and h1 : "f 1 = 7"
and h2 : "f 3 = 11"

shows "f 0 = 5"

22

Question:
Natural language version: "A map of the town that Annie, Barbara, and Charlie live in can
be represented by the Cartesian plane. Annie is located at (6,
20) and Barbara is located
at (1, 14). They agree to meet at the closest point that is equidistant from their current
locations and walk upwards together to get to Charlie’s location at
. How many units
upward do Annie and Barbara walk together to get to Charlie? The ﬁnal answer is 5."
(cid:1)
Translate the natural language version to an Isabelle version:

7
2 , 2

−

(cid:0)

Codex Output:

theorem

fixes a b c :: "real \<times> real"
assumes h0 : "a = (6, -20)"
and h1 : "b = (1, 14)"
and h2 : "c = (7 / 2, 2)"

shows "dist a c + dist b c = 5"

Question:
Natural language version: "Let x be a positive integer, and deﬁne the integers n = x2 + 2x +
17 and d = 2x + 5. When dividing n by d, the quotient is x, and the remainder is 7. Find x.
The ﬁnal answer is 2".

Codex Output:

theorem

fixes x n d :: int
assumes h0 : "x > 0"

and h1 : "n = x^2 + 2 * x + 17"
and h2 : "d = 2 * x + 5"
and h3 : "n div d = x"
and h4 : "n mod d = 7"

shows "x = 2"

Question:
Natural language version: "A line segment begins at (1, 3). It is 5 units long and ends at the
point (4, x) and x > 0. What is the value of x? The ﬁnal answer is 7".

Codex Output:

theorem

fixes x :: real
assumes h0 : "x > 0"

and h1 : "5 = sqrt ((4 - 1)^2 + (x - 3)^2)"

shows "x = 7"

23

Natural language version: "A line segment begins at (1, 3). It is 5 units long and ends at the
point (4, x) and x > 0. What is the value of x? The ﬁnal answer is 7".

Codex Output:

theorem

fixes x :: real
assumes h0 : "x > 0"

and h1 : "5 = sqrt ((4 - 1)^2 + (x - 3)^2)"

shows "x = 7"

Question:
Natural language version: "Let f (x) = x2
f (f (f (f (c)))) = 3? The ﬁnal answer is 9".

−

2x. How many distinct real numbers c satisfy

Codex Output:

theorem

fixes f :: "real \<Rightarrow> real"
assumes h0 : "\<forall> x. f x = x^2 - 2 * x"
shows "card {c. f (f (f (f c))) = 3} = 9"

Question:
Natural language version: "Find the solutions to z4 =
commas. The ﬁnal answer is 1 + i, 1 - i, -1 + i, -1 - i".

−

4. Enter the solutions, separated by

Codex Output:

theorem

fixes z :: complex
assumes "z^4 = -4"
shows "z = 1 + \<i> \<or> z = 1 - \<i> \<or> z = -1 + \<i> \<or> z = -1 -

\<i>"

Question:
Natural language version: "Let z be a complex number satisfying z2 = 4z
that

is an integer, ﬁnd z. The ﬁnal answer is 3 + 4i".

z

|

|

19 + 8i. Given

−

Codex Output:

theorem

fixes z :: complex
assumes h0 : "z^2 = 4 * z - 19 + 8 * \<i>"

and h1 : "norm z \<in> \<int>"

shows "z = 3 + 4 * \<i>"

24

Question:
Natural language version: "The sequence (an) satisﬁes

for all n

≥

2. If a63 = 1, ﬁnd a1. The ﬁnal answer is 2016".

a1 + a2 + a3 +

+ an = n2an

· · ·

Codex Output:

theorem

fixes a :: "nat \<Rightarrow> real"
assumes h0 : "\<forall> n \<ge> 2. (\<Sum> k = 1..n. a k) = n^2 * a n"

and h1 : "a 63 = 1"

shows "a 1 = 2016"

Question:
Natural language version: "Find the units digit of the following within the indicated number
base: 527 + 627 The ﬁnal answer is 4".

Codex Output:

theorem

fixes x y :: nat
assumes "x < 7"
and "y < 7"

shows "((x*7+2) + (y*7+2)) mod 7 = 4"

Question:
Natural language version: "How many factors of 8000 are perfect squares? The ﬁnal answer
is 8".

Codex Output:

theorem

fixes n :: nat
assumes "n = card {k::nat. k^2 dvd 8000}"
shows "n = 8"

Question:
Natural language version: "Solve the congruence 11n
43. (Give an answer between 0 and 42.) The ﬁnal answer is 28".

≡

7 (mod 43), as a residue modulo

Codex Output:

theorem

fixes n :: nat
assumes "n < 43"

and "(11 * n) mod 43 = 7"

shows "n = 28"

25

Question:
Natural language version: "What is the 100th digit after the decimal point of the decimal
representation of 1/7? The ﬁnal answer is 8".

Codex Output:

theorem

fixes x :: nat
assumes "x = (1/7) * 10^100"
shows "x mod 10 = 8"

Question:
Natural language version: "Two positive integers m and n are chosen such that m is the
smallest positive integer with only two positive divisors and n is the largest integer less than
100 with exactly three positive divisors. What is m + n? The ﬁnal answer is 51".

Codex Output:

theorem
fixes m n :: nat
assumes "m = (LEAST k. card {d. d dvd k \<and> d > 0} = 2)"

and "n = (GREATEST k. card {d. d dvd k \<and> d > 0} = 3 \<and> k < 100)"

shows "m + n = 51"

26

C.2 Incorrect Translations

In this section, we present failure cases for each of the categories in Table 2 in Section. 4.4.

Error category: incomplete/ill-formed/unclear prompt
Question:
Natural language version: "Find the largest value of t such that

13t2

−
3t

34t + 12
2

−

+ 5t = 6t

1.

−

The ﬁnal answer is \frac{5".

Codex Output:

theorem

fixes t :: real
assumes h0 : "13 * t^2 - 34 * t + 12 = 3 * t - 2"

and h1 : "5 * t = 6 * t - 1"

shows "t = 5 / 2"

Error category: fail to align deﬁnitions or concepts
Question:
Natural language version: "What is the smallest four-digit positive integer that is divisible
by 47? The ﬁnal answer is 1034".

Codex Output:

theorem

fixes x :: nat
assumes "x > 999"
and "x < 10000"
and "47 dvd x"
shows "x = 1034"

Here, the translator correctly captured the meaning of "four-digit positive integer" (i.e., "x > 999"
and "x < 10000") and that of "divisible by 47" (i.e., "47 dvd x"). However, it fails to align the
"smallest" concept to the one in Isabelle.

Error category: inconsistent/missing assumption
Question:
Natural language version: "Jack walked up a hill at a speed of (x2
22) miles per
hour. Meanwhile, Jill walked a total distance of (x2
54) miles in (x + 6) hours.
If Jack and Jill walked at the same speed, what is that speed, in miles per hour? The ﬁnal
answer is 4".

11x

3x

−

−

−

−

Codex Output:

theorem

fixes x :: real
assumes h0 : "x^2 - 11 * x - 22 = x^2 - 3 * x - 54"
shows "x = 4"

Here, the translator missed the "(x+6)" part in the natural language—it should be translated to "x^2
- 11 * x - 22 = (x^2 - 3 * x - 54)/(x+6)" instead. Also, the conclusion is incorrect either: it
should be "x^2 - 11 * x - 22 = 4" or "(x^2 - 3 * x - 54)/(x+6)= 4".

27

Error category: syntactical/type error)
Question:
Natural language version: "Find

1024

⌊
XN =1

log2 N

.

⌋

The ﬁnal answer is 8204".

Codex Output:

theorem

fixes N :: nat
shows "(\<Sum> N = 1..1024. nat \<lfloor>log 2 N\<rfloor>) = 8204"

In the current version, N will be inferred as a real number, so that the interval "1..1024" will be a
real interval from 1 to 1024. This is incorrect, and sum over such inﬁnite interval will result in 0 (i.e.,
"(\<Sum> N = 1..1024. nat \<lfloor>log 2 N\<rfloor>)= 0"). The correct version requires
an explicit type conversion: "(\<Sum> N = 1..1024. \<lfloor>log 2 (of_int N)\<rfloor>)=
8204".

Error category: missing deﬁnition in Isabelle
Question:
Natural language version: "The product of two positive three-digit palindromes is 436,995.
What is their sum? The ﬁnal answer is 1332".

Codex Output:

theorem

fixes x y :: nat
assumes "100 \<le> x \<and> x \<le> 999"
and "100 \<le> y \<and> y \<le> 999"
and "x * y = 436995"

shows "x + y = 1332"

The only missing part in this example is the deﬁnition of palindromes. It appears that the translator
does not know what a palindrome is so that it chooses to drop it from the assumptions.

Error category: wrong application of functions
Question:
Natural language version: "If the operation Z is deﬁned as aZb = b + 10a
value of 2Z6? The ﬁnal answer is 22".

−

a2, what is the

Codex Output:

theorem

fixes a b :: real
assumes h0 : "a Z b = b + 10 * a - a^2"
shows "2 Z 6 = 22"

The function Z should be applied in a preﬁx way in Isabelle. Also, the translator missed the "for
all" quantiﬁer in the assumption. The correct assumption should be "\<forall> a b. Z a b = b
+ 10 * a - a^2".

28

Error category: other
Question:
Natural language version: "Simplify:

Codex Output:

theorem

fixes x :: real
assumes h0 : "x = - 3 ^2 + 4"
shows "abs x = 5"

32 + 4

|

|−

The ﬁnal answer is 5".

Here, a parenthesis should be placed around 3 ^2 (i.e., "x = - (3 ^2)+ 4"). This is a subtle issue
to operator precedence in Isabelle.

Error category: other
Question:
Natural language version: "How many numbers from 1 to 150 are not perfect squares or
perfect cubes? The ﬁnal answer is 135".

Codex Output:

theorem

fixes n :: nat
assumes "n \<le> 150"
shows "card {k::nat. k \<le> n \<and> \<not> (\<exists> m. m^2 = k \<or>

m^3 = k) } = 135"

The translator somehow introduces an unnecessary variable n and assumed "n \<le> 150". The
correct translation should have n replaced with 150 in the conclusion: "card {k::nat. k \<le>
150 \<and> \<not> (\<exists> m. m^2 = k \<or> m^3 = k)} = 135".

29

D More Examples on Advanced Mathematics

D.1 Formalization

Question:
Natural language version: "Let f be a continuous function from a compact convex set S to
itself. Then there exists x
S such that f (x) = x." Translate the natural language version
to an Isabelle version:

∈

Codex Output:

theorem

fixes f :: "’a::real_normed_vector \<Rightarrow> ’a"
assumes "continuous_on S f"
"compact S"
"convex S"

shows "\<exists>x\<in>S. f x = x"

Here, we asked the model to formalize the statement of the famous Brouwer’s ﬁxed-point theorem.
The model made two mistakes. The ﬁrst one is that the model erroneously assume the function
is on a real normed vector space rather than a euclidean space or a banach space. This is quite
understandable as we left this information in the source. The second and more critical error is that
the absence of the assumption of f mapping from S to itself (i.e., f (S)

S or f (S) = S).

⊆

Question: Let γ be a closed path in the complex plane, and z be a point not on γ. Then the
winding number of γ around z is an integer.

Codex Output:

theorem
fixes \<gamma> :: "real \<Rightarrow> complex" and z :: complex
assumes "continuous_on {0..1} \<gamma>"
"\<gamma> 0 = \<gamma> 1"
"z \<notin> \<gamma> ‘ {0..1}"

shows "winding_number \<gamma> z \<in> \<int>"

Here, the model has made a perfect translation–not only the model correctly infers that a path in the
complex plane should be a function from the real interval [0, 1] to complex, it also manages to align
a path being closed to the assumption \<gamma> 0 = \<gamma> 1.

30

D.2

Informalization

The following lemma statements are from the standard library of
Complex_Analysis and HOL-Probability).

Isabellle (i.e., HOL-

proposition openin_clauses:
ﬁxes U :: "’a topology"
shows

"openin U {}"
" VS T. openin U S =⇒ openin U T =⇒ openin U (S ∩T)"
" VK. (∀ S ∈ K. openin U S) =⇒ openin U (S K)"

Translate the Isabelle version to a natural language version:

Codex Output:

Let $U$ be a topology, then $U$ is open if and only if it satisfies the

following conditions:

1. $U$ is open.
2. If $S$ and $T$ are open, then $S \cap T$ is open.
3. If $K$ is a collection of open sets, then $\cup K$ is open.

lemma openin_Int[intro]:

"openin U S =⇒ openin U T
=⇒ openin U (S ∩ T)"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let U be a topology, then
U , if K is a collection of sets, and each set in K is open in U , then

is open in U , if S and T are open in U , then S

∅

T is open in

∩
K is open in U ".

S

lemma openin_Int[intro]:

"openin U S =⇒ openin U T
=⇒ openin U (S ∩ T)"

Translate the Isabelle version to a natural language version:

Codex Output:
"If S and T are open in U , then S

T is open in U ".

∩

lemma openin_Inter [intro]:

assumes "finite F" " F 6= {}" " VX. X ∈ F =⇒ openin T X"
shows "openin T (T F)"

Translate the Isabelle version to a natural language version:

Codex Output:
"If T is a topological space, and
is open in T ".
then

F

T

is a ﬁnite non-empty collection of open subsets of T ,

F

31

lemma openin_subtopology:

"openin (subtopology U V) S ←→ (∃ T. openin U T ∧ S = T ∩ V)"

Translate the Isabelle version to a natural language version:

Codex Output:
"S is open in the subtopology of U induced by V if and only if there exists an open set T in
U such that S = T

V ".

∩

lemma closedin_subtopology_Un:

" [[closedin (subtopology X T) S; closedin (subtopology X U) S ]]

=⇒ closedin (subtopology X (T ∪ U)) S"

Translate the Isabelle version to a natural language version:

Codex Output:
"If S is closed in T and S is closed in U , then S is closed in T

U ".

∪

lemma connected_closedin:

"connected S ←→

(∄ E1 E2.
closedin (top_of_set S) E1 ∧
closedin (top_of_set S) E2 ∧
S ⊆ E1 ∪ E2 ∧ E1 ∩ E2 = {} ∧ E1 6= {} ∧ E2 6= {})"

Translate the Isabelle version to a natural language version:

Codex Output:
"A set S is connected if and only if there does not exist two closed sets E1 and E2 such that
=
S

=

".

E2 =

E1 ∪

E2, E1 ∩

⊆

, E1 6

∅

and E2 6

∅

∅

deﬁnition continuous_map where
"continuous_map X Y f ≡

(∀ x ∈ topspace X. f x ∈ topspace Y) ∧
(∀ U. openin Y U −→ openin X {x ∈ topspace X. f x ∈ U})"

Translate the Isabelle version to a natural language version:

Codex Output:
"A function f from a topological space X to a topological space Y is continuous if for every
open set U in Y , the preimage f −

1(U ) is open in X".

deﬁnition continuous_map where
"continuous_map X Y f ≡

(∀ x ∈ topspace X. f x ∈ topspace Y) ∧
(∀ U. openin Y U −→ openin X {x ∈ topspace X. f x ∈ U})"

Translate the Isabelle version to a natural language version:

Codex Output:
"A continuous map f : X
1(U ) is open in X".
f −

→

Y is a map such that for every open set U

Y , the preimage

⊂

32

lemma connectedin_separation:

"connectedin X S ←→

S ⊆ topspace X ∧
(∄ C1 C2. C1 ∪ C2 = S ∧ C1 6= {} ∧ C2 6= {}
∧ C1 ∩ X closure_of C2 = {} ∧ C2

∩ X closure_of C1 = {})" (is "?lhs = ?rhs")

Translate the Isabelle version to a natural language version:

Codex Output:
"S is connected in X if and only if S
and C2 such that C1 ∪

⊆
C2 = S and C1 ∩

X and there do not exist two non-empty sets C1
XC2 =
XC1 =

".

and C2 ∩

∅

∅

lemma connectedin_Union:

assumes U: " VS. S ∈ U =⇒ connectedin X S" and ne: " T U 6= {}"
shows "connectedin X (S U)"

Translate the Isabelle version to a natural language version:

Codex Output:
"If S is connected in X for all S

and

∈ U

S
T

∈U

S

=

, then

∅

S
S

∈U

S is connected in X".

lemma compact_space_alt:
"compact_space X ←→

(∀ U. (∀ U ∈ U. openin X U) ∧ topspace X ⊆ S U

−→ (∃ F. finite F ∧ F ⊆ U ∧ topspace X ⊆ S F))"

Translate the Isabelle version to a natural language version:

Codex Output:
"A topological space X is compact if and only if for every open cover
a ﬁnite subcover

of

".

F

U

of X, there exists

U

lemma compactin_subtopology:

"compactin (subtopology X S) T ←→ compactin X T ∧ T ⊆ S"

Translate the Isabelle version to a natural language version:

Codex Output:
"T is compact in S if and only if T is compact in X and T

S".

⊆

lemma closedin_compact_space:

" [[compact_space X; closedin X S ]] =⇒ compactin X S"

Translate the Isabelle version to a natural language version:

Codex Output:
"If X is a compact space and S is a closed subset of X, then S is a compact space".

33

6
lemma compactin_discrete_topology:

"compactin (discrete_topology X) S ←→ S ⊆ X ∧ finite S"

Translate the Isabelle version to a natural language version:

Codex Output:
"S is compact in the discrete topology on X if and only if S is a ﬁnite subset of X".

lemma image_compactin:

assumes cpt: "compactin X S" and cont: "continuous_map X Y f"
shows "compactin Y (f ‘ S)"

Translate the Isabelle version to a natural language version:

Codex Output:
"If S is compact in X and f is continuous from X to Y , then f (S) is compact in Y ".

lemma continuous_on_open:
"continuous_on S f ←→

(∀ T. openin (top_of_set (f ‘ S)) T −→
openin (top_of_set S) (S ∩ f -‘ T))"

Translate the Isabelle version to a natural language version:

Codex Output:
"f is continuous on S if and only if for any open set T in f (S), f −

1(T ) is open in S".

lemma continuous_closedin_preimage_gen:

assumes "continuous_on S f" "f ‘ S ⊆ T"

"closedin (top_of_set T) U"
shows "closedin (top_of_set S) (S ∩ f -‘ U)"

Translate the Isabelle version to a natural language version:

Codex Output:
"If f is continuous on S and f (S)
S".

⊆

T , and U is closed in T , then S

f −

1(U ) is closed in

∩

theorem Casorati_Weierstrass:

assumes "open M" "z ∈ M" "f holomorphic_on (M - {z})"

and " Vl. ¬ (f −−−→ l) (at z)"

" Vl. ¬ ((inverse ◦ f) −−−→ l) (at z)"

shows "closure(f ‘ (M - {z})) = UNIV"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let f be a holomorphic function on an open set M containing z. If f is not constant in any
neighborhood of z and f −
) is
dense in C".

1 is not constant in any neighborhood of z, then f (M

− {

}

z

34

theorem

assumes "open M" "z ∈ M" "f holomorphic_on (M - {z})"

and " Vl. ¬ (f −−−→ l) (at z)"

" Vl. ¬ ((inverse ◦ f) −−−→ l) (at z)"

shows "closure(f ‘ (M - {z})) = UNIV"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let M be an open set and z
not bounded in any neighborhood of z and 1
f (M

) is dense in C.

∈

z

− {

}

M . Let f be a holomorphic function on M

. If f is
f is not bounded in any neighborhood of z, then

− {

}

z

theorem great_Picard:

assumes "open M" "z ∈ M" "a 6= b"

and fab: " Vw. w ∈ M - {z} =⇒ f w 6= a ∧ f w 6= b"

and holf: "f holomorphic_on (M - {z})"

obtains l where "(f −−−→ l) (at z)

∨ ((inverse ◦ f) −−−→ l) (at z)"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let f be a holomorphic function on M
f (z)

= b, then f or 1

= a and f (z)

− {
f has a limit at z".

}

z

, where M is an open set and z

M . If

∈

theorem brouwer:

ﬁxes f :: "’a::euclidean_space ⇒ ’a"
assumes S: "compact S" "convex S" "S 6= {}"

and contf: "continuous_on S f"
and fim: "f ‘ S ⊆ S"

obtains x where "x ∈ S" and "f x = x"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let f be a continuous function from a compact convex set S to itself. Then there exists
x

S such that f (x) = x".

∈

theorem Jordan_curve:

ﬁxes c :: "real ⇒ complex"
assumes "simple_path c" and loop: "pathfinish c = pathstart c"
obtains inner outer where

"inner 6= {}" "open inner" "connected inner"
"outer 6= {}" "open outer" "connected outer"
"bounded inner" " ¬ bounded outer" "inner ∩ outer = {}"
"inner ∪ outer = - path_image c"
"frontier inner = path_image c"
"frontier outer = path_image c"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let c be a simple closed curve. Then there exist two disjoint open sets U and V such that
U is bounded, V is unbounded, U

, ∂U = c, and ∂V = c".

V = C

V =

c, U

∪

\

∩

∅

35

6
6
corollary Jordan_disconnected:
ﬁxes c :: "real ⇒ complex"
assumes "simple_path c" "pathfinish c = pathstart c"
shows " ¬ connected(- path_image c)"

Translate the Isabelle version to a natural language version:

Codex Output:
"If c is a simple closed curve, then R2

c is not connected".

−

theorem inverse_squares_sums: "(λn. 1 / (n + 1)2) sums (pi 2 / 6)"
Translate the Isabelle version to a natural language version:

Codex Output:
"Find the sum of the series

1

(i+1)2 . The ﬁnal answer is π2
6 ".

∞i=1

P

proposition connected_space_product_topology:

"connected_space(product_topology X I) ←→

(ΠE i ∈I. topspace (X i)) = {} ∨ (∀ i ∈ I. connected_space(X i))"

Translate the Isabelle version to a natural language version:

Codex Output:
"The product topology of a family of topological spaces is connected if and only if the
product of the topological spaces is empty or each topological space is connected".

theorem (in ring_of_sets) caratheodory’:

assumes posf: "positive M f" and ca: "countably_additive M f"
shows " ∃ µ :: ’a set ⇒ ennreal.

(∀ s ∈ M. µ s = f s) ∧ measure_space Ω (sigma_sets Ω M) µ"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let M be a σ-algebra on Ω, and f be a positive countably additive function on M . Then
there exists a measure µ on M such that µ(s) = f (s) for all s
M and (Ω, M, µ) is a
measure space".

∈

lemma sigma_finite_density_unique:

assumes borel: "f ∈ borel_measurable M" "g ∈ borel_measurable M"
and fin: "sigma_finite_measure (density M f)"

shows "density M f = density M g ←→ (AE x in M. f x = g x)"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let f and g be two measurable functions on a sigma-ﬁnite measure space M . Then f and
g are equal almost everywhere if and only if the measures µf and µg are equal".

36

lemma mvt_simple:

ﬁxes f :: "real ⇒ real"
assumes "a < b"

and derf: " Vx. [[a ≤ x; x ≤ b ]]

=⇒ (f has_derivative f’ x) (at x within {a..b})"

shows " ∃ x ∈{a<..<b}. f b - f a = f’ x (b - a)"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let f be a function deﬁned on [a, b] and differentiable on (a, b). Then there exists a point
c

(a, b) such that f (b)

f (a) = f ′(c)(b

a)".

∈

−

−

theorem second_countable_borel_measurable:

ﬁxes X :: "’a::second_countable_topology set set"
assumes eq: "open = generate_topology X"
shows "borel = sigma UNIV X"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let X be a set of open sets in a second countable topology. Then the Borel σ-algebra is the
σ-algebra generated by X".

theorem borel_measurable_ereal_iff_real:

ﬁxes f :: "’a ⇒ ereal"
shows "f ∈ borel_measurable M ←→

((λx. real_of_ereal (f x)) ∈ borel_measurable M ∧ f -‘ {∞}

∩ space M ∈ sets M ∧ f -‘ {-∞} ∩ space M ∈ sets M)"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let f be a function from M to R, then f is measurable if and only if f is measurable and
f −

) are measurable sets".

) and f −

1(

1(

∞

−∞

theorem condensation_test:

assumes mono: " Vm. 0 < m =⇒ f (Suc m) ≤ f m"
assumes nonneg: " Vn. f n ≥ 0"
shows "summable f ←→ summable (λn. 2^n * f (2^n))"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let f be a non-negative function such that f (n + 1)
summable if and only if 2nf (2n) is summable".

≤

f (n) for all n. Prove that f is

37

theorem ratio_test_convergence:

ﬁxes f :: "nat ⇒ real"
assumes pos_f: "eventually (λn. f n > 0) sequentially"
deﬁnes "l ≡ liminf (λn. ereal (f n / f (Suc n)))"
assumes l: "l > 1"
shows

"summable f"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let f be a positive function, and let l be the limit inferior of the sequence f (n)
then f is summable".

f (n+1) . If l > 1,

theorem Stone_Weierstrass_polynomial_function:

ﬁxes f :: "’a::euclidean_space ⇒ ’b::euclidean_space"
assumes S: "compact S"

and f: "continuous_on S f"
and e: "0 < e"

shows " ∃ g. polynomial_function g ∧ (∀ x ∈ S. norm(f x - g x) < e)"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let f be a continuous function on a compact set S. Then there exists a polynomial function
g such that

f (x)

< ǫ.

S,

x

∀

∈

|

g(x)
|

−

theorem Riemann_mapping_theorem:

"open S ∧ simply_connected S ←→

S = {} ∨ S = UNIV ∨
(∃ f g. f holomorphic_on S ∧ g holomorphic_on ball 0 1 ∧

(∀ z ∈ S. f z ∈ ball 0 1 ∧ g(f z) = z) ∧
(∀ z ∈ ball 0 1. g z ∈ S ∧ f(g z) = z))"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let S be a simply connected open set. Then S is either empty, the whole plane, or there
exists a holomorphic function f from S to the unit disk and a holomorphic function g from
the unit disk to S such that g
g is the identity function
on the unit disk."

f is the identity function on S and f

◦

◦

38

theorem Residue_theorem:

ﬁxes s pts::"complex set" and f::"complex ⇒ complex"

and g::"real ⇒ complex"

assumes "open s" "connected s" "finite pts" and

holo:"f holomorphic_on s-pts" and
"valid_path g" and
loop:"pathfinish g = pathstart g" and
"path_image g ⊆ s-pts" and
homo:" ∀ z. (z /∈ s) −→ winding_number g z

shows "contour_integral g f =

= 0"

2 * pi * i *(P p ∈pts. winding_number g p * residue f p)"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let f be a holomorphic function on a connected open set S and let g be a closed path
in S that does not pass through any of the points in the ﬁnite set P . Then
g f (z)dz =
R
2πi

P Res(f, p)".

p
P

∈

theorem integer_winding_number:

" [[path γ; pathfinish γ = pathstart γ;
z /∈ path_image γ]] =⇒ winding_number
γ z ∈ š"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let γ be a closed path in the complex plane, and z be a point not on γ. Then the winding
number of γ around z is an integer".

lemma winding_number_eq:

" [[path γ; pathfinish γ

= pathstart γ; w ∈ S; z ∈ S; connected S;
S ∩ path_image γ = {}]]

=⇒ winding_number γ w = winding_number γ z"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let γ be a closed path in the plane, and let w, z be two points in the plane. If γ does not
pass through w or z, and w, z are in the same connected component of the plane, then the
winding number of γ about w is the same as the winding number of γ about z".

corollary winding_number_zero_outside:
" [[path γ; convex s; pathfinish γ
= pathstart γ; z /∈ s; path_image γ
⊆ s ]] =⇒ winding_number γ z = 0"

Translate the Isabelle version to a natural language version:

Codex Output:
"If γ is a path, s is a convex set, γ is a closed path, z is not in s, and γ is in s, then the
winding number of γ around z is 0".

39

lemma winding_number_zero_at_infinity:

assumes γ: "path γ" and loop: "pathfinish γ = pathstart γ"
shows " ∃ B. ∀ z. B ≤ norm z −→ winding_number γ z = 0"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let γ be a closed path, then there exists a constant B such that for all z, if
the winding number of γ at z is 0".

z

|

|

> B, then

lemma winding_number_homotopic_paths:

assumes "homotopic_paths (-{z}) g h"
shows "winding_number g z = winding_number h z"

Translate the Isabelle version to a natural language version:

Codex Output:
"If g and h are homotopic paths in C
to the winding number of h around z".

− {

z

}

, then the winding number of g around z is equal

lemma simple_closed_path_winding_number_cases:

assumes "simple_path γ" "pathfinish γ = pathstart γ"

"z /∈ path_image γ"

shows "winding_number γ z ∈ {-1,0,1}"

Translate the Isabelle version to a natural language version:

Codex Output:
"If γ is a simple closed path, z is not in the image of γ, then the winding number of γ at z is
either -1, 0 or 1".

corollary Cauchy_theorem_primitive:

assumes " Vx. x ∈ S =⇒

(f has_field_derivative f’ x) (at x within S)"

and "valid_path g" "path_image g ⊆ S"
"pathfinish g = pathstart g"

shows "(f’ has_contour_integral 0) g"

Translate the Isabelle version to a natural language version:

Codex Output:
"If f is a function with a derivative f ′ on a set S, and g is a closed path in S, then
g f ′(z)dz = 0".
R

40

theorem (in prob_space) central_limit_theorem_zero_mean:

ﬁxes X :: "nat ⇒ ’a ⇒ real"
and µ :: "real measure"
and σ :: real
and S :: "nat ⇒ ’a ⇒ real"

assumes X_indep: "indep_vars (λi. borel) X UNIV"
and X_mean_0: " Vn. expectation (X n) = 0"
and σ_pos: " σ > 0"
and X_square_integrable: " Vn. integrable M (λx. (X n x)2)"
and X_variance: " Vn. variance (X n) = σ
and X_distrib: " Vn. distr M borel (X n) = µ"

2"

deﬁnes "S n ≡ λx. P i<n. X i x"
shows "weak_conv_m (λn. distr M borel

(λx. S n x / sqrt (n * σ

2))) std_normal_distribution"

Translate the Isabelle version to a natural language version:

Codex Output:
"Let X1, X2,
σ2. Let Sn =
distribution".

· · ·

P

be a sequence of independent random variables with mean 0 and variance
n
i=1 Xi. Then Sn/√nσ2 converges in distribution to a standard normal

proposition compact_space_product_topology:

"compact_space(product_topology X I) ←→

topspace(product_topology X I) = {} ∨ (∀ i ∈ I. compact_space(X i))"

Translate the Isabelle version to a natural language version:

Codex Output:
"If Xi is a compact space for all i

I, then X1 ×

X2 × · · · ×

∈

Xn is a compact space".

Lemma statements in the remainder of this section are from the Topology entry in the AFP.3 All the
natural language version is generated by the Codex model.

lemma seteqI:

" [[Vx. x ∈A =⇒ x ∈B; Vx. x ∈B =⇒ x ∈A ]] =⇒ A = B"

Translate the Isabelle version to a natural language version:

Codex Output:
"If A and B are sets such that A

B and B

⊆

⊆

A, then A = B."

lemma (in carrier) openI: "m ∈ T =⇒ m open"

Translate the Isabelle version to a natural language version:

Codex Output:
"If m is a topology on a set T , then m is open."

3https://www.isa-afp.org/browser_info/current/AFP/Topology/Topology.html

41

lemma (in carrier) openE: " [[ m open; m ∈ T =⇒ R ]] =⇒ R"

Translate the Isabelle version to a natural language version:

Codex Output:
"If m is an open set in a topological space T , then m

T ."

∈

lemma (in topology) open_kriterion:

assumes t_contains_open: " V x. x ∈t =⇒ ∃ t’. t’ open ∧ x ∈t’ ∧ t’⊆t"
shows "t open"

Translate the Isabelle version to a natural language version:

Codex Output:
"If t is a subset of a topological space T such that for every x
such that x

t, then t is open."

t′ and t′

∈

⊆

t, there exists an open set t′

∈

lemma (in carrier) carrierI [intro]:

" [[ t open; x ∈ t ]] =⇒ x ∈ carrier"

Translate the Isabelle version to a natural language version: "If t is an open set in a topolog-
ical space T and x

t, then x

T ."

∈

∈

lemma (in topology) Un_open [intro!]:
assumes abopen: "A open" "B open"
shows "A ∪ B open"

Translate the Isabelle version to a natural language version:

Codex Output:
"If A and B are open sets in a topological space T , then A

B is open."

∪

lemma topologyI:

" [[V x y. [[ is_open T x; is_open T y ]] =⇒ is_open T (x ∩ y);

V M. ∀ m ∈ M. is_open T m =⇒ is_open T (S M)

]] =⇒ topology T"

Translate the Isabelle version to a natural language version:

Codex Output:
"If T is a set and T is closed under ﬁnite intersections and arbitrary unions, then T is a
topology."

lemma (in topobase) topo_open:

"t open = (t ∈ topo B)"

Translate the Isabelle version to a natural language version:

Codex Output:
"If B is a topological base of a topological space T , then t is open if and only if t

B."

∈

42

lemma (in topobase) topo_induct

[case_names basic inter union, induct set: topo, consumes 1]:
assumes opn: "x open"

and bas: " Vx. x ∈ B =⇒ P x"
and int: " Vx y. [[x open; P x; y open; P y ]] =⇒ P (x ∩ y)"
and uni: " VM. (∀ t ∈M. t open ∧ P t) =⇒ P (S M)"

shows "P x"

Translate the Isabelle version to an natural language version:

Codex Output:
"If B is a topological base of a topological space T , then P (x) holds for all open sets x if
B and P (x) is closed under ﬁnite intersections and arbitrary unions."
P (x) holds for all x

∈

lemma subtopologyI:
ﬁxes S (structure)
ﬁxes T (structure)
assumes H1: " Vs. s open =⇒ ∃ t. t open T ∧ s = t ∩ carrier"

and

H2: " Vt. t open T =⇒ t ∩ carrier open"

shows "subtopology S T"

Translate the Isabelle version to an natural language version:

Codex Output:
"If S is a subset of a topological space T such that for every open set s in S, there exists an
open set t in T such that s = t
S is open in S, then S
is a subspace of T ."

S and for every open set t in T , t

∩

∩

lemma (in subtopology) subtopologyE [elim]:

assumes major: "s open"

and
shows "R"

minor: " Vt. [[ t open T; s = t ∩ carrier ]] =⇒ R"

Translate the Isabelle version to an natural language version:

Codex Output:
"If s is an open set in a topological space T , then s is an open set in a subspace S of T if and
only if s = t

S for some open set t in T ."

∩

lemma continuousI:
ﬁxes S (structure)
ﬁxes T (structure)
assumes "f : carrier S → carrier T"

" Vm. m open T =⇒ carrier ∩ (f -‘ m) open"

shows "continuous f S T"

Translate the Isabelle version to an natural language version:

Codex Output:
"If f is a function from a topological space S to a topological space T such that the preimage
of every open set in T is open in S, then f is continuous."

43

lemma continuousE:
ﬁxes S (structure)
ﬁxes T (structure)
shows

" [[continuous f S T;

[[f : carrier S → carrier T;
∀ m. m open T −→ carrier S ∩ (f -‘ m) open ]] =⇒ P

]] =⇒ P"

Translate the Isabelle version to an natural language version:

Codex Output:
"If x is a limit point of a set A in a topological space T , then there exists a ﬁlter F such that
x

F and A

F ."

∈

∈

44

