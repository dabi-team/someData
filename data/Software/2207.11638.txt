2
2
0
2

l
u
J

4
2

]
P
S
.
s
s
e
e
[

1
v
8
3
6
1
1
.
7
0
2
2
:
v
i
X
r
a

DCT Approximations Based on Chen’s Factorization

C. J. Tablada∗

T. L. T. da Silveira†

R. J. Cintra‡

F. M. Bayer§

Abstract

In this paper, two 8-point multiplication-free DCT approximations based on the Chen’s factorization are pro-
posed and their fast algorithms are also derived. Both transformations are assessed in terms of computational
cost, error energy, and coding gain. Experiments with a JPEG-like image compression scheme are performed and
results are compared with competing methods. The proposed low-complexity transforms are scaled according to
Jridi-Alfalou-Meher algorithm to eﬀect 16- and 32-point approximations. The new sets of transformations are
embedded into an HEVC reference software to provide a fully HEVC-compliant video coding scheme. We show
that approximate transforms can outperform traditional transforms and state-of-the-art methods at a very low
complexity cost.

Approximate DCT, Chen’s factorization, Fast algorithms, Image and video compression, Low-complexity transforms

Keywords

1 Introduction

Discrete transforms are very useful tools in digital signal processing and compressing technologies [10, 23]. In this

context, the discrete cosine transform (DCT) plays a key role [2] since it is a practical approximation for the Karhunen-

Lo`eve transform (KLT) [15]. The KLT has the property of being optimal in terms of energy compaction when the

intended signals are modeled after a highly correlated ﬁrst-order Markov process [10]. This is a widely accepted

supposition for natural images [17].

Particularly, the DCT type II (DCT-II) of order 8 is a widely employed method [10], being adopted in several

industry standards of image and video compression, such as JPEG [17], MPEG-1 [40], MPEG-2 [25], H.261 [26],

H.263 [27], H.264 [39], and the state-of-the-art HEVC [38]. Aiming at the eﬃcient computation of the DCT, many

fast algorithms have been reported in literature [12, 33, 43, 53]. Nevertheless, these methods usually need expensive

arithmetic operations, as multiplications, and an arithmetic on ﬂoating point, demanding major hardware require-

ments [32].

An alternative to the exact DCT computation is the use of DCT approximations that employ integer arithmetic

only and do not require multiplications [10, 23]. In this context, several approximations for the DCT-II were proposed
1
2 , ±1, ±2} [20,
in literature. Often the elements of approximate transform matrices are deﬁned over the set P = {0, ±
14]. Relevant methods include the signed DCT (SDCT) [20] and the Bouguezel-Ahmad-Swamy (BAS) series of

approximations [7, 8, 9, 3].

Transform matrices with elements in P have null multiplicative complexity [5]. Thus their associate hardware
implementations require only additions and bit-shifting operations [3]. This fact renders such multiplierless approx-

imations suitable for hardware-software implementations on devices/sensors operating at low computational power

and severe energy consumption constraints [11, 39, 40].

In this work, we aim at the following goals:

∗

†

‡

Signal Processing Group, Departamento de Estat´ıstica, Universidade Federal de Pernambuco, Recife, PE, Brazil
Programa de P´os-Gradua¸c˜ao em Computa¸c˜ao, Universidade Federal do Rio Grande do Sul, Porto Alegre, RS, Brazil
Signal Processing Group, Departamento de Estat´ıstica, Universidade Federal de Pernambuco, Recife, PE, Brazil E-mail: rjdsc@de.

ufpe.br
§

Departamento de Estat´ıstica and LACESM, Universidade Federal de Santa Maria, Santa Maria, RS, Brazil

1

 
 
 
 
 
 
• the proposition of new multiplication-free approximations for the 8-point DCT-II, based on Chen’s algo-

rithm [12];

• the derivation of fast algorithms for the introduced transforms;

• a comprehensive assessment of the new approximations in terms of coding and image compression performance

compared to popular alternatives;

• the extension of the proposed 8-point transforms to 16- and 32-point DCT approximations by means of the

scalable recursive method proposed in [29]; and

• the embedment of the obtained approximations into an HEVC-compliant reference software [28].

This paper unfolds as follows. Section 2 presents Chen’s factorization for the 8-point DCT-II. In Section 3,

we present two novel 8-point multiplierless transforms and their fast algorithms. The proposed approximations

are assessed and mathematically compared with competing methods in Section 4. Section 5 provides comprehensive

image compression analysis based on a JPEG-like compression scheme. Several images are compressed and assessed for

quality according to the approximate transforms. Section 6 extends the 8-point transforms to 16- and 32-point DCT

approximations and considers a real-world video encoding scheme based on these particular DCT approximations.

Final conclusions and remarks are drawn in Section 7.

2 Chen’s factorization for the DCT

Chen et al. [12] proposed a fast algorithm for the DCT-II based on a factorization for the DCT type IV (DCT-

IV). These two versions of the DCT diﬀer in the sample points of the cosine function used in their transformation
kernel [48, 10]. The (m, n)-th element of the N -point DCT-II and DCT-IV transform matrices, respectively denoted
as CII

N , are given by:

N and CIV

[CII

N ]m,n =

[CIV

N ]m,n =

√

√

⎡
⎢
⎢
⎢
⎢
⎣
⎡
⎢
⎢
⎢
⎢
⎣

2
N

2
N

cm cos(

m(2n + 1)π
2N

)

cos(

(2m + 1)(2n + 1)π
4N

,

⎤
⎥
⎥
⎥
⎥
⎦m,n
⎤
⎥
⎥
⎥
⎥
⎦m,n

)

,

where m, n = 0, 1, . . . , N − 1 and

cm =

√

2,

1/

1,

⎧⎪⎪
⎨
⎪⎪⎩

if m = 0,
if m ≠ 0.

In the following, let 0N the zero matrix of order N , IN the N × N identity and ¯IN the counter-identity matrix,

which is given by:

¯IN =

⎡
⎢
⎢
⎢
⎢
⎣

0 ⋯ 0 1
0 ⋯ 1 0
⋮
⋮ ⋰ ⋮
1 ⋯ 0 0

.

⎤
⎥
⎥
⎥
⎥
⎦

In [47], Wang demonstrated that the 8-point DCT-II matrix possesses the following factorization:

CII

8 =

1
2

P8

CII
4
04

⎡
⎢
⎢
⎢
⎢
⎣

04
¯I4 CIV
4

¯I4

B8,

⎤
⎥
⎥
⎥
⎥
⎦

(1)

2

where P8 and B8 are permutation and pre-addition matrices given by, respectively:

P8 =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

1 0 0 0 0 0 0 0
0 0 0 0 0 0 0 1
0 1 0 0 0 0 0 0
0 0 0 0 0 0 1 0
0 0 1 0 0 0 0 0
0 0 0 0 0 1 0 0
0 0 0 1 0 0 0 0
0 0 0 0 1 0 0 0

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

, B8 =

¯I4
I4
¯I4 −I4

⎡
⎢
⎢
⎢
⎢
⎣

.

⎤
⎥
⎥
⎥
⎥
⎦

Additionally, Chen et al. suggested in [12] that the matrix CIV

4 admits the following factorization:

CIV

4 = Q A1 A2 A3,

where

Q =

1 0 0 0
0 0 1 0
0 1 0 0
0 0 0 1

⎡
⎢
⎢
⎢
⎢
⎣

⎤
⎥
⎥
⎥
⎥
⎦

, A1 =

β0
0
0
β3

⎡
⎢
⎢
⎢
⎢
⎢
⎣

0
0
β2 β1
β1 −β2
0

β3
0
0
0 −β0

⎤
⎥
⎥
⎥
⎥
⎥
⎦

, A2 =

⎡
⎢
⎢
⎢
⎢
⎣

1 0 0
1
1 −1 0 0
0 −1 1
0
0 1 1
0

⎤
⎥
⎥
⎥
⎥
⎦

, A3 =

⎡
⎢
⎢
⎢
⎢
⎣

with α = cos(

π
4 ) and βn = cos(

(2n+1)π
16

).

Replacing (2) in (1) and expanding the factorization, we obtain:

CII

8 =

1
2

P8 M1 M2 M3 M4 B8 ,

where

0

0 1
0
0 α α 0
0 −α α 0
0 0
1

0

,

⎤
⎥
⎥
⎥
⎥
⎦

(2)

(3)

, M2 =

M1 =

M4 =

̃C =

⎡
⎢
⎢
⎢
⎢
⎣
⎡
⎢
⎢
⎢
⎢
⎣
⎡
⎢
⎢
⎢
⎢
⎣

I4
04

CII
2
04

04
¯I4 Q

⎤
⎥
⎥
⎥
⎥
⎦
⎤
⎥
⎥
⎥
⎥
⎦
04
¯I2 CIV
2

B4
04
04 A3

⎤
⎥
⎥
⎥
⎥
⎦

¯I2

⎤
⎥
⎥
⎥
⎥
⎦

P4
04
04 A1

⎡
⎢
⎢
⎢
⎢
⎣
1 0 0 0
0 0 0 1
0 1 0 0
0 0 1 0

⎤
⎥
⎥
⎥
⎥
⎦
α α 0
α −α 0
0
0

0
0
0 −γ0 γ1
0 γ1 γ0

⎡
⎢
⎢
⎢
⎢
⎣

⎡
⎢
⎢
⎢
⎢
⎣

=

,

⎤
⎥
⎥
⎥
⎥
⎦

, P4 =

, B4 =

,

⎤
⎥
⎥
⎥
⎥
⎦

, M3 =

̃C 04
04 A2

⎡
⎢
⎢
⎢
⎢
⎣
¯I2
I2
¯I2 −I2

,

⎤
⎥
⎥
⎥
⎥
⎦

⎡
⎢
⎢
⎢
⎢
⎣

with γn = cos(

(2n+1)π
8

). The expression in (3) is referred to as Chen’s factorization for the 8-point DCT-II.

Without any fast algorithm, the computation of the DCT-II requires 64 multiplications and 56 additions. Using the

Chen’s factorization in (3) the arithmetic complexity is reduced to 16 multiplications and 26 additions. The quantities
α, βn, and γn, presented in M2, M3, and M4, are irrational numbers and demand non-trivial multiplications.

For the sake of notation, hereafter the DCT-II is referred to as DCT.

3 Proposed DCT approximations

In this section, new approximations for the DCT are sought. To this end, we notice that the factorization (3)

naturally induces the following mapping:

TC ∶ R × R4

× R2

—→ M8(R)

(α, β, γ) —→ P8 M1 M2 M3 M4 B8,

(4)

where M8(R) is the space of 8×8 matrices with real-valued entries, α ∈ R, β = [β0 β1 β2 β3]
γ = [γ0 γ1]

∈ R4, and
∈ R2. Now the matrices M2, M3, and M4 are seen as matrix functions, where the constants in

⊺

⊺

3

(3) are understood as parameters:

In particular, for the values

M2 = M2(β),
M3 = M3(α, γ),
M4 = M4(α).

α = cos (

βn = cos (

γn = cos (

π
4 ) ,
(2n + 1)π
16
(2n + 1)π
8

) , n = 0, 1, 2, 3,

) , n = 0, 1,

(5)

(6)

we have TC (α, β, γ) = 2 CII
of low-complexity matrices whose elements are restricted to the set P = {0, ±

8 . In the following, we vary the values of parameters α, β, and γ aiming at the derivation

1
2 , ±1, ±2}.

To facilitate our approach, we consider the signum and round-oﬀ functions, respectively, given by:

sign(x) =

1,

0,

⎧⎪⎪⎪⎪⎪⎪
⎪⎪⎪⎪⎪⎪⎩

⎨

−1,

if x > 0,
if x = 0,
if x < 0,
1
2 ⌋

round(x) = sign(x) ⌊∣x∣ +

where ⌊x⌋ = max {m ∈ Z ∣ m ≤ x} is the ﬂoor function for x ∈ R. These functions coincide with their deﬁnitions
implemented in C and MATLAB computer languages. When applied to vectors or matrices, sign(⋅) and round(⋅)
operate entry-wise.

Thereby, considering the values in (6) and applying directly the functions above, we obtain the approximate

vectors shown below:

(̃α, ̃β, ̃γ) = sign[(α, β, γ)] = [1 1 1 1 1 1 1]
(̂α, ̂β, ̂γ) = round[(α, β, γ)] = [1 1 0 1 1 1 0]

⊺ .

⊺ ,

Then, the following matrices are generated according to (5):

̃M2 = M2( ̃β), ̂M2 = M2( ̂β),
̃M3 = M3(̃α, ̃γ), ̂M3 = M3(̂α, ̂γ),
̃M4 = M4(̃α), ̂M4 = M4(̂α),

4

which are explicitly given by:

1 0 0 0 0 0 0 0
0 0 0 1 0 0 0 0
0 1 0 0 0 0 0 0
0 0 1 0 0 0 0 0
0 0 0 0 1 0 0 0
0 0 0 0 0 1 1 0
0 0 0 0 0 1 −1 0
0 0 0 0 0 0 0 −1

1 1 0 0 0 0 0 0
1 −1 0 0 0 0 0 0
0 0 −1 0 0 0 0 0
0 0 0 1 0 0 0 0
0 0 0 0 1 1 0 0
0 0 0 0 1 −1 0 0
0 0 0 0 0 0 −1 1
0 0 0 0 0 0 1 1

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

,

,

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

̃M2 =

̃M3 =

̃M4 =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

1 0 0 0 0 0 0 0
0 0 0 1 0 0 0 0
0 1 0 0 0 0 0 0
0 0 1 0 0 0 0 0
0 0 0 0 1 0 0 1
0 0 0 0 0 1 1 0
0 0 0 0 0 1 −1 0
0 0 0 0 1 0 0 −1

1 1 0 0 0 0 0 0
1 −1 0 0 0 0 0 0
0 0 −1 1 0 0 0 0
0 0 1 1 0 0 0 0
0 0 0 0 1 1 0 0
0 0 0 0 1 −1 0 0
0 0 0 0 0 0 −1 1
0 0 0 0 0 0 1 1

1 0 0 1 0 0 0 0
0 1 1 0 0 0 0 0
0 1 −1 0 0 0 0 0
1 0 0 −1 0 0 0 0
0 0 0 0 0 0 0 1
0 0 0 0 0 1 1 0
0 0 0 0 0 −1 1 0
0 0 0 0 1 0 0 0

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

, ̂M2 =

, ̂M3 =

= ̂M4.

Invoking the factorization from (4), we deﬁne the following new transforms:

̃T8 ≜ TC (̃α, ̃β, ̃γ) = P8 M1 ̃M2 ̃M3 ̃M4 B8,
̂T8 ≜ TC (̂α, ̂β, ̂γ) = P8 M1 ̂M2 ̂M3 ̂M4 B8.

(7)

(8)

The numerical evaluation of (7) and (8) reveals the following matrix transforms:

̃T8 =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

1
0

1
1
1 −1

1
1
2
1
1 −1 −1 −1 −1
1
0 −2 −1
1
2
1
1 −1 −1
1 −1 −1
1
1 −2
1 −1
0
0
1 −1 −1
1 −1
1 −1
2 −1
0
1

1
1
1
0 −2 −1
1
1
0 −1
1
2 −1
1
0 −1

1 −2

, ̂T8 =

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

1

1

1
1
1
1
0
1
0 −2 −1
1
1 −1 −1
1
1 −1
1 −2
0
0 −1
0
1
0
1 −1
1 −1
0 −1

1
1
1
0
0 −1 −1
0
1
2
1 −1 −1
0
1 −1
1

1
1
0 −1 −1 −1
0
1
0 −1
1
2 −1
0
0

.

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

Above transformations have simple inverse matrices. Direct matrix inversion rules applied to (7) and (8) furnish:

̃T−1

8 =

̂T−1

8 =

1
2
1
2

B⊺

8 ̃M−1

4 ̃M−1

3 ̃M−1

2 M⊺

1 P⊺
8,

B⊺

8 ̂M−1

4 ̂M−1

3 ̂M−1

2 M⊺

1 P⊺
8,

where

and

P−1

8 = P⊺

8, M−1

1 = M⊺

1, ̃M−1

̃M−1

3 =

1
2

̃M3, ̂M−1

3 =

1
2

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

, ̂M−1

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

2 0 0 0 0 0 0 0
0 0 2 0 0 0 0 0
0 0 0 2 0 0 0 0
0 2 0 0 0 0 0 0
0 0 0 0 1 0 0 1
0 0 0 0 0 1 1 0
0 0 0 0 0 1 −1 0
0 0 0 0 1 0 0 −1

1
2

2 =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
1 1 0 0 0 0 0 0
1 −1 0 0 0 0 0 0
0 0 −2 0 0 0 0 0
0 0 0 2
0 0 0 0
0 0 0 0 1 1 0 0
0 0 0 0 1 −1 0 0
0 0 0 0 0 0 −1 1
0 0 0 0 0 0 1 1

, ̃M−1

4 =

1
2

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣

2 0 0 0 0 0 0 0
0 0 2 0 0 0 0 0
0 0 0 2 0 0 0 0
0 2 0 0 0 0 0 0
0 0 0 0 2 0 0 0
0 0 0 0 0 1 1 0
0 0 0 0 0 1 −1 0
0 0 0 0 0 0 0 −2

1
2

2 =

⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎣
1 0 0 1 0 0 0 0
0 1 1 0 0 0 0 0
0 1 −1 0 0 0 0 0
1 0 0 −1 0 0 0 0
0 0 0 0 0 0 0 2
0 0 0 0 0 1 −1 0
0 0 0 0 0 1 1 0
0 0 0 0 2 0 0 0

= ̂M−1
4 ,

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

(9)

(10)

,

⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎦

B−1

8 =

1
2

B⊺
8.

5

x0

x1

x2

x3

x4

x5

x6

x7

X0

X0

X2

X2

X4

X4

X6

X6

X7

X7

X5

X5

X3

X3

X1

X1

1/2

1/2
1/2

1/2

−2

2

2

2

(b) ̂T−1
8

x0

x1

x2

x3

x4

x5

x6

x7

(a) ̂T8

Figure 1: Signal ﬂow graph for ̂T8 and ̂T−1
8

(dotted lines indicates multiplication by −1).

Figure 1 depicts the signal ﬂow graphs (SFG) of the proposed fast algorithm for the transform ̂T8 and its inverse
8 are similar and

8 . Figure 1(a) and 1(b) are linked to (8) and (10), respectively. The SFGs for the ̃T8 and ̃T−1

̂T−1
were suppressed for brevity.

3.1 Orthogonality and near orthogonality

The proposed transforms lead to nonorthogonal approximations for the DCT. This is also the case for the well-known

SDCT [20] and the BAS approximation described in [7]. Indeed, for image/video processing, orthogonality is not

strict requirement; being near orthogonality suﬃcient for very good energy compaction properties.

To quantify how close a given matrix is to an orthogonal matrix, we adopt the deviation from diagonality mea-

sure [16], which is described as follows. Let M be a square matrix. The deviation from diagonality of M is given

by:

δ(M) = 1 −

2
∥ diag(M)∥
F
∥M∥

2
F

,

where ∥ ⋅ ∥F denotes the Frobenius norm [51, p. 115]. For diagonal matrices, the function δ(⋅) returns zero. Therefore
for a full rank low-complexity transformation matrix T, we can measure its closeness to orthogonality by calculating
δ(T T⊺

).

Both the 8-point SDCT [20] and the BAS approximation proposed in [7] are nonorthogonal and good DCT approx-

imations. Their orthogonalization matrices have deviation from diagonality equal to 0.20 and 0.1774, respectively.
Comparatively, matrices ̃T8 and ̂T8 have deviation from diagonality equal to 0.0714 and 0.0579, respectively. Because
these values are smaller than those for the SCDT and BAS approximations, the proposed transformations are more

“nearly orthogonal” than such approximations.

In [45], the problem of deriving DCT approximations based on nonorthogonal matrices was addressed. The

approach consists of a variation of the polar decomposition method as described in [21]. Let T be a full rank

low-complexity transformation matrix. If T satisﬁes the condition:

T T⊺

= D,

6

(11)

where D is a diagonal matrix, then it is possible to derive an orthonormal approximation ˆC linked to T. This is
accomplished by means of the polar decomposition [21]:

ˆC = S T,

where S =

√

(T T⊺)

−1 is a positive deﬁnite matrix and √

⋅ denotes the matrix square root operation [22].

From the computational point-of-view, it is desirable that S be a diagonal matrix [13]. In this case, the computa-
tional complexity of ˆC is the same as that of T, except for the scaling factors in the diagonal matrix S. Moreover, in
several applications, such scaling factors can be embedded into related computation step. For example, in JPEG-like

compression the quantization step can absorb the diagonal elements [3, 9, 31, 14].

Since the transformations ̃T8 and ̂T8 do not satisfy (11), one may consider approximating S itself by replacing
the oﬀ-diagonal elements of D by zeros, at the expense of not obtaining a precisely orthogonal approximation ˆC.
Therefore, we consider the following approximate matrix for S:

√

S′

=

[diag(T T⊺)]

−1,

(12)

where diag(⋅) returns the diagonal matrix from its matrix argument. Thus, the near orthogonal approximations for
the DCT-II associated to the proposed transforms are given by:

where

̃S8 = diag (

̂S8 = diag (

1
√

8
1
√

8

,

,

1
√

12
1
√

,

6

̃C8 = ̃S8 ̃T8,
̂C8 = ̂S8 ̂T8,

,

1
√

8

,

1
√

12

,

1
√

8

,

1
2

,

1
√

12

,

1
√

8

,

1
√

12

1
√

,

,

1
√

8
1
√

6

,

1
√

12

) ,

) .

12
1
2

,

Notice that ̃S8 and ̂S8 derive from (12).

4 Performance assessment and computational cost

To measure the proximity of the new multiplierless transforms with respect to the exact DCT, we elected the total

error energy [14] as ﬁgure of merit. We also considered the coding gain relative to the KLT [18] as the measure for

coding performance evaluation. For comparison, we separated the classical approximations SDCT [20] and BAS [7]—

which are nonorthogonal—as well as the HT [42] and the WHT [23], both orthogonal.

4.1 Performance measures

4.1.1 Total error energy

The total error energy (cid:15) total is a measure of spectral similarity between the exact DCT and the considered approx-
imate DCT [14]. Although originally deﬁned over the spectral domain [20], the total error energy for a given DCT
approximation matrix ˆC can be written as:

(cid:15) total = π ∥C −

ˆC∥

2
F ,

7

Table 1: Total error energy of the considered transforms

̂C8

̃C8

SDCT BAS WHT

HT

(cid:15) total

1.79

3.64

3.32

4.12

5.05

47.61

where C is the exact DCT matrix and ∥ ⋅ ∥F denotes the Frobenius norm [51]. The total error energy measurements
for all discussed approximations are listed in Table 1.

The proposed approximation ̂C8 presents the lower total error energy among all considered transforms, at the
same time that requires only 22 additions. The BAS transform, which possess the smallest arithmetic cost among
the considered methods, presents a considerably higher total error energy. Thus, ̂C8 and SDCT outperform BAS.
Comparatively, HT and WHT are less suitable approximations for the DCT.

4.1.2 Coding gain relative to the KLT

For coding performance evaluation, images are assumed to be modeled after a ﬁrst-order Markov process with
correlation coeﬃcient ρ, where 0 ≤ ρ < 1 [32, 10, 18]. Natural images satisfy the above assumptions [32]. Then, the
(m, n)-th element of the covariance matrix Rx of the input signal x is given by r(x)

m,n = ρ∣m−n∣ [10].

Let hk and gk be the kth rows of ˆC and ˆC−1, respectively. Thus, the coding gain of ˆC is given by:

Cg(

ˆC) = 10 log10[

N
∏
k=1

1
(Ak Bk)1/N ]

(in dB),

where Ak = su[(h⊺
element-wise matrix product [41], Bk = ∥gk∥
coding gain collapses into the usual coding gain as deﬁned in [10, 18].

k hk) ○ Rx], su(⋅) returns the sum of the elements of its matrix argument [35], operator ○ is the
2
2, and ∥ ⋅ ∥2 is the Euclidean norm. For orthogonal transforms, the uniﬁed

High coding gain values indicate better energy compaction capability into the transform domain [32].

In this

sense, the KLT is optimal [10, 15]. Thus, an appropriate measure for evaluating the coding gain is given by [18]:

Cg(

ˆC) − Cg(KLT),

where Cg(KLT) denotes the coding gain corresponding to the KLT. For example, for N = 8 and ρ = 0.95, the coding
gains linked to the KLT and DCT are 8.8462 dB and 8.8259 dB, respectively [10]. Hence, the DCT coding gain
relative to the KLT is Cg(C) − Cg(KLT) = −0.0203.

Figure 2 compares the values of coding gain relative to the KLT for the considered transforms in the range
0 ≤ ρ < 1. As expected, the DCT has the smallest diﬀerence with respect to the KLT, followed by the HT and
WHT (both with the same values). Roughly orthogonal transforms tend to show better coding gain performance
when compared to nonorthogonal. The proposed transforms ̂C8 and ̃C8 could outperform the SDCT and BAS, both
nonorthogonal transformations. As ρ → 1, the approximation ̂C8 performs as well as the HT and WHT. This scenario
is realistic for image compression, because natural images exhibit high inter-pixel correlation [17].

4.2 Computational cost

The low-complexity matrices associated to the proposed approximations and their inverses possess multiplierless

matrix factorizations as shown in (7), (8), (9), and (10). Therefore, the only truly multiplicative elements are the
ones found in the diagonal matrices ̃S8 and ̂S8. However, in the context of image and video coding, such diagonal
matrices can easily absorbed in the quantization step [3, 9, 31, 14]. As a consequence, in that context, the introduced

approximations can be understood as fully multiplierless operations.

8

Figure 2: Coding gain relative to the KLT for the considered transforms.

Table 2: Arithmetic complexity of the considered 8-point transforms

Transform Mult Add

Shift Total

DCT [12]
HEVC [34]
̂C8
̃C8
SDCT [20]
BAS [7]
WHT [23]
HT [42]

16
0
0
0
0
0
0
0

26
50
22
26
24
21
24
24

0
30
0
0
0
0
0
0

42
80
22
26
24
21
24
24

Table 2 presents the arithmetic complexity of the considered transforms. The computational cost of the exact

DCT according to the Chen’s factorization (cf. (3)) [12] and the integer DCT for HEVC [34] are also included for
comparison. The proposed approximation ̂C8 requires only 22 additions. On the other hand, the computational cost
of ̃C8 is comparatively larger.

5 Low-complexity image compression

In this section, we describe a JPEG-like image compression computational experiment. Proposed transformations

are evaluated in terms of their data compression capability.

9

00.10.20.30.40.50.60.70.80.91−3−2.5−2−1.5−1−0.50correlationcoeﬃcientρCodinggainrelativetoKLT  DCTHT,WHTSDCTBASbC8eC85.1 JPEG-like compression

We considered a set of 30 standard 8-bit 512×512 gray scale images obtained from [1]. The images were subdivided
into 8×8 blocks. Each block A was submitted to the 2-D transformation given by [44]:

ˆB =

ˆC A ˆC−1,

where ˆC is a particular transformation. The 64 obtained coeﬃcients in ˆB were arranged according to the standard
zig-zag sequence [46]. The ﬁrst r coeﬃcients were retained, being the remaining coeﬃcients discarded. We adopted
1 ≤ r ≤ 45. Then for each block ˆB, the 2-D inverse transform was applied to reconstruct the compressed image:

ˆA =

ˆC−1 ˆB ˆC.

Finally, the resulting image was compared with the original image according to the peak signal-to-noise ratio

(PSNR) [24] and the structural similarity index (SSIM) [50, 49]. The absolute percentage error (APE) for such

metrics relative to the exact DCT was also considered. The PSNR is the most commonly used measure for image

quality evaluation. However, the SSIM measure consider visual human system characteristics which are not con-

sidered by PSNR [50]. Following the methodology proposed in [14], the average values of the measures over the

30 standard images were computed. It leads to statistically more robust results when compared with single image

analysis [30].

5.2 Results

Results of the still image compression experiment are presented in Figure 3 and 4.

In Figure 4(b), the curve

corresponding to the HT was suppressed because it presents excessively high values in comparison with other curves.
In terms of PSNR, ̂C8 outperforms both the SDCT and the BAS approximations; and provides similar results as to
those furnished by the WHT, but at a lower computational cost. For SSIM results, both transforms ̃C8 and ̂C8 show
similar results. In terms of PSNR, the proposed approximation ̂C8 performs closely to the WHT. Figure 3(a) and
3(b) show that ̂C8 is superior to the WHT at high compression ratios (r ≤ 15).

A qualitative analysis is displayed in Figure 5. Standard Elaine image was compressed and reconstructed accord-
ing to the SDCT, WHT, HT, BAS, and the proposed approximation ̂C8 for visual inspection. Compressed image
resulted from the exact DCT is also exhibited. All images were compressed with r = 6, which represents a removal of
approximately 90.6% of the transformed coeﬃcients. The visual analysis of the obtained images shows the superiority
of the proposed transform ̂C8 over the SDCT in image compression. Furthermore, Table 3 lists the PSNR and SSIM
values for the Elaine image, for r = 6. The PSNR and SSIM values are listed for two additional images (Lenna and
Boat images). The proposed transform ̂C8 outperforms the HT, WHT, and SDCT approximations in terms of PSNR
and SSIM and BAS approximation in terms of PSNR for the Elaine and Lenna images.

5.3 Blocking artifact analysis

A visually undesirable eﬀect in image compression is the emergence of blocking artifacts [17, p. 573]. Figure 6 shows a
qualitative comparison in terms of blocking artifact resulted from ̂C8, WHT, and BAS. The proposed approximation
̂C8 eﬀected a lower degree of blocking artifact comparatively with the WHT and BAS.

6 HEVC-compliant video encoding

In this section, we aim at demonstrating the practical real-world applicability of the proposed DCT approximations

for video coding. However, the HEVC standard requires not only an 8-point transform, but also 4-, 16-, and 32-

10

(a) Average PSNR

(b) Average PSNR absolute percentage error relative to the DCT.

Figure 3: PSNR measures for several compression ratios.

(a) Average SSIM

(b) Average SSIM absolute percentage error relative to the DCT

Figure 4: SSIM measures for several compression ratios.

point transforms. In order to derive Chen’s DCT approximations for larger blocklengths, we considered the algorithm

proposed by Jridi-Alfalou-Meher (JAM) [29]. We embedded these low-complexity transforms into a publicly available

reference software compliant with the HEVC standard [28].

The JAM algorithm consists of a scalable method for obtaining higher order transforms from an 8-point DCT

approximation. An N -point DCT approximation ˇTN , where N is a power of two, is recursively obtained through:

ˇTN =

1
√

2

Mper
N

ˇT N
⎡
⎢
⎢
⎢
⎢
⎣

2
0 N
2

0 N
2
ˇT N

2

⎤
⎥
⎥
⎥
⎥
⎦

Madd
N ,

11

05101520253035404522242628303234363840rAverage PSNR  DCTbC8eC8SDCTBASWHTHT05101520253035404500.050.10.150.20.25rAPE (PSNR)  bC8eC8SDCTBASWHTHT0510152025303540450.550.60.650.70.750.80.850.90.951rAverage SSIM  DCTbC8eC8SDCTBASWHTHT05101520253035404500.010.020.030.040.050.060.070.080.09rAPE (SSIM)  bC8eC8SDCTBASWHT(a) DCT

(b) SDCT

(c) WHT

(d) HT

(e) BAS

(f) ̂C8

Figure 5: Elaine image (r = 6): ?? DCT, ?? SDCT, ?? WHT, ?? HT, ?? BAS and ?? ̂C8.

where

Madd

N =

⎡
I N
⎢
⎢
2
⎢
¯I N
⎢
⎣

2

¯I N

2

−I N

2

⎤
⎥
⎥
⎥
⎥
⎦

and Mper

N =

⎡
⎢
⎢
⎢
⎢
⎣

PN −1, N
01, N

2

2

01, N
PN −1, N

2

2

,

⎤
⎥
⎥
⎥
⎥
⎦

2

is an (N − 1) × (N /2) resulting from expanding the identity matrix I N
N is a permutation matrix and does not introduce any arithmetic cost. Matrix Madd

by interlacing it with zero rows.
and PN −1, N
The matrix Mper
N contributes with
2 can be merged into the image compression quantization step
only N additions. Furthermore, the scaling factor 1/
and does not contribute to the arithmetic complexity of the transform. Thus, the additive complexity of ˇTN is equal
to twice the additive complexity of ˇT N

plus N additions [29].

√

2

2

6.1 Chen’s DCT approximations for large blocklengths

In its original form, the JAM algorithm employs the 8-point DCT approximation introduced in [14]. In this section,

we adapt the JAM algorithm to derive DCT approximations based on Chen’s algorithm for arbitrary power-of-two
(N > 8) blocklengths. We are specially interested in 16- and 32-point low-complexity transformations for subsequent
embedding into the HEVC standard. Let N > 8 be a power of two. We introduce the Chen’s signed and rounded

12

Table 3: Quality measures for three compressed images, considering r = 6

Elaine image

Lenna image

Boat image

Transform PSNR SSIM PSNR SSIM PSNR SSIM

DCT [12]
̂C8
BAS [7]
WHT [23]
SDCT [20]
HT [42]

31.03
30.00
29.45
28.91
27.59
25.44

0.95
0.94
0.94
0.92
0.88
0.77

29.90
28.79
28.28
27.93
26.26
24.27

0.95
0.94
0.95
0.92
0.88
0.75

26.94
26.04
26.13
25.85
24.09
24.27

0.92
0.91
0.92
0.90
0.85
0.68

(a) WHT

(b) BAS

(c) ̂C8

Figure 6: Blocking artifact eﬀect in the Elaine image (r = 6): ?? WHT, ?? BAS and ?? ̂C8.

transformations, respectively, according to the following recursion:

̃TN = Mper

N

⎡
⎢
⎢
⎢
⎢
⎣

̃T N
2
0 N
2

0 N
2
̃T N
2

⎤
⎥
⎥
⎥
⎥
⎦

Madd
N

and

̂TN = Mper

N

⎡
⎢
⎢
⎢
⎢
⎣

̂T N
2
0 N
2

0 N
2
̂T N
2

⎤
⎥
⎥
⎥
⎥
⎦

Madd
N .

Based on (7) and (8), ̃T N
2

and ̂T N
2

admit the following factorizations:

̃T N

2 =

̂T N

2 =

ˇP N

2

ˇP N

2

M(1)

N
2

̃M(2)

N
2

̃M(3)

N
2

̃M(4)

N
2

M(1)

N
2

̂M(2)

N
2

̂M(3)

N
2

̂M(4)

N
2

ˇB N

2

ˇB N

2

,

.

Thus, applying the factorizations above in (13) and expanding them, we obtain:

where

ˇPN M(1)
ˇPN M(1)

N ̃M(2)
N ̂M(2)

N ̃M(3)
N ̂M(3)

N ̃M(4)
N ̂M(4)

N

N

ˇBN ,
ˇBN ,

̃TN =
̂TN =

ˇP N

2
0 N
2

0 N
2
ˇP N

2

,

⎤
⎥
⎥
⎥
⎥
⎦

N

⎡
⎢
⎢
⎢
⎢
⎣
̃M(i)

N
2
0 N
2

ˇPN = Mper

ˇBN =

̃M(i)

N =

⎡
⎢
⎢
⎢
⎢
⎢
⎣

0 N
2
̃M(i)

N
2

⎤
⎥
⎥
⎥
⎥
⎥
⎦

, ̂M(i)

N =

⎡
⎢
⎢
⎢
⎢
⎢
⎣

2
0 N
2

ˇB N
⎡
⎢
⎢
⎢
⎢
⎣
̂M(i)

N
2
0 N
2

Madd

N , M(1)

N =

M(1)

N
2
0 N
2

⎡
⎢
⎢
⎢
⎢
⎢
⎣

0 N
2
M(1)

N
2

,

⎤
⎥
⎥
⎥
⎥
⎥
⎦

i = 2, 3, 4.

0 N
2
ˇB N

⎤
⎥
⎥
⎥
⎥
⎦
2
⎤
⎥
⎥
⎥
⎥
⎥
⎦

,

0 N
2
̂M(i)

N
2

(13)

(14)

(15)

13

Their inverse transformations possess the following factorizations:

̃T−1

N =

̂T−1

N =

4
N
4
N

ˇB⊺

N ̃M(4)

N

ˇB⊺

N ̂M(4)

N

−1

̃M(3)
N

−1

̃M(2)
N

−1

M(1)
N

⊺ ˇP⊺
N ,

−1

̂M(3)
N

−1

̂M(2)
N

−1

M(1)
N

⊺ ˇP⊺
N ,

(16)

(17)

where

ˇP⊺

N =

−1

̃M(i)
N

=

0 N
2
ˇP⊺

N
2

−1

ˇP⊺

N
2
0 N
2

̃M(i)

N
2
0 N
2

⎡
⎢
⎢
⎢
⎢
⎢
⎣
⎡
⎢
⎢
⎢
⎢
⎢
⎣

Mper
N

⊺ ,

⎤
⎥
⎥
⎥
⎥
⎥
⎦

ˇB⊺

N = Madd

N

0 N
2

̃M(i)

N
2

−1

⎤
⎥
⎥
⎥
⎥
⎥
⎦

, ̂M(i)
N

−1

=

⎡
⎢
⎢
⎢
⎢
⎢
⎣

ˇB⊺

N
2
0 N
2

⊺

⎡
⎢
⎢
⎢
⎢
⎢
⎣
̂M(i)

−1

N
2
0 N
2

0 N
2
ˇB⊺

⎤
⎥
⎥
⎥
⎥
⎥
⎦
0 N
2

N
2

̂M(i)

N
2

−1

,

⎤
⎥
⎥
⎥
⎥
⎥
⎦

i = 2, 3, 4.

, M(1)
N

⊺

=

⊺

M(1)

N
2
0 N
2

⎡
⎢
⎢
⎢
⎢
⎢
⎣

0 N
2
M(1)

N
2

⊺

,

⎤
⎥
⎥
⎥
⎥
⎥
⎦

In particular, for N = 16, we have from (7) and (8) that ˇP8 = P8, ˇB8 = B8, M(1)
i = 2, 3, 4, and therefore it yields:

8 = M1, ̃M(i)

8 = ̃Mi, ̂M(i)

8 = ̂Mi,

̃T16 =
̂T16 =

ˇP16 M(1)
ˇP16 M(1)

16 ̃M(2)
16 ̂M(2)

16 ̃M(3)
16 ̂M(3)

16 ̃M(4)
16 ̂M(4)

16

16

ˇB16,
ˇB16,

where

ˇP16 = Mper

16

P8
08
08 P8

⎡
⎢
⎢
⎢
⎢
⎣

,

⎤
⎥
⎥
⎥
⎥
⎦

ˇB16 =

B8
08
08 B8

⎡
⎢
⎢
⎢
⎢
⎣
⎡
08
̂Mi
⎢
⎢
⎢
08 ̂Mi
⎢
⎣

,

⎤
⎥
⎥
⎥
⎥
⎦

Madd

16 , M(1)

16 =

⎤
⎥
⎥
⎥
⎥
⎦

M1
08
08 M1

⎡
⎢
⎢
⎢
⎢
⎣

,

⎤
⎥
⎥
⎥
⎥
⎦

i = 2, 3, 4.

̃M(i)

16 =

⎡
⎢
⎢
⎢
⎢
⎣

08
̃Mi
08 ̃Mi

⎤
⎥
⎥
⎥
⎥
⎦

, ̂M(i)

16 =

The near orthogonal DCT approximations linked to the proposed low-complexity matrices are given by (cf.

Section 3.1):

̃CN = ̃SN ̃TN ,

̂CN = ̂SN ̂TN ,

where ̃SN =

√

[diag(̃TN ̃T⊺

N )]−1 and ̂SN =

√

[diag(̂TN ̂T⊺

N )]−1.

Because the entries of ̃T8 and ̂T8 and their inverses are in the set P = {0, ±

1
2 , ±1, ±2}, we have that the matrices
in (14), (15), (16) and (17) also have entries in P. Moreover, (14), (15), (16) and (17) can also be recursively obtained
from (7), (8), (9), and (10). Thus, ̃CN and ̂CN are low-complexity DCT approximations for blocklength N . The
arithmetic complexity of the proposed 16- and 32-point Chen’s approximations and transformations prescribed in

the HEVC standard are presented in Table 4. In terms of hardware implementation, the circuitry corresponding to
̃C8 and ̂C8 and their inverses can be re-used for the hardware implementation of both the direct and inverse Chen’s
DCT approximations for larger blocklengths.

6.2 Results

The proposed approximations were embedded into the HEVC reference software [28]. For video coding experiments

we considered two set of videos, namely: (i) Group A, which consider eleven CIF videos from [52]; (ii) Group B,

with six standard video sequence, one for each class speciﬁed in the Common Test Conditions (CTC) document for

HEVC [6]. Such classiﬁcation is based on the resolution, frame rate and, as consequence, the main applications of

these kind of media [36]. All test parameters were set according to the CTC document, including the quantization

14

Table 4: Arithmetic complexity of the considered 16- and 32-point transforms

Transform

Mult Add

Shift Total

16-point exact DCT [12]
16-point transform in HEVC [34]
̂C16
̃C16
32-point exact DCT [12]
32-point transform in HEVC [34]
̂C32
̃C32

44
0
0
0
116
0
0
0

74
186
60
68
194
682
152
168

0
86
0
0
0
278
0
0

118
272
60
68
310
960
152
168

parameter (QP) that assumes values in {22, 27, 32, 37}. As suggested in [29], we selected the Main proﬁle and
All-Intra mode for our experiments.

The PSNR measurements—already furnished by the reference software—were obtained for each video frame and

YUV channel. The overall PSNR was obtained from each frame according to [37]. We averaged the PSNR values

for the ﬁrst 100 frames of all videos in each group. Figure 7 shows the average PSNR in terms of the quantization
parameter (QP) for each set of 8-, 16-, and 32-point transforms: ̃CN , ̂CN , and the original transforms in the HEVC
standard. Results in Figure 7 show no signiﬁcant degradation in terms of PSNR regardless of the video group. The

proposed approximations resulted in essentially the same frame quality while having a very low computational cost

when compared to those originally employed in HEVC.

Additionally, we computed the Bjøntegaard delta PSNR (BD-PSNR) and delta rate (BD-Rate) [19, 4] for com-

pressed videos considering all discussed 8- to 32-point transformations. The ﬁrst 11 rows of Table 5 present the results

for the Group A whilst the remaining ones correspond to Group B. We report a negligible impact in video quality

associated to the results from the modiﬁed HEVC with the approximate transforms. Similar to the still images
experiments, ̂CN performed better than ̃CN with a degradation of no more than 0.70dB and 0.58dB for Groups A
and B, respectively. These declines in PSNR represent an increase of 10.63% and 7.02% in bitrate, respectively.

As a qualitative example, Figure 8 displays particular frames of Silent and PeopleOnStreet video sequences
after compression according to the original HEVC and to the modiﬁed versions of HEVC based on the proposed

transforms. Visual inspection shows no sign of image quality degradation.

7 Conclusion

We introduced two new multiplierless DCT approximations based on the Chen’s factorization. The suggested ap-
proximations were assessed and compared with other well-known approximations. The proposed transformation ̂C8
presented low total error energy and very close similarity to the exact DCT. Furthermore, ̂C8 presents very close cod-
ing gain when compared to the optimal KLT. The approximation ̂C8 outperformed the SDCT, BAS, and HT as tools
for JPEG-like still image compression at a lower computational cost. Adapting the JAM scalable method, we also
proposed low-complexity Chen’s DCT approximations ̃CN and ̂CN , were N ≥ 16 is a power of two; we also provided
fast algorithms for their implementations. The introduced 8-, 16-, and 32-point approximations were embedded into

an HEVC reference software and assessed for video compression. Finally, the proposed low-complexity transforms are

suitable for image and video coding, being a realistic alternative for eﬃcient and low complexity image/video coding.

Acknowledgments

This research was partially supported by CAPES, CNPq, and FAPERGS, Brazil.

15

(a)

(b)

Figure 7: Average PSNR for QP in {22,27,32,37} for videos in Groups (a) A and (b) B.

Table 5: Bjøntegaard metrics for the approximate transforms and tested video sequences

Video information

Akiyo
Bowing
Coastguard
Container
Foreman
Hall monitor
Mobile
Mother daughter
News
Pamphlet
Silent

PeopleOnStreet
BasketballDrive
RaceHorses
BlowingBubbles
KristenAndSara
BasketballDrillText

BD-PSNR (dB)

̃CN

̂CN

BD-Rate (%)
̂CN
̃CN

0.4600
0.5301
0.7596
0.4075
0.2263
0.2754
0.2752
0.4202
0.2539
0.4253
0.3029

0.5350
0.3372
0.6444
0.2563
0.4651
0.1984

0.2990
0.4316
0.7026
0.3750
0.1627
0.1952
0.2629
0.3384
0.1975
0.3680
0.2399

0.4734
0.2531
0.5781
0.1986
0.3807
0.1565

−7.0310
−7.4519
−11.3634
−6.3002
−4.4006
−4.7577
−2.7072
−7.8362
−3.4211
−5.8660
−5.7215
−9.6530
−11.7780
−7.7823
−4.3438
−8.8416
−3.7436

−4.6870
−6.1509
−10.6298
−5.8044
−3.2148
−3.4125
−2.5860
−6.4112
−2.6772
−5.1057
−4.6042
−8.6227
−9.0093
−7.0233
−3.4080
−7.3234
−2.9711

16

20253035QP32343638404244AveragePSNR(dB)HEVCbCNeCN20253035QP3436384042AveragePSNR(dB)HEVCbCNeCN(a) HEVC

(b) ̃CN

(c) ̂CN

(d) HEVC

(e) ̃CN

(f) ̂CN

Figure 8: Qualitative comparison of frames from Silent and PeopleOnStreet videos compressed with proposed
Chen’s DCT approximations and default HEVC transforms and QP=32.

References

[1] The USC-SIPI Image Database, University of Southern California, Signal and Image Processing Institute., 2011.
[2] N. Ahmed, T. Natarajan, and K. R. Rao, Discrete Cosine Transform, IEEE Trans. Comput., C-23 (1974), pp. 90–93.
[3] F. M. Bayer and R. J. Cintra, DCT-like transform for image compression requires 14 additions only, Electron. Lett.,

48 (2012), pp. 919–921.

[4] G. Bjøntegaard, Calculation of average PSNR diﬀerences between RD-curves, in 13th VCEG Meeting, Austin, TX,

USA, Apr 2001. Document VCEG-M33.

[5] R. E. Blahut, Fast Algorithms for Signal Processing, Cambridge University Press, 2010.
[6] F. Bossen, Common test conditions and software reference conﬁgurations, 2013. Document JCT-VC L1100.
[7] S. Bouguezel, M. O. Ahmad, and M. N. S. Swamy, A multiplication-free transform for image compression, in 2nd

International Conference on Signals, Circuits and Syst. (SCS), Nov. 2008, pp. 1–4.

[8]

[9]

, A novel transform for image compression, in IEEE 53rd International Midwest Symposium on Circuits Syst.

(MWSCAS), Aug. 2010, pp. 509–512.

, A low-complexity parametric transform for image compression, in IEEE International Symposium on Circuits Syst.

(ISCAS), May 2011, pp. 2145–2148.

[10] V. Britanak, P. C. Yip, and K. R. Rao, Discrete Cosine and Sine Transforms: General Properties, Fast Algorithms

and Integer Approximations, Elsevier Science, 2010.

[11] T. S. Chang, C. S. Kung, and C. W. Jen, A simple processor core design for DCT/IDCT, IEEE Trans. Circuits Syst.

Video Technol., 10 (2000), pp. 439–447.

[12] W. H. Chen, C. Smith, and S. Fralick, A fast computational algorithm for the Discrete Cosine Transform, IEEE Trans.

Commun., 25 (1977), pp. 1004–1009.

[13] R. J. Cintra, An integer approximation method for discrete sinusoidal transforms, Circuits, Syst., and Signal Process.,

30 (2011), pp. 1481–1501.

[14] R. J. Cintra and F. M. Bayer, A DCT approximation for image compression, IEEE Signal Process. Lett., 18 (2011),

pp. 579–582.

[15] M. Effros, H. Feng, and K. Zeger, Suboptimality of the Karhunen-Lo`eve transform for transform coding, IEEE Trans.

Inf. Theory, 50 (2004), pp. 1605–1619.

17

[16] B. N. Flury and W. Gautschi, An algorithm for simultaneous orthogonal transformation of several positive deﬁnite

symmetric matrices to nearly diagonal form, SIAM J. Sci. Stat. Comput., 7 (1986), pp. 169–184.

[17] R. C. Gonzalez and R. E. Woods, Digital image processing, Prentice-Hall, Inc., Upper Saddle River, NJ, USA, 3rd ed.,

2006.

[18] J. Han, Y. Xu, and D. Mukherjee, A butterﬂy structured design of the hybrid transform coding scheme, in Picture

Coding Symposium, 2013, pp. 1–4.

[19] P. Hanhart and T. Ebrahimi, Calculation of average coding eﬃciency based on subjective quality scores, J. Vis. Commun.

Image R., 25 (2014), pp. 555–564.

[20] T. I. Haweel, A new square wave transform based on the DCT, Signal Process., 81 (2001), pp. 2309–2319.
[21] N. J. Higham, Computing the polar decomposition with applications, SIAM J. Sci. Stat. Comput., 7 (1986), pp. 1160–1174.
[22] N. J. Higham, Computing real square roots of a real matrix, Linear Algebra Appl., 88–89 (1987), pp. 405–430.
[23] K. J. Horadam, Hadamard matrices and their applications, Cryptography Commun., 2 (2010), pp. 129–154.
[24] Q. Huynh-Thu and M. Ghanbari, Scope of validity of PSNR in image/video quality assessment, Electron. Lett., 44

(2008), pp. 800–801.

[25] International Organisation for Standardisation, Generic coding of moving pictures and associated audio information

– Part 2: Video, ISO/IEC JTC1/SC29/WG11 - coding of moving pictures and audio, ISO, 1994.

[26] International Telecommunication Union, ITU-T recommendation H.261 version 1: Video codec for audiovisual ser-

vices at p × 64 kbits, tech. rep., ITU-T, 1990.

[27]
[28] Joint Collaborative Team on Video Coding (JCT-VC), HEVC reference software documentation, 2013. Fraunhofer

, ITU-T recommendation H.263 version 1: Video coding for low bit rate communication, tech. rep., ITU-T, 1995.

Heinrich Hertz Institute.

[29] M. Jridi, A. Alfalou, and P. K. Meher, A generalized algorithm and reconﬁgurable architecture for eﬃcient and scalable

orthogonal approximation of DCT, IEEE Trans. Circuits Syst. I, Reg. Papers, 62 (2015), pp. 449–457.

[30] S. M. Kay, Fundamentals of Statistical Signal Processing, Volume I: Estimation Theory, vol. 1 of Prentie Hall Signal

Processing Series, Prentice Hall, Upper Saddle River, NJ, 1993.

[31] K. Lengwehasatit and A. Ortega, Scalable variable complexity approximate forward DCT, IEEE Trans. Circuits Syst.

Video Technol., 14 (2004), pp. 1236–1248.

[32] J. Liang and T. D. Tran, Fast multiplierless approximations of the DCT with the lifting scheme, IEEE Trans. Signal

Process., 49 (2001), pp. 3032–3044.

[33] C. Loeffler, A. Ligtenberg, and G. S. Moschytz, Practical fast 1-D DCT algorithms with 11 multiplications, in

International Conference on Acoust., Speech, Signal Process. (ICASSP), May 1989, pp. 988–991.

[34] P. K. Meher, S. Y. Park, B. K. Mohanty, K. S. Lim, and C. Yeo, Eﬃcient Integer DCT Architectures for HEVC,

IEEE Trans. Circuits Syst. Video Technol., 24 (2014), pp. 168–178.

[35] J. K. Merikoski, On the trace and the sum of elements of a matrix, Linear Algebra Appl., 60 (1984), pp. 177–185.
[36] M. Naccari and M. Mrak, Chapter 5 - perceptually optimized video compression, in Academic Press Library in signal

Processing Image and Video Compression and Multimedia, vol. 5, Elsevier, 2014, pp. 155–196.

[37] J.-R. Ohm, G. J. Sullivan, H. Schwarz, T. K. Tan, and T. Wiegand, Comparison of the coding eﬃciency of video
coding standards - including high eﬃciency video coding (HEVC), IEEE Trans. Circuits Syst. Video Technol., 22 (2012),
pp. 1669–1684.

[38] M. T. Pourazad, C. Doutre, M. Azimi, and P. Nasiopoulos, HEVC: The new gold standard for video compression:

How does HEVC compare with H.264/AVC?, IEEE Consum. Electron. Mag., 1 (2012), pp. 36–46.

[39] A. Puri, X. Chen, and A. Luthra, Video coding using the H.264/MPEG-4 AVC compression standard, Signal Process.:

Image Commun., 19 (2004), pp. 793–849.

[40] N. Roma and L. Sousa, Eﬃcient hybrid DCT-domain algorithm for video spatial downscaling, EURASIP J. Adv. Signal

Process, 2007 (2007), pp. 1–16.

[41] G. A. F. Seber, A Matrix Handbook for Statisticians, John Wiley & Sons, Inc, 2008.
[42] J. Seberry, B. J. Wysocki, and T. A. Wysocki, On some applications of Hadamard matrices, Metrika, 62 (2005),

pp. 221–239.

[43] N. Suehiro and M. Hatori, Fast algorithms for the DFT and other sinusoidal transforms, IEEE Trans. Acoust., Speech,

Signal Process., 34 (1986), pp. 642–644.

[44] T. Suzuki and M. Ikehara, Integer DCT based on direct-lifting of DCT-IDCT for lossless-to-lossy image coding, IEEE

Trans. Image Process., 19 (2010), pp. 2958–2965.

[45] C. Tablada, F. Bayer, and R. Cintra, A class of DCT approximations based on the Feig-–Winograd algorithm, Signal

Process., 113 (2015), pp. 38–51.

[46] G. Wallace, The JPEG still picture compression standard, IEEE Trans. Consum. Electron., 38 (1992), pp. 18–34.

18

[47] Z. Wang, Reconsideration of: A fast computational algorithm for the Discrete Cosine Transform, IEEE Trans. Commun.,

31 (1983), pp. 121–123.

[48]

, Fast algorithms for the discrete W transform and for the Discrete Fourier Transform, IEEE Trans. Acoust.,

Speech, Signal Process., 32 (1984), pp. 803–816.

[49] Z. Wang and A. C. Bovik, Mean squared error: Love it or leave it? A new look at signal ﬁdelity measures, IEEE Signal

Process. Mag., 26 (2009), pp. 98–117.

[50] Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, Image quality assessment: from error visibility to structural

similarity, IEEE Trans. Image Process., 13 (2004), pp. 600–612.

[51] D. Watkins, Fundamentals of Matrix Computations, Pure and Applied Mathematics: A Wiley Series of Texts, Monographs

and Tracts, Wiley, 2004.

[52] Xiph.Org Foundation, Xiph.org video test media, 2014.
[53] W. Yuan, P. Hao, and C. Xu, Matrix factorization for fast DCT algorithms, in IEEE International Conference on

Acoust., Speech, Signal Process. (ICASSP), vol. 3, May 2006, pp. 948–951.

19

