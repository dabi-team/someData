2
2
0
2

r
a

M
7
1

]

C
D
.
s
c
[

1
v
4
8
3
9
0
.
3
0
2
2
:
v
i
X
r
a

Benchmarking a Proof-of-Concept Performance Portable SYCL-based Fast
Fourier Transformation Library

VINCENT R. PASCUZZI, Brookhaven National Laboratory, USA
MEHDI GOLI, Codeplay Software Ltd., UK

In this paper, we present an early version of a SYCL-based FFT library, capable of running on all major vendor hardware, including

CPUs and GPUs from AMD, ARM, Intel and NVIDIA. Although preliminary, the aim of this work is to seed further developments

for a rich set of features for calculating FFTs. It has the advantage over existing portable FFT libraries in that it is single-source, and

therefore removes the complexities that arise due to abundant use of pre-process macros and auto-generated kernels to target different

architectures. We exercise two SYCL-enabled compilers, Codeplay ComputeCpp and Intelâ€™s open-source LLVM project, to evaluate

performance portability of our SYCL-based FFT on various heterogeneous architectures. The current limitations of our library is
it supports single-dimension FFTs up to 211 in length and base-2 input sequences. We compare our results with highly optimized
vendor specific FFT libraries and provide a detailed analysis to demonstrate a fair level of performance, as well as potential sources of

performance bottlenecks.

CCS Concepts: â€¢ Computing methodologies â†’ Distributed programming languages; â€¢ Mathematics of computing â†’ Math-
ematical software performance.

Additional Key Words and Phrases: hpc, performance, portability, sycl, fft, algorithms

ACM Reference Format:
Vincent R. Pascuzzi and Mehdi Goli. 2022. Benchmarking a Proof-of-Concept Performance Portable SYCL-based Fast Fourier Transfor-
mation Library. In . ACM, New York, NY, USA, 12 pages. https://doi.org/XXXXXXX.XXXXXXX

1 INTRODUCTION

The Fast Fourier Transform (FFT) is a widely used algorithm for efficiently computing the discrete Fourier transforms

(DFT) of complex- or real-valued data sequences. The transformed data can be decomposed into the multiple pure

frequencies that make it up, a technique useful in a wide range of applicationsâ€”from fault analysis, quality control,

and condition monitoring of machines or systems to AI machine learning and deep learning [15]. As such, there

are numerous FFT implementations provided by nearly all vendors; however, these implementations are tied to a

single architecture or platform, requiring management of multiple codebases for a single software framework or

application. Several frameworks existâ€”such as FFTW [6, 12] and VkFFT [16]â€”which embed various FFT APIs through

the use of pre-process macros and vendor-supplied libraries to auto-generate architecture-specific kernels to target
different devices. While such codes are undoubtedly powerful, they suffer in readability (e.g., extensive use of macros)
and maintainability (e.g., multi-language code generation). Moreover, supporting constantly evolving APIs and their
languages, while also providing backward compatibility, complicates macro- and code-generation-based solutions

further. As an alternative to the above approach, open-standard parallel programming APIs, such as SYCL, can be used

to implement FFT and other algorithms directly to support multiple hardware platforms. Although performance of

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.

Â© 2022 Association for Computing Machinery.
Manuscript submitted to ACM

1

 
 
 
 
 
 
IWOCL and SYCLcon â€™22, May 10â€“12, 2022, Virtual

Pascuzzi and Goli

vendor-specific APIs is likely to be better in practice, a SYCL-based FFT will provide portability and also address the

readability and maintainability pitfalls. Whereas our previous work on linear algebra and random number generation

routines [10, 13] utilized SYCLâ€™s interoperability functionality, here we instead implement FFT algorithms directly using

the SYCL programming modelâ€”removing entirely the reliance on third-party libraries.

2 RELATED WORK

There are several implementations of FFTs supporting various architectures. FFTW is a C based implementation of

discrete Fourier transform that has been adopted mainly for CPU use. However, the code generated by an auto generator
tool can potentially make the support of new devices and architectures difficult1. VkFFT provides an open source FFT
library for accelerators by providing backend implementation of CUDA, OpenCL, HIP, and Vulkan. However, both

the library code itself (a single header totaling nearly 40k lines) and generated codes suffer from code duplication due

to the lack of high-level programming feature support. In practice, this tends to make code more error prone, less

maintainable and more difficult to add or optimise for new devices.

There are several vendors specified FFT which are been tuned specific architectures but are vendor-locked and not

portable to other others. cuFFT[11] is a closed-source FFT API that runs only on NVIDIA devices. The package also

provides cuFFTW, a porting tool to enable users of FFTW to leverage NVIDIA GPU compute capabilities. oneMKL[9]

also provide a closed-source FFT library that runs on x86_64 architectures, and AMD provides rocFFT[1] for computing

FFTs on ROCm architectures.

In this paper, we introduce SYCL-FFT, an open- and single-source FFT implementation to target a wide range of

heterogeneous devices. The development employs modern C++ features, such as template meta-programming supported

by SYCL, to provide a parametric representation of FFT kernels that can abstract out the kernel implementation from the

kernel modification. Using this approach, it is possible to tune the same kernel for various architectures with little-to-no

modification to the actual kernel implementation.

3 FAST FOURIER TRANSFORM

Fast Fourier transforms are computed by discretizing the input function, represented in a time or space domain, and

mapping it to an output, represented in its frequency domain. In closed form, the 1D DFT is written as,

ğ‘‹ğ‘˜ =

ğ‘ âˆ’1
âˆ‘ï¸

ğ‘›=0

ğ‘¥ğ‘›ğ‘’âˆ’ğ‘–2ğœ‹ğ‘˜ğ‘›/ğ‘ =

ğ‘ âˆ’1
âˆ‘ï¸

ğ‘›=0

ğ‘¥ğ‘›ğœ”ğ‘˜ğ‘›
ğ‘

(1)

where ğ‘˜ = [0, ğ‘ âˆ’ 1], {ğ‘¥ğ‘– } is the real- or complex-valued input sequence of length ğ‘ , and ğœ”ğ‘ = ğ‘’âˆ’ğ‘–2ğœ‹ /ğ‘ is the ğ‘ th de
Moivre number (root of unity). The inverse DFT (iDFT) is obtained simply by changing the sign in the exponent,

ğ‘›=0
with 1/ğ‘ being the normalization constant. From Eqns. (1), it can be seen that there are ğ‘ outputs, ğ‘‹ğ‘˜ , each of which
requires a sum of ğ‘ terms. Thus, a direct (naÃ¯ve) evaluation of the DFT has computational complexity O (ğ‘ 2).

ğ‘¥ğ‘˜ =

1
ğ‘

ğ‘ âˆ’1
âˆ‘ï¸

ğ‘¥ğ‘›ğœ”âˆ’ğ‘˜ğ‘›
ğ‘ ,

(2)

1From the Github site: â€œYOU WILL BE UNABLE TO COMPILE CODE FROM THIS REPOSITORY unless you have special tools and know what you are
doing.â€

2

A Proof-of-Concept SYCL FFT

IWOCL and SYCLcon â€™22, May 10â€“12, 2022, Virtual

Fig. 1. Illustration of a radix-2 DIT on an DFT with input size ğ‘ = 8. Intersecting vertical linesâ€”displaying butterfly-like patternsâ€”
among the input, {ğ‘¥ğ‘– }, correspond to combinations of additions and subtractions as per the twiddle factors, ğœ”ğ‘˜

ğ‘ ; see main text.

3.1 Cooley-Tukey algorithm

There are many FFT algorithms that reduce the complexity of DFT calculations [2â€“4, 7, 14], the most commonly used

being Cooley-Tukey [5]. Exploiting FFT periodicity, the Cooley-Tukey algorithm uses the divide-and-conquer technique

to recursivelyâ€”or using a breadth-first traversal of the computational treeâ€”reduce a DFT of composite length ğ‘ into

smaller DFTs. The simplest case of the Cooley-Tukey algorithm is the radix-2 decimation in time (DIT, bit order reversal),
illustrated in Figure 1 for a length ğ‘ = 8 DFT. In the radix-2 DIT, the input sequence of length ğ‘ is rearranged into two
subsets, one containing all even-indexed sequence elements and the other containing all odd-indexed elements. Each

subset is then separately summed over; from Eqn. (1),

ğ‘¥2ğ‘›ğœ” (2ğ‘›)ğ‘˜/ğ‘
ğ‘ /2

+

ğ‘ /2âˆ’1
âˆ‘ï¸

ğ‘›=0

ğ‘¥2ğ‘›+1ğœ” (2ğ‘›+1)ğ‘˜/ğ‘
ğ‘ /2

(cid:16)
ğ‘¥2ğ‘›ğœ”ğ‘˜ğ‘›

ğ‘ /2 + ğœ”ğ‘˜

ğ‘ ğ‘¥2ğ‘›+1ğœ”ğ‘˜ğ‘›
ğ‘ /2

(cid:17)

ğ‘ /2âˆ’1
âˆ‘ï¸

ğ‘›=0
ğ‘ /2âˆ’1
âˆ‘ï¸

ğ‘‹ğ‘˜ =

=

ğ‘›=0
â‰¡ ğ¸ğ‘˜ + ğœ”ğ‘˜

ğ‘ ğ‘‚ğ‘˜,

(3)

(4)

(5)

where the first factor includes even (ğ¸) indices and the second odd (ğ‘‚), and the summation is over ğ‘˜ = [0, ğ‘ /2 âˆ’ 1].
Given the periodicity of the complex exponential, the remaining ğ‘ /2 elements can be written similarly,

ğ‘‹ğ‘˜+ğ‘ /2 =

ğ‘ /2âˆ’1
âˆ‘ï¸

ğ‘›=0

(cid:16)
ğ‘¥2ğ‘›ğœ”ğ‘˜ğ‘›

ğ‘ /2 âˆ’ ğœ”ğ‘˜

ğ‘ ğ‘¥2ğ‘›+1ğœ”ğ‘˜ğ‘›
ğ‘ /2

(cid:17)

,

(6)

3

x0x4x2x6x1x5x3x7X0X1X2X3X4X5X6X7Ï‰02Ï‰02âˆ’Ï‰02âˆ’Ï‰02Ï‰02Ï‰02âˆ’Ï‰02âˆ’Ï‰02Ï‰04âˆ’Ï‰04âˆ’Ï‰14Ï‰14Ï‰04âˆ’Ï‰04âˆ’Ï‰14Ï‰14Ï‰08Ï‰28Ï‰38Ï‰18âˆ’Ï‰08âˆ’Ï‰28âˆ’Ï‰38âˆ’Ï‰18IWOCL and SYCLcon â€™22, May 10â€“12, 2022, Virtual

Pascuzzi and Goli

where the factor of âˆ’1 in the second term arises from an ğ‘’âˆ’ğ‘–ğœ‹ when simplifying. Provided the input length ğ‘ is a
power of 2, the original DFT can be split log ğ‘› times. Since there will still be a sum over ğ‘ terms for each splitting, the
complexity becomes O (ğ‘ log ğ‘›).

Higher-order radices can reduce the number of arithmetic operations needed to compute larger DFTs (e.g., radix-4,
radix-8 and radix-16), as can combinations of different radices (split-radix decompositions). A split-radix algorithm

reduces a single length ğ‘ DFT into three smaller summations at each step. As before, the summations are split into

even and odd indices, giving,

ğ‘ /2âˆ’1
âˆ‘ï¸

ğ‘‹ğ‘˜ =

ğ‘ /4âˆ’1
âˆ‘ï¸

ğ‘¥2ğ‘›2ğœ”ğ‘›2ğ‘˜

ğ‘ /2 +

ğ‘›2=0
â‰¡ ğ¸ğ‘˜ + ğœ”ğ‘˜

ğ‘›4=0
ğ‘ ğ‘‚ â€²
ğ‘˜,

ğ‘ ğ‘‚ğ‘˜ + ğœ”3ğ‘˜

(cid:16)
ğ‘ ğ‘¥4ğ‘›4+1ğœ”ğ‘›4ğ‘˜
ğœ”ğ‘˜

ğ‘ /4 + ğœ”3ğ‘˜

ğ‘ ğ‘¥4ğ‘›4+3ğœ”ğ‘›4ğ‘˜
ğ‘ /4

(cid:17)

(7)

(8)

with indices ğ‘›ğ‘š = ğ‘ /ğ‘š âˆ’ 1. Here, the first summation, ğ¸ğ‘˜ , is the even portion of a radix-2 DIT and the second,
ğ‘ ğ‘‚ğ‘˜ + ğœ”3ğ‘˜
ğœ”ğ‘˜
, contains the two odd portions of a radix-4. The efficiency of this algorithm is due again to the
periodicity of ğ‘˜; if we add ğ‘ /4 (ğ‘ /2) to ğ‘˜, the radix-4 (radix-2) portions are left unchanged. Using this fact, we see,

ğ‘ ğ‘‚ â€²
ğ‘˜

ğœ”ğ‘˜+ğ‘ /4
ğ‘
ğœ”3(ğ‘˜+ğ‘ /4)

ğ‘

= âˆ’ğ‘–ğœ”ğ‘˜
ğ‘ ,
= ğ‘–ğœ”3ğ‘˜
ğ‘ ;

(9)

(10)

i.e., only ğœ”ğ‘˜
ğ‘
domain can be calculated via,

and ğœ”3ğ‘˜
ğ‘

(so-called twiddle factors), need to be updated. As a result, all output values, ğ‘‹ğ‘˜ , in the frequency

ğ‘‹ğ‘˜ = ğ¸ğ‘˜ + ğœ”ğ‘˜
ğ‘‹ğ‘˜+ğ‘ /2 = ğ¸ğ‘˜ âˆ’ (ğœ”ğ‘˜
ğ‘‹ğ‘˜+ğ‘ /4 = ğ¸ğ‘˜+ğ‘ /4 âˆ’ ğ‘– (ğœ”ğ‘˜
ğ‘‹ğ‘˜+3ğ‘ /4 = ğ¸ğ‘˜+ğ‘ /4 + ğ‘– (ğœ”ğ‘˜

ğ‘ ğ‘‚ğ‘˜ + ğœ”3ğ‘˜
ğ‘ ğ‘‚ â€²
ğ‘˜
ğ‘ ğ‘‚ğ‘˜ + ğœ”3ğ‘˜
ğ‘ ğ‘‚ â€²
ğ‘˜ )
ğ‘ ğ‘‚ğ‘˜ âˆ’ ğœ”3ğ‘˜
ğ‘ ğ‘‚ğ‘˜ âˆ’ ğœ”3ğ‘˜

ğ‘ ğ‘‚ â€²
ğ‘˜ )
ğ‘ ğ‘‚ â€²
ğ‘˜ )

(11)

(12)

(13)

(14)

for ğ‘˜ = [0, ğ‘ /4]. The combinations of additions and subtractions are known as butterflies, depicted by the intersecting
vertical lines in Fig. 1.

4 IMPLEMENTATION

Our SYCL FFT library implements the Cooley-Tukey radix-2 algorithm described above, as well as radix-4, and radix-8

algorithms. The class interface is shown in Listing 1.

1
2
3
4
5
6
7
8
9
10
11
12

template < typename T , size_t WG_SIZE , int WG_FACTOR , int SYCL_LANGUAGE_VERSION >
class fft_1d {

public :

using float2 = sycl :: float2 ;

if constexpr ( SYCL_LANGUAGE_VERSION < 202000) {

using size_accessor = sycl :: accessor < size_t , 1 , sycl :: access :: mode :: read ,

using read_accessor = sycl :: accessor <T , 1, sycl :: access :: mode :: read ,

using write_accessor = sycl :: accessor <T , 1, sycl :: access :: mode :: write ,

sycl :: access :: target :: global_buffer >;

sycl :: access :: target :: global_buffer >;

sycl :: access :: target :: global_buffer >;

} else {

4

A Proof-of-Concept SYCL FFT

IWOCL and SYCLcon â€™22, May 10â€“12, 2022, Virtual

13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35

using stage_accessor = sycl :: accessor < size_t , 1, sycl :: access :: mode :: read ,

sycl :: access :: target :: device >;
using read_accessor = sycl :: accessor <T , 1, sycl :: access :: mode :: read ,

using write_accessor = sycl :: accessor <T , 1, sycl :: access :: mode :: write ,

sycl :: access :: target :: device >;

sycl :: access :: target :: device >;

}

using local_rw_accessor = sycl :: accessor <T , 1 , sycl :: access :: mode :: read_write ,

sycl :: access :: target :: local >;

if constexpr ( SYCL_LANGUAGE_VERSION >= 202000) {

[[ sycl :: reqd_work_group_size ( WG_SIZE ) ]]

}

};

fft1d ( size_accessor stage_sizes , read_accessor inputs ,

write_accessor outputs , local_rw_accessor local_shared ,
size_t work_group_size , int direction );
void operator () ( sycl :: nd_item <1 > item ) const {...}
inline void radix_2 ( sycl :: nd_item <1 > item , size_t stage_mod ,

inline void radix_4 ( sycl :: nd_item <1 > item , size_t stage_mod ,

float2 * temp ) const {...}

float2 * temp ) const {...}

inline void radix_8 ( sycl :: nd_item <1 > item , size_t stage_mod ,

float2 * temp ) const {...}

Listing 1. SYCL FFT function object interface.

The SYCL-FFT functor is a templated class requiring three template arguments to define the input data type, the required
work-group size and a constant, WG_FACTOR that depends on the input sequence length. Since variable array sizes are
not permitted in SYCL kernels, WG_FACTOR is automatically determined a priori on the host and the corresponding
kernel is called based on this value. The fft1d class takes five arguments to determine FFT execution; stage_sizes is
an array of numbers calculated on the host, used to derive the internal steps that need to be taken (e.g., the sequence of
radix function calls; inputs and outputs are memory allocations on the device for storing the sequence to transform
and the transformed output, respectively; local_shared is the cross-work-group shared memory; and direction
specifies whether to perform an FFT or iFFT (SYCLFFT_FORWARD or SYCLFFT_INVERSE).

It must be noted that our SYCL FFT library is largely a proof-of-concept work-in-progress, and therefore fairly

limited in capability and features. In its current state, the library can compute 1D single-precision complex-to-complex
(C2C) DFTs up to 211 in length2. All transforms are performed out-of-place. Nevertheless, the aim of this early work is
to provide the foundations for an open-source performance portable FFT library.

5 EXPERIMENTAL SETUP

To enable execution across a diverse set of platforms, we have employed two compilers. To target PTX64, HIP and

x86_64 architectures, Intel open-source LLVM compiler project (referred to simply as â€œIntel LLVMâ€ in what follows),
based on the sycl-nightly/20220223 branch based on LLVM major version 15, was used. Intel LLVM with support
for PTX64 and HIP was built using GCC 10.2.0 and 8.2.0, respectively, with CUDA 11.5.0 and ROCm 4.2.0. The Portable

Compute Language (POCL) used as an OpenCL driver along with Codeplayâ€™s ComputeCpp [] to run SYCL-FFT on

2This value is ultimately determined by the number of compute (execution) units available on a given device. For example, SYCL-FFT can perform on an
input length up to 212 on an ARM Neoverse CPU.

5

IWOCL and SYCLcon â€™22, May 10â€“12, 2022, Virtual

Pascuzzi and Goli

Device
(Architecture)

Maximum
Work-Group Size

ARM Neoverse-N1
(ARMv8-A)
Intel Xeon E3-1585 v5
(x86_64)
Intel Iris P580
(Gen9)
AMD MI-100
(CDNA)
NVIDIA A100
(Ampere)

4096

8192

256

256

1024

Backend

Compiler(s)

FFT Library

POCL 1.9
pre-gde9b966b
OpenCL 3.0
2021.12.9.0.24_005321
OpenCL 3.0
2021.12.9.0.24_005321

ComputeCpp 2.8.0

ComputeCpp 2.8.0

ComputeCpp 2.8.0

â€”

â€”

â€”

HIP 4.2.0

PTX64

sycl-nightly/20220223
hipcc 4.2.21155
sycl-nightly/20220223
nvcc 11.5.0

rocfft 4.2.0

cufft 11.5.0

Table 1. Device hardware and software versions for each platform considered in these studies. The sycl-nightly/x compilers refer
to the specific branch of the Intel LLVM compiler project. All systems run openSUSE 15.3, kernel version 5.3.18.

ARM CPU devices. The POCL host (where POCL runs) compiler was built using GCC 10.2.0 and its target (where

OpenCL runs) compiler using the Intel open-source LLVM compiler project. Due to LLVM compatibilty, the POCL
target compiler was built with the sycl-nightly/20220210 branch of Intel LLVM, as later nightlies bumped the LLVM
major version to 15 which is not yet supported by POCL. Details regarding the systems used in these studies are shown

in Table 1.

6 RESULTS

Without loss of generality, we evaluate our FFT library using the simple linear function ğ‘“ (ğ‘¥) = ğ‘¥. Input sequences in
the range 23â€“211 are produced on the host device and transferred to the device were the FFT is computed. All compute
nodes were dedicated and not shared among additional users during experimentation.

6.1 Computational Performance

The following timing measurements do not include host-side data preparation or data transfers between host and device.

Each data point corresponds to the mean of 1000 iterations for a given sequence length; the first launch is considered as
a â€œwarm-upâ€ and therefore discarded3.

Figure 2a shows the optimal total (kernel launch and execution) time out of 1000 test runs for computing the
FFT and iFFT for ğ‘“ (ğ‘¥) = ğ‘¥ on an NVIDIA A100 and AMD MI-100 using cuFFT (solid green), rocFFT (solid red)
and SYCL FFT (dashed curves). The SYCL FFT codes for both PTX64 and HIP backends were compiled using the
sycl-nightly/20220223 branch of Intel LLVM, built separately to target CUDA and AMDGPU, respectively. Compared
to the analogous vendor libraries, SYCL FFT is about half as performant, as seen by comparing the solid and dashed

curves in the figure. However, SYCL FFT total run-times are largely dominated by kernel launch overheads; disregarding

launch time and considering kernel execution time alone (dotted curves), it can be seen that dispatch overheads

are substantial, increasing the total execution time by a factor of 2â€“4. As such, kernel execution times do not vary

significantly, with SYCL FFT performing within 30% or better with respect to the corresponding vendor library. For

example, Fig. 2b shows that optimal SYCL-FFT run-times (chosen as the smallest of the 1000 test runs) do not differ

3The warm-up execution typically is a one-off, an order of magnitude or more larger than subsequent calculations.

6

A Proof-of-Concept SYCL FFT

IWOCL and SYCLcon â€™22, May 10â€“12, 2022, Virtual

largely from cuFFT or rocFFT. Similar behavior has been observed in previous studies [8], where the overhead of SYCL

runtime interacting with CUDA was constant 30 ğœ‡s.

(a) Optimal total (kernel dispatch + execution) run-times.

Fig. 2. SYCL-FFT, cuFFT and rocFFT run-times, in microseconds, on NVIDIA A100 and AMD MI-100 GPUs. Note the different scales
of each subfigure; in the best case, SYCL-FFT achieves very near native rocFFT kernel performance.

(b) Optimal kernel run-times.

A similar trend in launch overheads is observed for the Intel Iris P580 integrated GPU (iGPU) and ARM Neoverse

CPU, as seen in Fig. 3a. The Intel Iris P580 iGPU (blue, hexagons)â€”residing on the same silicon and sharing the same

memory as its host CPUâ€”is impacted most by launch times, fluctuating by as much as 20% between data points. In

contrast, the kernel execution times on the Intel iGPU is nearly flat across the input lengths considered. The ARM

Neoverse RISC-based CPU (gray, diamonds), which uses the POCL 1.9 prelease backend, shows the smallest launch

latency, though the kernel-only run-times are longer than would be expected. In addition, roughly 10% of the iterations

per sequence length run on the ARM system were discarded due to run-times exceeding the mean by an order of

magnitude. Lastly, the Intel x86_64 CPU has the smallest overheads of all platforms considered, and displays consistent
kernel and total execution times up to an input length of 29 where a linear increase occurs. As in the cuFFT and rocFFT

7

23242526272829210211Sequence Length1020304050FFT+iFFT [s]cuFFT-a100syclFFT-a100rocFFT-mi100syclFFT-mi10023242526272829210211Sequence Length510152025FFT+iFFT [s]cuFFT-a100syclFFT-a100rocFFT-mi100syclFFT-mi100IWOCL and SYCLcon â€™22, May 10â€“12, 2022, Virtual

Pascuzzi and Goli

case, Fig. 3b shows that optimal run-times are much improved compared to the mean of 1000 test runs which have a

large overall variance.

(a) Mean execution time.

(b) Optimal execution time.

Fig. 3. SYCL-FFT run-times, in microseconds, on ARM, and Intel CPU and iGPU.

In general, we observe fair computational performance of our SYCL FFT library to cuFFT and rocFFT at kernel
level. However, for kernels with run-times O (10) ğœ‡s, the dominant contribution to total run-times are the launching of
kernels on compute devices. These findings are summarized in Table 2.

6.2 Portability and Precision

A metric describing portability is entirely different from a metric for performance; portability and computational

throughput are arguable unrelated, and the former should pertain primarily to reproducibility (or consistency) of

the outputs. Moreover, performance is meaningless if results are not consistent to within some margin of error. To

measure portability, we therefore consider reproducibilityâ€”that is, the level at which our portable library agrees with

platform-specific analogs.

8

23242526272829210211Sequence Length02004006008001000FFT+iFFT [s]syclFFT-aarch64syclFFT-aarch64 (kernel)syclFFT-x86_64syclFFT-x86_64 (kernel)syclFFT-iris_p580syclFFT-iris_p580 (kernel)23242526272829210211Sequence Length0100200300400FFT+iFFT [s]syclFFT-aarch64 (optimal)syclFFT-aarch64 (kernel, optimal)syclFFT-x86_64 (optimal)syclFFT-x86_64 (kernel, optimal)syclFFT-iris_p580 (optimal)syclFFT-iris_p580 (kernel, optimal)A Proof-of-Concept SYCL FFT

IWOCL and SYCLcon â€™22, May 10â€“12, 2022, Virtual

Device

Compiler + Backend

Launch Latency [ğœ‡s]

ARM Neoverse-N1

ComputeCpp 2.8.0 + POCL 1.9
Intel Xeon E3-1585 v5 ComputeCpp 2.8.0 + OpenCL 3.0

Intel Iris P580
AMD MI-100
NVIDIA A100

ComputeCpp + OpenCL 3.0
Intel LLVM + HIP 4.2.0
Intel LLVM + CUDA 11.5.0

200-250
âˆ¼ 50
650-800
âˆ¼ 80
âˆ¼ 40 (13)

Table 2. Combinations of compiler and backend used to target the devices used in these studies, along with the range of corresponding
kernel launch latencies. Shown also (in parentheses) is associated latency using nvcc with cuFFT on the NVIDIA A-100, obtained from
an NVIDIA Nsight Compute profile.

A useful statistic for comparing distributions is the reduced ğœ’ 2 test, defined as:

ğœ’ 2
reduced =

ğ‘
âˆ‘ï¸

ğ‘–

(ğ‘ ğ‘– âˆ’ ğ‘›ğ‘– )2
ğ‘›ğ‘–

1
ndf

,

(15)

where the ğ‘ ğ‘– correspond to the SYCL FFT outputs, ğ‘›ğ‘– to the native library outputs in bin ğ‘– of their individual histograms,
each having ğ‘ bins, and ndf = ğ‘ âˆ’ 1. Since for large ğ‘ğ‘– the measurements are approximated by a Gaussian distribution,
the ğœ’ 2 test statistic follows a ğœ’ 2 distribution for ğ‘˜ = ndf degrees of freedom. The probability that a set of ğ‘€ measurements
would yield a ğœ’ 2 value greater than or equal to the one obtained is referred to as the ğ‘-value; a ğ‘-value close to unity is
representative of good agreement between the {ğ‘ ğ‘– } and {ğ‘›ğ‘– }.

In principle, FFT algorithms are well-defined and hence different algorithms should yield exact outputs at a given

precision. In practice, however, different rounding policies apply across devices and architectures. Also, during applica-

tion of sub-functions, textite.g., cos and sin, rounding operations which are non-associative can be applied at a low
level. Figure 4 shows the ratio |syclFFT âˆ’ cuFFT|/syclFFT, i.e., the difference between SYCL FFT and cuFFT output in
the frequency domain for ğ‘“ (ğ‘¥) = ğ‘¥. The calculated statistics ğœ’ 2/ndf = 3.47 Ã— 10âˆ’3 and ğ‘-value = 1.0 indicate a perfect
agreement across the range of input sequence lengths at single precision. The same comparison between SYCL FFT

Fig. 4. Absolute difference between SYCL-FFT and cuFFT outputs for a 2048 length DFT.

9

025050075010001250150017502000Frequency [Hz]0123456|syclFFTcuFFT|syclFFT [%]1e5  2/ndf=0.003470p-value=1.000000IWOCL and SYCLcon â€™22, May 10â€“12, 2022, Virtual

Pascuzzi and Goli

and rocFFT, shown in Fig. 5, reports a similar level of agreement between output FFT distributions. Since SYCL FFT is

implemented to use native trigonometric functions as defined by vendors when available, these are the expected results.

From a portable reproducibility perspective, SYCL FFT meets the desired precision.

Fig. 5. Absolute difference between SYCL-FFT and rocFFT outputs for a 2048 length DFT.

7 CONCLUSIONS

In this paper we introduced SYCL-FFT, a prototype performance portable Fast Fourier Transform library developed

using the SYCL programming model. Our library is based on Cooley-Tukey algorithms, giving ğ‘ log ğ‘› computational

performance. We test and benchmark SYCL-FFT on all major vendor platformsâ€”AMD, ARM, Intel and NVIDIAâ€”

including both CPUs and GPUs. To evaluate our library on various hardware, we used Codeplayâ€™s ComputeCpp and

Intelâ€™s open-source SYCL-enabled LLVM compiler in conjunction with Portable Open Compute Language (POCL),

Open Compute Language (OpenCL), PTX64 and HIP. Our initial analysis sheds light on a number of important features

pertaining to both the compilers and different backends employed in this work. Out of the box, SYCL-FFT shows a

roughly 2-3x performance hit compared to vendor-optimized libraries, however, attains the desired precision in both

time and frequency domains. Execution of over 1000 FFT exposed significant overhead costs in terms of kernel launches.

In particular, the overhead of the SYCL runtime, and especially kernel dispatch, affects the overall performance our

library. This observation is in direct agreement with previous work [8]; although the runtime overheads are significant

for small problem sizes, larger problems are impacted less as the gap between runtime and kernel execution increases.

Ongoing improvements to the various backend implementations and their offloading mechanisms can potentially close

the gaps between SYCL-basedâ€”and other portable librariesâ€”and vendor libraries. Based on these studies, AMD GPUs

are most efficient for small kernels.

Future work includes expanding the library to accommodate arbitrary input sizes and support for multidimensional

inputs. Ultimately, we aim to provide a set of SYCL-based mathematical libraries for performance portability across all

major platforms.

10

025050075010001250150017502000Frequency [Hz]0.000.250.500.751.001.251.501.75|syclFFThipFFT|syclFFT [%]1e5  2/ndf=0.000721p-value=1.000000A Proof-of-Concept SYCL FFT

IWOCL and SYCLcon â€™22, May 10â€“12, 2022, Virtual

ACKNOWLEDGMENTS

This work was supported by the DOE HEP Center for Computational Excellence at Brookhaven National Laboratory

under B&R KA2401045. The authors gratefully acknowledge the computing resources provided and operated by the

Joint Laboratory for System Evaluation (JLSE) at Argonne National Laboratory.

REFERENCES
[1] AMD. 2022. Software library for computing Fast Fourier Transforms (FFT) written in HIP. Github. Retrieved March 7, 2022 from https:

//github.com/ROCmSoftwarePlatform/rocFFT

[2] James B. Birdsong and Nicholas I. Rummelt. 2016. The hexagonal fast fourier transform. In 2016 IEEE International Conference on Image Processing

(ICIP). 1809â€“1812. https://doi.org/10.1109/ICIP.2016.7532670

[3] L. Bluestein. 1970. A linear filtering approach to the computation of discrete Fourier transform. IEEE Transactions on Audio and Electroacoustics 18, 4

(1970), 451â€“455. https://doi.org/10.1109/TAU.1970.1162132

[4] G. Bruun. 1978. z-transform DFT filters and FFTâ€™s.

IEEE Transactions on Acoustics, Speech, and Signal Processing 26, 1 (1978), 56â€“63. https:

//doi.org/10.1109/TASSP.1978.1163036

[5] James W Cooley and John W Tukey. 1965. An algorithm for the machine calculation of complex Fourier series. Mathematics of computation 19, 90

(1965), 297â€“301.

[6] M. Frigo and S.G. Johnson. 2005. The Design and Implementation of FFTW3. Proc. IEEE 93, 2 (2005), 216â€“231. https://doi.org/10.1109/JPROC.2004.

840301

[7] Gerald Goertzel. 1958. An Algorithm for the Evaluation of Finite Trigonometric Series. The American Mathematical Monthly 65, 1 (1958), 34â€“35.

http://www.jstor.org/stable/2310304

[8] Mehdi Goli, Kumudha Narasimhan, Ruyman Reyes, Ben Tracy, Daniel Soutar, Svetlozar Georgiev, Evarist M Fomenko, and Eugene Chereshnev. 2020.
Towards cross-platform performance portability of dnn models using sycl. In 2020 IEEE/ACM International Workshop on Performance, Portability and
Productivity in HPC (P3HPC). IEEE, 25â€“35.

[9] Intel. 2022. oneAPI Math Kernel Library (oneMKL). Website. Retrieved March 7, 2022 from https://spec.oneapi.io/versions/latest/elements/oneMKL/

source/index.html

[10] Mariia Krainiuk, Mehdi Goli, and Vincent R. Pascuzzi. 2021. oneAPI Open-Source Math Library Interface. In 2021 International Workshop on

Performance, Portability and Productivity in HPC (P3HPC). 22â€“32. https://doi.org/10.1109/P3HPC54578.2021.00006

[11] NVIDIA. 2022. Fast Fourier Transforms for NVIDIA GPUs. Website. Retrieved March 7, 2022 from https://developer.nvidia.com/cufft
[12] David Padua. 2011. FFTW. Springer US, Boston, MA, 671â€“671. https://doi.org/10.1007/978-0-387-09766-4_397
[13] Vincent R. Pascuzzi and Mehdi Goli. 2021. Achieving near native runtime performance and cross-platform performance portability for random number
generation through SYCL interoperability. arXiv e-prints, Article arXiv:2109.01329 (Sept. 2021), arXiv:2109.01329 pages. arXiv:2109.01329 [cs.DC]
[14] C.M. Rader. 1968. Discrete Fourier transforms when the number of data samples is prime. Proc. IEEE 56, 6 (1968), 1107â€“1108. https://doi.org/10.

1109/PROC.1968.6477

[15] K. R. Rao, D. N. Kim, and J.-J. Hwang. 2010. Fast Fourier Transform - Algorithms and Applications (1st ed.). Springer Publishing Company, Incorporated.
[16] Dmitrii Tolmachev. 2022. VkFFT - Vulkan/CUDA/HIP/OpenCL Fast Fourier Transform library. Github. Retrieved February 28, 2022 from

https://github.com/DTolm/VkFFT

A AUXILIARY FIGURES

Shown in Fig. 6 are the distributions of the combined kernel dispatch and execution timesâ€”along with their mean,

variance and standard deviationâ€”across all hardware used for benchmark studies. A first warm-up run is discarded

in all cases. These distributions highlight the sporadic and highly fluctuating run-times measured among the various

backends. In all cases we observe at least one outlier that negatively impacts the overall run-time of SYCL-FFT. The

A100, MI-100 and Intel CPU have mostly consistent behaviour across all 1000 tests, modulo several runs where spikes

in run-time occur. Frequency throttling is observed in Fig. 6a for the MI-100 after roughly 700 iterations, and around

500 iterations for the ARM Neoverse CPU. The Intel iGPU demonstrates an interesting sinusoidal behavior, possibly

due to hardware-enacted frequency reduction and resource sharing with the host CPU.

11

IWOCL and SYCLcon â€™22, May 10â€“12, 2022, Virtual

Pascuzzi and Goli

(a) Input sequence length of 1024.

12

(b) Input sequence length of 2048.

Fig. 6. Distributions of 1000 combined kernel launch and execution times of SYCL-FFT across all hardware.

02004006008001000Iteration4748495051525354Time [s] = 48.6556152 = 0.218910 = 0.467878A10002004006008001000Iteration5060708090100Time [s] = 61.3441422 = 11.168602 = 3.341946MI-10002004006008001000Iteration50010001500200025003000Time [s] = 398.9422582 = 74265.635055 = 272.517220Neoverse02004006008001000Iteration6080100120140160Time [s] = 58.7192232 = 29.663507 = 5.446422x86_6402004006008001000Iteration100200300400500600700800Time [s] = 480.3583132 = 466.442965 = 21.597291Iris P58002004006008001000Iteration515253545556575859Time [s] = 51.9352202 = 0.310251 = 0.557002A10002004006008001000Iteration5075100125150175200225250Time [s] = 61.3149742 = 48.899346 = 6.992807MI-10002004006008001000Iteration50010001500200025003000Time [s] = 554.3085132 = 79835.236169 = 282.551298Neoverse02004006008001000Iteration708090100110120130140150160Time [s] = 86.1703432 = 114.575124 = 10.703977x86_6402004006008001000Iteration500600700800900Time [s] = 479.5296732 = 420.860295 = 20.514880Iris P580