2
2
0
2

r
a

M
0
3

]
E
S
.
s
c
[

2
v
7
7
5
5
1
.
3
0
2
2
:
v
i
X
r
a

Understanding Code Snippets in Code Reviews: A Preliminary
Study of the OpenStack Community

Liming Fu
School of Computer Science
Wuhan University
Wuhan, China
limingfu@whu.edu.cn

Peng Liang∗
School of Computer Science
Wuhan University
Wuhan, China
liangp@whu.edu.cn

Beiqi Zhang
School of Computer Science
Wuhan University
Wuhan, China
zhangbeiqi@whu.edu.cn

ABSTRACT
Code review is a mature practice for software quality assurance in
software development with which reviewers check the code that
has been committed by developers, and verify the quality of code.
During the code review discussions, reviewers and developers
might use code snippets to provide necessary information (e.g.,
suggestions or explanations). However, little is known about the
intentions and impacts of code snippets in code reviews. To this
end, we conducted a preliminary study to investigate the nature of
code snippets and their purposes in code reviews. We manually
collected and checked 10,790 review comments from the Nova
and Neutron projects of the OpenStack community, and ﬁnally
obtained 626 review comments that contain code snippets for
further analysis. The results show that: (1) code snippets are not
prevalently used in code reviews, and most of the code snippets are
provided by reviewers. (2) We identiﬁed two high-level purposes of
code snippets provided by reviewers (i.e., Suggestion and Citation)
with six detailed purposes, among which, Improving Code Imple-
mentation is the most common purpose. (3) For the code snippets
in code reviews with the aim of suggestion, around 68.1% was
accepted by developers. The results highlight promising research
directions on using code snippets in code reviews.

CCS CONCEPTS
• Software and its engineering → Designing software; •
General and reference → Empirical studies.

KEYWORDS
Code Snippet, Code Review, OpenStack

ACM Reference Format:
Liming Fu, Peng Liang, and Beiqi Zhang. 2022. Understanding Code Snip-
pets in Code Reviews: A Preliminary Study of the OpenStack Community.
In 30th International Conference on Program Comprehension (ICPC ’22),
May 16–17, 2022, Virtual Event, USA. ACM, New York, NY, USA, 5 pages.
https://doi.org/10.1145/3524610.3527884

∗This work was funded by the National Key R&D Program of China with No.
2018YFB1402800 and the NSFC with No. 62172311.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full
citation on the ﬁrst page. Copyrights for components of this work owned by others
than ACM must be honored. Abstracting with credit is permitted. To copy otherwise,
or republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee. Request permissions from permissions@acm.org.
ICPC ’22, May 16–17, 2022, Virtual Event, USA
© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9298-3/22/05. . . $15.00
https://doi.org/10.1145/3524610.3527884

1 INTRODUCTION
Code review is widely known as one of the best practices in
software development with the aim of verifying the source code
quality. In a typical code review process, reviewers and developers
work collaboratively through an asynchronous online discussions
with review comments to ensure that the proposed code changes
are of suﬃciently high quality [10]. During the discussions, re-
viewers and developers may exchange information with each
other towards the issues to be addressed. In this context, code
snippets, as a special form of code artifacts, might be used in review
comments (e.g., reviewers might provide constructive suggestions
with code snippets to help improving the quality of code).

A recent study has been conducted to study the practice of
link sharing and their intentions in code reviews, and to explore
what information could be provided through link sharing [13].
Similar to links, code snippets are also considered as one of the
measures to convey necessary information during the code review
process. However, the natures of links and code snippets lead
to diﬀerent intentions and impacts in code reviews. To the best
of our knowledge, little is known about the code snippets in
code reviews. To bridge this gap, we conducted a preliminary
study to provide a comprehensive overview of code snippets about
its distribution, purposes, and acceptance in code reviews. We
collected and analyzed review comments from two projects, Nova
and Neutron, of the OpenStack community. The contribution of
this work is twofold: (1) a study focusing on exploring code
snippets in code reviews, and (2) a taxonomy of six purposes
of providing code snippets in code reviews. Moreover, we made
the dataset used in this work publicly available for replication
purposes [4].

The remaining of this paper is structured as follows: Section 2
surveys the related work on code reviews and code snippets, and
Section 3 describes the research design of this study. The results of
our study are presented in Section 4, followed by the implications
in Section 5. Section 6 clariﬁes the threats to the validity. Section
7 concludes this work with future directions.

2 RELATED WORK
Many studies have explored the topic of information needs in
code reviews. Pascarella et al. investigated the information that
reviewers need to conduct a proper code review [10]. They iden-
tiﬁed the presence of seven high-level reviewers’ information
needs. Wang et al. investigated link sharing and their intentions
in code reviews [13]. They identiﬁed seven intentions behind link

 
 
 
 
 
 
ICPC ’22, May 16–17, 2022, Virtual Event, USA

L. Fu et al.

sharing in code reviews, in which providing context and elaborat-
ing are the most common intentions. Several other studies have
focused on identifying various information about code snippets.
Subramanian et al. used code snippet analysis to extract their
structural information in order to eﬀectively identify API usage in
the snippets [12]. Chatterjee et al. also mined the natural language
text associated with code snippets in software-related documents,
e.g., API documentation and code reviews [2]. We also identiﬁed
symptoms of architecture erosion in code reviews [9]. Compared
to the existing work that focuses on the information needs in code
reviews and identifying information of code snippets, our work
intends to explore the distribution, purposes, and acceptance of
code snippets in code reviews.

3 RESEARCH DESIGN
3.1 Research Questions
The goal of this work formulated through the Goal Question Metric
approach [1] is to investigate the existence of code snippets in
code reviews for the purpose of exploration with respect to the
distribution, purposes, and acceptance of code snippets from the
point of developers and code reviewers in the context of OSS
development. To achieve this goal, we formulated three Research
Questions (RQs) as follows:
RQ1. How many review comments contain code snippets in
code reviews?
RQ2. What are the purposes of code snippets provided by
reviewers in code reviews?
RQ3. How many review comments that contain code snip-
pets are accepted by developers?

3.2 Data Collection
This study focuses on investigating the code snippets in code
reviews collected from the OpenStack1 community. OpenStack is
a set of software tools for building and managing cloud computing
platforms, and is supported by many large companies. We deemed
OpenStack to be appropriate for this study because it has made a
big investment in code reviews for several years [7] and is widely
used in many studies related to code reviews (e.g., [6, 7]). The
OpenStack community is composed of several projects, and we
selected two of the most active projects as our investigated projects
(based on the number of closed code changes), i.e., Nova2 and
Neutron3.

The code review process of OpenStack is supported by Gerrit4,
a web-based code review platform built on the top of Git. By using
the RESTful API provided by Gerrit, we were able to collect all the
closed code changes of the two selected projects that were updated
in 2020. We then extracted all available review comments of these
code changes and stored the data in a local ﬁle for further analysis.
In total, we collected a dataset that contains 3,447 code changes
and 20,978 review comments.

3.3 Data Labelling, Extraction and Analysis
Based on the recent data, OpenStack projects contain around 13
million lines of code, and most of them are written in Python5. Con-
sidering this, we decided to only focus on the review comments
that contain Python code snippets. Speciﬁcally, the inclusion
criterion is that the review comments must include a portion
of source code (or pseudocode), which contains at least one valid
statement.

To locate the expected code review comments and answer the
RQs in Section 3.1, we followed the following steps to identify
review comments with Python code snippets.

In step one, we ﬁltered out the review comments that are
commented by the bot reviewer (i.e., Zuul in OpenStack). Since
we aimed at exploring the code snippets in review comments from
the perspectives of developers and code reviewers in code reviews,
the review comments commented by bot should be excluded.
Moreover, we only retained the review comments to Python ﬁles
because Python ﬁles are directly related to Python code snippets.
As a result of this step, the number of review comments was
reduced to 14,141.

In step two, for answering RQ1, we read through the review
comments to identify whether they contain code snippets. We
ﬁrst conducted a pilot labelling with 993 review comments, which
were randomly selected among all review comments obtained
in step one based on 3% margin of error and 95% conﬁdence
level [8], by the ﬁrst and third authors independently. Conﬂicts
were discussed and resolved with the second author to make
sure that they had a consistent understanding of the inclusion
criterion of data labelling. We measured the inter-rater reliability
and calculated the Cohen’s Kappa coeﬃcient [3] as a way to
verify the consistency on the labelled comments. The Cohen’s
Kappa coeﬃcient is 0.86, indicating that the two coders reached a
decent agreement. In addition, we also used an automatic detection
tool named Guesslang6 to help us identify code snippets. It can
detect the programming language of a given text by predicting
the possibilities of candidate languages. Since we focused on
Python code snippets, we used Guesslang to calculate the Python
possibility of each review comment so that we could ﬁlter out the
review comments whose possibilities are lower than a threshold.
By comparing the detection results of Guesslang with those of
manual labelling during the pilot process, the threshold was set
to 0.01. This resulted in a reduction in the number of review
comments to 10,790. The ﬁrst and third authors then labelled the
remaining review comments independently.

In step three, for answering RQ2 and RQ3, we extracted the
contextual information of identiﬁed review comments with code
snippets obtained in step two, including the code review discus-
sions and associated source code. To mine the intentions behind
the code snippets provided by reviewers, we analyzed the extracted
information using the Constant Comparison method [5]. We also
checked whether the code snippets were accepted by developers.
Specially, we regarded the code snippets as accepted in the follow-
ing two situations:

1https://www.openstack.org/
2https://github.com/openstack/nova
3https://github.com/openstack/neutron
4https://www.gerritcodereview.com/

5https://www.openhub.net/p/openstack
6https://github.com/yoeo/guesslang

Understanding Code Snippets in Code Reviews

ICPC ’22, May 16–17, 2022, Virtual Event, USA

1) Changes were made in the code by developer(s) based on the

code snippets provided by reviewers.

2) Developer(s) clearly showed a positive attitude towards the
code snippets provided by reviewers (e.g., “Thanks for the tip,
I’ll deﬁnitely try that out...7”).

This data extraction and analysis step was conducted by the ﬁrst
author and the results were veriﬁed by two other authors. Conﬂicts
were discussed and addressed by the three authors. The dataset has
been provided online for replication purpose [4].

4 RESULTS
4.1 Results of RQ1
Motivation: As an exploratory study on code snippets in code
reviews, this RQ aims at investigating the distribution and pro-
portion of review comments that contain code snippets. Such
information can help us get a basic view of code snippets in code
reviews.
Results: Table 1 presents an overview of the review comments
and code snippets per project. In general, we obtained a total of
626 review comments that contain code snippets. Compared with
the number of all the review comments we analyzed (i.e., 10,790),
we can ﬁnd that code snippets are not prevalently used in code
reviews, only account for 5.8% on average. Concretely, there are
436 review comments containing code snippets that are identiﬁed
in Nova (out of 7,669, 5.7%). The proportion of review comments
that contain code snippets in Neutron is a little higher than Nova
(190 out of 3,121, 6.1%).

We further investigated how much of review comments having
code snippets are provided by code reviewers and developers.
From Table 1, we can learn that most of the review comments
that contain code snippets are provided by reviewers (547 out of
626, 87.4%). In Neutron, more than 90% (173 out of 190, 91.1%)
of the code reviews that contain code snippets are provided by
reviewers. It is not surprising that most of the code snippets in
code reviews are provided by reviewers since reviewers play an
important role in the code review process. For example, reviewers
usually provide useful suggestions to help developers resolve the
issues or improve the design of code, and such suggestions might
contain code snippets (Example: “Hello, what you think in create
a Class to deal with the complexity of calculating the VMs uptime?
If you agree, I have a suggestion bellow, something like this: [code
snippets]”8).

Table 1: Overview of Review Comments (RC) and Code
Snippets (CS) per Project

Project RC
7669
Nova
3121
Neutron
10790
Total

RC with CS (%) Reviewer Developer
374
436 (5.7%)
173
190 (6.1%)
547
626 (5.8%)

62
17
79

7http://alturl.com/hroeq
8http://alturl.com/uonk3

4.2 Results of RQ2
Motivation: As shown in the result of RQ1, most (87.4%) of the
code snippets in code reviews are provided by reviewers. However,
little is known about the intentions behind the code snippets
provided by reviewers. Therefore, this RQ aims at investigating the
purposes of provided code snippets. Such information could help
us better understand the role of code snippets in code reviews.
Results: Two high-level categories of purposes of providing code
snippets in code reviews are identiﬁed (i.e., Suggestion and Cita-
tion). Moreover, we further identiﬁed six detailed purposes for the
aforementioned two categories. To help readers better understand
the categories, we provide a review comment example for each
purpose. Due to the space limitation, the complete examples can
be found in our replication package [4].

1. Suggestion refers to the situation where reviewers provide
code snippets to recommend developers about what they could do
or what they should do to improve the quality of code. It contains
four detailed purposes, which are presented below:

1) Improving Code Implementation: The code snippets are
provided to point out alternative solutions or advice to improve
the current code in the patchsets (e.g., design or detailed imple-
mentation). (Example: “I think we could avoid iterating over the
keys/creating a new dict/recursion by doing something like: [code
snippets]”)

2) Following Code Style: The code snippets are provided to
make the style of the current code consistent with the best code
conventions. To improve the readability of the code, reviewers
may suggest developers to address various issues, such as
indention, spacing, line breaking, bracing, and so on. (Example:
“style nit: This would (IMO) read way nicer as: [code snippets]”)
3) Correcting Code: The code snippets are provided to show
what kind of mistakes developers have made in current code
and to correct the error code. (Example: “I think this still isn’t
correct, unfortunately. You shouldn’t translate the variables. This
should read e.g.: [code snippets]”)

4) Complementing Code Implementation: The code snippets
are provided to remind developers that the current code imple-
mentations are incomplete and they should complement the
code with the provided code snippets. (Example: “You need
(must) implement the OVO compatibility method, to avoid ver-
sioning problems: [code snippets]”)

2. Citation refers to the situation where reviewers cite internal
code (e.g., the current code of ﬁles in the patchsets) or external
code snippets (e.g., the code of other ﬁles in the project) in order
to supplement necessary information in the review comments. It
contains two detailed purposes as presented below:

1) Elaborating: The code snippets are cited to help reviewers
supplement their explanations or illustrations. (Example: “Un-
related observation but this is actually pretty bad pattern when
you think about it. If people don’t know we do this and to [code
snippets], then they will assign the result to the module replacing
it globally.”)

2) Providing Context: The code snippets are cited to provide
additional information related to what reviewers had said in the
review comments. (Example: “and actually these two lines is the

ICPC ’22, May 16–17, 2022, Virtual Event, USA

L. Fu et al.

diﬀerence, compared to the patch on master, where we have: [code
snippets]”)
We also further investigated what are the most common pur-
poses of the code snippets provided by reviewers in code reviews.
Table 2 presents the distribution of each detailed purpose of using
code snippets in code reviews. As for the two high-level categories
of purposes, we observed that Suggestion is the most common
purpose that accounts for 86.5% (307 + 74 + 52 + 40 = 473 out of
547), which is far more greater than the result of Citation (13.5%).
This ﬁnding indicates that code snippets are commonly used by
reviewers to convey suggestions to developers. With regards to
the detailed purposes, we found that the most common purpose
of providing code snippets in code reviews is Improving Code
Implementation (307 out of 547, 56.1%) whereas Providing
Context is the least common purpose (20 out of 547, 3.7%).

4.3 Results of RQ3
Motivation: As shown in the result of RQ2, the most common
purpose of providing code snippets is Suggestion. However, de-
velopers could decide whether to accept the suggestions or just
ignore them. Therefore, this RQ aims to investigate how much code
snippets are accepted by developers. Such information can help to
understand the usefulness of the code snippets in code reviews.
Results: Table 2 also presents the accept situation for each Sug-
gestion purpose, while “-” is used for the two Citation purposes
since the accept situation is not applicable for Citation purposes.
In general, we notice that in the 473 review comments that contain
code snippets with the aim of Suggestion by reviewers, a total of
322 (201 + 56 + 38 + 27 = 322) review comments were accepted
by developers, which accounts for 68.1%. This ﬁnding suggests
that code snippets can serve as an eﬀective way when providing
suggestions in code reviews.

We further investigated the acceptance of four detailed Sugges-
tion purposes. From Table 2, we can learn that the acceptance rates
for the four suggestion purposes are similar. Following Code
Style is the purpose with the highest rate of being accepted by
developers, which corresponds to 75.7%. The acceptance rate of
Improving Code Implementation is the lowest in our cases,
which corresponds to 65.5%. The diﬀerence between the highest
and lowest rates is only about 10%.

Table 2: Distribution and Accept Situation of Code Snippets
in Code Reviews for Each Detailed Purpose

Purpose
Improving Code Implementation
Following Code Style
Elaborating
Correcting Code
Complementing Code Implementation
Providing Context

Num Acc Rate
65.5%
201
307
75.7%
56
74
-
-
54
73.1%
38
52
67.5%
27
40
-
-
20

5 IMPLICATIONS
We conducted a preliminary study to provide a basic view of
code snippets on its distribution, purposes, and acceptance in code

reviews. Based on our results, we believe that our work could
beneﬁt both practitioners and researchers. For practitioners,
our work could present constructive suggestions. For example,
as indicated by the result of RQ2, Following Code Style is the
second most common purpose behind the code snippets provided
by reviewers. It implies that developers may lack familiarity with
the code conventions in their organization. Necessary education
should be conducted to make developers familiar with the code
styles adopted in the system. Moreover, tools that can automati-
cally check for compliance with code conventions would be also
useful. For researchers, our work highlights promising research
directions. For instance, the result of RQ2 provides a taxonomy
of six purposes of code snippets used by reviewers. In another
aspect, the purposes of code snippets used by developers also
needs further exploration. Moreover, as shown in the result of
RQ3, 68.1% of review comments that contain code snippets were
accepted by developers, and the reasons why developers did not
accept the comments that contain code snippets are worth further
investigation.

6 THREATS TO VALIDITY
We discuss several threats to the validity of this work according
to the guidelines proposed by Runeson et al. [11], and how these
threats were partially mitigated in our study. Internal validity
is not considered, since we do not address causal relationships
between variables and results.

Construct Validity: In this work, we depended on human
activities, which would induce personal bias. To reduce this threat,
the review comments were labelled by two researchers. Any dis-
agreements were discussed and addressed with a third researcher.
Moreover, we also conducted a pilot labelling to make sure that the
two researchers achieved a consensus on what are code snippets.
The data extraction and analysis process was conducted by one
researcher, and the results were reviewed and checked by other
two researchers. These measures can partially alleviate this threat.

External Validity: Our work considered two most active projects

(Nova and Neutron) from the OpenStack community because
OpenStack has made a signiﬁcant investment in code reviews and
is widely used in many studies related to code reviews, but we
admitted that more projects from diverse communities are needed
to increase the generalizability of the study results.

Reliability: All the steps in our study, including the data
mining process, manual data labelling, and manual data extraction
and analysis, were conducted and discussed by the three authors.
Furthermore, the dataset and analysis results of our study have
been made publicly available online in order to facilitate other
researchers to replicate our study easily [4]. We believe that these
measures can partially alleviate this threat.

7 CONCLUSIONS
This paper reports on a preliminary study that investigated code
snippets in code reviews. We chose a widely known community
OpenStack, which provides rich code review data. We then col-
lected and labelled 10,790 review comments from two most active
projects (i.e., Nova and Neutron) of OpenStack.

Understanding Code Snippets in Code Reviews

ICPC ’22, May 16–17, 2022, Virtual Event, USA

According to our results, we notice that code snippets are not
prevalently used in code reviews and most of code snippets are
provided by reviewers. We also got a taxonomy of the purposes
of using code snippets in code reviews with two categories (i.e.,
Suggestion and Citation) and six subcategories, among which,
Improving Code Implementation is the most common purpose.
Moreover, among the code snippets with the aim of suggestion,
around 68.1% was accepted by developers.

Our study highlights the role and usefulness of code snippets in
code reviews. Given its importance, we plan to extend this work
with a large dataset from diverse communities and projects to
further investigate code snippets in code reviews (see Section 5).

REFERENCES
[1] Victor R. Basili, Gianluigi Caldiera, and H. Dieter Rombach. 1994. The Goal
Question Metric Approach. Encyclopedia of Software Engineering (1994), 528–
532.

[2] Preetha Chatterjee, Manziba Akanda Nishi, Kostadin Damevski, Vinay Augus-
tine, Lori Pollock, and Nicholas A. Kraft. 2017. What information about code
snippets is available in diﬀerent software-related documents? An exploratory
study. In Proceedings of the 24th IEEE International Conference on Software
Analysis, Evolution and Reengineering (SANER). 382–386.

[3] Jacob Cohen. 1960. A coeﬃcient of agreement for nominal scales. Educational

and Psychological Measurement 20, 1 (1960), 37–46.

[4] Liming Fu, Peng Liang, and Beiqi Zhang. 2022. Replication Package for the
Paper: “Understanding Code Snippets in Code Reviews: A Preliminary Study

of the OpenStack Community”. https://zenodo.org/record/6158206

[5] Barney G Glaser. 1965. The constant comparative method of qualitative analysis.

Social Problems 12, 4 (1965), 436–445.

[6] Xiaofeng Han, Amjed Tahir, Peng Liang, Steve Counsell, and Yajing Luo. 2021.
Understanding code smell detection via code review: A study of the OpenStack
community. In Procceedings of the 29th IEEE/ACM International Conference on
Program Comprehension (ICPC). IEEE, 323–334.

[7] Toshiki Hirao, Shane McIntosh, Akinori Ihara, and Kenichi Matsumoto. 2020.
Code reviews with divergent review scores: An empirical study of the OpenStack
and Qt communities. IEEE Transactions on Software Engineering (2020).

[8] Glenn D. Israel. 1992. Determining Sample Size. Fact Sheet PEOD-6. Florida
Cooperative Extension Service, Institute of Food and Agricultural Sciences,
University of Florida, Florida, U.S.A.

[9] Ruiyin Li, Mohamed Soliman, Peng Liang, and Paris Avgeriou. 2022. Symptoms
of architecture erosion in code reviews: A study of two OpenStack projects. In
Proceedings of the 19th IEEE International Conference on Software Architecture
(ICSA).

[10] Luca Pascarella, Davide Spadini, Fabio Palomba, Magiel Bruntink, and Alberto
Bacchelli. 2018. Information needs in contemporary code review. In Proceedings
of the 21th ACM Conference on Computer Supported Cooperative Work and Social
Computing (CSCW), Vol. 2. ACM, Article No. 135.

[11] Per Runeson and Martin Höst. 2009. Guidelines for Conducting and Reporting
Case Study Research in Software Engineering. Empirical Software Engineering
14, 2 (2009), 131–164.

[12] Siddharth Subramanian and Reid Holmes. 2013. Making sense of online code
snippets. In Proceedings of the 10th Working Conference on Mining Software
Repositories (MSR). 85–88.

[13] Dong Wang, Tao Xiao, Patanamon Thongtanunam, Raula Gaikovina Kula, and
Kenichi Matsumoto. 2021. Understanding shared links and their intentions to
meet information needs in modern code review: A case study of the OpenStack
and Qt projects. Empirical Software Engineering 26, 5 (2021), 1–32.

