Learning Joint Detection, Equalization and
Decoding for Short-Packet Communications

Sebastian D¨orner1, Jannis Clausius1, Sebastian Cammerer2, and Stephan ten Brink1
1 Institute of Telecommunications, University of Stuttgart, Pfaffenwaldring 47, 70659 Stuttgart, Germany

1

doerner,clausius,tenbrink
}
{

2 NVIDIA, Fasanenstraße 81, 10623 Berlin, Germany
scammerer@nvidia.com

@inue.uni-stuttgart.de

2
2
0
2

l
u
J

2
1

]
T
I
.
s
c
[

1
v
9
9
6
5
0
.
7
0
2
2
:
v
i
X
r
a

Abstract—We propose and practically demonstrate a joint
detection and decoding scheme for short-packet wireless com-
munications in scenarios that require to ﬁrst detect the presence
of a message before actually decoding it. For this, we extend
the recently proposed serial Turbo-autoencoder neural network
(NN) architecture and train it to ﬁnd short messages that can
be, all “at once”, detected, synchronized, equalized and decoded
when sent over an unsynchronized channel with memory. The
conceptional advantage of the proposed system stems from a
holistic message structure with superimposed pilots for joint
detection and decoding without the need of relying on a dedicated
preamble. This results not only in higher spectral efﬁciency, but
also translates into the possibility of shorter messages compared
to using a dedicated preamble. We compare the detection error
rate (DER), bit error rate (BER) and block error rate (BLER)
performance of the proposed system with a hand-crafted state-
of-the-art conventional baseline and our simulations show a
signiﬁcant advantage of the proposed autoencoder-based system
over the conventional baseline in every scenario up to messages
conveying k = 96 information bits. Finally, we practically evaluate
and conﬁrm the improved performance of the proposed system
over-the-air (OTA) using a software-deﬁned radio (SDR)-based
measurement testbed.

I. INTRODUCTION

In the last decades, wireless communication systems have
been continuously pushed towards their fundamental physical
limits and roughly 70 years after Shannon has quantiﬁed
the achievable performance bounds in his seminal work [1],
we virtually achieve his capacity limits over many chan-
nels [2]. However, increased connectivity and the expected
omnipresence of smart devices in almost all ﬁelds of our
daily life becomes a challenging – but yet exciting – re-
quirement for future communication systems and upcoming
wireless communication standards [3], [4]. From a wireless
engineering perspective, these Internet of Things (IoT) and
massive machine-type communications (mMTC) networks are
mostly characterized by their large number of devices. It is also
expected that many of those low-rate devices do not require
the transmission of large amounts of data, but short messages
with sporadic channel accesses [3].

Yet, when considering the actual end-to-end performance
of today’s systems for short packet transmissions, we are far
away from Shannon’s achievable rates as the evaluation of

This work is supported by the German Federal Ministry of Education and
Research (BMBF) within the project Open6GHub under grant 16KISK019
and the project FunKI under grant 16KIS1187.

(a) Conventional concept

(b) Proposed holistic concept

Fig. 1: Conventional system with a dedicated preamble struc-
ture compared to the proposed holistically learned message.

systems only based on their symbol-wise spectral efﬁciency
over well-deﬁned and synchronized channels does often not
constitute their practical performance. Especially for short
messages where a conventional dedicated preamble constitutes
severe overhead, a carefully designed procedure is required
for detection, channel estimation and to synchronize trans-
mitter and receiver. However, from an information theoreti-
cal perspective it is known that the achievable coding rate
diminishes for short block lengths [5] and the conventional
separation of a transmission into a dedicated pilot preamble
for detection/estimation and a payload sequence carrying the
information, as depicted in Fig. 1, is provably suboptimal [6],
[7]. The theoretical results in [6] for the binary-input additive
white Gaussian noise (AWGN) channel further indicate, that
“in the short-packet regime,
joint detection and decoding
yields signiﬁcant gains in terms of maximum coding rate over
preamble-based detection followed by decoding” [6, p. 5].

In this work, we propose to jointly learn the transmitter and
receiver end-to-end for the aforementioned tasks of detection,
synchronization, equalization and decoding (see Fig. 1) by
following the concept of autoencoder-based communications
[8]. The main contributions of this paper are:

We demonstrate a fully differentiable end-to-end learning

•

tdetectionsynchronizationequalizationdecodingpayloadpreambletdetection+synchronization+equalization+decoding 
 
 
 
 
 
2

synchronization neural network (NN) was trained consecu-
tively after the messages were learned, thus, no strict joint
optimization. For most of the follow-up work [11], [12], [13],
[14], [15], the focus so far has mostly been on the advantages
of joint signal processing and the possibilities of data-driven
system optimization [16], [15], [17], i.e., the system can be
trained with real-world data including all actual hardware and
channel impairments. Also, with the emergence of the Turbo-
autoencoder architecture [12], which allows an increased
amount of information bits carried within a message, the focus
was mostly on learning a coded modulation scheme for the
AWGN channel that can compete with state-of-the-art short
length channel codes or even outperform state-of-the-art for
channels with feedback [18]. This concept has been extended
to serially concatenated Turbo-autoencoders in [9] for AWGN
channels. Using the autoencoder scheme for channels with
inter-symbol-interference was investigated in [19], however for
a static channel model without detection or synchronization.
It is worth mentioning that the concept of hyper-dimensional
modulation [20] describes a similar, but non-differentiable,
idea of learning holistic messages, which could be potentially
also extended by an outer synchronization component. Also
the authors of [21] identiﬁed a similar mMTC scenario and
addressed the task of joint detection, channel estimation and
decoding of conventional messages with a Turbo-receiver
scheme using a bilinear generalized approximate message
passing (BiG-AMP) algorithm. In this work, we want to shed
light on the question of how to materialize the full end-to-
end learning potential of the autoencoder concept by not just
focusing on joint signal-processing capabilities and raw coding
performance, but also on the advantages of learning a holistic
message structure that is inherently introduced by the Turbo-
autoencoder architecture as visualized in Fig. 1.

III. SYSTEM MODEL

We assume a single-input single-output (SISO) system
model with single-carrier modulation as depicted in Fig. 2. The
objective is to transmit k bits within a short-packet message
of n complex-valued channel uses (symbols) including all
required overhead for synchronization. In this scenario, the
(0, n) to the
channel model adds a random offset τoff ∈
message starting point to model initial random access without
any prior signaling. In conventional systems this is commonly
done using a message that consists of a dedicated preamble
sequence followed by the individual payload. Typically, the
payload modulation consists of symbols chosen from a set
of alphabets, e.g., quadrature phase shift keying (QPSK), 16-
quadrature amplitude modulation (QAM) or 256-QAM which,
however, may be a user speciﬁc choice, e.g., depending on
the individual SNR. The problem can be further complicated
by additional carrier frequency offset (CFO) and sampling
frequency offset (SFO) as transmitter and receiver oscillators
do not share the exact same frequency. Typically, a preamble
sequence is used for detection and to establish timing syn-
chronization and only if this is ensured, the processing of the
remaining data is possible. One example of such preamble
sequences are Zadoff-Chu sequences, which are also used in

Fig. 2: System overview showing all considered tasks in the
scope of this work including channel coding, modulation,
detection, synchronization, equalization and decoding.

scheme to establish the whole communications link on the
physical (PHY) layer using ultra short holistic messages.
The proposed system is based on an enhanced serial
Turbo-autoencoder [9] and the task goes even beyond
joint detection and decoding [6] as our system model,
depicted in Fig. 2, also includes synchronization and
equalization over multipath channels.
As we implicitly consider detection, synchronization,
equalization and decoding in the applied end-to-end per-
formance metric, the transmitter is trained to ﬁnd an
optimal trade-off between detectability and the amount of
added redundancy for decoding of the information pay-
load. For further insights and an intuitive interpretation
of the learned solution, we investigate and evaluate the
messages learned on the transmitter side.
We benchmark the performance of the proposed system
against a conventional state-of-the-art baseline and show
signiﬁcant gains for all simulated scenarios up to mes-
sages conveying k = 96 information bits.
Finally, we demonstrate the practicability of the pro-
posed concept over-the-air within a software-deﬁned ra-
dio (SDR)-based measurement testbed and discuss the
implications of actual deployment.

•

•

•

The rest of this paper is organized as follows. Section II
provides a short overview of related literature. Section III
introduces the system model,
the channel model and the
corresponding conventional baseline system. The proposed
holistic end-to-end framework is introduced in Section IV. In
Section V we present the results of our simulations and over-
the-air measurements and Section VI concludes the paper.

Notations: Random variables are denoted by capital italic
font, e.g., X, Y , with realizations x, y, respectively. Vectors
are represented using a lower case bold font, e.g., y.
(a, b)
U
(µ, σ2)
denotes a uniform distribution in the range [a, b) and
denotes a normal distribution with mean µ and variance σ2.

N

II. RELATED WORK

Autoencoder-based communication [8] has provided a new
paradigm of how to design future communication systems
– instead of individually optimized signal-processing blocks,
we can now jointly optimize the whole transceiver w.r.t.
a single end-to-end performance metric. The ﬁrst synchro-
nization for end-to-end learning has already been proposed
in [10], however, the performance was limited due to the
very short messages of only a few channel uses and the

CNN-basedTransmitterCNN-basedReceiveruChannelencoderMapperPilotadderChannelDetectorSynchronizerCSIestimatorEqualizerChanneldecoderˆuxy3

Fig. 4: Receiver model of a state-of-the-art conventional base-
line system including preamble correlation, energy detection
and channel estimation followed by iterative equalization,
demapping and decoding between an BCJR equalizer and an
BP decoder.

−

−

nM)

to the transmitted message x. The resulting output x(2n
is a sequence of 2n
nM symbols consisting of the message
x with random delay according to τoff and zero padding. This
sequence is then convolved with a randomly drawn channel
impulse response h, resulting in y(2n
1 due
−
to a full convolution. To simulate a random sampling time
offset (STO) at the receiver, as the result of un-synchronized
oscillators between transmitter and receiver, y(2n
is then
convolved with a randomly phase-shifted raised-cosine-ﬁlter
vector g(16)

STO sampled from g(t + τSTO) with

of length 2n

−

1)

1)

−

h

h

g(t) =






(cid:17)

1
π
4 sinc
cos(βt/T )
πt/T

(cid:16) π
2β

sinc (cid:0) πt

T

t=0

= T
2β

t
|
otherwise.

|

(cid:1)

(1)

∼ N

1 + 1 and the signal y(2n)

Note that we assume, that the STO adds a single signiﬁcant
tap to the impulse response which results in a total memory
of the channel of nM = ntaps −
of
g
(0, σ2)
length 2n. Finally, we add white Gaussian noise n
to y(2n)
resulting in y(2n) as our channel model’s output
g
sequence. We decided not to model CFO and SFO as the
inﬂuence of SFO is negligible for ultra short sequences and
the compensation of notable CFO would pose a signiﬁcant
challenge for the conventional baseline system since it would
probably require additional pilot symbols at the end of a
message. Also, considering the “not clock-synced” SDR-based
testbed, which was used to evaluate actual deployment, the
inﬂuence of frequency offsets was existent but negligible
throughout our measurements.

Fig. 3: Channel model used for training and performance
evaluation.

the 3GPP 5G standard [22]. The preamble sequence can then
also be used for channel estimation to enable equalization
and decoding of the following payload data. Additional pilots
may be embedded in the message structure to further improve
this process. However,
in particular for systems that only
aim to transmit a short-packet message (i.e., few information
bits, e.g. k < 100),
the signaling overhead to establish
timing synchronization between transmitter and receiver and
for piloting of the channel can be large.

Given this general description, we want to quickly clarify
the terminology throughout this work by deﬁning the meaning1
of the following terms:

•

•

•

•

·

Message: A message x consists of n complex-valued
channel uses (symbols), carrying k information bits in
total. This results in a message’s information rate R = k/n
(not to be confused with the code rate Rc = k/kcoded of
conventional systems using a coded payload).
Detection: The receiver scans received sequences y of
length ndet = 2
n and must be able to detect whether
a full message lies within such a received sequence of
complex-valued symbols or not.
Synchronization: The receiver needs to synchronize if
a message has been correctly detected. This means the
receiver must estimate the exact time offset ˆτoff of the
start/end of the message within the received sequence y.
Decoding: Recovery of the originally transmitted infor-
mation bits. We deﬁne the reliability of the system by the
bit error rate (BER) and block error rate (BLER) perfor-
mance after successful detection and synchronization.

A. Channel Model

For performance simulations and training we employ a
stochastic multi-path propagation channel model derived from
a Proakis type C tap-delay-line model with ﬁve coefﬁ-
cients [23]. The ntaps = 5 channel taps hi are randomly
following a normal-
drawn for each channel realization,
distribution with Proakis weighting coefﬁcients according to
(0, 1) and wProakis =
ti, where ti ∼ N
hi = wProakis,i ·
[0.227, 0.46, 0.688, 0.46, 0.227]. The full channel model
is
depicted in Fig. 3. In a ﬁrst step the random channel access
of a device is modeled by adding a random delay of τoff ∼
nM), where nM is the memory length of the channel,
(0, n
U

−

1Note that some terms are not clearly deﬁned in literature and their exact
meaning often depends on the application. However, these are the deﬁnitions
we use throughout this work.

B. Conventional State-of-the-Art Baseline System

To address the task of transmitting k bits within n complex-
valued channel uses, one can come up with a variety of
different conventional systems. We chose a single carrier short
message system consisting of a Zadoff-Chu-based preamble
sequence [22] followed by an QPSK modulated payload as a
conventional baseline system for performance comparison. For
the speciﬁc parameters of k = 64 bits within n = 64 complex
channel uses we empirically ended up with a preamble of
length nbl,ZF = 20 symbols and a payload of nbl,payload = 44
symbols as best performing system. An exemplary baseline
system message is shown in Fig. 1a. Thus, the QPSK mod-
ulated payload sequence conveys kcoded = 88 coded bits. To
protect the k = 64 information bits that have to be transmitted,
we use a 5G NR compliant low-density parity-check (LDPC)

τoﬀSynchronization(timing)offset∗∗+hMultipathg(t+τSTO)Sampling-timeoffsetn∼N(0,σ2)Noisex(n)x(2n−nM)y(2n−1)hy(2n)gy(2n)Det.&Sync.CSIest.BCJREQ5GLDPCBPDECπ−1πy(2n)y(n+nM)y(n+nM)ˆhLπˆcLˆcˆuL0ˆc,extL0πˆc,ext4

Fig. 6: CNN for message detection, followed by serial CNN-
based Turbo-decoder structure for data retrieval.

Fig. 7: Illustration of detection and synchronization with input
y(2n) and outputs y(cid:48)

(n(cid:48)) and p(n
−
τ

nM+1)

.

for PHY-level communication. For the sake of convenience
we will refer to this system as PHY-AE in the following.
Fig. 5 shows the transmitter part of the PHY-AE which
comprises piloting for detection and equalization as well as
powerful forward error correction (FEC) encoding of payload
information and modulation. In Fig. 6 the two staged receiver
part that comprises signal detection, synchronization, chan-
nel equalization and iterative decoding is shown. Further, a
detailed documentation of the employed convolutional neural
network (CNN) architectures and hyperparameters is given in
Appendix A.

A. Transmitter Part

The transmitter part, depicted in Fig. 5, consists of the
serial Turbo-autoencoder’s encoder part and closely follows
the architecture in [9] that showed, for the AWGN channel,
to be able to construct state-of-the-art short block codes.
Compared to this structure, the key adjustment to the encoder
is a change of the ﬁnal output activation to obtain a sequence
of complex-valued channel uses x(n) as the encoder’s output.
The main part stays the same, as the ﬁrst encoder (outer
encoder, Enc O) encodes the payload bits u(k) into a coded
sequence cR, where the subscript indicates that every entry is
real-valued. Then cR is binarized (using a saturated straight-
through estimator (STE) [30], [31]) to c
and
c is subsequently interleaved by a pseudo-random interleaver
to cπ. Finally, the inner encoder maps the coded sequence
cπ to the complex-valued symbol sequence x(n) which can
then be transmitted over the channel. Besides the power
normalization, we constrain the message to zero mean. We
want to empathize that the autoencoder learns the holistic
message structure solely based on the end-to-end applied loss
without any guidance or injection of expert knowledge.

1, +1
}

∈ {−

Fig. 5: The serially concatenated CNN-based encoder structure
that embodies the transmitter.

code2 [24] of rate Rc = 64/88 = 8/11. The code is based on
the second base graph with a lifting factor of 11, where the
ﬁrst 22 bits and the last 9 bits are punctured and the bits 65
and 66 are shortened.

The receiver of the conventional baseline system is shown
in Fig. 4 and consists of two separated steps, namely detection
and decoding. In a ﬁrst step the detector tries to ﬁnd a
valid message within the received symbol vector y(2n) using
a combination of preamble sequence correlation and energy
detection. If a certain threshold3 is reached, a message has
been detected and the decoder forwards the estimated channel
impulse response (which is the result of the preamble sequence
auto-correlation) and the snippet y(n+nM) of the detected
message to the BCJR equalizer. This concludes the ﬁrst step
of message detection/synchronization and starts the second
step of iterative equalization, demapping and decoding (IEDD)
[26]. Therefore, a max-log BCJR equalizer approximates
the maximum a posteriori (MAP) [27], [28], [29] sequence
estimate of the kcoded = 88 coded bits and forwards their
log-likelihood ratios (LLRs) Lˆx to a damped min-sum belief
propagation (BP) decoder with a damping factor of λ = 0.7.
The BP decoder then decodes the codeword for (cid:96)BP iterations
and feeds the gained extrinsic information Lˆx,ext back to
the BCJR equalizer. While the BCJR equalizer could not
make use of any a priori information in the ﬁrst iteration
(as there has not been any feedback from the decoder yet,
Lˆx,ext = 0), it can now estimate the most likely bit sequence
in form of Lˆx again using the extrinsic information Lˆx,ext
provided by the decoder. The decoder feedback is considered
in the equalizer by a weighted addition to the branch metrics.
However, the optimal weighting factor is a function of the
signal-to-noise-ratio (SNR) which is assumed to be unknown.
Therefore, we empirically optimize the weight and set it to 0.2.
Note, we found that an SNR estimation based on these short
messages does not yield a gain in performance. This process
can be repeated for several (cid:96)IEDD iterations resulting in a very
competitive best-in-class conventional receiver system that can
be considered state-of-the-art when it comes to bit-information
retrieval at receiver side. Finally, after (cid:96)IEDD iterations, the
decoder outputs the decoded bit sequence ˆx.

IV. SERIAL TURBO-AUTOENCODER-BASED SYSTEM
In this section, we introduce the proposed serial Turbo-
autoencoder-based holistic short message system architecture

2Altough, Polar codes may yield a slightly better error-rate performance in
the short length regime, the possibility of soft-output decoding and thereby
a simpler integration in an iterative equalization, demapping and decoding
(IEDD) loop makes LDPC codes a natural choice for the baseline.

3This threshold has been empirically optimized for a speciﬁcally targeted
false alarm rate of 0.1% according to the 5GNR PRACH speciﬁcations [25]

TransmitterEncOCNNBina-rizerπEncICNNNormu∈Fk2ck×FcRccπx∈CnReceivery(2n)Det&SyncCNNDecICNNDecOCNNπ−1πy0(n0)lEc,πlEclTu∈Rkl0Ec∈Rk×Fl0Ec,πsoftmaxp(n−nM+1)τy(2n)y0(n0)2nsymbolsn0symbolsDet&SyncCNNsoftmaxp(n−nM+1)τ={0.01,...,0.02,0.68,0.03,...,0.05}TABLE I: Hyperparameters for the training algorithm.

Parameter
Loss
TTX
TRX
Batchsize
Optimizer

Value
BCE + CCE
100
500
500
−
ADAM

4000

Parameter
Learning rate
Encoder SNR
Decoder SNR
Detector SNR
Loss-weight α

Value
4
10−
−
15.0dB
10.0
5.0
0.01

−

−

6
10−

15.0dB

10.0dB

B. Receiver Part

The receiver structure is depicted in Fig. 6 and is also
closely related to the receiver part of the serial Turbo-
autoencoder [9]. However, the proposed structure includes the
extension of a preceding CNN to the Turbo-autoencoder’s
decoder to cope with the challenges of the random access
scenario. This preceding CNN for detection and synchro-
nization estimates the starting position of a message from a
received sequence y(2n), where the superscript indicates the
length of the sequence. Note that the detection can also predict
that no message is contained in the received sequence. If no
message was detected, the subsequent CNNs for equalization
and decoding can be omitted. Otherwise, a snippet y(n(cid:48)) with
n(cid:48) = n + 2nM starting from nM positions before the predicted
starting position is forwarded. This process is schematically
depicted in Fig. 7. The following CNNs are connected in
an iterative fashion and separated by a deinterleaver and an
interleaver. The intuition is that the inner decoder learns a form
of equalization/symbol detection with inherent channel state
information (CSI) estimation. Since the a priori information
from the outer decoder is subtracted from the output of the
inner decoder, lE
c can be interpreted as extrinsic information
about the coded sequence c. Subsequently, the outer decoder
can calculate lT
u which is a prediction of the transmitted
sequence u. Additionally, the outer decoder sends extrinsic
feedback l(cid:48)E
to the inner decoder about the code word se-
c
quence c.

Furthermore, a non-trivial extension to the serial Turbo-
autoencoder structure is necessary in terms of the dimensions
of the inputs and outputs. In general, the dimensions of the
exchanged information between inner and outer decoder can
be chosen arbitrarily. However, as we use one-dimensional
CNNs, a suitable number of dimensions is 2. We interpret
the ﬁrst dimension as a positional dimension and the second
dimensions as depth with F entries per position. A practical
simpliﬁcation is to set the length of the positional dimension to
k. As a result, we can choose F freely and concatenate inputs
to a CNN via the depth. However, the a priori information and
the synchronized channel observations do no share the length,
but are of length k = n and n(cid:48) respectively. One way, that
works well, is to align the lengths of the positional dimension
via zero padding. Note, that we set the number of bits k and
the number of channel uses n to the same value (k = n).

C. Training

We train the PHY-AE by optimizing the binary cross-
entropy (BCE) loss LBCE,AE between the originally transmitted
input bit sequence u and the estimated bit sequence lT
u at
the receiver’s output. In parallel, the detection CNN preced-
ing the Turbo-decoder outputs a softmax activated prediction

5

−

nM+1)

p(n
on the starting point of a detected message within
τ
the received sequence y(2n), as schematically shown in Fig. 7.
On the basis of this prediction p(n
and the actual
τ
offset τ used by the channel model, we calculate a secondary
categorical cross-entropy (CCE) loss LCCE,det. which is added
to the BCE loss. The detection loss LCCE,det. can further be
weighted by a hyperparameter α to balance decodability and
detectability. Thus, the total loss is given by

nM+1)

−

Ltot. = LBCE,AE + α

LCCE,det..

·

(2)

As a result, all components including encoder and decoder
with preceding detection CNN contribute to the same loss Ltot
and are thereby trained in an end-to-end manner via stochastic
gradient descent (SGD). This ensures the learning of holistic
messages which are both optimized for detectability and
decoding performance. The training process itself is similar
to [12], [9] and the main hyperparameters are given in Tab. I.
However, some adjustments have to be made to account for
the random access scenario and the tapped-delay line channel
model with memory. First, the detector needs to be included
in the alternating training process of updating the encoder
without the decoder and vice versa. To insure that the goals
of the detector and the decoder are non-contradictory, the
encoder weights are set to non-trainable during detector and
decoder updates. Yet, while keeping the alternating training
schedule w.r.t. to the encoder/decoder training, the encoder
(and thereby the learned messages) is jointly optimized for
detection and decoding as the loss is calculated depending on
both detector and decoder CNNs. Note, that the trade-off pa-
rameter α also balances the contradicting goals of decodability
and detectability in the encoder. Another notable difference
to the AWGN case is, that the autoencoder over-ﬁts to the
interleaver that is used during training. As a consequence, the
interleaver cannot be exchanged after training and must be
chosen accordingly beforehand. This behavior might be due
to the memory induced disturbances in the channel and the
resulting position-aware sequence estimation and tracking of
the decoder.

Further, we want to emphasize that the BCE loss optimizes
the BER and not, as often desired, the BLER. As a result,
we observed a signiﬁcant number of block errors with only
a single erroneous bit. Thus, we propose a to add a single
parity bit and ﬂip the least reliable estimate in case the
parity bit is not matching. To account for the parity bit we
chose to transmit one more bit, i.e., the autoencoder transmits
kPHYAE,actual = k + 1 bits over n = k channel uses. Please
note, that this does not affect the ﬁnal information rate R.
Further implementational details and the training procedure of
a single epoch Alg. 1 are given in Appendix A.

D. Discussion of Learned Messages and Power Limitation

Before we take a look at the BER and BLER performance
results, we ﬁrst analyze the learned messages and discuss the
impact of symbol power limitation with respect to the peak-
to-average power ratio (PAPR). Note, that it is not informative
or even possible to inspect each learned message individ-
ually due to the sheer amount of 2k differently modulated

6

Fig. 8: Heatmap histogram of the learned modulation (i.e., the
constellation symbols of several thousand random messages,
k = 64, n = 64) when the transmitter is only constrained by
an average message power normalization. The green circles
indicate where the PHY-AE has, implicitly, learned to place
pilot symbols.

Fig. 9: Power and variance distribution per symbol position
i of learned message sequences (k = 64, n = 64) when the
transmitter is only constrained by an average message power
normalization (no PAPR reduction applied here).

−

messages. Further, it is instructive to realize that the learned
transmitter performs a non-linear encoding. Thus, to get a
better insight
into the learned message sequences, Fig. 8
provides a scatter plot (heatmap histogram) of several thousand
randomly generated messages, exemplary with parameters
k = 64 and n = 64. As can be seen, the transmitter learns
a “croissant”-shaped Gaussian distribution with one distinct
position outside of the center at around 2.3
2.3j, which
is presumably used for piloting. The fact that the learned
distribution is not perfectly Gaussian or perfectly symmetrical
indicates that a trade-off between detection/synchronization,
channel estimation/equalization and information transfer was
learned. Within the learned distribution, we observe four more
frequent positions (highlighted with green circles) which form
an almost straight line together with the piloting position at
2.3
2.3j. We assume that symbols at these positions mainly
serve the purpose of detection, synchronization and channel
estimation and can thereby be seen as superimposed pilot
positions, while the remaining positions within the “croissant”-
shape are most likely information carrying. Interestingly, the
observed shape of the distribution together with one distinct
pilot position was reproducible in our experiments. Starting
with a random initialization, we trained the system multiple
times from scratch and each time the learned messages exhib-
ited a similarly shaped symbol distribution.

−

Also if we take a look at the average power E

and variance Var (xi) allocated to each symbol position i,
as shown in Fig. 9, we can clearly identify 5 distinct pilot
symbols at the end of the learned messages. These ﬁnal 5
symbols do not carry signiﬁcant information as their average
variance is close to zero, meaning they consist of constant
values just like traditional explicit pilot symbols. Their average

2(cid:105)

(cid:104)

xi|
|

−

−

1 always corresponded to position 2.3

power also clearly differs from information carrying symbols.
Within the subset of investigated messages, the last symbol
2.3j, which is
xn
visible in Fig. 8, and also the remaining 4 designated pilot
symbols correspond to the more frequently used positions
identiﬁed in Fig. 8 (green circles). This result of the PHY-
AE apparently learning to use a dedicated pilot sequence is of
particular interest as it contradicts the information theoretical
argument, that a dedicated preamble and payload are sub-
optimal for detection and decoding [6], [7]. However, the
task of the chosen scenario goes beyond slotted detection and
decoding and also includes synchronization and channel esti-
mation, which likely beneﬁts from dedicated piloting symbols.
It is also not possible to determine if the PHY-AE solely relies
on these dedicated pilots or if a superimposed piloting scheme
is also present in the remaining symbols of a message. Which
can be assumed to some extent, due to the unsymmetrical non-
Gaussian distribution of the remaining symbols.

−

Furthermore, we can see in Fig. 9, that the transmitter learns
to allocate a signiﬁcant part of the available power per message
to the last symbol xn
1, presumably to easily measure the
channel’s impulse response. Unfortunately, such high symbol
power peaks lead to a large PAPR, which is disadvantageous
or even prohibitive for some hardware components, e.g.,
more expensive power ampliﬁers are required. Especially with
regard to cost- and power-efﬁcient user equipments (UEs)
either a limited PAPR or even a constant envelope modulation
can be required [32]. For example the learned messages shown
in Fig. 8, which have only been constrained by an average
power normalization (per message), exhibit a higher PAPR
than the conventional baseline system, as can be seen by
the complementary cumulative distribution function (CCDF)

−2−1012−2−1012InphaseQuadrature0246·10−5Normalizeddensity010203040506002468101SymbolIndexPower/VarianceAveragePowerEh|xi|2iAveragenormalizedvarianceVar(xi)E[|xi|2]Power|xi|2ofanexamplemessage7

Fig. 11: The CCDF of the PAPR in dB for the symbol power
constrained and unconstrained PHY-AE.

Fig. 12: Simulated detection error rate (DER) (detection er-
rors: misdetections + synchronization errors) vs. SNR for the
channel model with ntaps = 5 random channel taps, k = 64,
n = 64 and ndet = 128.

A. Detection Performance

±

We deﬁne a detection error as the event where the detector
is not able to detect and localize a message within a window of
ndet symbols to an accuracy of
nM symbols (misdetections
+ synchronization errors). A detection error also occurs in the
event of wrongly detecting a message where a “none-message”
ynone, a recording of ndet symbols without any transmitted
message, was simulated (false alarm). As a decision for a
threshold cannot optimize both types of errors jointly, we
set the threshold such that the false alarm rate is lower than
0.1% according to the 5G NR speciﬁcations for the physical
random access channel (PRACH) [25]. This has been ensured
empirically by simulations to ﬁnd the optimal threshold for
the conventional baseline system and by adjusting α and the
amount of none-messages during training of the PHY-AE.

Fig. 10: Heatmap histogram of the learned modulation (k =
64, n = 64) when the transmitter is constrained to a certain
power range for each symbol (here 0.99
1).
The green circles indicate where the PHY-AE has, implicitly,
learned to place pilot symbols (we know these positions due
to low variance Var (xi)).

xi|

≤ |

≤

2

of the PAPR depicted in Fig. 11.4 However, the PAPR can
easily be reduced by limiting the individual symbol power
2 to a desired range during training. In the most extreme
xi|
|
case the power of each symbol can thereby be limited to the
unit circle, resulting in the symbol distribution depicted by
Fig. 10. Consequently, the learned symbol power constrained
PHY-AE messages shown in Fig. 10 entail an PAPR reduction
of more than 5 dB, as shown in Fig. 11, resulting in a
PAPR performance comparable to that of the QPSK-based
conventional baseline. As can be seen in the heatmap of
Fig. 10, the symbols of these messages are also not uniformly
or symmetrically distributed over the unit circle, however, the
assumed pilot positions (green circles), which we determined
by their close to zero variance Var (xi), are not the most
frequently used positions anymore. Yet, due to the reduction of
the available modulation space to the unit circle, the density
increases and positions are therefore used more often. The
consequences of symbol power limitation are, however, a
more restricted modulation space that leads to less shaping
gain, hindered channel estimation/equalization, and hindered
detection, as will be shown in the next section.

V. RESULTS

We ﬁrst evaluate the detection and decoding performance
of the PHY-AE over the simulated channel model and, then,
over-the-air within a real world SDR-based deployment. We
compare the performance with the hand-crafted conventional
baseline system introduced in Sec. III-B.

4As the PAPR is deﬁned for the actual analog signal

leaves the
digital-to-analog converter after pulse shaping, we calculate a signal’s PAPR
assuming sinc pulse shaping (where sinc pulse shaping is a worst case
assumption in terms of PAPR).

that

−1−0.500.51−1−0.500.51InphaseQuadrature02468·10−4Normalizeddensity468101210−410−310−210−1100PAPR[dB]CCDFConventionalBaselinePHY-AEconstr.|xi|2=1PHY-AEunconstr.0246810121410−510−410−310−210−1ES/N0[dB]DERConventionalBaselinePHY-AEconstr.|xi|2=1PHY-AE8

Fig. 13: Simulated BLER (solid) and BER (dashed) vs. SNR
over the channel model with ntaps = 5 random channel taps
(k = 64, n = 64)

Fig. 14: Simulated BLER vs. SNR over the channel model
with a varying number of ntaps = 1..5 (solid) and ntaps = 7
(dashed) random channel taps (k = 64, n = 64), while both
systems are optimized for ntaps = 5.

As a result, Fig. 12 shows the simulated DER for the
conventional baseline system and the PHY-AE systems. As
can be seen, the unconstrained PHY-AE shows the best DER
performance. We assume that the possibility to allocate more
energy into single symbols enables better detection. Yet, also
the maximal symbol power-constrained PHY-AE constr. with
2 = 1 signiﬁcantly outperforms the correlation and en-
xi|
|
ergy detection-based conventional baseline. The overall better
detection performance of the PHY-AE’s CNN-based detector
shows the advantage of a system that is optimized for both
data transmission and detection from end-to-end.

B. Decoding Performance

the receiver side. One can observe that

After successful detection of a received message, the re-
ceivers needs to equalize y(cid:48) and estimate the originally trans-
mitted bit sequence u. Fig. 13 shows the achieved BLER
and BER performance of the conventional Baseline system,
the unconstrained PHY-AE and the maximal symbol power
2 = 1) PHY-AE constr. for parameters k = 64
xi|
constrained (
|
and n = 64. As a reference, we also show the maximal
achievable performance Baseline (full CSI) of the baseline
system where the CSI, i.e., h and τSTO, is perfectly known
the previously
at
6dB better than
discussed DER of all systems (Fig. 12) is
their respective BLER. This means that detection errors have
almost no impact on the overall performance for the simulated
channel. We can also see that the PHY-AE performs up to 1dB
better in terms of BLER and more than 2dB better in terms of
BER compared to the conventional Baseline. One particularly
interesting observation is that the symbol power constrained
PHY-AE constr. is almost on par with the unconstrained PHY-
AE, which shows that symbol power limitation only results in
slightly degraded end-to-end performance. Another interesting
result is that the PHY-AE even outperforms the Baseline (full
CSI) with perfect CSI in terms of BER in the low SNR regime.

≈

These large BER gains indicate that the PHY-AE must have
learned a holistic coding scheme with notable coding gain
considering the short block length of k = 64.

C. Universality and Scope of Application

A common misconception in terms of model-based training
is that NN-based PHY-layer components optimized over a
channel model will only work for the exact same chan-
if the channel model relies on
nel parameters. However,
stochastically drawn parameters,
it covers an ensemble of
many different scenarios. In the case of the chosen channel
taps h
model described in Sec. III-A, where the channel
are randomly drawn, the PHY-AE also encounters simpler
5 channel taps
channel instantiations with effectively ntaps ≤
during training (as some instantiations of hi can be close
to zero). From this perspective, the employed channel model
acts more like a hyperparameter of the PHY-AE itself, as it
deﬁnes an upper design limit for the PHY-AE, which learns
a robust signaling for up to ntaps = 5 channel
taps, but
can also operate under simpler conditions. This is similar to
the process of designing the length of a dedicated preamble
for a conventional system with respect to the desired scope
of application. Fig. 14 therefore depicts the averaged BLER
performance of the PHY-AE and the baseline system over the
channel model with explicitly reduced numbers of simulated
channel taps from ntaps = 1, . . . , 5. As can be seen, the PHY-
AE also outperforms the conventional baseline over simulated
5 channel taps.5 Fig. 14 also depicts the
channels with ntaps ≤
BLER performance of the PHY-AE and the baseline system for
ntaps = 7 channel taps (dashed lines), which is out of the scope
of application for both systems. As expected, both systems

5The differing slope and shifted BLER performance visible in Fig. 14
compared to the results for ntaps = 5 shown in Fig. 13 are due to a higher
SNR variance for simulated channel instantiations with ntaps < 5.

46810121416182010−410−310−210−11000.9dB2.7dBES/N0[dB]BER/BLERBaselineBLERBaselineBERPHY-AEBLERconstr.PHY-AEBERconstr.PHY-AEBLERPHY-AEBERBaselineBLER(fullCSI)BaselineBER(fullCSI)6810121416182010−210−1100ES/N0[dB]BLERPHY-AEntaps=1..5PHY-AEntaps=7Baselinentaps=1..5Baselinentaps=79

However, this is not the main focus of this work as for long
block lengths of n
100 the disadvantages of a dedicated
preamble vanish and conventional systems with state-of-the-
art coding schemes are already operating close to capacity.

(cid:29)

D. Actual Deployment and Measurement Testbed

To demonstrate the applicability of the proposed system, we
deploy the PHY-AE on an SDR-based testbed and evaluate
the over-the-air (OTA) performance on a real world channel.
Therefore, we ﬁx the weights of the transmitter part, which
had been optimized via end-to-end SGD updates through the
stochastic channel model. Although it was shown in [16] and
[17], that it is also possible to further optimize the transmitter
through the actual channel using reinforcement learning (RL)
methods or, respectively, a generative adversarial network
(GAN)-based channel model, we choose to not further adapt
the transmitter signaling. We see multiple motivations behind
this decision. First, re-optimizing the transmitter means a
potential loss of generalization as it could lead to overﬁtting to
a certain dataset or channel condition. To counter (or leverage)
overﬁtting, periodical RL-based re-training steps would be
required to follow changing channel conditions throughout
the whole topological area of operation and different environ-
ments. A similar problem holds for the GAN-based approach,
where a dataset of channel conditions for the entire scope of
application is required to be able to train a generative model
without overﬁtting effects. Secondly, training the transmitter
weights in-the-ﬁeld would require signiﬁcant computational
power at the transmitter devices, which contradicts a sce-
nario of low-power machine-type communications (MTC) de-
vices. And thirdly, both transmitter training approaches would
require some kind of feedback channel
to the transmitter
devices to update their weights, which requires additional
bandwidth and also contradicts an application scenario of
massive amounts of ultra low-budget transmit-only devices.
This is why we deploy the transmitter weights learned with
the stochastic channel model described in Sec. III-A, which
was deliberately designed to generate harsh channel conditions
for the targeted scope of application.

At the receiver side, on the other hand, we also show the
performance of a ﬁnetuned receiver according to [10]. As has
been shown in [10] and [15], the performance loss due to
unavoidable mismatch between the synthetic channel model
used for training and the actual channel can be signiﬁcantly
106
mitigated by ﬁnetuning the receiver. We used 12.5
recorded messages and their corresponding genie labels to
ﬁnetune the receiver via re-training. However, in practice the
required labels for the receiver re-training process can also
transmission of pilot
be easily obtained by the periodical
messages or by leveraging the idea of error-correcting code
(ECC)-based label recovery formulated in [33].

·

Our measurement testbed consists of two universal software
radio peripherals (USRPs) B210 from Ettus Research, trans-
mitting at a carrier-frequency of 2.35GHz and a bandwidth

Fig. 15: Simulated BLER vs. block length n evaluated at an
SNR of 18dB and ﬁxed information rate of R = k/n = 1 for
each block length n.

show a degraded BLER performance for ntaps = 7 while the
PHY-AE still outperforms the baseline system, indicating a
generalization to the task. To be able to operate over channels
with up to ntaps = 7 channel
the PHY-AE would
require re-training and the baseline system would have to be
redesigned w.r.t. preamble length and payload encoding.

taps,

To provide a better understanding of the general superiority
of learned holistic messages and joint CNN-based detection,
synchronization, equalization and decoding in the ﬁeld of
short-packet communications, Fig. 15 shows the BLER eval-
uated at a ﬁxed SNR of 18dB for various block lengths n.
For this evaluation the PHY-AE has been retrained and the
handcrafted baseline has been empirically redesigned for each
n to transmit k = n information bits. Further implementational
details are given in Appendix A. As can be seen, the PHY-AE
outperforms the conventional baseline for all simulated block
lengths up to n = 96. Especially for shorter block lengths
the gain of the PHY-AE compared to the baseline further
increases. On the one hand, this is linked to the practical
problem of how to reasonably design a conventional system
with explicit preamble and payload allocation for ultra short
block lengths, as short as n = 32. On the other hand, this
result can be easily explained by the information theoretical
advantages of holistic messages and joint processing over
provably sub-optimal dedicated preambles [6] for short block
lengths. Another observation is that the performance of both
systems increases with the block length n and the number
of transmitted information bits k, which is also expected as
it can be explained by the increasing achievable coding rate
for increasing k [5]. Yet, we know from [9], that the coding
gain of the Turbo-autoencoder architecture does not scale as
well as for conventional coding schemes with increasing k
for k
100. Therefore, we expect for increasing n, as soon
as detection and estimation can be handled by a sufﬁciently
long preamble sequence and coding gain predominates, that a
conventional system will, at some point, surpass the PHY-AE.

(cid:29)

32404856649610−410−310−210−1k=nBLERBaseline,@18dBPHY-AE,@18dB10

Fig. 18: BLER vs. SNR for over-the-air measurements with
the SDR testbed, k = 64, n = 64.

optimized for the synthetic channel model, perform – out-of-
the-box – better than the correlation and energy detection-
based conventional Baseline. Similar to the simulated results,
we can also see that the unconstrained PHY-AE achieves an
even better performance than the symbol power constrained
PHY-AE constr. variant. If we then ﬁnetune the receiver of
the PHY-AE via re-training to further ﬁt
the NN to all
measurement and hardware impairments of the SDR testbed,
we can see a signiﬁcant performance gain of about 0.5dB for
the PHY-AE w ﬁnetuned RX and about 1dB for the constrained
PHY-AE constr. w ﬁnetuned RX. Based on these results we can
state that the PHY-AE is able to conﬁrm its superior detection
performance over-the-air (despite the channel mismatch) and
the PHY-AE with a retrained receiver can outperform the
conventional system even more due to adaptation to hardware
insufﬁciencies.

xi|
|

When looking at the OTA BLER performance shown in
Fig. 18, we can see similar results. Both the unconstrained
2 = 1 constrained PHY-AE constr. show
PHY-AE and the
a better BLER performance compared to the Baseline system
out-of-the-box. This shows, again, that the chosen synthetic
channel model is accurate enough to enable the PHY-AE to
generalize to real world channels. If we further ﬁnetune the
PHY-AE’s receiver part, we can again observe a signiﬁcant
performance gain of about 2-2.5dB for both variants, while
the constrained PHY-AE seems to proﬁt slightly more from
ﬁnetuning. Note,
that ﬁnetuning in this case also means
deliberate overﬁtting to our static measurement environment,
and for real world application periodic ﬁnetuning steps would
be necessary to follow a changing environment [34].

In conclusion to these measurement results we can state that
the PHY-AE is as reliable as the handcrafted state-of-the art
conventional system for n = k = 64, but already at up to
3.6dB lower SNR.

Fig. 16: Averaged channel
impulse response during OTA
measurements at 2.35GHz and 40.0MHz bandwidth with the
SDR-based testbed.

Fig. 17: DER (misdetections + synchronization errors) vs.
SNR for over-the-air measurements with the SDR testbed,
k = 64, n = 64 and ndet = 128.

of 40.0MHz.6 The USRPs are placed in a static indoor ofﬁce
environment without line of sight and the measured channel
impulse response is depicted in Fig. 16. Transmitter and
receiver USRP are not clock-synced and during measurements
we rely on each USRP’s internal oscillator clock with a
2.0 ppm. Except the USRP’s
declared frequency accuracy of
internal hardware digital to analog converters we do not use
over-sampling at the transmitter as well as at the receiver side,
i.e., x is directly fed to the transmitter USRP and y is recorded
at the same sampling frequency at the receiver USRP.

±

E. Over-the-Air Results

As with the simulated results before, we ﬁrst have a look at
the detection error rate for over-the-air measurements with the
SDR testbed. Fig. 17 shows the OTA DER for the conventional
2 = 1 symbol power constrained PHY-
Baseline system, the
AE constr. and the unconstrained PHY-AE. It also shows the
performance of the PHY-AE with a ﬁnetuned receiver. As a
ﬁrst important observation we can see that both variants PHY-
AE and PHY-AE constr., which have only been trained and

xi|
|

6As our testbed was optimized for carrier frequencies in the WiFi spectrum,
we had to use a high bandwidth to experience notable delay spread. The
goal was to mimic similar conditions that IoT devices ﬁnd at typically used
unlicensed bands

900MHz for bandwidths of

200kHz.

∼

∼

0123400.51ChanneltapMagnitudeOTAchannelimpulseresponse12345610−410−310−210−1100ES/N0[dB]DERBaselinePHY-AEconstr.PHY-AEPHY-AEconstr.wﬁnetunedRXPHY-AEwﬁnetunedRX468101210−410−310−210−11003.6dBES/N0[dB]BLERBaselinePHY-AEconstr.PHY-AEconst.wﬁnetunedRXPHY-AEPHY-AEwﬁnetunedRXVI. OUTLOOK AND CONCLUSION

We have proposed an end-to-end optimized autoencoder-
NN-based solution for joint detection, synchronization, equal-
ization and decoding in short-packet communications. Our
proposed system shows better DER, BER and BLER perfor-
mance than a handcrafted state-of-the-art conventional base-
line system over a simulated multipath channel model for
block lengths of up to k
100 information bits. We further
demonstrated the applicability of the PHY-AE in actual over-
the-air measurements within an SDR-based testbed, where the
superior performance was conﬁrmed and gains were further
increased by additional receiver ﬁnetuning. Due to improved
performance in the domain of short-packet communications
and the conceptual simplicity of learned holistic messages,
we think this approach renders a viable option for future
mMTC systems and, potentially, also for initial channel access
schemes.

∼

Several open questions remain, e.g.: a) It would be advan-
tageous to extend the end-to-end loss function to explicitly
optimize the (often) desired BLER metric instead of the BER
via BCE. b) Adaptive ﬁnetuning of transmitter and receiver for
changing channel conditions could be an interesting investiga-
tion. And c) also an extension of the PHY-AE to waveform-
level signal modulation appears to be straightforward as it
would allow for direct PAPR and adjacent channel leakage
ratio (ACLR) targets during training [35].

REFERENCES

[1] C. E. Shannon, “A mathematical theory of communication,” The Bell

System Technical Journal, vol. 27, no. 3, pp. 379–423, 1948.

[2] S.-Y. Chung, G. D. Forney, T. J. Richardson, and R. Urbanke, “On
the design of low-density parity-check codes within 0.0045 dB of the
Shannon limit,” IEEE Communications letters, vol. 5, no. 2, pp. 58–60,
2001.

[3] F. Boccardi and R. W. Heath and A. Lozano and T. L. Marzetta
and P. Popovski, “Five disruptive technology directions for 5G,” IEEE
Communications Magazine, pp. 74 – 80, Feb. 2014.

[4] Xiaohu You et al., “Towards 6G wireless communication networks:
vision, enabling technologies, and new paradigm shifts,” Science China
Information Sciences, vol. 64, Nov. 2020.

[5] Y. Polyanskiy, H. V. Poor, and S. Verdu, “Channel coding rate in the
ﬁnite blocklength regime,” IEEE Transactions on Information Theory,
vol. 56, no. 5, pp. 2307–2359, 2010.

[6] A. Lancho, J. ¨Ostman, and G. Durisi, “On joint detection and decoding
in short-packet communications,” in 2021 IEEE Global Communications
Conference (GLOBECOM), 2021, pp. 1–6.

[7] A.-S. Bana, K. F. Trillingsgaard, P. Popovski, and E. de Carvalho,
“Short packet structure for ultra-reliable machine-type communication:
Tradeoff between detection and decoding,” in 2018 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP), 2018,
pp. 6608–6612.

[8] T. O’Shea and J. Hoydis, “An introduction to deep learning for the
physical layer,” IEEE Transactions on Cognitive Communications and
Networking, vol. 3, no. 4, pp. 563–575, Dec 2017.

[9] J. Clausius, S. D¨orner, S. Cammerer, and S. ten Brink, “Serial vs. parallel
Turbo-autoencoders and accelerated training for learned channel codes,”
in 2021 11th International Symposium on Topics in Coding (ISTC), 2021,
pp. 1–5.

[10] S. D¨orner, S. Cammerer, J. Hoydis, and S. ten Brink, “Deep learning
based communication over the air,” IEEE J. Sel. Topics in Signal
Process., vol. 12, no. 1, pp. 132–143, Feb 2018.

[11] F. Ait Aoudia and J. Hoydis, “Trimming the fat from OFDM: Pilot- and
CP-less communication with end-to-end learning,” in 2021 IEEE Inter-
national Conference on Communications Workshops (ICC Workshops),
2021, pp. 1–6.

11

[12] Y. Jiang, H. Kim, H. Asnani, S. Kannan, S. Oh, and P. Viswanath,
“Turbo autoencoder: Deep learning based channel codes for point-to-
point communication channels,” in Advances in Neural Information
Processing Systems, vol. 32. Curran Associates, Inc., 2019.

[13] B. Karanov, M. Chagnon, F. Thouin, T. A. Eriksson, H. B¨ulow, D. Lav-
ery, P. Bayvel, and L. Schmalen, “End-to-End Deep Learning of Optical
Fiber Communications,” J. Lightw. Technol., vol. 36, no. 20, pp. 4843–
4855, Oct. 2018.

[14] E. Bourtsoulatze, D. Burth Kurka, and D. G¨und¨uz, “Deep joint source-
channel coding for wireless image transmission,” IEEE Transactions on
Cognitive Communications and Networking, vol. 5, no. 3, pp. 567–579,
2019.

[15] S. Cammerer, F. Ait Aoudia, S. D¨orner, M. Stark, J. Hoydis, and S. ten
Brink, “Trainable communication systems: Concepts and prototype,”
IEEE Transactions on Communications, vol. 68, no. 9, pp. 5489–5503,
2020.

[16] F. Ait Aoudia and J. Hoydis, “Model-free training of end-to-end com-
munication systems,” IEEE J. Sel. Areas Commun., vol. 37, no. 11, pp.
2503–2516, Nov 2019.

[17] S. D¨orner, M. Henninger, S. Cammerer, and S. ten Brink, “WGAN-based
Autoencoder Training Over-the-air,” in 2020 IEEE 21st International
Workshop on Signal Processing Advances in Wireless Communications
(SPAWC), 2020, pp. 1–5.

[18] Y. Jiang, H. Kim, H. Asnani, S. Oh, S. Kannan, and P. Viswanath,
“Feedback Turbo autoencoder,” in 2020 IEEE International Conference
on Acoustics, Speech and Signal Processing (ICASSP), 2020, pp. 8559–
8563.

[19] Y. Zhang, H. Wu, and M. Coates, “On the design of channel coding
autoencoders with arbitrary rates for ISI channels,” IEEE Wireless
Communication Letters, 11 2021.

[20] H.-S. Kim, “HDM: Hyper-dimensional modulation for robust

low-
power communications,” in 2018 IEEE International Conference on
Communications (ICC), 2018, pp. 1–6.

[21] X. Bian, Y. Mao, and J. Zhang, “Joint activity detection and data
decoding in massive random access via a Turbo receiver,” in 2021 IEEE
22nd International Workshop on Signal Processing Advances in Wireless
Communications (SPAWC), 2021, pp. 361–365.

[22] 3rd Generation Partnership Project, “NR; physical channels and modu-

lation,” TS 38.211 V17.1.0, 2022.

[23] J. Proakis, Digital Communications. McGraw-Hill, 2001.
[24] 3GPP TSG RAN Meeting no. 71, RP-160671, “New SID Proposal:
Study on New Radio Access Technology,” NTT DOCOMO Inc.,
G¨oteborg, Sweden, Mar. 2016.

[25] 3rd Generation Partnership Project, “NR; base station radio transmission

and reception,” TS 38.104 V17.4.0, 2021.

[26] C. Douillard, M. J´ez´equel, C. Berrou, A. Picart, P. Didier, and
A. Glavieux, “Iterative correction of intersymbol interference: Turbo-
equalization,” Eur. Trans. Telecommun., vol. 6, pp. 507–511, 1995.
[27] J. Erfanian, S. Pasupathy, and G. Gulak, “Reduced complexity symbol
detectors with parallel structure for ISI channels,” IEEE Transactions
on Communications, vol. 42, no. 234, pp. 1661–1671, 1994.

[28] L. Bahl, J. Cocke, F. Jelinek, and J. Raviv, “Optimal decoding of linear
codes for minimizing symbol error rate (corresp.),” IEEE Transactions
on Information Theory, vol. 20, no. 2, pp. 284–287, March 1974.
[29] P. Robertson, E. Villebrun, and P. Hoeher, “A comparison of optimal and
sub-optimal MAP decoding algorithms operating in the log domain,” in
Proceedings IEEE International Conference on Communications ICC
’95, vol. 2, 1995, pp. 1009–1013 vol.2.

[30] Y. Bengio, N. L´eonard, and A. C. Courville, “Estimating or propagat-
ing gradients through stochastic neurons for conditional computation,”
arXiv:1308.3432, 2013.

[31] M. Courbariaux, I. Hubara, D. Soudry, R. El-Yaniv, and Y. Bengio,
“Binarized neural networks: Training deep neural networks with weights
and activations constrained to +1 or -1,” arXiv:1602.02830, 2016.
[32] C. Bockelmann, N. Pratas, H. Nikopour, K. Au, T. Svensson, C. Ste-
fanovic, P. Popovski, and A. Dekorsy, “Massive machine-type commu-
nications in 5G: physical and MAC-layer solutions,” IEEE Communica-
tions Magazine, vol. 54, no. 9, pp. 59–65, 2016.

[33] S. Schibisch, S. Cammerer, S. D¨orner, J. Hoydis, and S. ten Brink,
“Online label recovery for deep learning-based communication through
error correcting codes,” in IEEE ISWCS, 2018, pp. 1–5.

[34] M. B. Fischer, S. D¨orner, S. Cammerer, T. Shimizu, H. Lu, and
ten Brink, “Adaptive neural network-based OFDM receivers,”

S.
arXiv:2203.13571, 2022.

[35] F. Ait Aoudia and J. Hoydis, “Waveform learning for next-generation
wireless communication systems,” IEEE Transactions on Communica-
tions, pp. 1–1, 2022.

TABLE II: Hyperparameters of the CNNs

Parameter
Num. ﬁlters
Layers per CNN
Kernel

Value
100
5
5

Parameter
Activation
Decoder Iterations
Fc = F

Value
ELU
6
10

Fig. 19: Flowchart of the basic CNN block.

APPENDIX

In the appendix we want to provide further implementation
details of the autoencoder. All following parts of the system
are based on a basic CNN-structure as shown in Fig. 19.
This structure consists of 5 one-dimensional convolution-
layers with same-padding that are parameterized by the triple
[Nﬁlters, Lkernel, factivation] which is the number of ﬁlters, the
length of the kernel and the used activation function re-
spectively. The output layer is chosen according to the use
case within the PHY-AE system. Further, Alg. 1 shows a
more detailed (but probably still incomplete) summary of the
training process.

A. PHY-AE Encoder

layer of

The output

the outer encoder

is a one-
dimensional convolutional-layer with the hyperparamters
[Nﬁlters, Lkernel, factivation] = [10, 1, None]. The task of the layer
is to combine the channels per position to the desired output of
F = 10 coded features per bit-position. Similarly, the output
layer of the inner encoder is a one-dimensional convolutional-
layer with the hyperparamters [Nﬁlters, Lkernel, factivation] =
[2, 1, None]. In this case the channels are combined to resem-
ble the real part and imaginary part of a complex symbol.
The ﬁnal processing step in the transmitter concerns the
normalization. The basic normalization step ensure that each
symbol sequence x has a zero mean with unit energy via

(3)

x(cid:48)

µx(cid:48)

x =

−
σx(cid:48)
is the mean and σx(cid:48)

where µx(cid:48)
the standard deviation of
x(cid:48). Furthermore, during inference of the symbol power con-
strained PHY-AE, we only consider the phase of the symbol
= 1. While during training,
xi|
and set the magnitude to
we only clip xi according to a power-threshold per symbol
to ensure a stable training process, instead of considering the
phase. To achieve convergence we successively decrease this
2 = 1.01.
2 = 2,
power-threshold to
For each threshold we train until the test-loss saturates.

2 = 1.1 and

xi|
|

xi|
|

xi|

|

|

12

Algorithm 1: Training procedure of one epoch for the
PHY-AE.
Input

: γ, α, TTX, TRX, θENC, θDET, θDEC, σ2

ENC,

DET,min, σ2
σ2

DET,max, σ2

DEC,min, σ2

DEC,max

Output: θENC, θDET, θDEC
// Transmitter training
For i = 1, . . . , TTX do

ENC

ENC](cid:1)

set trainable(θENC, θDET, θDEC) =
[True, False, False]
u
generate Bits()
←
encode (u; θENC)
x
←
transmit (cid:0)x, [σ2
y
←
// Detector with σ2
detection (y)
pτ ←
LCCE,det ←
// Decoder with σ2
ˆτoff ←
argmax (pτ )
ycutout ←
lT
u ←
LBCE,dec ←
Ltot ←
θENC ←

LBCE,dec + α
SGD (θENC, Ltot)

decode (ycutout)
BCE (cid:0)u, lT

CCE (τoff, pτ ; θENC)

cutout (y, τoff)

u
LCCE,det

ENC

(cid:1)

·

end
// Receiver training
For i = 1, . . . , TRX do

DET,min, σ2

DET,max],

generate none msg(γ)

DEC](cid:1)

DET, σ2
DET

concat (yDET, None-messages)

←

←

generate SNR([[σ2

transmit (cid:0)x, [σ2

DEC,max]])
encode (u; θENC)

set trainable(θENC, θDET, θDEC) =
[False, True, True]
DET, σ2
σ2
DEC ←
[σ2
DEC,min, σ2
x
yDET, yDEC ←
// Detector with SNR σ2
None-messages
yDET ←
pτ ←
LCCE,det ←
CCE (τoff, pτ ; θDET)
// Decoder with SNR σ2
argmax(detection (yDEC))
ˆτoff ←
cutout (yDEC, ˆτoff)
ycutout ←
lT
decode (ycutout; θDEC)
u ←
BCE (cid:0)u, lT
LBCE,dec ←
Ltot ←
θDET, θDEC ←

detection (yDET; θDET)

LBCE,dec + α

(cid:1)

DEC

u ; θDEC
LCCE,det
SGD ([θDET, θDEC], Ltot)

·

end
// Adapting None-message ratio
if FAR
γ

0.1% then
γ + 0.05

≥
←

else

γ

γ

−

←

0.05

B. Detector

Before we describe the output layer of detector-CNN in
detail, we want
to the network. A
necessary pre-processing step is some form of normalization
to account for different received power levels. For this, we

to focus on the input

chose to normalize the channel observations y to unit power.
Otherwise a varying transmit power would be required during
simulation.

The output layer of the detector actually contains three
layers. The ﬁrst layer is a one-dimensional convolutional layer
with hyperparameters [Nﬁlters, Lkernel, factivation] = [1, 1, None]

Conv1D[100,5,ELU]Conv1D[100,5,ELU]Conv1D[100,5,ELU]Conv1D[100,5,ELU]Conv1D[100,5,ELU]OutputlayerXY13

Fig. 20: Unrolled decoder with implementation details. In the ﬁrst iteration the a priori information is set to l(cid:48)E,1
arrows indicate a channel depth of size F .

c,π = 0. Double

D. Achieving Variable Message Lengths

In order to achieve the BLER results for various message
lengths n, as shown in Fig. 15, we had to retrain the PHY-AE
and slightly re-design the conventional baseline system. The
PHY-AE was retrained from scratch for all lengths n, except
for n = 32 as we examined that a retrained n = 64-variant
performed better at n = 32 than the n = 32-variant learned
from scratch. For the conventional baseline, we empirically
optimized the trade-off between pilots and payload w.r.t. each
message length n. Thus, we still use QPSK modulation and
a 5G LDPC code with the respective length and rate. As
a result, we chose nbl,ZF = 16 pilot symbols for n = 40
and n = 48, nbl,ZF = 20 for n = 56 and n = 64, and
ﬁnally nbl,ZF = 24 for n = 96. Especially for short lengths
n < 56, reducing the number of pilot symbols led to further
performance degradation of the baseline system as can be seen
in Fig. 15.

to combine the channels. The second layer is a ﬂatten layer
and the third layer is a dense layer with n
nM + 1 neurons
followed by a softmax activation function. Due to the softmax
activation, each entry of p(n
can be interpreted as a
−
τ
probability of a speciﬁc integer offset τoff = [0, 1..., n
nM]
and the ﬁnal entry is the estimate whether a message is present
in the observed sequence or not.

nM+1)

−

−

For the training of the detector we use a cross-entropy (CE)-
loss. As the detector-CNN needs to ﬁnd a trade-off between
missed detections (MDs) and false alarms (FAs) we can split
the loss function in two terms. Note, that errors due to wrong
synchronization are interpreted as a MD. Thus, the loss can
be rewritten as

LCE = LCE,MD + γ

LCE,FA

·

(4)

where LCE,MD is the loss due to a MD, γ is the ratio none-
messages in the dataset and LCE,FA is the loss due to a FA.
Therefore, we can target a speciﬁc false alarm rate (FAR) by
choosing γ accordingly. For this, we propose to adapt γ during
training based on the FAR. At the end of each epoch we check
whether the FAR is smaller or larger than the target FAR and
increase or decrease γ, respectively.

Further, we want to emphasize that we use different SNRs
for detection and decoding during training, since the interest-
ing SNR region for detection is roughly 6dB lower than for
decoding.

C. Decoder

While Fig. 6 already shows the iterative structure of the
decoder, two implementation details are left out. Both are
shown in Fig. 20. The ﬁrst one regards the padding of the
a priori
information. In order to concatenate the a priori
information with the channel observations we pad it from
the left and the right with 2nM zeros in total. The second
detail concerns the calculation of the extrinsic information. It
is calculated by subtracting the a priori information from the
output of a decoder-CNN. Conveniently, this acts as a residual
connection in the network that might facilitate the training
process.

IterationiAddpaddingCNNDeci,1RemovepaddingDeinterleaveCNNDeci,2Interleaver++yl0E,ic,πl0E,i+1c,π−−LastiterationimaxAddpaddingCNNDecimax,1RemovepaddingDeinterleaveCNNDecimax,2+l0E,imaxc,πl0Tu−