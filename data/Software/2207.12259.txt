Surrogate Modeling of Melt Pool Thermal Field using Deep
Learning

AmirPouya Hemmasiana, Francis Ogokea, Parand Akbaria, Jonathan Malena,b, Jack
Beutha,b, Amir Barati Farimania,c,d

aDepartment of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, USA
bDepartment of Materials Science and Engineering, Carnegie Mellon
University, Pittsburgh, 15213, PA, USA
cDepartment of Chemical Engineering, Carnegie Mellon University, Pittsburgh, 15213, PA, USA
dMachine Learning Department, Carnegie Mellon University, Pittsburgh, 15213, PA, USA

Abstract

Powder-based additive manufacturing has transformed the manufacturing industry
over the last decade.
In Laser Powder Bed Fusion, a speciﬁc part is built in an
iterative manner in which two-dimensional cross-sections are formed on top of each
other by melting and fusing the proper areas of the powder bed. In this process, the
behavior of the melt pool and its thermal ﬁeld has a very important role in predicting
the quality of the manufactured part and its possible defects. However, the simulation
of such a complex phenomenon is usually very time-consuming and requires huge
computational resources. Flow-3D is one of the software packages capable of executing
such simulations using iterative numerical solvers.
In this work, we create three
datasets of single-trail processes using Flow-3D and use them to train a convolutional
neural network capable of predicting the behavior of the three-dimensional thermal
ﬁeld of the melt pool solely by taking three parameters as input: laser power, laser
velocity, and time step. The CNN achieves a relative Root Mean Squared Error of
2% to 3% for the temperature ﬁeld and an average Intersection over Union score of
80% to 90% in predicting the melt pool area. Moreover, since time is included as
one of the inputs of the model, the thermal ﬁeld can be instantly obtained for any
arbitrary time step without the need to iterate and compute all the steps.

Keywords: Additive Manufacturing, Laser Powder Bed Fusion, Meltpool
Temperature, Convolutional Neural Network, Surrogate Model

1. Introduction

Metal additive manufacturing (MAM) has attracted increasing scientiﬁc attention
from industry and academia owing to its noticeable advantages relative to conven-

Preprint submitted to arXiv

August 8, 2022

2
2
0
2

g
u
A
4

]

G
L
.
s
c
[

2
v
9
5
2
2
1
.
7
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
tional manufacturing methods [1]. It enables the manufacturing of complex geome-
tries with higher reliability and reduced material consumption and lead time. [2, 3]
Despite these beneﬁts, controlling the quality of the printed parts is a major challenge
as defects such as lack of fusion, keyhole, and balling can compromise the structural
[4] Since these defects are
integrity of the additively manufactured components.
rooted in the dynamics of the melt pool– a locally melted zone generated by the
emission of the laser on the powder particles– monitoring and controlling the melt
pool’s geometry and thermal ﬁeld are of critical importance. [3]

To monitor the melt pool in the Laser Powder Bed Fusion (LPBF) process, ex-
periments can be conducted. However, they are expensive and need laborious prepa-
ration and adjustment. In addition, employing simulation methods such as Flow-3D
Software[5] to generate computational predictions in such a complex multi-scale and
multi-physics phenomenon is time-consuming, and also requires huge computational
resources and integration of multiple discrete and costly simulations. [6] Flow-3D is
one of the software packages capable of executing such simulations utilizing iterative
numerical solvers.

As an alternative to the computationally expensive numerical solvers like Flow-3D,
we leverage the power of deep learning to make fast and accurate predictions of the
three-dimensional thermal ﬁeld of the melt pool over time. In the last decade, deep
learning has caused a revolution in the ﬁeld of computer vision [7, 8]. Deep neural
networks have shown success in many challenging areas like computer vision [7, 9] and
speech recognition [10, 11, 12, 13]. Following the introduction of convolutional neural
networks (CNNs) by Lecun et al.[14] and the demonstrated capability of AlexNet on
the image classiﬁcation benchmark [7], these networks have become widely used in
many computer vision tasks including image recognition and segmentation[15, 16], as
well as video classiﬁcation[17]. Inspired by this, many researchers have been applying
deep learning models in science and engineering problems [18, 19, 20]. Deep learning
has also been utilized to study complex physical systems by obtaining accurate solu-
tions to their systems of governing equations, which are usually ordinary or partial
diﬀerential equations[21, 22, 23]. Due to the high computational cost of conventional
numerical solvers, developing surrogate models to study physical systems has been
of great interest to many researchers and scientists as well[24, 25, 26]. Convolutional
neural networks are well-suited for dealing with spatially structured data due to their
inherent translational invariance, weight sharing, and feature extraction properties.
They have been applied to obtain rapid prediction and simulation of complex phe-
nomena like reaction-diﬀusion systems [27] and convective ﬂuid ﬂows [28].

In this work, we approximate the thermal ﬁeld and geometry of the melt pool
during the LPBF process by utilizing the capabilities of CNNs. Our model’s input
is simply a vector containing three numbers: The laser beam’s power and velocity,
and the time step. It succeeds in learning the dominant pattern of the melt pool’s

2

thermal ﬁeld for a wide variety of process parameters. We evaluate the performance
of our model qualitatively by visual comparison with the results from Flow-3D, and
quantitatively by measuring the Root Mean Squared Error for the thermal ﬁeld and
Intersection over Union for the melt pool region.

2. Dataset

Table 1: The datasets used in this work.

name

alloy

mesh powder

train val P(w) V(mm/s)

Ti64-5m

Ti-6Al-4V 5µm

Ti64-10m Ti-6Al-4V 10µm

Ti64-10m-p Ti-6Al-4V 10µm

SS-10m-p

SS316L

5µm

No

No

Yes

Yes

39

287

555

32

7

100-520

400-1200

71

100-460

100-1500

138

100-560

100-1400

7

100-320

100-400

A summary of the datasets created for this work can be found in Table 1. Each
simulation contains 100 timesteps spaced at 5 µs intervals. The FLOW-3D v11.2
CFD package was used to simulate the melting process [5]. Generally, coupled PDEs
describing the mass, momentum, and energy conservation present in the system are
solved using a volume of ﬂuid (VOF) model. These equations are reproduced below:

∇ · (ρ(cid:126)v) = 0

∂(cid:126)v
∂t

+ ((cid:126)v · ∇)(cid:126)v = −

1
ρ

∇ (cid:126)P + µ∇2(cid:126)v + (cid:126)g(1 − α(T − Tm))

∂h
∂t

+ ((cid:126)v · ∇) h =

1
ρ

(∇ · k∇T )

(1)

(2)

(3)

where (cid:126)P is the pressure of the system, (cid:126)g represents gravity, α is the coeﬃcient of
thermal expansion, ρ is the density of the material, h is the speciﬁc enthalpy, (cid:126)v is the
velocity of the system and k is the heat conductivity of the material. The thermal
parameters, Cp, k, as well as the density, ρ, are assumed to vary with temperature,
with their functional relationships described in [29] for both materials. While the
material is assumed to be incompressible in these simulations, however, there are

3

accommodations for the variation of density with temperature. To do so, the incom-
pressible ﬂow algorithm is solved using a variable density, calculated based on the
local temperature values.

To compute the dynamics of the free surface of the melt pool, the VOF method
is used to deﬁne the ﬂuid conﬁguration [30]. A conservation equation can be written
for the Volume of Fluid function, F (x, y, z, t), as demonstrated in equation 4. When
F = 1, the mesh cell contains ﬂuid, whereas when F = 0, a void region is deﬁned.
This void region represents areas that are ﬁlled with a gas with a much lower density
than the melted substrate. The gas dynamics in the void regions are not explicitly
modeled, they are assigned a uniform pressure to reduce the computational expense
of the simulation.

The laser beam is expressed as a Gaussian heat source, with a distribution de-

∂F
∂t

+ (∇F · v) = 0

(4)

scribed by

q =

P
r2
0π

exp






−

(cid:32)√

2r
r0

(cid:33)2




(5)

where P is the laser power and r0 is the laser beam radius. During simulation, the
heat ﬂux is only applied to the top layer of surface cells and propagates through the
rest of the domain through heat transfer mechanisms.

The evaporation mechanisms are also simulated, to model the ejection of vapor

during the melting process. The recoil pressure is given by

Ps = aPV exp

(cid:26)

∆Hv
(γ − 1)C vap

v Tv

(cid:19)(cid:27)

(cid:18)

1 −

Tv
T

(6)

Here, the accommodation coeﬃcient a, deﬁnes the ratio of the energy exchanged
with the vapor phase, to the maximum energy exchange that is thermodynamically
possible. ∆Hv represents the latent heat of vaporization, γ is the ratio of speciﬁc
heats, C vap
is the constant volume heat capacity of the vapor, and PV , TV describe
the saturation temperature and pressure respectively. Accordingly, the total mass
˙M , due to this evaporation process is also taken into account, with the following
loss,
relationship.

v

(cid:114) 1

˙M = a

(P sat

l − Pp)

2πR ¯T
In the above equation, R refers to the gas constant, ¯T describes the average temper-
ature of the liquid along the free surface, and Pp is the partial pressure of the metal
vapor.

(7)

4

During the melting process, the keyhole that is formed in high energy density situ-
ations can increase the absorptivity of the melt pool, due to the laser beam reﬂecting
within the keyhole cavity [31]. To account for this eﬀect, the relationship between
the power, velocity, and absorptivity is determined based on a scaling relationship
introduced in [32].

This scaling relationship reproduced in Equations 8 and 9 determines the absorp-
tivity A as a function of the beam radius, r0, thermal diﬀusivity, D, melting enthalpy
Hm, the minimum absorptivity on a ﬂat plate, Am, and the processing parameters.
Generally, as the energy density of the laser increases, the keyhole deepens, and the
local absorptivity increases.

A = (cid:0)0.70(1 − e−0.66y)(cid:1)

(8)

(9)

(cid:32)

y =

AmP D

(cid:112)Dr2

(cid:33)

(cid:112)Dr0/v)

(r0

0/v
This simulation was performed on a regular cartesian mesh, with mesh elements
of size 5 µm. A complete list of the values for material parameters used to simulate
the melt pool behavior can be found in the Appendix, in Tables A.3 and A.4.

πvHmr2
0

Flow-3D uses a Volume-Of-Fluid (VOF) approach towards simulating the heat
transfer dynamics, which depending on the resolution of the simulation, can cause
isolated mesh elements to take on artiﬁcially high temperatures. This can result when
the laser impacts small, disconnected ejected particles, or when the dynamics of the
ﬂuid ﬂow are chaotic and simulated at relatively coarse resolutions. To resolve this
issue, we take the 99.9% percentile of the temperature values above the melting point
and clipped the values above that temperature. The room temperature is 293K and
the 99.9% percentile was 6500K, so we use these values as Tmin and Tmax respec-
tively. This ﬁltering process allows us to use a mesh element size that is suﬃciently
coarse to enable the generation of large amounts of data while preserving the correct
temperature distribution. A comparison between the generated Flow-3D data and
reported experimental data from literature is made in Figure C.11. This comparison
is made for the melt pool depth for SS316L and the keyhole depth in Ti-6Al-4V. Both
comparisons are made within the keyhole regime where analytical models such as the
Rosenthal equation are no longer applicable [33]. This demonstrates that the scaled
absorptivity is able to simulate the increase in melt pool depth caused by the multiple
reﬂection eﬀect in the keyhole.

In order to feed the data to our network, we normalize the temperature values of
the thermal ﬁeld to be on the order ∼ 100 for eﬃcient training of the neural network
model. Therefore, we apply a linear transformation to the temperature values to
map Tmin and Tmax to 0 and 1 respectively, and rescale the other temperature values

5

appropriately. We also crop the temperature ﬁeld to a region of interest to train the
model directly on the area where the melt pool is located at a given point in time.
This modiﬁcation reduces the amount of memory required for training and improves
the learning process.

3. Methodology

We begin this section by explaining the architecture of the main deep learning
model of our method. Then, we continue by introducing an auxiliary network that
improves the performance of the original model and how it is trained.

3.1. Network architecture

Figure 1a provides a schematic of our model’s architecture. Our Temperature
CNN (T-CNN) consists of a fully connected layer followed by several 3D convolutional
layers. The input vector simply contains the laser beam’s power(P) and velocity(V)
and time (t). After a feature vector is constructed from the input by the fully con-
nected layer, it is reshaped into a coarse-grid feature map. This can be interpreted
as a learned feature vector for each point of a 3D coarse-grid tensor. This feature
map is then passed through several upsampling and convolutional layers to increase
the spatial resolution and decrease the number of channels. An illustration of the
feature map’s journey throughout the CNN can be found in Figure 1b. The shapes of
the feature maps are speciﬁc to the Ti64-5m dataset, but other aspects of the model
remain the same for all datasets. All convolutional layers use kernel size 3 and stride 1
with ’same’ padding. The scale factor for the trilinear upsampling layers is 2. We can
observe that after the ﬁrst two layers, the overall pattern and geometry of the melt
pool are captured and some ﬁner features are then learned in the following layers.
We can also notice the keyhole’s geometry as one of the learned feature maps in the
second to last layer for this particular example.

Regarding the hyperparameters of our model, the ﬁrst one is the number of chan-
nels of the ﬁrst spatial feature map (128 in Figure 1b). Choosing a lower number
of channels (64, 32, ...) resulted in a noticeable deterioration in the performance of
the model and bigger values (256, 512, ...) did not make a signiﬁcant improvement,
so we chose 128 as the ﬁnal choice. There is also the choice of using a deeper fully
connected network for the initial feature vector construction, but adding more hidden
layers to the initial network did not lead to any signiﬁcant improvement either. We
also considered the option to use transposed convolution instead of non-parametric
upsampling like the trilinear method, but it led to the checkerboard eﬀect and no
signiﬁcant diﬀerence in the performance, so non-parametric upsampling was chosen
to have a simpler and faster network. In order to ﬁnd the best activation function, we
tried using ELU, ReLU, SeLU, CELU, and Leaky ReLU, and all of them had a similar

6

Figure 1: a) The overall schematic of the architecture of T-CNN. b) The convolutional upsampling
layers and the feature maps through the network. The number of channels and the dimensions of
each feature map are noted above and below it respectively. c) The operators used in the network.

7

4x1x28x2x432x8x1664x16x32128x32x646432164128Inputs3D Thermal Field 16x4x88P V t31024ConvolutionalUpsamplingLayersa)b)1024214128Reshape LayerFully Connected LayerOutput LayerUpsampling BlockInput 3DTriLinear Upsample3D ConvLeaky ReLU3D ConvValved Leaky ReLUInputOutputInputOutputLeaky ReLUOutputc):::InputOutputoutcome, so we chose Leaky ReLU for faster optimization and lower computational
cost. The ﬁnal layer’s activation function is called a ”Valved” Leaky ReLU because
it is a Leaky ReLU in the training phase but a ReLU in the testing phase. Therefore,
we call it a valved Leaky ReLU since we open and close the leak manually. This is
because negative output values are not physically possible (temperature lower than
the ambient temperature), so we prevent the model from predicting negative outputs.
However, we need to design the model in a way that it can learn to predict positive
outputs, so we let the last activation be leaky in the training phase so that there is
a gradient that can make the network learn not to predict negative values and tweak
its parameters in the right way.

This problem is a regression task on the 3D thermal ﬁeld, so we use the mean
squared error (MSE) as the loss function to train our model. This loss is calculated
by taking the average of the squared error across all mesh elements in the 3D thermal
ﬁeld. Therefore, the loss for a single sample is deﬁned as follows:

M SE =

1
LW D

L
(cid:88)

W
(cid:88)

D
(cid:88)

x=1

y=1

z=1

[ ˆT (x, y, z) − T (x, y, z)]2

(10)

where ˆT is the predicted temperature value at the mesh element with the positional
index [x, y, z] of the thermal ﬁeld made by our T-CNN, T is the value for the same
point from the output of Flow-3D, and L, W, D represent the length, width, and depth
of the cartesian mesh respectively. We use the Adam optimizer[34] with a learning rate
of 0.0002 to optimize the parameters of the network and minimize the loss function.
We also utilize PyTorch’s learning rate scheduler to decrease the learning rate when
the learning curve reaches a plateau. The factor for the scheduler is set to 0.2 and
patience is set to 3, meaning if the average training loss does not improve after 3
consecutive epochs, the learning rate is multiplied by 0.2.

3.2. Using an auxiliary masker network

After training T-CNN, we observed appealing results in terms of visual quality
and achieved an average relative Root Mean Square Error of 2.5% on predicting the
thermal ﬁeld. However, there is a delicate issue with our model which is caused by how
the data is deﬁned. If you pay close attention to the output of the model in Figure 1a,
you may notice a thin layer in the boundary of the keyhole, which is visible between
the empty area of the keyhole and the high temperature values of the melt pool.
The reason behind this is the value of the thermal ﬁeld in the keyhole space. The
temperature value that Flow-3D assigns to the points not occupied by metal particles
is equal to the room temperature. Since the output of T-CNN is continuous, it cannot
suddenly change from a few thousand Kelvins to room temperature. Therefore, we
see a thin layer with intermediate temperature values between room temperature and

8

very hot values since the temperature decreases gradually over a few mesh elements.

Figure 2: A simple illustration of the role of the auxiliary M-CNN. a) The initial T-CNN model’s
functionality. b) How M-CNN and TM-CNN are trained. c) The MT-CNN model augmented with
M-CNN

In order to make the output of the model more realistic and avoid creating this
thin layer, we use our pre-trained T-CNN and train an auxiliary network called the
masker CNN (M-CNN). The architecture of this model is the same as Figure 1a,
except that the ﬁnal layer’s activation is the sigmoid function. The job of M-CNN is
to predict a binary mask for the keyhole. To be more precise, its output is supposed
to estimate the areas which are assigned the exact value of room temperature by
Flow-3D. That includes both the keyhole space and the regions of the metal where
the heat has not reached yet. After training the M-CNN to learn this task, we train
a new Masked Temperature CNN (MT-CNN) to predict the thermal ﬁeld. Now, the
values in the keyhole space are set to room temperature by the mask provided by
M-CNN, and MT-CNN’s output is neglected in that space. Therefore, MT-CNN can
freely predict high temperature values in that region without having to try to predict
the room temperature for the keyhole at the same time. A simple comparison between
T-CNN and MT-CNN and their outputs can be found in Figure 2.

4. Results and discussion

We begin with a qualitative comparison between our model’s predictions and the
results of the direct numerical simulations obtained from Flow-3D. Figure 3 contains a

9

Figure 3: Performance of MT-CNN on some validation samples from the Ti64-5m dataset. Note
that the original data is 3D, and the cross-section of the thermal ﬁeld is shown in these plots.

10

 few of the validation samples from the Ti64-5m dataset. We can see that the predicted
thermal ﬁeld closely matches the ground truth for the most part. Quantitative metrics
will be explained later. We can say that the only location where the model’s prediction
noticeably diﬀers from the ground truth is the keyhole area. This is because this area
contains the most turbulent and transient behavior compared to the other parts of
the melt pool, especially in high energy density regimes. Since the model is trained
with a simple MSE loss, it only learns the dominant pattern and geometry of the
thermal ﬁeld and fails to capture the turbulent phenomena happening at the keyhole.
However, learning the overall geometry is indeed the main purpose of this work,
because important features like the keyhole’s depth can be obtained from it. After
all, losing unimportant information is the trade-oﬀ that we are willing to take to
obtain the important information more quickly and eﬃciently.

Table 2: The mean and standard deviation of the quantitative evaluation metrics.

T-CNN

MT-CNN

Dataset

RMSE

IoU

RMSE

IoU

Ti64-5m

2.55 ± 1.04% 81.59 ± 14.67% 2.81 ± 1.21% 84.34 ± 12.46%

Ti64-10m

2.18 ± 1.25% 79.17 ± 15.52% 2.45 ± 1.39% 80.53 ± 14.09%

Ti64-10m-p

2.00 ± 0.79% 83.33 ± 10.06% 2.19 ± 0.89% 85.26 ± 7.82%

SS316L-5m-p 3.37 ± 1.11% 81.48 ± 10.51% 3.73 ± 1.30% 81.86 ± 8.31%

For the quantitative evaluation of our model’s performance, we use two metrics:
Root-Mean-Square Error (RMSE) on the thermal ﬁeld and Intersection over Union
(IoU) on the melt pool. We consider each mesh element with a temperature value
higher than the melting point as liquid. The melting point is set as the average of
liquidus and solidus temperature, which are provided in Tables A.3 and A.4. Looking
at Figure 3, we can see that the metrics achieved by the model also indicate its
success. The performance of the model for other datasets is summarized in Table 2.
The performance of T-CNN is also included for the sake of comparison. We can see
that despite the increase in the RMSE, the IoU score is improved by MT-CNN.

In order to investigate the performance of the model further, we will look into the
distribution of our evaluation metrics over time and the data distribution. Figure 4a
shows the averaged value of the metrics over time for each sample of the dataset. We
can see that there is a noticeable correlation between the performance of the model
and the energy density. In the bottom right of these plots, the energy density is low

11

Figure 4: The summarized results for Ti64-5m dataset. a) The average performance of the model
over the data distribution. The test samples are marked by a black edge. b) The performance of
the model over time. The main line indicates the median value for the metric, and the shaded area
indicates the interquartile range.

and the melt pool is relatively small. Since most of the thermal ﬁeld is still unaﬀected
by the heat from the laser beam, both the ground truth and the prediction are still
mostly at room temperature, therefore the RMSE is lower in this regime. It is also
observed that the IoU score is lower than the other regions of the plot which is due
to the small size of the melt pool. With a small melt pool, the IoU score is aﬀected
more severely by false predictions of the model. Moving to the high energy density
regime in the upper left of the plots, we can observe an increase in the RMSE and the
IoU score because of the larger size of the melt pool. The turbulence in the keyhole
greatly increases the RMSE in these regimes, but the IoU score is still high and the
model has succeeded in estimating the melt pool’s overall geometry.

Figure 4b shows the distribution of the metrics over the dataset for each time
step. We can see that both the RMSE and the IoU score are much lower in the initial
time steps. This is because of the small size of the melt pool as explained before.
The IoU score is very low at the beginning of the process which decreases the overall
average for the metric. However, we can see that the model achieves an IoU score

12

  a) b) of 90% for most time steps which again shows its successful estimation of the melt
pool geometry. The slight decrease of IoU in the last few time steps is due to the
solidiﬁcation of the metal which happens only for a few samples where the velocity
is too high and the laser beam exits the modeled part. Since there is very little data
on this phenomenon, the model has not learned to predict the thermal ﬁeld in such
a situation compared to the earlier time steps.

In this section, we compared the predictions of our model and the ground truth
for a qualitative evaluation of MT-CNN and further analyzed the results by looking
closer into the distribution of the RMSE and the IoU score over the dataset and
through time. We chose the Ti64-5m dataset to elaborate on in this section because
the model successfully achieved its goal despite having only 46 sampled processes and
the highest output dimensionality among other datasets. Similar plots and ﬁgures for
the other datasets can be found in Appendix B. The model achieves similar results
for all datasets, but it does not work as well for the SS-5m-5 dataset. This can be
because of the low number of data samples and also the higher amount of turbulent
phenomena in this dataset. However, we can see that our model still succeeds in
learning the main geometry of the melt pool in all datasets by looking at the IoU
score and comparing the predictions with the ground truth.

5. Conclusion and future work

In this paper, we proposed a deep learning framework that successfully predicts the
thermal ﬁeld and the dominant melt pool geometry in LPBF additive manufacturing
processes. Compared to the Flow-3D software which uses iterative numerical solvers,
this model has a huge computational advantage. Since time is included as one of the
inputs to our CNN, we can obtain the thermal ﬁeld at any arbitrary time instantly
without the need to run a whole simulation. For the Ti-6Al-4V alloy, the model
achieved an average relative RMSE of 2 to 3% on predicting the thermal ﬁeld and an
average IoU of 80 to 90% on predicting the melt pool area. We had a limited dataset
for the SS316L dataset and the model achieved a relative RMSE of 3.7% and an IoU
score of 82% which is not as good as Ti-6Al-4V. However, the model successfully
captures the dominant pattern and features of the melt pool for all datasets used in
this work.

References

[1] T. DebRoy, H. Wei, J. Zuback, T. Mukherjee, J. Elmer, J. Milewski, A. M.
Beese, A. d. Wilson-Heid, A. De, W. Zhang, Additive manufacturing of metallic
components–process, structure and properties, Progress in Materials Science 92
(2018) 112–224.

13

[2] J. Jiang, Y. Ma, Path planning strategies to optimize accuracy, quality, build
time and material use in additive manufacturing: a review, Micromachines 11 (7)
(2020) 633.

[3] P. Akbari, F. Ogoke, N.-Y. Kao, K. Meidani, C.-Y. Yeh, W. Lee, A. B.
Farimani, Meltpoolnet: Melt pool characteristic prediction in metal addi-
tive manufacturing using machine learning, Additive Manufacturing (2022)
102817doi:https://doi.org/10.1016/j.addma.2022.102817.
URL
S2214860422002172

https://www.sciencedirect.com/science/article/pii/

[4] C. Wang, X. Tan, S. Tor, C. Lim, Machine learning in additive manufactur-
ing: State-of-the-art and perspectives, Additive Manufacturing 36 (2020) 101538.
doi:https://doi.org/10.1016/j.addma.2020.101538.

[5] I. Flow Science, FLOW-3D, Version 12.0, Santa Fe, NM (2019).

URL https://www.flow3d.com/

[6] F. Yan, Y.-C. Chan, A. Saboo, J. Shah, G. B. Olson, W. Chen, Data-driven
prediction of mechanical properties in support of rapid certiﬁcation of additively
manufactured alloys, Computer Modeling in Engineering & Sciences 117 (3)
(2018) 343–366.

[7] A. Krizhevsky, I. Sutskever, G. E. Hinton, Imagenet classiﬁcation with deep con-
volutional neural networks, Advances in neural information processing systems
25 (2012).

[8] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare,
A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski, et al., Human-level
control through deep reinforcement learning, nature 518 (7540) (2015) 529–533.

[9] A. Voulodimos, N. Doulamis, A. Doulamis, E. Protopapadakis, Deep learning for
computer vision: A brief review, Computational intelligence and neuroscience
2018 (2018).

[10] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-r. Mohamed, N. Jaitly, A. Senior,
V. Vanhoucke, P. Nguyen, T. N. Sainath, et al., Deep neural networks for acoustic
modeling in speech recognition: The shared views of four research groups, IEEE
Signal processing magazine 29 (6) (2012) 82–97.

[11] L. Deng, G. Hinton, B. Kingsbury, New types of deep neural network learning
for speech recognition and related applications: An overview, in: 2013 IEEE

14

international conference on acoustics, speech and signal processing, IEEE, 2013,
pp. 8599–8603.

[12] A. Graves, A.-r. Mohamed, G. Hinton, Speech recognition with deep recurrent
neural networks, in: 2013 IEEE international conference on acoustics, speech
and signal processing, Ieee, 2013, pp. 6645–6649.

[13] O. Abdel-Hamid, A.-r. Mohamed, H. Jiang, L. Deng, G. Penn, D. Yu, Con-
volutional neural networks for speech recognition, IEEE/ACM Transactions on
audio, speech, and language processing 22 (10) (2014) 1533–1545.

[14] Y. LeCun, Y. Bengio, et al., Convolutional networks for images, speech, and
time series, The handbook of brain theory and neural networks 3361 (10) (1995)
1995.

[15] K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale

image recognition, arXiv preprint arXiv:1409.1556 (2014).

[16] J. Long, E. Shelhamer, T. Darrell, Fully convolutional networks for semantic
segmentation, in: Proceedings of the IEEE conference on computer vision and
pattern recognition, 2015, pp. 3431–3440.

[17] A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, L. Fei-Fei, Large-
scale video classiﬁcation with convolutional neural networks, in: Proceedings of
the IEEE conference on Computer Vision and Pattern Recognition, 2014, pp.
1725–1732.

[18] J. N. Kutz, Deep learning in ﬂuid dynamics, Journal of Fluid Mechanics 814

(2017) 1–4.

[19] T. Kirchdoerfer, M. Ortiz, Data-driven computational mechanics, Computer

Methods in Applied Mechanics and Engineering 304 (2016) 81–101.

[20] A. Oishi, G. Yagawa, Computational mechanics enhanced by deep learning, Com-
puter Methods in Applied Mechanics and Engineering 327 (2017) 327–351.

[21] J. Sirignano, K. Spiliopoulos, Dgm: A deep learning algorithm for solving partial

diﬀerential equations, Journal of computational physics 375 (2018) 1339–1364.

[22] J. Han, A. Jentzen, E. Weinan, Solving high-dimensional partial diﬀerential
equations using deep learning, Proceedings of the National Academy of Sciences
115 (34) (2018) 8505–8510.

15

[23] M. Raissi, P. Perdikaris, G. E. Karniadakis, Physics-informed neural networks:
A deep learning framework for solving forward and inverse problems involving
nonlinear partial diﬀerential equations, Journal of Computational physics 378
(2019) 686–707.

[24] L. Liang, M. Liu, C. Martin, W. Sun, A deep learning approach to estimate stress
distribution: a fast and accurate surrogate of ﬁnite-element analysis, Journal of
The Royal Society Interface 15 (138) (2018) 20170844.

[25] Z. L. Jin, Y. Liu, L. J. Durlofsky, Deep-learning-based surrogate model for reser-
voir simulation with time-varying well controls, Journal of Petroleum Science
and Engineering 192 (2020) 107273.

[26] M. Tang, Y. Liu, L. J. Durlofsky, A deep-learning-based surrogate model for data
assimilation in dynamic subsurface ﬂow problems, Journal of Computational
Physics 413 (2020) 109456.

[27] A. Li, R. Chen, A. B. Farimani, Y. J. Zhang, Reaction diﬀusion system prediction
based on convolutional neural network, Scientiﬁc reports 10 (1) (2020) 1–9.

[28] C. Jiang, A. B. Farimani, Deep learning convective ﬂow using conditional gen-

erative adversarial networks, arXiv preprint arXiv:2005.06422 (2020).

[29] K. C. Mills, Recommended values of thermophysical properties for selected com-

mercial alloys, Woodhead Publishing, 2002.

[30] C. W. Hirt, B. D. Nichols, Volume of ﬂuid (vof) method for the dynamics of free

boundaries, Journal of computational physics 39 (1) (1981) 201–225.

[31] J. Trapp, A. M. Rubenchik, G. Guss, M. J. Matthews, In situ absorptivity
measurements of metallic powders during laser powder-bed fusion additive man-
ufacturing, Applied Materials Today 9 (2017) 341–349.

[32] J. Ye, S. A. Khairallah, A. M. Rubenchik, M. F. Crumb, G. Guss, J. Belak,
M. J. Matthews, Energy coupling mechanisms and scaling behavior associated
with laser powder bed fusion additive manufacturing, Advanced Engineering
Materials 21 (7) (2019) 1900185.

[33] P. Promoppatum, S.-C. Yao, P. C. Pistorius, A. D. Rollett, A comprehensive
comparison of the analytical and numerical prediction of the thermal history
and solidiﬁcation microstructure of inconel 718 products made by laser powder-
bed fusion, Engineering 3 (5) (2017) 685–694.

16

[34] D. P. Kingma, J. Ba, Adam: A method for stochastic optimization, arXiv

preprint arXiv:1412.6980 (2014).

[35] J.-B. Forien, N. P. Calta, P. J. DePond, G. M. Guss, T. T. Roehling, M. J.
Matthews, Detecting keyhole pore defects and monitoring process signatures
during laser powder bed fusion: A correlation between in situ pyrometry and ex
situ x-ray radiography, Additive Manufacturing 35 (2020) 101336.

[36] R. Cunningham, C. Zhao, N. Parab, C. Kantzos, J. Pauza, K. Fezzaa, T. Sun,
A. D. Rollett, Keyhole threshold and morphology in laser melting revealed by
ultrahigh-speed x-ray imaging, Science 363 (6429) (2019) 849–852.

17

Appendix A. Material Parameters

Table A.3: Material Parameters used to simulate the Ti-6Al-4V melting process

Parameter

Value

Units

Density, ρ, 298 K

Density, ρ, 1923 K

Speciﬁc Heat, Cv, 298 K

Speciﬁc Heat, Cv, 1923 K

Vapor Speciﬁc Heat, Cv, vapor

4420

3920

546

831

600

Thermal Conductivity, k, 298 K 7

Thermal Conductivity, k, 1923 K 33.4

kg/m3

kg/m3

J/kg/K

J/kg/K

J/kg/K

W/m/K

W/m/K

Viscosity

0.00325

kg/m/s

Liquidus Temperature, TL

Solidus Temperature, TS

1923

1873

K

K

Latent heat of fusion

2.86 ×105

J/kg

Latent heat of vaporization

6.00 ×104

J/kg

18

Table A.4: Material Parameters used to simulate the SS316L melting process

Parameter

Value

Units

Density, ρ, 298 K

Density, ρ, 1923 K

Speciﬁc Heat, Cv, 298 K

Speciﬁc Heat, Cv, 1923 K

Vapor Speciﬁc Heat, Cv, vapor

7950

7249

470

726

600

Thermal Conductivity, k, 298 K 13.4

Thermal Conductivity, k, 1923 K 29.0

Viscosity

Liquidus Temperature, TL

Solidus Temperature, TS

0.008

1694

1717

kg/m3

kg/m3

J/kg/K

J/kg/K

J/kg/K

W/m/K

W/m/K

kg/m/s

K

K

Latent heat of fusion

2.6 ×105

J/kg

Latent heat of vaporization

6.00 ×104

J/kg

19

Appendix B. Results for the rest of the datasets

Figure B.5: Performance of MT-CNN on some validation samples from the Ti64-10m dataset.

20

 Figure B.6: Performance of MT-CNN on some validation samples from the Ti64-10m-p dataset.

21

 Figure B.7: Performance of MT-CNN on some validation samples from the SS-5m-p dataset.

22

 Figure B.8: Result for Ti64-10m dataset. a) Performance over the data distribution. The validation
data is marked by a black edge. b) Performance over time.

23

  a) b) Figure B.9: Result for Ti64-10m-p dataset. a) Performance over the data distribution. The valida-
tion data is marked by a black edge. b) Performance over time.

24

  a) b) Figure B.10: Result for SS-5m-p dataset. a) Performance over the data distribution. The validation
data is marked by a black edge. b) Performance over time.

25

  a) b) Appendix C. Comparison of Flow-3D data with experimental data

Figure C.11: A comparison of the Flow-3D simulated melt pool to experimental data from the
literature. (a) Comparisons for the melt pool depth at varying powers at a 95 micron beam diameter,
experimental data referenced from [35] for SS316L. (b) Comparisons for the keyhole depth at varying
powers at a 95 micron beam diameter, experimental data referenced from [36] for Ti-6Al-4V.

References

[1] T. DebRoy, H. Wei, J. Zuback, T. Mukherjee, J. Elmer, J. Milewski, A. M.
Beese, A. d. Wilson-Heid, A. De, W. Zhang, Additive manufacturing of metallic
components–process, structure and properties, Progress in Materials Science 92
(2018) 112–224.

[2] J. Jiang, Y. Ma, Path planning strategies to optimize accuracy, quality, build
time and material use in additive manufacturing: a review, Micromachines 11 (7)
(2020) 633.

26

[3] P. Akbari, F. Ogoke, N.-Y. Kao, K. Meidani, C.-Y. Yeh, W. Lee, A. B.
Farimani, Meltpoolnet: Melt pool characteristic prediction in metal addi-
tive manufacturing using machine learning, Additive Manufacturing (2022)
102817doi:https://doi.org/10.1016/j.addma.2022.102817.
URL
S2214860422002172

https://www.sciencedirect.com/science/article/pii/

[4] C. Wang, X. Tan, S. Tor, C. Lim, Machine learning in additive manufactur-
ing: State-of-the-art and perspectives, Additive Manufacturing 36 (2020) 101538.
doi:https://doi.org/10.1016/j.addma.2020.101538.

[5] I. Flow Science, FLOW-3D, Version 12.0, Santa Fe, NM (2019).

URL https://www.flow3d.com/

[6] F. Yan, Y.-C. Chan, A. Saboo, J. Shah, G. B. Olson, W. Chen, Data-driven
prediction of mechanical properties in support of rapid certiﬁcation of additively
manufactured alloys, Computer Modeling in Engineering & Sciences 117 (3)
(2018) 343–366.

[7] A. Krizhevsky, I. Sutskever, G. E. Hinton, Imagenet classiﬁcation with deep con-
volutional neural networks, Advances in neural information processing systems
25 (2012).

[8] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare,
A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski, et al., Human-level
control through deep reinforcement learning, nature 518 (7540) (2015) 529–533.

[9] A. Voulodimos, N. Doulamis, A. Doulamis, E. Protopapadakis, Deep learning for
computer vision: A brief review, Computational intelligence and neuroscience
2018 (2018).

[10] G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-r. Mohamed, N. Jaitly, A. Senior,
V. Vanhoucke, P. Nguyen, T. N. Sainath, et al., Deep neural networks for acoustic
modeling in speech recognition: The shared views of four research groups, IEEE
Signal processing magazine 29 (6) (2012) 82–97.

[11] L. Deng, G. Hinton, B. Kingsbury, New types of deep neural network learning
for speech recognition and related applications: An overview, in: 2013 IEEE
international conference on acoustics, speech and signal processing, IEEE, 2013,
pp. 8599–8603.

27

[12] A. Graves, A.-r. Mohamed, G. Hinton, Speech recognition with deep recurrent
neural networks, in: 2013 IEEE international conference on acoustics, speech
and signal processing, Ieee, 2013, pp. 6645–6649.

[13] O. Abdel-Hamid, A.-r. Mohamed, H. Jiang, L. Deng, G. Penn, D. Yu, Con-
volutional neural networks for speech recognition, IEEE/ACM Transactions on
audio, speech, and language processing 22 (10) (2014) 1533–1545.

[14] Y. LeCun, Y. Bengio, et al., Convolutional networks for images, speech, and
time series, The handbook of brain theory and neural networks 3361 (10) (1995)
1995.

[15] K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale

image recognition, arXiv preprint arXiv:1409.1556 (2014).

[16] J. Long, E. Shelhamer, T. Darrell, Fully convolutional networks for semantic
segmentation, in: Proceedings of the IEEE conference on computer vision and
pattern recognition, 2015, pp. 3431–3440.

[17] A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, L. Fei-Fei, Large-
scale video classiﬁcation with convolutional neural networks, in: Proceedings of
the IEEE conference on Computer Vision and Pattern Recognition, 2014, pp.
1725–1732.

[18] J. N. Kutz, Deep learning in ﬂuid dynamics, Journal of Fluid Mechanics 814

(2017) 1–4.

[19] T. Kirchdoerfer, M. Ortiz, Data-driven computational mechanics, Computer

Methods in Applied Mechanics and Engineering 304 (2016) 81–101.

[20] A. Oishi, G. Yagawa, Computational mechanics enhanced by deep learning, Com-
puter Methods in Applied Mechanics and Engineering 327 (2017) 327–351.

[21] J. Sirignano, K. Spiliopoulos, Dgm: A deep learning algorithm for solving partial

diﬀerential equations, Journal of computational physics 375 (2018) 1339–1364.

[22] J. Han, A. Jentzen, E. Weinan, Solving high-dimensional partial diﬀerential
equations using deep learning, Proceedings of the National Academy of Sciences
115 (34) (2018) 8505–8510.

[23] M. Raissi, P. Perdikaris, G. E. Karniadakis, Physics-informed neural networks:
A deep learning framework for solving forward and inverse problems involving
nonlinear partial diﬀerential equations, Journal of Computational physics 378
(2019) 686–707.

28

[24] L. Liang, M. Liu, C. Martin, W. Sun, A deep learning approach to estimate stress
distribution: a fast and accurate surrogate of ﬁnite-element analysis, Journal of
The Royal Society Interface 15 (138) (2018) 20170844.

[25] Z. L. Jin, Y. Liu, L. J. Durlofsky, Deep-learning-based surrogate model for reser-
voir simulation with time-varying well controls, Journal of Petroleum Science
and Engineering 192 (2020) 107273.

[26] M. Tang, Y. Liu, L. J. Durlofsky, A deep-learning-based surrogate model for data
assimilation in dynamic subsurface ﬂow problems, Journal of Computational
Physics 413 (2020) 109456.

[27] A. Li, R. Chen, A. B. Farimani, Y. J. Zhang, Reaction diﬀusion system prediction
based on convolutional neural network, Scientiﬁc reports 10 (1) (2020) 1–9.

[28] C. Jiang, A. B. Farimani, Deep learning convective ﬂow using conditional gen-

erative adversarial networks, arXiv preprint arXiv:2005.06422 (2020).

[29] K. C. Mills, Recommended values of thermophysical properties for selected com-

mercial alloys, Woodhead Publishing, 2002.

[30] C. W. Hirt, B. D. Nichols, Volume of ﬂuid (vof) method for the dynamics of free

boundaries, Journal of computational physics 39 (1) (1981) 201–225.

[31] J. Trapp, A. M. Rubenchik, G. Guss, M. J. Matthews, In situ absorptivity
measurements of metallic powders during laser powder-bed fusion additive man-
ufacturing, Applied Materials Today 9 (2017) 341–349.

[32] J. Ye, S. A. Khairallah, A. M. Rubenchik, M. F. Crumb, G. Guss, J. Belak,
M. J. Matthews, Energy coupling mechanisms and scaling behavior associated
with laser powder bed fusion additive manufacturing, Advanced Engineering
Materials 21 (7) (2019) 1900185.

[33] P. Promoppatum, S.-C. Yao, P. C. Pistorius, A. D. Rollett, A comprehensive
comparison of the analytical and numerical prediction of the thermal history
and solidiﬁcation microstructure of inconel 718 products made by laser powder-
bed fusion, Engineering 3 (5) (2017) 685–694.

[34] D. P. Kingma, J. Ba, Adam: A method for stochastic optimization, arXiv

preprint arXiv:1412.6980 (2014).

[35] J.-B. Forien, N. P. Calta, P. J. DePond, G. M. Guss, T. T. Roehling, M. J.
Matthews, Detecting keyhole pore defects and monitoring process signatures

29

during laser powder bed fusion: A correlation between in situ pyrometry and ex
situ x-ray radiography, Additive Manufacturing 35 (2020) 101336.

[36] R. Cunningham, C. Zhao, N. Parab, C. Kantzos, J. Pauza, K. Fezzaa, T. Sun,
A. D. Rollett, Keyhole threshold and morphology in laser melting revealed by
ultrahigh-speed x-ray imaging, Science 363 (6429) (2019) 849–852.

30

