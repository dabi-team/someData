GPSAF: A Generalized Probabilistic
Surrogate-Assisted Framework for Constrained
Single- and Multi-objective Optimization

Julian Blank, Student Member, IEEE and Kalyanmoy Deb, Fellow, IEEE

1

2
2
0
2

r
p
A
6

]

C
O
.
h
t
a
m

[

1
v
4
5
0
4
0
.
4
0
2
2
:
v
i
X
r
a

Abstract‚ÄîSigniÔ¨Åcant effort has been made to solve computa-
tionally expensive optimization problems in the past two decades,
and various optimization methods incorporating surrogates into
optimization have been proposed. Most research focuses on either
exploiting the surrogate by deÔ¨Åning a utility optimization prob-
lem or customizing an existing optimization method to use one or
multiple approximation models. However, only a little attention
has been paid to generic concepts applicable to different types
of algorithms and optimization problems simultaneously. Thus
this paper proposes a generalized probabilistic surrogate-assisted
framework (GPSAF), applicable to a broad category of uncon-
strained and constrained, single- and multi-objective optimization
algorithms. The idea is based on a surrogate assisting an existing
optimization method. The assistance is based on two distinct
phases, one facilitating exploration and another exploiting the
surrogates. The exploration and exploitation of surrogates are
automatically balanced by performing a probabilistic knockout
tournament among different clusters of solutions. A study of
multiple well-known population-based optimization algorithms
is conducted with and without the proposed surrogate assistance
on single- and multi-objective optimization problems with a
maximum solution evaluation budget of 300 or less. The results
indicate the effectiveness of applying GPSAF to an optimization
algorithm and the competitiveness with other surrogate-assisted
algorithms.

Index Terms‚ÄîSurrogate-Assisted Optimization, Model-based
Optimization, Simulation Optimization, Evolutionary Comput-
ing, Genetic Algorithms.

I. INTRODUCTION

M ANY optimization problems are computationally ex-

pensive and require the execution of one or multiple
time-consuming objective and constraint functions to evalu-
ate a solution. Expensive optimization problems (EOPs) are
especially important in practice and are omnipresent in all
kinds of research and application areas, for instance, Agri-
culture [1], Engineering [2], Health Care [3], or Computer
Science [4]. Often the expensive solution evaluations (ESEs)
are caused by running a simulation, such as Computational
Fluid Dynamic [5], Finite Element Analysis [6], or processing
a large amount of data [7], [8]. Most of such these simulation-
based or data-intensive ESEs are black-box in nature [9]
and no gradient information is available or even more time-
consuming to derive. Thus, the optimization method must be
designed for a signiÔ¨Åcantly limited evaluation budget without
any assumptions about the problem‚Äôs Ô¨Åtness landscape.

Julian Blank and Kalyanmoy Deb are at Michigan State University, East

Lansing, USA (email: {blankjul,kdeb}@msu.edu).

The majority of methods proposed for solving EOPs in-
corporate so-called surrogate models (or metamodels) [10]
into the optimization procedure. The surrogate model provides
an approximate solution evaluation (ASE) with less computa-
tional expense to improve the convergence behavior. A well-
known research direction with the signiÔ¨Åcant effort being made
in the past is referred to as ‚ÄùEfÔ¨Åcient Global Optimization‚Äù
(EGO) [11]. In EGO, solutions are evaluated in each iteration
based on the optimum of a utility optimization problem ‚Äì
also known as inÔ¨Åll criterion ‚Äì commonly deÔ¨Åned by the
surrogate‚Äôs value and error predictions from Kriging [12]. The
method can be summarized as a Ô¨Åt-deÔ¨Åne-optimize procedure:
A surrogate model is Ô¨Åtted, a utility problem based on the
surrogate predictions is deÔ¨Åned, and then optimized to obtain
an inÔ¨Åll solution. Original limitations such as the evaluation
of a single point per iteration, the lack of constraint handling,
or dealing with multiple objectives have been investigated,
and extensions have been proposed [13], [14]. Nevertheless,
adding such additional requirements further complicates the
utility problem and makes it signiÔ¨Åcantly more challenging.
The surrogate‚Äôs role in such Ô¨Åt-deÔ¨Åne-optimize methods is
critical because of the direct dependency on the inÔ¨Åll criteria
deÔ¨Åned based on approximations and error predictions.

Another research direction pursued by researchers is the
organic incorporation of surrogates into an existing optimiza-
tion [15]. Such approaches aim to improve the convergence
behavior of a ‚Äúbaseline‚Äù algorithm and, thus, the anytime
performance. Researchers have explored different ways of
incorporating surrogates into well-known population-based
algorithms, such as genetic algorithms (GA) [16], differ-
ential evolution (DE) [17], or particle swarm optimization
(PSO) [18]. All surrogate-assisted algorithms must Ô¨Ånd a
reasonable trade-off between exploiting the knowledge of the
surrogate and still exploring the search space. On the one hand,
researchers have investigated methods adding a surrogate with
lighter inÔ¨Çuence on the original algorithm, for instance, using
surrogate-based pre-selection in evolutionary strategy [19] or
a predictor for the individual replacement in DE [20]. On
the other hand, the behavior of an existing algorithm might
almost entirely rely on the surrogate predictions and guide the
search signiÔ¨Åcantly. For instance, a global and local surrogate
have been incorporated into PSO to solve expensive large-
scale optimization problems [21] or into DE for expensive
constrained optimization problems [22]. The existence of nu-
merous variants of surrogate-assisted algorithms indicates that
many different ways of using surrogates during optimization

 
 
 
 
 
 
2

surrogate-assisted methods, we are using the search pat-
tern of the search of an algorithm on the surrogate instead
of only using Ô¨Ånal solutions. The prediction error of the
surrogates and the search space exploration is addressed
using a probabilistic knockout tournament selection. The
surrogate prediction error is incorporated into the tour-
nament selection and reliably balances the exploitation-
exploration trade-off based on the surrogate‚Äôs accuracy.
In the remainder of this paper, we Ô¨Årst discuss related
work of surrogate-assisted optimization and its challenges
in Section II before proposing the generalized probabilistic
surrogate-assisted framework (GPSAF) in Section III. A com-
parison of GPSAF and other state-of-the-art surrogate-based
methods is provided in Section IV. Finally, conclusions are
drawn, and future work is presented in Section V.

II. BACKGROUND

In this section, the brief overview of methods in the previous
section shall be enriched with details, and surrogate-assisted
algorithms are categorized regarding their surrogate incorpo-
ration.

Surrogate-assisted methods can be roughly put into one of
the following categories based on the surrogate‚Äôs involvement:
aided, customized, centered, or once (see Figure 2). The latter
describes the early development of optimization using an ap-
proximation model, Ô¨Åtted exactly once during optimization and
never updated (once). Algorithms that perform an update of
the surrogate can mostly depend on its predictions (centered)
or use it as an assistant in an existing method to improve
the convergence behavior (aided, customized). The surrogate‚Äôs
role and dependency on the algorithm‚Äôs design are vital for
generalization and, thus, shall be spent special attention to.
Next, a thematic overview of these different types of surrogate
involvements in an algorithm is given.

Especially in the early phase of surrogate-based optimiza-
tion, the surrogate was Ô¨Åtted only once and optimized. Thus,
the optimization‚Äôs outcome entirely depends on the accuracy
of the surrogate model, assuming an efÔ¨Åcient optimizer is used
to obtain the surrogate‚Äôs optimum.

The limitation of Ô¨Åtting a surrogate only once has soon
been overcome by a more adaptive approach known as EGO
(EfÔ¨Åcient Global Optimization) [11]. Kriging [12] is used as
a surrogate and provides predictions as well as a measure
of uncertainty for each point. The prediction and uncertainty
together deÔ¨Åne the so-called acquisition function (or inÔ¨Åll

TABLE I
CATEGORIZATION REGARDING THE SURROGATE‚ÄôS ROLE IN AN
OPTIMIZATION ALGORITHM.

Category

Algorithm / Study

Aided
Customized MOEAD-EGO [26], K-RVEA [27], HSMEA [28],

MAES [19], SVC-DE [20]

Centered

Just Once

CSEA [29], PAL-SAPSO [30], CAL-SAPSO [31]
EGO [11], ParEGO [14], SMS-EGO [32], Max-
Min SAEA [33], SACOBRA [34], SABLA [35], GS-
MOMA [24], GSGA [25], MISO [36], GOSAC [37]
[38], [39], [40]

Fig. 1. Robustly Adding Surrogate-Assistance to Population-Based Algo-
rithms (Illustration inspired from [16]).

method exist, but also that no best practice procedure has been
established yet [23].

The need for more generalizable concepts in surrogate-
assisted optimization has been identiÔ¨Åed, and frameworks
aiming to solve a broader category of optimization problems
have been proposed [24], [25]. Existing frameworks provide
a generic method for different problems types using the Ô¨Åt-
deÔ¨Åne-optimize strategy or by replacing locally optimized
solutions (on ASEs) before their computationally expensive
evaluation. One shortcoming of existing frameworks for solv-
ing EOPs is their design being primarily algorithm-dependent
and their limitations to transferring it to different optimiza-
tion methods. Thus, this matter shall be addressed in this
paper by proposing a novel generalized probabilistic surrogate-
assisted framework (GPSAF), adding surrogate assistance to
population-based algorithms. In contrast to other surrogate-
assisted algorithms that customize a speciÔ¨Åc algorithm, our
goal is to provide a scheme to add surrogate assistance to
a whole algorithm class. Figure 1 ‚Äì inspired from [16] ‚Äì
shows different problem types on the x and the efÔ¨Åciency of
algorithms on the y-axis. Whereas speciÔ¨Åc algorithms can be
customized and thus be a specialist for a speciÔ¨Åc problem type,
this study considers algorithms that can solve a broad category
of problem types and adds surrogate assistance to them. Even
though specialized surrogate-assisted algorithms are likely to
outperform a generic concept on a speciÔ¨Åc problem type,
the merit of this study is its broad applicability. The main
contributions of this paper can be summarized as follows:

(i) We provide a categorization of existing surrogate-assisted
algorithms regarding their surrogate usage. Methods are
distinguished based on their surrogate‚Äôs impact and im-
portance during optimization and identify what has been
less attention paid to in the past.

(ii) We propose a framework that applies to all kinds of
population-based optimization algorithms. The frame-
work enables existing optimization methods designed for
unconstrained or constrained, single or multi-objective
optimization to become assisted by a surrogate. Intu-
itive hyper-parameters can control the surrogate‚Äôs impact.
A speciÔ¨Åc setting to even disable the surrogate usage
entirely exists, which demonstrates the truly surrogate
assistant behavior.

(iii) We propose a novel way of dealing with surrogate
prediction error algorithmically. In contrast to existing

Problem TypeEfficiency/ComputationRobustSpecializedSpecialized With SurrogateRobust With Surrogate3

Fig. 2. Different Roles of Surrogates in the Design of an Algorithm.

criterion), such as the expected improvement [11] or prob-
ability of improvement [41] aiming to balance exploitation
and exploration simultaneously. The optimization of the ac-
quisition function results in an inÔ¨Åll solution, which is Ô¨Årst
evaluated and then added to the model. The procedure is
repeated until a termination criterion is met. The limitation of
Ô¨Ånding only a single new solution in each iteration has been
investigated thoroughly, and multi-point EGO approaches have
been proposed [42], [43], [44]. Moreover, the concept has been
generalized to solve multi-objective optimization problems by
using decomposition [14], [26] or replacing the objective with
a performance indicator based metric [32]. The idea has also
been extended to handle constraints, which is especially impor-
tant for solving real-world optimization problems [45]. Instead
of using acquisition functions to address the surrogate‚Äôs uncer-
tainty, algorithms based on trust regions have been proposed.
Inevitable, updating the trust-region radii becomes vital for
the algorithm‚Äôs performance [46]. Whereas original studies
were limited to unconstrained single-objective optimization,
the surrogate-assisted trust-region concept has been general-
ized to constrained and also multi-objective optimization [24],
[25]. Apart from the approaches discussed above, the direct
usage of surrogates in an algorithm has been explored in
various areas, for instance, bi-level optimization [33], [35] or
mixed-integer optimization [36]. All these approaches have in
common that the algorithm has been designed with a strong
the surrogate‚Äôs
dependency on the surrogate model. Thus,
suitability and accuracy are critical for the optimization‚Äôs
success. Inaccurate surrogate predictions and error estimations,
inevitably occurring in large-scale optimization problems, are
known to be problematic [23].

In contrast

to algorithms being designed based on sur-
rogates, researchers have investigated surrogates‚Äô incorpora-
tion into existing optimization methods. Such approaches are
also known as surrogate-assisted algorithms, emphasizing the
surrogate‚Äôs role as an assistant during optimization. In our
categorization, surrogate-assisted algorithms are split up into
two categories. On the one hand, algorithms can be aided by a
surrogate where only minor changes of the original algorithm
design are made; on the other hand, surrogate-customized
methods where the algorithm has a signiÔ¨Åcant
impact on
the algorithm‚Äôs design. Because the judgment of impact is
subjective, the transition between both categories is somewhat
Ô¨Çuent.

The beneÔ¨Åt of surrogate-aided algorithms is that with rela-
tively minor modiÔ¨Åcations, a surrogate has been incorporated,
and the performance has been improved [10]. One well-known
approach is a pre-selection (or pre-Ô¨Åltering) which uses a
surrogate to select a subset of solutions that usually would be
evaluated on the EOP [19]. Moreover, instead of changing the
behavior in a generation, surrogates have also been used across
generations by switching between the expensive evaluation
and surrogate predictions entirely for some iterations [15],
[47]. Another example for a surrogate-inÔ¨Çuenced algorithm is
modifying a memetic algorithm (genetic algorithm with local
search) by executing the usually evaluation-intensive local
search on the surrogate [48].

Besides surrogate-assisted methods with relatively minor
modiÔ¨Åcations of existing algorithms, optimization methods can
be customized to incorporate surrogate usage. This let arise
surrogate-assisted variants of well-known algorithms, such as
lqCMAES [49] derived from CMAES [50], KRVEA [27] and
HSMEA [28] based on RVEA [51], MOEAD-EGO [26] as
an improvement of MOEAD [52], or CAL-PSO [31] based
on PSO [18] to name a few. Each surrogate-assisted variant
is in principle based on an algorithm originally developed for
computationally more inexpensive optimization problems but
customizes the default behavior, for instance, by one or mul-
tiple local or global surrogates, implementing a sophisticated
selection after surrogate-based optimization.

The increasing number of surrogate-assisted algorithms
shows its importance and relevance in practice. Indisputably,
approaches and ideas directly designed for and centered on one
or multiple surrogates have their legitimacy but are somewhat
tricky to use for newly proposed algorithms. The existence of
many different surrogate-based algorithms also indicates the
absence of a best practice procedure and the need for more
generic methods. Thus, this study shall address this research
gap and propose a surrogate-assisted framework of algorithms
applicable to a broad category of optimization methods.

III. METHODOLOGY

One of the major challenges when proposing a generalized
optimization framework is the number and strictness of as-
sumptions being made. On the one hand, too many assump-
tions restrict the applicability; on the other hand, too few
assumptions limit the usage of existing elements in algorithms.
In this study, we target any type of population-based algorithm

Surrogate-CenteredJust Once / Not AdaptiveSurrogate-CustomizedA surrogate is part of the algorithm's design and serves as an assistant to improve the algorithm's convergence.Surrogate-AidedAn algorithm retrieves some aid from a surrogate, which plays only a minor role in the algorithm's design.The surrogate is a substantial component of the algorithm and its design. Without any surrogate, the algorithm can not be executed.The surrogate is fitted exactly once and then optimized. Thus, the performance strongly depends on the surrogate's prediction error.Surrogate-BasedSurrogate-AssistedAlgorithm 1: InÔ¨Åll-And-Advance Interface

Input : Algorithm Œ¶

1 while Œ¶ has not terminated do
2

X ‚Üê Œ¶.infill()
F, G ‚Üê evaluate(X)
Œ¶.advance(X, F, G)

3

4
5 end

with two phases in an iteration: the process of generating
new solutions to be evaluated (inÔ¨Åll) and a method processing
evaluated inÔ¨Åll solutions (advance). With these two methods,
running an algorithm can be summarized by the pseudo-
code shown in Algorithm 1. Until the algorithm Œ¶ has been
terminated, the inÔ¨Åll method returns a set of new designs X to
be evaluated. After obtaining the objective F and constraint G
values for design, the algorithm is advanced by providing the
evaluated solutions {X, F , G}. By looking at this interface,
we further make two (weak) assumptions. First, we do not
assume that X needs to be identical with the suggested designs
from inÔ¨Åll (Line 2 and 4), but can also be modiÔ¨Åed. Second, the
inÔ¨Åll method is non-deterministic, resulting in different designs
X whenever called. Both assumptions can be considered weak
because most population-based algorithms already fulÔ¨Åll them.
So, how can existing optimization methods be described into
inÔ¨Åll and advance phases? Genetic algorithms (GAs) generate
new solutions using evolutionary recombination-mutation op-
erators and then process them using an environmental survival
selection [16] operator; PSO methods create new solutions
based on a particles‚Äô current velocity, personal best, and
global best, and process the solutions using a replacement
strategy [18]; CMAES samples new solutions from a normal
distribution, which is then updated in each iteration [50].
Shown by well-known state-of-the-art algorithms following or
being suitable to be implemented in this optimization method
design pattern, this seems to be a reasonable assumption to be
made for a generic framework. Moreover, it is worth noting
that some researchers and practitioners also refer to the pattern
as ask-and-tell interface.
However, how shall

this interface now be utilized, and
what role can surrogates play in improving the algorithm‚Äôs
performance? Precisely this is the subject of this article.
Nevertheless, before moving on to the proposed framework,
some more speciÔ¨Åcations of the surrogate usage are to be
deÔ¨Åned: First, the surrogate shall only be used as an assistant
(in contrast to other methods where everything is developed
centered around the surrogate). Second, the proposed method
should be adaptive, allowing to decrease and increase the
impact of surrogate usage and, if desired, even falling back
to the original pseudo-code shown in Algorithm 1. Third, the
surrogate prediction error needs to be addressed to ensure both
exploitation and exploration. Altogether, the design goals are
formulated to make the optimization framework and surrogate
incorporation Ô¨Çexible. The proposed Generalized Probabilistic
Surrogate-Assisted Framework (GPSAF) meets these goals
by introducing two different phases: First, the Œ±-phase using
the current state of algorithm Œ¶ introducing some surrogate
inÔ¨Çuence. This pre-Ô¨Åltering phase uses a replacement strategy

4

*/

*/

*/

*/

*/

Algorithm 2: GPSAF: Generalized Probablistic Surrogate-
Assisted Framework

Input : Algorithm Œ¶, Surrogate Tournament Pressure Œ±
(‚â• 1), Number of Simulated Iterations Œ≤ (‚â• 0),
Replacement Probability Exponent Œ≥, Maximum
Number of Solution Evaluations SE(max)
/* Sample Design of Experiments (DOE)

1 A ‚Üê ‚àÖ; P ‚Üê ‚àÖ; Q ‚Üê ‚àÖ; U ‚Üê ‚àÖ; e ‚Üê ‚àÖ
2 A.X ‚Üê doe();
3 while size(A) < SE(max) do

A.F, A.G ‚Üê evaluate(A.X)

/* Infill sols. from baseline algorithm
P.X ‚Üê Œ¶.infill()
/* Estimate error - only initially
if e = ‚àÖ then e ‚Üê estm error(A.X, A.F, A.G);
/* Surrogates for each obj. and constr.
S ‚Üê fit(A.X, A.F, A.G)
P.^F, P.^G ‚Üê S.predict(P.X)
/* Surrogate Influence (Œ±)
foreach k ‚Üê 2 to Œ± do
Q.X ‚Üê Œ¶.infill()
Q.^F, Q.^G ‚Üê S.predict(Q.X)
foreach j ‚Üê 1 to size(Q) do

if not dominates(P[j], Q[j]) then P[j] = Q[j] ;

end

end
/* Surrogate Bias (Œ≤)
Œ¶(cid:48) ‚Üê copy(Œ¶)
U ‚Üê ‚àÖ
foreach k ‚Üê 1 to Œ≤ do

Q.k ‚Üê k
Q.X ‚Üê Œ¶(cid:48).infill()
Q.^F, Q.^G ‚Üê S.predict(Q.X)
foreach j ‚Üê 1 to size(Q) do
i ‚Üê closest(P.X, Q[j].X)
U[i] ‚Üê U[i] ‚à™ Q[j]

end
Œ¶(cid:48).advance(Q.X, Q.^F, Q.^G)

end
V ‚Üê list()
foreach j ‚Üê 1 to size(U) do

V ‚Üê V ‚à™ prob knockout tourn(U[j])

end
/* Replacement (Œ≥)
foreach j ‚Üê 1 to size(P) do
œÅ ‚Üê repl prob(U[j], U, Œ≥)
if rand() < œÅ then P[j] ‚Üê V[j]) ;

end
/* Evaluate on ESE
P.F, P.G ‚Üê evaluate(P.X)
/* Prepare next iteration of GPSAF
Œ¶.advance(P.X, P.F, P.G)
e ‚Üê update error(P.F, P.G, P.^F, P.^G)
A ‚Üê A ‚à™ P

*/

*/

*/

*/

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38
39 end

based on surrogate predictions; second, the Œ≤-phase continues
to run algorithm Œ¶ for multiple consecutive iterations on the
surrogate resulting in a (convergence) search pattern. From
the search pattern, solutions are selected by applying a prob-
abilistic knockout tournament. The tournament incorporates
the distribution of historical prediction errors by comparing
solutions under noise to address the surrogate inaccuracies.

The two phases and their control parameter allow conÔ¨Åguring
the surrogate usage, and the probabilistic knockout tournament
serves as a self-adaptive mechanism to balance its exploitation
and exploration.

A. Generalized Probabilistic Surrogate-Assisted Framework

Before describing the responsibilities and details of each
of the phases, the outline of the algorithm shall be discussed
(see Algorithm 2). Before any surrogate can be Ô¨Åt, a solution
archive A is initialized by some design of experiments A.X are
generated in a space-Ô¨Ålling manner. A good spread of solutions
is recommended to allow surrogates to capture the overall
Ô¨Åtness landscape as accurately as possible. A.X is evaluated on
the expensive solution evaluation (ESE) resulting in A.F and
A.G (Line 2). Then, while the number of evaluations is less
than the maximum solution evaluation budget SE(max), inÔ¨Åll
solutions P.X are generated by calling the non-deterministic
inÔ¨Åll method of the baseline algorithm Œ¶. The default execu-
tion of algorithm Œ¶ would immediately evaluate P.X using
ESE and directly feed the solutions back to the algorithm
by executing Œ¶.advance(P.X, P.F, P.G) (Line 35 and 36).
However, instead of doing so, GPSAF modiÔ¨Åes P.X in a way
to be inÔ¨Çuenced and biased by surrogates (Line 6 to 30) and
advances the algorithm in the end of the iteration (Line 35
to 36). After having estimated the surrogate error and Ô¨Åtted the
surrogates for objective and constraint functions, the Œ±-phase
adds surrogate inÔ¨Çuence to P.X by replacing solutions being
predicted to be better (Line 8 to 14). Thereafter, the Œ≤-phase
runs algorithm Œ¶ for multiple generations (evaluations only
on ASE) and assigns each solution to its closest P.X. For each
of the resulting candidate solution pools U[j] assigned P[j]
a probabilistic tournament determines the winning candidate
(Line 15 to 30). Afterward, the replacement phase takes place
where either the solution originating from the Œ±-phase P[j] is
kept or replaced with U[j] from the Œ≤-phase (Line 31 to 34).
The solutions set to P.X are evaluated, and the algorithm Œ¶
is advanced (Line 35 and 36). Finally, the prediction error
is updated before starting the next iteration, and the newly
evaluated solutions are added to archive A.

The overall outline of GPSAF shall provide an idea of where
and when the Œ± and Œ≤ phases take place and what role they
play in modifying the inÔ¨Åll solutions fed back to the algorithm.
Next, each phase shall be explained and discussed in detail.

B. Surrogate InÔ¨Çuence through Tournament Pressure (Œ±)

The Ô¨Årst mechanism of GPSAF incorporates tournament
pressure by utilizing the predictions of a surrogate as a referee.
Tournament pressure is a well-known concept in evolutionary
computation to introduce a bias towards more promising
solutions [53]. Usually, its purpose is to introduce selection
bias during mating to increase the chances of involvement of
better-performing individuals. A speciÔ¨Åcally helpful control
parameter is the number of competitors in each tournament to
naturally increase or decrease the selection pressure.

Here, we borrow the tournament pressure mechanism to
provide solutions with surrogate inÔ¨Çuence before their eval-
uation on the EOP. The surrogate predictions provide the

5

Fig. 3. Tournament selection with Œ± competitors to create a surrogate-
inÔ¨Çuenced inÔ¨Åll solutions.

necessary ASEs to determine the winner of each tournament.
The number of competitors Œ± in each tournament can control
the amount of surrogate inÔ¨Çuence. In Figure 3 the surrogate-
assisted tournament selection with three competitors (Œ± = 3)
for four inÔ¨Åll solutions (n = 4) is visualized. Initially, the
algorithm‚Äôs inÔ¨Åll function is called three times to generate the
solution sets X Œ±1, X Œ±2 , and X Œ±3. After evaluating each of
the solution sets on the surrogate, a tournament takes place
where Œ± solutions of the j-th inÔ¨Åll solution set X Œ±j compete
with each other. For instance, for the Ô¨Årst tournament, the
winner of X Œ±1
is declared. The winner of
3
each solution pool is determined as follows: if all solutions
are infeasible, select the least infeasible solution; otherwise,
select a non-dominated solution (break ties randomly). For
both the constraint and objective values, only ASEs are used.
By repeating the tournament n times and declaring the winners
Xi where i ‚àà (1, . . . , n), here X1, X2, X3, and X4, four
surrogate-inÔ¨Çuenced solutions have been selected and the Œ±-
phase is completed.

2 , and X Œ±1

1 , X Œ±1

It is worth noting that because the inÔ¨Åll method calls of al-
gorithm Œ¶ is non-deterministic and do not have any order, this
can be implemented memory-friendly by a for loop as shown
in Algorithm 2 (see Line 8 to 14). Generally, it shall also
become apparent that setting Œ± = 1 disables the tournament
selection and serves as a fallback to the original algorithm. By
involving the surrogate in the tournament selection (Œ± > 1),
the inÔ¨Åll solutions P get a smaller or larger inÔ¨Çuence based on
the number of competitors, which provides a natural inclusion
of surrogate guidance.

C. Continue Optimization on Surrogate (Œ≤)

After completing the Œ±-phase, the solution set P is already
inÔ¨Çuenced by surrogates. But what are the limitations of the
Œ±-phase, and why is there a necessity for a second one? Even
though the inÔ¨Åll method is called multiple times, the algorithm

ùú∂=ùüë#infills = 4ùëã!"!ùëã#"!ùëã$"!ùëã%"!ùëã!""ùëã#""ùëã$""ùëã%""ùëã!"#ùëã#"#ùëã$"#ùëã%"#ùëã#"!ùëã$"!ùëã!""ùëã%""****Tournament Selection "ùêπ&"$Winnersùëã!ùëã#ùëã$ùëã%Algorithm 3: Probabilistic Knockout Tournament (PKT)
Input : Solution Set C, Prediction errors e, Number of

winners k

6

1 C (1) ‚Üê shuffle(C)
2 t ‚Üê 1
3 while |C (t)| > k do
4

5

6

7

8

9

end
t ‚Üê t + 1

10
11 end
12 if |C (t)| < k then
13
14 end
15 return C (t)

if |C (t)| is odd then C (t) ‚Üê C (t) ‚à™ rselect(C(t), 1);
C (t+1) ‚Üê ‚àÖ
foreach i ‚Üê 1 to |C (t)|/2 do
w ‚Üê compare noisy(C(t)
C (t+1) ‚Üê C (t+1) ‚à™ w

2i , C(t)

2i+1, e)

C (t) ‚Üê C (t) ‚à™ rselect(C(t‚àí1) \ C(t), |C(t)| ‚àí k)

is never advanced to the next iteration. Thus, it provides a one
step look-ahead, which is not sufÔ¨Åcient to Ô¨Ånd near-optimal
solutions on the surrogate (which to some degree can be very
useful for convergence). So, to further increase the surrogate‚Äôs
impact, the second phase looks Œ≤ iterations into the future by
calling inÔ¨Åll and advance of the baseline algorithm repetitively.
Whereas for a smaller Œ≤, the surrogates will be somewhat
exploited, for a larger Œ≤, near-optimal solutions using ASEs
will be found (similarly to optimizing the surrogate directly).
However, it must be considered that ASEs have an underlying
prediction error and can not be taken for granted. In GPSAF,
the error is addressed by making not only use of the Ô¨Ånal
solution set resulting from the Œ≤ optimization runs but using
the whole search pattern. The pattern is Ô¨Årst divided into
multiple clusters by assigning all solutions to their closest
solution (in the design space) to each solution in P.X. Then,
we use a so-called probabilistic knockout tournament (PKT)
to select solutions from each cluster with the goal of self-
adaptively exploiting surrogates. The goal is to use surrogates
more when they provide accurate predictions but use them
more carefully when they provide only rough estimations.
Necessary for generalization, PKT also applies to problems
with multiple objectives and constraints, often with varying
complexities and surrogate errors to be considered.

Generally, we deÔ¨Åne PKT as a subset selection of k
solutions from a set of solutions C by applying pairwise
comparisons under noise as shown in Algorithm 3. Initially,
the solution set C to select from is shufÔ¨Çed to randomize the
matches (Line 1). If the current number of participants |C (t)| is
odd, a random solution is chosen to compete twice (Line 4).
Each competition occurs under noise, based on the current
prediction error of the surrogates. The noise is added to each
objective and constraint independently before comparing the
solutions. After adding the noise, the comparison is identical
to the subset selection explained in Section III-B (feasibility,
dominance, random tie break) with two competitors (Œ± = 2).
The winner of each round moves on to the next and is added
to C (t+1) (Line 8). Finally, if too many solutions have been
eliminated, randomly choose some losers from the last round

Fig. 4. Continue Running the Algorithm for Œ≤ Iteration on the Surrogate.

(Line 13). This results in a set of solutions of size k being
returned as tournament winners under noise. The design of
PKT applies to the most general case of constrained multi-
objective optimization because the selection procedure can be
reduced two a comparison of two solutions.

Back to the cluster-wise selection in the Œ≤-phase where PKT
is executed with k = 1 to obtain a winner for each solution
set Uj. An example with Ô¨Åve iterations (Œ≤ = 5) and four inÔ¨Åll
solutions X1, X2, X3, and X4 is illustrated in Figure 4. Calling
the inÔ¨Åll and advance function of the baseline algorithm results
in Ô¨Åve solution sets (Œ≤1 to Œ≤5) with four solutions each. The
advancement of multiple iterations is based on ASEs. In each
iteration, all solutions are directly assigned to the closest Xi
solution from the Œ±-phase forming the cluster Ui. The cluster
search pattern division is essential to preserve diversity. For
each cluster, a winner Vi is declared by performing the PKT.
For instance, in this example, X1 has four solutions in U1
where one from the fourth iteration Œ≤4 is Ô¨Ånally selected. At
the end of the Œ≤-phase, each cluster Ui has at most one solution
Vi to be assigned to (some clusters may stay empty because
no solutions are assigned to it).

The Œ≤-phase exploits the surrogates signiÔ¨Åcantly more
than the Œ±-phase by optimizing multiple iterations on the
surrogates. In addition, mechanisms such as cluster-based
search pattern selection help preserve diversity. Finally, it is
worth noting that, analogously to the Œ±-phase, the surrogate
assistance can be disabled by setting a speciÔ¨Åc conÔ¨Åguration
(Œ≤ = 0). Thus, GPSAF provides a fallback mechanism to
the baseline optimization method without surrogate assistance
(when Œ± = 1 and Œ≤ = 0). Increasing one or the other will
add more and more guidance through surrogate models. How
the two phases, each resulting in a set of solutions, are now
combined to Ô¨Ånd a trade-off between the more explorative Ô¨Årst
and more exploiting second phase shall be discussed next.

ùë•#ùë•!ùëã!ùëã"ùëã#ùëã$ùëã!%!ùëã"%!ùëã#%!ùëã$%!ùõΩ%ùëã!%"ùëã"%"ùëã#%"ùëã$%"ùõΩ&ùëã!%#ùëã"%#ùëã#%#ùëã$%#ùõΩ‚Äôùëã!%$ùëã"%$ùëã#%$ùëã$%$ùõΩ(ùëã!%%ùëã"%%ùëã#%%ùëã$%%ùõΩ)ùú∑=ùüìùë•#PKT for each ùëã!ùëãùëã!ùëã#ùëã$ùëã%ùëã!ùê∂‚Äôùê∂‚Äôùëã%D. Balancing the Exploration and Exploitation (Œ≥)

The Œ± and Œ≤ phases are designed to add surrogate assistance
to an algorithm. The Œ≤ phase utilizes the search pattern
on the surrogate and assigns solutions from the Œ±-phase.
This means one can now choose to either stick to the more
explorative Œ± or exploit
the Œ≤ solution. The most simple
way of making this choice is by replacing the solution with
probability œÅ. However, in a pilot study addressing single-
objective optimization, it has been shown that a more dynamic
selection strategy is beneÔ¨Åcial [54].

A piece of particularly useful information for making this
decision is the distribution of assigned solutions across clus-
ters. The search pattern derived from surrogates with a high-
density area indicates a region of interest. Thus, we propose
to set the replacement probability:
(cid:18) |Uj|

(cid:19)Œ≥

(1)

œÅ =

maxj |Uj|

The denominator maxj |Uj| normalizes the number of as-
signed points with respect to the points in the current cluster
|Uj|. The exponent Œ≥ can be used to control the importance of
the distribution and was kept constant at Œ≥ = 0.5. The cluster
with the highest density is always chosen from the Œ≤-phase
because the nominator and denominator will be equal. This
will necessarily be the case for baseline algorithms returning
only one inÔ¨Åll solution where a stronger surrogate bias is
desirable. After the replacement, the solutions will Ô¨Ånally be
sent to the time-consuming solution evaluation.

E. Surrogate Management

Besides using surrogates in an algorithmic framework, some
more words need to be said about the models themselves.
First, one shall note that only the predictions of data points
need to be provided by surrogates and no additional error
track of by our
estimation (the error estimates are kept
method directly). Not requiring an error estimation does not
limit the models to a speciÔ¨Åc type, unlike other surrogate-
based algorithms. Second, each of the objective and constraint
functions is modeled independently, known as M1 in the
surrogate usage taxonomy in [55]. Even though modeling all
functions increases the algorithmic overhead, it prevents larger
prediction errors through complexity aggregations of multiple
functions. Third, a generic framework for optimizing com-
putationally expensive functions requires a generic surrogate
model implementation. Clearly, some model types are more
suitable for some problems than others. Thus, to provide a
more robust framework, each function is approximated with
a set of surrogates, and the best one is Ô¨Ånally chosen to be
used. The surrogate types in this paper consist of the model
types RBF [56] and Kriging [12], both initialized with different
hyper-parameters (normalization, regressions, kernel). A pre-
normalization step referred to as PLOG [34] is attempted
and selected if well-performing for constraint functions. Two
metrics assess the performance of a model: First, Kendall
Tau Distance [57] comparing the ranking of solutions being
less sensitive to outliers with a large prediction error; second,
the Maximum Absolute Error (MAE) to break any ties. The

7

value of MAE is also used as an error approximation when
noise is added to individuals. The error estimation in the Ô¨Årst
iteration is based on k-fold cross-validation (k = 5) to get
a rough estimate of how well a surrogate can capture the
function type. The performance metrics are updated in each
iteration by taking all solutions seen so far as training and
the newly evaluated solutions as a test set. Finally, a moving
average of Ô¨Åve iterations to avoid a smooth and more robust
estimation provides the data for selecting the best surrogate
and estimating the prediction error for each objective and
constraint.

IV. EXPERIMENTAL RESULTS

In this section, we present

the performance of GPSAF
applied to various population-based algorithms solving un-
constrained and constrained, single- and multi-objective op-
timization problems. Proposing an optimization framework
requires comparing a group of algorithms, which is not a
trivial task itself. Benchmarking is further complicated when
non-deterministic algorithms are compared, in which case not
only a single but multiple runs need to be considered.

For a fair comparison of optimization methods across test
problems and to measure the impact of GPSAF on a baseline
algorithm, we use the following ranking-based procedure:

i. Statistical Domination: After collecting the data for each
test problem and algorithm (A ‚àà ‚Ñ¶) from multiple runs,
we perform a pairwise comparison of performance indica-
tors (PI) between all algorithms using the Wilcoxon Rank
Sum Test (Œ± = 0.05). The null-hypothesis H0 is that
no signiÔ¨Åcant difference exists, whereas the alternative
hypothesis is that the performance indicator of the Ô¨Årst
algorithm (PI(A)) is smaller than the one of the second
one (PI(B)) The PI is for single-objective optimization
the gap to the optimum (if known) or the best function
value found. For multi-objective optimization IGD [58]
(if optimum is known) or Hypervolume [59] is used.

œÜ(A, B) = RANKSUM(PI(B), PI(A), alt =(cid:48) less(cid:48)),
(2)
where the function œÜ(A, B) returns zero if the null
hypothesis is accepted or a one if it is rejected.

ii. Number of Dominations: The performance P (A) of
algorithm A is then determined by the number of methods
that are dominating it:

P (A) =

(cid:88)

B‚àà‚Ñ¶
A(cid:54)=B

œÜ(B, A)

(3)

This results in a domination number P (A) for each
method, which is zero if no other algorithm does not
outperform it.

iii. Ranking: Finally, we sort the methods by their P (A).
This may result in a partial ordering with multiple al-
gorithms with the same P (A) values. In order to keep
the overall sum of ranks equal, we assign their average
ranks in case of ties. For instance, let us assume Ô¨Åve
optimizations methods A, B, C, D, and E: algorithm A
outperforms all others; between the performances of B,

8

TABLE II
A COMPARISON OF DE, GA, PSO, AND CMAES WITH THEIR GPSAF VARIANTS ON UNCONSTRAINED SINGLE-OBJECTIVE PROBLEMS WITH FOUR
OTHER SURROGATE-ASSISTED ALGORITHMS. THE RANK OF THE BEST PERFORMING ALGORITHM IN EACH GROUP IS SHOWN IN BOLD. THE OVERALL
BEST PERFORMING ALGORITHM FOR EACH PROBLEM IS HIGHLIGHTED WITH A GRAY SHADE.

Problem

DE

GPSAF-
DE

f01
f02
f03
f04
f05
f06
f07
f08
f09
f10
f11
f12
f13
f14
f15
f16
f17
f18
f19
f20
f21
f22
f23
f24
Total

11.0
10.0
8.5
8.5
5.5
7.0
9.5
8.0
10.0
10.5
10.5
2.5
7.5
9.5
10.0
9.0
9.5
9.5
11.0
9.5
8.5
9.5
10.0
10.0
8.958

4.0
4.0
3.0
4.0
1.0
7.0
5.5
6.0
3.5
5.5
3.5
6.5
5.0
5.0
3.5
6.0
5.0
4.0
5.0
2.5
7.0
6.0
5.5
2.0
4.583

GA

7.5
4.0
5.0
4.0
7.5
2.0
5.5
8.0
8.0
5.5
7.0
6.5
7.5
7.5
6.5
6.0
7.0
6.0
10.0
7.0
3.5
6.0
5.5
8.0
6.292

GPSAF-
GA

2.5
1.0
1.5
2.0
3.0
2.0
2.0
2.0
3.5
1.5
1.5
6.5
2.5
2.0
1.5
2.0
3.0
2.0
1.0
2.5
3.5
2.5
1.5
2.0
2.292

PSO

5.5
4.0
7.0
4.0
5.5
4.5
5.5
5.0
3.5
5.5
7.0
2.5
5.0
5.0
6.5
9.0
7.0
6.0
5.0
2.5
3.5
6.0
5.5
4.0
5.188

GPSAF-
PSO

CMAES

GPSAF-
CMAES

SACOSO

SACC-
EAM-II

SADESammon

SAMSO

1.0
2.0
1.5
1.0
2.0
4.5
2.0
2.0
3.5
1.5
3.5
2.5
1.0
2.0
1.5
2.0
3.0
2.0
5.0
2.5
3.5
2.5
5.5
2.0
2.479

5.5
7.5
8.5
6.5
7.5
9.0
5.5
4.0
7.0
5.5
7.0
2.5
5.0
5.0
6.5
4.0
3.0
6.0
8.5
5.5
3.5
2.5
11.0
8.0
6.021

2.5
6.0
5.0
6.5
4.0
2.0
2.0
2.0
3.5
5.5
7.0
6.5
2.5
2.0
3.5
2.0
1.0
2.0
5.0
5.5
3.5
2.5
12.0
5.5
4.146

7.5
12.0
10.0
10.0
11.0
10.0
9.5
10.0
3.5
10.5
10.5
10.0
10.0
9.5
9.0
11.5
11.0
9.5
5.0
9.5
10.0
9.5
9.0
8.0
9.417

9.5
7.5
5.0
8.5
9.5
7.0
8.0
8.0
9.0
5.5
1.5
9.0
9.0
7.5
6.5
6.0
7.0
8.0
2.0
8.0
8.5
8.0
1.5
5.5
6.896

12.0
10.0
11.5
11.0
9.5
11.0
11.0
11.0
11.5
10.5
12.0
11.0
11.0
11.0
11.0
11.5
9.5
11.0
8.5
11.5
11.5
11.0
5.5
11.0
10.667

9.5
10.0
11.5
12.0
12.0
12.0
12.0
12.0
11.5
10.5
7.0
12.0
12.0
12.0
12.0
9.0
12.0
12.0
12.0
11.5
11.5
12.0
5.5
12.0
11.062

C, and D, no signiÔ¨Åcant difference exists; E performs the
worst. In this case, method A gets rank 1, the group of
methods B, C, and D, rank (2 + 3 + 4)/3 = 9/3 = 3,
and E rank 5. Averaging the ranks for ties penalizes an
optimization method for being dominated by the same
amount of algorithms as others and keeps the rank sum
for each problem the same.

This conveniently provides a ranking for each test problem.
To evaluate the performance of a method on a test suite, we
Ô¨Ånally average the ranks across problems. If an algorithm
fails to solve a speciÔ¨Åc problem for all runs,
it gets the
maximum rank and becomes the worst performing algorithm.
Otherwise, all failing runs will be ignored (this has only
rarely happened for a competitor algorithm to compare with).
The ranks shall be used to compare the performances of
methods in this manuscript, the values of the performance
indicators for the methods on all test problems can be found
in the Supplementary Document. Each algorithm has been
executed 11 times on each test problem. If not explicitly
mentioned in the speciÔ¨Åc experiment, the total number of
solution evaluations has been set to SE(max) = 300. For
some simpler constrained problems, even fewer evaluations
have been used. A relatively limited evaluation budget also
means that more complicated problems might not be solved
(near) optimally. However, a comparison of how well an
algorithm has performed shall imitate the situation researchers
face in practice. If the number of variables is not Ô¨Åxed, the
number of variables is Ô¨Åxed to 10. The results are presented in
ranking tables where the overall best performing algorithm(s)
are highlighted with a gray cell background for each ranking-

based comparison for a test problem. The best-performing ones
in a group are shown in bold.

Moreover, some more details about our implementation
shall be said. For the baseline algorithms, we use implemen-
tations of population-based algorithms available in the well-
known multi-objective optimization framework pymoo1 [60]
developed in Python. For all methods, the default parameters
provided by the framework are kept unmodiÔ¨Åed, except the
population size (=20) and the number of offsprings (=10) to
create a more greedy implementation of the methods. The
surrogate implementation of Kriging is based on a Python
clone2 of DACEFit [61] originally implemented in Matlab.
The RBF models are a re-implementation based on [34].
The hyper-parameters of GPSAF were determined through
numerous empirical experiments during the algorithm develop-
ment. A reasonable and well-performing conÔ¨Åguration given
by Œ± = 30, Œ≤ = 5, and Œ≥ = 0.5 is Ô¨Åxed throughout all
experiments.

A. (Unconstrained) Single-objective Optimization

The Ô¨Årst experiment investigates the capabilities of GPSAF
for improving the performance of existing algorithms on
unconstrained single-objective problems. We use the BBOB
test problems (24 functions in total) available in the COCO-
platform [62] which is a widely used test suite with a va-
riety of more and less complex problems. Four well-known
population-based optimization methods, DE [63], GA [16],
PSO [18], and CMAES [50] serve as baseline optimization

1http://pymoo.org (Version 0.5.0)
2https://pypi.org/project/pydaceÔ¨Åt/

TABLE III
A COMPARISON OF DE, GA, PSO, AND ISRES WITH THEIR GPSAF VARIANTS, ON CONSTRAINED SINGLE-OBJECTIVE PROBLEMS WITH SACOBRA ‚Äì
THE CURRENT STATE-OF-ART ALGORITHMS FOR CONSTRAINED OPTIMIZATION.

9

Problem SE(max)

DE

GPSAF-
DE

G1
G2
G4
G6
G7
G8
G9
G10
G11
G12
G16
G18
G19
G24

Total

75
300
75
75
75
100
300
300
300
300
300
300
300
300

5.5
3.5
6.5
7.0
7.0
7.0
7.0
8.0
7.0
6.0
5.5
7.0
7.5
7.5
6.571

3.5
7.0
3.5
4.0
4.0
4.5
4.5
3.5
2.5
4.5
2.5
3.5
2.0
4.5
3.857

GA

7.5
1.0
6.5
7.0
7.0
7.0
7.0
6.5
5.5
8.0
5.5
7.0
6.0
7.5
6.357

GPSAF-
GA

3.5
3.5
5.0
4.0
4.0
4.5
2.5
3.5
2.5
4.5
8.0
3.5
2.0
4.5
3.964

PSO

7.5
6.0
8.0
7.0
7.0
7.0
4.5
6.5
5.5
7.0
7.0
7.0
7.5
6.0
6.679

GPSAF-
PSO

GPSAF-
ISRES

SACOBRA

5.5
3.5
3.5
4.0
4.0
3.0
2.5
3.5
2.5
3.0
2.5
3.5
2.0
2.0
3.214

1.0
8.0
1.5
1.5
2.0
1.0
7.0
3.5
2.5
1.5
2.5
3.5
5.0
2.0
3.036

2.0
3.5
1.5
1.5
1.0
2.0
1.0
1.0
8.0
1.5
2.5
1.0
4.0
2.0
2.321

algorithms and their GPSAF variants provide a surrogate-
assisted version. The results are compared with four other
surrogate-assisted algorithms, SACOSO [22], SACC-EAM-
II [64], SADESammon [65], SAMSO [66] available in the
PlatEMO [67] framework. The rankings from the experiment
are shown in Table II. First, one can note that GPSAF
outperforms the other four existing surrogate-assisted algo-
rithms. One possible reason for the signiÔ¨Åcant difference could
be their development for a different type of test suite (for
instance, problems with a larger number of variables). In
this test suite, some problems are rather complicated, and
exploiting the surrogate too much will cause to be easily
trapped in local optima. Also, we contribute the efÔ¨Åciency of
GPSAF to the signiÔ¨Åcant effort for Ô¨Ånding the most suitable
surrogate. The order of relative rank improvement is given
by GA (6.292/2.292 = 2.7452), PSO (2.0927), DE (1.9546),
and for CMAES (1.4522). Besides GPSAF-GA having the
biggest relative rank improvement, it also is the overall best
performing algorithm in this experiment, closely followed
by GPSAF-CMAES. Altogether, a signiÔ¨Åcant and quite re-
markable improvement is achieved by applying GPSAF for
(unconstrained) single-objective optimization.

B. Constrained Single-objective Optimization

Rarely are optimization problems unconstrained in prac-
tice. Thus, especially for surrogate-assisted methods aiming
to solve computationally expensive real-world problems, the
capability of dealing with constraints is essential. The so-
called G-problems or G-function benchmark [68], [69] was
proposed to develop optimization algorithms dealing with
different kinds of constraints regarding the type (equality and
inequality), amount, complexity, and result in feasible and
infeasible search space. The original 13 test functions were
extended in a CEC competition in 2006 [70] to 24 constrained
single-objective test problems [71]. In this study, G problems
with only inequality constraints (and no equality constraints)
are used. Besides the GPSAF variants of DE and GA, im-
proved stochastic ranking evolutionary strategy (ISRES) [72]

is applied to GSPAF. ISRES implements an improved mating
strategy using differentials between solutions in contrast to its
predecessor SRES [73]. ISRES follows the well-known 1/7
rule, which means with a population size of ¬µ individuals 7 ¬∑ ¬µ
offsprings are created. For this study, GPSAF creates a steady-
state variant of ISRES by using the proposed probabilistic
knockout tournament to choose one out of the Œª solutions.
This ensures a fair comparison with SACOBRA [34] which
also evaluates one solution per iteration. To the best of our
knowledge, SACOBRA implemented in R [74] is currently
the best-performing algorithm on the G problem suite.

The constrained single-objective results are presented in
Table III. First, it is apparent that the GPSAF variants improve
the baseline algorithms. Only for G2, the genetic algorithm
outperforms its and other surrogate-assisted variants, which
we contribute to the very restricted feasible search space (also,
this has shown to be a difÔ¨Åcult problem for surrogate-assisted
algorithms in [34]). Second, GPSAF-ISRES shows the best
results out of all GPSAF variants. This indicates that it is
beneÔ¨Åcial if the baseline method has been proposed with a
speciÔ¨Åc problem class in mind. Even though DE, GA, and
PSO can handle constraints (for instance, naively using the
there are known to not perform
parameter-less approach),
particularly well on complex constrained functions without
any modiÔ¨Åcations. In contrast, ISRES has been tested on the
G problems in the original study and proven to be effective.
Furthermore, adding surrogate assistance to it has further
improved the results. Third, GPSAF-ISRES shows competitive
performance to the state-of-the-art algorithm SACOBRA. In
this experiment, out of all 14 test problems: GPSAF variants
were able to outperform SACOBRA four times and a baseline
algorithm (GA) one time; Ô¨Åve times the performance of at
least one GPSAF variant was similar; four times SACOBRA
has shown signiÔ¨Åcantly better results. Altogether, one can
say GPSAF has created surrogate-assisted methods compet-
ing with the state-of-the-art method for constrained single-
objective problems.

10

TABLE IV
A COMPARISON OF NSGA-II, SMS-EMOA, AND SPEA2 WITH THEIR GPSAF VARIANTS WITH FOUR SURROGATE-ASSISTED ALGORITHMS ON
BI-OBJECTIVE OPTIMIZATION PROBLEMS.

Problem NSGA-II

GPSAF-
NSGA-II

SMS-EMOA

GPSAF-
SMS-EMOA

SPEA2

GPSAF-
SPEA2

AB-SAEA

K-RVEA

ParEGO

CSEA

ZDT1
ZDT2
ZDT3
ZDT4
ZDT6
WFG1
WFG2
WFG3
WFG4
WFG5
WFG6
WFG7
WFG8
WFG9
Total

9.0
9.0
9.0
6.5
7.5
9.0
7.0
8.0
6.5
8.0
9.0
5.5
7.5
7.5
7.786

2.5
1.5
4.5
2.0
3.0
6.0
1.5
3.5
1.5
2.5
2.0
4.0
2.5
3.0
2.857

9.0
9.0
9.0
6.5
9.5
9.0
8.0
10.0
9.0
8.0
10.0
8.5
10.0
7.5
8.786

2.5
6.0
4.5
2.0
6.0
6.0
9.0
3.5
5.0
4.0
6.5
2.0
5.0
3.0
4.643

9.0
9.0
9.0
6.5
9.5
9.0
4.5
8.0
6.5
10.0
4.5
8.5
9.0
6.0
7.786

2.5
5.0
4.5
2.0
3.0
6.0
4.5
1.5
1.5
5.0
2.0
2.0
2.5
3.0
3.214

6.0
3.0
4.5
9.0
5.0
4.0
4.5
5.5
3.5
6.0
2.0
5.5
2.5
3.0
4.571

5.0
4.0
1.0
6.5
3.0
2.0
1.5
1.5
3.5
2.5
4.5
7.0
6.0
10.0
4.143

2.5
1.5
2.0
10.0
1.0
2.0
10.0
5.5
9.0
1.0
6.5
2.0
2.5
9.0
4.607

7.0
7.0
7.0
4.0
7.5
2.0
4.5
8.0
9.0
8.0
8.0
10.0
7.5
3.0
6.607

TABLE V
A COMPARISON OF NSGA-III, SMS-EMOA, AND SPEA2 WITH THEIR GPSAF VARIANTS WITH FOUR SURROGATE-ASSISTED ALGORITHMS ON
THREE-OBJECTIVE OPTIMIZATION PROBLEMS.

Problem NSGA-III

GPSAF-
NSGA-III

SMS-EMOA

GPSAF-
SMS-EMOA

SPEA2

GPSAF-
SPEA2

AB-SAEA

K-RVEA

ParEGO

CSEA

DTLZ1
DTLZ2
DTLZ3
DTLZ4
DTLZ5
DTLZ6
DTLZ7
Total

1.5
8.5
2.0
6.5
6.0
7.5
8.0
5.714

3.5
2.0
5.5
6.5
3.0
5.5
3.5
4.214

1.5
8.5
2.0
9.0
9.0
7.5
8.0
6.5

6.5
2.0
2.0
6.5
1.0
3.5
3.5
3.571

5.0
8.5
5.5
6.5
9.0
9.0
8.0
7.357

8.0
2.0
8.0
3.5
2.0
5.5
3.5
4.643

10.0
6.0
10.0
2.0
6.0
1.5
3.5
5.571

9.0
4.0
9.0
1.0
6.0
1.5
1.0
4.5

6.5
5.0
5.5
10.0
4.0
10.0
10.0
7.286

3.5
8.5
5.5
3.5
9.0
3.5
6.0
5.643

C. (Unconstrained) Multi-objective Optimization

Many applications have not one but multiple conÔ¨Çicting
objectives to optimize. For this reason, this experiment fo-
cuses speciÔ¨Åcally on multi-objective optimization problems.
As a test suite, we choose ZDT [75], a well-known test
suite proposed when multi-objective optimization has gained
popularity. Throughout this experiment, we set the number
of variables to 10, except for the high multi-modal problem,
ZDT4, where the number of variables is limited to 5. The
WFG [76] test suit provides even more Ô¨Çexibility by being
scalable with respect to the number of objectives. Here, we
simply set the objective number to be two to create another
bi-objective test suite. Moreover,
the number of variables
has been set to 10 where four of them are positional. The
baseline algorithms NSGA-II [77], SMS-EMOA [78], and
SPEA2 [79] are used as baseline algorithms. The results are
compared with four other surrogate-assisted algorithms: AB-
SAEA [80], KRVEA [27], ParEGO [14], CSEA [29] available
in PlatEMO [67].

The results on the two multi-objective test suites are shown
in Table IV. First, one can note that all surrogate-assisted
algorithms outperform the ones without. This indicates that
surrogate assistance effectively improves the convergence be-
havior. Second, GPSAF-NSGA-II performs the best with a
rank of 2.893 and shows the best performance, followed

by GPSAF-SPEA2, GPSAF-SMS-EMOA, and KRVEA. It is
worth noting that ParEGO is penalized by being terminated for
ZDT4 and WFG2, where the surrogate model was not able to
be built.

this is not

To show the behavior of three-objective optimization prob-
lems, we have replaced NSGA-II with NSGA-III and run all
algorithms on the DTLZ problems suite [81] test suite. The
results are shown in Table V. Whereas for most problems,
the GPSAF variants outperform the baseline algorithms, for
DTLZ1 and DTLZ3,
the case. Both problems
consist of multi-modal convergence functions, which causes
a large amount of surrogate error. Thus, surrogate-assisted
algorithms (including the four GPSAF is compared to) are
misguided. This seems to be a vital observation deserving to
be investigated in more detail into the future. Nevertheless,
GPSAF improves the performance of baseline algorithms for
the other problems. GPSAF-SMS-EMOA shows overall the
best results in this experiment with an average rank of 2.786
followed by GPSAF-NSGA-III.

D. Constrained Multi-objective Optimization

Lastly, we shall compare GPSAF on constrained multi-
objective optimization problems which often occur in real-
world optimization. The challenge of dealing with multiple ob-
jectives and constraints in combination with computationally

11

TABLE VI
A COMPARISON OF NSGA-III, SMS-EMOA, AND SPEA2 WITH THEIR GPSAF VARIANTS WITH FOUR SURROGATE-ASSISTED ALGORITHMS ON
CONSTRAINED MULTI-OBJECTIVE OPTIMIZATION PROBLEMS.

Problem

SE(max)

NSGA-II

GPSAF-
NSGA-II

SMS-EMOA

GPSAF-
SMS-EMOA

SPEA2

GPSAF-
SPEA2

HSMEA

C1-DTLZ1
C2-DTLZ2
C3-DTLZ4
BNH
SRN
TNK
OSY
Total

300
300
300
100
100
100
300

4.0
4.5
5.0
5.5
6.0
6.0
5.0
5.143

4.0
4.5
1.5
2.5
3.0
2.0
1.5
2.714

4.0
4.5
5.0
7.0
6.0
6.0
5.0
5.357

4.0
4.5
5.0
4.0
3.0
2.0
3.0
3.643

4.0
4.5
5.0
5.5
6.0
6.0
5.0
5.143

4.0
4.5
5.0
2.5
3.0
2.0
1.5
3.214

4.0
1.0
1.5
1.0
1.0
4.0
7.0
2.786

expensive solution evaluations truly mimics the complexity
of industrial optimization problems. We have compared our
results with HSMEA [28] a recently proposed algorithm for
constraint multi-objective optimization. With consultation of
the authors, some minor modiÔ¨Åcations of the publicly available
source code had to be made for dealing with computationally
expensive constraints ‚Äì as this is an assumption made in this
study. The results on CDTLZ [82], BNH [83], SRN [84],
TNK [85], and OSY [86] are shown in Table VI. Again,
one can observe that the GPSAF variants consistently improve
the performance of the baseline optimization methods. The
only exception is C1-DTLZ1, where all methods could Ô¨Ånd
no feasible solution, and thus, an equal rank is assigned.
We contribute this to the complexity of the test problems
given by the constraint violation and the multi-modality of
the objective functions. For OSY, TNK, the GPSAF variants
show a signiÔ¨Åcantly better performance than HSMEA; for C3-
DTLZ4, the performance is similar; and for C2-DTLZ2, BNH,
and TNK, it performs better. Altogether, GPSAF-NSGA-II
can obtain a better rank than HSMEA, but it shall be fair to
say that for three out of the seven constrained multi-objective
optimization problems, HSMEA is the winner. Nevertheless,
GPSAF improved the performance of baseline algorithms
and showed competitive results to another surrogate-assisted
optimization method.

V. CONCLUDING REMARKS

This article has proposed a generalized probabilistic
surrogate-assisted framework applicable to any type of
population-based algorithm. GSPAF incorporates two different
phases to provide surrogate assistance, one considering using
the current state of the baseline algorithm and the other looking
at multiple iterations into the future. In contrast
to other
existing surrogate-assisted algorithms,
the surrogate search
is not reduced to the Ô¨Ånal solutions on the surrogate, but
the whole search pattern is utilized. Solutions are selected
using a probabilistic tournament that considers surrogate pre-
diction errors for objectives and constraints from the search
pattern. GPSAF has been applied to multiple well-known
population-based algorithms proposed for unconstrained and
constrained single and multi-objective optimization. We have
provided comprehensive results on test problem suites indicat-
ing that GPSAF competes and outperforms existing surrogate-
assisted methods. The combination of GPSAF creating well-

performing surrogate-assisted algorithms with its simplicity
and broad applicability is very promising.

The encouraging results provide scope for further exploring
generalized surrogate-assisted algorithms. One main challenge
of a generalized approach is the recommendation of hyper-
parameter conÔ¨Ågurations (Œ±, Œ≤, œÅ, or Œ≥). The parameters have
been set
through
through empirical experiments; however,
the broad applicability, different mechanisms of baseline al-
gorithms on very different optimization problems make it
difÔ¨Åcult to draw generally valid conclusions. A more systemic
and possibly resource-intensive study shall provide an idea of
how different hyper-parameter settings impact the performance
of different algorithms. In addition, experiments investigating
the sensitivity shall be especially of interest.

The focus of this study was to explore different types of
problems with multiple objectives and constraints. Thus the
number of variables was kept relatively small as this is often
the case for computationally expensive problems. Thus, even
though the search space dimensions do not directly impact the
idea proposed in this article, it shall be part of a future study
of how surrogate assistance performs for large-scale problems.
Moreover, the number of solution evaluations per run has been
set to 300, which allows using all solutions exhaustively for
modeling without a large modeling overhead. However, more
solution evaluations might be feasible for mediocre expensive
optimization problems.

Nevertheless, this extensive explorative study on the use
of surrogates in single and multi-objective optimization with
and without constraints has indicated a viable new direction
in congruence with existing emerging studies for a generic
optimization methodology.

REFERENCES

[1] P. C. Roy, A. Guber, M. Abouali, A. P. Nejadhashemi, K. Deb, and
A. J. M. Smucker, ‚ÄúSimulation Optimization of Water Usage and
Crop Yield Using Precision Irrigation,‚Äù in Evolutionary Multi-Criterion
Optimization, K. Deb, E. Goodman, C. A. Coello Coello, K. Klamroth,
K. Miettinen, S. Mostaghim, and P. Reed, Eds.
Cham: Springer
International Publishing, 2019, pp. 695‚Äì706.

[2] H. Yin, H. Fang, G. Wen, Q. Wang, and Y. Xiao, ‚ÄúAn adaptive RBF-
based multi-objective optimization method for crashworthiness design
of functionally graded multi-cell tube,‚Äù Structural and Multidisciplinary
Optimization, vol. 53, no. 1, pp. 129‚Äì144, 2016.

[3] S. Lucidi, M. Maurici, L. Paulon, F. Rinaldi, and M. Roma, ‚ÄúA
simulation-based multiobjective optimization approach for health care
service management,‚Äù IEEE Transactions on Automation Science and
Engineering, vol. 13, no. 4, pp. 1480‚Äì1491, 2016.

[4] Z. Lu, I. Whalen, V. Boddeti, Y. Dhebar, K. Deb, E. Goodman,
and W. Banzhaf, ‚ÄúNSGA-Net: Neural architecture search using
multi-objective genetic algorithm,‚Äù in Proceedings of the genetic and
evolutionary computation conference, ser. GECCO ‚Äô19. New York,
NY, USA: Association for Computing Machinery, 2019, pp. 419‚Äì427.
[Online]. Available: https://doi.org/10.1145/3321707.3321729

[5] J. D. Anderson and J. Wendt, Computational Ô¨Çuid dynamics. Springer,

1995, vol. 206.

[6] B. Szab¬¥o and I. BabuÀáska, Finite element analysis.

John Wiley & Sons,

1991.

[7] W. Luo, R. Yi, B. Yang, and P. Xu, ‚ÄúSurrogate-assisted evolutionary
framework for data-driven dynamic optimization,‚Äù IEEE Transactions
on Emerging Topics in Computational Intelligence, vol. 3, no. 2, pp.
137‚Äì150, 2019.

[8] H. Wang and Y. Jin, ‚ÄúA random forest-assisted evolutionary algorithm
for data-driven constrained multiobjective combinatorial optimization of
trauma systems,‚Äù IEEE Transactions on Cybernetics, vol. 50, no. 2, pp.
536‚Äì549, 2020.

[9] S. Olafsson and J. Kim, ‚ÄúSimulation optimization,‚Äù in Proceedings of

the winter simulation conference, vol. 1, 2002, pp. 79‚Äì84.

[10] Y. Jin, ‚ÄúSurrogate-assisted evolutionary computation: Recent advances
challenges,‚Äù Swarm and Evolutionary Computation,
[Online]. Available: http:

and future
vol. 1, no. 2, pp. 61 ‚Äì 70, 2011.
//www.sciencedirect.com/science/article/pii/S2210650211000198
[11] D. R. Jones, M. Schonlau, and W. J. Welch, ‚ÄúEfÔ¨Åcient global optimiza-
tion of expensive black-box functions,‚Äù J. of Global Optimization, 1998.
[12] D. G. Krige, ‚ÄúA statistical approach to some basic mine valuation
problems on the Witwatersrand, by D.G. Krige, published in the Journal,
December 1951 : introduction by the author,‚Äù 1951.

[13] R. T. Haftka, D. Villanueva, and A. Chaudhuri, ‚ÄúParallel surrogate-
assisted global optimization with expensive functions ‚Äìa survey,‚Äù
Structural and Multidisciplinary Optimization, vol. 54, no. 1, pp. 3‚Äì13,
2016. [Online]. Available: https://doi.org/10.1007/s00158-016-1432-3

[14] J. Knowles, ‚ÄúParEGO: a hybrid algorithm with on-line landscape
approximation for expensive multiobjective optimization problems,‚Äù
IEEE Transactions on Evolutionary Computation, vol. 10, no. 1, pp.
50‚Äì66, 2006. [Online]. Available: https://doi.org/10.1109/TEVC.2005.
851274

[15] Yaochu Jin, M. Olhofer, and B. Sendhoff, ‚ÄúA framework for evolutionary
optimization with approximate Ô¨Åtness functions,‚Äù IEEE Transactions on
Evolutionary Computation, vol. 6, no. 5, pp. 481‚Äì494, 2002.

[16] D. E. Goldberg, Genetic algorithms in search, optimization and machine
learning, 1st ed. USA: Addison-Wesley Longman Publishing Co., Inc.,
1989.

[17] R. Storn, ‚ÄúOn the usage of differential evolution for function optimiza-
tion,‚Äù in Proceedings of north american fuzzy information processing,
1996, pp. 519‚Äì523.

[18] J. Kennedy and R. Eberhart, ‚ÄúParticle swarm optimization,‚Äù in Proceed-
ings of ICNN‚Äô95 - international conference on neural networks, vol. 4,
1995, pp. 1942‚Äì1948 vol.4.

[19] M. Emmerich, A. Giotis, M. ¬®Ozdemir, T. B¬®ack, and K. Giannakoglou,
‚ÄúMetamodel‚ÄîAssisted evolution strategies,‚Äù in Parallel problem solving
from nature ‚Äî PPSN VII, J. J. M. Guerv¬¥os, P. Adamidis, H.-G.
Beyer, H.-P. Schwefel, and J.-L. Fern¬¥andez-VillacaÀúnas, Eds. Berlin,
Heidelberg: Springer Berlin Heidelberg, 2002, pp. 361‚Äì370, tex.ids=
2002-emmerich-metamodel-assisted.

[20] X. Lu, K. Tang, and X. Yao, ‚ÄúClassiÔ¨Åcation-assisted Differential Evo-
lution for computationally expensive problems,‚Äù in 2011 IEEE congress
of evolutionary computation (CEC), 2011, pp. 1986‚Äì1993.

[21] Y. Wang, D. Yin, S. Yang, and G. Sun, ‚ÄúGlobal and local surrogate-
assisted differential evolution for expensive constrained optimization
problems with inequality constraints,‚Äù IEEE Transactions on Cybernet-
ics, vol. 49, no. 5, pp. 1642‚Äì1656, 2019.

[22] C. Sun, Y. Jin, R. Cheng, J. Ding, and J. Zeng, ‚ÄúSurrogate-assisted co-
operative swarm optimization of high-dimensional expensive problems,‚Äù
IEEE Transactions on Evolutionary Computation, vol. 21, no. 4, pp.
644‚Äì660, 2017, tex.ids= 2017-sun-coop-swarm.

[23] J. Stork, M. Friese, M. Zaefferer, T. Bartz-Beielstein, A. Fischbach,
B. Breiderhoff, B. Naujoks, and T. TuÀásar, ‚ÄúOpen issues in surrogate-
assisted optimization,‚Äù in High-performance simulation-based optimiza-
tion, T. Bartz-Beielstein, B. FilipiÀác, P. KoroÀásec, and E.-G. Talbi, Eds.
Cham: Springer International Publishing, 2020, pp. 225‚Äì244.

[24] D. Lim, Y. Jin, Y. Ong, and B. Sendhoff, ‚ÄúGeneralizing surrogate-
assisted evolutionary computation,‚Äù IEEE Transactions on Evolutionary
Computation, vol. 14, no. 3, pp. 329‚Äì355, 2010.

[25] X. Cai, L. Gao, and X. Li, ‚ÄúEfÔ¨Åcient generalized surrogate-assisted
evolutionary algorithm for high-dimensional expensive problems,‚Äù IEEE

12

Transactions on Evolutionary Computation, vol. 24, no. 2, pp. 365‚Äì379,
2020.

[26] Q. Zhang, W. Liu, E. Tsang, and B. Virginas, ‚ÄúExpensive multiobjective
optimization by MOEA/D with gaussian process model,‚Äù IEEE
Transactions on Evolutionary Computation, vol. 14, no. 3, pp. 456‚Äì474,
2010. [Online]. Available: https://doi.org/10.1109/TEVC.2009.2033671
[27] T. Chugh, Y. Jin, K. Miettinen, J. Hakanen, and K. Sindhya, K-rvea: A
kriging-assisted evolutionary algorithm for many-objective optimization,
Mar. 2016.

[28] A. Habib, H. K. Singh, T. Chugh, T. Ray, and K. Miettinen, ‚ÄúA
multiple surrogate assisted decomposition-based evolutionary algorithm
for expensive Multi/Many-Objective optimization,‚Äù IEEE Transactions
on Evolutionary Computation, vol. 23, no. 6, pp. 1000‚Äì1014, 2019.
[Online]. Available: https://doi.org/10.1109/TEVC.2019.2899030
[29] L. Pan, C. He, Y. Tian, H. Wang, X. Zhang, and Y. Jin, ‚ÄúA classiÔ¨Åcation-
based surrogate-assisted evolutionary algorithm for expensive many-
objective optimization,‚Äù IEEE Transactions on Evolutionary Computa-
tion, vol. 23, no. 1, pp. 74‚Äì88, 2019.

[30] Z. Lv, L. Wang, Z. Han, J. Zhao, and W. Wang, ‚ÄúSurrogate-assisted
particle swarm optimization algorithm with Pareto active learning for ex-
pensive multi-objective optimization,‚Äù IEEE/CAA Journal of Automatica
Sinica, vol. 6, no. 3, pp. 838‚Äì849, 2019, tex.ids= 2019-lv-pal-pso.
[31] H. Wang, Y. Jin, and J. Doherty, ‚ÄúCommittee-based active learning for
surrogate-assisted particle swarm optimization of expensive problems,‚Äù
IEEE Transactions on Cybernetics, vol. 47, no. 9, pp. 2664‚Äì2677, 2017.
[32] W. Ponweiser, T. Wagner, D. Biermann, and M. Vincze, ‚ÄúMultiobjective
optimization on a limited budget of evaluations using model-assisted
$\mathcal{S}$-Metric selection,‚Äù in Parallel problem solving from
nature ‚ÄìPPSN x, G. Rudolph, T. Jansen, N. Beume, S. Lucas, and
C. Poloni, Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2008,
pp. 784‚Äì794.

[33] Yew-Soon Ong, P. B. Nair, and K. Y. Lum, ‚ÄúMax-min surrogate-
assisted evolutionary algorithm for robust design,‚Äù IEEE Transactions
on Evolutionary Computation, vol. 10, no. 4, pp. 392‚Äì404, 2006.
[34] S. Bagheri, W. Konen, M. Emmerich, and T. B¬®ack, ‚ÄúSelf-adjusting
parameter control for surrogate-assisted constrained optimization under
limited budgets,‚Äù Applied Soft Computing, vol. 61, pp. 377 ‚Äì 393, 2017.
[35] M. M. Islam, H. K. Singh, and T. Ray, ‚ÄúA surrogate assisted approach
for single-objective bilevel optimization,‚Äù IEEE Transactions on Evolu-
tionary Computation, vol. 21, no. 5, pp. 681‚Äì696, 2017.

[36] J. M¬®uller, ‚ÄúMISO: mixed-integer surrogate optimization framework,‚Äù
Optimization and Engineering, vol. 17, no. 1, pp. 177‚Äì203, Mar. 2016.
[Online]. Available: https://doi.org/10.1007/s11081-015-9281-2

[37] J. M¬®uller and J. D. Woodbury, ‚ÄúGOSAC: global optimization
with surrogate approximation of constraints,‚Äù Journal of Global
Optimization, vol. 69, no. 1, pp. 117‚Äì136, Sep. 2017.
[Online].
Available: https://doi.org/10.1007/s10898-017-0496-y

[38] G. Lei, T. Wang, Y. Guo, J. Zhu, and S. Wang, ‚ÄúSystem-level design op-
timization methods for electrical drive systems: Deterministic approach,‚Äù
IEEE Transactions on Industrial Electronics, vol. 61, no. 12, pp. 6591‚Äì
6602, 2014.

[39] Y. Duan and D. M. Ionel, ‚ÄúA review of recent developments in elec-
trical machine design optimization methods with a permanent-magnet
synchronous motor benchmark study,‚Äù IEEE Transactions on Industry
Applications, vol. 49, no. 3, pp. 1268‚Äì1275, 2013.

[40] M. Dorica and D. Giannacopoulos, ‚ÄúResponse clustering for electro-
magnetic modeling and optimization,‚Äù IEEE Transactions on Magnetics,
vol. 42, no. 4, pp. 1127‚Äì1130, 2006.

[41] D. R. Jones, ‚ÄúA taxonomy of global optimization methods based on
response surfaces,‚Äù Journal of Global Optimization, vol. 21, no. 4,
pp. 345‚Äì383, 2001.
[Online]. Available: https://doi.org/10.1023/A:
1012771025575

[42] F. Viana and R. Haftka, ‚ÄúSurrogate-based optimization with parallel
simulations using the probability of improvement,‚Äù in 13th AIAA/ISSMO
multidisciplinary analysis optimization conference, 2010.

[43] P. Beaucaire, C. Beauthier, and C. Sainvitu, ‚ÄúMulti-point inÔ¨Åll sam-
pling strategies exploiting multiple surrogate models,‚Äù in GECCO ‚Äô19:
Proceedings of the genetic and evolutionary computation conference
companion. New York, NY, USA: ACM, 2019, pp. 1559‚Äì1567.
[44] N. Berveglieri, B. Derbel, A. Liefooghe, H. Aguirre, Q. Zhang, and
K. Tanaka, ‚ÄúDesigning parallelism in surrogate-assisted multiobjective
optimization based on decomposition,‚Äù in Proceedings of
the 2020
genetic and evolutionary computation conference, ser. GECCO ‚Äô20.
New York, NY, USA: Association for Computing Machinery, 2020, pp.
462‚Äì470. [Online]. Available: https://doi.org/10.1145/3377930.3390202
[45] S. Bagheri, W. Konen, R. Allmendinger, J. Branke, K. Deb, J. Fieldsend,
D. Quagliarella, and K. Sindhya, ‚ÄúConstraint handling in efÔ¨Åcient

global optimization,‚Äù in Proceedings of the genetic and evolutionary
computation conference, ser. GECCO ‚Äô17. New York, NY, USA:
Association for Computing Machinery, 2017, pp. 673‚Äì680. [Online].
Available: https://doi.org/10.1145/3071178.3071278

[46] Y. S. Ong, P. B. Nair, and A. J. Keane, ‚ÄúEvolutionary optimization
of computationally expensive problems via surrogate modeling,‚Äù AIAA
Journal, vol. 41, no. 4, pp. 687‚Äì696, 2003.
[Online]. Available:
https://doi.org/10.2514/2.1999

[47] A. Ratle, Accelerating the convergence of evolutionary algorithms
by Ô¨Åtness landscape approximation, ser. International Conference on
Parallel Problem Solving from Nature. Springer, 1998.

[48] Z. Zhou, Y. S. Ong, P. B. Nair, A. J. Keane, and K. Y. Lum, ‚ÄúCombining
global and local surrogate models to accelerate evolutionary optimiza-
tion,‚Äù IEEE Transactions on Systems, Man, and Cybernetics, Part C
(Applications and Reviews), vol. 37, no. 1, pp. 66‚Äì76, 2007.

[49] N. Hansen, ‚ÄúA global surrogate assisted CMA-ES,‚Äù in Proceedings of
the genetic and evolutionary computation conference, ser. GECCO ‚Äô19.
New York, NY, USA: Association for Computing Machinery, 2019, pp.
664‚Äì672. [Online]. Available: https://doi.org/10.1145/3321707.3321842
[50] N. Hansen and A. Ostermeier, ‚ÄúCompletely derandomized self-
adaptation in evolution strategies,‚Äù Evolutionary Computation, vol. 9,
no. 2, pp. 159‚Äì195, Jun. 2001. [Online]. Available: http://dx.doi.org/10.
1162/106365601750190398

[51] R. Cheng, Y. Jin, M. Olhofer, and B. Sendhoff, ‚ÄúA reference vector
guided evolutionary algorithm for many-objective optimization,‚Äù IEEE
Transactions on Evolutionary Computation, vol. 20, no. 5, pp. 773‚Äì791,
2016.

[52] Q. Zhang and H. Li, ‚ÄúA multi-objective evolutionary algorithm based
on decomposition,‚Äù IEEE Transactions on Evolutionary Computation,
Accepted, vol. 2007, 2007.

[53] B. L. Miller, B. L. Miller, D. E. Goldberg, and D. E. Goldberg, ‚ÄúGenetic
Algorithms, Tournament Selection, and the Effects of Noise,‚Äù Complex
Systems, vol. 9, pp. 193‚Äì212, 1995.

[54] J. Blank and K. Deb, ‚ÄúPSAF: A Probabilistic Surrogate-Assisted
Framework for Single-Objective Optimization,‚Äù in GECCO ‚Äô21:
Proceedings of the genetic and evolutionary computation conference
companion. New York, NY, USA: ACM, 2021, place: New York, NY,
USA. [Online]. Available: https://doi.org/10.1145/3449639.3459297
[55] K. Deb, R. Hussein, P. C. Roy, and G. Toscano-Pulido, ‚ÄúA taxonomy for
metamodeling frameworks for evolutionary multiobjective optimization,‚Äù
IEEE Transactions on Evolutionary Computation, vol. 23, no. 1, pp.
104‚Äì116, 2019.

[56] R. L. Hardy, ‚ÄúMultiquadric equations of

topography and other
irregular surfaces,‚Äù Journal of Geophysical Research (1896-1977),
vol. 76, no. 8, pp. 1905‚Äì1915, Mar. 1971.
[Online]. Available:
https://doi.org/10.1029/JB076i008p01905

[57] M. G. Kendall, ‚ÄúA new measure of rank correlation,‚Äù Biometrika,
[Online]. Available: http:

vol. 30, no. 1/2, pp. 81‚Äì93, 1938.
//www.jstor.org/stable/2332226

[58] C. A. Coello Coello and M. Reyes Sierra, ‚ÄúA study of the paral-
lelization of a coevolutionary multi-objective evolutionary algorithm,‚Äù in
MICAI 2004: Advances in artiÔ¨Åcial intelligence, R. Monroy, G. Arroyo-
Figueroa, L. E. Sucar, and H. Sossa, Eds. Berlin, Heidelberg: Springer
Berlin Heidelberg, 2004, pp. 688‚Äì697.

[59] E. Zitzler, D. Brockhoff, and L. Thiele, ‚ÄúThe Hypervolume Indicator
Revisited: On the Design of Pareto-compliant Indicators via Weighted
Integration,‚Äù in Proceedings of
the 4th International Conference
on Evolutionary Multi-criterion Optimization, ser. EMO‚Äô07. Berlin,
Heidelberg: Springer-Verlag, 2007, pp. 862‚Äì876. [Online]. Available:
http://dl.acm.org/citation.cfm?id=1762545.1762618

[60] J. Blank and K. Deb, ‚Äúpymoo: Multi-objective Optimization in Python,‚Äù

IEEE Access, vol. 8, pp. 89 497‚Äì89 509, 2020.

[61] S. Lophaven, H. B. Nielsen, and J. S√∏ndergaard, ‚ÄúDACE ‚Äì a MATLAB

kriging toolbox,‚Äù 2002.

[62] N. Hansen, A. Auger, R. Ros, O. Mersmann, T. TuÀásar, and D. Brockhoff,
‚ÄúCOCO: A platform for comparing continuous optimizers in a black-box
setting,‚Äù Optimization Methods and Software, 2020.

[63] R. Storn and K. Price, ‚ÄúDifferential Evolution ‚ÄìA Simple and EfÔ¨Åcient
Heuristic for global Optimization over Continuous Spaces,‚Äù Journal of
Global Optimization, no. 4, pp. 341‚Äì359, Dec. 1997.

[64] J. Blanchard, C. Beauthier, and T. Carletti, ‚ÄúA surrogate-assisted coop-
erative co-evolutionary algorithm using recursive differential grouping
as decomposition strategy,‚Äù in 2019 IEEE congress on evolutionary
computation (CEC), 2019, pp. 689‚Äì696.

[65] G. Chen, K. Zhang, X. Xue, L. Zhang, J. Yao, H. Sun, L. Fan, and
Y. Yang, ‚ÄúSurrogate-assisted evolutionary algorithm with dimensionality
reduction method for water Ô¨Çooding production optimization,‚Äù Journal

13

of Petroleum Science and Engineering, vol. 185, p. 106633, 2020.
[Online]. Available: https://www.sciencedirect.com/science/article/pii/
S092041051931054X

[66] F. Li, X. Cai, L. Gao, and W. Shen, ‚ÄúA surrogate-assisted multiswarm
optimization algorithm for high-dimensional computationally expensive
problems,‚Äù IEEE Transactions on Cybernetics, vol. 51, no. 3, pp. 1390‚Äì
1402, 2021.

[67] Y. Tian, R. Cheng, X. Zhang, and Y. Jin, ‚ÄúPlatEMO: A MATLAB
platform for evolutionary multi-objective optimization,‚Äù IEEE Compu-
tational Intelligence Magazine, vol. 12, no. 4, pp. 73‚Äì87, 2017.
and M. Schoenauer,

‚ÄúEvolutionary algorithms
constrained parameter optimization problems,‚Äù Evolutionary
[Online].

for
Computation, vol. 4, no. 1, pp. 1‚Äì32, Mar. 1996.
Available: https://doi.org/10.1162/evco.1996.4.1.1

[68] Z. Michalewicz

[69] C. A. Floudas and P. M. Pardalos, ‚ÄúA collection of test problems
for constrained global optimization algorithms,‚Äù in Lecture notes in
computer science, 1990.

[70] IEEE international conference on evolutionary computation, CEC
2006, part of WCCI 2006, vancouver, BC, canada, 16-21 july
2006.
IEEE, 2006. [Online]. Available: https://ieeexplore.ieee.org/xpl/
conhome/11108/proceeding

[71] J. Liang, T. Runarsson, E. Mezura-Montes, M. Clerc, P. Suganthan,
C. Coello, and K. Deb, ‚ÄúProblem deÔ¨Ånitions and evaluation criteria for
the CEC 2006 special session on constrained real-parameter optimiza-
tion,‚Äù Nangyang Technological University, Singapore, Tech. Rep, vol. 41,
Jan. 2006.

[72] T. Runarsson and X. Yao, ‚ÄúSearch biases in constrained evolutionary
optimization,‚Äù IEEE Transactions on Systems, Man, and Cybernetics,
Part C (Applications and Reviews), vol. 35, no. 2, pp. 233‚Äì243, 2005.
[73] ‚Äî‚Äî, ‚ÄúStochastic ranking for constrained evolutionary optimization,‚Äù
IEEE Transactions on Evolutionary Computation, vol. 4, no. 3, pp. 284‚Äì
294, 2000.

[74] R Core Team, ‚ÄúR: A language and environment

statistical
computing,‚Äù Vienna, Austria, manual, 2021, organization: R Foundation
for Statistical Computing. [Online]. Available: https://www.R-project.
org/

for

[75] E. Zitzler, K. Deb, and L. Thiele, ‚ÄúComparison of multiobjective
evolutionary algorithms: Empirical results,‚Äù Evolutionary Computation,
vol. 8, no. 2, pp. 173‚Äì195, 2000.
[Online]. Available: https:
//doi.org/10.1162/106365600568202

[76] S. Huband, L. Barone, L. While, and P. Hingston, ‚ÄúA Scalable Multi-
objective Test Problem Toolkit,‚Äù in Evolutionary Multi-Criterion Opti-
mization, C. A. Coello Coello, A. Hern¬¥andez Aguirre, and E. Zitzler,
Eds. Berlin, Heidelberg: Springer Berlin Heidelberg, 2005, pp. 280‚Äì
295.

[77] K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan, ‚ÄúA fast
and elitist multiobjective genetic algorithm: NSGA-II,‚Äù Trans. Evol.
Comp, vol. 6, no. 2, pp. 182‚Äì197, Apr. 2002. [Online]. Available:
https://doi.org/10.1109/4235.996017

[78] N. Beume, B. Naujoks, and M. Emmerich, ‚ÄúSMS-EMOA: Multiobjective
selection based on dominated hypervolume,‚Äù European Journal of
Operational Research, vol. 181, no. 3, pp. 1653‚Äì1669, 2007.
[Online]. Available: https://www.sciencedirect.com/science/article/pii/
S0377221706005443

[79] E. Zitzler, M. Laumanns, and L. Thiele, ‚ÄúSPEA2: Improving the strength

pareto evolutionary algorithm,‚Äù 2001.

[80] X. Wang, Y.

Jin, S. Schmitt, and M. Olhofer, ‚ÄúAn adaptive
Bayesian approach to surrogate-assisted evolutionary multi-objective
optimization,‚Äù Information Sciences, vol. 519, pp. 317‚Äì331, 2020.
[Online]. Available: https://www.sciencedirect.com/science/article/pii/
S0020025520300591

[81] K. Deb, L. Thiele, M. Laumanns, and E. Zitzler, ‚ÄúScalable test problems
for evolutionary multiobjective optimization,‚Äù in Evolutionary multiob-
jective optimization: Theoretical advances and applications, A. Abra-
ham, L. Jain, and R. Goldberg, Eds. London: Springer London, 2005,
pp. 105‚Äì145.

[82] H. Jain and K. Deb, ‚ÄúAn evolutionary many-objective optimization
algorithm using reference-point based nondominated sorting approach,
part II: Handling constraints and extending to an adaptive approach,‚Äù
IEEE Transactions on Evolutionary Computation, vol. 18, no. 4, pp.
602‚Äì622, Aug. 2014.

[83] T. T. Binh and U. Korn, ‚ÄúMOBES: A multiobjective evolution strategy
for constrained optimization problems,‚Äù in In Proceedings of the Third
International Conference on Genetic Algorithms, 1997, pp. 176‚Äì182.

[84] N. Srinivas and K. Deb, ‚ÄúMulti-Objective function optimization using
non-dominated sorting genetic algorithms,‚Äù Evolutionary Computation
Journal, vol. 2, no. 3, pp. 221‚Äì248, 1994.

[85] M. Tanaka, ‚ÄúGA-based decision support system for multi-criteria opti-
mization,‚Äù in Proceedings of the international conference on systems,
man and cybernetics, vol. 2, 1995, pp. 1556‚Äì1561.

[86] A. Osyczka and S. Kundu, ‚ÄúA new method to solve generalized
multicriteria optimization problems using the simple genetic algorithm,‚Äù
Structural optimization, vol. 10, no. 2, pp. 94‚Äì99, Oct. 1995. [Online].
Available: https://doi.org/10.1007/BF01743536

14

Julian Blank is a PhD candidate in the Department
of Computer Science and Engineering at Michigan
State University. He received his B.Sc. in Business
Information Systems from Otto von Guericke Uni-
versity, Germany, in 2010. He was a visiting scholar
for six months at the Michigan State University,
Michigan, USA, in 2015, and Ô¨Ånished his M.Sc. in
Computer Science at Otto von Guericke University,
Germany, in 2016. He is the leading developer of
pymoo, an open-source multi-objective optimization
framework in Python. His research interests include
evolutionary computation, multi-objective optimization, surrogate-assisted op-
timization, and machine learning.

Kalyanmoy Deb is Fellow, IEEE, University Dis-
tinguished Professor and Koenig Endowed Chair
Professor with the Department of Electrical and
Computer Engineering, Michigan State University,
East Lansing, Michigan, USA. He received his Bach-
elor‚Äôs degree in Mechanical Engineering from IIT
Kharagpur in India, and his Master‚Äôs and Ph.D.
degrees from the University of Alabama, Tuscaloosa,
USA, in 1989 and 1991. He is largely known for his
seminal research in evolutionary multi-criterion op-
timization. He has published over 580 international
journal and conference research papers to date. His current research interests
include evolutionary optimization and its application in design, modeling, AI,
and machine learning. He is one of the top-cited EC researchers with more
than 190,000 Google Scholar citations.

