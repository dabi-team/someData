2
2
0
2

p
e
S
2

]
L
P
.
s
c
[

1
v
0
0
0
1
0
.
9
0
2
2
:
v
i
X
r
a

Programming with Context-Sensitive Holes using
Dependency-Aware Tuning

LINNEA STJERNA, EECS and Digital Futures, KTH Royal Institute of Technology, Sweden
DAVID BROMAN, EECS and Digital Futures, KTH Royal Institute of Technology, Sweden

Developing efficient and maintainable software systems is both hard and time consuming. In particular,
non-functional performance requirements involve many design and implementation decisions that can be
difficult to take early during system development. Choices—such as selection of data structures or where
and how to parallelize code—typically require extensive manual tuning that is both time consuming and
error-prone. Although various auto-tuning approaches exist, they are either specialized for certain domains
or require extensive code rewriting to work for different contexts in the code. In this paper, we introduce a
new methodology for writing programs with holes, that is, decision variables explicitly stated in the program
code that enable developers to postpone decisions during development. We introduce and evaluate two novel
ideas: (i) context-sensitive holes that are expanded by the compiler into sets of decision variables for automatic
tuning, and (ii) dependency-aware tuning, where static analysis reduces the search space by finding the set
of decision variables that can be tuned independently of each other. We evaluate the two new concepts in a
system called Miking, where we show how the general methodology can be used for automatic algorithm
selection, data structure decisions, and parallelization choices.

1 INTRODUCTION
Software developers constantly face implementation choices that affect performance, such as
choices of data structures, algorithms, and parameter values. Unfortunately, traditional program-
ming languages lack support for expressing such alternatives directly in the code, forcing the
programmer to commit to certain design choices up front. To improve the performance of a pro-
gram, a developer can profile the code and manually tune the program by explicitly executing
the program repeatedly, testing and changing different algorithm choices and parameter settings.
However, such manual tuning is both tedious and error prone because the number of program al-
ternatives grows exponentially with the number of choices. Besides choices of program parameters,
hardware properties, such cache layout and core configurations make manual optimization even
more challenging.

An attractive alternative to manual tuning of programs is to perform the tuning automatically.
Conceptually, a tuning problem is an optimization problem where the search space consists of
potential program alternatives and the goal is to minimize an objective, such as execution time,
memory usage, or code size. The search space is explored using some search technique, which
can be performed either offline (at compile-time) or online (at runtime). In this work, we focus on
offline tuning.

Several offline auto-tuning tools have been developed to target problems in specific domains. For
instance, ATLAS [Whaley 2011] for linear algebra, FFTW [Frigo 1999] and SPIRAL [Franchetti et al.
2018] for linear digital processing, PetaBricks [Ansel et al. 2009] for algorithmic choice, as well as
tools for choosing sorting algorithm automatically [Li et al. 2004]. Although these domain-specific
tuning approaches have shown to work well in their specific area, they are inherently targeting a
specific domain and cannot be used in general for other kinds of applications.

In contrast to domain-specific tuning, generic auto-tuners offer solutions that work across
domains and may be applicable to arbitrary software systems. For instance, approaches such as
ATF [Rasch and Gorlatch 2019], OpenTuner [Ansel et al. 2014], CLTune [Nugteren and Codreanu

Authors’ addresses: Linnea Stjerna, lstjerna@kth.se, EECS and Digital Futures, KTH Royal Institute of Technology, Stockholm,
Sweden; David Broman, dbro@kth.se, EECS and Digital Futures, KTH Royal Institute of Technology, Stockholm, Sweden.

 
 
 
 
 
 
2

Trovato and Tobin, et al.

2017], HyperMapper [Nardi et al. 2019], and PbO [Hoos 2012] make it possible for developers to
specify unknown variables and possible values. The goal of the tuner is then to assign values to
these variables optimally, to minimize for instance execution time. In particular, existing generic
auto-tuners assign values to variables globally, i.e., each unknown variable is assigned the same
value throughout the program.

In this work, we focus on two problems with state-of-the-art methods. Firstly, only using global
decision variables does not scale in larger software projects and it violates fundamental software
engineering principles. Specifically, a global decision variable does not take into consideration the
context from where a function may be called. Global decision variables can of course be manually
added in all calling contexts, but such manual refactoring of code makes code updates brittle and
harder to maintain. Secondly, auto tuning is typically computationally expensive, since the search
space consists of all combinations of decision variable values. This is because decision variables are
dependent on each other in general. However, if a subset of the decision variables is independent,
then the auto tuner wastes precious time exploring unnecessary configurations.

In this paper, we introduce a methodology where a software developer postpones design decisions
during code development by explicitly stating holes in the program. A hole is a decision variable
for the auto tuner, with a given default value and domain, such as integer range or Boolean type.
In contrast to existing work, we introduce context-sensitive holes. This means that a hole that is
specified in a program (called a base hole) can be expanded into a set of decision variables (called
context holes) that take the calling context into consideration. The compiler statically analyses the
call graph of the program and transforms the program so that the calling context is maintained
during runtime. Only paths through the call graph up to a certain length are considered, to avoid a
combinatorial explosion in the number of variables.

In our approach, context-sensitive holes can be automatically tuned using input data, without
manual involvement. We develop and apply a novel static dependency analysis to build a bipartite
dependency graph, which encodes the dependencies among the context-sensitive holes. In contrast
to existing approaches, the dependency analysis is automatic, though optional annotations may
be added to increase the accuracy. The dependency graph is used to reduce the search space in
a method we call dependency-aware tuning. Using this method, the auto tuner concentrates its
computation time on exploring only the necessary configurations of hole values.

Specifically, we make the following contributions:

• We propose a general methodology for programming with context-sensitive holes that enables
the software developer to postpone decisions to a later stage of automatic tuning. In particular,
we discuss how the methodology can be used for algorithm and parallelization decisions
(Section 2).

• To enable the proposed methodology, we propose a number of algorithms for performing pro-
gram transformations for efficiently maintaining calling context during runtime (Section 3).
• We design and develop a novel static dependency analysis, and use the result during tuning

to reduce the search space of the problem (Sections 4–5).

• We design and develop a complete solution for the proposed idea within the Miking frame-
work [Broman 2019], a software framework for developing general purpose and domain-
specific languages and compilers (Section 6).

To evaluate the approach, we perform experiments on several non-trivial case studies that are not
originally designed for the approach (Section 7).

Programming with Context-Sensitive Holes using Dependency-Aware Tuning

3

2 PROGRAMMING WITH CONTEXT-SENSITIVE HOLES
In this section, we first introduce the main idea behind the methodology of programming with
holes. We then discuss various programming examples, using global and context-sensitive holes.

2.1 Main Idea
Traditionally, an idea is implemented into a program by making a number of implementation
choices, and gradually reducing the design space. By contrast, when programming with holes, we
delay the decision of implementation choices. Design choices—such as what parts of the program to
parallelize or which algorithms to execute in different circumstances—are instead left unspecified by
specifying holes, that is, decision variables stated directly in the program code. Instead of taking the
design decision up-front, an auto-tuner framework makes use of input data and runtime profiling
information, to make decisions of filling in the holes with the best available alternatives. Thus, the
postponed decisions can be automated and based on more information, resulting in less ad hoc and
more informed decisions.

2.2 Global Holes
The key concept in our methodology is the notation of holes. A hole is an unknown variable whose
optimal value is to be decided by the auto-tuner, defined in a program using the keyword hole. The
hole takes as arguments the type of the hole (either Boolean or IntRange) and its default value.
Additionally, the IntRange type expects a minimum and maximum value.

Example 2.1. To illustrate the idea of a hole, we first give a small example illustrating how to
choose sorting algorithms based on input data length. Consider the following program, implemented
in the Miking core language1:

let sort = lam seq.

let threshold = hole (IntRange

{default = 10, min = 0, max = 10000}) in

if leqi (length seq) threshold then insertionSort seq
else mergeSort seq
The example defines a function sort using the let construction. The function has one parameter
seq, defined using an anonymous lambda function lam. Lines 2–3 define a hole with possible values
in the range [0, 10000] and default value 10. The program then chooses to use insertionSort if the
length of the sequence is less than the threshold, and mergeSort otherwise. That is, an auto-tuner
can use offline profiling to find the optimal threshold value that gives the overall best result. Note
□
also that the default value can be used if the program is compiled without the tuning stage.

The example above illustrates the use of a global hole, i.e., a hole whose value is chosen globally
in the program. Although global holes are useful, they do not take into consideration the calling
context.

2.3 Context-Sensitive Holes
All holes that are explicitly stated in the program code using the hole syntax represent base holes.
As illustrated in the previous example, a base hole that does not take into consideration the calling
context is the same thing as a global hole. One of the novel ideas in this paper is the concept of
context-sensitive holes. In contrast to a global hole, the value of a context-sensitive hole varies
depending on which call path is taken to the place in the program where the hole is defined. They

1We use the Miking core language in the rest of the paper because the experimental evaluation is implemented in Miking.
The concepts and ideas presented in the paper are, however, not bound to any specific language or runtime system.

1

2

3

4

5

4

Trovato and Tobin, et al.

are useful in programs where we believe the optimal value of the hole varies depending on the
context. Context-sensitive holes are implicitly defined from a base hole, taking into consideration
the different possible call paths reaching the base hole. The idea is illustrated with the following
example.

Example 2.2. Consider the higher-order function map, which applies a function f to all elements
in a sequence s. The function can be applied either sequentially or in parallel (given that f is
side-effect free). The optimal choice between the sequential or parallel version likely depends
partly on the length of the sequence, but also on the nature of the function f. In a large program, a
common function such as map is probably called from many different places in the program, with
varying functions f and sequences. Therefore, globally deciding whether to use the sequential or
□
parallel version may result in suboptimal performance.

To define a context-sensitive hole, we provide an additional (optional) field depth, which repre-
sents the length of the most recent function call history that should influence the choice of the
value of the hole.

Example 2.3. The following is an implementation of map that chooses between the parallel and

sequential versions (pmap and smap, respectively).

let map = lam f. lam s.

let par = hole (Boolean {default = false, depth = 1}) in
if par then pmap f s else smap f s

Line 2 defines a Boolean hole par with default value false (no parallelization). The depth = 1 tells
the tuner that the value of par should consider the call path one step backward. That is, two calls
□
to map from different call locations can result in different values of par.

Example 2.4. Given that we choose the parallel map pmap in Example 2.3, another choice is how
many parts to split the sequence into, before mapping f to each part in parallel. We can implement
this choice with an integer range hole that represents the chunkSize, i.e. the size of each individual
part.

let pmap = lam f. lam s.

let chunkSize = hole (IntRange

{default = 10000, depth = 2, min = 1, max = 1000000000}) in

let chunks = split s chunkSize in
let tasks = smap (lam chunk.

async (lam. smap f chunk)) chunks in

join (smap await tasks)

Function split splits the sequence s into chunks of size (at most) chunkSize, that async sends the
tasks to a thread pool, and that await waits for the tasks to be finished.

Note the choice of depth = 2 in this example. We expect the function pmap to be called from
map, which has depth = 1. Since we want to capture the context from map we need to increment
□
the depth parameter by one.

The choice of the depth parameter for a hole should intuitively be based on the number of
function calls backward that might influence the choice of the value of the hole. A larger depth
might give a better end result, but it also gives a larger search space for the automatic tuner, which
influences the tuning time.

Note that in order to use global holes to encode the same semantics as the context-sensitive holes,
we need to modify the function signatures. For example, in Example 2.3, which has a hole of depth
1, we can let map take par as a parameter, and pass a global hole as argument each time we call map.

1

2

3

1

2

3

4

5

6

7

Programming with Context-Sensitive Holes using Dependency-Aware Tuning

5

For holes of depth 𝑑 > 1, this strategy becomes even more cumbersome, as each function along
a call path need to pass on global holes as arguments. By instead letting the compiler handle the
analysis of contexts, we do not need to modify function signatures, and we can easily experiment
with the depth parameter. Additionally, holes can be “hidden” inside libraries, so that a user does
not need to be aware of where the holes are defined, but still benefit from context-sensitive tuning.
Another advantage of context-sensitive holes compared to global holes is that the compiler may
use the knowledge that two context holes originate from the same base hole to speed up the tuning
stage.

3 PROGRAM TRANSFORMATIONS
This section covers the program transformations necessary for maintaining the context of each
hole during runtime of the program. The aim of the program transformations is that the resulting
program maintain contexts at a minimum runtime overhead. Sections 3.1 and 3.2 provide definitions
and a conceptual illustration of contexts, while Section 3.3 covers the implementation in more
detail.

3.1 Definitions
Central in our discussion of contexts are call graphs. Given a program 𝑝 with holes, its call graph is
a quintuple 𝐺 = (𝑉 , 𝐸, 𝐿, 𝑆, 𝐻 ), where:

• the set of vertices 𝑉 represents the set of functions in 𝑝,
• each edge 𝑒 ∈ 𝐸 is a triple 𝑒 = (𝑣1, 𝑣2, 𝑙) that represents a function call in 𝑝 from 𝑣1 ∈ 𝑉 to

𝑣2 ∈ 𝑉 , labeled with 𝑙 ∈ 𝐿,

• 𝐿 is a set of labels uniquely identifying each call site in 𝑝; that is: |𝐸| = |𝐿|,
• 𝑆 ⊆ 𝑉 is the set of entry points in the program,
• the triple 𝐻 = (𝑛, 𝛿, 𝜂) contains the number 𝑛 of base holes; a function 𝛿 : [1, 𝑛] → N, which
maps each base hole to its depth parameter; and a function 𝜂 : [1, 𝑛] → 𝑉 , which maps each
base hole to the vertex 𝑣 ∈ 𝑉 in which the hole is defined.

Furthermore, a call string in a call graph is a string from the alphabet 𝐿, describing a path in the
graph from a start vertex 𝑣𝑠 ∈ 𝑆 to some end vertex 𝑣𝑒 ∈ 𝑉 . Let CS𝑖 denote the set of call strings of
the 𝑖th hole, that is, the set of call strings starting in some vertex 𝑣𝑠 ∈ 𝑆 and ending in 𝜂 (𝑖) ∈ 𝑉 .

Example 3.1. The call graph in Figure 1 is the quintuple:

({𝐴, 𝐵, 𝐶, 𝐷 },
{(𝐴, 𝐵, 𝑏), (𝐴, 𝐶, 𝑎), (𝐵, 𝐶, 𝑓 ), (𝐶, 𝐶, 𝑒), (𝐶, 𝐷, 𝑐), (𝐶, 𝐷, 𝑑)},
{𝑎, 𝑏, 𝑐, 𝑑, 𝑒, 𝑓 },
{𝐴},
(1, {1 ↦→ 3}, {1 ↦→ 𝐷 }))

In Figure 1, note that we mark a base hole with its depth as a smaller circle within the vertex where
it is defined, that we mark each entry point of the graphs with an incoming arrow, and that there
are two function calls from 𝐶 to 𝐷, hence two edges with different labels. The set CS1 of call strings
from 𝐴 to 𝐷 in Figure 1 is:

ae∗c, ae∗d, bfe∗c, bfe∗d

where the Kleene-star (∗) denotes zero or more repetitions of the previous label.

□

6

Trovato and Tobin, et al.

Call strings provide the context that is rel-
evant for context-sensitive holes. Ideally, the
tuning should find the optimal value for each
call string in CS𝑖 leading to the 𝑖th hole. How-
ever, in Example 3.1 we see that there can be
infinitely many call strings, which means that
we would have infinitely many decision vari-
ables to tune. Therefore, we wish to partition
the call strings into equivalence classes, and
tune each equivalence class separately. This
leads to the question of how to choose the equivalence relation.

Fig. 1. Call graph representing a program with four
functions: 𝐴, 𝐵, 𝐶, and 𝐷. Each edge represents a func-
tion call from a certain call site in the program, and is
marked with a unique label.

One possible choice of equivalence relation is to consider two call strings that have an equal
suffix (that is, an equal ending) as being equal. We can let the length of the suffix be 𝑑, where 𝑑 is
the context depth of the hole:

Example 3.2. Let ∼𝑖 be an equivalence relation defined on each set CS𝑖 , such that:

𝑠1 ∼𝑖 𝑠2 iff suffix𝛿𝑖 (𝑠1) = suffix𝛿𝑖 (𝑠2), 𝑠1, 𝑠2 ∈ CS𝑖
where suffix𝑑 (𝑠) returns the last 𝑑 labels of a call string 𝑠, or all of the labels if the length of the
string is less than 𝑑. We choose a canonical representation from each equivalence class as the
result from the suffix𝑑 function. The call strings from Example 3.1 have the following canonical
representations (that is, unique results after applying suffix3 to the call strings):

ac, aec, eec, ad, aed, eed, bfc, fec, bfd, fed
Note that the canonical representations are suffixes of call strings but not always call strings by
strict definition, as they do not always start in a start vertex 𝑣𝑠 ∈ 𝑆. We call these canonical
□
representations context strings.

While the equivalence relation in Example 3.2 at least gives an upper bound on the number of
decision variables to tune, it may still result in a large number of equivalence classes. Limiting the
number of recursive calls that are considered results in a more coarse-grained partitioning:

Example 3.3. Consider the equivalence relation ∼𝑟

𝑖 , which is like ∼𝑖 from Example 3.2, but where
we consider at most 𝑟 repetitions of any label, for some parameter 𝑟 . That is, if a string contains
more than 𝑟 repetitions of a label, then we keep the 𝑟 rightmost occurrences. For example, using
𝑟 = 1 in the call strings of Example 3.1 yields the 8 context strings:

ac, aec, ad, aed, bfc, fec, bfd, fed
Note that compared to the context strings in Example 3.2, we have filtered out eec and eed as they
include more than 1 repetition of the label 𝑒. For example, this means that the two call strings aec
and aeec belongs to the same equivalence class, namely the class represented by the context string
□
aec.

Using the definition of context strings, we can finally define what we mean by context-sensitive
holes. Given some equivalence relation ∼, a base hole is expanded (by the compiler) into 𝑐 number
of context holes, where 𝑐 is the number of equivalence classes (i.e., the number of context strings)
under the relation ∼. If 𝛿 (𝑖) = 0, then the hole is global, and 𝑐 = 1. In Example 3.2, there are
10 context holes, and in Example 3.3 there are 8. Thus, the choice of the equivalence relation
influences the number of decision variables to tune: few equivalence classes give fewer variables to
tune and potentially a shorter tuning time, while more classes might increase the tuning time, but
give better performance of the resulting program.

Programming with Context-Sensitive Holes using Dependency-Aware Tuning

7

3.2 Graph Coloring for Tracking Contexts
Each time a context-sensitive hole is used, we need to decide which equivalence class the current
call string belongs to, in order to know which value of the hole to use. The challenge is to introduce
tracking and categorization of call strings in the program with minimum runtime overhead. A
naive approach is to explicitly maintain the call string during runtime. However, this requires
book keeping of auxiliary data structures and potentially makes it expensive to decide the current
context string. This section describes an efficient graph coloring scheme that leaves a color trail in
the call graph, thereby implicitly maintaining the call history during runtime of the program. We
first discuss the underlying equivalence relation that the method implements (Section 3.2.1), and
then divide our discussion of the graph coloring into two parts: complete programs (Section 3.2.2)
and separately compiled library code (Section 3.2.3).

3.2.1 Equivalence Relation. The equivalence relation that the graph coloring method implements
is an approximation of the ∼1
𝑖 relation of Example 3.3. The difference is that we do not track the
call string beyond a recursive (including mutually recursive) call. This is because a recursive call
overwrites the call history in graph coloring, as we will see in Section 3.2. The context strings for
the call strings from the previous section are:

ac, ec, ad, ed, bfc, bfd

Compared to the context strings in Example 3.3, the strings aed and fed are merged into ed, and
the strings aec and fec are merged into ec. A consequence is that, for instance, the call strings bfed
and aed belong to the same equivalence class, namely the class represented by ed.

Algorithm 3.1 describes how to explicitly compute the context strings for the 𝑖th hole. The
recursive sub-procedure ContextStringsDFS traverses the graph in a backwards depth-first
search manner. It maintains the current vertex 𝑣 (initially 𝜂 (𝑖)), the current string 𝑠 (initially the
empty string 𝜖), the set of visited vertices 𝑈 (initially ∅) and the remaining depth 𝑑 (initially 𝛿 (𝑖)).
Line 3 returns a singleton set if the depth is exhausted, if the set of incoming edges to 𝑣 is empty,

Algorithm 3.1 Algorithm for computing the context strings of a hole.

Input Call graph 𝐺 = (𝑉 , 𝐸, 𝐿, 𝑆, 𝐻 ), index 𝑖 of the base hole.
Output Set of context strings of the hole.

1: procedure ContextStrings(𝐺,𝑖)
2:

procedure ContextStringsDFS(𝑣, 𝑠, 𝑈 , 𝑑)

if 𝑑 = 0 ∨ inc(𝐺, 𝑣) = ∅ ∨ 𝑣 ∈ 𝑈 then return {𝑠}
else

CS ←

(cid:208)
(𝑣𝑝,𝑣,𝑙) ∈inc(𝐺,𝑣)

if 𝑣 ∈ 𝑆 then return CS (cid:208){𝑠}
else return CS

return ContextStringsDFS(𝜂 (𝑖), 𝜖, ∅, 𝛿 (𝑖))

3:
4:
5:

6:
7:

8:

ContextStringsDFS(𝑣𝑝, 𝑠 ⊕ 𝑙, 𝑈 (cid:208){𝑣 }, 𝑑 − 1)

or if 𝑣 is visited. The function inc(𝐺, 𝑣) returns the set of incoming edges to vertex 𝑣 in 𝐺. Line 5
recursively computes the context strings of the preceding vertices of 𝑣, and takes the union of the
results. The ⊕ operator adds a label to a string. Lines 6–7 return the final result. If the current
vertex 𝑣 is a start vertex, then the current string 𝑠 is a context string starting in 𝑣, and is therefore
added to the result. Otherwise, we return the result of the recursive calls.

8

Trovato and Tobin, et al.

3.2.2 Coloring a Complete Program. In the case of a complete program, the program has a single
entry point, for instance, a main function where the execution starts. We will now walk through a
number of examples, showing how graph coloring works conceptually.

Example 3.4. Figure 2a shows the initial coloring state of the call graph in Figure 1. For instance,
the vertex 𝐶 has three incoming edges (with colors blue (1), magenta (2), and green (3)), while 𝐷
has two (blue and magenta). Note that we can reuse a given color for several edges, as long as each
vertex does not have two incoming edges with the same color. For instance, the edges labeled 𝑎
□
and 𝑏 are both blue.

Algorithm 3.2 describes the update to the coloring when an edge is traversed in the call graph.
Line 2 updates the color of the destination vertex to the color of the label of the edge being traversed.

Algorithm 3.2 Traversing an edge.

Input A call graph 𝐺 = (𝑉 , 𝐸, 𝐿, 𝑆, 𝐻 ), coloring functions 𝑐𝑉 and 𝑐𝐿, and traversed edge
(𝑣1, 𝑣2, 𝑙) ∈ 𝐸.
𝑉 .
Output Modified coloring function 𝑐 ′

1: procedure TraverseEdge(𝐺, 𝑐𝑉 , 𝑐𝐿, (𝑣1, 𝑣2, 𝑙))
𝑐𝑉 ← (𝑐𝑉 \ {𝑣2 ↦→ 𝑐𝑉 (𝑣2)}) (cid:208){𝑣2 ↦→ 𝑐𝐿 (𝑙)}
2:
return 𝑐𝑉
3:

⊲ Overwrite previous mapping of 𝑣2 in 𝑐𝑉

Example 3.5. Figure 2b shows the state of the call graph after the call string ad is taken, and
□

Figure 2c shows the state after the call string bfed is taken.

(a) Initial state of the call graph when performing
graph coloring: all vertices are white, and each
edge is colored so that the colors of the incoming
edges for each node are different. For readability
on a black and white rendering of the figure, we
mark each edge with an integer representing the
color in addition to coloring the edge (1 for blue,
2 for magenta, and 3 for green).

(b) State of the call graph after the call string ad
is taken. For readability, for each non-white node
we write the integer representing the color in the
vertex in addition to coloring it.

(c) State of the call graph after the call string bfed
is taken. Because of the recursive call in 𝐶, we
cannot trace the calls further backward from 𝐵.
The current context string is therefore 𝑒𝑑.

(d) A call graph with several entry points. Node 𝐶 ′
is a sentinel vertex that forwards external calls to
the internal vertex 𝐶. The call string ac has been
taken, immediately followed by call string 𝑐. The
current context string is 𝑐.

Fig. 2. Conceptual illustration of how the call history is maintained by coloring the call graph during runtime.

Programming with Context-Sensitive Holes using Dependency-Aware Tuning

9

When the value of a hole is used during runtime of the program, we check the current context
by following the colors of the vertices and edges backwards in the graph. The tracing stops when
we reach the depth of the hole, when we reach a white vertex, or when we detect a cycle.

Example 3.6. To determine the current context string in Figure 2b, we first inspect the color of 𝐷
(magenta), which means that 𝑑 is the last label in the string. Next, we see that 𝐶 is blue, so 𝐶 was
called by 𝐴, thus 𝑎 is the second to last label. The color of 𝐴 is white, so we stop the tracing. Thus,
□
the context string is 𝑎𝑑.
Example 3.7. Similarly, in Figure 2c we determine that the last two labels are 𝑑 and 𝑒. Since 𝐶
□
called itself via 𝑒, we have detected a cycle. Thus, the context string is 𝑒𝑑.
3.2.3 Code Libraries. In contrast to a complete program, a separately compiled code library may
have several entry points, namely, the publicly exposed functions. Further, each entry point may
have incoming edges from internal calls within the library. This poses a problem for the coloring
scheme described thus far, illustrated in the following example.

Example 3.8. Assume that vertex 𝐶 in Figure 2a also is an entry point, along with vertex 𝐴. Then
the set of context strings listed in Section 3.2.1 is extended with c and d. The reason for this is that
a call directly to 𝐶 can result in the path 𝑐 or path 𝑑, without visiting any other edges. Further,
assume that the call string ac has been taken immediately before a call to 𝐶 is made and the call
string 𝑐 is taken. Then the coloring state of the graph would be like in Figure 2b, if we follow the
coloring scheme described thus far. From this state, we cannot determine whether the current
□
context string is ac or 𝑐.

A possible solution to this problem is shown in Figure 2d. For each library node (𝐶 in this
example), we add an sentinel vertex (noted with a prime) which directly connects to the original
entry point of the library. If a call is via an sentinel vertex, the next vertex is colored white. Hence, it
is possible to distinguish between if the call is coming from the library entry point or from another
vertex in the graph.

3.3 Implementation of Graph Coloring
The input to the program transformations is a program 𝑝 with holes, as well as the path to the
tune file. The output is a transformed program 𝑝𝑡 that performs graph coloring, and where each
base hole in 𝑝 has been replaced by code that statically looks up a value depending on the current
context. We discuss the program transformations in Section 3.3.1, and analyze the runtime overhead
of the transformed program in Section 3.3.3.

3.3.1 Program Transformations. During compile-time, we build a call graph 𝐺 as defined in Sec-
tion 3.1. A key idea is that we do need to maintain the call graph during runtime of the program; it
is only used for analysis during the program transformations.

In the transformed program, we introduce for each vertex 𝑣 ∈ 𝑉 ′, an integer reference 𝑟𝑣 whose

initial value is 0 (white).

The TraverseEdge procedure in Algorithm 3.2 is then implemented as a transformation. Imme-
diately before a function call from 𝑣1 to a function 𝑣2, where (𝑣1, 𝑣2, 𝑙) ∈ 𝐸 ′, we introduce an update
of the reference 𝑟𝑣2 to the color (i.e., integer value) that the edge (𝑣1, 𝑣2, 𝑙) is assigned to.

Finally, determining the current context string, as informally described in Examples 3.6 and 3.7
also requires a program transformation, which we call context expansion. In context expansion, we
replace each base hole in the program with code that first looks up the current context string, and
thereafter looks up the value of the associated context hole. Determining the current context string
for a hole of depth 𝑑 requires checking the values of at most 𝑑 integer references. For example, if
the following declaration of a base hole exists in vertex 𝐷 in Figure 1:

10

Trovato and Tobin, et al.

1

hole (Boolean {default = true, depth = 3})

then we replace it by the following program code:

1

2

3

4

5

6

7

8

9

10

11

12

13

14

switch deref 𝑟𝐷
case 1 then

switch deref 𝑟𝐶
case 1 then <lookup ac>
case 2 then <lookup bfc>
case 3 then <lookup ec>
end

case 2 then

switch deref 𝑟𝐶
case 1 then <lookup ad>
case 2 then <lookup bfd>
case 3 then <lookup ed>
end

end

where deref reads the value of a reference, each 𝑟𝑣 is the reference storing the color of function
𝑣, and each <lookup 𝑠> is code that looks up the value for the context hole associated with the
context string 𝑠. In the final tuned program, each <lookup 𝑠> is simply a static value: the value that
has been tuned for context 𝑠 (tuned compilation, see Section 6). During tuning of the program, each
<lookup 𝑠> is an access into an array that stores the values of the context holes contiguously. This
array is read as input to the program via the tune file, so that the program does not have to be
re-compiled during tuning (see Section 6 for more details). Note that a global hole (depth 0) can be
seen as having one context string, namely the empty string, and thus does not need any switch
statement.

3.3.2 Adaption to Parallel Execution. In a parallel execution setting, there might be more than one
active call string during each given time in the program. We make an adaption to the program
transformation in order to handle a fixed number of threads 𝑇 . Instead of introducing one reference
per (relevant) function, we introduce an array with 𝑇 number of references per (relevant) function.
Each thread 𝑡 is assigned an array index 𝑡𝑖 . Each thread uses the references at index 𝑡𝑖 only. In this
way, we maintain up to 𝑇 active context strings simultaneously. If a thread pool is used, then the
size of the thread pool needs to be known at compile-time. Otherwise, the transformation works as
described in Section 3.3.1.

3.3.3 Runtime Overhead in the Resulting Program. As a baseline for runtime overhead, consider
the original program 𝑝 where each base hole is replaced by its default value (default compilation,
see Section 6): we call this program 𝑝def . The overhead of the transformed program 𝑝𝑡 compared
to 𝑝def when the number of threads 𝑇 = 1, includes initializing at most one integer reference per
function. The program 𝑝𝑡 performs at most one reference update per function call. Moreover, 𝑝𝑡
performs at most 𝑑 number of matches on references in switch statements each time it uses the
value of a hole, where 𝑑 is the depth of the hole. The underlying compiler can transform the switch
statements into an indexed lookup table. This lookup table is compact by construction, as we use
contiguous integers as values representing colors. When 𝑇 > 2, then 𝑝𝑡 introduces at most one
array of references per function, and each reference update and reference read includes an indexing
into an array.

1

2

3

4

5

6

7

8

9

10

11

12

13

14

Programming with Context-Sensitive Holes using Dependency-Aware Tuning

11

4 STATIC DEPENDENCY ANALYSIS
This section discusses static dependency analysis. The goal is to detect holes that can be tuned
independently of each other. This information is later used during tuning in order to reduce
the search space. Section 4.1 motivates the need of dependency analysis and provides intuition,
Section 4.2 makes necessary definitions that are used in Section 4.3, which describes the details of
the dependency analysis. Finally, Section 4.4 describes how the program is instrumented given the
result of the dependency analysis.

4.1 Motivation and Running Example
Consider the following 𝑘-nearest neighbor (𝑘-NN) classifier, which will be our running example in
this section:

let knnClassify = lam k: Int. lam data: [([Int],Label)]. lam query: [Int].

−− Step 1: compute the distance to each point in the data set
let dists: [(Int,Label)] = map (lam d: ([Int],Label).

(euclideanDistance query d.0, d.1)

) data

in
−− Step 2: sort the distances in ascending order
let sortedDists: [(Int,Label)] = sort (

lam d1: (Int,Label). lam d2: (Int,Label). subi d1.0 d2.0

) dists

in
−− Step 3: return the most common label among the k nearest neighbors
let kNearest: [(Int,Label)] = subsequence sortedDists 0 k in
mostCommonLabel kNearest

The classifier takes three arguments: the parameter k of the algorithm; the data set, which is a
sequence of tuples (𝑑, 𝑙), where 𝑑 is a data point (representing an integer vector) and 𝑙 is the class
label; and the query data point, whose class label we want to decide.

The algorithm has three steps. In the first step, we compute the pairwise distances between the
query and each point in the data set, in this example using Euclidean distance. In step two, we
sort the pairwise distances. The first argument to the function sort is the comparison function,
which in this case computes the difference between two distances. In the last step, we extract the 𝑘
nearest neighbors by taking the 𝑘 first elements in the sorted sequence sortedDists. Finally, we
assume that the mostCommonLabel function returns the most frequent label in a sequence of labels,
so that the query point is classified to the most common class among its neighbors.

Now, assume that the 𝑘-NN classifier implicitly uses three holes. The first hole, ℎseq, is for
deciding the underlying data structure for the sequences. In the Miking core language, a sequence
can either be represented by a cons list, or a Rope [Boehm et al. 1995]. We can use a Boolean hole to
choose the representation when creating the sequence, by either calling the function createList or
createRope. The second hole, ℎmap, chooses between sequential or parallel code in the map function,
see Example 2.3. Finally, the third hole, ℎsort, chooses between two sorting algorithms depending
on an unknown threshold value, see Example 2.1.

When tuning the classifier, these three choices need to be taken into consideration. If the program
is seen as a black box, then an auto tuner needs to consider the combination of each of these choices.
In this small example, we quickly see that while some choices are indeed necessary to explore in
combination, others can be explored in isolation. Choices that must be explored together, called
dependent choices, are for instance: (i) the underlying sequence representation and the map function
(ℎseq and ℎmap); and (ii) the underlying sequence representation and the sort function (ℎseq and

12

Trovato and Tobin, et al.

ℎsort). In both cases, this is because the sequence representation affects the execution time of the
operations performed on the sequence in the respective function. On the other hand, the sort
function and the map function do not need to be explored in combination with each other: the holes
ℎmap and ℎsort are independent of each other. Regardless of what choice is made in the map function
(sequential or parallel), the result of the function is the same, which means that the sort function
should be unaffected.2

With knowledge about independencies, an auto tuner can use the tuning time in a more intelligent
way, as it does not need to waste time exploring unnecessary combinations of holes. The remainder
of this section describes how we can automatically detect (in-)dependencies such as the examples
discussed here, using static analysis.

4.2 Definitions
Before discussing the details of the dependency analysis, we need to define the entities that
constitute dependency: measuring points and dependency graphs.

4.2.1 Measuring Points. Intuitively, two holes are independent if they affect the execution time of
disjoint parts of the program. That is, we want to find the set of subexpressions of the program
whose execution times are affected by a given hole. There are often many such subexpressions. For
instance, the complete knnClassify in Section 4.1 is a subexpression whose execution time depends
on three holes: ℎseq, ℎmap, and ℎsort. Moreover, the subexpression on Lines 3–5 (the computation of
dists) in knnClassify depends on ℎseq and ℎmap. So how do we choose which subexpressions that
are relevant in the dependency analysis?

Clearly, it is not useful to consider too large subexpressions of the program. This is because two
holes ℎ1 and ℎ2 may affect a large subexpression 𝑒, even though they in reality only affect smaller,
disjoint subexpressions 𝑒1 and 𝑒2, respectively, where 𝑒1 and 𝑒2 are subexpressions of 𝑒. Therefore,
we want to find small subexpressions whose execution time depends on a given hole. We exemplify
the type of expressions we are interested in for knnClassify in Example 4.1, before going into
details.

Example 4.1. Assume that the map function is given by Example 2.3, and the sort function is
given by Example 2.1. A small subexpression affected by ℎmap is Line 3 in map (the if-then-else
expression), because which branch is taken is decided by the hole par. Similarly, the if-then-else
expression on Lines 4–5 in sort is a small subexpression affected by ℎsort. These two subexpressions
are also affected by ℎseq, because the execution times of the branches depend on the underlying
sequence representation. Furthermore, Line 13 in knnClassify is a minimal subexpression affected
by ℎseq, because the execution time of subsequence also depends on the underlying sequence
□
representation.

We call these small subexpression whose execution time depends on at least one hole a measuring
point. The rationale of the name is that we measure the execution time of these subexpressions by
using instrumentation (see Section 4.4). The Miking language, being a core language, consists of
relatively few language constructs; any higher-order language implemented on top of Miking will
compile down to this set of expressions. The type of expressions that construct measuring points
are either:

(1) a match statement (including if-then-else expressions); or
(2) a call to a function f x, where f is either a built-in function (such as subsequence), or

user-defined.

2We say should here as cache effects from map may still affect the execution time of sort.

Programming with Context-Sensitive Holes using Dependency-Aware Tuning

13

Section 4.3 clarifies under which circumstances these expressions are measuring points. Other types
of expressions in Miking, such as lambda expressions, constants, records, and sequence literals, are
not relevant for measuring execution time.

4.2.2 Dependency Graph. We now define dependency
graphs. Given a program 𝑝 with a set of context holes 𝐻 ,
and a set of measuring points 𝑀, its dependency graph is
a bipartite graph (𝐻, 𝑀, 𝐸). There is an edge (ℎ, 𝑚) ∈ 𝐸,
ℎ ∈ 𝐻 , 𝑚 ∈ 𝑀, iff the hole ℎ affects the execution time of
𝑚.

Example 4.2. A (partial) dependency graph of
knnClassify is given by Figure 3. It is partial because
there are more measuring points in the functions
mostCommonLabel and pmap (because they contain
sequence operations, whose execution times depend on
□
ℎseq), but these functions are omitted for brevity.

The dependency graph encodes the dependencies
among the program holes. For instance, in Figure 3, we
see that ℎseq and ℎmap are dependent, because they both
affect 𝑚2, while ℎmap and ℎsort are independent, because
they have no measuring point in common.

for

graph

3. Dependency

Fig.
the
knnClassify function in Section 4.1.
The set 𝐻 is the set of holes (the choice
of sequence representation, choice of
sequential or parallel map, and the choice
of sorting function, respectively). The set 𝑀
is the set of measuring points, where 𝑚1 is
Line 13 of knnClassify, point 𝑚2 is Line 3
of map, and 𝑚3 is Lines 4–5 of sort.

4.3 Dependency Analysis
The goal of the dependency analysis is to compute the dependency graph of a given program.

0-CFA analysis. The backbone of the dependency analysis is 0-CFA analysis [Nielson et al.
4.3.1
1999]. We extend standard 0-CFA analysis, which tracks data-flow of functions, to additionally
track data-flow of holes. The result is that we compute for each subexpression in the program the
set of holes that affect the value of the subexpression.

Standard data-flow rules apply. The first two columns of Table 1 shows the result of the data-flow
analysis for a few example subexpressions from knnClassify. We denote the data dependency of
a subexpression by the set of holes whose value the subexpression depends on. In the first row,
the variable query depends on ℎseq because the variable refers to a sequence whose representation
is decided by ℎseq. Second, the if-then-else expression from the map function depends on both
ℎseq and ℎmap, because the condition of the if-then-else depends on ℎmap, and the result of the
subexpression is again a sequence dependent on ℎseq. In the third row, the variable dists also
depends on both ℎseq and ℎmap, because the variable refers to the result of the map function. In the
fourth row, Lines 4–5 in Example 2.1 depends on all three holes. It depends on ℎsort because the
condition of the if-then-else depends on ℎsort. It depends on ℎseq and ℎmap because the branches of
the if-then-else manipulate the sequence referred to by dists. Finally, the call to subsequence also
depends on all holes, because the built-in function subsequence returns a sequence that will have
the same data dependency as its input sequence, sortedDists.

Recall that we are interested in subexpressions whose execution time (not value) depends on holes:
these are the measuring points of the program. Luckily, we can incorporate the analysis of measuring
points into the 0-CFA, by using the data-flow information of the holes. Besides data dependency,
we introduce another kind of dependency: execution time dependency. A subexpression with a
non-empty execution time dependency is a measuring point. There are two kinds of expressions

HMhseqhmaphsortm1m2m314

Trovato and Tobin, et al.

Table 1. Result of the dependency analysis for a subset of the subexpressions in knnClassify, using Ex-
amples 2.1 and 2.3 as implementations of sort and map, respectively. Columns 2–3 and 4–5 show the data
dependency and the execution time dependency of each subexpression, for a program without and with
annotations, respectively. We see that without the annotation, the analysis concludes that all three holes are
execution time dependent, while the version with annotations results in the dependency graph in Figure 3.

Without annotations

With annotations

Subexpression

Data dep.

Exe. dep.

Data dep.

Exe. dep.

query
if par then ... else ...
dists
Lines 4–5 in Example 2.1

subsequence sortedDists 0 k

{ℎseq}
{ℎseq, ℎmap}
{ℎseq, ℎmap}
{ℎseq, ℎmap, ℎsort}
{ℎseq, ℎmap, ℎsort}

∅
{ℎseq, ℎmap}
∅
{ℎseq, ℎmap, ℎsort}
{ℎseq, ℎmap, ℎsort}

{ℎseq}
{ℎseq}
{ℎseq}
{ℎseq}
{ℎseq}

∅
{ℎseq, ℎmap}
∅
{ℎseq, ℎsort}
{ℎseq}

that may give rise to execution time dependency, i.e., measuring points: match expressions, and
calls to functions.

Match Expressions. Given a match expression e on the form match e1 with pat then e2 else
e3, the following two rules apply: (1) If e1 is data-dependent on a hole ℎ, then e is execution
time-dependent on ℎ; and (2) If e2 executes (directly or via a function call) another subexpression
that is execution time-dependent on a hole ℎ, then e is also execution time-dependent on ℎ, and
the same applies for e3. The justification of rule 1 is that if the decision of which branch to take
depends on a hole, then the execution time of the match expression depends on the hole. The
justification of rule 2 is that the execution time of the whole subexpression e should include any
execution time dependencies of the individual branches.

The third column of Table 1 shows execution time dependencies of some subexpressions in
knnClassify. Rows 2 and 4 are match expressions. Note that in the Miking core language, an
if-then-else expression is syntactic sugar for a match expression where pat is true. The conditions
of the match expressions depend on ℎmap and ℎsort, respectively, thus these holes are included in the
execution time dependencies. The branches of each subexpression perform sequence operations,
which will be measuring points dependent on ℎseq. Thus, the execution time of the match expressions
also depends on ℎseq. The dependency on row 4 also includes ℎmap, because the input sequence,
dists, has a data dependency on ℎmap.

Function calls. If the expression e is the result of an application of a built-in function, then custom
rules apply for each built-in. For instance, for the expression subsequence s i j, if the sequence s
is data-dependent on a hole ℎ, then e is execution time-dependent on ℎ. The subsequence expression
in the last row of Table 1 has the same execution time dependency as its data dependency, by
following this rule.

In addition, for all function calls e on the form e1 e2, if e1 is data-dependent on a hole ℎ, then e
is execution time-dependent on ℎ. As a simple example, the function call (if h then f else g) x
is a measuring point, given that h is data-dependent on some hole. In other words, since the left
hand side of the application is determined by a hole, the execution time of the function call depends
on a hole.

Note that the function call on Lines 3–5 in knnClassify does not constitute a measuring point,
even though its execution time depends on ℎseq and ℎmap. The reason is that the function map itself
is not data-dependent on a hole. The relevant execution times of the map functions are already
captured by measuring points within the map function.

Programming with Context-Sensitive Holes using Dependency-Aware Tuning

15

4.3.2 Call Graph Analysis. The 0-CFA analysis finds the set of measuring points of the program
and attaches an initial set of dependencies to each measuring point. Some dependencies, however,
are not captured in the 0-CFA analysis. Namely, if a measuring point 𝑚1 executes another measuring
point 𝑚2, then the holes that affect 𝑚2 also affect 𝑚1. For instance, the expression if par then
pmap f s else smap f s executes any measuring points within the pmap and smap function. We
perform another analysis step that analyzes the call graph of the program, in order to find the set
of measuring points that each measuring point executes. This analysis step does not introduce any
new measuring points, but it adds more dependencies (edges in the dependency graph).

False Positives and Annotations. As we have seen so far, the dependencies (both for data and
4.3.3
execution time) on some subexpressions in Table 1 are unnecessarily large. For instance, the value
of the subexpression on row 2 should intuitively not depend on ℎmap. After all, whether the map
is performed in parallel or sequentially does not affect the final result. In other words, the data
dependency on ℎmap on row 2 is a false positive.

The result of false positives on data dependencies is that some execution time dependencies may
also be unnecessarily large. As we see in Table 1, the false positive on ℎmap on row 2 propagates to
the data dependency of row 3 (dists), which in turn affects the execution time dependencies of
rows 4 and 5.

While it is in general hard for a compiler to detect, for instance, that parallel and sequential code
gives the same end result, or that two sorting functions are equivalent, this information is typically
obvious for a programmer.

Therefore, we introduce the option to add annotations to a program to reduce the number of
false-positive dependencies. The annotation states the set of variables that a match expression is
independent of, and is added directly after a match expression using the keyword independent.
For instance, replacing Line 3 in Example 2.3 with independent (if par then pmap f s else
smap f s) par states that the value of the match expression is independent of the variable par. More
variables can be included in the set by nesting several independent annotations, e.g. independent
(independent <e> x) y.

By incorporating this information in the analysis, the data dependency on the independent set is
ignored for the match expression. Columns 4–5 in Table 1 show the result of the analysis given
that the match expressions on rows 2 and 4 have been annotated to be independent of the variables
par and threshold, respectively. We see that the execution time dependencies now match the
dependency graph in Figure 3. Row 2 in Table 1 corresponds to 𝑚2, row 4 corresponds to 𝑚3, and
row 5 corresponds to 𝑚1.

4.3.4 Context-Sensitive Measuring Points. A property of 0-CFA is that it does not include context
information for the data-flow, unlike 𝑘-CFA for 𝑘 > 0. While we are limited to 0-CFA for efficiency
reasons, it is necessary to consider the contexts of context-sensitive holes. Therefore, we consider
the context strings (see Section 3) during the dependency analysis.

As an example, consider the map function in Example 2.3. Assume that it is called from two
locations, so that there are two possible call strings for the hole par; 𝑠1 and 𝑠2. During analysis of
the measuring point on Line 3, we conclude that the execution time depends either on the context
hole associated with 𝑠1, or the one associated with 𝑠2, but not both. This is taken into account
during instrumentation of the program, see Section 4.4.

4.4 Instrumentation
The instrumentation is a program transformation step, where the input is the program 𝑝 and
the dependency graph 𝐺 = (𝐻, 𝑀, 𝐸). The output is an instrumented program 𝑝𝐼 that collects
execution time information for each measuring point. Section 4.4.1 introduces three challenges

16

Trovato and Tobin, et al.

when designing the instrumentation. In Section 4.4.2, we present the proposed design and clarify
how the design addresses the identified challenges.

4.4.1 Challenges. Assume that we wish to instrument the measuring point in row 2 in Table 1
on page 14: if par then pmap f s else smap f s. A naive approach is to save the current time
before and after the expression has been executed, and then record the elapsed time after the
expression has been executed.

However, there are a number of problems with this simple solution. First, the measuring point
can execute another measuring point. In this specific case, it executes any measuring points within
the pmap or smap functions. If we do not keep track of whether a measuring point executes within
another one, we will count some execution times several times, which gives an inaccurate total
execution time of the program. Second, this simple instrumentation approach does not allow for
tail-call optimizations. The reason is that after the transformation of the program, some operations
are performed after the execution of the measuring point. The result is that a recursive call
within the measuring point will no longer be in tail position. The third challenge has to do with
context-sensitivity. For instance, assume that map in Example 2.3 is called from two locations. The
instrumented code must then consider these two calling contexts when recording the execution of
the measuring point.

Solution. The instrumentation introduces a number of global variables and functions in the
4.4.2
program, maintaining the current execution state via a lock mechanism. Moreover, every measuring
point is uniquely identified by an integer. In particular:

• The variable lock stores the identifier of the measuring point that is currently running, where
the initial value 0 means that no measuring point is running. Note that we do not mean a
lock for parallel execution; we can still execute and measure parallel execution of code.
• The array s of length |𝑀 |, where s[𝑖] stores the latest seen start time of the 𝑖th measuring

point.

• The array log of length |𝑀 |, where log[𝑖] stores a tuple (𝑇 , 𝑛) where 𝑇 is the accumulated

execution time, and 𝑛 is the number of runs, of the 𝑖th measuring point.

• The function acquireLock takes an integer 𝑖 > 0 (a unique identifier of a measuring point)
as argument, and is called upon entry of a measuring point. If the lock equals 0, then the
function sets lock to 𝑖, and writes the current time to s[𝑖]. Otherwise, that is, if the lock is
already taken, the function does nothing.

• The function releaseLock also takes an integer identifier 𝑖 > 0 as argument, and is called
when a measuring point exits. If the lock equals 𝑖, then the function sets lock to 0, and adds
the elapsed execution time to the global log. If the lock is taken by some other measuring
point, the function does nothing.

After the instrumented program is executed, the array log stores the accumulated execution time
and the number of runs for each measuring point.

As a result, the measuring point in row 2 in Table 1 is replaced by the following lines of code:

1

2

3

4

acquireLock i;
let v = if par then pmap f s else smap f s in
releaseLock i;
v
The lock design addresses the first of the identified challenges: to keeping track of whether a
measuring point is executed within another one. Because only one measuring point can possess the
lock at any given moment, we do not record the execution if one executes within another. Thus, the
sum of the execution times in the log array never exceeds the total execution time of the program.

Programming with Context-Sensitive Holes using Dependency-Aware Tuning

17

(a) Dependency graph of a pro-
gram with fully dependent holes.
All 2𝑛 possible combinations
need to be taken into consider-
ation when tuning.

(b) Dependency graph of a pro-
gram with fully independent
holes. It is enough with 2 pro-
gram runs to exhaust the search
space if fine-grained instrumen-
tation of each measuring point is
used.

(c) Dependency graph that is nei-
ther fully dependent nor fully
independent. The number of re-
quired program runs with in-
strumentation is 2𝑟 , where 𝑟 is
the maximum number of holes
affecting any given measuring
point.

Fig. 4. Possible dependency graphs for a program with 𝑛 holes of Boolean type. In all cases, there are 2𝑛
number of possible configurations. However, the more independence, the fewer of these configurations need
to be considered when tuning.

We now consider the second challenge: allowing for tail-call optimization. For a measuring point
with a recursive call f x in tail position, for instance if <cond> then <basecase> else f x, the call
to releaseLock is placed in the base case only, so that the recursive call remains in tail position:

1

2

3

4

5

6

acquireLock i;
if <cond> then

let v = <basecase> in
releaseLock i;
v

else f x

There can be more than one call to releaseLock in each base case, because of measuring points
in mutually recursive functions. The instrumentation analyzes the (mutually) recursive functions
within the program and inserts the necessary calls to releaseLock in the base cases of these
functions.

The third challenge, dependency on context-sensitive holes, is addressed similarly as in Sec-
tion 3.3.1. Consider again the measuring point if par then pmap f s else smap f s in within
the map function, and assume that there are two possible calls to map. The measuring point is
assigned a different identifier depending on which of these contexts is active. The identifier is found
by a switch expression of depth 1, reading the current color of the map function. If there is only
one call to map, then the identifier is simply an integer, statically inserted into the program.

5 DEPENDENCY-AWARE TUNING
In contrast to standard program tuning, dependency-aware tuning takes the dependency graph
into account to reduce the search space of the problem. This section describes how to explore this
reduced search space, and how to find the expected best configuration given a set of observations.

HMh1h2hnm1...HMh1h2hnm1m2mn......HMh1h2hnmmm1m2h3......18

Trovato and Tobin, et al.

ℎ1
false
false

true
true

ℎ2
false
true

false
true

ℎ3
false
false

true
true

ℎ4
false
true

?
?

𝑚1 𝑚2 𝑚3
1
5
7
2
4
2
6
3
3
6

?
?

1
2
3
4

Table 2. Columns ℎ1–ℎ4 show the four possible combinations of values for the four holes in the dependency
graph in Figure 4c, for 𝑛 = 4 and 𝑚 = 3. Columns 𝑚1–𝑚3 show possible costs for the three measuring points.
The cost of a measuring point could for instance be the sum (in seconds) of the execution times over all
invocations of the measuring point. The ?s indicate that we may choose any value for ℎ4 in iteration 3 and 4,
since we have already exhausted the sub-graph consisting of ℎ4 and 𝑚3. Note that the four combinations
listed in the table are not unique. For instance, we may shift the values in the ℎ1 column one step to produce
another table. However, there are never more than four necessary combinations to evaluate.

5.1 Reducing the Search Space Size
In standard program tuning (without dependency analysis), each hole needs to be tuned in combi-
nation with every other hole, which means that the number of configurations to consider grows
exponentially with the number of holes.

Example 5.1. Consider a program with 𝑛 Boolean holes, which has a search space of size 2𝑛.
With no dependency analysis, we may view the program as consisting of one measuring point,
affected by all the holes in the program. This corresponds to the dependency graph in Figure 4a. If
exhaustive search is used, then 2𝑛 program runs are required to find the optimal configuration. □

Dependency analysis finds the fraction of the total number of configurations that are relevant to

evaluate during tuning, as illustrated in Examples 5.2 and 5.3.

Example 5.2. Consider the program from Example 5.1. Figure 4b shows a dependency graph
where all the holes are completely independent, so that each measuring point is affected by exactly
one hole. If instrumentation is used, we collect the execution time for each measuring point in
isolation. In this case, it is enough to run 2 configurations to exhaust the search space. For example,
we can run one configuration where all holes are set to true, and one where they are set to false.
After this, the optimal configuration is found by considering the results for each hole in isolation
and determining whether its value should be true or false.

If end-to-end time measurement is used for the dependency graph in Figure 4b, then 𝑛 + 1
program runs is required. For example, one run where all holes are set to false, followed by 𝑛 runs
□
where each hole at a time is set to true, while keeping the remaining holes fixed.

Example 5.3. Again considering the program from Example 5.1, Figure 4c shows a scenario where
the holes are neither fully dependent nor fully independent. Assume that 𝑛 = 4 and 𝑚 = 3, so
that the dependency graph contains only the holes and measuring points that are visible (without
the “. . .” parts). There are at most 2 holes that affect any given measuring point, and each hole
has 2 possible values. Therefore it is enough to consider 2 · 2 = 4 configurations. For example,
we may consider the ones listed in Table 2, though this table is not unique. Note that the table
contains all combinations of values for {ℎ1, ℎ2}, for {ℎ2, ℎ3}, and for {ℎ4}, respectively. However,
some combinations of {ℎ1, ℎ3} are missing, because ℎ1 and ℎ3 do not have any measuring point in
□
common.

Programming with Context-Sensitive Holes using Dependency-Aware Tuning

19

We define the reduced search space size given a dependency graph (𝐻, 𝑀, 𝐸) as:
|dom(ℎ)|, where dom(ℎ) denotes the domain, that is, the set of possible values, for a

max
𝑚 ∈𝑀
hole ℎ. Applying this formula to Example 5.3 gives 22 = 4 configurations, as expected.g

(cid:206)
(ℎ,𝑚) ∈𝐸

5.2 Choosing the Optimal Configuration
This section considers how to choose the optimal configuration, given an objective value to be
minimized and the observed results of a set of hole value combinations. Specifically, we assume
that we have: a dependency graph 𝐺 = (𝐻, 𝑀, 𝐸); a configuration matrix 𝐶 of dimension 𝑟 × |𝐻 |,
where 𝐶 [𝑖, 𝑗] gives the value of the 𝑗th hole in the 𝑖th iteration (compare columns ℎ1–ℎ4 in Table 2);
a number of observation matrices 𝑂𝑘 , each with dimension 𝑟 × |𝑀 |, for 𝑘 in some set of measures 𝐾.
For the rest of this section, we assume that there is only one measure, namely accumulated execution
time. Thus, we denote the only observation matrix by 𝑂. That is, 𝑂 [𝑖, 𝑗] gives the accumulated
execution time for the 𝑗th measuring point in the 𝑖th iteration (compare columns 𝑚1–𝑚3 in Table 2).
The problem is to assign each hole in 𝐻 to values in their domains, such that the objective
function is minimized, where the objective function is built from the observation matrices. In this
section, we assume that the objective is to minimize the sum of the accumulated execution times
for the measuring points. However, the approaches discussed here are general enough to handle
any number of observation matrices, with some other custom objective function.

Before presenting two general approaches for solving this problem, we consider how to solve it

for the example in Table 2:

Example 5.4. Consider the results for the measuring points 𝑚1, 𝑚2, and 𝑚3 in Table 2. At first
glance, the optimal configuration seems to be configuration 2, since it has the lowest total execution
time, namely 8 s, out of the four options (regardless of the value of ℎ4 in iteration 3 and 4, the total
value will exceed 8). However, the first improvement to this is that we can choose the value of
ℎ4 independently of the values of the other holes, since ℎ4 is disjoint from the other holes in the
dependency graph. We see that the best value for ℎ4 is false, giving 𝑚3 the execution time 1 s. The
second improvement is that we can choose the value of ℎ1 independently of the value of ℎ3. With
this in mind, the best values for ℎ1, ℎ2, and ℎ3 is false, true, and true, respectively. This gives 𝑚2
and 𝑚3 the execution times 2 s and 3 s, respectively. Thus, the optimal configuration is one that is
□
not explicitly listed in the table, and has the estimated cost of 6 s.

The first approach is to consider each possible combination explicitly and pick the combination
giving the lowest total execution time. As an optimization, we can consider each disjoint part (that
is, each connected component) of the dependency graph separately. In the example in Table 2, this
means that we create one explicit matrix for the connected component consisting of the vertices
{ℎ1, ℎ2, ℎ3, 𝑚1, 𝑚2} and one for the connected component with vertices {ℎ4, 𝑚4}. That is, we would
infer the matrix in Table 3 for the measuring points 𝑚1 and 𝑚2, and similarly a matrix with two
rows for 𝑚3. From these explicit matrices, we can directly find that the minimum expected cost is 6,
when ℎ1 = false, ℎ2 = true, ℎ3 = true, and ℎ4 = false.

Although the complexity of the explicit approach scales exponentially with the number of holes,
we observe in our practical evaluation that this step is not a bottle neck for performance of the
tuning. However, if this were to become a practical problem in the future, this problem can be
solved in a more efficient way by formulating it as a constraint optimization problem (COP) [Rossi
et al. 2006]. There exist specialized constraint programming solvers (CP solvers), that are highly
optimized for solving general COPs, for instance Gecode [Gecode Team 2006] and OR-Tools [Perron
and Furnon 2019]. The problem of choosing the optimal configuration given a set of observations
can be expressed and solved using one of these solvers.

20

Trovato and Tobin, et al.

ℎ1
false
false

false
false
true
true
true
true

ℎ2
false
false

true
true
false
false
true
true

ℎ3
false
true

false
true
false
true
false
true

𝑚1 𝑚2
5
7
6
7
4
2
3
2
5
3
6
3
4
6
3
6

1
2
3
4
5
6
7
8

Table 3. Explicit listing of expected results for 𝑚1 and 𝑚2. The combinations in rows 2, 4, 5, and 7 have never
been run; they are inferred from the observations in Table 2, taking the dependency graph into account.

Fig. 5. There are three possible flows through the Miking compiler toochain: default compilation (green solid
arrows); tuned compilation (dotted magenta-colored arrows); and tuning (dashed blue arrows). Sections 6.2–
6.4 give a detailed explanation of each flow. In the figure, artifacts are marked grey and has sharp corners,
while transformations are white and rounded.

5.3 Exploring the Reduced Search Space
In the experimental evaluation of this paper, we have implemented exhaustive search of the reduced
search space. As an additional step in the search space reduction, the tuner can optionally focus on
the measuring points having the highest execution times. These measuring points are found by
executing the program with random configurations of the hole values a number of times, and finding
the measuring points with the highest mean execution times. This optional step reduces the search
space additionally in practical experiments. Of course, there exist other heuristic approaches for
exploring the search space, such as tabu search or simulated annealing. Evaluating these approaches
is outside the scope of this paper, but they can be implemented in our modular tuning framework.
In Section 6, we see that modularity is a key concept of the Miking language.

6 DESIGN AND IMPLEMENTATION
We implement the methodology of programming with holes into the Miking compiler toolchain [Bro-
man 2019]. Figure 5 shows the design of the implementation. In this section, we first discuss the
overall design of the toolchain, and then go through the three possible flows through it: default
compilation; tuned compilation; and tuning.

MCoreSourceCodeTuneFileTuneFileExecutableGraphColoringDependencyAnalysis&InstrumentationContextExpansionDependencyGraphContextInformationOfflinetuningTuningExecutableMikingcompilerDefaultcompilationTunedcompilationTuningTuneFileTunerInputdataProgramming with Context-Sensitive Holes using Dependency-Aware Tuning

21

6.1 The Miking Compiler Toolchain
Miking is a general language system for developing domain-specific and general-purpose languages.
The Miking compiler is self-hosting (bootstrapped with OCaml). The core language of the Miking
system is called MCore (Miking Core) and is a small functional language. A key language feature
of MCore is language fragments. A language fragment defines the abstract syntax and semantics of
a fragment of a programming language. By composing several language fragments, new languages
are built in a modular way. To extend the Miking compiler toolchain with holes, we create a new
language fragment defining the abstract syntax and semantics of holes, and compose this fragment
with the main MCore language. The holes are transformed away before the compilation of the
program. The motivation for implementing our methodology in Miking is partly because the system
is well-designed for implementing language extensions and program transformations, and partly
because the methodology can be incorporated in any language developed in Miking.

The Miking toolchain consists of approximately 300 files and 55, 000 lines of MCore code (out
of which approx. 30% is either blank lines or comments). The contribution of this paper is the
part implementing holes (including language extensions, program transformations, tuning, tuned
compilation and dependency analysis). This part consists of 18 files and approx. 5, 000 lines of code
(approx. 30% blank lines or comments).

6.2 Default Compilation
The green solid path in Figure 5 shows default compilation. In this path, each hole in the program
is statically replaced by its default value. The resulting program is compiled into an executable.
Default compilation is useful during development of a program, as tuning can take considerately
longer time than default compilation.

6.3 Tuned Compilation
The dotted magenta-colored path in Figure 5 shows tuned compilation. In this scenario, the program
and the tune file are given as input to the graph coloring, followed by context expansion (Section 3).
The context expansion statically inserts the tuned values for each context into the program. Finally,
the program is compiled into an executable. Tuned compilation is done after tuning has been
performed, in order to create an executable where the holes are assigned to the tuned values.
Optionally, tuned compilation can be performed automatically after tuning.

6.4 Tuning
The blue dashed flow in Figure 5 shows the offline tuning. The program and the tune file (optional)
are given as input to the graph coloring. If the tune file is provided, then these values are considered
defaults, instead of the values provided via the default keyword. The graph coloring outputs (i)
context information about the holes, which is used in the offline tuning, and in later transformation
stages, and (ii) a transformed program. Next, the dependency analysis and instrumentation (Sec-
tion 4) computes a dependency graph, which is also used in the offline tuning, and an instrumented
program. The last transformation stage, context expansion, replaces each hole with code that
looks up its current calling context. The context expansion sends the context information and the
dependency graph to the offline tuning, and the transformed program to the Miking compiler. The
Miking compiler creates an executable to be used during tuning, the (tuning executable). The offline
tuning takes the context information, dependency graph, tuning executable, and a set of input
data as input. The tuner maintains a temporary tune file, which contains the current values of the
holes. In each search iteration, the tuning executable reads these values from the file, and the tuner

22

Trovato and Tobin, et al.

measures the runtime of the program on the set of input data. When the tuning finishes, the tuner
writes the best-found values to a final tune file.

The tuner first reduces the search space using the dependency graph and then applies dependency-
aware tuning (Section 5). The stopping condition for the tuning is configurable by the user and is
either a maximum number of search iterations, or a timeout value.

7 EMPIRICAL EVALUATION
This section evaluates the implementation. The purpose is to demonstrate that the approach
scales to real-world use cases, and to show that context-sensitive holes are useful in these settings.
Specifically, we evaluate the following claims:
Claim 1: We can express implementation choices in real-world and non-trivial programs using

context-sensitive holes.

Claim 2: Dependency analysis reduces the search space of real-world and non-trivial tuning

problems.

The evaluation consists of three case studies of varying sizes and from different domains. Two
of the case studies, probabilistic programming and Miking compiler, are real-world applications
not originally written for the purpose of this evaluation. The third case study, 𝑘-nearest neighbor
classification, is of smaller size, yet is a non-trivial program. The experiments are run under Linux
Ubuntu 18.04 (64 bits) on an Intel Xeon Gold 6148 of 2.40 GHz, with 20 cores, hyperthreading enabled
(2 threads per core). The computer has 64 GB RAM and a 1 MB L2 cache. As backend compiler for
the Miking compiler, we use the OCaml compiler available as an OPAM switch 4.12.0+domains.
At the time of writing, this is the latest OCaml compiler with multicore support.

7.1 𝑘-Nearest Neighbor Classification
This case study consists of a variant of the running example in Section 4, 𝑘-NN classification. Again,
we consider the three implementation choices of the underlying representation of sequence (ℎseq),
parallelization of the map function (ℎmap), and choice of sorting algorithm (ℎsort). We assume that
the performance of these choices depends on the size of the input data, and that we are interested in
tuning the classifier for a range of different sizes of the data set. We believe that for small data sets,
the sequence representation cons list is more efficient than Rope, the map function is more efficient
when run sequentially than in parallel, and that insertion sort is more efficient than merge sort,
respectively. However, we do not know the threshold values for these choices. Therefore, we let the
three base holes ℎseq, ℎmap and ℎsort be of type IntRange, representing the unknown threshold values.
For instance, assuming the ℎmap hole is called parThreshold, the following: if lti (length
seq) parThreshold then smap f seq else pmap f seq, encodes the choice for the map function.
We assume we are interested in data sets of sizes 103–105 points. We set the minimum and
maximum values of the holes accordingly to min = 103 and max slightly higher than 105, say
max = 101, 000, respectively. That is, the min value corresponds to making the first choice (e.g.,
sequential map) for all input sizes, while the max value corresponds to making the second choice
(e.g., parallel map) for all input sizes.

We generate 6 random sets of data points with dimension 3, in sizes in the range of interest:
103, 2 · 104, 4 · 104, 6 · 104, 8 · 104, 105. We use a step size of 2 · 104 when tuning, so that hole values
with this interval are considered.

The dependency analysis results are that the search space size is reduced by approx. 83% (from
216 to 36 configurations). The best found configuration for the threshold values were 21000,
1000, and 101000 for ℎmap, ℎsort, and ℎseq, respectively. That is, all input sizes except the smallest
runs map in parallel, all input sizes use merge sort, and all input sizes use cons lists as sequence

Programming with Context-Sensitive Holes using Dependency-Aware Tuning

23

Input size Execution time

Speedup

1000
20000
40000
60000
80000
100000

0.04
0.09
0.15
0.20
0.25
0.30

3.28
323.49
367.06
919.16
1056.70
1569.68

(a) Tuning results for the 𝑘-NN classifier. The mea-
surements are done on different data sets than
were used during tuning. The ’Input size’ column
shows the size of each data set. The ’Execution
time’ column shows the execution time in sec-
onds for the tuned program for a given input size.
The ’Speedup’ column presents the speedup of
the tuned program compared to the worst config-
uration. The worst configuration for each input
size is found by measuring the execution time of
the program when setting the threshold so that
it is below respectively above the given input size,
for each of the three holes. That is, in total there
are 8 (= 23
) candidate configurations for each
input size.

Sequential Parallel (worst)

Rope
List

16.8
18.4

1.96
1.94

(b) Speedup of the tuned probabilistic program.
The numbers show the speedup of the best found
configuration (Rope and parallel map using a
chunk size of 610 elements), compared to the
other configurations. The ’Rope’ and ’List’ rows
are using the respective sequence representation.
The ’Sequential’ column uses sequential map, and
the ’Parallel (worst)’ column uses parallel map
with the chunk size giving the worst execution
time. For both Rope and List, the worst choice for
the chunk size is 10 elements. The execution time
of each program is measured 10 times, and the
speedup is calculated as the ratio of the mean ex-
ecution time of the program divided by the mean
of the baseline. The execution time of the baseline
(the tuned program) is 7.1 ± 0.06 seconds (mean
and standard deviation over 10 runs).

Fig. 6. Results for the 𝑘-NN and the probabilistic programming case studies.

representation. Table 6a presents the execution time results of the tuned program compared to the
worst configuration. We see that the tuning gives between 3–1500 speedup of the program.

We note that for this case study, allowing for tail-call optimization in the instrumented program
(see Section 4.4) is of utmost importance. The sorting functions are tail recursive, so an instrumented
program without tail-call optimizations gives non-representative execution times, or even stack
overflow for large enough input sizes. The total time for the tuning is approx. 3.5 hours, and the
static analysis takes less than 100 ms.

7.2 Probabilistic Programming
This case study considers a probabilistic programming framework developed consisting of approx.
150 files and 1, 500 lines of MCore code. Note that the majority of this code is the standard MCore
code of the general purpose program and that the probabilistic programming parts consists of a
minimal extension. We focus on the inference backend of the framework, using the importance
sampling inference method. The inference is a core part of the framework, and is used when solving
any probabilistic programming model. We tune the underlying sequence representations and the
map function within the inference backend. The sequence representation is either cons list or Rope.
The map function chooses between a sequential or parallel implementation. In addition, we tune
the chunk size of the parallel implementation (see Example 2.4).

We use a simple probabilistic model representing the outcome of tossing a fair coin. The model
makes 10, 000 observations of a coin flip from a Bernoulli distribution, and infers the posterior
distribution, given a Beta prior distribution. We expect that the choices the tuner makes are valid
for a given model and number of particles used in the inference algorithm, because these two
factors are likely to influence the execution time of the map function. Once a given model is tuned,

24

Trovato and Tobin, et al.

however, it does not need to be re-tuned for other sets of observed data, as long as the number of
observations is the same.

We tune the model using 30, 000 particles for the inference algorithm. The tuner chooses to
use Rope as sequence representation in combination with parallel map with a chunk size of 610
elements. Table 6b shows the speedup of the best found configuration compared to the others. For
instance, we see that we get a speedup of 1.96 when using a chunk size of 610 for Rope compared
to using the worst chunk size (10). The total tuning time for the program is approx. 6 minutes.

7.3 Miking Compiler
This case study considers the bootstrapping compiler, a subset of the Miking compiler toolchain.
The purpose is to test the dependency for a problem of larger scale. For each sequence used within
the compiler, we express the choice of which underlying representation to use (Rope or list) using
a context-sensitive hole. By default, the compiler uses Rope. Because the main use of sequences
within the compiler consists of string manipulation, which is very efficient using Rope, we do not
believe there is much to gain from using lists. However, the purpose of this experiment is not to
improve the execution time of the compiler, but rather to show search space reduction. After the
context expansion, there are in total 2, 309 holes. That is, the size of the original search space is
22309. After applying dependency analysis, the search space is reduced to 2924. By filtering out all
measuring points that have a mean execution time of less then 10 ms, the search space is further
reduced to 2816. The total time of the static analysis is approx. 16 minutes, which is considerably
higher than for the previous case studies, due to the size of this program.

When performing this case study, we choose to disable the feature of the instrumentation
that allows for tail-call optimization, because of an identified problem with this feature. We only
observe this problem for this large-scale program; for the other case studies the correctness of the
instrumentation is validated manually and by assertions within the instrumented code.

7.4 Discussion
This section relates the claims with the results from the case studies, and discusses correctness of
possible hole values.

This evaluation considers two claims and three case studies. Claim 1, expressibility of implemen-
tation choices in real-world and non-trivial programs, is shown in all three case studies. Using holes,
we can encode the automatic selection of algorithms and data structures, as well as parallelization
choices. We can also encode dependencies on data size in the program, using threshold values. We
address Claim 2 in the 𝑘-NN classification and Miking compiler case studies. In both these cases,
the search spaces are considerably reduced. We observe, especially from the Miking compiler case
study, that a possible area for improvement in the dependency analysis is the call graph analysis
step (Section 4.3.2). The reason is that for a large program, dependencies from potential executions
nested measuring points within branches in match expressions quickly accumulates, giving a
quickly growing search space. By taking into account that the execution of the nested points are
only conditionally dependent on the condition of the match expressions, we can reduce the search
space further.

An essential and challenging aspect when programming in general is the functional correctness
of the program. When programming with holes, this aspect can become even more challenging, as
combinations of hole values form a (sometimes complicated) set of possible programs. The typical
software engineering approach for increasing confidence of correctness is to use testing. As it turns
out, testing can also aid us in the case of programming with holes. The MCore language has built-in
support for tests (via the language construct utest), and these are stripped away unless we provide
the –test flag. By providing the –test flag when invoking the tuning stage, the tuner will run the

Programming with Context-Sensitive Holes using Dependency-Aware Tuning

25

tests during tuning, using the currently evaluated hole values. The result is a slight degradation in
tuning time but no overhead in the final tuned binary. As a practical example, we use utests in the
𝑘-NN case study in this evaluation in order to ensure that the classifier indeed chooses the correct
class for some test data sets.

8 RELATED WORK
This section discusses related work within auto-tuners, by partitioning them into domain-specific
and generic tuners. We also discuss work using static analysis within auto tuning.

Many successful auto-tuners target domain-specific problems. SPIRAL [Franchetti et al. 2018] is a
tuning framework within the digital signal processing domain, ATLAS [Whaley 2011] tunes libraries
for linear algebra, FFTW [Frigo 1999] targets fast Fourier transforms, PetaBrikcs [Ansel et al. 2009]
focuses on algorithmic choice and composition, and the work by [Li et al. 2004] automatically
chooses the best sorting algorithm for a given input list. Moreover, within the area of compiler
optimizations, a popular research field is auto-tuning the selection and phase-ordering of compiler
optimization passes [Ashouri et al. 2019]. On the one hand, a natural drawback with a domain-
specific tuner is that it is not applicable outside of its problem scope, while generic tuners (such
as our framework) can be applied to a wider range of tuning problems. On the other hand, the
main strength of domain-specific tuners is that they can use knowledge about the problem in order
to reduce the search space. For instance, SPIRAL applies a dynamic programming approach that
incrementally builds solutions from smaller sub-problems, exploiting the recursive structure of
transform algorithms. Similarly, PetaBricks also applies dynamic programming as a bottom-up
approach for algorithmic composition, and the authors of [Li et al. 2004] include the properties
of the lists being sorted (lengths and data distribution) in the tuning. Such domain-dependent
approaches are not currently applied in our framework, because the tuner has no deep knowledge
about the underlying problem. We are therefore limited to generic search strategies. An interesting
research problem is investigating how problem-specific information can be incorporated into our
methodology, either from the user, or from compiler analyses, or both. Potentially, such information
can speed up the tuning when targeting particular problems, while not limiting the generalizability
of our approach.

Among the generic tuners, CLTune [Nugteren and Codreanu 2017] is designed for tuning the
execution time of OpenCL kernels, and supports both offline and online tuning. OpenTuner [Ansel
et al. 2014] allows user-defined search-strategies and objective functions (such as execution time,
accuracy, or code size). ATF [Rasch and Gorlatch 2019] also supports user-defined search strategies
and objectives and additionally supports pair-wise constraints, such as expressing that the value of
a variable must be divisible by another variable. The HyperMapper [Nardi et al. 2019] framework
has built-in support for multi-objective optimizations so that trade-off curves of e.g. execution time
and accuracy can be explored. Our approach is similar to these approaches as we have a similar
programming model: defining unknown variables (holes) with a given set of values. The difference
is that we support context-sensitive holes, while previous works perform global tuning.

There are a few previous approaches within the field of program tuning using static analysis
to speed up the tuning stage. For instance, to collect metrics from CUDA kernels in order to
suggest promising parameter settings to the auto tuner [Lim et al. 2017], or static analysis in
combination with empirical experiments for auto tuning tensor transposition [Wei and Mellor-
Crummey 2014]. To the best of our knowledge, there is no prior work in using static analysis
for analyzing dependency among decision variables. One prior work does exploit dependency to
reduce the search space [Schaefer et al. 2009], but their approach relies entirely on user annotations
specifying the measuring points, the independent code blocks of the program, permutation regions,

26

Trovato and Tobin, et al.

and conditional dependencies. By contrast, our approach is completely automatic, where the user
can refine the automatic dependency analysis with certain annotations, if needed.

9 CONCLUSION
In this paper, we propose a methodology for programming with holes that enables developers to
postpone design decisions and instead let an automatic tuner find suitable solutions. Specifically,
we propose two new concepts: (i) context-sensitive holes, and (ii) dependency-aware tuning using
static analysis. The whole approach is implemented in the Miking system and evaluated on non-
trivial examples and a larger code base consisting of a bootstrapped compiler. We contend that
the proposed methodology may be useful in various software domains, and that the developed
framework can be used for further developments of more efficient tuning approaches and heuristics.

ACKNOWLEDGMENTS
This project is financially supported by the Swedish Foundation for Strategic Research (FFL15-0032
and RIT15-0012). The research has also been carried out as part of the Vinnova Competence Center
for Trustworthy Edge Computing Systems and Applications (TECoSA) at the KTH Royal Institute
of Technology. We would like to thank Joakim Jaldén, Gizem Çaylak, Oscar Eriksson, and Lars
Hummelgren for valuable comments on draft versions of this paper. We also thank the anonymous
reviewers for their detailed and constructive feedback.

REFERENCES
Jason Ansel, Cy P. Chan, Yee Lok Wong, Marek Olszewski, Qin Zhao, Alan Edelman, and Saman P. Amarasinghe. 2009.
PetaBricks: a language and compiler for algorithmic choice. In Proceedings of the 2009 ACM SIGPLAN Conference on
Programming Language Design and Implementation, PLDI 2009, Dublin, Ireland, June 15-21, 2009, Michael Hind and Amer
Diwan (Eds.). ACM, 38–49. https://doi.org/10.1145/1542476.1542481

Jason Ansel, Shoaib Kamil, Kalyan Veeramachaneni, Jonathan Ragan-Kelley, Jeffrey Bosboom, Una-May O’Reilly, and
Saman P. Amarasinghe. 2014. OpenTuner: an extensible framework for program autotuning. In International Conference
on Parallel Architectures and Compilation, PACT ’14, Edmonton, AB, Canada, August 24-27, 2014, José Nelson Amaral and
Josep Torrellas (Eds.). ACM, 303–316. https://doi.org/10.1145/2628071.2628092

Amir H. Ashouri, William Killian, John Cavazos, Gianluca Palermo, and Cristina Silvano. 2019. A Survey on Compiler
Autotuning using Machine Learning. ACM Comput. Surv. 51, 5 (2019), 96:1–96:42. https://doi.org/10.1145/3197978
Hans-Juergen Boehm, Russell R. Atkinson, and Michael F. Plass. 1995. Ropes: An Alternative to Strings. Softw. Pract. Exp.

25, 12 (1995), 1315–1330. https://doi.org/10.1002/spe.4380251203

David Broman. 2019. A Vision of Miking: Interactive Programmatic Modeling, Sound Language Composition, and Self-
Learning Compilation. In Proceedings of the 12th ACM SIGPLAN International Conference on Software Language Engineering
(SLE ’19). ACM, 55–60.

Franz Franchetti, Tze Meng Low, Doru-Thom Popovici, Richard Michael Veras, Daniele G. Spampinato, Jeremy R. Johnson,
Markus Püschel, James C. Hoe, and José M. F. Moura. 2018. SPIRAL: Extreme Performance Portability. Proc. IEEE 106, 11
(2018), 1935–1968. https://doi.org/10.1109/JPROC.2018.2873289

Matteo Frigo. 1999. A Fast Fourier Transform Compiler. In Proceedings of the 1999 ACM SIGPLAN Conference on Programming
Language Design and Implementation (PLDI), Atlanta, Georgia, USA, May 1-4, 1999, Barbara G. Ryder and Benjamin G.
Zorn (Eds.). ACM, 169–180. https://doi.org/10.1145/301618.301661

Gecode Team. 2006. Gecode: A Generic Constraint Development Environment. Available from http://www.gecode.org/.
Holger H. Hoos. 2012. Programming by optimization. Commun. ACM 55, 2 (2012), 70–80. https://doi.org/10.1145/2076450.

2076469

Xiaoming Li, María Jesús Garzarán, and David A. Padua. 2004. A Dynamically Tuned Sorting Library. In 2nd IEEE / ACM
International Symposium on Code Generation and Optimization (CGO 2004), 20-24 March 2004, San Jose, CA, USA. IEEE
Computer Society, 111–124. https://doi.org/10.1109/CGO.2004.1281668

Robert V. Lim, Boyana Norris, and Allen D. Malony. 2017. Autotuning GPU Kernels via Static and Predictive Analysis. In
46th International Conference on Parallel Processing, ICPP 2017, Bristol, United Kingdom, August 14-17, 2017. IEEE Computer
Society, 523–532. https://doi.org/10.1109/ICPP.2017.61

Luigi Nardi, Artur L. F. Souza, David Koeplinger, and Kunle Olukotun. 2019. HyperMapper: a Practical Design Space
Exploration Framework. In 27th IEEE International Symposium on Modeling, Analysis, and Simulation of Computer

Programming with Context-Sensitive Holes using Dependency-Aware Tuning

27

and Telecommunication Systems, MASCOTS 2019, Rennes, France, October 21-25, 2019. IEEE Computer Society, 425–426.
https://doi.org/10.1109/MASCOTS.2019.00053

Flemming Nielson, Hanne Riis Nielson, and Chris Hankin. 1999. Principles of program analysis. Springer. https://doi.org/10.

1007/978-3-662-03811-6

Cedric Nugteren and Valeriu Codreanu. 2017. CLTune: A Generic Auto-Tuner for OpenCL Kernels. CoRR abs/1703.06503

(2017). arXiv:1703.06503 http://arxiv.org/abs/1703.06503

Laurent Perron and Vincent Furnon. 2019. OR-Tools. Google. https://developers.google.com/optimization/
Ari Rasch and Sergei Gorlatch. 2019. ATF: A generic directive-based auto-tuning framework. Concurr. Comput. Pract. Exp.

31, 5 (2019). https://doi.org/10.1002/cpe.4423

Francesca Rossi, Peter van Beek, and Toby Walsh (Eds.). 2006. Handbook of Constraint Programming. Foundations of Artificial

Intelligence, Vol. 2. Elsevier. https://www.sciencedirect.com/science/bookseries/15746526/2

Christoph A. Schaefer, Victor Pankratius, and Walter F. Tichy. 2009. Atune-IL: An Instrumentation Language for Auto-tuning
Parallel Applications. In Euro-Par 2009 Parallel Processing, 15th International Euro-Par Conference, Delft, The Netherlands,
August 25-28, 2009. Proceedings (Lecture Notes in Computer Science, Vol. 5704), Henk J. Sips, Dick H. J. Epema, and Hai-Xiang
Lin (Eds.). Springer, 9–20. https://doi.org/10.1007/978-3-642-03869-3_5

Lai Wei and John M. Mellor-Crummey. 2014. Autotuning Tensor Transposition. In 2014 IEEE International Parallel &
Distributed Processing Symposium Workshops, Phoenix, AZ, USA, May 19-23, 2014. IEEE Computer Society, 342–351.
https://doi.org/10.1109/IPDPSW.2014.43

R. Clint Whaley. 2011. Automatically Tuned Linear Algebra Software (ATLAS). In Encyclopedia of Parallel Computing,

David A. Padua (Ed.). Springer, 101. https://doi.org/10.1007/978-0-387-09766-4_2061

