Toward the Detection of Polyglot Files

Luke Koch
Bredesen Center
kochlr@ornl.gov

Mary Adkisson
Tennessee Tech University
adkissonma@ornl.gov

Brian Weber
Oak Ridge National Laboratory
weberb@ornl.gov

Sean Oesch
Oak Ridge National Laboratory
oeschts@ornl.gov

Sam Erwin
Paciﬁc Northwest National Laboratory
Samantha.erwin@pnnl.gov

Amul Chaulagain
Oak Ridge National Laboratory
chaulagaina@ornl.gov

2
2
0
2

r
p
A
3
1

]

R
C
.
s
c
[

4
v
1
6
5
7
0
.
3
0
2
2
:
v
i
X
r
a

Abstract—Standardized ﬁle types play a key role in the
development and use of computer software. However, it is possible
to abuse standardized ﬁle types by creating a ﬁle that is valid
in multiple ﬁle types. The resulting polyglot (many languages)
ﬁle can confound ﬁle type identiﬁcation, allowing elements of the
ﬁle to evade analysis. This is especially problematic for malware
detection systems that rely on ﬁle type identiﬁcation for feature
extraction. Although work has been done to identify ﬁle types
using more comprehensive methods than ﬁle signatures, accurate
identiﬁcation of polyglot ﬁles remains an open problem. Since
malware detection systems routinely perform ﬁle type-speciﬁc
feature extraction, polyglot ﬁles need to be ﬁltered out prior to
ingestion by these systems. Otherwise, malicious content could
pass through undetected. To address the problem of polyglot
detection we assembled a data set using the mitra tool. We
then evaluated the performance of the most commonly used ﬁle
identiﬁcation tool, file. Finally, we demonstrated the accuracy,
precision, recall and F1 score of a range of machine and deep
learning models. Malconv2 and Catboost demonstrated the high-
est recall on our data set with 95.16% and 95.45%, respectively.
These models can be incorporated into a malware detector’s ﬁle
processing pipeline to ﬁlter out potentially malicious polyglots
before ﬁle type-dependent feature extraction takes place.

I. INTRODUCTION

A. Overview

A polyglot is a form of steganographic ﬁle that can be
successfully interpreted in two or more types [1]–[3]. In other
words, a JPG+JAR polyglot is one that presents an image when
interpreted by an image viewer and executes self-extracting
Java code when fed to the Java Runtime Environment. Many
combinations are possible, including a polyglot that can be
interpreted as an image, a video, a PDF, and a video game
depending on which program interprets the polyglot [1]. As
we demonstrate in our results (section IV), common utilities
for identifying ﬁles do not reliably identify polyglots. Ergo,
malware detection systems that rely on common utilities for
ﬁle type identiﬁcation prior to feature extraction are vulnerable

Notice: This manuscript has been authored [or, co-authored] by UT-
Battelle, LLC, under contract DE-AC05-00OR22725 with the US Department
of Energy (DOE). The US government retains and the publisher, by accepting
the article for publication, acknowledges that the US government retains a
nonexclusive, paid-up, irrevocable, worldwide license to publish or reproduce
the published form of this manuscript, or allow others to do so, for US
government purposes. DOE will provide public access to these results of
federally sponsored research in accordance with the DOE Public Access Plan
(http://energy.gov/downloads/doe-public-access-plan).

to polyglot ﬁles. If a detector recognizes only the JPG portion
of a JPG+JAR polyglot, then two problems can arise.

• For ML/DL-based detecters, feature extraction will only

extract ﬁelds from the JPG portion of the ﬁle

• For signature-based detectors, only malware signatures

associated with JPG ﬁles will be matched [4]

In either instance, malicious code in the JAR portion passes
through without accurate analysis. In 2019, researchers at Oak
Ridge National Laboratory established that multiple commer-
cial off-the-shelf (COTS) malware detection systems failed to
detect 100% of polyglot malware in the data set [5]. These
polyglots were created by Assured Information Security as
part of their red team campaign. Motivated by this failure,
we compiled a data set of normal and polyglot ﬁles, trained
multiple classiﬁers on this data set, and evaluated the recall
and F1 score of these classiﬁers. Our objective is to protect
malware detection systems that rely on ﬁle type identiﬁcation
for feature extraction or signature sub-selection by developing
a model to ﬁlter polyglots out of the ﬁle processing pipeline.
This will allow COTS tools to ﬁlter out potentially malicious
polyglots while still beneﬁting from the rich information
provided by ﬁle type-speciﬁc feature extraction [6].

B. Motivation

Malware detection systems commonly rely on ﬁle type-
speciﬁc features in order to classify an unknown ﬁle as either
malicious or benign [6]. For example, the header of a PE ﬁle
contains a great deal of information about the ﬁle, e.g., the
read/write/execute ﬂags of all sections, the offset to the import
function table, and the address of the entry point. In a PDf ﬁle
the XREF table, if present, is a useful source of information
for determining which portions of the PDF could contain
malicious activity. If the XREF is not present or consistent
with the ﬁle contents, then malicious code can be found by
scanning for action objects that launch Javascript code [7],
[8]. In any event, knowing the ﬁle type allows the detector
to extract far more information than otherwise possible. If the
ﬁle type is not known, then only generic features like byte
entropy, n-grams, and strings can be used for classiﬁcation
[6].

In some instances, malware detectors will ignore ﬁles if
the ﬁle type has no known malicious capability. If a polyglot

 
 
 
 
 
 
ﬁle is identiﬁed as having only one ﬁle type, only that type
will be used for feature extraction and further analysis. File
sections from the undiscovered type will simply be ignored,
allowing potential malicious activity to go undetected or
misunderstood [4]. One solution is to forego ﬁle type-speciﬁc
feature extraction. However, this greatly reduces the number
of available manual features [6], [9]. Deep learning could be
used to perform automatic feature extraction that is effective
across all desired ﬁle types. However, this would require the
complete overhaul of a ﬁle type-speciﬁc malware detection
system. Instead, we propose simply adding a polyglot ﬁlter as
a pre-processing step for existing malware detection systems.
Provided the polyglot ﬁlter has sufﬁciently high recall, this
solution would require minimal alteration to existing solutions.
Furthermore, existing solutions would continue to beneﬁt from
the rich features that can be extracted once a ﬁle is known to
contain only one ﬁle type.

Aside from the afore-mentioned trial at ORNL, additional
evidence of the pressing need for polyglot detection is pro-
vided by a 2019 attack on DICOM ﬁles [10], [11]. DICOM
ﬁles are commonly used medical imaging ﬁles. The attack
involves the creation of a PE+DICOM polyglot that functions
as expected when loaded into medical imaging software, yet
is also capable of execution as a Windows PE ﬁle. The
DICOM type is intentionally ﬂexible; the authors anticipated
the creation of TIFF+DICOM polyglots for non-malicious pur-
poses [12]. However, this ﬂexibility lends itself well to more
malicious pursuits when the second ﬁle contains malicious
code.

Due to the wide variety of ﬁle types that exist, we felt
that a rule-based approach to polyglot detection would require
excessive revision and, at best, only account for previously-
encountered forms of polyglots. There are also a large number
of discrepancies in terms of malformed ﬁles that make the
rule-based approach difﬁcult [4].

In an attempt to create a solution that learns the general
problem and has the possibility of protecting against novel
polyglots, we decided to explore machine and deep learning
classiﬁers. This required the creation of a sizable training set
that includes a wide variety of existing polyglots. Before we
discuss this data set, we ﬁrst provide a detailed look at the
various types of polyglots that are included within it.

II. BACKGROUND

A. Polyglot Mechanics

Although there has been some academic research into ﬁle
type identiﬁcation methods (discussed in the related works
section II-B), polyglot creation has largely been driven by
researchers from industry [1], [2]. Ange Albertini demon-
strated multiple methods for creating polyglots at industry
presentations and released the python-native mitra tool on
Github to enable fellow researchers. We utilized this tool to
create our polyglot dataset. Albertini classiﬁed polyglots based
on the method used to combine donor ﬁles into the polyglot.
Ergo, mitra attempts to create stacks, zippers, parasites, and
cavities from pairs of donor ﬁles.

1) Stacks: A stack is the simplest type of polyglot. The
second ﬁle is simply appended to the end of the ﬁrst ﬁle. The
caveat is that any byte offsets in the second ﬁle may need to
be adjusted (increased by the length of the ﬁrst ﬁle) in order
for the second ﬁle to function as expected. Although there is
no restriction on the ﬁrst ﬁle, the second ﬁle must not strictly
enforce the magic number at offset zero rule. A magic number
is an arbitrary (hence the magic moniker) hexadecimal value
that uniquely identiﬁes a ﬁle type. This number is used for
fast ﬁle type identiﬁcation, since a utility need only scan the
ﬁrst few bytes of the ﬁle in order to identify it. However, there
are many ﬁle types that do not enforce this rule.

PDF readers commonly accept ﬁles as valid PDFs if the
magic number is anywhere within the ﬁrst 1024 bytes of the
ﬁle [1], [13] despite the requirement listed in the ofﬁcial docu-
mentation [14]. Additionally, some types have no requirement
at all for a magic number at offset zero. Zip ﬁles commonly
begin with a magic number. However, this number is part of
the local ﬁle header for the ﬁrst ﬁle contained within the Zip
archive. According to the speciﬁcations [15], the Zip ﬁle is
indexed via a central directory at the end of the ﬁle. This
central directory has its own magic number for identiﬁcation.
Ergo, Zip ﬁles have no requirement that any magic number
be the ﬁrst byte. This makes them an ideal candidate for the
second ﬁle in a stack polyglot.

2) Parasites: In a parasite polyglot, the second ﬁle is added
within comment sections—offset by comment markers—of the
ﬁrst ﬁle. Many ﬁle types allow for comment sections that are
not displayed when the ﬁle is interpreted. These comments
are only visible when the ﬁle is opened for editing by a hex
editor like vim. In order for the second ﬁle within the comment
sections of the ﬁrst ﬁle to remain functional, it must not have
the strict magic number at offset zero rule. The byte offsets
for both ﬁles must be updated. In the case of the ﬁrst ﬁle, the
byte offsets must now account for the second ﬁle contents that
are now hidden within the comment sections. In the case of
the second ﬁle, the offsets must account for the fact that the
second ﬁle contents are now scattered in comment sections of
the ﬁrst ﬁle. As long as these offsets are updated correctly, both
ﬁles will continue to function normally. Although this update
process is more complex than the updates necessary for a stack
polyglot, there are many ﬁle types than can combine to create
a parasite.

3) Zippers: Zippers are a more complex version of a
parasite. In a zipper, both ﬁles are contained within each
other’s comment sections. This means that the two donor ﬁles
must use different markers to begin and end their comment
sections. This arrangement is rather unusual in practice, so
donor ﬁles for zippers are much harder to ﬁnd. In our data
set, only DCM ﬁles combined with either GIF or PDF ﬁles
were able to create zipper polyglots.

4) Cavities: Cavities are created when the second ﬁle is
hidden within null-padded areas of the ﬁrst ﬁle. This arrange-
ment is only possible when the ﬁrst ﬁle is of an executable or
ISO type, wherein memory is allocated in chunks. Since these
areas are often null-padded to a standard size, executable or

ISO ﬁles may contain enough null-padded memory to hide
a second ﬁle in the padded areas. This is very similar to
the classic code caving technique often used by malware
authors to hide malicious code. The distinction between a
cavity polyglot and code caving is that the caved material of
a cavity polyglot is a complete ﬁle that can function correctly
when interpreted by an appropriate program. Since the ﬁrst 16
sectors of an ISO ﬁle are left empty, the contents of another ﬁle
can be placed in the beginning of the ISO ﬁle. For executable
ﬁles, like Windows PE ﬁles, the second ﬁle would be written
into the null-padded trailing areas at the end of sections. No
updates will be needed for the ﬁrst ﬁle, but any byte offsets
in the second ﬁle will need to be updated if the second ﬁle
does not begin at offset zero of the ﬁrst ﬁle.

B. Related Work

File type identiﬁcation has historically been addressed
through signatures. The Linux utility file matches ﬁles
by examining magic bytes in unison with other structural
elements. The magic number is an arbitrary hexadecimal
value that uniquely identiﬁes a ﬁle type. Some ﬁle types can
be strictly identiﬁed simply by their magic number, while
others require additional elements to be scanned. JAR ﬁles,
for instance, are simply Zip ﬁles with a MANIFEST.INF ﬁle
present in the archive. Ergo, file scans for the presence of
this ﬁle in order to distinguish a JAR ﬁle from a Zip ﬁle.
In either event, file matches each input ﬁle to a unique
signature. Note, file scans until it detects a match, then
halts. There is a --keep going ﬂag, but in our examination
it did not allow file to detect polyglots. The results of
running file (with this ﬂag active) on our polyglot data set
is included in section IV. The signatures that file utilizes
are extremely accurate and efﬁcient in identifying conventional
(monoglot) ﬁles, which means little research has been done to
improve on this winning formula.

McDaniels and Heydari used byte histograms in concert
with three different algorithms to identify ﬁle types [16].
Under the ﬁrst algorithm (byte frequency analysis or BFA),
they converted ﬁles into a ﬁxed length feature vector. All
ﬁles, regardless of type, can be represented as a sequence of
hexadecimal values. Therefore, we can compactly summarize
a ﬁle’s contents by placing the number of times each possible
hex value occurs into a 256 (all possible hexadecimal values)
character vector where the index corresponds to the byte value.
Ergo, the 7th value stored in the vector is the number of times
the value 0x7 occurred in the ﬁle. This feature is referred to
as a byte occurrence vector, unigram, or byte histogram in
literature. McDaniels and Heydari then normalized each byte
occurrence vector and calculated an average vector for each
ﬁle type. Each average vector represented a unique ﬁle type
and was referred to as a ﬁleprint. Test ﬁles were compared
to the ﬁleprint to calculate correlation scores. Finally, each
test ﬁle received its ﬁle type label from the most correlated
ﬁleprint.

Li et al. extended Mcdaniel’s work by using centroids rather
than an average vector as the representation of each ﬁle type

[17]. Files were classiﬁed based on their Mahalanobis distance
from a centroid. The centroids were chosen using the K-means
algorithm.

Karresand [18], Veenman [19], Fitzgerald [20], Beebe [21],
[22] all trained machine learning classiﬁers that used a wide
variety of statistical features extracted from ﬁles and frag-
ments, which included unigrams, bigrams, bag-of-words, byte
rate-of-change, Kolmogorov complexity, and common/longest
strings/bytes. Models developed included support vector ma-
chines, K-nearest neighbors, and hierarchical clustering. Beebe
released an open-source tool, Sceadan, which achieved 73.7%
accuracy on 30 ﬁle types and 8 data types by utilizing a linear
SVM trained on an input vector of unigrams concatenated with
bigrams. Unigrams simply the natural language processing
(NLP) term for the byte occurrence count vector or byte
histogram. Bigrams are a 256x256 matrix of co-occurrence
counts. This data is usually sparse and slow to compute [23].
More recently, deep learning has been used to detect the
type of ﬁle fragments. File fragments may contain a partial
signature or no signature at all, making rule-based approaches
useless. Moreover, deep learning has an advantage over other
learning algorithms thanks to its automatic feature extraction,
which allows deep models to train on raw bytes. Mittal et al.
built a deep learning model, FiFTY, to identify ﬁle fragments
in 2021 [23]. They trained a one-dimensional convolutional
neural network to identify 75 different ﬁle types. Although the
authors experimented with training neural networks and convo-
lutional neural networks on a vector of statistical features that
included Shannon entropy, Kolmogorov complexity, deviation,
skewness, kurtosis, and mean values (arithmetic, geometric,
harmonic) as features, raw bytes as the only input proved the
most accurate. Their model outscored Sceadan (77.5% acc vs
69.0% acc) on a data set of 75 ﬁle types, which was released
along with the FiFTY model.

In terms of cybersecurity, polyglot ﬁles are the subject of
a small number of research papers [4], [10], [11]. Jana and
Shmatikov detailed a wide variety of obfuscation methods
that
target discrepancies between how a malware detector
parses a ﬁle and how the OS interprets the ﬁle [4]. Some
of these discrepancies cause the detector to misidentify the
ﬁle type of the incoming ﬁle, resulting in the wrong subset of
malicious signatures being applied to the ﬁle. These methods
are referred to as Chameleon attacks [4]. Werewolf attacks
[4], on the other had, exploit discrepancies in how the ﬁle is
parsed. Jana and Shmatikov describe one type of Werewolf
attack as ’ambiguous ﬁles conforming to multiple types’ [4].
These are polyglot ﬁles by another name. The authors note
that a malicious TAR+ZIP stack-type polyglot was incorrectly
classiﬁed by 20 out of 36 malware detectors hosted on
Virustotal at that time.

C. Relation to this Work

Our work builds upon three of the methods presented above.
Our data set consists of polyglot ﬁles whose basic structure
was described by Jana and Shmatikov, albeit with a different
nomenclature. Courtesy of Mittal et. al, we train a one-

dimensional convolutional neural network on raw bytes. We
also train a variety of ML models on the byte count histogram
as detailed by McDaniels and Heydari.

III. METHODOLOGY

A. Polyglot Data Set

Our dataset, described in Table I, consists of 7 monoglot
or normal ﬁles types as the negative class and 21 polyglot
ﬁle types as the positive class with an 80/20 train/test split.
We should note that these polyglots do not contain malicious
code. Our objective is a polyglot ﬁlter, not a malware detector.
Additionally, the use of benign polyglots greatly simpliﬁes
data sharing.

TABLE I: Data Set Overview

Data Set
Monoglot
Polyglot

Train
31,199
25,210

Test
7,799
6,303

There are 3120 of each ﬁle type in the monoglot training
set and 780 of each ﬁle type in the test set. The monoglot ﬁle
types are as follows:

• PDF
• PNG
• GIF

• TIFF
• JPG
• DCM

• JAR
• Zip
• PE

• ISO

Feeding a subset of the above ﬁles to mitra, we created 21
different polyglot combinations. There are 1200 of each ﬁle
type combination in the training set and 300 in test set.

• DCM+GIF
• DCM+JAR
• DCM+ISO
• DCM+PDF
• DCM+Zi[
• GIF+ISO
• GIF+JAR

• GIF+Zip
• JPG+JAR
• JPG+Zip
• PE+ISO
• PE+JAR
• PE+Zip
• PNG+ISO

• PNG+JAR
• PNG+PDF
• PNG+Zip
• TIFF+ISO
• TIFF+JAR
• TIFF+PDF
• TIFF+Zip

Since each pair of ﬁle types can only be combined in certain
ways (stack, zipper, parasite, cavity), the number of each type
of polyglot in this data set is not balanced. Our future work
includes the production of a data set that is balanced according
to polyglot combination method rather than ﬁle type. Table II
contains the breakdown of polyglot combination methods in
our training and test sets.

TABLE II: Data Set Polyglot Combination Method

Polyglot Method
Stack
Parasite
Zipper
Cavity

Train
10267
10301
1795
2847

Test
2574
2542
463
724

B. Model Selection

We trained a wide variety of models to identify polyglot
ﬁles. Traditionally, machine learning models used in cyber
security applications rely on manual features that are spe-
ciﬁc to each ﬁle type [24], [25]. Since polyglot ﬁles can
confound ﬁle type-speciﬁc feature extraction, our models
are ﬁle type agnostic. In the case of ML models trained
through scikit-learn, the input vector consists of a byte
histogram. In other words, the feature vector is 256 integers
in length where the value at each index corresponds to the
number of times that index occurs as a byte value in the ﬁle.
Since ﬁles are stored internally as hexadecimal values (hence
256 possible values for each byte), this feature can be used
regardless of ﬁle type. The models we tested include random
forest, support vector machine, stochastic gradient descent,
light GBM, gradient boosting, and CatBoost.

We also trained and tested a deep learning model. Deep
learning via a convolutional neural network (CNN) utilizes
automatic feature extraction [26]–[29], making it ideally suited
for our task. The deep learning model we chose is designed
for binary (two class) classiﬁcation of binary (compiled) ﬁles,
namely, Malconv2 [28]. This model
is a one-dimensional
convolutional neural network developed for malware detection
whose feature vector consists of the raw bytes. The ﬁrst
Malconv model demonstrated that CNNs can be effective
malware classiﬁers [27]. However, it had some issues that
prompted the authors to develop a second, more effective
model.

Since Malconv reads in raw bytes as features, the input ﬁle
must be truncated if it exceeds the maximum capacity of the
model. In the second iteration of the model, Malconv2, the
authors exploited the sparse nature of temporal max pooling.
This allowed them to partition the varying size ﬁles into N
sections, then collect only the bytes that would actually get
updated with nonzero gradient during the backward pass of
the training process. This temporal max pooling allows Mal-
conv2 to intake much larger ﬁles than the original Malconv.
Moreover, temporal max pooling is used in conjunction with
a gating mechanism to provide an attention mechanism. This
allows Malconv2 to correlate features that are distant from
one another in the byte space. This is especially important for
polyglots, where two separate headers might be in the same
ﬁle at a great distance from one another.

We note that one criticism of Malconv is that it pays far
more attention to headers than data or code [30]. Although
this was an undesirable trait in a malware detector, it is useful
for a polyglot detector since the header structure is closely tied
to the ﬁle type. Note, some ﬁle types utilizes footers instead
of headers or have no distinct header/footer, so learning which
parts of a ﬁle are most relevant is a challenging problem for
a polyglot detector.

Our ﬁnal method concatenated the byte histogram vector
with the mime-type output of the utility file. Since file is
very accurate on normal ﬁles, we theorized that adding file’s
output to the feature vector would lessen the learning load on

a model.

Fig. 2: ML/DL Model Accuracy on Test Data

IV. RESULTS & DISCUSSION

Firstly, Figure 1 shows that the most common method for
identifying ﬁle types, file, has poor recall on the test set
of monoglot and polyglot ﬁles. file does perform extremely
well on monoglot (normal) ﬁles, as demonstrated by its high
precision. Ergo, file is highly effective on expected input,
but fails on the most common types of polyglot.

Table III breaks down file’s performance by polyglot
type. Although file is effective at detecting zippers and
cavities, these two types are the rarest form of polyglot (in
our experience) due to the requirements for mutual com-
ment markers and padding bytes, respectively. We used the
--keep-going ﬂag when running file.

Fig. 1: file Performance on Test Data

Fig. 3: ML/DL Model Precision on Test Data

Fig. 4: ML/DL Model Recall on Test Data

TABLE III: file Results on Test Data

Overall
Stack
Parasite
Zipper
Cavity

Accuracy
67.82%
75.75%
80.68%
99.92%
99.54%

Precision
99.61%
90.41%
98.75%
98.51%
98.99%

F1 Score

Recall
28.11% 43.85%
4.99%
2.56%
21.68% 35.55%
100%
99.25%
95.58% 97.26%

Figures 2, 3, 4, and 5 show the accuracy, precision, recall
and F1 score, respectively, of a variety of machine learning
models and one deep learning model (Malconv2). The ML
models are trained on the byte histogram of each ﬁle while
the deep learning model is trained on the raw bytes.

Fig. 5: ML/DL Model F1 Score on Test Data

Fig. 7: ML with file Precision on Test Data

The deep learning model, Malconv2, had the highest recall
and F1 score on our test data. However, the feature vector
for the deep learning model is quite different from the feature
vector for the ML models. Therefore, we attempted to improve
the feature vector for our ML models by adding the mime-type
output of file to the vector.

Tables 6, 7, 8, and 9 show the accuracy, precision, recall,
and F1 score of the ML models when the feature vector
is a concatenation of the byte histogram and the mime-
type (generated by file) for each ﬁle. The mime-type is
converted to a 1-hot encoding for ingestion by the model.
This additional feature boosted the recall of our machine
learning models across the board. We tested whether adding
the deep
this feature to Malconv2 would likewise boost
learning model’s performance; however, the additional feature
merely degraded Malconv2’s performance. The performance
of Catboost improved dramatically from 83.86 to 94.75. Due
to this improvement, we tuned this model’s hyperparameters
to see if we could improve performance even more, yielding
our best recall to date: 95.45.

Fig. 6: ML with file Accuracy on Test Data

Fig. 8: ML with file Recall on Test Data

Fig. 9: ML with file F1 Score on Test Data

The hyper-parameter tuned version of CatBoost narrowly
outscored Malconv2 (95.45 vs 95.16 recall) thanks to the
additional mime-type feature. The CatBoost model, like all
of the ML models, has the advantage of a compact feature
space compared to Malconv2, which expects raw bytes. Our

version of Malconv2 truncates an input ﬁle if the ﬁle exceeds
16MB in size. Therefore, the feature vector is quite large
(16MB) and training is much slower. Although much work
remains to be done in terms of optimizing the detection of
polyglot ﬁles, we currently recommend the use of a Catboost
model whose feature space consists of the byte histogram
concatenated with the mime-type output of ﬁle (converted to
a 1-hot encoding) for polyglot detection. This model had the
highest recall combined with an efﬁcient feature space.

V. CONCLUSION & FUTURE WORK

We demonstrated that the most common method for ﬁle
type identiﬁcation fails to reliably detect polyglots. We then
evaluated machine and deep learning models for detecting
polyglots and found that Malconv2 had the highest recall. If
mime-type is included as a feature, then a hyper-parameter
tuned version of CatBoost has the highest recall. CatBoost
has the added advantage of a much smaller feature vector.
Our work is merely the beginning, however. There are several
avenues of research that need to advanced in order to produce
an operational polyglot detector, namely:

• Data diversiﬁcation: A production-grade system can en-
counter an extremely wide variety of ﬁle formats; ergo,
We need to assemble a data set that fully encompasses
the wide variety of ﬁle formats commonly encountered
in the wild.

• Feature space optimization: We need to asses and possi-
bly incorporate additional features into our feature vector.
Historical candidates include byte co-occurrence counts
and byte entropy.

• Hyper-parameter tuning: We need to continue to opti-
mize the top-scoring models to achieve maximum per-
formance.

• High throughput: We need to demonstrate that our top-
scoring models have high enough throughput to be in-
corporated into production-grade systems where high
throughput is essential.

• Benign polyglots: We need to address instances where
ﬁles are cmobined into polyglots for benign purposes,
e.g., DICOM+TIFF ﬁles that combine medical images
into one ﬁle.

REFERENCES

[1] A. Albertini, “Funky ﬁle formats,” International Journal of Proof-of-
Concept or Get The Fuck Out, March 2015. [Online]. Available: https://
github.com/angea/pocorgtfo/blob/master/contents/issue07.pdf#page=18

[2] S. Shah, “Weaponized polyglots as browser exploits,” International
Journal of Proof-of-Concept or Get The Fuck Out, June 2015. [Online].
Available: https://www.alchemistowl.org/pocorgtfo/pocorgtfo08.pdf
[3] M. Ortiz, “HIPAA-protected malware? exploiting dicom ﬂaw to embed

malware in ct/mri imagery,” Cylera Labs, 2019.

[4] S. Jana and V. Shmatikov, “Abusing ﬁle processing in malware detectors
for fun and proﬁt,” in 2012 IEEE Symposium on Security and Privacy,
2012, pp. 80–94.

[5] R. A. Bridges, S. Oesch, M. E. Verma, M. D. Iannacone, K. M.
Huffer, B. Jewell, J. A. Nichols, B. Weber, J. M. Beaver, J. M.
Smith et al., “Beyond the hype: A real-world evaluation of the impact
and cost of machine learning-based malware detection,” arXiv preprint
arXiv:2012.09214, 2020.

[6] H. S. Anderson and P. Roth, “Ember: An open dataset for training static
pe malware machine learning models,” arXiv preprint arXiv:1804.04637,
2018.

[7] D. Maiorca, B. Biggio, and G. Giacinto, “Towards adversarial malware
detection: Lessons learned from pdf-based attacks,” ACM Computing
Survey, vol. 52, 2019.

[8] D.-S. Popescu, “Hiding malicious content in pdf documents,” arXiv

preprint arXiv:1201.0397, 2012.

[9] J. Saxe and K. Berlin, “Deep neural network based malware
detection using two dimensional binary program features,” CoRR, vol.
abs/1508.03096, 2015. [Online]. Available: http://arxiv.org/abs/1508.
03096

[10] B. Desjardins, Y. Mirsky, M. Ortiz, Z. Glozman, L. Tarbox, R. Horn, ,
and S. Horii, “Dicom images have been hacked! now what?” American
Journal of Roentgenology, vol. 214:4, pp. 727–735, 2020. [Online].
Available: https://www.ajronline.org/doi/pdfplus/10.2214/AJR.19.21958
[11] S. G. Selvaganapathy and S. Sadasivam, “Malware attacks on electronic
health records,” in Congress on Intelligent Systems, 2021, pp. 589–599.
[12] R. Graham, R. Perriss, and A. Scarsbrook, “Dicom demystiﬁed:
A review of digital ﬁle formats and their use in radiological
practice,” Clinical Radiology, vol. 60, no. 11, pp. 1133–1140, 2005.
[Online]. Available: https://www.sciencedirect.com/science/article/pii/
S0009926005002199

[13] J. Wolf, “Omg wtf pdf,” Presentation at the 27th Chaos Communication

Congress, 2010.

[14] “Document management—portable document format—part 1: Pdf 1.7,”
2008. [Online]. Available: https://www.adobe.com/content/dam/acom/
en/devnet/pdf/pdfs/PDF32000 2008.pdf

[15] “Zip ﬁle format speciﬁcation,” PKWARE Inc., 2020. [Online]. Available:
https://pkware.cacheﬂy.net/webdocs/casestudies/APPNOTE.TXT
[16] M. McDaniel and M. Heydari, “Content based ﬁle type detection
algorithms,” in 36th Annual Hawaii International Conference on System
Sciences, 2003. Proceedings of the, 2003, pp. 10 pp.–.

[17] W.-J. Li, K. Wang, S. J. Stolfo, and B. Herzog, “Fileprints: identifying
ﬁle types by n-gram analysis,” Proceedings from the Sixth Annual IEEE
SMC Information Assurance Workshop, pp. 64–71, 2005.

[18] G. Mittal, P. Korus, and N. Memon, “Fifty: Large-scale ﬁle fragment
type identiﬁcation using convolutional neural networks,” IEEE Transac-
tions on Information Forensics and Security, vol. 16, pp. 28–41, 2021.
[19] C. J. Veenman, “Statistical disk cluster classiﬁcation for ﬁle carving,” in
Third International Symposium on Information Assurance and Security,
2007, pp. 393–398.

[20] S. Fitzgerald, G. Mathews, C. Morris, and O. Zhulyn, “Using NLP
techniques for ﬁle fragment classiﬁcation,” Digital Investigation, vol. 9,
pp. S44–S49, 2012, the Proceedings of the Twelfth Annual DFRWS
Conference. [Online]. Available: https://www.sciencedirect.com/science/
article/pii/S1742287612000333

[21] N. L. Beebe, L. A. Maddox, L. Liu, and M. Sun, “Sceadan: Using con-
catenated n-gram vectors for improved ﬁle and data type classiﬁcation,”
IEEE Transactions on Information Forensics and Security, vol. 8, no. 9,
pp. 1519–1530, 2013.

[22] N. Beebe, L. Liu, and M. Sun, “Data type classiﬁcation: Hierarchical
class-to-type modeling,” in Advances in Digital Forensics XII, G. Pe-
terson and S. Shenoi, Eds. Cham: Springer International Publishing,
2016, pp. 325–343.

[23] G. Mittal, P. Korus, and N. Memon, “Fifty: Large-scale ﬁle fragment
type identiﬁcation using convolutional neural networks,” IEEE Transac-
tions on Information Forensics and Security, vol. 16, pp. 28–41, 2021.
[24] A. Souri and R. Hosseini, “A state-of-the-art survey of malware
techniques,” Human-
detection
centric ComputComputing and Information Sciences, vol. 8, 2018.
[Online]. Available: https://hcis-journal.springeropen.com/articles/10.
1186/s13673-018-0125-x

data mining

approaches

using

[25] H. E. Merabet and A. Hajraoui, “Survey of malware detection tech-
niques based on machine learning,” International Journal of Advanced
Computer Science and Applications, vol. 10, 2019.

[26] E. Raff and C. Nicholas, “A survey of machine learning methods
and challenges for windows malware classiﬁcation,” arXiv preprint
arXiv:2006.09271, 2020.

[27] E. Raff, J. Barker, J. Sylvester, R. Brandon, B. Catanzaro, and C. K.
Nicholas, “Malware detection by eating a whole exe,” in AAAI Work-
shops, 2018.

[28] E. Raff, W. Fleshman, R. Zak, H. S. Anderson, B. Filar, and M. McLean,
“Classifying sequences of extreme length with constant memory applied
to malware detection,” arXiv preprint arXiv:2012.09390, 2020.

[29] D. Gibert, C. Mateu,

neural

convolutional
represented
Hacking
https://link.springer.com/article/10.1007/s11416-018-0323-0

of Computer Virology
2019.

Journal
15,

and R. Vicens,
classiﬁcation

“Using
of malware
and
[Online]. Available:

J.
networks

Planes,
for

Techniques,

images,”

vol.

as

[30] L. Demetrio, B. Biggio, G. Lagorio, F. Roli, and A. Armando, “Explain-
ing vulnerabilities of deep learning to adversarial malware binaries,”
arXiv preprint arXiv:1901.03583, 2019.

