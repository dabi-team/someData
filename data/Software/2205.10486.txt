2
2
0
2

y
a
M
1
2

]
E
M

.
t
a
t
s
[

1
v
6
8
4
0
1
.
5
0
2
2
:
v
i
X
r
a

ARTICLE

Multivariate generalized linear mixed models for underdispersed
count data

Guilherme Parreira da Silvaa, Henrique Aparecido Laureanoa, Ricardo Rasmussen
Petterleb, Paulo Justiniano Ribeiro J´uniora, Wagner Hugo Bonata

aLaboratory of Statistics and Geoinformation, Department of Statistics, Paran´a Federal
University, Curitiba, Brazil; bDepartment of Integrative Medicine, Paran´a Federal University,
Curitiba, Brazil

ARTICLE HISTORY
Compiled May 24, 2022

ABSTRACT
Researchers are often interested in understanding the relationship between a set of
covariates and a set of response variables. To achieve this goal, the use of regression
analysis, either linear or generalized linear models, is largely applied. However, such
models only allow users to model one response variable at a time. Moreover, it is
not possible to directly calculate from the regression model a correlation measure
between the response variables. In this article, we employed the Multivariate Gen-
eralized Linear Mixed Models framework, which allows the speciﬁcation of a set of
response variables and calculates the correlation between them through a random ef-
fect structure that follows a multivariate normal distribution. We used the maximum
likelihood estimation framework to estimate all model parameters using Laplace ap-
proximation to integrate out the random eﬀects. The derivatives are provided by au-
tomatic diﬀerentiation. The outer maximization was made using a general-purpose
algorithm such as PORT and BFGS. We delimited this problem by studying only count
response variables with the following distributions: Poisson, negative binomial (NB)
and COM-Poisson. While the ﬁrst distribution can model only equidispersed data,
the second models equi and overdispersed, and the third models all types of dis-
persion. The models were implemented on software R with package TMB, based on
C++ templates. Besides the full speciﬁcation, models with simpler structures in the
covariance matrix were considered (ﬁxed and common variance, ﬁxed dispersion, ρ
set to 0). These models were applied to a dataset from the National Health and
Nutrition Examination Survey, where three underdispersed response variables were
measured at 1281 subjects. The COM-Poisson model full speciﬁed overcome the
other two competitors considering three goodness-of-ﬁt indexes: AIC, BIC and like-
lihood. As a consequence, it estimated parameters with smaller standard error and a
greater number of signiﬁcant correlation coeﬃcients. Therefore, the proposed model
can deal with multivariate count responses and measures the correlation between
them taking into account the eﬀects of the covariates.

KEYWORDS
Regression models. Automatic diﬀerentiation. Multivariate models. Template
Model Builder. Optimization. Laplace Approximation.

CONTACT Guilherme Parreira da Silva. Email: guilhermeparreira.silva@gmail.com

 
 
 
 
 
 
1. Introduction

Researchers are often interested to understand the relationship between a set of re-
sponse variables and a set of covariates in their diﬀerent areas of study. For example,
doctors are interested to know whether polypharmacy is related to complications after
surgery; veterinarians may be interested to know whether animal welfare is related to
meat quality; administrators may be interested to know whether the usage of the new
policy has improved social indicators. When we have a set of covariates and one spe-
ciﬁc objective (response variable), these situations can be addressed in the statistical
literature by regression models. Certainly, one of the most known and widely applied
is the linear regression (LM) model [1].

LM is widely used due to its simplicity and the general ordinary least squares
estimation procedure, which is covered in diﬀerent textbooks in diﬀerent areas such
as business, numerical optimization, agronomy, among others. To correct apply it, it
is necessary to verify whether the residuals are independent, not autocorrelated and
with homogeneous variance. These assumptions can be too restrictive depending on
the context.

As an alternative, the generalized linear model (GLM) is a more ﬂexible approach
[2]. GLM is a class of models that generalizes LM by supporting response variables
that belong to the exponential family. The distributions that belong to the exponential
family are binomial, gamma, inverse Gaussian, normal, and Poisson. Moreover, it is
built upon a link function that connects the linear predictor to the expectation of the
response variable, and its variance can be related to its mean.

A count data represents the number of times that an event occurs in a ﬁxed interval,
such as time, space, distance, area, among others. Therefore, it is ﬁnite and non-
negative. One example of such data is the number of times ear, body posture and head
orientation changes in ewes after brushing (a treatment proposed to increase welfare in
animals) [3]. The Poisson distribution is widely used for this purpose but relies on the
fact that the variance of the data is equal to its mean, which is known as equidispersion.
However, this assumption is too restrictive, and a diﬀerent mean-variance relationship
can be found, such as overdispersion and underdispersion. Overdispersion occurs when
the variance of the data is greater than the mean, and it is often found in practice.
It usually happens due to excess of zeros, heavy-tailed distribution, or absence of a
covariate to model the data [4]. On the other hand, underdispersion occurs when the
variance is smaller than the mean and it is less usual than the overdispersion case [5].
An underdispersed random variable is characterized by a smaller range of observed
counts compared to an overdispersed count data.

Diﬀerent distributions have been proposed to model count data. When the variance
is equal to the mean, after considering the eﬀects of all covariates, Poisson is the most
obvious choice. When the data are overdispersed, negative binomial (NB) type II under
the same framework of GLM is a good choice. The Extended Poisson Tweedie [6] based
on the Poisson Tweedie distribution [7,8], Conway-Maxwell-Poisson (COM-Poisson)
[9] and Gamma Count [5] distributions can be used to model either under-, equi-
or overdispersed data. The drawback of them is that the probability mass function
(pmf) does not have a closed-form expression, making the process of inference time
consuming for procedures that rely on the pmf, such as likelihood.

Beyond diﬀerent distributions, hurdle and the zero-inﬂated models [10] can be used
to model count data, especially when the data is zero-inﬂated [11]. Two widely-known
alternatives are the hurdle and the zero-inﬂated models. The disadvantage of them is
that interpretability becomes cumbersome especially for hurdle model.

2

All the strategies pointed out here consider that we have available only one re-
sponse variable. However, it is not diﬃcult to ﬁnd in the literature datasets where
the researchers possess more than 1 response variable for the same study. Usually,
the analysis is made by each response individually due to the lack of alternatives in
statistical software. Nevertheless, there is an increasing interest in the literature to
develop models or distributions that can handle multivariate responses, that is, when
there is more than one response variable [12].

One approach to model more than one response variable simultaneously is to con-
struct multivariate distributions for count data. [13] present three alternatives to model
multivariate count data. The ﬁrst assumes that the marginal distribution is Poisson,
and a multivariate distribution is build under copulas or multivariate distribution the-
ory [14]. The second uses a mixture of independent Poisson. The third method gen-
eralizes the ﬁrst one, where the conditional distributions are also Poisson. However,
none of them deals with under-dispersed data. [15] proposed a multivariate generalized
Poisson regression model based on the multivariate generalized Poisson distribution
(MGPD) that can deal with equi-, under- or overdispersed data, the correlation es-
timates can either be positive or negative, and the estimation is made under the
maximum likelihood (ML) framework.

[16] provides an overview of diﬀerent distributions/models for count data. It presents
the multivariate NB model (MNBM) and the multivariate Poisson-gamma mixture
model (MPGM), which allow only for overdispersion and nonnegative correlation.
It also presents the multivariate Poisson-lognormal regression (MPLR) model and the
latent Poisson-normal regression model, which allows positive and negative correlation.
However, it is suitable only for overdispersed data.

[17] proposed the Multivariate Covariance Generalized Linear Models (MCGLM),
which is a class of models based on quasi-likelihood [18] and generalized estimating
equations (GEE) [19], that allows ﬁtting multivariate models using only second-order
moments assumptions with correlated data. Bayesian Regression Models using Stan
- brms package [20] and MCMC Generalized Linear Mixed Models - MCMCglmm
package [21] provide a framework to model multivariate models via Bayesian inference
[22].

Another alternative is to model the correlation between response variables for the
same individual using the class of hierarchical GLM [23]. This class allows to model
correlated variables or individuals via a random eﬀect, an unobserved variable, that
can follow any distribution. When the distribution of the random eﬀect is Gaussian,
we have the Generalized Linear Mixed Models (GLMM). However, GLMM is widely
known and used to model correlation between sample units, not for response variables,
such methodology is implemented in consolidated packages in software R [24], such as,
glmmTMB [25], lme4 [26] and nlme [27].

In this article, we propose to model multivariate underdispersed count data under

the framework of GLMMs to accommodate correlation between response variables.

This article contains six sections including this introduction. Section 2 describes
the dataset used as a model example of application. Section 3 presents a literature
review of the GLMM model. Section 4 proposes the MGLMM model along with the
estimation procedure. Section 5 presents the results of the model applied to the data
from Section 2. Finally, Section 6 discusses the main contributions of this article and
future work is also pointed.

3

2. DATASET: NATIONAL HEALTH AND NUTRITION

EXAMINATION SURVEY

The National Health and Nutrition Examination Survey (NHANES) is a program
that studies the health and nutrition status of adults and children in the United
States. This survey is being conducted every year since the early 1960s. Nowadays,
it examines a nationally representative sample of about 5,000 subjects each year [28].
Among diﬀerent types of data collected, the main objective of this analysis was to
investigate whether demographical variables inﬂuence sexual behaviour.

We used the sex behaviour and demographic datasets. From the ﬁrst, it was selected
three response variables Nmsp (Number of male sex partners in the past year), Nmosp
(Number of male oral sex partners in the past year) and Nspfy (Number of sex partners
who are ﬁve years older in the past year). From the second dataset, it was used the
covariates race (0 = Others, 1 = White), education level (range from 1 = Less Than
9th Grade to 5 = College Graduate or above) and marital status (0 = Marital, 1 =
Others). After deleting those respondents who had missing data, the sample consisted
of 1281 women, with ages ranging from 18 to 80, 57% were married, 43% white and
31% had some college or associates (AA) degree.

One way to analyse this dataset is via regression models. Once all three response
variables are count data, we need to choose a suitable probability mass function for
this data. In this paper, we compared the Poisson, NB and COM-Poisson probability
distributions. As this is a cross-sectional study, we do not have responses correlated
over time. However, we may have correlated responses variables, once they were mea-
sured in the same individual. The model proposed in section 4 can accommodate this
situation.

Table 1 presents the mean, variance, Fisher Dispersion Index (DI) [29] for every
response variable and the generalized dispersion index (GDI) [30] for the dataset. The
main reason for choosing those response variables is the fact that Nmsp and Nmosp
can be considered marginally underdispersed, once the sample variance is smaller than
the sample mean. Moreover, Nspfy is only a little overdispersed. It is easily seen from
the DI, which is calculated by dividing the variance of the variable by its mean. A
variable with DI > 1 can be said as overdispersed, DI = 1 as equidispersed and DI < 1
underdispersed.

Moreover, the GDI is a recently proposed multivariate dispersion index. It is cal-
culated based on the expectation of each variable and the covariance between them.
When the number of variables is equal to 1, it is just the classical Fisher DI. A GDI > 1
classiﬁes the multivariate responses as overdispersed, GDI = 1 as equidispersed and
GDI < 1 underdispersed. The standard error (SE) for GDI is calculated using the
asymptotic behaviour of the estimator. According to this index, a 95% conﬁdence
interval based on SE suggests that this dataset is equidispersed as 1 is included on it.
The three response variables show no or small (Nmsp and Nspfy) correlation be-
tween them. Figure 1 shows the barplot of each response variable. We can see that
there is a higher frequency for non-occurrence of events, rather than the occurrence.

3. GENERALIZED LINEAR MIXED MODELS (GLMM)

The GLMM class can be used to address dependent observations, overdispersion,
among others [31]. In addition to the ﬁxed eﬀect from the GLM, it accommodates
extra variability through an unobservable variable, the random eﬀect, and is calcu-

4

Table 1. DESCRIPTIVE MEASUREMENTS FOR NHANES RESPONSE VARIABLES

Spearman Correlation ρ Mean Variance

DI

GDI(SE)

Nmsp Nmosp Nspfy

Nmsp
Nmosp
Nspfy

0.033

0.222
0.038

1.313
0.372
0.368

1.084
0.350
0.411

0.826
0.939
1.117

1.092(0.22)

Figure 1. BARPLOT FOR EACH RESPONSE VARIABLE FROM NHANES DATA

lated for each set of dependent observations. Once the random eﬀect is an unobserved
random variable, we can write the GLMM in a hierarchical structure. The following
notation is valid when the dependent observations come for repeated measurements
and longitudinal studies:

g(µil) = x(cid:62)

Yil | bi· ∼ f (µil, φ)
ijβ + z(cid:62)
ij bi·
bi· ∼ N (0, Σ) ,

(1)

where Yil is the i-th unit sample measured in the l-th times (in a longitudinal study)
or in the l-th group (in a repeated measurements study), bi· is a vector of random
eﬀects for each sample unit that follows a multivariate normal distribution with mean
0 and covariance matrix Σ to accommodate the variance of each random eﬀect and
covariance among them, f is the conditional distribution of Yil on bi·, µil is the mean
for every sample unit i and measurement l, g(.) is a suitable link function, and z(cid:62)
ij is
the design matrix associated to the random eﬀect.

4. MULTIVARIATE GENERALIZED LINEAR MIXED MODEL

(MGLMM) FOR COUNT DATA

Let Yir be the multivariate outcome for subject i, where i = 1, . . . , n and response
variable r, where r = 1, . . . , k. Suppose that a set of p known covariates is available for
each response r, therefore, xirj is the value of the j-th covariate for individual i and
response r. The purpose of this article is to provide a joint model for a set of response
variables. We start from the standard GLMM model speciﬁcation with only a random

5

NmspNmospNspfy051015024680246025050075002004006008000300600900OccurrenceFrequencyintercept. The ﬁrst component we need to assume is the conditional distribution of
the response variables:

Yir | bir ∼ f (µir; φr),

where all response variables share the same distribution. However, with diﬀerent mean
and dispersion parameters. The second component we need to specify is the linear
predictor:

gr(µir) = x(cid:62)

irjβr + bir,

where gr(.) is a suitable link function, βr is a p × 1 vector of parameter estimates and
bir is the random intercept value for each individual and response variable. Lastly, the
distribution of the random eﬀects is speciﬁed by:








bi1
bi2
...
bir








∼ NM










0
0




...




0

; Σ
r×r

=








σ2
1
ρ21σ2σ1
...

ρ12σ1σ2
σ2
2
...

ρr1σrσ1 ρr2σrσ2

. . .
. . .
. . .
. . .















,

ρ1rσ1σr
ρ2rσ2σr
...
σ2
r

where each random eﬀect has mean 0, variance σ2, and ρrr(cid:48)(r (cid:54)= r(cid:48)) measures the
correlation between each pair of random eﬀects. Despite this is a general modelling
framework, this article addresses only the same distribution (either Poisson, binomial
negative or COM-Poisson) and link function (logarithm) for all responses variables.

An important question for this type of model is whether it is possible to estimate
simultaneously the dispersion parameters of the pmf and the variance parameters of
the random eﬀects, once they measure variability related to the same random variable,
and can cause identiﬁability problems.

4.1. INFERENCE AND ESTIMATION

In this section, we present the estimation procedure used to obtain the parame-
ter estimates based on the likelihood function. In order to estimate the model pre-
sented in section 4 under the maximum likelihood (ML) paradigm, it is necessary
to construct the joint distribution for both random variables (Yir and bir). Once we
have a hierarchical structure, the joint distribution of Yir and bir can be factored
into f (Yir, bir) = f (Yir | bir)f (bir). As only Y is observed, we are interested on
the marginal distribution of Y that can be obtained integrating out bir, that is,
f (Yir) = (cid:82) f (Yir | bir)f (bir)dbir, which in practical terms means that the joint dis-
tribution is averaged over the bir terms.

Now, we particularize the ML estimation method to the model described in section 4.
The objective is to estimate the parameter vector θ = {β, φ, σ2, ρ}, where β is the
regression parameter vector, φ the extra parameters of each distribution (dispersion in
most of cases), and σ2 and ρ are the parameters that compose the variance covariance
matrix Σ. The marginal likelihood function for the model described in section 4 for

6

each sample unit is

Li(β, Σ, φ | y) =

(cid:90) k
(cid:89)

r=1

f (yr | b, β, φ)f (b | Σ)db,

(2)

where y is the k-response vector, yr is each response and b is the random eﬀects vector.
The full likelihood for θ is given by

L(β, Σ, φ) =

N
(cid:89)

i=1

Li(β, Σ, φ | y),

where N is the total number of sample units. Under independence between sample
units, we have:

L(β, Σ, φ) =

N
(cid:89)

(cid:90) k
(cid:89)

i=1

r=1

f (yr | b, β, φ)f (b | Σ)db.

(3)

The Equation 3 is composed of the product of two probability distributions. The
ﬁrst one is the probability distribution of the sample units, while the second is the
probability distribution of the random eﬀects. The distribution of the random eﬀects
is assumed to be a multivariate normal distribution. As the probability distribution
of the response is not normal, the integral does not present a closed form solution
expression, thus numerical methods are required to solve such integral.

4.1.1. Numerical integration via Laplace approximation

Once we are dealing with non-normal data, one possibility is to use numerical integra-
tion methods to solve the integral in Equation 2 for each set of sample units. Other
possibilities include Penalized Quasi Likelihood (PQL) and Monte Carlo techniques
that will not be covered here. It is important to note that the integral is of dimension
k, and k can vary from two to r (the number of response variables). Methods based on
numerical quadratures such as trapezium, 1/3 Simpson, Gauss-Hermite or adaptative
Gauss-Hermite use too many points to evaluate the integrand and its complexity is
proportional to the dimension of the integral [32]. To solve the integral in Equation 2
we used the LA, which is a special case of the adaptive Gauss-Hermite quadrature
(AGHQ) when it is used only one integration point [33]. Although LA is faster than
AGHQ, it is less accurate [34].

The idea of LA is to replace an integral with a tractable closed-form expression. This
resulting expression is maximized concerning the variable that we wanted to integrate
and the integral is solved. Applying the LA to the integral in Equation 2 results in
the marginal likelihood function. The approximation is obtained by

(cid:90)

Rk

(cid:12)
exp{Q(b)}db ≈ (2π)nb/2 (cid:12)
(cid:12)−Q(cid:48)(cid:48)(ˆb)
(cid:12)
(cid:12)
(cid:12)

−1/2

exp{Q(ˆb)},

(4)

where Q(b) is a uni-modal and bounded function of the variable b and nb is the

7

dimension of the integral, that it is k in this case. Careful accounting of the approxi-
mation error shows it to generally be O(n−1) where n is the sample size (assuming a
ﬁxed length for b) [35]. In this case, Q(b) is the log of the integrand in Equation 2, b
the random eﬀect, ˆb the maximized random eﬀect values, while all other θ parameters
remain constant. Therefore, Q(ˆb) is the maximum value of the function with respect
to b and Q(cid:48)(cid:48)(ˆb) is the curvature of the function in the maximum, or in other words,
it corresponds to the value of the second derivative (Hessian) of the function in the
maximum.

It is important to say that the integral of order k in Equation 2 has to be solved
repeatedly in every step of the ML method for each one of the N sample units. There-
fore, we have two optimizations procedures: one that is called the outer maximization,
which is the maximization of the marginal likelihood (result from the integral), and
another one that is called the inner maximization, which is the maximization required
inside the LA.

For each optimization procedure, we have diﬀerent situations. In the inner process
is feasible to calculate the Hessian matrix eﬃciently (once we know the integrand) and
to choose a good initial guess for b. Therefore, the inner process maximization can be
eﬃciently implemented by the Newton-Raphson (NR) method (that requires second-
order derivatives). On the other hand, in the outer maximization, it is not feasible to
calculate the Hessian matrix eﬃciently, neither we have a good initial guess after the
integral is solved. Therefore, it will be maximized with algorithms that require only
ﬁrst-order derivatives and do not depend strongly on the initial guess as NR does. The
derivatives were obtained through automatic diﬀerentiation [36].

5. SOFTWARE IMPLEMENTATION

In this section, we present the software implementation employed to ﬁt the model
presented in section 4. The software used was R version 4.0.2 [24] along the Template
Model Builder - TMB [37] package. TMB is an R package that oﬀers a collection of tools to
build complex random eﬀects statistical models through C++ templates. TMB is based on
state-of-the art software: CppAD [38], Eigen C++ [39], BLAS [40], among others libraries
written in C++, which are responsible for obtaining the derivatives through AD, linear
algebra computations and parallelization, respectively.

Once the user supplies an objective function in a C++ template ﬁle (which, usu-
ally is the negative log-likelihood function), it obtains the marginal likelihood via LA
integrating out the b random eﬀects. The internal optimization of the LA is made
via Newton’s method, with ﬁrst and second derivatives provided via AD from TMB.
After that, the marginal can be optimized to obtain the MLE parameters with any
general-purpose algorithm (using ﬁrst derivative information provided from TMB), such
as PORT or BFGS implemented in nlminb and optim routine in R. Moreover, the stan-
dard deviation of the parameters (or a function of it) can be obtained via the Delta
method [41]; proﬁling is available too.

A

implementation

Poisson MGLMM is
http://www.leg.ufpr.br/doku.php/publications:papercompanions.

the

of

available

on

8

5.1. Reparametrization

We had to use reparametrization techniques for those parameters that vary in a subset
of R. Dispersion parameters for both NB and COM-Poisson distributions were log
reparametrized (ln to be more precise) into the dispersion parameter as input, allowing
it to will vary on all R. For σ and ρ we used an eﬃcient reparametrization from TMB
under the normal multivariate speciﬁcation.

Instead of estimating ρ directly in Σ, the TMB reparametrization consists to estimate
a diﬀerent unrestricted parameter (cid:37) in a lower triangular matrix with unit diagonal
L. An unstructured symmetric positive deﬁnite correlation matrix Ω can be obtained
via Ω = D− 1

2 , where D = diag(LL(cid:62)).

2 LL(cid:62)D− 1

The Ω matrix is only one part of TMB’s Σ decomposition. Consider the case we have
4 response variables, so, we want to estimate 6 correlation parameters. Thus, the lower
triangular matrix L has order 4 and is ﬁlled row-wise, such that:

L =







1
(cid:37)0
1
(cid:37)1 (cid:37)2
(cid:37)3 (cid:37)4 (cid:37)5 1

1







.

According to the the restrictions imposed into Ω, and the way the normal multi-
variate was coded into TMB, the variance parameters of the random eﬀects need to be
supplied as standard deviations. To obtain the full variance-covariance matrix Σ we
can use Σ = WΩW where W is a diagonal matrix with entries being equal to the
random eﬀects’s standard deviation.

6. DATA ANALYSIS

In this section we apply the proposed model in section 4 to analyze the NHANES
data set presented in section 2. Initial values had to be chosen carefully for the applied
models. Firstly, it was ﬁtted a MCGLM model [17] with log link function, power
parameter ﬁxed, and variance Tweedie, which corresponds to ﬁt a Poisson Model via
quasi-likelihood, in order to obtain initial parameter estimates for the regression and
variance parameters (based on the variance of the residuals). On the other hand, the
correlation parameter was set to 0. We did not use MCGLM to obtain initial estimates
for the correlation parameter due to the diﬀerence in methodologies. This parameter
estimates values were considered as initial values to the Poisson model.

Then, for every distribution, the estimation was made in two steps. In the ﬁrst, the
model was ﬁtted based on a random sample (SRS) of size 350. In the second step,
the initial values from the sample model were used to ﬁt the model with the whole
dataset. After that, the ﬁrst estimation was carried out with the PORT routine, followed
by BFGS and PORT. For the dataset analyzed, PORT was the fastest and produced a more
consistent optimization over BFGS in most scenarios. In every step, initial values were
used from the last optimization, and the choice of the intermediate models and the
ﬁnal results reported were based on the maximum value of the logLik.

The initial values for the NB model were the ﬁnal estimates from the Poisson model
(with initial value to the dispersion parameter φ = 1, i.e., small overdispersion). In
the same way, the initial values for the COM-Poisson model were the ﬁnal estimates
from the NB model (with initial value to the dispersion parameter ν = 1, i.e., equidis-

9

Figure 2. Model estimation process for each dataset

1ºPORT
2ºBFGS
3ºPORT

MCGLM

Poisson
sample

Poisson
full data

NB sample

NB full
data

1ºPORT
2ºBFGS
3ºPORT

COM-
Poisson
sample

COM-
Poisson
full data

1ºPORT
2ºBFGS
3ºPORT

persion). We used the mean-parametrization of the COM-Poisson model, where ν > 1
is considered underdispersion, and ν < 1, overdispersion [42].

This workﬂow is described in Figure 2. The reported results are only from the full

data, as the samples were used to obtain initial estimates.

In addition to the models presented in section 4, simpler versions of them were also
ﬁtted. We used some diﬀerent scenarios concerning the variance of the random eﬀects,
one for the dispersion parameter and another for the correlation parameter. The ﬁrst
case considered a model with a common variance speciﬁcation, where the variance of
the random eﬀect was equal to all response variables. In the second case, we used a
ﬁxed variance speciﬁcation, where the variance was ﬁxed at 1. The third scenario was
when the dispersion parameter was ﬁxed to φ = 1 for the NB and ν = 1.5 for the
COM-Poisson model indicating small underdispersion for this distribution. The ﬁnal
and fourth scenario sets the correlation parameter to zero, which aims to reproduce
the case where every response distribution would be ﬁtted separately. As the Poisson
distribution does not have a dispersion parameter, only the full speciﬁcation of the
model was used and when the correlation parameter was set to zero. This workﬂow
and the linear predictor selection that is explained in the next subsection is presented
in Figure 3.

10

Figure 3. Model structure and linear predictor selection

Poisson Best

1 - Full model
2 - Fixed variance
3 - Comum variance
4 - Fixed dispersion
5 - Correlation zero

NB Best

Best
model

COM-Poisson
Best

Linear
Predictor
Selection

Poisson1

Poisson5

NB1

NB2

NB3

NB4

NB5

COM-Poisson1

COM-Poisson2

COM-Poisson3

COM-Poisson4

COM-Poisson5

Choosing
model
structure

11

Table 2. Goodenss-of-ﬁt measures for NHANES data from diﬀerent distributions and speciﬁcations

Model

np

AIC

BIC

Loglik

SE

Poisson
Rho Zero Poisson

NB
Fixed Dispersion NB
Comum Variance NB
Fixed Variance NB
Rho Zero NB

COM-Poisson
Fixed Dispersion COM-Poisson
Comum Variance COM-Poisson
Fixed Variance COM-Poisson
Rho Zero COM-Poisson

21
18

24
21
22
21
21

24
21
22
21
21

7145.1
7169.8

7150.2
8092.4
7203.4
7924.2
7176.8

4615.9
6991.7
5608.2
6649.8
5526.3

7253.4
7262.6

7273.9
8200.6
7316.8
8032.5
7285.1

4739.6
7099.9
5721.6
6758.0
5634.5

-3551.6 (cid:88)
(cid:55)
-3566.9
-3551.1 (cid:88)
(cid:55)
-4025.2
(cid:55)
-3579.7
-3941.1 (cid:88)
(cid:55)
-3567.4
-2284.0 (cid:88)
(cid:55)
-3474.8
-2782.1 (cid:88)
-3303.9 (cid:88)
-2742.1 (cid:88)

We reported the results of the models presented in Figure 2 and their variations
with log-likelihood value (logLik - larger the best), Akaike Information Criterion (AIC
- lower the best), Bayesian Information Criterion (BIC - lower the best), number of
parameters estimates (np) and whether the SE was returned or not for the parameter
estimates.

6.1. NHANES data

Table 2 presents the goodness-of-ﬁt measures for NHANES data from diﬀerent distri-
butions and speciﬁcations.

Overall, the model which best ﬁtted the data with respect to the three ﬁt measures
was the COM-Poisson with full speciﬁcation. We can also note a large diﬀerence in
absolute numbers against the competitors. The second best speciﬁcation was with rho
zero for the COM-Poisson model. Moreover, we can note a very close logLik between
the NB and the Poisson: it happened due to a large value for the dispersion parameter
of the NB, approaching for the Poisson model. Among the smaller speciﬁcations, the
ﬁxed dispersion was the worst scenario for both NB and COM-Poisson models.

These results agree with the underdispersion characteristic of the data presented
in Table 1. It is important to note that beforehand only COM-Poisson is able to deal
with underdispersion data due to the ν parameter. For Poisson and NB models, the
random eﬀects structure only added some extra variance for each response variable. For
Poisson, the extra variance parameter gives the ﬂexibility to model only overdispersion;
while for NB, it allows modelling even greater variability than the traditional NB
model. Therefore, the analysis of this dataset conﬁrmed the expected results by the
speciﬁed model and distributions.

The checkmark (cid:51) in the last column speciﬁes that the SE of the parameter estimate
was returned at least for one parameter of the model. The (cid:55) indicates that it was not
possible to return the SE for any parameter estimate of the model. In order to deal
with this problem, we modiﬁed the linear predictor excluding those covariates that
their respective parameter estimates did not have the SEs returned for each response

12

Table 3. Goodness-of-ﬁt measures for NHANES data from the best speciﬁcation for each distribution

Model

np

AIC

BIC

logLik

SE

Poisson
NB
COM-Poisson

16
19
19

7147.8
7153.1
4448.6

7230.3
7251.0
4546.6

-3557.9 (cid:51)
-3557.5 (cid:51)
-2205.3 (cid:51)

Figure 4. Regression parameter estimates and 95% conﬁdence intervals by outcome and ﬁnal model

variable based on the best model, and it was reﬁtted. The same linear predictor was
used to ﬁt the best model from each distribution, in this case, Poisson, and NB. The
results are presented in Table 3.

We can see that reducing the linear predictor improved the COM-Poisson model ﬁt,
while it worsened the Poisson and NB in terms of logLik and AIC, but improved the
BIC because of a greater penalty due to the number of parameters. In order to better
understand the behaviour of the parameter estimates, Figure 4 compares the regression
estimates, Table 4 compares the dispersion and Equation 5 presents a matrix where
out of the diagonal are presented correlation estimates and the SE of each random
eﬀect, along with the standard deviation and SE in the diagonal.

From Figure 4 we can see that for most of the estimates, the COM-Poisson conﬁ-
dence intervals were smaller than NB and Poisson models. As these distributions can
not handle underdispersed data, they tend to overestimate the SE of the parameter
estimates. The conﬁdence interval for Nmosp intercept based on COM-Poisson was
the only larger than NB and Poisson models. Moreover, we see that the intercept
point estimate was not close between COM-Poisson and the other two models in every
scenario.

Regarding the relationship between the covariates and the response variables, the
models considered, mostly agree in the direction of the relationship to each response
variable. Race (0 = Others, 1 = White) covariate had a null eﬀect for Nmsp and
Nmosp; for Nspfy had a negative eﬀect for Poisson and NB models and null for COM-
Poisson model. Marital status (0 = Married, 1 = Others) had a positive eﬀect for all
three response variables and Poisson and NB models; while COM-Poisson model had

13

NmspNmospNspfy−0.20.00.20.4−2−10−2.0−1.5−1.0−0.50.0InterceptRaceMaritalEducationb^–1.96SECOM−PoissonNBPoissonTable 4. Dispersion parameter estimates and SEs for each model and outcome of NHANES data

NB (φ)

COM-Poisson (ˆν)

Outcome Estimate

SE

Estimate

SE

Nmsp
Nmosp
Nspfy

4958.17
753.63
1996.65

21947.1
3878.4
12993.9

46.513
20.964
19.675

0.059
5.829
1.286

only a positive eﬀect for Nmsp. Finally, education level (range from 1 = Less Than
9th Grade to 5 = College Graduate or above) had a negative eﬀect on Nspfy for NB
and Poisson models and null eﬀect for COM-Poisson. In those models that can not
handle underdispersion, more information was captured by the regression parameters
than in the COM-Poisson model.

From Table 4 we can see that φ was large enough to approximate the NB to a Poisson
model followed by an even larger SE; it justiﬁes the similar model measures presented
in Table 2 and Table 3. For COM-Poisson, large ˆν values indicate underdispersion and
a small SE indicates that ˆν is not one, so, it cannot be considered equidispersed.

Σ(cid:48)

Poisson =

Σ(cid:48)

NB =

Σ(cid:48)

COM-Poisson =









0.18(0.03)∗

0.94(0.1)∗
0.97(0.04)∗
0.23(0.08)∗ 0.92(0.13)∗
0.63(0.07)∗
0.18(0.03)∗ 0.97(0.08)∗ 0.99(0.02)∗
0.23(0.08)∗ 0.97(0.09)∗
0.63(0.07)∗









(5)





0.48(< 0.01)∗ < −0.01(< 0.01)∗ < 0.01(< 0.01)
1.21(0.15)∗
< −0.01(0.01)
1.25(0.06)∗





Equation 5 presents the correlation between random eﬀects in the upper diagonal
and the standard deviation in the diagonal. Stars represent statistical signiﬁcance at
5% level. It was necessary to make a distinction between Σ and Σ(cid:48) because the last
one uses standard deviation in the diagonal, and the ﬁrst use variance.

Equation 5 shows that the correlation estimates for Poisson and NB model are close
to one and are signiﬁcant at 5% level. In contrast, the correlation estimates for the
COM-Poisson model are close to zero and only one is signiﬁcant (between Nmsp and
Nmosp). It seems that the underdispersion information not modelled by Poisson and
NB models are somewhat present in the correlation estimates. Moreover, the standard
deviation of the random eﬀect was larger for COM-Poisson than was the Poisson and
NB models. It may occur because at the same time that the COM-Poisson has greater
variability due to the random eﬀect standard deviation, it balances out with smaller
dispersion of ˆν parameter.

14

7. Discussion

The main focus of this article was to propose MGLMM for underdispersed count data.
With this new class of statistical models, we can model more than one response variable
in the same framework accommodating a random eﬀect that follows a multivariate
normal distribution (MN). The parameters of the covariance matrix from the MN
allow us to account for the correlation between the random eﬀects and the variance of
them. This extra feature is not available in a GLMM model, where it is necessary to
model one response variable at a time.

In particular, we addressed only count data problems, considering Poisson, NB and
COM-Poisson distributions. This model was implemented using the TMB package in R.
It was estimated under the ML paradigm using numerical integration via LA with inner
and outer optimization based on Newton’s method and general-purpose algorithm
respectively, such as BFGS and PORT routines, which derivatives are provided through
AD.

A dataset from the NHANES survey was analysed by each model and variations
of them: rho set to zero, ﬁxed dispersion, ﬁxed variance and common variance for
all random eﬀects. It comprised of three response variables, being one equidispersed
and two underdispersed. The COM-Poisson was the best model compared to their
counterparts according to logLik, AIC and BIC, especially because of its ability to
model underdispersion. The SEs were smaller compared to the Poisson and NB models.
The dispersion parameter ν indicated underdispersion, which is expected due to the
nature of the data and the correlation parameter ρ was almost zero.

Therefore, we suggest using the MGLMM model framework for count data. In par-
ticular, the best results were obtained with the COM-Poisson model in three real
datasets. The main advantage of it is the possibility to model all response variables at
the same time and measure the correlation between the random eﬀects.

Future work could include the exploration of the residuals for this model and propose
a correlation coeﬃcient between the response variables, not the random eﬀects, that
it is based on the correlation of the random eﬀect.

Disclosure statement

No potential competing interest was reported by the authors.

Funding

The corresponding author was funded with a scholarship provided by the Coordena¸c˜ao
de Aperfei¸coamento de Pessoal de N´ıvel Superior (CAPES).

References

[1] Galton F. Regression towards mediocrity in hereditary stature. The Journal of the An-

thropological Institute of Great Britain and Ireland. 1886;15:246–263.

[2] Nelder JA, Wedderburn RW. Generalized linear models. Journal of the Royal Statistical

Society: Series A (General). 1972;135(3):370–384.

[3] Tamioso PR, Maiolino Molento CF, Boivin X, et al. Inducing positive emotions: Be-
havioural and cardiac responses to human and brushing in ewes selected for high vs low

15

social reactivity. Applied Animal Behaviour Science. 2018;208:56 – 65. Available from:
http://www.sciencedirect.com/science/article/pii/S0168159118304490.

[4] Grunwald GK, Bruce SL, Jiang L, et al. A statistical model for under-or overdispersed

clustered and longitudinal count data. Biometrical Journal. 2011;53(4):578–594.

[5] Zeviani WM, Ribeiro Jr PJ, Bonat WH, et al. The gamma-count distribution in the anal-
ysis of experimental underdispersed data. Journal of Applied Statistics. 2014;41(12):2616–
2626.

[6] Bonat WH, Jørgensen B, Kokonendji CC, et al. Extended Poisson–Tweedie: Properties

and regression models for count data. Statistical Modelling. 2018;18(1):24–49.

[7] El-Shaarawi AH, Zhu R, Joe H. Modelling species abundance using the Poisson–Tweedie

family. Environmetrics. 2011;22(2):152–164.

[8] Jørgensen B, Kokonendji CC. Discrete dispersion models and their Tweedie asymptotics.

AStA Advances in Statistical Analysis. 2016;100(1):43–78.

[9] Shmueli G, Minka TP, Kadane JB, et al. A useful distribution for ﬁtting discrete data:
revival of the Conway–Maxwell–Poisson distribution. Journal of the Royal Statistical
Society: Series C (Applied Statistics). 2005;54(1):127–142.

[10] Zeileis A, Kleiber C, Jackman S. Regression models for count data in R. Journal of

statistical software. 2008;27(8):1–25.

[11] Ridout M, Dem´etrio CG, Hinde J. Models for count data with many zeros. In: Proceedings
of the XIXth international biometric conference; Vol. 19; International Biometric Society
Invited Papers Cape Town, South Africa; 1998. p. 179–192.

[12] Bonat WH, Jørgensen B. Multivariate covariance generalized linear models. Journal of

the Royal Statistical Society Series C (Applied Statistics). 2016;:649–675.

[13] Inouye DI, Yang E, Allen GI, et al. A review of multivariate distributions for count data
derived from the Poisson distribution. Wiley Interdisciplinary Reviews: Computational
Statistics. 2017;9(3):e1398.

[14] Campbell JT. The Poisson correlation function. Proceedings of the Edinburgh Mathe-

matical Society. 1934;4(1):18–26.

[15] Famoye F. A multivariate generalized Poisson regression model. Comm Statist Theory

Methods. 2015 Feb;44(3):497–511.

[16] Winkelmann R. Econometric analysis of count data. Springer Science & Business Media;

2008.

[17] Bonat WH. mcglm: Multivariate covariance generalized linear models; 2016. R package

version 0.3.0; Available from: https://CRAN.R-project.org/package=mcglm.

[18] Wedderburn RW. Quasi-likelihood functions, generalized linear models, and the

gauss—newton method. Biometrika. 1974;61(3):439–447.

[19] Liang KY, Zeger SL. Longitudinal data analysis using generalized linear models.

Biometrika. 1986;73(1):13–22.

[20] B ¨Urkner PC. Advanced Bayesian multilevel modeling with the R package brms. The R

Journal. 2018;10(1):395–411.

[21] Hadﬁeld JD. Mcmc methods for multi-response generalized linear mixed models: The
MCMCglmm R package. Journal of Statistical Software. 2010;33(2):1–22. Available from:
http://www.jstatsoft.org/v33/i02/.

[22] Dempster AP. A generalization of bayesian inference. Journal of the Royal Statistical

Society: Series B (Methodological). 1968;30(2):205–232.

[23] Lee Y, Nelder JA. Hierarchical generalized linear models. Journal of the Royal Sta-
tistical Society Series B (Methodological). 1996;58(4):619–678. Available from: http:
//www.jstor.org/stable/2346105.

[24] R Core Team. R: A language and environment for statistical computing. Vienna, Austria:
R Foundation for Statistical Computing; 2020. Available from: https://www.R-project.
org/.

[25] Brooks ME, Kristensen K, van Benthem KJ, et al. glmmTMB balances speed and ﬂexi-
bility among packages for zero-inﬂated generalized linear mixed modeling. The R Journal.
2017;9(2):378–400. Available from: https://journal.r-project.org/archive/2017/

16

RJ-2017-066/index.html.

[26] Bates D, M¨achler M, Bolker B, et al. Fitting linear mixed-eﬀects models using lme4.

Journal of Statistical Software. 2015;67(1):1–48.

[27] Pinheiro J, Bates D, DebRoy S, et al. nlme: Linear and nonlinear mixed eﬀects mod-
els; 2017. R package version 3.1-131; Available from: https://CRAN.R-project.org/
package=nlme.

[28] Nhanes

[https://www.cdc.gov/nchs/nhanes/about_nhanes.htm];

2007. Accessed:

2020-08-14.

[29] Fisher RA. The eﬀect of methods of ascertainment upon the estimation of frequencies.

Annals of eugenics. 1934;6(1):13–25.

[30] Kokonendji CC, Puig P. Fisher dispersion index for multivariate count distributions: A

review and a new proposal. Journal of Multivariate Analysis. 2018;165:180–193.

[31] Breslow NE, Clayton DG. Approximate inference in generalized linear mixed models.

Journal of the American statistical Association. 1993;88(421):9–25.

[32] Bonat WH, Ribeiro-Jr PJ. Practical likelihood analysis for spatial generalized linear mixed

models. Environmetrics. 2016;27(1):83–89.

[33] Tierney L, Kadane JB. Accurate approximations for posterior moments and marginal
densities. Journal of the American Statistical Association. 1986;81(393):82–86. Available
from: https://www.tandfonline.com/doi/abs/10.1080/01621459.1986.10478240.
[34] Signorelli M, Spitali P, Tsonaka R. Poisson–Tweedie mixed-eﬀects model: A ﬂexible
approach for the analysis of longitudinal rna-seq data. Statistical Modelling. 2020;
:1471082X20936017.

[35] Wood SN. Core statistics. Cambridge University Press; 2015. 6.
[36] Baydin AG, Pearlmutter BA, Radul AA, et al. Automatic diﬀerentiation in machine
learning: a survey. The Journal of Machine Learning Research. 2017;18(1):5595–5637.
[37] Kristensen K, Nielsen A, Berg CW, et al. TMB: Automatic diﬀerentiation and Laplace

approximation. Journal of Statistical Software. 2016;70(5):1–21.

[38] Bell BM. Cppad: a package for c++ algorithmic diﬀerentiation; 2005. Available from:

http://www.coin-or.org/CppAD.

[39] Guennebaud G, Jacob B, et al. Eigen v3 [Http://eigen.tuxfamily.org]; 2010.
[40] Blackford LS, Petitet A, Pozo R, et al. An updated set of basic linear algebra subprograms

(blas). ACM Transactions on Mathematical Software. 2002;28(2):135–151.

[41] Thygesen UH, Albertsen CM, Berg CW, et al. Validation of ecological state space mod-
els using the Laplace approximation. Environmental and Ecological Statistics. 2017;
24(2):317–339.

[42] Huang A. Mean-parametrized Conway–Maxwell–Poisson regression models for dispersed

counts. Statistical Modelling. 2017;17(6):359–380.

17

