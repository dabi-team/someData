2
2
0
2

g
u
A
0
3

]

G
L
.
s
c
[

1
v
0
6
9
3
1
.
8
0
2
2
:
v
i
X
r
a

The case for fully Bayesian optimisation in small-sample trials

Yuji Saikai

School of Mathematics and Statistics, the University of Melbourne

Abstract

While sample eﬃciency is the main motive for use of Bayesian optimisation when black-
box functions are expensive to evaluate, the standard approach based on type II maximum
likelihood (ML-II) may fail and result in disappointing performance in small-sample trials. The
paper provides three compelling reasons to adopt fully Bayesian optimisation (FBO) as an
alternative. First, failures of ML-II are more commonplace than implied by the existing studies
using the contrived settings. Second, FBO is more robust than ML-II, and the price of robustness
is almost trivial. Third, FBO has become simple to implement and fast enough to be practical.
The paper supports the argument using relevant experiments, which reﬂect the current practice
regarding models, algorithms, and software platforms. Since the beneﬁts seem to outweigh the
costs, researchers should consider adopting FBO for their applications so that they can guard
against potential failures that end up wasting precious research resources.

Keywords: BoTorch, expected improvement, fully Bayesian Gaussian process, Pyro, type II
maximum likelihood

1 Introduction

Sample eﬃciency is the predominant motive for use of Bayesian optimisation (BO) when optimising
black-box functions that are expensive to evaluate. Function evaluations are said to be expensive
when each evaluation costs a signiﬁcant amount of resources including time and money. Func-
tion evaluations take place typically in the form of either real-world trials or computer simulations.
While the former case clearly can be expensive, because of the lack of analytic expressions for objec-
tive functions and/or constraints, the latter case can also be expensive. For example, researchers
used BO to learn robot controllers with only a handful of trials [1]. Consequently, in practical
applications of BO, small-sample performance is of the greatest concern.

In practice, estimating hyperparameters with small samples is a challenging task [5].

Gaussian process (GP) is the de facto standard surrogate model for BO, and GPs must be
speciﬁed in terms of kernel hyperparameters before applying BO. Since hyperparameters suitable
for particular problems are rarely known beforehand, these are estimated based on observations and
sequentially updated throughout the trials, commonly using type II maximum likelihood (ML-II)
[2–4].
In
particular, maximisation of the marginal likelihood is numerically diﬃcult because a wide range of
length-scales, both very short and intermediate values, are generally consistent with small data [6].
Several studies provide detailed accounts of how BO fails in various situations [7–10]. Nonetheless,
despite the challenge, this is precisely the kind of problems for which researchers use BO—locating
inputs that yield good enough function values using only small samples.

1

 
 
 
 
 
 
To address the challenge, the fully Bayesian approach has been proposed in the context of GP
regression [11, 12] and speciﬁcally in the context of BO [13–15]. Benassi, Bect, and Vazquez [10]
demonstrated that fully Bayesian optimisation (FBO) was statistically more robust in adversarial
circumstances than ML-II. However, the study imposed strong assumptions, namely, the use of
conjugate prior for output-scale, the lack of automatic relevance determination, and discretisation of
length-scale. In today’s hardware and software environments, these assumptions are unnecessarily
restrictive and should be relaxed to obtain more general insights.

Over the past decade, a handful of studies adopted FBO that took advantage of more sophis-
ticated algorithms and modern software platforms [16–18]. However, in these studies, FBO was
adopted only because it served for evaluating their theoretical claims, and no further justiﬁcation
for the adoption was provided [19]. Apart from these studies, the research on FBO remains sparse,
and direct comparison between ML-II and FBO is virtually non-existent in the recent literature.

This paper provides three compelling reasons why researchers should consider adopting FBO for
their applications where evaluations are expensive. First, failures of ML-II are more commonplace
than implied by the existing studies which used the contrived scenarios. To support this argument,
the experiments are set up only using common speciﬁcations, which other researchers may ﬁnd
in their applications, including those of the objective function, random initialisation, models, and
algorithms. Second, FBO is more robust than ML-II, and the price of the robustness is almost
trivial. This is shown in the results obtained from the identical experimental settings. In addition, to
make the results relevant in modern applications, the restrictive assumptions in FBO speciﬁcations
previously used in the literature are relaxed. Third, thanks to the modern software platforms, FBO
is now simple to implement and fast enough to be practical. To demonstrate this, the experiments
In addition, the code used to implement
are implemented using Pyro [20] and BoTorch [21].
the experiments is written deliberately in a simple fashion so that it can serve as a template for
other applications. The last point is a small but practical contribution because the existing code
examples for FBO found in BoTorch package are written speciﬁcally for the particular study [18],
and modiﬁcation for other FBO applications is not very straightforward.

In what follows, ﬁrst, BO is reviewed as a technique to address a dynamic problem, which is
deemed a more accurate formulation when involving evaluation budgets. The reader is reminded
that, in this formulation, an optimal solution is intractable and suboptimality of BO is by design in
practical applications (Section 2). Next, FBO is reviewed where the marginalised acquisition func-
tion and its approximation are highlighted as the key diﬀerence (Section 3). Then, the experiments
are described with emphasis of the roles played by Pyro and BoTorch, and the results are discussed
(Section 4). Finally, some concluding remarks are provided for future applications (Section 5). All
the code and data are available on the website (https://github.com/ysaikai/case4fbo).

2 Bayesian optimisation

A common formulation of the BO problem is a static optimisation problem:

f (x)

min
x∈X

(1)

where f is the black-box objective function, and X is a compact subset of Euclidean space. When
BO is adopted in practice, however, it is often the case that function evaluations are expensive,
and there is an evaluation budget. If an evaluation budget is explicitly modelled, a more accurate
problem formulation is the following.

Let N be the total number of evaluations allowed. Then, the BO problem is a sequential
decision problem; that is, choose xn ∈ X for each n ∈ {1, . . . , N } based on the history, the

2

preceding observations

in order to minimise the best observed value after N evaluations:

{(x0, f (x0)), . . . , (xn−1, f (xn−1))},

min
n∈{1,...,N }

f (xn).

Note that this is a dynamic problem as each choice depends on the preceding choices.

1, . . . , x∗

Since evaluations are allowed to be made only N times, it is necessary to alternatively search for
an optimal sequence x∗
N without directly evaluating f . This is where the notion of surrogate
comes in. When BO with a GP surrogate is used to address the problem, an implicit assumption
is that f is a sample path of the speciﬁed GP as a stochastic process. For the ﬁxed GP, it is known
that an optimal sequence ˆx1, . . . , ˆxN in terms of the Bayes risk is, in principle, obtained by dynamic
programming [22]. However, except for trivial cases, the problem is numerically intractable [10].
Furthermore, as mentioned above, specifying a suitable GP for a particular problem beforehand is
rarely possible in practical problems. Instead, it is speciﬁed based on observations and sequentially
updated throughout the trials.

The expected improvement (EI) acquisition function is a practical one-step lookahead strategy
[2, 23]. As a myopic strategy, EI is necessarily suboptimal [24] but proved reasonable in many
applications [25]. Although many diﬀerent acquisition functions have been proposed, EI main-
tains the practical advantage owing to the intuitive notion of “improvement”, the relatively light
computational requirement, and the proven performance.

3 Fully Bayesian optimisation

Performance of BO is dictated by the GP surrogate and the acquisition function. Since the former
seems to take precedence over the latter [25], and a GP is characterised by kernel hyperparameters, it
is vitally important to carefully handle kernel hyperparameters and their uncertainty for successful
BO applications. The principled way to handle parameter uncertainty is to follow the Bayesian
formalism [26], according to which functions of uncertain parameters are weighted by the posterior
probabilities of the parameters. (While the maximum a posteriori estimation is also used in practice
to incorporate prior information, in the light of the Bayesian formalism, it does not fully reﬂect the
parameter uncertainty and omitted in this paper.)

Let θ and Dn denote respectively the hyperparameter and the data observed for the ﬁrst n steps.
Also, let α(x|θ, Dn) and p(θ|Dn) denote respectively the acquisition function and the posterior of
θ. Then, the marginalised acquisition function, the weighted average according to p(θ|Dn), is

α(x|Dn) = Eθ|Dnα(x|θ, Dn) =

(cid:90)

α(x|θ, Dn)p(θ|Dn)dθ.

In FBO, this is the function to maximise for the next query point

xn+1 ∈ argmax

x∈X

α(x|Dn).

(2)

(3)

In other words, due to the randomness in θ, it is a stochastic optimisation problem. Since the
above integral generally permits no analytic expression for α(x|Dn), in practice, use of approxi-
mation methods is required to carry out the maximisation. In BO contexts, the maximisation is
commonly addressed by the sample average approximation [27], which is well supported by BoTorch
as reviewed below.

3

Except for trivial cases, the posterior p(θ|Dn) is a complicated distribution, for which no oﬀ-
the-shelf sampler is available, so it is necessary to use some approximation methods to obtain
samples. Among many diﬀerent methods, Hamiltonian Monte Carlo is the gold standard [18] and,
in particular, the No-U-Turn sampler [28] is an attractive option as it spares researchers the trouble
of manually tuning the step size and path length in Hamiltonian Monte Carlo.

After obtaining M Monte Carlo samples, the marginalised acquisition function is approximated

by the ﬁnite sum:

α(x|Dn) ≈

1
M

M
(cid:88)

m=1

α(x|θm, Dn).

(4)

Given M samples, the right-hand side is a deterministic function, which is commonly maximised
using quasi-Newton methods such as L-BFGS-B [29].

4 Experiments

4.1 The test problem

To compare performances of the two approaches, ML-II and FBO, the experiments were conducted
using common speciﬁcations, which many researchers may ﬁnd in their applications. The perfor-
mance metrics is simple “regret” after N evaluations, diﬀerence between the true minimum and
the best observed value over N evaluations. Diﬀerent N ∈ {1, . . . , 30} corresponds to a diﬀerent
evaluation budget. The following table contains key speciﬁcations of the test problem.

Objective function
GP Kernel
GP Mean function
Noise variance
Prior for output-scale Log normal with mean 10 and standard deviation 10
Prior for length-scale

Ackley function on X ⊂ R2
Mat´ern 5/2
0 for all x
10−6

Log normal with mean 0.5 and standard deviation 0.5

The objective function was Ackley function [30], one of the common optimisation test func-
tions [31]. The function was speciﬁed by following the recommendation [31], which is also im-
plemented and the default setting in BoTorch. For example, the function domain was set to
X = [−32.768, 32.768] × [−32.768, 32.768].

The total 101 experiments were conducted, corresponding to 101 distinct x0 and random seeds
(0-100) appropriately set for reproducibility. Fixing random seeds was necessary not only for the
hyperparameter sampling but also for the random multistart used by BoTorch in optimisation of
acquisition functions and marginal likelihood. Each experiment was initialised by x0, which was
shared between ML-II and FBO. Then, the subsequent N observations were made by following
each approach.

The acquisition function is EI, which works relatively well for noise-less test functions [19]. The
class of GP is a basic one—the zero-mean function, Mat´ern(5/2) kernel with automatic relevance
determination, and an output-scale parameter. Although the objective function is noise-less, follow-
ing the convention, the noise variance is set to 10−6 for numerical stability. As a result, there were
three hyperparameters: one output-scale and two length-scales. In FBO, three prior distributions
were assumed to be independent.

4

While gamma distribution is also common, for both output-scale and length-scales, log normal
distribution was adopted as it has strictly diminishing probability towards 0, which helps to avoid
sampling unreasonably small length-scales, which could in turn cause numerical problems. The
mean for each prior was chosen based on empirical evidence, while the standard deviation was set
so that the relative standard deviation was equal to 1.

Note that the prior for length-scale reﬂects the fact that inputs to GP are normalised to be-
tween 0 and 1. Note also that output observations used for GP are standardised to have mean
0 and standard deviation 1, which justiﬁes the use of the zero-mean function. The sampler was
Hamiltonian Monte Carlo and the No-U-Turn sampler. Following the recommendation [18], at each
iteration, 512 samples were ﬁrst drawn as warm-up/burn-in samples and then 256 samples were
drawn, which were thinned to M = 16 = 256/16 samples by keeping only every 16th sample.

Many of the existing software implementations specify log normal distribution with two param-
eters for the mean and standard deviation of the corresponding normal distribution. In this case,
when the desired mean and standard deviation of log normal distribution are µ and σ, following
are the corresponding parameters of normal distribution:

µN = log µ −

log

(cid:115)

σN =

log

1
2
(cid:18) σ2

µ2 + 1

(cid:18) σ2

(cid:19)

µ2 + 1
(cid:19)
.

4.2 Software platforms

Software platforms play a crucial role in modern machine learning research and practice. In BO
applications, key numerical operations include computation of posterior GP, optimisation of acqui-
sition functions, optimisation of marginal likelihood (for ML-II), and sampling of hyperparameters
(for FBO). In this paper, Pyro and BoTorch were used to implement the experiments. The software
versions used for the experimentation are 3.9.7, 1.8.0, and 0.6.4 for Python, Pyro, and BoTorch
respectively.

Pyro facilitates posterior sampling of kernel hyperparameters. In general, Hamiltonian Monte
Carlo and the No-U-Turn sampler are sophisticated algorithms that compute the gradient of the
posterior probability density and solve the ordinary diﬀerential equations based on the Hamiltonian
while automatically tuning the step size and path length for the solver. As a result, manual
implementation requires a signiﬁcant amount of coding. With Pyro, however, the implementation
becomes quite simple and straightforward; essentially, it is only necessary to specify the priors and
desired number of samples.

BoTorch facilitates implementation of GPs and acquisition functions, computation of posterior
GP, optimisation of marginal likelihood, and optimisation of acquisition functions. While in FBO
optimisation of the acquisition function takes place using the sample average approximation (Eq.4),
BoTorch is designed to handle this operation eﬃciently.

Both platforms are built upon PyTorch and in particular take advantage of its automatic dif-
ferentiation functionality, which facilitates computing the gradient in optimisation by BoTorch and
Hamiltonian Monte Carlo by Pyro. Moreover, both platforms automatically implement parallel
processing and utilise multiple cores of CPU/GPU if available.

5

4.3 Results and Discussion

Figure 1 illustrates the results by plotting the regret at each evaluation budget N ∈ {1, . . . , 30}
for both ML-II and FBO in terms of median and region formed by the 10th and 90th percentiles.
The regret distribution at N = 0, which is identical between ML-II and FBO, reﬂects the dis-
tribution of function evaluations f (x0) at 101 random initial x0. This initial distribution largely
remains unchanged at N = 1 and N = 2. Then, indicated by the downward-sloped median curves,
performances of both approaches start to improve at N = 3 and continue until N = 30, although
the rate of improvement slows down after N ≈ 10. Throughout all the evaluation budgets, the
median performances and downward dispersion from the medians are very similar between ML-II
and FBO. In contrast, as N increases, two distributions in terms of upward dispersion increasingly
diverge. While the upward dispersion for FBO continues to shrink, the one for ML-II remains
large, indicating the greater number of failures. For more details, Figure 2 and 3 plot histograms
for N = 20 and 30 respectively.

Figure 1: The results from 101 experiments for each number of evaluation budgets (N=1,...,30). 101 experi-
ments are distinguished from each other by 101 distinct initial samples x0 and random seeds. The solid lines
represent the median values. The shaded regions are formed by the 10th and 90th percentiles.

6

024681012141618202224262830Number of evaluations (N)05101520RegretOptimisation of Ackley functionML-II10-90%FBO10-90%Figure 2: Regret distribution of 101 samples after 20 evaluations.

Figure 3: Regret distribution of 101 samples after 30 evaluations.

Given the strong similarity in median and downward dispersion, the shrinking upward dispersion
indicates that FBO has clear advantage over ML-II in terms of statistical robustness. However,
bear in mind that the advantage is only statistical, and FBO certainly can fail as indicated by the
occurrence of large regrets in Figure 2 and 3. First of all, since FBO uses sampling of random
hyperparameters, poor choices of output-scale and length-scale can happen. However, the inﬂuence
of these unlucky samples can be reduced by increasing the number of Monte Carlo samples (M in
Eq.4).

More fundamentally, even if using the exact marginalised acquisition function (Eq.2), FBO with
EI (or any other practical acquisition function) is still myopic and may fail when x0 is unfavourable.
As analysed in the literature, such unfavourable initial samples “fool” the interpretation of data

7

05101520Regret0369121518212427FrequencyRegret distribution at N=20ML-IIFBO0.02.55.07.510.012.515.017.520.0Regret03691215182124FrequencyRegret distribution at N=30ML-IIFBOand lead to “deceptive” GPs with ill-updated hyperparameters [8, 10], which in turn result in un-
informative acquisition functions and undermine the eﬀectiveness of BO. In real-world applications
where function evaluations are expensive, researchers may not have enough information about prob-
lems and have to choose initial samples more of less randomly. Consequently, the failures caused
by random x0 in the experiments are deemed a relevant warning to researchers.

What FBO can achieve is to dilute the harm by adopting a continuum of data interpretations
and averaging them out according to the posterior distribution of hyperparameters. Even 10 years
ago, without restrictive assumptions, FBO might not have been a practical option. Now, thanks to
the recent development of both software and hardware technologies, it can be a viable option for
many practical problems. Given the ease of implementation, the price of the robustness advantage
of FBO is only additional computation, which is approximately 10 times greater than for ML-
II. Considering the expensiveness of experiments, however, the extra computing time is relatively
trivial in many applications. Thus, use of FBO is a simple way to guard against potential failures
that end up wasting precious research resources.

5 Conclusion

While small-sample performance is the main reason to use Bayesian optimisation when function
evaluations are expensive, the standard approach based on type II maximum likelihood may fail
in many practical applications. The paper made the case for fully Bayesian optimisation as a
more robust and viable alternative. Thanks to the modern software and hardware technologies,
the implementation is simple, and the execution is fast enough to be practical in many cases.
Since the beneﬁts seem to outweigh the costs, researchers should consider adopting fully Bayesian
optimisation for their applications so that they can guard against potential failures that end up
wasting precious research resources.

References

[1] Konstantinos Chatzilygeroudis, Vassilis Vassiliades, Freek Stulp, Sylvain Calinon, and Jean-
Baptiste Mouret. “A survey on policy search algorithms for learning robot controllers in a
handful of trials”. In: IEEE Transactions on Robotics 36.2 (2020), pp. 328–347.

[2] Donald R Jones, Matthias Schonlau, and William J Welch. “Eﬃcient global optimization of
expensive black-box functions”. In: Journal of Global optimization 13.4 (1998), pp. 455–492.

[3] David JC MacKay. “Comparison of approximate methods for handling hyperparameters”.

In: Neural computation 11.5 (1999). Publisher: MIT Press, pp. 1035–1068.

[4] Vidhi Lalchand and Carl Edward Rasmussen. “Approximate Inference for Fully Bayesian
Gaussian Process Regression”. In: Proceedings of The 2nd Symposium on Advances in Ap-
proximate Bayesian Inference. Ed. by Cheng Zhang, Francisco Ruiz, Thang Bui, Adji Bousso
Dieng, and Dawen Liang. Vol. 118. Proceedings of Machine Learning Research. PMLR, 2020,
pp. 1–12.

[5] Ziyu Wang and Nando de Freitas. “Theoretical analysis of Bayesian optimisation with un-
known Gaussian process hyper-parameters”. In: arXiv preprint arXiv:1406.7758 (2014).

[6] Carl Edward Rasmussen and Christopher K Williams. Gaussian Processes for Machine Learn-

ing. MIT Press, 2006.

8

[7] Donald R Jones. “A taxonomy of global optimization methods based on response surfaces”.

In: Journal of global optimization 21.4 (2001). Publisher: Springer, pp. 345–383.

[8] Alexander Forrester and Donald Jones. “Global optimization of deceptive functions with
sparse sampling”. In: 12th AIAA/ISSMO multidisciplinary analysis and optimization confer-
ence. 2008, p. 5996.

[9] Adam D Bull. “Convergence rates of eﬃcient global optimization algorithms.” In: Journal of

Machine Learning Research 12.10 (2011).

[10] Romain Benassi, Julien Bect, and Emmanuel Vazquez. “Robust Gaussian process-based global
optimization using a fully Bayesian expected improvement criterion”. In: International Con-
ference on Learning and Intelligent Optimization. Springer, 2011, pp. 176–190.

[11] Anthony O’Hagan. “Curve ﬁtting and optimal design for prediction”. In: Journal of the Royal

Statistical Society: Series B (Methodological) 40.1 (1978), pp. 1–24.

[12] Mark S Handcock and Michael L Stein. “A Bayesian analysis of kriging”. In: Technometrics

35.4 (1993). Publisher: Taylor & Francis, pp. 403–410.

[13] Marco Locatelli and Fabio Schoen. “An adaptive stochastic global optimization algorithm
for one-dimensional functions”. In: Annals of Operations research 58.4 (1995). Publisher:
Springer, pp. 261–278.

[14] Marco Locatelli. “Bayesian algorithms for one-dimensional global optimization”. In: Journal

of Global Optimization 10.1 (1997), pp. 57–76.

[15] Michael A Osborne, Roman Garnett, and Stephen J Roberts. “Gaussian processes for global

optimization”. In: 3rd international conference on learning and intelligent optimization (LION3).
Citeseer, 2009, pp. 1–15.

[16] Jasper Snoek, Hugo Larochelle, and Ryan P Adams. “Practical Bayesian optimization of
machine learning algorithms”. In: Advances in neural information processing systems. 2012,
pp. 2951–2959.

[17] Jos´e Miguel Hern´andez-Lobato, Matthew W Hoﬀman, and Zoubin Ghahramani. “Predictive
entropy search for eﬃcient global optimization of black-box functions”. In: Advances in neural
information processing systems. 2014, pp. 918–926.

[18] David Eriksson and Martin Jankowiak. “High-dimensional Bayesian optimization with sparse
axis-aligned subspaces”. In: Proceedings of the Thirty-Seventh Conference on Uncertainty in
Artiﬁcial Intelligence. Ed. by Cassio de Campos and Marloes H. Maathuis. Vol. 161. Proceed-
ings of Machine Learning Research. PMLR, 2021, pp. 493–503.

[19] George De Ath, Richard M Everson, and Jonathan E Fieldsend. “How Bayesian should
Bayesian optimisation be?” In: Proceedings of the Genetic and Evolutionary Computation
Conference Companion. 2021, pp. 1860–1869.

[20] Eli Bingham, Jonathan P Chen, Martin Jankowiak, Fritz Obermeyer, Neeraj Pradhan, The-
ofanis Karaletsos, Rohit Singh, Paul Szerlip, Paul Horsfall, and Noah D Goodman. “Pyro:
Deep universal probabilistic programming”. In: The Journal of Machine Learning Research
20.1 (2019). Publisher: JMLR. org, pp. 973–978.

[21] Maximilian Balandat, Brian Karrer, Daniel Jiang, Samuel Daulton, Ben Letham, Andrew
G Wilson, and Eytan Bakshy. “BoTorch: a framework for eﬃcient Monte-Carlo Bayesian
optimization”. In: Advances in neural information processing systems 33 (2020), pp. 21524–
21538.

9

[22] Bruno Betr`o. “Bayesian methods in global optimization”. In: Journal of Global Optimization

1.1 (1991). Publisher: Springer, pp. 1–14.

[23] J Mo´ckus, V Tiesis, and A ´Zilinskas. “The Application of Bayesian Methods for Seeking the
Extremum.” In: L Dixon and G Szego. Toward Global Optimization. Vol. 2. Amsterdam, The
Netherlands: Elsevier, 1978.

[24] David Ginsbourger and Rodolphe Le Riche. “Towards Gaussian process-based optimization
with ﬁnite time horizon”. In: mODa 9–Advances in Model-Oriented Design and Analysis.
Springer, 2010, pp. 89–96.

[25] Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P Adams, and Nando De Freitas. “Taking
the human out of the loop: A review of bayesian optimization”. In: Proceedings of the IEEE
104.1 (2015), pp. 148–175.

[26] Andrew Gelman, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B

Rubin. Bayesian data analysis. CRC press, 2013.

[27] Tito Homem-de-Mello and G¨uzin Bayraksan. “Monte Carlo sampling-based methods for
stochastic optimization”. In: Surveys in Operations Research and Management Science 19.1
(2014). Publisher: Elsevier, pp. 56–85.

[28] Matthew D Hoﬀman and Andrew Gelman. “The No-U-Turn sampler: adaptively setting path
lengths in Hamiltonian Monte Carlo.” In: Journal of Machine Learning Research 15 (2014),
pp. 1593–1623.

[29] Richard H Byrd, Peihuang Lu, Jorge Nocedal, and Ciyou Zhu. “A limited memory algorithm
for bound constrained optimization”. In: SIAM Journal on scientiﬁc computing 16.5 (1995).
Publisher: SIAM, pp. 1190–1208.

[30] David Ackley. A connectionist machine for genetic hillclimbing. Boston, MA: Kluwer Aca-

demic Publishers, 1987.

[31] Sonja Surjanovic and Derek Bingham. Optimization Test Functions and Datasets. url: http:

//www.sfu.ca/∼ssurjano/optimization.html.

10

