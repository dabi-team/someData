ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

1

Goal-Aware RSS for Complex Scenarios
via Program Logic

Ichiro Hasuo1,7,∗, Clovis Eberhart1,8,∗, James Haydon1,∗, J´er´emy Dubut1,8, Rose Bohrer2,†, Tsutomu Kobayashi1,
Sasinee Pruekprasert1, Xiao-Yi Zhang1, Erik Andr´e Pallas3,‡, Akihisa Yamada4,1, Kohei Suenaga5,1, Fuyuki

Ishikawa1, Kenji Kamijo6, Yoshiyuki Shinya6, and Takamasa Suetomi6

2
2
0
2

l
u
J

6

]

O
R
.
s
c
[

1
v
7
8
3
2
0
.
7
0
2
2
:
v
i
X
r
a

a

extension

introduce

goal-aware

Abstract—We

of
responsibility-sensitive
safety (RSS), a recent methodology
for rule-based safety guarantee for automated driving systems
(ADS). Making RSS rules guarantee goal achievement—in
addition to collision avoidance as
in the original RSS—
requires complex planning over long sequences of manoeuvres.
To deal with the complexity, we introduce a compositional
reasoning framework based on program logic, in which one can
systematically develop RSS rules for smaller subscenarios and
combine them to obtain RSS rules for bigger scenarios. As the
basis of the framework, we introduce a program logic dFHL
that accommodates continuous dynamics and safety conditions.
Our framework presents a dFHL-based workﬂow for deriving
goal-aware RSS rules; we discuss its software support, too.
We conducted experimental evaluation using RSS rules in a
safety architecture. Its results show that goal-aware RSS is
indeed effective in realising both collision avoidance and goal
achievement.

Index Terms—automated driving, safety, rule-based safety,
responsibility-sensitive safety (RSS), program logic, Floyd–Hoare
logic, differential dynamics, simplex architecture

I. INTRODUCTION

S AFETY of automated driving systems (ADS) is a problem

of growing industrial and social interest. New technologies
in sensing and planning (such as lidars and deep neural
networks) are making ADS technologically possible. However,

© 2022 IEEE. Personal use of this material is permitted. Permission from
IEEE must be obtained for all other uses, in any current or future media,
including reprinting/republishing this material for advertising or promotional
purposes, creating new collective works, for resale or redistribution to servers
or lists, or reuse of any copyrighted component of this work in other works.
The work is partially supported by ERATO HASUO Metamathematics for
Systems Design Project (No. JPMJER1603) and ACT-I (No. JPMJPR17UA),
JST; and Grants-in-aid No. 19K20215 & 19K20249, JSPS.

1National Institute of Informatics (NII), Tokyo 101-8430, Japan. {hasuo,
jhaydon, eberhart, dubut, t-kobayashi, sasinee, xiaoyi, f-ishikawa}@nii.ac.jp
2 Dept. Computer Science, Worcester Polytechnic Institute, 100 Institute

Road, Worcester, MA 01609-2280, USA. rose.bohrer.cs@gmail.com

3 Inst. Software & Systems Engineering, University of Augsburg, Univer-

sit¨atstraße 6a, D-86135 Augsburg, Germany. erik.pallas@t-online.de

4 Cyber Physical Security Research Center, AIST, Aomi 2-4-7, Tokyo 135-

0064, Japan. akihisa.yamada@aist.go.jp

5 Graduate School of Informatics, Kyoto University, Kyoto 606-8501, Japan.

ksuenaga@fos.kuis.kyoto-u.ac.jp

6 Mazda Motor Corporation, Fuchu 730-8670, Japan. {kamijyo.k, shinya.y,

suetomi.t}@mazda.co.jp

7 SOKENDAI (The Graduate University for Advanced Studies), Japan.
8 Japanese-French Laboratory for Informatics (IRL 3527), Tokyo, Japan
∗ Equal contribution.
† The work was done during R.B.’s employment at NII, Tokyo.
‡ The work was done during E.P.’s internship at NII, Tokyo.

towards the social acceptance of ADS, their safety should be
guaranteed, explained, and agreed upon.

is

paper

[1]—a recent

safety
responsibility-sensitive
about
This
(RSS)
rule-based approach to ADS safety.
Our contribution is to make the RSS framework goal-aware,
so that logical “safety rules” in RSS

• not only guarantee collision avoidance (as in the original

RSS [1]),

• but also guarantee goal achievement, such as changing
lanes and stopping at a designated position on the highway
shoulder (Example I.5).

Goal-aware RSS rules typically involve multiple manoeuvres
(accelerating, braking, changing lanes, etc.); deriving goal-
aware RSS rules and proving their correctness is therefore
much more complex compared to the original RSS. As tech-
nical contribution, we introduce logical, methodological and
software infrastructures that realise goal-aware RSS. They are
namely 1) a program logic suited for our purpose (called
dFHL, Section II), 2) a logical workﬂow for compositional
derivation of goal-aware RSS rules (Section IV), and 3) soft-
ware support for the workﬂow (Section V). We demonstrate
the value of our goal-aware RSS by experiments in a safety
architecture (Section VI).

A. (Collision-Avoiding) Responsibility-Sensitive Safety

(The original) responsibility-sensitive safety (RSS) [1] is
an approach to ADS safety that has been attracting growing
attention. RSS aims to provide safety rules that are rigorously
formulated in mathematical terms. Unlike most algorithms and
techniques studied for ADS, RSS is not so much about how
to drive safely; it is rather about breaking down the ultimate
goal (namely safety in the future) into concrete conditions that
only depend on the current system state. The core idea of RSS
is that those safety rules should guarantee ADS safety in the
rigorous form of mathematical proofs.

Here is an outline of original RSS [1]. We will often call the
original RSS [1] collision-avoiding RSS (CA-RSS), in contrast
to our extension that we call goal-aware RSS (GA-RSS). When
we simply say RSS, the argument should apply to both CA-
and GA-RSS.1

1Our introduction of CA-RSS here adapts some terminologies for our
purpose of extending it later; the terminologies can therefore differ from those
used in [1]. Another logic-oriented introduction to CA-RSS is found in [2].

© 2022 IEEE

 
 
 
 
 
 
ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

2

CA-RSS introduces RSS rules in a manner speciﬁc to
different driving scenarios (driving in a single lane, changing
lanes, other vehicles in front or behind, etc.). An RSS rule is
a pair (A, α) of

• a logical assertion A called an RSS condition, and
• a control strategy α called a proper response.
An RSS rule is subject to the following requirements.

Requirements I.1 (requirements on RSS rules, in CA-RSS).
Let (A, α) be an RSS rule. Consider an arbitrary execution E
of the proper response α; assume that the RSS condition A is
satisﬁed at the beginning of E. Then

• (the collision avoidance requirement) the execution E in

question must exhibit no collision; and

• (the responsibility requirement) the execution E must

satisfy the RSS responsibility principles.

The last RSS responsibility principles,

taken literally

from [1], are listed below (cf. Remark I.2).
1) Don’t hit the car in front of you.
2) Don’t cut in recklessly.
3) Right of way is given, not taken.
4) Be cautious in areas with limited visibility.
5) If you can avoid a crash without causing another one,

you must.

One signiﬁcance of the RSS framework is that the safety in
the future (that is, safety during the whole execution E of α)
is reduced to the RSS condition A at present (that is, one
that can be checked at the beginning of E). In other words,
the truth of A at present guarantees the safety in the future.
This means that, in particular, A and α must take into account
all possible future evolutions of the driving situation, such as
sudden braking or acceleration of other vehicles, etc.

Another signiﬁcance of RSS is the assume-guarantee rea-
soning via responsibilities. Establishing the collision avoidance
requirement (Requirements I.1) for the subject vehicle (SV) is
usually impossible without suitable assumptions on other ve-
hicles’ behaviours—imagine a malicious vehicle that actively
chases others and hits them. In RSS, one can impose the
RSS responsibility principles on other vehicles and limit their
behaviours; reciprocally, SV must obey the same principles,
too.

Remark I.2. The ﬁve RSS responsibility principles (as we
call them) are often called “safety rules” and “common sense
rules” in the RSS literature such as [1]. These principles are
often presented as the main concept of RSS—especially in the
presentation to the general public, such as Mobileye/Intel’s
webpage.2 However, we believe that the logical framework
of RSS (including reduction of the future to the present and
assume-guarantee reasoning, as discussed above) is at least as
important. The focus of the current paper is formalising and
extending this logical framework of RSS.

Example I.3 (a CA-RSS rule for one-way trafﬁc). Consider the
one-way trafﬁc scenario shown in Figure 1, where the subject
vehicle (SV, carrear) drives behind another car (carfront).

2https://www.mobileye.com/responsibility-sensitive-safety

Fig. 1: The one-way trafﬁc scenario

The (collision-avoiding) RSS rule for this simple scenario,
presented in [1], is (A, α) deﬁned as follows.

The RSS condition A The RSS condition A is

A = (cid:0)yf − yr > dRSS(vf , vr)(cid:1),

(1)

where dRSS(vf , vr) is the RSS safety distance deﬁned by

dRSS(vf , vr) :=

(cid:32)

max

0, vrρ +

1
2

amaxρ2 +

(vr + amaxρ)2
2bmin

−

v2
f
2bmax

(cid:33)

.

(2)
Here yf , yr are the positions of the two cars, and vf , vr
are their velocities (their dynamics are modelled in the 1-
dimensional
lane coordinate). The other parameters are as
follows: ρ is the maximum response time that carrear might
take to initiate the required braking; amax is the maximum
(forward) acceleration rate of carrear; bmin is the maximum
comfortable braking rate for carrear; and bmax is the maximum
emergency braking rate for carfront.

The proper response α The proper response α dictates SV
(carrear) to engage the maximum comfortable braking (at rate
bmin) when condition (1) is about to be violated.

That the RSS rule (A, α) satisﬁes the collision avoidance
requirement (Requirements I.1) is proved in the original RSS
paper [1]. We also give a formal proof later in Example II.15,
using the logic dFHL we introduce for our purpose of formal-
ising reasoning in RSS.

B. Usages of RSS

Before introducing our goal-aware extension of RSS, we
discuss some usages of (CA- and GA-)RSS, hoping that the
discussion further illustrates the goals and features of RSS.

A distinguishing feature of RSS is that it gives a priori rules

for rigorous safety guarantee. This is in contrast with

• many optimisation- and learning-based planning algo-
rithms for safe driving, such as [3] (they do not offer
rigorous safety guarantee),

• testing-based approaches for ADS safety, such as [4] (they

do not offer rigorous safety guarantee, either), and

• runtime veriﬁcation approaches for ADS safety by reach-

ability analysis, such as [5], [6].

(See Section I-G for further discussion.) This feature has
enabled multiple unique usages of RSS, as we discuss below.
These usages have been already pursued in the literature for
CA-RSS; we expect similar usages for our GA-RSS as well.
One usage of RSS is for attribution of liability [7], that is, to
identify culpable parties in accidents. RSS rules are designed
so that there is no collision as long as all parties comply with
them (Requirements I.1); therefore, in an accident, at least one
party was not compliant and is therefore culpable.

carrearcarfrontxACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

3

Another usage is as a safety metric (discussed and/or used
in [8]–[12]). Here, the risk of a given situation can be measured
by either 1) the degree with which the RSS condition of a
relevant RSS rule is violated, or 2) whether the proper response
of the RSS rule is not engaged while it should.

Another obvious usage of RSS is for formal reasoning
about ADS safety: by proving that SV complies with RSS
rules, one can prove a priori that SV is never responsible for
accidents. Often one does not go so far as formally proving
SV’s compliance with RSS rules. Even in that case, collecting
empirical evidences for RSS compliance, e.g. by testing, allows
one to establish logical safety cases. The importance of such
safety cases are emphasised in standards such as UL 4600 [13];
the use of RSS is advocated in the current efforts towards the
IEEE 2846 standard.

Yet another usage of RSS is as part of a safety architecture,
whose detailed introduction is deferred to Section I-E. This is
a variation of the last usage (formal safety reasoning), but is
more widely and easily deployable, and is therefore attracting
a lot of attention (see e.g. [14, Figure 1]). Our experimental
evaluation (Section VI) follows this usage.

After all, RSS rules are not only for making ADS safer
but also for limiting liabilities. In the dawn of automated
driving today, ADS vendors are under a lot of pressure to
ensure the safety of their products, fearing the possibilities
of unexpected or excessive liabilities. RSS rules cut clear
mathematical bounds of the vendors’ liabilities, easing their
safety assurance efforts.

C. Goal-Aware RSS

We seek a goal-aware extension of the original (collision-
avoiding) RSS [1], so that the RSS rules are not only concerned
with collision avoidance but also with achieving a goal.

Requirements I.4 (requirements on RSS rules, in GA-RSS).
In goal-aware RSS (GA-RSS), an RSS rule (A, α) must satisfy
the following: for any execution E of the proper response α
that starts at a state where the RSS condition A is true,

• (collision avoidance, the same as in Requirements I.1),
• (responsibility, the same as in Requirements I.1), and
• (the goal achievement requirement) the speciﬁed goal is

achieved at the end of E.

Deriving such goal-aware RSS rules and establishing their
correctness (in the sense of Requirements I.4) pose multiple
technical challenges. They include

• the formalisation of goals to be achieved,
• the identiﬁcation of proper responses α, which would in-
volve multiple manoeuvres (accelerating, braking, chang-
ing lanes, etc.),

• the identiﬁcation of RSS conditions A that guarantee
both collision avoidance and goal achievement along/after
complex controls described by α,

and so on. The technical contribution of the current paper is
a program logic framework that addresses these challenges. It
enables compositional derivation of goal-aware RSS rules, as
we will describe in Section I-D.

Example I.5 (the pull over scenario). Consider the scenario
shown in Figure 2.3 Here SV is initially in Lane 1; its goal is to
pull over to Lane 3 (the shoulder) at the speciﬁed position ytgt.
There are three principal other vehicles (POVs); two POVs are
in Lane 2 and the other is in Lane 1. This scenario is relevant
to automated emergency stop, an important example of level-4
ADS conditions.

Our aim here is to design an RSS condition A and a proper
response α that satisfy Requirements I.4. We ﬁnd that the
design of such (A, α) is harder than in the collision-avoiding
case in Example I.3. Major challenges include the following.
• (Complexity of a scenario) Achieving the ultimate goal
(stopping in Lane 3 at ytgt) is achieved by a series of
subgoals, such as changing lanes.

• (High-level manoeuvre planning) There can be multiple
high-level manoeuvre sequences that are feasible. In the
current scenario, they are speciﬁcally 1) to merge between
POV2 and POV1, and 2) to merge after POV1. These will
have different corresponding RSS conditions, and we have
to systematically compute them.

• (Multiple constraints at odds) To merge between POV2
and POV1, SV may need to accelerate in Lane 1, in order
to make enough space behind. However, doing so incurs
the risk of driving too fast to stop at ytgt in Lane 3.
• (Safety vs. goal-achievement) Proper responses should
achieve both goal achievement and collision avoidance,
which may be at odds as well. For example, the acceler-
ation discussed above should also take into account the
distance from POV3.

It is obvious that collision-avoiding RSS rules do not sufﬁce
to ensure goal achievement. For example, avoiding collision
without an eye to the ultimate goal can trap SV in Lane 1,
making it reach the position ytgt without changing lanes. We
experimentally show that this can indeed happen (Section VI).

D. Compositional Derivation of GA-RSS Rules by Program
Logic

Reasoning under the level of complexity in Example I.5
is hardly seen in the existing RSS literature. To address
in this paper, we propose a structured and
the challenge,
compositional approach by the application of program logic.

More speciﬁcally, our approach in this work is
• ﬁrstly to decompose a scenario into subscenarios, along

subgoals such as those shown in Figure 3,

• to identify proper responses for each subscenario (which
is easier since subscenarios are simpler, see Figure 3), and
• to identify preconditions of those subscenario proper
responses so that each precondition guarantee both 1) the
goal of the subscenario and 2) the precondition of the
subsequent proper response. Here we reason backwards
along a sequence of subscenarios (from Subgoal 4 to
Subgoal 1 in Figure 3), much like backward predicate
transformers in program logic [15].

A proper response for the whole scenario is then obtained
by combining the proper responses for subscenarios; so is the
corresponding RSS condition for the whole scenario.

The following is our leading example for goal-aware RSS.

3We assume that cars drive on the left, as in Japan, UK and other countries.

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

4

Fig. 2: The pull over scenario

Fig. 3: Subgoals in the pull
over scenario

In Section IV, we formulate the above workﬂow in terms of
the program logic that we introduce in Section II—the latter is
called differential Floyd–Hoare logic dFHL. The logic dFHL
extends classic Floyd–Hoare logic [16] in 1) accommodation
of continuous-time dynamics speciﬁed by ODEs and 2) what
we call safety conditions that must hold all the time during ex-
ecution. In Section II, we introduce derivation rules for dFHL
that addresses these extensions; we prove their soundness too.
The second extension discussed above (safety conditions)
makes the logic dFHL use Hoare quadruples {A} α {B} : S,
instead of triples {A} α {B} in the original Floyd–Hoare
logic. This extension follows the idea formally presented
in [17]; see Section I-G for further discussions. Explicating a
safety condition S allows us to reason simultaneously about
goal achievement (modelled by the postcondition B) and
collision avoidance (modelled by S).

Our logic dFHL can be seen as a variant of Platzer’s
differential dynamic logic dL [18]—we believe that embedding
of dFHL in dL is possible. Among a number of differences, a
major one is our choice of the Hoare-style syntax ({A} α {B}
with the safety extension : S discussed above) rather than
the dynamic logic-style one (A ⇒ [α]B, as in dL). This
syntactic choice ﬁts the purpose of formalising our workﬂow
(Section IV), where the emphasis is on compositional reason-
ing along sequential compositions.

We also discuss software support for the workﬂow in Sec-
tion V. Our current implementation is partially formalised in
the sense that 1) rule applications in dFHL are not formalised,
but 2) symbolic reasoning about real numbers (such as solving
quadratic equations) is formalised in Mathematica. Moreover,
the interactive features of Mathematica notebooks are exploited
so that even the informal part of reasoning is well-documented
and thus trackable. We also discuss prospects of full formali-
sation.

Fig. 4: The simplex architecture

A prototypical safety architecture is the simplex architecture
shown in Figure 4 [19], [20]. Here, the advanced controller
(AC) is a complex controller that pursues not only safety but
also other performance measures (such as comfort, progress,
and fuel efﬁciency); the baseline controller (BC) is a simpler
controller with a strong emphasis on safety; and the decision
module (DM) switches between the two controllers. DM tries
to use AC as often as possible for its superior performance.
However, when DM ﬁnds that the current situation is safety
critical, it switches to BC, whose behaviours are more pre-
dictable and easier to analyse.

The point of the simplex architecture is that the system’s
safety can be formally veriﬁed even if AC is a black box.
Logically, DM enforces contracts that AC should respect. The
safety of the whole system can then be established by formally
reasoning about DM, the plant (P), and BC (that takes over
the control in case AC cannot comply with the contracts).
Speciﬁcally,
to formally prove that a system guided by a
simplex architecture is safe, it is enough to show that BC is,
and that DM gives control to BC soon enough. Safety of AC is
irrelevant to the proof here. This point is especially appealing
for ADS, whose AC typically involves a number of learning
and optimisation components and thus is very hard to formally
analyse.

The components of an RSS rule (A, α) map naturally to the

simplex architecture:

• DM can be made so that it implements the RSS condition
A. It uses AC as long as A is robustly satisﬁed; however,
when A is about to be violated, it switches the control to
BC.

• BC can implement the proper response α. Safety of its

execution is then guaranteed by Requirements I.1.

• If it happens that

the robust satisfaction of the RSS
condition A is restored during BC’s execution, DM can
switch back from BC to AC.

In this way, a possibly unsafe AC can be made safe, via suitable
intervention of RSS-based DM and BC. The whole system built
this way will be called an RSS-supervised controller.
In Section VI, we present our implementation of

• the GA-RSS rule for Example I.5 (pull over) that we

derive in Section IV, and

E. RSS-Supervised Controller: RSS in a Safety Architecture

We continue Section I-B and discuss the usage of (CA- and
GA-)RSS that is the most relevant to us, namely in a safety
architecture. We use GA-RSS in this way to experimentally
demonstrate its signiﬁcance (Section VI).

• the CA-RSS rule in Example I.3 (one-way trafﬁc), natu-
rally adapted to the multi-lane setting of Example I.5,

both in the simplex architecture (AC is a trajectory planner
based on sampling and optimisation). Our experiments for the
scenario in Example I.5 demonstrate that the GA-RSS rule

yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV2POV3Goal:stop hereyytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV2POV3Subgoal 1:get ready to mergeSubgoal 2: change to Lane 2Subgoal 3: change to Lane 3Subgoal 4: stop hereDecision Module(DM)Plant(P)AdvancedController (AC)BaselineController (BC)ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

5

indeed achieves the goal safely, while the CA-RSS rule fails
to do so.

F. Contributions

This paper introduces the idea of goal-aware RSS (GA-
RSS). We claim that goal-aware RSS rules may be developed
for complex scenarios, and that they are suited for use in
the simplex architecture. These claims are backed up by the
following technical contributions; they collectively establish a
program logic framework for GA-RSS.

• We introduce a program logic dFHL (differential Floyd–
Hoare logic) as a logical foundation for GA-RSS (Sec-
tion II). It extends classic Floyd–Hoare logic by 1) differ-
ential dynamics and 2) safety conditions (S in our Hoare
quadruples {A} α {B} : S). We introduce derivation
rules for dFHL and prove their soundness.
The main novelty here is dealing with the combination
of the two extensions, speciﬁcally in the (DWH) rule in
Figure 7.

• We develop a compositional workﬂow for deriving GA-
RSS rules. It is formulated in terms of dFHL, exploiting
the organising power of the logic. We also describe
software support for the workﬂow by Mathematica.

• We run the workﬂow for the pull over scenario (Exam-
ple I.5). The resulting GA-RSS rule is implemented in the
simplex architecture. Its experimental comparison with 1)
no simplex and 2) a CA-RSS rule demonstrates the value
of GA-RSS.

G. Related and Future Work

Much of the related work on RSS has been already dis-
cussed. Recent extensions of RSS include a risk-aware one [14]
and one that allows swerves as evasive manoeuvres [21].
These extensions shall be pursued in our current goal-aware
framework. In particular, allowing swerves should be possible,
and it will signiﬁcantly improve the progress of a RSS-
supervised controller.

Inclusion of safety conditions in the Floyd–Hoare logic—
in the form of Hoare quadruples—is also pursued in [17], in
the context of veriﬁcation of concurrent systems. Our logic
dFHL combines the idea with the machinery of dL [18]
for handling continuous dynamics. In particular, our main
technical novelty—namely an inference rule for continuous
dynamics and safety (Section II-B)—does not appear in [17],
[18].

Some RSS rules have been implemented and are offered as a
library [22]. Integration of the goal-aware RSS rules we derive
in this paper, in the library, is future work. One advantage of
doing so is that the GA-RSS rules will then accommodate
varying road shapes.

This paper studies logical derivation of GA-RSS rules,
with a prospect of fully formal derivation (see Section V-C).
The problem of formally verifying correctness of RSS rules
is formulated and investigated in [23]. Their formulation is
based on a rigorous notion of signal; they argue that none
of the existing automated veriﬁcation tools is suited for
the veriﬁcation problem. This concurs with our experience

so far—in particular, formal treatment of other participants’
responsibilities (in the RSS sense) seems to require human
intervention. At the same time, in our preliminary manual
veriﬁcation experience in KEYMAERA X, we see a lot of
automation opportunities. Developing proof tactics dedicated
to those will ease manual veriﬁcation efforts.

An idea similar to that of RSS-supervised controllers (Sec-
tion I-E) is found in [24]. BC in [24] is a learning-based
controller that is realised by an RNN and is trained to follow
given safety rules. This is unlike our RSS-based BC that
executes explicitly RSS proper responses. There is no statistical
learning, hence no uncertainties from black-box learning, in
our BC.

In [6], a rigorous guarantee of ADS safety is pursued via
the notion of invariably safe set. The latter is deﬁned in
terms of backward reachability analysis, and in that sense,
the work is similar to RSS and the current work. The biggest
difference is that the approach in [6] is about runtime and
numeric veriﬁcation while RSS is about static, a priori and
symbolic rules. Consequently, many usages of RSS discussed in
Section I-B do not apply to [6]. Moreover, the symbolic nature
of RSS is what allows compositional derivation of rules, the
key contribution of this work. At the same time, the numeric
and online nature of [6] will probably yield less conservative
control actions. Overall, it seems that the two works target at
different classes of driving situations: [6] for urban scenarios
(less structure, shorter-term control); this work is for highway
scenarios (more structure, longer-term control).

Formal (logical, deductive) veriﬁcation of ADS safety is
also pursued in [25] using the interactive theorem prover
Isabelle/HOL [26]. The work uses a white-box model of
a controller, and a controller must be very simple. This is
unlike RSS and the current work, which allows black-box ACs
and thus accommodates various real-world controllers such as
sampling-based path planners (Section I-E).

In the presence of perceptual uncertainties (such as errors
in position measurement and object recognition), it becomes
harder for BCs and DMs to ensure safety. Making BCs tolerant
of perceptual uncertainties is pursued in [27], [28]. One way
to adapt DMs is to enrich their input so that they can better
detect potential hazards. Feeding DNNs’ conﬁdence scores is
proposed in [29]; in [30], it is proposed for DMs to look at
inconsistencies between perceptual data of different modes.

H. Organisation of the Paper

In Section II, we introduce our program logic dFHL, intro-
ducing its syntax, semantics, and derivation rules. We prove
the soundness of the derivation rules, too (Theorem II.14).
In Section III, we formulate our problem of deriving GA-RSS
rules, based on the mathematical notion of driving scenario
that we also introduce there. Our workﬂow for compositional
derivation of GA-RSS rules is presented in Section IV, where
our main theorem is the correctness of the workﬂow (Theo-
rem IV.11) assuming the correctness in each subscenario (the
condition (15)). We use the pull over scenario (Example I.5) as
a leading example, and derive a GA-RSS rule for it. Software
support for the workﬂow is discussed in Section V (the current

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

6

partially formal one and the prospects of full formalisation).
Our experimental evaluation is discussed in Section VI, where
our implementation of the GA-RSS rules for Example I.5 in
the simplex architecture is compared with those without BC
and with CA-RSS. In Section VII we conclude.

2) Formal Deﬁnition: We formally deﬁne dFHL. An exam-

ple is in Example II.10.

Deﬁnition II.2 ((dFHL) assertions). A term is a rational
polynomial on a ﬁxed inﬁnite set V of variables. dFHL
assertions are generated by the grammar

II. DIFFERENTIAL FLOYD-HOARE LOGIC dFHL

A. The Syntax of dFHL: Assertions, Hybrid Programs, and
Hoare Quadruples

Notation II.1. In this paper, we let [1, N ] denote the set
{1, 2, . . . , N } of integers, where N is a positive integer.

1) Overview of the Syntax: In this section, we describe three
ingredients to formalise our rules: assertions, hybrid programs,
and Hoare quadruples. Let us give some intuition before we
delve into formal deﬁnitions.

Assertions are logical objects describing qualitative prop-
erties of states. For example, in the one-way trafﬁc scenario
of Example I.3, if we denote by yf and vf the position and
velocity of the front car and yr and vr those of the rear car,
we will write an assertion ¬(vf = 0 ∧ vr = 0) ∧ yr < yf
to describe the conﬁgurations where at least one car is not
stopped and for which there is no collision.

Hybrid programs are a combination of usual programs of
imperative languages (such as IMP [31]) and differential equa-
tions that express continuous dynamics. Our syntax therefore
contains assignments, if-branchings, etc., but also constructs
allowing the state to change following the solutions of differen-
tial equations. The terminology “hybrid program” comes from
differential dynamic logic [18], which uses a slightly different
syntax, but to which our syntax can be translated.

Finally, Hoare quadruples {A} α {B} : S relate both
assertions and hybrid programs to formally specify and prove
correctness of the latter. The traditional Floyd–Hoare logic [16]
uses Hoare triples {A} α {B} that roughly means the truth
of a precondition A guarantees the truth of a postcondition B
after the execution of a program α. In dFHL, following [17],
we extend the above classic syntax and write

{A} α {B} : S

with the intention that

• every execution of the hybrid program α, if it starts from

a state satisfying the assertion A (the precondition),

• terminates in a state satisfying the assertion B (the

postcondition), and

• moreover, respects the assertion S (the safety condition)

at all times during the execution.

The addition of a safety condition S allows us to reason about
collision avoidance in RSS, while the goal of a scenario is
naturally modelled as a postcondition. Later in Section III,
driving scenarios and GA-RSS rules (cf. Section I-C) are
modelled as components of Hoare quadruples.

Assertions, hybrid programs, and Hoare quadruples form the

syntax of differential Floyd-Hoare logic (dFHL for short).

A, B ::= true | e ∼ f | A ∧ B | A ∨ B | ¬A | A ⇒ B

where e, f are terms and ∼ ∈ {=, ≤, <, (cid:54)=}.

A dFHL assertion can be open or closed (or both, or none).
Openness and closedness are deﬁned recursively: true is both
open and closed, e < f and e (cid:54)= f are open, e ≤ f and e = f
are closed, A ∧ B and A ∨ B are open (resp. closed) if both
components are, ¬A is open (resp. closed) if A is closed (resp.
open), and A ⇒ B is open (resp. closed) if A is closed and
B open (resp. A open and B closed). Note that open dFHL
assertions describe open subsets of RV .

Deﬁnition II.3. Hybrid programs (or dFHL programs) are
given by the syntax:

α, β

::= skip | α; β | x := e | if (A) α else β |
while (A) α | dwhile (A) { ˙x = f } .

We sometimes drop the braces in dwhile (A) { ˙x = f } for
readability. In dwhile (A) { ˙x = f }, x and f are lists of the
same length, respectively of (distinct) variables and terms, and
A is open.

All constructs are usual ones from imperative programming,
except for the differential while construct dwhile. It encodes the
˙x = f denotes a system of differential
differential dynamics:
equations, and dwhile (A) { ˙x = f } denotes a dynamical sys-
tem following the differential equations until the condition A is
falsiﬁed. Openness of A ensures that, if A is falsiﬁed at some
point, then there is the smallest time t0 when it is falsiﬁed,
and the system follows the dynamics for time t0.

Remark II.4. It is possible to extend the language of terms,
by allowing more functions than just polynomials. In that case,
the syntax ˙x = f is only allowed when f is locally Lipschitz
continuous to ensure existence and uniqueness of solutions,
by the Picard-Lindel¨of theorem. One should also make sure
that any term of the syntax possesses partial derivatives with
respect to all variables in order to use the rules of Section II-B.

Our programming language syntax (Deﬁnition II.3) is in-
spired by that in dL [18], but comes with signiﬁcant changes.
It is imperative and deterministic (see Lemma II.8), which
makes it easier to use for practitioners, while expressive enough
to encode interesting models. This also makes it more suited
to Hoare logic and total correctness, which is crucial for
applications to automated driving.

We deﬁne an operational semantics for our syntax:

Deﬁnition II.5 (semantics). A store is a function from vari-
ables to reals. Store update is denoted ρ[x → v]; it maps x
to v and any other variable x(cid:48) to ρ(x(cid:48)). The value
ρ of a
(cid:75)
term e in a store ρ is a real deﬁned as usual by induction on
e (see for example [31, Section 2.2]). The satisfaction relation

e

(cid:74)

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

7

(cid:104)skip; β, ρ(cid:105) → (cid:104)β, ρ(cid:105)

(cid:104)α, ρ(cid:105) → (cid:104)α(cid:48), ρ(cid:48)(cid:105)
(cid:104)α; β, ρ(cid:105) → (cid:104)α(cid:48); β, ρ(cid:48)(cid:105)

(cid:104)x := e, ρ(cid:105) → (cid:104)skip, ρ[x →

e
(cid:74)

ρ](cid:105)
(cid:75)

ρ (cid:15) A
(cid:104)if (A) α else β, ρ(cid:105) → (cid:104)α, ρ(cid:105)

ρ (cid:50) A
(cid:104)if (A) α else β, ρ(cid:105) → (cid:104)β, ρ(cid:105)

ρ (cid:50) A
(cid:104)while (A) α, ρ(cid:105) → (cid:104)skip, ρ(cid:105)

ρ (cid:15) A
(cid:104)while (A) α, ρ(cid:105) → (cid:104)α; while (A) α, ρ(cid:105)

t ≥ 0

ˆx(0) = ρ

ˆx(t)
(cid:75)
(cid:104)dwhile (A) { ˙x = f }, ρ(cid:105) → (cid:104)dwhile (A) { ˙x = f }, ρ(cid:48)(cid:105)

dˆx
dt (t) =

f
(cid:74)

ρ(cid:48) = ˆx(t) ∀t(cid:48) ≤ t. ˆx(t(cid:48)) (cid:15) A

(∗)

t ≥ 0

ˆx(0) = ρ

dˆx
dt (t) =
(cid:104)dwhile (A) { ˙x = f }, ρ(cid:105) → (cid:104)skip, ρ(cid:48)(cid:105)

ˆx(t)
(cid:75)

f
(cid:74)

ρ(cid:48) = ˆx(t) ∀t(cid:48) < t. ˆx(t(cid:48)) (cid:15) A ˆx(t) (cid:50) A

(∗)

Fig. 5: Reduction relation → on states; rules annotated with (∗) are discussed in Remark II.6

between stores ρ and dFHL assertions A, denoted ρ (cid:15) A, is
also deﬁned as usual (see [31, Section 2.3]).

A state is a pair (cid:104)α, ρ(cid:105) of a hybrid program and a store. The
reduction relation on states is deﬁned in Figure 5. A state s
reduces to s(cid:48) if s →∗ s(cid:48), where →∗ is the reﬂexive transitive
closure of →. A state s converges to ρ, denoted s ⇓ ρ, if there
exists a reduction sequence s →∗ (cid:104)skip, ρ(cid:105).

Let us explain how to read Figure 5: hypotheses are listed
above the horizontal line, and the conclusion below it. For
example, (cid:104)skip; β, ρ(cid:105) can always reduce to (cid:104)β, ρ(cid:105) (there are no
hypotheses), and if (cid:104)α, ρ(cid:105) reduces to (cid:104)α(cid:48), ρ(cid:48)(cid:105), then (cid:104)α; β, ρ(cid:105)
reduces to (cid:104)α(cid:48); β, ρ(cid:48)(cid:105).

Remark II.6. In the reduction rules for dwhile, ˆx is the global
solution to the differential equation ˙x = f with initial condition
ˆx(0) = ρ. As a side condition (left untold for readability in
the rule), we assume that all variables not mentioned in x are
left untouched during the transition, so if y is not in x, then
ρ(cid:48)(y) = ρ(y).

Convergence ⇓ corresponds to complete executions of pro-
grams (until termination), while reduction →∗ corresponds to
potentially partial executions, which can reach any intermediate
state of the computation.

Example II.7. The state (cid:104)α, ρ(cid:105), where

α = ( dwhile (x > 0) { ˙x = −1 } ;

x := x − 1) ,

and ρ(x) = 2, can reduce

• to (cid:104)α, ρ[x → v](cid:105) for any v ∈ (0, 2],
• to (cid:104)x := x − 1, ρ[x → 0](cid:105),
• and to (cid:104)skip, ρ[x → −1](cid:105),

but only the last one corresponds to convergence (namely
(cid:104)α, ρ(cid:105) ⇓ ρ[x → −1]).

Lemma II.8 (conﬂuence). Our language of hybrid programs
is conﬂuent. That is, if s →∗ s1 and s →∗ s2, then there exists
s(cid:48) such that s1 →∗ s(cid:48) and s2 →∗ s(cid:48). In particular, if s ⇓ ρ, s
cannot converge to any other store ρ(cid:48) (cid:54)= ρ.

Conﬂuence basically means that the language is determin-
istic in the sense that, no matter the reduction sequence,
a program always converges to the same value. This holds
because reduction in our language is mainly deterministic,

except for the dwhile rules, in which case the reduction that
has run for the smaller amount of time can be reduced again
to catch up with the other reduction.

Finally, we deﬁne validity of Hoare quadruples:

Deﬁnition II.9 (Hoare quadruples). A Hoare quadruple is a
quadruple {A} α {B} : S of three dFHL assertions A, B,
and S, and a hybrid program α. It is valid if, for all stores ρ
such that ρ (cid:15) A,

• there exists ρ(cid:48) such that (cid:104)α, ρ(cid:105) ⇓ ρ(cid:48) and ρ(cid:48) (cid:15) B, and
• for all reduction sequences (cid:104)α, ρ(cid:105) →∗ (cid:104)β, ρ(cid:48)(cid:105), ρ(cid:48) (cid:15) S.

Hoare quadruples have safety conditions S in addition to the
usual components of Hoare triples. They are required to specify
safety properties, which must hold at all times. In traditional
programming, one is usually only interested in input-output
behaviours: as long as a program returns a valid value, it
does not matter which intermediate states it went through.
In contrast, the intermediate states matter in our case, since
there may be a collision or safety violation halfway through
an execution that reaches the desired target.

The safety of all

intermediate states is ensured by the
deﬁnition of s → s(cid:48). The interesting case is that of the
differential dynamics, where the dynamics can be stopped at
any point in time, and thus s(cid:48) can be the state reached at any
point of the dynamics.

Also note that this semantics is total correctness, rather than
partial correctness. A Hoare triple {A} α {B} is valid for
partial correctness if, roughly, any terminating execution of
α under the precondition A satisﬁes the postcondition B. In
particular, if α is not terminating, then the Hoare triple is
trivially true, regardless of the truth of B. This is not desired
since we want to ensure goal achievement (modelled by the
postcondition B). In contrast, total correctness additionally
requires the existence of a terminating execution, which suits
our purpose. See [31] for more details on partial and total
correctness.

Example II.10 (the one-way trafﬁc scenario). The scenario for
Example I.3 can be modelled in dFHL. We start by modelling
the dynamics of the different agents involved in the scenario
(the front and rear cars) as a hybrid program α (see Figure 6).
We then model the property that we want to show (namely,
that the cars can stop without colliding if they are far enough

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

8

1

2

3

4

5

6

7

t := 0 ;

(cid:26)

dwhile (vf > 0 ∧ t < ρ)
(cid:20)
dwhile (t < ρ) δ1
r

if (vf = 0)

δf

,

δ1
r

(cid:27)

;

; dwhile (vr > 0) δ2
r

(cid:21)

else

dwhile (vf > 0 ∧ vr > 0)

(cid:26)

δf

,

δ2
r

(cid:27)

;

if (vf = 0) dwhile (vr > 0) δ2
r
else dwhile (vf > 0) δf

Fig. 6: Hybrid program α for the one-way trafﬁc scenario
(Example II.10)

apart) into a Hoare quadruple (see (4)). In what follows we
explain the modelling (α in Figure 6 and the Hoare quadruple
in (4)). We defer the proof of validity of (4) to Example II.15.
In this scenario, we aim to show that whatever the front car
is doing, the rear car can properly respond without colliding
with the front car, as long as it respects the RSS safety distance
(dRSS(vf , vr) in (2)).

The worst case is when the front car breaks at the maximal
braking rate bmax, while the rear car is accelerating with the
maximal acceleration rate amax during the reaction time ρ
before engaging the proper response α (namely decelerating
with the maximal comfortable braking rate bmin). If we denote
by yf and vf the position and velocity of the front car and by
yr and vr those of the rear car, then these behaviours of the
cars can be written as the hybrid programs

(cid:16)

(cid:16)

αf =

αr =

dwhile (vf > 0) δf

(cid:17)

,

t := 0; dwhile (t < ρ) δ1
r

; dwhile (vr > 0) δ2
r

where the δ’s represent the dynamics of each car:

δf = ( ˙yf = vf , ˙vf = −bmax) ,
r = (cid:0) ˙yr = vr, ˙vr = amax, ˙t = 1(cid:1) ,
δ1
δ2
r = ( ˙yr = vr, ˙vr = −bmin) .

(cid:17)

,

(3)

By manually combining the two hybrid programs αf , αr—
letting them run in parallel—we obtain the hybrid program α
in Figure 6.

This hybrid program α models the situation in which both
the front and rear cars are following their worst case behaviours
as long as they are not both stopped. The logical structure
of α enumerates all the different states the scenario can be
in: whether the front car has stopped braking or not, and
whether the rear car is still accelerating, has engaged the
proper response, or ﬁnished braking. For example, the dwhile
on Line 2 of α in Figure 6 corresponds to a state where the
front car is braking and the rear car is still accelerating, and
the if on Line 3 corresponds to the case where the front car has
stopped braking before the rear car starts engaging the proper
response.

We can then model the whole scenario as the following

Hoare quadruple.

(cid:26) vr ≥ 0 ∧ vf ≥ 0 ∧

(cid:27)

yf − yr > dRSS(vf , vr)

α {vr = 0 ∧ vf = 0}
: yr < yf .

(4)

The postcondition states that both cars have stopped, while
the precondition models the situations in which we want to
prove that there is no collision (namely, when the cars are
farther than an RSS safety distance apart). The safety condition
yr < yf models the fact that there is no collision along the
dynamics. We will prove that this dFHL quadruple is valid,
using derivation rules for dFHL, in Example II.15.

B. Derivation Rules in dFHL

We present a set of rules to derive valid Hoare quadruples,
listed in Figure 7. Like the rules in Figure 5, hypotheses are
listed above the horizontal line, and the conclusion below it.
For example, the (SEQ) rule can be read as: if {A} α {B} : S
and {B} β {C} : S are provable in dFHL,
then so is
{A} α; β {C} : S.

Assumption II.11. In the (WH) rule, (cid:38) ∈ {>, ≥} (meaning
that all the occurrences of (cid:38) should be replaced with the same
> or ≥) and x is a fresh variable. In the (DWH) rule, (∼, (cid:39)) ∈
{(=, =), (>, ≥), (≥, ≥)}, and the dynamics ˙x = f is assumed
to have a global solution.

Note that the existence of global solutions is not a constraint
in practice, since their non-existence would imply that some
physical quantity diverges to inﬁnity, which is impossible in a
physical system.

Some hypotheses of the (DWH) and (LIMP) rules are
dFHL assertions, by which we mean that these assertions
must be valid, that is, satisﬁed by all stores. For example, the
precondition A ⇒ evar ≥ 0 means that, for any ρ, if ρ (cid:15) A,
then

evar

ρ ≥ 0.

Most of the rules in Figure 7 are standard Hoare logic rules
when stripped of their safety conditions, so we only discuss
the exceptions: (WH), (DWH) and (DWH-SOL).

(cid:74)

(cid:75)

1) The (WH) Rule: The ﬁrst exception is the (WH) rule,
which is an alternative used for total correctness (similar
for example to the one found in [32]), while Hoare logic is
more often used for partial correctness. The parts that prove
total correctness are those that involve the variant evar, which
decreases with each iteration by at least 1, and must be positive
(or non-negative), so the loop must stop at some point. This
notion of variant is similar to those of ranking function [33]
and Lyapunov function [34].

2) The (DWH) Rule: The second exception is the (DWH)
rule, which uses the notion of Lie derivative. The term L ˙x=f e
is called the Lie derivative of e with respect to the dynamics
˙x = f . If x is the list of variables x1, . . . , xn, and f is the list
of terms f1, . . . , fn, its formal deﬁnition is

L ˙x=f e =

n
(cid:88)

i=1

∂e
∂xi

fi,

where the terms ∂e
are the partial derivatives of e whose
∂xi
deﬁnitions are by induction on the structure of the term e as
usual. The fundamental lemma of the Lie derivative (see [35]),
crucial for proving the soundness of the (DWH) rule is the
following:

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

9

{A} skip {A} : A

(SKIP)

{A} α {B} : S

{B} β {C} : S

{A} α; β {C} : S

(SEQ)

{A[e/x]} x := e {A} : A ∨ A[e/x]

(ASSIGN)

{A ∧ B} α {C} : S
{¬A ∧ B} β {C} : S

{B} if (A) α else β {C} : S

(IF)

{A ∧ B ∧ evar (cid:38) 0 ∧ evar = x} α {B ∧ evar (cid:38) 0 ∧ evar ≤ x − 1} : S
{B ∧ evar (cid:38) 0} while (A) α {¬A ∧ B ∧ evar (cid:38) 0} : S

(WH)†

inv : A ⇒ einv ∼ 0
var : A ⇒ evar ≥ 0
ter : A ⇒ eter < 0

evar ≥ 0 ∧ einv ∼ 0 ⇒ L ˙x=f einv (cid:39) 0
evar ≥ 0 ∧ einv ∼ 0 ⇒ L ˙x=f evar ≤ eter
evar ≥ 0 ∧ einv ∼ 0 ⇒ L ˙x=f eter ≤ 0

{A} dwhile (evar > 0) ˙x = f {evar = 0 ∧ einv ∼ 0} : einv ∼ 0 ∧ evar ≥ 0

(DWH)†

{A(cid:48)} α {B(cid:48)} : S(cid:48) S(cid:48) ∧ B(cid:48) ⇒ B

A ⇒ A(cid:48)

S(cid:48) ⇒ S

{A} α {B} : S

(LIMP)

{A} α {B} : S

{A} α {B(cid:48)} : S(cid:48)

{A} α {B ∧ B(cid:48)} : S ∧ S(cid:48)

(CONJ)

A0 ⇒ (∃t ≥ 0. C<t ∧ ¬Ct ∧ Bt ∧ S≤t)
{A} dwhile (C) ˙x = f {B} : S

(DWH-SOL)

Fig. 7: dFHL rules for total correctness; rules with † have side conditions discussed in Assumption II.11. Rule (DWH-SOL)
is discussed separately in Section II-B3.

Lemma II.12. Assume given any solution ˆx : R≥0 → Rn of
the differential equations ˙x = f . Then the derivative of the
function t (cid:55)→

ˆx(t).
ˆx(t) is given by t (cid:55)→
(cid:75)
Proof. This is just an application of the chain rule.

L ˙x=f e

e

(cid:75)

(cid:74)

(cid:74)

The (DWH) rule is similar to the (WH) rule, in that it
contains an invariant einv (B in (WH)), a variant evar, and a
terminator eter (decreasing by 1 in (WH)). The inv condition
states that the invariant holds at the start and is preserved by
the dynamics, so it must hold at all times along the dynamics.
The other conditions are only present to ensure that the
loop eventually terminates. The var condition essentially means
that the variant evar must decrease along the dynamics (if the
terminator eter is always negative). But this is not enough, as
the variant could get asymptotically closer to 0, without ever
reaching it. The condition ter ensures that this never happens,
by showing that the terminator eter is not only negative, but
below a ﬁxed negative value.

Note that, even though the (DWH) rule may look like it is
about a single variable, evar is typically a term that contains
several variables, which makes it expressive enough to prove
interesting properties of driving systems. For example, in (18)
in Section IV-D, evar depends on both y and v.

Remark II.13. We note that (WH) and (DWH) can be made
more general. For example, instead of the usual order on a
single term evar, (WH) could use a lexicographic order on
several terms, or any well-founded order. This is also true for
(DWH), where we could use more general forms than evar > 0
as the variant.

Indeed, in Section IV, we will use a “multiple-invariant
multiple-variant” generalization of (DWH); it is presented in
Figure 19 in Appendix A. In this section, we use the current
simpler forms of the rules that are easy to describe and
manipulate, and yet share their essence with the generalized
forms.

3) The (DWH-SOL) Rule: Finally,

let us discuss the
(DWH-SOL) rule in detail. It uses explicit solutions, which
makes it further from the spirit of Hoare logic, but it is still

f

(cid:74)

(cid:75)

valid. Let us assume that ˙x = f has a closed form solution, that
is, a function ˆx : Rn × R → Rn such that ˆx(x0, 0) = x0 and
dˆx
dt (x0, t) =
ˆx(x0,t). The only premise of (DWH-SOL) is the
dFHL assertion shown in Figure 7, where At is a shorthand
for the assertion A[ˆx(x0, t)/x] (and similarly for Bt and Ct),
while C<t is a shorthand for ∀s ∈ [0, t). C[ˆx(x0, s)/x] (and
similarly for S≤t). Intuitively, this rule means that for all states
x where the assertion A holds, there is some time t when the
condition C just becomes false, and it is enough to prove the
assertion B holds at time t, and that S holds for all times from
0 to t.

case

4) The

Construct:

by
case (A1) α1 . . . (An) αn the obvious nesting of if constructs,
then the following rule can be derived from repeated uses of
(IF) and (LIMP):

denote

we

If

{A1} α1 {B} : S
{(cid:87)n

{An} αn {B} : S
i=1 Ai} case (A1) α1 . . . (An) αn {B} : S

. . .

(CASE)

(5)

It is useful in our framework for automated driving: given
hybrid programs α1, . . . , αn that satisfy the same postcondition
B and safety condition S, but with different preconditions Ai,
case (A1) α1 . . . (An) αn also satisﬁes B and S, but on the
more general precondition A1 ∨ . . . ∨ An, as demonstrated in
Section IV-E.

5) Soundness: Soundness of dFHL can be proved:

Theorem II.14. Only valid Hoare quadruples can be proved
in dFHL.

Proof. The proof is done by induction on the size of the proof
tree and case analysis of the ﬁrst rule used. All cases are rather
standard except for the additional requirement of the safety
condition, so let us develop only the case when the last rule is
(DWH) in details.

Let us assume the premises of (DWH) are valid, and assume
given a store ρ such that ρ (cid:15) A. The goal is to prove that
(cid:104)dwhile (evar > 0) { ˙x = f }, ρ(cid:105) converges to a store ρ(cid:48) with
ρ(cid:48) (cid:15) evar = 0 ∧ einv ∼ 0, and for all reduction sequences
(cid:104)dwhile (evar > 0) { ˙x = f }, ρ(cid:105) →∗ (cid:104)α, ρ(cid:48)(cid:48)(cid:105), ρ(cid:48)(cid:48) (cid:15) einv ∼
0 ∧ evar ≥ 0. Let ˆx : R≥0 → Rn be the solution of ˙x = f

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

10

(cid:110)

with ˆx(0) = ρ, K =
(cid:12)
(cid:12)
(cid:12) ∀t(cid:48) ≤ t.

K (cid:48) =
evar
(cid:74)
be the supremum of K (cid:48).
Step 1: K = K (cid:48) and

t ≥ 0

(cid:75)

(cid:110)

t ≥ 0

(cid:12)
(cid:12)
(cid:12) ∀t(cid:48) ≤ t.
ˆx(t) > 0 ∧

(cid:74)
einv

evar

ˆx(t) > 0
(cid:111)

(cid:75)
ˆx(t) ∼ 0
(cid:75)

(cid:74)

(cid:111)

, and

. Let T

(cid:75)

einv

einv

einv
(cid:74)

ˆx(T ) ∼ 0. For the ﬁrst point,
(cid:75)
since K (cid:48) ⊆ K, it is sufﬁcient to show that einv ∼ 0 holds in
K. Let us assume that ∼ is = (other cases are similar). By inv
and Lemma II.12, the function t ∈ K (cid:55)→
ˆx(t) is 0 at t = 0
(cid:74)
and of constant derivative 0. This means its value at t ∈ K is
also 0, that is,
ˆx(t) = 0. For the second point, because
(cid:75)
(cid:74)
the function above is continuous and constantly equal to 0 on
einv
K, we also have
Step 2: K is bounded. By Step 1,

t ∈ K. By ter and Lemma II.12, the function t (cid:55)→
eter
is negative at t = 0 and of non-positive derivative,
non-increasing, on K. This means that
Similarly, by var and Lemma II.12,
function v : t (cid:55)→
evar
(cid:74)
monotonicity of integrals:

ˆx(t) ∼ 0 for all
ˆx(t)
(cid:75)
(cid:74)
i.e.,
ˆx(t) ≤
eter
ρ.
(cid:74)
(cid:75)
the derivative of the
eter
ˆx(t). By
ˆx(t) is bounded by

ˆx(T ) ∼ 0 (other cases are similar).

einv

eter

(cid:75)

(cid:75)

(cid:75)

(cid:74)

(cid:75)

(cid:74)

(cid:74)

(cid:75)

(cid:74)

v(t) − v(0) =

(cid:90)

[0,t]

˙v(t)dt ≤

(cid:90)

[0,t] (cid:74)

eter

ρ dt = t ·
(cid:75)

(cid:74)

eter

ρ ,
(cid:75)

with proofs in program logics, ﬁnding a suitable invariant is
difﬁcult. In our case, a suitable invariant turns out to be

yf − yr − dRSS(vf , vr, ρ − t) > 0,

(6)

where t is the current time (note that we make the ρ parameter
explicit throughout the proof, because it is important there).
Explicit use of the assertion (6) as an invariant is not common
in the literature—it is not used in [1] for example—showing
the subtlety of ﬁnding invariants.

Once a suitable invariant is found, constructing a dFHL
proof is relatively simple: for each program construct, we
apply the corresponding rule of dFHL. We present only part
of the validity proof here, focusing on Line 2 of the program
α (Figure 6). The rest of the proof is similar.

We let α(cid:48) denote Line 2, that is,

(cid:16)

α(cid:48) =

dwhile (vf > 0 ∧ vr > 0 ∧ t < ρ)

(cid:110)

δf

,

δ1
r

(cid:111)(cid:17)

.

Here we used snippets δf , δ1

r from (3).
Then we want to prove that the following Hoare quadruple

is valid:

{A(cid:48)} α(cid:48) {B(cid:48)} : yf − yr − dRSS(vf , vr, ρ − t) > 0,

(7)

ρ

evar
so for t > − (cid:74)
eter
(cid:74)
bounded by − (cid:74)
(cid:74)

(cid:75)
ρ
(cid:75)
evar
eter

.

ρ
(cid:75)
ρ
(cid:75)

≥ 0,

evar

(cid:74)

(cid:75)

ˆx(t) < 0, so t /∈ K, hence K is

where

(cid:74)

evar

Step 3: analysis of the exit time. By deﬁnition of K (cid:48), the
loop ends at time T (since T is ﬁnite by Step 2). By Step 1, T
is also the supremum of K. Furthermore, by openness of the
condition evar > 0 and the continuity of the solution ˆx, if T
belonged to K, then there would exist (cid:15) > 0, such that for all
t(cid:48) ≤ T + (cid:15), t(cid:48) ∈ K, which would contradict the supremality of
ˆx(T ) ≤ 0. Again by continuity of the
T . This means that
ˆx(T ) is in the closure of K, which is included
evar
solution,
(cid:74)
in R≥0. Consequently,

ˆx(T ) = 0.
Step 4: convergence. The previous analysis implies that
(cid:104)dwhile (evar > 0) { ˙x = f }, ρ(cid:105) converges to ρ(cid:48) = ˆx(T ), for
which ρ(cid:48) (cid:15) evar = 0 (by Step 3) and ρ(cid:48) (cid:15) einv ∼ 0 (by Step 1).
Step 5: safety. By uniqueness of the solutions of ˙x = f , we
can prove by induction on the number of reduction steps that
if (cid:104)dwhile (evar > 0) { ˙x = f }, ρ(cid:105) →∗ (cid:104)α, ρ(cid:48)(cid:48)(cid:105), then ρ(cid:48)(cid:48) = ˆx(t)
for some 0 ≤ t ≤ T . By Step 3, ρ(cid:48)(cid:48) (cid:15) evar ≥ 0, and by Step 1,
ρ(cid:48)(cid:48) (cid:15) einv ∼ 0.

(cid:75)
evar

(cid:75)

(cid:74)

(cid:75)

6) Example: We exemplify formal reasoning in dFHL using
the one-way trafﬁc scenario (Examples I.3 and II.10). We only
show a typical part of the proof here, and refer the interested
reader to Appendix A for the complete formal proof.

Example II.15 (proving safety of the one-way trafﬁc scenario).
We show how to prove the validity of the Hoare quadru-
ple (4)—which we shall write as {A} α {B} : yr < yf —for
the one-way trafﬁc scenario in Example II.10.

Here we use a slightly extended version of the (DWH) rule,
namely one that combines several variants and invariants. See
Remark II.13. The exact form of the rule is given in Figure 19
in Appendix A.

The proof then relies on ﬁnding an invariant that implies
yr < yf and that is preserved by the dynamics α. As always

A(cid:48) =

B(cid:48) =

(cid:18) vr ≥ 0 ∧ vf ≥ 0 ∧ t = 0 ∧
yf − yr > dRSS(vf , vr, ρ)

(cid:19)

,

(cid:18) ((vf ≥ 0 ∧ t = ρ) ∨ (vf = 0 ∧ t ≤ ρ)) ∧
vr ≥ 0 ∧ yf − yr > dRSS(vf , vr, ρ − t)

(cid:19)

.

This quadruple can be directly proved by applying the (DWH)
rule (and the (LIMP) rule) with the following variants and
invariants:

• einv,1 = (vr ≥ 0),
• einv,2 = (yf − yr − dRSS(vf , vr, ρ − t) > 0),
• evar,1 = vf ,
• evar,2 = ρ − t,

eter,1 = −bmax,
eter,2 = −1.
The only non-obvious point is that einv,2 is preserved by the
dynamics. We ﬁrst observe

Lδf ,δ1

r

einv,2 =

(cid:26) 0

vf − vr

if dRSS±(vf , vr, ρ − t) ≥ 0
otherwise,

where dRSS±(vf , vr, ρ) is given by

dRSS±(vf , vr, ρ) = vrρ+

amaxρ2
2

+

(vr + amaxρ)2
2bmin

−

v2
f
2bmax

.

Therefore, we can infer as follows.

dRSS±(vf , vr, ρ − t) < 0

⇐⇒ vr(ρ − t) +

amax(ρ − t)2
2

+

(vr + amax(ρ − t))2
2bmin

−

=⇒

(vr + amax(ρ − t))2
2bmin
=⇒ (vr + amax(ρ − t))2 < v2
f
r < v2
=⇒ v2
f
=⇒ vr < vf

< 0

−

v2
f
2bmax
v2
f
2bmax

< 0

(i)

(ii)

(iii)

(iv)

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

11

Here (i) and (iii) are because vr ≥ 0, t ≤ ρ (by einv,1 and
evar,2), and amax ≥ 0; (ii) because 0 ≤ bmin ≤ bmax; and (iv)
because vr ≥ 0 and vf ≥ 0 (the latter by evar,1).

The argument above concludes that einv,2 is indeed an invari-
ant, which establishes the validity of the Hoare quadruple (7)
on Line 2 of α. Combining similar arguments, we prove
the validity of the Hoare quadruple {A} α {B} : yr < yf
(from (4)) for the one-way trafﬁc scenario. The rest of the
proof can be found in Appendix A.

In the last example, in order to deﬁne dRSS (2) in dFHL,
we needed to add the max operator to the syntax for terms.
This is straightforward.

III. PROBLEM FORMULATION
A. Modelling of Physical Components: Roads, Lanes, Occu-
pancy, and Vehicle Dynamics

We use the double integrator model as done in the original
RSS work [1]. Occupancy is lane-based. In changing lanes,
a vehicle occupies two lanes—this modelling is reasonable in
less-congested highway situations. This way we do not need
to consider lateral positions of vehicles within a lane; this
modelling is even simpler than the lane-based one in [6].

to express

Concretely, we use integers

(l =
1, 2, 3, . . . ). A vehicle changing lanes from Lane 1 to 2 is
expressed by l = 1.5; it means that 1) the vehicle occupies both
Lanes 1 & 2, as discussed above, and 2) the vehicle is hence
subject to the RSS distance responsibilities (Example I.3) with
respect to preceding vehicles both in Lanes 1 & 2.

lanes

Our scope here is driving situations that are highly structured
and thus allow abstract modelling in terms of lane occupancy.
This is the case typically with highway trafﬁc situations.
Many other works, such as [36], study less structured driving
situations; their scope is therefore different from ours.

B. Scenario Modelling

What constitutes a mathematical notion of “driving scenario”
is a difﬁcult question—its answer can change depending on the
intended model granularity and the goal of modelling. For our
purpose of compositional derivation of goal-aware RSS rules
in dFHL, we propose the following deﬁnition.

Deﬁnition III.1 ((driving) scenario). A (driving) scenario is a
quadruple S = (Var, Safe, Env, Goal), where

• Var is a ﬁnite set of variables;
• Safe is a dFHL assertion called a safety condition;
• Env is a dFHL assertion called a environmental condition;

and

• Goal is a dFHL assertion called a goal.

It is required that all the variables occurring in Safe, Env, and
Goal belong to Var.

The set Var should cover all the variables that are used
for rule derivation; it is a modelling of the physical compo-
nents involved in the driving scenario in question. We follow
Section III-A in deciding Var.

The three assertions Safe, Env, Goal describe different as-
pects of a driving scenario, and are thus used differently in
our rule derivation workﬂow (Section IV).

• Safe describes safety conditions for collision avoidance.

SV should satisfy them all the time while it drives.
Typically Safe requires the RSS safety distance (Exam-
ple I.3) between SV and some of POVs. To be precise,
the latter POVs are those which are ahead of SV in the
same lane. (According to the RSS principles, the distance
between SV and a POV behind it is SV’s concern only if
SV is cutting in—see Goal(1) in (11), Section IV-B.)
• Env describes additional environmental conditions in
driving—these conditions must be satisﬁed all the time
during driving, too, but ensuring them is not SV’s re-
sponsibility but the environment’s.
Environmental conditions typically include 1) assump-
tions on POVs’ dynamics (e.g. they maintain their speed),
and 2) other assumptions imposed in the scenario, such
as “POV1 is behind SV” (T111 in Example IV.5). See
Example III.2.

• Goal describes the goal condition of a driving scenario. It

must be true at the end of driving.
Devising proper responses that achieve Goal—and prov-
ing that they do so safely—is a major feature of our
framework that the original (goal-unaware) RSS [1] lacks.

Example III.2. For the pull over scenario (Example I.5), a
scenario S = (Var, Safe, Env, Goal) is deﬁned as follows.

The set Var of variables for the pull over scenario, following

Section III-A, are

• l, l1, l2, l3 for the lanes of SV and the three POVs;
• y, y1, y2, y3 for their (longitudinal) positions;
• v, v1, v2, v3 for their (longitudinal) velocities; and
• a, a1, a2, a3 for their (longitudinal) acceleration rates.
The safety condition Safe is
Safe = (cid:86)

(cid:0) aheadSLi =⇒ yi − y > dRSS(vi, v) (cid:1),

i=1,2,3

∧ 0 ≤ v ≤ vmax ∧ −bmin ≤ a ≤ amax .

(8)
• The ﬁrst conjunct requires that SV maintain the RSS
safety distance dRSS (Example I.3) from the preceding
vehicle. We used the following abbreviation (“ahead in
the same lane”).

aheadSLi = yi > y ∧ |li − l| ≤ 0.5.

(9)

Recall, e.g., that l = 1.5 means SV’s occupancy of both
Lanes 1 and 2 (Section III-A).

• The second conjunct imposes the legal maximum velocity
on SV. In this paper, for simplicity, we do not impose the
legal minimum speed on SV (vmin ≤ v) because of its
emergency. In practice, this can be justiﬁed by turning on
SV’s hazard lights.

• The third conjunct bounds SV’s acceleration, where we
require that it brakes comfortably (within bmin) and does
not engage emergency braking (not within bmax), much
like in Example I.3.

The environmental condition Env is as follows.

Env = (cid:86)

i=1,2,3

(cid:0) vmin ≤ vi ≤ vmax ∧ ai = 0 (cid:1)
∧ l1 = 2 ∧ l2 = 2 ∧ l3 = 1 ∧ y2 > y1.

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

12

We assume that POVs do not change their speed (ai = 0)—
an assumption we adopt in this paper to simplify arguments.
Violation of this assumption can affect goal achievement (i.e.
reaching ytgt in Lane 3), but it does not endanger collision
avoidance. See Section IV-G3.

Each step of the workﬂow is described in detail below.
We use the pull over scenario (Example I.5) as a leading
example in its course. Another example scenario, which is
more complex, is discussed later in Section IV-F.

The goal Goal is to stop at the intended position, that is,

A. Scenario Modelling (Line 1)

Goal = l = 3 ∧ y = ytgt ∧ v = 0.

Remark III.3 (distinguishing Safe and Env). It turns out that
the mathematical positions of Safe and Env are the same in
our workﬂow in Section IV. Therefore there is no theoretical
need of separating them.

We nevertheless distinguish them for their conceptual differ-
ence: Safe is an invariant that SV must maintain, while Env is
an invariant that SV can assume. Separating Safe and Env also
helps modelling the scenario, because treating them separately
restricts the modeller’s focus to speciﬁc agents.

C. Our Problem: Goal-Aware RSS Rules as dFHL Quadruples

Using Deﬁnition III.1, we can formalise what we are after:

III.4

Deﬁnition
Let
(goal-aware
S = (Var, Safe, Env, Goal) be a driving scenario. A
goal-aware RSS rule (or GA-RSS rule) is a pair (A, α) of
• a dFHL assertion A (called an RSS condition), and
• a dFHL program α (called a proper response),

rule).

RSS

such that the quadruple

{A} α {Goal} : Safe ∧ Env

(10)

is valid.

Note that an RSS condition A is in the position of a

precondition in the quadruple (10).

Remark III.5. As a convention, in Deﬁnition III.4, the dFHL
program α controls only SV. The actual dynamics of the whole
driving situation includes parts that model POVs’ dynamics
too—they are described by ˙yi = vi, ˙vi = ai, where ai is
typically constrained in Env.

We use this convention throughout the paper, describing only
the control of SV and leaving POVs’ dynamics implicit in
dFHL programs. We do so e.g. in Example IV.6.

IV. COMPOSITIONAL DERIVATION OF GOAL-AWARE RSS
RULES: A GENERAL WORKFLOW

In this section, we present a general workﬂow that com-
positionally derives a goal-aware RSS rule (A, α). In the
the original scenario S is split up into a tree
workﬂow,
T of subscenarios—such as one shown in Figure 8. Each
subscenario is simpliﬁed and has a more speciﬁc scope,
which allows one to come up with proper responses and their
preconditions more easily. These subscenario proper responses
and preconditions get bundled up, using dFHL rules such as
(SEQ) and (CASE), to ﬁnally yield a goal-aware RSS rule for
the original scenario.

The outline of our rule derivation workﬂow is Procedure 1.

Some steps of the workﬂow are illustrated in Figures 8–11.

We assume that the input driving scenario is given only
in informal terms. In this step, we identify its mathematical
modelling (Var, Safe, Env, Goal) in the sense of Section III-B.
See Example III.2 for a concrete example for the pull over
scenario.

B. Subscenario Identiﬁcation (Lines 2–3)

In the two steps on Lines 2–3, we decompose the
to ﬁnd A and α such that
original problem (namely,
{A} α {Goal} : Safe ∧ Env) into problems about smaller
subscenarios. We aim to identify subscenarios such that 1)
they make local objectives and case distinctions explicit, 2)
each subscenario is simpler and more homogeneous, and 3)
the safety and environmental conditions for each subscenario
are more concrete and speciﬁc. These features will make it
easier to devise proper responses and preconditions for those
subscenarios.

The following formal deﬁnition will be justiﬁed in the
course of the explanation below, notably in the proof of
Theorem IV.11.

IV.1

(subscenario,

subgoal). Let S

=
Deﬁnition
(Var, Safe, Env, Goal) and S (cid:48) = (Var, Safe(cid:48), Env(cid:48), Goal(cid:48))
be scenarios with the same variable set. We say that S (cid:48)
is a subscenario of S if both of the logical
implications
Safe(cid:48) ∧ Env(cid:48) ⇒ Safe and Safe(cid:48) ∧ Env(cid:48) ⇒ Env are valid. In this
case, Goal(cid:48) is called a subgoal.

We separate the task of subscenario identiﬁcation into goal
decomposition (Line 2) and subscenario reﬁnement (Line 3).
The separation is not a necessity from the theoretical point of
view. We nevertheless explicate the separation for conceptual
and practical reasons: in our experience, the two-step workﬂow
(Lines 2–3) is the way we came up with useful subscenarios.
1) Goal Decomposition (Line 2): On Line 2, we aim at a
series Goal(1), . . . , Goal(N ) of subgoals that naturally paves the
way to the original goal Goal. More speciﬁcally, we expect
the subgoals to be such that their achievement in the given
order leads to the achievement of Goal. On Line 2, note that
the resulting subscenarios S (i) = (Var, Safe, Env, Goal(i)) all
have the same safety and environmental conditions Safe, Env
as the original scenario S. Strengthening those conditions is
left to the next step (Line 3).

Note that, in fact, any sequence Goal(1), . . . , Goal(N ) of
dFHL assertions qualiﬁes as the outcome of Line 2—
Deﬁnition IV.1 does not constrain Goal(cid:48). However, a good
choice of subgoals Goal(1), . . . , Goal(N ) eases the rest of the
workﬂow by making local objectives explicit. It is usually
easy to come up with a natural series of subgoals, too, as
we demonstrate now.

Example IV.2. For the pull over scenario (Examples III.2
and I.5), we use the goal decomposition that we informally

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

13

Fig. 8: The subscenario tree T in Example IV.5, obtained on Line 3 of Procedure 1, for the pull over scenario S (Example III.2).
The subscenarios T1, T11, . . . are deﬁned in Figure 12

Fig. 9: The subscenario tree T in Example IV.5, highlighting (informally) the goal Goalw, the safety condition Safew, and the
environmental condition Envw of each subscenario Tw. The full formal deﬁnition is in Figure 12

scenario 𝒮subscenario 𝒮!subscenario 𝒯"subscenario 𝒮"subscenario 𝒯""(merge before POV1) subscenario 𝒯"#(merge after POV1) subscenario 𝒮#subscenario 𝒯"""(merge before POV1) subscenario 𝒯"#"(merge after POV1) subscenario 𝒮%subscenario 𝒯""""(merge before POV1) subscenario 𝒯"#""(merge after POV1) yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV2POV3yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2scenario 𝒮subscenario 𝒮!subscenario 𝒯"subscenario 𝒮"subscenario 𝒯""(merge before POV1) subscenario 𝒯"#(merge after POV1) subscenario 𝒮#subscenario 𝒯"""(merge before POV1) subscenario 𝒯"#"(merge after POV1) subscenario 𝒮%subscenario 𝒯""""(merge before POV1) subscenario 𝒯"#""(merge after POV1) yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV2POV3yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2Safe1111:•keep away from POV3Goal1111:•make distance from POV1 & 2 •match speed with POV2Safe111:•keep away from POV2 & 3Env111:•SVisbetweenPOV2 & 1Safe11:•keep away from POV2Env11:•SVisbetweenPOV2 & 1Goal111:•change to Lane 2Goal11:•change to Lane 3Goal1:•stop at 𝑦tgtSafe12:•keep away from POV1Env12:•SVisafter POV1Goal12:•change to Lane 3Safe121:•keep away from POV1 & 3Env121:•SVisafter POV1Goal121:•change to Lane 2Safe1211:•keep away from POV3Goal1211:•make distance from POV1•reduce speed to 𝑣minACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

14

Fig. 10: The subscenario proper responses α1,1, α11,1, . . . in Example IV.6, obtained on Line 5 of Procedure 1, for the pull
over scenario S (Example III.2).

Fig. 11: The subscenario preconditions A1,1, A11,11, . . . in Example IV.9, obtained on Line 7 of Procedure 1, for the pull over
scenario S (Example III.2). Here the solid arrows represent Hoare quadruples (with a program in the middle and a safety
condition below); note that they realise the condition (15). The double arrows =⇒ represent logical implication.

scenario 𝒮subscenario 𝒮!subscenario 𝒯1subscenario 𝒮"subscenario 𝒯""(merge before POV1) subscenario 𝒯"#(merge after POV1) subscenario 𝒮#subscenario 𝒯"""(merge before POV1) subscenario 𝒯"#"(merge after POV1) subscenario 𝒮1subscenario 𝒯""""(merge before POV1) subscenario 𝒯"#""(merge after POV1) yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV2POV3yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2subscen.proper response𝛼","subscen.proper response𝛼"","subscen.proper response𝛼"#,"subscen.proper response𝛼""","subscen.proper response𝛼"#","𝛼!!!!,#𝛼!!!!,$𝛼!!!!,%SS proper response𝛼"""","𝛼!%!!,#𝛼!%!!,$𝛼!%!!,%SS proper response𝛼"#"","yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2scenario 𝒮subscenario 𝒮!subscenario 𝒯"subscenario 𝒮"subscenario 𝒯""(merge before POV1) subscenario 𝒯"#(merge after POV1) subscenario 𝒮#subscenario 𝒯"""(merge before POV1) subscenario 𝒯"#"(merge after POV1) subscenario 𝒮%subscenario 𝒯""""(merge before POV1) subscenario 𝒯"#""(merge after POV1) yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV2POV3yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yytgtLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2yLane 1Lane 2Lane 3(shoulder)SOSSVPOV1POV3POV2subscen.proper response𝛼","subscen.proper response𝛼"","subscen.proper response𝛼"#,"subscen.proper response𝛼""","subscen.proper response𝛼"#","𝛼!!!!,#𝛼!!!!,$𝛼!!!!,%SS proper response𝛼"""","𝛼!%!!,#𝛼!%!!,$𝛼!%!!,%SS proper response𝛼"#"","Goal1: Safe1∧Env1Goal11∧𝐴!,!: Safe11∧Env11⟹𝐴!,!: Safe12∧Env12Goal12∧𝐴!,!⟹Goal111∧𝐴!!,!!⟹𝐴!!,!!Goal121∧𝐴!#,!!⟹𝐴!#,!!Goal1111∧𝐴!!!,!!!⟹𝐴!!!,!!!Goal1211∧𝐴!#!,!!!⟹𝐴!#!,!!!𝐴!!!!,!!!!𝐴!!!!,!!!#𝐴!!!!,!!!$𝐴!!!!,!!!%𝐴!#!!,!!!!𝐴!#!!,!!!#𝐴!#!!,!!!$𝐴!#!!,!!!%: Safe111∧Env111: Safe121∧Env121: Safe1111∧Env1111: Safe1211∧Env1211ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

15

Procedure 1: our workﬂow for compositional derivation of goal-aware RSS rules
Input: a driving scenario
Output: a goal-aware RSS rule (A, α) (Deﬁnition III.4)

1 Scenario modelling: mathematically model the driving scenario, obtaining S = (Var, Safe, Env, Goal)

(cf. Section III-B);

2 Goal decomposition: identify subgoals Goal(1), . . . , Goal(N ) and decompose the scenario S into subscenarios

S (1), . . . , S (N ) where S (i) = (Var, Safe, Env, Goal(i));

3 Subscenario reﬁnement: reﬁne subscenarios, distinguishing cases and strengthening safety and environmental

conditions. Then express their causal relationships and obtain a subscenario tree T ;

4 foreach subscenario Tw = (Var, Safew, Envw, Goalw) in T do
5

Identify subscenario proper responses: ﬁnd programs αw,1, . . . , αw,Kw that achieve Goalw and maintain
Safew ∧ Envw during their execution. (The programs αw,i may include syntactic parameters F, G, . . . ; they are
instantiated by concrete expressions on Line 7);

6 end
7 Identify subscenario preconditions: ﬁnd dFHL assertions (Aw,u)w,u for each subscenario proper response αw,i,
reasoning backwards from shorter w to longer, so that they guarantee subgoal achievement as well as the next
preconditions (formalised in (15));

8 Compute global proper response and precondition: combine the subscenario proper responses αw,i and the subscenario

preconditions Aw,u obtained so far, to obtain A and α such that {A} α {Goal} : Safe ∧ Env is valid;

9 return (A, α)

described in Section I (Subscenario 1–4). These subscenarios
arise from 1) coming to a halt (Subscenario 4), 2) changing
lanes (Subscenarios 2–3), and 3) preparing for lane changes, in
case there are vehicles in the destination lane (Subscenario 1).
The corresponding subgoals are formalised as follows.

Goal(1) =

(cid:32) y2 − y ≥ dRSS(v2, v)

(cid:33)

∧ y − y1 ≥ dRSS(v, v1)
∧ v2 = v

∨

Goal(2) = (l = 2)
Goal(3) = (l = 3)
Goal(4) = (l = 3 ∧ y = ytgt ∧ v = 0)

(cid:16) y1 − y ≥ dRSS(v1, v)

(cid:17)

∧ vmin = v

(11)

is typical in our workﬂow: there are different possible inter-
vehicle relationships; distinguishing cases with respect to them
makes each case simpler and more focused.

On Line 3, we make such case distinction explicit as
different subscenarios. Relating the resulting subscenarios by
their causal relationship, we obtain a tree of subscenarios.
See Figure 8 for an example.
Notation IV.3. We use words w ∈ (Z>0)∗ to designate nodes
of a tree T , as is common in the literature. Speciﬁcally, 1) the
root of T is denoted by ε (where ε stands for the empty word),
and 2) the k-th child of a node w is denoted by wk.

We deﬁne S (i) = (Var, Safe, Env, Goal(i)) (for i = 1, . . . , 4),
where Var, Safe, Env are the ones in Example III.2. These
subscenarios S (i) appear at the top of Figure 8.

The two disjuncts in Goal(1) represent 1) the case of SV
merging between POV2 and POV1, and 2) that of merging
behind POV1, respectively. (For simplicity, we ignore the
case of merging in front of POV2.) In the former case,
keeping enough distance from POV1 is deemed to be the
responsibility of SV—although POV1 is behind SV, it is SV’s
lane-changing manoeuvre that creates the duty of distance
keeping. One can also see this responsibility as an instance of
the RSS responsibility principle 2) “Don’t cut in recklessly”—
see Section I-A.

In the ﬁrst disjunct of Goal(1), we additionally require that
SV’s velocity matches that of the preceding vehicle. We do
so because 1) it is a natural driving practice, and 2) it eases
the safety analysis of the later subscenarios (see the case for
T11 in Example IV.9, for example). For the second disjunct,
for similar reasons, we require that SV’s velocity is the legal
minimum.

IV.4

=
Deﬁnition
(Var, Safe, Env, Goal) be a scenario. A subscenario tree
T for S is a ﬁnite tree

(subscenario

tree). Let

S

• whose root is not labelled (we write • for the root label),
• whose non-root node w is labelled by a subscenario Tw

of S (cf. Deﬁnition IV.1), and

• additionally, for every node of depth 1 (i.e. Tw with
|w| = 1),
the corresponding subscenario Tw =
(Var, Safew, Envw, Goalw) satisﬁes Safew ∧ Envw ∧
Goalw ⇒ Goal, where Goal is the goal of S.

Hence Tε = • for the root, and Tw is a subscenario for w (cid:54)= ε.

In the third item above, a subscenario Tw with |w| = 1 is
one of those which are executed at the end (see T1 in Figure 8
for an example). The item is a natural requirement that its
goal Goalw implies the goal Goal of the whole scenario S,
potentially with the help of Safew and Goalw.

A subscenario tree T arises naturally from the outcome
of Line 2 (namely S (1), . . . , S (N )) by distinguishing cases,
as demonstrated below. Note that case distinction also helps
concretising safety conditions.

2) Subscenario Reﬁnement (Line 3): The case distinction
in Goal(1) of Example IV.2 (to merge before or after POV1)

Example IV.5. Continuing Example IV.2, we obtain the sub-
scenario tree T shown in Figure 8 as a possible outcome

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

16

of Line 3. We do so by distinguishing cases of SV merging
before or after POV1. The subscenarios Tw in T are deﬁned
in Figure 12, where Tw = (Var, Safew, Envw, Goalw). We use
the following abbreviation; it is much like aheadSLi in (9).

behindSLi = yi < y ∧ |li − l| ≤ 0.5.

The design of the subscenarios Tw is described below. Some

key conditions therein are highlighted in Figure 9.

The subscenario T1 This comes from S (4) in Example IV.2.
The condition l = 3 in the original goal Goal(4) is moved to the
safety condition Safe1 since it has to be maintained throughout
rather than achieved at the end. Requiring l = 3 in S (4)
automatically discharges the RSS safety distance requirement
in the overall safety condition Safe (see (8)) since aheadSLi
is false. As a result, the subscenario safety condition Safe1 is
much simpliﬁed.

The subscenario T11 This comes from S (3)

in Exam-
ple IV.2, and assumes that SV has merged between POV1
and POV2. The last assumption is found in the environmental
condition Env11. Consequently, the RSS distance requirement
is simpliﬁed: in Safe11, only the one for POV2 is required.

Note that we also assume 0 ≤ v ≤ v2 as part of the
safety condition. This assumption may not be necessary but
simpliﬁes the subsequent reasoning a lot, especially when it
comes to proving maintenance of the RSS safety distance.
This assumption can be enforced, too, by requiring velocity
matching in our subgoals (v2 = v and vmin = v in Goal(1)
in (11), and thus in Goal1111, Goal1211 in Figure 12).

The subscenarios T12, T111, T121 Similarly to T11, we 1)
explicate case distinction in the environmental conditions
Envw, and 2) simplify the safety conditions Safew, adding
some extra assumptions (such as v ≤ v2) if we ﬁnd them
useful.

The subscenarios T1111, T1211 These come from the two
disjuncts of Goal(1) (see (11)): their goals are precisely those
disjuncts; and the safety conditions Safe1111, Safe1211 are the
original safety condition Safe simpliﬁed using l = 1.

Each Tw is indeed a subscenario. It is not hard to show
that each Tw is indeed a subscenario of S from Example III.2,
in the sense of Deﬁnition IV.1, as required in Deﬁnition IV.4.

• For T1, we have to show that Safe1 ∧ Env1 ⇒ Safe holds.
Since l = 3 is in Safe1 and l1 = 2, l2 = 2, l3 = 1 are in
Env1, we see that aheadSLi is false for each i = 1, 2, 3;
this makes Safe in (8) trivially true.

• For T11, Safe11 ∧ Env11 ⇒ Safe can be shown as follows.
Note ﬁrst that 0 ≤ v ≤ vmax is inferred from 0 ≤ v ≤ v2
(in Safe11) and v2 ≤ vmax (in Env11).
If l = 3 then Safe is trivially true, much like in the
above. Otherwise l = 2.5 holds, which forces behindSL1
to hold (by Env11). Therefore aheadSL1 is false (it
contradicts with behindSL1), and Safe is equivalent to
y2 − y > dRSS(v2, v). The last is required in Safe11.
• Proofs for T12, T111, T121 are similar to the one for T11.
Deﬁnition IV.4 additionally requires Safe1 ∧Env1 ∧Goal1 ⇒

Goal, whose validity is obvious.

T1 : Safe1 = l = 3 ∧ 0 ≤ v ≤ vmax ∧ −bmin ≤ a ≤ amax

Env1 = Env
Goal1 = y = ytgt ∧ v = 0

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

T11 : Safe11 = (l = 2.5 ∨ l = 3) ∧ 0 ≤ v ≤ v2 ∧ y2 − y ≥ dRSS(v2, v)

∧ − bmin ≤ a ≤ amax

Env11 = Env ∧ (l = 2.5 ⇒ behindSL1 ∧ aheadSL2)
Goal11 = l = 3

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

T12 : Safe12 = (l = 2.5 ∨ l = 3) ∧ 0 ≤ v ≤ v1 ∧ y1 − y ≥ dRSS(v1, v)

∧ −bmin ≤ a ≤ amax

Env12 = Env ∧ (l = 2.5 ⇒ aheadSL1)
Goal12 = l = 3

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
T111 : Safe111 = (l = 1.5 ∨ l = 2) ∧ 0 ≤ v ≤ v2

∧ y2 − y ≥ dRSS(v2, v) ∧ y3 − y ≥ dRSS(v3, v)
∧ −bmin ≤ a ≤ amax

Env111 = Env ∧ behindSL1 ∧ aheadSL2
Goal111 = l = 2

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
T121 : Safe121 = (l = 1.5 ∨ l = 2) ∧ 0 ≤ v ≤ v1

∧ y1 − y ≥ dRSS(v1, v) ∧ y3 − y ≥ dRSS(v3, v)
∧ −bmin ≤ a ≤ amax

Env121 = Env ∧ aheadSL1
Goal121 = l = 2

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
T1111 : Safe1111 = l = 1 ∧ y3 − y ≥ dRSS(v3, v)

∧ 0 ≤ v ≤ vmax ∧ −bmin ≤ a ≤ amax

Env1111 = Env
Goal1111 = y2 − y ≥ dRSS(v2, v) ∧ y − y1 ≥ dRSS(v, v1)

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
T1211 : Safe1211 = l = 1 ∧ y3 − y ≥ dRSS(v3, v)

∧ v2 = v

∧ 0 ≤ v ≤ vmax ∧ −bmin ≤ a ≤ amax

Env1211 = Env
Goal1211 = y1 − y ≥ dRSS(v1, v) ∧ vmin = v

Fig. 12: The subscenarios Tw in Fig. 9 for the pull over
scenario. See Example IV.5

C. Identifying Subscenario Proper Responses (Line 5)

5,

for

On

Line

subscenario

each
in the

=
(Var, Safew, Envw, Goalw)
subscenario tree T ,
we ﬁnd dFHL programs αw,1, . . . , αw,Kw such that each αw,i
achieves the goal Goalw maintaining Safew ∧ Envw under a
certain precondition. These programs αw,1, . . . , αw,Kw are
proper responses for the subscenario Tw.

Tw

it

There can be a number of such proper responses: collecting
more of them and thus being more comprehensive is desired
here, but
is not mandatory. As we will shortly see in
Section IV-E, missing some proper responses may lead to a
stronger precondition (i.e. a stronger RSS condition, Deﬁni-
tion III.4) than necessary, but the resulting precondition may
still be weak enough to be useful.

The above requirement on proper responses αw,i—that they
“achieve Goalw maintaining Safew ∧ Envw”—is made precise
as follows.

Under some precondition Aw,i, the Hoare quadru-
ple {Aw,i} αw,i {Goalw} : Safew ∧ Envw should
be valid. Moreover, it is desired that Aw,i is weak.

(12)

Note that this is not a mathematical condition—while weak
Aw,i is desired, nothing prevents to have false as Aw,i, in
which case any program qualiﬁes as a proper response αw,i.
However, ﬁnding “better” αw,i
leads to weaker (and more
widely applicable) RSS conditions. See Section IV-E.

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

17

We allow the proper responses αw,1, . . . , αw,Kw to have
syntactic parameters F, G, . . . ; they are instantiated by con-
crete expressions later on Line 7. The use of this ﬂexibility is
demonstrated below in Examples IV.6 and IV.9.

Example IV.6. Continuing Example IV.5,
for each sub-
scenario Tw (Figure 12), we aim to ﬁnd proper
re-
sponses αw,1, . . . , αw,Kw , whose preconditions Aw,i are weak
(cf. (12)). The outcome is illustrated in Figure 10.

The subscenario T1 We have to stop at a desired position
ytgt while driving in a single lane. A sensible program α1,1
that achieves it is to 1) ﬁrst cruise with the initial velocity
until braking is needed, and 2) then engage the maximum
comfortable braking (i.e. at the rate bmin) until the vehicle
comes to a halt. Formally,






α1,1 =

a := 0;
dwhile ( v2
2bmin
a := −bmin;
dwhile (v > 0) { ˙y = v, ˙v = a }

< ytgt − y) { ˙y = v, ˙v = a } ;




 .

(13)

The switching point is where SV’s position y is ytgt − v2
.
2bmin
We came up with this condition by high-school maths; its
correctness is conﬁrmed later on Line 7.

We can also include other programs as proper responses
α1,i—such as ones that brake more gently. We do not do so in
this paper, since α1,1 in the above is the most powerful when
it comes to goal achievement (namely, to stop at ytgt).

The subscenario T11 The goal here is to change lanes,
and it can be achieved by different longitudinal manoeuvre
sequences: cruise; cruise and brake; accelerate; accelerate and
cruise; etc. A general approach would be to include all these
manoeuvre sequences as proper responses α11,1, . . . , α11,K11 .
Among these possible proper responses, the “cruise-brake”
one is the most relevant, given that our goal later is to stop at
a given position. For simplicity, we only consider this proper
response:

α11,1 =






l := 2.5; t := 0; a := 0;
dwhile (F11,1 > 0 ∧ t < tLC) (cid:8) ˙t = 1, ˙y = v, ˙v = a (cid:9) ;
a := −bmin;
dwhile (t < tLC) (cid:8) ˙t = 1, ˙y = v, ˙v = a (cid:9) ;
l := 3




 .

(14)
Here, the change of lanes is indicated by the assignments l :=
2.5 and l := 3. The constant tLC stands for the maximum
time needed for changing lanes; we use tLC = 3 seconds as
an estimate (see e.g. [37]). Note that assuming a larger tLC
means 1) SV occupies two lanes longer and 2) it takes longer
to reach the destination lane, and thus makes analysis more
conservative.

The switching point is harder to ﬁnd here than for T1 in the
above—we therefore leave it as a syntactic parameter F11,1. It
is instantiated later on Line 7.

The subscenario T12 By the same reasoning, we deﬁne

α12,1 =






l := 2.5; t := 0; a := 0;
dwhile (F12,1 > 0 ∧ t < tLC) (cid:8) ˙t = 1, ˙y = v, ˙v = a (cid:9) ;
a := −bmin;
dwhile (t < tLC) (cid:8) ˙t = 1, ˙y = v, ˙v = a (cid:9) ;
l := 3




 .

Note that F12,1 will be instantiated with a different expression
from F11,1, since they are constrained by different POVs

(namely, POV1 as the immediate preceding vehicle for the
former, and POV2 for the latter).

The subscenarios T111, T121 By the same reasoning as
above, we deﬁne proper responses α111,1, α121,1 to be the same
as (14), using different syntactic parameters such as F111,1.

The subscenario T1111 The goal here is to prepare for
merging between POV2 and POV1, by making enough dis-
tances in front (from POV2) and behind (from POV1) and
matching the velocity with the preceding POV2, while driving
in Lane 1. See Figure 12. This may be achieved by various
longitudinal manoeuvre sequences. We choose the following
four, which we believe constitutes a quite comprehensive list.
• (α1111,1: accel-brake) Accelerate, at the rate amax, to
make enough distance behind (from POV1). Then brake
in order to match the velocity with the preceding POV2.
• (α1111,2: accel-cruise-brake) Similar to accel-brake, but in
case SV’s velocity reaches the legal maximum during the
acceleration manoeuvre, SV cruises until it has to brake.
• (α1111,3: accel) Accelerate only (at the rate amax). This

is used when SV is initially slower than POV2.

• (α1111,4: brake) Brake only (at the maximum comfortable
rate bmin). This is used when SV is initially faster than
POV2.

The subscenario T1211 The goal Goal1211 here is to prepare
for merging behind POV1. For ease of logical reasoning later,
we require that SV’s velocity should be the legal minimum
the end (vmin = v)—we did so already in (11). This
at
requirement may delay the goal achievement (stopping at ytgt
in Lane 3) by travelling slowly, but it does not reduce the
possibility of the goal achievement.

The goal Goal1211 may be achieved by various longitudinal
manoeuvre sequences, but those which involve acceleration are
obviously redundant. This leaves us with the following two
proper responses.

• (α1211,1: brake-cruise) Brake until v is as small as vmin,
and then cruise at vmin for the time needed to make
enough distance in front (from POV1).

• (α1211,2: brake) Brake only. This manoeuvre is used when
SV is initially sufﬁciently behind POV1, in which case
braking until vmin = v already makes enough distance
from POV1.
Note again that
there are other possible proper responses.
The above list is nevertheless comprehensive enough and thus
provide a useful RSS rule with a weak RSS condition.

Remark IV.7 (basic maneuvers). The proper responses in Ex-
ample IV.6 are composed of several basic manoeuvres, namely

• to cruise (a := 0; dwhile (A) { ˙y = v, ˙v = a }),
• to brake (a := −bmin; dwhile (A) { ˙y = v, ˙v = a }),
• to accelerate (a := amax; dwhile (A) { ˙y = v, ˙v = a }),
• to initiate lane change (such as l := 2.5), and
• to complete lane change (such as l := 3).

Restriction to this limited vocabulary is not mandated by
our framework. Still we ﬁnd it useful because 1) the logical
reasoning later on Line 7 can be modularised along basic
manoeuvres (see Section IV-D), and 2) basic manoeuvres are
easy to implement in a baseline controller (see Section VI-B).

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

18

D. Identifying Subscenario Preconditions (Line 7)

satisﬁes (16). A dFHL proof is in Figure 13.

In this step, we identify subscenario preconditions—
preconditions for subscenario proper responses αw,i that we
identiﬁed on Line 5. A subscenario precondition must guaran-
tee, after the execution of the proper response αw,i in question,
• not only the achievement of the subscenario goal Goalw,
• but also the precondition of the next proper response

αw(cid:48),i(cid:48) (where w = w(cid:48)j with some j).

The latter requirement is inductive: a subscenario precondition
for αj1j2j3 is constrained by one for αj1j2, which is further
constrained by one for αj1, etc. This forces us to identify sub-
scenario preconditions backwards. Such backward reasoning is
common in program veriﬁcation; see e.g. [31].

Because of this backward reasoning, too, we identify sub-
scenario preconditions for each sequence of subscenario proper
responses, instead of for each subscenario proper response.
This is made precise in the following deﬁnition.

Deﬁnition IV.8 (backward condition propagation). Let S be a
scenario, T be a subscenario tree for S, and αw,1, . . . , αw,Kw
be proper responses for each subscenario Tw in T .

On Line 7 of Procedure 1, we identify an assignment

(Aw,u)w,u. Speciﬁcally,

• to each node w = j1j2 . . . jk of T and each sequence
u = i1i2 . . . ik of proper response indices (where i1 ∈
[1, Kj1], i2 ∈ [1, Kj1j2], . . . , ik ∈ [1, Kj1...jk ], cf. Nota-
tion II.1),

• we assign a dFHL assertion Aw,u = Aj1j2...jk,i1i2...ik ,
so that the assignment satisﬁes the following condition (15).

For each k ∈ [0, N − 1], jk+1, ik+1, w = j1 . . . jk,
u = i1 . . . ik, the dFHL quadruple

{Awjk+1,uik+1} αwjk+1,ik+1 {Goalwjk+1 ∧ Aw,u}
: Safewjk+1 ∧ Envwjk+1

(15)

is valid.

Here we set, as a convention, Aε,ε = true for k = 0. Note
that the condition (15) is deﬁned inductively on k; it therefore
forces us to choose Aw,u for shorter w, u ﬁrst.

Note that the deﬁnition does not uniquely determine the
assignment (Aw,u)w,u:
the assignment
is only constrained
by the condition (15);
there are generally many ways to
satisfy (15). We aim at weaker preconditions—as is usual
in program veriﬁcation—so that
the resulting RSS rule is
applicable to wider situations.

Example IV.9. We continue Example IV.6 and identify sub-
scenario preconditions A1,1, A11,11, A12,11, . . . in a backward
manner. These preconditions and their relationships—such as
the one required in (15)—are illustrated in Figure 11.
The subscenario T1 We aim at A1,1 that satisﬁes

{A1,1} α1,1 {y = ytgt ∧ v = 0} : l = 3 ∧ Env

(16)

where Env is from Example III.2 and α1,1 is from (13) (see
also Figure 12). It turns out that

(cid:16)

A1,1 =

Env ∧ l = 3 ∧ v > 0 ∧ v2
2bmin

≤ ytgt − y

(cid:17)

(17)

The subscenario T11 We aim at A11,11 that satisﬁes

{A11,11} α11,1 {l = 3 ∧ A1,1} : Safe11 ∧ Env11

(23)

where Safe11 and Env11 are from Figure 12 and α11,1 is
from (14). Note that A1,1 that we found in (17) is now part of
the postcondition.

It turns out that the deﬁnition of Safe11, Env and α11,1
simpliﬁes the reasoning a lot: for example, the safety condition
y2 − y ≥ dRSS(v2, v) is obviously preserved in the course of
the dynamics since we require v ≤ v2 in Safe11; moreover,
v ≤ v2 is preserved since α11,1 can brake or cruise but
never accelerates. Not imposing legal minimum speed on SV
(Example III.2) simpliﬁes the reasoning too.

In the end, we arrive at the following precondition, for which

we can prove (23).

A11,11 =

(cid:18) Env ∧ l = 2 ∧ 0 < v ≤ v2 ∧
y2 − y ≥ dRSS(v2, v) ∧ v2
2bmin

(cid:19)

,

≤ ytgt − y

Here we instantiate F11,1 in (14) with ytgt − y − v2
2bmin

.

v2
2bmin

The key inequality here is

≤ ytgt − y, much like
in (17). This is not surprising: ignoring lateral movements and
the leading vehicle POV2 (we can do so by the simpliﬁcation
discussed above), goal achievement depends solely on whether
the braking is in time.

The subscenarios T12, T111, T121 Similarly to T11, we
choose preconditions A12,11, A111,111, A121,111, while instan-
tiating syntactic parameters F12,11, F111,111, F121,111 in the
proper responses.

The subscenario T1111 We identiﬁed four proper responses
α1111,1, . . . , α1111,4 in Example IV.6. Here we focus on α1111,2
(accel-cruise-brake)—it is the most complicated—and identify
the corresponding precondition A1111,1112. The reasoning be-
low subsumes those for the other three proper responses.

The proper response α1111,2 accelerates until

the legal
maximum speed vmax, cruises at vmax in order to increase the
distance behind (from POV1), and brakes to match its velocity
with POV2. There are two switching points.

• The one from acceleration to cruising—its timing is easily

determined by v < vmax or not.

• The one from cruising to braking—its timing is decided
so that, at the end of braking (when v = v2), the distance
behind (from POV1) is precisely the required RSS safety
distance dRSS(v, v1).

These arguments can easily be translated to symbolic condi-
tions, which are used to instantiate symbolic parameters in
α1111,2. It is also easy to symbolically express the positions and
velocities of SV and POVs at the end of the proper response.
the precondition A1111,1112 must be such that
{A1111,1112} α1111,2
{Goal1111 ∧ A111,111} : Safe1111 ∧
Env1111 is valid. In other words, we must address the following
concerns.

Now,

• The subscenario goal Goal1111 = (cid:0)y2−y ≥ dRSS(v2, v)∧
y − y1 ≥ dRSS(v, v1) ∧ v2 = v(cid:1) (see Figure 12) as part
of the postcondition. The latter two conjuncts are trivially
satisﬁed by the above design of the proper response;
therefore y2 − y ≥ dRSS(v2, v) is a core part of the

(19)

(20)

(21)

(22)

∧ v2

2bmin

by (LIMP) and (20)

∧ v2

2bmin

≤ ytgt − y

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

(cid:40) Env ∧ l = 3 ∧ 0 < v ≤ vmax

(cid:41)

∧ ytgt − y − v2
2bmin

≥ 0

dwhile ( v2

2bmin

˙y = v, ˙v = 0

< ytgt − y)

(cid:40) Env ∧ l = 3 ∧ 0 < v ≤ vmax

∧ ytgt − y − v2
2bmin

= 0

(cid:41)

:

Env ∧ l = 3 ∧ 0 < v ≤ vmax
∧ −bmin ≤ a ≤ amax
∧ ytgt − y − v2
2bmin

≥ 0

19

(18)

by (DWH) with (einv ∼ 0) = (v > 0), evar = ytgt − y −

, eter = −v
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
(cid:40) Env ∧ l = 3 ∧ 0 < v ≤ vmax

v2
2bmin
(cid:40) Env ∧ l = 3 ∧ 0 < v ≤ vmax

(cid:41)

(cid:41)

dwhile ( v2

2bmin

˙y = v, ˙v = 0

< ytgt − y)

∧ v2

2bmin

= ytgt − y

:

Env ∧ l = 3 ∧ 0 ≤ v ≤ vmax
∧ −bmin ≤ a ≤ amax
∧ y ≤ ytgt

∧ v2

2bmin

≤ ytgt − y

by (LIMP) and (18)

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
(cid:40) Env ∧ l = 3 ∧ 0 < v ≤ vmax

(cid:41)

(cid:41)

dwhile (v > 0)

(cid:40) Env ∧ l = 3 ∧ v = 0
= ytgt − y

∧ v2

2bmin

:

Env ∧ l = 3 ∧ 0 < v ≤ vmax
∧ −bmin ≤ a ≤ amax
∧ v2

= ytgt − y

2bmin

∧ v2

2bmin

= ytgt − y

˙y = v, ˙v = −bmin

by (DWH) with (einv ∼ 0) = (ytgt − y −

= 0), evar = v, eter = −bmin

v2
2bmin

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
(cid:40) Env ∧ l = 3 ∧ 0 < v ≤ vmax

(cid:41)

(cid:27)

(cid:26) Env ∧ l = 3 ∧ v = 0

dwhile (v > 0)

= ytgt − y

˙y = v, ˙v = −bmin

∧ y = ytgt

:

Env ∧ l = 3 ∧ 0 ≤ v ≤ vmax
∧ −bmin ≤ a ≤ amax
∧ y ≤ ytgt

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
(cid:40) Env ∧ l = 3 ∧ 0 < v ≤ vmax

(cid:41)

(cid:27)

(cid:26) Env ∧ l = 3 ∧ v = 0

dwhile ( v2
dwhile (v > 0) (cid:8) ˙y = v, ˙v = −bmin

< ytgt − y) (cid:8) ˙y = v, ˙v = 0 (cid:9);

2bmin

(cid:9)

∧ y = ytgt

:

Env ∧ l = 3 ∧ 0 ≤ v ≤ vmax
∧ −bmin ≤ a ≤ amax
∧ y ≤ ytgt

by (SEQ), (19) and (21)

Fig. 13: A dFHL proof for {A1,1} α1,1 {Goal1} : Safe1 ∧ Env1, Example IV.9. Here we use the obvious constant substitution,
replacing (cid:0) a := 0; dwhile (A) { ˙y = v, ˙v = a } (cid:1) with (cid:0) dwhile (A) { ˙y = v, ˙v = 0 } (cid:1), for example. The dynamics of POVs is
not explicit here; see Remark III.5. The derivation of (18) and (20) in fact requires a more general form of (DWH) than we
presented in Figure 7 (namely the “multiple-invariant multiple-variant” one in Figure 19, Appendix A); see Remark II.13.

postcondition. Using the analytic solution of the proper
response, the last postcondition is easily translated to a
precondition on the initial positions, velocities, etc.

• The precondition A111,111 of the next subscenario T111,
as part of the postcondition. Much like for A11,11 (dis-
cussed above), the key inequality in A111,111 is again
v2
≤ ytgt − y—this is imposed ultimately to ensure
2bmin
that SV does not overshoot the stopping position ytgt.
The requirement of this inequality as a postcondition can
easily be translated to a precondition, too.

• The condition y3 − y ≥ dRSS(v3, v) as part of the
safety condition. Again, using the analytic solution of
the proper response, it is easy to calculate a precondition
that guarantees this safety condition. The reasoning here
is much like for the original RSS proof [1] that
the
RSS safety distance is enough for collision avoidance
(Example I.3).

above (for T1211)—it is much easier since T1211 does not have
requirements at odds, such as y2 − y ≥ dRSS(v2, v) ∧ y − y1 ≥
dRSS(v, v1).

In fact, the subscenario T1211 and the subsequent ones in the
subscenario tree (namely T121, T12, T1) are so simple that we
can automate the whole task of identiﬁcation of subscenario
proper responses (Line 5) and preconditions (Line 7). This
partial automation will be presented in another venue.

E. Global Proper Response and Precondition (Line 8)

The goal of Procedure 1 is to ﬁnd A (an RSS condition) and
α (a proper response) such that {A} α {Goal} : Safe ∧ Env
is valid (Section III-C). In this last step of Procedure 1,

• to obtain α, we

responses
αw,1, . . . , αw,Kw we have identiﬁed for different subsce-
narios Tw, and

the proper

combine

We deﬁne A1111,1112 as the conjunction of the three precon-
ditions that come from the above concerns. It requires enough
distances from ytgt and POV2–3, all formulated symbolically
in terms of the vehicles’ initial positions and velocities.

The above calculation of a precondition A1111,1112 is theo-
retically straightforward—an analysis of a quadratic dynamic
system with some case distinctions. It is nevertheless laborious,
with logical assertions easily blowing up to dozens of lines. We
use Mathematica to manage the necessary symbolic manipu-
lations, such as solving quadratic equations, substitution, and
tracking case distinctions. See Section V for further discussion.
The subscenario T1211 We identiﬁed two proper
re-
sponses α1211,1, α1211,2
in Example IV.6. Preconditions
A1211,1111, A1211,1112 for those can be found much like in the

• compute a collective precondition A.

We do so using the dFHL rules—especially the (SEQ) and
(CASE) rules, see Figure 7 and (5).

Deﬁnition IV.10 (global proper response and precondition).
Using the subscenario proper responses (αw,i)w,i and subsce-
nario preconditions (Aw,u)w,u obtained on Line 5 and 7, we
deﬁne the global proper response α and the global precondi-
tion A as follows.

α = case (Aw,u)w=j1...jk,u=i1...ik

A = (cid:87)

αj1...jk,ik ; αj1...jk−1,ik−1 ; · · · ; αj1,i1 ,
Aj1...jk,i1...ik .

w=j1...jk,u=i1...ik

(24)

Finally, A and α are returned as the outcome of Line 7.

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

20

In (24), the case distinction and the disjunction range over

all w and u considered earlier. That is,

• every word w = j1j2 . . . jk that designates a node of T

(the node Tw need not be a leaf), and

• all

index sequences u = i1 . . . ik compatible with w
(meaning i1 ∈ [1, Kj1], . . . , ik ∈ [1, Kj1...jk ], as above,
cf. Notation II.1).

See Example IV.9 and Figure 11 for an example.

The following is our main theorem; it states that the above
outcome indeed achieves the speciﬁed goal while maintaining
safety. Our framework—including the design of dFHL—has
been carefully designed so that its proof is straightforward.

Theorem IV.11 (correctness of Procedure 1). In Procedure 1,
the outcome (A, α) of Line 7 (Deﬁnition IV.8) is a goal-aware
RSS rule for S (Deﬁnition III.4), making the dFHL quadruple
{A} α {Goal} : Safe ∧ Env valid.

Proof. The proof is shown in Figure 14. It builds upon the
assumption (15) on the precondition Aw,u that we identiﬁed for
each subscenario proper response αw,i. It also relies crucially
on Deﬁnitions IV.1 and IV.4)—we require Safew ∧ Envw ⇒
Safe for each subscenario Tw in T on Line 3.

We note that, in the last proof, the subgoals Goalw with
|w| > 1 play no role. They are useful, however, in designing
subscenarios (especially choosing Safew and Envw in Sec-
tion IV-B2) and identifying proper responses (Section IV-C).
In other words, the subgoals Goalw play the role of glue in
our compositional workﬂow.

The proof does not use the (ASSIGN), (WH), and (DWH)
rules. They are used for establishing the assumption (15) for
each subscenario proper response αw,i. See e.g. Figure 13.

Example IV.12. Continuing Example IV.9, for the pull over
scenario in Example III.2, we obtain a global proper response

stands for, when j1 . . . jk designates a non-leaf node. It should
be noted too that the formal notion of scenario (Deﬁnition III.1)
does not state where to start—it only speciﬁes where to reach,
and what conditions to maintain.

F. Another Example Scenario: Emergency Stop with Limited
Visibility

We have given a detailed account of how to apply the
workﬂow to the pull over scenario (Example I.5). Here, we
present how the workﬂow applies to another scenario, in order
to validate the applicability of the workﬂow.

The scenario is illustrated in Figure 15. In this scenario there
are 4 lanes: 3 driving lanes (Lane 1-3), and the hard shoulder
(Lane 4). SV starts in Lane 1, there is a single POV in Lane 1
(ahead of SV) and two POVs in Lane 2, as in Example I.5. SV
is required to stop on the hard shoulder at one of two possible
locations (ytgt1 or ytgt2). Stopping at the ﬁrst target location
(ytgt1) is preferred, but there may be a POV (POV4) parked
there, in which case SV should stop at the second location
(ytgt2). Furthermore, SV only becomes aware of POV4 when
it comes within sensing distance D of it, which we assume to
be at least a ﬁxed constant, say 50 m.

The scenario differs from the previous one (Example I.5) in,
among others, 1) the number of lanes and 2) the dynamic char-
acter (the ﬁrst location ytgt1 may be occupied). As we sketch
below, our logical workﬂow is applicable to this scenario.

To model the existence of POV4, we use a variable p whose
value is 1 when POV4 exists, and 0 otherwise. In the case
that p = 1, variable y4 gives the position of POV4. Another
variable d takes on the values 0 or 1 depending on whether
SV has detected POV4. The goal, safety and environment
assertions are deﬁned as follows:











α =

case (A1,1)

α1,1
α11,1; α1,1
α12,1; α1,1

(A11,11)
(A12,11)
· · ·
(A1111,1111) α1111,1; α111,1; α11,1; α1,1
(A1111,1112) α1111,2; α111,1; α11,1; α1,1
· · ·
(A1211,1112) α1211,2; α121,1; α12,1; α1,1











,

and a global precondition A = A1,1 ∨ · · · ∨ A1211,1112. By
Theorem IV.11, it is guaranteed that {A} α {Goal} : Safe ∧
Env is valid. The resulting (A, α) are rather long—logically
combining dozens of symbolic inequalities. This makes them
hard to read for humans, but computers have little problem
checking and executing them (Section VI).

Remark IV.13. In (24), we do not require w to designate a
leaf node—this is strange if we think of α to lead from the
beginning of the driving scenario in question to its goal. We
include non-leaf nodes because of the use of the resulting RSS
rule in the simplex architecture (cf. Sections I-E and VI-B).
In the simplex architecture, a global proper response (as BC’s
control) can be switched on and off, depending on whether the
RSS conditions are true or not at each moment. It is then bene-
ﬁcial if we can start a global proper response from somewhere
in its middle; this is what the program αj1...jk,ik ; · · · ; αj1,i1

Goal =

Safe =

Env =

(cid:32)











(cid:33)

,

l = 4 ∧ v = 0 ∧ (y = ytgt1 ∨ y = ytgt2)
∧ (p = 0 ⇒ y = ytgt1)
(cid:86)

i=1,2,3(aheadSLi ⇒ yi − y > dRSS(vi, v))
∧ (p = 1 ∧ aheadSL4) ⇒ y4 − y > dRSS(v4, v)
∧ (0 ≤ v ≤ vmax ∧ −bmin ≤ a ≤ amax)
(cid:86)

(cid:0) vmin ≤ vi ≤ vmax ∧ ai = 0 ∧ li = i (cid:1)

i=1,2,3
∧ y2 > y1
∧ v4 = 0 ∧ y4 = ytgt1 ∧ D > 50




 ,




 .

Decomposition into subscenarios proceeds as in Sec-
tion IV-B for Example I.5. In total there are six subscenarios:
1) prepare to merge into Lane 2 (by adjusting speed and posi-
tion); 2) merge into Lane 2; 3) merge into Lane 3; 4) prepare to
merge into Lane 4, while waiting for ytgt1 − y < D; 5) merge
into Lane 4; 6) stop at target location. The subscenario subgoals
are similar to those in Section IV-B, except for Goal(4) = (l =
3∧ytgt1−y = D). The subscenario tree branches at the level of
subscenario 6 depending on which target location SV aims to
stop at, and at the level of subscenario 1 depending on whether
SV merges in front or behind POV1.

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

21

(cid:8)Aj1...jk+1,i1...ik+1

(cid:9) αj1...jk+1,ik+1 {Goalj1...jk+1 ∧ Aj1...jk,i1...ik } : Safej1...jk+1 ∧ Envj1...jk+1

(25)
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
(cid:8)Aj1...jk+1,i1...ik+1

(cid:9) αj1...jk+1,ik+1 {Aj1...jk,i1...ik } : Safe ∧ Env

for each j1 . . . jk+1, i1 . . . ik+1

for each j1 . . . jk+1, i1 . . . ik+1

(By condition (15))

(By (LIMP), (25), Goalj1...jk+1 ∧ Aj1...jk,i1...ik ⇒ Aj1...jk,i1...ik ,
Safej1...jk+1 ∧ Envj1...jk+1 ⇒ Safe, and Safej1...jk+1 ∧ Envj1...jk+1 ⇒ Env, see Deﬁnitions IV.1 and IV.4 )

for each j1, i1

for each j1, i1

((25) with k = 0. Recall that Aε,ε = true)

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
(cid:8)Aj1,i1
(27)
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
(cid:8)Aj1,i1

(cid:9) αj1,i1 {Goalj1} : Safej1 ∧ Envj1
(cid:9) αj1,i1 {Goal} : Safej1 ∧ Envj1

(28)
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
(cid:8)Aj1,i1

(By (LIMP), (27), and Safej1 ∧ Envj1 ∧ Goalj1 ⇒ Goal, see Deﬁnition IV.4 )

(29)
(By (LIMP), (28), Safej1 ∧ Envj1 ⇒ Safe, and Safej1 ∧ Envj1 ⇒ Env, see Deﬁnitions IV.1 and IV.4 )
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
(cid:8)Aj1...jk+1,i1...ik+1

(30)
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
(cid:8)(cid:87)
(31)

(Repeated application of (SEQ) to (26) and (29))
(cid:9) case (Aw,u)w=j1...jk,u=i1...ik αj1...jk,ik ; · · · ; αj1,i1

(cid:9) αj1,i1 {Goal} : Safe ∧ Env

(cid:9) αj1...jk,ik ; · · · ; αj1,i1

for each j1 . . . jk+1, i1 . . . ik+1

(cid:8)Goal(cid:9) : Safe ∧ Env

(cid:8)Goal(cid:9) : Safe ∧ Env

(By (CASE) and (30))

for each j1, i1

(26)

w,u Aw,u

Fig. 14: Correctness proof for Procedure 1 (Theorem IV.11)

the pull over example. The preconditions and proper responses
were successfully derived by following the workﬂow.

G. Discussions

We conclude with some discussions of our workﬂow.
1) Compositionality: We argue that our workﬂow (Proce-

dure 1) is compositional.

Firstly,

the design of proper responses is split up from
the whole scenario to individual subscenarios, and it can be
done independently for each subscenario (Line 5). We showed
through our leading example that it can be done systematically,
combining possible longitudinal and lateral movements, now
that a goal and a safety condition are much simpliﬁed. It is
also worth noting that many subscenarios are similar to each
other, allowing one to reuse previous analysis.

In this paper, for simplicity, we focused on a limited number
of subscenario proper responses that we see as more important
than others (see Example IV.6). A viable alternative is to sys-
tematically list possible proper responses, even if some of them
have limited applicability (i.e. strong preconditions). A well-
developed software support and/or ample human resources
would allow this brute-force approach. See also Section V.

Secondly,

subscenario

identiﬁcation

preconditions
of
(Line 7) is compositional, too—in the same sense as program
veriﬁcation in Floyd–Hoare logic is compositional. Unlike
Line 5, identiﬁcation of Aw,u is not independent for different
w, u—there is a backward interdependence in the form of (15).
However, splitting up the task of precondition identiﬁcation
to simpler subscenarios certainly makes it easier, as we see in
Example IV.9. There are a lot of duplicates, too, so that one
can reuse previous reasoning.

Fig. 15: The scenario in Section IV-F: emergency stop with
limited visibility

The subscenario proper responses were derived in much the
same way as in Section IV-C for Example I.5. Of note were
those derived for subscenarios 4 and 5 which took the form:

(cid:16)

(cid:16)

α4 =

α5 =

dwhile (ytgt1 − y > D) β4

(cid:17)

,

d := p; if (d = 1) β5,1

else β5,0

(cid:17)

.

SV waits to ﬁnd out if there is a parked vehicle or not (β4
is a hybrid program that stays in Lane 3), and then responds
in one of two ways: if a POV is detected, then SV merges
before ytgt2 (β5,1), otherwise it merges before ytgt1 (β5,0).
From this, we derive preconditions and proper responses as in

2) Completeness: There are many “best-effort” elements in

our workﬂow:

• On Line 5, the list of subscenario proper responses should
better be more comprehensive, but there is no formal
criterion on what is enough or what is the best.

yytgt1Lane 1Lane 2Lane 3Lane 4(shoulder)SOSSVPOV1POV3POV2ytgt2SOSPOV4 ??ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

22

• On Line 7, subscenario preconditions are only subject
to (15) that can be satisﬁed even by false. It is only desired
that they are weak.

• Moreover, on Line 2 and 3, there is no formal criterion
what is a good subscenario decomposition. The conditions
in Deﬁnitions IV.1 and IV.4 are only minimal sanity
checks.

Consequently, the question “how useful is the obtained RSS
rule (A, α)?”, that is, “is A weak enough?”, will always stand.
We argue, however, that this completeness issue should not

block the use of our workﬂow.

• Firstly, it is not hard to come up with proper responses
whose preconditions are fairly weak. This can be done by
mimicking what human drivers would do, in which case
the RSS-supervised ADS is at least as goal-achieving as
human drivers.

• Secondly, we can always incrementally improve (A, α)
by identifying more αw,i and weaker Aw,u. Note that this
process monotonically weakens the precondition A since
it adds new disjuncts to A (see (24)). The process makes
an RSS rule increasingly complete, without fallbacks.
• Thirdly, that (A, α) comes with a correctness guarantee
(Theorem IV.11) means that they can be used for many
years to come, as a solid basis of safe driving. The efforts
for better (A, α) therefore pay off in the long run.

3) On Environmental Assumptions: In our leading example
(the pull over scenario), we assumed constant speeds of the
other vehicles (Env in Example III.2). We note that

• while violation of this assumption may threaten goal

achievement (namely stopping at ytgt in Lane 3),

• it does not threaten collision avoidance,

because the scenario’s safety condition requires the RSS safety
distance (dRSS from Example I.3) from every other vehicle
(see (8)).

The above point has the following practical implication, in
the expected use of (CA- and GA-)RSS rules in the simplex
architecture (Section I-E; see also Section VI). In actual ADS,
we expect another layer of the simplex architecture on top of
the one based on our goal-aware RSS rules. The “collision
avoiding” BC of this other simplex architecture monitors the
RSS safety distance and brakes if necessary, thus ensuring col-
lision avoidance at the possible sacriﬁce of goal achievement.

V. SOFTWARE SUPPORT FOR RULE DERIVATION
We discuss software support for our workﬂow (Procedure 1).
Note that, in this section, we focus on software for deriving
goal-aware RSS rules. In contrast, software for using goal-
aware RSS rules in the simplex architecture is heavily de-
pendent on the choice of AC (Section I-E)—it is discussed
separately in Section VI-B.

Our workﬂow (Procedure 1) involves two types of tasks:
• human discovery tasks, namely of subscenarios (Line 3),
proper responses (Line 5), and preconditions (Line 7), and
• logical reasoning tasks in dFHL, such as ensuring the

condition (15) and computing A, α (see (24)).

Much like other formal veriﬁcation problems, we can imagine
different ways to execute them.

• A pen-and-paper execution. This requires less prepara-

tion/infrastructure work, but is more error-prone.

• A fully formalised execution, much like in formal veriﬁ-

cation by theorem proving (see e.g. [26]).

A. Current Software Support with Mathematica

Our current execution scheme of the workﬂow (Procedure 1)
is only partially formalised. Its software support principally
uses Mathematica notebooks [38], an interactive environment
in which users can mix

• symbol manipulations such as solving quadratic equa-
tions, substitution, and tracking case distinctions, exploit-
ing advanced algorithms of Mathematica as a computer
algebra system, and

• rich annotations for human readers, such as structured

natural language descriptions, ﬁgures, and tables.

Our logical reasoning in the workﬂow is currently formalised
as much as Mathematica can accommodate. Speciﬁcally,

• (static reasoning is formalised) all dFHL assertions are
expressed formally in Mathematica (which is possible
since each dFHL assertion is a predicate logic formula
over reals), and their implications are formally checked
using Mathematica functions such as Simplify; but

• (dynamic reasoning is not

formalised) neither dFHL
quadruples nor their derivation using the rules in Figure 7
is formalised, since the language of Mathematica does not
accommodate them.

Our current execution scheme therefore has
room for
improvement—formalisation of dynamic reasoning is certainly
desirable. See Section V-C for its prospects.

Nevertheless, our current Mathematica-based and partially
formalised execution scheme has the following distinctive
advantages.

• (Well-documented informal reasoning) Dynamic reason-
ing for deriving dFHL quadruples is recorded in Mathe-
matica notebooks in an informal yet trackable manner,
with natural
language explanations that explicate the
dFHL rules used therein. Therefore these proofs can be
efﬁciently checked by human reviewers, if not machine
checkable.

• (Interaction for discovery) The interactive nature of Math-
ematica notebooks allows us to make trials and errors
quickly for the human discovery part of our workﬂow
(Procedure 1).

• (No static reasoning errors) A large part of mistakes in
executing our workﬂow is in the treatment of vehicle
dynamics expressed in the double integrator model. For-
malisation of static reasoning in Mathematica purges these
mistakes. Note that our vehicle dynamics (Remark IV.7)
have closed-form solutions, which easily reduce dynamic
reasoning to static one.

Given these advantages, we claim that our current execution
scheme gives high conﬁdence in the correctness of derived
goal-aware RSS rules, and that the execution scheme is a viable
option for practical use.

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

23

B. Estimated Workload for Rule Derivation

We estimate the workload as follows: an expert

in our
workﬂow and its software support would need several days
to derive a GA-RSS rule, for a scenario of the complexity
of Example I.5. This was our experience when one of the
current authors conducted the task. Getting acquainted with our
workﬂow and its software support is not hard, either, especially
for people with backgrounds in formal logic. We expect that
the required training would take a couple of weeks.

Moreover, the compositional workﬂow and its implementa-
tion in Mathematica (featuring informal yet well-documented
reasoning) allow efﬁcient collaboration of multiple people. For
example, we could parallelise the identiﬁcation of subscenario
proper responses α1111,1 and α1111,2—together with the iden-
tiﬁcation of the preconditions A1111,1111 and A1111,1112, see
Figure 11—and distribute the task to different people. The
same happened between the subscenarios T1111 and T1211 in
Figure 11. The communication cost between different work-
ers was kept minimal, since they could communicate semi-
formally via Mathematica notebooks.

Overall, while the workload of deriving GA-RSS rules is
not very light (it is hardly a matter of minutes, for example),
we claim that it is light enough to be useful, especially given
that the derived GA-RSS rules can be used as a rigorous basis
of safe ADS in many years to come.

C. Towards Full Formalisation

For fully formalised execution of our workﬂow (Proce-
dure 1), natural tools to use are theorem provers for differential
dynamics such as KEYMAERA X [39]. Our logic dFHL is
designed with its translation to differential dynamic logic
dL [18] in mind, so the use of KEYMAERA X (which is a
theorem prover for dL) should not be hard.

We are currently working on systematic translation of dFHL
to dL, and on some dedicated proof tactics in KEYMAERA X.
Our preliminary experience of manually formalising part of
the reasoning for the pull over scenario (Example IV.9) is
encouraging. Building a fully formalised infrastructure for the
workﬂow will take considerable time and effort, though.

VI. EXPERIMENTS AND EVALUATION

In Section IV we presented a general workﬂow to gener-
ate GA-RSS rules. The “implementation” of the workﬂow,
speciﬁcally software support for its execution, was discussed
in Section V.

In this section, we seek to quantitatively evaluate our
workﬂow by conducting experiments on a speciﬁc output of
the workﬂow. Concretely, we evaluate the GA-RSS rule set
for the pull over scenario (Example I.5)—obtained using the
workﬂow in Section IV and ﬁnalised in Example IV.12—using
it as the baseline controller (BC) in the simplex architecture
(Section I-E).

The resulting RSS-supervised controller

is denoted by
AC+RSSGA; we will compare its performance to other similar
controllers (namely AC+RSSCA and AC, introduced later).

The rest of the section is organised as follows. We pose sev-
eral research questions in Section VI-A, based on which we de-
signed our experiments. The implementation of AC+RSSGA is
introduced in Section VI-B, together with those of AC+RSSCA
and AC. Experiment settings and results are described in
Section VI-C. Based on these results, in Section VI-D, we
address the research questions that we posed earlier. Finally,
in Section VI-E, we take a closer look at two notable scenario
instances that further demonstrate the value of GA-RSS.

A. Research Questions

To fully evaluate the GA-RSS rule set for the pull over
scenario (Example IV.12), we need to answer several research
questions. Our claim is that the rule set we derived with our
workﬂow is able to achieve a given goal (namely, pulling over)
safely, which leads to our ﬁrst research questions.

RQ 1. How does the GA-RSS-supervised controller perform
in terms of safety?

RQ 2. How does the GA-RSS-supervised controller perform
in terms of accomplishing its goal?

Another crucial point of the method, if we want it to be used
in automated driving, is whether this controller can be used in
practice. For example, are the RSS conditions not too complex
to be computed repeatedly in a control loop at run-time? Are
they not too restrictive to apply to many common driving
situations?

RQ 3. Can the GA-RSS-supervised controller be useful in
practice (e.g. in terms of computation speed and weakness of
the RSS condition)?

While reaching the goal and maintaining safety are the two
principal requirements of our controller, it is also desirable to
test it for other metrics. Reaching the goal in good time and
comfortably are desirable, even if these concerns are secondary
to safety and goal achievement.

RQ 4. How does the GA-RSS-supervised controller perform
in terms of other signiﬁcant metrics (progress, comfort, etc.)?

Finally,
the controller we build is based on the simplex
architecture, and contains an advanced controller (AC), which
may be unsafe, but is usually optimised for speed and comfort.
Our simplex architecture should thus interrupt AC as rarely as
possible.

RQ 5. How often is AC in control during execution?

B. Implementation of the Controllers

Our controller AC+RSSGA that uses the GA-RSS rule set
(Example IV.12) is based on the simplex architecture. As
AC of the architecture (Section I-E), we used a prototype
planner4 based on the algorithm in [3]. AC is a sampling-based
controller that, at each time step, generates a large number of
candidate short-term paths and chooses the best in terms of a

4This is a research prototype that is provided by Mazda Motor Corporation.

It is however unrelated to any of its products.

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

24

cost function. The cost function is a weighted sum of costs for
multiple concerns; they are namely safety, progress, vehicle
dynamics feasibility, trafﬁc law compliance, and comfort.

implementation of BC is a “surrogate” one:

In our GA-RSS-supervised controller AC+RSSGA, the cur-
rent
instead
of directly implementing the proper responses we identiﬁed
in Section IV, we implemented them as an alternative cost
function for the sampling-based controller used as AC. Specif-
ically, this cost function favours the short-term path that is the
closest to the desired proper response. The decision module
(DM) checks all RSS conditions Aw,u (computed on Line 7
of Procedure 1), and allows AC to remain in control as long
as one of them remains valid. When the last one fails, DM
switches control to BC which engages in the corresponding
proper response αw,i (identiﬁed on Line 5 of Procedure 1).

Remark VI.1 (prioritisation of GA-RSS rules). The above
description of DM and BC is simpliﬁed: for enhanced progress,
we additionally employ the prioritisation mechanism, ex-
plained below.

Speciﬁcally, some of our proper responses are designed with
progress in mind (while still ensuring safety), while others
reach the goal but do not make signiﬁcant progress. In order
to make our controller efﬁcient, we separate rules into a high-
priority and a low-priority group, and only use rules from the
high-priority group whenever possible. If at any point during
the execution, some high-priority rule can be engaged, then
the low-priority set is discarded to only allow the use of high-
priority rules.

We compare our controller AC+RSSGA to two other con-

trollers:

AC: AC alone—the sampling-based controller discussed

above—without any BC.

AC+RSSCA: A collision-avoiding RSS-supervised con-
troller. In this instance of the simplex architecture, BC imple-
ments the following CA-RSS rules. They are a straightforward
adaptation of the classic CA-RSS rule in Example I.3.

• SV must maintain the RSS safety distance from any POV
1) that SV shares a lane with and 2) that is in front of
SV. The proper response is to brake until the RSS safety
distance is restored.

• Additionally, when SV changes lanes, it must allow RSS
safety distances both in front of it and behind it.5 The
proper response is to abort changing lanes if these RSS
safety distances are not secured.

C. Experiment Settings and Results

We ran simulations with the three controllers above under
different instances of the pull over scenario (Example I.5). The
scenario instances were generated by the following parameter
values—we found them generate relevant scenario instances.
Here the positions are in meters (m) and velocities are in m/s:

v(0) ∈ {10, 14},
y(0) = 0,
y1(0) ∈ {−10, −5, 0, 5, 10};
y3(0) ∈ {85, 90, 95, 100, 105};

vi(0) ∈ {10, 14} (i = 1, 2, 3);
y2(0) ∈ {75, 80, 85, 90, 95};
ytgt ∈ {140, 160, 180},

5This is how we formalise the RSS responsibility principle 2) “Don’t cut

in recklessly”—see Example IV.2.

We imposed the constraint v1(0) ≤ v2(0) to avoid collisions
between POVs. For constants, we used the following values
taken from our AC: vmin = 10 m/s, vmax = 28 m/s, ρ = 0.3 s,
amax = 0.98 m/s2, bmax = 8 m/s2, and bmin = 2.94 m/s2.

We nevertheless found that some scenario instances are
clearly irrelevant (e.g. ytgt is too close to stop at); we ruled
out those instances as follows. While simulating, if none of the
RSS conditions for our GA-RSS rule set are satisﬁed for the
ﬁrst 0.5 s, then we discarded the scenario instance. In total,
we kept 2350 instances, that is 52% of the total number of
instances.

The statistics of the simulation results are given in Table I. In
the goal column, we count the number of instances that reach
the goal. In the collision column, we count how many instances
resulted in a collision. In the RSS violation, we count the num-
ber of instances where some RSS safety distance is violated;
the average and maximal violation times. We also compute by
how much the RSS safety distance was violated: it is computed
as the maximal value along any execution, for any time t,
and relevant POV i, of 1 − (yi(t) − y(t))/dRSS(vi(t), v(t)).
In the time column, we record the average and maximal
travel times. In the jerk column, we record the average and
maximal amount of uncomfortable jerk accumulated along the
trajectory. We only accumulate jerk over 0.5 m/s3, as jerk
below that threshold is considered comfortable [40]. In the BC
time column, we quantify how long BC has been in control on
average.

travel

In Figure 16 and Figure 17, we give more details on the
distributions of travel times and accumulated jerk. In Figure 16,
we show AC+RSSGA’s total
time compared to both
AC+RSSCA and AC. The size of a disc is proportional to the
number of scenario instances with that travel time. A red disc
indicates that AC+RSSCA failed to achieve the goal in this case.
All these experiment results indicate comparative advantages
and values of GA-RSS. We discuss them in detail below, along
the research questions we posed in Section VI-A.

D. Discussion

Let us address the different research questions in light of

the experimental results.

1) RQ 1: How does the GA-RSS-supervised controller per-
form in terms of safety?: All three controllers successfully
avoided collisions. However, when it comes to maintaining
RSS safety distances in order to prepare for sudden changes
of behaviours of other cars, their performance varied a lot.

The worst performer in terms of RSS violation was AC,
with a number of violations (12.8% of the scenarios) which
tend to be longer (max. 0.8 s) and bigger (max. 82.16%). The
last number is particularly alarming—it means the controller
leaves only a fraction of the necessary safety distance. At the
same time, the bad performance of AC was predicted, too—
it has no safety mechanism that tries to ensure RSS safety
distances.

Both AC+RSSCA and AC+RSSGA come equipped with BC
and DM that implement RSS rules that guarantee RSS safety
distances. We see, indeed, that the RSS violation was zero
or nearly zero for these controllers. We attribute the rare

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

25

TABLE I: Experimental results. In goal, we count the number of instances that reach the goal. In RSS violation, we count the
number of instances where some RSS safety distance is violated, the average and maximal violation times, and by how much
the RSS safety distance was violated. In BC time, we quantify how long BC has been in control on average.

RSS violation

time

jerk

AC
AC+RSSCA
AC+RSSGA

goal (%)
2350 (100%)
2285 (97.2%)
2350 (100%)

collision
0
0
0

num. (%)
300 (12.8%)
0 (0%)
15 (0.6%)

avg. time max time max dist

0.09 s
N/A
0.00 s

0.8 s
N/A
0.3 s

avg.
82.16% 14.97 s
16.23 s
5.16% 14.47 s

N/A

max
27.8 s
26.6 s
20.7 s

avg.
0.45 m/s2
0.36 m/s2
0.80 m/s2

max
2.65 m/s2
0.88 m/s2
4.12 m/s2

BC time
N/A
9.8%
34.6%

(a) AC+RSSCA vs AC+RSSGA.

(b) AC vs AC+RSSGA.

Fig. 16: Comparison for progress. A red disc indicates that AC+RSSCA failed to achieve the goal in this scenario instance.

(a) AC+RSSCA vs AC+RSSGA.

(b) AC vs AC+RSSGA.

Fig. 17: Comparison for comfort. A red disc indicates that AC+RSSCA failed to achieve the goal in this scenario instance.

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

26

RSS violations by AC+RSSGA to the implementation details—
especially to the current “surrogate implementation” of proper
responses (cf. Section VI-B). In any case, the degree of RSS
violation by AC+RSSGA was small (max. 5.16% of the required
distance), the level of error that can be easily caused by other
uncertainties such as sensor inaccuracies. We do not expect
serious safety concerns from these small RSS violations.

To conclude, we observed that AC+RSSGA successfully
ensured safety, by not only avoiding collisions but also re-
specting RSS safety distances (modulo minor exceptions that
we attribute to our surrogate implementation of BC). This is
much like AC+RSSCA and unlike AC.

2) RQ 2: How does the GA-RSS-supervised controller per-
form in terms of accomplishing its goal?: Both AC and
AC+RSSGA managed to achieve the goal 100% of the time,
as expected. AC+RSSCA did not perform as well, and only
achieved the goal in 97.3% of scenario instances. See Sec-
tion VI-E1 for an example scenario instance where AC+RSSCA
does not achieve the goal. In situations where achieving the
objective is of high importance (e.g. exiting a highway) or
cannot be delayed (e.g. an automated emergency stop), this
2.7% difference is signiﬁcant.

To conclude, AC+RSSGA managed to achieve the goal (while
maintaining safety). AC also managed to achieve the goal (but
at the expense of safety), while for AC+RSSCA, safety comes
at the expense of goal achievement.

3) RQ 3: Can the GA-RSS-supervised controller be useful

in practice?: This question can be split into two concerns.

• (The strength of RSS conditions) Are the RSS conditions
weak enough, so that
they are true in many driving
situations? If yes, it means the GA-RSS rule set (Exam-
ple IV.12) is widely applicable.

• (The computation cost) Is the computational time manage-
able? Is it small enough to be computable at each control
loop?

The ﬁrst point is hard to analyze quantitatively. Our rule set
was applicable to only 52% of the total number of scenario
instances—as we discussed in Section VI-C—but this does not
mean that our rule set has overly restrictive RSS conditions.
We expect that the remaining 48% are such that no possible
control can safely achieve the goal there (e.g. ytgt is too close
to stop at). To show that this expectation of ours is indeed
the case, we need to show the behavior of an ideal controller
for each scenario instance, which is hard and is left as future
work.

As a more practical consequence of the above consideration,
we will pursue an automated search-based method for identi-
fying proper responses—using e.g. evolutionary computation
techniques similar to [4]—so that it either 1) shows probable
adequacy of an existing current rule set (in case it does not
ﬁnd a new proper response) or 2) adds a new proper response
to the rule set (in case it does).

In any case, after the compositional derivation described in
Section IV and our manual inspection of experiment results
(which allowed us to identify the notable instances shown in
Section VI-E), we are pretty conﬁdent that the rule set in
Example IV.12 is as extensive and widely applicable as it
can be. Let us nevertheless emphasize that adding a newly

discovered proper response is easy and done modularly (cf.
Figure 11).

For the second point, recall that the GA-RSS rule set is
derived in advance; therefore, the runtime task is merely to
check the truth of RSS conditions (the truth of the precondi-
tions Aw,u to be precise, see Example IV.12). We can expect
that the computational cost for doing so is light.

Indeed,

the typical execution time for one of the more
complicated preconditions on commodity hardware (2.9 GHz
quad-core Intel Core i7) was 19.83 µs, averaged over 106
computations. This means that the computational cost is man-
ageable. It will remain so, even in the future where we have
hundreds or thousands of RSS conditions.

To conclude, the GA-RSS rule set in Example IV.12 can
indeed be used in practice, both from the point of view of
applicability and computation cost.

4) RQ 4: How does the GA-RSS-supervised controller per-
form in terms of other signiﬁcant metrics (progress, comfort,
etc.)?: We measured progress and comfort. Here, we expect
AC to be the best in both these metrics, AC+RSSCA to perform
slightly worse (because it is more constrained by its RSS
conditions), and AC+RSSGA to perform poorer still (because
its RSS conditions are stronger than those of AC+RSSCA).

In terms of progress, AC+RSSCA does not reach the goal
as fast as AC on average (16.23 s and 14.97 s respectively).
However, contrary to expectations, AC+RSSGA performs com-
parably to AC on average (14.47 s), and better than AC+RSSCA.
To compare AC+RSSGA to other controllers, let us look more
closely at Figure 16. We can see that,
instances,
the controllers behave similarly, with the distribution of sce-
nario instances concentrated around the diagonal. There are
however some outliers on the bottom right of the ﬁgures,
where AC+RSSGA performs better than the other controllers.
See Section VI-E2 for an example of such an outlier.

in most

Moreover, when comparing the maximal travel times of the
controllers, AC+RSSGA performed much better (20.7 s) than
both AC and AC+RSSCA (27.8 s and 26.6 s respectively). This
can be explained by the existence of scenario instances in
which AC+RSSGA accelerates to overtake POV1 (because it
knows it is safe to do so), while the other controllers do not.
In emergency situations (e.g. health emergency), this can be a
signiﬁcant time gain.

In terms of comfort, as expected, AC+RSSGA does not
perform as well as AC or AC+RSSCA. On average, it ac-
cumulates 0.80 m/s2 of jerk, against 0.45 m/s2 for AC and
0.36 m/s2 for AC+RSSCA. Maximal accumulated jerk follows
the same pattern. In Figure 17, we give more details about the
comparison of accumulated jerk. We can see that AC+RSSGA
consistently performs worse than both AC and AC+RSSCA
(with nearly all scenario instances above the diagonal), and
sometimes much worse (outliers at the top-left of Figure 17a).
This can be explained by the fact that the GA-RSS rule set
takes control more often, and the proper response can be harsh,
e.g. accelerating quickly to overtake POV1.

To conclude, as expected, AC+RSSGA performs poorly in
terms of comfort. Surprisingly however, it performs compara-
bly to or better than the other controllers in terms of progress.

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

27

1) Preventing Overshoot:

In this scenario, POV1 starts
slightly behind SV. All other cars and the target are rather
close, and all cars travel rather fast. The concrete scenario
instance parameters are as follows:

y1(0) = −5, y2(0) = 75, y3(0) = 85, ytgt = 140,
v(0) = 14, vi(0) = 14.

The observed behaviours are as follows:

• AC: SV merges in front of POV1 when it is unsafe to do
so. It manages to accomplish the goal in 9.8 s, but violates
the RSS safety distance by 82% with respect to POV1,
for 0.8 s. In the video6, we can see that, when changing
lanes, SV crosses over POV1’s red zone.

• AC+RSSCA: The CA-RSS-supervised controller repeat-
edly interrupts AC as it is attempting to merge in front
of POV1, because the distance in front of POV1 is less
than the RSS safety distance. Eventually AC is forced
to abandon merging into lane 2, and this results in SV
failing to accomplish the goal. The RSS minimum safety
distance is never violated. In the video7we see that AC
tries to overtake POV1, but is repeatedly blocked by BC,
which prevents SV from entering the red zone. BC then
immediately returns control to AC to make the same
action again.

• AC+RSSGA: For the GA-RSS-supervised controller, none
of the RSS conditions for any of the rules which merge
in front of POV1 were satisﬁed. This resulted in a proper
response for merging behind POV1 to be engaged. SV
brakes so as to merge behind POV1 and successfully stops
at the target in 14 s without ever violating the RSS safety
distance. In the video8, at ﬁrst our AC+RSSGA exhibits the
same behaviour as AC+RSSCA. However, when SV has no
choice but to brake in order to safely reach the goal, then
BC takes control to slow down and merge behind POV1.

In this scenario, AC accomplishes the goal at the expense of
safety: an RSS safety distance violation of 82% would surely
lead to POV1 engaging in dangerous evasive actions, which
may in turn lead to a loss of control and possibly a collision.
Both AC+RSSCA and AC+RSSGA prevent SV from violating
the RSS safety distances, but in different ways. AC+RSSCA
corrects AC’s behaviour but only takes safety into account,
which leads to failing the goal. AC+RSSGA also corrects AC’s
behaviour by taking the goal into account as well, and therefore
manages to accomplish the goal while maintaining safety.

The accumulated uncomfortable jerk was 1.17 m/s2, more
than double that of AC+RSSCA (0.47 m/s2) or AC (0.50 m/s2).
In conclusion, in this scenario instance, AC+RSSGA was the
only controller to safely achieve the goal: AC achieved the
goal, but violated the RSS safety distance when cutting in front
of POV1, and AC+RSSCA overshot the goal.

2) Bold but Safe: In this scenario, POV1 is in front of SV,
but SV is faster. At ﬁrst glance, this does not seem like a

6https://bit.ly/3r3IvRW
7https://bit.ly/3FqRYIp
8https://bit.ly/3qdCcMl

Fig. 18: A sample screenshot from a notable scenario instance

5) RQ 5: How often is AC in control during execution?: We
expect AC+RSSGA to take control more often than AC+RSSCA,
since its RSS conditions are more strict. And indeed, the GA-
RSS-supervised controller was more intrusive, taking control
for 34.6% of the journey, on average, compared to only 9.8%
for AC+RSSCA.

We would say that

intrusiveness (34.6%)
the level of
by AC+RSSGA is acceptable, especially because the goal it
achieves is an imminent one (such as pull over or taking a
highway ramp). We can also say that the level of intrusiveness
is rather low, which is enabled by the use of GA-RSS rules
in the simplex architecture (Section I-E)—the control is given
back to AC whenever it can.

E. Notable Scenario Instances

To better understand some of the results, we analyse in
detail two notable scenario instances in which the GA-RSS-
supervised controller AC+RSSGA improves upon the behaviour
of AC and AC+RSSCA.

Video animations of these scenario instances are provided on
the web; see Figure 18 for a sample screenshot. We present this
screenshot to explain the videos, and the reader should look at
the videos rather than the screenshot for more information.

In these videos the zones for which dRSS(vf , vr, 0) would
be violated are coloured in red. Similarly, the orange zones
indicate a violation of dRSS(vf , vr, ρ). (Recall that the three-
argument version of dRSS is from Example II.15.) Entering the
red zone is unsafe, as collisions may no longer be avoidable.
When the SV is in an orange zone, it must engage in the CA-
RSS proper response within time ρ, or risk entering the red
zone. SV’s colour reﬂects which controller is presently active:
dark green for AC and light green for BC.

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

28

situation where merging in front of POV1 can be done safely.
The concrete scenario instance parameters are as follows:

enough automation and traceability to be practical. We are also
working on a fully formalized implementation.

y1(0) = 10, y2(0) = 75, y3(0) = 90, ytgt = 160,
v(0) = 14, vi(0) = 10.

The observed behaviours are as follows:

• AC: As can be seen in the video9, SV merged behind
POV1, and successfully stopped at the target area, taking
a total time of 15.9 s. The RSS safety distance is violated
for 0.6 s, by a maximum of 25.6%.

• AC+RSSCA: The behaviour of AC+RSSCA similar to that
of AC, taking a total time of 23.3 s (see the video10),
however the RSS safety distance is not violated.

• AC+RSSGA: SV accelerated so as to overtake POV1
(knowing it is safe to do so), merging in front of it, and
then stopped in the target area. The total time taken was
11.8 s. The RSS safety distance was respected. As can be
seen in the video11, at ﬁrst SV’s path to merging in front
of POV1 seems totally blocked by overlapping red zones.
However, by accelerating (to put itself in a favourable
position between POV1 and POV2) then braking (thus
reducing the sizes of the red zones), it manages to open
a window through which it can merge in front of POV1.
In this case we observe that AC+RSSGA is able to engage in
bold behaviour, overtaking POV1, in a situation where AC and
AC+RSSCA simply merge behind POV1. AC+RSSGA is able to
engage in such bold behaviour to improve progress because a
mathematical proof exists that it will be able to respect safety
distances while also achieving the goal.

The discomfort level was roughly the same for all con-
trollers: 0.88 m/s2 for AC, 0.82 m/s2 for AC+RSSCA, and
0.88 m/s2 for AC+RSSGA.

To conclude, AC+RSSGA performed better than the other
controllers in this scenario instance. Indeed, all three con-
trollers managed to reach the goal, but AC+RSSGA performed
better than both AC and AC+RSSCA in terms of progress.

VII. CONCLUSIONS

In this paper, we proposed a goal-aware extension of
responsibility-sensitive safety (RSS), so that RSS rules ensure
not only collision-avoidance but also achievement of goals such
as pulling over at a desired position.

Derivation of goal-aware RSS rules involves complex plan-
ning that ranges over multiple manoeuvres. Our approach is
to deal with such complex reasoning with program logic,
speciﬁcally a program logic dFHL that we introduce as an
extension of classic Floyd–Hoare logic.

We presented a dFHL-based compositional workﬂow for
deriving goal-aware RSS rules, in which one can systematically
1) split a driving scenario into smaller subscenarios, 2) design
proper responses for those subscenarios, and 3) compute the
preconditions for those proper responses. Our current software
support by Mathematica is only partially formal, yet provides

9https://bit.ly/33qJy6w
10https://bit.ly/3zKCuNR
11https://bit.ly/31Ib7Ye

We conducted experiments in which RSS rules were used
in the simplex architecture. Our comprehensive experiments
showed the value of goal-aware RSS rules in 1) statistics (they
can realize both goal achievement and collision-avoidance)
and 2) notable scenarios (they can realize unexpected bold
behaviours whose safety is nevertheless guaranteed).

REFERENCES

[1] S. Shalev-Shwartz, S. Shammah, and A. Shashua, “On a formal model
of safe and scalable self-driving cars,” CoRR, vol. abs/1708.06374,
2017. [Online]. Available: http://arxiv.org/abs/1708.06374

[2] I. Hasuo, “Responsibility-sensitive safety: an introduction with an eye
to logical foundations and formalization,” CoRR, vol. abs/2206.03418,
2022. [Online]. Available: https://arxiv.org/abs/2206.03418

[3] M. McNaughton, C. Urmson, J. M. Dolan, and J.-W. Lee, “Motion plan-
ning for autonomous driving with a conformal spatiotemporal lattice,” in
Proc. IEEE Int. Conf. Robot. Autom., 2011, pp. 4889–4895.

[4] Y. Luo, X.-Y. Zhang, P. Arcaini, Z. Jin, H. Zhao, F. Ishikawa, R. Wu,
and T. Xie, “Targeting requirements violations of autonomous driving
systems by dynamic evolutionary search,” in The 36th IEEE/ACM Inter-
national Conference on Automated Software Engineering (ASE 2021),
2021, to appear.

[5] E. I. Liu, C. Pek, and M. Althoff, “Provably-Safe Cooperative Driving
via Invariably Safe Sets,” in 2020 IEEE Intelligent Vehicles Symposium,
IV 2020, Las Vegas, United States, October 19-22, 2020.
IEEE, 2020,
p. 8.

[6] C. Pek and M. Althoff, “Efﬁcient computation of invariably safe states
for motion planning of self-driving vehicles,” in 2018 IEEE/RSJ Interna-
tional Conference on Intelligent Robots and Systems (IROS), 2018, pp.
3523–3530.

[8] J. Silberling, P. Wells, A. Acharya,

[7] A. Shashua, S. Shalev-Shwartz, and S. Shammah, “Implementing the
RSS model on NHTSA pre-crash scenarios,” Mobileye, Tech. Rep., 2018.
J. Kelly, and J. Lenkeit,
“Development and application of a collision avoidance capability
metric,” in WCX SAE World Congress Experience. SAE International,
apr 2020. [Online]. Available: https://doi.org/10.4271/2020-01-1207
[9] L. Wang, C. F. Lopez, and C. Stiller, “Realistic Single-Shot and Long-
Term Collision Risk for a Human-Style Safer Driving,” in 2020 IEEE
Intelligent Vehicles Symposium, IV 2020, Las Vegas, United States,
October 19-22, 2020.

IEEE, 2020, p. 8.
[10] N. Altekar, M. Elli, J. Weast, Y. Chen, J. Wishart, S. Como, B. Russo,
and E. James, “Driving safety performance assessment metrics for
ADS-equipped vehicles,” SAE International Journal of Advances and
Current Practices in Mobility, vol. 2, no. 5, pp. 2881–2899, apr 2020.
[Online]. Available: https://doi.org/10.4271/2020-01-1206

[11] H. Zhao, Y. Zhang, P. Meng, H. Shi, E. Li, T. Lou, and J. Zhao, “Safety
score: A quantitative approach to guiding safety-aware autonomous
vehicle computing system design,” in 2020 IEEE Intelligent Vehicles
Symposium, IV 2020, Las Vegas, United States, October 19-22, 2020.
IEEE, 2020.

[12] B. Weng, S. J. Rao, E. Deosthale, S. Schnelle, and F. Barickman, “Model
Predictive Instantaneous Safety Metric for Evaluation of Automated
Driving Systems,” in 2020 IEEE Intelligent Vehicles Symposium, IV
2020, Las Vegas, United States, October 19-22, 2020.
IEEE, 2020,
p. 8.

[13] UL4600: Standard for Evaluation of Autonomous Products, 1st ed.,

Underwriters Laboratories, April 2020.

[14] F. Oboril and K.-U. Scholl, “Risk-Aware Safety Layer for AV Behavior
Planning,” in 2020 IEEE Intelligent Vehicles Symposium, IV 2020, Las
Vegas, United States, October 19-22, 2020.

IEEE, 2020, p. 7.

[15] E. W. Dijkstra, “Guarded commands, nondeterminacy and formal
derivation of programs,” Commun. ACM, vol. 18, no. 8, pp. 453–457,
aug 1975. [Online]. Available: https://doi.org/10.1145/360933.360975

[16] C. A. R. Hoare, “An axiomatic basis for computer programming,”

Communications of the ACM, vol. 12, pp. 576–580, 583, 1969.

[17] F. S. de Boer, U. Hannemann, and W. P. de Roever, “Hoare-style
compositional proof systems for reactive shared variable concurency,”
in Foundations of Software Technology and Theoretical Computer
Science, 17th Conference, Kharagpur, India, December 18-20, 1997,
Proceedings, ser. Lecture Notes in Computer Science, S. Ramesh and
G. Sivakumar, Eds., vol. 1346. Springer, 1997, pp. 267–283. [Online].
Available: https://doi.org/10.1007/BFb0058036

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

29

[18] A. Platzer, Logical Foundations of Cyber-Physical Systems.

Springer

International Publishing, 2018.

[19] T. L. Crenshaw, E. Gunter, C. L. Robinson, L. Sha, and P. R. Kumar, “The
simplex reference model: Limiting fault-propagation due to unreliable
components in cyber-physical system architectures,” in 28th IEEE Inter-
national Real-Time Systems Symposium (RTSS 2007), 2007, pp. 400–412.
[20] D. Seto, B. Krogh, L. Sha, and A. Chutinan, “The simplex architecture
for safe online control system upgrades,” in Proceedings of the 1998
American Control Conference. ACC (IEEE Cat. No.98CH36207), vol. 6,
1998, pp. 3504–3508 vol.6.

[21] R. de Iaco, S. L. Smith, and K. Czarnecki, “Safe swerve maneuvers for
autonomous driving,” in 2020 IEEE Intelligent Vehicles Symposium (IV),
2020, pp. 1941–1948.

[22] B. Gaßmann, F. Oboril, C. B¨urkle, S. Liu, S. Yan, M. S. Elli, I. J.
Alvarez, N. Aerrabotu, S. Jaber, P. van Beek, D. Iyer, and J. Weast,
“Towards standardization of AV safety: C++ library for responsibility
sensitive safety,” in 2019 IEEE Intelligent Vehicles Symposium, IV 2019,
Paris, France, June 9-12, 2019.
IEEE, 2019, pp. 2265–2271. [Online].
Available: https://doi.org/10.1109/IVS.2019.8813885

[23] N. Roohi, R. Kaur, J. Weimer, O. Sokolsky, and I. Lee, “Self-driving
vehicle veriﬁcation towards a benchmark,” CoRR, vol. abs/1806.08810,
2018. [Online]. Available: http://arxiv.org/abs/1806.08810

[24] A. Baheri, S. Nageshrao, I. Kolmanovsky, A. Girard, E. Tseng, and
D. Filev, “Deep Reinforcement Learning with Enhanced Safety for
Autonomous Highway Driving,” in 2020 IEEE Intelligent Vehicles Sym-
posium, IV 2020, Las Vegas, United States, October 19-22, 2020.
IEEE,
2020, p. 6.

[25] A. Rizaldi, F. Immler, B. Sch¨urmann, and M. Althoff, “A formally
for autonomous vehicles,” in Automated
veriﬁed motion planner
Technology for Veriﬁcation and Analysis - 16th International Symposium,
ATVA 2018, Los Angeles, CA, USA, October 7-10, 2018, Proceedings,
ser. Lecture Notes in Computer Science, S. K. Lahiri and C. Wang,
Eds., vol. 11138.
Springer, 2018, pp. 75–90. [Online]. Available:
https://doi.org/10.1007/978-3-030-01090-4 5

[26] T. Nipkow, L. C. Paulson, and M. Wenzel, Isabelle/HOL — A Proof
Assistant for Higher-Order Logic, ser. Lect. Notes Comp. Sci. Springer,
Berlin, 2002, no. 2283.

[27] R. Salay, K. Czarnecki, M. S. Elli, I. J. Alvarez, S. Sedwards, and
J. Weast, “PURSS: towards perceptual uncertainty aware responsibility
sensitive safety with ML,” in Proceedings of the Workshop on Artiﬁcial
Intelligence Safety, co-located with 34th AAAI Conference on Artiﬁcial
Intelligence, SafeAI@AAAI 2020, New York City, NY, USA, February 7,
2020, ser. CEUR Workshop Proceedings, H. Espinoza, J. Hern´andez-
Orallo, X. C. Chen, S. S. ´Oh ´Eigeartaigh, X. Huang, M. Castillo-Effen,
R. Mallah, and J. McDermid, Eds., vol. 2560. CEUR-WS.org, 2020,
pp. 91–95. [Online]. Available: http://ceur-ws.org/Vol-2560/paper34.pdf
[28] T. Kobayashi, R. Salay, I. Hasuo, K. Czarnecki, F. Ishikawa, and
S. Katsumata, “Robustifying controller speciﬁcations of cyber-physical
systems against perceptual uncertainty,” in NASA Formal Methods
- 13th International Symposium, NFM 2021, Virtual Event, May
24-28, 2021, Proceedings, ser. Lecture Notes in Computer Science,
A. Dutle, M. M. Moscato, L. Titolo, C. A. Mu˜noz, and I. Perez,
Eds., vol. 12673.
Springer, 2021, pp. 198–213. [Online]. Available:
https://doi.org/10.1007/978-3-030-76384-8 13

[29] M. Angus, K. Czarnecki, and R. Salay, “Efﬁcacy of pixel-level OOD
detection for semantic segmentation,” CoRR, vol. abs/1911.02897, 2019.
[Online]. Available: http://arxiv.org/abs/1911.02897

[30] J. Chow, V. Richmond, M. Wang, U. Guajardo, D.

Jackson,
N. Arechiga, G. Litt, S. Kong, and S. Campos, “Certiﬁed Control:
A New Safety Architecture for Autonomous Vehicles,” p. 11, 2020,
preprint. [Online]. Available: https://groups.csail.mit.edu/sdg/pubs/2020/
certiﬁed-control.pdf

[31] G. Winskel, The Formal Semantics of Programming Languages.

the

MIT Press, 1993.

[32] M. Huisman and B. Jacobs, “Java program veriﬁcation via a hoare
logic with abrupt termination,” in Fundamental Approaches to Software
Engineering, Third Internationsl Conference, FASE 2000, Held as Part
of
the European Joint Conferences on the Theory and Practice of
Software, ETAPS 2000, Berlin, Germany, March 25 - April 2, 2000,
Proceedings, ser. Lecture Notes in Computer Science, T. S. E. Maibaum,
Ed., vol. 1783.
Springer, 2000, pp. 284–303. [Online]. Available:
https://doi.org/10.1007/3-540-46428-X 20

[33] R. W. Floyd, “Assigning meanings to programs,” in Program Veriﬁcation.

Springer, 1993, pp. 65–81.

[34] H. Khalil, Nonlinear systems. Prentice Hall, 1996.

[35] A. Trautman, “Remarks on the history of the notion of Lie differen-
tiation,” in Variations, Geometry and Physics: In honour of Demeter
Krupka’s sixty-ﬁfth birthday, O. Krupkov´a and D. J. Saunders, Eds.
Nova Science, 2008, pp. 297–302.

[36] C. Schmidt, F. Oechsle, and W. Branz, “Research on trajectory planning
in emergency situations with multiple objects,” in 2006 IEEE Intelligent
Transportation Systems Conference, 2006, pp. 988–992.

[37] H. Ataelmanan, O. C. Puan, and S. A. Hassan, “Examination of
lane changing duration time on expressway,” IOP Conference Series:
Materials Science and Engineering, vol. 1144, no. 1, p. 012078,
may 2021. [Online]. Available: https://doi.org/10.1088/1757-899x/1144/
1/012078

[38] Wolfram Research, Inc., “Mathematica, Version 12.3.1,” Champaign,

IL, 2021. [Online]. Available: https://www.wolfram.com/mathematica

[39] S. Mitsch and A. Platzer, “The keymaera X proof IDE - concepts
on usability in hybrid systems theorem proving,” in Proceedings of
the Third Workshop on Formal Integrated Development Environment,
F-IDE@FM 2016, Limassol, Cyprus, November 8, 2016., ser. EPTCS,
C. Dubois, P. Masci, and D. M´ery, Eds., vol. 240, 2016, pp. 67–81.
[Online]. Available: https://doi.org/10.4204/EPTCS.240.5

[40] K. Czarnecki, “Automated driving system (ADS) high-level quality

requirements analysis—driving behavior comfort,” July 2018.

Ichiro Hasuo is a Professor at National Institute
of Informatics (NII), Tokyo, Japan. He is at
the
same time the Research Director of the JST ERATO
Metamathematics for Systems Design Project, and
the Director of Research Center for Mathematical
Trust in Software and Systems at NII. He received
PhD (cum laude) in Computer Science from Rad-
boud University Nijmegen, the Netherlands, in 2008.
His research interests include mathematical (logical,
algebraic and categorical) structures in software sci-
ence, abstraction and generalization of deductive and
automata-theoretic techniques in formal veriﬁcation; integration of formal
methods and testing; and their application to cyber-physical systems and
systems with statistical machine learning components.

researcher

Clovis Eberhart
in the
is a project
JST ERATO Metamathematics for Systems Design
Project at National Institute of Informatics, Tokyo,
Japan. He is also a member of the Japanese-French
Laboratory for Informatics. He received his PhD in
Mathematics and Computer Science from Universit´e
Savoie Mont Blanc, France, in 2018. His research in-
terests include semantics of programming languages,
logic and category theory in computer science, as
well as their applications to veriﬁcation.

James Haydon is a project technical specialist in the
JST ERATO Metamathematics for Systems Design
Project. He received his PhD in Mathematics from
University of Oxford, United Kingdom, in 2014. His
research interests include semantics of programming
languages, functional programming, logic and cate-
gories in computer science.

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

30

J´er´emy Dubut is a project assistant professor in the
JST ERATO Metamathematics for Systems Design
Project. He is also a member of the Japanese-French
Laboratory for Informatics. He received his PhD in
Mathematics and Computer Science from Universit´e
Paris-Saclay, France, in 2017. His research interests
include category theory, algebraic topology, and for-
malised mathematics.

Erik Andr´e Pallas is a student in the Elite Grad-
uate Program Software Engineering at University
of Augsburg, Technical University of Munich and
LMU Munich, Germany. He is currently writing his
Master’s thesis on deductive veriﬁcation of safety
rules for trafﬁc scenarios in autonomous driving. His
research interests are formal methods for modeling
and veriﬁcation of software systems.

Rose Bohrer is an assistant professor in the Com-
puter Science Department at Worcester Polytechnic
Institute, USA. Their research focuses on formal
methods and programming language foundations for
cyber-physical systems, including interactive theorem
proving for hybrid systems with applications to driv-
ing.

Akihisa Yamada is a senior researcher at National
Institute of Advanced Industrial Science and Tech-
nology, Japan. He received his PhD in Information
Science from Nagoya University in 2014. His re-
search interest includes term rewriting, termination
and complexity analysis, and interactive theorem
proving.

Tsutomu Kobayashi is a researcher at the JST ER-
ATO Metamathematics for Systems Design Project at
National Institute of Informatics, Tokyo, Japan. He
received his PhD from the University of Tokyo in
2017. His research interests include formal modeling
and veriﬁcation of software systems, theorem proving
methods, and software testing.

Kohei Suenaga is an associate professor at the Grad-
uate School of Informatics, Kyoto University. His
research focuses on formal veriﬁcation of software
and hybrid systems and veriﬁcation and testing of/for
machine learning systems.

Sasinee Pruekprasert is a project assistant professor
in the JST ERATO Metamathematics for Systems
Design Project. She received her PhD in Engineering
from Osaka University in 2016. Her research interests
include supervisory control of discrete event systems,
abstraction-based controller design, and decision-
making of autonomous vehicles.

Fuyuki Ishikawa is an associate professor at Infor-
mation Systems Architecture Science Research Di-
vision and the deputy director at GRACE Center, in
National Institute of Informatics, Japan. His research
focuses on dependability of advanced software sys-
tems, including testing and veriﬁcation techniques for
autonomous driving systems and machine learning-
based systems.

Xiao-Yi Zhang is a project assistant professor at the
National Institute of Informatics (NII), Japan. His
main research interests are related to software testing,
software fault localisation, and hazard analysis for
cyber-physical systems.

Kenji Kamijo is an Assistant Manager of the In-
tegrated Control System Development Division at
Mazda Motor Corporation, Hiroshima, Japan. He re-
ceived his BS in Electrical and electronic engineering
in 1991 from the Faculty of Engineering, Tokyo
Institute of Technology, Tokyo, Japan.

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

31

Yoshiyuki Shinya is a Senior Principal Engineer of
Integrated Control System Development Division at
Mazda Motor Corporation, Hiroshima, Japan. He re-
ceived M.E. degree in Electronics Engineering from
the University of Osaka in 1984, and MBA degree
from University of Kobe in 2008. After joining
Mazda in 1984, he has been engaged in research on
engine control systems and computer aided control
system design.

APPENDIX

A. A Formal Proof of the One-Way Trafﬁc Scenario

We want to prove the Hoare triple

{A} α {B} : S

as deﬁned in (4) is valid. Remember that the different dFHL
assertions are deﬁned as

A = (vr ≥ 0 ∧ vf ≥ 0 ∧ yf − yr > dRSS(vf , vr, ρ)) ,
B = (vr = 0 ∧ vf = 0) ,
S = (yr < yf ) ,

and α is deﬁned in Figure 6.

In order

to do this, we need to be able to deﬁne
dRSS(vf , vr, ρ) as a term of our syntax, so we make the
following addition to our setting (see Remark II.4): if e, e(cid:48)
are terms, then max(e, e(cid:48)) is a term, and its partial derivatives
are

∂
∂x

(max(e, e(cid:48))) =






∂e
∂x
∂e(cid:48)
∂x

if e ≥ e(cid:48)

otherwise,

which is also a term. Note that, if f and g are locally Lipschitz
continuous, then so is ˙x = max(f , g) (where max on a list is
deﬁned as the pointwise max).

Since

dRSS(vf , vr, ρ)
Remark
A.1.
to
max(0, dRSS±(vf , vr, ρ))
(see Example II.15), one may
think of replacing yf − yr > dRSS(vf , vr, ρ) with the
equivalent formula

equal

is

yf − yr > 0 ∧ yf − yr > dRSS±(vf , vr, ρ),

as this would spare us the need to add max to our setting.
However, these assertions are not preserved by the dynamics,
so we do need to introduce max into our setting for the proof
to go through.

Because, in this scenario, we do not know in which order
different events happen (e.g. which car stops ﬁrst), we will
need a (DWH) rule that uses several variants. We thus need a
more general (DWH) rule than the one in Figure 7, and use
the one in Figure 19 (see Remark II.13).

The overall proof structure is illustrated in Figure 20, and is
simply repeated application of the (SEQ) rule (as dictated by
the structure of α), composed with (LIMP) rules to strengthen
S to

Sinv = (yf − yr > dRSS(vf , vr, ρ − t)) .

The assertions C, D, D(cid:62), and D⊥ will be deﬁned later in the
corresponding sections.

1) Step 1: Line 1 of Figure 6: We deﬁne C as follows:
(cid:18) vr ≥ 0 ∧ vf ≥ 0 ∧ t = 0 ∧
yf − yr > dRSS(vf , vr)

C =

(cid:19)

.

is

t := 0

t := 0, we

Since α1
of
{A}
{C} : A ∨ C directly by (ASSIGN). We
can then show the validity desired Hoare quadruple by
(LIMP), since A ∨ C (which is equivalent to A) implies S.

show the

validity

can

Takamasa Suetomi is a Senior Principal Engineer of
Integrated Control System Development Division at
Mazda Motor Corporation, Hiroshima, Japan. He re-
ceived M.E. degree in Mechanical Engineering from
the University of Tokyo in 1987. After joining Mazda
in 1987, he has been engaged in research on man-
machine systems, driving simulators, advanced driver
assistant systems and battery electric-drive systems.
He is now responsible for development technology
for vehicle control models.

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

32

inv1 : A ⇒ einv,1 ∼1 0 (cid:86)n

i=1 evar,i ≥ 0 ∧ (cid:86)m

i=1 einv,i ∼i 0 ⇒ L ˙x=f einv,1 (cid:39)1 0

. . .

invm : A ⇒ einv,m ∼m 0 (cid:86)n
(cid:86)n
var1 : A ⇒ evar,1 ≥ 0
(cid:86)n
ter1 : A ⇒ eter,1 < 0

i=1 evar,i ≥ 0 ∧ (cid:86)m
i=1 evar,i ≥ 0 ∧ (cid:86)m
i=1 evar,i ≥ 0 ∧ (cid:86)m

i=1 einv,i ∼i 0 ⇒ L ˙x=f einv,m (cid:39)m 0
i=1 einv,i ∼i 0 ⇒ L ˙x=f evar,1 ≤ eter,1
i=1 einv,i ∼i 0 ⇒ L ˙x=f eter,1 ≤ 0

. . .

varn : A ⇒ evar,n ≥ 0
tern : A ⇒ eter,n < 0

{A} dwhile ((cid:86)n

i=1 evar,i > 0) ˙x = f

(cid:110)(cid:87)n

i=1(evar,i = 0 ∧ (cid:86)

(cid:86)n
(cid:86)n

i=1 evar,i ≥ 0 ∧ (cid:86)m
i=1 evar,i ≥ 0 ∧ (cid:86)m

i=1 einv,i ∼i 0 ⇒ L ˙x=f evar,n ≤ eter,n
i=1 einv,i ∼i 0 ⇒ L ˙x=f eter,n ≤ 0
: (cid:86)m

i=1 einv,j ∼j 0 ∧ (cid:86)n

j(cid:54)=i evar,j ≥ 0)

(cid:111)

(DWH)

i=1 evar,i ≥ 0

Fig. 19: A more general dwhile rule. It accommodates any number of invariants einv,1, . . . , einv,m and variants evar,1, . . . , evar,n.

(Appendix A1)
{A} α1 {C} : S

(Appendix A2)
{C} α2 {D} : Sinv
{C} α2 {D} : S

(LIMP)

{A} α {B} : S as in (4)

(Appendix A3)
{D(cid:62)} α3 {B} : Sinv

(Appendix A4)
{D⊥} α4,7 {B} : Sinv
{D ∧ vf (cid:54)= 0} α4,7 {B} : Sinv

(LIMP)
(IF)

{D} α3,7 {B} : Sinv
{D} α3,7 {B} : S

(LIMP)
(SEQ2)

Fig. 20: Overall proof structure. Here, α denotes the program in Figure 6, αi’s are the program fragments on Line i of Figure 6,
and αi,j’s are the program fragments on Lines i–j of Figure 6. (SEQ2) denotes two applications of the (SEQ) rule. The rest
of the proof is detailed in the corresponding sections.

2) Step 2: Line 2 of Figure 6: This part of the proof is

detailed in Example II.15. We deﬁne D as

D =

(cid:18) ((vf ≥ 0 ∧ t = ρ) ∨ (vf = 0 ∧ t ≤ ρ)) ∧
vr ≥ 0 ∧ yf − yr > dRSS(vf , vr, ρ − t)

(cid:19)

.

(Note that, in Example II.15, α2 is called α(cid:48), C is called A(cid:48),
and D is called B(cid:48).)

The only point that was left implicit in Example II.15 was
the computation of the Lie derivative of einv,2. We compute
the Lie derivative as follows (remember that δ’s are snippets
from (3)):

Note that D(cid:62) is equivalent to D ∧ vf = 0, which is needed
for the (IF) rule in Figure 20 to be applicable. We denote by
3 and α(cid:48)(cid:48)
α(cid:48)

3 the two sub-programs of α3, as in

α3 = (α(cid:48)

3; α(cid:48)(cid:48)

3 ).

To prove the desired Hoare quadruple, we thus use the (SEQ)
and (LIMP) rules as follows:

{D(cid:62)} α(cid:48)

...
3 {E} : Sinv

{E} α(cid:48)(cid:48)
{E} α(cid:48)(cid:48)
{D(cid:62)} α3 {B} : Sinv

...
3 {B(cid:48)} : S(cid:48)
(LIMP)
3 {B} : Sinv (SEQ)

− bmax

∂einv,2
∂vf

+ vr

∂einv,2
∂yr

+ amax

∂einv,2
∂vr

Here, B(cid:48) and S(cid:48) are assertions that will be deﬁned later, and
E is deﬁned as

Lδf ,δ1

r

= vf

einv,2
∂einv,2
∂yf
∂einv,2
∂t

+ 1

= vf − bmax

(cid:26) vf
bmax
0

− vr

+ amax

(cid:26) −(ρ − t) − vr+amax(ρ−t)

bmin

0

+ 1

(cid:26) vr + amax(ρ − t) + amax(vr+amax(ρ−t))

bmin

0

=

(cid:26) 0

vf − vr

if dRSS±(vf , vr, ρ − t) ≥ 0
otherwise.

With Example II.15, this concludes this part of the proof.
3) Step 3: Line 3 of Figure 6: We deﬁne D(cid:62) as

D(cid:62) =

(cid:18) vf = 0 ∧ t ≤ ρ ∧ vr ≥ 0 ∧

yf − yr > dRSS(vf , vr, ρ − t)

(cid:19)

.

E =

(cid:18) vf = 0 ∧ t = ρ ∧ vr ≥ 0 ∧

yf − yr > dRSS(vf , vr, ρ − t)

(cid:19)

.

Both branches of the proof above can be proved by an

application of (DWH) followed by (LIMP).

For α(cid:48)

3, we apply (DWH) with the following invariants,

variants, and terminators:
• einv,1 = (vr ≥ 0),
• einv,2 = (vf = 0),
• einv,3 = (yf − yr − dRSS(vf , vr, ρ − t) > 0),
• evar,1 = ρ − t,

eter,1 = −1.
Again, the only non-obvious point is the einv,3 is preserved by
the dynamics, for which we compute
(cid:26) 0

if dRSS±(vf , vr, ρ − t) ≥ 0
otherwise.

−vr

Lδ1

r

einv,3 =

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

33

We can show that this quantity is always non-negative:

4) Step 4: Lines 4–7 of Figure 6: We deﬁne D⊥ as

dRSS±(vf , vr, ρ − t) < 0

⇐⇒ vr(ρ − t) +

amax(ρ − t)2
2

+

(vr + amax(ρ − t))2
2bmin

−

v2
f
2bmax

< 0

=⇒ vr(ρ − t) +

amax(ρ − t)2
2

+

(vr + amax(ρ − t))2
2bmin

< 0

(i)

(vr + amax(ρ − t))2
2bmin

< 0

(ii)

=⇒ vr(ρ − t) +

=⇒ vr(ρ − t) +

=⇒ vr < 0

D⊥ =

(cid:18) vf ≥ 0 ∧ t = ρ ∧ vr ≥ 0 ∧

yf − yr > dRSS(vf , vr, ρ − t)

(cid:19)

.

Note that D ∧ vf (cid:54)= 0 does imply D⊥, which is necessary to
apply the (LIMP) rule.

We can decompose α4,7 as

α4,7 = (α5; if (vf = 0) α6 else α7) ,

where the αi’s correspond to the program fragments on Line
i of Figure 6.

To prove the desired Hoare quadruple, we use (SEQ) as
follows (where α6,7 denotes the program fragment on Lines
6–7 of Figure 6):

v2
r
2bmin

< 0

(iii)

(iv)

...
{D⊥} α5 {F } : Sinv

...
{F } α6,7 {B} : Sinv

{D⊥} α4,7 {B} : Sinv

(SEQ)

Here, (i) holds because vf = 0 (by einv,2) and bmax0; (ii)
because t ≤ ρ (by evar,1) and amax > 0; (iii) because vr ≥ 0,
t ≤ ρ (by einv,1 and evar,1), amax > 0, and bmin > 0; and (iv)
because vr ≥ 0 (by einv,1) and bmin > 0.

This proves the validity of

{D(cid:62)} α(cid:48)

3 {E} :

(cid:18) vr ≥ 0 ∧ vf = 0 ∧ t ≤ ρ ∧

yf − yr > dRSS(vf , vr, ρ − t)

(cid:19)

.

The proof of validity of {D(cid:62)} α(cid:48)
(LIMP), since the safety condition above implies Sinv.

3 {E} : Sinv follows by

For α(cid:48)(cid:48)

3 , we apply (DWH) with the following invariants,

variants, and terminators:

• einv,1 = (vf = 0),
• einv,2 = (ρ − t = 0),
• einv,3 = (yf − yr − dRSS(vf , vr, ρ − t) > 0),
• evar,1 = vr,

eter,1 = −bmin.

We can compute the Lie derivative for einv,3:

Lδ2

r

einv,3 =

(cid:26) (amax + bmin)ρ if dRSS±(vf , vr, ρ − t) ≥ 0
otherwise.

−vr

The ﬁrst term above is positive because amax, bmin, and ρ all
are. The proof that the second term is non-negative follows the
same pattern as for α(cid:48)
3.

This proves the validity of

{E} α(cid:48)(cid:48)

3 {B(cid:48)} : S(cid:48),

where

B(cid:48) =

S(cid:48) =

(cid:18) vr = 0 ∧ vf = 0 ∧ t = ρ ∧

yf − yr > dRSS(vf , vr, ρ − t)

(cid:18) vr ≥ 0 ∧ vf = 0 ∧ t = ρ ∧

yf − yr > dRSS(vf , vr, ρ − t)

(cid:19)

(cid:19)

,

.

(32)

The proof of validity of {E} α(cid:48)(cid:48)
3 {B} : Sinv follows by
(LIMP), since B(cid:48) implies B and S(cid:48) implies Sinv. This con-
cludes the proof of validity of {D(cid:62)} α3 {B} : Sinv.

Here, F is deﬁned as

F =

(cid:18) ((vf = 0 ∧ vr ≥ 0) ∨ (vf ≥ 0 ∧ vr = 0)) ∧
t = ρ ∧ yf − yr > dRSS(vf , vr, ρ − t)

(cid:19)

.

For α5, we use the (DWH) rule with the following invari-

ants, variants, and terminators:
• einv,1 = (ρ − t = 0),
• einv,2 = (yf − yr − dRSS(vf , vr, ρ − t) > 0),
eter,1 = bmax,
• evar,1 = vf ,
eter,2 = bmin.
• evar,2 = vr,
Once again, we compute the Lie derivative for einv,2:

Lδf ,δ2

r

einv,3 =

(cid:26) (amax + bmin)ρ if dRSS±(vf , vr, ρ − t) ≥ 0
otherwise.

vf − vr

The top term above is positive because amax, bmin, and ρ are,
and the proof that the bottom one is non-negative is the same
as in Example II.15. This proves the validity of

{D⊥} α5 {F } :

(cid:18) vr ≥ 0 ∧ vf ≥ 0 ∧ t = ρ ∧

yf − yr > dRSS(vf , vr, ρ − t)

(cid:19)

.

The validity of {D⊥} α5 {F } : Sinv follows directly by
(LIMP), since the safety condition above implies Sinv.

Since α6,7 is an if construct, the proof structure is as follows:

...
{F(cid:62)} α6 {B} : Sinv

...
{F⊥} α7 {B(cid:48)} : S(cid:48)
{F ∧ vf (cid:54)= 0} α7 {B} : Sinv

{F } α6,7 {B} : Sinv

Here, F(cid:62) and F⊥ are deﬁned as follows:

(LIMP)
(IF)

F(cid:62) =

F⊥ =

(cid:18) vf = 0 ∧ vr ≥ 0 ∧ t = ρ ∧

yf − yr > dRSS(vf , vr, ρ − t)

(cid:18) vf ≥ 0 ∧ vr = 0 ∧ t = ρ ∧

yf − yr > dRSS(vf , vr, ρ − t)

(cid:19)

(cid:19)

,

,

and B(cid:48) and S(cid:48) were deﬁned in (32).

Note that F(cid:62) is equivalent to F ∧ vf = 0, which allows
application of (IF). Similarly, F ∧ vf (cid:54)= 0 implies F⊥, B(cid:48)
implies B, and S(cid:48)
implies Sinv, which allows us to apply
(LIMP).

ACCEPTED FOR PUBLICATION IN IEEE TRANSACTIONS ON INTELLIGENT VEHICLES

34

For α6, we use (DWH) with the following invariants,

variants, and terminators:
• einv,1 = (ρ − t = 0),
• einv,2 = (vf = 0),
• einv,3 = (yf − yr − dRSS(vf , vr, ρ − t) > 0),
• evar,1 = vr,

eter,1 = −bmin.

If we compute the Lie derivative of einv,3, we get

Lδ1

r

einv,3 =

(cid:26) 0

−vr

if dRSS±(vf , vr, ρ − t) ≥ 0
otherwise,

and the proof that this is non-negative follows the same pattern
as that in Appendix A3. This proves that

{F(cid:62)} α6 {B} :

(cid:18) vr ≥ 0 ∧ vf = 0 ∧ t = ρ ∧

(cid:19)

yf − yr > dRSS(vf , vr, ρ − t)

is valid. By (LIMP), we get that {F(cid:62)} α6 {B} : Sinv, since
the safety condition above implies Sinv.

For α7, we use the (DWH) rule with the following invari-

ants, variants, and terminators:

• einv,1 = (vr = 0),
• einv,2 = (ρ − t = 0),
• einv,3 = (yf − yr − dRSS(vf , vr, ρ − t) > 0),
• evar,1 = vf ,

eter,1 = −bmax.

Again, let us compute the Lie derivative of einv,3:

Lδf

einv,3 =

(cid:26) 0
vf

if dRSS±(vf , vr, ρ − t) ≥ 0
otherwise.

The term above is non-negative by evar,1, which proves the
validity of

{F(cid:62)} α6 {B(cid:48)} : S(cid:48),

where B(cid:48) and S(cid:48) were deﬁned in (32). This concludes the
proof of validity of {D⊥} α4,7 {B} : Sinv, and ﬁnally that of
{A} α {B} : S.

