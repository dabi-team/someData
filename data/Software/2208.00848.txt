2
2
0
2

g
u
A
1

]

G
L
.
s
c
[

1
v
8
4
8
0
0
.
8
0
2
2
:
v
i
X
r
a

DeFL: Decentralized Weight Aggregation for
Cross-silo Federated Learning

Jialiang Han
Key Lab of High-Conﬁdence Software Technology, MoE (Peking University), Beijing
hanjialiang@pku.edu.cn

Yudong Han
Key Lab of High-Conﬁdence Software Technology, MoE (Peking University), Beijing
hanyd@pku.edu.cn

Gang Huang
Key Lab of High-Conﬁdence Software Technology, MoE (Peking University), Beijing
hg@pku.edu.cn

Yun Ma
Institute for Artiﬁcial Intelligence, Peking University, Beijing
mayun@pku.edu.cn

Abstract

Federated learning (FL) is an emerging promising paradigm of privacy-preserving
machine learning (ML). An important type of FL is cross-silo FL, which enables
a small scale of organizations to cooperatively train a shared model by keeping
conﬁdential data locally and aggregating weights on a central parameter server.
However, the central server may be vulnerable to malicious attacks or software
failures in practice. To address this issue, in this paper, we propose DeFL, a novel
decentralized weight aggregation framework for cross-silo FL. DeFL eliminates the
central server by aggregating weights on each participating node and weights of
only the current training round are maintained and synchronized among all nodes.
We use Multi-Krum to enable aggregating correct weights from honest nodes and
use HotStuff to ensure the consistency of the training round number and weights
among all nodes. Besides, we theoretically analyze the Byzantine fault tolerance,
convergence, and complexity of DeFL. We conduct extensive experiments over
two widely-adopted public datasets, i.e. CIFAR-10 and Sentiment140, to evaluate
the performance of DeFL. Results show that DeFL defends against common threat
models with minimal accuracy loss, and achieves up to 100x reduction in storage
overhead and up to 12x reduction in network overhead, compared to state-of-the-art
decentralized FL approaches.

1

Introduction

In many real-world scenarios, such as e-commerce, medical diagnosis, and Internet of Things (IoT),
data are distributed among devices or organizations and the volume of local data is insufﬁcient to
train reliable models without over-ﬁtting. To address this limitation, it is a common practice to feed
local data into a centralized server and train a global model. Undoubtedly, it raises concerns about
data ownership, privacy, security, and monopolies. Recently, emerging federated learning (FL) [35]

Preprint. Under review.

 
 
 
 
 
 
mitigates some of these concerns by training a global model without gathering conﬁdential data
from each participating node [41]. Cross-silo FL [53, 34] is an important type of FL where 2-100
organizations collectively aggregate weights on a central parameter server, which is assumed to be
trusted and reliable among organizations. However, this assumption may not hold in practice. For
example, the central server could be malicious, leading to poisoning the model [15, 1, 48, 49], or
skewing the model by favoring particular clients [33, 52]. Besides, fatal crashes in central servers
could lead to an accuracy drop, convergence time increase, or even training procedure abortion.

To address the preceding problems raised by the central parameter server of FL, some decentralized
FL solutions are proposed by eliminating the central server. These solutions can be categorized
into two directions. One direction is to dynamically elect a leader, where weights are aggregated
and transmitted to other nodes [47, 46, 30, 28]. The leader takes the place of the central server of
FL. However, if the dynamically elected leader is detected (probably through overmuch network
bandwidth [16]) and then attacked, or if the leader behaves maliciously, the risks of model poisoning
and skewing still exist. The other direction is to leverage a blockchain to maintain weights and
coordinate the weight aggregation [40, 13, 30, 39, 28, 2, 38, 32, 44, 19]. However, most of them
are implemented based on a third-party blockchain platform, such as Ethereum or FISCO, therefore
suffering from unnecessary storage and network overhead. The reason is that they maintain the
consistency of all history weights due to underlying consensus mechanisms. However, FL requires
weights of only the current training round for updating and does not require updates in one round to
be recorded in a particular sequence.

To this end, in this paper, we propose DeFL, a novel decentralized weight aggregation framework for
cross-silo FL. The key idea of DeFL is in two folds. First, the local updates of all nodes are aggregated
on each node so that the reliability concern of a leader or central server can be mitigated. Second,
weights of only the current training round are maintained and synchronized so that the storage and
network overhead can be signiﬁcantly reduced. Realizing such an idea faces two challenges. First,
the weights aggregated on or updated (local trained) by faulty or adversarial nodes are not reliable.
Second, synchronizing weights of only the current round brings in inconsistency in the round number
round _id . For example, at some speciﬁc point in the training procedure, round _id A on client A
with sufﬁcient computation and network resources could be larger than round _id B on client B with
insufﬁcient resources. As a result, aggregating weights of round _id A and round _id B is inconsistent
with FedAvg [35] in the standard FL setting, leading to accuracy drop or convergence time increase.
To tackle these challenges, we abstract each participating node as two roles, i.e. a client and a replica,
as shown in Figure 1. A client enables aggregating correct weights from honest nodes with a weight
ﬁlter based on Multi-Krum [4]. A replica ensures the consistency of round _id and weights of the
current and last rounds with a synchronizer based on HotStuff [51].

Figure 1: The architecture of DeFL

To evaluate the performance of DeFL, we conduct extensive experiments over two widely-adopted
public datasets, i.e. CIFAR-10 and Sentiment140. We comprehensively measure Byzantine fault
tolerance and scalability on the accuracy, computational overhead, storage overhead, and network
overhead. The results show that DeFL defends against common threat models with minimal accuracy
loss, and achieves up to 100x reduction in storage overhead and up to 12x reduction in network
overhead, compared to state-of-the-art decentralized FL baselines. We will make the source code of

2

ConsensusReplicaMemory PoolNodeNodeNodeNodeNodeClientSend last round weightsCommit current round weightsVote for new roundthis paper publicly available online when this paper is accepted. Our contributions of this paper can
be summarized as follows.

• We propose a novel decentralized weight aggregation framework for cross-silo FL (DeFL),
where weights are aggregated on each node and weights of only the current training round
are maintained and synchronized.

• We design a weight ﬁlter based on Multi-Krum to enable aggregating correct weights and
design a synchronizer based on HotStuff to ensure consistency of round _id and weights.

• We theoretically analyze the Byzantine fault tolerance, convergence, and overhead of DeFL.

• We use public datasets to measure the performance of DeFL and demonstrate its superior to

state-of-the-art baselines.

2 Related Work

In this section, we introduce related work about federated learning (FL) and decentralized FL.

Federated Learning. To allow users to collectively reap the beneﬁts of shared models trained from
rich data without transmitting raw data, McMahan et al. propose FL [35]. To improve communication
efﬁciency, Koneˇcn`y et al. [24] propose structured update and sketched update. Bonawitz et al. [5]
introduce the protocol of FL, detailed system design on devices and servers, and some speciﬁc
challenges of implementation. Yang et al. [50] categorize FL into Horizontal FL, Vertical FL, and
Federated Transfer Learning. In FL settings, the central parameter server aggregates updates from
devices with weights proportional to the size of local datasets, i.e. FedAvg [35]. Therefore, the
stability, fairness, and security of the central server are crucial to FL.

Decentralized Federated Learning. To mitigate security and fault tolerance concerns of FL, decen-
tralized FL [26, 25] is proposed, where users update their beliefs by aggregating information from
their one-hop neighbors. The following literature focuses on aggregating weights of all active nodes
and is categorized into two directions.

One direction is to dynamically elect a leader, where weights are aggregated and transmitted to other
clients. For example, Swarm Learning (SL) [47, 46] combines decentralized hardware infrastructures,
and distributed machine learning (ML) with a permissioned blockchain to securely onboard members,
dynamically elect the leader, and merge model parameters. BLADE-FL [28] allows each client to
broadcast the trained model to other clients, aggregate its model with received ones, and then compete
to generate a block before local training of the next round. In this direction, the network bandwidth
of leaders tends to be signiﬁcantly higher than other nodes [16] and easy to detect. If the leader is
attacked or behaves maliciously, these approaches become invalid.

The other direction is to leverage a blockchain to maintain weights and coordinate the model
aggregation. For example, Biscotti [40] uses blockchain and cryptographic primitives to coordinate a
privacy-preserving ML process. BAFFLE [39] uses Smart Contracts (SC) to coordinate the round
delineation, model aggregation, and update tasks in FL. BFLC [30] uses blockchain for global model
storage and local model update exchange and devises an innovative committee consensus mechanism
to reduce consensus computing and malicious attacks. BFL [38] designs a novel reward and develops
a mathematical framework that features the controllable network and parameters for privacy-aware
and efﬁcient on-vehicle FL. Lu et al. [32] integrate blockchain for maintaining parameters and
use reinforcement learning (RL) to solve the resource sharing task. However, most of them are
implemented based on a third-party blockchain platform, therefore suffering from unnecessary
storage and network overhead.

3 Methodology

In this section, we describe the threat models, weight ﬁltering and aggregation on a client, round _id
and weight synchronization among replicas, and the decoupling-storage-and-consensus design of
DeFL.

3

3.1 Threat Model

Following existing Byzantine fault tolerant (BFT) FL approaches [40, 8, 45, 37], we assume the
number of participating nodes is n > 3f , where f denotes the number of Byzantine nodes while other
nodes are honest. In cross-silo FL, where device heterogeneity is relatively low, we assume partially
synchronous communication [11], whereby all honest nodes complete a local training round before
a global stabilization time of local training (GST_LT). f Byzantine nodes are faulty or adversarial.
Faulty nodes may not always commit transactions promptly. Adversarial nodes can perform three
representative poisoning weight attacks, i.e., Gaussian attack [12], sign-ﬂipping attack [29] and
label-ﬂipping attack [3]. Adversarial nodes can also commit update transactions with weights of the
wrong round or commit aggregation transactions before GST_LT. Because one node plays the role
of both a client and a replica, malicious behaviors are not assumed to exist between the client and
replica of the same node.

3.2 Weight Filter

A client enables aggregating correct weights with a weight ﬁlter based on Multi-Krum [4]. The
main idea of Krum is that when data are independent and identically distributed (i.i.d.), the gradient
updates from honest clients tend to be close to the correct gradient, while those from the Byzantine
clients tend to be arbitrary and are supposed to be omitted for aggregation. Speciﬁcally, Krum selects
the gradient that minimizes the sum of squared distances to its n − f closest gradients. Multi-Krum
interpolates between Krum and FedAvg, thereby allowing to mix the BFT properties of Krum with
the convergence speed of FedAvg. Speciﬁcally, Multi-Krum applies FedAvg on top k gradients that
minimizes the sum of squared distances to its n − f closest gradients.

Algorithm 1 Local training and weight aggregation on a client

1

1: if l _round _id ≤ r _round _id then
start_time ← clock ()
2:
weight agg ← Multi-Krum(W LAST
, . . . , W LAST
3:
weight new ← local_train(weight agg , l _data)
4:
resp ← commit TX("UPD", id , r _round _id + 1, weight new )
5:
if resp = OK then
6:
7:
8:
9:
10:

end _time ← clock ()
sleep(max (0, GST_LT − (end _time − start_time)))
commit TX("AGG", l _round _id )

l _round _id ← r _round _id + 1

)

n

Algorithm 1 describes how a client executes writing operations to local data structures that do not
require synchronization, i.e. local round number and local weights. When the local training round
l _round _id falls behind the global (replica) training round r _round _id , the client is supposed to
update local round _id and local weights through local training. Within GST_LT, the client ﬁlters
and aggregates weights of other clients of the last round in Line 3, trains aggregated weights with
local data in Line 4, and commits an UPD transaction (TX) to replicas in Line 5. Then, the client waits
until GST_LT and commits an AGG transaction to replicas in Line 9-10.

3.3 Synchronizer

A replica ensures the consistency of round _id and weights of the current and last round with a
synchronizer based on HotStuff [51]. HotStuff [51] is proposed to address scaling challenge in
Practical Byzantine Fault Tolerance (PBFT) [7]. Under the partially synchronous communication
model [11], whereby a known bound ∆ on message transmission holds after some unknown global
stabilization time (GST), and n ≥ 3f +1, HotStuff is a leader-based BFT State Machine Replication
(SMR) protocol which achieves linear view change and optimistic responsiveness by adding a
PRE-COMMIT phase to each view in PBFT. Its overall communication complexity per view is O(n),
which enables large-scale deployment on FL devices.

Algorithm 2 describes how a replica executes writing operations to global data structures that
require synchronization, i.e. round _id and weights of the current and last rounds. When executing

4

Algorithm 2 Synchronization among replicas

else

id ← weight

W CUR
respond OK

if target_round _id = r _round _id + 1 then

if target_round _id = r _round _id + 1 then

1: on execution of TX("UPD", id , target_round _id , weight)
2:
3:
4:
5:
respond AlreadyUPDError
6:
7: on execution of TX("AGG", target_round _id )
8:
9:
10:
11:
12:
13:
14:
15:

r _round _id ← target_round _id
votes ← 0
for i ← 1 to n do
W LAST
i
i ← ∅
W CUR
respond OK

votes ← votes + 1
if votes meets a quorum then

← W CUR
i

16:
17:
18:
19:
20:

else

respond NotMeetQuorumWarning

else

respond AlreadyAGGError

transactions, the replica is supposed to verify that the committed round _id is consistent with the
current global training round, in Line 2 and Line 8. When executing the UPD transaction, the replica
synchronizes the weights of the current round of the corresponding client in Line 3. When executing
the AGG transaction, the replica waits until the number of received AGG transactions meets a quorum,
i.e. f + 1, in Line 8-10. Then, the replica updates and synchronizes round _id and the weights of the
current and last rounds in Line 11-16.

3.4 Decoupling Storage and Consensus

We construct DeFL in two layers: a communication layer and a storage layer. In the communication
layer, processes reliably broadcast their proposals and reach consensus, following the schedule of
HotStuff. In the storage layer, weights are stored in a trusted memory pool and can be retrieved by
a unique index, which does not require any extra communication.

4 Analysis

In this section, we analyze Byzantine fault tolerance, convergence, and overhead of DeFL.

4.1 Byzantine Fault Tolerance

Lemma 1. In HotStuff, when n ≥ 3f + 1, if t1 and t2 are conﬂicting transactions, then they cannot
be both committed, each by an honest replica.

This lemma is proven in HotStuff [51]. It means that all honest nodes receive transactions with the
same content and in the same sequence. Therefore, each honest node receives the same weights in
each round and behaves identically the same when aggregating weights. Therefore, we can treat each
honest node as a parameter server and consider one honest node to represent all.

Lemma 2. In Krum, let V1, ..., Vn be any independent and identically distributed (i.i.d.) random
d-dimensional vectors s.t. Vi ∼ G, with EG = g and E(cid:107)G − g(cid:107)2 = dσ2. Let B1, ..., Bf be any f
random vectors, possibly dependent on the Vi’s. If n > 2f + 2 and η(n, f )

d · σ < (cid:107)g(cid:107), where

√

η(n, f ) def=

(cid:18)

(cid:115)
2

n − f +

f · (n − f − 2) + f 2 · (n − f − 1)
n − 2f − 2

(cid:19)

=

(cid:26)O(n),
√
O(

n),

f = O(n)
f = O(1)

,

(1)

5

then the Krum function KR is (α, f )-Byzantine fault tolerant where 0 ≤ α < π/2 is deﬁned by

sin α =

√

η(n, f ) ·
(cid:107)g(cid:107)

d · σ

.

(2)

The deﬁnition of (α, f )-Byzantine fault tolerance and the proof of this lemma is in Multi-Krum [4].

√

d · σ < (cid:107)g(cid:107), there exists α such that DeFL is

Theorem 1. In DeFL, when n ≥ 3f + 3 and η(n, f )
(α, f )-Byzantine fault tolerant.

Proof. Let fH ≤ f be faulty nodes that fail to update weights before GST_LT, fK ≤ f be adversarial
nodes that update poisoned weights before GST_LT, where fH +fK = f . Obviously, active nodes nK
participating in weight synchronization satisfy 2f + 3 ≤ nK ≤ n. According to Equation 1, η(n, f )
monotonically increases with n, therefore, η(nK, fK)
d · σ ≤ (cid:107)g(cid:107). Therefore,
there exists α0 such that

d · σ ≤ η(n, f )

√

√

√

sin α0 =

η(nK, fK) ·
(cid:107)g(cid:107)

d · σ

≤ 1,

(3)

and the Krum function KR is (α0, fK)-BFT. Let fK = f , then DeFL is (α0, f )-BFT.

4.2 Convergence

Following HotStuff [51], we analyze the convergence of the Stochastic Gradient Descent (SGD)
using DeFL. The SGD optimization is formulated as wt+1 = wt − γt · KR(V t
n),. For an honest
node i, V t
i is a mini-batch of samples. The
local standard deviation σ(w) is deﬁned as d · σ2(w) = E(cid:107)G(w, ξ) − ∇Q(w)(cid:107)2, where Q(w) is the
loss function.

i ) where G is the gradient estimator and ξt

i = G(wt, ξt

1 , ..., V t

Lemma 3. In HotStuff, after GST, there exists a bounded time period Tf such that if all honest
nodes remain in view v during Tf and the leader for view v is honest, then a decision is reached.

This lemma is proven in HotStuff [51]. It means that synchronization among replicas would only
take a bounded time period and have bounded inﬂuence on convergence.

Lemma 4. In Krum, we assume that (i) the loss function Q is three times differentiable with continuous
derivatives, and is non-negative; (ii) the learning rates satisfy (cid:80)
t < ∞;
(iii) the gradient estimator satisﬁes EG(w, ξ) = ∇Q(w) and ∀r ∈ {2, ..., 4}, E(cid:107)G(w, ξ)(cid:107)r ≤
Ar + Br(cid:107)w(cid:107)r for some constants Ar, Br; (iv) there exists a constant 0 ≤ α < π/2 such that for all
d · σ(w) ≤ (cid:107)∇Q(w)(cid:107) · sin α; (v) beyond a certain horizon, (cid:107)w(cid:107)2 ≥ D, there exist
w, η(n, f ) ·
(cid:15) > 0 and 0 ≤ β < π/2 − α such that (cid:107)∇Q(w)(cid:107) ≥ (cid:15) > 0 and (cid:104)w,∇Q(w)(cid:105)
(cid:107)w(cid:107)·(cid:107)∇Q(w)(cid:107) ≥ cos β. Then the
sequence of gradients ∇Q(wt) converges almost surely to zero.

t γt = ∞ and (cid:80)

t γ2

√

This lemma is proven in Multi-Krum [4].

Theorem 2. In DeFL, when n ≥ 3f + 3, under the ﬁve assumptions of Lemma 4, the sequence of
gradients ∇Q(wt) converges almost surely to zero.

Proof. Note that DeFL inﬂuences only Assumption (iv) in Lemma 4 by changing the constraint that
n ≥ 3f + 3, fH + fK = f, and 2f + 3 ≤ nK ≤ n. Due to Assumption (iv) in Theorem 2, there exists
d · σ(w) ≤ (cid:107)∇Q(w)(cid:107) · sin α. Due to the
a constant 0 ≤ α < π/2 such that for all w, η(n, f ) ·
monotonicity of η(n, f ), η(nK, fK) ·
d · σ(w) ≤ (cid:107)∇Q(w)(cid:107) · sin α, which
d · σ(w) ≤ η(n, f ) ·
satisﬁes Assumption (iv) in Lemma 4. According to Lemma 4, ∇Q(wt) converges almost surely to
zero in DeFL.

√

√

√

The Byzantine fault tolerance and convergence analysis of DeFL on Multi-Krum is similar to that on
Krum, therefore, we omit it in Section 4.1 and Section 4.2 due to the page limit. Note that we have
not provided theoretical analysis when the data are non-i.i.d., however, we empirically evaluate this
scenario on public datasets in Section 5.

4.3 Overhead

Network bandwidth. The communication complexity per view is O(n) in HotStuff [51]. In a
training round, an honest node would commit an UPD transaction and an AGG transaction. As the size

6

of weights M is much larger than that of id or round _id , we only consider M here. Therefore, it
takes O(M n) network bandwidth to synchronize weights of the current round on an honest node. As
there are O(n) honest nodes, the overall network bandwidth of T training rounds is O(M T n2).

Storage. Thanks to the decoupling-storage-and-consensus design, DeFL maintains and caches
weights of only some constant τ ≥ 2 training rounds from n nodes, instead of maintaining the
consistency of all history weights. Therefore, the overall storage complexity is M τ n, regardless of
the number of training rounds.

Summary: When n ≥ 3f + 3, and the data are i.i.d., DeFL is BFT and reaches convergence in a
bounded time period. The network bandwidth of T training rounds is O(M T n2) and the storage
complexity is M τ n, where M is the size of weights and DeFL caches τ training rounds in storage.

5 Evaluation

In this section, we introduce the experimental setup and measure the fault tolerance and scalability of
DeFL.

5.1 Experiement Setup

Datasets. We use CIFAR-10 1 for image classiﬁcation under MIT License. It consists of 60,000
32x32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images
and 10,000 test images. We use Sentiment140 2 for sentiment analysis. The license of Sentiment140
allows academic use without commercial purposes. Because the size of its ofﬁcial testing set (498) is
much smaller than its ofﬁcial training set (1,600,000), the test accuracy would be unstable, especially
when this dataset is separated into many nodes. Therefore, we manually remove the labels of 160,000
(10%) samples in the ofﬁcial training set and treat them as the new testing set. Therefore, there are
1,440,000 training sentences and 160,000 testing sentences. The number of positive reviews and
negative ones are identical. For CIFAR-10 and Sentiment140, we follow related work [21, 31, 54] to
model non-i.i.d. data using a Dirichlet distribution Dir(α), in which a smaller α indicates higher data
heterogeneity. We choose α = 1 to create CIFAR-noniid and Sentiment-noniid datasets. Both datasets
do not contain personally identiﬁable information or offensive content. Note that the experimental
results of Sentiment140 and Sentiment-noniid are similar to those of CIFAR-10 and CIFAR-noniid
and are present in Section A due to the page limit.

Models. For CIFAR-10 and CIFAR-noniid, we use Dense Convolutional Network (DenseNet). The
depth of DenseNet is 100 and the growth rate is 12. The batch size is 32. The learning rate is 1e-3.
For Sentiment140 and Sentiment-noniid, we use attention-based Bidirectional Long Short-Term
Memory (Bi-LSTM). The length, iteration number, and window size of Word2Vec embeddings are
300, 32, and 7, respectively. The number of Bi-LSTM units is 128. The batch size is 1,024. The
dropout rate of the fully connected layer and the attention layer is 0.15.

Environments. We deploy DeFL and baselines on 4-10 instances, each equipped with an NVIDIA
Tesla K80 GPU with 12GB memory, 3 Xeon E5-2678 v3 CPUs, and 8GB RAM. Each setting is
repeated 10 times to take the average as reported results.

Baselines. We carefully choose 3 aforementioned open-source representative baselines to compare
with DeFL, i.e. FL [35], Swarm Learning (SL) [47], and Biscotti [40]. FL has no defense against
poisoning attacks. SL uses a blockchain to elect a leader. Biscotti defends against poisoning
attacks via Multi-Krum [4] and uses a blockchain to store and maintain the consistency of weights.

5.2 Fault Tolerance

As mentioned in Section 3.1, we measure 3 types of poisoning attacks with different attack factors
on 1 of 4 nodes. As shown in Table 1, FedAvg-based approaches (FL, SL) share similar accuracy
while Multi-Krum-based approaches (Biscotti, DeFL) share similar accuracy. When there is no or
a mild attack, i.e. Gaussian attack (σ=0.03) and label-ﬂipping attack, the accuracy of FedAvg-based

1https://www.cs.toronto.edu/∼kriz/cifar.html
2http://help.sentiment140.com/for-students

7

Table 1: Accuracy on different threat models

Attack

FL

SL

Biscotti DeFL

FL

CIFAR-10

CIFAR-noniid
SL

Biscotti DeFL

No
Gaussian (σ=0.03)
Gaussian (σ=1.00)
Sign-ﬂipping (σ=-1.0)
Sign-ﬂipping (σ=-2.0)
Sign-ﬂipping (σ=-4.0)
Label-ﬂipping

0.924
0.905
0.184
0.837
0.453
0.126
0.894

0.926
0.904
0.197
0.843
0.456
0.136
0.893

0.891
0.887
0.899
0.880
0.890
0.896
0.889

0.899
0.888
0.894
0.885
0.893
0.893
0.890

0.922
0.922
0.345
0.799
0.423
0.164
0.890

0.925
0.924
0.338
0.803
0.421
0.175
0.884

0.840
0.891
0.872
0.888
0.878
0.866
0.872

0.836
0.893
0.876
0.883
0.881
0.873
0.876

approaches is slightly higher than that of Multi-Krum-based ones. The reason is that Multi-Krum
ﬁlters outlier weights that might be trained by honest nodes and are supposed to be aggregated. This
is also why the accuracy of Multi-Krum-based approaches on CIFAR-noniid is lower than that of
CIFAR-10. However, when there is a relatively severe attack, the accuracy of Multi-Krum-based
approaches is signiﬁcantly higher than that of FedAvg-based ones. This indicates that Multi-Krum
effectively detects poisoned weights and aggregates with correct weights from honest nodes.

Table 2: Accuracy on CIFAR-noniid with sign-ﬂipping attack (σ=-2.0)

Attack

FL

SL

Biscotti DeFL

4+0 (β=0.00)
3+1 (β=0.25)
7+0 (β=0.00)
6+1 (β=0.14)
5+2 (β=0.29)
10+0 (β=0.00)
9+1 (β=0.10)
8+2 (β=0.20)
7+3 (β=0.30)

0.922
0.423
0.891
0.717
0.380
0.883
0.775
0.631
0.358

0.925
0.421
0.890
0.722
0.369
0.881
0.779
0.634
0.353

0.840
0.878
0.823
0.851
0.865
0.832
0.845
0.850
0.874

0.836
0.881
0.825
0.850
0.874
0.826
0.842
0.855
0.878

We choose sign-ﬂipping attack (σ=-2.0) on CIFAR-noniid to measure the accuracy under different
Byzantine rates β, as shown in Table 2. We scale DeFL on 4, 7, 10 nodes, and "a+b" means there
are a honest nodes and b Byzantine node(s). As β raises, the accuracy of FedAvg-based approaches
drops dramatically, while the accuracy of Multi-Krum-based ones remains stable and signiﬁcantly
higher.

Summary: Under most attacks, the accuracy of DeFL and Biscotti is signiﬁcantly higher than that
of FL and SL, no matter the Byzantine rate. However, when there is no or a mild attack, the accuracy
of DeFL and Biscotti is slightly lower than that of FL or SL.

5.3 Scalability

We scale DeFL and baselines to 4, 7, 10 nodes and measure computation, storage, and network
overhead. As shown in Figure 2, as the number of nodes increases, the RAM usage of DeFL and other
baselines increases linearly. The RAM usage of DeFL is close to that of Biscotti and FL, and lower
than that of SL. The GPU memory usage of DeFL and other baselines is always identical. In terms
of storage overhead, we measure the storage usage of only the blockchain for fairness. The storage
of DeFL is close to that of FL and SL (nearly 0 GB), and signiﬁcantly lower than that of Biscotti,
thanks to the decoupling-storage-and-consensus design. In terms of network overhead, we change
the y-axis into a logarithmic axis for clear presentation. The receiving bandwidth of SL and FL is
linear to the number of nodes, while that of DeFL and Biscotti is quadratic to the number of nodes.
Besides, the receiving bandwidth of DeFL is much lower than that of Biscotti, though higher than
that of FL and SL. Thanks to the shared memory pool, the sending bandwidth of DeFL is linear to the
number of nodes and similar to (even slightly lower than) that of FL, while that of other baselines is
similar to their receiving bandwidth.

8

Figure 2: Overhead of different scales on CIFAR-noniid

Summary: The computational overhead of DeFL is similar to that of baselines. The storage overhead
of DeFL is almost 0 GB. Although the network overhead of DeFL increases quadratically, it is up to
12x lower than that of Biscotti, which achieves similar accuracy to DeFL under most attacks.

6 Threats to Validity

In this section, we discuss some threats to our approach, including limited scalability and competitive
literature.

6.1 Extend to Cross-device Federated Learning

Note that we limit the scope to cross-silo FL, which makes the following assumptions and results
acceptable, (i) partially synchronous communication, (ii) independently local training, (iii) O(M T n2)
network bandwidth. (i) is the assumption of HotStuff [51], however, in cross-device FL, where
device heterogeneity is relatively high, we will consider asynchronous federated learning (AFL) [43]
to weaken this assumption in future work. AFL allows the central server to aggregate weights as
soon as it receives a local model. (ii) is the assumption of most FL approaches, however, in cross-
device FL, where devices are resource-constrained, we will consider on-device training optimizations,
like pruning [18], quantization [17], and knowledge distillation [20]. (iii) is the consequence of
decentralized aggregation on each node. It could optimize the network bandwidth to reduce the
number of synchronizations by designing consensus specialized for FL. For example, DeFL enables
updates in one training round to be recorded in a particular sequence, however, this feature is not
necessary for FL. We will consider asynchronous Byzantine Atomic Broadcast (BAB) protocols,
such as DAG-Rider [23], to slack the sequence constraint.

6.2 Difference from Byzantine Fault Tolerant Federated Learning

There are many efforts in defending Byzantine attacks in FL and they can be categorized into proactive
and reactive defenses [36]. Proactive defenses include knowledge distillation [27], pruning [22],
moving target defense [9], data sanitization [10], and federated multi-task learning [42]. Reactive
defenses include Sniper [6], anomaly detection [4], Foolsgold [14]. However, conventional BFT FL
approaches are based on the assumption that there exists an honest central parameter server. When
the central server is eliminated in DeFL, most of them become invalid.

9

45678910Number of Nodes1520253035Memory (GB)11.6720.4327.8115.5927.8134.6813.1622.3529.4312.2522.3632.5545678910Number of Nodes01234567Storage (GB)3.015.267.520.210.210.220.030.100.200.000.000.00FLSLBiscottiDeFL45678910Number of Nodes101102Network in (GB)3.115.457.774.679.3714.02113.58348.36647.019.1432.0554.7445678910Number of Nodes101102Network out (GB)3.115.457.774.679.3714.04113.58348.36646.533.095.377.397 Conclusion

In this paper, we propose a novel decentralized weight aggregation framework for federated learning
(DeFL), where weights are aggregated on each node and weights of only the current training round
are maintained and synchronized. To tackle the weight poisoning and round number inconsistency
challenges, DeFL enables aggregating correct weights from honest nodes based on Multi-Krum and
ensures the consistency of the round number and weights based on HotStuff. We theoretically
analyze the Byzantine fault tolerance, convergence, and overhead of DeFL and evaluate these results
over two public datasets. The experimental results validate the effectiveness of DeFL in defending
against common threat models with minimal accuracy loss, as well as show the efﬁciency of DeFL in
storage and network usage. In future work, we will leverage asynchronous FL [43] and asynchronous
BAB protocols [23] to extend DeFL to cross-device FL.

References

[1] Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly Shmatikov. How
to backdoor federated learning. In The 23rd International Conference on Artiﬁcial Intelligence
and Statistics, AISTATS 2020, 26-28 August 2020, Online [Palermo, Sicily, Italy], volume 108
of Proceedings of Machine Learning Research, pages 2938–2948, 2020.

[2] Xianglin Bao, Cheng Su, Yan Xiong, Wenchao Huang, and Yifei Hu. Flchain: A blockchain for
auditable federated learning with trust and incentive. In 5th International Conference on Big
Data Computing and Communications, BIGCOM 2019, QingDao, China, August 9-11, 2019,
pages 151–159, 2019.

[3] Battista Biggio, Blaine Nelson, and Pavel Laskov. Poisoning attacks against support vector
machines. In Proceedings of the 29th International Conference on Machine Learning, ICML
2012, Edinburgh, Scotland, UK, June 26 - July 1, 2012, 2012.

[4] Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, and Julien Stainer. Machine learning
with adversaries: Byzantine tolerant gradient descent. In Advances in Neural Information
Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017,
December 4-9, 2017, Long Beach, CA, USA, pages 119–129, 2017.

[5] Kallista A. Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman,
Vladimir Ivanov, Chloé Kiddon, Jakub Koneˇcný, Stefano Mazzocchi, Brendan McMahan,
Timon Van Overveldt, David Petrou, Daniel Ramage, and Jason Roselander. Towards federated
learning at scale: System design. In Proceedings of Machine Learning and Systems 2019,
MLSys 2019, Stanford, CA, USA, March 31 - April 2, 2019, 2019.

[6] Di Cao, Shan Chang, Zhijian Lin, Guohua Liu, and Donghong Sun. Understanding distributed
poisoning attack in federated learning. In 25th IEEE International Conference on Parallel and
Distributed Systems, ICPADS 2019, Tianjin, China, December 4-6, 2019, pages 233–239, 2019.
[7] Miguel Castro and Barbara Liskov. Practical byzantine fault tolerance. In Proceedings of the
Third USENIX Symposium on Operating Systems Design and Implementation (OSDI), New
Orleans, Louisiana, USA, February 22-25, 1999, pages 173–186, 1999.

[8] Jin-Hua Chen, Min-Rong Chen, Guo-Qiang Zeng, and Jian Weng. BDFL: A byzantine-fault-
tolerance decentralized federated learning method for autonomous vehicle. IEEE Trans. Veh.
Technol., 70(9):8639–8652, 2021.

[9] Richard Colbaugh and Kristin Glass. Moving target defense for adaptive adversaries. In 2013
IEEE International Conference on Intelligence and Security Informatics, Seattle, WA, USA,
June 4-7, 2013, pages 50–55, 2013.

[10] Gabriela F. Cretu, Angelos Stavrou, Michael E. Locasto, Salvatore J. Stolfo, and Angelos D.
Keromytis. Casting out demons: Sanitizing training data for anomaly sensors. In 2008 IEEE
Symposium on Security and Privacy (S&P 2008), 18-21 May 2008, Oakland, California, USA,
pages 81–95, 2008.

[11] Cynthia Dwork, Nancy A. Lynch, and Larry J. Stockmeyer. Consensus in the presence of partial

synchrony. J. ACM, 35(2):288–323, 1988.

[12] Minghong Fang, Xiaoyu Cao, Jinyuan Jia, and Neil Zhenqiang Gong. Local model poisoning
attacks to byzantine-robust federated learning. In 29th USENIX Security Symposium, USENIX
Security 2020, August 12-14, 2020, pages 1605–1622, 2020.

10

[13] L. Feng, Y. Zhao, S. Guo, X. Qiu, W. Li, and P. Yu. Baﬂ: A blockchain-based asynchronous

federated learning framework. IEEE Transactions on Computers, 71(05):1092–1103, 2022.

[14] Clement Fung, Chris J. M. Yoon, and Ivan Beschastnikh. Mitigating sybils in federated learning

poisoning. CoRR, abs/1808.04866, 2018.

[15] Clement Fung, Chris J. M. Yoon, and Ivan Beschastnikh. The limitations of federated learning
in sybil settings. In 23rd International Symposium on Research in Attacks, Intrusions and
Defenses, RAID 2020, San Sebastian, Spain, October 14-15, 2020, pages 301–316, 2020.
[16] Jialiang Han, Yun Ma, and Yudong Han. Demystifying swarm learning: A new paradigm of

blockchain-based decentralized federated learning. CoRR, abs/2201.05286, 2022.

[17] Song Han, Huizi Mao, and William J. Dally. Deep compression: Compressing deep neural
network with pruning, trained quantization and huffman coding. In 4th International Conference
on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference
Track Proceedings, 2016.

[18] Song Han, Jeff Pool, John Tran, and William J. Dally. Learning both weights and connections
for efﬁcient neural network. In Advances in Neural Information Processing Systems 28: Annual
Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal,
Quebec, Canada, pages 1135–1143, 2015.

[19] Justin D. Harris and Bo Waggoner. Decentralized and collaborative AI on blockchain. In IEEE
International Conference on Blockchain, Blockchain 2019, Atlanta, GA, USA, July 14-17, 2019,
pages 368–375, 2019.

[20] Geoffrey E. Hinton, Oriol Vinyals, and Jeffrey Dean. Distilling the knowledge in a neural

network. CoRR, abs/1503.02531, 2015.

[21] Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown. Measuring the effects of non-identical

data distribution for federated visual classiﬁcation. CoRR, abs/1909.06335, 2019.

[22] Yuang Jiang, Shiqiang Wang, Bong Jun Ko, Wei-Han Lee, and Leandros Tassiulas. Model

pruning enables efﬁcient federated learning on edge devices. CoRR, abs/1909.12326, 2019.

[23] Idit Keidar, Eleftherios Kokoris-Kogias, Oded Naor, and Alexander Spiegelman. All you need
is DAG. In PODC ’21: ACM Symposium on Principles of Distributed Computing, Virtual Event,
Italy, July 26-30, 2021, pages 165–175, 2021.

[24] Jakub Koneˇcný, H. Brendan McMahan, Daniel Ramage, and Peter Richtárik. Federated
optimization: Distributed machine learning for on-device intelligence. CoRR, abs/1610.02527,
2016.

[25] Anusha Lalitha, Osman Cihan Kilinc, Tara Javidi, and Farinaz Koushanfar. Peer-to-peer

federated learning on graphs. CoRR, abs/1901.11173, 2019.

[26] Anusha Lalitha, Shubhanshu Shekhar, Tara Javidi, and Farinaz Koushanfar. Fully decentralized

federated learning. In Third workshop on Bayesian Deep Learning (NeurIPS), 2018.

[27] Daliang Li and Junpu Wang. Fedmd: Heterogenous federated learning via model distillation.

CoRR, abs/1910.03581, 2019.

[28] Jun Li, Yumeng Shao, Kang Wei, Ming Ding, Chuan Ma, Long Shi, Zhu Han, and H. Vincent
Poor. Blockchain assisted decentralized federated learning (BLADE-FL): performance analysis
and resource allocation. CoRR, abs/2101.06905, 2021.

[29] Liping Li, Wei Xu, Tianyi Chen, Georgios B. Giannakis, and Qing Ling. RSA: byzantine-robust
stochastic aggregation methods for distributed learning from heterogeneous datasets. In The
Thirty-Third AAAI Conference on Artiﬁcial Intelligence, AAAI 2019, The Thirty-First Innovative
Applications of Artiﬁcial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on
Educational Advances in Artiﬁcial Intelligence, EAAI 2019, Honolulu, Hawaii, USA, January
27 - February 1, 2019, pages 1544–1551, 2019.

[30] Yuzheng Li, Chuan Chen, Nan Liu, Huawei Huang, Zibin Zheng, and Qiang Yan. A blockchain-
based decentralized federated learning framework with committee consensus. IEEE Netw.,
35(1):234–241, 2021.

[31] Tao Lin, Lingjing Kong, Sebastian U. Stich, and Martin Jaggi. Ensemble distillation for robust
model fusion in federated learning. In Advances in Neural Information Processing Systems 33:
Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December
6-12, 2020, virtual, 2020.

11

[32] Yunlong Lu, Xiaohong Huang, Ke Zhang, Sabita Maharjan, and Yan Zhang. Blockchain and

federated learning for 5g beyond. IEEE Netw., 35(1):219–225, 2021.

[33] Lingjuan Lyu, Xinyi Xu, Qian Wang, and Han Yu. Collaborative fairness in federated learning.
In Qiang Yang, Lixin Fan, and Han Yu, editors, Federated Learning - Privacy and Incentive,
volume 12500 of Lecture Notes in Computer Science, pages 189–204. Springer, 2020.

[34] Othmane Marfoq, Chuan Xu, Giovanni Neglia, and Richard Vidal. Throughput-optimal topol-
ogy design for cross-silo federated learning. In Advances in Neural Information Processing
Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS
2020, December 6-12, 2020, virtual, 2020.

[35] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Agüera y Arcas.
Communication-efﬁcient learning of deep networks from decentralized data. In Proceedings of
the 20th International Conference on Artiﬁcial Intelligence and Statistics, AISTATS 2017, 20-22
April 2017, Fort Lauderdale, FL, USA, 2017.

[36] Viraaji Mothukuri, Reza M. Parizi, Seyedamin Pouriyeh, Yan Huang, Ali Dehghantanha, and
Gautam Srivastava. A survey on security and privacy of federated learning. Future Gener.
Comput. Syst., 115:619–640, 2021.

[37] Safa Otoum, Ismaeel Al Ridhawi, and Hussein T. Mouftah. Blockchain-supported federated
learning for trustworthy vehicular networks. In IEEE Global Communications Conference,
GLOBECOM 2020, Virtual Event, Taiwan, December 7-11, 2020, pages 1–6, 2020.

[38] Shiva Raj Pokhrel and Jinho Choi. A decentralized federated learning approach for connected
autonomous vehicles. In 2020 IEEE Wireless Communications and Networking Conference
Workshops, WCNC Workshops 2020, Seoul, Korea (South), April 6-9, 2020, pages 1–6, 2020.

[39] Paritosh Ramanan and Kiyoshi Nakayama. BAFFLE : Blockchain based aggregator free
federated learning. In IEEE International Conference on Blockchain, Blockchain 2020, Rhodes,
Greece, November 2-6, 2020, pages 72–81, 2020.

[40] Muhammad Shayan, Clement Fung, Chris J. M. Yoon, and Ivan Beschastnikh. Biscotti: A
blockchain system for private and secure federated learning. IEEE Trans. Parallel Distributed
Syst., 32(7):1513–1525, 2021.

[41] Reza Shokri and Vitaly Shmatikov. Privacy-preserving deep learning. In Proceedings of the
22nd ACM SIGSAC Conference on Computer and Communications Security, Denver, CO, USA,
October 12-16, 2015, pages 1310–1321, 2015.

[42] Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet Talwalkar. Federated multi-task
learning. In Advances in Neural Information Processing Systems 30: Annual Conference on
Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA,
pages 4424–4434, 2017.

[43] Michael R. Sprague, Amir Jalalirad, Marco Scavuzzo, Catalin Capota, Moritz Neun, Lyman
Do, and Michael Kopp. Asynchronous federated learning for geospatial applications. In ECML
PKDD 2018 Workshops - DMLE 2018 and IoTStream 2018, Dublin, Ireland, September 10-14,
2018, Revised Selected Papers, volume 967 of Communications in Computer and Information
Science, pages 21–28, 2018.

[44] Kentaroh Toyoda, Jun Zhao, Allan NengSheng Zhang, and P. Takis Mathiopoulos. Blockchain-
enabled federated learning with mechanism design. IEEE Access, 8:219744–219756, 2020.

[45] Rong Wang and Wei-Tek Tsai. Asynchronous federated learning system based on permissioned

blockchains. Sensors, 22(4):1672, 2022.

[46] Stefanie Warnat-Herresthal, Hartmut Schultze, Krishnaprasad Lingadahalli Shastry, Sathya-
narayanan Manamohan, Saikat Mukherjee, Vishesh Garg, Ravi Sarveswara, Kristian Händler,
Peter Pickkers, N Ahmad Aziz, et al. Swarm learning as a privacy-preserving machine learning
approach for disease classiﬁcation. bioRxiv, 2020.

[47] Stefanie Warnat-Herresthal, Hartmut Schultze, Krishnaprasad Lingadahalli Shastry, Sathya-
narayanan Manamohan, Saikat Mukherjee, Vishesh Garg, Ravi Sarveswara, Kristian Händler,
Peter Pickkers, N Ahmad Aziz, et al. Swarm learning for decentralized and conﬁdential clinical
machine learning. Nature, 594(7862):265–270, 2021.

12

[48] Chulin Xie, Keli Huang, Pin-Yu Chen, and Bo Li. DBA: distributed backdoor attacks against
federated learning. In 8th International Conference on Learning Representations, ICLR 2020,
Addis Ababa, Ethiopia, April 26-30, 2020, 2020.

[49] Cong Xie, Sanmi Koyejo, and Indranil Gupta. Zeno: Distributed stochastic gradient descent
with suspicion-based fault-tolerance. In Proceedings of the 36th International Conference on
Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of
Proceedings of Machine Learning Research, pages 6893–6901, 2019.

[50] Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated machine learning: Concept

and applications. ACM Trans. Intell. Syst. Technol., 10(2):12:1–12:19, 2019.

[51] Maofan Yin, Dahlia Malkhi, Michael K. Reiter, Guy Golan-Gueta, and Ittai Abraham. Hotstuff:
BFT consensus with linearity and responsiveness. In Proceedings of the 2019 ACM Symposium
on Principles of Distributed Computing, PODC 2019, Toronto, ON, Canada, July 29 - August 2,
2019, pages 347–356, 2019.

[52] Han Yu, Zelei Liu, Yang Liu, Tianjian Chen, Mingshu Cong, Xi Weng, Dusit Niyato, and Qiang
Yang. A fairness-aware incentive scheme for federated learning. In AIES ’20: AAAI/ACM
Conference on AI, Ethics, and Society, New York, NY, USA, February 7-8, 2020, pages 393–399,
2020.

[53] Chengliang Zhang, Suyi Li, Junzhe Xia, Wei Wang, Feng Yan, and Yang Liu. Batchcrypt:
Efﬁcient homomorphic encryption for cross-silo federated learning. In 2020 USENIX Annual
Technical Conference, USENIX ATC 2020, July 15-17, 2020, pages 493–506, 2020.

[54] Zhuangdi Zhu, Junyuan Hong, and Jiayu Zhou. Data-free knowledge distillation for hetero-
geneous federated learning. In Proceedings of the 38th International Conference on Machine
Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine
Learning Research, pages 12878–12889, 2021.

Checklist

1. For all authors...

(a) Do the main claims made in the abstract and introduction accurately reﬂect the paper’s

contributions and scope? [Yes]

(b) Did you describe the limitations of your work? [Yes]
(c) Did you discuss any potential negative societal impacts of your work? [No] The
data privacy and security has raised considerable concerns of end-users and this work
beneﬁts the data privacy and security of federated learning (FL).

(d) Have you read the ethics review guidelines and ensured that your paper conforms to

them? [Yes]

2. If you are including theoretical results...

(a) Did you state the full set of assumptions of all theoretical results? [Yes]
(b) Did you include complete proofs of all theoretical results? [Yes]

3. If you ran experiments...

(a) Did you include the code, data, and instructions needed to reproduce the main experi-
mental results (either in the supplemental material or as a URL)? [Yes] We will make
the source code of this paper publicly available online when this paper is accepted.
(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they

were chosen)? [Yes]

(c) Did you report error bars (e.g., with respect to the random seed after running experi-

ments multiple times)? [Yes]

(d) Did you include the total amount of compute and the type of resources used (e.g., type

of GPUs, internal cluster, or cloud provider)? [Yes]

4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...

(a) If your work uses existing assets, did you cite the creators? [Yes]
(b) Did you mention the license of the assets? [Yes]
(c) Did you include any new assets either in the supplemental material or as a URL? [Yes]

13

(d) Did you discuss whether and how consent was obtained from people whose data you’re

using/curating? [Yes]

(e) Did you discuss whether the data you are using/curating contains personally identiﬁable

information or offensive content? [Yes]

5. If you used crowdsourcing or conducted research with human subjects...

(a) Did you include the full text of instructions given to participants and screenshots, if

applicable? [N/A]

(b) Did you describe any potential participant risks, with links to Institutional Review

Board (IRB) approvals, if applicable? [N/A]

(c) Did you include the estimated hourly wage paid to participants and the total amount

spent on participant compensation? [N/A]

14

A Extended Results for Sentiment140

In this section, we present extended results for Sentiment140 and Sentiment-noniid datasets in fault
tolerance and scalability.

A.1 Fault Tolerance

Table 3: Accuracy on different threat models

Attack

No
Gaussian (σ=0.03)
Gaussian (σ=1.00)
Sign-ﬂipping (σ=-1.0)
Sign-ﬂipping (σ=-2.0)
Sign-ﬂipping (σ=-4.0)
Label-ﬂipping

FL

0.745
0.745
0.737
0.736
0.725
0.655
0.719

Sentiment140
SL

Biscotti DeFL

Sentiment-noniid

FL

SL

Biscotti DeFL

0.746
0.743
0.736
0.738
0.722
0.659
0.720

0.744
0.746
0.745
0.749
0.750
0.745
0.746

0.746
0.746
0.747
0.747
0.748
0.748
0.746

0.700
0.699
0.537
0.685
0.699
0.508
0.698

0.699
0.701
0.534
0.686
0.700
0.510
0.699

0.701
0.700
0.701
0.698
0.699
0.697
0.701

0.698
0.699
0.699
0.699
0.700
0.700
0.700

As mentioned in Section 3.1, we measure 3 types of poisoning attacks with different attack factors
on 1 of 4 nodes. As shown in Table 3, FedAvg-based approaches (FL, SL) share similar accuracy
while Multi-Krum-based approaches (Biscotti, DeFL) share similar accuracy. In most settings,
especially when the attack is severe, the accuracy of Multi-Krum-based approaches is higher than
that of FedAvg-based ones. This indicates that Multi-Krum effectively detects poisoned weights and
aggregates with correct weights from honest nodes.

Table 4: Accuracy on Sentiment-noniid with Gaussian attack (σ=1.00)

Attack

FL

SL

Biscotti DeFL

4+0 (β=0.00)
3+1 (β=0.25)
7+0 (β=0.00)
6+1 (β=0.14)
5+2 (β=0.29)
10+0 (β=0.00)
9+1 (β=0.10)
8+2 (β=0.20)
7+3 (β=0.30)

0.700
0.537
0.701
0.624
0.573
0.701
0.656
0.633
0.601

0.699
0.539
0.700
0.622
0.570
0.699
0.660
0.631
0.604

0.701
0.700
0.700
0.701
0.700
0.700
0.702
0.701
0.700

0.698
0.699
0.701
0.700
0.701
0.701
0.701
0.702
0.702

We choose Gaussian attack (σ=1.00) on Sentiment-noniid to measure the accuracy under different
Byzantine rates β, as shown in Table 4. We scale DeFL on 4, 7, 10 nodes, and "a+b" means there
are a honest nodes and b Byzantine node(s). When the number of nodes is ﬁxed, as β raises, the
accuracy of FedAvg-based approaches drops dramatically, while the accuracy of Multi-Krum-based
ones remains stable and signiﬁcantly higher. Besides, when β keeps stable or even slightly raises, as
the number of nodes increases, the accuracy of FedAvg-based approaches raises. The reason could be
that the higher ensemble property of more nodes contributes to better generalizability and robustness,
however, it is beyond the scope of this paper.

Summary: Under most attacks, the accuracy of DeFL and Biscotti is signiﬁcantly higher than that
of FL and SL, no matter the Byzantine rate.

A.2 Scalability

We scale DeFL and baselines to 4, 7, 10 nodes and measure computation, storage, and network
overhead. As shown in Figure 3, as the number of nodes increases, the growth trends of overhead of
DeFL and baselines are similar to those on CIFAR-noniid, as mentioned in Section 5.3.

15

Figure 3: Overhead of different scales on Sentiment-noniid

Summary: The computational overhead of DeFL is similar to that of baselines. The storage overhead
of DeFL is almost 0 GB. Although the network overhead of DeFL increases quadratically, it is up to
12x lower than that of Biscotti, which achieves similar accuracy to DeFL under most attacks.

16

45678910Number of Nodes152025303540Memory (GB)14.6225.5935.7017.5030.9241.3417.0029.3140.2616.6229.7242.8745678910Number of Nodes0102030405060Storage (GB)0.000.000.000.210.220.2223.4540.9958.600.030.110.20FLSLBiscottiDeFL45678910Number of Nodes102103Network in (GB)24.2342.4760.5536.3973.01109.32885.042714.495039.3171.22249.74426.5545678910Number of Nodes102103Network out (GB)24.2342.4760.5536.3973.01109.33885.042714.495039.6424.0841.8457.58