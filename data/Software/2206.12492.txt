Guidelines for Artifacts to Support Industry-Relevant Research
on Self-Adaptation

Danny Weyns1,2, Ilias Gerostathopoulos3, Barbora Buhnova4, Nicolás Cardozo5, Emilia Cioroaica6,
Ivana Dusparic7, Lars Grunske8, Pooyan Jamshidi9, Christine Julien10, Judith Michael11,
Gabriel Moreno12, Shiva Nejati13, Patrizio Pelliccione14, Federico Quin1, Genaina Rodrigues15,
Bradley Schmerl12, Marco Vieira16, Thomas Vogel8,17, Rebekka Wohlrab12

1Katholieke Universiteit Leuven; 2Linnaeus University; 3Vrije Universiteit Amsterdam;
4Masaryk University; 5Universidad de los Andes; 6Fraunhofer IESE; 7Trinity College Dublin;
8Humboldt-Universität zu Berlin; 9University of South Carolina; 10University of Texas Austin;
11RWTH Aachen University; 12Carnegie Mellon University; 13University of Ottawa;
14Gran Sasso Science Institute; 15Universidade de Brasília;
16University of Coimbra; 17Paderborn University
danny.weyns@kuleuven.be, ilias.gerostathopoulos@vu.nl

2
2
0
2

n
u
J

4
2

]
E
S
.
s
c
[

1
v
2
9
4
2
1
.
6
0
2
2
:
v
i
X
r
a

ABSTRACT
Artifacts support evaluating new research results and help com-
paring them with the state of the art in a ﬁeld of interest. Over
the past years, several artifacts have been introduced to support
research in the ﬁeld of self-adaptive systems. While these arti-
facts have shown their value, it is not clear to what extent these
artifacts support research on problems in self-adaptation that are
relevant to industry. This paper provides a set of guidelines for
artifacts that aim at supporting industry-relevant research on self-
adaptation. The guidelines that are grounded on data obtained
from a survey with practitioners were derived during working ses-
sions at the 17th International Symposium on Software Engineer-
ing for Adaptive and Self-Managing Systems. Artifact providers
can use the guidelines for aligning future artifacts with industry
needs; they can also be used to evaluate the industrial relevance
of existing artifacts. We also propose an artifact template.

INTRODUCTION

1.
The term artifact has diﬀerent meanings in the ﬁeld of software
engineering. In software development communities, artifacts refer
to documents, deliverables, and work products [7]. Software engi-
neering conferences increasingly use the term artifact in associa-
tion with publications. Such artifacts can range from “functional”
i.e., artifacts associated with the research that are documented
and exercisable, and include appropriate evidence of veriﬁcation
and validation; to “replicated” i.e., the main results of the pa-
per have been independently obtained in a subsequent study by a
person or team other than the authors, without the use of author-
supplied artifacts.1 In this paper, we refer to an artifact as a tan-
gible object that is created with the intention to drive research
advances and compare and contrast alternative approaches.2 Our
particular focus is on artifacts that support research in the ﬁeld
of self-adaptation and its applicability in practice.

Generally, diﬀerent types of artifacts can be provided. Testbeds
refer to implementations of systems (or parts of systems) that sup-
port the study and evaluation of open challenges in self-adaptive
systems. Model problems provide detailed speciﬁcations of sys-

1https://conf.researchr.org/track/icse-2022/icse-2022-
artifact-evaluation
2https://conf.researchr.org/track/seams-2022/seams-
2022-papers#Artifacts

tems that pose fundamental or characteristic challenges that self-
adaptive systems should address, either in general or in speciﬁc
domains. Frameworks refer to concrete or conceptual platforms
with generic functionality that can be selectively specialized by
implementing self-adaptation techniques or algorithms that are
potentially useful in diﬀerent contexts and use. Datasets (e.g.,
logging data, sensor data, system traces, survey raw data) can
be used to develop, evaluate, and compare self-adaptation ap-
proaches. These common types of artifacts are representative
classes of the existing artifact landscape.

Over the past decade, researchers in the ﬁeld of self-adaptation
developed about 30 artifacts [20]. A pioneering example is
Znn.com [1] that provides a webserver system of a simpliﬁed news
site. Znn.com’s testing environment simulates the slash-dot ef-
fect, which are periods of abnormally high traﬃc that overload
the system. Another example artifact is TAS [23], which pro-
vides a service-based system, where services oﬀered by third-party
providers are dynamically composed into workﬂows delivering
complex functionality under uncertainties such as changing work-
load and ﬂuctuations in the network. DARTSim [15], instead,
oﬀers an artifact for the evaluation and comparison of adaptation
approaches for smart cyber-physical systems that are subject to
sensing errors among other uncertainties. Yet another example
artifact is RoboMax [3], which provides an extensible repository
of robotic mission adaptation exemplars. A recent study high-
lighted an increasing use of artifacts in the evaluation of research
results, although the adoption by teams other than the developing
team remains relatively low [2].

A recent analysis of the maturity of the ﬁeld of self-adaptation [22]
showed that we are currently in the phases of internal and ex-
ternal enhancement and exploration according to the model of
Redwine and Riddle [16]. Hence, the industrial application of
self-adaptation in real-life practical and commercial applications
is of crucial importance to reach full maturity. Yet, it is currently
not clear to what extent the existing artifacts support research
activities of problems in self-adaptation that are relevant to in-
dustry.

To that end, this paper provides a set of guidelines for future ar-
tifact providers that aim at supporting industry-relevant research
In addition, the guidelines enable assessing
on self-adaptation.

 
 
 
 
 
 
existing artifacts on their relevance to support industry-driven
research. The guidelines are grounded on the data obtained from
a large-scale survey with practitioners. The guidelines have been
derived from the outcome of a series of working sessions during the
in-person day at the 17th International Symposium on Software
Engineering for Adaptive and Self-Managing Systems, SEAMS
2022.3 Note that alignment of research with industry has been
topic of study in other domains, for instance in control [17] or in
computing systems in general, see e.g., [4, 18].

The remainder of this paper is structured as follows. In Section 2,
we present the process we followed to deﬁne the guidelines pre-
sented in this paper, and we summarize the data that was used as
input for the working sessions. Section 3 then presents the guide-
lines. In Section 4, we present a template to describe industry-
relevant artifacts on self-adaptation. Finally, we conclude the
paper in Section 5.

2. BACKGROUND
In this section, we give an overview of the process we followed to
create the guidelines for artifacts, together with a brief summary
of the data used to deﬁne the guidelines.

2.1 Process used to Derive the Guidelines
Figure 1 shows the process we followed to derive the guidelines
for artifacts.

reasoning (i.e., moving from speciﬁc fragments in comments to
general concepts) [19].

The coded data (elaborated below) was then used as input for
the working sessions that were organized during the in-person
part of SEAMS 2022. Concretely, we divided the group of 20
participants in three breakout groups. Each group drafted a set
of guidelines during two sessions of 1.5 hours. Finally, the insights
were brought together and discussed during a plenary session of
one hour. After the event, we consolidated the guidelines and
documented the results in this paper.

2.2 Survey Data
We summarize the results of the coding of the survey data by
highlighting (a) diﬃculties and challenges practitioners face when
applying self-adaptation, (b) problems for which they would ap-
preciate support from researchers, and (c) opportunities for ap-
plying self-adaptation.

Of all the surveyed practitioners, 35% regularly face diﬃculties
and challenges with applying self-adaptation, while 40% report
that they sometimes face problems. Table 1 shows the categories
and codes collected from the answers. The table shows that prac-
titioners face diﬃculties and challenges across diﬀerent aspects of
software engineering, from lifecycle issues to design, engineering
processes, and runtime.

Table 1: Diﬃculties and challenges in self-adaptive systems
as perceived by practitioners

Categories and codes

Lifecycle issues
Tuning/debugging
Limitations of tools/methods
System/environment evolution
Design challenges
Reliable/optimal design
Design complexity
Security
People and process issues
Skills/experience
Process and management
Documentation
Runtime challenges
Runtime uncertainty
Data collection/evaluation
Delayed/missing runtime changes

#

22
10
7
5
20
10
9
1
14
8
5
1
13
6
5
2

Twenty percent of the practitioners express that they would fre-
quently appreciate support from researchers to tackle problems
they face, while 23% would sometimes appreciate support. Ta-
ble 2 shows the categories and codes collected from the answers.
The table shows that practitioners would appreciate support for
tackling a variety of problems, from engineering to providing guar-
antees of trust, user interaction-related solutions, management of
data, and the realization of a number of advanced features.

Table 3 shows the opportunities practitioners see for applying
self-adaptation that are currently not exploited. The main op-
portunities are related to system activities and system properties.
Other opportunities concern engineering activities and human in-
volvement in the self-adaptation process.

Figure 1: Process used to derive guidelines.

In a recent large-scale survey, we collected data from 113 prac-
titioners4 about: (a) the drivers and motivations to apply self-
adaptation in industrial software, (b) the use cases and approaches
used to realize self-adaptation, (c) the problems and challenges
practitioners face, and (d) the opportunities practitioners see for
self-adaptation. For a summary of the initial results, we refer
to [24]. When deﬁning the guidelines, we have used raw data on
three speciﬁc topics: (a) diﬃculties and challenges practitioners
face when applying self-adaptation, (b) problems for which they
would appreciate support from researchers, and (c) opportunities
for applying self-adaptation. In addition, we used categories and
codes that were obtained from the raw data through inductive

3https://conf.researchr.org/track/seams-2022/seams-
2022-papers
4The participants range from diﬀerent companies across the globe,
active in a variety of domains; they have various roles in software
engineering with a variety of experience (67% have at least 9 years
of experience) [24].

Large-scale Survey Post-analysisWorking Sessionsparticipants: 113 practitionersselected raw datadraft guidelines participants: 20 researchers report with consolidated guidelines Data codingcoded dataTable 2: Problems for which practitioners would appreciate sup-
port from researchers

Table 3: Opportunities for self-adaptation in industry that are cur-
rently not exploited as mentioned by practitioners

Categories and codes

Engineering
Architecture & reuse
Adoption
Tools
Frameworks
Guarantees
Trustworthiness
Unknowns
Security
User interaction
User experience
Automation
User involvement
Data
Govern data
Assess data
Machine learning
Advanced features
Goals
Mechanisms
Testing

#

22
7
7
4
4
19
9
5
5
18
7
7
4
18
8
6
4
13
6
4
3

3. GUIDELINES
We now present the consolidated guidelines. Table 4 provides
an overview of the guidelines that are divided in three groups:
required, recommended, and desirable guidelines. We discuss each
group now in detail.

3.1 Required Guidelines
This ﬁrst group of guidelines are required for industry-relevant
artifacts in self-adaptation. Yet, which of these guidelines are
relevant and apply depends on the type of artifact and its concrete
purpose.

P1: Artifacts should take into account relevant sur-
rounding elements

Crucial for industry-relevant artifacts is that they take into ac-
count the context in which self-adaptation is applied. We reﬁne
this guideline in three concrete sub-guidelines.

P1.1: Artifact should take into account management
of real-world data

There are diﬀerent kinds of data that a self-adaptive system must
manage during operation. Some are inherent to the functional-
ity of the system, such as requests from users to a website and
sensor readings in a cyber-physical system. Others are necessary
for the self-adaptation process itself, such as monitoring data col-
lected for analysis and planning.
It is important that artifacts
can manage data with characteristics representative of industrial
use, including volume, rate, noise, etc. Otherwise, research eval-
uated with artifacts may not be able to deal with the data needs
of industrial use.

P1.2: Artifacts should facilitate humans-on-the-loop

The initial research in engineering self-adaptive systems was
In this re-
mainly concerned with automating tasks [9, 12, 21].
search, the role of humans was in essence limited to providing

Categories and codes

System activities
Autonomous operation
Autoscaling
AutoML & data management
System properties
Qualities
Cyber-security
Engineering activities
DevOps & maintenance
Adaptation patterns & libraries
Human involvement
Personalization
Human-machine interaction

#

26
10
8
8
20
12
8
15
10
5
5
4
1

high-level goals that the system should fulﬁll. Later, the role of
humans-in-the-loop became prominent [5].
In this perspective,
humans can take diﬀerent roles, from providing input to support-
ing decision-making and guiding adaptation actions. Yet, several
researchers pointed out the potential implications and risks of
uncertainty caused by humans-in-the-loop [6, 11]. On the other
hand, practitioners point to the need for humans-on-the-loop in
self-adaptive systems. In industrial applications, humans should
not be involved in the adaptation process all the time to avoid
that they become a bottleneck. The preferred role of humans is
instead supervision to achieve trustworthiness, avoid misuse or
disuse of the automated system. In this regard, artifacts should
consider diﬀerent stakeholder roles: Users, operators, business
owners, customers, etc., and emphasize their concerns such as
feasibility, added value, and Return On Investment (ROI).

P1.3: Artifacts should take into account industrial
adoption of newly proposed solutions

Artifacts are developed to evaluate and demonstrate new re-
search results, ultimately with the goal of advancing the state-of-
practice. It is however well known that industry will only adopt
research solutions if they are demonstrated to be eﬀective in the
context of real operational requirements. As such, transferring
research results to the ﬁeld requires organizations to conduct a
preliminary evaluation (e.g., in the form of an industrial proto-
type, testbed or case study), which has a cost that may be seen
as a risk by managers and decision-makers. Artifacts can play
a major role in the reduction of such costs, thereby facilitating
the experimentation of new solutions by industry and promoting
the adoption of research results. In practice, artifacts should be
built in such a way that allow industry to easily develop proofs of
concept to test the eﬀectiveness of new research solutions in their
speciﬁc settings and adopt the results in their practice.

P2: Artifacts should take into account industry scale

A representative scale is a key requirement for the industrial rel-
evance of an artifact. Artifacts to support industry-relevant re-
search should have a capacity and complexity that is characteris-
tic of industrial practice. Taking into account real-world data as
highlighted in guideline P1.1 is one speciﬁc facet of industry scale.
Other aspects include the size of systems (e.g., a representative
topology of an Internet of Things network), requirements of sys-
tems (e.g., representative requirements of health care systems in-

Table 4: Overview of guidelines for artifacts to support industry-relevant research on self-adaptation

Required Guidelines

P1: Artifacts should take into account relevant surrounding elements

P11: Artifact should take into account management of real-world data
P12: Artifacts should take into account humans-on-the-loop
P13: Artifacts should take into account industrial adoption of newly proposed solutions

P2: Artifacts should take into account industry scale
P3: Artifacts should provide industry-relevant metrics
P4: Artifacts should use an open policy

Recommended Guidelines

R1: Integration with standard technologies
R2: Process-related artifacts
R3: Generality and extensibility of artifacts
R4: Artifacts that facilitate collaborations across communities

Desirable Guidelines

D1: Artifacts may be built to exist in an ecosystem
D2: Artifacts may leverage open-source projects

cluding privacy, performance, and cost), the load exercised on sys-
tems (e.g., realistic workloads used by Cloud resources), and un-
derlying infrastructure (e.g., representative messaging techniques
for micro-service architectures).

3.2 Recommended Guidelines
The second group of guidelines are recommended for industry-
relevant artifacts in self-adaptation. We advise these guidelines
as they will add to the relevance for industry.

P3: Artifacts should provide industry-relevant metrics

To quantify the beneﬁts and costs of self-adaptation, artifacts
should provide industry-relevant metrics. On the one hand, such
metrics should address quality characteristics of software systems
to measure the satisfaction of quality requirements. This allows
practitioners and researchers to evaluate a self-adaptive system
built with an artifact from a technical perspective. On the other
hand, such metrics should also address a business-oriented per-
spective, for instance, to evaluate a self-adaptive system built with
an artifact economically (e.g., added value and ROI as also sug-
gested by guideline P1.2). This allows customers and business
owners to assess self-adaptation solutions developed with a spe-
ciﬁc artifact. Moreover, practitioners and researchers may select
suitable artifacts based on their technical and business interest
by taking these metrics into account. This allows them to eas-
ily pick up connection points for leveraging the self-adaptation
mechanisms.

P4: Artifacts should use an open policy

To facilitate adoption in industry, the artifacts need to (a) be
openly available under clear licensing schemes, (b) leverage open
standards (and preferably be based on standard technology, see
guideline R1, and open-source projects, see guideline D2), and
(c) ensure transparency. The transparency condition is crucial
not only in terms of artifact trustworthiness, but also to support
troubleshooting of defects in self-adaptation processes that are
likely to be common in industry, given the reported shortage of
expertise on the topic in the teams [24], and might require further
process-related support (see guideline R2). The transparency also
facilitates repeatability (i.e., same team, same experimental setup,
for the sake of validation), reproducibility (i.e., diﬀerent team,
same experimental setup, for the sake of statistical signiﬁcance),
and replicability (i.e., diﬀerent team, diﬀerent experimental setup,
for the sake of wider adoption). As artifacts may evolve over
time, clear guidance on versioning and quality assurance is key to
support industries willing to contribute to their extensions.

R1: Integration with standard technology

Central to industrial relevance of artifacts is the use of standard
technologies. This brings forward the following beneﬁts:

• Realism: Artifacts developed with standard technologies al-
low for a closer level of realism due to the fact that the
technologies used correspond to the actual technologies.5

• Engagement: Using standard technologies ensures that a
larger share of people is familiar with how the artifact
functions. Examples of standard technologies (at the time
of writing) include: Docker, Real-time Operating System
(ROS) for Robotics, Carla (self-driving simulator), etc.

• Relevance: The demonstrated beneﬁts and evidence of tech-
niques, solutions, or frameworks by using the artifact maps
closer to industrial practice. More speciﬁcally, technology-
speciﬁc settings of problems or opportunities put forward by
industry connect more to the artifact when using the same
technologies.

R2: Process-related artifacts

Process-related artifacts are those that are targeted at helping
apply self-adaptation in industrial settings. Rather than tools
that implement or support self-adaptation, these kinds of arti-
facts focus on software engineering processes (e.g., checklists) for
designing, testing, and deploying them. For instance:

• Design: Guidance is needed on how to ensure that when
applying self-adaptation in a particular context, that the

5Besides technologies used, real-world data traces, realistic uncer-
tainty proﬁles, etc. should be used to ensure industry relevance.

system is complete and can provide a certain level of assur-
ances. This requires that the right state is being modeled
and monitored and the feedback loop is properly developed
by combining tactics. E.g., it is not necessary to monitor el-
ements that do not contribute to the decision-making about
the system; similarly, if the self-adaptive system needs infor-
mation in the planning or analysis process, this information
needs to be stored in the knowledge that the self-adaptive
system has about the system it is managing, and/or that ap-
propriate monitoring is in place to retrieve that information
in a timely and accurate way.

• Testing: In order to practically apply self-adaptation, we
need strategies for testing self-adaptive systems aligned with
current practice, deﬁnitions of standard test metrics like cov-
erage in the context of self-adaptation, and guidelines on
how to provide a testing environment that drives the adap-
tations to be tested. Some of the research behind this has
been done in [8,10,13], but artifacts that can be used to op-
erationalize self-adaptive testing would be helpful in guiding
industry on how and what to apply.

• Deployment: Once an adaptation decision is made, the sys-
tem needs to enact the adaptation. This calls for strategies
to apply adaptation actions in a safe way. Artifacts to inte-
grate the execution of system adaptation aligned with state
of the practice infrastructure for continuous deployment are
key in helping practitioners with closing the feedback loop
of self-adaptation.

Process related artifacts may rely on, or take the form of best-
practices documents, checklists for practitioners to use to ensure
they deal with appropriate and common steps for self-adaptation,
or test/deployment scripts that practitioners can use to manage
CI/CD pipelines for self-adaptive systems.

R3: Generality and extensibility of artifacts

Generality and extensibility of artifacts add to their applicabil-
ity and reusability. Therefore,
it is important to deﬁne arti-
facts enabling their reuse both across application domains, such
as robotics, automotive, and telecommunications, and/or axes of
research/engineering activities, including requirements, architec-
ture, veriﬁcation, analysis, deployment, evolution, etc. Generality
will leverage research results across domains and support the in-
tegration of research/engineering activities. Extensibility, on the
other hand, enables the extension of existing artifacts to diﬀer-
ent domains and/or research/engineering activities. Note that
this does not imply that domain-speciﬁc artifacts cannot not be
eﬀective and useful. For instance, RoboMax [3], the artifact men-
tioned before, captures key sources of uncertainty and adapta-
tion concerns of missions for the domain of robotic systems. Such
domain-speciﬁc knowledge and know-how can add to the eﬃciency
of applying an artifact.

R4: Artifacts that facilitate collaborations across com-
munities and with industry

Industry requires simple and easily composable building blocks
that can be shared for experimentation. The motivation for
business gain could come from the composition of innovative
ideas that have been developed by members of diﬀerent sci-
entiﬁc communities and mapped into robust workﬂows. Fur-
thermore, science makes better progress when we have diver-
sity of ideas and the people who generate the ideas [14]. To
enable cross-community collaborations and integration with in-
dustry, researchers should make it easy for others to build on top

of the ideas and artifacts they generate. This calls for an in-
frastructure that easily facilitates automatic evaluation of meth-
ods/techniques/algorithms/etc. against benchmarks. Such an in-
frastructure will enable others to engage, while providing input
and feedback from these diverse set of people. Several examples
exist that have already demonstrated the added value; we give
two examples:

• DLRM6 is a platform to which researchers from Computer
Architecture and Systems and Recommendation Systems
actively contribute. DLRM was developed by academics
while placed as interns at Facebook.

• MLCommons7 supported the development of multiple im-
portant benchmarks such as MLPerf and TinyML for re-
searchers interested in machine learning for systems and sys-
tems for machine learning.

In sum, we need an infrastructure, preferably open source, that
makes it easier for researchers to share innovative ideas,
for
developers to experiment with ideas over a short time win-
dow (e.g., a weekend), and for software companies to make the
ideas production-ready. This creates opportunities for more re-
searchers, within and across diﬀerent communities, to engage, and
for industry to contribute to industry-relevant research eﬀorts and
engage with the research communities.

3.3 Desirable Guidelines
The third group of guidelines are desirable for industry-relevant
artifacts in self-adaptation. These guidelines are worth having as
they will add to the attractiveness for industry.

D1: Artifacts may be built to exist in an ecosystem

Desirable properties of artifacts for industry-relevant research on
self-adaptation are extensibility and integratability, so that they
can accommodate surrounding elements (compare also guideline
R3). In the past, the focus of self-adaptive systems has been on
mechanisms to adapt systems’ behaviors or structures, whereas
surrounding elements (e.g., data management, human-machine in-
teraction, and integration with basic infrastructure) have received
little attention (see guideline P1). To integrate surrounding ele-
ments, preferable in a lightweight way, it is desirable not to focus
on speciﬁcs of self-adaptive systems in isolation, but to design
artifacts to co-exist within an ecosystem. To support this guide-
line, for example, data management solutions may be provided as
reusable components. Moreover, artifacts should be designed so
that they can be extended and integrated with other systems (see
also guideline R4). This will add to a holistic perspective, which
is a key aspect for industrial relevance of artifacts.

D2: Artifacts may leverage open-source projects

To increase the industrial relevance of artifacts and their accep-
tance by industry, they would beneﬁt from relying on well-known
and robust projects. The use of open source projects may help ar-
tifacts to have a more stable underlying infrastructure. On the one
hand, relying on existing infrastructure from open-source projects
(e.g., containers, continuous integration tools, frameworks) re-
duces the learning curve for practitioners, and eases deployment
and integration of the artifacts solutions with their technology

6https://ai.facebook.com/blog/dlrm-an-advanced-open-
source-deep-learning-recommendation-model/
7https://mlcommons.org/en/

Table 5: Proposed template for industry-relevant artifacts to support research on self-adaptive systems

Element

Brief description

Problem
Prerequisites
Technologies
Outcome

Adoption

A brief description of the industry-relevant problem tackled by the artifact
Requirements or constraints for using the artifact and the research results obtained with it
Relevant state-of-the-practice technologies associated with the artifact
The expected outcome of using the artifact and adopting the solution in practice (e.g.,
quantiﬁable by metrics)
The relevant aspects required to adopt the research results obtained by using the artifact

Example
Related artifacts

An exemplary solution to the problem and how it was adopted
Artifacts that address similar problems or that can be combined to enrich the solution

Maintenance

A version history, and a reference to the maintainer of the artifact who keeps it up-to-date
and responds to change requests

base. On the other hand, using existing projects as a base,
can lead artifacts to reach a readiness level accepted by industry
faster. Finally, we note that adopting an open-source process for
the development of artifacts can be beneﬁcial for their evolution
and customization. As artifacts become more accepted, particular
industries can customize a base artifact for their particular needs.
As the artifacts evolve, new features can be integrated easily with
branched and customized development.

4. TEMPLATE FOR INDUSTRY-RELEVANT

ARTIFACTS

To support industry-relevant research on self-adaptation, artifact
descriptions would beneﬁt from a standard structure, similarly to
the uniform descriptions of design patterns. Standard template-
based descriptions support both researchers and practitioners in
searching,
identifying, understanding, and comparing artifacts
that are relevant for a given problem. Otherwise, the artifacts
themselves have to be investigated, analyzed, and even executed
to assess their relevance for the given problem and technology,
which is a diﬃcult and time-consuming eﬀort.

Table 5 shows the proposed template for industry-relevant arti-
facts.

The elements of the template were derived from the consolidated
guidelines. The top part considers the basic elements to describe
an artifact, from a description of the problem to the adoption of
research results obtained with the artifact. The elements of the
middle part provide an example solution and related artifacts that
put the artifact in a broader context. Finally, the bottom part
captures maintenance of the artifact in face of the rapid progress
of technology in industry. Up-to-date maintained artifacts are
essential to industrial relevance research. We anticipate that dif-
ferent types of templates might be needed to accommodate the
description of diﬀerent types of artifacts, such as testbeds, frame-
works, datasets, and checklists. Finally, although the template
elements proposed in Table 5 were derived based on data obtained
from practitioners in the context of self-adaptation, the elements
of the template are generic and applicable to industry-relevant
research in other areas. Yet, more study is required to underpin
this observation.

5. CONCLUSIONS
Artifacts are key to systematic evaluation of new research results
in a ﬁeld of interest. We provided a set of empirically grounded
guidelines for artifacts that aim at supporting industry-relevant

research in the ﬁeld of self-adaptation. The guidelines can be
used by artifact providers for aligning future artifacts with indus-
try needs as well as to assess the industrial relevance of existing
artifacts. Finally, we proposed a template for describing industry-
relevant artifacts to support research on self-adaptive systems.
We hope that this paper will support the research community in
self-adaptation to further enhance its maturity, the broader soft-
ware engineering community to engage across their borders, and
practitioners in adopting research results to build better software
systems.

Acknowledgment
We are grateful to the practitioners that participated in the survey
that we used as the basis for the presented guidelines.

6. REFERENCES
[1] Znn.com. https: // github. com/ cmu-able/ znn , 6/2022.
[2] Shubham A. Analysing and assessing self-adaptive systems

and designing a general criterion to evaluate sas artifacts.
MSc Thesis Vrije Universiteit Amsterdam, 2020.

[3] M. Askarpour, C. Tsigkanos, C. Menghi, R. Calinescu,
P. Pelliccione, S. Garc´ıa, R. Caldas, T. von Oertzen,
M. Wimmer, L. Berardinelli, M. Rossi, M. Bersani, and
G. Rodrigues. Robomax: Robotic mission adaptation
exemplars. In International Symposium on Software
Engineering for Adaptive and Self-Managing Systems, 2021.

[4] N. Boules, K. Douglas, S. Feldman, L. Fix, G. Hager,
B. Hailpern, M. Hebert, D. Lopresti, B. Mynatt,
C. Rossbach, and H. Wright. The future of computing
research: Industry-academic collaborations. Computing
Community Consortium, Version 2:1–19, 6/2022.

[5] J. C´amara, G. Moreno, and D. Garlan. Reasoning about

human participation in self-adaptive systems. In
IEEE/ACM 10th International Symposium on Software
Engineering for Adaptive and Self-Managing Systems, 2015.

[6] N. Esfahani and S. Malek. Uncertainty in self-adaptive
software systems. In R. de Lemos, H. Giese, H. M¨uller,
et al., editors, Software Engineering for Self-Adaptive
Systems II: International Seminar, Dagstuhl Castle,
Germany, October 24-29, 2010 Revised Selected and Invited
Papers, pages 214–238. Springer Berlin Heidelberg, 2013.
[7] D. Fern´andez, W. B¨ohm, A. Vogelsang, J. Mund, M. Broy,

M. Kuhrmann, and T. Weyer. Artefacts in software
engineering: a fundamental positioning. Softw. Syst. Model.,
18(5):2777–2786, 2019.

[8] E. Fredericks and B. Cheng. Automated generation of

[17] T. Samad, M. Bauer, S. Bortoﬀ, S. Di Cairano, L. Fagiano,

adaptive test plans for self-adaptive systems. In
IEEE/ACM 10th International Symposium on Software
Engineering for Adaptive and Self-Managing Systems, 2015.

[9] D. Garlan, S.W. Cheng, A.C. Huang, et al. Rainbow:
Architecture-based self-adaptation with reusable
infrastructure. Computer, 37(10):46–54, 2004.
[10] O. Gheibi and D. Weyns. Lifelong self-adaptation:
Self-adaptation meets lifelong machine learning. In
IEEE/ACM 17th International Symposium on Software
Engineering for Adaptive and Self-Managing Systems, 2022.

[11] S. Hezavehi, D. Weyns, P. Avgeriou, R. Calinescu,

R. Mirandola, and D. Perez-Palacin. Uncertainty in
self-adaptive systems: A research community perspective.
ACM Transactions on Autonomous and Adaptive Systems,
15(4), 2021.

[12] J. Kephart and D. Chess. The vision of autonomic

computing. Computer, 36(1):41–50, 2003.

[13] M. Langford and B. Cheng. Know what you know:

Predicting behavior for learning-enabled systems when
facing uncertainty. In International Symposium on Software
Engineering for Adaptive and Self-Managing Systems, 2021.
[14] D. Medin and C. Lee. Diversity makes better science. APS

Observer, 25(5), 2012.

[15] G. Moreno, C. Kinneer, A. Pandey, and D. Garlan.

Dartsim: An exemplar for evaluation and comparison of
self-adaptation approaches for smart cyber-physical
systems. In IEEE/ACM 14th International Symposium on
Software Engineering for Adaptive and Self-Managing
Systems, 2019.

[16] S. Redwine and W. Riddle. Software technology maturation.
In 8th International Conference on Software Engineering,
page 189–200, Washington, DC, USA, 1985. IEEE.

P. Odgaard, R. Rhinehart, R. S´anchez-Pe˜na, A. Serbezov,
F. Ankersen, P. Goupil, B. Grosman, M. Heertjes,
I. Mareels, and R. Sosseh. Industry engagement with
control research: Perspective and messages. Annual Reviews
in Control, 49:1–14, 2020.

[18] A. Scandura and S. Iammarino. Academic engagement with

industry: the role of research quality and experience.
Technology Transfer, Preprint:1–37, 2021.

[19] K. Stol, P. Ralph, and B. Fitzgerald. Grounded theory in
software engineering research: A critical review and
guidelines. In 38th International conference on Software
Engineering (ICSE), pages 120–131, 2016.

[20] T. Vogel. Catalog of SEAMS artifacts:

http://self-adaptive.org/exemplars. 6/2022.

[21] D. Weyns. Software engineering of self-adaptive systems. In
Sungdeok Cha, Richard N. Taylor, and Kyochul Kang,
editors, Handbook of Software Engineering, pages 399–443.
Springer International Publishing, Cham, 2019.

[22] D. Weyns. An Introduction to Self-adaptive Systems: A

Contemporary Software Engineering Perspective. John
Wiley & Sons, 2021.

[23] D. Weyns and R. Calinescu. Tele assistance: A self-adaptive

service-based system exemplar. In IEEE/ACM 10th
International Symposium on Software Engineering for
Adaptive and Self-Managing Systems, 2015.

[24] D. Weyns, I. Gerostathopoulos, N. Abbas, J. Andersson,

S. Biﬄ, P. Brada, T. Bures, A. Di Salle, P. Lago, A. Musil,
J. Musil, and P. Pelliccione. Preliminary results of a survey
on the use of self-adaptation in industry. In International
Symposium on Software Engineering of Adaptive and
Self-Managing Systems.

https://arxiv.org/abs/2204.06816, 2022.

