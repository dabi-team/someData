LogStamp: Automatic Online Log Parsing Based on
Sequence Labelling

Shimin Tao§, Weibin Meng§(cid:66), Yimeng Chen§, Yichen Zhu‡, Ying Liu†
Chunning Du¶, Tao Han§, Yongpeng Zhao§, Xiangguang Wang§, Hao Yang§
§Huawei,‡University of Toronto
†Tsinghua University
¶Beijing University of Posts and Telecommunications

2
2
0
2

g
u
A
0
1

]
E
S
.
s
c
[

1
v
2
8
2
0
1
.
8
0
2
2
:
v
i
X
r
a

Abstract—Logs are one of the most critical data for service
management. It contains rich runtime information for both
services and users. Since size of logs are often enormous in
size and have free handwritten constructions, a typical log-based
analysis needs to parse logs into structured format ﬁrst. However,
we observe that most existing log parsing methods cannot parse
logs online, which is essential for online services. In this paper,
we present an automatic online log parsing method, name as
LogStamp. We extensively evaluate LogStamp on ﬁve public
datasets to demonstrate the effectiveness of our proposed method.
The experiments show that our proposed method can achieve
high accuracy with only a small portion of the training set. For
example, it can achieve an average accuracy of 0.956 when using
only 10% of the data training.

Index Terms—Log Analysis; Log Parsing; AI for Operations;

Service Management;

I. INTRODUCTION

Logs are one of the most valuable data sources for large-
scale services maintenance[1, 2], which report service runtime
status and help operators to ﬁnd trace workﬂows. Logs have
been widely applied for a variety of service management
and diagnostic tasks. Prior research has proposed automated
approaches to analyze logs, such as status monitoring [3],
anomaly detection [4, 5], failures prediction [6] and root cause
analysis[7]. The fast-emerging AIOps (Artiﬁcial Intelligence
for IT Operations) solutions also utilize operation logs as their
input data[8].

Logs are designed by developers and generated by logging
statements (e.g., printf (), log.info())) in the source code[9].
As shown in Fig.1, a logging function composes of log level
(i.e., info), constant parts (i.e., “Interface” and “change state
to down”), and variables (i.e., “InterfaceID”). Service and
system generate raw logs by printing an unstructured text
that contains constant text and speciﬁed variables (e.g., “te-
1/1/50”). Usually, the constant parts sketch out the event and
summarize it, and variables vary from one log to another of
the same template.

Since logs are often extensive in size (e.g., Google and Face-
book respectively generate 100 Petabyte and 10 Petabyte of log
data per month[9]) and have free handwritten constructions[1],
log analysis remains a signiﬁcant challenge. To address the

(cid:66) Weibin Meng(mengweibin3@huawei.com) is corresponding author.

Fig. 1. An illustrative example of log parsing from source code of logging
to structure log

challenge of the large size of logs, researchers propose ap-
proaches for log compression[10]. However, most log com-
pression approaches only aim to save storage space while
not assisting when analyzing logs in practice. To address the
challenge of log analysis, using rules (e.g., source code[11]
and regular expressions[12]) is a simple yet effective ap-
proach. However, the source code is not always available,
and designing regular expressions relies on domain knowl-
edge, which cannot use in practice. Therefore, automatic log
parsing methods are getting attention. Researchers propose
many approaches for automatically parsing raw logs into
structured forms[13]. The main aim of log parsing is to ﬁnd
templates (constant parts) from logs and replace variables with
variable placeholders. Recently, many data-driven log parsing
approaches have been proposed. There are multiple techniques,
such as clustering [14], longest common subsequence[15],
frequent pattern mining[15, 16], heuristics parsing[17] and
others[9]. However, log parsing still faces two challenges.

Firstly, operators continuously conduct software/ﬁrmware
upgrades on services/systems to introduce new features, ﬁx
bugs, or improve performance[9], which can generate new
types of logs. Most of the existing approaches do not support
online analysis. A small number of approaches (e.g., FT-
tree[16], LogParse[9]) that support online parsing also have
some shortcomings, or they cannot handle new types of words,

Jul 1019:03:03INFOInterface te-1/1/50, changed state to down Timestamp:Jul 1019:03:03Level:INFOTemplate:Interface *, changed state to down Variable(s):Interface te-1/1/50RawlogParsingLoggingLog.info("Interface %s, changed state to down ", InterfaceID)StructuredpartsUnstructuredparts 
 
 
 
 
 
or they need to be combined with other log parsing algorithms
to complete. Therefore, Newly generated logs are difﬁcult to
process online .

Besides, most existing log parsing approaches similar group
logs and extracts templates for each group by keeping the same
parts from logs and replacing different parts with placeholders.
By default, log parsing is an unsupervised process. Parsers
extract templates based on provided data instead of domain
knowledge. Therefore, they only produce accurate results with
sufﬁcient historical log data. And, technically, the more data
provided, the more accurate result they return. However, when
a brand new service goes online, there are usually not enough
historical logs to generate accurate templates. Therefore, it’s
challenging to train a parsing model with small amounts of
log data.

To address the above challenges, we propose LogStamp.
The key intuition is based on the following observations: When
Operations reads the log, they mentally mark the words in the
log to identify the template. In LogStamp, we turn the log
parsing problem into a sequence labelling problem and ﬁnd
templates from logs online. LogStamp’s contribution can be
summarized as follows:

• LogStamp is an accurate online log parsing method.
LogStamp can parse logs one by one, and has extremely
high accuracy.

• LogStamp can train an accurate log parsing model based
on a small amount of log data, which ensures that it can
analyze online logs. Experiments show that it can achieve
an average accuracy of 0.956 when using only 10% of
the data training.

The rest of the paper is organized as follows: We discuss
related works in Section II and propose our approach in Sec-
tion III. The evaluation is shown in Section IV. In Section V,
we discuss LogStamp’s limitations and future works. Finally,
we conclude our work in Section VI.

II. RELATED WORK

Logs play an important role in service management. Log
parsing usually serves as the the ﬁrst step towards automated
log analysis [1].

The most straightforward approach is to use rules to parse
logs, such as regular expressions. The rule-based log parsing
methods rely on handcrafted rules provided by domain knowl-
edge. Though straightforward, this kind of method requires a
deep understanding of the logs, and a lot of manual efforts
are needed to write different rules for different kinds of logs,
which is not general. Commercial log analytic platforms (e.g.,
Splunk, ELK, Logentries) also allow operators to efﬁciently
manage and analyze large-scale logs by pre-deﬁne rules. But
they are only applicable to certain types of logs and are not
universal.

Utilizing source code can parsing logs accurate. For ex-
ample, [11] employs source code to extract log templates for
system problem detection. However, the source code is not
always available, especially for commercial services.

To achieve the goal of automated log parsing, many data-
driven approaches have been proposed. There are many cat-
egories of log parsing [1, 18]. The ﬁrst category is cluster-
based approaches, which log template forms a natural pattern
of a group of log messages. From this view, log parsing can
be modeled as a clustering problem, such as LogSig [19].
Next is longest common subsequence. For example, Spell
[15] uses the longest common subsequence algorithm to parse
logs in a stream. Iterative partitioning is used in IPLoM [17].
Some methods use heuristics to extract templates. As op-
posed to general text data, log messages have some unique
characteristics. Consequently, Drain [20] propose heuristics-
based log parsing methods. The next category is frequent
item mining, which is straightforward. Tokens, which regularly
appear together in different log entries, are built into frequent
itemsets. The parser obtains templates by looking up those
itemsets. Log templates can be seen as a set of constant
tokens that frequently occur in logs, such as FT-tree [16]. The
ﬁnal category is combined approaches. LogParse [9] combines
existing unsupervised log parsing approaches and supervised
machine learning approaches to generate templates for online
logs. The idea of LogParse is similar to our paper. However,
it’s a pipeline workﬂow, which will be affected by the accuracy
of traditional log parsing approaches because most log parsing
approaches cannot achieve high accuracy based on a small
number of logs.

III. DESIGN

In this section, we introduce the overall framework of our
proposed LogStamp. The overview of the framework is shown
in Fig. 2. We ﬁrst present the ofﬂine part in our workﬂow in
Section III-B, then we will describe the online part in detail
in Section III-A.

A. Ofﬂine workﬂow

Given a set of historical logs, our goal is to build a tagger to
identify if the incoming log is a template or variable. Previous
works [9] use the template extraction method to obtain the
templates from the logs. Then, a word classiﬁer (i.e., SVM
classiﬁer) is adopted to label each word in the logs. There
are two drawbacks to such methods. First, the accuracy of
labeling depends on the quality of the extracted template. If the
template extraction method fails to separate the templates from
the raw logs, the pseudo label assign by the classiﬁer would
be meaningless and cause failure on log parsing. Secondly,
prior works only utilize templates to train the word classiﬁer.
Generally, log data contains critical information on both word-
level and sentence-level (i.e., sentence order). For example,
in log anomaly detection task, a common way to detect the
anomalous logs in the log data is to see if the log orders are
correct. If we have received a log says that ”Vlan-Interfenerce
ae, change state to up” and no message of ”Vlan-Interfenerce
ae, change state to down” is followed in a certain time period,
we will recognize such log as anomalous log. And because the
word-level embedding only focus on the single word, it fails

Fig. 2. The workﬂow of LogStamp

to effective parse such logs .Therefore, learning logs feature
from the sentence level is important.

In this paper, we introduce a coarse to the ﬁne framework
to generate accurate pseudo labels. First of all, a pretrained
the feature
transformer is adopted to extract
bidirectional
representation of log data. Because the structure of raw logs
is different from the natural language, we need to ﬁnetune
the BERT [21] using our data. Note that ﬁnetuning the BERT
does not need any label. Then we use a dual-path framework
to get both coarse level embedding and ﬁne level embedding.
On the coarse level, we expect the sentence embedding can
reﬂect the nature of different logs. For instance, the above
example of two logs have similar structure, and most of the
words in these two logs are the same. However, the meaning
of these two logs are completely different. The coarse level
feature learns the inherent relations between the words, thus
output two embeddings with distant similarity. The sentence
embedding can be further group into number of clusters.

In general, one can exploit any clustering algorithm that can
split the sentence into clusters according to their embedding
features. Our approach is to use DBSCAN [22]. After we get
the clusters, we count the frequency of word appearance in
each clustering. We mark it as template if the number of
appearance is larger than the threshold, variables otherwise.
As such, we obtain the labels for each word.

For the ﬁne-grained level, we used the ﬁnetuned BERT to
output word embeddings. For each word embedding, we have
its corresponding label from the step above. Given a set of
word embeddings and word labels, we can train a classiﬁer
that serves as a tagger. As we trained via a deep neural
network, this tagger can accurately parse the logs without the
interference introduced by the wrong pseudo labels.

B. Online workﬂow

In real-time systems, systems may generate new log tem-
plates online; therefore, building a robust online workﬂow is
critical for real scenario deployment. Our online workﬂow is
simple. Given real-time logs, which can be either a piece of
logging information or a set of new logs, we reuse the BERT
model to extract the word embedding from the new logs. Then
the tagger that is trained in the ofﬂine stage will predict a label

TABLE I
DETAIL OF THE DATASETS

Datasets

Description

HDFS
Proxiﬁer
ZooKeeper
BGL
Hadoop

Hadoop distributed ﬁle system
Proxiﬁer software
ZooKeeper service
Blue Gene/L supercomputer
Hadoop MapReduce job

for the logs. As a result, we can immediately know whether
the speciﬁc words are templates or variables. We will show
that our online framework is simple yet surprisingly effective
under most of the circumstance.

IV. EVALUATION

In this section, we evaluate our approach using public log
datasets and aim to answer the following research questions:

• RQ1: How effective is LogStamp in log parsing?
• RQ2: Can LogStamp achieve accurate results based on a

small amount of log data?

• RQ3: How much can the BERT and tagger contribute to

the overall performance?

A. Experiment Setting

In this section, we evaluate the performance of LogStamp.
The datasets, baselines, evaluation metrics and experimental
setup of the experiments are as follows.

1) Datasets: We conduct experiments over ﬁve public log
datasets from distributed systems, which are BGL [1], HDFS
[23], ZooKeeper [24], Proxiﬁer [1] and Hadoop [14]. The
detailed information of these datasets is listed in Table I.
For each dataset, [1] sampled logs and manually labelled
each log’s template, which serves as the ground truth for our
evaluation.

To

2) Baselines:

of
demonstrate
LogStamp, we have implemented ﬁve template extraction
methods: FT-tree [16], Drain [20], Spell [15], LogSig [19],
LogParse [9], MoLFI [25] and IPLoM [17] . The parameters
of these methods are all set best for accuracy. LogParse [9]

performance

the

Sequence labelingOfflineOnlineBERTClusteringWordembeddingSentenceembeddingLabelsTaggerTemplatesVariablesHistoricallogsRealtimelogsBERTFig. 3. Comparison of the accuracy of ofﬂine log parsing between LogStamp and six baselines when they are trained by all ofﬂine logs

Fig. 4. Comparison of the accuracy of online log parsing between LogStamp and seven baselines when they are trained by 10% ofﬂine logs

can incorporate any existing template extraction method, our
paper utilized Spell to initialize LogParse.

4) Experimental Setup: We conduct experiments on a
Linux server with Intel Xeon 2.40 GHz CPU and 64G memory.

For BERT, we use three versions of BERT, i.e., BERT-
base, BERT-tiny and BERT-small. For tagger in LogStamp, we
compare the performances of GCN, CNN, LSTM and RNN.
3) Evaluation Metrics: We apply RandIndex [26] to
quantitatively evaluate the accuracy of template extraction.
RandIndex is a popular method for evaluating the similarity
between two data clustering techniques or multi-class classi-
ﬁcations. What’s more, RandIndex is applied to evaluating
existing template extraction methods in the literature, such as
in [9].

For each template extraction method, we evaluate its ac-
curacy by calculating the RandIndex between the man-
ual classiﬁcation results and the templates learned by it.
Speciﬁcally, among the template learning results of a spe-
ciﬁc method, we randomly select two logs, i.e., x and y,
and deﬁne T P, T N, F P, F N as follows. T P : x and y are
manually classiﬁed into the same cluster and they have the
same template; T N : x and y are manually classiﬁed into
different clusters and they have different templates; F P : x
and y are manually classiﬁed into different clusters and they
have the same template; F N : x and y are manually classiﬁed
into the same cluster and they have different templates. Then
RandIndex can be calculated using the above terms as
follows: RandIndex =

T P +T N
T P +T N +F P +F N .

B. Evaluation Results

1) RQ1: How effective is LogStamp in log parsing?
We ﬁrst compare accuracies of existing log parsing meth-
ods1 and LogStamp when extract template from historical logs.
The comparison results are shown in Fig. 3. We ﬁnd that most
log parsing methods are highly accurate in extract templates
from historical logs. However, the accuracy of existing parsers
the selection of
is not always consistent. In other words,
log data impacts the parsing accuracy [1]. Parsers may have
a good evaluation result with up to 90% of accuracy and
an unacceptable bad outcome down to 50% depending on
different input datasets (e.g., Proxiﬁer). Meanwhile, we ﬁnd
LogStamp still achieves high accuracy (the average accuracy
is more than 0.999) on different datasets. Therefore, we can
directly use the label results to train a tagger.

To demonstrate the performance of LogStamp in supporting
online parsing and simulate the launch of new services, for
each dataset, we apply each log parsing method to extract
templates from 10% of their logs. Fig. 4 shows the comparative
results. LogStamp achieves the best performance. Speciﬁcally,
the accuracy of LogStamp on each dataset is 0.956.

1LogParse’s ofﬂine step utilized other log parsing methods. It doesn’t have

its own ofﬂine parsing.

TABLE II
OFFLINE ACCURACY OF LOGSTAMP WITH DIFFERENT BERT VERSIONS

TABLE IV
ONLINE ACCURACY OF LOGSTAMP WITH DIFFERENT TAGGERS

Methods

Datasets
HDFS Proxiﬁer Zookeeper BGL Hadoop

Methods

Datasets
HDFS Proxiﬁer Zookeeper BGL Hadoop

BERT-tiny 0.9999 0.9356
BERT-base 0.9999 0.9836
BERT-small 0.9999 0.9840

0.9998
0.9998
0.9998

0.9950 0.9988
0.9994 0.9987
0.9979 0.9988

GCN 0.8888 0.9042
RNN 0.9822 0.9180
LSTM 0.9949 0.9998
CNN 0.9921 0.9164

0.9906
0.9790
0.9998
0.9998

0.9788 0.9762
0.9978 0.9962
0.9996 0.9974
0.9996 0.9974

TABLE III
ONLINE ACCURACY OF LOGSTAMP WITH DIFFERENT BERT VERSIONS

Methods

Datasets
HDFS Proxiﬁer Zookeeper BGL Hadoop

BERT-tiny 0.8888 0.9042
BERT-base 0.8798 0.9141
BERT-small 0.9147 0.8820

0.9906
0.9760
0.9851

0.9788 0.9762
0.9816 0.9637
0.9586 0.9752

2) RQ2: Can LogStamp achieve accurate results based

on a small amount of log data?

As shown in [1], the accuracy of existing parsers is not
always consistent, both for the datasets and the percentage of
training data. To demonstrate how stable LogStamp is to the
scale of training data, Fig. 5 shows the log parsing accuracy
of LogStamp on the ﬁve datasets, as the percentage of training
data increases from 10% to 90%, respectively. The results
show that LogStamp is stable to different scales of training
logs and can achieve high log parsing accuracy when trained
based on a small scale of training data.

3) RQ3: How much can the BERT and tagger contribute

to the overall performance?

LogStamp incorporates two modules: BERT and taggers.
In this RQ, we evaluate the effectiveness of different version
of each module. Firstly, we compare LogStamp with BERT-
base, BERT-small and BERT-tiny. Table II and Table III show
the performance of LogStamp in the ofﬂine stage and the
online stage, respectively. We ﬁnd that three versions of BERT
achieve similar performance, which means that LogStamp
doesn’t need to spend time adjusting the effect of BERT. Then,
in Table IV, we compare LogStamp with different taggers, i.e.,
GCN, RNN, LSTM and CNN. We ﬁnd that LSTM achieves
the best performance on all datasets. Because LSTM is more
suitable to natural language processing, and sequence labelling
is a problem in natural language processing.

V. DISCUSSION AND FUTURE WORK

Thanks to BERT for its powerful ability to capture both
sentence embedding of log sentences for clustering and word
embedding for distinguishing between templates and variables
in log. However, during experiments,
is observed that
syntactic structure and semantic information contained in log
sentences often vary considerably compared to those sentences
used to train BERT. One deduction is that if the BERT model
is ﬁne-tuned on log datasets with masked language modeling,

it

Fig. 5. The log parsing accuracy of LogStamp as the ratio of training data
changes

it might better understand log sentences and thus have higher
accuracy in ofﬂine and online log parsing. Yet, the experiment
result does not prove the deduction to be correct. By ﬁne-
tuning the BERT model with log sentences of each system for
1-3 epochs, the online clustering rand index does not seem to
be steadily improved.

We will continue to study how to apply better pre-trained
language models to log template extractions in our future
work. More abundant logs will be used to ﬁne-tune BERT or
to train a BERT from the beginning instead of directly loading
weights of model pre-trained with dissimilar vocabularies, e.g.,
from Wikipedia or books. Besides, as log sentences usually
have a more uniﬁed structure, we will also attempt to design
a more concise model structure based on BERT to achieve
higher efﬁciency in online log parsing to deal with higher
concurrency.

VI. CONCLUSION

In this paper, we propose LogStamp, an online log parsing
approach. Different from the prior log parsing approach,
LogStamp takes semantic into consideration and turns the log
parsing problem into a sequence labelling problem. LogStamp
supports a training model based on a small number of his-
torical logs. Experimental results on public log datasets have
validated the accuracy and stability of LogStamp.

10%20%30%40%50%60%70%80%90%The ratio of training data0.50.60.70.80.91.0RandIndexHDFSProxifierZookeeperBGLHadoopREFERENCES

[1] Jieming Zhu, Shilin He, Jinyang Liu, Pinjia He, Qi Xie,
Zibin Zheng, and Michael R Lyu. Tools and benchmarks
for automated log parsing. In Proceedings of the 41st In-
ternational Conference on Software Engineering(ICSE),
pages 121–130, 2019.

[2] Weibin Meng, Federico Zaiter, Yuheng Huang, Ying
Liu, Shenglin Zhang, Yuzhe Zhang, Yichen Zhu, Tianke
Summarizing
Zhang, En Wang, Zuomin Ren, et al.
arXiv preprint
unstructured logs in online services.
arXiv:2012.08938, 2020.

[3] Subhendu Khatuya, Niloy Ganguly, Jayanta Basak, Mad-
humita Bharde, and Bivas Mitra. Adele: Anomaly
detection from event log empiricism. IEEE Conference
on Computer Communications (INFOCOM), 2018.
[4] Weibin Meng, Ying Liu, Yichen Zhu, Shenglin Zhang,
Dan Pei, et al. Loganomaly: Unsupervised detection
of sequential and quantitative anomalies in unstructured
logs. In Proceedings of the Twenty-Eighth International
Joint Conference on Artiﬁcial Intelligence, IJCAI-19.,
volume 7, pages 4739–4745, 2019.

[5] Yichen Zhu, Weibin Meng, Ying Liu, Shenglin Zhang,
Tao Han, Shimin Tao, and Dan Pei. Unilog: Deploy one
model and specialize it for all log analysis tasks. arXiv
preprint arXiv:2112.03159, 2021.

[6] Shenglin Zhang, Ying Liu, Weibin Meng, Zhiling Luo,
Jiahao Bu, Sen Yang, Peixian Liang, Dan Pei, Jun
Preﬁx: Switch failure pre-
Xu, Yuzhi Zhang, et al.
the
diction in datacenter networks.
ACM on Measurement and Analysis of Computing Sys-
tems(SIGMETRICS), 2(1):2, 2018.

Proceedings of

[7] Satoru Kobayashi, Kensuke Fukuda, and Hiroshi Esaki.
Mining causes of network events in log data with causal
inference. In 2017 IFIP/IEEE Symposium on Integrated
Network and Service Management (IM), pages 45–53.
IEEE, 2017.

[8] Hetong Dai, Heng Li, Che Shao Chen, Weiyi Shang, and
Tse-Hsun Chen. Logram: Efﬁcient log parsing using
IEEE Transactions on Software
n-gram dictionaries.
Engineering, 2020.

[9] Weibin Meng, Ying Liu, Federico Zaiter, Shenglin
Zhang, Yihao Chen, Yuzhe Zhang, Yichen Zhu,
En Wang, Ruizhi Zhang, Shimin Tao, et al. Logparse:
Making log parsing adaptive through word classiﬁcation.
In 2020 29th International Conference on Computer
Communications and Networks (ICCCN), pages 1–9.
IEEE, 2020.

[10] Jinyang Liu, Jieming Zhu, Shilin He, Pinjia He, Zibin
Zheng, and Michael R Lyu. Logzip: Extracting hidden
structures via iterative clustering for log compression.
In 2019 34th IEEE/ACM International Conference on
Automated Software Engineering (ASE), pages 863–873.
IEEE, 2019.

In ACM Sigops
problems by mining console logs.
Symposium on Operating Systems Principles, pages 117–
132, 2009.

[12] Weibin Meng, Ying Liu, Shenglin Zhang, Federico
Zaiter, Yuzhe Zhang, Yuheng Huang, Zhaoyang Yu,
Yuzhi Zhang, Lei Song, Ming Zhang, et al. Logclass:
Anomalous log identiﬁcation and classiﬁcation with par-
tial labels. IEEE Transactions on Network and Service
Management, 2021.

[13] Steven Locke, Heng Li, Tse-Hsun Peter Chen, Weiyi
Shang, and Wei Liu. Logassist: Assisting log analysis
through log summarization. IEEE Transactions on Soft-
ware Engineering, 2021.

[14] Qingwei Lin, Hongyu Zhang,

Jian-Guang Lou,
Yu Zhang, and Xuewei Chen. Log clustering based
In
problem identiﬁcation for online service systems.
Proceedings of
the 38th International Conference
on Software Engineering Companion (ICSE), pages
102–111. ACM, 2016.

[15] Min Du and Feifei Li. Spell: Streaming parsing of system
event logs. In 2016 IEEE 16th International Conference
on Data Mining (ICDM), pages 859–864. IEEE, 2016.

[16] Shenglin Zhang, Weibin Meng, Jiahao Bu, Sen Yang,
Ying Liu, Dan Pei, Jun Xu, Yu Chen, Hui Dong, Xi-
anping Qu, et al. Syslog processing for switch failure
diagnosis and prediction in datacenter networks. In 2017
IEEE/ACM 25th International Symposium on Quality of
Service (IWQoS), pages 1–10. IEEE, 2017.

[17] Adetokunbo AO Makanju, A Nur Zincir-Heywood, and
Evangelos E Milios. Clustering event logs using iterative
partitioning. In Proceedings of the 15th ACM SIGKDD
international conference on Knowledge discovery and
data mining, pages 1255–1264. ACM, 2009.

[18] Yichen Zhu and Yi Wang. Student customized knowl-
edge distillation: Bridging the gap between student and
teacher. In Proceedings of the IEEE/CVF International
Conference on Computer Vision, pages 5057–5066, 2021.
[19] Liang Tang, Tao Li, and Chang-Shing Perng. Logsig:
Generating system events from raw textual logs.
In
Proceedings of the 20th ACM international conference
on Information and knowledge management, pages 785–
794. ACM, 2011.

[20] Pinjia He, Jieming Zhu, Zibin Zheng, and Michael R
Lyu. Drain: An online log parsing approach with ﬁxed
In 2017 IEEE International Conference on
depth tree.
Web Services (ICWS), pages 33–40. IEEE, 2017.
[21] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. Bert: Pre-training of deep bidirec-
tional transformers for language understanding. arXiv
preprint arXiv:1810.04805, 2018.

[22] Martin Ester, Hans-Peter Kriegel, J¨org Sander, Xiaowei
Xu, et al. A density-based algorithm for discovering
In Kdd,
clusters in large spatial databases with noise.
volume 96, pages 226–231, 1996.

[11] Wei Xu, Ling Huang, Armando Fox, David Patterson,
and Michael I. Jordan. Detecting large-scale system

[23] Wei Xu, Ling Huang, Armando Fox, David Patterson,
and Michael Jordan. Largescale system problem detec-

tion by mining console logs. Proceedings of SOSP’09,
2009.

[24] Shilin He, Jieming Zhu, et al. Experience report: System
In 2016 IEEE
log analysis for anomaly detection.
27th International Symposium on Software Reliability
Engineering (ISSRE), pages 207–218. IEEE, 2016.
[25] Salma Messaoudi et al. A search-based approach for ac-
curate identiﬁcation of log message formats. In Proceed-
ings of the 26th Conference on Program Comprehension,
pages 167–177. ACM, 2018.

[26] William M Rand. Objective criteria for the evaluation of
clustering methods. Journal of the American Statistical
association, 66(336):846–850, 1971.

