2
2
0
2

p
e
S
6
2

]

R
C
.
s
c
[

3
v
1
3
1
6
0
.
4
0
2
2
:
v
i
X
r
a

Timeloops: Automated System Call Policy Learning for Containerized
Microservices

Meghna Pancholi
meghna@cs.columbia.edu
Columbia University

Andreas D. Kellas
andreas.kellas@cs.columbia.edu
Columbia University

Vasileios P. Kemerlis
vpk@cs.brown.edu
Brown University

Simha Sethumadhavan
simha@columbia.edu
Columbia University

Abstract
We introduce TIMELOOPS, a novel technique for automati-
cally learning system call ﬁltering policies for containerized
microservices applications. At run-time, TIMELOOPS auto-
matically learns which system calls a program should be al-
lowed to invoke, while rejecting attempts to call spurious sys-
tem calls. Further, TIMELOOPS addresses many of the short-
comings of state-of-the-art static analysis-based techniques,
such as the ability to generate tight ﬁlters for programs written
in interpreted languages such as PHP, Python, and JavaScript.
TIMELOOPS has a simple and robust implementation because
it is mainly built out of commodity, and proven, technologies
such as seccomp-BPF, systemd, and Podman containers. We
demonstrate the utility of TIMELOOPS by learning system
calls for individual services and two microservices benchmark
applications, which utilize popular technologies like Python
Flask, Nginx (with PHP and Lua modules), Apache Thrift,
Memcached, Redis, and MongoDB. Further, the amortized
performance of TIMELOOPS is similar to that of an unhard-
ened system, while producing a smaller system call ﬁlter than
state-of-the-art static analysis-based techniques.

1 Introduction

Microservices have become prominent due to shifts from
monolithic to modularized and distributed architectures.
While monoliths are complex and large services running on
a single host, microservices are lightweight, loosely-coupled
services running in a distributed fashion. Inter-service net-
work communication allows these small components, which
are typically containerized, to collaborate and complete ac-
tions that would previously be completed by a single mono-
lith. Microservices have become a popular choice due to their
modularity, which simpliﬁes the development of large appli-
cations, allows for elastic scaling, and supports language and
framework heterogeneity. More importantly, microservice de-
ployments are quickly rising in popularity: surveys conducted
by O’Reilly in 2020 concluded that 77% of tech companies
have adopted this model for computing [46].

Microservice deployments, however, introduce two main
complexities that make security challenging: (1) Dynamism:
graphs of microservices architectures evolve rapidly due to
new application features [28], making it difﬁcult to keep se-
curity policies up to date; (2) Heterogeneity: each service
in an application can be developed by different teams in dis-
similar programming languages, and hosted on completely
different platforms, sometimes across data centers, increasing
the attack surface. These challenges are also compounded to
a degree by the need to provide low end-to-end latency. In the
absence of good security protection for microservices, there
is risk not only of application compromises but also a risk to
other tenants via container escape attacks [41].

State-of-the art efforts for securing a microservice in indus-
try and academia focus on two main techniques for protecting
microservices: (a) Rootless containers: increasingly contain-
ers offer rootless deployment options that permit containers
to be run as unprivileged users—this raises the bar to gain
privileged execution on a system via a compromised microser-
vice; (b) System call ﬁltering: even with rootless containers,
compromised microservices can be used to gain privileges via
the system call API. As such, system call ﬁltering is used to
conﬁne the process’ ability to make arbitrary system calls, or
invoke buggy ones [42], thus mitigating this risk [9,30,37,55].
An added beneﬁt of system call ﬁltering is that it does not
signiﬁcantly impact the latency of the microservice.

In this paper, we propose a new method for securing mi-
croservices called TIMELOOPS. We designed TIMELOOPS
with microservices’ strengths and weaknesses in mind. For
each service in a microservices application, the TIMELOOPS
technique relies on three components for learning legitimate
system calls: (1) a production service, (2) an oracle service,
and (3) a TIMELOOPS controller. The production service is
an unhardened service that is tuned for low latency, while the
oracle service is a hardened service that is tuned for security.
An example of an oracle service could be a microservice run-
ning with compiler-inserted, runtime checks to protect against
memory safety errors. The high level idea is to sparingly use
the oracle service to decide if a system call should be added to

1

 
 
 
 
 
 
the allow list. This provides the security guarantees of a hard-
ened microservice without constantly incurring the overheads
associated with hardening.

Compared to state-of-the-art microservice

security
two unique advantages:
techniques, our solution has
(i) TIMELOOPS is language agnostic, since microservice
deployments tend to be heterogeneous with services written
in different languages. Traditional system call ﬁltering
approaches that use static analysis to create ﬁlters [17, 31]
require writing custom tools for each language. This increases
the difﬁculty of applying these methodologies to modern
cloud microservices—TIMELOOPS avoids this problem
completely. (ii) TIMELOOPS offers a tighter set of system
call constraints that is customized to each service. Unlike
static analysis systems, TIMELOOPS learns the system calls
required per service using runtime workloads and therefore
produces a much tighter set.

Using these components we measure both the security and
performance of our TIMELOOPS system. We observe that the
amortized performance of a TIMELOOPS-protected system
is similar to that of an unhardened, insecure system, and our
approach nearly eliminates all the performance overheads
associated with hardening. In terms of the tightness of the
system call ﬁltering set, we show that a state-of-the-art static
analysis tool generated system call sets that were 32.7% larger
than the ones generated by TIMELOOPS. Additionally, we
demonstrate that TIMELOOPS succeeds in creating system call
ﬁlters for interpreted languages with very little effort, which
is a challenge for existing static analysis-based techniques.
Finally, as a side effect, we show that we can easily detect
memory corruption-based exploits while taking place.

The remainder of this paper is organized as follows. In
Section 2, we provide the necessary background informa-
tion and present our threat model. In Section 4, we introduce
TIMELOOPS, a novel approach for learning new security poli-
cies, which leverages runtime exploit detection techniques,
while providing amortized runtime performance overhead.
We consider the security architecture of TIMELOOPS in Sec-
tion 6, and evaluate our prototype’s runtime performance and
ﬁlter learning correctness in Section 7. We discuss related
work in Section 8, and conclude our work in Section 10.

2 Background and Threat Model

2.1 Microservices Overview

Microservices Microservices have become a de facto stan-
dard for building and deploying web-based services. Building
software as a set of communicating lightweight processes
allows multiple teams to work independently on small in-
dividual units of code—i.e., microservices—that can then
be combined together using only API calls exposed by the
service [27]. For example, if we consider the set of services
running in Figure 1, a team may be responsible for maintain-

Figure 1: Microservices applications are the composite of
diverse containers communicating to perform a task. They
are scheduled to run on various multitenant hosts with other
potentially malicious containers. Most of these services are
stateless and are scaled and restarted on demand.

ing Service 1, independently, while another team may manage
Services 3 and 4 without needing to understand the imple-
mentation details of the other services. The development of
microservice-based applications has been made easier by the
use of popular languages and libraries, like Python, Thrift, and
Node.js. Microservice environment management has become
conﬁgurable and reproducible through container technologies,
like Docker and Podman. Cloud platforms like Amazon EC2,
Google Cloud Platform, and Microsoft Azure have made de-
ployments easy to schedule and dynamically scale.

Since microservices are typically deployed in multitenant
cloud environments, they have to be written in a manner that
makes them resilient to crashes and long-latency inducing
events such as network congestion. A very common design
pattern is to write these microservices in a stateless manner
with retry semantics i.e.,, in a manner that does not preserve
state across requests and that produces correct results even
when multiple repeated queries are issued by a client. In fact,
most cloud deployments today isolate the stateless frontend,
routing, or computation services from the stateful database or
caching services, where service crashes and restarts do not af-
fect the correct behavior of the (composite) system. To ensure
successful execution of their requests despite frequent restarts
and long-latency events, clients will often resend identical,
idempotent requests until the requests are satisﬁed.

While the modularity of microservices has enabled many
desirable software engineering practices, like rapid feature
development, and continuous integration/delivery (CI/CD),
it has also created some serious security challenges. It is not
uncommon today to have deployed applications with hun-
dreds or even thousands of microservices [23], written in
many different languages, such as Python, PHP, Javascript,

2

Cloud Host 3Cloud Host 2Cloud Host 1Frontend (Nginx)Service 1 (Golang)Service 3(Python)Service 2(C/C++)Service 1(Golang)Frontend (Nginx)CacheDBAttackerOtherContainerOtherContainerStateless StatefulService 4(Java)OtherContainerC/C++, Rust, Go, etc. Frequent changes to these software
pieces rules out manually writing security policies because
expected behavior is hard to deﬁne in such a constantly chang-
ing environment; on the other hand, code analysis techniques
to understand application behavior are less effective in the
presence of excess library code and with interpreted languages
such as Python and Javascript. Besides, multiple microser-
vice applications can run in a multitenant manner, on a single
host, on a cloud with no guarantees about the services run-
ning alongside any given container. Container escape vulner-
abilities and lateral movement attacks pose huge threats to
deployments of this style [22, 56].

Exploitation and Mitigations When attackers attempt
to execute code in a container’s application—i.e., a
microservice,—they are limited by the isolation boundaries
established by the container runtime such as namespaces or
control groups (cgroups) [57]. However, attackers can some-
times “escape” from the container’s environment, and this
allows them to potentially access system resources [19] or
escalate their privileges.

In order for an attacker to gain arbitrary code execution
and execute system calls for nefarious purposes, in reason-
ably secure microservices, they often must exploit a vulner-
ability in the microservice. To prevent exploitation, a wide
range of research proposals that aim at hardening applica-
tion code, using runtime veriﬁcation and enforcement mecha-
nisms [16,40,64,65], can also be applied to microservices. For
example, SoftBound [51] and CETS [52], as well as Address-
Sanitizer (ASan) [61], provide detection of memory-safety-
related issues (e.g., out-of-bounds accesses and uses of freed
objects). However, these software techniques have fairly high
overhead ranging from 70% to 300% depending on the level
of protection. Due to these high overheads, many of them
are usually employed in security auditing and testing envi-
ronments and not in production deployments, which tend to
be latency sensitive—more so for microservices that rely on
expensive network calls for communication.

Because runtime vulnerability mitigation cannot be used
for microservices, to prevent container escapes, low overhead
mitigation techniques are typically used. A very popular
method is to use seccomp-BPF to restrict the system calls
available to a container application [30, 37]. Common con-
tainer implementations (e.g., Docker, Podman) allow easy in-
stallation of seccomp-BPF ﬁlters and even provide a default
ﬁlter that removes access to 44 system calls for all contain-
ers. The container seccomp-BPF interface can be leveraged
to customize and further restrict the system calls available to
an microservice executing in a container [26].

2.2 System Call Filtering

The system call (syscall) interface enables user-space appli-
cations to request privileged services from OS kernel. This
interface is quite large: for example, the Linux kernel (v5.x)

provides ≈350 syscalls to user-space applications [25]. Like
most programs, microservices only need a subset of these
syscalls for proper execution [17, 18, 25, 30, 31, 37]. An at-
tacker, however, who is able to leverage a vulnerability in a
microservice to gain arbitrary code execution can use any of
the available syscalls, effectively (1) violating the principle
of least privilege and (2) further (ab)using vulnerabilities in
less-stressed kernel code paths to escalate privilege [42]. By
restricting the system calls available to a microservice, an
attacker is constrained to only performing actions that fall
within the benign behavior(s) of the victim program.

Determining which system calls should be allowed for a
microservice is challenging. Policies can be created man-
ually, but with signiﬁcant developer effort [26]. Therefore,
attempts to synthesize policies automatically have become
more prevalent [17, 25, 30, 31, 37]. Current approaches for
automatically generating system call policies oftentimes use
either static or dynamic analyses (or a combination thereof).
Static analyses attempt to reason about the system calls that a
target program should be allowed to execute without execut-
ing the program [25, 30, 31]. These approaches are generally
over-approximate in their analyses because they explore all
possible code paths a program may execute. Dynamic anal-
yses typically execute the target program with some set of
known-safe training inputs, like developer-written tests, in
order to record all executed system calls and to populate an
allow-list from them [17, 37]. These approaches are generally
under-approximate, because they are only able to identify
system calls that are observed during execution of training
data, and fail when a new legitimate system call is executed.

For both static and dynamic system call policy extraction,
current approaches for syscall extraction and enforcement
create immutable policies that cannot be later reﬁned. In an
immutable system, when the target program attempts to exe-
cute a non-allowed system call, the enforcing mechanism will
terminate the program in order to prevent potential exploita-
tion. This occurs at the risk of the system call being the result
of a safe input that was incorrectly omitted from the training
data—i.e., a false positive. In order for it to be ﬂexible enough
to update its policy once deployed, the system must be able to
distinguish the execution of syscalls that result from benign
and offending inputs at runtime.

Once a system call policy is created in the form of an
allow- or deny-list, it must be enforced. The Linux kernel
provides the ‘SECure COMPuting’ (seccomp) mode that al-
lows users to restrict the system calls that a process is allowed
to make [44]. With custom BSD Packet Filters (BPF) [49],
seccomp-BPF allows a user to conﬁgure the behavior of the
kernel when the user-space process makes a non-allowed sys-
tem call; for example, the kernel can be conﬁgured to send a
SIGKILL or SIGSYS signal to the process, depending on the
arguments provided via the seccomp-BPF interface, log the
event to an audit log, etc. [68].

3

2.3 Threat Model

In this work, we consider an attacker who is able to gain re-
mote code execution in victim network applications. That is,
the attacker can provide inputs to a program over a network
connection to exploit vulnerabilities in the program and intro-
duce new, unintended code or behavior in the victim process.
Our model assumes that the attacker does not have physical
access to the host machine and considers side-channel [39,45]
and fault [50, 66] attacks out-of-scope.

In our model, the victim application executes in a container
environment that is isolated from the host system resources, so
we consider that the attacker is motivated to “escape” from the
container by using remote code execution to remove the iso-
lation between the victim application and the host resources.
The attacker is able to exploit some vulnerability or misconﬁg-
uration to execute code in the container process [65], and may
desire to escape the container environment or compromise the
container application for malicious purposes via executing
arbitrary system calls [11, 19, 42]. Our threat model is in par
with prior work in the area [17, 18, 25, 31].

3 Approach Overview

For a system to be able to learn a security policy at runtime,
it must be able to determine whether a violation of the cur-
rent policy is the result of a benign input that was previously
unseen or the result of an offending input that should be pre-
vented by the policy. In this section, we describe a novel
approach for learning software security policies by introduc-
ing an oracle to assist with determinations of safe inputs.

Our policy learning approach provides a mechanism to
learn from policy violations. When a violation occurs after
the program executes a speciﬁc input, we consult the oracle
service by providing it with the current policy and input, and
re-execute the program under the oracle’s observation. The
oracle makes a determination that the security policy violation
occurred either because of a benign input to the program
or because of offending input to the program. If the oracle
determines that the policy violation was due to a benign input,
then the policy is updated to allow the event that was observed,
and the program can be restarted with the updated policy. If
the oracle determines that the policy violation was due to
offending input, then an exploit attempt was prevented and an
alert is raised accordingly.

For this approach to succeed, the program must be resilient
to repeated re-executions from a known state, whether from
the program start or from some checkpoint location. We ob-
serve that network services, and in particular, microservices,
are often designed to be stateless and support the re-execution
of idempotent request operations. Because of this, we can
take advantage of retry semantics or we can record and re-
play requests without affecting the correctness of the entire
application’s state. For engineering simplicity, we assume

Figure 2: The TIMELOOPS controller initializes by starting
the production version of the service container, which ser-
vices incoming requests. When a system call violation occurs,
(1) the service container is killed by a signal sent from the host
OS, and then (2) the TIMELOOPS controller starts the oracle
container. The oracle container executes a hardened version
of the service, which receives the next incoming request and
determines whether it is a safe or offending input. The oracle
makes a determination and exits, and (3) the TIMELOOPS
controller uses the oracle’s determination to decide how to
update the policy. The controller starts the service container
with the most recently updated system call policy.

that retry semantics exist and our application’s clients resend
requests until they succeed. These types of services can be
re-executed and are thus good candidates for a timelooping
security policy learning approach.

4 Design and Implementation

In this section, we describe the design and implementation
of the TIMELOOPS system, which learns systems call poli-
cies on-the-ﬂy, as the programs execute, thereby including
only system calls that are actually observed and detecting
malicious behavior when a new system call is introduced.
The sequence of events that occur when a service running
in TIMELOOPS receives an input that causes a system call
violation is illustrated in Figure 2.

4.1 System Call Policy Learning

The TIMELOOPS system is designed as three main compo-
nents: (1) the service, (2) the oracle, and (3) the controller.
Both the service and oracle are deployed in their own isolated
container environments, while the controller is responsible for
managing the execution of the service and oracle containers
and for applying policy changes as information is learned.

The TIMELOOPS controller begins execution by starting
the service container with some default policy of allowed
syscalls (which may be initialized as an empty list). If, given
some input, the service container attempts to execute a syscall
that is not in the allow-list, the service is forced to exit and
the controller is notiﬁed. The controller then starts the oracle

4

ContainerRuntimeHOST OSApplicationSystemDaemonSeccompFilterRequestNormal Operation "production" 123ContainerRuntimeHOST OSApplicationSystemDaemonSeccompFilterRequestNew SyscallKILLApplicationContainerRuntimeHOST OSSystemDaemonSeccompFilterRequestLearning and AttackDetection "oracle"  container, which, in turn, starts the same service but with
additional runtime exploit mitigations deployed; for example,
the service can be compiled with ASan to act as an oracle for
some types of memory corruption-based exploits. Importantly,
the controller starts the oracle service with the same allow-list
of system calls that was applied to the service. Given the
same input, the oracle should either (1) exit due to the same
system call violation, or (2) exit due to an ASan abort. Case
(1) indicates that the code path taken to reach the system call
did not result in memory corruption, and so the offending
system call may safely be added to the allow-list—in this
case, the controller updates the policy and starts the original
service with the new policy. Case (2) indicates that prior to
reaching the new system call, a memory corruption violation
occurred, and that the input is unsafe.

To summarize, TIMELOOPS identiﬁes when a new system
call violates an existing policy, queries an oracle to determine
whether the input that caused the system call execution is
“safe” according to the runtime exploit detection features of
the oracle, and makes policy update decisions based on the
determination. An additional beneﬁt is that the runtime perfor-
mance overhead of executing a program with exploit detection
and mitigations applied occurs lazily, i.e., only when a system
call policy violation occurs. This means that in the critical
path of the program execution, the overall system executes
with the amortized runtime of the service, while still providing
the beneﬁts of executing exploit detection checks opportunis-
tically. We study and analyze the runtime performance of
TIMELOOPS in Section 5.

4.2 System Call Policy Enforcement

The service and oracle programs are isolated in their own con-
tainer environments, as we would see in typical microservices
deployments. This provides separation from system resources
and from the controller service that manages the security
policy. We use Podman containers [7] in the TIMELOOPS im-
plementation, which is an alternative to Docker, the most
popular container engine. Podman’s security advantage is its
daemonless architecture—unlike Docker, which uses a single
daemon executing with administrative privileges to manage
containers, Podman can create containers as non-root child
processes. Podman is compliant with the Open-Container
Initiative (OCI) standard, which makes it easy to use and com-
patible with existing Docker images. The TIMELOOPS con-
troller leverages these features to start and stop the service,
and oracle containers as systemd services.

Both Podman and other container runtimes provide support
for applying a seccomp-BPF ﬁlter to a container on start-up.
This functionality is enabled by the default ﬁlter [10] and
removes access to at least 44 system calls that can be abused
for container escape exploits, but which still leaves over 300
system calls available. We use the Podman feature to apply a
custom seccomp-BPF ﬁlter every time the TIMELOOPS con-

troller starts the service and oracle containers. In between
executions of the containers, the controller updates the ﬁlter,
but once a container is started with a given ﬁlter, the set of
syscalls that the container is allowed to execute is immutable
until the container exits (by the seccomp-BPF design).

4.3 System Calls Introduced by the Oracle

It is possible for the oracle container to execute system calls
that the original service did not. This occurs when the oracle’s
exploit detection mechanism introduces new system calls or
non-determinstic behavior takes place. To handle this, we
instruct our TIMELOOPS controller to add any system call
that the oracle encounters during execution to the allow-list,
assuming that the oracle does not detect exploitation prior to
the system call being executed. These system calls can be
trusted because the oracle is the determinant of safe inputs.
However, introducing these syscalls potentially causes our
allow-list to be looser than necessary and requires extra itera-
tions of TIMELOOPS learning, so ideally we want to choose a
hardening technique that provides strong security guarantees
without introducing many new system calls.

4.4 Retry-request Expectations

In the current TIMELOOPS implementation, the service may
receive an input that results in a system call violation, causing
the service to exit without handling the request. TIMELOOPS
then restarts the service container in the oracle and awaits
the next request. We expect the client to use retry semantics,
meaning that the client retries the request until successful.
These expectations also align with the behavior of clients
interacting with idempotent microservices often expect retry
semantics until a response conﬁrms success for robustness
and fault tolerance [24]. Additionally, the expectation that
identical messages are repeated does not introduce security
vulnerabilities in the TIMELOOPS system when the expec-
tation is not met—it only makes the system inefﬁcient. The
security implications of this are discussed further in Section 6.

4.5 Limitations of Policy Learning

In our implementation, we use ASan as the runtime exploit
detection technique for the oracle since it provides instru-
mentation for detecting runtime memory safety violations. To
create an oracle container for a given service, we use Clang
to compile the service’s code and dependencies with ASan.
Our ﬂexible design allows users to create oracle containers
hardened with other exploit detection techniques, customized
to their threat landscape. We opt for ASan since ≈70% of
CVEs each year are attributed to memory safety issues [67].
Our system determines when a new system call is the result
of a memory corruption exploit that ASan detects. However,
when a system call is introduced by an attacker via an exploit

5

or misconﬁguration that does not leverage a memory corrup-
tion vulnerability, TIMELOOPS will update the system call
policy to allow the new system call. Therefore, the scope of
the security policies that TIMELOOPS can learn is limited by
the abilities of the oracle. In Section 6.1, we discuss com-
plimentary approaches for maintaining the security of the
service container and the overall TIMELOOPS system in the
context of exploits beyond what the oracle can detect. We
also intend for the TIMELOOPS oracle model to be modular,
such that multiple oracle containers with different forms of
analyses can be deployed in parallel to alleviate some of the
pressure of ﬁnding one perfect hardening mechanism.

5 Evaluation Testbed

We conduct our analyses by executing four different applica-
tions in TIMELOOPS. Two applications are statically served
by Python Flask and Nginx, and two applications are the so-
cial network and media microservices benchmarks from the
DeathStarBench suite [28].

5.1 Python Flask

Flask is a popular Python web development framework used
in microservices. We developed a simple Flask application
that serves a static website over HTTP(S) to evaluate our
TIMELOOPS prototype. Flask applications are executed by
the Python interpreter and provide multi-threaded function-
ality. Many web applications are developed using similar
frameworks and interpreted languages, like PHP, Ruby, and
JavaScript. Since Python and its modules facilitate developing
web applications, or querying databases, easily, it is useful
for the rapid development of microservices, and thus has be-
come a popular choice for cloud developers and a suitable
application to evaluate TIMELOOPS [36].

5.2 Nginx and PHP

Nginx is a free and open-source web server that is used
by 32.9% of all websites, the largest of any available web
server [69]. It is often used as a gateway or load-balancer
to multi-tier microservices applications. We built a simple,
static website hosted by an Nginx server with PHP-FPM
integrations—PHP is used by 78.1% of websites where the
server-side language is known [70]. Both Nginx and PHP-
FPM use a forking server model that spawns worker processes
to handle connections. We evaluate TIMELOOPS with this ap-
plication to represent services that use multiple processes to
provide web content. Additionally, the PHP modules used in
this Nginx application rely on an interpreter which makes pre-
dicting its behavior difﬁcult, but suitable for our application
like the Python Flask application.

5.3 DeathStarBench Microservices

In order to evaluate TIMELOOPS in an environment represen-
tative of real-world microservices applications, we selected
applications from the DeathStarBench benchmark suite of mi-
croservices [28]. We speciﬁcally evaluated against the media
streaming benchmark, which models the structure of popular
media streaming services like Netﬂix, and the social network
benchmark, which models a social network site like Twitter.
Both applications depend on technologies used in real mi-
croservice deployments such as Memcached, Redis, Thrift,
MongoDB, and Nginx, and its services are written in a wide
variety of programming languages.

To deploy these services, we ran each each microservice
from a benchmark on a different Amazon EC2 instance [8],
similarly to how it might be deployed in practice. Each EC2
instance had its own TIMELOOPS controller setup and gener-
ated a unique ﬁlter for each service.

To evaluate the social media and media streaming applica-
tions, we use the workload generator provided by the bench-
mark suite. The workload generated for evaluation resulted in
the creation of many requests within the tiers of the microser-
vices application and required all services to undergo many
iterations of TIMELOOPS policy learning. This way, we en-
sured that this workload is suitable for not only performance
benchmarking, but also our TIMELOOPS security evaluation.

6 Security Evaluation

In this section, we consider the security features of
TIMELOOPS, and present the argument that it provides protec-
tion to a container application given reasonable assumptions
about the threat model considered.

6.1 Attacks Classiﬁcation

Given the presence of a remote attacker, as described in our
threat model (see Section 2.3), we classify attack scenarios
by considering whether the attacker invokes new system calls
and whether the attacker leverages oracle-detectable vulner-
abilities. The security of TIMELOOPS hinges on detecting
system call violations and detecting attacks with the oracle,
which is why we chose these components to rigorously ana-
lyze. These four attack categories are shown in Table 1, and in
this section we explain how the TIMELOOPS implementation
provides varying security beneﬁts in each attack scenario.

Category (1) attacks (oracle-detectable exploit that executes
a policy-violation system call) are detected and prevented
by the TIMELOOPS system, and TIMELOOPS provides the
strongest security beneﬁts against these attacks. When the
application container violates the system call policy as a result
of offending input, the oracle container will detect that the
input is an exploit trigger, prevent any changes to the security
policy, and alert an administrator.

6

Attacker Capabilities in TIMELOOPS vs. Static System Call Filtering

Oracle-Detectable
Vulnerability

Oracle-Undetectable
Vulnerability

New System Calls Executed
(1) TIMELOOPS always detects the
attack and stops execution, but static
system call ﬁltering can only do so
if ﬁlter is adequately tight.
(4) When TIMELOOPS is sup-
static-analysis-
plemented with
generated
ﬁlters, TIMELOOPS
security is equal to that of static
system call ﬁltering.

No New System Calls Executed
(2) The attacker is limited to using
the existing system call ﬁlter. The ﬁl-
ter is tighter with TIMELOOPS since
it only adds previously seen syscalls.

(3) The attacker is limited to using
the existing system call ﬁlter. The ﬁl-
ter is tighter with TIMELOOPS since
it only adds previously seen syscalls.

Table 1: TIMELOOPS provides strong security beneﬁts in comparison to previous works that rely on generating a static system
call ﬁlter. Static system call ﬁltering tools generate a ﬁlter prior to execution and only enforce that ﬁlter throughout application
execution. Our tight and incremental ﬁlter building process results in a smaller attack surface and restricts attacker capabilities
when a service is under attack.

Category (2) attacks (oracle-detectable exploit that does
not execute a policy-violation system call) and category (3)
attacks (oracle-undetectable exploit that does not execute a
policy-violation system call) are handled in the same way
by the TIMELOOPS. In these attack scenarios, TIMELOOPS’s
security beneﬁts are in line with the approach of enforcing
the Principle of Least Privilege (PoPL) [59], the goal of pre-
vious work in system call ﬁltering. Because the system call
policy is never violated in Category (2) and (3) attacks, the
oracle is never consulted, but an attacker is still severely lim-
ited in terms of its capabilities with respect to accessing the
system call API. Due to the tight system call policy learned,
the attacker is restricted to only invoking previously observed
system calls, thereby limiting attempts to compromise the
application or escape from the container. Unlike previous
works that create immutable lists that include all system calls
an application requires, TIMELOOPS is a signiﬁcant improve-
ment because system calls are conservatively added as they
are observed. Hence, the TIMELOOPS allow-list can be much
smaller than the set of all syscalls required by the application.

Category (4) attacks (oracle-undetectable exploit that exe-
cutes a policy-violation system call) may seem the most dan-
gerous to the TIMELOOPS system, but with relatively-simple
modiﬁcations, TIMELOOPS is able to prevent the execution
of arbitrary system calls. When an input from this attack cat-
egory is received, the oracle service is consulted to make a
determination on the input, but the oracle is unable to detect
an exploit. This grants attackers the ability to add any system
calls to the allow-list until a sufﬁcient set are available to
conduct an exploit. Therefore, to mitigate the chance of this
occurring, we propose two best practices when deploying an
application with TIMELOOPS. First, an oracle must be care-
fully chosen considering the application and the nature of its
vulnerabilities. Second, we can specify a list of system calls
that are known to be unnecessary and common in exploits and

Figure 3: Comparison of the number of system calls allowed
by static and dynamic system call ﬁltering, compared to
Timeloops.

prevent them from ever being added to our system call policy.
For example, an over-approximate static analysis tool or the
system calls in the default Docker and Podman seccomp-BPF
ﬁlter can be used to create this list. For stronger guarantees,
a static analysis-based technique for generating system call
ﬁlters can also be applied to create a list of system calls that
may never be included in the TIMELOOPS ﬁlter [25]. With
this mitigation, we see that TIMELOOPS security guarantees
are equal to those of static-analysis based techniques, but in
many most cases, much stronger.

6.2 System Call Policies

In addition to the qualitative analysis, we evaluated the quality
of the system call policies created by TIMELOOPS. To deter-
mine the effectiveness of TIMELOOPS for generating correct
and safe policies, we sought to determine the following:

1. How many fewer system calls does TIMELOOPS allow
than over-approximate static analysis techniques (RQ1)?

2. Which system calls do static analysis techniques allow

that are not allowed by TIMELOOPS (RQ2)?

7

Compose Post Service (SN)Text Service (SN)User Review Service (MM)Compose Review Service (MM)NginxPython Flask020406080100120Number of Syscalls Learned5252675585687674847911868454557467966Static Analysis (Sysfilter)TimeloopsDynamic Analysis (Syscall Auditing)3. Which system calls does TIMELOOPS allow that are not

allowed by static analysis techniques (RQ3)?

4. Which system calls does TIMELOOPS allow that would
not have otherwise be necessary for the application to
execute safely in a non-TIMELOOPS system (RQ4)?

To evaluate the system call policies, we generated sys-
tem call ﬁlters using static analysis, TIMELOOPS, and dy-
namic tracing. We chose sysfilter [25] to represent state-
of-the-art static analysis techniques for system call policy
creation. As a static analysis tool, sysfilter tends to be
over-approximate in its determinations. We used sysfilter
to generate syscall proﬁles for all our evaluated applications.
To generate our TIMELOOPS system call policies, we exe-
cuted each program it in the TIMELOOPS system with realistic
workloads that exercised the functionality of each service.

We additionally proﬁled the behavior of each evaluated
program by executing it in a container with seccomp RET_LOG
mode, which allows, but logs, each system call. We provided
a set of sample inputs to the proﬁled service and monitored
the system calls invoked. This technique can be considered
elemental dynamic analysis for generating system call ﬁlters.
This provided a baseline of system calls that the program
executes for a given input without the introduction of new
system calls from the TIMELOOPS system.
RQ1 For all evaluated programs, sysfilter created policies
that were at least as large as those created by TIMELOOPS. On
average, the sysfilter generated system call sets that were
32.7% larger than those generated by TIMELOOPS, meaning
that an attacker has access to approximately 32.7% more sys-
tem calls when exploiting a system defended by sysfilter
over one defended by TIMELOOPS, resulting in a larger attack
surface and capability set. Static approaches ignore the fact
that inputs modulate program behavior, at runtime, and esti-
mate the system call behavior solely based on static program
code, thus over-approximating the set of allowed system calls.
In contrast, our results demonstrate that TIMELOOPS is able
to tailor the system call list to speciﬁc inputs, and the degree
of difference shows the typical reduction in attack surface.
RQ2 When comparing system call policies, we can quan-
tify the size of the attack surface with the number of system
calls in a policy, but not all system calls are created equally.
Attackers do not need to access to every system call to be
successful; they frequently require only a speciﬁc subset of
system calls that is unique to the post-exploitation behavior
that they desire. This is difﬁcult to characterize, but in attempt
to do so, we will analyze the policies generated for two of
the services that we evaluated: Nginx and the ComposePost
service from the Social Network application.

For both the Nginx and ComposePost

services,
TIMELOOPS created smaller system call policies than
sysfilter. The TIMELOOPS ﬁlter for Nginx and Compose
Post were 40 and 37 system calls smaller than the sysfilter
ﬁlter respectively. Many of these extraneous system calls

were benign, like exit. Others, however, may provide
opportunities to compromise the container isolation from the
host system, with numerous previous CVEs reported with
associated system calls in the Linux kernel. For example,
sysfilter allowed both Nginx and ComposePost to have
access to mremap (associated with CVE-2020-10757),
sendmmsg (CVE-2011-4594), and ftruncate (CVE-2018-
18281), while TIMELOOPS did not. sysfilter also allowed
Nginx to execute shared memory operations shmat and
shmget (CVE-2017-5669), and allowed ComposePost to
execute clock_settime, while TIMELOOPS did not allow
these. clock_settime not allowed by the default Podman
container ﬁlter due to its effects on the host system settings
outside of the container. Note that the presence of previous
CVEs associated with a system call is not enough to classify
a system call as dangerous when executed inside a container
by an attacker; the CVEs simply show that there has been
some previous risk with allowing unrestricted access to the
system call but do not mean that the system call is still a
risk, nor that a system call with no associated CVE is not a
risk. We provide a full table of system calls allowed by each
system, along with a best-effort attempt to map the system
calls to associated Linux kernel CVEs, in Appendex A.
RQ3 Some system calls are allowed by TIMELOOPS that are
not allowed by sysfilter, in part due to the ASan instru-
mentation applied to create the oracle services. The Nginx
TIMELOOPS policy contained seven system calls that were
not present in the sysfilter policy, and the ComposePost
TIMELOOPS policy contained 13 system calls that were not
present in the sysfilter. Some of these, like open (CVE-
2020-8428 [4]) and pipe (CVE-2015-1805) do have history
of being abused in prior vulnerabilities, but overall this re-
mains a smaller attacker surface.

RQ4 In order to determine which system calls were
speciﬁcally introduced by the TIMELOOPS system, we
compare the Nginx and ComposePost polices gener-
ated by TIMELOOPS to the system calls observed when
executing the target program in a container outside of
the TIMELOOPS system while proﬁling all system calls.
The TIMELOOPS policies contain a superset of system calls
compared to the system calls observed in the baseline proﬁle,
meaning that all system calls executed by the program
outside of TIMELOOPS were also in the TIMELOOPS
policies. The TIMELOOPS policies included six additional
system calls in the Nginx policy (clock_gettime, kill,
madvise, open, readlink, sigaltstack) and seven ad-
ditional system calls in the ComposePost policy (getpid,
gettid, readlink, sched_getaffinity, sched_yield,
setrlimit, sigaltstack). These system calls were likely
introduced by either ASan, as our oracle hardening technique,
or by our modiﬁcations to ensure that forking services
properly exit when anomalous activity is detected.

We conclude that TIMELOOPS is effective at generating
tight system call policies when compared to current state-of-

8

the-art static analysis approaches. TIMELOOPS does introduce
some new system calls, but at a low incidence rate.

6.3 Real-world Exploits

We evaluate the effectiveness of TIMELOOPS in the detection
and prevention of real-world exploits. Long-running web ser-
vices are often subject to memory errors that enable attackers
to gain remote code execution abilities [47]. Buffer overﬂows,
for example, account for many software vulnerabilities and
memory unsafe code remains the foundation for many web
services. We created a web server (written in C) to illustrate
TIMELOOPS’s ability to detect and prevent attacks that per-
form memory corruption and strive to execute arbitrary code.
The web service contains a stack-based buffer overﬂow vul-
nerability modeled after CVEs sampled throughout the last
decade [6] [5] [1] [3]. The vulnerable web service serves
a simple HTML page in response to an HTTP GET re-
quest. Attackers can determine the addresses necessary to
successfully exploit the service and put together a payload, us-
ing a state-of-the-practice or state-of-the-art code-reuse tech-
nique [12–14, 21, 29, 32–34, 48, 58, 60, 62, 63], which executes
a TCP reverse shell. When the exploit is run on an unpro-
tected service, an attacker is able to successfully coerce the
service to “connect back” with a remote shell. However, when
the attack is executed in a system defended by TIMELOOPS,
the vulnerable buffer is overwritten, but the attacker is unable
to cause the service to connect back (with a remote shell),
because when the new system calls (e.g., dup2, connect)
are executed to achieve this we switch to our oracle service
and detect the corresponding memory corruption. While this
simple example can be defended or patched in other ways,
TIMELOOPS’s ability to mitigate attacker’s damage to the
host machine can be extended to defending against the entire
class of remote code execution attacks.

Additionally, we evaluated the effectiveness of TIMELOOPS
on an Nginx vulnerability CVE-2013-2028 [2]. This vulnera-
bility allows an attacker to abuse and integer signedness error
and stack-based buffer to execute arbitrary code. Similar to
our exploit with the HTTP server, the exploit succeeded on
an undefended system, but was caught and prevented when
TIMELOOPS system call ﬁltering was enabled.

6.4 Violating Retry-request Expectations

The analysis conducted in Section 6.1 expected that identical
requests are repeated until a valid response is sent from the
application. However, we must also consider the case where
an attacker violates this expectation or sends a different, mali-
cious request instead of resending the original input. If this
happens, then the oracle and the production services process
different inputs, but this does not introduce any opportunities
to violate security properties of the system.

The oracle is tasked with determining whether a given input
is safe or not. Even if it is making the classiﬁcation on an input
different from the one that the production service handled, it
will still be able to make the determination and update the
security policy accordingly. If we supply a malicious request
to the production and a benign one to the oracle, the oracle
will not add the new malicious system calls to the ﬁlter and
the malicious request will remain incomplete. If we supply
a benign request to the production that triggers the oracle
and a malicious one to the oracle, then the oracle will detect
the exploit and quit execution. If we supply two different
malicious inputs to the production and oracle services, the
oracle will still be able to detect the exploit from the second
malicious request and the ﬁrst one will remain incomplete.
There is no scenario where we can fool the oracle into adding
a system call to the allow-list with an exploit that the oracle
is capable of detecting.

This scenario still allows an attacker to abuse the system
architecture to cause targeted increased runtime overheads.
Attackers can induce repeated switches from application con-
tainer to oracle by providing an input that results in a new
system call, but by then providing inputs that do not cause
system call violations, the oracle container handles all new
requests but with the higher performance overhead that comes
from the exploit detection instrumentation in the oracle. To
prevent this from occurring (even accidentally), we add a
watchdog timer to the oracle container that causes it to exit af-
ter some conﬁgurable amount of time, causing a switch back
to the more performant application container. Besides, this be-
havior is trivially detectable using classic anomaly detection
and/or prevention techniques [20].

6.5 Application Container Compromise

If an attacker achieves remote code execution in the appli-
cation container, the TIMELOOPS system is engineered to
prevent full-system compromise.

First, TIMELOOPS leverages container abstractions pro-
vided by Podman to isolate the application and oracle con-
tainer resources. The containers are restricted from accessing
the full set of system calls by the container seccomp-BPF pol-
icy that is set by TIMELOOPS. The ﬁle representing the system
call policy is maintained entirely outside of the executing con-
tainer environments, and is only passed as an argument to Pod-
man at container startup. Therefore, an attacker with code exe-
cution inside either container is unable to directly manipulate
the policy ﬁle. Additionally, since seccomp-BPF is handled
in kernel space, all system call violations result in delivering
SIGSYS signals to the offending container’s thread and record-
ing the violation in the system’s audit log. It is possible for an
attacker to manipulate the userspace handling of the SIGSYS
signals, given code execution in the context of an application
process. While this would prevent TIMELOOPS from func-
tioning correctly, it would not allow the attacker to loosen the

9

existing syscall policy which is immutable (kernel-enforced).
We further mitigate the danger of a successful remote at-
tacker by running all containers without administrative priv-
ileges. This ensures that any container escapes result in an
attacker having the same permissions as the TIMELOOPS user,
and no more. These limited permissions do not allow attackers
to dismantle the system call ﬁlter or alter running processes
on the host. We believe that due to the series of security ben-
eﬁts provided by our approach, from exploit detection and
tight system call ﬁltering to container isolation, TIMELOOPS
sufﬁciently raises the bar for successful system compromise.

6.6 Timeloops vs. Permanent Hardening

We compare the security guarantees that TIMELOOPS pro-
vides with a permanently hardened system, or in our
case, a service that is always running with ASan. In the
TIMELOOPS design, we only check inputs with ASan when
they trigger new system calls. In the case that a malicious
input does not invoke a new system call, but induces memory
corruption, our TIMELOOPS production service will be cor-
rupted, but an ASan-hardened service will catch the exploit
and quit. We only offer protection equal to an ASan-hardened
service when new system calls are invoked, but we make the
key observation that malicious payloads tend to invoke new
system calls. By design, our hardened oracle service will in-
spect those inputs with greater scrutiny. Since it is impractical
to deploy ASan-hardened services due to their great perfor-
mance overheads, our approach provides the security beneﬁts
of ASan-hardening without incurring the costs. TIMELOOPS
enables heavyweight security techniques to be practical in
performance-critical deployments.

7 Performance Evaluation

To evaluate the performance of TIMELOOPS, we consider
the end-to-end latency of network requests sent to a service
application that is running under our TIMELOOPS prototype.
We measure latency as the elapsed time between a client
making the ﬁrst request to the service and the client receiving
a response, regardless of the number of times the client may
have retried the request.

We compare the latency of the application running under
TIMELOOPS to the latency of the same application running
with no additional exploit mitigations applied (i.e., outside
of TIMELOOPS). We additionally compare the latency of the
TIMELOOPS-hardened application to that of the same applica-
tion executing with ASan-hardening, outside of TIMELOOPS.
This represents a system that is instrumented to maximally
determine when an input causes a security violation. Our
evaluation aims to show that TIMELOOPS can monitor for
violations of security boundaries while also providing amor-
tized performance beneﬁts that are comparable to that of an
unhardened (and hence unprotected) system.

All experiments began by executing the test application
service in TIMELOOPS with an empty system call allow-list.
We used an HTTP client program to send each request to
the application repeatedly until it was successfully processed.
Some system calls are iteratively learned even before the
application is able to receive its ﬁrst input.

In all experiments, the very ﬁrst request sent to the
TIMELOOPS application resulted in very slow response times
since it typically required learning many new system calls.
Following requests tended not to invoke many new system
calls and were therefore quickly processed. Figure 4 shows
the latency of each request sent, and how the application run-
ning in TIMELOOPS always has a slower start than the other
services. However, the average latency, shown in Figure 5, of
ensuing requests processed by the TIMELOOPS application
was close to that of the completely unhardened service. In
all trials the average TIMELOOPS request outperformed the
average hardened service request.

The high latency of the ﬁrst few requests led to another
observation: by pre-training TIMELOOPS on known-safe in-
puts to the application, we can create an initial allow-list prior
to deployment. However, unlike in traditional dynamic sys-
tem call learning systems, these initial inputs do not need
to exhaustively include every system call that should be
learned—in this case, the TIMELOOPS system can still learn
new system calls from future inputs. By training on the most
performance-critical inputs ahead of time, an operator of the
TIMELOOPS system can further amortize system call learning
costs on the critical path.

8 Related Work

8.1 Static System Call Filtering

Static system call ﬁltering approaches attempt to determine a
correct system call policy without executing the program,
and then apply the policy via some enforcement mecha-
nism. sysfilter [25] is a binary analysis-based framework
that synthesizes syscall ﬁlters and applies them to applica-
tions. Like our approach, sysfilter determines developer-
intended program behavior and enforces only that behavior
via seccomp-BPF ﬁlters. However, sysfilter determines
this behavior statically and analyzes call graphs to generate
their system call ﬁlters. While the authors use many tech-
niques to prune this call graph to avoid adding unreachable
syscalls to their ﬁlter, it still may be too large. Abhaya [53],
like sysfilter, uses static code analysis to generate system
call policies, but analyzes program source code, rather than
compiled binaries, and targets both seccomp-BPF and Pledge
policies for enforcement.

Temporal syscall ﬁltering [31] relies on static analysis
to create syscall ﬁlters for applications. It differs from
sysfilter because it makes the observation that many sys-
tem calls that are used for the initialization of an application

10

(a) Compose Review (MM)

(b) Compose Post (SN)

(c) Python Flask

(d) Nginx

Figure 4: Comparison of cumulative time for processing repeated requests sent to an unhardened service, a TIMELOOPS service,
and a hardened service. Figures 4a and 4b show the end-to-end latency of sending requests to the media microservices (MM) and
social network microservices (SN) benchmark. Figures 4c and 4d show the end-to-end latency of sending requests to each of the
stand-alone applications that process web requests. In every case, the TIMELOOPS service starts with a longer response time
while system calls are learned, but eventually overtakes the hardened service (intercept is plotted).

(a) Compose Review (MM)

(b) Compose Post (SN)

(c) Python Flask

(d) Nginx

Figure 5: Comparison of request latency distribution per request sent to an unhardened service, a TIMELOOPS service, and a
hardened service. The average request latencies of the TIMELOOPS services are similar to that of the unhardened service and
lower than the hardened service, despite the maximum value of the TIMELOOPS service being a signiﬁcant outlier. The maximum
value comes from the large delay in servicing the ﬁrst requests as system calls are learned.

11

020000400006000080000100000Number of Requests Processed0500100015002000Total Time Elapsed (seconds)Request #: 18020020000400006000080000100000Number of Requests Processed0200400600800100012001400Total Time Elapsed (seconds)Request #: 14773020000400006000080000100000Number of Requests Processed0100200300400500Total Time Elapsed (seconds)Request #: 132900250005000075000100000125000150000175000200000Number of Requests Processed02004006008001000Total Time Elapsed (seconds)Request #: 65676UnhardenedTimeloopsHardened102101100101Total Time Per Request (s)UnhardenedTimeloopsHardened102101100101Total Time Per Request (s)UnhardenedTimeloopsHardened102101100101Total Time Per Request (s)UnhardenedTimeloopsHardened102101100101Total Time Per Request (s)are no longer required during the application’s steady state.
The authors create two ﬁlters: one that includes all of the ini-
tialization syscalls, applied during the “init” execution phase,
while the other is applied during the “main loop” phase.

Saphire [15] presents an approach for creating system call
policies for interpreted languages. Speciﬁcally, Saphire cre-
ates sandboxes for PHP applications by analyzing PHP source
code rather than attempting to analyze the entire interpreter.

8.2 Dynamic System Call Filtering

Dynamic syscall ﬁltering tools execute the target program
various inputs to observe which system calls are required by
an application. Like TIMELOOPS, dynamic approaches exe-
cute the program to derive policies based on observations of
program behavior. However, they tend to execute in distinct
phases of training and deployment, while TIMELOOPS con-
ducts its learning while able to service production workloads.
ZenIDS [35] is able to learn system call policies for PHP
applications with an online training period to then monitor
for anomalies. Systrace [54] also uses dynamic tracing to
learn policies, but enforces the policies by implementing a
userspace daemon.

8.3 Cloud and Container Security

As cloud and container environments have proliferated, new
approaches have been proposed to secure them. Conﬁne [30]
is a static system call ﬁltering technique speciﬁcally for ana-
lyzing the contents of containers to determine allowed system
calls exposed to the container. Dynamic approaches have also
been applied to containers [71] to proﬁle the syscalls invoked
by the container during the execution of automated test inputs,
and to enforce a policy restricted by the proﬁle. Work has
been done to analyze and categorize [43] privilege escalation
container exploits that break the resource isolation provided
by container abstractions. AUTOARMOR [41] is a proposal
to automatically generate policies for securing microservices
by analyzing the interactions between them.

9 Future Work

9.1 Optimizations

9.1.1 Performance Optimizations

In our evaluation, we saw that most of the additional over-
heads that timeloops applications have in comparison to the
unhardened services come from processing the ﬁrst few re-
quests. The rest of the execution after this "warmup phase" is
similar to that of the unhardened services. To avoid incurring
this warmup cost, we can save ﬁlters and reuse them in the
future if we are conﬁdent of thier correctness and can validate
that they have not been compromised between uses.

Figure 6: With additional hardware checkpointing and replay-
ing support, when a new syscall is encountered we will (1)
save the state of the production service and pause execution,
(2) execute the request in the oracle and update the policy, and
(3) restore the production service state from the checkpoint
and resume execution.

Additionally, we see that it is quite costly to stop and restart
containers, but this step is necessary since Seccomp ﬁlters are
immutable once installed. This is a feauture of Seccomp since
we do not want attackers to be able to modify the Seccomp ﬁl-
ters that are installed on a running program. This could lead to
uninstalling the Seccomp ﬁlter entirely or adding system calls
necessary for an attack. If we had a custom eBPF program
that allowed our trusted timeloops infrastructure to modify
the system call ﬁlter, then we could avoid incurring this cost
every time we encounter a new system call.

9.1.2 Security Optimizations

Our current implementation of TIMELOOPS involves itera-
tively writing a security policy by creating an allow-list of
behaviors. However, over time, the intended behavior of an
application may change depending on the phase of execution,
the set of inputs, the time of day or some other factor. When
application behavior changes, we do not want to include old
behaviors in our security policy any longer. To further tighten
our security guarantees, we could implement periodic pol-
icy forgetting. This would allow us to ensure that our policy
enforces tight bounds and only encapsulates current behavior.
Another assumption we make in our timeloops design is
that malicious behavior is always introduced via a vulnera-
bility that our oracle can detect. This is not always the case.
Future instantiations of TIMELOOPS could use different or
even multiple hardening techniques for the oracle.

Another optimization for our system call learning case
study is to keep track of system call arguments. This will
enforce a ﬁner-grained security policy. Even though common
system calls are used during attacks, they are often invoked
with different arguments than the ones used in normal pro-
gram execution.

12

Hardware Checkpoint andRestoreProductionOracle1329.1.3 Hardware Support

Introducing hardware support in our TIMELOOPS design may
allow us to incorporate some of these optimizations with ease.
For example, hardware checkpointing techniques [38] offer
the ability to simply pause execution in one instance of a
service and resume execution later. Instead of resending a
request to the production service again, we can simply re-
sume execution. Hardware checkpointing in conjunction with
hardware support for replaying execution could save us the
overheads of stopping services each time we need to consult
the oracle. This support could potentially allow us to imple-
ment timeloops on services that are not stateless as well.

10 Conclusion

Creating security policies for microservices is a difﬁcult and
tedious process: it requires a thorough understanding of each
service and must ﬂexibly adapt to changes in the deployment.
This paper takes the ﬁrst steps towards automatically crafting
security policies for containerized microservices. We aim to
learn policies for system call ﬁltering, a technology that is
becoming increasingly necessary for maintaining isolation in
cloud settings.

To learn policies automatically, we introduced the concept
of timelooping. The key idea is to: (i) re-execute a program
among two variants of an application, one hardened for se-
curity, and another one optimized for performance; (ii) learn
execution properties from the hardened version; and (iii) use
the results of the previous step to craft policies that can be
enforced on the performance-optimized version. Our solution
takes a pragmatic stance in the trade-off(s) between security
and performance.

We demonstrated the merit and applicability of our
TIMELOOPS learning scheme in three signiﬁcant ways: (1) we
showed that the system call allow-lists created by TIMELOOPS
for our applications are signiﬁcantly better than statically- and
dynamically-generated policies, (2) we showed that the idea
is compatible-with, and well-suited to, modern software engi-
neering practices, such the use of containerized microservices
crafted using popular interpreted languages. These use cases
have been the Achilles’ heel of several security studies in our
community, and (3) we showed that the idea can be easily
implemented by combining existing technologies.

In our community there has been signiﬁcant amount of
work on hardening applications. As is to be expected, these
hardening services come with performance and energy over-
heads. In an ideal world, these overheads should not matter. In
reality, however, users care about performance, forcing them
to make a hard choice between performance and security. In
our TIMELOOPS system we use the oracle version as needed
to learn security properties, and then enforce these security
properties on the production version using lightweight en-
forcement techniques. Thus, TIMELOOPS obviates the need

to make this performance-security choice. With time, we ex-
pect properties and policies beyond system call ﬁltering to
use our TIMELOOPS technique.

11 Acknowledgements and Disclosures

This work was partially supported by N00014-20-1-2746,
a NSF Graduate Research Fellowship, and a gift from
Bloomberg. Any opinions, ﬁndings, conclusions and recom-
mendations expressed in this material are those of the authors
and do not necessarily reﬂect the views of the US government
or commercial entities. Simha Sethumadhavan has a signiﬁ-
cant ﬁnancial interest in Chip Scan Inc. Patent Pending.

References

[1] Cve-2009-0187. National Vulnerability Database.

[2] Cve-2013-2028. National Vulnerability Database.

[3] Cve-2014-2206. National Vulnerability Database.

[4] Cve-2020-8428. National Vulnerability Database.

[5] Cve-2021-46393. National Vulnerability Database.

[6] Cve-2022-22274. National Vulnerability Database.

[7] Pod manager tool (podman). podman website.

[8] What is amazon ec2? AWS User Guide for Linux In-

stances.

[9] Improving host security with system call policies. In
12th USENIX Security Symposium (USENIX Security
03), Washington, D.C., August 2003. USENIX Associa-
tion.

[10] Seccomp security proﬁles for docker, Dec 2021.

[11] Muhammad Abubakar, Adil Ahmad, Pedro Fonseca,
{SHARD}: Fine-grained kernel
and Dongyan Xu.
specialization with context-aware hardening. In 30th
{USENIX} Security Symposium ({USENIX} Security
21), 2021.

[12] Andrea Bittau, Adam Belay, Ali Mashtizadeh, David
Mazières, and Dan Boneh. Hacking Blind. In IEEE
Symposium on Security and Privacy (S&P), pages 227–
242, 2014.

[13] Tyler Bletsch, Xuxian Jiang, Vince W Freeh, and
Zhenkai Liang. Jump-Oriented Programming: A New
Class of Code-Reuse Attack. In ACM Asia Symposium
on Information, Computer and Communications Secu-
rity (ASIACCS), pages 30–40, 2011.

13

[14] Erik Bosman and Herbert Bos. Framing Signals—A
Return to Portable Shellcode. In IEEE Symposium on
Security and Privacy (S&P), pages 243–258, 2014.

[15] Alexander Bulekov, Rasoul Jahanshahi, and Manuel
Egele. Saphire: Sandboxing {PHP} applications with
tailored system call allowlists. In 30th {USENIX} Secu-
rity Symposium ({USENIX} Security 21), 2021.

[16] Nathan Burow, Xinping Zhang, and Mathias Payer. Sok:
In 2019 IEEE Sym-
Shining light on shadow stacks.
posium on Security and Privacy (SP), pages 985–999.
IEEE, 2019.

[17] Claudio Canella, Mario Werner, Daniel Gruss, and
Michael Schwarz. Automating seccomp ﬁlter generation
for linux applications. In Proceedings of the 2021 on
Cloud Computing Security Workshop, pages 139–151,
2021.

[18] Claudio Canella, Mario Werner, Daniel Gruss, and
Michael Schwarz. Automating seccomp ﬁlter gener-
ation for linux applications. CCSW ’21, page 139–151,
New York, NY, USA, 2021. Association for Computing
Machinery.

[19] Canister. Container escapes: An exercise in practical

container escapology, Mar 2019.

[20] Varun Chandola, Arindam Banerjee, and Vipin Kumar.
Anomaly detection: A survey. ACM computing surveys
(CSUR), 41(3):1–58, 2009.

[21] Stephen

Checkoway, Lucas

Davi, Alexandra
Dmitrienko, Ahmad-Reza Sadeghi, Hovav Shacham,
and Marcel Winandy. Return-Oriented Programming
without Returns. In ACM Conference on Computer and
Communications Security (CCS), pages 559–572, 2010.

[22] Stefano Chierici. Cve-2022-0492: Privilege escalation
vulnerability causing container escape, Mar 2022.

[23] Adrian Cockcroft. Evolution of microservices - craft

conference, Apr 2016.

[24] Jeffrey Dean and Luiz André Barroso. The tail at scale.

Commun. ACM, 56(2):74–80, feb 2013.

[25] Nicholas DeMarinis, Kent Williams-King, Di Jin, Ro-
drigo Fonseca, and Vasileios P. Kemerlis. sysﬁlter: Au-
tomated system call ﬁltering for commodity software. In
23rd International Symposium on Research in Attacks,
Intrusions and Defenses (RAID 2020), pages 459–474,
San Sebastian, October 2020. USENIX Association.

[26] Docker Documentation. Seccomp security proﬁles for

docker.

14

[27] EdPrice-MSFT. N-tier architecture style - azure archi-

tecture center.

[28] Yu Gan, Yanqi Zhang, Dailun Cheng, Ankitha Shetty,
Priyal Rathi, Nayan Katarki, Ariana Bruno, Justin Hu,
Brian Ritchken, Brendon Jackson, Kelvin Hu, Meghna
Pancholi, Yuan He, Brett Clancy, Chris Colen, Fukang
Wen, Catherine Leung, Siyuan Wang, Leon Zaruvinsky,
Mateo Espinosa, Rick Lin, Zhongling Liu, Jake Padilla,
and Christina Delimitrou. An open-source benchmark
suite for microservices and their hardware-software im-
plications for cloud &; edge systems. In Proceedings
of the Twenty-Fourth International Conference on Ar-
chitectural Support for Programming Languages and
Operating Systems, ASPLOS ’19, page 3–18, New York,
NY, USA, 2019. Association for Computing Machinery.

[29] Robert Gawlik, Benjamin Kollenda, Philipp Koppe,
Behrad Garmany, and Thorsten Holz. Enabling Client-
Side Crash-Resistance to Overcome Diversiﬁcation and
Information Hiding. In Network and Distributed System
Security Symposium (NDSS), 2016.

[30] Seyedhamed Ghavamnia, Tapti Palit, Azzedine Be-
nameur, and Michalis Polychronakis. Conﬁne: Auto-
mated system call policy generation for container attack
surface reduction. In 23rd International Symposium on
Research in Attacks, Intrusions and Defenses ({RAID}
2020), pages 443–458, 2020.

[31] Seyedhamed Ghavamnia, Tapti Palit, Shachee Mishra,
and Michalis Polychronakis. Temporal system call spe-
cialization for attack surface reduction. In 29th USENIX
Security Symposium (USENIX Security 20), pages 1749–
1766. USENIX Association, August 2020.

[32] Enes Göktas, Elias Athanasopoulos, Herbert Bos, and
Georgios Portokalidis. Out Of Control: Overcoming
Control-Flow Integrity. In IEEE Symposium on Security
and Privacy (S&P), pages 575–589, 2014.

[33] Enes Göktas, Benjamin Kollenda, Philipp Koppe, Erik
Bosman, Georgios Portokalidis, Thorsten Holz, Her-
bert Bos, and Cristiano Giuffrida. Position-independent
Code Reuse: On the Effectiveness of ASLR in the Ab-
sence of Information Disclosure. In IEEE European
Symposium on Security and Privacy (EuroS&P), pages
227–242, 2018.

[34] Enes Göktas, Kaveh Razavi, Georgios Portokalidis, Her-
bert Bos, and Cristiano Giuffrida. Speculative Probing:
In ACM Confer-
Hacking Blind in the Spectre Era.
ence on Computer and Communications Security (CCS),
pages 1871–1885, 2020.

[35] Byron Hawkins and Brian Demsky. Zenids: Introspec-
tive intrusion detection for php applications. In 2017

IEEE/ACM 39th International Conference on Software
Engineering (ICSE), pages 232–243, 2017.

[46] Mike Loukides and Steve Swoyer. Microservices adop-

tion in 2020, Jul 2020.

[36] Matt Hedges and Joseph Keating. Deploying python
ﬂask microservices to aws using open source tools, Apr
2021.

[37] Sungjin Kim, Byung Joon Kim, and Dong Hoon Lee.
Prof-gen: Practical study on system call whitelist gen-
eration for container attack surface reduction. In 2021
IEEE 14th International Conference on Cloud Comput-
ing (CLOUD), pages 278–287. IEEE, 2021.

[38] Dirk Koch, Christian Haubelt, and Jürgen Teich. Efﬁ-
cient hardware checkpointing: Concepts, overhead anal-
ysis, and implementation. In Proceedings of the 2007
ACM/SIGDA 15th International Symposium on Field
Programmable Gate Arrays, FPGA ’07, page 188–196,
New York, NY, USA, 2007. Association for Computing
Machinery.

[39] Paul Kocher, Jann Horn, Anders Fogh, Daniel Genkin,
Daniel Gruss, Werner Haas, Mike Hamburg, Moritz
Lipp, Stefan Mangard, Thomas Prescher, et al. Spectre
attacks: Exploiting speculative execution. Communica-
tions of the ACM, 63(7):93–101, 2020.

[40] Per Larsen, Andrei Homescu, Stefan Brunthaler, and
Michael Franz. Sok: Automated software diversity. In
2014 IEEE Symposium on Security and Privacy, pages
276–291. IEEE, 2014.

[41] Xing Li, Yan Chen, Zhiqiang Lin, Xiao Wang, and
Jim Hao Chen. Automatic policy generation for
inter-service access control of microservices. In 30th
{USENIX} Security Symposium ({USENIX} Security
21), 2021.

[42] Yiwen Li, Brendan Dolan-Gavitt, Sam Weber, and
Justin Cappos.
Lock-in-pop: Securing privileged
operating system kernels by keeping on the beaten
path. In 2017 {USENIX} Annual Technical Conference
({USENIX}{ATC} 17), pages 1–13, 2017.

[43] Xin Lin, Lingguang Lei, Yuewu Wang, Jiwu Jing, Kun
Sun, and Quan Zhou. A measurement study on linux
In
container security: Attacks and countermeasures.
Proceedings of the 34th Annual Computer Security Ap-
plications Conference, ACSAC ’18, page 418–429, New
York, NY, USA, 2018. Association for Computing Ma-
chinery.

[44] Linux Programmer’s Manual. Seccomp(2).

[45] Moritz Lipp, Michael Schwarz, Daniel Gruss, Thomas
Prescher, Werner Haas, Jann Horn, Stefan Mangard, Paul
Kocher, Daniel Genkin, Yuval Yarom, et al. Meltdown:
Reading kernel memory from user space. Communica-
tions of the ACM, 63(6):46–56, 2020.

[47] Kylee Malkiewicz. This year (so far) in buffer overﬂows

- dover microsystems, Mar 2021.

[48] Andrea Mambretti, Alexandra Sandulescu, Alessan-
dro Sorniotti, William Robertson, Engin Kirda, and
Anil Kurmus. Bypassing memory safety mechanisms
through speculative control ﬂow hijacks. In IEEE Euro-
pean Symposium on Security and Privacy (EuroS&P),
pages 633–649, 2021.

[49] Steven McCanne and Van Jacobson. The bsd packet
ﬁlter: A new architecture for user-level packet capture.
In USENIX winter, volume 46, 1993.

[50] Kit Murdock, David Oswald, Flavio D Garcia,
Jo Van Bulck, Daniel Gruss, and Frank Piessens.
Plundervolt: Software-based fault injection attacks
against intel sgx. In 2020 IEEE Symposium on Security
and Privacy (SP), pages 1466–1482. IEEE, 2020.

[51] Santosh Nagarakatte, Jianzhou Zhao, Milo MK Martin,
and Steve Zdancewic. SoftBound: Highly Compatible
and Complete Spatial Memory Safety for C. In ACM
Conference on Programming Language Design and Im-
plementation (PLDI), pages 245–258, 2009.

[52] Santosh Nagarakatte, Jianzhou Zhao, Milo MK Mar-
tin, and Steve Zdancewic. CETS: Compiler Enforced
Temporal Safety for C. In International Symposium on
Memory Management (ISMM), pages 31–40, 2010.

[53] Shankara Pailoor, Xinyu Wang, Hovav Shacham, and
Isil Dillig. Automated policy synthesis for system call
sandboxing. Proc. ACM Program. Lang., 4(OOPSLA),
November 2020.

[54] Niels Provos. Improving host security with system call
In Proceedings of the 12th Conference on
policies.
USENIX Security Symposium - Volume 12, SSYM’03,
page 18, USA, 2003. USENIX Association.

[55] Niels Provos, Markus Friedl, and Peter Honeyman. Pre-
venting privilege escalation. In Proceedings of the 12th
Conference on USENIX Security Symposium - Volume
12, SSYM’03, page 16, USA, 2003. USENIX Associa-
tion.

[56] Yuxin Ren, Guyue Liu, Vlad Nitu, Wenyuan Shao, Riley
Kennedy, Gabriel Parmer, Timothy Wood, and Alain
Tchana. F2c: Enabling fair and ﬁne-grained resource
sharing in multi-tenant iaas clouds. IEEE Transactions
on Parallel and Distributed Systems, 27(9):2589–2602,
2016.

15

[67] MSRC Team, Jul 2019.

[68] The Linux Kernel. Seccomp bpf (secure computing with

ﬁlters).

[69] W3 Techs Web Technology Surveys. Usage statistics of

nginx.

[70] W3 Techs Web Technology Surveys. Usage statistics of

php for websites.

[71] Zhiyuan Wan, David Lo, Xin Xia, Liang Cai, and Shan-
ping Li. Mining sandboxes for linux containers.
In
2017 IEEE International Conference on Software Test-
ing, Veriﬁcation and Validation (ICST), pages 92–102,
2017.

A System Call Policy Comparison Table

As part of our evaluation of TIMELOOPS, we generated poli-
cies for multiple programs, as described in Section 6.2. In this
section, we list all syscalls contained in the generated poli-
cies produced by TIMELOOPS and sysfilter for our Nginx
web application and the ComposePost microservice of the
Social Network service benchmark. We additionally compare
these policies to system calls observed when executing the
programs in a container without any system call ﬁltering, as
well to the default Podman system call ﬁlter. We additionally
list the most recent Linux kernel CVE that we were able to
identify that could be associated with each system call.

[57] Liz Rice. Container security: fundamental technology
concepts that protect containerized applications. OR-
eilly Media, 2020.

[58] Robert Rudd, Richard Skowyra, David Bigelow, Veer
Dedhia, Thomas Hobson, Stephen Crane, Christopher
Liebchen, Per Larsen, Lucas Davi, Michael Franz,
Ahmad-Reza Sadeghi, and Hamed Okhravi. Address
Oblivious Code Reuse: On the Effectiveness of Leakage
Resilient Diversity. In Network and Distributed System
Security Symposium (NDSS), 2017.

[59] Jerome H. Saltzer and Michael D. Schroeder. The Pro-
IEEE,

tection of Information in Computer Systems.
63(9):1278–1308, 1975.

[60] Felix Schuster, Thomas Tendyck, Christopher Liebchen,
Lucas Davi, Ahmad-Reza Sadeghi, and Thorsten Holz.
Counterfeit Object-oriented Programming: On the Difﬁ-
culty of Preventing Code Reuse Attacks in C++ Appli-
cations. In IEEE Symposium on Security and Privacy
(S&P), pages 745–762, 2015.

[61] Konstantin Serebryany, Derek Bruening, Alexander
Potapenko, and Dmitriy Vyukov. Addresssanitizer:
In 2012 {USENIX}
A fast address sanity checker.
Annual Technical Conference ({USENIX}{ATC} 12),
pages 309–318, 2012.

[62] Hovav Shacham. The Geometry of Innocent Flesh on
the Bone: Return-into-libc Without Function Calls (on
the x86). In ACM Conference on Computer and Com-
munications Security (CCS), pages 552–561, 2007.

[63] Kevin Z Snow, Fabian Monrose, Lucas Davi, Alexandra
Dmitrienko, Christopher Liebchen, and Ahmad-Reza
Sadeghi. Just-In-Time Code Reuse: On the Effective-
ness of Fine-Grained Address Space Layout Random-
ization. In IEEE Symposium on Security and Privacy
(S&P), pages 574–588, 2013.

[64] Dokyung Song, Julian Lettner, Prabhu Rajasekaran,
Yeoul Na, Stijn Volckaert, Per Larsen, and Michael
Franz. Sok: sanitizing for security. In 2019 IEEE Sym-
posium on Security and Privacy (SP), pages 1275–1295.
IEEE, 2019.

[65] Laszlo Szekeres, Mathias Payer, Tao Wei, and Dawn
In 2013 IEEE
Song. Sok: Eternal war in memory.
Symposium on Security and Privacy, pages 48–62. IEEE,
2013.

[66] Adrian Tang, Simha Sethumadhavan, and Salvatore
{CLKSCREW}: Exposing the perils of
Stolfo.
In 26th
{Security-Oblivious} energy management.
USENIX Security Symposium (USENIX Security 17),
pages 1057–1074, 2017.

16

Table 2: Comparison of system calls allowed by various ﬁltering policies. If a system call does not appear in this table, it was not
contained in a policy generated by TIMELOOPS, sysfilter, or observed when the program executed. The CVE column lists
one CVE, if any could be found, in the Linux kernel where the associated system call was used to trigger the vulnerability.

syscall

accept
accept4
access
alarm
arch_prctl
bind
brk
capset
chdir
chmod
chown
clock_getres
clock_gettime
clock_nanosleep
clock_settime
clone
close
connect
dup
dup2
epoll_create
epoll_ctl
epoll_wait
eventfd2
execve
exit
exit_group
fadvise64
fcntl
fstat
ftruncate
futex
getcwd
getdents
getdents64
getegid
geteuid
getgid
getpeername
getpid
getppid
getrandom
getrlimit
getsockname
getsockopt
gettid
gettimeofday
getuid
ioctl
kill
listen
lseek
lstat
madvise
mkdir
mmap
mprotect
mremap
munmap
nanosleep
newfstatat

CVE

Baseline

Nginx
Timeloops

Sysﬁlter

Baseline

ComposePost
Timeloops

Sysﬁlter

Podman

CVE-2017-8890

CVE-2016-10200
CVE-2020-9391

CVE-2016-7097
CVE-2015-3339

CVE-2011-3209
CVE-2009-2767

CVE-2019-11815

CVE-2016-3750

CVE-2011-1083
CVE-2013-7446

CVE-2018-14634

CVE-2016-7118

CVE-2018-18281
CVE-2020-14381

CVE-2011-1593

CVE-2021-38208
CVE-2021-20194

numerous drivers

CVE-2013-3301

CVE-2016-5195

CVE-2018-7740
CVE-2010-4169
CVE-2020-10757
CVE-2020-29369

x
x
x

x
x
x
x
x

x

x
x
x
x
x
x
x
x
x
x

x

x
x

x
x
x

x
x
x
x
x
x
x

x
x

x
x

x
x
x

x
x
x

x

x

x

x
x
x
x

x

x
x
x

x
x

x
x

x

x
x

x

x

x

x
x

x

x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x

x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x

x
x
x

x
x
x
x
x

x
x

x
x
x
x
x
x
x
x
x
x

x

x
x

x
x
x

x
x
x
x
x
x
x

x
x

x
x
x
x
x
x
x
x
x
x

x

17

x

x

x
x
x
x

x

x
x
x

x
x

x
x

x

x

x
x

x
x

x

x

x
x

x

x

x

x
x

x
x
x
x

x
x
x

x
x

x
x

x
x
x

x
x

x

x
x
x
x

x
x
x
x
x
x

x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

Table 2: Comparison of system calls allowed by various ﬁltering policies. If a system call does not appear in this table, it was not
contained in a policy generated by TIMELOOPS, sysfilter, or observed when the program executed. The CVE column lists
one CVE, if any could be found, in the Linux kernel where the associated system call was used to trigger the vulnerability.

syscall

CVE

Baseline

Nginx
Timeloops

Sysﬁlter

Baseline

ComposePost
Timeloops

Sysﬁlter

Podman

open
openat
pause
pipe
poll
prctl
pread64
prlimit64
pselect6
pwrite64
pwritev
read
readlink
readv
recvfrom
recvmsg
rename
restart_syscall
rmdir
rt_sigaction
rt_sigprocmask
rt_sigreturn
rt_sigsuspend
sched_get_priority_max
sched_get_priority_min
sched_getaffinity
sched_getparam
sched_getscheduler
sched_setaffinity
sched_setscheduler
sched_yield
select
sendfile
sendmmsg
sendmsg
sendto
set_robust_list
set_tid_address
setgid
setgroups
setitimer
setpriority
setregid
setresgid
setresuid
setreuid
setrlimit
setsid
setsockopt
setuid
shmat
shmdt
shmget
shutdown
sigaltstack
socket
socketpair
stat
statfs
sysinfo
tgkill

CVE-2020-8428
CVE-2020-10768

CVE-2015-1805

CVE-2020-10768

CVE-2011-4077
CVE-2008-3535
CVE-2013-1979
CVE-2013-1979
CVE-2016-6198
CVE-2014-3180

CVE-2017-15537

CVE-2021-26708

CVE-2011-4594
CVE-2017-17712
CVE-2017-17712

CVE-2021-32760
CVE-2018-7169

CVE-2019-18684
CVE-2011-3145

CVE-2005-0178
CVE-2016-4998
CVE-2013-6825
CVE-2017-5669

CVE-2017-5669

CVE-2009-2847
CVE-2017-9074
CVE-2010-4249

CVE-2013-2141

x

x
x
x
x
x
x
x

x

x
x

x
x
x
x

x

x
x
x
x
x

x
x

x
x
x

x

x
x
x

x

x

x
x

x

x

x
x

x
x

x
x

x
x
x

x
x

x

x

x
x

x

x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

x
x
x
x
x
x
x

x
x
x
x
x
x

x
x

x
x
x
x
x
x
x

x
x
x
x

x
x
x
x

x

x
x
x
x
x

x
x

x
x
x

x
x
x
x
x

x

18

x

x
x

x

x
x

x
x

x
x

x
x
x

x

x
x
x

x
x

x

x

x
x
x
x

x
x

x

x

x

x
x
x

x
x
x

x
x

x
x

x
x

x

x
x
x
x
x

x
x
x
x

x
x

x

x

x

x
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

Table 2: Comparison of system calls allowed by various ﬁltering policies. If a system call does not appear in this table, it was not
contained in a policy generated by TIMELOOPS, sysfilter, or observed when the program executed. The CVE column lists
one CVE, if any could be found, in the Linux kernel where the associated system call was used to trigger the vulnerability.

syscall

time
times
umask
uname
unlink
utimes
vfork
wait4
write
writev

CVE

Baseline

Nginx
Timeloops

Sysﬁlter

Baseline

ComposePost
Timeloops

Sysﬁlter

Podman

CVE-2020-35513
CVE-2012-0957
CVE-2016-6197

CVE-2005-3106

CVE-2016-9755

x

x

x
x
x

x

x

x
x
x

x

x
x
x
x

x
x
x

x

x

x

x

x

x

x

x
x

x
x
x
x
x
x
x
x
x
x

19

