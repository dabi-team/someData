Efﬁcient RDF Streaming for the
Edge-Cloud Continuum

2
2
0
2

l
u
J

0
1

]

B
D
.
s
c
[

1
v
9
3
4
4
0
.
7
0
2
2
:
v
i
X
r
a

Piotr Sowi´nski
Systems Research Institute
Polish Academy of Sciences
Warsaw, Poland
0000-0002-2543-9461

Katarzyna Wasielewska-Michniewska
Systems Research Institute
Polish Academy of Sciences
Warsaw, Poland
0000-0002-3763-2373

Maria Ganzha
Systems Research Institute
Polish Academy of Sciences
Warsaw, Poland
0000-0001-7714-4844

Wiesław Pawłowski
Dept. of Mathematics, Physics, and Informatics
University of Gda´nsk
Gda´nsk, Poland
0000-0002-5105-8873

Paweł Szmeja
Systems Research Institute
Polish Academy of Sciences
Warsaw, Poland
0000-0003-0869-3836

Marcin Paprzycki
Systems Research Institute
Polish Academy of Sciences
Warsaw, Poland
0000-0002-8069-2152

Abstract—With the ongoing, gradual shift of large-scale dis-
tributed systems towards the edge-cloud continuum, the need
arises for software solutions that are universal, scalable, practical,
and grounded in well-established technologies. Simultaneously,
semantic technologies, especially in the streaming context, are
becoming increasingly important for enabling interoperability in
edge-cloud systems. However, in recent years, the ﬁeld of semantic
data streaming has been stagnant, and there are no available
solutions that would ﬁt those requirements. To ﬁll this gap, in
this contribution, a novel end-to-end RDF streaming approach is
proposed (named JELLY). The method is simple to implement,
yet very elastic, and designed to ﬁt a wide variety of use cases.
Its practical performance is evaluated in a series of experiments,
including end-to-end throughput and latency measurements. It
is shown that JELLY achieves vastly superior performance to
the currently available approaches. The presented method makes
signiﬁcant progress towards enabling high-performance semantic
data processing in a wide variety of applications, including future
edge-cloud systems. Moreover, this study opens up the possibility
of applying and evaluating the method in real-life scenarios,
which will be the focus of further research.

Index Terms—RDF, stream processing, edge-cloud continuum,

Protocol Buffers, Apache Kafka, gRPC, large IoT ecosystems

I. INTRODUCTION

Nowadays, a gradual shift in IoT ecosystems can be ob-
served, with the “traditional” division of computing infras-
tructures into cloud, edge, far edge, etc., being replaced with
the emerging idea of edge-cloud continuum [1]. It provides a
new way of thinking about how heterogeneous devices are to
cooperate seamlessly within large-scale ecosystems. However,
for this concept to become reality, a paradigm shift is needed
in how software and interfaces are designed [2]. For example,
when one focuses on the solution being performant on micro-
controllers, usually the method’s scalability and compatibility
with existing interfaces is sacriﬁced. This kind of approach is

This work is part of the ASSIST-IoT project that has received funding
from the EU’s Horizon 2020 research and innovation programme under grant
agreement No 957258.

no longer appropriate, as elastic and adaptable solutions are
needed, which scale vertically and horizontally, and can be
implemented effortlessly on a wide variety of hardware and
software platforms.

Semantic technologies have proven themselves to be a
vital asset for enabling interoperability in IoT, and facilitating
data reuse [3], [4]. However, the practicality of semantics-
based solutions is often criticized, especially with regard to
their implementation complexity and performance [5]. Both
these issues can, quite obviously, hamper the application of
semantics in edge-cloud systems. In this work,
the focus
is on a speciﬁc aspect of semantic technologies, namely
the streaming of semantic data. There are many ways in
which semantic data streaming can be deﬁned, however, the
following deﬁnition was chosen, due to it being very universal
and able to cover most use cases. Semantic data streaming is a
one-way communication act between two actors: the producer
and the consumer. The producer sends a potentially unbounded
sequence of Resource Description Framework (RDF) [6] state-
ments (triples or quads) to the consumer over the network. The
protocol used for network communication varies from appli-
cation to application and can span from synchronous, point-to-
point approaches (such as gRPC), to asynchronous, distributed
methods, involving a message broker (such as Apache Kafka).
For practical reasons, a stream of RDF statements is divided
into discrete RDF graphs (messages, blocks) to be sent over the
network. These messages are serialized by the producer and
then deserialized by the consumer. To improve communication
efﬁciency, the messages can be compressed, either by the
serialization format itself, or at the network protocol level
(using, for example, gzip compression).

Stream processing of semantic data is a key problem in im-
plementing semantics-enabled distributed systems, being used
in a wide variety of applications [5], [7], [8]. However, upon
a closer examination of the available solutions for semantic
data streaming (see Section II), it becomes clear that they are

 
 
 
 
 
 
hardly adequate to meet the requirements of future edge-cloud
continuum systems. For instance, up until now, there has been
no established standard for RDF data streaming. Moreover, the
existing solutions are fragmented, of little practical use, and
often focused on a very speciﬁc application domain.

This is the research gap that this contribution seeks to
cover. The proposed solution aims to be all-encompassing
with regard to the outlined requirements, by being scalable,
performant, easy to implement, and based on already estab-
lished best practices, used widely by both IoT and cloud
industries. The implementation of the approach, results, and
other additional materials are available publicly under an open-
source license1 [9].

II. RELATED WORKS

In the literature, one can encounter several approaches to
deﬁning what an RDF stream is. The deﬁnition given in
Section I does not apply directly to all of the works presented
below. For instance, some of them are only appropriate for
streams of RDF graphs, not statements. Also worth mentioning
is the deﬁnition used by the RDF Stream Processing commu-
nity, which focuses on timestamped RDF streams, where data
is annotated with the time, at which the event occurred and/or
was processed [10]. However, the deﬁnition used in this work
can be argued to be more general, as timestamped streaming
can be achieved by the inclusion of additional RDF statements
with the required timestamps.

One of the earlier works tackling efﬁcient RDF streaming is
the introduction of the Streaming HDT (S-HDT) format [11]
– a lightweight binary RDF representation that is oriented
towards resource-constrained IoT devices. The format features
a simple, dictionary-based compression method. Additionally,
a custom node-to-node communication protocol is introduced.
Unfortunately, the authors did not publish their source code.
Moreover, no additional resources or mentions of S-HDT’s
use in practice could be found. S-HDT builds on the earlier
work on HDT [12], which uses a more advanced compression
method, but can only work with entire datasets. Hence, it is
unsuitable for streaming applications.

RDSZ [13] was the ﬁrst RDF streaming approach that
attempted to signiﬁcantly lower the size of the serialized
representation. The method uses the standard Turtle format as
its base, but it also can apply differential encoding in cases that
can beneﬁt from it. The output is then additionally compressed
with Zlib (the Deﬂate algorithm). However, the method seems
rather impractical, being over two times slower than the Turtle
baseline, in serialization and deserialization.

A more elaborate solution to the same problem is the
Efﬁcient RDF Interchange (ERI) format [14]. The algorithm
focuses on achieving competitive compression ratios through
the use of dictionaries, storing structural information about the
graph. ERI assumes that the stream is divided into “blocks”
of triples (usually 4096 in length), with each block being
this is also an important
processed atomically. However,

1https://github.com/Ostrzyciel/jelly-wﬁot-2022

limitation of this approach, as it cannot effectively handle
small blocks, or individual triples/quads. Moreover, the im-
plementation is not integrated with any RDF library (such as
Apache Jena [15]).

Another notable approach is the RDF serialization based on
the binary W3C Efﬁcient XML Interchange (EXI) format [8].
It targets Web of Things environments and industrial devices
that, typically, need to exchange measurement data. RDF EXI
has the ability to integrate a base ontology (TBox only) into
the protocol with the use of code generation, which can greatly
reduce the size of the messages. This is done at the cost
of interoperability. Speciﬁcally, both the producer and the
consumer need to be aware of the ontology that is being used,
and have the necessary code already generated. The authors of
the format claim that one of its biggest advantages is that it is
based on a W3C standard (EXI). However, the implementation
for the RDF serialization was not open-sourced and (possibly
for this reason) the format has seen little adoption.

Over the years, the RDF Stream Processing community
has largely focused on streaming in the context of query
languages, query execution engines, and reasoners [10], for
timestamped RDF streams. However, few approaches to RDF
data streaming were proposed. Worth mentioning is CQUELS-
Cloud, a distributed RDF stream processing framework [16]
that internally compresses the RDF data, using dictionary en-
coding. However, also in this case, the code was not published,
and the protocol is only used internally, within the stream
processing cluster.

Overall, in the past, research on RDF streaming has been
very limited. Several works [8], [13], [14] focused on achiev-
ing high compression ratios, with little regard for the practical
applicability of the proposed solutions. The throughput mea-
surements were only performed on parts of the pipelines (such
as serialization and/or deserialization) in isolation, which is a
poor indicator of real-life performance. It should be also noted
that the mentioned works have been published in 2012–15 with
no follow-up that could be found.

Besides the mentioned works, it is also worth pointing out
that two non-standard binary serializations were implemented
in Apache Jena [17] – using Apache Thrift (2014) and, more
recently, Google Protocol Buffers (2021). These are very
simple serialization formats, with no compression built-in.
The two formats have been presented as particularly suitable
for high-performance streaming. However, Apache Jena only
implements the most rudimentary, byte-level streaming support
with Java IO Streams. This, obviously, is not appropriate for
end-to-end RDF streaming.

III. DESCRIPTION OF THE PROPOSED APPROACH

Bearing in mind the outlined research goals, a solution
was designed, consisting of a new RDF serialization format
and integrations with two streaming protocols. The method
makes extensive use of already available protocols, libraries,
and standards. This has the major beneﬁt of simplifying the
presented reference implementation, as well as any future
implementations for other software and hardware platforms.

Moreover, it helps to avoid numerous performance and security
pitfalls, associated with, e.g., implementing a new network
protocol.

A. Serialization Format

The new JELLY2 serialization format is based on the popu-
lar, high-performance Protocol Buffers format. It uses several
strategies to reduce payload size, while maintaining very high
performance. It supports serializing generalized RDF triples
and quads, which allows it to cover all aspects of the RDF
1.1 speciﬁcation [6]. Moreover, the upcoming RDF-star [18]
standard for reiﬁcation is also supported.
Let us now describe the details of

the proposed se-
rialization. The RDF stream is represented as a series
of RDF_StreamFrame objects, each containing a list of
RDF_StreamRow objects (Fig. 1). The number of rows per
frame is directly not limited by the proposed approach, and
can be as low as one, and as high as the network protocol will
allow. The size of the frame can also vary over the duration
of the stream. The serialization depends on the streaming
protocol to provide reliable transmission of messages, which
is a feature now commonly found in many solutions, such
as gRPC, Kafka, and MQTT. The frames and rows must be
processed strictly in the order, in which they arrive. This is
because preceding rows can set the context for the future rows.
Both the serializer and deserializer must maintain a lightweight
internal mutable state (containing, among others, three lookup
tables), to be able to update this context dynamically. For
streaming brokers (Kafka, MQTT) this places a requirement
on the supported Quality of Service, delivery guarantees and
message offsets.

An RDF_StreamRow is an atomic stream element that can

be one of:

• RDF_StreamOptionsRow – a small header at

the
beginning of the stream that informs the consumer about
the used compression settings.

• RDF_PrefixRow – a new entry in the preﬁx lookup
table (explained below). New entries to lookup tables can
be placed anywhere in the stream.

• RDF_NameRow – a new entry in the name lookup table.
• RDF_DatatypeRow – a new entry in the datatype

lookup table.

• RDF_Triple – a triple consisting of three RDF_Term

objects.

• RDF_Quad – a quad, constructed analogically to a triple.
An RDF_Term object can be one of:
• RDF_IRI – an RDF IRI, expressed as a pair of identi-
ﬁers, one for the preﬁx, and one for the name (remainder
of the IRI). These refer to entries in the preﬁx and name
lookup tables. Both identiﬁers are optional.

• RDF_BNode – a blank node with a unique string iden-

tiﬁer.

2The name does not bear any meaning, beyond being a short for Super-

fast Jellyﬁsh.

7LPH

5’)B6WUHDP)UDPH

5’)B6WUHDP)UDPH

5’)B6WUHDP2SWLRQV5RZ

5’)B3UHIL[5RZ

5’)B1DPH5RZ

5’)B1DPH5RZ

5’)B7ULSOH

5’)B7ULSOH

5’)B1DPH5RZ

5’)B7ULSOH

5’)B3UHIL[5RZ

5’)B1DPH5RZ

5’)B’DWDW\SH5RZ

5’)B7ULSOH

5’)B7ULSOH

5’)B4XDG

Fig. 1: An example JELLY stream.

• RDF_Literal – a literal with its lexical value (as a
string) and, optionally, a language tag or a datatype tag.
The datatype is an identiﬁer referring to an entry in the
datatype lookup table.

• RDF_Triple — a quoted triple in RDF-star.
• RDF_REPEAT – a special tag instructing the deserializer
to repeat the term that was previously seen in this position
(subject, object, predicate, or graph name) of the triple
or quad.

One notable feature of the proposed format is the use of
three, dynamically updated, lookup tables. They are integer-
indexed and their maximum size is communicated by the
producer to the consumer at the start of the stream (in the
stream options row). The consumer can use this information
to pre-allocate the necessary lookup tables, but it can also
expand them dynamically as needed. The lookup table size,
obviously, inﬂuences both the compression performance and
the memory usage. Thus, it can be freely adjusted from as
low as single-digit numbers to 228, however, using such huge
lookup tables would be impractical due to excessive memory
consumption. The lookup table size is usually between 30 and
10000.

The serializer is responsible for adding new elements to
the lookup, and evicting old ones. Here, any algorithm can
be applied to achieve this. In the reference implementation,
a linked hash map with a least-recently-used (LRU) policy is
used. It is a relatively uncomplicated algorithm that achieves
reasonable compression efﬁciency, by dynamically replacing
least recently used items in the lookup with new ones, when
the need arises. These updates are communicated to the
consumer with the RDF_PrefixRow, RDF_NameRow, and
RDF_DatatypeRow objects. The task of the deserializer is
more straightforward. Its lookups can be implemented as plain
arrays, with O(1) update and retrieve complexity (see Fig. 2).
The RDF_REPEAT term offers an efﬁcient, O(1) com-
pression mechanism, similar in its premise to the Turtle
RDF serialization. By eliminating repeating terms,
it not
only reduces the size of the data to be transmitted, but also
speeds up processing. This speedup is due to the serializer
and deserializer not having to encode/decode the same term
multiple times.

5’)B3UHIL[5RZ

5’)B1DPH5RZ

LG(cid:29)(cid:3)(cid:21)(cid:3)
YDOXH(cid:29)(cid:3)(cid:3)KWWS(cid:29)(cid:18)(cid:18)ZZZ(cid:17)Z(cid:22)(cid:17)RUJ(cid:18)QV(cid:18)VRVD(cid:18)(cid:3)

LG(cid:29)(cid:3)(cid:22)(cid:3)
YDOXH(cid:29)(cid:3)(cid:3)6HQVRU(cid:3)

VHW(cid:3)QHZ(cid:3)YDOXH

VHW(cid:3)QHZ(cid:3)YDOXH

3UHIL[(cid:3)ORRRNXS
WDEOH

(cid:20)

(cid:21) (cid:22)

Q

(cid:20) (cid:21)

(cid:22)

P

5’)B,5,

SUHIL[,G(cid:29)(cid:3)(cid:21)(cid:3)
QDPH,G(cid:29)(cid:3)(cid:22)(cid:3)

JHW

JHW

1DPH(cid:3)ORRRNXS
WDEOH

KWWS(cid:29)(cid:18)(cid:18)ZZZ(cid:17)Z(cid:22)(cid:17)RUJ(cid:18)QV(cid:18)VRVD(cid:18)6HQVRU

Fig. 2: IRI reconstruction during deserialization.

Overall, the available compression settings should allow the
serialization to ﬂexibly ﬁt the needs of both high-performance
servers and resource-constrained IoT devices. The lookup
tables can be almost arbitrarily sized, and updated with any
algorithm. For example, in an IoT device that produces only
a stream of triples with ﬁxed subjects and predicates, static
(or partially static) lookup tables can be employed. The preﬁx
table can be disabled entirely to simplify encoding and reduce
memory requirements, at the cost of increased payload size.
Conversely, in high-performance devices, larger lookup tables
may be used, with more sophisticated eviction strategies (for
example, least-frequently used). Additional compression (e.g.,
gzip) of the serialized messages can be introduced, to further
reduce the size of the payload. This is, however, not within
the scope of the serialization format itself, and is typically
handled by the streaming protocol.

The serialization format is formalized using the Protocol
Buffer language version 3. This speciﬁcation can be used
to quickly generate the needed serialization/deserialization
boilerplate code, in any of the many supported languages.
Currently, a reference implementation in Scala is provided [9].
The implementation is integrated with the popular Apache
Jena RDF library.

B. Integration with Streaming Protocols

The serialization format by itself is of little use – it is
necessary to integrate it with network streaming protocols. To
fulﬁll this requirement, JELLY is integrated with two protocols
that can be used for streaming purposes. The ﬁrst is gRPC3
– a Remote Procedure Call (RPC) framework, supporting bi-
directional streaming, oriented towards synchronous communi-
cation between services. gRPC’s services are deﬁned using the
Protocol Buffers Interface Deﬁnition Language, which allows
for implementing code compliant with the protocol speciﬁca-
tion quickly, on many platforms. gRPC is based on the modern
HTTP/2 standard, which natively supports gzip compression,
with content type negotiation. The second integration is with
Apache Kafka4, a popular asynchronous, distributed streaming
platform. It possesses a number of advanced features that allow

building highly scalable and resilient streaming applications.
Both integrations are based on the Akka framework5.

It is important to note that although both gRPC and Kafka
support streaming communication, they have very different
architectures and are designed for different applications. In
Section IV, one of the key aspects of the evaluation is address-
ing this very issue, to establish the strengths and weaknesses
of each approach, when applied to RDF streaming.

One reason for this particular choice of streaming protocols
is precisely due to them being very different. This helps
demonstrate the method’s applicability in a variety of scenar-
ios. Secondly, both gRPC and Kafka are high-performance,
mature solutions, that have seen wide adoption in the industry.

IV. EXPERIMENTAL EVALUATION

Selected aspects of the the proposed method have been
evaluated in a comprehensive set of benchmarks. The tests
were performed on a 14 vCore virtual machine (Intel Xeon
E5-2640 v2) with 16 GB of RAM, running Ubuntu 20.04.4
LTS, Linux kernel version 5.4.0. The Java Virtual Machine
(JVM) used was GraalVM Community 22.1.0, running in the
standard JIT mode.

The RDF streaming methods presented in Section II are
not compared in most of the experiments reported here. The
reasons are that (1) their implementations are not publicly
available (S-HDT, EXI, CQUELS-Cloud, RDSZ), or (2) they
are not integrated with any RDF library or network protocol
(ERI). To make reliable streaming throughput and latency
assessment, the compared methods should be based on the
same RDF library. This is necessary to properly compare the
performance of the full pipeline – transforming in-memory
objects to the serialized representation, and back. Similarly,
access to the implementation is needed to compare the meth-
ods on the same test platform (hardware, operating system,
etc.). As no such methods are available, JELLY is compared
to the serialization formats already available in Apache Jena.
For the purpose of the evaluation, Kafka stream connectors
were provided for the built-in Jena serialization formats.

A. Datasets Used in Experiments

For the experiments, a subset of the datasets used in the
evaluation of ERI [14] was selected, focusing on the streaming
datasets. Not all were included, either because of their inva-
lidity6 or processing time limitations. Moreover, to avoid disk
overhead inﬂuencing the benchmarks, all selected datasets had
to ﬁt into system memory. Thus, the Flickr_Event_Media and
LOD_Nevada datasets were trimmed to the the ﬁrst 10 million
triples. The following ten datasets were used: Mix, Identica,
Wikipedia, AEMET-1, AEMET-2, Petrol, Flickr_Event_Media
(10M), LOD_Nevada (10M), Eurostat_migr_reschange, Eu-
rostat_tour_cap_nuts3. It
these
datasets were designed to be representative of a wide variety

is worth pointing out

that

3https://grpc.io/
4https://kafka.apache.org/

5https://akka.io/
6For example, the LinkedMDB dataset contains invalid IRIs and cannot be

loaded into Apache Jena.

of semantic data streaming use cases. Thus, they are based on
data gathered from real applications and services.

Unless otherwise stated, the following results were averaged
over all ten datasets. Detailed per-dataset results can be found
in the supplementary materials.

B. Serialization and Deserialization Performance

First, the raw serialization and deserialization performance
was measured for JELLY (four variants of compression set-
tings) and four other serializations included in Apache Jena.
Jena’s serializers can only work with RDF graphs, thus the
stream of triples was transformed into a stream of 1000-triple
graphs (even though RDF graphs are sets of triples, in the
JVM environment not every Set whose elements are triples is
a Jena Graph object). The benchmarks were ran on a single
thread, with JVM being able to use additional threads, e.g., for
just-in-time compilation and garbage collection. The following
methods were tested:

• jelly-full – JELLY with the default settings – preﬁx table
size: 150, name table size: 4000, datatype table size: 32.
• jelly-nopreﬁx – jelly-full, with the preﬁx table disabled.
• jelly-nopreﬁx-sm – jelly-nopreﬁx, with the name table

size reduced to 256.

• jelly-norepeat – jelly-full, without

the use of

the

RDF_REPEAT term.

• jena-protobuf – Jena’s Protocol Buffers serialization.
• jena-n3 – W3C N-Triples format.
• jena-turtle – W3C Turtle format.
• jena-xml – W3C RDF/XML format.
The results can be found in Table I. All values are in-
dicated in thousands of triples processed per second (kT/s;
highest values in bold). Overall, JELLY offers signiﬁcantly
faster deserialization than any Jena-based method, including
its Protocol Buffers implementation. For serialization,
the
proposed method is visibly slower than Jena’s Protocol Buffers
implementation and much slower than the N-Triples format.
This difference can be explained by the binary encoding and
additional compression performed by JELLY. In serialization,
the nopreﬁx and nopreﬁx-sm variants are the fastest, due to
the simpler compression algorithm (no preﬁx lookup table).
Among all variants, norepeat is visibly the slowest, which
is due to the additional burden of encoding the same term
multiple times, instead of using an RDF_REPEAT term.

In Table I, the last column indicates the total theoretical
throughput of the method, calculated as the smaller value
of the serialization and deserialization speeds. This simple
calculation obviously cannot be used as an indicator of how the
methods would perform in real-life conditions. It is, however,
interesting to note that, owing to their superior deserialization
speeds, all variants of JELLY should, theoretically, outperform
Jena’s serializers. The text-based serializations (N3, Turtle,
RDF/XML) are not competitive with the binary representa-
tions, with the notable exception of N3’s serialization speed.
In further, end-to-end streaming experiments, the perfor-
mance of these methods is examined in more realistic sce-
narios. However, the largely theoretical results presented here

TABLE I: Raw Ser/Des Performance (kT/s)

Method
jelly-full
jelly-nopreﬁx
jelly-nopreﬁx-sm
jelly-norepeat
jena-protobuf
jena-n3
jena-turtle
jena-xml

Serialization
562.45
752.92
765.66
453.93
1060.07
2664.29
155.90
71.95

Deserialization
820.35
889.99
882.75
702.61
465.04
148.05
158.19
79.23

Th. throughput
562.45
752.92
765.66
453.93
465.04
148.05
155.90
71.95

help establish the baseline performance for the investigated
methods.

C. Serialized Representation Size

The size of the serialized representations was compared for
JELLY, the Jena-based serializations, and two earlier methods
(ERI [14] and the non-streaming HDT [12]), based on the
ﬁgures reported in the paper about ERI [14]. For Jena serial-
izations, 1000-triple message size was assumed, the same as in
the previous experiment. For ERI and HDT only the ﬁgures
for 4096-triple messages were available. Additionally, each
method was tested with a supplementary gzip compression
stage.

The results can be found in Table II. The compression ratios
are calculated as the ratio between the serialized size of the
representation and the size for the equivalent uncompressed
N-Triples ﬁle. The reported ﬁgures are the geometric means
of the ratios on all ten datasets. It can be observed that JELLY,
when used without gzip, achieves much better results than
RDF/XML or Turtle, while being vastly faster than either of
them. With gzip, its compression ratios are comparable to the
Jena-based results, and noticeably worse than ERI, but better
than HDT. The differences between the different variants of
the proposed method are relatively small. This suggests that,
for example, using the preﬁx table is useful only in constrained
network environments, or when working with data that lends
itself well to this particular compression method.

The Jena Protocol Buffers-based representation achieves
very poor compression ratios, with larger payloads than
N-Triples (when used without gzip). ERI offers the best
compression among all tested approaches. However, as it was
not integrated with an RDF library, it could not be examined
in the other, performance-oriented experiments. Moreover, the
larger message size (4096 vs 1000) likely gives an advantage
to both ERI and HDT. Consequently, it is impossible to say if
ERI and HDT would outperform other approaches in practice.
It is crucial to remember that the representation size is just
one of the many variables inﬂuencing streaming performance
and, as evidenced in the following sections, it is by itself a
poor indicator of how the method will perform.

D. End-to-End Streaming Throughput

To evaluate the practical achievable performance of the
method, it was tested in tandem with two streaming protocols
(gRPC and Kafka), over a full network stack. Additionally,

TABLE II: Serialized Size Comparison for Jelly and Compet-
ing Methods.

TABLE III: End-to-End Streaming Throughput (kT/s)

Method

Compression ratio
(geom. mean)

Serialization
jelly-full
jelly-full
jelly-nopreﬁx
jelly-nopreﬁx
jelly-nopreﬁx-sm
jelly-nopreﬁx-sm
jelly-norepeat
jelly-norepeat
jena-protobuf
jena-protobuf
jena-n3
jena-n3
jena-turtle
jena-turtle
jena-xml
jena-xml
ERI-4k
ERI-4k-Nodict
HDT-4k

25.55 %
3.41 %
27.57 %
3.44 %
29.48 %
3.69 %
29.10 %
5.49 %
108.33 %
6.71 %
100.00 %
5.80 %
72.20 %
3.20 %
50.05 %
2.99 %
* 2.23 %
* 2.11 %
* 6.71 %
* Estimated from the results reported in the paper
on ERI [14].

gzip
−
+
−
+
−
+
−
+
−
+
−
+
−
+
−
+
N/A
N/A
N/A

two scenarios of limited networking were simulated, using the
NetEm Linux kernel module [19], by introducing a limit on
the bandwidth and an artiﬁcial latency for the packets. The
ﬁrst scenario had 10 ms latency and 100 Mbit/s bandwidth
(10 / 100) and the other had 15 ms latency and 50 Mbit/s
bandwidth (15 / 50). To maintain a possibly fair comparison,
in tests involving Kafka, only the connection between the
producer and the broker was throttled – the consumer had
always unlimited networking. For Kafka, to avoid issues with
rebalancing and “warmup” of the broker, a single cluster,
with one consumer group and single partition was used. Other
settings were left at their defaults, with at-most-once delivery
guarantees from Kafka.

The results are presented in Table III. In all network
conditions JELLY vastly outperforms Jena-based serializations,
which is in line with the results from the previous experiment
on theoretical throughput. It can be observed that gzip slows
down streaming in unlimited network conditions, but as soon
as bandwidth limitations are introduced, it becomes indis-
pensable for Kafka streaming. For gRPC this effect is only
visible with 50 Mbit/s networking. Finally, Kafka can generally
provide better overall throughput than gRPC. However, this
advantage seems to shrink, when network bandwidth becomes
limited.

E. End-to-End Streaming Latency

Maintaining low latency is crucial in many streaming ap-
plications, including IoT, often making the difference between
the technology being feasible or not [20]. Thus, the streaming
latency of the proposed method was examined in a variety
of settings. In each test, a stream was opened between the
producer and the consumer. Next, 1000 messages were pub-
lished at regular intervals. The latency for each message was
measured as the time between it entering the serializer and it

C
P
R
g

a
k
f
a
K

Method
Serialization
jelly-full
jelly-full
jelly-nopreﬁx
jelly-nopreﬁx
jelly-full
jelly-full
jelly-nopreﬁx
jelly-nopreﬁx
jena-protobuf
jena-protobuf
jena-n3
jena-n3

gzip
−
+
−
+
−
+
−
+
−
+
−
+

Network conditions

Unlimited
398.55
270.11
482.51
314.91
480.73
322.18
597.55
391.37
282.33
257.09
125.15
126.49

10 / 100
292.91
274.45
269.76
311.45
56.67
292.69
52.75
342.58
18.74
227.28
20.16
120.35

15 / 50
150.12
268.22
138.43
311.79
35.91
272.03
33.34
304.86
11.85
186.61
12.73
123.27

leaving the deserializer (end-to-end). All combinations of the
following settings were tested:

• Network: three different setups, same as in the previous

experiment.

• Message size: 5, 50, 200 triples.
• Interval between messages: 100 µs, 1 ms, 10 ms.
• Dataset: Wikipedia, AEMET-1, AEMET-2, Petrol,

Flickr_Event_Media (10M)

Each run produced a series of 1000 values, an example of
which is presented in Fig. 5. Not all results could be presented
here, due to their excessive volume, however, they are available
in the supplementary materials [9].

Fig. 3 compares the performance of non-gzip serializations
in unlimited network conditions. It can be clearly seen that
JELLY provides much lower latencies than Jena-based seri-
alizations, and that gRPC outperforms Kafka in all of the
presented cases. The same observations hold true for limited
networking conditions (not presented here). Fig. 4 presents
how gzip compression impacts latencies in limited and unlim-
ited networks. Here, it is apparent that gzip increases latency
in unconstrained network conditions, which is expected, as
it necessitates additional processing. However, in a 50 Mbit/s
network, gzip starts giving a clear advantage for messages that
are large enough to beneﬁt from the additional compression.
Overall, it can be observed that the combination of JELLY
and gRPC results in sub-one millisecond latencies, greatly
improving over Kafka, and the standard serializations.

F. Evaluation Limitations

It is important to note the limitations of the above evalu-
ation. Firstly, in end-to-end streaming both the producer and
the consumer were running on the same virtual machine and
the same JVM, which may result in resource contention. On
the other hand, this setup has allowed for sub-microsecond
precision in measuring throughput and latency. Secondly, the
results could be inﬂuenced by any background tasks that have
been scheduled by the JVM, such as garbage collection and
JIT compilation. To mitigate this,
the tests include a few
“warm-up” runs and are then repeated several times to gather
more representative data.

Method

grpcμjellyμfull

grpcμjellyμnoprefix

kafkaμjellyμfull

kafkaμjellyμnoprefix

kafkaμjenaμproto

kafkaμn3

Method

grpcμjellyμfull

grpcμjellyμfullμg(ip

kafkaμjellyμfull

kafkaμjellyμfullμg(ip

4.0

3.5

)

3.0

m

(

2.5

2.0

y
c
n
e
t
a
L

1.5

1.0

0.5

2.5

2.0

)
s
m

(

1.5

y
c
n
e
t
a
L

1.0

0.5

13.5

13.0

12.5

)
s
m

(

y
c

12.0

e
t
a
L

11.5

11.0

10.5

19.0

18.5

18.0

)
s
m

(

17.5

y
c

17.0

e
t
a
L

16.5

16.0

15.5

Interval = 100 μ 

Interval = 1 m 

Interval = 10 m 

5

50

200

5

50

200

5

50

200

Message  ize (triple )

Me  age  ize (triple )

Me  age  ize (triple )

Fig. 3: Streaming latency in unlimited network conditions.

 et. = u limited ) i t. = 100 μs

 et. = u limited ) i t. = 1 ms

 et. = u limited ) i t. = 10 ms

 et. = 10 ms / 100 Mbit/s ) i t. = 100 μs  et. = 10 ms / 100 Mbit/s ) i t. = 1 ms  et. = 10 ms / 100 Mbit/s ) i t. = 10 ms

 et. = 15 ms / 50 Mbit/s ) i t. = 100 μs

 et. = 15 ms / 50 Mbit/s ) i t. = 1 ms

 et. = 15 ms / 50 Mbit/s ) i t. = 10 ms

5

50

200

5

50

200

5

50

200

Message si(e (triples)

Message si(e (triples)

Message si(e (triples)

Fig. 4: Inﬂuence of gzip compression and network conditions on streaming latency.

 
 
 
 
 
 
 
19.44 ms

39.04 ms

Method

grpc-jelly-full

kafka-jelly-full

1

10

)
s
m

(

y
c
n
e
t
a
L

0

10

0

200

400

600

800

1000

Message

Fig. 5: Streaming latency of 1000 consecutive messages (net-
work: unlimited, interval: 100 µs, message size: 50, dataset:
AEMET-1)

V. CONCLUSIONS AND FUTURE WORK

The presented approach makes signiﬁcant progress towards
enabling practical RDF data streaming in IoT and future edge-
cloud systems, by meeting the demands for high performance
(as evidenced in the exhaustive performance evaluation), scala-
bility (by being conﬁgurable), and portability (by being simple
to implement, and by the use of established technologies
and standards). JELLY advances the current state of the art,
being the ﬁrst end-to-end, publicly available RDF streaming
solution. This is in stark contrast to the current state-of-the-
art solutions, which solve only parts of the problem, and are
(most often) closed-source, which hampers the development of
future semantic data streaming systems. The proposed method
provides high performance and scalability in a variety of
scenarios, while being relatively simple to implement. It was
integrated with two modern communication protocols, and a
popular RDF framework, making it readily applicable.

There remains much to be explored in the topic of semantic
data streaming. In the future, the performance of JELLY will
be evaluated in a variety of real world-anchored use cases,
including those pertaining to edge-cloud systems. Namely, it
is planned to be used in the currently ongoing ASSIST-IoT EU
Horizon 2020 project, to meet the demands for low-latency and
high-throughput RDF streaming. Furthermore, it is planned
to improve the implementation of the protocol and create
new implementations to facilitate JELLY’s reuse on various
platforms. Currently considered is the popular Python rdﬂib
library, and a C++ implementation for microcontrollers. As for
streaming protocols, an integration with the MQTT standard7
is planned, due to its ubiquity in modern IoT ecosystems.

7https://mqtt.org/

REFERENCES

[1] J. Arulraj, A. Chatterjee, A. Daglis, A. Dhekne, and U. Ramachandran,
“eCloud: A vision for the evolution of the edge-cloud continuum,”
Computer, vol. 54, no. 5, pp. 24–33, 2021.

[2] A. Taivalsaari, T. Mikkonen, and C. Pautasso, “Towards seamless iot
device-edge-cloud continuum:,” in ICWE 2021 Workshops, M. Bakaev,
I.-Y. Ko, M. Mrissa, C. Pautasso, and A. Srivastava, Eds.
Cham:
Springer International Publishing, 2022, pp. 82–98.

[3] M. Ganzha, M. Paprzycki, W. Pawłowski, P. Szmeja,

and
K. Wasielewska, “Semantic interoperability in the Internet of Things:
An overview from the INTER-IoT perspective,” Journal of Network
and Computer Applications, vol. 81, pp. 111–124, 2017.

[4] H. Rahman and M. I. Hussain, “A comprehensive survey on semantic
interoperability for Internet of Things: State-of-the-art and research chal-
lenges,” Transactions on Emerging Telecommunications Technologies,
vol. 31, no. 12, p. e3902, 2020.

[5] M. Ganzha, M. Paprzycki, W. Pawłowski, P. Szmeja, K. Wasielewska,
B. Solarz-Niesłuchowski, and J. S. d. Puga García, “Towards high
throughput semantic translation,” in Interoperability, Safety and Security
in IoT. Springer, 2017, pp. 67–74.

[6] R. Cyganiak, M. Lanthaler, and D. Wood, “RDF 1.1 concepts
syntax,” W3C, W3C Recommendation, Feb. 2014,

and abstract
https://www.w3.org/TR/2014/REC-rdf11-concepts-20140225/.

[7] R. Tommasini and P. Bonte, “Web stream processing with rsp4j,” in
Proceedings of the 15th ACM International Conference on Distributed
and Event-based Systems, 2021, pp. 164–167.

[8] S. Käbisch, D. Peintner, and D. Anicic, “Standardized and efﬁcient RDF
encoding for constrained embedded networks,” in European Semantic
Web Conference. Springer, 2015, pp. 437–452.

[9] P. Sowi´nski, K. Wasielewska-Michniewska, M. Ganzha, W. Pawłowski,
the
P. Szmeja, and M. Paprzycki, “Efﬁcient RDF Streaming for
Edge-Cloud Continuum – materials,” Jul. 2022. [Online]. Available:
https://doi.org/10.5281/zenodo.6815017

[10] R. Tommasini, P. Bonte, F. Ongenae, and E. Della Valle, “RSP4J:
An API for RDF stream processing,” in European Semantic Web
Conference. Springer, 2021, pp. 565–581.

[11] H. Hasemann, A. Kröller, and M. Pagel, “RDF provisioning for the
Internet of Things,” in 2012 3rd IEEE International Conference on the
Internet of Things.

IEEE, 2012, pp. 143–150.

[12] J. D. Fernández, M. A. Martínez-Prieto, C. Gutiérrez, A. Polleres, and
M. Arias, “Binary RDF representation for publication and exchange
(HDT),” Journal of Web Semantics, vol. 19, pp. 22–41, 2013.

[13] N. Fernández, J. Arias, L. Sánchez, D. Fuentes-Lorenzo, and Ó. Corcho,
“RDSZ: an approach for lossless RDF stream compression,” in European
Semantic Web Conference. Springer, 2014, pp. 52–67.

[14] J. D. Fernández, A. Llaves, and O. Corcho, “Efﬁcient RDF interchange
(ERI) format for RDF data streams,” in International Semantic Web
Conference. Springer, 2014, pp. 244–259.

[15] J. J. Carroll, I. Dickinson, C. Dollin, D. Reynolds, A. Seaborne, and
K. Wilkinson, “Jena: implementing the semantic web recommendations,”
in Proceedings of the 13th international World Wide Web conference on
Alternate track papers & posters, 2004, pp. 74–83.

[16] D. Le-Phuoc, H. Nguyen Mau Quoc, C. Le Van, and M. Hauswirth,
“Elastic and scalable processing of linked stream data in the cloud,” in
International Semantic Web Conference. Springer, 2013, pp. 280–297.
binary
Available:

using
https://jena.apache.org/documentation/io/rdf-binary.html

[17] Apache

Foundation,

[Online].

Software

Apache

Thrift.”

“RDF

[18] O. Hartig, P.-A. Champin, G. Kellogg, A. Seaborne et al., “RDF-star
and SPARQL-star,” W3C, W3C Community Group Draft Report, Jun.
2022, https://w3c.github.io/rdf-star/cg-spec/editors_draft.html.

[19] S. Hemminger et al., “Network emulation with NetEm,” in Linux conf

au, vol. 5, 2005, p. 2005.

[20] P. Schulz, M. Matthe, H. Klessig, M. Simsek, G. Fettweis, J. Ansari,
S. A. Ashraf, B. Almeroth, J. Voigt, I. Riedel et al., “Latency critical
IoT applications in 5G: Perspective on the design of radio interface and
network architecture,” IEEE Communications Magazine, vol. 55, no. 2,
pp. 70–78, 2017.

 
