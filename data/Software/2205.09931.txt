Measure the Diversity of Open Source Software Projects’ Forks
with Fork Entropy

Zhiwen Zheng, Liang Wang, Jierui Zhang, Baihui Sang, Xianping Tao
State Key Laboratory for Novel Software Technology
Nanjing University, Nanjing, China
{zwzheng,jieruizhang,baihuisang}@smail.nju.edu.cn,{wl,txp}@nju.edu.cn

2
2
0
2

y
a
M
0
2

]
E
S
.
s
c
[

1
v
1
3
9
9
0
.
5
0
2
2
:
v
i
X
r
a

ABSTRACT
Forks play a central role in modern pull-based OSS development.
Although rich empirical results on the participants, challenges, and
features of forks have been announced, there is little discussion
on quantitatively measuring the population of forks around OSS
projects. In this paper, we take a step toward enriching the set
of metrics about forks by proposing the fork entropy to measure
the diversity of fork populations around OSS projects. We opera-
tionalize the proposed fork entropy based on Rao’s quadratic en-
tropy with a distance function deﬁned on the forks’ modiﬁcations
to project ﬁles. After verifying the construct validity of fork en-
tropy, we show the usefulness of fork entropy in understanding
and predicting OSS development in terms of external productiv-
ity, the acceptance rate of external pull-requests, and code quality
using a dataset consisting of ﬁfty popular OSS projects hosted on
GitHub. By conducting regression analyses, we ﬁnd that fork en-
tropy signiﬁcantly and positively aﬀects external productivity, the
acceptance rate of external pull-requests, and code quality, even
though sometimes with a small eﬀect. However, as expected, fork
entropy at a high level sometimes plays a negative role in OSS de-
velopment. We also observe fork entropy can magically moderate
other factors’ eﬀect on some project outcomes. We believe our new
metric of fork entropy is helpful to guide practices of OSS develop-
ment.

CCS CONCEPTS
• Software and its engineering → Open source model; • Gen-
eral and reference → Metrics.

KEYWORDS
Open-source software, Software metrics, Fork entropy, Diversity

ACM Reference Format:
Zhiwen Zheng, Liang Wang, Jierui Zhang, Baihui Sang, Xianping Tao. 2022.
Measure the Diversity of Open Source Software Projects’ Forks with Fork
Entropy. In Proceedings of ACM Conference (Conference’17). ACM, New York,
NY, USA, 12 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
Conference’17, July 2017, Washington, DC, USA
© 2022 Association for Computing Machinery.
ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn

1 INTRODUCTION
Forks play a central role in modern pull-based OSS development as
precursors of making contributions to source repositories through
pull-requests [15, 27, 28, 33]. On social coding platforms such as
GitHub1 and GitLab2, forks are created for various purposes such
as archiving, learning, ﬁxing bugs, adding new features, and etc
[28, 36]. Existing studies suggest that forks create increased oppor-
tunities for community engagement and voluntary participation
[17, 64]. Having a large number of forks is considered as an in-
dicator of an OSS project being popular [17]. There are also evi-
dences showing that the number of a project’s forks is positively
correlated to the amount of contributions it receives from external,
non-core members [57]. However, merely having a large popula-
tion of forks does not necessarily imply a productive and healthy
OSS project. As pointed out in [64], ineﬃcient forks can lead to re-
dundant eﬀorts such as duplicated pull-requests [33]. As a result,
an in-depth understanding of an OSS project’s fork population can
provide important insights about its developing status [28].

Compared to the rich body of empirical results about the par-
ticipants [28], challenges [64], and features [63] of forks, there
is few discussion on how to quantitatively measure the popula-
tion of forks around OSS projects. The most frequently, if not the
only, adopted metric in existing literature is the number of forks
[17, 57], which, as discussed above, is inadequate in characterizing
a project’s status. Given the central role of forks in OSS develop-
ment, and the importance of quantitative metrics in analyzing, and
predicting the development of OSS projects and communities [23],
we argue that a more comprehensive set of metrics about OSS forks
is desirable.

In this work, we take a step toward enriching the set of metrics
about forks by proposing the fork entropy to measure the diver-
sity of fork populations around OSS projects. Our interest in mea-
suring the diversity of forks is inspired by the abundant evidence
showing the importance of team diversity in team performance
during OSS development and in general knowledge creation pro-
cesses [6, 14, 38, 55, 58]. While existing studies explore the diversity
of OSS teams from diﬀerent aspects including social diversity [6],
gender and tenure diversity [14, 55], culture and country diversity
[19, 54], and linguistic diversity [56], there lacks formal discussions
on how to measure the diversity of forks created by the participants
of OSS projects, and what are the impact of fork diversity on OSS
development, to the best of our knowledge.

To ﬁll the niche, we propose to calculate the proposed fork en-
tropy with the Rao’s quadratic entropy [42]. The Rao’s quadratic
entropy provides us with a solid ground to measure the expected

1http://www.github.com/
2https://about.gitlab.com/

 
 
 
 
 
 
Conference’17, July 2017, Washington, DC, USA

Z. Zheng et al.

dissimilarity between two samples taken at random from the popu-
lation, which is widely adopted to quantify population and ecolog-
ical diversity [11, 42]. We further operationalize fork entropy with
a distance function deﬁned on the forks’ modiﬁcations to project
ﬁles. Modiﬁcations to ﬁles are the ﬁrsthand evidences about the
content of a fork and how it diﬀers from other forks, which can ef-
fectively be mined from the repositories of a project’s forks. After
verifying the construct validity of fork entropy to make sure that it
measures the diversity of forks as expected following the practices
in [13], we show the usefulness of fork entropy in understanding
and predicting OSS development in terms of external productivity
[53, 55, 57, 59], the acceptance rate of external pull-requests [64],
and code quality [24, 31, 44, 57, 59] using a dataset consisting of
ﬁfty popular OSS projects hosted on GitHub with the following
research questions.

RQ1: What is the eﬀect of fork entropy on an OSS project’s external

productivity?

By measuring an OSS project’s external productivity as the num-
ber of commits integrated from volunteer-owned forks into the
project’s source repository, in general, we ﬁnd fork entropy signif-
icantly and positively aﬀects external productivity. But sometimes,
e.g., when projects have large-scale fork populations or become
relatively mature, an increased fork entropy can decline external
productivity.

RQ2: How does fork entropy inﬂuence the acceptance rate of exter-

nal pull-requests?

We compute the proportion of the merged pull-requests in closed
ones as a proxy of the acceptance rate of external pull-requests.
Generally, we ﬁnd that fork entropy signiﬁcantly and positively af-
fects the acceptance rate of external pull-requests but with a small
eﬀect. And fork entropy can also moderate other factors’ impact
on the acceptance rate of external pull-requests.

RQ3: What is the correlation between fork entropy and OSS projects’

code quality?

We assess an OSS project’s code quality by the number of bug-
report issues. Conservatively, we ﬁnd fork entropy signiﬁcantly
and positively aﬀects the code quality of OSS projects with a medium
eﬀect. And fork entropy can also moderate the rise of bug-report
issues caused by the expansion of fork populations.

As a result, fork entropy generally plays a signiﬁcant and posi-
tive role in OSS development even though it sometimes performs
negatively. Furthermore, fork entropy can also moderate other fac-
tors’ eﬀects on the development of OSS projects, such as the growth
rate of external productivity with respect to the number of forks.
Our contributions in this article are central three folds. First, we en-
rich the set of metrics about forks by proposing the fork entropy
to measure the diversity of fork populations around OSS projects.
And we develop a framework to operationalize fork entropy by
considering the forks’ modiﬁcations to project ﬁles. Second, be-
sides the construct validity of fork entropy, we also conduct em-
pirical validations to show the usefulness of fork entropy in under-
standing and predicting OSS development in terms of external pro-
ductivity, the acceptance rate of external pull-requests, and code
quality. Third and last, we argue implications from the perspective

of fork entropy in understanding and guiding the practices for OSS
development in fork-based social coding.

The rest of this paper is organized as follows. Sec. 2 introduces
the background and related work. Sec. 3 explains the operational-
ization of the proposed fork entropy and discusses its construct
validity. In Sec. 4, we expound on the methods of experimental
validations conducted to show the usefulness of fork entropy. The
results are illustrated in Sec. 5. Sec. 6 discusses the eﬀects of fork
entropy, the implications on OSS development, and the threats to
our work’s validity. Finally, we conclude in Sec. 7.

2 BACKGROUND & RELATED WORK
This section introduces the background and works closely related
to this work.

2.1 Pull-Based OSS Development
The pull-based development model is a modern paradigm for geo-
graphically distributed software development [27]. The workﬂow
of the pull-based model is reﬁned into seven steps, including fork,
clone, edit, sync, push, submit, and evaluation [15, 33]. With as-
sembling the codebase and assistant functions such as task man-
agement, code review, DevOps tools, etc., the pull-based model
simpliﬁes the participation process and lowers the entry barrier
for volunteers compared with the traditional patch-based model
[27]. Moreover, for OSS projects, the pull-based model divides de-
velopers into two groups called “cathedral” and “bazaar” [45]. The
former includes maintainers responsible for controlling projects’
progress and handling external contributions. The latter consists of
volunteers developing in their forks independently and contribut-
ing to source repositories via pull-requests. Although the division
of labor between maintainers and volunteers encourages parallel
and distributed collaboration [65], the loose coordination, misalign-
ment, and conﬂict among developers may cause ineﬃciency in
terms of lost contributions, rejected pull-requests, redundant de-
velopment, and fragmented communities [64]. Nevertheless, there
are few discussions on quantitatively measuring the population of
forks around OSS projects. In this work, we enrich the set of met-
rics about forks by proposing fork entropy to measure the diversity
of forks.

2.2 Diversity Metrics in OSS Projects
We observe that most existing software engineering studies related
to our work mainly focus on the diversity of OSS team members.
The gender diversity of team members is widely studied and found
to promote the project’s growth [6], improve team productivity
[55], and reduce community smells [14]. In addition, Aué et al. ﬁnd
a signiﬁcant and positive correlation between the country diver-
sity of team members and the project’s growth [6]. Vasilescu et al.
suggest that tenure diversity positively impacts team productivity
[55]. And Daniel et al. measure the reputation and role diversity of
participants and state that both positively aﬀect the community en-
gagement and market success of OSS projects [19]. And yet, to the
best of our knowledge, there is a lack to quantify the diversity of
forks formally. Besides, the above diversity metrics are measured
using either the Blau index [9] or the coeﬃcient of variation [3].

Measure the Diversity of Open Source Software Projects’ Forks with Fork Entropy

Conference’17, July 2017, Washington, DC, USA

The Blau index is a well-established diversity measure for categor-
ical variables (e.g., gender [55] and country [6]) that computes the
probability that two samples randomly selected from the popula-
tion belong to diﬀerent categories. And the coeﬃcient of variation
measures the dispersion degree of an assemblage of numerical vari-
ables (e.g., tenure [55] and reputation [19]) by calculating the ratio
of the standard deviation to the mean. Both methods are not suit-
able to calculate the proposed fork entropy because of the limita-
tions on the data type.

2.3 Measurements of Diversity
There is a consensus that the concept of diversity is multi-faceted,
which can be generally divided into three components, including
richness, evenness, and disparity [30]. Richness denotes the abso-
lute number of species present in a population, evenness is the
equitability of a population’s species abundance distribution, and
disparity refers to the dissimilarities between species [18]. As a
complicated concept, diversity has been instantiated to diﬀerent
metrics depending on the expectations of speciﬁc applications. For
example, species richness itself as an indicator focuses on the rich-
ness component of the diversity concept, while the Gini coeﬃcient
used to measure income inequality emphasizes the disparity com-
ponent [18]. For the context of OSS development, forks become dif-
ferent naturally due to the diﬀerence in expertise, experience, and
intention between developers [48]. Thus, we focus on the dispar-
ity component of the diversity concept and quantify the diﬀerence
in ﬁle modiﬁcations between forks. We apply the Rao’s quadratic
entropy to calculate fork entropy because it measures the expecta-
tion of dissimilarity between two samples taken at random from a
population [42]. The Rao’s quadratic entropy has also been widely
used for population and ecological diversity [11, 42]. We introduce
more details of calculating fork entropy in Sec. 3.

3 FORK ENTROPY
Fig. 1 illustrates the overall process of calculating fork entropy to
measure the diversity of forks. We start with the details of calculat-
ing fork entropy in Sec. 3.1. The construct validity of fork entropy
in measuring the diversity of forks is provided in Sec. 3.2. And the
usefulness of fork entropy in understanding OSS development is
evaluated in the following sections.

3.1 Steps to Calculate Fork Entropy
As illustrated in Fig. 1, for each project involved in our study, we
ﬁrst collect data about its forks from the GHTorrent database [26],
and construct its fork populations over a series of time intervals.
Second, we build a ﬁle modiﬁcation matrix to represent the changes
made by the forks during each time interval. Finally, we calculate
the fork entropy with the Rao’s quadratic entropy deﬁned on the
pair-wise distance function that quantiﬁes the diﬀerence between
each pair of forks given a ﬁle modiﬁcation matrix.

More speciﬁcally, the ﬁrst step is to construct the fork popula-
tion as shown in Fig. 1(a). Given an OSS project, we ﬁrst locate its
source repository, e.g., tensorflow/tensorflow, in the database.
We then perform a breadth ﬁrst search using the ‘forked_from’ key
in the database to retrieve the direct forks and indirect forks (i.e.,
‘forks of forks’) of the source repository in an iterative manner

(a) Fork Population

fork
pull
commit

source
repository

one month

one month

one month

changes

(b) File Modification Matrix

(c) Distance Function

1
1

1
1

(cid:1855)(cid:2869)(cid:2870)
(cid:1855)(cid:2870)(cid:2870)
(cid:1709)
(cid:1855)(cid:3036)(cid:2870)
(cid:1855)(cid:3036)(cid:2870)
(cid:1709)
(cid:1855)(cid:3040)(cid:2870)

(cid:1710)(cid:2869)
(cid:1710)(cid:2869)
(cid:1712)
(cid:1710)(cid:2869)
(cid:1710)(cid:2869)
(cid:1712)
files
(cid:1710)(cid:2869)

1

= (cid:1855)(cid:2869)(cid:2869)
(cid:1855)(cid:2870)(cid:2869)
(cid:1709)
(cid:1855)(cid:3036)(cid:2869)
(cid:1855)(cid:3036)(cid:2869)
(cid:1709)
(cid:1855)(cid:3040)(cid:2869)

(cid:1839)

(cid:1855)(cid:2869)(cid:3041)
(cid:1855)(cid:2870)(cid:3041)
(cid:1709)
(cid:1855)(cid:3036)(cid:3041)
(cid:1855)(cid:3036)(cid:3041)
(cid:1709)
(cid:1855)(cid:3040)(cid:3041)

forks

(cid:2185)(cid:3036)

(cid:2270)

,

= 1

1

(cid:2270) (cid:2185)(cid:3036)

(cid:2185)(cid:3037)

(cid:3398)

(cid:2185)(cid:3284)(cid:2879)(cid:2185)(cid:3285) (cid:3117)

(cid:1857)

Fork Entropy:

1

=

(cid:3040)

(cid:3040)

,

(cid:2185)(cid:3036) (cid:3398) (cid:2185)(cid:3037) (cid:2869)

(cid:2274)(cid:3033)(cid:3042)(cid:3045)(cid:3038) (cid:1839)

(cid:2870) (cid:3533) (cid:3533) (cid:2270) (cid:2185)(cid:3036)
(cid:3037)(cid:2880)(cid:2869)

(cid:3036)(cid:2880)(cid:2869)

(cid:1865)

(cid:2185)(cid:3037)

Figure 1: Overall process of calculating fork entropy.

until all forks of the project are retrieved. The retrieved forks are
segmented by time intervals with a ﬁxed duration (empirically set
to a month in this work). For a fork to be included in a segment,
it must: 1) have at least one commit with ﬁle modiﬁcations during
the segment’s time interval; and 2) is owned by a external contrib-
utor who does not have write access to, or have privileges to close
issues or pull-requests in the source repository [64]. We restrict
our scope to forks owned by external, non-core members of the
project because we are interested in voluntary participation that is
self-assigned and loosely coordinated to contribute independently
in parallel streams. It should be noted that fork ownership is not
a part of the proposed metric of fork entropy. The set of forks in
each segment forms a fork population.

Next, we build a ﬁle modiﬁcation matrix to represent the changes
made by the fork population in a segment. In the matrix, a fork, e.g.,
the 𝑖-th fork, is encoded as a row vector3:

®c𝑖 = h𝑐𝑖1, 𝑐𝑖2, · · · , 𝑐𝑖 𝑗, · · · , 𝑐𝑖𝑛i⊤,

where 𝑛 is the number of ﬁles in the project that are modiﬁed by
one of the forks in the population, and 𝑐𝑖 𝑗 ∈ R is the count of lines
in ﬁle 𝑗 which are modiﬁed by fork 𝑖 during the time interval of the
segment. Intuitively, ®c𝑖 is the ﬁngerprint of the 𝑖-th fork in terms
of modiﬁcations to project ﬁles. Let 𝑚 be the number of forks in
the population, we can obtain the ﬁle modiﬁcation matrix, 𝑀 ∈
R𝑚×𝑛, by stacking the row vectors of all of the 𝑚 forks as shown
in Fig. 1(b). Because the set of ﬁles modiﬁed by fork populations
in diﬀerent segments are likely to be diﬀerent, it is common that
the number of columns, 𝑛, varies with diﬀerent time intervals. We
include only ﬁles that are modiﬁed by the fork population in a
segment to guarantee that the ﬁle modiﬁcation matrix does not
contain rows or columns that are all zeros.

3Vectors are by default column vectors in this paper.

Conference’17, July 2017, Washington, DC, USA

Z. Zheng et al.

In the last step, for each segment, we use the Rao’s quadratic
entropy with a distance function deﬁned on the ﬁle modiﬁcation
matrix 𝑀 to calculate the average degree of diﬀerence between
forks in the population following Eq. (1).

QE(𝑀) = 1
𝑚2

𝑚

𝑚

D (®c𝑖, ®c𝑗 ),

(1)

Õ𝑗=1

Õ𝑖=1
where QE(𝑀) denotes the Rao’s quadratic entropy that estimates
the expectation of diﬀerence between two individuals randomly se-
lected from the population [42], 𝑀 is the ﬁle modiﬁcation matrix
correspond to the segment, 𝑚 is the number of forks in the popula-
tion, ®c𝑖, ®c𝑗 are the the 𝑖- and 𝑗-th row in 𝑀, respectively, and D is a
distance function that quantiﬁes the degree of diﬀerence between
two vectors as deﬁned in Eq. (2) and visualized in Fig. 1(c).

D (®c𝑖, ®c𝑗 ) = 1 − exp(−𝛾 k®c𝑖 − ®c𝑗 k1),
(2)
where exp(−𝛾 k®c𝑖 − ®c𝑗 k1) is the Laplacian kernel [47], k · k1 is the
1-norm, and 𝛾 is the hyperparameter used to adjust the sensitiv-
ity of the function to diﬀerences. We adopt the Laplacian kernel
because it is a non-linear transform sensitive to slight change and
performs excellently in many detection tasks, e.g., character recog-
nition [22].

There are also practical reasons for us to adopt the Laplacian
kernel. We observe that most of the forks in our dataset only con-
tain light changes to the project ﬁles with some forks only include
changes to a single line in a single ﬁle, similar to the observations
reported in existing studies [2, 5]. As a result, we have a consider-
able amount of small diﬀerences, and the resulting fork entropy fol-
lows an approximately bell-shaped distribution. After testing with
diﬀerent distance functions including the Lapalacian and Gaussian
kernels [47], we eventually adopt the distance function in Eq. (2)
according to their real-world performance.

By substituting Eq. (2) into Eq. (1), we have the Eq. (3) for fork

entropy.

H𝑓 𝑜𝑟𝑘 (𝑀) = 1
𝑚2

𝑚

𝑚

1 − exp(−𝛾 k®c𝑖 − ®c𝑗 k1)

,

(3)

Õ𝑖=1

Õ𝑗=1 (cid:16)
where 𝛾 is set to 1 to compute the raw diﬀerence between two
vectors in practice. With the above deﬁnition, it is trivial to see
< 1, and H𝑓 𝑜𝑟𝑘 takes the minimum value when
that 0 ≤ H𝑓 𝑜𝑟𝑘
all ﬁle modiﬁcations made by diﬀerent forks are identical.

(cid:17)

3.2 Construct Validity
We next evaluate the construct validity of fork entropy on measur-
ing the diversity of forks in the context of pull-based OSS develop-
ment. By considering the basic axioms [18] of a diversity index and
expectations in the particular context jointly, the following prop-
erties are required for fork entropy to meet:

• Symmetry. Fork entropy does not depend on the order of
forks. We can easily prove H𝑓 𝑜𝑟𝑘 satisﬁes symmetry be-
cause its distance function D is symmetric, i.e., D (®c𝑖, ®c𝑗 ) =
D (®c𝑗 , ®c𝑖).

• Continuity. Fork entropy must be a continuous function.
We can derive that the value of H𝑓 𝑜𝑟𝑘 is in a continuous
interval from 0 (included) to 1 (excluded) according to its
deﬁnition.

• Monotonicity. Adding a redundant (or distinctive) fork must

decrease (or increase) fork entropy.

Symmetry and continuity are fundamental properties of a diver-
sity index, and monotonicity is introduced in the context of pull-
based OSS development to meet our expectations. We ﬁrst explain
corresponding notions before proving monotonicity. Given 𝑚 ex-
isting forks and a new fork ®c𝑚+1, Eq. (4) calculates the conﬂict of
the new fork over others.

D (®c𝑚+1) = 1
𝑚

𝑚

D (®c𝑖, ®c𝑚+1).

(4)

e

Õ𝑖=1
We state ®c𝑚+1 is redundant if its conﬂict over others is less than the
average diﬀerence among the existing 𝑚 forks; in contrast, ®c𝑚+1 is
distinctive if its conﬂict over others exceeds the average diﬀerence
among the existing 𝑚 forks.

Assuming a new fork ®c𝑚+1 is added into an existing ﬁle modiﬁ-
cation matrix 𝑀 that contains 𝑚 forks to obtain a new matrix 𝑀 ′,
we derive the new fork entropy of 𝑀 ′ in Eq. (5).

H𝑓 𝑜𝑟𝑘 (𝑀 ′) =

1
(𝑚 + 1)2

=

1
(𝑚 + 1)2

= 𝑚2

(𝑚 + 1)2

𝑚+1

𝑚+1

Õ𝑖=1
𝑚

Õ𝑗=1
𝑚

Õ𝑖=1

Õ𝑗=1

D (®c𝑖, ®c𝑗 )

𝑚

D (®c𝑖, ®c𝑗 ) + 2

D (®c𝑖, ®c𝑚+1)

!

H𝑓 𝑜𝑟𝑘 (𝑀) +

2
(𝑚 + 1)2

D (®c𝑖, ®c𝑚+1).

Õ𝑖=1
𝑚

Õ𝑖=1

(5)
We denote H𝑓 𝑜𝑟𝑘 (𝑀 ′) − H𝑓 𝑜𝑟𝑘 (𝑀) as Δ and obtain Eq. (6) by

substituting Δ into Eq. (5).

Δ = 2𝑚 + 1
(𝑚 + 1)2

≈

2𝑚 + 1
(𝑚 + 1)2

D (®c𝑖, ®c𝑚+1) − H𝑓 𝑜𝑟𝑘 (𝑀)

𝑚

1
𝑚 + 0.5

Õ𝑖=1
D (®c𝑚+1) − H𝑓 𝑜𝑟𝑘 (𝑀)

.

!

!

(6)

e

According to Eq. (6), Δ is negative when ®c𝑚+1 is redundant and
is positive when ®c𝑚+1 is distinctive. It means that fork entropy de-
creases after adding a redundant fork while increases after adding
a distinctive fork. Consequently, fork entropy possesses the above
properties and is valid to quantify the diversity of forks.

4 METHODS
This section presents the variables, dataset, and analysis methods
for the studies about the proposed fork entropy with respect to our
research questions.

4.1 Variables
We measure a project’s outcomes, including external productivity,
the acceptance rate of external pull-requests, and code quality. We
also introduce control variables relevant to those outcomes.

Outcome: external productivity. The number of commits is a
widely used indicator of the productivity of OSS projects [53, 55, 57,
59]. In this work, we focus on external productivity that quantiﬁes
volunteers’ contributions to a project, which is measured by the
number of commits integrated into the project’s source repository

 
 
 
Measure the Diversity of Open Source Software Projects’ Forks with Fork Entropy

Conference’17, July 2017, Washington, DC, USA

through pull-requests from volunteer-owned forks. The monthly
external productivity is obtained to perform regression analysis
with fork entropy in each segment to answer RQ1. A possible
threat lies in that maintainers may change the origins of commits
by “cherry-picking” in pull-requests [27], which can cause us to
miss some contributions made by volunteers. Fortunately, we ﬁnd
that “cherry-picking” is rare in our dataset after manual inspec-
tions.

Outcome: acceptance rate. Researchers regard the acceptance
rate of pull-requests as a crucial indicator of the development eﬃ-
ciency of OSS projects [64] because maintainers reject pull-requests
that are obsolete, conﬂicting, duplicated, etc [27, 39, 50]. We fo-
cus on the acceptance rate of external pull-requests delivered from
volunteer-owned forks to an OSS project’s source repository, mea-
sured as the proportion of the merged pull-requests among closed
ones. The monthly acceptance rate of external pull-requests is cal-
culated to perform regression analysis with fork entropy in each
segment to answer RQ2. As many developers integrate pull-requests
via other mechanisms rather than GitHub interface, the status of
pull-requests is not very reliable reported by GitHub [27, 64]. We
follow the heuristics ﬁrst proposed by Gousios et al. [27] and sub-
sequently reﬁned by Zhou et al. [64] to determine pull-requests’
status. A pull-request has been merged if any following condition
is satisﬁed.

• Maintainers perform a ‘merged’ action for the pull-request

on GitHub.

• The pull-request is closed by a commit using certain phrase
conventions (e.g., fixes #1234) advocated by GitHub4, and
the commit exists in the source repository’s commit history.
• Any of the last three comments of the pull-request refers to
a commit SHA, where the comment can be matched by the
regular expression (merg|apply|appl|pull|push|integrat|
land|cherry(-|\s+)pick|squash)(ing|i?ed), and the com-
mit exists in the source repository’s commit history.

• The last comment before the close of the pull-request matches

the phrase conventions or the regular expression.

If all conditions are false, we mark the pull-request as unmerged.
Outcome: code quality. The number of bugs per unit time is
a popular proxy of code quality [24, 31, 44, 57, 59]. We refer to
[57, 59] to assess an OSS project’s code quality by counting emerg-
ing bug-report issues in each segment. To identify bug-report is-
sues, we process issue titles and labels by lowercasing and Porter
stemming [60] then search bug-related keywords, including defect,
error, bug, issue, mistake, incorrect, fault, and ﬂaw. If the title or
any label of an issue contains at least one keyword, we mark it as
a bug-report issue. The monthly code quality is assessed to per-
form regression analysis with fork entropy in each segment to an-
swer RQ3. Since the count-based assessment of code quality relies
heavily on the issue base, a threat arises if projects rarely utilize
GitHub’s default issue-trackers. Thus, we examine the number of
issues in each project and exclude projects that own few issues.

Control variables. Finally, we combine prior software engi-
neering literature [27, 52, 57, 64] and our experience to consider
factors relevant to the above project outcomes.

• NumForks and NumFiles: The two variables are the num-
ber of forks and that of modiﬁed ﬁles, respectively. They
jointly describe the shape of a ﬁle modiﬁcation matrix. The
more forks a project has, the more pull-requests are submit-
ted by non-core developers [57].

• ProjectAge: The age of a project’s source repository in days.
The older the project, the fewer external pull-requests main-
tainers merge or reject [57].

• NumStars: The number of stars a project’s source reposi-
tory receives. This variable usually refers to the popularity
of OSS projects. Volunteers are more likely to contribute to
more popular projects [57].

• RatioOldVolunteers: The ratio of volunteers with prior ex-

perience in successfully submitting pull-requests to a project’s
source repository. Core developers prefer to trust volunteers
they have worked with before [27, 52, 64].

• RatioPRsWithTests: The ratio of pull-requests that con-
tain test cases. A pull-request has test cases if any ﬁle path-
name contains ‘test’ [52]. Pull-requests that contain test cases
are more likely to be merged [52].

• RatioPRsWithHotFiles: The ratio of pull-requests that touch
hot ﬁles. A hot ﬁle is that one modiﬁed by any merged pull-
request in the past three months [27]. Pull-requests that
modify hot ﬁles are more likely to be accepted [27].

4.2 Data Collection
We collect data through GHTorrent [26] and GitHub REST API5.
We start by selecting the most popular ﬁve thousand projects from
the May 2019 GHTorrent dump according to the number of stars
a source repository receives. Then, we ﬁlter projects based on the
following criteria.

• Projects that do not develop software applications or frame-
works are removed. We remove projects that serve for docu-
ment storage or course teaching. We examine project names
and ‘README’ ﬁles by searching keywords, including awe-
some, homework, assignment, course, note, and document. If
any keyword is found, we remove the project after manually
rechecking. We also delete projects with no programming-
language-speciﬁc ﬁles by looking at the ﬁle extensions.
• Projects whose active forks or external pull-requests are less
than one hundred are removed. To ensure a project has suf-
ﬁcient forks and contributions, we retain projects that con-
tain 1) at least one hundred active forks that have pushed
any commit after forking and 2) at least one hundred exter-
nal pull-requests submitted by external, non-core members.
• Projects whose issues are less than one hundred are also re-
moved. To reduce the threat to RQ3, we conservatively ex-
clude projects with less than one hundred issues to ensure
the remaining projects actively use the default issue-trackers
on GitHub.

We get 2533 projects after ﬁltering. Since GHTorrent does not
provide commit contents, i.e., which ﬁles are changed and how
many lines are modiﬁed in each ﬁle, we need to download commits
through GitHub REST API. However, it is onerous to download
commits of the 2533 projects and their hundreds of thousands of

4https://github.blog/2011-04-09-issues-2-0-the-next-generation/

5https://docs.github.com/en/rest

Conference’17, July 2017, Washington, DC, USA

Z. Zheng et al.

forks because of the high cost of network communication. There-
fore, we sample ﬁfty out of the 2533 projects to conduct experi-
mental validations. To enhance our data’s abundance in terms of
the application domain, we refer to [10] to manually determine
the application domain of each project and further adopt strati-
ﬁed random sampling to select projects. In addition, we manually
assign a weight to each project to serve for the sampling. The
more frequently the project has been studied previously (e.g., [20,
33, 64]), the higher the weight. Finally, our dataset includes ten
application software (e.g., Atom/atom), two system software (e.g.,
kubernetes/kubernetes), sixteen web libraries and frameworks
(e.g., angular/angular.js), nine non-web libraries and frameworks
(e.g., tensorflow/tensorflow), and thirteen software tools (e.g.,
Microsoft/vscode).

4.3 Regression Analysis
We calculate monthly variables for each project from its creation
to May 2019. All variables in each project segment compose an in-
dependent unit for regression analyses. We omit units with empty
fork populations because fork entropy is meaningless without forks,
even if it has a value of zero. Before ﬁtting models with the data,
we perform log-transform on control variables under skewed dis-
tributions to stabilize variance and reduce heteroscedasticity [37],
including NumForks, NumFiles, NumStars, and RatioOldVolunteers.
Then, we scale fork entropy and all control variables to make the
mean of each one is zero and the standard deviation is one, which
makes all estimated coeﬃcients of the model are on the same scale.
Additionally, we manually examine distributions of outcome vari-
ables and conservatively remove about 1% of values as outliers to
ensure the models are robust against outliers [41].

We build generalized linear mixed models (GLMMs) to model
the eﬀects of fork entropy on response variables. GLMMs inherit
from generalized linear models (GLMs) to allow response variables
from non-normal distributions and extend GLMs to include both
ﬁxed and random eﬀects [12]. After exploratory data analysis, GLMMs
are appropriate because the response variables in our data are non-
normal and show apparent variability among projects. Speciﬁcally,
fork entropy, control variables, and interactions between fork en-
tropy and each control variable are modeled as ﬁxed eﬀects. To cap-
ture the project-to-project variability in the response (e.g., some
projects naturally attract more volunteers and receive more con-
tributions than others), we add a random-eﬀects term for projects
into the models. We also allow for deviations in the slope of the
number of a project’s forks from the population values (i.e., we ac-
cept the possibility that, for example, projects with higher initial
external productivity may, on average, be less strongly aﬀected by
the increase in fork counts). We use the glmer function provided
by the lme4 package [7] in R to build models. Following prior prac-
tices [25, 64], the Poisson and logistic regressions are speciﬁed for
count (i.e., external productivity and code quality) and ratio (i.e.,
the acceptance rate of external pull-requests) response variables,
respectively. We also explicitly set the denominator (i.e., the num-
ber of closed pull-requests) from the ratio as the weights parame-
ter when modeling the acceptance rate of external pull-requests.
We check the collinearity among independent variables using
the variance inﬂation factors (VIF below ﬁve is recommended [16]).

Table 1: External productivity model. The response is the
number of integrated commits.

(Intercept)
H𝑓 𝑜𝑟𝑘
NumForks
NumFiles
ProjectAge
NumStars
RatioOldVolunteers
H𝑓 𝑜𝑟𝑘 :NumForks
H𝑓 𝑜𝑟𝑘 :NumFiles
H𝑓 𝑜𝑟𝑘 :ProjectAge
H𝑓 𝑜𝑟𝑘 :NumStars
H𝑓 𝑜𝑟𝑘 :RatioOldVolunteers
AIC=65465.38; BIC=65558.12; 𝑅2
Num. obs.=3579; Num. groups: ProjectID=50
*** 𝑝 < 0.001, ** 𝑝 < 0.01, * 𝑝 < 0.05

Coeﬀs (Errors)
-3.360 (0.136)***
-0.325 (0.005)***
-0.614 (0.075)***
-0.510 (0.006)***
-0.176 (0.005)***
-0.032 (0.004)***
-0.079 (0.003)***
-0.116 (0.006)***
-0.064 (0.005)***
-0.123 (0.004)***
-0.087 (0.005)***
-0.015 (0.003)***
𝑚=0.40; 𝑅2

𝑐 =0.98

Chisq

5038.09***
0067.84***
7700.90***
1097.94***
0098.00***
0600.72***
0383.30***
0147.55***
1070.85***
0311.58***
0021.59***

𝑚 and 𝑅2

𝑚 ) and the conditional R-squared (𝑅2

All values are below 2 in our models, which means collinearity
is not a problem in our data. We adopt the marginal R-squared
(𝑅2
𝑐 ) to assess the goodness-
of-ﬁt of the models. 𝑅2
𝑐 describe the proportion of vari-
ance explained by the ﬁxed eﬀects alone and explained by the
ﬁxed and random eﬀects together, respectively [29, 40]. In addition,
we report the coeﬃcient, standard error, signiﬁcance level (i.e., 𝑝-
value), and eﬀect size for each model variable. A variable’s eﬀect
size is the proportion of deviance explained by the model that can
be attributed to the variable. We use the ANOVA type-II analysis
(see ‘Chisq’ table columns) to compute eﬀect sizes. We also report
Akaike’s information criteria (AIC) [1] and Bayesian’s information
criteria (BIC) [49] for each model. All the above metrics are sup-
ported by the performance package [35] in R.

5 RESULTS
This section shows the results of regression analyses for our re-
search questions.

5.1 RQ1: What is the eﬀect of fork entropy on
an OSS project’s external productivity?
To answer RQ1, we model the number of commits integrated from
volunteer-owned forks into a project’s source repository as a func-
tion of fork entropy. In the regression, we control for confound-
ing factors, including the number of forks, the number of modiﬁed
ﬁles, project age, the number of stars, and the ratio of volunteers
with prior experience. Table 1 summarizes the regression results.
We can see that the model is excellent in explaining the variability
because about 98% of the variance can be explained by the ﬁxed
and random eﬀects together, which exceeds the ﬁxed eﬀects alone
by more than ﬁfty percentage points.

The results in Table 1 suggest that fork entropy signiﬁcantly
and positively aﬀects the external productivity of OSS projects (𝑝-
value below 0.001). In other words, projects with more diverse fork

Measure the Diversity of Open Source Software Projects’ Forks with Fork Entropy

Conference’17, July 2017, Washington, DC, USA

entropy respectively correspond to its actual minimum, mean, and
maximum values. In general, external productivity raises with the
increase in fork counts. However, a project has a lower growth rate
of external productivity with the increase in the number of forks
at a higher level of fork entropy. When varying fork entropy with
ﬁxing the number of forks, increasing fork entropy can improve
a project’s external productivity when the project has a small- or
medium-scale fork population. But if the project’s fork population
becomes too large-scale (e.g., beyond the canvas), the increase in
fork entropy may decline external productivity. We suggest that
the increased diversity of forks implicitly strengthens the decision-
making pressure when maintainers deal with large-scale contribu-
tions.

Second, Fig. 2(b) depicts the interaction between fork entropy
and project age. We see that the trends of external productivity
with project age are various at diﬀerent levels of fork entropy:
an increasing trend when fork entropy is low but a decreasing
trend when fork entropy is high. From another perspective, i.e.,
varying fork entropy with ﬁxing project age, we ﬁnd that the in-
crease in fork entropy improves external productivity for young
projects but declines mature projects’ external productivity. In Fig.
2(b), those two opposite cases are separated by a dashed vertical
line that passes through the intersection of the three marked solid
lines. Such a pattern implies that young projects are more willing
to accept diverse contributions than mature projects.

In summary, we answer RQ1 as below.

In general, fork entropy signiﬁcantly and positively aﬀects the
external productivity of OSS projects. Furthermore, fork en-
tropy can moderate the growth rate of external productivity
with respect to the number of forks. And increasing fork en-
tropy improves young projects’ external productivity but de-
clines mature projects’ external productivity.

5.2 RQ2: How does fork entropy inﬂuence the
acceptance rate of external pull-requests?

To answer RQ2, we study the eﬀect of fork entropy on the accep-
tance rate of external pull-requests submitted by volunteers. Here
we calculate fork entropy based on a variant of the ﬁle modiﬁcation
matrix that only includes modiﬁcations involved in pull-requests.
We perform the adjustment because pull-requests allow us to ﬁg-
ure out which modiﬁcations are submitted to source repositories
in each time interval. We do not consider modiﬁcations that only
exist in forks because they can not, at least, directly aﬀect the
decision-making process of maintainers. We apply logistic regres-
sion for the acceptance rate by considering fork entropy. We con-
trol other confounding factors, including the number of forks, the
number of modiﬁed ﬁles, project age, the ratio of volunteers with
prior experience, the ratio of pull-requests that contain test cases,
and the ratio of pull-requests that touch hot ﬁles. Interactions be-
tween fork entropy and each control variable are also involved in
the model. We ignore the interaction between fork entropy and the
number of forks because the control variable does not show signif-
icance alone. Table 2 summarizes the model’s results. The model
explains about 53% of variability by including the ﬁxed and random
eﬀects together, achieving a signiﬁcant improvement compared to
the ﬁxed eﬀects alone.

(a) The interaction between fork entropy and fork count.

(b) The interaction between fork entropy and project age.

Figure 2: Interactions in the external productivity model.
The vertical axes denote the external productivity.

populations generally integrate more commits created by volun-
teers. Furthermore, by looking at the ‘Chisq’ column in Table 1,
we are conﬁdent fork entropy is pivotal to volunteers’ productiv-
ity because it occupies over a third of the deviance explained by the
model. In addition, the controlled factors in the model also signiﬁ-
cantly impact external productivity. Table 1 shows that all controls
except project age are positively correlated to the external produc-
tivity of OSS projects. As a result, OSS projects with more forks
and modiﬁed ﬁles, higher popularity, less maturity, and more pro-
portion of volunteers with prior experience generally correspond
to more external productivity.

We then argue the interaction between fork entropy and each
control variable in the model. In Table 1, all interactions show sig-
niﬁcance. The interactions between fork entropy and the number
of forks and between fork entropy and project age negatively af-
fect the external productivity of OSS projects, and the remaining
interactions positively impact the response. By looking at those in-
teractions’ eﬀect sizes, we observe the two interactions negatively
correlated to the response have the two largest eﬀects. Thus, we
closely inspect and decouple the tangle between fork entropy and
each control variable by varying one factor with ﬁxing the other
and vice versa.

First, Fig. 2(a) illustrates the trends of external productivity with
increasing the number of forks at low, middle, and high levels of
fork entropy, respectively. The low, middle, and high levels of fork

Conference’17, July 2017, Washington, DC, USA

Z. Zheng et al.

Table 2: Acceptance rate model. The response is the propor-
tion of the merged pull-requests among closed ones.

Chisq

Coeﬀs (Errors)
-0.729 (0.195)***
(Intercept)
H𝑓 𝑜𝑟𝑘
-0.179 (0.015)*** 0145.07***
-0.196 (0.158)
NumForks
0001.55***
-0.049 (0.020)*
0011.54***
NumFiles
ProjectAge
-0.490 (0.011)*** 2710.74***
RatioOldVolunteers
-0.614 (0.010)*** 4578.80***
-0.135 (0.017)*** 0063.97***
RatioPRsWithTests
-0.091 (0.015)*** 0043.30***
RatioPRsWithHotFiles
H𝑓 𝑜𝑟𝑘 :NumFiles
-0.122 (0.012)*** 0097.07***
H𝑓 𝑜𝑟𝑘 :ProjectAge
-0.053 (0.009)*** 0038.38***
H𝑓 𝑜𝑟𝑘 :RatioOldVolunteers
-0.028 (0.009)** 0010.01***
H𝑓 𝑜𝑟𝑘 :RatioPRsWithTests
-0.230 (0.011)*** 0421.33***
H𝑓 𝑜𝑟𝑘 :RatioPRsWithHotFiles -0.140 (0.011)*** 0155.37***
AIC=46173.12; BIC=46272.04; 𝑅2
Num. obs.=3579; Num. groups: ProjectID=50
*** 𝑝 < 0.001, ** 𝑝 < 0.01, * 𝑝 < 0.05

𝑚 =0.09; 𝑅2

𝑐 =0.53

(a) The interaction between fork entropy and the ratio
(a) of pull-requests that contain test cases.

In Table 2, we ﬁnd fork entropy signiﬁcantly and positively im-
pacts the acceptance rate of external pull-requests. However, fork
entropy has a small eﬀect size of about 1.8% on the response. On the
contrary, the primary eﬀects (about 88%) are attributed to project
age and the ratio of volunteers with prior experience. All controlled
factors except the number of forks show signiﬁcance in the ac-
ceptance rate model, though the number of modiﬁed ﬁles is just
slightly signiﬁcant. Besides the ratio of pull-requests that touch
hot ﬁles, the other four signiﬁcant control variables positively af-
fect the acceptance rate of external pull-requests.

For the model’s interaction terms, only the interaction between
fork entropy and the proportion of pull-requests that touch hot
ﬁles signiﬁcantly and positively impacts the acceptance rate of ex-
ternal pull-requests. The remaining interactions are signiﬁcantly
and negatively correlated to the response. Furthermore, we ana-
lyze the interactions with relatively notable eﬀects, i.e., the last
two in Table 2.

First, Fig. 3(a) displays the eﬀect of the interaction between fork
entropy and the ratio of pull-requests that contain test cases on
the acceptance rate of external pull-requests. With increasing the
proportion of pull-requests that contain test cases, the acceptance
rate improves at a low level of fork entropy but declines at a high
level of fork entropy. From the perspective of varying fork entropy
with ﬁxing the other factor, i.e., comparing the left and right parts
separated by the vertical dashed line in Fig. 3(a), the acceptance
rate beneﬁts from the increased fork entropy when minority pull-
requests contain test cases. But when majority pull-requests con-
tain test cases, the increase in fork entropy instead declines the
acceptance rate. Thus, although test cases are helpful to make a
pull request be accepted [52], maintainers reduce the average pref-
erence on test cases when fork entropy is high.

Second, in Fig. 3(b), the interaction between fork entropy and
the proportion of pull-requests that touch hot ﬁles performs dif-
ferently compared to the above case. With increasing the ratio of
pull-requests that modify hot ﬁles, the acceptance rate improves at

(b) The interaction between fork entropy and the ratio
(b) of pull-requests that touch hot files.

Figure 3: Interactions in the acceptance rate model. The
vertical axes denote the acceptance rate of external pull-
requests.

a high level of fork entropy but declines at a low level of fork en-
tropy. The pattern is interesting and consistent with our intuition.
When fork entropy is low, increasing the ratio of pull-requests that
modify hot ﬁles can enhance the possibility of duplicated contribu-
tions, which are more likely to be rejected by maintainers and thus
decline the acceptance rate. On the other hand, by comparing the
left and right parts separated by the vertical dashed line in Fig. 3(b),
we ﬁnd that the acceptance rate improves with the increased fork
entropy when majority pull-requests touch hot ﬁles. But when mi-
nority pull-requests modify hot ﬁles, the increase in fork entropy
instead declines the acceptance rate. It means maintainers make a
trade-oﬀ between the diversity and the hotness when dealing with
volunteers’ contributions.

In summary, we answer RQ2 as below.

In general, fork entropy signiﬁcantly and positively aﬀects the
acceptance rate of external pull-requests but with a small eﬀect.
Moreover, increasing fork entropy can improve the acceptance
rate when minority pull-requests contain test cases or when
majority pull-requests touch hot ﬁles.

Measure the Diversity of Open Source Software Projects’ Forks with Fork Entropy

Conference’17, July 2017, Washington, DC, USA

5.3 RQ3: What is the correlation between fork
entropy and OSS projects’ code quality?
We ﬁnally study the eﬀect of fork entropy on the code quality of
OSS projects. We model the number of bug-report issues as a func-
tion of fork entropy with controlling other confounding factors, in-
cluding the number of forks, the number of modiﬁed ﬁles, project
age, and the number of stars. Interactions between fork entropy
and each controlled factor are also involved in the model as ﬁxed
eﬀects. Table 3 summarizes the results of the code quality model.
The model ﬁts data well and explains about 96% of the variability
by including both ﬁxed and random eﬀects, achieving a consider-
able improvement compared to the ﬁxed eﬀects alone by exceeding
over eighty percentage points.

The results in Table 3 suggest that fork entropy signiﬁcantly
and negatively inﬂuences the number of bug-report issues. And
fork entropy has a medium eﬀect because it occupies about 23%
of the deviance explained by the code quality model. As a result,
we state that, in general, the higher fork entropy, the fewer is-
sues are opened to report bugs, and perhaps, the higher code qual-
ity projects achieve. Noting our wording is conservative because
we only apply a naive assessment of OSS projects’ code quality,
which is a complicated software property and should be assessed
by more reﬁned approaches. Our ﬁndings coincide with Baudry et
al [8]. They advocate any form of software diversity that sponta-
neously emerges from software development can facilitate estab-
lishing fault-tolerant software systems. In addition, the number of
modiﬁed ﬁles signiﬁcantly and negatively aﬀects the number of
bug-report issues, and the remaining controlled factors are signif-
icantly and positively correlated to the response. All interaction
terms show signiﬁcance, and only the interaction of fork entropy
and the number of forks negatively aﬀects the number of bug-
report issues.

We observe an opposition between fork entropy and the num-
ber of forks, where the former positively aﬀects the response while
the latter negatively aﬀects the response. Fig. 4 shows the inter-
action. We ﬁnd that more bug-report issues arise with increasing
the number of forks regardless of fork entropy. But interestingly,
there is a lower rise of bug-report issues when fork entropy is at
a higher level. From another perspective, i.e., comparing the left
and right parts divided by the vertical dashed line in Fig. 4, when
a project has a small-scale fork population, the increase in fork en-
tropy makes more bug-report issues arise. On the contrary, increas-
ing fork entropy reduces the number of bug-report issues when the
project owns a large-scale population of forks.
In summary, we answer RQ3 as below.

Conservatively, fork entropy signiﬁcantly and positively aﬀects
the code quality of OSS projects with a medium eﬀect. In ad-
dition, fork entropy can also moderate the rise of bug-report
issues caused by the expansion of fork populations.

6 DISCUSSION
This section discusses the eﬀects of fork entropy, the implications
of our work for OSS development, and the threats to our work’s
validity.

Table 3: Code quality model. The response is the number of
bug-report issues.

Chisq

Coeﬀs (Errors)
-2.632 (0.204)***
-0.086 (0.006)***
-0.356 (0.066)***
-0.065 (0.007)***
-0.078 (0.007)***
-0.115 (0.006)***
-0.063 (0.008)***
-0.045 (0.007)***
-0.032 (0.005)***
-0.037 (0.006)***

(Intercept)
H𝑓 𝑜𝑟𝑘
NumForks
NumFiles
ProjectAge
NumStars
H𝑓 𝑜𝑟𝑘 :NumForks
H𝑓 𝑜𝑟𝑘 :NumFiles
H𝑓 𝑜𝑟𝑘 :ProjectAge
H𝑓 𝑜𝑟𝑘 :NumStars
AIC=35052.62; BIC=35133.00; 𝑅2
Num. obs.=3579; Num. groups: ProjectID=50
*** 𝑝 < 0.001, ** 𝑝 < 0.01, * 𝑝 < 0.05

222.49***
032.51***
082.53***
118.94***
332.64***
062.36***
040.92***
037.03***
038.55***
𝑐 =0.96

𝑚 =0.08; 𝑅2

6.1 Eﬀects of Fork Entropy
During the empirical validations, we obverse fork entropy has vari-
ous eﬀects under diﬀerent conditions, including positive, negative,
and moderating eﬀects.

Positive eﬀects. First, as we expected, fork entropy is posi-
tively correlated to OSS projects’ external productivity measured
by the number of commits integrated from volunteer-owned forks
into a project’s source repository. The ﬁnding implies that an OSS
project with a diverse population of forks can inspire volunteers’
dedication and promote voluntary participation, which is vital to
OSS projects’ sustainability [61]. Second, fork entropy positively
aﬀects the acceptance rate of external pull-requests submitted by
external, non-core members. One reasonable explanation is that a
higher degree of fork entropy, i.e., more dissimilarity in changes
among forks, implicitly reduces the possibility of duplicated con-
tributions, which is one main reason maintainers reject volunteers’
contributions [27, 39, 50]. Finally, conservatively, fork entropy has
a signiﬁcant and positive impact on an OSS project’s code qual-
ity measured by the number of bug-report issues. It is consistent
with prior studies that advocate any form of software diversity that
spontaneously emerges from software development can facilitate
establishing fault-tolerant software systems [8].

Negative eﬀects. However, fork entropy sometimes plays a
negative role in OSS development. When an OSS project’s fork pop-
ulation becomes too large-scale, increasing fork entropy may de-
cline the project’s external productivity. The ﬁnding is complemen-
tary with previous works that claim large-scale contributions can
cause an overwhelming decision-making pressure for maintainers
and hinder the development of OSS projects [51]. It means that
maintainers’ workload depends on the magnitude and the diver-
sity in volunteers’ contributions. We also ﬁnd an increased fork en-
tropy declines the external productivity of relatively mature projects.
A reasonable explanation is that mature projects are conservative
in treating external contributions because they are less likely to
do mass updates. In addition, the increase in fork entropy nega-
tively impacts the acceptance rate of external pull-requests when

Conference’17, July 2017, Washington, DC, USA

Z. Zheng et al.

 + L J K

 V
 H
 X
 V
 V
 ,
 W
 U
 R
 S
 H
 5
 J
 X
 %
 P
 X
 1

 / R Z

 / R Z

 ) R U N  ( Q W U R S \

 + L J K
 0 L G G O H
 / R Z

 1 X P ) R U N V

 + L J K

Figure 4: The interaction between fork entropy and fork
count in the code quality model. The vertical axis denotes
the code quality.

majority pull-requests contain test cases or when minority pull-
requests touch hot ﬁles. And more bug-report issues arise with the
increase in fork entropy when the fork populations of OSS projects
are small-scale.

Moderating eﬀects. Fork entropy also moderates other factors’
eﬀects on project outcomes. First, fork entropy can moderate the
growth rate of external productivity with respect to the number
of forks. Speciﬁcally, external productivity improves more quickly
when projects have a lower degree of fork entropy. Second, fork
entropy also moderates the eﬀect of the proportion of pull-requests
that touch hot ﬁles on the acceptance rate of external pull-requests.
When fork entropy is high, there is a positive correlation between
the ratio of pull-requests that modify hot ﬁles and the acceptance
rate. But the correlation turns negative when fork entropy is low.
Third and last, fork entropy moderates the rise of bug-report issues
attributed to the expansion of fork populations. There is a lower
rise of the bug-report issues when OSS projects achieve a higher
fork entropy.

6.2 Implications
This section summarizes the implications of our work for volun-
teers, maintainers, and researchers, respectively.

Implications for volunteers. The inﬂow and retention of vol-
unteers are vital for the sustainability and success of OSS projects
[62]. Nevertheless, the loose coordination among volunteers is ad-
verse to the development of OSS projects. For example, they some-
times make redundant eﬀorts or mismatch maintainers’ intentions,
and both may lead to the ineﬃciency in fork-based social coding
[64]. Researchers and practitioners have proposed some mecha-
nisms and tools to enhance the coordination among developers,
such as claiming work in progress in issue-trackers6 on GitHub
and making them aware of code changes of other forks in advance
[63]. However, there is still a gap in understanding the coordina-
tion and government of OSS systems, and we suggest an opportu-
nity to establish mechanisms for developers to communicate and
coordinate eﬃciently.

6https://github.com/dear-github/dear-github/issues/191

Implications for maintainers. The main challenge for main-
tainers is the considerable decision-making pressure caused by large-
scale populations of forks. Some automation methods have been
applied to reduce maintainers’ workload, such as continuous in-
tegration [57] and soft bots [34] on GitHub. Researchers have pro-
posed some methods to automatically detect duplicated pull-requests
[32] or even redundant unﬁnished patches [46] to avoid repeti-
tive labor, but none is implemented to serve for online OSS de-
velopment. In addition, diﬀerences in opinions and aims between
volunteers and maintainers increase the risk of ‘hard forking’ [4],
which can cause fragmented communities [64] and decline devel-
oper community participation [43]. Although many maintainers
set contribution guidelines to unify expectations between them
and volunteers, recent studies ﬁnd lots of contributions diverge
signiﬁcantly from the expected process [21]. Consequently, there
is still a defect in tackling the misalignment between maintainers
and volunteers.

Implications for researchers. While we ﬁnd critical new in-
sights on fork entropy, many unanswered research questions re-
main. First, how does diversity emerge among forks? We have only a
superﬁcial understanding of the emergence of fork diversity with-
out considering the project’s governance policy, the fork’s inten-
tion, the interaction between developers, etc. Second, how does
fork diversity change with the evolution of projects? We have not
organized an OSS project’s fork entropy into a time series, which
may display exciting patterns with the project’s evolution. Finally,
we are also interested in whether is it possible to intervention fork
entropy in OSS projects? As fork entropy plays a negative role in
some situations, the project development may be further improved
if there is a feasible approach to intervene in it.

6.3 Threats to Validity
The main limitation of our study is the dataset. Since we collect
popular OSS projects that own medium-size or large-size popu-
lations of forks, our results may not generalize to OSS projects
with few forks. Although we only select ﬁfty OSS projects, the
abundance in the application domain of the selected projects can
weaken the threat to external validity. For empirical validations,
we calculate fork entropy and project outcomes in monthly granu-
larity. Although the time interval of one-month size is widely used
in previous OSS studies (e.g., [59]), changing the granularity of seg-
mentation is possible to vary our results. Finally, the assessment
of OSS projects’ code quality is also threatened, even though the
number of bug-report issues is widely used in prior studies.

7 CONCLUSION
In this work, we concentrate on the pull-based OSS development
and propose a novel metric named fork entropy to measure the
diversity of the population of forks around an OSS project. To op-
erationalize the proposed fork entropy, we develop a framework
that applies the Rao’s quadratic entropy to calculate the average
diﬀerence among forks with a deﬁned distance function based on
forks’ modiﬁcations on project ﬁles. To ensure fork entropy per-
forms consistently with our expectations, we guarantee the con-
struct validity of fork entropy by verifying three required math-
ematical properties. Furthermore, we also show the usefulness of

Measure the Diversity of Open Source Software Projects’ Forks with Fork Entropy

Conference’17, July 2017, Washington, DC, USA

fork entropy in understanding and predicting OSS development
in terms of external productivity, the acceptance rate of external
pull-requests, and code quality. We conduct experimental valida-
tions using regression analyses based on a dataset consisting of
ﬁfty popular OSS projects hosted on GitHub. The results suggest
that, in general, fork entropy signiﬁcantly and positively aﬀects
OSS development. However, as we expected, an increased fork en-
tropy sometimes negatively aﬀects OSS development, such as de-
clining external productivity when projects have large-scale fork
populations or become relatively mature. We also observe that fork
entropy can moderate other factors’ eﬀects on OSS development,
such as the growth rate of external productivity with respect to the
number of forks. As a result, the proposed fork entropy enriches
the set of metrics on forks and oﬀers new opportunities for us to
understand or even guild the practices in fork-based social coding.

ACKNOWLEDGMENTS
This work was supported by the National Key R&D Program of
China No. 2018AAA0102302, and the Collaborative Innovation Cen-
ter of Novel Software Technology and Industrialization. Liang Wang
is the corresponding author.

REFERENCES
[1] Hirotogu Akaike. 1998. Information theory and an extension of the maximum
likelihood principle. In Selected papers of hirotugu akaike. Springer, 199–213.
[2] Abdulkareem Alali, Huzefa Kagdi, and Jonathan I Maletic. 2008. What’s a typical
commit? a characterization of open source software repositories. In 2008 16th
IEEE international conference on program comprehension. IEEE, 182–191.

[3] Paul D Allison. 1978. Measures of inequality. American sociological review (1978),

865–880.

[4] Stephanos Androutsellis-Theotokis, Diomides Spinellis, Maria Kechagia, Geor-
gios Gousios, et al. 2011. Open source software: A survey from 10,000 feet. Foun-
dations and Trends in Technology, Information and Operations Management 4, 3-4
(2011), 187–347.

[5] Oliver Arafat and Dirk Riehle. 2009. The commit size distribution of open source
software. In 2009 42nd Hawaii International Conference on System Sciences. IEEE,
1–8.

[6] Joop Aué, Michiel Haisma, Kristín Fjóla Tómasdóttir, and Alberto Bacchelli. 2016.
Social diversity and growth levels of open source software projects on github. In
Proceedings of the 10th ACM/IEEE International Symposium on Empirical Software
Engineering and Measurement. 1–6.

[7] Douglas Bates, Martin Maechler, Ben Bolker, and Steven Walker. 2016. Lin-
ear Mixed-Eﬀects Models using ’Eigen’ and S4 [R package lme4 version 1.1-11].
(2016).

[8] Benoit Baudry and Martin Monperrus. 2015. The multiple facets of software di-
versity: Recent developments in year 2000 and beyond. ACM Computing Surveys
(CSUR) 48, 1 (2015), 1–26.
[9] Peter Michael Blau. 1977.

Inequality and heterogeneity: A primitive theory of

social structure. Vol. 7. Free Press New York.

[10] Hudson Borges, Andre Hora, and Marco Tulio Valente. 2016. Understanding
the factors that impact the popularity of GitHub repositories. In 2016 IEEE Inter-
national Conference on Software Maintenance and Evolution (ICSME). IEEE, 334–
344.

[11] Zoltán Botta-Dukát. 2005. Rao’s quadratic entropy as a measure of functional
diversity based on multiple traits. Journal of vegetation science 16, 5 (2005), 533–
540.

[12] Norman E Breslow and David G Clayton. 1993. Approximate inference in gen-
eralized linear mixed models. Journal of the American statistical Association 88,
421 (1993), 9–25.

[13] Lionel C Briand, Sandro Morasca, and Victor R Basili. 1999. Deﬁning and validat-
ing measures for object-based high-level design. IEEE transactions on software
engineering 25, 5 (1999), 722–743.

[14] Gemma Catolino, Fabio Palomba, Damian A Tamburri, Alexander Serebrenik,
and Filomena Ferrucci. 2019. Gender diversity and women in software teams:
How do they aﬀect community smells?. In 2019 IEEE/ACM 41st International
Conference on Software Engineering: Software Engineering in Society (ICSE-SEIS).
IEEE, 11–20.

[15] Scott Chacon and Ben Straub. 2014. Pro git. Springer Nature.

[16] Patricia Cohen, Stephen G West, and Leona S Aiken. 2014. Applied multiple
regression/correlation analysis for the behavioral sciences. Psychology press.
[17] Laura Dabbish, Colleen Stuart, Jason Tsay, and Jim Herbsleb. 2012. Social coding
in GitHub: transparency and collaboration in an open software repository. In
Proceedings of the ACM 2012 conference on computer supported cooperative work.
1277–1286.

[18] Aisling J Daly, Jan M Baetens, and Bernard De Baets. 2018. Ecological diversity:

measuring the unmeasurable. Mathematics 6, 7 (2018), 119.

[19] Sherae Daniel, Ritu Agarwal, and Katherine J Stewart. 2013. The eﬀects of di-
versity in global, distributed collectives: A study of open source project success.
Information Systems Research 24, 2 (2013), 312–333.

[20] Manuel De Stefano, Emanuele Iannone, Fabiano Pecorelli, and Damian Andrew
Tamburri. 2022. Impacts of software community patterns on process and prod-
uct: An empirical study. Science of Computer Programming 214 (2022), 102731.

[21] Omar Elazhary, Margaret-Anne Storey, Neil Ernst, and Andy Zaidman. 2019. Do
as i do, not as i say: Do contribution guidelines match the github contribution
process?. In 2019 IEEE International Conference on Software Maintenance and Evo-
lution (ICSME). IEEE, 286–290.

[22] Sayed Fadel, Said Ghoniemy, Mohamed Abdallah, Hussein Abu Sorra, Amira
Ashour, and Asif Ansary. 2016. Investigating the eﬀect of diﬀerent kernel func-
tions on the performance of SVM for recognizing Arabic characters.
Interna-
tional Journal of Advanced Computer Science and Applications 7, 1 (2016), 446–
450.

[23] Norman Fenton and James Bieman. 2014. Software metrics: a rigorous and prac-

tical approach. CRC press.

[24] Matthieu Foucault, Marc Palyart, Xavier Blanc, Gail C Murphy, and Jean-Rémy
Falleri. 2015. Impact of developer turnover on quality in open-source software.
In Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineer-
ing. 829–841.

[25] Andrew Gelman and Jennifer Hill. 2006. Data analysis using regression and mul-

tilevel/hierarchical models. Cambridge university press.

[26] Georgios Gousios. 2013. The GHTorrent dataset and tool suite. In Proceed-
ings of the 10th Working Conference on Mining Software Repositories (San
Francisco, CA, USA) (MSR ’13). IEEE Press, Piscataway, NJ, USA, 233–236.
http://dl.acm.org/citation.cfm?id=2487085.2487132

[27] Georgios Gousios, Martin Pinzger, and Arie van Deursen. 2014. An exploratory
study of the pull-based software development model. In Proceedings of the 36th
International Conference on Software Engineering. 345–355.

[28] Jing Jiang, David Lo, Jiahuan He, Xin Xia, Pavneet Singh Kochhar, and Li Zhang.
2017. Why and how developers fork what from whom in GitHub. Empirical
Software Engineering 22, 1 (2017), 547–578.

[29] Paul CD Johnson. 2014. Extension of Nakagawa & Schielzeth’s R2GLMM to

random slopes models. Methods in ecology and evolution 5, 9 (2014), 944–946.

[30] Lou Jost. 2006. Entropy and diversity. Oikos 113, 2 (2006), 363–375.
[31] Foutse Khomh, Tejinder Dhaliwal, Ying Zou, and Bram Adams. 2012. Do faster
releases improve software quality? an empirical case study of mozilla ﬁrefox.
In 2012 9th IEEE working conference on mining software repositories (MSR). IEEE,
179–188.

[32] Zhixing Li, Gang Yin, Yue Yu, Tao Wang, and Huaimin Wang. 2017. Detecting
duplicate pull-requests in github. In Proceedings of the 9th Asia-Paciﬁc Sympo-
sium on Internetware. 1–6.

[33] Zhixing Li, Yue Yu, Minghui Zhou, Tao Wang, Gang Yin, Long Lan, and Huaimin
Wang. 2020. Redundancy, Context, and Preference: An Empirical Study of Du-
plicate Pull Requests in OSS Projects. IEEE Transactions on Software Engineering
(2020).

[34] Dongyu Liu, Micah J Smith, and Kalyan Veeramachaneni. 2020. Understanding
user-bot interactions for small-scale automation in open-source development. In
Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing
Systems. 1–8.

[35] Daniel Lüdecke, Mattan S. Ben-Shachar, Indrajeet Patil, Philip Waggoner, and
Dominique Makowski. 2021. performance: An R Package for Assessment, Com-
parison and Testing of Statistical Models. Journal of Open Source Software 6, 60
(2021), 3139. https://doi.org/10.21105/joss.03139

[36] Ines Mergel. 2015. Open collaboration in the public sector: The case of social
coding on GitHub. Government Information Quarterly 32, 4 (2015), 464–472.
[37] Charles E Metz. 1978. Basic principles of ROC analysis. In Seminars in nuclear

medicine, Vol. 8. Elsevier, 283–298.

[38] Rebecca Mitchell and Stephen Nicholas. 2006. Knowledge creation in groups:
The value of cognitive diversity, transactive memory and open-mindedness
norms. The Electronic Journal of Knowledge Management 4, 1 (2006), 67–74.
[39] Reza Nadri, Gema Rodriguez-Perez, and Meiyappan Nagappan. 2020. Insights
Into Nonmerged Pull Requests in GitHub: Is There Evidence of Bias Based on
Perceptible Race? IEEE Software 38, 2 (2020), 51–57.

[40] Shinichi Nakagawa and Holger Schielzeth. 2013. A general and simple method
for obtaining R2 from generalized linear mixed-eﬀects models. Methods in ecol-
ogy and evolution 4, 2 (2013), 133–142.

[41] Jason W Osborne and Amy Overbay. 2004. The power of outliers (and why
researchers should always check for them). Practical Assessment, Research, and

Conference’17, July 2017, Washington, DC, USA

Z. Zheng et al.

Evaluation 9, 1 (2004), 6.

[42] C Radhakrishna Rao. 1982. Diversity and dissimilarity coeﬃcients: a uniﬁed

approach. Theoretical population biology 21, 1 (1982), 24–43.

[43] Ayushi Rastogi and Nachiappan Nagappan. 2016. Forking and the Sustainabil-
ity of the Developer Community Participation–An Empirical Investigation on
Outcomes and Reasons. In 2016 IEEE 23rd international conference on software
analysis, evolution, and Reengineering (SANER), Vol. 1. IEEE, 102–111.

[44] Baishakhi Ray, Daryl Posnett, Vladimir Filkov, and Premkumar Devanbu. 2014.
A large scale study of programming languages and code quality in github. In
Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations
of Software Engineering. 155–165.

[45] Eric Raymond. 1999. The cathedral and the bazaar. Knowledge, Technology &

Policy 12, 3 (1999), 23–49.

[46] Luyao Ren, Shurui Zhou, Christian Kästner, and Andrzej Wąsowski. 2019. Iden-
tifying redundancies in fork-based development. In 2019 IEEE 26th International
Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE,
230–241.

[55] Bogdan Vasilescu, Daryl Posnett, Baishakhi Ray, Mark GJ van den Brand, Alexan-
der Serebrenik, Premkumar Devanbu, and Vladimir Filkov. 2015. Gender and
tenure diversity in GitHub teams. In Proceedings of the 33rd annual ACM confer-
ence on human factors in computing systems. 3789–3798.

[56] Bogdan Vasilescu, Alexander Serebrenik, and Mark GJ van den Brand. 2013. The
Babel of software development: Linguistic diversity in open source. In Interna-
tional Conference on Social Informatics. Springer, 391–404.

[57] Bogdan Vasilescu, Yue Yu, Huaimin Wang, Premkumar Devanbu, and Vladimir
Filkov. 2015. Quality and productivity outcomes relating to continuous integra-
tion in GitHub. In Proceedings of the 2015 10th Joint Meeting on Foundations of
Software Engineering. 805–816.

[58] Dindin Wahyudin, Khabib Mustofa, Alexander Schatten, Stefan Biﬄ, and A Min
Tjoa. 2007. Monitoring the “health” status of open source web-engineering
projects. International Journal of Web Information Systems (2007).

[59] Zhendong Wang, Yang Feng, Yi Wang, James A Jones, and David Redmiles. 2020.
Unveiling elite developers’ activities in open source projects. ACM Transactions
on Software Engineering and Methodology (TOSEM) 29, 3 (2020), 1–35.

[47] Matthias Rupp. 2015. Machine learning for quantum mechanics in a nutshell.

[60] Peter Willett. 2006. The Porter stemming algorithm: then and now. Program

International Journal of Quantum Chemistry 115, 16 (2015), 1058–1073.

(2006).

[48] Walt Scacchi, Joseph Feller, Brian Fitzgerald, Scott Hissam, and Karim Lakhani.
2006. Understanding free/open source software development processes.
, 95–
105 pages.

[49] Gideon Schwarz. 1978. Estimating the dimension of a model. The annals of

statistics (1978), 461–464.

[50] Igor Steinmacher, Gustavo Pinto, Igor Scaliante Wiese, and Marco Aurélio
Gerosa. 2018. Almost there: A study on quasi-contributors in open-source soft-
ware projects. In 2018 IEEE/ACM 40th International Conference on Software Engi-
neering (ICSE). IEEE, 256–266.

[51] Xin Tan, Minghui Zhou, and Brian Fitzgerald. 2020. Scaling open source com-
munities: An empirical study of the Linux kernel. In 2020 IEEE/ACM 42nd Inter-
national Conference on Software Engineering (ICSE). IEEE, 1222–1234.

[52] Jason Tsay, Laura Dabbish, and James Herbsleb. 2014.

Inﬂuence of social and
technical factors for evaluating contribution in GitHub. In Proceedings of the
36th international conference on Software engineering. 356–366.

[53] Bogdan Vasilescu, Vladimir Filkov, and Alexander Serebrenik. 2013. Stackover-
ﬂow and github: Associations between software development and crowdsourced
knowledge. In 2013 International Conference on Social Computing. IEEE, 188–195.
[54] Bogdan Vasilescu, Vladimir Filkov, and Alexander Serebrenik. 2015. Perceptions
of diversity on git hub: A user survey. In 2015 IEEE/ACM 8th International Work-
shop on Cooperative and Human Aspects of Software Engineering. IEEE, 50–56.

[61] Yunwen Ye and Kouichi Kishida. 2003. Toward an understanding of the moti-
vation of open source software developers. In 25th International Conference on
Software Engineering, 2003. Proceedings. IEEE, 419–429.

[62] Minghui Zhou, Audris Mockus, Xiujuan Ma, Lu Zhang, and Hong Mei. 2016.
Inﬂow and retention in oss communities with commercial involvement: A case
study of three hybrid projects. ACM Transactions on Software Engineering and
Methodology (TOSEM) 25, 2 (2016), 1–29.

[63] Shurui Zhou, Stefan Stanciulescu, Olaf Leßenich, Yingfei Xiong, Andrzej Wa-
sowski, and Christian Kästner. 2018.
Identifying features in forks. In 2018
IEEE/ACM 40th International Conference on Software Engineering (ICSE). IEEE,
105–116.

[64] Shurui Zhou, Bogdan Vasilescu, and Christian Kästner. 2019. What the fork: a
study of ineﬃcient and eﬃcient forking practices in social coding. In Proceedings
of the 2019 27th ACM Joint Meeting on European Software Engineering Conference
and Symposium on the Foundations of Software Engineering. 350–361.

[65] Jiaxin Zhu, Minghui Zhou, and Audris Mockus. 2016. Eﬀectiveness of code con-
tribution: From patch-based to pull-request-based tools. In Proceedings of the
2016 24th ACM SIGSOFT International Symposium on Foundations of Software En-
gineering. 871–882.

