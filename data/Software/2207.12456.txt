Overwatch: Learning Patterns in Code Edit Sequences

1

2
2
0
2

l
u
J

5
2

]
L
P
.
s
c
[

1
v
6
5
4
2
1
.
7
0
2
2
:
v
i
X
r
a

YUHAO ZHANG∗†, University of Wisconsin-Madison, USA
YASHARTH BAJPAI†, Microsoft, India
PRIYANSHU GUPTA†, Microsoft, India
AMEYA KETKAR∗†, Uber, USA
MILTIADIS ALLAMANIS, Microsoft Research, UK
TITUS BARIK∗, Apple, USA
SUMIT GULWANI, Microsoft, USA
ARJUN RADHAKRISHNA, Microsoft, USA
MOHAMMAD RAZA, Microsoft, USA
GUSTAVO SOARES, Microsoft, USA
ASHISH TIWARI, Microsoft, USA

Integrated Development Environments (IDEs) provide tool support to automate many source code editing
tasks. Traditionally, IDEs use only the spatial context, i.e., the location where the developer is editing, to
generate candidate edit recommendations. However, spatial context alone is often not sufficient to confidently
predict the developer’s next edit, and thus IDEs generate many suggestions at a location. Therefore, IDEs
generally do not actively offer suggestions and instead, the developer is usually required to click on a specific
icon or menu and then select from a large list of potential suggestions. As a consequence, developers often
miss the opportunity to use the tool support because they are not aware it exists or forget to use it.

To better understand common patterns in developer behavior and produce better edit recommendations,
we can additionally use the temporal context, i.e., the edits that a developer was recently performing. To enable
edit recommendations based on temporal context, we present Overwatch, a novel technique for learning
edit sequence patterns from traces of developers’ edits performed in an IDE. Our experiments show that
Overwatch has 78% precision and that Overwatch not only completed edits when developers missed the
opportunity to use the IDE tool support but also predicted new edits that have no tool support in the IDE.

1 INTRODUCTION

Integrated Development Environments (IDEs) offer developers an overwhelming deluge of tools
to support source code editing tasks, including writing new code, performing refactorings, and
applying code fixes. Popular IDEs such as Microsoft Visual Studio [Microsoft 2021] and JetBrains
ReSharper [JetBrains 2021], for example, provide over 100 C# refactorings, code fixes, and snippet
tools. Traditionally, these tools use the location where the developer is editing code and the
surrounding code as spatial context to generate candidate edits to recommend.

However, the spatial context alone is often not sufficient for IDEs to confidently predict the
developer’s next edit. At a specific location, there may be multiple candidate tools available for
different editing tasks. For instance, Figure 1a shows all tools available when the developer clicks
on the screwdriver next to a property declaration. There are 8 edits that the IDE can automate at

∗This work was done when these authors were employed at Microsoft
†Equal contribution

Authors’ addresses: Yuhao Zhang, yuhaoz@cs.wisc.edu, University of Wisconsin-Madison, USA; Yasharth Bajpai, t-
yabajpai@microsoft.com, Microsoft, India; Priyanshu Gupta, priyansgupta@microsoft.com, Microsoft, India; Ameya Ketkar,
Uber, USA, ketkara@uber.com; Miltiadis Allamanis, Microsoft Research, UK, miltos@allamanis.com; Titus Barik, Apple,
USA, tbarik@acm.org; Sumit Gulwani, Microsoft, USA, sumitg@microsoft.com; Arjun Radhakrishna, Microsoft, USA,
arradha@microsoft.com; Mohammad Raza, Microsoft, USA, moraza@microsoft.com; Gustavo Soares, Microsoft, USA,
gsoares@microsoft.com; Ashish Tiwari, Microsoft, USA, astiwar@microsoft.com.

 
 
 
 
 
 
Yuhao Zhang, Yasharth Bajpai, Priyanshu Gupta, Ameya Ketkar, Miltiadis Allamanis, Titus Barik, Sumit Gulwani, Arjun
Radhakrishna, Mohammad Raza, Gustavo Soares, and Ashish Tiwari
1:2

(a) Edit suggestions based on spatial context

(b) Edit suggestion using spatial and temporal contexts

Fig. 1. Edits suggested by Visual Studio when the developer adds a property to a class

that location. Unsurprisingly, developers have difficulty discovering these tools and applying them
at the appropriate time and place [Ge et al. 2012; Murphy-Hill et al. 2009].

To improve code edit recommendations, in addition to the spatial context, we can also use the
temporal context, that is, the code edits that the developer was performing at a particular point in
time. For instance, suppose the developer has just added the Offset property in Figure 1a. Next,
the developer is more likely to add the corresponding parameter to the constructor and use it to
initialize the property (7th option in the menu) than replace the nearly introduced property with a
method (4th option). If the developer moves the cursor to the constructor, then it is very likely that
they are about to insert the parameter. Recently, Visual Studio announced that they used this idea
of temporal context to implement an analyzer to detect this edit sequence and offer the suggestion
as “gray text” (Figure 1b) to add the parameter to the constructor as soon as the developer moves
the cursor to the constructor after adding a new property. By using spatial and temporal contexts
to generate suggestions at the right time and location, the IDE can afford to preemptively show
these edit suggestions, avoiding discoverability and late-awareness problems.

However, implementing tools that use temporal context is non-trivial. Tool builders have to
reason not only about the location where an edit should be suggested and how to automate the
edit but also how previous edits relate to the edit under consideration. Consider the example above,
developers can perform the "Insert Property", "Insert Parameter", "Insert Assignment" sequence of
edits in any order but Visual Studio only handles the order shown in Figure 1. Given the complexity
of manually implementing these edit sequence patterns, only a few of them are available today in
IDEs.

Instead of manually implementing patterns to recommend code edits, researchers have proposed
several approaches to learn edit patterns from edits in source code repositories [Bader et al. 2019;
de Sousa et al. 2021; Kim et al. 2013; Rolim et al. 2017; Yin et al. 2019]. These patterns represent the
location where an edit should be applied and how to perform the desired edit. However, very few
approaches use previous edits as temporal context. Blue-Pencil [Miltner et al. 2019] use previous
edits to suggest similar repetitive edits. C3PO [Brody et al. 2020] learns a model to complete an edit
given a previous edit but uses only a single edit as context, and can only predict edits that do not
generate new content. Additionally, C3PO is trained on data from source code repositories, which
may not reflect the temporal relationship of edits in an IDE.

In this paper, we propose Overwatch, a technique for learning Edit Sequence Patterns from
traces logged during editing sessions in the IDE. As input, Overwatch takes a set of source file
versions. Each version represents the state of the file while a developer is editing it. Given this
input, Overwatch’s problem is to find recurrent edit sequences and generalize them into Edit
Sequence Patterns (ESPs). In a nutshell, Overwatch performs three major steps: (1) generating edit
sequence sketches and their corresponding specifications; (2) synthesizing edit sequence patterns

Overwatch: Learning Patterns in Code Edit Sequences

1:3

class Node {

Node () {
}

}

(a) v0

class Node {

-
+

public str Id { get ;}
public str Id { get ; set ;}
Node () {
}

+

-
+

class Node {

public str Id { }
Node () {
}

}

(b) v1

class Node {

public str Id { get ; set ;}
Node () {
Node ( str id ) {

}

class Node {

-
+

}

public str Id { }
public str Id { get ;}
Node () {
}

(c) v2

class Node {

public str Id { get ; set ;}
Node ( str id ) {

+

Id = id ;

}

}

(d) v3

(e) v4
Fig. 2. Development Session: Syntactically correct versions while adding and initializing a property.

}

(f) v5

}

and (3) selecting and ranking the edit sequence patterns. Given a new development trace (i.e., edit
history), Overwatch can then use the learned edit sequence patterns to predict the next edit.

To evaluate Overwatch, we collected 335, 687 source file versions, which were logged from 12
professional software developers from a large company across several months. In our experiments,
Overwatch achieved 78.38% precision in the test set, showing a degree of domain-invariance,
when compared to its performance on the validation set collected 6 months earlier. Additionally,
we performed a qualitative analysis on the ESPs learned with Overwatch. Our findings show that
ESPs can be used not only to complete edits when developers typically miss the opportunity to use
the IDE tool support but also to predict new edits that have no tool support at all in the IDE.

In short, the paper makes the following contributions:

(1) We formalize the problem of learning Edit Sequence Patterns (ESPs) (Section 3);
(2) We propose Overwatch, a technique for learning edit sequences patterns from traces col-

lected during editing sessions in the IDE (Sections 4-6);

(3) We show that the ESPs learned by Overwatch can be used to predict edits with 78.38%

precision (Section 7.2);

(4) Our qualitative analysis shows that ESPs can be used not only to complete edits when
developers missed the opportunity to use the IDE tool support but also predict new edits
that have no tool support at all in the IDE (Section 7.2).

2 OVERVIEW

We begin with an overview of Overwatch’s technique to learn ESPs and how we can use these
patterns to predict code edits. To illustrate the process, we show how Overwatch learns an ESP that
predicts the code edit recommended by Visual Studio in Figure 1b. As we mentioned, Visual Studio
developers had to manually implement this feature, which is time-consuming and hard to scale. In
Section 7.2 we present a list of other patterns that were automatically learned by Overwatch.

Consider the source file traces shown in Figures 2 and 3 depicting the sequences of versions
produced when developers were performing similar edits in an IDE. At a high level, the developers
are performing the same ESP: (a) adding a new property to the class, (b) adding a new parameter to
the constructor with the same name as of the property (but lowercase) and same type, (c) adding a
statement assigning the parameter to the property. However, the developers take different paths
in the two cases—in Figure 2, the developer directly types in the new code while in Figure 3, the
developer copies an existing property and changes the name. Figure 4 illustrates how Overwatch
represents this pattern. Each individual transition represents the pre and post template of an edit
template. We see that the insert property pattern in Figure 4a has templates with holes in it. Holes
H2 and H3, respectively, represent the surrounding class members and methods preceding and

Yuhao Zhang, Yasharth Bajpai, Priyanshu Gupta, Ameya Ketkar, Miltiadis Allamanis, Titus Barik, Sumit Gulwani, Arjun
Radhakrishna, Mohammad Raza, Gustavo Soares, and Ashish Tiwari
1:4

class Graph {

public int Id { get ; set ;}
Graph ( int id ) {
Id = id ;

+

}

}

(a) v6

class Graph {

public int Id { get ; set ;}
public int Id { get ; set ;}
Graph ( int id ) {
Id = id ;

-
+

}

}

(b) v7

class Graph {

public int Id { get ; set ;}
public int Id { get ; set ;}
public int Size { get ; set ;}
Graph ( int id ) {
Id = id ;

}

}

(c) v8

class Graph {

public int Id { get ; set ;}
public int Size { get ; set ;}
Graph ( int id ) {
Graph ( int id , int size ) {

-
+

Id = id ;

}

}

(d) v9

class Graph {

public int Id { get ; set ;}
public int Size { get ; set ;}
Graph ( int id , int size ) {

+

}

}

Id = id ;
Size = size ;

(e) v10

Fig. 3. Development Session: Syntactically correct versions while copying, updating, and initializing a property.

pre

post

class H1 {

H2

H3

}

class H′

1 {

H′
2
public H4 H5 { get ; set ;}
H′
3

}

H′

1 = H1 ∧ H′

2 = H2 ∧ H′

3 = H3

pre

H†
1 (
H6

)

post

pre

post

H∗
1 (
H′
6 ,
4 H′
H′
5

)

H7

{

}

{

}

H′
7
H†
5 = H∗
5 ;

H†

1 = H∗
∧ H′

1 ∧ H′
6 = H6 ∧ H′
5 = ToLower(H5)

4 = H4

H′

7 = H7 ∧ H†
5 = H′
∧ H∗
5

5 = H5

(a) InsertProperty

(b) InsertConstructorParam

(c) InsertAssignment

Fig. 4. Example of an Edit Sequence Pattern learned by Overwatch for the workflow InsertProperty ·
InsertConstructorParameter·InsertAssignment The variable component of the pattern (holes) are represented
by H. Below each pre and post representaion of the template, we present the Hole Predicates specifying the
relationship between holes across the edit pattern sequence.

following the location of the edit. The type and name of the added property in the post template
correspond to holes H4 and H5, respectively. Based on the newly added property, holes H4 and H5
can be replaced with the appropriate type and name to match the edit.

We use hole predicates to define relationships between holes in the pre- and post-templates. The
𝑖 = H𝑖 for 𝑖 ∈ {1, 2, 3} represent that the class name and the class body does not change
predicates H′
apart from the newly added property. Similarly, in Figure 4b, the predicate H′
6 = H6 represents
that the constructor parameters do not change except the newly added parameter. The predicate
5 = ToLower(H5) says that the name of the parameter is the lower case version of the property
H′
name (e.g., if the property name is Id, the parameter name will be id). Note that this predicate
relates the holes in two different edit templates, i.e., H5 is in the InsertProperty template while H′
5
is in InsertConstructorParam. Hence, while learning an ESP, we need to consider the sequence of
edits as a whole, instead of separately learning single edit patterns and putting them together.

2.1 Using Edit Sequence Patterns to Predict Edits

We can use the above pattern to predict the next edits that the developer will perform. For instance,
consider the scenario shown in Figure 2. Suppose the developer has just performed the changes
v0 → v3. We can match this edit to InsertProperty to get the values of the holes H4 and H5, i.e., str
and Id, respectively. Now, using the predicates H′
5 = ToLower(H5), we can instantiate
InsertConstructorParam to obtain the next edit. In an IDE, we can use this instantiation to suggest

4 = H4 and H′

Overwatch: Learning Patterns in Code Edit Sequences

1:5

class Metric {

class Metric {

Metric () {
}

}

(a) v11

class Metric {

public float Cost { get ;}
public float Cost { get ; set ;}
Metric () {
}

-
+

}

+

}

public float Cost { }
Metric () {
}

(b) v12

class Metric {

-
+

}

public float Cost { }
public float Cost { get ;}
Metric () {
}

(c) v13

class Metric {

class Metric {

public float Cost { get ; set ;}
Metric () {
Metric ( int val ) {

-
+

public float Cost { get ; set ;}
Metric ( int val ) {

+

Cost = Math . Abs ( val );

}

(d) v14

(e) v15
Fig. 5. Another sequence of versions that is different from the edit sequence pattern learned in Fig 4.

}

(f) v16

}

}

adding str id as soon as the developer moves the cursor to the constructor’s parameter list using
an interface similar to the one shown in Figure 1b. Note that in Figure 1b, we can predict two
subsequent changes (adding the constructor parameter and adding an assignment) at once using
edit patterns InsertConstructorParam and InsertAssignment in sequence.

Note that the predictions made using the ESP is just that, a prediction. As shown in Figure 5, the
developer may actually want to make a different sequence of changes, i.e., the name and type of the
property and the initialization expression are different that the ones predicted by the ESP. In our
IDE plugin implementation, the developer can press the Escape key to ignore the recommendation
from the edit sequence template and make their own change.

2.2 Learning Edit Sequence Patterns

Given the traces presented in Figures 2, 3, and 5 as input, the aim of Overwatch is to learn the
ESP in Figure 4.
Building the Edit Graph. Overwatch first creates the edit graph in Figure 6a to where the nodes
represent edits at different levels of granularity and the edges represent their temporal relationship.
For example, the figure contains both the node v0 → v3, as well as the nodes v0 → v1, v1 → v2, and
v2 → v3; these represent the same change of adding the property public str Id { get; set; },
but at different levels of granularity. The edit v0 → v3 represents adding the full property, while
v0 → v1, v1 → v2, and v2 → v3 represent adding the property with the empty accessor list, adding
the get;, and adding the set;. The edges between v0 → v1, v1 → v2, and v2 → v3 represent that
each edit immediately follows the previous in the trace. Note that the graph does not contain nodes
for all changes (for example, v0 → v5). We describe how we select the edits that should be there in
the graph in Section 4–intuitively, we ignore large and unrelated edits.
Creating Sketches for Edit Pattern Sequences. Next, Overwatch produces a quotient graph
by grouping together similar edits in the edit graph. Two edits are grouped together, i.e., in the same
partition, if they have the same edit type (Insert, Delete, or Update) and the same type of AST node
that is being modified (e.g., PropertyDeclaration and Parameter). In Figure 6a, the nodes are colored
by partition. For example, the green nodes all represent the insertion of a PropertyDeclaration.

Figure 6b shows the quotient graph produced by Overwatch. The quotient graph summarizes
the edit graph at the level of partitions: the vertices of the quotient graph are the partitions. An
edge between two partitions exists in the quotient graph iff there are at least 2 pairs of edits in the
partitions that sequentially follow each other. For example, there is an edge between InsertProperty
and InsertParameter as there are 3 pairs of edits where a parameter is added immediately af-
ter a property is added (see edge label in Figure 6b). However, there are no edges to and from
UpdateName since no two occurrences of update name are followed by edits of the same partition.

Yuhao Zhang, Yasharth Bajpai, Priyanshu Gupta, Ameya Ketkar, Miltiadis Allamanis, Titus Barik, Sumit Gulwani, Arjun
Radhakrishna, Mohammad Raza, Gustavo Soares, and Ashish Tiwari
1:6

v0 → v1

v1 → v2

v2 → v3

v6 → v7

v7 → v8

v11 → v12

v12 → v13

v13 → v14

v0 → v3

v3 → v4

v4 → v5

v6 → v8

v8 → v9

v9 → v10

v11 → v14

v14 → v15

v15 → v16

(a) Part of edit graph for traces from Figures 2, 3, and 5

Insert Property
v0 → v1, v0 → v3
v6 → v7, v6 → v8
v11 → v12, v11 → v14

v0 → v1 → v2
v6 → v8 → v9
v11 → v12 → v13

Update Name
v7 → v8

v0 → v1 → v2
v11 → v12 → v13

Insert Get
v1 → v2, v12 → v13

v1 → v2 → v3
v12 → v13 → v14

Insert Set
v2 → v3, v13 → v14

v2 → v3 → v4
v13 → v14 → v15

Insert Parameter
v3 → v4, v8 → v9
v14 → v15

v3 → v4 → v5
v8 → v9 → v10
v14 → v15 → v16

Insert Assignment
v4 → v5, v9 → v10
v15 → v16

(b) Quotient graph for edit graph in Figure 6a

pre

post

pre

post

pre

post

Specification: {

v0 → v3 → v4 → v5,
v6 → v8 → v9 → v10,
v11 → v14 → v15 → v16

}

(c) Sketch for the edit sequence pattern “Insert Property” → “Insert Parameter” → “Insert Assignment”

Fig. 6. Overwatch: From Edit Graphs to Edit Sequence Patterns. We omit edits v0 → v2 and v11 → v13 that
should be in the edit graphs for ease of presentation.

, edSeq

, edSeq
2

3} which correspond to the traces from Figures 2, 3, and 5.

The paths in the quotient graph represent recurrent edit sequences applied by developers. For
each path in the quotient graph, the support is the set of all edit sequences that correspond to it.
For each path up to a size 𝑛 with sufficient support in the quotient graph, Overwatch creates a
sketch along with a specification that is given by its support. The right part of Figure 6c shows the
sketch of the ESP insert property, insert parameter, and assign property, and the specification given
by {edSeq
1
From Sketches to Edit Sequence Patterns. In the next step, Overwatch uses these concrete
sequences to infer edit templates and hole predicates to complete the sketch. We use a procedure
based on anti-unification to generalize the edit sequences into edit templates and corresponding
hole predicates. In essence, anti-unification is a technique to generalize two ASTs into a template
by replacing differing subtrees with holes. However, we anti-unify edit sequences instead of ASTs
and further, generate predicates relating the holes in the individual templates (see Section 5.2).
1, edSeq

3 produces the ESP depicted in
5 = ToLower(H5). This
Figure 4, but without the predicates H′
pattern, while general, cannot be used to predict the next changes. The absence of these predicates
means that we can predict neither the name and type of the inserted parameter, nor the right-hand
side of the assignment. On the contrary, anti-unifying just edSeq
2 produces exactly the
pattern in Figure 4, which can be used for predictions as shown in Section 2.1. Overwatch uses
agglomerative hierarchical clustering over edit sequences to produce a hierarchy of increasingly
general ESPs. Hence, we will produce both ESPs (with and without anti-unifying edSeq
3). We select
and rank a subset of the generated ESPs based on their predictive power on the input traces.

Anti-unifying the edit sequences edSeq

5 = ToLower(H5), and H∗

2, and edSeq

1 and edSeq

4 = H4, H′

Overwatch: Learning Patterns in Code Edit Sequences

1:7

3 EDIT SEQUENCE PATTERNS

The goal of this paper is to learn a sequence of edit patterns from a set of developer edit traces and
to use the learned patterns to make editing suggestions while a developer is working in an IDE. In
contrast to related works [Bader et al. 2019; de Sousa et al. 2021; Yin et al. 2019] that learn only a
single edit pattern, we aim to leverage the hole predicates among the sequence of edit patterns.
In this section, we show a novel representation for the sequence of edit patterns learned by our
approach.
Versions and Development Sessions. A version v is a syntactically correct source file that occurs
while a developer is editing code. A development session or trace Trace = v0 . . . v𝑛 is the sequence of
all versions that appear during an editing session. Here, we identify each version with its abstract
syntax tree (AST). Hence, unparsable intermediate versions of code do not appear in the trace.
Edits and Edit Sequences. The edit ed = vpre → vpost changes version vpre to vpost. The function
Localize on edits that produce the smallest difference between the two ASTs in the edit. Formally,
post are subtrees of vpre and vpost, respectively;
Localize(vpre → vpost) = v∗
pre and v∗
post if: (a) v∗
post in vpre yields vpost; and (c) v∗
(b) replacing v∗
pre is the smallest subtree of such kind.

pre → v∗

pre by v∗

Example 3.1. Consider the edit v3 → v4 in Figure 2, where the developer adds the parameter
str id to the constructor of Node. The localized version of this edit Localize(v3 → v4) is given by
3 corresponds to the subtree of v3 that represents the empty parameter list (),
3 → v∗
v∗
□
and (b) v∗

4 where: (a) v∗
4 corresponds to the subtree of v4 that represents the parameter list (str id).

An edit in the trace Trace = v0 . . . v𝑛 is given by v𝑖 → v𝑗 ∈ Edits(Trace) where 0 ≤ 𝑖 < 𝑗 ≤ 𝑛.
Given edits ed = v𝑖 → v𝑗 and ed′ = v𝑘 → vℓ from Trace, we say that ed′ sequentially follows
ed if 𝑖 < 𝑗 = 𝑘 < 𝑙. This is written as ed →seq ed′. An edit sequence ed0 . . . ed𝑛 is a sequence of
contiguous edits, i.e., ∀𝑖.ed𝑖 →seq ed𝑖+1.
Templates and Edit Templates. An AST template (or template for short) t is an AST where
some leaf nodes are holes, i.e., they do not represent a program fragment but are placeholders. A
substitution 𝜎 is a function that maps each hole to a finite sequence of AST nodes. The AST obtained
by replacing each hole H in t by the 𝜎 (H) is written as 𝜎 (t). We assume that holes are unique,
i.e., that a single hole does not appear in more than one location in a template and that multiple
templates cannot share holes.

Example 3.2. An example of a template t is (H, str id) where H is a hole. This template
represents all parameter lists of length 1 or more where the last parameter is str id. Note that we
are writing templates using the equivalent code for readability. The template t is represented as an
AST and does not contain a node for the comma separator.

With the substitution 𝜎0 = {H ↦→ 𝜖} that maps H to the empty sequence of nodes, we
have 𝜎0(t) = (str id). Note that the comma disappears when we substitute the hole with
the empty list—this is an artifact of writing the template as code. For 𝜎1 = {H ↦→ int count}
and 𝜎2 = {H ↦→ int count, str attr} we have 𝜎1(t) = (int count, str id) and 𝜎2(t) =
(int count, str attr, str id). Note that 𝜎0, 𝜎1, and 𝜎2 map H to sequences of AST nodes of
□
length 0, 1, and 2, respectively.

We represent common editing motifs using edit templates. Formally, an edit template et =
tpre → tpost is a pair of AST templates. We say that an edit vpre → vpost matches an edit template
pre → v∗
tpre → tpost if: (a) Localize(vpre → vpost) = v∗
post, and (b) there exists a substitution 𝜎 such
that v∗

pre = 𝜎 (tpre) and v∗

post = 𝜎 (tpost).

Example 3.3. An example of an edit template is et = (H1) → (H2, str id). Here, the first
template matches all parameter lists while the second matches all parameter lists where the last

Yuhao Zhang, Yasharth Bajpai, Priyanshu Gupta, Ameya Ketkar, Miltiadis Allamanis, Titus Barik, Sumit Gulwani, Arjun
Radhakrishna, Mohammad Raza, Gustavo Soares, and Ashish Tiwari
1:8

parameter is str id. Hence, it would match the edit v3 → v4 in Figure 2. However, note that this
edit template does not relate the values of H1 and H2 in pre- and post-versions of the edit. Therefore,
an edit like (int id) → (str label, str id) will match the edit template et. We solve this issue
using hole predicates below.

Hole Predicates. We introduce the notion of hole predicates to (a) relate the values of holes across
multiple templates, and (b) restrict the set of substitutions that can be applied to a template. Formally,
a hole predicate is an expression of type Boolean over holes and is evaluated over a substitution 𝜎.
• Unary predicates. The predicate IsNotNull(H) represents if a hole can be replaced by an
empty sequence, i.e., the substitution 𝜎 must satisfy 𝜎 (H) ≠ 𝜖 if IsNotNull(H) = True.
Another unary predicate IsKindlabel(H) is parametrized by an AST node type label (e.g.,
AssignExpr or ClassDeclaration). We have that IsKindlabel(H) = True for a substitution 𝜎
only if 𝜎 (H) = node and the label of node is label. Note that IsKindkind forbids the hole value
from being an empty sequence and a sequence with multiple elements.

• Binary predicates. We also use a class of predicates over two holes, written as H1 = F(H2)
where F is a function. The most common F is the identity function in terms of text value, in
which case, we write the predicate as H1 = H2. Other two functions F we use are ToLower
and ToUpper, which indicate that the text value of H1 in the substitution is the same as that
of H2, but the case of the first character changed appropriately.

Example 3.4 (Hole predicates). Consider the template t = (H, str id) from Example 3.2. Here,
imposing the predicate IsNotNull(H) ensures that any AST matched by t must have at least 2
parameters in the parameter list. Continuing from Example 3.3, we can augment the edit template
(H1) → (H2, str id) with the hole predicate H1 = H2 to ensure that we exactly capture the class
□
of edits that insert a new parameter str id to an existing parameter list.

Example 3.5. Hole predicates can be used to relate holes across multiple edits to exactly capture

the common editing pattern illustrated in Figure 2.

• Add a new property to a class. This category of edits is captured by the edit template et1 =
{H1 H2} → {H3 public H4 H5 {get;} H6}. Here, H1 and H2 represent the class members
that appear before and after the newly inserted property, respectively. The type and name of
the property are represented by H4 and H5, respectively. We can add the unary predicates
IsKindType(H4) and IsKindIdent(H5) to ensure that H4 and H5 are a Type node and an Identifier
node, respectively. To ensure that the contents of the class do not change apart from the
newly inserted property, we need the predicates H3 = H1 and H6 = H2.

• Add a new parameter to the constructor. This edit is captured by the edit template and predicates
similar to the ones presented in Example 3.4. We have et2 = (H7) → (H8, H9 H10) with
the predicate H8 = H7 to ensure that the parameter list is preserved apart from the new
parameter. We have the additional predicates H9 = H4 and H10 = ToLower(H5) to ensure
that the type and name match that of the inserted property. Note that the relation between
H5 and H10 is not strict equality, but involves an additional transformation ToLower to H5.
• Assign the new parameter to the new property. These edits add a new assignment statement
to the end of the block and are captured by et3 = {H11} → {H12; H13 = H14;} with the
predicates H12 = H11, H13 = H5, and H14 = H10. However, we omit some unary predicates if
the absence does not hinder understanding for ease of presentation in this paper.

Together, the edit templates et1, et2, and et3 along with the above predicates fully capture the
common editing pattern of adding a new property to a class and initializing it in the constructor. □

Edit Sequence Patterns. The main object of study in this paper is an Edit Sequence Pattern (ESP).
ESPs are used to capture sequences of common editing actions like in Example 3.5. Formally, an ESP

Overwatch: Learning Patterns in Code Edit Sequences

1:9

is a pair ⟨TS, Preds⟩ where: (a) TS is a restricted regular expression over edit templates, and (b) Preds
is a set of hole predicates. Here, the restricted regular expression TS is of the form et1 . . . et𝑛−1et[∗]
𝑛
where [∗] represents an optional Kleene star. That is, TS is a sequence of edit templates where the
last template may have a Kleene star.

Example 3.6. The edit templates and hole predicates from Example 3.5 can be written as an
ESP ⟨TS, Preds⟩. Here, TS = et1et2et3 and Preds = {H3 = H1, H6 = H2, H8 = H7, H9 = H4, H10 =
ToLower(H5), H12 = H11, H13 = H5, H14 = H10} ∪ {IsKindType(H4), IsKindIdentifier (H5), . . .}.

We say that a sequence of edits ed1 . . . ed𝑛 matches ⟨TS, Preds⟩, where TS = et1 . . . et𝑛−1et𝑛, if
there exists a substitution 𝜎 such that: (a) each ed𝑖 matches et𝑖 for 1 ≤ 𝑖 ≤ 𝑛, (b) the hole valuations
in 𝜎 satisfy all the predicates in Preds.

Extending this definition, we say that a sequence of edits ed1 . . . ed𝑚 (with 𝑚 ≥ 𝑛) matches
𝑛, if each of the sequences ed1 . . . ed𝑛−1ed𝑘 for 𝑛 ≤ 𝑘 ≤ 𝑚

⟨TS, Preds⟩, where TS = et1 . . . et𝑛−1et∗
matches ⟨et1 . . . et𝑛−1et𝑛, Preds⟩.

Example 3.7. Consider an ESP ⟨TS, Preds⟩, where TS = et1et∗

2 has a Kleene star, with
et1 = (H1, H2 H3) → (H4), et2 = (H5, H6) → (H7), and Preds = {H1 = H4, H5 =
H7, IsKindType(H2), IsKindIdent(H3), IsKindArg (H6)}. This pattern represents an editing sequence
where the developer deletes the last parameter in a declaration, and then, deletes the corresponding
argument in multiple callsites.

Consider the three edits ed1, ed2, and ed3 in Figure 7. We have that ed1ed2ed3 matches
et1et∗
2. To show this, we need to show that both ed1ed2 and ed1ed3 match the un-starred
ESP ⟨et1et2, Preds⟩. We can see that ed1ed2 matches et1et2 with the substitution 𝜎1 =
{H1 ↦→ Stream s, byte[] bs, H2 ↦→ bool, H3 ↦→ flush, H4 ↦→ Stream s, byte[] bs, H5 ↦→
io, bytes, H6 ↦→ f, H7 ↦→ io, bytes}. Similarly, we can show that ed1ed3 matches et1et2 with
□
the substitution 𝜎2, which is the same as 𝜎1 with bytes replaced by result for H5 and H7.

Remark 3.8. In our implementation, we consider a slightly more general form of edit sequence
patterns. There, we can have ESPs where any edit template (not just the last one) may be starred.
These more general patterns can be formalized in a straightforward way, though we do not do so
here for ease of presentation.

class Comms {
// Edit 1
void Write ( Stream s ,
byte [] bs , bool flush ) { }
void Write ( Stream s ,
byte [] bs ) { }

-
-
+
+
}
void Main () {
// Edit 2
Comms . Write ( io , bytes , f );}
Comms . Write ( io , bytes );
// Edit 3
Comms . Write ( io , result , f );
Comms . Write ( io , result );

-
+

-
+
}

Fig. 7. Delete a Parameter and Delete Arguments

Using Edit Sequence Patterns. After a edit
sequence matches a prefix of an ESP, we can use
the next edit template in the ESP to predict the
next change that the developer will make. We
illustrate an usage of an ESP in the following
example and we will further describe the details
in Section 6.

Example 3.9 (Usage of an ESP). Consider the
ESP ⟨et1et2et3, Preds⟩ defined in Example 3.6,
and the edit sequence ed1 →seq ed2 from Fig-
ure 2, where ed1 = v0 → v3, ed2 = v3 → v4.
We will consider the task of predicting the next
edit give that the developer has just performed
ed1 and ed2.

• First, we find a substitution 𝜎 such that ed1 and ed2 match et1 and et2, respectively using
𝜎. Further, we require that 𝜎 satisfies each predicate in Preds that is over only the holes
appearing in et1 and et2. Here, we have 𝜎 = {H2 ↦→ Node() { }, H4 ↦→ str, H5 ↦→ Id, H6 ↦→
Node() { }, H9 ↦→ str, H10 ↦→ id, } ∪ {H𝑖 ↦→ 𝜖 | 𝑖 ∈ {1, 3, 7, 8}}.

Yuhao Zhang, Yasharth Bajpai, Priyanshu Gupta, Ameya Ketkar, Miltiadis Allamanis, Titus Barik, Sumit Gulwani, Arjun
Radhakrishna, Mohammad Raza, Gustavo Soares, and Ashish Tiwari
1:10

• Then, we find an AST node in v4 such that the node matches et3,pre using a substitution 𝜎 ′.
We get 𝜎 ′ = {H11 ↦→ 𝜖} for the AST node that represents the empty body of the constructor.
And we require that 𝜎 ∪ 𝜎 ′ satisfies all predicates in Preds that are over the domain of 𝜎 ∪ 𝜎 ′.
• Now, we use the predicates in Preds that contain the holes from et3,post to predict the values
for those holes. Here, from the predicates H12 = H11, H13 = H5, and H14 = H10, we can predict
that H12 ↦→ 𝜖, H13 ↦→ Id, and H14 = id.

• Filling in these values in et3,post, we get the new constructor body {Id = id;}. The predicted
version is obtained by replacing node in v4 with this new constructor body. This exactly
produces the version v5 in Figure 2.

Problem Statement and Solution Sketch. The input to the ESP learning problem is a set of
traces. The expected output is a ranked set of ESPs ⟨TS1, Preds1⟩ . . . ⟨TS𝑛, Preds𝑛⟩. The aim is to
produce ESPs that are helpful in predicting the next version in any trace. To this end, we measure
the quality of the output using the standard notions of precision and recall, and a general F score
(see Section 7.1 for more details).

Algorithm 1 Overview of Overwatch
Require: Set of traces Traces
Ensure: Ranked list of ESPs
1: edits ← (cid:208){Edits(Trace) | Trace ∈ Traces}
2: EditGraph ← BuildEditGraph(edits)
3: Partitions ← partition of edits based on Kind
4: QuotientGraph ← Quotient(EditGraph, Partitions)
5: Paths ← FreqentPaths(QuotientGraph)
6: SketchesAndSpecs ← {GenerateSketchAndSpec(path) | path ∈ Paths}
7: Patterns ← ∅
8: for (sk, spec) ∈ SketchesAndSpecs do
9:
10: return FilterAndSelect(Patterns)

Patterns ← Patterns ∪ LearnPatterns(sk, spec)

Our solution strategy is in 3 parts:

• Generating edit sequence sketches and specifications. (Section 4, Lines 1-6 in Algorithm 1) The
first step is to generate sets of concrete edit sequences (called the specification) that can
potentially all match the same ESP, along with a sketch for that ESP. To generate these sketches
and specifications, we (a) partition the set of all edits in Traces (Lines 1-3), (b) summarize the
edit graph by the partitions to build a quotient graph (Line 4), and (c) generate sketches and
specifications from paths of the quotient graph (Lines 5-6).

• Synthesizing ESPs. (Section 5, Lines 7-9 in Algorithm 1) Given these edit sequence sketches
and specifications, we generate a hierarchy of ESPs iteratively where each pattern in the
hierarchy is more general and matches more edit sequences in the specifications than the
patterns lower in the hierarchy. The core algorithm here takes as input a set of edit sequences
and produces a set of ESPs that can potentially matches the provided edit sequences.

• Selecting and ranking ESPs. (Section 6, Line 10 in Algorithm 1) Once we build a hierarchy of
ESPs, we determine their predictive power by testing them on the input Traces. Based on
their precision on the Traces, we select a subset of the patterns and rank them accordingly.

4 FROM TRACES TO EDIT PATTERN SKETCHES

In this section, we produce sketches and specifications from a set of traces. Formally, an edit pattern
sketch sk is of the form 𝐴1 . . . 𝐴𝑛−1𝐴 [∗]
𝑛 where each 𝐴𝑖 is a placeholder for an edit template. A

Overwatch: Learning Patterns in Code Edit Sequences

1:11

specification spec for a sketch sk is a set of edit sequences such that the length of each edit sequence
in spec (a) is equal to 𝑛 if 𝐴𝑛 is un-starred in sk, and (b) is at least 𝑛 if 𝐴𝑛 is starred in sk.

Example 4.1. Given a set of input traces that include the traces from Figures 2 and 3, the technique
in this section will produce a set of pairs of the form (sk, spec). One such pair might be sk = 𝐴1𝐴2𝐴3
and spec = {ed1ed2ed3, ed′
, . . .} where ed1 = v0 → v3, ed2 = v3 → v4, ed3 = v4 → v5,
1
ed′
1 add a new property,
(b) ed2 and ed′
3 assign the newly added
parameter to the newly added property. This sketch and specification will then be used in Section 5
□
to generate a hierarchy of ESPs.

2 add a new parameter to the constructor, and (c) ed3 and ed′

3 = v9 → v10. Note that (a) ed1 and ed′

ed′
2
2 = v8 → v9, and ed′

1 = v6 → v8, ed′

ed′
3

We synthesize sketches of ESPs from traces in three steps, (a) build an edit graph that contains
information about the granularity and sequencing of edits in the input traces, (b) produce a summary
of edit sequences by quotienting the edit graph based on a partitioning of edits, and (c) produce
sketches and specifications of ESPs by finding frequent paths in the summary quotient graph. We
explain each of these steps below.
Generating the Edit Graph. The edit graph represents all edits in all input traces, as a graph. First,
we collect the set of all edits at all granularities in the input traces, i.e., edits between all pairs (not
necessarily consecutive) of versions. Since the number of edits grows quadratically in the length of
the trace, in practice, we prune the edits as follows. First, we debounce the transient edits, i.e., we
delete edits where the two versions were separated by less than 500ms of time [Miltner et al. 2019].
Second, we remove edits where the change is larger than a given threshold. Large edits are likely to
incorporate changes that are completely unrelated to each other. For example, the edit of adding a
new class and implementing all its methods is likely to contain many unrelated edits, and not be
a part of any common editing workflow. Now, the individual edits from this pruned set form the
vertices of the graph and there is an edge between ed1 and ed2 if and only if ed2 sequentially follows
ed1, i.e., ed1 →seq ed2. Note that the edit graph contains edits at different levels of granularity. For
example, in the edit graph for a trace with versions v0v1v2, both the coarse-grained edit v0 → v2,
as well as the fine-grained edits v0 → v1 and v1 → v2.

Example 4.2. The edit graph of the trace shown in Figure 2 contains vertices of the form 𝑣𝑖 𝑗 =
v𝑖 → v𝑗 for 0 ≤ 𝑖 < 𝑗 ≤ 5. The edit graph is shown in Figure 6a. Note that the graph contains nodes
for both fine-grained edits v0 → v1, v1 → v2, v2 → v3, and v3 → v4, as well as the coarse-grained
edit v0 → v4. There is an edge between 𝑣03 → 𝑣34 as v3 → v4 sequentially follows v0 → v3. On the
other hand, there is no edge from 𝑣03 to 𝑣45.
Summarizing the Edit Graph. Once the edit graph is built, the next task is to create an abstract
version of the edit graph that groups together edits of similar kind. To define similar, we first define
an embedding of edits. We categorize edits into 3 types: insert, delete, and update. The edit insert
child Insert(parent, child, 𝑖) and the edit delete child Delete(parent, child, 𝑖) insert and delete AST
node child of parent’s children at position 𝑖, respectively, whereas an update Update(old, new)
replaces the AST node old with new. Insert and delete child operations are also updates (of the
parent parent); however, we assume edits are written as insert or delete child when possible.

Given an edit ed, we define the kind of the edit Kind(ed) to be (operation, label) where:
(a) operation is one of Delete, Insert, or Update; and (b) label is the type of node that is being
deleted, inserted, or updated (e.g. MethodInvocation or Identifier). In an edit graph, we call the set
of all vertices (edits) of the same kind a partition.

Example 4.3. In Figure 6a, the edit v0 → v3 is of type (Insert, Property) and the type of v3 → v4
is (Insert, Parameter). The partition for (Insert, Property) is given by {v0 → v1, v0 → v2, v0 →
v3, v6 → v7, v6 → v8, v11 → v12, v11 → v13, v11 → v14, }.

Yuhao Zhang, Yasharth Bajpai, Priyanshu Gupta, Ameya Ketkar, Miltiadis Allamanis, Titus Barik, Sumit Gulwani, Arjun
Radhakrishna, Mohammad Raza, Gustavo Soares, and Ashish Tiwari
1:12

The quotient graph of the edit graph summarizes the sequencing information present in the edit
graph at the level of partitions. We build the quotient graph by lifting the edit graph’s sequencing
information to the level of partitions.

• Quotient graph vertices. A vertex in the quotient graph is a partition, i.e., the set of edits from
the edit graph with the same Kind. We use the term Partitions to denote the set of all vertices
in the quotient graph.

• Quotient graph edges. Classically, an edge exists between two vertices P → P′ in the quotient
graph when there exist ed ∈ P, ed′ ∈ P′ with an edge ed →seq ed′ between them (see,
for example, [Bloem et al. 2006]). Here, we strengthen the requirement by asking at least 𝑠
different pairs of such ed and ed′. This ensures that the ESPs we generate are general, i.e.,
there are multiple instances of the pattern. In our experiments, we use 𝑠 = 2.

• Quotient graph edge labels. We associate each edge P → P′ in the quotient graph with a label
Label(P → P′) that is a set of edit pairs. We define Label(P → P′) to be {(ed, ed′) | ed ∈
P, ed′ ∈ P, ed →seq ed′}, i.e., it contains all pairs of contiguous edits.

Example 4.4. The quotient graph for the edit graph in Figure 6a is shown in Figure 6b. There
are 3 different vertices (partitions) P1, P2, and P3 in the quotient graph corresponding to the
kinds (Insert, Property), (Insert, Parameter), and (Insert, Assignment), respectively. There is an
edge P1 → P2 from P1 to P2 as there are 3 > 𝑠 corresponding sequentially consecutive edit pairs:
(a) v0 → v3 and v3 → v4, (b) v6 → v8 and v8 → v9, and (c) v11 → v14 and v14 → v15. Further, the
label Label(P1 → P2) is given the same set of 3 edits.

Generating Sketches and Specifications. From the quotient graph, we generate ESP sketches
and corresponding specifications paths using paths in the quotient graph. First, we define the
support Support(P1 . . . P𝑛) as follows: (a) For the path with only 1 edge, we define Support(P1P2)
to be the label Label(P1 → P2), and (b) Otherwise, we define Support(P1P2 . . . P𝑛) recursively as
{ed1ed2 . . . ed𝑛 | (ed1 → ed2) ∈ Support(P1, P2), (ed2ed3 . . . ed𝑛) ∈ Support(P2 . . . P𝑛)}.

Now, we define a frequent path in the quotient graph as any path P1 . . . P𝑛 where
Support(P1 . . . P𝑛) has cardinality greater than a threshold 𝑠 = 2. The set of frequent paths can be
computed recursively by starting with single edges and adding edges to the end as long as the
support is greater than the threshold.

From the set of frequent paths, we generate two different kinds of sketch specification pairs.
• For any simple path P1 . . . P𝑛 (i.e., satisfying 𝑖 ≠ 𝑗 =⇒ P𝑖 ≠ P𝑗 ), we define sk = 𝐴1 . . . 𝐴𝑛

and spec = Support(P1 . . . P𝑛).

• For a set of paths {P1 . . . P𝑛−1P𝑛, P1 . . . P𝑛−1P𝑛P𝑛, . . . , P1 . . . P𝑛−1P𝑘

𝑛 } where P1 . . . P𝑛−1 is sim-

ple, we define sk = 𝐴1 . . . 𝐴∗

𝑛 and spec = (cid:208)

1≤𝑖 ≤𝑘 Support(P1 . . . P𝑛−1P𝑖

𝑛).

Example 4.5. One possible frequent paths in Figure 6b are given by P1P2P3 where the partitions
are equivalent to insert property, insert parameter, and insert assignment as described in Example 4.4.
From this path, we generate the sketch sk = 𝐴1𝐴2𝐴3 and the specification spec = {(v0 → v3)(v3 →
v4)(v4 → v5), (v6 → v8)(v8 → v9)(v9 → v10), (v11 → v14)(v14 → v15)(v15 → v16)}.

Overall, putting together the steps depicted in this section, we generate a set of sketch-
specification pairs (sk, spec) that each represent a common editing sequence in the input Traces.

5 SYNTHESIZING EDIT SEQUENCE PATTERNS

From Section 4, we get as input a number of sketch-specification pairs. Here, we synthesize
a hierarchy of ESPs for each sketch-specification pair. The procedure to do this has 3 major
components: (a) generate an ESP from an edit sequence, (b) combine two ESPs to a more general

Overwatch: Learning Patterns in Code Edit Sequences

1:13

pattern, and (c) produce a hierarchy of ESPs using the previous two components. Components (a),
(b), and (c) are explained in Sections 5.1, 5.2, and 5.3, respectively.

5.1 Generating an Edit Sequence Pattern
Consider generating an ESP from an edit sequence ed1 . . . ed𝑛 and a sketch sk = 𝐴1 . . . 𝐴𝑛.

• First, for each edit ed𝑖 , let Localize(ed𝑖 ) = ed𝑖,pre → ed𝑖,post. We set et𝑖 = ed𝑖,pre → ed𝑖,post
and Preds = ∅ and then iteratively perform the following operations. (a) Identify AST
nodes nodepre in et𝑖,pre and nodepost in et𝑖,post such that there is a predicate that relates
the two values. Further, we pick nodepre and nodepost such that they are of the largest
possible size. For example, we may pick nodepre and nodepost such that nodepost = nodepre or
nodepost = ToLower(nodepre). (b) We replace nodepre and nodepost in et𝑖 by two fresh holes
Hpre and Hpost, and add the predicate that relates the two values to Preds (e.g., Hpost = Hpre
or Hpost = ToLower(Hpre)). We will also add unary predicates IsNotNull and IsKind of Hpost
and Hpre if they satisfy the constraints. (c) We add the generated mappings to a substitution
𝜎𝑖 .

• Then, we union all the substitutions 𝜎𝑖 into a single 𝜎 (note that domains of 𝜎𝑖 are disjoint).
Now, for each H1 → node1, H2 → node2 ∈ 𝜎, we check if there exists a predicate that relates
node1 and node2. If so, we add that predicate on H1 and H2 to the Preds.

The produced ESP is ⟨et1 . . . et𝑛, Preds⟩. Note that the above procedure is for sketches without
Kleene stars—we discuss how to generate patterns with Kleene stars later.

Example 5.1. Consider the edit sequence ed1ed2ed3 where ed1 = v6 → v8, ed2 =
v8 → v9, and ed3 = v9 → v10 from Figure 3. We illustrate the ESP generation proce-
dure for ed1. First, we start with the localized edit Localize(ed1) = {<IdDecl> <Ctor>} →
{<IdDecl> public int Size {get; set;} <Ctor>}. The terms <IdDecl> and <Ctor> are short-
hand for public int Id {get; set;} and Graph(int id) {Id = id;}, respectively.

to get

Now, over all pairs of nodes in the localized edit, we check if there is a predicate that
is satisfied by the nodes. Here, we get that the node <IdDecl> is repeated in both the pre-
and post-versions. Replacing these with holes, we get the edit template {H1 <Ctor>} →
{H3 public int Size {get; set;} <Ctor>} and the predicate H1 = H3. Repeating this,
we replace <Ctor> with H2 and H4
{H1 H2} →
{H3 public int Size {get; set;} H4} and the predicate H4 = H2.

template et1

the edit

Doing the similar procedure on ed2 and ed3, we get the edit templates et2 = (H5) →
(H6, int size) and et3 = {H7} → {H8 Size = size;}, with the predicates H6 = H5 and H8 = H7.
We then compute the predicates across the different et𝑖 , and in this example, we do not find any.
The ESP returned is et1et2et3 along with the predicates Preds = {H3 = H1, H4 = H2, H6 =
H5, H8 = H7}. Note that the pattern does not create holes for the type or name of the inserted
property or parameter (int, Size, and size). With just a single edit sequence, we do not have any
evidence for the need to generalize these identifiers—hypothetically, every property that is added
in the input traces might have the type int and name Size. We can generalize these identifiers
□
when we have two ESPs as we will describe next.

=

5.2 Combining Edit Sequence Patterns
Using the previous step, we can generalize all concrete edit sequences in spec to ESPs. Now, we
discuss how to combine any two such ESPs into a single, more general, ESP. The primary tool we
use for this purpose is anti-unification [Plotkin 1970]. Anti-unification is a classical operation of
trees that retains the parts that are common to two trees, while replacing the parts that are different
with holes. It has been used in code edit analysis and synthesis literature to generalize ASTs and

Yuhao Zhang, Yasharth Bajpai, Priyanshu Gupta, Ameya Ketkar, Miltiadis Allamanis, Titus Barik, Sumit Gulwani, Arjun
Radhakrishna, Mohammad Raza, Gustavo Soares, and Ashish Tiwari
1:14

edits in multiple contexts [Bader et al. 2019; de Sousa et al. 2021; Gao et al. 2020]. However, in
our technique, we need to anti-unify sequences of edit templates rather than ASTs or single edit
templates, and further, need to consider the predicates.

Formally, given two sequences of edit templates et1 . . . et𝑛 and et′
1

𝑛, the anti-unification of
the two sequences produces an edit template sequence et∗
. . . et∗
𝑛 and two substitutions 𝜎, 𝜎 ′ such
1
𝑖,post) and et′
𝑖,pre) → 𝜎 (et∗
𝑖 , we have that et𝑖 = 𝜎 (et∗
that: For each et∗
𝑖,post).
Intuitively, anti-unification is generalization: if any edit sequence ed1 . . . ed𝑛 matches et1 . . . et𝑛 or
et′
𝑛. Further, we also need to generalize hole predicates Preds
1
and Preds′. For this, we generate only those hole predicates that are satisfied by both substitutions
𝜎 and 𝜎 ′. As a result, the newly generated hole predicates is also a generalization.

𝑛, it will also match et∗
1

𝑖,pre) → 𝜎 ′(et∗

𝑖 = 𝜎 ′(et∗

. . . et∗

. . . et′

. . . et′

Example 5.2 (Anti-unification of edit sequence patterns). Recall the edit templates et1et2et3 from
Example 5.1. Now consider another ESP from a similar sequence of edits shown in Figure 2, but
with the following changes: (a) the property and parameter added has a different name and type
(str Id and str id) and (b) the parameter list in the constructor and the body of the constructor
are empty. In the edit templates et′
1 is similar to et1
1
2 = () → (str id), i.e., it does not have H5 and H6 to
with the hole names replaced. However, et′
represent the already existing parameters in the parameter list. Similarly, et′
3 = { } → {Id = id;}
and it does not contain H7 and H8.

3 for an ESP generated for this case, et′

et′
2

et′

To generalize the two edit templates et1et2et3 and et′
1

et′
2

et′

3, we anti-unify the before and post

=

H∗

{H∗
1

2 as (H∗

𝑖 one by one:

11) → (H∗

templates in each et𝑖 and et′
• For et1 and et′
2} →
1, we get
10 {get; set;} H∗
H∗
3 public H∗
4}. Note that the type and name of the properties have
9 and H∗
10.

{H∗
9
been replaced by new holes H∗

the anti-unified edit

template et∗
1

• For generalizing, et2 and et′

2, additional care must be taken as there are no holes corresponding
to H5 and H6 in et′
2. Some anti-unification approaches [Bader et al. 2019; de Sousa et al. 2021]
will produce an overly general edit template et∗
12). With this edit template,
we do not have any holes for the name and type of the parameter, and thus we cannot express
the hole predicate between parameter type and property type.
We propose to further generalize the lists of children, i.e., (H6, int size) and (str id),
inspired by Gao et al. [2020]. During anti-unification, we examine if the two children lists
can be better generalized by introducing additional holes which are substituted by the empty
token 𝜖 in one case. Doing so, we get et∗
3 = {H∗

• Similarly, for et3 and et′
Note that we can get substitutions 𝜎 and 𝜎 ′ for free after we generalized these edit templates.
These substitutions can then be used to generate the hole predicates. (a) For a specific unary hole
predicate F, we enumerate every hole H in generalized edit templates and checking whether both
F(𝜎 (H)) and F(𝜎 ′(H)) are satisfied. Notice that 𝜎 (H) and 𝜎 ′(H) can still contain holes in the first
or the second ESP. If there are any holes in 𝜎 (H) or 𝜎 ′(H), we recursively repeat the substitution
procedure until H maps to an AST in concrete edit sequences. (b) We generate binary hole predicates
similarly but enumerate all pairs of holes in generalized edit templates. In this case, we end up
with the starred version of the predicates in Preds from Example 5.1, along with the predicates
14 = H∗
{H∗

13 = H∗
et∗
2
editing sequence of adding a new property and initializing it in the constructor.

, H∗
3 along with the new predicates exactly capture the
□

11 = H∗
12 = ToLower(H∗
The generalized edit templates et∗
1

6, H∗
5) → (H∗
13 = H∗
H∗

2 = (H∗
7} → {H∗

3, we get et∗

H∗
11
14}.

10), H∗

12}.

10
et∗

12).

, H∗

9

8

As illustrated in the previous example, we cannot generalize ESPs using standard anti-unification
techniques. When two nodes in the edit templates have different numbers of children, we may need
to introduce new holes that map to 𝜖. We do not explicitly write out our anti-unification algorithm

Overwatch: Learning Patterns in Code Edit Sequences

1:15

here for the lack of space—instead, it is available in the supplementary material. The algorithm
takes as input two ESPs ⟨TS1, Preds1⟩ and ⟨TS2, Preds2⟩, and produces a more general ⟨TS, Preds⟩.
Along with the generalized ESP, the algorithm also returns a cost of anti-unification. This cost
roughly measures how general the ⟨TS, Preds⟩ is compared to ⟨TS1, Preds1⟩ and ⟨TS2, Preds2⟩, with
more general patterns getting a higher cost than less general ones. This corresponds to the intuition
that anti-unification algorithms attempt to compute the least general generalization of two objects.
Based on the anti-unification costs, we will generate a hierarchy of ESP in the following section.

5.3 Building a Hierarchy of Edit Sequence Patterns

Algorithm 2 The procedure of building a dendrogram (LearnPatterns in Algorithm 1)
Require: Sketch of edit sequence pattern sk
Require: Specification for edit sequence pattern spec
Ensure: A set of edit sequence patterns Patterns
1: Nodes ← {GeneratePattern(sk, ed1 . . . ed𝑛) | ed1 . . . ed𝑛 ∈ spec}
2: Patterns ← ∅
3: while |Nodes| > 1 do
4:
5:
6:
7:
8: return Patterns

Pick Node1, Node2 such that AntiUnifyCost(Node1, Node2) is minimal
NewNode ← AntiUnify(Node1, Node2)
Patterns ← Patterns ∪ {NewNode}
Nodes ← Nodes − {Node1, Node2} ∪ {NewNode}

Algorithm 2 shows the full procedure going from an ESP sketch sk and specification spec to
a set of ESPs Patterns. The algorithm performs a standard agglomerative hierarchical clustering
(AHC) [Day and Edelsbrunner 1984] with the distance metric given by the anti-unification cost.
AHC builds a dendrogram where each node is an ESP. This is reminiscent of the techniques [Bader
et al. 2019], but performed over a sequence of edits rather than a single one. At line 1, we build
the leaf nodes in dendrogram by generalizing edit sequences to ESPs as described in Section 5.1.
At lines 4-5, we select two nodes in the dendrogram Node1, Node2 that have the lowest merging
anti-unification cost in anti-unification and anti-unify them into a new dendrogram node NewNode.
The procedure eventually returns the set of all nodes that were constructed.

Remark 5.3 (Handling Kleene stars). An ESP sketch 𝐴1 . . . 𝐴𝑛−1𝐴 [∗]

𝑛 with Kleene stars may contain
edit sequences with various lengths. To handle the sketch with Kleene stars, we will compute a new
set of edit sequences, each of which has length 𝑛 equal to the sketch, such that we can build the
dendrogram in the same way as the sketches without Kleene stars. Concretely, for an edit sequence
ed𝑖
. . . ed𝑖
1
Suppose we have an ESP sketch 𝐴1𝐴∗

𝑛−1
2 and an edit sequence ed1ed2ed3ed4, where ed1 corresponds
to 𝐴1 and ed2, ed3, ed4 correspond to 𝐴2. We will break the edit sequence into three edit sequence
with length 2, namely, ed1ed2, ed1ed3, and ed1ed4.

𝑚 in the sketch we will collect all subsequences ed𝑖
1

𝑘 for all 𝑛 ≤ 𝑘 ≤ 𝑚.

. . . ed𝑖

ed𝑖

6 RANKING EDIT SEQUENCE PATTERNS

As we discussed in Section 2, we cannot simply pick more general ESPs over less general ones.
More general patterns may be less predictive than specific ones. In this section, we will select a
ranked list of ESPs from all dendrograms as the output of Overwatch.
Predictions Using Edit Sequence Patterns First, we discuss how an ESP can be used for pre-
dicting the next change in Algorithm 3. As input, it takes an ESP ⟨TS, Preds⟩ and a trace v0 . . . v𝑚.

Yuhao Zhang, Yasharth Bajpai, Priyanshu Gupta, Ameya Ketkar, Miltiadis Allamanis, Titus Barik, Sumit Gulwani, Arjun
Radhakrishna, Mohammad Raza, Gustavo Soares, and Ashish Tiwari
1:16

Algorithm 3 The procedure of edit sequence pattern prediction
Require: An edit sequence pattern ⟨TS = et1 . . . et𝑛−1et[∗]
Require: A trace v0 . . . v𝑚
Ensure: Prediction for next version ˆv or ⊥
1: for all possible edit sequences ed1 →seq . . . →seq ed𝑘 ending at v𝑚 and 𝑘 ≤ 𝑛 do
2:
3:
4:
5:

vpredicted ← Predict(et𝑘+1, 𝜎)
if vpredicted ≠ ⊥ then return vpredicted

if ed1 . . . ed𝑘 matches et1 . . . et𝑘 using a unique 𝜎 then

if 𝑘 < 𝑛 then

𝑛 , Preds⟩

6:
7:
8:

else

vpredicted ← Predict(et𝑛, 𝜎)
if vpredicted ≠ ⊥ then return vpredicted

9: return ⊥
10: function Predict(et = tpre → tpost, 𝜎)
𝑚 in v𝑚 do
11:
𝑚 ∧ 𝜎 ′ satisfy Preds ∧ 𝜎 ⊆ 𝜎 ′ then
12:
13:

for all Every subtree v∗
if ∃𝜎 ′.𝜎 ′(tpre) = v∗

return v𝑚 with the subtree v∗

𝑚 replaced by 𝜎 ′(tpost)

14:

return ⊥

Algorithm 3 will first match a developer’s edits against a prefix of a learned ESP (Lines 1-2) and
use the next edit template in the ESP to predict the change the developer is going to make next
(Lines 3-8).

Remark 6.1. In our implementation, instead of brute-force enumeration at Lines 1-2, we enumer-
ate all matched edit sequences by prefixes of an ESP in polynomial time. We do this by matching
edits on a deterministic finite automaton generated from the ESP. Also note that we require the
substitution 𝜎 to be unique to avoid over-generalization. In our evaluation, we provide with the
cursor location information to Predict in Algorithm 3 such that we only need to enumerate sub-
trees v∗
𝑚 that contain the cursor location of the user to make more precise predictions. Notice that
we only let an ESP generate its first prediction for a trace in Algorithm 3. However, we recorded all
predictions that can be made by an ESP in our evaluation and found that no ESP had made multiple
predictions for a trace.

For each ESP, there are three outcomes at each version v𝑚: (1) the pattern does not predict, i.e.,
returns ⊥, (2) correct prediction, the pattern predicts ˆv that is equal to v𝑙, 𝑙 > 𝑚 in the later sessions,
and (3) otherwise, we consider the pattern makes a wrong prediction.
Ranking and Selecting Edit Sequence Patterns. From Section 5, we get a set of ESPs Patterns.
Let edSeqs be the union of all edit sequences in the specifications generated in Section 4. Here, we
try to solve the following problem: select and rank a subset of Patterns such that we maximize the
correctly predicted versions and minimize the wrongly predicted versions. Algorithm 4 depicts the
procedure for this.

The core component of Algorithm 4 is the GreedySelect procedure. The procedure takes as
input a set of patterns Patterns and traces Data and produces a ranked subset of patterns based on
their predictive performance. Intuitively, GreedySelect works similar to the approximate set-cover
algorithm. We call each version in a trace in Data a data point. The procedure maintains a partial
list of selected patterns and a set Uncovered of data points on which no selected pattern has made
a prediction. We first measure the number of correct and incorrect predictions each pattern makes
on Data. With these count of correct and incorrect predictions, we then eliminate all patterns with

Overwatch: Learning Patterns in Code Edit Sequences

1:17

Algorithm 4 The procedure of ranking edit sequence patterns (FilterAndSelect in Algorithm 1)
Require: A list of edit sequence patterns Patterns
Require: Input traces Traces
Require: Edit sequences EditSeqs
Require: Precision thresholds threshold1, threshold2
Ensure: A ranked list of edit sequence patterns Patterns
1: function FilterAndSelect
2:
3:
4:
5: function GreedySelect(Patterns, Data, threshold)
SelectPatterns ← [], Uncovered ← Data
6:
for all 𝑝𝑖 ∈ Patterns do
7:
8:

Patterns ← GreedySelect(Patterns, EditSeqs, threshold1)
Patterns ← GreedySelect(Patterns, Traces, threshold2)
return Patterns

correcti, incorrecti ← Evaluate(𝑝𝑖, Data)
correcti
> threshold}
correcti+incorrecti

Patterns ← {𝑝𝑖 |
while Patterns ≠ ∅ ∧ Uncovered ≠ ∅ do

𝑝 ← argmax𝑝𝑖 ∈Patternscorrecti − incorrecti
Patterns ← Patterns − {𝑝}
SelectPatterns ← SelectPatterns + [𝑝]
Uncovered ← Uncovered − {data points covered by 𝑝}
Update all correcti and incorrecti according to Uncovered

return SelectPatterns

9:
10:
11:
12:
13:
14:
15:

16:

precision less than a given threshold. In each iteration of selection, (a) we update the partial list of
pattern with the best pattern as measured by the difference in the number of correct and incorrect
predictions, and (b) we remove the set of datapoints on which the best pattern made predictions
from Uncovered and update all correcti and incorrecti accordingly.

Algorithm 4 calls GreedySelect twice in two phases. In the first, we only consider the predictive
power of each pattern on the set edSeqs. Then, in the second step, we select and rank based on the
full training data, i.e., the input Traces. Ideally, we only need the second step at line 3 because the
precision on traces reflects the effectiveness of ESPs in real scenarios. However, we add the first
step of filtering to reduce the number of patterns evaluated in the second step because performing
GreedySelect over traces on all patterns is very expensive. We find the first step is able to filter out
most of the patterns, speeding up the second step by a large degree.

7 EVALUATION

In this section, we present our evaluation to address the following research questions:

• RQ1: How effective is Overwatch at predicting edit sequences performed in the IDE?
• RQ2: What kind of ESPs are learned by Overwatch?

7.1 Experimental Setup

Data Collection. We developed a Visual Studio extension to record all syntactically correct versions
of the documents updated by the developer (in the background, without interruption). We selected
Visual Studio as the target IDE in this study as it is the most popular IDE for C#. We contacted 12
professional software developers from a large software company who agreed to use the extension
and participate in the study. They were working on four separate C# code bases with a total of
377.5K source lines of code. Initially, we recorded 682 development sessions ((cid:27) 250 hours) containing

Yuhao Zhang, Yasharth Bajpai, Priyanshu Gupta, Ameya Ketkar, Miltiadis Allamanis, Titus Barik, Sumit Gulwani, Arjun
Radhakrishna, Mohammad Raza, Gustavo Soares, and Ashish Tiwari
1:18

134, 545 versions of 425 documents, which we refer to as training dataset. After 6 months, we
collected an additional 399 sessions (containing 201, 142 versions), which we refer to as test dataset.
Parameter Choices. Apart from data, Overwatch requires a few runtime parameters : (a) The
maximum length of the sequences, (b) minimum length of the edit sequences (Section 4), (c) thresh-
olds threshold1 and threshold2 for selecting patterns based on the sketch and session analysis,
respectively (Section 5). We chose n = 3 for the maximum length based on our initial set of
sequence examples, which did not contain longer sequences, and s = 2 for the support so that we
have at least two examples for each pattern. We study the effect of varying the values of threshold1
and threshold2 in the experiments for RQ1.
RQ1 Methodology. To answer RQ1, we (a) perform a 5-fold validation over our training dataset
and (b) simulate the learned patterns from the training dataset on our test dataset containing unseen
development sessions. To perform the 5-fold validation, we randomly split 682 training sessions
into 5 equal folds and for each fold, we evaluate the ESPs that were learned from the other 4 folds.
We repeat the 5-fold validation varying threshold1, threshold2 ∈ [0, 1] by steps of 0.1. Using the
best threshold values found (as measured by the 𝐹3 metric defined below), we evaluate the ESPs
learned from the full training dataset on the test dataset.

For each experiment, we compute the precision of the code edit suggestions as the proportion of
the total suggestions that are correct (see Section 6). To compute recall, we need an oracle containing
all the edits expected from Overwatch. Since our data set consists of thousands of fine-grained
edits, it is not feasible to construct such an oracle manually. Instead for our experiments, we define
our baseline as the number of correct suggestions we get when using Overwatch in its most
general setting with threshold1 = 0 and threshold2 = 0 values in Algorithm 4. Using this baseline,
we define relative recall (recall𝑟𝑒𝑙 ) as the ratio of correct prediction Overwatch produces at a given
configuration with respect to the baseline.

To consolidate the precision and recall metric into a single score, we make use of a variation of

the popular 𝐹𝛽 metric [Chinchor 1992; van Rijsbergen 1979]. Here, we use 𝐹𝛾 given by:

𝐹𝛾 =

(1 + 𝛾 2) ∗ 𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 ∗ 𝑟𝑒𝑐𝑎𝑙𝑙𝑟𝑒𝑙
𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 + 𝛾 2𝑟𝑒𝑐𝑎𝑙𝑙𝑟𝑒𝑙

(1)

Note that this definition is equivalent to the definition of 𝐹𝛽 with 𝛽 set to 1
𝛾 and the recall term
replaced by relative recall. The 𝛾 parameter allows us to choose the relative emphasis we put on
the precision term compared to recall term, with precision given 𝛾 times more importance over
recall [van Rijsbergen 1979]. For our evaluation, we make use of 𝐹𝛾 =3 to give precision 3 times more
importance than recall𝑟𝑒𝑙 . We chose to increase the emphasis on precision because of two reasons:
(a) Reliability is one of main causes of disuse of automated refactorings in IDEs [Vakilian et al.
2012], so tool builders tend to favor precision over recall. (b) The use of recall𝑟𝑒𝑙 instead of recall
tend to introduce a bias towards recall because recall𝑟𝑒𝑙 will be higher than ground-truth recall.

For notational simplicity we use 𝐹3 instead of 𝐹𝛾 =3 to refer to this metric in the rest of the paper.
RQ2 Methodology. To answer RQ2, we manually analyzed the ESPs learned by Overwatch
using the best threshold parameters found from the RQ1 study. Two authors, each with more than
5 years of professional development in C#, coded these ESPs using established guidelines from the
literature [Campbell et al. 2013; Saldana 2009]. They first iteratively refined the code set on 20%
of the patterns. Then, using this code set, they independently coded another 20% of the patterns.
We then use Cohen’s kappa to calculate inter-rater reliability. Their inter-rater reliability was 0.95,
which shows a high agreement between the two raters. We then split the rest of the patterns into
two sets, and they independently coded each set. We detail each code set in RQ2.

Overwatch: Learning Patterns in Code Edit Sequences

1:19

Table 1. Precision and relative recall of Overwatch sorted by 5-fold Validation 𝐹3 scores
5-fold Validation (average)
Precision Recall𝑟𝑒𝑙
(in %)

Precision Recall𝑟𝑒𝑙
(in %)

Test Set Evaluation

F3
(in %)

Threshold2

F3
(in %)

Threshold1

(in %)

(in %)

0.7
0.6
0.6
0.8
0.5

0.8
0.7
0.8
0.8
0.8

Baseline (0, 0)

79.47
76.07
78.47
78.38
78.15

49.23

40.73
49.75
41.46
41.35
40.08

100

72.57
72.25
72.04
71.94
71.37

51.86

78.38
70.93
77.42
82.65
74.29

40.07

36.25
40.25
36.00
40.50
32.50

100

70.22
65.90
70.22
74.86
65.82

42.62

7.2 Results
RQ1: How effective is Overwatch at predicting edit sequences performed in the IDE?

Table 1 summarizes the precision, relative recall and 𝐹3 statistics for the top-5 threshold configu-
rations for both the 5-fold validation and the test set evaluation as described in Section 7.1. In the
bottom row, we also report the statistics for the baseline configuration used to calculate relative
recall. Among the top-5 configurations, Overwatch’s precision on the test set ranged from 70.93%
to 82.65% compared to baseline’s 40.07%, their relative recall ranged from 32.5% to 40.5% compared
to Baseline’s 100%, and their 𝐹3 ranged from 65.82% to 74.86% compared to Baseline’s 42.62%. The
best configuration on 5-fold validation set uses threshold1 = 0.7 and threshold2 = 0.8 and achieves
78.38% precision, 36.25% relative recall, and 70.22% 𝐹3 on the test set evaluation.

Comparing the statistics for 5-fold validation and test set evaluation, we observe high parallels
in terms of the precision and relative recall, hinting towards a degree of domain-invariance in the
learned patterns as the train dataset and test dataset were collected more than 6 months apart.

The effectiveness of Overwatch has a degree of domain-invariance and the best configuration
on 5-fold validation achieves 78.38% precision, 36.25% relative recall, and 70.22% 𝐹3 on the test
set evaluation.

RQ2: What are the edit sequence patterns learned by Overwatch?
Categorizing ESPs. Fixing the best configuration (threshold1 = 0.7 and threshold2 = 0.8) from
the previous study, Overwatch learned 135 edit sequence patterns. We classified these patterns
into four categories using the coding methodology from Section 7.1, as shown in Table 2.

• Workflows. We classified 25.9% of the ESP as Workflow, which consists of an ESP that describe
the workflow of a developer performing a particular high-level task. For instance, to rename
a variable, the developer first renames the variable in the declaration, and then renames each
one of the variable uses. Each step of the workflow is represented as an edit template in the
ESP. The ESP detects the step that the developer is in the task, and predicts the next steps to
finish it.

• Repeats. 27.5% of the ESP were classified as Repeat, which consists of ESP that represent a
developer performing a single task multiple times. For instance, a developer performs an
edit to remove the qualifier “this” from multiple parts of the code. The ESP detects that the
developer performed the edit in one location and when they move to another similar location,
the ESP predicts the change.

• Transients and Noise. Finally, we identified two categories of ESP that are not useful: Transient
and Noise. The former (13%) relates to edits that are too fine-grained, such as inserting
publicclass and then changing to public class. The latter (33.6%) relates to changes that

Yuhao Zhang, Yasharth Bajpai, Priyanshu Gupta, Ameya Ketkar, Miltiadis Allamanis, Titus Barik, Sumit Gulwani, Arjun
Radhakrishna, Mohammad Raza, Gustavo Soares, and Ashish Tiwari
1:20

do not represent a high-level task, such as adding a specific switch statement and then adding
a break statement.

After removing noisy ESPs and accounting for ESPs that are variations of a single type of refactoring,
we get 51 unique pattern types. The list of these 51 pattern types is shown in supplementary material.
Relating ESPs to IDE features. We further sub-classified the Workflow and Repeat ESPs into two
categories: Existing Feature and New Feature. Table 3 presents a list of 20 learned ESPs, 10 existing
features and 10 new features. In the first category, we include ESPs that have a corresponding
automated tool or refactoring implemented in the IDE, which allows the IDE to automate the
complete edit in one step using just the spatial context. Existing Feature ESPs correspond to 53%
and 39% of the Workflow and Repeat ESPs, respectively. The New Feature category includes ESPs
for which we did not find a corresponding IDE feature. For instance, ESP 9 is the inverse of ESP 6,
Instead of adding a property and its corresponding parameter, the developers removes the property
and the parameter. Note that this pattern shows that developers perform changes in a non-standard
way—the ESP first deletes the parameter, then the assignment, and finally the property.
Analyzing Existing Feature ESPs. We discuss existing feature ESPs in detail here as they are
closely connected to our motivation of addressing the late-awareness and discoverability problems.
Overwatch learns existing feature ESPs only because developers manually performed these edits,
which created a trace of fine-grained edits, instead of using the IDE tool support, which would
lead to a single, larger edit. For instance, ESP 4 represents the edit sequence shown in Figure 7.
The complete edit is automated in one step by Visual Studio (Delete Parameter) using the spatial
context. To apply this refactoring, the developer needs to put the cursor on the parameter list, then
click on the Quick Actions pop-up (the screwdriver icon on the left side of the text pane) select
“Change signature...” among all the code edit options, and then select the parameter to delete. To
apply this refactoring, not only does the developer need to be aware of this tool, but also needs to
use the tool before making any changes manually. If the developer starts by deleting the parameter
from the parameter list, Visual Studio will not generate a suggestion to finish the edit sequence by
deleting the corresponding arguments. Meanwhile, ESP 4 uses the fact that the developer manually
deleted the parameter to predict that the developer will delete the corresponding argument–the
developer can use a tool based on ESP 4 even if they have already started making changes.

These results suggest that IDE features were under used, in congruence with the observation
made by Ge et al. [2012]. They point to the fact that these tools are hard to discover (discoverability
issue) and even when they are discoverable, developers do not realize the possibility of using it
at the time when that suggestion is available (late-awareness). Overwatch can alleviate these
problems by producing code edit suggestions using the learned ESPs as shown in Figure 1b, while
developer is editing.

Our qualitative analysis shows that ESPs can be used not only to complete edits when developers
typically miss the opportunity to use the IDE tool support but also to predict edits based on
new patterns that have no tool support at all.

8 DISCUSSION

Our empirical study shows how Overwatch can help developers by predicting edits based on the
temporal context. In this sections, we discuss our results.

8.1 Overwatch’s effectiveness compared to related tools

To our knowledge, there is no other technique or tool that addresses the same problem so that we
can directly compare the precision. Instead, we indirectly contrast Overwatch to the closest tool,

Overwatch: Learning Patterns in Code Edit Sequences

1:21

Table 2. Categories of Edit Sequence Patterns

Id

1

Category Description

Examples

Workflow A pattern that represents the workflow that a devel-
oper performs to complete a task. Each edit in the
edit sequence represent a step that the developer took.
The temporal context is used to detect the previous
steps that the developer performed and predict the
remaining ones.

(i) Developer changes the name of a variable in its
declaration and then renames each one of the ref-
erences (rename variable);
(ii) Developer changes the type of a variable in the
left-hand side of an assignment and then changes
the name of the constructor in the right-hand side
of the assignment.

2

Repeat

A pattern that represents the developer performing
the same task multiple times. All edits in the sequence
have the same edit template. The temporal context
can predict that the developer will perform the task
again.

(i) A developer deletes the keyword this from
multiple locations in a class (Remove this);
(ii) Developer replaces a static method invocation
with a virtual method invocation in multiple loca-
tions.

3

4

Transient The sequence represented is too fine-grained to be

considered useful.

Noise

We could not identify a high-level task for this pat-
tern.

(i) Developer inserts i, then changes to i++;
(ii) Developer writes “publicclass” then changes to
“public class”
(i) Developer creates a switch statement with a spe-
cific case, and then adds a break statement;
(ii) developer cuts and pastes a statement.

%
25.9

27.5

13.0

33.6

Table 3. Sample of 20 Edit Sequence Patterns Learned by Overwatch

Category

Id

Pattern Description

Rename method decl → Rename method calls

Related Feature

Rename Method

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

Workflow

Repeat

Insert variable decl → Replace constants with new variable

Introduce Local Variable

Insert parameter → Insert argument to callsites

Delete parameter → Delete argument from callsites

Insert parameter

Delete parameter

Replace variable declaration by assignment → Insert new field

Promote local variable to field

Insert Property → Insert Parameter → Insert Assignment

Insert expression → Replace it by assignment

Initialize property

Introduce variable

Change type in variable decl → Change constructor name in initializer

New Feature

Delete parameter → Delete assignment → Delete property

New Feature

Insert parameter with default value → Replace constants with parameter

New Feature

Delete field → Delete assignment

Insert argument to callsite → Remove default parameter value

Insert variable declaration → Insert new variable as argument

Insert return statement → Delete throw "NotImplementedException"

New Feature

New Feature

New Feature

New Feature

Remove ‘this’ in multiple locations

Remove ‘cast’ in multiple locations

Change from qualified name to simple name

Remove unnecessary qualifier “this”

Remove unnecessary cast

Simplify Name Access

Converting static method calls to virtual in multiple locations

Remove a method invocation from many locations

Replace an expression by a method invocation

New Feature

New Feature

New Feature

C3PO [Brody et al. 2020]. Given a code snippet that is partially edited, C3PO uses a neural model
to predict a completion of the edit within the surrounding 10 lines of code. While not directly
comparable to Overwatch’s 70.22% 𝐹3, [Brody et al. 2020] report C3PO’s accuracy as 53%. C3PO is
also restricted to code updates or code deletions, and cannot handle authoring/adding of new code
(e.g., Insert-Property-Parameter-Assignment). While edit completion can be seen as an ESP of length
2, their intended context is completely different: C3PO is trained on edits from source control,
while Overwatch is targeted at much more fine-grained edits in the IDE. Further, Overwatch

Yuhao Zhang, Yasharth Bajpai, Priyanshu Gupta, Ameya Ketkar, Miltiadis Allamanis, Titus Barik, Sumit Gulwani, Arjun
Radhakrishna, Mohammad Raza, Gustavo Soares, and Ashish Tiwari
1:22

is driven by temporal context and can predict edits that are spatially far away from the current
editing location (e.g., Delete parameter & drop args at callsites).

8.2 Limitations

Our qualitative analysis revealed some limitations of Overwatch. First we observed that some
ESPs could be represented as a single more general ESP, which happened when two sketches could
be generalized into a single sketch. A possible solution for this problem is to try to merge top-ranked
ESPs of each sketches in a second round of hierarchical clustering, filtering and selection.

Additionally, we identified several transient and noisy ESPs. While only 13% of the ESPs were
considered transient, and this number can be reduced by implementing a few heuristics based on
these patterns, noisy ESPs represented 33.6% of the patterns. We observed that many of these noisy
ESPs were related to patterns that were too specific, which would not produce false positives, but
also would not likely trigger on other codebases. This problem can be alleviated with more data
and a higher threshold for the support of each edge in the quotient graph (we used support = 2).
Finally, our ranking step (Section 6) will filter out ESPs with unbounded holes that cannot be
filled by hole predicates because these ESPs will have zero precision. For example, our approach
will filter out the ESP when user copies a property declaration and then tries to update the name
of the copied property (v6 → v7 → v8 in Figure 3) because we do not know what will be the new
name of the property. Additionally, we rank our ESPs using their performance on the training
dataset. However, we could rank them adaptively every time when making a prediction given the
context of the code. We foresee that combining large language models with our ESPs will be a
fruitful research direction because the language models can help fill in unbounded holes in ESPs
and rank ESPs adaptively for each prediction.

8.3 Threats to validity

Construct Validity. We measured precision by checking if the edit predicted by Overwatch leads to
the exact same code of a subsequent version. Some correct predictions, however, may lead to code
that is similar but not exact the same. If the prediction adds a property to the beginning of the class
but the developer ended up ending it somewhere in the middle, we will classify the prediction as a
false positive, even though both edits are semantically equivalent. Therefore, our false positives
may contain some true positives.

Internal Validity. The choice of some parameters used in our evaluation may impact the results. To
reduce the bias on the choice of parameters, we performed a cross-validation to select the parameters
(𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑1 and 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑2) that would impact the most on the precision of Overwatch.

External Validity. Overwatch learned ESPs from 682 code development sessions from 12 Visual
Studio users (developers) that worked on 4 separate C# code bases. While our results suggest
that the ESPs generalize to other datasets, such as our test dataset collected several months after
the training dataset, these ESPs might not generalize to other IDEs or programming languages.
Nevertheless, we identified several ESPs that have corresponding features in the IDE, and the
proposed technique is independent of programming languages.

Verifiability. Our dataset is not publicly available due to a non-disclosure agreement with our
participants.

9 RELATED WORK

Our work distinguishes itself from existing work by simultaneously learning (i) the edits from
code development sessions in IDEs, and (ii) the temporal relation between the edits. Existing work

Overwatch: Learning Patterns in Code Edit Sequences

1:23

on edit patterns is mostly focused on coarse-grained edits, whereas existing work on temporal
patterns is limited in the scope of edits it considers.
Learning Edit Patterns from Commits Previous researchers have proposed a plethora of tech-
niques that learn edits patterns from the coarse commit level changes. de Sousa et al. [2021]
proposed a technique that infers code change pattern as rewrite rules (not specific fixes, or bugs)
using anti-unification and a greedy algorithm for clustering. Similarly, Bader et al. [2019] proposed a
technique (Getafix) to learn bug fix patterns using anti-unification. They presented a novel hierar-
chical, agglomerative clustering algorithm to cluster the examples. Getafix then applies an effective
ranking technique that uses three metrics to produce a small and appropriate number of fixes for
a given bug. Getafix inspires our design of the algorithms synthesizing edit sequence patterns,
including anti-unification and the hierarchical clustering algorithm. However, Overwatch learns
edit sequence patterns (not just an edit template) from fine-grained code development sessions
instead of commit level data.

Recently, Ketkar et al. [2022] proposed TCI-Infer that learns the rewrite rules to perform type
changes from the type changes identified by RefactoringMiner[Tsantalis et al. 2020] in the commit
level history of Java projects. Similarly, A3 [Lamothe et al. 2020] and MEditor [Xu et al. 2019] infer
the adaptations required to perform library migration by analyzing the changed control/data flow
across the commit. Kim et al. [2013] proposed a syntactic approach to automatically discover and
represent systematic changes as logic rules with the goal to enhance developer’s understanding
about the program’s evolution. Previously, Meng et al. [2011, 2013]; Ray et al. [2012] proposed
techniques to perform systematic code changes by creating a context-aware edit script, finding
potential locations and transforming the code. Andersen and Lawall [2008] propose a technique
that generates generic patches from a set of files and their updated versions and applies these to
other files. Yin et al. [2019] propose a model that combines neural encoder with edit encoder, to
express salient information of an edit and can be used to apply the edit. In contrast, Overwatch
learns sequences of edit patterns (as opposed to a single edit) that developers often apply while
performing their daily code development activities in an IDE. Blue-Pencil [Miltner et al. 2019]
identifies repetitive changes, and automatically suggests similar repetitive edits. However, all these
techniques either focus on a specific kind of edit or operate on coarse-grained VCS data which is
imprecise, incomplete and makes it impossible to involve the temporal aspect [Negara et al. 2012].
Learning Edit Patterns from Sequence of Changes. Mesbah et al. [2019] propose DeepDelta
to automatically suggest code fix for the common classes of build-time compilation failures. They
encode the human-authored, in-progress changes into a domain-specific language and feed them to
a neural machine translation network along with the compiler diagnostic. In contrast, Overwatch
operates over finer IDE level sequences of code changes to learn the sequences of edits performed
for a large variety of daily code development activities, not limited to compilation error fixes.
Previously Negara et al. [2014] proposed a technique to detect high-level code change patterns from
the fine-grained sequences of edits recorded in the IDE. In contrast, Overwatch learns sequences
of executable edit templates that not only captures the high-level code change patterns but also the
different workflows or sequences of edits that were applied to perform the change.
Detecting Sequences of Edit Patterns. Previous researchers have also tackled the temporal
aspect of applying edits like Overwatch. [Foster et al. 2012; Ge et al. 2012] identified that dis-
coverability and late-awareness led to underuse of refactoring tools, and proposed the techniques
Benefactor and WitchDoctor to overcome it. The users of these technique have to manually en-
code the sequence of edits that are applied to perform a larger refactoring. The authors conducted
interviews with software developers to manually recorded the sequences of edits they apply to
perform a refactoring. These tools detect when the user is performing a refactoring, and suggest
a completion. On the other hand Overwatch, automatically learns the sequence of edits that

Yuhao Zhang, Yasharth Bajpai, Priyanshu Gupta, Ameya Ketkar, Miltiadis Allamanis, Titus Barik, Sumit Gulwani, Arjun
Radhakrishna, Mohammad Raza, Gustavo Soares, and Ashish Tiwari
1:24

developers apply to perform any high level programming task (beyond refactorings) from code
development sessions. Overwatch basically automates the entire pipeline proposed by Benefactor
and WitchDoctor.

10 CONCLUSION

We introduce and tackle the problem of learning edit sequence patterns, with the aim of adding
temporal context into IDE edit suggestion tools. ESPs capture fine-grained details in developers’
editing behaviour, and can be used to address the two key challenges towards broader usage of IDE
edit suggestion tools—discoverability and late awareness. Our experiments show that Overwatch
can not only learn and automate editing patterns related to existing IDE tools, but also discover
new patterns! Besides being useful to automatically make edit suggestions in the IDE, we foresee
the ESPs being used by IDE toolsmiths to decide and prioritize what new features they should
develop in a data-driven manner.

ESPs and temporal context can help develop tools that are more accurate, and in turn, allow
for more aggressive presentation of suggestions with hand-raising interfaces like “grey text”. We
are currently exploring the design space for these interfaces to determine the best way to present
different kinds of insert, delete, and update edit suggestions based on the IDE’s confidence in those
suggestions. With the advent of powerful pre-trained language models for source code has also
opened up the possibility of extending Overwatch to cover more general patterns with unbounded
holes. Overall, ESPs offer the possibility of developing a new generation of IDE tools and exploring
a rich and exciting set of ideas from a range of research fields from HCI to AI to static analysis.

REFERENCES

J. Andersen and J. L. Lawall. 2008. Generic Patch Inference. In Proceedings of the 2008 23rd IEEE/ACM International Conference
on Automated Software Engineering (ASE ’08). IEEE Computer Society, USA, 337–346. https://doi.org/10.1109/ASE.2008.44
Johannes Bader, Andrew Scott, Michael Pradel, and Satish Chandra. 2019. Getafix: Learning to Fix Bugs Automatically. Proc.

ACM Program. Lang. 3, OOPSLA, Article 159 (Oct. 2019), 27 pages. https://doi.org/10.1145/3360585

R. Bloem, H. N. Gabow, and F. Somenzi. 2006. An algorithm for strongly connected component analysis in n log n symbolic

steps. Formal Methods in System Design 28, 1 (2006), 37–56.

Shaked Brody, Uri Alon, and Eran Yahav. 2020. A structural model for contextual code changes. Proc. ACM Program. Lang. 4,

OOPSLA (2020), 215:1–215:28. https://doi.org/10.1145/3428283

John L. Campbell, Charles Quincy, Jordan Osserman, and Ove K. Pedersen. 2013. Coding In-depth Semistructured Interviews.

Sociological Methods & Research 42, 3 (2013), 294–320. https://doi.org/10.1177/0049124113500475

Nancy Chinchor. 1992. MUC-4 Evaluation Metrics. In Proceedings of the 4th Conference on Message Understanding (McLean,
Virginia) (MUC4 ’92). Association for Computational Linguistics, USA, 22–29. https://doi.org/10.3115/1072064.1072067
William HE Day and Herbert Edelsbrunner. 1984. Efficient algorithms for agglomerative hierarchical clustering methods.

Journal of classification 1, 1 (1984), 7–24.

Reudismam Rolim de Sousa, Gustavo Soares, Rohit Gheyi, Titus Barik, and Loris D’Antoni. 2021. Learning Quick Fixes from
Code Repositories. In SBES ’21: 35th Brazilian Symposium on Software Engineering, Joinville, Santa Catarina, Brazil, 27
September 2021 - 1 October 2021, Cristiano D. Vasconcellos, Karina Girardi Roggia, Vanessa Collere, and Paulo Bousfield
(Eds.). ACM, 74–83. https://doi.org/10.1145/3474624.3474650

S. R. Foster, W. G. Griswold, and S. Lerner. 2012. WitchDoctor: IDE support for real-time auto-completion of refactorings.
In 2012 34th International Conference on Software Engineering (ICSE). 222–232. https://doi.org/10.1109/ICSE.2012.6227191
Xiang Gao, Shraddha Barke, Arjun Radhakrishna, Gustavo Soares, Sumit Gulwani, Alan Leung, Nachiappan Nagappan, and
Ashish Tiwari. 2020. Feedback-Driven Semi-Supervised Synthesis of Program Transformations. 4, OOPSLA, Article 219
(Nov. 2020), 30 pages. https://doi.org/10.1145/3428287

Xi Ge, Quinton L. DuBose, and Emerson Murphy-Hill. 2012. Reconciling Manual and Automatic Refactoring. In Proceedings
of the 34th International Conference on Software Engineering (Zurich, Switzerland) (ICSE ’12). IEEE Press, 211–221.

JetBrains. 2021. ReSharper. (2021). At https://www.jetbrains.com/resharper/.
Ameya Ketkar, Oleg Smirnov, Nikolaos Tsantalis, Danny Dig, and Timofey Bryksin. 2022. Inferring and Applying Type
Changes. In 44th International Conference on Software Engineering (ICSE ’22) (Pittsburgh, United States) (ICSE ’22). ACM.
https://doi.org/10.1145/3510003.3510115

Overwatch: Learning Patterns in Code Edit Sequences

1:25

M. Kim, D. Notkin, D. Grossman, and G. Wilson. 2013. Identifying and Summarizing Systematic Code Changes via Rule

Inference. IEEE Transactions on Software Engineering 39, 1 (2013), 45–62. https://doi.org/10.1109/TSE.2012.16

Maxime Lamothe, Weiyi Shang, and Tse-Hsun Peter Chen. 2020. A3: Assisting Android API Migrations Using Code Examples.

IEEE Transactions on Software Engineering (2020), 1–1. https://doi.org/10.1109/TSE.2020.2988396

Na Meng, Miryung Kim, and Kathryn S. McKinley. 2011. Sydit: creating and applying a program transformation from an
example. In SIGSOFT/FSE’11 19th ACM SIGSOFT Symposium on the Foundations of Software Engineering (FSE-19) and
ESEC’11: 13th European Software Engineering Conference (ESEC-13), Szeged, Hungary, September 5-9, 2011, Tibor Gyimóthy
and Andreas Zeller (Eds.). ACM, 440–443. https://doi.org/10.1145/2025113.2025185

Na Meng, Miryung Kim, and Kathryn S. McKinley. 2013. LASE: Locating and Applying Systematic Edits by Learning from
Examples. In Proceedings of the 2013 International Conference on Software Engineering (San Francisco, CA, USA) (ICSE ’13).
IEEE Press, 502–511.

Ali Mesbah, Andrew Rice, Emily Johnston, Nick Glorioso, and Edward Aftandilian. 2019. DeepDelta: Learning to Repair
Compilation Errors. In Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and
Symposium on the Foundations of Software Engineering (Tallinn, Estonia) (ESEC/FSE 2019). Association for Computing
Machinery, New York, NY, USA, 925–936. https://doi.org/10.1145/3338906.3340455

Microsoft. 2021. Visual Studio. (2021). At https://www.visualstudio.com.
Anders Miltner, Sumit Gulwani, Vu Le, Alan Leung, Arjun Radhakrishna, Gustavo Soares, Ashish Tiwari, and Abhishek
Udupa. 2019. On the Fly Synthesis of Edit Suggestions. Proc. ACM Program. Lang. 3, OOPSLA, Article 143 (Oct. 2019),
29 pages. https://doi.org/10.1145/3360569

Emerson Murphy-Hill, Chris Parnin, and Andrew P. Black. 2009. How We Refactor, and How We Know It. In Proceedings
of the 31st International Conference on Software Engineering (ICSE ’09). IEEE Computer Society, USA, 287–297. https:
//doi.org/10.1109/ICSE.2009.5070529

Stas Negara, Mihai Codoban, Danny Dig, and Ralph E. Johnson. 2014. Mining Fine-Grained Code Changes to Detect Unknown
Change Patterns. In Proceedings of the 36th International Conference on Software Engineering (Hyderabad, India) (ICSE
2014). Association for Computing Machinery, New York, NY, USA, 803–813. https://doi.org/10.1145/2568225.2568317
Stas Negara, Mohsen Vakilian, Nicholas Chen, Ralph E. Johnson, and Danny Dig. 2012. Is It Dangerous to Use Version Control
Histories to Study Source Code Evolution?. In Proceedings of the 26th European Conference on Object-Oriented Programming
(Beijing, China) (ECOOP’12). Springer-Verlag, Berlin, Heidelberg, 79–103. https://doi.org/10.1007/978-3-642-31057-7_5

Gordon D. Plotkin. 1970. A Note on Inductive Generalization. Machine Intelligence 5 (1970), 153–163.
Baishakhi Ray, Christopher Wiley, and Miryung Kim. 2012. REPERTOIRE: A Cross-System Porting Analysis Tool for Forked
Software Projects. In Proceedings of the ACM SIGSOFT 20th International Symposium on the Foundations of Software
Engineering (Cary, North Carolina) (FSE ’12). Association for Computing Machinery, New York, NY, USA, Article 8,
4 pages. https://doi.org/10.1145/2393596.2393603

Reudismam Rolim, Gustavo Soares, Loris D’Antoni, Oleksandr Polozov, Sumit Gulwani, Rohit Gheyi, Ryo Suzuki, and Björn
Hartmann. 2017. Learning syntactic program transformations from examples. In 2017 IEEE/ACM 39th International
Conference on Software Engineering (ICSE). IEEE, 404–415.

J Saldana. 2009. The coding manual for qualitative researchers. https://doi.org/10.1108/QROM-08-2016-1408
Nikolaos Tsantalis, Ameya Ketkar, and Danny Dig. 2020. RefactoringMiner 2.0. IEEE Transactions on Software Engineering

(2020), 21 pages. https://doi.org/10.1109/TSE.2020.3007722

Mohsen Vakilian, Nicholas Chen, Stas Negara, Balaji Ambresh Rajkumar, Brian P. Bailey, and Ralph E. Johnson. 2012.
Use, disuse, and misuse of automated refactorings. In 2012 34th International Conference on Software Engineering (ICSE).
233–243. https://doi.org/10.1109/ICSE.2012.6227190

C. J. van Rijsbergen. 1979. Information Retrieval. Butterworth. 133–134 pages. https://doi.org/10.1002/asi.4630300621

Available at http://www.dcs.gla.ac.uk/Keith/Preface.html.

Shengzhe Xu, Ziqi Dong, and Na Meng. 2019. Meditor: Inference and Application of API Migration Edits. In Proceedings of the
27th International Conference on Program Comprehension (Montreal, Quebec, Canada) (ICPC ’19). IEEE Press, Piscataway,
NJ, USA, 335–346. https://doi.org/10.1109/ICPC.2019.00052

Pengcheng Yin, Graham Neubig, Miltiadis Allamanis, Marc Brockschmidt, and Alexander Gaunt. 2019. Learning to
Represent Edits. In ICLR 2019. https://www.microsoft.com/en-us/research/publication/learning-to-represent-edits/
arXiv:1810.13337 [cs.LG].

