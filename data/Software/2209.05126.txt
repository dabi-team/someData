Extended Technical Report

Robust and Scalable Content-and-Structure Indexing
(Extended Version)

Kevin Wellenzohn ⋅ Michael H. B¨ohlen ⋅ Sven Helmer ⋅ Antoine Pietri ⋅ Stefano
Zacchiroli

2
2
0
2

p
e
S
2
1

]

B
D
.
s
c
[

1
v
6
2
1
5
0
.
9
0
2
2
:
v
i
X
r
a

Abstract Frequent queries on semi-structured hierarchical
data are Content-and-Structure (CAS) queries that ﬁlter data
items based on their location in the hierarchical structure
and their value for some attribute. We propose the Robust
and Scalable Content-and-Structure (RSCAS) index to ef-
ﬁciently answer CAS queries on big semi-structured data.
To get an index that is robust against queries with varying
selectivities we introduce a novel dynamic interleaving that
merges the path and value dimensions of composite keys
in a balanced manner. We store interleaved keys in our trie-
based RSCAS index, which efﬁciently supports a wide range
of CAS queries, including queries with wildcards and de-
scendant axes. We implement RSCAS as a log-structured
merge (LSM) tree to scale it to data-intensive applications
with a high insertion rate. We illustrate RSCAS’s robust-
ness and scalability by indexing data from the Software Her-
itage (SWH) archive, which is the world’s largest, publicly-
available source code archive.

Keywords Indexing ⋅ content and structure ⋅ interleaving ⋅
hierarchical data ⋅ semi-structured data ⋅ XML ⋅ LSM trees

1 Introduction

A lot of the data in business and engineering applications is
semi-structured and inherently hierarchical. Typical exam-
ples are source code archives [2], bills of materials [9], en-
terprise asset hierarchies [14], and enterprise resource plan-
ning applications [15]. A common type of queries on such
data are content-and-structure (CAS) queries [26], contain-

Kevin Wellenzohn E-mail: wellenzohn@iﬁ.uzh.ch ⋅ Michael H. B¨ohlen
E-mail: boehlen@iﬁ.uzh.ch ⋅ Sven Helmer E-mail: helmer@iﬁ.uzh.ch
Department of Informatics, University of Zurich, Zurich, Switzerland

Antoine Pietri E-mail: antoine.pietri@inria.fr
Inria, Paris, France

Stefano Zacchiroli E-mail: stefano.zacchiroli@telecom-paris.fr
LTCI, T´el´ecom Paris, Institut Polytechnique de Paris, Paris, France

ing a value predicate on the content of an attribute and a path
predicate on the location of this attribute in the hierarchical
structure.

CAS indexes are being used to support the efﬁcient pro-
cessing of CAS queries. There are two important properties
that we look for in a CAS index: robustness and scalability.
Robustness means that a CAS index optimizes the average
query runtime over all possible queries. It ensures that an
index can efﬁciently deal with a wide range of CAS queries.
Many existing indexes are not robust since the performance
depends on the individual selectivities of its path and value
predicates. If either the path or value selectivity is high,
these indexes produce large intermediate results even if the
combined selectivity is low. This happens because existing
solutions either build separate indexes for, respectively, con-
tent and structure [26] or prioritize one dimension over the
other (i.e., content over structure or vice versa) [6,11,42].
Scalability means that even for large datasets an index can
be efﬁciently created and updated, and is not constrained
by the size of the available memory. Existing indexes are
often not scalable since they rely on in-memory data struc-
tures that do not scale to large datasets. For instance, with
the memory-based CAS index [43] it is impossible to index
datasets larger than 100 GB on a machine with 400 GB main
memory.

We propose RSCAS, a robust and scalable CAS index.
RSCAS’s robustness is rooted in a well-balanced integration
of the content and structure of the data in a single index. Its
scalability is due to log-structured merge (LSM) trees [33]
that combine an in-memory structure for fast insertions with
a series of read-only disk-based structures for fast sequential
reads and writes.

To achieve robustness we propose to interleave the path
and value bytes of composite keys in a balanced manner. A
well-known technique to interleave composite keys is the z-
order curve [31,34], but applying the z-order curve to paths
and values is subtle. Often the query performance is poor

 
 
 
 
 
 
because of long common preﬁxes, varying key lengths, dif-
ferent domain sizes, and data skew. The paths in a hierarchi-
cal structure have, by their very nature, long common pre-
ﬁxes, but the ﬁrst byte following a longest common preﬁx
separates data items. We call such a byte a discriminative
byte and propose a dynamic interleaving that interleaves the
discriminative bytes of paths and values alternatingly. This
leads to a well-balanced partitioning of the data with a robust
query performance. We use the dynamic interleaving to de-
ﬁne the RSCAS index for semi-structured hierarchical data.
The RSCAS index is trie-based and efﬁciently supports the
basic search methods for CAS queries: range searches and
preﬁx searches. Range searches enable value predicates that
are expressed as a value range and preﬁx searches support
path predicates that contain wildcards and descendant axes.
Crucially, tries in combination with dynamically interleaved
keys allow us to efﬁciently evaluate path and value predi-
cates simultaneously.

To scale the RSCAS index to large datasets and sup-
port efﬁcient insertions, we use LSM trees [33] that com-
bine an in-memory RSCAS trie with a series of disk-resident
RSCAS tries whose size is doubling in each step. RSCAS
currently supports only insertions since our main use case,
indexing an append-only archive, does not require updates
or deletes. The in-memory trie is based on the Adaptive
Radix Tree (ART) [21], which is a memory-optimized trie
structure that supports efﬁcient insertions. Whenever the in-
memory RSCAS trie reaches its maximum capacity, we cre-
ate a new disk-based trie. Since disk-based RSCAS tries are
immutable, we store them compactly on disk and leave no
gaps between nodes. We develop a partitioning-based bulk-
loading algorithm that builds RSCAS on disk while, at the
same time, dynamically interleaving the keys. This algo-
rithm works well with limited memory but scales nicely with
the amount of memory to reduce the disk I/O during bulk-
loading.

Main contributions:
– We develop a dynamic interleaving to interleave paths
and values in an alternating way using the concept of
discriminative bytes. We show how to compute this in-
terleaving by a hierarchical partitioning of the data. We
prove that our dynamic interleaving is robust against vary-
ing selectivities (Section 5).

– We propose the trie-based Robust and Scalable Content-
and-Structure (RSCAS) index for semi-structured hierar-
chical data. Dynamically interleaved keys give RSCAS
its robustness. Its scalability is rooted in LSM trees that
combine a memory-optimized trie for fast in-place inser-
tions with a series of disk-optimized tries (Section 6).
– We propose efﬁcient algorithms for querying, inserting,
bulk-loading, and merging RSCAS tries. A combination
of range and preﬁx searches is used to evaluate CAS

queries on the trie-based structure of RSCAS. Insertions
are performed on the in-memory trie using lazy restruc-
turing. Bulk-loading creates large disk-optimized tries in
the background. Merging is applied when the in-memory
trie overﬂows to combine it with a series of disk-resident
tries (Section 7).

– We conduct an experimental evaluation with three real-
world and one synthetic dataset. One of the real-world
datasets is Software Heritage (SWH) [2], the world’s
largest archive of publicly-available source code. Our
experiments show that RSCAS delivers robust query per-
formance with up to two orders of magnitude improve-
ments over existing approaches, while offering compa-
rable bulk-loading and insertion performance (Section
8).

2 Application Scenario

As a practical use case we deploy a large-scale CAS index
for Software Heritage (SWH) [13], the largest public archive
of software source code and its development history.1

At its core, Software Heritage archives version control
systems (VCSs), storing all recorded source code artifacts
in a giant, globally deduplicated Merkle structure [28] that
stores elements from many different VCSs using crypto-
graphic hashes as keys. VCSs record the evolution of source
code trees over time, an aspect that is reﬂected in the data
model of Software Heritage [35]. The data model supports
the archiving of artifacts, such as ﬁle blobs (byte sequences,
corresponding to tree leaves), source code directories (inner
nodes, pointing to sub-directories and ﬁles, giving them lo-
cal path names), commits (called revisions in this context),
releases (commits annotated with memorable names such as
"1.0"), and VCS repository snapshots. Nodes in the data
model are associated with properties that are relevant for
querying. Examples of node properties are: cryptographic
node identiﬁers, as well as commit and release metadata
such as authors, log messages, timestamps, etc.

Revisions are a key piece of software development work-
ﬂows. Each of them, except the very ﬁrst one in a given
repository, is connected to the previous “parent” revision, or
possibly multiple parents in case of merge commits. These
connections allow the computation of the popular diff rep-
resentations of commits that show how and which ﬁles have
been changed in any given revision. Computing diffs for all
revisions in the archive makes it possible to look up all revi-
sions that have changed ﬁles of interest.

Several aspects make Software Heritage a relevant and
challenging use case for CAS indexing. First, the size of the

1 As of 2021-11-08 the Software Heritage archive contains more
than 11 billion source code ﬁles and 2 billion commits, coming from
more than 160 million public software projects. The archive can be
browsed at: https://archive.softwareheritage.org/.

2

archive is signiﬁcant: at the time of writing, the archive con-
sists of about 20 billion nodes (total ﬁle size is about 1 PiB,
but we will not index within ﬁles, so this measure is less
relevant). Second, the archive grows constantly by contin-
uously crawling public data sources such as collaborative
development platforms (e.g., GitHub, GitLab), Linux distri-
butions (e.g., Debian, NixOS), and package manager repos-
itories (e.g., PyPI, NPM). The archive growth ratio is also
very signiﬁcant: the amount of archived source code arti-
facts grows exponentially over time, doubling every 2 to 3
years [38], which calls for an incremental indexing approach
to avoid indexing lag. For instance, during 2020 alone the
archive has ingested about 600 million new revisions and 3
billion new ﬁle blobs (i.e., ﬁle contents never seen before).
Last but not least, short of the CAS queries proposed in
this paper, the current querying capabilities for the archive
are quite limited. Entire software repositories can be looked
up by full-text search on their URLs, providing entry points
into the archive. From there, users can browse the archive,
reaching the desired revisions (e.g., the most recent revi-
sion in the master branch since the last time a repository
was crawled) and, from there, the corresponding source code
trees. It is not possible to query the “diff”, i.e., ﬁnd revisions
that modiﬁed certain ﬁles in a certain time period, which is
limiting for both user-facing and research-oriented queries
(e.g., in the ﬁeld of empirical software engineering).

With the approach proposed in this paper we offer func-

tionality to answer CAS queries like the following:

Find all revisions from June 2021 that modify a C ﬁle
located in a folder whose name begins with "ext".

This query consists of two predicates. First, a content pred-
icate on the revision time, which is a range predicate that
matches all revisions from the ﬁrst to the last day of June
2021. Second, a structure predicate on the paths of the ﬁles
that were touched by a revision. We are only interested in
revisions that modify ﬁles with .c extension and that are
located in a certain directory. This path predicate can be
expressed as /**/ext*/*.c with wildcard ** to match
folders that are nested arbitrarily deeply in the ﬁlesystem of
a repository and wildcard * to match all characters in a di-
rectory or ﬁle name.

3 Related Work

For related work, two CAS indexing techniques have been
investigated: (a) creating separate indexes for content and
structure, and (b) combining content and structure in one
index. We call these two techniques separate CAS indexing
and combined CAS indexing, respectively.

Separate CAS indexing creates dedicated indexes for, re-
spectively, the content and the structure of the data. Mathis
et al. [26] use a B+ tree to index the content and a struc-
tural summary (i.e., a DataGuide [17]) to index the structure

of the data. The DataGuide maps each unique path to a nu-
meric identiﬁer, called the path class reference (PCR), and
the B+ tree stores the values along with their PCRs. Thus,
the B+ tree stores (value, ⟨nodeId, PCR⟩) tuples in its
leaf nodes, where nodeId points to a node whose content
is value and whose path is given by PCR. To answer a CAS
query we must look at the path index and the value index in-
dependently. The subsequent join on the PCR is slow if in-
termediate results are large. Mathis et al. assume that there
are few unique paths and the path index is small (fewer than
1000 unique paths in their experiments). Kaushik et al. [20]
present an approach that combines a 1-index [29] to evaluate
path predicates with a B+ tree to evaluate value predicates,
but they do not consider updates.

A popular system that implements separate indexing is
Apache Lucene [1], which is a scalable and widely deployed
indexing and search system that underpins Apache Solr and
Elasticsearch. Lucene uses different index types depending
on the type of the indexed attributes. For CAS indexing, we
represent paths as strings and values as numbers. Lucene
indexes strings with ﬁnite state transducers (FSTs), which
are automata that map strings to lists of sorted document
IDs (called postings lists). Numeric attributes are indexed in
a Bkd-tree [36], which is a disk-optimized kd-tree. Lucene
answers conjunctive queries, like CAS queries, by evaluat-
ing each predicate on the appropriate index. The indexes re-
turn sorted postings lists that must be intersected to see if
a document matches all predicates of a conjunctive query.
Since the lists are sorted, the intersection can be performed
efﬁciently. However, the independent evaluation of the pred-
icates may yield large intermediate results, making the ap-
proach non-robust. To scale to large datasets, Lucene imple-
ments techniques that are similar to LSM trees [33] (cf. Sec-
tion 6). Lucene batches insertions in memory before ﬂushing
them as read-only segments to disk. As the number of seg-
ments grows, Lucene continuously compacts them by merg-
ing small segments into a larger segment.

The problem with separate CAS-indexing is that it is not
robust. If at least one predicate of a CAS query is not selec-
tive, separate indexing approaches generate large intermedi-
ate results. This is inefﬁcient if the ﬁnal result is small. Since
the predicates are evaluated on different indexes, we cannot
use the more selective predicate to prune the search space.

Combined CAS indexing integrates paths and values in
one index. A well-known and mature technology are com-
posite indexes, which are used, e.g., in relational databases
to index keys that consist of more than one attribute. Com-
posite indexes concatenate the indexed attributes according
to a speciﬁed ordering. In CAS indexing, there are two pos-
sible orderings of the paths and values: the P V -ordering or-
ders the paths before the values, while the V P -ordering or-
ders the values ﬁrst. The ordering determines what queries a
composite index can evaluate efﬁciently. Composite indexes

3

are only efﬁcient for queries that have a small selectivity for
the attribute appearing ﬁrst. In our experiments we use the
composite B+ tree of Postgres as the reference point for an
efﬁcient and scalable implementation of composite indexes.
IndexFabric [11] is another example of a composite CAS
index. It uses a P V -ordering, concatenating the (shortened)
paths and values of composite keys, and storing them in a
disk-optimized PATRICIA trie [30]. IndexFabric shortens
the paths to save disk space by mapping long node labels
to short strings (e.g., map label ‘extension’ to ‘e’). During
query evaluation IndexFabric must ﬁrst fully evaluate the
path predicate before it can look at the value predicate since
it orders paths before the values in the index. Since it uses
shortened paths, it cannot evaluate wildcards within a node
label (e.g., ext* to match extension, exterior, etc.). Index-
Fabric does not support bulk-loading.

The problem with composite indexes is that they prior-
itize the dimension appearing ﬁrst. The selectivity of the
predicate in the ﬁrst dimension determines the query per-
formance. If it is high and the other selectivity is low, the
composite index performs badly because the ﬁrst predicate
must be fully evaluated before the second predicate can be
evaluated. As a result, a composite index is not robust.

Instead of concatenating dimensions, it is possible to in-
terleave dimensions. The z-order curve [31,34], for exam-
ple, is obtained by interleaving the binary representation of
the individual dimensions and is used in UB-trees [37] and
k-d tries [32,34,39]. Unfortunately, the z-order curve dete-
riorates to the performance of a composite index if the data
contains long common preﬁxes [43]. This is the case in CAS
indexing where paths have long common preﬁxes. The prob-
lem with common preﬁxes is that they are the same for all
data items and do not prune the search space during a search.
Interleaving a common preﬁx in one dimension with a non-
common preﬁx in the other dimension means we prune keys
in one dimension but not the other [25].

LSM trees [33] are used to create scalable indexing sys-
tems with high write throughput (see, e.g., AsterixDB [5],
BigTable [10], Dynamo [12], etc.). They turn expensive in-
place updates that cause many random disk I/Os into out-
of-place updates that use sequential writes. To achieve that,
LSM trees combine a small in-memory tree RM
0 with a se-
ries of disk-resident trees R0, R1, . . ., each tree being T times
larger than the tree in the previous level. Insertions are per-
formed exclusively in the main-memory tree RM
0 .

Modern LSM tree implementations, see [23] for an ex-
cellent recent survey, use sorted string tables (SSTables) or
other immutable data structures at multiple levels. Gener-
ally, there are two different merge policies: leveling and tier-
ing. With the leveling merge policy, each level i contains
exactly one structure and when the structure at level i grows
too big, this structure and the one at level i + 1 are merged.
A structure on level i + 1 is T times larger than a structure

on level i. Tiering maintains multiple structures per level.
When a level i ﬁlls up with T structures, they are merged
into a structure on level i + 1. We discuss the design deci-
sions regarding LSM-trees and RSCAS in Section 6.2.

An LSM tree requires an efﬁcient bulk-loading algo-
rithm to create a disk-based RSCAS trie when the in-memory
trie overﬂows. Sort-based algorithms sort the data and build
an index bottom-up. Buffer-tree methods bulk-load a tree by
buffering insertions in nodes and ﬂushing them in batches
to its children when a buffer overﬂows. Neither sort- nor
buffer-based techniques [7,3,8] can be used for RSCAS be-
cause our dynamic interleaving must look at all keys to cor-
rectly interleave them. We develop a partitioning-based bulk-
loading algorithm for RSCAS that alternatingly partitions
the data in the path and value dimension to dynamically in-
terleave paths and values.

The combination of the dynamic interleaving with wild-
cards and range queries makes it hard to embed RSCAS into
an LSM-tree-based key-value (KV) store. While early, sim-
ple KV-stores did not support range queries at all, more re-
cent KV-stores create Bloom ﬁlters for a predeﬁned set of
ﬁxed preﬁxes [27], i.e., only range queries using these pre-
ﬁxes can be answered efﬁciently. SuRF was one of the ﬁrst
approaches able to handle arbitrary range queries by stor-
ing minimum-length preﬁxes in a trie so that all keys can
be uniquely identiﬁed [45]. This was followed by Rosetta,
which stores all preﬁxes for each key in a hierarchical series
of Bloom ﬁlters [24]. KV-stores supporting ranges queries
without ﬁlters have also been developed. EvenDB optimizes
the evaluation of queries exhibiting spatial locality, i.e., keys
with the same preﬁxes are kept close together and in main
memory [16]. REMIX offers a globally sorted view of all
keys with a logical sorting of the data [46]. The evaluation
of range queries boils down to seeking the ﬁrst matching el-
ement in a sorted sequence of keys and scanning to the end
of the range. CAS queries follow a different pattern. During
query evaluation, we simultaneously process a range query
in the value dimension and match strings with wildcards at
arbitrary positions in the path dimension. The preﬁx shared
by the matching keys ends at the ﬁrst wildcard, which can
occur early in the path. We prune queries with wildcards by
regularly switching back to the more selective value dimen-
sion.

4 Background

4.1 Data Representation

We use composite keys to represent the paths and values of
data items in semi-structured hierarchical data.

Deﬁnition 1 (Composite Key) A composite key k is a two-
dimensional key that consists of a path k.P and a value k.V ,

4

Table 1: A set K1..9

k1
k2
k3
k4
k5
k6
k7
k8
k9

Path Dimension P

/Sources/Map.go$
/crypto/ecc.h$
/crypto/ecc.c$
/Sources/Schema.go$
/fs/ext3/inode.c$
/fs/ext4/inode.h$
/fs/ext4/inode.c$
/Sources/Schedule.go$
/Sources/Scheduler.go$

1

5

9

13

17

21

= {k1, . . . , k9} of composite keys
Value Dimension V (64 bit unsigned integer)
2019-10-17 17:17:46 (00 00 00 00 5D A8 94 2A)
2020-11-24 22:48:36 (00 00 00 00 5F BD 8D C4)
2020-11-24 22:48:36 (00 00 00 00 5F BD 8D C4)
2019-10-17 17:19:24 (00 00 00 00 5D A8 94 8C)
2020-06-24 01:20:41 (00 00 00 00 5E F2 9C 59)
2020-05-14 11:56:02 (00 00 00 00 5E BD 23 C2)
2020-11-24 17:05:30 (00 00 00 00 5F BD 3D 5A)
2019-10-17 17:32:11 (00 00 00 00 5D A8 97 8B)
2019-10-17 17:32:11 (00 00 00 00 5D A8 97 8B)
1 2 3 4 5 6 7 8

Revision R (SHA1 hash)
r1 (A1 A6 06 B0 B3 . . .)
r2 (D4 47 39 D8 F8 . . .)
r2 (D4 47 39 D8 F8 . . .)
r3 (41 D1 7A 7B 4D . . .)
r4 (96 98 D9 F5 06 . . .)
r5 (FF CA AE 8F 57 . . .)
r6 (68 8D 97 3C BE . . .)
r7 (99 07 EE 0A 7B . . .)
r7 (99 07 EE 0A 7B . . .)

and each key stores a reference k.R as payload that points
to the corresponding data item in the database.

D, i.e.,

lcp(K, D) = s iff

Given a dimension D ∈ {P, V } we write k.D to access
k’s path (if D = P ) or value (if D = V ). Composite keys can
be extracted from popular semi-structured hierarchical data
formats, such as JSON and XML. In the context of SWH we
use composite keys k to represent that a ﬁle with path k.P
is modiﬁed (i.e., added, changed, or deleted) at time k.V in
revision k.R.

Example 1 Table 1 shows the set K1..9
= {k1, . . . , k9} of
composite keys (we use a sans-serif font to refer to con-
crete instances in our examples). We write K2,5,6,7 to refer
to {k2, k5, k6, k7}. Composite key k2 denotes that the ﬁle
/crypto/ecc.h$ was modiﬁed on 2019-07-20 in revi-
sion r2. In the same revision, also ﬁle /crypto/ecc.c$
is modiﬁed, see key k3.
◻

We represent paths and values as byte strings that we
access byte-wise. We visualize them with one byte ASCII
characters for the path dimension and italic hexadecimal num-
bers for the value dimension, see Table 1. To guarantee that
no path is a preﬁx of another we append the end-of-string
character $ (ASCII code 0x00) to each path. Fixed-length
byte strings (e.g., 64 bit numbers) are preﬁx-free because
of the ﬁxed length. We assume that the path and value di-
mensions are binary-comparable, i.e., two paths or values
are <, =, or > iff their corresponding byte strings are <, =,
or >, respectively [21]. For example, big-endian integers are
binary-comparable while little-endian integers are not.

Let s be a byte-string, then ∣s∣ denotes the length of s
and s[i] denotes the i-th byte in s. The left-most byte of a
byte-string is byte one. s[i] = ǫ is the empty string if i > ∣s∣.
s[i, j] denotes the substring of s from position i to j and
s[i, j] = ǫ if i > j.

Deﬁnition 2 (Longest Common Preﬁx) The longest com-
mon preﬁx lcp(K, D) of a set of keys K in dimension D is
the longest preﬁx s that all keys k ∈ K share in dimension

5

∀k ∈ K(k.D[1, ∣s∣] = s) ∧
∄l(l > ∣s∣ ∧ ∀k, k′

∈ K(

l ≤ min(∣k.D∣, ∣k′.D∣) ∧ k.D[1, l] = k′.D[1, l]))

Example 2 The longest common preﬁx in the path and value
K1..9, P ) =
dimensions of the nine keys in Table 1 is lcp(
00 00 00 00. If we narrow down
/ and lcp(
the set of keys to K5,6 the longest common preﬁxes be-
K5,6, V ) =
come longer: lcp(
00 00 00 00 5E.
◻

K5,6, P ) = /fs/ext and lcp(

K1..9, V ) =

4.2 Content-and-Structure (CAS) Queries

Content-and-structure (CAS) queries contain a path predi-
cate and value predicate [26]. The path predicate is expressed
as a query path q that supports two wildcard symbols. The
descendant axis ** matches zero to any number of node la-
bels, while the * wildcard matches zero to any number of
characters in a single label.

Deﬁnition 3 (Query Path) A query path q is denoted by q =
+,
/λ1/λ2/. . ./λm. Each label λi is a string λi ∈ (A ∪ {*})
where A is an alphabet and * is a reserved wildcard symbol.
The wildcard * matches zero to any number of characters in
a label. We call λi = ** the descendant axis that matches
zero to any number of labels.

Deﬁnition 4 (CAS Query) CAS query Q(q, [vl, vh]) con-
sists of a query path q and a value predicate [vl, vh]. Given a
set K of composite keys, CAS query Q returns the revisions
k.R of all composite keys k ∈ K for which k.P matches q
and vl ≤ k.V ≤ vh.

Example 3 CAS query Q(/**/ext*/*.c, [2021-06-01,
2021-06-30]) matches all revisions (a) committed in June
2021 that (b) modiﬁed a C ﬁle located in a folder that be-
gins with name ext, anywhere in the directory structure of
a software repository.
◻

4.3 Interleaving of Composite Keys

We integrate path k.P and value k.V of a key k by interleav-
ing them. Table 2 shows three common ways to integrate
k.P and k.V of key k9 from Table 1. Value bytes are writ-
ten in italic and shown in red, path bytes are shown in blue.
The ﬁrst two rows show the path-value and value-path con-
catenation (IP V and IV P ), respectively. The byte-wise inter-
leaving IBW in the third row interleaves one value byte with
one path byte. Note that none of these interleavings is well-
balanced. The byte-wise interleaving is not well-balanced,
since all value-bytes are interleaved with a single label of
the path (/Sources).

Table 3: Illustration of the discriminative bytes for K1..9
from Table 1 and various subsets of it.

Composite Keys K dsc(K, P )
K1..9
K1,4,8,9
K4,8,9
K8,9
K9

2
10
14
18
23

dsc(K, V )
5
7
7
9
9

discriminative byte partitions a set of keys into subsets, which
we recursively partition further.

5.1 ψ-Partitioning

Table 2: Key k9 is interleaved using different approaches.

Interleaving of Key

Approach
IP V (k9) = /Sources/Scheduler.go$ 00 00 00 00 5D A8 97 8B
IV P (k9) = 00 00 00 00 5D A8 97 8B /Sources/Scheduler.go$
IBW (k9) = 00 / 00 S 00 o 00 u 5D r A8 c 97 e 8B s /Scheduler.go$

The ψ-partitioning of a set of keys K groups composite keys
together that have the same value at the discriminative byte
in dimension D. Thus, K is split into at most 28 non-empty
partitions, one partition for each value (0x00 to 0xFF) of
the discriminative byte in dimension D.

5 Theoretical Foundation – Dynamic Interleaving

We propose the dynamic interleaving to interleave the paths
and values of a set of composite keys K, and show how to
build the dynamic interleaving through a recursive partition-
ing that groups keys based on the shortest preﬁxes that dis-
tinguish keys from one another. We introduce the partition-
ing in Section 5.1 and highlight in Section 5.2 the properties
that we use to construct the interleaving. In Section 5.3 we
deﬁne the dynamic interleaving with a recursive partition-
ing and develop a cost model in Section 5.4 to analyze the
efﬁciency of interleavings.

The dynamic interleaving adapts to the speciﬁc charac-
teristics of paths and values, such as common preﬁxes, vary-
ing key lengths, differing domain sizes, and the skew of the
data. To achieve this we consider the discriminative bytes.

Deﬁnition 5 (Discriminative Byte) The discriminative byte
dsc(K, D) of keys K in dimension D is the ﬁrst byte for
which the keys differ in dimension D, i.e., dsc(K, D) =
∣lcp(K, D)∣ + 1.
Example 4 Table 3 illustrates the position of the discrimina-
tive bytes for the path and value dimensions for various sets
of composite keys K. Set K9
k9} contains only a single
key. In this case, the discriminative bytes are the ﬁrst posi-
tion after the end of k9’s byte-strings in the respective di-
mensions. For example, k9’s value is eight bytes long, hence
the discriminative value byte of {
◻

k9} is the ninth byte.

= {

Discriminative bytes are crucial during query evaluation
since at their positions the search space can be narrowed
down. We alternate in a round-robin fashion between dis-
criminative path and value bytes in our interleaving. Each

6

Deﬁnition 6 (ψ-Partitioning) The ψ-partitioning of a set
of keys K in dimension D is ψ(K, D) = {K1, . . . , Km} iff

1. (Correctness) All keys in a set Ki have the same value

at K’s discriminative byte in dimension D:
– ∀k, k′

∈ Ki (k.D[dsc(K, D)] = k′.D[dsc(K, D)])

2. (Disjointness) Keys from different sets Ki ≠ Kj do not
have the same value at K’s discriminative byte in D:
– ∀k ∈ Ki, k′

∈ Kj(

k.D[dsc(K, D)] ≠ k′.D[dsc(K, D)])

3. (Completeness) Every key in K is assigned to a set Ki.

All Ki are non-empty.
– K = ⋃1≤i≤m Ki ∧ ∅ ∉ ψ(K, D)

Let k ∈ K be a composite key. We write ψk(K, D) to
denote the ψ-partitioning of k with respect to K and dimen-
sion D, i.e., the partition in ψ(K, D) that contains key k.
Example 5 Let K1..9 be the set of composite keys from Ta-
ble 1. The ψ-partitioning of selected sets of keys in dimen-
sion P or V is as follows:

}

}

K4, K8,9

K1, K4,8,9

K1,4,8,9, K5,6, K2,3,7

K1..9, V ) = {
K1,4,8,9, P ) = {
K4,8,9, V ) = {
K8,9, P ) = {
K9, V ) = ψ(

– ψ(
– ψ(
– ψ(
– ψ(
– ψ(
The ψ-partitioning of key k9 with respect to sets of keys and
dimensions is as follows:

K8, K9
}
K9, P ) = {

K9

}

}

K1,4,8,9
K4,8,9

– ψk9 (
– ψk9 (
– ψk9 (
– ψk9 (

K1..9, V ) =
K1,4,8,9, P ) =
K4,8,9, V ) =
K9, V ) = ψk9 (

K8,9
K9, P ) =

K9.

◻

5.2 Properties of the ψ-Partitioning

We work out four key properties of the ψ-partitioning. The
ﬁrst two properties, order-preserving and preﬁx-preserving,
allow us to evaluate CAS queries efﬁciently while the other
two properties, guaranteed progress and monotonicity, help
us to construct the dynamic interleaving.

Lemma 1 (Order-Preserving) ψ-partitioning ψ(K, D) =
{K1, . . . , Km} is order-preserving in dimension D, i.e., all
keys in set Ki are either strictly greater or smaller in dimen-
sion D than all keys from another set Kj:
∀1 ≤ i, j ≤ m, i ≠ j ∶ (∀k ∈ Ki, ∀k′
(∀k ∈ Ki, ∀k′

∈ Kj ∶ k.D < k′.D) ∨
∈ Kj ∶ k.D > k′.D)

All proofs can be found in Appendix A.

K1..9, V ) is equal to the
Example 6 The ψ-partitioning ψ(
partitions {
}. It is order-preserving in
dimension V . The partitions cover the following value ranges
(denoted in seconds since the Unix epoch):

K1,4,8,9, K5,6, K2,3,7

– [0x5D 00 00 00, 0x5D FF FF FF]; approx. 06/2019 – 12/2019
– [0x5E 00 00 00, 0x5E FF FF FF]; approx. 01/2020 – 07/2020
– [0x5F 00 00 00, 0x5F FF FF FF]; approx. 08/2020 – 12/2021

The value predicate [07/2019, 09/2019) only needs to con-
sider partition K1,4,8,9, which spans keys from June to De-
cember, 2019, since partitions do not overlap.
◻

Lemma 2 (Preﬁx-Preserving) ψ-partitioning ψ(K, D) =
{K1, . . . , Km} is preﬁx-preserving in dimension D, i.e., keys
in the same set Ki have a longer common preﬁx in dimen-
sion D than keys from different sets Ki ≠ Kj:
∀1 ≤ i, j ≤ m, i ≠ j ∶ ∣lcp(Ki, D)∣ > ∣lcp(Ki ∪ Kj, D)∣ ∧

∣lcp(K, D)∣ = ∣lcp(Ki ∪ Kj, D)∣

K1..9, P ) = {

K1,4,8,9, K2,3,
Example 7 The ψ-partitioning ψ(
K5,6,7
} is preﬁx-preserving in dimension P . For example,
K1,4,8,9, P ) =
K1,4,8,9 has a longer common path preﬁx lcp(
K1,4,8,9 ∪
/Source/ than keys across partitions, e.g., lcp(
K2,3, P ) = /. Query path /Source/S*.go only needs to
consider partition K1,4,8,9.
◻

Lemmas 1 and 2 guarantee a total ordering among the
sets ψ(K, D) = {K1, . . . , Km}. In our RSCAS index we
order the nodes by the value at the discriminative byte such
that range and preﬁx queries can quickly choose the correct
subtree.

The next two properties allow us to efﬁciently compute

the dynamic interleaving of composite keys.

Lemma 3 (Guaranteed Progress) Let K be a set of com-
posite keys for which not all keys are equal in dimension D.
ψ(K, D) guarantees progress, i.e., ψ splits K into at least
two sets: ∣ψ(K, D)∣ ≥ 2.

Guaranteed progress ensures that each step partitions the
data and when we repeatedly apply ψ(K, D), we eventually
narrow a set of keys down to a single key. For each set of
keys that ψ(K, D) creates, the position of the discrimina-
tive byte for dimension D increases. This property of the
ψ-partitioning holds since each set of keys is built based on
the discriminative byte and to ψ-partition an existing set of
keys we need a discriminative byte that is positioned further
down in the byte-string. For the alternate dimension D, i.e.,
D = P if D = V and D = V if D = P , the position of the
discriminative byte remains unchanged or increases.

Lemma 4 (Monotonicity of Discriminative Bytes) Let Ki
be one of the partitions of K after partitioning in dimension
D. In dimension D, the position of the discriminative byte
in Ki is strictly greater than in K. In dimension D, the dis-
criminative byte is equal or greater than in K, i.e.,

Ki ∈ ψ(K, D) ∧ Ki ⊂ K ⇒

dsc(Ki, D) > dsc(K, D) ∧ dsc(Ki, D) ≥ dsc(K, D)

Example 8 The discriminative path byte of K1..9 is 2 while
the discriminative value byte of K1..9 is 5 as shown in Ta-
ble 3. For partition K1,4,8,9, which is obtained by partition-
ing K1..9 in the value dimension, the discriminative path
byte is 10 while the discriminative value byte is 7. For parti-
tion K4,8,9, which is obtained by partitioning K1,4,8,9 in the
path dimension, the discriminative path byte is 14 while the
discriminative value byte is still 7.
◻

Monotonicity guarantees that each time we ψ-partition a
set K we advance the discriminative byte in at least one di-
mension. Thus, we make progress in at least one dimension
when we dynamically interleave a set of keys.

These four properties of the ψ-partitioning are true be-
cause we partition K at its discriminative byte. If we parti-
tioned the data before this byte, we would not make progress
and the monotonicity would be violated, because every byte
before the discriminative byte is part of the longest com-
mon preﬁx. If we partitioned the data after the discrimi-
native byte, the partitioning would no longer be order- and
preﬁx-preserving. Skipping some keys by sampling the set
is not an option, as this could lead to an (incorrect) parti-
tioning using a byte located after the actual discriminative
byte.

Example 9 K1..9’s discriminative value byte is byte ﬁve. If
K1..9
we partitioned K1..9 at value byte four we would get {
}
and there is no progress since all keys have 0x00 at value
byte four. The discriminative path and value bytes would
remain unchanged. If we partitioned K1..9 at value byte six
K1,4,8,9, K2,3,6,7, K5
}, which is neither order-
we would get {
nor preﬁx-preserving in V . Consider keys k3, k6 ∈
K2,3,6,7
K5. The partitioning is not order-preserving in V
and k5 ∈

7

ρ(k, K, D) =

⎧⎪⎪⎪⎪
⎪⎪⎪⎪⎩

⎨

(K, D) ○ ρ(k, ψk(K, D), D)
ρ(k, K, D)
(K, –)

if ∣K∣ > τ ∧ ψk(K, D) ⊂ K
if ∣K∣ > τ ∧ ψk(K, D) = K ∧ ψk(K, D) ⊂ K
otherwise

Fig. 1: Deﬁnition of partitioning sequence ρ(k, K, D) for a threshold τ ≥ 1. Operator ○ denotes concatenation, e.g., a ○ b =
(a, b) and a ○ (b, c) = (a, b, c).

k5.V <

k3.V . The partitioning is not preﬁx-
since k6.V <
preserving in V since the longest common value preﬁx in
K2,3,6,7 is 00 00 00 00, which is not longer than the longest
common value preﬁx of keys from different partitions since
00 00 00 00.
◻
lcp(

K2,3,6,7 ∪ K5, V ) =

5.3 Dynamic Interleaving

To compute the dynamic interleaving of a composite key
k ∈ K we recursively ψ-partition K while alternating be-
tween dimension V and P . In each step, we interleave a
part of k.P with a part of k.V . The recursive ψ-partitioning
yields a partitioning sequence (K1, D1), . . . , (Kn, Dn) for
key k with K1 ⊃ K2 ⊃ ⋅ ⋅ ⋅ ⊃ Kn. We start with K1 = K
and D1 = V . Next, K2 = ψk(K1, V ) and D2 = D1 = P .
We continue with the general scheme Ki+1 = ψk(Ki, Di)
and Di+1 = Di. This continues until we reach a set Kn that
contains at most τ keys, where τ is a threshold (explained
later). The recursive ψ-partitioning alternates between di-
mensions V and P until we run out of discriminative bytes
in one dimension, which means ψk(Ki, D) = Ki. From then
on, we can only ψ-partition in dimension D until we run
out of discriminative bytes in this dimension as well, that is
ψk(Ki, D) = ψk(Ki, D) = Ki, or we reach a Kn that con-
tains at most τ keys. The partitioning sequence is ﬁnite due
to the monotonicity of the ψ-partitioning (see Lemma 4),
which guarantees that we make progress in each step in at
least one dimension.

Deﬁnition 7 (Partitioning Sequence) The partitioning se-
quence ρ(k, K, D) = ((K1, D1), . . . , (Kn, Dn)) of a com-
posite key k ∈ K is the recursive ψ-partitioning of the sets to
which k belongs. The pair (Ki, Di) denotes the partitioning
of Ki in dimension Di. The partitioning stops when Kn con-
tains at most τ keys or Kn cannot be further ψ-partitioned
in any dimension (Kn.D = – in this case). ρ(k, K, D) is
deﬁned in Figure 1.

Example 10 Below we illustrate the step-by-step expansion
k9, K1..9, V ) to get k9’s partitioning sequence. We set
of ρ(

8

τ = 2.
ρ(

k9, K1..9, V )
= (

K1..9, V ) ○ ρ(
K1..9, V ) ○ (
K1..9, V ) ○ (
K1..9, V ) ○ (

k9, K1,4,8,9, P )
K1,4,8,9, P ) ○ ρ(
K1,4,8,9, P ) ○ (
K1,4,8,9, P ) ○ (

= (

= (

= (

k9, K4,8,9, V )
K4,8,9, V ) ○ ρ(
K4,8,9, V ) ○ (

k9, K8,9, P )
K8,9, –)

Note the alternating partitioning in, respectively, V and P .
We only deviate from this if partitioning in one of the di-
mensions is not possible. Had we set τ = 1, K8,9 would be
partitioned once more in the path dimension.
◻

To compute the full dynamic interleaving of a key k we
set τ = 1 and continue until the ﬁnal set Kn contains a single
key (i.e, key k). To interleave only a preﬁx of k and keep a
sufﬁx non-interleaved we increase τ . Increasing τ stops the
partitioning earlier and speeds up the computation. An index
structure that uses dynamic interleaving can tune τ to trade
the time it takes to build the index and to query it. In Section
6 we introduce a memory-optimized and a disk-optimized
version of our RSCAS index. They use different values of τ
to adapt to the underlying storage.

We determine the dynamic interleaving IDY(k, K) of a
key k ∈ K via k’s partitioning sequence ρ. For each ele-
ment in ρ, we generate a tuple with strings sP and sV and
the partitioning dimension of the element. The strings sP
and sV are composed of substrings of k.P and k.V , ranging
from the previous discriminative byte up to, but excluding,
the current discriminative byte in the respective dimension.
The order of sP and sV in a tuple depends on the dimension
used in the previous step: the dimension that has been cho-
sen for the partitioning comes ﬁrst. Formally, this is deﬁned
as follows:

Deﬁnition 8 (Dynamic Interleaving) Let k ∈ K be a com-
posite key and let ρ(k, K, V ) = ((K1, D1), . . . , (Kn, Dn))
be the partitioning sequence of k. The dynamic interleaving
IDY(k, K) = (t1, . . . , tn, tn+1) of k is a sequence of tuples
ti, where ti = (sP , sV , D) if Di−1 = P and ti = (sV , sP , D)
if Di−1 = V . The tuples ti, 1 ≤ i ≤ n, are determined as
follows:

ti.sP = k.P [dsc(Ki−1, P ), dsc(Ki, P ) − 1]
ti.sV = k.V [dsc(Ki−1, V ), dsc(Ki, V ) − 1]
ti.D = Di

To correctly handle the ﬁrst tuple we deﬁne dsc(K0, V ) =
1, dsc(K0, P ) = 1 and D0 = V . The last tuple tn+1 =
(sP , sV , R) stores the non-interleaved sufﬁxes along with
revision k.R:
tn+1.sP = k.P [dsc(Kn, P ), ∣k.P ∣]
tn+1.sV = k.V [dsc(Kn, V ), ∣k.P ∣]
tn+1.R = k.R

◻

φ1 = V

φ2 = P

φ3 = V

φh = P

ςV = 2/3

ςP = 1/3

. . . . . . . . .

fanout o

) = (

k9, K1..9

Example 11 We compute the tuples for the dynamic inter-
t1, . . . , t5) of key k9 using the
leaving IDY(
k9, K1..9, V ) from Example 10. The
partitioning sequence ρ(
necessary discriminative path and value bytes can be found
in Table 3. Table 4 shows the details of each tuple of k9’s dy-
namic interleaving with respect to K1..9. The ﬁnal dynamic
interleavings of all keys from Table 1 are displayed in Ta-
ble 5. We highlight in bold the values of the discriminative
bytes at which the paths and values are interleaved, e.g., for
key k9 these are bytes 5D, S, and 97.
◻

Fig. 2: The search structure in our cost model is a complete
tree of height h and fanout o.

search follows a fraction of the outgoing branches o origi-
nating at this node. We call this the selectivity of a node (or
just selectivity). We assume that every path node has a se-
lectivity of ςP and every value node has a selectivity of ςV .
The cost ̂C of a search, measured in the number of visited
nodes during the search, is as follows:

Table 4: Computing IDY(

k9, K1..9

).

̂C(o, h, φ, ςP , ςV ) = 1 +

h

l

(o ⋅ ςφi )

∏
i=1

∑
l=1

t
t1
t2
t3
t4
t5

sV
= 00 00 00 00 k9.P
k9.P
= 5D A8
k9.P
= ǫ
k9.P
= 97 8B
k9.P
= ǫ

k9.V
k9.V
k9.V
k9.V
k9.V

1, 4
]
[
5, 6
]
[
7, 6
]
[
7, 8
]
[
9, 8
]
[

D
sP
= /
V
= Sources/ P
V
–

= Sche
= dule
= r.go$

1, 1
]
[
2, 9
[
]
10, 13
]
[
14, 17
]
[
18, 22
]
[

Unlike static interleavings I(k) that interleave a key k in
isolation, the dynamic interleaving IDY(k, K) of k depends
on the set of all keys K to adapt to the data. The result is a
well-balanced interleaving (compare Tables 2 and 5).

In Section 7 we propose efﬁcient algorithms to dynami-
cally interleave composite keys and analyze them for differ-
ent key distributions.

5.4 Efﬁciency of Interleavings

We propose a cost model to measure the efﬁciency of in-
terleavings that organize the interleaved keys in a tree-like
search structure. Each node represents the ψ-partitioning of
the composite keys by either path or value, and the node
branches for each different value of a discriminative path or
value byte. We simplify the cost model by assuming that the
search structure is a complete tree with fanout o where every
root-to-leaf path contains h edges (h is the height). Further,
we assume that all nodes on one level represent a partition-
ing in the same dimension φi ∈ {P, V } and we use a vector
φ(φ1, . . . , φh) to specify the partitioning dimension on each
level. We assume that the number of P s and V s in each φ
are equal. Figure 2 visualizes this scheme.

To answer a query we start at the root and traverse the
search structure to determine the answer set. In the case of
range queries, more than one branch must be followed. A

9

If a workload is well-known and consists of a small set
of speciﬁc queries, it is highly likely that an index adapted
to this workload will outperform RSCAS. For instance, if
ςV ≪ ςP for all queries, then a VP-index shows better per-
formance than an RSCAS-index. However, it performs badly
for queries deviating from that workload (ςV > ςP ). Our
goal is an access method that can deal with a wide range
of queries in a dynamic environment in a robust way, i.e.,
avoiding a bad performance for any particular query type.
This is motivated by the fact that modern data analytics uti-
lizes a large number of ad-hoc queries to do exploratory
analysis. For example, in the context of building a robust
partitioning for ad-hoc query workloads, Shanbhag et al. [41]
found that after analyzing the ﬁrst 80% of a real-world work-
load the remaining 20% still contained 57% completely new
queries. We aim for a good average performance across all
queries.

Deﬁnition 9 (Robustness) A CAS-index is robust if it opti-
mizes the average performance and minimizes the variabil-
ity over all queries.

State-of-the-art CAS-indexes are not robust because they
favor either path or value predicates. As a result they show
a very good performance for one type of query but run into
problems for other types of queries. To illustrate this prob-
lem we deﬁne the notion of complementary queries.

Deﬁnition 10 (Complementary Query) Given a query Q =
(ςP , ςV ) with path selectivity ςP and value selectivity ςV ,
there is a complementary query Q′
V ) with path se-
lectivity ς ′

= (ς ′
P = ςV and value selectivity ς ′

P , ς ′
V = ςP

Table 5: The dynamic interleaving of the composite keys in K1..9. The values at the discriminative bytes are written in bold.

k
k1
k4
k8
k9
k5
k6
k2
k3
k7

Dynamic Interleaving IDY(k, K1..9

)

00 00 00 00, /, V ), (
00 00 00 00, /, V ), (
00 00 00 00, /, V ), (
00 00 00 00, /, V ), (
00 00 00 00, /, V ), (
00 00 00 00, /, V ), (
00 00 00 00, /, V ), (
00 00 00 00, /, V ), (
00 00 00 00, /, V ), (

5D A8, Sources/, P ), (Map.go$, 94 2A, –), (ǫ, ǫ, r1))
5D A8, Sources/, P ), (Sche, ǫ, V ), (
5D A8, Sources/, P ), (Sche, ǫ, V ), (
5D A8, Sources/, P ), (Sche, ǫ, V ), (
5E, fs/ext, –), (3/inode.c$, F2 9C 59, r4))
5E, fs/ext, –), (4/inode.h$, BD 23 C2, r5))
5F BD, ǫ, P ), (crypto/ecc., 8D C4, –), (h$, ǫ, r2))
5F BD, ǫ, P ), (crypto/ecc., 8D C4, –), (c$, ǫ, r2))
5F BD, ǫ, P ), (fs/ext4/inode.c$, 3D 5A, –), (ǫ, ǫ, r6))

((
((
((
((
((
((
((
((
((

94 8C, ma.go$, –)), (ǫ, ǫ, r3))
97 8B, dule, –), (.go$, ǫ, r7))
97 8B, dule, –), (r.go$, ǫ, r7))

Example 12 Figure 3a shows the costs for a query Q and its
complementary query Q′ for different interleavings in terms
of the number of visited nodes during the search. We assume
parameters o = 10 and h = 12 for the search structure and
a dynamic interleaving IDY with τ = 1. IPV stands for path-
value concatenation with φi = P for 1 ≤ i ≤ 6 and φi = V for
7 ≤ i ≤ 12. IVP is a value-path concatenation (with an inverse
φ compared to IPV). We also consider two additional permu-
tations: I1 uses a vector φ = (V, V, V, V, P, V, P, V, P, P, P, P )
and I2 a vector equal to (V, V, V, P, P, V, P, V, V, P, P, P ).
They resemble byte-wise interleavings, which usually ex-
hibit irregular alternation patterns with a clustering of, re-
spectively, discriminative path and value bytes. Figure 3b
shows the average costs and the standard deviation. The num-
bers demonstrate the robustness of our dynamic interleav-
ing: it performs best in terms of average costs and standard
deviation.

Dynamic Interleaving IDY

IPV

IVP

I1

I2

]
s
e
d
o
n

3

0
1
[

t
s
o
C

100

50

0

ςV =0.1
ςP =0.5

ς ′
V =0.5
ς ′
P =0.1

Avg.

Std. Dev.

Theorem 1 shows that the dynamic interleaving has the
best query performance for complementary queries. It fol-
lows that for any set of complementary queries Q, the dy-
namic interleaving has the best performance.

Theorem 2 Let Q be a set of complementary queries, i.e.,
(ςP , ςV ) ∈ Q ⇔ (ςV , ςP ) ∈ Q. There is no interleaving φ
that in total performs better than the dynamic interleaving
over all queries Q, i.e.,

∀φ ∶ ∑

(ςP ,ςV )∈Q

̂C(o, h, φDY, ςP , ςV )

≤ ∑

(ςP ,ςV )∈Q

̂C(o, h, φ, ςP , ςV )

This also holds for the set of all queries, since for ev-
ery query there exists a complementary query. Thus, the dy-
namic interleaving optimizes the average performance over
all queries and, as a result, a CAS index that uses dynamic
interleaving is robust.

Corollary 1 Let Q = {(ςP , ςV ) ∣ 0 ≤ ςP , ςV ≤ 1} be the
set of all possible queries. There is no interleaving φ that
in total performs better than the dynamic interleaving φDY
over all queries Q.

We now turn to the variability of the search costs and

(a) Complementary Queries

(b) Robustness

show that they are minimal for dynamic interleavings.

Fig. 3: Robustness of dynamic interleaving.

In the previous example we used our cost model to show
that a perfectly alternating interleaving exhibits the best over-
all performance and standard deviation when evaluating com-
plementary queries. We prove that this is always the case.

P = ςV and ς ′

Theorem 3 Given a query Q (with ςP and ςV ) and its com-
plementary query Q′ (with ς ′
V = ςP ), there is
no interleaving that has a smaller variability than the dy-
namic interleaving with a perfectly alternating vector φDY,
i.e., ∀φ ∶ ∣ ̂C(o, h, φDY, ςP , ςV ) − ̂C(o, h, φDY, ς ′
∣ ̂C(o, h, φ, ςP , ςV ) − ̂C(o, h, φ, ς ′

P , ς ′

P , ς ′

V )∣.

V )∣ ≤

Theorem 1 Consider a query Q with selectivities ςP and
ςV and its complementary query Q′ with selectivities ς ′
P =
ςV and ς ′
V = ςP . There is no interleaving that on average
performs better than the dynamic interleaving with a per-
fectly alternating vector φDY, i.e., ∀φ ∶ ̂C(o, h, φDY, ςP , ςV )+
̂C(o, h, φDY, ς ′
V ).

V ) ≤ ̂C(o, h, φ, ςP , ςV )+ ̂C(o, h, φ, ς ′

P , ς ′

P , ς ′

Similar to the results for the average performance, The-

orem 3 can be generalized to the set of all queries.

Note that in practice the search structure is not a com-
plete tree and the fraction ςP and ςV of children that are tra-
versed at each node is not constant. We previously evaluated
the cost model experimentally on real-world datasets [43]

10

n2 (28 bytes)
(5D A8,Sources/,P )

n1 (30 bytes)
(00 00 00 00,/,V )

n7 (81 bytes)
(5E,fs/ext,–)
3/inode.c$, F2 9C 59, r4
{(
4/inode.h$, BD 23 C2, r5
(

,
)
)}

n4 (22 bytes)
(Sche,ǫ,V )

n3 (35 bytes)
(Map.go$,94 2A,–)
ǫ, ǫ, r1

{(

)}

n8 (20 bytes)
(5F BD,ǫ,P )

n9 (64 bytes)
(cypto/ecc.,8D C4,–)
,
)

c$, ǫ, r2
(

h$, ǫ, r2

)}

{(

n10 (44 bytes)
(fs/ext4/inode.c$,3D 5A,–)
ǫ, ǫ, r6

{(

)}

n5(34 bytes)
(94 8C,ma.go$,–)
ǫ, ǫ, r3

{(

)}

n6 (63 bytes)
(97 8B,dule,–)
,
)

r.go$, ǫ, r7
(

.go$, ǫ, r7

{(

)}
Fig. 4: The RSCAS trie for the composite keys K1..9.

and showed that the estimated and true cost of a query are
off by a factor of two on average, which is a good estimate
for the cost of a query.

6 Robust and Scalable CAS (RSCAS) Index

Data-intensive applications require indexing techniques that
make it possible to efﬁciently index, insert, and query large
amounts of data. The SWH archive, for example, stores bil-
lions of revisions and every day millions of revisions are
crawled from popular software forges. We propose the Ro-
bust and Scalable Content-And-Structure (RSCAS) index
to provide support for querying and updating the content
and structure of big hierarchical data. For robustness, the
RSCAS index uses our dynamic interleaving to integrate the
paths and values of composite keys in a trie structure. For
scalability, RSCAS implements log-structured merge trees
(LSM trees) that combine a memory-optimized trie with a
series of disk-optimized tries (see Figure 5).

6.1 Structure of an RSCAS Trie

RSCAS tries support CAS queries with range and preﬁx
searches. Each node n in an RSCAS trie includes a dimen-
sion n.D, a path substring n.sP , and a value substring n.sV .
They correspond to ﬁelds t.D, t.sP and t.sV in the dynamic
interleaving of a key (see Deﬁnition 8). Substrings n.sP and
n.sV are variable-length strings. Dimension n.D is P or
V for inner nodes and – for leaf nodes. Leaf nodes addi-
tionally store a set of sufﬁxes, denoted by n.sufﬁxes. This
set contains non-interleaved path and value sufﬁxes along
with references to data items in the database. Each dynam-
ically interleaved key corresponds to a root-to-leaf path in
the RSCAS trie.

Deﬁnition 11 (RSCAS Trie) Let K be a set of composite
keys and let R be a trie. Trie R is the RSCAS trie for K iff
the following conditions are satisﬁed.

1. IDY(k, K) = (t1, . . . , tm, tm+1) is the dynamic inter-
leaving of a key k ∈ K iff there is a root-to-leaf path

(n1, . . . , nm) in R such that ti.sP = ni.sP , ti.sV =
ni.sV , and ti.D = ni.D for 1 ≤ i ≤ m. Sufﬁx tm+1 is
stored in leaf node nm, i.e., tm+1 ∈ nm.sufﬁxes.

2. R does not include duplicate siblings, i.e., no two sibling
nodes n and n′, n ≠ n′, in R have the same values for
sP , sV , and D, respectively.

Example 13 Figure 4 shows the RSCAS trie for keys K1..9.
The values at the discriminative bytes are highlighted in bold.
t1, t2, t3, t4, t5)
The dynamic interleaving IDY(
n1, n2, n4,
from Table 5 is mapped to the root-to-leaf path (
n6) in the RSCAS trie. Tuple t5 is stored in n6.sufﬁxes. Key
k8 is stored in the same root-to-leaf path. For key k1, the
) are mapped to n1 and n2,
ﬁrst two tuples of IDY(
respectively, while the third tuple is mapped to n3.
◻

k1, K1..9

k9, K1..9

) = (

6.2 RSCAS Index

The RSCAS index combines a memory-optimized RSCAS
trie for in-place insertions with a sequence of disk-based
RSCAS tries for out-of-place insertions to get good inser-
tion performance for large data-intensive applications. LSM
trees [33,36] have pioneered combining memory- and disk-
resident components, and are now the de-facto standard to
build scalable index structures (see, e.g., [5,10,12]).

We implement RSCAS as an LSM trie that ﬁxes the size
ratio between two consecutive tries at T = 2 and uses the
leveling merge policy with full merges (this combination is
also known as the logarithmic method in [36]). Leveling op-
timizes query performance and space utilization in compar-
ison to the tiering merge policy at the expense of a higher
merge cost [22,23]. Luo and Carey show that a size ratio
of T = 2 achieves the maximum write throughput for lev-
eling, but may have a negative impact on the latency [22].
Since query performance and space utilization are impor-
tant to us, while latency does not play a large role (due to
batched updates in the background), we choose the setup de-
scribed above. If needed the LSM trie can be improved with
the techniques presented by Luo and Carey [22,23]. For ex-
ample, one such improvement is partitioned merging where
multiple tries with non-overlapping key ranges can exist at

11

the same level and when a trie overﬂows at level i, this trie
needs only to be merged with overlapping tries at level i + 1.
Partitioned merges reduce the I/O during merging since not
all data at level i needs to be merged into level i + 1.

Our focus is to show how to integrate a CAS index with
LSM trees. We do not address aspects related to recovery
and multi-user synchronization. These challenges, however,
exist and must be handled by the system. Typical KV-stores
use write-ahead logging (WAL) to make their system recov-
erable and multi-version concurrency control (MVCC) to
provide concurrency. These techniques are also applicable
to the RSCAS index.

The in-memory RSCAS trie RM

0 is combined with a se-
quence of disk-based RSCAS tries R0, . . . , Rk that grow in
size as illustrated in Figure 5. The most recently inserted
keys are accumulated in the in-memory RSCAS trie RM
0
where insertions can be performed efﬁciently. When RM
0
grows too big, the keys are migrated to a disk-based RSCAS
trie Ri. A query is executed on each trie individually and the
result sets are combined. We only consider insertions since
deletions do not occur in the SWH archive.

empty trie Ri. Assuming this is R0, the disk-resident trie R0
is bulk-loaded with the keys in RM
0 . After another day, RM
0
overﬂows again and this time the ﬁrst non-empty trie is R1.
Trie R1 is created from the keys in RM
0 and R0. At the end
R1 contains 20M keys, and RM
◻

0 and R0 are deleted.

An overﬂow in RM

0 does not stall continuous indexing
since we immediately redirect all incoming insertions to a
new in-memory trie RM ′
0 while we bulk-load Ri in the back-
ground. In order for this to work, RM
0 cannot allocate all
of the available memory. We need to reserve a sufﬁcient
amount of memory for RM ′
(in the SWH archive scenario
0
we allowed RM
0 to take up at most half of the memory). Dur-
ing bulk-loading we keep the old tries RM
0 and R0, . . . , Ri−1
around such that queries have access to all indexed data.
As soon as Ri is complete, we replace RM
and
R0, . . . , Ri−1 with Ri. In practice neither insertions nor queries
stall as long as the insertion rate is bounded. If the insertion
rate is too high and RM ′
overﬂows before we ﬁnish bulk-
0
loading Ri, we block and do not accept more insertions.
This does not happen in the SWH archive since with our
default of M = 108 keys (about 8 GB memory) trie RM ′
overﬂows every ten days and bulk-loading the trie on our
biggest dataset takes about four hours.

0 with RM ′

0

0

Trie RM
0
(0, M] keys
or empty

Trie R0
(0, M] keys
or empty

Trie R1
(M, 2M] keys
or empty

. . . . . .

Trie Rk
(2k−1M, 2kM] keys
or empty

Memory

Disk

RSCAS Index

Fig. 5: The RSCAS index combines memory- and disk-
based RSCAS tries for scalability.

The size of each trie is bounded. RM

0 and R0 contain
up to M keys, where M is chosen according to the memory
capacity of the system. With an average key length of 80
bytes in the SWH archive, reasonable values of M range
from tens of millions to a few billion keys (e.g., with M =
108, RM
0 requires about 8 GB of memory). Each disk-based
trie Ri, i ≥ 1, is either empty or contains between 2i−1M
keys (exclusive) and 2iM keys (inclusive).

When RM
0

is full, we look for the ﬁrst disk-based trie
Ri that is empty. We (a) collect all keys in tries RM
0 and
Rj, 0 ≤ j < i, (b) bulk-load trie Ri from these keys, and (c)
delete all previous tries.

Example 14 Assume we set the number of keys that ﬁt in
memory to M = 10 million, which is the number of new
keys that arrive every day in the SWH archive, on average.
When RM
0 overﬂows after one day we redirect incoming in-
sertions to a new in-memory trie and look for the ﬁrst non-

6.3 Storage Layout

The RSCAS index consists of a mutable in-memory trie RM
0
and a series of immutable disk-based tries Ri. For RM
0 we
use a node structure that is easy to update in-place, while we
design Ri for compact storage on disk.

6.3.1 Memory-Optimized RSCAS Trie

The memory-optimized RSCAS trie RM
0 provides fast in-
place insertions for a small number of composite keys that
ﬁt into memory. Since all insertions are buffered in RM
0 be-
fore they are migrated in bulk to disk, RM
is in the crit-
0
ical path of our indexing pipeline and must support efﬁ-
cient insertions. We reuse the memory-optimized trie [43]
that is based on the memory-optimized Adaptive Radix Tree
(ART) [21]. ART implements four node types that are opti-
mized for the hardware’s memory hierarchy and that have a
physical fanout of 4, 16, 48, and 256 child pointers, respec-
tively. A node uses the smallest node type that can accom-
modate the node’s child pointers. Insertions add node point-
ers and when a node becomes too big, the node is resized to
the next appropriate node type. This ensures that not every
insertion requires resizing, e.g., a node with ten children can
sustain six deletions or seven insertions before it is resized.
Figure 6 illustrates the node type with 256 child pointers;
for the remaining node types we refer to Leis et al. [21].
The node header stores the dimension D, the lengths lP and
lV of substrings sP and sV , and the number of children m.

12

Substrings sP and sV are implemented as variable-length
byte vectors. The remaining space of an inner node (beige-
colored in Figure 6) is reserved for child pointers. For each
possible value b of the discriminative byte there is a pointer
(possibly NULL) to the subtree where all keys have value b
at the discriminative byte in dimension D.

tively). After the header, inner nodes store m pairs (bi, ptri),
where bi (1 byte long) is the value at the discriminative byte
that is used to descend to this child node and ptri (6 bytes
long) is the position of this child in the trie ﬁle. Leaf nodes,
instead, store m sufﬁxes and for each sufﬁx we record sub-
strings sP and sV along with their lengths and the revision
r (20 byte SHA1 hash).

header

D, lP , lV , m
)
(

sP sV 00 01 02 . . . . . . FD FE FF

Inner Node:

Fig. 6: Structure of an inner node with 256 pointers.

header 4B

lP lV 1B

6B

1B

6B

(D, lP , lV , m) sP sV b1 ptr1

. . .

bm ptrm node1

. . .

nodem

Leaf Node:

1st sufﬁx

mth sufﬁx

The structure of leaf nodes is similar, except that leaf
nodes contain a variable-length vector with references k.R
instead of child pointers.

For the memory-optimized RSCAS trie we set the parti-
tioning threshold τ = 1 meaning that RM
0 dynamically inter-
leaves keys completely. This provides fast and ﬁne-grained
access to the indexed keys.

6.3.2 Disk-Optimized RSCAS Trie

We propose a disk-resident RSCAS trie to compactly store
dynamically-interleaved keys on disk. Since a disk-resident
RSCAS trie is immutable, we optimize it for compact stor-
age. To that end we store nodes gapless on disk and we in-
crease the granularity of leaf nodes by setting τ > 1. We
look at these techniques in turn. We store nodes gapless on
disk since we do not have to reserve space for future in-
place insertions. This means a node can cross page bound-
aries but we found that in practice this is not a problem.
We tested various node clustering techniques to align nodes
to disk pages. The most compact node clustering algorithm
[19] produced a trie that was 30% larger than with gapless
storage as it kept space empty on a page if it could not add
another node without exceeding the page size. Besides being
simpler to implement and more compact, the gapless storage
yields better query performance because less data needs to
be read from disk. In addition to the gapless storage, we in-
crease the granularity of leaf nodes by setting τ > 1. As a
result the RSCAS index contains fewer nodes but the size
of leaf nodes increases. We found that by storing fewer but
bigger nodes we save space because we store less meta-data
like node headers, child pointers, etc. In Section 8.4.1 we
determine the optimal value for τ .

Figure 7 shows how to compactly serialize nodes on
disk. Inner nodes point to other nodes, while leaf nodes store
a set of sufﬁxes. Both node types store the same four-byte
header that encodes dimension D ∈ {P, V, –}, the lengths
lP and lV of the substrings sP and sV , and a number m. For
inner nodes m denotes the number of children, while for
leaf nodes it denotes the number of sufﬁxes. Next we store
substrings sP and sV (exactly lP and lV bytes long, respec-

(D, lP , lV , m) sP sV l1

P l1

V s1

P s1

V r1 . . . lm

P lm

header 4B

lP lV

1B

1B

l

1
P

l

1
V

20B

1B

V rm

P sm
V sm
lm
lm
V
P

1B

20B

Fig. 7: Serializing nodes on disk.

Example 15 The size of n1 in Figure 4 is 30 bytes: 4 bytes
for the header, 4 bytes for sV , 1 byte for sP , and 3×(1+6) =
21 bytes for the three child pointers and their discriminative
bytes.
◻

7 Algorithms

We propose algorithms for querying, inserting, bulk-loading,
and merging RSCAS tries. Queries are executed indepen-
dently on all in-memory and disk-based RSCAS tries and
the results are combined. Insertions are directed at the in-
memory RSCAS trie alone. Merging is used whenever the
in-memory RSCAS trie overﬂows and applies bulk-loading
to create a large disk-optimized RSCAS trie.

7.1 Querying RSCAS

We traverse an RSCAS trie in pre-order to evaluate a CAS
query, skipping subtrees that cannot match the query. Start-
ing at the root node, we traverse the trie and evaluate at each
node part of the query’s path and value predicate. Evaluat-
ing a predicate on a node returns MATCH if the full predicate
has been matched, MISMATCH if it has become clear that
no node in the current node’s subtree can match the pred-
icate, and INCOMPLETE if we need more information. In
case of a MISMATCH, we can safely skip the entire subtree.
If both predicates return MATCH, we collect all revisions r
in the leaf nodes of this subtree. Otherwise, we traverse the
trie further to reach a decision.

7.1.1 Query Algorithm

Algorithm 1 shows the pseudocode for evaluating a CAS
query on a RSCAS trie. It takes the following parameters:
the current node n (initially the root node of the trie), a

13

query path q, and a range [vl, vh] for the value predicate.
Furthermore, we need two buffers buffP and buffV (ini-
tially empty) that hold, respectively, all path and value bytes
from the root to the current node n. Finally, we require state
information s to evaluate the path and value predicates (we
provide details as we go along) and an answer set W to col-
lect the results.

, buffV , buffP , s, W
]

)

Algorithm 1: CasQuery
n, q,
(
1 UpdateBuffers(n.sV , n.sP , buffV , buffP )
2 if n is an inner node then
3

vl, vh
[

matchV ← MatchValue(buffV , vl, vh, s, n)
matchP ← MatchPath(buffP , q, s, n)
if matchV ≠ MISMATCH ∧ matchP ≠ MISMATCH then

for each matching child c of n do

CasQuery(c, q, [vl, vh], buffV , buffP , s, W )

4

5

6

7

8 else
9

foreach t ∈ n.sufﬁxes do

10

11

12

13

14

UpdateBuffers(t.sV , t.sP , buffV , buffP )
matchV ← MatchValue(buffV , vl, vh, s, n)
matchP ← MatchPath(buffP , q, s, n)
if matchV = MATCH ∧ matchP = MATCH then

W ← W ∪ {t.R}

First, we update buffV and buffP by adding the in-

formation in sV and sP of the current node n (line 1).

For inner nodes, we match the query predicates against
the current node. MatchValue computes the longest com-
mon preﬁx between buffV and vl and between buffV
and vh. The position of the ﬁrst byte for which buffV
and vl differ is lo and the position of the ﬁrst byte for
which buffV and vh differ is hi. If buffV [lo] < vl[lo],
we know that the node’s value lies outside of the range,
hence we return MISMATCH. If buffV [hi] > vh[hi], the
node’s value lies outside of the upper bound and we return
MISMATCH as well. If buffV contains a complete value
(e.g., all eight bytes of a 64 bit integer) and vl ≤ buffV ≤
vh, we return MATCH. If buffV is incomplete, but vl[lo] <
buffV [lo] and buffV [hi] < vh[hi], we know that all
values in the subtree rooted at n match and we also return
MATCH. In all other cases we cannot make a decision yet and
return INCOMPLETE. The values of lo and hi are kept in
the state to avoid recomputing the longest common preﬁx
from scratch for each node. Instead we resume the search
from the previous values of lo and hi.

Function MatchPath matches the query path q against
the current path preﬁx buffP . It supports symbols * and
** to match any number of characters in a node label, re-
spectively any number of node labels in a path. As long
as we do not encounter any wildcards in the query path q,
we directly compare (a preﬁx of) q with the current con-
tent of buffP byte by byte. As soon as a byte does not
match, we return MISMATCH. If we successfully match the
complete query path q against a complete path in buffP
(both terminated by $), we return MATCH. Otherwise, we
return INCOMPLETE. When we encounter wildcard * in

14

q, we match it successfully to the corresponding label in
buffP and continue with the next label. A wildcard * it-
self will not cause a mismatch (unless we try to match it
against the terminator $), so we either return MATCH if it is
the ﬁnal label in q and buffP or INCOMPLETE. Match-
ing the descendant-axis ** is more complicated. We store
in state s the current position where we are in buffP and
continue matching the label after ** in q. If at any point
we ﬁnd a mismatch, we backtrack to the next path separa-
tor after the noted position, thus skipping a label in buffP
and restarting the search from there. Once buffP contains
a complete path, we can make a decision between MATCH or
MISMATCH.

The algorithm continues by checking the outcomes of
the value and path matching (line 5). If one of the outcomes
is MISMATCH, we stop the search since no descendant can
match the query. Otherwise, we continue with the matching
children of n (lines 6–8). Finding the matching children fol-
lows the same logic as described above for MatchValue
and MatchPath. If node n.D = P and we have seen a de-
scendant axis in the query path, all children of the current
node match.

As soon as we reach a leaf node, we iterate over each
sufﬁx t in the leaf to check if it matches the query using
the same functions as explained above (lines 10–14). If the
current buffers indeed match the query, we add the reference
t.R to the result set.

Example 16 Consider a CAS query that looks for revisions
in 2020 that modiﬁed a C ﬁle in the ext3 or ext4 ﬁlesys-
tem. Thus, the query path is q = /fs/ext*/*.c$ and the
value range is vl = 2020-01-01 (00 00 00 00 5E 0B E1 00)
and vh = 2020-12-31 (00 00 00 00 5F EE 65 FF). We exe-
cute the query on the trie in Figure 4.

– Starting at n1, we update buffV to 00 00 00 00 and
buffP to /. MatchValue matches four value bytes
and returns INCOMPLETE. MatchPath matches one
path byte and also returns INCOMPLETE. Both func-
tions return INCOMPLETE, so we have to traverse all
matching children. Since n1 is a value node, we look for
all matching children whose value for the discriminative
value byte is between 5E and 5F. Nodes n7 and n8 sat-
isfy this condition.

– Node n7 is a leaf. We iterate over each sufﬁx (there are
two) and update the buffers accordingly. For the ﬁrst
sufﬁx with path substring 3/inode.c$ we ﬁnd that
MatchPath and MatchValue both return MATCH.
Hence, revision r4 is added to W . The next sufﬁx matches
the value predicate but not the path predicate and is there-
fore discarded.

– Next we look at node n8. We ﬁnd that vl[5] =
BD
= buffV [5] = vh[5] and buffV [6] =
<

<
5F
=
vh[6], thus all values of n9’s descendants are within the

5E
EE

bounds vl and vh, and MatchValue returns MATCH.
Since n8.sP is the empty string, MatchPath still re-
turns INCOMPLETE and we descend further. According
to the second byte in the query path, q[2] = f, we must
match letter f, hence we descend to node n10, where
both predicates match. Therefore, revision r6 is added to
W .

7.2 Updating Memory-Based RSCAS Trie

All insertions are performed in the in-memory RSCAS trie
RM
0 where they can be executed efﬁciently. Inserting a new
key into RM
0 usually changes the position of the discrimina-
tive bytes, which means that the dynamic interleaving of all
keys that are located in the node’s subtree is invalidated.

Example 17 We insert the key k10 = (/crypto/rsa.c$,
00 00 00 00 5F 83 B9 AC, r8) into the RSCAS trie in Fig-
ure 4. First we traverse the trie starting from root n1. Since
n1’s substrings completely match k10’s path and value we
traverse to child n8. In n8 there is a mismatch in the value
dimension: k10’s sixth byte is 83 while for node n8 the cor-
responding byte is BD. This invalidates the dynamic inter-
leaving of keys K2,3,7 in n8’s subtree.
◻

7.2.1 Lazy Restructuring

If we want to preserve the dynamic interleaving, we need
to re-compute the dynamic interleaving of all affected keys,
which is expensive. Instead, we relax the dynamic inter-
leaving using lazy restructuring [44]. Lazy restructuring re-
solves the mismatch by adding exactly two new nodes, npar
and nsib, to RSCAS instead of restructuring large parts of
the trie. The basic idea is to add a new intermediate node
npar between node n where the mismatch happened and n’s
new sibling node nsib that represents the newly inserted key.
We put all bytes leading up to the position of the mismatch
into npar, and all bytes starting from this position move to
nodes n and nsib. After that, we insert node npar between
node n and its previous parent node np.

Example 18 Figure 8 shows the rightmost subtree of Figure
4 after it is lazily restructured when k10 is inserted. Two new
n′′
nodes are created, parent npar =
8 .
Additionally, n8.sV is updated.
◻

n′
8 and sibling nsib =

Lazy restructuring is efﬁcient: it adds exactly two new
nodes to RM
0 , thus the main cost is traversing the trie. How-
ever, while efﬁcient, lazy restructuring introduces small ir-
regularities that are limited to the dynamic interleaving of
the keys in the subtree where the mismatch occurred. These
irregularities do not affect the correctness of CAS queries,
but they slowly separate (rather than interleave) paths and
values if insertions repeatedly force the algorithm to split the

np = n1
00 00 00 00, /, V
(

)

npar = n′
8
(5F,ǫ,V )

nsib = n′′
8
(83 B9 AC,crypto/rsa.c$,–)
ǫ, ǫ, r8

{(

)}

n = n8
(BD,ǫ,P )

Fig. 8: The rightmost subtree of Figure 4 after inserting key
k10 with lazy restructuring.

same subtree in the same dimension. Since RM
0 is memory-
based and small in comparison to the disk-based tries, the
overall effect on query performance is negligible.

Example 19 After inserting k10, root node n1 and its new
child n′
8 both ψ-partition the data in the value dimension,
violating the strictly alternating property of the dynamic in-
terleaving, see Figure 8.
◻

7.2.2 Inserting Keys with Lazy Restructuring

Algorithm 2 inserts a key k in RM
0 rooted at node n. If RM
0
is empty (i.e., n is NIL) we create a new root node in lines
1-3. Otherwise, we traverse the trie to k’s insertion position.
We compare the key’s path and value with the current node’s
path and value by keeping track of positions gP , gV , iP , iV
in strings k.P, k.V, n.sP , n.sV , respectively (lines 8–11). As
long as the substrings at their corresponding positions coin-
cide we descend. If we completely matched key k, it means
that we reached a leaf node and we add k.R to the current
node’s sufﬁxes (lines 12–14). If during the traversal we can-
not ﬁnd the next node to descend to, the key has a new value
at a discriminative byte that did not exist before in the data.
We create a new leaf node and set its substrings sP and sV to
the still unmatched bytes in k.P and k.V , respectively (lines
20–22). If we ﬁnd a mismatch between the key and the cur-
rent node in at least one dimension, we lazily restructure the
trie (lines 15–17).

Algorithm 3 implements lazy restructuring. Lines 1–4
determine the dimension in which npar partitions the data. If
only a path mismatch occurred between n and k, we have to
use dimension P . In case of only a value mismatch, we have
to use V . If we have mismatches in both dimensions, then
we take the opposite dimension of parent node np to keep up
an alternating interleaving as long as possible. In lines 5–6
we create nodes npar and nsib. Node npar is an inner node of
type node4, which is the node type with the smallest fanout
in ART [21]. In lines 9–12 we install n and nsib as children
of npar. Finally, in lines 13–15, we place the new parent node
npar between n and its former parent node np.

15

Partition L =

gP , gV , mptr, fptr
)
(

Partition Table T

n ∶ Node n in RSCAS

L1..9

= (2, 5, 9, ●)
/Sources/Map.go$
/crypto/ecc.h$
/crypto/ecc.c$
/Sources/Schema.go$
/fs/ext3/inode.c$
/fs/ext4/inode.h$
/fs/ext4/inode.c$
/Sources/Schedule.go$
/Sources/Scheduler.go$

00 00 00 00 5D A8 94 2A
00 00 00 00 5F BD 8D C4
00 00 00 00 5F BD 8D C4
00 00 00 00 5D A8 94 8C
00 00 00 00 5E F2 9C 59
00 00 00 00 5E BD 23 C2
00 00 00 00 5F BD 3D 5A
00 00 00 00 5D A8 97 8B
00 00 00 00 5D A8 97 8B

r1
r2
r2
r3
r4
r5
r6
r7
r7

L1,4,8,9

= (9, 2, 4, ●)

Sources/Map.go$
Sources/Schema.go$
Sources/Schedule.go$
Sources/Scheduler.go$

n1:
00 00 00 00, /, V
(

5D 5E 5F

⋯

5D A8 94 2A
5D A8 94 8C
5D A8 97 8B
5D A8 97 8B
L5,6

r1
r3
r7
r7

= (7, 2, 2, ●)
fs/ext3/inode.c$
fs/ext4/inode.c$

5E F2 9C 59
5E BD 23 C2

r4
r5

)
⋯
L2,3,7
crypto/ecc.h$
crypto/ecc.c$
fs/ext4/inode.c$

= (1, 3, 3, ●)

5F BD 8D C4
5F BD 8D C4
5F BD 3D 5A

r2
r2
r6

(a) Root partition L1..9

(b) L1..9 from (a) is ψ-partitioned in dimension V

n2:
5D A8, Sources/, P
(
⋯ M ⋯ ⋯ ⋯ S ⋯

)

n1:
00 00 00 00, /, V
(

5D 5E 5F

⋯

)

⋯

L5,6

= (7, 2, 2, ●)
fs/ext3/inode.c$
fs/ext4/inode.c$

5E F2 9C 59
5E BD 23 C2

r4
r5

L1

= (8, 3, 1, ●)
94 2A
Map.go$

r7

L4,8,9

= (5, 1, 3, ●)

Schema.go$
Schedule.go$
Scheduler.swift$

94 8C
97 8B
97 8B

r3
r7
r7

L2,3,7

= (1, 3, 3, ●)

crypto/ecc.h$
crypto/ecc.c$
fs/ext4/inode.c$

5F BD 8D C4
5F BD 8D C4
5F BD 3D 5A

r2
r2
r6

(c) L1,4,8,9 from (b) is ψ-partitioned in dimension P

Fig. 9: The keys are recursively ψ-partitioned depth-ﬁrst, creating new RSCAS nodes in pre-order. A node represents the
longest common path and value preﬁxes of its corresponding partition.

Algorithm 2: Insert(k, n)
1 if n = NIL then
2

Install new root node: leaf(k.P, k.V, k.R)
return

// RSCAS is empty; create new root

3

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

4 np ← NIL
5 gP , gV ← 1
6 while true do
7

iP , iV ← 1
while iP ≤ ∣n.sP ∣ ∧ gP ≤ ∣k.P ∣ ∧ n.sP [iP ] = k.P [gP ] do

gP ++;

iP ++

while iV ≤ ∣n.sV ∣ ∧ gV ≤ ∣k.V ∣ ∧ n.sV [iV ] = k.V [gV ] do

gV ++;

iV ++

if gP > ∣k.P ∣ ∧ gV > ∣k.V ∣ then

n.sufﬁxes ← n.sufﬁxes ∪ {(ǫ, ǫ, k.R)}
return

else if iP ≤ ∣n.sP ∣ ∨ iV ≤ ∣n.sV ∣ then

LazyRestructuring(k, n, np, gP , gV , iP , iV )
return

if n.D = P then b ← k.P [gP ] else b ← k.V [gV ]
(np, n) ← (n, n.children[b])
if n = NIL then

np.children[b] ← leaf(k.P [gP , ∣k.P ∣], k.V [gV , ∣k.V ∣], k.R)
return

7.3 Bulk-Loading a Disk-Based RSCAS Trie

We create and bulk-load a new disk-based RSCAS trie when-
ever the in-memory trie RM
0 overﬂows. The bulk-loading
algorithm constructs RSCAS while, at the same time, dy-
namically interleaving a set of keys. Bulk-loading RSCAS is
difﬁcult because all keys must be considered together to dy-
namically interleave them. The bulk-loading algorithm starts
with all non-interleaved keys in the root partition. We use
partitions during bulk-loading to temporarily store keys along

16

Algorithm 3: LazyRestructuring(k, n, np, gP , gV , iP , iV )
// mismatch in P
1 if iP ≤ ∣n.sP ∣ ∧ iV > ∣n.sV ∣ then D ← P
2 else if iP > ∣n.sP ∣ ∧ iV ≤ ∣n.sV ∣ then D ← V // mismatch in V
// mismatch in P and V
3 else if np ≠ NIL then D ← np.D
4 else D ← V
5 npar ← node4(D, n.sP [1, iP − 1], n.sV [1, iV − 1])
6 nsib ← leaf(k.P [gP , ∣k.P ∣], k.V [gV , ∣k.V ∣], k.R)
7 n.sP ← n.sP [iP , ∣n.sP ∣]
8 n.sV ← n.sV [iV , ∣n.sV ∣]
9 if D = P then b1 ← nsib.sP [1] else b1 ← nsib.sV [1]
10 if D = P then b2 ← n.sP [1] else b2 ← n.sV [1]
11 npar.children[b1] ← nsib
12 npar.children[b2] ← n
13 if np = NIL then install npar as new root node
14 else if np.D = P then np.children[npar.sP [1]] ← npar
15 else if np.D = V then np.children[npar.sV [1]] ← npar

with their discriminative bytes. Once a partition has been
processed, it is deleted.

Deﬁnition 12 (Partition) A partition L = (gP , gV , size, ptr)
stores a set K of composite keys. gP = dsc(K, P ) and gV =
dsc(K, V ) denote the discriminative path and value byte,
respectively. size = ∣K∣ denotes the number of keys in the
partition. L is either memory-resident or disk-resident, and
ptr points to the keys in memory or on disk.
◻

Example 20 Root partition L1..9
= (2, 5, 9, ●) in Figure 9a
stores keys K1..9 from Table 1. The longest common preﬁxes
of L1..9 are type-set in bold-face. The ﬁrst bytes after these
preﬁxes are L1..9’s discriminative bytes gP = 2 and gV = 5.
We use placeholder ● for pointer ptr; we describe later how
to decide if partitions are stored on disk or in memory.
◻

Bulk-loading starts with root partition L and breaks it
into smaller partitions using the ψ-partitioning until a par-
tition contains at most τ keys. The ψ-partitioning ψ(L, D)
groups keys together that have the same preﬁx in dimension
D, and returns a partition table where each entry in this ta-
ble points to a new partition Li. We apply ψ alternatingly in
dimensions V and P to interleave the keys at their discrimi-
native bytes. In each call, the algorithm adds a new node to
RSCAS with L’s longest common path and value preﬁxes.

Example 21 Figure 9 shows how the RSCAS from Figure 4
is built. In Figure 9b we extract L1..9’s longest common path
and value preﬁxes and store them in the new root node n1.
Then, we ψ-partition L1..9 in dimension V and obtain a par-
tition table (light green) that points to three new partitions:
L1,4,8,9, L5,6, and L2,3,7. We drop L1..9’s longest common
preﬁxes from these new partitions. We proceed recursively
with L1,4,8,9. In Figure 9c we create node n2 as before and
this time we ψ-partition in dimension P and obtain two new
partitions. Given τ = 2, L1 is not partitioned further, but in
the next recursive step, L4,8,9 would be partitioned one last
time in dimension V .
◻

To avoid scanning L twice (ﬁrst to compute the discrim-
inative byte; second to compute ψ(L, D)) we make the ψ-
partitioning proactive by exploiting that ψ(L, D) is applied
hierarchically. This means we pre-compute the discrimina-
tive bytes of every new partition Li ∈ ψ(L, D) as we ψ-
partition L. As a result, by the time Li itself is ψ-partitioned,
we already know its discriminative bytes and can directly
compute the partitioning. Algorithm 6 in Section 7.4 shows
how to compute the root partition’s discriminative bytes; the
discriminative bytes of all subsequent partitions are com-
puted proactively during the partitioning itself. This halves
the scans over the data during bulk-loading.

7.3.1 Bulk-Loading Algorithm

The bulk-loading algorithm (Algorithm 4) takes three pa-
rameters: a partition L (initially the root partition), the par-
titioning dimension D (initially dimension V ), and the po-
sition in the trie ﬁle where the next node is written to (ini-
tially 0). Each invocation adds a node n to the RSCAS trie
and returns the position in the trie ﬁle of the ﬁrst byte af-
ter the subtree rooted in n. Lines 1–3 create node n and set
its longest common preﬁxes n.sP and n.sV , which are ex-
tracted from a key k ∈ L from the ﬁrst byte up to, but ex-
cluding, the positions of L’s discriminative bytes L.gP and
L.gV . If the number of keys in the current partition exceeds
the partitioning threshold τ and L can be ψ-partitioned, we
break L further up. In lines 5–6 we check if we can indeed
ψ-partition L in D and switch to the alternate dimension D
otherwise. In line 8 we apply ψ(L, D) and obtain a partition
table T , which is a 28-long array that maps the 28 possi-
ble values b of a discriminative byte (0x00 ≤ b ≤ 0xFF)

to partitions. We write T [b] to access the partition for value
b (T [b] = NIL if no partition exists for value b). ψ(L, D)
drops L’s longest common preﬁxes from each key k ∈ L
since we store these preﬁxes already in node n. We apply
Algorithm 4 recursively on each partition in T with the al-
ternate dimension D, which returns the position where the
next child is written to on disk. We terminate if partition L
contains no more than τ keys or cannot be partitioned fur-
ther. We iterate over all remaining keys in L and store their
non-interleaved sufﬁxes in the set n.sufﬁxes of leaf node n
(lines 16–19). Finally, in line 22 we write node n to disk at
the given offset in the trie ﬁle.

Algorithm 4: BulkLoad(L, D, preorderPos)
1 Let n be a new node, k a key in L;
2 n.sP ← k.P [1, L.gP − 1];
3 n.sV ← k.V [1, L.gV − 1];
4 if L.size > τ ∧ (L.gP > ∣k.P ∣ ∨ L.gV > ∣k.V ∣) then
5

if D = P ∧ L.gP > ∣k.P ∣ then D ← V ;
else if D = V ∧ L.gV > ∣k.V ∣ then D ← P ;
n.D ← D;
T ← ψ(L, D);
pos ← preorderPos + size(n);
for b ← 0x00 to 0xFF do
if T [b] ≠ NIL then

n.children[b] ← pos;
pos ← BulkLoad(T [b], D, pos);

14 else
15

n.D ← –;
foreach key k ∈ L do

sP ← k.P [L.gP , ∣k.P ∣];
sV ← k.V [L.gV , ∣k.V ∣];
n.sufﬁxes ← n.sufﬁxes ∪ {(sP , sV , k.R)};

Delete L;
pos ← preorderPos + size(n);

6

7

8

9

10

11

12

13

16

17

18

19

20

21

22 Write node n to disk from position preorderPos to preorderPos + size(n);
23 return pos;

Algorithm 5 implements ψ(L, D). We organize the keys
in a partition L at the granularity of pages so that we can
seamlessly transition between memory- and disk-resident
partitions. A page is a ﬁxed-length buffer that contains a
variable number of keys. If L is disk-resident, L.ptr points to
a page-structured ﬁle on disk and if L is memory-resident,
L.mptr points to the head of a singly-linked list of pages.
Algorithm 5 iterates over all pages in L and for each key
in a page, line 6 determines the partition T [b] to which k
belongs by looking at its value b at the discriminative byte.
Next we drop the longest common path and value preﬁxes
from k (lines 7–8). We proactively compute T [b]’s discrimi-
native bytes whenever we add a key k to T [b] (lines 10–17).
Two cases can arise. If k is T [b]’s ﬁrst key, we initialize par-
tition T [b]. If L ﬁts into memory, we make T [b] memory-
resident, else disk-resident. We initialize gP and gV with one
past the length of k in the respective dimension (lines 9–12).
These values are valid upper-bounds for the discriminative
bytes since keys are preﬁx-free. We store k as a reference
key for partition T [b] in refkeys[b]. If k is not the ﬁrst key
in T [b], we update the upper bounds (lines 13–17) as fol-

17

lows. Starting from the ﬁrst byte, we compare k with ref-
erence key refkeys[b] byte-by-byte in both dimension until
we reach the upper-bounds T [b].gP and T [b].gV , or we ﬁnd
new discriminative bytes and update T [b].gP and T [b].gV .

Algorithm 5: ψ(L, D)
Let T be a new partition table;
1
2 Let outpages be an array of 28
3 Let refkeys be an array to store 28
4 foreach page ∈ L.ptr do
5

foreach key k ∈ page do

pages for output buffering;

composite keys;

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

if D = P then b ← k.P [L.gP ] else b ← k.V [L.gV ];
k.P ← k.P [L.gP , ∣k.P ∣];
k.V ← k.V [L.gV , ∣k.V ∣];
if T [b] = NIL then

if L ﬁts into memory then ptr ← new linked list else ptr ← new

ﬁle;

T [b] ← (∣k.P ∣+1, ∣k.V ∣+1, 0, ptr);
refkeys[b] ← k;

proactively compute
discriminative bytes

else

k′, gP , gV ← (refkeys[b], 1, 1);
while gP < T [b].gP ∧ k.P [gP ] = k′.P [gP ] do gP ++;
while gV < T [b].gV ∧ k.V [gV ] = k′.V [gV ] do gV ++;
T [b].gP , T [b].gV ← (gP , gV );

if outpages[b] is full then

Push(T [b].ptr, outpages[b]);
Clear contents of page outpages[b];

Add k to outpages[b];
T [b].size++;

Delete page;

24 for b ← 0x00 to 0xFF do
25

if T [b] ≠ NIL then Push(T [b].ptr, outpages[b]);

26 Delete L;
27 return T ;

7.4 Merging RSCAS Tries Upon Overﬂow

When the memory-resident trie RM
reaches its maximum
0
size of M keys, we move its keys to the ﬁrst disk-based trie
Ri that is empty using Algorithm 6. We keep pointers to the
root nodes of all tries in an array. Algorithm 6 ﬁrst collects
all keys from tries RM
0 , R0, . . . , Ri−1 and stores them in a
new partition L (lines 2–4). Next, in lines 5–11, we compute
L’s discriminative bytes L.gP and L.gV from the substrings
sP and sV of the root nodes of the i tries. Finally, in lines
12–14, we bulk-load trie Ri and delete all previous tries.

Algorithm 6: HandleOverﬂow
1 Let i be the smallest number such that index Ri is empty;
2 Let L be a new disk-resident partition;
3 foreach trie R ∈ {RM
4

0 , R0, . . . , Ri−1} do
Collect all composite keys in R and store them in L.ptr;
0 , n0, . . . , ni−1} ← root nodes of all tries RM

5 {nM
6 L.gP , L.gV ← (∣nM
7 foreach root node n ∈ {n0, . . . , ni−1} do
8

0 .sP ∣ + 1, ∣nM

0 .sV ∣ + 1);

gP , gV ← (1, 1);
while gP < L.gP ∧ nM
while gV < L.gV ∧ nM
L.gP , L.gV ← (gP , gV );

9

10

11

0 .sP [gP ] = n.sP [gP ] do gP ++;
0 .sP [gV ] = n.sV [gV ] do gV ++;

0 , R0, . . . , Ri−1;

12 Create new trie ﬁle Ri;
13 BulkLoad(L, V, position 0 in Ri’s trie ﬁle);
14 Delete tries RM

0 , R0, . . . , Ri−1;

7.5 Analytical Evaluation

7.5.1 Total I/O Overhead During Bulk-Loading

The I/O overhead is the number of page I/Os without read-
ing the input and writing the output. We use N , M , and B
for the number of input keys, the number of keys that ﬁt into
memory, and the number of keys that ﬁt into a page, respec-
tively [4]. We analyze the I/O overhead of Algorithm 4 for a
uniform data distribution with a balanced RSCAS and for a
maximally skewed distribution with an unbalanced RSCAS.
The ψ-partitioning splits a partition into equally sized parti-
tions. Thus, with a ﬁxed fanout f the ψ-partitioning splits a
partition into f , 2 ≤ f ≤ 28, partitions.

Lemma 5 The I/O overhead to build RSCAS with Algorithm
4 from uniformly distributed data is

2 × ⌈logf ⌈

N
M ⌉⌉ × ⌈

N
B ⌉

Example 22 We compute the I/O overhead for N = 16, M =
16
4 ⌉⌉ = 2 intermediate
4, B = 2, and f = 2. There are ⌈log2⌈
levels with the data on disk. On each level we read and write
16
2 = 8 pages. In total, the disk I/O is 2 × 2 × 8 = 32.
◻

For maximally skewed data RSCAS deteriorates to a trie
whose height is linear in the number of keys in the dataset.

Lemma 6 The I/O overhead to build RSCAS with Algorithm
4 from maximally skewed data is

N −⌈ M

B ⌉B

2 ×

∑
i=1

N − i
B ⌉ + 1)

(⌈

Example 23 We use the same parameters as in the previous
example but assume maximally skewed data. There are 16 −
4
2 ⌉2 = 12 levels before the partitions ﬁt into memory. For
⌈
16−1
2 ⌉ = 8 pages
example, at level i = 1 we write and read ⌈
for L1,2. In total, the I/O overhead is 144 pages.
◻

Theorem 4 The I/O overhead to build RSCAS with Algo-
rithm 4 depends on the data distribution. It is lower bounded
N
by O(log(
B ).

N
B ) and upper bounded by O((N − M )

N
M )

Note that, since RSCAS is trie-based and keys are en-
coded by the path from the root to the leaves, the height of
the trie is bounded by the length of the keys. The worst-
case is very unlikely in practice because it requires that the
lengths of the keys is linear in the number of keys. Typically,
the key length is at most tens or hundreds of bytes. We show
in Section 8 that building RSCAS performs close to the best
case on real world data.

18

7.5.2 Amortized I/O Overhead During Insertions

Table 6: Dataset Statistics

Next, we consider the amortized I/O overhead of a single
insertion during a series of N insertions into an empty trie.
Note that M − 1 out of M consecutive insertions incur no
disk I/O since they are handled by the in-memory trie RM
0 .
Only the M th insertion bulk-loads a new disk-based trie.

Lemma 7 Let cost(N, M, B) be the I/O overhead of bulk-
loading RSCAS. The amortized I/O overhead of one inser-
1
tion out of N insertions into an initially empty trie is O(
N ×
log2(

N
M ) × cost(N, M, B)).

8 Experimental Evaluation

8.1 Setup

Environment. We use a Debian 10 server with 80 cores and
400 GB main memory. The machine has six hard disks, each
2 TB big, that are conﬁgured in a RAID 10 setup. The code
is written in C++ and compiled with g++ 8.3.0.

Datasets. We use three real-world datasets and one synthetic
dataset. Table 6 provides an overview.

– GitLab. The GitLab data from SWH contains archived
copies of all publicly available GitLab repositories up
to 2020-12-15. The dataset contains 914 593 archived
repositories, which correspond to a total of 120 071 946
unique revisions and 457 839 953 unique ﬁles. For all re-
visions in the GitLab dataset we index the commit time
and the modiﬁed ﬁles (equivalent to “commit diffstats”
in version control system terminology). In total, we in-
dex 6.9 billion composite keys similar to Table 1.

– ServerFarm. The ServerFarm dataset [43] mirrors the
ﬁle systems of 100 Linux servers. For each server we
installed a default set of packages and randomly picked
a subset of optional packages. In total there are 21 mil-
lion ﬁles. For each ﬁle we record the ﬁle’s full path and
size.

– Amazon. The Amazon dataset [18] contains hierarchi-
cally categorized products. For each product its location
in the hierarchical categorization (the path) and its price
in cents (the value) are recorded. For example, the shoe
‘evo’ has path /sports/outdoor/running/evo
and its price is 10 000 cents.

– XMark. The XMark dataset [40] is a synthetic dataset
that models a database for an internet auction site. It con-
tains information about people, regions (subdivided by
continent), etc. We generated the dataset with scale fac-
tor 500 and we index the numeric attribute ‘category’.

Previous Results. In our previous work [44] we com-
pared RSCAS to state-of-the-art research solutions. We com-
pared RSCAS to the CAS index by Mathis et al. [26], which
indexes paths and values in separate index structures. We

Origin
Attribute
Type
Size
Nr. Keys
Nr. Unique Keys
Nr. Unique Paths
Nr. Unique Values
Avg. Key Size
Total Size of Keys

GitLab

SWH
Commit time
real-world
1.6 TB
6 891 972 832
5 849 487 576
340 614 623
81 829 152
79.8 B
550.2 GB

[43]
Size
real-world
3.0 GB

ServerFarm Amazon
[18]
Price
real-world
10.5 GB
21 291 019 6 707 397
9 345 668 6 461 587
9 331 389 6 311 076
47 852
119.3 B
0.8 GB

234 961
79.8 B
1.7 GB

XMark

[40]
Category
synthetic
58.9 GB
60 272 422
1 506 408
7
389 847
54.8 B
3.3 GB

also compared RSCAS to a trie-based index where com-
posite keys are integrated with four different methods: (i)
the z-order curve with surrogate functions to map variable-
length keys to ﬁxed-length keys, (ii) a label-wise interleav-
ing where we interleave one path label with one value byte,
(iii) the path-value concatenation, and (iv) value-path con-
catenation. Our experiments showed that the approaches do
not provide robust CAS query performance because they
may create large intermediate results.

Compared Approaches. This paper compares RSCAS
to scalable state-of-the-art industrial-strengths systems. First,
we compare RSCAS to Apache Lucene [1], which builds
separate indexes for the paths and values. Lucene creates an
FST on the paths and a Bkd-tree [36] on the values. Lucene
evaluates CAS queries by decomposing queries into their
two predicates, evaluating the predicates on the respective
indexes, and intersecting the sorted posting lists to produce
the ﬁnal result. Second, we compare RSCAS to compos-
ite B-trees in Postgres. This simulates the two possible c-
order curves that concatenate the paths and values (or vice
versa). We create a table data(P, V, R), similar to Table 1,
and create two composite B+ trees on attributes (P, V ) and
(V, P ), respectively.

Parameters. Unless otherwise noted, we set the parti-
tioning threshold τ = 100 based on experiments in Section
8.4.1. The number of keys M that the main-memory RSCAS
trie RM

0 can hold is M = 108.

Artifacts. The code and the datasets used for our exper-

iments are available online.2

8.2 Impact of Datasets on RSCAS’s Structure

In Figure 10 we show how the shape (depth and width) of
the RSCAS trie adapts to the datasets. Figure 10a shows the
distribution of the node depths in the RSCAS trie for the
GitLab dataset. Because of its trie-based structure not ev-
ery root-to-leaf path in RSCAS has the same length (see
also Figure 4). The average node depth is about 10, with
90% of all nodes occurring no deeper than level 14. The ex-
6.9B
100 ⌉ = 8.7, where N is the
pected depth is log ¯f ⌈
number of keys, τ is the partitioning threshold that denotes
the maximum size of a leaf partition, and ¯f is the average

N
τ ⌉ = log8⌈

2 https://github.com/k13n/scalable_rcas

19

fanout. The actual average depth is higher than the expected
depth since the GitLab dataset is skewed and the expected
depth assumes a uniformly distributed dataset. In the Git-
Lab dataset the average key length is 80 bytes, but the aver-
age node depth is 10, meaning that RSCAS successfully ex-
tracts common preﬁxes. Figure 10b shows how the fanout of
the nodes is distributed. Since RSCAS ψ-partitions the data
at the granularity of bytes, the fanout of a node is upper-
bounded by 28, but in practice most nodes have a smaller
fanout (we cap the x-axis in Figure 10b at fanout 40, because
there is a long tail of high fanouts with low frequencies).
Nodes that ψ-partition the data in the path dimension typi-
cally have a lower fanout because most paths contain only
printable ASCII characters (of which there are about 100),
while value bytes span the entire available byte spectrum.

Node Depth

Node Fanout

b
a
L

t
i

G

m
r
a
F
r
e
v
r
e
S

n
o
z
a
m
A

k
r
a
M
X

]

%

[

y
c
n
e
u
q
e
r
F

]

%

[

y
c
n
e
u
q
e
r
F

]

%

[

y
c
n
e
u
q
e
r
F

]

%

[

y
c
n
e
u
q
e
r
F

40
30
20
10
0

40
30
20
10
0

40
30
20
10
0

60

40

20

0

(a)

Avg: 9.6
Exp: 8.7

0

10

20

30

(c)

Avg: 10.6
Exp: 6.1

0

10

20

30

(e)

Avg: 6.9
Exp: 4

40
30
20
10
0

40
30
20
10
0

40
30
20
10
0

Avg: 8.0

(b)

0

10

20

30

40

Avg: 7.6

(d)

0

10

20

30

40

(f)

Avg: 16.9

0

10

20

30

0

10

20

30

40

(g)

Avg: 4.8
Exp: 5.1

60
40
20
0

(h)

Avg: 32.6

0 1 2 3 4 5 6

0

10

20

30

40

Fig. 10: Structure of the RSCAS trie

The shape of the RSCAS tries on the ServerFarm and
Amazon datasets closely resemble that of the trie on the Git-
Lab dataset, see the second and third row in Figure 10. This
is to be expected since all three datasets contain a large num-
ber of unique paths and values, see Table 6. As a result, the
data contains a large number of discriminative bytes that are
needed to distinguish keys from one another. The paths in
these datasets are typically longer than the values and con-
tain more discriminative bytes. In addition, as seen above,
the discriminative path bytes typically ψ-partition the data
into fewer partitions than the discriminative value bytes. As
a consequence, the RSCAS trie on these three datasets is

narrower and deeper than the RSCAS trie on the XMark
dataset, which has only seven unique paths and about 390k
unique values in a dataset of 60M keys. Since the majority
of the discriminative bytes in the XMark dataset are value
bytes, the trie is ﬂatter and wider on average, see the last
row in Figure 10.

8.3 Query Performance

Table 7 shows twelve typical CAS queries with their query
path q and the value range [vl, vh]. We show for each query
the ﬁnal result size and the number of keys that match the in-
dividual predicates. In addition, we provide the selectivities
of the queries. The selectivity σ (σP ) [σV ] is computed as
the fraction of all keys that match the CAS query (path predi-
cate) [value predicate]. A salient characteristic of the queries
is that the ﬁnal result is orders of magnitude smaller than the
results of the individual predicates. Queries Q1 through Q6
on the GitLab dataset increase in complexity. Q1 looks up
all revisions that modify one speciﬁc ﬁle in a short two-hour
time frame. Thus, Q1 is similar to a point query with very
low selectivity in both dimensions. The remaining queries
have a higher selectivity in at least one dimension. Q2 looks
up all revisions that modify one speciﬁc ﬁle in a one-month
period. Thus, its path selectivity is low but its value selec-
tivity is high. Query Q3 does the opposite: its path predicate
matches all changes to GPU drivers using the ** wildcard,
but we only look for revisions in a very narrow one-day time
frame. Q4 mixes the * and ** wildcards multiple times and
puts them in different locations of the query path (in the mid-
dle and towards the end). Q5 looks for changes to all Make-
ﬁles, using the ** wildcard at the front of the query path.
Similarly, Q6 looks for all changes to ﬁles named inode
(all ﬁle extensions are accepted with the * wildcard). The
remaining six queries on the other three datasets are similar.

RSCAS

Lucene

Postgres (VP)

Postgres (PV)

]
s
m

[

e
m

i
t
n
u
R

]
s

m

[

e
m

i
t
n
u
R

106

103

100

106

103

100

(a) Query Q1

(b) Query Q2

(c) Query Q3

(d) Query Q4

(e) Query Q5

(f) Query Q6

Fig. 11: Runtime of queries Q1, . . . , Q6 on cold caches

Figure 11 shows the runtime of the six queries on the
GitLab dataset (note the logarithmic y-axis). We clear the
operating system’s page cache before each query (later we

20

Table 7: CAS queries with their result size and the number of keys that match the path, respectively value predicate.

Dataset: GitLab (the values are commit times that are stored as 64 bit Unix timestamps)

Query path q

vl

vh

Result size (σ)

Path matches (σP )

Value matches (σV )

09/10/17
01/10/17
07/08/14
06/05/13
22/05/12
07/08/18

/drivers/android/binder.c
/drivers/android/binder.c
/drivers/gpu/**
/Documentation/**/arm/**/*.txt
/**/Makefile
/**/ext*/inode.*

Q1
Q2
Q3
Q4
Q5
Q6
Dataset: ServerFarm (the values are the ﬁle sizes in bytes)
/usr/lib/**
Q7
/usr/share/doc/**/README
Q8
Dataset: Amazon (the values are product prices in cents)
/CellPhones&Accessories/**
Q9
100 $
/Clothing/Women/*/Sweaters/**
Q10
70 $
Dataset: XMark (the values denote the numeric attribute category)
Q11
0
Q12
0

/site/people/**/interest
/site/regions/africa/**

0 kB
4 kB

09/10/17
01/11/17
08/08/14
22/05/13
04/06/12
29/08/18

1 kB
5 kB

200 $
100 $

50000
50000

29 (4.2 ⋅ 10−9
3236 (4.7 ⋅ 10−7
60 344 (8.8 ⋅ 10−6
11 720 (1.7 ⋅ 10−6
263 754 (3.8 ⋅ 10−5
5080 (7.4 ⋅ 10−7

)
)
)
)
)
)

125 849 (1.8 ⋅ 10−5
125 849 (1.8 ⋅ 10−5
151 871 503 (2.2 ⋅ 10−2
5 927 129 (8.6 ⋅ 10−4
112 037 140 (1.6 ⋅ 10−2
529 875 (7.7 ⋅ 10−5

)
)
)
)
)
)

328 603 (4.8 ⋅ 10−5
72 883 667 (1.1 ⋅ 10−2
3 503 076 (5.1 ⋅ 10−4
22 221 892 (3.2 ⋅ 10−3
10 932 756 (1.6 ⋅ 10−3
70 971 382 (1.0 ⋅ 10−2

)
)
)
)
)
)

512 497 (2.4 ⋅ 10−2
521 (2.4 ⋅ 10−5

)
)

2 277 518 (1.1 ⋅ 10−1
24 698 (1.2 ⋅ 10−3

)
)

8 403 809 (3.9 ⋅ 10−1
761 513 (3.6 ⋅ 10−2

)
)

2758 (4.1 ⋅ 10−4
239 (3.6 ⋅ 10−5

)
)

291 625 (4.3 ⋅ 10−2
4654 (6.9 ⋅ 10−4

)
)

324 272 (4.8 ⋅ 10−2
269 936 (4.0 ⋅ 10−2

)
)

1 910 524 (3.2 ⋅ 10−2
104 500 (1.7 ⋅ 10−3

)
)

19 009 723 (3.2 ⋅ 10−1
1 043 247 (1.7 ⋅ 10−2

)
)

6 066 546 (1.0 ⋅ 10−1
6 066 546 (1.0 ⋅ 10−1

)
)

repeat the same experiment on warm caches). We start with
the runtime of query Q1 in Figure 11a. This point query is
well suited for existing solutions because both predicates
have low selectivities and produce small intermediate re-
sults. Therefore, the composite VP and PV indexes perform
best. No matter what attribute is ordered ﬁrst in the com-
posite index (the paths or the values), the index can quickly
narrow down the set of possible candidates. Lucene on the
other hand evaluates both predicates and intersects the re-
sults, which is more expensive. RSCAS is in between Lucene
and the two composite indexes. Q2 has a low path but high
value selectivity. Because of this, the composite PV index
outperforms the composite VP index, see Figure 11b. Eval-
uating this query in Lucene is costly since Lucene must fully
iterate over the large intermediate result produced by the
value predicate. RSCAS, on the other hand, uses the se-
lective path predicate to prune subtrees early during query
evaluation. For query Q3 in Figure 11c, RSCAS performs
best but it is closely followed by the composite VP index,
for which Q3 is the best case since Q3 has a very low value
selectivity. While Q3 is the best case for VP, it is the worst
case for PV and indeed its query performance is an order
of magnitude higher. For Lucene the situation is similar to
query Q2, except that the path predicate produces a large in-
termediate result (rather than the value predicate). Query Q4
uses the * and ** wildcards at the end of its query path. The
placement of the wildcards is important for all approaches.
Query paths that have wildcards in the middle or at the end
can be evaluated efﬁciently with preﬁx searches. As a result,
RSCAS’s query performance remains stable and is similar
to that for queries Q1, . . . , Q3. Queries Q5 and Q6 are more
difﬁcult for all approaches because they contain the descen-
dant axis at the beginning of the query path. Normally, when
the query path does not match a path in the trie, the node that
is not matched and its subtrees do not need to be considered
anymore because no path sufﬁx can match the query path.

The ** wildcard, however, may skip over mismatches and
the query path’s sufﬁx may match. For this reason, Lucene
must traverse its entire FST that is used to evaluate path
predicates. Likewise, the composite PV index must traverse
large parts of the index because the keys are ordered ﬁrst by
the paths and in the index. The VP index can use the value
predicate to prune subtrees that do not match the value pred-
icate before looking at the path predicate. RSCAS uses the
value predicate to prune subtrees when the path predicate
does not prune anymore because of wildcards and therefore
delivers the best query runtime.

RSCAS

Lucene

Postgres (VP)

Postgres (PV)

]
s
m

[

e
m

i
t
n
u
R

]
s
m

[

e
m

i
t
n
u
R

106

103

100

106

103

100

(a) Query Q7

(b) Query Q8

(c) Query Q9

(d) Query Q10

(e) Query Q11

(f) Query Q12

Fig. 12: Runtime of queries Q7, . . . , Q12 on cold caches

In Figure 12 we show the runtime of queries Q7, . . . Q12
on the remaining three datasets (again on cold caches). The
absolute runtimes are lower because the datasets are consid-
erably smaller than the GitLab dataset, see Table 6, but the
relative differences between the approaches are comparable
to the previous set of queries, see Figure 11.

We repeat the same experiments on warm caches, see
Figure 13 (the y-axis shows the query runtime in millisec-
onds). Note that we did not implement a dedicated caching
mechanism and solely rely on the operating system’s page

21

cache. When the caches are hot the CPU usage and mem-
ory access become the main bottlenecks. Since RSCAS pro-
duces the smallest intermediate results, RSCAS requires the
least CPU time and memory accesses. As a result, RSCAS
consistently outperforms its competitors, see Figure 13.

RSCAS

Lucene

Postgres (VP)

Postgres (PV)

]
s
m

[

e
m

i
t
n
u
R

]
s
m

[

e
m

i
t
n
u
R

]
s
m

[

e
m

i
t
n
u
R

]
s
m

[

e
m

i
t
n
u
R

106

103

100

106

103

100

106

103

100

106

103

100

(a) Query Q1

(b) Query Q2

(c) Query Q3

(d) Query Q4

(e) Query Q5

(f) Query Q6

(g) Query Q7

(h) Query Q8

(i) Query Q9

(j) Query Q10

(k) Query Q11

(l) Query Q12

Fig. 13: Runtime of queries Q1, . . . , Q12 on warm caches.

To evaluate the impact of the number of levels on the
query performance we ran an experiment for an RSCAS in-
dex with 109 keys from the GitLab dataset. By varying the
memory size to accommodate, respectively, 220, 226 and 230
keys, we got an RSCAS index with 1, 4 and 7 levels (tries),
respectively. The total running time for running queries Q1
to Q6 is detailed in Figure 14.

)
c
e
s
(

e
m

i
t

y
r
e
u
Q

100

50

0

1

4
Number of levels (tries) in the RSCAS index

7

Fig. 14: Query performance for RSCAS index with different
number of levels.

8.4 Scalability

RSCAS uses its LSM-based structure to gracefully and efﬁ-
ciently handle large datasets that do not ﬁt into main mem-
ory. We discuss how to choose threshold τ , the performance
of bulk-loading and individual insertions, the accuracy of the
cost model, and the index size.

8.4.1 Calibration

We start out by calibrating the partitioning threshold τ , i.e.,
the maximum number of sufﬁxes in a leaf node. We calibrate
τ in Figure 15 on a 100 GB subset of the GitLab dataset.
Even on the 100 GB subset, bulk-loading RSCAS with τ = 1
takes more than 12 hours, see Figure 15a. When we increase
τ , the recursive bulk-loading algorithm terminates earlier
(see lines 15–21 in Algorithm 4), hence fewer partitions are
created and the runtime improves. Since the bulk-loading
algorithm extracts from every partition its longest common
preﬁxes and stores them in a new node, the number of nodes
in the index also decreases as we increase τ , see Figure
15b. As a result, leaf nodes get bigger and store more un-
interleaved sufﬁxes. This negatively affects the query per-
formance and the index size, see Figures 15c and 15d, re-
spectively. Figures 15c shows the average runtime of the six
queries Q1, . . . , Q6. A query that reaches a leaf node must
scan all sufﬁxes to ﬁnd matches. Making τ too small de-
creases query performance because more nodes need to be
traversed and making τ too big decreases query performance
because a node must scan many sufﬁxes that do not match a
query. According to Figures 15c, values τ ∈ [10, 100] give
the best query performance. Threshold τ also affects the in-
dex size, see Figure 15d. If τ is too small, many small nodes
are created and for each such node there is storage overhead
in terms of node headers, pointers, etc., see Figure 7. If τ is
too big, leaf nodes contain long lists of sufﬁxes for which
we could still extract common preﬁxes if we ψ-partitioned
them further. As a consequence, we choose medium values
for τ to get a good balance between bulk-loading runtime,
query performance, and index size. Based on Figure 15 we
choose τ = 100 as default value. More details on a quan-
titative analysis on how τ affects certain parameters can be
found in Appendix B.

8.4.2 Bulk-Loading Performance

Bulk-loading is a core operation that we use in two situ-
ations. First, when we create RSCAS for an existing sys-
tem with large amounts of data we use bulk-loading to cre-
ate RSCAS. Second, our RSCAS index uses bulk-loading
to create a disk-based RSCAS trie whenever the in-memory
RSCAS trie RM
0 overﬂows. We compare our bulk-loading
algorithm with bulk-loading of composite B+ trees in Post-
gres (Lucene does not support bulk-loading; as a reference

22

]
h
[

g
n
i
d
a
o
l
-
k
l
u
B

]
s
[

e
m

i
t
n
u
R
y
r
e
u
Q

10

5

0

10
8
6
4
2
0

]

B

[

τ = 100

s
e
d
o
N

r

N

100

102
(a) Threshold τ

104

]

B
G

[

τ = 100

100

102
(c) Threshold τ

104

e
z
i

S
x
e
d
n
I

1.5
1
0.5
0

80
60
40
20
0

τ = 100

100

102
(b) Threshold τ

104

τ = 100

100

102
(d) Threshold τ

104

Fig. 15: Calibrating partitioning threshold τ

point we include Lucene’s performance for the correspond-
ing point insertions).

RSCAS

Postgres (VP)

Postgres (PV)

Lucene*

]
h
[

e
m
T

i

6

4

2

0

]

B
T
[

O

/
I

k
s
i
D

3
2
1
0

0

2

4
6
(a) Nr Keys [×109]

0

2

4
6
(b) Nr Keys [×109]

Fig. 16: Bulk-Loading performance

Figure 16 evaluates the performance of the bulk-loading
algorithms for RSCAS and Postgres. We give the systems
8 GB of main memory. For a fair comparison, we set the
ﬁll factor of the composite B+ trees in Postgres to 100%
to make them read-optimized and as compact as possible
since disk-based RSCAS tries are read-only. We compare
the systems for our biggest dataset, the GitLab dataset, in
Figure 16. The GitLab dataset contains 6.9 billion keys and
has a size of 550 GB. Figure 16a conﬁrms that bulk-loading
RSCAS takes roughly the same time as bulk-loading the PV
and VP composite indexes in Postgres (notice that RSCAS
and the PV composite index have virtually the same run-
time, thus PV’s curve is barely visible). The runtime and
disk I/O of all algorithms increase linearly in Figure 16a,
which means it is feasible to bulk-load these indexes efﬁ-
ciently for very large datasets. Postgres creates a B+ tree by
sorting the data and then building the index bottom up, level
by level. RSCAS partitions the data and builds the index top
down. In practice, both paradigms perform similarly, both in
terms of runtime (Figure 16a) and disk I/O (Figure 16b).

8.4.3 Insertion Performance

uate insertions into RM
0 in Figure 17a and look at the inser-
tion speed when RM
0 overﬂows in Figure 17b. For the latter
case we compare RSCAS’s on-disk insertion performance
to Lucene’s and Postgres’.

Since RM

0 is memory-based, insertions can be performed
quickly, see Figure 17a. For example, inserting 100 million
keys takes less than three minutes with one insertion tak-
ing 1.7µs, on average. In practice, the SWH archive crawls
about one million revisions per day and since a revision
modiﬁes on average about 60 ﬁles in the GitLab dataset,
there are 60 million insertions into the RSCAS index per
day, on average. Therefore, our RSCAS index can easily
keep up with the ingestion rate of the SWH archive. Every
two days, on average, RM
0 overﬂows and a new disk-based
RSCAS trie Ri is bulk-loaded.

RSCAS

Lucene

Postgres* (VP)

Postgres* (PV)

]
s
[

e
m
T

i

150

100

50

0

50
(a) Nr Keys [×106]

100

]

m

[

e
m
T

i

80
60
40
20
0

0

200

400

600

(b) Nr Keys [×106]

Fig. 17: Insertion (a) in memory and (b) on disk

In Figure 17b we show how the RSCAS index performs
when RM
0 overﬂows. In this experiment, we set the max-
imum capacity of RM
to M = 100 million keys and in-
0
sert 600 million keys, thus RM
0 overﬂows six times. Typ-
ically when RM
0 overﬂows we bulk-load a disk-based trie
in a background process, but in this experiment we execute
all insertions in the foreground in one process to show all
times. As a result, we observe a staircase runtime pattern,
see Figure 17b. A ﬂat part where insertions are performed
efﬁciently in memory is followed by a jump where a disk-
based trie Ri is bulk-loaded. Not all jumps are equally high
since their height depends on the size of the trie Ri that is
bulk-loaded. When RM
0 overﬂows, the RSCAS index looks
for the smallest i such that Ri does not exist yet and bulk-
loads it from the keys in RM
0 and all Rj, j < i. Therefore,
a trie Ri, containing 2iM keys, is created for the ﬁrst time
after 2iM insertions. For example, after M insertions we
bulk-load R0 (M keys); after 2M insertions we bulk-load
R1 (2M keys) and delete R0; after 3M insertions we again
bulk-load R0 (M keys); after 4M insertions we bulk-load
R2 (4M keys) and delete R0 and R1, etc. Lucene’s insertion
performance is comparable to that of RSCAS, but insertion
into Postgres’ B+ tree are expensive in comparison.3 This
is because insertions into Postgres’ B+ trees are executed

New keys are ﬁrst inserted into the in-memory trie RM
fore they are written to disk when RM

0 be-
0 overﬂows. We eval-

3 We measure insertion performance in Postgres by importing a
dataset twice: once with index and once without index, and then we
measure the difference in runtime

23

in-place, causing many random updates, while insertions in
RSCAS and Lucene are done out-of-place.

8.4.4 Evaluating the Cost Model

We evaluate the cost model from Lemma 5 that measures
the I/O overhead of our bulk-loading algorithm for a uni-
form data distribution and compare it to the I/O overhead
of bulk-loading the real-world GitLab dataset. The I/O over-
head is the number of page transfers to read/write interme-
diate results during bulk-loading. We multiply the I/O over-
head with the page size to get the number of bytes that are
transferred to and from disk. The cost model in Lemma 5
has four parameters: N , M , B, and f (see Section 5.4).
We set fanout f = 10 since this is the average fanout of
a node in RSCAS for the GitLab dataset, see Figure 10a.
The cost model assumes that M (B) keys ﬁt into memory (a
16 KB
80 B ⌉ = 205, where 16 KB
page). Therefore, we set B = ⌈
is the page size and 80 is the average key length (see Sec-
tion 8.2). Similarly, if the memory size is 8 GB we can store
M = ⌈

8 GB
80 B ⌉ = 100 million keys in memory.

In Figure 18a we compare the actual and the estimated
I/O overhead to bulk-load RSCAS as we increase the num-
ber of keys N in the dataset, keeping the memory size ﬁxed
at M = 100 million keys. The estimated and actual cost are
close and within 15% of each other. In Figure 18b we vary
the memory size and ﬁx the full GitLab dataset as input.
The estimated cost is constant from M = 100 to M = 400
N
million keys because of the ceiling operator in logf ⌈
M ⌉ to
compute the number of levels of the trie in Lemma 5. If we
increase M to 800 million keys, the trie in the cost model
has one level less before partitions ﬁt entirely into memory
and therefore the I/O overhead decreases and remains con-
stant thereafter since only the root partition does not ﬁt into
main memory.

]

B
T
[

d
a
e
h
r
e
v
O
O

/
I

2

1

0

Actual I/O overhead

Estimated I/O overhead

2

1

0

100
1600
400
(b) Memory Keys M [×106]

2

0
(a) Nr Keys N [×109]

6

4

Fig. 18: Bulk-Loading cost model

In Figure 19a we compare the actual and the estimated
I/O overhead to insert N keys one-by-one into RSCAS, set-
ting M = 100×106. We compute the estimated I/O overhead
by multiplying the amortized cost of one insertion accord-
ing to Lemma 7 with the number of keys N . We observe a
staircase pattern for the actual I/O overhead because of the
repeated bulk-loading when the in-memory trie overﬂows

after every M insertions. Next we ﬁx N = 600 million keys
and increase M in Figure 19b. In general, increasing M de-
creases the actual and estimated overhead because less data
must be bulk-loaded. But this is not always the case. For
example, the actual I/O overhead increases from M = 200
to M = 300 million keys. To see why, we have to look at
the tries that need to be bulk-loaded. For M = 200 we cre-
ate three tries: after M insertions R0 (200 mil.), after 2M
insertions R1 (400 mil.), and after 3M insertions again R0
(200 mil.) for a total of 800 million bulk-loaded keys. For
M = 300 we create only two tries: after M insertions R0
(300 mil.) and after M insertions R1 (600 mil.) for a total of
900 million bulk-loaded keys.

]

B
T
[

d
a
e
h
r
e
v
O
O

/
I

0.3

0.2

0.1

0

Actual I/O overhead

Estimated I/O overhead

0.3

0.2

0.1

200

400

600

(a) Nr Keys N [×106]

0

200

600
(b) Memory Keys M [×106]

400

Fig. 19: Insertion cost model

8.4.5 Index Size

Figure 20 shows the size of the RSCAS, Lucene, and Post-
gres indexes for our four datasets. The RSCAS index is be-
tween 30% to 80% smaller than the input size (i.e., the size
of the indexed keys). The savings are highest for the XMark
dataset because it has only seven unique paths and therefore
the RSCAS trie has fewer nodes since there are fewer dis-
criminative bytes. But even for a dataset with a large num-
ber of unique paths, e.g., the GitLab dataset, RSCAS is 43%
smaller than the input. RSCAS’s size is comparable to that
of the other indexes since all the indexes require space linear
in the number of keys in the input.

]

B
G

[

e
c
a
p
S

RSCAS

Lucene

Postgres (VP)

Postgres (PV)

600

400

200

0

1

0.5

1

0.5

(a) GitLab

0
(b) ServerFarm

0

1

0.5

0

(c) Amazon

(d) XMark

Fig. 20: Space consumption

9 Conclusion and Outlook

We propose the RSCAS index, a robust and scalable index
for semi-structured hierarchical data. Its robustness is rooted
in a well-balanced integration of paths and values in a single

24

index using a new dynamic interleaving. The dynamic inter-
leaving does not prioritize a particular dimension (paths or
values), making the index robust against queries with high
individual selectivities that produce large intermediate re-
sults and a small ﬁnal result. We use an LSM-design to scale
the RSCAS index to applications with a high insertion rate.
We buffer insertions in a memory-optimized RSCAS trie
that we continuously ﬂush to disk as a series of read-only
disk-optimized RSCAS tries. We evaluate our index analyti-
cally and experimentally. We prove RSCAS’s robustness by
showing that it has the smallest average query runtime over
all queries among interleaving-based approaches. We evalu-
ate RSCAS experimentally on three real-world datasets and
one synthetic data. Our experiments show that the RSCAS
index outperforms state-of-the-art approaches by several or-
ders of magnitude on real-world and synthetic datasets. We
show-case RSCAS’s scalability by indexing the revisions
(i.e., commits) of all public GitLab repositories archived by
Software Heritage, for a total of 6.9 billion modiﬁed ﬁles in
120 revisions.

In our future work we plan to support deletions. In the
in-memory RSCAS trie we plan to delete the appropriate
leaf node and efﬁciently restructure the trie if necessary. To
delete keys from the disk-resident RSCAS trie we plan to
ﬂag the appropriate leaf nodes as deleted to avoid expen-
sive restructuring on disk. As a result, queries need to ﬁlter
ﬂagged leaf nodes. Whenever a new disk-based trie is bulk-
loaded, we remove the elements previously ﬂagged for dele-
tion. It would also be interesting to implement RSCAS on
top of a high-performance platform, such as an LSM-tree-
based KV-store, the main challenge would be to adapt range
ﬁlters to our complex interleaved queries.

References

1. Apache Lucene. https://lucene.apache.org/ (2021).

[accessed September 2021]

2. Abramatic, J., Cosmo, R.D., Zacchiroli, S.: Building the universal
archive of source code. Commun. ACM 61(10), 29–31 (2018)
3. Achakeev, D., Seeger, B.: Efﬁcient bulk updates on multiversion

B-trees. PVLDB 6(14), 1834–1845 (2013)

4. Aggarwal, A., Vitter, J.S.: The input/output complexity of sorting
and related problems. Commun. ACM 31(9), 1116–1127 (1988)
5. Alsubaiee, S., et al.: AsterixDB: A scalable, open source BDMS.

PVLDB 7(14), 1905–1916 (2014)

6. Apache:

Apache

Jackrabbit

https://jackrabbit.apache.org/oak/
[accessed September 2021]

Oak.
(2021).

7. Arge, L.: The buffer tree: A technique for designing batched ex-

ternal data structures. Algorithmica 37(1), 1–24 (2003)

8. den Bercken, J.V., Seeger, B., Widmayer, P.: A generic approach
to bulk loading multidimensional index structures. In: VLDB, pp.
406–415 (1997)

9. Brunel, R., Finis, J., Franz, G., May, N., Kemper, A., Neumann, T.,
F¨arber, F.: Supporting hierarchical data in SAP HANA. In: ICDE,
pp. 1280–1291 (2015)

10. Chang, F., Dean, J., Ghemawat, S., Hsieh, W.C., Wallach, D.A.,
Burrows, M., Chandra, T., Fikes, A., Gruber, R.E.: Bigtable: A

distributed storage system for structured data. ACM Trans. Com-
put. Syst. 26(2), 4:1–4:26 (2008)

11. Cooper, B.F., Sample, N., Franklin, M.J., Hjaltason, G.R., Shad-
In: VLDB, pp.

mon, M.: A fast index for semistructured data.
341–350 (2001)

12. DeCandia, G., et al.: Dynamo: Amazon’s highly available key-

value store. In: ACM SOSP, pp. 205–220. ACM (2007)

13. Di Cosmo, R., Zacchiroli, S.: Software heritage: Why and how to

preserve software source code. In: iPRES (2017)

14. Finis, J., Brunel, R., Kemper, A., Neumann, T., F¨arber, F., May, N.:
DeltaNI: an efﬁcient labeling scheme for versioned hierarchical
data. In: SIGMOD, pp. 905–916 (2013)

15. Finis, J., Brunel, R., Kemper, A., Neumann, T., May, N., F¨arber, F.:
Indexing highly dynamic hierarchical data. PVLDB 8(10), 986–
997 (2015)

16. Gilad, E., Bortnikov, E., Braginsky, A., Gottesman, Y., Hillel, E.,
Keidar, I., Moscovici, N., Shahout, R.: Evendb: Optimizing key-
value storage for spatial locality. In: Proc. of the 15th Europ. Conf.
on Computer Systems (EuroSys’20) (2020)

17. Goldman, R., Widom, J.: DataGuides: Enabling query formulation
and optimization in semistructured databases. In: VLDB, pp. 436–
445 (1997)

18. He, R., McAuley, J.J.: Ups and downs: Modeling the visual evo-
lution of fashion trends with one-class collaborative ﬁltering. In:
WWW, pp. 507–517 (2016)

19. Kanne, C., Moerkotte, G.: The importance of sibling clustering
for efﬁcient bulkload of XML document trees. IBM Syst. J. 45(2),
321–334 (2006)

20. Kaushik, R., Krishnamurthy, R., Naughton, J.F., Ramakrishnan,
R.: On the integration of structure indexes and inverted lists. In:
SIGMOD, pp. 779–790 (2004)

21. Leis, V., Kemper, A., Neumann, T.: The adaptive radix tree: ART-
In: ICDE, pp. 38–49

ful indexing for main-memory databases.
(2013)

22. Luo, C., Carey, M.J.: On performance stability in LSM-based stor-

age systems. Proc. VLDB Endow. 13(4), 449–462 (2019)

23. Luo, C., Carey, M.J.: LSM-based storage techniques: a survey.

VLDB J. 29(1), 393–418 (2020)

24. Luo, S., Chatterjee, S., Ketsetsidis, R., Dayan, N., Qin, W., Idreos,
S.: Rosetta: A robust space-time optimized range ﬁlter for key-
value stores. In: SIGMOD ’20, pp. 2071–2086 (2020)

25. Markl, V.: MISTRAL: processing relational queries using a multi-
dimensional access technique. Ph.D. thesis, Technical University
of Munich (1999)

26. Mathis, C., H¨arder, T., Schmidt, K., B¨achle, S.: XML indexing
and storage: fulﬁlling the wish list. Computer Science - R&D
30(1) (2015)

27. Matsunobu, Y., Dong, S., Lee, H.: MyRocks: LSM-tree database
storage engine serving Facebook’s social graph. Proc. VLDB En-
dow. 13(12), 3217–3230 (2020)

28. Merkle, R.C.: A digital signature based on a conventional encryp-

tion function. In: CRYPTO, vol. 293, pp. 369–378 (1987)
29. Milo, T., Suciu, D.: Index structures for path expressions.

In:

ICDT, pp. 277–295 (1999)

30. Morrison, D.R.: PATRICIA - practical algorithm to retrieve infor-
mation coded in alphanumeric. J. ACM 15(4), 514–534 (1968)
31. Morton, G.: A computer oriented geodetic data base; and a new

technique in ﬁle sequencing. Tech. rep., IBM Ltd. (1966)

32. Nickerson, B.G., Shi, Q.: On k-d range search with patricia tries.

SIAM J. Comput. 37(5), 1373–1386 (2008)

33. O’Neil, P.E., Cheng, E., Gawlick, D., O’Neil, E.J.: The log-
structured merge-tree (LSM-Tree). Acta Informatica 33(4), 351–
385 (1996)

34. Orenstein, J.A., Merrett, T.H.: A class of data structures for asso-

ciative searching. In: PODS, pp. 181–190 (1984)

35. Pietri, A., Spinellis, D., Zacchiroli, S.: The software heritage graph
dataset: Large-scale analysis of public software development his-
tory. In: MSR, pp. 138–142 (2020)

25

36. Procopiuc, O., Agarwal, P.K., Arge, L., Vitter, J.S.: Bkd-tree: A

dynamic scalable kd-tree. In: SSTD, pp. 46–65 (2003)

37. Ramsak, F., Markl, V., Fenk, R., Zirkel, M., Elhardt, K., Bayer, R.:
Integrating the UB-Tree into a database system kernel. In: VLDB,
pp. 263–272 (2000)

38. Rousseau, G., Cosmo, R.D., Zacchiroli, S.: Software provenance
tracking at the scale of public source code. Empir. Softw. Eng.
25(4), 2930–2959 (2020)

39. Samet, H.: Foundations of multidimensional and metric data struc-
tures. Morgan Kaufmann series in data management systems.
Academic Press (2006)

40. Schmidt, A., Waas, F., Kersten, M.L., Carey, M.J., Manolescu, I.,
Busse, R.: XMark: A benchmark for XML data management. In:
VLDB, pp. 974–985 (2002)

41. Shanbhag, A., Jindal, A., Madden, S., Quian´e-Ruiz, J., Elmore,
A.J.: A robust partitioning scheme for ad-hoc query workloads.
In: SoCC, pp. 229–241 (2017)

42. Shukla, D., et al.: Schema-agnostic indexing with Azure Docu-

mentDB. PVLDB 8(12), 1668–1679 (2015)

43. Wellenzohn, K., B¨ohlen, M.H., Helmer, S.: Dynamic interleaving
of content and structure for robust indexing of semi-structured hi-
erarchical data. PVLDB 13(10), 1641–1653 (2020)

44. Wellenzohn, K., Popovic, L., B¨ohlen, M., Helmer, S.: Inserting
keys into the robust content-and-structure (RCAS) index. In: AD-
BIS, pp. 121–135 (2021)

45. Zhang, H., Lim, H., Leis, V., Andersen, D.G., Kaminsky, M., Kee-
ton, K., Pavlo, A.: Surf: Practical range query ﬁltering with fast
succinct tries. In: SIGMOD ’18, pp. 323–336 (2018)

46. Zhong, W., Chen, C., Wu, X., Jiang, S.: REMIX: efﬁcient range
query for lsm-trees. In: 19th USENIX Conf. on File and Storage
Technologies, (FAST’21), pp. 51–64 (2021)

A Proofs

)

{

=

K, D
(

Proof (Lemma 1) Consider the ψ-partitioning ψ
K1, . . . ,
. Let Ki ≠ Kj be two different partitions of K and let k′ ∈
Km
}
Ki and k′′ ∈ Kj be two keys belonging to these partitions. Since
the paths and values of our keys are binary-comparable [21], the most
signiﬁcant byte is the ﬁrst byte and the least signiﬁcant byte is the
last byte. Therefore, k′.D is smaller (greater) than k′′.D iff k′.D is
smaller (greater) than k′′.D at the ﬁrst byte for which the two keys
differ in dimension D. All keys in K have the same longest common
in dimension D and their discriminative byte is
preﬁx s = lcp
)
. By Deﬁnition 6, keys k′ and k′′ share the
+ 1 = dsc
g =
K, D
s
)
(
same longest common preﬁx s in D, i.e., k′.D
1, g−
[
≠ k′′.D
1
g
.
]
[
]
Therefore, if k′.D
, we know that k′.D < k′′.D (and
]
similarly for >). By the correctness constraint in Deﬁnition 6, all keys
in Ki have the same value at k′.D
and are therefore all smaller or
all greater than the keys in Kj, who all have the same value k′′.D
.
]
◻

= k′′.D
1, g−1
]
[
= s and they differ at the discriminative byte k′.D
g
[
< k′′.D

K, D
(

g
[

g
[

g
[

g
[

]

]

]

∣

∣

K, D
dsc
(
[

Proof (Lemma 2) By Deﬁnition 6, all keys k in a partition Ki have
for the discriminative byte of K in
the same value k.D
)]
K, D
dimension D. Therefore, dsc
is no longer a discriminative byte
)
(
. Let Ki ≠ Kj be two differ-
in Ki, instead dsc
K, D
Ki, D
> dsc
)
(
)
(
Ki ∪Kj , D
ent partitions. Again by Deﬁnition 6, we know that dsc
=
(
K, D
since any two keys from these two partitions differ at byte
dsc
)
(
− 1 concludes the
K, D
K, D
. Substituting
= dsc
dsc
(
)
(
proof that ψ
◻

K, D
(
is preﬁx-preserving in D.

lcp

)∣

)

)

∣

K, D
(

)

Proof (Lemma 3) Since not all keys in K are equal in dimension D,
we know there must be at least two keys k1 and k2 that differ in di-
mension D at the discriminative byte g = dsc
K, D
≠
(
. According to the disjointness constraint of Deﬁnition 6, k1
k2.D
]
K, D
and k2 must be in two different partitions of ψ
(
≥ 2.
◻

, i.e., k1.D
)

. Hence,
)

K, D
(

g
[

g
[

ψ

]

∣

)

K, D
≠ dsc
(

Proof (Lemma 4) The ﬁrst line states that Ki ⊂ K is one of the parti-
tions of K. From Deﬁnition 6 it follows that the value k.D
)]
is the same for every key k ∈ Ki. From Deﬁnition 5 it follows that
. By removing one or more keys from K to
Ki, D
dsc
)
(
get Ki, the keys in Ki will become more similar compared to those in
K. That means, it is not possible for the keys in Ki to differ in a posi-
K, D
tion g < dsc
K, D
for any
)
(
)
(
dimension D (so this also holds for D: dsc
K, D
Ki, D
).
≮ dsc
)
)
(
(
Ki, D
K, D
K, D
and dsc
Thus dsc
.
> dsc
≥ dsc
◻
(
(
)
(

Ki, D
. Consequently, dsc
(
)

K, D
dsc
(
[

Ki, D
(

≮ dsc

)

)

)

Proof (Theorem 1) We begin with a brief outline of the proof. We show
for a level l that the costs of query Q and complementary query Q′ on
level l is smallest with the dynamic interleaving. That is, for a level
l we show that ∏l
+ ∏l
is smallest with the
vector φDY =
of our dynamic interleaving. Since this
holds for any level l, it also holds for the sum of costs over all levels l,
1 ≤ l ≤ h, and this proves the theorem.

o ⋅ ςφi )
i=1(
V, P, V, P, . . .
)
(

i=1(

o ⋅ ς ′

φi )

We only look at search trees with a height h ≥ 2, as for h = 1 we
do not actually have an interleaving (and the costs are all the same).
W.l.o.g., we assume that the ﬁrst level of the search tree always starts
with a discriminative value byte, i.e., φ1 = V . Let us look at the cost
for one speciﬁc level l for query Q and its complementary query Q′.
We distinguish two cases: l is even or l is odd.

P )

l/2
V ς

, which is equal to ol

ςV ⋅ ςP . . . ςV ⋅ ςP
(
V ⋅ς ′

l is even: The cost for a perfectly alternating interleaving for Q for
level l is equal to ol
, while the cost for Q′ is equal
)
to ol
ς ′
V ⋅ς ′
P . . . ς ′
ςP ⋅ςV . . . ςP ⋅ςV
. This
(
)
(
l/2
l/2
is the same cost as for Q, so adding the two costs gives us 2olς
V ς
P .
For a non-perfectly alternating interleaving with the same number
of ςV and ςP multiplicands up to level l we have the same cost as for
l/2
our dynamic interleaving, i.e., 2olς
P . Now let us assume that the
number of ςV and ςP multiplicands is different for level l (there must
be at least one such level l). Assume that for Q we have r multiplicands
of type ςV and s multiplicands of type ςP , with r + s = l and, w.l.o.g.,
r > s. This gives us olς s
+
ς r−s
for the cost.
P )

We have to show that 2olς

ς r−s
V
all values are greater than zero, this is equivalent to 2ς
ς r−s
V + ς r−s
ς l−2s
V
b = ς
which is always true.

+ ς r−s
P )
l/2−s
l/2−s
ς
≤
P
V
P . The right-hand side can be reformulated: ς r−s
V + ς r−s
=
P
l/2−s
l/2−s
+ ς l−2s
. Setting a = ς
and
P
V
P
2,
, this boils down to showing 2ab ≤ a2 + b2 ⇔ 0 ≤
l/2−s
a − b
P
)
(

l/2
P ≤ olς s

P ς r−s
V

P ς r−s
P

l/2−s
ς
V

l/2−s
ς
P

= olς s

+ olς s

l/2−s
V

ς r−s
V

V ς s

V ς s

V ς s

V ς s

l/2
V ς

. As

= ς

P (

P (

+ ς

⌋

P

)

ςP

P (

l
2
⌉
/
⌈

ς ⌊l/2⌋−s
P

ςV + ς ⌊l/2⌋−s
P

.
)
ςV + ςP

multiplicands of type ςP . This results in olς ⌊l/2⌋

For a non-perfectly alternating interleaving, we again have olς s

l
2
⌊
/
for the sum of costs for Q and Q′.

l is odd: W.l.o.g. we assume that for computing the cost for a
multiplicands of
V ς ⌊l/2⌋

perfectly alternating interleaving for Q, there are
type ςV and
ςV + ςP
(
V ς s
P
ς r−s
V + ς r−s
with r + s = l and r > s, which can be reformulated to
P )
(
ς ⌊l/2⌋−s
ς ⌊l/2⌋−s
olς s
V ς s
V
V
What is left to prove is olς ⌊l/2⌋

V ς ⌊l/2⌋
V ς s
P (
P (
, which is equivalent to ς ⌊l/2⌋−s
)
ς ⌊l/2⌋−s
P
− s, this means showing that axbx

ς ⌊l/2⌋−s
V
ς ⌊l/2⌋−s
ς ⌊l/2⌋−s
ςV + ς ⌊l/2⌋−s
ς ⌊l/2⌋−s
ςP
P
P
P
V
ςV + ς ⌊l/2⌋−s
ς ⌊l/2⌋−s
≤ ς ⌊l/2⌋−s
ςP . Substituting a =
ςV + ςP
P
V
V
)
(
a + b
ςV , b = ςP , and x =
l
≤
2
)
(
/
⌋
⌊
a2x+1 + b2x+1 ⇔ 0 ≤ a2x+1 + b2x+1 − axbx
a + b
. Factorizing this
)
(
bx+1 −
ax+1 − bx+1
bx − ax
ax − bx
or
polynomial gives us
)
(
(
ax+1
ax+1 − bx+1
ax − bx
, the argument for the
. We look at
)
(
)
other factorization follows along the same lines. This term can only
become negative if one factor is negative and the other is positive. Let
us ﬁrst look at the case a < b: since 0 ≤ a, b ≤ 1, we can immediately
follow that ax < bx and ax+1 < bx+1, i.e., both factors are negative.
Analogously, from a > b (and 0 ≤ a, b ≤ 1) immediately follows
ax > bx and ax+1 > bx+1, i.e., both factors are positive.
◻

≤ olς s

)(
)(

)(

)

V

)∣

Proof (Theorem 2) We assume a tree with fanout o and height h. With
the dynamic interleaving, the dimension on each level alternates, i.e.,

26

φDY =
V, P, V, P, . . .
. We need to show that the cost for every query
)
(
in a set of complementary queries Q is minimal with φDY. Thus, we
show that this inequality holds:

∀φ ∶ ∑

(ςP ,ςV )∈Q

∑
(ςP ,ςV )∈Q

o, h, φDY, ςP , ςV
̂C
(

)

≤

o, h, φ, ςP , ςV
̂C
(

)

First, we double the cost on each side:

∀φ ∶ 2 × ∑

(ςP ,ςV )∈Q

o, h, φDY, ςP , ςV
̂C
(

)

≤

2 × ∑

(ςP ,ςV )∈Q

o, h, φ, ςP , ςV
̂C
(

)

This is the same as counting the cost of each query and its complemen-
tary query twice:

∀φ ∶ ∑

(ςP ,ςV )∈Q ( ̂C
(ςP ,ςV )∈Q ( ̂C

∑

o, h, φDY, ςP , ςV
(

o, h, φDY, ςV , ςP
+ ̂C
(

)

))

≤

o, h, φ, ςP , ςV
(

o, h, φ, ςV , ςP
+ ̂C
(

)

))

Since by Theorem 1 each summand on the left side is smaller than or
equal to its corresponding summand on the right side, the sum on the
left side is is smaller than or equal to the sum on the right side.
◻

∏l

o ⋅ ς ′

i=1(

Proof (Theorem 3) Similar to the proof of Theorem 1, we show that
− ∏l
for every level l,
o ⋅ ςφi )
is smallest for the
φi )∣
∣
V, P, V, P, . . .
dynamic interleaving vector φDY =
.
)
(
Again, we only look at search trees with a height h ≥ 2 and,
w.l.o.g., we assume that the ﬁrst level of the search tree always starts
with a discriminative value byte, i.e., φ1 = V . Let us look at the differ-
ence in costs for one speciﬁc level l for query Q and its complementary
query Q′. We distinguish two cases: l is even or l is odd.

i=1(

l is even: The cost for a perfectly alternating interleaving for Q for
level l is equal to ol
, while the cost for Q′ is equal
)
to ol
P . . . ς ′
V ⋅ ς ′
ς ′
.
)
(
This is the same cost as for Q, so subtracting one cost from the other
gives us 0.

ςV ⋅ ςP . . . ςV ⋅ ςP
(
V ⋅ ς ′

ςP ⋅ ςV . . . ςP ⋅ ςV
(

, which is equal to ol

P )

For a non-perfectly alternating interleaving with the same number
of ςV and ςP multiplicands up to level l we have the same difference in
costs as for our dynamic interleaving, i.e., 0. Now let us assume that the
number of ςV and ςP multiplicands is different for level l (there must
be at least one such level l). Assume that for Q we have r multiplicands
of type ςV and s multiplicands of type ςP , with r + s = l and, w.l.o.g.,
r > s. This gives us
for the absolute
value of the difference in costs, which is always greater than or equal
to 0.

P ς r−s
P ∣

P ς r−s
V

− olς s

V ς s

V ς s

olς s

∣

∣

⌉

P

=

P (

olς s

olς s

V ς s

l
2
/
⌈

l is odd: W.l.o.g. we assume that for computing the cost for a per-
multiplicands of
V ς ⌊l/2⌋
olς ⌊l/2⌋

multiplicands of type ςP . This results in
l
2
⌊
∣
⌋
/
for the difference in costs between Q and Q′.

fectly alternating interleaving for Q, there are
type ςV and
ςV − ςP
(
ς r−s
P ς r−s
ς r−s
V
P ∣
V
r > s, which can be reformulated to
ς ⌊l/2⌋−s
.
P

)∣
For a non-perfectly alternating interleaving, we again have
− olς s
V ς s

V ς s
P
with r + s = l and
ς ⌊l/2⌋−s
ς ⌊l/2⌋−s
ςV −
V
V

− ς r−s
P )∣
olς s
V ς s
P (

ς ⌊l/2⌋−s
P

ςP
What is left to prove is
ςV − ς ⌊l/2⌋−s
P

ςV −ςP

∣
ς ⌊l/2⌋−s
P

olς ⌊l/2⌋
ςP

V ς ⌊l/2⌋
P (

ς ⌊l/2⌋−s
≤
V
ς ⌊l/2⌋−s
. W.l.o.g., assume that ςV > ςP (if
V
ςV < ςP , we just have to switch the minuend with the subtrahend in
the subtractions and the roles of ςV and ςP in the following), then,
as all numbers in the inequality are greater than or equal to 0, we
have to prove olς ⌊l/2⌋
ςV −
ς ⌊l/2⌋−s
ς ⌊l/2⌋−s
≤
P
P

V ς ⌊l/2⌋
P (
P (
, which is equivalent to ς ⌊l/2⌋−s
)

ς ⌊l/2⌋−s
V
ςV −ςP
(

ς ⌊l/2⌋−s
V
ς ⌊l/2⌋−s
P

ςV − ςP

≤ olς s

V ς s

V ς s

olς s

P (

ςP

)∣

)∣

)∣

)

)

V

∣

∣

∣

ς ⌊l/2⌋−s
V
l
2
/
⌊

ςV − ς ⌊l/2⌋−s
ς ⌊l/2⌋−s
P
P
− s, this means showing that axbx

ς ⌊l/2⌋−s
ςP . Substituting a = ςV , b = ςP ,
V
≤ a2x+1 −
and x =
a − b
(
)
⌋
b2x+1 ⇔ ax+1bx − axbx+1 ≤ a2x+1 − b2x+1 ⇔ b2x+1 − axbx+1 ≤
a2x+1 − ax+1bx ⇔ bx+1
ax − bx
. Since a > b,
)
(
the left-hand side of the inequality is always less than 0, while the
right-hand side is greater than 0.
◻

bx − ax
(

≤ ax+1

)

N
M ⌉⌉

⌈

pages.

logf ⌈
Proof (Lemma 5) There are
levels before partitions ﬁt
⌈
completely into memory, at which point there is no further disk I/O
except writing the ﬁnal output (the index) to disk. At each level we
read and write
◻

N
B ⌉
Proof (Lemma 6) We assume that ψ
the ﬁrst contains one key and the second contains all other keys. Thus,
on each level of the partitioning we have two partitions Li,1 and Li,2
= N − i. Partition Li,1 occupies one
Li,1
such that
page on disk. Li,2 occupies
pages on disk. Setting the latter to
(i.e., the number of pages that ﬁt into memory) and solving for i
B is the smallest number of levels i such that
◻

⌈
shows that i = N −
Li,2 ﬁts completely into memory.

∣
N−i
B ⌉

L, D
(

= 1 and

returns two partitions where

M
B ⌉

M
B ⌉

Li,2

)

⌈

⌈

∣

∣

∣

(

N
B )

pages are transferred and there are O

Proof (Theorem 4) The lower-bound follows from Lemma 5. In each
level O
levels in
the partitioning. The base of the logarithm is upper-bounded by f =
28 since we ψ-partition at the granularity of bytes. The upper-bound
follows from Lemma 6. In each level O
pages are transferred and
there are O
◻

N
B )
levels in the worst case.

N
M ))

log
(

(

(

N − M
(

)

Proof (Lemma 7) A key moves through a series of indexes in our
indexing pipeline. First, it is stored in RM
at no I/O cost and after
0
that, it moves through a number of disk-based indexes R0, . . . , Rk.
Importantly, when a key in an index Ri is moved, it always moves
to a larger index Rj, j > i. After inserting N keys there exist at
N
log2
most O
RSCAS indexes, hence a key is moved at most
M ))
(
(
N
log2
times. The amortized I/O overhead when all N keys
O
M ))
(
(
are bulk-loaded at once is 1
. Hence, the amortized
)
I/O overhead of a single insertion in a sequence of N insertions is
O
◻

N, M, B
(

N × cost

×

1
N × cost

N, M, B
(

.
))

log2
(

(

N
M )

B Tuning τ

The following provides more details on how to calibrate the partition-
ing threshold τ discussed in Section 8.4.1. In particular, we quantify
the effects leading to the shape of the curves depicted in Figure 15. Al-
though we have not been able to develop a closed formula (so far), the
results below are important steps towards such a formula.

The diagrams in Figure 15(a) and Figure 15(b), showing the im-
pact of τ on the number of nodes and the overall time for bulk-loading
the index, are not particularly interesting for the calibration, as there
is a clear relationship: the larger the value of τ , the faster we can stop
the partitioning and the smaller the number of created nodes. Conse-
quently, the execution time for bulk-loading goes down, as we can skip
more and more partitioning steps.

Figure 15(c) and Figure 15(d) are much more interesting, as we
have two effects counteracting each other in both ﬁgures. We start with
Figure 15(d), showing the impact of τ on the index size. First of all,
τ inﬂuences the total amount of metadata stored on each disk page.
Clearly, the fewer leaf nodes per page we have, the smaller the amount
of this metadata. Assuming that we actually ﬁll every leaf node with
exactly τ key sufﬁxes and that we store d bytes of metadata, the over-
head is Np⋅d
per disk page (with Np being the number of input keys
per disk page). This reciprocal function ﬂattens out quickly and ex-
plains why the curve in Figure 15(d) drops at the beginning. However,
there is a second effect at play. The more key sufﬁxes share a leaf node
(i.e., the larger the value of τ ), the higher the probability that they share
a common preﬁx that has not been factored out, because we stopped the

τ

27

partitioning early. We found estimating the expected value of overlap-
ping preﬁxes in leaf nodes very hard to do, as it depends on the data
distribution. A simpliﬁed version can be computed as follows. Assume
we have n different preﬁxes x1, x2, . . . , xn that appear in the key suf-
ﬁxes stored in leaf nodes and that all preﬁxes have the same likelihood
of appearing. Moreover, let u be the number of unique preﬁxes in a
leaf node, then we have τ − u preﬁxes that are stored multiple times
(the ﬁrst time a preﬁx shows up in a leaf node, it is ﬁne, but every sub-
sequent appearance adds to the overhead). For a leaf node, let Ri be
a random variable that is 1 if xi is in the node, and 0 otherwise. Then
the number X of different preﬁxes found in the node is ∑n
i=1 Ri. Due
to the linearity of expectation, E
X
. The probability
[
]
of at least one preﬁx xi appearing in a leaf node is equal to one mi-
τ .
nus the probability that there is none, which is equal to 1 −
n−1
Thus, E
τ
1 −
= n
X
, which means that the expected over-
n )
)
(
[
]
head is τ − E
X
per leaf node. This rises slowly for small values of
]
[
τ , but ascends more quickly for larger values of τ . Nevertheless, this is
still a simpliﬁcation, as it counts the preﬁxes rather than summing their
lengths.

i=1 E
Ri
[

n−1
n )

= ∑n

(

(

]

We now turn to the impact of the threshold τ on the query runtime
(Figure 15(c)). The threshold determines how many internal nodes we
have that distinguish subsets of keys. For τ = 1, when evaluating a
query, we visit a path down the trie containing all discriminative bytes.
When increasing τ , the path shortens, as we skip the ﬁnal discrimi-
native bytes. Mapping τ to the path length is not straightforward, as
this depends on the distribution of the keys again. Assuming that every
discriminative byte splits a set of keys into b subsets and that the full
length of a trie path for τ = 1 is l, the number of internal nodes visited
by a query is equal to l − logb τ . The curve of this function drops at the
beginning, but then quickly ﬂattens out, explaining the left-hand part of
Figure 15(c). The second effect of increasing τ is that we are accessing
more and more keys that are not relevant for our query. The irrelevant
keys just happen to be in the same leaf node, because we no longer
distinguish them from the relevant keys. There is at least one key in the
node that satisﬁes the query, for the other keys we compute the proba-
bility that they are relevant. We cannot just use the selectivity σc of the
complete query, since we need the selectivity σs of the sufﬁx stored
in the leaf node. Thus, the expected number of keys in a leaf node not
τ − 1
. Assuming uniform
satisfying the query predicate is
)
)(
distribution and independence, we can estimate σs given σc: if the
length of the sufﬁx in the leaf node is 1
s of the total length of a key,
0, 1
then σs = s√σc. Since all selectivities are within the range of
,
]
[
τ − 1
1 − σs
σs ≥ σc, which means that
)
(
is usually a relatively ﬂat ascending line. This explains the shape of the
curve on the right-hand side of Figure 15(c).

1 − σs
(

1 − σs
(

1 − σc
(

, so
)

)(

≤

)

While the distribution of the keys has a direct impact on all of
these parameters, as far as we can see, the total number of input keys
does not directly inﬂuence them. Consequently, we can use a sample
to calibrate τ (as we have done in Section 8.4.1).

28

