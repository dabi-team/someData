Watermarking PRFs against Quantum Adversaries

Fuyuki Kitagawa 1

Ryo Nishimaki 1

1 NTT Corporation, Tokyo, Japan
{fuyuki.kitagawa.yh,ryo.nishimaki.zk}@hco.ntt.co.jp

Abstract

We initiate the study of software watermarking against quantum adversaries. A quantum adversary
generates a quantum state as a pirate software that potentially removes an embedded message from a
classical marked software. Extracting an embedded message from quantum pirate software is diﬃcult
since measurement could irreversibly alter the quantum state.
In software watermarking against
classical adversaries, a message extraction algorithm crucially uses the (input-output) behavior
of a classical pirate software to extract an embedded message. Even if we instantiate existing
watermarking PRFs with quantum-safe building blocks, it is not clear whether they are secure against
quantum adversaries due to the quantum-speciﬁc property above. Thus, we need entirely new
techniques to achieve software watermarking against quantum adversaries.

In this work, we deﬁne secure watermarking PRFs for quantum adversaries (unremovability

against quantum adversaries). We also present two watermarking PRFs as follows.

• We construct a privately extractable watermarking PRF against quantum adversaries from the
quantum hardness of the learning with errors (LWE) problem. The marking and extraction
algorithms use a public parameter and a private extraction key, respectively. The watermarking
PRF is unremovable even if adversaries have (the public parameter and) access to the extraction
oracle, which returns a result of extraction for a queried quantum circuit.

• We construct a publicly extractable watermarking PRF against quantum adversaries from indis-
tinguishability obfuscation (IO) and the quantum hardness of the LWE problem. The marking
and extraction algorithms use a public parameter and a public extraction key, respectively. The
watermarking PRF is unremovable even if adversaries have the extraction key (and the public
parameter).

We develop a quantum extraction technique to extract information (a classical string) from a
quantum state without destroying the state too much. We also introduce the notion of extraction-less
watermarking PRFs as a crucial building block to achieve the results above by combining the tool
with our quantum extraction technique.

Keywords: watermarking, pseudorandom function, post-quantum cryptography

2
2
0
2

y
a
M
3
2

]
h
p
-
t
n
a
u
q
[

1
v
4
3
0
1
1
.
5
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
Contents

1 Introduction

1.1 Background . . . .
. . . . .
. . . . .
1.2 Our Result . . . . .
1.3 Technical Overview . . . . .
1.4 More on Related Work . . .

. . . . . .
. . . . . .
. . . . . .
. . . . . .

. . . . .
. . . . .
. . . . .
. . . . .

. . . . . .
. . . . . .
. . . . . .
. . . . . .

. . . . . .
. . . . . .
. . . . . .
. . . . . .

. . . . .
. . . . .
. . . . .
. . . . .

. . . .
. . . .
. . . .
. . . .

1
1
2
3
8

2 Preliminaries

2.1 Quantum Information . . . .
. . . . . .
2.2 Measurement Implementation . . . . .
. . . . . .
2.3 Cryptographic Tools

. . . .

. . . . .
. . . . .
. . . . .

. . . . . .
. . . . . .
. . . . . .

. . . . . .
. . . . . .
. . . . . .

. . . . .
. . . . .
. . . . .

3 Deﬁnition of Quantum Watermarking

3.1 Syntax and Pseudorandomness . . . . .
. . . . .
3.2 Unremovability against Quantum Adversaries . .

. . . . . .
. . . . . .

. . . . . .
. . . . . .

. . . . .
. . . . .

4 Deﬁnition of Extraction-Less Watermarking
4.1 Syntax and Pseudorandomness . . . . .
. . . . . .
4.2 Simulatability for Mark-Dependent Distributions (SIM-MDD Security)

. . . . . .

. . . . .

. . . . .
. . . . .

5 Watermarking PRF from Extraction-Less Watermarking PRF

6 Extraction-Less Watermarking PRF from LWE

7 Extraction-Less Watermarking PRF with Public Simulation from IO

7.1 Puncturable Encryption, Revisited . . .
. . . . .
7.2 Construction of Extraction-less Watermarking PRF with Public Simulation . . .

. . . . . .

. . . . . .

. . . . .

8 Putting Pieces Altogether

A Achieving QSIM-MDD from SIM-MDD

A.1 Semi-Classical One-Way to Hiding (O2H) Lemma . . . . . .
. . . . . .
A.2 Proof

. . . . . .

. . . . . .

. . . . .

. . . . .

.

. . . . . .
. . . . . .

. . . . .
. . . . .

B Puncturable Encryption with Strong Ciphertext Pseudorandomness

. . . . .
B.1 Tools for PE . . . .
. . . . .
. . . . .
B.2 PE Scheme Description . . .
B.3 PE Security Proof .
. . . . .
. . . . .
B.4 Original Ciphertext Pseudorandomness of PE . .

. . . . . .
. . . . . .
. . . . . .

. . . . . .
. . . . . .
. . . . . .
. . . . . .

. . . . . .
. . . . . .
. . . . . .
. . . . . .

. . . . .
. . . . .
. . . . .
. . . . .

10
. . . . 10
. . . . 11
. . . . 15

19
. . . . 19
. . . . 21

23
. . . . 23
. . . . 23

25

28

34
. . . . 34
. . . . 35

43

48
. . . . 48
. . . . 48

50
. . . . 50
. . . . 51
. . . . 52
. . . . 60

1 Introduction

1.1 Background

Software watermarking is a cryptographic primitive that achieves a digital analog of watermarking.
A marking algorithm of software watermarking can embed an arbitrary message (bit string) into a
computer software modeled as a circuit. A marked software almost preserves the functionality of the
original software. An extraction algorithm of software watermarking can extract the embedded message
from a marked software. Secure software watermarking should guarantee that no adversary can remove
the embedded message without signiﬁcantly destroying the functionality of the original software (called
unremovability).

Barak, Goldreich, Impagliazzo, Rudich, Sahai, Vadhan, and Yang [BGI+12] initiate the study
of software watermarking and present the ﬁrst deﬁnition of cryptographically secure software wa-
termarking. Hopper, Molnar, and Wagner [HMW07] also study the deﬁnition of cryptographically
secure watermarking for perceptual objects. However, both works do not present a secure con-
crete scheme. A few works study secure constructions of watermarking for cryptographic prim-
itives [NSS99, YF11, Nis13, Nis19], but they consider only restricted removal strategies. Cohen,
Holmgren, Nishimaki, Wichs, and Vaikuntanathan [CHN+18] present stronger deﬁnitions for software
watermarking and the ﬁrst secure watermarking schemes for cryptographic primitives against arbitrary
removal strategies. After the celebrated work, watermarking for cryptographic primitives have been
extensively studied [BLW17, KW21, QWZ18, KW19, YAL+19, GKM+19, YAYX20, Nis20].

Primary applications of watermarking are identifying ownership of objects and tracing users that
distribute illegal copies. Watermarking for cryptographic primitives also has another exciting application.
Aaronson, Liu, Liu, Zhandry, and Zhang [ALL+21] and Kitagawa, Nishimaki, and Yamakawa [KNY21]
concurrently and independently ﬁnd that we can construct secure software leasing schemes by combining
watermarking with quantum cryptography.1 Secure software leasing [AL21] is a quantum cryptographic
primitive that prevents users from generating authenticated pirated copies of leased software.2 Since
watermarking has such an exciting application in quantum cryptography and quantum computers might
be an imminent threat to cryptography due to rapid progress in research on quantum computing, it is
natural and fascinating to study secure software watermarking in the quantum setting.

In quantum cryptography, building blocks must be quantum-safe such as lattice-based cryptogra-
phy [Reg09]. However, even if we replace building blocks of existing cryptographic primitives/protocols
with quantum-safe ones, we do not necessarily obtain quantum-safe cryptographic primitives/protocols [BDF+ 11,
ARU14]. We sometimes need new proof techniques which are diﬀerent from classical ones due to quan-
tum speciﬁc properties such as no-cloning and superposition access [Wat09, Zha12b, Zha12a, Unr12,
Zha19, CMSZ21]. Even worse, we must consider entirely diﬀerent security models in some settings.
Zhandry [Zha20] studies traitor tracing [CFN94] in the quantum setting as such an example. In quantum
traitor tracing, an adversary can output a quantum state as a pirate decoder. Zhandry shows that we
need new techniques for achieving quantum traitor tracing because running a quantum pirate decoder to
extract information may irreversibly alter the state due to measurement.

Zhandry [Zha20] refers to software watermarking as a cryptographic primitive that has a similar issue
to quantum traitor tracing. However, his work focuses only on traitor tracing and does not study software
watermarking against quantum adversaries. If we use software watermarking in the quantum setting, an
adversary can output a quantum state as a pirate circuit where an embedded message might be removed.
However, previous works consider a setting where an adversary outputs a classical pirate circuit. It is not
clear whether watermarking schemes based on quantum-safe cryptography are secure against quantum

1Precisely speaking, Aaronson et al. achieve copy-detection schemes [ALL+21], which are essentially the same as secure

software leasing schemes.

2Leased software must be a quantum state since classical bit strings can be easily copied.

1

adversaries because we need an entirely new extraction algorithm to extract an embedded message from
a quantum pirate circuit. Thus, the main question in this study is:

Can we achieve secure watermarking for cryptographic primitives against quantum adversaries?

We aﬃrmatively answer this question in this work.

1.2 Our Result

Our main contributions are two-fold. One is the deﬁnitional work. We deﬁne watermarking for
pseudorandom functions (PRFs) against quantum adversaries, where adversaries output a quantum
state as a pirate circuit that distinguishes a PRF from a random function.3 The other one is constructing
the ﬁrst secure watermarking PRFs against quantum adversaries. We present two watermarking PRFs as
follows.

• We construct a privately extractable watermarking PRF against quantum adversaries from the
quantum hardness of the learning with errors (LWE) problem. This watermarking PRF is secure
in the presence of the extraction oracle and supports public marking. That is, the marking
and extraction algorithms use a public parameter and secret extraction key, respectively. The
watermarking PRF is unremovable even if adversaries have access to the extraction oracle, which
returns a result of extraction for a queried quantum circuit.

• We construct a publicly extractable watermarking PRF against quantum adversaries from indistin-
guishability obfuscation (IO) and the quantum hardness of the LWE problem. This watermarking
PRF also supports public marking. That is, the marking and extraction algorithms use a public
parameter and a public extraction key, respectively. The watermarking PRF is unremovable (we do
not need to consider the mark and extraction oracles since it supports public marking and public
extraction).

The former and latter PRFs satisfy weak pseudorandomness and standard (strong) pseudorandomness
even against a watermarking authority, respectively.

We develop a quantum extraction algorithm to achieve the results above. Zhandry [Zha20] presents
a useful technique for extracting information from quantum states without destroying them too much.
However, we cannot simply apply his technique to the watermarking setting. Embedded information
(arbitrary string) is chosen from an exponentially large set in the watermarking setting. On the other
hand, in the traitor tracing setting, we embed a user index, which could be chosen from a polynomially
large set, in a decryption key. Zhandry’s technique is tailored to traitor tracing based on private linear
broadcast encryption (PLBE) [BSW06] where user information is chosen from a polynomially large set
with linear structure. Thus, we extend Zhandry’s technique [Zha20] to extract information chosen from
an exponentially large set. We also introduce the notion of extraction-less watermarking as a crucial
tool to achieve watermarking against quantum adversaries. This tool is a suitable building block for
our quantum extraction technique in our watermarking extraction algorithm. These are our technical
contributions. See Section 1.3 for the detail.

Although this paper focuses on watermarking PRFs against quantum adversaries, it is easy to extend
our deﬁnitions to watermarking public-key encryption (PKE) against quantum adversaries. In particular,
our construction technique easily yields watermarking PKE (where a decryption circuit is marked)
schemes. We will provide the detail of them in a future version.

We also focus on watermarking PRFs with public marking in this paper. However, we can easily

convert our PRFs into ones with private marking. See Remark 3.4 for the detail.

3This deﬁnitional choice comes from the deﬁnition of traceable PRFs [GKWW21]. See Sections 1.3 and 1.4 for the detail.

2

1.3 Technical Overview

Syntax of watermarking PRF. We ﬁrst review the syntax of watermarking PRF used in this work. A
watermarking PRF scheme consists of ﬁve algorithms (Setup, Gen, Eval, Mark, Extract ).4 Setup outputs
a public parameter pp and an extraction key xk. Gen is given pp and outputs a PRF key prfk and a public
tag τ. Eval is the PRF evaluation algorithm that takes as an input prfk and x in the domain and outputs y.
By using Mark, we can generate a marked evaluation circuit that has embedded message m ∈ {0, 1}ℓm
and can be used to evaluate Eval(prfk, x′) for almost all x′. Finally, Extract is the extraction algorithm
supposed to extract the embedded message from a pirated quantum evaluation circuit generated from
the marked evaluation circuit. By default, in this work, we consider the public marking setting, where
anyone can execute Mark. Thus, Mark takes pp as an input. On the other hand, we consider both the
private extraction and the public extraction settings. Thus, the extraction key xk used by Extract is kept
secret by an authority in the private extraction setting and made public in the public extraction setting.

In this work, we allow Extract to take the public tag τ generated with the original PRF key corre-
sponding to the pirate circuit. In reality, we execute Extract for a software when a user claims that the
software is illegally generated by using her/his PRF key. Thus, it is natural to expect we can use a user’s
public tag for extraction. Moreover, pirate circuits are distinguishers, not predictors in this work. As
discussed by Goyal et al. [GKWW21], security against pirate distinguishers is much preferable compared
to security against pirate predictors considered in many previous works on watermarking. In this case, it
seems that such additional information fed to Extract is unavoidable. For a more detailed discussion on
the syntax, see the discussion in Section 3.1.

It is also natural to focus on distinguishers breaking weak pseudorandomness of PRFs when we
consider pirate distinguishers instead of pirate predictors. Goyal et al. [GKWW21] already discussed
this point. Thus, we focus on watermarking weak PRF in this work.

Deﬁnition of unremovability against quantum adversaries. We say that a watermarking PRF scheme
C that has an embedded message m, any
satisﬁes unremovability if given a marked evaluation circuit
adversary cannot generate a circuit such that it is a “good enough circuit”, but the extraction algorithm
fails to output m. In this work, we basically follow the notion of “good enough circuit” deﬁned by Goyal
et al. [GKWW21] as stated above. Let D be the following distribution for a PRF Eval(prfk, ·) : Dom →
Ran.

e

D: Generate b ← {0, 1}, x ← Dom, and y0 ← Ran. Compute y1 ← Eval(prfk, x). Output (b, x, yb).
A circuit is deﬁned as good enough circuit with respect to Eval(prfk, ·) if given (x, yb) output by D, it
can correctly guess b with probability signiﬁcantly greater than 1/2. In other words, a circuit is deﬁned
as good enough if the circuit breaks weak PRF security.

Below, for a distribution D′ whose output is of the form (b, x, y), let MD′ = (M D′,0, M D′,1) be
binary positive operator valued measures (POVMs) that represents generating random (b, x, y) from D′
and testing if a quantum circuit can guess b from (x, y). Then, for a quantum state |ψi, the overall
distinguishing advantage of it for the above distribution D is hψ| M D,0 |ψi. Thus, a natural adaptation
of the above notion of goodness for quantum circuits might be to deﬁne a quantum state |ψi as good if
hψ| M D,0 |ψi is signiﬁcantly greater than 1/2. However, this notion of goodness for quantum circuits
is not really meaningful. The biggest issue is that it does not consider the stateful nature of quantum
programs.

This issue was previously addressed by Zhandry [Zha20] in the context of traitor tracing against
quantum adversaries. In the context of classical traitor tracing or watermarking, we can assume that a
pirate circuit is stateless, or can be rewound to its original state. This assumption is reasonable. If we
have the software description of the pirate circuit, such a rewinding is trivial. Even if we have a hardware

4In this paper, standard math font stands for classical algorithms, and calligraphic font stands for quantum algorithms.

3

box in which a pirate circuit is built, it seems that such a rewinding is possible by hard reboot or cutting
power. On the other hand, in the context of quantum watermarking, we have to consider that a pirate
circuit is inherently stateful since it is described as a quantum state. Operations to a quantum state can
alter the state, and in general, it is impossible to rewind the state into its original state. Regarding the
deﬁnition of good quantum circuits above, if we can somehow compute the average success probability
hψ| M D,0 |ψi of the quantum state |ψi, the process can change or destroy the quantum state |ψi. Namely,
even if we once conﬁrm that the quantum state |ψi is good by computing hψ| M D,0 |ψi, we cannot know
the success probability of the quantum state even right after the computation. Clearly, the above notion of
goodness is not the right notion, and we need one that captures the stateful nature of quantum programs.
In the work on traitor tracing against quantum adversaries, Zhandry [Zha20] proposed a notion of
goodness for quantum programs that solves the above issue. We adopt it. For the above POVMs MD,
let M′
D be the projective measurement {Pp}p∈[0,1] that projects a state onto the eigenspaces of M D,0,
where each p is an eigenvalue of M D,0. M′
D is called projective implementation of MD and denoted
as ProjImp(MD). Zhandry showed that the following process has the same output distribution as MD:

1. Apply the projective measurement M′

D = ProjImp(MD) and obtain p.

2. Output 0 with probability p and output 1 with probability 1 − p.

Intuitively, M′
D project a state to an eigenvector of M D,0 with eigenvalue p, which can be seen as a
quantum state with success probability p. Using M′
D, Zhandry deﬁned that a quantum circuit is Live if
the outcome of the measurement M′
D is signiﬁcantly greater than 1/2. The notion of Live is a natural
extension of the classical goodness since it collapses to the classical goodness for a classical decoder.
Moreover, we can ensure that a quantum state that is tested as Live still has a high success probability. On
the other hand, the above notion of goodness cannot say anything about the post-tested quantum state’s
success probability even if the test is passed. In this work, we use the notion of Live quantum circuits as
the notion of good quantum circuits.

Diﬃculty of quantum watermarking PRF. From the above discussion, our goal is to construct a
watermarking PRF scheme that guarantees that we can extract the embedded message correctly if a
pirated quantum circuit is Live. In watermarking PRF schemes, we usually extract an embedded message
by applying several tests on success probability to a pirate circuit. When a pirate circuit is a quantum
state, the set of tests that we can apply is highly limited compared to a classical circuit due to the stateful
nature of quantum states.

One set of tests we can apply without destroying the quantum state is ProjImp(MD′) for distributions
D′ that are indistinguishable from D from the view of the pirate circuit.5 We denote this set as
{ProjImp(MD′) | D′ c
≈ D}. Zhandry showed that if distributions D1 and D2 are indistinguishable,
the outcome of ProjImp(MD1) is close to that of ProjImp(MD2). By combining this property with
the projective property of projective implementations, as long as the initial quantum state is Live and
c
we apply only tests contained in {ProjImp(MD′) | D′
≈ D}, the quantum state remains Live. On
c
the other hand, if we apply a test outside of {ProjImp(MD′) | D′
≈ D}, the quantum state might
c
be irreversibly altered. This fact is a problem since the set {ProjImp(MD′) | D′
≈ D} only is not
suﬃcient to implement the existing widely used construction method for watermarking PRF schemes.

To see this, we brieﬂy review the method. In watermarking PRF schemes, the number of possible
embedded messages is super-polynomial, and thus we basically need to extract an embedded message in
a bit-by-bit manner. In the method, such a bit-by-bit extraction is done as follows. For every i ∈ [ℓm], we
deﬁne two distributions Si,0 and Si,1 whose output is of the form (b, x, y) as D above. Then, we design a
marked circuit with embedded message m ∈ {0, 1}ℓm so that it can be used to guess b from (x, y) with

5In the actual extraction process, we use an approximation of projective implementation introduced by Zhandry [Zha20]

since applying a projective implementation is ineﬃcient. In this overview, we ignore this issue for simplicity.

4

probability signiﬁcantly greater than 1/2 only for Si,0 (resp. Si,1) if m[i] = 0 (resp. m[i] = 1). The
extraction algorithm can extract i-th bit of the message m[i] by checking for which distributions of Si,0
and Si,1 a pirate circuit has a high distinguishing advantage.

As stated above, we cannot use this standard method to extract a message from quantum pirate
circuits. The reason is that Si,0 and Si,1 are typically distinguishable. This implies that at least either
one of ProjImp(MSi,0) or ProjImp(MSi,1) is not contained in {ProjImp(MD′) | D′ c
≈ D}. Since the
test outside of {ProjImp(MD′) | D′ c
perform the process for all i, and fail to extract the entire bits of the embedded message.

≈ D} might destroy the quantum state, we might not be able to

It seems that to perform the bit-by-bit extraction for a quantum state, we need to extend the set of

applicable tests and come up with a new extraction method.

Our solution: Use of reverse projective property. We ﬁnd that as another applicable set of tests,
we have ProjImp(MD′) for distributions D′ that are indistinguishable from Drev, where Drev is the
following distribution.
Drev: Generate b ← {0, 1}, x ← Dom, and y0 ← Ran. Compute y1 ← Eval(prfk, x). Output

(1 ⊕ b, x, yb).

We denote the set as {ProjImp(MD′) | D′ c
≈ Drev}. Drev is the distribution the ﬁrst bit of whose
output is ﬂipped from that of D. Then, MDrev can be seen as POVMs that represents generating random
(b, x, yb) from D and testing if a quantum circuit cannot guess b from (x, yb). Thus, we see that
MDrev = (M D,1, M D,0). Recall that MD = (M D,0, M D,1).

≈ D} and Drev

Let D1 ∈ {ProjImp(MD′) | D′ c

is a distribution contained in {ProjImp(MD′) | D′ c

be the distribution that generates (b, x, y) ← D1
≈ Drev}. Similarly
and outputs (1 ⊕ b, x, y). Drev
to the relation between D and Drev, if MD1 = (M D1,0, M D1,1), we have MDrev
,0).
Since M D1,0 + M D1,1 = I, M D1,0 and M D1,1 share the same set of eigenvectors, and if a vector is an
eigenvector of M D1,0 with eigenvalue p, then it is also an eigenvector of M D1,1 with eigenvalue 1 − p.
Thus, if apply ProjImp(MD1) and ProjImp(MDrev
) successively to a quantum state and obtain the
p′
outcomes
p1. We call this property the reverse projective property of
1, it holds that
the projective implementation.

p′
1 = 1 −

= (M Drev

,1, M Drev

p1 and

1

1

1

1

1

1

Combining projective and reverse projective properties and the outcome closeness for indistinguish-

e
able distributions of the projective implementation, we see that the following key fact holds.

e

e

e

c
≈ D} or {ProjImp(MD′)|D′

Key fact: As long as the initial quantum state is Live and we apply tests contained in {ProjImp(MD′) |
c
D′
≈ Drev}, the quantum state remains Live. Moreover, if the
outcome of applying ProjImp(MD) to the initial state is p, we get the outcome close to p every
time we apply a test in {ProjImp(MD′) | D′ c
≈ D}, and we get the outcome close to 1 − p every
time we apply a test in {ProjImp(MD′) | D′ c
≈ Drev}.

In this work, we perform bit-by-bit extraction of embedded messages by using the above key fact of
the projective implementation. To this end, we introduce the new notion of extraction-less watermarking
PRF as an intermediate primitive.

Via extraction-less watermarking PRF. An extraction-less watermarking PRF scheme has almost the
same syntax as a watermarking PRF scheme, except that it does not have an extraction algorithm Extract
and instead has a simulation algorithm Sim. Sim is given the extraction key xk, the public tag τ, and an
index i ∈ [ℓm], and outputs a tuple of the form (γ, x, y). Sim simulates outputs of D or Drev for a pirate
circuit depending on the message embedded to the marked circuit corresponding to the pirate circuit.
More concretely, we require that from the view of the pirate circuit generated from a marked circuit with

5

embedded message m ∈ {0, 1}ℓm , outputs of Sim are indistinguishable from those of D if m[i] = 0 and
are indistinguishable from those of Drev if m[i] = 1 for every i ∈ [ℓm]. We call this security notion
simulatability for mark-dependent distributions (SIM-MDD security).

By using an extraction-less watermarking PRF scheme ELWMPRF, we construct a watermarking PRF
scheme WMPRF against quantum adversaries as follows. We use Setup, Gen, Eval, Mark of ELWMPRF
as Setup, Gen, Eval, Mark of WMPRF, respectively. We explain how to construct the extraction algorithm
Extract of WMPRF using Sim of ELWMPRF. For every i ∈ [ℓm], we deﬁne Dτ,i as the distribution that
outputs randomly generated (γ, x, y) ← Sim(xk, τ, i). Given xk, τ, and a quantum state |ψi, Extract
extracts the embedded message in the bit-by-bit manner by repeating the following process for every
i ∈ [ℓm].

• Apply ProjImp(MDτ,i) to |ψi−1i and obtain the outcome

state after the (i − 1)-th loop for every i ∈ [ℓm].

pi, where |ψ0i = |ψi and |ψi−1i is the

• Set m′

i = 0 if
The extracted message is set to m′

pi > 1/2 and otherwise m′
.

1k · · · km′
ℓm

i = 1.

e

e

e

We show that the above construction satisﬁes unremovability. Suppose an adversary is given marked
C ← Mark(pp, prfk, m) and generates a quantum state |ψi, where (pp, xk) ← Setup(1λ) and
circuit
(prfk, τ) ← Gen(pp). Suppose also that |ψi is Live. This assumption means that the outcome p of
applying ProjImp(MD) to |ψi is 1/2 + ǫ, where ǫ is an inverse polynomial. For every i ∈ [ℓm], from the
SIM-MDD security of ELWMPRF, Dτ,i is indistinguishable from D if m[i] = 0 and is indistinguishable
c
from Drev if m[i] = 1. This means that Dτ,i ∈ {ProjImp(MD′) | D′
≈ D} if m[i] = 0 and
Dτ,i ∈ {ProjImp(MD′) | D′ c
≈ Drev} if m[i] = 1. Then, from the above key fact of the projective
pi is close to 1/2 + ǫ > 1/2 if m[i] = 0 and is close to 1/2 − ǫ < 1/2
implementation, it holds that
if m[i] = 1. Therefore, we see that Extract correctly extract m from |ψi. This means that WMPRF
satisﬁes unremovability.

e

The above deﬁnition, construction, and security analysis are simpliﬁed and ignore many subtleties.
The most signiﬁcant point is that we use approximated projective implementations introduced by
Zhandry [Zha20] instead of projective implementations in the actual construction since applying a
projective implementation is an ineﬃcient process. Moreover, though the outcomes of (approximate)
projective implementations for indistinguishable distributions are close, in the actual analysis, we have
to take into account that the outcomes gradually change every time we apply an (approximate) projective
implementation. These issues can be solved by doing careful parameter settings.

Comparison with the work by Zhandry [Zha20]. Some readers familiar with Zhandry’s work [Zha20]
might think that our technique contradicts the lesson from Zhandry’s work since it essentially says that
once we ﬁnd a large gap in success probabilities, the tested quantum pirate circuit might self-destruct.
However, this is not the case. What Zhandry’s work really showed is the following. Once a quantum
pirate circuit itself detects that there is a large gap in success probabilities, it might self-destruct. Even
if an extractor ﬁnds a large gap in success probabilities, if the tested quantum pirate circuit itself cannot
detect the large gap, the pirate circuit cannot self-destruct. In Zhandry’s work, whenever an extractor
ﬁnds a large gap, the tested pirate circuit also detects the large gap. In our work, the tested pirate circuit
cannot detect a large gap throughout the extraction process while an extractor can ﬁnd it.

The reason why a pirate circuit cannot detect a large gap in our scheme even if an extractor can ﬁnd
it is as follows. Recall that in the above extraction process of our scheme based on an extraction-less
watermarking PRF scheme, we apply ProjImp(MDτ,i) to the tested pirate circuit for every i ∈ [ℓm].
Each Dτ,i outputs a tuple of the form (b, x, y) and is indistinguishable from D or Drev depending on the
embedded message. In the process, we apply ProjImp(MDτ,i) for every i ∈ [ℓm], and we get the success
probability p if Dτ,i is indistinguishable from D and we get 1 − p if Dτ,i is indistinguishable from Drev.

6

The tested pirate circuit needs to know which of D or Drev is indistinguishable from the distribution
Dτ,i behind the projective implementation to know which of p or 1 − p is the result of an application of
a projective implementation. However, this is impossible. The tested pirate circuit receives only (x, y)
part of Dτ,i’s output and not b part. (Recall that the task of the pirate circuit is to guess b from (x, y).)
The only diﬀerence between D and Drev is that the ﬁrst-bit b is ﬂipped. Thus, if the b part is dropped,
Dτ,i is, in fact, indistinguishable from both D and Drev. As a result, the pirate program cannot know
which of p or 1 − p is the result of an application of a projective implementation. In other words, the
pirate circuit cannot detect a large gap in our extraction process.

Instantiating extraction-less watermarking PRF.
to realize extraction-less watermarking PRF.

In the rest of this overview, we will explain how

We consider the following two settings similar to the ordinary watermarking PRF. Recall that we

consider the public marking setting by default.

Private-simulatable: In this setting, the extraction key xk fed into Sim is kept secret. We require that
SIM-MDD security hold under the existence of the simulation oracle that is given a public tag τ′
and an index i′ ∈ [ℓm] and returns Sim(xk, τ′, i′). An extraction-less watermarking PRF scheme in
this setting yields a watermarking PRF scheme against quantum adversaries in private-extractable
setting where unremovability holds for adversaries who can access the extraction oracle.

Public-simulatable: In this setting, the extraction key xk is publicly available. An extraction-less
watermarking PRF scheme in this setting yields a watermarking PRF scheme against quantum
adversaries in the public-extractable setting.

We provide a construction in the ﬁrst setting using private constrained PRF based on the hardness of the
LWE assumption. Also, we provide a construction in the second setting based on IO and the hardness of
the LWE assumption.

To give a high-level idea behind the above constructions, in this overview, we show how to construct
a public-simulatable extraction-less watermarking PRF in the token-based setting [CHN+18]. In the
C ← Mark(pp, prfk, m) as a tamper-proof hardware token
token-based setting, we treat a marked circuit
that an adversary can only access in a black-box way.

e

Before showing the actual construction, we explain the high-level idea. Recall that SIM-MDD security
C ← Mark(pp, prfk, m) cannot distinguish (γ∗, x∗, y∗) ←
requires that an adversary A who is given
Sim(xk, τ, i∗) from an output of D if m[i∗] = 0 and from that of Drev if m[i∗] = 1. This is the same as
requiring that A cannot distinguish (γ∗, x∗, y∗) ← Sim(xk, τ, i∗) from that of the following distribution
Dreal,i∗. We can check that Dreal,i∗ is identical with D if m[i∗] = 0 and with Drev if m[i∗] = 1.
Dreal,i∗: Generate γ ← {0, 1} and x ← Dom. Then, if γ = m[i∗], generate y ← Ran, and otherwise,

e

compute y ← Eval(prfk, x). Output (γ, x, y).

C so that

C
C(x∗) with y∗, if we ensure that γ∗, x∗ are pseudorandom. In order to make the
C ← Mark(pp, prfk, m) and (γ∗, x∗, y∗) ← Sim(xk, τ, i∗),
e

Essentially, the only attack that A can perform is to feed x∗ contained in the given tuple (γ∗, x∗, y∗) to
and compares the result
construction immune to this attack, letting
we have to design Sim and
e
• If γ = m[i∗],
• If γ 6= m[i∗],

C(x∗) outputs a value diﬀerent from y∗.
e
C(x∗) outputs y∗.
e

We achieve these conditions as follows. First, we set (γ∗, x∗, y∗) output by Sim(xk, τ, i∗) so that γ∗
and y∗ is random values and x∗ is an encryption of y∗ki∗kγ∗ by a public-key encryption scheme with
pseudorandom ciphertext property, where the encryption key pk is included in τ. Then, we set
C as a
token such that it has the message m and the decryption key sk corresponding to pk hardwired, and it

e

e

7

e

outputs y∗ if the input is decryptable and γ∗ 6= m[i∗] holds for the decrypted y∗ki∗kγ∗, and otherwise
behaves as Eval(prfk, ·). The actual construction is as follows.

Let PRF be a PRF family consisting of functions {Fprfk(·) : {0, 1}n → {0, 1}λ|prfk}, where λ is
the security parameter and n is suﬃciently large. Let PKE = (KG, E, D) be a CCA secure public-key
encryption scheme satisfying pseudorandom ciphertext property. Using these ingredients, We construct
an extraction-less watermarking PRF scheme ELWMPRF = (Setup, Gen, Eval, Mark, Sim) as follows.
Setup(1λ): In this construction, pp := ⊥ and xk := ⊥.

Gen(pp): It generates a fresh PRF key prfk of PRF and a key pair (pk, sk) ← KG(1λ). The PRF key is

(prfk, sk) and the corresponding public tag is pk.

Eval((prfk, sk), x): It simply outputs Fprfk(x).

Mark(pp, (prfk, sk), m): It generates the following taken

C[prfk, sk, m].

Hard-Coded Constants: prfk, sk, m.
Input: x ∈ {0, 1}n.

e

1. Try to decrypt ykikγ ← D(sk, x) with y ∈ {0, 1}λ, i ∈ [ℓm], and γ ∈ {0, 1}.
2. If decryption succeeds, output y if γ 6= m[i] and Fprfk(x) otherwise.
3. Otherwise, output Fprfk(x).

Sim(xk, τ, i): It ﬁrst generates γ ← {0, 1} and y ← {0, 1}λ. Then, it parses τ := pk and generates

x ← E(pk, ykikγ). Finally, it outputs (γ, x, y).

We check that ELWMPRF satisﬁes SIM-MDD security. For simplicity, we ﬁx the message m ∈ [ℓm]
embedded into the challenge PRF key. Then, for any adversary A and i∗ ∈ [ℓm], SIM-MDD security
C[prfk, sk, m] ← Mark(mk, prfk, m) and τ = pk, A cannot distinguish (γ∗, x∗ =
requires that given
E(pk, y∗ki∗kγ∗), y∗) ← Sim(xk, τ, i∗) from an output of D if m[i∗] = 0 and is indistinguishable from
Drev if m[i∗] = 1.

e

We consider the case of m[i∗ ] = 0. We can ﬁnish the security analysis by considering the following se-
quence of mutually indistinguishable hybrid games, where A is given (γ∗, x∗ = E(pk, y∗ki∗kγ∗), y∗) ←
Sim(xk, τ, i∗) in the ﬁrst game, and on the other hand, is given (γ∗, x∗, y∗) ← D in the last game. We ﬁrst
change the game so that x∗ is generated as a uniformly random value instead of x∗ ← E(pk, y∗ki∗kγ∗)
by using the pseudorandom ciphertext property under CCA of PKE. This is possible since the CCA
C[prfk, sk, m] by A. Then, we further change the security
oracle can simulate access to the marked token
game so that if γ∗ = 1, y∗ is generated as Fprfk(x∗) instead of a uniformly random value by using the
pseudorandomness of PRF. Note that if γ∗ = 0, y∗ remains uniformly at random. We see that if γ∗ = 1,
C[prfk, sk, m] never evaluate Fprfk(x∗) since m[i∗] 6= γ∗. Thus, this change is possible. We
the token
see that now the distribution of (γ∗, x∗, y∗) is exactly the same as that output by D. Similarly, in the
case of m[i∗] = 1, we can show that an output of Sim(xk, τ, i∗) is indistinguishable from that output by
Drev. The only diﬀerence is that in the ﬁnal step, we change the security game so that y∗ is generated as
Fprfk(x∗) if γ∗ = 0.

e

e

In the actual public-simulatable construction, we implement this idea using iO and puncturable
encryption [CHN+18] instead of token and CCA secure public-key encryption. Also, in the actual
secret-simulatable construction, we basically follow the same idea using private constrained PRF and
secret-key encryption.

1.4 More on Related Work

Watermarking against classical adversaries. Cohen et al. [CHN+18] present a publicly extractable
watermarking PRF from IO and injective OWFs. It is unremovable against adversaries who can access

8

the mark oracle only before a target marked circuit is given. The mark oracle returns a marked circuit
for a queried arbitrary polynomial-size circuit. Suppose we additionally assume the hardness of the
decisional Diﬃe-Hellman or LWE problem.
In that case, their watermarking PRF is unremovable
against adversaries that can access the mark oracle before and after a target marked circuit is given.
However, adversaries can query a valid PRF key to the mark oracle in that case. They also present
deﬁnitions and constructions of watermarking for public-key cryptographic primitives.

Boneh, Lewi, and Wu [BLW17] present a privately extractable watermarking PRF from privately
programmable PRFs, which are variants of private constrained PRFs [BLW17, CC17]. It is unremovable
in the presence of the mark oracle. However, it is not secure in the presence of the extraction oracle and
does not support public marking. They instantiate a privately programmable PRF with IO and OWFs,
but later, Peikert and Shiehian [PS18] instantiate it with the LWE assumption.

Kim and Wu [KW21] (KW17), Quach, Wichs, and Zirdelis [QWZ18] (QWZ), and Kim and
Wu [KW19] (KW19) present privately extractable watermarking PRFs from the LWE assumption. They
are secure in the presence of the mark oracle. KW17 construction is not secure in the presence of the
extraction oracle and does not support public marking. QWZ construction is unremovable in the pres-
ence of the extraction oracle and supports public marking. However, it does not have pseudorandomness
against an authority that generates a marking and extraction key. KW19 construction is unremovable in
the presence of the extraction oracle and has some restricted pseudorandomness against an authority (see
the reference [KW19] for the detail). However, it does not support public marking.6

Yang et al. [YAL+19] present a collusion-resistant watermarking PRF from IO and the LWE assump-
tion. Collusion-resistant watermarking means unremovability holds even if adversaries receive multiple
marked circuits with diﬀerent embedded messages generated from one target circuit.

Goyal, Kim, Manohar, Waters, and Wu [GKM+19] improve the deﬁnitions of watermarking for
public-key cryptographic primitives and present constructions. In particular, they introduce collusion-
resistant watermarking and more realistic attack strategies for public-key cryptographic primitives. Nishi-
maki [Nis20] present a general method for equipping many existing public-key cryptographic schemes
with the watermarking functionality.

Goyal, Kim, Waters, and Wu [GKWW21] introduce the notion of traceable PRFs, where we can
identify a user that creates a pirate copy of her/his authenticated PRF. The diﬀerence between traceable
PRF and (collusion-resistant) watermarking PRF is that there is only one target original PRF and multiple
authenticated copies of it with diﬀerent identities in traceable PRF. In (collusion-resistant) watermarking
PRF, we consider many diﬀerent PRF keys. In addition, Goyal et al. introduce a reﬁned attack model.
Adversaries in previous watermarking PRF deﬁnitions output a pirate PRF circuit that correctly computes
the original PRF values for 1/2 + ǫ fraction of inputs. However, adversaries in traceable PRFs output a
pirate circuit that distinguishes whether an input pair consists of a random input and a real PRF value or
a random input and output value. This deﬁnition captures wide range of attacks. For example, it captures
adversaries who create a pirate PRF circuit that can compute the ﬁrst quarter bits of the original PRF
output. Such an attack is not considered in previous watermarking PRFs. We adopt the reﬁned attack
model in our deﬁnitions.

Learning information from adversarial entities in the quantum setting. Zhandry [Zha20] intro-
duces the deﬁnition of secure traitor tracing against quantum adversaries.
In traitor tracing, each
legitimate user receives a secret key that can decrypt broadcasted ciphertexts and where identity infor-
mation is embedded. An adversary outputs a pirate decoder that can distinguish whether an input is
a ciphertext of m0 or m1 where m0 and m1 are adversarially chosen plaintexts. A tracing algorithm
must identify a malicious user’s identity such that its secret decryption key is embedded in the pirate
decoder. Thus, we need to extract information from adversarially generated objects. Such a situation

6Their construction supports public marking in the random oracle model.

9

also appears in security proofs of interactive proof systems [Wat09, Unr12, ARU14, CMSZ21] (but not
in real cryptographic algorithms) since we rewind a veriﬁer.

Zhandry presents how to estimate the success decryption probability of a quantum pirate decoder
without destroying the decoding (distinguishing) capability. He achieves a quantum tracing algorithm
that extracts a malicious user identity by combining the probability approximation technique above
with PLBE [BSW06]. However, his technique is limited to the setting where user identity spaces are
only polynomially large while there are several traitor tracing schemes with exponentially large identity
spaces [NWZ16, GKW19]. As observed in previous works [GKM+19, Nis20, GKWW21], traitor tracing
and watermarking have similarities since an adversary outputs a pirate circuit in the watermarking setting
and an extraction algorithm tries to retrieve information from it. However, a notable diﬀerence is that we
must consider exponentially large message spaces by default in the (message-embedding) watermarking
setting.

Application of (classical) watermarking. As we explained above, Aaronson et al. [ALL+21], and
Kitagawa et al. [KNY21] achieve secure software leasing schemes by using watermarking. A leased
software consists of a quantum state and watermarked circuit. Although they use watermarking schemes
in the quantum setting, it is suﬃcient for their purpose to use secure watermarking against adversaries that
output a classical pirate circuit. This is because a returned software is veriﬁed by a checking algorithm
and must have a speciﬁc format in secure software leasing.7 That is, a returned software is rejected if it
does not have a classical circuit part that can be tested by an extraction algorithm of the building block
watermarking.

2 Preliminaries

Notations and conventions.
In this paper, standard math or sans serif font stands for classical algo-
rithms (e.g., C or Gen) and classical variables (e.g., x or pk). Calligraphic font stands for quantum
algorithms (e.g., Gen) and calligraphic font and/or the bracket notation for (mixed) quantum states (e.g.,
q or |ψi). For strings x and y, xky denotes the concatenation of x and y. Let [ℓ] denote the set of integers
{1, · · · , ℓ}, λ denote a security parameter, and y := z denote that y is set, deﬁned, or substituted by z.
In this paper, for a ﬁnite set X and a distribution D, x ← X denotes selecting an element from
X uniformly at random, x ← D denotes sampling an element x according to D. Let y ← A(x) and
y ← A(x ) denote assigning to y the output of a probabilistic or deterministic algorithm A and a quantum
algorithm A on an input x and x , respectively. When we explicitly show that A uses randomness r, we
write y ← A(x; r). PPT and QPT algorithms stand for probabilistic polynomial time algorithms and
polynomial time quantum algorithms, respectively. Let negl denote a negligible function.

2.1 Quantum Information

Let H be a ﬁnite-dimensional complex Hilbert space. A (pure) quantum state is a vector |ψi ∈ H. Let
S(H) be the space of Hermitian operators on H. A density matrix is a Hermitian operator X ∈ S(H)
with Tr(X ) = 1, which is a probabilistic mixture of pure states. A quantum state over H = C2 is
called qubit, which can be represented by the linear combination of the standard basis {|0i , |1i}. More
generally, a quantum system over (C2)⊗n is called an n-qubit quantum system for n ∈ N \ {0}.

A Hilbert space is divided into registers H = HR1 ⊗ HR2 ⊗ · · · ⊗ HRn. We sometimes write X Ri
to emphasize that the operator X acts on register HRi.8 When we apply X R1 to registers HR1 and HR2,
X R1 is identiﬁed with X R1 ⊗ IR2 .

7A valid software must run on a legitimate platform. For example, a video game title of Xbox must run on Xbox.
8The superscript parts are gray colored.

10

A unitary operation is represented by a complex matrix U such that UU † = I. The operation
U transforms |ψi and X into U |ψi and UX U†, respectively. A projector P is a Hermitian operator
(P† = P) such that P2 = P.

For a quantum state X over two registers HR1 and HR2 , we denote the state in HR1 as X [R1], where

X [R1] = Tr2[X ] is a partial trace of X (trace out R2).

Given a function F : X → Y, a quantum-accessible oracle O of F is modeled by a unitary trans-
formation U F operating on two registers Hin and Hout, in which |xi |yi is mapped to |xi |y ⊕ F(x)i,
where ⊕ denotes XOR group operation on Y. We write A |Oi to denote that the algorithm A’s oracle O
is a quantum-accessible oracle.

Deﬁnition 2.1 (Quantum Program with Classical Inputs and Outputs [ALL+21]). A quantum pro-
gram with classical inputs is a pair of quantum state q and unitaries {U x}x∈[N] where [N] is the domain,
such that the state of the program evaluated on input x is equal to U xqU †
x. We measure the ﬁrst register
of U xqU †
x to obtain an output. We say that {U x}x∈[N] has a compact classical description U when
applying U x can be eﬃciently computed given U and x.

Deﬁnition 2.2 (Positive Operator-Valued Measure). Let I be a ﬁnite index set. A positive operator
valued measure (POVM) M is a collection {M i}i∈I of Hermitian positive semi-deﬁne matrices Mi such
that ∑i∈I Mi = I. When we apply POVM M to a quantum state X , the measurement outcome is i with
probability pi = Tr(X Mi). We denote by M(|ψi) the distribution obtained by applying M to |ψi.

Deﬁnition 2.3 (Quantum Measurement). A quantum measurement E is a collection {Ei}i∈I of matrices
Ei such that ∑i∈I E†
i Ei = I. When we apply E to a quantum state X , the measurement outcome is i
with probability pi = Tr(X E†
i Ei). Conditioned on the outcome being i, the post-measurement state is
EiX E†

i /pi.

We can construct a POVM M from any quantum measurement E by setting Mi := E†

i Ei. We say

that E is an implementation of M. The implementation of a POVM may not be unique.

Deﬁnition 2.4 (Projective Measurement/POVM). A quantum measurement E = {Ei}i∈I is projective
if for all i ∈ I, Ei is a projector. This implies that EiEj = 0 for distinct i, j ∈ I.
In particular,
two-outcome projective measurement is called a binary projective measurement, and is written as
E = (P, I − P), where P is associated with the outcome 1, and I − P with the outcome 0. Similarly, a
POVM M is projective if for all i ∈ I, Mi is a projector. This also implies that Mi M j = 0 for distinct
i, j ∈ I.

Deﬁnition 2.5 (Controlled Projection). Let P = {Mi}i∈I be a collection of projective measurement
over a Hilbert space H, where Mi = (Πi, I − Πi) for i ∈ I. Let D be a distribution whose randomness
space is R. The controlled projection CProjP ,D = (CProj1

P ,D) is deﬁned as follows.9

P ,D, CProj0

CProj1

P ,D := ∑
r∈R

|ri hr| ⊗ ΠD(r),

CProj0

P ,D := ∑
r∈R

|ri hr| ⊗ (I − ΠD(r))

2.2 Measurement Implementation

Deﬁnition 2.6 (Projective Implementation). Let:
• P = (P, I − P) be a binary outcome POVM
• D be a ﬁnite set of distributions over outcomes {0, 1}
• E = {ED}D∈D be a projective measurement with index set D.
9We use superscript b to denote that it is associated with the outcome b here.

11

We deﬁne the following measurement.

1. Measure under the projective measurement E and obtain a distribution D over {0, 1}.

2. Output a bit sampled from the distribution D.

We say this measurement is a projective implementation of P , denoted by ProjImp(P ) if it is equivalent
to P .

Theorem 2.7 ([Zha20, Lemma 1]). Any binary outcome POVM P = (P, I − P) has a projective
implementation ProjImp(P ).

Deﬁnition 2.8 (Shift Distance). For two distributions D0, D1, the shift distance with parameter ǫ,
denoted by ∆ǫ

Shift(D0, D1), is the smallest quantity δ such that for all x ∈ R:

Pr[D0 ≤ x] ≤ Pr[D1 ≤ x + ǫ] + δ,
Pr[D1 ≤ x] ≤ Pr[D0 ≤ x + ǫ] + δ,

Pr[D0 ≥ x] ≤ Pr[D1 ≥ x − ǫ] + δ,
Pr[D1 ≥ x] ≤ Pr[D0 ≥ x − ǫ] + δ.

For two real-valued measurements M and N over the same quantum system, the shift distance between
M and N with parameter ǫ is

∆ǫ

Shift(M, N ) := sup
|ψi

∆ǫ

Shift(M(|ψi), N (|ψi)).

Deﬁnition 2.9 ((ǫ, δ)-Almost Projective [Zha20]). A real-valued quantum measurement M = {M i}i∈I
is (ǫ, δ)-almost projective if the following holds. For any quantum state |ψi, we apply M twice in a row
to |ψi and obtain measurement outcomes x and y, respectively. Then, Pr[|x − y| ≤ ǫ] ≥ 1 − δ.

Theorem 2.10 ([Zha20, Theorem 2]). Let D be any probability distribution and P be a collection of
projective measurements. For any 0 < ǫ, δ < 1, there exists an algorithm of measurement API ǫ,δ
P ,D that
satisﬁes the following.

• ∆ǫ

Shift(API ǫ,δ

P ,D, ProjImp(PD)) ≤ δ.

• API ǫ,δ

P ,D is (ǫ, δ)-almost projective.
• The expected running time of API ǫ,δ

P ,D is TP ,D · poly(1/ǫ, log(1/δ)) where TP ,D is the combined
running time of D, the procedure mapping i → (Pi, I − Pi), and the running time of measurement
(Pi, I − Pi).

Theorem 2.11 ([Zha20, Corollary 1]). Let q be an eﬃciently constructible, potentially mixed state, and
D0, D1 eﬃciently sampleable distributions. If D0 and D1 are computationally indistinguishable, for any
inverse polynomial ǫ and any function δ, we have ∆3ǫ

) ≤ 2δ + negl(λ).

, API ǫ,δ

Shift(API ǫ,δ

P ,D0

P ,D1

Note that the indistinguishability of D0 and D1 needs to hold against distinguishers who can construct
q in the theorem above. However, this fact is not explicitly stated in [Zha20]. We need to care about
this condition if we need secret information to construct q, and the secret information is also needed to
sample an output from D0 or D1. We handle such a situation when analyzing the unremovability of our
privately extractable watermarking PRF. In that situation, we need a secret extraction key to construct q
and sample an output from D0 and D1.

We also deﬁne the notion of the reverse almost projective property of API.

Deﬁnition 2.12 ((ǫ, δ)-Reverse Almost Projective). Let P = {(Πi, I − Πi)}i be a collection of binary
outcome projective measurements. Let D be a distribution. We also let P rev = {(I − Πi, Πi)}i. We
say API is (ǫ, δ)-reverse almost projective if the following holds. For any quantum state |ψi, we apply
API ǫ,δ
P rev,D in a row to |ψi and obtain measurement outcomes x and y, respectively. Then,
Pr[|(1 − x) − y| ≤ ǫ] ≥ 1 − δ.

P ,D and API ǫ,δ

12

Parameter: Collection of projective measurement P, distribution D, real values ǫ, δ.
Input: A quantum state |ψi.

Algorithm API ǫ,δ
P ,D

1. Initialize a state |1Ri |ψi.
2. Initialize a classical list L := (1).

3. Repeat the following T :=

ln 4/δ
ǫ2

.

(a) Apply CProjP ,D to register HR ⊗ HH. Let b2i−1 be the measurement outcome and set L := (L, b2i−1).
(b) Apply IsUR to register HR. Let b2i be the measurement outcome and set L := (L, b2i).

l

m

4. Let t be the number of index i such that bi−1 = bi in the list L = (0, b1, . . . , b2T), and
5. If b2T = 0, repeat the loop again until b2i = 1.
6. Discard HR register, and output

p.

p := t/2T.

e

Figure 1: The description of API .

e

We show that the measurement algorithm API ǫ,δ

P ,D in Theorem 2.10 also satisﬁes Deﬁnition 2.12.
First, we describe the detail of API ǫ,δ
P ,D in Figure 1. API uses an ancilla register HR besides the
original Hilbert space HH. Let R be the randomness space of distribution D. We deﬁne IsUR :=
(|1Ri h1R| , I − |1Ri h1R|) where

|1Ri :=

1
|R|

∑
r∈R

|ri .

p
We use the following lemma to analyze API ǫ,δ
P ,D.
Lemma 2.13 ([Jor75]). For any two Hermitian projectors Πv and Πw on a Hilbelt space H, there exists
an orthogonal decomposition of H into one-dimensional and two-dimensional subspaces (the Jordan
subspaces) that are invariant under both Πv and Πw. Moreover:

• in each one-dimensional space, Πv and Πw act as identity or rank-zero projectors; and
• in each two-dimensional subspace Sj , Πv and Πw are rank-one projectors: there exists

vj

Sj such that Πv projects onto

vj

and Πw projects onto

wj

.

,

wj

∈

(cid:12)
(cid:12)

(cid:11)

(cid:12)
(cid:12)

(cid:11)

It is easy to see that

vj

For each two-dimensional subspace Sj, we call pj :=

As previous works observed [MW05, Reg, CMSZ21], we obtain the following by Lemma 2.13. There
= 0. Similarly,

vj
is an eigenvector of the Hermitian matrix ΠvΠwΠv with eigenvalue pj.
(cid:12)
(cid:12)
that span Sj, such that Πv

(cid:11)
exists orthogonal vectors

(cid:11)
2 the eigenvalue of the j-th subspace.

and Πv

(cid:11)(cid:12)
(cid:12)

=

vj

vj

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:11)

(cid:10)

,

(cid:12)
wj
(cid:12)

(cid:12)
(cid:12)

= 0. By setting appropriate phases, we have

(cid:11)

(cid:11)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

v⊥
j

E

(cid:12)
(cid:12)
(cid:12)

Πw

wj

=

wj

(cid:11)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:11)
wj

and Πw
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
pj

=

v⊥
j

E

vj
w⊥
(cid:11)
j

(cid:12)
(cid:12)
(cid:12)
E
+

vj

1 − pj

v⊥
j

,

w⊥
j

=

1 − pj

vj

−

pj

v⊥
j

,

(cid:12)
(cid:12)

(cid:11)

vj

=

p

pj

(cid:12)
(cid:12)

(cid:11)
wj

q

+

1 − pj

(cid:12)
(cid:11)
(cid:12)
w⊥
j

,

(cid:12)
p
(cid:12)
∈ Sj such that

(cid:11)

q

vj

v⊥
j

where

v⊥
j

E
w⊥
j

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
=

,

E
wj

w⊥
j

E

=

q

v⊥
j

1 − pj

(cid:12)
(cid:12)
(cid:12)
(cid:12)
q
(cid:12)
(cid:12)
(cid:12)
(cid:12)
= 0. We also have

E

(cid:12)
(cid:12)

(cid:11)
wj

p

−

pj

(cid:11)

p

E
w⊥
j

,

E

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

E

(cid:12)
(cid:12)
(cid:12)

E

Πv

wj

=

E

D

D
pj

(cid:12)
(cid:12)
vj
(cid:12)

,

(cid:12)
(cid:12)
(cid:12)

E

(cid:12)
(cid:12)

(cid:11)

p

(cid:11)

(cid:12)
(cid:12)

13

Πw

vj

=

pj

wj

.

(cid:11)

(cid:12)
(cid:12)

p

(cid:11)

(cid:12)
(cid:12)

pj

1 − pj

vj

(cid:11)

(cid:12)
(cid:12)

v⊥
j

wj

(cid:11)

(cid:12)
(cid:12)

w⊥
j

pj

1 − pj

pj

1 − pj

wj

(cid:11)

(cid:12)
(cid:12)

w⊥
j

· · ·

· · ·

pj

pj

E

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
Figure 2: Solid lines denote that the measurement outcome is 1. Dashed line denote that the measurement
outcome is 0. Double lines denote we apply CProjP,D = (CProj1
P,D, CProj0
P,D). Single lines denote we apply
IsUR = (|1Ri h1R| , I − |1Ri h1R|).

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

E

E

E

1 − pj

pj

vj

(cid:11)

(cid:12)
(cid:12)

w⊥
j

E

(cid:12)
(cid:12)
(cid:12)

v⊥
j

E

(cid:12)
(cid:12)
(cid:12)

wj

(cid:11)

(cid:12)
(cid:12)

1 − pj

pj

1 − pj

1 − pj

pj

1 − pj

w⊥
j

E

(cid:12)
(cid:12)
(cid:12)

wj

(cid:11)

(cid:12)
(cid:12)

· · ·

· · ·

Figure 3: Solid lines denote that the measurement outcome is 1. Dashed line denote that the measurement outcome
is 0. Double lines denote we apply CProjrev
P,D). Single
lines denote we apply IsUR = (|1Ri h1R| , I − |1Ri h1R|).

P rev,D) = (CProj0

P,D = (CProj1

P rev,D, CProj0

P,D, CProj1

vj

(cid:11)

(cid:12)
(cid:12)

v⊥
j

vj

(cid:11)

(cid:12)
(cid:12)

v⊥
j

E

(cid:12)
(cid:12)
(cid:12)

Theorem 2.14. API ǫ,δ

P ,D in Figure 1 is (ǫ, δ)-reverse almost projective.

Proof of Theorem 2.14. To analyze API ǫ,δ
apply Lemma 2.13. Then, we have the following relationships:

P ,D, we set Πw := CProj1

P ,D, Πv := |1Ri h1R| ⊗ I, and

(cid:12)
(cid:12)
(cid:12)
(cid:12)
v⊥
(cid:12)
j

CProj1

P ,D

vj

=

pj

wj

,

CProj0

P ,D

CProj1

P ,D

=

p

(cid:12)
(cid:11)
1 − pj
(cid:12)

w⊥
j

,

q

=

1 − pj

wj

E
,

(|1Ri h1R|)
(I − |1Ri h1R|)

(|1Ri h1R|)

wj

=

pj

vj

(cid:11)

(cid:11)

wj

(cid:12)
(cid:12)
(cid:12)
w⊥
(cid:12)
j

=

p

(cid:12)
(cid:11)
1 − pj
(cid:12)

v⊥
j

q

=

1 − pj

vj

E

(cid:11)

(cid:11)

vj

(cid:12)
(cid:12)
(cid:12)
v⊥
(cid:12)
j

v⊥
j

E

E

(cid:12)
(cid:12)
(cid:12)
(cid:12)
w⊥
(cid:12)
j

(cid:11)

E

E

(cid:11)
,

(cid:12)
(cid:12)
(cid:12)

pj

pj

p

P ,D

(cid:12)
(cid:12)
vj

w⊥
j

CProj0

q
= −

q
= −

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
vj

where

wj

and

(I − |1Ri h1R|)

are decompositions of Πw and Πv, and pj =

Suppose we apply API ǫ,δ
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
P ,D to a |ψi on HH. We can write the initial state in Figure 1 as |1Ri |ψi =
vj
It is easy to see that (|1Ri h1R| ⊗
(cid:12)
(cid:12)
j = 0. Therefore, for any |ψi, we can write |1Ri |ψi =
P ,D(|ψi), the initial state is |1Ri |ψi = ∑j αj
vj
in each decomposed
(cid:11)

(cid:11)
+ α⊥
∑j αj
j
since Πv projects onto
I) |1Ri |ψi = |1Ri |ψi. Thus, for all j, α⊥
∑j αj
and we apply CProjP ,D and IsUR alternately. Therefore, the quantum state
subspace Sj changes as in Figure 2 when we run API ǫ,δ

(cid:12)
(cid:10)
(cid:12)
}j is a basis. We also have that |1Ri h1R|R ⊗ I = ∑j

vj
in each decomposed subspace Sj.
(cid:12)
(cid:12)

. As we see in Figure 1, when we run API ǫ,δ

(cid:11)
v⊥
j

since {

E
wj

v⊥
j

(cid:11)(cid:12)
(cid:12)

(cid:11) (cid:10)

p

2.

vj

vj

vj

vj

vj

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

E

E

E

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:11)

(cid:11)

(cid:11)

(cid:11)

,

,

P ,D(|ψi).

Next, suppose we apply API ǫ,δ
P ,D to |ψi.
P ,D ensures that the ﬁnal measurement is IsUR and its result is 1. This means that the state going
P rev,D (the third item in Figure 1) is identical to the state before HR is discarded

P rev,D to the quantum state immediately after applying API ǫ,δ

API ǫ,δ
into the main loop of API ǫ,δ

(cid:11)

(cid:12)
(cid:12)

14

P ,D to |ψi. By the deﬁnition of P rev, we have CProjb

P rev,D for
in each decomposed subspace Sj changes as in Figure 3 when

P ,D = CProj1−b

vj

(cid:11)
From the above discussions, we can view a successive execution of API ǫ,δ

(cid:12)
(cid:12)

P ,D and API ǫ,δ

P rev,D to |ψi as

at the application of API ǫ,δ
b ∈ {0, 1}. Thus, the quantum state
we apply API ǫ,δ
P rev,D.

the following single experiment.

• Sample pj from {pj}j with the probability α2
j .
• Flip 2T biased random coins whose probability of outputting 1 is pj.
• Flip an even number of additional random coins until 0 is found.
• Flip 2T biased random coins whose probability of outputting 1 is 1 − pj.
• Let K be the overall list of coin ﬂips.

Let

px and
ﬁrst 2T bits of K. Also,

py be the outcome of API ǫ,δ

P ,D and API ǫ,δ

P rev,D, respectively.

px is the fraction of 1’s in the

py is the fraction of 1’s in the last 2T bits of K. Then, we have

e

e

e

Pr

Pr

px − pj
py − (1 − pj)
(cid:2)(cid:12)
(cid:12)e

(cid:12)
(cid:12)
(cid:12)
(cid:12)

e

≥ ǫ/2

≤ δ/2

≥ ǫ/2

(cid:3)

≤ δ/2.

(1)

(2)

(cid:3)

py) − pj

≥ ǫ/2

≤ δ/2 due to |a| = |−a|.

It is easy to see that Equation (2) is equivalent to Pr
Therefore, by combining it with Equation (1), we obtain

(1 −

(cid:2)(cid:12)
(cid:12)e

Pr

px − (1 −

(cid:2)(cid:12)
(cid:12)
py)

(cid:12)
(cid:12)

e
≥ ǫ

≤ δ.

(cid:3)

This completes the proof.

(cid:2)(cid:12)
(cid:12) e

(cid:12)
(cid:12)

e

(cid:3)

2.3 Cryptographic Tools

Deﬁnition 2.15 (Learning with Errors). Let n, m, q ∈ N be integer functions of the security parameter
λ. Let χ = χ(λ) be an error distribution over Z. The LWE problem LWEn,m,q,χ is to distinguish the
following two distributions.

D0 := {(A, s⊺ A + e) | A ← Zn×m

q

, s ← Zn

q , e ← χm} and D1 := {(A, u) | A ← Zn×m

q

, u ← Zm

q }.

When we say we assume the quantum hardness of the LWE problem or the QLWE assumption holds,

we assume that for any QPT adversary A, it holds that

|Pr[A(D0) = 1] − Pr[A(D1) = 1]| ≤ negl(λ).

Deﬁnition 2.16 (Pseudorandom Generator). A pseudorandom generator (PRG) PRG : {0, 1}λ →
{0, 1}λ+ℓ(λ) with stretch ℓ(λ) (ℓ is some polynomial function) is a polynomial-time computable function
that satisﬁes the following. For any QPT adversary A, it holds that

Pr[A(PRG(s)) = 1 | s ← Uλ] − Pr

A(r) | r ← Uλ+ℓ(λ)

≤ negl(λ),

where Um denotes the uniform distribution over {0, 1}m.

h

(cid:12)
(cid:12)
(cid:12)

i(cid:12)
(cid:12)
(cid:12)

Theorem 2.17 ([HILL99]). If there exists a OWF, there exists a PRG.

15

Deﬁnition 2.18 (Quantum-Accessible Pseudo-Random Function). Let {PRFK : {0, 1}ℓ1 → {0, 1}ℓ2 |
K ∈ {0, 1}λ} be a family of polynomially computable functions, where ℓ1 and ℓ2 are some polynomials
of λ. We say that PRF is a quantum-accessible pseudo-random function (QPRF) family if for any QPT
adversary A, it holds that

Advprf

A (λ) =

Pr

A |PRFK(·)i(1λ) = 1 | K ← {0, 1}λ

− Pr

A |R(·)i(1λ) = 1 | R ← U

≤ negl(λ),

where U is the set of all functions from {0, 1}ℓ1 to {0, 1}ℓ2 .

i

h

i(cid:12)
(cid:12)
(cid:12)

h

(cid:12)
(cid:12)
(cid:12)

Theorem 2.19 ([Zha12a]). If there exists a OWF, there exists a QPRF.

Deﬁnition 2.20 (Puncturable PRF). A puncturable PRF (PPRF) is a tuple of algorithms PPRF =
(PRF.Gen, F, Puncture) where {FK : {0, 1}ℓ1 → {0, 1}ℓ2 | K ∈ {0, 1}λ} is a PRF family and satisﬁes
the following two conditions. Note that ℓ1 and ℓ2 are polynomials of λ.
Punctured correctness: For any polynomial-size set S ⊆ {0, 1}ℓ1 and any x ∈ {0, 1}ℓ1 \ S, it holds

that

Pr

FK(x) = FK /∈S (x) | K ← PRF.Gen(1λ), K /∈S ← Puncture(K, S)

= 1.

h

i

Pseudorandom at punctured point: For any polynomial-size set S ⊆ {0, 1}ℓ1 and any QPT distin-

guisher A, it holds that

| Pr

A(FK /∈S, {FK(xi)}xi∈S) = 1

− Pr

A(FK /∈S, (Uℓ2)|S|) = 1

| ≤ negl(λ),

h
where K ← PRF.Gen(1λ), K /∈S ← Puncture(K, S) and Uℓ2 denotes the uniform distribution over
{0, 1}ℓ2 .

i

(cid:3)

(cid:2)

If S = {x∗} (i.e., puncturing a single point), we simply write F6=x∗(·) instead of FK /∈S(·).

It is easy to see that the Goldwasser-Goldreich-Micali tree-based construction of PRFs (GGM
PRF) [GGM86] from one-way function yield puncturable PRFs where the size of the punctured key
grows polynomially with the size of the set S being punctured [BW13, BGI14, KPTZ13]. Thus, we have:
Theorem 2.21 ([GGM86, BW13, BGI14, KPTZ13]). If OWFs exist, then for any polynomials ℓ1(λ)
and ℓ2(λ), there exists a PPRF that maps ℓ1-bits to ℓ2-bits.
Deﬁnition 2.22 (SKE). An SKE scheme with plaintext space P = {Pλ}λ∈N and ciphertext space
C = {Cλ}λ∈N, where Cλ ⊆ {0, 1}ℓct for some ℓct = ℓct(λ), is a tuple of three algorithms.
Gen(1λ) → k: The key generation algorithm takes as input the security parameter λ, and outputs an

encryption key k.

Enc(k, m) → ct: The encryption algorithm takes as input k and a plaintext m ∈ Pλ, and outputs a

ciphertext ct ∈ Cλ.

Dec(k, ct) → m′: The decryption algorithm takes as input k and ct ∈ Cλ, and outputs a plaintext

m′ ∈ Pλ ∪ {⊥}.

Correctness: An SKE scheme is correct if for all λ ∈ N and m ∈ Pλ,

Pr

Dec(k, ct) = m | k ← Gen(1λ, 1κ), ct ← Enc(k, m)

= 1.

Sparseness: In this work, we also require that most strings are not valid ciphertexts under a randomly

h

i

generated key of an SKE scheme:

Pr

Dec(k, c) 6= ⊥

k ← Gen(1λ), c ← {0, 1}ℓct

≤ negl(λ).

h

(cid:12)
(cid:12)
(cid:12)

16

i

Deﬁnition 2.23 (Ciphertext Pseudorandomness for SKE). An SKE scheme satisﬁes ciphertext pseudo-
randomness if for any (stateful) QPT A, it holds that

2

AEnc(k,·)(ctb) = b

Pr



(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)



(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

1κ ← A(1λ), k ← Gen(1λ, 1κ),
m ← AEnc(k,·), b ← {0, 1},
ct0 ← Enc(k, m), ct1 ← {0, 1}ℓct 


−

≤ negl(λ).

1
2 (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Theorem 2.24. If OWFs exist, there exists an SKE scheme with sparseness and ciphertext pseudoran-
domness.

The well-known PRF-based SKE satisﬁes ciphertext pseudorandomness. However, we need padding
for sparseness. That is, a ciphertext is (r, PRFk(r) ⊕ 0ℓ−ℓµkm) where r ∈ {0, 1}n is randomness of
encryption, k is a PRF key, PRF : {0, 1}n → {0, 1}ℓ is a PRF, and |m| = ℓµ. We check that the ﬁrst
ℓ−ℓµ. If ℓ is suﬃciently long, the scheme has sparseness.
ℓ − ℓµ bits of m′ = Dec(k, (c1, c2)) equals to 0

Deﬁnition 2.25 (Constrained PRF (Syntax)). A constrained PRF (CPRF) with domain Dom, range
Ran, and constraint family F = {Fλ,κ}λ,κ∈N where Fλ,κ = { f : Dom → {0, 1}} is a tuple of four
algorithms.

Setup(1λ, 1κ) → msk: The setup algorithm takes as input the security parameter λ and a constraint-

family parameter κ, and outputs a master PRF key msk.

Constrain(msk, f ) → sk f : The constrain algorithm takes as input λ and a constraint f ∈ Fλ,κ, and

outputs a constrained key sk f .

Eval(msk, x) → y: The evaluation algorithm takes as input msk and an input x ∈ Dom, and outputs a

value y ∈ Ran.

CEval(sk f , x) → y: The constrained evaluation algorithm takes as input sk f and x ∈ Dom, and outputs

a value y ∈ Ran.

Deﬁnition 2.26 (Security for CPRF). A private CPRF should satisfy correctness, pseudorandomness,
and privacy.

Correctness: A CPRF is correct if for any (stateful) QPT adversary A, it holds that

Eval(msk, x) 6= CEval(sk f , x)
∧ x ∈ Dom ∧ f (x) = 0

Pr 

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
Selective single-key pseudorandomness: A CPRF is selectively single-key pseudorandom if for any









≤ negl(λ).



(1κ, f ) ← A(1λ),
msk ← Setup(1λ, 1κ),
sk f ← Constrain(msk, f ),
x ← AEval(msk,·)(sk f )

(stateful) QPT adversary A, it hods that

AEval(msk,·)(yb) = b
∧ x /∈ Qe
∧ f (x) 6= 0

Pr











2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

where Qe is the sets of queries to Eval(msk, ·).

(1κ, f ) ← A(1λ),
msk ← Setup(1λ, 1κ),
sk f ← Constrain(msk, f )
x ← AEval(msk,·)(sk f )
y0 := Eval(msk, x), y1 ← Ran,
b ← {0, 1}

≤ negl(λ),

−

1
2











(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

17

Selective single-key privacy: A CPRF is selectively single-key private if for any (stateful) QPT adversary

A, there exists a stateful PPT simulator Sim = (Sim1, Sim2) that satisfying that

2(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Pr 

A Ob(·)(skb) = b (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)





(1κ, f ) ← A(1λ),
msk ← Setup(1λ, 1κ), b ← {0, 1},
sk0 ← Constrain(msk, f ),
(stSim, sk1) ← Sim1(1κ, 1λ)

≤ negl(λ),



−





1
2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

where O0(·) := Eval(msk, ·) and O1(·) := Sim2(stSim, ·, f (·)).

We say that a CPRF is a selectively single-key private CPRF if it satisﬁes correctness, selective single-key
pseudorandomness, and selective single-key privacy.

Theorem 2.27 ([BTVW17, PS18]). If the QLWE assumption holds, there exists a selectively signle-key
private CPRF for polynomial-size classical circuits.

Deﬁnition 2.28 (PKE). A PKE with plaintext space P = {Pλ}λ∈N, ciphertext space C = {Cλ}λ∈N is
a tuple of three algorithms.

Gen(1λ) → (pk, sk): The key generation algorithm takes as input the security parameter λ and outputs

a key pair (pk, sk).

Enc(pk, m) → ct: The encryption algorithm takes as input pk, a plaintext m ∈ P , and outputs a

ciphertext ct ∈ C.

Dec(sk, ct) → m′/⊥: The decryption algorithm takes as input sk and ct ∈ C, and outputs a plaintext

m′ ∈ P or ⊥.

Correctness: A PKE scheme is correct if for all λ ∈ N and m ∈ Pλ, it holds that

Pr

Dec(sk, ct) = m | (pk, sk) ← Gen(1λ), ct ← Enc(pk, m)

= 1.

Deﬁnition 2.29 (CCA Security for PKE). A PKE scheme is CCA secure if for any (stateful) QPT
adversary A, it holds that

h

i

Pr 

b∗ = b
∧ ctb /∈ Q

2(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)





(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(pk, sk) ← Gen(1λ),
(m0, m1) ← ADec(sk,·)(1λ, pk),
b ← {0, 1}, ctb ← Enc(pk, mb),
b′ ← ADec(sk,·)(1λ, ctb)

≤ negl(λ),



−





1
2

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

where Q is the set of queries to Dec(sk, ·) after A is given ctb.

Theorem 2.30 ([Pei09]). If the QLWE assumption holds, there exists a PKE scheme that satisﬁes CCA
security.

Deﬁnition 2.31 (Indistinguishability Obfuscator [BGI+12]). A PPT algorithm iO is a secure IO for a
classical circuit class {Cλ}λ∈N if it satisﬁes the following two conditions.
Functionality: For any security parameter λ ∈ N, circuit C ∈ Cλ, and input x, we have that

Pr

C′(x) = C(x) | C′ ← iO(C)

= 1 .

Indistinguishability: For any PPT Samp and QPT distinguisher D, the following holds:

(cid:2)

(cid:3)

If Pr

∀x, C0(x) = C1(x) | (C0, C1, aux) ← Samp(1λ)

> 1 − negl(λ), then we have

(cid:2)
Advio

iO,D(λ) :=

Pr

D(iO(C0), aux) = 1 | (C0, C1, aux) ← Samp(1λ)

(cid:3)

(cid:12)
(cid:12)
(cid:12)

h
− Pr

i
D(iO(C1), aux) = 1 | (C0, C1, aux) ← Samp(1λ)

≤ negl(λ).

h

18

i(cid:12)
(cid:12)
(cid:12)

There are a few candidates of secure IO for polynomial-size classical circuits against quantum adver-
saries [BGMZ18, CHVW19, AP20, DQV+21]. In some candidates [WW21, GP21], the assumptions
behind the constructions were found to be false [HJL21].

3 Deﬁnition of Quantum Watermarking

We introduce deﬁnitions for watermarking PRFs against quantum adversaries in this section.

3.1 Syntax and Pseudorandomness

Deﬁnition 3.1 (Watermarking PRF). A watermarking PRF WMPRF for the message space M :=
{0, 1}ℓm with domain Dom and range Ran is a tuple of ﬁve algorithms (Setup, Gen, Eval, Mark, Extract ).
Setup(1λ) → (pp, xk): The setup algorithm takes as input the security parameter and outputs a public

parameter pp and an extraction key xk.

Gen(pp) → (prfk, τ): The key generation algorithm takes as input the public parameter pp and outputs

a PRF key prfk and a public tag τ.

Eval(prfk, x) → y: The evaluation algorithm takes as input a PRF key prfk and an input x ∈ Dom and

outputs y ∈ Ran.

Mark(pp, prfk, m) →

C: The mark algorithm takes as input the public parameter pp, a PRF key prfk,

and a message m ∈ {0, 1}ℓm , and outputs a marked evaluation circuit

C.

e

Extract (xk, τ, C ′, ǫ) → m′: The extraction algorithm takes as input an extraction key xk, a tag τ, a
quantum circuit with classical inputs and outputs C ′ = (q, U), and a parameter ǫ, and outputs m′
where m′ ∈ {0, 1}ℓm ∪ {unmarked}.

e

Evaluation Correctness: For any message m ∈ {0, 1}ℓm, it holds that

Pr 





C(x) = Eval(prfk, x) (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

e

(pp, xk) ← Setup(1λ)
(prfk, τ) ← Gen(pp)
C ← Mark(pp, prfk, m)
x ← Dom

e







≥ 1 − negl(λ).

Remark 3.2 (On extraction correctness). Usually, a watermarking PRF scheme is required to satisfy
extraction correctness that ensures that we can correctly extract the embedded mark from an honestly
marked circuit. However, as observed by Quach et al. [QWZ18], if we require the extraction correctness
to hold for a randomly chosen PRF key, it is implied by unremovability deﬁned below. Note that
the unremovability deﬁned below considers a distinguisher as a pirate circuit. However, it implies
the extraction correctness since we can easily transform an honestly marked circuit into a successful
distinguisher. Thus, we do not explicitly require a watermarking PRF scheme to satisfy extraction
correctness in this work.

Remark 3.3 (On public marking). We consider only watermarking PRFs with public marking as in Def-
inition 3.1 since we can achieve public marking by default. The reason is as follows. Suppose that we
generate pp, xk, and a marking key mk at the setup. When we generate a PRF key and a public tag at Gen,
we can ﬁrst generate (pp′, xk′, mk′) ← Setup(1λ) from scratch (ignoring the original (pp, xk, mk)) and
τ := (pp′, xk′, τ′) where (prfk′, τ′) ← Gen(pp′).
prfk := (prfk′, mk′) and a public tag
set a PRF key
prfk = (prfk′, mk′) by Mark(mk′, prfk′, m). There-
That is, anyone can generate a marked circuit from
fore, we consider public marking by default in our model.
b
d

d

19

Remark 3.4 (On private marking). We might prefer private marking in some settings since we might
want to prevent adversaries from forging a watermarked PRF. We can convert watermarking PRFs
in Deﬁnition 3.1 into ones with private marking by using signatures. Below, we assume that a PRF key
prfk includes its public tag τ since it does not harm security. At the setup phase, we also generate a
signature key pair (vk, sk) ← SIG.Gen(1λ) and set a mark key mk′ := (vk, sk) and an extraction key
xk′ := (xk, vk). To embed a message m into prfk, we generate a signature σ ← SIG.Sign(sk, τkm)
C ← Mark(pp, prfk, mkσ). To extract a message, we run m′ ← Extract (xk, τ, C ′, ǫ),
and generate
parse m′ = mkσ, and run SIG.Vrfy(vk, τkm, σ).
If the veriﬁcation result is ⊤, we output m. This
conversion is the same as what Goyal et al. [GKM+19] proposed. Adversaries cannot forge a signature
for τ∗km∗ 6= τkm by the unforgeability of SIG. Intuitively, if an adversary can forge a watermarked
PRF whose functionality is diﬀerent from those of watermarked PRFs given from a mark oracle, τ∗ 6= τ
should hold since public tags are related to PRF keys. This breaks the unforgeability of SIG. Thus, we
expect that adversaries cannot break the unforgeability of watermarking. However, we do not formally
deﬁne watermarking unforgeability against quantum adversaries since it is not a scope of this work. We
leave it as future work.

e

Discussion on syntax. Deﬁnition 3.1 is a natural quantum variant of classical watermarking PRFs
except that the key generation algorithm outputs a public tag τ, and the extraction algorithm uses it. Such
a public tag is not used in previous works on watermarking PRFs [CHN+18, KW21, QWZ18, KW19,
YAL+19]. A public tag should not harm watermarking PRF security. We justify using τ as follows.

First, we need to obtain many pairs of input and output to extract an embedded message from a marked
PRF in almost all known (classical) watermarking constructions [CHN+18, BLW17, KW21, QWZ18,
KW19, YAL+19, GKM+19, Nis20]. This is because we must check whether a tested PRF circuit outputs
particular values for particular inputs which depends on the target PRF (such particular inputs are known
as marked points). Suppose marked points are ﬁxed and do not depend on a PRF that will be marked. In
that case, an adversary can easily remove an embedded message by destroying functionalities at the ﬁxed
marked points that could be revealed via a (non-target) marked PRF that an adversary generated. Recall
that we consider the public marking setting. The attack was already observed by Cohen et al. [CHN+18].
Second, we consider a stronger adversary model than that in most previous works as the deﬁnition
of traceable PRFs by Goyal et al. [GKWW21]. An adversary outputs a distinguisher-based pirate circuit
in our security deﬁnition rather than a pirate circuit that computes an entire output of a PRF. This is a
reﬁned and realistic model, as Goyal et al. [GKWW21] argued (and we explain in Section 1.4). In this
model, we cannot obtain a valid input-output pair from a pirate circuit anymore. Such a pair is typical
information related to a target PRF. Goyal et al. resolve this issue by introducing a tracing key that is
generated from a target PRF. Note that parameters of watermarking (pp and xk) should not be generated
from a PRF since we consider many diﬀerent PRF keys in the watermarking PRF setting.

Thus, if we would like to achieve an extraction algorithm and the stronger security notion simulta-
neously, an extraction algorithm should somehow take information related to a target PRF as input to
correctly extract an embedded message. In the weaker adversary model, an extraction algorithm can
easily obtain many valid input and output pairs by running a tested circuit many times. However, in the
stronger distinguisher-based pirate circuit model, a pirate circuit outputs a single decision bit.

To resolve this issue, we introduce public tags. We think it is natural to have information related to
the original PRF key in an extraction algorithm. In reality, we check a circuit when a user claims that
her/his PRF key (PRF evaluation circuit) is illegally used. Thus, it is natural to expect we can use a user’s
public tag for extraction. This setting resembles watermarking for public-key cryptographic primitives,
where a user public key is available in an extraction algorithm. In addition, public tags do not harm
PRF security in our constructions. It is unclear whether we can achieve unremovability in the stronger
distinguisher-based model without any syntax change (even in the classical setting). 10

10Even if we consider the weaker adversary model, the same issue appears in the quantum setting in the end. If we run a

20

Extended pseudorandomness. We consider extended weak pseudorandomness, where weak pseu-
dorandomness holds even if the adversary generates pp. This notion is the counterpart of extended
pseudorandomness by Quach et al. [QWZ18], where pseudorandomness holds in the presence of the
extraction oracle. However, our pseudorandomness holds even against an authority unlike extended
pseudorandomness by Quach et al. since we allow adversaries to generate a public parameter.

Deﬁnition 3.5 (Extended Weak Pseudorandomness against Authority). To deﬁne extended weak
pseudorandomness for watermarking PRFs, we deﬁne the game Expext-wprf

A,WMPRF(λ) as follows.

1. A ﬁrst sends pp to the challenger.

2. The challenger generates (prfk, τ) ← Gen(pp) and sends τ to A.

3. The challenger chooses coin ← {0, 1}. A can access to the following oracles.

Owprf: When this is invoked (no input), it returns (a, b) where a ← Dom and b := Eval(prfk, a).
Ochall: When this is invoked (no input), it returns:

• (a, b) where a ← Dom and b := Eval(prfk, a) if coin = 0,
• (a, b) where a ← Dom and b ← Ran if coin = 1.

This oracle is invoked only once.

4. When A terminates with output coin′, the challenger outputs 1 if coin = coin′ and 0 otherwise.

We say that WMPRF is extended weak pseudorandom if for every QPT A, we have

Advext-wprf

A,WMPRF(λ) = 2

Pr

Expext-wprf

A,WMPRF(λ) = 1

h

(cid:12)
(cid:12)
(cid:12)
(cid:12)

3.2 Unremovability against Quantum Adversaries

= negl(λ).

−

1
2

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

We deﬁne unremovability for watermarking PRFs against quantum adversaries.

Deﬁnition 3.6 (Unremovability for private extraction). We consider the public marking and secret
extraction setting here. Let ǫ ≥ 0. We deﬁne the game Exptnrmv

A,WMPRF(λ, ǫ) as follows.

1. The challenger generates (pp, xk) ← Setup(1λ) and gives pp to the adversary A. A send
m ∈ {0, 1}ℓm to the challenger. The challenger generates (prfk, τ) ← Gen(pp), computes
C ← Mark(pp, prfk, m), and sends τ and

C to A.

2. A can access to the following oracle.

e
Oext: On input τ′ and a quantum circuit C , it returns Extract (xk, C , τ′, ǫ).

e

3. Finally, the adversary outputs a “pirate” quantum circuit C

is a quantum
program with classical inputs and outputs whose ﬁrst register (i.e., output register) is C2 and U is
a compact classical description of {U x,y}x∈Dom,y∈Ran.

= (q, U), where C

A

A

Let D be the following distribution.

D: Generate b ← {0, 1}, x ← Dom, and y0 ← Ran. Compute y1 ← Eval(prfk, x). Output (b, x, yb).

quantum circuit for an input and measure the output, the measurement could irreversibly alter the quantum state and we lost the
functionality of the original quantum state. That is, there is no guarantee that we can correctly check whether a tested quantum
circuit is marked or not after we obtain a single valid pair of input and output by running the circuit. However, as we explained
above, we want to obtain information related to a target PRF for extraction. Thus, we need a public tag in the syntax in either
case.

21

We also let P = (Pb,x,y, Qb,x,y)b,x,y be a collection of binary outcome projective measurements, where

Pb,x,y = U †

x,y |bi hb| U x,y

and Qb,x,y = I − Pb,x,y.

Moreover, we let MD = (PD, QD) be binary outcome POVMs, where

PD = ∑
r∈R

1
|R|

PD(r)

and QD = I − PD.

Live: When applying the measurement ProjImp(MD) to q, we obtain a value p such that p ≥ 1
GoodExt: When Computing m′ ← Extract (xk, C

, τ, ǫ), it holds that m′ 6= unmarked.

2 + ǫ.

BadExt: When Computing m′ ← Extract (xk, C

, τ, ǫ), it holds that m′ /∈ {m, unmarked}.

A

A

We say that WMPRF satisﬁes unremovability if for every ǫ > 0 and QPT A, we have

Pr[BadExt] ≤ negl(λ)

and Pr[GoodExt] ≥ Pr[Live] − negl(λ).

Intuitively, (Pb,x,y, Qb,x,y) is a projective measurement that feeds (x, y) to C

and checks whether
the outcome is b or not (and then uncomputes). Then, MD can be seen as POVMs that results in 0 with
the probability that C

can correctly guess b from (x, yb) for (b, x, yb) generated randomly from D.

A

A

Remark 3.7 (On attack model). We check whether C
correctly distinguishes a real PRF value from a
random value or not by applying ProjImp(MD) to q. This attack model follows the reﬁned and more
realistic attack model by Goyal et al. [GKWW21]. The adversary outputs a pirate circuit that computes
an entire PRF value in all previous works except their work.

A

The distinguisher-based pirate circuit model is compatible with the (quantum) pirate decoder model
of traitor tracing. Thus, our attack model also follows the attack model of quantum traitor tracing (the
black box projection model) by Zhandry [Zha20, Section 4.2].11

As in the traitor tracing setting [Zha20], ProjImp(MD) is ineﬃcient in general. We can handle
this issue as Zhandry did. We will use an approximate version of ProjImp(MD) to achieve an eﬃcient
reduction. In addition, we cannot apply both ProjImp(MD) and Extract to C
simultaneously. However,
the condition Pr[GoodExt] ≥ Pr[Live] − negl(λ) claims that an embedded mark cannot be removed
as long as the pirate circuit is alive. This ﬁts the spirit of watermarking. See Zhandry’s paper [Zha20,
Section 4] for more discussion on the models.

A

Remark 3.8 (On selective message). As we see in Deﬁnition 3.6, we consider the selective setting for
private extraction case, where A must send the target message m to the challenger before A accesses to
the oracle Oext and after pp is given. This is the same setting as that by Quach et al. [QWZ18]. We
can consider the fully adaptive setting, where A can send the target message m after it accesses to the
oracle Oext, as Kim and Wu [KW19]. However, our privately extractable watermarking PRF satisﬁes
only selective security. Thus, we write only the selective variant for the private extraction case.

Deﬁnition 3.9 (Unremovability for Public Extraction). This is the same as Deﬁnition 3.6 except we
use the game Exppub-ext-nrmv
(λ, ǫ) deﬁned in the same way as Exptnrmv
A,WMPRF(λ, ǫ) except the following
diﬀerences.

A,WMPRF

• In item 1, A is given xk together with pp.
• Item 2 is removed.

11In the watermarking setting, an extraction algorithm can take the description of a pirate circuit as input (corresponding
to the software decoder model [Zha20, Section 4.2]), unlike the black-box tracing model of traitor tracing. However, we
use a pirate circuit in the black box way for our extraction algorithms. Thus, we follow the black box projection model by
Zhandry [Zha20].

22

4 Deﬁnition of Extraction-Less Watermarking

We introduce the notion of extraction-less watermarking PRF as an intermediate primitive towards
watermarking PRFs secure against quantum adversaries.

4.1 Syntax and Pseudorandomness

Deﬁnition 4.1 (Extraction-Less Watermarking PRF). An extraction-less watermarking PRF WMPRF
for the message space {0, 1}ℓm with domain Dom and range Ran is a tuple of ﬁve algorithms (Setup, Gen, Eval, Mark, Sim),
where the ﬁrst four algorithms have the same input/output behavior as those deﬁned in Deﬁnition 3.1
and Sim has the following input/output behavior.

Sim(xk, τ, i) → (γ, x, y): The simulation algorithm Sim takes as input the extraction key xk, a tag τ,

and an index i, and outputs a tuple (γ, x, y).

Evaluation Correctness: It is deﬁned in exactly the same way as the evaluation correctness for water-

marking PRF deﬁned in Deﬁnition 3.1.

Extended pseudorandomness. Extended pseudorandomness for extraction-less watermarking PRF is
deﬁned in exactly the same way as that for watermarking PRF, that is Deﬁnition 3.5.

4.2 Simulatability for Mark-Dependent Distributions (SIM-MDD Security)

We introduce the security notion for extraction-less watermarking PRF that we call simulatability for
mark-dependent distributions. Let D and Drev be the following distributions.

D: Generate b ← {0, 1}, x ← Dom, and y0 ← Ran. Compute y1 ← Eval(prfk, x). Output (b, x, yb).
Drev: Generate (b, x, y) ← D. Output (1 ⊕ b, x, y).

Namely, D is the distribution that outputs a random value if the ﬁrst bit b = 0 and a PRF evaluation if
the ﬁrst bit b = 1, and Drev is its opposite (i.e., a PRF evaluation if b = 0 and a random value if b = 1).
C ← Mark(mk, prfk, m)
SIM-MDD security is a security notion that guarantees that an adversary given
cannot distinguish an output of Sim(xk, τ, i) from that of D if m[i] = 0 and from that of Drev if m[i] = 1.

Deﬁnition 4.2 (SIM-MDD Security with Private Simulation). To deﬁne SIM-MDD security with
private simulation, we deﬁne the game Exptsim-mdd

i∗,A,WMPRF(λ) as follows, where i∗ ∈ [ℓm].

e

1. The challenger generates (pp, xk) ← Setup(1λ) and sends pp to A. A sends m ∈ {0, 1}ℓm to the
C ← Mark(mk, prfk, m).

challenger. The challenger generates (prfk, τ) ← Gen(pp) and computes
The challenger sends τ and

C to A.

2. A can access to the following oracle.

e
Osim: On input τ′ and i′ ∈ [ℓm], it returns Sim(xk, τ′, i′).

e

3. Let Dreal,i∗ be the following distribution. Note that Dreal,i∗ is identical with D if m[i∗] = 0 and

with Drev if m[i∗] = 1.

Dreal,i∗: Generate γ ← {0, 1} and x ← Dom. Then, if γ = m[i∗], generate y ← Ran, and

otherwise, compute y ← Eval(prfk, x). Output (γ, x, y).

The challenger generates coin ← {0, 1}. If coin = 0, the challenger samples (γ, x, y) ← Dreal,i∗.
If coin = 1, the challenger generates (γ, x, y) ← Sim(xk, τ, i∗). The challenger sends (γ, x, y)
to A.

23

4. When A terminates with output coin′, the challenger outputs 1 if coin = coin′ and 0 otherwise.

Note that A is not allowed to access to Osim after A is given (γ, x, y).

We say that WMPRF is SIM-MDD secure if for every i∗ ∈ [ℓm] and QPT A, we have

Advsim-mdd

i∗,A,WMPRF(λ) = 2

Pr

Exptsim-mdd

i∗,A,WMPRF(λ) = 1

−

= negl(λ).

We consider the selective setting above as unremovability for private extraction in Deﬁnition 3.6 since

we use SIM-MDD security with private simulation to achieve unremovability for private simulation.

h

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
2

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Remark 4.3 (On multi challenge security). We can prove that the above deﬁnition implies the multi-
challenge variant where polynomially many outputs of Sim(xk, τ, i∗) are required to be indistinguishable
from those of Dreal,i∗. This is done by hybrid arguments where outputs of Sim(xk, τ, i∗) are simulated
using Osim and those of Dreal,i∗ are simulated using
C. To apply Theorem 2.11, we need the multi
challenge variant. However, we consider the single challenge variant due to the implication above. A
similar remark is applied to the variants of SIM-MDD security introduced below.

e

P ,Dτ′,i′

SIM-MDD security with private simulation under the API oracle. Let the API oracle be an oracle
that is given (ǫ, δ, τ′, i′) and a quantum state q, and returns the result of API ǫ,δ
(q) and the post mea-
surement state, where P is deﬁned in the same way as that in Deﬁnition 3.6 and Dτ′,i′ be the distribution
that outputs randomly generated (γ, x, y) ← Sim(xk, τ′, i′). The API oracle cannot be simulated using
the simulation oracle Osim since we need superposition of outputs of Sim to compute API ǫ,δ
(q).
When constructing watermarking PRFs with private simulation from extraction-less watermarking PRFs,
the underlying extraction-less watermarking PRF scheme needs to satisfy SIM-MDD security with pri-
vate simulation under the API oracle that we call QSIM-MDD security with private simulation. The
reason is as follows. In the security analysis of the construction, the indistinguishability guarantee pro-
vided by SIM-MDD security needs to hold for an adversary against the resulting watermarking scheme
who can access the extraction oracle. This means that it also needs to hold for an adversary who can
access the API oracle since API is repeatedly invoked in the extraction algorithm of the resulting scheme.
Fortunately, as we will see, we can generically convert an extraction-less watermarking PRF scheme
satisfying SIM-MDD security with private simulation into one satisfying QSIM-MDD security with
private simulation, using QPRFs. Thus, when realizing an extraction-less watermarking PRF scheme as
an intermediate step towards privately extractable watermarking PRFs, we can concentrate on realizing
one satisfying SIM-MDD security with private simulation.

P ,Dτ′,i′

Remark 4.4. There is a similar issue in the traitor tracing setting. If PLBE is a secret-key based one,
we need a counterpart of QSIM-MDD in secret-key based PLBE to achieve traitor tracing with a secret
tracing algorithm against quantum adversaries by using Zhandry’s framework [Zha20]. Note that Zhandry
focuses on public-key based PLBE in his work [Zha20].

Deﬁnition 4.5 (QSIM-MDD Security with Private Simulation). Let Dτ,i be a distribution deﬁned as
follows.

Dτ,i: Output (γ, x, y) ← Sim(xk, τ, i).
Then, we deﬁne the game Expq-sim-mdd
to Osim, A can access to the following oracle in the step 2.
Oapi: On input (ǫ, δ, τ′, i′) and a quantum state q, it returns the result of API ǫ,δ

i∗,A,WMPRF(λ) in the same way as Expsim-mdd

P ,Dτ′,i′
measurement state, where P is deﬁned in the same way as that in Deﬁnition 3.6.

i∗,A,WMPRF(λ) except that in addition

(q) and the post

24

We say that WMPRF is QSIM-MDD secure with private simulation if for every i∗ ∈ [ℓm] and QPT

A, we have

Advq-sim-mdd

i∗,A,WMPRF(λ) = 2

We have the following theorem.

Pr

Expq-sim-mdd

i∗,A,WMPRF(λ) = 1

h

(cid:12)
(cid:12)
(cid:12)
(cid:12)

−

1
2

i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

= negl(λ).

Theorem 4.6. Assume there exists an extraction-less watermarking PRF scheme satisfying SIM-MDD
security with private simulation and a QPRF. Then, there exists an extraction-less watermarking PRF
scheme satisfying QSIM-MDD security with private simulation.

We prove this theorem in Appendix A.

Deﬁnition 4.7 (SIM-MDD Security with Public Simulation). We deﬁne the game Expsim-mdd-pub
in the same way as Exptsim-mdd

i∗,A,WMPRF(λ) except the following diﬀerences, where i∗ ∈ [ℓm].

i∗,A,WMPRF (λ)

• In item 1, A is given xk together with pp.
• Item 2 is removed.
We say that WMPRF satisﬁes SIM-MDD security with public simulation if for every i∗ ∈ [ℓm] and

QPT A, we have

Advsim-mdd-pub

i∗,A,WMPRF (λ) = 2

5 Watermarking PRF from Extraction-Less Watermarking PRF

Pr

Expsim-mdd-pub

i∗,A,WMPRF (λ) = 1

h

−

1
2

i

= negl(λ).

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

We show how to construct watermarking PRF secure against quantum adversaries from extraction-less
watermarking PRF.

Let ELWMPRF = (Setup, Gen, Eval, Mark, Sim) be an extraction-less watermarking PRF scheme
whose message space is {0, 1}ℓm +1. We construct a watermarking PRF scheme WMPRF = (WM.Setup,
WM.Gen, WM.Eval, WM.Mark, Extract ) whose message space is {0, 1}ℓm as follows. We use Setup,
Gen, and Eval as WM.Setup, WM.Gen, and WM.Eval, respectively. Thus, the domain and range of
WMPRF are the same as those of ELWMPRF. Also, we construct WM.Mark and Extract as follows.

WM.Mark(pp, prfk, m):

• Output

C ← Mark(pp, prfk, mk0).

Extract (xk, C , τ, ǫ):
e

• Let ǫ′ = ǫ/4(ℓm + 1) and δ′ = 2−λ.
• Parse (q, U) ← C .
• Let P be deﬁned in the same way as that in Deﬁnition 3.6 and Dτ,i be the following

distribution for every i ∈ [ℓm + 1].

Dτ,i: Output (γ, x, y) ← Sim(xk, τ, i).
pℓm+1 ← API ǫ′,δ′

(q). If

• Compute

P ,Dτ,ℓm+1

pℓm+1 < 1

2 + ǫ − 4ǫ′, return unmarked. Otherwise,

letting q0 be the post-measurement state, go to the next step.

• For all i ∈ [ℓm], do the following.

e

e

1. Compute

pi ← API ǫ′,δ′
P ,Dτ,i

(qi−1). Let qi be the post-measurement state.

e

25

2. If

pi > 1

2 + ǫ − 4(i + 1)ǫ′, set m′
If
Otherwise, exit the loop and output m′ = 0ℓm.

i = 0.

pi < 1

2 − ǫ + 4(i + 1)ǫ′, set m′

i = 1.

e
• Output m′ = m′

1k · · · km′
ℓm

.

We have the following theorems.

e

Theorem 5.1. If ELWMPRF satisﬁes extended weak pseudorandomness against authority, then so does
WMPRF.

Theorem 5.2. If ELWMPRF is an extraction-less watermarking PRF that satisﬁes QSIM-MDD security,
WMPRF is a privately extractable watermarking PRF.

Theorem 5.3. If ELWMPRF is an extraction-less watermarking PRF that satisﬁes SIM-MDD security
with public simulation, WMPRF is a publicly extractable watermarking PRF.

It is clear that Theorem 5.1 holds since the evaluation algorithm of WMPRF is the same as that
of ELWMPRF and extended weak pseudorandomness is insensitive to how the marking and extraction
algorithms are deﬁned. Thus, we omit a formal proof.

The proofs of Theorems 5.2 and 5.3 are almost the same. Thus, we only provide the proof for the

former, and omit the proof for the latter.

Proof of Theorem 5.2. Let ǫ > 0. Let A be a QPT adversary attacking the unremovability of WMPRF.
The description of Exptnrmv

A,WMPRF(λ, ǫ) is as follows.

1. The challenger generates (pp, xk) ← Setup(1λ) and gives pp to the adversary A. A sends
m ∈ {0, 1}ℓm to the challenger. The challenger generates (prfk, τ) ← Gen(pp), computes
C ← Mark(pp, prfk, mk0), and sends

C to A.

2. A can access to the following oracle.

e
Oext: On input τ′ and a quantum circuit C , it returns Extract (xk, C , τ′, ǫ).

e

3. Finally, the adversary outputs a quantum circuit C

= (q, U).

A

We deﬁne D, P , MD, and the three events Live, GoodExt, and BadExt in the same way as

Deﬁnition 3.6.

The proof of Pr[GoodExt] ≥ Pr[Live] − negl(λ). Extract outputs unmarked if and only if
2 + ǫ − 4ǫ′, that is we have Pr[GoodExt] = Pr
1
by applying ProjImp(MD) to q. Then, we have Pr[Live] = Pr
obtained if we apply API ǫ′,δ′

pℓ+1 <
. Let p the probability obtained
p be the outcome
2 + ǫ

P ,D to q. From the property of API , we have

2 + ǫ − 4ǫ′

pℓ+1 ≥ 1

p ≥ 1
(cid:3)

. Let

e

e

(cid:2)

(cid:2)

(cid:3)

e

Pr[Live] = Pr

p ≥

(cid:20)

1
2

+ ǫ

≤ Pr

p ≥

(cid:21)

(cid:20)

1
2

+ ǫ − ǫ′

+ negl(λ).

(cid:21)

D and Dτ,ℓm+1 are computationally indistinguishable from the QSIM-MDD security of ELWMPRF since
outputs of Sim(xk, τ, i) is indistinguishable from those of D if m[i] = 0. This indistinguishability holds
even under the existence of Oapi. Then, from Theorem 2.11, we have

e

Pr

p ≥

(cid:20)

1
2

+ ǫ − ǫ′

≤ Pr

pℓ+1 ≥

(cid:21)

(cid:20)

1
2

+ ǫ − 4ǫ′

+ negl(λ) = Pr[GoodExt] + negl(λ).

(cid:21)

By combining the above two equations, we obtain Pr[GoodExt] ≥ Pr[Live] − negl(λ).

e

e

26

The reason D and Dτ,ℓ+1 need to be computationally indistinguishable under the existence of Oapi
to apply Theorem 2.11 is as follows. In this application of Theorem 2.11, the quantum state appeared
in the statement of it is set as q contained in the quantum circuit C output by A. Then, Theorem 2.11
(implicitly) requires that D and Dτ,ℓ+1 be indistinguishable for distinguishers who can construct q. To
construct q, we need to execute A who can access to Oext in which API is repeatedly executed. This is
the reason D and Dτ,ℓ+1 need to be indistinguishable under the existence of Oapi.

The proof of Pr[BadExt] ≤ negl(λ). We deﬁne the event BadExti as follows for every i ∈ [ℓm].
BadExti: When Running Extract (xk, C

, τ∗, ǫ), the following conditions hold.

A

pℓ+1 ≥ 1

2 + ǫ − 4ǫ′ holds.
j = mj holds for every j ∈ [i − 1].

•
• m′
e
• Extract exits the i-th loop or m′

i 6= mi holds.

Then, we have Pr[BadExt] ≤ ∑i∈[ℓ] Pr[BadExti]. Below, we estimate Pr[BadExti].

We ﬁrst consider the case of mi−1 = 0 and mi = 0. Assume m′
pi−1 > 1

i−1 = mi−1 = 0 holds. Then, we
(qi−1). From, the almost-projective property of API ,

i−1 ← API ǫ′,δ′
p′

2 + ǫ − 4iǫ′. Let

P ,Dτ,i−1

have
we have
e

e
Pr

(cid:20)

p′
i−1

> 1
2

+ ǫ − 4iǫ′ − ǫ′

≥ 1 − δ′.

(cid:21)

When mi−1 = 0 and mi = 0, Dτ,i−1 and Dτ,i are computationally indistinguishable since both of
them are computationally indistinguishable from D by the QSIM-MDD security of ELWMPRF. This
indistinguishability holds under the existence of Oapi. Thus, from Theorem 2.11, we have

e

1 − δ′ ≤ Pr

p′
i−1

(cid:20)

> 1
2

+ ǫ − (4i + 1)ǫ′

≤ Pr

(cid:21)

(cid:20)

pi > 1
2

+ ǫ − 4(i + 1)ǫ′

+ negl(λ).

(cid:21)

e

This means that Pr[BadExti] = negl(λ) in this case. Note that the reason the indistinguishability of
Dτ,i−1 and Dτ,i needs to hold under Oapi is that Theorem 2.11 requires it hold for distinguishers who
can construct qi−1.

Next, we consider the case of mi−1 = 0 and mi = 1. Assume m′
pi−1 > 1

2 + ǫ − 4iǫ′. We then deﬁne an additional distribution Drev

i−1 = mi−1 = 0 holds. Then, we
τ,i as follows.

e

τ,i : Generate (γ, x, y) ← Sim(xk, τ, i). Output (1 ⊕ γ, x, y).

τ,i (r), QDrev

That is, the ﬁrst bit of the output is ﬂipped from Dτ,i. Then, for any random coin r, we have
τ,i (r)) = (QDτ,i(r), PDτ,i(r)). This is because we have Qb,x,y = I − Pb,x,y = P1⊕b,x,y
(PDrev
for any tuple (b, x, y). Therefore, API ǫ′,δ′
. Let
i−1 ← API ǫ′,δ′
p′

(qi−1). From, the reverse-almost-projective property of API , we have

is exactly the same process as API ǫ′,δ′

P rev,Dτ,i−1

P ,Drev

P ,Drev

τ,i−1

τ,i−1

have
Drev

e

e

Pr

p′
i−1

− ǫ + 4iǫ′ + ǫ′

≥ 1 − δ′.

< 1
2

(cid:20)
When mi−1 = 0 and mi = 1, Drev
e
τ,i−1 and Dτ,i are computationally indistinguishable since both of them
are computationally indistinguishable from the following distribution Drev by the QSIM-MDD security
of ELWMPRF.
Drev: Generate (γ, x, y) ← D. Output (1 ⊕ γ, x, y).

(cid:21)

27

This indistinguishability holds under the existence of Oapi. Thus, from Theorem 2.11, we have

1 − δ′ ≤ Pr

p′
i−1

(cid:20)

< 1
2

− ǫ + (4i + 1)ǫ′

≤ Pr

(cid:21)

(cid:20)

pi < 1
2

− ǫ + 4(i + 1)ǫ′

+ negl(λ).

(cid:21)

This means that Pr[BadExti] = negl(λ) also in this case. Note that the reason the indistinguishability
of Drev
τ,i−1 and Dτ,i needs to hold under Oapi is that Theorem 2.11 requires it hold for distinguishers who
can construct qi−1.

e

e

Similarly, we can prove that Pr[BadExti] = negl(λ) holds in the case of (mi−1, mi) = (1, 0) and

(mi−1, mi) = (1, 1).

Overall, we see that Pr[BadExt] = negl(λ) holds in all cases.

6 Extraction-Less Watermarking PRF from LWE

We present an extraction-less watermarking PRF, denoted by PRFcprf , whose message space is {0, 1}ℓm
with domain {0, 1}n and range {0, 1}m. We use the following tools, which can be instantiated with the
QLWE assumption (See Theorems 2.24, 2.27 and 2.30):

• Private CPRF CPRF = (CPRF.Setup, CPRF.Eval, CPRF.Constrain, CPRF.CEval). For ease of
notation, we denote CPRF evaluation circuit CPRF.Eval(msk, ·) and constrained evaluation circuits
CPRF.CEval(sk f , ·) by G : {0, 1}n → {0, 1}m and G/∈V : {0, 1}n → {0, 1}m, respectively, where
x ∈ V iﬀ f (x) = 1.

• SKE scheme SKE = (SKE.Gen, SKE.Enc, SKE.Dec). The plaintext space and ciphertext space

of SKE are {0, 1}ℓske and {0, 1}n, respectively, where ℓske = log ℓm + 1.

• PKE scheme PKE = (Gen, Enc, Dec). The plaintext space of PKE is {0, 1}2λ.

Construction overview. We already explained the high-level idea for how to realize extraction-less
watermarking PRFs in Section 1.3. However, the construction of PRFcprf requires some additional eﬀorts.
Thus, before providing the actual construction, we provide a high-level overview of PRFcprf .

C ← Mark(pp, prfk, m) and (γ∗, x∗, y∗) ← Sim(xk, τ, i∗), we have to design

Sim and

Recall that letting
C so that
• If γ = m[i∗],
• If γ 6= m[i∗],

e

e

C(x∗) outputs a value diﬀerent from y∗.
C(x∗) outputs y∗.
e

e

In the token-based construction idea, we achieve these conditions by setting x∗ as an encryption of
y∗ki∗kγ∗ and designing
C as a token such that it outputs y∗ if the input is decryptable and γ∗ 6= m[i∗]
holds for the decrypted value y∗ ki∗kγ∗, and otherwise behaves as the original evaluation circuit. However,
in PRFcprf , we use a constrained evaluation circuit of CPRF as
C, and thus we cannot program output
values for speciﬁc inputs. Intuitively, it seems that Sim needs to use the original PRF key prfk to achieve
the above two conditions.

e

e

To solve the issue, we adopt the idea used by Quach et al. [QWZ18]. In PRFcprf , the setup algorithm
Setup generates (pk, sk) ← Gen(1λ) of PKE, and sets pp = pk and xk = sk. Then, the PRF key
generation algorithm is given pk, generates G ← CPRF.Setup(1λ, 1κ) along with ske.k ← SKE.Gen(1λ),
and sets the public tag τ as an encryption of (G, ske.k) under pk. The evaluation algorithm of PRFcprf
is simply that of CPRF.

Now, we explain how to design Sim and

C ← Mark(pp, prfk, m) to satisfy the above two conditions.
Given xk = sk, τ = Enc(pk, prfk) and i, Sim is able to extract prfk = (G, ske.k). Then, Sim generates
γ ← {0, 1} and sets x ← SKE.Enc(ske.k, ikγ) and y ← G(x). We set
C as a constrained version of
G for a circuit D that outputs 1 if the input x is decryptable by ske.k and γ = m[i] holds for decrypted

e

28

e

value ikγ, and otherwise outputs 0. For an input x, the constrained version of G outputs the correct
output G(x) if and only if D(x) = 0. We can check that PRFcprf satisﬁes the above two conditions.

The above construction does not satisfy extended weak pseudorandomness against authority since
the authority can extract the original CPRF key G by xk = sk. However, this problem can be ﬁxed by
constraining G. We see that Sim needs to evaluate G for valid ciphertexts of SKE. Thus, to implement
the above mechanism, it is suﬃcient to set the public tag τ as an encryption of ske.k and a constrained
version of G for a circuit Dauth that output 0 if and only if the input is decryptable by ske.k. Then, the
authority can only extract such a constrained key. By requiring sparseness for SKE, the constrained key
cannot be used to break the pseudorandomness of PRFcprf for random inputs. This means that PRFcprf
satisﬁes extended weak pseudorandomness against an authority. Note that we only need a single-key
CPRF for PRFcprf since either a user or the authority (not both) is a malicious entity in security games.

The description of PRFcprf is as follows.

Setup(1λ):

• Generate (pk, sk) ← Gen(1λ).
• Output (pp, xk) := (pk, sk).

Gen(pp):

• Parse pp = pk.
• Generate G ← CPRF.Setup(1λ, 1κ). In our construction, κ is the size of circuit D[ske.k, m]

described in Figure 5, which depends on ℓm (and λ).

• Generate ske.k ← SKE.Gen(1λ).
• Construct a circuit Dauth[ske.k] described in Figure 4.
• Compute G/∈Vauth := CPRF.Constrain(G, Dauth[ske.k]), where Vauth ⊂ {0, 1}n is a set such

that x ∈ Vauth iﬀ Dauth[ske.k](x) = 1.

• Output prfk := (G, ske.k) and τ ← Enc(pk, (G/∈Vauth , ske.k)).

Eval(prfk, x ∈ {0, 1}n): Recall that G is a keyed CPRF evaluation circuit.

• Parse prfk = (G, ske.k).
• Output y := G(x).

Mark(pp, prfk, m):

• Parse pp = pk and prfk = (G, ske.k).
• Construct a circuit D[ske.k, m] described in Figure 5.
• Compute G/∈V ← CPRF.Constrain(G, D[ske.k, m]), where V ⊂ {0, 1}n is a set such that

x ∈ V iﬀ D[ske.k, m](x) = 1.

• Output

C = G/∈V .

Sim(xk, τ, i):

e

• Parse xk = sk.
• Compute (G/∈Vauth , ske.k) ← Dec(sk, τ).
• Choose γ ← {0, 1}.
• Compute x ← SKE.Enc(ske.k, ikγ) and y ← G/∈Vauth (x).
• Output (γ, x, y).

29

Circuit Dauth[ske.k]

Constants: An SKE key ske.k, and a message m.
Input: A string x ∈ {0, 1}n.

1. Compute d ← SKE.Dec(ske.k, x).
2. Output 0 if d 6= ⊥ and 1 otherwise.

Figure 4: The description of Dauth

Circuit D[ske.k, m]

Constants: An SKE key ske.k, and a message m.
Input: A string x ∈ {0, 1}n.

1. Compute d ← SKE.Dec(ske.k, x).
2. If d 6= ⊥, do the following

(a) Parse d = ikγ, where i ∈ [ℓm] and γ ∈ {0, 1}.
(b) If γ = m[i], output 1. Otherwise, output 0.

3. Otherwise output 0.

Figure 5: The description of D

The evaluation correctness of PRFcprf follows from the sparseness of SKE and the correctness of

CPRF. For the security of PRFcprf , we have the following theorems.

Theorem 6.1. SKE is a secure SKE scheme with pseudorandom ciphertext, CPRF is a selectively single-
key private CPRF, PKE is a CCA secure PKE scheme, then PRFcprf is an extraction-less watermarking
PRF satisfying SIM-MDD security.

Theorem 6.2. If CPRF is a selective single-key private CPRF, PRFcprf satisﬁes extended weak pseudo-
randomness.

SIM-MDD security. First, we prove the SIM-MDD security of PRFcprf .

Proof of Theorem 6.1. We deﬁne a sequence of hybrid games to prove the theorem.
Hyb0: This is the same as the case coin = 1 in Expsim-mdd

In this game, A is given τ ←
Enc(pk, (G/∈Vauth , ske.k)) and G/∈V ← CPRF.Constrain(G, D[ske.k, m]) as a public tag and a
marked circuit. After τ and G/∈V are given, A can access to Osim. Finally, after ﬁnishing the
access to Osim, A is given (γ∗, x∗, y∗)) as the challenge tuple and outputs coin′ ∈ {0, 1}, where
γ∗ ← {0, 1}, x∗ ← SKE.Enc(ske.k, i∗kγ∗), and y∗ ← G/∈Vauth (x∗).

i∗,A,PRFcprf (λ).

Hyb1: This is the same as Hyb0 except for the following two changes. First, G is used instead of G/∈Vauth
when generating the challenge tuple (γ∗, x∗, y∗). Second, we change the behavior of Osim as
follows. When A sends τ′ and i′ to Osim, if τ′ = τ, Osim performs the remaining procedures by
using (G, ske.k) (without decrypting τ′ = τ).

Hyb2: This is the same as Hyb1 except that we use τ ← Enc(pk, 02λ) instead of τ ← Enc(pk, (G/∈Vauth , ske.k)).
Hyb3: This is the same as Hyb2 except that if m[i∗] = γ∗, we use y∗ ← {0, 1}m instead of y∗ ← G(x∗).
G) ← CPRF.Sim1(1κ, 1λ) instead
Hyb4: This is the same as Hyb3 except that we use a simulated (stSim,
of G/∈V ← CPRF.Constrain(G, D[ske.k, m]) for the challenge marked circuit. Also, if m[i∗] 6= γ∗,

b

30

the challenger computes y∗ ← Sim2(stSim, x∗, 0). In addition, we also change the behavior of
Osim as follows. Given τ′ and i′, if τ′ 6= τ, Osim answers in the same way as Hyb3. Otherwise,
it returns (γ, x, y), where γ ← {0, 1}, x ← SKE.Enc(ske.k, i′kγ), and y ← Sim2(stSim, x, 1) if
m[i′] = γ and y ← Sim2(stSim, x, 0) otherwise.

Hyb5: This is the same as Hyb4 except that we use x∗ ← {0, 1}n instead of x∗ ← SKE.Enc(ske.k, i∗kγ∗).
Hyb6: We undo the change at Hyb4.
Hyb7: We undo the change at Hyb2.
Hyb8: We undo the change at Hyb1. This is the same as the case coin = 0 in Expsim-mdd

i∗,A,PRFcprf (λ).

Proposition 6.3. If CPRF, SKE, and PKE are correct, it holds that |Pr[Hyb0 = 1] − Pr[Hyb1 = 1]| ≤
negl(λ).

Proof of Proposition 6.3. For the ﬁrst change, x∗ /∈ Vauth holds since ⊥ 6= SKE.Dec(ske.k, x∗) from
the correctness of SKE. Then, from the correctness of CPRF, we have G/∈Vauth (x∗) = G(x∗), and thus
the ﬁrst change does not aﬀect the view of A. For the second change, from the correctness of PKE,
(G/∈Vauth , ske.k) ← Dec(sk, τ′) if τ′ = τ. Then, similarly to the ﬁrst change, we can see that the second
change does not aﬀect the view of A.

Proposition 6.4. If PKE is CCA secure, it holds that |Pr[Hyb1 = 1] − Pr[Hyb2 = 1]| ≤ negl(λ).

Proof of Proposition 6.4. We construct an algorithm B that breaks CCA security of PKE by using A.

B: B is given pk from the challenger. B generates ske.k ← SKE.Gen(1λ), and G ← CPRF.Setup(1λ),
and sets pp := pk. B sends pp to A and obtain m from A. B then generate G/∈Vauth
:=
CPRF.Constrain(G, Dauth[ske.k]), sets (m0, m1) := ((G/∈Vauth , ske.k), 02λ) as the challenge plain-
text of the CCA game and receives τ from its challenger. B also constructs D[ske.k, m], generates
G/∈V ← CPRF.Constrain(G, D[ske.k, m]), and sends τ and G/∈V to A as the challenge public tag
and marked circuit.

Osim: When A sends τ′ and i′ to Osim, B simulates the answer by using G, ske.k, and the decryption

oracle Dec(sk, ·).

After ﬁnishing A’s oracle access to Osim , B chooses γ∗ ← {0, 1}, generates x∗ ← SKE.Enc(ske.k, i∗kγ∗)
and y∗ ← G/∈Vauth (x∗) = G(x∗), and sends (γ∗, x∗, y∗) to A. Note that G/∈Vauth (x∗) = G(x∗)
holds since ⊥ 6= SKE.Dec(ske.k, x∗) and thus x∗ /∈ Vauth.
Finally, when A terminates with output coin′, B outputs coin′ and terminates.

B perfectly simulates if Hyb1 if τ ← Enc(pk, (G/∈Vauth , ske.k)), and Hyb2 if τ ← Enc(pk, 02λ). This

completes the proof.

Proposition 6.5. If CPRF satisﬁes selective pseudorandomness, it holds that

|Pr[Hyb2 = 1] − Pr[Hyb3 = 1]| ≤ negl(λ).

Proof of Proposition 6.5. We use selective single-key pseudorandomness of G. We construct an algo-
rithm B that breaks the selective single-key pseudorandomness of G by using A.

B: B generates (pk, sk) ← Gen(1λ), ske.k ← SKE.Gen(1λ), and τ ← Enc(pk, 02λ), sets and sends
pp := pk to A, and obtains m from A. B constructs D[ske.k, m], sends D[ske.k, m] to its challenger,
and receives G/∈V . B sends τ and G/∈V to A as the challenge public tag and marked circuit.

31

Osim: When A sends τ′ and i′ ∈ [ℓm] to Osim, if τ′ 6= τ, B computes (G′, ske.k′) ← Dec(sk, τ′),
and computes and returns the answer (γ, x, y) by using (G′, ske.k′).
If τ′ = τ, B
returns (γ, x, y) computed as follows. B chooses γ ← {0, 1}, and generates x ←
SKE.Enc(ske.k, i′kγ). B ﬁnally sends x to its PRF evaluation oracle and receives y ← G(x).

After ﬁnishing A’s oracle access to Osim,B sends (γ∗, x∗, y∗) computed as follows to A. B ﬁrst
chooses γ∗ ← {0, 1} and generates x∗ ← SKE.Enc(ske.k, i∗kγ∗). If m[i∗] = γ∗, B sends x∗ to
its challenge oracle and receives y∗. If m[i∗] 6= γ∗, B sends x∗ to its PRF evaluation oracle and
receives y∗.
Finally, when A terminates with output coin′, B outputs coin′ and terminates.

B perfectly simulates Hyb2 if the challenge oracle returns y∗ = G(x∗), and Hyb3 if it returns
y∗ ← {0, 1}m. Note that in these games, x∗ ← SKE.Enc(ske.k, i∗kγ∗), and thus if m[i∗] = γ∗, we
have x∗ ∈ V (D[ske.k, m](x∗) = 1). This completes the proof.

Proposition 6.6. If CPRF satisﬁes selective single-key privacy, it holds that

|Pr[Hyb3 = 1] − Pr[Hyb4 = 1]| ≤ negl(λ).

Proof of Proposition 6.6. We use selective single-key privacy of G. We construct an algorithm B that
breaks the selective privacy of G by using A.

B: B generates (pk, sk) ← Gen(1λ), ske.k ← SKE.Gen(1λ), and τ ← Enc(pk, 02λ), sends pp := pk
to A, and obtains m from A. B constructs D[ske.k, m], sends D[ske.k, m] to its challenger, and
receives G∗. B sends τ and G∗ to A as the challenge public tag and marked circuit.

Osim: When A sends τ′ and i′ ∈ [ℓm] to Osim, if τ′ 6= τ, B computes (G′, ske.k′) ← Dec(sk, τ′)
If τ′ = τ, B returns
and returns the answer (γ, x, y) computed by using (G′, ske.k′).
the answer (γ, x, y) computed as follows. B chooses γ ← {0, 1}, and generates x ←
SKE.Enc(ske.k, i′kγ). B sends x to its oracle and receives y.

After ﬁnishing A’s oracle access to Osim, B sends (γ∗, x∗, y∗) computed as follows to A. B
chooses γ∗ ← {0, 1} and generates x∗ ← SKE.Enc(ske.k, i∗kγ∗). If m[i∗] = γ∗, B chooses
y∗ ← {0, 1}m. If m[i∗] 6= γ∗, B sends x∗ to its oracle and receives y∗.
Finally, when A terminates with output coin′, B outputs coin′ and terminates.

B perfectly simulates Hyb3 if G∗ = CPRF.Constrain(G, D[ske.k, m]) and B has access to G(·),
and Hyb4 if G∗ = Sim1(1κ, 1λ) and B has access to Sim2(stSim, ·, D[ske.k, m](·)). This completes the
proof.

Proposition 6.7. If SKE satisﬁes ciphertext pseudorandomness, it holds that

|Pr[Hyb4 = 1] − Pr[Hyb5 = 1]| ≤ negl(λ).

Proof of Proposition 6.7. We construct an algorithm B that breaks the ciphertext pseudorandomness of
SKE by using A.

B: B generates (pk, sk) ← Gen(1λ) and sends pp := pk to A, and obtains m from A. B then generates
G to A as the challenge public

G) ← Sim1(1κ, 1λ), and sends τ and

τ ← Enc(pk, 02λ) and (stSim,
tag and marked circuit.

b

b

32

Osim: When A sends τ′ and i′ ∈ [ℓm] to Osim, if τ′ 6= τ, B computes (G′, ske.k′) ← Dec(sk, τ) and
returns the answer (γ, x, y) computed by using (G′, ske.k′).
If τ′ = τ, B returns the answer
(γ, x, y) computed as follows. B chooses γ ← {0, 1}, sends i′kγ to its encryption oracle,
and receives x ← SKE.Enc(ske.k, i′kγ). B computes y ← Sim2(stSim, x, 1) if γ = m[i′] and
y ← Sim2(stSim, x, 0) otherwise.
After ﬁnishing A’s oracle access to Osim, B sends (γ∗, x∗, y∗) computed as follows to A. B
chooses γ∗ ← {0, 1}, sends i∗kγ∗ to its challenger as the challenge plaintext, and receives x∗. B
generates y∗ ← {0, 1}m if m[i∗] = γ∗ and y∗ ← Sim2(stSim, x, 0) otherwise.
Finally, when A terminates with output coin′, B outputs coin′ and terminates.

B perfectly simulates Hyb4 if x∗ ← SKE.Enc(ske.k, i∗kγ∗), and Hyb5 if x∗ ← {0, 1}n. This

completes the proof.

Proposition 6.8. If CPRF satisﬁes selective single-key privacy, it holds that

|Pr[Hyb5 = 1] − Pr[Hyb6 = 1]| ≤ negl(λ).

Proof of Proposition 6.8. This proof is almost the same as that of Proposition 6.6.

Proposition 6.9. If PKE is CCA secure, it holds that |Pr[Hyb6 = 1] − Pr[Hyb7 = 1]| ≤ negl(λ).

Proof of Proposition 6.9. This proof is almost the same as that of Proposition 6.4.

Proposition 6.10. If CPRF, SKE, and PKE are correct, it holds that |Pr[Hyb7 = 1] − Pr[Hyb8 = 1]| ≤
negl(λ).

Proof of Proposition 6.10. This proof is almost the same as that of Proposition 6.3.

By Propositions 6.3 to 6.10, we complete the proof of Theorem 6.1.

Extended weak pseudorandomness. Next, we prove the extended pseudorandomness of PRFcprf .

Proof of Theorem 6.2. Let A be an adversary attacking the extended weak pseudorandomness of PRFcprf .
We construct B that attacks the selective single-key pseudorandomness of CPRF.

B: Given pp from A, B ﬁrst generates ske.k ← SKE.Gen(1λ), sends Dauth[ske.k] to its challenger, and
obtains G∗. B sets pp := pk, generates τ ← Enc(pk, (G∗, ske.k)), and sends it to A. B answers
A’s queries as follows.

Owprf: When this is invoked (no input), B generates a ← {0, 1}n, sends it to its evaluation oracle,

and obtains b. Then, B returns (a, b) to A.

Ochall: When this is invoked (no input), B generates a∗ ← {0, 1}n, outputs a∗ as its challenge
input, and obtains b∗. B returns (a∗, b∗) to A. Note that this oracle is invoked only once.

When A terminates with output b′, B outputs b′ and terminates.

Due to the sparseness of SKE, without negligible probability, we have SKE.Dec(ske.k, a∗) = ⊥ thus
Dauth[ske.k](a∗) = 1, and a generated when answering to a query to Owprf is diﬀerent from a∗. Therefore,
without negligible probability, B is a valid adversary against the selective single-key pseudorandomness
of CPRF. When B is valid, we see that the advantage of B is the same as that of A. This completes the
proof.

33

7 Extraction-Less Watermarking PRF with Public Simulation from IO

We construct an extraction-less watermarking PRF satisfying SIM-MDD security with public simulation.
We ﬁrst introduce a tool.

7.1 Puncturable Encryption, Revisited

Cohen et al. [CHN+18] introduced the notion of puncturable encryption (PE). They used a PE scheme as a
crucial building block to construct a publicly extractable watermarking PRF against classical adversaries.
We also use a PE scheme to construct an extraction-less watermarking PRF with public simulation
(against quantum adversaries). However, we ﬁnd that the original PE deﬁnition is not suﬃcient for
proving unremovability (and our purpose) since there is a subtle issue in the security proof by Cohen et
al. [CHN+18]. However, we can ﬁx the issue since their PE scheme satisﬁes a stronger security notion
than what they proved. Thus, we introduce a stronger security notion for PE in this section.

The syntax of PE is almost the same as that of the original PE.

Deﬁnition 7.1 (Puncturable Encryption (Syntax)). A puncturable encryption (PE) scheme PE for a
plaintext space P = {0, 1}ℓp is a triple of PPT algorithms (Gen, Puncture, Enc) and a deterministic
algorithm Dec. The ciphertext space will be {0, 1}ℓct where ℓct = poly(λ, ℓp).
Gen(1λ) → (ek, dk): The key generation algorithm takes as input the security parameter 1λ and outputs

an encryption key ek and a decryption key dk.

Puncture(dk, {c∗}) → dk6=c∗: The puncturing algorithm takes as input dk and a string c∗ ∈ {0, 1}ℓct ,

and outputs a “punctured” decryption key dk6=c∗.

Enc(ek, m) → c: The encryption algorithm takes as input ek and a plaintext m ∈ {0, 1}ℓp , and outputs

a ciphertext c in {0, 1}ℓct.

Dec(dk′, c′) → m′ or ⊥: The decryption algorithm takes a possibly punctured decryption key dk′ and

a string c′ ∈ {0, 1}ℓct . It outputs a plaintext m′ or the special symbol ⊥.

There are four security requirements on PE. Three of those are the same as those in the original PE

security. The diﬀerence is ciphertext pseudorandomness.

Deﬁnition 7.2 (Puncturable Encryption Security). A PE scheme PE = (Gen, Puncture, Enc, Dec)
with plaintext space P = {0, 1}ℓp and ciphertext space C = {0, 1}ℓct is required to satisfy the following
properties.

Correctness: We require that for all plaintext m ∈ P and (ek, dk) ← Gen(1λ), it holds that

Dec(dk, Enc(ek, m)) = m.

Punctured Correctness: We require the same to hold for punctured keys. For all possible keys
(ek, dk) ← Gen(1λ), all string c∗ ∈ C, all punctured keys dk6=c∗ ← Puncture(dk, {c∗}), and all
potential ciphertexts c ∈ C \ {c∗}:

Dec(dk, c) = Dec(dk6=c∗, c).

Sparseness: We also require that most strings are not valid ciphertexts:

Pr

Dec(dk, c) 6= ⊥

(ek, dk) ← Gen(1λ), c ← {0, 1}ℓct

≤ negl(λ).

Ciphertext Pseudorandomness: We require that PE has strong ciphertext pseudorandomness deﬁned

i

h

(cid:12)
(cid:12)
(cid:12)

in Deﬁnition 7.3.

34

Deﬁnition 7.3 (Strong Ciphertext Pseudorandomness). We deﬁne the following experiment Exps-cpr

A

(λ).

1. A sends a message m∗ ∈ P = {0, 1}ℓp to the challenger.

2. The challenger does the following:

• Generate (ek, dk) ← Gen(1λ)
• Compute a ciphertext c∗ ← Enc(ek, m∗).
• Choose r∗ ← C = {0, 1}ℓct .
• Choose coin ← {0, 1} and set x0 := c∗ and x1 := r∗.
• Generate a punctured key dk6=xcoin ← Puncture(dk, {xcoin})
• Send (xcoin, ek, dk6=xcoin) to A:

3. A outputs coin∗ and the experiment outputs 1 if coin = coin∗; otherwise 0.

We say that PE has strong ciphertext pseudorandomness if for every QPT adversary A, it holds that

Advs-cpr

A

(λ) := 2

Pr

Exps-cpr

A (λ) = 1

−

1
2

≤ negl(λ).

(cid:2)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:3)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

Remark 7.4 (Diﬀerence from the original PE). In the original PE deﬁnition, Puncture takes two strings
{c0, c1} ⊂ {0, 1}ℓct and outputs a punctured decryption key dk/∈{c0,c1} and punctured correctness is
accordingly deﬁned.

In the original ciphertext pseudorandomness (described in Appendix B.4), a punctured decryption key
is punctured at both c∗ and r∗. That is, the information about m∗ remains in dk/∈{c∗,r∗} for coin ∈ {0, 1}.
This is an issue for our purpose (and the proof by Cohen et al. [CHN+18]). Thus, we introduce the
strong ciphertext pseudorandomness, where the information about m∗ disappears in the case coin = 1
since the punctured decryption key is dk6=r∗ when coin = 1.

In fact, the PE scheme PE by Cohen et al. [CHN+18] satisﬁes strong ciphertext pseudorandomness

(and thus, we can also ﬁx the issue in the proof by Cohen et al.12).

Theorem 7.5. If there exists secure IO for circuits and the QLWE assumption holds, there exists secure
PE that satisﬁes strong ciphertext pseudorandomness.

We prove this theorem in Appendix B.

7.2 Construction of Extraction-less Watermarking PRF with Public Simulation
We describe our extraction-less watermarking PRF PRFio for message space {0, 1}ℓm with domain
{0, 1}ℓin and range {0, 1}ℓout below. We use the following tools:

• PPRF PRF = PRF.(Gen, Eval, Puncture). We denote a PRF evaluation circuit PRF.Evalprfk(·)
by F : {0, 1}ℓin → {0, 1}ℓout , a PRF evaluation circuit with punctured key PRF.Evalprfk6=x(·) by
F6=x (that is, we omit prfk and simply write F(·) instead of Fprfk(·)) for ease of notations.

• PE scheme PE = PE.(Gen, Puncture, Enc, Dec). The plaintext and ciphertext space of PE
are {0, 1}ℓpt and {0, 1}ℓct, respectively, where ℓpt = ℓ + log ℓm + 1 and ℓin := ℓct (ℓct =
poly(ℓ, log ℓm)).

• Indistinguishability obfuscator iO.
• PRG PRG : {0, 1}ℓ → {0, 1}ℓout .
12See Appendix B.4 for the detail of the issue.

35

Constants: A PRF F, a PE decryption key pe.dk, and a message m.
Input: A string x ∈ {0, 1}ℓin.

Circuit D[F, pe.dk, m]

1. Compute d ← PE.Dec(pe.dk, x).
2. If d 6= ⊥, do the following

(a) Parse d = skikγ, where s ∈ {0, 1}ℓ, i ∈ [ℓm], and γ ∈ {0, 1}.
(b) If m[i] 6= γ, output PRG(s). Otherwise, output F(x).

3. Otherwise, output F(x).

Figure 6: The description of D

Setup(1λ):

• Output (pp, xk) := (⊥, ⊥).

Gen(pp):

• Parse pp = ⊥.
• Compute F ← PRF.Gen(1λ).
• Generate (pe.ek, pe.dk) ← PE.Gen(1λ).
• Output prfk := (F, pe.dk) and τ := pe.ek.

Eval(prfk, x ∈ {0, 1}ℓin ):

• Parse prfk = (F, pe.dk).
• Compute and output y ← F(x).

Mark(pp, prfk, m ∈ {0, 1}ℓm ):

• Parse pp = ⊥ and prfk = (F, pe.dk).
• Construct a circuit D[F, pe.dk, m] described in Figure 6.
• Compute and output

C := iO(D[F, pe.dk, m]).

Sim(xk, τ, i):

e

• Parse xk = ⊥ and τ = pe.ek.
• Choose γ ← {0, 1} and s ← {0, 1}ℓ.
• Compute y := PRG(s).
• Compute x ← PE.Enc(pe.ek, skikγ).
• Output (γ, x, y)

The size of the circuit D is appropriately padded to be the maximum size of all modiﬁed circuits, which
will appear in the security proof.

The evaluation correctness of PRFio immediately follows from the sparseness of PE and the func-
tionality of iO.13 PRFio trivially satisﬁes pseudorandomness (against an authority) since Setup outputs

13In fact, PRFio satisﬁes a stronger evaluation correctness than one written in Deﬁnition 4.1. The evaluation correctness

holds even for any PRF key prfk and input x ∈ Dom like the statistical correctness by Cohen et al. [CHN+18].

36

Circuit D$

6=x∗[F, pe.dk′, m, γ∗, x∗, y]

Constants: A PRF key F, a (possibly punctured) PE decryption key pe.dk′, a message m, a bit γ∗, and strings

x∗ ∈ {0, 1}ℓin, y ∈ {0, 1}ℓout .

Input: A string x ∈ {0, 1}ℓin.

1. If x = x∗, output y.
2. Compute d ← PE.Dec(pe.dk′, x).
3. If d 6= ⊥, do the following

(a) Parse d = skikγ, where s ∈ {0, 1}ℓ, i ∈ [ℓm], and γ ∈ {0, 1}.
(b) If m[i] 6= γ, output PRG(s). Otherwise, output F(x).

4. Otherwise, output F(x).

Figure 7: The description of D$

6=x∗ (for γ∗ = m[i∗])

nothing, τ is a public key pe.ek, and Eval is independent of (pe.ek, pe.dk) (pe.dk is not used in Eval).
Moreover, we have the following theorem.

Theorem 7.6. If PRF is a secure PPRF, PRG is a secure PRG, PE is a secure PE with strong ciphertext
pseudorandomness, and iO is a secure IO, then PRFio is an extraction-less watermarking PRF satisfying
SIM-MDD security with public simulation.

Proof of Theorem 7.6. We deﬁne a sequence of hybrid games. We sometimes omit hard-coded values
when we write some circuits. For example, we simply write D instead of D[F, pe.dk, m] when hard-coded
values (F, pe.dk, m) are not important in arguments or clear from the context.
Hyb0: This is the same as the case b = 1 in Exppub-sim-mdd

(λ). In this game, A is given τ = pe.ek
C = iO(D[F, pe.dk, m]) as a public tag and a marked circuit, where (pe.ek, pe.dk) ←
and
PE.Gen(1λ), (F, pe.dk) is the target PRF key, and m is the target message from A. Also,
A is given (γ∗, x∗, y∗) = (γ1, x1, y1) as the challenge tuple, where γ1 ← {0, 1}, x1 ←
PE.Enc(pe.ek, s∗ki∗kγ1), y1 := PRG(s∗), and s∗ ← {0, 1}ℓ.

i∗,A,PRFio

e

Case γ∗ = m[i∗]: We consider two cases separately hereafter. First, we consider the case where γ∗ =
k . Note that we can choose γ∗ at any time and

m[i∗]. We denote these hybrid games by Hyb=
hard-code it into

D in the proof since it is a uniformly random bit in all hybrid games.

Hyb=

1 : This is the same as Hyb0 except that if γ1 = m[i∗], we use

D ← iO(D$

[F, pe.dk6=x1, m, γ1, x1, y]),

6=x1

where D$
instead of pe.dk. However, we do not use a punctured key for F.

6=x∗ is described in Figure 7 and y := F(x1). We use a punctured decryption key pe.dk6=x1

e

e

Hyb=

2 : This is the same as Hyb=
• x0 ← {0, 1}ℓin ,
•
D ← iO(D$

[F, pe.dk6=x0, m, γ1, x0, y]).

6=x0

1 except that we generate

That is, we replace x∗ = x1 and pe.dk′ = pe.dk6=x1
e
respectively.

with x∗ = x0 and pe.dk′ = pe.dk6=x0

,

We also rename γ1 ← {0, 1} into γ0 ← {0, 1} (these distributions are the same).

Hyb=

3 : This is the same as Hyb=

2 except that we use y0 ← {0, 1}ℓout instead of y1 := PRG(s∗).
We describe the high-level overview of hybrid games for γ∗ = m[i∗] in Figures 9 and 10.

37

Circuit Dreal

6=x∗[F′, pe.dk′, m, γ∗, x∗, y∗]

Constants: A (possibly punctured) PRF key F′, a (possibly punctured) PE decryption key pe.dk′, a message m, a

bit γ∗, and strings x∗ ∈ {0, 1}ℓin , y∗ ∈ {0, 1}ℓout .

Input: A string x ∈ {0, 1}ℓin.

1. If x = x∗, output y∗.
2. Compute d ← PE.Dec(pe.dk′, x).
3. If d 6= ⊥, do the following

(a) Parse d = skikγ, where s ∈ {0, 1}ℓ, i ∈ [ℓm], and γ ∈ {0, 1}.
(b) If m[i] 6= γ, output PRG(s). Otherwise, output F′(x).

4. Otherwise, output F′(x).

Figure 8: The description of Dreal

6=x∗ (for γ∗ = 1 − m[i∗])

Case γ∗ 6= m[i∗]: Next, we consider the case where γ∗ 6= m[i∗]. We denote these hybrid games by

Hyb6=
k .

Hyb6=

1 : This is the same as Hyb0 except that if γ1 6= m[i∗], we generate

D ← iO(Dreal
6=x1

[F, pe.dk6=x1, m, γ1, x1, y1]),

where Dreal
pe.dk6=x1

6=x∗ is described in Figure 8 and y1 := PRG(s∗). We use a punctured decryption key
instead of pe.dk. However, we do not use a puncture key for F at this point.

e

Hyb6=

2 : This is the same as Hyb6=
• x0 ← {0, 1}ℓin ,
•
D ← iO(Dreal
6=x0

1 except that

[F, pe.dk6=x0, m, γ1, x0, y1]).

with x∗ = x0 and pe.dk′ = pe.dk6=x0
That is, we replace x∗ = x1 and pe.dk′ = pe.dk6=x1
respectively. We also rename γ1 ← {0, 1} into γ0 ← {0, 1} (these distributions are the same).

e

,

Hyb6=

Hyb6=

Hyb6=

Hyb6=

2 except that we use y0 ← {0, 1}ℓout instead of y1 := PRG(s∗).
3 : This is the same as Hyb6=
4 : This is the same as Hyb6=
3 except that we use F6=x0 instead of F.
4 except that we use y0 := F(x0) instead of y0 ← {0, 1}ℓout .
5 : This is the same as Hyb6=
6 : This is the same as Hyb6=
5 except that we use F instead of F6=x0.
We describe the high-level overview of hybrid games for γ∗ 6= m[i∗] in Figures 9 and 11.

End of case analysis: The two case analyses end. Remaining transitions are the reverse of transitions

from Hyb0 to Hyb=

1 or Hyb6=
1 .
7 : These are the same as Hyb=

Hyb=

4 and Hyb6=

3 and Hyb6=

6 , respectively except that

• if γ0 = m[i∗], we use

D ← iO(D[F, pe.dk, m]) instead of

where D$

6=x∗ is described in Figure 7 and y := F(x0).

• if γ0 6= m[i∗], we use

e
D ← iO(D[F, pe.dk, m]) instead of

where Dreal

6=x∗ is described in Figure 8 and y0 := F(x0).

D ← iO(D$

6=x0

[F, pe.dk6=x0, m, γ0, x0, y]),

e
D ← iO(Dreal
6=x0

[F, pe.dk6=x0, m, γ0, x0, y0]),

e
e
The each last hybrid is the same as the case b = 0 in Exppub-sim-mdd
iO(D[F, pe.dk, m]) and (γ0, x0, y0) ← Dreal,i∗. Recall that x0 ← {0, 1}ℓin and

i∗,A,PRFio

(λ). That is, A is given

C =

e

38

• y0 ← {0, 1}ℓout if γ0 = m[i∗] (see Hyb=
3 ),
• y0 := F(x0) if γ0 6= m[i∗] (see Hyb6=
5 ).

prfk

Ochall
γ1 = m[i∗] γ1 6= m[i∗]
iO(D)
iO(D$

)

6=x1

iO(D)
N/A
iO(Dreal
6=x1

security

IO & PE p-Cor.

)

IO & PE p-Cor.

Hyb0
Hyb=
1
Hyb6=
1

(F, pe.dk)
(F, pe.dk6=x1)
(F, pe.dk6=x1) N/A

Figure 9: High-level overview of hybrid games from Hyb0 to Hyb=
in D$
(γ1, x1, y1) ← Sim(xk, τ, i∗) and x∗ = x1. We use pe.dk6=x1
“security” column, PE p-Cor. means PE punctured correctness.

1 and Hyb6=
6=x1

1 . Note that in these hybrid games,
and Dreal
, but F is not punctured yet. In
6=x1

γ∗ = m[i]

y∗ (y1/y0)
x∗ (x1/x0)
PE.Enc(pi∗ ) PRG(s∗)
PRG(s∗)
x0 ← $
y0 ← $
$
$
$

y

F(x1)
F(x0)
F(x0)
F(x0)

Hyb=
1
Hyb=
2
Hyb=
3
Hyb=
4

Ochall
iO(D$
iO(D$
iO(D$
iO(D)

6=x1

6=x0

6=x0

prfk

security

[x1 7→ ¯y])
[x0 7→ ¯y])
[x0 7→ ¯y])

(F, pe.dk6=x1)
(F, pe.dk6=x0)
(F, pe.dk6=x0)
(F, pe.dk)

S-CPR
PRG
IO & PE p-Cor.

Figure 10: High-level overview of hybrid games from Hyb=
PE.Enc(pe.ek, pi∗). Note that y is an output of D$
means D$
PseudoRandomness of PE.

6=x∗(x∗) outputs the hard-coded value y.

1 to Hyb=

4 . Here, pi∗ := (s∗ki∗kγ1) and x1 ←
6=x∗ for input x∗ for γ1 = m[i∗] case. D$
6=x∗[x∗ 7→ y]
In “security” column, S-CPR means the Strong Ciphertext

We prove the lemma by proving the following propositions.

The case γ∗ = m[i]. We ﬁrst prove propositions for the case γ∗ = m[i].

Proposition 7.7. If iO is a secure IO and PE satisﬁes punctured correctness, it holds that

|Pr[Hyb0 = 1] − Pr[Hyb=

1 = 1]| ≤ negl(λ).
Proof of Proposition 7.7. The diﬀerence between the two games is that D$
[F, pe.dk6=x1, m, γ, x1, y] is
used for Ochall instead of D[F, pe.dk, m] in the case where γ1 = m[i∗]. These two circuits are the same
except that

6=x1

• for input x1, D$

6=x1

directly outputs y,

due to the punctured correctness of PE. Thus, if the following hold, D$
equivalent:

6=x1

and D are functionally

• D(x1) outputs y = F(x1) when γ1 = m[i∗].

This holds since x1 ← PE.Enc(pe.ek, s∗ki∗kγ1) and D(x1) runs the item (b) in Figure 6, but γ1 6= m[i∗]
does not hold in this case.

Thus, D$

6=x1

and D are functionally equivalent and the proposition holds due to IO security.

39

γ∗ 6= m[i]

y∗ (y1/y0) Ochall

prfk

security

x∗ (x1/x0)
PE.Enc(pi∗ ) PRG(s∗)
PRG(s∗)
x0 ← $
y0 ← $
$
$
$
F(x0)
F(x0)
F(x0)

$
$
$

Hyb6=
1
Hyb6=
2
Hyb6=
3
Hyb6=
4
Hyb6=
5
Hyb6=
6
Hyb6=
7

iO(Dreal
6=x1
iO(Dreal
6=x0
iO(Dreal
6=x0
iO(Dreal
6=x0
iO(Dreal
6=x0
iO(Dreal
6=x0
iO(D)

[x1 7→ y1])
[x0 7→ y1])
[x0 7→ y0])
[x0 7→ y0])
[x0 7→ y0])
[x0 7→ y0])

(F, pe.dk6=x1)
(F, pe.dk6=x0)
(F, pe.dk6=x0)
(F6=x0, pe.dk6=x0)
(F6=x0, pe.dk6=x0)
(F, pe.dk6=x0)
(F, pe.dk)

S-CPR
PRG
IO & PPRF p-Cor.

PPRF
IO & PPRF p-Cor.
IO & PE p-Cor.

Figure 11: High-level overview of hybrid games from Hyb6=
7 . Here, pi∗ := (s∗ki∗kγ1) and x1 ←
PE.Enc(pe.ek, pi∗). Dreal
6=x∗(x∗) outputs the hard-coded value y∗. In “security” column,
S-CPR and PPRF p-Cor. mean the Strong Ciphertext PseudoRandomness of PE and punctured correctness of
PPRF, respectively.

6=x∗[x∗ 7→ y∗] means Dreal

1 to Hyb6=

Proposition 7.8. If PE satisﬁes strong ciphertext pseudorandomness, it holds that

|Pr[Hyb=

1 = 1] − Pr[Hyb=

2 = 1]| ≤ negl(λ).

Proof of Proposition 7.8. We construct an algorithm B for strong ciphertext pseudorandomness by using
A. B generates F ← PRF.Gen(1λ), and chooses s∗ ← {0, 1}ℓ and γ1 ← {0, 1}. B sends s∗ki∗kγ1 to
the challenger. The challenger returns (x∗, pe.ek, pe.dk6=x∗) to B.

Then, B passes pp := ⊥ and xk := ⊥ to A. B also computes y := F(x∗).

Challenge: When A sends a challenge query m, B does the following

• Construct D$
• Return

6=x∗[F, pe.dk6=x∗, m, γ1, x∗, y] as described in Figure 7.

C := iO(D$

6=x∗[F, pe.dk6=x∗, m, γ1, x∗, y]) and τ := pe.ek to A.

After ﬁnishing A’s challenge query, B computes y∗ := PRG(s∗) and sends (γ1, x∗, y∗) to A. Finally,

e

when A terminates with output coin′, B outputs coin′ and terminates. B perfectly simulates

• Hyb=
• Hyb=

1 if x∗ ← PE.Enc(pe.ek, s∗ki∗kγ1),
2 if x∗ ← {0, 1}ℓin .
Thus, we see that the proposition holds.

Proposition 7.9. If PRG is a secure PRG, it holds that |Pr[Hyb=

2 = 1] − Pr[Hyb=

3 = 1]| ≤ negl(λ).

Proof of Proposition 7.9. The diﬀerence between the two games is that y∗ in the target triple (γ0, x0, y∗)
is PRG(s∗) or random in the case where γ0 = m[i]. Recall that we rename γ1 ← {0, 1} to γ0 ← {0, 1}.
Note that we randomly choose x0 ← {0, 1}ℓin and use F and pe.dk6=x0
in these games. Thus, we can
apply pseudorandomness of PRG since the value s∗ is never used anywhere else.

The case where γ∗ 6= m[i]. Next, we prove propositions for the case where γ∗ 6= m[i].

Proposition 7.10. If iO is a secure IO and PE satisﬁes punctured correctness, it holds that

Pr[Hyb0 = 1] − Pr

Hyb6=

1 = 1

≤ negl(λ).

(cid:12)
(cid:12)
(cid:12)

h

40

i(cid:12)
(cid:12)
(cid:12)

Proof of Proposition 7.10. The diﬀerence between the two games is that Dreal
[F, pe.dk6=x1, m, γ, x1, y1]
6=x1
is used for the challenge query instead of D[F, pe.dk, m] in the case where γ1 6= m[i∗]. These two
circuits are the same except that

• for input x1, Dreal
6=x1

directly outputs the hard-wired value y1 = PRG(s∗),
due to the punctured correctness of PE. Thus, if the following hold, Dreal
6=x1
equivalent:

• D(x1) outputs y1 = PRG(s∗) when γ1 6= m[i∗],

and D are functionally

This holds since x1 ← PE.Enc(pe.ek, s∗ki∗kγ1), D(x1) runs the item (b) in Figure 6, and γ1 6= m[i∗]
holds in this case. Thus, Dreal
and D are functionally equivalent and the proposition holds due to IO
6=x1
security.

Proposition 7.11. If PE satisﬁes strong pseudorandom ciphertext, it holds that

Pr

Hyb6=

1 = 1

− Pr

Hyb6=

2 = 1

≤ negl(λ).

h

h
Proof of Proposition 7.11. We construct an algorithm B for strong ciphertext pseudorandomness by
using a distinguisher A. B generates F ← PRF.Gen(1λ) and chooses s∗ ← {0, 1}ℓ and γ1 ← {0, 1}.
B sends s∗ki∗kγ1 to the challenger. The challenger returns (x∗, pe.ek, pe.dk6=x∗) to B.
Then, B passes pp := ⊥ and xk := ⊥ to A. B also computes y∗ := PRG(s∗).

i

i(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

Challenge: When A sends a challenge query m, B does the following

• Construct Dreal
• Return

C := iO(Dreal

6=x∗) and τ := pe.ek to A.

6=x∗[F, pe.dk6=x∗, m, γ1, x∗, y∗] where y∗ := PRG(s∗) as described in Figure 8.

After ﬁnishing A’s challenge, B sends (γ1, x∗, y∗) to A. Finally, when A terminates with output

e

coin′, B outputs coin′ and terminates.

B perfectly simulates
• Hyb6=

1 if x∗ ← PE.Enc(pe.ek, s∗ki∗kγ1),
2 if x∗ ← {0, 1}ℓin .
Thus, we see that the proposition holds.

• Hyb6=

Proposition 7.12. If PRG is a secure PRG, it holds that

Pr

Hyb6=

2 = 1

− Pr

Hyb6=

3 = 1

≤ negl(λ).

Proof of Proposition 7.12. The diﬀerence between the two games is that y∗ in the target triple (γ0, x0, y∗)
is PRG(s∗) or random in the case where γ0 6= m[i]. Recall that we rename γ1 ← {0, 1} to γ0 ← {0, 1}.
Note that we randomly choose x0 ← {0, 1}ℓin and use F and pe.dk6=x0
in these games. Thus, we can
apply pseudorandomness of PRG since the value s∗ is never used anywhere else.

h

(cid:12)
(cid:12)
(cid:12)

i

h

i(cid:12)
(cid:12)
(cid:12)

Proposition 7.13. If iO is a secure IO and F satisﬁes punctured correctness, it holds that

Pr

Hyb6=

3 = 1

− Pr

Hyb6=

4 = 1

≤ negl(λ).

h

(cid:12)
(cid:12)
(cid:12)

i

h

i(cid:12)
(cid:12)
(cid:12)

Proof of Proposition 7.13. The diﬀerence between the two games is that Dreal
6=x0
is used for the challenge query instead of Dreal
[F, pe.dk6=x0, m, γ0, x0, y0] in the case where γ0 6=
6=x0
m[i∗]. These two circuits are the same except that we use F6=x0 instead of F. Those two circuits
above are functionally equivalent since F6=x0(·) is functionally equivalent to F except for x0 and both

[F6=x0, pe.dk6=x0, m, γ0, x0, y0]

41

[F6=x0, pe.dk6=x0, m, γ0, x0, y0](x0) and Dreal
6=x0

Dreal
6=x0
the description of Dreal
6=x0

. Note that Dreal
6=x0

Thus, the proposition holds due to IO security.

[F, pe.dk6=x0, m, γ0, x0, y0](x0) directly outputs y0 by

does not have any “if branch” condition that uses F or F6=x0.

Proposition 7.14. If F satisﬁes punctured pseudorandomness, it holds that

Pr

Hyb6=

4 = 1

− Pr

Hyb6=

5 = 1

≤ negl(λ).

[F6=x0, pe.dk6=x0, m, γ0, x0, y∗])

h

(cid:12)
(cid:12)
(cid:12)

i

h

i(cid:12)
(cid:12)
(cid:12)

Proof of Proposition 7.14. We construct an algorithm B that breaks the pseudorandomness at punctured
points of F by using A.

B generates (pe.ek, pe.dk) ← PE.Gen(1λ), chooses x0 ← {0, 1}ℓin and γ0 ← {0, 1}, sends x0
as the challenge to its challenger of F, and receives F6=x0 and y∗. Here x0 does not rely on m, so
we can generate x0 before m is ﬁxed. B sends pp := ⊥ and xk := ⊥ to A. B also computes
pe.dk6=x0 ← PE.Puncture(pe.dk, x0).
Challenge: For query m, B can simulate the target marked circuit
, F6=x0, y∗, and the public tag τ = pe.ek.
e

After ﬁnishing A’s challenge query, B sends (γ0, x0, y∗) to A. Finally, when A terminates with output
coin′, B outputs coin′ and terminates.

by using pe.dk6=x0

C = iO(Dreal
6=x0

B perfectly simulates
• Hyb6=

4 if y∗ ← {0, 1}ℓout ,
5 if y∗ := F(x0).

• Hyb6=

The punctured pseudorandomness of F immediately implies this proposition.

Proposition 7.15. If iO is a secure IO and F satisﬁes punctured correctness, it holds that

Pr

Hyb6=

5 = 1

− Pr

Hyb6=

6 = 1

≤ negl(λ).

h

(cid:12)
(cid:12)
(cid:12)

i

h

i(cid:12)
(cid:12)
(cid:12)

Proof of Proposition 7.15. The diﬀerence between the two games is that Dreal
[F, pe.dk6=x0, m, γ0, x0, y0]
6=x0
is used for the challegne query instead of Dreal
[F6=x0, pe.dk6=x0, m, γ0, x0, y0] in the case where γ0 6=
6=x0
m[i∗]. These two circuits are the same except that we use F instead of F6=x0. This proof is the same as
that of Proposition 7.14 (in a reverse manner). Thus, we omit it.

End of case analyses. We complete the two case analyses.

Proposition 7.16. If iO is a secure IO, F satisﬁes punctured correctness, and PE satisﬁes punctured cor-
rectness, it holds that |Pr[Hyb=
7 = 1
negl(λ).

4 = 1]| ≤ negl(λ) and

3 = 1] − Pr[Hyb=

6 = 1

Hyb6=

Hyb6=

− Pr

Pr

h

h

i

Proof. This proof is the same as that of Proposition 7.7 and Proposition 7.10, respectively (in a reverse
manner). Thus, we omit them.

(cid:12)
(cid:12)
(cid:12)

≤

i(cid:12)
(cid:12)
(cid:12)

We complete the proof of Theorem 7.6.

42

8 Putting Pieces Altogether

Privately extractable watermarking PRF. We summarize how to obtain our privately extractable
watermarking PRF.

By Theorems 2.24, 2.27, 2.30, 6.1 and 6.2, we obtain an extraction-less watermarking with private
simulation from the QLWE assumption. By combining this with Theorems 4.6 and 5.2, we obtain the
following theorem.

Theorem 8.1. If the QLWE assumption holds, there exists a privately extractable watermarking PRF.

Publicly extractable watermarking PRF. We summarize how to obtain our publicly extractable
watermarking PRF.

By Theorems 2.17, 2.21, 7.5 and 7.6, we obtain an extraction-less watermarking with public simu-
lation from IO and the QLWE assumption since OWFs can be instantiated with the QLWE assumption.
By combining this with Theorem 5.3, we obtain a publicly extractable watermarking PRF from IO and
the QLWE assumption. Thus, we obtain the following theorem.

Theorem 8.2. If there exists a secure IO and the QLWE assumption holds, there exists a publicly
extractable watermarking PRF.

References

[AHU19]

Andris Ambainis, Mike Hamburg, and Dominique Unruh. Quantum security proofs
using semi-classical oracles.
In Alexandra Boldyreva and Daniele Micciancio, editors,
CRYPTO 2019, Part II, volume 11693 of LNCS, pages 269–295. Springer, Heidelberg,
August 2019. (Cited on page 48.)

[AKPW13]

Joël Alwen, Stephan Krenn, Krzysztof Pietrzak, and Daniel Wichs. Learning with rounding,
revisited - new reduction, properties and applications. In Ran Canetti and Juan A. Garay,
editors, CRYPTO 2013, Part I, volume 8042 of LNCS, pages 57–74. Springer, Heidelberg,
August 2013. (Cited on page 51.)

[AL21]

[ALL+21]

[AP20]

Prabhanjan Ananth and Rolando L. La Placa. Secure software leasing. In Anne Canteaut
and François-Xavier Standaert, editors, EUROCRYPT 2021, Part II, volume 12697 of
LNCS, pages 501–530. Springer, Heidelberg, October 2021. (Cited on page 1.)

Scott Aaronson, Jiahui Liu, Qipeng Liu, Mark Zhandry, and Ruizhe Zhang. New approaches
In Tal Malkin and Chris Peikert, editors, CRYPTO 2021,
for quantum copy-protection.
Part I, volume 12825 of LNCS, pages 526–555, Virtual Event, August 2021. Springer,
Heidelberg. (Cited on page 1, 10, 11.)

Shweta Agrawal and Alice Pellet-Mary.
Indistinguishability obfuscation without maps:
Attacks and ﬁxes for noisy linear FE. In Anne Canteaut and Yuval Ishai, editors, EURO-
CRYPT 2020, Part I, volume 12105 of LNCS, pages 110–140. Springer, Heidelberg, May
2020. (Cited on page 19.)

[ARU14]

Andris Ambainis, Ansis Rosmanis, and Dominique Unruh. Quantum attacks on classical
proof systems: The hardness of quantum rewinding. In 55th FOCS, pages 474–483. IEEE
Computer Society Press, October 2014. (Cited on page 1, 10.)

43

[BDF+11] Dan Boneh, Özgür Dagdelen, Marc Fischlin, Anja Lehmann, Christian Schaﬀner, and Mark
Zhandry. Random oracles in a quantum world. In Dong Hoon Lee and Xiaoyun Wang,
editors, ASIACRYPT 2011, volume 7073 of LNCS, pages 41–69. Springer, Heidelberg,
December 2011. (Cited on page 1.)

[BGI+12]

[BGI14]

[BGMZ18]

Boaz Barak, Oded Goldreich, Russell Impagliazzo, Steven Rudich, Amit Sahai, Salil P.
Vadhan, and Ke Yang. On the (im)possibility of obfuscating programs. Journal of the
ACM, 59(2):6:1–6:48, 2012. (Cited on page 1, 18.)

Elette Boyle, Shaﬁ Goldwasser, and Ioana Ivan. Functional signatures and pseudorandom
functions. In Hugo Krawczyk, editor, PKC 2014, volume 8383 of LNCS, pages 501–519.
Springer, Heidelberg, March 2014. (Cited on page 16.)

James Bartusek, Jiaxin Guan, Fermi Ma, and Mark Zhandry. Return of GGH15: Prov-
able security against zeroizing attacks. In Amos Beimel and Stefan Dziembowski, editors,
TCC 2018, Part II, volume 11240 of LNCS, pages 544–574. Springer, Heidelberg, Novem-
ber 2018. (Cited on page 19.)

[BHH+19] Nina Bindel, Mike Hamburg, Kathrin Hövelmanns, Andreas Hülsing, and Edoardo Per-
sichetti. Tighter proofs of CCA security in the quantum random oracle model. In Dennis
Hofheinz and Alon Rosen, editors, TCC 2019, Part II, volume 11892 of LNCS, pages
61–90. Springer, Heidelberg, December 2019. (Cited on page 48.)

[BLW17]

[BSW06]

Dan Boneh, Kevin Lewi, and David J. Wu. Constraining pseudorandom functions privately.
In Serge Fehr, editor, PKC 2017, Part II, volume 10175 of LNCS, pages 494–524. Springer,
Heidelberg, March 2017. (Cited on page 1, 9, 20.)

Dan Boneh, Amit Sahai, and Brent Waters. Fully collusion resistant traitor tracing with
short ciphertexts and private keys. In Serge Vaudenay, editor, EUROCRYPT 2006, volume
4004 of LNCS, pages 573–592. Springer, Heidelberg, May / June 2006. (Cited on page 2,
10.)

[BTVW17] Zvika Brakerski, Rotem Tsabary, Vinod Vaikuntanathan, and Hoeteck Wee. Private con-
strained PRFs (and more) from LWE. In Yael Kalai and Leonid Reyzin, editors, TCC 2017,
Part I, volume 10677 of LNCS, pages 264–302. Springer, Heidelberg, November 2017.
(Cited on page 18.)

[BW13]

[CC17]

[CFN94]

Dan Boneh and Brent Waters. Constrained pseudorandom functions and their applications.
In Kazue Sako and Palash Sarkar, editors, ASIACRYPT 2013, Part II, volume 8270 of
LNCS, pages 280–300. Springer, Heidelberg, December 2013. (Cited on page 16.)

Ran Canetti and Yilei Chen. Constraint-hiding constrained PRFs for NC1 from LWE. In
Jean-Sébastien Coron and Jesper Buus Nielsen, editors, EUROCRYPT 2017, Part I, volume
10210 of LNCS, pages 446–476. Springer, Heidelberg, April / May 2017. (Cited on page 9.)

Benny Chor, Amos Fiat, and Moni Naor. Tracing traitors.
In Yvo Desmedt, editor,
CRYPTO’94, volume 839 of LNCS, pages 257–270. Springer, Heidelberg, August 1994.
(Cited on page 1.)

[CHN+18] Aloni Cohen, Justin Holmgren, Ryo Nishimaki, Vinod Vaikuntanathan, and Daniel Wichs.
Watermarking cryptographic capabilities. SIAM Journal on Computing, 47(6):2157–2202,
2018. (Cited on page 1, 7, 8, 20, 34, 35, 36, 51, 52, 60, 61.)

44

[CHVW19] Yilei Chen, Minki Hhan, Vinod Vaikuntanathan, and Hoeteck Wee. Matrix PRFs: Con-
structions, attacks, and applications to obfuscation. In Dennis Hofheinz and Alon Rosen,
editors, TCC 2019, Part I, volume 11891 of LNCS, pages 55–80. Springer, Heidelberg,
December 2019. (Cited on page 19.)

[CMSZ21] Alessandro Chiesa, Fermi Ma, Nicholas Spooner, and Mark Zhandry. Post-quantum
succinct arguments: Breaking the quantum rewinding barrier. In Nisheeth Vishnoi, editor,
FOCS 2021 (to appear). IEEE, 2021. (Cited on page 1, 10, 13.)

[DQV+21] Lalita Devadas, Willy Quach, Vinod Vaikuntanathan, Hoeteck Wee, and Daniel Wichs.
Succinct lwe sasmpling, random polynomials and obfuscation. In Kobbi Nissim and Brent
Waters, editors, TCC 2021, LNCS. Springer, 2021. (Cited on page 19.)

[GGM86]

Oded Goldreich, Shaﬁ Goldwasser, and Silvio Micali. How to construct random functions.
Journal of the ACM, 33(4):792–807, 1986. (Cited on page 16.)

[GKM+19] Rishab Goyal, Sam Kim, Nathan Manohar, Brent Waters, and David J. Wu. Watermarking
public-key cryptographic primitives. In Alexandra Boldyreva and Daniele Micciancio, edi-
tors, CRYPTO 2019, Part III, volume 11694 of LNCS, pages 367–398. Springer, Heidelberg,
August 2019. (Cited on page 1, 9, 10, 20.)

[GKW19]

Rishab Goyal, Venkata Koppula, and Brent Waters. New approaches to traitor tracing with
In Dennis Hofheinz and Alon Rosen, editors, TCC 2019, Part II,
embedded identities.
volume 11892 of LNCS, pages 149–179. Springer, Heidelberg, December 2019. (Cited on
page 10.)

[GKWW21] Rishab Goyal, Sam Kim, Brent Waters, and David J. Wu. Beyond software watermarking:
Traitor-tracing for pseudorandom functions.
In Mehdi Tibouchi and Huaxiong Wang,
editors, Asiacrypt 2021 (to appear), Lecture Notes in Computer Science. Springer, 2021.
(Cited on page 2, 3, 9, 10, 20, 22.)

[GP21]

[HILL99]

[HJL21]

Romain Gay and Rafael Pass. Indistinguishability obfuscation from circular security. In
Samir Khuller and Virginia Vassilevska Williams, editors, STOC ’21: 53rd Annual ACM
SIGACT Symposium on Theory of Computing, Virtual Event, Italy, June 21-25, 2021, pages
736–749. ACM, 2021. (Cited on page 19.)

Johan Håstad, Russell Impagliazzo, Leonid A. Levin, and Michael Luby. A pseudorandom
generator from any one-way function. SIAM Journal on Computing, 28(4):1364–1396,
1999. (Cited on page 15.)

Samuel B. Hopkins, Aayush Jain, and Huĳia Lin. Counterexamples to new circular security
assumptions underlying iO. In Tal Malkin and Chris Peikert, editors, CRYPTO 2021, Part II,
volume 12826 of LNCS, pages 673–700, Virtual Event, August 2021. Springer, Heidelberg.
(Cited on page 19.)

[HMW07] Nicholas Hopper, David Molnar, and David Wagner. From weak to strong watermarking.
In Salil P. Vadhan, editor, TCC 2007, volume 4392 of LNCS, pages 362–382. Springer,
Heidelberg, February 2007. (Cited on page 1.)

[Jor75]

Camille Jordan. Essai sur la géométrie à n dimensions. Bulletin de la Société Mathématique
de France, 3:103–174, 1875. (Cited on page 13.)

45

[KNY21]

Fuyuki Kitagawa, Ryo Nishimaki, and Takashi Yamakawa. Secure software leasing from
In Kobbi Nissim and Brent Waters, editors, TCC 2021, LNCS.
standard assumptions.
Springer, 2021. (Cited on page 1, 10.)

[KPTZ13] Aggelos Kiayias, Stavros Papadopoulos, Nikos Triandopoulos, and Thomas Zacharias.
Delegatable pseudorandom functions and applications. In Ahmad-Reza Sadeghi, Virgil D.
Gligor, and Moti Yung, editors, ACM CCS 2013, pages 669–684. ACM Press, November
2013. (Cited on page 16.)

[KW19]

[KW21]

[MW05]

[Nao91]

[Nis13]

[Nis19]

[Nis20]

[NSS99]

[NWZ16]

[Pei09]

[PS18]

Sam Kim and David J. Wu. Watermarking PRFs from lattices: Stronger security via
extractable PRFs. In Alexandra Boldyreva and Daniele Micciancio, editors, CRYPTO 2019,
Part III, volume 11694 of LNCS, pages 335–366. Springer, Heidelberg, August 2019. (Cited
on page 1, 9, 20, 22.)

Sam Kim and David J. Wu. Watermarking cryptographic functionalities from standard
lattice assumptions. J. Cryptol., 34(3):28, 2021. (Cited on page 1, 9, 20.)

Chris Marriott and John Watrous. Quantum arthur-merlin games. Comput. Complex.,
14(2):122–152, 2005. (Cited on page 13.)

Moni Naor. Bit commitment using pseudorandomness. Journal of Cryptology, 4(2):151–
158, January 1991. (Cited on page 51.)

Ryo Nishimaki. How to watermark cryptographic functions. In Thomas Johansson and
Phong Q. Nguyen, editors, EUROCRYPT 2013, volume 7881 of LNCS, pages 111–125.
Springer, Heidelberg, May 2013. (Cited on page 1.)

Ryo Nishimaki. How to watermark cryptographic functions by bilinear maps.
Transactions, 102-A(1):99–113, 2019. (Cited on page 1.)

IEICE

Ryo Nishimaki. Equipping public-key cryptographic primitives with watermarking (or: A
hole is to watermark). In Rafael Pass and Krzysztof Pietrzak, editors, TCC 2020, Part I,
volume 12550 of LNCS, pages 179–209. Springer, Heidelberg, November 2020. (Cited on
page 1, 9, 10, 20.)

David Naccache, Adi Shamir, and Julien P. Stern. How to copyright a function? In Hideki
Imai and Yuliang Zheng, editors, PKC’99, volume 1560 of LNCS, pages 188–196. Springer,
Heidelberg, March 1999. (Cited on page 1.)

Ryo Nishimaki, Daniel Wichs, and Mark Zhandry. Anonymous traitor tracing: How to
embed arbitrary information in a key. In Marc Fischlin and Jean-Sébastien Coron, editors,
EUROCRYPT 2016, Part II, volume 9666 of LNCS, pages 388–419. Springer, Heidelberg,
May 2016. (Cited on page 10.)

Chris Peikert. Public-key cryptosystems from the worst-case shortest vector problem:
In Michael Mitzenmacher, editor, 41st ACM STOC, pages 333–342.
extended abstract.
ACM Press, May / June 2009. (Cited on page 18.)

Chris Peikert and Sina Shiehian. Privately constraining and programming PRFs, the LWE
way. In Michel Abdalla and Ricardo Dahab, editors, PKC 2018, Part II, volume 10770 of
LNCS, pages 675–701. Springer, Heidelberg, March 2018. (Cited on page 9, 18.)

[PW11]

Chris Peikert and Brent Waters. Lossy trapdoor functions and their applications. SIAM
Journal on Computing, 40(6):1803–1844, 2011. (Cited on page 51.)

46

[QWZ18] Willy Quach, Daniel Wichs, and Giorgos Zirdelis. Watermarking PRFs under standard
assumptions: Public marking and security with extraction queries. In Amos Beimel and
Stefan Dziembowski, editors, TCC 2018, Part II, volume 11240 of LNCS, pages 669–698.
Springer, Heidelberg, November 2018. (Cited on page 1, 9, 19, 20, 21, 22, 28.)

[Reg]

[Reg09]

[SW21]

[Unr12]

[Wat09]

[WW21]

Oded Regev.
https://cims.nyu.edu/~regev/teaching/quantum_fall_2005/ln/qma.pdf.
(Cited on page 13.)

Witness-preserveing

ampliﬁcation

(lecture

qma

of

notes).

Oded Regev. On lattices, learning with errors, random linear codes, and cryptography.
Journal of the ACM, 56(6):34:1–34:40, 2009. (Cited on page 1.)

Amit Sahai and Brent Waters. How to use indistinguishability obfuscation: Deniable
encryption, and more. SIAM J. Comput., 50(3):857–908, 2021. (Cited on page 50.)

Dominique Unruh. Quantum proofs of knowledge.
In David Pointcheval and Thomas
Johansson, editors, EUROCRYPT 2012, volume 7237 of LNCS, pages 135–152. Springer,
Heidelberg, April 2012. (Cited on page 1, 10.)

John Watrous. Zero-knowledge against quantum attacks. SIAM J. Comput., 39(1):25–58,
2009. (Cited on page 1, 10.)

Hoeteck Wee and Daniel Wichs. Candidate obfuscation via oblivious LWE sampling.
In Anne Canteaut and François-Xavier Standaert, editors, EUROCRYPT 2021, Part III,
volume 12698 of LNCS, pages 127–156. Springer, Heidelberg, October 2021. (Cited on
page 19.)

[YAL+19] Rupeng Yang, Man Ho Au, Junzuo Lai, Qiuliang Xu, and Zuoxia Yu. Collusion resistant
watermarking schemes for cryptographic functionalities. In Steven D. Galbraith and Shiho
Moriai, editors, ASIACRYPT 2019, Part I, volume 11921 of LNCS, pages 371–398. Springer,
Heidelberg, December 2019. (Cited on page 1, 9, 20.)

[YAYX20] Rupeng Yang, Man Ho Au, Zuoxia Yu, and Qiuliang Xu. Collusion resistant watermarkable
PRFs from standard assumptions. In Daniele Micciancio and Thomas Ristenpart, editors,
CRYPTO 2020, Part I, volume 12170 of LNCS, pages 590–620. Springer, Heidelberg,
August 2020. (Cited on page 1.)

[YF11]

[Zha12a]

[Zha12b]

[Zha19]

Maki Yoshida and Toru Fujiwara. Toward digital watermarking for cryptographic data.
IEICE Transactions, 94-A(1):270–272, 2011. (Cited on page 1.)

Mark Zhandry. How to construct quantum random functions. In 53rd FOCS, pages 679–687.
IEEE Computer Society Press, October 2012. (Cited on page 1, 16, 50.)

Mark Zhandry. Secure identity-based encryption in the quantum random oracle model. In
Reihaneh Safavi-Naini and Ran Canetti, editors, CRYPTO 2012, volume 7417 of LNCS,
pages 758–775. Springer, Heidelberg, August 2012. (Cited on page 1, 50.)

Mark Zhandry. How to record quantum queries, and applications to quantum indiﬀeren-
tiability. In Alexandra Boldyreva and Daniele Micciancio, editors, CRYPTO 2019, Part II,
volume 11693 of LNCS, pages 239–268. Springer, Heidelberg, August 2019. (Cited on
page 1.)

[Zha20]

Mark Zhandry. Schrödinger’s pirate: How to trace a quantum decoder. In Rafael Pass
and Krzysztof Pietrzak, editors, TCC 2020, Part III, volume 12552 of LNCS, pages 61–91.
Springer, Heidelberg, November 2020. (Cited on page 1, 2, 3, 4, 6, 9, 12, 22, 24.)

47

A Achieving QSIM-MDD from SIM-MDD

We prove Theorem 4.6, that is, we show that we can transform extraction-less watermarking PRF
satisfying SIM-MDD security with private simulation into one satisfying QSIM-MDD security with
private simulation, by using a QPRF. Before the proof, we introduce semi-classical one-way to hiding
(O2H) lemma.

A.1 Semi-Classical One-Way to Hiding (O2H) Lemma

We recall a few lemmas.

Deﬁnition A.1 (Punctured oracle). Let F : X → Y be any function, and S ⊂ X be a set. The oracle
F \ S (“F punctured by S”) takes as input a value x ∈ X. It ﬁrst computes whether x ∈ S into an
auxiliary register and measures it. Then it computes F(x) and returns the result. Let Find be the event
that any of the measurements returns 1.

Lemma A.2 (Semi-classical O2H [AHU19, Theorem 1]). Let G, H : X → Y be random functions, z
be a random value, and S ⊆ X be a random set such that G(x) = H(x) for every x /∈ S. The tuple
(G, H, S, z) may have arbitrary joint distribution. Furthermore, let A be a quantum oracle algorithm.
Let Ev be any classical event. Then we have

Pr

Ev : A |Hi(z)

− Pr

Ev : A |Gi(z)

≤ 2

(q + 1) · Pr

Find : A |H\Si(z)

.

h

i

(cid:12)
(cid:12)
(cid:12)

i(cid:12)
(cid:12)
Lemma A.3 (Search in semi-classical oracle [AHU19, Theorem 2]). Let H : X → Y be a random
(cid:12)
function, let z be a random value, and let S ⊂ X be a random set. (H, S, z) may have arbitrary joint
distribution. Let A be a quantum oracle algorithm. If for each x ∈ X, Pr[x ∈ S] ≤ ǫ (conditioned on
H and z), then we have

h

(cid:3)

(cid:2)

q

where q is the number of queries to H by A.

h

i

Pr

Find : A |H\Si(z)

≤ 4qǫ ,

Note that the above lemma is originally introduced in [AHU19], but we use a variant that is closer to

Lemma 4 in [BHH+19].

A.2 Proof

Construction. We start with the construction. Let ELWMPRF = (Setup, Gen, Eval, Mark, Sim) be an
extraction-less watermarking PRF scheme satisfying SIM-MDD security with private simulation. We
also let the message space of ELWMPRF is {0, 1}ℓm . Let PRF be a QPRF with domain {0, 1}λ and range
RSim, which is the randomness space of Sim. We construct an extraction-less watermarking PRF scheme
QELWMPRF = (QEL.Setup, QEL.Gen, QEL.Eval, QEL.Mark, QEL.Sim) satisfying QSIM-MDD secu-
rity with private simulation as follows. We use Gen, Eval, and Mark as QEL.Gen, QEL.Eval, and
QEL.Mark, respectively. The domain and range of QELWMPRF are the same as those of ELWMPRF.
The mark space of QELWMPRF is {0, 1}ℓm . Also, we construct QEL.Setup and QEL.Sim as follows.

QEL.Setup(1λ):

• Generate (pp, xk) ← Setup(1λ).
• Genrate K ← {0, 1}λ.
• Outputs (pp, qxk := (xk, K)).

48

QEL.Sim(qxk, τ, i; r):

• Parse (xk, K) ← qxk.
• Output (γ, x, y) ← Sim(xk, τ, i; PRFK(r)).

Security analysis. Let i∗ ∈ [ℓm] and A be any QPT adversary for QSIM-MDD security with private
simulation making total q queries to Osim and Oapi. We prove that for any polynomial w, it holds that
Advq-sim-mdd
i∗,A,QELWMPRF(λ) ≤ 1/w. We prove it using hybrid games. Let SUCX be the event that the ﬁnal
output is 1 in Game X. We deﬁne a distribution Dτ′,i′ as
Dτ′,i′: Output (γ, x, y) ← Sim(xk, τ′, i′).

Game 1: This is Exptq-sim-mdd

i∗,A,QELWMPRF(λ). Thus, Advq-sim-mdd

i∗,A,QELWMPRF(λ) = 2|Pr[SUC1] − 1/2|.

1. The challenger generates (pp, xk) ← Setup(1λ) and K ← {0, 1}λ, and gives pp to A. A send
m ∈ {0, 1}ℓm to the challenger. The challenger generates (τ, prfk) ← Gen(pp), computes
C ← Mark(pp, prfk, m), and sends
2. A can access to the following oracles.
e

e
Osim: On input τ′ and i′, it returns Sim(xk, τ′, i′; PRFK(r)), where r ← {0, 1}λ.
Oapi: On input (ǫ, δ, τ′, i′) and a quantum state q, it returns the result of API ǫ,δ

(q) and

C to A.

P ,DPRF
τ′,i′

the post measurement state, where DPRF

τ′,i′ = Dτ′,i′(PRFK(·)).

3. The challenger generates coin ← {0, 1}. If coin = 0, the challenger samples (γ, x, y) ←
Dreal,i∗. If coin = 1, the challenger generates (γ, x, y) ← Sim(xk, τ, i∗; PRFK(r∗)), where,
r∗ ← {0, 1}λ. The challenger sends (γ, x, y) to A.

4. When A terminates with output coin′, the challenger outputs 1 if coin = coin′ and 0 otherwise.

Game 2: This game is the same as Game 1 except that PRFK is replaced with a quantum-accessible

random function R.

We have |Pr[SUC1] − Pr[SUC2]| = negl(λ) from the the security of PRF.

Game 3: This game is the same as Game 2 except that R is replaced with

V(r) =

v∗
R(r)

(

(if r = r∗)
(otherwise),

where v∗ ← RSim.

We have |Pr[SUC2] − Pr[SUC3]| = 0.

Game 4: This game is the same as Game 3 except the followings. When A makes a query τ′ and i′
to Osim, Sim(xk, τ′, i′; R(r)) is returned instead of Sim(xk, τ′, i′; V(r)). Also, when A makes a
query (ǫ, δ, τ′, i′) to Oapi, API ǫ,δ
τ′,i′ =
Dτ′,i′(R(·)) and DV
By this change, V is now used only for generating the challenge tuple (γ, x, y) ← Sim(xk, τ, i∗; V(r∗)) =
Sim(xk, τ, i∗; v∗).

(q) is performed instead of API ǫ,δ

τ′,i′
τ′,i′ = Dτ′,i′ (V(·)).

(q), where DR

P ,DR

P ,DV

τ′,i′

We have |Pr[SUC3] − Pr[SUC4]| = O(

q2
2λ ) from Lemma A.2 and Lemma A.3.

q

49

Game 5: This game is the same as Game 4 except that R is replaced with G ◦ F, where F : {0, 1}λ → [s]

and G : [s] → RSim are random functions and s is a polynomial of λ speciﬁed later.

Theorem A.4 (Small Range Distribution [Zha12a]). For any QPT adversary B making q quantum
queries to R or G ◦ F, we have

B |G◦Fi(1λ) = 1

B |Ri(1λ) = 1

≤ O(q3/s).

− Pr

Pr

h
By the above theorem, we have |Pr[SUC4] − Pr[SUC5]| = O(q3/s).

h

i

(cid:12)
(cid:12)
(cid:12)

i(cid:12)
(cid:12)
(cid:12)

We can simulate F using a 2q-wise independent function E by the following theorem.

Theorem A.5 ([Zha12b]). For any QPT adversary B making q quantum queries to F or E, we have
Pr

B |Ei(1λ) = 1

B |Fi(1λ) = 1

= Pr

.

i
P ,DG◦E
τ′,i′

h

i

h

We can eﬃciently simulate API ǫ,δ

in Game 5 using s samples from Dτ′,i′ since Dτ′,i′(G(·))
can be interpreted as a mapping for s samples from Dτ′,i′. Then, from the SIM-MDD security with
private simulation of ELWMPRF, we have |Pr[SUC5] − 1/2| = negl(λ). From the above, we also have
Advq-sim-mdd
i∗,A,QELWMPRF(λ) ≤ O(q3/s) + 2γ for some negligible function γ. Thus, by setting s = O(q3 · w2),
we obtain Advq-sim-mdd

i∗,A,QELWMPRF(λ) ≤ 1/w.

Since w is any polynomial, this means that Advq-sim-mdd

i∗,A,QELWMPRF(λ) = negl(λ).

Remark A.6. It is easy to see that the extended weak pseudorandomness of ELWMPRF is preserved after
we apply the transformation above since the evaluation algorithm is the same as that of ELWMPRF and
extended weak pseudorandomness holds against adversaries that generate pp. Thus, we omit a formal
proof.

B Puncturable Encryption with Strong Ciphertext Pseudorandomness

We prove Theorem 7.5 in this section.

B.1 Tools for PE
Deﬁnition B.1 (Statistically Injective PPRF). If a PPRF family F = {FK : {0, 1}ℓ1 (λ) → {0, 1}ℓ2 (λ) |
K ∈ {0, 1}λ} satisﬁes the following, we call it a statistically injective PPRF family with failure probability
ǫ(·). With probability 1 − ǫ(λ) over the random choice of K ← PRF.Gen(1λ), for all x, x′ ∈ {0, 1}ℓ1 (λ),
if x 6= x′, then FK(x) 6= FK(x′). If ǫ(·) is not speciﬁed, it is a negligile function.

Sahai and Waters show that we can convert any PPRF into a statistically injective PPRF [SW21].

Theorem B.2 ([SW21]). If OWFs exist, then for all eﬃciently computable functions n(λ), m(λ), and
e(λ) such that m(λ) ≥ 2n(λ) + e(λ), there exists a statistically injective PPRF family with failure
probability 2−e(λ) that maps n(λ) bits to m(λ) bits.

Deﬁnition B.3. An injective bit-commitment with setup consists of PPT algorithms (Gen, Com).
Gen(1λ): The key generation algorithm takes as input the security parameter 1λ and outputs a commit-

ment key ck.

Comck(b): The commitment algorithm takes as input ck and a bit b and outputs a commitment com.

These satisfy the following properties.

Computationally Hiding: For any QPT A, it holds that

Pr

A(Comck(0)) = 1 | ck ← Gen(1λ)

− Pr

A(Comck(1)) = 1 | ck ← Gen(1λ)

≤ negl(λ).

h

(cid:12)
(cid:12)
(cid:12)

i

h

50

i(cid:12)
(cid:12)
(cid:12)

Statistically Binding: It holds that

Pr





com0 = com1 (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

ck ← Gen(1λ)
com0 ← Comck(0)
com1 ← Comck(1)





≤ negl(λ).

Injective: For every security parameter λ, there is a bound ℓr on the number of random bits used by
Com such that if ck ← Gen(1λ), Comck(· ; ·) is an injective function on {0, 1} × {0, 1}ℓr except
negligible probability.

Theorem B.4. If the QLWE assumption holds, there exists a secure injective bit-commitment with setup.

This theorem follows from the following theorems.

Theorem B.5 ([Nao91]). If there exists (injective) OWFs, there exists (injective) bit-commitment.

Theorem B.6 ([PW11, AKPW13, Adapted]). If the QLWE assumption holds, there exists a secure
injective OWF with evaluation key generation algorithms.

Remark B.7. The injective OWFs achieved in Theorem B.6 needs evaluation key generation algorithms
unlike the standard deﬁnition of OWFs. However, OWFs with evaluation key generation algorithms
are suﬃcient for proving Theorem B.4 by using Theorem B.5 since we use commitment key generation
algorithm Gen (i.e., setup) in Deﬁnition B.3. Note that there is no post-quantum secure injective OWF
without evaluation key generation algorithm so far.

B.2 PE Scheme Description

We review the puncturable encryption scheme by Cohen et al. [CHN+18]. We can see Theorem 7.5
holds by inspecting their PE scheme. The scheme utilizes the following ingredients and the length n of
ciphertexts is 12 times the length ℓ of plaintexts:

• A length-doubling PRG : {0, 1}ℓ → {0, 1}2ℓ
• An injective PPRFs (See Deﬁnition B.1) F : {0, 1}3ℓ → {0, 1}9ℓ.
• A PPRF G : {0, 1}9ℓ → {0, 1}ℓ.
• An injective bit-commitment with setup (Com.Gen, Com) using randomness in {0, 1}9ℓ. We only

use this in our security proof.

Scheme. The scheme PE by Cohen et al. [CHN+18] is as follows.

Gen(1λ): Sample functions F and G, generates pe.ek as the obfuscated circuit iO(E) where E is de-
scribed in Figure 12, and returns (pe.ek, pe.dk) := (iO(E), D), where pe.dk is the (un-obfuscated)
program D in Figure 13.

Puncture(pe.dk, c∗): Output pe.dk6=c∗, where pe.dk6=c∗ is the obfuscated circuits iO(D6=c∗) where D6=c∗

is described in Figure 14, that is, pe.dk6=c∗ := iO(D6=c∗).

Enc(pe.ek, m): Take m ∈ {0, 1}ℓ, sample s ← {0, 1}ℓ, and outputs c ← pe.ek(m, s).
Dec(pe.dk, c): Take c ∈ {0, 1}12ℓ and returns m := pe.dk(c).

The size of the circuits is appropriately padded to be the maximum size of all modiﬁed circuits, which
will appear in the security proof.

51

Constants : Injective PPRF F : {0, 1}3ℓ → {0, 1}9ℓ, PPRF G : {0, 1}9ℓ → {0, 1}ℓ
Inputs: m ∈ {0, 1}ℓ

, s ∈ {0, 1}ℓ

Circuit E[F, G]

1. Compute α = PRG(s).
2. Compute β = F(αkm).
3. Compute γ = G(β) ⊕ m.
4. Output (α, β, γ).

Figure 12: Description of encryption circuit E

Constants : Injective PPRF F : {0, 1}3ℓ → {0, 1}9ℓ, PPRF G : {0, 1}9ℓ → {0, 1}ℓ
Inputs: c = (αkβkγ), where α ∈ {0, 1}2ℓ, β ∈ {0, 1}9ℓ, and γ ∈ {0, 1}ℓ.

Circuit D[F, G]

1. Compute m = G(β) ⊕ γ.
2. If β = F(αkm), output m.
3. Else output ⊥.

Figure 13: Description of decryption circuit D

Constants : Point c∗ ∈ {0, 1}12ℓ, injective PPRF F : {0, 1}3ℓ → {0, 1}9ℓ, and PPRF G : {0, 1}9ℓ → {0, 1}ℓ
Inputs: c = (αkβkγ), where α ∈ {0, 1}2ℓ, β ∈ {0, 1}9ℓ, and γ ∈ {0, 1}ℓ.

Circuit D6=c∗ [F, G, c∗]

1. If c = c∗, output ⊥.
2. Compute m = G(β) ⊕ γ.
3. If β = F(αkm), output m.
4. Else output ⊥.

Figure 14: Description of punctured decryption circuit D6=c∗ at c∗

B.3 PE Security Proof

Cohen et al. [CHN+18] proved correctness, punctured correctness, and sparseness of PE above by using
secure PRG PRG, secure injective PPRF F, secure PPRF G, and secure IO iO. Thus, we complete the
proof of Theorem 7.5 by combining Theorems B.2 and B.4, and Theorem B.8 below, which we prove in
this section.

Theorem B.8. If PRG is a secure PRG, F is a secure injective PPRF, G is a secure PPRF, Com is a
secure injective bit-commitment with setup, and iO is a secure IO, then PE is a secure PE that satisifes
strong ciphertext pseudorandomness.

Proof of Theorem B.8. To prove x0 := c∗ ← Enc(pe.ek, m∗) is indistinguishable from x1 := r∗ ←
{0, 1}ℓ, we deﬁne a sequence hybrid games.
Real: This is the same as the real game with b = 0. That is, for queried m∗ the challenger does the

following.

1. Choose an injective PPRF F : {0, 1}3ℓ → {0, 1}9ℓ and PPRF G : {0, 1}9ℓ → {0, 1}ℓ.

52

2. Choose s ← {0, 1}ℓ and compute α0 := PRG(s), β0 := F(α0km∗), and γ0 := G(β0) ⊕ m∗.
3. Set x0 := α0kβ0kγ0 and computes pe.ek := iO(E) and pe.dk6=x0 := iO(D6=x0).
4. Send (x0, pe.ek, pe.dk6=x0) to the adversary.

Hyb1: This is the same as Hyb0(0) except that α0 is uniformly random.
Hyb2: This is the same as Hyb1 except that we use punctured F6=α0km∗ and modiﬁed circuits E6=α0km∗
6=α0km∗ described in Figures 16 and 17. Intuitively, these modiﬁed circuits are punctured at

and D2
input α0km∗ and use exceptional handling for this input.

Hyb3: This is the same as Hyb2 except that β0 ← {0, 1}9ℓ.
Hyb4: This is the same as Hyb3 except that we use punctured G6=β0 and modiﬁed circuits E6=α0km∗,6=β0
described in Figures 18 and 19. Intuitively, these modiﬁed circuits are punctured

and D4
at input β0 and use F6=α0km∗ and exceptional handling for β0.

6=α0km∗,6=β0

Hyb5 = Rand2: This is the same as Hyb4 except that γ0 is uniformly random. Now, α0, β0, γ0 are
uniformly random and we rewrite them into α1, β1, γ1, respectively. For ease of notation, we also
denote this game by Rand2.

Rand1: This is the same as Hyb5 = Rand2 except that we use un-punctured G, circuit E6=α0km∗,6=β0
6=α1km∗

reverts to E6=α1km∗ described in Figure 16, and we change circuit D4
described in Figure 21.

6=α1km∗,6=β1

into Dr

Rand: This is the same as the real game with b = 1. That is, for queried m∗ the challenger does the

following.

1. Choose an injective PPRF F : {0, 1}3ℓ → {0, 1}9ℓ and PPRF G : {0, 1}9ℓ → {0, 1}ℓ.
2. Choose α1 ← {0, 1}2ℓ, β1 ← {0, 1}9ℓ, and γ1 ← {0, 1}ℓ.
3. Set x1 := α1kβ1kγ1 and computes pe.ek := iO(E) and pe.dk6=x1 := iO(D6=x1).
4. Send (x1, pe.ek, pe.dk6=x1) to the adversary.

We described the overview of these hybrid games in Figure 15. If we prove these hybrid games are

α∗

PRG(s)
$
$

$
$

$
$

$

Real
Hyb1
Hyb2
Hyb3
Hyb4
Hyb5
Rand1
Rand

pe.ek := iO(·)

β∗
γ∗
F(α0km∗) G(β0) ⊕ m∗ E
F(α0km∗) G(β0) ⊕ m∗ E
F(α0km∗) G(β0) ⊕ m∗ E6=α0km∗
G(β0) ⊕ m∗ E6=α0km∗
$
G(β0) ⊕ m∗ E6=α0km∗,6=β0
$
E6=α1km∗,6=β1
$
E6=α1km∗
$
E

$
$

$

$

pe.dk := iO(·)

D6=x0
D6=x0
D2
D2
D4
D4
Dr

D6=x1

6=α0km∗[F6=α0km∗]
6=α0km∗[F6=α0km∗]
6=α0km∗,6=β0

6=α1km∗,6=β1
6=α1km∗[F6=α1km∗]

[F6=α0km∗, G6=β0]
[F6=α1km∗, G6=β1]

Figure 15: High-level overview of hybrid games from Real to Rand. Recall that Hyb5 = Rand2. Transitions from
Rand2 to Rand are baiscally the reverse transitions from Hyb0 to Hyb4, but there are subtle diﬀerences.

indistinguishable, we complete the proof of Theorem B.8.

We prove that those hybrid games in Figure 15 are indistinguishable by Lemmata B.9, B.10, B.14,

B.15, B.19, B.20 and B.25.

53

Circuit E6=α∗km∗ [F′, G]

Constants : Injective PPRF F′, PPRF G
Inputs: m ∈ {0, 1}ℓ

, s ∈ {0, 1}ℓ

1. Compute α = PRG(s).
2. Compute β = F′(αkm).
3. Compute γ = G(β) ⊕ m.
4. Output (α, β, γ).

Figure 16: Description of encryption circuit E6=α∗km∗

Circuit D2

6=α∗km∗ [F′, G, α∗, β∗, γ∗, m∗]

Constants : Point x∗ = α∗kβ∗kγ∗ ∈ {0, 1}12ℓ, injective PPRF F′, PPRF G, m∗.
Inputs: c = (αkβkγ), where α ∈ {0, 1}2ℓ, β ∈ {0, 1}9ℓ, and γ ∈ {0, 1}ℓ.

1. If c = x∗, output ⊥.
2. Compute m = G(β) ⊕ γ.
3. If (α, m) = (α∗, m∗), output ⊥.
4. If β = F′(αkm), output m.
5. Else output ⊥.

Figure 17: Description of punctured decryption circuit D2

6=α∗km∗

From Real to Hyb5. We ﬁrst move from Real to Hyb5.

Lemma B.9. If PRG is a secure PRG, it holds that |Pr[Hyb0(0) = 1] − Pr[Hyb1 = 1]| ≤ negl(λ).

Proof of Lemma B.9. The randomness s for encryption is never used anywhere except α0 := PRG(s).
We can apply the PRG security and immediately obtain the lemma.

Lemma B.10. If iO is a secure IO and F is a secure injective PPRF, it holds that

|Pr[Hyb1 = 1] − Pr[Hyb2 = 1]| ≤ negl(λ).

Proof of Lemma B.10. We change E and D6=x0 into E6=α0km∗ and D2

6=α0km∗, respectively.

We deﬁne a sequence of sub-hybrid games.
1: This is the same as Hyb1 except that we generate F6=α0km∗ and set F′ := F6=α0km∗ and pe.ek :=

Hyb1

iO(E6=α0km∗) described in Figure 16.

Hyb2

1: This is the same as Hyb1

:= iO(D2
described in Figure 17. That is, we still use F, but modify the circuit.

1 except that we set pe.dk6=x0

6=α0km∗[F, G, α0, β0, γ0, m∗])

Proposition B.11. If iO is a secure IO, it holds that

Pr[Hyb1 = 1] − Pr

Hyb1

1 = 1

≤ negl(λ).

(cid:12)
Proof of Proposition B.11. In these games, value α0 ← {0, 1}2ℓ is not in the image of PRG except
(cid:12)
(cid:12)
with negligible probability. The only diﬀerence between the two games is that F6=α0km∗ is used in Hyb1
1.
Thus, E and E6=α0km∗ are functionally equivalent except with negligible probability. We can obtain the
proposition by applying the IO security.

i(cid:12)
(cid:12)
(cid:12)

h

54

Circuit E6=α∗km∗,6=β∗ [F′, G′]

Constants : Injective PPRF F′, PPRF G′
Inputs: m ∈ {0, 1}ℓ

, s ∈ {0, 1}ℓ

1. Compute α = PRG(s).
2. Compute β = F′(αkm).
3. Compute γ = G′(β) ⊕ m.
4. Output (α, β, γ).

Figure 18: Description of encryption circuit E6=α∗km∗,6=β∗

Proposition B.12. If iO is a secure IO and F is injective, it holds that
negl(λ).

Pr

Hyb1

1 = 1

− Pr

Hyb2

1 = 1

≤

h

i

(cid:2)

(cid:12)
(cid:12)
(cid:12)

(cid:3)(cid:12)
(cid:12)
(cid:12)

Proof of Proposition B.12. We analyze the case where (α, m) = (α0, m∗) since it is the only diﬀerence
between D6=x0 and D2
• If c = x0, D2

6=α0km∗ outputs ⊥ by the ﬁrst line of the description. Thus, the output of D2

6=α0km∗(x0)

6=α0km∗.

is the same as that of D6=x0(x0).

• If c 6= x0, it holds (β0, γ0) 6= (β, γ) in this case. However, it should be β0 = β due to the
6=α0km∗(c) output ⊥ in this case

injectivity of F and β0 = F(α0km∗). Thus, both D6=x0(c) and D2
(D6=x0(c) outputs ⊥ at the ﬁrst line).

Therefore, D6=x0 and D2
the IO security.

6=α0km∗ are functionally equivalent. We can obtain the proposition by applying

Proposition B.13. If iO is a secure IO, it holds that

Pr

Hyb2

1 = 1

− Pr[Hyb2 = 1]

≤ negl(λ).

Proof of Proposition B.13. Due to the exceptional handling in the third item of D2
never computed for input (α0, m∗). Thus, even if we use F6=α0km∗ instead of F, D2
D2

6=α0km∗[F6=α0km∗] are functionally equivalent. We can obtain the proposition by the IO security.

(cid:12)
6=α0km∗, F(αkm) is
(cid:12)
6=α0km∗[F] and

(cid:12)
(cid:12)

(cid:2)

(cid:3)

We complete the proof of Lemma B.10.

Lemma B.14. If F is a secure injective PPRF, it holds that |Pr[Hyb2 = 1] − Pr[Hyb3 = 1]| ≤ negl(λ).

Proof of Lemma B.14. The diﬀerence between these two games is that β0 is F(α0km∗) or random. We
can immediately obtain the lemma by applying punctured pseudorandomness of F since we use F6=α0km∗
in these games.

Lemma B.15. If iO is a secure IO and F is a secure injective PPRF, it holds that

|Pr[Hyb3 = 1] − Pr[Hyb4 = 1]| ≤ negl(λ).

Proof of Lemma B.15. We change E6=α∗km∗ and D2

6=α∗km∗ into E6=α∗km∗,6=β∗ and D4

6=α∗km∗,6=β∗, respectively.

We deﬁne a sequence of sub-hybrid games.

Hyb1

Hyb2

3: This is the same as Hyb3 except that we use punctured G6=β0 and set pe.ek := iO(E6=α0km∗,6=β0[F6=α0km∗, G6=β0]).
3: This is the same as Hyb1

3 except that we still use G but set pe.dk6=c0 := iO(D4

[F6=α0km∗, G]).

6=α0km∗,6=β0

55

Circuit D4

6=α∗km∗,6=β∗[F′, G′, α∗, β∗, γ∗, m∗]

Constants : Point x∗ := α∗kβ∗kγ∗ ∈ {0, 1}12ℓ, injective PPRF F′, PPRF G′, m∗.
Inputs: c = (αkβkγ), where α ∈ {0, 1}2ℓ, β ∈ {0, 1}9ℓ, and γ ∈ {0, 1}ℓ.

1. If β = β∗, output ⊥.
2. Compute m = G′(β) ⊕ γ.
3. If (α, m) = (α∗, m∗), output ⊥.
4. If β = F′(αkm), output m.
5. Else output ⊥.

Figure 19: Description of punctured decryption circuit D4

6=α∗km∗,6=β∗

Proposition B.16. If iO is a secure IO, it holds that

Pr[Hyb3 = 1] − Pr

Hyb1

3 = 1

≤ negl(λ).

(cid:12)
Proof of Proposition B.16. In these games β0 ← {0, 1}9ℓ is uniformly random. By the sparsity of
(cid:12)
(cid:12)
F, β0 is not in the image of F except with negligible probability. Thus, E6=α0km∗ and E6=α0km∗,6=β0
are functionally equivalent except with negligible probability. We obtain the proposition by the IO
security.

i(cid:12)
(cid:12)
(cid:12)

h

Proposition B.17. If iO is a secure IO, it holds that

Pr

Hyb1

3 = 1

− Pr

Hyb2

3 = 1

≤ negl(λ).

(cid:12)
h
6=α0km∗ and D4
Proof of Proposition B.17. The diﬀerence between D2
(cid:12)
is that we replace “If
(cid:12)
c = x0, outputs ⊥.” with “If β = β0, outputs ⊥.”. In these games, β0 ← {0, 1}9ℓ is not in the image of
F except with negligible probability. Recall that c = x0 means c = α0kβ0kγ0. Thus, those two circuits
may diﬀer when β = β0 but (α, γ) 6= (α0, γ0). However, it does not happen β = F′(αk(G(β) ⊕ γ)) in
6=α0km∗ and D4
this case due to the injectivity of F. Thus, D2
are functionally equivalent and we
obtain the proposition by applying the IO security.

(cid:2)
6=α0km∗,6=β0

6=α0km∗,6=β0

(cid:3)(cid:12)
(cid:12)
(cid:12)

i

Proposition B.18. If iO is a secure IO, it holds that

Pr

Hyb2

3 = 1

− Pr[Hyb4 = 1]

≤ negl(λ).

Proof of Proposition B.18. The diﬀerence between these two games that we use D4
instead of D4
D4

6=α0km∗,6=β0
. We obtain the proposition by the IO security.

[F6=α0km∗, G]. However, G6=β0(β0) is never computed by the ﬁrst item of

(cid:12)
6=α0 km∗,6=β0
(cid:12)

[F6=α0km∗, G6=β0]

(cid:12)
(cid:12)

(cid:3)

(cid:2)

6=α0km∗,6=β0

We complete the proof of Lemma B.15.

Lemma B.19. If G is a secure PPRF, it holds that |Pr[Hyb4 = 1] − Pr[Hyb5 = 1]| ≤ negl(λ).

Proof of Lemma B.19. The diﬀerence between these two games is that γ0 is G(β0) or random. We can
immediately obtain the lemma by applying punctured pseudorandomness of G since we use G6=β0 in
these games.

In Hyb5, α0, β0, and γ0 are uniformly random strings as α1, β1, and γ1.

From Rand to Hyb5. We leap to Rand and move from Rand to Rand2 = Hyb5 instead of directly
moving from Hyb5 = Rand2 to Rand since Real ≈ Hyb5 and Rand2 ≈ Rand is almost symmetric (but
not perfectly symmetric).

Lemma B.20. If iO is a secure IO and F is a secure injective PPRF, it holds that

|Pr[Rand = 1] − Pr[Rand1 = 1]| ≤ negl(λ).

56

Circuit Dr-2

6=α∗km∗ [F′, G, α∗, β∗, γ∗, ˆβ, ˆγ, m∗]

Constants : Point x∗ = α∗kβ∗kγ∗ ∈ {0, 1}12ℓ, injective PPRF F′, PPRF G, ˆβ, ˆγ, m∗.
Inputs: c = (αkβkγ), where α ∈ {0, 1}2ℓ, β ∈ {0, 1}9ℓ, and γ ∈ {0, 1}ℓ.

1. If α = α∗ and β = ˆβ and γ = ˆγ, output m∗.
2. If c = x∗, output ⊥.
3. Compute m = G(β) ⊕ γ.
4. If β = F′(αkm), output m.
5. Else output ⊥.

Figure 20: Description of punctured decryption circuit Dr-2

6=α∗km∗

Circuit Dr

6=α∗km∗ [F′, G, α∗, β∗, γ∗, ˆβ, ˆγ, m∗]

Constants : Point x∗ = α∗kβ∗kγ∗ ∈ {0, 1}12ℓ, injective PPRF F′, PPRF G, ˆβ, ˆγ, m∗.
Inputs: c = (αkβkγ), where α ∈ {0, 1}2ℓ, β ∈ {0, 1}9ℓ, and γ ∈ {0, 1}ℓ.

1. If α = α∗ and β = ˆβ and γ = ˆγ, output m∗.
2. If c = x∗, output ⊥.
3. Compute m = G(β) ⊕ γ.
4. If (α, m) = (α∗, m∗), output ⊥.
5. If β = F′(αkm), output m.
6. Else output ⊥.

Figure 21: Description of punctured decryption circuit Dr

6=α∗km∗

Proof of Lemma B.20. We change E and D6=x1 into E6=α1km∗ and Dr

6=α1km∗, respectively.

We deﬁne a sequence of sub-hybrid games.

rHyb1: This is the same as Rand except that we generate F6=α1km∗ and set F′ := F6=α1km∗ and pe.ek :=

iO(E6=α1km∗) described in Figure 16.

rHyb2: This is the same as rHyb1 except that we set pe.dk6=x1 := iO(Dr-2

6=α1km∗[F, G]) described in Fig-
ure 20. That is, we still use F, but the modiﬁed circuit that outputs m∗ for input α1k ˆβk ˆγ, where
ˆβ := F(α1km∗) and ˆγ := G( ˆβ) ⊕ m∗.

rHyb3: This is the same as rHyb2 except that we set pe.dk6=x1

6=α1km∗[F, G]) described
in Figure 21. That is, we still use F, but the modiﬁed circuit outputs ⊥ for an input such
that (α, m) = (α1, m∗).

:= iO(Dr

Proposition B.21. If iO is a secure IO, it holds that

Pr[Rand = 1] − Pr

rHyb1 = 1

≤ negl(λ).

(cid:12)
Proof of Proposition B.21. In these games, value α1 ← {0, 1}2ℓ is not in the image of PRG except
(cid:12)
(cid:12)
with negligible probability. Thus, E and E6=α1km∗ are functionally equivalent except with negligible
probability. We can obtain the proposition by applying the IO security.

i(cid:12)
(cid:12)
(cid:12)

h

Proposition B.22. If iO is a secure IO and F is injective, it holds that
negl(λ).

Pr

rHyb1 = 1

− Pr

rHyb2 = 1

≤

h

(cid:12)
(cid:12)
(cid:12)

i

(cid:2)

(cid:3)(cid:12)
(cid:12)
(cid:12)

57

Circuit Dcom

6=α∗km∗ [F′, G, α∗, β∗, γ∗, ˆz, ck, ˆγ, m∗]

Constants : Point x∗ = α∗kβ∗kγ∗ ∈ {0, 1}12ℓ, injective PPRF F′, PPRF G, m∗, ˆz, ck, ˆγ.
Inputs: c = (αkβkγ), where α ∈ {0, 1}2ℓ, β ∈ {0, 1}9ℓ, and γ ∈ {0, 1}ℓ.

1. If α = α∗ and Comck(0; β) = ˆz and γ = ˆγ, output m∗.
2. If c = x∗, output ⊥.
3. Compute m = G(β) ⊕ γ.
4. If (α, m) = (α∗, m∗), output ⊥.
5. If β = F′(αkm), output m.
6. Else output ⊥.

Figure 22: Description of punctured decryption circuit Dcom

6=α∗km∗

6=α1km∗ is “If α = α∗ and β = ˆβ and
Proof of Proposition B.22. The diﬀerence between D6=x1 and Dr-2
γ = ˆγ, output m∗.”. Although α1k ˆβk ˆγ is a valid encryption, ˆβ = F(α1km∗) is not equal to β1 except
with negligible probability since β1 is uniformly random. Similarly, ˆγ is not equal to γ1 except with
negligible probability. Thus, D6=x1(α1k ˆβk ˆγ) outputs m∗. That is, D6=x1 and Dr-2
6=α1km∗ are functionally
equivalent. We can obtain the proposition by applying the IO security.

Proposition B.23. If iO is a secure IO and F is injective, it holds that
negl(λ).

(cid:3)(cid:12)
(cid:12)
Proof of Proposition B.23. We analyze the case where (α, m) = (α1, m∗). We can reach the forth line
of Dr
6=α1km∗ if c 6= x1. If c 6= x1 and (α, m) = (α1, m∗), it holds that (β, γ) 6= (β1, γ1). However, it
should be β1 = β in this case due to the injectivity of F. That is, if Dr
6=α1km∗(c) outputs ⊥ at the fourth
6=α1km∗(c) also outputs ⊥ at the second line. Therefore, Dr-2
line, Dr-2
6=α1km∗ are functionally
equivalent. We can obtain the proposition by applying the IO security.

6=α1km∗ and Dr

(cid:12)
(cid:12)

(cid:2)

(cid:3)

(cid:2)

Pr

rHyb2 = 1

− Pr

rHyb3 = 1

≤

Proposition B.24. If iO is a secure IO, it holds that

Pr

rHyb3 = 1

− Pr[Rand1 = 1]

≤ negl(λ).

(cid:12)
Proof of Proposition B.24. Due to the exceptional handling in the fourth line of Dr
6=α1km∗, F(αkm)
(cid:12)
is never computed for input (α1, m∗). Thus, even if we use F6=α1km∗ instead of F, Dr
6=α1km∗[F] and
Dr

6=α1km∗[F6=α1km∗] are functionally equivalent. We can obtain the proposition by the IO security.

(cid:12)
(cid:12)

(cid:3)

(cid:2)

We complete the proof of Lemma B.20.

Lemma B.25. If iO is a secure IO, F is a secure injective PPRF, and (Com.Gen, Com) is a secure
injective bit-commitment with setup, it holds that |Pr[Rand1 = 1] − Pr[Rand2 = 1]| ≤ negl(λ).

Proof of Lemma B.25. We change E6=α∗km∗ and Dr
tively.

6=α∗km∗ into E6=α∗km∗,6=β∗ and D4

6=α∗km∗,6=β∗, respec-

rHyb1

rHyb2

We deﬁne a sequence of sub-hybrid games.
1: This is the same as Rand1 except that we use ˆβ ← {0, 1}9ℓ instead of F(α1km∗).
1 except that we use Dcom
1: This is the same as rHyb1
Com.Gen(1λ) and ˆz = Comck(0; ˆβ) are hardwired, instead of Dr

6=α1km∗.

6=α1km∗ described in Figure 22, where ck ←

rHyb3

1: This is the same as rHyb2
Comck(0; ˆβ).

1 except that we hard-code ˆz = Comck(1; ˆβ) into Dcom

6=α1km∗ instead of

58

Circuit DF

6=α∗km∗ [F′, G, α∗, β∗, γ∗, m∗, ˆz, ˆγ]

Constants : Point x∗ = α∗kβ∗kγ∗ ∈ {0, 1}12ℓ, injective PPRF F′, PPRF G, m∗, ˆz, ˆγ.
Inputs: c = (αkβkγ), where α ∈ {0, 1}2ℓ, β ∈ {0, 1}9ℓ, and γ ∈ {0, 1}ℓ.

// Never triggered

1. If α = α∗ and False and γ = ˆγ, output m∗.
2. If c = x∗, output ⊥.
3. Compute m = G(β) ⊕ γ.
4. If (α, m) = (α∗, m∗), output ⊥.
5. If β = F′(αkm), output m.
6. Else output ⊥.

Figure 23: Description of punctured decryption circuit DF

6=α∗km∗

rHyb4

rHyb5

rHyb6

1: This is the same as rHyb3
1: This is the same as rHyb4
1: This is the same as rHyb5

1 except that we use DF

6=α1km∗ described in Figure 23

1 except that we use punctured G6=β1 and set pe.ek := iO(E6=α1km∗,6=β1[F6=α1km∗, G6=β1]).
1 except that we still use G but set pe.dk6=c1 := iO(D4

[F6=α1km∗, G]).

6=α1km∗,6=β1

Proposition B.26. If F is a secure PPRF, it holds that

Pr[Rand1 = 1] − Pr

rHyb1

1 = 1

≤ negl(λ).

Proof of Proposition B.26. In these games, we use F6=α1km∗ in E6=α1km∗ and Dr
apply the punctured pseudorandomness and immediately obtain the proposition.

(cid:12)
(cid:12)
(cid:12)

h

6=α1km∗. Thus, we can

i(cid:12)
(cid:12)
(cid:12)

Proposition B.27. If iO is a secure IO and Comck is injective, it holds that

Pr

rHyb1

1 = 1

− Pr

rHyb2

1 = 1

≤ negl(λ).

h

(cid:12)
(cid:12)
Proof of Proposition B.27. The diﬀerence between Dcom
(cid:12)
ˆz” or “β = ˆβ”, where ˆz = Comck(0; ˆβ) and ck ← Com.Gen(1λ). Since Com is injective, these two
conditions are equivalent. Therefore, those two circuits are functionally equivalent. We obtain the
proposition by applying the IO security.

6=α1km∗ is whether we use “Comck(0; β) =

6=α1 km∗ and Dr

(cid:3)(cid:12)
(cid:12)
(cid:12)

i

(cid:2)

Proposition B.28. If (Com.Gen, Com) is computationally hiding, it holds that

Pr

rHyb2

1 = 1

− Pr

rHyb3

1 = 1

≤ negl(λ).

(cid:2)
Proof of Proposition B.28. The only diﬀerence between these two games is that ˆz = Comck(0; ˆβ) or
ˆz = Comck(1; ˆβ). Note that ˆβ is never used anywhere else. We can obtain the proposition by the hiding
property of Com.

(cid:2)

(cid:3)

(cid:3)(cid:12)
(cid:12)

(cid:12)
(cid:12)

Proposition B.29. If iO is a secure IO and (Com.Gen, Com) is statistically binding, it holds that
Pr

≤ negl(λ).

rHyb3

rHyb4

− Pr

1 = 1

1 = 1

(cid:3)

(cid:2)

h

i(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
Proof of Proposition B.29. The diﬀerence between DF
(cid:12)
6=α1km∗
is never executed. However, ˆz = Comck(1; ˆβ) is hardwired in Dcom
6=α1km∗, in
particular, condition “Comck(0; β) = ˆz = Comck(1; ˆβ)” is also never true except negligible probability
due to the statistical binding property of Com. That is, these two circuits are functionally equivalent
except negligible probability. We obtain the proposition by applying the IO security.

6=α1km∗ is that the ﬁrst line of DF
6=α1km∗. Thus, the ﬁrst line of Dcom

6=α1km∗ and Dcom

59

Proposition B.30. If iO is a secure IO, it holds that

Pr

rHyb4

1 = 1

− Pr

rHyb5

1 = 1

≤ negl(λ).

(cid:12)
Proof of Proposition B.30. In these games β1 ← {0, 1}9ℓ is uniformly random. By the sparsity of
(cid:12)
(cid:12)
F, β1 is not in the image of F except with negligible probability. Thus, E6=α1km∗ and E6=α1km∗,6=β1
are functionally equivalent except with negligible probability. We obtain the proposition by the IO
security.

(cid:3)(cid:12)
(cid:12)
(cid:12)

h

i

(cid:2)

Proposition B.31. If iO is a secure IO, it holds that

Pr

rHyb5

1 = 1

− Pr

rHyb6

1 = 1

≤ negl(λ).

(cid:2)

(cid:3)
6=α1km∗ in Figure 23 and D4

(cid:12)
Proof of Proposition B.31. The diﬀerence between DF
(cid:12)
is that we replace “If c = x1, outputs ⊥.” with “If β = β1, outputs ⊥.” since the ﬁrst line of DF
6=α1km∗
In these games, β1 ← {0, 1}9ℓ is not in the image of F except with negligible
is never triggered.
probability. Recall that c = x1 means c = α1kβ1kγ1. Thus, those two circuits may diﬀer when
β = β1 but (α, γ) 6= (α1, γ1). However, it does not happen β = F′(αk(G(β) ⊕ γ)) in this case due
to the injectivity of F. Thus, DF
are functionally equivalent and we obtain the
6=α1km∗,6=β1
proposition by applying the IO security.

6=α1km∗ and D4

in Figure 19

6=α1km∗,6=β1

(cid:3)(cid:12)
(cid:12)

(cid:2)

Proposition B.32. If iO is a secure IO, it holds that

Pr

rHyb6

1 = 1

− Pr[Rand2 = 1]

≤ negl(λ).

Proof of Proposition B.32. The diﬀerence between these two games that we use D4
instead of D4
D4

6=α1km∗,6=β1
. We obtain the proposition by the IO security.

[F6=α1km∗, G]. However, G6=β1(β1) is never computed by the ﬁrst line of

6=α1 km∗,6=β1

[F6=α1km∗, G6=β1]

(cid:2)

(cid:3)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

6=α1km∗,6=β1

We complete the proof of Lemma B.25.

B.4 Original Ciphertext Pseudorandomness of PE

We describe the original ciphertext pseudorandomness of PE deﬁned by Cohen et al. [CHN+18] in this
section for reference.

Deﬁnition B.33 (Ciphertext Pseudorandomness). We deﬁne the following experiment Exptcpr
PE.

A (λ) for

1. A sends a message m∗ ∈ {0, 1}ℓp to the challenger.

2. The challenger does the following:

• Generate (ek, dk) ← Gen(1λ)
• Compute encryption c∗ ← Enc(ek, m∗).
• Choose r∗ ← {0, 1}ℓct .
• Generate the punctured key dk/∈{c∗,r∗} ← Puncture(dk, {c∗, r∗})
• Choose coin ← {0, 1} and sends the following to A:

(c∗, r∗, ek, dk/∈{c∗,r∗}) if coin = 0
(r∗, c∗, ek, dk/∈{c∗,r∗}) if coin = 1

3. A outputs coin∗ and the experiment outputs 1 if coin = coin∗; otherwise 0.

We say that PE has ciphertext pseudorandomness if for every QPT adversary A, it holds that

Advcpr

A (λ) := 2 · Pr

Exptcpr

A (λ) = 1

− 1 ≤ negl(λ).

(cid:2)

(cid:3)

60

In the watermarking PRF by Cohen et al. [CHN+18], we use x0 ←
Issue in the proof by Cohen et al.
PE.Enc(pe.ek, akbkcki) to extract an embedded message. They replace x0 ← PE.Enc(pe.ek, akbkcki)
with x1 ← {0, 1}ℓct in their proof of unremovability [CHN+18, Lemma 6.7]. Then, they use PRG
security [CHN+18, Lemma 6.8] to replace PRG(c) with a uniformly random string since the information
about c disappears from the PE ciphertext. However, there is a subtle issue here. The information about
c remains in the punctured decryption key dk/∈{x0,x1} ← Puncture(pe.dk, {x0, x1}), which is punctured
both at x0 and x1, since they use ciphertext pseudorandomness in Deﬁnition B.33 and need to use the
punctured decryption key. Thus, we cannot apply PRG security even after we apply the ciphertext
pseudorandomness in Deﬁnition B.33. This is the reason why we introduce the strong ciphertext
pseudorandomness in Deﬁnition 7.3.

61

