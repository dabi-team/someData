Comparative Review of Cloud Computing Platforms
for Data Science Workﬂows

Mohammad Rehman
School of Computer Science and Applied Mathematics
University of the Witwatersrand
Johannesburg, South Africa
707386@students.wits.ac.za

Hairong Wang
School of Computer Science and Applied Mathematics
University of the Witwatersrand
Johannesburg, South Africa
hairongwng@gmail.com

2
2
0
2

g
u
A
0
3

]

C
D
.
s
c
[

1
v
5
1
5
4
1
.
8
0
2
2
:
v
i
X
r
a

Abstract—With the advantages that cloud computing offers
in terms of platform as a service, software as a service, and
infrastructure as a service, data engineers and data scientists are
able to leverage cloud computing for their ETL/ELT (extract,
transform and load) and ML (machine learning) requirements
and deployments. The proposed framework for the comparative
review of cloud computing platforms for data science workﬂows
uses an amalgamation of the analytical hierarchy process, Saaty’s
fundamental scale of absolute numbers, and a selection of
relevant evaluation criteria (namely: automation, error handling,
fault tolerance, performance quality, unit testing, data encryp-
tion, monitoring, role based access, security, availability, ease of
use, integration and interoperability). The framework enables
users to evaluate criteria pertaining to cloud platforms for data
science workﬂows, and additionally is able to recommend which
cloud platform would be suitable for the user based on the
relative importance of the above criteria. Evaluations of the
criteria are shown to be consistent and thus the weighting of
criteria against the goal of cloud service provider or cloud
platform selection are sensible. The proposed framework is robust
enough to accommodate for changes in criteria and alternatives,
depending on user cloud platform requirements and scope of
cloud platform selection.

Index Terms—Data science workﬂows, analytical hierarchy
process (AHP), evaluation of criteria, cloud platform, cloud
services

I. INTRODUCTION

With an increase in migration to cloud-based extract, transform
and load (ETL) operations, analytics, machine learning (ML)
and reporting solutions, data scientists and analysts need to
become comfortable with moving away from tools such as
Microsoft Excel and on-premises databases for their data
storage and compute requirements, and gain conﬁdence in
storage and compute technology offered by cloud service
providers. Although there are the giants among the cloud
computing service providers (CSPs), for example Microsoft1,
Amazon2 and Google3, consumers can still opt to partner with
many other CSPs such as Alibaba4, Oracle5 and IBM6.

As the migration to cloud platforms is a journey that could

1https://portal.azure.com
2https://aws.amazon.com/console
3https://console.cloud.google.com
4https://home-intl.console.aliyun.com
5https://cloud.oracle.com
6https://cloud.ibm.com

span many months to years, consumers need to be sure that
the services offered by their desired CSP are a good ﬁt for
their requirements, and thus need to know the advantages
and disadvantages of the different CSPs based on factors
such as compute, security, governance, scalability, pricing,
this research has investigated,
availability, etc. Therefore,
evaluated and reviewed the ETL capabilities and the ML
service integration of the cloud platforms offered by three
popular cloud service providers: Microsoft Azure, Amazon
Web Services, and Google Cloud Platform. The analytical
hierarchy process was used to provide a framework for evalu-
ating criteria pertaining to cloud based platforms speciﬁcally
for data science workﬂows, for the use case of cloud service
provider selection. The research shows that consumers can
use multi-criteria decision making methodologies to determine
which cloud provider would be most beneﬁcial for them based
on the relative importance of their requirements.

The following sections in this report delve into the available
literature, followed by an overview of the methodology used
for experimentation and evaluation, and subsequently elaborate
on the results obtained from the experiments while providing
a concise discussion on the implications of the results. Finally,
a conclusion is provided in terms of the overall outcomes of
the research.

II. RELATED WORK

In as early as 2008, Vouk had considered the use of cloud
computing infrastructure for building out effective workﬂows
[1].The importance and need of on-demand as well as reserve-
based provisioning of computational services, automation and
security was highlighted as a measure of effectiveness, and this
is true to-date. Integration of services, appropriate governance
and security, and automation are all critical to having efﬁcient
and effective workﬂows within any cloud computing platform.
C. Chen, J. Chen, J. Liu and Y. Wen have presented the need
for workﬂow scheduling on cloud platforms and how it can be
implemented [2], however, this was based on using external
workﬂow scheduling platforms. Zhou et al. have investigated
this further by incorporating parallelism into cloud-based
workﬂows [3] and have shown that external workﬂow engines
can be used (together with a run-time service) to leverage

 
 
 
 
 
 
parallelism in order to achieve improvements when scaling
workﬂows.

The generally accepted criteria for evaluating cloud plat-
forms and services are: security, performance, accessibility
and useability, scalability, and adaptability [4] which can be
further explored thanks to the consolidation of past evaluations
by Abdel-Basset, Mohamed and Chang [4]. Reference [4]
has additionally provided individuals with a ”neutrosophic
multi-criteria decision analysis” methodology to determine the
quality of service that a cloud provider offers. A method-
ology that has been used in many frameworks that aim to
evaluate various aspects of cloud computing is the analytical
hierarchy process, which aims to decompose multi-criteria
decision problems into hierarchical segments for evaluation
(both qualitatively and quantitatively) [5] [6] [7]. For security
speciﬁcally, Ghazizadeh and Cusack have proposed a ”Trust
Framework” for evaluation of cloud computing technologies
[8]. Additionally,
the National Institute of Standards and
Technology (U.S. Department of Commerce) have developed
the ”Cloud Usability Framework” that enables users to be
informed of what cloud service providers need to adhere to
and ensure is available within their platforms and services [9].
Costa, Santos and Mira da Silva have looked into a signif-
icant number of criteria for the evaluation of cloud services
in general, broadly within the realm of accountability, agility,
management, performance, security and usability [10]. Metrics
for evaluating cloud-based machine learning services were
proposed and reviewed in 2017 [11]. The paper included, but
was not limited to, metrics such as availability, data capacity,
compatibility, documentation, functionality, integration, per-
formance, pricing and usability. In a recent study looking at the
selection of cloud services adequate for big data, the proposed
important criteria were identiﬁed as: architecture, cost, func-
tionality, performance, usability and vendor reputation [12].
In a quality of service evaluation approach study pertaining
to managing cloud service evaluation and selection, a similar
range of criteria were considered, namely: accountability,
agility, assurance, cost, performance and security [13].

III. METHODOLOGY

A qualitative review of criteria pertaining to the top cloud
computing platforms required an in-depth understanding of
the various ETL processes available across the cloud platforms
and thus necessitated the exploration of the services related
to data science workﬂows prior to building out the workﬂows
to gain familiarity with their functionality, governance and
accessibility related capabilities, thus making these the criteria
that were used within the evaluation framework. As such,
each of the cloud computing platforms that were utilised
explored the following capabilities, i.e. their sub-criteria:

Functionality: Automation, error handling, fault tolerance,
performance quality and unit testing
Governance Data encryption, monitoring,
role-based access
Accessibility Availability,

security and

integration,

ease

use,

of

interoperability

A focus was placed on services that enabled data engineer-
ing and analytics in order to remain in scope of the proposed
research. The accessibility criteria were included in order to
supplement the evaluation as a major driver of cloud adoption
is the ability to learn and use the platform relatively easily
to promote its adoption, as well as to have certainty that it is
able to integrate well with applications and tools external to the
platform, thus mitigating vendor lock-in. A similar workﬂow
was developed using the various platforms and the experience
gained while building out the end-to-end workﬂows was used
as a basis for reviewing each of the criteria and sub-criteria
from an entry level data scientist perspective, thus informing
the valuation of each of the attributes within the framework.
The analytical hierarchy process (AHP) was subsequently
used to develop a framework [14] that evaluated the criteria
pertaining to cloud platforms based on the valuations of the
criteria and sub-criteria previously mentioned. In the evalua-
tion process, Saaty’s fundamental scale of absolute numbers
[14] was used to attribute numerical values to linguistic associ-
ations of importance to a pair of relevant attributes. Although
Microsoft Azure, Amazon Web Services and Google Cloud
Platform were used as the cloud platforms in this research,
the actual development of the framework used anonymised
platform providers, i.e. CSP1, CSP2 and CSP3, as the intention
of the research is to ultimately propose a feasible, dynamic
evaluation framework to identify suitable cloud computing
platforms for data science workﬂows rather than to compare
Azure, AWS and GCP in an ofﬁcial and categorical manner.
The context of this research is within the domain of a
multi-criteria decision making problem, where a selection of
alternatives need to be evaluated based on a set of criteria in
order to decide on which alternative is the most favourable for
a requirement. Therefore, the analytical hierarchy process can
be used to develop a framework for decision making pertaining
to the comparative review of a multitude of criteria that pertain
to a set of cloud platforms for data science workﬂows, from
the perspective of an entry level data scientist who has the
goal of deciding which platform would be most suitable for
the user’s data science requirements. The hierarchy tree used
for this research is illustrated in Fig. 1

The analytical hierarchy process was selected as it provides
decision makers with a framework to attribute mathematical
valuations to subjective opinionations pertaining to a set of
criteria in an overall evaluation, thereby enabling users to
mathematically deduce which alternative is most suitable for
the user against a deﬁned goal. It does this by associating
relative measures among a pair of criteria that are relevant
to the user, thus propagating a pairwise matrix of relative
importance for each of the criteria. This can be developed
further by means of using sub-criteria, which provide a
granular numeric representation of importance among the
hierarchy of attributes relevant to the user. As the process is
based on subjective beliefs, aggregated inputs from a myriad
of users is beneﬁcial, especially for important decision making.

TABLE I
GLOBAL SUB-CRITERIA WEIGHTINGS FOR THE ANALYTICAL HIERARCHY
PROCESS

Criteria
Functionality
Functionality
Functionality
Functionality
Functionality
Governance
Governance
Governance
Governance
Accessibility
Accessibility
Accessibility
Accessibility

Sub-criteria
Automation
Error Handling
Fault Tolerance
Performance Quality
Unit Testing
Data Encryption
Monitoring
Security
Role Based Access
Availability
Ease of Use
Integration
Interoperability

Global Weight
0.14
0.07
0.02
0.04
0.28
0.02
0.07
0.01
0.03
0.02
0.17
0.04
0.08

weighting of the alternatives against the goal, similar to how
the sub-criteria were weighed against the goal, as shown in
Table I. Speciﬁcally, this was done by multiplying the weight
of each alternative per sub-criteria to the global weight of the
sub-criteria. As a result, the ﬁnal weighting of the alternatives
were calculated and are demonstrated in Table II:

TABLE II
OVERALL WEIGHTINGS OF ALTERNATIVES AGAINST THE GOAL

CSP1
CSP2
CSP3

Weights
0.28
0.19
0.53

Implications
Suitable for user
Least suitable for the user
Most suitable for the user

The results indicate that based on the relative importance of
criteria and sub-criteria to the user, the experience obtained by
making use of the cloud platform provided by CSP3 would
be most suitable for the data scientist as it has the highest
weighting based on the evaluation of the criteria and sub-
criteria relevant to the tasks needed to be performed on said
platform.

V. DISCUSSION

Within the scope of the research, the attributes selected
were what the data scientist would look for when using the
cloud platforms for data science workﬂows, thus ensuring that
the criteria used to review and evaluate each platform were
suitable. Additionally, as a comparative review was desired,
and not a review to determine the absolute best platform, the
analytical hierarchy process was perfect for achieving this.
Pairwise comparisons were done between criteria and sub-
scriteria to determine the numeric representation of the rela-
tive levels of importance among attributes. As the analytical
hierarchy process has a means of evaluating consistency, the
evaluations made when reviewing the attributes were able to
be tested for any inconsistency and the outcomes for the eval-
uations pertaining to the criteria and sub-criteria were indeed
consistent. Finally, the alternatives were reviewed against each
of the sub-criteria in order to weigh the various alternatives
(cloud platforms provided by the cloud service providers)

Fig. 1. AHP model for determining cloud platform based on data science
workﬂow requirements

IV. EXPERIMENTATION AND RESULTS
The analytical hierarchy process was used to develop a frame-
work for reviewing criteria pertaining to cloud computing
platforms for data science workﬂows. The experimental pro-
cess entailed the construction of ETL pipelines using the
cloud-based ETL platforms of various (anonymised) cloud
service providers to investigate attributes such as automation,
error handling, fault tolerance, performance quality, unit test-
ing, data encryption, monitoring, security, role based access,
availability, ease of use, integration and interoperability. The
attributes were subsequently used to review and evaluate the
ETL platforms relative to one another based on the experience
of an entry level data scientist, to determine which cloud
platform would be the most suitable in terms of selection
for carrying out data science workﬂows. In the evaluation
process, Saaty’s fundamental scale of absolute numbers was
used to attribute numerical values to linguistic associations of
importance to a pair of relevant attributes. This conversion of
linguistic valuation to numeric valuation ensured that matrices
containing the relative importance of criteria and sub-criteria
were able to be constructed, which aided in assigning global
weights to sub-criteria in terms of their overall importance.
Subsequently, a similar approach made it possible to evaluate
each of the cloud platforms relative to one another in order to
determine the platform with the highest overall weighting in
terms of the chosen sub-criteria, thus serving as a recommen-
dation for the platform that would likely be most suitable for
the data scientist.

Once all criteria and sub-criteria evaluations were validated
the weightings of the sub-criteria were
to be consistent,
converted to global weights. This was done by multiplying
the weight of each sub-criteria with the weight of its parent
criteria. Remembering that the sum of weights for criteria, as
well as sub-criteria sets, was equal to 1, the weights can be
treated as percentages, thus the multiplication of sub-criteria
weight and parent weight yields the weighting of a sub-criteria
in terms of the goal of the analytical hierarchy process. As
such, the sum of the global weights is also equal to 1. Table I
illustrates the global weights of each of the sub-criteria:

Having obtained the weights of each alternative against each
sub-criteria ultimately allowed for the calculation of the overall

against the goal. Ultimately, this allowed the framework to
recommend a cloud provider to the user by answering the
question present in the goal of the analytical hierarchy process
with the alternative that yielded the highest weight, which in
the experiment conducted for this research was CSP3.

Evaluation of multi-criteria systems can become quite com-
plex, moreso when the criteria are of a linguistic nature and
are dependent on subjective beliefs. This was an additional
motivation of using the analytical hierarchy process, along
with Saaty’s fundamental scale of absolute numbers, so that
linguistic associations of relative importance between each
of the attributes could be converted to numeric values upon
which mathematical operations could be conducted to produce
weightings of sub-criteria and alternatives against the goal. It
enabled the framework to be both replicable and robust, as the
analytical hierarchy process is a widely known methodology
for multi-criteria decision analysis and thus can be followed to
reproduce the experiments and results obtained in this report.
Additionally, based on how the framework is set up, users can
apply the framework to systems with varying criteria, sub-
criteria and alternatives, depending on their requirements and
accessibility to platforms.

As such, having shown the consistency in evaluation as
well as the ability for the framework to recommend a cloud
service provider, the outcomes of the research efforts have
been positive: a successful framework was developed using
the analytical hierarchy process in order to review, compare
and evaluate criteria pertaining to cloud platforms based on
the required attributes, and to recommend a suitable platform
for a user based on the review and subsequent evaluation of
the attributes, while maintaining conﬁdence in the evaluation
process by means of determining that the evaluations of the
criteria and sub-criteria were consistent.

VI. CONCLUSION

Although a signiﬁcant amount of research has been done
regarding scheduling of data science workﬂows, cloud com-
puting theory, and the comparison of cloud computing plat-
forms in terms of concepts such as performance, pricing and
storage, not much has been done with regards to evaluating or
reviewing cloud based platforms for data science workﬂows
speciﬁcally. Thus research was conducted to understand var-
ious data science workﬂow platforms, the requirements that
a data scientist would have when using such platforms and
the availability of existing frameworks or methodologies that
would enable some one to conduct a comparative review of
cloud platforms for data science workﬂows. Since no such
framework was identiﬁed, a novel framework using the analyt-
ical hierarchy process, Saaty’s fundamental scale of absolute
numbers, and relevant attributes to a data science workﬂow
was created. It was applied to a scenario where a data scientist
needed to select a cloud platform that would be suitable for
the user’s requirements and the framework was successful in
recommending a suitable cloud service provider to the data
scientist.

The beneﬁts of using the analytical hierarchy process were
twofold: the ﬁrst was that a measure, namely consistency,
could be used to ensure that evaluations were done correctly,
and the second was that it enabled the review and evaluations
of criteria pertaining to the cloud platforms (alternatives) to
be done in a relative manner depending on the experience
of an entry level data scientist. In this way, decisive or
categorical proposals of one cloud platform being objectively
better than another could be avoided, with the additional
beneﬁt on users of the framework being able to have their
own alternatives depending on which set of platforms would
be feasible for them (depending on budget, vendor agreements,
brand afﬁliation, etc.).

Overall, a successful framework was created and demon-
strated for the comparative review of cloud computing plat-
forms for data science workﬂows. The evaluations were
deemed consistent and the framework is dynamic enough to
be tailored to user requirements (attributes can be changed as
needed) and platform scope (relevant alternatives to the user’s
circumstances can be chosen).

REFERENCES

[1] M.A. Vouk, “Cloud Computing - issues, research and implementations,”
Journal of Computing and Information Technology, vol. 4, 2008, pp.
235–246.

[2] C. Chen and J. Chen and J. Liu and Y. Wen, “Research on workﬂow
scheduling algorithms the cloud,” , in Process-Aware Systems, 2014,
pp.35–48.

[3] J. Zhou and C. Sun and W. Fu and J. Liu and L. Jia and H. Tan,
“Modeling, design, and implementation of a cloud workﬂow engine
based on Aneka,” Journal of Applied Mathematics, pp. 1–9, 2014.
[4] M. Abdel-Basset and M. Mohamed and V. Chang, “NMCDA: A
framework for evaluating cloud computing services,” Future Generation
Computer Systems, vol. 86, pp. 12–29, 2018.

[5] W. Liao and W. Qiu, “Applying analytic hierarchy process to assess
healthcare-oriented cloud computing service systems,” SpringerPlus, vol.
5, pp. 1–9, 2016.

[6] B. M. R. Wilson and B. Khazaei and L. Hirsch, “Cloud adoption
decision support for SMEs using analytical hierarchy process (AHP),”
SpringerPlus, pp. 1–5, 2016.

[7] N. Chawla and D. Kumar, “Decision-making model to evaluate cloud
computing service nodel using analytic hierarchy process (AHP) and
beneﬁts, costs, opportunities, and risks (BCOR) analysis,” International
Journal of Sensors, Wireless Communications and Control, vol. 10, pp.
846–856, 2020.

[8] E. Ghazizadeh and B. Cusack, “Evaluation theory for characteristics of
cloud identity trust framework,” Cloud Computing - Technology and
Practices, 2019.

[9] B. Stanton and M. Theofanos and K. P. Joshi, “Framework for cloud

usability,” NIST Special Publication, vol. 500, pp. 1–18, 2015.

[10] P. Costa and J. Santos and M. Mira da Silva, “Evaluation criteria for
cloud services,” IEEE International Conference on Cloud Computing,
CLOUD, pp. 598–605, June 2013.

[11] A. Tataru, “Metrics for evaluating machine learning cloud services,” pp.

1–103, 2017.

[12] N. Aﬁﬁ and H. Belhadaoui and I. Hilal and F.E. Mdarbi, “An approach
for selecting cloud service adequate to big data,” International Journal of
Computer Science and Information Security, vol. 16, pp. 20–32, 2018.
[13] N. Uphadyay, “Managing cloud service evaluation and selection,” Pro-

cedia Computer Science, vol. 122, pp. 1061–1068, 2008.

[14] T.L. Saaty, “Decision making with the analytical hierarchy process,”
International Journal of Services Sciences, vol. 1, pp. 83–98, 2008.

