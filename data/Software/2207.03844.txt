2
2
0
2

l
u
J

8

]

C
O
.
h
t
a
m

[

1
v
4
4
8
3
0
.
7
0
2
2
:
v
i
X
r
a

On data-driven chance constraint learning for mixed-integer
optimization problems

Antonio Alcántaraa,∗, Carlos Ruiza,b

aDepartment of Statistics, University Carlos III of Madrid, Avda. de la Universidad,
30, Leganés, 28911, Madrid, Spain
bUC3M-BS Institute for Financial Big Data (IFiBiD), University Carlos III of Madrid, Avda. de la
Universidad, 30, Leganés, 28911, Madrid, Spain

Abstract

When dealing with real-world optimization problems, decision-makers usually face high
levels of uncertainty associated with partial information, unknown parameters, or com-
plex relationships between these and the problem decision variables. In this work, we
develop a novel Chance Constraint Learning (CCL) methodology with a focus on mixed-
integer linear optimization problems which combines ideas from the chance constraint
and constraint learning literature. Chance constraints set a probabilistic conﬁdence
level for a single or a set of constraints to be fulﬁlled, whereas the constraint learning
methodology aims to model the functional relationship between the problem variables
through predictive models. One of the main issues when establishing a learned con-
straint arises when we need to set further bounds for its response variable: the fulﬁllment
of these is directly related to the accuracy of the predictive model and its probabilistic
behaviour. In this sense, CCL makes use of linearizable machine learning models to
estimate conditional quantiles of the learned variables, providing a data-driven solu-
tion for chance constraints. An open-access software has been developed to be used
by practitioners. Furthermore, beneﬁts from CCL have been tested in two real-world
case studies, proving how robustness is added to optimal solutions when probabilistic
bounds are set for learned constraints.
Keywords: Chance constraint, Constraint learning, Data-driven optimization,
Quantile estimation, Machine learning

∗Corresponding author
Email addresses: antalcan@est-econ.uc3m.es (Antonio Alcántara),

caruizm@est-econ.uc3m.es (Carlos Ruiz)

Preprint submitted to Elsevier

July 11, 2022

 
 
 
 
 
 
1. Introduction

Recent digitization and automation within our society have not only brought big
amounts of data available for decision-makers, but also high levels of uncertainty inher-
ent to the information. From assessing climate change to dealing with the evolution of
a pandemic [1], decision-makers have to set optimal solutions in an environment full of
uncertainty.

In the operations research ﬁeld, there exist certain standard approaches that are
typically employed to solve problems where uncertainty and/or big amounts of external
data are present. In particular, one of the most employed ones is stochastic program-
ming, where the optimization model incorporates the estimated probability distribution
of the uncertain parameters [2]. In particular, stochastic programming considers the
following problem:

min
x∈X
s.t.

E [c(x; ξ)]

g(x; ξ) ≤ 0

(1a)

(1b)

where x ∈ X ⊂ Rdx represents the decision variables, ξ is a random vector valued in
Rdξ, c(x; ξ) : Rdx × Rdξ → R is the cost function, g(x; ξ) : Rdx × Rds → Rdg are the
constraints, and E [·] represents the expected value over the cost function.

Some recent works have focused on upgraded versions of (1) that leverage the inclu-
sion of external information and predictive models within the problem-solving method-
ology. From the classical “Predict and Optimize” strategy, researchers have moved on to
frameworks where prediction and prescriptions intersect. For example, in [3], authors
address an integrated approach to ﬁnd functions f to model other decision variables
y inﬂuenced by the uncertainty ξ that also generate good prescriptions. The so-called
Predictive to Prescriptive two-step approach is proposed in [4] to manage the trade-oﬀ
between prediction and prescription performance.

An alternative for dealing with uncertainty is the employment of robust optimization
methodologies [5]. Some examples of robust optimization rely on renewable-energy
integration in microgrids [6], dealing with risks and improving the sustainability of
supply chains [7, 8], or establishing robust R&D budget allocation [9]. Historically, one
of the most employed approaches in the literature has been Wald’s maximin model for
non-probabilistic robust optimization problems. A simple model is presented in (2),
where ξ is a random vector valued in Rdξ, that this time is contained in the uncertainty
set U(x).

max
x∈X

min
ξ∈U (x)

c(x; ξ)

2

(2a)

s.t.

g(x; ξ) ≤ 0

(2b)

The adequate modelling of the uncertainty set U(x) has been a major research
problem for the last years.
In particular, data-driven uncertainty sets may allow us
to obtain probabilistic guarantees associated with the optimal solutions to our robust
optimization problems [10]. Several well-known uncertainty sets have been explored
[5]. For example, a Markov set contains all distributions perfectly deﬁned by its mean
and support. In a Chebyshev set, distributions are presented with bounds on the ﬁrst
and second-order moments, whereas in a Huber set all contained distributions present
a known upper bound on the expected Huber loss function.

Finally, some applications need to explicitly model and limit the uncertainty asso-
ciated with the satisfaction of a single or a set of constraints by using probabilities [11].
This is the main approach we will address in this work, the so-called chance constraint
approach. We will start by introducing the general formulation of a chance-constrained
optimization problem (3). For a ﬁxed safety probability level α ∈ (0, 1), we can replace
constraint (1b) by:

P (g(x; ξ) ≤ 0) ≥ α

(3)

Chance constraint (3) imposes that g(x; ξ) ≤ 0 will be satisﬁed with a probability
not below α. Traditionally, one approach for addressing chance constraints has been
scenario generation. Therefore, the real (or estimated) probability distribution of the
uncertain parameters is discretized, and scenarios are generated from this discretization.
Then, the big-M approach is used jointly with binary variables to check and assert that
at least α% of the binary variables are set to one. This approach is also known as
Sample Average Approximation (SAA) [12]. One of the main disadvantages of this
proposal is the computational cost increment due to the addition of binary variables
for each scenario.

However, chance constraint (3) can also be written equivalently as follows:

Qα(g(x; ξ)) ≤ 0

(4)

where Qα(·) represents the quantile function associated with probability α. This in-
dicates that α × 100% of the values of a random variable will lay under the value of
this quantile. Qα(·) is also considered in the literature as the Value-at-Risk (VaR) for
a certain random variable at probability level α.

We can also ﬁnd in the literature a related approach that employs the buﬀered

failure probability method [13] to transform (3) into:

Qα(g(x; ξ)) ≤ 0

3

(5)

where Qα
represents the superquantile function associated with probability α, also
known as the Conditional-Value-at-Risk (CVaR). This superquantile function can be
simply described as the expectation of the (1 − α)-tail distribution for a random vari-
able. Regarding its relationship with the quantile function, the superquantile can be
deﬁned as the mean value of the area not covered under the quantile associated with
the same probability α, that is the right tail of the distribution. Mathematically, the
superquantile function is deﬁned as:

Qα(·) =

1
1 − α

(cid:90) 1

α

Qα(cid:48)(·)dα(cid:48)

for α ∈ (0, 1)

(6)

The superquantile formulation can also be adapted to the left tail of the distribution,
i.e, Q1−α(·). This representation of the CVaR is useful when referring to proﬁts, whereas
the right-tail formulation is often used regarding costs. Generally, we will always refer
to the superquantile as Qα(·), by specifying the side of the tail we are dealing with.

It can be noticed how replacing (3) with either (4) or (5) is not equivalent, as the
employment of the superquantile function gives an extra region of safety, and therefore
makes this approach more conservative. However, the superquantile approach, apart
from rendering a coherent risk measure, is simpler to implement numerically within
optimization problems by using the key result by using the linear formulation proposed
by [14].

As can be seen, this approach has been presented under a stylized context. However,
real-world optimization models can present several casuistries that are not directly taken
into account in this formulation. For example, from a data-driven perspective, we can
beneﬁt from the amount of available information by ﬁtting predictive models to output
a direct quantile estimation, getting rid of the conservativeness from the buﬀered failure
probability method. Furthermore, in real complex optimization problems, the decision-
maker may not have a direct decision capacity over a certain optimization variable y,
but there may exist a direct dependency with another decision variable x, which can
be explicitly modelled. This process is called constraint learning, a topic that is getting
attention in the literature lately. For example, in [15], ensembles of decision trees are
employed to learn a probabilistic description of a constraint, whereas in [16] stability
power system constraints are learned employing neural networks.

In this work, we propose an extension of the constraint learning methodology in
order to consider chance constraints, which can also be useful to tackle the inherent
uncertainty of point predictive models.

Now suppose we set the optimization model (7). This model aims to minimize
an objective cost function c(x, y|θ, ξ) : Rdx → R, which mainly depends on decision
variables x ⊂ Rdx, y ⊂ Rdy , but at the same time it is conditioned by external contextual

4

information θ ⊂ Rdθ and uncertainty ξ ⊂ Rdξ.

E [c(x, y|θ; ξ)]

min
x,y
s.t.

g(x, y|θ; ξ) ≤ 0
y = f D(x|θ; ξ)
y ≤ k

(7a)

(7b)

(7c)
(7d)

Whereas x represents an accessible, straight-forward decision variable, the nature of
the other decision variable y makes it a learned variable. This means that the value set
for y is conditioned by the decision we take over x and the contextual information θ. In
some contexts, the relationship between x, y, and θ can be learned through a selected
. This
predictive model f D, which is trained employing a dataset D = {xi, yi, θi}N
i=1
process is called “constraint learning” [17], and it is represented by (7c). Furthermore,
lets assume that the real-world application requires that an additional restriction has
to be imposed over the learned decision variable y in (7d). In this case it is an upper
bound constraint, but it can be a lower bound constraint or any other one included
within (7b) without loss of generality. These constraints conform the feasible region for
x and y, i.e., S(θ; ξ).

However, the bound constraint (7d) and its fulﬁllment is directly related to the
chosen predictive model f D, how good the training process was, and how accurate the
prediction for y is. From an statistical point of view, lets suppose the new prediction
In this case, if we
for y, i.e., ˆy, follows a estimated Normal distribution N (k, σy).
employ the point prediction of ˆy, the optimization problem will consider constraint
(7d) fulﬁlled, as the predictive model will set the value of y equal to k. Nevertheless,
from a stochastic point of view and taking into account the inherent uncertainty of the
predictive model, the bound constraint will not be fulﬁlled in half of the realizations of
y due to its statistical distribution.

To solve the exposed issues, a Chance Constraint Learning methodology (CCL) for
mixed-integer optimization (MIO) problems is developed. The main contributions of
this work are four-fold:

– to develop a complete data-driven CCL framework, allowing practitioners to train
several machine learning models employing their own data, and generate linear
constraints to be embedded in their MIO problems.

– to extend the standard constraint learning methodology by including chance con-
straints, and quantile and superquantile estimation methods in order to add ro-
bustness to learned decision variables.

5

– to address chance constraints with a direct data-driven functional approach, which
avoids using scenario generation and auxiliary binary variables, like SAA-based
techniques.

– to show the validity of the developed framework in two realistic case studies that
verify the good probabilistic performance of the optimal solutions obtained by
CCL.

– to provide practitioners with an open-access software named “CCL_tool”, devel-
oped in Python which allows them to implement CCL within their optimization
models.

The structure of this article is as follows. Section 2 describes the proposed method-
ology in detail, from the conceptual model developed based on linearizable quantile
estimation machine learning models to extensions related to superquantiles. Section 3
explains the functioning of the open-access software developed. Sections 4.1 and 4.2
test our methodology in two real-world case studies. Finally, Section 5 draws the main
conclusions of this work.

2. Chance Constraint Learning Methodology

2.1. Conceptual model

We propose an extension of the bound constraint for a learned variable to add
probabilistic guarantees. In model (8), the bound constraint (7d) has been replaced by
a probabilistic chance constraint (8d), i.e., we seek for the probability of y being lower
or equal than k to be greater than a conﬁdence level α.

E [c(x|θ; ξ)]

min
x,y
s.t.

g(x, y, θ; ξ) ≤ 0
y = f D(x, θ; ξ)
P(y ≤ k) ≥ α

(8a)

(8b)

(8c)
(8d)

For jointly addressing constraints (8c) and (8d), we propose a simple but eﬀective
change over the predictive function f D in model (9) that will allow to tackle the inherit
uncertainty of the point prediction and increase the robustness of the solutions of the
optimization problem. The resulting CCL framework is as follows:

E [c(x|θ; ξ)]

min
x,y

6

(9a)

s.t.

g(x, y|θ; ξ) ≤ 0
Qy
α (x|θ; ξ)
Qy

α = f D
α ≥ k

(9b)

(9c)
(9d)

can be trained to output an speciﬁc conditional quantile of the
As can be seen, f D
α
decision variable y: Qy
to be equal or greater than k makes
. Restricting the value of Qy
α
α
constraints (9c) and (9d) equivalent to (8c) and (8d). The feasibility of constraint (9d)
is then achieved by deciding over decision variable x, as it has a direct implication
in the value of y. Although (9c)-(9d) can be viewed as a deterministic counterpart
of (8c)-(8d), we maintain the expectation in (9a) to acknowledge that there might be
other sources of uncertainty in our model, e.g., uncertain parameters in the objective
function and/or in the constraints.

Furthermore, despite conditional quantiles being estimated, this framework can be
extended to work with superquantiles, a measure that keeps coherent risk-measures
properties. CCL is a ﬂexible framework, that can be employed to tackle uncertainty and
give robustness to learned variables by changing point predictive methods by quantile
estimation methods, as well as for eﬀective integration in optimization problems where
chance constraints are needed due to real-world requirements.

2.2. Linearizable quantile estimation methods

Whereas the training of classical point regression methods is based on the minimiza-
tion of a loss derived from the diﬀerence between the point prediction and the actual
value of the dependent variable y (mean squared error, the sum of squared errors, etc.),
quantile estimation methods are set by minimizing the so-called quantile loss [18].

In particular, the α-quantile loss Lα(u) is deﬁned in (10), with u representing the

residual y − Qy
α

.

Lα(u) =

(cid:40)

αu,
u ≥ 0
(α − 1)u, u < 0

(10)

As we can see, this loss is not unique but dependent on the speciﬁc estimated α-
quantile (there will be a loss value for every α). When estimating quantiles for a value
of α bigger than 0.5, (10) penalizes the case when the quantile is under y at a greater
extent than in the opposite case. On the other side, when α is smaller than 0.5, being
over y brings a bigger penalization.

Employing dataset D = {xi, yi, θi}N
i=1

, the actual value of the α-quantile loss Lα(D)
is computed by averaging loss values over the complete dataset, as in (11). The mini-

7

mization of Lα(D) is the main pillar of state-of-art quantile estimation methods.

Lα(D) =

1
N

N
(cid:88)

i=1

Lα(yi − Qyi
α )

(11)

What follows is an introduction to several quantile estimation methods whose struc-
ture is relatively easy to linearize with or without binary variables. This linearization
will be critical for embedding these methods as f D
α (·) within mixed-integer linear op-
timization versions of the problems like (9), and therefore be a participant in a CCL
framework.

2.2.1. Linear Quantile Regression

One of the simplest approaches is to ﬁt a linear model to estimate the conditional
quantile Qy
. This model is called Linear Quantile Regression (LQR) and it is based
α
on ﬁnding the set of coeﬃcients β that minimizes the α-quantile loss [19]. In this way,
LQR outputs Qy
as a function of the decision variables x and contextual information
α
θ.

α = β0 + βxx + βθθ
As can be seen, LQR is a method easy to embed within the optimization problem as
(9c), allowing also the sensibility and interpretability analysis of the dependent variable
with respect to the independent ones.

Qy

(12)

2.2.2. Support Vector Quantile Regression

Support Vector Machine (SVM) is a machine learning method based on hyper-plane
cutting in order to generate point predictions or classiﬁcations [20]. However, the SVM
methodology can be adapted by employing the α-quantile loss as the minimization
target, taking the name of Support Vector Quantile Regression (SVQR).

We focus on the linear version of SVQR, which makes this model easy to embed in
our CCL framework. Linear SVQR is trained in the same way as the exposed LQR,
but only penalizes residuals greater than a certain threshold (cid:15). After the training is
completed, the embedding of the Qy
estimated by the linear SVQR model is done like
α
in LQR (12), i.e., as a linear combination of coeﬃcients β and the decision variables x
and contextual information θ.

2.2.3. Quantile Regression Tree

A decision tree is a non-linear prediction model based on the creation of sample
partitions in diﬀerent nodes or leaves reached by speciﬁc restrictions, and posterior
computations to generate predictions. These partitions are made to minimize an error

8

measure. One of the most popular tree-based algorithms is CART (Classiﬁcation And
Regression Tree), ﬁrstly introduced in [21].

Generally, in order to generate a point prediction for a new observation, we follow
the tree structure until reaching a certain ﬁnal leaf. In this leaf, we compute the mean
of the dependent variable from the training data samples. This average is assigned to
the new observation as a prediction.

.

However, in the CCL methodology, we focus on predicting conditional quantiles in
order to model chance constraints. A simple but eﬀective extension regarding regression
trees was proposed in [22]. Basically, instead of computing one average over the data
samples in the ﬁnal leaf, we keep all the observations. With these observations, we can
empirically compute every estimated conditional quantile for the dependent variable,
i.e., Qy
α

Figure 1 shows the typical structure of a decision tree (in this case a tree of depth
2). As can be seen, to make a prediction, we move down the tree following the path
created by some restrictions. When we arrive at a ﬁnal node (a leaf), we can ﬁnd the
training data distribution. For example, for an observation x to be assigned to the
2 x ≤ b2} must be true. In point
fourth node, the set of inequalities N4 : {AT
prediction, we would compute an average to get the expected value of the prediction
when a leaf node is reached. Nevertheless, under the CCL framework, we can actually
compute the empirical quantile, or even the superquantile as the average of the samples
greater than the quantile (or below it without loss of generality).

1 x ≤ b1, AT

In order to embed a tree-based prediction model in a mixed-integer optimization
problem, we have to write these restriction linearly to obtain an equivalent set of con-
straints. For that purpose, we follow the formulation proposed in [23] with a slight
modiﬁcation to include quantile estimation. Thus, considering the tree in Figure 1, the
leaf assignment encoding for an observation x is described as:

AT
AT
AT
−AT
−AT
AT
−AT
−AT

1 x − M (1 − u4) ≤ b1
2 x − M (1 − u4) ≤ b2
1 x − M (1 − u5) ≤ b1
2 x − M (1 − u5) ≤ −b2 − (cid:15)
1 x − M (1 − u6) ≤ −b1 − (cid:15)
3 x − M (1 − u6) ≤ b3
1 x − M (1 − u7) ≤ −b1 − (cid:15)
3 x − M (1 − u7) ≤ −b3 − (cid:15)

u4 + u5 + u6 + u7 = 1

9

(13a)

(13b)

(13c)

(13d)

(13e)

(13f)

(13g)

(13h)
(13i)

Figure 1: Decision tree regression structure.

y − (qα

4 u4 + qα

5 u5 + qα

6 u6 + qα

7 u7) = 0

(13j)

where ui represent a binary variable for the corresponding leaf i, (cid:15) a small parameter
to remove strict inequalities, and M a suﬃciently large constant (big-M approach).

1 x ≤ b1, constraints (13e) and (13g) will force u6 and u7 to be zero.
For x, if AT
2 x ≤ b2, constraint (13d) will assign u5 a value of zero. Finally,
Furthermore, if AT
constraint (13i) will force u4 to be one, assigning to y (13j) the value of the predicted
quantile qα
4

(the quantile in leaf 4).

2.2.4. Tree-based quantile ensemble methods

An ensemble is a machine learning method based on generating predictions from
multiple independent base simple models. In this section, we will focus on two ensemble
methods based on quantile regression trees: Quantile Regression Forest (QRF) and
Gradient Boosting Quantile Regression (GBQR).

QRF [22] is a method closely related to randomization, as data and features are
bootstrapped to grow the quantile regression tree that can be chosen also randomly.
Typically, QRF generates a new prediction by averaging over the prediction of each base
t∈T Qyi
, where T represents the number of quantile regression
model, i.e., Qyi
α = 1
α,t
T
trees conforming the ensemble.

(cid:80)

The functioning of each tree is the same as the one exposed in Section 2.2.3. There-
fore, in order to embed QRF in a MIO problem, we have to embed each tree one by one,

10

while adding a ﬁnal constraint to generate a ﬁnal quantile estimation as the average of
all the estimations from the base models.

GBQR is an extension from the gradient boosting (GB) methodology proposed in
[24]. GB aims to improve the performance of a weak base model (“to boost”) by training
a new ensemble member with a modiﬁed dataset, i.e., with the residuals from the pre-
vious base model instead of the original dependent variable. GB can be implemented
with any regression method as a base learner, although it is mostly used within regres-
sion trees in the literature. To achieve a conditional quantile estimation, tree-based
models of the ensemble are grown making use of the quantile loss (10), taking the name
of GBQR.

2.2.5. Quantile Regression Neural Networks

Neural Networks (NNs) are powerful and ﬂexible techniques employed to a great
extent in the current machine learning and artiﬁcial intelligent state-of-art [25]. NNs
are composed of one input layer, L − 2 hidden layers, and one ﬁnal output layer. Each
layer can be composed of several nodes or neurons that perform computations regarding
weights and biases.

In a given hidden layer l of the NN, with nodes N l, the value of a node i ∈ N l,
, is calculated using the weighted sum of the previous layer’s node values,

denoted as vl
i
followed by a non-linear activation function g(·). This value is given as:


bl

i +

vl
i = g



wl

ijvl−1
j



(cid:88)

j∈N l−1

represents the bias term, and wl
ij

the weights or coeﬃcients for node i in layer
where bl
i
l. This process will continue in the following layers, taking as inputs the outputs of the
previous layers, until reaching the ﬁnal one.

Recent works [26, 27] have studied rectiﬁed linear unit (ReLU)-based NNs as a MIO-
representable class of neural networks, and therefore, adequate for the CCL framework.
Taking the previous example, if g(·) represents the ReLU activation function, the output
from node i in layer l is computed as:

0, bl

vl
i = max

ijvl−1
j

i +

(cid:88)

wl





The training process of this NN can be focused on minimizing the α-quantile loss
. This approach is de-
in order to output the corresponding conditional quantile Qyi
α
noted as Quantile Regression Neural Networks (QRNN). Thus, constraints for the CCL

j∈N l−1

11

framework can be generated in a recursive procedure from the input layer to the output
layer. This ﬁnal layer L will consist in an unique neuron which, by means of a linear
combination of values obtained in layer L − 1, will output Qy
α

as follows:

Qy

α = bL +

(cid:88)

wL

j vL−1
j

j∈N L−1

We can anticipate that the complexity and the number of constraints will grow
exponentially using QRNNs instead of linear models such as LQR or linear SVQR.
Furthermore, as the number of layers increases, the explainability of the model will
decrease, transforming QRNN into a “black-box” model. However, if we focus on pre-
diction accuracy, the use of NNs gives a better performance than the use of linear
models in many relevant applications.

2.3. Empirical superquantile estimation

As it has been mentioned in Section 1, the main advantage of using estimated
empirical quantiles (VaR) to deal with probabilistic constraints is getting rid of the
extra buﬀered probability associated with the superquantile (CVaR). However, CVaR
possesses some modelling advantages as it is a coherent risk measure.

Thus, we propose an extension of the CCL methodology in order to employ su-
perquantiles, so that the decision-maker has the option to choose between VaR and
CVaR regarding its preferences for risk modelling.

This derivation is based on Mixed Quantile Regression (14), a methodology proposed

in [28] and [29]. In particular, for linear problems:

Q

(14)

yi
α = CVaRα[y|x, θ] = β(x, θ)
This implies that for an empirical approximation of the superquantile we can use
(cid:80)M
which is based on the discretization of the probability distribution of y em-
j=1 wjQyi
αj
ploying M diﬀerent quantiles (or VaRs). Results from [30] show that, for heteroscedastic
datasets, β = (cid:80)M
j=1 wjβj. This means that coeﬃcients for a CVaR-based model can
be obtained by means of a linear combination of coeﬃcients from M diﬀerent linear
quantile models. Extensions for homocedastic datasets can be found in the same work.
Moreover, to determine the values of weights wj as well as the quantiles employed
for modelling the CVaR, a midpoint quadrature rule can be used. In this way, with
∆ = J −1(1 − α), we have wj = (1 − α)−1∆ and αj = α + (j − 0.5)∆, j = 1, . . . , J as
the weighs and VaRs to employ, when dealing with the right tail of the distribution. In
the case of a CVaR referring to the left side of the distribution, we can use ∆ = J −1α,
and wj = α−1∆ and αj = α − (j − 0.5)∆, j = 1, . . . , J as the weighs and quantiles,
respectively.

12

However, the above procedure can not be extended to the case of tree-based pre-
diction models. In this case, there are no coeﬃcients β available, but data partitions
in leaf nodes. For that reason, we propose to empirically compute the superquantile
from the data distribution presented in leaf nodes. Taking as an example Figure 1,
we can see how, from the data distribution of leaf node 7, the empirical quantile can
be computed. From that, the superquantile is calculated as the mean value from the
observations greater than the quantile (in the case of a right tail CVaR). To give ro-
bustness to the estimation, there must be enough observations in the leaf. Therefore,
we should control the minimum number of samples within leaves as a hyper-parameter
of our tree-based models. This approximation can be employed for decision trees and
ensembles such as QRF.

j=1 wjQy
αj

α = (cid:80)M

Finally, for QRNNs, although there are coeﬃcients β associated with each neuron,
the methodology proposed in [30] cannot be applied when we include several layers
and neurons, as we turn the model into a non-linear one. Thus, we propose to directly
compute the conditional superquantile as the weighted sum of estimated quantiles,
y
. For instance, we can make use of the same weights values
i.e., Q
and quantiles of the midpoint quadrature rule. Furthermore, we can accelerate the
training process and ﬁt one unique QRNN that outputs the J seek quantiles in the
ﬁnal layer, instead of one NN for each quantile.
In this way, all the quantiles from
the NN will share all of the coeﬃcients except those from the ﬁnal layer. However,
obtaining multiple quantile outputs in a single NN can bring up the well-known issue of
quantile crossing, that is, the resulting distribution function may not be monotonically
increasing. To ensure that the resulting QRNN solves this issue, we add a penalty term
in case of quantile crossing to the quantile loss during the training phase [31].

As can be seen, there is not a well-deﬁned homogeneous methodology for computing
the superquantile regardless of the prediction model. However, we believe that the
proposed methodologies that numerically estimate the CVaR can be of great interest to
practitioners working on real-world problems. These proposals are validated empirically
in Sections 4.1 and 4.2.

3. CCL software development

In this section, we introduce the software developed in order to implement the chance

constraint learning methodology.

The “CCL_tool” has been fully developed in Python, and it is completely open
access for practitioners in [32]. This tool is Scikit-learn [33] and Pytorch [34] based for
ﬁtting diﬀerent machine learning models, while also extending some code from [35] for
embedding predictive models within MIO problems modeled in Pyomo [36].

13

Its functioning is deﬁned by four steps. First, an initialization where the learning
methodology and prediction model are selected by the user. Then, a training process
where, from a dataset, we ﬁt the predictive model. Later, once the model is trained, we
generate the learned constraints from the predictive model and ﬁnally, these constraints
are embedded in a MIO problem. A summary of this structure is sketched in Figure 2.

Figure 2: Chance constraint learning tool structure

In the initialization phase, we choose a methodology between point, quantile, or
superquantile estimation. That is, with point estimation we want a model to estimate
the expected value of the learned variable (with this variable having a possible bound).
However, if quantile or superquantile estimation is chosen, we deﬁne a CCL problem,
i.e., we want our learned variable to be greater or lower than a value with a certain
probability. In this case, we will have to select the conﬁdence level α, and the number of
quantiles to approximate the superquantile depending on the method (see Section 2.3).
Regarding the predictive models, linear regression, tree models, random forest, and
(deep) neural networks are available for both point, quantile, and superquantile estima-
tion. Only GB is not available for superquantile estimation as it is being developed from
scratch, and SVM for (super)quantile estimation, as there is no Python-based package
for SVM quantile estimation with linear kernel. We suggest practitioners interested in
SVM train models in R and embed the model as linear regression.

14

When we enter the training step, a dataset D = {xi, yi, θi}N
i=1

is required, with x rep-
resenting past decisions, y being the learned variable, and θ the contextual information.
In this way, the tool will split the dataset into a training and validation subset to select
the best hyper-parameter setting for the predictive model. For example, the number
of trees, the maximum depth, or the minimum number of samples in leaf for Random
Forest. This selection is the one that minimizes the validation error, for example, the
MAE for point estimation and the α-quantile loss (11) for quantile and superquantile
estimation.

Once the model is ﬁtted, constraints are generated as exposed in Section 2.2 de-
pending on the selection of the predictive model. These constraints are ﬁnally added
to our MIO problem.

Therefore, a fully data-driven CCL methodology is developed, where practitioners
can ﬁnd optimal solutions to their decision-making problems under uncertainty by using
high-level machine learning models and information while solving chance constraints
and hedging the risk associated with the value of a non-accessible decision variable: the
learned constraint.

4. Case Studies

In this section, we empirically validate the proposed CCL methodology in two re-
alistic frameworks. For clarity, in these case studies, no contextual information θ is
employed to build the learned constraints. However, we can easily deal with this exten-
sion in the “CCL_tool”, in particular, by setting θ as decision variables within vector
x, and then by ﬁxing their values in the MIO problem to the observed ones.

4.1. Case study I: concrete compressive strength

In this case study, we develop an optimization problem based on the very well know
“concrete” dataset, ﬁrst time published in [37]. This dataset contains information about
concrete compressive strength (dependent variable) measured in megapascals (MPa),
along with values from the concrete components and age (independent and decision
variables).

Establishing the relationship between the compressive strength and its components
through a linearizable prediction model will allow us to embed this learned variable into
mixed-integer optimization problems like the one we propose. During the development
of this case study, we will focus on the diﬀerent realizations the decision variables take
depending on the constraint learning methodology. That is, we study the decision-maker
behaviour from the (point) constraint learning and the chance constraint learning (using
both quantiles and superquantiles) perspectives.

15

4.1.1. Optimization problem

The optimization problem will be based on minimizing concrete production costs
while ensuring a predeﬁned compressive strength level. We assume the producer has
complete ﬂexibility to decide when to produce, and the production cost to be measured
in kg/m3, to preserve the nature of the dataset, as it will be detailed later.

First, we deﬁne the following notation for the problem:

Indices and sets:

– I: Set of concrete components, indexed by i.

Variables:

– xi: Quantity of concrete component i, measured in kilograms, employed for pro-

ducing one m3.

– d: Age of strength testing (in days).

– ystrg: Concrete compressive strength, measured in MPa.

Parameters:

– ci: Cost in euros for concrete component i, per kilogram.

– weight and weight: Lower and upper bound for the total component weight used

in the concrete production, respectively.

– k: Concrete compressive strength lower bound.

– α: Probability conﬁdence level.

The formulation of the chance constrained optimization problem is presented below:

min
x,ystrg,d

(cid:88)

i∈I

cixi

s.t.

ystrg = f D(x, d)
P(ystrg ≥ k) ≥ α
weight ≤

(cid:88)

xi ≤ weight

i∈I

16

(15a)

(15b)
(15c)

(15d)

The objective function of this problem (15a) aims to minimize the production costs.
The producer will have to decide how much quantity of each component xi add to the
mixture in order to produce one m3 of concrete. Furthermore, he must decide when to
produce, as the compressive strength is dependent on the age of the concrete.

Constraint (15b) is the so-called “learned constraint”, which deﬁnes the “learned
decision variable”: the compressive strength for a speciﬁc concrete mixture, ystrg. We
can see how this strength is dependent of the components x and the age of the concrete
d. This relationship will be established through a predictive function f D, trained using
a dataset D, and embedded within the optimization problem. Next, constraint (15c)
deﬁnes a chance constraint. The producer wants its concrete to have a compressive
strength ystrg at least equal to a deﬁned value k, with a certain probability α. Notice
how both constraints (15b) and (15c) create a CCL framework together.

Finally, constraint (15d) ensures that the weight of the concrete components is

between a lower and upper bound.

4.1.2. Methodology

As it has been mentioned before, the well-known “concrete” dataset will be employed
in this problem. Table 1 indicates the variables presented in this dataset composed by
1030 samples. We can see how all the components are measured in kg/m3, so that we
assume orders are made in m3.

Table 1: Set of variables employed for the concrete compressive strength problem.

Type of variable
Dependent

Independent

Name

Units

Compressive strength Mpa
Cement
Blast Furnace Slag
Fly Ash
Water
Superplasticizer
Coarse Aggregate
Fine Aggregate
Age

kg/m3
kg/m3
kg/m3
kg/m3
kg/m3
kg/m3
kg/m3
Days

The next information needed for the optimization problem are the costs associated
with each concrete component. This information is not provided in the original dataset,
so we assume the producer to have the costs presented in Table 2.

Regarding the predictive task to illustrate the CCL methodology, Random Forest
(RF) will be employed as the predictive model to relate compressive strength and

17

Table 2: Concrete components costs

Component
Cement
Blast Furnace Slag
Fly Ash
Water
Superplasticizer
Coarse Aggregate
Fine Aggregate

Cost [e/kg]
0.050
0.040
0.045
0.002
1.800
0.020
0.020

concrete components. Concerning the diﬀerent methodologies, point estimation will
be employed to ensure a compressive strength bigger than 45 Mpa without taking
into account the probability of chance constraints. On the other side, quantile and
superquantile estimation methodology will be employed under the CCL framework to
ensure compressive strength to be bigger than 45 Mpa with a probability bigger than
95%. This means that, as a lower bound restriction is presented in the problem, we
need to model a quantile and superquantile at 5% (1−α) level and force it to be greater
than 45 Mpa. Then, the RF will estimate the conditional quantile (or superquantile)
at level 5%.

Finally, the lower and upper bounds, weight and weight for the component weights
in the mixture will be 2230 kg and 2450 kg, respectively (chosen as the ﬁfth and ninety-
ﬁfth quantile of the component weight in the dataset).

4.1.3. Results

The optimal concrete components mixture problem has been solved through a
Python 3.9.12 implementation, using Pyomo 6.3 [36]. The selected mathematical solver
for all the computations was Gurobi [38] in its version 9.5. Besides, the computer em-
ployed included a CPU Intel Core i7 10700, RAM of 64 GB, and NVIDIA GeForce
GTX 2060 graphic card. As we mentioned before, the optimal solution will be obtained
for the three diﬀerent exposed methodologies: point estimation, quantile estimation,
and superquantile estimation methodology.

Table 3 shows the optimal concrete mixture for ensuring a compressive strength
depending on the selected methodology when choosing RF as the predictive model. As
can be seen, the cement quantity increases as we move to more restrictive methodologies
to ensure compressive strength. The opposite occurs with the quantity of water and
coarse aggregate.
It is interesting to notice the null use of superplasticizer (a really
expensive component) and the diﬀerences in the age of the concrete for the diﬀerent

18

methodologies.

Table 3: Optimal concrete components mixture

Decision
Variable
Cement
Blast Furnace Slag
Fly Ash
Water
Superplasticizer
Coarse Aggregate
Fine Aggregate
Age
Cost

Point
Estimation
166.90 kg
43.72 kg
-
175.08 kg
-
1149.93 kg
694.37 kg
78 days
47.33 e

Quantile
Estimation
357.50 kg
-
-
176.45 kg
-
1016.7 kg
679.35 kg
95 days
52.15 e

Superquantile
Estimation
357.50 kg
59.35 kg
-
153.7 kg
-
945.75 kg
713.7 kg
73 days
53.75 e

The biggest employment of cement in the quantile and superquantile methodologies
suggests that the optimal solution would be more expensive, i.e., we need to ensure
the compressive strength to a greater extent. For that reason, we analyze the objective
value for the three diﬀerent cases. For the point estimation methodology, a cost of 47.33
e for the concrete mixture is obtained. In the case of quantile estimation, the cost rises
to 52.15 e. Finally, the biggest cost is obtained by making use of the superquantile
methodology, with a value of 53.75 e. We can see an increase in the cost of more than
6 e (almost 15%) between the point and the superquantile estimation. This diﬀerence
in the cost should imply an increase in the safety regarding the compressive strength
to support the (super)quantile estimation approach. To ensure that, we compute the
distribution function of the three diﬀerent optimal solutions. In that sense, we ﬁt a
Quantile Regression Forest with our training dataset. With this ﬁtted model, we will
predict the conditional quantile of the optimal solution at several values of α to recreate
the distribution function.

In Figure 3, blue, orange, and green curves represent the distribution function for
the optimal solution obtained from the point estimation, quantile estimation, and su-
perquantile estimation methodology, respectively. The vertical black line indicates the
value of the required compressive strength in the optimization problem (45 Mpa).

We can see how, for point estimation methodology, most of the probability distribu-
tion is under the required compressive strength. This shows how, even ﬁtting a powerful
machine learning point prediction model, the distribution of the optimal solution can
be biased. Note that, in most of the real-life scenarios, the actual compressive strength
would be below 45 Mpa.

19

Figure 3: Optimal solution’s distribution function for the compressive strength problem regarding the
employed methodology.

On the other side, the distribution of the optimal solution for the quantile and
superquantile methodology is quite shifted to the right with respect to the one from
the point methodology. In these cases, most of the distribution is over the required
compressive strength.

Before concluding this case study, if we go beyond RF, Table 4 shows a brief per-
formance comparison between diﬀerent predictive models (Section 2.2) regarding their
testing error, ﬁtting, and constraint learning time, optimization problem resolution
time, number of constraints, binary variables, and continuous variables, within the
ﬁnal optimization problem. For RF models, a grid search methodology is applied to se-
lect the best set of hyper-parameters, whereas, for NN predictive models, a 100 neurons
single-layer structure is selected.

First of all, we can see how linear and NN-based methods are the fastest in obtaining
the optimal solution. Besides, we can notice the higher number of constraints and
variables we have to deal with when complex models like RF and NN are employed as
our predictive models. Furthermore, due to the high number of binary variables that RF
models include within the optimization problem, the optimization solving time when

20

Table 4: Chance constraint learning performance regarding methodology and predictive model for the
compressive strength problem

Methodology Predictive

model

Testing error
(MAE/Quant loss)

Fitting &
CL time (s)

Optimization
solving time (s)

Problem size
(constraints)

Binary
vars

Point
Estimation

Quantile
Estimation

Superquantile
Estimation

LR
RF
NN
LR
RF
NN
LR
RF
NN

7.87
4.86
3.41
0.94
0.70
0.42
0.96
0.70
0.32

0.5
61.5
58.9
0.1
105.8
63.1
0.7
109.2
76.7

0.3
274.2
0.3
0.2
84.4
0.3
0.2
50.4
0.3

4
454
304
4
604
304
4
604
309

0
3714
100
0
3711
100
0
3711
100

Non-
binary
vars
9
159
109
9
159
109
9
159
114

using these tree-based methods is bigger to a higher extent. As an additional note, we
cannot compare the ﬁtting process time between RF and NN, as hundreds of RF are
trained during the grid search phase. Generally, the NN-based model obtains the lowest
error (MAE or quantile loss) regarding the test partition of our dataset. However,
the small number of samples in the dataset makes NNs not generalize appropriately
(overﬁtting).

4.2. Case study II: palatable food basket

In this section, we address the case study presented in [23]; being a simpliﬁcation
of the one presented in [39]. In particular, a decision-making humanitarian operation
tool is provided to the World Food Program (WFP) to optimize, among others, the
food basket to be delivered. A food basket has to ensure certain nutrition requirements
while also accomplishing some palatability rules. In [23], palatability scores are set to
be learned by a constraint learning process, employing machine learning models for
point estimation. In this work, we propose to include chance constraints for the model
to ensure a minimum level of palatability with a certain probability.

Therefore, we will obtain and compare three diﬀerent optimal food baskets regarding
the three addressed methodologies of this work: point, quantile, and superquantile
estimation.

4.2.1. Optimization problem

The optimization problem is based on a network ﬂow model, restricted by nutrition
requirements and food basket palatability. In this problem, we aim to minimize the
procurement and transportation costs of the diﬀerent commodities.
In the following, the notation for the problem is introduced.

Indices and sets:

– NS: Set of source nodes.

21

– NT : Set of transshipment nodes.

– ND: Set of delivery nodes.

– K: Set of commodities, indexed by k.

– L: Set of nutrients, indexed by l.

Variables:

– Fijk: Metric tons of commodity k transported between node i and node j.

– xk: Grams of commodity k in the food basket.

– ypltb: Food basket palatability

Parameters:

– γ: Conversion rate from metric tons (mt) to grams (g).

– di: Number of beneﬁciaries at delivery point i ∈ ND

– days: Number of feeding days.

– N utreql: Nutritional requirement for nutrient l ∈ L (grams/person/day).

– N utvalkl: Nutritional value for nutrient l ∈ L per gram of commodity k ∈ K.

– pP
ik

: Procurement cost (in $/mt) of commodity k from source i ∈ NS.

: Transportation cost (in $/mt) of commodity k from node i ∈ NS ∪ NT to

– pT
ijk
node j ∈ NT ∪ ND.

– t: Palatability score lower bound.

– α: Probability conﬁdence level.

The extension of the palatable food basket problem to include chance constraints is

presented as follows:

(cid:88)

(cid:88)

(cid:88)

pP
ikFijk +

(cid:88)

(cid:88)

(cid:88)

pT
ijkFijk

(16a)

i∈NS

j∈NT ∪ND

k∈K

i∈NS ∪NT

j∈NT ∪ND

k∈K

min
x,ypltb,F

s.t.

22

(cid:88)

Fijk =

(cid:88)

j∈NT

Fjik,

i ∈ NT , k ∈ K

j∈NT

(cid:88)

γF jik = dixkdays,

i ∈ ND, k ∈ K

i∈NS ∪NT
(cid:88)

N utvalklxk ≥ N utreql,

l ∈ L

k∈K
xsalt = 5
xsugar = 20
ypltb = f D(x)
P(ypltb ≥ t) ≥ α

(16b)

(16c)

(16d)

(16e)
(16f)

(16g)
(16h)

The objective function (16a) aims to minimize both procurement and transporta-
tion costs. Constraint (16b) is employed to balance the network. Then, constraint
(16c) ensures that the ﬂow into the delivery node is equal to the demand, computed
as the number of beneﬁciaries times the daily quantity of commodity k times the num-
ber of days. Constraint (16d) forces the optimal food basket to meet the nutritional
requirements. Constraints (16e) and (16f) maintain the amount of salt and sugar at a
ﬁxed value. Finally, constraints (16g) and (16h) characterize the CCL framework. In
this sense, constraint (16g) represents the learned decision variables: the food basket
palatability, ypltb. These score values are completely dependent from the basket com-
ponents x, establishing a relationship learned by means a predictive model f D, trained
using a dataset D. On the other hand, constraint (16h) represents a chance constraint:
we force the probability of the palatability score ypltb to be greater than t at conﬁdence
level α.

4.2.2. Methodology

As has been mentioned before, a dataset is needed to relate the palatability score
with the diﬀerent commodities. In this set, a sample dataset of 5000 observations has
been employed, where each food basket is rated with a palatability value from zero
(worst case) to one (best case).
In this dataset, we can ﬁnd up to 25 features or
commodities, including beans, lentils, sugar, oil, and wheat, among others.

For the sake of brevity, we refer the reader to [23], where the authors explain the
complete development of the dataset. In the same work, information about nutritional
commodity contents and nutrient requirements can be found.

In relation to the predictive model, and again for illustrative purposes, a two hidden-
layer deep neural network with 100 neurons per layer has been selected as the main
function to establish the relationship between palatability and commodities. The ﬁnal

23

layer of this NN will be composed of only one neuron in the point and quantile method-
ology. In order to approximate the superquantile, we output 5 diﬀerent quantiles in
the ﬁnal layer (see Section 2.3 for more information). Furthermore, a palatability lower
bound of 0.5 is chosen.

As in the previous case study, three diﬀerent optimal solutions will be obtained
for each point, quantile, and superquantile estimation methodology. For the point
estimation methodology, we will assume that the chance constraint does not exist (that
is, the optimization problem will only include a point prediction learned constraint).
For the quantile and superquantile methodology, we force the chance constraint to be
fulﬁlled at a conﬁdence level of 95%.

4.2.3. Results

The same software presented in Section 4.1.3 was employed to solve the palatable
food basket problem. Table 5 shows the optimal solution for the palatable food basket
regarding the employed methodology.

Table 5: Optimal food basket

Decision Variable
Selection
Milk
Salt
Lentils
Maize
Sugar
Oil
Wheat
WSB
Cost

Point
Estimation
45.74 g
5.00 g
32.87 g
99.94 g
20.00 g
21.66 g
280.54 g
74.69 g
3258.90 $

Quantile
Estimation
45.55 g
5.00 g
34.16 g
98.53 g
20.00 g
21.70 g
280.68 g
74.79 g
3260.78 $

Superquantile
Estimation
44.85 g
5.00 g
38.97 g
93.28 g
20.00 g
21.86 g
281.19 g
75.18 g
3267.78 $

For clarity, Table 5 only contains the optimal solution for all the components of
the food basket with a value greater than zero. As can be seen, diﬀerences across
methodologies are minimum. We can notice how, as we move from point to quantile,
and from quantile to superquantile estimation, the quantity of milk in the food basket
decreases. The same happens with the amount of maize. On the other hand, the
amount of lentils, oil, wheat, and WSB increases.

However, these small changes in the optimal food basket have an inﬂuence on the
objective function. For the point estimation methodology, the total cost for fulﬁlling

24

the demand takes a value of 3258.90$. This cost rises up to 3260.78$ with the quantile
estimation methodology and reaches 3267.78$ with the superquantile methodology.

The low variability in the three diﬀerent food baskets also gives us information about
how powerful Deep Neural Networks (DNN) methods are in predicting palatability.
This accurate performance allows big chances in the probability distribution with small
changes in the optimal solution. As a piece of additional information, the DNN obtained
a testing MSE of 0.0001 for the point estimation methodology, and a testing α-quantile
loss of 0.0013 for the quantile methodology, conﬁrming the excellent performance of the
method.

As in the previous case study, we present the distribution function of the optimal
solution in Figure 4. This distribution function has been computed by training another
two hidden-layer NN, this time obtaining as outputs several conditional quantiles. Op-
timal solutions are passed through the ﬁtted DNN and estimations of the quantiles are
obtained to represent the distribution function.

Figure 4: Optimal solution’s distribution function for the palatable food basket problem regarding the
employed methodology.

We can see how, as we expected, the employment of chance constraints makes the
distribution function of the optimal solutions to be over the seek palatability score (0.5)

25

in most of the cases. We can also notice how powerful the DNN is by looking at the
range of values of the palatability score. For example, the distribution function for
the superquantile optimal solution ranges from 0.51 to almost 0.59. This narrow range
actually represents a 99% prediction interval for the estimated palatability. Note that
this improvement is achieved by a basket cost increase of only 0.27%, which illustrates
the convenience of our approach.

Finally, Table 6 shows a brief summary of the performance of some selected predic-

tive models in relation to the presented case study.

Table 6: Chance constraint learning performance regarding methodology and predictive model for the
palatable food basket problem

Methodology Predictive

model

Testing error
(MAE/Quant loss)

Fitting &
CL time (s)

Optimization
solving time (s)

Problem size
(constraints)

Binary
vars

Point
Estimation

Quantile
Estimation

Superquantile
Estimation

LR
RF
NN
LR
RF
NN
LR
RF
NN

0.120
0.077
0.009
0.014
0.010
0.002
0.015
0.010
0.002

0.2
119.7
427.9
1.3
749.6
451.6
1.4
739.9
515.6

0.2
14.1
198.9
0.3
722.3
4.1
0.2
477.1
10.2

5
115
605
5
455
605
5
455
610

0
5574
200
0
16651
200
0
16651
200

Non-
binary
vars
26
76
226
26
176
226
26
176
231

As can be seen in Table 6, the optimization solving time is directly (but not only)
related to the problem size. We can take as an example the results produced from the
diﬀerent NN models. When employing a point estimation methodology, optimization
time is way bigger than using (super)quantile estimation methodology. This may indi-
cate that, for this particular problem, modelling the expected palatability value is more
diﬃcult than modelling a conditional quantile. However, when modelling palatability
with RF models, it is faster to obtain the optimal food basket for point estimation
methodology compared to the quantile ones, mainly due to the signiﬁcant increment in
the problem size (number of binary variables).

The accurate performance of NN-based models (especially with large datasets),
jointly with their optimization solving time makes them suitable for these types of
applications. As was shown before, NNs were accurate in correctly ﬁtting within the
CCL methodology.

5. Conclusions

In this work, a novel methodology has been developed in order to deal with the inter-
section of chance constraint and constraint learning within mixed-integer optimization

26

problems, two topics that are increasingly getting attention among the operations re-
search community.

From the constraint learning side, we deal with problems where some optimization
variables x are directly controlled by the decision-makers, whereas other variables y
can be indirectly inﬂuenced as they depend on the decisions over x and external co-
variates known when decisions are made. Recent approaches have been developed in
the literature, allowing practitioners to embed linearizable machine learning methods
within their optimization problem to estimate the value of y conditioned to the values
of x. However, there are many real-world applications where we need to set a lower
(or upper) bound to this learned variable, and the fulﬁllment of this constraint is not
guaranteed, i.e., it depends on its probabilistic behaviour, which is further conditioned
by the ﬁtting process of the machine learning model.

For that reason, we take ideas from chance constraints and further impose proba-
bilistic guarantees, i.e., we want the learned variable to be over (or under) a pre-deﬁned
bound with a certain probability. This is done by employing quantile estimation lin-
earizable models as the predictive functions to be embedded in the problem. These
models have the capacity to output a conditional quantile at a speciﬁc level α. Setting
the value of this quantile over (or under) the bound will result in the fulﬁllment of the
chance constraint. Furthermore, this procedure can be extended to estimate superquan-
tiles, a better option if we seek coherent risk measures. This novel proposed framework
has been denoted as Chance Constraint Learning (CCL) and can be employed for both
solving chance constraints and adding statistical guarantees to learned constraints.

This machine learning-based approach will also allow us to avoid the employment
of scenarios to model the chance constraint or the assumption of certain probability
distributions. Thus, depending on the selected predictive model, we will reduce the
number of additional binary variables that have to be employed.

Finally, the proposed CCL methodology has been tested in two diﬀerent case studies,
where we check the diﬀerences in the optimal solutions regarding the selected method-
ology and the impact of the conservatism of chance constraints.

We consider the proposed CCL framework to be useful in real-world problems where
a decision variable has to be learned and the decision-maker is interested in giving
robustness to its optimal solution. To this end, open-access software has been developed
to give practitioners the appropriate tools to implement the CCL methodology within
their optimization problems. Furthermore, the development of this framework paves the
way for future research regarding quantile estimation and optimization problems. For
example, we can tackle uncertainties by making use of prediction intervals composed of
two learned quantiles.

27

Credit authorship contribution statement

Antonio Alcántara: Conceptualization, Methodology, Validation, Investigation,
Software, Writing - Original Draft. Carlos Ruiz: Conceptualization, Methodology,
Validation, Investigation, Writing - Review & Editing, Funding acquisition.

Declaration of competing interest

The authors declare that they have no known competing ﬁnancial interests or per-
sonal relationships that could have appeared to inﬂuence the work reported in this
paper.

Acknowledgements

The authors gratefully acknowledge the ﬁnancial support from MCIN/AEI/10.13039/
501100011033, project PID2020-116694GB-I00 and from the FPU grant (FPU20/00916).

References

[1] Z. Ertem, O. M. Araz, M. Cruz-Aponte, A decision analytic approach for social
distancing policies during early stages of covid-19 pandemic, Decision Support
Systems (2021) 113630.

[2] J. R. Birge, F. Louveaux, Introduction to stochastic programming, Springer Science

& Business Media, 2011.

[3] A. N. Elmachtoub, P. Grigas, Smart “predict, then optimize”, Management Science

68 (1) (2022) 9–26.

[4] D. Bertsimas, N. Kallus, From predictive to prescriptive analytics, Management

Science 66 (3) (2020) 1025–1044.

[5] A. Ben-Tal, L. El Ghaoui, A. Nemirovski, Robust optimization, Vol. 28, Princeton

university press, 2009.

[6] A. A. Lekvan, R. Habibifar, M. Moradi, M. Khoshjahan, S. Nojavan, K. Jerm-
sittiparsert, Robust optimization of renewable-based multi-energy micro-grid inte-
grated with ﬂexible energy conversion and storage devices, Sustainable Cities and
Society 64 (2021) 102532.

28

[7] R. Lotﬁ, Y. Z. Mehrjerdi, M. S. Pishvaee, A. Sadeghieh, G.-W. Weber, A robust
optimization model for sustainable and resilient closed-loop supply chain network
design considering conditional value at risk, Numerical Algebra, Control & Opti-
mization 11 (2) (2021) 221.

[8] K. Govindan, T. Cheng, Advances in stochastic programming and robust opti-
mization for supply chain planning, Computers & Operations Research 100 (2018)
262–269.

[9] H. Jang, A decision support framework for robust r&d budget allocation using
machine learning and optimization, Decision Support Systems 121 (2019) 1–12.

[10] D. Bertsimas, V. Gupta, N. Kallus, Data-driven robust optimization, Mathemati-

cal Programming 167 (2) (2018) 235–292.

[11] G. Guo, L. Zephyr, J. Morillo, Z. Wang, C. L. Anderson, Chance constrained unit
commitment approximation under stochastic wind energy, Computers & Opera-
tions Research 134 (2021) 105398.

[12] S. Küçükyavuz, R. Jiang, Chance-constrained optimization: A review of mixed-
integer conic formulations and applications, arXiv preprint arXiv:2101.08746
(2021).

[13] R. T. Rockafellar, J. O. Royset, On buﬀered failure probability in design and
optimization of structures, Reliability engineering & system safety 95 (5) (2010)
499–510.

[14] R. T. Rockafellar, S. Uryasev, Optimization of conditional value-at-risk, Journal

of risk 2 (2000) 21–42.

[15] J. L. Cremer, I. Konstantelos, S. H. Tindemans, G. Strbac, Data-driven power
system operation: Exploring the balance between cost and risk, IEEE Transactions
on Power Systems 34 (1) (2018) 791–801.

[16] C. Spyros, From decision trees and neural networks to milp: power system op-
timization considering dynamic stability constraints, in: 2020 European Control
Conference (ECC), IEEE, 2020, pp. 594–594.

[17] A. Fajemisin, D. Maragno, D. d. Hertog, Optimization with constraint learning:

A framework and survey, arXiv preprint arXiv:2110.02121 (2021).

29

[18] R. Koenker, V. Chernozhukov, X. He, L. Peng, Handbook of quantile regression,

CRC press, 2017.

[19] L. Hao, D. Q. Naiman, D. Q. Naiman, Quantile regression, no. 149 in Quantitative

applications in social sciences, Sage, 2007.

[20] H. Drucker, C. J. Burges, L. Kaufman, A. Smola, V. Vapnik, Support vector
regression machines, Advances in neural information processing systems 9 (1996).

[21] L. Breiman, J. Friedman, R. Olshen, C. Stone, Classiﬁcation and regression trees.

wadsworth int, Group 37 (15) (1984) 237–251.

[22] N. Meinshausen, G. Ridgeway, Quantile regression forests., Journal of Machine

Learning Research 7 (6) (2006).

[23] D. Maragno, H. Wiberg, D. Bertsimas, S. I. Birbil, D. d. Hertog, A. Fa-
jemisin, Mixed-integer optimization with constraint learning, arXiv preprint
arXiv:2111.04469 (2021).

[24] J. H. Friedman, Stochastic gradient boosting, Computational statistics & data

analysis 38 (4) (2002) 367–378.

[25] S. I. Gallant, S. I. Gallant, Neural network learning and expert systems, MIT press,

1993.

[26] B. Grimstad, H. Andersson, Relu networks as surrogate models in mixed-integer

linear programs, Computers & Chemical Engineering 131 (2019) 106580.

[27] R. Anderson, J. Huchette, W. Ma, C. Tjandraatmadja, J. P. Vielma, Strong mixed-
integer programming formulations for trained neural networks, Mathematical Pro-
gramming 183 (1) (2020) 3–39.

[28] R. T. Rockafellar, S. Uryasev, M. Zabarankin, Risk tuning with generalized linear

regression, Mathematics of Operations Research 33 (3) (2008) 712–729.

[29] S. Y. Chun, A. Shapiro, S. Uryasev, Conditional value-at-risk and average value-
at-risk: Estimation and asymptotics, Operations Research 60 (4) (2012) 739–756.

[30] P. Harsha, R. Natarajan, D. Subramanian, A prescriptive machine-learning frame-
work to the price-setting newsvendor problem, Informs Journal on Optimization
3 (3) (2021) 227–253.

30

[31] S. J. Moon, J.-J. Jeon, J. S. H. Lee, Y. Kim, Learning multiple quantiles with
neural networks, Journal of Computational and Graphical Statistics 30 (4) (2021)
1238–1248.

[32] A. Alcántara, ccl_tool: Chance constraint learning tool (2022).
URL https://github.com/antonioalcantaramata/ccl_tool/

[33] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel,
M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos,
D. Cournapeau, M. Brucher, M. Perrot, E. Duchesnay, Scikit-learn: Machine learn-
ing in Python, Journal of Machine Learning Research 12 (2011) 2825–2830.

[34] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen,
Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito,
M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, S. Chintala,
Pytorch: An imperative style, high-performance deep learning library, in: H. Wal-
lach, H. Larochelle, A. Beygelzimer, F. d'Alché-Buc, E. Fox, R. Garnett (Eds.),
Advances in Neural Information Processing Systems 32, Curran Associates, Inc.,
2019, pp. 8024–8035.

[35] D. Maragno, H. Wiberg, Opticl: Mixed-integer optimization with constraint learn-

ing (2021).
URL https://github.com/hwiberg/OptiCL/

[36] W. E. Hart, C. D. Laird, J.-P. Watson, D. L. Woodruﬀ, G. A. Hackebeil, B. L.
Nicholson, J. D. Siirola, et al., Pyomo-optimization modeling in python, Vol. 67,
Springer, 2017.

[37] I.-C. Yeh, Modeling of strength of high-performance concrete using artiﬁcial neural

networks, Cement and Concrete research 28 (12) (1998) 1797–1808.

[38] Gurobi Optimization, LLC, Gurobi Optimizer Reference Manual (2022).

URL https://www.gurobi.com

[39] K. Peters, S. Silva, R. Gonçalves, M. Kavelj, H. Fleuren, D. den Hertog, O. Ergun,
M. Freeman, The nutritious supply chain: optimizing humanitarian food assis-
tance, INFORMS Journal on Optimization 3 (2) (2021) 200–226.

31

