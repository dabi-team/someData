Demeter: A Fast and Energy-Efficient Food Profiler
using Hyperdimensional Computing in Memory

Taha Shahroodi† Mahdi Zahedi† Can Firtina‡ Mohammed Alser‡
Stephan Wong† Onur Mutlu‡ Said Hamdioui†

†TU Delft

‡ETH Z¨urich

2
2
0
2

g
u
A
4
2

]

R
A
.
s
c
[

2
v
2
3
9
1
0
.
6
0
2
2
:
v
i
X
r
a

Food profiling is an essential step in any food monitoring
system needed to prevent health risks and potential frauds in
the food industry. Significant improvements in sequencing
technologies are pushing food profiling to become the main
computational bottleneck. State-of-the-art profilers are unfor-
tunately too costly for food profiling. Our goal is to design a
food profiler that solves the main limitations of existing pro-
filers, namely (1) working on massive data structures and (2)
incurring considerable data movement for a real-time mon-
itoring system. To this end, we propose Demeter, the first
platform-independent framework for food profiling. Deme-
ter overcomes the first limitation through the use of hyper-
dimensional computing (HDC) and efficiently performs the
accurate few-species classification required in food profiling.
We overcome the second limitation by using an in-memory
hardware accelerator for Demeter (named Acc-Demeter) based
on memristor devices. Acc-Demeter actualizes several domain-
specific optimizations and exploits the inherent characteristics
of memristors to improve the overall performance and energy
consumption of Acc-Demeter. We compare Demeter’s accu-
racy with other industrial food profilers using detailed software
modeling. We synthesize Acc-Demeter’s required hardware
using UMC’s 65nm library by considering an accurate PCM
model based on silicon-based prototypes. Our evaluations
demonstrate that Acc-Demeter achieves a (1) throughput im-
provement of 192× and 724× and (2) memory reduction of 36×
and 33× compared to Kraken2 and MetaCache (2 state-of-the-
art profilers), respectively, on typical food-related databases.
Demeter maintains an acceptable profiling accuracy (within
2% of existing tools) and incurs a very low area overhead.

1. Introduction

The urgent need for a real-time, efficient, and accurate food
monitoring system is apparent when one considers the eco-
nomic impacts and health risk issues due to human errors
and/or intentional fraud regarding everyday food. For exam-
ple, a worldwide annual loss of $10 to $24 billion is estimated
only for the frauds happening in the fish industry [1]. The
Halal meat scandal [2] and the black fish scandal [3] are just a
few other preventable examples that could have been quickly
prevented if we had accurately and efficiently monitored all
the food productions in real-time.

Food profiling is the first step and the only computationally
expensive task in a food monitoring system. The food profiling
task entails determining the existing species in a food sample
and their relative abundance [4,5]. Today’s food profilers work
with sequenced data as we can capture a more accurate profile

using the sequences of a food sample. The rapid drop in the cost
of DNA sequencing in the past decades and the expectation
for a continual trend [6, 7]1 is expected to lead the way for
profiling to become the main bottleneck of this pipeline.

Currently, the industry utilizes state-of-the-art (SOTA) taxo-
nomic profilers from metagenomic studies for food profiling
due to the similarity of problem statements in food profiling
and metagenomics profiling. However, as alluded to, such
profilers are developed as the first step of metagenomic stud-
ies [9–11]: a new yet different line of research that allows us
to study many species that are taken directly from their envi-
ronment altogether, as opposed to studying them individually.
Unfortunately, these profilers are overkill for simply profiling a
given food sample and, therefore, costly since those taxonomic
profilers have been designed for different, more complex goals
such as (1) capturing complex operations between organisms or
(2) finding insights on species that cannot be clonally cultured
in labs. Such profilers are also designed for working on larger,
more complex, and randomly mixed genome sequences and
demand a significant amount of resources that simply impede
real-time monitoring of all food samples after production, ship-
ment, or distribution; the ultimate goal of a food monitoring
system. Therefore, a new solution must be sought for food
profiling that is cheaper, faster, more energy-efficient, and yet
accurate.

In particular, we pinpoint two critical sources of inefficiency
in SOTA profilers currently used for food monitoring, collec-
tively called food profilers or profilers hereafter. First, all cur-
rent (food) profilers work with significantly large working data
structures, e.g., humongous hash tables or sorted lists, that
require high-end servers with extensive storage and memory
capabilities to be handled. This fundamentally limits perfor-
mance scaling on par with that in sequencing technologies.
Second, current profiling techniques incur a significant num-
ber of random accesses to large working datasets, and as a
result, unnecessary data movement between their storage and
memory plus their memory and compute units which cannot be
otherwise done where the data resides due to (1) the size of the
final data structures and (2) the required operations for tasks
in hand. This directly translates to massive energy consump-
tion and latency. For example, as shown in our evaluations
Sections 4, 7, a widely used SOTA profiler takes ∼1 minute to
profile one high-coverage sequenced food sample. However,
it requires a super machine or cluster with at least 300 GB of

1Researchers expect that soon different analyses of the sequenced data will
become the cost and performance bottleneck rather than sequencing itself, as
is currently the case for read mapping vs. DNA sequencing [8].

1

 
 
 
 
 
 
memory and proportionally scaled-up compute power. These
costs add up to an unbearable required time and equipment
for real-time monitoring of all existing and producing food
samples. Therefore, a healthy economy regarding the food in-
dustry cannot keep using these profilers and demands cheaper,
faster, more energy-efficient, and accurate food profilers for
the years to come.

Our goal in this work is to solve both limitations of previous
profilers, namely (1) reliance on high-end servers and scaling
problems due to required massive data structures and (2) incur-
ring unnecessary data movement. To this end, we propose
Demeter, an end-to-end, hardware/software co-designed food
profiling framework that efficiently profiles species of a food
sample. The key idea of Demeter is to reduce the food pro-
filing problem to a multi-object (multi-species) classification
problem using hyperdimensional (HD) computing (HDC) fol-
lowed by an abundance estimation step. Demeter is a platform-
independent framework and produces accurate results on any
hardware platform such as a central processing unit) CPU,
graphics processing unit (GPU), or application-specific inte-
grated circuit (ASIC).

Our experiments show that although the accuracy of Deme-
ter is comparable with existing SOTA profilers, typical pro-
cessing units (CPUs) are not exploiting the full parallelism
offered by our HDC-based approach, prohibiting those plat-
forms from outperforming SOTA profilers. Moreover, we find
two more optimization opportunities that can be achieved
with a wisely-chosen platform: (1) eliminating the cost of
existing shift operations and (2) mitigating the significant
amount of data movement involved in our HDC-based solu-
tion. Therefore, we propose an in-memory hardware accel-
erator for Demeter, Acc-Demeter, to mitigate the costs men-
tioned above and simultaneously solve the second problem
of profilers as well. Acc-Demeter achieves these by (1) the
physical attributes of nanoscale memristive-based devices2, (2)
Processing-In-Memory (PIM), where the data resides, and (3)
zero-overhead shift operation in hardware. It is worth not-
ing that, with the advent of portable sequencing machines, a
move from cloud computing with sophisticated infrastructure
towards an in-build profiler (or other genomics-related kernels)
inside the sequencer is finally in the foreseeable future.
Our paper makes the following main contributions:

• To our knowledge, Demeter is the first framework that en-
ables food profiling via HDC. Demeter provides a five-step
approach to determine the relative abundance of a set of the
food read sequences at the species level. We design Deme-
ter to (1) address the key problems of food profiling rather
than accelerating regular metagenomic profilers and (2) be
platform-independent (Section 3).

• We propose a PIM-enabled hardware accelerator for Deme-
ter using memristor devices (Acc-Demeter) to extract Deme-
ter’s full potentials and solve the data movement problem
in Demeter and previous profilers. We propose several op-

2We choose Phase Change Memory (PCM) devices as members of mem-
ristor families due to our accessibility to accurate measurements and mod-
els. However, in principle, our proposed techniques can be applied to any
memristor-based memory technology, such as ReRAM or STT-MRAM.

timization techniques for Acc-Demeter based on domain-
specific knowledge of food profiling and our background
in PCM cells characteristics and HDC operations. To our
knowledge, Acc-Demeter is the first (in-memory) hardware
accelerator for a food profiler (Section 5).

• We rigorously compared Demeter and Acc-Demeter to four
SOTA food profilers. We show that Demeter provides an
accuracy level comparable with previous food profilers and
within the accepted level of food monitoring systems. The
default setting of Acc-Demeter enables a (1) throughput im-
provement of ∼192× and 724× and (2) reduction in the re-
quired memory of ∼36× and 33× compared to Kraken2 [12]
and MetaCache [4], respectively, when querying on a typical
food-related reference genome database, i.e., AFS20 [4]. Our
design requires only ∼8.9 mm2 die area and can process
∼9.45 Mbp per joule for our largest food-related database
AFS31 [4] (Section 7).

2. Background and Motivation

This section discusses the necessary background and intro-
duction to (1) the current taxonomic profilers and their short-
comings when used for food profiling, (2) HDC, and (3) the
PIM paradigm. We devote the materials mainly to those closely
related to or used by Demeter. For more detailed background
information, we refer the reader to comprehensive reviews on
these topics [13–19].

2.1. Metagenomic Profilers

Constantly increasing the performance of sequencing tech-
nologies and the fast drop in the cost of DNA sequencing [6, 7]
catalyzed the metagenomic studies [9–11]. These studies en-
able us to capture the big picture of the environment without
isolating or cultivating individual organisms. For this purpose,
one needs to perform taxonomic profiling: determining the
relative abundances of species in a sample directly taken from
the environment. Due to the high cost associated with align-
ment and assembly for large reference datasets, to this date,
we still prefer heuristics statistical-based profilers to assembly-
or alignment-based ones. However, even these profilers are
not yet cheap or economic and prevent large-scale, real-time
studying. Their cost is mainly related to the required memory
for profilers’ data structure and algorithms. Such large data
structures or sophisticated algorithms force us to use high-end
servers and are needed to fulfill complex goals of subsequent
metagenomic analysis, namely capturing complex operations
between organisms and discovering insights on species that
can not be clonally cultured in labs. This high cost of profiling
in metagenomics profiler prevents us from efficiently profiling
food samples in real-time, the end goal of a food monitoring
system.

2.2. Problems of Food Profilers

We use VTune [20] and profile three SOTA profilers that
are currently used for food samples as well, namely Kraken2,
CLARK, and MetaCache, using their default datasets and pa-
rameters on the original platforms for which they have been
designed. We make two main observations, which follow
a similar trend reported in previous studies in genomics as

2

well [12, 21, 22].
Observation 1. All these profilers induce large memory re-
quirements for their data structures. For example, Kraken2
requires a minimum of 300 GB memory for its reference data
structure. Even for smaller and less complex reference data
bases such as those in food industry, Kraken2 still requires
more than 50 GB of memory (Section 4.4).
Observation 2. All profilers induce high miss rates in L2 and
L3 (∼68 to 90%). The nature of their underlying algorithms
causes this inefficiency because they always query a small frac-
tion of keys in a large hash table and/or sorted list, leading
to random memory access patterns. In other words, the arith-
metic intensity of the profilers is too small to the extent that
even increasing the number of threads does not help resolve
the CPU stall cycles caused by memory accesses required by
these misses.

Overall, current food profilers’ large working data structure
and their low arithmetic intensity lead to high storage cost, low
performance, and high energy consumption. It also demands
high-end servers. This motivates designs (such as Demeter and
Acc-Demeter) that provide reduced working data structures,
eliminate unnecessary data movements, and can liberate us
from dependency on the clusters.

2.3. Hyperdimensional Computing

Hyperdimensional computing (HDC) [23, 24] is a brain-
inspired computing paradigm that has been demonstrated to
be effective in reference-based learning domains, such as text
classification [25–27], gesture recognition [28], and latent se-
mantic analysis [29]. Elements of HDC are presented using
high-dimensional vectors, hereafter called HD vectors. HD
vectors can be composed of real [30–32], binary [23, 33], bipo-
lar [28,34], or complex numbers [35]. Previous works show that
binary representations of HD vectors are more practical and
efficient for classification problems or one-shot reinforcement
learning. This representation is also more hardware-friendly.
Therefore, we proceed with binary HD representations. HD
vectors also come with other powerful features such as robust-
ness to random errors, holistic representation, and randomness.
We refer the enthusiastic readers to previous works for more
details on these features [17, 23].

Like other reference-based classifiers, an HDC-based system
also takes two steps: (1) training and (2) classification. An en-
coding mechanism is used in both steps. One famous example
is the N-gram encoding mechanism that follows a two-step
approach for encoding a string of size L to an HD vector of size
D. Step 1: It combines N consecutive alphabets of the string
and builds an HD vector that is orthogonal to them all and can
preserve their relative order. This operation is called binding
and is represented in Equation 1, where ρi(X ) represents the ith
permutation of vector X and Bi are once randomly-generated
representative HD vectors (also referred to as atomic or basis
HD vectors) for the ith character of the string Ci. The string is
a DNA sequence in Demeter.

N – gram(C1, C2, …, CN ) = B1 ⊕ ρ(B2) ⊕ · · · ⊕ ρN –1(BN )

(1)

Step 2: The encoder performs an element-wise addition be-
tween all HD vectors corresponding to consecutive N-grams,
called bundling, to present the entire input sequence. To bina-
rize the final HD vector, the encoder applies a majority function
over each position. This final vector is stored in associate mem-
ory (AM) and is called a prototype HD vector if the input was
a reference genome. Otherwise, it is called query HD vector
and will use it for classification.

The most common approach for classifying whether the
sequence query belongs to any of the classes in AM after us-
ing N-gram encoding mechanism is to measure the hamming
distance between the query HD vector (Q) and each of the
prototype HD vectors (Ps) and decide based on a fixed distance
or threshold (T). This can be easily performed with an XNOR
of Q and each P followed by a pop-count3 and thresholding
operation, as shown in Equation 2.

Classification(i) =






if

1,

D
(cid:80)
j=1
0, otherwise

Q(j) ¯⊕Pi(j) ≥ T

(2)

2.4. Computing Inside/Near Memory

For decades, the processing units have been developed at
a faster rate than memory units, causing memory units to
become a bottleneck, especially in data-intensive workloads.
The Processing-In-Memory (PIM) (interchangeably also re-
ferred to as Computation-In-Memory (CIM)) is a promising
paradigm that aims to alleviate the data movement bottleneck.
In essence, PIM advocates for avoiding unnecessary data move-
ment and redesigning systems such that they are no longer
processor-centric. Previous works show the potential of vari-
ous memory technologies for implementing PIM-based archi-
tectures [36–39]. Resistive memories or memristive devices,
such as ReRAM and PCM [37, 40, 41], have recently been intro-
duced as a suitable candidate for both storage and computation
units that can efficiently perform vector-matrix multiplica-
tion [42] and bulk bit-wise logical operations [43, 44] since
they can follow Kirchhoff’s law inherently. They also enjoy
non-volatility, high-density, and near-zero standby power. Due
to the inherent high parallelism, simplicity of the required
operations, and intrinsic robustness and error tolerance of
an HDC-based system, such a system fits well with the PIM
paradigm. A few recent works propose application-specific
hardware accelerators based on memristive devices [41, 45–47]
for such HDC-based systems. We describe the differences be-
tween our implementation and closest previous proposals in
Sections 5 and 9.

3. Demeter

Demeter is a configurable framework for food profiling and
is based on three main insights: (1) current food profilers,
whereas accurate, are neither memory- nor energy-efficient,
(2) the primary sources of high cost and inefficiency in cur-
rent food profilers is their large reference data structures and
working sets, and (3) one can profile food samples quickly and

3Pop-count (population count) of a vector or specific value is the process

of finding the number of set bits (1s) in that value.

3

Figure 1: Overview of Demeter framework.

accurately using HDC. Fig. 1 provides an overview of the five
key steps in Demeter: 1 defining an HD space, 2 building an
HD reference database (HD-RefDB), 3 converting sample reads
into HD space, 4 determining the possible species assignment
per sample read, and 5 performing abundance estimation. We
describe each step in more detail next.
3.1. Step 1: Define the HD Space

As the first step ( 1 in Fig. 1), Demeter defines an HD space
for all subsequent operations and steps. This is a crucial step
as it determines the operations in the remaining steps. Unfor-
tunately, many previous HDC-based proposals did not support
the user’s input for determining the HD space and designed
their space statically. Hence, such designs are more limited.

Demeter defines the HD space in 4 stages. Stage 1: Deme-
ter fixes two hyperparameters: (1) The dimension of the HD
space; i.e., the dimensionality of the HD vectors (element rep-
resentations), and (2) The sparsity of each element (HD vector).
Stage 2: Demeter generates a few atomic HD vectors and
stores them in memory (commonly called Item Memory (IM)).
These vectors can be (1) the HD vectors that represent our
genome alphabets or (2) the one-time randomly generated HD
vectors that some encoding mechanisms use, for example, to
introduce the concept of order between alphabets of one in-
put. Stage 3: Demeter decides on the encoding mechanism to
build the space with. This very encoding mechanism will be
used throughout Steps 2 and 3 of Demeter. Stage 4: Demeter
fixes the similarity metric and any other associated parameters
(such as thresholds) based on the user’s input or a common
choice considering previous stages. Demeter stores a default
value for each stage in a configuration file. Once the user sum-
mons Demeter, Demeter quickly checks if a configuration file

matches with the user’s requested HD space or not. Demeter
only runs this step if such file does not exist or the user asked
for a change.

3.2. Step 2: Build Demeter’s Reference Data Struc-

ture

Demeter takes two sets of inputs in step 2 : (1) HD space pa-
rameters defined in Step 1 and (2) a reference genome database.
Subsequently, Demeter builds a new reference database in its
HD space out of all the considered reference genomes. This
new database, called HD-RefDB, consists of one (or few) pro-
totype HD vector(s) from any given reference genome in the
original reference database and is stored in AM. HD-RefDB
can be as varied as the number of combinations of possible
hyperparameters, atomic vectors, and encoding mechanisms
in Step 1 . This step aims to reduce the size of the working
set for the classification task while avoiding accuracy drop.
Since this step requires only simple arithmetics and is also
highly parallelizable, it can still be accelerated on our proposed
PIM-enabled accelerator (Section 5).

3.3. Step 3: Demeter’s Read Conversion

Demeter again takes two inputs in Step 3 : (1) HD space
configuration and (2) read sequences of the food sample under
study. Demeter translates each of these read sequences into
one query HD vector. To prevent any extra storage cost and
to pipeline computations of Step 3 and Step 4 , Demeter for-
wards each query HD vector to the next step instead of storing
them inside a memory unit while waiting for all of them to

4

Similarity Check Online / MultipleSimilarity Check Online / MultipleHDC ConfigurationNew DimensionNew SparsityEncoding Mechanismetc.HDC ConfigurationNew DimensionNew SparsityEncoding Mechanismetc.Reference GenomesAAACTGGTCA … TGTTCACCCGATCATGACGA … TCGTCTACGCCTACATAGTA … AAATCACACTGAGCGTGCCC … TGTTCACCCGTTACGAGTCA … TGGGCAGCAACCCCTGGTCC … CGTGCACGGG. . .L_RefReference GenomesAAACTGGTCA … TGTTCACCCGATCATGACGA … TCGTCTACGCCTACATAGTA … AAATCACACTGAGCGTGCCC … TGTTCACCCGTTACGAGTCA … TGGGCAGCAACCCCTGGTCC … CGTGCACGGG. . .L_RefFood Sample ReadsRead SequencesATTATCCGCGA … GGTCCTTGA. . .GGAAACCATT … TTTGCACGCGL_ReadRead SequencesATTATCCGCGA … GGTCCTTGA. . .GGAAACCATT … TTTGCACGCGL_ReadFood Sample ReadsRead SequencesATTATCCGCGA … GGTCCTTGA. . .GGAAACCATT … TTTGCACGCGL_ReadUser InputEncoder UnitStep 2: Build HD-RefDB2Step 2: Build HD-RefDB2Value0010111001 … 0010110001Specie 10010111001 … 0010110001Specie N. . .HD-RefDB0010001101 … 1010010111Specie 2KeyValue0010111001 … 0010110001Specie 10010111001 … 0010110001Specie N. . .HD-RefDB0010001101 … 1010010111Specie 2KeyStep 3: Read Conversion3Step 3: Read Conversion30010100101 … 0011110100Read k0010100101 … 0011110100Read kSpecies-level Abundance CalculationStep 4: Multi-Species Classification4Step 4: Multi-Species Classification4ReadsRefs.cfgOffline / One-timeStep 5: Relative Abundance Estimations5Online / MultipleStep 1: Define the HD Space 1Step 1: Define the HD Space 1Offline / One-time1.Hyperparameters:O Dimension of HDO Sparsity of HD vecs2.HD vecs’ generation3.Encoding mechanism4.Similarity metricOnline / Multiplebe constructed first4. Query HD vectors created in this step
can require larger or smaller space than a read, depending on
the initial length of the read sequences and the dimension of
the HD space. Therefore, although Steps 2 and 3 share the
encoding mechanism, their input and how Demeter treats the
outcome are pretty different. Step 3 neither introduces a new
operation nor a procedure other than those already existing
from Step 2 . Therefore, it enjoys similar benefits as Step 2 ,
namely high parallelization and in-memory suitability. Deme-
ter runs Step 3 every time it profiles a new read of a food
sample.
3.4. Step 4: Multi-Species Classification per Read

In this step, Demeter takes (1) the query HD vector (Step 3 ),
(2) HD-RefDB (Step 2 ), and (3) similarity function and its cor-
responding parameters (Step 1 ) as inputs. To determine the
specie(s) that each read belongs to, Demeter performs a sim-
ilarity check between the query HD vector and each of the
prototype HD vectors in HD-RefDB. The similarity measure
can vary depending on the vector representations and encod-
ing approaches. Demeter allows various famous mechanisms
for the similarity check, such as Hamming distance [17] and
dot product [16]. Usually, this step can be implemented only
with simple operations (Section 2.3). It also enjoys high paral-
lelization, similar to the previous steps. Although a similarity
metric and its related parameters highly relate to (1) the en-
coding mechanism and (2) hyperparameters of the HD space,
such as representations, sparsity, and the dimension of HD
vectors, and therefore it makes sense not to let them change
arbitrarily, Demeter supports changing them in Step 4 as well,
without needing to re-run Steps 2 or 3 . This is because some
studies show that different similarity metrics and thresholds
may outperform others depending on your application and
data for a fixed set of hyperparameters and encoding mech-
anisms. Therefore, if one decides to change their reference
database, they may need to play with these to find the right
match, and Demeter allows such investigations. Currently,
Demeter provides a default option.

Demeter may find out that the query HD vector is close
to one, multiple, or none of the prototype HD vectors in HD-
RefDB. This variety in possible outputs differentiates Demeter
from many previous HDC-based designs [17, 41, 48–50]. In
such works, mostly due to the characteristics of applications
under study, researchers always assume that (1) the query HD
vector can only belong to one of the prototype HD vectors,
and (2) the class of the query HD vector will exist in the AM.
However, none of these assumptions hold for a food profiler.
One read from the food sample can be related to one, multi-
ple, or none of the reference genomes in the original reference
genome database. This is because the read sequences are mostly
short strings with a reasonably high probability of existence
in longer reference genome sequences. It is also not uncom-
mon that the query HD vector does not belong to any of the
4This is the default behavior in Demeter. However, we also provide the
option for the user to keep and store these query HD vectors (HD-ReadDB)
in case one needs to analyze them further. If one uses this option, the stored
query HD vectors create another database representing the reads in our food
sample, called HD-ReadDB hereafter.

reference genomes in the initial reference genome database.
This case can happen when, for example, (1) there is either
an unknown species in the food sample, (2) one incorrectly
excludes the corresponding reference genome in the initial
reference genome database, or (3) an uncorrected sequencing
error has happened. A food profiler should capture such cases.
This difference between how many prototype HD vectors in
HD-RefDB can be assigned to one query HD vector is a key
difference that affects both the following abundance estimation
step and final results. It also distinguishes this work further
from previous HDC-based proposals for different applications.
Step 4 also enjoys high parallelization and in-memory suit-
ability features similar to previous steps.

3.5. Step 5: Species Level Abundance Estimation

In Step 5 , Demeter performs a relative abundance estimation
based on the results of Step 4 . This step is particularly needed
for a food profiler in which one query HD vector can be similar
to one or more classes/species. Demeter categorizes each query
HD vector into (1) uniquely-mapped, (2) multi-mapped, and
(3) unmapped, taking a two-step approach. In the first step,
Demeter assigns the uniquely mapped query HD vectors to
the species they are similar to. In the second step, Demeter
assigns the multi-mapped query HD vector to multi-species
proportionally to the number of reads that have been uniquely
aligned to in the first step divided by the length of species
(reference genome). Demeter’s Step 5 can be extended to
support different assignment policies for the multi-mapped
reads. We leave investigating the effect of such methods for
future work.

4. Demeter’s Evaluation
4.1. Methodology

We implement a multi-threaded highly-parallelized version
of Demeter in C++ using SeqAn library [51], called C-Demeter.
SeqAn library is an open-source optimized library for biologi-
cal data. C-Demeter verifies the accuracy of Demeter. We also
implement a GPU version of Demeter, G-Demeter. G-Demeter
uses CUDA streams for parallelizing data copy operation be-
tween shared memory and global memory with other compu-
tations as much as possible. It implements the similarity check
using the parallel reduction technique introduced by Harris et
al. [52] in the shared memory. All of our experiments run on
a 128-core server with AMD EPYC 7742 CPUs [53] and with
500 GB of DDR4 DRAM. G-Demeter runs on an NVIDIA RTX
2080Ti GPU. Our sensitivity analysis shows that binary HD
vectors of size 40,000, with dense distributed representation
(DDR [17]) and N-gram-based encoding mechanism, strike a
sweet spot in the tradeoff between accuracy, required mem-
ory, and performance. Therefore, unless otherwise stated, our
evaluations use these setups.
Accuracy Metrics. We capture the four fundamental rates
from a (food) profiler when considering the presence and ab-
sence of each species in the output, i.e., True Positive (TP), False
Positive (FP), False Negative (FN), and True Negative (TN) Rate.
Based on these rates, Demeter reports two standard metrics of
Precision and Recall [12, 54, 55] to assess the accuracy of our

5

(food) profilers.
Performance Metrics. Performance analysis consists of three
experiments: (1) Build time, (2) Query time, and (3) Query
throughput or speed. This separation has two main reasons.
(1) Build time is normally a one-time job and does not affect
the overall profiler’s performance. Therefore, it is only fair
to separate build time and query time. (2) Query time is sim-
ply the required time for profiling one single read. However,
throughput is measured by million reads per minute ( MR
) and
m
should be differentiated as it can get affected easily by other
factors such as the size of the data structure, the classifier’s
parallelization capability, or the infrastructure’s computation
and storage/memory limitations (e.g., duplicating capabilities).
Datasets. We have two sets of datasets. (1) Genome sequences
used as a reference database. (2) Genomes sequences used
as food samples and input queries. We consider AFS20 and
AFS31 [4, 5] as our reference genome datasets. These datasets
are two commonly used datasets consisting of 20 and 31 food-
related reference genomes related to animals whose sizes vary
from 12 MB to 14 GB. AFS31 is currently also the biggest ref-
erence dataset used in food profiling. Food sample reads or
queries are from calibrator sausage samples from ENA project
ID PRJEB34001 [56], and PRJNA271645 [57]. These reads are
real short-read sequences from a mixture of food ingredients
such as chicken, turkey, etc., sequenced on an Illumina HiSeq
machine.
Baselines. We compare Demeter against MetaCache [4] (the
most accurate food profiler) Kraken2 [12], Kraken2+Bracken
[58], and CLARK [59], the top 3 alignment-free and fastest
metagenomic profilers that are also commonly used for food
profiling.
4.2. Demeter’s Accuracy Analysis

Figures 2 and 3 present the results for the precision and
recall of all evaluated food profilers on the species levels over
AFS20 for Kylo and Kal food samples [56,57], respectively. Note
that the relative abundance of higher taxonomy levels is not of
importance in food profiling. Additionally, those calculations
highly depend on the propagation method from species level
to those levels. Therefore, they have been excluded from this
study.

Figure 2: Precision rate for Kylo and Kal Samples on AFS20.

We observe that Demeter stands very close to the most ac-
curate profiler, MetaCache, and has only 1.4% and 2.6% less
precision and recall, respectively, for KLyo samples. Moreover,
Demeter achieves similar results on AFS31 and Kal samples.

6

Figure 3: Recall rate for Kylo and Kal Samples on AFS20.

Note that accuracy is very much data-dependent, and indeed
this accuracy drop is acceptable for a food profiler. The results
of the latest comparison between current (metagenomics) pro-
filers [60] show an Std error of the mean ranging from 0 to 5%
regarding the precision and recall among various widely-used
profilers on different datasets.

We conclude that Demeter is accurate and achieves high
precision and recall for food samples. These results show that
Demeter’s HDC-based classification approach followed by our
abundance estimation technique does not hurt the accuracy of
the profiler compared to baselines.
4.3. Demeter’s Software Performance Analysis

Fig. 4-a and Fig. 5-a present the time that each profiler takes
to query one (short) read from the query food sample and
classify its specie(s) over AFS20 and AFS31, respectively.

Figure 4: (a) Query time and (b) Query throughput on AFS20.

Figure 5: (a) Query time and (b) Query throughput on AFS31.
We observe that both C-Demeter and G-Demeter, whereas
accurate, require higher query time compared to Kraken2. The
time breakdown, using Intel VTune [20] and cudaEvents, re-
veals that both implementations are memory bound, meaning
there exists a significant percentage of under-utilized slots due
to data access issues.

We believe that there are two main reasons behind this prob-
lem. First, the shift operation per processed character in the
encoding mechanism of Demeter. Both of these implementa-
tions store the large HD vectors into multiple registers. Every

shift operation translates to multiple copy operations among
those registers, which can become costly in terms of time and
energy consumption. This is why the query time is higher
than expected. Second, not all prototype HD vectors fit in the
caches. Therefore, the software versions take a few cycles to
read prototype HD vectors in batches, compare them to query
HD vector, save the results, and continue with the next batch.
Note that these also put a limit on the expected throughput.

Fig. 4-b and Fig. 5-b present throughput of different profilers
over AFS20 and AFS31. We make three observations. First,
C-Demeter achieves a lower throughput compared to Kraken2.
The reasons behind this are similar to what was discussed for
its longer query time. Second, we observe that G-Demeter
improves the throughput by up to 24% (depending on the ref-
erence dataset) and therefore can be used for food profiling in
the industry in the near future. Third, we observe that simply
increasing the number of working threads by moving from
C-Demeter to G-Demeter does not improve the throughput
considerably. We ask to use the commodity GPUs to perform
the food profiling to cut the cost in the short term. In the
long term, we propose extending Demeter to ASIC designs
(such as those we present next) that solve the new sources of
inefficiency we discussed above.

However, our analysis also shows that even a massively-
parallel implementation of Demeter, G-Demeter, does not fully
utilize the parallelism offered by vector operations of HDC
classification of Demeter, while also suffering from expensive
copy-pasting among registers and its inability to perform the
classification efficiently on a large vector in software.

4.4. Demeter’s Memory Analysis

To show a key source of improvement in Demeter (and an
enabler for Acc-Demeter), we compared the memory require-
ment of Demeter with the other food profilers. Fig. 6 presents
the required memory for each profiler on AFS20 and AFS31.

Figure 6: Required memory for (a) AFS20 and (b) AFS31.

We make the following two observations. First, Demeter
requires ∼33x and 36x less memory than Kraken2 and Meta-
Cache for AFS20 database and ∼27x and 30x less memory for
them for AFS31 database, respectively. This makes Demeter the
most efficient food profiler from a memory usage perspective.
Second, the reduction in memory requirement for Demeter is
to the extent that, for the first time, the data structure of the
food profiler can fit into a standard size memory and does not
require a colossal RAM to manage further queries. This reduc-
tion is the primary enabler behind Acc-Demeter. We conclude
that Demeter is very memory efficient.

7

5. Demeter’s PIM-enabled Accelerator

Demeter is positioned as a platform-independent food profil-
ing framework that uses HDC. Demeter works with large HD
vectors, is robust against errors, enjoys high parallelism, and
exploits simple operations. These characteristics make Demeter
a suitable candidate for hardware acceleration. However, the
interest behind accelerating Demeter in a highly parallelizable
and energy-efficient platform and specifically a PIM-enabled
design goes beyond being simply its suitability and is a requi-
site for such a platform with two main motives.
Motivation 1: As discussed in Section 4.3, a software ver-
sion of Demeter incurs a considerable cost on copy operations
among registers holding intermediate HD vectors and classifi-
cation. It also performs the classification poorly due to larger
than cache HD-RefDB and low cache hit rate. These costs di-
minish all the benefits of Demeter that come from its small
data structures and memory requirement. However, one can
prevent this if Demeter is implemented in hardware as they
can (1) realize the shift operation for free by only redirecting
the output of each register to the next one and (2) perform the
classification efficiently.
Motivation 2: A software-based implementation of Demeter
still incurs a lot of unnecessary data movement for Steps 2 , 3 ,
and 4 . A hardware accelerator, especially a PIM-enabled one,
can mitigate this problem greatly.

Therefore, we propose a PIM-enabled hardware accelerator
for Demeter using PCM cells. One can accelerate Demeter
using a PIM-enabled design on different memory technolo-
gies. We choose a memristor-enabled design for three main
reasons. First, it is well-known that memristor-based memory
technologies can perform vector-matrix multiplication [61–64]
using Kirchhoff’s law efficiently, making them suitable for
our design.
In this work, we manage to propose a hybrid
row-major/column-major data mapping and intelligent data
duplication scheme to perform encoding, classification, and
profiling efficiently on PCM devices using this operation. Other
technologies than memristors do not offer the same features
for our hybrid data mapping.

Second, traditional technologies, such as non-memristor-
based ones, are generally general-purpose and cost-driven.
Moreover, their design does not allow even simple circuit mod-
ifications without high penalty on the area and cost. This makes
them face a lot of pushback from the industry and unlikely to
see future adoption. One of the advantages of memristors over
them is their high density and scalability, and previous works
show a wide range of accelerators using them.

Third, researchers already show the potential of accelerators
based on emerging technologies for other ML-based algorithms
[62, 65]. Also, multiple memory technologies already exist in
current sequence machines. Therefore, it is not unreasonable
to imagine one sort of these emerging memory technologies
also be installed in these machines, especially for performing
ML-based algorithms such as those for base-calling that are
necessary for the sequencers [66].

In this work, we focus on PCM devices, as a member of the
family of memristor devices, due to our accessibility to accurate

device measurements and models for these devices and leave
exploring other technologies for future research.

fit from a non-intrusive (compatible) random number generator
in the future.

5.1. Overview of Demeter’s Accelerator

Figure 7: Overview of Demeter’s in-memory accelerator.
Fig. 7 shows an overview of the proposed PIM-enabled hard-
ware accelerator for Demeter, Acc-Demeter. Acc-Demeter con-
sists of 5 key elements: 1 Item Memory (IM), 2 Encoder, 3
Associate Memory (AM), 4 Distance calculator, and 5 Con-
troller. IM and AM units are memory units, and we implement
them as PCM arrays with their control circuitry. However,
the encoder and distance calculator units are computing units
implemented as the periphery. The controller is a simple FSM
designed to harmonize the required steps of Demeter. The CPU
initiates Demeter by gathering the user’s input (Step 1 ) and
then booting the controller; i.e., it sends the start command,
initializes the registers, and sets the addresses to consider for
food samples and/or reference genomes in the controller. In a
nutshell, Acc-Demeter accelerates Steps 2 , 3 , and 4 of Deme-
ter. The controller returns the results of Step 4 to the CPU
for final processing and performing the relative abundance
estimation (Step 5 ). We will discuss these units in more detail
next.

5.2. Item Memory (IM) Design

We implement our IM using PCM arrays and corresponding
circuits, such as decoders. IM stores the atomic HD vectors.
Binary “0” and binary “1” in an HD vector translate to amor-
phous and crystalline states, respectively. In the beginning,
the user (or Demeter) generates 4 HD vectors for each DNA
alphabet in Step 1 of Demeter and stores them in the IM. Acc-
Demeter reads these atomic HD vectors from IM every time
it meets a new symbol. Once Demeter fixes the HD space,
IM becomes a read-only memory. This allows us to prevent
unwanted changes to the atomic vectors.

Fig. 8-(A) presents the IM design. The gate enabler provides
access to cells that the row decoder activated. This way, the
design of an entire array is achieved much easier, and the
write/read disturbance effect is also mitigated to a great ex-
tent. However, this design also blocks the write on a row basis
and only allows column-wise programming of IM. This does
not complicate IM in any way because the atomic vectors are
generated once in the beginning by the host CPU and then
stored in the IM for a long time. Note that random number
generators are already well-optimized in CPUs. In addition,
randomly generated values inside memristors are still in early
stages [67–69], and Acc-Demeter can be modified later to bene-

Figure 8: (A) IM design. (B) Data Mapping and placement of
atomic HD vectors in IM.

Fig. 8-(B) presents (1) data mapping and (2) placement of
HD vectors in the IM unit. Note that data mapping is a critical
contribution of Acc-Demeter. Acc-Demeter uses a hybrid row-
major and column-major data mapping for IM and AM units,
respectively. IM enjoys a row-major data mapping for two
reasons. First, a row-major data mapping of HD vectors allows
Acc-Demeter to read the cells written in one row in one cycle.
This is helpful as IM is used in the encoding procedure, which
is the bottleneck. Second, the used PCM model provides more
#columns than #rows. Therefore, even if there was a method
to read column cells all at once but separately, one could only
store smaller chunks of an HD vector on that column.

An important design choice regarding IM is related to the
limited size of PCM arrays (512×2048 [41]). This limitation of
array size (which also exists in mature memory technologies
such as DRAM) prevents us from fitting an entire large HD
vector in one row or column. Therefore, one needs to break
such an HD vector into smaller chunks and store them in sep-
arate rows. Three options exist: (1) putting the chunks in the
same array, (2) putting them in different arrays, (3) a hybrid
approach. As shown in Section 7, encoder is the bottleneck
of our operation. Therefore, to prevent exacerbating the over-
head of the encoding procedure, IM breaks a HD vector to
the largest power of two that is smaller than the number of
columns available in an array (2048 in our case) and stores
different chunks on different arrays. This is a direct tradeoff
between the used area (#arrays) and performance. Fig. 8-(B)
also shows this placement.

5.3. Encoder Design

The encoder is the main compute unit of Acc-Demeter. The
encoder is implemented in the periphery of arrays and exe-
cutes the binding and bundling operations via a sequence of
commands determined by the controller. Demeter is capable
of handling different representations (Section 3). However, to
reduce the complexity and make the design hardware friendly,
the current design of Acc-Demeter only supports binary rep-
resentations. In this setup, the N-gram encoding mechanism
is the most common one, which Acc-Demeter supports. We
suspect other choices are possible with the same hardware or
minimal changes. We leave the exploration of those designs
for future work.

8

Controller5ArraysPeripherialsArraysPeripherialsCPU14-b5CPU14-b5IMEncoder1223IMEncoder1223AMDistance Calculator344-aAMDistance Calculator344-a. . .. . .. . .. . .Gate Enabler / ControllerRead/Query HD VectorB_1B_2B_(n)SASASA. . .. . . . .. . . . .. . . . .. . . . .. . . . .. . . . .. . . . .. . . . .. . .# Atomic HD VecsDimension of HD Vecs. . . . .. . . . .. . . . .. . . . .. . .# Atomic HD VecsDimension of HD Vecs(B)(A)Based on Equation 1, building an N-gram requires only sim-
ple XOR and shift operations. This bitwise XOR operation
can be quickly computed after reading the atomic HD vector
from the IM with an XOR gate in the periphery. Note that one
can also implement XOR using bitwise AND (∧) and OR (∨).
However, this technique requires breaking the XOR operations
into minterms whose numbers increase exponentially. Any
attempt to reduce them, even if empirically works as in [41],
will only produce approximated results and hurt the accuracy.
Although some applications can tolerate such extreme accu-
racy loss, food profiling cannot. Note that the 2-minterm based
encoding in [41] also affects the sparsity of N-grams (acknowl-
edged in the paper) and limits the size of the N-gram. However,
this is not the case in Acc-Demeter because all the operations
accurately use XOR gates. This way, Acc-Demeter can benefit
from larger N-grams and does not hurt the density of the HD
vectors. As discussed in Section 4.3, the shift operation can
quickly become a bottleneck for large HD vectors and strings
in a software-based implementation. However, this does not
happen here since Acc-Demeter realizes the shift for free by
simply redirecting each Flip-Flop (FF)’s stored value to the
neighboring one every clock cycle. Fig. 9 depicts a schematic
illustration of the encoder unit.

Figure 9: Encoder components and schematic.

From the hardware perspective, the encoder distinguishes
the binding and bundling components completely. For the
binding, the SA reads out the value from IM to one input of an
XOR gate and uses the previously stored value of neighbor FFs
as the second input. The encoder then stores the results in a
buffer and repeats the procedure. This design choice provides
Acc-Demeter with the cascaded logical operations, with min-
imum changes to the memory array, and prevents any write
back and pressuring the endurance of the PCM substrates. The
encoder performs this sequence N times (enforced by the sig-
nals from the controller) to build an N-gram. After it finishes
creating one N-gram, it passes the N-gram to the bundler unit,
resets the buffer, and starts building the next N-gram until it
hits either the last character of the input or set limit per the
final HD vector.

The bundler takes N-grams and adds them to a global HD
vector that presents each position with a counter instead of
only one bit per position. It then repeats this operation for
M N-grams. Finally, the bundler applies a threshold (T) and
makes a final binary HD vector representing all the processed

9

characters while building this vector. At this point, the encoder
is done. It passes the results to be stored as prototype HD
vectors or used as query HD vector in AM and resets both the
integer-based and binary HD vectors.

5.4. Associate Memory (AM) Design

The AM unit is implemented using PCM arrays and their
corresponding circuitry, similar to the IM unit. This unit takes
the output of the encoding mechanism (an HD vector) as input.
Although the AM and the IM can technically be combined, Acc-
Demeter considers separate hardware for three reasons. First,
these units serve in subsequent and completely different steps
in a profiling pipeline, naming encoding, and classification step.
Such a distinct separation enables building a pipeline for them.
Second, row-major and column-major data mapping in IM
and introduce different parallelism opportunities for encoding
and classification steps of a profiling pipeline, respectively.
Row-major data mapping of IM parallelizes encoding of all
bits in a single HD vector in each clock cycle. On the other
hand, column-major mapping parallelizes the similarity check
of one query HD vector with all prototype HD vectors stored
vertically in that clock cycle. Third, separate hardware helps
us to simplify IM design by using sense amplifiers instead of
ADCs. Doing so brings various benefits in terms of area saving,
energy consumption, and read-out time. Note that ADCs are
usually the bottleneck of a memristor-based memory in terms
of energy, area, and time [70] and that is why one only uses
them when VMM or other logical operations such as Scouting
Logic [43] are necessary.

Equation 2 shows that for the classification, we need to count
the differences between the query HD vector and each proto-
type HD vector and then decide whether or not it can belong
to the corresponding class. Although one can realize this in
hardware by performing XNOR operation between the two
vectors followed by a pop-count operation all in the periph-
ery, such design comes with two drawbacks: (1) it requires
the pop-count operation even after the XNOR, which intro-
duces an enormous area cost and significant delay (log2D + 1
cycles [71]), and (2) the AM unit, similar to the IM, only allows
to write columns, not the rows. Since prototype HD vectors
are not known from the beginning (unlike atomic HD vectors),
this limitation forces us to save them all in another extra unit
first and then write them back on a row basis. This is again
inefficient.

However, Acc-Demeter proposes a new column-major data
mapping and intelligent data duplication for this unit and ex-
ploits the characteristics of the PCM substrate to solve all these
problems for HDC-based classification. It is well-known that
memristor-based memory technologies can perform vector-
matrix multiplication [61–64]. Therefore, Acc-Demeter imple-
ments the required XNOR and following pop-count operations
in Equation 2 in four steps, three of which happen in the unit
and the last one in the Similarity Check unit.

Step 1: Acc-Demeter stores one prototype HD vector (or a
chunk of one HD vector) in one column and its complement in
the same column number of a second array. Fig. 10-A shows
their placement in the AM unit. Step 2: Acc-Demeter applies

IM. . .. . .. . .EncoderBinderBundlerEncoderBinderBundlerthe query HD vector (Q) to the rows of the first array and
the complement of the query HD vector ( ¯Q) to the rows of
the second array with complement prototype HD vectors (Ps),
shown in Fig. 10-B. Step 3: Acc-Demeter enables columns
consecutively and effectively read out the number of ones in
Q.P and ¯Q.¯P in ADCs of each array. This way, it performs
two vector-matrix multiplications using Kirchhoff’s law, one
between Q and all Ps in the first array and one between ¯Q
and all ¯Ps. Section 5.5 describes Step 4 that realizes XNOR
and pop-count operation simultaneously. Fig. 10-B presents a
high-level illustration of AM design.

Figure 10: (A) Data mapping and placement of prototype HD
vectors in, (B) High-level design, and (C) Partial hardware for
Similarity Check unit.

Similar to the case in IM, the limited array size of PCM
substrates also prevents Acc-Demeter from storing a full HD
vector in one row or column of AM. To reduce the required
area, and since the encoding is the bottleneck and not the
classification (Section 7), in the AM, unlike IM, Acc-Demeter
stores the chunks of HD vectors in the same array. Fig. 10-
A takes a color-coding approach and depicts the way Acc-
Demeter breaks prototype HD vectors into multiple chunks
and stores them in columns of AM in and among tiles. It is
worth noting that Acc-Demeter only writes to the PCM cells
once in both IM and AM units unless either the configuration
file in Step 1 or the default reference genome database in
Step 2 changes, as a request by the user, for example. This
prevents many writes to the devices, which still have limited
endurance compared to traditional memory technologies.
5.5. Similarity Check Hardware

The similarity check unit is a small computing unit that takes
the two ADCs’ output of similar columns from the two cross-
bars and adds them together (Step 4). Fig. 10-C depicts all the
logic for this unit. The output of this unit is the results of XNOR
and pop-count together. At this stage, the similarity check unit

10

sends the results out to the host CPU to determine whether the
similarity is close to the threshold and should be considered
in the abundance estimation ( 4 -b, and 5 ). The reason behind
sending the results out instead of a winner-take-all (WTA)
circuit used in previous works [41, 72] is two-folded. First, a
WTA circuit assumes that the query matches one and only one
prototype HD vector. However, as discussed in Section 3.4 and
3.5, this is not always the case when profiling the genomics
data. Second, the relative abundance estimation techniques
(Step 5 in Fig. 1), although simple, require more complex and
area-hungry logic circuits, which Acc-Demeter aims to avoid
whenever possible. Therefore, since the results will be analyzed
outside the PCM-substrate anyway and transferring such small
data can be easily handled by interconnects between the host
and Acc-Demeter, Acc-Demeter relies on the host CPU to per-
form the final steps of Demeter. Note that the host is aware of
prototype HD vectors’ mappings.

5.6. Controller Unit

The controller orchestrates all the operations of Acc-Demeter
by generating control signals for other components. It gets
the start signal and the address of food samples (or reference
genomes) in the memory as its inputs. The controller outputs
the results of the similarity check unit back to the host for the
final steps. The controller is designed as a simple FSM machine
and operates based on parameters set in Step 1 .

6. System Integration of Acc-Demeter

This section discussed Acc-Demeter’s system integration
stack that enables it to operate with the host processing system.

6.1. Address Translation

Acc-Demeter works with physical addresses instead of vir-
tual ones and is relieved of address translation challenges that
exist and are dealt with in previous works [73, 74]. The CPU
host uses the same translation lookaside buffer (TLB) lookup
mechanism for normal load/store operations to translate in-
structions’ virtual memory addresses into their physical ad-
dresses when we have a Acc-Demeter’s instruction.

6.2. Coherence

Acc-Demeter may require modified and/or generated atomic
vectors (for the IM units) or loaded prototype vectors (for the
AM units). Similar to previous works [75–77], ensuring that
data for Acc-Demeter is up-to-date is a responsibility for pro-
grammers and can be achieved easily by flushing cache lines.
Acc-Demeter is also capable of leveraging previous PIM coher-
ence optimizations [78, 79] for further performance improve-
ment.

6.3. Interrupts

We assume that the pages required by Acc-Demeter’s AM
and IM units are already present. When this is not the case, we
rely on the conventional mechanisms for handling the page
faults to place this data into the correct arrays. Therefore, Acc-
Demeter does not face page fault during the execution of food
profiling since pages used by Acc-Demeter are already loaded
and pinned into AM and IM units. Acc-Demeter may, however,
face an interrupt during a context switch. In such cases, the

. . .. . .. . .. . .Gate Enabler / Controller. . .. . .ADCs. . .. . .. . .. . .Gate Enabler / ControllerRead/Query HD Vector. . .. . .P1P2P(n). . .Buffer and PCI_X. . .Buffer and PCI_XADCsP(n)P(n)P2P2P1P1. . .. . .Analog MUXAnalog MUXAnalog MUXAnalog MUX.   .   .   .   ..   .   .   .   .. . .Chunk of HD Vecs.   .   .   .   .. . .Chunk of HD Vecs(A)(B)(C)Read/Query HD Vector.   .   .   .   ..   .   .   .   ..   .   .   .   .context of the control unit in Acc-Demeter will be saved and
then restored when the profiler resumes.

6.4. ISA Extensions and Programming Interface

An expressive and efficient programming interface is a must
for Acc-Demeter as it directly impacts the usability of Deme-
ter framework. To enable easy communication between Acc-
Demeter and the programmer, we envision extending the ISA
with a few instructions to let the control unit know the required
operations, their timing, and where data objects reside in IM
and AM units. ISA extension is possible due to the unused
opcode space in the host CPU and has also been adopted in
previous PIM-related architectures [36, 73].

Acc-Demeter requires 2 types of instructions: (1) bbop init
initialization of IM and AM units and (2)
address, size, n:
bbop op size, n: instructions for performing different opera-
tions in Acc-Demeter. bbop init is the initialization instruction
informs the OS that the memory object is for Acc-Demeter.
This way, the OS performs virtual-to-physical memory map-
ping required for AM and IM units. bbop init takes the base
physical address, the size of the vector, and the intended value.
For Acc-Demeter’s operations, we extend the CPU ISA with
bbop op. Acc-Demeter utilizes an array-based computation
model, i.e., src and dst are the source and destination arrays.
bbop op is the opcode, where size and n are #elements in the
array and #bits in each array element, respectively. This pa-
per assumes that the programmer will manually write suitable
code for Acc-Demeter operations. We summarized the required
CPU ISA extensions for these operations in Table 1.

Type

Initialization
Input Operation

ISA Format
bbop init, address, size, n
bbop op, size, n

Table 1: Acc-Demeter ISA Extensions.

7. Acc-Demeter’s Evaluation

7.1. Methodology

We emulate the execution of Acc-Demeter using a cycle-
accurate RTL model and synthesized it using UMC 65 nm tech-
nology node in Synopsys Design Compiler [80]. We verify the
correct behavior of our memory model using test benches and
previous in-memory simulators [41, 62]. We consider a typical
operation condition of temperature 25°and voltage 1.2V when
evaluating our energy consumption. All the experiments for
the PCM-based Acc-Demeter are carried out based on PCM sta-
tistical models that capture the variations in the spatiotemporal
conductivity of the devices. PCM prototypes and analytical
models used for validation and further simulations are based on
the results of EU project MNEMOSENE [81], led and concluded
by TU Delft in 2020. Table 2 shows the other parameters of our
PCM crossbars.

Technology
Current on Conducting Devices
Read Voltage
Read/Write Latency
ADC

2

PCM (512*2048 @1bit), Cell Size = 50 F
0.1 µA
0.1 V
Read=2.8 ns, write=100 ns
9 bits resolution, 2 ns, 4 pJ per sample

Table 2: PCM configuration.

7.2. Acc-Demeter’s Performance Analysis

This section compares the performance of SOTA profilers
compared to Acc-Demeter, our PIM-enabled accelerator design
of Demeter.
7.2.1. Build time.. Fig. 11 shows the build time that each
profiler takes to build its initial data structure for two reference
databases AFS20 and AFS31.

Figure 11: Build time on (a) AFS20 and (b) AFS31.

We make two observations. First, Acc-Demeter has the low-
est build time among all previous food profilers. Acc-Demeter
builds HD-RefDB corresponding to AFS20 and AFS31 ∼3.2x
and 2.8x faster, respectively, than MetaCache, the next fastest
profiler. Unlike previous HDC-based methods that are faster
than their ML competitors due to the one-shot learning ability
of HDC paradigm, Acc-Demeter outperforms SOTA profilers
due to its highly parallelized performance and simple oper-
ations being performed on Acc-Demeter’s hardware. SOTA
food profilers parse the reference genomes only once, and the
one-shot learning of Demeter is not particularly advantageous.
Second, CLARK exceeds the 500 GB memory of the system
when running it for AFS31. This is in line with observations
in [4]. Therefore, we excluded it from all analyses regarding
AFS31 from now on. This case shows an excellent example of
where metagenomic profilers, whereas good for lengthy and
costly studies, may not be applicable for the scenario of food
profiling and later food analysis and monitoring.
7.2.2. Query time.. Fig. 12 presents the time that each profiler
takes to query one (short) read from the query food sample
and classify its specie(s) over AFS20 and AFS31.

Figure 12: Query time on (a) AFS20 and (b) AFS31.

We make two key observations. Acc-Demeter improves the
query time by ∼74x/88x and 272x/350x compared to Kraken2

11

and MetaCache, respectively, on AFS20/AFS31. This shows
that the acceleration of Demeter pays off and finally makes
Demeter not only an accurate but also a fast food profiler.

Second, the query time for Acc-Demeter remains almost
the same for both databases and does not change much. We
further investigate this and realize a bottleneck shift: Step 5 or
abundance estimation that is being performed inside the CPU
is now the bottleneck of Acc-Demeter. This happens because
of the high-frequency Acc-Demeter achieved. However, this
contrasts with other profilers that spend most of their time
querying their massive data structure.
7.2.3. Query throughput.. Fig. 13 shows the throughput of
different profilers over AFS20 and ASF31.

Figure 13: Query throughput on (a) AFS20 and (b) AFS31.

We make two observations. First, Acc-Demeter provides
throughput improvement of ∼192x and 232x for both AFS20
and AFS31, respectively, compared to Kraken2, the second
food profiler regarding throughput. This more remarkable
improvement in throughput than query time results from Acc-
Demeter’s ability to classify one query read in parallel with
the encoding of the following query. Note that the throughput
analysis of the previous profiler does not consider the time for
loading their data structure. Second, similar to the query time,
throughput is almost the same regardless of the database due
to the bottleneck shift. We conclude that Acc-Demeter signifi-
cantly outperforms all four SOTA baselines for all performance
metrics.

7.3. Acc-Demeter’s Power and Area Analysis

Table 3 provides the area and energy consumption break-
down of different components in Acc-Demeter per query on
AFS31.

Unit

IM
Encoder
AM
Similarity

Area (mm
0.07
1.375
0.15
0.1815

2)

Area (%)

3.1
78.3
8.4
10.2

Energy (nj)
1.179E-06
1.43E-05
2.47E-07
6.91E-08

Energy (%)

7.4
90.6
1.56
0.4

Table 3: Area and power breakdown of Acc-Demeter.

We make two observations. First, the logic for the encoder
unit is the most energy and area hungry unit among all others,
more than 90% and 78% energy and area of the whole Acc-
Demeter. This is expected because (1) the encoder consists of

12

many CMOS circuits, whereas AM and IM are small memory
units with PCM technology, and (2) the encoder is in the heart
of all operations in Demeter, and we spend most of our time
in this unit. We argue that this amount of logic around our
array is still justifiable. Second, compared to the die area in an
Intel Xeon E5-2697 CPU [82], Acc-Demeter only has an area
overhead of less than 2%. We conclude that Acc-Demeter is
low-cost in terms of die area.

Our evaluations show that Acc-Demeter can perform a
9.45Mbp query per joule. Unfortunately, measuring the en-
ergy consumption of other profilers and having an apple-to-
apple comparison between the energy consumption of this
method with other ones is hard. However, Merelli et al. [83,84]
show that running Kraken2 with querying an even smaller
data structure built from a reduced reference genome dataset,
minikraken [83, 85], can incur more energy (maximum of
0.6 Mbp
). This considerable difference happens because of three
reasons: (1) Kraken2 queries a more complex data structure
compared to Acc-Demeter and requires more complex opera-
tions, (2) Kraken2 queries a bigger data structure for its query,
and (3) Kraken2 incurs significant data movement between
the memory and the processing unit. All of these limitations
exist in similar forms in CLARK and MetaCache. We conclude
that Acc-Demeter is more energy-efficient than all four SOTA
baselines.

j

8. Discussions and Future Works
Capacity. We define the capacity of Demeter as the ratio be-
tween the number of reference genomes encoded as prototype
HD vectors to the size of HD space for a competitive profil-
ing accuracy target. The higher #prototype HD vectors are,
the bigger capacity is needed, resulting in bigger HD space
and lower efficiency. Therefore, if one uses Demeter, as is,
as a metagenomics profiler, they cannot expect similar im-
provements compared to SOTA metagenomics profilers (e.g.,
Kraken2, on those datasets. We are currently investigating
the additional techniques to enable Demeter for those cases as
well. However, we leave further analysis of required changes
to Demeter for supporting metagenomics profiling or other
profiling studies with many reference genomes for future work.
Supported functions and representations. As discussed
(Sections 2, 3, and 5), Acc-Demeter currently supports only
binary representations and N-gram encoding mechanism. This
design choice is made for simplicity and is based on acceptable
accuracy results of the software version. We leave the hardware
for other encoding mechanisms and data representations for
future work.

9. Related Works

To our knowledge, Demeter is the first paper to propose a
framework to perform food profiling using HDC. Acc-Demeter
is also the first hardware accelerator that enables low-cost and
accurate in-memory profiling for a typical reference database
in food profilers. We have already compared Demeter and Acc-
Demeter extensively to SOTA profilers in Sections 4 and 7. This
section briefly discusses previous software works for profilers
(food or metagenomics), software or hardware of HDC-based

systems, and PIM-enabled accelerators.

9.1. Metagenomic Profilers

Several recent works propose approaches and techniques
to directly or indirectly accelerate or improve the accuracy of
metagenomics profiling, the first step of such studies. These
(1) Reducing the reference
works take three approaches:
database’s size by pre-alignment filtering [86, 87] or heuris-
tics for taxonomic classification techniques [55, 88–91], (2)
Accelerating read alignment or assembly (only for alignment-
/assembly-based profilers) on CPUs, FPGAs, or GPUs [92–
98], (3) post-alignment/-assembly/-classification presence and
abundance estimation heuristics [54, 55, 99]. Demeter is catego-
rized in the first group, taking a HDC-based approach for the
first time. However, compared to the first group, Acc-Demeter
is much faster and has a lower cost (regarding both energy and
area consumption). Note that Demeter and Acc-Demeter are
orthogonal to works in the third group, and their Step 5 can
adapt their proposed techniques for the abundance estimation
after the initial classification.

9.2. HDC-based Systems

Many works exploit the HDC paradigm for specific machine
learning applications that require capturing temporal patterns.
These works vary from language [100] and voice [101] detec-
tion to seizure detection [102]. Demeter is the first work that
investigates HDC in the realm of profiling genomics data. Al-
though HDNA [48] and GenieHD [103] propose to use HDC for
(partial5) sequence alignment of a single reference genome di-
vided into multiple pieces, they never exploit it for any metage-
nomics or food profiling.

A few works also suggest various hardware platforms such
as FPGAs, GPUs, or ASICs [41, 48] to improve the performance
of HDC-based designs. Acc-Demeter is different from all of
these designs in two important aspects. First, Acc-Demeter
performs an exact pop-count operation in one cycle, perform-
ing two VMM in parallel and then adding the outputs of ADCs.
This is in contrast to previous works [41, 48, 102, 103] that per-
form an exact pop-count operation in log2D + 1 cycles, where D
is the size of an HD vector. Second, unlike [41], Acc-Demeter
can perform the required HDC-based operations on long, non-
sparse N-grams (discussed in Section 5.3). To our knowledge,
Acc-Demeter is the only PIM-enabled accelerator for food pro-
filing.

9.3. PIM-enabled Accelerators

Prior works also heavily investigate various forms of
compute-capable memories [36, 104, 105]. Among these, only a
few use in-memory capability for HDC designs [41, 106]. How-
ever, these works are either tuned for single tasks or capable of
limited sizes for N-grams like only up to 3-grams [106], or only
based on compact models from small prototypes with 256×256
ReRAM arrays. Demeter is the first work that proposes food
profiling inside the memory. Theoretically, one can accelerate
Demeter using a PIM-enabled design on DRAM, SRAM, and

5Neither HDNA nor GenieHD is capable of producing the exact type and
location of edits between their query and the reference genome as in the typical
outputs (.sam file) of a sequence aligner. Hence, the term ”partial”.

other technologies. However, for the reasons iterated in Sec-
tion 5, Acc-Demeter exploits PCM to improve the performance
of Demeter.

10. Conclusion

This paper introduces Demeter, the first framework that en-
ables profiling of food samples via HDC whereas strictly meet-
ing the accuracy of state-of-the-art profilers. Demeter uses a
five-step approach to enable species-level profiling using HDC.
This paper also introduces the first PCM-baed PIM-enabled
hardware accelerator, called Acc-Demeter. We evaluate Deme-
ter on software and Acc-Demeter using a cycle-accurate model
based on a small-scale PCM-based prototype. We design Deme-
ter and Acc-Demeter to (1) address the key challenge of HDC-
systems when facing a massive input, (2) eliminate the need for
a powerful machine with very large memories, and (3) prevent
unnecessary data movement between memory and process-
ing units and therefore prevent wasting time and energy. We
achieve significant performance and energy benefits over the
SOTA CPU implementations whereas achieving the same accu-
racy. We hope that future work builds on top of our framework
and its hardware and extends it to further improve our food
profiling systems.

Acknowledgments

We thank the members of the SAFARI Research Group at
ETH Zurich and the Quantum & Computing Engineering at
TU Delft for their valuable feedback and the constructively
critical environment that they provide. We specifically thank
Abhairaj Singh for his feedback regarding PCM devices and
circuit designs. We acknowledge the generous gifts provided
by our industry partners, including Google, Huawei, Intel,
Microsoft, and VMware. We acknowledge support from the
ETH Future Computing Laboratory and the Semiconductor
Research Corporation.

References

[1] D. J. Agnew, J. Pearce, G. Pramod, T. Peatman, R. Watson, J. R. Bed-
dington, and T. J. Pitcher, “Estimating the worldwide extent of illegal
fishing,” PloS one, 2009.

[2] R. Smith, “Rural rogues: a case story on the “smokies” trade,” Inter-
national Journal of Entrepreneurial Behavior & Research, 2004.
[3] R. Smith, “Documenting the UK “Black Fish Scandal” as a case study
of criminal entrepreneurship,” International Journal of Sociology and
Social Policy, 2015.

[4] R. Kobus, J. M. Abu´ın, A. M¨uller, S. L. Hellmann, J. C. Pichel, T. F. Pena,
A. Hildebrandt, T. Hankeln, and B. Schmidt, “A big data approach to
metagenomics for all-food-sequencing,” BMC bioinformatics, 2020.
[5] F. Ripp, C. F. Krombholz, Y. Liu, M. Weber, A. Sch¨afer, B. Schmidt,
R. K¨oppel, and T. Hankeln, “All-Food-Seq (AFS): a quantifiable screen
for species in biological samples by deep DNA sequencing,” BMC
genomics, 2014.

[6] Wetterstrand KA., “DNA Sequencing Costs: Data from the NHGRI
Genome Sequencing Program (GSP),” https://www.genome.gov/seq
uencingcostsdata.

[7] Barba, M, Czosnek, H and Hadidi, A, “Cost in US Dollars per Raw
Megabase of DNA Sequence,” https://www.genome.gov/about-gen
omics/fact-sheets/DNA-Sequencing-Costs-Data.

[8] M. Alser, Z. Bing¨ol, D. S. Cali, J. Kim, S. Ghose, C. Alkan, and O. Mutlu,
“Accelerating Genome Analysis: A Primer on an Ongoing Journey,”
IEEE Micro, 2020.

[9] J. Handelsman, M. R. Rondon, S. F. Brady, J. Clardy, and R. M. Good-
man, “Molecular biological access to the chemistry of unknown soil
microbes: a new frontier for natural products,” Chemistry & biology,
1998.

13

[10] M. R. Rondon, P. R. August, A. D. Bettermann, S. F. Brady, T. H.
Grossman, M. R. Liles, K. A. Loiacono, B. A. Lynch, I. A. MacNeil,
C. Minor et al., “Cloning the soil metagenome: a strategy for accessing
the genetic and functional diversity of uncultured microorganisms,”
Appl. Environ. Microbiol., 2000.

[11] J. C. Wooley, A. Godzik, and I. Friedberg, “A primer on metagenomics,”

PLoS Comput Biol, 2010.

[12] D. E. Wood, J. Lu, and B. Langmead, “Improved Metagenomic Analy-

sis with Kraken 2,” Genome biology, 2019.

[13] A. E. P´erez-Cobas, L. Gomez-Valero, and C. Buchrieser, “Metagenomic
approaches in microbial ecology: an update on whole-genome and
marker gene sequencing analyses,” Microbial Genomics, 2020.
[14] A. B. McIntyre, R. Ounit, E. Afshinnekoo, R. J. Prill, E. H´enaff,
N. Alexander, S. S. Minot, D. Danko, J. Foox, S. Ahsanuddin et al.,
“Comprehensive benchmarking and ensemble approaches for metage-
nomic classifiers,” Genome biology, 2017.

[15] F. P. Breitwieser, J. Lu, and S. L. Salzberg, “A Review of Methods and
Databases for Metagenomic Classification and Assembly,” Briefings
in bioinformatics, 2019.

[16] L. Ge and K. K. Parhi, “Classification using hyperdimensional com-
puting: A review,” IEEE Circuits and Systems Magazine, 2020.
[17] D. Kleyko, A. Rahimi, D. A. Rachkovskij, E. Osipov, and J. M. Rabaey,
“Classification and Recall with Binary Hyperdimensional Computing:
Tradeoffs in Choice of Density and Mapping Characteristics,” IEEE
transactions on neural networks and learning systems, 2018.

[18] H. A. D. Nguyen, J. Yu, M. A. Lebdeh, M. Taouil, S. Hamdioui, and
F. Catthoor, “A classification of memory-centric computing,” JETC,
2020.

[19] S. Hamdioui, L. Xie, H. A. Du Nguyen, M. Taouil, K. Bertels, H. Corpo-
raal, H. Jiao, F. Catthoor, D. Wouters, L. Eike et al., “Memristor based
computation-in-memory architecture for data-intensive applications,”
in DATE, 2015.

[20] Intel, “Intel VTune Amplifier 2019 User Guide.” https://software.inte

l.com/en-us/vtune-amplifier-help, 2018.

[21] L. Wu, R. Sharifi, M. Lenjani, K. Skadron, and A. Venkat, “Sieve: Scal-
able In-situ DRAM-based Accelerator Designs for Massively Parallel
k-mer Matching,” in ISCA, 2021.

[22] M. Zhou, L. Wu, M. Li, N. Moshiri, K. Skadron, and T. Rosing, “Ul-
tra Efficient Acceleration for De Novo Genome Assembly via Near-
Memory Computing,” in PACT, 2021.

[23] P. Kanerva, “Hyperdimensional Computing: An Introduction to Com-
puting in Distributed Representation with High-Dimensional Ran-
dom Vectors,” Cognitive computation, 2009.

[24] R. W. Gayler, “Vector symbolic architectures answer Jackendoff’s
challenges for cognitive neuroscience,” arXiv preprint, 2004.
[25] F. R. Najafabadi, A. Rahimi, P. Kanerva, and J. M. Rabaey, “Hyperdi-
mensional computing for text classification,” in DATE, 2016.
[26] D. Kleyko, E. Osipov, N. Papakonstantinou, V. Vyatkin, and
A. Mousavi, “Fault detection in the hyperspace: Towards intelligent
automation systems,” in INDIN, 2015.

[27] D. Kleyko, E. Osipov, R. W. Gayler, A. I. Khan, and A. G. Dyer, “Imita-
tion of honey bees’ concept learning processes using vector symbolic
architectures,” Biologically Inspired Cognitive Architectures, 2015.
[28] A. Rahimi, S. Benatti, P. Kanerva, L. Benini, and J. M. Rabaey, “Hy-
perdimensional biosignal processing: A case study for EMG-based
hand gesture recognition,” in ICRC, 2016.

[29] P. Kanerva, J. Kristoferson, and A. Holst, “Random indexing of text
samples for latent semantic analysis,” in Proceedings of the Annual
Meeting of the Cognitive Science Society, 2000.

[30] T. A. Plate, “Holographic reduced representations,” TNN, 1995.
[31] R. W. Gayler, “Multiplicative binding, representation operators &

analogy,” Workshop Poster, 1998.

[32] S. I. Gallant and P. Culliton, “Positional binding with distributed

representations,” in ICIVC, 2016.

[33] D. A. Rachkovskij, “Representation and processing of structures with
binary sparse distributed codes,” IEEE Transactions on Knowledge and
Data Engineering, 2001.

[34] S. I. Gallant and T. W. Okaywe, “Representing objects, relations, and

sequences,” Neural computation, 2013.

[35] T. A. Plate, “Holographic Reduced Representation: Distributed repre-

sentation for cognitive structures,” TNN, 2003.

[36] V. Seshadri, D. Lee, T. Mullins, H. Hassan, A. Boroumand, J. Kim,
M. A. Kozuch, O. Mutlu, P. B. Gibbons, and T. C. Mowry, “Ambit:
In-memory accelerator for bulk bitwise operations using commodity
DRAM technology,” in MICRO, 2017.

14

[37] B. C. Lee, E. Ipek, O. Mutlu, and D. Burger, “Phase change memory
architecture and the quest for scalability,” Communications of the
ACM, 2010.

[38] M. Kang, S. K. Gonugondla, A. Patil, and N. R. Shanbhag, “A multi-
functional in-memory inference processor using a standard 6T SRAM
array,” JSSC, 2018.

[39] E. Chen, D. Apalkov, Z. Diao, A. Driskill-Smith, D. Druist, D. Lottis,
V. Nikitin, X. Tang, S. Watts, S. Wang et al., “Advances and future
prospects of spin-transfer torque random access memory,” IEEE Trans-
actions on Magnetics, 2010.

[40] R. Waser, R. Dittmann, G. Staikov, and K. Szot, “Redox-based re-
sistive switching memories–nanoionic mechanisms, prospects, and
challenges,” Advanced materials, 2009.

[41] G. Karunaratne, M. Le Gallo, G. Cherubini, L. Benini, A. Rahimi,
and A. Sebastian, “In-memory hyperdimensional computing,” Nature
Electronics, 2020.

[42] Q. Xia and J. J. Yang, “Memristive crossbar arrays for brain-inspired

computing,” Nature materials, 2019.

[43] L. Xie, H. A. Du Nguyen, J. Yu, A. Kaichouhi, M. Taouil, M. Al-
Failakawi, and S. Hamdioui, “Scouting logic: A novel memristor-
based logic design for resistive computing,” in ISVLSI, 2017.

[44] L. Cheng, Y. Li, K.-S. Yin, S.-Y. Hu, Y.-T. Su, M.-M. Jin, Z.-R. Wang, T.-
C. Chang, and X.-S. Miao, “Functional demonstration of a memristive
arithmetic logic unit (memalu) for in-memory computing,” Advanced
Functional Materials, 2019.

[45] D. Ielmini and H.-S. P. Wong, “In-memory computing with resistive

switching devices,” Nature Electronics, 2018.

[46] H. Li, T. F. Wu, A. Rahimi, K.-S. Li, M. Rusch, C.-H. Lin, J.-L. Hsu, M. M.
Sabry, S. B. Eryilmaz, J. Sohn et al., “Hyperdimensional computing
with 3D VRRAM in-memory kernels: Device-architecture co-design
for energy-efficient, error-resilient language recognition,” in IEDM,
2016.

[47] T. F. Wu, H. Li, P.-C. Huang, A. Rahimi, J. M. Rabaey, H.-S. P. Wong,
M. M. Shulaker, and S. Mitra, “Brain-inspired computing exploit-
ing carbon nanotube FETs and resistive RAM: Hyperdimensional
computing case study,” in ISSCC, 2018.

[48] M. Imani, T. Nassar, A. Rahimi, and T. Rosing, “HDNA: Energy-
Efficient DNA Sequencing using Hyperdimensional Computing,” in
BHI, 2018.

[49] D. Kleyko, E. Osipov, A. Senior, A. I. Khan, and Y. A. S¸ekerciog˘glu,
“Holographic graph neuron: A bioinspired architecture for pattern
processing,” IEEE transactions on neural networks and learning systems,
vol. 28, no. 6, pp. 1250–1262, 2016.

[50] M. Imani, S. Pampana, S. Gupta, M. Zhou, Y. Kim, and T. Rosing, “Dual:
Acceleration of clustering algorithms using digital-based processing
in-memory,” in MICRO, 2020.

[51] K. Reinert, T. H. Dadi, M. Ehrhardt, H. Hauswedell, S. Mehringer,
R. Rahn, J. Kim, C. Pockrandt, J. Winkler, E. Siragusa et al., “The seqan
c++ template library for efficient sequence analysis: A resource for
programmers,” Journal of biotechnology, 2017.

[52] M. Harris et al., “Optimizing parallel reduction in cuda,” Nvidia de-

veloper technology, 2007.

[53] AMD, “AMD EPYC 7742 CPU.” https://www.amd.com/en/products/

cpu/amd-epyc-7742.

[54] N. LaPierre, S. Mangul, M. Alser, I. Mandric, N. C. Wu, D. Koslicki,
and E. Eskin, “MiCoP: Microbial Community Profiling Method for
Detecting Viral and Fungal Organisms in Metagenomic Samples,”
BMC genomics, 2019.

[55] N. LaPierre, M. Alser, E. Eskin, D. Koslicki, and S. Mangul, “Metalign:
Efficient Alignment-Based Metagenomic Profiling via Containment
Min Hash,” BioRxiv, 2020.

[56] Project: PRJEB34001, “Calibration sausages WGS containing mam-
malian and avian species,” https://www.ebi.ac.uk/ena/browser/view
/PRJEB34001.

[57] Project: PRJNA271645, “Calibration sausages Metagenome,” https:

//www.ebi.ac.uk/ena/browser/view/PRJNA271645.

[58] J. Lu, F. P. Breitwieser, P. Thielen, and S. L. Salzberg, “Bracken: Esti-
mating Species Abundance in Metagenomics Data,” PeerJ Computer
Science, 2017.

[59] R. Ounit, S. Wanamaker, T. J. Close, and S. Lonardi, “CLARK: fast
and accurate classification of metagenomic and genomic sequences
using discriminative k-mers,” BMC genomics, 2015.

[60] F. Meyer, A. Fritz, Z.-L. Deng, D. Koslicki, A. Gurevich, G. Robertson,
M. Alser, D. Antipov, F. Beghini, D. Bertrand et al., “Critical Assess-
ment of Metagenome Interpretation-the second round of challenges,”
bioRxiv, 2021.

[61] M. Hu, C. E. Graves, C. Li, Y. Li, N. Ge, E. Montgomery, N. Davila,
H. Jiang, R. S. Williams, J. J. Yang et al., “Memristor-based analog
computation and neural network classification with a dot product
engine,” Advanced Materials, 2018.

[62] M. Zahedi, M. Mayahinia, M. A. Lebdeh, S. Wong, and S. Hamdioui,
“Efficient organization of digital periphery to support integer datatype
for memristor-based cim,” in ISVLSI, 2020.

[63] S. Choi, J. H. Shin, J. Lee, P. Sheridan, and W. D. Lu, “Experimental
demonstration of feature extraction and dimensionality reduction
using memristor networks,” Nano letters, 2017.

[64] M. Zahedi, R. van Duijnen, S. Wong, and S. Hamdioui, “Tile Archi-
tecture and Hardware Implementation for Computation-in-Memory,”
in ISVLSI, 2021.

[65] A. Ankit, I. E. Hajj, S. R. Chalamalasetti, G. Ndu, M. Foltin, R. S.
Williams, P. Faraboschi, W.-m. W. Hwu, J. P. Strachan, K. Roy et al.,
“PUMA: A programmable ultra-efficient memristor-based accelerator
for machine learning inference,” in ASPLOS, 2019.

[66] Q. Lou, S. C. Janga, and L. Jiang, “Helix: Algorithm/Architecture Co-
design for Accelerating Nanopore Genome Base-calling,” in PCAT,
2020.

[67] G. Diarce, ´A. Campos-Celador, K. Martin, A. Urresti, A. Garc´ıa-
Romero, and J. Sala, “A comparative study of the cfd modeling of a
ventilated active fac¸ade including phase change materials,” Applied
Energy, 2014.

[68] S. Balatti, S. Ambrogio, Z. Wang, and D. Ielmini, “True random num-
ber generation by variability of resistive switching in oxide-based
devices,” Journal on Emerging and Selected Topics in Circuits and
Systems, 2015.

[69] F. M. Puglisi, N. Zagni, L. Larcher, and P. Pavan, “A new verilog-a
compact model of random telegraph noise in oxide-based rram for
advanced circuit design,” in ESSDERC, 2017.

[70] A. Shafiee, A. Nag, N. Muralimanohar, R. Balasubramonian, J. P.
Strachan, M. Hu, R. S. Williams, and V. Srikumar, “ISAAC: A convo-
lutional neural network accelerator with in-situ analog arithmetic in
crossbars,” ISCA, 2016.

[71] M. Imani, A. Rahimi, D. Kong, T. Rosing, and J. M. Rabaey, “Exploring

Hyperdimensional Associative Memory,” in HPCA, 2017.

[72] R. G. Carvajal, J. Ramirez-Angula, and J. Tombs, “High-speed high-
precision voltage-mode MIN/MAX circuits in CMOS technology,” in
ISCAS, 2000.

[73] J. Ahn, S. Yoo, O. Mutlu, and K. Choi, “PIM-enabled instructions: A
low-overhead, locality-aware processing-in-memory architecture,”
in ISCA, 2015.

[74] J. Picorel, D. Jevdjic, and B. Falsafi, “Near-memory address transla-

tion,” in PACT, 2017.

[75] N. Hajinazar, G. F. Oliveira, S. Gregorio, J. D. Ferreira, N. M. Ghiasi,
M. Patel, M. Alser, S. Ghose, J. G´omez-Luna, and O. Mutlu, “SIM-
DRAM: a framework for bit-serial SIMD processing using DRAM,”
in ASPLOS, 2021.

[76] A. Holdings, “Cortex-A8 Technical: Reference Manual,” 2010.
[77] P. Guide, “Intel® 64 and ia-32 architectures software developer’s
manual,” Volume 3B: System programming Guide, Part, vol. 2, no. 11,
2011.

[78] A. Boroumand, S. Ghose, M. Patel, H. Hassan, B. Lucia, K. Hsieh,
K. T. Malladi, H. Zheng, and O. Mutlu, “LazyPIM: An efficient cache
coherence mechanism for processing-in-memory,” IEEE Computer
Architecture Letters, 2016.

[79] A. Boroumand, S. Ghose, M. Patel, H. Hassan, B. Lucia, R. Ausavarung-
nirun, K. Hsieh, N. Hajinazar, K. T. Malladi, H. Zheng et al., “CoNDA:
Efficient cache coherence support for near-data accelerators,” in ISCA,
2019.

[80] Synopsys, Inc., “Synopsys Design Compiler,” https://www.synopsys
.com/support/training/rtl-synthesis/design-compiler-rtl-synthesis.
html.

[81] MNEMOSENE partners, “The MNEMOSENE project.” http://www.

mnemosene.eu/, 2020.

[82] D. Fujiki, S. Mahlke, and R. Das, “Duality cache for data parallel

acceleration,” in ISCA, 2019.

[83] I. Merelli, L. Morganti, E. Corni, C. Pellegrino, D. Cesini, L. Roverelli,
G. Zereik, and D. D’Agostino, “Low-power portable devices for
metagenomics analysis: Fog computing makes bioinformatics ready
for the Internet of Things,” Future Generation Computer Systems, 2018.

15

[85]

[84] D. D’Agostino, L. Morganti, E. Corni, D. Cesini, and I. Merelli,
“Combining edge and cloud computing for low-power, cost-effective
metagenomics analysis,” Future Generation Computer Systems, 2019.
¨O. Eyice, M. Namura, Y. Chen, A. Mead, S. Samavedam, and
H. Sch¨afer, “SIP metagenomics identifies uncultivated Methylophi-
laceae as dimethylsulphide degrading bacteria in soil and lake sedi-
ment,” The ISME journal, 2015.

[86] H. Xin, D. Lee, F. Hormozdiari, S. Yedkar, O. Mutlu, and C. Alkan,
“Accelerating read mapping with FastHASH,” in BMC genomics, 2013.
[87] M. Alser, T. Shahroodi, J. Gomez-Luna, C. Alkan, and O. Mutlu,
“SneakySnake: A Fast and Accurate Universal Genome Pre-Alignment
Filter for CPUs, GPUs, and FPGAs,” arXiv preprint arXiv:1910.09020,
2019.

[88] N. Segata, L. Waldron, A. Ballarini, V. Narasimhan, O. Jousson, and
C. Huttenhower, “Metagenomic microbial community profiling using
unique clade-specific marker genes,” Nature methods, 2012.

[89] B. Liu, T. Gibbons, M. Ghodsi, T. Treangen, and M. Pop, “Accurate
and fast estimation of taxonomic profiles from metagenomic shotgun
sequences,” Genome biology, 2011.

[90] D. E. Wood and S. L. Salzberg, “Kraken: Ultrafast Metagenomic Se-
quence Classification Using Exact Alignments,” Genome biology, 2014.
[91] R. Kobus, C. Hundt, A. M¨uller, and B. Schmidt, “Accelerating metage-
nomic read classification on CUDA-enabled GPUs,” BMC bioinfor-
matics, 2017.

[92] A. Brady and S. Salzberg, “PhymmBL expanded: confidence scores,
custom databases, parallelization and more,” Nature methods, 2011.
[93] J. Daily, “Parasail: SIMD C Library for Global, Semi-global, and Local

Pairwise Sequence Alignments,” BMC bioinformatics, 2016.

[94] S. S. Banerjee, M. El-Hadedy, J. B. Lim, Z. T. Kalbarczyk, D. Chen, S. S.
Lumetta, and R. K. Iyer, “Asap: Accelerated short-read alignment on
programmable hardware,” IEEE Transactions on Computers, 2018.
[95] X. Fei, Z. Dan, L. Lina, M. Xin, and Z. Chunlei, “Fpgasw: Accelerating
large-scale smith–waterman sequence alignment application with
backtracking on fpga linear systolic array,” Interdisciplinary Sciences:
Computational Life Sciences, 2018.

[96] E. J. Houtgast, V.-M. Sima, K. Bertels, and Z. Al-Ars, “An FPGA-
based systolic array to accelerate the BWA-MEM genomic mapping
algorithm,” in SAMOS, 2015.

[97] Y. Liu, A. Wirawan, and B. Schmidt, “CUDASW++ 3.0: Accelerating
Smith-Waterman Protein Database Search by Coupling CPU and
GPU SIMD Instructions,” BMC bioinformatics, 2013.

[98] R. Luo, T. Wong, J. Zhu, C.-M. Liu, X. Zhu, E. Wu, L.-K. Lee, H. Lin,
W. Zhu, D. W. Cheung et al., “SOAP3-dp: Fast, Accurate and Sensitive
GPU-based Short Read Aligner,” PloS one, 2013.

[99] D. T. Truong, E. A. Franzosa, T. L. Tickle, M. Scholz, G. Weingart,
E. Pasolli, A. Tett, C. Huttenhower, and N. Segata, “MetaPhlAn2 for
enhanced metagenomic taxonomic profiling,” Nature methods, 2015.
[100] M. Imani, J. Hwang, T. Rosing, A. Rahimi, and J. M. Rabaey, “Low-
power sparse hyperdimensional encoder for language recognition,”
Design & Test, 2017.

[101] Y. Kim, M. Imani, and T. S. Rosing, “Efficient human activity recogni-
tion using hyperdimensional computing,” in Proceedings of Conference
on the Internet of Things, 2018.

[102] A. Burrello, K. Schindler, L. Benini, and A. Rahimi, “Hyperdimen-
sional computing with local binary patterns: one-shot learning of
seizure onset and identification of ictogenic brain regions using short-
time ieeg recordings,” IEEE Transactions on Biomedical Engineering,
2019.

[103] Y. Kim, M. Imani, N. Moshiri, and T. Rosing, “Geniehd: Efficient dna
pattern matching accelerator using hyperdimensional computing,”
in DATE, 2020.

[104] S. Li, D. Niu, K. T. Malladi, H. Zheng, B. Brennan, and Y. Xie, “Drisa:

A dram-based reconfigurable in-situ accelerator,” in MICRO, 2017.

[105] J. Ahn, S. Hong, S. Yoo, O. Mutlu, and K. Choi, “A scalable processing-
in-memory accelerator for parallel graph processing,” in ISCA, 2015.
[106] H. Li, T. F. Wu, A. Rahimi, K.-S. Li, M. Rusch, C.-H. Lin, J.-L. Hsu, M. M.
Sabry, S. B. Eryilmaz, J. Sohn et al., “Hyperdimensional computing
with 3D VRRAM in-memory kernels: Device-architecture co-design
for energy-efficient, error-resilient language recognition,” in IEDM,
2016.

