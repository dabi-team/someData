2
2
0
2

y
a
M
7
2

]
S
M

.
s
c
[

1
v
7
7
0
4
1
.
5
0
2
2
:
v
i
X
r
a

ARKODE: A flexible IVP solver infrastructure for one-step
methods

DANIEL R. REYNOLDS, Southern Methodist University, USA
DAVID J. GARDNER, Lawrence Livermore National Laboratory, USA
CAROL S. WOODWARD, Lawrence Livermore National Laboratory, USA
RUJEKO CHINOMONA, Temple University, USA

We describe the ARKODE library of one-step time integration methods for initial-value problems (IVPs). In
addition to providing standard explicit and diagonally-implicit Runge–Kutta methods, ARKODE also supports
one-step methods designed to treat additive splittings of the IVP, including implicit-explicit (ImEx) additive
Runge–Kutta methods and multirate infinitesimal (MRI) methods. We present the role of ARKODE within the
SUNDIALS suite of time integration and nonlinear solver libraries, the core ARKODE infrastructure for utilities
common to large classes of one-step methods, as well as its use of “time stepper” modules enabling easy
incorporation of novel algorithms into the library. Numerical results show example problems of increasing
complexity, highlighting the algorithmic flexibility afforded through this infrastructure, and end with a larger
multiphysics application leveraging multiple algorithmic features from ARKODE and SUNDIALS.

CCS Concepts: • Mathematics of computing → Solvers; Ordinary differential equations.
Additional Key Words and Phrases: ODEs, Adaptive integration, Additive Runge-Kutta, IMEX methods,
Multirate methods

ACM Reference Format:
DANIEL R. REYNOLDS, DAVID J. GARDNER, CAROL S. WOODWARD, and RUJEKO CHINOMONA. 2022.
ARKODE: A flexible IVP solver infrastructure for one-step methods. ACM Trans. Math. Softw. 0, 0, Article 0
( 2022), 25 pages. https://doi.org/XXXXXXX.XXXXXXX

1 INTRODUCTION
The SUite of Nonlinear and DIfferential/ALgebraic Solvers (SUNDIALS) [4, 18, 31] is a numerical
software library providing time integrators and nonlinear solvers for use on a range of computing
systems – from laptops to leadership class supercomputers. The newest package in SUNDIALS,
ARKODE, provides highly flexible time integration methods for additive systems with partitions
of differing stiffness (implicit-explicit methods) and differing time scales (multirate methods).
ARKODE focuses on one-step, multi-stage methods for first-order initial-value problems (IVPs)
that typically include robust temporal adaptivity, based on estimates of both solution error and
solver efficiency. These methods leverage significant theoretical developments over recent decades
in Runge–Kutta methods, and they naturally map to space-time systems of partial differential
equations (PDEs) that employ spatially-adaptive meshes. Furthermore, ARKODE can be considered
as an infrastructure for one-step methods, providing a range of reusable components that may be
replaced with problem-optimal choices, or even experimental methods for rapid development and

Author’s addresses: D. R. Reynolds, reynolds@smu.edu, Department of Mathematics, Southern Methodist University;
D. J. Gardner, gardner48@llnl.gov; C. S. Woodward, woodward6@llnl.gov, Center for Applied Scientific Computing,
Lawrence Livermore National Laboratory; and R. Chinomona, rujeko.chinomona@temple.edu, Department of Mathematics,
Temple University.

ACM acknowledges that this contribution was authored or co-authored by an employee, contractor, or affiliate of the United
States government. As such, the United States government retains a nonexclusive, royalty-free right to publish or reproduce
this article, or to allow others to do so, for government purposes only.
© 2022 Association for Computing Machinery.
0098-3500/2022/0-ART0 $15.00
https://doi.org/XXXXXXX.XXXXXXX

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

 
 
 
 
 
 
0:2

D. R. Reynolds, D. J. Gardner, C. S. Woodward, and R. Chinomona

testing. The ARKODE implementations for different classes of methods follow similar APIs and
leverage many heuristics from other SUNDIALS packages allowing for similar usage and efficiency.
Over the last two decades, there have been significant advances in the derivation of numerical
methods that allow both high accuracy and increased flexibility with regard to how various
components of a problem are treated. These methods range from those that apply a uniform time
step size for an entire problem while varying the algorithms used on individual components, to
multirate methods that evolve separate solution components using different step sizes.

Methods in the former category have been introduced primarily for problems that couple stiff
and nonstiff processes. Instead of employing a fully implicit or fully explicit method that would be
ideally suited to only the stiff or nonstiff components of the problem, respectively, these approaches
apply robust implicit solvers to the stiff components while treating the remaining nonstiff (and
frequently nonlinear) components explicitly. While simplistic first-order operator-split approaches
have been utilized for decades, including higher-order variants that introduce complex arithmetic
or backward integration [7], novel methods that provide increased accuracy and stability for such
problems include implicit-explicit (ImEx) additive Runge–Kutta methods, first introduced in [10]
with newer embedded versions supporting temporal adaptivity developed in [34, 36].

Multirate methods, on the other hand, evolve separate problem components using different
time step sizes and are frequently applied to multiphysics problems that combine various physical
processes which may separately evolve on disparate time scales. In such circumstances the “fast”
processes are often evolved with small step sizes, while the “slow” processes are evolved using larger
time steps. Here again, simple first-order “subcycling” approaches have been employed for many
years; however, research into higher-order approaches has recently seen dramatic advances through
development of multirate methods [9, 20] including multirate infinitesimal methods [8, 37, 39, 49–
51, 64] and multirate generalized additive Runge-Kutta methods [22, 48].

Recently, several software packages have been developed to meet some of the challenges pre-
sented by multiphysics, time-dependent problems. Some of the most notable ones include the
PETSc/TS [2] and Trilinos/Tempus [40] packages, that respectively provide C and C++ implemen-
tations of explicit, implicit, and additive Runge–Kutta methods for ODEs and DAEs. Additionally,
the DifferentialEquations.jl package [42] provides a suite for numerically solving ordinary differen-
tial equations and stochastic differential equations (including back-end interfaces to SUNDIALS)
written in Julia, Python, and R. All of these packages include temporal adaptivity and additive
formulations that support splitting a problem into its stiff and nonstiff components. Additionally,
these packages provide support for solving the nonlinear and linear systems of equations that arise
from implicit time discretizations, as well as implementations that enable computations on GPU
accelerators. However, at present, none of these packages natively support multirate methods, that
are critical for a wide range of multiphysics applications.

The goal of the ARKODE solver library is to provide a bridge between recent mathematical
advances into flexible time integration methods and the large-scale simulations that need them.
Our overall aims in designing ARKODE were three-fold:

(1) Provide high-order, stable, efficient, and scalable methods for multiphysics, multirate sys-
tems of ordinary differential equation (ODE) IVPs, for which no single “textbook” solution
technique optimally applies to all of its various components.

(2) Provide both an IVP solver and experimentation framework that allows users to rapidly

explore algorithmic optimizations.

(3) Provide a high-quality, scalable, open-source software library that can easily be incorporated
into existing simulation codes without requiring application developers to rewrite or convert
their native data structures, and that can be run on a broad range of computing systems.

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

The ARKODE IVP solver infrastructure

0:3

While ARKODE may be used as a standalone library, it is released as part of, and leverages
numerous components from, the larger SUNDIALS suite, which also consists of the solvers CVODE
(for ODE IVP systems), IDA (for differential-algebraic IVP systems), CVODES and IDAS (forward and
adjoint sensitivity analysis variants of CVODE and IDA, respectively), and KINSOL (for nonlinear
algebraic systems). As part of SUNDIALS, ARKODE has access to a rich ecosystem of vector, linear
solver, and nonlinear solver classes to foster both experimentation between SUNDIALS integrators
(e.g., CVODE vs ARKODE) and to leverage existing interfaces and infrastructure. SUNDIALS,
including ARKODE, is written in C with modern Fortran interfaces. All operations on data within
the SUNDIALS packages are done through a clear set of abstract vector, matrix, linear solver, and
nonlinear solver interfaces. To wit, SUNDIALS integrators, including ARKODE, make no assumption
about how a user’s data is laid out in memory; specifically, users can (if they wish) supply their
own class implementations, as long as they provide the methods needed by the integrator.

This flexibility allows for ARKODE, along with other SUNDIALS integrators, to be easily em-
ployed from within existing applications. For example, ARKODE has been used in several appli-
cations including the High-Order Methods Modeling Environment (HOMME) dynamical core in
the Energy Exascale Earth System Model (E3SM) [63], the Tempest atmospheric dynamical core
[17], the ParaDiS dislocation dynamics simulator [19], the Modular Finite Element Methods Library
(MFEM) [3], the PeleC adaptive-mesh compressible hydrodynamics code for reacting flows [56],
the Mushroom fusion code [15], and the MEUMAPPS phase-field modeling code [11, 43].

ARKODE also serves as an infrastructure for one-step methods, and, as such, it provides a variety
of shared modules for (a) handling temporal adaptivity to achieve a desired solution accuracy and
efficiently utilize any underlying iterative algebraic (nonlinear and linear) solvers, (b) interfaces
to translate user-defined IVP right-hand side and Jacobian routines into the routines required by
SUNDIALS’ general purpose algebraic solver classes, (c) stiff and nonstiff temporal interpolation
modules for dense output and efficient implicit predictors for iterative algebraic solvers, (d) root-
finding capabilities for event detection, and (e) enforcing solution inequality constraints.

The rest of this paper is organized as follows. In Section 2 we introduce the current time stepping
modules provided within ARKODE, as these user-facing components define both the types of
problems that may be solved and the algorithms that can be applied to them. For readers interested
in the underlying structure of ARKODE, in Section 3 we discuss the shared infrastructure on which
ARKODE’s time stepping modules are built. Then, in Section 4, we present the standard usage
of ARKODE. In Section 5 we present a sequence of simple numerical examples highlighting the
algorithmic flexibility of ARKODE and a demonstration example showing an advanced use of
ARKODE for a large-scale multiphysics application. Finally, in Section 6 we point out open-source
options for accessing ARKODE and provide concluding remarks. For the sake of readability, we omit
some specific usage and implementation details; for this information, as well as additional details
on ARKODE itself, we refer readers to the ARKODE documentation at sundials.readthedocs.io.

2 TIME-STEPPING MODULES
ARKODE considers time-dependent initial-value problems in linearly implicit first order form,

𝑀 (𝑡) 𝑦 ′(𝑡) = 𝑓 (𝑡, 𝑦),

𝑦 (𝑡0) = 𝑦0,

(1)

where the independent variable typically satisfies 𝑡 ∈ [𝑡0, 𝑡𝑓 ] (ARKODE also allows 𝑡 ∈ [𝑡𝑓 , 𝑡0],
in which case (1) is a final-value problem), and the dependent variable is 𝑦 ∈ R𝑁 . 𝑀 (𝑡) is a user-
specified nonsingular operator from R𝑁 → R𝑁 , that is assumed to be independent of 𝑦. For standard
systems of ODEs and for problems arising from the spatial semi-discretization of PDEs using finite
difference, finite volume, or spectral element methods, 𝑀 is typically the identity matrix, 𝐼 . For PDEs
using finite-element spatial semi-discretizations, 𝑀 is typically a well-conditioned mass matrix.

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

0:4

D. R. Reynolds, D. J. Gardner, C. S. Woodward, and R. Chinomona

While each of the time-stepping modules supplied with ARKODE considers different formulations
of the problem (1), all share the basic structure wherein 𝑦 is provided at only the initial (or final) time,
and ARKODE computes approximate values of 𝑦 (𝑡) at a discrete set of independent variable values,
either 𝑡0 < 𝑡1 < . . . < 𝑡𝑓 for forward-in-time evolution, or 𝑡𝑓 > . . . > 𝑡1 > 𝑡0 for reverse evolution.
We denote these approximations of the solution 𝑦 (𝑡𝑛) as 𝑦𝑛. One-step methods for solution of (1)
generate these approximate solutions using some formula,

𝑦𝑛 = 𝜑 (𝑡𝑛−1, 𝑦𝑛−1, 𝑦𝑛, ℎ𝑛),

(2)

where ℎ𝑛 = 𝑡𝑛 − 𝑡𝑛−1 is the step size, and 𝜑 denotes the approximation method that updates the
solution 𝑦𝑛−1 → 𝑦𝑛. ARKODE makes no assumption that the step sizes are uniform, i.e. ℎ𝑛 ≠ ℎ𝑛−1,
although such use is supported. Instead, ARKODE strives to take the largest possible step that
simultaneously ensures that the approximations, 𝑦𝑛, are sufficiently accurate and that the time-
stepping algorithms used to evaluate 𝜑 are efficient and robust.

Fig. 1. The relationship between ARKODE and its time-stepping modules. ARKODE provides the time
integration loop; each stepper performs individual time steps leveraging the shared infrastructure as needed.

While the ARKODE infrastructure provides utilities for temporal integration of one-step IVP
methods, it does not specify either the type of IVP problems that should be solved (i.e., the structure
of the function 𝑓 (𝑡, 𝑦)), nor does it require any specific numerical algorithm for taking the step,
𝜑 (𝑡𝑛−1, 𝑦𝑛−1, 𝑦𝑛, ℎ𝑛). These aspects of integration are left up to specific time stepping modules that
rest on the ARKODE infrastructure – a diagram of this relationship is shown in Figure 1. The
time-stepping modules provide the user-facing software layer for problem definition, evolution,
and reporting of solver statistics. Upon creation of a time-stepping module, that module internally
creates the main ARKODE memory structure and “attaches” itself to ARKODE by providing two
functions used by ARKODE during the IVP evolution:

(1) an initialization function that is called by ARKODE once all setup has completed and temporal

integration of the problem is about to commence, and

(2) a step function that computes a candidate update, ˜𝑦 = 𝜑 (𝑡𝑛−1, 𝑦𝑛−1, ℎ𝑛), and the corresponding

estimate of the local truncation error, ∥𝑇𝑛 ∥.

Currently, ARKODE includes three time-stepping modules: ERKStep, ARKStep, and MRIStep,

discussed in the following subsections.

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

ARKODEtime  stepping loopERKStepARKStepMRIStepTemporalinterpolationNonlinear solverinterfaceAdaptivitycontrollersImplicitpredictorsLinear solverinterfaceTemporal root-findingSolution inequalityconstraintsThe ARKODE IVP solver infrastructure

2.1 ERKStep
The ERKStep time-stepping module is designed for IVPs of the form

𝑦 ′(𝑡) = 𝑓 (𝑡, 𝑦),

𝑦 (𝑡0) = 𝑦0,

0:5

(3)

i.e., 𝑀 (𝑡) = 𝐼 in (1). For such problems, ERKStep provides variable-step, embedded, explicit Runge-
Kutta (ERK) methods, that evolve a single time step 𝑡𝑛−1 → 𝑡𝑛−1 + ℎ𝑛 = 𝑡𝑛 using the algorithm

𝑧𝑖 = 𝑦𝑛−1 + ℎ𝑛

𝑦𝑛 = 𝑦𝑛−1 + ℎ𝑛

˜𝑦𝑛 = 𝑦𝑛−1 + ℎ𝑛

𝑖−1
∑︁

𝑗=1
𝑠
∑︁

𝑖=1
𝑠
∑︁

𝑖=1

𝐴𝑖,𝑗 𝑓 (𝑡𝑛,𝑗, 𝑧 𝑗 ),

𝑖 = 1, . . . , 𝑠,

𝑏𝑖 𝑓 (𝑡𝑛,𝑖, 𝑧𝑖 ),

˜𝑏𝑖 𝑓 (𝑡𝑛,𝑖, 𝑧𝑖 ),

(4a)

(4b)

(4c)

where the internal stage times are abbreviated using the notation, 𝑡𝑛,𝑗 = 𝑡𝑛−1 + 𝑐 𝑗ℎ𝑛, and the
coefficients 𝐴 ∈ R𝑠×𝑠 , 𝑏 ∈ R𝑠 , 𝑐 ∈ R𝑠 , and optional embedding coefficients ˜𝑏 ∈ R𝑠 (a.k.a., the
Butcher table) define the method. The embedding, ˜𝑦𝑛. typically provides a slightly lower accuracy
approximation than the computed solution, 𝑦𝑛. ARKODE provides a number of ERK Butcher tables
having orders of accuracy 𝑞 = {2, 3, 4, 5, 6, 8}, each is supplied with an embedding ˜𝑏 that usually has
order of accuracy 𝑝 = 𝑞 − 1. User-supplied Butcher tables are also supported and are not required
to include embedding coefficients, although if these are not provided then automatic temporal
adaptivity will be disabled. We have found this “fixed-step” mode to be particularly useful when
existing simulation codes transition to ARKODE. By providing the ERK Butcher table that a code
currently uses and ceding control over ℎ𝑛 to the application code, users may run verification tests
to ensure reproducibility before switching to higher-order and/or adaptive ERK methods.

In order to allow users to “tune” ERKStep to better exploit problem structure, numerous optional
features may be enabled or modified by the user. The full set of features is described in [47]; a few
of which are highlighted in the example problem below.

2.2 ARKStep
The ARKStep time-stepping module is designed for IVPs where the right-hand side function may
be additively split into two components,

𝑀 (𝑡) 𝑦 ′(𝑡) = 𝑓 𝐸 (𝑡, 𝑦) + 𝑓 𝐼 (𝑡, 𝑦),

𝑦 (𝑡0) = 𝑦0,

(5)

where the user-provided right-hand side function 𝑓 𝐸 (𝑡, 𝑦) contains the “nonstiff” components
of the system, and 𝑓 𝐼 (𝑡, 𝑦) contains the “stiff” components of the system. In solving (5), we first
convert to standard additive form,

𝑦 ′(𝑡) = ˆ𝑓 𝐸 (𝑡, 𝑦) + ˆ𝑓 𝐼 (𝑡, 𝑦),

𝑦 (𝑡0) = 𝑦0,

(6)

where ˆ𝑓 𝐸 (𝑡, 𝑦) = 𝑀 (𝑡)−1𝑓 𝐸 (𝑡, 𝑦) and ˆ𝑓 𝐼 (𝑡, 𝑦) = 𝑀 (𝑡)−1 𝑓 𝐼 (𝑡, 𝑦). ARKStep utilizes variable-step,
embedded, ImEx additive Runge-Kutta (ARK) methods. Given a pair of 𝑠-stage Butcher tables

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

0:6

D. R. Reynolds, D. J. Gardner, C. S. Woodward, and R. Chinomona

(𝐴𝐸, 𝑏𝐸, ˜𝑏𝐸, 𝑐𝐸) and (𝐴𝐼 , 𝑏𝐼 , ˜𝑏𝐼 , 𝑐𝐼 ), a single time step 𝑡𝑛−1 → 𝑡𝑛 is advanced via the algorithm

𝑧𝑖 = 𝑦𝑛−1 + ℎ𝑛

𝑦𝑛 = 𝑦𝑛−1 + ℎ𝑛

˜𝑦𝑛 = 𝑦𝑛−1 + ℎ𝑛

𝑖−1
∑︁

𝑗=1
𝑠
∑︁

𝑖=1
𝑠
∑︁

𝑖=1

𝑖,𝑗 ˆ𝑓 𝐸 (𝑡 𝐸
𝐴𝐸

𝑛,𝑗, 𝑧 𝑗 ) + ℎ𝑛

𝑖
∑︁

𝑗=1

𝑖,𝑗 ˆ𝑓 𝐼 (𝑡 𝐼
𝐴𝐼

𝑛,𝑗, 𝑧 𝑗 ),

𝑖 = 1, . . . , 𝑠,

(cid:16)
𝑖 ˆ𝑓 𝐸 (𝑡 𝐸
𝑏𝐸

𝑛,𝑖, 𝑧𝑖 ) + 𝑏𝐼

𝑖 ˆ𝑓 𝐼 (𝑡 𝐼

𝑛,𝑖, 𝑧𝑖 )

(cid:16)˜𝑏𝐸

𝑖 ˆ𝑓 𝐸 (𝑡 𝐸

𝑛,𝑖, 𝑧𝑖 ) + ˜𝑏𝐼

𝑖 ˆ𝑓 𝐼 (𝑡 𝐼

𝑛,𝑖, 𝑧𝑖 )

(cid:17)

(cid:17)

,

,

(7a)

(7b)

(7c)

where we denote the internal stage times as 𝑡 𝐸
𝑗ℎ𝑛. We note
that ARKStep enforces the constraint that the explicit and implicit Butcher tables share the same
number of stages, 𝑠, but it allows for the possibility of different explicit and implicit abscissae, i.e.,
𝑐𝐸 ≠ 𝑐𝐼 (as required for various SSP ImEx-ARK methods [28–30, 41]).

𝑛,𝑗 = 𝑡𝑛−1 + 𝑐𝐸

𝑛,𝑗 = 𝑡𝑛−1 + 𝑐𝐼

𝑗 ℎ𝑛 and 𝑡 𝐼

Through appropriate selection of the Butcher tables and right-hand side functions, ARKStep
supports three classes of Runge–Kutta methods: ImEx, explicit, and diagonally-implicit. Several
Butcher tables are provided for each class, all of which include the embedding coefficients, ˜𝑏𝐸 and
˜𝑏𝐼 , although users may provide their own tables without embeddings (in which case adaptivity will
be disabled). For mixed stiff/nonstiff problems, a user should provide both of the functions 𝑓 𝐸 and
𝑓 𝐼 that define the IVP system, in which case ARKStep provides the ARK Butcher tables proposed in
[33, 35] with orders of accuracy 𝑞 = {3, 4, 5} and embeddings of orders 𝑝 = {2, 3, 4}, respectively.
Either of the function pointers for 𝑓 𝐼 or 𝑓 𝐸 may be NULL to disable that component. For nonstiff

problems one can disable 𝑓 𝐼 , in which case (5) reduces to the non-split IVP

𝑀 (𝑡) 𝑦 ′(𝑡) = 𝑓 𝐸 (𝑡, 𝑦),

𝑦 (𝑡0) = 𝑦0.

(8)

In this scenario, the implicit Butcher table (𝐴𝐼 , 𝑏𝐼 , ˜𝑏𝐼 , 𝑐𝐼 ) in (7) is ignored, and the ARK methods
reduce to classical ERK methods. Here, all methods from ERKStep are again available in ARKStep.
We note that in this mode, both the problem (8) and the method (7) fully encapsulate the ERKStep
problem (3) and method (4). While it therefore follows that ARKStep can be used to solve every
problem solvable by ERKStep (even with the same Butcher tables), we retain ERKStep as a distinct
time-stepping module since its simplified form admits a more efficient and memory-friendly
implementation than that provided by ARKStep.

Alternately, for stiff problems 𝑓 𝐸 may be disabled so that (5) reduces to

𝑀 (𝑡) 𝑦 ′(𝑡) = 𝑓 𝐼 (𝑡, 𝑦),

𝑦 (𝑡0) = 𝑦0.

(9)

Here the explicit Butcher table (𝐴𝐸, 𝑏𝐸, ˜𝑏𝐸, 𝑐𝐸) in (7) is ignored, and the ARK methods reduce to
standard diagonally-implicit Runge-Kutta (DIRK) methods, for which ARKODE provides tables with
orders of accuracy 𝑞 = {2, 3, 4, 5} and embeddings of orders 𝑝 = {1, 2, 3, 4}, respectively.

As with ERKStep, the ARKStep module includes a number of features that allow users to optimize
its usage on their problems. The full list of these is included in [47]. One such feature is a “set”
routine that allows the user to specify that 𝑓 𝐼 depends linearly on 𝑦, and thus each implicit stage
equation for 𝑧𝑖 from (7) corresponds to a linear system of equations. In this case, only one iteration
of the Newton nonlinear solver is performed, avoiding extraneous nonlinear iterations and residual
norm computations to assess convergence.

A second notable feature in ARKStep is its native interface to the scalable parallel-in-time (PinT)
library XBraid [12]. Instead of performing a standard time-marching approach from one step to
the next (𝑡𝑛−1 → 𝑡𝑛), XBraid solves for all time values simultaneously using multigrid reduction in
time (MGRIT) [13], a highly parallel iterative method that exposes parallelism in the time domain

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

The ARKODE IVP solver infrastructure

0:7

in addition to spatial parallelization. We have designed the ARKStep + XBraid interface so that
simulation codes using ARKStep should require minimal modifications to explore using PinT.

2.3 MRIStep
MRIStep is the newest time-stepping module in ARKODE and targets multirate IVPs of the form

𝑦 ′(𝑡) = 𝑓 𝐸 (𝑡, 𝑦) + 𝑓 𝐼 (𝑡, 𝑦) + 𝑓 𝐹 (𝑡, 𝑦),

𝑦 (𝑡0) = 𝑦0.

(10)

The right-hand side function is split into slow components, 𝑓 𝐸 (𝑡, 𝑦) + 𝑓 𝐼 (𝑡, 𝑦), that should be
integrated with a large step size 𝐻 , and where 𝑓 𝐸 (𝑡, 𝑦) contains nonstiff terms and 𝑓 𝐼 (𝑡, 𝑦) contains
stiff terms; and fast components, 𝑓 𝐹 (𝑡, 𝑦), that should be integrated with a small step size ℎ ≪ 𝐻 .
For approximating solutions to (10), MRIStep utilizes multirate infinitesimal (MRI) methods, that
are characterized through an alternation between an outer ARK-based method for the slow time
scale, and a sequence of fast time scale IVP systems that are evolved using an inner solver.

When both slow components 𝑓 𝐸 and 𝑓 𝐼 are present, MRIStep uses implicit-explicit multirate
infinitesimal generalized-structure additive Runge–Kutta (ImEx-MRI-GARK) methods [8]. When
either 𝑓 𝐸 or 𝑓 𝐼 are NULL-valued, ImEx-MRI-GARK methods simplify to either implicit or explicit
multirate infinitesimal GARK (MRI-GARK) methods [50]. The following algorithm outlines a single
step 𝑡𝑛−1 → 𝑡𝑛−1 + 𝐻 = 𝑡𝑛 of an 𝑠-stage MRI method from either family:

(1) Let 𝑧1 = 𝑦𝑛−1 and 𝑡𝑛,1 = 𝑡𝑛−1.
(2) For 𝑖 = 2, . . . , 𝑠

𝑟𝑖 (𝑡) = 1
Δ𝑐𝑖

(a) Let 𝑡𝑛,𝑖 = 𝑡𝑛−1 + 𝑐𝑖𝐻 , Δ𝑐𝑖 = 𝑐𝑖 − 𝑐𝑖−1, 𝑣 (𝑡𝑛,𝑖−1) = 𝑧𝑖−1, and
(cid:17)
(cid:16) 𝑡 −𝑡𝑛,𝑖−1
Δ𝑐𝑖 𝐻

𝑖
(cid:16) 𝑡 −𝑡𝑛,𝑖−1
(cid:205)
Δ𝑐𝑖 𝐻
𝑗=1
(b) Solve 𝑣 ′(𝑡) = 𝑓 𝐹 (𝑡, 𝑣) + 𝑟𝑖 (𝑡) over 𝑡 ∈ [𝑡𝑛,𝑖−1, 𝑡𝑛,𝑖 ].
(c) Set 𝑧𝑖 = 𝑣 (𝑡𝑛,𝑖 ).

𝑓 𝐸 (𝑡𝑛,𝑗, 𝑧 𝑗 ) + 1
Δ𝑐𝑖

𝑖−1
(cid:205)
𝑗=1

𝜔𝑖,𝑗

𝛾𝑖,𝑗

(cid:17)

𝑓 𝐼 (𝑡𝑛,𝑗, 𝑧 𝑗 ).

(3) Set 𝑦𝑛 = 𝑧𝑠 .

Here the coefficients, 0 = 𝑐1 < · · · < 𝑐𝑠 = 1, define the abscissae for the method. The coefficient
functions, 𝜔𝑖,𝑗 and 𝛾𝑖,𝑗 , are polynomials in time that dictate the couplings from the slow to the fast
time scale and can be expressed as in [8] as

𝜔𝑖,𝑗 (𝜃 ) =

𝐾
∑︁

𝑘=0

𝜔 {𝑘 }
𝑖,𝑗 𝜃 𝑘,

𝛾𝑖,𝑗 (𝜃 ) =

𝐾
∑︁

𝑘=0

𝛾 {𝑘 }
𝑖,𝑗 𝜃 𝑘,

, coefficients respectively.

, and implicit, 𝛾 {𝑘 }
𝑖,𝑗

where typically 0 ≤ 𝐾 ≤ 2. The coupling tables, Ω {𝑘 } ∈ R𝑠×𝑠 and Γ {𝑘 } ∈ R𝑠×𝑠 , contain the explicit,
𝜔 {𝑘 }
𝑖,𝑗
Like Runge–Kutta methods, implicitness at the slow time scale is characterized by nonzero
values on or above the diagonal. MRIStep currently supports diagonally-implicit, “solve-decoupled”
methods i.e., 𝜔 {𝑘 }
𝑖,𝑗 = 0 for 𝑗 > 𝑖, and Δ𝑐𝑖 = 0 if 𝛾 {𝑘 }
𝑖,𝑖 ≠ 0. When Δ𝑐𝑖 = 0, the “fast”
IVP solve in step 2b reduces to a standard ImEx-ARK stage (7a), with step size, 𝐻 , and coefficients

𝑖,𝑗 = 0 for 𝑗 ≥ 𝑖, 𝛾 {𝑘 }

𝐴𝐸

𝑖,𝑗 =

𝜔 {𝑘 }
𝑖,𝑗
𝑘 + 1

𝐾
∑︁

𝑘=0

, 𝐴𝐼

𝑖,𝑗 =

𝛾 {𝑘 }
𝑖,𝑗
𝑘 + 1

.

𝐾
∑︁

𝑘=0

Thus an MRI stage only requires a nonlinear implicit solve if 𝐴𝐼

𝑖,𝑖 ≠ 0.

MRIStep also supports Multirate infinitesimal step (MIS) methods [52–54]. These methods are
a subset of MRI-GARK methods where the coupling coefficients are uniquely defined based on a
slow explicit Butcher table (𝐴𝐸, 𝑏𝐸, 𝑐𝐸) with 𝑠 − 1 stages and sorted abscissae 𝑐𝐸. The MIS method

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

0:8

D. R. Reynolds, D. J. Gardner, C. S. Woodward, and R. Chinomona

then has abscissae, 𝑐 = [𝑐𝐸

1 · · · 𝑐𝐸

𝑠−1 1]𝑇 , and coupling coefficients, 𝛾 {0}

𝑖,𝑗 = 0, and

𝜔 {0}

𝑖,𝑗 =

0,

𝐴𝐸
𝑖,𝑗 − 𝐴𝐸

𝑗 − 𝐴𝐸
𝑏𝐸


𝑖−1,𝑗,
𝑠−1,𝑗,

if 𝑖 = 1,
if 2 ≤ 𝑖 ≤ 𝑠 − 1,
if 𝑖 = 𝑠.

(11)

At present, the MRIStep module implements all third and fourth order ImEx-MRI-GARK methods
from [8], the third-order MIS method defined by the slow Butcher table from [37], as well as all of
the third and fourth order MRI-GARK methods from [50]. Alternately, users may provide a custom
set of coupling tables, Γ {𝑘 } and/or Ω {𝑘 }, to define their own MRI method. MRIStep includes a utility
routine that will also convert a slow Butcher table (𝐴𝐸, 𝑏𝐸, 𝑐𝐸) with sorted abscissae 𝑐𝐸 into a set of
MRI-GARK coefficients using (11). If the slow Butcher table has order of accuracy at least two then
the MIS method will also have order two, but third-order accuracy can be obtained if the slow table
itself is at least third order and satisfies the condition [37]

^𝑠
∑︁

𝑖=2

(cid:16)
𝑖 − 𝑐𝐸
𝑐𝐸
𝑖−1

(cid:17)

(𝑒𝑖 + 𝑒𝑖−1)𝑇 𝐴𝐸𝑐𝐸 +

(cid:16)

1 − 𝑐𝐸
^𝑠

(cid:17) (cid:18) 1
2

+ 𝑒𝑇

^𝑠 𝐴𝐸𝑐𝐸

(cid:19)

=

,

1
3

where 𝐴𝐸 has ˆ𝑠 stages and 𝑒𝑘 is the 𝑘-th column of an ˆ𝑠 × ˆ𝑠 identity matrix.

The ODEs in step 2b may be solved using any sufficiently accurate method by supplying a “fast
IVP” stepper to the MRIStep module. For convenience, ARKODE includes a constructor that will
attach an ARKStep instance as the inner integrator, thereby enabling an adaptive explicit, implicit,
or ImEx treatment of the fast time scale. Alternatively, applications can supply a user-defined
integrator for the fast time scale as demonstrated in the simple example problem below and in the
large-scale demonstration problem in Section 5. Currently MRIStep supports temporal adaptivity
only at the fast time scale. Efficient multirate temporal adaptivity is an open research question
(see, e.g., [14]), but future support is anticipated to follow new developments in the field. Finally,
like ERKStep and ARKStep, MRIStep provides numerous configuration options for users to control
integrator behavior. The full list of options is included in [47].

3 SHARED INFRASTRUCTURE
As mentioned above, the ARKODE time-stepping modules rest on a shared infrastructure providing
various utilities for one-step methods. This infrastructure manages the time loop, calling the time
stepper modules both to advance the solution with a given step size and to compute a temporal
error estimate for that step. This outer loop handles the temporal error control and time step
adaptivity, the detection of events (root finding) and solution constraint violations, and, if necessary,
interpolation of the solution to a requested output time. Moreover, ARKODE provides time steppers
with interfaces to algebraic solvers and methods for predicting the new time solution. We note that
ARKODE itself rests on the shared SUNDIALS infrastructure. Thus, throughout this section we
focus on the ARKODE-specific utilities, deferring to more general SUNDIALS references [4, 18, 31]
for descriptions of that shared infrastructure.

3.1 User-supplied Tolerances and Error Control
To control errors at various levels (time integration and algebraic solvers), ARKODE, like other
SUNDIALS solvers [31, eq. (4)], uses a weighted root-mean-square norm for all error-like quantities,

∥𝑣 ∥WRMS =

(cid:33) 1/2

(𝑣𝑖 𝑤𝑖 )2

.

(cid:32)

1
𝑁

𝑁
∑︁

𝑖=1

(12)

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

The ARKODE IVP solver infrastructure

0:9

This norm allows problem-specific error measurement via the weighting vector, 𝑤, that combines
the units of the problem with user-supplied values that specify “acceptable” error levels. Thus, at
the start of each time step 𝑡𝑛−1 → 𝑡𝑛, we construct two weight vectors. The first is an error weight
vector that, like in CVODE [31, eq. (5)], uses the most recent step solution and user-supplied relative
and absolute tolerances (scalar- or vector-valued),

𝑤𝑖 = (cid:0)rtol |𝑦𝑛−1,𝑖 | + atol𝑖 (cid:1) −1 .
The second focuses on problems with a non-identity mass matrix 𝑀, since the units of (1) may
differ from the units of the solution 𝑦. Here, we construct a residual weight vector,

(13)

𝜔𝑖 = (rtol |𝑟𝑖 | + ratol𝑖 )−1 ,

𝑟 = 𝑀 (𝑡𝑛−1)𝑦𝑛−1,

(14)

where the user may specify a separate residual absolute tolerance value or array, ratol.

ARKODE uses 𝑤 or 𝜔 based on the quantity being measured: errors having “solution” units use
𝑤, whereas those having “equation” units use 𝜔. Obviously, when 𝑀 = 𝐼 the solution and equation
) represents
units match, and ARKODE uses 𝑤 for all error norms. In both cases, since 𝑤 −1
a tolerance in the 𝑖-th component of the solution (or equation) vector, then an error whose WRMS
norm is ≤ 1 is regarded as being within an acceptable error tolerance.

(or 𝜔 −1

𝑖

𝑖

3.2 Stepsize Adaptivity
A critical utility provided by ARKODE is its adaptive control of local truncation error (LTE), 𝑇𝑛,
at each step, which corresponds to the error induced within the time step 𝑡𝑛−1 → 𝑡𝑛, under an
assumption that the initial condition for that step was exact. At every internal step, ARKODE
requests both an approximate solution 𝑦𝑛, and an estimate of 𝑇𝑛, from the time-stepping module.
These approximations have global orders of accuracy, 𝑞 and 𝑝, respectively, where generally 𝑝 = 𝑞−1.
Since the global and local errors for one step methods usually differ by one factor of ℎ𝑛 [25], then

∥𝑦𝑛 − 𝑦 (𝑡𝑛)∥ = 𝐶ℎ𝑞+1

𝑛 + O

∥𝑇𝑛 ∥ = 𝐷ℎ𝑝+1

𝑛 + O

(cid:16)
ℎ𝑞+2
𝑛

(cid:17)

(cid:16)
ℎ𝑝+2
𝑛

(cid:17)

,

.

(15)

(16)

where 𝐶 and 𝐷 are constants independent of ℎ𝑛, and where we have assumed exact initial conditions
for the step, i.e. 𝑦𝑛−1 = 𝑦 (𝑡𝑛−1). Given this time-stepper-estimated value of 𝑇𝑛, ARKODE adopts the
same local temporal error test as other SUNDIALS integrators, simply

∥𝑇𝑛 ∥WRMS ≤ 1.
If this test passes, the step is accepted and 𝑇𝑛 is used to estimate a prospective next step size, ℎ′,
using an adaptive error controller. If (17) fails then the step is rejected, and 𝑇𝑛 is used to estimate
a reduced step size, ℎ′. In either case, temporal adaptivity in ARKODE focuses on choosing the
maximum ℎ′ such that (17) should pass on the next attempted step. We thus define the biased local
error estimate

(17)

𝜀𝑘 ≡ 𝛽 ∥𝑇𝑘 ∥WRMS,
where the error bias 𝛽 > 0 helps to account for the error constant 𝐷 in (16). ARKODE stores the
biased error estimates corresponding to the three most recent steps, 𝜀𝑛, 𝜀𝑛−1 and 𝜀𝑛−2. Of these,
both 𝜀𝑛−1 and 𝜀𝑛−2 correspond to the last two successful steps, whereas 𝜀𝑛 corresponds to the
most-recently attempted step. ARKODE provides a variety of error controllers that utilize these
estimates, including PID (the ARKODE default) [33, 57–59], PI [33, 57–59], I (the “standard” method
used in most publicly-available IVP solvers) [32], the explicit Gustafsson controller [23], the implicit
Gustafsson controller [24], and an “ImEx” Gustaffson controller that sets ℎ′ as the minimum of
the explicit and implicit Gustafsson controller values. Alternately, users may provide their own

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

0:10

D. R. Reynolds, D. J. Gardner, C. S. Woodward, and R. Chinomona

functions to produce ℎ′ using the inputs 𝑦𝑛, 𝑡𝑛, ℎ𝑛, ℎ𝑛−1, ℎ𝑛−2, 𝜀𝑛, 𝜀𝑛−1, and 𝜀𝑛−2. Each controller
bases its adaptivity off the order of accuracy for the error estimate, 𝑝, although the user may
instead request to use the solution order 𝑞 instead. All of the provided controllers include tuning
parameters, with default values determined using an exhaustive genetic optimization process based
off of dozens of challenging IVP test problems, including nearly all from the “Test Set For IVP
Solvers” [62].

In addition to error-based temporal adaptivity, ARKODE adopts many of the heuristics from
CVODE [31] for bounding ℎ′, including approaches for handling repeated temporal error test
failures, overly aggressive growth or decay in prospective steps (ℎ′ ≫ ℎ𝑛 or ℎ′ ≪ ℎ𝑛), step size
reduction following a failed implicit solve, and user-supplied step size bounds ℎmin ≤ ℎ′ ≤ ℎmax.
Complete details on these heuristics, as well as information on how each parameter may be adjusted
by users, are provided in the ARKODE documentation [47].

3.3 Interpolation Modules
ARKODE supports interpolation of approximate solutions 𝑦 (𝑡𝑜𝑢𝑡 ), and derivatives 𝑦 (𝑑) (𝑡𝑜𝑢𝑡 ), where
𝑡𝑜𝑢𝑡 occurs within the most recently completed step 𝑡𝑛−1 → 𝑡𝑛. This utility also supports extrapola-
tion of 𝑦 and its derivatives outside this time step to construct predictors for iterative algebraic
solvers. These approximations are based on polynomial interpolants 𝜋𝜉 (𝑡) of degree up to 𝜉 = 5,
that are constructed using one of two complementary approaches: “Hermite” and “Lagrange”.

3.3.1 Hermite interpolation module. For non-stiff problems ARKODE provides Hermite polynomial
interpolants, constructed using both solution and derivative data (𝑦𝑛 ≈ 𝑦 (𝑡𝑛) and 𝑓𝑛 ≡ 𝑓 (𝑡𝑛, 𝑦𝑛) ≈
𝑦 ′(𝑡𝑛)), following the approach outlined in [25, II.6]. The available Hermite interpolants are:

2 (𝑦𝑛−1 + 𝑦𝑛).

• 𝜋0 (𝑡): satisfies 𝜋0 (𝑡) = 1
• 𝜋1 (𝑡): satisfies 𝜋1 (𝑡𝑛−1) = 𝑦𝑛−1 and 𝜋1(𝑡𝑛) = 𝑦𝑛.
• 𝜋2 (𝑡): satisfies 𝜋2 (𝑡𝑛−1) = 𝑦𝑛−1, 𝜋2(𝑡𝑛) = 𝑦𝑛, and 𝜋 ′
• 𝜋3 (𝑡): satisfies 𝜋3 (𝑡𝑛−1) = 𝑦𝑛−1, 𝜋3(𝑡𝑛) = 𝑦𝑛, 𝜋 ′
• 𝜋4 (𝑡): satisfies 𝜋4 (𝑡𝑛−1) = 𝑦𝑛−1, 𝜋4(𝑡𝑛) = 𝑦𝑛, 𝜋 ′
(cid:16)
𝑡𝑛 − ℎ𝑛
3
• 𝜋5 (𝑡): satisfies 𝜋5 (𝑡𝑛−1) = 𝑦𝑛−1, 𝜋5(𝑡𝑛) = 𝑦𝑛, 𝜋 ′
(cid:17)(cid:17), and 𝜋 ′
(cid:16)
𝑡𝑛 − ℎ𝑛
3

(cid:16)
𝑡𝑛 − ℎ𝑛
3

(cid:16)
𝑡𝑛 − ℎ𝑛
3

(cid:16)
𝑡𝑛 − ℎ𝑛
3

(cid:16)
𝑡𝑛 − ℎ𝑛
3

, 𝜋3

, 𝜋4

(cid:17)(cid:17).

= 𝑓

= 𝑓

𝜋 ′
4

𝜋 ′
5

(cid:17)

(cid:17)

5

2 (𝑡𝑛) = 𝑓𝑛.
3(𝑡𝑛−1) = 𝑓𝑛−1, and 𝜋 ′
4(𝑡𝑛−1) = 𝑓𝑛−1, 𝜋 ′

3 (𝑡𝑛) = 𝑓𝑛.
4 (𝑡𝑛) = 𝑓𝑛, and

5 (𝑡𝑛) = 𝑓𝑛,
5(𝑡𝑛−1) = 𝑓𝑛−1, 𝜋 ′
(cid:16)
𝑡𝑛 − 2ℎ𝑛
= 𝑓
3

(cid:16)
𝑡𝑛 − 2ℎ𝑛
3

(cid:17)

, 𝜋4

(cid:16)
𝑡𝑛 − 2ℎ𝑛
3

(cid:17)(cid:17).

The interpolants 𝜋4 (𝑡) and 𝜋5(𝑡) require one and four additional evaluations of 𝑓 (𝑡, 𝑦), respectively,
whereas all others are constructed using readily-available data from the last successful time step.
Due to these increasing costs, interpolants of degree 𝜉 > 5 are not currently provided.

Lagrange interpolation module. For stiff problems, interpolants that use derivative values 𝑓 =
3.3.2
𝑦 ′ can result in order reduction. We thus provide a second module based on polynomial interpolants
of Lagrange type, constructed using an extended “history” of solution data, (cid:8)𝑦𝑛, 𝑦𝑛−1, . . . , 𝑦𝑛−𝜉 (cid:9),

𝜋𝜉 (𝑡) =

𝜉
∑︁

𝑗=0

𝑦𝑛−𝑗 ℓ𝑗 (𝑡), where

ℓ𝑗 (𝑡) =

(cid:19)

(cid:18) 𝑡 − 𝑡𝑖
𝑡 𝑗 − 𝑡𝑖

𝜉
(cid:214)

𝑖=0
𝑖≠𝑗

,

𝑗 = 0, . . . , 𝜉.

Since generally each solution vector 𝑦𝑛−𝑗 has many more than 5 entries, we evaluate 𝜋𝜉 at any
desired 𝑡 ∈ R by first evaluating the basis functions at 𝑡, and then performing a linear combination

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

The ARKODE IVP solver infrastructure

0:11

of the stored solution vectors {𝑦𝑛−𝑘 }

𝜉
𝑘=0

. Derivatives 𝜋 (𝑑)

𝜉

(𝑡) may be evaluated similarly as

𝜋 (𝑑)
𝜉

(𝑡) =

𝜉
∑︁

𝑗=0

𝑦𝑛−𝑗 ℓ (𝑑)

𝑗

(𝑡).

Due to the increasing algorithmic complexity involved in evaluating ℓ (𝑑)
, ARKODE only supports
derivatives up to 𝑑 = 3. Also, since in the first (𝜉 −1) internal time steps ARKODE has an insufficient
solution history to construct the full 𝜉-degree interpolant, during these initial steps we construct
the highest degree interpolants that are currently available.

𝑗

3.4 Implicit Solvers
For both ARKStep and MRIStep, if 𝑓 𝐼 is nonzero then each implicit stage, 𝑧𝑖 ∈ R𝑁 , may require the
solution of an algebraic system of equations:

𝑀 (𝑡𝑛,𝑖 ) (𝑧𝑖 − 𝑎𝑖 ) − 𝛾𝑖 𝑓 𝐼 (𝑡𝑛,𝑖, 𝑧𝑖 ) = 0,
where 𝑡𝑛,𝑖 is the corresponding implicit stage time, 𝛾𝑖 ∈ R is proportional to ℎ𝑛, 𝑓 𝐼 (𝑡, 𝑦) is the
implicit portion of the IVP right-hand side, and 𝑎𝑖 is “known data” that may include previous
stages or IVP right-hand side evaluations. ARKODE provides utilities to map between 𝑓 𝐼 and the
nonlinear or linear algebraic system for each stage (18), interfaces to a range of algebraic solvers
from SUNDIALS, and optimizations to enhance the efficiency of these solvers for the IVP context.

(18)

3.4.1 Nonlinear Solver Methods. SUNDIALS provides multiple nonlinear solver modules through its
SUNNonlinearSolver interface [18], all of which utilize predictor-corrector form and are targeted
to nonlinear systems of equations with either root-finding or fixed-point structure. Writing the
stage solution as 𝑧𝑖 = 𝑧𝑖,𝑝 + 𝑧𝑖,𝑐 , where 𝑧𝑖,𝑝 is the prediction and 𝑧𝑖,𝑐 the desired correction, ARKODE
rewrites the nonlinear system (18) in root-finding or fixed-point form as

0 = 𝐺𝑟 𝑓 (𝑧𝑖,𝑐 ) := 𝑀 (𝑡𝑛,𝑖 )𝑧𝑖,𝑐 − 𝛾𝑖 𝑓 𝐼 (𝑡𝑛,𝑖, 𝑧𝑖,𝑝 + 𝑧𝑖,𝑐 ) − 𝑀 (𝑡𝑛,𝑖 ) (cid:0)𝑎𝑖 − 𝑧𝑖,𝑝 (cid:1) ,
𝑧𝑖,𝑐 = 𝐺 𝑓 𝑝 (𝑧𝑖,𝑐 ) := 𝑀 (𝑡𝑛,𝑖 )−1 (cid:16)

𝛾𝑖 𝑓 𝐼 (𝑡𝑛,𝑖, 𝑧𝑖,𝑝 + 𝑧𝑖,𝑐 )

+ (𝑎𝑖 − 𝑧𝑖,𝑝 ),

(cid:17)

or

(19a)

(19b)

respectively. Note, these equations may be simplified in the cases where 𝑀 is independent of
𝑡 or when 𝑀 = 𝐼 . When setting up an ARKODE simulation, users must identify the category
of 𝑀 at problem initialization, at which point ARKODE will provide a function pointer for the
relevant nonlinear system to the generic SUNNonlinearSolver object. This ARKODE layer serves
to translate from the user-supplied functions 𝑀 and 𝑓 𝐼 and user-selected IVP method to the generic
nonlinear solver module. To simplify the discussion below, we focus on the general cases (19).

Nonlinear solvers for root-finding problems typically solve linear systems related to the Jacobian,

A (𝑡, 𝑧, 𝛾) :=

𝜕𝐺𝑟 𝑓
𝜕𝑧𝑖,𝑐

= 𝑀 (𝑡) − 𝛾

𝜕𝑓 𝐼 (𝑡, 𝑧)
𝜕𝑧

.

(20)

When either the matrix A is explicitly stored or a preconditioner is supplied by the user, ARKODE
updates these infrequently to amortize the high costs of Jacobian construction and preconditioner
formulation. Thus, ARKODE will use a Jacobian or preconditioner corresponding to (20) at a
previous time step i.e., ˜A (˜𝑡, ˜𝑧, ˜𝛾) where ˜𝑧, ˜𝑡 and ˜𝛾 are previous time step values. The logic guiding
this lagging process follows the heuristics described for CVODE in [31, Sec. 2.1] and each of the
specific heuristic parameters may be modified by the user for their problem.

ARKODE utilizes an identical stopping test for the nonlinear iteration as is used in CVODE, that
strives to solve the nonlinear system slightly more accurately than the temporal accuracy in an

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

0:12

D. R. Reynolds, D. J. Gardner, C. S. Woodward, and R. Chinomona

effort to minimize extraneous (and costly) nonlinear solver iterations. As with the other heuristics
in ARKODE all of the stopping test parameters are user modifiable.

Implicit Predictors. For iterative nonlinear solvers, a good initial guess can dramatically affect
3.4.2
both their speed and robustness, making the difference between rapid quadratic convergence versus
divergence of the iteration. To this end, ARKODE provides a variety of algorithms to construct the
predictor 𝑧𝑖,𝑝 from (19), typically using an interpolating polynomial via ARKODE’s interpolation
module (Section 3.3). Specifically, since each stage solution typically satisfies 𝑧𝑖 ≈ 𝑦 (𝑡𝑛,𝑖 ), where 𝑡𝑛,𝑖
is the stage time associated with 𝑧𝑖 , then we predict these stage solutions as

(21)
𝑧𝑖,𝑝 = 𝜋𝜉 (𝑡𝑛,𝑖 ).
Since 𝑡𝑛,𝑖 are usually outside of the previous successful step, [𝑡𝑛−2, 𝑡𝑛−1] (containing the data used
to construct 𝜋𝜉 (𝑡)), (21) will correspond to an extrapolant instead of an interpolant. The dangers of
using polynomial extrapolation are well-known, with higher-order polynomials and evaluation
points further outside the interpolation interval resulting in the greatest risk. To support “optimal”
choices for different types of problems, ARKODE’s prediction algorithms construct a variety of
interpolants with different degree and using different interpolation data, as described below.

Trivial predictor. This Predictor is given by 𝜋0 (𝑡) = 𝑦𝑛−1. While not highly accurate, this predic-
tor is often the most robust choice for very stiff problems or for problems with implicit constraints
whose violation may cause illegal solution values (e.g., a negative density or temperature).

Maximum order predictor. At the opposite end of the spectrum, we may construct the highest-
degree interpolant available, 𝜋𝜉max (𝑡). We note that as 𝜉max increases, this predictor provides a very
accurate prediction for stage times that are “close” to [𝑡𝑛−2, 𝑡𝑛−1] but could be dangerous otherwise.
As discussed in Section 3.3, ARKODE caps the polynomial degree at 5, but the degree may be further
limited by setting, 𝜉user, and the IVP solver method order, 𝑞, such that 𝜉max ≤ min{𝑞 − 1, 𝜉user, 5}.
Variable order predictor. In-between the two previous approaches, this predictor uses 𝜋𝜉max (𝑡)
for predicting earlier stages and lower-degree polynomials for later stages. Thus, the polynomial
degree is chosen adaptively based on the stage index 𝑖, 𝜉 = max{𝜉max − 𝑖, 1}, which may be
reasonable under the assumption that the stage times are increasing, i.e., 𝑐𝑖 ≤ 𝑐 𝑗 for 𝑖 < 𝑗.

Cutoff order predictor. Following a similar idea as above, this predictor monitors the actual

stage times to determine the polynomial degree for 𝜋𝜉 (𝑡):
𝑡𝑛,𝑖 −𝑡𝑛−1
if
ℎ𝑛−1
otherwise.

(cid:40)𝜉max,
1,

𝜉 =

< 1
2

,

User supplied. Finally, ARKODE supports a user-provided implicit predictor function that is
called after the selected built-in routine. Thus it could predict all components of 𝑧𝑖,𝑝 if desired, or it
could merely “fix” specific components that result from a higher order built-in predictor (e.g., to
satisfy underlying physical constraints) before the prediction is passed to the nonlinear solver.

3.4.3 Linear Solver Methods. For problems that require linear solves within a nonlinear solver or
the action of 𝑀 (𝑡)−1, users may leverage any of the SUNLinearSolver and SUNMatrix modules
provided by SUNDIALS [18]. These solvers generally fit within one of four categories: (a) direct
solvers that store and operate on matrices, (b) iterative and matrix-based solvers, (c) iterative
and matrix-free solvers, or (d) solvers that embed the linear system. For linear solvers of each
type, ARKODE provides utilities to assist in translating from the user-supplied, problem-defining
functions, 𝑓 𝐼 , 𝑀 (𝑡) (or the product, 𝑀 (𝑡) 𝑣), and, optionally, the Jacobian, 𝐽 (𝑡, 𝑧) = 𝜕𝑧 𝑓 𝐼 (𝑡, 𝑧), or
product, 𝐽 (𝑡, 𝑧) 𝑣, to the generic SUNDIALS modules. In the case of matrix-based linear solvers that
utilize dense or banded matrices, ARKODE provides utilities to approximate the Jacobian matrix, 𝐽 ,
using a minimum number of evaluations of 𝑓 𝐼 [31].

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

The ARKODE IVP solver infrastructure

0:13

As with the nonlinear case, ARKODE attempts to solve each linear system to an accuracy just
below that of the encompassing routine (e.g., an outer nonlinear solver in the case of A from (20), or
the temporal error controller in the case of 𝑀 −1). Again, ARKODE follows the same techniques for
this purpose as CVODE [31], with the only salient differences being ARKODE’s use of the residual
weight vector, 𝜔, from (14) for linear system residual norms. As before, all of the associated heuristic
parameters are user modifiable. When solving problems with both a non-identity mass matrix
and a matrix-based nonlinear solver, the “types” of the mass matrix and system SUNLinearSolver
objects must match (matrix-based, matrix-based iterative, matrix-free iterative, or embedded). If
both are matrix-based, these matrices must use the same SUNMatrix storage type for streamlined
construction of the combination, 𝑀 − 𝛾 𝐽 . Otherwise, ARKODE has no restriction that the solvers
themselves be the same (e.g., a basic conjugate gradient method could be used for the mass matrix
systems, along with a preconditioned generalized minimum residual method for the system matrix
A).

3.5 Temporal root-finding
A particularly useful feature of SUNDIALS integrators and provided in the ARKODE infrastructure
is event detection. While integrating an IVP, ARKODE can find roots of a set of user-defined
functions, 𝑔𝑖 (𝑡, 𝑦 (𝑡)) = ˜𝑔𝑖 (𝑡). The number of these functions is arbitrary, and, if more than one ˜𝑔𝑖 is
found to have a root in any given interval, the various root locations are found and reported in the
order that they occur in the direction of integration. The basic scheme and heuristics match what
was used elsewhere in SUNDIALS [31]. During integration of (1), following each successful step
ARKODE checks for sign changes of any ˜𝑔𝑖 (𝑡); if one is found, it then will home in on the root (or
roots) with a modified secant method [27].

3.6 Inequality Constraints
A final notable feature of the ARKODE infrastructure, also shared with other SUNDIALS integrators,
is support for user-imposed inequality constraints on components of the solution 𝑦: 𝑦𝑖 > 0, 𝑦𝑖 < 0,
𝑦𝑖 ≥ 0, or 𝑦𝑖 ≤ 0. Constraint satisfaction is tested after a successful step and before the temporal error
test. If any constraint fails, ARKODE estimates a reduced step size based on a linear approximation
in time for each violated component (including a safety factor to cover the strict inequality case). If
applicable, a flag is set to update the Jacobian or preconditioner in the next step attempt.

4 USAGE
Each time stepping module in ARKODE admits a similar usage style, modeled after CVODE [31,
Sec. 6]. Moreover, due to the recent addition of Fortran 2003 interfaces throughout SUNDIALS [18],
users may call ARKODE from C, C++, or Fortran by following the same progression of steps. This
general approach is as follows:

(1) The user provides one or more functions that define the IVP to be solved, i.e., 𝑓 (𝑡, 𝑦), 𝑓 𝐼 (𝑡, 𝑦),

as well as any problem-specific preconditioners or utility routines.

(2) For problems with a non-identity mass matrix, the user provides a function to either compute

the mass matrix, 𝑀 (𝑡), or to perform the mass matrix-vector product, 𝑀 (𝑡) 𝑣.

(3) The user creates a vector of initial conditions, 𝑦0, for the problem (1).
(4) The user creates the ARKODE time-stepper memory structure that contains default values

for solver options, such as solution error tolerances and time-stepping method order.

(5) The user creates nonlinear and/or linear solver objects for use by the stepper, e.g., a Newton
solver, a sparse linear solver, and a sparse matrix. These objects also include default options.

(6) The user attaches the algebraic solver objects to the ARKODE time-stepper.

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

0:14

D. R. Reynolds, D. J. Gardner, C. S. Woodward, and R. Chinomona

(7) The user adjusts time-stepper or algebraic solver options via “set” routines. The user may

additionally specify temporal root-finding functions, inequality constraints, etc.

(8) The user advances the solution toward a desired output time, 𝑡𝑜𝑢𝑡 , using one of four “modes”:
• NORMAL takes internal steps until simulated time has just passed 𝑡𝑜𝑢𝑡 and returns an

approximation of 𝑦 (𝑡𝑜𝑢𝑡 ) using interpolation (see Section 3.3).

• ONE-STEP takes a single internal step and returns to the user. If this step overtakes 𝑡𝑜𝑢𝑡 ,

then the solver approximates 𝑦 (𝑡𝑜𝑢𝑡 ); otherwise it returns 𝑦𝑛.

• NORMAL-TSTOP takes internal steps until the next step will overtake 𝑡𝑜𝑢𝑡 . The subsequent

step is limited so that 𝑡𝑛 = 𝑡𝑜𝑢𝑡 , and the internal solution 𝑦𝑛 is returned.

• ONE-STEP-TSTOP takes a single internal step and returns to the user (like “one-step”).

However, if the step will overtake 𝑡𝑜𝑢𝑡 , then this mode is identical to “normal-tstop”.

Most users call ARKODE in either NORMAL or NORMAL-TSTOP mode, where the latter is
preferred when full integrator accuracy is required (to avoid interpolation error). The two
ONE-STEP modes are frequently used when debugging or first beginning with ARKODE, in
order to verify the results following each internal step.

(9) The user retrieves optional outputs from the time-stepper via “get” routines, including solver

statistics or interpolated solution values.

(10) The user may repeat the above process starting at step 7.
(11) When the solution process is complete, the user destroys any SUNDIALS objects they have

created e.g., solution vectors, algebraic solvers, time integrators, etc.

A variety of additional options are supported within this basic structure. Three particularly useful
ARKODE features include the ability to re-initialize, reset, and resize the integrator. Re-initialization
is useful when a user has already solved an IVP using ARKODE and wants to solve a new problem
with a state vector of the same size. Here, no memory is (de)allocated, but all solver history (previous
step sizes, temporal error estimates, stored solutions, solver statistics) is cleared. This is useful
when performing parameter sweeps, where the user wishes to run repeated forward simulations
using different problem parameters. This is also useful when treating jump discontinuities in the
IVP right-hand side functions that cause solution characteristics to change dramatically. Here, one
may run ARKODE up to the discontinuity discontinuity in “tstop” or root-finding mode, and then
re-initialize the solver with the new right-hand side function to be used following the discontinuity.
Alternately, ARKODE steppers may be “reset”, allowing them to solve an IVP with the same right-
hand side function(s), but using an updated initial condition (𝑡0, 𝑦0). As with re-initialization, the
memory footprint remains unchanged and the step size and solution history are cleared, but all
solver statistics (total number of steps, etc.) are retained. This mode is used by MRIStep to ensure
that each fast time scale IVP is solved using the prescribed initial condition, while still accumulating
all fast time scale solver statistics. Finally, since ARKODE is built for one-step methods, it is natural
to apply it to PDEs that adaptively refine the spatial grid. Here, the ARKODE “resize” functions
support simulations in which the number of equations and unknowns in the IVP system change
between time steps. This resizing obviously modifies ARKODE’s internal memory structures to use
the new problem size, but does so without destroying the temporal adaptivity heuristics.

5 NUMERICAL RESULTS
To highlight the algorithmic flexibility provided by ARKODE, we first present a sequence of
simple numerical examples that progressively increase in both problem and integrator complexity,
emulating the progression of a typical new ARKODE user. We then present a demonstration problem
showing an advanced use of ARKODE for a large-scale multiphysics application.

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

The ARKODE IVP solver infrastructure

0:15

5.1 Simple Example Problem
For each stepper module example, we consider a one-dimensional advection-diffusion-reaction
equation using a variation of the Brusselator chemical kinetics model [26]. The system is given by

𝑢𝑡 = −𝑐 𝑢𝑥 + 𝑑 𝑢𝑥𝑥 + 𝑎 − (𝑤 + 1) 𝑢 + 𝑣 𝑢2,
𝑣𝑡 = −𝑐 𝑣𝑥 + 𝑑 𝑢𝑥𝑥 + 𝑤 𝑢 − 𝑣 𝑢2,
𝑤𝑡 = −𝑐 𝑤𝑥 + 𝑑 𝑢𝑥𝑥 + (𝑏 − 𝑤)/𝜖 − 𝑤 𝑢,

(22)

for 𝑡 ∈ [0, 10] with 𝑥 ∈ [0, 1], where 𝑢, 𝑣, and 𝑤 are the chemical species concentrations, 𝑐 = 0.001 is
the advection speed, 𝑑 is the diffusion rate (typically 0.01), 𝑎 = 0.6 and 𝑏 = 2 are the concentrations
of species that remain constant over time, and 𝜖 = 0.01 is a parameter that determines the stiffness
of the system. The initial conditions are

𝑢 (0, 𝑥) = 𝑎 + 0.1 sin(𝜋𝑥),

𝑣 (0, 𝑥) = 𝑏/𝑎 + 0.1 sin(𝜋𝑥),

𝑤 (0, 𝑥) = 𝑏 + 0.1 sin(𝜋𝑥).

Spatial derivatives are computed using second-order centered differences with the data distributed
over 𝑁 = 512 points on a uniform spatial grid with stationary boundary conditions i.e.,
𝑤𝑡 (𝑡, 0) = 𝑤𝑡 (𝑡, 1) = 0.

𝑢𝑡 (𝑡, 0) = 𝑢𝑡 (𝑡, 1) = 0,

𝑣𝑡 (𝑡, 0) = 𝑣𝑡 (𝑡, 1) = 0,

All of the examples use the serial N_Vector implementation, and results were obtained on the Quartz
cluster at Lawrence Livermore National Laboratory. The source files for this example problem are
ark_advection_diffusion_reaction.hpp and ark_advection_diffusion_reaction.cpp.

5.1.1 ERKStep. We first consider an advection-reaction setup (i.e., 𝑑 = 0 in (22)) and evolve the
system in time using the default second- (Heun-Euler), third- [5], fourth- [65], and fifth-order [6]
ERK methods in ARKODE. The optimal method choice will depend on the user’s desired accuracy,
the cost per step of the method, and the step sizes selected by the adaptivity controller. As such,
we show how the options in ARKODE can help users determine more effective methods in their
accuracy regimes of interest. We compare the performance of each method using “loose,” “medium,”
and “tight” sets of relative and absolute tolerances pairs (10−4/10−9, 10−5/10−10, and 10−6/10−11,
respectively) and the PID, PI, I, and explicit Gustafsson controllers. The maximum relative error at
the final time is computed using a reference solution generated with the default fifth-order DIRK
method (ARK5(4)8L[2]SA-ESDIRK in [33]) with relative and absolute tolerances of 10−8 and 10−14,
respectively.

Fig. 2 shows a work-precision plot for the various configurations. Given its lower cost per step,
the second-order method gives the best performance at coarser levels of accuracy (three left-most
solid red markers) despite requiring more than double the number of step attempts as the third-order
method. For errors between 10−5 and 10−7 the third-order method is the most efficient (lower left
orange markers) since the second-order method requires at least three times as many step attempts,
while the fourth- and fifth-order methods make fewer attempts but the reduced number of attempts
is insufficient to offset their higher cost per step. The fifth-order method becomes most efficient at
accuracies below 10−7 (blue markers near the bottom left).

Across the methods and tolerances, the I controller is frequently the least efficient for this example
as it only considers the error in the current step leading to a high step rejection rate (between 13%
and 50%). The additional error history retained by the PI and Gustafsson controllers leads to better
step size predictions and often the greatest efficiency (rejection rates <7%). The longer history of
the PID controller does not lead to further improvement and it generally produces results that fall
between the PI and I controllers. As explored in [44], the choice of controller parameters (tunable
in ARKODE but not explored here) also plays an important role in performance.

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

0:16

D. R. Reynolds, D. J. Gardner, C. S. Woodward, and R. Chinomona

Fig. 2. Work-precision plot for the default 2nd to 5th order ERK methods with various error controllers and
tolerances. Configurations further to the left and lower in the plot indicate methods with less work and
greater accuracy, respectively.

5.1.2 ARKStep. We extend the previous model to now include diffusion (i.e., 𝑑 = 0.01 in (22)). To
avoid the stability limitations of a fully-explicit approach, users could either treat the full system
implicitly with a DIRK method or partition the right-hand side and apply an ImEx-ARK method
with implicit diffusion. In the latter case, different splitting approaches could be considered, and in
both cases the choice of predictor may not be clear. As such, we show how these methods could be
compared. In the DIRK case, we advance the system in time using the implicit part of the ImEx-ARK
method, ARK4(3)6L[2]SA, from [33], and, in the ImEx case, we use the ARK4(3)6L[2]SA ImEx-ARK
method. We consider two different ImEx splittings that both treat advection explicitly, but the
reaction terms are either treated implicitly (IMEX-1) to step over the fastest reaction dynamics or
explicitly (IMEX-2) to track the reaction timescale. In each setup, we solve the nonlinear systems
at each implicit stage using a modified Newton method paired with a banded direct linear solver.
Additionally, in the ImEx-2 case we enable the “linearly-implicit” ARKStep option to allow only
one Newton iteration per nonlinear solve. The integration relative and absolute tolerances are set
to 10−4 and 10−9, respectively. For each method we compare the trivial, max order, variable order,
and cutoff implicit predictor algorithms.

Table 1 shows various integrator statistics for each configuration. In this test, where there are long
periods of slow change followed by shorter, faster transition intervals, higher order extrapolation
with the max order predictor significantly improves efficiency compared to the trivial predictor for
the DIRK and IMEX-1 methods. The variable order and cutoff predictors also increase performance
but are more conservative at later stages and are better suited to cases where the max order predictor
becomes unstable. For ImEx-2, the choice of predictor is less important since its overall performance
is largely dictated by the explicit treatment of reactions that require smaller time steps to resolve.
Comparing the integration methods more broadly, the performance of the DIRK and ImEx-1
methods are nearly identical as they use the same implicit method. We note that with ImEx-
ARK methods, the terms included in 𝑓 𝐸 are evaluated far less often than those in 𝑓 𝐼 , since 𝑓 𝐸
is only evaluated once per stage rather than once per nonlinear iteration. As such, when 𝑓 𝐸 is

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

100012001400160018002000220024002600107106105104Max Relative Error3900425046001340013500107106105104Order:2nd3rd4th5thController:PIDPIIGTolerance:LooseMediumTightNumber of RHS EvaluationsComparison of Methods, Controllers, and Tolerances with ERKStepThe ARKODE IVP solver infrastructure

0:17

Table 1. Comparison of integrator statistics using the default 4th order DIRK and ImEx methods. The ImEx
results use two splittings of (22), in both cases diffusion is treated implicitly and advection explicitly while the
reactions are treated implicitly (ImEx-1) or explicitly (ImEx-2). Each method is paired with the trivial (T), max
order (M), variable order (V), and cutoff (C) predictors. The statistics given are the number of successful steps
(Steps), number of failed steps due to an error test or nonlinear solver failure (Err and Solve fails), number of
explicit and implicit function evaluations (𝑓 𝐸 and 𝑓 𝐼 evals), number of nonlinear solver iterations and failures
(NLS iters and fails), number of linear solver setups (LS setups), and number of Jacobian evaluations (𝐽 evals).

DIRK
Predictor
T M V

34
0
6
-
758
528
24
46
25

21
0
0
-
385
256
6
18
7

24
0
1
-
460
308
10
24
11

C

24
0
1
-
487
335
14
28
15

ImEx-1
Predictor
T M V

31
0
4
204
672
468
18
35
19

21
0
0
129
385
256
6
18
7

25
0
1
158
475
317
10
25
11

Stats

Steps
Err fails
Solve fails
𝑓 𝐸 evals
𝑓 𝐼 evals
NLS iters
NLS fails
LS setups
𝐽 evals

ImEx-2
Predictor
V
M

258
67
0
1,953
3,578
1,625
0
171
68

256
62
0
1,911
3,501
1,590
0
167
63

C

250
44
0
1,767
3,237
1,470
0
134
45

C

25
0
1
158
495
337
13
28
14

T

255
56
0
1,869
3,424
1,555
0
156
57

expensive but non-stiff, an ImEx approach can offer greater efficiency. Alternatively, when an
efficient nonlinear solver is unavailable for the unsplit right-hand side, an ImEx approach may
offer similar performance without requiring an algebraic solver for the full system. Considering
ImEx-2, we see that it is far more expensive than the DIRK or ImEx-1 approaches since its time
steps are determined by the reactions. However in terms of 𝑓 𝐸 evaluations, ImEx-2 is on par with
the advection-reaction results using ERKStep, as its implicit treatment of diffusion successfully
alleviates the step size restrictions that would be present if this problem were treated fully explicitly.

5.1.3 MRIStep. With ARKStep, (22) was split into implicit and explicit partitions using the same
step size for all components, but, as was clear from Table 1, resolving the reactions required smaller
step sizes than advection and diffusion. Therefore, we apply the default third-order ImEx-MRI-
GARK method (IMEX-MRI-GARK3a from [8]) in MRIStep with advection and diffusion at the slow
time scale using a fixed step size of 𝐻 = 0.1, and the reactions at the fast time scale. For this fast
scale we consider three integration methods: the default third-order adaptive step size ERK method
[5] in ARKStep that will resolve the fastest reaction dynamics, the default third-order adaptive step
size DIRK method (ARK3(2)4L[2]SA–ESDIRK from [33]) in ARKStep that will step over the fastest
reaction dynamics but at an increased cost per step, or an adaptive order and step size BDF method
from CVODE that will also step over the fast reaction dynamics with a lower cost per step but that
must start each fast integration phase at first order. At the slow time scale, the linearly implicit
systems are solved with a single Newton iteration and a banded direct linear solver. When using
the DIRK and BDF methods at the fast time scale, the nonlinear implicit systems are solved with a
modified Newton iteration paired with a banded direct linear solver. The integrators all use the
same relative and absolute tolerances of 10−4 and 10−9, respectively.

To use BDF methods for the fast integration, the example code wraps CVODE as an MRIStepIn-
nerStepper object. The derived class implemented in the example code contains the data needed
by the fast integrator (e.g., the CVODE memory structure) and defines three methods utilized by

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

0:18

D. R. Reynolds, D. J. Gardner, C. S. Woodward, and R. Chinomona

MRIStep: Evolve, FullRHS, and Reset. The first evolves the fast IVP system from step 2b of the
MRI method over a given time interval, the second evaluates 𝑓 𝑓 (𝑡, 𝑦) for slow time scale dense
output, and the third resets the integrator to a given time and state value.

Table 2.
Integrator statistics using the default 3rd order ImEx MRI method paired with either an ERK method,
DIRK method, or BDF method for the fast time scale integrator. The statistics given are the number of slow
time steps (Steps slow), number of successful fast time steps (Steps fast), number of failed fast time steps
(Failed steps fast), number of slow explicit, slow implicit, and fast function evaluations (𝑓 𝐸 , 𝑓 𝐼 , and 𝑓 𝑓 evals),
number of nonlinear iterations and failures at the slow and fast time scales (NLS iters and fails), number of
slow and fast linear solver setups (LS setups), and number of slow and fast Jacobian evaluations (𝐽 evals).

Stats

MRI-ERK MRI-DIRK MRI-BDF

Steps slow
Steps fast
Failed steps fast
𝑓 𝐸 evals
𝑓 𝐼 evals
𝑓 𝑓 evals
Slow NLS iters
Slow NLS fails
Slow LS setups
Slow 𝐽 evals
Fast NLS iters
Fast NLS fails
Fast LS setups
Fast 𝐽 evals

100
426
1
401
701
2,111
300
0
1
1
–
–
–
–

100
307
0
401
701
3,470
300
0
1
1
1,839
0
304
300

100
867
3
401
701
2,112
300
0
1
1
1,212
0
757
401

Table 2 shows various integrator statistics for each configuration. Since all three setups apply
the same ImEx method at the slow time scale, the “slow” statistics are identical. Comparing the
performance statistics from the fast integration we see various trade-offs between the methods. The
DIRK method takes the fewest steps (approximately one per fast solve) but it requires significantly
more fast function evaluations due to the nonlinear solves in each step. The ERK method takes more
steps but also requires fewer function evaluations, making it the most efficient for this reaction
model. Finally, the BDF method takes the most steps (approximately three per fast solve) as it must
bootstrap up from first order. However, it requires only one nonlinear solve per step and has just
one more fast function evaluation than the explicit method. Thus, for stiffer reactions requiring
more substeps per fast solve, the BDF method may become the best approach.

For any given application, the optimal choice of integrator family (explicit, ImEx, multirate),
problem splittings (implicit-explicit and/or fast-slow), Runge–Kutta or MRI method coefficients,
algebraic solvers, adaptivity methods, and solver parameters will obviously be problem specific.
However, this sequence of examples illustrates that through ARKODE’s broad range of options and
simple API, users may easily explore these choices to discover what works best for their application.

5.2 Multiphysics Demonstration Problem
As a final demonstration of ARKODE’s flexibility and performance, we consider the three-dimensional
nonlinear inviscid compressible Euler equations, with advection and reaction of chemical species,

𝑤𝑡 = −∇ · 𝐹 (𝑤) + 𝑅(𝑤),

(23)

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

The ARKODE IVP solver infrastructure

0:19

with the independent variables (𝑋, 𝑡) = (𝑥, 𝑦, 𝑧, 𝑡) ∈ Ω × [0, 𝑡𝑓 ], and where the spatial do-
main is a three-dimensional cube, Ω = [0, 1] × [0, 1] × [0, 1]. The solution is given by 𝑤 =
[𝜌 𝜌𝑣𝑥 𝜌𝑣𝑦 𝜌𝑣𝑧 𝑒𝑡 c]𝑇 , corresponding to the density, momentum in the x, y, and z directions, total
energy per unit volume, and some number of chemical densities c ∈ R𝑛𝑐ℎ𝑒𝑚 that are advected along
with the fluid. The fluxes are given by

𝐹𝑥 (𝑤) = (cid:2)𝜌𝑣𝑥
𝐹𝑦 (𝑤) = (cid:2)𝜌𝑣𝑦
𝐹𝑧 (𝑤) = (cid:2)𝜌𝑣𝑧

𝜌𝑣 2

𝑥 + 𝑝
𝜌𝑣𝑥𝑣𝑦

𝜌𝑣𝑥𝑣𝑦

𝜌𝑣𝑥𝑣𝑧

𝑣𝑥 (𝑒𝑡 + 𝑝)

𝜌𝑣 2

𝑦 + 𝑝

𝜌𝑣𝑦𝑣𝑧

𝑣𝑦 (𝑒𝑡 + 𝑝)

𝜌𝑣𝑥𝑣𝑧

𝜌𝑣𝑦𝑣𝑧

𝜌𝑣 2

𝑧 + 𝑝

𝑣𝑧 (𝑒𝑡 + 𝑝)

c𝑣𝑥 (cid:3)𝑇 ,
c𝑣𝑦 (cid:3)𝑇 ,
c𝑣𝑧 (cid:3)𝑇 .

(24)

(25)

(26)

𝑦 + 𝑣 2

𝑧 )), where 𝛾 = 𝑐𝑝 /𝑐𝑣 is the ratio of specific heats for the gas.

The reaction network is encoded in 𝑅(𝑤), and the ideal gas equation of state gives 𝑝 = (𝛾 − 1)(𝑒𝑡 −
𝜌
2 (𝑣 2

𝑥 + 𝑣 2
We discretize this problem using the method of lines, where we first semi-discretize in space
using a regular finite volume grid with dimensions 𝑛𝑥 × 𝑛𝑦 × 𝑛𝑧, with fluxes at cell faces calculated
using a 5th-order FD-WENO reconstruction [55]. MPI parallelization is achieved using a standard
3D domain decomposition of Ω. We organize the corresponding spatially-discretized solution
vector, 𝑦, using the SUNDIALS MPIManyVector [18] that wraps node-local vectors for each of the
fields, 𝜌, . . . , c, to create the overall state vector, 𝑤, and provides the requisite MPI functionality
for coordinating vector operations among the subvectors. The hydrodynamic fields, (𝜌, 𝜌v, and 𝑒),
are stored in CPU memory, and the chemical densities, c, are stored in GPU memory. After spatial
semi-discretization, we are faced with a large IVP system,

𝑤 ′(𝑡) = 𝑓1(𝑤) + 𝑓2 (𝑤), 𝑤 (𝑡0) = 𝑤0,

(27)

where 𝑓1 (𝑤) and 𝑓2 (𝑤) contain the spatially discretized forms of −∇ · 𝐹 (𝑤) and 𝑅(𝑤), respectively.
For additional information on this test problem or our computational implementation, please see
the technical report [46] and the GitHub repository [45].

In the results that follow, we simulate the advection and reaction of a low density primordial
gas, present in models of the early universe [1, 21, 38, 61]. This gas consists of 10 advected species
(i.e., 𝑛𝑐ℎ𝑒𝑚 = 10), corresponding to various ionization states of atomic and molecular Hydrogen
and Helium, free electrons, and the internal gas energy. For this setup the reaction network is
considerably stiffer than the advection, so we consider two forms for temporal evolution:

(a) O (cid:0)𝐻 4(cid:1), temporally-adaptive, single-step, ImEx method from ARKStep (ARK4(3)7L[2]SA1

from [35]), where 𝑓1 is treated explicitly and 𝑓2 is treated implicitly, and

(b) O (cid:0)𝐻 3(cid:1) explicit MIS method from MRIStep (using the “RK3” coefficients from [37]), where 𝑓1
is treated at the slow time scale using fixed step sizes, and 𝑓2 is treated at the fast time scale
using the DIRK portion of the O (cid:0)𝐻 4(cid:1), adaptive, DIRK method from (a).

For (a) we use SUNDIALS’ modified Newton solver to handle the global nonlinear algebraic systems
arising at each implicit stage of each time step. Since only 𝑓2 is treated implicitly and the reactions are
purely local in space, the Newton linear systems are block-diagonal. As such, we provide a custom
SUNLinearSolver implementation that solves each MPI rank-local linear system independently.
The portion of the Jacobian matrix on each rank, 𝐽𝑝 , is itself block-diagonal, i.e.,

𝐽𝑝,1,1,1

𝐽𝑝 =











𝐽𝑝,2,1,1

. . .

,











𝐽𝑝,𝑛𝑥𝑙𝑜𝑐,𝑛𝑦𝑙𝑜𝑐,𝑛𝑧𝑙𝑜𝑐

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

0:20

D. R. Reynolds, D. J. Gardner, C. S. Woodward, and R. Chinomona

with each cell-local block 𝐽𝑝,𝑖,𝑗,𝑘 ∈ R10×10. We further leverage this structure by solving each
𝐽𝑝𝑥𝑝 = 𝑏𝑝 linear system using the SUNDIALS SUNLinearSolver implementation interfacing to
GPU-enabled, batched, dense LU solver routines from MAGMA [60].

The multirate approach (b) can leverage the structure of 𝑓2 at a higher level. Since the MRI

method applied to this problem evolves “fast” sub-problems of the form

𝑣 ′(𝑡) = 𝑓2 (𝑡, 𝑣) + 𝑟𝑖 (𝑡),

𝑖 = 2, . . . , 𝑠,

(28)

and all MPI communication necessary to construct the forcing functions, 𝑟𝑖 (𝜏), has already been
performed, each sub-problem (28) consists of 𝑛𝑥 𝑛𝑦 𝑛𝑧 spatially-decoupled fast IVPs. We construct
a custom fast integrator that groups all the independent fast IVPs on an MPI rank together as a
single system evolved using a rank-local ARKStep instance. The code for this custom integrator
itself is minimal, primarily consisting of steps to access the local subvectors in 𝑤 on a given MPI
rank and wrapping them in MPI-unaware ManyVectors provided to the local ARKStep instance.
The collection of independent local IVPs also leads to a block diagonal Jacobian, and we again
utilize the SUNDIALS interface to MAGMA for solving linear systems within the modified Newton
iteration.

These tests use periodic boundary conditions and a “clumpy” initial background density field

(cid:32)

𝜌𝑏 (𝑋 ) = 100

1 +

(cid:32)

𝑠𝑖 exp

−2

(cid:18) ∥𝑋 − 𝑋𝑖 ∥
𝑟𝑖

(cid:19) 2(cid:33)(cid:33)

,

𝑁𝑐∑︁

𝑖=1

where 𝑠𝑖 ∈ [0, 5], 𝑟𝑖 ∈ [3Δ𝑥, 6Δ𝑥], and 𝑋𝑖 ∈ Ω𝑝 are uniformly-distributed random values and there
are 10 “clumps” per MPI rank. The initial background temperature is 𝑇𝑏 (𝑋 ) = 10, and the initial
velocity field is identically zero. The initial conditions for density and temperature are obtained by
adding a Gaussian bump to the background states

𝜌0(𝑋 ) = 𝜌𝑏 (𝑋 ) + 500 exp

−2

(cid:32)

(cid:19) 2(cid:33)

(cid:18) ∥𝑋 − 0.5∥
0.1

,

𝑇0 (𝑋 ) = 𝑇𝑏 (𝑋 ) + 50 exp

−2

(cid:32)

(cid:18) ∥𝑋 − 0.5∥
0.1

(cid:19) 2(cid:33)

,

causing a high-pressure front that emanates from the center of the domain. We initialize the
chemical network to consist almost exclusively of neutral Hydrogen (76%) and Helium (24%), with
trace amounts of ionized Hydrogen and Helium (0.0000000001%) outside of this high pressure region.
As the region expands and increases the surrounding temperature, the chemical concentrations in
those cells rapidly transition to a different equilibrium, resulting in a chemical time scale that is
multiple orders of magnitude faster than the spatial propagation of the high-pressure front.

In Figure 3 we present timing results for this problem run on Summit at the Oak Ridge Leadership

Computing Facility. We performed a weak-scaling simulation with:

• a 25 × 25 × 25 spatial grid per MPI rank,
• multirate integrators using a slow time step size satisfying the CFL constraint 𝐻 ≤ 10Δ𝑥,
• fast multirate time step sizes and ImEx time step sizes chosen adaptively by the ARKStep

integrator with relative and absolute tolerances of 10−5 and 10−9, respectively,

• temporal evolution over [0, 5𝐻 ], and
• 6 MPI ranks per Summit node, with one NVIDIA Volta GPU tied to each MPI rank.

The top row of Figure 3 shows the total simulation times for both configurations of the problem,
while the second row shows the corresponding algorithmic scalability. Examining the second row,
we see that for all solver statistics both configurations demonstrate ideal algorithmic scalability,
implying that our algorithm choices map optimally to the underlying problem structure.

From the first row of Figure 3 two observations are immediately clear. First, the high cost
associated with each evaluation of the advection operator (shown as fAdv) causes the MRI approach

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

The ARKODE IVP solver infrastructure

0:21

to easily outperform the ImEx method, due to its much smaller number of evaluations. Second, the
primary runtime slowdown experienced within both approaches arises in the green MPI component.
For the ImEx method, this component corresponds solely to a single MPI_Allreduce after each
rank-local linear solve to determine the overall “success” or “failure” of the global linear solve.
Thus, the MPI cost reflects the cost of global synchronization across GPUs. Similarly, in the MRI
case the MPI component measures an MPI_Allreduce that determines success of the fast local
IVP solves. Hence, the fundamental scalability difference between the ImEx and MRI approaches
results from the frequency of these synchronizations. For the ImEx method synchronizations occur
following each linear solve, within each Newton iteration, within each implicit stage, within each
time step. Since ARKStep’s temporal adaptivity tracked the (fast) reaction time scale, the simulation
required a large number of GPU synchronizations. On the other hand, with the MRI method these
synchronizations occur at the slow time scale, i.e., considerably less often than in the ImEx case.
Taking a step back to focus on ARKODE as an infrastructure, we conclude that its algorithmic
flexibility, and in particular its support for custom solver components and the new MRIStep multirate
module, enables a rich exploration of the “solver space” for this and many problems.

Fig. 3. Demonstration code scaling: simulation times (first row) and algorithmic scalability (second row).
fAdv corresponds to evaluation of the advection operator and fChem the chemistry operator. In the first row,
MPI corresponds with the global synchronization times required following each rank-local solver component,
and other contains all components that are not directly measured (e.g., time spent within the GPU-based
MAGMA linear solver). In the second row, steps, slow steps and fast steps show the total number of time
steps taken at each level of each solver, LSetups shows the total number of linear solver setup calls, Jevals
shows the total number of Jacobian evaluations, and Niters shows the total number of Newton iterations.

6 CONCLUSIONS
ARKODE is highly flexible, usable, and scalable infrastructure for one-step IVP solvers. It is currently
used by a variety of applications with functionality that is rapidly expanding to encompass novel and
flexible numerical methods for simulating complex phenomena. The current version of ARKODE is
5.2.0, is contained within SUNDIALS version 6.2.0, and is widely available through distribution
modes including Spack [16] and GitHub.

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

2419215365184ranks050010001500200025003000time [s]ImEx Simulation TimefAdvfChemMPIother24192153651841228824000ranks010203040time [s]Multirate Simulation TimefAdvfChemMPIother2419215365184ranks101102103104statsImEx Algorithmic ScalabilitystepsfAdv evalsfChem evalsLSetupsJevalsNIters24192153651841228824000ranks101102103104statsMultirate Algorithmic Scalabilityslow stepsfast stepsfAdv evalsfChem evalsLSetupsJevalsNIters0:22

D. R. Reynolds, D. J. Gardner, C. S. Woodward, and R. Chinomona

We have designed ARKODE to support a range of one-step methods, providing reusable infras-
tructure components that new methods may leverage to minimize the time between initial inception
and public release in a high-quality open-source software library. By supplying a method-specific
step function that propagates the IVP solution and provides an estimate of the local truncation
error, ARKODE can wrap these methods to provide well-established usage modes that evolve an
IVP over a time interval or return after each internal step. ARKODE also provides added features
including high-order dense output, event handling, and support for inequality constraints on
solution components.

The existing ecosystem of ARKODE time stepping modules allows users to explore various options
for time integration with only minor modifications to their codes, allowing these algorithms to
increase in complexity with their application. The current modules include a lean explicit Runge–
Kutta time stepper, an additive Runge–Kutta time stepper for explicit, implicit, and ImEx integration,
and a new multirate infinitesimal time stepper that supports explicit, implicit, and ImEx integration
of at slow time scale while allowing for arbitrary integration methods at the fast time scale.

As with most open-source packages, we continue to add functionality to ARKODE. Current
enhancements include support for multirate temporal adaptivity within MRIStep, as well as new
time stepping modules for advanced one-step methods (positivity/structure preserving, etc.).

ACKNOWLEDGMENTS
The authors would like to thank Alan Hindmarsh, Cody Balos, Jean Sexton, Slaven Peles, Ting Yan,
and John Loffeld for their software and mathematical contributions. We would also like to thank
Gregg Hommes, Sylvie Aubry, Tom Arsenlis, Paul Ullrich, Jorge Guerra, Chris Vogl, Andrew Steyer,
Mark Taylor, Darin Ernst, and Manaure Francisquez for their use and feedback on ARKODE, and
their patience as we ironed out kinks and constructed improvements.

Support for this work was provided in part by the U.S. Department of Energy, Office of Science,
Office of Advanced Scientific Computing Research, Scientific Discovery through Advanced Com-
puting (SciDAC) Program through the Frameworks, Algorithms, and Scalable Technologies for
Mathematics (FASTMath) Institute, under Lawrence Livermore National Laboratory subcontract
B626484 and DOE award DE-SC0021354.

This research was supported in part by the Exascale Computing Project (17-SC-20-SC), a collabo-
rative effort of the U.S. Department of Energy Office of Science and the National Nuclear Security
Administration.

This research used resources of the Oak Ridge Leadership Computing Facility at the Oak Ridge
National Laboratory, which is supported by the Office of Science of the U.S. Department of Energy
under Contract No. DE-AC05-00OR22725.

This work was performed under the auspices of the U.S. Department of Energy by Lawrence
Livermore National Laboratory under contract DE-AC52-07NA27344. Lawrence Livermore National
Security, LLC. LLNL-JRNL-835429.

REFERENCES
[1] Tom Abel, Peter Anninos, Yu Zhang, and Michael L. Norman. 1997. Modeling primordial gas in numerical cosmology.

New Astronomy 2, 3 (1997), 181 – 207. https://doi.org/10.1016/S1384-1076(97)00010-9

[2] Shrirang Abhyankar, Jed Brown, Emil M. Constantinescu, Debojyoti Ghosh, Barry F. Smith, and Hong Zhang. 2018.

PETSc/TS: A Modern Scalable ODE/DAE Solver Library. arXiv:1806.01437 [math.NA]

[3] Robert Anderson, Julian Andrej, Andrew Barker, Jamie Bramwell, Jean-Sylvain Camier, Jakub Cerveny, Veselin Dobrev,
Yohann Dudouit, Aaron Fisher, Tzanio Kolev, Will Pazner, Mark Stowell, Vladimir Tomov, Ido Akkerman, Johann
Dahm, David Medina, and Stefano Zampini. 2021. MFEM: A Modular Finite Element Methods Library. Computers &
Mathematics with Applications 81 (2021), 42–74. https://doi.org/10.1016/j.camwa.2020.06.009

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

The ARKODE IVP solver infrastructure

0:23

[4] Cody J. Balos, David J. Gardner, Carol S. Woodward, and Daniel R. Reynolds. 2021. Enabling GPU Accelerated
Computing in the SUNDIALS Time Integration Library. Parallel Comput. 108 (Dec. 2021), 102836. https://doi.org/10.
1016/j.parco.2021.102836

[5] Przemyslaw Bogacki and Lawrence F. Shampine. 1989. A 3(2) pair of Runge–Kutta formulas. Appl. Math. Lett. 2 (1989),

321–325. https://doi.org/10.1016/0893-9659(89)90079-7

[6] Jeff R. Cash and Alan H. Karp. 1990. A variable order Runge-Kutta method for initial value problems with rapidly
varying right-hand sides. ACM Trans. Math. Software 16 (1990), 201–222. https://doi.org/10.1145/79505.79507
[7] Jessica Cervi and Raymond J Spiteri. 2019. A comparison of fourth-order operator splitting methods for cardiac

simulations. Applied Numerical Mathematics 145 (2019), 227–235.

[8] Rujeko Chinomona and Daniel R. Reynolds. 2021. Implicit-Explicit Multirate Infinitesimal GARK Methods. SIAM J. Sci.

Comput. 43, 5 (Jan. 2021), A3082–A3113. https://doi.org/10.1137/20M1354349

[9] Emil M. Constantinescu and Adrian Sandu. 2013. Extrapolated Multirate Methods for Differential Equations with

Multiple Time Scales. J Sci Comput 56, 1 (July 2013), 28–44. https://doi.org/10.1007/s10915-012-9662-z

[10] Graeme J. Cooper and Ali Sayfy. 1980. Additive Methods for the Numerical Solution of Ordinary Differential Equations.

Math. Comp. 35 (1980), 1159–1172.

[11] Stephen DeWitt, Philip Fackler, Younggil Song, Balasubramaniam Radhakrishnan, and Sarma Gorti. 2022. MEUMAPPS

(C++ Version). https://doi.org/10.11578/dc.20220114.1

[12] Robert D. Falgout et al. 2022. XBraid: Parallel multigrid in time. http://llnl.gov/casc/xbraid.
[13] Robert D. Falgout, Stephanie Friedhoff, Tzanio V. Kolev, Scott P. MacLachlan, and Jacob B. Schroder. 2014. Parallel

time integration with multigrid. SIAM Journal of Scientific Computing 36 (2014), C635–C661.

[14] Alex C. Fish and Daniel R. Reynolds. 2022. Adaptive time step control for infinitesimal multirate methods. https:

//doi.org/10.48550/ARXIV.2202.10484

[15] Manaure Francisquez, Darin R. Ernst, Daniel R. Reynolds, and Cody J. Balos. 2021. 63rd Annual Meeting of the
APS Division of Plasma Physics - A 2D gyrofluid model for coupled toroidal ITG/ETG multiscale turbulence and its
comparison to gyrokinetics. In Bulletin of the American Physical Society, Vol. 66. American Physical Society, Pittsburgh,
PA.

[16] Todd Gamblin, Matthew P. LeGendre, Michael R. Collette, Gregory L. Lee, Adam Moody, Bronis R. de Supinski, and
W. Scott Futral. 2015. The Spack Package Manager: Bringing order to HPC software chaos. In Supercomputing 2015
(SC’15). ACM/IEEE, Austin, Texas.

[17] David J. Gardner, Jorge E. Guerra, François P. Hamon, Daniel R. Reynolds, Paul A. Ullrich, and Carol S. Woodward.
2018. Implicit–explicit (IMEX) Runge–Kutta methods for non-hydrostatic atmospheric models. Geosci. Model Dev. 11, 4
(2018), 1497–1515.

[18] David J. Gardner, Daniel R. Reynolds, Carol S. Woodward, and Cody J. Balos. 2020. Enabling New Flexibility in the

SUNDIALS Suite of Nonlinear and Differential/Algebraic Equation Solvers. arXiv:2011.10073 [cs.MS]

[19] David J. Gardner, Carol S. Woodward, Daniel R. Reynolds, Gregg Hommes, Sylvie Aubry, and A. Tom Arsenlis. 2015.
Implicit integration methods for dislocation dynamics. Modelling and Simulation in Materials Science and Engineering
23, 2 (2015), 025006.

[20] C. William Gear and Daniel R. Wells. 1984. Multirate Linear Multistep Methods. BIT 24, 4 (Dec. 1984), 484–502.

https://doi.org/10.1007/BF01934907

[21] Simon C. O. Glover and Tom Abel. 2008. Uncertainties in H2 and HD chemistry and cooling and their role in
early structure formation. Monthly Notices of the Royal Astronomical Society 388, 4 (08 2008), 1627–1651. https:
//doi.org/10.1111/j.1365-2966.2008.13224.x

[22] Michael Günther and Adrian Sandu. 2016. Multirate Generalized Additive Runge Kutta Methods. Numer. Math. 133, 3

(July 2016), 497–524. https://doi.org/10.1007/s00211-015-0756-z

[23] Kjell Gustafsson. 1991. Control theoretic techniques for stepsize selection in explicit Runge-Kutta methods. ACM

Trans. Math. Software 17 (1991), 533–554.

[24] Kjell Gustafsson. 1994. Control-theoretic techniques for stepsize selection in implicit Runge-Kutta methods. ACM

Trans. Math. Software 20 (1994), 496–512.

[25] Ernst Hairer, Syvert P. Nørsett, and Gerhard Wanner. 2000. Solving Ordinary Differential Equations I – Nonstiff Problems

(2 ed.). Springer Series in Computational Mathematics, Vol. 8. Springer-Verlag, Berlin.

[26] Ernst Hairer and Gerhard Wanner. 2002. Solving Ordinary Differential Equations II – Stiff and Differential-Algebraic

Problems (2 ed.). Springer Series in Computational Mathematics, Vol. 14. Springer-Verlag, Berlin.

[27] Kathie L. Hiebert and Lawrence F. Shampine. 1980. Implicitly Defined Output Points for Solutions of ODEs. Technical

Report SAND80-0180. Sandia National Laboratories.

[28] Inmaculada Higueras. 2006. Strong Stability for Additive Runge–Kutta Methods. SIAM J. Numer. Anal. 44, 4 (Jan. 2006),

1735–1758. https://doi.org/10.1137/040612968

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

0:24

D. R. Reynolds, D. J. Gardner, C. S. Woodward, and R. Chinomona

[29] Inmaculada Higueras. 2009. Characterizing Strong Stability Preserving Additive Runge-Kutta Methods. J Sci Comput

39, 1 (April 2009), 115–128. https://doi.org/10.1007/s10915-008-9252-2

[30] Inmaculada Higueras, Natalie Happenhofer, Othmar Koch, and Friedrich Kupka. 2014. Optimized strong stability
preserving IMEX Runge–Kutta methods. J. Comput. Appl. Math. 272 (Dec. 2014), 116–140. https://doi.org/10.1016/j.
cam.2014.05.011

[31] Alan C. Hindmarsh, Peter N. Brown, Keith E. Grant, Steven L. Lee, Radu Serban, Dan E. Shumaker, and Carol S.
Woodward. 2005. SUNDIALS: Suite of Nonlinear and Differential/Algebraic Equation Solvers. ACM Trans. Math.
Software 31, 3 (2005), 363–396.

[32] Alan C. Hindmarsh and Radu Serban. 2012. User Documentation for CVODE v2.7.0. Technical Report UCRL-SM-208108.

Lawrence Livermore National Laboratory.

[33] Christopher A. Kennedy and Mark H. Carpenter. 2003. Additive Runge-Kutta schemes for convection-diffusion-reaction

equations. Appl. Numer. Math. 44 (2003), 139–181. https://doi.org/10.1016/S0168-9274(02)00138-1

[34] Christopher A. Kennedy and Mark H. Carpenter. 2003.

Additive Runge–Kutta Schemes for Convec-
tion–Diffusion–Reaction Equations. Applied Numerical Mathematics 44, 1-2 (Jan. 2003), 139–181. https://doi.org/10.
1016/S0168-9274(02)00138-1

[35] Christopher A. Kennedy and Mark H. Carpenter. 2019. Higher-order additive Runge-Kutta schemes for ordinary

differential equations. Appl. Numer. Math. 136 (2019), 183–205.

[36] Christopher A. Kennedy and Mark H. Carpenter. 2019. Higher-Order Additive Runge–Kutta Schemes for Ordinary
Differential Equations. Applied Numerical Mathematics 136 (Feb. 2019), 183–205. https://doi.org/10.1016/j.apnum.2018.
10.007

[37] Oswald Knoth and Ralf Wolke. 1998. Implicit-explicit Runge-Kutta methods for computing atmospheric reactive flows.

Appl. Numer. Math. 28, 2 (1998), 327–341.

[38] H. Kreckel, H. Bruhns, M. Čížek, S. C. O. Glover, K. A. Miller, X. Urbain, and D. W. Savin. 2010. Experimental
Results for H2 Formation from H- and H and Implications for First Star Formation. Science 329, 5987 (2010), 69–71.
https://doi.org/10.1126/science.1187191

[39] Vu Thai Luan, Rujeko Chinomona, and Daniel R. Reynolds. 2020. A New Class of High-Order Methods for Multirate
Differential Equations. SIAM Journal on Scientific Computing 42, 2 (Jan. 2020), A1245–A1268. https://doi.org/10.1137/
19M125621X

[40] Curtis C. Ober. 2022. The Tempus Project Website. https://trilinos.github.io/tempus.html.
[41] Lorenzo Pareschi and Giovanni Russo. 2005. Implicit–Explicit Runge–Kutta Schemes and Applications to Hyperbolic
Systems with Relaxation. J Sci Comput 25, 1 (Oct. 2005), 129–155. https://doi.org/10.1007/s10915-004-4636-4
[42] Christopher Rackauckas and Qing Nie. 2017. DifferentialEquations.jl–a performant and feature-rich ecosystem for

solving differential equations in Julia. Journal of Open Research Software 5, 1 (2017), 15.

[43] Bala Radhakrishnan, Sarma Gorti, and Suresh Sudharsanam Babu. 2016. Phase field simulations of autocatalytic
formation of alpha lamellar colonies in Ti-6Al-4V. Metallurgical and Materials Transactions A 47, 12 (2016), 6577–6592.
[44] Hendrik Ranocha, Lisandro Dalcin, Matteo Parsani, and David I. Ketcheson. 2021. Optimized Runge-Kutta Methods
with Automatic Step Size Control for Compressible Computational Fluid Dynamics. Communications on Applied
Mathematics and Computation (2021), 1–38.

[45] Daniel R. Reynolds, David J. Gardner, and Cody J. Balos. 2021. SUNDIALS ManyVector+Multirate Demonstration Code.

https://github.com/sundials-codes/sundials-manyvector-demo.

[46] Daniel R. Reynolds, David J. Gardner, Cody J. Balos, and Carol S. Woodward. 2019.

SUNDIALS Multi-

physics+MPIManyVector Performance Testing. arXiv:1909.12966 [cs] (Sept. 2019). arXiv:1909.12966 [cs]

[47] Daniel R. Reynolds, David J. Gardner, Carol S. Woodward, and Cody J. Balos. 2022. User Documentation for ARKODE.

https://sundials.readthedocs.io/en/latest/arkode.

[48] Steven Roberts, John Loffeld, Arash Sarshar, Carol S Woodward, and Adrian Sandu. 2021. Implicit multirate GARK

methods. Journal of Scientific Computing 87, 1 (2021), 1–32.

[49] Steven Roberts, Arash Sarshar, and Adrian Sandu. 2020. Coupled Multirate Infinitesimal GARK Schemes for Stiff
Systems with Multiple Time Scales. SIAM Journal on Scientific Computing 42, 3 (2020), A1609–A1638. https://doi.org/
10.1137/19M1266952

[50] Adrian Sandu. 2019. A Class of Multirate Infinitesimal GARK Methods. SIAM J. Numer. Anal. 57, 5 (Jan. 2019),

2300–2327. https://doi.org/10.1137/18M1205492

[51] Martin Schlegel, Oswald Knoth, Martin Arnold, and Ralf Wolke. 2009. Multirate Runge–Kutta Schemes for Advection

Equations. J. Comput. Appl. Math. 226, 2 (April 2009), 345–357. https://doi.org/10.1016/j.cam.2008.08.009

[52] Martin Schlegel, Oswald Knoth, Martin Arnold, and Ralf Wolke. 2009. Multirate Runge–Kutta schemes for advection

equations. J. Comput. Appl. Math. 226 (2009), 345–357.

[53] Martin Schlegel, Oswald Knoth, Martin Arnold, and Ralf Wolke. 2012. Implementation of multirate time integration

methods for air pollution modelling. GMD 5 (2012), 1395–1405.

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

The ARKODE IVP solver infrastructure

0:25

[54] Martin Schlegel, Oswald Knoth, Martin Arnold, and Ralf Wolke. 2012. Numerical solution of multiscale problems in

atmospheric modeling. Appl. Numer. Math. 62 (2012), 1531–1542.

[55] Chi-Wang Shu. 2003. High-order Finite Difference and Finite Volume WENO Schemes and Discontinuous Galerkin
Methods for CFD. International Journal of Computational Fluid Dynamics 17, 2 (2003), 107–118. https://doi.org/10.
1080/1061856031000104851

[56] Hariswaran Sitaraman, Shashank Yellapantula, Marc T. Henry de Frahan, Bruce Perry, Jon Rood, Ray Grout, and
Marc Day. 2021. Adaptive mesh based combustion simulations of direct fuel injection effects in a supersonic cavity
flame-holder. Combustion and Flame 232 (2021), 111531.

[57] Gustaf Söderlind. 1998. The automatic control of numerical integration. CWI Quarterly 11 (1998), 55–74.
[58] Gustaf Söderlind. 2003. Digital filters in adaptive time-stepping. ACM Trans. Math. Software 29 (2003), 1–26.
[59] Gustaf Söderlind. 2006. Time-step selection algorithms: Adaptivity, control and signal processing. Appl. Numer. Math.

56 (2006), 488–502.

[60] Stanimire Tomov, Jack Dongarra, and Marc Baboulin. 2010. Towards dense linear algebra for hybrid GPU accelerated
manycore systems. Parallel Comput. 36, 5-6 (June 2010), 232–240. https://doi.org/10.1016/j.parco.2009.12.005
[61] Cynthia S. Trevisan and Jonathan Tennyson. 2002. Calculated rates for the electron impact dissociation of molecular
hydrogen, deuterium and tritium. Plasma Physics and Controlled Fusion 44, 7 (Jun 2002), 1263–1276. https://doi.org/10.
1088/0741-3335/44/7/315

[62] INdAM Bari unit project group. 2013. Test Set for IVP Solvers. https://archimede.dm.uniba.it/~testset/testsetivpsolvers.
[63] Christopher J. Vogl, Andrew Steyer, Daniel R. Reynolds, Paul A. Ullrich, and Carol S. Woodward. 2019. Evaluation of
Implicit-Explicit Additive Runge-Kutta Integrators for the HOMME-NH Dynamical Core. J. Adv. Model. Earth Syst. 11,
12 (2019), 4228–4244.

[64] Jörg Wensch, Oswald Knoth, and Alexander Galant. 2009. Multirate Infinitesimal Step Methods for Atmospheric Flow

Simulation. Bit Numer Math 49, 2 (June 2009), 449–473. https://doi.org/10.1007/s10543-009-0222-3

[65] J.A. Zonneveld. 1963. Automatic integration of ordinary differential equations. Technical Report R743. Mathematisch

Centrum, Postbus 4079, 1009AB Amsterdam.

ACM Trans. Math. Softw., Vol. 0, No. 0, Article 0. Publication date: 2022.

