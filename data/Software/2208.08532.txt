Survey of Methods for Solving Systems of Nonlinear Equations, Part II:
Optimization Based Approaches

Ilias S. Kotsireas
ikotsire@wlu.ca
Wilfrid Laurier University
Canada

Panos M. Pardalos
ppardalos@toxeus.org
Toxeus Systems LLC
Orlando, Florida, USA

Alexander Semenov
asemenov@uﬂ.edu
University of Florida
Gainesville, Florida, USA

William T. Trevena
wtrevena@uﬂ.edu
University of Florida
Gainesville, Florida, USA

Michael N. Vrahatis
vrahatis@math.upatras.gr
University of Patras
Patras, Greece

August 19, 2022

Abstract

This paper presents a comprehensive survey of methods which can be utilized to search for solutions to
systems of nonlinear equations (SNEs). Our objectives with this survey are to synthesize pertinent literature
in this ﬁeld by presenting a thorough description and analysis of the known methods capable of ﬁnding one or
many solutions to SNEs, and to assist interested readers seeking to identify solution techniques which are well
suited for solving the various classes of SNEs which one may encounter in real world applications.

To accomplish these objectives, we present a multi-part survey.

In part one, we focused on root-ﬁnding
approaches which can be used to search for solutions to a SNE without transforming it into an optimization
problem. In part two, we introduce the various transformations which have been utilized to transform a SNE
into an optimization problem, and we discuss optimization algorithms which can then be used to search for
solutions. We emphasize the important characteristics of each method, and we discuss promising directions for
future research. In part three, we will present a robust quantitative comparative analysis of methods capable of
searching for solutions to SNEs.

Keywords: systems of nonlinear equations, global optimization, localization of zeros, computation of roots, meta-
heuristics, topological degree, total number of solutions and extrema

1 Introduction

This is the second part of a survey on methods for ﬁnding one or many real solutions to a system of nonlinear
equations (SNE):

2
2
0
2

g
u
A
7
1

]
S
M

.
s
c
[

1
v
2
3
5
8
0
.
8
0
2
2
:
v
i
X
r
a

Fm(x) = Θm ≡ (0, 0, . . . , 0)(cid:62) ⇐⇒

(1)






f1(x1, x2, . . . , xn) = 0,

f2(x1, x2, . . . , xn) = 0,
...
fm(x1, x2, . . . , xn) = 0,

where Fm = (f1, f2, . . . , fm) : Dn ⊂ Rn → Rm, where f1, f2, . . . , fm are real-valued continuous or continuously
diﬀerentiable functions on the domain Dn, and where at least one of f1, f2, . . . , fm is nonlinear. For example,
consider the system of transcendental equations

F2(x) = Θ2 ≡ (0, 0)(cid:62) ⇐⇒

(cid:40)f1(x1, x2) = x1 − x1 sin(x1 + 5x2) − x2 cos(5x1 − x2) = 0,

f2(x1, x2) = x2 − x2 sin(5x1 − 3x2) + x1 cos(3x1 + 5x2) = 0,

(2)

which is comprised of two transcendental equations of two unknowns (See Figure 1).

1

 
 
 
 
 
 
Figure 1: An example of a SNE with two transcendental equations of two unknowns as introduced by Eq. (2):
(Blue): f1(x1, x2) = x1 − x1 sin(x1 + 5x2) − x2 cos(5x1 − x2) = 0;
(Red): f2(x1, x2) = x2 − x2 sin(5x1 − 3x2) +
x1 cos(3x1 + 5x2) = 0. Solutions to this SNE are deﬁned as the points where the blue and red contours intersect.
Finding all of the points within a certain region which satisfy both equations is a challenging task.

Finding one or more solutions to a SNE is a challenging and ubiquitous task faced in many ﬁelds including
chemistry [1, 2, 3], chemical engineering [4], automotive steering [5], power ﬂow [6, 7], large-scale integrated circuit
designs [8], climate modeling [9], materials engineering [10], robotics [11, 12, 13, 14], nuclear engineering [15],
image restoration [16], protein interaction networks [8], neurophysiology [17], economics [18], ﬁnance [19], applied
mathematics [20], physics [21], ﬁnding string vacua [22], machine learning [23, 24], and geodesy [25, 26] among others.
The problem of solving even a system of polynomial equations has been proven to be NP-hard [27]. Furthermore,
it has also been proven [28] that no general algorithm exists for determining whether an integer solution exists for
a polynomial equation with a ﬁnite number of unknowns and only integer coeﬃcients. The latter has been known
as Hilbert’s 10th problem.

1.1 Notation / Scientiﬁc Style
Throughout this paper, we utilize x = (x1, x2, . . . , xn)(cid:62) ∈ D ⊂ Rn to denote a real vector within the bounded
n)(cid:62) ∈ D ⊂ Rn to denote a real solution to a SNE such that all
1, x∗
domain D. Furthermore, we utilize x∗ = (x∗
n)(cid:62) ∈
equations in the SNE are satisﬁed (Fm(x∗) = 0). In an iterative method, we utilize xk = (xk
D ⊂ Rn for k = 0, 1, . . . to denote the vector found during the k−th iteration of the iterative method. Here, xk
i
denotes the i−th coordinate of the vector xk. When we discuss optimization methods, we denote an objective
function as ϕ : Rn → R, and we denote the corresponding gradient as ∇ϕ(x).

2, . . . , xk

2, . . . , x∗

i , . . . xk

1, xk

1.2 Terminology

Although we refer to Eq.
(2) as a system of nonlinear equations (SNE), such systems have been referred to in a
variety of diﬀerent ways in literature. For example, articles [29, 30, 31, 32, 33, 34] utilize the abbreviation “SNLE”
to refer to a system of nonlinear equations, and article [35] uses the abbreviation “SoNE”. Other papers refer to
Eq. (2) as a nonlinear system of equations, and use the abbreviations “NSE” [36, 37] and “NLS” [38]. Eq. (2) has
also been referred to as a nonlinear equation system (NES) [39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53].
The survey in article [54] uses the terminology Nonlinear Equations (NEs) to refer to a system of one or more
nonlinear equations.

When m > n, a SNE can be referred to as an overdetermined SNE, and when n > m, a SNE can be referred to

2

as an underdetermined SNE. When m = n, a SNE can be referred to as a square SNE [55]. Furthermore, a SNE is
considered to be consistent if a solution exists which satisﬁes all equations [56].

For a square SNE, a solution x∗ = (x∗

n)(cid:62) of the SNE Fn(x) = Θn or equivalently a zero x∗ of the
function Fn(x) or a root x∗ of the function Fn(x) is called simple if for the determinant of the corresponding
Jacobian matrix:

2, . . . , x∗

1, x∗

JFn (x) ≡ F (cid:48)

n(x)ij ≡

(cid:27)

(cid:26) ∂fi(x)
∂xj

ij

≡














∂f1(x)
∂x1

∂f2(x)
∂x1
...
∂fn(x)
∂x1

∂f1(x)
∂x2

∂f2(x)
∂x2
...
∂fn(x)
∂x2

· · ·

· · ·
. . .

· · ·














,

∂f1(x)
∂xn

∂f2(x)
∂xn
...
∂fn(x)
∂xn

(3)

at x∗ it holds that det JFn (x∗) (cid:54)= 0, otherwise it is called multiple. The problem of conservation and decomposition
of a multiple root into simple roots in the case of systems of homogeneous algebraic equations has been tackled
in [57]. This approach can be applied to high dimensional CAD where it is sometimes required to compute the
intersection of several hypersurfaces that are a perturbation of a set of original unperturbed hypersurfaces.

When Fn satisﬁes the monotonicity condition:

(cid:0)Fn(x) − Fn(y)(cid:1)(cid:62)

(x − y) (cid:62) 0, ∀ x, y ∈ Rn,

(4)

the corresponding SNE can be referred to as a system of monotone nonlinear equations [58]. Furthermore, Fn is
considered to be Lipschitz continuous if there exists L > 0 such that

(cid:107)Fn(x) − Fn(y)(cid:107)2 (cid:54) L(cid:107)x − y(cid:107)2, ∀ x, y ∈ Rn.

(5)

1.3 Comparison to other surveys

Other surveys discussing solution techniques for SNEs include [59] and [54]. We have decided to conduct this
comprehensive literature review because many new solution techniques for SNEs have been introduced since the
publication of [59] in 1994, and because the recent survey presented in [54] focuses mainly on methods which ﬁrst
convert a SNE into an optimization problem, and then search for multiple solutions to the optimization problem
using Intelligent Optimization Algorithms (IOAs). The IOAs discussed in article [54] are primarily metaheuristics
for global optimization. Although the survey in article [54] provides a very nice discussion of IOAs for solving SNEs
reformulated as optimization problems, many of the IOAs they discuss are only introduced at a very high level,
only eight IOAs were tested in their computational study, and the IOAs were evaluated on SNEs comprised of 20
equations or less. Also, article [54] only brieﬂy mentions methods which can be used to search for solutions to SNEs
without transforming them into optimization problems.

We would like to present a broader survey which covers in detail the large set of methods which can be used
to solve a SNE without transforming it into an optimization problem (i.e. homotopy and symbolic computation
methods). These methods were our main focus in part one of this survey. In part two, we expand upon article
[54] by introducing additional reformulation techniques and optimization algorithms which have been used to solve
SNEs, and by discussing in much more detail many optimization algorithms which were only brieﬂy introduced in
article [54]. This will allow us to appropriately set the stage for the comprehensive empirical study we will present
in part three of this survey. Furthermore, we believe it is imperative to introduce the reader to a technique for
determining the number of solutions to a SNE that exist within a bounded domain. Such techniques are of critical
practical importance for those interested in ﬁnding all solutions to a SNE that exist within a domain of interest.

1.4 Organization of this survey

Before we discuss optimization methods which can be used to search for solutions to SNEs, we ﬁrst introduce a
method which can be used to determine the total number of solutions to a SNE that exist within a given bounded
domain. If one can determine the number of solutions to a SNE which exist within a bounded domain of interest,
one can conﬁdently deﬁne an appropriate stopping criteria for algorithms which can be used to search for solutions.
Next, we will discuss the various ways that a SNE can be transformed into an optimization problem, and we will
introduce techniques that can be utilized to search for solutions to the global optimization problem that arises
when the most common reformulation is performed. We will conclude our paper by highlighting promising areas
for future research.

3

2 Determining the number of solutions to a SNE in a bounded domain

The knowledge of all the solutions of a system of nonlinear equations and/or all the extrema of a function is of
major importance in various ﬁelds. The total number of the solutions of a system of nonlinear equations can be
obtained by computing the topological degree. Suppose that the function Fn = (f1, f2, . . . , fn) : Dn ⊂ Rn → Rn is
deﬁned and is two times continuously diﬀerentiable in a bounded domain Dn of Rn with boundary b(Dn). Suppose
further that the solutions of Fn(x) = Θn are not located on b(Dn), and that they are simple (that the determinant
of the Jacobian of Fn at these solutions is non-zero). Then the topological degree of Fn at Θn relative to Dn is
denoted by deg[Fn, Dn, Θn] and can be deﬁned by the following relation:

deg[Fn, Dn, Θn] =

(cid:88)

x∈F −1

n (Θn)

sgn det JFn(x),

where det JFn(x) denotes the determinant of the Jacobian matrix and sgn deﬁnes the three-valued sign function.
The above deﬁnition can be generalized when Fn is only continuous [60].

It is evident that, since deg[Fn, Dn, Θn] is equal to the number of simple solutions of Fn(x) = Θn which give
positive determinant of the Jacobian matrix, minus the number of simple solutions which give negative determinant
of the Jacobian matrix, then the total number N s of simple solutions of Fn(x) = Θn can be obtained by the value
of deg[Fn, Dn, Θn] if all these solutions have the same sign of the determinant of the Jacobian matrix. Thus, Picard
considered the following extensions of the function Fn and the domain Dn [61, 62]:

Fn+1 = (f1, f2, . . . , fn, fn+1) : Dn+1 ⊂ Rn+1 → Rn+1,

(6)

where fn+1 = y det JFn , Rn+1 : x1, x2, . . . , xn, y, and Dn+1 is the direct product of the domain Dn with an
arbitrary interval of the real y-axis containing the point y = 0. Then the solutions of the following system of
equations:

fi(x1, x2, . . . , xn) = 0,
y det JFn(x1, x2, . . . , xn) = 0,

i = 1, 2, . . . , n,

are the same simple solutions of Fn(x) = Θn provided that y = 0. Obviously, the determinant of the Jacobian
matrix obtained for the function (6) is equal to (det JFn(x))2 which is always positive. Thus, the total number N s
of the solutions of the system Fn(x) = Θn can be obtained by the following value of the topological degree:

N s = deg[Fn+1, Dn+1, Θn+1].

For example, in the one dimensional case, using the above Picard’s extensions it is proved that the total number
of simple solutions N s of the equation f (x) = 0, where f : (a, b) ⊂ R → R is twice continuously diﬀerentiable in a
predetermined interval (a, b), is given by the following relation [61, 62]:

N s = −

(cid:34)

ε

1
π

(cid:90) b

a

f (x) f (cid:48)(cid:48)(x) − f (cid:48)2(x)
f 2(x) + ε2f (cid:48)2(x)

dx + arctan

(cid:19)

(cid:18) εf (cid:48)(b)
f (b)

− arctan

(cid:18) εf (cid:48)(a)
f (a)

(cid:19)(cid:35)

,

(7)

where ε is a small positive constant. Note that N s was shown to be independent of the value of ε. Also, the above
approach can be applied for computing the number of multiple solutions. Obviously, the total number N e of the
extrema of f ∈ C 3 i.e. x ∈ (a, b) such that f (cid:48)(x) = 0 can be obtained using the above formula (7). For details of the
topological degree we refer the interested reader to the books [63, 64, 65, 66, 60, 67]. Details of the computation of
the value of the topological degree and its usefulness as well as some applications and issues related to the number
of zeros can be found for example in [68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82].

Article [83] discusses the robust satisﬁability of SNEs, and discusses utilizing the topological degree to determine

the existence of robust solutions to a SNE.

3 Transforming a SNE into an optimization problem

Although many of the root ﬁnding methods described in part one of this survey are guaranteed to converge to a
solution on certain classes of SNEs (such as SNEs that satisfy the conditions of monotonicity (cf. Eq. (4)) and
Lipschitz continuity (cf. Eq. (5))), many of the root ﬁnding methods described in part one of this survey are
incapable of reliably ﬁnding solutions to SNEs which do not satisfy such conditions. As a result, many approaches
for solving general classes of SNEs ﬁrst reformulate a SNE as an optimization problem, and then utilize optimization

4

algorithms to attempt to ﬁnd solutions. However, it is important to note that the resulting optimization problem
may be multimodal and potentially nonsmooth. Therefore, global optimization techniques are often utilized to
attempt to ﬁnd solutions. For the interested reader, the books [84, 85] discuss feasibility and infeasibility in
optimization.

From the best of our knowledge, this section discusses the various techniques which have been presented in
literature for reformulating a SNE as an optimization problem. In literature, techniques have been presented for
transforming a SNE into a single objective global optimization problem (Section 3.1), into a multiobjective optimiza-
tion problem (Section 3.3), into a constrained optimization problem (Section 3.2), and into a nonlinear programming
problem (Section 3.4). Article [54] provides a nice analysis and comparison of many of the reformulation techniques
described in this section, especially in regards to the techniques they use to support eﬀorts aimed at ﬁnding multiple
solutions to a SNE.

3.1 Transforming a SNE into a single-objective global optimization problem

A nonlinear system of equations (Eq. (1)) may be transformed into a single-objective global optimization problem
by introducing the objective function

ϕ0(x) = α

|fi(x)|p

(8)

m
(cid:88)

where α > 0 and p > 0 (See Figure 2). Alternate formulations of ϕ0(x) have also been proposed in literature, for
example, article [86] proposes utilizing ϕ0(x) = (cid:112)(cid:80)m
i=1 f 2
i (x). In order to ﬁnd solutions to a SNE (Eq. (1)), the
following global optimization problem should be solved:

i=1

That is, to ﬁnd the value of the minimizer x:

ϕ0(x).

min
x∈D

arg min
x∈D

ϕ0(x),

(9)

for which ϕ0(x) attains its minimum value.

Although almost all papers which reformulate SNEs as optimization problems reformulate them as minimization
problems, SNEs can also be transformed into maximization problems. Article [87] proposes transforming SNEs into
maximization problems by maximizing over an objective function of the form ϕ(x) = 1/(1 + (cid:80)m
i=1 |fi(x)|). In this
reformulation, solutions to a SNE are represented by points with an objective function value of 1. Article [87] is
the only work that we are aware of that reformulates SNEs as maximization problems. For the purposes of this
paper, when we discuss reformulating a SNE as an optimization problem, we are referring to the standard case of
reformulating a SNE as a minimization problem such as Eq. (9).

(a) α = 1, p = 1

(b) α = 1, p = 2

Figure 2: The objective function surface ϕ0(x) = α (cid:80)m
example SNE introduced in Eq. (2) with two transcendental equations and two unknowns:
f1(x1, x2) = x1 − x1 sin(x1 + 5x2) − x2 cos(5x1 − x2) = 0; f2(x1, x2) = x2 − x2 sin(5x1 − 3x2) + x1 cos(3x1 + 5x2) = 0.

i=1 |fi(x)|p when α = 1, p = 1 and α = 1, p = 2 for the

Since systems of nonlinear equations may have more than one solution, the reformulated optimization problem
Eq. (9) may have more than one global minimizer, and each global minimizer with an objective function value

5

0246810121416020406080100120140of 0 (global minimum) will correspond to a solution to the SNE. Although the problem shown by Eq. (9) can be
repeatedly solved to ﬁnd many solutions to a SNE, depending on the solution technique used, the same solution(s)
to a SNE may be found repeatedly during the search for new unfound solutions. To address this, a plethora of
alternate reformulations have been utilized in literature which are speciﬁcally designed to help algorithms ﬁnd
further solutions to a SNE. These reformulations typically introduce a penalty (also referred to as a “repulsion” [46]
or “polarization” [5] technique) into the objective function to repel the search for new solutions away from solutions
which have already been found. These reformulations are often of the form:

ϕ(x) = ϕ0(x) + ϕk(x),

(10)

where ϕk(x) creates a penalty region around the k already found solutions (See Figure 3). Article [37] proposed to
represent ϕk(x) as:

ϕk(x) =

k
(cid:88)

j=0

a ξ

(cid:18) (cid:107)x − xj(cid:107)2
ρ

(cid:19)

,

(11)

where xj are already found solutions, k is the number of solutions found so far, a > 0 and ρ > 0 are user deﬁned
parameters, and ξ(δ) is a continuous real function that is positive for |δ| < 1 and zero elsewhere. Article [37]
proposes to utilize the following variants of ξ(δ):

(a) ξ(δ) = 1 − |δ| for |δ| < 1, otherwise 0,

(b) ξ(δ) = (1 − δ2)2 for |δ| < 1, otherwise 0,

(c) ξ(δ) = (1 + cos(πδ))/2 for |δ| < 1, otherwise 0,
(d) ξ(δ) = exp(cid:0)−δ2/(1 − δ2)(cid:1) for |δ| < 1, otherwise 0.

(a) α = 1, p = 1, a = 1, ρ = 1

(b) α = 1, p = 2, a = 4, ρ = 1

j=1 a ξ (cid:0)(cid:107)x − xj(cid:107)2/ρ(cid:1)
Figure 3: The penalized objective function ϕ(x) = ϕ0(x) + ϕk(x) = α (cid:80)m
2 and 0 otherwise) with a penalty ϕk(x) for a single found solution (k = 1) x1
(where ξ(δ) = (2 − δ2)2 for |δ| <
at (0, 0) when α = 1, p = 1, a = 1, ρ = 1 and α = 1, p = 2, a = 4, ρ = 1 for the example SNE introduced in Eq. (2):
f1(x1, x2) = x1 − x1 sin(x1 + 5x2) − x2 cos(5x1 − x2) = 0; f2(x1, x2) = x2 − x2 sin(5x1 − 3x2) + x1 cos(3x1 + 5x2) = 0.
Notice the sharply elevated region surrounding the point (0, 0) on both objective function surfaces.

i=1 |fi(x)|p + (cid:80)k

√

Notice that if there are no solutions found yet, then Eq. (10) reduces to the original optimization problem Eq. (9).
A similar approach is suggested in the papers [88, 89] where

ϕk(x) = β

k
(cid:88)

j=0

exp(cid:0)−(cid:107)x − xj(cid:107)2) χ((cid:107)x − xj(cid:107)2

(cid:1).

(12)

Here, β is a large constant, (cid:37) is a small constant, χ(δ) = 1 when δ < (cid:37) and otherwise χ(δ) = 0. For the rest of the
reformulations introduced in Section 3.1, we assume that at least one solution has been found so far (k (cid:62) 1).

Article [5] proposes minimizing an objective function of the form

ϕ(x) =

ϕ0(x)
j=1 arctan (cid:107)x − xj(cid:107)2

Πk

,

6

(13)

0510152025303540020406080100120140160while article [90] proposes minimizing an objective function of the form

(14)
j=1
where ε > 0 is a small user deﬁned constant and α (cid:62) 1 is a user deﬁned parameter which is utilized to adjust the
radius of the penalty region.

ϕ(x) = (cid:0)ϕ0(x) + ε(cid:1) Πk

(cid:12)coth(α(cid:107)x − xj(cid:107)2)(cid:12)
(cid:12)
(cid:12),

Article [91] proposes minimizing an objective function of the form

ϕ(x) = ϕ0(x) Πk

j=1ξ(x, xj, α, ρ),

(15)

where

ξ(x, xj, α, ρ) = | erf(α(cid:107)x − xj(cid:107)2)|−1 if (cid:107)x − xj(cid:107)2 (cid:54) ρ, and 0 otherwise.

Here, ρ > 0 and α > 0 are user deﬁned parameters which adjust the radius of the penalty region and the magnitude
of the penalty respectively, and erf(x) = 2√
π

(cid:82) x
0 exp(−t2)dt.

Article [44] proposes a similar reformulation to Eq. (15) with a dynamic repulsion radius that is updated within

a evolutionary algorithm, and article [92] proposes minimizing an objective function of the form:

ϕ(x) = ϕ0(x) +

k
(cid:88)

j=1

ξ(x, xj, α, ρ),

(16)

where

ξ(x, xj, α, ρ) = α(cid:0)1 − erf((cid:107)x − xj(cid:107)2)(cid:1) if (cid:107)x − xj(cid:107)2 (cid:54) ρ, and 0 otherwise,
where ρ > 0 and α > 0 are user deﬁned parameters which adjust the radius of the penalty region and the magnitude
of the penalty respectively, and where erf(x) = 2√
π

(cid:82) x
0 exp(−t2)dt.
Other single objective reformulations have been utilized for particular applications. For example, articles [93, 94]

propose minimizing over an objective function of the form:

ϕ(x) = ϕ0(x) Πk

j=1

(cid:18) Πn
Πn

i=1((bi)kα)
i=1|xi − xk
i |α

(cid:19)

,

(17)

where a (cid:54) x (cid:54) b, xj for j = 1, 2, . . . , k are already found solutions (k is the number of solutions found so far), xi is
the i−th coordinate of the solution x, and α > 0 is a user deﬁned parameter. Article [94] also proposes a slightly
diﬀerent objective function, they propose minimizing over an objective function of the form

ϕ(x) = ϕ0(x) Πk

j=1 exp

(cid:18) Πn
Πn

i=1((bi)kα)
i=1|xi − xk
i |α

(cid:19)

.

(18)

It is important to note that for the reformulations in Eq. (17) and Eq. (18), if any of the coordinates of a new
solution are the same as that of a previous found solution, the objective function value will be inﬁnity. By using
this reformulation, one can ensure that for each new solution that is found, every dimension will be diﬀerent from
that of all previously found solutions.

3.2 Transforming a SNE into a single-objective constrained optimization problem

In addition to the non-constrained reformulations we have described so far, constrained reformulations include:

min ϕ(x) for ϕ(x) =

m
(cid:88)

i=1

fi(x),

(19)

subject to

fi(x) (cid:62) 0, ∀ i = 1, 2, . . . , m,
as presented in [34]. Alternatively, article [95] ﬁrst partitioned the SNE into two sets of equations S1 = {1, 2, . . . , m}
and S2 = {1, 2, . . . , m}/S1. Based on these two sets of equations, article [95] then utilized the reformulation:

min ϕ(x) for ϕ(x) =

f 2
i (x),

(cid:88)

i∈S1

(20)

subject to

fj(x) = 0, ∀ j ∈ S2.
Constrained optimization based transformation techniques such as those presented above require a constraint han-
dling method to solve.

7

3.3 Transforming a SNE into a multiobjective optimization problem

Instead of transforming a SNE into a single-objective optimization problem, a number of research papers (see for
example [18, 40]) suggest transforming a SNE (Eq. (1)) into a multiobjective optimization problem of the form






min |f1(x1, x2, . . . , xn)|,

min |f2(x1, x2, . . . , xn)|,
...
min |fm(x1, x2, . . . , xn)|,

(21)

which can be solved via multiobjective optimization methods. Alternatively, instead of having an objective function
for each equation, article [96] randomly splits the m equations into two subsets S1 and S2 such that S1 ∩ S2 = ∅
and S1 ∪ S2 is equivalent to the SNE (1). In terms of these two sets, article [96] then transforms a SNE into a
biobjective optimization problem of the form:

or











min ϕ1(x) for ϕ1(x) =

min ϕ2(x) for ϕ2(x) =

min ϕ1(x) for ϕ1(x) =

min ϕ2(x) for ϕ2(x) =

|S1|
(cid:88)

i=1

|S2|
(cid:88)

i=1

|S1|
(cid:88)

i=1

|S2|
(cid:88)

i=1

|fS1(i)(x)|, s.t. fS1(i)(x) = 0,

|fS2(i)(x)|, s.t. fS2(i)(x) = 0,

|fS1(i)(x)|, s.t. fS1(i)(x) (cid:62) 0,

|fS2(i)(x)|, s.t. fS2(i)(x) (cid:62) 0.

Article [40] reformulates a SNE into a biobjective optimization problem of the form:






min ϕ1(x) for ϕ1(x) = x1 +

m
(cid:88)

i=1

|fi(x)|,

min ϕ2(x) for ϕ2(x) = 1 − x1 + m max |fi(x)|,

(22)

(23)

(24)

where i = 1, 2, . . . , m, and x1 represents the ﬁrst decision variable of x. In this reformulation, x1 is utilized to
ensure that the two objective functions conﬂict. Note that when using this reformulation, it may be diﬃcult to
detect multiple solutions that have the same value of x1 [54]. Expanding upon this approach, article [39] presented
a biobjective reformulation of the form:






min ϕ1(x) for ϕ1(x) =

(cid:80)n

i=1 wi xi
(cid:80)n
i=1 wi

+

m
(cid:88)

j=1

|fj(x)|,

min ϕ2(x) for ϕ2(x) = 1 −

(cid:80)n

i=1 wi xi
(cid:80)n
i=1 wi

+

m
(cid:88)

j=1

|fj(x)|,

(25)

where i = 1, 2, . . . , n, wi is a randomly generated weight for each variable such that (cid:80)n
i=1 wi = 1, n is the number
of decision variables in x, and m is the number of equations. By utilizing this reformulation, the risk of not being
able to identify two solutions with the same value of x1 inherent in reformulation (24) is decreased.

Also expanding upon reformulation (24), article [41] transforms a SNE into a multiobjective optimization prob-
lem with n + 1 objectives where n is the number of decision variables in the SNE. The reformulated multiobjective

8

optimization problem is of the form:






min ϕ1(x) for ϕ1(x) =

min ϕ2(x) for ϕ2(x) =

min ϕ3(x) for ϕ3(x) =

x1
n

x1
n

x1
n

+

+

+

x2
n − 1

x2
n − 1

x2
n − 1

+ · · · +

xn−1
2

+

xn
1

+ C

m
(cid:88)

i=1

|fi(x)| ln(n + 2),

+ (1 − xn) + C

m
(cid:88)

i=1

|fi(x)| ln(n + 1),

+ (1 − xn−1) + C

m
(cid:88)

i=1

|fi(x)| ln(n),

+ · · · +

+ · · · +

xn−1
2

xn−2
3

...

min ϕn(x) for ϕn(x) =

x1
n

+ (1 − x2) + C

m
(cid:88)

|fi(x)| ln(3),

min ϕn+1(x) for ϕn+1(x) = (1 − x1) + C

i=1
m
(cid:88)

|fi(x)| ln(2).

i=1

In article [47], a SNE is transformed into a biobjective optimization problem of the form:






min ϕ1(x) for ϕ1(x) =

m
(cid:88)

i=1

[fi(x)]2,

min ϕ2(x) for ϕ2(x) = −

1
Sn

Sn(cid:88)

j=1

K(x, xj),

(26)

(27)

where Sn is the size of the population utilized in the article’s proposed evolutionary algorithm, xj for j = 1, . . . , Sn
are the elements of the current population, K(x, xj) = exp(cid:0)−(cid:107)x − xj(cid:107)2/(2σ2)(cid:1) is the Gaussian kernel of x and xj,
and σ > 0 is the kernel radius. In [47], the authors set σ = 2. Here, the ﬁrst objective focuses on exploitation while
the second focuses on exploration. There is no guarantee that the two objectives ϕ1(x) and ϕ2(x) will conﬂict.

Article [97] reformulates a SNE as a dynamic tri-objective optimization problem, and introduces a self-adaptive
ranking multi-objective diﬀerential evolution algorithm which is utilized to solve the dynamic tri-objective opti-
mization problem. The proposed tri-objective optimization problem is of the form






min ϕ1(x) for ϕ1(x) =

(cid:80)Sn

j=1 (cid:107)x − rj(cid:107)2
(cid:80)Sn

maxt=1,...,Ps

j=1 (cid:107)xt − rj(cid:107)2

+

9ng3
γ3

(cid:32) m
(cid:88)

i=1

|fi(x)| + max

i=1,...,m

|fi(x)|

,

(cid:33)

min ϕ2(x) for ϕ2(x) = 1 −

(cid:80)Sn

j=1 (cid:107)x − rj(cid:107)2
(cid:80)Sn

maxt=1,...,Ps

j=1 (cid:107)xt − rj(cid:107)2

+

9ng3
γ3

(cid:32) m
(cid:88)

i=1

|fi(x)| + max

i=1,...,m

|fi(x)|

,

(28)

(cid:33)

min ϕ3(x) for ϕ3(x) =



max

1 −

Sn(cid:88)

j=1

(cid:107)x − xj(cid:107)
√
n
(1 − g
γ )
n√
Sn



, 0

 +

9ng3
γ3

(cid:32) m
(cid:88)

i=1

|fi(x)| + max

i=1,...,m

|fi(x)|

,

(cid:33)

where Sn is the population size utilized in the proposed evolutionary algorithm, rj for j = 1, 2, . . . , Sn are randomly
generated reference points at the initial stage, xt for t = 1, 2, . . . , Sn are the current points in the population, n
is the dimension of the solution vector x ∈ Rn, g is the index of the current evolutionary generation, and γ is the
maximum number of generations over which the evolutionary algorithm is allowed to evolve.

Since the proposed bi-objective and tri-objective optimization problems introduced in Eq. (27) and Eq. (28)
contain parameters which depend on the conﬁguration of algorithms proposed in the original papers, we refer the
interested reader to the source articles [97, 47] for additional details.

9

3.4 Transforming a SNE into a nonlinear programming problem

SNEs can also be explicitly reformulated as nonlinear programming problems. Article [38] reformulates a square
SNE (such that m = n) into a nonlinear programming problem of the form:

subject to

min (cid:13)

(cid:13)εi − ε∗
i

(cid:13)
(cid:13)∞,






(cid:12)fi(x)(cid:12)
(cid:12)

(cid:12) − εi (cid:54) 0,

εi (cid:62) 0,

(29)

(30)

where i = 1, 2, . . . , n and ε∗ ∈ Rn is the precision of the desired solution (meaning that ε∗
true solution to a SNE).

i = 0 corresponds to a

4 Optimization techniques to ﬁnd solutions to a SNE

By formulating SNEs of interest as optimization problems, many techniques traditionally utilized for ﬁnding one
or more minima of a function can be applied to attempt to ﬁnd solutions to SNEs. There are many well known
optimization algorithms which can be used to attempt to ﬁnd one or more minima of an objective function, and
the performance of these methods can vary considerably depending on the characteristics of the objective function.
However, some optimization algorithms can only be applied to objective functions with certain characteristics (of
diﬀerentiability class C 2 for example). Since some of the reformulations described in Section 3 can result in non-
smooth and multimodal objective function surfaces, it is important that the characteristics of the reformulated
objective function are considered when a solution technique is selected.

In cases where the characteristics of the reformulated objective function are diﬃcult to determine, one should
consider utilizing an optimization algorithm which can be applied to non-smooth and multimodal objective func-
tions. If one can assume that the reformulated objective function is unimodal and smooth (neither of which is true
in the general case for SNEs), one could simply use a local search method to attempt to ﬁnd a solution to a SNE
via minimization. If one can only assume that the reformulated objective function is unimodal, then a gradient-
free local search technique should be used. If one can not assume that the objective function is unimodal, then a
local search method alone is unlikely to be suﬃcient for ﬁnding a solution to a SNE. In the multimodal case, one
should attempt to ﬁnd solutions to a SNE by using an algorithm for global optimization, such as those described in
Section 4.2. Although the scope of our paper is focused on discussing techniques which have been directly utilized
in literature to search for solutions to SNEs, there are many optimization algorithms which have yet to be utilized
to search for solutions to SNEs. In addition to learning about the techniques explicitly described in this paper, we
suggest that the interested reader learn more about the taxonomy of global optimization algorithms by reviewing
articles such as [98].

In this paper, we have classiﬁed the optimization algorithms which have been utilized to search for solutions
to SNEs into two categories: (1) local search methods, and (2) global search methods. Section 4.1 describes a few
of the many local search techniques which can be used to attempt to ﬁnd a point x(cid:48) suﬃciently close to a critical
point on the objective function surface. Therefore, a solution to a SNE can be found if a local search algorithm
terminates at a point x(cid:48) which has an objective function value suﬃciently close to zero. Since the reformulated
objective function of an arbitrary SNE may be highly multimodal, local search techniques are often utilized within
hybrid metaheuristics and memetic algorithms to ﬁnd solutions to SNEs via global optimization. Section 4.2 focuses
on introducing metaheuristics which have been utilized to ﬁnd solutions to SNEs via global optimization. The book
[99] provides a nice introduction to heuristics for global optimization, and the books [100, 101] discuss strategies
for developing portfolios of such optimization algorithms. Unless otherwise noted, in Section 4 we will describe
techniques which can be used to solve SNEs reformulated into single objective non-constrained global optimization
problems such as Eq. (9).

4.1 Local search methods

Since Newton’s method is capable of ﬁnding the roots of a diﬀerentiable function, Newton’s method can be applied
to the gradient ∇ϕ(x) of a twice diﬀerentiable function ϕ(x) to ﬁnd critical points. Therefore, if an objective
function such as Eq. (10) is twice diﬀerentiable, Newton’s method can be applied from an arbitrary starting point
x0 ∈ D ⊂ Rn to ﬁnd a nearby local minimum or saddle point on the objective function surface. Once Newton’s

10

method terminates at a point x(cid:48) ∈ D ⊂ Rn, one can then check whether or not the objective function value at x(cid:48) is
suﬃciently close to zero to determine whether or not x(cid:48) is a solution to the NSE of interest (since every solution to
a SNE corresponds to a point with an objective function value of zero).

If the objective function is diﬀerentiable, then nonlinear gradient methods and nonlinear conjugate gradient
methods may be used to attempt to ﬁnd one if its critical points. Gradient descent methods are based on the
observation that the function ϕ(x) decreases the most in the direction opposite to its gradient ∇ϕ(x). Hence,
starting from an initial solution x0 ∈ D ⊂ Rn, the gradient descent method iteratively ﬁnds a sequence of new
solutions by calculating xi+1 = xi − αisi where si = ∇ϕ(xi) is the search direction and αi is the step size.
There are multiple methods for determining the step size αi, including the well known Barzilai-Borwein method
[102]. Article [103] provides a nice introduction to the Barzilai-Borwein method and compares the Barzilai-Borwein
method against alternative methods. Overview of gradient descent optimization methods may be found in [104].
Popular extension of the gradient descent method is called stochastic gradient descent, that can be eﬃcient when
the function ϕ(x) can be represented as a sum of large number of functions ϕ(x) = (cid:80)K
i ϕi(x). Then, the gradient
is estimated on a random subset of ϕi(x). Widely used stochastic gradient descent algorithms are ADAM [105],
AdaGrad[106], and others.

Conjugate gradient methods diﬀer from gradient descent methods by using the conjugate search direction si =
−∇ϕ(xi) + βisi−1. Multiple methods for calculating the parameter βi of the conjugate search direction have been
proposed in the literature. Commonly utilized methods for calculating βi were introduced by Fletcher–Reeves [107],
Polak–Ribi`ere [108], Hestenes-Stiefel [109], and Dai-Yuan [110] among others. Many variants based on conjugate
gradient methods have been proposed in literature. For example, articles [16, 111, 55, 112] propose new methods
which combine hyperplane projection techniques with the conjugate gradient method to solve systems of monotone
nonlinear equations (SNEs which satisfy the inequality in Eq. (4)). Article [113] applies the conjugate gradient
method to solve SNEs, and it suggests combining the Fletcher–Reeves and Polak–Ribi`ere methods with the Quasi-
Newton update. The paper ﬁrst reformulates a SNE into a unconstrained single objective optimization problem,
and then searches for a solution. Article [113] numerically evaluates the performance of the proposed method on
20 test problems with up to 10k dimensions, and most of the problems were solved by the proposed method in
under 3 seconds and with less than 30 iterations of the algorithm when coded in MATLAB and run on a computer
with a 2.13 GHz CPU processor and 2GB of RAM. Additional works which discuss using conjugate gradient based
methods for solving SNEs reformulated as single objective optimization problems include [114, 115].

In addition to Quasi-Newton methods, other commonly utilized derivative-free direct search methods worth
mentioning include the Rosenbrock search method [116], the Hooke and Jeeves pattern search method [117], Brent’s
method [118], and the Nelder-Mead simplex method [119]. The Nelder-Mead simplex method in particular has
been frequently utilized as a local search method within hybrid metaheuristics and memetic algorithms for ﬁnding
solutions to SNEs via global optimization [37, 92, 120, 2]. The books [121, 122] provide a nice introduction to
methods for derivative-free optimization.

4.2 Global search / global optimization methods

Global optimization is a well developed ﬁeld, and There are many ways to classify global search methods as shown
in article [98], but in this paper we decide to classify them into three main categories: (1) exact methods, (2) single-
solution-based methods, and (3) population-based methods. We consider exact methods to be methods which are
guaranteed to ﬁnd a solution via exhaustive search, we consider single-solution-based methods to be methods which
search the solution space with a single agent at a time (population = 1), and we consider population-based methods
to be methods which search the solution space simultaneously with many agents (population (cid:29) 1). Since much of
the recent literature discussing solution techniques for SNEs has focused on metaheuristcs, we focus our attention on
the two main classes of metaheuristics: the single-solution-based and population-based methods. Hybrid methods,
or methods which combine metaheuristics with local search algorithms, are not explicitly separated from the single-
solution based methods and the population-based methods in this survey as many of the metaheuristics mentioned
in these sections can easily be hybridized if desired. For example, see article [37] which hybridizes the Continuous
Variable Neighborhood Search (C-VNS) metaheuristic with the Nelder-Mead method for local search. For readers
who are interested in learning more about global optimization methods and applications, we refer the interested
reader to the books [123, 124, 125, 126, 127].

4.2.1 Exact methods

Exact methods for global optimization guarantee that a solution will be found within a speciﬁc tolerance (if one

11

exists) by exhaustively searching the solution space. Exact methods for global optimization are typically too
computationally expensive to be applied in practice, especially in cases where the objective function is highly
multimodal or the number of dimensions is very large. The Branch-and-bound algorithm is a well known exact
method for global optimization [128].

4.2.2 Single-solution-based methods

Single-solution-based methods explore the solution space with a single agent who makes decisions about which path
to take based upon a predeﬁned set of rules typically based upon the objective function values at the points which
the agent has explored so far. This section introduces single-solution-based methods which have been utilized in
literature to search for solutions to SNEs through global optimization.

Continuous Greedy Randomized Adaptive Search Procedure (C-GRASP): In [129], Hirsch et al. intro-
duced the Continuous Greedy Randomized Adaptive Search Procedure (C-GRASP) which extends Feo and Resende’s
Greedy Randomized Adaptive Search Procedure (GRASP) [130] for discrete optimization to the domain of continuous
global optimization. The C-GRASP metaheuristic utilizes multistart and a derivative-free stochastic local search
method to perform global optimization. In [88], Hirsch et al. utilize an enhanced version of the original C-GRASP
metaheuristic proposed in [129] to ﬁnd multiple solutions to Eq. (9) via global optimization. Each iteration of C-
GRASP is initialized with an initial coarse discretization of the search space and an initial random solution vector
x. Each iteration of C-GRASP consists of a series of construction-local improvement cycles where the output of
the construction phase is used as the input to the local search phase, and where the output from the local search
phase is used as the input for the next iteration’s construction phase. As the iterations progress, the discretization
of the search space becomes increasingly dense as C-GRASP converges to a minimum. After reaching a maximum
number of multi-start iterations, the C-GRASP metaheuristic returns all the solutions to the SNE that it found.

During C-GRASP’s construction phases, C-GRASP utilizes greediness and randomization to create a diverse
set of quality initial solutions from which to start local search. Each construction phase takes an initial feasible
solution x as an input, and starts by letting all coordinates of x be unﬁxed. Then, in an iterative fashion, C-
GRASP’s construction phase will ﬁrst conduct a line search in each unﬁxed coordinate direction of x (while holding
all other n − 1 coordinates at their current values) to ﬁnd the coordinate value along each dimension (using the
current discretization) that results in the best objective function value. After conducting this line search, the best
and worst objective function values found across all coordinates are saved in the variables min and max. Then,
each unﬁxed coordinate of x is set to the best value found during the coordinate-wise line search. From here, a
restricted candidate list of unﬁxed coordinates is formed which is comprised of the coordinates whose best objective
function values found during line search were less than or equal to α max +(1 − α) min where α ∈ [0, 1] is randomly
selected at the beginning of each construction phase. Then, a dimension in the restricted candidate list is selected
at random, and the corresponding coordinate value of x is ﬁxed and will no longer be moved throughout the
current construction phase. By selecting a coordinate at random from the restricted candidate list (meaning the
not necessarily the best coordinate is selected to be ﬁxed) the authors preserve some randomness which they argue
helps the C-GRASP metaheuristic explore more of the search space. This process repeats until all coordinates of
x are ﬁxed which ends the construction phase. The ﬁnal feasible point x found by the construction phase will then
serve as the starting point for the next derivative-free local search phase. Here, even though x may be a good
solution, it may not be optimal as the line search was performed along each coordinate direction. As a result, local
search is then conducted starting at the feasible point x found by the construction phase.

During each derivative-free local search phase, C-GRASP searches in the neighborhood of the current solution
for a better solution, where the neighborhood of the current solution x is deﬁned as the projection of all the current
grid points onto the hyper-sphere centered at x with radius equal to the current discretization level h. C-GRASP
then determines at which points in the neighborhood of x, if any, the objective function improves. Then, if an
improving point is identiﬁed, it is made the new current point and local search continues from this new point. This
local search process continues until an approximate local minimum x(cid:48) is reached such that taking a step in any
evaluated direction would result in a worse objective function value. The x(cid:48) returned by each local improvement
phase then serves as the starting point for the next construction phase. Speciﬁcally, the ﬁrst construction phase
(before any local search has been conducted) starts at a random feasible point, every construction phase after the
ﬁrst starts at the approximate local minimum x(cid:48) found by the previous local improvement phase, and each local
improvement phase starts at the point generated by the previous construction phase.

The original version of C-GRASP [129] was evaluated on three SNEs: (a) a SNE arising in robot kinematics
that is comprised of eight nonlinear equations in eight unknowns and which has 16 known roots [131, 124], (b) a

12

SNE from the area of chemical equilibria which has ten equations and ten unknowns and which has one physical
solution where all variables are positive [132], and (c) a transformed version of the original SNE from the area of
chemical equilibria which has ﬁve equations, ﬁne unknowns, and one solution where all variables are positive [132].
The original version of C-GRASP was tested ten times on the SNE arising in robot kinematics, and successfully
found all 16 solutions each time with an average runtime of 3,048s. On the original version of the SNE arising in
chemical interaction and equilibrium modeling, C-GRASP successfully found the solution on eight out of ten runs
with an average run time of 201.58s. On the transformed version of the SNE arising in chemical interaction and
equilibrium modeling, C-GRASP successfully found the solution on all ten runs with an average runtime of 37.53s.
The improved version of C-GRASP [88] was evaluated on four SNEs, three of which had two variables and two
unknowns, and one of which had three solutions and three unknowns. Over thousands of trials, C-GRASP found
all solutions to each system almost every time, and the longest average runtime for any of the problems tested was
5.06s. Other systems tested were solved in fractions of a second.

Continuous Variable Neighborhood Search (C-VNS): Continuous Variable Neighborhood Search (C-VNS)
is a continuous extension of the variable neighborhood search (VNS) metaheuristic proposed by [133], a popular
method for solving discrete optimization problems. C-VNS systematically explores the solution space by ﬁrst
deﬁning a set of neighborhood structures, and then repeatedly performing local search starting from a point within
the corresponding neighborhoods which increase in size when improving solutions are not found. C-VNS was utilized
to search for solutions to SNEs in [37]. The paper reformulates a SNE as an optimization problem and performs
minimization of the resulting objective function using C-VNS. The paper deﬁnes the set of neighborhood structures
to be a set of hyperspherical shells with increasing internal and external radii, so that the union of the shells covers
the entire solution space. C-VNS then performs local search using the Nelder-Mead method, starting at a random
point in the current neighborhood structure. The paper experimentally evaluates multiple local search methods,
along with multiple ways to reformulate problem 1. The paper concentrates on ﬁnding all solutions of small SNEs
(2-20), and the largest SNE described in the paper consisted of 1000 equations.

Tabu Search (TS): Developed initially for solving combinatorial optimization problems, Tabu Search (TS) is a
metaheuristic approach that can be utilized for global optimization. Starting at an initial feasible solution x, TS
follows a pre-deﬁned set of rules to identify a set of Y solutions in the neighborhood of x to explore. Let N (x)
denote the neighborhood of x such that Y ⊂ N (x). After evaluating the objective function value at each point
y ∈ Y, the point y∗ ∈ Y with the best objective function value is selected as the new starting point for the next
iteration of TS, even if the initial point x has a better objective function value than y∗. By allowing moves to points
with worse objective function values, TS attempts to escape the neighborhood of previously found local minima.
While exploring a discrete or discretized solution space, TS stores a list of recently visited points called a “tabu
list”. To ensure that TS continues to explore new regions of the solution space, TS prevents future moves to points
in the tabu list. Other memory structures containing information such as the best points visited so far may also
be maintained and utilized in an attempt to facilitate the performance of TS [134]. TS continues to explore the
solution space until a stopping criteria is met (in the case of SNEs, when the function value is suﬃciently close to
zero or upon a maximum number of iterations).

One variant of TS, named, Directed Tabu Search (DTS), incorporates local search methods into the TS search
procedure. Local search can either be conducted from the identiﬁed y∗ ∈ Y ⊂ N (x) to ﬁnd a local minimizer x∗
from which to start the next iteration of DTS, or local search can be performed immediately from an initial starting
point x to ﬁnd a local minimizer x∗ from which to select and evaluate the points y ∈ Y ⊂ N (x∗) as described in
Algorithm 2.1 of [134].

Numerical results presented in [134] showed that the described DTS method was tested on SNEs with up to
n = 51 decision variables, and that it was successful in converging on some but not all of the SNEs within 100 n2
function evaluations.

Simulated Annealing (SA): Originally proposed in [135] for solving hard combinatorial optimization problems,
Simulated Annealing (SA) is a well known metaheuristic that can be utilized to ﬁnd approximate solutions to global
optimization problems. SA only utilizes evaluations of the objective function during its search procedure, and
can therefore be utilized in cases where information about the derivatives of the objective function is inaccessible.
Although it is not always guaranteed that SA will converge to a true global minimum (some papers such as [136]
have proved the convergence of SA under certain speciﬁc conditions), SA can be used in cases where the objective
function is non-smooth or even discontinuous over the feasible region [137].

Starting with in initial step vector v0 ∈ Rn, an initial parameter T 0 (cid:62) 0 called the “temperature”, and an
initial feasible solution x0 ∈ D ⊂ Rn, SA attempts to generate a sequence of successive points xk ∈ D ⊂ Rn for
k = 1, 2, . . . , K which approach a global minimum x∗ of the objective function. At each iteration of SA, a new

13

i . If any new coordinate x(cid:48)

i centered around the previous coordinate value xk

candidate solution x(cid:48) is generated from the previous solution xk by taking random moves along each coordinate
direction in turn. Each new coordinate value x(cid:48)
i for i = 1, 2, . . . , n is sampled uniformly from an interval of width
2vk
i makes x(cid:48) fall outside of the feasible
region D, then a new coordinate value of x(cid:48)
i is randomly generated until a feasible point is found or a maximum
number of attempts is met. When a new feasible point x(cid:48) is found, if ϕ(x(cid:48)) (cid:54) ϕ(xk), we set xk+1 = x(cid:48) so that x(cid:48) is the
starting point for the next iteration of SA. Alternatively, if ϕ(x(cid:48)) > ϕ(xk), SA sets xk+1 = x(cid:48) with some probability
P (acceptance). For example, P (acceptance) can be deﬁned as P (acceptance) = exp(−(ϕ(x(cid:48)) − ϕ(xk))/T k) where
T k is the “temperature” parameter. Notice that if T k = 0, only improving points will be selected, but as T k
increases, the probability that non-improving moves will be accepted increases. SA accepts non-improving moves to
allow the algorithm to avoid being trapped in local minima. A new step vector vk+1 ∈ Rn and a new “temperature”
T k+1 (cid:62) 0 can be selected at each iteration as desired. Typically, the “temperature” T and the elements of the step
vector v are gradually decreased as the number of iterations increases so that the algorithm can take smaller and
smaller improving steps as it (hopefully) approaches a global minimum.

When tested against the Nelder-Mead simplex method on a variety of global optimization problems, SA was
found to take 500 to 1000 times more function evaluations than the Nelder-Mead simplex method, but it more
reliably found a global minimum of the objective functions it was tested on than the Nelder-Mead method [137].
Expanding upon the work presented in [137], article [5] introduces a metaheuristic which utilizes SA to solve the
objective function described in Eq. (13) which has a penalty designed to repel SA from already found solutions.
Article [5] refers to this penalized objective function as a “polarization technique”. Article [138] attempts to
ﬁnd multiple solutions to SNEs by repeatedly solving Eq.
(9) with a multistart fuzzy adaptive SA algorithm.
The proposed algorithm successfully found multiple solutions to SNEs of up to 20 equations and 20 unknowns
(m = n = 20) in less than four minutes when programmed in C++ and run on a computer with 2 CPU at 2.4 GHz
and 512 MB of RAM.

4.2.3 Population-based methods

Population-based methods explore the solution space with many agents simultaneously, typically in a coordinated
manner which balances exploration and exploitation. This section introduces population-based methods which have
been utilized in literature to search for solutions to SNEs via global optimization.

Evolutionary Algorithms: Evolutionary algorithms are a class of metaheuristic optimization algorithms, princi-
ples of which are inspired by mechanisms of biological evolution. Often, evolutionary algorithms associate candidate
solutions to biological individuals, which gradually evolve, and only the ﬁttest survive. For example, article [36]
proposes an evolutionary algorithm for solving SNEs which ﬁrst ranks all candidate solutions of the current popu-
lation by their ﬁtness values, and then performs mutation operations on the best candidate solutions to generate
“oﬀspring” which will serve as the new set of candidate solutions for the next iteration of the evolutionary algorithm.
Here, ﬁtness is quantiﬁed as a mathematical ﬁtness function. The set of candidate solutions forms a population,
that is being iteratively improved. An attractive property of some evolutionary algorithms is niching [139], which
can help ﬁnd multiple solution to a SNE by dividing the whole population into multiple diverse subpopulations [43].
We refer the interested reader to the book [140] which discusses utilizing evolutionary algorithms for multimodal
optimization.

A large number of research papers are devoted to the application of evolutionary algorithms for solving SNEs
transformed into multiobjective optimization problems (Eq. (21)). Some of the approaches used for solving mul-
tiobjective optimization problems involve “scalarization”, that is, conversion to a problem of the form similar to
Eq. (8). Evolutionary algorithms are popular as they may generate multiple solutions at the same time, which
may be used to model the Pareto-front of the optimization problem. While [18] proposed to use each equation as
an objective, thus forming a many-objective optimization problem, paper [40] proposed to utilize a multiobjective
evolutionary algorithm called MONES to search for solutions to a SNE reformulated as Eq. (24) where all optimal
solutions of the SNE would be Pareto optimal solutions of Eq. (24).

Genetic Algorithms (GAs): Genetic algorithms (GAs) are one of the most commonly utilized types of evolu-
tionary algorithms. Memetic algorithms (also known as genetic local search algorithms) are a class of GAs which
utilize a local search technique to attempt to improve the quality of the approximate solution(s) found. Article
[43] discusses utilizing memetic algorithms for searching for solutions to SNEs. Paper [89] applied the Random-Key
Genetic Algorithm (RKGA) for ﬁnding solutions of a box-constrained SNE, i.e. such that their solutions x∗ ∈ S,
where S = {x = (x1, x2, . . . , xn) ∈ Rn : li (cid:54) xi (cid:54) ui}. The RKGA was originally proposed for solving discrete
optimization problems [141]. At each iteration of the evolutionary process, RKGA computes the value of the ﬁtness

14

function of its chromosomes; after which, the most ﬁt chromosomes are placed into an “elite” group, and remaining
chromosomes are considered to be “non-elite”. Then, the next population is created by combining all the “elite”
chromosomes, a small group of new random chromosomes, and another small group of new chromosomes which
are generated by performing crossover between “elite” and “non-elite” chromosomes. There are many diﬀerent
variations of the RKGA, some of which which diﬀer from the original algorithm by allowing chromosomes to have
more than one oﬀspring, and others by modifying the crossover operation so that “parents” are taken from the
entire population. The RKGA also contains an encoder and a decoder which encode and decode the solution of
the optimization problem to the chromosome representation. In [89], the encoder represents a solution as a random
vector with each element χi lying in the interval [0,1], and the decoder “rescales” this random vector by calculating
xi = li +χi (ui −li). In addition to the original RKGA procedure, article [89] proposes to utilize a local improvement
procedure to attempt to ﬁnd a better solution in the neighborhood of the current solution. The gradient-free local
search method utilized in [89] is based on the method introduced in [142]. Article [89] evaluates the method on
small-scale problems from kinematics, chemical engineering, and other ﬁelds [51]. Article [34] utilizes a GA to solve
a SNE transformed into a constrained optimization problem. The constraints are handled by adding a penalty into
the objective function which penalizes solutions for which the constraints are not satisﬁed.

GAs have also been utilized within hybrid algorithms for solving SNEs. For example, article [32] attempted
to solve SNEs reformulated as a single objective optimization problem (Eq. (9)) by using the novel hybrid-GOA-
GA algorithm which combines the grasshopper optimization algorithm (GOA) with a GA. The hybrid-GOA-GA
algorithm was tested on eight benchmark SNEs of up to ten equations and unknowns, and on the largest SNEs the
hybrid-GOA-GA algorithm converged to a solution in less than 15 seconds on average.

Diﬀerential Evolution (DE): Similarly to GAs, algorithms based on diﬀerential evolution (DE) work by gen-
erating a population of candidate solutions which get iteratively improved by combining candidate solutions from
the previous population. New candidate solutions are generated by subsequently applying mutation and crossover
operations to solutions from the previous generation; then, the solutions are compared with their parents and are
selected and added to the next population if their ﬁtness function value is better.

Article [143] proposes to hybridize the Grey Wolf Optimization (GWO) algorithm with a DE algorithm; the
algorithm is utilized to search for solutions to a SNE reformulated as an unconstrained optimization problem. The
algorithm was evaluated on small-scale SNEs and was able to ﬁnd multiple solutions to SNEs without using an
objective function penalty (Eq. 10) since the population of candidate solutions can potentially contain multiple
solutions to a SNE found simultaneously in a single run. Article [48] proposes to explore new candidate solutions
using a fuzzy neighborhood technique (based on Euclidean distance). Paper [46] also reformulates a SNE as a
global optimization problem, and proposes a repulsion-based adaptive DE algorithm which utilizes additive and
multiplicative repulsion techniques (cf equations 9 and 14) along with adaptive control of DE parameters. Article
[49] utilizes niching techniques with DE in order to search for multiple solutions to a SNE simultaneously in a single
run. It has also been proposed to apply k-means clustering to the set of candidate solutions, and to treat each
cluster as a separate population to preserve the diversity of the solutions [45]. Article [47] reformulates a SNE as
a multiobjective optimization problem and attempts to solve it using a two-phase EA. The ﬁrst phase attempts to
maintain the population diversity by combining a multiobjective optimization technique with a niching technique,
and the second phase attempts to detect promising subregions within the solution space and explore them by using
DE to perform local search. Niching is also used with DE in [52]. Article [97] applies DE with modiﬁed crossover
to a SNE transformed into a tri-objective multiobjective optimization problem.

Particle Swarm Optimization (PSO): Particle Swarm Optimization (PSO) algorithms generate a set of can-
didate solutions (“particles”) that are moving in the search space in accordance to some movement law. Typically,
each particle has a velocity that controls its movement [144]. Particles’ movement directions are iteratively updated
based on the best solution of the individual particle, and the current best solution of all particles. Article [120]
reformulates a SNE as an optimization problem of the form Eq. (8) and searches for solutions to it using a hybrid
PSO algorithm. The hybrid PSO algorithm utilized in article [120] is a combination of PSO with the Nelder-Mead
local search method. Here, some of the particles update their positions according to movement equations, and
others update their positions using the Nelder-Mead method. The paper evaluates the method on small SNEs with
less than seven equations, and looks for only one solution. Paper [86] proposes a hybrid algorithm combining PSO
and Cuckoo search for solving SNEs. The reformulation utilized in article [86] is the square root of the objective
function shown in Eq. (8) with α = 1 and p = 2. Article [145] utilizes PSO to minimize an objective function
of the form shown in Eq. (8) where α = 1 and p = 1. The algorithm utilized in [145] is a modiﬁed PSO algo-
rithm with a new expression for ﬁnding the inertia weight. The algorithm is used to ﬁnd only one solution, and
is tested on small SNEs. Paper [146] proposes utilizing Quantum behaved Particle Swarm Optimization (QPSO)

15

to solve a SNE reformulated as Eq. (9). The main diﬀerence between the QPSO algorithm proposed in [147] and
the traditional PSO algorithm is that the QPSO algorithm utilizes principles from quantum mechanics while the
traditional PSO algorithm utilizes principles from Newtonian mechanics. Additionally, the method presented in
article [147] changes the pseudo-random number generator to a chaotic map. The resulting algorithm is evaluated
on small-size problems, and their experiments show that the proposed method tends to converge to solutions faster
than the ordinary PSO algorithm. Article [148] aims at solving a SNE by minimizing an objective function of the
form shown in 8 with α = 1 and p = 2. The proposed method combines the standard PSO algorithm with Powell’s
conjugate direction (CD) method which can be used to ﬁnd a local minimum of a function. The resulting method is
used to ﬁnd one solution and is tested on SNEs of 5-10 dimensions. PSO was also utilized to search for solutions to
SNEs in [149, 150]. MATLAB code for PSO and a modiﬁcation of PSO named “Uniﬁed PSO” that aggregates its
local and global variants [151] can be found in [152, 144]. PSO has also been hybridized with insights from memetic
algorithms as discussed in article [153].

Spiral Optimization (SPO): Initally introduced in articles [154, 155], spiral optimization (SPO) methods are
multistart methods for global optimization which are inspired by spiral phenomena in nature. Article [155] ini-
tially proposed a SPO method for solving 2-dimensional continuous optimization problems, and article [154] ex-
panded upon this work to introduce a SPO algorithm for n−dimensional continuous optimization problems. The
n−dimensional SPO algorithm is constructed based on rotation matrices deﬁned in the n−dimensional space. The
iterative SPO algorithm explores the solution space with a population of solutions simultaneously, each of which
explores the solution space by moving in a tightening spiral centered around the best solution found so far. Upon
initialization, the spiral dynamics optimization algorithm randomly selects a set of starting points within the do-
main of interest D, and evaluates the objective function value at each point. The point with the best objective
function value is set as the initial center point which all other members of the population will spiral around. The
motivation behind the spiral model is that initially when the spiral is large, the model will explore a diverse set of
points across the solution space. As the number of iterations increases the spiral tightens, and the search intensiﬁes
around the center of the spiral to facilitate exploitation. One interesting aspect of the SPO algorithm is that it
explores the solution space with a population of candidate solutions which move in a non-stochastic manner.

Article [87] presents a method which utilizes SPO and clustering to search for multiple solutions to a SNE.
Instead of selecting the set of starting points for SPO in a purely random fashion, article [87] utilizes the low-
discrepancy Sobol sequence to attempt to select a set of starting points which are more likely to be uniformly
spread across D. By selecting starting points which are more uniformly spread across D, one can facilitate the
exploration of the model by powerfully leveraging the advantages presented by SPO’s multistart framework. We
refer the interested reader to Chapter 2 of the book [156] for information on low-discrepancy sequences and on how
to generate random numbers with speciﬁed distributions.

To attempt to ﬁnd multiple roots to a SNE in a single run, article [87] proposes a method which utilizes a
clustering technique to identify diﬀerent regions which are likely to contain a solution to a SNE, and simultaneously
utilizes SPO to search for solutions within each cluster. The proposed method was tested on six SNEs of up to
eight equations and eight unknowns, and the method demonstrated the ability to eﬀectively ﬁnd multiple solutions
to each SNE in a single run in a matter of seconds.

Other metaphor-based metaheuristics: Cuckoo search models solutions of an optimization problem as eggs in
a nest. Initially, there are multiple nests. The algorithm performs multiple iterations; at each iteration a randomly
chosen “egg” (a solution) in a random “nest” is replaced by another solution (modeling a situation where a cuckoo
lays her egg in another host bird’s nest); then the ﬁtness function of the “nests” of solutions is evaluated, and the
best nests are moved to the next generation, while a randomly chosen fraction of nests of worse quality is dropped
(modeling the situation when a host bird discovers the cuckoo’s egg and leaves the nest). Randomization is often
performed using Levy ﬂights random walk. Cuckoo search was applied to SNEs in [157, 86, 158].

Monarch butterﬂy optimization (MBO) algorithms, proposed in [159], are inspired by the behavior of North
American Monarch Butterﬂies, and their autumn migration from Northern USA and Southern Canada to Mexico.
In MBO, a population of Monarch butterﬂies is split into two sub-populations (modeling populations of butterﬂies
in “Land 1” and “Land 2”). MBO then performs two operations, one of which is a migration operator which
creates new butterﬂies which potentially replace butterﬂies from the previous population, and the other of which
is a butterﬂy adjusting operator which changes the positions of the butterﬂies. These operations are iteratively
applied to the two sub-populations until a stopping criteria is met. MBO is used to search for solutions to SNEs in
[160].

Many other metaphor-based metaheuristics have been used to solve SNEs, including invasive weed optimization
[33, 90], glowworm swarm optimization [161], hybrid artiﬁcial bee colony algorithm [162], imperialist competitive

16

algorithms [163], modiﬁed ﬁreﬂy algorithm [164], harmony search [165, 91], and a soccer league competition algorithm
[166] among others.

1, xp

2, . . . , xp

Chaotic global optimization methods: Chaotic global optimization methods typically generate one or more
chaotic sequences, and then map these chaotic sequences to a corresponding sequence of P feasible solutions xp =
(xp
n) ∈ D ⊂ Rn for p = 1, 2, . . . , P to the global optimization problem of concern. The set of generated
feasible solutions xp are then used in some way, for example, they could be utilized as starting points for local
search within a multi-start framework as shown in [167]. The reason why chaotic sequences are utilized as the basis
for the set of starting points xp is because chaotic sequences have three key traits, namely, (a) pseudo-randomness,
(b) ergodicity, and (c) irregularity [168].

× IS22

× · · · × IS1n

Article [31] presented a two-stage metaheuristic to ﬁnd solutions to a SNE by solving Eq. (9) where ϕ0(x) is
of the form shown in Eq. (8). The authors of [31] claim that the ﬁrst stage of the metaheuristic attempts to ﬁnd
within the feasible region over which ϕ0(x) is unimodal. Starting
a hyper-rectangle S2 = IS21
× · · · × IS2n
such that S2 ⊆ S1 (meaning that ϕ0(x) is not
with a larger feasible hyper-rectangle S1 = IS11
× IS12
necessarily unimodal over S1), the authors utilize the elements of a chaotic sequence in a process which iteratively
shrinks S1 for a set number of iterations to obtain S2. It is important to note that though they hope to obtain
a hyper-rectangle S2 over which ϕ0(x) is unimodal, there is no guarantee that this will occur. After ﬁnding S2,
the second stage of the metaheuristic presented in [31] utilizes an n-dimensional expansion of golden section search
[169] to perform local search over S2. Since n-dimensional golden section search is designed to be utilized on a
hyper-rectangle over which the objective function is unimodal, stage one attempts to ﬁnd this region. The authors
of [31] tested their algorithm on a variety of SNEs of up to 10 variables and 10 unknowns, and were able to solve
each problem in less than a second. However, they did not compare their algorithm to any other techniques capable
of ﬁnding multiple solutions to a SNE, and there is little evidence to suggest that stage 1 of their algorithm is
capable of consistently ﬁnding a hyper-rectangle S2 such that ϕ0(x) is unimodal (as is required to guarantee that
n-dimensional golden section search will converge to a global minimum of ϕ0(x) over S2).

4.3 Neural network-based optimization

Various neural network-based optimization techniques have been utilized to search for solutions to SNEs. These
approaches construct and train an artiﬁcial neural network (ANN) for each SNE; then, roots of the SNE may be
found at the neurons’ weights. An example of this technique is discussed in [170], where it is referred to as a
Gradient Neural Network and used to search for the solution to system of linear equations. Similar approaches are
presented in [171] and [172]. In these approaches, solutions to the equations also correspond to the state vector
of the ANN. These neural network based approaches are diﬀerent from traditional modern application of ANNs,
which are expected to be able to ﬁnd solutions to unseen SNEs, after being trained on many SNEs such as [173]. In
[174], Margaris et al. presented a back-propagation trained four-layered feed-forward ANN framework for solving
algebraic systems of n polynomial equations with n unknown variables. The four-layered network presented in [174]
consists of:

(a) a single neuron input layer whose output synaptic weights are trained to become the components of one of

the SNE’s solutions,

(b) a ﬁrst hidden layer of n summation neurons which generate each of the linear terms {x1, x2, . . . , xn} and

which have an identity activation function,

(c) a second hidden layer of product units with custom activation functions which generate all of the nonlinear
higher order terms of the algebraic system by multiplying the linear quantities received from the ﬁrst hidden
layer (for example, if a SNE had the nonlinear term x2
1, a corresponding neuron will have an activation function
that squares the input x1),

(d) an output layer of n summation neurons that generate the right hand side of each nonlinear equation fi(x) = 0
of the SNE (serving as the estimate of the training error when compared to each equation’s true right hand
side value of 0),

where the only synaptic weights adjusted during training are those between the single neuron in the input layer
and the neurons of the ﬁrst hidden layer which represent each unknown variable of the system. Expanding upon
this work, Awaad et al. utilized a new Manhattan-Adam hybrid updating rule to accelerate model convergence
and overcome the vanishing gradient problem [175]. The main goal of the paper is to be able to use hardware
accelerators that provide eﬃcient implementation of this update rule. The new updating rule dynamically adjusts

17

the step size during training, and rotates after a set number of iterations between using the Manhattan updating
rule and the Adam updating rule to eﬃciently handle problems with sparse and vanishing gradients.

Also expanding upon the work of Margaris et al. [174], Goulianas et al. introduced the General Back-propagation
with Adapative Learning Rate (GBALR) algorithm which allows the activation functions of the second hidden layer
to be any function, including non-algebraic functions [176].

A related technique is called a Zeroing Neural Network (ZNN) [177]. ZNNs aim at zeroing error functions, the
design of which depends on the problem. In the case of SNEs, similar to the research described above, the goal
of ZNNs is to ﬁnd a solution to a nonlinear system by applying gradient-based optimization methods. However,
in contrast to previous papers which solve static systems, a ZNN introduces temporal dependency into its error
function; that is, coeﬃcients of SNEs may be dependent on an additional time parameter t. Also addressing
temporal SNEs with ANNs, Zhang utilized a Recurrent Neural Network (RNN) to ﬁnd approximate online solutions
to a time-variant SNE emerging in robot kinematics [11].

5 Synopsis and concluding remarks

In this article, we have presented part two of a survey on methods for solving a system of nonlinear equations
(SNE). In part two we have presented a comprehensive survey of techniques which can be utilized to search for
solutions to a SNE via optimization. Since many of the SNEs that arise in real world applications are considered
over a ﬁnite bounded domain D, we ﬁrst introduced a technique which can be utilized to determine the number of
solutions to a SNE that exist within D. Then, we introduced various techniques which can be used to transform
a SNE into an optimization problem, and we described a vast array of optimization algorithms which can then be
used to search for solutions to a SNE after transformation. We discussed both local search algorithms and global
search algorithms for optimization, and we place an emphasis on cutting edge metaheuristics for global optimization
which have been shown to be particularly eﬀective at ﬁnding one or many solutions to SNEs.

Analyzing this literature has led us to conclude that for the hardest classes of SNEs, many of the most promising
techniques that we currently have are metaheuristics such as those discussed in Section 4.2 of this paper. Although
such techniques are not necessarily guaranteed to converge to a solution in ﬁnite time, many can be applied to
ill-formed and challenging classes of SNEs as they only require evaluations of the objective function (and hence can
be applied when the objective function is not everywhere diﬀerentiable). However, more research needs to be done
towards improving these techniques. To address this need, we are currently exploring how machine learning can be
utilized to enhance the eﬀectiveness of metaheuristics for solving SNEs through global optimization. Additionally,
as described in part one of this survey, we are also actively developing a new taxonomy of SNEs to facilitate the
identiﬁcation of new classes of tractable problems as well as the methods most capable of solving them. Furthermore,
we are actively exploring methods capable of solving systems of nonlinear equations and inequalities.

In part one of this survey, we discussed methods for solving SNEs without transforming them into optimization
problems. In part two of this survey, we discussed methods for solving SNEs by transforming them into optimization
problems. In part three of this survey, we will present a robust quantitative comparative analysis of methods capable
of searching for solutions to SNEs.

References

[1] Christodoulos A. Floudas. Global optimization in design and control of chemical process systems. Journal of

Process Control, 10(2):125–134, 2000.

[2] Wagner F. Sacco and N´elio Henderson. Finding all solutions of nonlinear systems using a hybrid metaheuristic

with fuzzy clustering means. Applied Soft Computing, 11(8):5424–5432, 2011.

[3] Astrid Holstad. Numerical solution of nonlinear equations in chemical speciation calculations. Computational

Geosciences, 3(3):229–257, Dec 1999.

[4] Hugo Jim´enez-Islas, Gloria M. Mart´ınez-Gonz´alez, Jos´e L. Navarrete-Bola˜nos, Jos´e E. Botello- ´Alvarez, and
J. Manuel Oliveros-Mu˜noz. Nonlinear homotopic continuation methods: A chemical engineering perspective
review. Industrial & Engineering Chemistry Research, 52(42):14729–14742, Oct 2013.

[5] N´elio Henderson, Wagner F. Sacco, and Gustavo Mendes Platt. Finding more than one root of nonlinear equa-
tions via a polarization technique: An application to double retrograde vaporization. Chemical Engineering
Research and Design, 88(5):551–561, 2010.

18

[6] Hsiao-Dong Chiang, Tian-Qi Zhao, Jiao-Jiao Deng, and Kaoru Koyanagi. Homotopy-enhanced power ﬂow
methods for general distribution networks with distributed generators. IEEE Transactions on Power Systems,
29(1):93–100, 2014.

[7] Dhagash Mehta, Hung Dinh Nguyen, and Konstantin Turitsyn. Numerical polynomial homotopy continuation
method to locate all the power ﬂow solutions. IET Generation, Transmission & Distribution, 10(12):2972–
2980, 2016.

[8] Hsiao-Dong Chiang and Tao Wang. Novel homotopy theory for nonlinear networks and systems and its
applications to electrical grids. IEEE Transactions on Control of Network Systems, 5(3):1051–1060, 2018.

[9] Chao Yang, Jianwen Cao, and Xiao-Chuan Cai. A fully implicit domain decomposition algorithm for shallow

water equations on the cubed-sphere. SIAM Journal on Scientiﬁc Computing, 32(1):418–438, 2010.

[10] Matti Schneider, Daniel Wicht, and Thomas B¨ohlke. On polarization-based schemes for the ﬀt-based compu-
tational homogenization of inelastic materials. Computational Mechanics, 64(4):1073–1095, Oct 2019.

[11] Yunong Zhang. A set of nonlinear equations and inequalities arising in robotics and its online solution via a

primal neural network. Neurocomputing, 70(1):513–524, 2006.

[12] Amir Salimi Lafmejani, Ahmad Kalhor, and Mehdi Masouleh. A new development of homotopy continuation
method, applied in solving nonlinear kinematic system of equations of parallel mechanisms. 2015 3rd RSI
International Conference on Robotics and Mechatronics (ICROM), 10 2015.

[13] David A Cox, John Little, and Donal O’Shea. Robotics and automatic geometric theorem proving. In Ideals,

Varieties, and Algorithms, pages 291–343. Springer, 2015.

[14] Ping Ji and Hongtao Wu. Kinematics analysis of an oﬀset 3-upu translational parallel robotic manipulator.

Robotics Auton. Syst., 42:117–123, 2003.

[15] Strachimir Cht. Mavrodiev and Maksym Deliyergiyev. Modiﬁcation of the nuclear landscape in the inverse
problem framework using the generalized bethe-weizs¨acker mass formula. arXiv e-prints, pages arXiv–1602,
2016.

[16] Sani Aji, Poom Kumam, Punnarai Siricharoen, Auwal Bala Abubakar, and Mahmoud Muhammad Yahaya.
A modiﬁed conjugate descent projection method for monotone nonlinear equations and image restoration.
IEEE Access, 8:158656–158665, 2020.

[17] Jan Verschelde, Pierre Verlinden, and Ronald Cools. Homotopies exploiting Newton polytopes for solving

sparse polynomial systems. SIAM Journal on Numerical Analysis, 31(3):915–930, 1994.

[18] Crina Grosan and Ajith Abraham. A new approach for solving nonlinear equations systems. IEEE Transac-

tions on Systems, Man, and Cybernetics - Part A: Systems and Humans, 38(3):698–714, 2008.

[19] Ahmad Golbabai, Davood Ahmadian, and Mariyan Milev. Radial basis functions with application to ﬁnance:

American put option under jump diﬀusion. Mathematical and Computer Modelling, 55(3):1354–1362, 2012.

[20] Guang Zhang and Liang Bai. Existence of solutions for a nonlinear algebraic system. Discrete dynamics in

nature and society, 2009, 2009.

[21] Karol Kowalski and Karol Jankowski. Towards complete solutions to systems of nonlinear equations of many-

electron theories. Phys. Rev. Lett., 81:1195–1198, Aug 1998.

[22] Dhagash Mehta. Numerical polynomial homotopy continuation method and string vacua. Advances in High

Energy Physics, 2011:263937, Oct 2011.

[23] Yang Song, Chenlin Meng, Renjie Liao, and Stefano Ermon. Nonlinear equation solving: A faster alternative

to feedforward computation. arXiv preprint arXiv:2002.03629, 2020.

[24] Yunfeng Cai and Ping Li. Solving the robust matrix completion problem via a system of nonlinear equations.
In Silvia Chiappa and Roberto Calandra, editors, Proceedings of the Twenty Third International Conference
on Artiﬁcial Intelligence and Statistics, volume 108 of Proceedings of Machine Learning Research, pages 4162–
4172. PMLR, 26–28 Aug 2020.

19

[25] B´ela Pal´ancz, Piroska Zaletnyik, Joseph L Awange, and Erik W Grafarend. Dixon resultant’s solution of

systems of geodetic polynomial equations. Journal of Geodesy, 82(8):505–511, 2008.

[26] B´ela Pal´ancz, Joseph L. Awange, Piroska Zaletnyik, and Robert H. Lewis. Linear homotopy solution of

nonlinear systems of equations in geodesy. Journal of Geodesy, 84(1):79, Sep 2009.

[27] Christian Jansson. An np-hardness result for nonlinear systems. Reliable Computing, 4(4):345–350, Nov 1998.

[28] Yuri V. Matiyasevich. Hilbert’s Tenth Problem. MIT Press, Cambridge, MA, USA, 1993.

[29] Mustafa Q Khirallah and MA Haﬁz. Solving system of nonlinear equations using family of Jarratt methods.

International Journal of Diﬀerential Equations and Applications, 12(2), 2013.

[30] MQ Khirallah and MA Haﬁz. Novel three order methods for solving a system of nonlinear equations. Bulletin

of Mathematical Sciences & Applications, 1(2):01–14, 2012.

[31] J Alikhani Koupaei and Seyed Mohammad Mehdi Hosseini. A new hybrid algorithm based on chaotic maps

for solving systems of nonlinear equations. Chaos, Solitons & Fractals, 81:233–245, 2015.

[32] M. A. El-Shorbagy and Adel M. El-Refaey. Hybridization of grasshopper optimization algorithm with genetic

algorithm for solving system of non-linear equations. IEEE Access, 8:220944–220961, 2020.

[33] Y Ramu Naidu and Akshay Kumar Ojha. Solving multiobjective optimization problems using hybrid co-
operative invasive weed optimization with multiple populations. IEEE Transactions on Systems, Man, and
Cybernetics: Systems, 48(6):821–832, 2016.

[34] Angel Kuri. Solution of simultaneous non-linear equations using genetic algorithms. WSEAS Transactions

on Systems, 2, 01 2003.

[35] Lin Xiao, Zhijun Zhang, and Shuai Li. Solving time-varying system of nonlinear equations by ﬁnite-time
recurrent neural networks with application to motion tracking of robot manipulators. IEEE Transactions on
Systems, Man, and Cybernetics: Systems, 49(11):2210–2220, 2018.

[36] Huan-Tong Geng, Yi-Jie Sun, Qing-Xi Song, and Ting-Ting Wu. Research of ranking method in evolution
strategy for solving nonlinear system of equations. In 2009 First International Conference on Information
Science and Engineering, pages 348–351, 2009.

[37] Jun Pei, Zorica Draˇzi´c, Milan Draˇzi´c, Nenad Mladenovi´c, and Panos M Pardalos. Continuous variable
neighborhood search (c-vns) for solving systems of nonlinear equations. INFORMS Journal on Computing,
31(2):235–250, 2019.

[38] Abd allah Mousa and Islam Eldesoky. Genls: Co-evolutionary algorithm for nonlinear system of equations.

Applied Mathematics and Computation, 197:633–642, 04 2008.

[39] Wenyin Gong, Yong Wang, Zhihua Cai, and Shengxiang Yang. A weighted biobjective transformation tech-
nique for locating multiple optimal solutions of nonlinear equation systems. IEEE Transactions on Evolu-
tionary Computation, 21(5):697–713, 2017.

[40] Wu Song, Yong Wang, Han-Xiong Li, and Zixing Cai. Locating multiple optimal solutions of nonlinear
equation systems based on multiobjective optimization. IEEE Transactions on Evolutionary Computation,
19(3):414–431, 2015.

[41] Sha Qin, Sanyou Zeng, Wei Dong, and Xi Li. Nonlinear equation systems solved by many-objective hype. In

2015 IEEE Congress on Evolutionary Computation (CEC), pages 2691–2696, 2015.

[42] Jinjin Guo, Binbin Qiu, and Yunong Zhang. New-type dtz model for solving discrete time-dependent nonlinear
equation system with robotic-arm application. In 2020 10th International Conference on Information Science
and Technology (ICIST), pages 153–162, 2020.

[43] Zuowen Liao, Wenyin Gong, and Ling Wang. Memetic niching-based evolutionary algorithms for solving

nonlinear equation system. Expert Systems with Applications, 149:113261, 2020.

20

[44] Zuowen Liao, Wenyin Gong, Xuesong Yan, Ling Wang, and Chengyu Hu. Solving nonlinear equations system
with dynamic repulsion-based evolutionary algorithms. IEEE Transactions on Systems, Man, and Cybernetics:
Systems, 50(4):1590–1601, 2020.

[45] Weifeng Gao, Yuting Luo, Jingwei Xu, and Shengqi Zhu. Evolutionary algorithm with multiobjective opti-

mization technique for solving nonlinear equation systems. Information Sciences, 541, 07 2020.

[46] Wenyin Gong, Yong Wang, Zhihua Cai, and Ling Wang. Finding multiple roots of nonlinear equation systems
via a repulsion-based adaptive diﬀerential evolution. IEEE Transactions on Systems, Man, and Cybernetics:
Systems, 50(4):1499–1513, 2020.

[47] Weifeng Gao, Genghui Li, Qingfu Zhang, Yuting Luo, and Zhenkun Wang. Solving nonlinear equation systems
by a two-phase evolutionary algorithm. IEEE Transactions on Systems, Man, and Cybernetics: Systems,
51(9):5652–5663, 2021.

[48] Wei He, Wenyin Gong, Ling Wang, Xuesong Yan, and Chengyu Hu. Fuzzy neighborhood-based diﬀerential
evolution with orientation for nonlinear equation systems. Knowledge-Based Systems, 182:104796, 2019.

[49] Jianye Wu, Wenyin Gong, and Ling Wang. A clustering-based diﬀerential evolution with diﬀerent crowding

factors for nonlinear equations system. Applied Soft Computing, 98:106733, 2021.

[50] Weifeng Gao and Yu Li. Solving a new test set of nonlinear equation systems by evolutionary algorithm.

IEEE Transactions on Cybernetics, pages 1–10, 2021.

[51] Aijuan Song, Guohua Wu, and Witold Pedrycz. Integrating variable reduction strategy with evolutionary

algorithm for solving nonlinear equations systems. CoRR, abs/2008.04223, 2020.

[52] Zuowen Liao, Wenyin Gong, Ling Wang, Xuesong Yan, and Chengyu Hu. A decomposition-based diﬀerential
evolution with reinitialization for nonlinear equations systems. Knowledge-Based Systems, 191:105312, 2020.

[53] Shi Cheng, Junfeng Chen, Xiujuan Lei, and Yuhui Shi. Locating multiple optima via brain storm optimization

algorithms. IEEE Access, 6:17039–17049, 2018.

[54] Wenyin Gong, Zuowen Liao, Xianyan Mi, Ling Wang, and Yuanyuan Guo. Nonlinear equations solving with

intelligent optimization algorithms: A survey. Complex System Modeling and Simulation, 1(1):15–32, 2021.

[55] Masoud Ahookhosh, Keyvan Amini, and Somayeh Bahrami. Two derivative-free projection approaches for

systems of large-scale nonlinear monotone equations. Numerical Algorithms, 64, 10 2013.

[56] Stepan Yu. Gatilov. Properties of nonlinear systems and convergence of the Newton-Raphson method in

geometric constraint solving. volume 32, pages 57—-75. NCC, 2011.

[57] Susumu Tanab´e and Michael N. Vrahatis. On perturbation of roots of homogeneous algebraic systems.

Mathematics of Computation, 255:1383–1402, 2006.

[58] Najib Ullah, Jamilu Sabi’u, and Abdullah Shah.

A derivative-free scaling memoryless broyden–
ﬂetcher–goldfarb–shanno method for solving a system of monotone nonlinear equations. Numerical Linear
Algebra with Applications, 28(5):e2374, 2021.

[59] Jos´e Mario Mart´ınez. Algorithms for Solving Nonlinear Systems of Equations, pages 81–108. Springer Nether-

lands, Dordrecht, 1994.

[60] James M. Ortega and Werner C. Rheinboldt. Iterative Solution of Nonlinear Equations in Several Variables.

Society for Industrial and Applied Mathematics, January 2000.

[61] ´Emile Picard.

Sur le nombre des racines communes `a plusieurs ´equations simultan´ees.

Journal de

Math´ematiques Pures et Appliqu´ees, 8(4e s´erie):5–24, 1892.

[62] ´Emile Picard. Trait´e d’Analyse. Gauthier-Villars, Paris, 1922.

[63] Jane Cronin. Fixed Points and Topological Degree in Nonlinear Analysis. American Mathematical Society,

Providence, Rhode Island, 1964.

[64] Noel G. Lloyd. Degree Theory. Oxford University Press, New York, 1978.

21

[65] Donal O’Regan, Yeol Je Cho, and Yu-Qing Chen. Topological Degree Theory and Applications. Taylor &

Francis Group, Boca Raton, FL, 2006.

[66] Enrique Outerelo and Jes´us M. Ruiz. Mapping Degree Theory. American Mathematical Society, Providence,

Rhode Island, 2009.

[67] Krzysztof A. Sikorski. Optimal Solution of Nonlinear Equations. Oxford University Press, New York, 2001.

[68] Jeroen M. Bergamin, Tassos C. Bountis, and Michael N. Vrahatis. Homoclinic orbits of invertible maps.

Nonlinearity, 15(5):1603–1619, 2002.

[69] Ioannis Z. Emiris, Bernard Mourrain, and Michael N. Vrahatis. Sign methods for counting and computing
real roots of algebraic systems. Technical report, Rapport de Recherche No.3669, INRIA (Institut National
de Recherche en Informatique et en Automatique), Sophia Antipolis, France, April 1999.

[70] Dimitris J. Kavvadias and Michael N. Vrahatis. Locating and computing all the simple roots and extrema of

a function. SIAM Journal on Scientiﬁc Computing, 17(5):1232–1248, 19965.

[71] R. Baker Kearfott. An eﬃcient degree-computation method for a generalized method of bisection. Numerische

Mathematik, 32:109–127, 1979.

[72] Bernard Mourrain, Nicos G. Pavlidis, Dimitris K. Tasoulis, and Michael N. Vrahatis. Determining the number
of real roots of polynomials through neural networks. Computers and Mathematics with Applications, 51(3-
4):527–536, 2006.

[73] Bernard Mourrain, Michael N. Vrahatis, and Yakoubsohn Jean-Claude. On the complexity of isolating real
roots and computing with certainty the topological degree. Journal of Complexity, 18(2):612–640, 2002.

[74] Vassilis P. Plagianakos, Nicos K. Nousis, and Michael N. Vrahatis. Locating and computing in parallel all
the simple roots of special functions using pvm. Journal of Computational and Applied Mathematics, 133(1-
2):545–554, 2001.

[75] Chronis Polymilis, Graziano Servizi, Charalampos Skokos, Giorgio Turchetti, and Michael N. Vrahatis. Topo-

logical degree theory and local analysis of area preserving maps. Chaos, 13(1):94–104, 2003.

[76] Frank Stenger. Computing the topological degree of a mapping in Rn. Numerische Mathematik, 25:23–38,

1975.

[77] Martin Stynes. An algorithm for numerical calculation of topological degree. Applicable Analysis, 25:23–38,

1979.

[78] Michael N. Vrahatis. An eﬃcient method for locating and computing periodic orbits of nonlinear mappings.

Journal of Computational Physics, 119:105–119, 1995.

[79] Michael N. Vrahatis. Solving systems of nonlinear equations using the nonzero value of the topological degree.

ACM Transactions on Mathematical Software, 14(4):312–329, Dec. 1988.

[80] Michael N. Vrahatis. A short proof and a generalization of Miranda’s existence theorem. Proceedings of the

American Mathematical Society, 107(3):701–703, 1989.

[81] Michael N. Vrahatis and Kosmas I. Iordanidis. A rapid generalized method of bisection for solving systems

of nonlinear equations. Numerische Mathematik, 49(2-3):123–138, 1986.

[82] Michael N. Vrahatis, Graziano Servizi, Giorgio Turchetti, and Tassos C. Bountis. A procedure to compute
the ﬁxed points and visualize the orbits of a 2D map. Technical report, CERN SL/93-06 (AP), CERN-SL
Division, European Organization for Nuclear Research (CERN), Geneva, Switzerland, February 1993.

[83] Peter Franek and Marek Krˇc´al. Robust satisﬁability of systems of equations. J. ACM, 62(4), sep 2015.

[84] Erik Boman, Walter Murray, Gene Golub, and Michael Saunders.

Infeasibility and negative curvature in

optimization. 03 1999.

[85] John W. Chinneck. Feasibility and Infeasibility in Optimization. Springer US, 2008.

22

[86] Abdelmonem M Ibrahim and Mohamed A Tawhid. A hybridization of cuckoo search and particle swarm

optimization for solving nonlinear systems. Evolutionary Intelligence, 12(4):541–561, 2019.

[87] Kuntjoro Sidarto and Adhe Kania. Finding all solutions of systems of nonlinear equations using spiral dy-
namics inspired optimization with clustering. Journal of Advanced Computational Intelligence and Intelligent
Informatics, 19:697–707, 09 2015.

[88] Michael J Hirsch, Panos M Pardalos, and Mauricio GC Resende. Solving systems of nonlinear equations with

continuous grasp. Nonlinear Analysis: Real World Applications, 10(4):2000–2006, 2009.

[89] Ricardo M. A. Silva, Mauricio G. C. Resende, and Panos M. Pardalos. Finding multiple roots of a box-
constrained system of nonlinear equations with a biased random-key genetic algorithm. Journal of Global
Optimization, 60(2):289–306, Oct 2014.

[90] Ebrahim Pourjafari and Hamed Mojallali. Solving nonlinear equations systems with a new approach based on
invasive weed optimization algorithm and clustering. Swarm and Evolutionary Computation, 4:33–43, 2012.

[91] Gisela C. V. Ramadas, Edite M. G. P. Fernandes, and Ana Maria A. C. Rocha. Multiple roots of systems of
equations by repulsion merit functions. In Computational Science and Its Applications – ICCSA 2014, pages
126–139. Springer International Publishing, 2014.

[92] Gisela C. V. Ramadas, Ana Maria A. C. Rocha, and Edite M. G. P. Fernandes. Testing nelder-mead based
repulsion algorithms for multiple roots of nonlinear systems via a two-level factorial design of experiments.
PLOS ONE, 10(4):1–30, 04 2015.

[93] N´elio Henderson, L´ea Freitas, and Gustavo Platt. Prediction of critical points: A new methodology using

global optimization. AIChE Journal, 50:1300 – 1314, 06 2004.

[94] L´ea Freitas, Gustavo Platt, and N´elio Henderson. Novel approach for the calculation of critical points in

binary mixtures using global optimization. Fluid Phase Equilibria, 225:29–37, 2004.

[95] Abolfazl Pourrajabian Shahrbabak, Ebrahimi Reza, Masoud Mirzaei, and Mehrzad Shams. Applying genetic
algorithms for solving nonlinear algebraic equations. Applied Mathematics and Computation, 219:11483–11494,
08 2013.

[96] Y. Ramu Naidu and Akshay Kumar Ojha. Solving multiobjective optimization problems using hybrid co-
operative invasive weed optimization with multiple populations. IEEE Transactions on Systems, Man, and
Cybernetics: Systems, 48(6):821–832, 2018.

[97] Jing-Yu Ji and Man Leung Wong. An improved dynamic multi-objective optimization approach for nonlinear

equation systems. Information Sciences, 576:204–227, 2021.

[98] J¨org Stork, A. E. Eiben, and Thomas Bartz-Beielstein. A new taxonomy of global optimization algorithms.

Natural Computing, Nov 2020.

[99] Rafael Mart´ı, Panos M. Pardalos, and Mauricio G. C. Resende, editors. Handbook of Heuristics. Springer

International Publishing, 2018.

[100] Dimitris Souravlias, Ilias S Kotsireas, Panos M Pardalos, and Konstantinos E Parsopoulos. Parallel algorithm
portfolios with performance forecasting. Optimization Methods and Software, 34(6):1231–1250, 2019.

[101] Dimitris Souravlias, Konstantinos E Parsopoulos, Ilias S Kotsireas, and Panos M Pardalos. Algorithm Port-

folios: Advances, Applications, and Challenges. Springer, 2021.

[102] Jonathan Barzilai and Jonathan M. Borwein. Two-Point Step Size Gradient Methods.

IMA Journal of

Numerical Analysis, 8(1):141–148, 01 1988.

[103] Roger Fletcher. On the barzilai-borwein method. In Optimization and control with applications, pages 235–

256. Springer, 2005.

[104] Sebastian Ruder. An overview of gradient descent optimization algorithms. CoRR, abs/1609.04747, 2016.

23

[105] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua Bengio and
Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA,
USA, May 7-9, 2015, Conference Track Proceedings, 2015.

[106] John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic

optimization. J. Mach. Learn. Res., 12(null):2121–2159, jul 2011.

[107] Roger Fletcher and Colin M. Reeves. Function minimization by conjugate gradients. The Computer Journal,

7(2):149–154, 01 1964.

[108] Elijah Polak and Gerard Ribiere. Note sur la convergence de m´ethodes de directions conjugu´ees.
ESAIM: Mathematical Modelling and Numerical Analysis-Mod´elisation Math´ematique et Analyse Num´erique,
3(R1):35–43, 1969.

[109] Magnus Rudolph Hestenes, Eduard Stiefel, et al. Methods of conjugate gradients for solving linear systems,

volume 49. NBS Washington, DC, 1952.

[110] Yu-Hong Dai and Yaxiang Yuan. A nonlinear conjugate gradient method with a strong global convergence

property. SIAM Journal on optimization, 10(1):177–182, 1999.

[111] Mohammed M. Mahdi, Hasan Hadi Dwail, H. A. Wasi, Karrar Habeeb Hashim, Nabiha kahtan Dreeb, Hus-
sein Ali Hussein, and Mushtak A. K. Shiker. Solving systems of nonlinear monotone equations by using a
new projection approach. Journal of Physics: Conference Series, 1804(1):012107, feb 2021.

[112] MM Mahdi and Mushtak AK Shiker. A new class of three-term double projection approach for solving
nonlinear monotone equations. In Journal of Physics: Conference Series, volume 1664, page 012147. IOP
Publishing, 2020.

[113] Mohammed Yusuf Waziri, Aliyu Yusuf, and Auwal Bala Abubakar. Improved conjugate gradient method for

nonlinear system of equations. Computational and Applied Mathematics, 39(4):1–17, 2020.

[114] MK Dauda, Mustafa Mamat, MY Waziri, Fadhila Ahmad, and Fatma Susilawati Mohamad. Inexact CG-
method via SR1 update for solving systems of nonlinear equations. far east journal of mathematical sciences,
100(11):1787, 2016.

[115] MK Dauda, AS Magaji, US Shehub, MA Usman, and MY Waziri. A simple conjugate gradient type method for
solving large-scale systems of nonlinear equations. Malaysian Journal of Computing and Applied Mathematics,
3(2):25–35, 2020.

[116] Howard H. Rosenbrock. An Automatic Method for Finding the Greatest or Least Value of a Function. The

Computer Journal, 3(3):175–184, 01 1960.

[117] Robert Hooke and T. A. Jeeves. “ direct search” solution of numerical and statistical problems. J. ACM,

8(2):212–229, apr 1961.

[118] Richard P. Brent. An algorithm with guaranteed convergence for ﬁnding a zero of a function. Comput. J.,

14:422–425, 1971.

[119] John A. Nelder and Roger Mead. A Simplex Method for Function Minimization. The Computer Journal,

7(4):308–313, 01 1965.

[120] Aijia Ouyang, Yongquan Zhou, and Qifang Luo. Hybrid particle swarm optimization algorithm for solving
systems of nonlinear equations. In 2009 IEEE International Conference on Granular Computing, pages 460–
465. IEEE, 2009.

[121] Richard P. Brent. Algorithms for minimization without derivatives. Prentice-Hall Series in Automatic Com-

putation. Prentice-Hall, Inc., Englewood Cliﬀs, N.J., 1973.

[122] Andrew R. Conn, Katya Scheinberg, and Luis N. Vicente. Introduction to derivative-free optimization, vol-
ume 8 of MPS/SIAM Series on Optimization. Society for Industrial and Applied Mathematics (SIAM),
Philadelphia, PA; Mathematical Programming Society (MPS), Philadelphia, PA, 2009.

24

[123] Reiner Horst, Panos M. Pardalos, and Nguyen V. Thoai. Introduction to global optimization, volume 48 of
Nonconvex Optimization and its Applications. Kluwer Academic Publishers, Dordrecht, second edition, 2000.

[124] Christodoulos A. Floudas, Panos M. Pardalos, Claire S. Adjiman, William R. Esposito, Zeynep H. G¨um¨u¸s,
Stephen T. Harding, John L. Klepeis, Cliﬀord A. Meyer, and Carl A. Schweiger. Handbook of Test Problems
in Local and Global Optimization. Springer US, 1999.

[125] Reiner Horst and Panos M. Pardalos, editors. Handbook of Global Optimization. Nonconvex Optimization

and Its Applications. Springer US, 1995.

[126] Panos M. Pardalos and H. Edwin Romeijn, editors. Handbook of Global Optimization, Volume 2. Springer

US, 2002.

[127] Christodoulos A. Floudas and Panos M. Pardalos. A collection of test problems for constrained global opti-
mization algorithms. Lecture Notes in Computer Science. Springer, New York, NY, September 1990.

[128] Eugene L. Lawler and D. E. Wood. Branch-and-bound methods: A survey. Operations Research, 14(4):699–

719, 1966.

[129] M. J. Hirsch, C. N. Meneses, P. M. Pardalos, and M. G. C. Resende. Global optimization by continuous

grasp. Optimization Letters, 1(2):201–212, Mar 2007.

[130] Thomas A. Feo and Mauricio G. C. Resende. Greedy randomized adaptive search procedures. Journal of

Global Optimization, 6(2):109–133, Mar 1995.

[131] R. Baker Kearfott. Some tests of generalized bisection. ACM Trans. Math. Softw., 13(3):197–220, September

1987.

[132] Keith Meintjes and Alexander P. Morgan. Chemical equilibrium systems as numerical test problems. ACM

Trans. Math. Softw., 16(2):143–151, June 1990.

[133] Nenad Mladenovi´c and Pierre Hansen. Variable neighborhood search. Computers & Operations Research,

24(11):1097–1100, 1997.

[134] Gisela C.V. Ramadas and Edite M.G.P. Fernandes. Self-adaptive combination of global tabu search and local
search for nonlinear equations. International Journal of Computer Mathematics, 89(13-14):1847–1864, 2012.

[135] Scott Kirkpatrick, Daniel Gelatt, and Mario P. Vecchi. Optimization by simulated annealing. Science,

220(4598):671–680, 1983.

[136] V. Granville, M. Kriv´anek, and J. P. Rasson. Simulated annealing: A proof of convergence. IEEE Trans.

Pattern Anal. Mach. Intell., 16(6):652–656, jun 1994.

[137] A. Corana, M. Marchesi, C. Martini, and S. Ridella. Minimizing multimodal functions of continuous variables

with the “simulated annealing” algorithm. ACM Trans. Math. Softw., 13(3):262–280, sep 1987.

[138] Hime A. e Oliveira and Antonio Petraglia. Solving nonlinear systems of functional equations with fuzzy

adaptive simulated annealing. Applied Soft Computing, 13(11):4349–4357, 2013.

[139] Ofer M. Shir. Niching in Evolutionary Algorithms, pages 1035–1069. Springer Berlin Heidelberg, Berlin,

Heidelberg, 2012.

[140] Mike Preuss. Multimodal optimization by means of evolutionary algorithms. Springer, 2015.

[141] James C. Bean. Genetic algorithms and random keys for sequencing and optimization. ORSA Journal on

Computing, 6(2):154–160, 1994.

[142] M.J. Hirsch, P.M. Pardalos, and M.G.C. Resende. Speeding up continuous GRASP. European Journal of

Operational Research, 205(3):507–521, September 2010.

[143] Mohamed A Tawhid and Abdelmonem M Ibrahim. A hybridization of grey wolf optimizer and diﬀerential

evolution for solving nonlinear systems. Evolving Systems, 11(1):65–87, 2020.

25

[144] Konstantinos E. Parsopoulos and Michael N. Vrahatis. Particle swarm optimization and intelligence: Advances

and applications. Information Science Publishing (IGI Global), Hershey, PA, USA, 2010.

[145] Yugui Li, Yanxu Wei, and Yantao Chu. Research on solving systems of nonlinear equations based on improved

pso. Mathematical Problems in Engineering, 2015, 2015.

[146] Oguz Emrah Turgut, Mert Sinan Turgut, and Mustafa Turhan Coban. Chaotic quantum behaved particle
swarm optimization algorithm for solving nonlinear system of equations. Computers & Mathematics with
Applications, 68(4):508–530, 2014.

[147] Jun Sun, Bin Feng, and Wenbo Xu. Particle swarm optimization with particles having quantum behavior. In
Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No.04TH8753), volume 1, pages
325–331 Vol.1, 2004.

[148] Yuanbin Mo, Hetong Liu, and Qin Wang. Conjugate direction particle swarm optimization solving systems

of nonlinear equations. Computers & Mathematics with Applications, 57(11-12):1877–1882, 2009.

[149] Ivan Amaya, Jorge Cruz, and Rodrigo Correa. Real roots of nonlinear systems of equations through a

metaheuristic algorithm. Dyna, 78(170):15–23, 2011.

[150] Majid Jaberipour, Esmaile Khorram, and Behrooz Karimi. Particle swarm algorithm for solving systems of

nonlinear equations. Computers & Mathematics with Applications, 62(2):566–576, 2011.

[151] Konstantinos E. Parsopoulos and Michael N. Vrahatis. Parameter selection and adaptation in uniﬁed particle

swarm optimization. Mathematical and Computer Modelling, 46(1-2):198–213, 2007.

[152] Konstantinos E. Parsopoulos and Michael N. Vrahatis. Recent approaches to global optimization problems

through particle swarm optimization. Natural Computing, 1(2-3):235–306, 2002.

[153] Yiannis G. Petalas, Konstantinos E. Parsopoulos, and Michael N. Vrahatis. Memetic particle swarm opti-

mization. Annals of Operations Research, 156(1):99–127, 2007.

[154] Kenichi Tamura and Keiichiro Yasuda. Spiral dynamics inspired optimization. Journal of Advanced Compu-

tational Intelligence and Intelligent Informatics, 15(8):1116–1122, 2011.

[155] Kenichi Tamura and Keiichiro Yasuda. Primary study of spiral dynamics inspired optimization. IEEJ Trans-

actions on Electrical and Electronic Engineering, 6(S1):S98–S100, 2011.

[156] R¨udiger U. Seydel. Tools for Computational Finance. Springer London, 2012.

[157] Mahdi Abdollahi, Asgarali Bouyer, and Davoud Abdollahi.

Improved cuckoo optimization algorithm for

solving systems of nonlinear equations. The Journal of Supercomputing, 72(3):1246–1269, 2016.

[158] Xinming Zhang, Qian Wan, and Youhua Fan. Applying modiﬁed cuckoo search algorithm for solving systems

of nonlinear equations. Neural Computing and Applications, 31(2):553–576, 2019.

[159] Gai-Ge Wang, Suash Deb, and Zhihua Cui. Monarch butterﬂy optimization. Neural Computing and Applica-

tions, 31(7):1995–2014, Jul 2019.

[160] Abdelmonem M Ibrahim and Mohamed A Tawhid. A hybridization of diﬀerential evolution and monarch
butterﬂy optimization for solving systems of nonlinear equations. Journal of Computational Design and
Engineering, 6(3):354–367, 2019.

[161] Yongquan Zhou, Jiakun Liu, and Guangwei Zhao. Leader glowworm swarm optimization algorithm for solving

nonlinear equations systems. Electrical Review, 88(1):101–106, 2012.

[162] Ruimin Jia and Dengxu He. Hybrid artiﬁcial bee colony algorithm for solving nonlinear system of equations.
In 2012 Eighth international conference on computational intelligence and security, pages 56–60. IEEE, 2012.

[163] Mahdi Abdollahi, Ayaz Isazadeh, and Davoud Abdollahi. Imperialist competitive algorithm for solving sys-

tems of nonlinear equations. Computers & Mathematics with Applications, 65(12):1894–1908, 2013.

[164] MKA Ariyaratne, TGI Fernando, and Sunethra Weerakoon. Solving systems of nonlinear equations using a

modiﬁed ﬁreﬂy algorithm (modfa). Swarm and Evolutionary Computation, 48:72–92, 2019.

26

[165] Gisela CV Ramadas and Edite Manuela da GP Fernandes. Solving systems of nonlinear equations by harmony

search. International Conference on Mathematical Methods in Science and Engineering . . . , 2013.

[166] Naser Moosavian and Babak Kasaee Roodsari. Soccer league competition algorithm, a new method for solving

systems of nonlinear equations. International Journal of Intelligence Science, 04(01):7–16, 2014.

[167] Ya-Zhong Luo, Guo-Jin Tang, and Li-Ni Zhou. Hybrid approach for solving systems of nonlinear equations

using chaos optimization and quasi-newton method. Applied Soft Computing, 8(2):1068–1073, 2008.

[168] Dixiong Yang, Gang Li, and Gengdong Cheng. On the eﬃciency of chaos optimization algorithms for global

optimization. Chaos Solitons and Fractals, 34(4):1366–1375, November 2007.

[169] J. Kiefer. Sequential minimax search for a maximum. Proceedings of the American Mathematical Society,

4(3):502–506, 1953.

[170] Yu-Nong Zhang, Zeng-Hai Chen, and Ke Chen. Convergence properties analysis of gradient neural network

for solving online linear equations. Acta Automatica Sinica, 35(8):1136–1139, 2009.

[171] Guimei Li and Zhezhao Zeng. A neural-network algorithm for solving nonlinear equation systems. volume 1,

pages 20–23, 12 2008.

[172] Karl Mathia. Solutions of linear equations and a class of nonlinear equations using recurrent neural networks.

Technical report, January 2000.

[173] Guillaume Lample and Fran¸cois Charton. Deep learning for symbolic mathematics. CoRR, abs/1912.01412,

2019.

[174] Athanasios Margaris and Miltiadis Adamopoulos. Solving nonlinear algebraic systems using artiﬁcial neural

networks. CEUR Workshop Proceedings, 284, 01 2007.

[175] Tasneem A. Awaad, Abdelrahman M. Elbehery, Amany Abdelhamid, Salma K. Elsokkary, Youssef M. Ali,
Khaled Salah, Mohamed Abdel Salam, and M. Watheq El-Kharashi. An ultrafast neural network-based
hardware acceleration for nonlinear systems’ simulators. Computers & Electrical Engineering, 79:106452,
2019.

[176] Konstantinos Goulianas, Athanasios Margaris, Ioannis Refanidis, Konstantinos Diamantaras, and Theoﬁlos
Papadimitriou. A back propagation-type neural network architecture for solving the complete nxn nonlinear
algebraic system of equations. 2016.

[177] Long Jin, Shuai Li, Bolin Liao, and Zhijun Zhang. Zeroing neural networks: A survey. Neurocomputing,

267:597–604, 2017.

27

