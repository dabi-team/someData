Microstructure Characterization and Reconstruction in Python: MCRpy

Paul Seibert, Alexander Ra√üloÔ¨Ä, Karl Kalina, Marreddy Ambati, Markus K√§stner ‚àó

Institute of Solid Mechanics,
TU Dresden, Germany

2
2
0
2

l
u
J

1
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
2
5
6
4
0
.

7
0
2
2
:
v
i
X
r
a

Abstract

Microstructure characterization and reconstruction (MCR)
is an important prerequisite for empowering and accelerat-
ing integrated computational materials engineering. Much
progress has been made in MCR recently, however, in absence
of a Ô¨Çexible software platform it is diÔ¨Écult to use ideas from
other researchers and to develop them further. To address this
issue, this work presents MCRpy1 for easy-to-use, extensible
and Ô¨Çexible MCR. The software platform that can be used
as a program with graphical user interface, as a command
line tool and as a Python library. The central idea is that
microstructure reconstruction is formulated as a modular and
extensible optimization problem. In this way, any descriptors
can be used for characterization and any loss function com-
bining any descriptors can be minimized using any optimizer
for reconstruction. With stochastic optimizers, this leads to
variations of the well-known Yeong-Torquato algorithm. Fur-
thermore, MCRpy features automatic diÔ¨Äerentiation, enabling
the utilization of gradient-based optimizers. In this work, after
a brief introduction to the underlying concepts, the capabilities
of MCRpy are demonstrated by exemplarily applying it to
typical MCR tasks. Finally, it is shown how to extend MCRpy
by deÔ¨Åning a new microstructure descriptor and readily using
it for reconstruction without additional implementation eÔ¨Äort.

Keywords: Microstructure ‚Äì Characterization ‚Äì Reconstruc-
tion ‚Äì Descriptor ‚Äì Software ‚Äì ICME

1

Introduction

Establishing and inverting process-structure-property (PSP)
linkages is a central goal in integrated computational materials
engineering (ICME) in order to accelerate the development
of new materials. With increasing computational resources
and much development in data processing and machine learn-
ing, data-centric workÔ¨Çows for microstructure design receive
more and more attention [1]. These workÔ¨Çows rely on large
databases that are created using numerical simulations. One
central aspect to consider in this context is how to choose and
create the microstructures to simulate from the extremely big
set of possible structures. To avoid extremely time-consuming
and cost-intensive experimental campaigns, an eÔ¨Écient mi-
crostructure characterization and reconstruction (MCR) tool is

‚àóContact: markus.kaestner@tu-dresden.de
1https://github.com/NEFM-TUDresden/MCRpy

therefore a key ingredient to making large-scale ICME work-
Ô¨Çows feasible. A very brief introduction to MCR is given in
the following and the reader is kindly referred to [2] for an
in-depth review.

Microstructure characterization, the Ô¨Årst aspect of MCR,
is required to handle the stochasticity of the microstructures:
Two distinct image sections of the same microstructure are
similar from a visual and statistical perspective, but completely
diÔ¨Äerent in terms of a pixel-based representation. Thus, for
operations like quantitative comparisons, it is reasonable to
map the pixel-based microstructure to a translation-invariant,
stationary descriptor ùê∑ that allows for these operations. There-
fore, ùê∑ is a reasonable choice for representing structures in
PSP linkages. Furthermore, it provides a possibility to explore
the microstructure space in data-driven materials development
workÔ¨Çows.

Microstructure reconstruction, the second aspect of MCR,
can be regarded as the inverse operation to microstructure
characterization: The goal is to Ô¨Ånd a microstructure such
that the corresponding descriptor equals the given value. Mi-
crostructure reconstruction allows to (i) create a plausible 3D
volume element from a 2D slice like a microscopy image, (ii)
create a set of similar microstructures given one realization
and (iii) interpolating between microstructures in terms of
descriptors.

These two aspects of MCR, namely characterization and
reconstruction, can be treated independently, for example us-
ing spatial correlations as descriptors and modern machine
learning-based techniques for reconstruction. However, auto-
matic ICME workÔ¨Çows for complex materials highly beneÔ¨Åt
from a principled exploration of the descriptor space, where
microstructures are selected for reconstruction, simulation and
homogenization in a way that maximizes the expected informa-
tion gain for the PSP linkage [3]. Therefore, it is important to
combine characterization and reconstruction so that given any
combination of descriptors and their values, the reconstruction
can be triggered from these descriptors. Furthermore, recent
research indicates that there is no single best descriptor for
microstructure reconstruction [4] and for PSP linkages [5],
but that it is reasonable to choose descriptors based on the
structure at hand. For this purpose, we present MCRpy, a
modular and extensible open-source tool that facilitates easy
microstructure characterization and reconstruction based on
arbitrary descriptors.

Free open-source platforms are a great way of harness-

Preprint submitted to Springer
arXiv

1

 
 
 
 
 
 
Seibert et al., Microstructure Characterization and Reconstruction in Python: MCRpy, 2022

ing the advantages of digitization and modern computational
infrastructure. The free accessibility allows researchers to
quickly test each others‚Äô ideas and to develop them further.
The open-source nature of such a platform enables it to become
a collaborative project, considerably leveraging its potential.
Especially in complex scientiÔ¨Åc disciplines, such collaboration
is indispensable. As an example, consider the Ô¨Åeld of machine
learning, speciÔ¨Åcally neural networks [6]. In the beginning
of research on neural networks, newcomers had to implement
relatively complex procedures like back-propagation before
being able to reproduce results from the literature, let alone to
develop them further. Later, easy-to-use open-source libraries
like TensorFlow and pyTorch have greatly lowered the hurdle,
allowing more researchers to enter the Ô¨Åeld easily. This surely
contributed to the rapid progress in the last decades and to the
plethora of neural network architectures and applications that
is observed today.

The digital infrastructure of the materials science commu-
nity has grown considerably as a consequence of the materials
genome initiative [7] and similar projects. Despite the rapidly
growing number of tools for materials innovation in general,
MCR speciÔ¨Åcally is in a comparable position now as machine
learning was 20 years ago: A great variety of methods exists,
but in absence of a common platform and interface, every
newcomer in the Ô¨Åeld has to implement fundamental tech-
nologies like the lineal path function and the Yeong-Torquato
algorithm by hand. This is a big hurdle and thwarts any rapid
progress. Thus, the goal of this contribution is to accelerate
MCR research by providing MCRpy as an easy-to-use, exten-
sible and Ô¨Çexible software solution that aims at realizing a
seamless workÔ¨Çow by providing various interfaces to new and
established techniques.

The work starts with Section 2, where the current digital
infrastructure is reviewed and it is outlined how MCRpy inte-
grates into it. Then, MCRpy is presented in Section 3. Typical
application workÔ¨Çows are presented in Section 4 and Ô¨Ånally, a
conclusion is drawn in Section 5.

2 Current Digital Infrastructure

After President Barack Obama announced the US-American
Materials Genome Initiative [7] that provided substantial
funding for accelerated materials development, collaborative
projects and digital frameworks were initiated all over the world.
A non-exhaustive list includes the European NOMAD-CoE [8]
and its platform described in [9] and the Swiss NCCR MAR-
VEL [10] with its AiiDA platform [11] described in [12]. The
extremely popular and often-cited pymatgen library [13] can
be mentioned as an early contribution to open-source materials
science software infrastructure. This trend continues, as can
be seen with the recent example radonpy [14]. However, much
of this research is focused on deriving material properties from
considerations on the atomistic length scale.

On the continuum length scale, the Python Materials Knowl-
edge System (pyMKS) [15] is a notable open-source framework.
Its eÔ¨Écient FFT-based implementation of the spatial two-point
correlation ùëÜ2 facilitates easy microstructure characterization.
However, in pyMKS, microstructure characterization is lim-

ited to ùëÜ2 and no further descriptors are available. Moreover,
pyMKS does not allow for microstructure reconstruction, only
characterization. A strong focus lies on eÔ¨Écient homoge-
nization [16] and direct coupling to an internal Ô¨Ånite element
solver, SfePy [17, 18]. This is very convenient for simple
problems like elasticity. For advanced techniques like crystal
plasticity, external software like the D√ºsseldorf Advanced
Materials Simulation Kit (DAMASK) [19] can be used. Fur-
thermore, pyMKS provides an easy interface for dimensionality
reduction of the descriptor space and for establishing structure-
property-linkages based on the reduced descriptors and the
corresponding homogenized properties. In summary, pyMKS
acts as an overarching framework to implement ICME work-
Ô¨Çows.

For numerical simulation of microstructures, many open-
source tools are available, ranging from general and easy-to-use
packages like SfePy [17, 18] to special-purpose software like
DAMASK [19], which comes with a highly optimized Fourier-
based crystal plasticity solver. Furthermore, current research
on FFT-based homogenization [20] is making remarkable
progress that might lead to an open-source tool soon. Thus,
with pyMKS as an overarching framework and numerous tools
and progress for numerical simulation and homogenization,
an open-source MCR software package can be identiÔ¨Åed as a
Ô¨Ånal component of ICME workÔ¨Çows.

To the authors‚Äô best knowledge, the only widely-used soft-
ware tool for MCR is DREAM.3D [21], a long developed
and full-Ô¨Çedged program.
Its roots date back around 20
years to the early works of Michael Groeber and the Carnegie
Mellon University microstructure builder. Despite this long
history, DREAM.3D still enables numerous current research ac-
tivities in materials innovation and ICME, see for example [22].
This success is empowered by the many features, robustness,
eÔ¨Éciency and easy user interface of DREAM.3D, which may be
partially attributable to its open-source core. Thus, DREAM.3D
can be highly recommended for the workÔ¨Çows it implements.
However, the internal microstructure representation and the
available pipelines in DREAM.3D are mainly intended for
certain material systems and microstructure descriptors. The
internal data format as well as the provided characterization
and reconstruction algorithms are centered around classical de-
scriptors like grain size distribution functions and orientation
distribution functions. This makes DREAM.3D excellent at
reconstructing geometric inclusions like ellipses and texture as
in metallic materials, but multi-phase materials with complex
morphology as shown in Figure 8 cannot be realized. Further-
more, DREAM.3D is written in c++, which is not common
among engineering researchers due to its complexity. In recent
research, new microstructure descriptors or reconstruction
algorithms are sometimes provided as Python or Matlab code
in a GitHub repository, but are hardly ever implemented in c++
as a DREAM.3D pipeline. Even if that was the case, then these
descriptors could not be readily used for reconstruction since
the DREAM.3D reconstruction pipelines are tailored towards
speciÔ¨Åc descriptors and would need to be re-implemented.
Thus, DREAM.3D is an excellent and robust program, but it is
mainly suited for speciÔ¨Åc practical applications and for certain

Preprint submitted to Springer
arXiv

2

Seibert et al., Microstructure Characterization and Reconstruction in Python: MCRpy, 2022

materials.

In contrast, the present work aims at creating a Ô¨Çexible
research platform for multiphase materials of high morphologi-
cal complexity. Thus, MCRpy clearly diÔ¨Äers from DREAM.3D
regarding the targeted audience and the scope of materials
systems. As a Python package, it integrates naturally with
numerous tools for numerical simulation, machine learning
or materials science workÔ¨Çows Especially pyMKS can act as
an overarching ICME framework, where the present work pro-
vides an MCR solution. In summary, MCRpy attempts to Ô¨Åll a
striking gap in the ICME software landscape. A theoretical
understanding of MCRpy is provided in Section 3, followed by
an illustration of typical workÔ¨Çows in Section 4.

3 Overview of MCRpy

Microstructure characterization and reconstruction in
Python (MCRpy) is an open-source software tool accessible
under https://github.com/NEFM-TUDresden/MCRpy. It
is released under the Apache 2.0 license and can be used

(i) as a program with graphical user interface (GUI), intended
for non-programmers and as an easy introduction to MCR,

(ii) as a command line tool, intended for automated and large-
scale application on high-performance computers without
graphical interface, and

(iii) as a regular PIP-installable Python module, intended
for performing advanced and custom operations in the
descriptor space.

A schematic overview is given in Figure 1: The main func-
tionalities of MCRpy, characterization and reconstruction, are
explained in Sections 3.1 and 3.2 respectively. Furthermore,
additional functions are provided to manipulate the microstruc-
tures and descriptors and to visualize data. A complete set
of the available operations is given in Table 1. The core idea
of MCRpy is its extensibility in that any descriptors can be
used for characterization and any loss function combining
any descriptors can be minimized using any optimizer for
reconstruction. This is outlined in Section 3.3.

3.1 Characterization

The characterization function

ùëìùê∂ : ùëÄ ‚Ü¶‚Üí {ùê∑ùëñ }ùëõùê∑
ùëñ=1

(1)

assigns a given pixel-based microstructure ùëÄ to a set of ùëõùê∑
corresponding descriptors ùê∑ùëñ. These descriptors quantify the
microstructural morphology in a statistical and translation-
invariant manner. Hereby, a microstructure with ùëõp diÔ¨Äerent
phases is represented as a set of ùëù indicator functions

ùêº ùëù (ùë•) =

(cid:26) 1,
0,

if ùë• in phase ùëù
else.

(2)

For example, the volume fraction ùë£f of a microstructure
is a very simple descriptor. Of course, the volume fraction
captures some but not all information needed to describe the

microstructure. Several other quantities matter, for example the
size and shape of inclusions and the degree to which distinct
phases are spatially clustered. Besides these classical descrip-
tors, in the light of increasing computational resources, recent
research has been focused on more universal high-dimensional
descriptors that are less dense in information, but have higher
descriptive capabilities in total. As an early example for high-
dimensional descriptors, spatial correlations [23] have proven
to be a versatile tool that is still used today [2]. A good intro-
duction can be found in [24]. A diÔ¨Äerentiable generalization
of spatial correlation is presented in [25] and used in this
work. Spatial correlations have inspired a range of concep-
tually similar descriptors like the lineal path function [26],
cluster correlation function [27] and polytope function [28].
The reader is referred to [2] for a comprehensive overview.
Finally, the Gram matrices of the feature maps of pre-trained
convolutional neural networks have been shown to contain
relevant microstructural information [29]. Remarkable results
in microstructure reconstruction have been achieved using such
Gram matrices alone [30, 31] and in combination with other
descriptors [32, 4].

Finding a microstructure description that is both dense
and contains all relevant information is an active Ô¨Åeld of
research [2]. Examples are the recently developed entropic
descriptors [33] or polytope functions [28]. Thus, besides the
currently available descriptors listed in Table 2, any researcher
can add a descriptor plugin to MCRpy. If the descriptor plugin
is deÔ¨Åned with an indicator function as input, it is applied to
the indicator function of each phase separately. Furthermore,
a 2D descriptor is automatically applied on and averaged over
2D slices of a 3D structure. The only requirement posed on
new descriptors is that they must be computable on a pixel or
voxel geometry. More details on extensibility can be found in
Section 3.3. Any of the available and added descriptors can be
used from microstructure reconstruction, which is discussed
in the following section.

3.2 Reconstruction

In MCRpy, microstructure reconstruction is fundamentally

regarded as an optimization problem

ùëÄ rec = argmin

ùëÄ

(cid:16)

L

{(ùê∑ùëñ (ùëÄ), ùê∑des

ùëñ

(cid:17)

)}ùëõùê∑
ùëñ=1

,

(3)

where the reconstructed microstructure ùëÄ rec minimizes a
loss function L. The loss function depends on ùëõùê∑ diÔ¨Äerent
descriptors {ùê∑ùëñ }ùëõùê∑
ùëñ=1 and quantiÔ¨Åes the distance between their
current and desired values. Herein, ùê∑ùëñ (ùëÄ) denotes the value
of the ùëñ-th descriptor associated with the current microstructure
and its desired value ùê∑des
. Naturally, as in the characterization
step, any descriptors can be used, for example the volume
fractions ùë£f, the spatial correlations ùëÜ or the Gram matrices ùê∫.
For the loss function L, a simple choice is a weighted sum
over the mean squared error norm. DiÔ¨Äerent loss functions
are available in MCRpy and the user can implement additional
ones. Finally, given a set of descriptors and a loss function, an
optimization problem emerges as a special case of Equation 3.
This optimization problem can be solved using an optimizer,

ùëñ

Preprint submitted to Springer
arXiv

3

Seibert et al., Microstructure Characterization and Reconstruction in Python: MCRpy, 2022

Figure 1: Schematic overview of MCRpy: Microstructures can be characterized by descriptors and reconstructed by
optimization. Herein, descriptors, losses and optimizers can be provided as Ô¨Çexible plugin modules.

Table 1: Functions.

function

explanation

characterize
reconstruct
match
view
smooth
merge
interpolate

characterize a microstructure, see Section 3.1
reconstruct a microstructure given the descriptors, see Section 3.2
characterize and reconstruct immediately, for validation and for 2D-to-3D workÔ¨Çows
plot microstructures, descriptors and convergence data interactively or save to a Ô¨Åle
smooth a microstructure
merge diÔ¨Äerent descriptors to prescribe them on orthogonal sections for reconstructing anisotropic structures
interpolate between given descriptors

which is provided as a plugin module. If all descriptors are
diÔ¨Äerentiable, then a gradient-based optimizer like L-BFGS-
B [35] can be used, leading to the very eÔ¨Écient diÔ¨Äerentiable
MCR [25, 4]. Otherwise, the choice is limited to gradient-free
optimizers like simulated annealing.

As a simple example, if only the spatial two-point cor-
relation ùëÜ2 is used as a descriptor and the loss function is
formulated as a mean squared error norm of the descriptor
diÔ¨Äerence, the following optimization problem emerges:

ùëÄ rec = argmin

ùëÄ

||ùëÜ2 (ùëÄ) ‚àí ùëÜdes

2 ||MSE

.

(4)

If simulated annealing is chosen as an optimizer, MCRpy
eÔ¨Äectively performs the well-known Yeong-Torquato algorithm
as used in [36].

As a more recent example, if the Gram matrices ùê∫ of the
feature maps of the VGG-19 CNN are chosen as a descrip-
tor [29] for the same loss function, the emerging optimization
problem

ùëÄ rec = argmin

ùëÄ

||ùê∫ (ùëÄ) ‚àí ùê∫des||MSE

(5)

allows for a gradient-based optimizer. If L-BFGS-B [35] is
chosen for this purpose, MCRpy eÔ¨Äectively performs the ap-
proach of Li et al. [30], which is a special case of diÔ¨Äerentiable
MCR [25].

As a Ô¨Ånal example, the diÔ¨Äerentiable three-point corre-
lations ùëÜ3, the above-mentioned Gram matrices ùê∫ and the
normalized total variation V are combined. The loss function
accumulates the weighted mean squared error norm, where ùúÜùê∑ùëñ

denotes the weight of the ùëñ-th descriptor. If the resulting opti-
mization problem

ùëÄ rec = argmin

ùëÄ

ùúÜùëÜ ||ùëÜ3(ùëÄ) ‚àí ùëÜdes

3 ||MSE+

+ùúÜùê∫ ||ùê∫ (ùëÄ) ‚àí ùê∫des||MSE+
+ùúÜ V ||V (ùëÄ) ‚àí Vdes||MSE

(6)

is solved using the gradient-based L-BFGS-B optimizer,
MCRpy eÔ¨Äectively performs the diÔ¨Äerentiable MCR algorithm
as used in [4].

As can be seen, diÔ¨Äerent parameter settings allow to re-
create well-known reconstruction algorithms as well as to
try out new ones by simply changing the arguments. As an
overview, all descriptors, optimizers and loss functions are
listed in Table 3.

3.3 Extensibility

The central advantage of MCRpy is its extensibility in
that descriptors, loss functions and optimizers can be easily
provided by anyone. For example, new optimization-based
reconstruction algorithms like the work of Cecen at al. [42] can
be implemented as an optimizer plugin to combine them with
all the available microstructure descriptors. This is achieved
by a plugin architecture, which is sketched in Figure 2. In this
section, we explain the underlying software pattern, whereas
exact instructions and an example on how to write a plugin are
given in Section 4.4. In the following, the plugin architecture
is explained for the case of descriptors. The same idea is
employed for loss functions and optimizers.

Preprint submitted to Springer
arXiv

4

MCRpyLosspluginsWeightedMSEWeightedL2¬∑¬∑¬∑OptimizerpluginsL-BFGS-BAdam¬∑¬∑¬∑SimulatedannealingDescriptorpluginsSpatialcorrelationLinealpathfunction¬∑¬∑¬∑GrammatricesVolumefractionsReconstructionbyoptimizationCharacterizationbydescriptorsr1r2x1x3x2Seibert et al., Microstructure Characterization and Reconstruction in Python: MCRpy, 2022

Table 2: Microstructure descriptors that are implemented in MCRpy.

Descriptor

VolumeFractions
Correlations
FFTCorrelations
GramMatrices
Variation
LinealPath

DiÔ¨Äerentiable
(cid:88)
(cid:88)
(cid:55)
(cid:88)
(cid:88)
(cid:88)

ùë£f
ÀúùëÜ
ùëÜ
ùê∫
V
Àúùêø

Comment

-
ÀúùëÜ2 and ÀúùëÜ3; see [25]
only ùëÜ2; FFT-based; from pyMKS [15]
using VGG19 [34]; see [30]
normalized total variation; see [4]
see Appendix A

Table 3: Microstructure descriptors, optimizers and loss functions that are implemented in MCRpy. Simulated annealing is the
only optimizer in the list that is not gradient-based. More details on the descriptors is given in Table 2.

Descriptors

Optimizers

Volume fractions
Correlations
Lineal path
Gram matrices
Variation

L-BFGS-B [35]
TNC [37]
Adam [38], Adagrad [39], Adadelta [40], ...
RMSprop [41]
SGD [41]
Simulated Annealing [23]

Loss functions

2D/3D weighted MSE
2D/3D weighted RMS error
2D/3D weighted L1 distance
2D/3D weighted L2 distance

A descriptor plugin can be written by simply inheriting from
the abstract Descriptor class. Consequently, the available
descriptor plugins are not known at the time of writing the
MCRpy core code, so they must be loaded dynamically as soon
as the characterization or reconstruction module demands the
plugin. This is done by means of a loader module based on
importlib. Upon import, a descriptor plugin registers itself
at a descriptor factory. After that, the descriptor factory can
be queried to create descriptor instances from the plugin. The
descriptor factory then returns a callable which computes the
descriptor value given a microstructure. This callable can
now be used to characterize microstructures, compose loss
functions, compute gradients using automatic diÔ¨Äerentiation
and to reconstruct microstructures.

Thus, adding a descriptor plugin to MCRpy merely consists
of adding a Ô¨Åle with the plugin deÔ¨Ånition to the right directory,
while the rest of the code does not need to be changed. The
descriptor immediately becomes available for characteriza-
tion and for reconstruction in combination with any other
descriptors, any loss function and any optimizer.

4 Typical MCRpy workÔ¨Çows

Typical use-cases and workÔ¨Çows of MCRpy are illustrated in
this section by means of three representative examples. First,
in Section 4.1, a plausible 3D volume element is reconstructed
from a 2D microstructure slice. This very relevant, since 3D
information can be very time- and cost-intensive to obtain ex-
perimentally. Secondly, in Section 4.2, a statistically similar set
of small volume elements is generated from a single example.
This greatly reduces the computational eÔ¨Äort for numerical
homogenization. Thirdly, in Section 4.3, descriptor values
are directly manipulated and used for reconstructing novel
structures. Techniques like this may be explored in the future
to augment data sets and explore PSP linkages. These three

examples are demonstrated in the three modes of operating
MCRpy, namely via a GUI, as a command line tool and as a
Python library, respectively. Note that this order is chosen for
demonstration purposes only and it is possible to execute all
three workÔ¨Çows with all three modes of operation. Finally, in
Section 4.4, it is demonstrated how to add a custom descriptor
to MCRpy and how to use it for characterization and recon-
struction. The original structures are taken from pyMKS [15]
for Sections 4.1 to 4.3 and from [30] for Section 4.4.

4.1 Obtaining a 3D domain from a 2D microstructure

slice

As a Ô¨Årst example, MCRpy is used to reconstruct a plausible
3D volume element given a segmented 2D slice. This is
a common task since experimental observations are often
available only in 2D. The 3D volume element can be used
for example for numerical simulations. From an algorithmic
perspective, this goal is achieved by computing the descriptor
on the given slice and prescribing it on every slice of the
microstructure, details cf. [4].

This task is solved using the MCRpy GUI as shown in
Figure 3. A simple approach would be characterization and
immediate reconstruction, but as mentioned in Table 1, MCRpy
provides a shortcut for this in the match function. After se-
lecting the match-action on the left, the relevant options can
be set in the center. The name of each option is identical to the
command line and the Python library, allowing users to easily
switch interfaces. By default, a 2D structure is reconstructed
in 2D. However, by using the option add_dimension, the
extent of the reconstructed structure in ùëß-direction is set to the
desired value. The diÔ¨Äerentiable three-point correlations ÀúùëÜ3
as proposed in [25] are chosen as descriptor. Furthermore, as
discussed in [4], the variation V is employed as a descriptor in
order to suppress noise in the 3D reconstruction. The weights

Preprint submitted to Springer
arXiv

5

Seibert et al., Microstructure Characterization and Reconstruction in Python: MCRpy, 2022

Figure 2: Schematic overview of the plugin architecture in MCRpy.

of ÀúùëÜ3 and V are empirically set to 1 and 100, respectively2.
Finally, the role of the setting limit_to needs to be discussed.
The parameter is introduced in [25] as ùëÉ and ùëÑ and quantiÔ¨Åes
the length in pixels up to which spatial correlations are com-
puted with the highest-possible precision. All longer-ranged
correlations are computed on a lower-resolution version of the
structure in order to save computational resources, cf. [25].
With a default of 16, it allows a Ô¨Çexible trade-oÔ¨Ä between
accuracy and eÔ¨Éciency. In this example, it is lowered to 8 in
order to accelerate the computations.

After setting all options, the reconstruction can be started
and the results can be viewed from the GUI by selecting
the view-action on the left. 2D microstructures are plotted
directly, whereas 3D structures are exported to and opened
in ParaView [43]. The original 2D slice and the reconstructed
3D volume are shown in Figure 4.

In addition to the Ô¨Ånal microstructure, a convergence data Ô¨Åle
is written, which can be viewed interactively with MCRpy as
shown in Figure 5. On the left, the loss is plotted over iterations
along with blue dots indicating intermediate results. The user
can click on any of these dots to have the corresponding
microstructure displayed on the right. For 3D structures,
only one slice is plotted and the user can scroll through the
microstructure using the mouse wheel. For displaying the raw
phase indicator functions of multiphase structures and other
functionalities, the user is referred to the documentation. In
summary, the MCRpy GUI constitutes an easily accessible
solution for microstructure reconstruction.

4.2 Obtaining a set of similar volume elements

As a second example, a statistically similar set of volume
elements is created from a single microstructure example. In
numerical homogenization, a volume element can only be
called representative if it is large enough for the stochasticity of
the microstructure to have no eÔ¨Äect on the eÔ¨Äective properties.
In practice, this requirement can imply unfeasible computa-
tional eÔ¨Äort. If smaller volume elements are used, it is still
possible to quantify the eÔ¨Äective behavior by using suÔ¨Éciently
many smaller volume elements and statistically aggregating
the results. An example for structure-property linkages based
on this idea can be found in [44]. From an MCR perspective,

2The role of the weights is discussed in [4]. If the weight of the variation
is too small, the noise is not suppressed well enough. If it is too large, the
optimization problem becomes harder to solve and more iterations are needed
for convergence.

this requires characterizing the given structure and reconstruct
diÔ¨Äerent random realizations from it3.

This task is solved using MCRpy as a command line tool as
shown in Listing 1. First, the original 2D microstructure stored
as ms_slice.npy is characterized using the same parameters
as in Section 4.1 (line 1). Then, 9 diÔ¨Äerent 3D structures are
generated by a simple loop over the reconstruction script (lines
2-7). Note that the extent of the reconstructed structures
in voxels is set independently of the original slice (line 5).
Furthermore, the loop index is passed to the reconstruction
script in order to have it added to all result Ô¨Ålenames and
prevent to overwrite previous results (line 5). Because the
chosen descriptors are diÔ¨Äerentiable, the standard optimizer
L-BFGS-B [35] can be used, allowing to harness the computa-
tional eÔ¨Éciency of DMCR [25, 4]. On an Nvidia A100 GPU,
the reconstructions take around 25 minutes per structure for
500 iterations. The original structure and the results can be
seen in Figure 6. In summary, the command line interface
is analogous to the GUI and allows for easy automation and
large-scale application.

4.3 Manipulating the descriptor space

As a third example, the explicit availability of the descriptor
is exploited by directly manipulating it. SpeciÔ¨Åcally, MCRpy is
used to interpolate between two given microstructures in a mor-
phologically meaningful way. Consider two microstructures
that could stem from diÔ¨Äerent sets of process parameters. It
can be interesting to create a morphology that is a mix between
these two structures. For example, if numerical simulations and
homogenization of the interpolated structure predict favorable
eÔ¨Äective properties, it might be worth to Ô¨Åne-tune the process
parameters or try to establish a PSP linkage to manufacture
these structures. Direct interpolation of the microstructures in
terms of pixel values is meaningless. As a simple alternative,
we interpolate linearly in the descriptor space and reconstruct
microstructures from the interpolated descriptors.

This task is solved using MCRpy as a Python library as
shown in Listing 2. After deÔ¨Åning the settings (lines 4-10),

3In [25], the reconstruction was shown to converge to the exact same
microstructure that was used for characterization. The same can be seen for
some cases in Figure 8. However, this only happens in 2D reconstruction (not
in 3D) and only for certain descriptors and microstructures. In these cases, the
desired descriptor prescribed for reconstruction needs to be varied statistically
in order to create a diverse set of microstructure realizations. This aspect is
not considered in the following because in application, it is most useful to
reconstruct 3D structures.

Preprint submitted to Springer
arXiv

6

MCRpycoreDescriptorpluginsCharacterizeReconstruct¬∑¬∑¬∑LoaderFactoryVolumefractionsCorrelations¬∑¬∑¬∑Descriptorsf:M‚ÜíS2loadS2createS2importregisterSeibert et al., Microstructure Characterization and Reconstruction in Python: MCRpy, 2022

Figure 3: Screenshot of the MCRpy graphical user interface. After selection an action on the left, all options can be set set in
the center and performed upon clicking start. The options are identical to the command line interface and the Python library.

for a 3D reconstruction, which returns the convergence data
and the Ô¨Ånal microstructure (line 29). The convergence data
is viewed in an interactive window as shown in Figure 5 (line
31). Finally, the microstructures are smoothed by a Gaussian
Ô¨Ålter (line 32) and saved to a Ô¨Åle (line 33). The results are
shown in Figure 7. It can be conÔ¨Årmed that linear interpolation
in the descriptor space leads to a visually reasonable transition
between the corresponding microstructures.

(a) Original slice

(b) Reconstructed structure

4.4 DeÔ¨Åning a custom descriptor

Figure 4: Results for the example in Section 4.1.

the original 2D microstructure slices are loaded (lines 13-14)
and characterized (lines 17-18). For reconstructing elongated
3D structures, the 2D descriptors need to be combined such
that diÔ¨Äerent descriptors are used in diÔ¨Äerent directions. The
order thereby matters and mistakes can lead to geometrically
unrealizable descriptors4. In order to avoid confusion and
mistakes, MCRpy provides the function merge for this task.
The merged descriptors (lines 21-22) are then interpolated in 5
steps including start and end (line 25). Each descriptor is used

4For example, consider the three planes ùë• ‚àí ùë¶, ùë• ‚àí ùëß and ùë¶ ‚àí ùëß. Structures
that are elongated in ùë•-direction can be created by prescribing horizontally
elongated descriptors in planes 1 and 2 and an isotropic descriptor in plane 3.
However, if the same horizontally elongated descriptors are prescribed in
planes 1 and 3, the structure cannot be realized: Plane 1 requires elongations in
the ùë¶-direction, whereas plane 3 requires the elongations to be in the ùëß-direction
and not in ùë¶.

MCRpy can be easily extended by adding custom plugin
modules. In this section, the procedure is demonstrated by
means of a descriptor plugin. Similar concepts apply to
loss functions and optimizers. First, the implementation of
a descriptor plugin is discussed for the volume fraction ùë£f.
Secondly, a diÔ¨Äerentiable approximation to the lineal path
function is developed and tested.

Listing 3 shows the plugin source code for the volume
fraction ùë£f. Like all descriptors in MCRpy, the volume fraction
must inherit from the abstract Descriptor class (line 5). This
base class provides

(i) a wrapper that applies descriptors deÔ¨Åned for single phases

to the indicator function of each phase,

(ii) a wrapper to compute multigrid descriptors as discussed

in [25] and

(iii) default functions for visualizing descriptors5.

5By default, low-dimensional descriptors are visualized via bar plots and

Preprint submitted to Springer
arXiv

7

Seibert et al., Microstructure Characterization and Reconstruction in Python: MCRpy, 2022

Figure 5: Interactive window for inspecting convergence data. By selecting the highlighted dot on the left at iteration 60, a
slice of the intermediate result is displayed on the right. In this example, the indicator function of phase 1 is displayed for
slice 18 of 64.

Listing 1: Simple bash script for automating reconstruction using the MCRpy command line interface. The results are shown
in Figure 6

1
2
3
4
5
6
7

python characterize.py ms_slice.npy --limit_to 8 --descriptor_types Correlations Variation
for i in {1..9}
do

python reconstruct.py --descriptor_filename results/ms_slice_characterization.pickle \

--extent_x 64 --extent_y 64 --extent_z 64 --limit_to 8 --information ${i} \
--descriptor_types Correlations Variation --descriptor_weights 1 100

done

In this case, it is reasonable to deÔ¨Åne the descriptor for a
single phase and let the superclass handle the generalization
to multiple phases. For this purpose, the subclass function
make_singlephase_descriptor is deÔ¨Åned (line 9). This
function receives information about the microstructure, like
the resolution, which is not needed in this case and therefore
summarized via **kwargs. It returns a callable which com-
putes the descriptor given the indicator function of a phase (line
12). In order to allow for automatic diÔ¨Äerentiation of the de-
scriptor with respect to the microstructure, this callable
needs to be implemented in TensorFlow. In contrast, a non-
diÔ¨Äerentiable descriptor would be implemented in Numpy and
integrated into the computation graph by MCRpy using the
TensorFlow function tf.py_function. Finally, the plugin
is required to register itself at the descriptor factory using its
class name (lines 16-17).

In the following, the same procedure is applied to a diÔ¨Äeren-
tiable approximation Àúùêø to the lineal path function ùêø, which is
developed in Appendix A. Naturally, the code for deÔ¨Åning Àúùêø
is much longer than Listing 3 and is not given in this paper.
Instead, the reader is referred to the GitHub repository for

high-dimensional descriptors are reshaped to an approximately quadratic array
and plotted as a heatmap. This behavior can be overwritten for each descriptor
subclass separately.

viewing the code. After adding the descriptor deÔ¨Ånition to the
mcrpy/descriptors directory, it is accessible for characteri-
zation and reconstruction via the MCRpy GUI, the command
line interface and the Python library.

In the Yeong-Torquato algorithm, the lineal path function is
often employed to compensate for the shortcomings of the two-
point correlation ùëÜ2 alone [23, 2]. As an alternative approach
to enriching ùëÜ2, the diÔ¨Äerentiable three-point correlations ÀúùëÜ3
are used in [25]. Furthermore, Gram matrices ùê∫ have become
a common descriptor recently [30, 31, 4, 32].
In order to
determine a best-practice for gradient-based reconstruction,
ÀúùëÜ3 is compared to ùê∫ and a combination of ÀúùëÜ2 and Àúùêø in
Figure 8. It can be seen that ÀúùëÜ3 yields perfect reconstructions
except for the copolymer, which can only be reconstructed
well from ùê∫. In contrast, ùê∫ yields acceptable results for all
structures. The combination of ÀúùëÜ2 and Àúùêø performs very poorly
for the alloy and the copolymer and is relatively noisy for
the carbonate and ceramics. However, it outperforms ùê∫ for
the polymer composite. In summary, the results in Figure 8
indicate that including higher-order information to ÀúùëÜ2 via ÀúùëÜ3 is
more promising for gradient-based reconstruction than via the
newly proposed diÔ¨Äerentiable approximation to the lineal path
function Àúùêø.

The more relevant aspect, however, is how easily new de-

Preprint submitted to Springer
arXiv

8

Seibert et al., Microstructure Characterization and Reconstruction in Python: MCRpy, 2022

(a) Original 2D structure

(b) Small set of reconstructed 3D volumes

Figure 6: Input and results generated from the code in Listing 1.

Listing 2: Simple Python script that uses MCRpy to characterize two microstructure slices, interpolate between them in the
descriptor space and reconstruct the corresponding 3D structures.

import mcrpy

# define settings
limit_to = 8
descriptor_types = [‚ÄôCorrelations‚Äô, ‚ÄôVariation‚Äô]
descriptor_weights = [1.0, 10.0]
characterization_settings = mcrpy.CharacterizationSettings(descriptor_types=descriptor_types,

limit_to=limit_to)

reconstruction_settings = mcrpy.ReconstructionSettings(descriptor_types=descriptor_types,

descriptor_weights=descriptor_weights, limit_to=limit_to, use_multigrid_reconstruction=True)

# load microstructures
ms_from = mcrpy.load(‚Äômicrostructures/ms_slice_isotropic.npy‚Äô)
ms_to = mcrpy.load(‚Äômicrostructures/ms_slice_elongated.npy‚Äô)

# characterize microstructures
descriptor_isotropic = mcrpy.characterize(ms_from, characterization_settings)
descriptor_elongated = mcrpy.characterize(ms_to, characterization_settings)

# merge descriptors
descriptor_from = mcrpy.merge([descriptor_isotropic])
descriptor_to = mcrpy.merge([descriptor_elongated, descriptor_isotropic])

# interpolate in descriptor space
d_inter = mcrpy.interpolate(descriptor_from, descriptor_to, 5)

# reconstruct from interpolated descriptors and save results
for i, interpolated_descriptor in enumerate(d_inter):

convergence_data, ms = mcrpy.reconstruct(interpolated_descriptor, (128, 128, 128),

settings=reconstruction_settings)

mcrpy.view(convergence_data)
smoothed_ms = mcrpy.smooth(ms)
mcrpy.save_microstructure(f‚Äôms_interpolated_{i}.npy‚Äô, smoothed_ms)

Preprint submitted to Springer
arXiv

9

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33

Seibert et al., Microstructure Characterization and Reconstruction in Python: MCRpy, 2022

(a) Isotropic ÀúùëÜ3 ((cid:174)ùëü, (cid:174)ùëü)

(b) 25%-interpolation

(c) 50%-interpolation

(d) 75%-interpolation

(e) Elongated ÀúùëÜ3 ((cid:174)ùëü, (cid:174)ùëü)

(f) Reconstruction from (a) (g) Reconstruction from

(b)

(h) Reconstruction from
(c)

(i) Reconstruction from (d) (j) Reconstruction from (e)

Figure 7: The original descriptors (a, e) are linearly interpolated (b-d) and used for reconstruction to create a smooth transition
between an isotropic and an elongated microstructure (a-f). For the descriptor ÀúùëÜ3 ((cid:174)ùëüùëé, (cid:174)ùëüùëè), only the case that (cid:174)ùëüùëé = (cid:174)ùëüùëè = (cid:174)ùëü is
plotted for clarity.

scriptors can be assessed using MCRpy. After deÔ¨Åning a plugin
as shown in Listing 3, it can be used for characterization and
reconstruction and evaluated seamlessly. This extensibility fa-
cilitates quick and easy experimentation, allowing researchers
to assess new MCR techniques easily and provide them to their
colleagues.

5 Conclusions and Outlook

MCRpy is a powerful and extensible open-source Python
library and toolkit for microstructure characterization and
reconstruction. Besides these core features, MCRpy provides
a plethora of convenient tools for inspecting and comparing
descriptors, analyzing reconstruction results and controlling the
descriptor space. It be easily applied via a GUI and brought
to automated large-scale application on high-performance
computers through a command line interface. For advanced
and custom operations in the descriptor space, MCRpy can be
imported and used as a Python module with direct access to
the structures and descriptors. Typical workÔ¨Çows for these
interfaces are presented in this work by means of diÔ¨Äerent
MCR tasks.

A central design aspect in MCRpy is its extensibility in that
descriptors, loss functions and optimizers can be provided
by the community as simple plugin modules. An example
for a simple plugin is given in this work. We hope that the
open source nature of the code and the plugin architecture
will make MCRpy an international collaborative project with
contributions from numerous researchers. This growth can
leverage the potential of the presented tool to facilitate faster
and easier MCR research and ultimately help accelerating
materials development.

Acknowledgements

The group of M. K√§stner thanks the German Research
Foundation DFG which supported this work under Grant
number KA 3309/18-1. Furthermore, this work is partially
funded by the European Regional Development Fund (ERDF)
and co-Ô¨Ånanced by tax funds based on the budget approved
by the members of the Saxon State Parliament under Grants
100373334. All presented computations were performed on a
PC-Cluster at the Center for Information Services and High
Performance Computing (ZIH) at TU Dresden. The authors
thus thank the ZIH for generous allocations of computer time.

Code availability

MCRpy is available on the GitHub repository https://

github.com/NEFM-TUDresden/MCRpy.

Competing interests

The authors declare no competing interests.

Author contributions

P. Seibert: Conceptualization, Formal analysis, Investi-
gation, Methodology, Software, Validation, Visualization,
Writing - original draft. A. Ra√üloÔ¨Ä: Conceptualization, Soft-
ware, Writing - review and editing. K. Kalina: Supervision,
Visualization, Writing - review and editing. M. Ambati: Su-
pervision, Writing - review and editing. M. K√§stner: Funding
acquisition, Resources, Supervision, Writing - review and
editing.

Preprint submitted to Springer
arXiv

10

Seibert et al., Microstructure Characterization and Reconstruction in Python: MCRpy, 2022

Listing 3: Simple deÔ¨Ånition of a descriptor plugin for computing the volume fraction ùë£f. This descriptor is diÔ¨Äerentiable
with respect to each pixel in the microstructure, so it is implemented in TensorFlow to allow for automatic diÔ¨Äerentiation.
Non-diÔ¨Äerentiable descriptors can be implemented in Numpy.

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17

import tensorflow as tf
from mcrpy.src import descriptor_factory
from mcrpy.descriptors.Descriptor import Descriptor

class VolumeFractions(Descriptor):

is_differentiable = True

@staticmethod
def make_singlephase_descriptor(**kwargs) -> callable:

@tf.function
def compute_descriptor(indicator_function: tf.Tensor) -> tf.Tensor:

return tf.math.reduce_mean(indicator_function)

return compute_descriptor

def register() -> None:

descriptor_factory.register("VolumeFractions", VolumeFractions)

A DiÔ¨Äerentiable approximation to lineal path

function

The lineal path function ùêø is a well-established microstruc-
ture descriptor [26] that is often used in the Yeong-Torquato
algorithm to compensate for the shortcomings of the two-point
correlation ùëÜ2 alone [23, 2]. Given a vector (cid:174)ùëü = (ùëü ùë•, ùëü ùë¶), it
yields the probability that (cid:174)ùëü lies entirely within a single phase if
it is placed randomly in the structure. In contrast to ùëÜ2, which
considers only the start and end point of the vector, ùêø incorpo-
rates information about the connectedness of the phases. In
this section, Àúùêø is presented as a diÔ¨Äerentiable approximation
to ùêø.

The lineal path function is approximated using a convolve -
threshold - reduce pipeline similarly to [25]. For this purpose,
the vector or line (cid:174)ùëü is discretized to a pixel grid as shown in
Figure 9 and divided by the length of the line. In this work,
the Bresenham line algorithm [45] is used, but alternative
approaches like the Xiaolin Wu line algorithm [46] might be
equally viable options that can be investigated in future works.
In the convolve step, the discretized line from Figure 9 is used
as a mask for a convolution with periodic boundary conditions.
The output of the convolution is an image where each pixel
corresponds to the discretized line being placed at the pixel‚Äôs
location. The pixel value is 0 if no part of the line lies in
phase 1 and 1 if the line lies completely in phase 1. If only
parts of the line are in phase 1, the value is between 0 and 1.
These pixels can be set to zero by thresholding the image with
a value ùë°, where 1/(1 ‚àí ||(cid:174)ùëü ||‚àû) < ùë° < 1. The threshold step thus
yields an image which can be interpreted as an ensemble of
realizations, where each pixel takes the value 0 or 1. In the
reduce step, this ensemble is averaged to obtain the probability
of a randomly placed line being entirely in phase 1.

To make the convolve - threshold - reduce pipeline diÔ¨Äer-
entiable, only the thresholding needs to be modiÔ¨Åed. The
hard thresholding is therefore approximated using a scaled and

Preprint submitted to Springer
arXiv

shifted diÔ¨Äerentiable sigmoid function6 as shown in Figure 10.
This introduces errors, because the ensemble to average does
not contain only ones and zeros but also intermediate values.
Unlike in [25], where a similar error for ÀúùëÜ could be eliminated
by deriving a correction step, the diÔ¨Äerence between ùêø and Àúùêø
can not be quantiÔ¨Åed easily. Thus, it is clear that Àúùêø is only
an approximation to ùêø, not a generalization. This is not prob-
lematic if the same descriptor is used for characterization and
reconstruction.

To the author‚Äôs best knowledge, this concludes the Ô¨Årst

diÔ¨Äerentiable approximation to the lineal path function.

B Underlying technologies

MCRpy is programmed in Python and based on very
common packages like Numpy, Scipy, Matplotlib and
TensorFlow. While simulated annealing is implemented from
scratch, the gradient-based optimizers are taken from Scipy and
TensorFlow. Furthermore, TensorFlow is used for automatic
diÔ¨Äerentiation of the loss function and the descriptors as well
as for just-in-time compilation via AutoGraph. This allows
MCRpy to run highly optimized code on GPUs despite being
written entirely in Python. As optional dependencies, the
Gooey is required to run the MCRpy GUI and pyMKS is used
in a descriptor plugin for FFT-based 2-point correlations. A
summary of required and optional dependencies and their
versions is given in Table 4.

6We use the same function as in [25].

11

Seibert et al., Microstructure Characterization and Reconstruction in Python: MCRpy, 2022

(a) Original alloy

(b) Reconstruction from ÀúùëÜ2, Àúùêø

(c) Reconstruction from ÀúùëÜ3

(d) Reconstruction from ùê∫

(e) Original carbonate

(f) Reconstruction from ÀúùëÜ2, Àúùêø

(g) Reconstruction from ÀúùëÜ3

(h) Reconstruction from ùê∫

(i) Original ceramics

(j) Reconstruction from ÀúùëÜ2, Àúùêø

(k) Reconstruction from ÀúùëÜ3

(l) Reconstruction from ùê∫

(m) Original copolymer

(n) Reconstruction from ÀúùëÜ2, Àúùêø

(o) Reconstruction from ÀúùëÜ3

(p) Reconstruction from ùê∫

(q) Original polymer comp.

(r) Reconstruction from ÀúùëÜ2, Àúùêø

(s) Reconstruction from ÀúùëÜ3

(t) Reconstruction from ùê∫

Figure 8: Comparison between original microstructures and reconstruction results from diÔ¨Äerent descriptors. For a clearer
visualization, the reconstructed microstructures are shifted periodically to match the original structure as closely as possible.

Preprint submitted to Springer
arXiv

12

Seibert et al., Microstructure Characterization and Reconstruction in Python: MCRpy, 2022

Table 4: Software dependencies for the current version of
MCRpy.

Figure 9: A discretization of the vector (cid:174)ùëü to a discrete pixel
grid using Bresenham‚Äôs method [45].

Figure 10: Approximation of a hard threshold by a scaled and
shifted diÔ¨Äerentiable sigmoid function.

References
[1] W. Chen, A.

Iyer, R. Bostanabad, Engineering p.
DOI 10.1016/j.eng.2021.
URL https://linkinghub.elsevier.com/

S209580992200056X (2022).
05.022.
retrieve/pii/S209580992200056X

[2] R. Bostanabad, Y. Zhang, X. Li, T. Kearney, L.C. Brinson, D.W.
Apley, W.K. Liu, W. Chen, Progress in Materials Science 95, 1
(2018). DOI 10.1016/j.pmatsci.2018.01.005

[3] D. Khatamsaz, A. Molkeri, R. Couperthwaite, J. James,
R. Arr√≥yave, A. Srivastava, D. Allaire, Materials &
Design 209, 110001 (2021).
DOI 10.1016/j.matdes.
2021.110001. URL https://linkinghub.elsevier.com/
retrieve/pii/S0264127521005566

[4] P. Seibert, A. Ra√üloÔ¨Ä, M. Ambati, M. K√§stner, Acta
Materialia 227, 117667 (2022). DOI 10.1016/j.actamat.
2022.117667. URL https://linkinghub.elsevier.com/
retrieve/pii/S1359645422000520

[5] H. Liu, B. Yucel, D. Wheeler, B. Ganapathysubramanian, S.R.
Kalidindi, O. Wodo, MRS Communications (2022). DOI 10.
1557/s43579-021-00147-4. URL https://link.springer.
com/10.1557/s43579-021-00147-4

[6] S. Sonnenburg, M.L. Braun, C.S. Ong, S. Bengio, L. Bottou,
G. Holmes, Y. LeCun, Journal of Machine Learning Research
p. 25 (2007)

[7] J.J. de Pablo, B. Jones, C.L. Kovacs, V. Ozolins, A.P. Ramirez,
Current Opinion in Solid State and Materials Science 18(2), 99
(2014). DOI 10.1016/j.cossms.2014.02.003

[8] European center of excellence for novel materials discovery
(NOMAD-CoE) (2021). URL https://nomad-lab.eu/

[9] L.M. Ghiringhelli, C. Carbogno, S. Levchenko, F. Mohamed,
M. L√ºders, M. Oliveira, M. ScheÔ¨Ñer, arXiv:1607.04738 pp.
1‚Äì16 (2016)

package

numpy
yes
matplotlib
yes
scipy
yes
tensorÔ¨Çow yes
pymks
gooey

required

version
‚â• 1.20.1
‚â• 3.3.4
‚â• 1.6.2
‚â• 2.3.1
for FFT-based correlations ‚â• 0.4.1
for GUI

‚â• 1.0.8.1

[10] Computational design and discovery of novel materials (NCCR
MARVEL) (2021). URL https://www.nccr-marvel.ch/

[11] Automated interactive infrastructure and database for computa-
tional science (2021). URL https://www.aiida.net/

[12] G. Pizzi, A. Cepellotti, R. Sabatini, N. Marzari, B. Kozinsky,
Computational Materials Science 111, 218 (2016). DOI 10.
1016/j.commatsci.2015.09.013

[13] S.P. Ong, W.D. Richards, A. Jain, G. Hautier, M. Kocher,
S. Cholia, D. Gunter, V.L. Chevrier, K.A. Persson, G. Ceder,
Computational Materials Science 68, 314 (2013). DOI 10.
1016/j.commatsci.2012.10.028. URL https://linkinghub.
elsevier.com/retrieve/pii/S0927025612006295

[14] Y. Hayashi,

J. Shiomi,

J. Morikawa, R. Yoshida,

arXiv:2203.14090 p. 42 (2022)

[15] D.B. Brough, D. Wheeler, S.R. Kalidindi, Integrating Materials
and Manufacturing Innovation 6(1), 36 (2017). DOI 10.1007/
s40192-017-0089-0

[16] T. Fast, S.R. Kalidindi, Acta Materialia 59(11), 4595
URL

DOI 10.1016/j.actamat.2011.04.005.

(2011).
https://linkinghub.elsevier.com/retrieve/pii/
S1359645411002473

[17] R. Cimrman, Proc. of the 6th Eur. Conf. on Python in Science

(Euroscipy 2013) pp. 69‚Äì69 (2014)

[18] R. Cimrman, V. Luke≈°, E. Rohan, Advances in Compu-
tational Mathematics 45(4), 1897 (2019). DOI 10.1007/
s10444-019-09666-0

[19] F. Roters, M. Diehl, P. Shanthraj, P. Eisenlohr, C. Reuber,
S. Wong, T. Maiti, A. Ebrahimi, T. Hochrainer, H.O. Fabritius,
S. Nikolov, M. Fri√°k, N. Fujita, N. Grilli, K. Janssens, N. Jia,
P. Kok, D. Ma, F. Meier, E. Werner, M. Stricker, D. Weygand,
D. Raabe, Computational Materials Science 158, 420 (2019).
DOI 10.1016/j.commatsci.2018.04.030

[20] S. Keshav, F. Fritzen, M. Kabel, arXiv:2204.13624 [cs, math]
(2022). URL http://arxiv.org/abs/2204.13624

[21] M.A. Groeber, M.A. Jackson, Integrating Materials and
Manufacturing Innovation 3(1), 56 (2014). DOI 10.1186/
2193-9772-3-5

[22] F. Azhari, W. Davids, H. Chen, S.P. Ringer, C. Wallbrink,
Z. Sterjovski, B.R. Crawford, D. Agius, C.H. Wang, G. SchaÔ¨Äer,
Integrating Materials and Manufacturing Innovation (2022).
DOI 10.1007/s40192-022-00257-4. URL https://link.
springer.com/10.1007/s40192-022-00257-4

[23] C.L.Y. Yeong, S. Torquato, Physical Review E 57(1), 495 (1998).

DOI 10.1103/PhysRevE.57.495

Preprint submitted to Springer
arXiv

13

Seibert et al., Microstructure Characterization and Reconstruction in Python: MCRpy, 2022

[24] Y. Jiao, F.H. Stillinger, S. Torquato, Physical Review E 76(3),

[45] Bresenham, IBM Systems Journal 4(1), 25 (1965)

[46] X. Wu, Computer Graphics 25(4) (1991)

031110 (2007). DOI 10.1103/PhysRevE.76.031110

[25] P. Seibert, M. Ambati, A. Ra√üloÔ¨Ä, M. K√§stner, Computational

Materials Science p. 16 (2021)

[26] B. Lu, S. Torquato, Physical Review A 45(2), 922 (1992). DOI

10.1103/PhysRevA.45.922

[27] Y. Jiao, F.H. Stillinger, S. Torquato, Proceedings of the National
Academy of Sciences 106(42), 17634 (2009). DOI 10.1073/
pnas.0905919106

[28] P.E. Chen, W. Xu, N. Chawla, Y. Ren, Y. Jiao, SSRN Electronic

Journal pp. 1‚Äì23 (2019). DOI 10.2139/ssrn.3397269

[29] N. Lubbers, T. Lookman, K. Barros, Phys. Rev. E 96, 052111
(2017). DOI 10.1103/PhysRevE.96.052111. URL https:
//link.aps.org/doi/10.1103/PhysRevE.96.052111

[30] X. Li, Y. Zhang, H. Zhao, C. Burkhart, L.C. Brinson,

W. Chen, ScientiÔ¨Åc Reports 8(1), 13461 (2018). DOI
10.1038/s41598-018-31571-7

[31] R. Bostanabad, Computer-Aided Design 128, 102906 (2020).

DOI 10.1016/j.cad.2020.102906

[32] A. Bhaduri, A. Gupta, A. Olivier, L. Graham-Brady,
arXiv:2102.02407 [cond-mat] (2021). URL http://arxiv.
org/abs/2102.02407

[33] R. Piasecki, A. Plastino, Physica A: Statistical Mechanics and
its Applications 389(3), 397 (2010). DOI 10.1016/j.physa.2009.
10.013

[34] K. Simonyan, A. Zisserman, CoRR abs/1409.1556 (2015)

[35] R.H. Byrd, S.L. Hansen, J. Nocedal, Y. Singer, arXiv:1401.7020
[cs, math, stat] (2015). URL http://arxiv.org/abs/1401.
7020

[36] D. Cule, S. Torquato, Journal of Applied Physics 86(6), 3428

(1999). DOI 10.1063/1.371225

[37] S.G. Nash, SIAM Journal on Numerical Analysis 21(4), 770
(1984). DOI 10.1137/0721052. URL http://epubs.siam.
org/doi/10.1137/0721052

[38] D.P. Kingma, J. Ba, arXiv:1412.6980 [cs] pp. 1‚Äì15 (2017)

[39] J. Duchi, E. Hazan, Y. Singer, Journal of Machine Learning

Research p. 39 (2011)

[40] M.D. Zeiler, arXiv:1212.5701 [cs] (2012). URL http://

arxiv.org/abs/1212.5701

[41] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean,
M. Devin, S. Ghemawat, G. Irving, M. Isard, M. Kudlur,
J. Levenberg, R. Monga, S. Moore, D.G. Murray, B. Steiner,
P. Tucker, V. Vasudevan, P. Warden, M. Wicke, Y. Yu, X. Zheng,
in Proceedings of the 12th USENIX Conference on Operating
Systems Design and Implementation (USENIX Association,
USA, 2016), OSDI‚Äô16, p. 265‚Äì283

[42] A. Cecen, B. Yucel, S.R. Kalidindi, Journal of Composites
Science 5(8), 211 (2021). DOI 10.3390/jcs5080211. URL
https://www.mdpi.com/2504-477X/5/8/211

[43] J. Ahrens, B. Geveci, C. Law, The visualization handbook

717(8) (2005)

[44] A. Ra√üloÔ¨Ä, P. Schulz, R. K√ºhne, M. Ambati, I. Koch,
A.T. Zeuner, M. Gude, M. Zimmermann, M. K√§st-
ner, GAMM-Mitteilungen (2021). DOI 10.1002/gamm.
202100012. URL https://onlinelibrary.wiley.com/
doi/10.1002/gamm.202100012

Preprint submitted to Springer
arXiv

14

