Addressing Census data problems in race imputation

via fully Bayesian Improved Surname Geocoding
and name supplements∗

Kosuke Imai†

Santiago Olivella‡

Evan Rosenman§

September 2, 2022

Abstract

Prediction of individual’s race and ethnicity plays an important role in social science and

public health research. Examples include studies of racial disparity in health and voting. Recently,

Bayesian Improved Surname Geocoding (BISG), which uses Bayes’ rule to combine information
from Census surname ﬁles with the geocoding of an individual’s residence, has emerged as a

leading methodology for this prediction task. Unfortunately, BISG suﬀers from two Census

data problems that contribute to unsatisfactory predictive performance for minorities. First,

the decennial Census often contains zero counts for minority racial groups in the Census blocks

where some members of those groups reside. Second, because the Census surname ﬁles only

include frequent names, many surnames – especially those of minorities – are missing from the

list. To address the zero counts problem, we introduce a fully Bayesian Improved Surname

Geocoding (fBISG) methodology that accounts for potential measurement error in Census counts

by extending the na¨ıve Bayesian inference of the BISG methodology to full posterior inference. To

address the missing surname problem, we supplement the Census surname data with additional

data on last, ﬁrst, and middle names taken from the voter ﬁles of six Southern states where

self-reported race is available. Our empirical validation shows that the fBISG methodology and

name supplements signiﬁcantly improve the accuracy of race imputation across all racial groups,

and especially for Asians. The proposed methodology, together with additional name data, is
available via the open-source software package wru.

Keywords: BISG, ecological inference, measurement error, racial disparity, voter ﬁles

2
2
0
2

g
u
A
1
3

]
L
M

.
t
a
t
s
[

3
v
9
2
1
6
0
.
5
0
2
2
:
v
i
X
r
a

∗We thank Bruce Willsie of L2, Inc.

for his generosity in letting us make publicly available additional data on

names and race.

†Professor, Department of Government and Department of Statistics, Harvard University.

1737 Cambridge

Street,

Institute for Quantitative Social Science, Cambridge MA 02138.

Email:

imai@harvard.edu URL:

https://imai.fas.harvard.edu

‡Associate Professor, Department of Political Science, University of North Carolina at Chapel Hill.
§Postdoc, Harvard Data Science Initiative, Harvard University.

 
 
 
 
 
 
1 Introduction

Social scientists and public health researchers often must predict individual race and ethnicity when

assessing disparities in policy and health outcomes. The Bayesian Improved Surname Geocoding

(BISG), which uses Bayes’ rule to combine information from the Census surname list with the

geocoding of individual residence, has emerged as a leading methodology for this prediction task

(Elliott et al., 2008, 2009; Fiscella and Fremont, 2006; Imai and Khanna, 2016). Recent applications

of the BISG methodology include studies on racial disparity in police violence (Edwards, Lee and

Esposito, 2019), eviction (Hepburn, Louis and Desmond, 2020), suicide (Studdert et al., 2020), and

turnout (Fraga, 2018).

In this paper, we address two Census data problems that hinder accurate prediction of individual

race and ethnicity when using the BISG. First, the decennial Census often contains zero counts for

minority groups in the Census blocks where some members of those groups reside. This may happen

for several reasons. Some individuals may have moved after the decennial Census. There may also

be under-counts. Another possibility is that the Census may inject measurement error for privacy

protection (see Kenny et al., 2021, and references therein).

Second, the decennial Census surname ﬁles only include the racial composition of surnames that

occur 100 or more times in the population. According to the Census Bureau, these names account for

about 90 percent of people with surnames recorded in the 2010 Census (Comenetz, 2016). This means

that no racial breakdown statistic is available for the remaining 10 percent. This lack of information

may disproportionately aﬀect minority groups if their surnames are less frequently occurring than

those of the majority group.

Using data from six Southern states in which individual race of voters is available for validation,

we show how these problems can result in a deterioration of predictive quality for the standard BISG

approach (Section 2). To address these problems, we introduce a fully Bayesian generalization of

the BISG approach and extend the coverage of available name-race tables (Section 3).

Our empirical validation study demonstrates that these proposed solutions yield substantial im-

provements in predictive accuracy — particularly among racial minorities (Section 4). Speciﬁcally,

a model that incorporates all our proposed improvements increases classiﬁcation accuracy by an

average of about 14% among all ﬁve major racial groups (vis-`a-vis the standard BISG), with im-

provements as high as 26% among Asian voters. Moreover, these gains in predictive accuracy do

not come at the expense of the calibration of predicted probabilities across racial groups, which

is particularly high for predictions made by the standard BISG methodology for White and Black

voters. Finally, we conclude with a brief discussion about the applicability of our proposed modeling

approach to various domains.

2 The Census Data Problems in Race Imputation

In this section, we ﬁrst brieﬂy review the standard BISG methodology. We then describe the census

data problems and quantify the degree to which they negatively aﬀect the predictive performance of

1

BISG.

2.1 Bayesian Improved Surname Geocoding (BISG): A Review

The goal of BISG is to predict the race of individual i, deﬁned as Ri ∈ R where |R| = J is the total
number of (mutually exclusive) racial categories. In this manuscript, we will have J = 5, with the

categories R = {“White,” “Black,” “Hispanic,” “Asian,” “Other”}.

Suppose we observe the individual’s surname Si ∈ S = {1, 2, . . . , K} and geolocation Gi ∈ G =
{1, 2, . . . , L} where the latter is typically recorded as a Census geographical unit (e.g., Census block),

in which his or her residence is located. The BISG methodology is an application of na¨ıve Bayes

prediction, where the key assumption is given by the following conditional independence relation

between geolocation and surname, given race.

Assumption 1 (Independence between Surname and Geolocation within Racial Group)

Gi ⊥⊥ Si | Ri

Under Assumption 1, the BISG prediction of an individual’s race is given by,

P (Ri | Si, Gi) ∝ P (Si | Ri, Gi)P (Ri | Gi) = P (Si | Ri)P (Ri | Gi).

(1)

One may also use the following equivalent formula obtained via another application of Bayes’ rule:

P (Ri | Si, Gi) ∝ P (Ri | Si)P (Gi | Ri)

In practice, the decennial Census surname ﬁles are used to compute P (Si | Ri), whereas for P (Ri | Gi)
it is common to use the Census Bureau’s cross-tabulations of racial category by geographic location

(e.g. Census blocks).

Although we do not address the appropriateness of Assumption 1 in this paper, it is important

to acknowledge its limitation. The assumption is violated if, for example, among Asian Americans,

various ethnic groups (Chinese, Indians, Japanese, Korean, Vietnamese, etc.) have distinct surnames

and tend to live in diﬀerent areas. A similar problem might also arise among Hispanic Americans.

The surname “Santos,” for instance, may be common among Hispanics in some areas, but it may

also be a common last name among Brazilian Americans (who are classiﬁed as non-Hispanic whites

according to the Census) in other areas.

We now turn to two Census data problems that negatively aﬀect the predictive performance of

BISG.

2.2 Consequences of Zero Census Counts

The decennial census is intended to provide a full accounting of where each resident of the United

States lives as of April 1 on the census year. Reported census distributions are considered reasonably

reliable as of this date, though still imperfect (see e.g. Kenny et al., 2021). Over time, however, this

accuracy degrades even further, as individuals move within the nation’s borders at signiﬁcant rates

(Basso and Peri, 2020). At ﬁne levels of resolution, such as Census blocks, this means that the racial

2

Census Tally

White

Black

Hispanic

Asian

Other

Zero counts
Non-zero counts

0.12 (1%)
22.13 (99%)

0.32 (4%)
7.55 (96%)

0.16 (5%)
2.84 (95%)

0.13 (20%)
0.51 (80%)

0.22 (30%)
0.51 (70%)

Table 1: Count of individuals of each race in millions, for whom the 2010 Census states that there
are zero (top row) or more than zero (bottom row) members of that racial group living within the
individual’s home census block. Data is sourced from voter ﬁles from AL, FL, GA, LA, NC, and SC
and racial data is self-reported on the ﬁle.

distributions may not fully capture the diversity of residents within a short time after the census

is conducted. Among rapidly growing minority groups, such as Asian Americans and Hispanic

Americans, errors may be particularly large.

Prior studies have shown that the use of the Census block level data, rather than the data at a

higher level of geographical aggregation, tend to yield more accurate BISG prediction of individual

race and ethnicity (e.g., Imai and Khanna, 2016). This, however, can result in a greater chance

of measurement error. In particular, when Census counts are used to obtain the prior distribution

P (Ri | Gi) at the Census block level, some blocks may record zero individuals of certain ethnic and
racial categories. In such cases, P (Ri | Gi) would be set to zero, making the posterior probability
of belonging to these groups automatically zero for all individuals who reside in these blocks. For

example, someone with the last name “Guti´errez” — a distinctively Hispanic last name — living

in a neighborhood where the Census failed to count anyone of Hispanic descent would have a zero

posterior probability of being classiﬁed as such according to the standard BISG methodology.

Thus, the predictive accuracy of the BISG methodology can suﬀer dramatically when probabilities

are zeroed-out a priori. To quantify this error, we consider the voter ﬁles of six Southern states —

Alabama, Florida, Georgia, Louisiana, North Carolina, and South Carolina — sourced between

October 2020 and February 2021 (prior to the release of 2020 census data). The voter ﬁles were

provided by L2, Inc., a leading national non-partisan ﬁrm and the oldest organization in the United

States that supplies voter data and related technology to candidates, political parties, pollsters, and

consultants for use in campaigns. These ﬁles tally all registered voters (approximately 37.8 million

voters) in the state as of the production date, geocoding the Census blocks of their home addresses.

About 91% of these voters provided self-reported race data.

Table 1 shows the counts of voters (in millions) by self-reported race, further divided by whether

the 2010 Census indicates that exactly zero members of the individual’s racial group live within their

home block. Due to internal mobility and other forms of measurement error, just shy of one million

voters (2.8%) live in a Census block where the 2010 Census tallies indicate that no members of the

individual’s racial group reside. Notably, these errors are not shared evenly across races. While fewer

than 1% of White voters live in a Census block in which the Census data says no White individuals

reside, a full ﬁfth of Asian voters live in Census blocks in which the 2010 Census says there are no

Asian residents. Even these aggregates mask substantial heterogeneity by state. In South Carolina,

for example, 19% of Hispanic voters and 31% of Asian voters reside in zero-Hispanic and zero-Asian

3

Census Tally

White Black Hispanic Asian Other

Zero counts
Non-zero counts
Overall

50.0% 50.0%
89.2% 92.4%
89.8% 91.7%

50.0%
94.9%
91.9%

50.0% 50.0%
91.4% 58.9%
82.2% 59.0%

Table 2: Area under the receiver operating characteristic curve (AUROC) for BISG predictions of
individual race, using Census blocks to set racial prior distributions. Overall AUROC values (third
row) are lower for all non-white racial groups than are AUROC values for individuals living in blocks
for which the racial prior for those groups is nonzero.

blocks, according to the 2010 Census.

This mismatch presents a signiﬁcant challenge for the BISG methodology. A na¨ıve application

of BISG would yield a prediction of 0% for the true racial group of all individuals in the ﬁrst row of

Table 1 — comprising a relatively large proportion of all minority voters in the South — simply as a

mechanical result the Census reporting no members of these racial groups living in the corresponding

geographies.

The impact on BISG prediction is summarized in Table 2, where we split out the data as in

Table 1 and compute the area under the receiver operating characteristic (AUROC) curve for the

BISG predictions on each subgroup. The AUROC measures the probability that a randomly chosen

member of each racial group will have a higher predicted probability of belonging to that racial

group than a randomly chosen non-member. Accordingly, higher values of the AUCROC indicate

better classiﬁcation accuracy. The ﬁrst row of entries are all equal to 50.0% — a direct consequence

of the fact that the true positive rates must be zero for each racial group in any block for which

the Census prior is zero. In Census blocks for which the prior on the racial group is nonzero, the

AUROC is above 90% for Black, Hispanic, and Asian voters, indicating good predictive accuracy.

As a result, aggregate performance across all Census blocks (the third row) tends to be poorer for

most racial groups (with the exception of White and Other voters), owing to the poor prediction on

Census blocks for which the prior is erroneously set to zero.

We can also compute misclassiﬁcation rates for each racial group, by assigning each individual

to the the maximum a posteriori class and comparing against their true, self-reported race. These

results can be found in Table A1 in the Appendix, where we report both overall error and false

positive and false negative rates by racial group. All individuals living in Census blocks for whom

the prior equals zero for their true race are misclassiﬁed, driving the overall error rate up from 14.5%

to 16.9%.

These results suggest that individual race prediction can be improved by addressing the possibility

that block-level racial priors may be inaccurate or out of date, especially if they are equal to zero.

2.3 Consequences of Missing Race-Name Data

A second plausible source of error arises from the use of surname data. In most applications of the

BISG methodology, surname racial distributions are drawn from the Census Bureau’s surname list.

4

Name Match? White

Black

Hispanic

Asian

Other

No
Yes

1.47 (7%)
20.79 (93%)

0.27 (3%)
7.61 (97%)

0.13 (4%)
2.88 (96%)

0.09 (14%)
0.55 (86%)

0.08 (10%)
0.66 (90%)

Table 3: Count of individuals (in millions) of each race for whom the individual’s surname cannot
be matched to a name in the Census surname dictionary or Hispanic surname ﬁle. Data is sourced
from voter ﬁles from AL, FL, GA, LA, NC, and SC and racial data is self-reported on the ﬁle.

Name Match? White Black Hispanic Asian Other

No
Yes
Overall

79.4% 85.5%
90.3% 91.8%
89.8% 91.7%

78.1%
92.2%
91.9%

71.3% 55.9%
82.3% 59.1%
82.2% 59.0%

Table 4: Area under the receiver operating characteristic curve (AUROC) for BISG predictions
of individual race, using Census blocks to set racial prior distributions. Predictive performance
among individuals whose last names cannot be matched to the WRU name dictionary (ﬁrst row) is
signiﬁcantly worse than among individuals for whom a match is found (second row).

The 2010 Census surname list, for example, provides the racial distribution of surnames appearing at

least 100 times, which amounts to a total of about 160,000 names. These data are supplemented with

the Census’s Spanish surname list, a list of about 12,000 common Hispanic surnames, approximately

half of which are not in the Census surname list.

While these data are quite broad, they do not account for the possibility of rare surnames. In

our sample of Southern states as of late 2020 and early 2021, we ﬁnd that about 2 million voters

(5.9%) have surnames that cannot be matched to the census name dictionary, even after the data

are cleaned and stripped of punctuation to improve the chance of a match. The distribution of this

mismatch across racial groups is given in Table 3. Although Asian voters are particularly unlikely to

have their surnames matched (14%), the same is true for a signiﬁcant portion of White voters (7%).

In the absence of a surname match, the default behavior of a common implementation of BISG

(viz. the software package WRU (Khanna et al., 2021)) is to use the approximate 2010 national race
proportions as an estimate for P (Ri | Si). This approximation yields a degradation in predictive
performance among these records, as seen in Table 4. The AUROC is signiﬁcantly lower among

individuals without a name match than among those whose surnames are found in the dictionary,

and the discrepancy is more than ten percentage points for White, Hispanic, and Asian voters.

As in the prior section, we compute misclassiﬁcation rates for each racial group. These results can

be found in Table A2 in the Appendix. The results are somewhat less dramatic in this case, because

the default behavior in the absence of a name match does not automatically yield a misclassiﬁcation.

Nonetheless, we can see that misclassiﬁcations occur for less than one sixth of individuals whose

names are matched, but nearly a quarter of individuals whose names are unmatched, increasing the

overall error rate.

Once again, a data limitation yields a reduction in the predictive performance of the BISG

5

methodology. Accordingly, better name coverage would improve the quality of our predictions. In

what follows, we lay out our proposed solutions to these common data quality issues, and show

how correcting for them can substantially improve the prediction accuracy of BISG. In addition, we

further extend the common BISG approach to incorporate ﬁrst and middle names — information

that is typically readily available from voter ﬁles, and which can further improve BISG’s accuracy.

3 The Proposed Solutions

In this section, we propose solutions to the measurement error problems described above. We begin

by introducing a measurement error model designed to address potential for error in census tallies.

Our model generalizes the na¨ıve Bayes BISG methodology to a fully Bayesian model. We complete

our approach by discussing our name augmentation strategy, designed to correct for lack of coverage

in commonly used name-by-race dictionaries.

3.1 Accounting for the Measurement Error in Census Counts

We use a fully Bayesian modeling strategy to account for potential measurement error that arises

when quantifying the racial distribution within each geography. We begin by modeling the ob-

served Census counts as a draw from a Multinomial distribution with the true, but unknown, race

proportions in geolocation g, denoted by ζg = (ζ1g, ζ2g, . . . , ζJg),

Ng

indep.

∼ Multinom(Ng, ζg)

(2)

where Ng = (N1g, N2g, . . . , NJg) is the J-dimensional vector of Census counts for individuals who
belong to diﬀerent racial groups and live in geolocation g, and Ng = (cid:80)
r∈R Nrg is the observed total
Census population count in geolocation g.

Next, we place the following conjugate prior distribution over the unknown race distribution for

the geolocation g,

ζg

indep.

∼ Dirichlet(α)

(3)

where α = (α1, α2, . . . , αJ ) is the J-dimensional vector of prior hyperparameters. In our implemen-
tation, we deﬁne a uniform prior distribution with α = 1. This provides enough smoothing over

observed zero counts, without preferring a particular ethnic and racial group over another.

We call this measurement error model the fully-Bayesian BISG (fBISG). Letting P (Si | Ri =

r) = πr, the full posterior distribution of the fBISG is given by,

P ({Ri}n

i=1, {ζg}g∈G | S, G, {πr}r∈R, α)

∝

=

n
(cid:89)

(cid:89)

(cid:89)

(cid:40)(cid:32)

(cid:89)

(cid:33)

(cid:41)1{Ri=r}

π1{Si=s}
sr

ζ 1{Gi=g}
rg

i=1
(cid:89)

r∈R
(cid:89)

g∈G
πmsr
sr ×

s∈S
(cid:89)

(cid:89)

ζ nrg+Nrg+αr−1
rg

s∈S

r∈R

r∈R

g∈G

(cid:89)

(cid:89)

×

ζ Nrg+αr−1
rg

r∈R

g∈G

(4)

where nrg = (cid:80)n
r and live in geographical unit g, and msr = (cid:80)n
the voter ﬁle who belong to race r and have surname s.

i=1 1{Ri = r, Gi = g} is the number of individuals on the voter ﬁle who belong to race
i=1 1{Si = s, Ri = r} is the number of individuals in

6

To simplify computation, we integrate out ζg, obtaining the following marginalized posterior

distribution,

P ({Ri}n

i=1 | {πr}r∈R, S, G, α) ∝




(cid:89)

(cid:89)

r∈R



s∈S

πmsr
sr

(cid:89)

g∈G

Γ(nrg + Nrg + αr)






.

(5)

To sample from this joint posterior, we construct a Gibbs sampler. Using the fact that Γ(x+y) =
xyΓ(x) for y ∈ {0, 1}, we can derive the following conditional posterior distribution for Ri given the
race of the other individuals,

Pr(Ri = r | R−i, Si = s, Gi = g, G−i, α) ∝ πsr(n−i

rg + Nrg + αr)

(6)

rg = (cid:80)

where n−i
i(cid:48)(cid:54)=i 1{Ri(cid:48) = r, Gi(cid:48) = g} is the only parameter that needs to be updated throughout the
sampling process. After the corresponding Markov chain has converged to its stationary distribution,

the posterior prediction for Ri can now be based on the posterior approximated by iteratively
sampling from the full set of conditional distributions in Equation (6).

The comparison of Equation (6) with Equation (1) shows how the fBISG addresses the problems

| Gi) in the
caused by zero census counts. Notice that the race-geolocation probability Pr(Ri
BISG prediction formula, which is given by Nrg/ (cid:80)
rg + Nrg +
αr)/ (cid:80)
r(cid:48)g + Nr(cid:48)g + αr(cid:48)) in the fBISG formula. Thus, in the BISG methodology, if Nrg = 0,
the posterior prediction for this racial group r in the geolocation g is zero. In contrast, the fBISG

r(cid:48)g Nr(cid:48)g, is replaced with the ratio (n−i

r(cid:48)(n−i

methodology gives non-zero probability of belonging to the racial group with zero Census counts by

adding a prior and partially pooling other individuals who live in the same geolocation.

3.2 Increasing Surname Coverage, and Incorporating First and Middle Names

In addition to the surname, we may also have ﬁrst and middle names of each individual whose racial

group we wish to predict. Let Fi ∈ F = {1, 2, . . . , KF } and Mi ∈ M = {1, 2, . . . , KM } denote the
ﬁrst and middle names of individual i, respectively. Using the same voter ﬁle data from L2, Inc., we

construct the racial composition of each ﬁrst name and that of each middle name. This allows us to

further approximate the joint distributions P (Ri, Fi) and P (Ri, Mi).

Voicu (2018) shows that incorporating the ﬁrst name can improve the performance of the BISG.

The author makes the assumption, similar to Assumption 1, that the ﬁrst name is independent of

geolocation conditional on race. In addition, it is assumed that the ﬁrst name is independent of the

surname given race. If we make the same assumption about middle names, the prediction formula

becomes,

P (Ri | Fi, Mi, Si, Gi) ∝ P (Fi | Ri)P (Mi | Ri)P (Si | Ri)P (Ri | Gi).

Combining this information with our fully-Bayesian model for smoothing over zero census counts

results in the following updated full conditional distribution over individual i’s race:

Pr(Ri = r | R−i, Fi = f, Mi = m, Si = s, Gi = g, G−i, α) ∝ πF

f rπM

mrπS

sr(n−i

rg + Nrg + αr)

(7)

where πF

f r = P (Fi = f | Ri = r), and similarly with πM

mr and πS
sr.

7

Figure 1: Percentage of individuals in each racial group who cannot be matched to any name
dictionary, under four diﬀerent matching schemes: matching to census last names only; matching to
census and L2 last names; matching last names and ﬁrst names; and matching last, ﬁrst, and middle
names. Data is drawn from the voter ﬁles of Alabama, Florida, Georgia, Louisiana, North Carolina,
and South Carolina.

We next demonstrate the empirical beneﬁt of incorporating voter ﬁle data surname racial distri-

butions, as well as those of ﬁrst and middle names. Using the same set of voter ﬁles from L2, Inc.,

we consider matching individuals to name dictionaries under several schemes. First, we consider sur-

names exclusively, and compute the proportion of individuals from each racial group who do not have

a surname matched to the Census dictionaries (as in Table 3). Next, we compute the proportion of

individuals of each race who do not have a surname matched to the Census dictionaries, augmented

with data from the L2 voter ﬁles themselves. Third, we compute the proportion of individuals of

each race who do not have a surname matched to the augmented surname dictionary or a ﬁrst name

matched to the separate ﬁrst name dictionary compiled from the L2 data. Lastly, we compute the

proportion of individuals of each race who do not have a name matched to any of the augmented

surname dictionary or to ﬁrst and middle name dictionaries compiled from the L2 data.

Because the voter ﬁle data is used both to compile the dictionaries and to assess coverage, we

iteratively hold out each of the six states (Alabama, Florida, Georgia, Louisiana, North Carolina,

and South Carolina), and consider coverage using a dictionary compiled from the other ﬁve states.

The results in Figure 1 show that dictionary augmentation — and inclusion of additional names —

substantially decreases the proportion of individuals who cannot be matched to any dictionary. For

non-Asian voters, all but a negligible fraction of voters can be matched to at least one dictionary

once all their names are included. Among Asians, approximately one percent of voters still cannot be

matched when using ﬁrst, middle, and last names. This, however, represents a dramatic improvement

relative to the case of exclusively using surnames, and sourcing data only from the Census.

8

6.62.980.040.023.431.40.190.114.323.050.110.0714.069.011.621.0910.813.070.060.03051015WhiteBlackHispanicAsianOtherRace/EthnicityPercentage with No Matching NameNames Used to MatchLast (Census)Last (Census + L2)Last + FirstLast, First, Middle4 Empirical Validation

To empirically validate our proposed improvements, we ﬁt both the standard BISG and our fBISG

to the combined voter ﬁles from AL, FL, GA, LA, NC, and SC, from L2, Inc. As discussed in

Section 2, this combined data set contains information for roughly 38 million voters.

4.1 The Setup

In our validation, we treat the self-reported race of each record as unobserved, and use the remaining

available information for that record to obtain posterior probability distributions over their race.

Speciﬁcally, we use the last, ﬁrst, and middle names of each voter, as well as the Census block in

which their reported home address is located. We then compare predictions based on these posterior

distributions to the known racial categories of each record in order to evaluate the overall quality of

our fBISG predictions vis-`a-vis those of the standard BISG methodology.

To obtain samples from the fBISG posterior distribution over races for each voter in our combined

voter ﬁle, we rely on the latest version of the wru package in R (Khanna et al., 2021). We initialize

the global counts in the Gibbs updates of Equation (6) using the predictions based on the standard

BISG methodology, and run a single Markov chain for 1,500 iterations, discarding the ﬁrst 500

samples as burn-in. Note that the conditional posterior in Equation (6) factorizes over locations g,

which allows us to ﬁt the model separately across any level of geographic aggregation deﬁned on G.

In our application, we ﬁt models separately by state through the same leave-one-out approach we

used when assessing the impact of dictionary coverage (see Section 3.2). For instance, in sampling

the race probabilities of voters in North Carolina, we only use the name-given-race distributions

derived from augmenting the original Census dictionary with records from all other states. This

ensures that the name-given-race distributions are not obtained from the validation voter ﬁle. While

the size of each voter ﬁle in our sample did not require parallelization to make computation feasible,

factorization over g allows researchers to parallelize their analyses in order to ﬁt our model eﬃciently

on much larger data ﬁles. We completed all analyses on a laptop computer with an M1 Max CPU

and 64Gb of RAM in under 3 hours of wall time.

4.2 Correcting the Zero Census Counts Problem

Figure 2 shows, for each racial category, the area under the receiver operating characteristic curve

(AUROC) based on posterior predictions generated by the standard BISG (light grey) and fBISG

(dark grey) methods. For all but the “Other” racial category, the predictive performance of the

fBISG methodology represents a substantial improvement over that of the standard BISG. These

performance gains are most dramatic for Hispanic and Asian racial groups — with the latter yielding

an 11% increase (from 0.82 using the BISG to 0.91 using the fBISG). In general, the use of fBISG

eﬀectively eliminates the performance gap observed between major racial categories when using

BISG, which disproportionately aﬀected members of the Asian category.

The source of these improvements in classiﬁcation accuracy varies by racial category, as indicated

by changes in False Positive and False Negative error rates (see column “Last name (census)” of

9

Figure 2: Area under the receiver operating characteristic curve for race predictions obtained us-
ing the standard BISG methodology (dotted) and our fully Bayesian BISG methodology (fBISG;
stripped). All results are based on the 2010 Census surname dictionary. A greater value of AUROC
indicates more accurate race classiﬁcation. For all but the “Other” category, the fBISG methodol-
ogy has better classiﬁcation performance than the standard BISG methodology, generating the most
dramatic improvements among Asian minorities.

Figure 3: Calibration curves for race predictions obtained using the standard BISG (dotted) and
fBISG (dashed) methods. The results are based on the 2010 Census surname dictionary. Curves
closer to the 45°line indicate better calibrated predictions.

Table A3 in the Appendix). Among White voters, fBISG substantially reduces the false positive

rate from 31% to 24%, while keeping the false negative rate below 10%. Among Black voters, the

improvement comes primarily from reducing false negatives, bringing type II error down to about

24% from the 36% achieved by BISG.

In turn, while error reduction among Hispanics is small, accounting for the zeroes in the Census

counts substantially aﬀects the accuracy of classiﬁcation among Asian voters. For the latter, fBISG

reduces both the false negative rate (from 47% to 41%) and the false positive rate (from 0.78% to

0.48%) relative to the standard BISG model. Given the large percentage (20%) of Asian voters living

in a block for which the 2010 Census tallies register zero Asians, the improvement induced by fBISG

is unsurprising.

In addition to improving prediction accuracy, fBISG generally improves the calibration of pre-

10

0.90.920.920.820.590.910.940.960.910.570.60.70.80.91.0WhiteBlackHispanicAsianOtherRace/EthnicityAUCROCModelBISGfBISGWhiteBlackHispanicAsianOther0.00.20.40.60.81.00.00.20.40.60.81.00.00.20.40.60.81.00.00.20.40.60.81.00.00.20.40.60.81.00.00.20.40.60.81.0PredictedObservedModelBISGfBISGdicted probabilities, as shown in Figure 3. The ﬁgure shows predicted probabilities vs. observed

sample proportions of voters in each racial category, for both BISG (light gray) and fBISG (dark
gray) methods. The closer the curves lie to the 45°line, the better calibrated the corresponding
method’s predictions. This is because well-calibrated methods generate predicted probabilities that

match observed sample proportions of positive cases. The ﬁgure shows that fBISG can produce bet-

ter calibrated predictions than the standard BISG methodology for voters in most racial categories,

producing well calibrated predictions even among “White” voters — the only category in which

calibration becomes slightly worse when making predictions based on fBISG rather than on BISG.

In sum, correcting the zero-count measurement error issues can yield substantial improvements in

race predictive accuracy across all major racial categories.

4.3 Correcting the Missing Race-Name Data Problem

Correcting for name under-coverage, and adding additional name information, also result in sub-

stantial improvements in predictive accuracy. Figure 4 shows the overall improvement in predictive

accuracy that results from using additional name-race data from the L2 voter ﬁles, for both BISG

(light bars) and fBISG (dark bars). While these results aggregate across voter ﬁles, recall that we

mitigate over-ﬁtting by sampling each state separately, leaving names from that state out of the

augmented dictionaries. Figure A1 in the Appendix presents the results separately for each state.

Consistent with prior ﬁndings (e.g. Voicu, 2018), we ﬁnd that using ﬁrst and middle name

information typically improves the predictive performance of models. Moving from top to bottom,

panels in Figure 4 show the steady improvement in model performance as the predictions rely on

an increasing amount of name information (i.e., surnames only, surnames and ﬁrst names, and

surnames, ﬁrst names, and middle names together). While both BISG and fBISG beneﬁt from

the progressively larger name-sets being used in the prediction, fBISG is able to make the most

of the additional information. This is especially true among White voters, for whom accuracy can

be improved by as much as 4.4% (from and AUROC of 0.91 to 0.95 using fBISG for generating

predictions).

Once all our proposed solutions are implemented, improvements in predictive accuracy over the

standard BISG methodology are substantial. Across major racial categories, the average increase

in AUROC is about 7%, with improvements among Asian voters being as large as 15% (from 0.82

using the standard, surname-only BISG to 0.94 using all our proposed solutions). Using our fully

speciﬁed model renders predictive quality across major racial categories eﬀectively uniform, bringing

probabilities of a correct classiﬁcation over 0.95 for all major racial groups.

These gains in accuracy come primarily from substantial reductions in the number of false neg-

atives among all but White voters, as can be seen by comparing the gray boxes within each error

block across columns 4 and 7 of Table A3 in the Appendix. For non-White voters, type II error

is reduced, on average, by 18 percentage points once all our solutions are implemented. These im-

provements come primarily from correcting false positives attributed to the White category, where

we see a corresponding type I error rate reduction of almost 16 percentage points.

11

Figure 4: Area under the receiver operating characteristic curve (AUROC) for race predictions
obtained using the standard BISG (light grey) and fBISG (dark grey) methods. The results are
based on progressively more name information, starting with the L2-augmented surname dictionary
(top panel). As before, higher values indicate better predictive accuracy. Overall, using more name
information uniformly improves the accuracy of models, and using fBISG combined with more name
information produces the most accurate models.

Augmenting name dictionaries can also improve calibration, although gains are more modest on

this front. Figure 5 presents the calibration curves for the BISG (light gray) and fBISG (dark gray)

models, now estimated using augmented name dictionaries. Comparing the ﬁrst row of this ﬁgure to

the panels in Figure 3, we ﬁnd that using the expanded surname set can improve name calibration

— particularly among White and Black voters, for whom calibration is exceptionally high — and

reduce the observed diﬀerences between BISG and fBISG approaches.

Moreover, gains in accuracy from adding information on ﬁrst and middle names are not made at

the expense of calibration, with calibration curves that are eﬀectively the same across most rows of

12

0.90.920.920.820.590.910.940.960.910.580.910.930.920.830.60.940.960.970.930.610.910.930.910.830.60.950.960.980.940.62Last nameLast and first namesLast, first, and middle namesWhiteBlackHispanicAsianOther0.60.70.80.91.00.60.70.80.91.00.60.70.80.91.0Race/EthnicityAUCROCModelBISGfBISGFigure 5: Calibration curves for race predictions obtained using BISG (light grey) and fBISG (dark
grey), using progressively more name information from dictionaries augmented with L2 data (from
top to bottom rows). As before, curves closer to the 45° line indicate better calibrated predictions.

Figure 5. The exceptions to this pattern come from the inclusion of middle names among Hispanic

and Asian voters, which slightly worsens calibration for predictions based on both BISG and fBISG.

This is likely the result of diﬀerent norms around middle name usage among members of these racial

groups. Of all four major racial categories, calibration remains worst among Asian voters.

5 Conclusion

In this paper, we consider the problem of predicting an individual’s race. This task is especially

relevant to modern research on racial equity in areas such as public health and political science.

The current state-of-the-art approach is Bayesian Improved Surname Geocoding (BISG), which uses

surname and geolocation data to generate a probabilistic prediction for each individual over racial

classes. Yet, as we have shown, BISG predictions can underperform for minority groups due to two

consistent challenges: inaccurate Census counts, and name under-coverage.

To address these challenges, we have introduced a fully Bayesian analogue known as fully-

Bayesian Improved Surname Geocoding (fBISG) that addresses the problem of Census zero counts.

Moreover, we have augmented our name dictionaries, including additional surnames, as well as ﬁrst

and middle names, sourced from voter ﬁles in six southern states provided by L2, Inc. Taken together,

these methodological improvements yield substantial performance gains in predictive accuracy — as

measured by AUROC, as well as false positive and false negative error rates under maximum a

posteriori predictions – while simultaneously improving the calibration of predictions. Moreover, the

13

WhiteBlackHispanicAsianOtherLast nameLast and first namesLast, first, and middle names0.00.20.40.60.81.00.00.20.40.60.81.00.00.20.40.60.81.00.00.20.40.60.81.00.00.20.40.60.81.00.00.20.40.60.81.00.00.20.40.60.81.00.00.20.40.60.81.0PredictedObservedModelBISGfBISGgains are most pronounced among Hispanics and Asian Americans, drawing their predictions almost

to parity with those for White and Black voters in terms of accuracy. We believe these improvements

will be useful for practitioners, allowing them to obtain improved individual-level racial predictions

and better characterize disparate racial impacts.

References

Basso, Gaetano and Giovanni Peri. 2020. “Internal mobility: The greater responsiveness of foreign-

born to economic conditions.” Journal of Economic Perspectives 34:77–98.

Comenetz, Joshua. 2016. Frequently Occuring Surnames in the 2010 Census. Technical Report.

United States Census Bureau https://www2.census.gov/topics/genealogy/2010surnames/

surnames.pdf: .

Edwards, Frank, Hedwig Lee and Michael Esposito. 2019. “Risk of being killed by police use of

force in the United States by age, race-ethnicity, and sex.” Proceedings of the National Academy

of Science 116:16793–16798.

Elliott, Marc N., Allen Fremont, Peter A. Morrison, Philip Pantoja and Nicole Lurie. 2008. “A New

Method for Estimating Race/Ethnicity and Associated Disparities Where Administrative Records

Lack Self-Reported Race/Ethnicity.” Health Services Research 43:1772–1736.

Elliott, Marc N., Peter A. Morrison, Allen Fremont, Daniel F. McCaﬀrey, Philip Pantoja and Nicole

Lurie. 2009. “Using the Census Bureau’s surname list to improve estimates of race/ethnicity and

associated disparities.” Health Services and Outcomes Research Methodology 9:69–83.

Fiscella, Kevin and Allen M. Fremont. 2006. “Use of Geocoding and Surname Analysis to Estimate

Race and Ethnicity.” Health Services Research 41:1482–1500.

Fraga, Bernard L. 2018. The Turnout Gap: Race, Ethnicity, and Political Inequality in a Diversifying

America. New York: Cambridge University Press.

Hepburn, Peter, Renee Louis and Matthew Desmond. 2020. “Racial and Gender Disparities among

Evicted Americans.” Sociological Science 7:649–662.

Imai, Kosuke and Kabir Khanna. 2016. “Improving ecological inference by predicting individual

ethnicity from voter registration records.” Political Analysis 24:263–272.

14

Kenny, Christopher T, Shiro Kuriwaki, Cory McCartan, Evan TR Rosenman, Tyler Simko and

Kosuke Imai. 2021. “The use of diﬀerential privacy for census data and its impact on redistricting:

The case of the 2020 US Census.” Science advances 7:eabk3283.

Khanna, Kabir, Kosuke Imai, Evan Rosenman and Santiago Olivella. 2021. wru: Who are You?

Bayesian Prediction of Racial Category Using Surname and Geolocation. R package version 0.1-

12.

URL: https://github.com/kosukeimai/wru

Studdert, David M., Yifan Zhang, Sonja A. Swanson, Lea Prince, Jonathan A. Rodden, Erin E.

Holsinger, Matthew J. Spittal, Garen J. Wintemute and Matthew Miller. 2020. “Handgun Own-

ership and Suicide in California.” New England Journal of Medicine 382:2220–2229. PMID:

32492303.

Voicu, Ioan. 2018. “Using First Name Information to Improve Race and Ethnicity Classiﬁcation.”

Statistics and Public Policy 5:1–13.

15

Appendix: Additional Results

Ethnicity

Data

Overall Error Rate

White

Black

Hispanic

Asian

Other

False negative
False positive
False negative
False positive
False negative
False positive
False negative
False positive
False negative
False positive

Nonzero Census
Blocks

Zero Census
Blocks

Total

14.5%
5.6%
31.4%
33.7%
3.5%
15.7%
2.2%
33.2%
0.7%
92.7%
0.3%

NA

100% 16.9%
100% 6.1%
NA 31.4%
100% 36.4%
3.5%
100% 20.3%
2.2%
100% 46.6%
0.7%
100% 94.9%
0.3%

NA

NA

NA

Table A1: Overall classiﬁcation error rate as well as false positive (Type I error) and false negative
(Type II error) rates for White, Black, Latino, Asian, and Other voters using the standard BISG
prediction as implemented in the WRU package. Each voter is classiﬁed to the racial category with
the highest predicted probability. We compare rates for individuals in blocks for whom the Census
sets a nonzero prior for their true racial group (“Nonzero Census Blocks”) against individuals in
blocks from who the census sets a zero prior (“Zero Census Blocks”). All individuals are classiﬁed
to the wrong racial group in zero Census blocks, so false negative rates are 100% while false positive
rates are undeﬁned.

16

Ethnicity

Error

Overall Error Rate

White

Black

Hispanic

Asian

Other

False negative
False positive
False negative
False positive
False negative
False positive
False negative
False positive
False negative
False positive

Name Matched
to Dictionary

Name Unmatched
to Dictionary

Total

16.4%
6.1%
30.1%
35.5%
3.6%
18.4%
2.1%
40.3%
0.6%
94.4%
0.3%

24.7% 16.9%
6.5% 6.1%
58.8% 31.4%
63.7% 36.4%
2.1% 3.5%
65.4% 20.3%
4.1% 2.2%
84.6% 46.6%
2.7% 0.7%
99.3% 94.9%
0.2% 0.3%

Table A2: Overall classiﬁcation error rate as well as false positive (Type I error) and false negative
(Type II error) rates for White, Black, Latino, Asian, and Other voters using prediction using
standard BISG as implemented in the WRU package. Each voter is classiﬁed to the racial category
with the highest predicted probability. We compare rates for individuals whose names are matched
to our name dictionary against those whose names are not matched (in which case a national racial
prior is used). Error rates are signiﬁcantly higher among those whose names are unmatched.

17

Ethnicity Error

Model

Last name
(Census)

Last name
(augmented)

Last & ﬁrst
names

Last, ﬁrst, &
middle names

White

Black

Hispanic

Asian

Other

False negative

False positive

False negative

False positive

False negative

False positive

False negative

False positive

False negative

False positive

BISG
fBISG
BISG
fBISG

BISG
fBISG
BISG
fBISG

BISG
fBISG
BISG
fBISG

BISG
fBISG
BISG
fBISG

BISG
fBISG
BISG
fBISG

6.11
9.37
31.40
24.25

36.44
24.39
3.54
6.91

20.35
24.16
2.22
2.11

46.59
41.10
0.74
0.48

94.90
95.21
0.28
0.16

8.60
9.67
25.36
23.00

26.22
23.81
6.29
6.89

24.58
22.81
2.05
2.08

48.36
39.35
0.41
0.52

94.30
94.10
0.43
0.50

6.87
7.79
21.90
17.69

22.98
19.21
4.81
5.25

20.21
14.99
1.92
2.06

45.27
32.58
0.39
0.54

92.98
92.91
0.63
0.55

6.29
6.93
19.73
15.59

21.24
17.93
4.19
4.23

18.38
12.05
1.99
2.19

43.68
29.40
0.40
0.60

91.96
91.85
0.83
0.73

Table A3: False positive (Type I error) and false negative (Type II error) error rates for White, Black,
Latino, Asian, and Other voters using predictions from standard BISG and from our proposed fBISG
model. Each voter is classiﬁed to the racial category with the highest posterior probability. For all
but the ‘Other’ category, both types of errors are reduced as you move from standard, Census-
dictionary BISG, to fBISG using the augmented dictionary (gray cells within each block of rows).

18

Figure A1: Area under the receiver operating characteristic curve (AUROC) for race predictions ob-
tained using the standard BISG (light grey) and fBISG (dark grey) methods, by state. The results
are based on progressively more name information, starting with the L2-augmented surname dictio-
nary (left-most panel). Higher values indicate better predictive accuracy. Overall, the same patterns
we observed when considering all states combined are evident when we disaggregate accuracy by
state: additional name information improves accuracy, especially when using fBISG.

19

Last nameLast and first namesLast, first, and middle namesALFLGALANCSCWhiteBlackHispanicAsianOtherWhiteBlackHispanicAsianOtherWhiteBlackHispanicAsianOther0.60.70.80.91.00.60.70.80.91.00.60.70.80.91.00.60.70.80.91.00.60.70.80.91.00.60.70.80.91.0Race/EthnicityAUCROCModelBISGfBISG