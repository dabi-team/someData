2
2
0
2

y
a
M
7
1

]
E
S
.
s
c
[

1
v
1
2
4
0
0
.
6
0
2
2
:
v
i
X
r
a

The Use of NLP-Based Text Representation Techniques to Support
Requirement Engineering Tasks: A Systematic Mapping Review

Riad Sonbola,∗, Ghaida Rebdawia, Nada Ghneimb

aDepartment of Informatics, Higher Institute for Applied Sciences and Technology (HIAST)
bFaculty of Information and Communication Technology, Arab International University (AIU)

Abstract

Natural Language Processing (NLP) is widely used to support the automation of diﬀerent Require-
ments Engineering (RE) tasks. Most of the proposed approaches start with various NLP steps that
analyze requirements statements, extract their linguistic information, and convert them to easy-to-
process representations, such as lists of features or embedding-based vector representations. These
NLP-based representations are usually used at a later stage as inputs for machine learning tech-
niques or rule-based methods. Thus, requirements representations play a major role in determining
the accuracy of diﬀerent approaches. In this paper, we conducted a survey in the form of a system-
atic literature mapping (classiﬁcation) to ﬁnd out (1) what are the representations used in RE tasks
literature, (2) what is the main focus of these works, (3) what are the main research directions in
this domain, and (4) what are the gaps and potential future directions. After compiling an initial
pool of 2,227 papers, and applying a set of inclusion/exclusion criteria, we obtained a ﬁnal pool
containing 104 relevant papers. Our survey shows that the research direction has changed from
the use of lexical and syntactic features to the use of advanced embedding techniques, especially
in the last two years. Using advanced embedding representations has proved its eﬀectiveness in
most RE tasks (such as requirement analysis, extracting requirements from reviews and forums,
and semantic-level quality tasks). However, representations that are based on lexical and syntactic
features are still more appropriate for other RE tasks (such as modeling and syntax-level quality
tasks) since they provide the required information for the rules and regular expressions used when
handling these tasks. In addition, we identify four gaps in the existing literature, why they matter,
and how future research can begin to address them.

Keywords: Natural Language Processing, Requirements Engineering, Requirements
Representation, Syntax, Semantic

∗Corresponding author
Email address: riad.sonbol@hiast.edu.sy (Riad Sonbol )

Preprint submitted to

April 2, 2022

 
 
 
 
 
 
1. Introduction

Requirements Engineering (RE) is the most critical phase of the software development life cycle
[1]. It aims to specify precisely the requirements that must be met or possessed by the desired system
[2]. RE involves a wide range of tasks related to extracting, documenting, analyzing, validating,
and managing requirements [3]. The requirement represents the core elements of all these tasks. It
is a broad concept describing a purpose, a need, a goal, a functionality, a constraint, a quality, a
behavior, a service, a condition, or a capability [4]. Requirements play a major role in the success
or failure of software projects [5]. According to many studies, most errors in software development
projects stem from the RE phase. The lack of understanding of requirements increases the risk of
time and cost overrun of the project [5, 3].

Requirements come from various stakeholders who have diﬀerent needs, roles, and responsibil-
ities, and are as such prone to the occurrence of conﬂicts including interference, interdependency,
and inconsistency [6]. Moreover, requirements typically are speciﬁed in natural languages, which
increases the complexity of requirement engineering because of the inherent ambiguity, incomplete-
ness, and inaccuracy of natural languages [7]. These factors make RE tasks challenging, time-
consuming, and error-prone work mainly for large projects, as large volumes of requirements need
to be processed, analyzed, and understood [8].

Many researches have been carried out on the automation of diﬀerent RE tasks. The proposed
approaches usually start by applying a set of Natural Language Processing (NLP) steps that ex-
tract linguistic features and information from requirements texts and construct various NLP-based
representations. These representations are used in further stages to solve the targeted task (e.g.,
classifying requirements [9, 10, 11], detecting trace links, discovering quality defects, etc.).

In the last decade, a growing number of works employed various syntactic and semantic-based
features to represent requirements. The used representation is considered one of the most important
factors that aﬀect the accuracy of the proposed solutions for diﬀerent RE tasks [12, 13]. Therefore,
there is a need to analyze the related literature to investigate the suggested representations, identify
gaps, and guide future research.

To address the aforementioned needs, a systematic mapping review was used as a research
method for this study. A mapping review is aimed at providing an understanding of the scope
of the research activities in a given area [14]. Compared to a traditional literature review, a
mapping review has many advantages, such as a well-deﬁned methodology that reduces bias and a
wider context that allows more general conclusions [15]. The review presented in this paper aims
to identify all recently published primary literature that employs NLP-based representations to
support RE tasks. We classify these works based on two aspects: the targeted RE task and the
proposed representation, and identify potentials and gaps in the ﬁeld to inform future research.

The rest of the paper is structured as follows: In section 2 we provide a background for NLP-
related concepts. Section 3 provides a quick overview of related works. Section 4 describes the
methodology adopted to conduct this study including the search terms, online databases, and the

2

systematic mapping process. Section 5 presents and discusses our results. We summarize our
ﬁndings in section 6 and conclude our paper in section 7.

2. Background: Natural Language Processing

Natural language processing is one of the main artiﬁcial intelligence disciplines. It aims to enable
computer programs to “understand” and process natural language texts to achieve some speciﬁc
goals [16, 17]. Traditionally, there are three main levels of processing in an NLP-based approach:
[18]: lexical and morphological level, syntactic level, and semantic level.

2.1. Morphological (or Lexical) Level

The Morphological level focuses on analyzing words into their morphemes like preﬁxes, suﬃxes,

and base words. It includes common tasks, such as Tokenization and Lemmatization [18].

Tokenization: the process of splitting a text into a list of tokens. Tokens can be words,

numbers, or punctuation marks.

Lemmatization: the process of ﬁnding the dictionary form, or the lemma, of each word. For

example, the lemma of “Supporting” and “Supported” is “Support”.

2.2. Syntactic Level

The Syntactic level focuses on analyzing the grammatical structure of sentences. This level usu-
ally includes Part-of-Speech Tagging (POS-tagging), Chunking, dependency Parsing, and Named-
Entity Recognition [18].

POS-Tagging: the process of tagging each token in a sentence with its corresponding part of

a speech tag (such as noun, verb, adjective, etc.) based on its syntactical context [19].

Chunking: the process of detecting syntactic constituents such as Noun Phrases and Verb

Phrases in a sentence [20].

Dependency Parsing: the process of analyzing the syntactic structure of the sentence, by
ﬁnding out the grammatically related words, as well as the type of the relationship between them
[21].

Named-Entity Recognition: It seeks to locate and classify named entities mentioned in the

sentence into pre-deﬁned categories such as person names, organizations, locations, etc [22].

2.3. Semantic Level

The Semantic level focuses on understanding the meaning of the text. The main goal of semantic
processing is to automatically map a natural language sentence into a formal representation of its
meaning. Diﬀerent semantic representations have been proposed in the literature, such as:

3

Ontology-Based Representation: The ontology is a data model that represents a set of
concepts within a domain and the relationships between those concepts [23]. WordNet [24] is one
of the widely used lexical ontologies. Ontologies are commonly used to assign words to a predeﬁned
set of concepts and to measure semantic similarity between them using diﬀerent ontology-based
measures such as Wu and Palmer [25] and path-based similarity [26].

Vector Space Model (VSM): A basic representation model that represents text as a term-
by-document matrix [27]. The Bag-of-Words (BOW) model is a special case for VSM where words
frequencies are used as weights, and words are used as features. Other weighting factors are used
in VSM, such as IDF and TF-IDF.

Topic Modeling-Based Representation: A statistical modeling approach used to discover
the latent or abstract topics that occur in a set of texts. These topics are used to represent each
text. This approach helps in ﬁnding a low-rank approximation to the term-document matrix by
retaining the semantic relations between words. Latent Dirichlet Allocation (LDA) [28] and Latent
Semantic Analysis (LSA) [29] are two common examples of this approach.

Advanced Embedding Techniques: Embedding is an eﬃcient method for learning high-
quality vector representations of words from large amounts of unstructured text data [30]. Word
embedding can capture the context of a word within a document, which allows words with similar
meanings to have similar vector representations. Many famous pre-trained word embeddings are
available to the public, such as Word2Vec [30], GloVe [31], BERT [32], etc.

3. Related Reviews

Many reviews have been published on the relation between NLP and RE tasks [33, 34, 35].
Some of these reviews provide a broad picture of NLP activities and technologies used in the
RE domain [36, 37, 33]. Dermeval et al. [36] conducted a systematic literature review to identify
the primary studies on the use of ontologies in the RE domain. This study considered 77 studies
published between January 2007 and October 2013. Nazir et al. [37] investigated the applications
of NLP in the context of RE. It included 27 studies published between 2002 and 2016. Zhao et al.
[33] introduced a comprehensive overview of the applications of NLP in RE research focusing on the
state of the literature, the state of empirical research, the research focus, the state of the practice,
and the NLP technologies used. This study reviewed 404 relevant primary studies reported between
1983 and April 2019.

Other reviews focused on speciﬁc RE problems. Bozyigit et al.

[38] provided a review of 44
primary studies related to the automatic transformation of software requirements into conceptual
models. It covered works published between 1996 and 2020.

On the other hand, a number of reviews have limited their work to speciﬁc templates for re-
[35] reviewed studies that investigate or develop solutions for

quirements [35, 34]. Amna et al.

4

Group Main Keyword
Group
A

Requirements Engi-
neering

Group
B

Syntactic Process-
ing

Enriched List
”requirement engineering” AND ”software requirement”

”syntax” OR ”POS-tagging” OR ”tagging” OR ”Dependency
Parsing” OR ”shallow parsing” OR ”chunking” OR ”named en-
tity recognition”

Group
C

Semantic Process-
ing

”semantic” OR ”BERT” OR ”word embedding” OR ”word2vec”
OR ”Vector Space Model” OR ”VSM” OR ”Latent Semantic
Analysis” OR ”LSA”

Table 1: Keywords used in our study

problems related to ambiguity in user stories. The study covered 36 researches published between
2001 and 2020. Similarly, Raharjana et al. [34] presented a systematic literature review for research
related to the role of NLP on user story speciﬁcation. This work found 30 primary studies between
January 2009 to December 2020.

Although all these works provided good information regarding requirements engineering, no
conducted secondary studies have focused on the used techniques to represent textual requirements
and the involved syntactic and semantic aspects in these representations.

4. Research Method

This study was undertaken as a systematic mapping review using the guidelines presented in
Petersen et al. [15]. The goal of this review is to identify, categorize, and analyze existing literature
published between 2010 and 2021 and use syntactic and semantics aspects to represent software
requirements when handling RE tasks.

4.1. Planning

In this section, we deﬁne our research questions, the search strategy we use, and the inclusion

and exclusion criteria considered to ﬁlter the results.

4.1.1. Research question

Our work is guided by the following main research questions:
“How are the syntactic and semantics aspects considered to represent software requirements when

handling RE tasks?”.

This question is detailed in the following ﬁve RQs:

(RQ1) What is the state of the published literature on RE works that use syntactic and semantic

representations for requirements?

5

(RQ2) In which RE tasks are the syntactic and semantic aspects mostly considered to represent

requirements?

(RQ3) What are the proposed representations in the literature for RE tasks?

(RQ4) What are the main research directions to represent requirements for each category of RE

tasks?

(RQ5) What gaps and potential future directions exist in this ﬁeld?

While the ﬁrst question (RQ1) focuses on having a general overview of the published works
(number of publications and the top publication venues), the second and the third questions analyze
the targeted problems in RE (RQ2) and the proposed solutions (RQ3). The fourth research question
(RQ4) explores the current research directions for each category of RE tasks, and the ﬁfth question
(RQ5) discusses the gaps and possible future improvements in this domain.

4.1.2. Search Strategies

We used ﬁve digital libraries to conduct the automated search: Scopus, IEEE Xplore, ACM
Digital Library, ScienceDirect, and SpringerLink. Scopus and ScienceDirect are general indexing
systems that help to cover a broader scope for our search. On the other hand, IEEE Xplore, ACM
Digital Library, and SpringerLink publish papers related to the most well-known conferences and
journals related to the software domain.

The search string is built based on the following three key terms: “Requirements Engineering”,
“Syntactic Processing”, and “Semantic Processing”. These terms are derived from our main re-
search question. Each of these terms is enriched by adding synonyms and sub-ﬁelds. Table 1 shows
the whole set of selected keywords for this study divided into three groups: A, B, and C. These
groups were used to create the ﬁnal search query as follows:

A AND ( B OR C)

4.1.3. Inclusion and Exclusion Criteria

Inclusion and exclusion criteria are used to ﬁlter out papers that are not relevant to our research

questions. We deﬁned three inclusion criteria and four exclusion criteria.

Inclusion Criteria:

1C1: Peer-reviewed research presents an approach related to the ﬁeld of software requirements

engineering.

2C2: The research uses NLP techniques including syntactic or semantic processing.

3C3: It is published between 2010 and 2021

Exclusion Criteria:

EC1: Secondary research is excluded (such as literature reviews, summaries, etc.)

EC2: The research is published in languages other than English

6

Figure 1: Search ﬂow diagram for our systematic review

EC3: Duplicate papers (only the most recent and detailed one is considered)

EC4: The study does not provide detailed information about the proposed approach (such as, short

papers, posters, etc.)

4.2. Conducting the Search

The review process consists of ﬁve main stages. Figure 1 illustrates these stages and the numbers
of selected publications after each stage. Starting from the deﬁned data sources, we obtained a total
of 2,227 candidate papers. Duplicated papers were automatically eliminated using Parsifal tool1
ﬁrst, and then additional duplicate entries were manually eliminated by comparing authors, titles,
and abstracts. After removing all duplicates, 1,573 papers remained.

These papers are ﬁltered by applying the selection criteria based on titles and abstracts. This
stage led to the selection of 252 papers. A full-text review of those papers was then conducted to
discard papers that did not satisfy our selection criteria. The remaining primary research papers
after this stage are 98. Finally, reference checking led to an additional 6 relevant papers. After
these stages, our ﬁnal list consists of 104 unique primary papers.

1https://parsif.al

7

4.3. Data Extraction and classiﬁcation

A Data Extraction Form (DEF) is developed to collect the required data to answer our RQs.

The form is designed in a table format consisting of the following types of information:

• Bibliometric Information: author(s), publication year, type of publication, and publication

venue.

• Targeted RE task(s).

• Proposed solution including the Syntactic and semantic information used to represent require-

ments.

• Evaluation Details: evaluation dataset, used metrics, and the results.

• limitations and constraints.

5. Results and Discussions

This section describes and explains the results obtained by the analysis of the 104 selected

papers answering the RQs exposed in the previous sections.

5.1. (RQ1) What is the state of the published literature on RE works that use syntactic and semantic

representations for requirements?

As previously mentioned, our ﬁnal list consists of 104 unique peer-reviewed research papers. Fig
2 shows the distribution of these publications per year. This chart reﬂects a growing interest in the
use of syntactic and semantic levels of processing to handle RE tasks. The vast majority of papers
(more than 85%) have been published since 2015.

Among the selected papers, 47% of them appeared in journals; 42% of papers were published

in conference proceedings, while 11% of papers came from workshops.

The most popular venue for publishing articles related to our study is IEEE International
Conference on Requirements Engineering and its workshops with more than 12% of papers, while the
most popular journals are: Information and Software Technology, Empirical Software Engineering,
Requirements Engineering with 5-6% of papers in each of them.

5.2. (RQ2) In which RE tasks are the syntactic and semantic aspects mostly considered to represent

requirements?

We classiﬁed the retrieved papers based on the type of the targeted RE task. Fig. 3 shows the
hierarchy of all 104 papers categorized into 6 top-level categories and 19 subcategories. The six
main categories are:

8

Figure 2: Number of published per year

5.2.1. Requirements Analysis

This category represents the majority of publications (50 out of 104 papers). It includes papers

focusing on the following RE tasks:

• Requirements Classiﬁcation: Requirements classiﬁcation is an important step towards
automatically analyzing natural language requirements, especially when handling projects
with large numbers of requirements [10]. We recognized 21 papers proposing solutions to
various requirements classiﬁcation tasks. Most of them focused on Functional/Non-Functional
classiﬁcation tasks [39, 40, 41, 10, 11, 42, 43, 44, 45, 46, 47, 48, 49], while the remaining focused
on other classiﬁcation tasks: security/Not security [50, 51, 52], topic-based classiﬁcation [53],
and classiﬁcation based on requirements importance level [54].

• Requirements Traceability: Requirements traceability is used to capture the relationships
between the requirements, the design, and the implementation of a system [55]. We recognized
21 papers related to this task, part of which focused on detecting the relationships between
requirements (inter-dependency between requirements) [56, 57, 58, 59, 60, 61, 62, 63, 64, 65,
66], while the remaining focused on detecting the relationships between requirements and
other artifacts (design documents and source code) [67, 55, 68, 69, 70, 71, 72, 73, 74].

• Requirements Clustering: Requirements clustering is used to organize software require-
ments into a set of clusters with high cohesion and low coupling [75]. We recognized 5 papers
presenting approaches to cluster requirements. These papers used the resultant clusters to
understand the main functional groups or topics over requirements [76, 77, 78], to organize

9

20102011201220132014201520162017201820192020202105101520Figure 3: A chart illustrating the hierarchy of papers categorized based on their targeted RE task.

10

requirements in a tree structure (hierarchy) [79], or as a step towards discovering redundancy
and inconsistency between requirements [80].

• Semantic Role Labeling: Semantic role labeling is the task of extracting semantic in-
formation from a software requirements speciﬁcation [81]. Four papers addressed this task
[82, 83, 81]. These works focused on mapping requirements to formal representations by
extracting their main semantic elements such as actors, actions, and objects.

5.2.2. Requirements Extraction

Requirements extraction (or elicitation) is one of the crucial steps in software development. We
recognized 19 papers addressing tasks related to this category. These papers can be divided into
three groups:

• Extracting Requirements from Reviews and Forums: 9 papers [84, 85, 86, 87, 88, 63,
89, 90, 91] proposed solutions for this task, where various applications reviews and forums are
used as a source for input texts such as App Store and Google Play.

• Extracting Requirements from Textual Documents: 7 papers [92, 93, 94, 95, 96, 97, 98]
presented approaches to extract requirements from SRS documents, policies, user manuals,
and emails.

• Extracting Requirements from Similar applications: 3 papers [99, 100, 101] focused
on recommending requirements based on the speciﬁcations of similar applications. This goal
is achieved by processing the description of similar products to suggest new possible features
and generate creative requirements.

5.2.3. Quality assessment

Quality assessment tasks are concerned with detecting defects in software requirements speci-
[102, 103]. We recognized 17 papers focusing on tasks related to the following quality

ﬁcations.
assessment tasks:

• Ambiguity Detection: This task helps in the identiﬁcation of ambiguous requirements.
The works under this sub-category (9 papers) can be further classiﬁed based on the discussed
level of ambiguity:

– Lexical Ambiguity: The main focus at this level is the ambiguity caused by words and

terms. We recognized 6 papers related to this level [93, 104, 105, 106, 10, 107].

– Syntactic Ambiguity: This level focuses on detecting sentences that have diﬀerent pos-
sible grammatical structures. We recognized one paper handling this level of ambiguity
(Osama et al. [108]).

11

– Semantic Ambiguity: This level focuses on detecting confusing contexts in sentences such
as anaphoric ambiguity and coordination ambiguity. We recognized one paper handling
this level (Ezzini et al. [109]).

– Pragmatic Ambiguity: This level focuses on detecting sentences with multiple meanings.

We recognized one paper handling this level (Ferrari et al. [110])

• Incompleteness Detection: This task is concerned with detecting any possible incomplete-
ness in requirements statements. We recognized 3 papers handling this task [111, 112, 113].

• Conformance With Templates: This task focuses on verifying that the requirements are
indeed written according to pre-deﬁned templates. We recognized one work proposing a
solution to handle this task (Arrora et al. [114]); speciﬁcally, this work focused on checking
the conformance of requirements with two well-known templates: Rupp [115] and EARS [116]
templates.

• Vagueness Detection: Vagueness occurs when a statement can have a continuum of inter-
pretations (e.g., when using words like tall, large, etc.). We recognized one paper focusing on
this problem (Cruz et al. [117]).

• General Assessment: Other papers suggest approaches providing a general assessment
for diﬀerent aspects of requirements quality. Three papers can be classiﬁed under this type
[118, 102, 103]

5.2.4. Modeling

Modeling software requirements is the process of transferring the natural language requirements
into models and diagrams [119]. We recognized 12 papers proposing solutions related to this type
of RE tasks. One of the main diﬀerences between these works is the type of the generated model:

• Use Case Diagrams [120, 121, 119, 122], that focus on actors and their corresponding actions.

• Feature Models [123, 124], that deﬁne features and their dependencies.

• Conceptual Diagrams[125, 126], that focus on concepts and relationships between them.

• Glossaries [127, 128], which deﬁne technical terms which are speciﬁc to an application domain.

• Goal Models [129], that focus on the objectives which a system should achieve through the

cooperation of actors in the intended software and the environment.

• Semantic of Business Vocabulary and Rules (SBVR) [130], which deﬁnes the semantics of

business vocabulary, business facts, and business rules.

12

5.2.5. Requirements Management

Requirements management is an ongoing activity throughout the development process [131].

We classiﬁed two tasks under this category:

• Requirements Prioritization: the main target for this task is to determine which candidate
requirements of a software product should be included in a certain release. We recognized 5
papers handling this task [132, 133, 134, 135, 136].

• Eﬀort Estimation: This task focuses on estimating the eﬀort involved in implementing a
requirement [137]. We found 2 papers proposing methods to handle this problem [138, 137].
Both of them focused on estimating the eﬀort in Agile development methodologies.

5.2.6. Others

One of the retrieved papers (Mishra et al. [139]) focused on building a language model for the
software requirement domain. This model was based on a domain-speciﬁc text corpus collected by
crawling the software engineering category on Wikipedia.

5.3. (RQ3) What are the proposed representations in the literature for RE tasks?

In general, almost all covered papers consist of two main phases:

(1) Representation Phase: NLP processing steps are applied to analyze requirements texts, and to

capture linguistic information in order to represent them in various forms.

(2) Solving Phase: the results of the previous stage are used to solve the targeted problem based

on various ML and non-ML approaches.

Fig. 4 shows these two phases and the techniques used for each of them. Overall, we recognized
ﬁve diﬀerent text representation techniques used to handle the ﬁrst phase: Lexical and syntactic
features, ontology-based representation, VSM, topic modeling-based representation, and advanced
embedding techniques. On the other hand, two families of solutions were proposed for the second
phase: Machine Learning approaches which represent 55% of papers, and Rule-Based approaches
(in 45% of papers) where patterns, regular expressions, and heuristics were used.

To answer our third research question (RQ3), we explore the representations used in the ﬁrst

phase in more detail:

5.3.1. Lexical and Syntactic features

This part represents the largest group with more than 46% of papers (48 out of the selected
104 papers). The solutions proposed in these papers share a similar pipeline: (1) Applying a set
of NLP pre-processing steps. (2) Representing each requirement as a pre-deﬁned set of linguistic
features. (3) Then, proceeding to the solving phase which uses ML techniques (such as Decision
Trees [97, 138, 81, 118, 52], SVM [53, 10, 88], and RF [96, 60, 90, 49]), or rule-based approach using
a set of syntactic regular expressions [125, 95, 126, 130, 117].

13

Figure 4: The general ﬂow and the used techniques for each phase

The used pre-deﬁned set of features (in step 2) usually includes features related to the following

four groups:

• The lexical and morphological features, which are based on requirement words and their
morphological information, such as token, stem (or lemma), n-gram (sequence of words).

• The syntactic features, which are derived from the syntax-related information in the re-
quirement statement, such as POS-tag, chunks (noun or verb phrases), dependency relations,
and the entities extracted using NER.

• The frequency-based features, which are based on the requirements list frequency meta-

data such as the number of words and the number of requirements.

• Dictionary-based features, which are extracted with the help of special dictionaries rep-

resenting special words lists.

To further investigate the commonly used features, Fig. 5 shows the most frequently used
features and the number of papers that consider each of these features. The most used feature is
the POS-tag, as it is considered in 34 out of the total 48 papers related to this type of representation.

14

UnderstandingPhaseInputSolvingPhaseOutputLex.andSyn.(48papers)VSM(15papers)Ontology-Based(9)TopicModeling(8)Adv.Embedding(24papers)MachineLearning(57papers)RuleBased(47papers)Figure 5: Frequently used features

5.3.2. Ontology-Based Representation

This group represents about 9% of papers (9 out of 104). It beneﬁts from pre-deﬁned lexicons
and semantic resources to extend the lexical and syntactic features. Most of these papers used a
rule-based approach in their solutions by applying various ontology-path-based similarity measures.
[110, 105, 74, 109, 113].

Figure 6: The used ontologies with their frequencies

One of the main diﬀerences between these papers is whether the used ontology is general or
domain-speciﬁc. Fig. 6 shows three types of works under this category based on the type of the
used ontology: 6 papers used a general ontology (speciﬁcally WordNet) [127, 129, 113, 105, 140, 74],
while 2 papers used a domain-speciﬁc ontology [110, 109], and one paper merges both approaches
in its similarity calculations [83].

5.3.3. VSM

Various forms of VSM representation are used in 15% of papers (15 papers). These works
combine the BOW technique with diﬀerent weighting methods. The most frequent combination is
BOW with TF-IDF (10 papers). Fig 7 shows all used weighting methods with their frequencies.

15

05101520253035posTagsTokensChunkingStemDependencyRel.Freq-Basedn-GramDictionary-BasedNER246WordNetKnowledgeDomainBothFigure 7: Weighting methods used in VSM representations with their frequency

Based on this type of representation, each requirement is represented as a vector of words or
tokens or stems combined with their weights. These vectors are used in the subsequent phase to
apply similarity-based rules [55, 71] or as an input to train machine learning models (such as SVM
[87, 69, 40, 141]).

5.3.4. Topic modeling based representations

About 8% of papers (8 papers) used topic modeling techniques to represent requirements texts
based on automatically discovered latent topics. Two main topic modeling techniques are used in
these papers: LSA and LDA. Fig 8 shows the distribution of these two techniques over the related
papers.

Figure 8: The used Topic modeling techniques with their frequency

The output of both techniques is a k-dimensional space that reﬂects a k latent topics within
the processed requirements. Then, each requirement is represented as a vector representation in
this k-dimensional space. In most related papers, this representation is employed to calculate the
similarity between requirements as a part of similarity-based rules [70, 107] or clustering machine
learning techniques [135, 99, 78].

5.3.5. Advanced Embedding Representations

This part represents the second largest group of papers (24 papers) with a major increase in
the last couple of years.
It is noted that papers that use this kind of representations achieve
promising results in many major tasks such as requirement classiﬁcation [11, 50, 51], traceability
[64, 56, 59, 58], ambiguity detection [106], and requirement extraction [98, 91].

16

246810TF-IDFFrequencyBoolean23456LSALDABased on this type of representation, each requirement is represented as a vector of ﬂoating
point values. The proposed representations in the related papers are built following two generic
steps (Fig. 9): First, each token in the requirement text is represented using a word embedding
technique; then the ﬁnal requirement representation is constructed using the representation of its
words. To further investigate papers that use advanced embedding techniques, we explore the
techniques and models used in the implementation of each of these two steps.

• Word Representation: Various word embedding techniques were used in the related liter-
ature. Word2vec and BERT are the most common techniques utilized in this group; together
they were used in 17 out of the total 24 papers related to this group. Other works used GloVe
and FastText models, while the remaining papers used an embedding layer instead (added to
the front of their neural network model).

Table 2 shows the related papers for each of the used word embedding techniques.

Word Embedding
word2vec
BERT
Embedding Layer
GloVe
FastText

Related Papers
[101, 104, 106, 139, 59, 67, 50, 43, 58, 76]
[11, 47, 56, 64, 91, 84, 98]
[39, 51, 137, 112]
[54]
[128, 66]

Table 2: The used word embedding techniques with their related papers

• Statement Representation: Papers that use this type of representation can be further
classiﬁed based on the method used to merge word embeddings in order to represent state-
ments. Table 3 shows all related papers classiﬁed into three types of statement embedding
techniques.

Statement embedding
Aggregation-based
RNN-based
CNN-based

Related Papers
[11, 47, 56, 64, 91, 84, 98, 128, 66, 101, 104, 59, 58, 76]
[54, 51, 137, 67, 112, 43]
[39, 50]

Table 3: the used statement embedding techniques with their related paper

The aggregation approach is the most used technique (16 out of 24). It produces the require-
ment representation by applying various aggregation methods on word embedding results such
as:

– Using the average of words embedding to represent statements [101, 128, 66].

– For BERT-based word embedding, a special token ([CLS]) is added to the beginning
of the sentence and is used to calculate an aggregated representation of the statement
[11, 64, 91, 84, 98].

17

Figure 9: The general ﬂow of representing requirements based on advanced embedding techniques

– Combining the syntactic information with the semantic ones by (1) classifying words
based on their syntactic role, (2) calculating the weighted average for each role, then (3)
concatenating the resultant vectors to form the ﬁnal representation [58].

– Representing requirements by representing its main ”semantic frames” which can be re-
trieved with the help of FrameNet [142]. The representation of these frames is calculated
by averaging the embedding vectors of their words [59].

Recurrent Neural Network (RNN) based representation takes word embedding vectors as input.
It ﬁnds a dense and low-dimensional semantic representation for each requirement statement
by sequentially and recurrently processing its words. Many RNN architectures have been
used in the related papers such as LSTM [51, 137, 43], Bi-LSTM [54], BI-GRU [67], and
Skip-Thought [112].

Convolutional Neural Network (CNN) based representation takes word embedding vectors as
It ﬁnds the ﬁnal representation through a number of convolutional layers, pooling
input.
layers, and fully connected layers [39, 50].

18

WordRepresentationRequirementStatementRepresentationRequirementRepresentationBERT(7papers)Word2Vec(10papers)EmbeddingLayer(4papers)FastText(2papers)GloVe(1)RNNanditsvariants(6papers)Aggregation(16papers)CNN(2papers)UnderstandingPhaseUsingAdvancedEmbedding5.4. (RQ4) What are the main research directions to represent requirements for each category of

RE tasks?

To answer this question, we start with a general overview of how the research directions to
represent requirements have evolved over the last decade; then we present a deeper analysis of the
trends and possible future directions in each category of RE tasks.

5.4.1. General Overview

Fig. 10 shows the number of papers according to the used NLP representation and the year
of publication. The bubble chart (Fig. 10) shows clearly how the trend has changed in the last
few years from the lexical and syntactic features to the advanced embedding techniques. These
embedding representations became the most used type in the last 2 years (2020-2021) with 15 out
of 40 published works in that period.

Figure 10: Bubble chart showing the number of papers according to the used NLP representation and the year of
publications

5.4.2. Research directions for each category of RE tasks

To further investigate the trends of various representations, we studied their distribution over

the main categories.

Fig. 11 shows the number of papers that used each of these representations for each category.
As noted, representing requirements based on a set of lexical and syntactic features is the most used
approach in many tasks, especially in quality assessment and requirement modeling. However, there
is a clear interest in the use of advanced embedding and VSM-based representations in requirement
analysis tasks.

19

Lex.andSyn.ontology-basedVSMTopicModellingadvancedembedding2020-20212018-20192016-20172014-20152012-20132010-2011141111753121116522112221671Figure 11: The percentage of used NLP representation for each category of RE tasks

The following sub-sections discuss the trends for each category.

• Requirement Analysis: Embedding techniques have been proven to be useful for various
requirement analysis tasks [11, 64, 58, 59]. Two recent studies [11, 64] compared the perfor-
mance of lexical-syntactic features representation with advanced embedding representation,
and concluded that using embedding vectors led to better results in requirement classiﬁcation
[11] and traceability detection [64] tasks. This ﬁnding is consistent with the results observed
in the NLP literature [143], which indicate that embedding techniques are powerful in deter-
mining the similarity of words and sentences. of words and sentences. Similarity represents
the core operation in almost all requirements analysis tasks.

• Quality Assessment: More than 50% of quality assessment papers used lexical and syntactic
features to represent requirements (Fig. 11). However, a deeper analysis of related papers
showed that we can diﬀerentiate between two types of quality-related RE tasks:

– The majority of papers focused on lexical and syntactic quality-related issues such as
lexical ambiguity and conformance with templates. Many signiﬁcant contributions pro-
vide experiments that indicate the eﬀectiveness of using lexical and syntactic features to
represent requirements when handling this category of tasks [103, 102, 114, 144].

– The remaining papers focused on semantic quality-related issues such as incompleteness,
and semantic-level quality problems. For these tasks, the most used representation in
the literature is ontology-based representation [109, 113, 111]. Besides, one of the recent
interesting works employed advanced embedding representation based on an embedding
layer with a Skip-Thought model to handle incompleteness detection problem [112].

• Requirements Extraction: It is noted that there are two directions to handle requirements

extraction tasks based on the source of data:

– Extracting requirements from documents: the structured format of these documents

20

0102030405060708090100Req.AnalysisQualityAssessmentReq.ExtractionReq.ModellingReq.ManagementsLex.andSyn.Ontology-BasedVSMTopicModellingAdv.Embeddingmotivated many researchers to use lexical and syntactic features. All retrieved papers
under this sub-category used lexical and syntactic representations [92, 96, 95].

– Extracting requirements from reviews, forums, or similar applications: Most of the re-
cent papers (especially the ones published in the last 2 years) used advanced embedding
techniques to handle these tasks [84, 91, 101]. This ﬁnding could be due to the ap-
proaches used to handle this type of requirement extraction tasks; most solutions handle
the problem as a classiﬁcation task (classify sentences or phrases into requirements or
not requirements classes) or a clustering task (group sentences that mention the same
aspects in the product). Both approaches (clustering and classiﬁcation) make the embed-
ding technique more suitable (as mentioned previously when discussing the requirement
analysis case).

• Requirements Modeling: Almost all works under this category represent requirements
based on their lexical and syntactic features or using ontology-based representation [130, 120,
129]. These features are used in the form of rules and syntactic patterns to generate various
models based on rule-based transfer techniques.

• Requirements Management: Most of the papers under this category use lexical and syn-
tactic features representation [136, 133, 134]. However, the number of NLP-based publications
related to this category is still limited to have a clear conclusion regarding the suitable rep-
resentations for this type of tasks.

5.5. (RQ5) What gaps and potential future directions exist in this ﬁeld?

Our survey shows that the use of NLP-based requirements representation has made remarkable
progress over the last decade. Based on our ﬁndings in the previous research questions (especially
RQ4), the use of advanced embedding techniques to represent requirements seems to be promising
for most RE tasks (mainly requirement analysis, extracting requirements from reviews and forums,
and semantic-level quality tasks). Besides, representing requirements based on a set of lexical and
syntactic features or using ontology-based information seems more suitable for other RE tasks (such
as modeling and syntax-level quality tasks).

In the following paragraphs, we will discuss the gaps that represent potential future research

directions in this domain.

5.5.1. More RE domain-speciﬁc word embedding models

As shown in Fig. 9, word representation plays an essential role in representing requirements
(mainly when using embedding techniques). To implement this step, most researchers use generic
word embedding pre-trained models in their solutions. One of the main limitations of these generic
models is their inability to provide appropriate representations for many domain-speciﬁc words.

21

For example, the domain-speciﬁc meaning of words like ”virus”, ”cookies”, ”Python”, ”fork”, etc.
can not be captured based on models trained on generic corpora [139]. Building such domain-
speciﬁc word embedding models is notoriously a challenging task, especially with the little size of
data available in the RE domain. One of the recent works [139] provided an embedding model
trained on 92 MB of texts collected from Wikipedia pages related to the software engineering
domain. However, more research is needed (1) to have embedding models trained on more practical
industrial texts, (2) and to evaluate the use of these models in various RE tasks.

5.5.2. More suitable statements representation techniques

Another important challenge, related to embedding techniques, is the way of merging word vec-
tors to formulate requirements representations (step 2 in Fig 9). Although the suggested techniques
lead to good accuracy in some RE tasks (such as requirements classiﬁcation and traceability detec-
tion), these representations can still be considered as a step towards more suitable representations.
Most of these works use aggregation techniques (that ignore word order [145]) or RNN-based tech-
nique (that usually focus on predicting the next element in a sequence [146]). These works can be
further improved by considering more RE domain-speciﬁc representations [58]. One of the main
potential future directions to handle this problem is using a ”syntax-aware sentence embedding”
technique that considers both the main syntactic roles in requirement statements (such as actor,
action, objects,...) and the semantic aspects of requirements.

5.5.3. More adaptive syntactic processing

Many studies have concluded that there is a gap between RE tasks automation research and
its implementation undertaken in industrial and real-life projects [147, 148, 149]. This gap is more
obvious in the case of rule-based approaches since they usually need the requirements to be repre-
sented based on speciﬁc templates [150]; hence, their success strongly depends on the consistency of
the requirements with the predeﬁned templates [114, 150]. Using such “template-based” approaches
to handle RE tasks could lead to lower accuracy when applied to new requirements written based on
some variations of the predeﬁned template or a completely diﬀerent template. These situations are
common in real-life projects when it is hard to control requirements authoring environments, espe-
cially in large development projects, or when one has little control over the requirements authoring
[114, 151, 147, 148, 149, 150, 12]. One of the potential future research directions
environments.
is working on more adaptive approaches which can be more ﬂexible when handling requirements,
such as identifying the syntactic structures automatically and building more adaptive approaches
based on the dynamically identiﬁed structure.

5.5.4. More research in some RE tasks

Only a few works handled the following RE tasks: requirements prioritization, eﬀort estimation,
and semantic and pragmatic level quality tasks. More research should be conducted to explore the
eﬃciency of using advanced embedding techniques for these tasks.

22

6. Main Findings:

In this section, we summarize the main conclusions and ﬁndings in the following points:

(1) There is a signiﬁcant increase in the number of papers that use NLP-based requirements rep-

resentation over the last decade. The increase is more obvious in the last 2 years.

(2) We recognized 104 papers that employed an NLP-based representation to solve various RE
tasks. We classiﬁed these works based on (1) the targeted RE task using a hierarchy consisting
of 6 top-level categories and 19 sub-categories (Fig. 3), (2) the used NLP-based representation
using 5 classes of text representation techniques (Fig. 4).

(3) Using advanced embedding techniques to represent requirements seems to be promising for most
RE tasks (especially requirement analysis, extracting requirements from reviews and forums,
semantic-level quality tasks). Besides, representing requirements based on a set of lexical and
syntactic features or using ontology-based information seems more suitable for other RE tasks
(such as modeling and syntax-level quality tasks).

(4) Most of the proposed embedding-based representations use generic language models that suﬀer
from limitations when representing the meaning of software engineering terms. Having more
domain-speciﬁc language models to represent words is considered one of the important research
directions in future works.

(5) Most of the proposed embedding-based techniques represent requirements statements without
giving attention to the special structure of a software requirement that consists of clear compo-
nents (actor, action, data object, etc). Using syntax-aware statements embedding could be one
of the possible solutions to have more domain-speciﬁc representations that reﬂect the semantics
of requirements in a better way (compared to traditional aggregation approaches).

(6) There is a need for more ﬂexible approaches in terms of the ability to handle requirements that
do not follow (completely or partially) standard requirements templates, which is the common
case in real-life projects.

(7) The number of researches that use NLP-based representation is still limited for some RE tasks

(requirements prioritization, eﬀort estimation, semantic-based quality assessment).

Finally, tables 4 and 5 summarize the extracted information for all 104 selected papers, in
addition to their categorization based on their targeted RE task and the used text representation.
In the matrix represented in Table 4, each cell includes the papers related to each category of RE
tasks and text representation. Note that two papers ([97] and [98]) are mentioned twice in the table
since they are related to both requirement analysis and requirement extraction categories. Table
5 shows a detailed summary of the 104 papers. This table includes detailed information about
the input and the output of the approach proposed in each paper. In addition, it encloses other
descriptive information including the employed text processing steps, details about the solution
technique (e.g., which ML approach is used), the used dataset, and a summary of the results.

23

Lexical and
Syntactic
Features
[152, 44, 65,
97, 53, 46, 10,
81, 80, 60, 57,
52, 61, 45, 77,
82, 72]
[89, 96, 94,
153, 90, 95,
88, 92, 97]
117,
[103,
114, 118, 144,
93, 108, 111,
102]
130,
[123,
125, 120, 121,
124, 122, 119,
126]
[138,
136, 133]

134,

Requirement
Analysis

Requirements
Extraction

Quality
Assessment

Modeling

Management

Others

Ontology-
Based

VSM

[74, 140, 83]

[41, 55, 48,
40, 51, 79, 71,
73, 141, 69,
42, 49, 62]

Topic
Modeling-
Based
[68, 78, 70]

[87, 100]

[99, 85, 86]

[107]

[113,
110, 109]

105,

[129, 127]

[132]

[135]

Advanced
Embedding

[39, 50, 98,
43, 76, 64, 58,
11, 67, 66, 47,
54, 56, 59]

[63, 91, 101,
84, 98]

106,

[112,
104]

[128]

[137]

[139]

Table 4: The ﬁnal list of selected papers categorized based on the type of targeted RE task and the used text
representation

This table provides a starting point for researchers and practitioners in this ﬁeld to obtain a quick
overview of the state-of-the-art in each RE task, including the recommended dataset to be used
and the most related publications.

7. Threats To Validity

Likewise any secondary research process, it is almost impossible to guarantee that we found the
entire population of all the relevant papers. However, several actions were undertaken to minimize
threats to validity.

• To ensure the inclusion of almost all relevant academic works in the ﬁeld, we followed a
systematic mapping review methodology based on the recommenced guidelines for similar
cases.[15].

• Five reputable and well-known data sources ( Scopus, IEEE Xplore, ACM Digital Library,
ScienceDirect, and SpringerLink) were chosen to maximize the number of candidate papers.

• We tried to make our search string as general as possible by including various synonyms for
each term and by including papers that cover either syntactic or semantic aspects. However,

24

the ﬁnal search string may not encompass all the existing synonyms, which might lead to not
capturing all the relevant studies. We mitigated this threat by checking the references of the
ﬁnal selected papers to add any additional relevant works.

• To minimize mistakes caused by subjective analyses, we followed a rigorous study selection
process, guided by clear inclusion and exclusion criteria. However, the exclusion of papers
published in languages other than English may have failed to potentially ﬁnd some relevant
works.

• When there were doubts or conﬂicts about whether to include an article or not, the ﬁnal

decision is discussed between authors.

• To obtain data consistency and avoid bias in data extraction, we deﬁned a clear data extraction

template and discussed our results in several brainstorming sessions.

8. Conclusion

This study presents a systematic mapping review of the used NLP-based representations in
various RE tasks. Starting from 2,227 papers retrieved from ﬁve well-known digital libraries, we
recognized 104 primary papers fulﬁlling the inclusion and exclusion criteria. We analyzed these
works and categorized them based on: the targeted RE task and the used text representation.

Our results indicate that about two-thirds of retrieved publications handle tasks related to
requirements classiﬁcation, requirements traceability, ambiguity detection, and extracting require-
ments from reviews and documents. On the other hand, Lexical and syntactic features are widely
used to represent requirements (more than 45% of publications). Besides, a growing number of
papers use advanced word embedding techniques, especially in the last two years. Moreover, we
summarize the main research directions to represent requirements in each category, and identify
the gaps and possible future directions.

The data extracted from the selected 104 papers and their categorization, can help as a useful
set of references for further analysis in each task or category of tasks in RE. Besides, trends and
gaps identiﬁed from this mapping study have provided many new ideas for research opportunities.

25

-
2
8
.
0

:
1
F

+
E
S
I
M
O
R
P

*
N
N
C

;

N
N
A

-
k
o
T

;
l
a
v
o
m
e
r

s
d
r
o
w

p
o
t
S

L
M

d
e
c
n
a
v
d
A

R
F
N

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

.
l
a

t
e

r
e
k
a
B

s
t
l
u
s
e
R

t
e
s
a
t
a
D

g
n
i
v
l
o
S

g
n
i
s
s
e
c
o
r
P
t
x
e
T

g
n
i
v
l
o
S
n
o
i
t
a
t
n
e
s
e
r
p
e
R

t
u
p
t
u
O

t
u
p
n
I

d
e
t
e
g
r
a
T

r
e
p
a
P

-
e
D

d
o
h
t
e

M

s
l
i
a
t

d
o
h
t
e

M

d
o
h
t
e

M

k
s
a
T

:

R
F
N

/

1
9
.
0

)
n
o
i
s
r
e
v

-
c
e
l
e
s

e
r
u
t
a
e
f

2
H
C

,

E
D
I
F
T

R
F
N
/
R
F

a
m

i
l
(

R
L

;

N
N
K

,

W
O
B

;
g
n
i
m
m
e
t
S

;
n
o
i
t
a
z
i
n
e

2
7
.
0

n
o
i
t

s
e
s
s
a
l
c

R
F
N

2
9
.
0

:
1
F

E
S
I
M
O
R
P

;

B
N
M

;
*
M
V
S

-
k
o
T

;
l
a
v
o
m
e
r

s
d
r
o
w

p
o
t
S

L
M

M
S
V

;

R
F
N
/
R
F

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

t
e

;
g
n
i
m
m
e
t
S

;
n
o
i
t
a
z
i
n
e

g
n
i
d
d
e
b
m
E

s
e
s
s
a
l
c

]
9
3
[

s
a
i
D

]
0
4
[
.
l
a

y
g
e

5
7
.
0

:
c
c
A

E
S
I
M
O
R
P

-
i
s
s
a
l
C

n
a
i
s
e
y
a
B

-

m
e
t
S

;
l
a
v
o
m
e
r

s
d
r
o
w

p
o
S

L
M

M
S
V

R
F
N

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

r
o
y
a
m
a
s
a
C

-
t
a
r
t
s

M
E
+

r
e
ﬁ

F
D

I
-
F
T
+
W
O
B

;
g
n
i
m

s
e
s
s
a
l
c

]
1
4
[

.
l
a

t
e

;
)
9
7
.
0
(
F

:
1
F

+
E
S
I
M
O
R
P

M
V
S

s
e
r
u
t
a
e
f

c
i
t
c
a
t
n
y
s
-
l
a
c
i
x
e
l

7
1

L
M

-
l
a
c
i
x
e
L

R
Q
/
R
F

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

t
e

z
a
i
p
l
a
D

)
6
7
.
0
(
Q

-
y
c
n
e
d
n
e
p
e
d

.
n
y
s

g
n
i
d
u
l
c
n
i

s
e
r
u
t
a
e
f

d
e
s
a
b

c
i
t
c
a
t
n
y
S

s
e
r
u
t
a
e
f

]
0
1
[

.
l
a

p
u

R
Q
/
R
F

E
S
I
M
O
R
P

N
N
F
F

T
R
E
B

L
M

d
e
c
n
a
v
d
A

;

R
Q
/
R
F

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

.
l
a

t
a

y
e
H

5
7
.
0

:
1
F

E
S
I
M
O
R
P

;

F
R

;

N
N
K

;

T
D

-

m
e
t
S

;
l
a
v
o
m
e
r

s
d
r
o
w

p
o
t
S

L
M

M
S
V

R
F
N

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

t
e

n
a
i
t
a
h
K

*
R
L

;

B
N

W
O
B

;
g
n
i
m

s
e
s
s
a
l
c

]
2
4
[

.
l
a

1
7
.
0

:
1
F

E
S
I
M
O
R
P

;

U
R
G

;

M
T
S
L

c
e
v
2
d
r
o
w

L
M

d
e
c
n
a
v
d
A

R
F
N

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

t
e

n
a
m
h
a
R

N
N
C

g
n
i
d
d
e
b
m
E

s
e
s
s
a
l
c

]
3
4
[

.
l
a

-
7
6
.
0

I

:
1
F
A
D
R
O
C
N
O
C

M
V
S

-
t
i
l
p
s

e
c
n
e
t
n
e
S

,
n
o
i
t
a
z
i
n
e
k
o
T

L
M

d
n
a

l
a
c
i
x
e
L

R
F
N

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

t
e

n
a
w
h
s
a
R

4
8
.
0

E
S
I
M
O
R
P
+

;
g
n
i
m
m
e
t
S

,
r
e
t

c
i
t
c
a
t
n
y
S

s
e
s
s
a
l
c

]
4
4
[

.
l
a

s
e
r
u
t
a
e
F

:

P
/

8
8
.
0

:

R

n
w
O

d
e
s
a
b
-
y
t
i
r
a
l
i

m

i
s

d
e
z
i
l
a
m
r
o
N

;
n
o
i
t
a
z
i
t
a
m
m
e
l

-
e
l
u
R

d
n
a

l
a
c
i
x
e
l

R
F
N

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

t
e

d
u
o
m
h
a
M

2
5
.
0

t
e
s
a
t
a
D

h
c
a
o
r
p
p
a

)
D
G
N
(

e
c
n
a
t
s
i
D
e
l
g
o
o
G

d
e
s
a
B

c
i
t
c
a
t
n
y
s

s
e
s
s
a
l
c

]
6
4
[

.
l
a

s
d
r
o
w
y
e
k

r
o
t
a
c
i
d
n
i

R
F
N

s
e
r
u
t
a
e
F

4
6
.
0

:
1
F

E
S
I
M
O
R
P

d
e
s
a
b
-
y
t
i
r
a
l
i

m

i
s

-

m
e
t
s

,
l
a
v
o
m
e
r

s
d
r
o
w
p
o
t
s

-
e
l
u
R

d
n
a

l
a
c
i
x
e
L

R
F
N

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

.
l
a

t
e

s
a
n
u
o
Y

h
c
a
o
r
p
p
a

s
u
o
m
a
f

,
g
n
i
g
g
a
t
-
S
O
P

,
g
n
i
m

d
e
s
a
B

c
i
t
c
a
t
n
y
S

s
e
s
s
a
l
c

]
5
4
[

s
e
r
u
t
a
e
f

o
t

p
u

R
F

2
9
.
0

;
4
9
.
0

o
t

z
a
i
p
l
a
D
(

;
7
8
.
0

R
F
N

)
n
o
i
s
r
e
V

g
n
i
d
d
e
b
m
E

;
s
e
s
s
a
l
c

R
F
N

s
e
s
s
a
l
c

R
F

]
1
1
[

26

-
1
7
.
0

:
c
c
A

6
9
.
0

t
e
s
a
t
a
D

t
e
s
a
t
a
D

n
w
O

n
o
i
t
n
e
t

g
n
i
d
d
e
b
m
E

.

R
F

]
4
5
[

.
l
a

t
e

N
N
C

-
l
o
c

a

n
o

d
e
n
i
a
r
t

c
e
v
2
d
r
o
w

L
M

d
e
c
n
a
v
d
A

c
e
S
N
/
c
e
S

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

.
l
a

t
e

o
i
c
a
l
a
P

t
e
s
a
t
a
d

y
t
i
r
u
c
e
s

d
e
t
c
e
l

g
n
i
d
d
e
b
m
E

]
0
5
[

6
8
.
0

:
1
F

n
w
O

-
t
A

+

M
T
S
L
-
i

B

S
R
S

4
2
1

n
o

d
e
n
i
a
r
t

e
V
o
l
G

L
M

d
e
c
n
a
v
d
A

t
n
a
c
ﬁ
i
n
g
i
S

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

e
e
j
r
e
t
t
a
h
C

4
8
.
0

:
c
c
A

q
e
R
c
e
S

-
o
g
l
a

L
M

2
2

W
O
B

L
M

M
S
V

c
e
S
N
/
c
e
S

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

t
e

a
c
i
l
i
b
o
K

;
8
6
.
0
:
P

s
t
e
s
a
t
a
d

6

y
t
i
r
a
l
i

m

i
s

y
z
z
u
F

-
e
r

s
d
r
o
w
p
o
t
S

,
n
o
i
t
a
z
i
n
e
k
o
T

L
M

M
S
V

y
t
i
l
a
u
Q

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

t
e

a
j
r
a
h
a
R

5
5
.
0
:
R
)
+
E
S
I
M
O
R
P
(

N
N
K
+
e
r
u
s
a
e
m

F
D

I
-
F
T

,
g
n
i
m
m
e
t
S

,
l
a
v
o
m

s
t
c
e
p
s
a

]
8
4
[

.
l
a

)
o
M
L
E

0
8
.
0

:
1
F

+

S
R
O
O
D

t
x
e
t

s
s
a
l
c
-
i
t
l
u
m

-
l
l
i
t
s
i
D
(

g
n
i
d
d
e
b
m
e

d
r
o
w

L
M

d
e
c
n
a
v
d
A

R
F
N
/
R
F

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

.
l
a

t
e

i
c
i
K

E
S
I
M
O
R
P

n
o
i
t
a
c
ﬁ
i
s
s
a
l
c

+

M
T
S
L
B

i

d
n
a

T
R
E
B

g
n
i
d
d
e
b
m
E

]
7
4
[

g
n
i
d
u
l
c
n
i
(

m
h
t
i
r

)
*
M
T
S
L

]
1
5
[
.
l
a

E
S
I
M
O
R
P
+

s
e
l
u
r

c
i
t
s
i
u
g
n
i
l

4
3

+

)
s
e
r
u
t

)
s
e
r
u
t
a
e
F

c
i
t
c
a
t
n
y
S
(

c
i
t
c
a
t
n
y
S

s
e
r
u
t
a
e
F

3
6
.
0

:
1
F

q
e
R
c
e
S

R
L

;

B
N

;
8
4
J

-
a
e
f

l
a
c
i
x
e
L
(

s
d
r
o
w
y
e
K

0
4
1

L
M

d
n
a

l
a
c
i
x
e
L

c
e
S
N
/
c
e
S

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

]
2
5
[
.
l
a

t
e

i

L

g
n
i
r
e
t
s
u
l
c

c
e
v
2
d
r
o
w

;
s
d
r
o

W

e
r
u
s
a
e
m

o
n

E
R
d
w
o
r
C

s
’
r
e
v
o
M

d
r
o

W

s
d
r
o
w

p
o
t
S

;
n
o
i
t
a
z
i
n
e
k
o
T

L
M

d
e
c
n
a
v
d
a

s
r
e
t
s
u
l
C

f
o

t
e
s

a

g
n
i
r
e
t
s
u
l
C

.
l
a

t
e

e
l
l
u
G

s
t
s
i
x
e

d
e
s
a
b

e
c
n
a
t
s
i
D

e
t
a
l
p
m
e
T

e
v
o
m
e
R

;
l
a
v
o
m
e
r

g
n
i
d
d
e
b
m
e

.
q
e
R

]
6
7
[

:
x
e
d
n
I

d
n
a
R

n
w
O

d
e
s
a
B

g
n
i
r
e
t
s
u
l
C

-
t
a
c

;
g
n
i
k
n
u
h
c

;
g
n
i
g
g
a
t
-
S
O
P

L
M

d
n
a

l
a
c
i
x
e
l

s
r
e
t
s
u
l
C

-
e
s
u

g
n
i
r
e
t
s
u
l
C

r
o
y
a
m
a
s
a
C

0
8
.
0

t
e
s
a
t
a
D

,
b
e
W
b
o
C

,

M
E

n
o

-
i
s
n
o
p
s
e
r

e
t
a
d
i
d
n
a
c

e
z
i
r
o
g
e

c
i
t
c
a
t
n
y
s

-
c
n
u
f

r
o
f

s
e
s
a
c

]
7
7
[

.
l
a

t
e

2
5
.
0

:
1
F

+
E
S
I
M
O
R
P

,

B
N
M

,

R
L

F
D

I
-
F
T

L
M

M
S
V

n
g
i
s
e
D

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

.
l
a

t
e

a
v
l
i
S

F
R

,
*
M
V
S

6
.
0

:

P
/
8
.
0
:
R

U
C
D

*
M
V
S

,

B
N
M

-
r
u
S

,

m
a
r
g
-
n

,
n
o
i
t
a
z
i
n
e
k
o
T

L
M

d
n
a

l
a
c
i
x
e
L

9
7
.
0
:
1
F

t
e
s
a
t
a
D

n
w
O

c
i
t
c
a
t
n
y
s

,

m
a
r
g
-
n

,

W
O
B

t
e
l
p
i
r
T
c
i
t
n
a
m
e
S

,
s
e
r
u
t
a
e
f

F
R

,
s
e
r
u
t
a
e
f

d
e
s
a
b
-
h
t
g
n
e
L

L
M

M
S
V

s
t
n
e
m
e
r
i
u
q
e
r

g
n
i
d
n
u
o
r

c
i
t
c
a
t
n
y
S

s
e
r
u
t
a
e
F

s
n
r
e
t
t
a
P

.
q
e
R

c
i
p
o
T

y
t
i
l
a
u
q

d
e
t
a
l
e
r

e
u
s
s
i

s
e
u
s
s
I

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

t
e

i
q
i
n
s
a
r
K

]
9
4
[

.
l
a

.
q
e
R
a

n
o
i
t
a
c
ﬁ

i
s
s
a
l
C

.
l
a

t
a

t
t
O

]
3
5
[

]
1
4
1
[

27

n
a
c
S
B
D

,
s
n
a
e
m
X

d
n
a

P
N
e
h
t

n
o

d
e
s
a
b

s
e
i
t
i
l
i
b

s
e
r
u
t
a
e
f

.
o
t

s
e
t
a
l
e
r
V

l
a
n
o
i
t

p
u
o
r
g

;
6
4
.
0

:
y
t
i
r
u
P

n
w
O

d
e
s
a
b

e
m
e
h
T

-
e
R

;
g
n
i
k
n
u
h
c

;
g
n
i
g
g
a
t

s
o
p

L
M

-
d
o
m

c
i
p
o
T

s
r
e
t
s
u
l
C

S
R
S

g
n
i
r
e
t
s
u
l
C

.
l
a

t
e

a
r
s
i

M

.
2
5
.
0

:
1
F

t
e
s
a
t
a
D

g
n
i
r
e
t
s
u
l
c

-
a
z
i
t
e
m
m
e
l

;
s
d
r
o
w
-
p
o
t
s

e
v
o
m

g
n
i
l
e

A
S
L

;
n
o
i
t

-
u
c
o
D

t
n
e
m

]
8
7
[

)
C
H
A
(

g
n
i
r
e
t
s
u
l
c

/
3
8
.
0
-
2
7
.
0
:
P

n
w
O

e
v
i
t
a
r
e
m
o
l
g
g
A

-
e
r

s
d
r
o
w
p
o
t
s

;
n
o
i
t
a
z
i
n
e
k
o
T

L
M

M
S
V

s
r
e
t
s
u
l
C

f
o

t
e
s

a

g
n
i
r
e
t
s
u
l
C

.
l
a

t
e

l
a
y
E

1
6
.
0
-
4
5
.
0
:
R

t
e
s
a
t
a
D

l
a
c
i
h
c
r
a
r
e
i
H

M
S
V

;
g
n
i
m
m
e
t
s

;
l
a
v
o
m

.
q
e
R

]
9
7
[

e
l
b
a
l
i
a
v
A
o
N

n
w
O

n
a
e
m
K

-

g
n
i
k
n
u
h
c

P
N

;
g
n
i
g
g
a
t

s
o
p

L
M

d
n
a

l
a
c
i
x
e
l

s
r
e
t
s
u
l
C

S
R
S

g
n
i
r
e
t
s
u
l
C

t
e

i
n
a
h
g
z
e

M

s
q
e
r

f
o

8
8
.
0

:
c
c
A

s
r
i
a
p

0
0
8

y
t
i
r
a
l
i

m
i
S

s
o
C

s

m
r
e
t

T
R
E
B

s
t
l
u
s
e
R

t
e
s
a
t
a
D

s
s
e
n
i
s
u
b

l
a
c
i
n
h
c
e
t

t
c
e
t
e
d

o
t

-
e
l
u
R

d
e
s
a
B

g
n
i
d
d
e
b
m
E

e
r
o
c
s

s
q
e
R

]
6
5
[

d
e
c
n
a
v
d
A

y
t
i
r
a
l
i

m
i
S

o
w
T

y
t
i
l
i
b
a
e
c
a
r
T

.
l
a

t
e

s
a
D

c
i
t
c
a
t
n
y
s

s
e
r
u
t
a
e
f

-
u
c
o
D

t
n
e
m

]
0
8
[

.
l
a

-
l
i
a
v
A

t
o
N

n
w
O

-
e
b

y
t
i
r
a
l
i

m
i
S

-
e
r

s
d
r
o
w
p
o
t
s

;
n
o
i
t
a
z
i
n
e
k
o
T

-
e
l
u
R

d
n
a

l
a
c
i
x
e
l

y
f
i
t
n
e
d
i

o
w
T

y
t
i
l
i
b
a
e
c
a
r
T

.
l
a

t
e

e
k
a
l
B

e
l
b
a

t
e
s
a
t
a
D

s
i

s
q
e
r

n
e
e
w
t

;
s

m
y
n
o
n
y
s

e
t
a
r
e
n
e
g

;
l
a
v
o
m

d
e
s
a
B

c
i
t
c
a
t
n
y
s

-
r
e
v
o

d
e
s
a
b

d
e
t
a
l
u
c
l
a
c

f
o

r
e
b
m
u
n

n
o

s
d
r
o
w
r
a
l
i

m

i
s

s
b
r
e
v

e
n
i
m
r
e
t
e
d

s
e
r
u
t
a
e
f

g
n
i
p
p
a
l

-
e
r
i
u
q
e
r

s
t
n
e
m

-
u
c
o
d

s
t
n
e
m

S
R
S

]
7
5
[

9
8
.
0
:
1
F

E
R
U
P

t
e
s
a
t
a
d

B
N

,

M
V
S

,

F
R

-
e
r

s
d
r
o
w

p
o
t
s

,
d
e
z
i
n
e
k
o
t

L
M

d
n
a

l
a
c
i
x
e
l

y
c
n
e
d
n
e
p
e
D

o
w
T

y
t
i
l
i
b
a
e
c
a
r
T

e
d
n
a
p
h
s
e
D

n
o
i
t
a
z
i
t
a
m
m
e
l

;
l
a
v
o
m

c
i
t
c
a
t
n
y
s

s
t
i

d
n
a

s
q
e
R

]
0
6
[

.
l
a

t
e

s
e
r
u
t
a
e
f

e
p
y
t

9
8
.
0

:
1
F

q
e
R
n
e
p
O

,

M
V
S

r
a
e
n
i
L

,

l
a
v
o
m
e
R

s
d
r
o
w

p
o
t
S

L
M

d
n
a

l
a
c
i
x
e
l

d
e
t
a
l
e
r

o
w
T

y
t
i
l
i
b
a
e
c
a
r
T

.
l
a

t
e

r
e
m
a
S

8
5
.
0

:
1
F

n
w
O

-
i
l
l
e
t
n
i

m
r
a
w
s

-

m
e
t
s

,
l
a
v
o
m
e
r

s
d
r
o
w

p
o
t
s

L
M

N
N
K

n
o
i
t
a
z

s
e
r
u
t
a
e
f

M
S
V

d
e
t
a
l
e
r

d
e
t
a
l
e
r

o
w
T

y
t
i
l
i
b
a
e
c
a
r
T

t
e

v
o
n
a
t
l
u
S

t
e
s
a
t
a
D

d
n
a

,
*
F
R
B
N

,

-
i
t
a
m
m
e
l

,
s

m
y
n
o
n
y
s

d
e
g
r
e
m

c
i
t
c
a
t
n
y
s

t
o
n

/

s
q
e
R

]
1
6
[

t
e
s
a
t
a
D

e
c
n
e
g

t
n
e
g
a

;

F
D

I
-
F
T
+
M
S
V

,
g
n
i
m

t
o
n

/

s
q
e
R

]
2
6
[

.
l
a

s
d
r
o
w

d
e
t
a
l
e
r

2
9
.
0

:
1
F

s
r
i
a
p

2
5
8
,
5

-
s
i
D

n
a
t
t
a
h
n
a
M

;
g
n
i
g
g
a
T

S
O
P

;
n
o
i
t
a
z
i
n
e
k
o
T

s
q
e
r

f
o

d
e
s
a
B

e
c
n
a
t

-
e
r

y
f
i
s
s
a
l
c

;
g
n
i
k
n
u
h
c

P
N

y
t
i
r
a
l
i

m
i
S

-
i
d

c
i
t
n
a
m
e
s

o
t

s
t
n
e
m
e
r
i
u
q

c
e
v
2
d
r
o
w

;
s
n
o
i
s
n
e
m

6
8
.
0

:
1
F

s
r
i
a
p

0
7
7
,
1

e
r
o
c
s

s
s
e
n
d
e
t
a
l
e
r

-
e
r

d
r
o
w
-
p
o
t
s

,
n
o
i
t
a
s
i
n
e
k
o
t

s
q
e
r

f
o

e
m
a
r
f

n
o

d
e
s
a
b

d
n
a

g
n
i
g
g
a
t

S
O
P

,
l
a
v
o
m

d
n
a

s
g
n
i
d
d
e
b
m
E

-
g
n
i
d
d
e
b
m
E

,
n
o
i
t
a
s
i
t
a
m
m
e
l

m

i
s

s
o
c

-
e
s

f
o

n
o
i
t
a
t
n
e
s
e
r
p
e
r

d
e
s
a
b

s
e
m
a
r
f

c
i
t
n
a
m

-
e
l
u
R

d
e
s
a
B

-
e
l
u
R

d
e
s
a
B

g
n
i
d
d
e
b
m
E

e
r
o
c
s

s
q
e
R

]
8
5
[

d
e
c
n
a
v
d
A

y
t
i
r
a
l
i

m

i
s

o
w
T

y
t
i
l
i
b
a
e
c
a
r
T

.
l
a

t
e

l
o
b
n
o
S

g
n
i
d
d
e
b
m
E

e
r
o
c
s

s
q
e
R

]
9
5
[

.
l
a

d
e
c
n
a
v
d
A

y
t
i
r
a
l
i

m
i
S

o
w
T

y
t
i
l
i
b
a
e
c
a
r
T

t
e

n
a
h
s
o
h
l
A

28

d
n
a

-
t
u
o

,

A
S
E

D
G
N

m
r
o
f
r
e
p

d
n
a

A
S
L

.

A
D
L

.
t
s
u
r
T

i

,
)
S
O
P
-
M
S
V
(

M
S
V

d
e
l
b
a
n
e

g
n
i
x
e
d
n
i

c
i
t
n
a
m
e
s

t
n
e
t
a
l

-
e
s

t
i
c
i
l
p
x
e

,

A
D
L

,
)
I
S
L
(

d
n
a

,
)
A
S
E
(

s
i
s
y
l
a
n
a

c
i
t
n
a
m

e
c
n
a
t
s
i
d

e
l
g
o
o
G

d
e
z
i
l
a
m
r
o
n

.
)
D
G
N
(

s
t
a
c
f
i
t

9
5
.
0

:
n
o
i
s

)
t
i
n
U
d
e
t
a
G

d
e
t
a
l
e
r

n
g
i
s
e
D

-
u
c
o
d

s
t
n
e
m

s
t
l
u
s
e
r

e
g
r
e
m

-
r
a
l
i

m

i
s

s
o
C

;
q
e
r
F
+
M
V
S

y
t
i

s
t
c
e
j
o
r
p

o
t

c
i
g
o
l

y
z
z
u
f

;
g
n
i
m
m
e
t
s

;
l
a
v
o
m
e
r

s
e
r
u
t
a
e
f

d
e
t
a
l
e
r

4
1

m
o
r
f

e
s
u

d
n
a

s
e
h
c
a
o
r
p

s
d
r
o
w

p
o
t
s

)
B
(

h
c
a
o
r
p

d
e
s
a
b

c
i
t
c
a
t
n
y
s

t
o
n

/

s
q
e
R

3
8
.
0

:
c
c
A

a
t
a
D

n
w
O

-
p
a

o
w
t

y
l
p
p
a

-
p
a

d
e
s
a
b

m

i
s

d
r
a
c
c
a
J

)
A
(

e
l
u
r

d
n
a

l
a
c
i
x
e
l

d
e
t
a
l
e
r

o
w
T

y
t
i
l
i
b
a
e
c
a
r
T

]
3
6
[

.
l
a

t
e
u
L

-
r
e
v
A

n
a
e
M

n
w
O

-
c
e
r
i
d
i
B
(

N
N
R

-
o
d

a

n
o

d
e
n
i
a
r
t

c
e
v
2
d
r
o
w

L
M

d
e
c
n
a
v
d
a

T
R
E
B

d
e
t
a
l
e
r

d
e
t
a
l
e
r

s
S
R
S

y
t
i
l
i
b
a
e
c
a
r
T

.
l
a

t
e

o
u
G

-
i
c
e
r
P

e
g
a

t
e
s
a
t
a
D

t
n
e
r
r
u
c
e
R

l
a
n
o
i
t

s
u
p
r
o
c

n
i
a
m

g
n
i
d
d
e
b
m
e

t
o
n

/

d
n
a

]
7
6
[

3
9
.
0

:
1
F

e
n
i
m
d
e
R

e
c
n
e
u
q
e
S
r
o
F
t
r
e
B

-
o
t

;
l
a
v
o
m
e
r

s
d
r
o
w

p
o
t
s

L
M

d
e
c
n
a
v
d
a

d
e
t
a
l
e
r

o
w
t

y
t
i
l
i
b
a
e
c
a
r
T

e
d
n
a
p
h
s
e
D

t
e
s
a
t
a
D

n
o
i
t
a
c
ﬁ
i
s
s
a
l
C

;
n
o
i
t
a
z
i
t
a
m
m
e
l

;
n
o
i
t
a
z
i
n
e
k

g
n
i
d
d
e
b
m
e

t
o
n

/

s
q
e
R

]
4
6
[

.
l
a

t
e

0
3
.
0
/
0
7
.
0

o
g
l
A

g
n
i
l
e
d
o
M

c
i
p
o
T

s
t
a
c
f
i
t

r
e
g
r
a
l

P
/
R

n
w
O

c
i
p
o
T

m
r
e
t
i
B

-
g
a
t

s
o
p

,
l
a
v
o
m
e
r

s
d
r
o
w
p
o
t
s

L
M

-
d
o
m

c
i
p
o
T

e
c
a
r
t

s
q
e
r

y
t
i
l
i
b
a
e
c
a
r
T

.
l
a

t
e

g
n
a
W

n
a
h
t

t
e
s
a
t
a
D

c
i
t
e
n
e
G
–
l
e
d
o
M

,

F
D
I
–
F
T

,
g
n
i
m
m
e
t
s

,
g
n
i
g

g
n
i
l
e

s
k
n
i
l

-
r
a

d
n
a

]
8
6
[

;
1
9
.
0
:
P

,
c
i
n
i
l
c
y
s
a
E

g
n
i
n
r
a
e
l

n
a
i
s
e
y
a
B

W
o
B
+
F
D

I
-
F
T

L
M

M
S
V

e
c
a
r
t

s
q
e
r

y
t
i
l
i
b
a
e
c
a
r
T

.
l
a

t
e
h
k
e
s
a
R

4
9
.
0
:
R

e
t
a
g
r
e
b
l
a

,
k
r
o
w
t
e
N

F
B
R

,

T
D

,

M
V
S

,

R
L

s
k
n
i
l

-
r
a

d
n
a

s
t
a
c
f
i
t

]
9
6
[

,
S
O
P
-
M
S
V

d
n
a

,
r
u
o
T
e

n
o
i
t

-
S
O
P

-

,
)
T
M
S
V
(

t
r
o
p
p
u
s

d
e
s
a
b

g
n
i
l
e

s
k
n
i
l

-
r
a

d
n
a

]
0
7
[

.
l
a

,

-

T
M
S
V

,
1
-
M
C

-
c
n
u
f

y
t
i
r
a
l
i

m

i
s

s
u
r
u
a
s
e
h
t

h
t
i
w

M
S
V

,

M
S
V

e
l
u
r

-
d
o
m

c
i
p
o
T

e
c
a
r
t

s
q
e
r

y
t
i
l
i
b
a
e
c
a
r
T

t
e

d
u
o
m
h
a
M

-
l
i
a
v
A

t
o
N

,
c
i
n
i
l
c
y
s
a
E

-
h
c
e
t

g
n
i
k
n
a
r

,
g
n
i
m
m
e
t
s

,
n
o
i
t
a
z
i
l
a
m
r
o
n

e
l
b
a

,
t
s
u
r
T

i

r
u
o
T
e

e
u
q
i
n

c
e
v
2
d
r
o
w

,

M
S
V

t
e
s
a
t
a
D

6
5
.
0

:
1
F

n
w
O

s
c
i
t
s
i
r
u
h

f
o

t
e
s

a

l
e
d
o
m
d
e
s
a
b
M
S
V

d
e
s
a
b

e
l
u
r

d
e
s
a
b

e
l
u
r

M
S
V

s
q
e
r
-
e
d
o
c

e
s
u

y
t
i
l
i
b
a
e
c
a
r
T

t
e

a
r
b
a
h
h
C

s
k
n
i
l
e
d
o
c
+
s
e
s
a
c

]
3
7
[

.
l
a

M
S
V

e
c
a
r
t

s
q
e
r

y
t
i
l
i
b
a
e
c
a
r
T

.
l
a

t
e

g
n
a
W

s
k
n
i
l

-
r
a

d
n
a

s
t
a
c
f
i
t

]
5
5
[

29

%
4
6
-
%
8

d
n
a

,
a
k
o
o
P

+

s
e
h
c
a
o
r
p
p
a

d
n
a
P
r
e
h
g
i
h

P
I
S

,
x
n
y
L

d
e
s
a
b
-
t
n
i
a
r
t
s
n
o
C

M
S
V
n
a
h
t
R

M
S
J

d
n
a

-
p
a

o
t

g
n
i
n
u
r
p

s
k
n
i
l

e
v
o
r
p

%
7
0
1
-
%
1
1

,
t
s
u
r
T

i

e
n
i
l
e
s
a
b

y
l
p
p
a

,
g
n
i
m
m
e
t
s

,
g
n
i
g
g
a
t

s
o
p

d
e
s
a
b

e
l
u
r

M
S
V

e
c
a
r
t

s
q
e
r

y
t
i
l
i
b
a
e
c
a
r
T

.
l
a

t
e

a
i
l

A

s
k
n
i
l

-
r
a

d
n
a

s
t
a
c
f
i
t

]
1
7
[

s
t
c
i
ﬂ

s
e
r
u
t
a
e
f

:
y
c
a
r
u
c
c
A

,
S
M
P
C

m
e
t
s
y
s

d
e
s
a
b

e
l
u
r

g
n
i
s
s
e
c
o
r
p

P
L
N
c
i
s
a
b

e
l
u
r

d
n
a

l
a
c
i
x
e
l

s
t
c
i
ﬂ
n
o
c

f
o

t
e
s

a

y
t
i
l
i
b
a
e
c
a
r
T

t
e

l
i
a
h
k
e
d
l
A

%
0
0
1

S
M
F

,

P
N
E

-
n
o
c

y
f
i
t
n
e
d
i

o
t

d
e
s
a
b

c
i
t
c
a
t
n
y
s

s
q
e
r

]
5
6
[

.
l
a

e
h
t

f
o

%
9
9

e
s
a
c

l
a
i
r
t

m
h
t
i
r
o
g
l
a

g
n
i
s
u

e
r
u
s
a
e
m
y
t
i
r
a
l
i

m

i
s

;

P
V

d
e
t
c
a
p
m

i

s
e
i
d
u
t
s

d
e
s
a
b

h
t
a
p

d
n
a

n
i
e
t
s
n
e
v
e
L

d
e
t
c
e
t
e
d

-
s
u
d
n
i

o
w
T

d
e
s
a
b

y
t
i
r
a
l
i

m

i
s

d
n
a

P
N

t
c
a
r
t
x
e

;
g
n
i
k
n
u
h
c

s
q
e
r

m

i
s

5
6
.
0
:
1
F

s
t
e
s
a
t
a
d

5

-
e
r

g
n
i
r
e
t
s
u
l
c

,
g
n
i
g
g
a
t

s
o
p

,
n
o
i
t
a
z
i
n
e
k
o
t

n
e
h
t

,
s
t
n
e
m
e
r
i
u
q

,
e
e
r
t

y
c
n
e
d
n
e
p
e
d

,
r
e
s
r
a
p

s
r
e
t
s
u
l
c

s
s
e
c
o
r
p

s
t
c
i
ﬂ
n
o
c

t
c
e
t
e
d
o
t

t
e
N
d
r
o

W

d
e
s
a
b

e
l
u
r

d
e
s
a
b

e
l
u
r

-
y
g
o
l
o
t
n
o

s
t
c
i
ﬂ
n
o
c

f
o

t
e
s

a

y
t
i
l
i
b
a
e
c
a
r
T

.
l
a

t
e

h
a
h
S

d
e
s
a
b

s
q
e
r

]
0
4
1
[

y
c
n
e
d

-
n
e
p
e
d

o
i
r
a
n
e
s

-
y
g
o
l
o
t
n
o

-
r
e
t
n
i

f
o

t
e
s

y
t
i
l
i
b
a
e
c
a
r
T

.
l
a

t
e

a
r
o
r
A

d
e
s
a
b

t
n
e
m
e
r
i
u
q
e
e
r
g
n
a
h
c
+
s
q
e
r

]
4
7
[

-
5
5
.
0

:
1
F

s
e
s
a
c

t
s
e
t

3

N
N

,

F
R

,
*
R
L

g
n
i
d
d
e
b
m
e

d
r
o
w

L
M

d
e
c
n
a
v
d
a
s
e
i
c
n
e
d
n
e
p
e
d

f
o

t
e
s

a

y
t
i
l
i
b
a
e
c
a
r
T

t
e

n
o
s
l
o
h
c
i
N

-
x
e

s
e
l
u
r

7
6
.
0

8
3
2

e
r
e
w

d
e
t
c
a
r
t

t
e
s
a
t
a
D

g
n
i
n
i
M

g
n
i
k
n
u
h
c

c
i
t
c
a
t
n
y
s

s
e
r
u
t
a
e
f

s
e
l
u
R

.
c
e
p
S

d
n
a

s
q
e
R

]
2
7
[

n
w
O

e
l
u
R

n
o
i
t
a
i
c
o
s
s
A

,
g
n
i
g
g
a
t

s
o
p

,
n
o
i
t
a
z
i
n
e
k
o
t

L
M

d
n
a

l
a
c
i
x
e
l

n
o
i
t
a
i
c
o
s
s
A

n
g
i
s
e
D

y
t
i
l
i
b
a
e
c
a
r
T

.
l
a

t
e

o
a
t
i
e
L

g
n
i
d
d
e
b
m
e

s
q
e
r

]
6
6
[

.
l
a

6
7
.
0

:
1
F

a
t
a
D
n
w
O

n
o
i
s
s
e
r
g
e
r

c
i
t
s
i
g
o
l

-
c
a
t
n
y
s

,
s
o
p

,
a
m
m
e
l

:
s
e
r
u
t
e
F

L
M

d
n
a

l
a
c
i
x
e
l

s
t
p
e
c
n
o
C

q
e
R
a

c
i
t
n
a
m
e
S
s
o
l
u
o
p
o
t
n
a
m
a
i
D

r
e
ﬁ
i
s
s
a
l
c

s
n
o
i
t
a
l
e
r

y
c
n
e
d
n
e
p
e
d

c
i
t

c
i
t
c
a
t
n
y
s

-
a
l
e
R

+

-
a
L

e
l
o
R

]
2
8
[

.
l
a

t
e

s
e
r
u
t
a
e
f

s
n
o
i
t

g
n
i
l
e
b

5
8
.
0
:
1
F

n
w
O

m
u
m
i
x
a
m

e
h
T

;
s
g
a
t

s
o
p

;
s
a
m
m
e
l

:
s
e
r
u
t
e
F

L
M

-
y
g
o
l
o
t
n
o

c
i
t
n
a
m
e
s

q
e
R
a

c
i
t
n
a
m
e
S

.
l
a

t
e

g
n
a
W

t
e
s
a
t
a
D

r
e
ﬁ
i
s
s
a
l
c

y
p
o
r
t
n
e

g
n
i
s
r
a
p

;
s
s
a
l
c
b
r
e
V

;
g
n
i
k
n
u
h
c

d
e
s
a
b

s
e
l
o
r

-
a
L

e
l
o
R

]
3
8
[

g
n
i
s
u
s
e
r
u
t
e
f

e
s
n
e
s
d
r
o
w

;
e
e
r
t

-
l
o
t
n
o

n
i
a
m
o
d

d
n
a

t
e
N
d
r
o
w

y
g
o

g
n
i
l
e
b

;
3
9
.
0
-
2
9
.
0

:

P

S
R
S

8
1

r
e
ﬁ
i
s
s
a
l
c
T
D

,
g
n
i
g
g
a
t

s
o
p

,
n
o
i
t
a
z
i
n
e
k
o
t

L
M

d
n
a

l
a
c
i
x
e
l

c
i
t
n
a
m
e
s

S
R
S

c
i
t
n
a
m
e
S

.
l
a

t
e

g
n
a
W

2
9
.
0
-
1
9
.
0

:

R

R
E
N

,
g
n
i
s
r
a
p

c
i
t
c
a
t
n
y
s

s
e
r
u
t
a
e
f

s
e
l
o
r

-
a
L

e
l
o
R

]
1
8
[

g
n
i
l
e
b

30

i
k
i
w
n
o

d
e
s
a
b

s
u
p
r
o
c

c
ﬁ
i
c
e
p
s

s
n
u
o
n

d
e
t
c
a
r
t
x
e

d
n
a

:

R

;
0
8
.
0

:

P

s
q
e
R

0
2

d
n
a

s
e
l
u
r

f
o

t
e
s

a

,
r
e
g
g
a
T

S
O
P

,
r
e
z
i
n
e
k
o
T

9
8
.
0

s
t
n
e
m
u
c
o
d

s
c
i
t
s
i
r
u
e
h

-
n
i
a
m
o
d

,
r
e
s
r
a
p

,
r
e
z
i
t
a
m
m
e
L

d
e
s
a
b

e
l
u
r

-
y
g
o
l
o
t
n
o

-
i
b
m
a

s
i

q
e
R
a

y
t
i
u
g
i
b
m
A

.
l
a

t
e

i
n
i
z
z
E

d
e
s
a
b

?
s
u
o
i
g

n
o
i
t
c
e
t
e
D

]
9
0
1
[

7
5
.
0
-
2
5
.
0

:

s
t
p
e
c
n
o
c

e
t
a
d

s
e
r
u
t

s
e
r
u
t
a
e
f

s
u
o
m
y
n
o

n
o
i
s
i
c
e
r
p

e
g
a

)
s
q
e
r

9
5
4
(

-
i
d
n
a
c

t
c
a
r
t
x
e

o
t

-
a
e
f

d
e
s
a
b

n
r
e
t
t
a
p

,
s
e
r
u
t
a
e
f

d
e
s
a
b

c
i
t
c
a
t
n
y
s

-
n
y
S

d
n
a

s
q
e
R

n
o
i
t
c
e
t
e
D

-
r
e
v
a

n
a
e
M

s
t
c
e
j
o
r
p

4

d
o
h
t
e
m

e
u
l
a
v
-
C

l
a
u
t
x
e
t
n
o
c

,
s
e
r
u
t
a
e
f

l
a
c
i
x
e
l

e
l
u
r

d
n
a

l
a
c
i
x
e
l

d
e
d
a
o
l
r
e
v
O

f
o

t
e
s

a

y
t
i
u
g
i
b
m
A

t
e

g
n
a
W

]
3
9
[
.
l
a

-
u
g
i
b
m
a

y
t
i

-
i
c
e
r
p

5
6
.
0
:
P

-
e
r

6
2
1

s
c
i
t
s
i
r
u
e
h

f
o

t
e
s

g
n
i
s
r
a
p

c
i
t
c
a
t
n
y
s

e
l
u
r

d
n
a

l
a
c
i
x
e
l

g
n
i
v
l
o
s
e
r

q
e
R
a

y
t
i
u
g
i
b
m
A

.
l
a

t
e

a
m
a
s
O

9
9
.
0
:
R

,
n
o
i
s

s
t
n
e
m
e
r
i
u
q

d
e
s
a
b

c
i
t
c
a
t
n
y
s

c
i
t
c
a
t
n
y
s

n
o
i
t
c
e
t
e
D

]
8
0
1
[

s
e
r
u
t
a
e
f

-
u
g
i
b
m
a

y
t
i

6
.
0

:
1
F

s
q
e
r

5
6

d
e
s
a
b
-
y
t
i
r
a
l
i

m
i
S

-
x
e

s

m
r
e
t

,
g
n
i
g
g
a
T

S
O
P

e
l
u
r

-
d
o
m

c
i
p
o
T

s
e
s
a
i
l
a

q
e
R
a

y
t
i
u
g
i
b
m
A

l
a

t
e

a
r
s
i

M

h
c
a
o
r
p
p
a

-
e
r

s
d
r
o
w

p
o
t
s

,
n
o
i
t
c
a
r
t

d
e
s
a
b

g
n
i
l
e

-
i
b
m
a
s
i
d

n
o
i
t
c
e
t
e
D

]
7
0
1
[

-

f
o

f
o
o
r
p

-
n
o
c

e
h
t

s
e
k
a
t

d
e
t
a
l
e
r

n
i
a
m
o
d

a

d
l
i
u
B

t
p
e
c
n
o
c

s
e
h
c
r
a
e
s

,
s
t
p
e
c

s
h
p
a
r
g

e
g
d
e
l
w
o
n
k

d
e
s
a
b

e
l
u
r

-
y
g
o
l
o
t
n
o

t
c
e
t
e
d

f
o

t
e
s

a

y
t
i
u
g
i
b
m
A

.
l
a

t
e

i
r
a
r
r
e
F

d
e
s
a
b

-
u
g
i
b
m
a

s
q
e
R

n
o
i
t
c
e
t
e
D

]
0
1
1
[

-
ﬁ
i
t
n
e
d
i

g
n
i
l
l
e
p
s
s
i

m

,
l
a
v
o
m

,
n
o
i
t
a
c
ﬁ
i
t
n
e
d
i

s
e
s
a
i
l
a

,
n
o
i
t
a
c

A
S
L

y
t
i
u
g

31

n
a

h
t
i
w

s
h
t
a
p

t
p
e
c
n
o
c

r
o
f

e
l
p
m
a
x
e

h
c
a
e

n
i
h
t
i
w

e
r
a
p
m
o
c

,
h
p
a
r
g

s
h
t
a
p

y
t
i

-

-
x
e

f
o

t
e
s

a

h
c
i
h
w

t
u
o

d
n
ﬁ

n
o
i
t
a
u
t
c
n
u
P

,
n
o
i
t
a
z
i
n
e
k
o
T

e
l
u
r

d
e
c
n
a
v
d
a

n
i
a
m
o
d

-
r
o
c

2

y
t
i
u
g
i
b
m
A

.
l
a

t
e

a
r
h
s
i

M

s
e
l
p
m
a

y
l
n
o
m
m
o
c

e
h
t

f
o

,
l
a
v
o
m
e
r

d
r
o
w

p
o
t
S
,
l
a
v
o
m
e
R

d
e
s
a
b

g
n
i
d
d
e
b
m
e

c
ﬁ
i
c
e
p
s

:
s
e
s
u
p

n
o
i
t
c
e
t
e
D

]
4
0
1
[

s
d
r
o
w

S
C

d
e
s
u

-
a
z
i
t
a
m
m
e
L

,
g
n
i
g
g
a
T

S
o
P

t
n
e
r
e
ﬀ
i
d

a

e
v
a
h

m
o
r
f

c
e
v
2
d
r
o
w

n
r
a
e
l

,
n
o
i
t

g
n
i
n
a
e
m

s
u
p
r
o
c

h
c
a
e

S
C

s
u
o

t
o
n
/
d
e
t
a
l

-
u
g
i
b
m
a

-
e
r

s
d
r
o
w

d
e
t
a
l
e
r

e
h
t

o
t

n
i
a
m
o
d

m
u
m
i
x
a
M

m
o
r
f

a
t
a
d

:
n
i
a
m
o
d

h
c
a
e

r
o
F

t
c
a
r
t
x
e

o
t

a
i
d
e
p
i
k
i
W

l

w
a
r
c

e
l
u
r

d
e
c
n
a
v
d
a

s
u
o
u
g
i
b
m
a

s
e
s
u
p
r
o
c

y
t
i
u
g
i
b
m
A

.
l
a

t
e

i
r
a
r
r
e
F

e
s
u

d
n
a

,
s
e
c
n
e
t

d
n
a

e
u
l
a
v
-
C

-
n
a
m
e
s

t
e
N
d
r
o

W

o
t

y
t
i
r
a
l
i

m

i
s

c
i
t

m
e
h
t

r
e
t
s
u
l
c

e
u
l
a
V
C

-

-

-
x
e

f
o

t
e
s

a

:

m
r
e
t

h
c
a
e

r
o
F

-
x
e

,
n
o
i
t
a
z
i
n
e
k
o
t

e
c
n
e
t
n
e
s

s
e
l
p
m
a

-
n
e
s

d
e
t
a
l
e
r

t
e
g

,
t
e
N
d
r
o
w

g
n
i
s
u

s

m
r
e
t

t
c
a
r
t

d
e
s
a
b

e
l
u
r

-
y
g
o
l
o
t
n
o

d
e
s
a
b

t
c
e
t
e
d

-

m
a

s
u
o
u
g
i
b

s

m
r
e
t

S
R
S

y
t
i
u
g
i
b
m
A

t
e

a
k
o
u
s
t
a
m

n
o
i
t
c
e
t
e
D

]
5
0
1
[

.
l
a

r
a
l
i

m

i
s

p
o
t

f
o

h
c
a
e

r
o
f

s
d
r
o
w

e
r
a
p
m
o
C

.
n
u
o
n

o
t

s
d
r
o
w

r
a
l
i

m

i
s

y
t
i
u
g
i
b
m
a

d
n
ﬁ

n
o
i
t

8
8

f
o

u
a
T

t
e
s

a

d
n
ﬁ

,
s
n
u
o
n

-
a
r
e
n
e
G

s
l
e
d
o
M

e
g
a
u
g
n
a
L

s
’
l
l
a
d
n
e
K

s
n
i
a
m
o
d

5

.
q
e
r
f

t
s
o
m

d
n
ﬁ

;
s
t
n
e
m
u
c
o
d

c
ﬁ
i
c
e
p
s

n
i
a
m
o
d

d
e
s
a
b

g
n
i
d
d
e
b
m
e

s

m
r
e
t

m
o
r
f

-
f
i
d

t
n
e
r
e
f

-
o
d

s
n
i
a
m

n
o
i
t
c
e
t
e
D

]
6
0
1
[

7
8
.
0

:
c
c
A

E
S
O
C
N

I

,

T
R
A
P

,
*
5
.
4
C

-
e
r

t
a
h
t

s
c
i
r
t
e
m

y
t
i
l
a
u
q

4
2

L
M

d
n
a

l
a
c
i
x
e
l

d
o
o
G

f
o

t
e
s

a

l
a
r
e
n
e
G

.
l
a

t
e

a
r
r
a
P

s
u
p
r
o
c

d
n
a

g
n
i
g
g
a
B
h
t
i
w

-
n
i

c
i
t
c
a
t
n
y
s

d
n
a

l
a
c
i
x
e
l

t
c
e
ﬂ

c
i
t
c
a
t
n
y
s

d
a
B

r
o

s
q
e
r

g
n
i
t
s
o
o
B

n
o
i
t
a
m
r
o
f

s
e
r
u
t
a
e
f

u
q
e
R

-
s
s
e
s
s
A

t
n
e
m

]
8
1
1
[

;
9
5
.
0

:

P

s
q
e
r

1
7
4
1

d
n
a

s
e
l
u
r

f
o

t
e
s

a

-
a
z
i
t
a
m
m
e
L

;
g
n
i
g
g
a
T

S
O
P

e
l
u
r

d
n
a

l
a
c
i
x
e
l

y
t
i
l
a
u
q

f
o

t
e
s

a

l
a
r
e
n
e
G

t
e

r
e
m
m
e
F

2
8
.
0
:
R

s
c
i
t
s
i
r
u
e
h

n
o
i
t

d
e
s
a
b

c
i
t
c
a
t
n
y
s

s
e
r
o
c
s

s
q
e
R

s
e
r
u
t
a
e
f

-
s
s
e
s
s
A

t
n
e
m

]
2
0
1
[

.
l
a

;
3
8
.
0

:

P

t
o
l
i

P
-
D

d
n
a

s
e
i
t
a
n
o
i
t
c
i
d

;
g
n
i
g
g
a
T

S
O
P

;
n
o
i
t
a
z
i
n
e
k
o
T

e
l
u
r

d
n
a

l
a
c
i
x
e
l

s
e
p
y
t

0
1

-
e
R

a

l
a
r
e
n
e
G

.
l
a

t
e

i
r
a
r
r
e
F

5
8
.
0
:
R

-

D

d
n
a

s
e
l
u
r

;
s
r
e
t
t
e
z
a
G

;
g
n
i
s
r
a
P

w
o
l
l
a
h
S

d
e
s
a
b

c
i
t
c
a
t
n
y
s

s
t
c
e
f
e
d

f
o

e
g
r
a
L

;
s
e
l
u
r

E
P
A
J

s
e
r
u
t
a
e
f

-
e
r
i
u
q

t
n
e
m

-
s
s
e
s
s
A

t
n
e
m

]
3
0
1
[

:

P

;
5
2
.
0

:

R

a
t
a
d

1
5
.
0

s
t
e
s

8
2

e
h
t

-
e
b

e
t
a
l
u
c
l
a
c

y
t
i
r
a
l
i

m

i
s

e
r
o
c
s

n
e
h
t

s

m
r
e
t

n
e
e
w
t

r
i
e
h
t

g
n
i
s
u

n
e
e
w
t
e
b

t
x
e
t
n
o
c

o
i
.
l
a
c
i
t
r
o
C

s
e
r
u
t
a
e
f

s

m
r
e
t

c
i
t
c
a
t
n
y
s

d
n
a

l
a
c
i
x
e
l

e
l
u
r

d
n
a

l
a
c
i
x
e
l

-
r
a
e
n

f
o

t
e
s

a

y
t
i
u
g
i
b
m
A

t
e

z
a
i
p
l
a
D

d
e
s
a
b

c
i
t
c
a
t
n
y
s

s

m
y
n
o
n
y
s

s
q
e
R

n
o
i
t
c
e
t
e
D

]
4
4
1
[

.
l
a

32

.
g
i
b
m
A

)
8
7
.
0
(

-
e
r
i
u
q
e
r

t
c
e
f
e
d

e
m
o
s

e
v
l
o
s

s
t
n
e
m

s
e
s
a
c

t
e
N
d
r
o

W

t
c
e
f
e
d

s
e
s
a
c

n
o
i
t
c
e
t
e
D

y
t
i
u
g
i
b

-
n
I

:
1
F

-
e
s

0
0
4

-
e
d
e
r
p

f
o

t
e
s

a

-
p
o
t
S

;
g
n
i
l
e
b
a
L

c
i
t
n
a
m
e
S

;
)
6
7
.
0
(
.
p
m
o
c

d
e
t
c
e
l

o
t

s
e
l
u
r

d
e
n
ﬁ

;
g
n
i
g
g
a
t
S
O
P

;
l
a
v
o
m
e
r

s
d
r
o
w

d
e
s
a
b

e
l
u
r

-
y
g
o
l
o
t
n
o

-
e
r
p

e
v
l
o
s

q
e
R
a
s
s
e
n
e
t
e
l
p
m
o
c
n
I

t
e

r
e
m
u
a
B

d
e
s
a
b

d
e
n
ﬁ
e
d

-

m
A

d
n
a

]
3
1
1
[

.
l
a

;
4
3
.
0

:

P

y
d
u
t
s

t
o
l
i
p

-
S
O
P

,
r
e
r
t
i
l
p
s

e
c
n
e
t
n
e
s

e
l
u
r

d
n
a

l
a
c
i
x
e
l

?
e
u
g
a
v

s
i

q
e
R
a

s
s
e
n
e
u
g
a
V

.
l
a

t
e

z
u
r
C

4
9
.
0
:
R

d
n
a

s
e
v
i
t
c
e
j
d
a

t
e
g

,
g
n
i
g
g
a
t

d
e
s
a
b

c
i
t
c
a
t
n
y
s

n
o
i
t
c
e
t
e
D

]
7
1
1
[

r
e
d
o
c
n
e

s
q
e
r

c
e
v
2
t
n
e
s

s
t
h
g
u
o
h
t
-
p
i
k
s

;
n
o
i
t

t
n
e
m

2
5
.
0
:
1
F

f
o

t
e
s

a

d
e
s
a
b
-
h
p
a
r
g

a

p
o
t
S

,
S
O
P

,
n
o
i
t
a
z
i
n
e
k
o
T

L
M

d
e
c
n
a
v
d
a

-

m
o
c
n
i

s
i

S
R
S
s
s
e
n
e
t
e
l
p
m
o
c
n
I

.
l
a

t
e

u
i
L

e
c
a
p
s
o
r
e
a

g
n
i
r
e
t
s
u
l
c

-
a
z
i
t
a
m
m
e
L

;
l
a
v
o
m
e
r

s
d
r
o
w

g
n
i
d
d
e
b
m
e

?
e
t
e
l
p

-
u
c
o
D

n
o
i
t
c
e
t
e
D

]
2
1
1
[

s
e
u
l
a
V

C
N
C

-

n
o

d
e
s
a
b

)
n
u
o
n
+
e
v
i
t

s
e
r
u
t
a
e
f

-

y
d
u
t
s

t
o
l
i
p

-

m
o
c

e
t
a
l
u
c
l
a
c

t
c
a
r
t
x
e

,
g
n
i
g
g
a
T

S
O
P

e
l
u
r

d
n
a

l
a
c
i
x
e
l
s
s
e
n
e
t
e
l
p
m
o
C

f
o

t
e
s

a
s
s
e
n
e
t
e
l
p
m
o
c
n
I

.
l
a

t
e

i
r
a
r
r
e
F

e
r
o
c
s

s
s
e
n
e
t
e
l
p

-
c
e
j
d
a
(

s
n
r
e
t
t
a
p

d
e
s
a
b
-
S
O
P

d
e
s
a
b

c
i
t
c
a
t
n
y
s

e
r
o
c
s

s
q
e
R

n
o
i
t
c
e
t
e
D

]
1
1
1
[

-
k
c
a
l
b

a

h
c
t
a
m

t
a
h
t

s
b
r
e
v
d
a

r
o

s

m
r
e
t

e
u
g
a
v

n
w
o
n
k

f
o

t
s
i
l

t
s
i
l
e
t
i
h
w

a

h
c
t
a
m

t
o
n

s
e
o
d

.
s

m
r
e
t

e
u
g
a
v

t
o
n

f
o

s
e
r
u
t
a
e
f

33

s
p
e
t
s

g
n
i
s
s
e
c
o
r
P

s
e
r
u
t
a
e
f

d
e
s
a
b

.
s
q
e
r

-
t
s
o
P

f
o

t
e
s

a

-
y
c
n
e
u
q
e
r
f

,
s
e
r
u
t
a
e
f

c
i
t
n
a
m
e
s

s
e
r
u
t
a
e
f

-
u
c
o
d

t
n
e
m

0
.
1
-
6
9
.
0

:
2
F

s
e
s
a
c

t
s
e
t

4

n
o
d
e
s
a
b
p
x
E
q
e
R

;
g
n
i
g
g
a
t

S
O
P

;
n
o
i
t
a
z
i
n
e
k
o
T

e
l
u
r

d
n
a

l
a
c
i
x
e
l
e
c
n
a
m
r
o
f
n
o
C

q
e
R
a

e
c
n
a
m
r
o
f
n
o
c

.
l
a

t
e

a
r
o
r
A

g
n
i
h
c
t
a
m
n
r
e
t
t
a
p

g
n
i
k
n
u
h
C

;

R
E
N

d
e
s
a
b

c
i
t
c
a
t
n
y
s

t
o
N
r
o

-

m
e
t

h
t
i
w

]
4
1
1
[

s
e
r
u
t
a
e
f

s
e
t
a
l
p

:

R

,
1
8
.
0

:

P

-
s
u
d
n
i

3
3

-
n
e
s

t
s
o
c

h
t
i
w
F
R

d
e
s
a
b
-
n
e
k
o
t

:
s
e
r
u
t
a
e
F

0
2

L
M

d
n
a

l
a
c
i
x
e
l

r
o

q
e
R

-
x
e
t

a

n
o
i
t
c
a
r
t
x
E

a
j
i
a
h
l
a
u
b
A

5
9
.
0

f
o

t
e
s

l
a
i
r
t

+

g
n
i
n
r
a
e
l

e
v
i
t
i
s

,
s
e
r
u
t
a
e
f

c
i
t
c
a
t
n
y
s

,
s
e
r
u
t
a
e
f

c
i
t
c
a
t
n
y
s

q
e
R
t
o
N

l
a
u
t

s
c
o
D
m
o
r
f

]
6
9
[

.
l
a

t
e

9
8
.
0
-
4
6
.
0

:

R

t
e
s
a
t
a
d

n
r
e
t

d
e
s
a
b

c
i
t
c
a
t
n
y
s

q
e
R
t
o
N

s
c
o
D
m
o
r
f

]
5
9
[

;
0
.
1
-
4
6
.
0
:
P

E
R
U
P

-
t
a
p

g
n
i
g
g
a
t

S
O
P

g
n
i
k
n
u
h
c

,
g
n
i
g
g
a
T
S
O
P

e
l
u
r

d
n
a

l
a
c
i
x
e
l

r
o

q
e
R

S
R
S

n
o
i
t
c
a
r
t
x
E

l
a

t
e

s
i
r
a
H

2
9
.
0
:
1
F

l
a
i
r
t
s
u
d
n
i

-
t
a
p

l
a
c
i
t
c
a
t
n
y
S

-
c
a
r
t
x
e

s

m
r
e
t

;
g
n
i
g
g
a
t

S
O
P

e
l
u
r

d
n
a

l
a
c
i
x
e
l

f
o

t
s
i
l

r
e
s
u

n
o
i
t
c
a
r
t
x
E

r
y
a
m
h
c
r
i
u
Q

e
s
a
c

s
n
r
e
t

d
e
s
a
b
-
n
r
e
t
t
a
P

;
g
n
i
s
r
a
p

;

n
o
i
t

d
e
s
a
b

c
i
t
c
a
t
n
y
s

s
e
r
u
t
a
e
f

l
a
u
n
a
m

s
c
o
D
m
o
r
f

]
4
9
[

.
l
a

t
e

s
e
r
u
t
a
e
f

n
o
i
t
c
e
r
r
o
c

d
n
a

s
n
o
i
t
a
m
r
o
f
s
n
a
r
t

e
e
r
t

e
s
r
a
p

s
e
r
u
t
a
e
f

:
c
c
A

g
v
A

-
4
5
.
0

g
v
A

;
1
8
.
0

2
9
.
0
-
3
7
.
0
:
P

:

R

e
g
r
e

M
n
i
W

-
x
E

h
c
t
a
M

1
F

t
c
a

h
c
t
a
M

l
a
i
t

r
o
f

5
2
1
(

)
2
6
.
0
(

)
h
c
a
e

-
r
a
P

;
)
6
4
.
0
(

s
p
p
A

8

r
o
f

s
e
i
r
a
d
n
u
o
b

t
e
s
a
t
a
d

l
e
b
a
l

o
t

s
n
o
i
t
a
t

g
n
i
d
d
e
b
m
e

:
l
l
a
c
e
r

g
v
A

u
t
n
u
b
U

6
8
.
0

y
t
i
n
u
m
m
o
c

s
e
r
u
t
a
e
f

6
8
.
0

:
1
F

S
R
S

2
2

-

F
R
C
M
T
S
L
-
i

B

-
a
z
i
t
a
m
m
e
l

,
n
o
i
t
a
z
i
n
e
k
o
T

L
M

d
n
a

l
a
c
i
x
e
l
s
t
n
e
m
e
r
i
u
q
e
r

-
x
e
t

a

n
o
i
t
c
a
r
t
x
E

.
l
a

t
e

g
n
a
W

s
t
n
e
m
u
c
o
d

-
n
e
p
e
d

,
g
n
i
g
g
a
t

s
o
p

,
n
o
i
t

g
n
i
s
r
a
p

y
c
n
e
d

c
i
t
c
a
t
n
y
s

s
e
r
u
t
a
e
f

-
u
c
o
d

t
n
e
m

l
a
u
t

s
c
o
D
m
o
r
f

]
3
9
[

-
i
c
e
r
p

g
v
A

s
l
i
a
m
e

7
1
3

-
e
s

c
i
t
n
a
m
e
s

0
1

s
e
l
u
r

y
z
z
u
f

1
8

e
l
u
r

d
n
a

l
a
c
i
x
e
l

e
r
u
t
a
e
F

g
n
i
l
i
a
M

n
o
i
t
c
a
r
t
x
E

.
l
a

t
e

i
h
S

6
7
.
0

:
n
o
i
s

m
o
r
f

s
n
r
e
t
t
a
p

e
c
n
e
u
q

d
e
s
a
b

c
i
t
c
a
t
n
y
s

s
t
s
e
u
q
e
r

t
s
i
l

s
c
o
D
m
o
r
f

]
2
9
[

s
w
e
i
v
e
r

-
o
n
n
a

O

,
I
,
B

e
s
u

T
R
E
B

,
n
o
i
t
a
z
i
n
e
k
o
t

L
M

d
e
c
n
a
v
d
a

t
c
a
r
t
x
e

-
e
r

r
e
s
u

n
o
i
t
c
a
r
t
x
E

]
4
8
[

.
l
a
t
e

e
D

t
n
e
s
e
r
p
e
r

e
r
u
t
a
e
f

a

k
n
u
h
c

h
c
i
h
w

w
e
i
v

-
e
R

m
o
r
f

s
w
e
i
v

,
x
i
r
t

)
g
v
a

2
8
.
0
(

s
e
c
n
e
t

s
e
r
u
t
a
e
f

-
a
M

t
n
e
m
u
c
o
D
m
r
e
T

-

,

F
D

I

s
w
e
i
v

2
6
.
0
(

7
8
.
0

:

P

e
r
a
w
t
f
o
s

2
3

-
t
a
p

c
i
t
c
a
t
n
y
s

-
a
m
m
e
l

,
l
a
v
o
m
e
r

s
d
r
o
w

p
o
t
s

e
l
u
r

-
d
o
m

c
i
p
o
T

s
e
r
u
t
a
e
f

-
e
r

r
e
s
u

n
o
i
t
c
a
r
t
x
E

.
l
a

t
e

r
a
k
a
B

6
8
.
0

:

R

;
)
g
v
a

-
n
e
s

3
5
2
1

/

t
c
a
r
t
x
e

o
t

s
n
r
e
t

-
F
T

,
g
n
i
g
g
a
t

s
o
p

,
n
o
i
t
a
z
i
t

d
e
s
a
b

g
n
i
l
e

w
e
i
v

-
e
R

m
o
r
f

]
5
8
[

:

R

;
0
9
.
0

:

P

8
.
0
-
5
.
0

t
e
s

7
2
3

a
t
a
d

g
n
i
l
e
d
o
m

c
i
p
o
t

-
e
r

s
d
r
o
w

p
o
t
s

,
n
o
i
t
a
z
i
n
e
k
o
t

L
M

-
d
o
m

c
i
p
o
T

-
p
o
t
n
i
a
m

r
e
s
u

n
o
i
t
c
a
r
t
x
E

t
e

o
n
e
r
r
a
C

f
o

t
n
e
m

i
t
n
e
s

d
n
a

,
l
a
v
o
m

g
n
i
l
e

s
c
i

-
d
e
e
f

-
e
R

m
o
r
f

]
6
8
[

.
l
a

s
t
n
e
m
m
o
c

s
i
s
y
l
a
n
a

k
c
a
b

s
w
e
i
v

s
e
r
u
t
a
e
F

:
1
F

e
e
r
h
T

B
N

,
*
M
V
S

-
s
i
l
i
b
a
b
o
r
p

a

d
e
s
a
b

:

F
O
B
)
1
(

L
M

M
S
V

r
o

s
g
u
b

-
e
r

r
e
s
u

n
o
i
t
c
a
r
t
x
E

.
l
a

t
e

a
h
J

s
g
u
B

;
)
5
7
.
0
(

f
o

s
t
e
s
a
t
a
d

)
5
8
.
0
(

s
w
e
i
v
e
r

.
r
e
s
r
a
p

c
i
t
n
a
m
e
s

e
m
a
r
f

c
i
t

W
O
B

,
r
e
m
m
e
t
S

:

W
O
B
)
2
(

s
e
r
u
t
a
e
f

w
e
i
v

-
e
R

m
o
r
f

]
7
8
[

s
w
e
i
v

34

g
v
A

;
7
7
.
0

,
e
l
b
m
u
M

s
n
r
e
t
t
a
p

c
i
t
c
a
t
n
y
s

d
n
a

c
i
t
c
a
t
n
y
s

-
e
r

r
e
s
u

s
t
s
e
u
q

-
e
R

m
o
r
f

,
s
s
a
P
e
e
K

B
N

,

N
N
K

,
*
M
V
S

l
a
c
i
x
e
l

;

E
D

I
-
F
T

;

m
a
r
g
i
n
U

L
M

d
n
a

l
a
c
i
x
e
l

y
f
i
s
s
a
l
c

-
e
r

r
e
s
u

n
o
i
t
c
a
r
t
x
E

]
8
8
[

.
l
a

t
e

i

L

s
e
p
y
t

8

s
e
r
u
t
a
e
f

o
t

s
t
s
e
u
q

s
w
e
i
v

1
7
.
0

:
1
F

-
n
e
s

0
0
0
4

,
8
4
J

,
s
e
y
a
B
e
v
i
a
N

o
t

c
e
v
2
d
r
o
w

d
e
s
u

r
e
p
a
p

e
h
t

L
M

d
e
c
n
a
v
d
a

s
w
e
i
v
e
r

4

-
e
r

r
e
s
u

n
o
i
t
c
a
r
t
x
E

]
3
6
[

.
l
a

t
e
u
L

s
e
c
n
e
t

*
g
n
i
g
g
a
B
d
n
a

W
o
B
R
U
A

-

:
e
c
u
d
o
r
p

g
n
i
d
d
e
b
m
e

.
s
e
s
s
a
l
c

w
e
i
v

-
e
R

m
o
r
f

s
w
e
i
v

2
8
.
0

:

F

-
e
r

4
2
9
1

s
e
y
a
B
e
v
i
a
N

-
g
a
t

s
o
p

,
g
n
i
s
s
e
c
o
r
p

l
a
c
i
x
e
l

L
M

d
n
a

l
a
c
i
x
e
l

e
r
u
t
a
e
f

-
e
r

r
e
s
u

n
o
i
t
c
a
r
t
x
E

.
l
a

t
e

g
n
e
P

s
w
e
i
v

r
e
s
r
a
p

y
c
n
e
d
n
e
p
e
d

,
g
n
i
g

c
i
t
c
a
t
n
y
s

s
t
s
e
u
q
e
r

s
w
e
i
v

-
e
R

m
o
r
f

]
9
8
[

s
e
r
u
t
a
e
f

s
w
e
i
v

2
7
.
0

:
1
F

r
o
f

s
w
e
i
v
e
r

F
R

t
n
e
m

i
t
n
e
s

,
g
n
i
t
t
i
l
p
s

e
c
n
e
t
n
e
S

L
M

d
n
a

l
a
c
i
x
e
l

s
e
r
u
t
a
e
f

-
e
r

r
e
s
u

n
o
i
t
c
a
r
t
x
E

.
l
a

t
e

g
n
a
Y

s
t
c
u
d
o
r
p

6

-

m
e
t
s

,
g
n
i
g
g
a
t

S
O
P

,
s
i
s
y
l
a
n
a

g
n
i
m

c
i
t
c
a
t
n
y
s

s
e
r
u
t
a
e
f

s
w
e
i
v

s
w
e
i
v

-
e
R

m
o
r
f

]
0
9
[

8
7
.
0

:
1
F

p
p
a

0
0
2

n
o
i
s
s
e
r
g
e
r

A

,
g
n
i
g
g
a
t

s
o
p

,
n
o
i
t
a
z
i
n
e
k
o
t

L
M

d
e
c
n
a
v
d
a

y
e
k

s
w
e
i
v
e
r

n
o
i
t
c
a
r
t
x
E

.
l
a

t
e

u
W

.
s
w
e
i
v
e
r

s
e
r
u
t
a
e
f

s
w
e
i
v

M
1
,
1

h
t
i
w

y
f
i
t
n
e
d
i

o
t

l
e
d
o
m

T
R
E
B

,
g
n
i
s
r
a
p

y
c
n
e
d
n
e
p
e
d

g
n
i
d
d
e
b
m
e

s
e
r
u
t
a
e
f

-
e
R

m
o
r
f

]
1
9
[

5
1
@
t
i
H

-
o
n
n
a

3
3
5

-
h
c
e
t

g
n
i
r
e
t
s
u
l
c

A
D
L
+
W
O
B

L
M

-
d
o
m

c
i
p
o
T

d
e
t
s
e
g
g
u
.
o
s
p
e
r
+
s
r
u
t
a
e
f

n
o
i
t
c
a
r
t
x
E

.
l
a

t
e

g
n
a
i
J

%
8
7

m
o
r
f

s
e
r
u
t

s
p
p
a

0
0
1

o
t

p
u

:
e
r
o
c
s

-
a
e
f

d
e
t
a
t

e
u
q
i
n

g
n
i
l
e

w
e
n

-

m

i
s

f
o

s
e
r
u
t
a
e
f

r
a
l
i

-
a
c
i
l
p
p
a

s
n
o
i
t

r
a
l
i

m
i
S

m
o
r
F

s
p
p
A

]
9
9
[

4
7
.
0

:
c
c
A

-
e
r

8
8
1

-
e
r

g
n
i
r
e
t
s
u
l
c

-
g
a
t

s
o
p

,
l
a
v
o
m
e
r

s
d
r
o
w
p
o
t
S

L
M

M
S
V
d
e
d
n
e
m
m
o
c
e
r

s
u
p
r
o
c

n
o
i
t
c
a
r
t
x
E

t
e

s
a
b
b
A

o
t

s
r
u
o
b
h
g
i
e
N

s
q
e
r

d
n
e
m
m
o
c
e
r

s
t
n
e
m
e
r
i
u
q

e
s
u

+
s
t
n
e
m
e
r
i
u
q

F
D

I
-
F
T

,
n
o
i
t
a
z
i
t
a
m
m
e
L

,
r
e
g

t
n
e
m

-
e
r
i
u
q
e
r

s
q
e
r

f
o

r
a
l
i

m
i
S

m
o
r
F

s
p
p
A

]
0
0
1
[
.
l
a

-
l
a
v
e

n
a
m
u
H

-
s
y
s

1
7
5

d
e
s
a
b

g
n
i
r
e
t
s
u
l
c

,
n
o
i
t
a
z
i
n
e
k
o
t

,
g
n
i
m
m
e
t
s

L
M

d
e
c
n
a
v
d
a

d
e
t
s
e
g
g
u
s

f
o

t
e
s

n
o
i
t
c
a
r
t
x
E

.
l
a

t
e

o
D

6
6
.
0

:
1
F

s
t
c
e
j
o
r
p

4

5
.
4
C

;

P
N

:
g
n
i
d
u
l
c
n
i

s
e
r
u
t
a
e
f

L
M

d
n
a

l
a
c
i
x
e
l

n
o
i
t
c
n
u
F

f
o

t
e
s

a

-
i
t
s
E
t
r
o
ﬀ
E

t
e

n
i
a
s
s
u
H

n
o
i
t
a
u

m
o
r
f

s

m
e
t

-
o
g
l
a

H
C
R
I
B

g
n
i
g
g
a
t

S
O
P

,
c
e
v
2
c
o
d

g
n
i
d
d
e
b
m
e

w
e
n

-
e
r
i
u
q
e
r

s
n
i
a
m
o
d

3

m
h
t
i
r

s
t
n
e
m

-
e
r
i
u
q
e
r

s
t
n
e
m

r
a
l
i

m
i
S

m
o
r
F

s
p
p
A

]
1
0
1
[

35

s

m
r
o
f
r
e
p
t
u
o

3
1
3
,
3
2

-
r
u
c
e
r

d
n
a
M
T
S
L

g
n
i
d
d
e
b
m
e

d
r
o
w

L
M

d
e
c
n
a
v
d
a

y
r
o
t
ss
t
n
e
m
e
r
i
u
q
e
r

-
i
t
s
E
t
r
o
ﬀ
E

l
u
k
i
t
r
e
i
k
t
e
o
h
C

n
o
m
m
o
c

3

s
e
u
s
s
i

-
t
e
n

y
a
w
h
g
i
h

t
n
e
r

s
e
n
i
l
e
s
a
b

k
r
o
w

g
n
i
d
d
e
b
m
e

s
t
n
i
o
p

n
o
i
t
a
m

]
7
3
1
[
.
l
a

t
e

s
e
i
d
u
t
s

e
u
q
i
n
h
c
e
t

W
O
B

,
l
a
v
o
m

-
f
i
d

r
u
o
f

-
a
e
r

d
e
s
a
b
-
e
s
a
c

,
g
n
i
g
g
a
t

S
O
P

,
n
o
i
t
a
z
i
n
e
k
o
T

e
s
a
c

t
n
e
r
e
f

)
R
B
C
(

g
n
i
n
o
s

-
e
r

s
d
r
o
w

p
o
t
S

,
g
n
i
m
m
e
t
S

d
e
s
a
b

e
l
u
r

M
S
V

y
t
i
r
o
i
r
p

f
o

t
e
s

n
o
i
t
a
z
i
t
i
r
o
i
r
P

.
l
a

t
e

i
l

A

-
e
r
i
u
q
e
r

s
t
n
e
m

]
2
3
1
[

;
s
b
r
e
V

e
v
i
t
c
A

;
s
e
s
e
h
t
n
e
r
a
P

-
n
o
C

;
s
e
s
e
h
t
n
e
r
a
p

n
i

s
n
e
k
o
T

;

P
V

;
s
n
u
o
n
o
r
P

;
s
n
o
i
t
c
n
u
j

s
e
u
q
i
n
U

;
s
e
c
n
e
t
n
e
S

;
s
d
r
o

W

)
a
n
e
m
o
g
e
l

x
a
p
a
h
(

c
i
t
c
a
t
n
y
s

s
e
r
u
t
a
e
f

t
n
i
o
P

l
e
v
e
L

s
q
e
r

n
o
i
t
a
m

]
8
3
1
[

.
l
a

.
s
q
e
r

g
n
i
z
i
t
i
r
o
i
r
p

e
r
o
c
s

s
e
i
d
u
t
s

l
a
c
i

s
e
i
t
r
e
p
o
r
p

e
l
b
a

-
y
l
a
n
a

t
n
e
m

i
t
n
e
s

,
g
n
i
m
m
e
t
s

d
e
s
a
b

c
i
t
c
a
t
n
y
s

r
o
f

t
n
a
v
e
l
e
r

y
t
i
r
e
v
e
s

,
e
r
o
c
s

n
o
i
t
n
e
t
n
i

,
s
i
s

s
e
r
u
t
a
e
f

-
r
i
p
m
e

o
w
t

-
ﬁ
i
t
n
a
u
q

s
t
c
a
r
t
x
e

,
g
n
i
g
g
a
t

s
o
p

,
n
o
i
t
a
z
i
n
e
k
o
t

e
l
u
r

d
n
a

l
a
c
i
x
e
l

y
t
i
r
o
i
r
p

f
o

+

s
q
e
r

’
s
q
e
r

-
d
e
e
f

s
k
c
a
b

]
3
3
1
[

.
l
a

t
e
s

n
o
i
t
a
z
i
t
i
r
o
i
r
P

t
e

w
e
t
e
f
i

K

s
q
e
r

0
0
1

+

r
e
v
l
o
s

T
M
S

s
o
p

,
g
n
i
m
m
e
t
s

,
n
o
i
t
a
z
i
n
e
k
o
t

e
l
u
r

d
n
a

l
a
c
i
x
e
l

y
t
i
r
o
i
r
p

f
o

t
e
s

n
o
i
t
a
z
i
t
i
r
o
i
r
P

t
e

a
r
a
Z
c
M

e
r
a

0
2

p
o
t
(

)
d
e
t
a
t
o
n
n
a

P
H
A

g
n
i
g
g
a
t

d
e
s
a
b

c
i
t
c
a
t
n
y
s

s
e
r
u
t
a
e
f

-
e
r
i
u
q
e
r

s
t
n
e
m

]
4
3
1
[

.
l
a

-
e
r
i
u
q
e
r

1
4

d
e
s
a
b
-
y
t
i
r
a
l
i

m

i
s

-
c
a

d
n
a

s
e
i
t
i
t
n
e

,
g
n
i
g
g
a
t

s
o
p

e
l
u
r

-
d
o
m

c
i
p
o
T

y
t
i
r
o
i
r
p

f
o

t
e
s

n
o
i
t
a
z
i
t
i
r
o
i
r
P

.
l
a

t
e

a
r
s
i

M

s
t
n
e
m

h
c
a
o
r
p
p
a

A
S
L

,
n
o
i
t
c
a
r
t
x
e

n
o
i
t

d
e
s
a
b

g
n
i
l
e

-
e
r
i
u
q
e
r

s
t
n
e
m

]
5
3
1
[

:

R

;
2
7
.
0

:

P

s
e
s
a
c

t
s
e
t

4

d
e
s
a
b

e
l
u
r

;
g
n
i
g
g
a
t

S
O
P

;
n
o
i
t
a
z
i
n
e
k
o
T

e
l
u
r

d
n
a

l
a
c
i
x
e
l

s
e
s
a
c

e
s
u

f
o

t
e
s

a

g
n
i
l
e
d
o
M

l
a

t
e

a
z
m
a
H

9
6
.
0

-
t
a
p

r
a
m
m
a
r
G

;
g
n
i
k
n
u
h
C

d
e
s
a
b

c
i
t
c
a
t
n
y
s

s
q
e
R

)
L
M
U
(

]
1
2
1
[

g
n
i
g
g
a
t

s
n
r
e
t

s
e
r
u
t
a
e
f

n
o
i
t
a
u
l
a
v
E

.
s
e
i
d
u
t
s

e
e
r
T

d
e
s
a
b

c
i
t
c
a
t
n
y
s

s
q
e
R

)
L
M
U
(

]
0
2
1
[

n
a
m
u
H

e
s
a
c

0
1

d
e
s
a
b

e
l
u
r

y
c
n
e
d
n
e
p
e
D

,
r
e
g
g
a
T

S
O
P

e
l
u
r

d
n
a

l
a
c
i
x
e
l

s
e
s
a
c

e
s
u

f
o

t
e
s

a

g
n
i
l
e
d
o
M

.
l
a

t
e

i
r
a
w
T

i

s
e
r
u
t
a
e
f

;
7
9
.
0
-
8
8
.
0
:
R

-
s
u
d
n
i

4

c
i
t
s
i
r
u
e
h

f
o

t
e
s

a

,
g
n
i
g
g
a
t

s
o
p

;
n
o
i
t
a
z
i
n
e
k
o
t

e
l
u
r

d
n
a

l
a
c
i
x
e
l

s
t
p
e
c
n
o
c

f
o

t
e
s

a

g
n
i
l
e
d
o
M

t
e

n
e
s
s
a
c
u
L

8
9
.
0
-
2
9
.
0
:
P

a
t
a
d

l
a
i
r
t

s
e
l
u
r

g
n
i
s
r
a
p

y
c
n
e
d
n
e
p
e
d

d
e
s
a
b

c
i
t
c
a
t
n
y
s

d
n
a

s
q
e
R

s
t
e
s

s
e
r
u
t
a
e
f

s
n
o
i
t
a
l
e
r

l
a
u
t
p
e
c

)
l
e
d
o
M

-
n
o
C
(

]
6
2
1
[

.
l
a

7
8
.
0

:
1
F

e
s
a
c

3

d
e
s
a
b

e
l
u
r

,
g
n
i
g
g
a
t

s
o
p

,
n
o
i
t
a
z
i
t
a
m
m
e
L

e
l
u
r

d
n
a

l
a
c
i
x
e
l

R
V
B
S

f
o

t
e
s

a

g
n
i
l
e
d
o
M

.
l
a

t
e

j
a
H

s
e
i
d
u
t
s

,

R
E
N

,
e
e
r
t

y
c
n
e
d
n
e
p
e
d

d
e
s
a
b

c
i
t
c
a
t
n
y
s

s
q
e
R

)
R
V
B
S
(

]
0
3
1
[

s
e
r
u
t
a
e
f

s
e
r
u
t
a
e
f

3
p
o
t

e
g
a
r
e
v
a

s
t
c
e
j
o
r
p

9
1

c
i
t
a
m
o
t
u
a
-
i

m
e
s

%
1
8

c
c
a

h
c
a
o
r
p
p
a

L
M

d
n
a

l
a
c
i
x
e
l

d
e
t
s
e
g
g
u
s

f
o

t
e
s

a

n
o
i
t
a
z
i
t
i
r
o
i
r
P

.
l
a

t
e

q
ﬁ
a
h
S

c
i
t
c
a
t
n
y
s

y
t
i
r
o
i
r
p

s
q
e
R

]
6
3
1
[

s
e
r
u
t
a
e
f

-
3
4
.
0

:
1
F

s
e
s
a
c

t
s
e
t

5

t
c
i
d
e
r
p

o
t

N
N
A

,
g
n
i
g
g
a
t

s
o
p

,
n
o
i
t
a
z
i
n
e
k
o
T

L
M

d
n
a

l
a
c
i
x
e
l

e
s
U

f
o

t
e
s

a

g
n
i
l
e
d
o
M

t
e

b
o
o
r
H

-
l

A

4
4
.
0

h
c
a
e

f
o

e
l
o
r

e
h
t

g
n
i
s
r
a
p

y
c
n
e
d
n
e
p
e
d

d
r
o
w

c
i
t
c
a
t
n
y
s

s
e
r
u
t
a
e
f

s
e
s
a
C

s
q
e
R

)
L
M
U
(

]
2
2
1
[

.
l
a

;
7
8
.
0

:

P

-
o
t
s

r
e
s
u
0
9

d
e
s
a
b

e
l
u
r

g
n
i
g
g
a
t

s
o
p

e
l
u
r

d
n
a

l
a
c
i
x
e
l

s
e
s
a
c

e
s
u

f
o

t
e
s

a

g
n
i
l
e
d
o
M

t
e

i
u
o
a
l
l
a
l
E

5
8
.
0
:
R

s
e
i
r

d
e
s
a
b

c
i
t
c
a
t
n
y
s

s
q
e
R

)
L
M
U
(

]
9
1
1
[

.
l
a

36

3
9
.
0
-
7
5
.
0

R

P

/

:
n
o
i
t
a
l
e
R

7
8
.
0
-
1
4
.
0

6
7
.
0
-
8
4
.
0
R

F
D

I

s
e
r
u
t
a
e
f

)
l
e
d
o
M

1
9
.
0

:
c
c
A

e
s
u

0
4

d
e
s
a
b

e
l
u
r

,
g
n
i
g
g
a
t

s
o
p

;
n
o
i
t
a
z
i
n
e
k
o
t

e
l
u
r

d
n
a

l
a
c
i
x
e
l

s
t
p
e
c
n
o
c

f
o

t
e
s

a

g
n
i
l
e
d
o
M

t
e

r
u
k
a
h
T

s
e
s
a
c

g
n
i
s
r
a
p

y
c
n
e
d
n
e
p
e
d

d
e
s
a
b

c
i
t
c
a
t
n
y
s

d
n
a

s
q
e
R

s
e
r
u
t
a
e
f

s
n
o
i
t
a
l
e
r

l
a
u
t
p
e
c

)
l
e
d
o
M

-
n
o
C
(

]
5
2
1
[

.
l
a

-
l
a
v
e

n
a
m
u
h

e
s
a
c

4

c
i
t
s
i
r
u
e
h

f
o

t
e
s

a

g
n
i
g
g
a
t

s
o
p

,
n
o
i
t
a
z
i
n
e
k
o
t

e
l
u
r

d
n
a

l
a
c
i
x
e
l

s
e
r
u
t
a
e
F

f
o

t
e
s

a

g
n
i
l
e
d
o
M

l
a

t
e

a
z
m
a
H

n
o
i
t
a
u

s
e
i
d
u
t
s

s
e
l
u
r

d
e
s
a
b

c
i
t
c
a
t
n
y
s

l
e
d
o
M

s
q
e
R

s
e
r
u
t
a
e
F
(

]
4
2
1
[

s
e
r
u
t
a
e
f

)
l
e
d
o
M

P

/

:
s
e
r
u
t
a
e
F

e
s
a
c

6

s
c
i
t
s
i
r
u
e
h

f
o

t
e
S

-
k
o
T

,
l
a
v
o
m
e
r

s
d
r
o
w

p
o
t
S

e
l
u
r

d
n
a

l
a
c
i
x
e
l

s
e
r
u
t
a
e
F

f
o

t
e
s

a

g
n
i
l
e
d
o
M

r
a
m
u
K
-
e
e
r
S

3
7
.
0
-
0
4
.
0

s
e
i
d
u
t
s

s
e
l
u
r

-
F
T

,
g
n
i
k
n
u
h
c
P
N

,
n
o
i
t
a
z
i
n
e

d
e
s
a
b

c
i
t
c
a
t
n
y
s

s
q
e
R

s
e
r
u
t
a
e
F
(

]
3
2
1
[

.
l
a

t
e

s
q
e
r

4
6
.
0
-
2
5
.
0
:

F

h
c
a
e

s
t
e
s

3

-
s
i
r
u
h

f
o

t
e
s

a

,
g
n
i
g
g
a
t

s
o
p

,
n
o
i
t
a
z
i
n
e
k
o
t

0
8
3
-
0
1
1

f
o

h
c
a
o
r
p
p
a

d
e
s
a
b

t
e
N
d
r
o
w

s
t
s
i
s
n
o
c

-
y
t
i
r
a
l
i

m

i
s

+

s
c
i
t

,

F
D

I
-
F
T

t
f
o
S

,
g
n
i
k
n
u
h
c

d
e
s
a
b

e
l
u
r

-
y
g
o
l
o
t
n
o

y
r
a
s
s
o
l
G

f
o

t
e
s

a

y
r
a
s
s
o
l
G

t
e

a
r
o
r
A

d
e
s
a
b

-
s
u
l
c

+

s
q
e
R

s

m
r
e
T

]
7
2
1
[
.
l
a

g
n
i
r
e
t

s

m
r
e
t

n
o
i
t
c
a
r
t
x
E

s

m
r
e
T

:
1
F

E
R
d
w
o
r
C

x
i
r
t
a
M
y
t
i
r
a
l
i

m
i
S

-
k
o
T

,
l
a
v
o
m
e
r

s
d
r
o
w

p
o
t
S

L
M

d
e
c
n
a
v
d
a

y
r
a
s
s
o
l
G

f
o

t
e
s

a

y
r
a
s
s
o
l
G

.
l
a

t
e

a
i
t
a
h
B

-
s
u
l
C

;
)
9
3
.
0
(

t
e
s
a
t
a
D

d
e
t
a
l
u
c
l
a
c

s
i

-
a
m
m
e
L

;
g
n
i
k
n
u
h
c

,
n
o
i
t
a
z
i
n
e

g
n
i
d
d
e
b
m
e

-
s
u
l
c

+

s
q
e
R

s

m
r
e
T

]
8
2
1
[

37

)
5
6
.
0
(

g
n
i
r
e
t

-
t
s
a
f

n
o

d
e
s
a
b

e
v
o
m
e
r

o
t

t
e
N
d
r
o

W

,
n
o
i
t
a
z
i
t

-

-

e
s
a
c

t
s
e
t

a

s
e
l
u
r

c
i
t
s
i
r
u
h

-
g
a
t

s
o
p

,
l
a
v
o
m
e
r

s
d
r
o
w
p
o
t
s

g
n
i
r
e
t
s
u
l
c

r
o
f

M
E

+

t
x
e
T

s
t
p
e
c
n
o
c

n
o
m
m
o
c

-
e
l
e

y
r
o
t
s

r
e
s
u

t
c
a
r
t
x
e

,
g
n
i
g

s
e
r
o
c
s

y
t
i
r
a
l
i

m

i
s

,
s
t
n
e
m

d
e
s
a
b

e
l
u
r

-
y
g
o
l
o
t
n
o

l
a
o
g

f
o

t
e
s

a

g
n
i
l
e
d
o
M

l
a

t
e

s
e
n
u
G

d
e
s
a
b

l
e
d
o
m

s
q
e
R

)
l
e
d
o
M

l
a
o
G
(

]
9
2
1
[

g
n
i
r
e
t

s

m
r
e
t

n
o
i
t
c
a
r
t
x
E

r
u
o

f
o

e
z
i
s

c
e
v
2
d
r
o
w

g
n
i
d
d
e
b
m
e

d
r
o
w

L
M

d
e
c
n
a
v
d
a

d
r
o
w

E
S

s
u
p
r
o
c

e
g
a
u
g
n
a
L

.
l
a

t
e

a
r
h
s
i

M

s
i

l
e
d
o
m

d
e
n
i
a
r
t

B
M
2
9

s
g
n
i
d

l
e
d
o
m

m
o
r
f

i
k
i
w

g
n
i
d
d
e
b
m
e

-
d
e
b
m
e

s
t
x
e
t

f
o

l
e
d
o
M

]
9
3
1
[

-
c
a
r
t
x
E

:
1
F

t
e
s
a
t
a
d

r
e
ﬁ
i
s
s
a
l
C
e
e
r
T
a
r
t
x
E

n
o
i
t
c
a
r
t
x
E

)
1
(

:
s
e
r
u
t
a
e
F

L
M

d
n
a

l
a
c
i
x
c
e
i
l
t
n
a
m
e
S
+
s
q
e
r

t
e
s

n
o
i
t
c
a
r
t
x
E

t
e

n
n
a
m

l
l
o
D

;
)
1
9
.
0
(
n
o
i
t

c
i
t
n
a
m
e
s

g
n
i
l
e
b
a
l

)
3
7
.
0
(

-
e
c
r
u
o
S

e
g
r
o
F

m
o
r
f

;
h
t
g
n
e
L

;

W
O
B
(

h
c
a
o
r
p
p
A

c
i
t
c
a
t
n
y
s

g
n
i
l
e
b
a
l

-
n
e
s

.
)
s
g
a
t

S
O
P

;
s
e
i
c
n
e
d
n
e
p
e
d

-
o
h
t
r
O
(

g
n
i
l
e
b
a
L

c
i
t
n
a
m
e
S

g
n
i
s
u

c
i
t
n
a
m
e
S

;
c
i
h
p
a
r
g

)
s
e
i
c
n
e
d
n
e
p
e
d

;
t
e
N
d
r
o

W

s
e
r
u
t
a
e
f

s
e
c
n
e
t

+

c
i
t
n
a
m
e
S

g
n
i
l
e
b
a
L

m
o
r
F

s
c
o
D

]
7
9
[

.
l
a

a

f
o

-
x
E

:
1
F

s
t
c
a
r
t
n
o
c

M
T
S
L
B

i

,
n
o
i
t
a
z
i
t
a
m
m
e
l

,
s
d
r
o
w

p
o
t
s

L
M

d
e
c
n
a
v
d
a

n
o
i
t
a
g
i
l
b
O

s
t
c
a
r
t
n
o
C

n
o
i
t
c
a
r
t
x
E

t
e

i
n
a
n
i
a
S

-
s
a
l
C

;
)
3
9
.
0
(

,
s
e
g
a
p

0
5
2
(

n
o
i
t
c
a
r
t

t
n
e
m
u
c
o
d

)
6
9
.
0
-
0
6
.
0
(

)
s
e
c
n
e
t

n
o
i
t
a
c
ﬁ
i
s

-
n
e
s

8
0
6
1

-
F
T

,
s

m
a
r
g
i
r
t

d
n
a

s

m
a
r
g
i
b

g
n
i
d
d
e
b
m
e

t
o
n

r
o

-
u
c
o
d

s
c
o
D

m
o
r
F

]
8
9
[

.
l
a

F
D

I

s
t
n
e
m

-
ﬁ

i
s
s
a
l
C

/

n
o
i
t
a
c

s
r
e
p
a
p

d
e
t
c
e
l
e
s

4
0
1

l
l
a

r
o
f

o
f
n
I

d
e
l
i
a
t
e
D
e
h
T

:
5

e
l
b
a
T

38

References

[1] A. Tahir, R. Ahmad, Requirement engineering practices-an empirical study, in: 2010 Interna-
tional Conference on Computational Intelligence and Software Engineering, IEEE, 2010, pp.
1–5.

[2] IEEE, Ieee standard glossary of software engineering terminology (std. 610.12-1990) (1990).

[3] T. Ambreen, N. Ikram, M. Usman, M. Niazi, Empirical research in requirements engineering:

trends and opportunities, Requirements Engineering 23 (1) (2018) 63–95.

[4] I. Jureta, J. Mylopoulos, S. Faulkner, Revisiting the core ontology and problem in require-
ments engineering, in: 2008 16th IEEE International Requirements Engineering Conference,
IEEE, 2008, pp. 71–80.

[5] A. Aurum, C. Wohlin, Requirements engineering: setting the context, in: Engineering and

managing software requirements, Springer, 2005, pp. 1–15.

[6] A. Van Lamsweerde, R. Darimont, E. Letier, Managing conﬂicts in goal-driven requirements

engineering, IEEE transactions on Software engineering 24 (11) (1998) 908–926.

[7] C. Denger, D. M. Berry, E. Kamsties, Higher quality requirements speciﬁcations through
natural language patterns, in: Proceedings 2003 Symposium on Security and Privacy, IEEE,
2003, pp. 80–90.

[8] R. Vlas, W. N. Robinson, A rule-based natural language technique for requirements discov-
ery and classiﬁcation in open-source software development projects, in: 2011 44th Hawaii
International Conference on System Sciences, IEEE, 2011, pp. 1–10.

[9] Z. Kurtanovi´c, W. Maalej, Automatically classifying functional and non-functional require-
ments using supervised machine learning, in: 2017 IEEE 25th International Requirements
Engineering Conference (RE), Ieee, 2017, pp. 490–495.

[10] F. Dalpiaz, D. Dell’Anna, F. B. Aydemir, S. C¸ evikol, Requirements classiﬁcation with in-
terpretable machine learning and dependency parsing, in: 2019 IEEE 27th International
Requirements Engineering Conference (RE), IEEE, 2019, pp. 142–152.

[11] T. Hey, J. Keim, A. Koziolek, W. F. Tichy, Norbert: Transfer learning for requirements
classiﬁcation, in: 2020 IEEE 28th International Requirements Engineering Conference (RE),
IEEE, 2020, pp. 169–179.

[12] A. Ferrari, F. Dell’Orletta, A. Esuli, V. Gervasi, S. Gnesi, Natural language requirements

processing: A 4d vision., IEEE Softw. 34 (6) (2017) 28–35.

39

[13] R. Garigliano, D. Perini, L. Mich, Which semantics for requirements engineering: From shal-
low to deep., in: The 1st Workshop on Natural Language Processing for REquirements En-
gineering (NLP4RE), 2018.

[14] A. Booth, A. Sutton, M. Clowes, M. Martyn-St James, Systematic approaches to a successful

literature review.

[15] K. Petersen, S. Vakkalanka, L. Kuzniarz, Guidelines for conducting systematic mapping stud-
ies in software engineering: An update, Information and Software Technology 64 (2015) 1–18.

[16] D. Jurafsky, Speech and language processing : an introduction to natural language processing,
computational linguistics, and speech recognition, Prentice Hall, Upper Saddle River, N.J,
2000.

[17] V. Teller, Speech and language processing: an introduction to natural language processing,

computational linguistics, and speech recognition (2000).

[18] D. Jurafsky, J. H. Martin, Speech and language processing: An introduction to natural lan-

guage processing, computational linguistics, and speech recognition.

[19] K. Toutanova, D. Klein, C. D. Manning, Y. Singer, Feature-rich part-of-speech tagging with a
cyclic dependency network, in: Proceedings of the 2003 Human Language Technology Confer-
ence of the North American Chapter of the Association for Computational Linguistics, 2003,
pp. 252–259.

[20] S. Abney, Partial parsing via ﬁnite-state cascades, Natural Language Engineering 2 (4) (1996)

337–344.

[21] M.-C. De Marneﬀe, C. D. Manning, Stanford typed dependencies manual, Tech. rep., Tech-

nical report, Stanford University (2008).

[22] D. Nadeau, S. Sekine, A survey of named entity recognition and classiﬁcation, Lingvisticae

Investigationes 30 (1) (2007) 3–26.

[23] T. R. Gruber, A translation approach to portable ontology speciﬁcations, Knowledge acqui-

sition 5 (2) (1993) 199–220.

[24] G. A. Miller, Wordnet: a lexical database for english, Communications of the ACM 38 (11)

(1995) 39–41.

[25] Z. Wu, M. Palmer, Verb semantics and lexical selection, in: 32nd Annual Meeting of the

Association for Computational Linguistics, 1994, pp. 133–138.

[26] R. Rada, H. Mili, E. Bicknell, M. Blettner, Development and application of a metric on
semantic nets, IEEE transactions on systems, man, and cybernetics 19 (1) (1989) 17–30.

40

[27] G. Salton, Automatic text processing-addison-wesley longman publishing co., inc.

[28] D. M. Blei, A. Y. Ng, M. I. Jordan, Latent dirichlet allocation, the Journal of machine

Learning research 3 (2003) 993–1022.

[29] S. T. Dumais, Latent semantic analysis, Annual review of information science and technology

38 (1) (2004) 188–230.

[30] T. Mikolov, K. Chen, G. Corrado, J. Dean, Eﬃcient estimation of word representations in

vector space, arXiv preprint arXiv:1301.3781.

[31] J. Pennington, R. Socher, C. D. Manning, Glove: Global vectors for word representation,
in: Proceedings of the 2014 conference on empirical methods in natural language processing
(EMNLP), 2014, pp. 1532–1543.

[32] J. Devlin, M.-W. Chang, K. Lee, K. Toutanova, BERT: Pre-training of deep bidirectional
transformers for language understanding, in: Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computational Linguistics: Human Language Tech-
nologies, Volume 1 (Long and Short Papers), Association for Computational Linguistics,
Minneapolis, Minnesota, 2019, pp. 4171–4186. doi:10.18653/v1/N19-1423.
URL https://aclanthology.org/N19-1423

[33] L. Zhao, W. Alhoshan, A. Ferrari, K. J. Letsholo, M. A. Ajagbe, E.-V. Chioasca, R. T.
Batista-Navarro, Natural language processing for requirements engineering: A systematic
mapping study, ACM Computing Surveys (CSUR) 54 (3) (2021) 1–41.

[34] I. K. Raharjana, D. Siahaan, C. Fatichah, User stories and natural language processing: A

systematic literature review, IEEE Access 9 (2021) 53811–53826.

[35] A. R. Amna, G. Poels, Ambiguity in user stories: A systematic literature review, Information

and Software Technology (2022) 106824.

[36] D. Dermeval, J. Vilela, I. I. Bittencourt, J. Castro, S. Isotani, P. Brito, A systematic review on
the use of ontologies in requirements engineering, in: 2014 Brazilian Symposium on Software
Engineering, IEEE, 2014, pp. 1–10.

[37] F. Nazir, W. H. Butt, M. W. Anwar, M. A. K. Khattak, The applications of natural language
processing (nlp) for software requirement engineering-a systematic literature review, in: In-
ternational conference on information science and applications, Springer, 2017, pp. 485–493.

[38] F. Bozyi˘git, ¨O. Akta¸s, D. Kılın¸c, Linking software requirements and conceptual models: A
systematic literature review, Engineering Science and Technology, an International Journal
24 (1) (2021) 71–82.

41

[39] C. Baker, L. Deng, S. Chakraborty, J. Dehlinger, Automatic multi-class non-functional soft-
ware requirements classiﬁcation using neural networks, in: 2019 IEEE 43rd annual computer
software and applications conference (COMPSAC), Vol. 2, IEEE, 2019, pp. 610–615.

[40] E. Dias Canedo, B. Cordeiro Mendes, Software requirements classiﬁcation using machine

learning algorithms, Entropy 22 (9) (2020) 1057.

[41] A. Casamayor, D. Godoy, M. Campo, Identiﬁcation of non-functional requirements in textual
speciﬁcations: A semi-supervised learning approach, Information and Software Technology
52 (4) (2010) 436–445.

[42] V. M. Khatian, Q. A. Arain, M. Alenezi, M. O. Raza, F. Shaikh, I. Farah, Comparative
analysis for predicting non-functional requirements using supervised machine learning, in:
2021 1st International Conference on Artiﬁcial Intelligence and Data Analytics (CAIDA),
IEEE, 2021, pp. 7–12.

[43] M. A. Rahman, M. A. Haque, M. N. A. Tawhid, M. S. Siddik, Classifying non-functional
requirements using rnn variants for quality software development, in: Proceedings of the
3rd ACM SIGSOFT International Workshop on Machine Learning Techniques for Software
Quality Evaluation, 2019, pp. 25–30.

[44] A. Rashwan, O. Ormandjieva, R. Witte, Ontology-based classiﬁcation of non-functional re-
quirements in software speciﬁcations: a new corpus and svm-based classiﬁer, in: 2013 IEEE
37th Annual Computer Software and Applications Conference, IEEE, 2013, pp. 381–386.

[45] M. Younas, D. N. Jawawi, I. Ghani, M. A. Shah, Extraction of non-functional requirement
using semantic similarity distance, Neural Computing and Applications 32 (11) (2020) 7383–
7397.

[46] A. Mahmoud, G. Williams, Detecting, classifying, and tracing non-functional software re-

quirements, Requirements Engineering 21 (3) (2016) 357–381.

[47] D. Kici, G. Malik, M. Cevik, D. Parikh, A. Ba¸sar, A bert-based transfer learning approach

to text classiﬁcation on software requirements speciﬁcations.

[48] I. M. S. Raharja, D. O. Siahaan, Classiﬁcation of non-functional requirements using fuzzy
similarity knn based on iso/iec 25010, in: 2019 12th International Conference on Information
& Communication Technology and System (ICTS), IEEE, 2019, pp. 264–269.

[49] R. Krasniqi, A. Agrawal, Analyzing and detecting emerging quality-related concerns across
oss defect report summaries, in: 2021 IEEE International Conference on Software Analysis,
Evolution and Reengineering (SANER), IEEE, 2021, pp. 12–23.

42

[50] D. N. Palacio, D. McCrystal, K. Moran, C. Bernal-C´ardenas, D. Poshyvanyk, C. Sheneﬁel,
Learning to identify security-related issues using convolutional neural networks, in: 2019
IEEE International conference on software maintenance and evolution (ICSME), IEEE, 2019,
pp. 140–144.

[51] A. Kobilica, M. Ayub, J. Hassine, Automated identiﬁcation of security requirements: A
machine learning approach, in: Proceedings of the Evaluation and Assessment in Software
Engineering, 2020, pp. 475–480.

[52] T. Li, Z. Chen, An ontology-based learning approach for automatically classifying security

requirements, Journal of Systems and Software 165 (2020) 110566.

[53] D. Ott, Automatic requirement categorization of large natural language speciﬁcations at
mercedes-benz for review improvements, in: International Working Conference on Require-
ments Engineering: Foundation for Software Quality, Springer, 2013, pp. 50–64.

[54] R. Chatterjee, A. Ahmed, P. R. Anish, Identiﬁcation and classiﬁcation of architecturally sig-
niﬁcant functional requirements, in: 2020 IEEE Seventh International Workshop on Artiﬁcial
Intelligence for Requirements Engineering (AIRE), IEEE, 2020, pp. 9–17.

[55] H. Wang, G. Shen, Z. Huang, Y. Yu, K. Chen, Analyzing close relations between target
artifacts for improving ir-based requirement traceability recovery, Frontiers of Information
Technology & Electronic Engineering 22 (7) (2021) 957–968.

[56] S. Das, N. Deb, A. Cortesi, N. Chaki, Sentence embedding models for similarity detection of

software requirements, SN Computer Science 2 (2) (2021) 1–11.

[57] M. B. Blake, I. Saleh, Y. Wei, I. D. Schlesinger, A. Yale-Loehr, X. Liu, Shared service rec-
ommendations from requirement speciﬁcations: A hybrid syntactic and semantic toolkit,
Information and Software Technology 57 (2015) 392–404.

[58] R. Sonbol, G. Rebdawi, N. Ghneim, Towards a semantic representation for functional software
requirements, in: 2020 IEEE Seventh International Workshop on Artiﬁcial Intelligence for
Requirements Engineering (AIRE), IEEE, 2020, pp. 1–8.

[59] W. Alhoshan, R. Batista-Navarro, L. Zhao, Using frame embeddings to identify semantically

related software requirements., in: REFSQ Workshops, 2019.

[60] G. Deshpande, C. Arora, G. Ruhe, Data-driven elicitation and optimization of dependencies
between requirements, in: 2019 IEEE 27th International Requirements Engineering Confer-
ence (RE), IEEE, 2019, pp. 416–421.

[61] R. Samer, M. Stettinger, M. Atas, A. Felfernig, G. Ruhe, G. Deshpande, New approaches
to the identiﬁcation of dependencies between requirements, in: 2019 IEEE 31st International
Conference on Tools with Artiﬁcial Intelligence (ICTAI), IEEE, 2019, pp. 1265–1270.

43

[62] H. Sultanov, J. H. Hayes, W.-K. Kong, Application of swarm techniques to requirements

tracing, Requirements Engineering 16 (3) (2011) 209–226.

[63] M. Lu, P. Liang, Automatic classiﬁcation of non-functional requirements from augmented
app user reviews, in: Proceedings of the 21st International Conference on Evaluation and
Assessment in Software Engineering, 2017, pp. 344–353.

[64] G. Deshpande, B. Sheikhi, S. Chakka, D. L. Zotegouon, M. N. Masahati, G. Ruhe, Is bert
the new silver bullet?-an empirical investigation of requirements dependency classiﬁcation,
in: 2021 IEEE 29th International Requirements Engineering Conference Workshops (REW),
IEEE, 2021, pp. 136–145.

[65] M. Aldekhail, M. Almasri, Intelligent identiﬁcation and resolution of software requirement
conﬂicts: Assessment and evaluation, COMPUTER SYSTEMS SCIENCE AND ENGINEER-
ING 40 (2) (2022) 469–489.

[66] A. Nicholson, G. J. LC, Issue link label recovery and prediction for open source software,
in: 2021 IEEE 29th International Requirements Engineering Conference Workshops (REW),
IEEE, 2021, pp. 126–135.

[67] J. Guo, J. Cheng, J. Cleland-Huang, Semantically enhanced software traceability using deep
learning techniques, in: 2017 IEEE/ACM 39th International Conference on Software Engi-
neering (ICSE), IEEE, 2017, pp. 3–14.

[68] B. Wang, R. Peng, Z. Wang, X. Wang, Y. Li, An automated hybrid approach for generat-
ing requirements trace links, International Journal of Software Engineering and Knowledge
Engineering 30 (07) (2020) 1005–1048.

[69] A. H. Rasekh, S. M. Fakhrahmad, M. H. Sadreddini, Mining traces between source code
and textual documents, International Journal of Computer Applications in Technology 59 (1)
(2019) 43–52.

[70] A. Mahmoud, N. Niu, On the role of semantics in automated requirements tracing, Require-

ments Engineering 20 (3) (2015) 281–300.

[71] N. Ali, H. Cai, A. Hamou-Lhadj, J. Hassine, Exploiting parts-of-speech for eﬀective automated

requirements traceability, Information and Software Technology 106 (2019) 126–141.

[72] V. Leit˜ao, I. Medeiros, Srxcrm: Discovering association rules between system requirements

and product speciﬁcations., in: REFSQ Workshops, 2021.

[73] J. K. Chhabra, et al., Requirements traceability through information retrieval using dynamic
integration of structural and co-change coupling, in: International Conference on Advanced
Informatics for Computing Research, Springer, 2017, pp. 107–118.

44

[74] C. Arora, M. Sabetzadeh, A. Goknil, L. C. Briand, F. Zimmer, Change impact analysis for
natural language requirements: An nlp approach, in: 2015 IEEE 23rd International Require-
ments Engineering Conference (RE), IEEE, 2015, pp. 6–15.

[75] T. N. Al-Otaiby, M. AlSherif, W. P. Bond, Toward software requirements modularization
using hierarchical clustering techniques, in: Proceedings of the 43rd annual Southeast regional
conference-Volume 2, 2005, pp. 223–228.

[76] K. J. G¨ulle, N. Ford, P. Ebel, F. Brokhausen, A. Vogelsang, Topic modeling on user stories
using word mover’s distance, in: 2020 IEEE Seventh International Workshop on Artiﬁcial
Intelligence for Requirements Engineering (AIRE), IEEE, 2020, pp. 52–60.

[77] A. Casamayor, D. Godoy, M. Campo, Functional grouping of natural language requirements

for assistance in architectural software design, Knowledge-Based Systems 30 (2012) 78–86.

[78] J. Misra, S. Sengupta, S. Podder, Topic cohesion preserving requirements clustering, in: 2016
IEEE/ACM 5th International Workshop on Realizing Artiﬁcial Intelligence Synergies in Soft-
ware Engineering (RAISE), IEEE, 2016, pp. 22–28.

[79] H. Eyal Salman, M. Hammad, A.-D. Seriai, A. Al-Sbou, Semantic clustering of functional
requirements using agglomerative hierarchical clustering, Information 9 (9) (2018) 222.

[80] M. Mezghani, J. Kang, F. S`edes, Industrial requirements classiﬁcation for redundancy and
inconsistency detection in semios, in: 2018 IEEE 26th International Requirements Engineering
Conference (RE), IEEE, 2018, pp. 297–303.

[81] Y. Wang, Semantic information extraction for software requirements using semantic role
labeling, in: 2015 IEEE International Conference on Progress in Informatics and Computing
(PIC), IEEE, 2015, pp. 332–337.

[82] T. Diamantopoulos, M. Roth, A. Symeonidis, E. Klein, Software requirements as an appli-
cation domain for natural language processing, Language Resources and Evaluation 51 (2)
(2017) 495–524.

[83] Y. Wang, Automatic semantic analysis of software requirements through machine learning and
ontology approach, Journal of Shanghai Jiaotong University (Science) 21 (6) (2016) 692–701.

[84] A. F. de Ara´ujo, R. M. Marcacini, Re-bert: automatic extraction of software requirements
from app reviews using bert language model, in: Proceedings of the 36th Annual ACM
Symposium on Applied Computing, 2021, pp. 1321–1327.

[85] N. H. Bakar, Z. M. Kasirun, N. Salleh, H. A. Jalab, Extracting features from online software

reviews to aid requirements reuse, Applied Soft Computing 49 (2016) 1297–1315.

45

[86] L. V. G. Carreno, K. Winbladh, Analysis of user comments: an approach for software re-
quirements evolution, in: 2013 35th international conference on software engineering (ICSE),
IEEE, 2013, pp. 582–591.

[87] N. Jha, A. Mahmoud, Using frame semantics for classifying and summarizing application

store reviews, Empirical Software Engineering 23 (6) (2018) 3734–3767.

[88] C. Li, L. Huang, J. Ge, B. Luo, V. Ng, Automatically classifying user requests in crowdsourc-

ing requirements engineering, Journal of Systems and Software 138 (2018) 108–123.

[89] Z. Peng, J. Wang, K. He, M. Tang, An approach of extracting feature requests from app
reviews, in: International Conference on Collaborative Computing: Networking, Applications
and Worksharing, Springer, 2016, pp. 312–323.

[90] C. Yang, L. Wu, C. Yu, Y. Zhou, A phrase-level user requests mining approach in mobile
application reviews: Concept, framework, and operation, Information 12 (5) (2021) 177.

[91] H. Wu, W. Deng, X. Niu, C. Nie, Identifying key features from app user reviews, in: 2021
IEEE/ACM 43rd International Conference on Software Engineering (ICSE), IEEE, 2021, pp.
922–932.

[92] L. Shi, C. Chen, Q. Wang, B. Boehm, Automatically detecting feature requests from develop-
ment emails by leveraging semantic sequence mining, Requirements Engineering 26 (2) (2021)
255–271.

[93] Y. Wang, I. L. M. Guti´errez, K. Winbladh, H. Fang, Automatic detection of ambiguous
terminology for software requirements, in: International Conference on Application of Natural
Language to Information Systems, Springer, 2013, pp. 25–37.

[94] T. Quirchmayr, B. Paech, R. Kohl, H. Karey, G. Kasdepke, Semi-automatic rule-based domain
terminology and software feature-relevant information extraction from natural language user
manuals, Empirical Software Engineering 23 (6) (2018) 3630–3683.

[95] M. S. Haris, T. A. Kurniawan, F. Ramdani, Automated features extraction from software
requirements speciﬁcation (srs) documents as the basis of software product line (spl) engi-
neering, JITeCS (Journal of Information Technology and Computer Science) 5 (3) (2020)
279–292.

[96] S. Abualhaija, C. Arora, M. Sabetzadeh, L. C. Briand, M. Traynor, Automated demarcation of
requirements in textual speciﬁcations: a machine learning-based approach, Empirical Software
Engineering 25 (6) (2020) 5454–5497.

[97] M. Dollmann, M. Geierhos, On-and oﬀ-topic classiﬁcation and semantic annotation of user-
generated software requirements, in: Proceedings of the 2016 Conference on Empirical Meth-
ods in Natural Language Processing, 2016, pp. 1807–1816.

46

[98] A. Sainani, P. R. Anish, V. Joshi, S. Ghaisas, Extracting and classifying requirements from
software engineering contracts, in: 2020 IEEE 28th International Requirements Engineering
Conference (RE), IEEE, 2020, pp. 147–157.

[99] H. Jiang, J. Zhang, X. Li, Z. Ren, D. Lo, X. Wu, Z. Luo, Recommending new features
from mobile app descriptions, ACM Transactions on Software Engineering and Methodology
(TOSEM) 28 (4) (2019) 1–29.

[100] M. Abbas, M. Saadatmand, E. Enoiu, D. Sundamark, C. Lindskog, Automated reuse recom-
mendation of product line assets based on natural language requirements, in: International
Conference on Software and Software Reuse, Springer, 2020, pp. 173–189.

[101] Q. A. Do, T. Bhowmik, G. L. Bradshaw, Capturing creative requirements via requirements
reuse: A machine learning-based approach, Journal of Systems and Software 170 (2020)
110730.

[102] H. Femmer, D. M. Fern´andez, S. Wagner, S. Eder, Rapid quality assurance with requirements

smells, Journal of Systems and Software 123 (2017) 190–213.

[103] A. Ferrari, G. Gori, B. Rosadini, I. Trotta, S. Bacherini, A. Fantechi, S. Gnesi, Detecting
requirements defects with nlp patterns: an industrial experience in the railway domain, Em-
pirical Software Engineering 23 (6) (2018) 3684–3733.

[104] S. Mishra, A. Sharma, On the use of word embeddings for identifying domain speciﬁc ambigu-
ities in requirements, in: 2019 IEEE 27th International Requirements Engineering Conference
Workshops (REW), IEEE, 2019, pp. 234–240.

[105] J. Matsuoka, Y. Lepage, Ambiguity spotting using wordnet semantic similarity in support
to recommended practice for software requirements speciﬁcations, in: 2011 7th International
Conference on Natural Language Processing and Knowledge Engineering, IEEE, 2011, pp.
479–484.

[106] A. Ferrari, A. Esuli, An nlp approach for cross-domain ambiguity detection in requirements

engineering, Automated Software Engineering 26 (3) (2019) 559–598.

[107] J. Misra, S. Das, Entity disambiguation in natural language text requirements, in: 2013 20th

Asia-Paciﬁc Software Engineering Conference (APSEC), Vol. 1, IEEE, 2013, pp. 239–246.

[108] M. Osama, A. Zaki-Ismail, M. Abdelrazek, J. Grundy, A. Ibrahim, Score-based automatic
detection and resolution of syntactic ambiguity in natural language requirements, in: 2020
IEEE International Conference on Software Maintenance and Evolution (ICSME), IEEE,
2020, pp. 651–661.

47

[109] S. Ezzini, S. Abualhaija, C. Arora, M. Sabetzadeh, L. C. Briand, Using domain-speciﬁc
corpora for improved handling of ambiguity in requirements, in: 2021 IEEE/ACM 43rd In-
ternational Conference on Software Engineering (ICSE), IEEE, 2021, pp. 1485–1497.

[110] A. Ferrari, S. Gnesi, Using collective intelligence to detect pragmatic ambiguities, in: 2012
20th IEEE International Requirements Engineering Conference (RE), IEEE, 2012, pp. 191–
200.

[111] A. Ferrari, F. Dell’Orletta, G. O. Spagnolo, S. Gnesi, Measuring and improving the complete-
ness of natural language requirements, in: International Working Conference on Requirements
Engineering: Foundation for Software Quality, Springer, 2014, pp. 23–38.

[112] C. Liu, Z. Zhao, L. Zhang, Z. Li, Automated conditional statements checking for complete

natural language requirements speciﬁcation, Applied Sciences 11 (17) (2021) 7892.

[113] F. S. B¨aumer, M. Geierhos, Flexible ambiguity resolution and incompleteness detection in
requirements descriptions via an indicator-based conﬁguration of text analysis pipelines, in:
Proceedings of the 51st Hawaii International Conference on System Sciences, 2018.

[114] C. Arora, M. Sabetzadeh, L. Briand, F. Zimmer, Automated checking of conformance to
requirements templates using natural language processing, IEEE transactions on Software
Engineering 41 (10) (2015) 944–968.

[115] C. Rupp, K. Pohl, Requirements engineering fundamentals, Rocky Nook.

[116] A. Mavin, P. Wilkinson, A. Harwood, M. Novak, Easy approach to requirements syntax
(ears), in: 2009 17th IEEE International Requirements Engineering Conference, IEEE, 2009,
pp. 317–322.

[117] B. D. Cruz, B. Jayaraman, A. Dwarakanath, C. McMillan, Detecting vague words & phrases
in requirements documents in a multilingual environment, in: 2017 IEEE 25th International
Requirements Engineering Conference (RE), IEEE, 2017, pp. 233–242.

[118] E. Parra, C. Dimou, J. Llorens, V. Moreno, A. Fraga, A methodology for the classiﬁcation of
quality of requirements using machine learning techniques, Information and Software Tech-
nology 67 (2015) 180–195.

[119] M. Elallaoui, K. Naﬁl, R. Touahni, Automatic transformation of user stories into uml use

case diagrams using nlp techniques, Procedia computer science 130 (2018) 42–49.

[120] S. Tiwari, D. Ameta, A. Banerjee, An approach to identify use case scenarios from textual
requirements speciﬁcation, in: Proceedings of the 12th Innovations on Software Engineering
Conference (Formerly Known As India Software Engineering Conference), 2019, pp. 1–11.

48

[121] Z. A. Hamza, M. Hammad, Generating uml use case models from software requirements using
natural language processing, in: 2019 8th International Conference on Modeling Simulation
and Applied Optimization (ICMSAO), IEEE, 2019, pp. 1–6.

[122] A. Al-Hroob, A. T. Imam, R. Al-Heisa, The use of artiﬁcial neural networks for extracting
actions and actors from requirements document, Information and Software Technology 101
(2018) 1–15.

[123] A. Sree-Kumar, E. Planas, R. Claris´o, Extracting software product line feature models from
natural language speciﬁcations, in: Proceedings of the 22nd International Systems and Soft-
ware Product Line Conference-Volume 1, 2018, pp. 43–53.

[124] M. Hamza, R. J. Walker, Recommending features and feature relationships from requirements
documents for software product lines, in: 2015 IEEE/ACM 4th International Workshop on
Realizing Artiﬁcial Intelligence Synergies in Software Engineering, IEEE, 2015, pp. 25–31.

[125] J. S. Thakur, A. Gupta, Identifying domain elements from textual speciﬁcations, in: Proceed-
ings of the 31st IEEE/ACM International Conference on Automated Software Engineering,
2016, pp. 566–577.

[126] G. Lucassen, M. Robeer, F. Dalpiaz, J. M. E. Van Der Werf, S. Brinkkemper, Extracting
conceptual models from user stories with visual narrator, Requirements Engineering 22 (3)
(2017) 339–358.

[127] C. Arora, M. Sabetzadeh, L. Briand, F. Zimmer, Automated extraction and clustering of
requirements glossary terms, IEEE Transactions on Software Engineering 43 (10) (2016) 918–
945.

[128] K. Bhatia, S. Mishra, A. Sharma, Clustering glossary terms extracted from large-sized soft-
ware requirements using fasttext, in: Proceedings of the 13th Innovations in Software Engi-
neering Conference on Formerly known as India Software Engineering Conference, 2020, pp.
1–11.

[129] T. G¨une¸s, F. B. Aydemir, Automated goal model extraction from user stories using nlp, in:
2020 IEEE 28th International Requirements Engineering Conference (RE), IEEE, 2020, pp.
382–387.

[130] A. Haj, A. Jarrar, Y. Balouki, T. Gadir, The semantic of business vocabulary and business
rules: An automatic generation from textual statements, IEEE Access 9 (2021) 56506–56522.

[131] P. Tzortzopoulos, R. Cooper, P. Chan, M. Kagioglou, Clients’ activities at the design front-

end, Design studies 27 (6) (2006) 657–683.

49

[132] S. Ali, Y. Hafeez, S. Hussain, S. Yang, M. Jamal, Requirement prioritization framework using
case-based reasoning: A mining-based approach, Expert Systems 38 (8) (2021) e12770.

[133] F. M. Kifetew, A. Perini, A. Susi, A. Siena, D. Mu˜nante, I. Morales-Ramirez, Automating
user-feedback driven requirements prioritization, Information and Software Technology 138
(2021) 106635.

[134] J. McZara, S. Sarkani, T. Holzer, T. Eveleigh, Software requirements prioritization and selec-
tion using linguistic tools and constraint solvers—a controlled experiment, Empirical Software
Engineering 20 (6) (2015) 1721–1761.

[135] J. Misra, S. Sengupta, S. Das, Latent semantic centrality based automated requirements
prioritization, in: Proceedings of the 7th India Software Engineering Conference, 2014, pp.
1–10.

[136] S. Shaﬁq, A. Mashkoor, C. Mayr-Dorn, A. Egyed, Nlp4ip: Natural language processing-based
recommendation approach for issues prioritization, in: 2021 47th Euromicro Conference on
Software Engineering and Advanced Applications (SEAA), IEEE, 2021, pp. 99–108.

[137] M. Choetkiertikul, H. K. Dam, T. Tran, T. Pham, A. Ghose, T. Menzies, A deep learning
model for estimating story points, IEEE Transactions on Software Engineering 45 (7) (2018)
637–656.

[138] I. Hussain, L. Kosseim, O. Ormandjieva, Approximation of cosmic functional size to support

early eﬀort estimation in agile, Data & Knowledge Engineering 85 (2013) 2–14.

[139] S. Mishra, A. Sharma, Crawling wikipedia pages to train word embeddings model for software
engineering domain, in: 14th Innovations in Software Engineering Conference (formerly known
as India Software Engineering Conference), 2021, pp. 1–5.

[140] U. Shah, S. Patel, D. C. Jinwala, Detecting intra-conﬂicts in non-functional requirements,
International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems 29 (03) (2021)
435–461.

[141] V. Silva-Rodr´ıguez, S. E. Nava-Mu˜noz, L. A. Castro, F. E. Mart´ınez-P´erez, H. G. P´erez-
Gonz´alez, F. Torres-Reyes, Classifying design-level requirements using machine learning for
a recommender of interaction design patterns, IET Software 14 (5) (2020) 544–552.

[142] C. F. Baker, C. J. Fillmore, J. B. Lowe, The berkeley framenet project, in: COLING 1998

Volume 1: The 17th International Conference on Computational Linguistics, 1998.

[143] Y. Li, T. Yang, Word embedding for understanding natural language: a survey, in: Guide to

big data applications, Springer, 2018, pp. 83–104.

50

[144] F. Dalpiaz, I. Van Der Schalk, S. Brinkkemper, F. B. Aydemir, G. Lucassen, Detecting
terminological ambiguity in user stories: Tool and experimentation, Information and Software
Technology 110 (2019) 3–16.

[145] C. De Boom, S. Van Canneyt, T. Demeester, B. Dhoedt, Representation learning for very
short texts using weighted word embedding aggregation, Pattern Recognition Letters 80
(2016) 150–156.

[146] S. Dupond, A thorough review on the current advance of neural network structures, Annual

Reviews in Control 14 (2019) 200–230.

[147] Z. Liu, B. Li, J. Wang, R. Yang, Requirements engineering for crossover services: Issues,

challenges and research directions, IET Software 15 (1) (2021) 107–125.

[148] A. Mavin, P. Wilkinson, S. Teuﬂ, H. Femmer, J. Eckhardt, J. Mund, Does goal-oriented
requirements engineering achieve its goal?, in: 2017 IEEE 25th international requirements
engineering conference (RE), IEEE, 2017, pp. 174–183.

[149] U. Eklund, H. H. Olsson, N. J. Strøm, Industrial challenges of scaling agile in mass-produced
embedded systems, in: International Conference on Agile Software Development, Springer,
2014, pp. 30–42.

[150] G. Fanmuy, A. Fraga, J. Llorens, Requirements veriﬁcation in the industry, in: Complex

systems design & management, Springer, 2012, pp. 145–160.

[151] Y. Wautelet, S. Heng, M. Kolp, I. Mirbel, Unifying and extending user story models, in:
International Conference on Advanced Information Systems Engineering, Springer, 2014, pp.
211–225.

[152] A. Di Thommazo, T. Ribeiro, G. Olivatto, V. Werneck, S. Fabbri, An automatic approach
to detect traceability links using fuzzy logic, in: 2013 27th Brazilian Symposium on Software
Engineering, IEEE, 2013, pp. 21–30.

[153] Y. Wang, J. Zhang, Experiment on automatic functional requirements analysis with the efrf’s
semantic cases, in: 2016 International Conference on Progress in Informatics and Computing
(PIC), IEEE, 2016, pp. 636–642.

51

