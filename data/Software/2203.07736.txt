2
2
0
2

r
p
A
7
2

]
E
S
.
s
c
[

4
v
6
3
7
7
0
.
3
0
2
2
:
v
i
X
r
a

CSRS: Code Search with Relevance Matching and Semantic
Matching

Yi Cheng
Central South University
ChangSha, China
roycheng@csu.edu.cn

Li Kuang∗
Central South University
ChangSha, China
kuangli@csu.edu.cn

ABSTRACT
Developers often search and reuse existing code snippets in the
process of software development. Code search aims to retrieve rel-
evant code snippets from a codebase according to natural language
queries entered by the developer. Up to now, researchers have al-
ready proposed information retrieval (IR) based methods and deep
learning (DL) based methods. The IR-based methods focus on key-
word matching, that is to rank codes by relevance between queries
and code snippets, while DL-based methods focus on capturing
the semantic correlations. However, the existing methods do not
consider capturing two matching signals simultaneously. There-
fore, in this paper, we propose CSRS, a code search model with
relevance matching and semantic matching. CSRS comprises (1)
an embedding module containing convolution kernels of different
sizes which can extract n-gram embeddings of queries and codes,
(2) a relevance matching module that measures lexical matching
signals, and (3) a co-attention based semantic matching module
to capture the semantic correlation. We train and evaluate CSRS
on a dataset with 18.22M and 10k code snippets. The experimental
results demonstrate that CSRS achieves an MRR of 0.614, which out-
performs two state-of-the-art models DeepCS and CARLCS-CNN
by 33.77% and 18.53% respectively. In addition, we also conducted
several experiments to prove the effectiveness of each component
of CSRS.

CCS CONCEPTS
• Software and its engineering → Reusability; • Information
systems → Retrieval models and ranking.

KEYWORDS
code search, relevance matching, semantic matching, attention
mechanism

∗Li Kuang is the corresponding author.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ICPC ’22, May 16–17, 2022, Virtual Event, USA
© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9298-3/22/05. . . $15.00
https://doi.org/10.1145/3524610.3527889

ACM Reference Format:
Yi Cheng and Li Kuang. 2022. CSRS: Code Search with Relevance Matching
and Semantic Matching. In 30th International Conference on Program Com-
prehension (ICPC ’22), May 16–17, 2022, Virtual Event, USA. ACM, New York,
NY, USA, 10 pages. https://doi.org/10.1145/3524610.3527889

1 INTRODUCTION
In modern society, software systems have already been applied
in various fields. Similar functions may exist in different software
systems, and their implementation codes are similar to each other.
When developing or maintaining software systems, in order to
improve the development efficiency, developers tend to search or
reuse for existing code in search engines or open source repositories
such as Google and GitHub, rather than wasting time redeveloping
the function. Therefore, code search has become one of the most
frequent activities in software development, and it is necessary to
develop a code search tool [29].

Many code search methods have been proposed in the past few
years to advance the code search task. The existing researches can
be divided into two categories: information retrieval (IR) based and
deep learning (DL) based [4]. Earlier code search approaches are
mostly based on IR techniques, which focus on keyword matching
to calculate the relevant score between a query and a code snippet.
For example, Lv et al. [20] proposed CodeHow, which expands the
query with the APIs and performs code retrieval by applying the
extended boolean model. Lu et al. [18] propose an approach that
extends a query with synonyms generated from WordNet [22].

Obviously, the IR-based methods cannot capture the semantic
relationship between the query and the code. To tackle this issue,
many DL-based methods have been proposed, which can bridge
the semantic gaps between programming language in code and
natural language in query. Gu et al. [5] proposed DeepCS (Deep
Code Search), which uses two different LSTM (Long Short-Term
Memory) [9] to jointly embed code snippets and natural language
queries into a high-dimensional vector space, and then calculates
the cosine similarity between code snippets and queries. Shuai
et al. [25] proposed CARLCS-CNN that leverages convolutional
neural network (CNN) [13] and co-attention mechanism to learn
the semantic relationship between code and query.

However, the above two types of methods have different con-
cerns. The characteristic of the IR-based model is that the relevance
between queries and code snippets can be determined by the key-
word matching signals, and the DL-based model performs well in
obtaining the semantic relationship between the query and code.
Due to the early IR-based methods being mostly rule-based or
heuristic, it can not be well combined with the DL-based model.
However, with the development of deep learning, some studies

 
 
 
 
 
 
ICPC ’22, May 16–17, 2022, Virtual Event, USA

Yi Cheng and Li Kuang

tasks compared to two state-of-the-art models DeepCS and
CARLCS-CNN.

The rest of the paper is organized as follows. Section 2 discusses
the related work about code search and neural IR. Section 3 provides
some background knowledge on code representation and attention
mechanism. Then, we introduce the details of our proposed model
CSRS in Section 4. Section 5 and 6 describe the experiment settings,
the evaluation results and give some illustrative examples to show
the performance of CSRS. Section 7 discusses threats to validity.
Finally, Section 8 concludes the paper and illustrates future work.

2 RELATED WORK
The purpose of code search task is to search for relevant code
snippets in the code base according to the query statements entered
by the user, while the neural IR models are usually used to retrieve
relevant documents, which is similar to code search. Thus, we will
introduce the related work of code search (Sec.2.1) and neural IR
(Sec.2.2) in the next two subsections.

2.1 Code Search
In recent years, a lot of studies have emerged to improve the per-
formance of code search. The prior studies are mostly based on
information retrieval techniques, which focus on query reformu-
lation and keyword matching between natural language queries
and code snippets. For instance, McMillan et al. [21] proposed Port-
folio, which returns a series of code fragments through keyword
matching and PageRank. Haiduc et al. [7] proposed a machining
learning model Refoqus to recommend a reformulation strategy
based on the properties of the query to improve its performance.
Sourcerer [17] is an infrastructure for large-scale code search based
on Lucene1.

In recent years, with the rapid development of deep learning,
many researchers use deep learning techniques to implement code
search models. Gu et al. [5] first designed a deep learning model
DeepCS, which uses the LSTMs to embed codes and queries into
the unified semantic space. Based on DeepCS, Shuai et al. [25]
proposed a co-attentive representation learning model to capture
the correlations between query and code. Xu et al. [31] introduced
a two-stage attention-based model to learn the semantic correlation
effectively and efficiently.

In addition, many deep learning models use the structure infor-
mation of the code. Wan et al. [28] developed a multimodal rep-
resentation method to represent the unstructured and structured
features of source code, in which LSTM, tree LSTM, and GGNN
(Gating Graph Neural Network) [15] are used to represent the to-
kens, the AST (Abstract Syntax Tree) and the CFG (Control Flow
Graph) of the code. Sun et al. [26] proposed PSCS that encodes both
the semantics and structures of code represented by AST paths.
Ling et al. [16] represented both queries and code snippets with
the unified graph-structured data, and then match two graphs to
retrieve the best code snippet.

Furthermore, some studies improve the performance of code
search by introducing other code-related tasks. Yao et al. [32] pro-
posed a code annotation model to generate code comments of the
given code snippets that can be leveraged by the code retrieval

1https://lucene.apache.org/

Figure 1: An example of code search.

use neural networks to build IR models and apply it to document
retrieval [6, 10, 23, 24, 30], while this kind of IR method is called
neural information retrieval (i.e. neural IR). Therefore, it is possible
to obtain the relevance and semantic correlations between queries
and code snippets.

As shown in Fig.1, the common keywords "array", "new", and
"size" are shared in the query and the code, which indicates that
the code snippet has relevance to the query. In addition, the query
in Fig.1 is semantically correlated with the code. Therefore, in this
work, we propose a code search model CSRS (Code Search with
Relevance Matching and Semantic Matching) to learn the relevance
and semantic relationship between query and code. Specifically,
CSRS contains a CNN-based encoding module to extract n-gram em-
bedding from query and code, a neural IR based relevance matching
module that measures keyword matches using n-gram embedding
to generate an interaction matrix, and a semantic matching module
that learns the semantic relationship between query and code by
the co-attention mechanism.

To evaluate the effectiveness of CSRS, we conduct a series of
experiments on the dataset shared by Gu et al. [5] which contains
18.22M and 10k query-code pairs for the training set and testing set
separately. We compare CSRS with two DL-based baseline models
DeepCS and CARLCS-CNN. Experimental results show that CSRS
achieves an MRR (mean reciprocal rank) of 0.614, outperforming
DeepCS and CARLCS-CNN by 33.77% and 18.53% respectively.
In summary, this paper makes the following contributions:

• We introduce the neural IR method into code retrieval and
design a relevance matching module based on neural IR that
captures keyword matching signals (e.g. words, terms, and
phrases) between query-code pairs.

• We design a semantic matching module based on the co-
attention mechanism which can learn the semantic repre-
sentation of queries and code snippets.

• We propose a novel code search model CSRS that combines
our neural IR based relevance matching module and the
semantic matching module. CSRS can simultaneously cap-
ture keyword matching signals and semantic correlations
between queries and codes.

• We evaluate CSRS on a large-scale dataset. The experimental
results demonstrate that our model can advance code search

//Query: Reallocates an array with a new size//Code:publicstaticObjectresizeArray(ObjectoldArray,intnewSize) {intoldSize=java.lang.reflect.Array.getLength(oldArray);ClasselementType=oldArray.getClass().getComponentType();ObjectnewArray=java.lang.reflect.Array.newInstance(elementType,newSize);intpreserveLength=Math.min(oldSize,newSize);if(preserveLength>0)System.arraycopy(oldArray,0,newArray,0,preserveLength);returnnewArray;}CSRS: Code Search with Relevance Matching and Semantic Matching

ICPC ’22, May 16–17, 2022, Virtual Event, USA

model, which can distinguish relevant codes better from others.
Ye et al. [33] utilized the code generation model to improve code
retrieval via dual learning. Bui et al. [2] introduced a self-supervised
contrastive learning framework to alleviate the need of labeled data
for code retrieval.

In general, although DL-based models have achieved consid-
erable results in the code search task, most of the above methods
convert the query and code into a vector representation, which only
retains the semantic information of queries and codes. While the
IR-based models can only obtain the lexical correlations between
queries and code snippets, which lack the support of semantic in-
formation. We believe that the combination of the two categories
of models can enrich the matching information and improve the
ability of the code search model.

2.2 Neural Information Retrieval
In general, the aim of IR is to retrieve the relevant documents
according to the queries. The IR methods represent queries and
documents by words. The final ranking is based on the lexical match-
ing between query words and document words, and the matching
features are manually defined, which can be incomplete and time-
consuming. Recently, with the successes of deep learning in many
related areas, neural IR methods have the ability to improve the
performance of traditional IR.

Existing neural IR models can be divided into two categories:
representation based and interaction based [6]. The early studies
mainly focus on representation based models, which try to construct
representations of queries and documents, and the ranking is to
match the similarity of the representations. For example, DSSM
[10] projects queries and documents into a low-dimensional space
where the distance is computed as the relevance between them.
Based on the DSSM, Shen et al. [24] used a convolutional-pooling
structure to improve the performance. These methods directly learn
the representation of queries and documents without considering
the interactions between them.

The interaction based models learn word-level matching signals
by building the translation matrix from word pairs between queries
and documents, then summarizing it into a ranking score. Guo et
al. [6] utilized the pyramid pooling technique to summarize the
translation matrix. Xiong et al. [30] proposed K-NRM that uses
kernel-based pooling to obtain matching signals at different levels.
Mitra et al. [23] combined representation based and interaction
based models to improve the performance.

In the document retrieval task, compared with traditional IR
methods, neural IR methods can capture lexical matching signals
through neural networks without manually defining matching fea-
tures. Inspired by this, we use the neural IR based method to con-
struct the relevance matching module for queries and codes.

3 PRELIMINARIES
In this section, we briefly introduce some background knowledge of
CSRS. We first discuss the code representation using deep learning
techniques for the code search task in subsection 3.1. Then we
illustrate the preliminary of attention mechanism in subsection 3.2.

3.1 Code Representation
In the code search task, code representation is a basic step toward
understanding the code. Like the neural language, a code snippet
should be mapped into a vector space so that it can be fed to the
deep neural network for subsequent calculations.

We can extract three features from the code snippet shown in
Fig.1: (1) method name, a sequence of tokens split by camel case;
(2) API sequence, a list of API words called in the code snippet;
(3) code tokens, a list of words used in the method body. First, a
vocabulary is employed to encode the words of the three features.
Then the words in three features are converted into vectors with
the same dimension. Each feature can be represented by a vector
matrix. Finally, the three original vector matrices are fed into neural
networks to obtain the embedded three feature matrices.

In the existing researches, DeepCS embeds the API sequence
sapi and method name sname by LSTM, while the code tokens stok
are embedded by a multilayer perceptron (MLP)[3]. The final code
representation c for DeepCS is computed in Eq.(1). As shown in
Eq.(2), CARLCS-CNN uses LSTM to embed the API sequence, and
the method name and code tokens are embedded by CNN. Recently,
TabCS proposes to use the attention mechanism to encode three
code features, as shown in Eq.(3).

c = 𝐿𝑆𝑇 𝑀 (sapi) + 𝐿𝑆𝑇 𝑀 (sname) + 𝑀𝐿𝑃 (stok)
c = 𝐿𝑆𝑇 𝑀 (sapi) + 𝐶𝑁 𝑁 (sname) + 𝐶𝑁 𝑁 (stok)
c = 𝐴𝑡𝑡 (sapi) + 𝐴𝑡𝑡 (sname) + 𝐴𝑡𝑡 (stok)

(1)

(2)

(3)

3.2 Attention Mechanism
Encoder-decoder models have achieved a lot of success in tasks like
machine translation and text summarization. As the sentence length
increases, the performance of the basic encoder-decoder model will
decline sharply. To tackle this issue, the attention mechanism was
proposed by Bahdanau et al. [1], which allows the model to focus
on the relevant parts of the long input sequence. The basic attention
mechanism takes the input sequence as three matrices: query matrix
(𝑄), key matrix (𝐾), and value matrix (𝑉 ), and each matrix consists
of word vectors. The aim of the attention mechanism is to weigh
the value vector by calculating the attention score through the
query vector and key vector. Formally, the attention score can be
computed as follows:

𝐴𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛(𝑄, 𝐾) = 𝑔(𝑓 (𝑄, 𝐾))
where 𝑔 is the activation function, and 𝑓 is the attention score
function which can be a multi-layer perceptron [1], dot product
function [19], and scaled dot product [27]. After the calculation of
the attention score, we obtain the final attention by weighing the
value vector using the attention scores:

(4)

∑︁

𝛼 =

𝑖

𝐴𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛𝑖 (𝑄𝑖, 𝐾𝑖 )𝑉𝑖

(5)

where 𝐴𝑡𝑡𝑒𝑛𝑡𝑖𝑜𝑛𝑖 is the 𝑖-th attention score, and 𝑄𝑖 , 𝐾𝑖 , 𝑉𝑖 are the
𝑖-th element in query, key and value vector matrix respectively.

4 PROPOSED MODEL
In this section, we present the design and implementation details
of our proposed model CSRS.

ICPC ’22, May 16–17, 2022, Virtual Event, USA

Yi Cheng and Li Kuang

Figure 2: The architecture of CSRS. The model consists of three major modules: (1) a CNN-based embedding module that gen-
erates n-gram embeddings; (2) a relevance matching module for learning keyword matching signals; (3) a semantic matching
module with co-attention mechanisms for learning semantic matching signals.

4.1 Overview
Fig.2 illustrates the overall structure of CSRS. The model is com-
posed of three major parts: (1) a CNN based embedding module,
which uses convolution kernels of different sizes to generate n-
gram embeddings of descriptions and codes (Sec.4.2); (2) a rel-
evance matching module that measures keyword matches (e.g.
words, terms, and phrases) between descriptions and code snip-
pets (Sec.4.3); (3) a semantic matching module with the co-attention
mechanism for learning semantic matching signals (Sec.4.4). Finally,
we feed the relevance matching features and semantic matching
features to an MLP, and then output the matching score of the
description and code.

4.2 Embedding Module
Code Embedding. Each code snippet consists of three parts: method
name, API sequence, and tokens. Firstly, for each feature of the
code, we use an embedding layer to convert each word into a vector.
However, using this kind of embedding is equivalent to treating
each word as a unigram. In this way, it is difficult to express the
information of specific terms composed of multiple words in the
code, such as "quickSort", "HashMap" and so on. We hope to match
these terms as n-grams instead of splitting them into unigrams for
matching. Therefore, we employ CNN to compose adjacent words’
embeddings to n-gram embeddings. We implement the n-gram
embeddings of description and code through the following steps.

Figure 3: The embedding process of code tokens.

Firstly, code token is a list of words extracted from the method
body, in which duplicate words, stop words, and Java keywords are
not included.

The implementation of n-gram embeddings for code tokens is
i ∈ R𝑑 be a 𝑑-dimensional word initial vector
shown in Fig.3. Let eT
corresponding to the 𝑖-th word in code tokens. A code tokens se-
quence with length 𝑛𝑡 can be represented by an embedding matrix
𝐸𝑇 ∈ R𝑛𝑡 ×𝑑 as shown in Eq.(6).
𝐸𝑇 = [eT
1

, . . . , eT
nt

, eT
2

(6)

]

Code FeatureMatrix CRelevance MatchingMatrix𝑅=𝑄𝐶𝑇CNN embedCNN embedSemantic Matrix𝑆=tanh(𝑄𝑊𝐶)Query FeatureMatrix QParameterMatrix WMax PoolingMean PoolingQuery AttentionVector 𝑎𝑄Code AttentionVector 𝑎𝐶Dot Product𝐶𝑇𝑎𝐶Dot Product𝑄𝑇𝑎𝑄MLPMatchScore1. EmbeddingModule2. Relevance Matching Module3. Semantic Matching Modulelistsizeelementequalsgetremove𝑡11𝑡21…𝑡81𝑡12𝑡22…𝑡72𝑡13𝑡23…𝑡63𝑻𝟏(unigrams)𝑻𝟐(bigrams)𝑻𝟑(trigrams)Code TokenMatrix TconcatCode TokensEmbedding MatrixCSRS: Code Search with Relevance Matching and Semantic Matching

ICPC ’22, May 16–17, 2022, Virtual Event, USA

, . . . ,𝑊 𝑇

Then the convolutional layer applies convolution filters to compose
n-grams from the code tokens. We use 𝑑 different convolution filters
𝑊 𝑇
𝑑 ∈ Rℎ×𝑑 slide over the code tokens embedding matrix
1
𝐸𝑇 like a sliding window, where ℎ from 1 to 3 denotes the width
of convolution kernels. For each window of ℎ words, the filter 𝑊 𝑇
𝑗
sums up all elements in the ℎ words’ embeddings 𝐸𝑇
, and
produces a feature score 𝑣𝑡

𝑗 as follows:
𝑗 ∗ 𝐸𝑇
where 𝑗 ∈ {1, 2, . . . , 𝑑 }, b ∈ R is a bias term, ∗ is the convolution
operator and 𝑓 is a non-linear function such as the hyperbolic
tangent. The 𝑑 filters produce 𝑑 feature scores, so that we can
obtain a 𝑑-dimensional code tokens embedding for the h-gram:

𝑗 = 𝑓 (𝑊 𝑇
𝑣𝑡

𝑖:𝑖+ℎ−1 + b)

𝑖:𝑖+ℎ−1

(7)

, 𝑣𝑡
2
Thus, the convolution layer converts the code tokens embedding
matrix 𝐸𝑇 into h-gram embedding matrix 𝑇 ℎ ∈ R(𝑛𝑡 −ℎ+1)×𝑑 .

i = [𝑣𝑡
th

, . . . , 𝑣𝑡
𝑑 ]

(8)

1

𝑇 ℎ = [th
1

, . . . , th
nt

, th
2
Specifically, the window size ℎ ranges from 1 to 3, which means
we can get three ℎ-gram embedding matrices: 𝑇 1 for unigram, 𝑇 2
for bigram, and 𝑇 3 for trigram. Then, three h-gram embedding
matrices are concatenated into the final code tokens matrix 𝑇 :

(9)

]

𝑇 = 𝑇 1 ⊕ 𝑇 2 ⊕ 𝑇 3

(10)

where ⊕ is the concatenation operator.

For a given method name, such as "getValue", we split it into a
sequence of words according to the camal-case naming convention.
Given a method name sequence of length 𝑛𝑚, its original embedding
matrix is 𝐸𝑀 = [eM
denotes the 𝑖-th
1
word embedding in method name sequence. The n-gram embedding
matrix 𝑀 for the method name are generated using the same way
as code token embedding.

] ∈ R𝑛𝑚×𝑑 , where eM
i

, . . . , eM
nm

Given an API sequence of length 𝑛𝑎, such as "getThemeImage,
Map, put", its original embedding matrix is 𝐸𝐴 = [eA
] ∈
1
R𝑛𝑎×𝑑 , where eA
denotes the 𝑖-th word embedding in the API
i
sequence. We use the same method to obtain the final API feature
matrix 𝐴.

, . . . , eA
na

After converting the three parts of the code into n-gram embed-
dings, we get three code feature matrices, we eventually concatenate
them into the final code feature matrix 𝐶 ∈ R𝑛×𝑑 .

𝐶 = 𝑇 ⊕ 𝑀 ⊕ 𝐴

(11)

Description Embedding. The description indicates the user’s
query intention, which also contains special terms. Therefore, for
the given description 𝐸𝐷 = [eD
de-
1
notes the 𝑖-th word embedding in the description. As shown in
, . . . ,𝑊 𝐷
Eq.(12)-(13), we use 𝑑 different convolution kernels 𝑊 𝐷
𝑑 ∈
1
Rℎ×𝑑 for convolution operation, and the feature scores 𝑣𝑑
𝑗 generated
by each convolution kernel are considered as n-gram embedding
vectors 𝑑ℎ
𝑖 .

m] ∈ R𝑚×𝑑 , where eD

, . . . , eD

i

𝑣𝑑
𝑗 = 𝑓 (𝑊 𝐷
i = [𝑣𝑑
dh

1

𝑗 ∗ 𝐸𝐷

𝑖:𝑖+ℎ−1 + b)
, . . . , 𝑣𝑑
𝑑 ]

, 𝑣𝑑
2

(12)

(13)

The h-gram embedding matrix 𝐷ℎ consists of n-gram embedding
vectors 𝑑ℎ
𝑖 . We obtain the final description feature matrix 𝐷 ∈ R𝑚×𝑑
by concatenating ℎ n-gram embedding matrices:

𝐷ℎ = [dh
1

, . . . , dh

, dh
2
𝐷 = 𝐷1 ⊕ 𝐷2 ⊕ 𝐷3

m]

(14)

(15)

4.3 Relevance Matching Module
This section describes our efforts to capture keyword matching
signals for relevance matching, which measures soft term matches
between description-query pairs. We build the interaction matrix
𝑅 by multiplying the description feature matrix 𝐷 ∈ R𝑚×𝑑 and
the code feature matrix 𝐶 ∈ R𝑛×𝑑 , which aims to calculate the
relevance score between the description and the code:

(16)

𝑅 = 𝐷𝐶𝑇
where 𝑅𝑖,𝑗 can be considered the similarity score by matching the
description n-gram vector 𝐷 [𝑖] with the code n-gram vector 𝐶 [ 𝑗].
Since in the description and code, similar n-grams will have
closer embedding vectors, their product will produce larger scores.
Next, we obtain a normalized relevance matching matrix ^𝑅 by ap-
plying a softmax function over the code columns of 𝑅 to normalize
the similarity scores into the [0, 1] range. For each description n-
gram 𝑖, the softmax function normalizes its matching scores over
all n-grams in the code and makes the similar n-grams have a score
closer to 1.0. Then we leverage 𝑚𝑎𝑥 and 𝑚𝑒𝑎𝑛 pooling to obtain
two relevance matching feature vectors for the matrix ^𝑅:

oRM
max = [𝑚𝑎𝑥 ( ^𝑅1,:), . . . , 𝑚𝑎𝑥 ( ^𝑅𝑛,:)]
oRM
mean = [𝑚𝑒𝑎𝑛( ^𝑅1,:), . . . , 𝑚𝑒𝑎𝑛( ^𝑅𝑛,:)]

(17)

(18)

4.4 Semantic Matching Module
In addition to relevance matching, the semantic matching module
aims to capture semantic correlations via co-attention mechanisms
on the description and code feature matrices. Unlike the basic at-
tention mechanism, the co-attention mechanism can focus on the
description attention and the code attention simultaneously, and
learn the semantic vector representation of both.

In detail, we take the description feature matrix 𝐷 ∈ R𝑚×𝑑 and
code feature matrix 𝐶 ∈ R𝑛×𝑑 as the query matrix and the key
matrix of the attention mechanism. The attention matrix 𝑆 ∈ R𝑚×𝑛
can be calculated by 𝐷, 𝐶 and a parameter matrix𝑊 ∈ R𝑑×𝑑 learned
by the neural networks. We use the 𝑡𝑎𝑛ℎ activation function to scale
each element in 𝑆 between -1 and 1.

𝑆 = 𝑡𝑎𝑛ℎ(𝐷𝑊 𝐶)

(19)

The attention matrix 𝑆 can focus on the semantic correlation
between descriptions and codes. 𝑆𝑖,𝑗 represents the semantic match-
ing score between the description n-gram feature vector 𝐷 [𝑖] and
the code n-gram feature vector 𝐶 [ 𝑗]. Specifically, the 𝑖-th row in 𝑆
denotes the semantic correlations of the 𝑖-th n-gram in description
to each n-gram in code. Similarly, the 𝑗-th column in 𝑆 denotes the
semantic correlations of the 𝑗-th n-gram in code to each n-gram in
the description.

Then, we employ 𝑚𝑎𝑥 pooling along rows and columns over
𝑆 as follows, which denotes that we can focus on the description

ICPC ’22, May 16–17, 2022, Virtual Event, USA

Yi Cheng and Li Kuang

attention and the code attention:

Table 1: Statistics For Java-small Dataset

(20)

𝐷 = [𝑚𝑎𝑥 (𝑆1,:), . . . , 𝑚𝑎𝑥 (𝑆𝑚,:)]
u
𝐶 = [𝑚𝑎𝑥 (𝑆:,1), . . . , 𝑚𝑎𝑥 (𝑆:,𝑛)]
(21)
u
where the 𝑖-th element of u𝐷 ∈ R𝑚 represents a semantic score
between the 𝑖-th n-gram in description 𝐷 and its most semantically
similar n-gram in code 𝐶, and the 𝑖-th element of u𝐶 ∈ R𝑛 repre-
sents a semantic score between the 𝑖-th n-gram in code 𝐶 and its
most semantically similar n-gram in description 𝐷. Next, we ob-
tain the description attention weight vector and the code attention
weight vector by transforming u𝐷 and u𝐶 into a𝐷 and a𝐶 using
softmax function.

(22)

𝐷
𝑖 =
a

,

exp (u𝐷 )
(cid:205)𝑚
𝑝=1 exp (u𝐷
𝑝 )
𝐷
𝑚],
, . . . , a

𝐶
𝑖 =
a

exp (u𝐶 )
(cid:205)𝑛
𝑞=1 exp (u𝐶
𝑞 )
𝐶
, . . . , a
𝑛 ]

𝐶
𝐶 = [a
a
1

𝐷
𝐷 = [a
a
1

(23)
Finally, based on the two attention weight vectors, the final
description attention vector o𝑆𝑀
and the code attention vector
𝑑𝑒𝑠𝑐
o𝑆𝑀
can be calculated as the weighted sum of the description
𝑐𝑜𝑑𝑒
feature matrix 𝐷 and the code feature matrix 𝐶. We take the two
vectors o𝑆𝑀
and o𝑆𝑀
as the description semantic vector and the
𝑐𝑜𝑑𝑒
𝑑𝑒𝑠𝑐
code semantic vector.
𝑑𝑒𝑠𝑐 = 𝐷𝑇
𝑆𝑀
o

𝑐𝑜𝑑𝑒 = 𝐶𝑇
𝑆𝑀
o

𝐷,
a

(24)

𝐶
a

, o𝑆𝑀

max, oRM

mean, o𝑆𝑀
𝑑𝑒𝑠𝑐

4.5 Prediction
After all the computation of the relevance matching module and
the semantic matching module, we obtain the matching features
𝑐𝑜𝑑𝑒 }. Then we concatenate all features to
{oRM
the final feature vector o, and feed o to a two-layer perceptron fol-
lowed by a ReLU activation. We express the output of the two-layer
perceptron as the matching score, and divide the scores into two
categories. The first class indicates that the input natural language
description is related to the code, and the output value is closer to
1, while the second class indicates that the input natural language
description is not related to the code, and the output value is closer
to 0.

o = oRM

max ⊗ oRM

mean ⊗ o

𝑆𝑀
𝑑𝑒𝑠𝑐 ⊗ o

𝑆𝑀
𝑐𝑜𝑑𝑒

(25)

4.6 Training
During training, we let each training data be a triple < D, C, L >,
where D is the description, C is the code and L represents the
ground truth class. We use Adam algorithm [12] to minimizing
cross-entropy loss in the training process:

𝑙𝑜𝑠𝑠 = −

2
∑︁

𝑖=1

𝑙 (𝑖) log 𝑔(𝑖)

(26)

where 𝑙 denotes the ground truth class, 𝑔 is the matching score
computed by CSRS.

4.7 Implementation Details
To conduct our experiment, we set the word embedding size to
100, and the batch size is set as 128. In order to avoid overfitting,
we use the dropout technique [8] and set the drop rate to 0.25. We
initialize the Adam optimizer [12] with the learning rate 0.0001. All
the experiments are implemented using the Keras 2.3.1 framework

Dataset

Size

Training
Testing

18223872
10000

Avg
Query
9.89
9.87

Avg
Token
10.30
10.29

Avg
Methname
2.48
2.49

Avg
Apiseq
8.39
8.33

with Python 3.6, and the experiments are conducted on a computer
with a GeForce RTX 2080 Ti GPU with 11 GB memory, running on
Ubuntu 16.04.

5 EXPERIMENT SETUP
In this section, we first report several research questions (RQs)
and experiment results. Then we describe the dataset, evaluation
metrics, and several baselines.

5.1 Research Questions
Our work aims to answer the following four research questions:

• RQ1: How does our proposed model perform?

To answer this question, we conduct an experiment to inves-
tigate whether our proposed model performs better than two
state-of-the-art baseline models DeepCS [5] and CARLCS-
CNN [25].

• RQ2: What is the contribution of each module in CSRS?
In RQ2, we focus on exploring the contribution of the rele-
vance matching module and semantic matching module to
CSRS. Specifically, we start with the complete model and
then remove each module in turn to understand its effective-
ness.

• RQ3: How do the three code features affect the model?
We use three code features (i.e. method name, API sequence,
and code tokens) to represent a whole code method. In order
to understand the impact of these three code features on
CSRS, we train CSRS using individual features separately,
and then compare with the complete model to analyze the
impact of each feature.

• RQ4: How does the window size affect the model effec-

tiveness?
In the embedding module, we let the window size be 1, 2,
and 3 to capture unigram, bigram, and trigram respectively.
This RQ mainly focuses on the choice of window size. Due
to analyzing the effectiveness of the choice of window size,
we run CSRS with individual window size so that the model
can only generate one n-gram embedding.

5.2 Dataset
We evaluate our approach on Gu’s [5] dataset. The dataset for train-
ing contains 18,223,872 commented Java code methods collected
from GitHub repositories with at least one star from August 2008
to June 2016. The testing dataset contains 10,000 code-query pairs.
As shown in Table 1, we also count the average tokens of the de-
scription and the three features of code snippets in the training and
testing dataset.

CSRS: Code Search with Relevance Matching and Semantic Matching

ICPC ’22, May 16–17, 2022, Virtual Event, USA

5.3 Evaluation Metrics
We evaluate the performance of CSRS by using three common met-
rics: recall, MRR (Mean Reciprocal Rank) and NDCG (Normalized
Discounted Cumulative Gain) [11]. The three metrics are defined
as follows:

• Recall@k calculates the proportion of queries that the rele-
vant code could be found in the top-𝑘 ranked list. 𝑅𝑒𝑐𝑎𝑙𝑙@𝑘
is computed as follows:

𝑅𝑒𝑐𝑎𝑙𝑙@𝑘 =

1
|Q|

| Q |
∑︁

𝑖=1

𝐼 (Q𝑖 ≤ 𝑘)

(27)

where Q is the 10,000 queries in testing dataset, 𝐼 is the
indicator function that returns 1 if the code related to 𝑖-
th query Q𝑖 is in the top-k list, otherwise it returns 0. We
evaluate 𝑅𝑒𝑐𝑎𝑙𝑙@𝑘 when 𝑘’s value equals 1, 5 and 10. These
values reflect the typical lengths of ranked list that users
would focus[14].

• MRR counts the average of the reciprocal ranks of all queries

Q. The MRR is computed as follows:

𝑀𝑅𝑅 =

1
|Q|

| Q |
∑︁

𝑖=1

1
𝑅𝑎𝑛𝑘 Q𝑖

(28)

where Q is the 10,000 queries in testing dataset, 𝑅𝑎𝑛𝑘 Q𝑖
denotes the rank of the ground truth code related to the 𝑖-th
query Q𝑖 in the top-𝑘 ranked list. Following Gu et al.[5], We
let 𝑘 equal to 10. If the ground truth code is not in the ranked
list, we set the

equal to 0.
• NDCG measures the correlation between the ranking result
of code snippets and the query. The idea of 𝑁 𝐷𝐶𝐺 is that
the results of high correlation affect the final 𝑁 𝐷𝐶𝐺 score
more than the results of general correlation, and when the
results with high correlation appear in the front position, the
𝑁 𝐷𝐶𝐺 score will be higher. We calculate 𝑁 𝐷𝐶𝐺 as follows:

1
𝑅𝑎𝑛𝑘Q𝑖

𝑁 𝐷𝐶𝐺 =

1
|Q|

𝑘
∑︁

𝑖=1

2𝑟𝑖 − 1
log2 (𝑖 + 1)

(29)

where Q denotes the 10k queries in testing dataset, 𝑘 equals
to 10, and 𝑟𝑖 is the relevance score of the top-𝑘 results at
position 𝑖.

5.4 Baselines
DeepCS. The first model uses the deep learning method proposed
by Gu et al. [5], which embeds query and code features separately
with two different LSTM models. We reproduce the DeepCS by the
open source code shared on GitHub2.
CARLCS-CNN. A code search model based on CNN, which uses
co-attention mechanism to construct the semantic relationship
between code snippets and their queries. We also reproduce the
source code shared by Shuai et al.3 [25].

6 RESULTS
In this section, we first report our experimental results and an-
swer research questions described in Sec 5.1 respectively. Then, we
provide several illustrative examples to show the effect of CSRS.

6.1 RQ1: Model Effectiveness
We compare CSRS with two state-of-the-art models DeepCS and
CARLCS-CNN under the 𝑅𝑒𝑐𝑎𝑙𝑙@𝑘, 𝑀𝑅𝑅 and 𝑁 𝐷𝐶𝐺 evaluation
metrics. The evaluation results are presented in Table 2.

Table 2: Comparison of the effects of DeepCS and CARLCS-
CNN

Model
DeepCS
CARLCS-CNN
CSRS

Recall@1 Recall@5 Recall@10 MRR NDCG
0.522
0.459
0.518
0.577
0.614 0.674

0.624
0.674
0.787

0.337
0.402
0.486

0.720
0.762
0.864

As we can see from Table 2, CSRS provides the best results com-
pared with two state-of-the-art models. For the metric of 𝑅𝑒𝑐𝑎𝑙𝑙
@1/5/10, CSRS achieves 0.486/0.787/0.864 respectively, which out-
performs the DeepCS and CARLCS-CNN by 44.21%/26.12%/20.00%
and 20.90%/16.77%/13.39% respectively. CSRS achieves an 𝑀𝑅𝑅 of
0.614, which improves DeepCS by 33.77% and CARLCS-CNN by
18.53%. In addition, CSRS achieves 0.674 for 𝑁 𝐷𝐶𝐺, which advances
DeepCS and CARLCS-CNN by 29.12% and 16.81%.

Result 1: Our proposed model outperforms two state-of-
the-art models DeepCS and CARLCS-CNN with the evalu-
ation metrics of 𝑅𝑒𝑐𝑎𝑙𝑙@𝑘, 𝑀𝑅𝑅 and 𝑁 𝐷𝐶𝐺.

6.2 RQ2: The contribution of Two Matching

Modules

To answer RQ2, we conduct the ablation experiment to investigate
the contribution of two matching modules. We test by removing
one matching module separately:

Relevance Matching (RM): The relevance matching module
focus on the lexical matching between the queries and code snip-
pets. We remove the semantic matching module to evaluate the
contribution of the relevance matching module.

Semantic Matching (SM): The semantic matching module aims
to capture the semantic correlation between the queries and code
snippets. Similarly, we delete the relevance matching module to
figure out the contribution of the semantic matching module.

Table 3: The contribution of each matching module

Model Recall@1 Recall@5 Recall@10 MRR NDCG
0.602
0.539
0.574
0.634
0.614 0.674

CSRS(RM)
CSRS(SM)
CSRS

0.706
0.737
0.787

0.802
0.823
0.864

0.416
0.452
0.486

2https://github.com/guxd/deep-code-search
3https://github.com/cqu-isse/CARLCS-CNN

Table 3 illustrates the reduction in metrics when the module
is removed. RM results in a decrease of 𝑀𝑅𝑅 by 13.91%, where

ICPC ’22, May 16–17, 2022, Virtual Event, USA

Yi Cheng and Li Kuang

the 𝑀𝑅𝑅 of SM drops by 6.97%. For the metric 𝑁 𝐷𝐶𝐺, RM and
SM have the decrease by 11.96% and 6.31%. In addition, for the
𝑅𝑒𝑐𝑎𝑙𝑙@𝑘 evaluation metric, both RM and SM have different de-
grees of decline. The ablation experiment shows that the complete
model is superior to RM and SM, which indicates the effectiveness
of the combination of two matching modules.

Table 5 shows that three different sizes of convolution kernels
can improve the effectiveness of CSRS. As we expected, the kernel of
size 1 contributes more to the complete model. Meanwhile, the best
performance can be obtained by using three sizes of convolution
kernels at the same time.

Result 2: Both relevance matching and semantic match-
ing are effective, while the combination of two matching
modules performs the best.

Result 4: The three different sizes of convolution kernels
are all necessary. The convolution kernel with width 1 is
close to the effect of the complete model, while the combi-
nation achieves the best performance.

6.3 RQ3: The Impact of Different Code Features
Three code features are used in CSRS, including method name (M),
API sequence (A), and code tokens (T). In order to find out the
impact of these code features, we trained three models, each of
which uses only M, A, or T as the input code feature.

Table 4 reported the evaluation results. We can observe that only
using the method name, API sequence or code tokens results in a
drastic decrease of 𝑀𝑅𝑅 and 𝑁 𝐷𝐶𝐺, which denotes that all code
features can improve the performance of CSRS.

Table 4: Comparison of the effects of the three code features

Model Recall@1 Recall@5 Recall@10 MRR NDCG
0.513
CSRS(M)
0.456
0.244
CSRS(A)
0.193
0.409
CSRS(T)
0.474
CSRS
0.614 0.674

0.596
0.302
0.568
0.787

0.694
0.411
0.681
0.864

0.350
0.109
0.291
0.486

6.5 Illustrative Examples
Fig.4 shows the top 1 search result of CSRS and CARLCS-CNN
for the query "return the value at index or null if that is out of
range". It can be observed from Fig.4(a) that CSRS can retrieve the
ground truth code snippet, because there are many overlaps be-
tween the query and the code, such as "value", "index" and "null",
which demonstrates the effectiveness of the relevance matching
module in CSRS. Meanwhile, it also illustrates that CSRS can un-
derstand the semantic of "out of range" in the query. In contrast,
Fig.4(b) shows that CARLCS-CNN returns a irrelevant code.

Fig.5 shows another search result for the query "get current
time stamp". Obviously, from Fig.5(a), we can see that the query
words can match the method name exactly in the first result of
CSRS. Moreover, the query word "time" semantically correlates
with the word "date" in the code snippet. However, Fig.5(b) shows
that CARLCS-CNN can not retrieve the correct code.

To sum up, the above two cases illustrate that CSRS can cap-
ture both keyword matching information and semantic matching
information.

Result 3: The result shows that the three code features(i.e.
method name, API sequence, and code tokens) have an
effect on the proposed model CSRS, while the method
name is the most effective feature.

6.4 RQ4: The Effects of Different Convolution

Kernel Size in CNN

In the embedding module, we use three different sizes of convolu-
tion kernels to obtain n-gram embeddings. To explore the impact
of using only one size of kernel on the model, we ran three models
which only use kernels with sizes of 1 (Conv1), 2 (Conv2), or 3
(Conv3) respectively.

(a) The top 1 result of CSRS

Table 5: The effect of different sizes of convolution kernels
on the effectiveness of CSRS

(b) The top 1 result of CARLCS-CNN

Model
CSRS(Conv1)
CSRS(Conv2)
CSRS(Conv3)
CSRS

Recall@1 Recall@5 Recall@10 MRR NDCG
0.593
0.652
0.518
0.585
0.618
0.554
0.614 0.674

0.838
0.799
0.819
0.864

0.473
0.386
0.427
0.486

0.751
0.699
0.728
0.787

Figure 4: The top 1 search result of CSRS and CARLCS-CNN
for the query "return the value at index or null if that is out
of range"

publicValuegetValue(intindex) { if( values ==null||values.size() ==0||index >=values.size()){returnnull;}returnvalues.get(index);}publicIterable<AnalysisPhase>getIndexPhases(StringfieldValue) {returnindexPhasesByFieldValue.get(fieldValue);}CSRS: Code Search with Relevance Matching and Semantic Matching

ICPC ’22, May 16–17, 2022, Virtual Event, USA

REFERENCES
[1] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural ma-
chine translation by jointly learning to align and translate. arXiv preprint
arXiv:1409.0473 (2014).

[2] Nghi DQ Bui, Yijun Yu, and Lingxiao Jiang. 2021. Self-Supervised Contrastive
Learning for Code Retrieval and Summarization via Semantic-Preserving Trans-
formations. In Proceedings of the 44th International ACM SIGIR Conference on
Research and Development in Information Retrieval. 511–521.

[3] Matt W Gardner and SR Dorling. 1998. Artificial neural networks (the multilayer
perceptron)—a review of applications in the atmospheric sciences. Atmospheric
environment 32, 14-15 (1998), 2627–2636.

[4] Wenchao Gu, Zongjie Li, Cuiyun Gao, Chaozheng Wang, Hongyu Zhang, Zenglin
Xu, and Michael R Lyu. 2021. CRaDLe: Deep code retrieval based on semantic
Dependency Learning. Neural Networks 141 (2021), 385–394.

[5] Xiaodong Gu, Hongyu Zhang, and Sunghun Kim. 2018. Deep code search. In 2018
IEEE/ACM 40th International Conference on Software Engineering (ICSE). IEEE,
933–944.

[6] Jiafeng Guo, Yixing Fan, Qingyao Ai, and W Bruce Croft. 2016. A deep relevance
matching model for ad-hoc retrieval. In Proceedings of the 25th ACM international
on conference on information and knowledge management. 55–64.

[7] Sonia Haiduc, Gabriele Bavota, Andrian Marcus, Rocco Oliveto, Andrea De Lucia,
and Tim Menzies. 2013. Automatic query reformulations for text retrieval in soft-
ware engineering. In 2013 35th International Conference on Software Engineering
(ICSE). IEEE, 842–851.

[8] Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and
Ruslan R Salakhutdinov. 2012. Improving neural networks by preventing co-
adaptation of feature detectors. arXiv preprint arXiv:1207.0580 (2012).

[9] Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural

computation 9, 8 (1997), 1735–1780.

[10] Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry
Heck. 2013. Learning deep structured semantic models for web search using
clickthrough data. In Proceedings of the 22nd ACM international conference on
Information & Knowledge Management. 2333–2338.

[11] Kalervo Järvelin and Jaana Kekäläinen. 2002. Cumulated gain-based evaluation
of IR techniques. ACM Transactions on Information Systems (TOIS) 20, 4 (2002),
422–446.

[12] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-

mization. arXiv preprint arXiv:1412.6980 (2014).

[13] Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient-
based learning applied to document recognition. Proc. IEEE 86, 11 (1998), 2278–
2324.

[14] Xuan Li, Zerui Wang, Qianxiang Wang, Shoumeng Yan, Tao Xie, and Hong Mei.
2016. Relationship-aware code search for JavaScript frameworks. In Proceedings
of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software
Engineering. 690–701.

[15] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. 2015. Gated
graph sequence neural networks. arXiv preprint arXiv:1511.05493 (2015).
[16] Xiang Ling, Lingfei Wu, Saizhuo Wang, Gaoning Pan, Tengfei Ma, Fangli Xu,
Alex X Liu, Chunming Wu, and Shouling Ji. 2021. Deep Graph Matching and
Searching for Semantic Code Retrieval. ACM Transactions on Knowledge Discovery
from Data (TKDD) 15, 5 (2021), 1–21.

[17] Erik Linstead, Sushil Bajracharya, Trung Ngo, Paul Rigor, Cristina Lopes, and
Pierre Baldi. 2009. Sourcerer: mining and searching internet-scale software
repositories. Data Mining and Knowledge Discovery 18, 2 (2009), 300–336.
[18] Meili Lu, Xiaobing Sun, Shaowei Wang, David Lo, and Yucong Duan. 2015. Query
expansion via wordnet for effective code search. In 2015 IEEE 22nd International
Conference on Software Analysis, Evolution, and Reengineering (SANER). IEEE,
545–549.

[19] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. 2015. Effec-
tive approaches to attention-based neural machine translation. arXiv preprint
arXiv:1508.04025 (2015).

[20] Fei Lv, Hongyu Zhang, Jian-guang Lou, Shaowei Wang, Dongmei Zhang, and
Jianjun Zhao. 2015. Codehow: Effective code search based on api understanding
and extended boolean model (e). In 2015 30th IEEE/ACM International Conference
on Automated Software Engineering (ASE). IEEE, 260–270.

[21] Collin McMillan, Mark Grechanik, Denys Poshyvanyk, Qing Xie, and Chen Fu.
2011. Portfolio: finding relevant functions and their usage. In Proceedings of the
33rd International Conference on Software Engineering. 111–120.

[22] George A Miller. 1998. WordNet: An electronic lexical database. MIT press.
[23] Bhaskar Mitra, Fernando Diaz, and Nick Craswell. 2017. Learning to match using
local and distributed representations of text for web search. In Proceedings of the
26th International Conference on World Wide Web. 1291–1299.

[24] Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng, and Grégoire Mesnil. 2014.
A latent semantic model with convolutional-pooling structure for information

(a) The top 1 result of CSRS

(b) The top 1 result of CARLCS-CNN

Figure 5: Another search result of CSRS and CARLCS-CNN
for the query "get current time stamp"

7 THREATS TO VALIDITY
Our proposed model may suffer from two threats to validity. The
first one is the implementation of baselines, reproducing the base-
line models by ourselves may cause errors. To reduce this threat,
we re-ran DeepCS and CARLCS-CNN with the source code and
datasets shared by the authors in GitHub.

The second threat to this work is the generalization of the pro-
posed approach. The dataset provided by Gu et al. [5] is obtained
from the open source Java project on GitHub and contains only
about 10,000 testing data. Therefore, the experimental results and
conclusions may be different for using other programming language
datasets or larger testing sets.

8 CONCLUSION AND FUTURE WORK
In this paper, we propose a novel deep learning model for code
search. Our approach consists of two parts, a relevance matching
module to capture n-gram matching signals and a semantic match-
ing module for capturing the semantic correlation between the
queries and the codes. Our experimental results show that CSRS
outperforms DeepCS and CARLCS-CNN in terms of 𝑀𝑅𝑅 by 33.77%
and 18.53%, and 𝑁 𝐷𝐶𝐺 by 29.12% and 16.81%, which achieves a
significant improvement.

We consider two future works. First, we will try to design a more
effective method to combine the relevance matching module and the
semantic matching module. Second, we plan to incorporate external
knowledge such as knowledge graphs or API documentation to
enhance the quality of training data.

ACKNOWLEDGMENT
This work has been supported by the Foundation item: National
Key R&D Program of China (2018YFB1402800); National Natural
Science Foundation of China (61772560).

privatestaticStringgetCurrentTimeStamp() { DateFormatdateFormat=newSimpleDateFormat("yyyy-MM-dd-HH-mm-ss");Datedate=newDate();returndateFormat.format(date);}publiclonggetTimeInMillis() {if(!isTimeSet) computeTime();returntime;}ICPC ’22, May 16–17, 2022, Virtual Event, USA

Yi Cheng and Li Kuang

retrieval. In Proceedings of the 23rd ACM international conference on conference on
information and knowledge management. 101–110.

[25] Jianhang Shuai, Ling Xu, Chao Liu, Meng Yan, Xin Xia, and Yan Lei. 2020. Im-
proving code search with co-attentive representation learning. In Proceedings of
the 28th International Conference on Program Comprehension. 196–207.

[26] Zhensu Sun, Yan Liu, Chen Yang, and Yu Qian. 2020. PSCS: A Path-based Neural
Model for Semantic Code Search. arXiv preprint arXiv:2008.03042 (2020).
[27] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in neural information processing systems. 5998–6008.
[28] Yao Wan, Jingdong Shu, Yulei Sui, Guandong Xu, Zhou Zhao, Jian Wu, and
Philip S Yu. 2019. Multi-modal attention network learning for semantic source
code retrieval. arXiv preprint arXiv:1909.13516 (2019).

[29] Xin Xia, Lingfeng Bao, David Lo, Pavneet Singh Kochhar, Ahmed E Hassan, and
Zhenchang Xing. 2017. What do developers search for on the web? Empirical

Software Engineering 22, 6 (2017), 3149–3185.

[30] Chenyan Xiong, Zhuyun Dai, Jamie Callan, Zhiyuan Liu, and Russell Power. 2017.
End-to-end neural ad-hoc ranking with kernel pooling. In Proceedings of the 40th
International ACM SIGIR conference on research and development in information
retrieval. 55–64.

[31] Ling Xu, Huanhuan Yang, Chao Liu, Jianhang Shuai, Meng Yan, Yan Lei, and Zhou
Xu. 2021. Two-Stage Attention-Based Model for Code Search with Textual and
Structural Features. In 2021 IEEE International Conference on Software Analysis,
Evolution and Reengineering (SANER). IEEE, 342–353.

[32] Ziyu Yao, Jayavardhan Reddy Peddamail, and Huan Sun. 2019. Coacor: Code
annotation for code retrieval with reinforcement learning. In The World Wide
Web Conference. 2203–2214.

[33] Wei Ye, Rui Xie, Jinglei Zhang, Tianxiang Hu, Xiaoyin Wang, and Shikun Zhang.
2020. Leveraging code generation to improve code retrieval and summarization
via dual learning. In Proceedings of The Web Conference 2020. 2309–2319.

