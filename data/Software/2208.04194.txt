2
2
0
2

g
u
A
8

]

A
G
.
h
p
-
o
r
t
s
a
[

1
v
4
9
1
4
0
.
8
0
2
2
:
v
i
X
r
a

Draft version August 9, 2022
Typeset using LATEX default style in AASTeX631

DarkMix: Mixture Models for the Detection and Characterization of Dark Matter Halos
Llu´ıs Hurtado-Gil,1, 2
—

Michael A. Kuhn,3 Pablo Arnalte-Mur,2, 4 Eric D. Feigelson,5, 6 Vicent Mart´ınez2, 4, 7

1eDreams ODIGEO
C/ Bail`en 67-69,
08009 Barcelona, Spain.
2Observatori Astron`omic
Universitat de Val`encia
C/ Catedr`atic Jos´e Beltr´an 2
E-46980, Paterna, Spain
3California Institute of Technology
Pasadena, CA 91125, USA
4Departament d’Astronomia i Astrof´ısica
Universitat de Val`encia
E-46100, Burjassot, Spain
5Department of Astronomy & Astrophysics,
Penn State University
University Park, PA 16802, USA
6Center for Astrostatistics,
Penn State University, University Park, PA 16802, USA
7Unidad Asociada Observatorio Astron´omico (IFCA-UV)
E-46980, Paterna, Spain

(Accepted July 26, 2022)

Submitted to ApJ

ABSTRACT

Dark matter simulations require statistical techniques to properly identify and classify their halos
and structures. Nonparametric solutions provide catalogs of these structures but lack the additional
learning of a model-based algorithm and might misclassify particles in merging situations. With
mixture models, we can simultaneously ﬁt multiple density proﬁles to the halos that are found in a
dark matter simulation. In this work, we use the Einasto proﬁle (Einasto 1965, 1968, 1969) to model
the halos found in a sample of the Bolshoi simulation (Klypin et al. 2011), and we obtain their location,
size, shape and mass. Our code is implemented in the R statistical software environment and can be
accessed on https://github.com/LluisHGil/darkmix.

Keywords: Dark matter distribution (356), Galaxy dark matter halos (1880), Spatial point processes

(1915), Mixture model (1932)

Corresponding author: Llu´ıs Hurtado-Gil
lluis.hurtado@edreamsodigeo.com, lluis.hurtado@uv.es

 
 
 
 
 
 
2

1. INTRODUCTION

1.1. Dark Matter Halos

In 1952, Neyman & Scott proposed the ﬁrst statistical model of large-scale galaxy distribution (Neyman & Scott
1952, 1953, 1954). This model interpreted luminous matter to be distributed in the universe according to a stochastic
process, where a discrete distribution of galaxies is aggregated into overdense clusters that themselves are distributed
in space as a Poisson process. This model needs three main components to be built: the distribution of galaxies within
each cluster, the size distribution of the clusters, and a description of the clustering of clusters. While their original
formulation was too simple, this framework is still a valid approach for the baryonic distribution in the universe and
it can be extended to dark matter distribution (Cooray & Sheth 2002). Here, dark matter is a continuous ﬁeld of
particles that collapses from overdensities into strongly clustered structures, which are called halos. The identiﬁcation
and morphology of these halos is the main topic of the present work.

Analytic models and numeric simulations show how the initial dark matter ﬁeld, which is made of particles, evolves
from an initially smooth state to a highly clustered ﬁnal condition, which results in a complex cosmic web of knots
(the halos), ﬁlaments, sheets and voids (Bertschinger 1985). Simulations show that the halo mass (Moore et al. 1999;
Navarro et al. 1996), abundance and spatial distribution (Church et al. 1997; Jenkins et al. 2001) are highly dependent
on the initial conditions. The ﬁnal structure within a halo can be reasonably assumed to be in virial equilibrium. The
nature and evolution of the galaxies that have formed inside halos is strongly dependent on the parent halo’s properties
(Kauﬀmann et al. 1999; Somerville & Primack 1999; Benson et al. 2001; Colberg et al. 2000), with more galaxies formed
in more massive and clustered halos. However, the galaxy distribution is biased toward stronger clustering conditions
(Madgwick et al. 2003; Zehavi et al. 2011; Hurtado-Gil et al. 2016).

The spherical collapse model is a classic approximation for initial conditions leading to dark matter halos (Gunn
& Gott 1972; Fillmore & Goldreich 1984; Bertschinger 1985). Here, dark matter overdensity collapses from a tophat
density perturbation into a halo that, depending on the overdensity mass and density, virializes when a certain size is
reached. The ﬁnal density of the halo is much higher that the prediction of a linear model because the evolution of the
halo clustering is governed by nonlinear processes, where the densest regions are populated by the most massive halos
(Bardeen 1980; Kaiser 1984) and the dark matter follows a log-normal distribution (Coles & Jones 1991; Hurtado-Gil
et al. 2017; Clerkin et al. 2017).

The shape of the collapsed halos, Bertschinger (1985) and Fillmore & Goldreich (1984) suggests that their density
proﬁle around the center depends on the initial density distribution of the parent overdense region. Although more
massive halos arise from denser peaks in the initial ﬂuctuation ﬁeld (Kaiser 1984; Hoﬀman & Shaham 1985), these
dense peaks are also less centrally concentrated (Bardeen 1980). Massive virialized halos are thereby less centrally
concentrated than less massive halos (Navarro et al. 1996).

Several halo density proﬁles have been proposed, including the Hernquist (1990), Navarro-Frenk-White Navarro et al.
(1996, 1997), and Einasto (1968) proﬁle. In sections 2.1 and 2.2, we introduce the two later proﬁles and we justify our
ﬁnal selection of the Einasto proﬁle.

1.2. Finding Structure with Mixture Models and Other Methods

The growth in volume and detail of astronomical observations and simulations requires automated tools to char-
acterize the properties and evolution of halo structures. These tools should be robust and objective, and should not
depend on heuristic choices or subjective judgment.

Most of the widely-used clustering algorithms for galaxy clustering analysis are nonparametric and are based on
dissimilarity distances, which is a metric that is used to decide if two particles are suﬃciently close to belong to the
same cluster. Astronomers commonly use the Friends-of-Friends algorithm, which is known in statistics as single-linkage
hierarchical agglomerative clustering (Gower & Ross 1969). This method is highly performant and is scalable, which is
crucial for large volume data sets, such as dark matter numerical simulations (Willis et al. 2020). However, this method
is prone to ‘chaining’ of unrelated groupings (Everitt et al. 2011). The resulting clusters depend strongly on the choice
of density or size threshold value. Other nonparametric clustering procedures—such as Ward’s hierarchical clustering,
k-means algorithm, DBSCAN, kernel density estimation bump hunting, and their many extensions—also have heuristic
thresholds or stopping rules with a corresponding loss of objectivity and robustness. These procedures also have the
limitation of giving ‘hard’ classiﬁcations where data points are strictly classiﬁed on one cluster or another without
regard to the reliability of this decision. Therefore, the characterization of merging or blended clusters is limited.
In contrast, parametric methods assume a particular shape to the structures in the population. They also have the

3

advantage that modeling can be based on maximum likelihood estimation or (if prior information is available) Bayesian
inference, without requiring the addition of heuristic thresholds or stopping rules. These methods are typically based
on probability density functions. This allows us to perform statistical tests (e.g., signiﬁcance tests on the parameters)
and goodness of ﬁt validations (e.g., the coeﬃcient of determination) (Rao et al. 1973). Furthermore, they give ‘soft’
probabilities for each point belonging to each cluster. Hard membership classiﬁcations can be decided afterwards using
heuristic decision rules.

These beneﬁts motive us to use ﬁnite mixture models to detect and characterize dark matter structures (Peel &
MacLahlan 2000; McLachlan & Peel 2000; Everitt 2005; Fr¨uhwirth-Schnatter 2006; McLachlan & Krishnan 2007;
Everitt et al. 2011). This technique has been widely used in astronomy and astrophysics with considerable success
(Kuhn et al. 2014; Fruhwirth-Schnatter et al. 2019; Kuhn et al. 2019).

We understand the dark matter distribution to be structured in halos, which can be described by a parametric
surface-density distribution. The halos and other structures are described by the mixture model components, which
are summed to create the surface density function. Mixture models are widely used in parametric modeling of point
processes, usually with Gaussian function components (Fraley & Raftery 2002). As previously explained, we will
instead use an astrophysically motivated function, such as the Einasto proﬁle.

The mixture model is then estimated following a three step method: ﬁrst, the number of components is chosen by
the user; second, the properties of these components are obtained through maximum likelihood parameter estimation
(MLE); and third, the component assignments for dark matter particles are determined using posterior probabilities
from the ﬁtted models (Everitt et al. 2011).

Mixture models are dependent on three main choices: the chosen number of components, the convergence criteria
towards the surface density distribution, and the selected proﬁle. The ﬁrst is assessed using model selection, such
as Bayesian and Akaike Information criteria (Schwarz et al. 1978; Akaike 1998). The model goodness-of-ﬁt will be
measured using well-known statistics, such as the coeﬃcient of determination, or residual maps between the input data
and model predictions (Kuhn et al. 2014; de Souza et al. 2017). We will justify the election of the Einasto proﬁle in
section 2.2. Once the model is estimated, we may want to give a ﬁnal particle classiﬁcation in the clusters. Mixture
models allow for a probability based classiﬁcation, but as we explain in section 7.2 we recommend the application of
a heuristic threshold for background particles. This threshold should be based on the merging conditions of our data.
Aside from the mixture model alternatives, several algorithms are widely used by the community to detect structures
in dark matter N-body simulations and classify their particles. We mention the Bound Density Maximum algorithm
(Klypin & Holtzman 1997; Riebe et al. 2013) in section 7.4, which is based on density maximums and spherical halos.
Another alternative is the ROCKSTAR algorithm (Behroozi et al. 2013), ‘based on adaptive hierarchical reﬁnement of
friends-of-friends groups in six phase-space dimensions and one time dimension’. With this method, the algorithm can
provide an eﬀective particle classiﬁcation and can even detect small subhalos in merging conditions. The halo ﬁnder
VELOCIraptor (Elahi et al. 2019) has also been proven to be able to ‘identify sub-halos deep within the host that have
negligible density contrasts to their parent halo’. Both methods are meant to be used on large N-body simulations,
providing a full catalog of halos, sub-halos and even tidal features.

In contrast, our method is a parametric based approach. Although this limits its use to small-sized samples of
particles, it provides a parametric ﬁtting of the halos density proﬁle. In this work, we will focus on the advantages of
obtaining such a proﬁle-based description.

This paper is organized as follows. Section 2 presents the ﬁnite mixture modelling technique, the Einasto proﬁle and
diﬀerent applications for the estimated results. Section 3.1 illustrates the MLE calculation and section 3.2 describes
the tools that we used to validate the best-ﬁt model. In section 4 we summarize the steps of our code darkmix and we
apply it in section 5 to a set of generated realizations of a simulated dark matter distribution with Einasto proﬁle and
ﬁt them with our software to validate it. Section 6 presents a data set from the Bolshoi simulation, and section 7 shows
the analysis and results of our mixture modeling and validation. In section 8, we summarize our main conclusions and
outline future work.

2. FINITE MIXTURE MODELS FOR DARK MATTER HALOS

Finite mixture densities are a family of probability density distributions that combine multiple components into
a single probability function. Each component has a probability density function (e.g., the Einasto proﬁle) and the
ﬁnal mixture model is the weighted sum of c components. All components are continuous, and can be evaluated at
any location of the data space, occupied or not by a particle. Mixture models admit as many diﬀerent components

4

as desired, as long as they can be deﬁned as probability distributions.
In this work we will consider two kinds of
components: k halos, and a single background component containing all of the particles that are not associated with
a halo. The total number of the mixture model is c = k + 1.

Given a data sample of N dark matter particles from a simulation, we deﬁne X as a three column matrix containing
the coordinates of our particles. Each component will be modeled by a proﬁle function ρj(ri, (cid:126)θj), j = 1, . . . , c, where
(cid:126)θj is the parameters vector for component j and Θ is the matrix of the c vectors (cid:126)θj. The sum of these components is
weighted by the mixing proportions (cid:126)w = {wj}, j = 1, . . . , c, which are non-negative. In point process statistics, the
model is deﬁned over a window W containing the sample of N points X = {ri}, where ri = (xi, yi, zi). Together, the
ﬁnite mixture model Σ can be written as

Σ(X| (cid:126)w, Θ) =

c
(cid:88)

j=1

wj · ρj(X|(cid:126)θj) =

c
(cid:88)

N
(cid:88)

j=1

i=1

wj · ρj(ri|(cid:126)θj)

(1)

Our implementation of the mixture model for the dark matter distribution will follow the strategy of (Kuhn et al.

2014), and therefore we chose our notation after this paper.

Functions ρj represent the proﬁle functions of our dark matter structures, which are summed into the surface density
function Σ and the probability density function that we use as a model and will ﬁt to our data. These functions typically
create a multimodal distribution that matches the clusters that are present in our data. Therefore, individual dark
matter particles are used to obtain the overall density distribution of the structure that they belong to. No learning
can be obtained from the internal distribution (i.e., the relative position of the particles inside their structure). The
total ﬁnite mixture model Σ is the weighted sum of these components and models the dark matter density distribution
as generated by the N-body simulation.

The proﬁle of a mixture model component can be as irregular as we are able to model it. However, since this
method is generally used as a cluster classiﬁcation method, we will model two diﬀerent components—the halos and
the background.

We will introduce the NFW and the Einasto proﬁles in the next section. However, as we justify, we will only make
use of the latter. We will also introduce the ﬁnal version of our mixture model before deducing several quantities and
functions of interest.

The NFW proﬁle (Navarro et al. 1996, 1997) has the following shape

2.1. The NFW Proﬁle

ρ(r|M ) =

(cid:104)

ρs(M )
(cid:105) (cid:104)

1 + c(M )

(cid:105)2 ,

r
rvir(M )

c(M )

r
rvir(M )

(2)

truncated at the virial radius r = rvir(M ). This proﬁle has a logarithmic slope of −1 at small scales (r (cid:28) rvir/c)
and of −3 at large scales (r (cid:29) rvir/c). Here, ρs(M ) is a normalization factor that is ﬁxed from the condition that
the total mass integrated to rvir(M ) must be equal to M and c(M ) is the concentration parameter. We note that the
NFW proﬁle or power-law proﬁles cannot be used in this context because they do not have a ﬁnite integral. Instead,
we will use the Einasto proﬁle for our study.

2.2. The Einasto Proﬁle

The Einasto proﬁle (Einasto 1965, 1968, 1969) for three-dimensional density proﬁles is similar to the S´ersic proﬁle
used for two-dimensional galaxy brightness proﬁles (S´ersic 1963; Sersic 1968). Assuming spherical symmetry, the
Einasto proﬁle describes the density ρ of halo j as a function of distance from the halo center r0,j. The S´ersic index
n is a free parameter that is used to measure the shape of the halo density proﬁle: larger values of n create centrally
concentrated proﬁles. As we will see in section 7, large values of this parameter (above n ∼ 8) degenerate the proﬁle
into a power law-like function. The other free parameter of the proﬁle is Einasto’s radius re, which deﬁnes a volume
containing half of the total mass that can be used to understand the size of the halo.

Given these parameters, we can deﬁne dn, which is a function of n such that ρe is the density at the radius re, and

we have deﬁned ρe. The factor dn can be obtained by solving

Γ(3n) = 2γ(3n, dn)

(3)

where Γ is the complete gamma function and γ is the lower incomplete gamma function1.

We are now ready to deﬁne the Einasto proﬁle as

ρ(r) = ρe exp

(cid:16)

(cid:104)
(r/re)1/n − 1

(cid:105)(cid:17)

− dn

5

(4)

where r = ||r − r0|| is the distance between a chosen location r and the center of the halo r0. As we see in eq. 1, this
proﬁle will be multiplied by parameter pj, which is the mixture coeﬃcient. This makes it impossible for us to estimate
pj and pe separately. The results that we provide for pj in Tables 3 and 5 should be read as pj · pe.

Before moving on to the next section, we deﬁne the proﬁle of the background component as a constant density, having
value 1 at all locations of the window W . Since the background proﬁle is multiplied by its our mixture coeﬃcient pb,
we expect it to be close to the mean density of the data set. In a large data set, where conditions are comparable to
the universe, we would expect it to be around the mean density of the universe. This is equivalent to deﬁning the
background as a homogeneous Poisson distributed point process, with proﬁle function

ρb(r) = 1

(5)

2.3. Dark Matter Halo Mixture Model

The mixture model for our problem is a weighted sum of the background component (ρb) plus the k halo components
(ρ), hence c = k + 1 components (see eq. 6). The parameters for each halo proﬁle are the three vectors representing the
halo center r0, the size parameter re, and the shape parameter n. These parameters are collected into a ﬁve-dimensional
parameter vector (cid:126)θ = (r0, re, n).

The contribution of each component to the ﬁnal density distribution is uneven. The mixture proportions (cid:126)w = {wj},
j = 1, . . . , c are used as weights to normalize each halo’s contribution to the mixture model. Based on equation (1),
the resulting model is

Σ(r| (cid:126)w, Θ) =

(cid:16)

N
M

wb · ρb(r) +

k
(cid:88)

j=1

wj · ρ(r − r0,j|re,j, nj)

(cid:17)

(6)

where the weights wj give the mixture proportions pj = N · wj/M in equation (1) and M is the total mass given by

M =

(cid:90)

(cid:16)

W

wb +

k
(cid:88)

j=1

wj · ρ(r − r0,j|re,j, nj)

(cid:17)

dr

(7)

The term N/M works as a normalizing constant so that the integral of the model Σ is always the number of particles
N . Note that we ignore function ρb(r) because it is constant 1. Function Σ is our probability density function for a
mixture model problem as in equation 1. Since the density of the universe is constrained to not be inﬁnite, we can
model the density of the components relative to each other. In equation 6, the mixture proportions are deﬁned so that
(cid:80)c

i=1 pi = N , and by deﬁnition we can set w1 = 1.
This normalization of the model by the total number of objects N has other advantages. The integral of Σ(r) in
a region A ⊂ W gives the number of model objects in A. The integration of a chosen model component over the
entire volume W gives the number of model objects belonging to this component. The statistical model can thus be
understood as an inhomogeneous Poisson distribution with intensity Σ(r).

Notice how the quantity ρe in the Einasto proﬁle will be masked into the mixture proportion as a consequence of

the mixture model because both are factors to the proﬁle.

2.4. Halo Identiﬁcation and Characterization

Once the mixture model is ﬁtted (section 3.1), analysis of each Einasto-shaped component representing a halo can
follow. Due to the additive nature of a mixture model, it is easy to determine the dominant component at every
location. Here, we apply a simple decision rule to assign individual data points to a halo: given a particle, we calculate
its probability to belong to each component. We then randomise the membership of the particle using the probabilities.

1 The gamma functions are extensions of the factorial function to complex numbers.

6

Each model halo component can be compared to the empirical halo proﬁle in the context of the total mixture model
of overlapping halos. Component j has a three-vector r0,j, giving its location, and three Einasto parameters wj,
re,j and nj. We deﬁne the empirical halo proﬁle as the number of real particles per volume, the particle density, in
concentric shells centred at r0,j with volumes Sj(r) = Vj(r + dr) − Vj(r). The empirical halo proﬁle is

ˆδj(r) =

1
Sj(r)

(nj(r + dr) − nj(r))

(8)

where nj(r) is the number of particles in a sphere of radius r and center r0,j. Note this has the same units, number of
particles per unit volume, as the mixture model in equation 6 by N/M . The estimated density proﬁle of the mixture
model centered at r0,j is

(cid:90)

ˆP (r|r0,j) =

Σ(r|(cid:126)p, Θ)dr.

(9)

Sj (r)
The integral of Σ at any volume V gives us the estimated number of particles. Since proﬁle ˆP (r) is evaluated at the
concentric shells Vj(r) with thickness dr, it should be understood as a density proﬁle over radius r. Component j in
the previous integral can be isolated from the total model proﬁle as

ˆρ(r|r0,j) =

(cid:90)

Sj (r)

pjρ(r − r0,j|re,j, nj)dr.

(10)

We can now compare the observed proﬁle of ˆδj with the full model estimator ˆP (r|r0,j) and with the isolated estimated
proﬁle ˆρ(r|r0,j), which may show important departures from the total proﬁle. For short distances, ˆρ and ˆP should have
similar values. However, for distances at which our component j starts to increasingly overlap with other components,
these functions will start to diverge as other structures contribute more to ˆP .

Parametric models oﬀer the possibility of easily generating new samples following the model distribution. For a
mixture model, this is done with an inverse transform sampling for the estimated number of objects per component
Nj.

For the possible interest of the user, software implementations of these functions are included in the R language and

are included in our repository.

Nj =

(cid:90)

W

pjρ(r − r0,j|re,j, nj)dr.

(11)

3. MODEL FITTING

3.1. Estimation of Model Parameters and Model Selection

The optimal mixture model for a data set is calculated by maximum likelihood estimation (MLE) for the log-

likelihood

log L((cid:126)p, Θ|X) =

N
(cid:88)

i=1

log Σ(ri|(cid:126)p, Θ) −

(cid:90)

W

Σ(r(cid:48)|(cid:126)p, Θ)dr(cid:48)

(12)

where X = {ri} contains the point process distributed in the window W with surface density distribution Σ. Note that
the right-hand side term is the mass M for the parameters Θ. The MLE and Bayesian best-ﬁt model parameters Θ
are calculated for a chosen number of c components. Model selection among models of diﬀerent complexities is based
on minimising two commonly-used penalized likelihood measures, the Bayesian Information Criterion (BIC) and the
Akaike Information Criterion (AIC) (Schwarz et al. 1978; Akaike 1998),

BIC(k) = −2 log L + 6(c − 1) log N

AIC(k) = −2 log L + 12(c − 1)

(13)

(14)

where 6(c − 1) is the number of parameters in c − 1 halo components plus the background component and logL is the
log-likelihood for the best ﬁt parameters.

The relative strengths of AIC and BIC is widely debated, although both are founded on powerful theorems (Lahiri
2001; Konishi & Kitagawa 2008; Burnham & Anderson 2002; Kass & Wasserman 1995; Everitt et al. 2011). The BIC

7

has a well-accepted valuation for relative model merit: one model is strongly (very strongly) favored over another when
∆(BIC) > 6 (> 10) (Kass & Raftery 1995). For the mixture model problem, Kuhn et al. (2014) found that the AIC
was more sensitive to the presence of sparse clusters in the presence of rich clusters because its penalty for complexity
is weaker when N is large.

3.2. Goodness-of-Fit

A best-ﬁt model with optimum complexity selected with a likelihood-based criterion is not guaranteed to be a good
ﬁt to the data. A complex clustered spatial distributions cannot be eﬀectively ﬁtted with a mixture model of a few
halos. It is therefore necessary to assess the overall quality of the ﬁt for the entire pattern by a study of the residuals to
identify departures of the model from the real data density distribution. Several such tests are outlined here. Studies
involving residual analysis of astronomical spatial point processes for goodness-of-ﬁt evaluation of maximum likelihood
mixture models include Kuhn et al. (2014) and de Souza et al. (2017).

The residual analysis that is used here is described in Baddeley et al. (2005, 2015) as a ‘raw residuals’. Raw residuals
are deﬁned as the absolute diﬀerence between the real number of points in a region A and our estimation for the same
region. For our mixture model,

R(A) = n(X ∩ A) −

(cid:90)

A

Σ(u|(cid:126)p, Θ)du

(15)

where n(X ∩ A) is the number of data points in the region A. For well-ﬁtted models, the sum of the raw residuals
should approach zero when integrated over W , and the residual map should approach a random spatial distribution
with no correlations between the values of the residuals and the locations of the data points (spatial white noise).
Residuals should have low amplitude when compared with the surface density function based on the data.

The calculation of the residuals is made using a quadrature or grid of dummy points Q = {ui} ⊂ W , i = 1, . . . , T
(Baddeley et al. 2005). Each point deﬁnes a small cell where the residuals will be calculated. These residuals create a
sparse distribution that is 1 when the cell contains a data point r and −Σ(u|X, (cid:126)p, Θ) at empty locations in W , which
is negative and typically close to zero.

To eﬀectively visualise the spatial distribution of the residuals, they have to be smoothed. With grid Q dense enough

to approximate an integral, we can obtain the smoothed residual map s(u) with

s(u) =

(cid:90)

W

κω(u − v)dR(v) =

N
(cid:88)

i=1

κω(u − ri) −

(cid:90)

W

κω(u − v) ·

(cid:88)

(u|X, (cid:126)p, Θ)dv

(16)

where κω is a kernel function and RΘ(v) is the raw residual in a cell v.

It is also useful to deﬁne the relative residuals e(u), which are deﬁned as the residual map normalized by the model

intensity. The model intensity Σ†

ω is the right-hand term of eq. 16. Hence the deﬁnition of these two functions is

Σ†

ω(u|(cid:126)p, Θ) =

(cid:90)

W

κω(u − v)Σ(u|(cid:126)p, Θ)dv

e(u) = s(u)/Σ†

ω(u|(cid:126)p, Θ)

(17)

(18)

As we will see in the following sections, this function can be used to detect data structures that have not been
modeled by any model component. For any structure that is properly mapped by the model, s(u) will be a small
quantity and the values of e(u) in its region will also be small. However, if a structure in the data is not included in
the model, then the value of function Σ†
ω(u|(cid:126)p, Θ) will be close to zero for any location close to that structure and the
error value in s(u) will be ampliﬁed in e(u) and unﬁtted structures can be easily detected.

The kernel function that is used in this work is the Gaussian ﬁlter, which is commonly used in cosmology (Mart´ınez
& Saar 2002), where ω is the smoothing radius or bandwidth. The appearance of the smoothing strongly depends on
the choice of this quantity. The bandwidth can be selected using cross-validation or other techniques and we select it
heuristically to give informative residual maps.

Finally, we use the coeﬃcient of determination (Rao et al. 1973) to assess the global goodness of ﬁt. Using the
expected proportionality between the model density (Σ†
ω) functions, we estimate a simple
linear regression between them and use the resulting R2 coeﬃcient as a measure of goodness of ﬁt (de Souza et al.
2017).

ω) and the data density (Σ∗

8

The data X can be similarly smoothed with the same kernel. This function is not used in the ﬁtting or model
validation process, which would be incorrect given the loss of data structure detail. However, we include it in our code
repository for completeness and visualization purposes (as in Fig 6 top left-hand panel):

Σ∗

ω(u) =

N
(cid:88)

i=1

κω(u − ri)

ri ∈ W

(19)

3.3. Available Software Packages

It is not our aim to compare the performance of our code with other packages available for users.

In contrast,
our solution is adapted to the particular scenario of dark matter halos with Einasto proﬁle, while most of the public
solutions use GMM or only accept two-dimensional data. However, we ﬁnd it interesting to provide a small summary
of the available solutions.

Substantial code devoted for mixture model analysis are available in the R public domain statistical software envi-
ronment such as CRAN packages mixtools, mclust, and EMCluster (Benaglia et al. 2009; Scrucca et al. 2016; Chen &
Maitra 2015). The Python Machine Learning library scikit-learn (Pedregosa et al. 2011) includes Gaussian mixture
models (GMM) algorithms. Another option is EM M IX, which is written in Fortran (McLachlan & Peel 1999), where
the Expectation-Maximization (EM) algorithm is used to ﬁnd the MLE (Krishnan & McLachlan 1997; McLachlan Ge-
oﬀrey & Krishnan 2008). However, estimation of best ﬁts in complex data sets can be diﬃcult to achieve thanks to the
multiple peaks. A more robust procedure makes use of the stochastic EM algorithm (Celeux & Govaert 1992), where
randomization of the steps seeks to avoid trapping in the ﬁrst found local maximum. Even with this technique, it is
advisable to repeatedly run estimation algorithms using diﬀerent starting values to avoid convergence to a non-optimal
local maximum. If the same best ﬁt solution is achieved every time, then we can be more conﬁdent of reaching an
absolute maximum.

3.4. Software Repository

Our solution necessarily departs from the previous packages. As explained, while most mixture model software
assumes Gaussian shapes and use the EM algorithm for parameter estimation, we will adopt diﬀerent algorithms.
Mixture model solutions with non-Gaussian functions such as the Einasto proﬁle are not so easily achieved with this
method, due to the reduced curvature in the derivative.

Following Kuhn et al. (2014), who calculate two-dimensional mixture models with the isothermal ellipsoid shapes,
we will maximize the log-likelihood function using the Nelder-Mead simplex algorithm (Nelder & Mead 1965) as
implemented in function optim within CRAN package stats (Team 2015). Testing with diﬀerent initial values is
recommended to avoid trapping in local maxima. Since the models have high dimensionality, a strategy of systematic
freezing and thawing parameters during estimation can be useful. Once the Nelder-Mead algorithm has ﬁnished a
ﬁrst attempt at estimation, the results can often be improved by freezing some of the parameters and repeating the
calculation for the remaining free parameters. This technique is valuable in mixture models because the parameters
of distant halos tend to be uncorrelated. It can also be helpful to obtain a good estimates of halo centers r0 before
attempting the ﬁtting of the rest of the parameters. Conﬁdence intervals on MLE parameters can be estimated from
the Fisher Information Matrix.

MLE can present additional problems that depend on the proﬁle functions ρi(X, Θ). It is possible for singularities
to exist for certain values of X or Θ where the likelihood becomes inﬁnite. This might happen when the number
of parameters to be estimated is high when compared with the sample size. This problem can be addressed with
a Bayesian approach where the posterior distribution of the parameters is mapped instead of maximizing the log-
likelihood function. As priors, we use Gaussian functions with large variances for the centers of the halos, and
log-normal distributions for the size and shape parameters re and n. These calculations are performed using Markov
chain Monte Carlo (MCMC). However, even if aided by MLE results that were previously obtained by the Nelder-Mead
algorithm, suﬃcient MCMC evaluations of high-dimensional parametric models can be computationally expensive.

The software that we have used for our Bayesian calculations is the CRAN package LaplacesDemon (Statisticat
& LLC. 2013a,b,c,d), which provides more than 40 diﬀerent MCMC algorithms. These algorithms make diﬀerent
decisions regarding the next combination of parameters Θ to be tested to eﬃciently map the normalized log-likelihood
function 12. Adaptive MCMC algorithms, which use the previous evaluations to choose the next Θ, are often more
eﬃcient in ﬁnding the overall distribution of the function but we must always ﬁnish with a long run of a non adaptive

9

algorithm to ensure convergence. In this work, we make use of the Adaptive Metropolis-Within-Gibbs (AMWG, Roberts
& Rosenthal (2009)) and the twalk (Christen et al. 2010) algorithms. These calculations start with a preliminary MLE
solution that is obtained with the Nelder-Mead algorithm.

Our software implementation of this mixture model decomposition of the dark matter distribution is named DarkMix
and is written in the R statistical software environment, which has many tools relating to spatial point processes,
mixture models, likelihood calculations, model assessment, and graphics. Our work extends that developed by Kuhn
et al. (2014) to identify star clusters in two dimensions. We present a new library to model three-dimensional data sets
(Hurtado-Gil et al. 2022), which is publicly available on Github2. Its use is explained in sections 4 and 7. Additional
documentation for the code can be found online3.

With the equations from section 3 the darkmix code has the following capabilities:

4. DARKMIX OVERVIEW

1. Create data and model objects that are compatible with the R library spatstat. This is a powerful library to

work with point processes and its capabilities can be combined with our code.

2. Parametric estimation with two available methods: the Nelder-Mead simplex algorithm (Nelder & Mead 1965)

and MCMC.

3. Functions are incorporated for model selection (through AIC and BIC calculations) and goodness-of-ﬁt (through

R2 and residuals plots).

4. Generation of model outputs, which comprise the soft classiﬁcation of the particles, the extraction of individual
proﬁles for components, the generation of model realizations and the visualization of the components’ sizes.

5. MODEL VALIDATION

Before we introduce our real case data set in section 6 and estimate a mixture model, we must ﬁrst validate the
performance of our algorithm. To do so, we will estimate the mixture model in three diﬀerent conﬁgurations: 3, 9 and
16 dark matter halos with background particles in a cube of 25 length units side. For each conﬁguration, we generate
20 realizations with three diﬀerent particle densities: 0.25, 0.5 and 0.75 particles per volume unit.

The halos are modeled using the Einasto proﬁle and the background components is uniformly distributed, as assumed
by our model. The true parameters deﬁning the location, size and shape of the halos, together with the number of
particles, are generated randomly (see Tables 1 and 2). We then obtained the mixture coeﬃcients using eq. 7 knowing
that w0 = 1. When using three halos, the conﬁguration is a simple set of components around the center of the volume,
and its ﬁtting presented no problem. We will use the more complex cases of 9 and 16 halos to study merging halos or
locate halos near the volume window boundary.

Once these realizations are generated, we estimate the best ﬁt parameters using our darkmix algorithm. As explained
in section 4, this algorithm starts with an approximation of initial values, which is later optimized using the Nelder-
Mead algorithm. The three-halos case is easy to model and the true parameters lie inside the conﬁdence intervals of
our best ﬁt. The samples with nine-halos are more challenging, and we will present several results and plots to show
the performance of our model, which we consider acceptable. With 16 halos, the model is no longer able to ﬁnd and
correctly model some of the extra halos because they are too small and faint to be distinguished from the background.
As we can see in Fig. 1, the parameters for a population of nine components is generally correctly estimated. The
center of the halos is found. This allows for correct estimations of the radius re and the S´ersic index n, only in two cases
do we see one of these parameters to be outside the 1-sigma error bars. The mixture coeﬃcients tend to be slightly
overestimated, but a correction of these values does not greatly improves the maximum likelihood. Consequently, the
estimation of the components population is rather accurate, which allows for a correct classiﬁcation of the particles.
Even in the case of 16 halos, when several components are incorrectly estimated, the halos’ population is close to the
true values.

2 https://github.com/LluisHGil/darkmix
3 https://darkmix.readthedocs.io/

10

Table 1. True parameters for model validation: 9 halos

k

1
2
3
4
5
6
7
8
9

x0

y0

z0

2.9
8.2
8.7
10.1
16.1
16.4
18.4
20.3
21.7

21.0
6.5
14.9
16.2
7.7
22.8
16.3
6.1
14.9

21.7
18.6
16.0
4.4
5.9
19.5
22.3
13.9
7.9

re

1.1
0.9
1.4
1.3
2.0
2.2
1.4
0.7
1.1

n

log w N

0.0
2.4
1.4
0.68
1.7 −0.86
1.9 −0.64
1.7 −0.42
2.9 −0.65
1.9 −0.08
1.09
1.7
0.20
2.3

256
544
66
92
518
454
403
717
415

Note—These parameters have been randomly
generated in a cube of side 25 to describe a
conﬁguration of 9 Einasto halos (here they are
sorted by x0) with density 0.25 particles per vol-
ume unit. The background contains 442 parti-
cles, which gives log wb = −2.4. The popula-
tions N for densities 0.5 and 0.75 can obtained
multiplying the values in the table by 2 and 3.

An additional validation analysis was performed with the nine-halo conﬁguration and low density: the same real-
ization of particles (one of the 20 samples generated for the previous analysis) was estimated using mixture models
of diﬀerent components, from 6 to 12 halos (see Fig. 2). The results were shown to be satisfactory: for k ≤ 8, the
model ﬁnds the real halos and tries to estimate the Einasto proﬁle. However, it is not until we input the right value
of k = 9 halos that the halos are not only found but correctly estimated, as seen in Fig. 1. When k ≥ 10, the model
tries to estimate spurious over-densities in the background population, which creates halos with large radius and S´ersic
index. With such values, the mass of the halo is concentrated around a few close particles, which adds a minimal
contribution to the maximum likelihood of the model. This contribution is negligible, and the AIC and BIC clearly
show a regression for such models.

We conclude that our model is fully validated for conﬁgurations of at least nine halos with background component
and densities equal or greater than 0.25 particles per volume unit. In Fig. 3, we provide a four-panel plot with the
data and model densities, plus the raw and relative residuals. The plot shows the close agreement between data and
model. Only two halos (top left-hand a bottom left-hand panels) seem to be overestimated (blue raw residuals) and
underestimated (red in raw residuals). The relative residuals show an uncorrelated pattern with the data, which means
that no component is excluded from the model.

The case of 16 halos is still interesting and valid conclusions can be obtained for the richer halos, although the fainted

halos might add biased results. All of the results and related data ﬁles can be found in our Git Hub repository.

6. DATA

We perform this analysis for a case study data set from the Bolshoi simulation (Klypin et al. 2011). This cosmological
N-body simulation oﬀers the necessary conditions and a high particle resolution that allows us to apply our method-
ologies over a sample of scientiﬁc interest. The MultiDark Database (Riebe et al. 2013) hosts two 8.6 billion particle
cosmological N-body simulations: the already mentioned Bolshoi simulation (Klypin et al. 2011) and MultiDark Run1
simulation (MDR1, or BigBolshoi) (Prada et al. 2012). The Bolshoi simulation can be used to study both the large
scale structure of the universe and the properties of dark matter halos. In this work we focus on the latter, which
agreed with the assumptions made for our model.

The MultiDark Database allows us to use a SQL (Structured Query Language) query interface to extract the desired
sample. In this paper, data has been extracted from the Bolshoi simulation. The simulation has been performed in a
volume of 250 h−3Mpc3, having a mass resolution of 1.35×108 h−1 M(cid:12), and a force resolution of physical (proper) scale

Table 2. True parameters for model validation: 16 halos

11

k

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16

x0

y0

z0

1.3
2.9
5.4
5.7
7.9
8.2
8.7
9.2
10.1
15.5
16.1
16.4
18.4
20.3
21.7
23.8

6.2
21.0
15.7
20.0
15.4
6.5
14.9
21.3
16.2
10.6
7.7
22.8
16.3
6.1
14.9
15.5

5.2
21.7
5.2
6.9
12.8
18.6
16.0
19.4
4.4
5.7
5.9
19.5
22.3
13.9
7.9
16.8

re

1.3
1.1
1.1
2.0
1.0
0.9
1.4
0.9
1.3
1.0
2.0
2.2
1.4
0.7
1.1
1.2

n

log w N

1.9
0.0
2.4 −0.21
0.76
1.8
2.1 −0.57
0.33
1.4
1.4
0.25
1.7 −0.56
1.6
0.29
1.9 −0.58
0.71
1.8
1.7
−0.4
2.9 −0.84
−0.5
1.9
0.91
1.7
0.22
2.3
0.55
2.3

204
83
729
212
179
108
69
130
55
481
293
154
83
255
230
571

Note—These parameters have been randomly
generated in a cube of side 25 to describe a conﬁg-
uration of 16 Einasto halos (here they are sorted
by x0). Components 2, 6, 7, 9, 11, 12, 13, 15, and
16 are copied from the 9 halos conﬁguration (see
Table 1). The background contains 68 particles,
which gives log wb = −2.85. The populations N
for densities 0.5 and 0.75 can obtained multiply-
ing the values in the table by 2 and 3.

of 1 h−1kpc (Klypin et al. 2011). The cosmological parameters that we have used for this simulation are Ωm = 0.27,
Ωb = 0.0469, ΩΛ = 0.73, σ8 = 0.82, spectral index ns = 0.95, and H0 = 100 h km s−1Mpc−1 with h = 0.70. The
snapshot that we have used is at redshift z = 0.

Since this work is a case study, we select a small region of interest from the table Bolshoi.Particles416 at
https://www.cosmosim.org/. We are interested in a volume W containing an interesting structure with halos of
diﬀerent sizes and merging cases. With this purpose, we select a ﬂat cuboid with an squared face to facilitate the
two-dimensional examination. This sample contains three halos that are among the 100 most massive, plus several
other halos of smaller size. The ﬁnal sample contains 2081 particles in a volume of 4375 h−3 Mpc3 (deﬁned by a box
of 25 h−1 Mpc×25 h−1 Mpc×7 h−1 Mpc). We wish to remark here that we tested the method on other more sparse
galaxy samples. However, success is not reached when the data sparsity of the sample is high. Evaluating which is the
minimum needed structure density to be properly described by our model is outside the scope of this work, but this
can serve as a reference. The Bolshoi simulation also provides a catalog of halos that have been categorized with the
BDM algorithm (Klypin & Holtzman 1997; Riebe et al. 2013). In section 7.4, we make a comparison between these
halos and our ﬁndings. It is worth noting here that neither the BDM catalog of halos, nor any other catalog, has been
used in this work apart from at the appendix.

An image of the selected sample can be seen in Figure 4, notice the abundant structure and variations in the shape

and size of its clusters.

7. DARKMIX APPLICATION TO THE BOLSHOI SIMULATION

7.1. The Fitting Procedure

12

Figure 1. Left: distribution of best ﬁt parameters for the 20 realizations of 9 halos with low density (black) and true parameters
from Table 1 (red crosses). The validation of the center of the halos is showed as the distance (ﬁrst panel) to the true center
(red line). Right: same for the 16 halos conﬁguration (see Table 2).

This section serves as an example of how our code can be used to estimate a model for the data set presented in
section 6. All of the calculations and results presented in this section have been obtained with darkmix code and a
full walk-through can be found in the code documentation 4.

4 https://darkmix.readthedocs.io/en/latest/darkmix steps.html

13

Figure 2. Relative change in the log-likelihood (gray band), and in the information criteria BIC and AIC (symbols), as a
function of the number of components included in the model, c. The model is ﬁt over the nine-halo conﬁguration. Changes are
shown with respect to the best model in each case. The inset shows a zoom of the range 10 ≤ c ≤ 12. The horizontal dotted
(dashed) line shows the threshold for strong (very strong) evidence, ∆(BIC) > 6 (> 10) according to Kass & Raftery (1995).

The data can be easily loaded into a spatsat point process object, while the model and the parameters are deﬁned
as arrays of functions and values. The code contains functions for Einasto proﬁles and the background component
(a constant function) but the user can easily deﬁne additional functions to similarly model a structure of interest.
Regarding the integration grid, this object is used to calculate the model mass and in eq. 7. After testing diﬀerent
grid sizes, the authors recommend using a relation of 2:1 (i.e., we divide the sides of length 25 of our window into 50
parts). Thinner grids do not produce a diﬀerent result. We only recommend using a thinner grid for plotting purposes
(in this work, we use 128 grid points per side of 25 units).

Once these objects are created, we can proceed to estimate the parameters. It is advisable to start with an initial
guess of the number of halos and their centers. We recommend using function centers, which outputs a list with the
k densest locations in the data set and will be used as the initial guess for the halo components.

The remaining parameters are defaulted to 1 for the radius re and 3 for the S´ersic index n. The mixing coeﬃcients

are in logarithmic form: 1 for the halos weights and −2 for the background component.

We will start with a c = 11 components model and the Nelder-Mead simplex algorithm via the R function optim,
which maximizes the likelihood function of our mixture model. However, the model needs several iterations to achieve
our best ﬁt. To improve the estimation, additional functions have been created to freeze some parameters while
estimating the rest. While algorithms spend little time ﬁnding the center of the halos, most of the computation is
devoted to the estimation of the three Einasto model parameters. The radius of a component is generally independent
of the center of a distant location and reducing the total number of parameters per optimization can greatly improve
the ﬁt. Each function ﬁxed one of the diﬀerent parameter types: centers, radii, S´ersic index and mixture coeﬃcients.
It is advisable to repeat this procedure until convergence and ending by calling the optim function with no frozen
parameters for a ﬁnal ﬁt. For the data set that we have used in this work, the full procedure might take around 30
minutes to complete on a commonly-available laptop.

The results for our data set in Figure 4 for an assumed c = 11 number of components are shown in Table 3. The
expected number of particles per component can be obtained directly from the mixture model: the component’s mass
is integrated independently and normalized to the total number of particles. The last column of Table 3 shows the
expected number of particles per component.

Function optim and the other R routines that are designed to estimate the maximum likelihood provide the hessian
matrix of the best ﬁt set of parameters. This matrix can be used to obtain conﬁdence intervals for the parameters.
However, the numerical approximation of the hessian matrix obtained in our problem was ill-deﬁned and produced

14

Figure 3. Comparison of one realization of a nine-halo sample and density 0.25 with the estimated model. Top left-hand panel:
data kernel particle density ﬁeld Σ∗
ω(r|X). Top right-hand panel: smoothed raw residuals s(r). Bottom left-hand panel: model
particle density ﬁeld Σ†
ω(r|X, (cid:126)p, Θ). Bottom right-hand panel: relative residuals e(r). In the data and model density ﬁelds,
gray intensity is in logarithmic scale. Both images have been normalized over the number of particles. Dark areas indicate a
denser region or higher probability of being occupied by a point, while lighter areas are unlikely to be occupied by a particle.
Smoothing bandwidth for all maps is ω = 1, and the values summed over the dimension Z. Data points from Figure 4 are shown
as small black dots.

negative variances. Given the impossibility of calculating the conﬁdence intervals, we decided to run a MCMC routine
with a simpler model and estimate them here. We explain this with more detail in §7.5 .

The mixture model should be ﬁtted for several values of c, and the AIC and BIC (eq. 14 and 13) functions should be
calculated for model selection. Figure 5 shows the log-likelihood and information criteria values from ﬁts of the Bolshoi
simulation data set for models with c = 4 to 15 components. As expected, the log-likelihood increases monotonically
with the number of components, while both the BIC and the AIC reach a minimum value for c = 11. Consequently,
this is the preferred model according to both criteria. We can interpret the evidence in favour of this model according
to both criteria using the scale introduced by Kass & Raftery (1995). In the case of BIC, the c = 11 model is very
strongly favoured in all cases, as ∆(BIC) > 10 for all other models. However, when considering the AIC, the models
with c = 12, 13 cannot be discarded. This is a consequence of the AIC’s lower penalty for increased model complexity

15

Figure 4. Sample of dark matter particles from the Bolshoi simulation.

(see eqs. 13, 14). Following the BIC result, and choosing the most parsimonious among the accepted models by the
AIC, we stick to the model with c = 11.

As we discuss in §7.5, it is possible for scientiﬁc considerations to prefer a non-optimal model, such as k = 6 rather
than k = 10. Generally, the most populous halos will appear in all models and increasing k will identify small,
sparser halos. However, it is also possible that small changes in k may lead to major changes in the structure of the
best-ﬁt model. In particular, spatial mixture models can identify a large diﬀuse halo that encompasses or overlaps
smaller, denser halos. This will occur when the clustering of points has a complicated hierarchical structure, rather
than exhibiting distinct halo structures. Since the model for each value of k is a maximum likelihood ﬁt, they are
all statistically valid. Whether to use the BIC and AIC for model selection or another choice of k that gives a more
parsimonious or more complete model of the particle distribution is a scientiﬁc decision.

7.2. Particle Membership in Halos

Once we have our estimated mixture model, we may want to classify the data set particles into its diﬀerent com-
ponents. This comes naturally with a soft classiﬁer method such as a mixture model: given a particle, we evaluate
each model component at the particle location and we then normalize the obtained quantities to one. The resulting
values can be understood as membership probabilities and used in a multinomial distribution to assign one particle to
c components with the c probabilities. If the model is correct, then the number of particles assigned per component
should match, on average, to that shown in Table 3.

We recommend adapting this criteria to our scientiﬁc interests. Halos with heavy tails might populate areas with
particles far from the real halo boundaries, hence overestimating the halo population.
In contrast, under merging
circumstances, several halos might be competing for the same particle and the model will assign low probabilities to
each of them. Assuming same size halos, the border between two merging halos will be populated by particles with
0.5 probability of belonging to each halos, 0.33 for three halos, etc. The multinomial criteria might end up assigning
these particles to the background instead, especially when the number of merging halos is high. To compensate for
this, we provide two modiﬁcations to the multinomial criteria. First, the background component will not compete
with the halos and the particle will be directly assigned to the background whenever the background probability is

16

Figure 5. Relative change in the log-likelihood (gray band), and in the information criteria BIC and AIC (symbols), as a
function of the number of components included in the model, c. The model is ﬁt over the Bolshoi dataset. Changes are shown
with respect to the best model in each case. The inset shows a zoom of the range c ≥ 10. The horizontal dotted (dashed) line
shows the threshold for strong (very strong) evidence, ∆(BIC) > 6 (> 10) according to Kass & Raftery (1995).

Table 3. Maximum Likelihood Fit to the 10 Halo Model

Initial estimates

Best ﬁt parameters

k

1
2
3
4
5
6
7
8
9
10
Bk

x

y

z

ρ

33.5
36.5
39.5
25.5
20.5
38.5
37.5
33.5
32.5
21.5
· · ·

178.5
192.5
174.5
189.5
192.5
193.5
175.5
172.5
185.5
190.5
· · ·

99.5
98.5
97.5
98.5
100.5
96.5
99.5
100.5
99.5
98.5
· · ·

0.078
0.060
0.023
0.018
0.015
0.011
0.005
0.005
0.005
0.004
· · ·

x0

33.5
36.7
39.5
26.0
20.4
38.7
37.4
33.1
32.8
25.1
· · ·

y0

z0

178.9
192.4
174.3
189.4
192.8
193.9
175.4
190.4
185.5
181.9
· · ·

99.7
98.8
97.5
98.9
100.9
96.3
99.5
99.4
100.0
95.3
· · ·

re

2.1
0.9
1.7
2.0
1.6
1.4
8.7
2.0
3.8
4.1
· · ·

n

log w

N

14.1
2.9

0.00
0.95
28.5 −0.37
26.2 −0.14
28.3 −0.53
4.0 −0.06
9.2 −2.75
26.9 −1.43
30.0 −1.92
25.3 −1.91
0.13
· · ·

688
354
138
449
94
119
47
23
48
48
73

Note—Input point process shown in Figure 4. k identiﬁes the halo component. Initial
r0 values from kernel density estimator in order of decreasing maximum density ρ. Best
ﬁt parameters give the halo center, Einasto parameters re and n, mixing coeﬃcient,
and number of dark matter particles.

higher than that of any halo. Second, the user can input a threshold value such that the particle is assigned directly
to the background component if all probabilities are below this value.

In our case study data set, we detect cases of the merging halos (see Figure 8). Following the rule given above, we
recommend a threshold of 0.3, which is suﬃcient to assign to the background all particles in an undecided situation.
In Table 4, we provide an example of this classiﬁcation procedure for the ﬁrst ﬁve particles in our data set, showing
the probability of each particle (rows) to belonging to each component (column). A ﬁnal column gives the identifying

17

Table 4. Halo Membership Probabilities for Bolshoi Dark Matter Particles

Part

Location

Halo Component

Bkgd Memb

x

y

z

1

2

3

4

5

6

7

8

9

10

1
2
3
4
5

39.125
35.139
34.817
32.199
31.930

192.997
191.504
191.624
189.673
189.982

95.635
98.906
98.213
99.982
99.307d

0.001
0 004
0.006
0.028
0.024

0.020
0.942
0.896
0.029
0.029

0.000
0.000
0.000
0.001
0.001

0.001
0.007
0.013
0.112
0.127

0.000
0.000
0.001
0.003
0.003

0.969
0.010
0.021
0.004
0.005

0.000
0.000
0.000
0.002
0.001

0.000
0.022
0.038
0.730
0.732

0.000
0.003
0.004
0.044
0.032

0.000
0.000
0.002
0.002
0.001

0.007
0.010
0.018
0.042
0.021

6
2
2
8
8

Note—This only shows a portion of the membership table. The full table is available in https://github.com/LluisHGil/darkmix/

blob/master/Output/membership.txt.

number of the halo component for each particle according to the chosen decision rule. This table is used to plot
Figure 8, with each component given in a diﬀerent color.

7.3. Goodness-of-Fit and Residual Analysis

Once our best ﬁt parameters are estimated, they can be displayed and analyzed for astrophysical properties. Some
halo components show degenerate values for re and n. As can be seen in Figure 8, each component is numbered
according to Table 3 and the circles have radius re. Halos 7 to 10 have extremely large radius. From Table 3, we
also note that these components have mixing coeﬃcients > 20 times lower than the other components—they have low
central densities with large radii and few particles. This is a sign that these components do not follow an Einasto
proﬁle and cannot be correctly modeled by our model. In addition, the S´ersic index n is also unreliable—while values
around 3 are expected in astrophysics (Merritt et al. 2006), much greater values are found instead. In §7.5, we provide
conﬁdence intervals for the parameters and a covariance matrix can be used to evaluate the reliability of the coeﬃcients.
An Einasto proﬁle with a high n mimics a power law with a strong concentration of points around the center and
weak tails. Optimally, we would use a diﬀerent function to model this kind of structure, but we can choose between
including degenerated halos or neglecting them and incorporate their particles to the background.

For our best ﬁt model of 11 components, we have a coeﬃcient of determination R2 = 0.92. In this calculation, the
kernel density estimator of the data (eq. 19) is compared to the model density ﬁeld (eq. 17). Even if these ﬁelds are
expressed in diﬀerent units, they must follow a linear relation if the ﬁtting is perfect. A linear regression between the
densities is ﬁtted in each spatial tile and R2 is reported as a measure of goodness-of-ﬁt.

These two ﬁelds, Σ∗

ω, can be seen in the left-hand panel of Fig. 6. We can see a clear agreement in both the
distribution, size and range of densities of the halos. The main diﬀerences arise from asymmetries in the real structure,
which are diﬃcult to capture with spherical halos.

ω and Σ†

We can see the probability density distribution of the smoothed raw residuals in Fig. 7. The residuals are skewed
(g1 = −5.4) at low values away from the halo peaks and exhibit heavy tails at high values near halo peaks. The reason
for the heavy tails is evident in the lower left-hand panel, which shows the absolute (s(r)) from equations 16. While
errors have mean zero by construction, a strong red-blue pattern around one of the biggest halos is responsible for the
largest residuals. This suggests that the shape is poorly ﬁtted by an Einasto proﬁle. It is diﬃcult to assess if these
errors are within the expected shot-noise errors of the model or if we should consider a change in the model, such as a
parameter ﬁt reﬁning or a diﬀerent proﬁle. However, the bottom right-hand panel of Fig. 6, which maps the relative
raw residuals (e(r)), shows that these model errors are small compared to the background, which is covered by red
areas when data is present. This implies that, in relative terms, the background has stronger ﬁtting problems that the
halo components.

This panel is particularly eﬀective at revealing structures that are not included in the model. The most prominent
structure missing in the model is at the bottom where, due to truncation by the window edge, an Einasto proﬁle of
a sparse cluster did not ﬁt well. Finally, on Fig. 8 we present a randomized classiﬁcation of the particles based on

18

Figure 6. Comparison of smoothed Bolshoi sample data and the 10-halo model. Top left-hand panel: data kernel particle

density ﬁeld Σ∗
ω(r|X). Top right-hand panel: smoothed raw residuals s(r). Bottom left-hand panel: model particle density
ﬁeld Σ†
ω(r|X, (cid:126)p, Θ). Bottom right-hand panel: relative residuals e(r). In the data and model density ﬁelds, gray intensity is
in logarithmic scale. Both images have been normalized over the number of particles. Dark areas indicate a denser region or
higher probability of being occupied by a point, while lighter areas are unlikely of being occupied by a particle. The smoothing
bandwidth for all maps is ω = 1, and the values summed over the dimension Z. Data points from Figure 4 are shown as small
black dots.

our model. The plot shows how a soft classiﬁer mixes the particles of diﬀerent components, specially under merging
conditions.

Another interesting visualization analysis is the proﬁle extraction. With eq. 9 and 10 we can plot the one-dimensional
proﬁle of the whole mixture model and also that of any individual halo component. In Fig. 9, we see the case for
components 2 and 4 in our classiﬁcation. We can see that the Einasto proﬁles (red curves) match the empirical proﬁle
(black dots) out to ∼ 2 Mpc, beyond which additional halos appear. The full model (green curves) follows the empirical
proﬁle remarkably well, with peaks associated with other clusters. With this method, mixture models can be used to
disentangle the real proﬁle of merging halos, recovering the distribution of these structures where the empirical proﬁle
does not allow it.

7.4. Comparison with BDM Calculations

19

Figure 7. Probability density distribution of the smoothed raw residuals.

Figure 8. Particle classiﬁcation based on Table 4. Clusters are labeled as in Table 3 and the circle radii are the ﬁtted Einasto
radii re.

The tables provided by the MultiDark Database (Riebe et al. 2013), including the Bolshoi simulation used in this
work, include a catalog of halos that have been detected with the Bound Density Maximum (BDM) algorithm (Klypin
& Holtzman 1997; Riebe et al. 2013). This algorithm detects local density maxima and deﬁnes a spherical halo that
removes unbound particles. This algorithm allows for the detection of subhalos, which are smaller structures inside
parent halos.

Our work makes use of a low density data sample, which does not permit the detection of small structures, such as
the less massive halos. Therefore, we compare our detected halos with the most massive BDM structures. In table
Bolshoi.BDMV from the Multidark Database, and inside the region of our data set, 26 halos can be found with more
than 30,000 particles. Since we have 10 halo components in our best ﬁt model, we select the 10 halos laying closer to
our centers. The resulting list can be found in the Github repository, ﬁle bdm halo.txt. In Figure 10 we compare both
sets of halos. As can be seen, the selected BDM halos lie very close to our halo centers and have been calculated to
contain a number of particles that highly correlates with our estimation (see Table 3, column N ). Since we are using
just a sample of particles to illustrate the methods, our numbers are only a fraction of the real number of particles.

20

Figure 9. Radial density proﬁles of clusters 2 (left-hand panel) and 6 (right-hand panel). Black dots represent the particle
number densities. The red curve is the density proﬁle of an isolated component (ˆρ(r|r0,j)) and the green curve is the density
proﬁle of the full mixture model ( ˆP (r|r0,j)). Note the close ﬁtting of the full mixture model proﬁle (in green).

Figure 10. Left-hand panel: layout of dark matter particles with BDM halo centers (squares) and our estimations (triangles).
Right-hand panel: number of particles found in the BDM catalog vs estimated number of particles in our mixture model. Line
indicates the best linear regression between both variables.

7.5. A Simpler, Bayesian Model
In Fig. 5 we see how the AIC and BIC showed a plateau after c = 6, Fig. 8 shows how the 7th component has a
radius re that extends around other halos and does not follow an Einasto proﬁle, and components 8 − 10 are sparse.
It may thus be scientiﬁcally useful to examine a simpler model with 7 rather than 11 components.

21

Table 5. Bayesian Fit to a Simpler c=7 Model

k

1
2
3
4
5
6
Bk

x0

y0

z0

re

n

log w

N

33.46 ± 0.01
36.67 ± 0.02
26.00 ± 0.03
38.60 ± 0.04
39.47 ± 0.02
20.40 ± 0.02
· · ·

178.80 ± 0.02
192.33 ± 0.01
189.35 ± 0.03
193.88 ± 0.03
174.22 ± 0.02
192.72 ± 0.02
· · ·

99.70 ± 0.02
98.75 ± 0.02
98.87 ± 0.02
96.18 ± 0.03
97.44 ± 0.03
100.81 ± 0.02
· · ·

1.05 ± 0.04
0.77 ± 0.05
1.11 ± 0.07
0.75 ± 0.08
0.90 ± 0.10
0.56 ± 0.08
· · ·

2.4 ± 0.2
3.0 ± 0.3
2.5 ± 0.3
2.2 ± 0.4
3.2 ± 0.6
3.2 ± 0.9
· · ·

1.5 ± 0.9
2.0 ± 1.0
0.8 ± 0.4
0.7 ± 0.5
0.4 ± 0.3
1.0

0.14 ± 0.004

599 ± 22
413 ± 19
376 ± 19
108 ± 11
127 ± 12
74 ± 8
384 ± 26

Note—Values are the mean and standard variation of the posterior distribution. Component 6 has

been used as the ﬁrst component in the model, and therefore w6 = 1.

Figure 11. Residuals from the Bayesian ﬁtting of the k = 6 halo mixture model. Absolute raw residuals s(r) (left-hand panel)
and relative residuals e(r) (right-hand panel) of the Bolshoi sample. Smoothing bandwidth is ω = 1 and values summed over
dimension Z.

This simpliﬁed model still has 36 parameters and was estimated using the MCMC sampling approach with maximum
a posterior best ﬁt parameters, where 3,600,000 iterations are needed to satisfactorily map the distributions. Although
it is not included in darkmix.R and shown here, we recommend the user to examine graphical and scalar (e.g., the
Gelman-Rubin statistic) diagnostics of convergence of the MCMC chains. CRAN package CODA is widely used for this
purpose. The long calculation time can be a considerable handicap and the MLE procedure that was given earlier may
be operationally more feasible for large data sets. The advantage of a Bayesian approach is to map non-Gaussianities
in the posterior distributions and curved relationships in bivariate parameter conﬁdence intervals. However, for many
science applications these capabilities are not needed and the MLE approach would be preferred.

In Table 5 we summarize the estimated maximum a posterior estimated parameters with error bars.
Compared to the c = 11 mixture model, the removal of components 7 to 10 has an impact on the estimation of the
other parameters. The R2 coeﬃcient is 0.936, which is similar to the more elaborate model. We show in Figure 11 the
absolute and the relative residuals (s(r) and e(r)). As can be seen, the structures that were previously modeled by
components 7 and 8 appear now in red colors. The absence of model components leave these structures underestimated.

22

However, its intensity is similar to that of some other regions in the data set and a visual inspection alone might not
be enough to detect them. We use the relative residuals in Figure 11 bottom panel to detect their presence.

8. CONCLUSIONS

We have demonstrated the use of ﬁnite mixture models to detect and characterize a sample of simulated dark matter
halos. The maximum-likelihood solution to a parametric model of the particle distribution produces a maximum
likelihood probability density function. Two results emerge from the model: a list of halos with their properties
(Table 3), and the probability that each particle is a member of each cluster (Table 4). This is a ‘soft classiﬁcation’
measure and additional decision rules are needed to assign membership probabilities to each particle. A variety of
graphical and statistical measures of goodness-of-ﬁt are provided. This mixture model approach has several important
diﬀerences from other conventional clustering techniques.

1. The user speciﬁes a radial proﬁle function based on previous astronomical experience or astrophysical insight.
Here, we chose an Einasto proﬁle, which is the three-dimensional analog of the S´ersic proﬁle and a generalization
of the de Vaucouleurs proﬁle for elliptical galaxies. This permits an estimation of parameters with a physical
interpretation, such as the size, shape and particle abundance of a halo. In addition, this estimation is done
directly on the three-dimensional data set, without the need to integrate the one-dimensional proﬁle and the loss
of information that it involves.

2. No threshold densities, maximum distance scales, minimum membership population, or other arbitrary parame-
ters are needed, as in nonparametric clustering procedures such as the ‘friends-of-friends’ algorithm (single-linkage
hierarchical clustering) or DBSCAN. A unique MLE for each value of k is calculated without any free parameters.
Model complexity (i.e., the value of k) is chosen based on penalized likelihood information criteria combined with
scientiﬁc judgment. The location, size and population of each halo is not subject to arbitrary parameter choices
but are outcomes of a likelihood calculation based on an astrophysically reasonable proﬁle function. Only the
membership of each particle can be enhanced using a threshold determined by the number of merging halos.
When two or three halos overlap, a value of 0.3 is advised.

3. As a soft classiﬁcation method, we have a measure of the reliability that a given dark matter particle is a member
of a given halo. Researchers who are interested in merging scenarios might use these results in various ways to
obtain more informative descriptions of the interactions. For example, sparse satellite halos can be identiﬁed
and their merging history into large protogalaxies can be traced. The ability of the mixture model to identify
clustered ensembles of halos (see Figure 8) may be useful. Mixture modeling of time sequences of the dark
matter distribution can reveal, in a statistically rigorous fashion, when and where merging occurs. Alternatively,
decision rules can be constructed to identify the most isolated dark matter particles to understand the evolution
of particles that have not merged into equilibrated halos.

4. The parametric mixture model would be challenged in situations where halos with a wide range of populations
N are present. If, for example, the data set here was dominated by a large halo with N ∼ 10, 000 particles,
then the likelihood may not be suﬃciently improved by the addition of a small halo with N ∼ 100. However,
most nonparametric clustering techniques have similar diﬃculties. Methods such as hierarchical density-based
clustering seek to address this diﬃculty (Campello et al. 2013).

Mixture models have been discouraged for use to understand the galaxy large-scale structure distribution because
it is dominated by interconnected curved ﬁlamentary structures rather than centrally condensed clusters (Kuhn et al.
2019). However, the dark matter collapses into distinct equilibrated halos early in the evolution of cosmic structures
and is more amenable to mixture analysis. The biggest handicap of these models is the calculation costs for large data
sets and large k. This method is best applied to the understanding of dark matter evolution within small boxes, rather
than analysis of a full multi-billion particle simulation. There is also the possibility that convergence will be diﬃcult,
either for the optimization of the MLE or for the MCMC chains of the Bayesian calculation. Other algorithms, such
as MultiNest (Skilling 2004; Feroz & Skilling 2013) or PolyChord (Handley et al. 2015a,b), that are specially meant
to estimate high-dimensional multimodal likelihood functions might be tried. Finally, we reiterate that all of the R
functions used in this work can be downloaded from our GitHub repository https://github.com/LluisHGil/darkmix.

23

ACKNOWLEDGEMENTS

This work has been funded by the project PID2019-109592GB-I00/AEI/10.13039/501100011033 from the Spanish
Ministerio de Ciencia e Innovaci´on - Agencia Estatal de Investigaci´on, by the Project of excellence Prometeo/2020/085
from the Conselleria d’Innovaci´o, Universitats, Ci`encia i Societat Digital de la Generalitat Valenciana, and by the
Acci´on Especial UV-INV-AE19-1199364 from the Vicerrectorado de Investigaci´on de la Universitat de Val`encia.

The CosmoSim database used in this paper is a service by the Leibniz-Institute for Astrophysics Potsdam (AIP). The
MultiDark database was developed in cooperation with the Spanish MultiDark Consolider Project CSD2009-00064.
The Bolshoi and MultiDark simulations have been performed within the Bolshoi project of the University of California
High-Performance AstroComputing Center (UC-HiPACC) and were run at the NASA Ames Research Center. The
MultiDark-Planck (MDPL) and the BigMD simulation suite have been performed in the Supermuc supercomputer at
LRZ using time granted by PRACE. E.D.F. thanks Penn State’s Center for Astrostatistics for an environment where
cross-disciplinary research can be eﬀectively pursued.

REFERENCES

Akaike, H. 1998, in Selected papers of hirotugu akaike

Church, S. E., Ganga, K. M., Ade, P. A. R., et al. 1997,

(Springer), 199–213

ApJ, 484, 523, doi: 10.1086/304362

Baddeley, A., Rubak, E., & Turner, R. 2015, Spatial point

Clerkin, L., Kirk, D., Manera, M., et al. 2017, MNRAS,

patterns: methodology and applications with R (CRC

466, 1444, doi: 10.1093/mnras/stw2106

press)

Baddeley, A., Turner, R., Møller, J., & Hazelton, M. 2005,

Journal of the Royal Statistical Society: Series B

(Statistical Methodology), 67, 617,

doi: 10.1111/j.1467-9868.2005.00519.x

Bardeen, J. M. 1980, PhRvD, 22, 1882,

doi: 10.1103/PhysRevD.22.1882

Behroozi, P. S., Wechsler, R. H., & Wu, H.-Y. 2013, ApJ,

762, 109, doi: 10.1088/0004-637X/762/2/109

Benaglia, T., Chauveau, D., Hunter, D. R., & Young, D.

2009, Journal of Statistical Software, 32, 1.

http://www.jstatsoft.org/v32/i06/

Benson, A. J., Frenk, C. S., Baugh, C. M., Cole, S., &

Lacey, C. G. 2001, MNRAS, 327, 1041,

doi: 10.1046/j.1365-8711.2001.04824.x

Bertschinger, E. 1985, ApJS, 58, 1, doi: 10.1086/191027

Burnham, K. P., & Anderson, D. R. 2002, Model selection

and multimodel inference: a practical

information-theoretic approach (Springer Science &

Business Media)

Colberg, J. M., White, S. D. M., Yoshida, N., et al. 2000,

MNRAS, 319, 209, doi: 10.1046/j.1365-8711.2000.03832.x

Coles, P., & Jones, B. 1991, MNRAS, 248, 1,

doi: 10.1093/mnras/248.1.1

Cooray, A., & Sheth, R. 2002, PhR, 372, 1,

doi: 10.1016/S0370-1573(02)00276-4

de Souza, R. S., Dantas, M. L. L., Costa-Duarte, M. V.,

et al. 2017, MNRAS, 472, 2808,
doi: 10.1093/mnras/stx2156

Einasto, J. 1965, Trudy Astroﬁzicheskogo Instituta

Alma-Ata, 5, 87

—. 1968, Publications of the Tartu Astroﬁzica Observatory,

36, 414

—. 1969, Astroﬁzika, 5, 137
Elahi, P. J., Ca˜nas, R., Poulton, R. J. J., et al. 2019,

PASA, 36, e021, doi: 10.1017/pasa.2019.12

Everitt, B., Landau, S., Leese, M., & Stahl, D. 2011,
Cluster Analysis (¿ Wiley Series in Probability and
Statistics), Chichester, UK: Wiley

Everitt, B. S. 2005, Encyclopedia of statistics in behavioral

science

Campello, R. J., Moulavi, D., & Sander, J. 2013, in

Paciﬁc-Asia conference on knowledge discovery and data

mining, Springer, 160–172

Celeux, G., & Govaert, G. 1992, Computational statistics &

Data analysis, 14, 315

Feroz, F., & Skilling, J. 2013, in American Institute of

Physics Conference Series, Vol. 1553, American Institute
of Physics Conference Series, ed. U. von Toussaint,
106–113, doi: 10.1063/1.4819989

Fillmore, J. A., & Goldreich, P. 1984, ApJ, 281, 9,

Chen, W.-C., & Maitra, R. 2015, EMCluster: EM

doi: 10.1086/162071

Algorithm for Model-Based Clustering of Finite Mixture

Fraley, C., & Raftery, A. E. 2002, Journal of the American

Gaussian Distribution

statistical Association, 97, 611

Christen, J. A., Fox, C., et al. 2010, Bayesian Analysis, 5,

263

Fr¨uhwirth-Schnatter, S. 2006, Finite mixture and Markov
switching models (Springer Science & Business Media)

24

Fruhwirth-Schnatter, S., Celeux, G., & Robert, C. P. 2019,
Handbook of mixture analysis (Chapman and Hall/CRC)

McLachlan, G., & Peel, D. 1999, Journal of Statistical

Software, 004.

Gower, J. C., & Ross, G. J. 1969, Journal of the Royal

https://EconPapers.repec.org/RePEc:jss:jstsof:v:004:i02

Statistical Society: Series C (Applied Statistics), 18, 54

—. 2000, Finite Mixture Models, 238

Gunn, J. E., & Gott, J. Richard, I. 1972, ApJ, 176, 1,

McLachlan Geoﬀrey, J., & Krishnan, T. 2008, The EM

doi: 10.1086/151605

algorithm and extensions, Wiley Series in Probability

Handley, W. J., Hobson, M. P., & Lasenby, A. N. 2015a,

and Statistics. Wiley-Interscience

MNRAS, 453, 4384, doi: 10.1093/mnras/stv1911

—. 2015b, MNRAS, 450, L61, doi: 10.1093/mnrasl/slv047

Hernquist, L. 1990, ApJ, 356, 359, doi: 10.1086/168845

Hoﬀman, Y., & Shaham, J. 1985, ApJ, 297, 16,

doi: 10.1086/163498

Merritt, D., Graham, A. W., Moore, B., Diemand, J., &

Terzi´c, B. 2006, AJ, 132, 2685, doi: 10.1086/508988

Moore, B., Quinn, T., Governato, F., Stadel, J., & Lake, G.

1999, MNRAS, 310, 1147,

doi: 10.1046/j.1365-8711.1999.03039.x

Hurtado-Gil, L., Kuhn, M. A., & Arnalte-Mur, P. 2022,

Navarro, J. F., Frenk, C. S., & White, S. D. M. 1996, ApJ,

LluisHGil/darkmix: v1.0.3, v1.0.3, Zenodo,
doi: 10.5281/zenodo.6855703

Hurtado-Gil, L., Mart´ınez, V. J., Arnalte-Mur, P., et al.

2017, A&A, 601, A40, doi: 10.1051/0004-6361/201629097

Hurtado-Gil, L., Arnalte-Mur, P., Mart´ınez, V. J., et al.

2016, ApJ, 818, 174, doi: 10.3847/0004-637X/818/2/174

Jenkins, A., Frenk, C. S., White, S. D. M., et al. 2001,

MNRAS, 321, 372, doi: 10.1046/j.1365-8711.2001.04029.x

Kaiser, N. 1984, ApJL, 284, L9, doi: 10.1086/184341

Kass, R. E., & Raftery, A. E. 1995, Journal of the american

statistical association, 90, 773

Kass, R. E., & Wasserman, L. 1995, Journal of the

american statistical association, 90, 928

Kauﬀmann, G., Colberg, J. M., Diaferio, A., & White, S.

D. M. 1999, MNRAS, 303, 188,
doi: 10.1046/j.1365-8711.1999.02202.x

Klypin, A., & Holtzman, J. 1997, arXiv e-prints, astro.

https://arxiv.org/abs/astro-ph/9712217

Klypin, A. A., Trujillo-Gomez, S., & Primack, J. 2011,
ApJ, 740, 102, doi: 10.1088/0004-637X/740/2/102

Konishi, S., & Kitagawa, G. 2008, Information criteria and
statistical modeling (Springer Science & Business Media)

Krishnan, T., & McLachlan, G. 1997, Wiley, 1, 58

Kuhn, M. A., Hillenbrand, L. A., Sills, A., Feigelson, E. D.,

& Getman, K. V. 2019, ApJ, 870, 32,
doi: 10.3847/1538-4357/aaef8c

462, 563, doi: 10.1086/177173

—. 1997, ApJ, 490, 493, doi: 10.1086/304888

Nelder, J. A., & Mead, R. 1965, The computer journal, 7,

308

Neyman, J., & Scott, E. L. 1952, ApJ, 116, 144,

doi: 10.1086/145599

—. 1953, Proceedings of the National Academy of Science,

39, 737, doi: 10.1073/pnas.39.8.737

—. 1954, Proceedings of the National Academy of Science,

40, 873, doi: 10.1073/pnas.40.10.873

Pedregosa, F., Varoquaux, G., Gramfort, A., et al. 2011,

Journal of Machine Learning Research, 12, 2825

Peel, D., & MacLahlan, G. 2000, John & Sons

Prada, F., Klypin, A. A., Cuesta, A. J., Betancort-Rijo,

J. E., & Primack, J. 2012, MNRAS, 423, 3018,

doi: 10.1111/j.1365-2966.2012.21007.x

Rao, C. R., Rao, C. R., Statistiker, M., Rao, C. R., & Rao,

C. R. 1973, Linear statistical inference and its

applications, Vol. 2 (Wiley New York)

Riebe, K., Partl, A. M., Enke, H., et al. 2013,

Astronomische Nachrichten, 334, 691,

doi: 10.1002/asna.201211900

Roberts, G. O., & Rosenthal, J. S. 2009, Journal of

Computational and Graphical Statistics, 18, 349,

doi: 10.1198/jcgs.2009.06134

Kuhn, M. A., Feigelson, E. D., Getman, K. V., et al. 2014,

Schwarz, G., et al. 1978, The annals of statistics, 6, 461

ApJ, 787, 107, doi: 10.1088/0004-637X/787/2/107

Scrucca, L., Fop, M., Murphy, T. B., & Raftery, A. E. 2016,

Lahiri, P. 2001, in Model selection, IMS

Madgwick, D. S., Hawkins, E., Lahav, O., et al. 2003,

The R Journal, 8, 205. https://journal.r-project.org/

archive/2016-1/scrucca-fop-murphy-etal.pdf

MNRAS, 344, 847, doi: 10.1046/j.1365-8711.2003.06861.x

S´ersic, J. L. 1963, Boletin de la Asociacion Argentina de

Mart´ınez, V. J., & Saar, E. 2002, Statistics of the Galaxy

Astronomia La Plata Argentina, 6, 41

Distribution (Chapman & Hall/CRC Press)

Sersic, J. L. 1968, Atlas de Galaxias Australes, Vol. 1

McLachlan, G., & Krishnan, T. 2007, The EM algorithm

(Observatorio Astronomico, Universidad Nacional de

and extensions, Vol. 382 (John Wiley & Sons)

Cordoba)

25

Skilling, J. 2004, in American Institute of Physics

—. 2013b, Bayesian Inference. http://cran.r-project.org/

Conference Series, Vol. 735, American Institute of

Physics Conference Series, ed. R. Fischer, R. Preuss, &

U. V. Toussaint, 395–405, doi: 10.1063/1.1835238

Somerville, R. S., & Primack, J. R. 1999, MNRAS, 310,

1087, doi: 10.1046/j.1365-8711.1999.03032.x

Statisticat, & LLC. 2013a, LaplacesDemon: Complete

web/packages/LaplacesDemon/index.html

—. 2013c, LaplacesDemon Examples. http://cran.

r-project.org/web/packages/LaplacesDemon/index.html
—. 2013d, LaplacesDemon Tutorial. http://cran.r-project.

org/web/packages/LaplacesDemon/index.html
Team, R. C. 2015, URL http://www. R-project. org
Willis, J. S., Schaller, M., Gonnet, P., & Helly, J. C. 2020,

arXiv e-prints, arXiv:2003.11468.
https://arxiv.org/abs/2003.11468

Environment for Bayesian Inference. http://cran.

Zehavi, I., Zheng, Z., Weinberg, D. H., et al. 2011, ApJ,

r-project.org/web/packages/LaplacesDemon/index.html

736, 59, doi: 10.1088/0004-637X/736/1/59

