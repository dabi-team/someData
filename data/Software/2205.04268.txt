Modeling Interconnected Social and Technical
Risks in Open Source Software Ecosystems

William Schueller and Johannes Wachs

1

2
2
0
2

y
a
M
0
1

]
E
S
.
s
c
[

2
v
8
6
2
4
0
.
5
0
2
2
:
v
i
X
r
a

Abstract—Open source software ecosystems consist of thou-
sands of interdependent libraries, which users can combine
to great effect. Recent work has pointed out two kinds of
risks in these systems: that technical problems like bugs and
vulnerabilities can spread through dependency links, and that
relatively few developers are responsible for maintaining even the
most widely used libraries. However, a more holistic diagnosis of
systemic risk in software ecosystem should consider how these
social and technical sources of risk interact and amplify one
another. Motivated by the observation that the same individu-
als maintain several libraries within dependency networks, we
present a methodological framework to measure risk in software
ecosystems as a function of both dependencies and developers.
In our models, a library’s chance of failure increases as its
developers leave and as its upstream dependencies fail. We
apply our method to data from the Rust ecosystem, highlighting
several systemically important libraries that are overlooked when
only considering technical dependencies. We compare potential
interventions, seeking better ways to deploy limited developer
resources with a view to improving overall ecosystem health and
software supply chain resilience.

Index Terms—Open source software, risk, supply chains,

dependencies, networks, human factors

I. INTRODUCTION

Open source software (OSS) ecosystems are built by de-
centralized collaborations of thousands of software developers.
Relative to the number of developers active in the system as
a whole, individual libraries are maintained by small teams
or even individuals. The dependencies between these libraries
form the backbone of the ecosystem, allowing developers to
focus on highly specialized work by importing the work of
others. The resulting dependency network represents both a
valuable distribution of work and effort across developers, and
a potential source of risk. Errors, bugs, and vulnerabilities can
propagate through this network [1], [2] and we rely on the
maintainers of the libraries we use to address these issues [3].
Yet a more complete conceptualization of systemic risk in OSS
ecosystems should recognize that these are correlated risks in
an interconnected system: key individuals maintain multiple
libraries up and down the dependency network.

Indeed recent events have shown how a variety of issues
can propagate through software dependency networks, causing
outages and problems in important real-world systems. The
growth of dependencies in multiple ecosystems [1] and the
proliferation of vulnerabilities through those dependencies [4]
are well-documented [5]. Another line of research, highlight-
ing a different aspect of OSS ecosystem fragility, focuses

W. Schueller is with the Complexity Science Hub Vienna and the Med-
ical University of Vienna. J. Wachs is with the Vienna University of
Economics and Business and the Complexity Science Hub Vienna. Email:
johannes.wachs@wu.ac.at

on the developers maintaining these libraries. These works
examine the social and structural patterns associated with
collaboration and sustained activity in OSS [6], [7]. One often
replicated ﬁnding is that many of the most important libraries
are maintained by small groups or individuals [3], [8].

While these two perspectives certainly each highlight im-
portant problems on their own, we argue that signiﬁcant
systemic risks in OSS ecosystem emerge through the complex
interaction of their social and technical systems. The risks
of ever-expanding dependency networks are ampliﬁed when
individuals are core contributors to several libraries in a depen-
dency chain. As we can observe in Figure 1, in which we plot
the dependencies among the 100 most downloaded libraries in
the Rust ecosystem, it often happens that individual developers
are the most proliﬁc contributors to multiple libraries. The de-
parture of any of these developers would introduce a correlated
shock affecting the future functionality of several libraries in
the system. The aim of our work is to establish a framework
to quantify the systemic importance of all developers and
libraries that takes these potential correlations into account.

In particular, we adapt methods used to study the propaga-
tion of errors in complex systems to the case of open source
software ecosystems. We use a simulation approach to quantify
systemic risk and apply it to data from the Rust ecosystem.
In particular, we simulate the removal of developers from
the system, which induces potential failures in libraries that
they maintain, which in turn spread with some probability to
downstream dependencies. The likelihood that a library fails,
governed by a production function, increases in the share of
its developers who have left and as its upstreams fail. We
quantify this likelihood using production functions, modeling
maintainers and functioning upstream dependencies as playing
a complementary role in insuring the survival of a library. We
deﬁne an iterative equation to calculate the spread of issues
resulting from the departure of speciﬁc developers from the
system. At the system level we ﬁnd the signiﬁcant potential
for long cascades of failures when speciﬁc individuals leave.
We also highlight the libraries that play a major role in many
potential cascade paths - which present natural intervention
points.

Among the top 1,000 Rust

libraries by count of their
downstream dependencies, our measure of an individual li-
brary’s systemic importance is moderately correlated with how
many direct (Spearman’s ρ ≈ .56) and transitive dependen-
cies (Spearman’s ρ ≈ .54) it has, and thus highlights key
libraries that these purely technical dependency-based mea-
sures overlook. Our measure has an even weaker correlation
with the number of GitHub stars a library has (Spearman’s
ρ ≈ .42), suggesting that social visibility is a poor proxy for

 
 
 
 
 
 
2

Fig. 1. The dependency network among the 100 most downloaded libraries in the Rust ecosystem, observed July 2020. A directed edge between two libraries
indicates a dependency. Distinct colors highlight three groups of libraries that have the same developer making the most commits in the previous year. For
example, Developer B makes the most commits in each of the three red libraries. Across all 100 libraries, there are 59 unique most active developers, indicating
that key individuals often play an important role in multiple interdependent libraries. Note: 24 disconnected libraries are not shown.

systemic importance. This motivated us to use our framework
to evaluate potential interventions, i.e. by allocating developer
resources to libraries according to various heuristics. We
show that allocating developers to the most systemically risky
libraries improves system robustness more than by adding
developers to libraries central
in the dependency network
or to socially popular libraries. We argue that this provides
valuable insights for individuals, foundations, and ﬁrms who
are seeking to support OSS ecosystem stability by sponsoring
developers or by contributing directly [9], [10].

We now proceed with a review of related works and then
introduce the Rust ecosystem and the data we use. We then
describe the simulations we carry out and report results. We
consider various alternative intervention strategies aiming to
improve the global health of an ecosystem by deploying devel-
opers to key libraries. The paper concludes with a discussion
of limitations and ideas for future work.

II. BACKGROUND

In this section we review related work, ﬁrst on the mea-
surement of systemic risks and cascades in complex systems.
We then turn to the speciﬁc case of such risks in software
ecosystems, discussing both social and technical factors.

software systems [1], [19]. However, to our knowledge most
work in this area so far has been descriptive.

These studies of complex systems simulate the spread of
failures from speciﬁc sources to quantify overall systemic
risk and the importance of individual entities in the system
[20]. In these simulations, the functions governing how errors
spread are tailored to the speciﬁc situation. For instance,
recent work on the resilience of supply chains has used
production functions such as the Cobb-Douglas and Leontief
functions to model the effect of upstream failures on a node’s
production [13]. The choice of a speciﬁc production function
allows us to consider whether inputs are complementary or
whether they can be substituted for each other. In the case of
the production and maintenance of software libraries, the effort
of maintainers and the functionality of upstream dependencies
are complementary, in general they cannot replace one another.
The initial condition of the error or failure is also important:
for instance contagion in ﬁnancial networks often begins with
the default of a large loan or a bankruptcy. In the case of
any speciﬁc application, care must be taken to understand
conceptually the mechanisms of how errors spread.

B. Vulnerabilities of OSS Ecosystems

A. Resilience and Vulnerability of Complex Systems

The ﬁeld of complexity science has long studied the vul-
nerability of interconnected systems. Studies of cascading
failures in ﬁnancial networks [11], [12], supply chains [13],
power distribution networks [14], regional economies [15], and
healthcare systems [16] all highlight that a few key nodes
in a system can play a systemically important role that is
not obvious from their local topology or individual size. The
spread of errors in coupled networks, and thus the identity
of the most important nodes vis-a-vis such spreading, is even
less predictable
[17], [18]. Previous work in the software
engineering research community has pointed out the potential
application of complex systems approaches to the study of

Technical Vulnerabilities: Bugs and vulnerabilities spread
through software ecosystems via dependencies [7]. A 2018
study estimates that half of libraries in the NPM ecosystem
are affected by upstream vulnerabilities [4]. A series of real
world examples highlight the multiple ways problems can
spread through and affect whole software ecosystems via their
dependency networks. In 2016 a developer of an auxiliary
string formatting program called left-pad removed his libraries
from NPM, a package manager for JavaScript libraries, and
caused a cascade of failures that lead to large scale service
interruptions around the web [21]. A signiﬁcant share of the
web’s infrastructure depended, often indirectly, on left-pad’s
11 lines of code.

Library 1Library 2Dev ADependencyDev BDev CMost active developer in given libraryWhile in this case a reasonable solution would be for OSS
developers to remove the dependency and implement their
own version of this short script, upstream issues sometimes
occur in more substantial pieces of software. Many of these
systemically important libraries are overlooked because they
have worked well in the background for many years. The
Heartbleed bug, introduced into the widely used OpenSSL
cryptography library in 2012, made roughly half a million
webservers and their user passwords and cookies vulnerable
to attack [22]. Though the bug was quickly resolved, servers
remained vulnerable until patched.

Software systems are also frequently attacked via loopholes
introduced by upstream dependencies [5]. In 2017, intrud-
ers exploited a vulnerability to access an Equifax database,
exposing personal ﬁnance data of over one hundred million
people. Equifax used an outdated version of Apache Struts 2,
an OS web application framework which had a publicly-known
(and patched) security vulnerability [23]. Another example of
software that is widely relied upon is log4j, a “ubiquitous”
Java logging library used widely in enterprise software [24]. In
late 2021, a zero-day vulnerability in log4j was reported which
can be used to take control of software systems remotely. In
other words, software using log4j became vulnerable. Security
researchers have recently demonstrated how dependency man-
agers themselves can be used to introduce malicious lines into
the codebases of leading software companies [25]. A recent
study suggests that the share of libraries in NPM inheriting
vulnerabilities from upstream dependencies is rising over time
[26]. Tracking vulnerabilities is also a signiﬁcant challenge
for developers and companies [27], and they often persist in
ecosystems [28], for instance when patches are not adopted
by downstream dependencies [29].

These risks in the “supply chain” of OSS are increas-
ingly recognized and quantiﬁed in the empirical software
engineering literature [30], [31]. Decan, Mens, and Grosjean
describe the evolution of the dependency networks of seven
large OSS ecosystems, ﬁnding an increasing trend in the
number of direct and indirect (sometimes called transitive)
dependencies in all of them [1]. Many of these upstream
dependencies are small libraries in the mold of left-pad [32].
These so called “trivial” libraries are ironically more likely to
occupy critical positions in the dependency network, owing
to their widespread use [33]. This highlights the importance
of considering the network as a whole, rather than focusing
on important seeming libraries. Indeed, the relative position
of a library in a dependency network is a strong predictor of
continued activity [7]. In particular, having dormant upstreams
increases the risk that a library will itself become dormant.

Social roots of ecosystem vulnerability: Early advocates for
the OSS model of software development argued that small
contributions of many developers would lead to high quality
software [34]. And although the decentralized peer production
process has resulted in remarkably successful software [35],
the reliance on volunteers and unpaid labor to maintain such
widely used software has led to an underproduction of OSS.
In this context underproduction, coined by Champion and
Mako Hill, refers to a mismatch between the supply of
software development labor and demand of people relying on

3

a particular software library [36].

The extent to which software relies on individual developers
has been conceptualized as the truck factor or bus factor of
a library [37], [38]. It has been described as “the number of
developers on a team who have to be hit with a truck (i.e.,
to go on vacation, to become ill, or to leave the company for
another) before the project is in serious trouble” (see: http://
www.agileadvice.com/archives/2005/05/truck). In other words,
the truck factor describes the distribution and redundancy of
essential knowledge and know-how about a speciﬁc software
library or project among its developers. A hypothetical library
with a truck factor of one relies in some essential way on the
contributions, efforts, and knowledge of a single individual.
Empirical studies have shown that truck factors of even very
widely used libraries are often very low [8], [39]. One study of
133 popular projects on GitHub found that nearly two-thirds
had a truck factor of two or less [3]. In practice, libraries are
often abandoned because their original core developers and
maintainers lack the time or interest to continue working on
them [40]. On the other hand, libraries that have contributors
that contribute to other libraries tend to stay active [7].

When libraries go under-maintained or become deprecated,
issues tend to build up. It is one of Lehman’s Laws that
software quickly becomes ineffective or nonfunctional without
maintenance [41]. In practice, the same individuals who write
the original code of a program are the ones who maintain it, a
task which often requires quick interventions when something
goes wrong [42]. Unmaintained libraries are not adapted to
changes of the broader ecosystem. When upstream libraries
introduce breaking changes, a deprecated library will cease
to function properly and pass issues downstream. This is not
just a theoretical concern: over half of NPM libraries depend
transitively on at least one deprecated library [43].

Previous work diagnosing the health of ecosystems has not
directly addressed the phenomenon of developers working on
multiple libraries within an ecosystem. Such developers can
make highly valuable contributions, for example because they
facilitate coordination and communication between interlink-
ing parts of a larger system [44] or because they are uniquely
placed to anticipate failures or issues [45]. Although their
attention may be divided [46], developers involved in multiple
part of an ecosystem are in a position to better consider how
new developments in one library may affect others. At the
same time, these same aspects make such developers essential
to the system as a whole. When such a developer leaves the
OSS world, whether it is because they ﬁnd a new job and no
longer have the time, or because they retire, or simply because
they no longer want to participate, they may leave several key
libraries under- or unmaintained at the same time.

III. DATA
We now turn to the data we use to build and test our
systemic risk measurement framework. We use data from the
Rust ecosystem, utilizing a dynamic database of dependencies
and contributions to Rust libraries assembled by Schueller et
al. [47]. Rust is a relatively young but popular and growing
programming language, which was recently adopted as the sec-
ond ofﬁcial language of the Linux kernel project. We choose

Rust for several reasons. First, the Rust dependency manager
Cargo stores valuable data on the evolution of dependencies
between libraries overtime. It also has data on the number
of downloads over time, allowing us to test the impact of
hypothetical failures on end users. Second, a large majority of
Rust libraries are hosted on GitHub or Gitlab, likely because
of the language’s youth relative to these platforms and its
community’s strong OSS orientation, allowing us to download
nearly all libraries and their complete development histories.
Finally, as a growing ecosystem, Rust allows us to track the
evolution of systemic risk across its life-course. We note that
while other ecosystems may not have the same quality and
scope of data, our framework is modular and can be adapted
to different datasets.

A. Package metadata, repositories, dependency network

The core of the dataset is derived from a database dump
from Cargo (available on https://crates.io/data-access, updated
daily) containing extensive metadata about packages (called
crates in the Rust ecosystem). The dataset includes package
names, URLs, versions, dependencies, creation date, and daily
downloads. URLs can be linked to valid repository URLs
on GitHub and Gitlab, which can be cloned locally. It also
provides details on dependencies between packages, enabling
the construction of a dependency network at various points
in time, which is important as libraries add and remove
dependencies on a regular basis. The database discards infor-
mation about versions by considering only the dependencies
of the latest version of a library - recognizing that version
conﬂicts are a major way in which libraries break because of
undermaintenance [1], [48].

B. Developer Contributions

We consider commits as the elemental contributions that
developers make to projects. Though we acknowledge that
other forms of contributions such as issue reporting represent
valuable contributions to OSS projects and ecosystems as
a whole [49], adjusting to upstream issues, for example,
typically requires committing code. To quantify the extent
to which individuals contribute to speciﬁc packages, commit
authors need to be disambiguated because commits themselves
are only signed with email addresses. The database we use
disambiguates contributor emails to the level of GitHub and
Gitlab accounts using the respective APIs [47], [50]. This
approach makes more accurate merges than commit email
address approaches [51], which rather have the beneﬁt that
they scale to larger datasets. The database we use also labels
contributions from bots, using a ground truth dataset [52] and
a manual inspection of the most active account, which we
exclude from our analyses.

Finally, we considered two approaches for associating de-
velopers to libraries as contributors. Often researchers consider
some threshold, for example the smallest set of contributors
accounting for at least 80% of activity in the library [53], [54].
We rather considered all developers making any contribution
to a library in the year preceding a chosen reference time,
weighing them by their share of contributions (in number

4

of commits). In our application, we felt this was a more
appropriate choice because (relatively) infrequent contributors
may be good candidates to step in when additional help is
needed, and their work may still constitute a non-negligible
share of the global work done on repository. Our code and
methods can easily be adapted to consider only core developers
according to a threshold of activity, or only contributors with
merge rights, or to study activity at different time scale (e.g.
a month instead of a year).

In the analysis carried out in the rest of the paper we ﬁx
the scope of the dataset: we consider the dependency network
between Rust repos as observed on January 1, 2022. We
consider contributions (commits) made to repos from January
1, 2021 to January 1, 2022. We operate in repo space rather
than package space, noting that a similar analysis can be
carried out in the latter. To emphasize this point of ﬂexibility,
we refer to libraries rather than repos or packages in the
subsequent sections.

C. Data and Code availability

An anonymized dataset is available on Figshare (https://
ﬁgshare.com/s/93158d03416765444650). The underlying code
for both data collection and processing is released as an
open-source Python library called RepoDepo: https://github.
com/wschuell/repodepo. RepoDepo acts as a wrapper around
a database structure in either SQLite or PostgreSQL, with
the database from different data
speciﬁc adaptors to ﬁll
sources (CSVs, GitHub/Gitlab REST or GraphQL APIs, and
crates.io daily database dumps) and to extract data/apply
speciﬁc processing. The structure is meant to be modular
so that custom functions to collect more data can be added
later on. Code to reproduce our analyses is available at
https://github.com/wschuell/misteriosse.

IV. METHODS AND ANALYSIS
A. Modeling Library Functionality via Production Functions

The key insight our paper brings from the complex systems
literature is that when systems have rich interdependencies,
small changes in seemingly unimportant parts of a system can
have an outsized effect on the functioning of the whole. To
carry out this kind of analysis in the context of spreading
failures in the Rust ecosystem, we will now describe how
to quantify a library’s functionality in terms of social and
technical inputs.

A library i requires both functioning upstream dependencies
and active contributors to continue to function properly. A
developer stopping to contribute, or a dependency missing,
compromised or exposed to bugs will expose the library
itself to an increased risk. We assume that both sources of
risk can be combined into one quantity: a probability of
failure 0 ≤ F (i) ≤ 1. Risk is minimized when a library
has active maintainers and functioning dependencies. Risk
is highest when all developers having stopped maintenance
work on the library and/or all upstream dependencies have
failed. To combine the two sources of risk, adapt the notion
of a production function from the economics literature [55].
Production functions are used in a variety of contexts to

describe how inputs are combined to generate outputs. A
traditional example is how capital and labor combine to create
goods in an economy. The chosen functional form governs how
the inputs interact with one another. For instance, two inputs
may substitute for or complement one another. In one extreme
case, one or more inputs may be essential to production.

5

In our case, we argue that maintaining developers and
functioning upstream dependencies are both required for a
library to continue to work. These two inputs to software
maintenance can only substitute for each other in a limited
way. This perspective aggregates and necessarily simpliﬁes
several sources of risks, but provides a ﬂexible framework to
consider the impact of both social and technical vulnerabilities.
Speciﬁcally we use a Cobb-Douglas style production function
[55] Pi, which considers the product of the shares of func-
tioning its upstream dependencies (di) and active contributors
(ci):

Fi = 1 − Pi = 1 − (c1/2

i

(cid:63) d1/2
i

)

.

For example, a library or package with one half of its
contributors available, and two-thirds of its upstream depen-
dencies functioning, will have a roughly 43% (1 − ((1/2)1/2 (cid:63)
(2/3)1/2)) risk exposure, i.e. its chance of failing. We selected
the Cobb-Douglas production function to model the spread
of risk because it suggests that contributors and upstream
health are complements and imperfect substitutes, and that
libraries can fail if either is missing. Indeed the Cobb-Douglas
functional form is often used to model or estimate the relative
contributions of labor and capital to output in a ﬁrm or industry
[55].

Other production functions such as the Leontief production
function (1 − min(ci, di)), in which inputs cannot be substi-
tuted at all, or a linear production function (1 − ci+di
), in
which inputs are perfect substitutes, may be more appropriate
for the spread of different kinds of issues. In this sense our
framework is ﬂexible and can diagnose systemic risk with
respect to different kinds of issues. We plot the Cobb-Douglas
function predicted chance of library failure in Figure 2. In the
following, we study libraries at the level of repositories.

2

Diffusion of Failures

In order to model

the spread of library failures in the
ecosystem, we need represent two kinds of relationships. The
ﬁrst kind consists of maintenance activity by developers in
speciﬁc libraries. We store this information as a matrix1 C,
in which the entry Ci,j counts the number of commits made
by developer i to library j. We normalize the columns of this
matrix and obtain ˆC, in which the entry ˆCi,j can be interpreted
as the share of contributions to library j made by developer i.
The second kind of relationships within the ecosystem we
consider are the dependencies between libraries. We store this
information in a matrix D. D is a square matrix with rows and
columns equal to the number of dependencies. Entry Di,j is
equal to 1 if library j depends on library i, and is 0 otherwise.

1We refer to developers and contributors interchangeably, preferring to use
the notation C to distinguish their role from the role of technical dependencies.

Fig. 2. The chance of library failure in terms of the shares of inactive
developers and failed upstream dependencies, as quantiﬁed using a Cobb-
Douglas production function. A library with all of its original developers still
active, and 60% of its direct upstream dependencies functional has a roughly
80% chance to survive.

Similar to the previous case, we normalize the columns of this
matrix to obtain ˆD, in which the entry ˆDi,j can be interpreted
as the share of dependency of library j on library i.

We now deﬁne two vectors that

track the state of the
system. SC is a vector corresponding to the contributors
in the ecosystem. The i-th entry of SC is 1 if contributor
i is active, otherwise 0. As our analysis deals with the
potential consequences of contributors leaving the ecosystem,
this vector will be an input to our scenarios.

The second vector SL tracks the state of each library. That
is to say it deﬁnes the likelihood that a library will fail, given
the status of its upstream dependencies and contributors.

When all libraries are fully functioning, every coordinate of
SL is equal to 1. Those coordinates correspond conceptually
to 1 − Fi as deﬁned in the previous subsection, and depending
on the imposed conditions – e.g. some developers missing –
can take values between 0 and 1, 0 being the highest possible
level of risk exposure.

Our scenarios consider what happens to the libraries after a
contributor leaves the ecosystem. The departure of a developer
triggers potential issues: either directly on those libraries to
which she contributes, or indirectly, on those libraries which
depend on libraries she maintains. This information is captured
by the following self-referential equation:

SL = (SC(cid:124)

(cid:63) ˆC)1/2 (cid:12) (SL(cid:124)

(cid:63) ˆD)1/2.

In this equation (cid:12) denotes element-wise matrix multiplica-
tion. Likewise, the exponents are to be taken element-wise. (cid:124)
denotes the transpose of the vectors. In plain terms, the left
factor corresponds to the effect of absent contributors on the
states of the libraries, while the right factor corresponds to
the effect of potential malfunctioning upstream dependencies.
These effects are combined by the Cobb-Douglas style pro-
duction function.

In our application ˆC, ˆD, and SC are ﬁxed and we can
represent the equation in the following form SL = f (cid:0)SL(cid:1),
emphasizing that the library state vector is updating. To ﬁnd
the solution of this equation, we iterate from the initial state
in which all libraries are functioning, which we denote SL
0 :

0.00.20.40.60.81.0Share of Upstream Dependencies Functional0.00.20.40.60.81.0Survival Probability (Pi)All Devs ActiveHalf Devs ActiveNo Devs Active6

ˆD =


0
0


0

0

1
0
0
0

0
.5
0
.5


1
0


0

0

This matrix indicates that library 1 has no upstream depen-
dencies (column 1), while libraries 2 and 4 depends solely on
library 1. Library 3 (column 3) depends on both libraries 2
and 4.

We now calculate what happens according to our method
if contributor 2 is removed from the system, as indicated in
Figure 3. We obtain the following equation:

1 = ((cid:2)1
SL

0

1(cid:3) (cid:63) ˆC)1/2 (cid:12) ((cid:2)1

1

1

1(cid:3) (cid:63) ˆD)1/2

Carrying out the matrix multiplications and the exponents

(element-wise) of the two factors results in:

SL

1 =








0
(cid:113) 3
4

1
1








(cid:12)



1
1




1


1

As the multiplication is element-wise, the updated vector is

simply the ﬁrst factor:

SL

1 =















0
(cid:113) 3
4

1
1

In the next step of the calculation, the left factor would be
unchanged, but the right factor would be changed, reﬂecting
the spread of the probability of failure from libraries 1 and
2 (recall that the removed contributor 2 contributed to both).
As the reader can verify, the removal of contributor 2 leads
to a chain reaction in which the functionality of all libraries
in the ecosystem is affected. Speciﬁcally the next step of the
iteration yields:

SL

2 =









0
0
(cid:114) √
3 + 2
4
0









.

The next iteration after that results in a library state vector

of all zeros. In other words, SL

3 = SL

F in = (cid:126)0.

Ranking Contributors, Libraries, and the Ecosystem as a
Whole

With this method to model the spread of failures resulting
from the removal of individual contributors, we proceed to
test the robustness of the whole Rust ecosystem, aiming to
rank contributors and libraries for their systemic importance.
To do so we simply repeat the iterated calculation above for
every contributor in the ecosystem. That is, we remove each
contributor, alone, a single time. Note that more complex
removals are possible - the diffusion equation is ﬂexible and

Fig. 3. An example ecosystem. A) The network of dependencies between four
libraries. B) The three contributors to the libraries. Percentages denote what
share of contributions they make to a speciﬁc library. For instance, contributor
1 makes 25% of all contributions to library 2. In our example calculation, we
simulate the consequences of the departure of contributor 2 from the system.

SL

n

(cid:1)

0 = 1
n+1 = f (cid:0)SL
SL
As we will discuss below, this sequence converges towards
a solution in a ﬁnite number of steps, which we denote SL =
SL

F in. Subsequent iterations do not update the vector.
We now describe the speciﬁc analyses we carry out. As
discussed, we proceed by initializing all entries of the library
state vector SL to 1. We then remove a developer from
the system, changing a single entry of the contributor state
vector SC from 1 to 0. This allows us to calculate a step of
the spread or diffusion of issues. We note that our practical
implementation includes two small corrections to the equation
to handle edge cases. When a library has no dependencies, its
entry on the right factor is set to one at the end of every step
in the iteration. Similarly for the left factor for libraries with
no default contributors.

In the next step of the spreading, note that the left factor
is unchanged - we do not remove additional developers - and
that the right factor is simply the result of the calculation
carried out in the previous step. We repeat this calculation
several times, until the state vector of SL is unchanged. As
the dependency network has no cycles (i.e. is a directed acyclic
graph or DAG), the process always converges. In practice, this
happens in a relatively small number of steps – approximately
20 in our application – as the depth of the dependency tree
(through which faults spread) is small relative to the size of
the system as a whole.

We now carry out one step of an example diffusion on
a toy ecosystem. We visualize this example in Figure 3. In
this ecosystem there are four libraries maintained by four
developers. We deﬁne the normalized contributors matrix:

ˆC =


0
1

0



.5
.25 0
.25 1

0 0
0

1

Column 2 indicates that contributor 1 is responsible for half
of the contributions to library 2, while contributors 2 and 3
are responsible for one quarter each. Contributor 2 is the sole
contributor to library 1. The normalized dependency matrix,
on the other hand is a square 4x4 matrix:

7

can accommodate any valid input contributor state vector. For
example, one could remove all contributors supported by a
speciﬁc corporation or foundation.

For each contributor we remove from the system, our
calculations yield a ﬁnal
Fin. These
vectors represent the functionality of the libraries following
the cascade induced by a speciﬁc contributor’s departure. We
deﬁne the risk Ri to library i as the difference:

library state vector SL

Ri = 1 − SL

Fin(i)

.

As not all libraries are equally important to the ecosystem
as a whole, we weigh these entries by the share of downloads
the speciﬁc library has of all total downloads. Speciﬁcally the
download-weighted risk of a simulated removal to library i is
deﬁned as:

Rdl

i = (1 − SL

Fin(i)) ·

dli
j dlj

(cid:80)

,

Fig. 4. The rank-ordered contributions of Rust contributors to systemic risk,
on a logarithmic scale. The top 10 developers account for 43% of systemic
risk.

where the denominator in the right factor of the product
denotes the sum of downloads of all libraries. Recall that
downloads (like commits) are counted only in the year January
1, 2021 to January 1, 2022 for the analysis and results
presented in this paper.

Summing the resulting download-weighted risk score over
all libraries in the ecosystem yields our ﬁnal risk score for a
speciﬁc scenario (deﬁned originally by the input contributor
state vector SC. It also carries a straightforward interpretation:
it describes the average risk exposure of a random individual
download of a library in the ecosystem for the given scenario.
With this framework in hand we can now deﬁne how we rank
contributors and libraries, and quantify overall ecosystem’s
risk.

Ranking Contributors: Ranking contributors in terms of
their systemic importance in this context is straightforward.
Given the removal of contributor j, implemented by setting
the j-th entry of the input contributor state vector SC to 0,
the overall Contributor Impact Ij is simply the sum of all
library download-weighted risk scores:

Ij =

(cid:88)

Rdl
i .

i

In other words, this measures the average impact that the
removal a contributor from the system would have on a random
observed download of a library in the Rust ecosystem.

Overall ecosystem risk: We derive global measure G
of the systemic risk of the ecosystem by summing up all
contributor impact scores:

G =

(cid:88)

Ij.

j

This quantity can be used to compare the change in overall
risk due to some intervention, as we will implement later in
the paper. It also provides a baseline which we use to deﬁne
library importance.

Ranking Libraries: Finally, we also derive a measure
ranking the systemic importance of libraries. This is perhaps
the most important ranking, as interventions can most easily
be made at the level of libraries. Speciﬁcally, we consider
how often a library serves as a conduit of spreading failure to
downstream dependencies.

We do this by rerunning the full set of developer removals
and failure propagation calculations with each library “im-
munized” to failure, one by one. In terms of our equation,
the immunized library’s entry in the library state vector SL is
hard-coded to 1. This counterfactual allows us to quantify how
a library ampliﬁes or transmits issues through the software
dependency network. The change in the overall ecosystem risk
score G when a library is protected in this way serves as a
quantiﬁcation of its contribution to overall risk. We deﬁne this
measure, which we call the Risk Transmission Score of a
library i, as follows:

RT Si = G − Gi,

where Gi denotes the ecosystem risk score calculated when

library i is immune to failure.

Results

We plot the rank-ordered distribution of Contributor Impact
in Figure 4. We observe a remarkable concentration of sys-
temic risk: with the top 10 contributors accounting for over
a 40% of the risk observed in our analyses. We observe a
similar, though slightly less concentrated distribution when we
consider the importance of different libraries in terms of their
Risk Transmission Score. This recalls our motivating example
from earlier in the paper: individual developers are playing an
important role in multiple important libraries.

To compare our method of ranking important

libraries
with alternative measures, for example by the count of their
transitive dependencies, we zoom in on the very top ranked

110100100010000Contributor Rank0.000.020.040.060.080.100.12Contributor ImpactImpact Summed over Top 10: 43%8

Fig. 5. The Risk Transmission Rank (RTR) importance of Rust libraries,
on a logarithmic scale. We quantify a library’s importance by rerunning our
failure cascade model with that library immunized against failure, and then
comparing the overall outcome against the general case when the library can
fail. The top 10 libraries account for 22% of the total observed differences
across all libraries.

libraries. We plot libraries ranked among the top 20 according
to Risk Transmission Rank or by the count of their transitive
dependencies in Figure 6. Our method suggests that libraries
above the diagonal are more important than a count of their
downstream dependencies suggests. Our method highlights
several libraries (“rand” and “syn”, among others) that are
among the top 10 libraries according to Risk Transmission
Rank, but do not break into the top 100 libraries by number
of transitive dependencies. These libraries have a prominent
position in the network topology that amplify their contribution
to systemic risk.

V. INTERVENTIONS

While it is valuable to highlight vulnerabilities in a system,
our methodology can be used to suggest how to intervene
in the system to improve its resilience by allocating scarce
development resources. In particular, our ranking of libraries
in the Rust ecosystem can be used to allocate support. For
instance, a foundation or ﬁrm may have funds to sponsor
development or maintenance on a speciﬁc library. Though
in reality developer resources are not fungible and cannot be
allocated to any library in arbitrary amounts, a prioritization in
terms of risk remains useful. Thus in this section we describe
an intervention in terms of development time contributed to a
ﬁxed number of libraries. We compare the impact on systemic
risk of various allocation strategies based on rankings of
libraries, including our Risk Transmission Rank score. We ﬁrst
describe alternative rankings, then describe how we implement
the interventions, and ﬁnally report results.

A. Rankings

As our aim is to compare reasonable strategies to allocate
development resources across libraries, we consider several

Fig. 6. Libraries of the Rust ecosytem in the top 20 according to either
their Risk Transmission Rank (RTR) or the count of (downstream) transitive
dependencies. We observe several libraries in the top 10 of the RTR, hence
likely of systemic importance, that are not even in the top 100 according to
the number of transitive dependencies they have.

Name

Description

Transitive Dependencies
Downloads
Age
Stars
Random
Risk Transmission Rank

Count of upstream dependencies
Number of downloads on Cargo
Time of ﬁrst appearance on Cargo
Number of stars on GitHub
Random allocation (baseline)
Spreading-based measure

TABLE I
WAYS TO RANK LIBRARIES IN THE RUST ECOSYSTEM TO ALLOCATE
DEVELOPER RESOURCES IN AN INTERVENTION.

perspectives on what makes a library important or well-known.
We consider a library’s place in the dependency network, its
overall use, its age, its popularity, and its systemic importance
as quantiﬁed by our Risk Transmission Rank. We also test
random allocations as a benchmark. We summarize these
rankings in Table I, and describe them below.

In a technical sense, a library is important in an ecosystem if
many other libraries depend on it. These dependencies can be
direct or indirect (sometimes called transitive). We therefore
use the count of transitive dependencies as one ranking of
libraries [1]. A simpler way to rank libraries is by their age,
arguing that older (active) libraries are more likely to be
important.

In practice,

libraries are often ranked by their use and
popularity in the broader community. We measure use via the
count of downloads of a Rust library, as tracked by Cargo.
Popularity or social visibility is measured by counting the
number of stars a library has received on GitHub [56]. Both

110100100010000Library Rank0.000.010.020.030.04Risk Transmission ScoreImpact Summed over Top 10: 22%1101001000Risk Transmission Rank1101001000Transitive Dependencies Ranklibccfg-ifwinapi-rsnum-traitsbitflagslazy-static.rsnum-integermemchrlogregexmemoffsetmachminimal-lexicalnomnum-complexwasirust-smallvecchrononum-rationalparking_lotproc-macro2crossbeamquoterandtokiosynsemver-parsersemvertracingutilsserdefutures-rspin-projectfactors are thought to play an important role in the success of
open source software. A large active user base of a speciﬁc
library provides a kind of defense against errors as suggested
by Raymond’s notion that “with many eyes all bugs are
shallow” [34]. The launch of GitHub Sponsors and growing
adoption of crowdfunding to support OSS maintainers suggests
that highly visible libraries will be even more likely receive
resources [10]. However we know from examples that not all
systemically importance packages are highly visible. Anecdo-
tally, OpenSSL was taken for granted before the discovery of
the Heartbleed vulnerability.

B. Intervention Design and Quantifying Impact

While software developers and software development time
is not a fungible resource, we make the simplifying assumption
that a donor can contribute to a library by adding a single
developer. Developers added this way make a uniform weekly
contribution of commits, which we ﬁx at 5/7 times the number
of days across which we analyze the system (in our case 365,
covering all of 2021). We denote this contribution factor (5/7
times 365) by e. This simpliﬁcation suggests that allocated
developers make roughly one contribution per weekday. In our
framework this level of contribution can be tuned. In any case,
we add a single developer to the top K libraries according to
each ranking for a range of values between 1 and 1000.

After allocation we rerun our framework - one by one
we remove each developer in the system and calculate the
resulting cascades. We calculate G, the overall systemic risk
of the ecosystem in each of these scenarios, comparing it
the original estimate derived in the previous section. As
more contributors are added, the overall systemic risk falls.
Comparing which ranking method decreases risk how much
and how quickly across a range of values will tell us about
the effectiveness of interventions.

There is one modiﬁcation we need to make to the method-
ology in this case. Speciﬁcally, if we are adding contributions
to a library as part of an intervention, we should not simulate
what happens if these new resources are withdrawn. Rather,
we represent these extra contributions as a kind of surplus or
overproduction (c.f. [36]) that can be used to absorb shocks.
Speciﬁcally, we add a term X to our self-referencing equation
for the library state vector:

SL = (SC(cid:124)

(cid:63) ˆC)1/2 (cid:12) (SL(cid:124)

(cid:63) ˆD + X)1/2.

Here X is a vector corresponding to the libraries of the
ecosystem. An entry i is equal to e/N , where N is the total
number of commits to library i, if library i is allocated a
developer, 0 otherwise. Recall that e captures the contributions
of these allocated developers, estimated at a rate of one commit
per week day. This correction insures that additional resources
allocated by the intervention can only help a library. In each
round of the calculation, we cap entries of the library state
vector SL at 1 to insure convergence.

C. Intervention Results

We visualize the improvement in systemic risk as a func-
tion of developers added according to the different ranking

9

Fig. 7. The change in overall systemic risk as a function of developers added
by various library ranking heuristics, ranging from adding one contributor to
100 (log scale).

Fig. 8. Extending the previous ﬁgure to scenarios adding between 100 and
1000 developers to the ecosystem.

heuristics in Figures 7 and 8. We observe a sharp decrease in
overall risk using the Risk Transmission Rank, the number
of downloads, or the number of transitive dependencies to
rank libraries. Using GitHub stars, library age, or a random
ranking to allocate development resources are signiﬁcantly
less effective strategies. Given that GitHub stars are a major
source of visibility in the OSS community [56], we suggest
that equating systemic importance with stars may be leading
to systemic mis-allocation of attention and help.

To quantify the relative performance of these rankings, we

110100Developers Added0.00.10.20.30.40.50.60.70.8Overall Systemic RiskRisk Transmission RankRandomDownloadsGitHub StarsAgeTransitive Dependencies1101001000Developers Added0.00.10.20.30.40.50.60.70.8Overall Systemic RiskRisk Transmission RankRandomDownloadsGitHub StarsAgeTransitive DependenciesDevelopers Added:

1

2

5

10

20

50

100

250

500

1000

10

Intervention
Risk Transmission Rank
Downloads
Transitive Dependencies
GitHub Stars
Age
Random

6.5%

2.4% 4.7% 9.5% 14.8% 21.9% 34.3% 45.3% 62.9% 75.4% 84.9%
1.0% 1.9% 4.0%
14.5% 30.8% 43.7% 61.8% 74.0% 83.4%
1.1% 2.9% 7.7% 11.2% 14.4% 20.7% 28.0% 37.5% 48.6% 66.3%
14.0% 26.2%
0.0% 0.0% 0.0%
15.7%
9.4%
0.0% 0.1% 0.5%
0.5%
0.2%
0.0% 0.0% 0.0%

0.2%
1.0%
0.0%

1.0%
2.1%
0.1%

2.0%
3.6%
0.1%

0.1%
0.8%
0.0%

6.3%
5.7%
0.1%

TABLE II
CUMULATIVE REDUCTION OF SYSTEMIC RISK WHEN ADDING DEVELOPERS ACCORDING TO DIFFERENT INTERVENTION STRATEGIES, RELATIVE TO THE
BASELINE SYSTEMIC RISK. WHETHER ADDING JUST A FEW OR MANY DEVELOPERS, ADDING THEM TO HIGH RTR RANKED LIBRARIES YIELDS THE
GREATEST DECREASE IN SYSTEMIC RISK.

calculate the area below the horizontal line at the baseline
systemic risk level and above the curve for each heuristic
up to different numbers of developers added, and normalize
by the total area under the baseline. We report these values
in Table II. These results verify the patterns we observe in
the ﬁgures: allocating developers by RTR, downloads, and
transitive dependencies are better strategies than allocating
them by age or visibility (i.e. stars on GitHub). Though RTR
performs best across the entire range of the intervention, it is
still interesting to note that ranking libraries by transitive de-
pendencies and downloads are also relatively strong heuristics.
As these require less data and calculation, they may be good
strategies in other ecosystems with less available data.

VI. DISCUSSION
OSS ecosystems tend to evolve, like many complex systems,
towards efﬁciency. If there is a library that does something
well, it can quickly become widely used. However, this drive
towards efﬁciency may increase systemic risks. Studies of risk
in ecosystems that focus on the structure of technical de-
pendencies overlook the potential synchronized risks coming
from developers active in multiple libraries. In this work we
presented a framework to quantify these risks. Our method
highlights individual libraries which are worthy of more atten-
tion and support. As the most central and important developers
in OSS ecosystems are under increasing pressure and stress
[2], measures of ecosystem health need to consider the interac-
tion of these social aspects with their technical structure [57].
Within individual libraries or projects, the importance of socio-
technical congruence - that is the coordination between people
working on interdependent modules - is well known [58]; our
paper suggests how such congruence at the ecosystem level
could provide warnings and help maintainers of downstream
libraries anticipate upstream issues. More generally, our work
contributes to a growing literature on the sustainability and
resilience of key software supply chains [5], [59], [60].

Our framework has several potential extensions. The most
natural one is to generalize the approach to other ecosystems
[61], as done for the analysis of dependency networks in Decan
et al. [1]. Given that dependency networks are known to be
growing in several ecosystems, and that the truck factor of
key libraries in multiple ecosystems are known to be low, we
are conﬁdent that the application of our framework to other
systems will yield a similarly useful diagnosis of points of
vulnerability. We chose to focus on Rust given that temporal

data on downloads of individuals is available, and that a
signiﬁcant majority of libraries are available on GitHub. This
suggests a threat to generalizability: many package ecosystems
do not disclose data on downloads. Here we note that our
approach can be adapted to such cases by simply equalizing
download weights across all libraries, or using some other
measure of or proxy for use as a substitute. It is also possible
to deﬁne dependencies, and subsequently ecosystems, via
references in code [62]. The general idea of our work can
be applied to other contexts in the software industry in which
people reuse and share code, for instance the case of Docker
images [63].

Another potential threat to validity and point to improve
is that we only use commits to determine contributors. While
commits are needed to adapt to issues and bugs from upstream
dependencies, they are not the only way to help an open source
project, and a more complete accounting of contributions
would include work on issues and community management
[49]. Even among commit activity, future work could go into
greater depth by inferring which developers are maintaining
which parts of a library [64]. However, in general it is difﬁcult
to estimate which contributors are most essential
to open
source projects [65], and perhaps even more difﬁcult to know
which developers can take over for particular colleagues. We
can also test what happens to libraries downstream from
abandoned libraries [66],
to validate whether focusing on
commits is appropriate.

Another simplifying assumption of our work is that the
libraries we observe are functioning and maintained, however
many developers they have. This is often false, as shown by
Champion and Mako Hill in their recent work on the Debian
package ecosystem [36]. They introduce the the notion of
underproduction and quantify it by tracking issue survival
rates. One could extend our model by adapting this measure.
Our framework can also be adapted to analyze the con-
sequences of multiple developers leaving an ecosystem at
the same time. This is not a hypothetical scenario - the
increased reliance on centralized sponsors of libraries and even
ecosystems presents another kind of risk. For example, many
of the core developers of the Rust ecosystem were employed
by Mozilla. In a round of layoffs in the summer of 2020, many
of these developers lost their jobs at the same time. While Rust
seems to have weathered this storm, it demonstrates that often
multiple developers leave a system at around the same time.
In general, people leave OSS projects for reasons that may

be correlated within an ecosystem, such as the end of funding
of a university project or changing workplaces [67]. Luis Villa
of Tidelift, a ﬁrm that helps users and ﬁrms support OSS with
ﬁnancial contributions, suggests that we should perhaps rather
talk of a “boss factor” than truck factor.2. Indeed, many of the
most widely used and inﬂuential OSS projects are maintained
by companies and paid individuals [68]. In this way, OSS
ecosystems can be thought of as a co-production of volunteers
and companies [69]. Policymakers seeking to promote the use
of OSS should consider these aspects of sustainability [70].

Our work provides additional motivation for getting more
people involved in OSS. Mentorship of new contributors has
been shown to be a key determinant of people becoming active
participants in ecosystems [71]. At the same time, our work
shows indirectly how social barriers to participation [72] make
software ecosystems more brittle in the long run. More work is
needed to understand how disparities in participation in open
source, for example owing to gender [73], [74] or geography
[75]–[77], block us from realizing more stable systems.

ACKNOWLEDGEMENTS

The authors thank Christian Diem, Tobias Reisch, Hannah
Schuster, Balint Daroczy, Aleksandra Urman, Rositsa Ivanova,
and participants of seminars at the Complexity Science Hub
Vienna and WU Wien for valuable feedback.

REFERENCES

[1] A. Decan, T. Mens, and P. Grosjean, “An empirical comparison of
dependency network evolution in seven software packaging ecosystems,”
Empirical Software Engineering, vol. 24, no. 1, pp. 381–416, 2019.
[2] N. Eghbal, Working in Public: The Making and Maintenance of Open

Source Software. Stripe Press, 2020.

[3] G. Avelino, L. Passos, A. Hora, and M. T. Valente, “A novel approach for
estimating truck factors,” in 2016 IEEE 24th International Conference
on Program Comprehension (ICPC).

IEEE, 2016, pp. 1–10.

[4] A. Decan, T. Mens, and E. Constantinou, “On the impact of security
vulnerabilities in the npm package dependency network,” in Proceedings
of the 15th International Conference on Mining Software Repositories,
2018, pp. 181–191.

[5] M. Ohm, H. Plate, A. Sykosch, and M. Meier, “Backstabber’s knife
collection: A review of open source software supply chain attacks,” in
International Conference on Detection of Intrusions and Malware, and
Vulnerability Assessment. Springer, 2020, pp. 23–43.

[6] H. S. Qiu, A. Nolte, A. Brown, A. Serebrenik, and B. Vasilescu, “Going
farther together: The impact of social capital on sustained participation
in open source,” in 2019 IEEE/ACM 41st International Conference on
Software Engineering (ICSE).

IEEE, 2019, pp. 688–699.

[7] M. Valiev, B. Vasilescu, and J. Herbsleb, “Ecosystem-level determinants
of sustained activity in open-source projects: A case study of the pypi
ecosystem,” in Proceedings of the 2018 26th ACM Joint Meeting on
European Software Engineering Conference and Symposium on the
Foundations of Software Engineering, 2018, pp. 644–655.

[8] R.-H. Pfeiffer, “Identifying critical projects via pagerank and truck
factor,” in 2021 IEEE/ACM 18th International Conference on Mining
Software Repositories (MSR).

IEEE, 2021, pp. 41–45.

[9] S. Spaeth, G. von Krogh, and F. He, “Research note—perceived ﬁrm
attributes and intrinsic motivation in sponsored open source software
projects,” Information Systems Research, vol. 26, no. 1, pp. 224–237,
2015.

[10] C. Overney, J. Meinicke, C. K¨astner, and B. Vasilescu, “How to not get
rich: An empirical study of donations in open source,” in Proceedings of
the ACM/IEEE 42nd International Conference on Software Engineering,
2020, pp. 1209–1221.

2See: https://blog.tidelift.com/bus-factor-boss-factor-and-the-economics-of-

disappearing-maintainers

11

[11] A. G. Haldane and R. M. May, “Systemic risk in banking ecosystems,”

Nature, vol. 469, no. 7330, pp. 351–355, 2011.

[12] S. Thurner and S. Poledna, “Debtrank-transparency: Controlling sys-
temic risk in ﬁnancial networks,” Scientiﬁc reports, vol. 3, no. 1, pp.
1–7, 2013.

[13] C. Diem, A. Borsos, T. Reisch, J. Kert´esz, and S. Thurner, “Quantifying
ﬁrm-level economic systemic risk from nation-wide supply networks,”
Available at SSRN 3826514, 2021.

[14] R. Kinney, P. Crucitti, R. Albert, and V. Latora, “Modeling cascading
failures in the north american power grid,” The European Physical
Journal B-Condensed Matter and Complex Systems, vol. 46, no. 1, pp.
101–107, 2005.

[15] G. T´oth, Z. Elekes, A. Whittle, C. Lee, and D. F. Kogler, “Technol-
ogy network structure conditions the economic resilience of regions,”
Economic Geography, 2022.

[16] D. R. L. Sardo, S. Thurner, J. Sorger, G. Duftschmid, G. Endel, and
P. Klimek, “Quantiﬁcation of the resilience of primary care networks
by stress testing the health care system,” Proceedings of the National
Academy of Sciences, vol. 116, no. 48, pp. 23 930–23 935, 2019.
[17] C. M. Schneider, N. Yazdani, N. A. Ara´ujo, S. Havlin, and H. J.
Herrmann, “Towards designing robust coupled networks,” Scientiﬁc
reports, vol. 3, no. 1, pp. 1–7, 2013.

[18] S. Poledna, J. L. Molina-Borboa, S. Mart´ınez-Jaramillo, M. Van
Der Leij, and S. Thurner, “The multi-layer network nature of systemic
risk and its implications for the costs of ﬁnancial crises,” Journal of
Financial Stability, vol. 20, pp. 70–81, 2015.

[19] T. Mens and P. Grosjean, “The ecology of software ecosystems,”

Computer, vol. 48, no. 10, pp. 85–87, 2015.

[20] K. Peters, L. Buzna, and D. Helbing, “Modelling of cascading effects
and efﬁcient response to disaster spreading in complex networks,”
International Journal of Critical Infrastructures, vol. 4, no. 1-2, pp.
46–62, 2008.

[21] J. Hejderup, A. van Deursen, and G. Gousios, “Software ecosystem
call graph for dependency management,” in 2018 IEEE/ACM 40th
International Conference on Software Engineering: New Ideas and
Emerging Technologies Results (ICSE-NIER).
IEEE, 2018, pp. 101–
104.

[22] Z. Durumeric, F. Li, J. Kasten, J. Amann, J. Beekman, M. Payer,
N. Weaver, D. Adrian, V. Paxson, M. Bailey et al., “The matter
of heartbleed,” in Proceedings of
the 2014 conference on internet
measurement conference, 2014, pp. 475–488.

[23] J. Luszcz, “Apache struts 2: how technical and development gaps caused
the equifax breach,” Network Security, vol. 2018, no. 1, pp. 5–8, 2018.

[24] L. H. Newman, “The internet is on ﬁre,” Wire Magazine, 2021.
[25] A. Birsan, “Dependency confusion: How i hacked into apple, microsoft

and dozens of other companies,” Medium, 2021.

[26] A. Zerouali, T. Mens, A. Decan, and C. De Roover, “On the impact of
security vulnerabilities in the npm and rubygems dependency networks,”
arXiv preprint arXiv:2106.06747, 2021.

[27] I. Pashchenko, H. Plate, S. E. Ponta, A. Sabetta, and F. Massacci,
“Vulnerable open source dependencies: Counting those that matter,”
in Proceedings of the 12th ACM/IEEE International Symposium on
Empirical Software Engineering and Measurement, 2018, pp. 1–10.
[28] M. Alfadel, D. E. Costa, and E. Shihab, “Empirical analysis of security
vulnerabilities in python packages,” in 2021 IEEE International Con-
ference on Software Analysis, Evolution and Reengineering (SANER).
IEEE, 2021, pp. 446–457.

[29] A. Decan, T. Mens, A. Zerouali, and C. De Roover, “Back to the past–
analysing backporting practices in package dependency networks,” IEEE
Transactions on Software Engineering, 2021.

[30] Y. Ma, “Constructing supply chains in open source software,” in 2018
IEEE/ACM 40th International Conference on Software Engineering:
Companion (ICSE-Companion).

IEEE, 2018, pp. 458–459.

[31] S. Amreen, B. Bichescu, R. Bradley, T. Dey, Y. Ma, A. Mockus,
S. Mousavi, and R. Zaretzki, “A methodology for measuring ﬂoss
ecosystems,” in Towards Engineering Free/Libre Open Source Software
(FLOSS) Ecosystems for Impact and Sustainability. Springer, 2019, pp.
1–29.

[32] R. Abdalkareem, O. Nourry, S. Wehaibi, S. Mujahid, and E. Shihab,
“Why do developers use trivial packages? an empirical case study on
npm,” in Proceedings of the 2017 11th joint meeting on foundations of
software engineering, 2017, pp. 385–395.

[33] M. A. R. Chowdhury, R. Abdalkareem, E. Shihab, and B. Adams, “On
the untriviality of trivial packages: An empirical study of npm javascript
packages,” IEEE Transactions on Software Engineering, 2021.

[34] E. Raymond, “The cathedral and the bazaar,” Knowledge, Technology &

Policy, vol. 12, no. 3, pp. 23–49, 1999.

[35] Y. Benkler, A. Shaw, and B. M. Hill, “Peer production: A form of
collective intelligence,” Handbook of collective intelligence, vol. 175,
2015.

[36] K. Champion and B. M. Hill, “Underproduction: An approach for mea-
suring risk in open source software,” in 2021 IEEE International Con-
ference on Software Analysis, Evolution and Reengineering (SANER).
IEEE, 2021, pp. 388–399.

[37] L. Williams and R. R. Kessler, Pair programming illuminated. Addison-

Wesley Professional, 2003.

[38] M. Torchiano, F. Ricca, and A. Marchetto, “Is my project’s truck
factor low? theoretical and empirical considerations about the truck
factor threshold,” in Proceedings of the 2Nd International Workshop
on Emerging Trends in Software Metrics, 2011, pp. 12–18.

[39] M. Ferreira, T. Mombach, M. T. Valente, and K. Ferreira, “Algorithms
for estimating truck factors: a comparative study,” Software Quality
Journal, vol. 27, no. 4, pp. 1583–1617, 2019.

[40] J. Coelho and M. T. Valente, “Why modern open source projects fail,” in
Proceedings of the 2017 11th Joint Meeting on Foundations of Software
Engineering, 2017, pp. 186–196.

[41] M. M. Lehman, “Programs, life cycles, and laws of software evolution,”

Proceedings of the IEEE, vol. 68, no. 9, pp. 1060–1076, 1980.

[42] R. I. Cook, “Above the line, below the line,” Communications of the

ACM, vol. 63, no. 3, pp. 43–46, 2020.

[43] F. R. Cogo, G. A. Oliva, and A. E. Hassan, “Deprecation of packages
and releases in software ecosystems: A case study on npm,” IEEE
Transactions on Software Engineering, 2021.

[44] J. D. Herbsleb and R. E. Grinter, “Splitting the organization and
integrating the code: Conway’s law revisited,” in Proceedings of the 21st
international conference on Software engineering, 1999, pp. 85–95.
[45] M. Cataldo and J. D. Herbsleb, “Coordination breakdowns and their
impact on development productivity and software failures,” IEEE Trans-
actions on Software Engineering, vol. 39, no. 3, pp. 343–360, 2012.

[46] B. Vasilescu, K. Blincoe, Q. Xuan, C. Casalnuovo, D. Damian, P. De-
vanbu, and V. Filkov, “The sky is not the limit: multitasking across
GitHub projects,” in Proceedings of the 38th International Conference
on Software Engineering, 2016, pp. 994–1005.

[47] W. Schueller, J. Wachs, V. D. P. Servedio, S. Thurner, and V. Loreto,
“Evolving collaboration, dependencies, and use in the rust open source
software ecosystem,” arXiv preprint, 2022.

[48] Y. Wang, M. Wen, Y. Liu, Y. Wang, Z. Li, C. Wang, H. Yu, S.-
C. Cheung, C. Xu, and Z. Zhu, “Watchman: Monitoring dependency
conﬂicts for python library ecosystem,” in Proceedings of the ACM/IEEE
42nd International Conference on Software Engineering, 2020, pp. 125–
135.

[49] B. Trinkenreich, M. Guizani, I. Wiese, A. Sarma, and I. Steinmacher,
“Hidden ﬁgures: Roles and pathways of successful OSS contributors,”
Proceedings of the ACM on Human-Computer Interaction, vol. 4, no.
CSCW2, pp. 1–22, 2020.

[50] J. E. Montandon, L. L. Silva, and M. T. Valente, “Identifying experts
in software libraries and frameworks among GitHub users,” in 2019
IEEE/ACM 16th International Conference on Mining Software Reposi-
tories (MSR).

IEEE, 2019, pp. 276–287.

[51] T. Fry, T. Dey, A. Karnauch, and A. Mockus, “A dataset and an approach
for identity resolution of 38 million author ids extracted from 2b git
commits,” in Proceedings of the 17th international conference on mining
software repositories, 2020, pp. 518–522.

[52] M. Golzadeh, A. Decan, D. Legay, and T. Mens, “A ground-truth dataset
and classiﬁcation model for detecting bots in GitHub issue and PR
comments,” Journal of Systems and Software, vol. 175, p. 110911, 2021.
[53] A. Mockus, R. T. Fielding, and J. D. Herbsleb, “Two case studies of open
source software development: Apache and mozilla,” ACM Transactions
on Software Engineering and Methodology (TOSEM), vol. 11, no. 3, pp.
309–346, 2002.

[54] G. Robles, J. M. Gonzalez-Barahona, and I. Herraiz, “Evolution of
the core team of developers in libre software projects,” in 2009 6th
IEEE international working conference on mining software repositories.
IEEE, 2009, pp. 167–170.

[55] E. P. Brown, “The meaning of the ﬁtted cobb-douglas function,” The

Quarterly Journal of Economics, vol. 71, no. 4, pp. 546–560, 1957.

[56] H. Borges and M. T. Valente, “What’s in a GitHub star? understanding
repository starring practices in a social coding platform,” Journal of
Systems and Software, vol. 146, pp. 112–129, 2018.

[57] E. Constantinou and T. Mens, “Socio-technical evolution of the Ruby
ecosystem in GitHub,” in 2017 IEEE 24th International Conference on
Software Analysis, Evolution and Reengineering (SANER).
IEEE, 2017,
pp. 34–44.

12

[58] M. Cataldo, J. D. Herbsleb, and K. M. Carley, “Socio-technical con-
gruence: a framework for assessing the impact of technical and work
dependencies on software development productivity,” in Proceedings of
the Second ACM-IEEE international symposium on Empirical software
engineering and measurement, 2008, pp. 2–11.

[59] M. Zimmermann, C.-A. Staicu, C. Tenny, and M. Pradel, “Small world
with high risks: A study of security threats in the npm ecosystem,”
in 28th USENIX Security Symposium (USENIX Security 19), 2019, pp.
995–1010.

[60] C. Lamb and S. Zacchiroli, “Reproducible builds: Increasing the in-

tegrity of software supply chains,” IEEE Software, 2021.

[61] O. Franco-Bedoya, D. Ameller, D. Costal, and X. Franch, “Open source
software ecosystems: A systematic mapping,” Information and software
technology, vol. 91, pp. 160–185, 2017.

[62] K. Blincoe, F. Harrison, and D. Damian, “Ecosystems in GitHub and a
method for ecosystem identiﬁcation using reference coupling,” in 2015
IEEE/ACM 12th Working Conference on Mining Software Repositories.
IEEE, 2015, pp. 202–211.

[63] J. Cito, G. Schermann, J. E. Wittern, P. Leitner, S. Zumberi, and H. C.
Gall, “An empirical analysis of the Docker container ecosystem on
GitHub,” in 2017 IEEE/ACM 14th International Conference on Mining
Software Repositories (MSR).

IEEE, 2017, pp. 323–333.

[64] C. Gote, I. Scholtes, and F. Schweitzer, “Analysing time-stamped co-
editing networks in software development teams using git2net,” Empir-
ical Software Engineering, vol. 26, no. 4, pp. 1–41, 2021.

[65] A. Casari, K. McLaughlin, M. Z. Trujillo, J.-G. Young, J. P. Bagrow,
and L. H´ebert-Dufresne, “Open source ecosystems need equitable credit
across contributions,” Nature Computational Science, vol. 1, no. 1, pp.
2–2, 2021.

[66] G. Avelino, E. Constantinou, M. T. Valente, and A. Serebrenik, “On
the abandonment and survival of open source projects: An empirical
investigation,” in 2019 ACM/IEEE International Symposium on Empiri-
cal Software Engineering and Measurement (ESEM).
IEEE, 2019, pp.
1–12.

[67] C. Miller, D. G. Widder, C. K¨astner, and B. Vasilescu, “Why do people
give up ﬂossing? a study of contributor disengagement in open source,”
in IFIP International Conference on Open Source Systems. Springer,
2019, pp. 116–129.

[68] M. Germonprez, J. Lipps, and S. Goggins, “The rising tide: Open

source’s steady transformation,” First Monday, 2019.

[69] M. O’Neil, L. Muselli, M. Raissi, and S. Zacchiroli, “‘Open source has
won and lost the war’: Legitimising commercial–communal hybridis-
ation in a FOSS project,” New Media & Society, vol. 23, no. 5, pp.
1157–1180, 2021.

[70] K. Blind, M. B¨ohm, P. Grzegorzewska, A. Katz, S. Muto, S. P¨atsch,
and T. Schubert, “The impact of open source software and hardware on
technological independence, competitiveness and innovation in the eu
economy,” 2021.

[71] I. Steinmacher, S. Balali, B. Trinkenreich, M. Guizani, D. Izquierdo-
Cortazar, G. G. Cuevas Zambrano, M. A. Gerosa, and A. Sarma, “Being
a mentor in open source projects,” Journal of Internet Services and
Applications, vol. 12, no. 1, pp. 1–33, 2021.

[72] I. Steinmacher, T. Conte, M. A. Gerosa, and D. Redmiles, “Social
barriers faced by newcomers placing their ﬁrst contribution in open
source software projects,” in Proceedings of the 18th ACM conference
on Computer supported cooperative work & social computing, 2015,
pp. 1379–1392.

[73] J. Terrell, A. Koﬁnk, J. Middleton, C. Rainear, E. Murphy-Hill,
C. Parnin, and J. Stallings, “Gender differences and bias in open source:
Pull request acceptance of women versus men,” PeerJ Computer Science,
vol. 3, p. e111, 2017.

[74] B. Vasilescu, A. Capiluppi, and A. Serebrenik, “Gender, representation
and online participation: A quantitative study,” Interacting with Com-
puters, vol. 26, no. 5, pp. 488–511, 2014.

[75] Y. Takhteyev, Coding places: Software practice in a South American

city. MIT Press, 2012.

[76] F. Braesemann, N. Stoehr, and M. Graham, “Global networks in collab-
orative programming,” Regional Studies, Regional Science, vol. 6, no. 1,
pp. 371–373, 2019.

[77] J. Wachs, M. Nitecki, W. Schueller, and A. Polleres, “The geography of
open source software: Evidence from github,” Technological Forecasting
and Social Change, vol. 176, p. 121478, 2022.

