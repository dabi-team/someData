2
2
0
2

r
a

M
9
2

]
E
S
.
s
c
[

1
v
4
5
2
5
1
.
3
0
2
2
:
v
i
X
r
a

Constructing Effective Customer Feedback Systems –
A Design Science Study Leveraging Blockchain Technology

Mark C. Ballandies1∗, Valentin Holzwarth2, Barry Sunderland3, Evangelos Pournaras4 and
Jan vom Brocke2

1Computational Social Science, ETH Zurich,
Stampfenbachplatz 50, Zurich, Switzerland
2Hilti Chair of Business Process Management, University of Liechtenstein, Liechtenstein
3ETH Library Lab, ETH Zurich
4School of Computing, University of Leeds

∗To whom correspondence should be addressed; E-mail: bcmark@protonmail.com.

Organizations have to adjust to changes in the ecosystem, and customer feedback sys-

tems (CFS) provide important information to adapt products and services to chang-

ing customer preferences. However, current systems are limited to single-dimensional

rating scales and are subject to self-selection biases. This work contributes design

principles for CFS and implements a CFS that advances current systems by means

of contextualized feedback according to speciﬁc organizational objectives. It also uses

blockchain-based incentives to support CFS use. We apply Design Science Research

(DSR) methodology and report on a longitudinal DSR journey considering multiple

stakeholder values. We conducted expert interviews, design workshops, demonstra-

tions, and a four-day experiment in an organizational setup, involving 132 customers

of a major Swiss library. This validates the identiﬁed design principles and the imple-

mented software artifact both qualitatively and quantitatively. Based on this evalua-

tion, the design principles are revisited and conclusions for the construction of success-

ful CFS are drawn. The ﬁndings of this work advance the knowledge on the design of

CFS and provide a guideline to managers and decision makers for designing effective

CFS.

Keywords - Design Science Research; Blockchain; Feedback Systems; Cryptoeconomics;

value-sensitive Design; Token Engineering

1

 
 
 
 
 
 
Acknowledgements: The research team thanks Benjamin A. Degenhart and Kevin Pluut for their input and the ETH

Library Lab for their support.

1 Introduction

Customer feedback is important for the potential of an organization to differentiate itself from competi-

tors (Culnan, 1989) and to improve its products and services according to customer preferences (H.-

H. Hu, Parsa, Chen, & Hu, 2016; Stoica & Özyirmidokuz, 2015). Nevertheless, due to status differences,

hierarchy steepness, and reduced levels of cooperation, large hierarchical organizations such as ﬁrms or

public institutions impede the ﬂow of feedback to and within their organization (Anderson & Brown,

2010), which reduces the quality of management decisions (Khatri, 2009).

Inspired by the observation that technology can be utilized to support the self-organization capacity

and thus the efﬁciency of a large scale system, such as a trafﬁc light control network (Lämmer & Helbing,

2008), this work generates design knowledge on the construction of a customer feedback system (CFS)

that improves the provision of high-quality feedback about services and products from customers to an

organization.

We report on Design Science Research at a case organization, which is a major Swiss library. This

library is challenged by a lack of feedback from so-called unaware-customers, i.e. customers that are not

aware that they are using services provided by the organization. Moreover, the library is challenged to

distinguish important from unimportant feedback, particularly, when the feedback quantity is high. Fur-

thermore, the library has difﬁculties evaluating the questions utilized in solicited surveys with customers.

The innovation & networking team within the library organization had been mandated to implement a

solution in the form of a CFS that improves the status quo of feedback provision from library users to the

organization. We identiﬁed this need of the library in the ﬁrst step of the applied research methodology

(Section 3) and consecutively accompanied the construction of the CFS.

We argue that a CFS should not only optimize for performance, but its design also needs to integrate

the values of stakeholders (Kleineberg & Helbing, 2021; Van den Hoven, Vermaas, & Van de Poel,

2015) such as autonomy or credibility. This has been recognized by the IS community (Friedman, Kahn,

Borning, & Huldtgren, 2013; Maedche, 2017). Though already utilized in similar systems (Friedman,

Howe, & Felten, 2002; Miller, Friedman, Jancke, & Gill, 2007), value considerations in the methods of

CFS construction and thus the resulting design knowledge is limited. In particular, to our best knowledge,

2

design principles for CFS that explicitly consider values have not been found. We therefore ask the ﬁrst

Research Question (RQ1):

(RQ1) What are the design principles of a value-sensitive customer feedback system?

By applying an established design science research (DSR) methodology (A. R. Hevner, March, Park,

& Ram, 2004; Peffers, Tuunanen, Rothenberger, & Chatterjee, 2007; Sonnenberg & Brocke, 2011; Son-

nenberg & Vom Brocke, 2012) and putting a focus on stakeholder values during the design phase as per-

formed in Ballandies, Dapp, Degenhart, and Helbing (2021), we facilitate both, i) the value-alignment

of the created tool with the affected stakeholders and ii) the implementation of the design principles in

a software artifact, which is iteratively evaluated at different stages. A controlled experiment with 132

customers of the library and focus groups with experts of that organization are conducted to measure the

performance of the software artifact. In order to evaluate the performance, we ask the second Research

Question (RQ2):

RQ2: What is the performance of a software artifact that implements the design principles with

regard to usability and quality of collected feedback?

This paper illustrates how design science as a journey can be conducted (Vom Brocke, Winter,

Hevner, & Maedche, 2020) and contributes the following: I) challenges, risks, values, and best practices

in feedback provision to and within an organisation are elicited from expert interviews with employees

of two major organisations (>150 employees), including the directors of these institutions, II) design

principles for a value-sensitive customer feedback system are identiﬁed utilizing an established DSR

methodology that includes the identiﬁcation of stakeholders, the association of values with these stake-

holders, and the elicitation of design requirements based on these values, III) a feedback system design

is introduced that utilizes distributed ledger technologies (DLT), cryptoeconomic incentives and contex-

tualized solicited and unsolicited feedback to facilitate high-quality feedback ﬂows from customers to

an organization, IV) a software artifact is constructed that instantiates the feedback system design by

following the design principles: Users are incentivized with two types of blockchain-based tokens to

provide solicited feedback in the form of answers to survey-type questions (e.g., Are you using Ser-

vice X?) and to contextualize each of their responses with further information, such as the importance

of the question to improve the service of the organisation, their satisfaction with the answer options,

and open comments. Moreover, users can provide unsolicited feedback to the organization in an open

3

question forum, similar to the popular web platforms reddit1 and stack overﬂow2, which includes an

up- and down-voting mechanism that is fueled by collected tokens. Finally, users can investigate their

performance by querying the blockchain about their token balance and by comparing with other users

on a leaderboard. The artifact is evaluated by both i) crowdsourcing feedback in an ethics commission

approved four-day real-world experiment involving a major Swiss library and 132 of its customers, and

ii) conducting a focus group involving experts and executives from the library. The ﬁndings indicate that

the artifact improves the quality of customer feedback by increasing its breadth and depth while having a

good usability, as measured by customer interactions with the software artifact and self-reporting within

standardized questionnaires. Moreover, the organization’s experts and executives perceive the combina-

tion of solicited and unsolicited feedback and the contextualization of feedback as innovative, improving

the post-analysis of the collected feedback.

This paper is organized as follows: In Section 2, a literature review about CFS in organizations

is given. The DSR methodology that this paper follows is illustrated in Section 3, while the ﬁndings

and artifacts from applying this methodology are outlined in Section 4. Thereafter, Section 5 embeds

the ﬁndings as design knowledge chunks (Vom Brocke et al., 2020) into the broader research journey

and illustrates the ﬁnalized design principles for customer feedback systems. Finally, in Section 6 a

conclusion is drawn and an outlook on future work is given.

2 Research Background

Customer feedback is an important element of an organizations’ quality management (Chase & Hayes,

1991), as the perceived quality of services and products is related to market share and return on invest-

ment (Parasuraman, Zeithaml, & Berry, 1985). This is particularly relevant for service businesses (Chase

& Hayes, 1991) such as libraries (Casey & Savastinuk, 2006), since there is an increased emphasis on

service quality rather than on manufacturing quality (Vargo & Lusch, 2004). This importance is recog-

nized within the seminal work of Sampson (1999), who developed a framework for designing customer

feedback systems (CFS) to improve service quality. Furthermore, an overview of advantages and dis-

advantages of different feedback collection systems and their designs for improving service quality in

organizations have been illustrated by Wirtz and Tomlin (2000).

1Reddit is an American social news aggregation, web content rating, and discussion website: https://www.reddit.com/ (last

accessed 2021-12-10)

2Stack Overﬂow is a question and answer website for programmers: https://stackoverﬂow.com/ (last accessed 2021-12-10)

4

Usually, in these systems, customers provide feedback on services in the form of online reviews either

directly on the selling platform (e.g. rating a service booked on Fiverr3) or on speciﬁc review platforms

(e.g. providing travel reviews on Tripadvisor4) (Schneider, Weinmann, Mohr, & vom Brocke, 2021).

Although online ratings do not necessarily provide an objective measure of service quality (de Langhe,

Fernbach, & Lichtenstein, 2015), they are highly inﬂuential for customer-decision making, which is re-

ﬂected in sales and consequently in business success (Simonson, 2016). Customers’ online rating data

can even be utilized to predict service business failures months in advance as it has been shown for the

hospitality industry (Naumzik, Feuerriegel, & Weinmann, 2021). Despite their high relevance for inﬂu-

encing customers’ decision making, online ratings are potentially challenged by various factors including

self-selection (N. Hu, Zhang, & Pavlou, 2009), social inﬂuence (Muchnik, Aral, & Taylor, 2013), manip-

ulation of reviews (Gössling, Hall, & Andersson, 2018; Zhuang, Cui, & Peng, 2018), and dimensional

rating (Schneider et al., 2021). Particularly, single-dimensional rating scales (e.g. Google reviews, which

allow for a score from 1 to 5 stars) are not suitable to assess complex performance dimensions (Ittner &

Larcker, 2003). By these means, an organization will only receive a single rating, which often cannot

be associated with a particular service that the customer received. To overcome this issue, ﬁrms have to

invest in dedicated CFS, which allow them to receive feedback that they can beneﬁt from (e.g. feedback

on a speciﬁc service that they intend to improve) (Sampson, 1999). Within such a system, the feedback

is processed in the following sequential manner: channeling (i.e. feedback reception), processing (i.e.

using the feedback for improvements), and conversion of the feedback into organization-wide knowledge

(Birch-Jensen, Gremyr, & Halldórsson, 2020). In this context, channeling is highly relevant, since feed-

back in a certain quantity and quality needs to be received to enable the subsequent steps of processing

and conversion (Lafky & Wilson, 2020). Depth and extremity of reviews have been identiﬁed as useful

indicators of the quality of feedback on an e-commerce platform (Mudambi & Schuff, 2010), which are

found to be rather incentivized by social norms than ﬁnancial rewards (Burtch, Hong, Bapna, & Griske-

vicius, 2018). Feedback quantity is known to be positively inﬂuenced by ﬁnancial incentives (Burtch et

al., 2018), along with several other factors such as trust (Celuch, Robinson, & Walz, 2011) and perceived

usefulness (i.e. customers thinks that their feedback is useful for the organization) (Robinson, 2013).

Nevertheless, feedback quality may be reduced by applying such incentives (Lafky & Wilson, 2020).

3Fiverr is an online marketplace for freelance services: https://www.ﬁverr.com/ (last accessed 2021-12-10)
4Tripadvisor is an online travel company that operates a website and mobile app with user-generated content and comparison

shopping website: https://www.tripadvisor.com/ (last accessed 2021-12-10

5

For instance, ﬁnancial incentives lead to a reduction in feedback quality measured in depth (e.g., the

length of a written review) while increasing feedback quantity measured in breadth (number of provided

reviews) (Burtch et al., 2018), thus revealing a trade-off between quantity and quality that is steered by

the chosen incentive (Lafky & Wilson, 2020).

Multi-dimensional incentives in the form of blockchain-based tokens have been proposed as an alter-

native to such ﬁnancial incentives improving the properties of incentivized behavior such as actions con-

tributing to sustainability (Ballandies, Dapp, Degenhart, & Helbing, 2021; Dapp, 2019; Dapp, Helbing,

& Klauser, 2021; Kleineberg & Helbing, 2021). In this regard, blockchain-based incentives have been

suggested to improve the data quality in inter-organizational information exchange (Hunhevicz, Schraner,

& Hall, 2020; Zavolokina, Spychiger, Tessone, & Schwabe, 2018). For instance, it has been found that

Blockchain technology could contribute to trustworthy CFS in the tourism industry (Önder, Treiblmaier,

et al., 2018). Chandratre and Garg (2019); Gipp, Breitinger, Meuschke, and Beel (2017); Rahman, Ri-

fat, Tanin, and Hossain (2020) are among the ﬁrst to propose and implement blockchain-based feedback

systems. Although these systems utilize blockchain technology for tracking and the immutable storing

of feedback items, they do not explore incentivizing feedback provision with blockchain-based tokens.

This is a missed opportunity as, on the on hand, cryptoeconomic incentives carry monetary value (Kranz,

Nagel, & Yoo, 2019; Sunyaev et al., 2021), and thus could motivate users to increase feedback quantity,

while, on the other hand, they have different characteristics to money (Ballandies, Dapp, Degenhart,

& Helbing, 2021; Dapp, 2019; Dapp et al., 2021; Kleineberg & Helbing, 2021), and thus might im-

pact feedback quality differently when compared to monetary incentives.

In order to construct such

blockchain-based systems, Design Science Research (DSR) methods (A. Hevner & Chatterjee, 2010;

A. R. Hevner et al., 2004; Vom Brocke et al., 2020) have been successfully applied within the IS com-

munity (Ballandies, Dapp, Degenhart, & Helbing, 2021; Ostern & Riedel, 2020). For this, amongst

others, the model of Zargahm (2018) is utilized that describes a system in ﬁve layers, as illustrated in

Figure 3. Design principles can only be explicitly formulated and implemented in the software system

(Ballandies, Dapp, Degenhart, & Helbing, 2021), i.e.

the bottom three layers of the model ((I-III) in

Figure 3). The upper two layers emerge and cannot be explicitly deﬁned by the system designer (e.g. the

associated researchers).

In summary, the following observations can be made about current CFS applied in organizations:

First, initial, prior ﬁndings provide promising evidence regarding the utilization of blockchain-based to-

6

Figure 1: Activities, methods, participants and outputs of the four steps (I-IV) of the cyclic DSR process
(Sonnenberg & Vom Brocke, 2012)

kens for incentivizing behavior, such as inﬂuencing the provision of high-quality feedback. However,

they have not been incorporated within a feedback system and studied within a real-world use case.

Second, research on CFS mostly focuses on hospitality, tourism, and e-commerce applications, while

neglecting other application domains such as a library ecosystem. Third, CFS often focus on uncontex-

tualized and solicited feedback in the form of single-dimensional rating scales. In this work, we address

these gaps by investigating the design of a value-sensitive blockchain-based feedback system that incen-

tivizes the provision of feedback and utilizes the concept of contextualization of feedback to enable users

to increase the depth of their feedback and consequently feedback quality (Burtch et al., 2018). For this,

we apply an established DSR methodology (A. R. Hevner et al., 2004; Peffers et al., 2007; Sonnenberg

& Vom Brocke, 2012) that consists of expert interviews, stakeholder and value analysis, focus groups,

and a four-day ethics commission approved socioeconomic experiment, involving a major Swiss library

and its customers.

7

3 Research Design

This research applies a DSR methodology (A. Hevner & Chatterjee, 2010; A. R. Hevner et al., 2004;

Peffers et al., 2007). We report on a DSR journey (Vom Brocke et al., 2020), that comprised of four

iterations of concurrent design and evaluation (Sonnenberg & Brocke, 2011; Sonnenberg & Vom Brocke,

2012). Figure 1 illustrates how the process with its four steps (I-IV) has been implemented in this work:

In step I, a literature review (Identify Problem in Figure 1) identiﬁes suboptimal feedback ﬂows to and

within organizations. Expert Interviews (Evaluation 1 in Figure 1) with employees of two major libraries

evaluate this problem. Moreover, these interviews are utilized to identify important values and best-

practice mechanisms in the context of feedback provision in these organizations that can be utilized

to mitigate the identiﬁed problems and that are implemented within the constructed software artifact

(Section 4.3). In step II, two design workshops with library employees and a customer of that library

from University 1 resulted in (i) a stakeholder analysis which informs (ii) a value analysis which in turn

facilitates the identiﬁcation of (iii) design requirements (Design solution in Figure 1). The requirements

are incorporated in a system design via design principles and evaluated by the associated researchers

(Evaluation 2 in Figure 1). In step III, the associated researchers implemented the system by the means

of agile development into a software artifact (Construct solution in Figure 1). This artifact is validated in

two demonstrations with focus groups consisting of library employees, researchers, software developers,

and artists (FG2 in Table 1). Finally, the software artifact is put into use in an organizational context

of Library 1 in the form of an experiment (Use in Figure 1) involving employees and customers of the

library. The user behavior and answers to surveys are analyzed by the associated researchers (Evaluation

4 in Figure 1). Moreover, the collected feedback is evaluated by a focus group consisting of experts and

executives of Library 1 (FG3 in Table 1).

4 Research Findings

In the following, we present the ﬁndings and artifacts obtained at each activity of the cyclic DSR process

(Figure 1).

4.1

Identify Problem

During the ﬁrst activity, expert interviews were conducted by the ﬁrst author (A1) that evaluated the

identiﬁed problem of suboptimal feedback ﬂows in organizations (Section 1). Table 1 illustrates the

8

Section Lead
Section Lead

ID Hierarchy
01 Team Lead
02 Employee
03 Director
04 Employee
05 Team Lead
06
07
08 Employee
09 Director
10 Team Lead
11 Employee
12 Team Lead
13 Research Lead
14 Artist
15 Artist
16 Researcher
17

Attended
Institution
Working Area
IW, DW, FG2, FG3
Library 1
Market Research
IW, DW, FG2, FG3
Library 1
Innovation & Networking
IW
Library 1
Upper Management
IW, DW, FG2, FG3
Library 1
Innovation & Networking
IW, DW, FG2, FG3
Library 1
Innovation & Networking
IW
Library 1
IT-Services
IW
Library 1
Issuing Desk
IW
Library 1
Issuing Desk
IW
Library 2
Upper Management
IW
Knowledge Management
Library 1
IW, DW
Research data management Library 1
Library 1
E-Publishing
IW
University 1 DW
Information Systems
-
Video Game Designer
FG1, FG2
FG1, FG2
-
Interactive Media Designer
University 3 FG1, FG2
Neuroscience
Library 1

FG1

Software Developer Machine Learning

Table 1: Participants in the Interviews (IW), Design Workshops (DW) and Focus Groups (FG1, FG2,
FG3), their working area and hierarchy in their institution.

twelve participants from two libraries who were interviewed in a semi-structured format. The participants

were sampled by convenience based on the criterion that they work in a library. The interview protocol

and guide are illustrated in Section 1 of the Supplementary Material (Table 1 and 2 of the Supplementary

Material). Library 1 is the largest public scientiﬁc and technical library in Switzerland, whereas Library

2 is the largest in the German speaking countries. From Library 1 employees from all hierarchy levels

(employee, team lead, section lead, director) and ﬁve of seven organizational sections were interviewed,

including the director (ID 03, Table 1), whereas from Library 2 the director has been interviewed (ID 09,

Table 1). The interviews were transcribed by a third party following the standard of Dresing and Pehl

(2010) and were coded by the A1 with 19 codes (Table 2). The codes were developed by the A1 and A2

following the method of O’Connor and Joffe (2020). The deﬁnitions of the codes are given in Table 3 of

the Supplementary Material. The interviews are then analyzed by grouping manually similar contents of

each code into clusters (e.g., Figure 1 and Figure 2 of the Supplementary Material for the codes "status

quo: challenge" and "risk").

In Section 4.1.1, a subset of these challenges are illustrated that are addressed in this work. Moreover,

the interviews are utilized to identify the values stakeholders have in the context of feedback provision

(Section 4.1.2). Finally, the interviews are utilized to identify best practices when collecting feedback in

the organizations (Section 4.1.3).

9

l
e
n
n
a
h
c

:
k
c
a
b
d
e
e
f

l
a
n
r
e
t
x
e

:
k
c
a
b
d
e
e
f

l
a
n
r
e
t
n
i

:
k
c
a
b
d
e
e
f

y
c
n
e
t
a
l

:
k
c
a
b
d
e
e
f

m

s
i
n
a
h
c
e
m

:
k
c
a
b
d
e
e
f

y
t
i
t
n
a
u
q

:
k
c
a
b
d
e
e
f

d
e
t
i
c
i
l
o
s

:
k
c
a
b
d
e
e
f

r
e
d
l
o
h
e
k
a
t
s

:
k
c
a
b
d
e
e
f

d
e
t
i
c
i
l
o
s
n
u

:
k
c
a
b
d
e
e
f

c
i
s
n
i
r
t
x
e

:
n
o
i
t
a
v
i
t
o
m

c
i
s
n
i
r
t
n
i

:
n
o
i
t
a
v
i
t
o
m

d
n
u
o
r
g
k
c
a
b

l
a
n
o
s
r
e
p

k
s
i
r

e
d
o
C

e
r
i
s
e
d

e
c
i
t
c
a
r
p

t
s
e
b

:
o
u
q

s
u
t
a
t
s

m

s
i
n
a
h
c
e
m

:
o
u
q

s
u
t
a
t
s

e
g
n
e
l
l
a
h
c

:
o
u
q

s
u
t
a
t
s

t
c
i
ﬂ
n
o
c

e
u
l
a
v

e
u
l
a
v

Units

56

60

77

61

19

68

47

31

15

38

43

33

58

43

16

78

86

84

7

Table 2: Alphabetically ordered codes utilized in the analysis of the expert interviews and the amount
of units of analysis that is marked with each code. The deﬁnition of codes are given in in Table 3 of the
Supplementary Material.

4.1.1 Suboptimal feedback ﬂows

In order to obtain a multi-faceted perspective of the current and future challenges that exist or might

arise with regard to feedback in an organizational context, the codes "status quo: challenge" and "risk"

(Table 2) are analyzed. A comprehensive compilation of challenges are identiﬁed and illustrated in Figure

1 and Figure 2 of the Supplementary Material. The following challenges are addressed in this work:

i) Mobilising non-customers: Obtaining feedback from those that do not utilize the library services,

respectively those that are unaware that they are utilizing a service of the library is difﬁcult. (ii) Hierarchy

of the organization prevents agile processing of feedback: Feedback is not forwarded preventing the

recognition of the feedback by the responsible organizational unit (iii) Difﬁculty to distinguish important

from unimportant feedback: When the quantity of collected feedback is high and enters the organization

via various channels and organizational units, identifying feedback that would result in an improvement

of services is hard. (iv) Difﬁculty to evaluate the quality of questions utilized in solicited feedback: When

designing surveys, often similar questions are repeated or the posed questions are not evaluated if they

enable a comprehensive answer (e.g., a limited set of answer options in single-choice type questions). (v)

Monetary incentives may increase quantity while reducing quality of collected feedback when awarded

to customers for the provision of feedback.

4.1.2 Values

The top six mentioned values are Anonymity (17), Transparency (16), Openness (11), Safety (11), Phys-

ical Human Interactions (10), and Simplicity (10) (Table 4 of the Supplementary Material lists all men-

tioned values). The mentioning of anonymity and transparency are positively biased by the interview

10

guide (Table 1 and 2 of the Supplementary Material) by surveying participants about the importance

of those values. Openness, Safety, Physical Human interactions, and Simplicity have been brought to

the discussion by the experts. In particular, the value of physical human interactions is considered as

important to facilitate a successful feedback process as it enables the exchange of informal feedback: It

facilitates the recognition of gestures and the exchange of spontaneous and unsolicited feedback. This is

expressed by an employee as: "If an IT system really supports me in my work, in my human existence,

then I very, very much agree [to utilize it]. If, as a person, I adapt again and even more to a system in

order to give feedback and that separates me from my customers, the project or idea generators, then I

am not in favor of it."

4.1.3 Best practice mechanisms

It is mentioned 16 times that the libraries follow best-practices ("status quo: best practices", Table 2).

These can be summarized to: i) A web-based feedback wall in the form of a pin-board is utilized where

users can quickly post around the clock unsolicited feedback. The wall enables anonymous input and

open/ transparent visibility of feedback items. The newest feedback is always on top. ii) A team im-

plements the practice to share positive incoming feedback with all employees.

iii) Physical feedback

collection points in the form of boxes are installed in the library buildings which facilitated the collec-

tion of high quantity feedback. iv) A team gamiﬁed the process of annotating archival pictures which

lead to the establishment of a large community that actively supports the library in its work. v) The

libraries facilitate an open and trustworthy culture that enables most employees to voice their opinion

without the fear of restrictions. vi) A working group has been established that facilitates the provision of

feedback on library processes.

4.2 Design Solution

During this activity, two design workshops are conducted with employees of Library 1 and a customer of

the library from University 1 (DW in Table 1) to identify the design requirements of the feedback system

(Figure 1). A1 moderated the workshop, whereas A2 facilitated the technical setup in the background

and assisted participants in case of questions. Due to the Covid-19 policies at the research institute, the

workshops are conducted virtually utilizing zoom5 and Miro6.

5A video conferencing platform: https://zoom.us/, last accessed: 2021-10-04
6Online whiteboard and visual collaboration platform: https://miro.com/, last accessed: 2021-10-04

11

Activity

Mode

Training

collaborative

Brain
storming

Brain writing

individual

Clustering

collaborative

Rating

individual

Discussion

collaborative

Workshop 1:
Stakeholder
Analysis

Workshop 2:
Value Analysis and
Design Requirements

Miro-board
utilization
Stakeholder
identiﬁcation
Meta-category
identiﬁcation of
Stakeholders
Inﬂuence and
interest of each
stakeholder
Association of
Stakeholder
with values

-

Design Requirement
identiﬁcation

-

Association of
Stakeholders
with values
Acceptance of ﬁnalised
stakeholders inﬂuence/
interest matrix

Table 3: Activities, the mode of collaboration and the output of the two Design workshops

Table 3 illustrates the workshop activities: Activities are either collaborative if participants inter-

act with each other, or individual if participants have no interactions. At the beginning of workshop 1,

all participants conducted a collaborative training to familiarize themselves with Miro. Because sta-

tus differences are evident in the group and participants (partly) did not know each other beforehand

which limits social interactions, both workshops utilized Brainwriting (VanGundy, 1984) as an indi-

vidual Brainstorming method to identify the stakeholders and design requirements. Both, the rating of

stakeholder interest and inﬂuence, and the association of these stakeholders with values are performed

individually and were analyzed by the research team after the workshops: By averaging participants’ rat-

ing of stakeholders inﬂuence and interest in the solution, the ﬁnal stakeholders inﬂuence / interest matrix

and its clusters are identiﬁed (Figure 7 of the Supplementary Material). This summarized stakeholder

map was accepted by all participants in the second workshop. In order to facilitate that the stakeholders’

values are accounted for in the design requirements of the system, the value analysis is performed as

an intermediate step between the stakeholder analysis and the requirements elicitation: Each participant

individually assigned all relevant values to a subset of stakeholders (Cluster 3 and 4 in Figure 7 of the

Supplementary Material) of the overall stakeholder analysis. The strength of stakeholders’ association

with a value is illustrated in Table 4. The values have been taken from value sensitive design literature

(Friedman, Kahn Jr, & Borning, 2020; Hänggli, Pournaras, & Helbing, 2021; Harbers & Neerincx, 2017;

12

Huldtgren, 2015; Van de Poel, 2015). The value of Excellence has been added by the participants during

the ﬁrst Design Workshop.

The ﬁnal design requirements (Figure 2) are then elicited by ﬁrst identifying the requirements asso-

ciated with each value via brainwriting and then to prioritize those requirements (Average ≥ 1 in Table

4). In order to familiarize the workshop participants with these values, a preliminary value association

task has been performed with the participants at the end of workshop 1 to prepare them for the second

workshop. The chosen brainwriting and clustering approach was tested before the workshops within a

diverse focus group consisting of artists, a researcher, and a software developer (FG1 in Table 1).

In the following, the outputs of the two Design Workshops are illustrated: a Stakeholder map (Sec-

tion 4.2.1), a ranking of values based on their average importance (Section 4.2.2) and value-based design

requirements (Section 4.2.3). Moreover, elicited by the associated researchers from the design require-

ments, design principles that guide the construction of value-sensitive feedback systems (Section 4.2.4)

and a system design based on these principles (Section 4.2.5) are illustrated.

4.2.1 Stakeholder Analysis

Figure 7 of the Supplementary Materials illustrates the participants and interest groups of the feedback

system in the form of a Stakeholder map (Rössner, Dapp, & Fach, 2018).

Four clusters are identiﬁed: Cluster (1) does not have a positive inﬂuence on the construction of the

solution and a low to medium interest in it. The cluster contains stakeholders such as suppliers, other

libraries, and publishers. Cluster (2) contains the legislation, politics, and public funding institutions.

These stakeholders have an inﬂuence on the solution while not having a high interest in it. The interest

in and possible inﬂuence on the solution of Cluster (3) is the highest. These stakeholders are key in the

design requirements engineering of Section 4.2.3. This cluster includes the management and experts of

the library as well as average employees and customers (e.g. researchers and lecturers). The directorate

of the library has the highest interest and inﬂuence in the solution. Cluster (4) contains potential users

of the system (e.g. students) that have a high interest in the solution but a low inﬂuence on its design.

As these stakeholders are potential users of the system, their perspective is considered in the design

requirements engineering to positively inﬂuence the adoption of the solution.

13

.

g
a
n
a
M
y
t
i
s
r
e
v
i
n
U
1
1
1
3
0
1
2
0
2
0
2
1
1
0
1
0
0
0
3
0
0
0
0
0
0

d
a
e
L

t
c
e
j
o
r
P
1
3
2
3
1
3
0
2
0
1
1
1
0
1
1
1
0
0
0
0
0
1
1
2
0

s
r
e
h
c
r
a
e
s
e
R
3
3
3
3
3
3
1
3
2
0
1
0
2
0
1
2
1
0
0
1
0
0
1
0
1

s
r
e
r
u
t
c
e
L
3
3
3
2
3
3
1
3
2
3
1
0
2
1
0
1
0
0
0
0
1
0
0
0
0

f
f
a
t
S
k
s
e
D
e
u
s
s
I

2
3
2
0
3
1
1
2
0
2
0
3
0
0
0
0
1
3
0
0
2
2
1
0
0

m
a
e
T

t
s
i
l
a
i
c
e
p
S
1
0
1
1
0
1
0
2
0
2
0
3
0
1
1
3
0
1
0
1
0
1
1
0
0

g
n
i
t
e
k
r
a

M
2
0
1
1
0
1
3
0
0
3
1
0
0
0
1
0
0
0
0
3
0
0
0
0
0

t
n
e
m
e
g
a
n
a
M

.

d
i
M
1
1
1
3
1
0
0
0
1
0
1
0
1
0
3
0
1
0
1
0
0
0
1
0
0

h
c
r
a
e
s
e
R

t
k
e
r
a

M
2
1
2
0
0
3
0
0
0
0
0
0
1
0
0
0
2
0
0
0
0
0
0
0
0

r
e
g
a
n
a
M

t
c
u
d
o
r
P
3
1
2
0
3
0
3
0
0
0
2
1
0
0
0
1
0
0
2
1
0
0
0
3
1

t
n
e
m

t
r
a
p
e
D

l
a
g
e
L
0
0
0
1
1
1
0
0
3
0
1
0
3
3
0
0
1
0
0
0
3
0
0
0
0

e
t
a
r
o
t
c
e
r
i

D
3
2
0
3
3
0
2
0
0
0
2
0
1
0
1
0
0
0
3
3
0
1
1
0
0

f
f
a
t
S
1
1
1
1
1
0
3
1
1
3
0
3
0
3
1
1
2
3
0
0
0
2
0
0
1

f
f
a
t
S
n
i
m
d
a

/
.
h
c
e
T
1
3
3
2
0
0
0
1
2
0
1
1
1
3
0
0
0
2
0
0
1
0
0
0
0

s
t
n
e
d
u
t
S
3
3
3
0
1
0
0
2
2
1
0
0
0
0
1
1
2
0
0
0
0
0
0
0
0

Avg. Var.
1.03
1.80
1.52
1.67
1.10
1.67
1.55
1.53
1.67
1.33
1.55
1.13
1.50
1.07
1.35
1.07
1.14
1.00
1.57
1.00
0.55
0.87
1.41
0.87
0.89
0.80
1.46
0.80
0.64
0.73
0.81
0.67
0.67
0.67
1.26
0.60
1.26
0.60
1.11
0.60
0.84
0.47
0.55
0.47
0.26
0.40
0.81
0.33
0.17
0.20

Value
Credibility
Simplicity
Universal Useability
Excellence
Efﬁciency
Transparency
Identity
Autonomy
Safety
Physical Hum. Inter.
Accountability
Responsibility
Informed Consent
Privacy
Inclusiveness
Freedom
Openness
Courtesy
Human Welfare
Sustainability
Calmness
Trust
Resilience
Ownership
Unbiased

Table 4: Strength of stakeholder association for each value: Green (3) - strong, yellow (2) - medium,
red (1) - low, white (0) - none, sorted by average strength, as identiﬁed by the design workshop partici-
pants (Table 1).

14

Figure 2: A ﬂow chart illustrating the identiﬁed values (left), design requirements associated with these
values (middle) and the found design-principles facilitating those requirements (right).

4.2.2 Value Analysis

Table 4 illustrates which values the various Stakeholders from Cluster (3) and (4) carry, sorted by strength

of association (output of the second Design Workshop). The following values have the strongest asso-

ciation with the stakeholders (average strength ≥ 1): Credibility, Simplicity, Universal Usability, Excel-

lence, Efﬁciency, Identity, Autonomy, Safety, and Physical human interaction. These values are consid-

ered in the design requirements identiﬁcation (Section 4.2.3).

4.2.3 Design Requirements

Figure 2 illustrates the identiﬁed important values (Section 4.2.2) and the associated design requirements,

which are the output of the second Design Workshop (Table 3). Because the directorate is the stakeholder

with the greatest inﬂuence on and interest in the solution (Section 4.2.1), its values are added to the iden-

15

tiﬁed important values (Section 4.2.2). In total 97 requirements are identiﬁed of which 32 are associated

with the important values. The full list of requirements are given in Tables 5-7 of the Supplementary

Materials.

4.2.4 Design Principles

By grouping the design requirements (Section 4.2.3) into solution clusters, 15 design principles are

identiﬁed (Figure 2) that guide the construction of a value-sensitive feedback system. Three types of

principles are found: i) infrastructure principles informing about technological requirements, ii) feedback

principles illustrating the handling of the collected feedback, and iii) interaction principles illustrating

the interplay among stakeholders and the system. In the following, these principles are illustrated in

greater detail.

Infrastructure principles: Feedback system designers should use a public and trustworthy storage

infrastructure combined with a transparent computing engine. Moreover, software tools that are created

in the construction of the feedback system should integrate into existing software stacks and should be

easy to use.

Feedback principles: Feedback items should be contextualized such that metadata7 of feedback

(e.g., location of provision, the receiver, or importance) is also stored. A possibility for ranking feedback

to visualize the impact of each feedback item should be integrated. Also, the feedback should be aggre-

gated and visualized to the stakeholders of the system and a focus on processes not humans should be

put as the content of feedback.

Interaction principles: Stakeholders of the system should be enabled to have personal contacts in

both, the cyberspace, but also in the physical reality. In particular, customer-customer interactions should

be enabled. Anonymity, as well as simple registration and login should be enabled by (re)using already

existing pseudonymous identities. Also, participation in the system should be voluntary. Interactions

with and within the system should be simple and guided by a respectful behavior. Rewards could be uti-

lized to incentivize feedback provision and personal contact between stakeholders should be facilitated.

4.2.5 System Design

Figure 3 illustrates the system design that is found by instantiating the identiﬁed design principles. The

mapping of design principles to system design choices is illustrated in the following. Design principles

7Metadata contributes to usability of information, a quality dimension of data (Cai & Zhu, 2015) which can be implemented

utilizing semantic web technologies (Ballandies & Pournaras, 2021)

16

Figure 3: Utilizing the model of Zargahm (2018) (left, grey), the interaction of the socio-economic
feed4org system with its underlying software system is illustrated (red, right) (adapted from Ballandies,
Dapp, Degenhart, and Helbing (2021)).

that are related to the instantiation of the software artifact are illustrated in Section 4.3.

Distributed Ledger: A distributed ledger is a distributed data structure, whose entries are written

by participants of a consensus mechanism after reaching an agreement on the validity of the entries.

Such a consensus mechanism is called permissionless, if the public can participate in it, otherwise it is

called permissioned (Ballandies, Dapp, & Pournaras, 2021). A permissionless distributed ledger (e.g.

blockchain) affords a public and trustworthy storage, which in turn facilitates a transparent computing

engine if open source smart contracts are utilized as trusted computation protocols. With these protocols,

interactions patterns can be implemented in the platform that deﬁne what users of the system can or can-

not do (Ballandies, Dapp, Degenhart, & Helbing, 2021): (i) blockchain-based cryptoeconomic incentives

in the form of tokens can be deﬁned and awarded as rewards to users for the provision of high-quality

feedback or respectful behavior; (ii) Also, diverse and trustworthy statistics can be aggregated and shown

to the stakeholders of the system by analyzing the publicly accessible data storage via trusted computing

protocols; (iii) Moreover, public distributed ledgers (e.g. Bitcoin) do not restrict the creation of user

identities (Ballandies, Dapp, & Pournaras, 2021) (e.g. no know your customer policies), thus each user

can decide how much information is revealed about their identity which facilitates pseudonymous in-

teractions among stakeholders; (iv) Also, by open sourcing the code basis, a transparent code access is

facilitated.

17

Figure 4: Software Stack of the feed4org app.

Figure 5: Open Feedback View (feedback wall) of
the software artifact.

Contextualization and incentives: In order to improve the processing and depth of the collected

feedback, which is associated with feedback quality (Mudambi & Schuff, 2010), users are enabled to

contextualize their feedback with meta-properties such as the importance of the feedback, their satis-

faction with the answer options, general comments, and the target audience to which their feedback is

directed. Also, the system provides solicited (survey style questions, e.g. Figure 6) and unsolicited (red-

dit style forum, e.g. Figure 5) input forms such that diverse feedback can be collected and user-user

interactions are facilitated. The system encourages both, the provision of solicited feedback and the con-

textualization of this feedback, by incentivizing stakeholders with cryptoeconomic rewards in the form

of tokens.

Cyber-physicality: Personal contact is enabled by following a cyber-physical approach: Stakehold-

ers can interact via the created software artifact but are also encouraged to meet physically8 at the library

facilities by i) including interactive answer options such as taking photos at the library facility and ii)

turning spots in the library into "real-time digital voting centers" (Hänggli et al., 2021), e.g. via the proof

of witness presence (Pournaras, 2020).

4.3 Construct Solution

Utilizing agile development, a software artifact is constructed that is evaluated by demonstration in a

focus group (Figure 1): Based on the identiﬁed requirements (Section 4.2.3), design principles (Sec-

8The physical approach has been removed from the user study (Section 4.4) due to the COVID-19 restrictions at the time

and location of the experiment.

18

Figure 6: Answer View - Entry point to the feed4org app where the organization can ask for solicited
feedback. Users have the possiblity to contextualize the feedback with its importance or their satisfaction.
Moreover, each feedback item can be commented.

tion 4.2.4) and system design (Section 4.2), a software artifact is created to incentivize the provision of

high-quality feedback to organizations. Figure 4 illustrates the software stack: A web app is built using

the VUEjs9 framework, on top of the Finance 4.0 software stack (Ballandies, Dapp, Degenhart, & Hel-

bing, 2021; Ballandies, Dapp, Degenhart, Helbing, Klauser, & Pardi, 2021), which enables the creation

of cryptoeconomic incentives in the form of tokens. By utilizing the Finance 4.0 software stack, the

trustworthy data storage and computation engine of the Ethereum blockchain is utilized that facilitates

durable data and trusted computation as required by the system design (Section 4.2.5). Moreover, Fi-

nance 4.0 facilitates the creation of tokens and proof veriﬁcations for awarding these tokens to feedback

providers. The web app consists of four main components: i) Answer Question view that facilitates the

provision of solicited feedback and the awarding of cryptoeconomic incentives, ii) Give Open Feedback

view where users can provide unsolicited feedback, iii) View Statistics that informs users about their

collected cryptoeconomic tokens and the behavior of others users and iv) See About Page where infor-

mation about the app and a Netiquette are displayed. In the following, these components are illustrated

in greater detail.

4.3.1 Answer Questions

When users enter the app, they have the possibility to give feedback on questions posed by the library

(Figure 6). These questions focus on processes and services of the library as required by the design

9https://vuejs.org/, last accessed: 2021-10-17

19

Total

-
d
e
e
F

-
n
o
C

e
t
a
g
i
v
a
N

k Solicited
c
a
b

21286
55
Unsolicited
6018
Importance
5692
Satisfaction
2107
Comments
6990
Question
3605
Statistics
3094
Open feed.
About View 549

t
x
e
t

o
t

user

C
18
71.5
0.8
28.4
26.9
15.2
19.9
11
14.6
3

T
54
189.7
0.5
52.1
50.3
19.1
65.6
35.9
30.3
5

unaw.-user
C
15
63.9
0.2
33.5
22.5
9.3
15.8
10.3
7.8
1.4

T
45
195.5
0.2
48.6
47.9
14.7
63.3
29.2
23.9
4.5

Figure 7: Token Design of the utilized cryptoeco-
nomic incentives utilizing the DLT system taxon-
omy (Ballandies, Dapp, & Pournaras, 2021).

Table 5: Total and mean amount of interactions with the
software artifact for the 132 experiment participants and the
treatment (T, with token incentives) and control group (C, no
token incentives) for users and unaware-users.

principles (Figure 2). The following question types are implemented: Single-choice, multiple-choice,

likert scales, open text, and combinations of these options.

Contextualization:

In addition to answering questions, users can contextualize their answers by

clicking on the contextualization buttons (bottom buttons in Figure 6). Three types of contextualizations

are implemented. Users can state with the Importance contextualization how important the question is

for the library to improve their services, with the Satisfaction contextualization how satisﬁed they are

with the range of answer options and with the Comment contextualization to provide further comments

in an open feedback form (Figure 10 of the Supplementary Materials).

Cryptoeconomic incentivization in the form of blockchain-based tokens is utilized via the Finance

4.0 platform to incentivize the provision of feedback. Figure 7 illustrates the design choices of the

utilized cryptoeconomic incentives using a taxonomy for DLT systems (Ballandies, Dapp, & Pournaras,

2021), as performed by Dobler, Ballandies, and Holzwarth (2019):

The Money token is pre-mined and is pegged to the Swiss franc, thus being a stable coin collateralized

with a ﬁat currency (Mita, Ito, Ohsawa, & Tanaka, 2019). Each token unit is worth 0.20 CHF. For each

answered question, the user is rewarded with a token unit.

The Context token is created whenever a contextualization action is performed and awarded to the

feedback provider. Thus, this token is not capped, but its amount illustrates the number of contextu-

alization actions performed in the system. Users can utilize this token to vote on the importance of

unsolicited feedback (Section 4.3.2). Moreover, the token is utilized to rank users in a leader board,

20

which is displayed to all users in the View Statistics view of the app (Section 4.3.3).

4.3.2 Give Open Feedback

Via the Navigation bar (top bar in Figure 6), users can switch to the Give Open feedback view. This

view is based on the best practice mechanisms "feedback wall" of the library identiﬁed in Section 4.1.3

and thus could be the integration point of this software artifact into the existing library software stack as

required by a design principle. Via the feedback wall, users can provide unsolicited feedback to the or-

ganization. This paper extends this mechanism by i) enabling users to up and downvote a feedback item,

facilitating the design principle of ranking feedback items, ii) to comment on a feedback item, facilitating

personal contacts among users (user-user interaction), and iii) to provide area tags on a feedback item

that connects it with strategic action areas of the library where the management of the library aims to

improve their services. In order to up and downvote a feedback item, users are required to spend a unit

of the context token (Section 4.3.1).

4.3.3 View Statistics

In the statistics view (Figure 11 of the Supplementary Material), users are informed about the amount

of collected cryptoeconomic tokens. Moreover, the behavior of other users is displayed in a leaderboard

that illustrates how many context tokens other users in the system collected. This facilitates the design

principles of collecting statistics.

4.4 Use Solution

The software artifact is utilized in a four-day long real-time experiment to collect feedback from library

customers. The collected feedback is then evaluated by both, statistical analysis, and a focus group

consisting of library employees (FG3 in Table 1).

The experiment has been conducted in collaboration with the ETH Decision Science Laboratory10,

who recruited the participants, guaranteed a fair compensation (10 CHF show-up fee, 30 CHF/h mean

compensation), and facilitated anonymity for the participants by separating their identity information

from the experiment data: The research team has only access to the latter. The four-day experiment setup

has been approved by the ETH Zurich Ethics commission (Section 2 of the Supplementary Material),

application number: EK 2021-N-22. In total, 132 users participated in four waves receiving in total

10ETH Decision Science Laboratory provides infrastructures and services for researchers to perform human subject trials in

the intersecting areas of Decision and Behavioral Sciences: https://www.descil.ethz.ch/ (last accessed: 2022-03-11)

21

5309.75 CHF as compensation (on average 40.23 CHF). The total experiment cost including lab cost

was 6034.80 CHF. The software artifact and the experiment setup were evaluated with demonstrations

before the experiment in two focus group meetings with library employees, artists, and a researcher (FG2

in Table 1). The ﬁnalized experiment setup is composed as follows: At the beginning of each wave,

participants obtained onboarding materials (Section 6.2.1 of the Supplementary Material) in which they

are introduced to the app and answered demographic questions, Computer Self-Efﬁcacy (adapted from

Compeau and Higgins (1995); Thatcher, Zimmer, Gundlach, and McKnight (2008) as performed in Sun,

Wright, and Thatcher (2019)) and Personal Innovativeness in IT (adapted from Agarwal and Karahanna

(2000) as performed in Sun et al. (2019)) questions.

During the experiment phase, participants utilized the software artifact and provided feedback to

Library 1. In the exit phase, users answered a questionnaire that included a UTAUT (Section 3 of the

Supplementary Material, adapted from Venkatesh, Thong, and Xu (2012)) and questions regarding the

value of cryptoeconomic tokens (Ballandies, Dapp, Degenhart, Helbing, Klauser, & Pardi, 2021). After

the experiment, a focus group consisting of Library 1 employees (FG3 in Table 1) evaluated the quality

of collected feedback.

In total, 132 participants completed the study with an average age of 23.2 years. Of these, 51.5 %

are male, 47.0 % are female and 1.5 % do not want to reveal their gender. On average, the participants

self-report to be modest computer self-effective (2.811 computer self-efﬁcacy (Sun et al., 2019)) and

innovative in IT (2.4 innovativeness in IT (Sun et al., 2019)). Moreover, 54.5 % of the participants are

utilizing the services of the library that is focus of this study. 99 participants received the treatment in

form of cryptoeconomic tokens. In the following, user interactions with the App and user responses to

the exit survey, and the evaluation of the focus group are illustrated.

4.4.1 App interactions

Table 5 illustrates the user interactions with the software artifact. In total, 21286 solicited feedback items

and 13817 contextualizations are collected from users which indicates a high useability of the artifact.

In particular, the scoring on the UTAUT (Table 6) for the effort expectancy (2.83) validates the design

principle of simple user input/ self-explanatory UI (Figure 2): Above all, it is easy for participants to

learn using the software artifact (3.00). The focus group (FG4 in Table 1) indicated that this might be

due to the clear focus in the design of the question answering and contextualization views which does

11 Average value on a 5-point likert scale (0 - strongly disagree to 4 - strongly agree).

22

Construct QID

Mean CI (95%) low CI (95%) up Stdev N

UTAUT_5
Effort
UTAUT_6
Expectancy UTAUT 7
UTAUT 8
Average

Token
Value

FIN4_1
FIN4 2
FIN4 3
Average

3.00
2.77
2.92
2.63
2.83

2.54
3.19
2.71
2.81

2.87
2.62
2.77
2.47
2.68

2.27
2.97
2.45
2.56

3.13
2.91
3.07
2.79
2.98

2.81
3.42
2.97
3.07

0.78
0.85
0.86
0.91
0.85

1.36
1.13
1.32
1.27

132
132
130
132
131.5

99
99
99
99

Table 6: Mean, lower/ upper 95 % conﬁdence interval, standard deviation and number of participant
answers of the constructs of effort expectancy (UTAUT, Table 8 of the Supplementary Material) and
token value (Ballandies, Dapp, Degenhart, & Helbing, 2021) of Evaluation 4 that utilize a 5-point likert
scale (0 - strongly diasagree to 4 - strongly agree). Token value is evaluated only for the treatment group
as the control group did not utilize tokens.

not utilize unnecessary design elements.

Table 7 illustrates the usefulness evaluation of the artifact by the participants. Both, the treatment

(2.82) and the control (2.80) group evaluate the features of the artifact as useful on average. In particular,

the statistics view has been evaluated as most useful in the treatment group, whereas the control group

rated the open feedback view as most useful.

Figure 12 of the Supplementary Material illustrates the user interactions with the software artifact

in a heatmap. The plots are obtained from hotjar12. The importance (6018) and satisfaction (5692)

contextualization are more often utilized than the comment (2107) contextualization.

Figure 5 illustrates the obtained unsolicited feedback and the participants ranking of these items for

the fourth experiment round. A focus group (FG4 in Table 1) evaluated the content and the ranking of the

unsolicited feedback as useful for improving the library services because the mechanism highlights the

most important feedback items. Moreover, the focus group highlighted the innovativeness and useability

of combining solicited and unsolicited feedback into one software artifact, because it facilitates the com-

bination of quantitative and qualitative analysis. In particular, the group was positively surprised about

the quantity of provided unsolicited feedback, though it was not incentivized. Also, the focus group

stated that because the existing library wall had been utilized in the software artifact, an integration of

the tool into the infrastructure and processes of the organization would be simple and should be initiated.

12Hotjar provides a visual way to discover, consolidate, and communicate user needs: https://www.hotjar.com/, last accessed:

2021-09-29

23

Usefulness
Question Answering
Contextualization of questions
Statistics
Open feedback
About page
Tokens
Up/ down voting
Average

Mean

T
2.95
2.93
2.96
2.82
2.59
2.71
2.80
2.82

C
3.06
2.67
2.76
3.09
2.33
1.88
2.88
2.80a

Variance
C
T
0.43
0.76
0.98
0.64
0.81
0.95
0.59
0.77
0.92
0.69
0.80
1.07
0.61
0.89
0.73
0.82

Table 7: Mean and variance of responses by the treatment (N=99) and control (N=33) group to the
question "How useful did you ﬁnd the following features of the app", utilizing a 5-point likert scale (0 -
strongly diasagree to 4 - strongly agree).

aBecause the control group did not utilize tokens, its usefulness evaluation is removed from the calculation of the control

groups average.

Contextual.

Rewards

I found the contextualization options restricting.
I wanted to have more contextualization options.
I found the rewards fair.
I understand how the rewards have been assigned to me.
I know at which time the rewards were assigned to me.

Mean

T
1.55
1.88
2.71
2.4
2.67

C
1.82
2.15
2.39
0.94
1.09

Variance
T
C
0.84
0.78
0.95
1.05
0.62
0.8
0.81
1.77
1.27
1.46

Table 8: Mean and variance of responses to the contextualization options and assignment of rewards by
the treatment (N=99) and control (N=33) group, utilizing a 5-point likert scale (0 - strongly diasagree to
4 - strongly agree).

4.4.2 Feedback contextualization

The participants of the experiment evaluated the contextualization feature of the software artifact as

useful (Table 7). In particular, the contextualization options are neither perceived as restricting nor do

users want to have on average more contextualization options (Table 8). This indicates that the chosen

contextualization options are sufﬁcient for the users to express themselves.

Table 9 illustrates the percentage of contextualizations performed by experiment participants for

each question type. The satisfaction (26.9%) and importance (28.4%) contextualizations are utilized

more often than the comment (9.6%) contextualization. Multiple-choice and likert scales are chosen

above average for comment contextualization, indicating its potential to contextualize the answer for

these question types.

The focus group (FG4 in Table 1) evaluated the contextualization of solicited and unsolicited feed-

back as innovative and useful improving the quality of the collected feedback. In particular, the focus

group evaluated the contextualization of solicited feedback items as an enabler for i) an identiﬁcation of

24

Question Type
choice-multiple
choice-multiple-single
choice-multiple-single-text
choice-multiple-text
choice-single
choice-single-text
likert
text-input
Average

#Answers

1704
1324
918
952
8363
668
3531
3826

Contextualization percentage

Satisfaction
0.290
0.272
0.258
0.257
0.263
0.271
0.270
0.267
0.269

Importance Comment

0.301
0.286
0.291
0.268
0.276
0.270
0.287
0.290
0.284

0.124
0.088
0.073
0.068
0.091
0.096
0.127
0.097
0.096

Table 9: Total number of questions answered per question type and percentage of questions for which a
contextualization is performed.

weakly formulated questions by analyzing those with low satisfaction rating via the comment contextu-

alization, ii) identiﬁcation of feedback items that are important for the library to improve their services

by focusing on those items that have a high importance rating and iii) a differentiated view on given feed-

back by comparing rating behavior of all users with those that found the question important to improve

the library service (Figure 13 of the Supplementary Material). In particular, this differentiated view on

given feedback is described as "very interesting, because it enables a better interpretation of answers".

The ranking of unsolicited feedback is evaluated as useful because it enables prioritization of unso-

licited feedback which is not possible with the current implementation of the feedback wall in the library.

Moreover, the combination of unsolicited with solicited feedback in one software tool has been evaluated

"as a very useful approach for the library" as it facilitates a combination of quantitative and qualitative

analysis.

4.4.3 Token Incentives

The token feature of the software artifact is evaluated as useful by the treatment group (Table 7). In

particular, the token carries value for that group (Table 6). Table 5 illustrates the impact of token in-

centives on the amount of provided feedback and contextualizations. On average, the treatment group

provided more solicited feedback and contextualizations than the control group. The latter indicates that

the incentives are encouraging participants to increase the depth of their feedback and thus its quality

(Burtch et al., 2018; Mudambi & Schuff, 2010). Unaware-users of the library services are incentivized

to increase the amount of solicited feedback, indicating the potential of the chosen incentives to mobilize

non-customers of the library to provide feedback. Nevertheless, in the mean, the control group gave

more unsolicited feedback than the treatment group, which might be due to the following: Providing

25

Figure 8: The contributions of the four steps of the research methodology (I-IV in Figure 1) with regards
to projectability (of the research context to new research contexts), ﬁtness (of solving the target problem)
and conﬁdence (in the evaluation of the solution) of the design knowledge (DK) chunks of the research
process as introduced in Vom Brocke et al. (2020).

unsolicited feedback is not incentivized. Thus, users have to have intrinsic motivation, which might be

crowded out in the treatment group with the applied incentives (Osterloh & Frey, 2000).

5 Discussion

5.1 Design science as a journey

This study reports on a DSR process, that creates and evaluates multiple DSR artifacts. The study is

an example of conducting a DSR journey, as suggested by Vom Brocke et al. (2020), which aims to

accumulate design knowledge across multiple intermediate designs. Figure 8 illustrates this journey by

connecting the design knowledge chunks obtained from each step of the DSR methodology (Section 3):

The research background (Section 2) revealed a broad problem space when it comes to feedback provi-

sion within and to organisations. In Step I in Figure 8, this problem space is contextualized with risks and

challenges that arise in feedback provision for the context of library organisations. In particular, good-

ness criteria in form of important values (e.g. the values of simplicity or physical human interactions) are

elicited (Section 4.1.2). Moreover, solutions in the form of best-practice mechanisms (e.g. the feedback

wall) for feedback collection are identiﬁed (Section 4.1.3). In step II in Figure 8, the problem space is

further contextualized by identiﬁying key stakeholders (Section 4.2.1) and design requirements (Section

4.2.3) for a system that focuses on feedback provision from customers to a library organization. Based

26

on these requirements, the ﬁtness of the solution is enhanced with novel design principles (Section 4.2.4)

and system design (Section 4.2.5), which answers the ﬁrst research question (Section 1). Nevertheless,

the conﬁdence in the problem solution link is low as it is not externally evaluated. In step III in Figure 8,

the design knowledge is ampliﬁed by instantiating a solution in the form of a software artifact (Section

4.3), which is evaluated in demonstrations. This evaluation is extended in step IV in Figure 8 by both,

analyzing the behavior of library customers interacting with the artifact, and a focus group consisting

of library employees that evaluated the quality of the collected feedback (Section 4.4). This combina-

tion of quantitative and qualitative validations facilitates the conﬁdence in the problem solution link and

answers the second research question: It is found that the instantiated solution of the design principles

in the constructed system design (Section 4.2.5) results in a software artifact (Section 4.3) that is useful

(Section 4.4.1) and advances current systems by addressing the challenges identiﬁed in Section 4.1: i)

The applied incentives carry value for the participants (Section 4.4.3) and mobilise unaware-customers

of the library service to provide feedback, when compared to both, a control group and a treatment group

consisting of library customers (Section 4.4.3). Also, the combination of two incentives results in an

increase of feedback items (breadth) while improving the quality (depth) of collected feedback measured

in amount of contextualization actions (Section 4.4.3). ii) Feedback is highlighted by ranking unsolicited

feedback items (Section 4.4.1) and thus the visibility is increased; iii) Contextualizing solicited feedback

enables an identiﬁcation of important feedback and improving the quality of posed questions for solicited

feedback (Section 4.4.2).

5.2 Design principles revisited

The discussion of the previous section illustrates how the identiﬁed design principles facilitate the con-

struction of a CFS that is useful and improves the status quo of feedback provision. Table 10 illustrates

the identiﬁed design principles, their implementation in the software artifact, the evaluation of these

implementations and the associated ﬁndings.

Due to the Covid-19 policy at the research institute, physical interactions were restricted. Thus, the

physicality in the principle of cyber-physical interactions (ID 10 in Table 10) had not been facilitated in

the experiment. Nevertheless, the value of physical human interactions had been identiﬁed as important

for the stakeholders in the interviews (Section 4.1) and the design workshops (Section 4.2). Thus, we

recommend that the impact of mechanisms that require physical interactions for feedback provision

27

#

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

C. Design Principle

Ex.

Implementation

Eval.
U FG

Finding

e
r
t
u
c
u
r
t
s
a
r
f
n
I

k
c
a
b
d
e
e
F

n
o
i
t
c
a
r
e
t
n
I

Use a public and
trustworthy storage
Use a transparent
computing engine

Integrate into
exist. software stacks

Create a self-explantory UI

Enable contextualizton
of feedback

Focus on processes

Rank feedback

Visualize (feedb.) statistics
Combine solicited & unsol.
feedback collection

Enable cyber-physical
interactions

(Re)use already existing
pseudonymous identities

Build an opt-in system

Facilitate respect. behavior

Facilitate simple user input

Utilize incentives

Allow permissionless
code access

Enable personal interactions

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

x

Blockchain (Ethereum)

Smart Contracts

Library tool (feedback wall)
as entering point; ﬁnance
4.0 as infrastructure
Reused existing interfaces
(Google, Reddit, Stackover.)

Dedicated views

Process related topics in
solicited feedback
Up/ down voting of
unsolicited feedback
Dedicated statistics view

Dedicated views

Interactive answering
options; real-time digital
voting centers

Blockchain addresses

No force applied on users
to join
Nettiquette
Reused existing interfaces
(Google, Reddit, Stackover.)

Blockchain-based tokens

Published code on github

Comments on unsolicited
feedback; private messages

x

x

x

x

x

x

x

x

x

x

simple integr.
in exist. proces.

fast onboarding;
low-threshold
exhaustive; impr.
post-analysis

Enables
priorization
High usefulness
Quant. and
qual. eval

Low-threshold
in utilization
Improves quant.
and quality

Table 10: The Finalised Design Principles for customer feedback systems per category (C.) illustrating
if the principles have been applied in the artifact utilized in the experiment (EX.), how the principle has
been implemented in the software artifact (Implementation), if it has been evaluated by the users (U) or
focus group (FG), and the ﬁndings of these evaluations.

28

should be evaluated in future work.

Four of the design principles (ID 1, 2, 11, 15 in Table 10) are afforded by the blockchain technology

which illustrates the useability of this technology for CFS. In particular, blockchain-based cryptoeco-

nomic incentives represent a novel class of incentives that can motivate users to improve the breadth and

depth of shared feedback.

This work includes the existing unsolicited feedback provision mechanism of the library (library

wall, Section 4.1.3) to account for the design principle of integrating into existing software stacks (ID 3

in Table 10). This did not only facilitate the principle of simple integration into existing library processes,

but resulted also in the combination of solicited and unsolicited feedback prevision in one software

artifact. This has been identiﬁed by the experts of the focus group (FG4 in Table 1) as innovative and

useful. In particular, it facilitates the combination of quantitative and qualitative analysis. Because of

that, we added the principle of combining solicited and unsolicited feedback collection to the design

principles (ID 9 in Table 10).

The contextualization of feedback (ID in Table 10) has been evaluated by both, the experiment par-

ticipants and the focus group as useful. In particular, amongst others, it enables a differentiated post-

analysis of the feedback by comparing rating behavior of users based on the given contextualizations

(Section 4.4.2).

6 Conclusion

This paper argues that the feedback provision to organizations via software artifacts can be improved

by following the design principles identiﬁed in this work (Table 10). In particular, in this way a system

can be instantiated that is useable, motivates users to provide feedback and that improves the quality

of the collected information. By considering values of stakeholders explicitly in the design steps of

an established Design Science Research methodology, this work accounts for both, i) the alignment of

the created system with stakeholder values such as credibility and autonomy, and ii) an innovation in

the way how feedback is provided to organizations by means of blockchain-based incentivization and

contextualized information. Hence, the principles (Table 10) can be utilized by decision makers and

managers to create novel value-sensitive and status quo-improving customer feedback systems.

The results point to various avenues for future research. Firstly, the software artifact and the instanti-

ated system could be utilized in organizations other than libraries to evaluate the generality of the found

29

design principles and thus increase the conﬁdence in the problem-solution link. Secondly, the reduced

provision of unsolicited feedback by the control group when compared to the treatment group indicates a

crowding out of intrinsic motivation. This could be validated in future work by further analyzing the in-

terplay of the applied incentivizes. In particular, because we found that the quality of provided feedback

in form of contextualizations is improved by applying cryptoeconomic incentives while increasing the

quantity, future studies could investigate the impact of varying combinations of cryptoeconomic incen-

tives on the characteristics of provided feedback to identify an optimal combination of incentives. Third,

considering the importance of values for humans and the ﬁndings of this work, the DSR community

could theorize how value-sensitive design methods can be integrated in established DSR methodologies

to make design knowledge comparable across application domains and to enhance the conﬁdence in

problem-solution links.

References

Agarwal, R., & Karahanna, E. (2000). Time ﬂies when you’re having fun: Cognitive absorption and

beliefs about information technology usage. MIS quarterly, 665–694.

Anderson, C., & Brown, C. E.

(2010). The functions and dysfunctions of hierarchy. Research in

organizational behavior, 30, 55–89.

Ballandies, M. C., Dapp, M. M., Degenhart, B. A., & Helbing, D.

(2021).

Finance 4.0: Design

Principles for a value-sensitive Cryptoeconomic System to address sustainability . ECIS 2021

Research Papers, 62(62).

Ballandies, M. C., Dapp, M. M., Degenhart, B. A., Helbing, D., Klauser, S., & Pardi, A.-L. (2021).

Finance 4.0-a socio-ecological ﬁnance system. In Finance 4.0-towards a socio-ecological ﬁnance

system (pp. 53–89). Springer, Cham.

Ballandies, M. C., Dapp, M. M., & Pournaras, E.

(2021). Decrypting distributed ledger de-

sign—taxonomy, classiﬁcation and blockchain community evaluation. Cluster Computing, 1–22.

Ballandies, M. C., & Pournaras, E. (2021). Mobile link prediction: Automated creation and crowd-

sourced validation of knowledge graphs. Microprocessors and Microsystems, 87, 104335.

30

Birch-Jensen, A., Gremyr, I., & Halldórsson, Á. (2020). Digitally connected services: Improvements

through customer-initiated feedback. European Management Journal, 38(5), 814–825.

Burtch, G., Hong, Y., Bapna, R., & Griskevicius, V. (2018). Stimulating online reviews by combining

ﬁnancial incentives and social norms. Management Science, 64(5), 2065-2082.

Cai, L., & Zhu, Y. (2015). The challenges of data quality and data quality assessment in the big data era.

Data science journal, 14.

Casey, M. E., & Savastinuk, L. C. (2006). Library 2.0: Service for the next-generation library. Library

journal, 131(14), 40.

Celuch, K. G., Robinson, N., & Walz, A. (2011). In search of the gift of feedback: The moderating

role of trust on retailer-customer communication. In American marketing association educators’

proceedings (Vol. 22, pp. 494–501).

Chandratre, A., & Garg, S. (2019). Blockchain based course feedback system. SSRN Electronic Journal.

Chase, R. B., & Hayes, R. (1991). Beeﬁng up operations in service ﬁrms. Sloan Manage review, 33(1),

15–26.

Compeau, D. R., & Higgins, C. A. (1995). Computer self-efﬁcacy: Development of a measure and initial

test. MIS quarterly, 189–211.

Culnan, M. J. (1989). Designing information systems to support customer feedback: An organizational

message system perspective.

Dapp, M. M. (2019). Toward a sustainable circular economy powered by community-based incentive

systems. In Business transformation through blockchain (pp. 153–181). Springer.

Dapp, M. M., Helbing, D., & Klauser, S. (2021). Finance 4.0-towards a socio-ecological ﬁnance system:

A participatory framework to promote sustainability. Springer Nature.

de Langhe, B., Fernbach, P. M., & Lichtenstein, D. R. (2015, 09). Navigating by the Stars: Investigating

the Actual and Perceived Validity of Online User Ratings. Journal of Consumer Research, 42(6),

817-833. Retrieved from https://doi.org/10.1093/jcr/ucv047 doi: 10.1093/jcr/ucv047

Dobler, M., Ballandies, M., & Holzwarth, V. (2019). On the extension of digital ecosystems for scm

31

and customs with distributed ledger technologies requirements analysis, innovation assessment,

and prototype design for the lake constance region.

In 2019 ieee international conference on

engineering, technology and innovation (ice/itmc) (pp. 1–8).

Dresing, T., & Pehl, T. (2010). Transkription. In G. Mey & K. Mruck (Eds.), Handbuch qualitative

forschung in der psychologie (pp. 723–733). Wiesbaden: VS Verlag für Sozialwissenschaften.

Friedman, B., Howe, D. C., & Felten, E. (2002). Informed consent in the mozilla browser: Implementing

value-sensitive design.

In Proceedings of the 35th annual hawaii international conference on

system sciences (pp. 10–pp).

Friedman, B., Kahn, P. H., Borning, A., & Huldtgren, A. (2013). Value sensitive design and information

systems.

In Early engagement and new technologies: Opening up the laboratory (pp. 55–95).

Springer.

Friedman, B., Kahn Jr, P. H., & Borning, A. (2020). Value sensitive design and information systems. In

The ethics of information technologies (pp. 289–313). Citeseer.

Gipp, B., Breitinger, C., Meuschke, N., & Beel, J. (2017). Cryptsubmit: introducing securely times-

tamped manuscript submission and peer review feedback using the blockchain. In 2017 acm/ieee

joint conference on digital libraries (jcdl) (pp. 1–4).

Gössling, S., Hall, C. M., & Andersson, A.-C. (2018). The manager’s dilemma: a conceptualization of

online review manipulation strategies. Current Issues in Tourism, 21(5), 484–503.

Hänggli, R., Pournaras, E., & Helbing, D. (2021). Human-centered democratic innovations with digital

and participatory elements. In Dg. o2021: The 22nd annual international conference on digital

government research (pp. 227–233).

Harbers, M., & Neerincx, M. A.

(2017). Value sensitive design of a virtual assistant for workload

harmonization in teams. Cognition, Technology & Work, 19(2), 329–343.

Hevner, A., & Chatterjee, S. (2010). Design science research in information systems. In Design research

in information systems (pp. 9–22). Springer.

Hevner, A. R., March, S. T., Park, J., & Ram, S. (2004). Design science in information systems research.

32

MIS quarterly, 75–105.

Hu, H.-H., Parsa, H., Chen, C.-T., & Hu, H.-Y. (2016). Factors affecting employee willingness to report

customer feedback. The Service Industries Journal, 36(1-2), 21–36.

Hu, N., Zhang, J., & Pavlou, P. A. (2009, October). Overcoming the j-shaped distribution of product

reviews. Commun. ACM, 52(10), 144-147.

Huldtgren, A. (2015). Design for values in ict. Handbook of Ethics, Values, and Technological Design,

739–767.

Hunhevicz, J. J., Schraner, T., & Hall, D. M. (2020). Incentivizing high-quality data sets in construction

using blockchain: A feasibility study in the swiss industry. In Isarc. proceedings of the interna-

tional symposium on automation and robotics in construction (Vol. 37, pp. 1291–1298).

Ittner, C. D., & Larcker, D. F.

(2003). Coming up short on nonﬁnancial performance measurement.

Harvard business review, 81(11), 88–95.

Khatri, N. (2009). Consequences of power distance orientation in organisations. Vision, 13(1), 1–9.

Kleineberg, K.-K., & Helbing, D. (2021). A “social bitcoin” could sustain a democratic digital world.

In Finance 4.0-towards a socio-ecological ﬁnance system (pp. 39–51). Springer, Cham.

Kranz, J., Nagel, E., & Yoo, Y. (2019, apr). Blockchain token sale. Business & Information Systems

Engineering, 61(6), 745–753. doi: 10.1007/s12599-019-00598-z

Lafky, J., & Wilson, A. J.

(2020, jan). Experimenting with incentives for information transmission:

Quantity versus quality. Journal of Economic Behavior & Organization, 169, 314–331.

Lämmer, S., & Helbing, D. (2008). Self-control of trafﬁc lights and vehicle ﬂows in urban road networks.

Journal of Statistical Mechanics: Theory and Experiment, 2008(04), P04019.

Maedche, A. (2017). Interview with prof. jeroen van den hoven on “why do ethics and values matter in

business and information systems engineering?”. Business & Information Systems Engineering,

59(4), 297–300.

Miller, J. K., Friedman, B., Jancke, G., & Gill, B. (2007). Value tensions in design: the value sensitive

design, development, and appropriation of a corporation’s groupware system. In Proceedings of

33

the 2007 international acm conference on supporting group work (pp. 281–290).

Mita, M., Ito, K., Ohsawa, S., & Tanaka, H. (2019). What is stablecoin?: A survey on price stabilization

mechanisms for decentralized payment systems. In 2019 8th international congress on advanced

applied informatics (iiai-aai) (pp. 60–66).

Muchnik, L., Aral, S., & Taylor, S. J. (2013). Social inﬂuence bias: A randomized experiment. Science,

341(6146), 647-651.

Mudambi, S., & Schuff, D. (2010, 03). What makes a helpful online review? a study of customer reviews

on amazon.com. MIS Quarterly, 34, 185-200. doi: 10.2307/20721420

Naumzik, C., Feuerriegel, S., & Weinmann, M. (2021). I will survive: Predicting business failures from

customer ratings. Marketing Science.

Önder, I., Treiblmaier, H., et al. (2018). Blockchain and tourism: Three research propositions. Annals

of Tourism Research, 72(C), 180–182.

Osterloh, M., & Frey, B. S. (2000). Motivation, knowledge transfer, and organizational forms. Organi-

zation science, 11(5), 538–550.

Ostern, N. K., & Riedel, J.

(2020, dec). Know-your-customer (KYC) requirements for initial coin

offerings. Business & Information Systems Engineering. doi: 10.1007/s12599-020-00677-6

O’Connor, C., & Joffe, H. (2020). Intercoder reliability in qualitative research: debates and practical

guidelines. International Journal of Qualitative Methods, 19, 1609406919899220.

Parasuraman, A. P., Zeithaml, V., & Berry, L. (1985, 01). A conceptual model of service quality and its

implication for future research (servqual). The Journal of Marketing, 49, 41-50.

Peffers, K., Tuunanen, T., Rothenberger, M. A., & Chatterjee, S. (2007). A design science research

methodology for information systems research. Journal of management information systems,

24(3), 45–77.

Pournaras, E. (2020). Proof of witness presence: blockchain consensus for augmented democracy in

smart cities. Journal of Parallel and Distributed Computing, 145, 160–175.

Rahman, M. M., Rifat, M. M. H., Tanin, M. Y., & Hossain, N. (2020, dec). A feedback system using

34

blockchain technology. In 2020 3rd international conference on intelligent sustainable systems

(ICISS). IEEE. doi: 10.1109/iciss49785.2020.9315989

Robinson, N.

(2013). Understanding customer engagement: What makes customers more likely to

provide feedback to an organization in the services sector.

Rössner, M., Dapp, M. M., & Fach, F. (2018). Prospects of distributed ledger systems: Requirements

engineering and analysis of existing mechanisms for multidimensional incentive systems (ﬁnance

4.0): Project studies in management and technology. ﬁnal report. Research Collection.

Sampson, S. E. (1999). An empirically deﬁned framework for designing customer feedback systems.

Quality Management Journal, 6(3), 64-80.

Schneider, C., Weinmann, M., Mohr, P. N., & vom Brocke, J. (2021). When the stars shine too bright:

The inﬂuence of multidimensional ratings on online consumer ratings. Management Science,

67(6), 3871-3898.

Simonson, I. (2016, 04). Imperfect Progress: An Objective Quality Assessment of the Role of User Re-

views in Consumer Decision Making, A Commentary on de Langhe, Fernbach, and Lichtenstein.

Journal of Consumer Research, 42(6), 840-845.

Sonnenberg, C., & Brocke, J. v. (2011). Evaluation patterns for design science research artefacts. In

European design science symposium (pp. 71–83).

Sonnenberg, C., & Vom Brocke, J. (2012). Evaluations in the science of the artiﬁcial–reconsidering the

build-evaluate pattern in design science research. In International conference on design science

research in information systems (pp. 381–397).

Stoica, E. A., & Özyirmidokuz, E. K. (2015). Mining customer feedback documents. International

Journal of Knowledge Engineering, 1(1), 68–71.

Sun, H., Wright, R. T., & Thatcher, J. (2019). Revisiting the impact of system use on task performance:

An exploitative-explorative system use framework. Journal of the Association for Information

Systems, 20(4), 3.

Sunyaev, A., Kannengießer, N., Beck, R., Treiblmaier, H., Lacity, M., Kranz, J., . . . Luckow, A. (2021).

35

Token economy. Business & Information Systems Engineering, 1–22.

Thatcher, J. B., Zimmer, J. C., Gundlach, M. J., & McKnight, D. H. (2008). Internal and external dimen-

sions of computer self-efﬁcacy: An empirical examination. IEEE Transactions on Engineering

Management, 55(4), 628–644.

Van den Hoven, J., Vermaas, P. E., & Van de Poel, I. (2015). Handbook of ethics, values and technolog-

ical design. Handbook of Ethics, Values, and Technological Design.

Van de Poel, I.

(2015). Conﬂicting values in design for values. Handbook of ethics, values, and

technological design: Sources, theory, values and application domains, 89–116.

VanGundy, A. B. (1984). Brain writing for new product ideas: an alternative to brainstorming. Journal

of Consumer Marketing.

Vargo, S. L., & Lusch, R. F.

(2004). Evolving to a new dominant logic for marketing. Journal of

Marketing, 68(1), 1-17.

Venkatesh, V., Thong, J. Y., & Xu, X. (2012). Consumer acceptance and use of information technology:

extending the uniﬁed theory of acceptance and use of technology. MIS quarterly, 157–178.

Vom Brocke, J., Winter, R., Hevner, A., & Maedche, A. (2020). Special issue editorial–accumulation

and evolution of design knowledge in design science research: A journey through time and space.

Journal of the Association for Information Systems, 21(3), 9.

Wirtz, J., & Tomlin, M.

(2000).

Institutionalising customer-driven learning through fully integrated

customer feedback systems. Managing Service Quality: An International Journal.

Zargahm, M. (2018). Creating interconnected collaborative communities. Retrieved from https://www

.youtube.com/watch?v=nOP6anxiHkk (Future of Trust Summit. Hall of Knights, The Hague.)

Zavolokina, L., Spychiger, F., Tessone, C. J., & Schwabe, G.

(2018).

Incentivizing data quality in

blockchains for inter-organizational networks–learning from the digital car dossier.

Zhuang, M., Cui, G., & Peng, L. (2018). Manufactured opinions: The effect of manipulating online

product reviews. Journal of Business Research, 87, 24–35.

36

