A Survey on Sustainable Software Ecosystems to
Support Experimental and Observational
Science at Oak Ridge National Laboratory⋆

David E Bernholdt[0000−0001−7874−3064],
Mathieu Doucet[0000−0002−5560−6478],
William F Godoy[0000−0002−2590−5178],
Addi Malviya-Thakur[0000−0002−2681−9992], and
Gregory R Watson[0000−0002−8591−2441] ⋆⋆

Oak Ridge National Laboratory
Oak Ridge TN, 37830 USA
https://www.ornl.gov

Abstract. In the search for a sustainable approach for software ecosys-
tems that supports experimental and observational science (EOS) across
Oak Ridge National Laboratory (ORNL), we conducted a survey to un-
derstand the current and future landscape of EOS software and data.
This paper describes the survey design we used to identify signiﬁcant ar-
eas of interest, gaps, and potential opportunities, followed by a discussion
on the obtained responses. The survey formulates questions about project
demographics, technical approach, and skills required for the present and
the next ﬁve years. The study was conducted among 38 ORNL partici-
pants between June and July of 2021 and followed the required guidelines
for human subjects training. We plan to use the collected information
to help guide a vision for sustainable, community-based, and reusable
scientiﬁc software ecosystems that need to adapt eﬀectively to: i) the
evolving landscape of heterogeneous hardware in the next generation of
instruments and computing (e.g. edge, distributed, accelerators), and ii)
data management requirements for data-driven science using artiﬁcial
intelligence.

Keywords: Scientiﬁc Software Ecosystem · Experimental and Observa-
tional Science EOS · Sustainability· Survey.

1

Introduction

2
2
0
2

r
p
A
2
1

]
E
S
.
s
c
[

1
v
6
9
8
5
0
.
4
0
2
2
:
v
i
X
r
a

Computational science and engineering (CSE) is well-established as a compute,
data, and software-intensive approach to scientiﬁc research with decades of his-
tory behind it. Traditionally, the software and data aspects of CSE have been
⋆

This manuscript has been authored by UT-Battelle, LLC, under contract DE-AC05-
00OR22725 with the US Department of Energy (DOE). The publisher acknowledges
the US government license to provide public access under the DOE Public Access
Plan (https://energy.gov/downloads/doe-public-access-plan).

⋆⋆ These authors contributed equally to this work.

 
 
 
 
 
 
2

D.E. Bernholdt, M. Doucet, et al.

marginalized, as incentive systems have emphasized novel scientiﬁc results over
considerations related to the software and data that underpin them or indeed the
skills and expertise of the people who develop the software. However, in recent
years, there has been a trend to improve this through an increased understanding
of the importance of the software and data to achieve high quality, trustworthy,
and reasonably reproducible scientiﬁc results.

Experiment and observation have a far longer history in the conduct of scien-
tiﬁc research than computationally-based approaches. As computing has become
more capable and accessible, experimental and observational science (EOS) has
also progressively expanded its use of software and computing for instrument
control, data collection, reduction, analysis; data management; and other activ-
ities. It would not be a stretch to say that modern EOS relies on software as
much as computational science, but with diﬀerences in complexity and scale.
Therefore, as new approaches in instrumentation, and enhanced computational
capabilities make feasible novel and more complex experiments, the reliance on
software and computing in many areas of EOS is growing rapidly [18,3,2,13]. In
addition, EOS researchers are increasingly seeking to harness high-performance
computing (HPC) that had historically been the province of computational sci-
entists to deal with rapidly increasing data volumes. Modeling and simulation
techniques originated in the CSE community are widely used to help understand
and interpret EOS data [18,9]. As a result, the EOS community is transforming
towards an increasing software- and compute-intensity level.

This paper represents the results of a small survey targeting EOS-focused
staﬀ within one organization that is focused heavily on EOS: Oak Ridge National
Laboratory (ORNL). ORNL is the largest multi-program laboratory under the
U.S. Department of Energy (DOE) Oﬃce of Science. The survey attempts to
identify challenges facing EOS software stakeholders and how they anticipate
the situation evolving over a ﬁve-year time frame. The structure of the paper is
as follows: Section 2 presents background information on the need for software
ecosystems in related ﬁelds, while a brief description of the current landscape of
software ecosystems in scientiﬁc computing is also presented in anticipation of
the survey responses. Next, an overview of the survey structure, methodology
and questions is described in Section 3. Next, results from the survey and a
discussion is presented in Section 4. This section is perhaps the most important
in the report as we attempt to craft a narrative and interpretation by correlating
the overall answers. Lastly, our conclusions from the survey results and analysis
are presented in Section 5 outlining the most important takeaways from the
collected data.

2 Background

Software ecosystems are an increasingly important component of scientiﬁc en-
deavors, particularly as computational resources have become more available
to include simulations and data analysis in research [17]. Nevertheless, there
is still debate of what constitutes a “software ecosystem”. Dhungana et al. [7]

Survey Software Eco EOS ORNL

3

points out the similarities between software and natural ecosystems. Monteith et
al. [19] indicates that scientiﬁc software ecosystems incorporate a large environ-
ment that includes not only software developers, but also scientists who both use
and extend the software for their research endeavors. Therefore, it is important
to acknowledge the diﬀerent needs and goals of these groups when considering
the broad breadth of scientiﬁc software. Hannay et al. [10] asserts that there is a
great deal of variation in the level of understanding of software engineering con-
cepts when scientists develop and use software.Kehrer and Penzenstadler [15]
explore individual, social, economic, technical and environmental dimensions to
provide a framework for sustainability in research software. As described by Don-
garra et al. [8], the high-performance computing (HPC) community identiﬁed in
the last decade the need for an integrated ecosystem in the exascale era. Eﬀorts
resulted in the DOE Exascale Computing Project (ECP) [1]. Within the scope
of ECP, the Extreme-scale Scientiﬁc Software Stack (E4S) [12] aims to reduce
barriers associated with software quality and accessibility in HPC.

Few studies have been carried out to assess EOS software ecosystems, so
it is necessary to draw from experiences in other communities. A critical part
of a software ecosystem are the developers themselves, since they play a cru-
cial role that requires establishing sustainable collaborative relationships within
the community. Sadi et al. [20] draws from test cases on mobile platforms to
provide an in-depth analysis of developers’ objectives and decision criteria for
the design of sustainable collaborations in software ecosystems. The guidelines
to pursue requirements for a software ecosystem is discussed by Kaiya [14] to
allow for a decrease in eﬀort, increase of gain, sustainability and increase in
participation of developers in an engaging conversation. Empirical assessments
of how modern software and data practices are used in science are provided in
recent studies [11,16,22]. Software ecosystems can be vast and have been con-
tinuously evolving through the development of new processes, inventions, and
governance [5]. Therefore it is important that scientiﬁc communities develop a
tailored plan that relies on software reuse and development of an interdepen-
dent [6] and component-centric [21] software ecosystem that understands the
goals and needs within the context of EOS.

3 Survey Overview

3.1 Survey Motivation

As a preeminent scientiﬁc research organization, ORNL uses and creates a great
deal of the software used to undertake CSE. Software is central to modern EOS
for data acquisition, reduction, analysis, distribution, and related modeling and
simulation used for CSE. However, instruments and sensors are growing more
capable and sophisticated and experiments more complex. At the same time, the
computing landscape is also changing, with a transition towards “edge” systems
that are situated closer to the experiments, and the increasing use of cloud and
HPC resources. These factors drive complexity in software and consequently cre-
ate greater challenges for developers. In order to better understand this changing

4

D.E. Bernholdt, M. Doucet, et al.

landscape, we decided to conduct a Software Ecosystem Survey. The goal was to
collect a range of information about immediate and future development needs,
the environmental factors inﬂuencing these needs, and the skills and training
necessary for developer teams to be able to eﬀectively work in these changing
environments. We hope to use the information collected from the survey to im-
prove participation and collaboration in software ecosystems and aid in creating
sustainable software as we enter an exciting new frontier of scientiﬁc discovery.

3.2 Survey Design

The survey is organized into 10 major sections for a total of 34 questions.
Responses are completely anonymous and meet the requirements for conduct-
ing ethical human-subject research studies. The survey design was focused on
multiple-choice questions and answers, allowing the taker to register quickly and
eﬃciently. The survey is exhaustive and might take up to 45 minutes to complete.
The survey begins with the description and motivation so that participants
understand what the survey is trying to achieve as well as what information
is expected from them. The survey then asks a series of questions to provide
background information and project demographics to understand the nature of
the software project and its contributors. A series of questions relating to the
technical approach used by the project are asked in order to understand current
software and data needs and challenges. Next, there are questions to understand
the current skill levels and how new skills are acquired among software project
participants. Finally, questions about the future demographics, future technical
approach, and preparations for the future are formulated to understand the
leading technological disruptions and the signiﬁcant challenges projects will be
facing in the next ﬁve years. In addition, we formulated questions on conﬁdence
to address current and future challenges at a personal and team level. The survey
was developed using Google FormsTM and the responses were recorded over the
course of a few weeks.

3.3 Selection of Participants

We invited individuals at ORNL working across diverse scientiﬁc domains devel-
oping research software to participate in this survey. This included developers
from nuclear energy, biostatistics, transportation, building technology, geospa-
tial analytics, among several others. Almost all of the invited participants had
experience developing scientiﬁc software and were part of the broader software
development community. The participants’ anonymity was maintained by ex-
cluding any personal or work related information.

4 Survey Results

We received a total of 38 responses to the survey (raw results available at [4]).
None of the questions were required, so the number of responses to speciﬁc

Survey Software Eco EOS ORNL

5

Table 1. Responses to time percentage spent using or developing software.

Research Software
Activity
Using
Developing

0-20%
34.2%
21.2%

Time percentage
21-40%
23.7%
13.2%

41-60% 61-80% 81-100%
18.4% 13.2%
23.7% 13.2%

10.5%
28.9%

questions may in some cases, be fewer, which we will indicate as necessary. For
questions about the project demographics and technical approach, we asked both
about the current situation and the situation expected ﬁve years from now.

4.1 Background Information

This survey section consists of three questions to identify the respondents’ rela-
tionship with scientiﬁc software activities and roles. The ﬁrst question attempts
to classify the respondents’ work in relation to software. Overall, 71% of respon-
dents indicated that research software is a primary product of their work, while
29% indicated it is not. The other two questions asked respondents to character-
ize the portion of their work time spent using or developing research software.
Table 1 shows that 67% of the respondents spend at least 41% of their time as
developers. We take this as a good indication that the survey respondents are in
our target audience.

4.2 Project Demographics

In the remainder of the survey, we asked respondents to focus on the single
research software development project that they considered most signiﬁcant in
their work, as the Project Demographics section of the survey was intended
to characterize aspects of their particular project. Overall, 82% of respondents
reported that they were users of the software as well as developers, whereas 18%
were exclusively developers. This is consistent with our informal observations of
computational science and engineering, where the majority of developers are also
users. Looking ﬁve years out, respondents had essentially the same expectations
(81% and 19%).

Table 2 illustrates responses to questions about the size of the development
team, in terms of the overall number of active developers on the project and the
number of those developers the respondent interacts with on a regular (weekly)
basis. The results show that roughly two-thirds (58%) of projects are comprised
of no more than 3 developers, and even on larger projects, the majority (68%)
regularly interact with no more than 3 team members. However, there are also
a considerable minority of software project teams (18%) with more than 10
developers.

We also tried to characterize the organizational breadth of the project teams.
Table 3 shows that the majority of projects are of multi-institutional nature.
Of the project teams comprised exclusively of ORNL staﬀ members, the largest

6

D.E. Bernholdt, M. Doucet, et al.

Table 2. Number of developers in a project and how many of these interact weekly
with the respondent.

Developers that are:
Active including
the respondent

Interacting weekly
with the respondent

People
1

0

2-3

4-5

6-10

> 10

n/a

10.5% 47.4% 18.4% 5.3% 18.4%

7.9% 21.1% 39.5% 18.4% 10.5% 2.6%

Table 3. Organizational breadth of research software projects. Organizational units
within ORNL are listed from smallest (group) to largest (directorate). The “ORNL”
response denotes teams spanning multiple directorates.

Breadth
all developers within
Group
Section
Division
Directorate
Whole lab
Multiple institutions

Typical
Size
8-10 staﬀ
3-4 groups
3-4 sections
2-4 divisions
8 science directorates

Current
Percentage
13%
8%
0%
8%
16%
55%

Expected
in Five Years
8%
0%
3%
3%
3%
84%

number included staﬀ from multiple directorates (the largest organizational level
at ORNL), but the next largest number included staﬀ from a single group (the
smallest organizational level). Our informal observation is that in CSE at ORNL,
the majority of projects are also multi-institutional. This is an indicator that
while some of the software serves ORNL speciﬁc scientiﬁc purposes, a large por-
tion exposes the team to outside organizations that could help leverage common
software development activities via collaboration. It is interesting to observe
that in ﬁve years, there are expectations for a strong shift towards more broadly
based project groups, particularly multi-institutional teams.

The DOE Oﬃce of Science deﬁnes a user facility as “a federally sponsored re-
search facility available for external use to advance scientiﬁc or technical knowl-
edge.”1 The DOE stewards a signiﬁcant number of the user facilities in the
United States, nine of which are hosted at ORNL2 and were targeted in our
distribution of the survey. We asked respondents whether their research soft-
ware was intended for use at a user facility (whether at ORNL, within the DOE
system, or elsewhere). Only 8% of respondents indicated that their software did
not target a user facility. The remainder indicated that the software was used in
their own work at a user facility (13%), or by multiple users (47%). A quarter of
respondents (26%) indicated that their software was part of the software suite
that the facility oﬀers to its users.

1 https://science.osti.gov/User-Facilities/Policies-and-Processes/Definition
2 https://www.ornl.gov/content/user-facilities

Table 4. Characteristics considered to be of moderate or higher importance to the
software projects.

Survey Software Eco EOS ORNL

7

Characteristic
Functionality
Usability
Maintainability or Sustainability
Performance
Portability
Security

Current
Percentage
97%
87%
87%
89%
53%
21%

Expected
in Five Years
97%
89%
89%
92%
34%
34%

Table 5. Analysis of free-form responses asking for additional important characteristics
not included in the original six. The authors consider most of the proposed character-
istics could be included in one of the original six, while two could not.

Response
Unique capabilities
Documentation
Intuitive
Robustness
Extensibility
Accuracy
Correctness

Occurrences Original Characteristic

1
2
1
1
1
1
1

Functionality
Usability
Usability
Usability
Maintainability or Sustainability
n/a
n/a

Finally, we asked the respondents to rate the importance of various software
characteristics as summarized in Table 4. The importance of most of these char-
acteristics is expected to be about the same looking out ﬁve years, except that
portability drops and security increases in importance. Given an opportunity
to suggest additional “moderate importance or higher” characteristics, we re-
ceived 7 responses (some multiple listing characteristics). We consider that some
of the responses could be consolidated into the original list of characteristics,
while others would be new additions. The free-form responses are characterized
in Table 5.

4.3 Project Technical Approach

This section included six questions related to the technical aspects of the project
and its environment.

First, we asked respondents to indicate the various technical categories ap-
plied to their software project. Multiple categories could be selected, and a free-
response option was allowed so respondents could add categories not included
in the original list. Table 6 summarizes the results. Not surprisingly, for a sur-
vey focused on EOS, data processing and analysis is by far the most common
category used to describe the software. The prominence of data reduction and in-
teraction, each considered applicable to 50% of projects. Interestingly, tools and

8

D.E. Bernholdt, M. Doucet, et al.

Table 6. Categories applicable to the focus software project. The last two were pro-
vided as free-form additions to the list.

Category
Data acquisition
Data reduction
Data processing and analysis
Data interaction (e.g., Jupyter notebooks, graphical
or web interfaces, etc.)
Data dissemination or sharing
Modeling and simulation
Numerical libraries
Tools and infrastructure
Deep learning, machine learning, text analysis
Optimization

Current
Percentage
31%
50%
74%
50%

Expected
in Five Years
47%
55%
79%
55%

21%
46%
21%
50%
3%
3%

29%
60%
45%
55%
3%
3%

infrastructure, modeling, and simulation were also similarly prominent (50% and
47%, respectively). “Modeling and simulation” is a term often used to character-
ize applications in CSE, and may indicate fairly routine use of these techniques in
the analysis of experimental and observational data. The number of projects cat-
egorized as tools and infrastructure was unexpectedly large. We plan to explore
both of these categories in greater depth in follow-up studies. It is interesting to
note that looking out ﬁve years, nearly every category increases, suggesting an
expectation that the projects will broaden in terms of the capabilities and thus
more categories will apply in the future. The largest growth areas are expected
to be in numerical libraries and data acquisition.

We also asked several questions intended to elicit the importance of various
technologies or approaches to the software projects. The ﬁrst question asked for
an assessment of the importance of eight explicitly named technologies (on a
4-point scale), while the second questions was request for a free-form response.
Table 7 shows the number and percentage of the 38 survey respondents who
indicated that each technology was of moderate or higher importance (responses
of 3 or 4). This question was intended to gauge the extent of technologies we
thought might be “emergent” in this community. We were not surprised to see
that continuous integration/deployment was essential to most of the projects
(76%), followed by numerical libraries (66%) as many EOS eﬀorts require fairly
sophisticated numerical approaches. Data storage and interaction technologies
were also important (55% and 63%, respectively). Cloud-based deployment is
only relevant to roughly one-third of the respondents (32%) and only a small
minority (5%) rated cloud application programming interface (API) services as
important, despite growing trends in cloud computing technologies in the last
decades. This can be interpreted due to either lack of expertise in available
cloud technologies, or that the cost of migrating operations might not justify
the added value to the funded science deliverables. This is something we plan to
explore further in follow-up studies. Looking ahead ﬁve years, all of the listed

Table 7. Technologies considered to be of moderate or higher importance to the soft-
ware projects.

Survey Software Eco EOS ORNL

9

Technology
Data storage
Data interaction (e.g., Jupyter notebooks, graphical
or web interfaces, etc.)
Data dissemination or sharing
Continuous integration/continuous deployment
Server-based deployment and operation
Cloud deployment and operation (using cloud re-
sources to make the software available to users)
Numerical
libraries (using library-based APIs as
part of your software solution, for example BLAS,
solvers, etc.)
Use of cloud API services (using cloud-based APIs
as part of your software solution, for example, GCP
Life Sciences API, Vision API, Treﬂe API, GBIF
API, etc.)

Current
Percentage
55%
63%

Expected
in Five Years
66%
68%

39%
76%
45%
32%

66%

5%

58%
79%
53%
42%

82%

37%

technologies are expected to increase in their importance to software projects.
The largest growth is expected in the importance of cloud API services, with
numerical libraries, data dissemination or sharing, and cloud deployment and
operation technologies also signiﬁcantly increased in importance.

The free-form version of the question was included with the expectation that
a wide range of technologies would be considered useful to diﬀerent projects. A
total of 33 of the 38 respondents answered this question, listing a total of 69
distinct items, many appearing in multiple responses. For the sake of brevity,
we have assigned the responses to categories, which are listed in Table 8. We
note that there is no unique and unambiguous way to categorize the tools and
technologies named in the responses, but in this paper, our goal is to provide
an overview; the speciﬁc responses are available in the survey dataset [4]. We
note that application frameworks, libraries, and software development tools play
signiﬁcant roles in the software projects surveyed. Python is also prominent, as
are data tools, and artiﬁcial intelligence (AI) tools.

We also asked respondents to indicate the programming languages used in
their projects. Overall, 37 of the 38 survey respondents answered this free-form
question, naming a total of 58 distinct languages, 22 unique. Python and C++
were the most prominent languages, cited by 78% and 54% of the responding
projects, respectively. C and Javascript followed, listed in 16% and 14% of re-
sponses, respectively; Java and bash were the only other languages listed more
than once (8% and 5%). Programming for GPUs was noticeable as well, but
diverse approaches were named (CUDA, HIP, Kokkos, OpenACC, OpenMP).

Finally, in this section of the survey, we asked about the computational envi-
ronments targeted by the project. Respondents could select from ﬁve pre-deﬁned

10

D.E. Bernholdt, M. Doucet, et al.

Table 8. Important technologies for the respondents’ software projects, as catego-
rized by the authors. There were a total of 69 unique technologies identiﬁed by the
respondents.

Technology Category
AI tools
Application Frameworks
Build and test tools
Computational Notebook Tools
Data tools
Deployment tools
Hardware
Libraries
Python modules
Software Development tools

Responses Percentage

6
9
5
2
8
1
2
15
7
14

9%
13%
7%
3%
12%
1%
3%
22%
10%
20%

responses as well as being able to provide a free-form response (four were re-
ceived). The results are summarized in Table 9. Here, we see that individual
computers dominate, but in many cases, accelerators (e.g., GPUs, or FPGAs)
are used. However usage of larger shared resources is also high. About a third
of project target cloud computing, which is consistent with the response to an
earlier question in which a third of respondents also rated cloud deployment
and operation technologies as important to their projects (Table 7). The use
of GPU accelerators is consistent with the use of GPU programming languages
as well. Looking out ﬁve years, we see that respondents are generally expecting
decreased use of single computers in favor of most other types of hardware, most
signiﬁcantly large-scale cloud and HPC environments.

4.4 Skills and Training

This section gauges their assessment of their own knowledge and that of their
project team as a whole in various, as well as the areas in which new knowledge
would be important. We requested responses on a 4-point scale ranging from
“not knowledgeable” (1) to “very knowledgeable” (4), or “not important” (1)
to “very important” (4). Table 10 summarizes the responses of 3-4 for personal
knowledge, team knowledge, and the importance of acquiring new knowledge.
Respondents are fairly conﬁdent in both their own and their team’s knowledge
of most areas. The weakest area was computer hardware, which also scored
the lowest in terms of the importance of improving knowledge. Respondents
were somewhat more comfortable with their (and their teams’) knowledge of
the science, algorithms, and software tools for their work than with software
development practices. However software development practices and algorithms
rated slightly higher than the science and software tools in terms of areas needing
more knowledge.

Table 9. Hardware environments targeted by the projects. Respondents could select
any choices that applied, the last two entries were provided as free-form responses.

Survey Software Eco EOS ORNL

11

Hardware Environment Target
Single computer (laptop, desktop, or server)
Single computer with computational accelerator
(e.g., GPU, FPGA, etc.)
Shared organizational resource (e.g., multipro-
cessor server or cluster, “edge” systems, etc.)
Lab-level, national, or commercial cloud re-
sources (e.g., CADES cloud, AWS, etc.)
Lab-level, or national HPC resources (e.g.,
CADES condos, OLCF, etc.)
Neuromorphic processors
Quantum processors
Dedicated computational infrastructure for on-
line analysis of experimental data (cpu + gpu
+fpga)
Resources/infrastructure frozen for the duration
of the experiment

Current
Percentage
68%
40%

Expected
in Five Years
60%
50%

63%

34%

47%

3%
0%
3%

0%

66%

53%

63%

3%
3%
0%

3%

4.5 Preparing for the Future

The ﬁnal section of the survey asked respondents about their concerns about
their projects in the next ﬁve years, and their overall conﬁdence level in being
able to deal with the changes they anticipate.

As we see in Table 11, the most signiﬁcant area of concern has to do with the
performance of the software, followed by changes in the hardware environment
and the requirements for the maintainability or sustainability of the software.
Concerns about changes in the hardware environment here are noteworthy, given
the fact that in Table 10 respondents were both least conﬁdent in their personal
and their team’s knowledge of the hardware, and ranked it the least important

Table 10. Self-assessed level of knowledge in various areas for the respondent and their
team, and the perceived importance of gaining new knowledge in the area.

Area
The scientiﬁc context of the software
The algorithms and methods required to implement
the software
The software frameworks, libraries, and tools to sup-
port the implementation of the software
Software development best practices
The computer hardware to which the software is tar-
geted (including cloud computing, if appropriate)

Personal

Team
Knowledge Knowledge Knowledge
95%
84%

69%
74%

84%
84%

New

79%

68%
58%

82%

79%
66%

71%

74%
55%

12

D.E. Bernholdt, M. Doucet, et al.

Table 11. Levels of concern about various possible changes in their projects over the
next ﬁve years. Responses were on a 4-point scale from “not concerned” (1) to “very
concerned” (4). We summarize the responses of moderate or high concern (3-4).

Aspect
Changes in the hardware environment
Changes in the scientiﬁc context
Changes in the required functionality of the software
Changes in the required usability of the software
Changes in the required maintainability or sustainability of the
software
Changes in the required performance of the software
Changes in or increased importance of data storage technologies
Changes in or increased importance of numerical libraries
Changes in or increased importance of data interaction technolo-
gies (e.g., Jupyter notebooks, graphical or web interfaces, etc.)
Changes in or increased importance of continuous integra-
tion/continuous deployment technologies
Changes in or increased importance of cloud for making the soft-
ware available to users
Changes in or increased importance of the use of cloud API ser-
vice technologies

Responses Percentage

23
12
23
21
23

25
18
16
19

17

16

13

61%
32%
61%
55%
61%

66%
47%
42%
50%

44%

42%

34%

area in which to gain more knowledge. The areas of least concern were the
scientiﬁc context of the project (which was also an area of high conﬁdence in
Table 10) and in cloud service APIs. The low concern about cloud service APIs
may be explained by their low importance in Table 7.

When asked how conﬁdent they were as individuals in their ability to deal
with the changes anticipated over the next ﬁve years, a signiﬁcant portion (63%)
responded that they were moderately conﬁdent (3 on a 4-point scale), and one-
ﬁfth of the respondents (19%) were highly conﬁdent. When asked about their
team’s ability to deal with the coming changes, the majority (79%) are conﬁdent,
with 42% being moderately conﬁdent and 37% highly conﬁdent.

5 Conclusions

Our survey attempts to provide empirical evidence to understand the landscape
of the software supporting EOS activities at a major research laboratory. Results
suggest that the ﬁeld is still focused on classical computing approaches. More
recent developments in computing that are the norm outside of science, like AI,
edge computing, and cloud-based services, are still not being used extensively in
existing projects. On the other hand, the ﬁeld is clearly moving towards a broad
collaborative approach. Projects tend to be multi-institutional and beneﬁt a
wider array of users. At the same time, most projects are comprised of a handful
of developers, and most project interactions tend to be between a few developers.
This highlights the niche nature of highly-specialized scientiﬁc software. We have

Survey Software Eco EOS ORNL

13

also seen that data dissemination and sharing are becoming a focus across a
range of scientiﬁc endeavors. In addition, projects feel conﬁdent that they will
tackle challenges in the next ﬁve-year time frame. We understand these results
as a reﬂection of the alignment to sponsors’ expectations, for which its impact on
ORNL EOS deliverables must justify investments in aspects of scientiﬁc software
shown in this survey. In the future, we would like to use the insights gained
from this survey to better support EOS developers and develop guidelines for a
sustainable EOS software and data ecosystem.

References

1. Exascale computing project. https://exascaleproject.org/ (September 2017)
and
2. Open

second

ﬁrst

observing
SoftwareX 13,

runs
100658

of Ad-
(2021).

data

from the
vanced LIGO and Advanced Virgo.
https://doi.org/10.1016/j.softx.2021.100658

3. Special

issue

on

software

that

discovery.
https://www.sciencedirect.com/journal/softwarex/special-issue/103XKC9DRLV

SoftwareX (2021),

article

be

contributed
collection

to
can

gravitational wave
at

accessed

4. A survey

on

sustainable

software

ecosystems

to

tal and observational
https://doi.org/10.6084/m9.ﬁgshare.19529995

science at oak ridge national

support

experimen-
laboratory (2022).

5. Bartlett, R., Demeshko, I., Gamblin, T., Hammond, G., Heroux, M., Johnson, J.,
Klinvex, A., Li, X., McInnes, L.C., Moulton, J.D., Osei-Kuﬀuor, D., Sarich, J.,
Smith, B., Willenbring, J., Yang, U.M.: xSDK foundations: Toward an extreme-
scale scientiﬁc software development kit. Supercomputing Frontiers and Innova-
tions 4(1), 69–82 (feb 2017). https://doi.org/10.14529/jsﬁ170104

6. Bavota, G., Canfora, G., Penta, M.D., Oliveto, R., Panichella, S.: The Evolution
of Project Inter-dependencies in a Software Ecosystem: The Case of Apache. In:
2013 IEEE International Conference on Software Maintenance. pp. 280–289 (2013).
https://doi.org/10.1109/ICSM.2013.39

7. Dhungana, D., Groher, I., Schludermann, E., Biﬄ, S.: Software ecosystems vs.
natural ecosystems: learning from the ingenious mind of nature. In: Proceedings of
the Fourth European Conference on Software Architecture: Companion Volume.
pp. 96–102 (2010)

8. Dongarra, J.et al..: The International Exascale Software Project roadmap. The
International Journal of High Performance Computing Applications 25(1), 3–60
(2011). https://doi.org/10.1177/1094342010391989

9. Enders, B., Bard, D., Snavely, C., Gerhardt, L., Lee, J., Totzke, B., Anty-
pas, K., Byna, S., Cheema, R., Cholia, S., Day, M., Gaur, A., Greiner, A.,
Groves, T., Kiran, M., Koziol, Q., Rowland, K., Samuel, C., Selvarajan, A.,
Sim, A., Skinner, D., Thomas, R., Torok, G.: Cross-facility science with the Su-
perfacility Project at LBNL. In: 2020 IEEE/ACM 2nd Annual Workshop on
Extreme-scale Experiment-in-the-Loop Computing (XLOOP). pp. 1–7 (2020).
https://doi.org/10.1109/XLOOP51963.2020.00006

10. Hannay, J.E., MacLeod, C., Singer, J., Langtangen, H.P., Pfahl, D., Wilson, G.:
How do scientists develop and use scientiﬁc software? In: 2009 ICSE Workshop on
Software Engineering for Computational Science and Engineering. pp. 1–8 (2009).
https://doi.org/10.1109/SECSE.2009.5069155

14

D.E. Bernholdt, M. Doucet, et al.

11. Heaton, D., Carver, J.C.: Claims about the use of software engineering practices
in science: A systematic literature review. Information and Software Technology
67, 207–219 (2015). https://doi.org/10.1016/j.infsof.2015.07.011

12. Heroux, M.A.: The extreme-scale scientiﬁc software stack (e4s). Tech. rep., Sandia

National Lab.(SNL-NM), Albuquerque, NM (United States) (2019)

13. Ivezi´c, ˇZ., et al.: LSST: From Science Drivers

Anticipated Data Products. Astrophysical Journal 873(2)
https://doi.org/10.3847/1538-4357/ab042c

to Reference Design and
2019).

(Mar

14. Kaiya, H.: Meta-Requirements for Information System Requirements: Lesson
Learned from Software Ecosystem Researches. Procedia Computer Science 126,
1243–1252 (2018). https://doi.org/10.1016/j.procs.2018.08.066, Knowledge-Based
and Intelligent Information & Engineering Systems: Proceedings of the 22nd In-
ternational Conference, KES-2018, Belgrade, Serbia

15. Kehrer, T., Penzenstadler, B.: An exploration of sustainability thinking in re-
search software engineering. In: Chitchyan, R., Penzenstadler, B., Venters, C.C.
(eds.) Proceedings of the 7th International Workshop on Requirements Engineer-
ing for Sustainable Systems (RE4SuSy 2018) co-located with the 26th International
Conference on Requirements Engineering (RE 2018), Banﬀ, Alberta, Canada, Au-
gust 20, 2018. CEUR Workshop Proceedings, vol. 2223, pp. 34–43. CEUR-WS.org
(2018), http://ceur-ws.org/Vol-2223/paper5.pdf

16. Lamprecht, A.L., Garcia, L., Kuzak, M., Martinez, C., Arcila, R., Martin Del Pico,
E., Dominguez Del Angel, V., Van De Sandt, S., Ison, J., Martinez, P.A., et al.:
Towards fair principles for research software. Data Science 3(1), 37–59 (2020)
17. Manikas, K., Hansen, K.M.: Software ecosystems–a systematic literature review.

Journal of Systems and Software 86(5), 1294–1306 (2013)

18. Megino, F.B., De, K., Jha, S., Klimentov, A., Maeno, T., Nilsson, P., Oleynik, D.,
Padolski, S., Panitkin, S., Wells, J., and, T.W.: Integration of titan supercomputer
at OLCF with ATLAS production system. Journal of Physics: Conference Series
898, 092002 (oct 2017). https://doi.org/10.1088/1742-6596/898/9/092002

19. Monteith, J.Y., McGregor, J.D., Ingram, J.E.: Scientiﬁc research software ecosys-
tems. In: Proceedings of the 2014 European Conference on Software Architecture
Workshops. pp. 1–6 (2014)

20. Sadi, M.H., Dai, J., Yu, E.: Designing software ecosystems: How to develop sus-
tainable collaborations? In: Persson, A., Stirna, J. (eds.) Advanced Information
Systems Engineering Workshops. pp. 161–173. Springer International Publishing,
Cham (2015)

21. dos Santos, R.P., Werner, C.M.L.: Revisiting the Concept of Components in Soft-
ware Engineering from a Software Ecosystem Perspective. In: Proceedings of the
Fourth European Conference on Software Architecture: Companion Volume. p.
135–142. ECSA ’10, Association for Computing Machinery, New York, NY, USA
(2010). https://doi.org/10.1145/1842752.1842782

22. Storer, T.: Bridging the chasm: A survey of software engineering practice in scien-

tiﬁc programming. ACM Computing Surveys (CSUR) 50(4), 1–32 (2017)

