2
2
0
2

r
p
A
8
2

]

O
L
.
s
c
[

1
v
7
5
3
3
1
.
4
0
2
2
:
v
i
X
r
a

EvTL: A Temporal Logic for the Transient Analysis
of Cyber-Physical Systems

Valentina Castiglioni

Michele Loreti

Simone Tini

Abstract

The behaviour of systems characterised by a closed interaction of
software components with the environment is inevitably subject to
perturbations and uncertainties. In this paper we propose a general
framework for the speciﬁcation and veriﬁcation of requirements on the
behaviour of these systems. We introduce the Evolution Temporal
Logic (EvTL), a stochastic extension of STL allowing us to specify
properties of the probability distributions describing the transient be-
haviour of systems, and to include the presence of uncertainties in the
speciﬁcation. We equip EvTL with a robustness semantics and we
prove it sound and complete with respect to the semantics induced by
the evolution metric, i.e., a hemimetric expressing how well a system
is fulﬁlling its tasks with respect to another one. Finally, we develop
a statistical model checking algorithm for EvTL speciﬁcations. As an
example of an application of our framework, we consider a three-tanks
laboratory experiment.

1

Introduction

Cyber-physical systems [35], IoT systems [22] and smart devices are char-
acterised by software applications that must be able to deal with highly
changing operational conditions, henceforth referred to as the environment.
Examples of these applications are the software components of unmanned
vehicles, controllers, (on-line) service applications, the devices in a smart
house, etc. In these contexts, the behaviour of a system is the result of the
interplay of the devices, or software components, with their environment.

The main challenge in the analysis and veriﬁcation of these systems is
then the dynamical and, sometimes, unpredictable behaviour of the envi-
ronment. The highly dynamic behaviour of physical processes can only be
approximated in order to become computationally tractable and can consti-
tute a safety hazard for the devices in the system (like, e.g., an unexpected
gust of wind for a drone that is autonomously setting its trajectory to avoid
obstacles); some devices may appear, disappear, or become temporarily un-
available; faults or conﬂicts may occur (like, e.g., in a smart home the ap-
plication responsible for the ventilation of a room may open a window in

1

 
 
 
 
 
 
conﬂict with the one that has to limit the noise level); sensors may introduce
measurement errors; etc. Introducing uncertainties and approximations in
these systems is therefore inevitable to achieve some degree of system ro-
bustness.

Clearly, this uncertain, stochastic, behaviour needs to be taken into ac-
count in the speciﬁcation, and the consequent veriﬁcation, of requirements
over systems.

The main objective of this paper is then to provide a general
framework to model and check properties of systems running un-
der uncertainties.

The evolution sequence.

Our starting point is the observation that the behaviour of the systems we
study can be modelled in a purely data-driven fashion: while the environ-
mental conditions are (partially) available to the software components as a
set of data (for instance collected by sensors), the latter ones can in turn use
data (for instance communicated through actuators) to (partially) control
the environment and fulﬁl their tasks. Hence, it is natural to adopt the (dis-
crete time) model of [12] and represent the software-environment interplay
in terms of the changes they induce on a set of application-relevant data,
henceforth referred to as the data space. Let us call data state the descrip-
tion of the current state of the data space. Following [12], at each step,
both the software component and the environment induce some changes on
the data state, providing thus a new data state at the next step. This is
an abstraction: in concrete, the application operates at a given frequency,
thus changing the values in the data state at each time tick, while the envi-
ronment modiﬁes continuously these values between two ticks. We focus on
the sum of the eﬀects of the actions of both components. However, changes
on data are subject to the presence of uncertainties, meaning that it is not
always possible to determine exactly the values assumed by data at the next
step. Therefore, we represent the changes induced at each step as a proba-
bility measure on the attainable data states. For instance, we can assume
the computation steps of the system to be determined by a Markov ker-
nel. The behaviour of the system is then entirely expressed by its evolution
sequence, i.e., the sequence of probability measures over the data states ob-
tained at each step. We remark that the evolution sequence of a system
takes into account the eﬀect of perturbations and uncertainties at each time
step. Therefore, by expressing requirements on the evolution sequence of a
system we are able to verify the overall behaviour, as well as properties of
the step-by-step behaviour.

2

A novel temporal logic.

In the literature, quantitative extensions of model checking have been pro-
posed, like stochastic (or probabilistic) model checking [5, 6, 25, 26], and sta-
tistical model checking [10, 18, 39, 40, 48]. These techniques rely either on a
full speciﬁcation of the system to be checked, or on the possibility of simu-
lating the system by means of a Markovian model or Bayesian inference on
samples. Then, quantitative model checking is based on a speciﬁcation of
requirements in a probabilistic temporal logic, such as PCTL [19], CSL [3,4],
probabilistic variants of LTL [33], etc. Similarly, if Runtime Veriﬁcation [7]
is preferred to oﬀ-line veriﬁcation, probabilistic variants of MTL [24] and
STL [28] were proposed [38, 43]. In the quantitative setting, uncertainties
are usually dealt with in temporal logics by imposing probabilistic guarantees
on a given property to be satisﬁed: All the aforementioned logics provide a
quantitative construct of the form ϕ(cid:46)(cid:47)p where ϕ is a formula (the property),
p ∈ [0, 1] is a threshold (the probabilistic guarantee), and (cid:46)(cid:47)∈ {<, ≤, ≥, >}.
A system s satisﬁes ϕ(cid:46)(cid:47)p if the total probability mass of the runs of s satis-
fying ϕ is (cid:46)(cid:47) p.

This approach is natural and has found several applications, like estab-
lishing formal guarantees on reachability. However, it does not allow us to
analyse the properties of the distributions describing the transient behaviour
of the system. To specify complex system requirements, under uncertainties,
we need to be able to characterise the distribution on data at a given time.
For instance, in the probabilistic risk assessment analysis of the decommis-
sioning of a nuclear power plant, one of the main concerns is related to the
likelihood of the deﬂagration of hydrogen [30]. In detail, the objective there
is to estimate the probability of an overpressurization failure of the reac-
tor building given hydrogen deﬂagration. This estimation follows from the
comparison of the probability distribution of the pressure generated by the
deﬂagration with the probability distribution of the pressure resistance of the
reactor building. Informally, the area of the overlapping region between the
two curves gives the desired estimation of the failure probability. We remark
that classic temporal logics, like PCTL, would allow us to verify whether the
probability that the pressure generated by the deﬂagration (or, respectively,
the probability of the pressure resistance) is within a given interval. How-
ever, they do not allow us to verify, in practice, whether the values of such
pressure (or, respectively, resistance) are distributed according to a speciﬁc
distribution. In the situation described above, this disparity is crucial, since
the risk assessment can only be carried out with that information.

To capture this kind of properties, we introduce the Evolution Temporal
Logic (EvTL) as a probabilistic variant of STL characterised by the use
of stochastic signals: the probabilistic operator ϕ(cid:46)(cid:47)p is replaced by atomic
propositions being probability measures over data states.
Intuitively, by
modelling the evolution in time of the probability measures over data, we

3

can gain useful information on the behaviour of the system, including its
transient behaviour, and we can also express the presence of uncertainties
explicitly in the formulae.

EvTL robustness.

We equip EvTL with a real-valued semantics expressing the robustness of
the satisfaction of EvTL speciﬁcations. The robustness of a system s with
respect to a formula ϕ is expressed as a real number
s ∈ [−1, 1]: if it is
ϕ
(cid:75)
(cid:74)
positive, s satisﬁes ϕ. In detail,
s describes how much the behaviour of s
ϕ
(cid:75)
(cid:74)
has to be modiﬁed in order to violate (or satisfy) ϕ. We can then interpret
s as an indicator of how well s behaves with respect to the requirement
ϕ
(cid:74)
(cid:75)
ϕ. Hence, the challenge is to properly formalise “how well ”.

To this end, we use the evolution metric of [12], a (time-dependent)
hemimetric on the evolution sequences of systems based on a hemimetric
on data states and the Wasserstein metric [45]. The former is deﬁned in
terms of a penalty function allowing us to compare two data states only on
the base of the objectives of the system. The latter lifts the hemimetric
on data states to a hemimetric on probability measures on data states.
We then obtain a hemimetric on evolution sequences as the maximum of
the Wasserstein distances over time. The reason to opt for a hemimetric,
instead of a more standard (pseudo)metric, is that it allows us to compare
the relative behaviour of two systems and thus to express whether one system
is better than the other. We use the evolution metric to deﬁne the robustness
of systems with respect to EvTL formulae. As atomic propositions are
probability measures over data states, by means of the evolution metric
we can directly compare them to the probability measures in the evolution
sequences of systems.
In this way, we obtain useful information on the
diﬀerences in the behaviour of two systems from the comparison of their
robustness. In particular, we prove the robustness to be sound and complete
with respect to our metric semantics: whenever the robustness of s1 with
respect to a formula ϕ is greater than the distance between s1 and s2, then
we can conclude that the robustness of s2 with respect to ϕ is positive.

Finally, we provide a statistical model checking algorithm for the veriﬁca-
tion of EvTL speciﬁcations, consisting of three components: 1. A simulation
procedure for the evolution sequence of a system. 2. An algorithm, based
on statistical inference, for the evaluation of the Wasserstein distance over
probability measures. 3. A procedure that computes the robustness with
respect to a formula ϕ, by inspecting its syntax.

In order to show how our techniques can be applied, we consider a very
classical problem, namely the n-tanks experiment. Several variants (with
diﬀerent number of tanks) of this problem have been widely used in control
program education (see, among the others, [1, 20, 34, 49]). Moreover, some
recently proposed cyber-physical security testbeds, like SWaT [2, 29], can

4

be considered as an evolution of the tanks experiment. Here, we consider a
variant of the three-tanks laboratory experiment described in [34]. We plan
to tackle in the future more complex case studies, like the SWaT of [2, 29],
and the risk assessment analysis of the decommissioning of a nuclear power
plant explained above.

Summary of contributions.

Our main contributions can be summarised as follows:

1. We introduce the Evolution Temporal Logic (EvTL), a probabilistic
variant of STL allowing us to express requirements on systems under
uncertainties. By means of EvTL we can capture the properties of the
transient probabilities of systems, and we can express explicitly the
presence of uncertainties in the speciﬁcations.

2. We use the evolution metric of [12] to deﬁne the robustness of EvTL
speciﬁcations, which we prove to be sound and complete with respect
to our metric semantics.

3. We provide a statistical model checking algorithm for EvTL speciﬁca-

tions.

4. To show the adequacy of our approach we apply it to the three-tanks

experiment.

The technical proofs and the simplest parts of the algorithm can be found
in the Appendix.

2 Background

Measurable spaces A σ-algebra over a set Ω is a family Σ of subsets of
Ω s.t. Ω ∈ Σ and Σ is closed under complementation and under countable
union. The pair (Ω, Σ) is called a measurable space and the sets in Σ are
called measurable sets, ranged over by A, B, . . . . For an arbitrary family
Ψ of subsets of Ω, the σ-algebra generated by Ψ is the smallest σ-algebra
over Ω containing Ψ. In particular, given a topology T over Ω, the Borel
σ-algebra over Ω, denoted B(Ω), is the σ-algebra generated by the open sets
in T . Given two measurable spaces (Ωi, Σi), i = 1, 2, the product σ-algebra
Σ1 ⊗ Σ2 is the σ-algebra on Ω1 × Ω2 generated by the sets {A1 × A2 | Ai ∈
In particular, for any n ∈ N , if Ω1, . . . , Ωn are Polish spaces, then
Σi}.
i=1 Ωi) = (cid:78)n
B(×n

i=1 B(Ωi) [8].

5

Distributions On a measurable space (Ω, Σ), a function µ : Σ → [0, 1] is
a probability measure if µ(Ω) = 1, µ(A) ≥ 0 for all A ∈ Σ, µ((cid:83)
Ai) =
(cid:80)
i∈I µ(Ai) for every countable family of pairwise disjoint measurable sets
{Ai}i∈I ⊆ Σ. With a slight abuse of terminology, we shall use the term
distribution in place of probability measure.

i∈I

We let ∆(Ω, Σ) denote the set of all distributions over (Ω, Σ). For ω ∈ Ω,
the Dirac distribution δω is deﬁned by δω(A) = 1, if ω ∈ A, and δω(A) = 0,
otherwise, for all A ∈ Σ. Given a countable set (pi)i∈I ∈ R with pi ≥ 0
and (cid:80)
i∈I pi = 1, the convex combination of the distributions {µi}i∈I is the
distribution (cid:80)
i∈I piµi(A), for all
A ∈ Σ.

i∈I pi · µi deﬁned by ((cid:80)

i∈I pi · µi)(A) = (cid:80)

Assume measurable spaces (Ω, Σ), (Ω(cid:48), Σ(cid:48)) and µ ∈ ∆(Ω, Σ). Then,
X : Ω → Ω(cid:48) is a random variable if it is Σ-measurable, i.e., X −1(A) ∈ Σ for
all A ∈ Σ(cid:48). The distribution measure of X is the distribution µX on (Ω(cid:48), Σ(cid:48))
deﬁned by µX (A) = µ(X −1(A)) for all A ∈ Σ(cid:48). We write X ∼ µX if X has
µX as distribution measure.

The Wasserstein hemimetric A metric on a set Ω is a function m : Ω ×
Ω → R≥0 s.t. m(ω1, ω2) = 0 iff ω1 = ω2, m(ω1, ω2) = m(ω2, ω1), and
m(ω1, ω2) ≤ m(ω1, ω3) + m(ω3, ω2), for all ω1, ω2, ω3 ∈ Ω. We obtain a
hemimetric by relaxing the ﬁrst property to m(ω1, ω2) = 0 if ω1 = ω2, and
by dropping the requirement on symmetry. A (hemi)metric m is l-bounded
if m(ω1, ω2) ≤ l for all ω1, ω2 ∈ Ω.

In this paper we are interested in deﬁning a hemimetric on distributions.
To this end we will make use of the Wasserstein lifting [45] which is well
deﬁned on Polish spaces equipped with the Borel σ-algebra (see e.g. [46]).

Deﬁnition 1 (Wasserstein hemimetric). Consider a Polish space Ω and let
m be a hemimetric on Ω. For any two distributions µ and ν on (Ω, B(Ω)),
the Wasserstein lifting of m to a distance between µ and ν is deﬁned by

W(m)(µ, ν) = inf

w∈W(µ,ν)

(cid:90)

Ω×Ω

m(ω, ω(cid:48))dw(ω, ω(cid:48))

where W(µ, ν) is the set of the couplings of µ and ν, namely the set of
distributions w over the product space (Ω × Ω, B(Ω × Ω)) having µ and ν
as left and right marginal, respectively, i.e., w(A, Ω) = µ(A) and w(Ω, A) =
ν(A), for all A ∈ B(Ω).

Despite the original version of the Wasserstein distance being deﬁned on
a metric on Ω, the Wasserstein hemimetric given above is well-deﬁned. This
is proved in [17]. In particular, the Wasserstein hemimetric is given in [17]
as Deﬁnition 7 (considering the compound risk excess metric as in Equation
(31)), and Proposition 4 in [17] guarantees that it is indeed a well-deﬁned
hemimetric on ∆(Ω, B(Ω)). Moreover, Proposition 6 in [17] guarantees that

6

the same result holds for the hemimetric m(x, y) = max{x − y, 0}, which
will play an important role in our work (cf. Deﬁnition 5 below).

As elsewhere in the literature, we shall henceforth use the term metric

in place of the term hemimetric.

3 The model

Following [12], we describe the behaviour of a system in terms of a proba-
bilistic evolution of data. This is fully motivated in various contexts. For
instance, in a cyber-physical system, the interaction between the logic com-
ponent and the physical one can be naturally described by focusing on the
values that are assumed by physical quantities, and on those that are de-
tected by sensors and assigned to actuators. Moreover, one introduces prob-
ability as an abstraction mechanism in order to average over the eﬀect of
inessential or unknown details of the evolution of physical quantities which
may be also impossible to observe in practice. Probability also allows one to
quantify the degree of approximation introduced by some instruments, such
as the sensors.

Technically, we assume a data space deﬁned by means of a ﬁnite set
of variables Var representing: i) environmental conditions, such as pressure,
temperature, humidity, etc., ii) values perceived by sensors, which depend on
the value of environmental conditions and are unavoidably aﬀected by impre-
cision and approximations introduced by sensors, and iii) state of actuators,
which are usually elements in a discrete domain, like {on, oﬀ }. Without loss
of generality, we assume that for each x ∈ Var the domain Dx ⊆ R is either
a ﬁnite set or a compact subset of R. Notice that, in particular, this means
that Dx is a Polish space. Moreover, as a σ-algebra over Dx we assume the
Borel σ-algebra, denoted Bx. As Var is a ﬁnite set, we can always assume
it to be ordered, namely Var = {x1, . . . , xn} for a suitable n ∈ N.

Deﬁnition 2 (Data space). We deﬁne the data space over Var, notation
DVar, as the Cartesian product of the variables domains, namely DVar =
×n
i=1 Dxi. Then, as a σ-algebra on DVar we consider the product σ-algebra
BDVar = (cid:78)n

i=1 Bxi.

When no confusion arises, we use D for DVar and BD for BDVar. Then, we
let SD denote the set of systems having D as data space. Elements in D are
the n-ples of the form (v1, . . . , vn), with vi ∈ Dxi, which can be also identiﬁed
by means of functions d : Var → R from variables to values, with d(x) ∈ Dx
for all x ∈ Var. Each function d identiﬁes a particular conﬁguration in the
data space, and it is thus called a data state.

Deﬁnition 3 (Data state). A data state is a mapping d : Var → R from
variables to values, with d(x) ∈ Dx for all x ∈ Var.

7

We deﬁne an evolution sequence as a sequence of distributions over data
states describing the dynamics of a system. This sequence is countable
as we adopt a discrete time approach.
In this paper we do not focus
on how evolution sequences are generated: we simply assume a function
step : D → ∆(D, BD) governing the evolution of the system. In particular,
we recall that, at each step, the activity of the software component depends
on the available data and environment conditions, and potential modiﬁca-
tions by the component to these data may trigger diﬀerent behaviours of
the environment. Hence, it is reasonable to assume that the evolution at
each step depends only on the current state. Consequently, we can assume
that step is a Markov kernel and that our evolution sequence is the Markov
process generated by step (see Deﬁnition 4 below). Formally, step(d)(D) ex-
presses the probability of a system s to reach a data state in D from the data
state d in one computation step. Clearly, each system is characterised by
a particular function step. Moreover, it is also natural to assume that each
system will start its computation from a determined conﬁguration. Hence,
for each system s ∈ SD, we let ds denote the data state from which s starts
its computation.

Deﬁnition 4 (Evolution sequence). Assume a Markov kernel step : D →
∆(D, BD) generating the behaviour of system s. Then, the evolution se-
quence of s is a countable sequence of distributions in ∆(D, BD) of the form
Ss = Ss,0 . . . Ss,n . . . such that, for all D ∈ BD:

Ss,0(D) = δds(D)

(cid:90)

Ss,i+1(D) =

step(d)(D) d(Ss,i(d)) .

D

For a possible deﬁnition of step, we refer to [12]. There, a (cyber-
physical) system is speciﬁed as a combination of a program (or logic com-
ponent), having a discrete behaviour and reading/writing data at each time
instant, and a probabilistic evolution function, which models the eﬀects of
the environment (physical component) on data between two time instants.
Then, step is deﬁned by combining the eﬀects on data of the program with
those of the evolution function.

A typical scenario can be the following and shows that the discrete-time

and the Markov assumptions are fully motivated.

Notation. In the examples throughout the paper we will slightly abuse
of notation and use a variable name x to denote all: the variable x, the
(possible) function describing the evolution in time of the values assumed
by x, and the (possible) random variable describing the distribution of the
values that can be assumed by x at a given time. The role of the variable
name x will always be clear from the context.

8

pump

q1

lM
l1

lm

Flow rate under
the control of
the software

Flow rate under
the control of
the environment

q2

lg

l2

q12

l3

q23

Flow rate under
the control of
the software

pump

q0

Tank 1

Tank 2

Tank 3

Figure 1: Schema of the three-tanks scenario.

Example 1. As outlined in the Introduction, as an example of application
we consider a variant of the three-tanks laboratory experiment from [34]. As
schematised in Figure 1, there are three identical tanks connected by two
pipes. Water enters in the ﬁrst and in the last tank by means of a pump
and an incoming pipe, respectively. The last tank is equipped with an outlet
pump. We assume that water ﬂows through the incoming pipe with a rate
that is determined by the environment, whereas the ﬂow rate through the
two pumps is under the control of a software component. The task of the
system consists in guaranteeing that the levels of water in the three tanks
fulﬁl some given requirements.

The level of water in tank i at time τ is denoted by li(τ ), for i = 1, 2, 3,
and is always in the range [lm, lM ], for suitable lm and lM giving, respectively,
the minimum and maximum level of water in the tanks. The dynamics of
li(τ ) can be modelled via the following set of stochastic diﬀerence equations,
with sampling time interval ∆τ = 1:

l1(τ + 1) = l1(τ ) + q1(τ ) − q12(τ )
l2(τ + 1) = l2(τ ) + q12(τ ) − q23(τ )
l3(τ + 1) = l3(τ ) + q2(τ ) + q23(τ ) − q0(τ )

(1)

where q1 denotes the ﬂow rate of the pump connected to the ﬁrst tank,
q2 denotes the ﬂow rate of the incoming pipe, qij denotes the ﬂow rate
from tank i to tank j, and q0 denotes the ﬂow rate of the outlet pump.
Note that q12 and q23 depend on li and on the physical dimensions of the
three tanks. We omit here all the details on the evaluation of the ﬂow
rates q12 and q23, that are discussed in [34] and reported in Appendix A.
We assume that the ﬂow rate q2 is under the control of the environment,
so that its value is aﬀected by the uncertainties and, thus, can only be
described probabilistically. Conversely, the two pumps are controlled by a
software component that, by reading the values of li(τ ) can select the value
of q1(τ +1) and q0(τ +1). The three rates assume values in the range [0, qM ],
for a given maximal ﬂow rate qM . The exact value of q2(τ ) is unknown and

9

will be evident only at execution time. However, we can consider diﬀerent
scenarios that render the assumptions we have on the environment. For
instance, we can assume that the ﬂow rate of the incoming pipe is normally
distributed with mean qav and variance δq:

q2(τ + 1) ∼ N (qav, δq)

(2)

In a more elaborated scenario, we could assume that q2 varies at each step
by a value v that is normally distributed with mean 0 and variance 1. In
this case, we have:

v(τ ) ∼ N (0, 1)

q2(τ + 1) = min {max {0, q2(τ ) + v(τ )} , qM }

(3)

The equations describing the behaviour of the controller governing the

behaviour of the two pumps is the following:

q1(τ + 1) =

q0(τ + 1) =











max{0, q1(τ ) − qs}
if l1(τ ) > lg + δl
min{qM , q1(τ ) + qs} if l1(τ ) < lg − δl
q1(τ )

otherwise.

min{qM , q0(τ ) + qs} if l3(τ ) > lg + δl
if l3(τ ) < lg − δl
max{0, q0(τ ) − qs}
otherwise.
q0(τ )

(4)

(5)

Above, lg is the desired level of water in the tanks, while qs is the variation
of the ﬂow rate that is controllable by the pump. Moreover, δl is a threshold
on the read level of water. The idea behind Equation (4) is that when l1 is
greater than lg + δl, the ﬂow rate of the pump is decreased by qs. Similarly,
when l1 is less than lg − δl, that rate is increased by qs. The reasoning
for Equation (5) is symmetrical. In both cases, the use of the threshold δl
prevents continuous contrasting updates.

The data space for the considered system is then deﬁned on the set of
variables Var = {l1, l2, l3, q1, q2, q0} and the step function determining its
behaviour is derived from Equations (1), (2) (or (3)), (4) and (5) in the
obvious way.

(cid:16)

4 The evolution metric

Our aim is now to introduce a distance measuring the diﬀerences in the
behaviour of systems that will be used to deﬁne the robustness of EvTL
speciﬁcations. As the behaviour of a system is totally expressed by its
evolution sequence, it is natural to use the evolution metric of [12]. The
deﬁnition of the hemimetric in [12] is based on the observation that, in
most applications, the tasks of the system can be expressed in a purely
data-driven fashion. At any time step, any diﬀerence between the desired

10

value of some parameters of interest and the data actually obtained can
be interpreted as a ﬂaw in systems behaviour. Hence, we can introduce a
penalty function ρ : D → [0, 1], i.e., a continuous function that assigns to
each data state d a penalty in [0, 1] expressing how far the values of the
parameters of interest in d are from their desired ones (hence ρ(d) = 0 if
d respects all the parameters). For instance, the penalty function can be
though of as a linear function assigning a value in [0, 1] to data states that
is directly proportional to the (Euclidean) distance between the values of
the parameters in the data state and their optimal value. However, please
bear in mind that this is just one possibility, as the actual deﬁnition of the
penalty function depends only on the application context.

Example 2. In the three-tanks scenario from Example 1, a requirement on
system behaviour can be that each li should be at the level lg. Hence, we
can deﬁne penalty functions ρi, for i = 1, 2, 3, as the normalised distance
between the current level of water d(li) and lg, namely:

ρi(d) =

|d(li) − lg|
max{lM − lg, lg − lm}

(6)

(cid:16)
We can then use a penalty function ρ to obtain a distance on data states,
namely a 1-bounded hemimetric mD
ρ : given the data states d1 and d2,
mD
ρ (d1, d2) expresses how much d2 is worse than d1 according to parameters
of interest, and thus according to ρ. Since some parameters can be time-
dependent, so is ρ: at any time step τ , the τ -penalty function ρτ compares
the data states with respect to the values of the parameters expected at
time τ .

Deﬁnition 5 (Metric on data states). For any time step τ , let ρτ : D →
[0, 1] be the τ -penalty function on D. The τ -metric on data states in D,
mD
ρ,τ (d1, d2) =
max{ρτ (d2) − ρτ (d1), 0}.

ρ,τ : D × D → [0, 1], is deﬁned, for all d1, d2 ∈ D, by mD

Proposition 1. Function mD

ρ,τ is a 1-bounded hemimetric on D.

Notice that mD

ρ,τ (d1, d2) > 0 if and only if ρτ (d2) > ρτ (d1), i.e., the
penalty assigned to d2 is higher than that assigned to d1. For this reason,
we say that mD
ρ,τ (d1, d2) expresses how worse d2 is than d1 with respect to
the objectives of the system.

By means of the Wasserstein distance (cf. Deﬁnition 1), we can lift mD
ρ,τ
to a hemimetric W(mD
ρ,τ ) over distributions in ∆(D, BD). The evolution
hemimetric of [12] is then obtained as a weighted inﬁnity norm of the tu-
ple of the Wasserstein distances between the distributions in the evolution
sequences. As in most applications the changes on data induced by the sys-
tems can be appreciated only along wider time intervals than a computation

11

step by the logical component (like, e.g., in the case of the evolution of the
temperature in a room), a discrete, ﬁnite set OT of time steps at which
the modiﬁcations on data give us useful information on the evolution of the
system is considered.

As weight we consider a non-increasing function λ : OT → (0, 1] allowing
us to express how much the distance at time τ aﬀects the overall distance
between two systems. Following the terminology used for behavioural met-
rics [11, 13, 14], we refer to λ as to the discount function, and to λ(τ ) as to
the discount factor at time τ .

Deﬁnition 6 (Evolution metric). Assume a ﬁnite set OT of observation
times and a discount function λ. For each τ ∈ OT, let ρ be a penalty
function and let mD
ρ,τ be the τ -metric on data states deﬁned on it. Then, the
λ-evolution metric over ρ and OT, is the mapping mλ
ρ,OT : SD × SD → [0, 1]
deﬁned, for all systems s1, s2, by

mλ

ρ,OT(s1, s2) = max
τ ∈OT

λ(τ ) · W(mD

ρ,τ )(Ss1,τ , Ss2,τ ).

Proposition 2. Function mλ

ρ,OT is a 1-bounded hemimetric on SD.

Notice that if λ is a strictly non-increasing function, then it speciﬁes
how much the distance of future events is mitigated, and it guarantees that
to obtain upper bounds on the evolution metric only a ﬁnite number of
observations is needed. Hence, the choice of having OT ﬁnite is not too
restrictive.

5 The Evolution Temporal Logic

In this section we introduce the Evolution Temporal Logic (EvTL), which
allows us to specify requirements on evolution sequences, and thus the prop-
erties of systems behaviour under the presence of uncertainties.
The logic bases on two atomic properties, target(µ)ρ

p and brink(µ)ρ
p,
where µ is a distribution over data states in (D, BD), ρ is a penalty function
and p is a real in [0, 1]. Informally, target(µ)ρ
p can be used to express a
desirable behaviour, whereas brink(µ)ρ
p can be used for unwanted, or haz-
ardous, behaviours. These formulae are evaluated on a distribution Ss,τ in
the evolution sequence of a system s. Let us analyse the formula target(µ)ρ
p
in detail. In this case, µ is the desired distribution over data states. So,
to establish whether the system exhibits a proper behaviour, we compare µ
with the distribution Ss,τ obtained by the system: our means of comparison
is the Wasserstein lifting of the hemimetric between data states evaluated
with respect to the penalty ρ. (Notice that ρ is a parameter of the formula
target(µ)ρ
p. This is due to the fact that, clearly, the penalty is not a prop-
erty of the system but part of the requirements imposed on its behaviour.)

12

As µ is our target distribution, it is natural to check whether Ss,τ is worse
than µ, i.e., to evaluate the distance W(mD
ρ,τ )(µ, Ss,τ ). Clearly, given the
presence of uncertainties, it would not be feasible to say that the system
satisﬁes the considered formula if and only if W(mD
In-
stead, we use the parameter p as a tolerance on the distance: if Ss,τ is such
that W(mD
ρ,τ )(µ, Ss,τ ) ≤ p, then the behaviour of the system can be consid-
ered acceptable. In other words, p is the maximal acceptable hemi-distance
between the desired behaviour µ and the current behaviour Ss,τ .

ρ,τ )(µ, Ss,τ ) = 0.

Conversely, in the formula brink(µ)ρ

p the distribution µ expresses some
unwanted, hazardous, behaviour. Hence, the distribution Ss,τ reached by the
system must be better than µ, i.e., W(mD
ρ,τ )(Ss,τ , µ) > 0. Also in this case,
due to the presence of uncertainties, we need to make use of a threshold
parameter p: assuming a distribution Ss,τ acceptable when it is only slightly
better than µ can still lead to an unwanted behaviour (because, in this case,
the diﬀerence between the two distributions may only be due to some noise).
Hence, we let p be the minimal required hemi-distance between Ss,τ and µ,
so that Ss,τ is an acceptable behaviour if and only if W(mD
ρ,τ )(Ss,τ , µ) ≥ p.
Let var(µ) ⊆ Var be the set of data variables over which the distribution
µ is deﬁned. Similarly, for a penalty function ρ, we can consider the set
var(ρ) ⊆ Var.

Deﬁnition 7 (EvTL). The modal logic EvTL consists in the set of formulae
L deﬁned by the following syntax:

ϕ ::= (cid:62) | target(µ)ρ
p

| brink(µ)ρ
p

|

¬ϕ | ϕ ∨ ϕ | ϕ1 U [a,b] ϕ2

with ϕ ranging over L, µ ∈ ∆(D, BD) a distribution over data states, p ∈
[0, 1], ρ a penalty function such that var(ρ) ⊆ var(µ), p ∈ [0, 1] and [a, b] an
interval in OT.

Disjunction and negation are the standard Boolean connectives, and
ϕ1 U [a,b] ϕ2 is the bounded until operator stating that ϕ1 is satisﬁed un-
til, at a time in [a, b], ϕ2 is.

For any penalty function ρ, we denote by Lρ the sub-class of L with

atomic propositions of the form (·)ρ

(·).

Formulae are evaluated over systems and observable times. In a quanti-
tative semantics approach, for a formula ϕ, a system s, and a time instant
τ , the value
s,τ ∈ [−1, 1] expresses the robustness of s with respect to
ϕ
(cid:75)
(cid:74)
ϕ at time τ , i.e., how much the behaviour of s at time τ can be modiﬁed
either while preserving the validity of property ϕ (if ϕ is already satisﬁed),
or in order to obtain it.

Deﬁnition 8 (EvTL: quantitative semantics). For any system s, time step
τ , and EvTL formula ϕ, the robustness of s with respect to ϕ at τ , notation

13

s,τ ∈ [−1, 1], is deﬁned inductively with respect to the structure of ϕ as
ϕ
(cid:74)
(cid:75)
follows:

ρ,τ )(µ, Ss,τ )
ρ,τ )(Ss,τ , µ) − p

s,τ = 1
(cid:62)
(cid:75)
(cid:74)
target(µ)ρ
s,τ = p − λ(τ ) W(mD
p
(cid:75)
(cid:74)
s,τ = λ(τ ) W(mD
brink(µ)ρ
p
(cid:75)
(cid:74)
ϕ
s,τ = −
¬ϕ
s,τ
(cid:75)
(cid:74)
(cid:75)
(cid:74)
ϕ1
s,τ = max {
ϕ1 ∨ ϕ2
(cid:74)
(cid:75)
(cid:74)

s,τ ,
(cid:75)

ϕ1 U [a,b] ϕ2
(cid:74)

s,τ =
(cid:75)

max
τ (cid:48)∈[τ +a,τ +b]

min

ϕ2
(cid:74)

(cid:110)

s,τ }
(cid:75)

ϕ2
(cid:74)
min
τ (cid:48)(cid:48)∈[τ +a,τ (cid:48))(cid:74)

s,τ (cid:48),
(cid:75)
ϕ1

(cid:111)
.

s,τ (cid:48)(cid:48)
(cid:75)

target(µ)ρ
p
(cid:74)

Intuitively, the value λ(τ ) W(mD

ρ,τ )(µ, Ss,τ ) quantiﬁes the (discounted)
diﬀerence between the distribution Ss,τ reached by the system s at time
s,τ expresses
τ and µ. Hence, on the one hand the robustness
(cid:75)
whether the distribution in the evolution sequence of s is within the maximal
acceptable hemi-distance p from µ. On the other hand, it also expresses
how much Ss,τ can be modiﬁed while guaranteeing that the behaviour of
the system remains within the speciﬁed parameters. Clearly, the closer µ
s,τ quantiﬁes the
and Ss,ρ, the higher the robustness. Similarly,
(cid:75)
robustness of Ss,τ with respect to µ (and ρ) in terms of how much Ss,τ
may get close to µ while keeping the minimal required hemi-distance p.
Hence, the farther Ss,τ and µ, the higher the robustness. The semantics
of boolean connectives and bounded until is standard. Notice that due to
the potential asymmetry of our distances, it is not true in general that
brink(µ)ρ

brink(µ)ρ
p
(cid:74)

p = ¬target(µ)ρ

1−p.

As expected, other operators can be deﬁned as macros in our logic:

ϕ1 ∧ ϕ2 ≡ ¬(¬ϕ1 ∨ ¬ϕ2) ϕ1 → ϕ2 ≡ ¬ϕ1 ∨ ϕ2
[a,b]¬ϕ.

[a,b]ϕ ≡ (cid:62) U [a,b] ϕ2

[a,b]ϕ ≡ ¬

(cid:51)

Example 3. EvTL formulae can be used to express requirements on the
three-tanks scenario of Example 1. Let ρi, for i = 1, 2, 3, be the penalty
functions introduced in Example 2. We can express the following two re-
quirements:

(cid:50)

(cid:51)

Prop1: After an initial start up period of at most τ1 steps, for the next τ2
steps the distribution of l3 is at a distance of at most p from a normal
distribution with mean lg and variance δl:

[0,τ1]

[0,τ2]target(l3 ∼ N (lg, δl))ρ3
p .

(cid:51)

(cid:50)

Prop2: If in the ﬁrst τ1 steps the level experienced in at least one of the
three tanks gets too close, i.e., at a distance less than ph, to an haz-
ardous normal distribution with mean lM − ε and variance ε, then in

14

at most τ2 steps the experienced values in all tanks will be close, i.e.
at a distance less than ps, to the safe expected distributions:

ϕ =
(cid:50)
ϕh = (cid:87)3
ϕs = (cid:86)3

[0,τ2]ϕs)
[0,τ1](ϕh →
i=1 ¬brink(li ∼ N (lM − ε, ε))ρi
ph
i=1 target(li ∼ N (lg, δl))ρi
ps.

(cid:51)

We remark that neither Prop1 nor Prop2 can be expressed with classic
probabilistic temporal logics.

(cid:16)
We can show that EvTL characterises the distance between systems.
More precisely, the quantitative semantics of EvTL induces a distance be-
tween systems that coincides with the symmetrisation of the hemimetric mλ
ρ
and is therefore a pseudometric. Clearly, since the evolution metric is de-
ﬁned in terms of a given penalty function ρ, it will be characterised by the
distance over formulae in Lρ.

Deﬁnition 9 (EvTL distance). Given a penalty function ρ, the EvTL dis-
tance over systems s1 and s2 with respect to ρ and OT is deﬁned as

(cid:96)ρ,OT(s1, s2) =

sup
ϕ∈Lρ,τ ∈OT

s1,τ −
ϕ
|
(cid:75)
(cid:74)

ϕ
(cid:74)

s2,τ | .
(cid:75)

Firstly, we show that the symmetrisation of mλ

ρ,OT is an upper bound to

(cid:96)ρ,OT.

Lemma 1. For any penalty function ρ, and systems s1 and s2 we have that:

(cid:96)ρ,OT(s1, s2) ≤ max(mλ

ρ,OT(s1, s2), mλ

ρ,OT(s2, s1)).

Proof. The proof can be found in Appendix B.

We can provide a formula witnessing that (cid:96)ρ,OT and the symmetrisation
ρ,OT coincide.

of mλ

Lemma 2. For all systems s1, s2 and penalty functions ρ, there is a formula
ϕ ∈ Lρ with |
, for
some τ ∈ OT.

s2,τ | = max
ϕ
(cid:75)
(cid:74)

(cid:17)
ρ,OT(s2, s1)

ρ,OT(s1, s2), mλ

s1,τ −
(cid:75)

ϕ
(cid:74)

mλ

(cid:16)

Proof. The proof can be found in Appendix C.

From Lemma 1 and Lemma 2 we infer that the EvTL distance (cid:96)ρ,OT and

the symmetrisation of mλ

ρ,OT coincide.

Theorem 1. For all systems s1 and s2 we have that:

(cid:96)ρ,OT(s1, s2) = max(mλ

ρ,OT(s1, s2), mλ

ρ,OT(s2, s1)).

15

Theorem 1 entails the soundness (Lemma 1) and completeness (Lemma 2)
of our notion of robustness. In particular, as a direct consequence of Theo-
rem 1, we can obtain the following classic result (see, e.g., [15]): whenever
the robustness of a system s with respect to a formula ϕ is greater than
the distance between s and s(cid:48), then the robustness of s(cid:48) with respect to ϕ is
positive as well.

Corollary 1. Let ϕ be any formula in Lρ, τ ∈ OT and let i ∈ {1, 2}.
Whenever

ρ,OT(s2, s1)), then

ρ,OT(s1, s2), mλ

si,τ ≥ max(mλ
ϕ
(cid:75)
(cid:74)

ϕ
(cid:74)

s3−i,τ ≥ 0.
(cid:75)

6 Statistical Model Checking

In this section we present an algorithm, based on statistical model-checking,
that allows us to estimate the robustness of a system s with respect to a
formula ϕ. This algorithm consists of three basic elements: (i) a randomised
procedure that, based on simulation, permits the estimation of the evolution
sequence of s, assuming an initial data state ds; (ii) a mechanism to estimate
the Wasserstein distance between two probability distributions on (D, BD);
(iii) a procedure that by inspecting the syntax of ϕ and by using the ﬁrst
two components computes the robustness.

Due to lack of space, we only present an overview of the three steps. The
algorithms we are going to discuss are reported in Appendix F. A Python
implementation of the proposed approach is available at https://github.
com/gitUltron/Ultron.

In Section 5 we have introduced robustness in its general form, i.e., by
presenting its evaluation in a formula at any time τ . However, the simulation
of the evolution sequence of a system s can only be done starting from an
initial data state ds (or at least from a given ﬁnite, discrete distribution over
data states), and thus, ideally, from time 0. Hence, it is natural, and also
common practice, to evaluate the robustness of s with respect to a formula
always at time 0. Clearly, the temporal operators in EvTL still allow us
to reason on timed requirements on evolution sequences. Therefore, we
will henceforth consider, for a system s and a formula ϕ, the robustness
ϕ
(cid:74)

s =
(cid:75)

s,0.
(cid:75)

ϕ
(cid:74)

6.1 Statistical estimation of evolution sequences

Given an initial data state ds and an integer k, we let Simul be the function
used to sample a sequence of data states of form d0, d1, . . . , dk, modelling
k-steps of a computation starting from ds = d0. Simul is deﬁned assuming
that for any index 0 ≤ i ≤ k−1 and measurable set D ∈ BD, the likelihood to
sample di+1 ∈ D after the sampling of d0, . . . , di corresponds to step(di)(D)
(details in Appendix F).

16

(a) Simulation results.

(b) Estimated distributions of the water level in
tank 3.

Figure 2: The three-tanks experiment in the two scenarios from Example 1.

Example 4. A simulation of the three-tanks laboratory experiment is given
in Figure 2a, with the following setting: (i) lm = 0, (ii) lM = 20, (iii) lg = 10,
(iv) δl = 0.5, (v) qM = 6, (vi) qs = qM /5, (vii) δq = 0.5, (viii) ∆τ = 0.1. On
the left hand side we can see a single simulation run related to scenario 1,
namely the one in which the ﬂow rate q2 of the incoming pipe is regulated
by Equation (2). On the right hand side, we report a run of scenario 2, in
which the variation of that rate is modelled as Equation (3). In both cases,
we assume an initial data state ds with li = lm and qi = 0, for i = 1, 2, 3.
(The parameters related to the evaluation of q12 and q23 in our simulations
can be found in Appendix A.)

k, for j = 1, . . . , N , from ds = dj

(cid:16)
We then use a function, called Estimate in Appendix F, to obtain the
empirical evolution sequence of system s starting from ds. Intuitively, this
function uses function Simul to obtain N sampled sequences of data states
dj
0, . . . , dj
0. Then, a sequence of sets of
samples E0, . . . , Ek is computed, where each Ei is the tuple d1
i of
the data states observed at time i in each of the N sampled computations.
Notice that, for each i ∈ {0, . . . , k}, the samples d1
i are independent
and identically distributed (see Appendix F). Each Ei can be used to esti-
mate the distribution Ss,i. For any i, with 0 ≤ i ≤ k, we let ˆS N
s,i be the distri-
|Ei ∩ D|
bution such that for any measurable set D ∈ BD we have ˆS N
.
N
Then, by applying the weak law of large numbers to the i.i.d samples, we
get that ˆS N

s,i converges weakly to Ss,i when N → ∞:

i , . . . , dN

i , . . . , dN

s,i(D) =

lim
N →∞

ˆS N
s,i = Ss,i

(7)

17

Example 5. In Figure 2b we give an estimation of the distribution of l3,
after 100 time steps for N = 1000 samples, for the two scenarios from
Example 1.

√

(cid:80)N

j=1(dj

i (x)−Ei(x))2
N −1

(cid:16)
As usual in the related literature, we can apply the classic standard
error approach to analyse the approximation error of our statistical esti-
mation of the evolution sequences. Brieﬂy, we let x ∈ {l1, l2, l3} and we
focus on the distribution of the means of our samples (in particular we con-
sider the cases N = 100, 500, 1000, 5000, 10000) for each variable x. In each
case, for each i ∈ {0, . . . , k} we compute the mean Ei(x) = 1
i (x)
N
of the sampled data, and we evaluate their standard deviation ˜σi,N (x) =
(cid:114) (cid:80)N

j=1 dj

(see Figure 3a for the variation in time of the stan-
dard deviation of the distribution of x = l3). From ˜σi,N (x) we obtain the
standard error of the mean σi,N (x) = ˜σi,N (x)
(see Figure 3b for the varia-
N
tion in time of the standard error for the distribution of x = l3). Finally,
we proceed to compute the z-score of our sampled distribution as follows:
zi,N (x) = Ei(x)−E(x)
, where E(x) is the mean (or expected value) of the real
σi,N (x)
In Figure 3c we report the variation in time of the
distribution over x.
z-score of the distribution over x = l3: the dashed red lines correspond to
z = ±1.96, namely the value of the z-score corresponding to a conﬁdence
interval of the 95%. We can see that our results can already be given with
a 95% conﬁdence in the case of N = 1000 (for readability, in Figure 3c
we have reported only the values related to N = 100, 1000, 10000). Please
notice that the oscillation in time of the values of the z-scores is due to the
perturbations introduced by the environment in the simulations and by the
natural oscillation in the interval [lg − δl, lg + δl] of the water levels in the
considered experiment (see Figure 2a). A similar analysis, with analogous
results, can be carried out for the distributions of l1 and l2. In Figure 3d we
report the variation in time of the z-scores of the distributions of the three
variables, in the case N = 1000.

6.2 Statistical estimation of the Wasserstein metric

1, . . . , dN

1 } taken from µ and (cid:96)N independent samples {d1

Let us consider two distributions µ and ν on (D, BD). Following an approach
similar to the one presented in [42], to estimate the Wasserstein distance
W(mD
ρ,i) between (the unknown) µ and ν we can use N independent samples
{d1
2 } taken
from ν. We then exploit the i-penalty function ρi to map each sampled data
state onto R, so that it is enough to consider the sequences of values for
the evaluation of the distance {ωj = ρi(dj
2 )}. We can
assume, without loss of generality, that these sequences are ordered, i.e.,
ωj ≤ ωj+1 and νh ≤ νh+1. The value W(mD
ρ,i)(ν, µ) can be approximated

1)} and {νh = ρi(dh

2, . . . , d(cid:96)N

18

(a) Standard deviation for l3.

(b) Standard error for l3.

(c) z-score for l3.

(d) z-scores for l1, l2, l3, N = 1000.

Figure 3: Analysis of the approximation error, over time, of the distributions of
l1, l2, l3, in scenario 2, for N = 100, 500, 1000, 5000, 10000.

as:

1
(cid:96)N

(cid:96)N
(cid:88)

h=1

max{νh − ω(cid:100) h

(cid:96) (cid:101), 0}.

The next theorem, based on results in [42, 46], ensures that the larger the
number of samplings the closer the gap between the estimated value and the
exact one.

1, . . . , dN
Theorem 2. Let µ, ν ∈ ∆(D, BD) be unknown. Let {d1
1 } be in-
dependent samples taken from µ, and {d1
2 } independent samples
taken from ν. Let {ωj = ρi(dj
1)} and {νh = ρi(dh
2 )} be the ordered sequences
obtained by applying the i-penalty function to the samples. Then, it holds,
almost surely, that

2, . . . , d(cid:96)·N

W(mD

ρ,i)(µ, ν) = lim
N →∞

1
(cid:96)N

(cid:96)N
(cid:88)

h=1

max

Proof. The proof can be found in Appendix D.

(cid:110)

νh − ω(cid:100) h

(cid:111)
(cid:96) (cid:101), 0

.

In Appendix F, the function that realises the procedure outlined above
is function ComputeWass. Since the penalty function allows us to reduce
the evaluation of the Wasserstein distance in Rn to its evaluation on R, due
to the sorting of {νh | h ∈ [1, . . . , (cid:96)N ]} the complexity of outlined procedure

19

1: function Sat(ds, ϕ, (cid:96), N )
k ← Horizon(ϕ)
2:
E0, . . . , Ek ← Estimate(ds, k, (cid:96)N )
3:
return Eval({E0, . . . , Ek}, ϕ, (cid:96), N )
4:
5: end function

Figure 4: Function used to evaluate system robustness w.r.t. a formula.

is O((cid:96)N log((cid:96)N )) (cf. [42]). We refer the interested reader to [41, Corollary
3.5, Equation (3.10)] for an estimation of the approximation error given by
the evaluation of the Wasserstein distance over N samples.

6.3 Statistical estimation of robustness

The computation of the robustness of a system s with respect to a for-
mula ϕ, starting from the data state ds, is performed via the function Sat
deﬁned in Figure 4. Together with the data state ds and the formula ϕ,
function Sat takes as parameters the two integers (cid:96) and N identifying the
number of samplings that will be used to estimate the Wasserstein metric.
This function consists of three steps. First the time horizon k of the for-
mula ϕ is computed (by induction on the structure of ϕ) to identify the
number of steps needed to evaluate the robustness.
In the second step,
function Estimate is used to simulate the evolution sequence of s from ds
by collecting the sets of samplings E1, . . . , Ek on which the robustness is
computed, in the third step, by calling function Eval deﬁned in Figure 5.
The structure of Eval is similar to the monitoring function for STL deﬁned
in [28]. Given (cid:96)N sampled values at time 0, . . . , k, a formula ϕ and integers
(cid:96) and N , function Eval yields a tuple of the form v0, . . . , vk, where vi is
the robustness with respect to ϕ at time step i. Function Eval is deﬁned
recursively on the syntax of ϕ. If ϕ = (cid:62) all the elements in the resulting
tuple are equal to 1, since (cid:62) is always satisﬁed with robustness 1. When ϕ
is target(µ)ρ
p) the value vi is computed by ﬁrst sampling
N (resp. (cid:96)N ) values of µ via the sampling function Sample, and then us-
ing function ComputeWass introduced in Section 6.2. Function Sample,
given a probability distribution µ and an integer N , yields N independent
samplings of µ. In case of brink(µ)ρ
p, only N elements are selected from Ei
(denoted by Ei ↓ N ). The robustness with respect to ϕ1 ∨ ϕ2 is computed
as the maximum between the robustness with respect to ϕ1 and that in ϕ2.
The robustness with respect to ¬ϕ1 is computed as the additive inverse of
the robustness with respect to ϕ1. Finally, when ϕ = ϕ1 U [a,b] ϕ2, the out-
put tuple v0, . . . , vk is computed from the robustness with respect to ϕ1 and
ϕ2, and the time interval [a, b] via the function Until deﬁned in Figure 6.

p (resp. brink(µ)ρ

Given a formula ϕ and an initial data state ds, we let Robust(ds, ϕ, (cid:96), N ) =

v if and only if Sat(ds, ϕ, (cid:96), N ) = v0, . . . , vk and v = v0. The following the-
orem guarantees that when N goes to inﬁnite, the robustness computed by

20

match ϕ

1: function Eval({E0, . . . , Ek}, ϕ, (cid:96), N )
2:
3:
4:
5:

∀0 ≤ i ≤ k : vi ← 1.0
return v0, . . . , vk

with (cid:62) :

6:
7:
8:
9:
10:
11:
12:
13:

14:
15:
16:
17:
18:
19:
20:
21:

22:
23:
24:
25:
26:

27:
28:
29:
30:

31:
32:
33:
34:

with target(µ)ρ

p :

∀0 ≤ i ≤ k : vi ← 0.0
i ← 0
while i ≤ k do

E(cid:48) ← Sample(µ, N )
vi ← p − ComputeWass(E(cid:48), Ei, ρ)

end while
return v0, . . . , vk

with brink(µ)ρ

p :

∀0 ≤ i ≤ k : vi ← 0.0
i ← 0
while i ≤ k do

E(cid:48) ← Sample(µ, (cid:96)N )
vi ← ComputeWass(Ei ↓ N, E(cid:48), ρ) − p

end while
return v0, . . . , vk

with ϕ1 ∨ ϕ2 :
v1
0, . . . , v1
0, . . . , v2
v2
∀0 ≤ i ≤ k : vi ← max{v1
return v0, . . . , vk

k = Eval({E0, . . . , Ek}, ϕ1, (cid:96), N )
k = Eval({E0, . . . , Ek}, ϕ2, (cid:96), N )

i , v2
i }

with ¬ϕ1 :
v1
0, . . . , v1
∀0 ≤ i ≤ k : vi ← −v1
i
return v0, . . . , vk

k = Eval({E0, . . . , Ek}, ϕ1, (cid:96), N )

with ϕ1 U [a,b] ϕ2 :
0, . . . , v1
v1
0, . . . , v2
v2
return Until(v1

k = Eval({E0, . . . , Ek}, ϕ1, (cid:96), N )
k = Eval({E0, . . . , Ek}, ϕ2, (cid:96), N )
k, a, b)

0, . . . , v2

0, . . . , v1

k , v2

35: end function

Figure 5: Evaluation of robustness.

21

0, . . . , v1

k , v2

0, . . . , v2

k,a,b)

∀0 ≤ i ≤ k : vi ← 0.0
i ← 0
while i ≤ k do

1: function Until(v1
2:
3:
4:
5:
6:
7:
8:
9:
10: end function

end while
return v0, . . . , vk

∀j ∈ [i + a, i + b] : w1
∀j ∈ [i + a, i + b] : w2
vi ← max{w2

j = min{v1
j = min{w1
j |j ∈ [i + a, i + b]}

h|h ∈ [i, j]}
j , v2
j }

Figure 6: Evaluation of robustness with respect to the until formula.

(a) Prop1, k = 150.

(b) Prop2, k = 150.

(c) Prop2, k = 300.

(d) Prop2, k = 600.

Figure 7: Estimated robustness with respect to Prop1 and Prop2.

function Sat converges, almost surely, to the exact value.

Theorem 3. For any formula ϕ, system s, data state ds, and integer (cid:96) > 0

lim
N (cid:55)→∞

Robust(ds, ϕ, (cid:96), N ) =

s.
ϕ
(cid:75)
(cid:74)

Proof. The proof can be found in Appendix E.

Example 6. The proposed algorithm can be used to verify the requirements
of Example 3.
In Figure 7 we report the results related to the following
parameters instantiations: N = 100, (cid:96) = 10, and for Prop1 we used τ1 =
20, τ2 = 30 and p = 0.2; whereas for Prop2 we used τ1 = 40, τ2 = 20,
ph = 0.2, ps = 0.3, and ε = 0.3. The plots depicted in Figure 7 compare
the variation of robustness (in time) of the system with respect to the two

22

diﬀerent scenarios from Example 1. The small drop, after step 120, in the
value of the robustness with respect to Prop2 (Figure 7b) is only due to a
contrast between the time horizon of the formula and the time horizon k of
the simulation. In fact, the same ﬁnal drop can be observed when considering
diﬀerent time horizons for the simulation, e.g. k = 300 in Figure 7c and
k = 600 in Figure 7d.

(cid:16)

7 Concluding remarks

We have introduced the Evolution Temporal Logic (EvTL), a probabilistic
variant of STL expressing requirements on the behaviour of systems under
uncertainties. Diﬀerently from the other probabilistic temporal logics usu-
ally considered in the literature, EvTL can be used to express the properties
of the distributions expressing the transient behaviour of the system. Up to
our knowledge, [44] is the only other paper proposing to substitute proba-
bilistic guarantees on the temporal properties with a richer description of the
probabilistic events. In detail, [44] introduces ProbSTL a stochastic variant
of STL tailored to the incremental runtime veriﬁcation of safe behaviour of
robotic systems under uncertainties. The objective is to develop a predic-
tive stream reasoning tool for monitoring the runtime behaviour of robotic
systems. Hence, their stochastic signal is given by the prediction on the pos-
sible future trajectories of a system, taking into account the measurement
errors by the sensors and the unpredictable behaviour of the environment.
Yet, ProbSTL speciﬁcations are tested only on the current trajectory of
the system. This is the main diﬀerence with our work, since our logic has
been built to express the overall uncertain behaviour of the system. This
disparity is also a consequence of the diﬀerent application context: oﬀ-line
veriﬁcation for us, runtime veriﬁcation in [44]. However, as future work,
we plan to develop a predictive model for the runtime monitoring of EvTL
speciﬁcations. In particular, inspired by [9, 32] where deep neural networks
are used as reachability predictors for predictive monitoring, we intend to
integrate our work with learning techniques, to favour the computation and
evaluation of the predictions.

Another application context of probabilistic temporal logics is that of
Markov processes as transformers of distributions [23,27]. Roughly, one can
interpret state-to-state transition probabilities as a single distribution over
the state space, so that the behaviour of the system is given by the sequence
of the so obtained distributions. While this approach may resemble the
evolution sequences of [12], there are some substantial diﬀerences. Firstly,
the state space in [23, 27] is ﬁnite and discrete, whereas here we are in the
continuous setting. Secondly, the transformers of distributions consider the
behaviour of the system as a whole, i.e., it is not possible to separate the
logical component from the environment. Moreover, the temporal logics used

23

to model check properties of transformers of distributions, respectively iLTL
in [27] and the almost acyclic B¨uchi automata in [23], are not comparable
to our EvTL. In fact, those speciﬁcations have a boolean semantics, while
EvTL formulae are interpreted in terms of robustness.

Recently, [47] proposed a statistical model checking algorithm based on
stratiﬁed sampling for the veriﬁcation of PCTL speciﬁcation over Markov
chains. Informally, stratiﬁed sampling allows for the generation of negatively
correlated samples, i.e., samples whose covariance is negative, thus consid-
erably reducing the number of samples needed to obtain conﬁdent results
from the algorithm. However, the proposed algorithm works under a num-
ber of assumptions restricting the form of the PCTL formulae to be checked.
While direct comparison of the two algorithms would not be feasible, nor
meaningful given the disparity in the classes of formulae, it would be worth
studying the use of stratiﬁed sampling in our model checking algorithm.

We also plan to investigate the application of our framework to the
analysis of biological systems. Some quantitative extensions of temporal
logics have already been proposed in that setting (e.g. [16,36,37]) to capture
the notion of robustness from [21] or similar proposals [31].
It would be
interesting to see whether the use of EvTL and evolution sequences can lead
to new results in this setting.

References

[1] I. Alvarado, D. Limon, W. Garc´ıa-Gab´ın, T Alamo, and E.F. Cama-
cho. An educational plant based on the quadruple-tank process. IFAC
Proceedings Volumes, 39(6):82–87, 2006. 7th IFAC Symposium on Ad-
vances in Control Education. URL: https://www.sciencedirect.
com/science/article/pii/S1474667015331104, doi:https://doi.
org/10.3182/20060621-3-ES-2905.00016.

[2] Daniele Antonioli, Hamid Reza Ghaeini, Sridhar Adepu, Mart´ın Ochoa,
and Nils Ole Tippenhauer. Gamifying ICS security training and re-
search: Design,
In Proceedings
implementation, and results of S3.
of CPS-SPC@CCS 2017, pages 93–102. ACM, 2017. doi:10.1145/
3140241.3140253.

[3] Adnan Aziz, Kumud Sanwal, Vigyan Singhal, and Robert K. Brayton.
Verifying continuous time Markov chains. In Proceedings of CAV ’96,
volume 1102 of Lecture Notes in Computer Science, pages 269–276,
1996. URL: https://doi.org/10.1007/3-540-61474-5_75, doi:10.
1007/3-540-61474-5\_75.

[4] Adnan Aziz, Kumud Sanwal, Vigyan Singhal, and Robert K. Brayton.
Model-checking continous-time Markov chains. ACM Trans. Comput.
Log., 1(1):162–170, 2000. doi:10.1145/343369.343402.

24

[5] Christel Baier. Probabilistic model checking. In Javier Esparza, Orna
Grumberg, and Salomon Sickert, editors, Dependable Software Systems
Engineering, volume 45 of NATO Science for Peace and Security Series
- D: Information and Communication Security, pages 1–23. IOS Press,
2016. doi:10.3233/978-1-61499-627-9-1.

[6] Christel Baier, Luca de Alfaro, Vojtech Forejt, and Marta Kwiatkowska.
In Edmund M. Clarke,
Model checking probabilistic systems.
Thomas A. Henzinger, Helmut Veith, and Roderick Bloem, edi-
tors, Handbook of Model Checking, pages 963–999. Springer, 2018.
URL: https://doi.org/10.1007/978-3-319-10575-8_28, doi:10.
1007/978-3-319-10575-8\_28.

[7] Ezio Bartocci, Yli`es Falcone, Adrian Francalanza, and Giles Reger. In-
troduction to runtime veriﬁcation. In Lectures on Runtime Veriﬁcation
- Introductory and Advanced Topics, volume 10457 of Lecture Notes
in Computer Science, pages 1–33. 2018. URL: https://doi.org/10.
1007/978-3-319-75632-5_1, doi:10.1007/978-3-319-75632-5\_1.

[8] Vladimir I. Bogachev. Measure Theory. Number v. 1 in Mea-
sure Theory. Springer-Verlag, Berlin/Heidelberg, 2007. doi:10.1007/
978-3-540-34514-5.

[9] Luca Bortolussi, Francesca Cairoli, Nicola Paoletti, Scott A. Smolka,
and Scott D. Stoller. Neural predictive monitoring. In Proceedings of RV
2019, volume 11757 of Lecture Notes in Computer Science, pages 129–
147, 2019. URL: https://doi.org/10.1007/978-3-030-32079-9_8,
doi:10.1007/978-3-030-32079-9\_8.

[10] Luca Bortolussi, Dimitrios Milios, and Guido Sanguinetti. Smoothed
model checking for uncertain continuous-time Markov chains. Inf. Com-
put., 247:235–253, 2016. doi:10.1016/j.ic.2016.01.004.

[11] Valentina Castiglioni, Michele Loreti, and Simone Tini. The metric
linear-time branching-time spectrum on nondeterministic probabilistic
processes. Theor. Comput. Sci., 813:20–69, 2020. doi:10.1016/j.tcs.
2019.09.019.

[12] Valentina Castiglioni, Michele Loreti, and Simone Tini. How adaptive
and reliable is your program? In Proceedings of FORTE 2021, volume
12719 of Lecture Notes in Computer Science, pages 60–79, 2021. The
technical report version of the paper can be found at http://icetcs.
ru.is/opel/Forte21.pdf. doi:10.1007/978-3-030-78089-0_4.

[13] Luca de Alfaro, Thomas A. Henzinger, and Rupak Majumdar.
In Proceedings of

Discounting the Future in Systems Theory.

25

ICALP’03, ICALP ’03, pages 1022–1037. Springer, 2003. doi:10.1007/
3-540-45061-0\_79.

[14] Josee Desharnais, Vineet Gupta, Radha Jagadeesan, and Prakash
Panangaden. Metrics for labelled Markov processes. Theor. Comput.
Sci., 318(3):323–354, 2004. doi:10.1016/j.tcs.2003.09.013.

[15] Alexandre Donz´e and Oded Maler. Robust satisfaction of temporal
In Proceedings of FORMATS 2010,
logic over real-valued signals.
volume 6246 of Lecture Notes in Computer Science, pages 92–106,
2010. URL: https://doi.org/10.1007/978-3-642-15297-9_9, doi:
10.1007/978-3-642-15297-9\_9.

[16] Fran¸cois Fages and Aur´elien Rizk. On temporal logic constraint solv-
ing for analyzing numerical data time series. Theor. Comput. Sci.,
408(1):55–65, 2008. doi:10.1016/j.tcs.2008.07.004.

[17] Olivier P. Faugeras and Ludeger R¨uschendorf. Risk excess measures
induced by hemi-metrics. Probability, Uncertainty and Quantitative
Risk, 3:6, 2018. doi:10.1186/s41546-018-0032-0.

[18] Soﬁe Haesaert, Paul M. J. van den Hof, and Alessandro Abate. Data-
driven and model-based veriﬁcation via bayesian identiﬁcation and
reachability analysis. Autom., 79:115–126, 2017.
doi:10.1016/j.
automatica.2017.01.037.

[19] Hans Hansson and Bengt Jonsson. A logic for reasoning about time and
reliability. Formal Asp. Comput., 6(5):512–535, 1994. doi:10.1007/
BF01211866.

[20] Karl Henrik Johansson. The quadruple-tank process: a multivariable
laboratory process with an adjustable zero. IEEE Trans. Control. Syst.
Technol., 8(3):456–465, 2000. doi:10.1109/87.845876.

[21] Hiroaki Kitano.

Towards a theory of biological

Molecular Systems Biology,
www.embopress.org/doi/abs/10.1038/msb4100179,
//www.embopress.org/doi/pdf/10.1038/msb4100179,
//doi.org/10.1038/msb4100179.

3(1):137,

2007.

robustness.
URL: https://
arXiv:https:
doi:https:

[22] Hermann Kopetz.

Internet of Things, pages 307–323. Springer US,

Boston, MA, 2011. doi:10.1007/978-1-4419-8237-7\_13.

[23] Vijay Anand Korthikanti, Mahesh Viswanathan, Gul Agha, and Young-
Min Kwon. Reasoning about mdps as transformers of probability distri-
butions. In Proceedings of QEST 2010, pages 199–208. IEEE Computer
Society, 2010. doi:10.1109/QEST.2010.35.

26

[24] Ron Koymans. Specifying real-time properties with metric temporal
logic. Real Time Syst., 2(4):255–299, 1990. doi:10.1007/BF01995674.

[25] Marta Z. Kwiatkowska, Gethin Norman, and David Parker. Stochas-
In Proceedings of SFM 2007, volume 4486
tic model checking.
of Lecture Notes
2007.
URL: https://doi.org/10.1007/978-3-540-72522-0_6, doi:10.
1007/978-3-540-72522-0\_6.

in Computer Science, pages 220–270,

[26] Marta Z. Kwiatkowska and David Parker. Advances in probabilistic
model checking.
In Tobias Nipkow, Orna Grumberg, and Benedikt
Hauptmann, editors, Software Safety and Security - Tools for Analysis
and Veriﬁcation, volume 33 of NATO Science for Peace and Security
Series - D: Information and Communication Security, pages 126–151.
IOS Press, 2012. doi:10.3233/978-1-61499-028-4-126.

[27] YoungMin Kwon and Gul Agha. Linear inequality LTL (iltl): A model
checker for discrete time markov chains.
In Proceedings of ICFEM
2004, volume 3308 of Lecture Notes in Computer Science, pages 194–
208, 2004. URL: https://doi.org/10.1007/978-3-540-30482-1_21,
doi:10.1007/978-3-540-30482-1\_21.

[28] Oded Maler and Dejan Nickovic. Monitoring temporal properties of
continuous signals. In Proceedings of FORMATS and FTRTFT 2004,
volume 3253 of Lecture Notes in Computer Science, pages 152–166,
2004. doi:10.1007/978-3-540-30206-3\_12.

[29] Aditya P. Mathur and Nils Ole Tippenhauer. Swat: a water treat-
ment testbed for research and training on ICS security. In Proceedings
of CySWater@CPSWeek 2016, pages 31–36. IEEE Computer Society,
2016. doi:10.1109/CySWater.2016.7469060.

[30] D. Mercurio, V. Andersen, and K. Wagner. Decommissioning level 2
probabilistic risk assessment methodology for boiling water reactors. In
Proceedings of PSAM 13 2016, 2016.

[31] Lucia Nasti, Roberta Gori, and Paolo Milazzo. Formalizing a notion of
concentration robustness for biochemical networks. In Proceedings of
STAF 2018, volume 11176 of Lecture Notes in Computer Science, pages
81–97, 2018. URL: https://doi.org/10.1007/978-3-030-04771-9_
8, doi:10.1007/978-3-030-04771-9\_8.

[32] Dung Phan, Nicola Paoletti, Timothy Zhang, Radu Grosu, Scott A.
Smolka, and Scott D. Stoller. Neural state classiﬁcation for hy-
brid systems.
In Proceedings of ATVA 2018, volume 11138 of
Lecture Notes in Computer Science, pages 422–440, 2018. URL:

27

https://doi.org/10.1007/978-3-030-01090-4_25, doi:10.1007/
978-3-030-01090-4\_25.

[33] Amir Pnueli. The temporal logic of programs. In Proceedings of FOCS
1977, pages 46–57. IEEE Computer Society, 1977. doi:10.1109/SFCS.
1977.32.

[34] J¨org Raisch, Eberhard Klein, Siu O’Young, Christian Meder, and
Alexander Itigin. Approximating automata and discrete control for
continuous systems - two examples from process control. In Proceed-
ings of Hybrid Systems V, 1997, volume 1567 of Lecture Notes in Com-
puter Science, pages 279–303, 1997. URL: https://doi.org/10.1007/
3-540-49163-5_16, doi:10.1007/3-540-49163-5\_16.

[35] R. Rajkumar, I. Lee, L. Sha, and J. A. Stankovic. Cyber-physical
systems: the next computing revolution. In DAC, pages 731–736. ACM,
2010.

[36] Aur´elien Rizk, Gr´egory Batt, Fran¸cois Fages, and Sylvain Soliman. A
general computational method for robustness analysis with applications
to synthetic gene networks. Bioinform., 25(12), 2009. doi:10.1093/
bioinformatics/btp200.

[37] Aur´elien Rizk, Gr´egory Batt, Fran¸cois Fages, and Sylvain Soliman.
Continuous valuations of temporal logic speciﬁcations with applications
to parameter optimization and robustness measures. Theor. Comput.
Sci., 412(26):2827–2839, 2011. doi:10.1016/j.tcs.2010.05.008.

[38] Dorsa Sadigh and Ashish Kapoor.

Safe control under uncer-
tainty with probabilistic signal temporal
In Proceedings of
URL: http:
Robotics:
//www.roboticsproceedings.org/rss12/p17.html, doi:10.15607/
RSS.2016.XII.017.

Science and Systems XII 2016, 2016.

logic.

[39] Koushik Sen, Mahesh Viswanathan, and Gul Agha. Statistical model
checking of black-box probabilistic systems.
In Proceedings of CAV
2004, volume 3114 of Lecture Notes in Computer Science, pages 202–
215, 2004. URL: https://doi.org/10.1007/978-3-540-27813-9_16,
doi:10.1007/978-3-540-27813-9\_16.

[40] Koushik Sen, Mahesh Viswanathan, and Gul Agha. On statistical
In Proceedings of CAV 2005,
model checking of stochastic systems.
volume 3576 of Lecture Notes in Computer Science, pages 266–280,
2005. URL: https://doi.org/10.1007/11513988_26, doi:10.1007/
11513988\_26.

28

[41] Bharath K. Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Bernard
Sch¨olkopf, and Gert R. G. Lanckriet. On the empirical estimation of
integral probability metrics. Electronic Journal of Statistics, 6:1550–
1599, 2021. doi:10.1214/12-EJS722.

[42] D. Thorsley and E. Klavins. Approximating stochastic biochemical
processes with Wasserstein pseudometrics. IET Syst. Biol., 4(3):193–
211, 2010. doi:10.1049/iet-syb.2009.0039.

[43] Mattias Tiger and Fredrik Heintz. Stream reasoning using temporal
logic and predictive probabilistic state models. In Proceedings of TIME
2016, pages 196–205, 2016. doi:10.1109/TIME.2016.28.

[44] Mattias Tiger and Fredrik Heintz. Incremental reasoning in probabilis-
tic signal temporal logic. Int. J. Approx. Reason., 119:325–352, 2020.
doi:10.1016/j.ijar.2020.01.009.

[45] L. N. Vaserstein. Markovian processes on countable space product de-
scribing large systems of automata. Probl. Peredachi Inf., 5(3):64–72,
1969.

[46] C´edric Villani. Optimal transport: old and new, volume 338. Springer,

2008.

[47] Yu Wang, Nima Roohi, Matthew West, Mahesh Viswanathan, and
Geir E. Dullerud. Statistical veriﬁcation of PCTL using antithetic and
stratiﬁed samples. Formal Methods Syst. Des., 54(2):145–163, 2019.
doi:10.1007/s10703-019-00339-8.

[48] Paolo Zuliani, Andr´e Platzer, and Edmund M. Clarke. Bayesian sta-
tistical model checking with application to stateﬂow/simulink veriﬁca-
tion. Formal Methods Syst. Des., 43(2):338–367, 2013. doi:10.1007/
s10703-013-0195-3.

[49] K.J. ˚Astrom and M. Lundh. Lund control program combines theory
with hands-on experience. IEEE control systems, 3(12):22–30, 1992.
doi:10.1109/37.165511.

29

A Additional details on the three-tank experiment

Let A be the cross sectional area of each tank, and a be the cross sectional
area of the connecting and outlet pipes. The volume balance diﬀerence
equations of each tank, considering ∆τ = 1 as sampling time interval, are
the following:

A(l1(τ + 1) − l1(τ )) = q1(τ ) − q12(τ )
A(l2(τ + 1) − l2(τ )) = q12(τ ) − q23(τ )
A(l3(τ + 1) − l3(τ )) = q2(τ ) + q23(τ ) − q0(τ ).

(8)

We can then apply Torricelli’s law to the equations in (8) to obtain the ﬂow
rates q12 and q23:







q12(τ ) =

q23(τ ) =

(cid:113)

a12(τ )a



−a12(τ )a

2g(cid:0)l1(τ ) − l2(τ )(cid:1)
(cid:113)

2g(cid:0)l2(τ ) − l1(τ )(cid:1)

(cid:113)

a23(τ )a



−a23(τ )a

2g(cid:0)l2(τ ) − l3(τ )(cid:1)
(cid:113)

2g(cid:0)l3(τ ) − l2(τ )(cid:1)

if l1(τ ) ≥ l2(τ )

otherwise;

if l2(τ ) ≥ l3(τ )

otherwise;

where g is the gravitational constant, and a12, a23 are the loss coeﬃcients of
the respective pipes. These coeﬃcients are represented as time dependent
functions since they depend on the geometry of the pipes and on the water
level in the tanks. In our experiments (see the script at https://github.
com/gitUltron/Ultron), we have used the approximation g = 9.81, and the
following values for the aforementioned coeﬃcients: (i) a = 0.5, (ii) a12 =
0.75, (iii) a23 = 0.75.

B Proof of Lemma 1

Lemma 1. For any penalty function ρ, and systems s1 and s2 we have that:

(cid:96)ρ,OT(s1, s2) ≤ max(mλ

ρ,OT(s1, s2), mλ

ρ,OT(s2, s1)).

Proof. It is enough to show that

s1,τ −
ϕ
|
(cid:75)
(cid:74)

ϕ
(cid:74)

s2,τ | ≤ max(mλ
(cid:75)

ρ,OT(s1, s2), mλ

ρ,OT(s2, s1))

holds for all EvTL formula ϕ and τ ∈ OT. We proceed by structural induc-
tion over ϕ.

• Base case ϕ ≡ (cid:62). Immediate.

30

• Base case ϕ ≡ target(µ)ρ

p. We distinguish two cases. The ﬁrst case is

W(mD

ρ,τ )(µ, Ss1,τ ) ≥ W(mD

ρ,τ )(µ, Ss2,τ ). We have

ϕ
(cid:74)

s2,τ |
s1,τ −
ϕ
|
(cid:75)
(cid:75)
(cid:74)
= |p − λ(τ ) W(mD
= λ(τ ) W(mD
≤ λ(τ ) W(mD
= λ(τ ) W(mD
≤ mλ
≤ max(mλ

ρ,OT(s2, s1)

ρ,τ )(µ, Ss1,τ ) − p + λ(τ ) W(mD

ρ,τ )(µ, Ss2,τ )|

ρ,τ )(µ, Ss1,τ ) − λ(τ ) W(mD
ρ,τ )(µ, Ss2,τ ) + λ(τ ) W(mD
ρ,τ )(Ss2,τ , Ss1,τ )

ρ,τ )(µ, Ss2,τ )
ρ,τ )(Ss2,τ , Ss1,τ ) − λ(τ ) W(mD

ρ,τ )(µ, Ss2,τ )

ρ,OT(s1, s2), mλ

ρ,OT(s2, s1))

with the fourth step by the triangular property.
The second case is W(mD
ρ,τ )(µ, Ss1,τ ) < W(mD
treated as the previous one, by exchanging the roles of s1 and s2.

ρ,τ )(µ, Ss2,τ ) and can be

• Base case ϕ ≡ brink(µ)ρ

p. This case is analogous to case ϕ ≡ target(µ)ρ
p.

• Inductive step ¬ϕ. We have

s1,τ −
s2,τ |
¬ϕ
¬ϕ
|
(cid:75)
(cid:75)
(cid:74)
(cid:74)
s1,τ − (−
s2,τ )|
ϕ
ϕ
= | −
(cid:74)
(cid:74)
(cid:75)
(cid:75)
s1,τ |
ϕ
s2,τ −
ϕ
= |
(cid:75)
(cid:74)
(cid:75)
(cid:74)
ρ,OT(s1, s2), mλ
≤ max(mλ

ρ,OT(s2, s1))

with the last step by the inductive hypothesis.

• Inductive step ϕ1 ∨ ϕ2. We distinguish two cases.
The ﬁrst case is max(
ϕ1
ϕ1
(cid:74)
(cid:74)
We have two subcases. The ﬁrst subcase is
ϕ1
(cid:74)
have:

s1,τ ) ≥ max(
(cid:75)

s1,τ ,
(cid:75)

ϕ2
(cid:74)

s2,τ ).
ϕ2
s2,τ ,
(cid:75)
(cid:75)
(cid:74)
s1,τ . We
ϕ2
s1,τ ≥
(cid:75)
(cid:74)
(cid:75)

s1,τ −
ϕ1 ∨ ϕ2
|
ϕ1 ∨ ϕ2
s2,τ |
(cid:74)
(cid:75)
(cid:74)
(cid:75)
s1,τ ,
ϕ1
= | max(
ϕ2
s1,τ ) − max(
ϕ1
(cid:74)
(cid:75)
(cid:74)
(cid:74)
(cid:75)
ϕ2
s1,τ ,
ϕ1
ϕ1
s1,τ ) − max(
= max(
(cid:74)
(cid:75)
(cid:74)
(cid:75)
(cid:74)
s2,τ )
ϕ1
s1,τ − max(
ϕ1
(cid:75)
(cid:75)
(cid:74)
(cid:74)
≤
s1,τ −
ϕ1
s2,τ
(cid:75)
(cid:75)
(cid:74)
ρ,OT(s1, s2), mλ
≤ max(mλ

ρ,OT(s2, s1))

s2,τ ,
(cid:75)

ϕ2
(cid:74)

ϕ1
(cid:74)

=

s2,τ ,
(cid:75)
s2,τ ,
(cid:75)

ϕ2
(cid:74)
ϕ2
(cid:74)

s2,τ )|
(cid:75)
s2,τ )
(cid:75)

with the last step by the inductive hypothesis.
The second subcase is
s1,τ <
ϕ2
(cid:75)
(cid:74)
same arguments, by exchanging the role of ϕ1 and ϕ2.
The second case is max(
s2,τ )
ϕ2
ϕ1
(cid:75)
(cid:74)
(cid:74)
and is obtained with the same arguments of the ﬁrst case, by exchang-
ing the role of s1 and s2.

s1,τ and is obtained with the
(cid:75)
ϕ1
s1,τ ) < max(
(cid:74)
(cid:75)

s1,τ ,
(cid:75)

s2,τ ,
(cid:75)

ϕ2
(cid:74)

ϕ1
(cid:74)

31

• Inductive case ϕ1 U [a,b] ϕ2. We distinguish two cases.
s2,τ .
(cid:75)
, we have that

ϕ1 U [a,b] ϕ2
The ﬁrst case is
(cid:74)
By deﬁnition of the semantic function

ϕ1 U [a,b] ϕ2
(cid:74)

s1,τ ≥
(cid:75)

(cid:74) (cid:75)

(cid:26)

s1,τ (cid:48), min
(cid:75)

τ (cid:48)(cid:48)∈[τ +a,τ (cid:48))(cid:74)

ϕ1

(cid:27)

,

s1,τ (cid:48)(cid:48)
(cid:75)

min

max
τ (cid:48)∈[τ +a,τ +b]

ϕ1 U [a,b] ϕ2
s1,τ =
(cid:74)
(cid:75)
which equals the value min (cid:8)
ϕ2
(cid:74)
suitable τ (cid:48)(cid:48)(cid:48).
We have two subcases. The ﬁrst subcase is
We have:

ϕ2
(cid:74)

s1,τ (cid:48)(cid:48)(cid:48), minτ (cid:48)(cid:48)∈[τ +a,τ (cid:48)(cid:48)(cid:48))
(cid:75)

ϕ1
(cid:74)

s1,τ (cid:48)(cid:48)
(cid:75)
s2,τ (cid:48)(cid:48)(cid:48) ≤ minτ (cid:48)(cid:48)∈[τ +a,τ (cid:48)(cid:48)(cid:48))
(cid:75)

ϕ2
(cid:74)

(cid:9) for a

ϕ1
(cid:74)

s2,τ (cid:48)(cid:48).
(cid:75)

|

=

ϕ1 U [a,b] ϕ2
(cid:74)
ϕ1 U [a,b] ϕ2
(cid:74)
(cid:26)
= min

s1,τ −
(cid:75)
s1,τ −
(cid:75)

ϕ1 U [a,b] ϕ2
(cid:74)
ϕ1 U [a,b] ϕ2
(cid:74)

s2,τ |
(cid:75)
s2,τ
(cid:75)

(cid:27)

ϕ2
(cid:74)

s1,τ (cid:48)(cid:48)(cid:48), min
(cid:75)

τ (cid:48)(cid:48)∈[τ +a,τ (cid:48)(cid:48)(cid:48))(cid:74)

ϕ1

ϕ2
(cid:74)

s1,τ (cid:48)(cid:48)(cid:48), min
(cid:75)

τ (cid:48)(cid:48)∈[τ +a,τ (cid:48)(cid:48)(cid:48))(cid:74)

ϕ1

≤ min

(cid:26)

(cid:26)

= min

ϕ2
s1,τ (cid:48)(cid:48)(cid:48), min
(cid:74)
(cid:75)
≤
s1,τ (cid:48)(cid:48)(cid:48) −
ϕ2
(cid:75)
(cid:74)
≤ max(mλ

ϕ2
s2,τ (cid:48)(cid:48)(cid:48)
(cid:75)
(cid:74)
ρ,OT(s1, s2), mλ

τ (cid:48)(cid:48)∈[τ +a,τ (cid:48)(cid:48)(cid:48))(cid:74)

ϕ1

ρ,OT(s2, s1))

− max

τ (cid:48)∈[τ +a,τ +b]
(cid:26)

(cid:26)

min

ϕ2
(cid:74)

s2,τ (cid:48), min
(cid:75)

τ (cid:48)(cid:48)∈[τ +a,τ (cid:48))(cid:74)
(cid:27)

ϕ1

s2,τ (cid:48)(cid:48)(cid:48), min
(cid:75)

τ (cid:48)(cid:48)∈[τ +a,τ (cid:48)(cid:48)(cid:48))(cid:74)

ϕ1

s2,τ (cid:48)(cid:48)
(cid:75)

− min

ϕ2
(cid:74)

−

ϕ2
(cid:74)

s2,τ (cid:48)(cid:48)(cid:48)
(cid:75)

s1,τ (cid:48)(cid:48)
(cid:75)

s1,τ (cid:48)(cid:48)
(cid:75)

s1,τ (cid:48)(cid:48)
(cid:75)

(cid:27)

(cid:27)

with the ﬁrst step since we are in the ﬁrst case, the second step from
the deﬁnition of τ (cid:48)(cid:48)(cid:48), the fourth step since we are in the ﬁrst subcase
and the last step by the inductive hypothesis.
The second subcase is
ϕ2
(cid:74)
such that minτ (cid:48)(cid:48)∈[τ +a,τ (cid:48)(cid:48)(cid:48))

s2,τ (cid:48)(cid:48). Let τ (cid:48)(cid:48)(cid:48)(cid:48) be
(cid:75)

ϕ1
(cid:74)
s2,τ (cid:48)(cid:48)(cid:48)(cid:48). We have:
(cid:75)

s2,τ (cid:48)(cid:48)(cid:48) > minτ (cid:48)(cid:48)∈[τ +a,τ (cid:48)(cid:48)(cid:48))
(cid:75)
ϕ1
ϕ1
(cid:74)
(cid:74)
s2,τ |
(cid:75)
s2,τ
(cid:75)

s2,τ (cid:48)(cid:48) =
(cid:75)
φ1 U [a,b] φ2
(cid:74)
φ1 U [a,b] φ2
(cid:74)

(cid:27)

(cid:27)

s2,τ (cid:48)(cid:48)
(cid:75)

(cid:27)

s2,τ (cid:48)(cid:48)
(cid:75)

− max

τ (cid:48)∈[τ +a,τ +b]
(cid:26)

(cid:26)

min

ϕ2
(cid:74)

s2,τ (cid:48), min
(cid:75)

τ (cid:48)(cid:48)∈[τ +a,τ (cid:48))(cid:74)
(cid:27)

ϕ1

− min

ϕ2
(cid:74)

s2,τ (cid:48)(cid:48)(cid:48), min
(cid:75)

τ (cid:48)(cid:48)∈[τ +a,τ (cid:48)(cid:48)(cid:48))(cid:74)

ϕ1

s2,τ (cid:48)(cid:48)
(cid:75)

−

min
τ (cid:48)(cid:48)∈[τ +a,τ (cid:48)(cid:48)(cid:48))(cid:74)

ϕ1

s2,τ (cid:48)(cid:48)
(cid:75)

−

ϕ1
(cid:74)

s2,τ (cid:48)(cid:48)(cid:48)(cid:48)
(cid:75)

s1,τ (cid:48)(cid:48)
(cid:75)

s1,τ (cid:48)(cid:48)
(cid:75)

s1,τ (cid:48)(cid:48)
(cid:75)

s1,τ (cid:48)(cid:48)
(cid:75)

(cid:27)

(cid:27)

(cid:27)

=

φ1 U [a,b] φ2
|
(cid:74)
φ1 U [a,b] φ2
(cid:74)
(cid:26)
= min

s1,τ −
(cid:75)
s1,τ −
(cid:75)

ϕ2
(cid:74)

s1,τ (cid:48)(cid:48)(cid:48), min
(cid:75)

τ (cid:48)(cid:48)∈[τ +a,τ (cid:48)(cid:48)(cid:48))(cid:74)

ϕ1

ϕ2
(cid:74)

s1,τ (cid:48)(cid:48)(cid:48), min
(cid:75)

τ (cid:48)(cid:48)∈[τ +a,τ (cid:48)(cid:48)(cid:48))(cid:74)

ϕ1

(cid:26)

(cid:26)

≤ min

= min

s1,τ (cid:48)(cid:48)(cid:48), min
(cid:75)

τ (cid:48)(cid:48)∈[τ +a,τ (cid:48)(cid:48)(cid:48))(cid:74)

ϕ1

ϕ2
(cid:74)
(cid:26)

= min

ϕ2
s1,τ (cid:48)(cid:48)(cid:48), min
(cid:74)
(cid:75)
≤
s1,τ (cid:48)(cid:48)(cid:48)(cid:48) −
ϕ1
(cid:75)
(cid:74)
≤ max(mλ

ϕ1
s2,τ (cid:48)(cid:48)(cid:48)(cid:48)
(cid:74)
(cid:75)
ρ,OT(s1, s2), mλ

τ (cid:48)(cid:48)∈[τ +a,τ (cid:48)(cid:48)(cid:48))(cid:74)

ϕ1

ρ,OT(s2, s1))

32

with the ﬁrst step since we are in the ﬁrst case, the second step from the
deﬁnition of τ (cid:48)(cid:48)(cid:48), the fourth step since we are in the second subcase, the
ﬁfth step from the deﬁnition of τ (cid:48)(cid:48)(cid:48)(cid:48) and the last step by the inductive
hypothesis.

C Proof of Lemma 2

Lemma 2. For all systems s1, s2 and penalty functions ρ, there is a formula
ϕ ∈ Lρ with |
, for
some τ ∈ OT.

s2,τ | = max
ϕ
(cid:75)
(cid:74)

(cid:17)
ρ,OT(s2, s1)

ρ,OT(s1, s2), mλ

s1,τ −
(cid:75)

ϕ
(cid:74)

mλ

(cid:16)

Proof. Given the set of observation times OT, we let

τ1 = arg max
τ ∈OT
τ2 = arg max
τ ∈OT

λ(τ ) W(mD

ρ,τ )(Ss1,τ , Ss2,τ )

λ(τ ) W(mD

ρ,τ )(Ss2,τ , Ss1,τ )

so that

(cid:110)

max

ρ,OT(s1, s2), mλ

mλ
= max (cid:8)λ(τ1) W(mD

ρ,OT(s2, s1)

(cid:111)

ρ,τ1)(Ss1,τ1, Ss2,τ1), λ(τ2) W(mD

ρ,τ2)(Ss2,τ2, Ss1,τ2)(cid:9) .

Assume, without loos of generality, that

λ(τ1) W(mD

ρ,τ1)(Ss1,τ1, Ss2,τ1) ≥ λ(τ2) W(mD

ρ,τ2)(Ss2,τ2, Ss1,τ2).

In the symmetric case, the proof follows by switching the roles of s1 and s2.

Consider the formula

ϕ = target(µ)ρ
p

µ = Ss1,τ1
p = λ(τ2) W(mD

ρ,τ2)(Ss2,τ2, Ss1,τ2).

Then we have

s1,τ1 = p − λ(τ1) W(mD
ϕ
(cid:75)
(cid:74)
= λ(τ2) W(mD
= λ(τ2) W(mD
s2,τ1 = p − λ(τ1) W(mD
ϕ
(cid:75)
(cid:74)
= λ(τ2) W(mD

ρ,τ1)(µ, Ss1,τ1)

ρ,τ2)(Ss2,τ2, Ss1,τ2) − λ(τ1) W(mD
ρ,τ2)(Ss2,τ2, Ss1,τ2)
ρ,τ1)(µ, Ss2,τ1)

ρ,τ2)(Ss2,τ2, Ss1,τ2) − λ(τ1) W(mD

ρ,τ1)(Ss1,τ1, Ss2,τ1)

ρ,τ1)(Ss1,τ1, Ss1,τ1)

from which we obtain

s2,τ1| = λ(τ1) W(mD
ϕ
s1,τ1 −
ϕ
(cid:75)
(cid:74)
(cid:75)
(cid:74)
thus concluding the proof.

|

ρ,τ1)(Ss1,τ1, Ss2,τ1)

33

D Proof of Theorem 2

1, . . . , dN
Theorem 2. Let µ, ν ∈ ∆(D, BD) be unknown. Let {d1
1 } be in-
dependent samples taken from µ, and {d1
2 } independent samples
taken from ν. Let {ωj = ρi(dj
1)} and {νh = ρi(dh
2 )} be the ordered sequences
obtained by applying the i-penalty function to the samples. Then, it holds,
almost surely, that

2, . . . , d(cid:96)·N

W(mD

ρ,i)(µ, ν) = lim
N →∞

1
(cid:96)N

(cid:96)N
(cid:88)

h=1

max

(cid:110)

νh − ω(cid:100) h

(cid:96) (cid:101), 0

(cid:111)

.

Proof. We split the proof into two parts showing respectively:

W(mD

ρ,i)(µ, ν) = lim
N →∞

W(mD

ρ,i)(ˆµN , ˆν(cid:96)N

s2,i) .

W(mD

ρ,i)(ˆµN , ˆν(cid:96)N ) =

1
(cid:96)N

(cid:96)N
(cid:88)

h=1

max

(cid:110)

νh − ω(cid:100) h

(cid:96) (cid:101), 0

(9)

(10)

(cid:111)

.

where ˆµN and ˆν(cid:96)N are the estimated probability distributions obtained from
µ and ν by sampling N and (cid:96)N values.

• Proof of Equation (9).

We recall that the sequence {ˆµN } (resp. {ˆνN }) converges weakly
to µ (resp.
ν) (see Equation (7)). Moreover, we can prove that
these sequences converge weakly in ∆(D, BD) in the sense of [46,
In fact, given the i-ranking function ρi, the exis-
Deﬁnition 6.8].
tence of a data state ˜d such that ρi(˜d) = 0 is guaranteed (remem-
ber that the constraints used to deﬁne ρi are on the possible values
of state variables and a data state fulﬁlling all the requirements is
ρ,i(˜d, d) =
assigned value 0). Thus, for any d ∈ D we have that mD
max{ρi(d) − ρi(˜d), 0} = ρi(d). Since, moreover, by deﬁnition ρi is
continuous and bounded, the weak convergence of the probability mea-
sures gives (cid:82)
(cid:82)
D ρi(d)d(ν(d)) and thus Deﬁnition 6.8.(i) of [46] is satisﬁed. As D is
a Polish space, by [46, Theorem 6.9] we obtain that

D ρi(d)d(ˆµN (d)) → (cid:82)

D ρi(d)d(µ(d)) and (cid:82)

D ρi(d)d(ˆν(cid:96)N (d)) →

ˆµN → µ and ˆν(cid:96)N → ν implies W(mD

ρ,i)(µ, ν) = lim
N →∞

W(mD

ρ,i)(ˆµN , ˆν(cid:96)N ) .

• Proof of Equation (10).

For this part of the proof we follow [42]. Since the ranking func-
tion is continuous, it is in particular BD measurable and therefore
for any probability measure µ on (D, BD) we obtain that Fµ,ρi(r) :=
µ({ρi(d) < r}) is a well deﬁned cumulative distribution function.

34

Since, moreover, we can always assume that the values ρi(dj
1) are
sorted, so that ρi(dj
) for each j = 1, . . . , N − 1, we can
express the counter image of the cumulative distribution function as

i ) ≤ ρi(dj+1

1

F −1

ˆµN ,ρi

(r) = ρi(dj

1) whenever

j − 1
N

< r ≤

j
N

.

(11)

A similar reasoning holds for F −1

ˆν(cid:96)N ,ρi

(r).

Then, by [17, Proposition 6.2], for each N we have that

W(mD

ρ,i)(ˆµN , ˆν(cid:96)N ) =

(cid:90) 1

0

max

(cid:110)

F −1

ˆνD,(cid:96)N ,ρi

(r) − F −1

ˆµD,N ,ρi

(cid:111)

(r), 0

dr .

Let us now partition the interval [0, 1] into (cid:96)N intervals of size 1
thus obtaining

(cid:96)N ,

W(mD

ρ,i)(ˆµN , ˆν(cid:96)N ) =

(cid:96)N
(cid:88)

h=1

(cid:32)(cid:90) h

(cid:96)N

h−1
(cid:96)N

max

(cid:110)

F −1

ˆν(cid:96)N ,ρi

(r) − F −1

ˆµN ,ρi

(cid:111)

(r), 0

(cid:33)

dr

.

From Equation (11), on each interval ( h−1

(cid:96)N , h

(cid:96)N ] it holds that F −1

ˆνN ,ρi

(r) =

(cid:100) h
(cid:96) (cid:101)
1

) and F −1

ρi(d
2 ). Moreover, both functions are con-
stant on each the interval so that the value of the integral is given by
the diﬀerence multiplied by the length of the interval:

ˆν(cid:96)N ,ρi

(r) = ρi(dh

W(mD

ρ,i)(ˆµN , ˆν(cid:96)N ) =

=

(cid:96)N
(cid:88)

h=1
(cid:96)N
(cid:88)

h=1

1
(cid:96)N

1
(cid:96)N

(cid:26)

max

ρi(dh

2 ) − ρi(d

(cid:27)

(cid:100) h
(cid:96) (cid:101)
1

), 0

max

(cid:110)

νh − ω(cid:100) h

(cid:96) (cid:101), 0

(cid:111)

.

By substituting the last equality into Equation (9) we obtain the thesis.

E Proof of Theorem 3

Theorem 3. For any formula ϕ, system s, data state ds, and integer (cid:96) > 0

lim
N (cid:55)→∞

Robust(ds, ϕ, (cid:96), N ) =

s.
ϕ
(cid:75)
(cid:74)

Proof. The proof follows by induction on the structure of the formula ϕ,
using Theorem 2 to deal with the base cases of ϕ = target(µ)ρ
p and ϕ =
brink(µ)ρ
p.

35

i ← 0
c ← ds
a ← c
while i ≤ k do

1: function Simul(ds, k)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11: end function

c ← SimStep(c)
a ← a, c
i ← i + 1

end while
return a

1, . . . , dN
2, . . . , d(cid:96)N

1: function ComputeWass(E1, E2, ρ)
(d1
1 ) ← E1
2:
(d1
2 ) ← E2
3:
∀j : (1 ≤ j ≤ N ) : ωj ← ρ(dj
1)
4:
∀h : (1 ≤ h ≤ (cid:96)N ) : νh ← ρ(dh
2 )
5:
re index {ωj} s.t. ωj ≤ ωj+1
6:
re index {νh} s.t. νh ≤ νh+1
7:

8:

return 1
(cid:96)N

9: end function

(cid:96)N
(cid:88)

h=1

max{νh − ω(cid:100) h

(cid:96) (cid:101), 0}

∀i : (0 ≤ i ≤ k) : Ei ← ∅
counter ← 0
while counter < N do

1: function Estimate(ds, k, N )
2:
3:
4:
5:
6:
7:
8:
9:
10: end function

(c0, . . . , ck) ← Simul(ds, k)
∀i : Ei ← Ei, ci
counter ← counter + 1

end while
return E0, . . . , Ek

F The algorithms

Given an initial data state ds and an integer k, we use function Simul
to sample a sequence of data states d0, d1, . . . , dk, modelling k-steps of a
computation from ds = d0. Each simulation step is performed by means of
function SimStep. The exact deﬁnition of function SimStep depends on
the kind of model underlying the generation of the evolution sequence. As
we are abstracting from such a model, we only assume that for any d ∈ D
and measurable set D ∈ BD:

Pr (SimStep(d) ∈ D) = step(d)(D).

We use function Estimate to obtain the empirical evolution sequence
of system s starting from ds. Function Estimate(ds, k, N ) invokes N times
function Simul to obtain N sampled sequences of data states dj
0, . . . , dj
k,
for j = 1, . . . , N , from ds = d0. It returns the sequence of sets of samples
E0, . . . , Ek, where Ei is the tuple d1
i of the data states observed at
time i in each of the N sampled computations.

i , . . . , dN

36

