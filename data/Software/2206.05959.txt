A Live Extensible Ontology of Quality Factors for
Textual Requirements

1st Julian Frattini
4th Michael Unterkalmsteiner
5th Daniel Mendez*, 6th Davide Fucci
Blekinge Institute of Technology
Karlskrona, Sweden
{ﬁrstname}.{lastname}@bth.se

2nd Lloyd Montgomery
University of Hamburg
Hamburg, Germany
lloyd.montgomery@uni-hamburg.de

3rd Jannik Fischbach
Netlight Consulting GmbH and *fortiss GmbH
Munich, Germany
jannik.ﬁschbach@netlight.com

2
2
0
2

n
u
J

3
1

]
E
S
.
s
c
[

1
v
9
5
9
5
0
.
6
0
2
2
:
v
i
X
r
a

Abstract—Quality factors like passive voice or sentence length
are commonly used in research and practice to evaluate the
quality of natural
language requirements since they indicate
defects in requirements artifacts that potentially propagate to
later stages in the development life cycle. However, as a research
community, we still lack a holistic perspective on quality factors.
This inhibits not only a comprehensive understanding of the
existing body of knowledge but also the effective use and evolution
of these factors. To this end, we propose an ontology of quality
factors for textual requirements, which includes (1) a structure
framing quality factors and related elements and (2) a central
repository and web interface making these factors publicly
accessible and usable. We contribute the ﬁrst version of both by
applying a rigorous ontology development method to 105 eligible
primary studies and construct a ﬁrst version of the repository and
interface. We illustrate the usability of the ontology and invite
fellow researchers to a joint community effort to complete and
maintain this knowledge repository. We envision our ontology to
reﬂect the community’s harmonized perception of requirements
quality factors, guide reporting of new quality factors, and
provide central access to the current body of knowledge.

Index Terms—requirements engineering, requirements quality,

quality factor, ontology

I. INTRODUCTION

Context. A requirements quality factor [1] is a normative
metric which maps a textual requirement of a speciﬁc granu-
larity to a scale which informs about the quality of this input.
Because quality factors can be calculated entirely on textual
input and do not necessarily need to consider the perspective
of any stakeholder who is intended to use the requirement,
factors are an efﬁcient tool for early estimates of requirements
quality, often even eligible for full automation. This satisﬁes
the need for detecting potential defects in textual requirements
at an early stage, as the cost for addressing these defects
increases the longer they stay undetected, putting the project
success at risk when treated poorly [2]. The applicability of
quality factors is corroborated by the plethora of existing tools
which automate their detection [3], [4]. Among the popular
requirements quality factors are passive voice [4], where the
use of a verb in passive voice is associated with ambiguity
of a requirement due to the omission of the subject within a
sentence, and sentence length [5], where exceeding a speciﬁc
threshold of words or characters in a sentence is associated

with complexity due to the sentence becoming increasingly
hard to comprehend.

Problem. Requirements quality research is lacking a holis-
tic perspective on quality factors and a central repository
containing the existing body of knowledge to enable reuse
and evolution. These two gaps result in challenges such as
concurrent work on same or similar quality factors instead of
reusing and advancing those already established. For example,
anaphora or anaphoric ambiguity is described as “an expres-
sion used, in language, to refer to another expression” [6],
“a linguistic expression that refers to a preceding utterance
in text” [7], and “whenever a pronoun (e.g., he, it, that, this,
which, etc.) refers to a previous part of the text” [5]. While
a certain degree of similarity between all three competing
descriptions is apparent, the lack of consensus on the deﬁnition
is bound to introduce ambiguity to the understanding of the
quality factor. Furthermore, another challenge of requirements
quality research is the proposal of shallow quality factors
neglecting practical relevance due to insufﬁcient or anecdotal
evidence [3].

Approach. We take the ﬁrst step at tackling these prob-
lems by deﬁning requirements quality factors, their related
elements like data sets and automatic detection approaches,
and the relationships between the elements. These elements
and their relationship constitute our domain of interest. Next,
we formalize this domain into an ontology where each element
is represented by an individual taxonomy initially derived from
literature. Using a set of 105 primary studies from the area of
empirical research on requirements quality [3], we rigorously
improve the structure of the ontology by applying established
guidelines [8] and extracted eligible objects to populate the
ontology. Finally, the reﬁned structure of the ontology as well
as all extracted objects are stored centrally in a repository and
visualized through a connected web interface.

Structure. After discussing related work in Sec. II, we
elaborate the long-term objectives of this research direction
in Sec. III by explaining the domain of requirements quality
factors as well as the corresponding ontology development
method in Sec. IV. Sec. V describes the ﬁrst step taken
towards this long-term objective in the scope of this work
by presenting the process and results of the ﬁrst prototype

 
 
 
 
 
 
at ontology development. Challenges are outlined in Sec. VI
before calling for action in Sec. VII to involve the requirements
quality research community in a joint effort at advancing
and maintaining a harmonized vision of requirements quality
before concluding in Sec. VIII.

II. RELATED WORK

The concept of requirements quality factors has been im-
plicitly used in many publications over the last years: Femmer
et al. [4], for instance, introduce nine requirements smells,
which indicate quality violations in textual requirements. Din
and Rine [9] propose a metric for requirements complexity,
which is referred to as a requirements indicator. Ormandjieva
et al. [10] gather several quality characteristics to deﬁne
the quality of requirements text. We continue using the term
quality factor which was applied in this context by Femmer
et al. [11], since the term avoids the negative connotation that
for example requirements smell evokes, opening the concept
of quality factors up to also represent positive impacts on
requirements quality, and since the term is well-embedded into
a larger context of requirements quality [11].

Several sets of requirements quality factors have already
been proposed in literature, among which are–as previously
mentioned–the requirements smells proposed by Femmer et
al. [4], the quality user story framework introduced by Lu-
cassen et al. [12], and the framework for quality measurement
developed by G´enova et al. [13]. Previous attempts at estab-
lishing a subject-based classiﬁcation for requirements quality
are to the best of our knowledge limited to an approach by
Saavedra et al. [14], which is, however, on a coarser granu-
larity and elicits only high-level requirements quality aspects
like correctness, completeness, and others. The work most
comparable to our approach has been conducted by Femmer
et al. [15], where 129 industrial requirements writing rules
were classiﬁed regarding their eligibility for automation. Our
own work differs from theirs in that (1) we aim at integrating
quality factors established in peer-reviewed literature instead
of in industrial writing rules [15] into a holistic ontology,
while (2) considering the eligibility of the individual factors
for automation only as one of many sub-goals. Further (3),
as our endeavour shall lay the groundwork for a long-term
community initiative, one main contribution is to publicly
disclose all of our results for an effective maintenance and
evolution of the ontology by the community.

III. LONG-TERM OBJECTIVE

We begin by framing the long-term objective of our ini-
tiative. While this objective is out of scope of this paper, it
guides the design and implementation of the prototype.

A. Establishing a Requirements Quality Factor Domain

Harmonizing the perspectives on requirements quality fac-
tors presupposes understanding the domain of related elements
in which factors are embedded. We conceptualize four relevant
elements during initial investigations of the available literature
(see Fig. 1). We consider a requirements quality factor–as

Fig. 1. Schema of the ontology structure in Crow’s foot notation [16]

described in the introduction–as a normative metric which
maps a textual requirement at a speciﬁc level of granularity to
a scale which informs about the quality of this input, where
the level of granularity represents different ranges of text (e.g.,
words, sentences, or documents) and the scale is an often
binary categorization of whether the factor has a positive or
negative impact on speciﬁc aspects of quality (e.g., ambiguity,
consistency) [14]. The lack of an explicit deﬁnition of this
concept so far, however, led to quality factors only being
referred to implicitly in literature. This resulted in the abstract
concept of quality factors being instantiated predominantly
as descriptions of varying levels of formality in literature.
Consequently, the abstract element of a quality factor is related
to one or more description elements which deﬁne the factor.

Evaluating textual requirements artifacts against these de-
scriptions of quality factors is a way of estimating the quality
of the requirements. In several cases,
this evaluation can
be automated: in our domain, we denote an approach for
automatically detecting violations against a quality factor as an
approach, which is associated to at least one description since
approaches often automate the detection of several quality
factors. These approaches are evaluated on data sets, which
may have information about certain quality factors embedded
into them, for example through the annotation of violations
against a set of quality factors.

We deem these four elements relevant for achieving our
objective: the quality factors serve as a conceptual anchor for
our objects of interest, descriptions make the factors tangible
and comprehensible, and data sets as well as approaches
facilitate application and reuse of the factors. We do not claim
exhaustive completeness of the domain but rather use it as
a starting point for the ﬁrst iteration. Hence, we focus on
extracting these four types of elements from existing literature.

B. Guiding the Ontology Development

In order to formalize these domain elements, we select
the simplest subject-based classiﬁcation system capable of
representing the domain elements and their relationships [17].
Hence, we formalize our domain of interest as an ontology,
where each element is represented by a taxonomy. All objects
contained in each taxonomy are classiﬁed in a ﬁxed number
of dimensions speciﬁc to that taxonomy. As visualized in
Fig. 1, an object contained for example in the quality factor
taxonomy is classiﬁed among others by the dimension scope.
Each object takes exactly one value per dimension, where the
set of all possible values of a dimension is called the character-
istics [17]. The dimension scope contains the characteristics
word, sentence, and others. We denote the collection of all
dimensions and characteristics of a taxonomy as its structure.
The structure of the ontology is the collection of all taxonomy
structures.

Strictly categorical dimensions are not able to represent cer-
tain attributes of an object in the context of our ontology. First,
references between two objects of different taxonomies require
indexing each object, where indices are not meaningful char-
acteristics. Second, textual attributes like a natural language
description of a quality factor can also not be represented by
a ﬁnite set of characteristics. We therefore extend the attributes
of our subject based-classiﬁcation by indices as well as scope
notes as commonly used in thesauri [17], which enables a
proper description of objects. Each quality factor object for
example contains a scope note name to associate the object
with a unique label.

For the sake of brevity in notation we also introduce
dimension-clusters, which consist of a list of dimensions and
a list of characteristics, where the latter applies to each di-
mension. A dimension-cluster abbreviates similar dimensions,
e.g., the dimension cluster quality aspects of the quality factor
taxonomy contains dimensions like ambiguity, complexity, and
veriﬁability, which all can take the characteristics impacted
positively, impacted negatively, or not impacted individually.
We translate the rigorous taxonomy development guideline
proposed by Nickerson et al. [8] and extended by Kundisch
et al. [18] to the larger scale of our ontology. None of the
aspects in which our ontology design extends the design of
a taxonomy contradicts the abstract guidelines, since (1) the
ontology simply consists of four individual taxonomies and
(2) the extraction guideline is applicable to the additionally
included index and scope note attribute as well.

IV. PROVISIONAL ONTOLOGY DESIGN

We take a step towards our long-term objective by deﬁning
requirements and exit criteria of the ontology creation process.

A. Meta-Characteristics

As deﬁned in the guideline [8], the design of the clas-
siﬁcation system is rooted in the identiﬁcation of the users
which are intended to use the ontology, and their goals, which
these users are supposed to achieve with the ontology. We
consider two types of users to interact with the ontology:

researchers dedicated to advancing the ﬁeld of requirements
quality research and practitioners aiming to apply results
emerging from this research in order to evaluate the quality
of their requirements artifacts. The goals of these two abstract
users constitute the meta-characteristics [8] and represent the
high-level requirements for the ontology. The following goals
(G) are formulated in the user story template:
• G1: As a researcher or practitioner, I want to ﬁnd expla-
nations to available requirements quality factors so that I
understand how they inform about requirements quality.
• G2: As a researcher or practitioner, I want to ﬁnd available
resources connected to a quality factor so that I can reuse
these resources for my own work.

• G3: As a researcher, I want to identify gaps in literature
so that I can tailor my own research to provide valid
contributions.

• G4: As a researcher or practitioner, I want to ﬁnd who is
working on speciﬁc quality factors so that I can establish a
collaboration.

These goals strictly apply to the ontology. The obvious, over-
arching goal to evaluate the quality of requirements artifacts
applies to the quality factors and is independent of our goals.

B. Exit criteria

The exit criteria, which indicate the completeness of the
iterative ontology development method, are also derived from
Nickerson et al. [8]. In this, we aim to achieve the following
objective ending conditions (condensed from [8]): (1) All
objects or a representative sample of objects have been exam-
ined, (2) no object, dimension or characteristic was merged or
split in the last iteration, (3) at least one object is classiﬁed
under every characteristics of every dimension, (4) no new
dimensions or characteristics were added in the last iteration,
and (5) every dimension is unique in every taxonomy of the
ontology and every characteristic is unique in its dimension.
By documenting all changes to the ontology in each itera-
tion, we can objectively decide when these ending conditions
are met. We have explicitly excluded the objective ending
criterion “Each cell (combination of characteristics) is unique
and is not repeated” [8], since the extension of the ontology
as described in Sec. III-B entailed the inclusion of attributes
that are not dimensions, i.e., indices and scope notes. Two
objects can hence have the same combination of characteristics
among all dimensions, but be distinct due to different scope
note values. In addition, we also aim to achieve the following
subjective ending conditions [8]:
• Concise: the number of dimensions needs to be meaningful

yet manageable

• Robust: the dimensions and characteristics need to provide

for differentiation among objects of interest

• Comprehensive: all objects within the domain of interest

can be classiﬁed

• Extendable: new dimensions and characteristics can be

easily added

• Explanatory: the dimensions and characteristics explain the

objects

V. PROTOTYPE OF THE ONTOLOGY

We developed a prototype of the ontology to (1) illustrate
the usability of the structure, repository, and tool, and to (2)
contribute the ﬁrst step towards the long-term objectives.

A. Iterative process

We illustrate the approach outlined in Sec. III-B by adopt-
ing the iterative ontology development process as extended
from Nickerson et al. [8]. Accordingly, either an empirical-
to-conceptual or conceptual-to-empirical approach has to be
chosen. We chose the former approach for the initial iteration,
as a signiﬁcant understanding of the domain has already
been established along previous engagement with requirements
quality research. We distilled an initial structure of the ontol-
ogy based on relevant literature [14], [15], [19].

An empirical-to-conceptual approach was chosen for the
subsequent four iterations, as we aim to extract eligible objects
for the four taxonomies from established literature. For this
prototype, we selected the set of primary studies gathered in
a recent systematic mapping study on empirical requirements
quality research by Montgomery et al. [3] as our data to extract
from. This publication is the only secondary study to our
knowledge which explicitly investigates requirements quality
and, thus, serves as a reliable collection of peer-reviewed pri-
mary studies. The three ﬁrst authors distributed the set of 105
eligible studies among each other and split the resulting subset
into four iterations. During each iteration, they extracted all
relevant objects based on an extraction guideline, which was
initiated during the ﬁrst iteration and maintained according to
ontology development protocol [8], [18]. Publications had to at
least contain one eligible quality factor based on the deﬁnition
established in Sec. I and an according description. Data set and
approach objects were extracted when eligible according to the
extraction guideline. At the end of each iteration, the three
extracting authors convened together with the fourth author
and discussed necessary changes to the ontology structure in
case objects were encountered which could currently not be
framed by the taxonomies.

After this ﬁnal

The set of references in [3] is heavily biased towards em-
pirical work. To conﬁrm that the ontology is also robust when
considering non-empirical work, we conducted a ﬁnal iteration
considering publications that were excluded in the reference
selection phase of [3]. The inclusion of non-empirical work,
e.g., [20], did not challenge the structure of any taxonomy,
strengthening our conﬁdence in the robustness of the ontology.
iteration, all relevant exit criteria were
fulﬁlled, which indicated the completion of the ontology
creation process in the scope of this work. The objective
ending conditions were fulﬁlled as the documentation of the
ﬁnal iteration of the protocol showed no violation against
any of the ﬁve conditions. The subjective ending conditions
were assessed and agreed upon by the ﬁrst four authors to a
reasonable extent of this prototype; for example, the ontology
was deemed concise since the number of dimensions of each
taxonomy is compliant with the seven plus two rule [8], [21],
and robust since the inclusion of non-empirical work did not

challenge any taxonomy structure. The ﬁnal assessment of the
subjective ending conditions applies to the future version of the
ontology and will be discussed in the outlook in Sec. VII-B.

B. Current State

The schema of the ontology structure at the current stage
of development is shown in Fig. 1 with the structure and
relationship between all four included taxonomies. A thorough
explanation of all attributes (dimensions, dimension-clusters,
scope notes, and references), the eligible characteristics, and
their corresponding extraction rule can be found in our repli-
cation package1 and on our web interface2. We limit
the
following explanations to the most important of these attributes
and illustrate them with a running example.

Requirements quality factors are characterized by a name
and scope, which is the dimension representing the granularity
of input necessary in order to decide the quality factor. As
an example, one publication by Femmer et al. [15] contains
multiple quality factors, one of which is named containing
subﬂows. The scope of this factor is use case, as a full use
case is necessary to decide whether at least one subﬂow is
contained or not. Quality factors are further characterized by
the dimension-cluster quality aspect: it is necessary to denote
the impact which the calculated value of a quality factor has on
the activities in which the requirement is used, which is framed
by the notion of activity-based requirements quality [11]. The
factor containing subﬂows is reported to have a negative effect
on the aspect understandability, because subﬂows “force the
reader to jump between different positions in the text in order
to read through the use case, which can be argued to lead to
less readable use cases that are harder to understand” [15], but
also a positive effect on maintainability, because “if parts of
the ﬂow change, they only need to be changed in one location
(the subﬂow), and not in each use case” [15]. The notion of
aspects is further explained in Sec. VI. The set of quality
aspects is a harmonized superset of aspects used in established
literature [3], [14], [22], [23]. We make no claim about the
completeness and granularity of this set, as we consider quality
aspects as a connected, but distinct element in a larger domain.
Using a harmonized superset, we provide an interface for
future research in this subsequent domain of requirements
quality, for example, on their interrelationships [19].

Descriptions are instantiated by a scope note for both the
deﬁnition of the quality factor and also its impact. Since a
rigorous framework of requirements quality factors has been
absent in requirements quality research, textual descriptions of
what a quality factor means and how it impacts subsequent de-
velopment activities are most common. The factor containing
subﬂows is deﬁned as “Subﬂows are mechanisms for reuse that
enable the author of a use case to extract a certain set of steps
into a reusable subﬂow to prevent copy-and-paste reuse [...] in
the use cases” [4], while the impact is described as mentioned
in the previous paragraph about aspects. Description objects

1Replication package at https://doi.org/10.5281/zenodo.6583690
2The application can be accessed at http://www.reqfactoront.com

are further annotated on whether the according publication
provides empirical evidence for its relevance and whether
practitioners were involved in its inception or development,
as these dimensions help identifying quality factors that are
empirically informed. Since all quality factors in [15] were
derived from an industrial requirements writing guideline, they
explicitly have practitioners involved and their use in practice
serves as empirical evidence.

Data sets are characterized by their origin, which reﬂects
whether the data is from industry, academia, or mocked, and
who embedded the information (called ground-truth annota-
tors) of quality factor violations in the data, i.e., whether the
authors themselves, practitioners, or students annotated the
violations. Femmer et al. [15] report on one data set from
a large software project at a German reinsurance company,
whose origin is practitioner data. Since the data bears no
annotations, the data set has no ground-truth annotators. The
size and granularity of the data set represents the number
and type of contained elements. The aforementioned data set
contains 51 objects of the granularity document. Finally, the
accessibility of a data set reﬂects to what degree the data set
can be used. If available, the corresponding link or reference
to the source is given. The described data set is private and
has no link or source given.

A similar approach for characterizing the accessibility is
done for an approach object, in addition to the type of release
(source code, tool, API, or other). Approaches are further
characterized by their type (rule-based, machine learning or
deep learning) and the necessary information utilized to con-
duct the automatic evaluation (e.g., POS tags, dependency
tags, or other). Finally, approaches are–similar to descriptions–
classiﬁed regarding the empirical evidence they provide and
whether practitioners were involved in the evaluation. The
approach Smella, described in another publication by Femmer
et al. [4], is a proprietary tool detecting smells with a rule-
based algorithm using POS tags and lemmatization.

In the following paragraphs we describe how the current
state of the ontology and its contained objects address the
meta-characteristics. All conclusions are drawn based on the
limited subset that was selected for this prototype [3], hence
the inferences are not necessarily universal. In addition, the
conclusions are currently limited to a quantitative evaluation of
the ontology’s structure and content. A qualitative evaluation
involving the intended users of the ontology will be necessary
to determine its usability.

Addressing G1. The association of a quality factor object
with at
least one description object provides an overview
over all proposed explanations of a quality factor. Out of the
105 primary studies from the initial set [3], 59 contained at
least one eligible quality factor. In total, 206 unique quality
factors were extracted and associated to 258 descriptions.
Consequently, 172 quality factors are associated to exactly
one description. On the other hand, nine quality factors were
described in three or more occasions: anaphora, coordina-
tion ambiguity, vagueness, passive voice, referential integrity,
subjectivity, nocuous ambiguity, multiple interpretations, and

consistency.

Addressing G2. The association of a quality factor object
with data set and approach objects allows to ﬁnd available
resources for reuse and evolution. The 105 primary studies
describe 56 unique data sets and 36 approaches. However, only
9 of 56 data sets are publicly available (i.e., have the character-
istic available in paper or open access link in the dimension
accessibility), while most data sets are either private or not
disclosed. Only 5 of the 36 approaches are publicly available
(i.e., have the characteristic open access or open source in
the dimension accessibility), while most approaches are not
disclosed at all. These numbers highlight a dire condition of
open source in the requirements quality research landscape,
which inhibits the use and reuse of existing resources. Filtering
by the dimension accessibility supports identifying available
resources and exposing undisclosed contributions.

Addressing G3. As well as achieving G2 in the afore-
mentioned way to identify which quality factors are not yet
annotated in a data set or automatically detected with an
approach implementation, the dimensions empirical evidence
and practitioners involved can be used as a ﬁlter to identify
objects that lack empirical validation. Out of the 258 descrip-
tions, only 82 are devised based either on empirical evidence,
i.e., by assessing how well the metrics correspond to the
subjective perception of requirements quality in a survey [24],
or by involving practitioners in the design process of the
quality factor [25]. In addition, only 92 of the extracted 258
description objects contain an explicit impact of the quality
factor. The signiﬁcance of this lack of an impact description
is further emphasized in Sec. VI.

Addressing G4. The association of description, data set, and
approach object to references allows to trace every contribution
to the corresponding authors, which can be used to connect
to researchers who have contributed in a speciﬁc area of
requirements quality research.

C. Repository and Tool

The initial results are recorded in a ﬁrst version of a
maintainable tool: both the structure and the objects of the
ontology are stored in a publicly accessible data repository
hosted on GitHub1. The structure is represented by structure
ﬁles deﬁning the attributes of each taxonomy. The objects
are stored in form of extractions, where each extraction is
associated to one reference and contains an arbitrary number
of extracted objects according to the existing taxonomies. The
current status of the repository is retrieved by an interactive
web application which processes the data and visualizes it
in a human-readable and -comprehensible way2, fulﬁlling the
elicited goals through ﬁlters and links. The repository can be
easily maintained using the version control offered by GitHub:
contributions to both the structure and the content of the
ontology can be made by adding new extraction elements for
either existing or new references. This way, new publications
can be included or already included publications can be
revised, supporting an inclusive and collaborative approach at
harmonizing the perspective on requirements quality factors.

VI. THREATS AND CHALLENGES

a) Transparent Ontology Design Process: A major chal-
lenge in developing any subject-based classiﬁcation is the lack
of transparency of the process [18], where the process obscures
the rationale behind design decisions. Since our ontology
is both meant to facilitate collaboration and a community-
driven maintenance and evolution, we mitigate this threat by
disclosing all process documentations1.

b) Shared Understanding of Extraction Guidelines: As
with any extraction task, the subjective nature of interpreting
literature according to an extraction guideline is inherently
prone to misunderstandings. Even though the initial set of
extracted objects are neither the main contribution of this
work nor assumed to be permanent, we assured a common
understanding by assigning primary studies which were al-
ready processed by one author to another author in order to
calculate an overlap and quantify the agreement. This way,
each of the ﬁrst three authors additionally extracted relevant
objects from two already processed primary studies, such that
every extractor had an overlap with every other extractor. All
relevant attributes were evaluated: dimensions were assessed
by equivalence, scope notes were assessed by similarity using
sequence matching scaled to range [0, 1]. The six primary
studies resulted in 799 extracted individual values, on which
an agreement of 85.03% between all authors was achieved.
This agreement assures a sufﬁciently common understanding
of the extraction guidelines.

c) Requirements Quality Research Framework: As men-
tioned in Sec. I, requirements quality factors are purely nor-
mative and evaluate textual input based on metrics which are
often arbitrary. The relationship between these metrics and the
actual impact on the quality is more complex: as identiﬁed in
previous research on speciﬁc quality factors [26], a violation
against the rule entailed by a quality factor may or may not
lead to an actual impact on the requirements quality depending
on numerous context factors. For example, the use of passive
voice might not lead to an ambiguous interpretation in a small-
scale development unit if the stakeholders which are intended
to use the written requirement can reconstruct the omitted
subject of the sentence anyway.

This relationship has been framed by Femmer et al. in
the form of activity-based requirements engineering quality
models [11], where a violation against a quality factor only
potentially leads to an impact on an activity in which the
requirement is meant to be used. The relevance of a quality
factor is dependent on the likelihood of an impact on subse-
quent activities under the given context factors.

This imposes a necessary interface on the requirements
quality factor ontology: ultimately, every quality factor should
be associated to a speciﬁc impact on speciﬁc activities given
speciﬁc context factors in order to determine the relevance
of the factor. The state of research in this respect is cur-
rently relatively poor, as shown in the preliminary results
of Sec. V-B, and most publications proposing quality factors
are satisﬁed with determining the impact of a factor based

on educated guesses or anecdotal evidence. Therefore, our
ontology currently only records explicitly stated impacts in
the dimension-cluster quality aspect of the taxonomy quality
factor. However, improving the information about the potential
impact of quality factors is an anticipated extension point of
our ontology once research in this domain has advanced.

VII. LIMITATIONS AND CALL FOR ACTION

We discuss the limitations of the prototype to highlight the
distance between this ﬁrst step and the long-term objective.
Further, we propose a community effort to bridge this distance.

A. Limitations of the current Approach

Incompleteness of Publications The lack of a shared
terminology impedes identifying what the complete set of
publications would be, as quality factors have been addressed
with different names and in different approaches. Hence, the
list of publications to extract eligible objects from is far
from complete. The systematic mapping study on empirical
requirements quality research by Montgomery et al. [3] is
to our knowledge the only secondary study which makes an
attempt at comprehending the research domain of requirements
quality. Currently not considered publications could potentially
add relevant objects to the ontology or challenge its structure.
Since the domain of requirements quality research is only
loosely coherent by an explicit identity, the effort to compre-
hend and order relevant research is, as we argue, an extensive
undertaking.

Overload of factors The result addressing goal G1 pre-
sented in Sec. V-B raises the question about the relevance
of this large number of unique quality factors. The included
publications show a large variation in the degree of evidence
for their relevance, as also noticed by Montgomery et al. [3],
which ranged from purely anecdotal justiﬁcations over refer-
ences to established literature [27] to sound empirical evalua-
tions [26]. We decided not to exclude publications with lacking
evidence of relevance at the cost of a manageable number of
resulting factors, mainly because no mature research approach
to reliably determine a quality factor’s relevance exists yet.

B. Call for Action

One hope we associate with this RE@Next! contribution is
to appeal for participation in a coordinated community effort
aimed at tackling this task. The extension of this task to a
community effort makes the extensive undertaking of identify-
ing all relevant literature surmountable. In addition, it ensures
to include diverse perspectives on the matter, contributing to
establish a harmonized vision. This will additionally lead to
healthy scrutiny and subsequent evolution of the ontology
structure, for example by including the dimension language
for quality factors, as publications discussing quality factors
in languages other than English begin to emerge [28]. Finally,
involving as many parts of the implicit requirements quality
research community as possible is bound to establish an
explicit, shared identity of the research domain in the process.

The community effort will be initialized by interested
members of the requirements quality research community
committing to it. We anticipate this effort to span over several
years, though a consistent commitment is not mandatory. Coor-
dinated by the ﬁrst authors of this paper, systematic strategies
for identifying previously not considered publications will be
developed, distributed, and executed. Once conﬁdence in the
completeness of the publications will have been reached, the
iterative ontology creation process described in Sec. V-A will
be scaled up and continued by the members involved in the
community effort. The ultimate deliverable of this community
effort will be a sufﬁciently complete and robust ontology
structure and content–assessed jointly using the objective and
subjective exit criteria–which reﬂects the harmonized perspec-
tives of the requirements quality research community.

This also lays the groundwork for addressing the relevance-
problem of requirements quality publications: after the space
of quality factors has expanded during the community effort,
this same community shall be involved in developing a reliable
research approach for determining the relevance of a quality
factor. This method will be used to condense the space of
quality factors again to a manageable number of relevant
objects, addressing the second limitation mentioned in the
Sec. VII-A. Finally, a complete yet concise set of applicable
and relevant quality factors contained in the ﬁnal version of
the ontology fulﬁlling goals G1-G4 can be delivered.

VIII. CONCLUSION AND OUTLOOK

This paper presents the long-term objective of a harmo-
nized vision on requirements quality factors in the form of
an ontology, relating four taxonomies to represent the four
elements quality factor, description, data set, and approach of
the domain containing quality factors for textual requirements.
The extraction of eligible objects from 105 primary studies as
well as a central repository and accessible web interface are
the ﬁrst step towards this long-term objective.

Establishing a harmonized perspective on the structure of
quality factors and related elements as well as a central reposi-
tory containing a sufﬁciently complete set of relevant objects is
an extensive task necessitating a community effort, making this
task surmountable and also including diverse perspectives on
the domain. The ﬁnal version of the ontology will then serve as
a conceptual framework for future research, a reliable resource
for practitioners to base requirements quality assurance on, and
a tool for requirements quality education.

ACKNOWLEDGMENTS

This work was supported by the KKS foundation through
the S.E.R.T. Research Proﬁle project at Blekinge Institute of
Technology.

REFERENCES

[1] H. Femmer, “Requirements engineering artifact quality: deﬁnition and
control,” Ph.D. dissertation, Technische Universit¨at M¨unchen, 2017.
[2] D. M´endez Fern´andez, S. Wagner, M. Kalinowski, M. Felderer, P. Mafra,
A. Vetr`o, T. Conte, M.-T. Christiansson, D. Greer, C. Lassenius et al.,
“Naming the pain in requirements engineering: Contemporary problems,
causes, and effects in practice,” EMSE, vol. 22, no. 5, 2017.

[3] L. Montgomery, D. Fucci, A. Bouraffa, L. Scholz, and W. Maalej,
“Empirical research on requirements quality: A systematic mapping
study,” REJ, 2021.

[4] H. Femmer, D. M. Fern´andez, S. Wagner, and S. Eder, “Rapid quality

assurance with requirements smells,” JSS, vol. 123, 2017.

[5] A. Ferrari, G. Gori, B. Rosadini, I. Trotta, S. Bacherini, A. Fantechi, and
S. Gnesi, “Detecting requirements defects with nlp patterns: an industrial
experience in the railway domain,” EMSE, vol. 23, no. 6, 2018.

[6] H. Yang, A. De Roeck, V. Gervasi, A. Willis, and B. Nuseibeh,
“Extending nocuous ambiguity analysis for anaphora in natural language
requirements,” in RE, 2010.

[7] ——, “Analysing anaphoric ambiguity in natural

language require-

ments,” REJ, vol. 16, no. 3, 2011.

[8] R. C. Nickerson, U. Varshney, and J. Muntermann, “A method for
taxonomy development and its application in information systems,”
European Journal of Information Systems, vol. 22, no. 3, 2013.

[9] C. Y. Din and D. Rine, Requirements content goodness and complexity

measurement based on NP chunks. VDM Publishing, 2008.

[10] O. Ormandjieva, I. Hussain, and L. Kosseim, “Toward a text classiﬁca-
tion system for the quality assessment of software requirements written
in natural language,” in SOQUA, 2007.

[11] H. Femmer, J. Mund, and D. M. Fern´andez, “It’s the activities, stupid!

a new perspective on re quality,” in RET, 2015.

[12] G. Lucassen, F. Dalpiaz, J. M. E. van der Werf, and S. Brinkkemper,
“Improving agile requirements: the quality user story framework and
tool,” Requirements engineering, vol. 21, no. 3, pp. 383–403, 2016.
[13] G. G´enova, J. M. Fuentes, J. Llorens, O. Hurtado, and V. Moreno, “A
framework to measure and improve the quality of textual requirements,”
Requirements engineering, vol. 18, no. 1, pp. 25–41, 2013.

[14] R. Saavedra, L. C. Ballejos, and M. A. Ale, “Software requirements
quality evaluation: State of the art and research challenges,” in ASSE-
JAIIO, 2013.

[15] H. Femmer, M. Unterkalmsteiner, and T. Gorschek, “Which require-
ments artifact quality defects are automatically detectable? a case study,”
in REW, 2017.

[16] G. C. Everest, “Basic data structure models explained with a common
example,” in Proc. Fifth Texas Conference on Computing Systems, 1976.
[17] L. M. Garshol, “Metadata? thesauri? taxonomies? topic maps! making

sense of it all,” Journal of information science, vol. 30, no. 4, 2004.

[18] D. Kundisch, J. Muntermann, A. M. Oberl¨ander, D. Rau, M. R¨oglinger,
T. Schoormann, and D. Szopinski, “An update for taxonomy designers,”
Business & Information Systems Engineering, pp. 1–19, 2021.

[19] M. Unterkalmsteiner and T. Gorschek, “Requirements quality assurance
in industry: why, what and how?” in REFSQ. Springer, 2017.
[20] F. Fabbrini, M. Fusani, V. Gervasi, S. Gnesi, and S. Ruggieri, “Achieving

quality in natural language requirements,” in QW, 1998.

[21] G. A. Miller, “The magical number seven, plus or minus two: Some
limits on our capacity for processing information.” Psychological review,
vol. 63, no. 2, p. 81, 1956.

[22] R. E. Schneider, A process for building a more effective set of require-

ment goodness properties. George Mason University, 2002.

[23] “Systems and software engineering — Life cycle processes — Re-
quirements engineering,” International Organization for Standardization,
Geneva, CH, Standard, Nov. 2018.

[24] C. P. Usdadiya, “Assessing quality of use case speciﬁcations,” Ph.D.
dissertation, Dhirubhai Ambani Institute of Information and Communi-
cation Technology, 2018.

[25] V. Antinyan, M. Staron, A. Sandberg, and J. Hansson, “A complexity

measure for textual requirements,” in IWSM-MENSURA, 2016.

[26] H. Femmer, J. Kuˇcera, and A. Vetr`o, “On the impact of passive voice

requirements on domain modelling,” in ESEM, 2014.

[27] E. Juergens, F. Deissenboeck, M. Feilkas, B. Hummel, B. Schaetz,
S. Wagner, C. Domann, and J. Streit, “Can clone detection support
quality assessments of requirements speciﬁcations?” in ICSE, 2010, pp.
79–88.

[28] H. Hasso, M. Dembach, H. Geppert, and D. Toews, “Detection of
defective requirements using rule-based scripts.” in REFSQ Workshops,
2019.

