Highlights

When Traceability Goes Awry: an Industrial Experience Report

Davide Fucci, Emil Al´egroth, Thomas Axelsson

• We report the design of an empirical study aimed at identifying and address-

ing the issue of quality inﬂation.

• We reﬂect on how the lack of simple traceability links between requirements

and test cases hindered the development of the proposed solution.

• Based on our experience, we present takeaways and considerations for re-
searchers and practitioners about the role and value of traceability in indus-
trial settings.

2
2
0
2

n
u
J

9

]
E
S
.
s
c
[

1
v
2
6
4
4
0
.
6
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
When Traceability Goes Awry: an Industrial Experience
Report

Davide Fuccia, Emil Al´egrotha, Thomas Axelssonb

aSERL, Blekinge Institute of Technology, Valhallavagen 1, Karlskrona, 37141, Sweden
bCOMPANY, Address, City, Postcode, Country

Abstract

The concept of traceability between artifacts is considered an enabler for software
project success. This concept has received plenty of attention from the research
community and is by many perceived to always be available in an industrial set-
ting.

In this industry-academia collaborative project, a team of researchers, sup-
ported by testing practitioners from a large telecommunication company, sought
to investigate the partner company’s issues related to software quality. However, it
was soon identiﬁed that the fundamental traceability links between requirements
and test cases were missing. This lack of traceability impeded the implementation
of a solution to help the company deal with its quality issues.

In this experience report, we discuss lessons learned about the practical value
of creating and maintaining traceability links in complex industrial settings and
provide a cautionary tale for researchers.

Keywords: Industry-Academia Collaboration, Traceability, Software Quality
2000 MSC: 68N01

1. Introduction

The concept of traceability refers to links between different software artifacts,
such as requirements, source code, and test cases. Establishing traceability within
requirements helps the organization manage dependencies. In contrast, traceabil-
ity between requirements and test cases, also referred to as alignment [1], is nec-
essary to measure coverage and ensure that the product fulﬁlls customers’ needs
with a given degree of quality. Moreover, the traceability between source code
and test cases enables the analysis of the impact when changes occur.

Preprint submitted to Journal of Systems and Software

June 10, 2022

In this study, Blekinge Institute of Technology (BTH) collaborated with a
large telecommunication company (hereafter, COMPANY1), with the original in-
tent to study COMPANY’s software quality. Speciﬁcally, the researchers collabo-
rated with the organization within COMPANY in charge of the veriﬁcation before
release (i.e., TestOrg). The initial aim of this collaboration was to investigate the
challenges related to the state-of-practice of the COMPANY quality assurance pro-
cess. TestOrg was a suitable partner in this project since they are responsible for
the quality assurance of all COMPANY products and can be considered the ﬁrst
user of the product once it leaves the development phase. BTH and TestOrg orga-
nized a series of workshops to elicit pain points regarding software quality. One
outcome of such workshops was the perceived mismatch between the organization
level of quality assurance activities and the actual observed quality. We termed
this difference quality inﬂation. The study of the quality inﬂation phenomenon at
COMPANY became the reﬁned objective of our industrial collaboration.

The researchers analyzed the artifacts TestOrg uses to perform their activities,
such as requirement speciﬁcations, issue reports, and test cases. To observe the
symptoms and connect them to possible root causes of quality inﬂation, the re-
searchers needed to connect the requirements to other artifacts in the development
process. Therefore, the existing traceability links and the possibility of establish-
ing new ones play a signiﬁcant role for detecting quality inﬂation. However, we
found that such traces were generally lacking and that reverse engineering these
traces from existing artifacts was not only time-consuming but also, in most cases,
not possible.

In this paper, we report our experience in detecting quality inﬂation at COM-
PANY and how the investigation of this phenomenon failed due to the lack of
traceability between artifacts. This experience serves as a case for academia to
consider for future research and provide an example for practitioners of the chal-
lenges that can arise once traceability between software development artifacts is
lacking.

The rest of the paper is organized as follows: Section 2 presents an overview
of the existing literature on traceability in software projects and its application to
different artifacts in the software development lifecycle. Section 3 presents the
industrial context of our study, and Section 4 shows our experience in trying to
establish traceability links in a large-scale organization to investigate a particular
aspect of software quality—i.e., quality inﬂation. Section 5 reports a discussion of

1We omitted the COMPANY name due to their wish to stay anonymous.

2

our experience and takeaways for researchers and practitioners. Finally, Section 6
concludes the paper.

2. Software artifacts Traceability

The body of research in traceability is vast, with early works published in the
70s—e.g., Randell [2]. Since then, the concept has been explored in both industry
and academia through empirical studies and summarized in systematic literature
reviews [3, 4, 5]. Traceability is essential to govern the software development
process, to manage complexity, and mitigate costs [6, 7]. However, research has
also established that maintaining traceability links of high quality over time can
be a costly process [8]. Therefore, research has started focusing on traceability
automation [9].

Among the secondary studies, Mustafa and Labiche performed a literature
review that identiﬁed a lack of tools for tracing heterogenous artifacts [10]. Con-
versely, a review by Tufail et al. [11], identiﬁed seven models, ten challenges, and
14 tools for traceability. The review by Javed and Zdun examined the connec-
tions between traceability and software architecture [12]. In contrast, Santiago
et al.
looked at managing traceability in the context of model-driven engineer-
ing and the associated complexities [13]. According to a recent mapping study
surveying 63 papers between 2000 and 2020, traceability involving testing arti-
facts and related activities is the least investigated [4]. Moreover, according to
the authors, few tools support traceability in software testing activity [4]. This
conclusion is drawn, despite the numerous research on the tools that either explic-
itly focus on, or support, traceability in software development. Examples of such
tools include PLM/ALM which, according to a study by Ebert [14], was beneﬁcial
to deﬁne traceability for testing purposes. The project management tool DOORS
is commonly used in the industry and is used as a driver for research into, for
example, automated traceability links [15] and rich traceability [16]. Another ex-
ample is Enterprise architect—a large-scale modelling framework that
can be used to model traceability between several aspects of development, includ-
ing assets, processes, and the organization [17]. Although used successfully in
practice, these tools share a human component. Thereby, their success is tied to
how rigorously they are used.

Tian et al. [4] show that traceability in different software development activ-
ities has rarely been evaluated in industrial settings (i.e., 16% of the reviewed
primary studies). However, despite several studies commending traceability as a
prerequisite for a successful software project (and conversely pointing to a lack of

3

traceability as a factor leading to failure [18]), there is no empirical evidence, to
the best of our knowledge, that supports these claims in the industrial context.

Traceability is often discussed as a sequential trace from requirements to code,
and from code to test cases. Another critical dimension is alignment—i.e., the
traceability between requirements and tests. Unterkalmsteiner et al. [1] proposes
a taxonomy for requirements and test alignment (REST). They show a method for
designing contextual taxonomies of alignment, including concepts for how to rea-
son about the establishment of traceability links from requirements speciﬁcations
to design, development, and testing.

Another concept related to traceability is change management [19]—i.e., the
idea that when a software artifact is changed, all associated artifacts need to be
identiﬁed and updated accordingly. The responsibility for this task is often del-
egated to the development team, and its complexity is affected by the already
available traceability links. In their case study, Borg et al. found that develop-
ers prefer ﬂexible forms of information rather than formal information, including
traceability information, when dealing with changes [19].

Both the research on requirements-tests alignment and change management
demonstrate an academic idea of the importance of traceability in software devel-
opment. This suggestion, although reasonable, does not account for the costs of
keeping traceability and alignment up-to-date in complex industrial settings.

3. Investigation of Software Quality within COMPANY

BTH and COMPANY are collaborating on a research project in the area of soft-
ware quality, with a focus on automated software testing. This project is enabled
by BTH’s approach to Industry-Academia collaboration and technology transfer
based on the model proposed by Gorscheck et al. [20]. Since the project is per-
formed in co-production, BTH began by identifying the demands and constraints
imposed on TestOrg by the process used to develop and deliver software at COM-
PANY. TestOrg is in charge of verifying digital business solutions (DBS)—e.g.,
online charging systems, mobile ﬁnancial services, and service catalog manager—
for telecommunication operators worldwide.

3.1. Preliminary Workshops and Research Objectives

In the Fall of 2019, BTH organized two explorative workshops at COMPANY
to understand the organizational challenges in the area of testing and quality assur-
ance related to automation. The ﬁrst workshop (Workshop 1) involved members
of the quality assurance (QA) team and product managers, whereas the second

4

(Workshop 2) involved developers, testers, and operations personnel. We assumed
that the challenges highlighted within the two groups would differ based on norms
and values [21, 22].

The workshops were organized into three parts. First, the participants an-
swered the question “What are the challenges your team and organization are
currently facing with test automation?” in brief statements on post-it notes (sev-
eral answers are possible) in a time-boxed exercise (15 minutes). In the second
part, each participant pitches their answers to the entire group and engages in a
discussion. As the participants read and connect their answers, the researchers
cluster the notes according to themes emerging during the discussion. This part
of the workshop is not time-boxed to give everyone the possibility to voice their
ideas. In the third part, the researchers present the themes that emerged during
the discussions (i.e., clusters) and, in real time, validate with the participants the
correct interpretation of their answers. We identiﬁed eight themes associated with
QA and Test Automation challenges in Workshop 1 and six in Workshop 2.

The researchers prioritized the themes that emerged during the workshop in
collaboration with the TestOrg leaders and test managers, taking the results from
the developers as supporting input. The rationale for this decision was that the
emerging challenges on the management level were of more general and larger
complexity; thereby, they incorporated several of the challenges expressed by the
developers. BTH presented the results to the TestOrg team, and during a discus-
sion structured around the identiﬁed challenges, TestOrg provided further input to
prioritize them.

Finally, BTH and TestOrg set out to study quality inﬂation—a mismatch be-
tween the perceived effort in quality assurance activities performed by TestOrg
and the quality observed in use. We use the term inﬂation to indicate that the effort
in quality assurance activities is artiﬁcially increased; hence, creating such mis-
match. TestOrg perceived that the motivations for quality inﬂation were related to
both technical and human factors. For example, during Workshop 1, participants
pointed out the misalignment between the metrics used by management and the
ones used by developers to evaluate quality. TestOrg managers felt that the team
would intentionally write “happy” test cases and defer more thorough testing ac-
tivities down the development pipeline. During Workshop 2, developers felt that
quality goals are not explicit and communicated with poor rationale.

Focusing on the technical causes ﬁrst, BTH researchers collaborating with

TestOrg focused on the following objectives.

O1. Evaluate the quality of the test suites associated with different types of Busi-

5

ness Requirements (BR). A BR is a high-level requirement for the product,
which is later broken down into smaller requirements. During Workshop
1, it emerged that some BRs within the DBS system are perceived to work
well since they have few issue reports (IR) associated with them. We aim
to locate such BRs, characterize them based on aspects such as their history
and the history of the associated IR and test cases, and ﬁnally compare them
to those BRs that are considered troublesome by the development and QA
teams. This analysis aimed to show TestOrg possible root causes for quality
inﬂation.

O2. Correlate the quality of the automated test cases with the quality of the
test speciﬁcation (e.g., test smells—sub-optimal design of test code [23]).
This objective assumes that better-speciﬁed test scenarios lead to better test
cases.

O3. Evaluate the effects of the triaging process on perceived quality. During
Workshop 1, it appeared that the number of open IRs plays a crucial role in
establishing the managers’ perception of quality (e.g., when a BR receives
many IRs, or IRs for a BR are often reopened, that BR may be perceived as
low-quality). However, IRs go through a triaging process to decide if (and
to what extent) they will be tested (either with additional tests or during
regression testing). We wanted to study such triaging process as it directly
impacts the number of open/closed IRs and, in turn, the perceived quality
of a BR.

O4. Evaluate quality with respect to functional vs. non-functional BR features,
such as performance. During Workshop 1, participants agreed that an area
in which TestOrg should improve is testing of non-functional requirements.
On the other hand, in Workshop 2, developers pointed out that non-functional
testing is difﬁcult. Our objective is to understand to what extent non-functional
aspects contribute to quality inﬂation.

When conducting empirical investigations to address O1 and O2, it became
apparent that although traceability links between artifacts (i.e., BR, IR, and test
cases) were assumed to exist, this was not necessarily the case.

3.2. Development Lifecycle at COMPANY

A simpliﬁed version of COMPANY’s development workﬂow is reported in Fig-
ure 1. The workﬂow is based on decisions taken together by development and

6

Study

Speciﬁcation

Development

Release

Figure 1: Simpliﬁed version of the SDLC in use at COMPANY. Orange marks indicate TestOrg
main decision points in the process.

product management and provides a transparent, common understanding of the
development status.

COMPANY initiates the Study phase to fulﬁll new market needs, meet their
R&D goals, or respond to a customer request. By the end of this phase, the
stakeholders agree on the scope and resources available for development. In the
Speciﬁcation phase, the development organizations within COMPANY and the or-
ganization impacted by the development2, work on a document specifying a BR,
and divide it into Business Sub-Requirements (BSR). The end of this phase is a
synchronization point for the interested organizations, including TestOrg, to align
with the BR scope and plan. Once the Development phase starts, there is an agree-
ment on the development plans, dependencies, and test plans to be carried out.
Inputs to this phase are the BR, the architecture model, general improvements for
the area (e.g., mobile payments) and several guidelines (e.g., coding conventions,
UX guidelines). Development ends when TestOrg completes internal veriﬁcation
consisting of unit testing and integration testing. TestOrg follows checklists con-
taining the activities necessary to get the BR and BSR to a done state. The outputs
of this phase are a package ﬁle containing the implemented solution (e.g., a Jar in
case of a Java project), the source code, a release note document, and the updated
architecture and risk management models. This phase is iterative and feedback-
driven from internal channels—which perform continuous integration, simulation,
and laboratory evaluation—and external ones, including customer laboratory eval-
uations and restricted launches. Each iteration usually lasts two weeks. The end
of the Release signals that a feature is ready and can be commercially released.

3.3. Main Development artifacts at COMPANY

Organizations within COMPANY handle requirements at different levels of
granularity, from Business Opportunities (a high-level customer-centric deﬁnition

2The list of organizations impacted by the development of a new requirement is one of the

outcome of the study phase.

7

Table 1: BR attributes used in this study extracted from COMPANY’s requirements management
system.

Attribute

name

description

type
project
version
created
modiﬁed
creator
status
release
business goal
validation

Description

Type

string

text

name of a requirement
description of the requirements.
Contains purpose, DoD and references to sub-requirements
Indicates the granularity of a requirement—i.e., task, user story, epic

emun
enum The project the requirement belongs to
integer Existing revisions of the requirement
Date when the requirement is created
date
Date when the requirement is modiﬁed
date
string
Name of the employee who created the requirement
enum Current status of the requirement (released, tested, etc.)
enum The targeted release in which the requirement should be included
enum The targeted high level business requirement
enum Context in which the requirement is validated

planned phase X

date

moved to phase X date

issue reports
reference

list
link

When the requirement is intended to be moved to the next phase X in the development
X ∈ [study, speciﬁcation, development, release]
When the requirement is actually moved to the next phase X in the development
X ∈ [study, speciﬁcation, development, release]
Issue reports currently associated with the requirement
Link to the complete document speciﬁcation stored in another system)

of a solution to a problem or need) to User Stories, derived from BSR, imple-
mented by development teams in Scrum sprints. TestOrg interacts mainly with
BRs—i.e., requirements at intermediate granularity—which can be divided into
BSR due to size and complexity. BR and BSR are speciﬁed following a template,
and their contents vary in length (on average between 20 and 40 pages). These
speciﬁcations include:

i) General Information (e.g., scope, terminology).
ii) Output from the Study phase (including recommendation for further studies).
iii) Technical solution description which contains the requirements for the tech-

nical use case implementation.

iv) A Glossary of terms used in the document.
v) References used in the documents.
vi) Changelog and revision information.

The speciﬁcation documents are stored in a repository that allows tracking of
changes. A web-based project management tool tracks BR and BSR status, re-
sponsible team, and other metadata. Table 1 shows the main BR attributes tracked
using the tool.

8

Table 2: IR attributes used in this study extracted from COMPANY’s issue tracker system.

Attribute

Type

Description

name
content
priority
registered
assigned
answered
completed
product
market
issuing BR
characteristic
hot
duplicate
is child
parent
rejected
observation

string Name given to the IR
string Content of the IR
enum Priority of the IR according to the submitter
date When the IR is created
date When the IR is assigned to a team
date When a ﬁx for the IR is proposed
date When the work to address the IR is completed
string Product experiencing the fault
string Market reference in which the product is experiencing the fault
string Name of the BR related to this IR
enum Quality characteristic describing the IR (e.g., functional, reliability)
bool Whether the IR requires immediate attention
bool Whether the IR is a duplicate of an existing one
bool Whether the IR is in a is-a relationship with another IR
string Reference to the parent IR (iff is child is True)
bool Whether the IR will be addressed or not
text

Free text (e.g., stack traces, steps to reproduce)

Another type of artifact involved in the development process at COMPANY is
Issue Report (IR). IRs are defects reported before release with varying granularity
and can impact several BRs and BSRs. COMPANY uses a taxonomy of eight soft-
ware characteristics associated with an IR. These range from functional suitability
(e.g., functional completeness or correctness) to usability and maintainability. The
IR lifecycle is handled using a web-based issue-tracking tool. Table 2 show the
main IR attributes tracked using the tool.

Testing activities occur at different levels of abstraction. Manual or semi-
automated testing is usually performed for BRs that impact several organizations
responsible for different DBS solutions within COMPANY. Manual tests are man-
aged and reported in a separate web-based application. Automated tests—written
in different programming languages and version-controlled in a repository—are
also present and implemented to verify (parts of) BRs and BSRs.

4. The Role of Traceability in Investigating Software Quality

BTH had access to BRs, source code, test results, and IRs. Given such a rich
set of data, we set out to map artifacts (and their quality) developed early in the

9

Conceptualization

Design

- Workshops
- Literature study

- Artefact analysis
- Results presentation
- Feedback + Interviews

Validation

Project stopped before
empirical validation

Figure 2: Overview of design science approach and activities for each phase.

Development phase to later ones. In this section, we present the approach that
was initially taken to identify such traces and the challenges that arose during this
work.

4.1. Research Methodology

During this research collaboration with COMPANY, we followed the design
science paradigm [24] as presented in Figure 2. After establishing the research
objectives and familiarizing with the existing literature, the researchers at BTH
started the solution design activities. Initially, the researchers needed to familiar-
ize themselves with the artifacts, domain-speciﬁc language, information systems,
and processes at COMPANY. To that end, BTH obtained access to the infras-
tructure and worked in collaboration with TestOrg3 to clarify uncertainties and be
onboarded on the internal processes and systems in use within the organization.
Moreover, BTH researchers and TestOrg members had more structured meetings
during which the former presented their current understanding of the problem,
based on the analysis of the artifact, and proposed alternative ways forward and
possible solutions. TestOrg gave feedback on the results pointing out, for exam-
ple, wrong assumptions the researchers made. The researchers followed up with

3One of the researchers spent approximately 20 hours/month at the company ofﬁce in early

2020 before work-from-home was established due to the pandemic.

10

Table 3: Metrics used to characterize Troublesome BR. In the table, phase ∈ [study, speciﬁcation,
implementation, release].

Name

Monthly IR for BR

Release IR for BR

Time BR spent in phase

Deﬁnition

The number of functional IR associated to a speciﬁc BR aver-
aged over a monthly period.
The number of functional IR associated to a speciﬁc BR aver-
aged over release.
Number of days a BR stayed in a speciﬁc phase as indicated by
its status.

ad hoc interviews about speciﬁc topics when necessary. After several iterations
between Conceptualization and Design, BTH and TestOrg could not produce a
solution—i.e., an intervention to reveal where quality inﬂation was taking place—
which could be Validated due to the lack of traceability between artifacts.

4.2. Provisional Design Solution

The initial design goal was a set of guidelines to support TestOrg in identifying
issues with quality inﬂation, inform them about test cases that needed improve-
ment, and suggest BRs that need to be better tested or reﬁned (i.e., reworded, sim-
pliﬁed, re-scoped). Furthermore, we aimed to create automated support through
a recommender system, based on such guidelines, which could be integrated into
the TestOrg continuous integration environment and reveal “quality inﬂated” BR
and BSR.

Based on the initial conceptualization and discussion with TestOrg, we hy-
pothesize that writing automated tests can be more challenging for some BRs than
for others (Objective O1). In the ﬁrst design iteration (left pane of Figure 3), we
characterize such Troublesome BRs using several metrics mined from the COM-
PANY artifact repositories (see Table 3). In particular, we considered the number
of IRs associated with a BR over time (e.g., in a release), the amount of time a
BR spent in the different phases of the development (e.g., as reported in Figure 4),
and the difference between the planned and actual time for a BR to advance to
the next phase. When deﬁning the Troublesome BR metric, we used the existing
traceability link between IR and BR available in the issue tracking tool (marked
with 1(cid:13) in Figure 3).

In informal interviews, the researchers presented and discussed their results
together with TestOrg and got early feedback that helped better conceptualize the
solution design.

11

Metrics

Traceability

No traceability

BR
History

1

IR

Troublesome
BR

Test
suite
quality

3

1st iteration

2nd iteration

2

Test
cases

4

IR-ﬁxing
commit

Figure 3: Traceability (and lack thereof) between artefacts used for the proposed design.

For the second iteration (right pane of Figure 3), we needed to deﬁne the qual-
ity of the test cases for a BR to obtain a metric (i.e., Test suite quality) which we
could then correlate with Troublesome BR. We discussed several ways of estab-
lishing the necessary traceability links between BRs and test cases. The more im-
mediate one—a direct bidirectional link between BR and test cases is unavailable
(marked with 2(cid:13) in Figure 3). In their development process, COMPANY does not
enforce traceability between high-level requirements, such as BR, and low-level
code artifacts, such as test cases.

Next, since we already had a traceability link between IR and BR, we investi-
gated downstream (i.e., IR-to-source code) and upstream (i.e., source code-to-IR)
traceability links to connect IR and test cases via IR-ﬁxing commits (marked with
3(cid:13) in Figure 3). From a commit, it is possible to establish a link to the test cases
(marked with 4(cid:13) in Figure 3)—e.g., using the approach proposed in [25]. How-
ever, the ﬁeld that explicitly connects IR and commit in the issue-tracking system
is barely used (approximately 10% of IRs contains a reference to a commit).

We then looked at the upstream traceability between test cases and IRs, using
information from the IR-ﬁxing commit (the other direction of the arrow marked as
3(cid:13) in Figure 3). Development organizations within COMPANY are required to use
a structured commit template. The template has a ﬁeld in which the developer can
indicate, among other things, whether the commit is part of a ﬁx. The developer
can do this by including the id of the artifact describing the issue, such as an IR.
From the source code version control system, we mined patches and associated

12

Table 4: Goal-Question-Metrics for the study of quality inﬂation at COMPANY.

Goal (based on O1 and O2)

Question

Metrics

Answered?

Purpose: Characterize the
Issue: spread of
Object: quality inﬂation
Viewpoint: QA managers at
Context: COMPANY

How widespread is quality inﬂation?
When is there a mismatch between QA effort
and quality observed for a BR?

What is the QA effort dedicated to a BR?

Why are some BR perceived to be more trou-
blesome than others?

Quality inﬂated TR
All TR

QA effort for TR

Observed Quality for TR > Threshold
Test smells
Test suite effectiveness
Test suite time to complete
Defect density
Defect age
Monthly IR for BR
Release IR for BR
Time BR spent in phase

No

No

No, due to lack of
traceability

Yes

discussions taking place during the same timeframe during which BRs were im-
plemented and IRs were addressed (i.e., 2016–mid 2020). We parsed the commit
messages looking for ﬁxes mentioning IRs and their id. However, this automated
approach returned a low number of hits. Upon manual inspection of 50 random
commit messages, it appeared that the commit template is mostly ﬁlled in by au-
tomatic tools (e.g., static code analyzers) or used for tracing refactoring to code
smells (e.g., from SonarQube) which are outside the scope of this study.

In summary, Table 4 show how the goal of the study relates to the metrics
using the GQM framework [26]. In particular, we deﬁned troublesome BRs but
could not establish the QA effort associated with them due to lack of traceability.
In turn, we could not answer the remaining questions to fulﬁll our original goal.

Figure 4: BRs times in the different SDLC phases.

13

0200400600800100012001400DaysstudyspecificationimplementationreleasePhaseLack of
resource

Team norm

Perceived
value

Integration
of different
teams

Human

Interoperability

Fragmented
information

Components
integration

Integration
issues

Lack of
ownership

Tools

Causes

Lack of
Traceability

Consequences

Redundant
work

Outdated
legacy
system

Wrong
feature
scoping

Inefﬁcient
resource
allocation

Complex
defect
management

Figure 5: Causes and consequences of lack of traceability.

5. Discussion

In this section, we provide the lessons learned from our failed attempt at study-
ing (and eventually addressing) quality inﬂation at COMPANY due to lack of trace-
ability and discuss the implications of these results for research in this ﬁeld. We
summarize our considerations about the causes and consequences of lack of trace-
ability in Figure 5.

The lessons learned and considerations presented in this section are derived
from our own experience analyzing the artifacts used within COMPANY and our
interactions with practitioners in TestOrg during workshops, feedback, and inter-
view sessions. The takeaways are complemented with references to the literature
that can provide further insights.

5.1. Lessons learned

We report the lessons learned from practitioner and researcher perspectives.
For the latter, we include takeaways that should be considered when studying
traceability in complex industry settings.

14

For practitioners. In the context of a company, the traceability links are main-
tained for a purpose that can be different from the one of a research project. We
recommend that establishing and updating traceability links, at least the one that
matters for the company, should be treated as a backlog item and tracked like any
other items in the development process. Moreover, the explicit lack of traceabil-
ity needs to be treated as a technical debt item and included in Sprints aimed at
paying it back.

Toledo et al [27] show that the lack of traceability between artifacts leads to
architectural technical debt. They show how, in the case of microservice archi-
tectures, maintaining data-to-data source traceability is often necessary to fulﬁll
regulations and identify services that are not needed anymore. Whereas, also
in the area of architecture and design, Charalampidou et al [28] show that it is
useful to document traceability links to manage and estimate the cost of paying
debt. Similarly, traceability supports managing documentation and requirements
debt [29]; conversely, lack thereof is detrimental to maintenance tasks.

Considering traceability is important as lack of links, or hard-to-establish links,
can be smells for other problems, such as wrong scoping. For example, when a
requirement is too large in scope, its implementation is expected to receive several
change requests. However, understanding the scope requires a mechanism to trace
change requests to requirements.

Traceability of artifacts is important from a management perspective. With-
out it, several overhead costs can be expected due to lack of implementation
ownership—i.e., which team is responsible for implementing a functionality (for
example, see [30, 31]). This lack of ownership can, in the worst case, lead to the
same functionality being implemented several times or for the implementation to
be disrupted during integration due to lacking knowledge of the code dependen-
cies [32].

Traceability also helps mitigate failure propagation—i.e., due to defects in the
code that endure through the development cycle and potentially reach the cus-
tomer (for example, see [33, 34]). Aligning tests with requirements to establish
coverage metrics is vital, and without this information, it can be unclear if a re-
quirement has been correctly tested or not. Despite defects reaching the customer
or not, lingering faults cause additional overhead, delay releases, and result in
longer implementation time.

Traceability also helps mitigate uncertainties regarding the allocation of re-
sources (e.g., [35]). While changed or added requirements give input to allocate
more resources, veriﬁcation of said requirements provides grounds for their deal-
location. However, without knowing if a development task has been properly

15

addressed, such deallocation can be delayed or spent inefﬁciently (for example,
see [36, 37, 38]).

For researchers. Researchers should validate their assumptions about what is
available in terms of traceability when collaborating with a large company. Some
activities that are taken for granted in some settings (e.g., open source) are hard
to apply in a complex industrial organizational context, such as COMPANY. In
such contexts, it is inherently difﬁcult to have an overview of what is available in
terms of information, data, and artifacts, and what is not. In the case of TestOrg,
although the managers were aware of the traceability between BRs and IRs, the
lack of traceability links between the source code and IRs or BRs was not con-
sidered since it is outside the scope of their activities. For the researchers, this
became clear in discussions with people in more operational roles.

Takeaway 1

When assessing traceability links between different artifacts involve
early personnel working day-to-day with such artifacts. For example,
when traceability between source code and requirements is needed, de-
velopers and business analysts in the company should be involved.

Within the organization, we realised that horizontal traceability (i.e., traceabil-
ity between artifacts at the same level of abstraction, such as requirement-to-
requirement) has more value than vertical traceability (e.g., at different levels,
such as test cases-to-requirements). This may be the case in large companies,
where the different phases of the development cycle—and, therefore, their asso-
ciated artifacts—are managed by different internal organizations. For the practi-
tioners we interacted with, limited traceability (mostly among BRs, and between
BRs and IRs) was enough to perform their daily tasks. To enact a different type
of traceability, researchers need a strong use case for the company. The company
will have to i) allocate resources to support the researchers in establishing extra
traceability links, ii) maintain the traceability links (e.g., for further evaluation by
the researchers).

16

Takeaway 2

We recommend gaining an early understanding of the organizational
structure, and being aware that the amount of traceability information
available may be inﬂuenced by such structure.

Take-away 1 and Take-away 2 are related to research on Conway’s law (e.g., [39,
40]) and the impact that traceability has on organizational vs. architectural struc-
ture. Moreover, research on communication of traceability highlights how or-
ganizational structure inﬂuences the way tasks are allocated and who within the
company possesses the necessary knowledge about artifacts of interest for the re-
searcher [41].

In the context of a large organization, different artifacts are tracked at differ-
ent levels of detail. In our collaboration with COMPANY, we realized that the
system used to track BRs was not populated with much information (e.g., many
ﬁelds were left blank or ﬁlled with boilerplate values). The organizational norm in
case BR details are needed is to refer to the BR speciﬁcation document (through
a link in the tracking system) stored in a separate repository. This limited the au-
tomatic extraction of information from BRs, as the two systems are not designed
to communicate autonomously.

Takeaway 3

When establishing traceability, consider that in complex settings differ-
ent information about the same artifact are likely to be scattered across
systems. Regardless of the approach, consolidating such information
requires knowledge of the company’s norms.

Several researchers tried to address the challenge of scattered information [42, 43,
44]. Promising approaches have combined traditional information retrieval with
model-driven engineering [45] and (semi)supervised machine learning [46].

TestOrg was aware of the problem with dispersed information. They led,
within COMPANY, an initiative to centralize test cases and BR tracking for sev-
eral purposes, including improving their traceability. By the end of such initiative,
COMPANY will use a single tracking system for all these artifacts.

17

Takeaway 4

Depending on the structure and location of the information required to
establish traceability, a fully-automated solution may not be feasible. A
solution for creating traceability links should not start by considering
full-ﬂedged automation but by accommodating human intervention.

Tool support is fundamental when establishing, using, and maintaining traceabil-
ity links. Organizations developing complex systems deal with artifacts at differ-
ent levels of abstraction, details, and formats, which entail using different artifact-
tracking tools. Moreover, practitioners choose, conﬁgure, and use tools according
to the level of traceability necessary for their tasks—for them interoperability may
not be a decisive criterion for selecting a tool. For example, COMPANY uses an
homebrew system for tracking requirements speciﬁcation documents and IRs, a
third-party commercial solution (which reached end-of-life in early 2019, but it
is still maintained for legacy reasons) for tracking BRs, and different open-source
systems for source code version control and code reviews. Some offer APIs, but
none offered out-of-the-box integration towards any of the other systems.

Takeaway 5

Fragmentation in terms of tools within a company developing complex
systems is to be expected. Therefore, effort is required to achieve inter-
operability between systems when establishing traceability links.

Addressing tools fragmentation is signiﬁcant for safety-critical software develop-
ment [47] and could be mitigated, for instance, through modelling [48].

In the case of COMPANY, fragmentation (and the consequent lack of trace-
ability) derived from a tradeoff between other system properties deemed more
desirable. During our feedback sessions with TestOrg, it became apparent that
the homebrew solution was selected to have control over i) the security of the
speciﬁcations as they contain information pivotal for COMPANY’s competitive
advantage, and ii) the redundancy of the storage to avoid costly data loss.

5.2. Considerations on traceability in complex industrial settings

The results of this study provide insights into the state-of-practice, lessons
learned, and considerations for industrial practitioners and academics to reﬂect

18

upon regarding traceability. The experience reported in this paper highlights a
dichotomous and puzzling situation that was surprising for the researchers in-
volved in this study. The academic literature on traceability and alignment sup-
ports the idea that traceability among software artifacts is needed to manage com-
plexity [18]. Despite these claims, COMPANY is producing systems in the order
of millions of lines of code, with thousands of developers, yet traceability links
from high-level requirements to source code and tests are not readily available.
Paradoxically, traceability within COMPANY may not be achieved because of the
system’s complexity, while traceability could mitigate said complexity.

What is going on in this case? The results may seem bafﬂing, but in real-
world settings—when software grows and the organization along with it—several
factors inﬂuence the evolution of a product, its development process, and the en-
vironment. We did not study the root cause of the current situation, but several
hypotheses can be formulated.

First, the system is considered a system of systems (SoS), developed in a het-
erogeneous environment of processes, tools, and third-party components. Without
a strong culture to tie this development together with an emphasis on traceability,
it is only natural that its amount and consistency will vary. Integration and SoS
development are still considered possible, as such is managed at a higher level
of abstraction, primarily considering the interfaces of the underlying components,
despite the lack of end-to-end traceability.

Second, achieving traceability in a large system is resource-intensive, and hu-
man commitment also comes into play. In a study by Borg et al. about change
requests and change management, it was observed that teams are hesitant to even
touch upon other teams’ code [19]. In larger silo organizations this situation is ex-
acerbated since silos may assume that other individuals or teams keep traceability
up to date, especially when teams suffer from resource constraints.

Take, as an example, a scenario in which Team A is adapting a system core
component to conform to a BR. As BRs are high level, they likely require changes
to surrounding components. The developers in Team A make changes, but due to
the lack of insight or knowledge about the Team B artifacts, not all artifacts asso-
ciated with the modiﬁed components are updated. This causes a slight misalign-
ment between the requirement traces and the system under development. After
many such changes, traceability will naturally degrade over time, leading to a sit-
uation where traces will have to be maintained or reverse engineered. However,
since reverse engineering is expensive, process solutions that enforce localized
knowledge—i.e., silo organizations are instead encouraged.

Finally, there can be a legacy component to the challenge—i.e., that compo-

19

nents within the SoS are decaying. These components may have had extensive
traceability information, but as Agile practices are leaner in terms of documenta-
tion, such traces are no longer maintained. Hence, a situation that is perceived as
a product of a new way of working with software in which artifacts of long-term
value—associated with high cost—are de-prioritised in favour of short-term value
gains and other forms of light-weight documentation that fulﬁll similar purposes.
Furthermore, we observed that traceability between high-level requirements,
source code, and test suites is not maintained at COMPANY. A question remains,
how can COMPANY continue producing high-quality, large-scale, and complex
software on time while keeping their customers satisﬁed? As discussed in this
section, we believe it is due to the evolution of the development organization and
its ability to adapt to circumstances in which traceability is not always available.
Hence, instead of relying on traceability information, workarounds and alternate
processes, coupled with organizational structures and architectural design deci-
sions, provide COMPANY a cohesive understanding of the system.

Hence, although the academic literature highlights the need for traceability
for understanding of how the system ﬁts together [7], the situation we observed at
COMPANY indicates that such requirements may have been overstated.

6. Conclusion

In this paper, we reported our experience in applied research with COMPANY.
In particular, our goal was to deﬁne and apply an intervention for identifying
quality inﬂation using artifacts in different development phases. However, our
attempt failed due to the lack of traceability between such artifacts.

We reﬂected on the outcomes of this industrial study, which led us to ques-
tion the role and perceived value of traceability in industry, and its return-on-
investment for large software projects. From our experience, we encourage prac-
titioners to be selective about the traceability links necessary for their organization
while highlighting the importance of requirement-to-test case trace links. More-
over, practitioners need to explicitly manage traceability links as they do for other
artifacts (e.g., requirements, documents, test cases). We also suggest takeaways
that can support researchers performing empirical studies that consider traceabil-
ity a prerequisite.
In particular, they need to be aware that the organizational
structure and norms can impact which traceability links exist and how they are
managed. For complex projects in large settings, scattered information among
different tools and systems is to be expected.

20

In the future, we aim to systematically study the state-of-practice related to

traceability among our industrial partners.

7. Acknowledgements

Davide Fucci and Emil Al´egroth would like to acknowledge that this work was
supported by the KKS foundation through the S.E.R.T. Research Proﬁle project at
Blekinge Institute of Technology.

References

[1] M. Unterkalmsteiner, R. Feldt, T. Gorschek, A taxonomy for requirements
engineering and software test alignment, ACM Transactions on Software
Engineering and Methodology (TOSEM) 23 (2) (2014) 1–38.

[2] B. Randell, Towards a methodology of computing system design, in: NATO

working conference on software engineering, 1968, pp. 204–208.

[3] S. Charalampidou, A. Ampatzoglou, E. Karountzos, P. Avgeriou, Empiri-
cal studies on software traceability: A mapping study, Journal of Software:
Evolution and Process 33 (2) (2021) e2294.

[4] F. Tian, T. Wang, P. Liang, C. Wang, A. A. Khan, M. A. Babar, The impact
of traceability on software maintenance and evolution: A mapping study,
Journal of Software: Evolution and Process 33 (10) (2021) e2374.

[5] S. Nair, J. L. De La Vara, S. Sen, A review of traceability research at the re-
quirements engineering conference re@ 21, in: 2013 21st IEEE International
Requirements Engineering Conference (RE), IEEE, 2013, pp. 222–229.

[6] R. Watkins, M. Neal, Why and how of requirements tracing, Ieee Software

11 (4) (1994) 104–106.

[7] J. Kukkanen, K. V¨akev¨ainen, M. Kauppinen, E. Uusitalo, Applying a sys-
tematic approach to link requirements and testing: A case study, in: 2009
16th Asia-Paciﬁc Software Engineering Conference, IEEE, 2009, pp. 482–
488.

[8] J. Cleland-Huang, C. K. Chang, M. Christensen, Event-based traceability for
managing evolutionary change, IEEE Transactions on Software Engineering
29 (9) (2003) 796–810.

21

[9] J. H. Hayes, A. Dekhtyar, S. K. Sundaram, E. A. Holbrook, S. Vadlamudi,
A. April, Requirements tracing on target (retro): improving software main-
tenance through traceability recovery, Innovations in Systems and Software
Engineering 3 (3) (2007) 193–202.

[10] N. Mustafa, Y. Labiche, The need for traceability in heterogeneous systems:
a systematic literature review, in: 2017 IEEE 41st Annual Computer Soft-
ware and Applications Conference (COMPSAC), Vol. 1, IEEE, 2017, pp.
305–310.

[11] H. Tufail, M. F. Masood, B. Zeb, F. Azam, M. W. Anwar, A systematic
review of requirement traceability techniques and tools, in: 2017 2nd Inter-
national Conference on System Reliability and Safety (ICSRS), IEEE, 2017,
pp. 450–454.

[12] M. A. Javed, U. Zdun, A systematic literature review of traceability ap-
proaches between software architecture and source code, in: Proceedings
of the 18th International Conference on Evaluation and Assessment in Soft-
ware Engineering, 2014, pp. 1–10.

[13] I. Santiago, A. Jim´enez, J. M. Vara, V. De Castro, V. A. Bollati, E. Marcos,
Model-driven engineering as a new landscape for traceability management:
A systematic literature review, Information and Software Technology 54 (12)
(2012) 1340–1356.

[14] C. Ebert, Improving engineering efﬁciency with plm/alm, Software & Sys-

tems Modeling 12 (3) (2013) 443–449.

[15] J. Lin, C. C. Lin, J. Cleland-Huang, R. Settimi, J. Amaya, G. Bedford,
B. Berenbach, O. B. Khadra, C. Duan, X. Zou, Poirot: A distributed tool sup-
porting enterprise-wide automated traceability, in: 14th IEEE International
Requirements Engineering Conference (RE’06), IEEE, 2006, pp. 363–364.

[16] J. Dick, Rich traceability, in: Proceedings of the 1st international workshop
on traceability in emerging forms of software engineering, Citeseer, 2002,
pp. 18–23.

[17] A. Tang, Y. Jin, J. Han, A rationale-based architecture model for design
traceability and reasoning, Journal of Systems and Software 80 (6) (2007)
918–934.

22

[18] D. M. Fern´andez, S. Wagner, M. Kalinowski, M. Felderer, P. Mafra,
A. Vetr`o, T. Conte, M.-T. Christiansson, D. Greer, C. Lassenius, et al., Nam-
ing the pain in requirements engineering, Empirical software engineering
22 (5) (2017) 2298–2338.

[19] M. Borg, E. Al´egroth, P. Runeson, Software engineers’ information seeking
behavior in change impact analysis-an interview study, in: 2017 IEEE/ACM
25th International Conference on Program Comprehension (ICPC), IEEE,
2017, pp. 12–22.

[20] T. Gorschek, P. Garre, S. Larsson, C. Wohlin, A model for technology trans-
fer in practice, IEEE Software 23 (6) (2006) 88–95. doi:10.1109/MS.
2006.147.

[21] P. Lenberg, E. Al´egroth, R. Feldt, L. G. W. Tengberg, An initial analysis of
differences in software engineers’ attitudes towards organizational change,
in: Proceedings of the 9th International Workshop on Cooperative and Hu-
man Aspects of Software Engineering, 2016, pp. 1–7.

[22] P. Lenberg, R. Feldt, Psychological safety and norm clarity in software en-
gineering teams, in: Proceedings of the 11th international workshop on co-
operative and human aspects of software engineering, 2018, pp. 79–86.

[23] A. Van Deursen, L. Moonen, A. Van Den Bergh, G. Kok, Refactoring test
code, in: Proceedings of the 2nd international conference on extreme pro-
gramming and ﬂexible processes in software engineering (XP2001), Cite-
seer, 2001, pp. 92–95.

[24] P. Runeson, E. Engstr¨om, M.-A. Storey, The Design Science Paradigm as a
Frame for Empirical Software Engineering, Springer International Publish-
ing, 2020.

[25] A. Zaidman, B. Van Rompaey, S. Demeyer, A. Van Deursen, Mining soft-
ware repositories to study co-evolution of production & test code, in: 2008
1st international conference on software testing, veriﬁcation, and validation,
IEEE, 2008, pp. 220–229.

[26] V. R. B. G. Caldiera, H. D. Rombach, The goal question metric approach,

Encyclopedia of software engineering (1994) 528–532.

23

[27] S. S. d. Toledo, A. Martini, D. I. Sjøberg, Identifying architectural technical
debt, principal, and interest in microservices: A multiple-case study, Journal
of Systems and Software 177 (2021) 110968. doi:10.1016/j.jss.
2021.110968.

[28] S. Charalampidou, A. Ampatzoglou, A. Chatzigeorgiou, N. Tsiridis, Inte-
grating Traceability within the IDE to Prevent Requirements Documenta-
tion Debt, 2018 44th Euromicro Conference on Software Engineering and
Advanced Applications (SEAA) (2018) 421–428doi:10.1109/seaa.
2018.00075.

[29] S. Charalampidou, A. Ampatzoglou, E. Karountzos, P. Avgeriou, Empiri-
cal studies on software traceability: A mapping study, Journal of Software:
Evolution and Process 33 (2) (2021). doi:10.1002/smr.2294.

[30] D. Diaz, G. Bavota, A. Marcus, R. Oliveto, S. Takahashi, A. De Lucia, Us-
ing code ownership to improve ir-based traceability link recovery, in: 2013
21st International Conference on Program Comprehension (ICPC), 2013, pp.
123–132. doi:10.1109/ICPC.2013.6613840.

[31] J. Ahlgren, M. E. Berezin, K. Bojarczuk, E. Dulskyte, I. Dvortsova,
J. George, N. Gucevska, M. Harman, S. He, R. L¨ammel, et al., Ownership
at large: Open problems and challenges in ownership management, in: Pro-
ceedings of the 28th International Conference on Program Comprehension,
2020, pp. 406–410.

[32] S. Dasanayake, S. Aaramaa, J. Markkula, M. Oivo, Impact of requirements
volatility on software architecture: How do software teams keep up with
ever-changing requirements?, Journal of software: evolution and process
31 (6) (2019) e2160.

[33] P. M¨ader, A. Egyed, Do developers beneﬁt from requirements traceability
when evolving and maintaining a software system?, Empirical Software En-
gineering 20 (2) (2015) 413–441.

[34] B. Cornu, E. T. Barr, L. Seinturier, M. Monperrus, Casper: Automatic track-
ing of null dereferences to inception with causality traces, Journal of Sys-
tems and Software 122 (2016) 52–62. doi:https://doi.org/10.
1016/j.jss.2016.08.062.

24

[35] R. Wohlrab, P. Pelliccione, A. Shahrokni, E. Knauss, Why and how your
traceability should evolve: Insights from an automotive supplier, IEEE Soft-
ware 38 (4) (2021) 62–70. doi:10.1109/MS.2020.2996369.

[36] H. A. Cetin, Identifying the most valuable developers using artifact trace-
ability graphs, in: Proceedings of the 2019 27th ACM Joint Meeting on
European Software Engineering Conference and Symposium on the Foun-
dations of Software Engineering, ESEC/FSE 2019, Association for Com-
puting Machinery, New York, NY, USA, 2019, p. 1196–1198. doi:
10.1145/3338906.3342487.
URL https://doi.org/10.1145/3338906.3342487

[37] H. A. C¸ etin, E. T¨uz¨un, Identifying key developers using artifact traceabil-
ity graphs, in: Proceedings of the 16th ACM International Conference on
Predictive Models and Data Analytics in Software Engineering, PROMISE
2020, Association for Computing Machinery, New York, NY, USA, 2020, p.
51–60. doi:10.1145/3416508.3417116.
URL https://doi.org/10.1145/3416508.3417116

[38] E. S¨ul¨un, E. T¨uz¨un, U. Do˘grus¨oz, Reviewer recommendation using software
artifact traceability graphs, in: Proceedings of the Fifteenth International
Conference on Predictive Models and Data Analytics in Software Engineer-
ing, PROMISE’19, Association for Computing Machinery, New York, NY,
USA, 2019, p. 66–75. doi:10.1145/3345629.3345637.
URL https://doi.org/10.1145/3345629.3345637

[39] J. D. Herbsleb, R. E. Grinter, Architectures, coordination, and distance: Con-

way’s law and beyond, IEEE software 16 (5) (1999) 63–70.

[40] J. D. Herbsleb, R. E. Grinter, Splitting the organization and integrating the
code: Conway’s law revisited, in: Proceedings of the 21st international con-
ference on Software engineering, 1999, pp. 85–95.

[41] S. Imtiaz, N. Ikram, Effective task allocation in distributed environments: A
traceability perspective, in: International Conference on Software Engineer-
ing Advances, 2011, pp. 563–569.

[42] G. Shen, H. Wang, Z. Huang, Y. Yu, K. Chen, Supporting requirements to
code traceability creation by code comments, International Journal of Soft-
ware Engineering and Knowledge Engineering 31 (08) (2021) 1099–1118.

25

[43] H. Wang, G. Shen, Z. Huang, Y. Yu, K. Chen, Analyzing close relations be-
tween target artifacts for improving ir-based requirement traceability recov-
ery, Frontiers of Information Technology & Electronic Engineering 22 (7)
(2021) 957–968.

[44] M. Taromirad, N. D. Matragkas, R. F. Paige, Towards a multi-domain model-
driven traceability approach., in: MPM@ MoDELS, 2013, pp. 27–36.

[45] N. Sannier, B. Baudry, Toward multilevel textual requirements traceability
using model-driven engineering and information retrieval, in: 2012 Second
IEEE International Workshop on Model-Driven Requirements Engineering
(MoDRE), IEEE, 2012, pp. 29–38.

[46] E. E. Bella, S. Creff, M.-P. Gervais, R. Bendraou, Atlas: A framework
for traceability links recovery combining information retrieval and semi-
supervised techniques, in: 2019 IEEE 23rd International Enterprise Dis-
tributed Object Computing Conference (EDOC), IEEE, 2019, pp. 161–170.

[47] A. Baumgart, C. Ellen, A recipe for tool interoperability, in: 2014 2nd Inter-
national Conference on Model-Driven Engineering and Software Develop-
ment (MODELSWARD), IEEE, 2014, pp. 300–308.

[48] N. Drivalos, D. S. Kolovos, R. F. Paige, K. J. Fernandes, Engineering a dsl
for software traceability, in: International Conference on Software Language
Engineering, Springer, 2008, pp. 151–167.

26

