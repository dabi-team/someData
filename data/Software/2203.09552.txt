Robin Belton, Bree Cummins, and Tom´aˇs Gedeon

Department of Mathematical Sciences
Montana State University
Bozeman, MT, 59717, USA
Brittany Terese Fasy

Department of Mathematical Sciences and School of Computing
Montana State University
Bozeman, MT, 59717, USA

2
2
0
2

g
u
A
4
2

]
S
D
.
s
c
[

3
v
2
5
5
9
0
.
3
0
2
2
:
v
i
X
r
a

EXTREMAL EVENT GRAPHS: A (STABLE) TOOL FOR ANALYZING NOISY
TIME SERIES DATA

Abstract. Local maxima and minima, or extremal events, in experimental time series can be used
as a coarse summary to characterize data. However, the discrete sampling in recording experimental
measurements suggests uncertainty on the true timing of extrema during the experiment. This
in turn gives uncertainty in the timing order of extrema within the time series. Motivated by
applications in genomic time series and biological network analysis, we construct a weighted directed
acyclic graph (DAG) called an extremal event DAG using techniques from persistent homology that
is robust to measurement noise. Furthermore, we deﬁne a distance between extremal event DAGs
based on the edit distance between strings. We prove several properties including local stability
for the extremal event DAG distance with respect to pairwise L∞ distances between functions in
the time series data. Lastly, we provide algorithms, publicly free software, and implementations on
extremal event DAG construction and comparison.

1. Introduction

Experimental time series data are ubiquitous in today’s science and provide a window through
which we can observe the underlying dynamics of complex systems, ranging from cells to ecosystems
and climate. We study collections of time series which are also referred to as multivariate time
series in the literature [61, 65]. We construct a weighted directed graph descriptor of a collection of
time series data using persistent homology, a technique that belongs to a collection of approaches
known as Topological Data Analysis (TDA) that uses algebraic topology [25, 39] to extract shape
from data. TDA is used to study data from a wide range of applications including material science
[34], cancer biology [63], and political science [20]. Some of the classic and foundational papers in
TDA include [68, 26, 22, 18, 46].

Our descriptor characterizes a collection of time series by the order of their extrema in a way that
also captures the robustness of this order with respect to measurement uncertainty. Our motivation
comes from the desire to mathematically capture and compare collections of ‘omics time series data,
such as transcriptomics, proteomics, and others. In particular, the coarse information of orders
of extrema have been used to assess regulatory network models of gene/protein interactions [16].
Other applications involve quantifying similarity between gene expression time series [5, 57] across
repeated experiments.

Our mathematical methods are motivated by the combinatorial approaches in [16, 5, 44] that use
only the approximate timing of time series extrema as the relevant features of experimental data.
To take into account the uncertainty of capturing temporal orderings of extrema, [16] replaced

2020 Mathematics Subject Classiﬁcation. Primary: 05C90, 55N31. Secondary: 92-08.
Key words and phrases. time series, topological data analysis, stability, directed graphs, biological networks.
This material is based upon work supported by the US National Science Foundation under grant No. DGE 1649608
(Belton) and DMS 1839299 (Cummins and Gedeon), CCF 2046730 (Fasy), as well as the National Institute of Health
under grant No. 5R01GM126555-01 (Gedeon).

1

 
 
 
 
 
 
2

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

the single time point locations of extrema with time intervals that were determined by manual
inspection. If the intervals are disjoint, then the ordering of extrema is interpreted to be robust
to measurement uncertainty. In the follow-up paper [5], an approach was developed in which the
intervals are algorithmically constructed using merge trees [19, 38], branch decompositions [37],
and sublevel sets. These intervals are called ε-extremal intervals and have the property that they
are the smallest intervals for which all continuous perturbations of a continuous function (with
additional technical restrictions) that lie within an ε-band are guaranteed to attain an extremum
under measurement uncertainty of size ε. Using the ε-extremal intervals, labeled directed acyclic
graphs (DAGs) are constructed to represent the time series data for any ﬁxed value of ε. We refer
to these DAGs as ε-DAGs. Vertices or nodes in the ε-DAG represent extrema in the time series
data. Directed edges a → b indicate that we can unambiguously discern the order (in time) of
events corresponding to vertices a and b under measurement uncertainty of size ε.

Continuing this line of research, [44] deﬁned a distance metric that compares two collections of
time series by comparing the corresponding ε-DAGs. This metric involves computing the directed
maximal common edge subgraph (DMCES) and was applied in [5] to quantify similarity in replicate
experiments of microarray yeast cell cycle data. Additionally, the metric was used in [57] to
provide quantitative evidence that an intrinsic oscillator drives the blood stage cycle of the malaria
parasite Plasmodium falciparum. The metric for ε-DAGs using the DMCES is eﬀective in capturing
similarity between the time series, but is computationally expensive. This limits the total number
of extrema across all time series that can be eﬀectively analyzed. Another limitation is that the
distance can only be measured at a single measurement uncertainty level ε, which is often unknown
and thus the distance has to be computed multiple times for a collection of ε values. A better
measurement would incorporate information about changes in similarity as a function of changing
ε in a single value.

We signiﬁcantly expand and generalize the work of [5] and [44] by constructing a weighted DAG
that reﬂects robustness of the extremal ordering for all levels of measurement error ε. We call this
an extremal event DAG. Vertices in this graph again represent extrema in the time series data, and
a directed edge a → b indicates that extremum a occurs before extremum b. The node weights
measure prominence of extrema while the edge weights indicate the smallest ε level for which the
relative order between the two associated extrema can no longer be guaranteed. The node weights
are computed using sublevel set persistence [19]. After representing the collection of time series as
an extremal event DAG, we deﬁne a distance between extremal event DAGs as a modiﬁed version
of the edit distance (Chapter 15 of [15]). The edit distance quantiﬁes similarity of two strings based
on the minimum number of operations (e.g., insertion, substitution, and deletion) it takes to align
the two strings. This distance is commonly used in many applications including DNA sequence
alignment, see [43] for one of the ﬁrst papers on the topic. The standard algorithm for the edit
distance between two strings of length n can be computed via dynamic programming in Θ(n2)
(Chapter 15 of [15]).

We prove several key properties of the extremal event DAG weights. Most importantly for
computability and applications, Theorem 3.3 gives a simple criterion to compute edge weights.
Furthermore, we analyze stability properties of distances between extremal event DAGs. Section 5
gives stability results for distances used to compare extremal event DAGs with respect to pairwise
L∞ distance between the underlying continuous functions. These stability results show that small
changes within time series data lead to small changes in the corresponding extremal event DAG
distances. In Theorem 5.21, we show the extremal event DAG distance is stable in a local case:
two paired continuous functions from the two collections of time series must lie within an ε band
that allows for an unambiguous alignment of the minima and maxima between the two time series.
Additionally, one of the time series can have small amplitude additional maxima and minima.

Furthermore, extremal event DAGs and the extremal event DAG distance is computable. The
general pipeline of utilizing extremal event DAGs takes two datasets of collections of time series as

EXTREMAL EVENT GRAPHS

3

input, computes the associated extremal event DAGs, and the extremal event DAG distance be-
tween the extremal event DAGs, see Figure 1. We illustrate two biological applications of extremal
event DAGs and distances in Section 6. Additionally, the polynomial time algorithm to compute the
extremal event DAG given collections of discrete time series, and the dynamic program needed to
compute the extremal event DAG distance is provided in the supplementary materials. Lastly, free
and public software on computing extremal event DAGs and the distance between these descriptors
is available at [2].

Figure 1. Schematic for Comparing Collections of Time Series Using Extremal
Event DAGs. Each dataset consists of collections of time series. Extremal event
DAGs are computed for both datasets. Each vertex corresponds to a local extremum
of one of the time series in the dataset. Vertices highlighted in blue correspond to
local extrema in the blue time series while vertices highlighted in green correspond
to local extrema in the green time series. Vertices and directed edges capture the
order of local extrema, and weights signify the robustness of extremal orderings. To
compute a distance between extremal event DAGs, an extremal event supergraph is
computed using a modiﬁed version of the edit distance. The extremal event super-
graph has doubly weighted vertices and edges. The weight in the ﬁrst component is
associated to extremal event DAG 1 and the weight in the second component is asso-
ciated to extremal event DAG 2. Datasets 1 and 2 diﬀer by only a few perturbations
and we see the resulting extremal event DAG distance is equal to 1.29.

1.1. TDA in Analyzing Time Series Data. TDA has been used to study time series data and
the dynamics of underlying biological networks. One common method studies single variable time
series by using Takens’ embedding theorem [59]. The data is transformed by computing a sliding
window embedding of the data into a point cloud in Rn. This point cloud is then analyzed using one
dimensional persistent homology to detect and quantify periodicity. Examples that take this or a
modiﬁed approach include detecting periodicity of genomic time series data [48], studying entropy

Dataset 1Dataset 2vvvvvvvvvvvv0.250.250.0160.250.0160.0160.0160.0160.0160.0160.250.250.0160.50.50.50.5vvvvvvvvvvvv0.250.25v0.0680.420.0680.0160.0160.250.420.0680.0160.0160.0680.0160.0160.25maxmax0.250.50.50.0160.0160.250.50.50.5minminminminmaxmaxmax0.016sinecosinevvvv0.50.50.0180.0180.5minminmaxmaxmax0.0180.5vvvvvvvvvvvvvvvv0.250.0420.0420.250.250.250.0420.0420.50.0420.250.250.250.0420.250.250.0420.0420.50.50.250.0180.0180.0180.50.50.0180.0180.018minminminmaxmaxmax0.25sinecosine0.250.0180.25vvvvvvvvvvvvvvvv0.0180.0080.0120.0680.420.250.0420.0180.0180.0420.0420.0180.0180.0420.0680.0180.0180.0420.0180.0180.0750.250.0680.0180.018vvvv0.50.018minminmaxmaxmax0.50.50.500.01800.50.5vvvvvvvvvvvvvvvvvvvv0.250.0420.0420.50.50.0160.25000.50.50minminminmaxmaxmaxvvvvvvvvvvvvvvvv0.0160min0.250.25max(0,0.042)Distance =1.29Extremal Event  DAG 1Extremal Event  DAG 2Extremal Event  Supergraph4

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

and the dynamics of the underlying system [55, 1], characterizing gene regulatory networks [6], and
distinguishing between audio signals of the same note from diﬀerent instruments [52]. The goal in
these approaches is to quantify periodicity of single variable time series whereas we are interested
in capturing order of local extrema in multivariate time series.

The second common method to study single variable time series using TDA is to apply sublevel
set persistence to detect prominent features. Applications include signal processing [28], Fourier
spectrum analysis and parameter detection [41], arrythmia detection [17], and cancer studies [33].
Additionally, in [10], sublevel set persistence is used to deﬁne a topological regularizer that can then
be used as a classiﬁer for machine learning. Furthermore, sublevel set persistence on time series can
be used to determine noise that is often seen as small peaks in the time series [42]. We also apply
sublevel set persistence to detect prominent features, however, we also explore its connections to
capturing order and robustness of local extrema across multiple time series.

Lastly, TDA has been used to study other types of time dependent data. One includes dynamic
metric spaces that can be used to describe phenomena such as bird ﬂocks, insect swarms, schools
of ﬁsh, and aphid trajectories. TDA techniques to study these types of data include vineyards
[14], CROCKER plots [60, 62, 66], spatiotemporal ﬁltrations [30] and zig-zag persistence [9, 29].
Furthermore, time series data of fMRI images have been used to construct functional networks, and
then applying ﬁltrations on the weights of these networks to extract topological features [58, 49].
A more extensive summary on TDA techniques to study time series can be found in [21].

1.2. Biological Motivation. Extremal event DAGs are developed abstractly for mulitvariate time
series in general, however, we focus on the application of analyzing ‘omics data that measures
expression levels of thousands of genes. Transcription of genes produces messenger RNA (mRNA)
which are translated to proteins. Gene expression, measured by either the amount of mRNA
produced (transcriptomics) or by the amount of corresponding protein (proteomics), can be used
to measure the level of activity of a given gene product. There is strong evidence that the relative
phases of oscillating regulators are important to controlling important cellular processes such as
the cell cycle [32], circadian rhythm, or malaria parasite periodic infection of human blood cells.
The assertion of [5, 16] is that the ordering of extrema is a reasonable approximation of control by
phase relationship.

For example, it is hypothesized that a small transcriptional regulatory network controlling the cell
cycle can activate hundreds of other transcription factors in a phase-speciﬁc manner to play a vital
role in maintaining the proper progression of DNA replication and cell division [8, 12, 45, 31, 54].
There are still many open questions about the precise role of the transcriptional network in the
ordering of cell cycle events [50, 53]. A reproducible ordering of gene expression such as what was
observed in [5] provides supporting evidence for the central role of the cell cycle gene regulatory
network in orchestrating timely expression of other cell cycle events.

A question of interest in biology is evaluating the similarity of two experiments across labs or
experimental conditions. For example, an experimentalist may wish to measure the similarity
of expression level of genes driving the cell cycle between replicate experiments between time
series collected under diﬀerent growth conditions, or across organisms and tissues. For example,
circadian clock networks in diﬀerent tissues that control the temporal ordering of phase speciﬁc gene
expression [40, 67]. Similarity and diﬀerences in timing of the same network in tissues like heart
and liver can tell us about their mutual coupling as well as coupling to the master circadian clock in
the brain [35, 51]. In summary, mathematically modeling and comparing orders of extremal events
in ‘omics data is useful for identifying time series diﬀerences in multiple biological applications.
In particular, extremal event DAGs and distances can be used to study the important biological
questions about time dependent cellular processes, some of which we have mentioned here.

EXTREMAL EVENT GRAPHS

5

2. Background

We now summarize necessary terminology for the results that have been developed in this paper.
Many of these terms build oﬀ of ideas mentioned in Section 1. Throughout this section and the
rest of this paper, we use the following notation. Let X ⊂ R denote an arbitrary subset of R. Let
C := [a1, a2] ⊂ R be a closed interval of R.

2.1. Extrema. For a subset X ⊂ R, x ∈ X and ε > 0, let Bε(x) be the open neighborhood of
radius ε centered at x. That is

Bε(x) := {y ∈ X | |y − x| < ε}.
Deﬁnition 2.1 (Local Extrema). Let f : X → R be a function. We say f has a local minimum at
x ∈ X if there exists ε > 0 for which f (x) < f (y) for all y ∈ Bε(x) \ {x}. Similarly, f has a local
maximum at x ∈ X if there exists ε > 0 for which f (x) > f (y) for all y ∈ Bε(x) \ {x}. We refer to
any local minimum or local maximum as a local extremum of f . If x ∈ X with f (x) < f (y) for all
y ∈ X \ {x}, we say f has a global minimum at x. Similarly, for x ∈ X where f (x) > f (y) for all
y ∈ X \ {x}, we say f has a global maximum at x.

We often order the extrema of a function. To ease notation, we write [n] to be the set of the ﬁrst

n integers. That is

[n] := {1, 2, . . . , n}.

2.2. Distances. We use the L∞ metric to quantify distances between collections of points and
functions.

Deﬁnition 2.2 (L∞ metric). Let R := R∪{∞}. For points p = (p1, p2, . . . , pn), q = (q1, q2, . . . , qn) ∈
Rn
, we deﬁne the L∞ distance between points p and q as (cid:107)p − q(cid:107)∞ = maxi |pi − qi|For functions
f, g : K → R where K ⊂ R is compact, we deﬁne the L∞ distance between functions f and g as
(cid:107)f − g(cid:107)∞ = supx∈K |f (x) − g(x)|.

For a subset X ⊂ Rn

centered at x. That is

, x ∈ X and ε > 0, let (cid:3)ε(x) be the L∞ open neighborhood of radius ε

(cid:3)ε(x) := {y ∈ X | (cid:107)y − x(cid:107)∞ < ε}.

2.3. ε-Perturbations. We consider perturbations of a function f .

Deﬁnition 2.3 (ε-Neighborhood of f ). Let f : K → R be a continuous function, where K ⊂ R is
compact. For ε ≥ 0, deﬁne

Nε(f ) := {g : K → R | g is continuous and (cid:107)f − g(cid:107)∞ < ε}

to be the ε-neighborhood of f . A function g ∈ Nε(f ) is called an ε-perturbation of f .

2.4. ε-Extremal Intervals. Let INT(C) be the set of relatively open intervals contained in
C := [a1, a2] ⊂ R. To enable comparability between local extrema for functions in Nε(f ) for diﬀer-
ent levels of ε, we use the following deﬁnition.

Deﬁnition 2.4 (ε-Extremal Interval at t). Let f : C → R be a continuous function and T be the
set of domain coordinates of all local extrema of f . Let ε > 0. Deﬁne ϕf
ε : T → INT(C) such that
ε (t) to be the connected component

Case 1: If t ∈ T and (t, f (t)) is a local minimum, deﬁne ϕf

of (f − ε)−1(−∞, f (t) + ε) that contains t.

Case 2: If t ∈ T and (t, f (t)) is a local maximum, deﬁne ϕf

ε (t) to be the connected component

of (f + ε)−1(f (t) − ε, ∞) that contains t.

We call ϕf

ε (t) the ε-extremal interval at t (see Figure 2).

6

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

We note that sometimes we omit the superscript f and simply write ϕε when the function used

to construct the ε-extremal intervals is clear.
Remark 2.5 (Notation for Endpoints of ε-Extremal Intervals). Let f : C → R be a continuous
function with a local extremum at t ∈ C. Suppose ϕf
ε (t) is the ε-extremal interval at t. We deﬁne
ε (t)). We deﬁne the right endpoint of ϕf
the left endpoint of ϕf
ε (t)) := inf(ϕf
ε (t) to
ε (ti) by len(ϕf
ε (t)). Finally, we denote the length of ϕf
be right(ϕf

ε (t) to be left(ϕf

ε (t)) := sup(ϕf

ε (t)).

Figure 2. The ε-extremal intervals at t3 and t4. The ε-extremal interval at t3 is
the connected component of (f + ε)−1(f (t3) − ε, ∞) that contains t3 (Case 2). The
ε -extremal interval at t4 is the connected component of (f − ε)−1(−∞, f (t4) + ε)
that contains t4 (Case 1).

2.5. Sublevel Set Persistence. We work with a speciﬁc case of persistent homology that encodes
the changes of the connectedness of sublevel sets of a real-valued function f : X → R deﬁned on a
topological space X as the height parameter ranges from −∞ to ∞. This information is encoded
in a topological descriptor called a persistence diagram and encodes the prominence of the local
extrema of f . Persistent homology is a general mathematical framework and we only provide the
deﬁnitions necessary for our results here; see [19, 47] for more detailed introductions to persistence.
Below we deﬁne sublevel set persistence using notation similar to page 181 of [19]. One assumption
we need is tameness of f .
Deﬁnition 2.6 (Homological Critical Values). Let X be a topological space, f : X → R a function.
We call a ∈ R a homological critical value if there exists a non-negative integer n and δ > 0 such
that for all 0 < ε < δ, the linear map Hn(f −1(−∞, a − ε]) → Hn(f −1(−∞, a + ε]) induced by the
inclusion of sublevel sets is not an isomorphism.

In other words, the homological critical values are the values at which the homology of the
sublevel sets change. For Morse functions f on a smooth manifold, these points are exactly the
heights of the local extrema of f [36]. We also note that in this paper we work with Z/2Z coeﬃcients.
Deﬁnition 2.7 (Tameness). Let X be a topological space. A function f : X → R is tame if it has
a ﬁnite number of homological critical values and the homology groups Hn(f −1(−∞, a]) are ﬁnite
for every a ∈ R.

EXTREMAL EVENT GRAPHS

7

Next, we consider a nested sequence of sublevel sets. A ﬁltration of a topological space X is
a nested family of subspaces (Xr)r∈T starting at the empty set, where T ⊂ R, such that for all
r, s ∈ T where r ≤ s, we have Xr ⊂ Xs, and (cid:83)
r∈T Xr = X. For f : X → R, the sequence of
all sublevel sets (f −1(−∞, r])r∈R, ordered by inclusion and indexed by R, is called the sublevel
In particular, for r ≤ s, we have f −1(−∞, r] ⊂ f −1(−∞, s]. The inclusion map
set ﬁltration.
ι : f −1(−∞, r] → f −1(−∞, s] induces a homomorphism between homology groups

n : Hn(f −1(−∞, r]) → Hn(f −1(−∞, s]).
gr,s
This homomorphism takes the homology of the sublevel set of f −1(−∞, r] to the homology of the
sublevel set of f −1(−∞, s]. The image of gr,s
n contains all this important information. We deﬁne
the nth persistent homology groups to be the images of all the homomorphisms H r,s
n ).
The nth persistent Betti numbers are the ranks; βr,s

n := im(gr,s

n := rank(H r,s

n ).

n

n

n

, βi,j

, and gi,j

n := gri,rj

n := βri,rj

n := H ri,rj

. The persistent homology group H i,j

Next we describe how to encode the persistent homology groups into a multiset of points in the
extended plane. Consider a tame function f : X → R. Let (ri)N
i=1 be the ordered sequence of
homological critical values of f . Since we are working with a tame function, there are only a ﬁnite
number of heights we need to consider where the sublevel sets change. To ease notation, we write
H i,j
n consists of
the homology classes of f −1(−∞, ri] that still persist in f −1(−∞, rj]. The persistent Betti number
βi,j
n counts the number of homology classes that persist between f −1(−∞, ri] and f −1(−∞, rj].
The ﬁrst index for which a homology class appears is the birth of that class. When a class in
f −1(−∞, ri−ε] merges with another in f −1(−∞, ri], then the class dies at a height of ri. When
classes merge together we follow the elder rule (See section 7.1 of [19]) that requires the class with
a greater birth height to merge with the class of the lower birth height.
Deﬁnition 2.8 (Persistence Diagram Dn(f )). Let f : X → R be a tame function with homological
i=1. Consider the set S := R ∪ {∞}. The nth dimensional persistence
critical values R := {ri}N
diagram Dn(f ) is the multiset set of points in R2
such that the point p = (ri, rj) ∈ R × S where
ri ≤ rj is included with multiplicity,

µn(p) = lim
ε→0+

(βi,j

n − βi,j+ε
n

) − (βi−ε,j

n

− βi−ε,j+ε
n

).

We set p ∈ Dn(f ) if, and only if, µn(p) > 0.

In regards to µn(p), the ﬁrst diﬀerence counts the number of homology classes that are born
at or before a height of ri and die at a height of rj. The second diﬀerence counts the number of
homology classes that are born at or before a height of ri − ε and die at a height of rj.

The persistence diagram summarizes the homology groups as the height parameter ranges from −∞

to ∞. Each persistence point p = (b, d) ∈ Dn(f ) is called a birth-death pair since it represents a
unique generator of the homology groups of the sublevel sets of f that is born at parameter b and
dies going into parameter d. In this work, we are concerned with a special type of tame function.
Deﬁnition 2.9 (Nicely Tame Functions). Let X ⊂ R be a topological space. A function f : X → R
is nicely tame if f is tame, continuous, and for each critical value y, the preimage f −1(y) is a ﬁnite
set.

Speciﬁcally, we work with a nicely tame function f : [a1, a2] → R where a1, a2 ∈ R.

If the
function values at the local extrema are unique, then there is a one-to-one correspondence between
persistence points and the local minima of f . Then a persistence point (b, d) corresponds to the
local minimum (t, f (t) = b) since the homological critical values are the local minima and maxima
of f .

In the event that the values of several minima are the same, this correspondence is not unique.
However, a unique correspondence can be induced by ﬁxing an order on the local minima (e.g.,
the domain coordinates) and using that ordering to break ties. For a multiset A, we write |A| for

8

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

the total multiplicity of A i.e., |A| = (cid:80)
persistence diagram from a sublevel set ﬁltration.

p∈A µ(p). Figure 3 gives an example of a function and its

In this work, we are only concerned with D0(f ) and we denote D(f ) := D0(f ). Furthermore,
all our persistence diagrams have a unique point in D(f ) with a death coordinate of ∞. We call
this the essential connected component. If t does not represent the essential component, then there
exists a local maximum (t(cid:48), f (t(cid:48))) such that (f (t), f (t(cid:48))) ∈ D(f ). In this case, f (t(cid:48)) is the height
at which the connected component of f −1(−∞, f (t(cid:48))] containing t merges with another connected
component of the sublevel set f −1(−∞, f (t(cid:48))] represented by a local minimum s where f (s) < f (t).1
We call f (t(cid:48)) the merge height of t.

Figure 3. Left. A function, f :
Persistence dia-
gram of f , D(f ) obtained from a sublevel set ﬁltration of f . The set D(f ) is
{(f (t1), ∞), (f (t3), f (t2)), (f (t5), f (t4))}. The ﬁrst coordinate of each point in D(f )
is the height of a local minimum, while the second coordinate is the height of a local
maximum or ∞.

[t1, t5] → R. Right.

As mentioned before, sublevel set persistence has been previously studied to characterize promi-
In [3], well groups that are deﬁned using ε > 0 and sublevel sets of a
nent features of data.
continuous function between topological spaces are used to measure the robustness of homology
groups from sublevel sets of a function under any ε-perturbation. Unlike ε-extremal intervals, well
groups are algebraic groups and are not speciﬁc to a local extremum.

2.6. Persistence of Extrema. Given a function f : C → R and the domain coordinate t of a local
extremum, any continuous function g ∈ Nε(t) is guaranteed to have the same type of extremum in
the interval ϕf
ε (t) for small enough ε. At some value of ε, however, this is no longer guaranteed.
We use the persistence diagram D(f ) to assist us with understanding when this occurs.
Deﬁnition 2.10 (Birth-Death Pairing Map). Let f : C → R be a nicely tame function. Let {ti}n
i=1
be the set of domain coordinates of the local minima of f . Deﬁne the birth-death pairing map to
be ζf : {ti}n

i=1 → R>0 by

ζf (ti) =

(cid:40)

max(f )
f (tj)

if ti represents the essential component
otherwise,

where f (tj) is the merge height of the minimum at ti.

1The choice of pairings in D(f ) follows the Elder Rule. In the case where both connected components are born

at the same height, we arbitrarily choose to continue the connected component that occurs ﬁrst in the domain.

EXTREMAL EVENT GRAPHS

9

Observe the minima for f are the maxima of −f and vice-versa. Additionally, the absolute
diﬀerence in heights between extrema of f remain the same in both f and −f . Hence, we can
study the prominence of maxima of f by studying the minima of −f . This follows from [4] which
discusses the symmetry between persistence diagrams computed from height ﬁltrations that are
ascending versus descending.

Deﬁnition 2.11 (Persistence of Extrema). Let f : C → R be a nicely tame function, and let
(b, d) ∈ D(f ). The persistence of (b, d) is the diﬀerence between the birth and death heights, d − b.
Suppose t is the domain coordinate such that f (t) = b and (t, f (t)) is the local minimum of f
representing the pair (b, d). We deﬁne the persistence of the extremum (t, f (t)), denoted persf (t),
as

persf (t) :=






max(f ) − f (t),
d − b,
pers−f (t),

if (t, f (t)) is the global minimum of f
if (t, f (t)) is a local (and not global) minimum of f
if (t, f (t)) is a local maximum of f.

See Figure 4 for an example of computing the persistence of local extrema.

Deﬁnition 2.12 (Node Life). Let f : C → R be a nicely tame function with a local extremum at
domain coordinate t. The node life of t is persf (t)/2.

We sometimes omit the subscript f from persf (t) when the function we are computing the node
life from is clear. Proposition 2 and Corollary 1 from [5] states that ϕf
ε (t) is the smallest interval
for which any nicely tame ε-perturbation of f is guaranteed to have at least one local extremum of
the same type as t, as long as ε is less than the node life.

To deﬁne the extremal event DAG, that will capture information about extrema of multiple time

series, we need a notion of comparability of local extrema.

3. Extremal Event DAG

Deﬁnition 3.1 (Comparability of Extrema). Let f, g : C → R be nicely tame functions. Let
tf , tg be local extrema of f and g respectively. Let ε > 0. We declare tf ≺ε tg if for every nicely
tame ε-perturbation of f and g there exists ε-perturbed extrema t(cid:48)
ε (tf ),
g ∈ ϕg
t(cid:48)

g. We say tf and tg are comparable at ε if all of the following hold.

g such that t(cid:48)

f and t(cid:48)

f ∈ ϕf

f < t(cid:48)
ε(tg), and t(cid:48)
(1) persf (tf ) > 2ε
(2) persg(tg) > 2ε
(3) tf ≺ε tg or tg ≺ε tf

If at least one of these conditions does not hold, then tf and tg are incomparable at ε.

Deﬁnition 3.1 relates order of extrema to possible ε-perturbations of functions. Using this deﬁ-

nition, we are ready to deﬁne the extremal event DAG.
Deﬁnition 3.2 (Extremal Event DAG). Let F = {fi : C → R}n
functions. For i ∈ [n], let ti
The extremal event DAG of F is the directed graph, DAG(F ) := (V, E, ωV , ωE), where

i=1 be a collection of nicely tame
ni be the domain coordinates for the local extrema of fi.

2 < · · · < ti

1 < ti

• V := {v(i, j) | i ∈ [n] and j ∈ [ni]}. In particular v(i, j) ∈ V corresponds to the extremum

of fi at ti
j.

weights.

• E := {(v(i, j), v(r, s)) | ti
j < tr
• ωV : V → R≥0 is deﬁned by the node life ωV (v(i, j)) := 1

s}.

2 persfi(ti

j). We call ωV the node

• ωE : E → R≥0 is deﬁned by ωE(v(i, j), v(r, s)) := inf{ε | ti

j and tr

s are incomparable}. We

call ωE the edge weights.

10

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

Figure 4. Top. A continuous function f and its persistence diagram from a sublevel
set ﬁltration. In this example, persf (t1) = max(f ) − f (t1), persf (t3) = f (t2) − f (t3),
and persf (t5) = f (t4) − f (t5). Bottom. −f and its persistence diagram from a
sublevel set ﬁltration. Now we can compute the persistence of the local maxmima
of f as persf (t4) = f (t4) − min(f ) and persf (t2) = f (t2) − f (t3).

We note that we use the terms vertices and nodes interchangeably throughout this paper. Given
ε > 0, we can easily recover ε-DAG(F ) from DAG(F ) where ε-DAG(F ) is deﬁned in [5]. Speciﬁcally,
ε-DAG(F ) is the subgraph of the DAG(F ) that consists of vertices and edges with a weight less
than or equal to ε. Hence, DAG(F ) is a stronger descriptor since it is not dependent on ε.

Computing the vertices and directed edges of the extremal event DAG can be done directly from
the graphs of the functions in F . Computing the weights requires more information. Expanding
upon earlier observation about node lives, we note that we choose to deﬁne the node weights as
the node lives for the following reason. Proposition 2 of [5] states that every nicely tame g ∈ Nε(f )
has a local extremum of the same type as t, say t(cid:48) ∈ ϕf
2 persf (t). Furthermore,
Proposition 1 of [5] states that for any two local extrema at (s, f (s)), and (t, f (t)) of f of the same
ε (t) ∩ ϕf
type, we have ϕf
2 persf (t), we guarantee a relative ordering of
extrema for ε-perturbations of f . If ε > 1
2 persf (t), Proposition 1 of [5] does not apply and we lose
the association between the extrema of the perturbed function of g ∈ Nε(f ) and the extremum of
f at t.

ε (s) = ∅. Hence, when ε < 1

ε (t) as long as ε < 1

EXTREMAL EVENT GRAPHS

11

3.1. Computing Edge Weights. In Appendix 8.1, we prove a few properties of ε-extremal in-
tervals that are needed to prove the condition for computing edge weights. We state a condition
for checking that requirement 3 of Deﬁnition 3.1 is met.
Theorem 3.3 (Computing Edge Weights). Let F = {fi : C → R}n
i=1 be a collection of nicely tame
functions where ti
ni are all the domain coordinates of the local extrema of fi. Let
DAG(F ) := (V, E, ωV , ωE) be the extremal event DAG of F . For all edges (v(i, j), v(c, d)) ∈ E, the
following statements hold
(1) If i = c, then

2 < · · · < ti

1 < ti

ωE(v(i, j), v(c, d)) = min{ωV (v(i, j)), ωV (v(c, d))}.

(2) If i (cid:54)= c, then

ωE(v(i, j), v(c, d)) = min{ωV (v(i, j)), ωV (v(c, d)), ε∗(ti

j, tc

d)},

where

ε∗(ti

j, tc

d) := inf{ε | ϕfi

ε (ti

j) ∩ ϕfc

ε (tc

d) (cid:54)= ∅}.

The proof of Theorem 3.3 is technical and involves analyzing several cases. We provide the proof

of Theorem 3.3 in Appendix 8.2.

3.2. Example of Extremal Event DAG Construction. We give an example of constructing
an extremal event DAG.

Example 3.4. We construct the extremal event DAG for sin(x) : [0, 2π] → R, cos(x) : [0, 2π] → R
as illustrated in Figure 5. First we compute the persistence diagram from a sublevel set ﬁltration
of sin(x), − sin(x), cos(x), and − cos(x). This computes the node lives of all local extrema in sin(x)
and cos(x). These node lives are the node weights in the extremal event DAG. Next we compute
edge weights between nodes based on Theorem 3.3(1).

For an illustration of this, consider the local extrema at x = 0 and x = π

2 of sin(x). The node
lives of these two local extrema are 0.5 and 1 respectively. The edge weight between the two
corresponding vertices in the extremal event DAG is the minimum of these two node lives: 0.5.

Computing the edge weights between two vertices corresponding to diﬀerent function is more
involved. We need to apply Theorem 3.3(2). To illustrate this, consider the local extrema at
x = π
2 of sin(x) and x = π of cos(x). Since sin(x) and cos(x) are translations of one another, the
ε-extremal intervals grow at the same rate for both sin(x) and cos(x). We know that ϕsin
ε (π/2)
ε (π) ﬁrst intersect at the half-way point of the domain coordinates, which is 3π
and ϕcos
4 . Using the
deﬁnition of the ε-extremal intervals we ﬁnd

sin(π/2) − ε = sin(3π/4) + ε

ε =

√

(2 −

1
4

2) ≈ 0.14

cos(π) + ε = cos(3π/4) − ε
1
4

(2 −

ε =

√

2) ≈ 0.14

The epsilon value computed is the inﬁmum ε for which ϕsin

ε (π) both contain 3π
4 .
Hence this is also the inﬁmum ε for which ϕsin
ε (π) (cid:54)= ∅. Since 0.14 is less than the node
life of either extremum, then by Theorem 3.3(2), the edge weight between the vertices corresponding

ε (π/2) and ϕcos

ε (π/2) ∩ ϕcos

12

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

to x = π/2 of sin(x) and x = π of cos(x) is 0.14. Applying a similar process to all edges, we get
the extremal event DAG.

(a) Functions.

(b) Extremal Event DAG.

Figure 5. Extremal Event DAG for sin(x) : [0, 2π] → R and cos(x) : [0, 2π] → R.
The vertices on the left and highlighted in blue represent the local extrema of sin(x)
while the vertices on the right and highlighted in green represent the local extrema
of cos(x). The vertices highlighted in blue from top to bottom correspond to the
local extrema of sin(x) in ascending order by domain coordinate. For example, the
top blue vertex with label and weight (min, .5) corresponds to the local extremum
(0, 0), the second blue vertex (max, 1) corresponds to the local extremum ( π
2 , 1), etc.
Similarly the green vertices correspond to the local extrema of cosine in ascending
order by domain coordinate. Directed edges indicate the ordering of the domain
coordinates of the local extrema. The vertex weights are the node lives of the
corresponding local extrema while the edge weights are computed using Theorem 3.3.

4. Extremal Event DAG Distance

In this section, we deﬁne a distance between extremal event DAGs representing diﬀerent col-
lections of time series, or datasets. In particular, we ﬁrst discuss the alignment of nodes between
diﬀerent collections of time series and then the alignment of edges. We call the result an extremal
event supergraph. The weights on the nodes and edges of the extremal event supergraph are deter-
mined by the weights on the two extremal event DAGs. The distance between the extremal event
DAGs is then computed from the weights on the extremal event supergraph.

4.1. Backbone Distance. From Figure 5, one can see that each time series is translated into an
ordered linear sequence of alternating minima and maxima. These linear sequences greatly simplify
the comparison between datasets assuming that there is a one-to-one correspondence between the
identiﬁcations of each of the time series in each dataset. For example, consider two gene expression
datasets under diﬀerent experimental conditions. In this case, each time series has a unique identity
corresponding to the gene that it represents. Our primary task in this section is to perform a
matching operation between the extrema of two time series with matching identities. To perform

sin(x)cos(x)minmax>>minmaxmax>minmax>>>>>>>>>>>>>>>>.14.84..5.84.14.14.14.5.5.5.5.511.5111111.5.5.5.51EXTREMAL EVENT GRAPHS

13

(a) Dataset 1

(b) Dataset 2

(c) Extremal Event DAG 1

(d) Extremal Event DAG 2

Figure 6. Time Series Data and Corresponding Extremal Event DAGs. We con-
sider two datasets consisting of two functions, 1
2 cos(x) over [0, 2π] with
some added noise. In Figure 6a and Figure 6b, we label the blue curve as “sine” and
green curve as “cosine”. Figure 6c is the extremal event DAG for Dataset 1 while
Figure 6d is extremal event DAG for Dataset 2.

2 sin(x) and 1

the matching, we use a modiﬁed version of the edit distance. Throughout this section, we refer to
Figure 6 for illustrations of deﬁnitions.

Deﬁnition 4.1 (Backbones). A backbone is a ﬁnite sequence x = (x1, x2, . . . , xn), where each xi is
a tuple xi = (si, wi) with si a string, and wi ∈ R≥0. The empty string is denoted by 0. The length
of x is denoted len(x), and is equal to the number of elements in the sequence (here, len(x) = n).
We call each xi a node and we denote the ﬁrst k terms of x by x[1 : k].

Remark 4.2 (Constructing Backbones from Nicely Tame Functions). In what follows, we construct
a backbone from a nicely tame function f : C → R by computing DAG({f }) = (V, E, ωV , ωE)

vvvvvvvvvvvv0.250.250.0160.250.0160.0160.0160.0160.0160.0160.250.250.0160.50.50.50.5vvvvvvvvvvvv0.250.25v0.0680.420.0680.0160.0160.250.420.0680.0160.0160.0680.0160.0160.25maxmax0.250.50.50.0160.0160.250.50.50.5minminminminmaxmaxmax0.016sinecosinevvvv0.50.50.0180.0180.5minminmaxmaxmax0.0180.5vvvvvvvvvvvvvvvv0.250.0420.0420.250.250.250.0420.0420.50.0420.250.250.250.0420.250.250.0420.0420.50.50.250.0180.0180.0180.50.50.0180.0180.018minminminmaxmaxmax0.25sinecosine0.250.0180.25vvvvvvvvvvvvvvvv0.0180.0080.0120.0680.420.250.0420.0180.0180.0420.0420.0180.0180.0420.0680.0180.0180.0420.0180.0180.0750.250.0680.0180.01814

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

and removing all edges and edge weights; the nodes are ordered by their corresponding domain
coordinates. Then, the data associated to each node v ∈ V is a string representing which type of
local maxima (min or max) along with the node weight ωV (v). This backbone for f is denoted as
B(f ). See Figure 7 for an example.

(a) Sine Backbone 1

(b) Sine Backbone 2

Figure 7. Extracting Sine Backbones from Extremal Event DAG 1 and Extremal
Event DAG 2. Figure 7a illustrates the backbone where each node corresponds to a
local extremum of the sine labeled curve from Dataset 1 (see Figure 6a). Mathemat-
ically, this backbone is the sequence (min, 0.25), (max, 0.5), (min, 0.5), (max, 0.016),
(min, 0.016), (max, 0.25). Figure 7b illustrates the backbone where each node cor-
responds to a local extremum of the sine labeled curve from Dataset 2 (see Fig-
ure 6b). Mathematically, this backbone is the sequence (min, 0.25), (max, 0.042),
(min, 0.042), (max, 0.5), (min, 0.5), (max, 0.25).

Remark 4.3 (Backbones as Sets). We consider functions over backbones to other spaces. For
these settings, we think of a backbone as an ordered multiset, x = {x1, x2, . . . , xn}, (i.e., repeated
elements are allowed) equipped with an injective index function, ιx : x → [n] where ιx(xi) = i. Let
0 := (0, 0). We also deﬁne (cid:101)x = {0} ∪ x, where 0 is the empty node. The function ι is not extended
to (cid:101)x.

Next we discuss alignments and how to compute a distance between two backbones using an

optimal alignment.

Deﬁnition 4.4 (Alignment). Let x = (x1, x2, . . . , xm) and y = (y1, y2, . . . , yn) be backbones. An
alignment is a totally ordered correspondence between (cid:101)x and (cid:101)y that does not repeat elements of x
or y and respects the labels (or strings) of the backbones. We say that the number of pairs in the
correspondence is the length of the alignment. In particular, we represent an alignment of length
k between x and y as a function α : [k] → (cid:101)x × (cid:101)y, where α(i) can be written as two coordinate
functions α(i) := (αx(i), αy(i)), such that

(1) No Null Alignments. The pair (0, 0) is not in the image of α, which we denote by im(α).

(2) Preserves Order of Backbones. The coordinate functions αx : [k] → (cid:101)x, αy : [k] → (cid:101)y
are partially monotone. The function αx is partially monotone if for every i, j ∈ [k] such
that αx(i) (cid:54)= 0 and αx(j) (cid:54)= 0, we have

ιx(αx(i)) < ιx(αx(j)) if and only if i < j.

An analogous deﬁnition applies to αy.

(3) No Misalignments. For each ((sx, wx), (sy, wy)) ∈ im(α), we either have equality in

strings sx = sy, or one of (sx, wx), (sy, wy) is equal to 0.

0.250.50.50.0160.0160.25minminminmaxmaxmax0.250.50.250.0420.0420.5minminminmaxmaxmaxEXTREMAL EVENT GRAPHS

15

(4) Restriction to Matching. Each element of x and y appears in the image of αx and αy
exactly once. That is, for each xi ∈ x, there exists exactly one j ∈ [k] for which αx(j) = xi.
The analogous statement holds for each yi ∈ y.

If α(i) = (αx(i), 0), we say that αx(i) is aligned with an insertion; similarly for α(i) = (0, αy(i)).
We denote the restriction of α to the ﬁrst h integers, [h] = {1, 2, . . . , h} ⊂ [k] as α[1 : h].

Notation 4.5 (Elements in im(α)). When we use the notation (x, y) ∈ im(α), we always assume
that x (cid:54)= 0 and y (cid:54)= 0. We also use notation (x, 0) ∈ im(α) and (0, y) ∈ im(α) to denote that x or
y is aligned with an insertion.

Note that the restriction of im(α) ∩ (x × y) is a partial matching (that is, each element in x × y,
if not aligned with an insertion, is aligned with a distinct element of the other backbone). We call
any pair (x, y) ∈ im(α) ∩ (x × y) a nontrivial match. An example of two diﬀerent alignments of
the sine backbones shown in Figure 7 is given in Figure 8. Figure 8a is aligned without insertions,
while Figure 8b has two insertions in each of the backbones. Notice that the insertions occur at
the small noisy extrema in each of the time series.

(a) Alignment 1

(b) Alignment 2

Figure 8. Two Possible Alignments of Sine Backbones. We consider the backbones
shown in Figure 7. Call these x and y respectively. The top row consists of nodes
from x while the bottom row consists of nodes from y. Figure 8a gives an alignment,
α1 : {1, 2, . . . , 6} → (cid:101)x × (cid:101)y of the two backbones where α1(i) = (xi, yi). Figure 8b
gives an alignment α2 : {1, 2, . . . , 8} → (cid:101)x × (cid:101)y where α2(1) = (x1, y1), α2(2) = (0, y2),
α2(3) = (0, y3), α2(4) = (x2, y4), α2(5) = (x3, y5), α2(6) = (x4, 0), α2(7) = (x5, 0),
and α2(8) = (x6, y6).

Deﬁnition 4.6 (Cost of Alignment). Let x and y be backbones and α : [k] → (cid:101)x×(cid:101)y be an alignment
of length k. The cost of α is deﬁned as

cost(α) :=

(cid:88)

|wx − wy|,

(x,y),(x,0),(0,y)∈im(α)

where x = (sx, wx) and y = (sy, wy). We deﬁne the cost of the partial alignment cx,y(i, j) to be
the minimum cost of aligning x[1 : i] with y[1 : j], that is,

cx,y(i, j) := min{cost(α) | α is an alignment of x[1 : i] and y[1 : j]}.

0.250.50.250.0420.0420.5minminminmaxmaxmax0.25maxmax0.250.0160.50.5min0.016minminmax0.25max0.250.50.250.0420.0420.5minminminmaxmaxmax0.25max0.0160.0160.25minmaxmax0.25000.50.5min0min0max000016

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

Referring again to Figure 8, we compute that the alignment in Figure 8b has a lower cost, 0.116,

than that in Figure 8a, 0.932.

Deﬁnition 4.7 (Optimal Alignment). Let x = (x1, x2, . . . , xm) and y = (y1, y2, . . . , yn) be back-
bones. We call an alignment α : [k] → (cid:101)x × (cid:101)y optimal if cost(α) = cx,y(m, n).

An optimal alignment minimizes cost. We note that there could be multiple alignments that

minimize cost and so an optimal alignment is not necessarily unique.

We deﬁne the distance between two backbones x and y using an optimal alignment. To do this,

we need to identify nontrivial matches, i.e., those alignment pairs that do not involve insertions.

Deﬁnition 4.8 (Backbone Distance). The backbone distance between backbones x and y is deﬁned
as

(1)

dB(x, y) = inf
α





(cid:88)

|wx − wy| +

(cid:88)

wx +

(cid:88)



wy



(x,y)∈im(α)

(x,0)∈im(α)

(0,y)∈im(α)

where α ranges over all alignments between x and y.

The backbone distance ﬁnds the best alignment between x and y, then deﬁnes the distance to
be the L1 norm between a vector consisting of the node weights in (cid:101)x and a vector consisting of
the matching node weights in (cid:101)y. The ﬁrst term of Equation 1 accounts for the cost of the nodes
in x that are aligned with nodes in y, the second term accounts for the cost of the nodes in x that
are aligned with an insertion, and the third term accounts for the cost of the nodes in y that are
aligned with an insertion. We show that this distance is in fact a metric in Appendix 8.3.

4.2. Extremal Event DAG Distance. Using the backbone distance, we deﬁne a distance be-
tween two extremal event DAGs, D and D(cid:48), constructed from comparable datasets. In other words,
the number and identity of the time series are the same between the two datasets so that the choice
of which backbones to align is clear. Once the alignments have been computed, we construct a
supergraph based on D and D(cid:48) where there is a vertex for each node pair from each alignment. We
add a directed edge between two vertices if the edge exists between the two vertices in either D or
D(cid:48). After we construct the supergraph, we impose two weight functions on the vertices and nodes
given by the weights of the nodes and edges in D and D(cid:48) respectively. The diﬀerence between these
weight vectors is the extremal event DAG distance between D and D(cid:48).

Deﬁnition 4.9 (Extremal Event Supergraph). Let D = (V, E, ωV , ωE) and D(cid:48) = (V (cid:48), E(cid:48), ω(cid:48)
E)
be two extremal event DAGs with n pairs of aligned backbones. Let x1, x2, . . . , xn be the backbones
of D, and y1, y2, . . . , yn be the backbones of D(cid:48) and, for each i ∈ [n], let α(i) : [ki] → (cid:101)xi × (cid:101)yi be the
corresponding alignments where ki = len(αi). Just as we expanded α to two coordinate functions in
Deﬁnition 4.4, α(i) can be expanded into two coordinate functions α(i) := (αxi, αyi). The extremal
i=1 of D and D(cid:48) is a doubly weighted directed
event supergraph determined by the alignments {α(i)}n
graph (Vα, Eα, ωα, ω(cid:48)

V , ω(cid:48)

α), where

• Vα := {v(i, j) | i ∈ [n], j ∈ [ki]}. That is, the vertices of Vα are in one-to-one correspondence

with each element of every alignment. Note V ∪ V (cid:48) ⊂ Vα.

• An ordered pair of vertices (v(i, j), v(k, l)) ∈ Vα × Vα is a directed edge in Eα if and only if

either one or both of the following is true

◦ (αxi(j), αxk (l)) ∈ E
◦ (αyi(j), αyk (l)) ∈ E(cid:48).

Note E ∪ E(cid:48) ⊂ Eα.

• The weight function ωα : Vα ∪ Eα → R≥0 is deﬁned by

EXTREMAL EVENT GRAPHS

17

ωα(x) =




ωV (v(i, j)),
ωE(v(i, j), v(k, l)), x = (v(i, j), v(k, l)) ∈ E ⊂ Eα

otherwise.
0

x = v(i, j) ∈ V ⊂ Vα

• The weight function ω(cid:48)

α : Vα ∪ Eα → R≥0 is deﬁned by

ω(cid:48)

α(x) =




ω(cid:48)
V (v((i, j)),
ω(cid:48)
E(v(i, j), v(k, l)), x = (v(i, j), v(k, l)) ∈ E(cid:48) ⊂ Eα

otherwise.
0

x = v(i, j) ∈ V (cid:48) ⊂ Vα

We give an example of an extremal event supergraph and its weights in Figure 9.
We deﬁne the extremal event DAG distance to be the sum of absolute diﬀerences in node and
edge weights from the extremal event supergraph determined by the best alignment we can easily
compute.

Deﬁnition 4.10 (Extremal Event DAG Distance). D and D(cid:48) be two extremal event DAGs where
x1, x2, . . . xn are the backbones of D and y1, y2, . . . , yn are the backbones of D(cid:48). The extremal
event DAG distance is deﬁned as:

dED(D, D(cid:48)) =

n
(cid:88)

i=1

dB(xi, yi) + inf
{αi}n

i=1

(cid:88)

(u,v)∈Eα

|ωα

D(u, v) − ωα

D(cid:48)(u, v)|.

where {αi}n

i=1 ranges over all sets of optimal alignments between the backbones.

We deﬁne extremal event DAG distance using optimal alignments between backbones because
of its computability. As we show in Section 9, we use modiﬁed edit distance alignment algorithms
to eﬃciently compute backbone alignments.

An open conjecture is that the sum of diﬀerences of edge weights is minimized only under an

optimal alignment; that is,

dED(D, D(cid:48)) = inf
{α}n

i=1





(cid:88)

u∈Vα

|ωα

D(u) − ωα

D(cid:48)(v)| +

(cid:88)

(u,v)∈Eα



|ωα

D(u, v) − ωα

D(cid:48)(u, v)|



where {αi}n

i=1 ranges over all sets of alignments between the backbones.

If this conjecture is true, then we can prove the triangle inequality for the extremal event DAG
distance using the same composition of alignments that we used for showing the triangle inequality
holds for the backbone metric. If the conjecture is not true, then it is possible that the triangle
inequality does not hold for the extremal event DAG distance. For the biological applications
we have in mind, the key property that we desire is from a distance is stability, which is the
property that small changes in two datasets does not cause a large jump in the distance between
the associated extremal event DAGs. We show this property holds in Section 5 when the functions
are “close” to one another.

5. Stability of Extremal Event DAGs

In this section, we prove a Lipschitz stability result: that small changes in functions that are
suﬃciently close result in small distances between the corresponding extremal event DAGs. Our
results are similar in ﬂavor to stability for persistence diagrams [13].

18

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

Figure 9. Extremal event supergraph of (extremal event) DAG 1 and DAG 2 from
Figure 6. The nodes on the left represent to the optimal alignment between the sine
backbones in DAG 1 and DAG 2. The nodes on the right represent to the optimal
alignment between the cosine backbones in DAG 1 and DAG 2. The node weights
are listed on the node where the upper node weight comes from the weight function
for DAG 1 and the lower node weight comes from the weight function for DAG 2.
The blue node in the extremal event supergraph comes from aligning the blue node
in DAG 2 with an insertion. The green node in the extremal event supergraph comes
from aligning the green nodes in DAG 1 and DAG 2. For readability, we present
only one edge weight pair, associated to the bold edge. The edge weight on the left
is equal to zero since the blue node in DAG 2 is aligned with an insertion. The edge
weight on the right is equal to 0.042 which is the edge weight between the blue and
green node in DAG 2.

vvvv0.50.018minminmaxmaxmax0.50.50.500.01800.50.5vvvvvvvvvvvvvvvvvvvvv0.250.0420.0420.50.50.0160.25000.50.50minminminmaxmaxmaxvvvvvvvvvvvvvvvv0.0160min0.250.25max(0,0.042)vvvvvvvvvvvv0.250.250.0160.250.0160.0160.0160.0160.0160.0160.250.250.0160.50.50.50.5vvvvvvvvvvvv0.250.25v0.0680.420.0680.0160.0160.250.420.0680.0160.0160.0680.0160.0160.25maxmax0.250.50.50.0160.0160.250.50.50.5minminminminmaxmaxmax0.016sinecosinevvvv0.50.50.0180.0180.5minminmaxmaxmax0.0180.5vvvvvvvvvvvvvvvv0.250.0420.0420.250.250.250.0420.0420.50.0420.250.250.250.0420.250.250.0420.0420.50.50.250.0180.0180.0180.50.50.0180.0180.018minminminmaxmaxmax0.25sinecosine0.250.0180.25vvvvvvvvvvvvvvvv0.0180.0080.0120.0680.420.250.0420.0180.0180.0420.0420.0180.0180.0420.0680.0180.0180.0420.0180.0180.0750.250.0680.0180.0180.042DAG 1DAG 2Extremal Event Supergraph  of DAG 1 and DAG 2EXTREMAL EVENT GRAPHS

19

5.1. Stability in Backbone Distance. We begin by proving stability results for the backbone
distance. The main result of this section is Corollary 5.13, which states the backbone distance
between backbones of two nicely tame real valued functions from a closed interval is bounded by a
constant times the L∞ distance between the two functions. That is,

dB(B(f ), B(f (cid:48))) ≤ K (cid:13)

(cid:13)f − f (cid:48)(cid:13)

(cid:13)∞ .

To get there, we show that the maximum diﬀerence in node weights arising from an optimal
alignment is bounded by the L∞ distance of the two corresponding functions (Theorem 5.12). This
leads us to comparing the backbone distance to the following distance that looks at the maximum
distance between aligned node weights that arises from an optimal backbone alignment.

Deﬁnition 5.1 (Backbone Inﬁnity Distance). Let x, y be backbones. We deﬁne the backbone
inﬁnity distance between x and y as

where α ranges over all alignments of x and y.

dB∞(x, y) = inf
α

max |ωx(αx(i)) − ωy(αy(i))|

In Appendix 8.4, we prove the backbone inﬁnity distance is a metric. The proof is a simpliﬁed

version of the proof that the backbone distance is a metric (Proposition 8.7).

5.1.1. Relationship Between Local Extrema, Points in Persistence Diagrams, and Backbone Nodes.
We prove backbone distance stability by moving between concepts of local extrema of functions,
points in persistence diagrams, and backbone nodes. We describe the relationship between these
three concepts next.

Let f : C → R be a nicely tame function and (t, f (t)) be a local minimum of f that does not
represent the essential component in D(f ). Recall from Section 2.6 that at a height of f (t) in the
sublevel set ﬁltration, a new connected component is born. The death of this connected component
happens at the height of a local maximum denoted as ζf (t) (recall Deﬁnition 2.10). This implies
existence of a point (f (t), ζf (t)) ∈ D(f ) in the persistence diagram.. We then compute the node
life, 1
2 persf (t)) ∈ B(f ) is a backbone
node. In summary, a local minimum (t, f (t)) corresponds to a point in the persistence diagram
(f (t), ζf (t)) ∈ D(f ), and a vertex in a backbone (min, 1

2 (ζf (t) − f (t)). This shows that the node (min, 1

2 persf (t) = 1

2 persf (t)) ∈ B(f ).

Now suppose t represents the essential component in D(f ), which means that t is a global
2 persf (t)) ∈ B(f ) where

minimum of f . Then, (t, f (t)) corresponds to (f (t), ∞) ∈ D(f ) and (min, 1
2 persf (t) = 1
1

2 (max(f ) − f (t)).

There is the same type of correspondence for local maxima of f by applying the same process
to −f . All the local maxima of f become local minima of −f . To make the correspondence
between nodes in backbones, extrema, and points in persistence diagrams more precise, we deﬁne
the following.

Deﬁnition 5.2 (Truncated Persistence Points). Let f : C → R be a nicely tame function. Let
(t, f (t)) be a local minimum of f . The point (f (t), ζf (t)) is the truncated persistence point of
(t, f (t)).

We often refer to the truncated persistence points as persistence points. We note that if (t, f (t))
is a local maximum of f , then we declare the point (−f (t), ζ−f (t)) as the persistence point of
(t, f (t)). Because of the correspondence between extrema, persistence points, and backbone nodes,
we discuss pairings of extrema or persistence points to get aligned pairs in backbone alignments.

Remark 5.3 (Persistence Diagram Containing Diagonal). Persistence diagrams are often deﬁned as
in Deﬁnition 2.8 along with a union of all points on the diagonal ∆ = {(x, x) ∈ R2} counted with
inﬁnite multiplicity. The addition of the diagonal is useful for deﬁning distances between persistence
diagrams. For the remainder of this section, we assume that persistence diagrams contain all points

20

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

(a) f

(b) D(f )

(c) B(f )

Figure 10. Moving Between Local Minima, Persistence Diagrams, and Back-
bone Nodes. The local minimum, (s, f (s)) in light blue corresponds to the point
(f (s), f (r)) ∈ D(f ) and (min, 1

2 persf (s)) ∈ B(f ).

on the diagonal counted with inﬁnite multiplicity. This representation is useful for constructing
alignments between backbones.

5.1.2. dB∞ is stable. A key result that we use is the Box Lemma, that is proved in [13] to prove
stability for persistence diagrams.
Lemma 5.4 (Box Lemma ([13])). Let X be a topological space, f, g : X → R be tame functions
and let ε = (cid:107)f − g(cid:107)∞. For a < b < c < d, let R = [a, b] × [c, d] be a box in the extended plane, R2
,
and Rε = [a + ε, b − ε] × [c + ε, d − ε] be the box obtained by shrinking R by ε on all sides. Then,
|D(f ) ∩ Rε| ≤ |D(g) ∩ R| .

The next result is similar in ﬂavor to the Easy Bijection Lemma from [13]. We ﬁrst prove stability

for the backbone inﬁnity distance in a special case. The result will depend on two constants.
Deﬁnition 5.5 (Constants δmin, δmax ). Let X be a topological space and f : X → R be a tame
function. Deﬁne δmin to be half of the smallest distance between two distinct oﬀ-diagonal points,
or a point in D(f ) and a point on the diagonal, that is,

δmin :=

1
2

min{(cid:107)p − q(cid:107)∞ | p ∈ D(f ) \ ∆, q ∈ D(f ), p (cid:54)= q}.

The constant δmax is deﬁned analogously using D(−f ).

Next, we note a relationship between Deﬁnition 5.5 and the minimum node life of extrema of f .
Lemma 5.6 (Minimum of Node Lives is Bounded Below by δmin). Let f : C → R be a nicely
tame function. Let {ti}n
i=1 be the domain coordinates for local minima of f . Deﬁne δ to be half the
minimum of the node lives of ti, that is,

Then δmin ≤ δ.

δ :=

1
2

min{persf (ti)}n

i=1.

pqrff(q)f(s)f(r)∞(f(s),f(r))stminminmaxmaxmax12persf(p)12persf(q)12persf(r)12persf(s)12persf(t)f(t)f(p)pqrff(q)f(s)f(r)∞(f(s),f(r))stminminmaxmaxmax12persf(p)12persf(q)12persf(r)12persf(s)12persf(t)f(t)f(p)pqrff(q)f(s)f(r)∞(f(s),f(r))stminminmaxmaxmax12persf(p)12persf(q)12persf(r)12persf(s)12persf(t)f(t)f(p)EXTREMAL EVENT GRAPHS

21

Proof. Let t ∈ {ti}n
orthogonal projection of (f (t), ζf (t)) onto the diagonal. In particular,
2 persf (t) + f (t), 1
( 1

2 persf (t) = δ. Observe the point ( 1

i=1 such that 1

2 persf (t) + f (t)) is the closest point on the diagonal to (f (t), ζf (t)). Notice,

2 persf (t), 1

2 persf (t)) is the

persf (t) + f (t))| = |ζf (t) − (

ζf (t) −

1
2

f (t) + f (t))|

|ζf (t) − (

Furthermore,

|f (t) − (

1
2

1
2

1
2
1
2

1
2
1
2

= |

ζf (t) −

f (t)|

=

persf (t).

= |

f (t) −

ζf (t)|

=

persf (t).

1
2
1
2

1
2
1
2

persf (t) + f (t))| = |f (t) − (

ζf (t) −

1
2

f (t) + f (t))|

Therefore,

(cid:13)
(cid:13)
(cid:13)
(cid:13)

(f (t), ζf (t)) − (

1
2

Additionally, since for all ti ∈ {ti}n
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(f (ti), ζf (ti)) − (

persf (t) + f (t),

1
2
i=1 where ti (cid:54)= t, we have 1

(cid:13)
(cid:13)
persf (t) + f (t))
(cid:13)
(cid:13)∞

=

1
2

persf (t) = δ.

2 persf (ti) ≥ δ, it must be the case that

1
2

persf (ti) + f (ti),

1
2

(cid:13)
(cid:13)
persf (ti) + f (ti))
(cid:13)
(cid:13)∞

≥ δ.

This implies that half the minimum distance between a point p ∈ D(f ) \ ∆ and a point on the
diagonal is equal to δ, that is,

1
2

min{(cid:107)p − q(cid:107)∞ | p ∈ D(f ) \ ∆, q ∈ ∆} = δ.

Lastly, since

{(cid:107)p − q(cid:107)∞ | p ∈ D(f ) \ ∆, q ∈ ∆} ⊂ {(cid:107)p − q(cid:107)∞ | p ∈ D(f ) \ ∆, q ∈ D(f ), p (cid:54)= q}

we conclude δmin ≤ δ.

(cid:3)

Using the same proof but with −f and D(−f ), we ﬁnd δmax ≤ δ. We use the two constants δmin

and δmax to determine when functions are “close”.
Deﬁnition 5.7 (Very Close). Let f : C → R be a nicely tame function. Let δf = min{δmin, δmax}.
A nicely tame function f (cid:48) : C → R is very close to f if (cid:107)f − f (cid:48)(cid:107)∞ < δf .

Next we prove an analogue of the Easy Bijection Lemma [13] for backbones. We start by
constructing an alignment between two backbones arising from nicely tame functions f and f (cid:48)
where f (cid:48) is very close to f . Figure 11 shows an example on how to construct the direct alignment
between very close functions.

Construction 5.8 (Direct Alignment). Let f, f (cid:48) : C → R be nicely tame functions such that f (cid:48)
is very close to f . Let ε = (cid:107)f − f (cid:48)(cid:107)∞. Note, that since f, f (cid:48) are very close, we have ε < δf . The
direct alignment construction consists of two steps:

(1) Pairing nodes in B(f ) with B(f (cid:48)). Recall that each node in B(f ) and B(f (cid:48)) corresponds to
a local extremum of f and f (cid:48), respectively. We begin by pairing local minima of f with local
minima of f (cid:48). By deﬁnition of persistence diagrams, there is a one-to-one correspondence

22

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

between the local minima of f and the points in D(f ). Thus, we can pair local minima of
f and f (cid:48) by pairing oﬀ diagonal points in D(f ) and D(f (cid:48)), respectively.

Let p = (p1, p2) ∈ D(f ) \ ∆. We describe what point in D(f (cid:48)) is paired with p. Since

p ∈ (cid:3)ε(p), the Box Lemma tells us that the multiplicity µ(p) of p satisﬁes
(cid:12)D(f (cid:48)) ∩ (cid:3)ε(p)(cid:12)

(cid:12) ≤ |D(f ) ∩ (cid:3)2ε(p)| .

µ(p) ≤ (cid:12)

By deﬁnition of δf and the assumption ε < δf , we know that p is the only point contained
in the set D(f ) ∩ (cid:3)2ε(p). Therefore, |D(f (cid:48)) ∩ (cid:3)ε(p)| = µ(p). Furthermore, since p ∈
D(f ) ∩ (cid:3)ε(p), there is the same number of points, with multiplicity, in D(f (cid:48)) ∩ (cid:3)ε(p) and
in D(f ) ∩ (cid:3)ε(p).

We explain how to deﬁne a bijection by pairing the points in the squares D(f ) ∩ (cid:3)ε(p)
and D(f (cid:48)) ∩ (cid:3)ε(p). Let n = µ(p) and let {ti}n
i=1 be the set of the domain coordinates of the
local minima of f for which f (ti) = p1. Let q = (q1, q2) ∈ D(f (cid:48)) ∩ (cid:3)ε(p). Observe q1 = f (cid:48)(t)
for some local minimum (t, f (cid:48)(t)) of f (cid:48). Because p, q ∈ (cid:3)ε(p), we have (cid:107)p − q(cid:107)∞ ≤ ε < δf .
In particular,

|p1 − q1| = |f (ti) − f (cid:48)(t)| < δf , for all i ∈ [n].

This implies that

f (ti) − δf < f (cid:48)(t) < f (ti) + δf , for all i ∈ [n].

This inequality, the fact that δf ≤ δmin, and f (ti) = p1 for all i ∈ [n] implies

t ∈ A := (f − δf )−1(−∞, p1 + δf ).
2 min{persf (ti)}n

By Lemma 5.6, δf ≤ 1
i=1. Applying Proposition 1 of [5], we ﬁnd A is a
disjoint union of intervals and each contains exactly one ti, i.e., A = (cid:83)n
i ∈
{ti}n
i )) with
(t, f (cid:48)(t)). Iterating this process for all points q ∈ D(f (cid:48))∩(cid:3)ε(p) results in a bijection between
points in the squares D(f ) ∩ (cid:3)ε(p) and D(f (cid:48)) ∩ (cid:3)ε(p).

i ). For our alignment, we pair the local minima (t∗

i=1 ϕδf (ti). Let t∗
i , f (t∗

i=1 such that t ∈ ϕδf (t∗

Iterating the above procedure for all points p ∈ D(f ) \ ∆, we pair all local minima of f
with local minima of f (cid:48). All remaining local minima of f (cid:48) are paired with an empty node.
The order of the alignment is given by the domain coordinates of f (cid:48).

What remains are the local maxima of f and f (cid:48). To pair these extrema, we apply the

same exact process to minima of −f and −f (cid:48) since they are local maxima of f and f (cid:48).
(2) Indexing the pairs so that order of the backbones for B(f ) and B(f (cid:48)) are preserved. Let
x = B(f ) and x(cid:48) = B(f (cid:48)). Since extrema in f (and f (cid:48)) are in one-to-one correspondence
with nodes in x (and x(cid:48), respectively), we know that each pair of aligned extrema in Step (1)
correspond to a pair of nodes in (cid:101)x × (cid:101)x(cid:48). To construct the direct alignment α : [k] → (cid:101)x × (cid:101)x(cid:48),
we order the pairs found in Step (1) based on the order of the domain coordinates of the
local extrema of f (cid:48). It follows that k is the number of local extrema of f (cid:48). Let (t(cid:48)
i))
be the ith extremum based on order of domain coordinates of f (cid:48), and assume, without loss
of generality, that this extremum is a local minimum. Then, α(i) = (αx(i), αx(cid:48)(i)) is given
by αx(cid:48)(i) = (min, 1

i)) and αx(i) is the paired node from Step (1).

i, f (cid:48)(t(cid:48)

2 persf (cid:48)(t(cid:48)

Lemma 5.9 (Direct Alignment is an Alignment). Let f, f (cid:48) : C → R be nicely tame functions such
that f (cid:48) is very close to f . Let x = B(f ) and x(cid:48) = B(f (cid:48)). The direct alignment, α : [k] → (cid:101)x × (cid:101)x(cid:48)
constructed in Construction 5.8 is an alignment.

Proof. We show Deﬁnition 4.4 holds. By Construction 5.8, we immediately see we have no null
alignments, misalignments, and have a restriction to matching. Hence, Property (1), Property (3),
and Property (4) hold. What remains is showing the alignment preserves order of backbones.

Since the nodes of x(cid:48) are ordered by domain coordinates of local extrema of f (cid:48), the alignment
α preserves the order of nodes of x(cid:48). We now show that the alignment α also preserves the order

EXTREMAL EVENT GRAPHS

23

of nodes in B(f ). Consider nodes αx(i), αx(j) ∈ x = B(f ) such that i < j and αx(i), αx(j)
map to local extrema (t, f (t)) and (s, f (s)), respectively. Trivially, t, s are contained in ϕδf (t)
and ϕδf (s), respectively. Since (cid:107)f − f (cid:48)(cid:107)∞ < δf ≤ min{ 1
i=1 by Lemma 5.6, then if t and
s are not adjacent, ϕδf (t) ∩ ϕδf (s) = ∅ by Proposition 1 of [5]. Otherwise t and s are adjacent
and by Lemma 8.2, Statement (3), we have t /∈ ϕδf (s) and s /∈ ϕδf (t). Either way, we ﬁnd
ι(αx(cid:48)(i)) < ι(αx(cid:48)(j)) implies ι(αx(i)) < ι(αx(j)). The same argument in reverse can be used to
show that if i < j, then ι(αx(i)) < ι(αx(j)). Therefore, the order of the backbones B(f ) and B(f (cid:48))
(cid:3)
is preserved and we have constructed an alignment between B(f ) and B(f (cid:48)).

2 persf (ti)}n

Next, we prove a bound on the absolute diﬀerence between aligned weights in the direct align-

ment.

Lemma 5.10 (Bound in Diﬀerence in Node Weights in Direct Alignment). Let f, f (cid:48) : C → R
be nicely tame functions such that f (cid:48) is very close to f . Let ε := (cid:107)f − f (cid:48)(cid:107)∞. Let x = B(f ),
x(cid:48) = B(f (cid:48)), and α : [k] → (cid:101)x × (cid:101)x(cid:48) be the direct alignment as deﬁned in Construction 5.8. Then, the
absolute diﬀerence in weights between aligned nodes is bounded by ε; that is, for all (x, x(cid:48)) ∈ im(α),
|wx − wx(cid:48)| ≤ ε.

Proof. Let (x, x(cid:48)) ∈ im(α). Either both represent extrema from f and f (cid:48), or the node x(cid:48) is the
empty node.

First, assume that both nodes represent extrema. For this proof, we assume they are minima and
note an analogous argument holds for maxima. Let (t, f (t)) and (t(cid:48), f (cid:48)(t(cid:48))) be the local minima
corresponding to nodes x and x(cid:48), respectively. Either both of these extrema do not represent the
essential component in D(f ) and D(f (cid:48)) or at least one of them does. Suppose neither represents
the essential component. Consider the persistence points p = (f (t), ζf (t)), q = (f (cid:48)(t(cid:48)), ζf (cid:48)(t(cid:48))) in
D(f ) \ ∆ and D(f (cid:48)) \ ∆ respectively. From Construction 5.8, we know that both p, q ∈ (cid:3)ε(p). This
implies (cid:107)p − q(cid:107)∞ ≤ ε. Hence,

|wx − wx(cid:48)| =

=

=

≤

≤

1
2
1
2
1
2
1
2
ε
2

|persf (t) − persf (cid:48)(t(cid:48))|

|(ζf (t) − f (t)) − (ζf (cid:48)(t(cid:48)) − f (cid:48)(t(cid:48)))|

|(ζf (t) − ζf (cid:48)(t(cid:48))) + (f (cid:48)(t(cid:48)) − f (t))|

|f (cid:48)(t(cid:48)) − f (t)|

1
2

|ζf (t) − ζf (cid:48)(t(cid:48))| +

+

ε
2

= ε.

Next, consider the case at least one of (t, f (cid:48)(t)) or (t(cid:48), f (cid:48)(t(cid:48))) represents the essential component.
By the Box Lemma, we can infer that both points have to represent the essential component. Then
we know these points are global minima of f and f (cid:48). Since (f (t), ∞) and (f (cid:48)(t(cid:48)), ∞) are both
contained in the square of radius ε centered at (f (t), ∞) in the extended plane, |f (t) − f (cid:48)(t(cid:48))| ≤ ε.
Additionally, by Construction 5.8 we know that tmax, a global maximum of f , is paired with t(cid:48)
max, a
global maximum of f (cid:48) such that t(cid:48)
max)| ≤ ε. Applying
the same computation as above, we see |wx − wx(cid:48)| ≤ ε.

max ∈ ϕδf (tmax). This implies |f (tmax) − f (cid:48)(t(cid:48)

Lastly, consider the case (t(cid:48), f (cid:48)(t(cid:48))) is paired with an empty node. Consider the point (f (cid:48)(t(cid:48)), ζf (cid:48)(t(cid:48))) ∈

D(f (cid:48)). The Box Lemma implies (cid:3)ε((f (cid:48)(t(cid:48)), ζf (cid:48)(t(cid:48)))) must contain at least one point from D(f ). By
assumption (t(cid:48), f (cid:48)(t(cid:48))) is paired with an empty node, and so (cid:3)ε((f (cid:48)(t(cid:48)), ζf (cid:48)(t(cid:48))) must contain a point
on the diagonal. Therefore, (f (cid:48)(t(cid:48)), ζf (cid:48)(t(cid:48))) is within an L∞ distance of ε from a point on the di-
agonal. Because the point ( 1
2 persf (cid:48)(t(cid:48)) + f (t(cid:48))) is the orthogonal projection of
(f (cid:48)(t(cid:48)), ζf (cid:48)(t(cid:48))) onto the diagonal, it is the closest point on the diagonal in R2 to (f (cid:48)(t(cid:48)), ζf (cid:48)(t(cid:48))).

2 persf (cid:48)(t(cid:48)) + f (t(cid:48)), 1

24

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

(a) f, f (cid:48)

(b) D(f ), D(f (cid:48))

(c) Direct Alignment between B(f ) and B(f (cid:48))

Figure 11. Construction of Direct Alignment. In Figure 11a, f is the black func-
tion while f (cid:48) is the pink function. The black labeled ticks denote the domain co-
ordinates of the local extrema of f and the pink labeled ticks denote the domain
coordinates of the local extrema of f (cid:48). The ε-extremal intervals for the local extrema
of f are illustrated. Since any two points in D(f ) where one is not a diagonal point,
have a distance of at least ε, and f (cid:48) ∈ Nε(f ), we have f (cid:48) is very close to f . Applying
the Direct Alignment Lemma, we get pairings of points in D(f ) and D(f (cid:48)) as shown
in Figure 11b. From the pairings in D(f ) and D(f (cid:48)), we get pairings of nodes with
the label “min” that preserve order. The preservation of order comes from how the
ε-extremal intervals for minima of f are disjoint. We apply an analogous process to
pair nodes with the label “max”. The alignment that is constructed in the Direct
Alignment Lemma for f and f (cid:48) is shown in Figure 11c.

Therefore

(2)

(cid:13)
(cid:13)
(f (cid:48)(t(cid:48)), ζf (cid:48)(t(cid:48))) − (
(cid:13)
(cid:13)

1
2

persf (cid:48)(t(cid:48)) + f (t(cid:48)),

1
2

(cid:13)
(cid:13)
persf (cid:48)(t(cid:48)) + f (t(cid:48)))
(cid:13)
(cid:13)∞

≤ ε.

pqrff(q)f(s)f(r)∞stminmaxmax12persf(p)12persf(q)12persf(r)f(t)f(p)(((())))φε(p)φε(q)φε(r)φε(s)φε(t)f′ ε}εD(f)D(f′ )r′ s′ q′ p′ t′ u′ v′ f′ (u′ )f(s)f′ (s′ )f(q)f′ (q′ )max12persf′ (p′ )min12persf′ (q′ )max12persf′ (r′ )min12persf′ (u′ )max12persf′ (v′ )min12persf(s)min12persf′ (s′ )max12persf(t)max12persf′ (t′ )f′ (v′ )f(r)f′ (r′ )(a)(b)}pqrff(q)f(s)f(r)∞stminmaxmax12persf(p)12persf(q)12persf(r)f(t)f(p)(((())))φε(p)φε(q)φε(r)φε(s)φε(t)f′ ε}εD(f)D(f′ )r′ s′ q′ p′ t′ u′ v′ f′ (u′ )f(s)f′ (s′ )f(q)f′ (q′ )max12persf′ (p′ )min12persf′ (q′ )max12persf′ (r′ )min12persf′ (u′ )max12persf′ (v′ )min12persf(s)min12persf′ (s′ )max12persf(t)max12persf′ (t′ )f′ (v′ )f(r)f′ (r′ )(a)(b)minmaxmax12persf(p)12persf(q)12persf(r)max12persf′ (p′ )min12persf′ (q′ )max12persf′ (r′ )min12persf′ (u′ )max12persf′ (v′ )min12persf(s)min12persf′ (s′ )max12persf(t)max12persf′ (t′ )0000EXTREMAL EVENT GRAPHS

25

Comparing the x-coordinates of pair of points in (2), we ﬁnd ( 1
comparing the y-coordinates we ﬁnd ζf (cid:48)(t(cid:48)) − ( 1

2 persf (cid:48)(t(cid:48)) + f (t(cid:48))) ≤ ε. Observe

2 persf (cid:48)(t(cid:48)) + f (t(cid:48))) − f (cid:48)(t(cid:48)) ≤ ε and

(

1
2

persf (cid:48)(t(cid:48)) + f (t(cid:48))) − f (cid:48)(t(cid:48)) = ζf (cid:48)(t(cid:48)) − (

1
2

persf (cid:48)(t(cid:48)) + f (t(cid:48))) =

1
2

persf (t).

We ﬁnd 1

2 persf (cid:48)(t(cid:48)) ≤ ε.

We conclude that for all paired extrema,

|wx − wx(cid:48)| ≤ ε.

(cid:3)

We can now prove local stability for the backbone inﬁnity distance.

Lemma 5.11 (Local Backbone Inﬁnity Stability). Let f, f (cid:48) : C → R be nicely tame functions such
that f (cid:48) is very close to f . Then,

dB∞(B(f ), B(f (cid:48))) ≤ (cid:13)

(cid:13)f − f (cid:48)(cid:13)

(cid:13)∞ .

Proof. In Lemma 5.10, we showed that using the direct alignment between B(f ) and B(f (cid:48)), the
absolute diﬀerence in aligned node weights is bounded by (cid:107)f − f (cid:48)(cid:107)∞. Since the backbone inﬁnity
distance is deﬁned by using an optimal alignment, we get

dB∞(B(f ), B(f (cid:48))) ≤ (cid:13)

(cid:13)f − f (cid:48)(cid:13)

(cid:13)∞ .

To remove the assumption that f and f (cid:48) are very close and thus to globalize the backbone
inﬁnity stability result, we construct a straight-line homotopy between f and f (cid:48) and consider a
ﬁnite number of functions within this homotopy for which every two successive functions are very
close. For each such pair of functions, Lemma 5.11 applies and we are able to apply almost the same
argument as the proof of the Interpolation Lemma in [13]. Because we sample functions between
f and f (cid:48) in the homotopy, we are able to conclude that dB∞(B(f ), B(f (cid:48))) ≤ (cid:107)f − f (cid:48)(cid:107)∞.
Theorem 5.12 (Backbone Inﬁnity Stability). Let f, f (cid:48) : C → R be nicely tame functions. Then,

(cid:3)

dB∞(B(f ), B(f (cid:48))) ≤ (cid:13)

(cid:13)f − f (cid:48)(cid:13)

(cid:13)∞ .

Proof. Let c := (cid:107)f − f (cid:48)(cid:107)∞. Deﬁne hλ := (1 − λ)f + λf (cid:48) where λ ∈ [0, 1]. This is the family of
convex combinations of f and f (cid:48) forms a linear interpolation between the two functions, starting
at h0 = f and ending at h1 = f (cid:48). Furthermore, we deﬁne δ(λ) := δhλ as in Deﬁnition 5.7. Consider
the open cover U of [0, 1] by open intervals Jλ = (λ − δ(λ)/2c, λ + δ(λ)/2c) for all λ ∈ [0, 1]. The
compactness of [0, 1] implies the existence of a ﬁnite subcover U (cid:48) of U . Let λ1 < λ2 < · · · < λn be
the midpoints of the open intervals in U (cid:48). Observe, that half the length of Jλ is equal to δ(λ)/2c.
Since any two consecutive intervals Jλi and Jλi+1 have a non-empty intersection,

λi+1 − λi ≤ δ(λi)/2c + δ(λi+1)/2c

≤ 2 max{δ(λi)/2c, δ(λi+1)/2c}
= max{δ(λi), δ(λi+1)}/c

Furthermore, note

|hλi − hλi+1| = |((1 − λi)f + λif (cid:48)) − ((1 − λi+1)f + λi+1f (cid:48))|
= |f (λi+1 − λi) − f (cid:48)(λi+1 − λi)|
= (cid:13)
(cid:13)∞ (λi+1 − λi).

(cid:13)f − f (cid:48)(cid:13)

26

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

This implies

(cid:13)
(cid:13)hλi − hλi+1

(cid:13)
(cid:13)∞ = c(λi+1 − λi) ≤ max{δ(λi), δ(λi+1)}.

Therefore, hλi is very close to hλi+1 or vice-versa. Either way, Lemma 5.11 applies and we have

dB∞(hλi, hλi+1) ≤ (cid:13)

(cid:13)hλi − hλi+1

(cid:13)
(cid:13)∞

for all 1 ≤ i ≤ n − 1. Setting λ0 = 0 and λn+1 = 1, we see the inequality also holds for i = 0 and
i = n because hλ1 is very close to hλ0, and hλn+1 is very close to hλn Therefore,

dB∞(B(f ), B(f (cid:48))) ≤

≤

n
(cid:88)

i=0
n
(cid:88)

i=0

dB∞(B(hλi), B(hλi+1))

(cid:13)
(cid:13)hλi − hλi+1

(cid:13)
(cid:13)∞

= (cid:107)f − g(cid:107)∞ .

The ﬁrst inequality follows from the triangle inequality of the backbone inﬁnity distance (Lemma 8.8).
The last equality follows from how the collection hλi samples the straight line homotopy from f to
(cid:3)
f (cid:48). Thus dB∞(B(f ), B(f (cid:48))) ≤ (cid:107)f − f (cid:48)(cid:107)∞ .

5.1.3. Backbone Stability Results. Using Theorem 5.12, we also get stability results for the backbone
distance.
If the alignment that realizes the backbone inﬁnity distance between two backbones,
B(f ) and B(f (cid:48)) is of length K, then the sum of absolute diﬀerences of node weights is bounded by
K (cid:107)f − f (cid:48)(cid:107)∞. This is because the backbone distance is bounded by the sum of absolute diﬀerences
in node weights from the alignment realizing the backbone inﬁnity distance.

Corollary 5.13 (Backbone Stability). Let f, f (cid:48) : C → R be nicely tame functions. Let K be the
length of the alignment realizing the backbone inﬁnity distance between B(f ) and B(f (cid:48)). Then,

dB(B(f ), B(f (cid:48))) ≤ K (cid:13)

(cid:13)f − f (cid:48)(cid:13)

(cid:13)∞ .

If we are unable to compute K, note that we can bound K by the number of extrema of f plus
the number of extrema of f (cid:48) because that is the longest possible length of an alignment between
B(f ) and B(f (cid:48)).

5.2. Local Extremal Event DAG Stability. We showed stability between backbones. In this
section, we extend those results to the entire extremal event DAG in a local case (when f (cid:48) is
extremely close to f ). We start by proving that the direct alignment for functions we call extremely
close is the optimal backbone alignment for the backbones of those two functions.

Deﬁnition 5.14 (Extremely Close). Let f : C → R be a nicely tame function. Let δf be as deﬁned
in Deﬁnition 5.5. A nicely tame function f (cid:48) : C → R is extremely close to f if (cid:107)f − f (cid:48)(cid:107)∞ < δf /2.
The diﬀerence between functions that are very close and extremely close is that the constant is
δf is divided by two for functions that are extremely close. This is needed to show that the direct
alignment between two functions that are extremely close is the unique optimal alignment. Proving
this involves several technical lemmas which we prove in Appendix 8.5.

5.2.1. Bounding Diﬀerences in Aligned Node and Edge Weights. We next prove a few lemmas that
bound diﬀerences in node weights of aligned extrema.

For the rest of this subsection, we use the following assumptions and notation:

EXTREMAL EVENT GRAPHS

27

Assumptions 5.15 (Local Stability Assumptions). Let F = {fi}n
of nicely tame functions from C to R. Furthermore, suppose f (cid:48)
i ∈ [n]. Let D = (V, E, ωV , ωE) and D(cid:48) = (V (cid:48), E(cid:48), ω(cid:48)
F (cid:48), respectively. Let Sα = (Vα, Eα, ωα, ω(cid:48)
of alignments α = {αi}n
and D(cid:48).

i=1 and F (cid:48) = {f (cid:48)
i}n
i=1 be collections
i is extremely close to fi for each
E) be the extremal event DAGs of F and
α) be the extremal event supergraph arising from the set
i=1 that is used to compute the extremal event DAG distance between D

V , ω(cid:48)

Lemma 5.16 (Bound on Diﬀerence in Node Lives). Assume Assumptions 5.15. Let v(i, j) ∈ Vα.
Then,

|ωα(v(i, j)) − ω(cid:48)

α(v(i, j))| ≤ (cid:13)

(cid:13)fi − f (cid:48)
i

(cid:13)
(cid:13)∞ .

Proof. By Lemma 8.12, the alignment αi between B(fi) and B(f (cid:48)
In
Lemma 5.10, we showed the absolute diﬀerence in node weights between aligned nodes is bounded
by (cid:107)fi − f (cid:48)

i) is the direct alignment.

i(cid:107)∞. Therefore,

|ωα(v(i, j)) − ω(cid:48)

α(v(i, j))| ≤ (cid:13)

(cid:13)fi − f (cid:48)
i

(cid:13)
(cid:13)∞ .

(cid:3)

From Lemma 5.16, we can conclude that if f (cid:48) is extremely close to f , then the backbone distance
between B(f ) and B(f (cid:48)) is bounded by the number of extrema in f (cid:48) multiplied by (cid:107)f − f (cid:48)(cid:107)∞. This
is because the direct alignment has a length of B(f (cid:48)) and the absolute diﬀerence in aligned node
weights for each pair is bounded by (cid:107)f − f (cid:48)(cid:107)∞.
Corollary 5.17 (Bound on Backbone Distance for Extremely Close Functions). Let f, f (cid:48) : C → R
be nicely tame functions such that f (cid:48) is extremely close to f . Let k be the number of extrema of f (cid:48).
Then,

dB(B(f ), B(f (cid:48))) ≤ k (cid:13)

(cid:13)f − f (cid:48)(cid:13)

(cid:13)∞ .

Next we give a bound on the absolute diﬀerence in heights of aligned extrema when every pair

of functions is extremely close. In the following lemma we simplify notation as follows:

• uj := αB(fi)(j)
• u(cid:48)
i )(j).
j := αB(f (cid:48)

Lemma 5.18 (Bound on Diﬀerence in Heights of Aligned Extrema). Assume Assumptions 5.15.
i=1 be the set of backbone alignments between B(fi) and B(f (cid:48)
Let v(i, j) be a vertex in Sα. Let {αi}n
i)
i). Let (t, fi(t)) and (t(cid:48), fi(t(cid:48))) be the local extrema
that determines Sα. Let uj ∈ B(fi) and u(cid:48)
corresponding to uj and u(cid:48)

j, respectively. Then,

j ∈ B(f (cid:48)

i(t(cid:48))| ≤ (cid:13)
Proof. By Lemma 8.12, αi is the direct alignment for all i ∈ [n]. Recall from Construction 5.8,
(t(cid:48))) are contained in the square centered at (fi(t), ζfi(t)) of
that both (fi(t), ζfi(t)) and (f (cid:48)
(cid:3)
radius (cid:107)fi − f (cid:48)

i(t(cid:48)), ζf (cid:48)
i(cid:107)∞. Hence, |fi(t) − f (cid:48)

i(t(cid:48))| ≤ (cid:107)fi − f (cid:48)

|fi(t) − f (cid:48)

(cid:13)fi − f (cid:48)
i

(cid:13)
(cid:13)∞ .

i(cid:107)∞.

i

We now have a bound on the maximum diﬀerence between node weights in extremal event
DAGs. What remains is bounding the diﬀerence in edge weights between extremal event DAGs
when each pair of functions is extremely close. Let (v(i, k), v(j, m)) be an edge in the extremal
event supergraph. We show

|ωα(v(i, k), v(j, m)) − ω(cid:48)

α(v(i, k), v(j, m))| ≤ max{(cid:13)
For Lemma 5.19, recall from Theorem 3.3 that ε∗(t, s) is the inﬁmum ε for which ϕε(t)∩ϕε(s) (cid:54)= ∅.

(cid:13)fj − f (cid:48)
j

(cid:13)fi − f (cid:48)
i

(cid:13)
(cid:13)∞ , (cid:13)

(cid:13)
(cid:13)∞

}.

Furthermore, we simplify notation as follows:

28

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

• uk := αB(fi)(k)
• u(cid:48)
i )(k)
k := αB(f (cid:48)
• sm := αB(fj )(m)
• s(cid:48)
j )(m).
m := αB(f (cid:48)

Lemma 5.19 (Bound on Diﬀerence of Extremal Interval Intersection Values). Assume Assump-
tions 5.15. Let (v(i, k), v(j, m)) ∈ Eα such that i (cid:54)= j, and all four nodes deﬁning these two edges,
uk, u(cid:48)
k, sm, s(cid:48)
m are not empty nodes. Suppose the extrema these nodes represent are (t, fi(t)),
i(t(cid:48))), and (s(cid:48), f (cid:48)
(s, fj(s)), (t(cid:48), f (cid:48)

j(s(cid:48))), respectively. Then,

where εi,j := max{(cid:107)fi − f (cid:48)

i(cid:107)∞ ,

(cid:13)
(cid:13)fj − f (cid:48)
(cid:13)

j

(cid:13)
(cid:13)
(cid:13)∞

}.

|ε∗(t, s) − ε∗(t(cid:48), s(cid:48))| ≤ εi,j

Proof. Consider the case that both (t, fi(t)) and (s, fj(s)) are local minima. In the case that one
or both are local maxima, we replace one, or both fi, fj by the corresponding negative function
and convert the problem to a problem about two minima. Hence, only considering the case that
both are local minima is suﬃcient. Additionally, we omit superscripts on ε-extremal intervals to
avoid notational clutter. An input of t or s indicates the ε-extremal interval is computed from
fi or fj, respectively. An input of t(cid:48) or s(cid:48) indicates the ε-extremal interval is computed from
i or f (cid:48)
f (cid:48)
, and
εij := max{εi, εj}.

j, respectively. For convenience of exposition, let εi = (cid:107)fi − f (cid:48)

(cid:13)
(cid:13)fj − f (cid:48)
(cid:13)

i(cid:107)∞, εj =

(cid:13)
(cid:13)
(cid:13)∞

j

Suppose ε∗(t, s) < ε∗(t(cid:48), s(cid:48)). Let ε > ε∗(t, s). Then ϕε(t) ∩ ϕε(s) (cid:54)= ∅. By Lemma 5.18,

|fi(t) − f (cid:48)

i(t(cid:48))| ≤ εi ≤ εi,j.

Hence, fi(t) ≤ f (cid:48)

i(t(cid:48)) + εi,j. Additionally, since (cid:107)fi − f (cid:48)

i(cid:107)∞ ≤ εi,j,

These two inequalities imply fi(t) + ε ≤ f (cid:48)
x ∈ C. Recall

(f (cid:48)

i − εi,j)(x) ≤ fi(x) for all x ∈ C.
i(t(cid:48)) + ε + εi,j and (f (cid:48)

i − ε − εi,j)(x) ≤ fi(x) − ε for all

ϕε(t) is the connected component of (fi − ε)−1(fi(t) + ε) containing t,
ϕε+εi,j (t(cid:48)) is the connected component of (f (cid:48)

i − ε − εi,j)−1(f (cid:48)

i(t(cid:48)) + ε + εi,j) containing t(cid:48).

left(ϕε+εi,j (t(cid:48))) < left(ϕε(t)) and right(ϕε+εi,j (t(cid:48))) > right(ϕε(t)). We get ϕε(t) ⊂
Therefore,
ϕε+εi,j (t(cid:48)). Similarly, we get ϕε(s) ⊂ ϕε+εi,j (s(cid:48)). The non-empty intersection of ϕε(t) ∩ ϕε(s) im-
plies ϕε+εi,j (t(cid:48)) ∩ ϕε+εi,j (s(cid:48)) (cid:54)= ∅. This non-empty intersection holds true for all ε > ε∗(t, s). Since
ε∗(t, s) < ε∗(t(cid:48), s(cid:48)), we get

ε∗(t(cid:48), s(cid:48)) ≤ εi,j + ε∗(t, s).

Therefore,

ε∗(t(cid:48), s(cid:48)) − ε∗(t, s) ≤ εi,j.
In the case ε∗(t(cid:48), s(cid:48)) < ε∗(t, s), we get ϕε(t(cid:48)) ⊂ ϕε+εi,j (t) and ϕε(s(cid:48)) ⊂ ϕε+εi,j (s) by symmetry.
Therefore,

Combining these two cases, we conclude

ε∗(t, s) − ε∗(t(cid:48), s(cid:48)) ≤ εi,j.

|ε∗(t, s) − ε∗(t(cid:48), s(cid:48))| ≤ εi,j.

(cid:3)

Next, we can bound the absolute diﬀerence in aligned edge weights.

EXTREMAL EVENT GRAPHS

29

Figure 12. Nested ε-extremal intervals. We see that ϕfi

ε (t) ⊂ ϕf (cid:48)

i
ε+εi,j

(t(cid:48)).

Lemma 5.20 (Bound on Diﬀerences in Edge Weights). Assume Assumptions 5.15. Then,

|ωα(v(i, k), v(j, m)) − ω(cid:48)
j(s(cid:48))) be the local extrema corresponding to
Proof. Let (t, fi(t)), (s, fj(s)), (t(cid:48), f (cid:48)
j )(m), respectively. Additionally, we omit super-
nodes αB(fi)(k), αB(fj )(m), αB(f (cid:48)
scripts on ε-extremal intervals to avoid notational clutter. An input of t or s indicates the ε-extremal
interval is computed from fi or fj, respectively. An input of t(cid:48) or s(cid:48) indicates the ε-extremal interval
is computed from f (cid:48)

α(v(i, k), v(j, m))| ≤ max{(cid:107)fi − gi(cid:107)∞ , (cid:107)fj − gj(cid:107)∞}.
i(t(cid:48))), and (s(cid:48), f (cid:48)

i )(k), and αB(f (cid:48)

i or f (cid:48)

j, respectively.

We prove this lemma by discussing several cases. First, we assume that ωα(v(i, k), v(j, m)) and
α(v(i, k), v(j, m)) are non-zero. Then, by deﬁnition,

ω(cid:48)

Ediﬀ := |ωα(v(i, k), v(j, m)) − ω(cid:48)

= | min{

1
2

pers(t),

1
2

α(v(i, k), v(j, m))|
1
2

pers(s), ε∗(t, s)} − min{

pers(t(cid:48)),

1
2

pers(s(cid:48)), ε∗(t(cid:48), s(cid:48))}|.

Let εi = (cid:107)fi − gi(cid:107)∞, εj = (cid:107)fj − gj(cid:107)∞, and εi,j = max{εi, εj}. Now we begin to go through
the cases. Note that Ediﬀ can be one of nine absolute diﬀerences depending on which value the
minimum is achieved. In the cases where the diﬀerence comes from node weights of the same node
or the extremal intersection values, we can apply either Lemma 5.16 or Lemma 5.19. In all other
cases we split the equality Ediﬀ = |U1 − U2| into two cases Ediﬀ = U1 − U2 or Ediﬀ = U2 − U1. We
replace the larger term with one of the possible values from Ediﬀ so that we can apply Lemma 5.16
or Lemma 5.19. For example, in one of the cases, if we assume Ediﬀ = 1
2 (pers(s(cid:48)) − pers(t)). Then,
pers(s(cid:48)) ≤ pers(t(cid:48)). Applying Lemma 5.16, we ﬁnd
1
1
2
2
All together, we have 15 cases. We explicitly write these 15 cases out in Appendix 8.6. Based on
these bounds, we conclude in the case that ωα(v(i, k), v(j, m)) and ω(cid:48)
α(v(i, k), v(j, m)) are non-zero,
Ediﬀ ≤ εi,j.

(pers(t(cid:48)) − pers(t)) ≤ εi ≤ εi,j.

(pers(s(cid:48)) − pers(t)) ≤

Ediﬀ =

tfi−εf′ i−ε−εi,jt′ f′ i(t′ )+ε+εi,jfi(t)+ε((((φfiε(t)φf′ iε+εi,j(t′ )30

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

Now assume one of ωα(v(i, k), v(j, m)) or ω(cid:48)

generality, suppose ω(cid:48)

α(v(i, k), v(j, m)) = 0. Then,

α(v(i, k), v(j, m)) is equal to zero. Without loss of

Applying Lemma 5.16, we ﬁnd

Ediﬀ = min{

1
2

pers(t),

1
2

pers(s), ε∗(t, s)}.

1
2

pers(t) ≤ εi ≤ εi,j,

1
2

pers(s) ≤ εj ≤ εi,j.

If Ediﬀ = ε∗(t, s), then ε∗(t, s) ≤ 1

2 pers(t) ≤ εi ≤ εi,j. Hence, Ediﬀ ≤ εi,j.

Combining all the cases, we can conclude

|ωα(v(i, k), v(j, m)) − ω(cid:48)

α(v(i, k), v(j, m))| ≤ εi,j.

(cid:3)

Using the bounds we established between aligned node and edge weights in the extremal event
supergraph arising from extremely close functions, we can bound the extremal event DAG distance.

i. Let εi := (cid:107)fi − f (cid:48)

Theorem 5.21 (Extremal Event DAG Stability). Assume Assumptions 5.15. Let ki be the number
of extrema in f (cid:48)
i(cid:107)∞ and εi,j := max{εi, εj}. Let P be the set of unordered pairs
between the ﬁrst n positive integers. Let Sα|αi be the restricted subgraph of Sα that is induced by
αi. Furthermore, let i (cid:54)= j and denote Ei,j to be the set of cross edges in Sα, that is, (u, v) ∈ Ei,j
if u ∈ Sα|αi and v ∈ Sα|αj . Then,

dED(D, D(cid:48)) ≤

n
(cid:88)

i=1

kiεi +

n
(cid:88)

i=1

(cid:18)ki
2

(cid:19)

εi +

(cid:88)

(i,j)∈P

|Ei,j|εi,j.

Proof. Let Ei be the set of edges in the extremal event supergraph restricted to the subgraph
induced by αi. Hence, for each edge (u, v) ∈ Ei, we have u, v ∈ Sα|αi. The extremal event DAG
distance between D and D(cid:48) can be expressed as the sum of three terms.

dED(D, D(cid:48)) =

n
(cid:88)

i=1

+

dB(B(fi), B(f (cid:48)

i)) +

(cid:88)

(u,v)∈Ei

|ωα(u, v) − ω(cid:48)

α(u, v)|

(cid:88)

|ωα(u, v) − ω(cid:48)

α(u, v)|.

(u,v)∈Ei,j

The ﬁrst term is the sum of backbone distances between B(fi) and B(f (cid:48)

i) for each i ∈ [n]. The
second term is the sum of the absolute diﬀerence in edge weights where the nodes deﬁning each
edge are from the same backbone alignment. The third term is the sum of the absolute diﬀerence
in edge weights where the nodes deﬁning each edge are contained in diﬀerent backbones.

Applying Corollary 5.17, we know that dB(B(fi), B(f (cid:48)

i)) ≤ kiεi. Hence, we can bound the ﬁrst

term

n
(cid:88)

i=1

dB(B(fi), B(f (cid:48)

i)) ≤

n
(cid:88)

i=1

kiεi.

Applying Lemma 5.20, and noting both u, v ∈ Sα|αi, we know that if (u, v) ∈ Ei, then |ωα(u, v)−
α(u, v)| ≤ εi. There are (cid:0)ki
ω(cid:48)

(cid:1) edges in Ei. Hence, we can bound the second term by

2

(cid:88)

(u,v)∈Ei

|ωα(u, v) − ω(cid:48)

α(u, v)| ≤

n
(cid:88)

i=1

(cid:18)ki
2

(cid:19)

εi.

Let |Ei,j| be the cardinality of the set Ei,j. Applying Lemma 5.20, we can bound the third term

EXTREMAL EVENT GRAPHS

31

(cid:88)

(u,v)∈Ei,j

|ωα(u, v) − ω(cid:48)

α(u, v)| ≤

(cid:88)

(i,j)∈P

|Ei,j|εi,j.

Combining the three bounds we ﬁnd that

dED(D, D(cid:48)) ≤

n
(cid:88)

i=1

kiεi +

n
(cid:88)

i=1

(cid:19)

(cid:18)ki
2

(cid:88)

εi +

|Ei,j|εi,j.

(i,j)∈P

(cid:3)

Note that Theorem 5.21 requires that in collections {fi}n

j) is
extremely close. Therefore, this is a local stability result. Theorem 5.12 oﬀers an approach to use
a local result (Lemma 5.11) to prove a global result. This globalization approach uses a homotopy
that is sampled suﬃciently densely so that each consecutive pair satisﬁes the assumptions of the
local result. However, the key ingredient used to aggregate the local results to a global estimate is
a triangle inequality. It remains an important open question whether extremal event DAG distance
satisﬁes the triangle inequality. If so, than a similar globalization process would yield a version of
Theorem 5.21 without restrictions on closeness of fj and f (cid:48)
j.

i=1 each pair (fj, f (cid:48)

i=1 and {f (cid:48)

i}n

6. Applications

We apply the extremal event DAG construction and distance to two applications: (1) quantifying
similarity in replicate experiments of microarray yeast cell cycle data and (2) providing quantitative
evidence that an intrinsic oscillator drives the blood stage cycle of the malaria parasite Plasmodium
falciparum. We discuss how to apply the extremal event DAG construction and distance to the
discrete setting in the supplementary materials. These two datasets were analyzed in [5] and [57],
respectively, using a directed maximal common edge subgraph (DMCES) metric that compared
ε-DAGs (recall ε-DAGs described after Deﬁnition 3.2) with a sequence of ﬁxed ε. Because of
the computational complexity of computing the DMCES metric, these calculations were done on
a limited number of time series with a limited number of extrema per time series, i.e., on less
noisy data. Additionally, since the ε-DAGs specify a value of a parameter ε, the experiments were
performed over a range of ε between 0 and 0.15. The construction of extremal event DAGs does not
need the value of ε to be speciﬁed. Additionally, both the extremal event DAG construction and
distance can be computed much more quickly than the DMCES metric which has an exponential
time complexity. This all means we can compute distances over much larger sets of genes in a
signiﬁcantly shorter amount of time.

6.1. Yeast Cell Cycle Data. The ﬁrst dataset consists of microarray time series transcriptomics
from the yeast Saccharomyces cerevisiae, published in [45]. The yeast cell cycle is well studied
and has experimental validation [23, 11, 24, 54]. The amplitude of the data has been normalized
between -0.5 and 0.5 and its phase has been shifted by alignment using CLOCCS analysis, see
“Appendix A: Yeast Data Analysis” in [5]. Using the CLOCCS analysis, the replicate experiments
were aligned so that the time series start at the same point in the yeast cell cycle. Furthermore,
the data were truncated to one period so that the data analysis focuses on the extrema from a
synchronized cell population, since the production of daughter cells causes increasing levels of cell
division asynchrony that reduces the periodic signal. We analyze two collections of time series data
D1 and D2 that each consists of 16 genes and 265 time points.

We perform three diﬀerent comparison computations:
(1) We focus on a subset of D1 and D2 that consists of the time series for four genes: SWI4,
2 respectively. We

YOX1, NDD1, and HCM1. We denote these sub-datasets as D(cid:48)

1 and D(cid:48)

32

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

then compute the extremal event DAG distance between the extremal event DAGs of D(cid:48)
1
and D(cid:48)
2,

dED(DAG(D(cid:48)

1), DAG(D(cid:48)

2)).

(2) We consider dataset D(cid:48)

2 but switch labels between time series for CLB2 and Y OX1. We

call this mislabeled dataset D(cid:48)

3. Then we compute

dED(DAG(D(cid:48)

1), DAG(D(cid:48)

3)).

The comparison between dED(DAG(D(cid:48)
3)) indicates
the impact of the replacement of one time series by another on the extremal event DAG
distance.

2)) to dED(DAG(D(cid:48)

1), DAG(D(cid:48)

1), DAG(D(cid:48)

(3) Lastly, we assess the distance between the full datasets D1 and D2 by constructing a baseline
distribution for the expected distance. We do this by ﬁrst by scrambling the gene names in
D2 to create a dataset ˆD2. We then compute

dED(DAG(D1), DAG( ˆD2)).

We repeat this computation 100 times for 100 random name assignments. This experiment
gives us an idea on the range of possible distances between D1 and D2. We then compare
this distribution to the actual distance

dED(DAG(D1), DAG(D2)).

Since the extremal event DAG distance can be any non-negative number, it can be diﬃcult to
discern how similar D1 and D2 are solely based on computing dED(DAG(D1), DAG(D2)). To gain
a better understanding of how similar D1 and D2 are, we perform computation (3) to get a baseline
distribution of distances between the time series in D1 and time series in D2. This distribution can
then be used as a null hypothesis H0 for testing H1 that D1 and D2 measure gene expression in the
identically behaving cell in the same environmental condition.

Computations 1 & 2. We computed

2))) = 10.34
3))) = 15.48.

dED(DAG(D(cid:48)
dED(DAG(D(cid:48)

1), DAG(D(cid:48)
1), DAG(D(cid:48)
The mismatched gene dataset causes a 50% increase in distance even though only 25% of the dataset
was perturbed, a substantial change. This result is consistent with the result from numerical
experiment 3 in [5] where the same data were analyzed using ε-DAGs and the DMCES metric.
Speciﬁcally, DMCES similarity was computed between the ε-DAGs at ε values ranging between 0
and 0.15. A similarity score of one indicated that the ε-DAGs are equal whereas a similarity score
of 0 indicates the ε-DAGs are very dissimilar. The similarity ranged between 0.7 and 1 for D(cid:48)
1
and D(cid:48)
3. The same qualitative
conclusion can be drawn from our results and the earlier work; namely that replacing one time
series with another decreases similarity, or increases distance, between datasets.
Computation 3. After computing dED(DAG(D1)), DAG( ˆD2)) 100 times we get the distribution
of distances shown in Figure 13 with the following statistics

2, whereas the similarity ranged between 0.4 and 0.6 for D(cid:48)

1 and D(cid:48)

• Maximum Distance = 384.30
• Mean Distance = 341.90
• Minimum Distance = 273.95
• Standard Deviation = 23.14

We found dED(DAG(D1), DAG(D2)) = 150.44. Therefore dED(DAG(D1), DAG(D2)) is roughly
eight standard deviations (see Figure 13) below the mean of the estimated null distribution, which
suggests that there is a signiﬁcant amount of similarity between D1 and D2.

EXTREMAL EVENT GRAPHS

33

Figure 13. Extremal Event DAG Distances in Experiment 3. The red bar is
dED(DAG(D1), DAG(D2)), the distance between the two yeast datasets without
any scrambling of genes.

In numerical experiment 4 in [5], the same goal of measuring replicate similarity was approached
using a diﬀerent technique. Subsets of 4 and 8 genes out of the 16 total were used to construct
ε-DAGs over the range of ε ∈ [0, 0.15]. No baseline was calculated, but the computations showed
a mean similarity that was usually over the relatively high value of 80% and frequently over 90%.
Overall, the results of these three computations are consistent with the numerical experiments
in [5]. We oﬀer the signiﬁcant improvement that we did not need to run each of these computations
over a range of ε because the extremal event DAG construction does not depend on ε. Because
of the vast increase in computational eﬃciency, we were able to perform computation 3 using
all 16 genes in the two datasets instead of randomly sampled subsets. It was shown in [5] that
using subsets of increasing size decreased variance in the subsampled computations rather than
substantially changing mean performance, which was taken to be evidence that subsampling was
a good proxy for the distance between D1 and D2. In other words, if the DMCES method could
have computed the distance between D1 and D2, then increasing the size of the subsamples would
show convergence to that value. We oﬀer a method that does not require a convergence argument,
but rather can compute the value directly.

6.2. Malaria Parasite Data. In this application, we seek to show that oscillatory genes in strains
of Plasmodium falciparum maintain as much of a phase ordering as well known circadian genes
across various mouse tissues. This provides circumstantial evidence that malaria parasites have an
internal clock that is at least as conserved as that of the circadian oscillator, as shown in [57]. The
mouse data comes from [67] that contains the circadian transcriptomes of 12 mouse organ tissues
every two hours for 48 hours. In [57], similarity between datasets within malaria or mouse was
determined by choosing “reference datasets” to which the other strains and tissues were compared,
as opposed to computing all pairwise comparisons. The 3D7 strain and the liver tissue were chosen
as the reference datasets in Plasmodium falciparum and the mouse tissues respectively.

In both collections of time series, subsets of periodic genes were selected that peak at similar
times across parasite strains or mouse tissues. These genes are called “in-phase” subsets. After
this subset of genes was found, all datasets were interpolated with piecewise cubic Hermite inter-
polating polynomial spline to one hour intervals. The data were wrapped so that there could be

010020030040005101520DistancesFrequency34

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

a common starting point. Furthermore, Plasmodium falciparum was down-sampled by removing
every odd datapoint. More details on the experiments and data preprocessing can be found in the
supplementary materials of [57]. After the pre-processing steps, our time series contain 119 parasite
genes and 107 mouse genes.

To gain a better understanding of how similar our datasets are, we created a baseline distribution
for each strain or tissue by randomly interchanging gene names and shifting each time series by a
random amount, using the same random shifts as in [57]. Speciﬁcally, if we view the values of a
time series as an ordered list h1, h2, . . . , hn of length n, we randomly select 1 ≤ m ≤ n to create a
new shifted time series

hm, hm+1, . . . , hn, h1, h2, . . . , hm−1.

The phase shift operation preserves characteristics of the dataset except for the ordering of ex-
trema. For each strain and tissue, the baseline distance was computed between the unpermuted
and unshifted reference dataset and the permuted and shifted datasets.

We use the following notation for the parasite datasets:

• Let D1 be the collection of time series from strain 3D7. This is the reference dataset.
• Let D2 be the collection of time series from strain FVO-NIH.
• Let D3 be the collection of time series from strain SA250.
• Let D4 be the collection of time series from strain D6.
• Let D(cid:48)
• Let D(cid:48)
• Let D(cid:48)

2 be the collection of shifted and permuted time series of D2.
3 be the collection of shifted and permuted time series of D3.
4 be the collection of shifted and permuted time series of D4.

We perform the following computations to study the parasite data.
(1) Pick 1500 random subsets of 15 genes. With the arbitrary choice of 15 genes ﬁxed, let ˆDi
denote the subset of the corresponding time series from Di for i ∈ {1, 2, 3, 4}. Compute

dED(DAG( ˆD1), DAG( ˆDj))

for each random subset and each j ∈ {2, 3, 4}.

(2) Pick a new set of 1500 random subsets of 15 genes, where ˆDi for i ∈ {1, 2, 3, 4} is deﬁned
j denote the subset of the shifted and permuted time
j)) for each random subset and

j for j ∈ {2, 3, 4}. Compute dED(DAG( ˆD1), DAG( ˆD(cid:48)

as above for each subset. Let ˆD(cid:48)
series D(cid:48)
j ∈ {2, 3, 4}.

We do analogous experiments to study the mouse gene data. We use the following notation.

• Let Da be the collection of time series recorded from liver tissue. This is the reference

dataset.

• Let Db be the collection of time series recorded from kidney tissue.
• Let Dc be the collection of time series recorded from lung tissue.
• Let D(cid:48)
• Let D(cid:48)

b be the collection of shifted and permuted time series of Db.
c be the collection of shifted and permuted time series of Dc.
We perform the following experiments to study the mouse tissue data.
(1) Pick 1500 random subsets of 15 genes. Let ˆDi denote the subset of the corresponding time
series from Di for i ∈ {a, b, c}. Compute dED(DAG( ˆDa), DAG( ˆDj)) for each random subset
and j ∈ {b, c}.

(2) Pick a new set of 1500 random subsets of 15 genes, where ˆDi for i ∈ {1, 2, 3, 4} is deﬁned as
j denote the subset of the shifted and permuted time series D(cid:48)
j
j)) for each random subset and j ∈ {b, c}.

above for each subset. Let ˆD(cid:48)
for j ∈ {b, c}. Compute dED(DAG( ˆDa), DAG( ˆD(cid:48)

EXTREMAL EVENT GRAPHS

35

We summarize the results of the experiments below and provide more statistics in Appendix 8.7.
In Figure 14 and Figure 15, we see in general that the baseline distances are larger than the distances
between cell lines and reference cell line.

(a) D6

(b) FVO-NIH

(c) SA250

Figure 14. Histograms from Plasmodium falciparum experiments. The reference
strain was 3D7 for all experiments. The distribution of baseline extremal event DAG
distances is shown in blue for each graph and the distribution of extremal event DAG
distances is shown in purple. In all three plots, the extremal event DAG distances
are smaller than the corresponding baseline distances. Performing a paired t-test to
the blue and purple distributions with a null hypothesis that the distributions are
the same in all three plots resulted in a p-value below machine precision.

(a) Lung

(b) Kidney

Figure 15. Histograms from mouse experiments. The reference cell line was liver
for all experiments. The distribution of baseline extremal event DAG distances is
shown in blue for each graph and the distribution of extremal event DAG distances
is shown in purple. In all three plots, we see the extremal event DAG distances are
smaller than the corresponding baseline distances. Performing a paired t-test to the
blue and purple distributions with a null hypothesis that the distributions are the
same in all three plots resulted in a p-value below machine precision.

Overall, we ﬁnd the extremal event DAG distances from the parasite experiments to be smaller
than the extremal event DAG distances from the mouse experiments, both in absolute value and in
terms of distribution overlap, as found in [57], indicating support for a malarial clock. Additionally,
Figure 14 shows another pattern seen in [57], which is that the D6 data have the smallest distance to
the 3D7 reference data and that SA250 has the largest distance to 3D7 compared both in absolute
value and to their respective baselines.

In this computation, we used subsampling to computationally handle the size of dataset, as
in [57], and computed 1500 samples instead of 5000. However, we used more than double the genes

025050075010000200400DistancesFrequency025050075010000200400DistancesFrequency025050075010000200400DistancesFrequency025050075010000200400DistancesFrequency025050075010000200400DistancesFrequency025050075010000200400DistancesFrequency025050075010000200400DistancesFrequency025050075010000200400DistancesFrequency36

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

in our samples, 15 versus 6, and incorporated information about all levels of ε instead of only a
small ﬁxed subset of ε. The consistency of results found between the computations validates the
methodology of using extremal event DAGs in place of ε-DAGs.

7. Conclusion

We constructed a weighted directed graph descriptor of collections of time series data that keeps
track of the order and prominence of extrema, and is robust to experimental noise that arises from
taking discrete time samples of a continuous process. Furthermore, we deﬁne a distance between
these extremal event DAGs that constructs an extremal event supergraph using a modiﬁed version
of the edit distance and then computes the distance by taking the L1 distance between aligned node
and edge weights in the extremal event supergraph. The beneﬁt of this distance is that it can be
computed via dynamic programming and eﬃciently. We used this distance to compare the similarity
of experimental replicates in yeast cell cycle data, the similarity of circadian gene expression in
diﬀerent mouse tissues, and the similarity of gene expression across malaria parasite strains. Our
results are consistent with results from other literature [5, 57] that used directed maximal common
edge subgraphs of ε-DAGs [44]. The beneﬁt to using the extremal event DAG methodology is
that the savings in memory and computation speed facilitates the analysis of signiﬁcantly larger
datasets.

Furthermore, we prove several stability results.

In particular, the backbone distance arising
from two functions is bounded by the L∞ distance of the two functions multiplied by the number
of nodes in the backbone inﬁnity alignment. Using backbone stability, we prove the extremal event
DAG distance is stable in a local case. Local here means that the individual time series in one
collection diﬀers from the corresponding time series in the other collection by the amount that
allows direct alignment of the minima and maxima between the two time series. Additionally,
one of the time series can have small amplitude additional maxima and minima. Extension of
the local stability result to a stability between arbitrary multivariate time series is challenging. If
the triangle inequality for the extremal event DAG distance holds, then the local stability of the
extremal event DAG can be used to prove a global stability result using the same technique as in
the proof of backbone stability (Theorem 5.12). While in this paper we deﬁne the extremal event
DAG distance using the L1 norm, we suspect that stability also holds if we use any Lp norm. We
leave this generalization as future work.

We focus on a descriptor that is robust to measurement error that arises from taking discrete
time samples of a continuous process. However, there can be other types of uncertainty present in
the data. One type is related to signal processing and is seen as small peaks in the data. If we
want to remove this type of measurement errors from our analysis, we can apply a preprocessing
step using techniques from [42]. This technique applies sublevel set persistence to a time series to
determine a node life threshold. Nodes with a node life below the threshold are classiﬁed as results
of signal processing errors, or as noise. Eliminating nodes classiﬁed as noise and then computing
extremal event DAGs gives a smaller descriptor of a collection of time series that further increases
the size of computationally feasible datasets. Similar preprocessing steps to remove small peaks
can be made using Fourier transforms [7, 27].

In summary, extremal event DAGs are a new computational tool that can be used alone or in
combination with noise reduction algorithms to summarize and compare collections of time series
data.

References

[1] Christoph Bandt and Bernd Pompe. Permutation entropy: A natural complexity measure for time series. Phys.

Rev. Lett., 88:174102, Apr 2002.

[2] Robin Belton, Bree Cummins, and Robert R. Narem. Computing and comparing extremal event dags. https:

//github.com/breecummins/min_interval_posets, 2021.

EXTREMAL EVENT GRAPHS

37

[3] Paul Bendich, Herbert Edelsbrunner, Dmitriy Morozov, and Amit Patel. Homology and Robustness of Level and

Interlevel sets. Homology, Homotopy and Applications, 15(1):51 – 72, 2013.

[4] Paul Bendich and John Harer. Persistent intersection homology. Foundations of Computational Mathematics,

11:305–336, December 2010.

[5] Eric Berry, Bree Cummins, Robert R. Narem, Lauren M. Smith, Steven B. Haase, and Tom´aˇs Gedeon. Using
extremal events to characterize noisy time series. Journal of Mathematical Biology, 80:1523–1557, February 2020.
[6] Jesse Berwald and Marian Gidea. Critical transitions in a model of a genetic regulatory system. Mathematical

Biosciences & Engineering, 11(4):723–740, 2014.

[7] Steven Boll. Suppression of acoustic noise in speech using spectral subtraction. IEEE Transactions on Acoustics,

Speech, and Signal Processing, 27(2):113–120, 1979.

[8] Sara L. Bristow, Adam R. Leman, Laura A. Simmons Kovacs, Anastasia Deckard, John Harer, and Steven B.
Haase. Checkpoints couple transcription network oscillator dynamics to cell-cycle progression. Genome Biology,
15(446), 2014.

[9] Gunnar Carlsson and Vin de Silva. Zigzag persistence. Foundations of Computational Mathematics, 10:367–405,

2010.

[10] Chao Chen, Xiuyan Ni, Qinxun Bai, and Yusu Wang. A topological regularizer for classiﬁers via persistent

homology. In AISTATS, 2019.

[11] Chun-Yi Cho, Christina M. Kelliher, and Steven B. Haase. The cell-cycle transcriptional network generates and

transmits a pulse of transcription once each cell cycle. Cell Cycle, 2019.

[12] Chun-Yi Cho, Francis C. Motta, Christina M. Kelliher, and Steven B. Haase. Reconciling conﬂicting models for

global control of cell-cycle transcription. Cell Cycle, 2017.

[13] David Cohen-Steiner, Herbert Edelsbrunner, and John Harer. Stability of persistence diagrams. Discrete and

Computational Geometry, 37:103–120, 2007.

[14] David Cohen-Steiner, Herbert Edelsbrunner, and Dmitriy Morozov. Vines and vineyards by updating persistence
in linear time. In SoCG 2006: Proceedings of the Twenty-Second Annual Symposium on Computational Geometry,
pages 119–126, 2006.

[15] Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Cliﬀord Stein. Introduction to Algorithms,

Third Edition. The MIT Press, 3rd edition, 2009.

[16] Bree Cummins, Tom´aˇs Gedeon, Shaun Harker, and Konstantin Mischaikow. Model rejection and parameter

reduction via time series. SIAM Journal of Applied Dynamical Systems, 17(2):1589–1616, 2018.

[17] Meryll Dindin, Yuhei Umeda, and Fr´ed´eric Chazal. Topological Data Analysis for Arrhythmia Detection through
Modular Neural Networks. In CanadianAI 2020 - 33rd Canadian Conference on Artiﬁcial Intelligence, Proc. 33rd
Canadian Conference on Artiﬁcial Intelligence, May 2020., Ottawa, Canada, May 2020. 7 pages, 4 ﬁgures.
[18] Herbert Edelsbrunner and John Harer. Persistent homology - a survey. Surveys on Discrete and Computational

Geometry: Twenty Years Later, pages 257–282, 2008.

[19] Herbert Edelsbrunner and John Harer. Computational Topology: An Introduction. Applied Mathematics. Amer-

ican Mathematical Society, 2010.

[20] Michelle Feng and Mason A. Porter. Persistent homology of geospatial data: A case study with voting. SIAM

Review, 63:67–99, 2021.

[21] Shaﬁe Gholizadeh and Wlodek Zadrozny. A short survey of topological data analysis in time series and system

analysis. arXiv:1809.10745, 2018.

[22] Robert Ghrist. The persistent topology of data. American Mathematical Society. Bulletin. New Series., 45:61–75,

2008.

[23] David G¨unther, Joseph Salmon, and Julien Tierny. Mandatory critical points of 2d uncertain scalar ﬁelds.

Computer Graphics Forum, 33:31–40, 2014.

[24] Steven B. Haase and Curt Wittenberg. Topology and control of the cell-cycle-regulated transcriptional circuitry.

Genetics, 196:65–90, 2014.

[25] Allen Hatcher. Algebraic Topology. Algebraic Topology. Cambridge University Press, 2002.
[26] Tomasz Kaczynski, Konstantin Mischaikow, and Marian Mrozek. Computational Homology, volume 157.

Springer-Verlag, 2004.

[27] Sunil D. Kamath and Philipos C. Loizou. A multi-band spectral subtraction method for enhancing speech
corrupted by colored noise. 2002 IEEE International Conference on Acoustics, Speech, and Signal Processing, 4,
2002.

[28] Firas A. Khasawneh and Elizabeth Munch. Topological data analysis for true step detection in periodic piecewise
constant signals. Proceedings of the Royal Society A: Mathematical, Physical and Engineering Science, 474, 2018.
[29] Woojin Kim and Facundo M´emoli. Stable signatures for dynamic metric spaces via zigzag persistent homology,

2017. arXiv:1712.04064.

[30] Woojin Kim and Facundo M´emoli. Spatiotemporal persistent homology for dynamic metric spaces. Discrete

Computational Geometry, 66:831–875, 2021.

38

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

[31] Laura A. Simmons Kovacs, Michael B. Mayhew, David A. Orlando, Yuanjie Jin, Qingyun Li, Chenchen Huang,
Steven I. Reed, Sayan Mukherjee, and Steven B. Haase. Cyclin-dependent kinases are regulators and eﬀectors
of oscillations driven by transcription factor network. Molecular Cell, 45(5):669–679, 2012.

[32] Laura A. Simmons Kovacs, David A. Orlando, and Steven B. Haase. Transcription networks and cyclin/cdks:
The yin and yang of cell cycle oscillators. Foundations of Computational Mathematics, 7:2626–2629, 2008.
[33] Peter Lawson, Andrew B. Sholl, J. Quincy Brown, Brittany Terese Fasy, and Carola Wenk. Persistent homology
for the quantitative evaluation of architectural features in prostate cancer. Scientiﬁc Reports, 9(1139), 2019.
[34] Yongjin Lee, Senja D. Barthel, Pawe(cid:32)l D(cid:32)lotko, Seyed Mohamad Moosavi, Kathryn Hess, and Berend Smit. High-
throughput screening approach for nanoporous materials genome using topological data analysis: Application to
zeolites. Journal of Chemical Theory and Computation, 14(8):4427–4437, 2018.

[35] Di Ma, Tongyu Liu, Lin Chang, Crystal Rui, Yuanyuan Xiao, Siming Li, John B. Hogenesch, Y. Eugene Chen,
and Jiandie D. Lin. The liver clock controls cholesterol homeostasis through trib1 protein-mediated regulation of
pcsk9/low density lipoprotein receptor (ldlr) axis*. Journal of Biological Chemistry, 290(52):31003–31012, 2015.

[36] John Milnor. Morse Theory. Princeton University Press, New Jersey, 1963.
[37] Dimitriy Morozov and Gunther H. Weber. Distributed merge trees. In Proceedings of the Annual Symposium on

Principles and Practice of Parallel Programming, pages 93–102. ACM, February 2013.

[38] Dmitriy Morozov, Kenes Beketayev, and Gunther H. Weber. Interleaving distance between merge trees. Discrete

Computational Geometry, 49:22–45, 2013.

[39] James R. Munkres. Elements of Algebraic Topology. Addison-Wesley, 1984.
[40] Ludovic S. Mure, Hiep D. Le, Giorgia Benegiamo, Max W. Chang, Luis Rios, Ngalla Jillani, Maina Ngotho,
Thomas Kariuki, Ouria Dkhissi-Benyahya, Howard M. Cooper, and Satchidananda Panda. Diurnal transcriptome
atalas of primate across major neural and peripheral tissues. Science, 359, 2018.

[41] Audun Myers and Firas A. Khasawneh. On the automatic parameter selection for permutation entropy. Chaos:

An Interdisciplinary Journal of Nonlinear Science, 30(033130), 2020.

[42] Audun Myers, Firas A. Khasawneh, and Brittany Terese Fasy. Separating persistent homology of noise from

time series data using topological signal processing. arXiv:2012.04039, 2020.

[43] Saul B. Needleman and Christian D. Wunsch. A general method applicable to the search for similarities in the

amino acid sequence of two proteins. Journal of Molecular Biology, 48:443–453, March 1970.

[44] Riley Nerem, Peter Crawford-Kahrl, Bree Cummins, and Tom´aˇs Gedeon. A poset metric from the directed

maximum common edge subgraph, 2019. arXiv:1910.14638.

[45] David A. Orlando, Charles Y. Lin, Allister Bernard, Jean Y. Wang, Joshua E. S. Socolar, Edwin S. Iversen,
Alexander J. Hartemink, and Steven B. Haase. Global control of cell cycle transcription by coupled cdk and
network oscillators. Nature, 453(7197):944–947, 2008.

[46] Nina Otter, Mason A. Porter, Ulrike Tillmann, Peter Grindrod, and Heather A. Harrington. A roadmap for the

computation of persistent homology. EPJ Data Science, 6, 2017.
[47] Jose A. Perea. A brief history of persistence. Morﬁsmos, 23:1–16, 2019.
[48] Jose A. Perea, Anastasia Deckard, Steve B. Haase, and John Harer. Sw1pers: Sliding windows and 1-persistence
scoring; discovering periodicity in gene expression time series data. BMC Bioinformatics, 16, August 2015.
[49] G. Petri, P. Expert, F. Turkheimer, R. Carhart-Harris, D. Nutt, P.J. Hellyer, and F. Vaccarino. Homological

scaﬀolds of brain functional networks. Journal of the Royal Society Interface, 11(20140873), 2014.

[50] Sahand Jamal Rahi, Kresti Pecani, Andrej Ondracka, and Catherine Oikonomou. The cdk-apc/c oscillator

predominantly entrains periodic cell-cycle transcription. Cell, 165:475–487, 2016.

[51] Marc D. Ruben, Gang Wu, David F. Smith, Robert E. Schmidt, Lauren J. Francey, Yin Yeng Lee, Ron C.
Anaﬁ, and John B. Hogenesch. A database of tissue-speciﬁc rhythmically expressed human genes has potential
applications in circadian medicine. Science Translational Medicine, 10, September 2018.

[52] Nicole F. Sanderson, Elliott Shugerman, Samantha Molnar, James D. Meiss, and Elizabeth Bradley. Computa-
tional topology techniques for characterizing time-series data. In Niall Adams, Allan Tucker, and David Weston,
editors, Advances in Intelligent Data Analysis XVI. Springer, 2017.

[53] Kerby Shedden and Stephen Cooper. Analysis of cell-cycle gene expression in saccharomyces cerevisiae using

microarrays and multiple synchronization methods. Nucleic Acids Research, 30:2920–2929, 2002.

[54] I. Simon, J. Barnett, N. Hannett, C.T. Harbison, N.J. Rinaldi, T.L. Volkert, J.J. Wyrick, J. Zeitlinger, Giﬀord
D.K., T.S. Jaakkola, and R.A. Young. Serial regulation of transcriptional regulators in the yeast cell cycle. Cell,
106:697–708, 2001.

[55] Michael Small. Complex networks from time series: Capturing dynamics. In 2013 IEEE International Symposium

on Circuits and Systems (ISCAS), pages 2509–2512, 2013.

[56] Dmitriy Smirnov and Dmitriy Morozov. Triplet merge trees. Topological Methods in Data Analysis and Visual-

ization V (TopoInVis’17), 2020.

[57] Lauren M. Smith, Francis C. Motta, Garima Chopra, J. Kathleen Moch, Robert R. Nerem, Bree Cummins,
Kimberly E. Roche, Christina M. Kelliher, Adam R. Leman, John Harer, Tom´aˇs Gedeon, Norman C. Waters,

EXTREMAL EVENT GRAPHS

39

and Steven B. Haase. An intrinsic oscillator drives the blood stage cycle of the malaria parasite plasmodium
falciparum. Science, 368(6492):754–759, 2020.

[58] Bernadette J. Stolz, Heather A. Harrington, and Mason A. Porter. Persistent homology of time-dependent

functional networks constructed from coupled time series. Chaos, 27, 2017.

[59] Floris Takens. Detecting strange attractors in turbulence. Dynamical Systems and Turbulence, Warwick 1980,

Lecture Notes in Mathematics, 898:366 – 381, 1981.

[60] Chad M. Topaz, Lori Ziegelmeier, and Tom Halverson. Topological data analysis of biological aggregation models.

PLoS ONE, 2015.

[61] Ruey S. Tsay. Multivariate Time Series Analysis: With R and Financial Applications. Wiley, 1st edition, 2013.
[62] M. Ulmer, Lori Ziegelmeier, and Chad M. Topaz. A topological approach to selecting models of biological

experiments. PLoS ONE, 2019.

[63] Oliver Vipond, Joshua A. Bull, Philip S. Macklin, Ulrike Tillmann, Christopher W. Pugh, Helen M. Byrne, and
Heather A. Harrington. Multiparameter persistent homology landscapes identify immune cell spatial patterns in
tumors. Proceedings of the National Academy of Sciences, 118(41), 2021.

[64] Robert A. Wagner and Michael J. Fischer. The string-to-string correction problem. Journal of the ACM, 21:168–

173, 1974.

[65] William W. S. Wei. Multivariate Time Series Analysis and Applications. Wiley, 1st edition, 2019.
[66] Lu Xian, Henry Adams, Chad M. Topaz, and Lori Ziegelmeier. Capturing dynamics of time-varying data via

topology. Foundations of Data Science, 2021.

[67] Ray Zhang, Nicholas F. Lahens, Heather I. Ballance, Michael E. Hughes, and John B. Hogenesch. A circadian
gene expression atlas in mammals: Implications for biology and medicine. Proceedings of the National Academy
of Sciences of the United States of America, 111:16219–16224, 2014.

[68] Afra Zomorodian and Gunnar Carlsson. Computing persistent homology. Discrete Computational Geometry,

33:249–274, 2005.

8. Appendix

8.1. Properties of ε-Extremal Intervals. We prove some properties of the ε-extremal intervals
that are useful for computing the edge weights. For Lemma 8.1 and Lemma 8.2, we omit the
superscript and subscript f from ϕf

ε and persf since f is the only function we are considering.

Lemma 8.1 (Nesting of ε-Extremal Intervals). Let f : C → R be a nicely tame function. Let t be
the domain coordinate of a local extremum of f . If 0 < ε0 < ε1, then,

ϕε0(t) ⊂ ϕε1(t).

Proof. Assume t is the domain coordinate of a local minimum. Since sublevel sets of a function
form a ﬁltration, we have

(f − ε0)−1(−∞, f (t) + ε0) ⊂ (f − ε0)−1(−∞, f (t) + ε1).

At the same time, because ε0 < ε1,

(f − ε0)−1(−∞, f (t) + ε1) ⊂ (f − ε1)−1(−∞, f (t) + ε1).

Combining these two statements we ﬁnd that

(3)

(f − ε0)−1(−∞, f (t) + ε0) ⊂ (f − ε1)−1(−∞, f (t) + ε1).

Note that ϕε0(t) ∩ ϕε1(t) (cid:54)= ∅ because they are connected components of
(f − ε0)−1(−∞, f (t) + ε0) and (f − ε1)−1(−∞, f (t) + ε1) respectively that contain t. Therefore
(3) implies ϕε0(t) ⊂ ϕε1(t). An analogous argument holds if t is the domain coordinate of a local
(cid:3)
maximum.
Lemma 8.2 (Properties of ϕε(ti)). Let f : C → R be a nicely tame function. Let t1 < t2 < ... < tn
be the domain coordinates of the local extrema of f . The following statements hold.
ε (t)) increases as a function of ε.
2 |f (ti) − f (ti+1)| if and only if ti+1 /∈ ϕε(ti) and ti /∈ ϕε(ti+1).

(1) The length len(ϕf
(2) For i < n, ε ≤ 1

40

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

(3) For i < n, if ε ≤ 1

2 min{pers(ti), pers(ti+1)}, then ti+1 /∈ ϕε(ti) and ti /∈ ϕε(ti+1).

Proof. Let f and T = {ti}n
i=1 be deﬁned as in the lemma statement. We prove the three statements
for local minima ﬁrst. Let i ∈ [n]. Assume that (ti, f (ti)) is a local minimum. Note that, since
minimum and maximum alternate in T , we know that ti+1 (if it exists) is a local maximum.

Proof of Statement (1) for minima. Consider two values 0 < ε0 < ε1. By Lemma 8.1, we ﬁnd

ϕε0(ti) ⊂ ϕε1(ti).

Therefore len(ϕε0(ti)) ≤ len(ϕε1(ti)).

Proof of Statement (2) for minima. For the forward direction, we assume i < n and ε ≤ 1

f (ti+1)|. Since ti is a local minimum and ti+1 is a local maximum, we have ε ≤ 1
which implies

2 |f (ti)−
2 (f (ti+1) − f (ti)),

(4)

f (ti+1) − ε ≥ f (ti) + ε.

By deﬁnition of ε-extremal intervals (Deﬁnition 2.4) and since ti is a local minimum, any point
x ∈ ϕε(ti) satisﬁes f (x) − ε < f (ti) + ε. Since we already established that f (ti+1) − ε ≥ f (ti) + ε
in Equation (4), we know that ti+1 /∈ ϕε(ti). Similarly, since ti+1 is a maximum, for any point y ∈
ϕε(ti+1), we know that f (y) + ε > f (ti+1) − ε. Along with Equation (4), we conclude ti /∈ ϕε(ti+1).
2 |f (ti)−f (ti+1)|.

Next, we prove the backward direction by contrapositive. Assume i < n and ε > 1

Since ti is a local minimum and ti+1 is a local maximum, we have

f (ti+1) − ε < f (ti) + ε.
Therefore, ti+1 ∈ (f − ε)−1(−∞, f (ti) + ε). In order for ti+1 ∈ ϕε(ti), we need to show that ti+1 is
in the connected component of (f − ε)−1(−∞, f (ti) + ε) containing ti. Recalling that left(∗) denotes
the left endpoint of an interval and since ti ∈ ϕε(ti), we have left(ϕε(ti)) < ti < ti+1. In addition,
since ti and ti+1 are adjacent, right(ϕε(ti)) > ti+1. We conclude that ti+1 ∈ ϕε(ti). Therefore,
Statement (2) holds for minima.

Proof of Statement (3) for minima. Statement (3) follows directly from [5, Proposition 4].
For the case where (ti, f (ti)) is a local maximum, we substitute −f for f and follow the proofs
(cid:3)

above.

8.2. Computing Edge Weights Lemma. We prove Theorem 3.3. We ﬁrst need the following
lemma.

Lemma 8.3 (Comparability of Extrema from Same function when ε is Smaller than Node Weights).
Let F = {fi : C → R}n
i=1 be a collection of nicely tame functions where ti
are all
the domain coordinates of the local extrema of fi. Let DAG(F ) := (V, E, ωV , ωE) be the extremal
event DAG of F . Let (v(i, j), v(c, d)) ∈ E. Suppose i = c, ε < min{ωV (v(i, j)), ωV (v(c, d))}, and
ϕfi

2 < · · · < ti
ki

1 < ti

d) (cid:54)= ∅. Then ti

j and tc

d are comparable.

j) ∩ ϕfc

ε (tc

ε (ti

Proof. Since i = c in this case, we omit the superscripts i and c of ti
f := fi. Furthermore, we omit the subscript and superscript f from the functions persf and ϕf
ε .

d. Additionally we set

j and tc

By Proposition 1 and Theorem 2 of [5], one of tj or td is the domain coordinate of a local maximum
while the other is the domain coordinate of a local minimum, and these two extrema are adjacent,
i.e. there are no extrema of f between tj and td. Without loss of generality, suppose (tj, f (tj)) is
a local minimum, (td, f (td)) is a local maximum, and tj < td. By way of contradiction, suppose
tj and td are incomparable. Since we assume that the ﬁrst two requirements of Deﬁnition 3.1 are
satisﬁed, it is the third condition that is violated. Therefore it is not true that tj ≺ε td nor it is
true that td ≺ε tj. Since tj < td, there exists g ∈ Nε(f ) such that for every t(cid:48)
j ∈ ϕε(tj) that is a
domain coordinate of a local minimum of g, and t(cid:48)
d ∈ ϕε(td) that is a domain coordinate of a local
d. Consider such t(cid:48)
maximum of g, we have t(cid:48)

d that are adjacent.

j and t(cid:48)

j > t(cid:48)

EXTREMAL EVENT GRAPHS

41

We claim that g(t(cid:48)
j) > f (td)−ε. On the contrary, suppose g(t(cid:48)
a local maximum (t(cid:48)
g, g(t(cid:48)
and td are incomparable.

g ∈ ϕε(td) and t(cid:48)

g)) such that t(cid:48)

j < t(cid:48)

Since g ∈ Nε(f ), we have f (td) − ε < g(td). Hence, g(t(cid:48)

j) ≤ f (td)−ε. We show there exists
g, which contradicts the assumption tj

j) < g(td). Suppose C = [a1, a2] where

a1, a2 ∈ R. We discuss two cases: either right(ϕε(td)) = a2 or right(ϕε(td)) (cid:54)= a2.

We prove Case 1 that right(ϕε(td)) (cid:54)= a2. By deﬁnition of ε-extremal intervals, f (right(ϕε(td))) +

ε = f (td) − ε. Since g ∈ Nε(f ),

g(right(ϕε(td))) < f (right(ϕε(td))) + ε = f (td) − ε.

Recall, f (td) − ε < g(td). Therefore, g(right(ϕε(td))) < g(td). By Statement (3) of Lemma 8.2,
we have td /∈ ϕε(tj). Hence, t(cid:48)
d ∈ ϕε(td).
Hence, t(cid:48)
j ∈ ϕε(td). All together we have,

j < td. Furthermore, by assumption t(cid:48)

d > left(ϕε(td)) and t(cid:48)

j where t(cid:48)

d < t(cid:48)

j > t(cid:48)

t(cid:48)
j < td < right(ϕε(td)),

j < td < right(ϕε(td)). Thus, t(cid:48)
j) < g(td),

g(t(cid:48)

g(td) > g(right(ϕε(td))).

This and the assumption g is nicely tame implies there exists a local maximum (t(cid:48)
that t(cid:48)

j, right(ϕε(td))). Hence, t(cid:48)

g ∈ ϕε(td) and t(cid:48)

j < t(cid:48)
g.

g ∈ (t(cid:48)

g, g(t(cid:48)

g)) such

We prove Case 2 right(ϕε(td)) = a2. Using the same reasoning as in the case (right(ϕε(td)) (cid:54)= a2),

we ﬁnd

Furthermore, we must have either

t(cid:48)
j < td < right(ϕε(td)),

g(t(cid:48)

j) < g(td).

g(td) > g(right(ϕε(td))) or g(a2) = g(right(ϕε(td))) ≥ g(td).

Either way, we can conclude there exists a local maximum t(cid:48)

g ∈ (t(cid:48)

j, a2] ⊂ ϕε(td) of g.

(t(cid:48)

In both cases (right(ϕε(td)) = a2 and right(ϕε(td)) (cid:54)= a2) we ﬁnd there exists a local maximum
g, g(t(cid:48)
g)) such that t(cid:48)
Therefore the claim

g. This shows that tj ≺ε td, which is a contradiction.

g ∈ ϕε(td) and t(cid:48)

j < t(cid:48)

holds. A similar argument can be used to show

g(t(cid:48)

j) > f (td) − ε

g(t(cid:48)
By Statement (3) of Lemma 8.2, tj /∈ ϕε(td) since ε < min{ωV (v(i, j)), ωV (v(c, d))} = 1
Applying Statement (2) of Lemma 8.2, we get ε ≤ 1

d) < f (tj) + ε.

2 min{pers(tj), pers(td)}.

g(t(cid:48)

j) > f (td) − ε ≥

g(t(cid:48)

d) < f (tj) + ε ≤

This implies that

(f (td) + f (tj)).

2 (f (td) − f (tj)). Hence,
1
2
1
2

(f (td) + f (tj)).

j).
d)) is a local maximum while (t(cid:48)

d) < g(t(cid:48)

g(t(cid:48)

d < t(cid:48)

d, g(t(cid:48)

j and (t(cid:48)

Since t(cid:48)
exist domain coordinates of a local minimum and maximum of g between t(cid:48)
a contradiction with the assumption that t(cid:48)
that tj and td are comparable.

j)) is local minimum of g, there must
j. Hence, we reach
j are adjacent extrema. Therefore, we conclude

d and t(cid:48)

d and t(cid:48)

j, g(t(cid:48)

(cid:3)

Theorem 3.3 (Computing Edge Weights). Let F = {fi : C → R}n
i=1 be a collection of nicely tame
functions where ti
2 < · · · < ti
are all the domain coordinates of the local extrema of fi. Let
ki
DAG(F ) := (V, E, ωV , ωE) be the extremal event DAG of F . For all edges (v(i, j), v(c, d)) ∈ E, the
following statements hold

1 < ti

42

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

(1) If i = c, then

(2) If i (cid:54)= c, then

ωE(v(i, j), v(c, d)) = min{ωV (v(i, j)), ωV (v(c, d))}.

ωE(v(i, j), v(c, d)) = min{ωV (v(i, j)), ωV (v(c, d)), ε∗(ti

j, tc

d)},

where

ε∗(ti

j, tc

d) := inf{ε | ϕfi

ε (ti

j) ∩ ϕfc

ε (tc

d) (cid:54)= ∅}.

Proof. Assume all hypotheses.

First, we prove Statement (1). Since i = c in this case, we omit the superscripts i and c of ti
j
d. Additionally we set f := fi. Furthermore, we omit the subscript and superscript f from

and tc
the functions persf and ϕf
ε .

First, suppose ε < min{ωV (v(i, j)), ωV (v(c, d))}. We show that tj and td are comparable. We

consider two cases.

Suppose ϕε(tj) ∩ ϕε(td) = ∅. Without loss of generality, assume tj < td. Let g ∈ Nε(f ). Using
j and t(cid:48)
d
d. Therefore, tj and

Proposition 2 and Corollary 2 of [5], we get that ϕε(tj) and ϕε(td) contain local extrema t(cid:48)
of the same type as tj and td. Since ϕε(tj) ∩ ϕε(td) = ∅, tj < td implies t(cid:48)
td are comparable.

j < t(cid:48)

Next suppose ϕε(tj) ∩ ϕε(td) (cid:54)= ∅. This is the content of Lemma 8.3 in Appendix 8.2. Altogether

we ﬁnd that if ε < min{ωV (v(i, j), ωV (v(c, d))}, then tj and td are comparable.

Lastly, we consider the case that ε ≥ min{ωV (v(i, j), ωV (v(c, d))}. By Deﬁnition 3.1, tj and td

are incomparable.

We have shown that tj, td are comparable for all ε < min{ωV (v(i, j)), ωV (v(c, d))} and tj, td are

incomparable for all ε ≥ min{ωV (v(i, j)), ωV (v(c, d))}. Therefore,

min{ωV (v(i, j)), ωV (v(c, d))} = inf{ε | tj and td are incomparable}.

We conclude ωE(v(i, j), v(c, d)) = min{ωV (v(i, j)), ωV (v(c, d))}.

j, fi(ti

Next, we prove Statement (2). Let (ti

j)) and (tc
ε ≤ min{ωV (v(i, j)), ωV (v(c, d)), ε∗}.
Then, by deﬁnition of ε∗, the intervals ϕfi
j) and ϕfc
d) are disjoint. Additionally, from Proposi-
tion 2 and Corollary 2 of [5], both intervals guarantee existence of local extrema of the appropriate
j and tc
type under any ε-perturbation. Therefore, ti

d)) be local extrema. First, let

d, fc(tc

ε (tc

ε (ti

Next, if ε∗ < ε ≤ min{ωV (v(i, j)), ωV (v(c, d))}, then ϕfi

of an ε-perturbation can happen anywhere in ϕε(ti
at ε.

d are comparable.
ε (tc
d), then ti

ε (ti
j) and ϕε(tc

j)∩ϕfc

d) (cid:54)= ∅. Since a local extremum
d are incomparable

j and tc

Lastly, if ε ≥ min{ωV (v(i, j)), ωV (v(c, d))}, then by Deﬁnition 3.1, ti
We conclude that ωE(v(i, j), v(c, d)) = min{ωV (v(i, j), ωV (v(c, d)), ε∗(ti

j and tc
j, tc
d)}.

d are incomparable.
(cid:3)

8.3. Backbone Distance is A Metric. In order to show the triangle inequality, dB(x, z) ≤
dB(x, y) + dB(y, z), we need a way of composing an alignment between x and y with an alignment
between y and z. This is the content of Construction 8.4 and Lemma 8.5.

Construction 8.4 (Composition of Alignments). Let x, y, z be backbones and α1 : [k] → (cid:101)x×(cid:101)y, α2 :
[l] → (cid:101)y × (cid:101)z be alignment maps. The composition of α1 and α2 induces an ordered correspondence
between (cid:101)x and (cid:101)z whose nontrivial pairs are given by

A := {(x, z) | ∃y ∈ y s.t. (x, y) ∈ im(α1) and (y, z) ∈ im(α2)} .

EXTREMAL EVENT GRAPHS

43

The pairs in A are ordered using the order given in x. The set A, however does not form a complete
alignment of x and z because xi ∈ x with (xi, 0) ∈ im(α1) and zj ∈ z with (0, zj) ∈ im(α2) are not
accounted for in pairs in A. We include all such pairs (xi, 0) and (0, zj) to construct a function
α2 ◦ α1 : [s] → (cid:101)x × (cid:101)z in such a way that each pair satisﬁes

(a) If ιx(xi) < ιx(x) (ιx(x) < ιx(xj)) and (xi, zi) ∈ A ((xj, zj) ∈ A) then for

α2 ◦ α1(s1) = (xi, zi), α2 ◦ α1(s2) = (x, 0), α2 ◦ α1(s3)(xj, zj)

we have the order s1 < s2 (s2 < s3).

(b) If ιz(zi) < ιz(z) (ιz(z) < ιz(zj)) and (xi, zi) ∈ A ((xj, zj) ∈ A) then for

α2 ◦ α1(s1) = (xi, zi), α2 ◦ α1(s2) = (0, z), α2 ◦ α1(s3)(xj, zj)

we have the order s1 < s2 (s2 < s3).

An extension of A to an alignment α2 ◦ α1 : [s] → (cid:101)x × (cid:101)z exists, but also that it may not be
unique since there may be multiple options on where to place consecutive insertions. We re-
solve this ambiguity arbitrarily in the following way.
If there is a set of consecutive insertions
{(xi1, 0), (xi2, 0), . . . , (xik , 0), (0, zj1), . . . , (0, zjs)} between a pair (xi, zi) and a pair (xj, zj), then
we order them starting with the insertions {(xir , 0)}k
r=1 ordered by the order given in x, followed
by the insertions {(0, zjr )}s
r=1 insertions ordered by the order given in z. We hasted to point out
that the following results (Lemma 8.5, Lemma 8.6, and Lemma 8.8) hold for α2 ◦ α1 deﬁned using
any choice of order of such consecutive insertions.

The ordered correspondence α2 ◦ α1 is, in fact, an alignment:

Lemma 8.5 (Composition is an Alignment). Let x, y, z be backbones and α1 : [k] → (cid:101)x × (cid:101)y,
α2 : [l] → (cid:101)y × (cid:101)z be alignment maps. Then, α2 ◦ α1 is an alignment between x and z.
Proof. We show that all properties of Deﬁnition 4.4 hold. Since α1, α2 are alignments, they contain
no null alignments or misalignments. This implies that α2 ◦ α1 also contains no null alignments or
misalignments. Furthermore, im(α2 ◦ α1) contains all x ∈ x that are nontrivially aligned with y ∈ y
along with all x ∈ x that are aligned with an insertion. Hence all x ∈ x appear in the image of
(α2 ◦ α1)x exactly once. The same can be said for all z ∈ z. Therefore, Property (1), Property (3),
and Property (4) of Deﬁnition 4.4 hold.

Lastly, we show that α2 ◦ α1 preserves order of the backbones x and z. First consider the set of
nontrivial pairs A. We show the order of the (partial) backbones x and z is preserved in this set. By
construction, we know the order of x is preserved. Replacing each pair (x, z) ∈ A by (x, y) ∈ im(α1)
where (y, z) ∈ im(α2), we see the order of y is preserved because α1 is an alignment. Next, replacing
each of these pairs with (y, z) where (y, z) ∈ im(α2), we see that order z is preserved in A because α2
is an alignment. Hence, the order of the backbones x and z are preserved in A. By Construction 8.4,
each remaining trivial pair is added to the set A so that the order of the backbones x and z are
preserved. Thus, Property (2) of Deﬁnition 4.4 also holds and we have an alignment α2 ◦α1 between
(cid:3)
x and z.

Next, we prove that the backbone distance satisﬁes the triangle inequality. We consider three
backbones x, y, and z. We use optimal alignments between x and y, and y and z, to construct an
alignment between x and z. We show that the constructed alignment between x and z satisﬁes the
triangle inequality. Since the cost of the alignment between x and z that we ﬁnd is an upper bound
of the cost of an optimal alignment between x and z, the backbone distance must also satisfy the
triangle inequality.

Lemma 8.6 (Backbone Distance Satisﬁes Triangle Inequality). Let x, y, z be backbones. Then,

dB(x, z) ≤ dB(x, y) + dB(y, z).

44

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

Proof. Let α1 : [k] → (cid:101)x × (cid:101)y, α2 : [m] → (cid:101)y × (cid:101)z be optimal alignments. Consider the composition
alignment α2 ◦ α1 from Construction 8.4. Deﬁne A as in Construction 8.4,

Ax := {(x, y) ∈ im(α1) | ∃z ∈ z s.t. (y, z) ∈ im(α2)},

and

Az := {(y, z) ∈ im(α2) | ∃x ∈ x s.t. (x, y) ∈ im(α1)}.
We start by considering and justifying all the relations we need in the triangle inequality compu-
tation. Since dB(x, z) is computed using an optimal alignment between x and z and α2 ◦ α1 is one
alignment,

(5)

dB(x, z) ≤

(cid:88)

|wx − wz| +

(cid:88)

wx +

(cid:88)

wz

(x,z)∈im(α2◦α1)

(x,0)∈im(α2◦α1)

(0,z)∈im(α2◦α1)

We apply the L1 norm triangle inequality to the ﬁrst term in (5) to get

(6)

(cid:88)

|wx − wz| ≤

(cid:88)

|wx − wy| +

(cid:88)

|wy − wz|.

(x,z)∈im(α2◦α1)

(x,y)∈Ax

(y,z)∈Az

Now we discuss the second term in (5). Deﬁne

X(y,0) := {(x, 0) ∈ im(α2 ◦ α1) | ∃y ∈ y s.t. (x, y) ∈ im(α1) \ Ax}.

Observe, if (x, y) ∈ im(α1) \ Ax, then for all z ∈ z, (y, z) /∈ im(α2). Hence, (y, 0) ∈ im(α2). This
implies the set

(x × {0}) ∩ im(α2 ◦ α1) = ((x × {0}) ∩ im(α1)) ∪ X(y,0)

and this union is disjoint. Thus,

(7)

(cid:88)

wx =

(cid:88)

wx +

(cid:88)

wx.

(x,0)∈im(α2◦α1)

(x,0)∈im(α1)

(x,0)∈X(y,0)

By deﬁnition of X(y,0), for each (x, 0) ∈ X(y,0), there exists y ∈ y such that (x, y) ∈ im(α1) \ Ax
and, at the same time, (y, 0) ∈ im(α2). Noting this observation and applying the triangle inequality
from the L1-norm to the last term of Equation (7), gives

(8)

(cid:88)

wx ≤

(cid:88)

wx +

(cid:88)

|wx − wy|

(x,0)∈im(α2◦α1)

(x,0)∈im(α1)

im(α1)\Ax

+

(cid:88)

wy.

(y,0)∈im(α2) s.t. (x,y)∈im(α1)

Now we discuss the third term in (5). Deﬁne

Z(0,y) := {(0, z) ∈ im(α2 ◦ α1) | ∃y ∈ y s.t. (y, z) ∈ im(α2) \ Az}.

Similarly, the set

This implies

(9)

({0} × z) ∩ im(α2 ◦ α1) = (({0} × z) ∩ im(α2)) ∪ Z(0,y).

(cid:88)

wz =

(cid:88)

wz +

(cid:88)

wz.

(0,z)∈im(α2◦α1)

(0,z)∈im(α2)

(0,z)∈Z(0,y)

EXTREMAL EVENT GRAPHS

45

By deﬁnition, for each (0, z) ∈ Z(0,y), there exists y ∈ y such that (y, z) ∈ im(α2) \ Az and
(0, y) ∈ im(α1). Applying the triangle inequality from the L1-norm to the last term of Equation
(9), we get

(cid:88)

wz ≤

(cid:88)

wz +

(cid:88)

|wz − wy|

(10)

(0,z)∈im(α2◦α1)

(0,z)∈im(α2)

(y,z)∈im(α2)\Az
(cid:88)

+

wy.

(0,y)∈im(α1) s.t. (y,z)∈im(α2)

We derive two additional sets of relationships that will be used in the ﬁnal estimate. We ﬁrst

note that since im(α1) ∩ (x × y) = Ax ∪ ((im(α1) ∩ (x × y)) \ Ax) and this union is disjoint,

(11)

(cid:88)

|wx − wy| +

(cid:88)

|wx − wy| =

(cid:88)

|wx − wy|.

(x,y)∈Ax

(x,y)∈im(α1)\Ax

(x,y)∈im(α1)

Analogously, since im(α2) ∩ (y × z) = Az ∪ ((im(α2) ∩ (y × z)) \ Az) and this union is disjoint. Thus,

(12)

(cid:88)

|wy − wz| +

(cid:88)

|wy − wz| =

(cid:88)

|wy − wz|.

(y,z)∈Az

(y,z)∈im(α2)\Az

(y,z)∈im(α2)

The second set of relationships are inequalities. First, notice if (y, z) ∈ im(α2) \ Az, then y must

align with an empty node in the alignment α1. Hence,

{(0, y) | (y, z) ∈ im(α2) \ Az} ⊂ {(0, y) ∈ im(α1)}.

This implies

(13)

(cid:88)

wy ≤

(cid:88)

wy.

(0,y) s.t. (y,z)∈im(α2)\Az

(0,y)∈im(α1)

Finally, we note that {(y, 0) ∈ im(α2) | (x, y) ∈ im(α1)} ⊂ im(α2) ∩ (y × {0}). Therefore,

(14)

(cid:88)

wy ≤

(cid:88)

wy

(y,0)∈im(α2) s.t. (x,y)∈im(α1)

(y,0)∈im(α2)

Now we can put all these relations together to prove the backbone distance satisﬁes the triangle

inequality.

46

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

dB(x, z) ≤

(cid:88)

|wx − wz| +

(cid:88)

wx +

(cid:88)

wz

(x,z)∈im(α2◦α1)

(x,0)∈im(α2◦α1)

(0,z)∈im(α2◦α1)

by Equation (5)
(cid:88)

|wx − wy| +

≤

(cid:88)

|wy − wz| +

(cid:88)

wx

(x,y)∈Ax

(y,z)∈Az

(x,0)∈im(α2◦α1)

(cid:88)

+

(0,z)∈im(α2◦α1)

wz by Equation (6)

(cid:88)

≤

(x,y)∈Ax

|wx − wy| +

(cid:88)

|wx − wy|

(cid:88)

(x,y)∈im(α1)\Ax
(cid:88)

wx +

wy

(x,0)∈im(α1)

(y,0)∈im(α2) s.t. (x,y)∈im(α1)

(cid:88)

|wy − wz| +

(cid:88)

|wz − wy|

(y,z)∈Az

(y,z)∈im(α2)\Az

(cid:88)

wy +

(cid:88)

wz

(0,z)∈im(α2)

(0,y)∈im(α1) s.t. (y,z)∈im(α2)
by Equations (8) and (10)

+

+

+

(cid:88)

≤

|wx − wy| +

(cid:88)

wx +

(cid:88)

wy

(x,y)∈im(α1)
(cid:88)

+

(x,0)∈im(α1)
(cid:88)

|wy − wz| +

(0,y)∈im(α1)
(cid:88)

wy +

wz

(y,z)∈im(α2)

(y,0)∈im(α2)

(0,z)∈im(α2)

by Equations (11), (13), (12), and (14)

= dB(x, y) + dB(y, z).

Hence, dB(x, z) ≤ dB(x, y) + dB(y, z).

(cid:3)

We can now prove the backbone distance is a metric.

Proposition 8.7 (Backbone Distance is a Metric). The backbone distance (Deﬁnition 4.8) is a
metric.

Proof. Let x, y be backbones. Recall that for each x ∈ x, we can write x = (sx, wx); likewise for
y ∈ y. Let α : [k] → (cid:101)x × (cid:101)y be an optimal alignment. We verify all properties of a metric.

Non-Negativity. Since all node weights are non-negative, dB(x, y) ≥ 0.
Symmetry. By construction, dB is symmetric; see (1).
Deﬁniteness. If x = y, then the optimal alignment aligns each node with itself, and there are no

insertions. Hence, all node weights match and dB(x, y) = 0.
On the other hand, assume dB(x, y) = 0. This implies

(cid:88)

0 =

|wx − wy| +

(cid:88)

wx +

(cid:88)

wy.

(x,y)∈im(α)

(x,0)∈im(α)

(0,y)∈im(α)

Since all weights are non-negative, the latter two summands (corresponding to nodes aligned with
insertions) sum to zero. Since there are no null alignments (Deﬁnition 4.4 Property (1)), every

EXTREMAL EVENT GRAPHS

47

node in x is aligned with a node in y. We have
(cid:88)

0 =

|wx − wy|

(x,y)∈im(α)

and so wx = wy for all nontrivial pairs (x, y). Additionally, if (x, y) ∈ im(α), we know that sx = sy.
Since this is true for all nodes, we must have x = y.

Triangle Inequality. By Lemma 8.6, the triangle inequality holds.
Therefore, the backbone distance is a metric.

(cid:3)

8.4. Backbone Inﬁnity Distance is A Metric. We show the backbone inﬁnity distance is a
metric. We start by proving that the triangle inequality holds.

Lemma 8.8 (Backbone Inﬁnity Distance Satisﬁes Triangle Inequality). Let x, y, z be backbones.
Then,

dB∞(x, z) ≤ dB∞(x, y) + dB∞(y, z)

Proof. Let α1 : [k] → (cid:101)x × (cid:101)y, α2 : [m] → (cid:101)y × (cid:101)z be optimal alignments. Consider the composition
alignment α2 ◦ α1 from Construction 8.4. Deﬁne A as in Construction 8.4,
Ax := {(x, y) ∈ im(α1) | ∃z ∈ z s.t. (y, z) ∈ im(α2)},

and

Let

Az := {(y, z) ∈ im(α2) | ∃x ∈ x s.t. (x, y) ∈ im(α1)}.

C1 :=

max
(x,z)∈im(α2◦α1)

{|wx − wz|}, C2 =

max
(x,0)∈im(α2◦α1)

{wx}, C3 =

max
(0,z)∈im(α2◦α1)

{wz}.

Because dB∞(x, z) is computed from an optimal alignment between x and z, then

dB∞(x, z) ≤ max{C1, C2, C3}.
Suppose max{C1, C2, C3} = C1. Let (x, z) ∈ im(α2 ◦ α1) such that |wx − wz| = C1. Observe
since (x, z) ∈ im(α2 ◦ α1) then there exists y ∈ y such that (x, y) ∈ im(α1) and (y, z) ∈ im(α2).
This observation and the triangle inequality from the L1-norm implies

|wx − wz| ≤ |wx − wy| + |wy − wz|
≤ dB∞(x, y) + dB∞(y, z).

Hence, in the case max{C1, C2, C3} = C1, we have dB∞(x, z) ≤ dB∞(x, y) + dB∞(y, z).

Next, suppose max{C1, C2, C3} = C2. Let (x, 0) ∈ im(α2 ◦ α1) such that wx = C2. Deﬁne

X(y,0) := {(x, 0) ∈ im(α2 ◦ α1) | ∃y ∈ y s.t. (x, y) ∈ im(α1) \ Ax}.
Observe, if (x, y) ∈ im(α1) \ Ax, then for all z ∈ z, (y, z) /∈ im(α2). Hence, (y, 0) ∈ im(α2). This
implies the set

(x × {0}) ∩ im(α2 ◦ α1) = ((x × {0}) ∩ im(α1)) ∪ X(y,0)

and this union is disjoint. Either (x, 0) ∈ (x × {0}) ∩ im(α1) or (x, 0) ∈ X(y,0).
(x × {0}) ∩ im(α1), then

If (x, 0) ∈

C2 = wx ≤ dB∞(x, y) ≤ dB∞(x, y) + dB∞(y, z).
Now suppose (x, 0) ∈ X(y,0). By deﬁnition of X(y,0), there exists y ∈ y such that (x, y) ∈ im(α1)\Ax
and, at the same time, (y, 0) ∈ im(α2). Noting this observation and applying the triangle inequality
from the L1-norm gives

wx ≤ |wx − wy| + wy

≤ dB∞(x, y) + dB∞(y, z).

48

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

We can conclude that in the case max{C1, C2, C3} = C2 that dB∞(x, z) ≤ dB∞(x, y) + dB∞(y, z).
Lastly, suppose max{C1, C2, C3} = C3. Let (0, z) ∈ im(α2 ◦ α1) such that wz = C3. Deﬁne

Z(0,y) := {(0, z) ∈ im(α2 ◦ α1) | ∃y ∈ y s.t. (y, z) ∈ im(α2) \ Az}.

Similarly, the set

({0} × z) ∩ im(α2 ◦ α1) = (({0} × z) ∩ im(α2)) ∪ Z(0,y)

and this union is disjoint. Either (0, z) ∈ ({0} × z) ∩ im(α2) or (0, z) ∈ Z(0,y).
({0} × z) ∩ im(α2), then

If (0, z) ∈

C3 = wz ≤ dB(y, z) ≤ dB(x, y) + dB(y, z).

Now suppose (0, z) ∈ Z(0,y). By deﬁnition of Z(0,y), there exists y ∈ y such that (y, z) ∈ im(α2)\Az
and (0, y) ∈ im(α1). Noting this observation and applying the triangle inequality from the L1-norm,
we get

wz ≤ |wz − wy| + wy

≤ dB∞(y, z) + dB∞(x, y).

We can conclude in the case max{C1, C2, C3} = C3 that dB∞(x, z) ≤ dB∞(x, y) + dB∞(y, z).

Therefore, the backbone inﬁnity distance satisﬁes the triangle inequality.

(cid:3)

Proposition 8.9 (Backbone Inﬁnity Distance is a Metric). Let x, y, z be backbones. The backbone
inﬁnity distance (Deﬁnition 5.1) satisﬁes all properties of a metric.

Proof. Recall that for each x ∈ x, we can write x = (sx, wx); likewise for y ∈ y. Let α : [k] → (cid:101)x × (cid:101)y
be an optimal alignment. We verify all properties of a metric.

Non-Negativity. Since all node weights are non-negative, dB∞(x, y) ≥ 0.
Symmetry. By construction, dB∞ is symmetric; see Deﬁnition 5.1.
Deﬁniteness. If x = y, then the optimal alignment aligns each node with itself, and there are no

insertions. Hence, all node weights match and dB∞(x, y) = 0.
On the other hand, assume dB∞(x, y) = 0. This implies

0 = inf
α

max |ωx(αx(i)) − ωy(αy(i))|.

Therefore, |ωx(αx(i)) − ωy(αy(i))| ≤ 0 for all i ∈ [n]. Furthermore, |ωx(αx(i)) − ωy(αy(i))| ≥ 0 for
all i ∈ [n]. Thus, |ωx(αx(i)) − ωy(αy(i))| = 0 for all i ∈ [n]. Hence, each aligned pair of nodes must
have the same node weight. By Deﬁnition 4.4, we never align two empty nodes. This implies each
node in x is aligned with a node in y. Furthermore, each aligned pair must have the same label by
Deﬁnition 4.4. We can conclude x = y.

Triangle Inequality. By Lemma 8.8, the triangle inequality holds.
Therefore, the backbone inﬁnity distance is a metric.

(cid:3)

8.5. Lemmas Used For Proving Lemma 8.12 that Direct Alignment is Optimal and
Unique when Functions are Extremely Close.

Lemma 8.10 (Extremal Pairs With Node Life Diﬀerences Greater Than ε). Let f, f (cid:48) : C → R be
nicely tame functions such that f (cid:48) is extremely close to f . Let ε := (cid:107)f − f (cid:48)(cid:107)∞. Let (t, f (t)) be a
local minimum of f and (t(cid:48), f (cid:48)(t(cid:48))) be a local minimum of f (cid:48). Suppose p := (f (t), ζf (t)) ∈ D(f ) \ ∆
and q := (f (cid:48)(t(cid:48)), ζf (cid:48)(t(cid:48))) ∈ D(f (cid:48)) ∩ (cid:3)ε(p). Then,

(1) 1
(2) | 1

2 persf (cid:48)(t(cid:48)) > ε.
2 persf (cid:48)(t(cid:48)) − 1

2 persf (s)| > ε for all (f (s), ζf (s)) ∈ D(f ) \ (cid:3)ε(p).

Proof. Suppose p := (f (t), ζf (t)) ∈ D(f ) \ ∆ and q := (f (cid:48)(t(cid:48)), ζf (cid:48)(t(cid:48))) ∈ D(f (cid:48)) ∩ (cid:3)ε(p).

EXTREMAL EVENT GRAPHS

49

(1) We ﬁrst show 1

2 persf (cid:48)(t(cid:48)) > ε. Consider (cid:3)4ε(p). Since f (cid:48) is extremely close to f , ε < δf /2.
Hence, 4ε < 2δf . Recall 2δf is at most the smallest distance between any two points in
D(f ), provided that at least one point is not on the diagonal. Therefore, (cid:3)4ε(p) does not
intersect the diagonal. Consider a square of radius 4ε where the right bottom corner is the
point (f (t) + 4ε, f (t) + 4ε), that is, (cid:3)4ε((f (t), f (t) + 8ε)). Since q ∈ D(f (cid:48)) ∩ (cid:3)ε(p), the
diﬀerence of the y- and x- coordinates of q (which is the persistence of q) is bounded below
by the diﬀerence of y- and x- coordinates of the point (f (t) + ε, f (t) + 7ε), see Figure 16a.
Hence,

1
2

persf (cid:48)(t(cid:48)) >

1
2

((f (t) + 7ε) − (f (t) + ε)) = 3ε > ε.

(2) Let (f (s), ζf (s)) ∈ D(f ) \ (cid:3)ε(p). Since f (cid:48) is extremely close to f , ε < δf /2 and hence
2ε < δf . Since δf is at most half the smallest distance between two points in D(f ) where at
least one point is not on the diagonal, the squares of radius 2ε centered at diﬀerent points
in D(f ) \ ∆ are all disjoint. This implies

(cid:107)(f (t), ζf (t)) − (f (s), ζf (s))(cid:107)∞ > 2ε.

Furthermore, by the direct alignment, we know q ∈ (cid:3)ε(p). This implies q /∈ (cid:3)2ε((f (s), ζf (s))).
Consider the point ((f (s) − 2ε), ζf (s)). From planar geometry (See Figure 16b),
|persf (cid:48)(t(cid:48)) − persf (s)| > |(ζf (s) − f (s)) − (ζf (s) − (f (s) − 2ε))| = 2ε.

Therefore, 1

2 |persf (cid:48)(t(cid:48)) − persf (s)| > ε.

(cid:3)

(a) Case 1

(b) Case 2

Figure 16. Geometric Arguments for Lemma 8.10. In Figure 16a, 1
1
2 ((f (t) + 7ε) − (f (t) + ε) = 3ε > ε. In Figure 16b, 1
1
2 |(ζf (s) − f (s)) − (ζf (s) − (f (s) − 2ε))| = ε.

2 persf (cid:48)(t(cid:48)) >
2 |persf (cid:48)(t(cid:48)) − persf (s)| >

Next, we need the following technical lemma that is used to prove the uniqueness and optimality

of the direct alignment for extremely close and nicely tame functions.

∞}4εf(t)6εf(t)+εf(t)+8ε(f(t)+4ε,f(t)+4ε)f(t)+7ε}ε∞}2εf(s)ζf(s)f(s)−2ε50

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

Lemma 8.11 (Bijections Within Boxes). Let f, f (cid:48) : C → R be nicely tame functions such that f (cid:48) is
extremely close to f . Let α be the direct alignment deﬁned in Construction 5.8 between x := B(f )
and x(cid:48) := B(f (cid:48)). Suppose η is a diﬀerent alignment between x and x(cid:48) such that cost(η) ≤ cost(α).
For each x(cid:48) ∈ x(cid:48), let xα ∈ (cid:101)x be the unique element such that (xα, x(cid:48)) ∈ im(α). For each x(cid:48) ∈ x(cid:48),
deﬁne xη similarly. Suppose there exists x(cid:48) ∈ x(cid:48) such that

|wx(cid:48) − wxη | ≤ |wx(cid:48) − wxα|

and xη (cid:54)= xα. Then

(1) |wx(cid:48) − wxη | = |wx(cid:48) − wxα|.
(2) There exists z(cid:48) ∈ x(cid:48) for which |wz(cid:48) − wxη | > ε where ε := (cid:107)f − f (cid:48)(cid:107)∞.

Proof. We prove Statement (1).

Let (t(cid:48), f (cid:48)(t(cid:48))) be the local extemum of f (cid:48) associated with node x(cid:48), and let (t, f (t)) be the local
extremum of f associated with xα. Without loss of generality, we asume (t(cid:48), f (cid:48)(t(cid:48))) is a local
minimum. (Note that if (t(cid:48), f (cid:48)(t(cid:48))) is a local maximum, then we apply the same argument with −f (cid:48)
and −f ). Since (xα, x(cid:48)) ∈ im(α), we know that (t, f (t)) is also a local minimum. We ﬁrst prove,
by the way of contradiction, that neither xη nor xα is the empty node.

If xη is the empty node, then, by the assumption xη (cid:54)= xα, it follows that xα is not the empty

node. From Construction 5.8, we know that (f (cid:48)(t(cid:48)), ζf (cid:48)(t(cid:48))) ∈ D(f (cid:48)) ∩ (cid:3)ε(f (t), ζf (t)).

Applying Lemma 8.10, we ﬁnd

(15)

wx(cid:48) > ε.

On the other hand, by assumption,

|wx(cid:48) − wxη | ≤ |wx(cid:48) − wxα| ≤ ε,
where the last inequality follows from Lemma 5.10. Finally, using (15) and that wxη = 0, we have
|wx(cid:48) − wxη | = wx(cid:48) > ε,

giving a contradiction. Therefore, we conclude that xη is not the empty node.

If xα is the empty node, then by the same argument as above, we arrive at contradiction.

Therefore, xα is also not the empty node.

Therefore, neither xη nor xα is an empty node. Let (sη, f (sη)) be the local extremum of f
associated with node xη. By Lemma 5.10, |wx(cid:48) − wxα| ≤ ε. Additionally, consider the point
p = (f (sη), ζf (sη)) ∈ D(f ) and (cid:3)ε(p). In Construction 5.8, we established a bijection between the
multiplicity of p, denoted µ(p), and the number of points contained in D(f (cid:48)) ∩ (cid:3)ε(p). Additionally,
in Lemma 5.10, we showed for all points (f (cid:48)(x), ζf (cid:48)(x)) ∈ D(f (cid:48)) ∩ (cid:3)ε(p), we have 1
2 |persf (cid:48)(x) −
persf (sη)| ≤ ε. Furthermore, by Lemma 8.10, 1
2 |persf (cid:48)(y) − persf (sη)| > ε for all (f (cid:48)(y), ζf (cid:48)(y)) ∈
D(f (cid:48)) \ (cid:3)ε(p). By assumption,
(16)

|wx(cid:48) − wxη | ≤ |wx(cid:48) − wxα| ≤ ε.
Let (sα, f (sα)) be the local extremum of f associated with node xα. Since the only point of D(f )
contained in the square (cid:3)ε(p) is the point p with multiplicity µ(p), we must have (f (sη), ζf (sη)) =
(f (sα), ζf (sα)) in order for (16) to hold. Therefore, the two extrema of f have the same node lives
and thus wxη = wxα. We can conclude

|wx(cid:48) − wxη | = |wx(cid:48) − wxα|,

as was to be shown to prove Statement (1).

Next we prove Statement (2). We note that the ε-extremal intervals discussed in this proof
are all constructed from f . We claim there exists a local extremum (s(cid:48), f (cid:48)(s(cid:48))) of f (cid:48) such that
(f (cid:48)(s(cid:48)), ζf (cid:48)(s(cid:48))) ∈ D(f (cid:48))∩(cid:3)ε(p) and is aligned via η with an extremum (s, f (s)) such that (f (s), ζf (s)) ∈
D(f ) \ (cid:3)ε(p). By way of contradiction, suppose that is not the case. Hence, all persistence points
in D(f (cid:48)) ∩ (cid:3)ε(p) are paired with persistence points in D(f ) ∩ (cid:3)ε(p). Since η (cid:54)= α, η restricted to

EXTREMAL EVENT GRAPHS

51

D(f ) ∩ (cid:3)ε(p) is a bijection onto D(f (cid:48)) ∩ (cid:3)ε(p) that is diﬀerent from the bijection α. In other words,
if we denote γ := α|D(f )∩(cid:3)ε(p) and γ(cid:48) := η|D(f )∩(cid:3)ε(p), we have γ (cid:54)= γ(cid:48). By Construction 5.8 of α and
noting η (cid:54)= α, there exists an extremum (s(cid:48), f (cid:48)(s(cid:48))) that aligns via η with an extremum (s, f (s))
such that s(cid:48) does not belong to the interval of size ε around s; that is, s(cid:48) /∈ ϕε(s). Without loss of
generality, suppose s < s(cid:48). Since f (cid:48) is extremely close to f , the number of extrema with persistence
points contained in (D(f ) ∪ D(f (cid:48))) ∩ (cid:3)ε(p) where the domain coordinates are greater than s is the
same for both f and f (cid:48). Let

A := {(t, f (t)) | (f (t), ζf (t)) ∈ D(f ) ∩ (cid:3)ε(p) and t > s}
be the set of extrema of f whose persistence points are contained in D(f ) ∩ (cid:3)ε(p) such that the
domain coordinates of these extrema are greater than s. Additionally, let

B := {(t, f (cid:48)(t)) | (f (cid:48)(t), ζf (cid:48)(t)) ∈ D(f (cid:48)) ∩ (cid:3)ε(p) and t > s(cid:48)}

To preserve order in η, elements of A must be aligned with the elements of B. Since |A| > |B|,
by the pigeonhole principle, at least two extrema of f are aligned by η with the same extremum
of f (cid:48). This contradicts the fact that η is a bijection. This contradiction shows that there exists a
z ∈ x(cid:48) for which |wz(cid:48) − wzη | > ε. By construction of the direct alignment, |wz(cid:48) −wzη | ≤ ε. Therefore,
|wz(cid:48) − wzη | > |wz(cid:48) − wzη |.

(cid:3)

Next, we prove the uniqueness and optimality of the direct alignment for extremely close and

nicely tame functions.

: C → R be
Lemma 8.12 (Direct Alignment Gives Optimal Backbone Alignment). Let f, f (cid:48)
nicely tame functions such that f (cid:48) is extremely close to f . Then, the direct alignment deﬁned in
Construction 5.8 is the unique optimal alignment that realizes dB(B(f ), B(f (cid:48))).

Proof. Let α be the direct alignment between x := B(f ) and x(cid:48) := B(f (cid:48)). Recall in Deﬁnition 4.1
that each x ∈ x can be written as a tuple x = (sx, wx); likewise, we can write x(cid:48) ∈ x(cid:48) as x(cid:48) =
(sx(cid:48), wx(cid:48)). By way of contradiction, suppose η is a diﬀerent alignment between x and x(cid:48) such that
cost(η) ≤ cost(α). Recall from the construction of the direct alignment (Construction 5.8) that
the length of the direct alignment is the number of nodes in x(cid:48). By Construction 5.8, for each
x(cid:48) ∈ x(cid:48), there exists a unique xα ∈ (cid:101)x such that (xα, x(cid:48)) ∈ im(α). Hence, we can write

cost(α) =

(cid:88)

|wx − wx(cid:48)| =

(x,x(cid:48))∈im(α)

(cid:88)

x(cid:48)∈x(cid:48)

|wx(cid:48) − wxα|.

Since η is an alignment, it must align all nodes of x(cid:48). Hence, we have len η ≥ len x(cid:48) = len α. Let xη
denote the unique element of (cid:101)x such that (xη, x(cid:48)) ∈ im(η). We now discuss the following logical
dichotomy: either
Case 1: for all x(cid:48) ∈ x(cid:48), |wx(cid:48) − wxη | > |wx(cid:48) − wxα|, or
Case 2: there exists at least one x(cid:48) ∈ x(cid:48) for which |wx(cid:48) − wxη | ≤ |wx(cid:48) − wxα|.

We ﬁrst consider Case 1. Suppose, for all x(cid:48) ∈ x(cid:48), we have |wx(cid:48) − wxη | > |wx(cid:48) − wxα|. Since η

aligns all nodes of x(cid:48), we have the ﬁrst inequality below

cost(η) ≥

>

(cid:88)

x(cid:48)∈x(cid:48)
(cid:88)

|wx(cid:48) − wxη |

|wx(cid:48) − wxα|

x(cid:48)∈x(cid:48)
= cost(α).

This is a contradiction with cost(η) ≤ cost(α).

52

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

Now, we consider Case 2. Suppose there exists x(cid:48) ∈ x(cid:48) for which

(17)

|wx(cid:48) − wxη | ≤ |wx(cid:48) − wxα|.
If xη = xα for all such x(cid:48) ∈ x(cid:48), then we get that either η is the same alignment as α or there must
exist y(cid:48) ∈ x(cid:48) for which (17) is not true and hence |wy(cid:48) − wyη | > |wy(cid:48) − wyα|. In particular, since for
all instances where |wx(cid:48) − wxη | ≤ |wx(cid:48) − wxα|, xη = xα, this implies |wx(cid:48) − wxη | = |wx(cid:48) − wxα|. For
all other y(cid:48) ∈ x(cid:48), we must have |wy(cid:48) − wxη | > |wy(cid:48) − wxα|. Therefore in this case, cost(η) > cost(α).
In either case, we have a contradiction with cost(η) ≤ cost(α).

Hence, there must exist some x(cid:48) ∈ x(cid:48) for which (17) holds and xη (cid:54)= xα.
In Lemma 8.11, we show that both of the following statements are true:
(a) |wx(cid:48) − wxη | = |wx(cid:48) − wxα|.
(b) There exists a z(cid:48) ∈ x(cid:48) for which |wz(cid:48) − wxη | > ε where ε := (cid:107)f − f (cid:48)(cid:107)∞.

From (a) and (b), we ﬁnd that for all x(cid:48) ∈ x(cid:48) for which |wx(cid:48) − wxη | ≤ |wx(cid:48) − wxα| and xη (cid:54)= xα, the
equality |wx(cid:48) − wxη | = |wx(cid:48) − wxα| must hold. Furthermore, there exists z(cid:48) ∈ x(cid:48) for which

For all remaining y(cid:48) ∈ x(cid:48), we have

Putting this all together, we obtain

|wz(cid:48) − wzη | > |wz(cid:48) − wzα|.

|wy(cid:48) − wyη | ≥ |wy(cid:48) − wyα|.

cost(η) ≥

>

(cid:88)

x(cid:48)∈x(cid:48)
(cid:88)

|wx(cid:48) − wxη |

|wx(cid:48) − wxα|

x(cid:48)∈x(cid:48)
= cost(α),

which again contradicts the assumption that cost(η) ≤ cost(α).

We conclude that any alignment that is diﬀerent from the direct alignment has a higher cost.
Therefore, the direct alignment is the unique optimal alignment that realizes dB(x, x(cid:48)) = dB(B(f ), B(f (cid:48))).

(cid:3)

8.6. Cases for Bound Diﬀerences in Edge Weights in Lemma 5.20.

(1) Ediﬀ = 1

2 |pers(t) − pers(t(cid:48))|. Applying Lemma 5.16, we ﬁnd

Ediﬀ =

1
2

|pers(t) − pers(t(cid:48))| ≤ εi ≤ εi,j.

(2) Ediﬀ = 1

2 |pers(s) − pers(s(cid:48))|. Applying Lemma 5.16, we ﬁnd

Ediﬀ =

1
2

|pers(s) − pers(s(cid:48))| ≤ εj ≤ εi,j.

(3) Ediﬀ = |ε∗(t, s) − ε∗(t(cid:48), s(cid:48))|. Applying Lemma 5.19, we ﬁnd
Ediﬀ = |ε∗(t, s) − ε∗(t(cid:48), s(cid:48))| ≤ εi,j.

(4) Ediﬀ = 1

2 (pers(t) − pers(s(cid:48))). Then, pers(t) ≤ pers(s). Applying Lemma 5.16, we ﬁnd

Ediﬀ =

1
2

(pers(t) − pers(s(cid:48))) ≤

1
2

(pers(s) − pers(s(cid:48))) ≤ εj ≤ εi,j.

EXTREMAL EVENT GRAPHS

53

(5) Ediﬀ = 1

2 (pers(s(cid:48)) − pers(t)). Then, pers(s(cid:48)) ≤ pers(t(cid:48)). Applying Lemma 5.16, we ﬁnd

Ediﬀ =

1
2

(pers(s(cid:48)) − pers(t)) ≤

1
2

(pers(t(cid:48)) − pers(t)) ≤ εi ≤ εi,j.

(6) Ediﬀ = 1

2 (pers(s) − pers(t(cid:48))). Then, pers(s) ≤ pers(t). Applying Lemma 5.16, we ﬁnd

Ediﬀ =

1
2

(pers(s) − pers(t(cid:48))) ≤

1
2

(pers(t) − pers(t(cid:48))) ≤ εi ≤ εi,j.

(7) Ediﬀ = 1

2 (pers(t(cid:48)) − pers(s)).Then, pers(t(cid:48)) ≤ pers(s(cid:48)). Applying Lemma 5.16, we ﬁnd

Ediﬀ =

1
2

(pers(t(cid:48)) − pers(s)) ≤

1
2

(pers(s(cid:48)) − pers(s)) ≤ εj ≤ εi,j.

(8) Ediﬀ = ε∗(t, s) − 1

2 pers(t(cid:48)). Then, ε∗(t, s) ≤ 1

2 pers(t). Applying Lemma 5.16, we ﬁnd

Ediﬀ = ε∗(t, s) −

pers(t(cid:48)) ≤

1
2

1
2

(pers(t) − pers(t(cid:48))) ≤ εi ≤ εi,j.

(9) Ediﬀ = 1

2 pers(t(cid:48)) − ε∗(t, s). Then, 1
1
2

Ediﬀ =

pers(t(cid:48)) − ε∗(t, s) ≤ ε∗(t(cid:48), s(cid:48)) − ε∗(t, s) ≤ εi,j.

2 pers(t(cid:48)) ≤ ε∗(t(cid:48), s(cid:48)). Applying Lemma 5.19, we ﬁnd

(10) Ediﬀ = ε∗(t, s) − 1

2 pers(s(cid:48)). Then, ε∗(t, s) ≤ 1

2 pers(s). Applying Lemma 5.16, we ﬁnd

Ediﬀ = ε∗(t, s) −

pers(s(cid:48)) ≤

1
2

1
2

(pers(s) − pers(s(cid:48))) ≤ εj ≤ εi,j.

(11) Ediﬀ = 1

2 pers(s(cid:48)) − ε∗(t, s). Then, 1
1
2

Ediﬀ =

pers(s(cid:48)) − ε∗(t, s) ≤ ε∗(t(cid:48), s(cid:48)) − ε∗(t, s) ≤ εi,j.

2 pers(s(cid:48)) ≤ ε∗(t(cid:48), s(cid:48)). Applying Lemma 5.19, we ﬁnd

(12) Ediﬀ = ε∗(t(cid:48), s(cid:48)) − 1

2 pers(t). Then, ε∗(t(cid:48), s(cid:48)) ≤ 1

2 pers(t(cid:48)). Applying Lemma 5.16, we ﬁnd

Ediﬀ = ε∗(t(cid:48), s(cid:48)) −

1
2

pers(t) ≤

1
2

(pers(t(cid:48)) − pers(t)) ≤ εi ≤ εi,j.

(13) Ediﬀ = 1

2 pers(t) − ε∗(t(cid:48), s(cid:48)). Then 1
1
2

Ediﬀ =

pers(t) − ε∗(t(cid:48), s(cid:48)) ≤ ε∗(t, s) − ε∗(t(cid:48), s(cid:48)) ≤ εi,j.

2 pers(t) ≤ ε∗(t, s). Applying Lemma 5.19, we ﬁnd

(14) Ediﬀ = ε∗(t(cid:48), s(cid:48)) − 1

2 pers(s). Then, ε∗(t(cid:48), s(cid:48)) ≤ 1

2 pers(s(cid:48)). Applying Lemma 5.16, we ﬁnd

Ediﬀ = ε∗(t(cid:48), s(cid:48)) −

1
2

pers(s) ≤

1
2

(pers(s(cid:48)) − pers(s)) ≤ εj ≤ εi,j.

(15) Ediﬀ = 1

2 pers(s) − ε∗(t(cid:48), s(cid:48)). Then 1
1
2

Ediﬀ =

pers(s) − ε∗(t(cid:48), s(cid:48)) ≤ ε∗(t, s) − ε∗(t(cid:48), s(cid:48)) ≤ εi,j.

2 pers(s) ≤ ε∗(t, s). Applying Lemma 5.19, we ﬁnd

54

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

Distance

Mean Median Standard Deviation

dED(DAG( ˆD1), DAG( ˆD2)) 123.13
dED(DAG( ˆD1), DAG( ˆD(cid:48)
2)) 267.97
dED(DAG( ˆD1), DAG( ˆD3)) 143.44
dED(DAG( ˆD1), DAG( ˆD(cid:48)
3)) 301.70
dED(DAG( ˆD1), DAG( ˆD4)) 282.00
dED(DAG( ˆD1), DAG( ˆD(cid:48)
4)) 424.06

122.68
268.18
142.20
302.38
279.72
421.20

22.12
28.68
30.37
30.55
56.59
53.24

Table 1. Summary of Results from Parasite Data.

8.7. Applications. We provide tables summarizing the results of the computations described in
Section 6.2.

Distance

Mean Median Standard Deviation

dED(DAG( ˆDa), DAG( ˆDb)) 493.40
dED(DAG( ˆDa), DAG( ˆD(cid:48)
b)) 642.51
dED(DAG( ˆDa), DAG( ˆDc)) 436.17
dED(DAG( ˆDa), DAG( ˆD(cid:48)
c)) 607.97

490.88
640.78
432.42
607.06

71.38
66.70
59.62
60.33

Table 2. Summary of Results from Mouse Data.

9. Supplementary Materials - Computations of Extremal Event DAGs and

Extremal Event Supergraphs

We describe how to compute the extremal event DAG and extremal event DAG distance. Since
experimental time series data often collects discrete time points as opposed to continuous functions,
we ﬁrst take a detour to discuss ε-extremal intervals and their associated properties in the discrete
setting.

9.1. Discrete ε-Extremal Intervals.

Deﬁnition 9.1 (Collection of Time Series). A set D = {Dj}K
series Dj on the closed interval C := [a, b] where Dj = {(zi, hj
i )}N
Z := {z1 = a, z2, . . . , zN −1, zN = b},

j=1 is a dataset composed of time
j=1 with

is an ordered set with zj < zj+1 and the heights hi
series i.

j are the heights of the jth points at zj of time

For our purposes, we assume that Z denotes the progression of time. However, the following

results hold even when Z denotes some ordered quantity other than time, for example, distance.
Deﬁnition 9.2 (Discrete ε-Extremal Intervals). Let fi : [a, b] → R be the linear interpolation of
the time series Di. Let ε > 0, and suppose fi has a local extremum at t. Deﬁne the discrete
ε-extremal interval to be a relatively open interval dfi

ε (t) ⊂ [a, b] with endpoints in Z such that

(1) dDi
(2) dDi

ε (t)

ε (t) ⊃ ϕfi
ε (t) is the minimal such interval, meaning there does not exist an interval I with endpoints
in Z such that dDi

ε (t) (cid:41) I ⊃ ϕfi

ε (t).

We note that we omit the superscript Di from dDi
ε
A few properties of ε-extremal intervals still hold in the discrete case. Namely, Propositions 1
and 2 of [5]. Proposition 1 implies that as long as ε does not exceed the node life of two local

if the function is clear.

EXTREMAL EVENT GRAPHS

55

minima (tj, fi(tj)), (tk, fi(tk)) of Di, then dε(tj) ∩ dε(tk) = ∅. Proposition 2 implies that as long
as ε does not exceed the node of life of the extremum at tj, then any ε-perturbation of fi has a
local minimum contained in dε(tj). The ε-extremal interval property that is lost is minimality,
which is Proposition 3 of [5]. This proposition states that the ε-extremal intervals are the smallest
intervals to guarantee extrema of ε-perturbations of fi, given the node lives of extrema is less than
ε. Since discrete ε-extremal intervals contain the ones we would get from the linear interpolations,
we cannot guarantee minimality. A more thorough discussion of these properties in the discrete
case can be found in Section 4.2 of [5].

In regards to properties mentioned in this paper, Statement (1) of Lemma 8.2 states ε-extremal
intervals grow as ε increases also holds in the discrete setting. This is because the computation
of the discrete ε-extremal intervals is the same as the continuous case except that the intervals
are widened so that the endpoints are contained in the domain of the time series. This added
computation does not aﬀect the monotonicity of growth in the ε-extremal intervals.

Lemma 9.3 (Monotonicity of dε(ti)). Let Dj be a time series with t1 < t2 < ... < tn the domain
coordinates of the local extrema. Then, for each i ∈ [n], the length len(dε(ti)) is increasing with
respect to ε.

Additionally, Statement (2) of Lemma 8.2 holds in the discrete case. We prove that here since

we apply it in Section 9.2.

Lemma 9.4 (Containment Property of Discrete ε-Extremal Intervals). Let Dj be a time series with
domain coordinates {ti}n
i=1 for i ∈ [n] where t1 < t2 < ... < tn. Suppose Dj has a local minimum at
ti where i ≤ n − 1. Then, ε ≤ 1

2 |fj(ti) − fj(ti+1)| if and only if ti+1 /∈ dε(ti).

Proof. Let ti be the domain coordinate of a local minimum of Dj. For this proof we omit the
subscript j from Dj and its linear interpolation fj.

First assume ε ≤ 1

2 |f (ti) − f (ti+1)|. We show ti+1 /∈ dε(ti). Since ti is the domain coordinate of

a local minimum, f (ti) < f (ti+1). Thus,

ε ≤

1
2

(f (ti+1) − f (ti))

f (ti) + ε ≤ f (ti+1) − ε.
This implies ti+1 /∈ (f − ε)−1(−∞, f (ti) + ε). Hence, ti+1 /∈ ϕε(ti). By Deﬁnition 9.2, the right
endpoint of dε(ti) is equal to ti+1, and the right half of this interval is open. Hence, ti+1 /∈ dε(ti).
2 |f (ti) − f (ti+1)|. We do this by proving the
2 |f (ti)−f (ti+1)|. Since ti is the domain coordinate of a local minimum,

Next we prove that ti+1 /∈ dε(ti) implies ε ≤ 1

contrapositive. Assume ε > 1
f (ti) < f (ti+1). Thus,

ε >

1
2

(f (ti+1) − f (ti))

f (ti) + ε > f (ti+1) − ε.
This implies ti+1 ∈ (f − ε)−1(−∞, f (ti) + ε). Furthermore, ti+1 must be in the same connected
component as ti in (f − ε)−1(−∞, f (ti) + ε) since ti+1 is adjacent to ti. Therefore, ti+1 ∈ ϕε(ti).
(cid:3)
By Deﬁnition 9.2, dε(ti) ⊃ ϕε(ti). Therefore, ti+1 ∈ dε(ti).

Applying a symmetric argument as in Lemma 9.4, we see that ε ≤ 1

2 |fj(ti) − fj(ti−1)| if and only

if ti−1 /∈ dε(ti) and i ≥ 2.

In discrete time series, the idea of incomparability is reduced to intersections between a ﬁnite
number of intervals. A linear interpolation of a time series giving rise to ε-extremal intervals ϕε
results in greater values of ε∗ than the discrete intervals dε. Therefore ε∗ determined by dε is a
conservative estimate of incomparability available from the time series information.

Lastly, we remark that local stability of the extremal event DAG distance extends to the discrete
case. To see this, note the node lives of extrema in discrete functions can be computed from the

56

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

sublevel set persistence diagram obtained through linearly interpolating the values of the discrete
function. Therefore, Lemma 8.10, Lemma 8.12, Lemma 5.16, Corollary 5.17, Lemma 5.18 that are
all statements about node lives and diﬀerences in aligned node lives all extend to the discrete case.
Furthermore, the proof of Lemma 5.19 (that bounds the diﬀerence between ε-extremal intersection
values between aligned edge weights) relies on the nesting property of ε-extremal intervals. This
property still holds in the discrete case and so Lemma 5.19 also extends in the discrete case. The
proofs of Lemma 5.20 and Theorem 5.21 use the aforementioned lemmas. Therefore local stability
for extremal event DAGs holds for discrete time series.

9.2. Computing the Extremal Event DAG. In this section, we describe Algorithm 5, which
computes the extremal event DAG from a collection of time series over a closed interval. This
algorithm is based on two key insights. First, the edge weight between two local extrema from
the same function is the minimum of the node lives of the two local extrema (Statement (1) of
Theorem 3.3). Second, the edge weight between two local extrema from diﬀerent functions is the
minimum of the two node lives and the inﬁmum ε for when the two ε-extremal intervals intersect
(Statement (2) of Theorem 3.3). We ﬁrst describe the computation of merge trees that are used to
compute the node lives of local extrema.

9.2.1. Merge Trees and Node Lives. The merge tree captures the connectivity of sublevel sets of a
function. The information we get from the merge tree of a function is very similar to information
we capture from the zeroth-dimensional persistence diagram from a sublevel set ﬁltration of f .

Deﬁnition 9.5 (Merge Tree). Let f be a real-valued function. Let Γ(f ) be the graph of f . We
declare x ∼ y if there exists an h ∈ R for which x, y ∈ f −1(h) and x, y are in the same connected
component of f −1(−∞, h]. The merge tree of f , denoted Mf , is deﬁned to be the quotient space

Mf := Γ(f )/ ∼ .
Given a nicely tame function, f : C → R, we construct the structure of the merge tree, G =
(V, E), by [56]. This structure consists of a list of merge triplets where each triplet is a three-
tuple of real numbers (u, s, v) such that u represents the connected component containing itself for
a ∈ [f (u), f (s)) and v becomes the representative of the connected component at a height of f (s).
In relation to zeroth-dimensional persistence diagram from a sublevel set ﬁltration, (f (u), f (s)),
is a birth-death pair and the two connected components represented by u and v merge into the
connected component represented by v at a height of f (s).
If the merge triplet has identical
components denoted as (u, u, u), then u is the global minimum of its connected component in
G. The time complexity of computing the Merge Tree using Kruskal’s algorithm for a function
represented as a graph, G = (V, E) is O(m log n) where n = |V | and m = |E| [56]. In our setting,
the number of edges is bounded by n and so the time complexity is O(n log n).

We describe how we compute the node lives and node labels of the extremal event DAG, using
the triplets computed from the merge trees. Algorithm 1 (GetMinLives) takes input a merge
tree M for a time series D = {(zi, hi)}N
i=1. Algorithm 1 outputs the node lives of the local minima
of D. For each merge triplet with distinct components, (zi, zj, zk) in M , (hi, hj) is a point in the
zeroth-dimensional persistence diagram from the sublevel set ﬁltration. By Deﬁnition 2.12, we get
that 1
2 persD(zi) = (hj − hi)/2. If the merge triplet has all identical components, (zj, zj, zj), then
2 persD(zj) = 1
1
i=1)). Applying one of these two computations to all
merge triplets computes node lives for all local minima in D. To compute the node lives of the
local maxima, we apply the same process to −D, where we take the negative of all heights hi.

i=1) − min({hi}N

2 (max({hi}N

The algorithm GetNodeLives(D, Mmin, Mmax) applies GetMinLives twice for both D and
−D with merge trees Mmin and Mmax respectively. Suppose D has n local extrema. Each line
in Algorithm 1 takes constant time. Since the loop has at most n iterations, then the total time
complexity of Algorithm 1 is O(n). Hence, the time complexity of GetNodeLives is also O(n).

Algorithm 1 GetMinLives(D, M )

EXTREMAL EVENT GRAPHS

57

Input: Array of merge tree triplets M and time series D = {(zi, hi)}N
Output: Dictionary of node lives for each point in curve.
1: minlives ← Initialize dictionary keyed by locations of extrema
2: for (zi, zj, zk) ∈ M do
3:

if zj = zk then

i=1.

minlives(zi) ← (max({hi}N

i=1) − min({hi}N

i=1))/2

else

4:
5:
6:
7:
8: end for
9: return minlives

end if

minlives(zi) ← |hj − hi|/2

9.2.2. Computing Edge Weights. We explain how to compute the edge weights of the extremal
event DAG. First consider the edge weight between two nodes in B(f ), a single backbone. By
Statement (1) of Theorem 3.3, we know the edge weight is the minimum node life between the two
extrema. Computing the minimum between two values takes constant time.

Next, we describe how we compute the edge weight between two nodes from diﬀerent backbones.
In order to do this, we must ﬁrst compute the inﬁmum ε for which two ε-extremal intervals intersect.
In the discrete setting, the growth of the ε-extremal intervals only change at a ﬁnite number of
ε. We refer to the ε values where discontinuous changes in length occur as jumps. Algorithm 2
(GetEpsJumpsRight) computes the ε jumps for the right endpoint of an ε-extremal interval. We
recall in the discrete setting, connected components are determined by the linear interpolation of
points in the image of f . In Lemma 9.6, we use ∼ to denote the equivalence relation given by
connected components i.e., for a time series Di = {(zj, hi
j=1, and zj, zk ∈ Z, we declare zj ∼ zk
at ε > 0 if both zj, zk are contained in the same connected component of (fi − ε)−1(−∞, fi(x) + ε)
where fi is the linear interpolation of Di and x ∈ Z.

j)}N

Algorithm 2 GetEpsJumpsRight(D, zi)
Input: Time series D = {(zi, hi)}N
Output: Vector of real numbers indicating values for which the right endpoint of dε(zi) jumps.

i=1 and domain point zi ∈ Z.

epsilons ← (cid:104)|hi+1 − hi|/2(cid:105)
levelheight ← hi+1
for j ← (i + 2) . . . N do

1: Initialize epsilon array and jump height
2: if i (cid:54)= N then
3:
4:
5:
6:
7:
8:
9:
10:
11:
12: end if
13: return epsilons

epsilons append |hj − hi|/2
levelheight ← hj

end for

end if

if (extremum(zi) = min ∧ hj ≥ levelheight)
(cid:87) (extremum(zi) = max ∧ hj ≤ levelheight) then

Lemma 9.6 (Correctness of Algorithm 2). Let D = {(zi, hi)}N
i=1 be a time series. Let zi be the
domain coordinate of a local extremum of D. Let ri(ε) : R>0 → R denote the right endpoint of

58

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

dε(zi). Then, GetEpsJumpsRight(D, zi) Algorithm 2 returns all ε values for which ri has a jump
discontinuity.

Proof. We note that if i = N , then ri(ε) = zi for all ε ≥ 0. Hence, there are no jumps. GetEp-
sJumpsRight returns the empty array, which is correct. For the rest of this proof, we assume
i (cid:54)= N . To prove correctness, we show that we have the following loop invariant. At the start of
each iteration of the for loop, the array epsilons consists of jumps of ri(ε) in sorted order. We
ﬁrst remark that jump discontinuities of ri(ε) occur at the inﬁmum ε for which a point zj ∈ Z is
contained in dε(zi) with j > i. This is because in the discrete setting, the ε-extremal intervals only
grow when a new point in Z is contained in dε(zi). In particular, we show the loop invariant that
zi+j ∈ dε(cid:48)(zi), where ε(cid:48) is the maximum of the array named epsilons after the jth iteration.

Initialization: First, consider ε1 = |hi − hi+1|/2. By Lemma 9.4, zi+1 /∈ dε1(zi) and for all
ε > ε1, zi+1 ∈ dε(zi). Hence, ε1 is the inﬁmum ε for which zi+1 ∈ dε(zi). This implies
that ε1 is a jump discontinuity of ri. From Lemma 9.3, we know that dε(zi) increases
monotonically. Hence no other point in Z is contained in dε(zi) at a smaller value of ε.
Therefore, ε1 is the smallest jump discontinuity of ri(ε) and so the loop invariant holds
before the ﬁrst iteration.

Maintenance: Assume the loop invariant holds after the jth iteration. We show it also holds

after the j + 1st iteration. First assume zi is a local minimum. Then,

levelheight = max{hk | k ∈ [i + 1, i + j]}.

Denote z∗ := zi+(j+1). We want to ﬁnd the inﬁmum ε > 0 for which z∗ ∈ dε(zi).

Suppose h∗ < levelheight. We claim that z∗ ∈ dε(cid:48)(zi) where ε(cid:48) := max{epsilons}. This

means that no new ε value needs to be added to the epsilons vector in Algorithm 3. Let

z(cid:48) := argmax{hk | k ∈ [i + 1, i + j]}.

Thus h(cid:48) = levelheight. Since h∗ < levelheight = h(cid:48) and ε(cid:48) = (h(cid:48) − hi)/2, then

h∗ − hi < h(cid:48) − hi = 2ε(cid:48)
h∗ − ε(cid:48) < hi + ε(cid:48)

This implies that z∗ ∈ (f − ε(cid:48))−1(−∞, f (zi) + ε(cid:48)) (recall f is the linear interpolation of
D). Observe, zi+j ∈ dε(cid:48)(zi) by the assumption that the loop invariant holds at the jth
iteration. Since z∗ is adjacent to zi+j, z∗ must be in the same connected component of
(f − ε(cid:48))−1(−∞, f (zi) + ε(cid:48)) as zi, i.e., z∗ ∼ zi. Therefore, z∗ ∈ dε(cid:48)(zi) and the loop invariant
holds.

Next suppose h∗ ≥ levelheight. Let ε(cid:48) be as before. Applying a similar computation as
above we ﬁnd that z∗ /∈ (f − ε(cid:48))−1(−∞, f (zi) + ε(cid:48)). Observe that at ε∗ := (h∗ − hi)/2 we
have

f (z∗) − ε∗ = f (zi) + ε∗.

This leads to the observation that z∗ ∈ (f −ε)−1(−∞, hi+ε) for any ε > ε∗ by Lemma 9.3.
Since ε∗ > ε(cid:48), zi+j ∈ (f − ε)−1(−∞, f (zi) + ε) as well. Since zi ∼ zi+j by the loop invariant
and zi+j ∼ z∗ by adjacency, zi ∼ z∗ as desired for any ε > ε∗. These two observations tell
us that ε∗ is the inﬁmum ε for which z∗ ∈ dε(zi). Therefore, ε∗ should indeed be added
to the epsilons array and is larger than all other values in the array. By assumption, the
epsilons array is sorted. Hence, the loop invariant holds.

In the case that (zi, hi) is a local maximum, we apply a symmetric argument by noting
that dε(zi) is the (expanded out) connected component of (f +ε)−1(f (zi)−ε, ∞) containing
zi and a new value is added to the ε vector if hj ≤ levelheight.

End: Note that the for loop terminates since there are only a ﬁnite number of iterations.

EXTREMAL EVENT GRAPHS

59

Since the number of jumps of ri(ε) is bounded by N − i, and epsilons consists of all inﬁmum ε
for which a point in N and greater than zi is contained in dε(zi), then Algorithm 2 is correct. (cid:3)
Next, we analyze the time complexity of Algorithm 2. Every line takes constant time. Since the
for loop (Line 5-Line 11) has at most N −1 iterations, then the total time complexity of Algorithm 2
is O(N ).

Furthermore, we can apply the same algorithm but with going through points on the left of zi to
ﬁnd all the points for which the left endpoint of dε(zi) changes. Note that there are N − 1 points
to the left and right of zi combined, and so ﬁnding all ε-jumps of dε(zi) takes O(N ). We call this
combined function, GetEpsJumps (Algorithm 3).

Algorithm 3 GetEpsJumps(D, zi)

Input: Time series D = {(zi, hi)}N
Output: Vector of real numbers indicating values for which the left or right endpoint of dε(zi)
jumps.

i=1 and domain point zi ∈ Z.

1: Initialize epsilon array and jump height
2: epsilons ← {GetEpsJumpsLeft(D, zi)}
3: epsilons append GetEpsJumpsRight(D, zi)
4: return epsilons

Lastly, to ﬁnd the inﬁmum ε for which two ε-extremal intervals intersect, we apply Algorithm 4.
Algorithm 4 takes input of two time series Dj, Dk, two domain coordinates of local extrema of
Dj, Dk, and merge trees of Dj, −Dj, Dk, −Dk. Algorithm 3 (GetEpsJumps) is applied to both
functions and extrema. Then, Algorithm 4 goes through all jumps in order to ﬁnd the smallest one
for which the two ε-extremal intervals intersect.

Algorithm 4 GetEpsIntersection(Dj, Dk, zj, zk, MDj , M−Dj , MDk , M−Dk )

i )}N

i )}N

ε (zj) ∩ dDk

i=1, Dk = {(zi, hk

Input: Time series Dj = {(zi, hj
i=1 and domain points of extrema in Dj
and Dk, denoted zj, zk ∈ Z. MDj , M−Dj , MDk , M−Dk are merge trees of Dj, −Dj, Dk, −Dk
respectively.
Output: inf ε dDj
1: Initialize epsilon array
2: epsilons ← {GetEpsJumps(Dj, zj)}
3: epsilons append GetEpsJumps(Dk, zk)
4: sort epsilons
5: for ε ∈ epsilons do
6:

ε (zk) (cid:54)= ∅

dDj
ε (zj) ← GetExtremalInterval(Dj, zj, MDj , M−Dj , ε)
ε (zk) ← GetExtremalInterval(Dk, zk, MDk , M−Dk , ε)
dDk
if dDj
return ε

ε (zk) (cid:54)= ∅ then

ε (zj) ∩ dDk

7:

8:
9:
10:
11: end for

end if

Next, we discuss the time complexity of Algorithm 4. The number of jumps is bounded by the
number of points in the domains of the two functions. Additionally, at each jump, we compute
GetExtremalInterval for the two extrema, where the computation of the discrete extremal in-
tervals are discussed in [5] and implemented in [2]. In particular, the time complexity for computing
GetExtremalInterval(D, zi, MD, M−D) is O(N ). This is because computing the ε-extremal in-
terval requires evaluating f at points in Z near zi. In summary

60

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

• Line 2 and Line 3 each take O(N ).
• Line 4 takes O(N log N ).
• Line 6 and Line 7 take O(N ).
• All other lines take constant time.
• The number of iterations of the for loop in Line 5-Line 11 is bounded by 2N .

as

All together we compute the time complexity of GetEpsIntersection(Dj, Dk, zj, zk, MDj , M−Dj , MDk , M−Dk )

O(2N + N log N + 2N 2) = O(N log N + N 2).

9.2.3. Computing Extremal Event DAG. Algorithm 5 computes the extremal event DAG from a
collection of time series D = {Dj}K
j=1. Algorithm 5 uses previously deﬁned algorithms and functions
from this section along with InitializeGraph. This algorithm is designed and implemented in [2].
InitializeGraph takes a collection of time series D as input and outputs (T, H, V, E) where V, E
are vertices and directed edges of the extremal event DAG of D, T is the domain coordinates of
the local extrema, and H is the heights of local extrema. This function checks through all points
in Z for extrema to record as vertices and then goes through all vertex pairs to check for edges.
Let N = |Z|. The number of vertices is bounded by N K and the number of edges is bounded by
(cid:0)N K
2

(cid:1). Hence, the time complexity of InitializeGraph is

O(N K +

(N K)(N K − 1)
2

) = O((N K)2).

Algorithm 5 GetExtremalEventDAG(D)

Input: A collection of time series D = {Dj}K
Output: The extremal event DAG of D.

j=1.

Initialize unweighted extremal event DAG.

end if

if (T (v), H(v)) ∈ Dj then
ωV (v) ← NodeLivesj(v)

1: MDj ← merge tree for Dj
2: M−Dj ← merge tree for − Dj
3: NodeLivesj ← GetNodeLives(Dj, MDj , M−Dj )
4: (T, V, E) ← InitializeGraph(D)
5: Initialize function ωV : V → R with all values set to zero.
6: Initialize function ωE : E → R with all values set to zero.
7: for v ∈ V do
8:
9:
10:
11: end for
12:
13: for e = (u, v) ∈ E do
14:
15:
16:
17:
18:
19:
20: end for
21: return (V, E, ωV , ωE)

ωE(e) ← min(NodeLivesj(u), NodeLivesj(v))
else if (T (u), H(u)) ∈ Dj, (T (v), H(v)) ∈ Dk then

if (T (u), H(u)), (T (v), H(v)) ∈ Dj then

end if

ε ← GetEpsIntersection(Dj, Dk, T (u), T (v), MDj , M−Dj , MDk , M−Dk )
ωE(e) ← min(NodeLivesj(u), NodeLivesk(v), ε)

The correctness of Algorithm 5 follows from the correctness of all our other previously deﬁned

algorithms. Next we analyze the time complexity.
• Line 1 and Line 2 each take KO(N log N ).

EXTREMAL EVENT GRAPHS

61

• Line 3 takes KO(N ).
• Initializing the extremal event DAG in Line 4 takes O((N K)2).
• Computing all the node weights in Line 7-Line 12 has a time complexity of O(N K).
• Each iteration in the for loop between Line 13 - Line 21 takes at most O(N log N + N 2).
Since the number of vertices is bounded above by N K, then the number of edges is bounded
above by (cid:0)N K
. Thus, the number of iterations of this for loop is bounded
2
by (N K)(N K−1)

(cid:1) = (N K)(N K−1)
.
In total, we get the time complexity to be

2

2

(cid:18)

O

K(N log N ) + KN + (N K)2 + N K +

(N K)(N K − 1)
2

(cid:0)(N log N ) + N 2(cid:1)

(cid:19)

= O(N 4K2).

9.3. Computing Optimal Backbone Alignments. To compute a distance between extremal
event DAGs, we align backbones in the extremal event DAGs in an optimal manner. Here, we
describe how the alignment is computed and prove that the alignment is optimal. Recall, that α
denotes an alignment between two backbones (Deﬁnition 4.4).

Deﬁnition 9.7 (Alignment Matrix). Let x = (x1, x2, . . . , xm), y = (y1, y2, . . . , yn) be backbones.
Note that each xi can be written as the pair xi = (sx,i, wx,i); likewise each yi can be written as the
pair yi = (sy,i, wy,i). The alignment matrix, denoted mat, is an (m + 1) × (n + 1) matrix recursively
deﬁned as follows:

mat[i, j] =

k=1 wx,k,
k=1 wy,k,


0
(cid:80)i−1
(cid:80)j−1






min



mat[i − 1, j] + wx,i−1
mat[i, j − 1] + wy,j−1
mat[i − 1, j − 1] + diﬀ(xi−1, yj−1)

i = j = 1
i > 1, j = 1
i = 1, j > 1

otherwise,






where diﬀ : x × y → R≥0 ∪ {∞} is deﬁned by

diﬀ ((sx, wx), (sy, wy)) =

(cid:40)

|wx − wy|,
∞,

if sx = sy
otherwise

.

Next we note that the bottom right entry in the alignment matrix is the minimum cost of
aligning two backbones x and y. This follows from [64]. Recall the deﬁnition of the cost function
in Deﬁnition 4.6. We also prove it here.

Proposition 9.8 (Alignment Matrix Finds Minimum Cost). Let x = (x1, x2, . . . , xm) and y =
(y1, y2, . . . , yn) be backbones. Let mat be the (m + 1) × (n + 1) alignment matrix. Then, mat[m +
1, n + 1] = cx,y(m, n).

Proof. For i ∈ [n], let xi = (sx,i, wx,i) and yi = (sy,i, wy,i).

We proceed by induction. For the base case, ﬁrst observe that cx,y(1, 0) = wx,1 and cx,y(0, 1) =
wy,1. By construction, mat[2, 1] = wx,1 = cx,y(1, 0) and mat[1, 2] = wy,1 = cx,y(0, 1). Next con-
sider cx,y(1, 1). The possible alignments (see Deﬁnition 4.4) of x1 := x[1 : 1] and y1 := y[1 : 1]
are

(1) α1 : {1, 2} → (cid:101)x1 × (cid:101)y1, where α1(1) = (x1, 0) and α1(2) = (0, y1).
(2) α2 : {1, 2} → (cid:101)x1 × (cid:101)y1, where α2(1) = (0, y1) and α2(2) = (x1, 0).
(3) α3 : {1} → (cid:101)x1 × (cid:101)y1, where α3(1) = (x1, y1) is a possible alignment.

62

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

Observe cost(α1) = cost(α2) = wx,1 + wy,1 and cost(α3) = diﬀ(x1, y1) = |wx,1 − wy,1|. Therefore,

By construction,

cx,y(1, 1) = min

(cid:26) wx,1 + wy,1
diﬀ(x1, y1)

mat[2, 2] = min






mat[2, 1] + wy,1
mat[1, 2] + wx,1
mat[1, 1] + diﬀ(x1, y1)

Substituting wx,1 for mat[2, 1] , wy,1 for mat[1, 2] and zero for mat[1, 1], we ﬁnd cx,y(1, 1) =
mat[2, 2]. This shows the base case holds.

For the induction hypothesis we assume that mat[h, k] = cx,y(h − 1, k − 1) for all h ≤ i and

k ≤ j where i ≤ m and j ≤ n.

In the induction step, we show mat[i + 1, j] = cx,y(i, j − 1), mat[i, j + 1] = cx,y(i − 1, j), and
mat[i + 1, j + 1] = cx,y(i, j). First consider cx,y(i, j − 1). Let α : [k] → (cid:101)x[1 : i] × (cid:101)y[1 : j − 1] be an
alignment of the ﬁrst i nodes of x with the ﬁrst j − 1 nodes of y with cost cx,y(i, j − 1). Consider
the last pair of nodes aligned via α(k). The cost of these two nodes is either (a) the cost of xi
aligned with an insertion, (b) the cost of yj−1 aligned with an insertion, or (c) the cost of xi aligned
with yj−1. Note, by Deﬁnition 4.4, we never have an insertion aligned with an insertion. Since the
cost is the minimum across these three possibilities, the cost is

cx,y(i, j − 1) = min






cx,y(i − 1, j − 1) + wx,i
cx,y(i, j − 2) + wy,j−1
cx,y(i − 1, j − 2) + diﬀ(xi, yj−1)

Applying the induction hypothesis, we ﬁnd

cx,y(i, j − 1) = min






mat[i, j] + wx,i
mat[i + 1, j − 1] + wy,j−1
mat[i, j − 1] + diﬀ(xi, yj−1)

By construction of mat (Deﬁnition 9.7), we see that cx,y(i, j − 1) = mat[i + 1, j]. Using a similar
approach, we ﬁnd mat[i, j + 1] = cx,y(i − 1, j), and mat[i + 1, j + 1] = cx,y(i, j).

This concludes the induction argument. Thus, mat[i, j] = cx,y(i − 1, j − 1) for all i ≤ m + 1 and
(cid:3)

j ≤ n + 1. In particular, mat[m + 1, n + 1] = cx,y(m, n).

9.3.1. Finding Optimal Alignment from Alignment Matrix.

Deﬁnition 9.9 (Path). Let M be an m × n matrix with real valued entries. A path in M is an
injective function p : [k] → M such that p(i) and p(i + 1) are adjacent values in a row, column, or
diagonal for all i ∈ {1, 2, . . . , k − 1}.

To ﬁnd an optimal alignment from the alignment matrix we construct a path via backtracking.

Path via Backtracking. Let x = (x1, x2, . . . , xm) and y = (y1, y2, . . . , yn) be backbones. Let
mat be the corresponding alignment matrix. We construct a path p in mat recursively as follows:

• p(1) = mat[m + 1, n + 1]
• If p(h) = mat[i, j] for h ≥ 1 and i, j > 1, then,

p(h + 1) =






mat[i − 1, j] if mat[i, j] = mat[i − 1, j] + wx,i−1
mat[i, j − 1] if mat[i, j] = mat[i, j − 1] + wy,j−1
mat[i − 1, j − 1] if mat[i, j] = mat[i − 1, j − 1] + diﬀ(xi−1, yj−1)

If multiple of the conditions hold, then deﬁne p(h + 1) to be any one of them. We call p a
backtracking path.

EXTREMAL EVENT GRAPHS

63

In summary, we are undoing the matrix construction to ﬁgure out which matrix entries lead
to the cost in mat[m + 1, n + 1]. Once we apply backtracking, we have at least one path from
mat[m + 1, n + 1] to mat[1, 1]. We remark that backtracking is well-deﬁned. For any entry
p(h) = mat[i, j], one of the three upper left entries (mat[i − 1, j], mat[i, j − 1], mat[i − 1, j − 1])
equals p(h + 1) by construction of the alignment matrix (Deﬁnition 9.7). Since we have a ﬁnite
matrix, we eventually end at mat[1, 1]. We note that a path constructed from backtracking is
not necessarily unique. For describing the alignment from a backtracking path p : [k] → mat, we
consider the reverse path p(cid:48) : [k] → mat where p(cid:48)(i) = p(k − (i − 1)).

Figure 17. Backtracking in alignment matrix of sine backbones. Consider the
backbones x and y from Figure 7. The path p : {1, 2, . . . , 7} → (cid:101)x × (cid:101)y, constructed
from backtracking is illustrated through the black arrows and purple highlighted
entries. In particular, p(1) = mat[7, 7] = 0.115 and p(9) = mat[1, 1] = 0.

Alignment from Backtracking. Let x = (x1, x2, . . . , xm) and y = (y1, y2, . . . , yn) be backbones.
Let mat be the corresponding alignment matrix. Let p : [k] → mat be a path computed from
backtracking and p(cid:48) : [k] → mat be the reverse path. We construct an alignment α : [k − 1] → (cid:101)x × (cid:101)y
such that

α(h) =






(xi, 0)
(0, yj)
(xi, yj)

if p(cid:48)(h) = mat[i, j] and p(cid:48)(h + 1) = mat[i + 1, j]
if p(cid:48)(h) = mat[i, j] and p(cid:48)(h + 1) = mat[i, j + 1]
if p(cid:48)(h) = mat[i, j] and p(cid:48)(h + 1) = mat[i + 1, j + 1]

.

In other words, the following moves of p(cid:48) through the matrix mat mean:

• Vertical move from mat[i, j] to mat[i + 1, j] indicates an alignment of xi with an insertion.
• Horizontal move from mat[i, j] to mat[i, j+1] indicates an alignment of yj with an insertion.
• Diagonal move from mat[i, j] to mat[i + 1, j + 1] indicates an alignment of xi with yj.

Next we verify that an alignment found from backtracking is indeed an alignment.

0.25min0.50.0420.5minminmax0.042max0.25max0.25min0.0160.50.016minminmax0.5max0.25max00.250.751.251.2661.2811.5310.2500.51.01.0161.0311.2811.2390.9890.9740.9580.4580.0420.2920.3340.0840.50.9160.9320.9471.1970.8650.6150.60.5840.0840.5840.8341.3341.0840.5840.0840.10.1150.3650.1150.3340.3180.3340.8341.3341.584vvvvvvvv64

R. BELTON AND B. CUMMINS AND B. T. FASY AND T. GEDEON

Proposition 9.10 (Backtracking Finds an Alignment). Let x = (x1, x2, . . . , xm) and y = (y1, y2, . . . , yn)
be backbones. Let mat be the (m+1)×(n+1) alignment matrix. Let α : [k] → (cid:101)x×(cid:101)y be an alignment
found from backtracking. Then, α is an alignment.

Proof. We verify that α is well-deﬁned, and α satisﬁes all four properties of being an alignment
(Deﬁnition 4.4). Let p(cid:48) : [k + 1] → mat be the path used to construct α.

First we show α is well-deﬁned. Let h ∈ [k − 1] and consider α(h). Observe exactly one of
the three conditions (vertical move, horizontal move, diagonal move) that deﬁne α(h) holds by the
construction of p(cid:48), and α(h) ∈ (cid:101)x × (cid:101)y. Hence, α is well-deﬁned.

Observe by construction, α has no null alignments. Hence, Property (1) of Deﬁnition 4.4 holds.

Next we show the remaining properties.

Property (2) (Preserves Order of Backbones). We use the index function ιx and the coordinate
function αx from Deﬁnition 4.4. Suppose αx(i), αx(j) ∈ x where i < j. Suppose further that
p(cid:48)(i) = mat[q, r] and p(cid:48)(j) = mat[s, t], indicating that αx(i) = xq, αx(j) = xs. By construction of
p(cid:48) and the fact that i < j either (1) q = s and r < t or (2) q < s. We claim that only (2) holds in
our setting.

Assume for a contradiction that q = s and r < t. By construction of p(cid:48), this means that there are
only horizontal moves between p(cid:48)(i) and p(cid:48)(j). Hence, αx(i) or αx(j) or both must be the empty
node. This contradicts the assumption that both αx(i) and αx(j) are in x. Therefore q < s, and
in particular, q < s if and only if i < j.

Since αx(i) = xq and αx(j) = xs, we have the index function ιx(αx(i)) = q and ιx(αx(j)) = s
if and only if ιx(αx(i)) < ιx(αx(j)). Therefore ιx(αx(i)) < ιx(αx(j)) if and only if i < j, so that
α preserves the order of nodes in the backbone x. The same argument substituting y for x also
shows that α preserves the order of nodes in the backbone y.

Property (3) (No Misalignments). By design of mat, a misalignment has an inﬁnite cost. Since
each entry in the alignment matrix is a minimum of three values where at least two values are ﬁnite,
then mat does not contain any inﬁnite entries. This implies that when applying backtracking, we
never have a diagonal move corresponding to a misalignment.

Property (4) (Restriction to Matching). Let xi ∈ x. Recall in the deﬁnition of p(cid:48), we construct
a path using adjacent entries in the alignment matrix such that p(cid:48)(0) = mat[1, 1] and p(cid:48)(k) =
mat[1, 1]. By deﬁnition of p(cid:48), there exists a j ∈ [k + 1] such that p(cid:48)(j) = mat[i + 1, h] where
h ∈ [n + 1]. This implies that xi appears in im(αx) at least once. Similarly, for yi ∈ y, there exists
a j ∈ [k + 1] such that p(cid:48)(j) = mat[h, i + 1] where h ∈ [m + 1]. Hence yi appears in im(αy) at least
once. Furthermore, in backtracking, no same move (vertical, horizontal, or diagonal) between two
matrix entries is repeated twice. Hence, each xi ∈ x and each yi ∈ y appears in im(αx) and im(αy)
exactly once. Therefore we have a restriction to matching.

(cid:3)

We now prove that an alignment found using this backtracking has a cost equal to mat[m +

1, n + 1].

Proposition 9.11 (Backtracking Finds Alignment with Cost Computed from Alignment Matrix).
Let x = (x1, x2, . . . , xm) and y = (y1, y2, . . . , yn) be backbones. Let mat be the (m + 1) × (n + 1)
alignment matrix. Let α : [k] → (cid:101)x × (cid:101)y be an alignment found from backtracking. Then, cost(α) =
mat[m + 1, n + 1].

Proof. Let p(cid:48) : [k+1] → mat be the path used to construct α. We show cost(α) = mat[m+1, n+1].
To do this, we prove cost(α[1 : h]) = p(cid:48)(h+1) for all h ≤ k by induction. For the base case, consider
α[1 : 1] = α(1). There are three possibilities for α(1). Either:

(1) α(1) = (x1, 0)
(2) α(1) = (0, y1)
(3) α(1) = (x1, y1).

EXTREMAL EVENT GRAPHS

65

Recall that xi ∈ x can be expanded as xi = (sx,i, wx,i); likewise, for yi ∈ y, we can write yi =
(sy,i, wy,i). If (1), then cost(α(1)) = wx,1 = mat[2, 1] = p(cid:48)(2). If (2), then cost(α(1)) = wy,1 =
mat[1, 2] = p(cid:48)(2). If (3), then cost(α(1)) = diﬀ(x1, y1) = mat[2, 2] = p(cid:48)(2). In all three cases we
ﬁnd cost(α(1)) = p(cid:48)(2).

Next, we assume the induction hypothesis that cost(α[1 : h]) = p(cid:48)(h + 1) for some h < k.
Suppose p(cid:48)(h + 1) = mat[i, j]. There are three possibilities for α(h + 1). Either
(1) α(h + 1) = (xi, 0)
(2) α(h + 1) = (0, yj)
(3) α(h + 1) = (xi, yj).

If (1), then

cost(α[1 : h + 1]) = cost(α[1 : h]) + wx,i = p(cid:48)(h + 1) + wx,i = mat[i, j] + wx,i = p(cid:48)(h + 2).

If (2), then

cost(α[1 : h + 1]) = cost(α[1 : h]) + wy,j = p(cid:48)(h + 1) + wy,j = mat[i, j] + wy,j = p(cid:48)(h + 2).

If (3), then

cost(α[1 : h + 1]) = cost(α[1 : h]) + diﬀ(xi, yj) = p(cid:48)(h + 1) + diﬀ(xi, yj)
= mat[i, j] + diﬀ(xi, yj) = p(cid:48)(h + 2).

All equalities follow from either the induction hypothesis or construction of p(cid:48)

By induction, cost(α[1 : h]) = p(cid:48)(h + 1) for all h ≤ k. In particular,

cost(α[1 : k]) = cost(α) = p(cid:48)(k + 1) = mat[m + 1, n + 1].

(cid:3)

Observe that Proposition 9.8 and Proposition 9.11 give the following corollary.

Corollary 9.12 (Backtracking Finds Optimal Alignment). Let x = (x1, x2, . . . , xm) and y =
(y1, y2, . . . , yn) be backbones. Let mat be the (m + 1) × (n + 1) alignment matrix. Let α : [k] → (cid:101)x × (cid:101)y
be an alignment found from backtracking. Then cost(α) = cx,y(m, n).

9.3.2. Time Complexity of Computing Backbone and Extremal Event DAG Distance. Using the
dynamic program above, we can compute the backbone distance in O(mn) time where m and n
are the lengths of the two backbones. However, since backbone alignments are not always unique,
then computing all optimal backbone alignments can become costly.

When computing the extremal event DAG distance, we must compute the optimal backbone
alignments that minimize the diﬀerence in weights over all possible aligned edges. Since we could
have multiple optimal backbone alignments, then computing the extremal event DAG distance
in the worst case is expensive. However, we have found empirically for the applications below
that almost always there is a unique optimal alignment. This then results in a polynomial time
complexity for computing the extremal event DAG distance.

Email address: robin.belton@montana.edu
Email address: breschine.cummins@montana.edu
Email address: brittany.fasy@montana.edu
Email address: gedeon@math.montana.edu

