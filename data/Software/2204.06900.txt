Prepared for submission to JINST

AI4EIC-Exp – Experimental Applications of Artificial Intelligence for the Electron-
Ion Collider
7-10 September 2021
Brookhaven National Laboratory, Upton (NY), USA

Using Machine Learning for Particle Identiﬁcation in

ALICE

Łukasz Kamil Graczykowski,

𝑎,1 Monika Jakubowska,

𝑏

Kamil Rafał Deja

𝑐

and Maja Kabus

𝑎

on behalf of the ALICE collaboration
𝑎Faculty of Physics, Warsaw University of Technology
Koszykowa 75, 00-662 Warsaw, Poland
𝑏Faculty of Electrical Engineering, Warsaw University of Technology
Pl. Politechniki 1, 00-661 Warsaw, Poland
𝑐Faculty of Electronics and Information Technology, Warsaw University of Technology
Nowowiejska 15/19, 00-665 Warsaw, Poland

E-mail: lukasz.graczykowski@pw.edu.pl

Abstract: Particle identiﬁcation (PID) is one of the main strengths of the ALICE experiment at
the LHC. It is a crucial ingredient for detailed studies of the strongly interacting matter formed in
ultrarelativistic heavy-ion collisions. ALICE provides PID information via various experimental
techniques, allowing for the identiﬁcation of particles over a broad momentum range (from around
100 MeV/𝑐 to around 50 GeV/𝑐). The main challenge is how to combine the information from
various detectors eﬀectively. Therefore, PID represents a model classiﬁcation problem, which can
be addressed using Machine Learning (ML) solutions. Moreover, the complexity of the detector and
richness of the detection techniques make PID an interesting area of research also for the computer
science community. In this work, we show the current status of the ML approach to PID in ALICE.
We discuss the preliminary work with the Random Forest approach for the LHC Run 2 and a more
advanced solution based on Domain Adaptation Neural Networks, including a proposal for its future
implementation within the ALICE computing software for the upcoming LHC Run 3.

Keywords: Particle identiﬁcation methods, Analysis and statistical methods, Data processing
methods

1Corresponding author.

2
2
0
2

r
p
A
4
1

]
x
e
-
l
c
u
n
[

1
v
0
0
9
6
0
.
4
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
Contents

1

Introduction

2 Preliminary work with Random Forest in LHC Run 2

3 ALICE computing framework in LHC Run 3

3.1 O2 Analysis Framework

4 The proposed solution for particle identiﬁcation in LHC Run 3

4.1 Domain Adaptation
4.2

Implementation of the Machine Learning PID analyses with the O2 framework

5 Future works

6 Conclusions

1

Introduction

1

2

3
3

5
5
6

8

8

ALICE (A Large Ion Collider Experiment) [1] is one of the four big detectors located at the Large
Hadron Collider (LHC) at CERN [2]. Its main goal is widening our understanding of the physics
of ultrarelativistic heavy-ion collisions and measuring the properties of the quark–gluon plasma
(QGP), a deconﬁned state of quarks and gluons, theorized to exist in the early Universe [3, 4]. The
detailed characterization of QGP requires utilizing several observables, which are calculated from
the lead nuclei collision (Pb–Pb) data, systematically compared with the proton-proton (pp) and
proton-lead (p–Pb) collision data, and interpreted through various theoretical models [5, 6].

The apparatus is composed of various detector systems that use a number of techniques to
measure signals from the particles emitted in such collisions. The so-called “central barrel”
surrounds the collision point and consists of a large solenoid magnet that generates a uniform
magnetic ﬁeld of up to 0.5 T along the beam direction. Inside the magnet, a set of detectors is
located surrounding the beam axis radially. Additional detectors, such as the muon spectrometer, are
located outside the central barrel in the forward beam direction. One of the main aspects of ALICE,
diﬀerentiating it from other LHC experiments and a pre-requirement for detailed QGP studies, is its
particle identiﬁcation (PID) capability, i.e., the discrimination power for diﬀerent particle species
produced in a collision. Due to a number of available detectors which operate concurrently, the
signal separation for various types of particles is possible over a wide range of momentum, from
just around 100 MeV/𝑐 up to around 10 GeV/𝑐. For the purpose of the work presented in this study,
three detectors are most relevant. For the track reconstruction and hadron PID, the information
provided by the Inner Tracking System (ITS) [7], the Time Projection Chamber (TPC) [8, 9], and the
Time-of-Flight detector (TOF) [10–12] is used. For a detailed description of the ALICE detector
performance, we refer the reader to Ref. [13].

– 1 –

The main task of PID is to provide high purity samples of particles of a given type required by
the analyzer conducting a speciﬁc analysis. In the most traditional approach, particles are selected by
applying so-called “cuts” applied to the reconstructed features obtained from the detector response,
rejecting the particles not meeting the speciﬁed criterion. Such an approach is justiﬁed when
the separation between various particle species is signiﬁcantly large. However, when the feature
distributions associated with the particle species begin to overlap, the process of combining the
information from multiple detectors becomes non-trivial, and the “trial and error” approach based
on the intuition and experience of the analyzer becomes not optimal. This leads to lowered PID
eﬃciency and limits the statistical signiﬁcance of the ﬁnal data analysis. These shortcomings can
be addressed with more advanced classiﬁcation methods. One particular example is the Bayesian
approach, which has proven successful in the ALICE experiment [14]. However, other solutions,
i.e., those based on Machine Learning (ML), also have a potentially signiﬁcant impact. In particular,
in our preliminary studies done with the LHC Run 2 data in Ref. [15], we show that classiﬁers
based on Random Forest [16] improve the separation between various particle species signiﬁcantly.
Nonetheless, one of the main limitations of that work was not taking into account any discrepancies
between the Monte Carlo (MC) and experimental data.

This paper presents a status of ongoing activity to deliver a comprehensive PID framework for
LHC Run 3, with a new computing framework and data format (called O2) being deployed [17].
Based on what we have learned in the preliminary work for LHC Run 2, we propose a novel and
more advanced solution based on Domain-Adversarial Training of Neural Networks [18], which
also addresses the MC and experimental data misalignment.

2 Preliminary work with Random Forest in LHC Run 2

For data gathered throughout the LHC Run 2, several attempts to introduce ML-based PID strategies
were made. For example, in [15], we proposed a method based on a Random Forest [16] algorithm
and showed the results for kaon selection. This technique is based on the idea of ensemble methods,
where a group of weak decision trees is used to produce the ﬁnal output, which corresponds to the
class predicted by most of the individual classiﬁers. Each tree is trained with only a subset of all
available parameters and a subset of available data examples to increase their variance. In [15],
the tree generation method based on the Gini index was used, which is deﬁned as the probability
of the wrong classiﬁcation while using only a given attribute. Proposed experiments indicate
that thanks to incorporating additional track-related attributes, the ML-based PID provides much
higher eﬃciency and purity for the selected particles than standard methods. In particular, in [15],
we showed a comparison of purity and eﬃciency as a function of 𝑝T for kaons selected with the
traditional method (𝑛 𝜎,TCP < 2 for 𝑝T ≤ 0.5 GeV/𝑐 and
< 2 for 𝑝T > 0.5 GeV/𝑐,
where for a given particle measured in a detector, 𝑛 𝜎 is the number of standard deviations from
the expected value), and using the Random Forest classiﬁer for PYTHIA 6.4 [19, 20] (Perugia-0
𝑠 = 7 TeV. In this study on simulated
tune [21]) simulated MC pp data at a collision energy of
data, the Random Forest classiﬁer outperformed the traditional cut-based selection.

√︃𝑛2

𝜎,TOF

𝜎,TCP

+ 𝑛2

√

Even though the proposed method provided signiﬁcant improvement in PID performance, its
incorporation in the AliRoot [22] computing framework has turned out to be very diﬃcult. The
reason is the communication between the Python environment, in which the ML classiﬁers were

– 2 –

prepared, and C++, which is the basis of ROOT [23] and AliRoot. Each track needs to be propagated
to the classiﬁer to receive a response with probabilities assigned to it for each particle species. We
considered several attempts to propagate tracks on a track-by-track basis or propagate chunks of
tracks combined from single or multiple events to the classiﬁer. However, since the processes
running the analysis in AliRoot on the GRID cannot be parallelized, this was a signiﬁcant limitation,
and the fastest solution had a processing time more than 3 times slower than the traditional PID.
However, with the end of the LHC Run 2 data-taking period and preparations ongoing for the
upcoming LHC Run 3 with the new ALICE computing software more open to external ML tools,
it was decided not to continue attempting to solve those problems related to AliRoot.

3 ALICE computing framework in LHC Run 3

Currently, the LHC is being upgraded before the next data-taking period, LHC Run 3, which will
start in the spring of 2022. The ALICE experiment will need to cope with a 100 times bigger
data-taking rate than the LHC Run 2. Therefore, the upgrade includes replacing some detectors
like ITS and TPC and the data acquisition software. Moreover, the new detector will continuously
collect the data instead of using a triggered readout, switching the data readout on and oﬀ each time
a collision is expected [24].

The new ALICE software called the ALICE Online-Oﬄine (O2) framework is being developed
anew to allow for high throughput, hardware acceleration, and more concurrency [17, 25]. Data
reconstruction will happen in two main stages, the synchronous (online) and the asynchronous
(oﬄine) stage [17]. Synchronous processing encompasses fast, rough calibration and reconstruction
that substantially reduces the data volume at an early stage. The data is then compressed and stored
for the asynchronous stage at which ﬁnal calibration is applied to achieve permanently stored
high-quality output. Therefore, a considerable speed-up will be conducted by performing detector
calibration and data reconstruction (traditionally oﬄine/asynchronous) also partially online (at the
synchronous stage), concurrently with data-taking. Figure 1 presents a simpliﬁed scheme of the
reconstruction and calibration data ﬂow. After the ﬁnal calibration, particle identiﬁcation will take
part at the asynchronous stage.

3.1 O2 Analysis Framework

One of the main parts of the O2 software is the Analysis Framework, which encompasses tools for
physics data analysis [26]. It provides eﬃcient data processing with an object-like, user-friendly
API, making it easier for the users to migrate from the old software framework and taking implicit
advantage of vectorization and parallelization. The solution is based on Apache Arrow for data
representation, allowing integration with other tools like Python Pandas. The Analysis Framework
is integrated with the O2 Data Processing Layer (DPL) that encompasses the whole data ﬂow from
data acquisition to its analysis.

The event data is reduced as much as possible to reduce disk space requirements and speed-up
retrieval. It follows the LHC Run 2 AOD (Analysis Object Data) design but without any quantities
that can be calculated on the ﬂy. The data model no longer consists of objects, but it is represented as
ﬂat tables similar to relational databases and stored as ﬂat ROOT trees. This will save the costs due
to serialization during message passing, enable vectorized processing, and allow for more eﬃcient

– 3 –

Figure 1. Reconstruction and calibration data ﬂow (FLP – First Level Processors, EPN – Event Processing
Nodes, CTF – Continuous Time Frames, AOD – Analysis Object Data). Figure from [17].

use of the shared memory backend of FairMQ (Message Queuing Library and Framework) [27].
Nevertheless, the analysis output and histograms will be serialized as objects with ROOT.

An analysis is performed in a workﬂow, a sequence of tasks. Each task is a struct that needs to
contain at least the process() method. The users can subscribe to speciﬁc tables by passing them
as parameters to process(). Other task struct members can deﬁne ﬁlters and partitions to apply or
new tables and histograms to be produced.

Listing 1 shows a sample task. The tracks are processed from one collision at a time, and they
are ﬁltered according to their 𝜂. Inside the process() method, a 2D histogram is ﬁlled with 𝜂 and
𝜙 of the ﬁltered tracks and then tracks with positive and negative 𝜙 are processed separately.

struct FilterTask {

using myTracks = soa::Filtered<aod::Tracks>
Filter etafilter = (aod::track::eta < 1.0f) && (aod::track::eta > -1.0f);
Partition<myTracks> leftPhi = aod::track::phiraw < 0.0f;
Partition<myTracks> rightPhi = aod::track::phiraw >= 0.0f;
OutputObj<TH2F> etaphiH{TH2F("etaphi", "etaphi", 100, 0., 2. * M_PI, 102, -2.01, 2.01)};

void process(aod::Collision const& collision, myTracks const& tracks)
{

for(auto& track : tracks) {

etaphiH->Fill(track.phi(), track.eta());

}
for (auto& track : leftPhi) { /*Processing filtered tracks from the first partition*/ }
for (auto& track : rightPhi) { /*Processing filtered tracks from the second partition*/ }

}
};

Listing 1. An example of ﬁltering and partitioning tracks.

Since the results of particle identiﬁcation will be directly used by the analyzers, the PID
framework needs to eﬃciently take the inputs from the O2 analysis tasks and pass the calculated

– 4 –

particle codes back to user-deﬁned analysis tasks.

4 The proposed solution for particle identiﬁcation in LHC Run 3

To improve particle identiﬁcation performance, we propose to implement a classiﬁer based on a
multilayered perceptron. We train it with data from corresponding MC simulations. To simplify
integration and allow the selection of individual particles independently, we propose to train one
model with a binary classiﬁcation objective for each particle type.

4.1 Domain Adaptation

In analysis, PID is used to select particles of desired types in both real experimental data and Monte
Carlo simulations. However, recorded signals in physical detectors can diﬀer from those produced
in simulations. Therefore, standard PID methods rely on partially automated processes for data
domains alignment. For instance, one of ALICE’s approaches consists of using the so-called “tune
on data”. This procedure is based on generating a random detector signal based on a parametrization
obtained from data. The resulting distributions of Monte Carlo and experimental data should be
equivalent, and only statistical ﬂuctuations are present.

To circumvent the limitations of standard data alignment methods, we propose combining it
with particle identiﬁcation stating it as a known problem of classiﬁcation with unsupervised domain
adaptation. The main idea of this technique is to learn the discrepancies between two data domains,
that is, the labeled source domain (in our case simulation data) and the unlabelled target one (in our
case experimental data), and translate those to a single hyperspace, where the diﬀerences between
domains are no longer visible. Classiﬁers trained on top of features located in combined latent
space should have similar performance on both MC simulated and experimental data. Nevertheless,
in such a scenario, simulation data is crucial to learn how to distinguish diﬀerent particles based
on aligned representations. The domain-adaptation technique is widely used in natural language
processing [28, 29] and computer vision [30, 31].
In the domain of high-energy-physics, its
application is limited only to preliminary studies of jet classiﬁcation [32]. In this work, the authors
present that this method can improve the quality of automatic jet tagging on real experimental data.
Our initial experiments with Domain Adversarial Neural Networks (DANN) [18] show that this
technique improves the classiﬁcation of particles in experimental data. The main idea behind this
method is to build a system composed of three neural networks. The goal of the feature mapping
network is to map original input into domain invariant features. Those features serve as an input to
the standard particle classiﬁer that outputs the particle type. Additionally, the last model, known
as domain classiﬁer, enforces domain invariance of extracted features through adversarial training
procedure. The training of the model is divided into two steps. First, on top of current features
from the feature mapping network, the domain classiﬁer is trained independently to classify domain
labels – whether data come from a real or a simulation source. Then, the domain classiﬁer is being
frozen so that the particle classiﬁer and the feature mapper can be trained jointly to predict accurate
particle types while fouling the domain classiﬁer at the same time. With this approach, the feature
mapper’s weights are updated with a gradient from the particle classiﬁer and reversed gradient
from the domain classiﬁer. Training a domain-adaptation-based classiﬁer is more complex than the

– 5 –

Figure 2. Architecture of DANN composed of three models: feature mapper, particle classiﬁer and domain
classiﬁer.

Figure 3. Preliminary result of DANN PID for the TPC detector signal (d𝐸/d𝑥) as a function of particle
momentum for particles identiﬁed as protons without domain adaptation (left) and with domain adaptation
(right).

classical neural model. However, the application performance of those two methods is similar and
depends on the complexity of the classiﬁer and feature extractor.

Figure 3 presents preliminary results of the proposed DANN model for pion identiﬁcation in
𝑠 = 13 TeV from the LHC Run 2 period. The training dataset was a corresponding MC

√

pp data at
simulation with PYTHIA 8 Monash tune [33].

Our preliminary results of classiﬁcation applied with the proposed model indicate that domain
adaptation improves experimental data classiﬁcation. The enhancement is visible as a reduction of
contamination outside the proton band in the energy loss signal of protons classiﬁed with DANN in
Fig. 2. However, detailed benchmarks will have to be done in the future after the ﬁnal architecture
of the model is achieved in order to support that hypothesis.

4.2

Implementation of the Machine Learning PID analyses with the O2 framework

Besides developing and improving the neural network models, the new particle identiﬁcation
framework needs to be integrated into the more extensive analysis software. Figure 4 depicts an

– 6 –

initial, tentative design of the PID workﬂow, which will be further tested and updated.

The current developments make use of the ONNX (Open Neural Network Exchange) stan-
dard [34], which deﬁnes a common ﬁle format for storing machine learning models developed in
various frameworks such as Tensorﬂow and PyTorch. Additionally, the ONNX Runtime [35] library
enables ONNX models to be used in diﬀerent programming languages such as Python and C++
with a simple API. ONNX and ONNX Runtime are also tested by other machine learning projects
at ALICE, and the solution provided for PID ML will be an example base for the other projects.

Figure 4. An initial scheme of the particle identiﬁcation workﬂow in O2. More information about the
workﬂow topology in the O2 Analysis Framework can be found in [26].

Firstly, it is assumed that the reconstructed collision data will be available in AOD ﬁles.
Separately, diﬀerent trained and untrained neural networks will be stored in their own repository in
ONNX format. PID analysis tasks in the O2 Analysis Framework will comprise the PID ML API
available to users. Once an analyzer requests a PID task in their workﬂow, a PID producer task will
be ﬁrst attached. This task will read appropriate collision data and distill the variables needed for
the identiﬁcation task so that the further processing will operate on a skimmed, much smaller table.

Then, the framework will determine whether a matching neural network is available. If the
network requires training, the training task is triggered. The training process itself might be
performed on the C++ or Python side – this also depends on ONNX Runtime limitations. In the
case of Python, the data table will be converted from stored ROOT trees to Python pandas.

Finally, the ready model is passed back to the Analysis Framework, and the inference task
is triggered. Currently, the inference is implemented both in Python and in C++ (with ONNX
Runtime). The tests presented in this work were performed in Python. The inference results will
then be passed to the user analysis task.

Initially, a multi-output neural network was considered, but it was rejected in favor of having
In this way, the development can be

diﬀerent models for recognizing diﬀerent particle kinds.
concentrated on the most commonly used particle species.

– 7 –

5 Future works

This work presents the current status of the development of particle identiﬁcation techniques based
on machine learning. Several main concerns still need to be addressed for those methods to work
in practice.

To assess the precision of measurements based on ML-PID, we have to estimate the systematic
uncertainties of machine learning models. While this is still an open research question, several
methods approximate diﬀerent sources of systematic uncertainties. In [36], the authors demonstrate
how dataset uncertainties can aﬀect machine learning model predictions. Among the works related
speciﬁcally to high-energy physics, in [37], the authors propose a model where classiﬁers are aware
of systematic uncertainties of input parameters. This approach improves the model’s sensitivity. At
the same time, in [38], the authors use adversarial training for this purpose.

In our solution, we plan ﬁrst to include experiments analogous to [36] measuring how training
dataset selection might aﬀect the model’s performance. Next, we intend to follow the developments
described in [39] where the authors show that dropout – a standard method for reducing overﬁtting in
neural networks – might be used to approximate Bayesian uncertainty in deep Gaussian processes.
A method for calibrating Bayesian uncertainties is presented also in [40].

6 Conclusions

Identiﬁcation of various particle species is one of the strengths of ALICE and a crucial ingredient
of many analyses studying the QGP properties from heavy-ion data analysis. While the typical PID
methods are based on more or less arbitrary cut-oﬀ values selected by the analyzers, improvement
can be achieved with ML-based approaches. PID can be seen as a multi-class classiﬁcation problem
presenting the challenges described in the text, which can be of interest to other communities. This
fosters multidisciplinary approaches like the ones we proposed. The preliminary work from the
LHC Run 2 with the Random Forest approach already shows that using ML techniques for PID
improves the purity of selected samples while maintaining high eﬃciency. However, one of the
essential ingredients is the misalignment between the Monte Carlo training data and the experimental
data. A solution to that problem is domain adaptation via the DANN networks. The ﬁrst results
obtained with DANN networks show that this approach is promising. The implementation in
the new ALICE software framework (the O2 via the ONNX environment) should also be feasible
without the drawbacks present in the preliminary work for LHC Run 2 data and the previous AliRoot
framework.

Acknowledgments

Research was funded by POB HEP of Warsaw University of Technology within the Excellence Ini-
tiative: Research University (IDUB) program as well as by the Polish National Science Center grants
no. UMO-2018/31/N/ST6/02374, UMO-2017/27/B/ST2/01947, UMO-2016/22/M/ST2/00176 and
the Polish Ministry of Education and Science under agreement no. 2022/WK/01.

– 8 –

References

[1] K. Aamodt et al. The ALICE experiment at the CERN LHC. JINST, 3:S08002, 2008.

[2] Lyndon Evans and Philip Bryant. LHC Machine. JINST, 3:S08001, 2008.

[3] Edward V. Shuryak. Quark-Gluon Plasma and Hadronic Production of Leptons, Photons and Psions.

Phys. Lett., 78B:150, 1978. [Yad. Fiz.28,796(1978)].

[4] John Adams et al. Experimental and theoretical challenges in the search for the quark gluon plasma:
The STAR Collaboration’s critical assessment of the evidence from RHIC collisions. Nucl. Phys.,
A757:102–183, 2005.

[5] Panagiota Foka and Małgorzata Anna Janik. An overview of experimental results from

ultra-relativistic heavy-ion collisions at the CERN LHC: Bulk properties and dynamical evolution.
Rev. Phys., 1:154–171, 2016.

[6] Panagiota Foka and Małgorzata Anna Janik. An overview of experimental results from

ultra-relativistic heavy-ion collisions at the CERN LHC: Hard probes. Rev. Phys., 1:172–194, 2016.

[7] G. Dellacasa et al. ALICE technical design report of the inner tracking system (ITS). 6 1999.

[8] G. Dellacasa et al. ALICE: Technical design report of the time projection chamber. 1 2000.

[9] C. Garabatos. The ALICE TPC. Nucl. Instrum. Meth. A, 535:197–200, 2004.

[10] ALICE Time-Of-Flight system (TOF): Technical Design Report. 2000.

[11] P. Antonioli. The ALICE time of ﬂight system. Nucl. Phys. B Proc. Suppl., 125:193–197, 2003.

[12] A. Akindinov et al. Performance of the ALICE Time-Of-Flight detector at the LHC. Eur. Phys. J.

Plus, 128:44, 2013.

[13] Betty Bezverkhny Abelev et al. Performance of the ALICE Experiment at the CERN LHC. Int. J.

Mod. Phys. A, 29:1430044, 2014.

[14] Jaroslav Adam et al. Particle identiﬁcation in ALICE: a Bayesian approach. Eur. Phys. J. Plus,

131(5):168, 2016.

[15] Tomasz Trzciński, Łukasz Graczykowski, Michał Glinka, ALICE Collaboration, et al. Using random
forest classiﬁer for particle identiﬁcation in the alice experiment. In Conference on Information
Technology, Systems Research and Computational Physics, pages 3–17. Springer, 2018.

[16] Tin Kam Ho. Random decision forests. In Proceedings of 3rd international conference on document

analysis and recognition, volume 1, pages 278–282. IEEE, 1995.

[17] P. Buncic, M. Krzewicki, and P. Vande Vyvre. Technical Design Report for the Upgrade of the

Online-Oﬄine Computing System. Technical Report CERN-LHCC-2015-006. ALICE-TDR-019,
CERN, 4 2015.

[18] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François

Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks.
The journal of machine learning research, 17(1):2096–2030, 2016.

[19] Torbjorn Sjostrand, Stephen Mrenna, and Peter Z. Skands. PYTHIA 6.4 Physics and Manual. JHEP,

05:026, 2006.

[20] Torbjörn Sjöstrand. The PYTHIA Event Generator: Past, Present and Future. Comput. Phys.

Commun., 246:106910, 2020.

– 9 –

[21] Peter Zeiler Skands. Tuning Monte Carlo Generators: The Perugia Tunes. Phys. Rev., D82:074018,

2010.

[22] R. Brun, P. Buncic, F. Carminati, A. Morsch, F. Rademakers, and K. Safarik. Computing in ALICE.

Nucl. Instrum. Meth. A, 502:339–346, 2003.

[23] Rene Brun and Fons Rademakers. Root — an object oriented data analysis framework. Nuclear

Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and
Associated Equipment, 389(1):81–86, 1997. New Computing Techniques in Physics Research V.

[24] B Abelev et al. Upgrade of the ALICE Experiment: Letter Of Intent. J. Phys. G, 41:087001, 2014.

[25] Ananya et al. O2: A novel combined online and oﬄine computing system for the ALICE Experiment

after 2018. J. Phys. Conf. Ser., 513:012037, 2014.

[26] Anton Alkin, Giulio Eulisse, Jan Fiete Grosse-Oetringhaus, Peter Hristov, and Maja Kabus. ALICE

Run 3 Analysis Framework. EPJ Web Conf., 251:03063, 2021.

[27] D. Klein et al. FairMQ. FairRoot Group at GSI, 2020,

https://github.com/FairRootGroup/FairMQ. (Accessed: 18 October 2021).

[28] John Blitzer, Mark Dredze, and Fernando Pereira. Biographies, bollywood, boom-boxes and blenders:
Domain adaptation for sentiment classiﬁcation. In Proceedings of the 45th annual meeting of the
association of computational linguistics, pages 440–447, 2007.

[29] Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Domain adaptation for large-scale sentiment

classiﬁcation: A deep learning approach. In ICML, 2011.

[30] Raghuraman Gopalan, Ruonan Li, and Rama Chellappa. Domain adaptation for object recognition:
An unsupervised approach. In 2011 international conference on computer vision, pages 999–1006.
IEEE, 2011.

[31] Basura Fernando, Amaury Habrard, Marc Sebban, and Tinne Tuytelaars. Unsupervised visual domain
adaptation using subspace alignment. In Proceedings of the IEEE international conference on
computer vision, pages 2960–2967, 2013.

[32] David Walter. Domain adaptation studies in deep neural networks for heavy-ﬂavor jet identiﬁcation

algorithms with the cms experiment. 2018.

[33] Peter Skands, Stefano Carrazza, and Juan Rojo. Tuning PYTHIA 8.1: the Monash 2013 Tune. Eur.

Phys. J. C, 74(8):3024, 2014.

[34] ONNX Community. ONNX. ONNX Community, 2021, https://onnx.ai/. (Accessed: 18

October 2021).

[35] ONNXRuntime Community. ONNXRuntime. ONNXRuntime Community, 2021,

https://onnxruntime.ai/. (Accessed: 18 October 2021).

[36] Anurag Jha, Anand Chandrasekaran, Chiho Kim, and Rampi Ramprasad. Impact of dataset

uncertainties on machine learning model predictions: the example of polymer glass transition
temperatures. Modelling and Simulation in Materials Science and Engineering, 27(2):024002, 2019.

[37] Aishik Ghosh, Benjamin Nachman, and Daniel Whiteson. Uncertainty aware learning for high energy

physics. arXiv preprint arXiv:2105.08742, 2021.

[38] Christoph Englert, Peter Galler, Philip Harris, and Michael Spannowsky. Machine learning

uncertainties with adversarial neural networks. The European Physical Journal C, 79(1):1–10, 2019.

– 10 –

[39] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model

uncertainty in deep learning. In international conference on machine learning, pages 1050–1059.
PMLR, 2016.

[40] Volodymyr Kuleshov, Nathan Fenner, and Stefano Ermon. Accurate uncertainties for deep learning
using calibrated regression. In International Conference on Machine Learning, pages 2796–2804.
PMLR, 2018.

– 11 –

