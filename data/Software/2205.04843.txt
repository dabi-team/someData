2
2
0
2

y
a
M
0
1

]

V
C
.
s
c
[

1
v
3
4
8
4
0
.
5
0
2
2
:
v
i
X
r
a

Assessing Streamline Plausibility Through Randomized
Iterative Spherical-Deconvolution Informed Tractogram
Filtering

Antonia Haina, Daniel J¨orgensb,c, Rodrigo Morenoc,∗

aSaarland University, Faculty of Mathematics and Computer Science, Campus
E1.7, Saarbruecken, 66041, Saarland, Germany
bDivision of Brain, Imaging, and Behaviour, Krembil Research Institute, Toronto
Western Hospital, University Health Network, Toronto, Ontario, Canada
cKTH Royal Institute of Technology, Department of Biomedical Engineering and Health
Systems, Halsovagen 11C, Huddinge, 14157, Stockholm, Sweden

Abstract

Tractography has become an indispensable part of brain connectivity stud-
ies. However, it is currently facing problems with reliability. In particular,
a substantial amount of nerve ﬁber reconstructions (streamlines) in trac-
tograms produced by state-of-the-art tractography methods are anatomi-
cally implausible. To address this problem, tractogram ﬁltering methods
have been developed to remove faulty connections in a postprocessing step.
This study takes a closer look at one such method, Spherical-deconvolution
Informed Filtering of Tractograms (SIFT), which uses a global optimization
approach to improve the agreement between the remaining streamlines af-
ter ﬁltering and the underlying diﬀusion magnetic resonance imaging data.
SIFT is not suitable to judge the plausibility of individual streamlines since
its results depend on the size and composition of the surrounding trac-
togram. To tackle this problem, we propose applying SIFT to randomly
selected tractogram subsets in order to retrieve multiple assessments for
each streamline. This approach makes it possible to identify streamlines
with very consistent ﬁltering results, which were used as pseudo ground
truths for training classiﬁers. The trained classiﬁer is able to distinguish
the obtained groups of plausible and implausible streamlines with accuracy
above 80%.

Keywords: Diﬀusion MRI, Tractography, Tractogram ﬁltering, Machine
Learning

Preprint submitted to arXiv

 
 
 
 
 
 
1. Introduction

Tractography uses data acquired with diﬀusion-weighted magnetic reso-
nance imaging (DW-MRI) to trace nerve ﬁber tracts in the brain, producing
a model called a tractogram. A tractogram consists of a set of streamlines,
each of which represents an assumed nerve ﬁber through an ordered set
of 3-dimensional coordinates [1]. The main goal of tractography can be
described as creating a set of streamlines that pose a maximally accurate,
digital representation of the structural connectome [2], which refers to the
actual set of nerve ﬁbers in the brain [3]. Applications for tractography
include neurosurgery planning [4], the study of neurological diseases [5], or
the scientiﬁc study of the brain to understand its function and its links to
human behavior [6].

By generating many streamlines (usually millions), current tractography
methods have been shown to be able to recover all relevant bundles [7], at
least if they are run in an appropriate way [8, 9]. However, they are also
It has been
prone to generating erroneous and implausible streamlines.
estimated that an average of four false-positive streamlines are generated
for each valid streamline in the tractogram [10]. This can hardly be fully
avoided because tractography methods with high sensitivity tend to show
low speciﬁcity and vice versa [11]. In order to take steps towards a reliable
model of the connectome, removing implausible connections is crucial.

A whole ﬁeld of research, commonly called tractogram ﬁltering, has been
established as a way to deal with the excess of false-positive streamlines.
Tractogram ﬁltering approaches remove streamlines from tractograms by
evaluating their plausibility, for example, by considering the geometrical
properties of streamlines (e.g.,
[13]),
through clustering approaches (e.g., [14]) or by correspondence to the un-
derlying DW-MRI data (e.g., [15]). A review of methods is presented in
[16].

[12]), anatomical constraints (e.g.,

Identifying implausible streamlines can be posed as a binary classiﬁca-
tion problem: Each streamline is assigned a “positive” (P) or “negative” (N)
label if it appears to be plausible or implausible, respectively. Streamlines
with a “negative” label are subsequently removed from the tractogram. The
terms “true positive” (TP) and “false positive” (FP) frequently appear in

∗Corresponding author
Email addresses: s8anhain@stud.uni-saarland.de (Antonia Hain),

danjorg@kth.se (Daniel J¨orgens), rodmore@kth.se (Rodrigo Moreno)

2

tractography literature as well, even though they express notions that are
slightly diﬀerent from the meaning used in statistics [17]: Here, a “true posi-
tive” streamline is regarded to be a fully correct reconstruction of an actual,
plausible nerve ﬁber bundle, while a “false positive” streamline represents a
faulty/noisy reconstruction that does not accurately represent any existing
structure in the brain. Therefore, in this work, we use the terms “plausible”
or “implausible” interchangeably with “positive” and “negative” or “true
positive” and “false positive”, even though the concepts are not entirely
equal in the classical sense.

One popular tractogram ﬁltering method is Spherical-deconvolution In-
formed Filtering of Tractograms (SIFT) [15]. This approach belongs to the
family of methods that assess tractogram quality by comparing the acquired
DW-MRI data to the expected one from the tractogram [16]. In particu-
lar, SIFT removes streamlines to increase the consistency of the tractogram
with respect to the acquired data based on a global optimization approach.
Other examples of such methods include LiFE [18], COMMIT [19], SIFT2
[20], and COMMIT2 [21, 22, 23]. SIFT does not operate directly on raw
data, but instead uses the ﬁber orientation distribution (FOD) [24]. A
tractogram can be ﬁltered by investigating how the eﬀect of removing an
individual streamline manifests in the streamline density in each voxel com-
pared to the corresponding local FOD along the streamline. Streamlines
that increase the mismatch between streamline density and local FODs are
prioritized for ﬁltering. Given the complexity of the computation and the
number of streamlines, trying to ﬁnd a globally optimal solution is infeasible.
Therefore, a gradient-descent approach is used to reduce a cost function.

Several criteria for termination of the optimization process are provided
by SIFT. By default, streamlines are removed until the cost function gradi-
ent of the candidate streamlines becomes suﬃciently small. This option is
referred to as ﬁltering “to convergence”. In the absence of other termination
criteria which specify a maximum number of streamlines to be removed, ﬁl-
tering to convergence will naturally lead to the most reliable result set of
streamlines, but with the streamline density being decreased the most. In
fact, it has been argued that the remaining number of streamlines is not al-
ways suﬃcient for quantitative analyses, and for that reason, the authors of
SIFT recommend applying the method to tractograms with a high number
of streamlines [25].

Due to the design of SIFT’s cost function, streamlines will be removed
if the track density in their path is too high to match (parts of) the FODs.

3

Such a mismatch could be due to diﬀerent reasons, including at least the
following cases:

1. The FOD representation in a voxel is not accurately describing the
underlying anatomy. This can happen, for example, when the raw
data is not able to model and resolve diﬀerent ﬁber populations.
2. The streamlines may be (partly) faulty/noisy. This is the target case
for ﬁltering, as the streamline is a false positive and must be removed.
3. The streamlines are plausible, but the streamline density in the cor-
It is common for
responding voxel fractions is simply exaggerated.
tractography methods to create multiple similar streamlines. We will
refer to these streamlines as redundants.

Thus, a streamline being rejected by SIFT is therefore not a suﬃcient
indicator of it being implausible. Since SIFT removes streamlines from
these three categories, SIFT as such is not completely suitable for assessing
the correspondence of an individual streamline to the DW-MRI data. The
focus of this paper is, therefore, to distinguish cases two and three.

Machine learning has been used for training classiﬁers to speed up the
processing of expensive tractogram ﬁltering methods [26, 27]. Although it is
appealing to train a binary classiﬁer to distinguish false-positive from true-
positive streamlines based on the raw output of SIFT, this is unfortunately
not possible for the abovementioned reasons. Indeed, redundant and true
positive streamlines share similar features, but SIFT rejects the former and
accepts the latter. Thus, for SIFT to be used in classiﬁers of streamlines,
it is necessary to have a method to distinguish between false positives and
redundants.

We have found that speciﬁc streamlines may be classiﬁed diﬀerently by
SIFT depending on the composition of the tractogram. In this paper, we
take advantage of this property with the goal of disentangling false positives
from redundant streamlines. More speciﬁcally, we apply SIFT on random-
ized subsets of tractograms to identify both of those streamline groups.
Since SIFT seems to yield inconsistent results for certain streamlines when
found in diﬀerent subsets, we spotlight those streamlines and explore how
they might be appropriately labeled. We refer to the proposed approach as
randomized SIFT (rSIFT).

4

2. Materials and Methods

2.1. Datasets

We carried out the experiments on pre-processed data [28] of six diﬀerent
subjects from the young adult data set of the Human Connectome Project
[29]. The whole-brain tractograms derived from this data were provided
by the authors of [30]1 and computed with the iFOD2 [31] algorithm. Ten
million streamlines were created for each subject, restricted to be between
40mm and 250mm in length, with a step size of 0.625mm. The tracking
was further constrained by anatomical priors based on the segmentation of
diﬀerent tissue types in the brain [32]. In order to make computation more
feasible, we used an additional post-processing step in which the streamlines
were compressed to smaller sets of coordinates with the method in [33] using
a tolerance error of 0.35mm.

The ten million streamlines in each HCP tractogram covered the en-
tire white matter volume. An exemplary depiction of the distribution of
streamline length, the number of sampling points, and their correlation for
one subject can be seen in Fig. 1. This ﬁgure also shows that the stream-
line length and the number of sampling points are still highly correlated
after compression. The tractograms were generated with MRtrix3 [34] with
the exception of the compression step, for which the Python library Dipy
[35] was used.

We further studied the phantom data from the DiSCo Challenge [36],
which was used as ground truth to create datasets with known true positive,
redundant, and false-positive streamlines. The ground truth of this dataset
consists of 12 196 streamlines. In our ﬁrst experiment on this data, we used
half of the streamlines as true positives, while the other half was distorted
to produce realistic implausible streamlines by applying random rotation
in 3D. The rotations were done by randomly selecting Euler angles in the
range of 45–315 degrees to get streamlines not too close to the ground
truth. We ﬁlled the tractogram with false positives to a total of 89 570
streamlines in order to achieve a similar streamline density compared to
the 10 million used in the HCP case. In a second experiment, half of the
ground-truth streamlines were used as true positives, while the second half
was systematically copied to produce redundant streamlines. Notice that
all streamlines are plausible in this experiment. The second half of the data
was split evenly into ﬁve further groups: the ﬁrst ﬁfth of the streamlines was

1https://doi.org/10.5281/zenodo.1088277
5

copied once, such that each of them would appear twice in the tractogram.
The other groups were copied twice, four, nine, and 48 times (ﬁller data),
respectively. This resulted in a tractogram with around 89 000 streamlines,
including groups of streamlines appearing with very diﬀerent frequencies.

2.2. Randomized SIFT (rSIFT)

Fig. 2 summarizes the method, and Algorithm 1 shows the pseudocode
of rSIFT. The following subsections detail the diﬀerent components of the
method.
Instead of running SIFT once on the complete tractogram, we
applied it several times to random subsets of streamlines. The number of
times a streamline was ﬁltered out or kept over the diﬀerent runs of SIFT
was used to deﬁne its acceptance rate (AR) per subset size. We refer to each
evaluation of a streamline through SIFT as a vote. That means a streamline
that was kept in a tractogram after ﬁltering receives a positive vote and a
streamline that was removed receives a negative vote.

In order to examine the inﬂuence of not only the composition, but also
the subset size on the results of the SIFT algorithm, we employ diﬀerent sub-
set sizes in the rSIFT procedure. The streamline subset sizes were selected
to cover a wide range but simultaneously be able to produce meaningful
results within reasonable computation time.

In pretests, out of the ten million streamlines per HCP tractogram, only
around 2–2.5% remained after ﬁltering. The fact that the algorithm termi-
nated through convergence indicates that the remaining set of streamlines
was too small to guarantee a stable model and valid removal of streamlines.
Any results for streamline sets smaller than that might not be meaning-
ful. Thus, the smallest subset size was chosen to be 2.5% of the original
tractogram size, i.e., 250 000 streamlines for the HCP data. We applied a
similar procedure to determine a minimum subset size for the DisCo data,
which turned out to be around 16 000 in the tractogram with ground truth
and false-positive data and around 13 000 in the tractogram with ground
truth and redundant data.

Between the largest (the complete tractogram) and smallest subsets,
subset sizes were systematically chosen, usually by halving the subset size.
Thus, the probed sizes were SS = {1×107, 5×106, 2.5×106, 1.25×106, 6.25×
105, 5 × 105, 2.5 × 105} for the HCP data.

For the ﬁrst DiSCo data experiment (with implausible streamlines), we
used SS = {89 570, 44 785, 22 392, 16 000} and for the second experiment
(with redundant streamlines), SS = {88 996, 44 498, 22249, 13 000}.

6

Figure 1: Distribution of the number of points and length of streamlines in an exem-
plary tractogram of ten million streamlines. Top: histogram of the number of points
per streamline. Middle: histogram of streamline length in mm. Bottom: correlation
plot between streamline length and the mean number of sampling points with standard
deviation (light blue).

7

Figure 2: Pipeline of rSIFT. Top: SIFT is run on diﬀerent random subsets of the orig-
inal tractogram. The numbers of positive and negative votes are used to estimate the
acceptance rate (AR) of every streamline. Bottom: streamlines with AR=100% and 0%
are used to compute a pseudo ground truth of streamlines. The remaining streamlines
are inconclusive.

8

Input:

Output:

T = {t1, t2, . . . , tM } : tractogram,
SS = {s1, s2, . . . , sN } : subset sizes

P = {p1, p2, . . . , pM }: plausibility votes,
N = {n1, n2, . . . , nM }: implausibility votes

Initialize P and N with zeros
forall n ∈ SS do

Initialize Pn and Nn with zeros
k ← τ M/n
for i ∈ {1, . . . , k} do

subseti ← {r1, . . . , rn} ⊆ T , where r1,...,n are randomly
selected from T
i , subsetN
[subsetP
Pn(subsetP
Nn(subsetN

i ) ← Pn(subsetP
i ) ← Nn(subsetN

i ] ← SIF T (subseti)

i ) + 1
i ) + 1

end
P = P + Pn
N = N + Nn

end

Algorithm 1: Pseudocode outlining the procedure of rSIFT. For each
chosen subset size n, k random subsets of the tractogram are extracted
and ﬁltered with SIFT to receive the indices of the accepted and rejected
streamlines subsetP
i . These are used to update the number
of votes.

i and subsetN

9

Subsequently, rSIFT was run on all of the pre-deﬁned subset sizes n ∈
SS, with a number of repetitions k deﬁned for each n. k, was adapted
to n, such that n × k remained constant. In particular, k = τ M/n, with
M being the total number of streamlines in the tractogram and τ being
a parameter that we set to ﬁve in the experiments. This way, we aim to
obtain enough votes for each streamline to compute robust statistics (e.g.,
k = 5 and k = 20 for n = 1 × 107 and n = 2.5 × 106, respectively, in the
experiments with HCP data).

Notice that, since each streamline subset is deﬁned from the complete
tractogram, the number of occurrences across all subsets varies for all stream-
lines. That means that the number of received votes is expected to diﬀer
between streamlines and could, for some, even be zero.

After completing the ﬁltering procedure, the total numbers of positive
and negative votes of a streamline s for subset size n, denoted as Pn(s) and
Nn(s), respectively, were used to compute its acceptance rate ARn as:

ARn(s) =

Pn(s)
Pn(s) + Nn(s)

.

(1)

In addition to this, AR(s) (without n) refers to the acceptance rate of
a streamline compiling the votes received over all subset sizes. For the
analysis of the method, we analyzed the distribution of ARn over diﬀerent
choices of n.

As mentioned, ﬁnding an anatomically reliable ground truth is an ongo-
ing challenge in tractogram ﬁltering. Having this in mind, our focus here
is limited to extending the notion of streamline acceptance that is possible
with SIFT. Streamlines with AR = 100% and AR = 0% are likely to be
plausible and implausible, respectively, since all runs of SIFT are consistent
for these streamlines regardless of the tractogram conﬁguration they are in.
That means that these streamlines can be used to generate a pseudo ground
truth of a plausible and implausible class of streamlines in the sense of SIFT.
The plausibility of the remaining streamlines with less consistent results is
harder to assess solely based on their AR. Thus, we group them with the
label inconclusive. Notice that inconclusive streamlines may consist of a
mix of plausible and implausible streamlines that SIFT cannot consistently
detect or that SIFT has not evaluated in all subset sizes. In summary, we
separate the streamlines in a tractogram into three classes:

1. plausible where AR = 100%
2. implausible where AR = 0%

10

3. inconclusive where 0% < AR < 100%.

We use the distinction of plausible and implausible streamlines as pseudo
ground truth for training the classiﬁers described in the next section.

2.3. Neural network-based streamline classiﬁer

We designed rSIFT with the goal of providing useful information about
the plausibility of individual streamlines. In order to gain insight into the
properties of the streamline grouping based on plausible, implausible, and
inconclusive labels, we analyzed the performance of a neural network clas-
siﬁer trained on these labels in diﬀerent scenarios. In doing so, we simulta-
neously show the feasibility of training a neural network model that mimics
the characteristics of rSIFT, and thus provide a computationally eﬃcient
alternative implementation to the originally proposed method.

In our experiments, we investigated the composition of the three rSIFT
labels by means of their separation based on neural network classiﬁers.
First, we trained models for the pair-wise separation of labels, i.e., plau-
sible (positive) vs.
inconclusive, and
implausible (negative), plausible vs.
implausible vs. inconclusive streamlines. Secondly, we trained a multi-class
model to distinguish between all three rSIFT labels simultaneously.

The training of all classiﬁers was performed using a 5-fold cross-validation
(CV) approach on the pooled set of streamlines from two HCP subjects. We
report the average performance of all CV models on the respective validation
set. For testing, we chose the best performing model in terms of balanced
sensitivity and speciﬁcity in order to minimize bias. This model was used
to evaluate streamlines from four unseen HCP subjects, which we refer to
as test data.

In order to make the classiﬁer applicable to data from multiple subjects
and to provide a basic image registration, streamline coordinates were nor-
malized to a range of -1 and 1 in each dimension using the minimum and
maximum streamline coordinates per subject. Since the input streamlines
comprised a varying number of points, they were resampled to the same
number of points in order to be used as input for the network. To min-
imize the impact of this resampling on as many streamlines as possible,
the median number of streamline points across training subjects, which was
determined to be 22 points, was chosen as the resampling target. Linear
interpolation was applied to approximate the original streamline geometry.
Each classiﬁer was composed of two 1-D convolution layers (kernel sizes
5 and 3), with ReLU activation and max-pooling (pool size 2) applied after
11

Figure 3: Architecture of the classiﬁers. Left: binary classiﬁer. Right: multi-class classi-
ﬁer. The only diﬀerence is in the last layer. The binary classiﬁer uses one output neuron
with sigmoid activation, while the multi-class classiﬁer uses multiple output neurons with
softmax activation.

each of them. The convolutional layers were followed by a dense layer with
a dropout chance of 0.5 and connected to either one or multiple output
neurons (depending on the classiﬁer type being binary or multi-class). For
the binary type, the last layer used a sigmoid activation function, while the
multi-class classiﬁer used softmax. Therefore, both classiﬁer architectures
were identical except for the number of output neurons (one vs. multiple)
and the corresponding activation functions. An illustration of the structure
of the classiﬁers is shown in Fig. 3. The input to the network consisted of
a one-dimensional array of the coordinates of one streamline reordered in
an interleaved manner, such that the x-, y-, and z-coordinates of the same
point were subsequently following each other (i.e., x1, y1, z1, x2, y2, z2, ...).

Since the data labels were determined based on a ﬁltering method that
rejects the vast majority of streamlines, a large disproportion in the number
of training samples available for each class was expected. Thus, a balanced
data generator was used to oversample data of plausible streamlines for
network training and testing. The epoch size was deﬁned by the larger
of the classes such that each training sample was seen at least once per
epoch. The smaller set of samples was shuﬄed and re-used whenever it was
exhausted during an epoch. Each classiﬁer was trained towards maximizing
accuracy using the Adam optimizer [37] with default settings in TensorFlow
2.8.0 [37]. The training was done in batches of 50 samples each (except for

12

the categorical classiﬁer with three classes, which used a batch size of 60
such that each batch could contain an equal number of samples from each
class). Five training epochs were determined to be suﬃcient since accuracy
and loss saturated quickly and showed almost no improvement after two
epochs.

3. Results

3.1. Randomized SIFT on HCP data

Fig. 4 and 6 show the distribution of streamlines for the diﬀerent subset
sizes and AR ranges on the six HCP subjects. As shown, most of the
streamlines received either ARn = 0% or ARn = 100% after rSIFT for all
n. Notice that the fractions of those streamlines with 0% < ARn < 100%
increased when the subsets became smaller. Moreover, using smaller subset
sizes led to a substantial increase in streamlines with ARn = 100% even after
repeated evaluation: The number of streamlines with exclusively positive
votes rose from an average of 2.63% to 14.86%, comparing the largest and
the smallest subset sizes. Conversely, the streamlines with ARn = 0%
were reduced from 96.64% to 53.67%. As shown in the last column of
Fig. 4, the number of plausible and implausible streamlines for the whole
dataset are around 1.7% and 53.7%, which means that approximately 44.6%
of the streamlines can be considered as inconclusive. Interestingly, SIFT
yielded inconclusive results for on average 0.7% of the streamlines when the
complete tractogram was used (i.e., subset size of ten million), in four of
the HCP subjects.

As mentioned, the rSIFT procedure does not guarantee having the same
amount of votes for each streamline. Thus, we assessed the distribution of
ARs for streamlines with exactly ﬁve votes, as shown in Fig. 5. Although
the values are slightly diﬀerent in this case, they follow a very similar trend.
Due to the entirely random choice of streamlines for each round of the
experiment, we found that the number of streamlines that were not included
in any of the subsets in each subset size was negligible. They were not
included in Fig. 4. Every streamline received on average 35 votes over all
experiments, with an average of ﬁve votes per subset size.

We were further interested in assessing the inﬂuence of the streamline
length on the ﬁltering. As shown in Fig. 7, SIFT strongly inﬂuenced the
distribution of streamline lengths.
In fact, streamlines deemed plausible
were among the shortest and barely exceeded the length of 125mm. The

13

Figure 4: Distribution of streamlines per acceptance rates ARn and diﬀerent subset sizes
n. Each cell shows the mean ratio of streamlines across HCP subjects, with standard
deviations in parentheses. In the last column, percentages are computed over all exper-
iment instances and subset sizes, thus denoting AR instead of ARn. Note that the AR
intervals do not include the particular lower bound and include the upper bound, except
for 80–100%, where 100% is also excluded.

14

Figure 5: Distribution of streamlines per vote combination and subset size. Only com-
binations of exactly 5 votes are considered. “P: 0, N: 5” refers to “0 positive, 5 negative
votes” with the other rows labeled analogously. The cell values show the mean ratio of
streamlines across HCP subjects, with standard deviations in parentheses.

15

rSIFT streamline acceptance rates (ARn) by subset size n

100

80

60

40

20

s
e
n
i
l

m
a
e
r
t
s

f
o

e
g
a
t
n
e
c
r
e
P

53.67%

0

1.65%
0
1

2

3

ARn= 0%
ARn > 0%
ARn > 20%
ARn > 40%
ARn > 60%
ARn > 80%
ARn = 100%

7

8

9

10

4

5
Subset size (×106)

6

Figure 6: Evolution of acceptance rates (ARn) from rSIFT with the subset size n. Each
curve shows the percentage of streamlines with the respective AR, averaged over all
six HCP subjects. Standard deviations are shown in transparent (zoom in for details).
Dashed lines show the respective ARs considering all subset sizes at once for AR=0%
(in grey) and AR=100% (in orange). As shown, streamlines tend to get higher AR in
smaller subset sizes.

16

Figure 7: Distribution of streamlines accepted and rejected by SIFT with respect to their
length for one exemplary subject with ten million streamlines.

same pattern is shown for rSIFT in Fig. 8. Notice that the new class of
inconclusive streamlines covers the whole range of lengths.

3.2. Randomized SIFT on the DiSCo data

Fig. 9 summarizes the ARs of rSIFT on the DiSCo data with false posi-
tives, considering all subset sizes. Although SIFT ﬁlters out false positives
more often, it also ﬁlters out true positives. As shown, selecting a single
threshold of AR for distinguishing between true and false positives is chal-
lenging since it involves a compromise between ﬁltering out as few plausible
streamlines as possible at the cost of accepting more implausible ones or ﬁl-
tering out more plausible ones to minimize the false positives. For example,
using a threshold of 20% will lead to a rejection of 64.8% of false positives,
at the cost of losing 11.4% of true positives in this experiment. In turn, a
threshold of 80% will reject 87.7% false positives, but, at the same time,
it will reject almost half of the true positives (48.5%). As in the case of
the HCP data, analyzing the streamlines independently where SIFT is not
consistent might be beneﬁcial.

Fig. 10 shows the results of the experiment with DiSCo data with re-
dundant streamlines. Redundant streamlines are ﬁltered out more often
when they appear more frequently in the tractogram. For example, the
amount of streamlines with AR = 0% increases from 13.5% to 27.5% when
their multiplicity grows from 2 to 49, respectively. However, this increment
17

Figure 8: Distribution of streamlines labeled plausible (accepted), implausible (rejected),
and inconclusive by rSIFT with respect to their length for one exemplary subject with
ten million streamlines.

in the amount of rejected streamlines is relatively slow. For example, for
AR = 0%, the amount of streamlines only increases by 3.4% (13.5% vs.
16.9%) when increasing the number of redundant copies from 2 to 10. Re-
dundancy has a larger eﬀect at the other end: the number of streamlines
with AR = 100% decreases rapidly with the number of redundant copies.
Comparing Fig. 9 and 10, it can be seen that SIFT rejects more often true
positives when there are no false positives. As a comparison, around 53% of
streamlines (6 483 of 12 196) remain in the tractogram when SIFT is used
only once on the DiSCo ground truth streamline set.

3.3. Classiﬁcation performance

An overview of the performance of the three binary classiﬁers on HCP

data can be found in Fig. 11.

As shown, the binary classiﬁer for plausible and implausible streamlines
was around 80% accurate on the validation folds, with similar accuracy for
both classes. This shows that the procedure for balancing the classes was
appropriate for this task. In turn, the performance of the binary classiﬁers
trained to distinguish inconclusive streamlines from plausible or implausible
was much lower and very similar (e.g., accuracy was 67.80% and 66.09%,
respectively).

18

Figure 9: Distribution of acceptance rate (AR) for true positive (TP) and false positive
(FP) streamlines in the DiSCo dataset after running rSIFT with τ = 5 and four diﬀerent
subset sizes. The range 80–100% excludes AR = 100%. Note that the values in the
columns TP and FP sum to 100%, respectively.

19

Figure 10: Distribution of acceptance rate (AR) for true positive (TP) and redundant (R)
streamlines in the DiSCo dataset after running rSIFT with τ = 5 and four diﬀerent subset
sizes. The number in parentheses indicates the number of replications per streamline, i.e.,
how often they were found in the tractogram. The range 80–100% excludes AR = 100%.
Each column sums up to 100%.

20

Figure 11: Classiﬁer performance for binary classiﬁcation. “N” denotes “negative” (im-
plausible), “P” “positive” (plausible), and “I” inconclusive. The metrics are speciﬁed
through the mean values as determined by 5-fold cross-validation (CV) in training or
tests with unseen subjects during training, with standard deviations in parentheses.

21

Figure 12: Performance metrics of the multi-class classiﬁer. “N” denotes “negative”
(implausible), “P” “positive” (plausible) and “I” inconclusive. TPR = true positive
rate, TNR = true negative rate, TIR = true inconclusive rate.

As mentioned, we also evaluated the best-performing CV model for dis-
tinguishing negative and positive streamlines on the four unseen subjects.
As shown in Fig. 11, the results of this test were equal to the ﬁve-fold CV
experiment, with a mean accuracy of 80.2%.

Fig. 12 and 13 show the performance of the multi-class classiﬁer in terms
of the confusion matrix and accuracy-based metrics, respectively. This net-
work was trained to recognize the three classes ’P’, ’N’, and ’I’. While it
showed some success on the sets of plausible and implausible streamlines
(true positive rate (TPR) and true negative rate (TNR) around 70% in
Fig. 12, column maximum for ’P’ and ’N’ on the diagonal of confusion
matrix in Fig. 13), its performance remained at chance level for the incon-
clusive class (true inconclusive rate (TIR) less than 1/3 for three classes
in Fig. 12, similar values in all entries of column ’I’ in confusion matrix in
Fig. 13). Therefore, it seems that this classiﬁer is unable to tell the incon-
clusive streamlines apart from plausible or implausible ones in our pseudo
ground truth.

For further analyses, we chose the binary model between plausible and
implausible streamlines from the cross-validation fold that yielded the most
balanced sensitivity/speciﬁcity values (81.26% and 83.15%). Raw classiﬁer
scores for test samples from the positive class showed a mean of around
0.71 and a median of around 0.76, while the negative test samples received

22

Figure 13: Confusion matrix for the multi-class task involving samples from all three sets
from rSIFT. “N” denotes “negative” (implausible), “P” “positive” (plausible), and “I”
inconclusive. The cells show the mean percentage of streamlines belonging to this case
in cross-validation, with the standard deviation in parentheses. The columns show the
original labels, and the rows show the label given by the classiﬁer. Each column sums
up to 100%.

23

Figure 14: Histogram of streamline lengths of positive (P) streamlines, grouped by the
streamline labels obtained from the binary positive vs. negative (plausible vs.
implau-
sible) classiﬁer. The streamlines were taken from one test subject unseen in training.
Longer streamlines are more frequently misclassiﬁed (i.e., labeled diﬀerently by the clas-
siﬁer than by rSIFT). Negative classiﬁcations outnumber positive classiﬁcations above a
streamline length of around 75mm.

a mean score of around 0.28 and a median of around 0.21. These results sug-
gest that the classiﬁer was relatively conﬁdent about the results. However,
the mismatch between mean and median hints at the presence of outlier
streamlines. Accordingly, classiﬁcation scores had both a mean and a me-
dian of around 0.48 when the classiﬁer was applied to the inconclusive set,
which was not part of the training data.

We further split this set into two groups using a threshold of 0.5 on
the classiﬁcation score to get a set of leaning positive and leaning negative
streamlines. The mean scores of these two groups were 0.72 and 0.21, which
shows that they were slightly more oﬀ-center for the negative class.

As mentioned before, SIFT tends to ﬁlter out long streamlines. Fig. 14
and 15 show the performance of the binary classiﬁer (P vs. N) with respect
to the length of the streamlines. It is apparent that longer streamlines of
the positive class were misclassiﬁed more frequently (cf. Fig. 14), and the
same applies to the shorter streamlines of the negative class (cf. Fig. 15).
Applying the P vs. N classiﬁer to the inconclusive set, we found that, also
here, shorter streamlines tended more to be classiﬁed as plausible and longer
ones to be classiﬁed as implausible (cf. Fig. 16).

24

Figure 15: Histogram of streamline lengths of negative (N) streamlines, grouped by the
streamline labels obtained from the binary positive vs. negative (plausible vs.
implau-
sible) classiﬁer. The streamlines were taken from one test subject unseen in training.
Shorter streamlines are more frequently misclassiﬁed (i.e., labeled diﬀerently by the clas-
siﬁer than by rSIFT). Positive classiﬁcations outnumber negative classiﬁcations below a
streamline length of around 60mm.

Figure 16: Histogram of streamline lengths of inconclusive (I) streamlines, grouped by
im-
the streamline labels obtained from the binary positive vs. negative (plausible vs.
plausible) classiﬁer. The streamlines were taken from one test subject unseen in training.
Shorter streamlines are more frequently classiﬁed as positive, and longer streamlines are
more frequently as negative, with an equal amount of positive and negative predictions
around a streamline length of around 65mm.

25

Figure 17: Scatter plot relating classiﬁer scores of streamlines and their acceptance rate
from rSIFT. The data points (i.e., streamlines) in the plot are sampled in a balanced
manner such that all classes (i.e., plausible, implausible, and inconclusive) appear with
the same frequency, where blue represents the positive, orange the negative, and gray the
inconclusive class. As seen, scores for the positive and negative classes accumulate around
the ends of the spectrum. For the inconclusive samples, there is a weak correlation of
0.28 (depicted with the trend line) between scores and AR from rSIFT.

3.3.1. Comparison between classiﬁer scores and rSIFT

The correlation coeﬃcient for the relation between classiﬁer scores and
the ARs of inconclusive streamlines in rSIFT was moderately positive with
a value of 0.28. Fig. 17 depicts scores given by the classiﬁer to each class
and how they compare to the vote distribution from rSIFT.

In order to visualize clustering patterns of the three diﬀerent sets, we
used a t-stochastic neighbor embedding (t-SNE) [38], which enables high-
dimensional input vectors to be projected into a 2-dimensional plane. This
way, hidden structures in the data as well as the closeness of data points
in high-dimensional space can be made visible. We applied t-SNE to the
streamlines’ feature vectors taken from the 4-th (pre-dense) network layer
to examine if the streamline groups were clustered together. For the sets of
streamlines, we used the pseudo ground truth and inconclusive streamlines
with 0% <= AR < 20%, or 80% < AR <= 100%, respectively. These
inconclusive streamlines are expected to be closer to the pseudo ground
truth data.

Plots of t-SNE were ﬁne-tuned to a learning rate and perplexity of 100

26

each and 800 iterations. The comparison of t-SNE results with and without
inconclusive streamlines using balanced sampling can be seen in Fig. 18.

As shown, the positive and negative streamlines formed multiple small
clusters which were positioned close to each other (cf. Fig. 18a). When
additionally presented with samples from the inconclusive class, small dif-
ferences were noticeable depending on if samples with low or high AR were
used. Especially the latter seemed to be more close to the clusters of the
plausible streamlines (cf. blue and black dots in Fig. 18c).

4. Discussion

Tractogram ﬁltering based on methods like SIFT oﬀers the opportunity
to improve the match of a given tractogram with the measured diﬀusion
MRI data. However, the ability of SIFT to assign binary labels of stream-
line plausibility is inherently limited. In this paper, we propose a random-
ized iterative adaptation, called rSIFT, as a way to address this limitation
of SIFT. We analyzed rSIFT in experiments on human and phantom data
and employed neural network-based streamline classiﬁers further to charac-
terize the properties of the output of our method. Additionally, the trained
classiﬁers underline the potential for tractogram ﬁltering being performed
by neural networks at a reduced computational cost. In the following sub-
sections, we discuss diﬀerent aspects of our ﬁndings in further detail.

4.1. SIFT

Our experiments highlight how the ﬁltering performed by SIFT depends
not only on the characteristics of a streamline but also on the size and
composition of the streamline set used as the input. As shown in the pre-
sented results, the same streamline can be accepted and rejected in diﬀerent
SIFT runs depending on the streamlines contained in the analyzed trac-
togram. This ambiguity, reﬂected in the inconclusive class from rSIFT, is
more prominent with smaller tractograms. Through the randomized and it-
erative approach, rSIFT is designed to exploit this dependency of the SIFT
output on the composition of the input tractogram.

This dependency on the input tractogram is rooted in the global opti-
mization approach for improving the consistency between tractogram and
diﬀusion data. It implies that the focus of SIFT lies in ﬁtting all stream-
lines simultaneously to the diﬀusion data instead of assessing an individual

27

a) P/N

b) P/N/I(AR ≤ 20%)

c) P/N/I(AR ≥ 80%)

Figure 18: t-SNE results. Orange dots represent streamlines from the implausible pseudo
ground truth, blue dots represent streamlines from the plausible pseudo ground truth, and
black dots show inconclusive streamlines. The upper row does not include inconclusive
samples. In the middle row, inconclusive samples with an acceptance rate AR ≤ 20% in
rSIFT were used. The bottom row shows the results with inconclusive streamlines with
AR ≥ 80%.

28

streamline alone. As shown in the experiments, ﬁltering a tractogram con-
taining fewer streamlines with SIFT will directly lead to an increase in ac-
cepted streamlines (2.6% for the whole tractogram vs. 14.9% for the small-
est subset size), a decrease in rejected ones (96.6% vs. 56.8%, respectively),
and an increase in streamlines for which SIFT gives mixed results (0.7%
vs. 28.4%). One possible explanation is that smaller tractograms might
contain fewer redundant streamlines making it more likely for streamlines
to be accepted.

As a consequence, we argue that SIFT in its original form with only a
single run is not perfectly suited for the assessment of individual streamline
plausibility with respect to the diﬀusion data. In fact, for some of the HCP
tractograms, the results diﬀered even when the set of streamlines did not:
In the experiment instance where the complete tractogram was repeatedly
ﬁltered (i.e. subset size 10 million), around 0.7% of the streamlines received
mixed votes even though the overall tractogram remained the same, but
was arranged in shuﬄed order due to our random sampling of streamlines.
A general limitation of SIFT is that the method is indiﬀerent to why
streamlines do not match the data. As mentioned in the introduction,
anatomical implausibility is just one possible reason, but another possible
explanation can be that the streamline in question contributes to a white
matter ﬁber bundle that has been reconstructed with exaggerated stream-
line density compared to other bundles, relative to the measured data. This
is supported by our ﬁndings on the DiSCo data: As shown in Fig. 10, re-
dundant streamlines are rejected more often when they appear with a higher
frequency in the dataset. At the same time, SIFT rejects true positives more
often when there are no false positives present in the tractogram. Together,
this shows that SIFT rejects not only implausible, but also both plausible
and redundant streamlines. However, for purposes such as ﬁnding training
samples for a machine learning classiﬁer or for the purpose of combining
several ﬁltering methodologies in an ensemble fashion, as showcased in [27],
there is a need for methods performing the distinction between plausible
and implausible streamlines more reliably than what is achievable with a
single run of SIFT.

4.2. Randomized SIFT

The proposed method, rSIFT, is a randomized, iterative adaptation of
SIFT with the aim to separate plausible (including redundant) streamlines
from implausible ones. Through the repeated application of SIFT to ran-
dom tractogram subsets, we deﬁned distilled sets of streamlines that are
29

consistently categorized as either ﬁtting the diﬀusion data well or not, thus
deemed plausible or implausible in the sense of SIFT. Despite a large amount
of votes per streamline (35 on average), the repeated SIFT assessments were
consistent for around half of the streamlines in the HCP tractograms. Based
on this, these streamlines might also possess distinct characteristics that a
machine learning classiﬁer may be able to learn. Thus, they are suitable
for creating a pseudo ground truth of plausible and implausible streamlines
with consistent characteristics within each of the two label groups, as we
did in this study.

On the other hand, around half of the streamlines were inconclusive, with
ARs between 0% and 100%. Some of these streamlines may be outliers that
received mostly consistent votes. Apart from those, we suspected that the
group of inconclusives contains a large number of redundant streamlines
as well. By choosing random subsets of the tractogram and thus omitting
potentially similar streamlines that would “rival” a candidate redundant
streamline, our ﬁltering procedure allows such streamlines to receive more
positive votes than in the context of the full tractogram. Indeed, our ex-
periments show that this group of inconclusive streamlines likely contains
a mixture of both redundant, i.e., actually plausible, as well as implausible
streamlines. Naturally, alternative choices of AR thresholds for the sepa-
ration of plausible, inconclusive, and implausible streamlines are possible.
Actually, our results show that streamlines in the inconclusive group with
higher and lower AR (e.g., higher than 80% and lower than 20%) share
similar characteristics with plausible and implausible streamlines, respec-
tively. This is a promising avenue for future research to better understand
the composition of the group of inconclusive streamlines.

In general, it needs to be noted that the labeling of a streamline as “plau-
sible” through SIFT represents more of an absence of the label “implausi-
ble”. One could even argue that those plausible streamlines had remained
in the tractogram because there were other streamlines that demonstrated
to be even less plausible before ﬁltering was terminated. However, we think
this to be unlikely as, from our experience, SIFT ﬁlters streamlines quite
strictly compared to other tractogram ﬁltering methods, leading to the re-
moval of a signiﬁcant amount of streamlines. For example, it is interesting
that SIFT only kept 53% of the streamlines in the original DiSCo data.
This value was even lower for AR=100% after rSIFT (35.0% and 33.2% for
the false positives and redundant experiments). This means that SIFT may,
in general, be too restrictive, and a threshold on AR can be set to a lower

30

value (e.g., 80%) to distinguish between plausible and implausible stream-
lines. Of course, such a threshold involves a trade-oﬀ between rejected false
positives and removed true positives.

It is important to emphasize that, as discussed in Smith et al.

[39],
SIFT results tend to correlate with streamline length. Since rSIFT builds
on SIFT, this characteristic is inherited and also rSIFT, and the trained
classiﬁers show this tendency to keep shorter streamlines.
It would be
interesting to assess if this correlation is a bias of SIFT or if the longer
streamlines are more likely to be implausible.

Finally, notice that while rSIFT is based on SIFT, they have diﬀerent
goals and applications. While SIFT assesses the consistency of the whole
tractogram with respect to the measured data, rSIFT augments this goal
with the assessment of the stability of these results and thus becomes more
speciﬁc for individual streamlines.

4.3. rSIFT neural network classiﬁer

We employed diﬀerent neural network classiﬁers to investigate the in-
conclusive streamlines in rSIFT as well as to showcase the potential of such
machine learning-based approaches for the purpose of reducing the compu-
tational burden of our method.

The classiﬁer which was trained to tell apart the plausible and implau-
sible samples showed good accuracy. This indicates that some distinct
structural information that may separate the two sets of streamlines was
recognized, even in data samples unseen during training. Since rSIFT is
time-consuming, it is relevant to assess whether the obtained classiﬁcation
scores could be used as an alternative to the SIFT-based method. The
distributions of classiﬁcation scores show that it is unlikely for a plausible
streamline to receive a classiﬁer score that is lower than the average (0.28) or
median (0.21) scores for implausible streamlines. Considering the diﬀerence
in the size of the groups of plausible and implausible streamlines, we would
argue that streamlines with scores lower than approximately 0.2 could be
safely removed. Such a strategy could signiﬁcantly reduce the number of
false-positive streamlines in a tractogram and would require little compu-
tational eﬀort once the classiﬁcation neural network has been trained.

Since the performance of the binary classiﬁers distinguishing plausi-
ble from implausible streamlines carried over to unseen data (of plausi-
ble/implausible samples), it may also be suited to identify such information
in the streamlines assigned to the inconclusive group. However, employing

31

a similar network architecture, the three-class network was unable to rec-
ognize the inconclusive samples (cf. TPR and TNR in Fig. 12). The same
tendency was found for the binary approaches to distinguish inconclusive
from plausible or implausible streamlines, respectively (in both cases, ac-
curacy, sensitivity, and speciﬁcity decreased signiﬁcantly compared to the
N vs. P case, as seen in Fig. 11). This suggests that there is no inherent
structural diﬀerence between inconclusive and likely plausible or implausi-
ble samples obtained through rSIFT. The ﬁndings of the t-SNE experiment
further show that inconclusive streamlines are clustered together with the
likely plausible and implausible samples. Additionally, their acceptance rate
seems to be related to the observation of being closer to one group or the
other. Taking this into account, as well as the performance of the classiﬁers,
it can be inferred that the inconclusive samples are a mixture of plausible
(containing redundant) and implausible streamlines.

Notice that the binary classiﬁer (plausible vs. implausible) yielded good
results in both cross-validation as well as classiﬁcation of unseen data de-
spite the fact that its only input is the streamline coordinates. In contrast,
SIFT considers the FOD data. This observation is consistent with the re-
sults in [27] that showed that the coordinates of the streamlines are the
most important features for the prediction of diﬀerent tractogram ﬁltering
methods, followed by diﬀusion data.

Further, the presented classiﬁcation results were achieved with a rela-
tively simple neural network architecture. In preliminary experiments, we
explored the architecture of the classiﬁer (e.g., adding more layers or batch
normalization) without a large improvement in performance. However, ways
of building more sophisticated classiﬁers achieving even better accuracy are
a direction of research that may be explored more in the future. For datasets
that suﬀer from severe data imbalance (such as our training data), speciﬁc
care may be put on recognizing the false positive samples in order to help
decrease their number in comparison to the true positives.

4.4. Future work

There are many avenues for extending the current study. While we
focused our experiments on SIFT, the same methodology can be applied
to similar tractogram ﬁltering methods such as LiFE [18], COMMIT [19],
SIFT2 [20], or COMMIT2 [21, 22, 23]. It may be particularly interesting to
investigate if the presented ﬁndings would generalize to these methods as
well. Also, further performance evaluation with other tractography methods
and images acquired with clinical settings is relevant.

32

Regarding the classiﬁer, one possibility is to add diﬀerent input features
as done, e.g., in [40, 27], which described the streamline’s structure in a
more sophisticated manner or add diﬀusion data [41, 27].

As discussed previously, rSIFT can be used to assess streamline plausi-
bility or to use it for training machine learning-based classiﬁers, as we did
in this paper. An additional interesting application would be to combine
ﬁltering and tractography in order to improve the quality of the tractogram
from its generation.

5. Conclusion

In this paper, we proposed rSIFT, a randomized and iterative adapta-
tion of SIFT that allows assessing the plausibility of individual streamlines
with improved speciﬁcity. rSIFT was used to generate pseudo ground truths
for the training of machine learning-based classiﬁers. These classiﬁers were
used to study the characteristics of diﬀerent types of streamlines (plausi-
ble, implausible, and inconclusive) and to speed up the computations. We
show how to use AR from rSIFT or the classiﬁcation scores for distinguish-
ing plausible and implausible streamlines. Streamlines with inconclusive
results from rSIFT are likely to be a mixture of redundant and implausible
streamlines.

Acknowledgments

Data for this study were provided in part by the Human Connectome
Project, WU-Minn Consortium (Principal Investigators: David Van Essen
and Kamil Ugurbil; 1U54MH091657) funded by the 16 NIH Institutes and
Centers that support the NIH Blueprint for Neuroscience Research; and by
the McDonnell Center for Systems Neuroscience at Washington University.
We thank Jakob Wasserthal for computing and providing the tractograms

we used in this paper.

Antonia Hain was aﬃliated with Saarland University at the time the pre-
sented research was conducted and is now with the Department Quality As-
surance, Characterization and Simulation at Fraunhofer Institute for Solar
Energy Systems ISE, Heidenhofstr. 2, 79110 Freiburg, Baden-W¨urttemberg,
Germany.

33

Funding sources

This work was partially supported by Digital Futures, project dBrain.
The funding sources had no involvement in the research and preparation of
this article.

Author contributions

AH: conceptualization; formal analysis; investigation; methodology; soft-
ware; validation; visualization; writing - original draft; writing - review &
editing. DJ: conceptualization; formal analysis; investigation; methodol-
ogy; software; validation; visualization; writing - original draft; writing -
review & editing. RM: conceptualization; funding acquisition; methodol-
ogy; visualization; resources; project administration; supervision; writing -
review & editing.

Conﬂicts of interest/Competing interests

The authors declare that they have no conﬂict of interest.

Data and code availability statement

We used data from the Human Connectome Project and the DiSCo
challenge. The software code used in the paper and pretrained weights of
the classiﬁer are distributed freely via the Github repository
https://github.com/djoerch/randomised ﬁltering.

References

[1] D. Ugurlu, Z. Firat, U. Ture, G. Unal, Supervised classiﬁcation of white matter
ﬁbers based on neighborhood ﬁber orientation distributions using an ensemble of
neural networks, in: Proc. MICCAI 2019: Computational Diﬀusion MRI, 2019, pp.
143–154. doi:10.1007/978-3-030-05831-9\_12.

[2] B. Jeurissen, M. Descoteaux, S. Mori, A. Leemans, Diﬀusion MRI ﬁber tractography

of the brain, NMR in Biomedicine 32 (2017). doi:10.1002/nbm.3785.

[3] M. Frigo, S. Deslauriers-Gauthier, D. Parker, A. A. Ould Ismail, J. J. Kim,
R. Verma, R. Deriche, Diﬀusion MRI tractography ﬁltering techniques change the
topology of structural connectomes., Journal of Neural Engineering 17 (6) (2020).
doi:10.1088/1741-2552/abc29b.

[4] S. S. Panesar, K. Abhinav, F. C. Yeh, T. Jacquesson, M. Collins, J. Fernandez-
Miranda, Tractography for Surgical Neuro-Oncology Planning: Towards a
Gold Standard, Neurotherapeutics 16 (1)
doi:10.1007/
S13311-018-00697-X.

(2019) 36–51.

34

[5] K. Yamada, K. Sakai, K. Akazawa, S. Yuen, T. Nishimura, MR tractography: A
review of its clinical applications, Magnetic resonance in medical sciences 8 (2009)
165–74. doi:10.2463/mrms.8.165.

[6] Y. Assaf, H. Johansen-Berg, M. Thiebaut de Schotten, The role of diﬀusion MRI in
neuroscience, NMR in Biomedicine 32 (4) (2019) e3762. doi:10.1002/nbm.3762.
[7] F. Rheault, P. Poulin, A. Caron, E. St-Onge, M. Descoteaux, Common misconcep-
tions, hidden biases and modern challenges of dMRI tractography, Journal of Neural
Engineering 17 (2020). doi:10.1088/1741-2552/ab6aad.

[8] K. G. Schilling, L. Petit, F. Rheault, S. Remedios, C. Pierpaoli, A. Anderson,
B. Landman, M. Descoteaux, Brain connections derived from diﬀusion MRI trac-
tography can be highly anatomically accurate—if we know where white matter
pathways start, where they end, and where they do not go, Brain Structure and
Function 225 (2020) 2387—-2402. doi:10.1007/s00429-020-02129-z.

[9] K. G. Schilling, C. M. Tax, F. Rheault, C. Hansen, Q. Yang, F.-C. Yeh, L. Cai,
A. W. Anderson, B. A. Landman, Fiber tractography bundle segmentation depends
on scanner eﬀects, vendor eﬀects, acquisition resolution, diﬀusion sampling scheme,
diﬀusion sensitization, and bundle segmentation workﬂow, NeuroImage 242 (2021)
118451. doi:10.1016/j.neuroimage.2021.118451.

[10] K. H. Maier-Hein, P. F. Neher, J.-C. Houde, M.-A. Cˆot´e, E. Garyfallidis, J. Zhong,
M. Chamberland, F.-C. Yeh, Y.-C. Lin, Q. Ji, W. E. Reddick, J. O. Glass, D. Q.
Chen, Y. Feng, C. Gao, Y. Wu, J. Ma, R. He, Q. Li, C.-F. Westin, S. Deslauriers-
Gauthier, J. O. O. Gonz´alez, M. Paquette, S. St-Jean, G. Girard, F. Rheault,
J. Sidhu, C. M. W. Tax, F. Guo, H. Y. Mesri, S. D´avid, M. Froeling, A. M.
Heemskerk, A. Leemans, A. Bor´e, B. Pinsard, C. Bedetti, M. Desrosiers, S. Bram-
bati, J. Doyon, A. Sarica, R. Vasta, A. Cerasa, A. Quattrone, J. Yeatman, A. R.
Khan, W. Hodges, S. Alexander, D. Romascano, M. Barakovic, A. Aur´ıa, O. Es-
teban, A. Lemkaddem, J.-P. Thiran, H. E. Cetingul, B. L. Odry, B. Mailhe, M. S.
Nadar, F. Pizzagalli, G. Prasad, J. E. Villalon-Reina, J. Galvis, P. M. Thompson,
F. De Santiago Requejo, P. L. Laguna, L. M. Lacerda, R. Barrett, F. Dell’Acqua,
M. Catani, L. Petit, E. Caruyer, A. Daducci, T. B. Dyrby, T. Holland-Letz, C. C.
Hilgetag, B. Stieltjes, M. Descoteaux, The challenge of mapping the human connec-
tome based on diﬀusion tractography, Nature Communications 8 (1) (2017) 1349.
doi:10.1038/s41467-017-01285-x.

[11] C. Thomas, F. Q. Ye, M. O. Irfanoglu, P. Modi, K. S. Saleem, D. A. Leopold,
C. Pierpaoli, Anatomical accuracy of brain connections derived from diﬀusion MRI
tractography is inherently limited, Proceedings of the National Academy of Sciences
111 (46) (2014) 16574–16579. doi:10.1073/pnas.1405672111.

[12] L. Petit, F. Rheault, M. Descoteaux, N. Tzourio-Mazoyer, Half of the streamlines
built in a whole human brain tractogram is anatomically uninterpretable., in: Proc.
OHBM, 2019, p. 1118488. doi:10.7490/f1000research.1118488.1.

[13] D. Wassermann, N. Makris, Y. Rathi, M. Shenton, R. Kikinis, M. Kubicki, C.-F.
Westin, The white matter query language: a novel approach for describing human
white matter anatomy, Brain Structure and Function 221 (9) (2016) 4705–4721.
doi:10.1007/s00429-015-1179-4.

[14] E. Garyfallidis, M.-A. Cˆot´e, F. Rheault, J. Sidhu, J. Hau, L. Petit, D. Fortin,
S. Cunanne, M. Descoteaux, Recognition of white matter bundles using local and

35

global streamline-based registration and clustering, NeuroImage 170 (2018) 283–295.
doi:10.1016/j.neuroimage.2017.07.015.

[15] R. E. Smith, J.-D. Tournier, F. Calamante, A. Connelly, SIFT: Spherical-
deconvolution informed ﬁltering of tractograms, NeuroImage 67 (2013) 298–312.
doi:10.1016/j.neuroimage.2012.11.049.

[16] D. J¨orgens, M. Descoteaux, R. Moreno, Challenges for tractogram ﬁltering, in:
E. ¨Ozarslan, T. Schultz, E. Zhang, A. Fuster (Eds.), Anisotropy Across Fields and
Scales, Springer International Publishing, Cham, 2021, pp. 149–168. doi:10.1007/
978-3-030-56215-1\_7.

[17] S. Jbabdi, H. Johansen-Berg, Tractography: Where do we go from here?, Brain

connectivity 1 (2011) 169–83. doi:10.1089/brain.2011.0033.

[18] F. Pestilli, J. Yeatman, A. Rokem, K. Kay, H. Takemura, B. Wandell, LiFE: Linear
Fascicle Evaluation a new technology to study visual connectomes, Journal of Vision
14 (2014) 1122–1122. doi:10.1167/14.10.1122.

[19] A. Daducci, A. Dal Pal`u, A. Lemkaddem, J.-P. Thiran, COMMIT: Convex opti-
mization modeling for microstructure informed tractography, IEEE Transactions on
Medical Imaging 34 (1) (2015) 246–257. doi:10.1109/TMI.2014.2352414.

[20] R. E. Smith, J.-D. Tournier, F. Calamante, A. Connelly, SIFT2: Enabling dense
quantitative assessment of brain white matter connectivity using streamlines trac-
tography, NeuroImage 119 (2015) 338–351. doi:10.1016/j.neuroimage.2015.06.
092.

[21] S. Schiavi, M. Ocampo-Pineda, M. Barakovic, L. Petit, M. Descoteaux, J.-P. Thiran,
A. Daducci, A new method for accurate in vivo mapping of human brain connections
using microstructural and anatomical information, Science Advances 6 (31) (2020)
eaba8245. doi:10.1126/sciadv.aba8245.

[22] M. Ocampo-Pineda, S. Schiavi, F. Rheault, G. Girard, L. Petit, M. Descoteaux,
A. Daducci, Hierarchical microstructure informed tractography, Brain Connectivity
11 (2) (2021) 75–88. doi:10.1089/brain.2020.0907.

[23] V. Sairanen, M. Ocampo-Pineda, C. Granziera, S. Schiavi, A. Daducci, Incorporat-
ing outlier information into diﬀusion-weighted mri modeling for robust microstruc-
tural imaging and structural brain connectivity analyses, NeuroImage 247 (2022)
118802. doi:10.1016/j.neuroimage.2021.118802.

[24] J.-D. Tournier, F. Calamante, D. G. Gadian, A. Connelly, Direct estimation of the
ﬁber orientation density function from diﬀusion-weighted MRI data using spherical
deconvolution, NeuroImage 23 (3) (2004) 1176–1185. doi:10.1016/j.neuroimage.
2004.07.037.

[25] R. E. Smith, J.-D. Tournier, F. Calamante, A. Connelly, SIFT2: Enabling dense
quantitative assessment of brain white matter connectivity using streamlines trac-
tography, NeuroImage 119 (2015) 338–351. doi:10.1016/j.neuroimage.2015.06.
092.

[26] P. Astolﬁ, R. Verhagen, L. Petit, E. Olivetti, J. Masci, D. Boscaini, P. Avesani,
Tractogram ﬁltering of anatomically non-plausible ﬁbers with geometric deep learn-
ing, Medical Image Computing and Computer Assisted Intervention – MICCAI 2020
12267 LNCS (2020) 291–301. doi:10.1007/978-3-030-59728-3\_29.

[27] D. J¨orgens, P.-M. Jodoin, M. Descoteaux, R. Moreno, Merging multiple input
descriptors and supervisors in a deep neural network for tractogram ﬁltering,

36

manuscript (2022).

[28] M. F. Glasser, S. N. Sotiropoulos, J. A. Wilson, T. S. Coalson, B. Fischl, J. L. Ander-
sson, J. Xu, S. Jbabdi, M. Webster, J. R. Polimeni, D. C. Van Essen, M. Jenkinson,
The minimal preprocessing pipelines for the Human Connectome Project, NeuroIm-
age 80 (2013) 105–124, mapping the Connectome. doi:10.1016/j.neuroimage.
2013.04.127.

[29] D. C. Van Essen, S. M. Smith, D. M. Barch, T. E. Behrens, E. Yacoub, K. Ugurbil,
The WU-Minn Human Connectome Project: An overview, NeuroImage 80 (2013)
62–79, mapping the Connectome. doi:10.1016/j.neuroimage.2013.05.041.
[30] J. Wasserthal, P. Neher, K. H. Maier-Hein, TractSeg - Fast and accurate white
doi:10.1016/j.

matter tract segmentation, NeuroImage 183 (2018) 239–253.
neuroimage.2018.07.070.

[31] J.-D. Tournier, F. Calamante, A. Connelly, Improved probabilistic streamlines trac-
tography by 2nd order integration over ﬁbre orientation distributions, Proc. Intl.
Soc. Mag. Reson. Med. (ISMRM) 18 (2010).

[32] R. E. Smith, J.-D. Tournier, F. Calamante, A. Connelly, Anatomically-constrained
tractography: Improved diﬀusion MRI streamlines tractography through eﬀective
use of anatomical information, NeuroImage 62 (3) (2012) 1924–1938. doi:10.1016/
j.neuroimage.2012.06.005.

[33] C. Presseau, P.-M. Jodoin, J.-C. Houde, M. Descoteaux, A new compression for-
mat for ﬁber tracking datasets, NeuroImage 109 (2015) 73–83. doi:/10.1016/j.
neuroimage.2014.12.058.

[34] J.-D. Tournier, R. Smith, D. Raﬀelt, R. Tabbara, T. Dhollander, M. Pietsch,
D. Christiaens, B. Jeurissen, C.-H. Yeh, A. Connelly, MRtrix3: A fast, ﬂexible
and open software framework for medical image processing and visualisation, Neu-
roImage 202 (2019) 116137. doi:10.1016/j.neuroimage.2019.116137.

[35] E. Garyfallidis, M. Brett, B. Amirbekian, A. Rokem, S. Van Der Walt, M. De-
scoteaux, I. Nimmo-Smith, Dipy, a library for the analysis of diﬀusion MRI data,
Frontiers in Neuroinformatics 8 (2014) 8. doi:10.3389/fninf.2014.00008.
[36] J. Rafael-Patino, G. Girard, R. Truﬀet, M. Pizzolato, E. Caruyer, J.-P. Thiran, The
diﬀusion-simulated connectivity (disco) dataset, Data in Brief 38 (2021) 107429.
doi:/10.1016/j.dib.2021.107429.

[37] D. P. Kingma, J. Ba, Adam: A method for stochastic optimization (2017). arXiv:

1412.6980.

[38] L. van der Maaten, G. Hinton, Visualizing data using t-SNE, Journal of Machine

Learning Research 9 (86) (2008) 2579–2605.
URL http://jmlr.org/papers/v9/vandermaaten08a.html

[39] R. E. Smith, J.-D. Tournier, F. Calamante, A. Connelly, The eﬀects of SIFT on the
reproducibility and biological accuracy of the structural connectome, NeuroImage
104 (2015) 253–265. doi:10.1016/j.neuroimage.2014.10.004.

[40] P. D. Ngattai Lam, G. Belhomme, J. Ferrall, B. Patterson, M. Styner, J. C. Prieto,
TRAFIC: Fiber tract classiﬁcation using deep learning, Proceedings of SPIE–the
International Society for Optical Engineering 10574 (2018) 37. doi:10.1117/12.
2293931.

[41] D. J¨orgens, P. Poulin, R. Moreno, P.-M. Jodoin, M. Descoteaux, Towards a deep
learning model for diﬀusion-aware tractogram ﬁltering, in: Proc. Int. Soc. Magn.

37

Reson. Med. ISMRM-ESMRMB, 2019, p. 3375.

38

