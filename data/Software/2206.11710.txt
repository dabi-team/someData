Tracking Janus microswimmers in 3D with Machine
Learning

Maximilian R. Bailey,∗a Fabio Grilloa, and L. Isa∗a
aLaboratory for Soft Materials and Interfaces, Department of Materials, ETH Z¨urich,
Vladimir-Prelog-Weg 5, 8093 Z¨urich, Switzerland
∗To whom correspondence should be addressed:
E-mail: maximilian.bailey@mat.ethz.ch;

E-mail: lucio.isa@mat.ethz.ch

Abstract

Advancements in artiﬁcial active matter heavily rely on our ability to characterise their
motion. Yet, the most widely used tool to analyse the latter is standard wide-ﬁeld mi-
croscopy, which is largely limited to the study of two-dimensional motion. In contrast,
real-world applications often require the navigation of complex three-dimensional environ-
ments. Here, we present a Machine Learning (ML) approach to track Janus microswimmers
in three dimensions, using Z-stacks as labelled training data. We demonstrate several ex-
amples of ML algorithms using freely available and well-documented software, and ﬁnd
that an ensemble decision tree-based model (Extremely Randomised Decision Trees) per-
forms the best at tracking the particles over a volume spanning a depth of more than 40 µm.
With this model, we are able to localise Janus particles with a signiﬁcant optical asymmetry
from standard wide-ﬁeld microscopy images, bypassing the need for specialised equipment
and expertise such as that required for digital holographic microscopy. We expect that ML
algorithms will become increasingly prevalent by necessity in the study of active matter
systems, and encourage experimentalists to take advantage of this powerful tool to address
the various challenges within the ﬁeld.

2
2
0
2

n
u
J

3
2

]
t
f
o
s
.
t
a
m
-
d
n
o
c
[

1
v
0
1
7
1
1
.
6
0
2
2
:
v
i
X
r
a

1

 
 
 
 
 
 
1

Introduction

Inspired by the collective phenomena that emerge in biological systems across a range of length

scales, active matter systems – agents that transduce freely available energy into directed mo-

tion (1) – have been the subject of extensive research in soft matter and statistical physics. In

particular, the behaviour of active materials at the microscale is of interest due to the interplay

between thermal ﬂuctuations and the driving force of motion. This driving force makes active

matter systems intrinsically out-of-equilibrium, and endows them with promising properties for

applications, ranging from smart drug delivery (2) to water remediation (3).

Perhaps the most popular model system to study the dynamics of active matter are Janus mi-

croswimmers (4), which are also arguably the simplest class of synthetic active agents. These

(typically micron-sized) particles possess patches with different chemical or physical properties

(e.g. catalytic activity) that can generate asymmetric gradients around the particle under certain

experimental conditions, leading to motion by self-phoresis (5–8). The dynamics of these Janus

microswimmers are typically conﬁned to 2D because of their density and interactions with the

substrate, whether they move by self-diffusiophoresis (9) or self-dielectrophoresis (10). How-

ever, from an applications perspective, the ability to navigate in 3D is highly desirable (11). As

such, there is a growing interest in the synthesis of microswimmers that display 3D motion and

in developing greater understanding of their swimming behaviour (12–16).

Unfortunately, tracking the motion of microswimmers in the third dimension presents new

experimental challenges that must be overcome. Conventional light-microscopy techniques are

ill-suited to track the diffusion of micron-sized objects in three dimensions, especially when the

particles exhibit enhanced mobility. A widespread approach to studying (ﬂuorescent) colloids

in 3D is confocal microscopy (17). This involves scanning the volume of interest via a series

of Z-stacks, using a pinhole to exclude signal outside the imaged Z-slice. The resultant inten-

2

sity distributions of the ﬂuorescent particles are then used to obtain a 3D reconstruction from

which the particle centres can be identiﬁed. This methodology, although accurate, is limited in

temporal resolution by the time taken between subsequent Z stacks (18). In the case of active

Janus colloids, which can move several body-lengths per second, this leads to a smearing of the

traced particle and thus difﬁculties in accurate centre ﬁnding. Furthermore, the surface patches

of Janus microswimmers, typically realized with thin metal ﬁlms, leads to an asymmetry in

its optical properties, hindering the proper reconstruction of the intensity distribution and thus

jeopardising the tracking.

To overcome these issues, Campbell et al. used the method previously proposed by Spiedel

et al.

for passive particles to track the vertical position of ﬂuorescent gravitactic Janus mi-

croswimmers from 2D microscopy images using the outermost radius of the concentric rings of

the ﬂuorescent particles as they swim out of focus (19, 20). Unlike confocal microscopy, this

method does not require a rigorous model and knowledge of the optical properties of the micro-

scope. A single Janus particle was ﬁxated in gellan gum, from which the “bright ring radius”

of the ﬂuorescent particle was extracted at different heights, to which a calibration curve was

ﬁtted using a cubic polynomial. The heights of the Janus microswimmers were then predicted

from the evolution of the bright ring radius of the ﬂuorescent Janus microswimmers taken from

a single 2D plane. The described method effectively extracted 3D trajectories from 2D videos

using a ﬂuorescent microscope and a basic piezo Z-stage, allowing standard microscopy im-

age acquisition conditions. However, it is noteworthy that the radius of the bright rings can be

on the order of hundreds of pixels, and as the rings cannot overlap, this limits 3D tracking to

very dilute suspensions. Zhang et al. proposed a similar approach to track thermally-diffusing

non-ﬂuorescent particles by radially projecting the diffraction pattern of a particle and com-

paring it to a reference model obtained with a Z-stack (21). Least-squares ﬁtting of the radial

proﬁle is then used to determine the Z-height, which minimises the difference between the ra-

3

dial projection of the imaged particle and the reference model. This method is highly sensitive

to asymmetries in the particle, and therefore is not viable for a freely-rotating Janus particle.

Likewise, the detailed methodology presented by Kovari et al., solving for the vertical posi-

tion by minimising the difference between the interpolated, continuous look up table (LUT) of

radial proﬁles taken with Z-stacks and the radial proﬁle of the imaged particle, relies on the

Mie scattering of symmetric particles (22), and therefore also cannot be applied effectively to

microswimmers with signiﬁcant optical asymmetries.

To track non-ﬂuorescent particles in 3D, digital holographic microscopy has emerged as

a powerful technique capable of digitally reconstructing 3D images with holograms obtained

from the interference pattern between the sample and a reference laser beam (18). The method-

ology has been demonstrated to track the motion of photo-gravitactic microswimmers in 3D

(23), albeit those that principally swim directly upwards, which minimises the extent of visi-

ble cap asymmetry. The optical asymmetry of a Janus particle, and the particle-wise variations

present in their surface patches, would otherwise further complicate holographic reconstruc-

tion (24). Midtvedt et al. used Machine Learning (ML) U-Nets, a convolutional encoder-

decoder neural network architecture, to interpret in-line holographic data obtained with local-

ization accuracies comparable in performance to off-axis holographic microscopy (25). They

were thus able to reduce the computational cost of holographic microscopy-based 3D tracking.

Their DeepTrack 2.0 software provides a fascinating test case for the applicability of ML to

the 3D (and 2D) tracking of particles. Despite this potential decrease in computational cost,

holographic microscopy still requires specialised imaging conﬁgurations, limiting the general

accessibility of this technique. Furthermore, the U-Net is trained on simulated Mie scatter-

ing spectra of spherical particles, which does not account for the asymmetries present in Janus

particles, which can have implications for accuracy as discussed above. Therefore, a general ap-

proach enabling the 3D tracking of spherical non-ﬂuorescent microswimmers with asymmetries

4

in their optical properties is still lacking.

For example, photocatalytic TiO2-SiO2 Janus microswimmers synthesised in large quan-

tities via Toposelective Nanoparticle Attachment (TNA), were recently shown to possess un-

usual 3D mobility, characterised by predominantly 2D motion inter-dispersed with ballistic

out-of-plane segments (26). Unsurprisingly, the asymmetric optical properties from the TiO2

nanoparticle cap introduced signiﬁcant difﬁculties in accurate 3D tracking by standard methods.

Therefore, a simple approach using the particle’s grayscale moment of inertia, which varied as

a function of its vertical position, was developed. Similar to the strategy in (20), an LUT of the

microswimmers’ evolving moment of inertia was extracted from a series of particle Z-stacks,

to which a cubic polynomial was ﬁtted (see Supporting Information of (26)). However, the

over-reliance on a singular image property averaged over a few particles is undesirable, and

motivates a more robust approach to the 3D tracking of non-ﬂuorescent Janus microswimmers

with conventional wide-ﬁeld microscopy techniques.

We thus return to ML, previously discussed in reference to the Deeptrack 2.0 software, as

a promising approach to 3D microswimmer tracking.

In contrast to conventional statistical

approaches that assume an appropriate data model, ML models algorithmically learn the re-

lationship between a target response and its predictors (27). ML can thus be more generally

described as a way that machines can learn to perform tasks without speciﬁc programming or

a set of rules to follow. Inspired by the ability of ML models to detect underlying patterns in

data, we here investigate the suitability of traditional ML techniques for 3D tracking from stan-

dard 2D brightﬁeld microscopy images. Relevant features are extracted from light-microscopy

videos, and the underlying structure characterising their vertical position are extracted using

the freely accessible Scikit-learn package (28). To evaluate our method, we study the classic

non-ﬂuorescent Pt-SiO2 particle system (R = 1.06 µm) with a clear optical asymmetry, as an ex-

ample of a challenging but common example of Janus microswimmers whose vertical position

5

would not be easily identiﬁable with conventional methods (See Figures 1a,c). We take Z-stacks

of the Pt sputter-coated particles freely diffusing in pure water (i.e. passive due to the absence

of a fuel), rather than “sticking” them to the glass slide. This likely increases the labelling error

of the Z-stacks, but better represents the experimental conditions of the mobile states and the

ability of the active colloids to rotate in 3D as they swim (26). We conclude by studying a dif-

ferent TiO2-SiO2 particle system obtained by TNA with a modiﬁed microscope conﬁguration,

and demonstrate that traditional ML models can provide a viable and generalisable approach to

track non-ﬂuorescent Janus microswimmers moving in 3D.

2 Experimental Method

2.1 Particle Synthesis

2.1.1 Pt-SiO2 microswimmer synthesis

Pt-SiO2 Janus particles were synthesised following well-established protocols (29). Brieﬂy,

monolayers of SiO2 microparticles were prepared by spreading a 50 µL droplet of SiO2 mi-

croparticles (0.5 % w/w, 2.16 µm microParticles GmbH) onto a glass-slide, which was pre-

treated in a plasma-oven to increase its wettability. A thin, 5 nm Pt ﬁlm was then sputter-coated

onto the monolayer to obtain asymmetrically functionalised Pt-SiO2 Janus particles. The parti-

cles were collected by sonication for 1 minute followed by multiple rounds of centrifugation in

water.

2.1.2 TiO2-SiO2 microswimmer synthesis

TiO2-SiO2 microswimmers were prepared as previously described (26). Brieﬂy, Pickering

SiO2-Wax emulsions were prepared from 250 mg SiO2 (5 % w/w, 2.16 µm microParticles

GmbH) suspensions in a 10.8 mg/L didodecyldimethylammonium bromide (DDAB) solution,

using a 1:10 molten wax:water volumetric ratio (30). The suspension was heated to 75◦C then

6

stirred for 15 min at 3000 RPM before vigorous mixing at 13500 RPM for 160 s using an IKA

T-25 Digital Ultraturrax. After the emulsiﬁcation step, the Pickering emulsion was immediately

placed in an ice bath to rapidly solidify the colloidosomes. The emulsion was then washed in 0.1

M NaCl solution to remove surfactants, before further washing in deionised water. The SiO2-

Wax colloidosomes were dispersed overnight by gentle agitation in an aqueous solution of a

post-modiﬁed (poly)pentaﬂuoroacetate (pPFPAC) polymer (31). The pPFPAC-colloidosomes

were then washed thoroughly in deionized water before redispersion in a phosphate-buffered

saline (PBS) pH 7.0 suspension containing the TiO2 (P-25 aeroxide) nanoparticles. After gentle

mixing overnight, the TiO2 functionalized colloidosomes were collected by ﬁltration and the

wax was removed with chloroform to obtain the ﬁnal microswimmers.

2.2 Image Acquisition

2.2.1 Pt-SiO2 Z-stacks

280 uL dilute solutions of the Pt-SiO2 in milliQ were pipetted into a ﬂow-through cell (cell

137-QS; Hellma Analytics) with a light path length of 1 mm. Particles were imaged on an

inverted microscope (Nikon Eclipse Ti2e) under K¨ohler illumination with white-light using a

40× objective (CFI S Plan Fluor ELWD 40XC) with adjustable collar (set to 1 mm), and Z-

stacks were taken with an exposure time of 30 ms using a Hamamatsu C14440-20UP digital

camera. The Z-labels were then adjusted to account for refractive index mismatches between

the air objective and aqeuous media as in (32).

2.2.2 TiO2-SiO2 Z-stacks

280 uL dilute solutions of the TiO2-SiO2 in milliQ were pipetted into a ﬂow-through cell (cell

137-QS; Hellma Analytics) with a light path length of 1 mm. Particles were imaged on an in-

verted microscope (Nikon Eclipse Ti2e) under K¨ohler illumination with white light using a 40×

objective (CFI S Plan Fluor ELWD 40XC) with adjustable collar (set to 1 mm), and Z-stacks

7

were taken with an exposure time of 30 ms using a Hamamatsu C14440-20UP digital camera.

To simulate the conditions of swimming experiments, the particles were also illuminated with

UV (340 nm), using a Lumencor SPECTRA X light engine as the excitation source through

the objective (epiﬂuorescence). The Z-labels were then adjusted to account for refractive index

mismatches between the air objective and aqueous

media as in (32).

2.2.3

3D motion experiments

280 uL dilute solutions of the TiO2-SiO2 in fuel-rich aqueous conditions (H2O2, 3 % v/v) were

pipetted into a ﬂow-through cell (cell 137-QS; Hellma Analytics) with a light path length of 1

mm. The particles were imaged on an inverted microscope (Nikon Eclipse Ti2e) under K¨ohler

illumination with white light using a 40× objective (CFI S Plan Fluor ELWD 40XC) with ad-

justable collar (set to 1 mm), and videos were taken with an exposure time of 30 ms using a

Hamamatsu C14440-20UP digital camera at 10 FPS. To activate the TiO2 photocatalyst and

induce swimming, particles were illuminated with UV (340 nm), using a Lumencor SPECTRA

X light engine as the excitation source through the objective (epiﬂuorescence). Particles were

imaged 26.6 µm below their focal plane, to maximise the effective range over which their 3D

motion could be tracked.

2.3 Image pre-processing and extraction of relevant particle features for

model training

Before training the ML models, it is ﬁrst necessary to extract out the relevant image features

to reduce the computational complexity of the algorithmic learning process, and remove spuri-

ous or otherwise non-instructive information (e.g. background noise). Brieﬂy, Z-stacks of the

diffusing particles are ﬁrst taken as described above. The raw image Z-slices contain multiple

particles in the ﬁeld of view, which must ﬁrst be localised. As our method relies on the inter-

8

ference patterns of the particles, it is necessary that they are relatively well spaced from each

other and from the edges, and therefore particles not meeting a threshold separation distance

(3 particle diameters) between each other or the edges of the image are removed. A square

around each remaining particle centre (mask) is then extracted from the images, and labelled

with its corresponding height (Z-slice). The masks are then adjusted to possess the same mean

grayscale intensity, before the application of a median ﬁlter with a 3x3 kernel size, and then

normalisation of the pixel values to take values between 0 and 1. The Z-labels are then adjusted

to match a reference image plane, due to difﬁculty in experimentally ensuring the exact same

labels between different Z-stacks. From the adjusted and processed masks, key image features

are extracted to reduce the dimensionality of the inputs into the model for training. In this man-

ner, a small vector can be used to represent a much larger particle mask, signiﬁcantly reducing

computational time and sensitivity to noise. These vectors, which are labelled according to the

adjusted Z values, are then randomly shufﬂed and separated into a Training and Test set, before

a ﬁnal feature engineering step to further reduce the dimensions of the input parameter space.

As outlined later, the model learns on the training set, and the quality of its predictions are eval-

uated on the Test set. By preventing the model from learning from the test data, this allows a

better evaluation of the generalisability of the predictions.

2.3.1 Extraction of particle masks from Z-stacks and pre-processing

Prior to extracting the features from the labelled Z-slices, we ﬁrst performed a pre-processing

step on the raw image data. Particle centres were localised in the ﬁeld of view using the MAT-

LAB implementation of the Hough circle transform (33), which we found to be the most effec-

tive over the largest range of Z-stack slices. Due to the asymmetry of our (non-ﬂuorescent) parti-

cles, the underlying assumptions of the more commonly used centroid method do not hold (34).

The vertical depth over which centre ﬁnding is accurate is highly dependent on the optical con-

9

ﬁguration of the microscope and should be determined empirically; for the Pt-SiO2 system, this

was a range of approximately 35 µm, however, in the case of our TiO2-SiO2 microswimmers,

we were able to reach up to 40 µm by adjusting the illumination conditions. A square mask,

the size of which is dependent on the microscope resolution and particle dimensions, was then

extracted around the particle centres to obtain a labelled set of particle masks. The particle

masks were adjusted to all have a mean pixel intensity of 145 units (8-bit grayscale), an edge-

preserving median ﬁlter transform with a 3x3 kernel size was then applied, and ﬁnally the pixel

values were re-scaled to 0-1 before exporting the masks for further processing as necessary.

As the model was trained from experimental Z-stacks (rather than simulated data), it was

important to ensure that the particle masks are labelled as consistently as possible. We observed

that the diffusing particles occupy different vertical positions above the objective, based on

their appearances in the microscopy images. Furthermore, it is difﬁcult to reproducibly assign

the same focal point (Z = 0µm, see Figure 1) of particles at different regions of the glass

cell across Z-stacks taken. By visual inspection of many particle Z-stacks, we noted that each

particle defocuses into a black sphere approximately 5 µm above the slice where it is in-focus

(See Figure 1). This provides us with a reference height that can be compared between the

different Z-stacks acquired, to ensure consistent labelling between the Z-stacks and thus the data

observations. To use this feature at Z = 5µm as the reference plane, we examine 5 different

Z-stacks, and select for each a representative particle mask where the particle ﬁrst appears as

black sphere. We then average these 5 different particle masks to obtain a reference, Z = 5µm

image. We take the radial proﬁle of this created reference mask, which we deﬁned as the average

pixel value of the region spanned by a circle with its origin at the centre of the reference image,

for different values of the circle’s radius (from 1 pixel to 40 pixels, inclusive). We then scan

through the Z-stacks, and for each Z-stack we ﬁnd the 10 Z-slices that were the most similar

to the created, reference image. This was achieved by ﬁnding the 10 particle masks in each

10

Z-stack which have the lowest squared difference between their radial proﬁle and that of the

reference, radial proﬁle. Of these 10 Z-slices, we select the radial proﬁle from the particle with

the lowest Z value, and re-scale all values in the Z-stack such that the selected particle mask is

now labelled as Z = 5µm. We nevertheless note that this could lead to certain mislabelling of

data points, and therefore increase the model error determined during its validation.

2.4 Feature Extraction and Feature Engineering

The ML models discussed here are trained on features taken from the 2D particle masks, ex-

tracted and labelled as described above, to determine the vertical (Z) position of a microswim-

mer from the image-based inputs provided. The processed particle masks are 111x111 pixels in

dimension (grayscale, 0-1 normalised values), and therefore ﬂattening the image directly as an

input vector would create a large feature space with 12321 dimensions. This would signiﬁcantly

slow down training, introduce large amounts of noise from unnecessary image information, and

increase the risk of overﬁtting and thus poor model generalisability. Therefore, it is ﬁrst nec-

essary to reduce the dimensionality of the input data to improve the training step. This can be

achieved by computing various metrics from the particle masks which capture their key fea-

tures. We identify the following image properties which are initially extracted from the particle

masks.

1. The radial proﬁle of the particle mask

2. The difference in the maximum and minimum values of the radial and the horizontal

proﬁles of the particle masks

3. The number of local minima and maxima in the horizontal proﬁle of the particle masks

4. The image moment of inertia from the particle mask

The radial proﬁle of a particle mask from its centre (as described above), can be used to

11

Figure 1: Optical micrograph from a Z-stack of passive (no fuel - diffusing by Brownian motion
only) Janus particles to obtain labelled data sets. The optical asymmetry due to the Pt metal ﬁlm
is clearly visible. Snapshots of different Z-slices are shown to demonstrate the changes to the
extracted raw particle masks with at different Z values.

12

detect the presence of the interference pattern observed in the images (22). To evaluate the

radial proﬁle (40 pixels), we took the mean of the pixel intensities of the entire circle spanned by

the speciﬁed radius from the centre, rather than individual concentric rings as often performed

in the literature. This smoothed the noise arising from the wide-ﬁeld optical conﬁguration used,

but more importantly dampened the signiﬁcant asymmetry in the optical properties arising from

the Janus structure of the microswimmers. From the radial proﬁle of each Z-slice particle mask,

we also extract the difference between the maximum and minimum value of the radial proﬁle

as an additional, potentially important feature. We likewise extract the difference between the

minimum and maximum value of the horizontal proﬁle of each particle mask, obtained by

averaging across all vertical pixels of the particle mask for each pixel along the horizontal axis.

The horizontal proﬁle is noisier than the radial proﬁle, largely due to the lack of self-

similarity present from averaging over an increasingly growing circle, but it is also more sen-

sitive to the fringes of the interference pattern. We therefore smooth the horizontal proﬁle be-

fore determining the number of local maxima and minima present, using the inbuilt MATLAB

functions islocalmin and islocalmax. The number of minima and maxima is not a continuous

relationship, and therefore these features are treated as categorical variables. All other features

described and used here are treated as numerical, continuous variables. As they take discrete

values, the categorical features (number of minima and maxima), were ﬁrst treated to be prop-

erly included in the trained models (One-Hot-Encoding, OHE). From the distribution of the

number of maxima and minima, we ﬁnd that observations with more maxima and minima than

3 (in both cases) are outliers, and therefore set all values for the maxima and minima > 3 to 3.

This left two categorical variables which have values of 0, 1, 2, or 3 (8 total features - each with

an associated binary value).

Finally, the particle mask’s ﬁrst image moment (35), also referred to as the image’s moment

of inertia (as it is analogous to the moment of inertia around the image centroid, treating pixel

13

Figure 2: Schematic for extraction of relevant features for model training from raw microscopy
videos. Masks around particle centres are ﬁrst created and processed before the relevant image
properties are obtained. After reducing the variable space, the desired features are selected.

intensities as mass), is calculated for each particle mask (26). Thus, from the initial 111x111

particle mask with associated Z-label, 51 predictor variables are initially obtained (43 numerical

variables and the 8 categorical variables). Next, we perform feature engineering of the numer-

ical variables to further reduce the dimensionality of the feature space and reduce the potential

for overﬁtting (see Figure 2).

Before performing feature engineering, we ﬁrst randomly shufﬂed and split the data into

Training and Test sets. Preventing the model from seeing the Test dataset during the training

stage ensures that no information from the Test set can inﬂuence the outcomes of the model

training. This is necessary to test the generalisability of the model predictions. We randomly

shufﬂed all Z slice observations of the particle masks, then split the initial dataset into 80% for

training the models, and 20% for validating its predictions. We then perform feature engineering

on the 43 numerical variables identiﬁed previously. From visual inspection, we observe that the

distributions for the sequential values of the radial proﬁle in particular appear to show signiﬁcant

self-similarity (see Supporting Information, Figure S4). This can be explained by the method

used to extract the radial proﬁles from the particle masks, as we evaluate the mean pixel intensity

14

of a circle of increasing size centred at the origin. Therefore, sequential values of the radial

proﬁle will contain signiﬁcant amounts of information from the previous values. To treat this

collinearity present in the numerical feature space, we use the Python factor analyzer function

to reduce the dimensionality of our feature space (See Figure 2). The factor analyzer function

implements a varimax rotation and can be used to identify underlying latent variables which

capture the largest amount of variance amongst the original feature space. This in turn allows

a signiﬁcant reduction in the number of numerical parameters to be input into the model. The

number of extracted features that we use depends on the regression model applied, as we explain

in further detail later.

After extracting the relevant feature vector from our Z-stack images as described above, we

ﬁtted the selected model on the Training dataset, or tuned its hyper-parameters to improve per-

formance where closed-form solutions do not exist. The trained model is then used to predict

the Z-labels of the hold-out Test set of observations, and these predictions are then compared

to the actual labels obtained from the Z-stack. To evaluate model performance on unseen data,

we use the normalised error (cid:15) = s(zmeasured − zlabel)/Ztotal (where (cid:15) is the normalised error,

s(zmeasured − zlabel) is the sample standard deviation of the residuals, and Ztotal is the total valid

range of tracking, from (36)). Given the diversity of traditional ML models that can be ﬁtted,

we focus here on linear models (Linear and Polynomial regression), and a non-linear ensemble

decision tree (Extremely Randomised Decision Trees), to investigate the suitability of ML to

track the 3D motion of Janus microswimmers. Further discussions of other models that we in-

vestigated (Random Forest, XGBoost, and a Voting Ensemble combining the predictions of the

Extremely Randomised Decision Trees and XGBoost models), including a brief investigation

into the applicability of convolutional neural nets, can be found in the Supporting Information.

15

3 Results

3.1 Linear Regression

We begin our study with the simplest ML model, a standard linear regression using the extracted

image features to predict the Z-values labelled from the Z-stack. A closed-form solution for the

cost function of a linear regression model exists when the mean-squared-error (MSE) is used,

known as the normal equation (See Equation 1). However, it is more computationally efﬁcient

to calculate the Moore-Penrose inverse of the vectorized form of the MSE using Singular Value

Decomposition (SVD) to obtain the feature weights, which is the default approach used by the

Scikit-learn LinearRegression class. When there is a large feature space, it is nevertheless ad-

visable to use a general optimization algorithm such as gradient descent-based methods. Linear

regression models are highly effective when there is a linear relationship between the predictor

variables and the target variable. However, there are a set of assumptions when using linear

regression which are often not met in more complex datasets. One of these is the absence of

collinearities in the feature space, however this is not the case in e.g. the radial proﬁle of the

particle masks as described in the previous section.

Using the Python factor analyzer function, we automatically extract 9 underlying variables

from an initial parameter space of 43 numerical features, in doing so reducing the extent of the

collinearity in the numerical parameter space. However, as we wish to reduce the dimensionality

of the linear regression for the subsequent attempt at polynomial linear regression, we take

the ﬁrst 5 variables with the highest explanatory power (with respect to the total variance) of

the initial numerical variables. Between them, 99.5% of the variance in the underlying initial

numerical feature space is captured. We ﬁnally append the categorical OHE features (number of

troughs and peaks) to these 5 features, and run the Scikit-learn in-built LinearRegression class

on the training dataset (80% of all observations after shufﬂing, 31834 observations)

16

ˆθ = (X T X)−1 · (X T Y )

(1)

where Y is the vector of observations of the dependent variable,

X is the matrix of independent variables for each observation,

and ˆθ = argminθ ||Y − Xθ||2

From a linear regression model, we obtain a normalised error of 0.080. This translates to

an unnormalized value on the order of a particle diameter, which is clearly not acceptable for

particle tracking applications. More importantly, we clearly observe that the residuals of the

model predictions are non-Gaussian, and that there appears to be an underlying data structure

present (see Figures 3a,b). This demonstrates that a simple linear regression is not sufﬁcient

to capture the complexities of the data structure, due to the presence of non-linearities. We

therefore move to more complex models, and also do not consider regularization to further

improve this simple linear model.

The next ML model that we ﬁt is a polynomial regression model including higher order

terms and interactions between the numerical features. In this manner, linear weights can be

ﬁtted to non-linear data, and thus a closed-form solution also exists for polynomial regression.

The presence of higher order terms and their interactions signiﬁcantly increases the number of

weights to be ﬁtted, and therefore care should be taken in reducing the dimensionality of the

feature space and the order of the regression to prevent a combinatorial explosion of parame-

ters (see Equation 2). The Scikit-learn PolynomialFeatures class transforms the input predictor

variables to include all higher order terms and interaction terms between each feature. The

LinearRegression class can then be applied to this transformed data set as before. As the cat-

egorical features which are one-hot-encoded are sparse columns with binary values, only the

numerical features should be transformed with PolynomialFeatures. The categorical OHE fea-

tures can then be appended to this transformed dataset. From 5 numerical features, transformed

17

to include terms up to the 3rd order, we thus obtain 56 features (and the intercept) to which

the 8 categorical features are added. To minimize the possibility of overﬁtting, we constrain

the weights by using Ridge regression. In Ridge regression, a penalty term on the size of the

squared weights is added to the cost function to be minimized. This keeps the weights as small

as possible, but does not provide feature selection as with LASSO or Elastic-Net regularization

techniques. However, it possesses a closed-form solution, making it computationally more ef-

ﬁcient and less erratic. Ridge regression can be simply implemented on Scikit-learn using the

Ridge class, and we use the GridSearchCV class to identify the optimal penalty term

(cid:19)

(cid:18)n + d
d

or

(n + d)!
n! d!

(2)

where n is the dimension of the original feature space, and d is the highest order of the polynomial

We ﬁnd that higher-order polynomial regression provides little to no reduction in training-

validation error, and in some cases, can increase it signiﬁcantly due to over-ﬁtting. We therefore

limit our model to a 3rd order polynomial Ridge regression model which we ﬁt to our training

data, and then test as previously described. The residuals of the model ﬁtted to the test data are

shown in Figure 3d. We note a signiﬁcant improvement in the normalised prediction error from

the linear regression case to 0.032. Furthermore, we see that most of the systematic periodicity

in the residuals present for the standard linear regression has disappeared. Nonetheless, we can

still see some structure in the residuals, in particular around Z = 0µm where the asymmetry of

the Janus particles is likely the most visible.

3.2 Decision Tree Models

The inability of linear models to satisfactorily capture the structure of our extracted image

properties suggests the use of more complex ML techniques. One powerful and widely used

class of models are those based on decision trees. Decision trees make a series of recursive

18

Figure 3: Comparison of the model predictions (top row) and residuals (bottom row) obtained
against the ground-truth values from labelled Z-slices, for different regression strategies (39320
total observations). Left: Predictions obtained using linear regression. Middle: Predictions ob-
tained using polynomial regression. Right: Predictions obtained using Extremely Randomised
Decision Trees (ERTs). For comparison, the models were trained and tested on the same ran-
domly shufﬂed datasets.

19

binary splits on the input parameter space, greedily minimising (typically) the Gini impurity

(or variance for regression) of the two subsets of data after the split (37). Since there is no

direct mapping between the predictors and the target variable, Decision Trees, unlike linear

regression, can handle non-linearities in datasets. Furthermore, the hierarchical structure of

Decision Trees means they can implicitly capture interactions between features (38). However,

the ﬂexibility of decision trees to model non-linear data is such that they are very sensitive to

variations in datasets and prone to overﬁtting (39). To overcome these issues, decision trees

are typically integrated into ensembles to average the predictions and thus reduce the model

variance at the cost of some bias. So long as the trees are in sufﬁcient number and diversity,

even a set of only “weak” learners (low accuracy) can be combined to obtain a “strong” learner

(high accuracy) (40). To ensure that the decision trees are sufﬁciently diverse, a number of

strategies can be implemented. Here, we highlight one example of an ensemble decision tree

learner – the Extremely Randomised Decision Trees ensemble model (ERT) (41). For further

discussion of the different decision tree ensemble models we investigate, see the Supporting

Information.

The ERT model is based on a modiﬁcation to the well-known random forest (RF) model

(42, 43), where randomly determined thresholds for each feature at the nodes of a decision tree

to split the dataset to improve the scoring metric, rather than determining the optimal thresholds

for each feature. Not only does this decrease the variance of the model further compared to

a standard RF (at the cost of more model bias), it also signiﬁcantly reduces the training time

for an equivalent RF model, as determining the best thresholds for each feature at each node is

one of the most computationally intensive tasks of training. We expect that the high variance

present in the input image data makes a model that prioritises variance at the cost of bias more

effective at making predictions of the particle’s vertical positions.

We train our ERT ensemble model using the Scikit-learn ExtraTreesRegressor class. Un-

20

like the linear regressors, we input all latent features identiﬁed during the exploratory factor

analysis step (9 factors), which we ﬁnd reduces the prediction error. With the categorical OHE

features, we therefore initially have 17 predictor variables to input into our ERT ML model. To

identify potentially non-signiﬁcant features, we furthermore add a “noise” feature with values

drawn from a normal distribution for each observation (44). After ﬁtting the ERT, we call the

feature importances attribute of the ﬁtted model and ﬁnd that the observation that the number

of peaks and troughs >= 3 in the horizontal intensity proﬁle of the particle masks are both

less informative to the model than the random noise term. We therefore assign all peaks and

troughs >= 2 to 2 and re-ﬁt the categorical OHE, reducing the feature space by 2 to 15. Due

to the large number of hyperparameters which can be tuned when ﬁtting a ERT (e.g. number of

trees, feature sub-set size per node, depth of a tree etc.), we use k-folds (k=10) cross validation

using the GridSearchCV functionality of Scikit-learn to identify the optimal ﬁtting parameters

by minimizing the RMSE on the k validation sets.

After identifying the optimal hyperparameters by K-folds cross validation, we ﬁt an ERT

model on the entire training set. We then determine the generalizability of the trained model

on the Test dataset, and ﬁnd an improvement in the model error to 0.021. Furthermore, the

structure of the residuals is more homoscedastic than those of the polynomial regression model

(see Figures 3e,f) with only some bias at the extreme values, which was also observed when

ﬁtting 3D data with Deeptrack 2.0 (25), albeit the explanation for their prediction errors does

not apply to our case. The superior performance of the ensemble decision tree models appears

to justify their selection, and indicates their suitability for the problem of tracking the 3D motion

of Janus microswimmers.

21

3.3 Tracking 3D motion

We investigate the 3D tracking abilities of our ML-based approach and the generalisability

of the strategy described here on our photo-responsive TiO2-SiO2 microswimmers. Due to

gravity and the existence of well-characterised “sliding states”, the benchmark case of Pt-based

microswimmers (9, 24) typically shows motion constrained to a 2D plane, and we thus expand

our tests to a more challenging case of photocatalytic microswimmers (26). Like the Pt-SiO2

system we have previously discussed, our TiO2 microswimmers also possess a challenging

(but different) asymmetry in their optical properties. The Janus coating of TiO2 nanoparticles

appears as dark “chunks” under brightﬁeld microscopy (see Supporting Information, Figure

S1), allowing us to investigate how well our ML model can handle different types of optical

asymmetry. We furthermore use a modiﬁed optical conﬁguration with regards to exposure

times and brightﬁeld intensity, to check whether our ML workﬂow can be used across a range

of experimental conditions. By adjusting the microscope conﬁguration, we were ﬁnally able to

track the particle centres over 40 µm, a wider range than for the Pt-SiO2 system (35 µm).

We extract the same features from the particle masks; however, the exploratory factor anal-

ysis stage identiﬁed 12 relevant latent factors in this case rather than 9. We attribute this to

a range of factors, such as the different optical conﬁguration used, which allows us to scan a

wider Z range, as well as the different optical asymmetry of the particles studied. We directly

train our ERT on these 12 features extracted using factor analyzer, and in this manner, we are

able to obtain a normalised error of 0.019, with no notable underlying structure in the residuals

as shown in Figure 4a-b.

We thus see that traditional ML models, speciﬁcally decision tree-based ensemble models,

are an effective approach to track the vertical position of Janus particles and therefore capable of

3D tracking. As a demonstration, we show some sample 3D trajectories that we obtain using our

trained ERT model (see Figures 4c,d,e). Speciﬁcally, we show the Z-tracking of a highly chiral

22

Figure 4: Tracking the 3D motion of SiO2-TiO2 microswimmers using an Extremely Ran-
domised Decision Tree (ERT) model: a) Model predictions vs ground-truth values from labelled
Z-slices (26924 total observations, 5385 of which are in the Test set (20%)). b) Residuals as a
function of labelled Z-slices. c) Selected Z positions vs time (different colours denote different
microswimmers), comparing the out-of-plane motion of particles for different chiral and non-
chiral microswimmers. d) Example trajectory of a microswimmer that remains mostly in-plane.
e) Example trajectory of a highly chiral microswimmer that swims out-of-plane

23

0102030405060Frame #051015202530Z ((cid:1)m)Frames #Z (µm)(µm)(µm)Z (µm)Z (µm)abc052001011019015180802468101214<V0>Z (µm)X (µm)Y (µm)d032051031030015290280510152025<V0>X (µm)Y (µm)Z (µm)e“looping” particle, whose motion would present signiﬁcant difﬁculty to track using conventional

methods. We also show the Z trajectory of a particle that moves in 2D, noting the small length

scales over which positional ﬂuctuations occur in the vertical direction.

4 Conclusion

Our ﬁndings demonstrate the applicability of simple ML techniques to the 3D tracking of ac-

tive Janus particles from 2D slices of non-ﬂuorescent wide-ﬁeld microscopy videos. Rather

than simulating the optical conﬁguration of a microscope, our approach allows the training of

ML models on Z-stacks taken on a standard light microscope. Although this introduces some

uncertainty in the Z-position due to the vertical resolution of the microscope, the performance

we achieve using ML models is high, and our method does not require specialised equipment

as for holographic microscopy. Furthermore, our approach is robust to Janus microparticles

with a high degree of optical asymmetry, which is otherwise a challenge for other 3D tracking

techniques (24). We furthermore expect that higher accuracy could be reported if the models

were trained on particles adhered to the glass substrate. However, we wished to replicate true

experimental conditions as closely as possible, in particular the rotational diffusion of particles,

which exposes different asymmetries to the microscope. Importantly, we ﬁnd that the trajecto-

ries of 2D swimming particles are relatively noise-free in the Z direction, removing most of the

spurious displacements which were occasionally present in previous attempts at 3D tracking of

Janus microswimmers with a wide-ﬁeld microscope (26). We nonetheless stress the importance

of checking the model predictions as outlier swimmers will possess noisy trajectories, which

should be ﬁltered. The presence of contamination on the glass slide, or even uneven illumina-

tion ﬁelds, could all contribute to additional sources of noise in the trajectories of swimming

particles. It is also critical that the trajectories analysed are limited to the bounds of the opti-

cal conﬁguration used (around 40 µm), and we strongly advise against extrapolating to vertical

24

positions beyond these values.

We moreover ﬁnd that traditional ML techniques are effective at tracking the vertical posi-

tions of two different Janus particle systems, with videos taken using different optical condi-

tions. We ﬁnd that decision-tree based ensemble models are the most accurate type of traditional

ML model. The extremely randomised decision tree model is the best stand-alone traditional

ML technique for predicting the vertical positions of Janus particles, and combining its pre-

dictions with those of a Hypothesis Boosting Gradient model in a Voting Regressor may lead

to a very slight improvement in overall performance (see Supporting Information, Figure S5).

We limit our discussion of DL convolutional neural networks to the SI, but we note that these

models can accept particle masks directly, circumventing the time-consuming process of feature

extraction. Nevertheless, traditional ML models provide better understanding and control over

inputs, and we favour the use of simpler models where possible.

Using the freely-available and well-documented Scikit-learn packages, the training of ML

models can be performed with a few simple lines of code. Coupled with the extensive learning

resources widely available (45), this enables a low-barrier extension of existing resources to new

problems. We highly encourage experimentalists in the active matter community to explore the

fascinating possibilities of ML by developing their own models. If nothing else, it provides

an engaging learning exercise in a burgeoning ﬁeld, but can likely help address experimental

challenges in a manner not possible by well-established protocols for particle tracking.

25

Acknowledgements

The authors thank V. Niggel for the various discussions on image processing and analysis.

We also acknowledge the various online learning resources which made this study feasible, as

well as the wide-ranging discussions on image-processing and ML to be found on community

forums such as Stack Exchange, Stack Overﬂow, and MathWorks.

Author Contribution Statement

Author contributions are deﬁned based on the CRediT (Contributor Roles Taxonomy). Con-

ceptualization: M.R.B., F.G. Formal Analysis: M.R.B. Funding acquisition: L.I. Investiga-

tion: M.R.B. Methodology: M.R.B. Software: M.R.B., F.G. Supervision: F.G., L.I. Validation:

M.R.B. Visualization: M.R.B., F.G., L.I. Writing - original draft: M.R.B. Writing - review and

editing: M.R.B., F.G., L.I.

26

References

1. S. Ramaswamy, Annual Review of Condensed Matter Physics 2010, 1 323.

2. P. D´ıez, E. Lucena-S´anchez, A. Escudero, A. Llopis-Lorente, R. Villalonga, R. Mart´ınez-

M´a˜nez, ACS Nano 2021, 15, 3 4467.

3. L. Wang, A. Kaeppler, D. Fischer, J. Simmchen, ACS Applied Materials and Interfaces

2019, 11, 36 32937.

4. J. Zhang, R. Alert, J. Yan, N. S. Wingreen, S. Granick, Nature Physics 2021, 17, 8 961.

5. R. Golestanian, T. B. Liverpool, A. Ajdari, Physical Review Letters 2005, 94, 22 1.

6. M. N. Popescu, S. Dietrich, M. Tasinkevych, J. Ralston, European Physical Journal E

2010, 31, 4 351.

7. K. K. Dey, F. Wong, A. Altemose, A. Sen, Current Opinion in Colloid and Interface

Science 2016, 21 4.

8. M. R. Bailey, N. Reichholf, A. Flechsig, F. Grillo, L. Isa, Particle and Particle Systems

Characterization 2021, 2100200 1.

9. W. E. Uspal, M. N. Popescu, S. Dietrich, M. Tasinkevych, Soft Matter 2015, 11, 3 434.

10. S. Gangwal, O. J. Cayre, M. Z. Bazant, O. D. Velev, Physical Review Letters 2008, 100, 5

1.

11. A. I. Campbell, S. J. Ebbens, Langmuir 2013, 29, 46 14066.

12. A. I. Campbell, R. Wittkowski, B. Ten Hagen, H. L¨owen, S. J. Ebbens, Journal of Chemical

Physics 2017, 147, 8.

27

13. D. P. Singh, W. E. Uspal, M. N. Popescu, L. G. Wilson, P. Fischer, Advanced Functional

Materials 2018, 28, 25.

14. O. Yasa, P. Erkoc, Y. Alapan, M. Sitti, Advanced Materials 2018, 30, 45 1.

15. J. G. Lee, A. M. Brooks, W. A. Shelton, K. J. Bishop, B. Bharti, Nature Communications

2019, 10, 1 1.

16. A. M. Brooks, S. Sabrina, K. J. Bishop, Proceedings of the National Academy of Sciences

of the United States of America 2018, 115, 6 E1090.

17. V. Prasad, D. Semwogerere, E. R. Weeks, Journal of Physics Condensed Matter 2007, 19,

11 1.

18. F. Saglimbeni, S. Bianchi, A. Lepore, R. Di Leonardo, Optics Express 2014, 22, 11 13710.

19. M. Speidel, A. Jon´aˇs, E.-L. Florin, Optics Letters 2003, 28, 2 69.

20. A. Campbell, R. Archer, S. Ebbens, Journal of Visualized Experiments 2016, 2016, 113 1.

21. Z. Zhang, C. H. Menq, Applied Optics 2008, 47, 13 2361.

22. D. T. Kovari, D. Dunlap, E. R. Weeks, L. Finzi, Optics Express 2019, 27, 21 29875.

23. D. P. Singh, W. E. Uspal, M. N. Popescu, L. G. Wilson, P. Fischer, Advanced Functional

Materials 2018, 28, 25 1706660.

24. S. Ketzetzi, J. De Graaf, D. J. Kraft, Physical Review Letters 2020, 125, 23 238001.

25. B. Midtvedt, S. Helgadottir, A. Argun, J. Pineda, D. Midtvedt, G. Volpe, Applied Physics

Reviews 2021, 8, 1.

28

26. M. R. Bailey, F. Grillo, N. D. Spencer, L. Isa, Advanced Functional Materials 2021,

2109175 1.

27. L. Breiman, Statistical Science 2001, 16, 3 199.

28. F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blon-

del, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau,

M. Brucher, M. Perrot, E. Duchesnay, Journal of Machine Learning Research 2011, 12

2825.

29. J. R. Howse, R. A. Jones, A. J. Ryan, T. Gough, R. Vafabakhsh, R. Golestanian, Physical

Review Letters 2007, 99, 4 8.

30. A. Perro, F. Meunier, V. Schmitt, S. Ravaine, Colloids and Surfaces A: Physicochemical

and Engineering Aspects 2009, 332, 1 57.

31.

ˆA. Serrano, S. Z¨urcher, S. Tosatti, N. D. Spencer, Macromolecular Rapid Communications

2016, 622–629.

32. T. D. Visser, J. L. Oud, Scanning 1994, 16, 4 198.

33. H. Yuen, J. Princen, J. Illingworth, J. Kittler, Image and Vision Computing 1990, 8, 1 71.

34. J. C. Crocker, D. G. Grier, Journal of Colloid and Interface Science 1996, 179, 1 298.

35. M.-K. Hu, IRE Transactions On Information Theory 1962, 8, 2 179.

36. R. Barnkob, C. J. K¨ahler, M. Rossi, Lab on a Chip 2015, 15, 17 3556.

37. M. Krzywinksi, N. Altman, Nature Methods 2017, 14, 8 757.

38. J. Elith, J. R. Leathwick, T. Hastie, Journal of Animal Ecology 2008, 77, 4 802.

29

39. A. J. Myles, R. N. Feudale, Y. Liu, N. A. Woody, S. D. Brown, Journal of Chemometrics

2004, 18, 6 275.

40. R. Schapire, In Nonlinear Estimation and Classiﬁcation. Lecture Notes in Statistics, 149–

173. Springer, New York, ISBN 978-0-387-95471-4, 2003.

41. P. Geurts, D. Ernst, L. Wehenkel, Machine Learning 2006, 63, 1 3.

42. Tin Kam Ho, Proceedings of 3rd International Conference on Document Analysis and

Recognition 1995, 278–282.

43. L. Breiman, Machine Learning 2001, 45 5.

44. T. Williams, K. McCullough, J. A. Lauterbach, Chemistry of Materials 2020, 32, 1 157.

45. A. G´eron, Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow, O’Reilly

Media, Inc., Sebastopol, CA 95472, 2nd edition, 2019.

46. T. Chen, C. Guestrin, Proceedings of the 22nd ACM SIGKDD International Conference on

Knowledge Discovery and Data Mining 2016, 785–794.

47. W. S. McCulloch, W. Pitts, Bulletin of Mathematical Biophysics 1943, 5 115.

48. R. Yamashita, M. Nishio, R. K. G. Do, K. Togashi, Insights into Imaging 2018, 9 611.

49. K. Fukushima, Biological Cybernetics 1980, 36, 4 193.

50. Y. LeCun, L. Bottou, Y. Bengio, P. Haffner, Proceedings of the IEEE 1998, 86, 11 2278.

51. D. H. Hubel, T. N. Wiesel, The Journal of Physiology 1968, 195, 1 215.

52. V. Nair, G. E. Hinton, Proceedings of the 27 th International Conference on Machine

Learning 2010.

30

53. F. Chollet, Keras, 2015.

54. M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Davis, C. Andy,

J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, R. Jozefow-

icz, Y. Jia, L. Kaiser, M. Kudlur, J. Levenberg, D. Man´e, M. Schuster, R. Monga, S. Moore,

D. Murray, C. Olah, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke,

V. Vasudevan, F. Vi´egas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, X. Zheng,

Zenodo 2015, 1–19.

55. A. LeNail, Journal of Open Source Software 2019, 4, 33 747.

31

Supplementary materials

Fig. S1: Optical asymmetry of TiO2 nanoparticles on a SiO2 microparticle support
Fig. S2: Extraction of features from a single particle mask (Pt-SiO2 Janus particle system)
Fig. S3: Distribution of features extracted from all Z-masks (Pt-SiO2 Janus particle sys-

tem)
Fig. S4: Distribution of radial features extracted from all Z-masks (Pt-SiO2 Janus particle

system)
Fig. S5: Performance of different Decision Tree based ensemble methods (Pt-SiO2 Janus

particle system)
Text S1: Deep Learning (Convolutional Neural Networks)
Fig. S6: Overview of Convolutional Neural Network (CNN) architecture, training, and

model performance

32

Traditional Machine Learning models:
Pt-SiO2 Janus particle system

Image Properties and Feature Extraction

Fig. S 1: Optical asymmetries arising from the TiO2 nanoparticles on a SiO2 microparticle
support. Contrast has been enhanced to highlight the nanoparticles (dark spots)

Fig. S 2: Extraction of numerical and categorical features from a single particle mask. From the
mask, 40 values of the radial proﬁle, the image moment of inertia, the difference between the
largest and smallest values in the horizontal and radial proﬁles, and the number of maxima and
minima in the horizontal proﬁle are extracted. From the numerical features (radial proﬁle, mo-
ment of inertia, and ∆(max−min)) of the two proﬁles), exploratory factor analysis determines
the 5 underlying factors with the highest explanatory power (99.5% of total variance)

33

Fig. S 3: Extraction of numerical and categorical features from the full set of Z-slices across
many particles (> 100). The 5 underlying factors with the highest explanatory power are ex-
tracted from the numerical features as described in Figure S2. The distributions across all
observations (31834 total Z-slices) for selected features are shown.

34

Fig. S 4: Extraction of all the radial features from the full set of Z-slices across many particles
(> 100). The self-similarity between subsequent values of the radial proﬁle can be observed
from the distributions

35

Performance of Ensemble Tree-based Models

Fig. S 5: Comparison of the model predictions (top row) and residuals (bottom row) obtained
against the ground-truth values from labelled Z-slices, for different decision tree based ensem-
ble models. Left: Predictions obtained using a Random Forest (27, 42). Middle: Predictions
obtained using XGBoost (46). Right: Predictions obtained using a voting regressor combin-
ing the predictions of the XGBoost model (middle) and Extremely Randomised Trees model
discussed in the main text. For comparison, all models were trained and tested on the same ran-
domly shufﬂed datasets. We ﬁnd no qualitiative difference in the performance of the respective
models (all with normalised errors (cid:15) = s(zmeasured − zlabel)/Ztotal = 0.021 (where (cid:15) is the nor-
malised error, s(zmeasured − zlabel) is the sample standard deviation of the residuals, and Ztotal
is the total valid range of tracking, from (36))). We opt for the Extremeley Randomised Trees
in the main text principally by visual inspection of the residuals and the signiﬁcantly reduced
model training time (due to the random selection of thresholds at the decision tree nodes).

36

Text S1: Deep Learning (Convolutional Neural Networks)

The recent hype surrounding Machine Learning (ML) models is in large part due to the renewed

interest in Deep Learning (DL) architectures. The concept of artiﬁcial neurons is not new (47),

but the rise in computing power, demonstrated by Moore’s law, coupled with the accessibility

of GPU processors and modiﬁcations to training algorithms, has made the training of Neural

Networks far more feasible. One of the main advantages of DL models for the 3D tracking of

the Janus microswimmers compared to traditional ML models described in this manuscript is

that they can directly accept image inputs, and the extensive feature extraction and engineering

steps described for the traditional ML models are no longer necessary. This makes the training

pipeline of DL models more generalisable to different particle systems and optical conﬁgura-

tions compared to traditional ML methods, as we will now demonstrate.

Amongst standard Deep Learning architectures, Convolutional Networks (CNNs) are the

best performers for computer vision tasks such as image classiﬁcation (48). The introduction of

convolutional and pooling layers into the architecture of neural networks (49, 50), was in-part

inspired by studies into the neurons of the visual cortex which demonstrated the presence of

small, local receptive ﬁelds recognising patterns of varying complexity (51). Unlike a dense

layer, each neuron in a convolutional layer is connected to a limited subset of pixels in the

previous layer. This allows the network to ﬁrst focus on smaller features before assembling

them into higher-level features in subsequent layers. Each convolutional layer will consist of a

deﬁned number of ﬁlters performing linear operations, outputting different feature maps. Thus,

the output of each convolutional layer can be represented as a 3D set of 2D feature map slices

representing each linear operation. An activation function, typically the rectiﬁed linear activa-

tion function (52), is then usually applied to the outputs to introduce non-linearities into the

transformed feature maps. Pooling layers, which sub-sample the input feature map by aggre-

37

gating the values and return a feature map of reduced size, are frequently used in CNNs to

minimise the memory requirements during training and inference. At the cost of image infor-

mation, they reduce the number of parameters, computations and memory usage in subsequent

layers, and can also introduce a small degree of invariance to different transformations of the

image. They are typically used between convolutional layers, particularly in deep CNNs, to

prevent an explosion of computational load. The ﬁnal layers of a CNN are a dense layer with

outputs appropriate for the desired regression or classiﬁcation task.

Given our relatively simple image processing task, we build our CNN sequentially using the

Keras backend of the TensorFlow API (53, 54), analysing our TiO2-SiO2 Janus particle system.

In this manner, we ﬁnd that the best performance can be achieved with a CNN architecture

consisting of 3 convolutional layers and 2 fully connected dense layers (see Figure S 6). The ﬁrst

convolutional layer is constructed with 3x3 kernels outputting 64 feature maps, using a stride of

2. This reduces the dimensionality of the input image (87x87 pixels), allowing an increase in the

number of ﬁlters in the second convolutional layer (128) without an explosion of parameters.

The ﬁrst two convolutional layers are followed by the ReLU activation function, and no pooling

is used. Interestingly, we obtain better performances by introducing a third convolutional layer

(128 feature maps) without an activation function. The output of the third convolutional layer

is then fully connected to a dense layer, with 64 output neurons and again activated with the

ReLU function. The output of this dense layer is ﬁnally connected to a dense layer with a single

output neuron representing the target Z-value. This output has a linear activation function for

regression, which is regularised using L2 (Ridge) penalty terms. The model is trained using

Mean Absolute Error (MAE) as the cost function (25). Mini-batch gradient descent with early

stopping is used to optimise the weights (100 observations), which was the batch size identiﬁed

as optimal for training and which also easily ﬁt into the memory without signiﬁcantly extending

training times.

38

Remarkably, this simple CNN architecture achieves similar results as the Decision tree

based ensemble methods that we study, despite the essentially raw particle masks with mini-

mal pre-processing used as inputs. However, in the application to our 3D swimming trajec-

tories, we note signiﬁcant noise in the axial tracking, speciﬁcally during the 2D segments of

motion. On closer visual inspection of the model predictions on the test data, we note an un-

derlying structure in the residuals, which has a signiﬁcant negative impact on our Z-tracking.

This highlights the importance of validating the model predictions on the out-of-test data to be

analysed. Nevertheless, the performance of our trained CNN on our particle masks during the

training-validation-test stage demonstrates that even simple neural network architectures can be

promising for the 3D tracking of microswimmers with optical asymmetry, and further work in

this direction might yield better outcomes than that achievable with traditional ML models.

39

Fig. S 6: Top row: Schematic of the architecture of our CNN with 3 Convolutional layers and 2
Dense layers (single output for the Z-label regressed), created using software from (55). Middle
row: Training-Validation performance of the CNN with Epochs. The root-mean-squared error
(RMSE) saturates at a value similar to that achieved using traditional decision-tree based en-
semble ML models. Bottom row: Performance of our trained CNN on the test data-set. We note
a slight underlying structure in the residuals (right), which could explain the poor performance
on real 3D trajectories despite good performance on the shufﬂed test data.

40

