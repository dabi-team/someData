2
2
0
2

y
a
M
4
2

]
S
M

.
s
c
[

1
v
1
2
7
2
1
.
5
0
2
2
:
v
i
X
r
a

Accelerating High-Order Mesh Optimization Using Finite Element
Partial Assembly on GPUs

Jean-Sylvain Camier1, Veselin Dobrev1, Patrick Knupp2, Tzanio Kolev1, Ketan Mittal1,
Robert Rieben1, Vladimir Tomov1

Abstract

In this paper we present a new GPU-oriented mesh optimization method based on high-

order ﬁnite elements. Our approach relies on node movement with ﬁxed topology, through

the Target-Matrix Optimization Paradigm (TMOP) and uses a global nonlinear solve over

the whole computational mesh, i.e., all mesh nodes are moved together. A key property of

the method is that the mesh optimization process is recast in terms of ﬁnite element opera-

tions, which allows us to utilize recent advances in the ﬁeld of GPU-accelerated high-order

ﬁnite element algorithms. For example, we reduce data motion by using tensor factoriza-

tion and matrix-free methods, which have superior performance characteristics compared

to traditional full ﬁnite element matrix assembly and oﬀer advantages for GPU-based HPC

hardware. We describe the major mathematical components of the method along with their

eﬃcient GPU-oriented implementation. In addition, we propose an easily reproducible mesh

optimization test that can serve as a performance benchmark for the mesh optimization

community.

Keywords: mesh optimization, GPUs, performance benchmark, ﬁnite elements, curved

meshes, HPC, high-order, matrix-free methods, TMOP

1. Introduction

The rise of heterogeneous architectures, such as general-purpose GPUs, has motivated

a rethinking of the algorithms used in large-scale, high-performance simulations [1]. The

(cid:63)Performed under the auspices of the U.S. Department of Energy under Contract DE-AC52-07NA27344

(LLNL-JRNL-835500)

1Lawrence Livermore National Laboratory, 7000 East Avenue, Livermore, CA 94550
2Dihedral LLC, Bozeman, MT 59715

Preprint submitted to Journal

May 26, 2022

 
 
 
 
 
 
new computing systems favor algorithms that expose ultra ﬁne-grain parallelism and max-

imize the ratio of ﬂoating point operations to energy-intensive data movement. As more

applications are porting their codes to GPU systems, meshing algorithms can become a bot-

tleneck unless they can be formulated in a balanced, data-parallel way. Some of the existing

mesh optimization methods are not a good match for the new architectures because they

rely on geometric operations and local topology changes that introduce branching and load

imbalance between parallel threads.

In this paper we present a computationally eﬃcient GPU-capable mesh optimization

method based on high-order ﬁnite elements (FE). Starting with our existing mesh optimiza-

tion FE framework [2], we reformulate all FE kernels using the so-called partial assembly

(PA) technique, and implement the resulting formulation through a general abstraction that

allows both CPU and GPU execution. Partial assembly is a technique introduced in the pio-

neering work of Deville, Fischer, and Mund [3], where the authors demonstrate that by using

a tensor product of 1D basis functions, fully assembled operators do not need to be stored

anymore and the computational cost associated with the storage, assembly, and evaluation

of partially assembled operators reduces to O(pd), O(pd), and O(pd+1) per element, respec-

tively, where p is the polynomial order of the FE space and d is the space dimension. The

traditional FE approach of pre-assembling and storing sparse matrices, on the other hand,

leads to much worse computational costs per element, namely, O(p2d) for storage, O(p3d)

for assembly, and O(p2d) for evaluation. Obtaining the above PA complexities, however,

requires that the ﬁnite element basis functions are tensor products of 1D basis functions,

e.g., quadrilaterals in 2D and hexahedra in 3D. Partial assembly has become even more

relevant in recent years [4, 5, 6] owing to its eﬃcient use of GPU-based architectures, which

are desirable for arithmetically intensive applications that do not require a large amount of

data to be moved between the CPU and GPU [1].

The presented algorithms are developed in the context of the Target-Matrix Optimization

Paradigm (TMOP) for high-order meshes [2, 7] and its implementation in the MFEM ﬁnite

element library [8]. TMOP minimizes a functional that depends on each element’s current

and target (desired) geometric parameters: element aspect-ratio, size, skew, and orientation,

which allows us to optimize and adapt the mesh to improve the accuracy and computational

2

cost of FEM calculations (see, e.g., Section 4.1 of [9]). The TMOP-based methodology is

purely algebraic, extends to both simplices and hexahedra/quadrilaterals of any order, and

supports nonconforming isotropic and anisotropic reﬁnements in 2D and 3D. Similar methods

in the literature include Laplacian smoothing, where each node is typically moved as a linear

function of the positions of its neighbors [10, 11, 12], optimization-based smoothing, where

a functional based on elements’ geometrical parameters is minimized [13, 14, 15, 16, 17, 18],

and equidistribution with respect to an appropriate metric tensor [19, 20, 21], amongst others

[22, 23, 24].

A survey of the literature shows that despite the introduction of recent mesh optimization

strategies on GPU-based architectures, the notion of partial assembly is not present in the

ﬁeld of mesh optimization. This is likely because most existing methods are either developed

for low-order meshes [25, 26] or use a localized approach (such as Laplacian smoothing

or optimization-based smoothing with a sequential patch-by-patch approach) [27, 26, 28,

29]. In contrast to other approaches, the variational-based TMOP methods are well-suited

to GPU acceleration, as all of the operations can be recast in the form of ﬁnite element

computations, allowing us to take advantage of the signiﬁcant GPU advances in this area.

In particular, matrix-free algorithms and partial assembly of nonlinear forms, such as the

global TMOP functional, can lead to orders-of-magnitude reduction in the runtime of high-

order applications compared to traditional matrix-based algorithms [30].

The remainder of the paper is organized as follows. Section 2 gives an overview of

preliminaries such as high-order mesh representation and the TMOP-based mesh adaptation

framework, that are essential for understanding our method. In Section 3, we describe the

fundamentals of partial assembly for high-order FEM operators. Here, we also describe our

methodology for partial assembly of TMOP-based mesh optimization methods. In Section

4, we present several numerical examples and benchmarks demonstrating the improvement

in computational eﬃciency due to use of partial assembly on GPU-based architectures in

comparison to full-assembly on CPUs. Finally, we close with directions for future work in

Section 5.

3

2. Preliminaries

This section provides a basic description of the TMOP-based r−adaptivity algorithm

that is the starting point of our work. We only focus on the aspects that are relevant to the

description of partial assembly of TMOP on GPUs. See [2, 7] for additional details.

2.1. Discrete Mesh Representation

In our ﬁnite element based framework, the domain Ω ⊂ Rd is discretized as a union of

curved mesh elements of order p. To obtain a discrete representation of these elements, we
select a set of scalar basis functions { ¯wi}Np

i=1, on the reference element ¯E.

In the case of

tensor-product elements (quadrilaterals in 2D, hexahedra in 3D) which is the focus of this

paper, Np = (p + 1)d, and the basis spans the space of all polynomials of degree at most

p in each variable, denoted by Qp. The position of an element E in the mesh M is fully

described by a matrix xE of size d × Np whose columns represent the coordinates of the

element control points (also known as nodes or element degrees of freedom). Given xE, we
introduce the map ΦE : ¯E → Rd whose image deﬁnes the physical element E:

x(¯x) = ΦE(¯x) ≡

Np
(cid:88)

i=1

xE,i ¯wi(¯x),

Np
(cid:88)

i=1

xE,i ¯wi(¯x),

¯x ∈ ¯E, x = x(¯x) ∈ E,

(1)

where xE,i denotes the i-th column of xE, i.e., the i-th node of element E. To represent

the whole mesh, the coordinates of the control points of every element are arranged in a

global vector x of size d × Nx that stores the coordinates of all node positions and ensures

continuity at the faces of all elements. Here Nx is the global number of control points for a

principal direction.

2.2. TMOP for r−adaptivity

In this subsection we summarize the main components of the TMOP approach; all details

of the speciﬁc method we use are provided in [7]. The input of TMOP is the user-speciﬁed
transformation matrix W , from reference-space ¯E to target element Et, which represents

the ideal geometric properties desired for every mesh point. Note that after discretization,

there will be multiple input transformation matrices W – one for every quadrature point in

4

Figure 1: Schematic representation of the major TMOP matrices.

every mesh element. The construction of this transformation is guided by the fact that any

Jacobian matrix can be written as a composition of four components:

W = ζ

(cid:124)(cid:123)(cid:122)(cid:125)
[volume]

R
(cid:124)(cid:123)(cid:122)(cid:125)
[rotation]

Q
(cid:124)(cid:123)(cid:122)(cid:125)
[skewness]

D
(cid:124)(cid:123)(cid:122)(cid:125)
[aspect ratio]

.

(2)

Further details and a thorough discussion on how TMOP’s target construction methods

encode geometric information into the target matrix W is given by Knupp in [31]. In the

context of r−adaptivity the geometric parameters of (2) are typically constructed using a

discrete PDE solution available on the initial mesh. As the nodal coordinates change during

the optimization process, these discrete functions are mapped to the updated mesh so that

W can be constructed at each reference point, see Section 4 in [32].

Using (1), the Jacobian A of the mapping ΦE from the reference coordinates ¯x ∈ ¯E to

the current physical-space coordinates x ∈ E is deﬁned as

A(¯x) =

∂ΦE
∂ ¯x

=

Np
(cid:88)

i=1

xE,i[∇ ¯wi(¯x)]T ,

¯x ∈ ¯E.

(3)

Combining (3) and (2), the transformation from the target coordinates to the current physical

coordinates, see Figure 1, is deﬁned as

T = AW −1.

(4)

The matrix T is then used to deﬁne a quality metric µ(T ) that measures the diﬀerence

between A and W in terms of the geometric parameters of interest speciﬁed in (2). For

example, µ2 = |T |2/2τ − 1 is a shape metric that depends on the skew and aspect ratio

5

components, but is invariant to orientation and volume. Here, |T | is the Frobenius norm of

T and τ = det(T ). Similarly, µ55 = (τ − 1)2 is a size metric that depends only on the volume
of the element. There are also shape+size metrics such as µ7 = |T −T −t|2 or µ9 = τ |T −T −t|2

that depend on volume, skew and aspect ratio, but are invariant to orientation. A list of

metrics along with their theoretical properties can be found in [33].

The quality metric µ(T ) is used to deﬁne the TMOP objective function: for any given

vector x of node positions, we deﬁne

F (x) =

(cid:90)

(cid:88)

E∈M

Et

ω(xt)µ(T (xt))dxt +

(cid:90)

(cid:88)

E∈M

Et

ξ(x − x0, δ(x0))dxt,

(5)

where x = x(¯x) = x(¯x(xt)) is the element E mapping deﬁned by x, Et is the target element

corresponding to the physical element E, ω is a user-prescribed spatial weight, and the

integral involving ξ(x−x0, δ(x0)) limits the node displacements in a user-speciﬁed manner (a

typical choice is ξ(y, δ) = |y|2/δ2) with x0 = x0(¯x) = x0(¯x(xt)) being a given initial/reference

mesh position. The integrals are computed with a standard quadrature rule. The mesh is

optimized by minimizing the objective F through node movement. More speciﬁcally, we

solve ∂F (x)/∂x = 0 with a nonlinear solver, e.g., Newton’s method. The gradient ∂F and

Hessian ∂2F of F are discussed in further detail in Sections 3.3 and 3.4.

Figure 2 shows an example of r−adaptivity to a discrete material indicator using TMOP

to control the aspect-ratio and the size of the elements in a mesh.

In this example, the

material indicator function is used to deﬁne discrete functions for aspect-ratio and size targets

in (2), and the mesh is optimized using a shape+size metric.

Figure 2: (left) Material indicator function on the initial uniform mesh and (right) the optimized mesh.

6

2.3. Nonlinear Solver

The optimal nodal locations are determined by minimizing the TMOP objective function

(5) using the Newton’s method. At each Newton iteration, we update the nodal positions as

xn+1 = xn − α∆xn,

∆xn = [∂2F (xn)]−1∂F (xn).

(6)

(7)

Here, xn refers to the vector of nodal positions at the n-th iteration during r−adaptivity, α is

a scalar determined by a line-search procedure, and ∂2F (xn) and ∂F (xn) are the Hessian and

the gradient, respectively, associated with the TMOP objective function. The line-search pro-

cedure requires that α is chosen such that F (xn+1) < 1.2F (xn), |∂F (xn+1)| < 1.2|∂F (xn)|,

and that the determinant of the Jacobian of the transformation at each quadrature point in

the mesh is positive, i.e., det(A(xn+1)) > 0. These line-search constraints have been tuned

using many numerical experiments and have demonstrated to be eﬀective in improving mesh

quality. For Newton’s method, the Hessian ∂2F (xn) is inverted using the Minimum Residual

(MINRES) method with Jacobi preconditioning; more sophisticated preconditioning tech-

niques can be found in [34]. Additionally, the optimization solver iterations (6) are repeated

until the relative l2 norm of the gradient of the objective function with respect to the current

and original mesh nodal positions is below a certain tolerance ε, i.e., |∂F (x)|/|∂F (x0)| ≤ ε.

We set ε = 10−10 for the results presented in the current work.

3. Partial Assembly for Adaptive Mesh Optimization

Traditionally, linear FEM operators are assembled and stored in the form of sparse matri-

ces, and their action is computed using matrix-vector products. This approach can become

prohibitively expensive when the polynomial degree p of the basis functions is high, as op-

erator storage, assembly, and evaluation, per element, scale as O(p2d), O(p3d), and O(p2d),

respectively [8].

In contrast to this full-assembly approach, the high-order ﬁnite element

community has demonstrated that using a tensor-product structure for the basis functions

and integration rule with a matrix-free approach [8, 35, 3] reduces the computational com-

plexity of FEM operators such that the storage, assembly, and evaluation, per element, scale

7

Figure 3: Fundamental ﬁnite element operator decomposition, see [8, 1].

as O(pd), O(pd), and O(pd+1), respectively.

In this section, we present our approach to

extend the notion of partial assembly for FEM operators to mesh optimization.

The PA technique utilizes heavily the fundamental ﬁnite element operator decomposition

[8, 1], namely, that any parallel FE operator A can be decomposed as:

A = P T GT BT DBGP,

(8)

see Figure 3, where P represents the subdomain restriction operator that maps the global

MPI vector (T-vector) to its local processor values (L-vector), G represents the element

restriction operator that maps the L-vector to its element values (E-vector), B represents

the basis evaluator that interpolates an E-vector to the quadrature points inside each element

(Q-vector), and ﬁnally D is the operator that deﬁnes the quadrature-level computations. The

idea of PA is to compute and store only the result of D, and evaluate the actions of P, G and

B on-the-ﬂy. Furthermore, PA takes advantage of the tensor product structure of the degrees

of freedom and quadrature points on quadrilateral and hexahedral elements to perform the

action of B without storing it as a matrix, as shown later.

In the following subsections we will often refer to the individual components of the po-

sition x = x(¯x), namely, x = (x1, . . . , xd)T where d is the dimension and each component is
expanded as xa(¯x) = (cid:80)Nx

i=1 xa,i ¯wi(¯x), a = 1, . . . , d. Then the discrete vector that contains all
nodal positions is x = {xa,i} for all a = 1, . . . , d and i = 1, . . . , Nx. At places we will also

redirect the interested reader to the source code of our implementation. We use the ﬁnite

element library MFEM [8], speciﬁcally version 4.3.

8

3.1. Basis Functions and Tensor Products

Recall that we represent the mesh positions by (1), where on the reference element we use

the scalar basis functions { ¯wi}Np

i=1. For quadrilateral and hexahedral elements, we utilize basis

functions that are constructed as tensor products of the standard 1D Lagrange polynomials,

e.g., for d = 3 we can write:

¯wi(¯x) = ¯wi1,i2,i3(¯x1, ¯x2, ¯x3) = (cid:96)i1(¯x1)(cid:96)i2(¯x2)(cid:96)i3(¯x3),

(9)

where ¯x = (¯x1, ¯x2, ¯x3) is a position in reference space and (cid:96)j denotes a 1D Lagrange polyno-

mial (or basis function) in [0, 1] of degree p. There are p + 1 such basis functions, and we

will often refer to this number as ni = p + 1. For simplicity of notation, we will identify the

multi-index i = (i1, i2, i3) with a single index i given by an explicit formula depending on

the ordering. For example, for 3D lexicographic ordering,

i = 1 +

(cid:16)

(cid:17)

i1 − 1

(cid:16)

+

(cid:17)(cid:16)

i2 − 1

p + 1

(cid:17)

(cid:16)

+

(cid:17)(cid:16)

i3 − 1

(cid:17)2

,

p + 1

i1, i2, i3 ∈ {1, . . . , p + 1} .

With the tensor-product decomposition (9), the spatial derivatives of the reference basis

functions can be written as

∂ ¯wi(¯x)
∂ ¯x1

= (cid:96)(cid:48)

i1(¯x1)(cid:96)i2(¯x2)(cid:96)i3(¯x3),

∂ ¯wi(¯x)
∂ ¯x2

= (cid:96)i1(¯x1)(cid:96)(cid:48)

i2(¯x2)(cid:96)i3(¯x3),

∂ ¯wi(¯x)
∂ ¯x3

= (cid:96)i1(¯x1)(cid:96)i2(¯x2)(cid:96)(cid:48)

i3(¯x3).

In addition, we always use quadrature rules that are constructed from products of 1D

quadrature rules. More speciﬁcally, suppose we use a quadrature rule with nq quadrature

points in each direction, having a total of Nq = nd

q points in each element. Then a 3D

quadrature point χq for q = (q1, q2, q3) can be represented as

χq = χq1,q2,q3 = (χq1, χq2, χq3),

where {χj} for j = 1, . . . , nq are the points of the 1D (e.g. Gaussian) rule. When both the

basis functions and the quadrature rule have tensor product structure, we can use tensor

contractions to transfer data between degrees of freedom and quadrature points, leading to

eﬃcient ﬁnite element calculations as described in the following sections.

Once a quadrature rule is selected, we deﬁne 1D reference matrices of size nq × ni:

B1D

qi = (cid:96)i(χq), G1D

qi = (cid:96)(cid:48)

i(χq),

i = 1, . . . , ni,

q = 1, . . . , nq,

(10)

where (cid:96)i is a 1D basis function and χq is a quadrature point of the 1D quadrature rule.

9

3.2. Quadrature Level Calculations

The primary calculation at a quadrature point is that of the Jacobian matrix A, see (3).

For a reference point ¯x the entries of A = A(¯x) can be written as:

Aab =

∂xa
∂ ¯xb

=

Np
(cid:88)

i=1

xa,i

∂ ¯wi(¯x)
∂ ¯xb

,

a, b = 1, . . . , d.

Since a given element contains O(pd) degrees of freedom (DOFs) and O(pd) quadrature

points, computing A at all quadrature points would be of complexity O(p2d) assuming we

precompute and store the terms ∂ ¯wi(ξq)/∂ ¯xb. When we utilize 1D tensor contractions, the

entries of Aab at all quadrature points in the element can be computed by (example for the

3D case when b = 2):

Aa2(χq) =

(cid:32)

(cid:88)

B1D
q1,i1

(cid:32)

(cid:88)

G1D
q2,i2

(cid:32)

(cid:88)

i1

i2

i3

(cid:33)(cid:33)(cid:33)

B1D

q3,i3xa,i1,i2,i3

= (cid:2)B1D ⊗ G1D ⊗ B1D xE,a

(cid:3)
q1,q2,q3

where xE,a = {xa,i}Np

i=1. Here the ⊗ symbol denotes the tensor outer product which means

that the matrices will be applied as a sequence of multiplications as given by the above

formula. The important point here is that each contraction is of complexity O(pd+1) (as

xE,a is a tensor of rank d), resulting in an overall complexity of O(pd+1). This is a signiﬁcant

improvement over O(p2d), especially for high p. One complication with tensor contractions

is that the implementation has to take care of arranging the vectors xE in a suitable tensor

form.

The rest of the quadrature level calculations are independent of the ﬁnite element dis-

cretization, i.e., they do not involve the ﬁnite element basis functions { ¯wi}. Here the notion

of sum factorization does not apply; computational gains can be achieved on GPU devices

by proper batching over many quadrature points. The major quadrature level calculations

are the following:

• Given physical coordinates of a point x, construct the target matrix W (x) and compute

det(W (x)). In the case of adaptivity, additional simulation-speciﬁc values also provided

as input to the computation of W .

• Given a d × d matrix T , compute the mesh quality metric the µ(T ), its ﬁrst derivative

10

∂µ/∂T which is a d×d matrix, and its second derivative ∂2µ/∂T 2 which is a d×d×d×d

tensor. These are derived using standard matrix algebra, e.g. [36].

3.3. Objective Function and First Derivative

In this section we consider the TMOP objective function of the form (5) and its ﬁrst

derivative. In this section we focus on the ﬁrst term in (5) while the second term will be

discussed later in Section 3.5.

To evaluate the objective function F (x) one can use the following decomposition similar

to (8)

F (x) = 1T D0(BGP x)

where 1 is a vector of ones and D0 evaluates, at all quadrature points, the integrand of the
ﬁrst term in (5) after changing the variables in the integral from Et to ¯E and applying the

quadrature rule:

D0(A) = wq det(W )ω(xt)µ(AW −1).

(11)

Here wq is the quadrature point weigth, ω(xt) det(W ) and W are the precomputed values

for the current quadrature point, and A is the Jacobian matrix at the current quadrature

point computed by evaluating BGP x.

The main speedup in the calculation of the objective function comes from proper batching

of the computation of the Jacobian A over all quadrature points, as explained in Section

3.2. Once T = AW −1 and µ(T ) are computed at all quadrature points, the ﬁnal integral is

readily available.

The computation of the gradient ∂F/∂x is improved by utilizing the PA technique. For

simplicity, in the formulas below we assume that W = I (the target elements coincide with

the reference one), although this is generally not the case as explained in Section 3.6. Then

the ﬁrst derivative of the objective F with respect of the node xa,i for each element is:
(cid:90)

(cid:19)

(cid:90)

∂T (x)
∂xa,i

d¯x =

∂µ
∂T

(cid:18) ∂A
∂xa,i

:

¯E

d¯x

∂µ
∂Tmn

δm,a

∂ ¯wi(χq)
∂ ¯xn

(cid:21)

,

a = 1, . . . , d,

i = 1, . . . , Nx,

(12)

∂F (x)
∂xa,i

:

∂µ
∂T (x)
(cid:20)
d
(cid:88)

zq

¯E
Nq
(cid:88)

=

=

q=1

m,n=1

where zq is the quadrature point weight and δ is the standard Kronecker delta. The depen-

dence of x in (12) comes through the nonlinearity of µ(T ). With PA we eﬃciently compute

11

all quadrature points together, as a result of a tensor contraction. We ﬁrst form a D matrix

of size nq × nq × nq in each element that stores all quadrature data, e.g., the derivatives

∂µ/∂T . This quadrature-based calculation is of complexity O(pd). Then D, x, B, G are con-

tracted appropriately to obtain the ﬁnal derivative vector, with complexity O(pd+1). These

contraction calculation are complicated and can be found in the mfem-4.3 source in ﬁles

fem/tmop/tmop pa p2.cpp and fem/tmop/tmop pa p3.cpp for 2D and 3D, respectively. Once

the gradient of the TMOP objective function is computed on an element-by-element basis

(E-vector), it is mapped to a global T-vector, see Figure 3, to ensure that the gradients are

consistent for DOFs that are shared between neighboring elements.

3.4. Second Derivative and Linear Solver

Again assuming W = I, the second derivative of F for the nodes xa,i and xb,j is:

∂2F (x)
∂xb,j∂xa,i

=

=

(cid:90)

¯E
Nq
(cid:88)

∂
∂xb,j
(cid:20)

zq

(cid:20) ∂µ
∂T

(cid:18) ∂A
∂xa,i

:

(cid:19) (cid:21)

d¯x

d
(cid:88)

d
(cid:88)

∂2µ
∂Top∂Tmn

δo,b

∂ ¯wj(χq)
∂ ¯xp

δm,a

∂ ¯wi(χq)
∂ ¯xn

(cid:21)

,

(13)

q=1

m,n=1

o,p=1

a, b = 1, . . . , d,

i, j = 1, . . . , Nx,

where zq is the quadrature point weight and δ is the standard Kronecker delta. Assembling

and applying the Hessian matrix ∂2F are the two most expensive computations in our al-

gorithm. The classical (full assembly) approach forms a sparse matrix over all DOFs in the

problem, requiring to store O(p2d) entries per element. Computing these entries with stan-

dard nested loops requires O(p3d) operations per element, while applying the sparse matrix

to a vector is complexity O(p2d). Since ∂2F depends on the current mesh positions (due

to the nonlinearity of µ with respect to T ), the assembly must be performed at every New-

ton iteration. For higher mesh orders p these computations become prohibitively expensive,

especially in 3D.

The use of PA for ∂2F is critical, as it avoids the formation of a global sparse matrix.

In this case the assembly is replaced by pre-computing and storing the quadrature-speciﬁc

data at all quadrature points, with complexity and storage of O(pd) per element. The action

of ∂2F is performed element-by-element, using tensor contractions involving the quadrature

12

data, the DOF vector x, and the 1D matrices B and G. This PA-based action is of com-

plexity O(pd+1) per element. The complete calculation can be seen in mfem-4.3’s source

ﬁles fem/tmop/tmop pa h2m.cpp and fem/tmop/tmop pa h3m.cpp for 2D and 3D, respectively.

The assembly of all quadrature point data is in the ﬁles fem/tmop/tmop pa h2s.cpp and

fem/tmop/tmop pa h3s.cpp for 2D and 3D, respectively. The inversion of ∂2F is performed

by an iterative solver that uses the PA-based action of the operator. Our default choice is the

Minimum Residual (MINRES) method, as ∂2F is symmetric but not necessarily positive-

deﬁnite. Preconditioning for matrix-free inversion is a substantial challenge and an active

area of research [5]. We have the option to perform Jacobi preconditioning, as the diagonal of

∂2F can be computed through tensor contractions without having the global matrix; these

algorithms can be foung in ﬁles fem/tmop/tmop pa h2d.cpp and fem/tmop/tmop pa h3d.cpp

for 2D and 3D, respectively.

3.5. Limiting of Node Displacements

The term involving the limiting function ξ(x−x0, δ(x0)) in (5) is used to restrict the node

displacements in certain regions of the domain during mesh optimization, see Section 3.2 of

[7]. A simple example of a node limiting function is ξ(x − x0, δ(x0)) = (x − x0)2/δ2, which

would start to dominate the objective function once the displacements go above the local δ

value. Computing this term and its derivatives through PA does not present any diﬃculty.

For example, the second derivative of this term is:

∂2
∂xb,j∂xa,i

(cid:90)

Et

ξ(x − x0, δ(x0))dxt =

=

(cid:90)

¯E
Nq
(cid:88)

q=1

det(W )

∂2ξ
∂xb∂xa

∂xb
∂xb,j

∂xa
∂xa,i

d¯x

zq det(W (¯xq))

∂2ξ
∂xb∂xa

¯wj(¯xq) ¯wi(¯xq),

(14)

which resembles a standard FE mass operator. Dependence on the current mesh positions

x in (14) appears when ξ is chosen as a nonlinear function with respect to x − x0. The

PA-based action is formed by contracting B and x with the matrix D that contains all the

quadrature data needed in (14). For example, in 3D, the action of this operator to a vector

x (rearranged as a tensor X) is computed as

B1DT

⊗ B1DT

⊗ B1DT

⊗ D ⊗ B1D ⊗ B1D ⊗ B1DX.

13

The implementation of the above computation can be found in the following mfem-4.3 source

ﬁles: fem/tmop/tmop pa h2m c0.cpp and fem/tmop/tmop pa h3m c0.cpp for 2D and 3D, respec-

tively.

3.6. Adaptivity and Field Transfer

When TMOP is used to achieve r-adaptivity, the deﬁnitions of the target matrices contain

information about discrete simulation ﬁelds [7]. For illustration purposes, we denote such

simulation ﬁelds by η(x), which for our purposes is always a FE function. The evaluation of

W requires the evaluation of η(x), which is optimized by tensor contractions, that is, the η

values at all quadrature points are obtained through d contractions of the B1D matrices.

The target matrices W becomes space-dependent through its η dependence. Since

∂W/∂x (cid:54)= 0, the derivatives in equations (12), (13) and (14) become more complicated,

as well as their PA implementation. In our experience, adding the extra derivative terms

does not change the results in a signiﬁcant way, and we don’t include these terms in our

current implementation. The dependence of W on x is still accounted by the algorithm, as

the targets are recomputed after every position change in the nonlinear iteration.

Since ﬁnite element ﬁelds are only deﬁned with respect to the initial mesh M0, remap

procedures are needed to obtain their values on the diﬀerent meshes obtained during the mesh

optimization iterations [32, 37]. Our GPU implementation utilizes the so-called advection

approach, where remap is achieved by solving an advection PDE in pseudo-time. This

approach is entirely based on standard ﬁnite element operations, enabling the use of sum

factorization and optimized matrix-free kernels. By deﬁning a mesh velocity v = x − x0, the

remap of a function η(x) is posed as the following PDE in pseudo-time τ ∈ [0, 1]:

dη(xτ , τ )
dτ

= v · ∇η(xτ , τ ),

xτ = x0 + τ v,

η(x0, 0) = η0(x0).

More details about the mathematical formulation can be found in Section 4.2 of [32]. Solving

the above PDE in a matrix-free manner requires to deﬁne the actions of a mass operator

and an advection operator. The mass operator is applied many times per time step, as it is

used by a conjugate gradient linear solver. The advection operator is applied once per time

step, to form the right-hand-side of the linear system. The actions of these operators are

standard FE kernels, and we directly use their optimized PA implementations from MFEM.

14

4. Numerical Results

In this section we present several numerical examples and benchmarks demonstrating

the improvement in computational eﬃciency due to use of partial assembly on GPU-based

architectures in comparison to full-assembly on CPUs.

4.1. Kershaw Benchmark

Below we propose a performance benchmark for optimization of high-order meshes. The

setup is based on the Kershaw meshes introduced in [38]. The test is designed so that both

the initial (deformed) mesh and the ﬁnal (optimized) mesh are straightforward to reproduce.

This allows to compare the performance of diﬀerent optimization methods on a problem with

well-deﬁned initial conﬁguration and ﬁnal output.

The initial mesh (that will be optimized) is obtained by an analytic deformation of

a uniform Cartesian mesh. The deformation curves and distorts the elements, allowing

to quantify the performance of the method in terms of speed and accuracy for meshes of

diﬀerent orders and element counts. The Kershaw meshes [38, 39] are parameterized by two

anisotropy parameters εy, εz ∈ (0, 1] such that the meshes are uniform for εy = εz = 1 and

become increasingly anisotropic as εy an εz decrease, see Figure 4. To obtain the Kershaw

mesh, the x-axis of the mesh is decomposed into 6 equally sized layers, and elements in

the leftmost and rightmost layers are modiﬁed to have aspect-ratios 1/εy and 1/εz. The

high aspect-ratio elements are placed in the opposite corners, while the intermediate layers

are smoothly transitioned with a piecewise quintic function. The generating C++ code is

provided in Appendix A for convenience. Due to the problem setup, the number of elements

in the x-direction must be an integer multiple of 6, while in the y- and z-directions must be

multiples of 2.

Baseline Wall Time. First we report baseline time-to-solution for a complete mesh opti-

mization computation, that is, evolving an initially deformed mesh to the ideal uniform

conﬁguration. The deformed meshes are obtained by εy = εz = 0.3 and the resolution is

ﬁxed to 24 × 24 × 24. We present timings for diﬀerent mesh orders, diﬀerent solver strategies

(Newton’s method with and without preconditioner), and diﬀerent architectures (CPU versus

GPU). For these experiments, the quadrature order is ﬁxed at 8, resulting in 93 quadrature

15

Figure 4: Kershaw meshes: (left to right) (a) εy = εz = 1, (b) εy = 0.3, εz = 1, (c) εy = 1, εz = 0.3, and (d)

εy = εz = 0.3.

points per element, maximum number of linear solver iterations per Newton iterations is 60,
and µ303 = |T |2
3τ (2/3)

− 1 is used for shape optimization. The results presented here were ob-

tained on Lassen, a Livermore Computing supercomputer, that has IBM Power9 CPUs (792

nodes with 44 CPU cores per node) and NVIDIA V100 GPUs (4 per node). All reported

computations utilize a single machine node. The CPU runs use 36 CPU cores, while the

GPU runs utilize 4 CPU cores with 1 GPU per core.

Table 1 compares the unique degrees of freedom and total quadrature points per core,

total time to solution, Newton iterations, and MINRES iterations, for diﬀerent mesh orders

(p = 1, . . . , 4) and diﬀerent solver strategies. The corresponding data is also shown in Figure

5. We note that the use of GPUs leads to a 30-40× speed up in comparison to CPUs. We

also quantify the total time spent in each of the main kernels (gradient, Hessian, etc.) during

mesh optimization in Figure 6.

Figure 5: (left to right) Comparison of (a) total time to solution, (b) Newton iterations, and (c) MINRES

iterations for diﬀerent solver strategies and architectures.

16

Time to solution (sec)

Unique Degrees of Freedom

p = 1

p = 2

p = 3

p = 1

p = 2

p = 3

p = 4

CPU

22.7

97.9

186.7

352,947

46,875
Quadrature points per core ( E(Q+1)d

1,167,051

2,738,019

P

CPU+Prec

18.8

43.0

129.6

)

GPU

GPU+Prec

0.5

0.4

1.9

1.0

5.2

3.9

p = 4

303.4

224.3

8.9

7.5

CPU

GPU

279,936

2,519,424

(a)

Speedup (GPU+Prec vs CPU+Prec)

47× 43× 33×

30×

(b)

Total Newton Iterations

Total MINRES Iterations

p = 1

p = 2

p = 3

p = 4

p = 1

p = 2

p = 3

p = 4

CPU

CPU+Prec

GPU

GPU+Prec

16

11

16

11

31

17

28

17

(c)

51

37

43

38

67

53

70

56

CPU

CPU+Prec

GPU

GPU+Prec

293

227

295

227

1395

2577

3869

539

1621

2574

1216

2397

3586

539

1572

2781

(d)

Table 1: For meshes of diﬀerent orders (p), we compare (a) unique degrees of freedom and total quadrature

points per core, (b) total time to solution, (c) total Newton iterations, and (d) total MINRES iterations.

Strong scaling. A strong scaling study of the GPU algorithm is reported in Figure 7 on up to

128 GPUs. For all computations, the number of elements is ﬁxed to 96 × 96 × 96. For ideal

strong scaling, the time per cycle would decrease linearly as we increase the GPU count. As

expected, the scaling deteriorates as the GPU count increases, as there is no longer suﬃcient

work to feed each GPU.

Every data point in Figure 7 is obtained by timing the computation of a single Newton

iteration on the initial deformed mesh, with 20 iterations of the MINRES linear solver. The

number of quadrature point per element is set to 33, 43, 53, and 63 for mesh orders 1, 2, 3,

and 4, respectively.

Throughput. Next we provide throughput results that demonstrate how well the proposed

algorithms utilize the machine resources as the problem size increases. The plots on Figure

17

(a) GPU

(b) GPU+Prec

(c) CPU

(d) CPU+Prec

Figure 6: Percentage of the total time spent in diﬀerent Kernels for diﬀerent solver strategies and architec-

tures.

8 show the throughput for our most important kernel, i.e., the action of ∂2F , in terms of

billions of degrees of freedom processed per second vs. the problem size in the CPU and

GPU cases. Such plots are useful in comparing the performance of diﬀerent orders and

problem size in both the weak and scale limits, see e.g. [1]. For example, higher throughput

means faster run time, and from Figure 8 we can see that on both platforms higher orders

perform better, but the diﬀerence is much more signiﬁcant on GPUs. Furthermore, while

CPU performance is relatively ﬂat across problem sizes, the GPU requires signiﬁcant number

of unknowns (in the millions of degrees of freedom) to achieve the best results.

Figure 9 shows the throughput for the complete TMOP algorithm for a single GPU. Again

we observe that the higher orders achieve better computational intensity, especially for larger

problems. Every data point in Figures 8 and 9 is obtained by timing the computation of a

18

Figure 7: Strong scaling for the Kershaw benchmark.

single Newton iteration on the initial deformed mesh. The number of linear solver iteration

is ﬁxed to 20 to make sure every data point represents the same amount of computational

work. The number of quadrature point per element is set to 33, 43, 53, and 63 for mesh orders

1, 2, 3, and 4, respectively.

4.2. ALE Simulation with Material-Adaptive TMOP

In this section we demonstrate the proposed GPU-algorithms in the settings of a mul-

timaterial ALE hydrodynamics production code. We consider a simulation of the BRL81a

shaped charge using the MARBL multiphysics application [40]. A shaped charge is a device

which focuses the pressures of a high explosive onto a metal “liner” to form a hyper-velocity

jet which can be used in many applications, including armor penetration, metal cutting and

perforation of wells for the oil/gas industry [41].

The ALE hydrodynamics algorithm consists of the following phases:

1. High-order Lagrange multimaterial hydrodynamics on a moving, unstructured, high-

order mesh [42], including use of GPU accelerated 3rd party libraries for material

19

48163264128100101NumberofGPUsSolveTime(second)Idealp=1p=2p=3p=4a. 40 IBM Power9 cores

b. 4 NVIDIA Tesla V100-SXM2

Figure 8: Throughput comparison - action of the second derivative operator. Single Lassen node throughput

(in GDOF/s, i.e. billions of degrees of freedom per second) of (a) 40 IBM Power9 CPU cores and (b) 4

NVIDIA Tesla V100-SXM GPU.

Figure 9: Throughput of the complete TMOP computation. Single NVIDIA Tesla V100-SXM GPU through-

put (in MDOF/s, i.e. millions of processed degrees of freedom per second).

equations of state (EOS) evaluation and material constitutive models.

2. Non-linear, material adaptive, high-order mesh optimization using the presented TMOP

method.

20

10410510610705101520DegreesofFreedom(DOF)MDOF/sp=1p=2p=3p=43. High-order continuous (kinematic) and discontinuous Galerkin (thermodynamic) advection-

based remap using ﬂux corrected transport (FCT).

Figure 10: Snapshots of the density (top) and mesh (bottom) for the ALE shaped charge GPU simulation

using material adaptive TMOP at times t=0, 17.5 and 35 (left to right).

In Figure 10, we show results of a MARBL calculation of the BRL81a model with all three

phases of the ALE algorithm run on the GPU. To enhance the high-order mesh resolution

near the hyper-velocity copper jet, we employ the material adaptive capabilities of the TMOP

mesh optimization phase at the copper material with a 2:1 size ratio. To prevent the mesh

from moving in regions which have not experienced hydrodynamic motion, we utilize the

limiting term in our optimization metric. We use p = 2 elements for the mesh and the

continous kinematic ﬁelds with 64 quad points per element (combined with p = 1 DG

elements for the thermodynamic variables). This simulation consists of 14, 346, 240 total

quadrature points on a high-order (p = 2), highly unstructured mesh. We run the problem

using 2 nodes of the Lassen machine at LLNL and compare performance results between

the CPU only case (80 IBM Power9 cores) and the GPU case (8 NVIDIA Tesla V100-SXM

GPUs) for total of 2500 simulation cycles. Over these 2500 cycles, the code performs ALE

remap at ﬁxed time intervals for a total of 25 ALE steps. The material adaptive TMOP

Newton solver is run at each ALE step with an outer residual tolerance of 10−10 with a

max of 10 iterations while the inner linear solver has a max of 100 iterations. The relative

21

performance comparison between the CPU and GPU node simulations is shown in Table 2

and Table 3. In the CPU case, mesh optimization takes a substantially larger portion of

the overall runtime, comprising 15% of total wall time vs. 7% in the GPU case as shown in

Table 2. The GPU speedup for the mesh optimization phase of the simulation is over 20×

as shown in Table 3.

Lagrange Mesh Optimization Remap Other

CPU

31.34%

GPU 14.00%

14.86%

6.72%

53.53% 0.17%

73.39% 5.89%

Table 2: Percentage of total run time for each phase of the multimaterial ALE simulation. Comparison of

CPU vs GPU runs.

Min time/rank Max time/rank Avg time/rank Speedup

CPU MeshOpt

CPU Action

GPU MeshOpt

GPU Action

4730.828

4713.425

288.126

209.422

4730.831

4713.427

289.125

209.436

4730.830

4713.426

-

-

288.842

16.37×

209.430

22.51×

Table 3: Total run time with min/max/avg time across all MPI ranks (80 for CPU, 8 for GPU) for the

full mesh optimization phase (MeshOpt) and for the ∂2F operator evaluation (Action) over 2500 simulation

cycles for the multimaterial ALE simulation. Comparison of CPU vs GPU runs.

5. Conclusion

This paper discussed the use of ﬁnite element partial assembly techniques in the context

of high-order mesh optimization. We demonstrated that this approach leads to substantial

improvements in performance complexity for tensor-product elements (quads and hexes), and

the resulting tensor contractions perform well on GPU hardware. In addition, we proposed

a simple mesh optimization benchmark for the mesh optimization community. Our method

relies on eﬃcient matrix-free preconditioning, which is still an area of active research. We

plan to explore that further in a future publication.

22

References

[1] T. V. Kolev, P. Fischer, M. Min, J. Dongarra, J. Brown, V. Dobrev, T. Warbur-

ton, S. Tomov, M. Shephard, A. Abdelfattah, V. Barra, N. Beams, J.-S. Camier,

N. Chalmers, Y. Dudouit, A. Karakus, I. Karlin, S. Kerkemeier, Y.-H. Lan, D. Medina,
E. Merzari, A. Obabko, W. Pazner, T. Rathnayake, C. Smith, L. Spies, K. ´Swirydowicz,

J. Thompson, A. Tomboulides, V. Z. Tomov, Eﬃcient exascale discretizations: High-

order ﬁnite element methods, Int. J. High Perform. Comput. Appl. (2021). doi:

10.1177/10943420211020803. 1, 2, 8, 18

[2] V. A. Dobrev, P. Knupp, T. V. Kolev, K. Mittal, V. Z. Tomov, The Target-Matrix

Optimization Paradigm for high-order meshes, SIAM J. Sci. Comp. 41 (1) (2019) B50–

B68. 2, 4

[3] M. O. Deville, P. F. Fischer, P. F. Fischer, E. Mund, et al., High-order methods for

incompressible ﬂuid ﬂow, Vol. 9, Cambridge university press, 2002. 2, 7

[4] P. D. Bello-Maldonado, T. V. Kolev, R. N. Rieben, V. Z. Tomov, A matrix-free hyper-

viscosity formulation for high-order ALE hydrodynamics, Computers & Fluids (2020)

104577. 2

[5] M. Franco, J.-S. Camier, J. Andrej, W. Pazner, High-order matrix-free incompressible

ﬂow solvers with GPU acceleration and low-order reﬁned preconditioners, Computers

& Fluids (2020) 104541. 2, 13

[6] M. Kronbichler, K. Kormann, Fast matrix-free evaluation of discontinuous Galerkin

ﬁnite element operators, ACM Transactions on Mathematical Software (TOMS) 45 (3)

(2019) 1–40. 2

[7] V. A. Dobrev, P. Knupp, T. V. Kolev, K. Mittal, R. N. Rieben, V. Z. Tomov, Simulation-

driven optimization of high-order meshes in ALE hydrodynamics, Comput. Fluids

(2020). 2, 4, 13, 14

[8] R. Anderson, J. Andrej, A. Barker, J. Bramwell, J.-S. Camier, J. Cerveny, V. A. Dobrev,

Y. Dudouit, A. Fisher, T. V. Kolev, W. Pazner, M. Stowell, V. Z. Tomov, I. Akkerman,

23

J. Dahm, D. Medina, S. Zampini, MFEM: a modular ﬁnite elements methods library,

Comput. Math. Appl. 81 (2020) 42–74. doi:10.1016/j.camwa.2020.06.009. 2, 7, 8

[9] V. A. Dobrev, P. Knupp, T. V. Kolev, K. Mittal, V. Z. Tomov, HR-adaptivity for

nonconforming high-order meshes with the Target-Matrix Optimization Paradigm, Eng.

Comput. (2021). doi:10.1007/s00366-021-01407-6. 3

[10] J. Vollmer, R. Mencl, H. Mueller, Improved Laplacian smoothing of noisy surface

meshes, in: Computer graphics forum, Vol. 18, Wiley Online Library, 1999, pp. 131–138.

3

[11] D. A. Field, Laplacian smoothing and Delaunay triangulations, Communications in

applied numerical methods 4 (6) (1988) 709–712. 3

[12] G. Taubin, et al., Linear anisotropic mesh ﬁltering, Res. Rep. RC2213 IBM 1 (4) (2001).

3

[13] P. Knupp, Introducing the target-matrix paradigm for mesh optimization by node move-

ment, Engr. with Comptr. 28 (4) (2012) 419–429. 3

[14] A. Gargallo-Peir´o, X. Roca, J. Peraire, J. Sarrate, Optimization of a regularized distor-

tion measure to generate curved high-order unstructured tetrahedral meshes, Interna-

tional Journal for Numerical Methods in Engineering 103 (5) (2015) 342–363. 3

[15] K. Mittal, P. Fischer, Mesh smoothing for the spectral element method, Journal of

Scientiﬁc Computing 78 (2) (2019) 1152–1173. 3

[16] P. T. Greene, S. P. Schoﬁeld, R. Nourgaliev, Dynamic mesh adaptation for front evolu-

tion using discontinuous Galerkin based weighted condition number relaxation, Journal

of Computational Physics 335 (2017) 664–687. 3

[17] M. Turner, J. Peir´o, D. Moxey, Curvilinear mesh generation using a variational frame-

work, Computer-Aided Design 103 (2018) 73–91. 3

24

[18] G. Aparicio-Estrems, A. Gargallo-Peir´o, X. Roca, Deﬁning a stretching and alignment

aware quality measure for linear and curved 2d meshes, in:

International Meshing

Roundtable, Springer, 2018, pp. 37–55. 3

[19] W. Huang, Y. Ren, R. D. Russell, Moving mesh partial diﬀerential equations (MM-

PDES) based on the equidistribution principle, SIAM J. Numer. Anal. 31 (3) (1994)

709–730. 3

[20] W. Huang, R. D. Russell, Adaptive moving mesh methods, Springer Science & Business

Media, 2010. 3

[21] D. An, N. Lei2B, T. Zhao, H. Si, X. Gu, A moving mesh adaptation method by optimal

transport (2021). 3

[22] J. G. Wallwork, N. Barral, D. A. Ham, M. D. Piggott, Anisotropic goal-oriented mesh

adaptation in ﬁredrake, 28th Intl Meshing Roundtable, Zenodo (2020) 83–100. 3

[23] D. Zint, R. Grosso, F. Lunz, Discrete mesh optimization on surface and volume meshes,

28th International Meshing Roundtable. Zenodo (2020). 3

[24] O. Coulaud, A. Loseille, Very high order anisotropic metric-based mesh adaptation in

3d, Procedia engineering 163 (2016) 353–365. 3

[25] J. P. D’Amato, M. V´enere, A CPU–GPU framework for optimizing the quality of large

meshes, Journal of Parallel and Distributed Computing 73 (8) (2013) 1127–1134. 3

[26] D. Zint, R. Grosso, Discrete mesh optimization on GPU, in: International Meshing

Roundtable, Springer, 2018, pp. 445–460. 3

[27] J. Eichst¨adt, M. Green, M. Turner, J. Peir´o, D. Moxey, Accelerating high-order mesh

optimisation with an architecture-independent programming model, Computer Physics

Communications 229 (2018) 36–53. 3

[28] G. Mei, J. C. Tipper, N. Xu, A generic paradigm for accelerating Laplacian-based mesh

smoothing on the GPU, Arabian Journal for Science and Engineering 39 (11) (2014)

7907–7921. 3

25

[29] E. Shaﬀer, Z. Cheng, R. Yeh, G. Zagaris, L. Olson, Simple and eﬀective GPU-based

mesh optimization, Parallel Computing: Accelerating Computational Science and En-

gineering (CSE) 25 (2014) 285–294. 3

[30] P. Fischer, M. Min, T. Rathnayake, S. Dutta, T. Kolev, V. Dobrev, J.-S. Camier,

M. Kronbichler, T. Warburton, K. Swirydowicz, J. Brown, Scalability of high-

performance PDE solvers, Int. J. HPC App. 34 (5) (2020) 562–586. doi:10.1177/

1094342020915762. 3

[31] P. Knupp, Target formulation and construction in mesh quality improvement, Tech. Rep.

LLNL-TR-795097, Lawrence Livermore National Lab.(LLNL), Livermore, CA (2019).

doi:10.2172/1571722.

URL https://www.osti.gov/biblio/1571722 5

[32] V. A. Dobrev, P. Knupp, T. V. Kolev, V. Z. Tomov, Towards Simulation-Driven Opti-

mization of High-Order Meshes by the Target-Matrix Optimization Paradigm, Springer

International Publishing, 2019, pp. 285–302. 5, 14

[33] P. Knupp, Metric type in the target-matrix mesh optimization paradigm, Tech. Rep.

LLNL-TR-817490, Lawrence Livermore National Lab.(LLNL), Livermore, CA (United

States) (2020). doi:10.2172/1782521.

URL https://www.osti.gov/biblio/1782521 6

[34] E. Ruiz-Giron´es, X. Roca, Automatic penalty and degree continuation for parallel pre-

conditioned mesh curving on virtual geometry, Comput.-Aided Des. 146 (2022) 103208.

doi:10.1016/j.cad.2022.103208. 7

[35] S. A. Orszag, Spectral methods for problems in complex geometrics, in: Numerical

methods for partial diﬀerential equations, Elsevier, 1979, pp. 273–305. 7

[36] K. B. Petersen, M. S. Pedersen, The matrix cookbook (version: November 15, 2012)

(2012). 11

[37] K. Mittal, S. Dutta, P. Fischer, Nonconforming Schwarz-spectral element methods for

incompressible ﬂow, Computers & Fluids 191 (2019) 104237. 14

26

[38] D. S. Kershaw, Diﬀerencing of the diﬀusion equation in Lagrangian hydrodynamic codes,

Journal of Computational Physics 39 (2) (1981) 375–395. 15

[39] T. Kolev, P. Fischer, A. P. Austin, A. T. Barker, N. Beams, J. Brown, J.-S. Camier,

N. Chalmers, V. Dobrev, Y. Dudouit, L. Ghaﬀari, S. Kerkemeier, Y.-H. Lan, E. Merzari,

M. Min, W. Pazner, T. Ratnayaka, M. S. Shephard, M. H. Siboni, C. W. Smith, J. L.

Thompson, S. Tomov, T. Warburton, CEED ECP milestone report: High-order algo-

rithmic developments and optimizations for large-scale GPU-accelerated simulations,

Tech. Rep. WBS 2.2.6.06, CEED-MS36, Exascale Computing Project (2021). 15

[40] R. Anderson, A. Black, B. Blakeley, R. Bleile, J.-S. Camier, J. Ciurej, A. Cook, V. Do-

brev, N. Elliott, J. Grondalski, C. Harrison, R. Hornung, T. Kolev, M. Legendre, W. Liu,

W. Nissen, B. Olson, M. Osawe, G. Papadimitriou, O. Pearce, R. Pember, A. Skinner,

D. Stevens, T. Stitt, L. Taylor, V. Tomov, R. Rieben, A. Vargas, K. Weiss, D. White,

L. Busby, The Multiphysics on Advanced Platforms Project, Tech. rep., LLNL-TR-

815869, LLNL (2020). doi:10.2172/1724326. 19

[41] W. Walters, A brief history of shaped charges, Vol. 1, 24th International Symposium

on Ballistics, New Orleans, LA, 2008, pp. 3–10. 19

[42] V. Dobrev, T. Kolev, R. Rieben, High-order curvilinear ﬁnite element methods for

Lagrangian hydrodynamics, SIAM J. Sci. Comp. 34 (5) (2012) B606–B641. 19

27

Appendix A. Source Code for Generating the Kershaw Mesh

In this appendix we provide the C++ code that is used to obtain the initial 3D Kershaw

mesh that is optimized in the benchmarks tests of Section 4.1. The initial domain is [0, 1]3.

Starting with a Cartesian mesh, the deformed conﬁguration is computed by the kershaw

function that transforms the input coordinates x,y,z to the deformed positions X,Y,Z. The

deformation is applied to all nodes of the position function x, see Section 2.1. If the initial

Cartesian mesh is nx × ny × nz, then nx should be divisible by 6 and ny and nz should be

divisible by 2. The parameters epsy and epsz correspond to εy and εz, see Figure 4.

return ( x <= 0.5) ? (2 - eps ) * x : 1+ eps *( x -1) ;

1 double right ( const double eps , const double x ) // 1 D transformation at right boundary
2 {
3
4 }
5 double left ( const double eps , const double x )
6 {
7
8 }
9 double step ( const double a , const double b , double x )
10 {
11

// 1 D transformation at left boundary

return 1 - right ( eps ,1 - x ) ;

12

if ( x <= 0) { return a ; }
if ( x >= 1) { return b ; }
return a + (b - a ) *( x * x * x *( x *(6* x -15) +10) ) ;

13
14 }
15 void kershaw ( const double epsy , const double epsz ,
16

// Smooth transition from a to b

const double x , const double y , const double z ,
double &X , double &Y , double & Z )

// (x ,y , z ) -> (X ,Y , Z ) Kershaw transform

17
18 {
19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

X = x ;
int layer = x *6.0;
double lambda = (x - layer /6.0) *6;
switch ( layer )
{

case 0:

Y = left ( epsy , y ) ;
Z = left ( epsz , z ) ;
break ;

case 1:
case 4:

Y = step ( left ( epsy , y ) , right ( epsy , y ) , lambda ) ;
Z = step ( left ( epsz , z ) , right ( epsz , z ) , lambda ) ;
break ;

case 2:

Y = step ( right ( epsy , y ) , left ( epsy , y ) , lambda /2) ;
Z = step ( right ( epsz , z ) , left ( epsz , z ) , lambda /2) ;
break ;

case 3:

Y = step ( right ( epsy , y ) , left ( epsy , y ) , (1+ lambda ) /2) ;
Z = step ( right ( epsz , z ) , left ( epsz , z ) , (1+ lambda ) /2) ;
break ;

default :

Y = right ( epsy , y ) ;
Z = right ( epsz , z ) ;
break ;

}

45
46 }

28

