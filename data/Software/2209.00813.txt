CASU: Compromise Avoidance via Secure Update
for Low-end Embedded Systems

Ivan De Oliveira Nunes
Rochester Institute of Technology

Sashidhar Jakkamsetti
UC Irvine

Youngil Kim
UC Irvine

Gene Tsudik
UC Irvine

2
2
0
2

p
e
S
2

]

R
C
.
s
c
[

1
v
3
1
8
0
0
.
9
0
2
2
:
v
i
X
r
a

Abstract—Guaranteeing runtime integrity of embedded sys-
tem software is an open problem. Trade-offs between security
and other priorities (e.g., cost or performance) are inherent,
and resolving them is both challenging and important. The
proliferation of runtime attacks that introduce malicious code
(e.g., by injection) into embedded devices has prompted a range
of mitigation techniques. One popular approach is Remote
Attestation (RA), whereby a trusted entity (veriﬁer) checks the
current software state of an untrusted remote device (prover).
RA yields a timely authenticated snapshot of prover state that
veriﬁer uses to decide whether an attack occurred.

Current RA schemes require veriﬁer to explicitly initiate RA,
based on some unclear criteria. Thus, in case of prover’s compro-
mise, veriﬁer only learns about it late, upon the next RA instance.
While sufﬁcient for compromise detection, some applications
would beneﬁt from a more proactive, prevention-based approach.
To this end, we construct CASU: Compromise Avoidance via
Secure Updates. CASU is an inexpensive hardware/software co-
design enforcing: (i) runtime software immutability, thus pre-
cluding any illegal software modiﬁcation, and (ii) authenticated
updates as the sole means of modifying software. In CASU, a
successful RA instance serves as a proof of successful update, and
continuous subsequent software integrity is implicit, due to the
runtime immutability guarantee. This obviates the need for RA
in between software updates and leads to unobtrusive integrity
assurance with guarantees akin to those of prior RA techniques,
with better overall performance.

I. INTRODUCTION

Over the past two decades, Internet-of-Things (IoT) devices
and Cyber-Physical Systems (CPS) have become very popular.
They are deployed in many everyday settings, including both
private (e.g., homes, ofﬁces, and factories) and public (e.g.,
cultural, entertainment, and transportation) spaces. They are
also widely used in farming, industrial, and vehicular au-
tomation. These devices often collect sensitive information
and perform safety-critical tasks. Also, in many cases, they
are both interconnected and connected to the global Internet.
They are usually implemented atop low-end microcontroller
units (MCUs) that have very stringent cost, size, and energy
constraints, and unlike their higher-end counterparts, have no
(or few) security features. It is thus not at all surprising that
these embedded devices (sensors, actuators, and hybrids) have
become attractive attack targets.

In particular, code injection attacks [1], [2], [3], [4] represent
a real and prominent threat to low-end devices. Embedded
systems software is mostly written in C, C++, or Assembly
– languages that are very prone to errors. Code injection
attacks exploit these errors to cause buffer overﬂows and inject

malicious code into the existing software or somewhere else
in the device memory.

Some previous results considered such attacks in low-end
devices and proposed security techniques such as Remote
Attestation (RA) [5], [6], [7], [8], [9], [10], as well as proofs of
remote software updates and memory erasure [11], [12], [13].
RA aims to detect compromise by authenticated measurement
of the device’s current software state. However, it has consider-
able runtime costs since it requires computing a cryptographic
function (usually, a Message Authentication Code (MAC))
over the entire software. A recent result, RATA [14], minimized
the cost of RA by measuring a constant-size memory region
that reﬂects the time of last software modiﬁcation (legal or
otherwise). RATA achieved that by introducing a hardware
security monitor that securely logs each modiﬁcation time to
that region.

Regardless of their speciﬁcs, RA techniques only detect
code modiﬁcations after the fact. They cannot prevent them
from taking place. Hence, there could be a sizeable window of
time between the initial compromise and the next RA instance
when the compromise would be detected.

To this end, the goal of this paper is to take a more proactive,
prevention-based approach to avoid potential compromise. It
constructs CASU: Compromise Avoidance via Secure Update,
which consists of two main components. First is a simple
hardware security monitor that is formally veriﬁed. It performs
two functions: (1) blocks all modiﬁcations to the speciﬁc
program memory region where the software resides, and (2)
prevents anything stored outside that region from executing.
It runs independently from (in parallel with) the MCU core,
without modifying the latter. This thwarts all code injection
attacks. However, it is unrealistic to prohibit all modiﬁcations
to program memory, since genuine software updates need to be
installed during the device’s lifetime. Otherwise, the software
could be housed in ROM or the entire device would function as
an ASIC (Application Speciﬁc Integrated Circuit). Therefore,
CASU second component is a secure remote software update
scheme.

The key beneﬁt of CASU is maintaining constant software
integrity without repeated RA measurements while allowing
genuine secure software updates. Speciﬁcally, it guarantees
that, between any two successive secure updates, device
software is immutable. However, the device liveness can be
ascertained at any time by repeating the latest update, which

 
 
 
 
 
 
essentially represents RA.
The intended contributions of CASU are:
1) A tiny formally veriﬁed hardware monitor that guarantees
benign (authorized) software immutability and prevents
the execution of any unauthorized code.

2) A scheme to enable secure software updates when autho-

rized by a trusted 3rd party.

3) An open-source CASU prototype built atop a commodity
low-end MCU to demonstrate its low cost and practicality.

II. PRELIMINARIES

A. Targeted Devices

This paper focuses on CPS/IoT sensors and actuators (or
hybrids thereof) with low computing power. These are some
of the smallest and weakest devices based on ultra-low-power
single-core MCUs with only a few KBytes of memory. Two
prominent examples are Atmel AVR ATmega [15] and TI
MSP430[16], with 8- and 16-bit CPUs respectively, typically
running at 1-16MHz clock frequencies, with ≈ 64 KBytes
of addressable memory. Figure 1 shows a typical architecture
of such an MCU. It includes a CPU core, a Direct Memory
Access (DMA) controller, and an interrupt control logic con-
nected to the memory via a bus. DMA is a hardware controller
that can read/write to memory in parallel with the core. Main
memory contains several regions: Interrupt Vector Table (IVT),
program memory (PMEM), read-only memory (ROM), data
memory (DMEM or RAM), and peripheral memory. IVT
stores pointers to the Interrupt Service Routines (ISRs), where
the execution jumps when an interrupt occurs; it also contains
the Reset Vector pointer from where the core starts to execute,
after a reboot. Application software is installed in PMEM
and it uses DMEM for its stack and heap. ROM contains
the bootloader and/or any immutable software hard-coded at
manufacturing time.

MCUs usually run software atop “bare metal” and execute
instructions in place, i.e., directly from PMEM. They have
neither memory management units (MMUs) to support virtu-
alization, nor memory protection units (MPUs) for isolating
memory regions. Therefore, privilege levels and isolation
regimes used in higher-end devices and generic trusted exe-
cution environments (e.g., ARM TrustZone [17] or Intel SGX
[18]) are not viable.
NOTE: Our initial implementation of CASU uses MSP430
MCU, a common platform for low-end embedded devices.
One important factor in this choice is the public availability of
an open-source MSP430 MCU design – OpenMSP430 [19].
Nonetheless, CASU is readily applicable to other low-end
MCUs of the same class.

B. Remote Attestation & VRASED

RA, mentioned above, allows a trusted entity (veriﬁer =
Vrf) to remotely measure current memory contents (e.g.,
software) of an untrusted embedded device (prover = Prv). RA
is usually realized as a simple challenge-response protocol:

1) Vrf sends an RA request with a challenge (Chal) to Prv.

Fig. 1: System architecture of a typical low-end MCU.

2) Prv receives the request and computes an authenticate
integrity check over its software memory region and Chal.
The memory region can be either pre-deﬁned or explicitly
speciﬁed in the RA request.
3) Prv returns the result to Vrf.
4) Vrf veriﬁes the result and decides if Prv is in a valid

state.

Although several RA techniques for low-end devices have
been proposed, only very few offer any concrete (provable) se-
curity guarantees. The latter include SIMPLE[8], VRASED [7],
and a variant of SANCUS[6]. While SIMPLE, as its name
suggests, is simple, it is a purely software-based RA technique
(meaning that no hardware modiﬁcations are needed) that only
protects against remote attacks and does not support DMA.
Whereas, SANCUS is a purely hardware-based RA technique
which, though very fast, incurs a signiﬁcant hardware cost over
the baseline MCU.

VRASED [7] is a formally veriﬁed hybrid (hardware/soft-
ware) RA design comprising veriﬁed hardware and software
sub-modules. The software sub-module, which is immutable
(stored in ROM), implements the authenticated integrity func-
tion computed over some “Attested Region” (AR) of Prv
memory (usually in PMEM). Meanwhile, its hardware com-
ponent assures that its software counterpart executes securely
and that no function of the RA secret key (K) is ever
leaked. The authenticated integrity function is realized with
a formally veriﬁed HMAC implementation from the HACL*
cryptographic library [20] used to compute:

H = HM AC(KDF (K, Chal), AR)

(1)

where KDF (K, Chal) is a one-time key derived from the

received Chal and K using a key derivation function.
NOTE: CASU uses VRASED to verify the update request
before it installs the new software on the device. Speciﬁcally,
CASU invokes VRASED to compute equation 1 on the new
software and checks whether H matches an authentication
token sent in the update request. Consequently, CASU update
veriﬁcation inherits the security properties of VRASED.

2

C. TOCTOU Attacks & TOCTOU-Security

All RA techniques share a common limitation: they yield no
information about the state of Prv software during the time
between two consecutive RA instances. Consequently, it is
impossible to detect the past presence of transient malware
that: (1) infected Prv, (2) remained active for a while, and (3)
at some later time erased itself and restored Prv software to
its “good” state. This holds as long as (1)-(3) occur between
two successive RA instances. This attack type is referred to
as Time-Of-Check Time-Of-Use (TOCTOU).

One recent technique, RATA [14], mitigates TOCTOU attacks
with a minimal additional hardware component that securely
logs the time of the last PMEM modiﬁcation to a protected
memory region called Latest Modiﬁcation Time (LMT) that
can not be modiﬁed by any software. LMT is then covered by
the RA function. Therefore, an RA response captures both the
current software state of Prv and the time of change to that
state. Furthermore, RATA minimizes the computational cost of
RA for Prv, since, instead of attesting its entire software, it
sufﬁces for Prv to attest just the LMT. This way, instead of
computing a MAC over the entire PMEM, Prv computes it
over a ﬁxed-size (32-byte) LM T region.
NOTE: In this paper, unlike RATA, CASU actively prevents
any modiﬁcation to PMEM at runtime, unless it is a securely
and causally authorized (by the trusted Vrf) software update.

III. CASU SCHEME & ASSUMPTIONS

A. Basics

Similar to the typical RA setting, CASU involves a low-end
MCU (Prv) and veriﬁer (Vrf). The latter is a trusted higher-
end device, e.g, a laptop, a smartphone, a smart home gateway,
or a device manufacturer’s back-end server. Vrf is responsible
for initiating each software update request, verifying whether
the update was successful, and keeping track of the latest
successfully conﬁrmed software update. We assume a single
Vrf for a given Prv. Also, Prv and Vrf are assumed to share
a master secret key (K) installed on Prv at manufacturing
time. Our discussion focuses on the symmetric key setting,
which is more practical for low-end MCUs. Nonetheless, the
use of public-key cryptography is possible with some cosmetic
changes to CASU, provided that Prv has sufﬁcient computing
capabilities1.

B. Secure Update Overview

At the time of its initial deployment, Vrf is assumed to
know the software state (Sold) of Prv. When Vrf later wishes
to update this software, it issues an update request, denoted
by UpdateVrf , to Prv. This request carries the new software
Snew and a fresh authentication token ATok, based on Snew.
When Prv receives an UpdateVrf , Sold invokes CASU,
which handles the update process in two steps: (1) AuthPrv
veriﬁes that ATok is a fresh and timely token that corresponds

1In case of MSP430, based on our experimental attempts, neither generating

nor even verifying public key signatures is viable.

Fig. 2: CASU Secure Update Protocol.

to Snew, and (2) if the ﬁrst step succeeds, InstallPrv replaces
Sold with Snew and generates an authenticated acknowledgment
(AAck). At this point, CASU terminates and control is given
to Snew which must send AAck to Vrf.

Upon receiving AAck, Vrf executes the VerifyVrf proce-
dure to check whether the AAck is a valid conﬁrmation for
the outstanding UpdateVrf . If no AAck is received, or if
AAck veriﬁcation fails, Vrf assumes a failed update. Figure
2 illustrates the interaction between Vrf and Prv. Protocol
details are described in Section IV below.

C. Adversary Model

We consider an adversary, Adv, that controls the entire
memory state of Prv, including PMEM (ﬂash) and DMEM
(RAM). It can attempt to write, read or execute any memory
location. It can also attempt to remotely launch code injection
attacks to modify Prv software. It may also divert the execu-
tion control-ﬂow to ignore update requests, as well as attempt
to extract any Prv secrets or forge update conﬁrmations.

Furthermore, Adv can conﬁgure DMA controllers on Prv
to read/write to any part of the memory while bypassing the
CPU. It can induce interrupts in an attempt to pause the
update procedure, modify any part of the old or new software
versions, or cause inconsistencies or race conditions. It might
also eavesdrop on, and interfere, with network trafﬁc between
Vrf and Prv, in a typical Dolev-Yao manner [21].

As common in most related work, physical attacks requiring
adversarial presence are considered out of scope. This includes
both non-invasive and invasive physical attacks. The former
describes attacks whereby Adv physically reprograms Prv
software using direct/wired interfaces, such as USB/UART,
SPI, or I2C. The latter refers to inducing hardware faults,
modifying code in ROM, extracting secrets via physical side-
channels, and tampering with hardware. Protection against
non-invasive attacks can be obtained via well-known features,
such as a secure boot. Whereas, protection against invasive
attacks can be obtained via standard tamper-resistant tech-
niques [22].

IV. CASU DESIGN

One of CASU main features is the prevention of all unau-
thorized software modiﬁcations to Prv software. As mentioned
earlier, the former can be trivially achieved by making all Prv
software read-only, or by making Prv an ASIC. However,
this precludes all benign (authorized) updates. Therefore, it

3

Fig. 3: CASU Software Execution Flow.

is essential to have a secure update mechanism. The term
“authorized” refers to software installed on Prv physically at
manufacture or deployment time, as well as each subsequent
version installed via update request by Vrf.

From Vrf perspective, CASU guarantees that, once in-
stalled, authorized software on Prv remains unchanged un-
til the next Vrf-initiated successful secure update. This is
achieved via three features:

1) Authorized Software Immutability: Except via a secure
update (implemented within CASU trusted code), autho-
rized software cannot be modiﬁed.

2) Unauthorized Software Execution Prevention: Only the
memory containing the (immutable) authorized software
is executable.

3) Secure Update: Vrf is the only entity that can authenticate
to Prv to install new software. After an update,
the
previous version of the installed software is no longer
authorized.

The ﬁrst two features are realized by a hardware module,
CASU-HW, that runs in parallel with the CPU. It monitors
a few CPU hardware signals and triggers an MCU reset if any
violation is detected. The third feature is realized by a trusted
code base (TCB), CASU-SW, that extends VRASED to authen-
ticate incoming update requests containing new software to be
installed (Snew) and an authorization token (ATok) that must be
issued by Vrf using the key K pre-shared with CASU module
within Prv. If ATok matches Snew, then CASU-SW installs
Snew on Prv and produces an authenticated AAck, attesting to
Vrf that a successful update occurred on Prv.

Figure 3 depicts CASU software execution ﬂow. After
each boot or reset, it executes authorized software that was
previously installed (either physically or via CASU Secure
Update). In this state, CASU-HW ensures software immutabil-
ity and execution prevention of anything else. However, when
an update request is received, CASU-SW must be invoked
to securely apply the update and re-conﬁgure CASU-HW to
protect the memory region where Snew is installed. Note that
the update cannot be performed without invoking CASU-SW
due to the immutability guarantee.

Table I summarizes MCU hardware signals and memory
regions relevant to CASU. Figure 4 illustrates the CASU
architecture: (1) CASU-HW prevents modiﬁcation of memory
regions in gray and prevents execution of all other memory,

Fig. 4: CASU System Architecture.

TABLE I: Notation Summary

Notation

Description

P C

Wen

Daddr

ER

EP

bEP

AT R

IV T R
SF

that

Program Counter, points to the current instruction being
executed
1-bit signal
memory
Memory address where the MCU core is currently access-
ing
1-bit signal that indicates if DMA is active

indicates if MCU core is writing to

DM Aen
DM Aaddr Memory address being accessed by DMA, when active
reset
T CR

Signal that reboots the MCU when set to logic ‘1’
Trusted Code Region, a ﬁxed ROM region storing CASU-
SW
Executable Region, a conﬁgurable memory region where
authorized software is stored; ER = [ERmin, ERmax],
where ERmin and ERmax are the boundaries of ER
Executable Pointer, a ﬁxed memory region storing current
values of ERmin and ERmax
Buffer Executable Pointer, a ﬁxed memory location used
to save the boundaries of the memory region storing new
software Snew.
Fixed memory buffer from which AuthPrv reads ATok
and also where InstallPrv outputs AAck
Reserved memory region for the MCU’s IVT
Fixed memory region where Status ﬂag is stored; Status
is used by CASU-SW for consistency.

while (2) CASU-SW resides in the ROM; it contains a boot-
loader and subroutines related to secure update. We describe
these features in detail in the rest of this section.

A. CASU-HW: Hardware Security Monitor

CASU-HW monitors P C, Wen, Daddr, DM Aen,
DM Aaddr to detect
illegal writes or execution. When a
violation is detected, CASU-HW activates the reset signal.
To simplify notation when describing CASU-HW properties,
we deﬁne the following macro:

M od M em(i) ≡ (Wen ∧ Daddr = i) ∨ (DM Aen ∧ DM Aaddr = i)

i represents a memory address. M od M em (i) is true
whenever the MCU core or the DMA is writing to i. When
representing a write within some contiguous memory region

4

Authorized Software Immutability:

[M od M em(ER, EP, SF, IV T R) ∧ (P C /∈ T CR)] → reset

Unauthorized Software Execution Prevention:

[(P C /∈ ER) ∧ (P C /∈ T CR)] → reset

Fig. 5: CASU-HW Security Properties.

(2)

(3)

(with multiple addresses) M = [Mmin, Mmax], we “abuse”
the notation as M od M em (M ). To denote that a write
has occurred within one of the multiple contiguous memory
regions, e.g., when a write happens to some address within
M1 or M2, we say M od M em (M1, M2).

1) Authorized Software Immutability: Software autho-
rized by CASU, including any ISRs, is located in the con-
tiguous memory segment ER. The pointer EP stores the
boundaries that deﬁne ER, i.e., ERmin and ERmax. CASU-
HW monitors EP to locate the currently authorized software
and enforce its rules based on this region. Write attempts to
EP are also monitored and only allowed when performed by
CASU-SW, preventing malicious changes to EP that could
misconﬁgure the deﬁnition ER, leading CASU-HW to enforce
protections based on the incorrect region. ER is conﬁgurable
to give CASU-SW ﬂexibility to change the location and size of
authorized software, instead of ﬁxing Snew to the same location
and size of Sold, as software versions vary in size. CASU-
HW also protects memory regions SF and IV T R. SF is
used during a secure update, described in Section IV-B. Since
ISRs are a part of ER, IVT must be protected to maintain
the integrity of interrupt handling during authorized software
execution.

Incidentally, Authorized Software Immutability also pro-
hibits self-modifying code, i.e., code in ER writing to ER,
to prevent code injection attacks within ER.

2) Unauthorized Software Execution Prevention: Only
authorized software (located in ER) or CASU-SW (located
in T CR) are allowed to execute on Prv. Since ER is
conﬁgurable via EP , after a secure update, CASU-SW re-
conﬁgures EP to allow execution from the new ER location.
3) CASU-HW Properties Formally: Figure 5 formalizes
the aforementioned CASU-HW security properties using pro-
portional logic. Note that these properties must hold at all
times. Equation 2 states that any modiﬁcation to ER, EP ,
SF , and IV T R– when a program other than CASU-SW
(P C /∈ T CR) is executing – causes a reset. Equation 3 states
that MCU cannot execute programs other than those in ER
and T CR. If P C points to any other memory location, the
MCU is reset.

B. CASU Secure Update

Recall (from Section III-B) that CASU Secure Update im-
plements: (UpdateVrf , VerifyVrf ) on Vrf and (AuthPrv,

InstallPrv) on Prv. At a high level, there are two ways of
implementing it on Prv.

1) Download Snew to DMEM (RAM), i.e., the stack or heap
of the current software (Sold), and invoke AuthPrv. If
it succeeds, InstallPrv overwrites ER with Snew and
updates EP . This is problematic, because,
if a reset
occurs in the middle of InstallPrv execution, then ER
containing Sold would be partially overwritten and Snew in
the DMEM would be lost as a consequence of the reset.
This would leave Prv software in a corrupted state.
2) Download Snew to PMEM (ﬂash) and invoke AuthPrv. If
AuthPrv succeeds, InstallPrv updates EP to the loca-
tion where Snew resides. This is generally safer since Snew
and Sold reside in two separate ﬂash memory regions.
If the installation is interrupted by a reset, CASU-SW
can re-invoke InstallPrv to complete the installation.
this requires Prv PMEM to be sufﬁciently
However,
large to accommodate both Snew and Sold, i.e., at least
double the size of ER. We believe that this is a realistic
assumption. The size of ﬂash memory on our targetted
devices is at least 8KB, whereas the typical binary size
is usually under 2KB.

Construction 1 shows the whole scheme. Recall that CASU-
SW is immutable (being in ROM). Its functionality is described
below.

1) UpdateVrf : Secure update requires for any software
Snew to be installed on Prv to adhere to the following for-
mat Snew := (LSnew ||VSnew ||NSnew ||BINSnew ||IV TSnew ), where
LSnew , VSnew , NSnew is the Snew header consisting of its size,
version number, and a random nonce, respectively. BINSnew
is the Snew binary in byte-code that mandatorily includes a
download and acknowledge subroutine that accepts future
update requests and replies acknowledgment message back to
Vrf. IV TSnew is the IVT of Snew that needs to be overwritten to
IV T R region so that MCU knows where to jump into the new
software when an interrupt is triggered. Another requirement is
that VSnew should always be greater than the version number of
the current (or old) software on Prv. This avoids replay attacks
that attempt to trick Prv into installing an old software version
that contains vulnerabilities. In case Vrf wishes to revert to an
older version (e.g., due to later-discovered bugs in Snew), it
must issue a brand new update request with the older-version
software, though with a new version number.

Vrf, by invoking UpdateVrf , computes ATok using equa-

tion 4 and sends (Snew, ATok) to Prv.

2) AuthPrv: When Prv receives UpdateVrf with Snew
and ATok, the current download subroutine on Sold in ER
accepts and downloads Snew to an available PMEM slot. It
then writes the pointers to Snew to bEP , buffer Executable
Pointer, in PMEM, and writes ATok to AT R. This download
subroutine should not be a part of CASU-SW, as exposing
network interfaces directly to trusted parts of the device is
in the exploitation of unknown
hazardous and may result
vulnerabilities in it,
leading to key leakage. Hence, even
though ER is untrusted, it should be the one receiving the

5

Construction 1: CASU Secure Update scheme deﬁned by [UpdateVrf , AuthPrv, InstallPrv, VerifyVrf ] is realized as follows:
– K is a symmetric key pre-shared between Vrf and Prv (protected by VRASED secure architecture);

1) UpdateVrf (Snew) → ATok:

Vrf generates a tuple T := (Snew, ATok), where Snew is the new software and ATok is the accompanying authentication token,
as follows:
a) Compiles and generates Snew:= (LSnew ||VSnew ||NSnew ||BINSnew ||IV TSnew ), where LSnew is Snew size, VSnew is Snew version
number, NSnew is a random nonce, BINSnew is Snew binary, and IV TSnew is Snew IV T , to be placed in IV T R of Prv.
b) Computes ATok using equation 4 with the second operand set to: 0||Snew, where ’0’ is the direction indicator from Vrf to

Prv.

Vrf sends T to Prv for update.
2) AuthPrv(Snew, ATok) →⊥ /(cid:62):

ATok := HM AC(K, 0||Snew)

(4)

Upon receiving a tuple T := (Snew, ATok) from Vrf, Snew is downloaded at memory region pointed to by bEP and ATok is
written to AT R. Then Prv does the following:
a) If VSnew <= VER, output ⊥ and return to ER; otherwise, proceed to the next step.
b) Computes σ using equation 5.

σ := HM AC(K, 0||bEP )

(5)

c) If σ == ATok, output (cid:62) and invoke InstallPrv; otherwise, output ⊥ and return to ER, where the current software (Sold)

resides.

3) InstallPrv(Snew) → AAck:

Upon invocation by AuthPrv, or at boot time, in case Status is equal to 1, Prv does the following:
a) Sets Status to 1 and updates EP with values in bEP .
b) Updates IV T R with IV TSnew .
c) Computes AAck using equation 6 and stores it at AT R. In equation 6 the second operand is 1||VSnew ||NSnew , where ’1’ is the

direction indicator from Prv to Vrf.

AAck := HM AC(K, 1||VSnew ||NSnew )

(6)

d) Sets Status to 0 and jumps to new ER, which is pointed to by the new value in EP .
Prv replies to Vrf with AAck indicating successful update.

4) VerifyVrf (AAck) →⊥ /(cid:62):

Upon receiving AAck from Prv, Vrf does the following:
a) Computes γ using the same equation 6.
b) If γ == AAck, outputs (cid:62); otherwise outputs ⊥.

request, because even if it fails to receive or chooses to not
call AuthPrv, then AAck is not generated/sent, which is a
clear indication to Vrf that the update was unsuccessful.

To securely verify that Snew is a valid software to be
installed on Prv, AuthPrv ﬁrst checks whether the VSnew is
greater than the one of ER, i.e., VER. If the VSnew is valid, it
invokes VRASED as a subroutine to compute σ according to
equation 5. If σ matches with ATok received from Vrf, then it
outputs (cid:62) (accept symbol) and further invokes InstallPrv to
apply the update. Otherwise, it outputs ⊥ (reject symbol) and
returns to old software at ER without computing any response
to be sent back to Vrf.

Note that CASU-SW execution is guarded by CASU-
HW (which inherits VRASED hardware properties), i.e., any
interrupts or DMA, or any attempts to access the key or any
conﬁdential data that CASU-SW generates, will be considered
as a violation and an MCU reset will be triggered immediately.
Also note that if such an abrupt reset occurs, MCU will return
to the old software, and eventually Vrf has to send a new
update request. In this new request, Vrf can use the same
version number (but with a different nonce for maintaining
freshness) because the previous update was not applied, and
thus, the version number of the current software is still old.

3) InstallPrv: Once Snew is authenticated, InstallPrv is
invoked. This is the critical step of Secure Update. It
is
responsible for updating the EP with bEP , IV T R with
IV TSnew and computing authenticated acknowledgment AAck
that is to be replied to Vrf. As mentioned in Section IV-B2, if
a reset occurs during any of these sub-steps, they have to be
repeated from the beginning. This is because, if EP is updated
and IV T R is not, vulnerabilities in old ISRs pointed to by
the old IV T can be exploited by malware. Furthermore, if
EP and IV T R are updated, yet the computation of AAck
failed, Vrf assumes that the update failed and repeats the
update request with the same version number (since EP is
updated to the new software), and AuthPrv will fail again.
Therefore, all three sub-steps must take place atomically. To
this end, CASU-SW uses a Status ﬂag SF in PMEM, which it
sets and unsets, before and after the completion of InstallPrv
sub-steps, respectively.

To handle cases when a reset is triggered during InstallPrv,
the Reset Vector in IV T R is programmed to start executing
from CASU-SW. This technique is analogous to having a
bootloader. At boot time, CASU-SW uses Status to determine
whether a reset occurred prior to the completion of InstallPrv.
If so, CASU-SW re-invokes InstallPrv from the beginning.
Finally, InstallPrv computes AAck according to equation

6

to AT R. After generating AAck, CASU-
6 and writes it
SW jumps to new ER. Now, it is the responsibility of the
acknowledge subroutine in Snew to reply to Vrf with AAck.
Acknowledgment Receipt: There are two unlikely cases
where Vrf may not receive AAck, after being generated by
InstallPrv. Firstly, AAck sent by Prv being lost or cor-
rupted in transit. In this case, upon a time-out, Vrf re-sends
UpdateVrf . Since InstallPrv stores AAck in a dedicated
region of DMEM (AT R), download in ER checks whether
the update request has the same version number as itself and
directly replies AAck to Vrf, instead of invoking AuthPrv
again. Secondly, a reset occurring after a successful update
and before AAck is sent to Vrf. In that case, AAck is lost and,
upon a timeout, Vrf needs to send a new UpdateVrf with a
new version number. The drawback of this approach is that
the same update is re-applied, wasting MCU clock cycles.
However, the latter case is very rare, and even if it occurs,
CASU-SW only takes less than a second to re-install Snew
(see Section VI-B).

Vrf can distinguish between these cases by ﬁrst re-sending
the same UpdateVrf . If there is still no response, then AAck
is most likely lost due to a reset and Vrf must send a new
UpdateVrf with a new version number.

There are other ways to mitigate the aforementioned AAck
issues. Rather than storing AAck in DMEM, it could be placed
into a reserved memory in PMEM to ensure its persistence
even if a reset occurs. Now, download can always reply with
AAck whenever it sees a duplicate request, thus eliminating
the cost of re-update. However, this approach requires an
additional write to ﬂash, which may be undesirable. Alter-
natively, we can use a Vrf-supplied timestamp instead of
a nonce in Snew and modify AuthPrv to accept duplicate
requests with a more recent timestamp. This approach does not
require any reserved memory (not even in DMEM). However,
it incurs runtime overhead every time Vrf issues a duplicate
request. Each aforementioned alternative has its own beneﬁts
and drawbacks. We leave it up to Vrf to decide which is most
suitable.

Note that none of the above can result in a DoS attack due to
multiple requests, because all UpdateVrf -s originate from a
legit Vrf and are veriﬁed by AuthPrv. Moreover, download
can check the Snew header to check if the request was already
seen, discard the rest of the packets, and simply reply stored
AAck to Vrf.

4) VerifyVrf : Finally, if all goes well, Vrf receives an
AAck and checks its validity veriﬁes using equation 6. If either
AAck is invalid, or a time-out occurs, Vrf assumes that the
update failed.

Figure 6 depicts the workﬂow of secure updates. When Prv
comes out of reset, it starts executing CASU-SW. CASU-
SW ﬁrst checks whether Status is 1, it invokes InstallPrv
to resume installation of already veriﬁed Snew located at
bEP . Otherwise, it jumps to Sold in ER. Upon receiving
UpdateVrf ,
the download routine in Sold accepts and
downloads Snew to an available memory slot in PMEM and

Fig. 6: Secue Update Workﬂow: blue and green boxes indicate
authorized and trusted execution routines, respectively.

Fig. 7: FSM of CASU-HW Veriﬁed Hardware Module.

stores this address in bEP . Sold is free to complete its pending
tasks before invoking AuthPrv in CASU-SW. Once, it invokes
CASU-SW, atomic execution of AuthPrv and InstallPrv (if
the former succeeds) begins. During InstallPrv, if a violation
is detected, Prv resets and invokes CASU-SW with Status
set to 1, thus invoking InstallPrv again. After successful
completion of InstallPrv, CASU-SW jumps to Snew in ER.
Eventually, the acknowledge in Snew replies AAck to Vrf,
and continues with its normal execution.

V. IMPLEMENTATION

A. CASU-HW Veriﬁed Hardware Module

Figure 7 presents a hardware FSM formally veriﬁed to
enforce both properties of Figure 5. It is a Mealy FSM, where
output is determined by both the current state and current
input. This FSM takes as input the signals shown in Figure 4
and produces a single one-bit output reset. If reset is 1, the
MCU core immediately resets.

There are two states in the FSM: RESET and EXEC. In
RESET, reset is 1 and remains so until the FSM leaves that
state; in other cases reset is 0. After a reset, as soon as P C
reaches 0 (execution is ready to start), the FSM transitions to
EXEC. While in EXEC, the FSM constantly checks for: (1)
modiﬁcations to ER, EP , SF , or IV T R, and (2) execution
attempts outside ER and T CR. In either case,
the FSM
transitions to RESET.

We implement the FSM using Verilog HDL and automati-
cally translate it into Symbolic Model Veriﬁer (SMV) language
using Verilog2SMV [23] tool. Finally, we use the NuSMV
Model Checker [24] to generate machine proofs showing that
the FSM adheres to the properties in Figure 5.

7

B. CASU-SW Secure Update Routine

CASU-SW implements

casu_authenticate,
casu_exit.

subroutines
casu_install,

casu_entry,
and

casu_entry is the only legal entry point to CASU-SW;
it is invoked at boot and during an update. Boot invocation is
obtained by setting the IVT reset vector to casu_entry.
casu_entry takes a boolean argument
to test whether
it was invoked at boot or by ER for an update. In the
former case, it checks Status to determine whether to in-
voke casu_install in order to resume the unﬁnished
update from the last reset. Otherwise, it calls casu_exit,
which clears the MCU registers and jumps to the binary in
ER. In the latter case, it invokes casu_authenticate.
casu_authenticate checks for the validity of the ver-
sion number of Snew at bEP and invokes VRASED soft-
ware to compute HMAC.
the measurement matches
If
ATok, casu_install is invoked; otherwise, it jumps to
casu_exit. Finally, casu_install updates EP , copies
the new IVT to IV T R, and computes and stores AAck at
AT R. It also sets/unsets Status to indicate the status of
installation to casu_entry subroutine, in case of a reset.

CASU-SW is implemented in C with a tiny TCB of ≈ 140
lines of code. It uses VRASED software, which is implemented
using a formally veriﬁed cryptographic library, HACL* [20].

VI. EVALUATION

All CASU source code and hardware veriﬁcation/proofs
are publicly available at [25]. CASU prototype is built on
OpenMSP430 [19], an open-source implementation of TI-
MSP430 [16]. We use Xilinx Vivado to synthesize an RTL
description of CASU-HW and deploy it on the Diligent Basys3
board featuring an Artix7 FPGA.

A. Hardware Overhead

Table II presents CASU hardware overhead compared to
unmodiﬁed OpenMSP430 and VRASED. Similar to prior
work [7], [26], [6], [5], we consider additional Look-Up Tables
(LUTs) and registers. Compared to VRASED, CASU only
requires 3% (99) additional LUTs and 0.3% (34) additional
registers.
Veriﬁcation Cost: CASU was veriﬁed using a Ubuntu 18.04
LTS machine running 3.2GHz with 16GB of RAM. Table II
shows veriﬁcation time and memory. CASU requires 95
additional lines of Verilog code to enforce properties in Figure
5. The veriﬁcation cost includes the veriﬁcation of VRASED
properties. The time to verify the composite design is under a
second and requires 148MB of RAM.

TABLE II: Hardware Overhead & Veriﬁcation cost.

Architecture

OpenMSP430
VRASED
CASU (+VRASED)

Hardware

LUTs
1859
1902
1958

Regs
692
724
726

Veriﬁcation
Time (s)
-
0.4
0.9

#(LTLs)
-
10
12

LoC
-
481
576

RAM (MB)
-
13.6
148

(a) Additional HW overhead (%) in
Number of Look-Up Tables

(b) Additional HW overhead (%) in
Number of Registers

Fig. 8: Hardware Overhead Comparison.

Comparison with Related Architectures: In Figure 8, we
compare CASU with other low-end MCU security architec-
tures, including VRASED [7], RATA [14], APEX [26], and
PURE [11], which provide RA-related services. However,
recall that, unlike CASU, all these other architectures are
reactive. As a superset of VRASED, CASU naturally has a
higher overhead. CASU and RATA have similar overheads,
since both monitor memory modiﬁcations. Whereas APEX and
PURE enforce additional hardware properties for generating
proofs of execution (APEX), and proofs of update, reset,
erasure (PURE); and thus, they have a higher overhead than
CASU.

B. Runtime for Secure Updates

The runtime of CASU-SW was evaluated on three sample
applications: (1) Blinking LED (250 bytes of binary size) -
toggles an LED every half a second, (2) Ultrasonic Ranger
(422 bytes) - available at [27] - computes the distance of an
obstacle from a moving object, and (3) Temperature Sensor
(734 bytes) - available at [28] - measures the temperature
of a room. In each case, we measured execution time of
casu_authenticate and casu_install – the most
time-consuming tasks dominated by HMAC computations.
Results are shown in Figure 9. casu_install runtime is
constant because it updates ﬁxed-size memory ranges (includ-
ing EP , IV T R, and SF ) and computes HMAC on a ﬁxed-
size input. Whereas, casu_authenticate scales linearly
with Snew size, over which HMAC is computed. The combined
runtime for the worst case (temperature sensor case with 734-
byte binary) is ≈ 200ms, which we consider to be reasonable,
considering that updates are infrequent.
Reserved Memory: CASU requires 32 bytes of reserved
RAM for AT R, 8 bytes of reserved PMEM for EP and bEP ,
and 1 byte of PMEM for SF . In total, it consumes 41 bytes
of additional storage.

VII. RELATED WORK

Prior related work generally falls into two categories: pas-

sive and active Roots-of-Trust (RoTs).
Passive RoTs aim to detect software compromise by pro-
ducing an unforgeable proof of Prv state to Vrf. In terms
of functionality, they implement the following services: (1)
i.e., RA [5], [6], [7], [8],
memory integrity veriﬁcation,

8

CASUVRASEDRATAAPEXPURE02468101214161820% Additional LUTsCASUVRASEDRATAAPEXPURE02468101214161820% Additional RegistersFig. 9: Runtime of CASU-SW Secure Update

[9], [10], [29], [30], [31], [32], [33], [34], [35], [36]; (2)
veriﬁcation of runtime properties, including control-ﬂow and
data-ﬂow attestation [26], [37], [38], [39], [40], [41], [42],
[43], [44]; and (3) proofs of remote software update, erasure,
and reset [11], [12], [13]. As mentioned in Section I, they are
passive in nature and do not prevent modiﬁcations. Whereas,
CASU is active and, as such, ensures software immutability
except for authorized updates. However, CASU is similar to
these RA techniques with respect to updates.
Active RoTs proactively monitor Prv behavior to prevent
(or minimize the extent of) compromises. For example, [45],
[46], [47] are architectures that guarantee execution of critical
tasks even when all other software is compromised. Simi-
larly, VERSA [48] guarantees sensor data privacy for low-
end MCUs by allowing only authorized software to access
and process sensed quantities. In contrast, CASU can be
viewed as an active RoT that focuses on software immutability,
prevention of illegal execution, and authorized updates.
Remote Over-the-Air (OTA) Updates support seamless de-
livery of software updates for IoT devices. Notably, TUF [49]
is an update delivery framework resilient to key compromises.
Uptane [50] extends TUF for supporting updates for vehicular
ECUs. However, both TUF and Uptane require relatively
heavy cryptographic operations, unsuitable for CASU-targeted
low-end devices. ASSURED [13] extends TUF to provide
a secure update framework for large-scale IoT deployments.
SCUBA [51] uses software-based attestation to identify and
patch infected software regions. However, due to the timing
assumptions of software-based attestation, it is unsuitable for
remote IoT settings. PoSE [52] and AONT [53] use proofs of
secure erasure to wipe Prv to show that its memory is fully
erased and then install new software. However, these schemes
are not fault-tolerant and can not retain previous software, in
case of reset during erasure or new update installation. Also,
an extensive discussion of various software update schemes
can be found in [54].
Formal Veriﬁcation provides increased conﬁdence about the
correctness of security techniques’ implementations. In the
space of low-end MCUs, VRASED [7] and RATA [14] are
formally veriﬁed hybrid RA architectures, where the latter one
detects TOCTOU attacks. APEX [26] and PURE [11] offer
formally veriﬁed proofs of remote software execution, and
proof of update, reset, and erasure. Similarly, CASU offers a

veriﬁed hardware module for authorized software immutability
and unauthorized execution prevention.

VIII. CONCLUSIONS

In this paper, we designed CASU, a prevention-based root-
of-trust architecture for low-end MCUs. CASU differs from
prior work by disallowing illegal software modiﬁcations rather
than detecting them. CASU also prevents execution of any
unauthorized software and supports secure software updates.
CASU is prototyped on OpenMSP430 and its hardware com-
ponent is formally veriﬁed. Experiments show that CASU
incurs quite low overhead and is thus suitable for resource-
constrained low-end IoT devices. Its entire implementation is
publicly available at [25].

REFERENCES

[1] A. Francillon and C. Castellucia, “Code injection attacks on harvard-

architecture devices,” in CCS ’08, 2008.

[2] L. Szekeres, M. Payer, T. Wei, and D. Song, “Sok: Eternal war in
memory,” in 2013 IEEE Symposium on Security and Privacy, pp. 48–62,
IEEE, 2013.

[3] C. Cowan, F. Wagle, C. Pu, S. Beattie, and J. Walpole, “Buffer overﬂows:
Attacks and defenses for the vulnerability of the decade,” in IEEE
DISCEX, IEEE, 2000.

[4] OWASP, “Owasp top ten.” https://owasp.org/www-project-top-ten/,

2021.

[5] K. Eldefrawy, G. Tsudik, A. Francillon, and D. Perito, “SMART: Secure
and minimal architecture for (establishing dynamic) root of trust,” in
NDSS, 2012.

[6] J. Noorman, J. V. Bulck, J. T. M¨uhlberg, F. Piessens, P. Maene,
B. Preneel, I. Verbauwhede, J. G¨otzfried, T. M¨uller, and F. C. Freiling,
“Sancus 2.0: A low-cost security architecture for iot devices,” ACM
Trans. Priv. Secur., vol. 20, no. 3, pp. 7:1–7:33, 2017.

[7] I. De Oliveira Nunes, K. Eldefrawy, N. Rattanavipanon, M. Steiner,
and G. Tsudik, “VRASED: A veriﬁed hardware/software co-design for
remote attestation,” in USENIX Security, 2019.

[8] M. Ammar, B. Crispo, and G. Tsudik, “Simple: A remote attestation
approach for resource-constrained iot devices,” in 2020 ACM/IEEE 11th
International Conference on Cyber-Physical Systems (ICCPS), pp. 247–
258, IEEE, 2020.

[9] F. Brasser, B. E. Mahjoub, A. Sadeghi, C. Wachsmann, and P. Koeberl,
“Tytan: tiny trust anchor for tiny devices,” in Proceedings of the 52nd
Annual Design Automation Conference, San Francisco, CA, USA, June
7-11, 2015, pp. 34:1–34:6, ACM, 2015.

[10] P. Koeberl, S. Schulz, A.-R. Sadeghi, and V. Varadharajan, “TrustLite:
A security architecture for tiny embedded devices,” in EuroSys, 2014.
[11] I. De Oliveira Nunes, K. Eldefrawy, N. Rattanavipanon, and G. Tsudik,
“Pure: Using veriﬁed remote attestation to obtain proofs of update, reset
and erasure in low-end embedded systems,” 2019.

[12] M. Ammar and B. Crispo, “Verify&revive: Secure detection and recov-
ery of compromised low-end embedded devices,” in Annual Computer
Security Applications Conference, pp. 717–732, 2020.

[13] N. Asokan, T. Nyman, N. Rattanavipanon, A.-R. Sadeghi, and G. Tsudik,
“ASSURED: Architecture for secure software update of realistic em-
bedded devices,” IEEE Transactions on Computer-Aided Design of
Integrated Circuits and Systems, vol. 37, no. 11, 2018.

[14] I. De Oliveira Nunes, S. Jakkamsetti, N. Rattanavipanon, and G. Tsudik,

“On the toctou problem in remote attestation,” CCS, 2021.

[15] “Avr atmega 1284p 8-bit microcontroller.” http://ww1.microchip.com/

downloads/en/DeviceDoc/doc8059.pdf, 2009.

[16] T.

Instruments,

“Msp430

measurement
msp430-ultra-low-power-mcus/overview.html.

mcus.”

&
ultra-low-power
http://www.ti.com/microcontrollers/

sensing

[17] Arm Ltd.,

“Arm TrustZone.”

https://www.arm.com/products/

security-on-arm/trustzone, 2018.

[18] Intel, “Intel Software Guard Extensions (Intel SGX).” https://software.

intel.com/en-us/sgx.

[19] O. Girard, “openMSP430,” 2009.

9

200300400500600700800Binary size (in bytes)20406080100120140160180200Runtime (ms)Blinking LED(250 bytes)Ultrasonic Ranger    (422 bytes) Temperature    Sensor (734 bytes)Entire Secure UpdateAuthenticate SubroutineInstall Subroutine[39] G. Dessouky, S. Zeitouni, T. Nyman, A. Paverd, L. Davi, P. Koeberl,
N. Asokan, and A.-R. Sadeghi, “Lo-fat: Low-overhead control ﬂow
attestation in hardware,” in Proceedings of the 54th Annual Design
Automation Conference 2017, p. 24, ACM, 2017.

[40] S. Zeitouni, G. Dessouky, O. Arias, D. Sullivan, A. Ibrahim, Y. Jin,
and A.-R. Sadeghi, “Atrium: Runtime attestation resilient under mem-
ory attacks,” in Proceedings of the 36th International Conference on
Computer-Aided Design, pp. 384–391, IEEE Press, 2017.

[41] Z. Sun, B. Feng, L. Lu, and S. Jha, “Oat: Attesting operation integrity of
embedded devices,” in 2020 IEEE Symposium on Security and Privacy
(SP), pp. 1433–1449, IEEE, 2020.

[42] I. De Oliveria Nunes, S. Jakkamsetti, and G. Tsudik, “Tiny-CFA:
Minimalistic control-ﬂow attestation using veriﬁed proofs of execution,”
in Design, Automation and Test in Europe Conference (DATE), 2021.

[43] I. De Oliveira Nunes, S. Jakkamsetti, and G. Tsudik, “Dialed: Data

integrity attestation for low-end embedded devices,” 2021.

[44] M. Geden and K. Rasmussen, “Hardware-assisted remote runtime at-
testation for critical embedded systems,” in 2019 17th International
Conference on Privacy, Security and Trust (PST), pp. 1–10, IEEE, 2019.
[45] M. Xu, M. Huber, Z. Sun, P. England, M. Peinado, S. Lee, A. Marochko,
D. Mattoon, R. Spiger, and S. Thom, “Dominance as a new trusted
computing primitive for the internet of things,” in 2019 IEEE Symposium
on Security and Privacy, SP 2019, San Francisco, CA, USA, May 19-23,
2019, pp. 1415–1430, IEEE, 2019.

[46] M. Huber, S. Hristozov, S. Ott, V. Sarafov, and M. Peinado, “The lazarus
effect: Healing compromised devices in the internet of small things,”
in ASIA CCS ’20: The 15th ACM Asia Conference on Computer and
Communications Security, Taipei, Taiwan, October 5-9, 2020 (H. Sun,
S. Shieh, G. Gu, and G. Ateniese, eds.), pp. 6–19, ACM, 2020.
[47] E. Aliaj, I. De Oliveira Nunes, and G. Tsudik, “GAROTA: generalized
active root-of-trust architecture,” CoRR, vol. abs/2102.07014, 2021.
[48] I. De Oliveira Nunes, S. Hwang, S. Jakkamsetti, and G. Tsudik,
“Privacy-from-birth: Protecting sensed data from malicious sensors with
VERSA,” CoRR, vol. abs/2205.02963, 2022.

[49] J. Samuel, N. Mathewson, J. Cappos, and R. Dingledine, “Survivable
key compromise in software update systems,” in Proceedings of the 17th
ACM Conference on Computer and Communications Security, p. 61–72,
Association for Computing Machinery, 2010.

[50] T. Karthik, A. Brown, S. Awwad, D. McCoy, R. Bielawski, C. Mott,
S. Lauzon, A. Weimerskirch, and J. Cappos, “Uptane: Securing software
updates for automobiles,” in International Conference on Embedded
Security in Car, pp. 1–11, 2016.

[51] A. Seshadri, M. Luk, A. Perrig, L. van Doorn, and P. Khosla, “Scuba:
Secure code update by attestation in sensor networks,” in In Proceedings
of the 5th ACM workshop on Wireless security (WiSe ’06), p. 85–94,
2006.

[52] D. Perito and G. Tsudik, “Secure code update for embedded devices via

proofs of secure erasure.,” in ESORICS, 2010.

[53] G. O. Karame and W. Li, “Secure erasure and code update in legacy
sensors,” in Trust and Trustworthy Computing, pp. 283–299, Springer
International Publishing, 2015.

[54] K. Zandberg, K. Schleiser, F. Acosta, H. Tschofenig, and E. Baccelli,
“Secure ﬁrmware updates for constrained iot devices using open stan-
dards: A reality check,” IEEE Access, pp. 71907–71920, 2019.

[20] J.-K. Zinzindohou´e, K. Bhargavan, J. Protzenko, and B. Beurdouche,
“Hacl*: A veriﬁed modern cryptographic library,” in CCS, 2017.
[21] D. Dolev and A. Yao, “On the security of public key protocols,” IEEE

Transactions on Information Theory, 1983.

[22] S. Ravi, A. Raghunathan, and S. Chakradhar, “Tamper resistance mech-

anisms for secure embedded systems,” in VLSI Design, 2004.

[23] A. Irfan, A. Cimatti, A. Griggio, M. Roveri, and R. Sebastiani, “Ver-
ilog2SMV: A tool for word-level veriﬁcation,” in Design, Automation
& Test in Europe Conference & Exhibition (DATE), 2016, 2016.
[24] A. Cimatti, E. Clarke, E. Giunchiglia, F. Giunchiglia, M. Pistore,
M. Roveri, R. Sebastiani, and A. Tacchella, “Nusmv 2: An opensource
tool for symbolic model checking,” in CAV, 2002.

[25] “CASU source code.” https://github.com/sprout-uci/CASU, 2022.
[26] I. De Oliveira Nunes, K. Eldefrawy, N. Rattanavipanon, and G. Tsudik,
“APEX: A veriﬁed architecture for proofs of execution on remote
devices under full software compromise,” in 29th USENIX Security
Symposium (USENIX Security 20), (Boston, MA), USENIX Association,
Aug. 2020.

[27] “Ultrasonic ranger code.” https://github.com/Seeed-Studio/LaunchPad

Kit/tree/master/Grove Modules/ultrasonic ranger.

sensor

[28] “Temperature

code.”
LaunchPad Kit/tree/master/Grove Modules/temp humi sensor.
[29] Trusted Computing Group., “Trusted platform module (tpm),” 2017.
[30] R. Kennell and L. H. Jamieson, “Establishing the genuinity of remote

https://github.com/Seeed-Studio/

computer systems,” in USENIX Security Symposium, 2003.

[31] A. Seshadri, A. Perrig, L. Van Doorn, and P. Khosla, “SWATT: Software-
based attestation for embedded devices,” in IEEE Symposium on Re-
search in Security and Privacy (S&P), (Oakland, California, USA),
pp. 272–282, IEEE, 2004.

[32] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. van Doorn, and P. Khosla,
“Pioneer: Verifying code integrity and enforcing untampered code exe-
cution on legacy systems,” in ACM SOSP, 2005.

[33] A. Seshadri, M. Luk, and A. Perrig, “SAKE: Software attestation for

key establishment in sensor networks,” in DCOSS, 2008.

[34] R. W. Gardner, S. Garera, and A. D. Rubin, “Detecting code alteration
by creating a temporary memory bottleneck,” IEEE TIFS, 2009.
[35] J. M. McCune, B. J. Parno, A. Perrig, M. K. Reiter, and H. Isozaki,
“Flicker: An execution infrastructure for tcb minimization,” in Pro-
ceedings of the 3rd ACM SIGOPS/EuroSys European Conference on
Computer Systems 2008, pp. 315–328, 2008.

[36] D. Schellekens, B. Wyseur, and B. Preneel, “Remote attestation on
legacy operating systems with trusted platform modules,” Science of
Computer Programming, vol. 74, no. 1, pp. 13 – 22, 2008.

[37] G. Dessouky, T. Abera, A. Ibrahim, and A.-R. Sadeghi, “Litehax:
lightweight hardware-assisted attestation of program execution,” in 2018
IEEE/ACM International Conference on Computer-Aided Design (IC-
CAD), pp. 1–8, IEEE, 2018.

[38] T. Abera, N. Asokan, L. Davi, J. Ekberg, T. Nyman, A. Paverd,
A. Sadeghi, and G. Tsudik, “C-FLAT: control-ﬂow attestation for
embedded systems software,” in Proceedings of the 2016 ACM SIGSAC
Conference on Computer and Communications Security, Vienna, Austria,
October 24-28, 2016 (E. R. Weippl, S. Katzenbeisser, C. Kruegel, A. C.
Myers, and S. Halevi, eds.), pp. 743–754, ACM, 2016.

10

