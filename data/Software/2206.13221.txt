2
2
0
2

n
u
J

4
2

]
h
p
-
t
n
a
u
q
[

1
v
1
2
2
3
1
.
6
0
2
2
:
v
i
X
r
a

Three principles of quantum computing

Yuri Ozhigov (1,2)
Moscow State University of M.V.Lomonosov,
Faculty of computational mathematiccs and cybernetics,
2. Institute of physics and technology RAS of K.A.Valiev

June 28, 2022

Abstract

The point of building a quantum computer is that it allows to model living
things with predictive power and gives the opportunity to control life.
Its
scaling means not just the improvement of the instrument part, but also,
mainly, mathematical and software tools, and our understanding of the QC
problem. The ﬁrst principle of quantum modeling is the reduction of reality
to ﬁnite-dimensional models similar to QED in optical cavities. The second
principle is a strict limitation of the so-called Feynman principle, the number of
qubits in the standard formulation of the QC. This means treating decoherence
exclusively as a limitation of the memory of a classical modeling computer,
and introducing corresponding progressive restrictions on the working area of
the Hilbert space of quantum states as the model expands. The third principle
is similarity in processes of diﬀerent nature. The quantum nature of reality
is manifested in this principle; its nature is quantum nonlocality, which is the
main property that ensures the prospects of quantum physical devices and
their radical advantage over classical ones.

1 Introduction

The quantum computer project (QC) from the original idea of R. Feynman ([1],[2])
has undergone a very signiﬁcant metamorphosis, mainly due to serious eﬀorts in
the ﬁeld of experiments with gates, as well as deepening our understanding of how
quantum theory works in the ﬁeld of complex processes.

At the end of the last century, the idea was generally accepted about the possi-
bility of unlimited scaling of QCs by increasing the number of qubits, and about the
possibility of performing unitary operations on their states according to the rules of
quantum theory, so that decoherence (deviation of real evolution from the unitary

1

 
 
 
 
 
 
law) was perceived as an annoying technical obstacle that can be overcome by er-
ror correction codes ([3]). The basis of this interpretation of decoherence was the
quantum master equation

i(cid:126) ˙ρ = [H, ρ] + iL(ρ), L(ρ) =

N −1
(cid:88)

i=1

γi(AρA+ −

1
2

{A+Aρ, ρA+A}),

(1)

on the density matrix ρ(t) of the system under consideration, in which the coher-
ence violation is represented as the inﬂuence of the environment, and this inﬂuence
enters into it in the form of decoherence factors Ai forming an orthonormal basis
of the space of Liouville operators, and their speciﬁc form does not depend on the
Hamiltonian H ([4].

However, experiments of the last 20 years have clearly shown the fallacy of such
a representation for quantum computing. The equation (1), as well as its basis - the
Schrodinger equation i(cid:126) ˙Ψ = HΨ, is suitable only for systems whose complexity is
low. They were the object of research by physicists of the 20th century, and quantum
theory was tested on them and showed excellent agreement with experiments.

Applying this theory to a quantum computer takes us beyond its applicability
as such. The fact is that the states of multi-qubit systems, which, according to
traditional quantum theory, should arise during certain types of quantum computing,
are not simple, and therefore go beyond the applicability of this theory. We are
talking about so-called fast quantum algorithms, such as Grover’s GSA algorithm
([5]). These are exactly the processes predicted by the standard quantum theory,
which in principle would be impossible to simulate on a classical computer if they
exist in reality.

In light of this, decoherence is a sign that the mathematical constructions of
quantum mechanics go beyond the scope of their applicability. And these limits
are determined by the capabilities of classical computers. Therefore, the deﬁnition
of complexity should proceed from these possibilities. Such a turn is unusual for
physics, where the concept of complexity has always been secondary compared to
general laws.

We will formulate a new approach to quantum theory suitable for its application
to complex systems, introducing gradual restrictions on the mathematical formalism
applied in it. These restrictions are already actually applied in real computations,
but it is necessary to consider them as a new formalism, and not an addition to the
standard one, because the ﬁeld of complex systems and processes dictates its own
laws.

2 Finiteness of quantum theory

Quantum mechanics does not accept inﬁnities, and therefore is not fully compatible
with mathematical analysis. This is well known: the eigenstates of the coordi-
nate and momentum operators are not normalizable, and therefore the idea of an

2

inﬁnite-dimensional Hilbert space of quantum states contradicts the Born rule - the
cornerstone principle of quantum theory. Ignoring mathematical correctness, tra-
ditionally allowed by physicists, did not bring much inconvenience in the study of
simple systems and has always been regarded as a kind of curiosity. However, this
is no longer acceptable for complex systems. When it comes to the limits of the
applicability of formalism, we must strictly follow the requirement of correctness.

So, any state space of a quantum system must be ﬁnite-dimensional. This im-
mediately makes it impossible to accurately move to the limit of dx → 0 and lowers
analytical methods to approximate ones. This technique corresponds to quantum
electrodynamics (QED), in which the divergence of the series for the amplitudes
of fundamental processes is solved by the so-called renormalization of charges and
masses, the correctness of which is proved in [6]. The charges and masses of elemen-
tary particles turn out to depend on the choice of a grain of resolution dx, which
gives this grain a physical meaning.

If there is an abstraction - a one-dimensional wave function Ψ(x) from a contin-
uous variable x, it can be made realistic if we introduce a discrete set of possible
values of the variable x = x0, x1 = x0 + dx, x2 = x0 + 2dx, ..., xN = x0 + N dx, and
then represent approximately this continuous function Ψ(x) as

Ψ(x) ≈

N −1
(cid:88)

j=0

Ψ(xj)dj(x),

(2)

where dj(x) is the characteristic function of the j-th segment [xj, xj+1],  = 0, 1, ..., N −
1 (see ﬁgure 1 upper part), the orthonormal basis of the N -dimensional the state
space will consist of vectors |j(cid:105) = dj/

dx, and λj = Ψ(xj)

dx.

√

√

So we will come to the representation of our function in the form of a ﬁnite-

dimensional state vector

|Ψ(cid:105) =

(cid:88)

j

λj|j(cid:105);

(3)

now this vector will be the most accurate representation of the real state for complex
systems, so that the continuous function |Ψ(t) will already be an approximation.
(For a wave function deﬁned on the space R2 or R3, instead of
dx, there will be
√

√

√

dx2 or

dx3, respectively)1.

The discrete form of the Fourier transform and its inverse are operators acting

1The transition from discrete to continuous recording consists in the fact that all sums are
replaced by integrals, and summation variables are replaced by integration variables. For example,
the formula (2) will turn into Ψ(x) = (cid:82)
Ψ(y)δy(x)dy where δy(x) is the limit of functions dj(x)
R

at dx → 0, so xj → y. Such a limit, of course, does not exist in mathematical analysis - among
ordinary functions, since at dx → 0 the function dj(x) will turn into a needle inﬁnitely high and
inﬁnitely thin. This is a generalized Dirac function.

3

on the basis states of an n-qubit system as follows:

QF T : |c(cid:105) → 1√
N

exp(−2πiac/N )|a(cid:105)

QF T −1 : |a(cid:105) → 1√
N

exp(2πiac/N )|c(cid:105)

(4)

N −1
(cid:80)
a=0

N −1
(cid:80)
c=0

Both of these mutually inverse operators with linear extension to the entire space

of quantum states C N will give unitary operators - Fourier and inverse to it.

For applications, it is convenient to assume that for the variable a, the number
√
N ] (Planck’s constant in the
N is the coordinate belonging to the segment [0,
a/
proper system of units can be considered as a unit). Then c/
N must be associated
with the momentum. It is natural to assume that the momentum belongs to the
N ] can move
segment [−
N (c/N − 1/2).
in both directions. Therefore, the momentum should be equal to

N /2], since a particle located on the segment [0,
√

N /2,

√

√

√

√

√

Accordingly, the discrete form of the momentum operator will be the N -dimensional

Hermitian operator
√
pdiscr = QF T −1
diagonal operator A = diag(exp(πia))a=0,1,...,N −1.
form A−1QF T −1|a(cid:105) and their eigenvalues will be the numbers
0, 1/N, ..., (N − 1)/N .

N (xdiscr − I/2)QF T = A−1QF T −1

√

N xdiscrQF T A, where the
Its eigenvectors will have the
N (a − 1/2); α =

√

Such a discrete representation was used in [7],[8] to construct a quantum algo-
rithm that simulates the unitary evolution of a multiparticle system with memory
growing linearly from the size of the system, and quadratic deceleration compared
to real time.

So, in the discrete representation, all the eigenstates of the basic operators are
normalized by one, and there are no contradictions with mathematical analysis.
Here we used the analytical technique of continuous Fourier transforms to correctly
write its discrete analog. It is not diﬃcult to show that all the useful properties
of the Fourier transform: the transition from diﬀerentiation (application of the mo-
mentum operator) to multiplication by a constant, as well as the identiﬁcation of
the hidden period of the complex exponent will be preserved during the transition
from a continuous form to a discrete one, so that we can use discrete operators in
ﬁnite-dimensional spaces in all physical problems related to the quantum theory of
complex systems.

Note that this limitation of the formalism does not yet aﬀect the amplitudes:

they can be arbitrarily small, so for now mathematical analysis is applicable.

3 Reduction of complexity by canonical transfor-

mation

The second stage of formalism restriction will already aﬀect the amplitudes. They
cannot be inﬁnitesimal because of the Born rule: we cannot introduce fully virtual

4

events into the formalism, which in no way can be made explicitly observable in an
experiment.

The physical experiment consists in choosing not the basis of the Hilbert space
of quantum states, but the order of the basic vectors |j(cid:105) in the expression (3). Each
basic vector |j(cid:105) is encoded by the binary string a0, a1, ..., an−1 of the signs of the
expansion of the approximation with an accuracy of 2−n of the physical quantity

n−1
(cid:80)
i=0

jphys = L(j), where j =

ai2i, L is some linear transformation. For example, jphys

can be the coordinate of a particle or its momentum. The order of the basic vectors
|j(cid:105) is always determined by the lexicographic ordering of strings ¯a. Thus, changing
the order of the basic vectors means replacing the bits of aj with a new system of
bits of bj.

For example, for a system of interacting harmonic oscillators with the usual
coordinates ql, we can do the Fourier transform over them, considering l as an
argument and ql as the value of the original function, so that the new coordinates
obtained by the rule

(cid:88)

Qk = A

exp(−αi lk)ql, k = 0, 1, ..., N − 1, N = 2n,

(5)

then, from the quantum theory viewpoint, this will be a permutation of the basic
vectors in the Hilbert state space, since ql and Qk are basic vectors, and the expres-
sions (5) are a point-to-point mapping, or a basic vector to the basic vector ([9]).
Such a transformation, extended to the entire space H of the quantum states of the
oscillator system, turns out to be untangling: phonons having coordinates Qk do
not get entangled when quantizing the Newtonian dynamics of the oscillator system.
This type of transformation is called canonical.

Naive deﬁnition of complexity ν(Ψ) of the quantum state |Ψ(cid:105) as the maximum
number of qubits in the entangled component of the tensor decomposition |Ψ(cid:105) =
|ψ1(cid:105)|ψ2(cid:105)...|ψs(cid:105), should be modiﬁed taking into account the possibility of a canonical
transformation reducing naive complexity. Namely, the true complexity of the |Ψ(cid:105)
state is

C(Ψ) = minτ ∈SN ν(τ Ψ)

(6)

- minimal naive complexity over all possible permutations τ of basic vectors.
Similarly, the complexity of the Hamiltonian H is determined. Its naive complex-
ity ν(H) is the maximum number of qubits in subsystems S1, S2, ..., Ss, which form a
partition of the entire system of qubits with a maximum s, such that decomposition
takes place

H = H1 ⊗ I1 + H2 ⊗ I2 + ... + Hs ⊗ Is

(7)

where Hi acts on the set of qubits Si, ß = 1, 2, ..., s. Then the true complexity
of the Hamiltonian H is deﬁned as C(H) = minτ ∈SN ν(τ −1Hτ ). The canonical
transformation τ , reduces the naive complexity of the Hamiltonian to a minimum
value.

5

It follows from the deﬁnition that if we start from the basic state |Ψ(0)(cid:105), then
in the quantum evolution induced by the Hamiltonian H, only states of complexity
not exceeding C(H) can appear. Indeed, given (7), we have

exp(−itH)|Ψ(0)(cid:105) = τ (H1 ⊗ I1 + H2 ⊗ I2 + ... + Hs ⊗ Is)τ −1|Ψ(0)(cid:105),
and considering that τ −1 is an inverse permutation of the basic, we get the required.
The simplest example of a canonical transformation into 2 qubits is the operator
CN OT , which reduces the Hamiltonian H with 4 basic states passing into each
other in pairs:







H =

.

0 1 0 1
1 0 1 0
0 1 0 1
1 0 1 0







= CN OT (σ(1)

x ⊗ I2 + I1σ(2)

x )CN OT.

The problems in which quantum physics made progress in the 20th century had -
in our deﬁnition - a small complexity. Along with the mentioned system of interact-
ing harmonic oscillators, which serves as the basis of solid state physics, the transi-
tion to the impulse-energy representation of the electromagnetic ﬁeld, which allows
mathematically accurately describe the concept of photon, the theory of superﬂu-
idity, etc. advanced models are based precisely on the canonical transformation,
which radically reduces the complexity of the problem.

Quantum computing has a very special nature. Quantum states arising during

the implementation of Grover ’s algorithm have the form

|ΨGSA(t)(cid:105) = α

(cid:88)

j(cid:54)=j0,0≤j<N

j(cid:105),
|j(cid:105) + |
¯

(8)

√

where α = cos(t)/
b = sin(t) for some t, and N = 2n has the maximal complexity n.

N − 1,

This superposition has the property that all of its basic components, with the
exception of exactly one, have the same nonzero amplitude, and this one component
has a diﬀerent amplitude.

This property is preserved for any permutation of the basic vectors, that is, for
any quasi-partial representation. But if this state was reducible, it would have the
form

λ1|i1(cid:105) + λ2|j2(cid:105) + ...) ⊗ (λ3|j3(cid:105) + λ4|j4(cid:105) + ...) for some basic |ji(cid:105), and such a super-
position cannot contain exactly 2 values of amplitudes for all basic states, because
there must either be at least 3 diﬀerent non-zero values of amplitudes, or it must
contain exactly two diﬀerent non-zero amplitudes corresponding to two groups of
basic vectors containing an equal number of elements. Both of these possibilities are
excluded for states of the form (8).

6

The complexity of this state is thus equal to n if only t (cid:54)= kπ/2 for any integer k.
This state has the maximum possible complexity of all n qubit states, and therefore
can be used as a complexity meter.

The complexity of the quantum state is the amount of memory of the quantum
processor, which is necessary to represent |Ψ(cid:105) with the possibility of classical par-
allelization. The complexity of the Hamiltonian is the required amount of memory
of a quantum processor designed to simulate the corresponding evolution, with the
possibility of classical parallelization of the computation. The complexity of this
state is thus equal to n if only t (cid:54)= kπ/2 for any integer k. This state has the
maximum possible complexity of all n qubit states, and therefore can be used as a
complexity meter.

A complex state cannot be described with the same precision as a simple one. If
the accuracy is A(Ψ) of quantum description of the state |Ψ(cid:105) we treat as the number
of independent instances of systems that are in such a state and are available for
measurement, we get a natural constraint of the form

A(Ψ)C(Ψ) ≤ Q

(9)

simply because there is a physical limit to the quantum memory available to us.
Experiments suggest that the constant Q does not exceed several tens. This constant
can be found when implementing Grover’s algorithm as the maximum number of
qubits for which this algorithm is able to work.

Given that the accuracy of determining the amplitudes of λj in the decomposition
of (3) coincides with A(Ψ), we get the "complexity - accuracy" dilemma, which is
illustrated by the ﬁgure 1. The case is shown at the bottom left when the main
part of the computational resource is occupied with accuracy: |Ψ(cid:105) = λ0|0(cid:105) + |λ1(cid:105);
if we limit the number of basic states to 2, as for a particle in a two-dimensional
potential, we get a satisfactory similarity with the experiment. Above is a case where
the computational resource is evenly distributed between accuracy and complexity;
this is the area of maximum coincidence with the experiment - a typical area of
applications of quantum mechanics, where it is correct to talk about the "wave
function". At the bottom right, the main resource is occupied by complexity: |Ψ(cid:105) =
N −1
(cid:80)
j=0
obtained in a single measurement.

ε|j(cid:105), (cid:107)ε| = 1. Our knowledge here is limited to only one basic state, which is

Thus, the modeling of complex systems at the quantum level assumes a reduction
in accuracy the greater the more complex is the system under consideration. Already
for ﬁnite-dimensional QED models ([10]) in cavities, the Hamiltonian turns out to
be irreducible, and the complexity of such models grows rapidly with their size.
Moreover, this will be true for the quantum description of chemistry.

Discarding states with a small amplitude is a technique that has always been
used in physics. In computer modeling, this technique should be modiﬁed in such a
way as to take into account the rate of amplitude growth even at very small initial

7

Figure 1: Representation of the state vector. The curves denote the hypothetical
wave function |Ψ(cid:105) predicted by the Copenhagen theory. The rectangles represent
the information about it that we can actually get.

values. The working area of the model, which is covered by the sum in the expansion
(3), cannot be too large; it should, ideally, ﬁt in the memory of a desktop computer.
However, there is a property of quantum computing that cannot be adequately

represented using classical computing tools. This is quantum nonlocality.

4 The principle of similarity

Quantum nonlocality is a subtle property of our world that gives hope for building
computer models of the living. The critical quality of such models is the ultimate
simpliﬁcation of reality. We must discard the lion’s share of the details that make
up the subject of physics, chemistry and biology in order to build such a model.

The ﬁrst principle of quantum computing is the reduction of models to ﬁnite-
dimensional ones, which means a fundamental rejection of inﬁnities in linear algebra,
while preserving the analytical apparatus.

The second principle is the radical reduction of the dimensions of such models by
means of canonical transformation, it means the rejection of mathematical analysis
as a working tool; all its achievements are encapsulated in the basic states of the
system. Moreover, the fact that ﬁnite-dimensional QED models are not reducible
using canonical transformation suggests that all such reduction has already been
done and is contained in the available ﬁnite-dimensional models. Further work
will take place as a modernization of ﬁnite-dimensional models of on a computer
programming platform.

But that’s not enough. The enormous complexity of biological objects dictates

8

the need for an even more radical simpliﬁcation of the model. We must admit the
presence of memory in the environment and evolution can no longer be considered
as Markovian. We have to abandon the density matrix, moving to a virtual pure
state, in which we need to include elements of the environment. Physically, this
means including quantum nonlocality in the model ([11],[12]).

In chemistry and biology, complex processes are traditionally described as being
controlled by classical information ﬂows. For example, signals are interpreted as
binary strings sent and received by participants of information exchange. This is
a one-sided view. The control should include quantum nonlocality - only in this
case the model will be predictive. Behind the complexity of the living is a physical
feature that distinguishes living matter from the mechanism, and this is quantum
long-range action.

The construction of such models requires reliance on the heuristics of biology,
and this heuristic consists in the similarity of processes in living and inanimate
matter. This similarity is provided by a single mathematical formalism - quantum
mechanics in the spaces of states of strongly limited dimension. This third principle
is the least developed, but it is in it that the future of quantum computing lies.

5 Conclusion

So, we cannot count on a big advance of the quantum computer project, betting
only on the expansion of its qubit memory.

Three principles: ﬁniteness, limitation of complexity by precision, and similarity
form the basis for the development of a quantum operating system designed to
simulate complex phenomena, primarily life, in its most complex manifestations.
We should not look at a quantum computer only as a nanoelectronic device that
will soon appear on our table. QC is, ﬁrst of all, a method by which we hope not just
to achieve a better understanding of complex processes, involving the quantum level
of their description for this. It is also a way of very ﬁne control of such processes,
which makes it possible to achieve the goals in a complex way, containing unexpected
and sometimes counter-intuitive moves, based, however, on a reliable foundation of
quantum physics.

This is important for the proper management of the most complex system -
human society. The quantum view of politics makes it objective and accessible to
a wide range of participants, and avoids the costs of a head-on collision, making
competition the engine of progress. This is one of the main tasks of the quantum
computer project.

6 Acknowledgements

The work was performed at the Moscow Center for Fundamental and Applied Math-
ematics.

9

References

[1] Richard P. Feynman, Simulating Physics with Computers, International Jour-

nal of Theoretical Physics, VoL 21, N 6/7, 1982, pp. 467-488.

[2] D. Deutsch, Quantum theory, the Church–Turing principle and the universal
quantum computer, Proceedings of the Royal Society of London; Series A, 1985.
vol. 400, N 1818, pp. 97—117.

[3] P.W.Shor, Scheme for reducing decoherence in quantum computer memory,

Phys. Rev. A 52, R2493(R), 1995.

[4] H. Breuer and F. Petruccione, The Theory of Open Quantum Systems, Oxford

(2002).

[5] L.Grover, A fast quantum mechanical algorithm for database search, Proceed-
ings, 28th Annual ACM Symposium on the Theory of Computing (STOC),
May 1996, pages 212-219. Proceedings, Melville, NY, 2006, vol. 810, electronic
version: xxx.lanl.gov, quant-ph/0610052.

[6] N. N. Bogolyubov, O. S. Parasyuk (1955). "Towards the theory of multiplication

of causal singular functions". DAN USSR, 100: 25.

[7] C.Zalka, Simulating quantum systems on a quantum computer, Proceedings of

The Royal Society A 454(1969):313-322, January 1998.

[8] S.Wiesner, Simulations of Many-Body Quantum Systems by a Quantum Com-

puter, arXiv:quant-ph/9603028.

[9] Mattuck, R.D., A guide to Feynman diagrams in the many-body problem, 1976,

New York : McGraw-Hill, 429 p.

[10] E.T. Jaynes, F.W. Cummings, Comparison of quantum and semiclassical radi-
ation theories with application to the beam maser, Proc. IEEE 51 (1): 89–109,
(1963). doi:10.1109/PROC.1963.1664.

[11] Aspect, Alain; Dalibard, Jean; Roger, G´erard (December 1982). "Experimental
Test of Bell’s Inequalities Using Time- Varying Analyzers". Physical Review
Letters. 49 (25): 1804–1807.

[12] Jian-Wei Pan; D. Bouwmeester; M. Daniell; H. Weinfurter; A. Zeilinger (2000).
"Experimental test of quantum nonlocality in three-photon GHZ entangle-
ment". Nature. 403 (6769): 515–519.

10

