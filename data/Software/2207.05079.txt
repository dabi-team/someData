Horizontal Federated Learning and Secure Distributed Training 
for Recommendation System with Intel SGX

Siyuan Hui 
Intel Corporation 
 Shanghai, China  
 siyuan.hui@intel.com 

Albert Hu 
 Intel Corporation 
 Shanghai, China 
 albert.hu@intel.com 

Yuqiu Zhang 
 Intel Corporation 
 Shanghai, China 
 yuqiu.zhang@intel.com 

Edmund Song 
 Intel Corporation 
 Shanghai, China 
 edmund.song@intel.com

ABSTRACT 
With the advent of big data era and the development of artificial 
intelligence  and  other  technologies,  data  security  and  privacy 
important.  Recommendation 
protection  have  become  more 
systems  have  many  applications  in  our  society,  but  the  model 
construction of recommendation systems is often inseparable from 
users'  data.  Especially  for  deep  learning-based  recommendation 
systems,  due 
the 
characteristics of deep learning itself, its training process not only 
requires long training time and abundant computational resources 
but also needs to use a large amount of user data, which poses a 
considerable  challenge  in  terms  of  data  security  and  privacy 
protection.  How  to  train  a  distributed  recommendation  system 
while ensuring data security has become an urgent problem to be 
solved. 

the  complexity  of 

the  model  and 

to 

In  this  paper,  we  implement  two  schemes,  Horizontal  Federated 
Learning  and  Secure  Distributed  Training,  based  on  Intel 
SGX(Software  Guard  Extensions)  [1],  an  implementation  of  a 
trusted  execution  environment  [2],  and  TensorFlow  framework 
[3],  to  achieve  secure,  distributed  recommendation  system-based 
learning  schemes  in  different  scenarios.  We  experiment  on  the 
classical Deep Learning Recommendation Model (DLRM), which 
is  a  neural  network-based  machine  learning  model  designed  for 
personalization and recommendation [4], and the results show that 
our  implementation  introduces  approximately  no  loss  in  model 
performance. The training speed is within acceptable limits. 

CCS CONCEPTS 

Permission to make digital or hard copies of part or all of this work for personal or 
classroom  use  is  granted  without  fee  provided  that  copies  are  not  made  or 
distributed for profit or commercial advantage and that copies bear this notice and 
the  full  citation  on  the  first  page.  Copyrights  for  third-party  components  of  this 
work must be honored. For all other uses, contact the owner/author(s). 
© 2022 Copyright held by the owner/author(s). 

• Security and privacy → Software and application security 
→Domain-specific security and privacy architectures; • 
Computing methodologies → Machine learning → Machine 
learning approaches → Neural networks. 

KEYWORDS 
Federated  Learning,  Trusted  Execution  Environment,  Deep 
Learning, Recommendation System, TensorFlow 

in 

also 

shone 

1  INTRODUCTION 
The goal of the recommendation system is to infer users' potential 
preferences and offer the most appropriate recommendation based 
on  users,  items  and  relevant  information.  The  recommendation 
system  has  a  history  of  decades.  With  the  rapid  development  of 
deep learning, recommendation systems based on this technology 
recent  years.  Deep-learning-based 
have 
recommendation  systems  such  as  DLRM  have  become  classic 
recommendation system models and have been widely used in the 
industry. 
However,  the  recommendation  system  based  on  deep  learning 
faces  some  challenges:  This  model  usually  has  humongous 
parameters,  requiring  a  large  number  of  sample  data  and  a  long 
training time. Therefore, the deep learning-based recommendation 
system  training  is  not  friendly  to  companies  or  institutions  with 
few computing resources. So, these companies may outsource the 
training  process 
institutions  with  rich  computing 
resources. If the training of the recommendation system is outside 
the  model  owner’s  company,  it  will  raise  a  problem  of  data 
security and privacy protection. Therefore, there is an urgent need 
for  a  safe  training  scheme  for  recommendation  system  in-depth 
learning. 
Secure  distributed  training  includes  a  wide  range  of  concepts, 
which  intend  to  prevent  data  leakage  to  a  certain  extent  in  the 
training  process.  Federated  learning  is  a  new  secure  distributed 
deep learning technology [5]. It mainly emphasizes that data will 
not  leave  its  owner’s  scope  in  the  training  process,  and  only 

to  other 

 
transfer gradient and other information, ensuring data security at a 
higher  level.  Horizontal  federated  learning  is  a  type  of  federated 
learning  in  which  each  participant  in  distributed  computing  has 
the same model but different training data. 
Security  and  privacy  protection  technology  is  closely  related  to 
cryptography  technologies  and  algorithms,  such  as  secure  multi-
party  computing  (MPC)  [6],  homomorphic  encryption  (HE)  [7], 
differential  privacy  (DP)  [8],  trusted  execution  environment 
(TEE).  MPC  requires  constructing  complex  communication 
schemes  with  significant  communication  overhead,  while  HE 
needs  to  consume  considerable  computing  resources  to  calculate 
the ciphertext. DP usually affects the model training performance, 
and  it  is  challenging  to  balance  the  impact  of  privacy  protection 
and training performance. Compared with other privacy protection 
computing  technologies,  TEE  has  the  advantages  of  taking 
security,  compat and performance into account at the same time. 
TEE  can  seamlessly  support  general  computing  frameworks  and 
applications, with computing performance comparable to plaintext 
computing. TEE is an essential technology in scenarios involving 
big  data,  high-performance  and  general  privacy  computing,  such 
as  secure  and 
large-scale  data 
trusted  cloud  computing, 
confidentiality  cooperation  and  in-depth  learning  of  privacy 
protection.  
Intel  introduced  SGX2  in  Xeon  [9],  designed  to  provide  user-
space  TEE  with  hardware  security  as  a  mandatory  guarantee, 
independent  of  firmware  and  software  security  status.  In  this 
paper,  the  term  SGX  specifically  means  SGX2.  The  processor 
implements  a  new  set  of  instruction  set  extensions  and  memory 
access  control  mechanisms  to  enable  isolated  operation  between 
different programs and safeguard the user's critical code and data 
from  malware.  SGX's  TCB  includes  only  hardware,  avoiding 
software-based TCB's software security vulnerabilities and greatly 
enhancing system security. 
The  SGX  instruction  set  extensions  allocate  a  portion  of  the 
protected area in memory called Enclave Page Cache (EPC). The 
data  in  the  EPC  is  encrypted by the  Memory  Encryption  Engine 
(MEE) inside the CPU. SGX allows applications to create Enclave 
containers on the EPC to run protected application code segments 
and ensure that the data therein is isolated from external software, 
including the operating system. The Enclave can prove its identity 
to remote authenticators and provide the necessary functionality to 
secure the key transfer. 

2  RELATED WORKS 
Privacy-Preserving  Recommender  Systems  have  also  seen  many 
new  advances  in  recent  years.  For  example,  Ribero  proposed  a 
differential  privacy-based  approach  to  implement  a  federal 
recommender  system  [10].  Minto  et  al.  proposed  a  practical 
federated  recommender  system  for  implicit data  under  user-level 
local differential privacy (LDP) [11]. Ben presented secure multi-
party protocols that enable several vendors to share their data in a 
privacy-preserving  manner  to  allow  more  accurate  Collaborative 
Filtering (CF) [12]. 

Federated  learning  is  now  widely  used  in  industry,  and  various 
cryptographic techniques can be used to ensure privacy security in 
different  application  scenarios.  For  example,  Google's  Gboard 
uses the federated averaging algorithm to train the data stored in 
the mobile phone, uses DP to protect the user's privacy, constructs 
a global model and pushes it back to the mobile phone to predict 
the  next  word  input  by  the  use  [13].  The  AI  Department  of 
WeBank  released  the  federated  learning  open-source  framework 
FATE  and  applied  it  to  financial  business  [14].  FATE  uses  HE 
and MPC to build the underlying security computing protocol.  It 
has currently supported a variety of machine learning algorithms 
such  as  logistic  regression  and  deep  learning.  ByteDance  has 
launched  Fedlearner,  an  open-source  framework 
that  uses 
cryptographic  techniques,  such  as  homomorphic  encryption,  to 
provide privacy protection  to  recommender  systems  like  training 
of Wide & Deep. 

3  PROBLEM DEFINITION AND 

CHALLENGES 

In this part, we mainly consider two scenarios. 
(1) Data providers often have only a portion of the data within the 
company  to  build  a  well-performed  recommendation  system 
model.  One  solution  is  to  train  the  model  among  different  data 
providers collaboratively with their own potion of data, as shown 
in Figure 1 (a). However, this raises the issue of data security. 
(2)  Some  data  providers  do  not  have  more  abundant  computing 
resources.  When  training  recommendation  systems,  they  may 
need to hand over the training task to cloud service providers with 
abundant  computing  resources,  as  shown  in  Figure  1  (b).  Issues 
like privacy leakage may arise in the process.  

(a) 

(b) 
Figure 1: Two data leakage scenarios 

 
 
 
 
 
 
 
 
• 

Platform  Integrity  -  Providing  the  Remote  Attestation 
mechanism  so  that  users  can  gain  trust  in  the  remote 
Intel SGX platform. 

We  adopt 
the  Parameter  Server  architecture  provided  by 
TensorFlow.  There  are  two  types  of  training  nodes:  parameter 
server  and  worker.  The  parameter  server  node  mainly  saves  and 
aggregates  the  parameter  information  of  the  model,  and  the 
worker  node  is  mainly  responsible  for  performing  forward 
propagation and backpropagation during the training process. 
In the training process, each worker uses local data in its Enclave 
to  complete  a  round  of  training  and  then  sends  the  gradient 
information  in  the  backpropagation  process  to  the  parameter 
server  through  the  RA-TLS  technology.  The  parameter  server 
the  gradient  aggregation  and  updates  network 
completes 
parameters. Finally, it sends the updated parameters back to each 
worker. 
The  training  phase  can  be  divided  into  the  following  steps  as 
shown in Figure 2: 

Secure Distributed Training and Horizontal Federated Learning for Recommendation system with 
Intel SGX 

4  METHOD 
In  this  section,  we  will  describe  the  three  aspects  of  privacy 
protection  we  have  adopted,  as  well  as  two  distributed  secure 
training  architectures  based  on  DLRM.  These  two  architectures 
are applied separately to whether data is allowed to leave the local 
area  or  not.  For  the privacy  leakage  problem  in  scenario  (1)  and 
scenario  (2),  our  Horizontal  Federated  Learning  solution  and 
Secure  Distributed  Training  solution  can  be  used  to  solve  the 
problem, respectively. 

 Privacy Protection with Intel SGX 

4.1 
In  our  solution,  privacy  protection  is  provided  in  the  following 
aspects: 
Runtime  security using  Intel-SGX.  The gradient information is 
stored  inside  the  Intel  SGX  Enclave  in  the  training  phase  of 
federated 
that  no 
learning.  Intel  SGX  provides  assurance 
unauthorized access or memory snooping of the Enclave occurs to 
prevent leakage of gradient and model information. 
In-Transit  security.  We  use  the  Remote  Attestation  with 
Transport  Layer  Security  (RA-TLS)  of  Intel  SGX  technology  to 
ensure  security  during 
technology 
combines TLS technology and remote attestation technology. RA-
TLS  uses  TEE  as  the  hardware  root  of  trust.  The  certificate  and 
private key are generated in the Enclave and are not stored on the 
disk.  Therefore,  participants  cannot  obtain  the  certificate  and 
private  key  in  plain  text,  preventing  the  man-in-the-middle 
attacks.  In  this  federated  learning  solution,  RA-TLS  is  used  to 
ensure the encrypted transmission of gradient information. 
Application integrity and confidentiality. To solve the problem 
of  how 
integrity,  we 
implemented  RA-TLS  enhanced  gRPC  in  TensorFlow  to  verify 
the Intel SGX Enclave. It ensures that the runtime application is a 
trusted version. 

the  untrusted  application 

transmission  [15].  This 

to  verify 

4.2  DLRM 
The  following  paper  will  demonstrate  our  horizontal  federated 
learning  and  secure  distributed  training  scheme  with  DLRM. 
DLRM  is  a  classical  neural  network-based  recommendation 
model  proposed  by  Facebook  for  social  media  and  ad  click-
through  rate  prediction.  The  model  contains  multiple  embedding 
layers  and  multi-layer-perceptrons  that  take  multiple  categorical 
and numerical data as input and give a probability output.  

4.3  Horizontal Federated Learning 
We  proposed  a  horizontal  federated  learning  solution  based  on 
Intel  SGX  technology  for  the  DLRM.  This  solution  mainly 
contains the below items: 

Figure  2:  Architecture  of  Horizontal  Federated  Learning 
based on Intel SGX 

  ①  Using  Intel  SGX  technology,  the  training  program  of  the 

participants runs in different Enclaves. 

  ② Workers calculate gradient information based on local data 

in the Enclave environment. 

  ③  Workers  send  gradient  to  parameter  server  through  RA-

TLS. 

  ④   Parameter  server  performs  gradient  aggregation  and 

•  AI  Framework  –  TensorFlow,  an  open-source  platform 

updates global model parameters in the Enclave. 

• 

for machine learning. 
Security  Isolation  LibOS  –  Gramine,  an  open-source 
project  for  Intel  SGX,  can  run  applications  with  no 
modification in Intel SGX. 

  ⑤ Parameter server sends model parameters to workers. 
  ⑥ Workers update local model parameters. 

Steps  ②-⑥  will  be  repeated  continuously  during  the  training 
process.  Since  the  workers  and  the  parameter  server  run  in  a 
and  RA-TLS 
memory-encrypted  Enclave 

environment, 

 
 
 
 
 
 
 
 
 
 
 
 
technology  guarantees  encryption  during 
solution can ensure privacy during training. 

transmission, 

this 

 Secure Distributed Training 

4.4 
We  implemented  another  secure  distributed  training  scheme, 
which  divides  the  distributed  nodes  into  three  categories: 
parameter  server,  worker,  and  chief.  The  chief  node  has  the 
information  of  the  dataset  and  model.  Before  the  training  starts, 
the node distributes the information required for training such as 
model or dataset to other nodes, as shown in Figure 3. 

Figure 3: Architecture of secure distributed training based on 
Intel SGX 

to 

and 

ensure 

security 

communication 

In  terms  of  privacy  protection,  we  also  use  RA-TLS  enhanced 
GRPC 
remote 
authentication  during  the  training  process.  All  three  distributed 
nodes  above  run  in  the  Enclave  environment  to  ensure  runtime 
security. 
The  difference between  this  scheme  and  the horizontal  federated 
learning is that the data is not stored in the worker node, but the 
chief  node  divides  the  dataset  during  training  initialization  and 
transmits it to each node through the network. This process is also 
under  the  RA-TLS  enhanced  gRPC  framework  to  ensure  secure 
transmission. 

5  EXPERIMENT 

5.1  Experiment Configuration 
In  the  experiment,  we  implement  horizontal  federated  learning 
and secure distributed training on TensorFlow and test it with the 
DLRM  model.  For  both  tests,  we  evaluate  the  training  process 
with  click-through  record  in  Kaggle  Cretio  Ad  dataset,  which 
contains  13  numerical  features  in  float32  and  26  categorical 
features  in  int32.  For  both  training,  we  selected  one  tenth  of  the 
original  dataset  as  the  training  set.  The  training  hyperparameters 
were  set  according  to  the  original  paper  [4].  To  justify  the 
correctness and efficiency of our implementation, we collect and 
compute the loss, training speed and accuracy and compare with 
non-SGX distributed training. 

The  model  is  performed  on  a  dual-socket  Intel  Ice  Lake  server 
with  1TB  DDR4  DRAM,  which  supports  Intel  SGX.  The 
TensorFlow 
for  metric 
acceleration  (AVX2,  AVX512)  [16].  We  allocate  32GB  of 
memory for each Enclave and support up to 1024 threads. 

is  optimized  with 

Intel  OneAPI 

5.2  Federated Learning Performance 
The  implementation  of  horizontal  federated  learning  is  based  on 
TensorFlow distributed  training. We  set  up one  parameter  server 
and  four  workers.  They  each  run  in  a  Docker  container 
environment. In this scenario, a worker simulates a company that 
has its own private dataset. 
Figures  4  and  5  are  the  training  losses  and  accuracy  of  native 
distributed  training  and  horizontal  federated  learning  with  Intel-
SGX. We can see that the converging speed and final accuracy are 
approximately identical.  

Figure 4: Training loss of native and HFL 

Figure 5: Training accuracy of native and HFL 

Figure  6  shows  the  training  speed  of  native  distributed  training 
and horizontal federated learning with Intel SGX. Introducing our 
federated learning scheme brings about a 2.2x overhead.  

Figure 6: Training time of native and HFL 

 
 
 
 
 
 
 
 
 
 
 
 
Secure Distributed Training and Horizontal Federated Learning for Recommendation system with 
Intel SGX 

5.3  Secure Distributed Training Performance 
We  set  up  a  chief,  a  parameter  server  and  two  workers  to 
complete  the  training.  They  each  run  in  a  separate  Docker 
container  environment  as  well.  In  this  scenario,  workers  and  ps 
can  be  placed  on  cloud  servers  with  abundant  computing 
resources, while the chief node can be placed on the data owner. 
The test is also based on the TensorFlow distributed framework. 
Figures  7  is  the  training  losses  of  native  distributed  training  and 
secure  distributed  training  with  Intel-SGX.  We  can  see  that  the 
converging speed and final accuracy are approximately identical. 

Figure 7: Training loss of native and Secure Distributed 
Training 

Figures  8  shows  the  training  speed  of  native  distributed  training 
and Secure Distributed Learning with Intel SGX. Introducing our 
federated learning scheme brings about a 1.6x overhead.  

Figure 8: Training time of native and Secure Distributed 
Training 

5.4  Experiment summary 
We  can  find  from  the  above  two  experiments  based  on different 
architectures  and  scenarios:  adopting  our  privacy-preserving 
scheme  has  almost  no  effect  on  the  training  convergence  of 
DLRM. In addition, the overhead brought by the two schemes is 
2.2x  and  1.6x,  respectively.  For  MPC,  we  did  not  find  any 
available  performance  data 
system 
implementations  (MPC  version  vs  native  version).  However, 
compared  with  HE-based  methods  [17],  [18]  and  DP-based 
methods [19], the overhead of our scheme is tolerable. 

recommendation 

for 

paper 

security 

6  CONCLUSION 
for 
This 
training  methods 
introduces 
recommendation  systems  with  Intel-SGX.  We  raised 
two 
scenarios  of  recommendation  model  training  that  face  data 
security  challenges.  To  solve  these  urgent  needs,  we  preset 
horizontal  federated  learning  and  secure  distributed  training 
schemes with Intel-SGX on the TensorFlow. To justify them, we 
established  experiments  with  the  training  of  the  DLRM  and 
evaluated  the  correctness  and  performance  of  our  method.  The 
results  prove  that  our  implementation  is  correct  in  terms  of 
training  accuracy  and  fast  compared  to  other  security  deep 
learning schemes. 

REFERENCES 
[1] 

intel. 

Johnson, S., Makaram, R., Santoni, A., & Scarlata, V. 2021. Supporting intel 
sgx  on  multi-socket  platforms.  Intel  Corporation.[Online].  Available: 
https://www. 
com/content/www/us/en/architecture-and-
technology/software-guard-extensions/supporting-sgx-on-multi-socket-
platforms. html. 
Sabt, M., Achemlal, M., & Bouabdallah, A. 2015, August. Trusted execution 
environment:  what 
IEEE 
Trustcom/BigDataSE/ISPA (Vol. 1, pp. 57-64). IEEE. 

is,  and  what 

In  2015 

is  not. 

it 

it 

[2] 

[3]  Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., ... & Zheng, 
X. 2016. TensorFlow: A System for Large-Scale Machine Learning. In 12th 
USENIX  symposium  on  operating  systems  design  and  implementation 
(OSDI 16), 265-283. 

[4]  Naumov, M., Mudigere, D., Shi, H. J. M., Huang, J., Sundaraman, N., Park, 
J.,  ...  &  Smelyanskiy,  M.  2019.  Deep  learning  recommendation  model  for 
personalization and recommendation systems. arXiv:1906.00091. 

[5]  Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. 2019. Federated 
Machine  Learning:  Concept  and  Applications.  ACM  Trans.  Intell.  Syst. 
Technol. 10, 2, Article 12 , 19 pages. https://doi.org/10.1145/3298981 
[6]  Goldreich,  O.  1998.  Secure  multi-party  computation.  Manuscript. 

[7] 

Preliminary version, 78, 110. 
Fontaine,  C.,  &  Galand,  F.  2007.  A survey  of  homomorphic  encryption  for 
nonspecialists. EURASIP Journal on Information Security, 2007, 1-10. 
[8]  Abadi,  M.,  Chu,  A.,  Goodfellow,  I.,  McMahan,  H.  B.,  Mironov,  I.,  Talwar, 
K.,  &  Zhang,  L.  2016.  Deep  learning  with  differential  privacy.  In 
Proceedings  of  the  2016  ACM  SIGSAC  conference  on  computer  and 
communications security, 308-318 

[9]  Xing,  B.  C.,  Shanahan,  M.,  &  Leslie-Hurd,  R.  2016.  Intel®  software  guard 
extensions  (Intel®  SGX)  software  support  for  dynamic  memory  allocation 
inside  an  enclave.  Proceedings  of  the  Hardware  and  Architectural  Support 
for Security and Privacy 2016, 1-9. 

[10]  Ribero, Mónica, et al. 2022. Federating recommendations using differentially 

private prototypes, Pattern Recognition 

[11]  Minto,  Lorenzo,  et  al.  2021,  Stronger  Privacy  for  Federated  Collaborative 
Implicit  Feedback,  Fifteenth  ACM  Conference  on 

Filtering  With 
Recommender Systems.  

[12]  Ben Horin, Alon, and Tamir Tassa., 2021. Privacy Preserving Collaborative 
Filtering  by  Distributed  Mediation.  Fifteenth  ACM  Conference  on 
Recommender Systems. 

[13]  VAN ESCH D, SARBAR E, LUCASSEN T, et al. 2019. Writing Across the 
World's  Languages:  Deep  Internationalization  for  Gboard,  the  Google 
Keyboard[J], arXiv:1912.01218. 

[14]  Federated  AI  Technology  Enabler  (FATE)[A/OL].  2022.WeBank  AI 

Department, .https://github.com/FederatedAI/FATE. 

[15]  Knauth, T., Steiner, M., Chakrabarti,  S., Lei, L., Xing, C., & Vij, M. 2018. 
Integrating  remote  attestation  with  transport  layer  security.  arXiv  preprint 
arXiv:1801.05863.(ra-tls) 

[16]  Intel  Crop. 

Intel  OneAPI 

online 

resources.  Retrieved 

from: 

https://www.intel.com/content/www/us/en/developer/tools/oneapi.html 
[17]  Marcano,  Néstor  J.  Hernández,  et  al.  2019.  On  fully  homomorphic 
encryption  for  privacy-preserving  deep  learning.  2019  IEEE  Globecom 
Workshops (GC Wkshps). IEEE 

[18]  Vizitiu, A., Niƫă, C. I., Puiu, A., Suciu, C., & Itu, L. M. 2020. Applying deep 
neural  networks  over  homomorphic  encrypted  medical  data.  Computational 
and mathematical methods in medicine 

[19]  Du, M., Jia, R., & Song, D. 2019. Robust anomaly detection and backdoor 
attack detection via differential privacy. arXiv preprint arXiv:1911.07116. 

 
 
 
 
 
 
