Springer Nature 2021 LATEX template

2
2
0
2

n
u
J

7
2

]
E
S
.
s
c
[

1
v
4
0
2
3
1
.
6
0
2
2
:
v
i
X
r
a

A Model-Based Approach for Specifying
Changes in Replications of Empirical Studies
in Computer Science

Margarita Cruz1,2*, Beatriz Bern´ardez1,2, Amador
Dur´an1,2, Cathy Guevara-Vega3 and Antonio Ruiz-Cort´es1,2

1I3US Institute, Universidad de Sevilla, Sevilla, Spain.
2SCORE Lab, Universidad de Sevilla, Sevilla, Spain.
3eCIER Research Group, Universidad T´ecnica del Norte, Ibarra,
Ecuador.

*Corresponding author(s). E-mail(s): cruz@us.es;
Contributing authors: beat@us.es; amador@us.es;
cguevara@utn.edu.ec; aruiz@us.es;

Abstract

Context: The need of replicating empirical studies in Computer Science
is widely recognized among the research community as a means to con-
solidate the acquired knowledge from previous studies and generalizing re-
sults. It is essential to report the changes in the settings of each replication
to promote not only the comprehensibility of the evolution of the exper-
imental validity of an original study across a family of studies, but also
the lack of proposals for the systematic
replicability itself. Unfortunately,
reporting of changes in replication undermines these desirable objectives.
Objective. The main goal of the work presented in this article is to provide re-
searchers in Computer Science, and in other areas of research when appropriate,
with a systematic, tool-supported approach for the speciﬁcation and reporting of
changes in the replications of their empirical studies. Method: Applying Design
Science Research, once the problem was identiﬁed, we have developed and val-
idated a composite artifact consisting of (i) a metamodel that formalizes all the
relevant concepts related to replications and their changes; (ii) templates and lin-
guistic patterns that facilitates the reporting of those relevant concepts; and (iii) a
proof-of-concept model-based software tool that supports the proposed approach.
For its validation, we have carried out a multiple case study including 9 families
of empirical studies not only from Computer Science, but also from an area as

1

 
 
 
 
 
 
Springer Nature 2021 LATEX template

2

A Model-Based Approach for Specifying Changes in Replications

different as Agrobiology, in order to check the external validity of our approach
when applied to research areas for which it was not initially designed. The 9 fam-
ilies encompass 23 replication studies and a total of 92 replication changes, for
which we have analyzed the suitability of our proposal. Results: The multiple
case study revealed some initial limitations of our approach, such as shortcom-
ings related to threats to experimental validity or context variables. After several
improvement iterations on the artifact, all the 92 replication changes could be
properly speciﬁed, including also their qualitatively estimated effects on the dif-
ferent types of experimental validity across the entire family of experiments and
its corresponding visualization. Conclusions: Our proposal for the speciﬁcation
of replication changes seems to ﬁt the needs not only of replications in Com-
puter Science, but also in other research areas. Nevertheless, further research is
needed to improve it and to disseminate its use among the research community.

Keywords: Replication changes, Templates, Linguistic patterns, Families of experiments,
Threats to validity

1 Introduction

As in most research areas, empirical studies, especially controlled experiments, can
be used in Computer Science to rigorously evaluate technologies, methods, and tools
and help guide further research by revealing existing problems and difﬁculties [17].
However, for their results to be generalizable, reported experiments must be repli-
cated in different contexts, at different times, and under different conditions [15] by
means of so-called families of experiments.1 As Basili et al introduced in 1999 [8], a
family of experiments consists of a baseline or original study, followed up by a set
of replications that answer the same research questions as the original study. Later,
Santos et al in 2018 [57], proposed the following premises to consider a series of ex-
periments as a family, namely: (i) access to the raw data is guaranteed; (ii) researchers
know the exact setup of each experiment; and (iii) at least three experiments evaluate
the effects of at least two different technologies (or methods or tools) on the same
response variable. Nowadays, it is widely accepted in the research community that
the knowledge obtained from a family of experiments is more robust and reliable
than that obtained from a single isolated experiment, the results of which can only be
considered as preliminary [64, 68].

Let us consider for a moment a novice researcher in Computer Science who de-
cides to replicate an original study or a previous replication of an original study.
According to Carver [16], she needs to carefully review the entire family of previous
studies, in order to acquire the necessary knowledge to properly adapt the experimen-
tal settings, improve its design—if possible—to increase its experimental validity, or
avoid making the same mistakes than in previous studies. To alleviate this situation,
several initiatives have recently emerged, the most relevant being Open Science [43],

1The concept of family of experiments can be understood as an specialization of the more general concept of family of
empirical studies. Since experiments are the most common type of empirical study in Computer Science and its related
disciplines, in this article we will use mainly the term family of experiments, but most of the proposal is also applicable to
other types of replicable empirical studies such as, for example, case studies or surveys.

Springer Nature 2021 LATEX template

A Model-Based Approach for Specifying Changes in Replications

3

which promulgates that making available the datasets, the analyses, and a preprint
version of an experiment and its related software, provides valuable knowledge al-
lowing not only that any interested party may audit it, but also that others build
directly upon the previous work through reuse and repurposing [5].

A complementary approach to increase the visibility and reproducibility of em-
pirical studies in Computer Science is promoting the availability of artifacts such
as laboratory or replication packages [8, 66]. According to [64], replication pack-
ages should include not only datasets, analyses, and experimental material, but also
guidelines to conduct a replication and a summary of the evolution of the experiment
across the family [67], promoting traceability among replications.

Despite all these efforts, Shepperd et al [62] stated that although there is a con-
sensus on replications being essential to consolidate the ﬁndings of empirical studies,
there is a need for better reporting of both original and replicated studies. To report
a replication of a controlled experiment, Computer Science researchers usually use
as a reference some seminal works such as those by Wohlin et al [72], Jedlitschka
et al [33], or Juristo and Moreno [35], complementing them with Carver’s replica-
tions guidelines [16]. The recommendations in the aforementioned works are meant
for controlled experiments in general, but not for the speciﬁcation of the changes
that often arise during replications to address threats to experimental validity and,
therefore, improve the original study and the validity of its results [14].

To the best of our knowledge, there is a lack of speciﬁc proposals to specify the
changes introduced between replications of the same family of experiments. In this
situation, researchers choose either to report the experimental setting of the replica-
tion without highlighting the changes from the original study or previous replications
[24, 31, 44, 58], or they report the changes in an ad-hoc manner, describing them in
narrative text [1, 4, 49, 50]. This lack of detail in the speciﬁcation of changes leads to
some problems in carrying out new replications, since the replicator has difﬁculties
not only in deciding which aspects of the experimental setup are best suited to the new
environment, but also in avoiding mistakes made in previous experiments that threat-
ened their validity [5, 16]. On the other hand, a proper knowledge of the changes
allows a better meta–analysis of the family, since they impact on issues such as the
deﬁnition of moderator variables, the deﬁnition of the aggregated family design, or
the choice of the most appropriate analysis, among others [10].

The proposal described in this article aims to specify replication changes in a
structured, systematic way, identifying aspects such as the rationale for each change
or its effect on experimental validity, which can be quantiﬁed and used to visualize
the evolution of the entire family of experiments, thus supporting decision mak-
ing for new replications [16]. By specifying changes explicitly, our proposal helps
to decrease not only the so-called tacit knowledge [63], but also experimenter bias
[59], that occurs when replicators have to interact with the original experimenters to
request missing information about the family, speciﬁcally their changes.

In this work, we focus on the speciﬁcations of replications and their correspond-
ing changes of empirical studies in general and controlled experiments in particular.
For that purpose, we have adopted Design Science Research (DSR) as our research

Springer Nature 2021 LATEX template

4

A Model-Based Approach for Specifying Changes in Replications

methodology, creating and evaluating an artifact that is designed to solve an iden-
tiﬁed problem [70]. In our case, the developed artifact consists of (i) a metamodel
developed by an iterative and incremental process that represents the relevant con-
cepts about replications and their changes; (ii) templates for reporting the information
included in the metamodel, thus promoting reusability, avoiding redundancies, and
tracing the effects of changes on experimental validity across the family of experi-
ments; and, (iii) CÆSAR, a proof-of-concept model-driven software tool developed
to provide an initial evaluation and support for our proposal, including the afore-
mentioned templates and the automatic visualization of the effect of the changes on
experimental validity across the family of experiments.

The rest of the paper is organized as follows. Section 2 summarizes a brief state-
of-the-art on families of experiments, replications, and changes in Computer Science.
Section 3 presents the three components of the developed artifact, i.e. the metamodel,
the templates, and the tool support. Section 4 reports a multiple case study carried
out to evaluate the artifact, encompassing 9 families of experiments from Computer
Science and Agrobiology. Related work is commented in Section 5 and, ﬁnally,
concluding remarks and future work are presented in Section 6.

2 Background

According to [2], a replication can be deﬁned as the repetition of an experiment,
either as closely following the original experiment as possible, or with deliberate
changes to the original experiment’s settings, in order to achieve, or ensure, greater
validity in the carried out research. Despite the importance of replications, and al-
though their practice has increased in recent years [18, 20], the number of replications
in Computer Science in general, and in Software Engineering in particular, remains
low [67]. Among the causes inﬂuencing this situation are (i) the tacit knowledge
not explicit in replication reports [63]; (ii) the lack or incompleteness of laboratory
packages [67]; (iii) the lack of agreement on common terminology and criteria for
reporting replications [16]; and, last but not least, (iv) the effort and resources needed
to carry out an experiment [20].

Several taxonomies have been proposed to classify the different types of repli-
cations. There is a wide agreement to use the term internal replication for those
replications carried out by the same experimenters at the same site than the origi-
nal study, whereas external replication is used when the experimental team and site
are different from the original ones. With respect to the process to carry out a family
of experiments, once the original experiment concludes, it is advisable to carry out
internal replications to conﬁrm preliminary results and adjust experimental settings.
Then, external replications can be carried out for generalizing the provisional results
from internal replications [13].

Nevertheless, there is a lack of agreement in the used terminology in other
replication taxonomies. For example, according to the degree to which the original
experiment protocol is followed, Shull et al [64] classify replications as exact and
conceptual, but Juristo and Vegas [38] use closed and differentiated instead. Basili
et al refer to strict replications when the original study is duplicated as accurately as

Springer Nature 2021 LATEX template

A Model-Based Approach for Specifying Changes in Replications

5

possible [8], whereas G´omez et al [28], classify them as literal, operational and con-
ceptual depending on the changes carried out and their purpose. Other taxonomies
such as those proposed in [2] and [6] use some of the terms commented above.
In [42], de Magalh˜aes et al compare different taxonomies, concluding that any at-
tempt to establish a replication typology must be done with care since, as stated in
[27], there are authors who use the same term for different types of replications and
conversely, use different terms to refer to the same type of replication.

In our opinion, the main underlying concept behind the different proposed tax-
onomies are the changes between the original study and its replications. In particular,
in human-oriented experiments such as those common in Software Engineering, each
change in the experimental settings, even if the protocol of the original experiment
is followed, can eventually produce different results [23]. As a consequence, speci-
fying the changes and their motivation allows the comparison of results and increase
knowledge by analyzing the conditions under which the results were obtained, thus
encouraging further replication.

Last but not less important, and although several authors [16, 62] have reported
their relevance, only a few replications report their related changes when published.
When included, changes are reported in narrative text, e.g. [1, 32, 60], or in a simple,
non-standard tabular form, with one row per change including a few properties only,
such as elements affected by the change (population, experimental design, etc.) or
the situation after the change, e.g. [4, 49, 50].

3 Model-based proposal for specifying replication

changes

In this section, the model-based proposal for the speciﬁcation of replication changes
in empirical studies, encompassing a metamodel, some templates, and a proof–of–
concept software tool, is presented.

3.1 Metamodel for Replication Changes

Figure 1 shows the proposed metamodel for replication changes using a UML class
diagram. As can be seen, the classes at the top model the necessary context informa-
tion for understanding replication changes, whereas the classes at the bottom model
the structure and properties of the changes themselves. The enumerations on the right
of the diagram correspond to the categorical domains of some class attributes.

With respect to the replication context, two types of empirical studies are consid-
ered, original studies and replications. Both of them are identiﬁed by an acronym,
take place in a given site at a given date, and usually have a report that can be
accessed using a URL. In the case of original studies, a speciﬁcation of their goal—
that should include at least the cause and effect constructs and the population under
study, for example using a well-known template such as GQM [7]—and their de-
scription are also included, since they are supposed to be shared by its replications,
thus providing a context which is needed for understanding related replications and
their changes. For replications, their type (internal, external), their purposes (conﬁrm
results, generalize results, or overcome limitations), and their changes are recorded

Springer Nature 2021 LATEX template

6

A Model-Based Approach for Specifying Changes in Replications

Figure 1: Metamodel for replication changes (UML class diagram)

together with their base study, i.e. the study they replicate, which can be an original
study or a previous replication, as modeled by the abstract superclass EmpiricalStudy.
Regarding replication changes, they are identiﬁed by a descriptive name and must
describe narratively what changes from the base study (base situation) to the repli-
cation (replication situation). The purpose of the changes must also be recorded, as
well as their impacts (if any) on experimental validity (modeled by the ChangeIm-
pact class), following the validity taxonomy described by Wohlin et al in [72] and
modeled by the Validity enumeration. For each impact of a change, its rationale, i.e.
why the change affects a given validity type, must be recorded together with its effect,
using a 7-point linear scale modeled by the Effect enumeration. Note that associat-
ing a value in an linear scale from substantially (-3), moderately (-2), and slightly
(-1) decreases to their positive counterparts, including a does not affect (0) central
point, allows to have an idea on how the changes in the different experiments in a
family increase or decrease original study’s experimental validity and it can be easily
visualized graphically, as it will be shown in Section 3.3.

3.1.1 Change Dimensions

For classifying the different types of changes in replications, we have followed and
expanded the dimensions for experimental conﬁguration proposed by G´omez et al in
[28], resulting in the classiﬁcation described below.

acronym : IDsite : Stringdate : Datereport: URLcomments : Text [0..1]EmpiricalStudyacronym : IDsite : Stringdate : Datereport: URLcomments : Text [0..1]EmpiricalStudyacronym : IDsite : Stringdate : Datereport: URLcomments : Text [0..1]EmpiricalStudygoal : Textdescription : TextOriginalStudygoal : Textdescription : TextOriginalStudygoal : Textdescription : TextOriginalStudytype : enum { internal, external }purpose : Purpose [1..*]Replicationtype : enum { internal, external }purpose : Purpose [1..*]Replicationtype : enum { internal, external }purpose : Purpose [1..*]ReplicationisReplicatedBybase1*confirm_resultsgeneralize_resultsovercome_limitationsPurpose<<enumeration>>confirm_resultsgeneralize_resultsovercome_limitationsPurpose<<enumeration>>confirm_resultsgeneralize_resultsovercome_limitationsPurpose<<enumeration>>name : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Change*validity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpactvalidity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpactvalidity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpact*construct_validityinternal_validityexternal_validityconclusion_validityValidity<<enumeration>>construct_validityinternal_validityexternal_validityconclusion_validityValidity<<enumeration>>construct_validityinternal_validityexternal_validityconclusion_validityValidity<<enumeration>>affected_element : StringContextChangeaffected_element : StringContextChangeaffected_element : StringContextChangeaffected_element : OperationalizationElementOperationalizationChangeaffected_element : OperationalizationElementOperationalizationChangeaffected_element : OperationalizationElementOperationalizationChangeaffected_element : StringPopulationChangeaffected_element : StringPopulationChangeaffected_element : StringPopulationChangetreatmentmetricsmeasurement_proceduresOperationalizationElement<<enumeration>>treatmentmetricsmeasurement_proceduresOperationalizationElement<<enumeration>>treatmentmetricsmeasurement_proceduresOperationalizationElement<<enumeration>>affected_element : ProtocolElementProtocolChangeaffected_element : ProtocolElementProtocolChangeaffected_element : ProtocolElementProtocolChangeaffected_element : ExperimenterRoleExperimenterChangeaffected_element : ExperimenterRoleExperimenterChangeaffected_element : ExperimenterRoleExperimenterChangeexperimental_designexperimental_materialexperimental_guidesmeasurement_instrumentsdata_analysis_techniquesProtocolElement<<enumeration>>experimental_designexperimental_materialexperimental_guidesmeasurement_instrumentsdata_analysis_techniquesProtocolElement<<enumeration>>experimental_designexperimental_materialexperimental_guidesmeasurement_instrumentsdata_analysis_techniquesProtocolElement<<enumeration>>substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>replication contextchange specificationdesignertrainermonitormeasureranalystExperimenterRole<<enumeration>>designertrainermonitormeasureranalystExperimenterRole<<enumeration>>designertrainermonitormeasureranalystExperimenterRole<<enumeration>>Springer Nature 2021 LATEX template

A Model-Based Approach for Specifying Changes in Replications

7

Operationalization change In a controlled experiment, the cause construct is opera-
tionalized as one or more treatments, whereas the effect construct is operationalized
as one or more metrics, which are measured following measurement procedures. Any
change related to any of the above items (modeled as the OperationalizationElement
enumeration), e.g. changing the duration of a treatment, should be an instance of the
OperationalizationChange class.

Population change This class encompasses any change related to the experimental
subjects or objects, e.g. changing the experience level or the average age of the
experimental subjects with respect to those in the base study.

Protocol change As deﬁned by Juristo and G´omez in [34], the experimental pro-
tocol is the setup of the experimental design, experimental material, experimental
guides, measuring instruments, and data analysis techniques, which are the ele-
ments modeled by the ProtocolElement enumeration in our metamodel. Any change
affecting one of those elements, such as changing the tasks that subjects have to
perform or using Bayesian instead of frequentist statistics, should be an instance of
the ProtocolChange class.

Experimenter change These are changes related to the experimenters and their
roles in the replication when compared to the base study. As modeled by the Ex-
perimenterRole enumeration, the roles considered are designer, trainer, monitor,
measurer and analyst.

Context change This class, not present in [28], models any change related to the
context in which the replication is carried out compared to the context in which the
base study took place. For example, in human-oriented experiments using students
as subjects, changing the time of year when the study is conducted from before ﬁnal
exams to after ﬁnal exams is a change of this kind. In technology-oriented experi-
ments, moving from running the software on a real machine to running it on a virtual
machine would also be a context change.

3.2 Templates for Replications Changes

Templates have been successfully applied in Computer Science, Software Engineer-
ing, and related areas. For example, the well-known GQM template proposed in 1994
by Basili et al [7], the Wieringa’s proposal for the speciﬁcation of the problem un-
der study in DSR, and many others, including templates for requirements [21, 22],
process performance indicators [51, 52], or metamorphic testing relations [61].

Templates help visualizing information in a standard form, which can be easily
adopted by practitioners, especially by novice researchers. In order to improve its
usability, we have augmented templates with linguistic patterns (L-patterns) when
possible, in a similar manner than in [21, 22, 51, 52]. L-patterns are pre–written,
parametrized sentences that can be used for ﬁlling in some template ﬁelds in a easier,

Springer Nature 2021 LATEX template

8

A Model-Based Approach for Specifying Changes in Replications

Replication

<repl. acronym> (<report URL>)
{ Internal | External } replication based on <base acronym>
{ original study | previous replication }

Original Study

Goal: { <GQM> | <goal - cause, eﬀect, population> }
Description: <description>

Site and Date

The base experiment was carried out at <site> in <date>
This replication was carried out at <site> in <date>

Purposes

{ • Conﬁrm results
| • Generalize results
| • Overcome limitations of previous studies }+

Comments

[<comments>]

Figure 2: Template for replication context information

Change #<i>

<name> (<repl. acronym>)

Description

Originally, <situation in base experiment>.
In this replication, <situation in replication>.
With the purpose of <change purpose>

Dimension

{ Operationalization, speciﬁcally, the

{ treatments | metrics | measurement procedures }

| Population, speciﬁcally, the <population property >
| Protocol, speciﬁcally, the

{ experimental design | experimental material
| experimental guides | measuring instruments
| data analysis techniques }

| Experimenter, speciﬁcally, the role of

{ designer | analyst | trainer | monitor | measurer }

| Context, speciﬁcally, the <context variable> }

Eﬀects on
Validity

{ • This change

{ { substantially (3) | moderately (2) | slightly (1) }

{ increases (+) | decreases (−) }

| does not aﬀect (0) }
<validity type> because <rationale>

}+

Comments

[<comments>]

Figure 3: Template for replication changes (one for each change in the replication)

standard way. Driven by the metamodel in Figure 1, our proposal includes two tem-
plates, one for the replication context shown in Figure 2, and another for replication
changes shown in Figure 3.

In the notation used in the templates in Figures 2 and 3, placeholders are depicted
between angle brackets (<. . .>), single options are enclosed by curly brackets and
separated by vertical bars ({. . . |. . . }), multiple options are indicated by a plus symbol
after the closing bracket ({. . . |. . . }+), and elements in square brackets ([. . .]) are
considered as optional.

Springer Nature 2021 LATEX template

A Model-Based Approach for Specifying Changes in Replications

9

3.3 Proof-of-concept Software Tool: CÆSAR

Applying a model-driven development approach, we have built a proof-of-concept
tool called CÆSAR (ChAngE SpeciﬁcAtion for Replications) using the Grails frame-
work (https://grails.org/) and the metamodel described in Section 3.1. CÆSAR is
deployed for demonstration at https://caesarus.herokuapp.com?lang=en, providing a
simple interface for manipulating instances of the entities in the metamodel and dis-
playing their information using the templates described in the previous section, as
shown in Figures 4 and 5.

As can be seen in Figure 4, the context template for replications have been aug-
mented with information corresponding to the effects of their changes—expressed in
a 7-point linear scale from -3 to +3 as commented in Section 3.1—on the four types
of experimental validity proposed in [72], which can be used by experimenters when
reporting their replications according to their preferences.

Figure 4: Example of context template in CÆSAR for the replication reported in [11]

Figure 5: Example of change template in CÆSAR for one of the changes in [11]

Springer Nature 2021 LATEX template

10

A Model-Based Approach for Specifying Changes in Replications

Apart from validating the metamodel displayed in Figure 1 and adding computed
information to the templates, the main added value of building this tool is the pos-
sibility of visualizing the evolution of the experimental validity along a family of
experiments. For that purpose, a template for original studies has also been devel-
oped into the tool in which all the studies in an associated family of experiments are
queried and the effects of their changes are displayed accumulatively from the origi-
nal study—for which all types of validity are assumed to start at zero—as a line graph
for the four aforementioned types of experimental validity, as shown in Figures 6 and
7.

This kind of visualization provides a valuable information about a family of
experiments that is not usually reported and that can drive changes in new replica-
tions. For example, note how in the case of the family of experiments described in
[3] and displayed in Figure 6, three types of experimental validity increase along
time—especially internal validity—whereas in the family described in [36, 39, 40]
and displayed in Figure 7, internal validity substantially decrease, mainly because of
the lack of resources in follow-up replications, as commented later in Section 4.1.1.
In the latter case, the graph clearly indicates that experimenters carrying out a new
replication should try to increase internal validity whenever possible.

Figure 6: Validity evolution for the family of experiments described in [3]

Springer Nature 2021 LATEX template

A Model-Based Approach for Specifying Changes in Replications

11

Figure 7: Validity evolution for the family of experiments described in [36, 39, 40]

CÆSAR has been successfully used in the validation of our proposal, which is

discussed in the next section.

4 Multiple Case Study for Artifact Evaluation

As commented in [72], experiments in Computer Science may be classiﬁed as
human-oriented or technology-oriented depending mainly on the nature of exper-
imental subjects. In order to evaluate the suitability of our artifact, we conducted
a multiple case study involving both human and technology-oriented families of
experiments in Computer Science.

Since we had the opportunity to meet experimenters from a different discipline,
Agrobiology, we decided to include some families of experiments from that dis-
cipline in the multiple case study with a twofold purpose. On one hand, to check
whether our artifact could also be applied to a completely different type of experi-
ments, using plants as subjects, which somehow have some common characteristics
not only to human-oriented experiments, but also to technology-oriented ones. On
the other hand, to identify reported information that could be incorporated into the
templates and thus improve them.

The research method followed for such evaluation was based on the case study
research process proposed by Runeson et al in [54, 55]. An overview of the phases of
the multiple case study, which are detailed in the next sections, is depicted in Figure 8.

Springer Nature 2021 LATEX template

12

A Model-Based Approach for Specifying Changes in Replications

Figure 8: Phases of the multiple case study for artifact evaluation

4.1 Design and Data Collection

In the design phase, those families of experiments to evaluate our proposal were
selected applying the criteria of having a relevant number of replications and changes
in order to cover as many different options in the proposed templates as possible and
to answer the following research questions (RQs):

RQ1 (Expressiveness) Can the proposed templates be used to specify reported repli-
cation changes properly? Do they need to be augmented to include more reported
information? Is the usually reported information sufﬁcient to specify all the informa-
tion included in the templates? Are they suitable for disciplines other than Computer
Science?

RQ2 (Usability) Do researchers ﬁnd the proposed templates useful? Do they ﬁnd
them easy to use? Is the terminology used understood by researchers outside
Computer Science community?

For each case study, a brief description of the selected families, the followed pro-
tocol, and the collected data is presented below. Note that the collected data, i.e. the
speciﬁcations of all the selected replication studies and their changes using a LATEX
version of the proposed templates, is publicly available at Zenodo [19], although
the meeting minutes are not included for the sake of the privacy of the participant
researchers.

4.1.1 Human-Oriented Case (HOE–Case)

For this ﬁrst case study, we selected three families of human-oriented experiments
dealing with (i) the effect of mindfulness on conceptual modeling performance
(Mind) [9–11], (ii) requirements elicitation (Req) [3], and (iii) code testing tech-
niques (Test) [36, 39, 40], due to our familiarity with these topics. This case study

Define goal· RQ1: Expressiveness· RQ2: UsabilityData collection and analysis protocol· Select participants· Meeting protocolCase selection· Human-oriented case (HOE)· Technology-oriented case (TOE)· Agrobiology caseDevelop theoryTemplates & patternsDesignConduct & report HOE-Case· Templates filled in from published studies· Use of archival data· Expresiveness limitations detectedData collectionConduct & report Agrobio-Case· Templates filled in by replication authors· Semi-structured meetings· Use of archival data· Use of the CÆSAR tool· Terminology reviewConduct & report TOE-Case· Templates validated by replication authors· Use of archival data· Terminology reviewDraw cross-case conclusions· Analyze each case· Compare findingsModify theory· Add site and date· Add description· Add acronym· Replication on replication· Modify validity effects· Add context dimensionWrite cross-case report· Answer RQs· Analysis of terminologyAnalysis and reportSpringer Nature 2021 LATEX template

A Model-Based Approach for Specifying Changes in Replications

13

was designed as a self–evaluation case study, so all the replications and changes were
speciﬁed by ourselves after a close reading of the corresponding reports. All the lim-
itations and issues found were registered for further analysis and potential artifact
improvement.

4.1.2 Technology-Oriented Case (TOE–Case)

To evaluate our proposal with other types of Computer Science experiments where
the subjects are not human beings, two families of experiments on automated soft-
ware testing (Testing) [47], and software product line testing (SPL) [56] were also
selected at suggestion of the researchers who accepted to participate and to whom
we had direct access. In this case study, the selected replication changes were also
speciﬁed by ourselves, but then several meetings were held with the researchers who
carried out the experiments to validate our speciﬁcations and obtain feedback from
them, recording the valuable information.

4.1.3 Agrobiology (Agrobio–Case)

In order to evaluate our proposal in other areas of knowledge, we selected four fam-
ilies of experiments belonging to Agrobiology dealing with soil decontamination
(Soil) [30, 45, 53], harvesting systems (Harvest) [48], extraction of olive oil com-
ponents (Olive) [26], and inﬂuence of diet on cholesterol accumulation (Diet) [46].
These families were selected at the suggestion of the Agrobiology researchers who
accepted to participate and to whom we had direct access.

Several meetings were held where we followed a protocol consisting of the fol-
lowing steps: (i) we explained the templates to ensure that the researchers understood
how to use them; (ii) we asked each researcher to select one of her experiments
with at least one replication and, if possible, already published; (iii) for the selected
experiment, we asked each researcher to ﬁll in the corresponding templates for all
the experiment replications and their associated changes, providing us with as much
feedback as possible; and (iv) we asked the researchers whether they had found any
limitations, usability problems, or unknown terminology using the templates, record-
ing all the details. By the time we conducted this case study, an earlier version of
the CÆSAR tool was already available, and some researchers agreed to use it for
reporting their replications, providing very valuable feedback.

4.2 Analysis and Report

In this section, the results of the three case studies, which are summarized in Table 1,
are analyzed and reported.

4.2.1 HOE–Case analysis

When this ﬁrst case study was conducted, the metamodel of our artifact was in a early
stage. This is the reason why we designed it as a self–evaluation case study and that is
why most of the evolution of the metamodel—and therefore of the templates and the
CÆSAR tool—is based on the ﬁndings obtained during its conduction. As a matter of

Springer Nature 2021 LATEX template

14

A Model-Based Approach for Specifying Changes in Replications

l
e
d
o
m
a
t
e
m
e
h
t

f
o

n
o
i
s
r
e
v

y
l
r
a
e

e
h
t

h
t
i

w
d
e
ﬁ

i
c
e
p
s

e
b

d
l
u
o
c

)

%
0
0
1

,
4

-
r
e
p
u
s

t
c
a
r
t
s
b
a
w
e
n
e
h
t
n
i

s
t
l
u
s
e
r

s
i
h
T

.
s
e
i
d
u
t
s

l
a
n
i
g
i
r
o
n
i

f
o
t
u
o
4
(

s
e
g
n
a
h
c

l
l
a

,
s
n
o
i
t
a
c
i
l
p
e
r
n
o
d
e
s
a
b
s
n
o
i
t
a
c
i
l
p
e
r

e
h
t

r
o
f

t
p
e
c
x
E

y
l
n
o

t
o
n

,
s
n
o
i
t
a
c
i
l
p
e
r

n
o

d
e
s
a
b

e
r
e
w
s
n
o
i
t
a
c
i
l
p
e
r

e
m
o
S

r
a
l
u
b
a
T

4

.
s
e
t
a
l
p
m
e
t

d
n
a

-
s
o
p
m
o
C
e
h
t

f
o
n
o
i
t
a
c
i
l
p
p
a

e
h
t
d
n
a

y
d
u
t
S
l
a
c
i
r
i
p
m
E
s
s
a
l
c

e
r
a

s
e
t
u
b
i
r
t
t
a
m
y
n
o
r
c
a

d
n
a

,
e
t
a
d

,
e
t
i

S

.
n
r
e
t
t
a
p

n
g
i
s
e
d

e
t
i

.
s
s
a
l
c
w
e
n

e
h
t

o
t

d
e
d
d
a

e
r
o
m
g
n
i
t
c
a
p
m

i

o
t

e
u
d

s
e
t
a
l
p
m
e
t

d
n
a

l
e
d
o
m
a
t
e
m
e
h
t

f
o

n
o
i
s
r
e
v

y
l
r
a
e

g
n
i
l
e
d
o
m

r
o
f

e
r
u
t
c
u
r
t
s

e
h
t

f
o

n
o
i
t
u
l
o
v
e

n
a

n
i

s
t
l
u
s
e
r

e
h
t

h
t
i

w
d
e
ﬁ
i
c
e
p
s

y
l
e
r
i
t
n
e

e
b

t
o
n

d
l
u
o
c

s
e
g
n
a
h
c

)

%
3
3
(

3
3

f
o

t
u
o

1
1

s
i
h
T

.
e
p
y
t

y
t
i
d
i
l
a
v

e
n
o

n
a
h
t

e
r
o
m

t
c
a
p
m

i

s
e
g
n
a
h
c

e
m
o
S

r
a
l
u
b
a
T

3
3

.
e
p
y
t

y
t
i
d
i
l
a
v

e
n
o

n
a
h
t

d
e
d
d
a
s
i
e
t
u
b
i
r
t
t
a
e
l
a
n
o
i
t
a
R

.
s
t
c
e
f
f
e
d
n
a
s
t
c
a
p
m

i

,
s
e
g
n
a
h
c

.
s
s
a
l
c

t
c
a
p
m
I
e
g
n
a
h
C
o
t

y
t
i
d
i
l
a
v

n
o

s
t
c
a
p
m

I

.
d
e
t
r
o
p
e
r

m
o
d
l
e
s

s
i

e
s
o
p
r
u
p

e
g
n
a
h
c

,
l
a
r
e
n
e
g

n
I

.
y
f
i
t
n
e
d
i

o
t

d
r
a
w
r
o
f
t
h
g
i
a
r
t
s

s
y
a
w
l
a

t
o
n

e
r
a

s
n
o
i
s
n
e
m
i
d

d
e
ﬁ

i
d
o
m
d
n
a

.
n
o
i
s
n
e
m
i
d

e
g
n
a
h
c

t
x
e
t
n
o
c

e
h
t

e
h
t

f
o

k
c
a
l

e
h
t

f
o

e
s
u
a
c
e
b

d
n
a

y
l
i

m
a
f

q
e
R

e
h
t

n
i

n
a
h
t

n
o
s
a
e
r

e
m
a
s

.
s
s
a
l
c
b
u
s

e
g
n
a
h
C
t
x
e
t
n
o
C
w
e
n

e
h
t

n
i

g
n
i
t
l
u
s
e
r

,
d
e
ﬁ

i
t
n
e
d
i

r
o
f

d
e
ﬁ
i
c
e
p
s

y
l
e
t
e
l
p
m
o
c

e
b

t
o
n

d
l
u
o
c

s
e
g
n
a
h
c

)

%
4
1
(

1
2

f
o

t
u
o

3

y
l
r
a
e
l
c

e
b

t
o
n

d
l
u
o
c

s
e
g
n
a
h
c

e
m
o
s

f
o

n
o
i
s
n
e
m
i
d

e
h
T

r
a
l
u
b
a
T

d
e
v
l
o
v
e
n
a
g
n
i
s
u
d
e
ﬁ
i
c
e
p
s
y
l
r
e
p
o
r
p
e
b
d
l
u
o
c
s
t
n
e
m

i
r
e
p
x
e
f
o
e
p
y
t

s
i
h
T

f
o

e
c
n
e
u
q
e
s
n
o
c

a

s
a

t
c
a
f
i
t
r
a

e
h
t

f
o

n
o
i
t
u
l
o
v
e

t
n
a
v
e
l
e
r

o
N

f
o
n
o
i
t
a
c
ﬁ
i
c
e
p
s

e
h
t
h
g
u
o
h
t
l
a

,
s
e
t
a
l
p
m
e
t
d
n
a

l
e
d
o
m
a
t
e
m
e
h
t

f
o
n
o
i
s
r
e
v

h
t
i

w
s
e
c
n
e
r
e
f
f
i
d

o
t

e
u
d

s
u
o
i
v
b
o

s
y
a
w
l
a

t
o
n

s
a
w
s
n
o
i
s
n
e
m
i
d

e
g
n
a
h
c

.
s
e
i
d
u
t
s
E
O
H

.
y
d
u
t
s

e
s
a
c

s
i
h
t

e
l
b
i
s
s
o
p
m

i

t
s
o
m
l
a

e
r
a

s
n
o
i
t
a
c
i
l
p
e
r

,
n
o
i
t
a
m
r
o
f
n
i

l
a
u
t
x
e
t
n
o
c

t
u
o
h
t
i

W

-
g
i
r
o
e
h
t
o
t
d
e
t
a
l
e
r
n
o
i
t
a
m
r
o
f
n
i

l
a
u
t
x
e
t
n
o
c
f
o
d
e
e
n
r
a
e
l
c
A

.
s
u
o
i
v
b
o

t
o
n

s
a
w
s
n
o
i
s
n
e
m
i
d

e
g
n
a
h
c

f
o

n
o
i
t
a
c
ﬁ

i
c
e
p
S

.
d
n
a
t
s
r
e
d
n
u

o
t

s
i
h
T

.
d
e
t
c
e
t
e
d

s
i

s
t
n
e
m

i
r
e
p
x
e

f
o

y
l
i

m
a
f

a

f
o

y
d
u
t
s

l
a
n
i

e
v
i
t
i
s
o
P

.
d
e
t
c
e
t
e
d
e
r
e
w
y
g
o
l
o
n
i
m
r
e
t

l
a
t
n
e
m

i
r
e
p
x
e
n
i

s
e
c
n
e
r
e
f
f
i
d
e
m
o
S

s
s
a
l
c
r
e
p
u
s

y
d
u
t
S
l
a
n
i
g
i
r
O
e
h
t

n
i

s
e
t
u
b
i
r
t
t
a
w
e
n

n
i

s
t
l
u
s
e
r

.
l
o
o
t

R
A
S
Æ
C
e
h
t

e
h
t

o
t

t
c
e
p
s
e
r

h
t
i

w
k
c
a
b
d
e
e
f

s
t
c
e
f
f
e

f
o

n
o
i
t
a
c
ﬁ

i
t
n
a
u
q

e
h
t

r
o
f

n
o
i
t
a
v
i
t
o
m
e
h
t

s
i

t
i

d
n
a

n
i

l
o
o
t

R
A
S
Æ
C

e
h
t

n
i

n
o
i
t
a
z
i
l
a
u
s
i
v

s
t
i

d
n
a

y
t
i
d
i
l
a
v

n
o

.
s
n
o
i
t
a
r
e
t
i

r
e
h
t
r
u
f

e
v
i
t
a
r
r
a
N

e
v
i
t
a
r
r
a
N

e
v
i
t
a
r
r
a
N

e
v
i
t
a
r
r
a
N

r
a
l
u
b
a
T

e
v
i
t
a
r
r
a
N

1
2

8
5

3 2

5

6
1

1
1 1

1

9
2

2
9

2

8

4

q
e
R

e
d
o
C

d
n
M

i

E
O
H

4
1

3

l
a
t
o
T

3 1

4

2 1 1 1

5

3
2

L
P
S

g
n
i
t
s
e
T

E
O
T

2

l
a
t
o
T

t
s
e
v
r
a
H

e
v
i
l

O

t
e
i
D

l
i

o
S

i

o
b
o
r
g
A

4

9

l
a
t
o
T

l
a
t
o
T

s
e
m
o
c
t
u
o

y
d
u
t
s

e
s
a
c

e
l
p
i
t
l
u
m
e
h
t

f
o

y
r
a
m
m
u
S

:
1

e
l
b
a
T

s
g
n
i
d
n
ﬁ

l
a
n
o
i
t
i
d
d
A

n
o
i
t
u
l
o
v
e

t
c
a
f
i
t
r

A

y
l
l
a
n
i
g
i
r

O

s
a
d
e
t
r
o
p
e
R

g
n
h
C
#

l
p
e
R
#

y
l
i

m
a
F

.

p
x
E
f
o

e
s
a
C

y
d
u
t
s

Springer Nature 2021 LATEX template

A Model-Based Approach for Specifying Changes in Replications

15

fact, only 76% of the changes in the selected families of experiments could be spec-
iﬁed with the initial version of the metamodel, but 100% with the evolved version.
One of the main evolutive changes in the early metamodel was motivated by the fact
that some of the replications in the Mind family were based not on an original study
but on a previous replication. Since replications in the initial metamodel were asso-
ciated to original studies only, we had to include the abstract class EmpiricalStudy to
allow replications based on replications, in a similar way to the Composite design pat-
tern [25]. As shown in Figure 9, in this evolutionary change we also introduced some
missing information like date, site, and report and an acronym as a public unique
identiﬁer to facilitate the referencing of empirical studies and their traceability.

On the other hand, during the speciﬁcation of the replication changes in this case
study, we observed that some of them affected more than one type of experimental va-
lidity, so we evolved the metamodel accordingly, as shown in Figure 10. Sometimes,
the impact of a change on a speciﬁc type of experimental validity was not obvious,
so we also decided to add the rationale attribute to the new ChangeImpact class,
letting the experimenters register why they thought a given change increased or de-
creased a given validity type. In a subsequent iteration, we considered that this effect
could be subjectively quantiﬁed using a 7-point linear modeled by the Effect value-
based enumeration and the corresponding effect attribute in the ChangeImpact class.
As previously commented in Section 3.1, this enhancement of the metamodel allows

(a) Early version

(b) Evolved version

Figure 9: Metamodel evolution for modeling replications based on replications

(a) Early version

(b) Evolved version

Figure 10: Metamodel evolution for modeling more than one validity effect per
change

acronym : IDsite : Stringdate : Datereport : URLcomments : Text [0..1]EmpiricalStudyacronym : IDsite : Stringdate : Datereport : URLcomments : Text [0..1]EmpiricalStudyacronym : IDsite : Stringdate : Datereport : URLcomments : Text [0..1]EmpiricalStudygoal : Textdescription : TextOriginalStudygoal : Textdescription : TextOriginalStudygoal : Textdescription : TextOriginalStudytype : enum { internal, external }purpose : Purpose [1..*]Replicationtype : enum { internal, external }purpose : Purpose [1..*]Replicationtype : enum { internal, external }purpose : Purpose [1..*]ReplicationisReplicatedBybase1*goal : Textcomments : Text [0..1]OriginalStudygoal : Textcomments : Text [0..1]OriginalStudygoal : Textcomments : Text [0..1]OriginalStudytype : enum { internal, external }purpose : Purpose [1..*]comments : Text [0..1]Replicationtype : enum { internal, external }purpose : Purpose [1..*]comments : Text [0..1]Replicationtype : enum { internal, external }purpose : Purpose [1..*]comments : Text [0..1]ReplicationisReplicatedBybase1*name : Stringbase_situation : Textreplication_situation : Textpurpose : Textvalidity : Validityeffect : enum { increase, decrease }comments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textvalidity : Validityeffect : enum { increase, decrease }comments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textvalidity : Validityeffect : enum { increase, decrease }comments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Changevalidity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpactvalidity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpactvalidity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpact*substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>acronym : IDsite : Stringdate : Datereport : URLcomments : Text [0..1]EmpiricalStudyacronym : IDsite : Stringdate : Datereport : URLcomments : Text [0..1]EmpiricalStudyacronym : IDsite : Stringdate : Datereport : URLcomments : Text [0..1]EmpiricalStudygoal : Textdescription : TextOriginalStudygoal : Textdescription : TextOriginalStudygoal : Textdescription : TextOriginalStudytype : enum { internal, external }purpose : Purpose [1..*]Replicationtype : enum { internal, external }purpose : Purpose [1..*]Replicationtype : enum { internal, external }purpose : Purpose [1..*]ReplicationisReplicatedBybase1*goal : Textcomments : Text [0..1]OriginalStudygoal : Textcomments : Text [0..1]OriginalStudygoal : Textcomments : Text [0..1]OriginalStudytype : enum { internal, external }purpose : Purpose [1..*]comments : Text [0..1]Replicationtype : enum { internal, external }purpose : Purpose [1..*]comments : Text [0..1]Replicationtype : enum { internal, external }purpose : Purpose [1..*]comments : Text [0..1]ReplicationisReplicatedBybase1*name : Stringbase_situation : Textreplication_situation : Textpurpose : Textvalidity : Validityeffect : enum { increase, decrease }comments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textvalidity : Validityeffect : enum { increase, decrease }comments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textvalidity : Validityeffect : enum { increase, decrease }comments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Changevalidity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpactvalidity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpactvalidity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpact*substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>acronym : IDsite : Stringdate : Datereport : URLcomments : Text [0..1]EmpiricalStudyacronym : IDsite : Stringdate : Datereport : URLcomments : Text [0..1]EmpiricalStudyacronym : IDsite : Stringdate : Datereport : URLcomments : Text [0..1]EmpiricalStudygoal : Textdescription : TextOriginalStudygoal : Textdescription : TextOriginalStudygoal : Textdescription : TextOriginalStudytype : enum { internal, external }purpose : Purpose [1..*]Replicationtype : enum { internal, external }purpose : Purpose [1..*]Replicationtype : enum { internal, external }purpose : Purpose [1..*]ReplicationisReplicatedBybase1*goal : Textcomments : Text [0..1]OriginalStudygoal : Textcomments : Text [0..1]OriginalStudygoal : Textcomments : Text [0..1]OriginalStudytype : enum { internal, external }purpose : Purpose [1..*]comments : Text [0..1]Replicationtype : enum { internal, external }purpose : Purpose [1..*]comments : Text [0..1]Replicationtype : enum { internal, external }purpose : Purpose [1..*]comments : Text [0..1]ReplicationisReplicatedBybase1*name : Stringbase_situation : Textreplication_situation : Textpurpose : Textvalidity : Validityeffect : enum { increase, decrease }comments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textvalidity : Validityeffect : enum { increase, decrease }comments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textvalidity : Validityeffect : enum { increase, decrease }comments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Changevalidity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpactvalidity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpactvalidity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpact*substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>acronym : IDsite : Stringdate : Datereport : URLcomments : Text [0..1]EmpiricalStudyacronym : IDsite : Stringdate : Datereport : URLcomments : Text [0..1]EmpiricalStudyacronym : IDsite : Stringdate : Datereport : URLcomments : Text [0..1]EmpiricalStudygoal : Textdescription : TextOriginalStudygoal : Textdescription : TextOriginalStudygoal : Textdescription : TextOriginalStudytype : enum { internal, external }purpose : Purpose [1..*]Replicationtype : enum { internal, external }purpose : Purpose [1..*]Replicationtype : enum { internal, external }purpose : Purpose [1..*]ReplicationisReplicatedBybase1*goal : Textcomments : Text [0..1]OriginalStudygoal : Textcomments : Text [0..1]OriginalStudygoal : Textcomments : Text [0..1]OriginalStudytype : enum { internal, external }purpose : Purpose [1..*]comments : Text [0..1]Replicationtype : enum { internal, external }purpose : Purpose [1..*]comments : Text [0..1]Replicationtype : enum { internal, external }purpose : Purpose [1..*]comments : Text [0..1]ReplicationisReplicatedBybase1*name : Stringbase_situation : Textreplication_situation : Textpurpose : Textvalidity : Validityeffect : enum { increase, decrease }comments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textvalidity : Validityeffect : enum { increase, decrease }comments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textvalidity : Validityeffect : enum { increase, decrease }comments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Changename : Stringbase_situation : Textreplication_situation : Textpurpose : Textcomments : Text [0..1]Changevalidity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpactvalidity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpactvalidity : Validityeffect : Effectrationale : Textcomments : Text [0..1]ChangeImpact*substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>substantially increases = 3moderately increases = 2slightly increases = 1does not affect = 0 slightly decreases = -1moderately decreases = -2substantially decreases = -3Effect<<enumeration>>Springer Nature 2021 LATEX template

16

A Model-Based Approach for Specifying Changes in Replications

to visualize the evolution of the experimental validity across a family of experiments
(see Figures 6 and 7), supporting decisions in further replications.

It is worth mentioning that in most of the reported replications the purposes of
the changes were rarely stated, making it difﬁcult to identify their effects on validity
and the modiﬁed dimensions.

4.2.2 TOE–Case analysis

The main goal of this case study was to conﬁrm the results of the previous one and
to consolidate the evolutive changes on the artifact. Using the evolved templates, we
were able to specify all the replications changes, although it took us some time to
agree on the dimensions modiﬁed by some changes.

Overall, considering that most of the limitations of the initial artifact had been
identiﬁed in the ﬁrst case study, the participating researchers found our approach
satisfactory, providing very positive feedback.

4.2.3 Agrobio–Case analysis

After validating our approach for the speciﬁcation of changes in Computer Science
experiments, the main goal of the third case study was to test it in a different research
area with users other than ourselves. One of the ﬁrst issues identiﬁed during this case
study was the need of a context for replication changes to be understood due to their
high speciﬁcity. Clearly, that context had to be provided by the original study since
it was shared by all its replications. As shown in Figure 9, in the early version of the
metamodel, only the goal of the original study was registered whereas in the evolved
metamodel, a description is added to provide such a context. See the description of
the original study of the Soil–2018 replication in Figure 11 for a clear example.

In families of experiments in Agrobiology, it is a common practice to change
the growing medium of the plants from Petri dishes to culture chambers, to green-
houses, and ﬁnally, to natural soils. It is also common to repeat the same experiment
in different seasons to conﬁrm results. These kinds of change, that we were not able
to classify in any of the change dimensions by G´omez et al [28], were the reason
to expand their proposal with the context2 dimension. Including this new change di-
mension, we were also able to classify some changes in the HOE–Case in which the
experiments were held with students at different moments of the academic course,
e.g., at the beginning of the course, during examination period, and that we had not
been able to completely specify before.

Regarding the user experience of the participating researchers, they found the
templates and L–patterns very useful for reporting their replications, helping them
to focus on the essential information. Those who agreed to use CÆSAR, despite
being a proof–of–concept tool, found it very useful for generating reports of their
experiments and showed a great interest to use it in the future. Nevertheless, some
differences in the terminology used in the templates were detected. Particularly, the
concept of change dimension was foreign to them, something that it seemed rea-
sonable considering that it is a recent concept proposed by an Computer Science

2The name was decided because this kind of change usually affects context variables in experimental design. An

alternative name, environment dimension, was also discussed among us but was ﬁnally discarded in favor of context.

Springer Nature 2021 LATEX template

A Model-Based Approach for Specifying Changes in Replications

17

Figure 11: Speciﬁcation of the Soil–2018 replication [45] in the CÆSAR tool

researcher [28]. Another foreign concepts to them were those of experimental validity
and validity threats, which was very surprising to us considering the importance they
are given in our discipline. After several meetings, we found out that they handle a
list of usual experimental risks with their corresponding actions to mitigate them, but
they use the term avoiding experimental errors instead of minimizing validity threats
as we do in Computer Science. On the other hand, they preferred the term repetition
to replication.

4.3 Threats to Validity

Runeson et al [55] provide a detailed description of threats to the validity of case
studies. In this section, such threats and the actions performed to mitigate them in
our multiple case study are described.

4.3.1 Construct validity

This validity is concerned with the degree to which the operationalization actually
reﬂects what is to be the investigated. According to [73], using multiple sources of
evidence during data collection increases construct validity, as it has been our case.
On the other hand, it is also recommended in [73] that a draft of the case study report

Springer Nature 2021 LATEX template

18

A Model-Based Approach for Specifying Changes in Replications

be reviewed by key informants. In our case, the participant researches have not only
followed the evolution of the artifact across the whole evaluation process, but they
have also reviewed a draft report of our multiple case study.

4.3.2 Internal validity

This validity is concerned when causal relations are examined. The main hypothe-
sis in our study is that the use of the proposed artifact is useful for the speciﬁcation
and reporting of replications, not only in Computer Science, but also in other areas
of knowledge. The only potential threat to the internal validity is that the differ-
ences in the used terminology could affect the usage of the artifact by participant
researchers, especially for those from research areas other than Computer Science.
To mitigate this threat, we explained the use of the templates and assisted the Agrobi-
ology researchers during the Agrobio–Case, apart from investigating the differences
and similarities between their terminology and that used in Computer Science, in
order to improve our communication with them.

4.3.3 External validity

This validity is concerned with the generalization of results in cases that have com-
mon characteristics. The fact that the templates were ﬁrstly used by ourselves could
limit the generalization of the ﬁndings. In order to overcome this threat, we invited
other researchers from our own research area and from other research areas to par-
ticipate in the study, thus reducing the potential bias. Nevertheless, further research
is needed to validate the artifact in more replications, belonging to the Computer
Science discipline or to other different disciplines. In this sense, the CÆSAR tool is
available to the scientiﬁc community, so other researchers can report their replication
changes using it and provide feedback for further improvements.

4.3.4 Reliability

This aspect is concerned with obtaining similar results when the study is carried
out by other researchers. Since the speciﬁcation of all replications with their corre-
sponding changes is available at Zenodo [19], the study can be repeated by other
researchers which can then compare their results with ours.

5 Related work

Regarding replications in Computer Science, several literature reviews show the rel-
evance of the topic [12, 18, 20, 42]. These reviews are systematic mapping studies
dealing with general aspects such as types of replications, conceptual frameworks,
or addressed research topics. However, to the best of our knowledge, there is a lack
of literature reviews on more speciﬁc aspects of replications such as the reporting of
changes. Despite of the recommendations by Carver [16], Shepperd et al [62], Juristo
and Vegas [37, 38], G´omez et al [28], and Baldassarre et al [6] to report replica-
tion changes, no concrete proposals have been provided on how to specify them in
Computer Science.

Springer Nature 2021 LATEX template

A Model-Based Approach for Specifying Changes in Replications

19

The works that are most related to ours are [2], [65], and [69], who propose a tab-
ular form to summarize the experiments that compose a family. In [2], replications
are reported including their motivation, their changes (in unstructured narrative text),
the conﬁrmation or non-conﬁrmation of results in previous experiments, other char-
acteristics such as subjects, tasks, and materials, and whether hypotheses or research
questions changed from previous experiments. In [65], a tabular replication summary
is used, including information on, among others, experimental design, laboratory
package, material preparation, replication operation, data analysis, and experimenter
evaluation. Finally, in [69], the speciﬁcation of each experiment is summarized in-
cluding elements such as factors, treatments, response variables, design, experimental
objects, and participants.

After reviewing these proposals, we consider that all of them provide an in-depth
overview of the conﬁguration of each experiment in a family. However, to identify
replication changes, table content corresponding to the different replications must be
compared, whereas in our proposal, apart from being model-based and having tool
support, each change is speciﬁed separately in a explicit manner, thus reducing tacit
knowledge as recommended in [41].

In a recent survey closely related to the approach presented in this article, 137
articles published between 2013 and 2018 reporting at least one replication were an-
alyzed [18]. Most of the replication changes were deﬁned in controlled experiments,
conﬁrming that this is the most frequently applied empirical strategy in the research
area [29]. In general, most changes—also referred to as adjustments or differences—
were described with respect to an original experiment using natural language or
tabular forms, only about 25%-30% of the studies reported the purpose of the changes
and their effect on experimental validity.

6 Conclusions and Future work

In the context of replications of empirical studies in Computer Science, and applying
DSR, we have develop and evaluated a composite artifact to systematically specify
and report replication changes. We have developed the artifact following a model-
based approach, generating (i) a metamodel formalizing all the relevant concepts
related to replication changes; (ii) templates for reporting replication contexts and
replication changes using the information in the metamodel together with L-patterns
to facilitate their use; and (iii) a proof-of-concept tool based on the metamodel and
supporting the management of the proposed templates. We have also evaluated the
artifact by means of a multiple case study in which 92 replications changes cor-
responding to 23 replication studies in 9 families of experiments in the areas of
Computer Science and Agrobiology were speciﬁed by ourselves and by other re-
searchers and subsequently analyzed. The evaluation revealed some initial limitations
of our approach, but they were overcome after several improvement iterations. One
of the most relevant improvements was the quantitative determination of the effect of
changes on experimental validity, that allows the visualization of the evolution of the
validity of a family of experiments thus supporting decision-making.

Springer Nature 2021 LATEX template

20

A Model-Based Approach for Specifying Changes in Replications

Our model-based proposal for the speciﬁcation of replication changes seems to
ﬁt the needs not only of Computer Science, but also of other research areas such as
Agrobiology, obtaining very positive feedback from the participant researchers from
both disciplines.

As future work, our aim in the middle term is to apply our templates not only to
report changes of already conducted replications, but to use them during replication
design, as a means of analyzing and documenting the purpose and effects of replica-
tion changes before they are performed. This design-oriented approach needs a more
advanced version of the CÆSAR tool, including a virtual assistant, probably a chat-
bot, that guides the researcher in the process and suggests, for example, potential
effects of changes on experimental validity depending on the modiﬁed dimension or
on other criteria that might be identiﬁed from experience. In the short term, we want
to provide Computer Science researchers with a consolidated LATEX package for us-
ing the proposed templates in their articles when they need to report some replication
changes, thus disseminating our artifact in the community.

Acknowledgments

We want to thank Carmen Florido, Ar´anzazu Garc´ıa, Roc´ıo Abia, and Eddy Plasquy
for their contribution to the multiple case study by specifying their experiments and
for their kind willingness to provide us with all the information required.

This work has been partially supported by the European Commission (FEDER)
and the Spanish Government under projects OPHELIA (RTI2018-101204-B-C22),
EKIPMENT-PLUS (P18-FR-2895), and MEMENTO (US-1381595).

References

[1] Albayrak ¨O, Carver JC (2014)

factors im-
pacting the effectiveness of requirements inspections: a replicated experi-
ment. Empirical Software Engineering 19(1):241–266. https://doi.org/10.1007/
s10664-012-9221-0

Investigation of

individual

[2] Almqvist JPF (2006) Replication of controlled experiments in empirical soft-
ware engineering - a survey. Master’s thesis, master’s thesis, Department of
Computer Science, Faculty of Science, Lund University, Sweden

[3] Aranda A (2016) Empirical study of the inﬂuence of analyst experience and
domain knowledge on the effectiveness of requirements education. PhD thesis,
Polytechnic University of Madrid, https://doi.org/10.20868/UPM.thesis.40566

[4] Assar S, Borg M, Pfahl D (2016) Using text clustering to predict defect
resolution time: a conceptual replication and an evaluation of prediction ac-
curacy. Empirical Software Engineering 21(4):1437–1475. https://doi.org/10.
1007/s10664-015-9391-7

Springer Nature 2021 LATEX template

A Model-Based Approach for Specifying Changes in Replications

21

[5] Association

for

view
artifact-review-and-badging-current

badging.

and

Computing Machinery

re-
(2020)
https://www.acm.org/publications/policies/

Artifact

[6] Baldassarre MT, Carver J, Dieste O, et al (2014) Replication types: Towards a
shared taxonomy. In: Proceedings of EASE’14, p 18:1–18:4, https://doi.org/10.
1145/2601248.2601299

[7] Basili VR, Caldiera G, Rombach HD (1994) Goal question metrics paradigm.

Encyclopedia of Software Engineering pp 528–532

[8] Basili VR, Shull F, Lanubile F (1999) Building knowledge through families
of experiments. IEEE Trans Softw Eng 25(4):456–473. https://doi.org/10.1109/
32.799939

[9] Bern´ardez B, Dur´an A, Parejo JA, et al (2014) A controlled experiment to
evaluate the effects of mindfulness in software engineering. In: Proceedings of
ESEM’14, pp 17–27, https://doi.org/10.1145/2652524.2652539

[10] Bern´ardez B, Dur´an AD, Parejo JA, et al (2020) Effects of mindfulness on
conceptual modeling performance: A series of experiments. IEEE Transac-
tions on Software Engineering 48(2):432–452. https://doi.org/10.1109/TSE.
2020.2991699

[11] Bern´ardez B, Dur´an A, Parejo JA, et al (2018) An experimental replication
on the effect of the practice of mindfulness in conceptual modeling perfor-
mance. Journal of Systems and Software 136:153–172. https://doi.org/10.1016/
j.jss.2016.06.104

[12] Bezerra RM, da Silva FQ, Santana AM, et al (2015) Replication of empirical
studies in software engineering: An update of a systematic mapping study. In:
Proceedings of ESEM’15, IEEE, pp 1–4, https://doi.org/10.1109/ESEM.2015.
7321213

[13] Brooks A, Daly J, Miller J, et al (1996) Replication of experimental re-
sults in software engineering. Technical Report ISERN-96-10, University of
Strathclyde, Glasgow, UK

[14] Brooks A, Roper M, Wood M, et al (2008) Replication’s Role in Software Engi-
neering, Springer, pp 365–379. https://doi.org/10.1007/978-1-84800-044-5 14

[15] Campbell DT, Stanley JC (2015) Experimental and quasi-experimental designs

for research. Ravenio books

[16] Carver JC (2010) Towards reporting guidelines for experimental replications:
A proposal. In: Proceedings of the 1st international workshop on replication in
empirical software engineering, pp 1–4

Springer Nature 2021 LATEX template

22

A Model-Based Approach for Specifying Changes in Replications

[17] Ciolkowski M, Shull F, Bifﬂ S (2002) A family of experiments to investigate
the inﬂuence of context on the effect of inspection techniques. In: Proceedings
of EASE’02, pp 48–60

[18] Cruz M, Bern´ardez B, Dur´an A, et al (2019) Replication of studies in empirical
software engineering: A systematic mapping study, from 2013 to 2018. IEEE
Access 8:26,773–26,791. https://doi.org/10.1109/ACCESS.2019.2952191

[19] Cruz M, Bern´ardez B, Dur´an A, et al (2021) Supplemental material: Instantia-
tion of the proposed templates in the multiple case study using CÆSAR LaTeX
template. https://doi.org/10.5281/zenodo.6631976

[20] Da Silva FQ, Suassuna M, Franc¸a ACC, et al

(2014) Replication of
empirical studies in software engineering research: a systematic mapping
study. Empirical Software Engineering 19(3):501–557. https://doi.org/10.1007/
s10664-012-9227-7

[21] Dur´an A, Bern´ardez B, Ruiz-Cort´es A, et al (1999) A requirements elicitation

approach based in templates and patterns. In: Proceedings of WER’99

[22] Dur´an A, Corchuelo R, Ruiz-Cort´es A, et al (2002) Supporting requirements
veriﬁcation using XSLT. In: Proceedings of RE’02, pp 165–172, https://doi.org/
10.1109/ICRE.2002.1048519

[23] Fern´andez DM, Graziotin D, Wagner S, et al (2020) Open science in software
engineering, Springer International Publishing, pp 477–501. https://doi.org/10.
1007/978-3-030-32489-6 17

[24] Fern´andez-S´aez AM, Genero M, Caivano D, et al (2016) Does the level of detail
of UML diagrams affect the maintainability of source code?: a family of ex-
periments. Empirical Software Engineering 21(1):212–259. https://doi.org/10.
1007/s10664-014-9354-4

[25] Gamma E, Helm R, Johnson R, et al (1995) Design Patterns: Elements of

Reusable Object-Oriented Software. Addison-Wesley

[26] Garc´ıa A, Rodr´ıguez-Juan E, Rodr´ıguez-Guti´errez G, et al (2016) Extraction
of phenolic compounds from virgin olive oil by deep eutectic solvents (DESs).
Food chemistry 197:554–561. https://doi.org/10.1016/j.foodchem.2015.10.131

[27] G´omez OS, Juristo N, Vegas S (2010) Replications types in experimental disci-
plines. In: Proceedings of ESEM’10, p 71–75, https://doi.org/10.1145/1852786.
1852790

[28] G´omez OS, Juristo N, Vegas S (2014) Understanding replication of experiments
in software engineering: A classiﬁcation. Information and Software Technology
56(8):1033–1048. https://doi.org/10.1016/j.infsof.2014.04.004

Springer Nature 2021 LATEX template

A Model-Based Approach for Specifying Changes in Replications

23

[29] Guevara-Vega C, Bern´ardez B, Dur´an A, et al (2021) Empirical strategies in
software engineering research: A literature survey. In: II International Confer-
ence on Information Systems and Software Technologies (ICI2ST 2021). IEEE
Press, Quito, Ecuador

[30] Carvajal de la Haza S (2016) Copper extraction by brown mustard (brassica
juncea) plants during vegetative growth in an artiﬁcially contaminated soil
and effect of rhamnolipid application. http://hdl.handle.net/11441/50282, (Final
Degree Project). Universidad de Sevilla

[31] Herbold S, Trautsch A, Grabowski J (2017) Global vs. local models for cross-
project defect prediction. Empirical Software Engineering 22(4):1866–1902.
https://doi.org/10.1007/s10664-016-9468-y

[32] Itkonen J, M¨antyl¨a MV (2014) Are test cases needed? replicated comparison
between exploratory and test-case-based software testing. Empirical Software
Engineering 19(2):303–342. https://doi.org/10.1007/s10664-013-9266-8

[33] Jedlitschka A, Ciolkowski M, Pfahl D (2008) Reporting experiments in soft-
ware engineering. In: Guide to advanced empirical software engineering.
Springer, p 201–228, https://doi.org/10.1007/978-1-84800-044-5 8

[34] Juristo N, G´omez OS (2012) Replication of software engineering experiments.
In: Empirical software engineering and veriﬁcation. Springer, p 60–88, https:
//doi.org/10.1007/978-3-642-25231-0 2

[35] Juristo N, Moreno AM (2013) Basics of software engineering exper-
imentation. Springer Science & Business Media, https://doi.org/10.1007/
978-1-4757-3304-4

[36] Juristo N, Vegas S (2003) Functional testing, structural testing and code
reading: What fault type do they each detect? In: Empirical Methods and
Studies in Software Engineering. Springer, p 208–232, https://doi.org/10.1007/
978-3-540-45143-3 12

[37] Juristo N, Vegas S (2009) Using differences among replications of software en-
gineering experiments to gain knowledge. In: Proceedings of ESEM’09, IEEE,
pp 356–366, https://doi.org/10.1109/ESEM.2009.5314236

[38] Juristo N, Vegas S (2011) The role of non-exact replications in software en-
gineering experiments. Empirical Software Engineering 16(3):295–324. https:
//doi.org/10.1007/s10664-010-9141-9

[39] Juristo N, Vegas S, Solari M, et al (2012) Comparing the effectiveness of equiv-
alence partitioning, branch testing and code reading by stepwise abstraction
applied by subjects. In: Proceedings of International Conference on Software
Testing, Veriﬁcation and Validation, pp 330–339, https://doi.org/10.1109/ICST.

Springer Nature 2021 LATEX template

24

A Model-Based Approach for Specifying Changes in Replications

2012.113

[40] Juristo N, Vegas S, Solari M, et al (2013) A process for managing interac-
tion between experimenters to get useful similar replications. Information and
Software Technology 55(2):215–225. https://doi.org/10.1016/j.infsof.2012.07.
016

[41] Kitchenham B (2008) The role of replications in empirical software engineering
a word of warning. Empirical Software Engineering 13(2):219–221. https://doi.
org/10.1007/s10664-008-9061-0

[42] de Magalh˜aes CV, da Silva FQ, Santos RE, et al (2015) Investigations about
replication of empirical studies in software engineering: A systematic map-
ping study. Information and Software Technology 64:76–101. https://doi.org/
10.1016/j.infsof.2015.02.001

[43] Mendez D, Graziotin D, Wagner S, et al (2020) Open science in software
engineering. In: Contemporary Empirical Methods in Software Engineering.
Springer, p 477–501, https://doi.org/10.1007/978-3-030-32489-6 17

[44] Mondal M, Rahman MS, Roy CK, et al (2018) Is cloned code really sta-
ble? Empirical Software Engineering 23(2):693–770. https://doi.org/10.1007/
s10664-017-9528-y

[45] M´arquez M (2018) Copper extraction by brown mustard (brassica juncea)
plants during vegetative growth in an artiﬁcially contaminated soil and effect
of rhamnolipid application. https://hdl.handle.net/11441/132481, (Final Degree
Project). Universidad de Sevilla

[46] Pacheco YM, L´opez S, Berm´udez B, et al (2008) A meal rich in oleic
acid beneﬁcially modulates postprandial sicam-1 and svcam-1 in normoten-
sive and hypertensive hypertriglyceridemic subjects. Journal of Nutritional
Biochemistry 19(3):200–205. https://doi.org/10.1016/j.jnutbio.2007.03.002

[47] Parejo JA, S´anchez AB, Segura S, et al (2016) Multi-objective test case prior-
itization in highly conﬁgurable systems: A case study. Journal of Systems and
Software 122:287–310. https://doi.org/10.1016/j.jss.2016.09.045

[48] Plasquy E, Florido MC, Sola-Guirado RR, et al (2021) Effects of a harvesting
and conservation method for small producers on the quality of the produced
olive oil. Agriculture 11. https://doi.org/10.3390/agriculture11050417

[49] Reimanis D, Izurieta C, Luhr R, et al (2014) A replication case study to measure
the architectural quality of a commercial system. In: Proceedings of ESEM’14,
ACM, pp 1–8, https://doi.org/10.1145/2652524.2652581

Springer Nature 2021 LATEX template

A Model-Based Approach for Specifying Changes in Replications

25

[50] Riaz M, King J, Slankas J, et al (2017) Identifying the implied: Findings
from three differentiated replications on the use of security requirements tem-
plates. Empirical Software Engineering 22(4):2127–2178. https://doi.org/10.
1007/s10664-016-9481-1

[51] del R´ıo-Ortega A, Resinas M, Dur´an A, et al (2012) Deﬁning process perfor-
mance indicators by using templates and patterns. In: Proceedings of BPM’12,
Springer, pp 223–228, https://doi.org/10.1007/978-3-642-32885-5 18

[52] del R´ıo-Ortega A, Resinas M, Dur´an A, et al (2016) Using templates and
linguistic patterns to deﬁne process performance indicators. Enterprise Informa-
tion Systems 10(2):159–192. https://doi.org/10.1080/17517575.2013.867543

[53] del R´ıo P (2019) Effect of rhamnolipid JBR–425 on the development of brassica
juncea in urban garden soils in Sevilla. https://hdl.handle.net/11441/132478,
(Final Degree Project) Universidad de Sevilla

[54] Runeson P, H¨ost M (2009) Guidelines for conducting and reporting case study
research in software engineering. Empirical Software Engineering 14(2):131.
https://doi.org/10.1007/s10664-008-9102-8

[55] Runeson P, H¨ost M, Rainer A, et al (2012) Case study research in software
engineering. In: Guidelines and examples. Wiley Online Library, p 109–126,
https://doi.org/10.1002/9781118181034.ch8

[56] S´anchez AB, Segura S, Ruiz-Cort´es A (2014) A comparison of test case pri-
oritization criteria for software product lines. In: Proceedings of ICST’14, pp
41–50, https://doi.org/10.1109/ICST.2014.15

[57] Santos A, G´omez OS, Juristo N (2018) Analyzing families of experiments in
Software Engineering: a systematic mapping study. IEEE Transactions on Soft-
ware Engineering 46(5):566–583. https://doi.org/10.1109/TSE.2018.2864633

[58] Santos AR, do Carmo Machado I, de Almeida ES, et al (2019) Comparing the
inﬂuence of using feature-oriented programming and conditional compilation
on comprehending feature-oriented software. Empirical Software Engineering
24(3):1226–1258. https://doi.org/10.1007/s10664-018-9658-x

[59] dos Santos DA, de Almeida ES, Ahmed I (2022) Investigating replication
challenges through multiple replications of an experiment. Information and
Software Technology p 106870. https://doi.org/10.1016/j.infsof.2022.106870

[60] Scanniello G, Marcus A, Pascale D (2015) Link analysis algorithms for static
concept location: an empirical assessment. Empirical Software Engineering
20(6):1666–1720. https://doi.org/10.1007/s10664-014-9327-7

Springer Nature 2021 LATEX template

26

A Model-Based Approach for Specifying Changes in Replications

[61] Segura S, Dur´an A, Troya J, et al (2017) A template-based approach to de-
scribing metamorphic relations. In: Proceedings of International Workshop on
Metamorphic Testing, pp 3–9, https://doi.org/10.1109/MET.2017.3

[62] Shepperd M, Ajienka N, Counsell S (2018) The role and value of replication in
empirical software engineering results. Information and Software Technology
99:120–132. https://doi.org/10.1016/j.infsof.2018.01.006

[63] Shull F, Basili V, Carver J, et al (2002) Replicating software engineering exper-
iments: addressing the tacit knowledge problem. In: Proceedings of ISESE’02,
pp 7–16, https://doi.org/10.1109/ISESE.2002.1166920

[64] Shull F, Carver JC, Vegas S, et al (2008) The role of replications in empirical
software engineering. Empirical Software Engineering 13(2):211–218. https:
//doi.org/10.1007/s10664-008-9060-1

[65] Solari M (2013) Identifying experimental incidents in software engineering
replications. In: Proceedings of ESEM’13, IEEE, pp 213–222, https://doi.org/
10.1109/ESEM.2013.26

[66] Solari M, Vegas S (2006) Classifying and analysing replication packages for
software engineering experimentation. In: Proceedings of WSESE’06 Amster-
dam, Paises Bajos, pp 19–24

[67] Solari M, Vegas S, Juristo N (2017) Content and structure of laboratory
packages for software engineering experiments. Information and Software
Technology 97:64–79. https://doi.org/10.1016/j.infsof.2017.12.016

[68] Spence JR, Stanley DJ (2016) Prediction interval: What to expect when you’re
expecting. . . a replication. PloS one 11(9):e0162,874. https://doi.org/10.1371/
journal.pone.0162874

[69] Vegas S, Riofr´ıo P, Marcos E, et al (2020) On (mis) perceptions of testing effec-
tiveness: an empirical study. Empirical Software Engineering 25:2844–2896.
https://doi.org/10.1007/s10664-020-09805-y

[70] Von Alan RH, March ST, Park J, et al (2004) Design science in informa-
tion systems research. MIS quarterly 28(1):75–105. https://doi.org/10.2307/
25148625

[71] Wieringa RJ (2014) Design science methodology for information systems and

software engineering. Springer

[72] Wohlin C, Runeson P, H¨ost M, et al (2012) Experimentation in software

engineering: an introduction. Springer

[73] Yin RK, et al (2003) Design and methods. Case study research. Sage Publica-

tions: Thousand Oaks

Springer Nature 2021 LATEX template

A Model-Based Approach for Specifying Changes in Replications

27

A Online Resources

The speciﬁcation of the replications and their corresponding changes selected in the
multiple case study are available at the Zenodo repository [19].

The CÆSAR tool is available at https://caesarus.herokuapp.com?lang=en.

