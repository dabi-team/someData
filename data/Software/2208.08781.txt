2
2
0
2

g
u
A
8
1

]

G
L
.
s
c
[

1
v
1
8
7
8
0
.
8
0
2
2
:
v
i
X
r
a

Eﬃcient data-driven gap ﬁlling of satellite image time series using
deep neural networks with partial convolutions

Marius Appel1

1University of M¨unster, Insitute for Geoinformatics, Heisenbergstr. 2, 48149 M¨unster,
Germany; Contact: marius.appel@uni-muenster.de

Abstract

The abundance of gaps in satellite image time series often complicates the application of deep
learning models such as convolutional neural networks for spatiotemporal modeling. Based on
previous work in computer vision on image inpainting, this paper shows how three-dimensional
spatiotemporal partial convolutions can be used as layers in neural networks to ﬁll gaps in
satellite image time series. To evaluate the approach, we apply a U-Net-like model on incomplete
image time series of quasi-global carbon monoxide observations from the Sentinel-5P satellite.
Prediction errors were comparable to two considered statistical approaches while computation
times for predictions were up to three orders of magnitude faster, making the approach applicable
to process large amounts of satellite data. Partial convolutions can be added as layers to other
types of neural networks, making it relatively easy to integrate with existing deep learning
models. However, the approach does not quantify prediction errors and further research is
needed to understand and improve model transferability. The implementation of spatiotemporal
partial convolutions and the U-Net-like model is available as open-source software.

Keywords: deep learning, remote sensing, Sentinel-5P, spatiotemporal interpolation

1 Introduction

Deep learning (DL) and particularly convolutional neural networks (CNNs) have been exception-
ally successful for satellite image analysis tasks including object detection and segmentation. In
recent years, DL models have been increasingly used also for modeling continuous spatiotemporal
phenomena such as soil moisture (ElSaadani et al., 2021) or air temperature (Amato et al., 2020).
Developments in De B´ezenac et al. (2019) demonstrate that such models can reproduce fundamen-
tal physical properties of processes such as advection and diﬀusion in a purely data-driven way.

1

 
 
 
 
 
 
Rasp and Thuerey (2021) even show that CNN-based models can perform medium range weather
prediction with performance close to an operational physical model. More generally, Camps-Valls
et al. (2021) and Reichstein et al. (2019) describe challenges and approaches for hybrid data-driven
and physical modeling. However, a fundamental challenge when applying CNN-based spatiotempo-
ral models on satellite image time series is the existence of missing values e.g, due to atmospheric
conditions (in many cases clouds).

Numerous approaches to ﬁll gaps in spatiotemporal data have been proposed, including statis-
tical methods based on discrete cosine transforms (Wang et al., 2012), singular spectrum analysis
(Ghafarian Malamiri et al., 2018; v. Buttlar et al., 2014), Markov random ﬁelds (Fischer et al.,
2020), spatiotemporal interpolation (Cressie and Johannesson, 2008; Appel and Pebesma, 2020),
and more algorithmic methods such as quantile regression in local neighborhoods (Gerber et al.,
2018). In computer vision, a similar problem is referred to as image inpainting or video inpaint-
ing, where the aim is to restore corrupt parts of images and videos respectively. Liu et al. (2018)
present a promising approach for the former, using a U-Net-like (Ronneberger et al., 2015) encoder
/ decoder model with partial convolutional layers to ﬁll gaps.

Since it has been shown that CNN models are capable of modeling complex tasks and at the
same time predictions can be computationally eﬃcient, this study aims at (i) making CNNs with
partial convolutions applicable to spatiotemporal Earth observation data from satellite image time
series, (ii) evaluating prediction performance and computational aspects with regard to a quasi
global atmospheric dataset, and (iii) discussing limitations, advantages, and future work towards
purely data-driven modeling of spatiotemporal dynamics from incomplete datasets.

Notice that recently, Xing et al. (2022) similarly applied partial convolutions to a spatiotemporal
snow cover dataset. In contrast to their work, the presented approach uses three-dimensional partial
convolutions, compares predictions to other methods, uses atmospheric data on (quasi) global scale,
and discusses the approach as a computationally eﬃcient gap ﬁlling method.

The remainder of this paper is organized as follows. Section 2 introduces the partial convolution
operation and how it can be included in a model. Section 3 describes experimental details and the
datasets used, before results are presented in Section 4. A discussion of limitations of the approach
and potential for future research is given in Section 5, and Section 6 concludes the paper.

2 Methods

2.1 Partial convolutions

The following paragraph describes the partial convolution operation as introduced in Liu et al.
(2018).

2

Compared to ordinary convolutions, partial convolutions not only receive a data subset of the
same size as the ﬁlter kernel but also a corresponding binary mask as input. Let X, M, and K
be the data input, the mask input, and kernel weights respectively, all of identical shape. M has
zeros for missing values and ones for valid observations, and we assume X is zero for missing values,
too. We can then write the partial convolution operation as an ordinary convolution of X and K
followed by multiplication with the number of elements in K divided by the number of ones in
M. The last step can be seen as applying a weight to adjust for missing values. Afterwards, the
mask value of the center pixel is set to one if there is at least one valid observation in X. Formally,
applying a partial convolution at one location can be written as (Liu et al., 2018)

x(cid:48) =




K ∗ (X (cid:12) M)

0


(cid:80) 1
(cid:80) M if (cid:80) M > 0
else,

where (cid:12) is the element-wise multiplication, ∗ is the ordinary convolution, and 1 is an array with
ones in the same shape as X, K, and M. The mask is updated by

m(cid:48) =


1


0


if (cid:80) M > 0

else.

Similar to ordinary convolutional layers in neural networks, a bias can be added and, if the input
has multiple channels, separate convolutions (with diﬀerent weights) are applied before computing
per-pixel sums of the convolved channels. Notice that partial convolutions implicitly provide a
padding strategy by simply extending the mask and data subset at the boundaries with zeros.

2.2 Spatiotemporal models with partial convolutions

Similar to Liu et al. (2018) and Xing et al. (2022), we integrate partial convolutional layers in
a U-Net-like (Ronneberger et al., 2015) model architecture consisting of encoder / decoder (or
convolution / deconvolution) parts and skip connections. The encoder reduces resolution by strided
partial convolutions and (typically) increases the channel depth while the decoder increases the
resolution and combines lower resolution output with output from associated layers of the encoder.
In contrast to Liu et al. (2018) and Xing et al. (2022), our model applies three-dimensional
partial convolutions. The input is a spatiotemporal block X of size nx × ny × nt and a binary mask
M of the same size, where 1 represents that the corresponding value in X is valid and 0 represents
missing values.

At ﬁrst, one or more partial convolutional blocks are applied to the input. A block applies
one or more partial convolutions sequentially with a user-deﬁned number of kernels, where the last

3

Figure 1: Architecture of our U-Net-like model (STpconv) with spatiotemporal partial convolutional
layers. Notice that masks are omitted in the illustration but pass the network similarly to X.

convolution applies striding. Each partial convolutional layer is followed by a leaky ReLU (α = 0.1)
activation function. Once the lowest spatiotemporal resolution is reached, the output is upsampled
again to increase spatiotemporal resolution. The upsampled output is then concatenated with the
output of the associated block from the convolutional phase, before another partial convolutional
block (without striding) and leaky ReLU activation is applied and ﬁnally the original size of the
block is reached.

Gaps are ﬁlled during the encoder part, while individual partial convolutions are applied. Using
larger kernels and applying more and/or larger striding result in a faster ﬁlling of gaps. The depth
of the model hence must be adapted to the size of the gaps to make sure that all gaps become ﬁlled.
Figure 1 illustrates the basic architecture of the model in an example, where spatiotemporal
blocks have size 128 × 128 × 16, spatiotemporal resolution is reduced by a striding factor of 2 in all
dimensions, there are three partial convolutional blocks in the encoder, each consisting of a single
partial convolutional layer, and the channel depth is increased as the spatiotemporal resolution is
decreased by using an increasing number of ﬁlters.

The proposed model is highly customizable. Table 1 lists important hyperparameters with

regard to the model architecture, training, and data preparation.

Our implementation (Section 2.5) allows to deﬁne architectural parameters diﬀerently per di-
mensions. For example, it is possible to add purely temporal or spatial partial convolutional blocks,
and to deﬁne diﬀerent kernel sizes in space and time. This can be used to optimize the model for
speciﬁc spatiotemporal phenomena, depending on spatial and temporal resolution and autocorre-
lations.

4

Table 1: Important hyperparameters related to the model architecture, model training, and data
preparation.

Model architecture

Model training

Data

Number of convolutional blocks
Convolutional layers per block
Spatiotemporal striding

Loss function
Optimizer
Learning rate

Kernel sizes
Number of ﬁlters

Batch size
. . .

Block-size
n
Transformations, trend / seasonality re-
moval
Method to add gaps
. . .

2.3 Addition of artiﬁcial gaps

To assess prediction errors during model training and validation, data must be predicted at locations
with available measurements. Since the aim is to predict (larger) gaps, the following strategy to
add artiﬁcial gaps to the input is applied.

For each time slice in a spatiotemporal block Y :

1. Simulate a two-dimensional Gaussian random ﬁeld using a predeﬁned covariance function
cov(s, s(cid:48)) depending on the spatiotemporal distance between pairs of observations at spa-
tiotemporal locations s and s(cid:48) within a block.

2. Apply a threshold to select a moderate amount of data.

3. Mask corresponding pixels from Y to create X.

X is then the input to our model and Y the target data used for training and validation. The
ﬁnal amount of missing data in X depends on both, the original amount of missing values in Y as
well as on the amount of missing values in the synthetic mask. Since the former varies strongly
among the data, the amount of missing values in the synthetic mask is less important than the
actual shape of added masks. To allow the model to learn long range predictions of a process, it
is important to generate artiﬁcial gaps of diﬀerent sizes instead of just leaving out random pixels,
resulting in only very small gaps. Figure 2 illustrates how the additional mask is applied on a single
time slice of a spatiotemporal block.

2.4 Model training

We directly use the prediction error of values that have been omitted by the artiﬁcially added masks
(Section 2.3) in our loss function and simply use the mean absolute error of observations that are
available in Y but not in X.

5

Figure 2: Original image Y (left), additional mask (center) and masked image X (right) of a single
time slice. X is used as input to the model.

Notice that it is of course possible to consider observations that are available in both Y and X
and also the smoothness of transitions at gap boundaries (Xing et al., 2022) in individual or in a
combined loss function. Similarly, absolute errors can be replaced by squared errors to put more
weight on outliers or extreme values. However, in the experiments (Section 3.2), the choice and the
design of the loss function had no clear eﬀect of prediction performance and we therefore used the
simple MAE metrics.

We used the Adam optimizer (Kingma and Ba, 2014) and an initial learning rate of 0.005 that

is divided by 10 after every 10 epochs. Training runs for at least 30 epochs.

2.5 Implementation

We implemented the partial convolutions in Python (Van Rossum and Drake, 2009) using Tensor-
Flow (Abadi et al., 2015) with Keras (Chollet et al., 2015). The implementation contains a class
for three-dimensional partial convolutional layers and a class for the U-Net-like model that can be
customized by hyperparameters (see Table 1). Notice that we reuse the original implementation
of ordinary convolutional layers and an available open-source implementation of two-dimensional
partial convolutions in Keras1.

The source code of our implementation, including a small example dataset and a pre-trained

model, is available on GitHub2.

1see https://github.com/MathiasGruber/PConv-Keras
2https://github.com/appelmar/STpconv

6

3 Application to Sentinel-5P data

To validate the proposed gap ﬁlling approach, we used imagery from the European Sentinel-5P
mission for satellite-based monitoring of the atmosphere. The TROPOMI instrument on board of
the satellite measures atmospheric variables (total column observations of carbon monoxide, ozone,
methane, nitrogen dioxide, and others3) at high spatial resolution up to 3.5 km x 5.5 km and a revisit
time of one day. Recently, Sentinel-5P NO2 observations have been integrated into operational
Copernicus Atmosphere Monitoring Service forecasts by the European Centre for Medium-Range
Weather Forecasts.

For the experiments, we downloaded 4518 images of total column carbon monoxide observations
and corresponding per-pixel quality assessment images of the oﬄine processing stream from the
Sentinel-5P Level 2 open data catalog on Amazon Web Services4.
Images have been recorded
between 2021-01-01 and 2021-11-25.

3.1 Data preprocessing

We resampled the data to 0.1 degree spatial resolution, derived daily aggregates, cropped to lati-
tudes between -60 and 60 degrees, and, following the oﬃcial recommendation (Sentinel-5P Mission
Performance Centre, 2021), only used pixels with quality value larger than 0.5. Figure 3 shows the
availability of valid observations of the resulting dataset.

At most of the locations, less than 20% of the days are missing in the prepared dataset. Some
exceptions include the Northern coast of Australia, the Argentinian coast in the southern Atlantic
ocean, Southeast Asia, and further coastal areas.

As a next step, we divided the data into spatiotemporal blocks of size 128 × 128 × 16. We
used a smaller block size in time, because gaps are typically larger in space. Furthermore, spatial
autocorrelations between any two pixels are expected to show a longer range compared to temporal
autocorrelations.

All of the preprocessing steps including the resampling, aggregation, cropping, and ﬁltering
have been performed in R (R Core Team, 2022) using the gdalcubes package (Appel and Pebesma,
2019).

3.2 Experiments

To assess the performance of predictions, we randomly selected 500 spatiotemporal blocks for
model training and applied two diﬀerent validation strategies on additional 250 randomly selected

3http://www.tropomi.eu/data-products/level-2-products
4see https://registry.opendata.aws/sentinel5

7

Figure 3: Percentage of missing values per pixel time series after daily aggregation, cropping, and
ﬁltering by quality values (QA > 0.5). Contains modiﬁed Copernicus Sentinel data [2021].

validation blocks:

1. We added artiﬁcial gaps as for the training data (see Section 2.3), predict missing values, and
computed prediction scores for predicted values that have been missing in X but available in
Y .

2. We used all available data but completely left out the last time slice of a block, which was

then predicted and used to calculate prediction scores.

In the following, the validation strategies are referred to as gap ﬁlling and one-step ahead
predictions respectively. We used mean absolute error (MAE) and root mean squared error (RMSE)
as metrics and additionally calculated average computation times for predicting single blocks. Error
metrics refer only to pixels that have been additionally left out but do not include predictions of
pixels that were available in both X and Y .

As a benchmark, we furthermore applied two naive methods (simple block-wise mean prediction
and linear time series interpolation). The block-wise mean predictions simply use the empirical
mean from all available observations of a block for all missing values whereas the time series
interpolation independently interpolates time series of a block. We use the NumPy (Harris et al.,
2020) implementation in numpy.interp, with default parameters, meaning that if time series start
or end with missing values, the ﬁrst / last available observation is carried forward / backward. If a
time series has no valid observations, it is not predicted and omitted in the calculation of prediction
scores.

8

As alternative data-driven approaches, we applied two statistical approaches on the same val-
idation dataset. First, the method described in Gerber et al. (2018), which we refer to as gapﬁll,
constructs a spatiotemporal neighborhood for each missing value, whose size is increased until
enough observations are available. Quantile regression is then applied on values in the neighbor-
hood. This not only allows to predict the median but also to quantify prediction uncertainties as
conﬁdence intervals. For details, the reader is referred to the original publication in Gerber et al.
(2018).

Second, we applied an eﬃcient approximation of spatiotemporal Gaussian processes called multi-
resolution approximations (referred to as stmra) as proposed in Appel and Pebesma (2020). This
approach recursively partitions the area of interest into smaller regions, assuming conditional in-
dependence between diﬀerent regions at the same partitioning level, and uses a basis function
representation of processes within regions to approximate residuals from previous partitioning lev-
els. Compared to traditional Geostatistical modeling, this approach can be used for large datasets
but still requires ﬁtting a spatiotemporal covariance model. For simplicity, we used a separable
spatiotemporal covariance function where both functions use the exponential covariance model.
Corresponding parameters have been ﬁtted based on 10 randomly selected blocks.

For computation time measurements, a single CPU core was used and the average after predict-
ing all blocks from the validation set has been calculated. Computations have been executed on an
Intel Core i7-7700HQ CPU with 16 GB main memory, and a 512 GB solid-state drive. Notice that
our STpconv model has been trained on a NVIDIA A100 GPU with 40GB VRAM, before.

After trying out models with diﬀerent complexities, diﬀerent optimizers, and loss functions, a
relatively small model with less than 50000 parameters has been selected for the experiment. This
model turned out to oﬀer a good compromise of prediction performance and computation times.
Details of the model can be found in the Appendix (Table 3).

4 Results

4.1 Prediction performance

Table 2 presents results of the experiments for diﬀerent models and both validation strategies.

For gap ﬁlling, the statistical and STpconv models outperformed the naive approaches in terms
of MAE and RMSE. Among the non-naive methods, stmra performed best for MAE but worst in
terms of RMSE, suggesting that stmra had diﬃculties for predicting outliers or extreme values. In
general, gapﬁll seems to achieve slightly better predictions than our partial convolutional neural
network. However, gapﬁll is not applicable to one-step ahead forecasting where a complete time
slice is missing because it cannot ﬁnd a suitable neighborhood. stmra performed signiﬁcantly worse

9

Table 2: Prediction errors and computation times of diﬀerent models and validation strategies.
STpconv refers to the proposed model based on spatiotemporal partial convolutions.

Gap ﬁlling

One-step ahead forecasts

MAE

RMSE

MAE

RMSE

t (s)

Block-wise mean
Time series interp.
gapﬁll (Gerber et al., 2018)
stmra (Appel and Pebesma, 2020)
STpconv

0.00274
0.00245
0.00166
0.00155
0.00186

0.00443
0.00412
0.00302
0.00333
0.00321

0.00295
0.00276
NA
0.01062
0.00243

0.00437
0.00421

0.02
0.51
NA 1480.23
159.96
0.44

0.01168
0.00357

for one-step ahead forecasting and our STpconv model clearly performs best.

Interestingly, predictions with the partial convolution model have been even slightly faster than
simple time series interpolation, and approximately 300 and 3000 times faster compared to stmra
and gapﬁll respectively. However, notice that the computation time measurements include only the
prediction but not model ﬁtting. Training the STpconv model on 500 spatiotemporal blocks took
20 minutes on a powerful GPU. In contrast, parameter optimization of the stmra approach took
approximately 30 minutes on 10 randomly selected blocks using a CPU. However, the optimization
time for stmra is generally hard to estimate in advance and can vary strongly for diﬀerent starting
values, covariance functions, and similar (Appel and Pebesma, 2020). gapﬁll and the naive methods
do not require any model ﬁtting at all.

Figure 4 additionally shows prediction errors of individual spatiotemporal blocks for gap ﬁlling
plotted by their percentage of missing values. Here, we compare only our STpconv with gapﬁll but
the results look very similar. Prediction errors seem relatively independent from the percentage of
missing values even up to 90% missing data. Interestingly, outliers with larger prediction errors
refer to the same tiles for both approaches, though their RMSE values of course diﬀers.

4.2 Visual comparison

Figure 5 shows input and predictions of ﬁve example time slices for the two statistical models and
the model based on partial convolutions.

Predictions from the gapﬁll approach show relatively ﬁne details, mostly including the typical
vertical stripe pattern. Due to the selection of local neighborhoods for ﬁlling individual pixels, there
are some sharp edges. The stmra approach shows visible artefacts due to the recursive partitioning

10

Figure 4: RMSE of individual spatiotemporal blocks by their percentage of missing values for
predictions from STpconv (left) and gapﬁll (right). Each dot represents a block in the validation
dataset and the x axis refers to the percentage of missing values in the input block (including added
gaps).

of the area of interest, although the corresponding MAE was best for gap ﬁlling. A model averaging
using shifted partitioning grids was not performed but would reduce artefacts (Appel and Pebesma,
2020). Predictions from the three-dimensional partial convolutions are relatively smooth, such that
the vertical stripe pattern is less visible in predicted areas.

4.3 CO mapping

We used the trained model to ﬁll gaps in the original dataset and produce quasi-global (60°S –
60°N) daily maps of total column CO for the time range of the data. Figure 6 shows a few days
of the original incomplete and the corresponding ﬁlled images. Animated predictions can be found
in the supplementary material of this paper5. To reduce artefacts at block boundaries, an overlap
has been applied. For each spatiotemporal block, only inner observations (leaving out a few pixels
at each side) are taken as predictions while adjacent blocks overlap by two-times the number of
left-out pixels.

Notice that Figure 6 shows complete predictions, i.e. the model output without merging with
true observations, where available. The results look relatively smooth and do not show any obvious
block artefacts. The general dynamics of the process seems well preserved. As expected, extremes
tend to be underestimated.
Interestingly, the gap ﬁlled animation reveals some clearly visible
pattern of extreme values above the south-west Atlanic Ocean, mostly close to the south American
coastline. These extreme values up to 0.7 mol m−2 also occur in the original data but are only

5for now, available at http://appel.staff.ifgi.de/S5P_CO_demo.html

11

Figure 5: Input and predictions of (left to right) ﬁve time slices using (from top to bottom) gapﬁll,
stmra, and STpconv. Contains modiﬁed Copernicus Sentinel data [2021].

12

Figure 6: Global daily original dataset (left) and model predictions (right) at 6 consecutive days.
Contains modiﬁed Copernicus Sentinel data [2021].

13

hardly visible due to the gaps.

5 Discussion

Neural networks with spatiotemporal partial convolutional layers turned out to be able to eﬃciently
ﬁll gaps in atmopsheric (Sentinel-5P) image time series. While prediction errors in the experiments
were similar to complex statistical models, computation times for prediction even outperformed
naive time series interpolation. For model training, a powerful GPU is required although training
times have been reasonable. Such GPUs are also available on cloud computing platforms for a few
USD per hour6, resulting in less than 3 USD total costs for training in our case.

However, compared to the naive and statistical approaches, models based on partial convolutions
come with the risk of excessive prediction errors under extrapolation conditions i.e., when the neural
network is applied to data dissimilar to the input data in the training set (Meyer and Pebesma,
2021), or if there is hardly any observation available in a block. More complex loss functions could
improve the robustness of predictions. For example, terms that penalize if block-wise means of
predictions deviate too much from actual means of available pixels could be added. The approach
also does not provide uncertainty estimates such as prediction intervals as the statistical models
do. Zammit-Mangion and Wikle (2020) therefore integrate a CNN for modeling spatiotemporal
dynamics into a hierarchical statistical framework.

This study has not investigated how well models based on spatiotemporal partial convolutions
work for other types of data such as optical imagery, or land surface temperatures. Xing et al.
(2022) suggest that a similar method based on partial convolutions seems to work well for snow
cover mapping, too. Similarly, it would be interesting to study how models trained on one variable
can be used to predict other variables. Figure 7 exemplarily shows results when the model trained
on CO observations is applied to NO2 data, after scaling to a similar value range. However, further
experiments are needed to evaluate model transferability among other Sentinel-5P variables. To
improve predictions, it might also be important to add other Sentinel-5P variables and/or further
external variables such as elevation to the model.

Given the amount of hyperparameters, tuning can be time consuming and make the optimization
of the model architecture, data preprocessing, and similar to speciﬁc datasets diﬃcult in practical
applications. In the presented experiments, we have found that data-related parameters such as the
spatiotemporal block size had a stronger eﬀect on prediction performance compared to architectural
parameters such as the number of ﬁlters per layer. However, this might me diﬀerent when using
much larger sets of training data. Further, it would be possible to use partial convolutional layers in

6see, e.g. https://aws.amazon.com/de/ec2/instance-types/p3 (accessed 2022-05-20)

14

Figure 7: Results after applying a model that has been trained on CO data to NO2 observations.
The top row shows six original NO2 time slices, where one slice is completely missing, and the bot-
tom row shows gaps ﬁlled with corresponding predictions. Contains modiﬁed Copernicus Sentinel
data [2021].

15

other model architectures than the presented U-Net-like model. For example, it would be interesting
to explore models following the idea of residual neural networks (He et al., 2016), where data at
diﬀerent spatial and/or temporal resolutions is provided as input to the model and residuals from
ﬁlling gaps at lower resolution are recursively considered by partial convolutional blocks.

DL based models have become promising for modeling the dynamics of continuous spatiotem-
poral phenomena (De B´ezenac et al., 2019; Zammit-Mangion and Wikle, 2020; Rasp and Thuerey,
2021; Keisler, 2022). Since the abundance of gaps in satellite-derived observations makes their
application often diﬃcult, it would be very interesting to integrate partial convolutions into similar
models applied on incomplete data. As a ﬁrst experiment, one could replace convolutional layers
in De B´ezenac et al. (2019) with partial convolutional layers and study how the performance of
forecasts changes with the amount of missing values.

6 Conclusions

This paper discussed the use of neural networks based on partial convolutional layers for eﬃciently
ﬁlling gaps in satellite image time series. Prediction results have been comparable to statistical
methods while computations of predictions were between two and three orders of magnitude faster.
However, future research should be conducted to assess model transferability and prediction errors,
and to combine the approach with deep learning models of spatiotemporal dynamics in Earth
observation data.

Acknowledgments

This research has been funded by the Deutsche Forschungsgemeinschaft (DFG, German Research
Foundation) – 396611854. Thanks to Edzer Pebesma for comments and suggestions to improve the
ﬁnal manuscript.

Data availability statement

Data used for model training and validation have been made available on Zenodo under the DOI
10.5281/zenodo.6838651 (Appel, 2022). The dataset also includes predictions from other models
discussed in Section 3.2.

To reproduce results, the method has been made available as open-source software at GitHub7.

7https://github.com/appelmar/STpconv

16

Appendix

Model details

Table 3: Selected hyperparameters of the used model with partial convolutions.

Parameter

Value

Number of partial convolutional blocks
Partial convolutional layers per block
Spatiotemporal striding for all blocks
Kernel sizes
Number of ﬁlters per block
Loss function
Optimizer
Learning rate
Batch size
Data block size
Transformations

2
1
[2, 2, 2]
[3, 3, 3]
[16, 16]
MAE (on gap pixels only)
Adam
adaptive (initially 0.005)
6
[128, 128, 16]
None

17

References

Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G. S., Davis,
A., Dean, J., Devin, M., Ghemawat, S., Goodfellow, I., Harp, A., Irving, G., Isard, M., Jia,
Y., Jozefowicz, R., Kaiser, L., Kudlur, M., Levenberg, J., Man´e, D., Monga, R., Moore, S.,
Murray, D., Olah, C., Schuster, M., Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker,
P., Vanhoucke, V., Vasudevan, V., Vi´egas, F., Vinyals, O., Warden, P., Wattenberg, M., Wicke,
M., Yu, Y., and Zheng, X. (2015). TensorFlow: Large-scale machine learning on heterogeneous
systems. Software available from tensorﬂow.org.

Amato, F., Guignard, F., Robert, S., and Kanevski, M. (2020). A novel framework for spatio-
temporal prediction of environmental data using deep learning. Scientiﬁc reports, 10(1):1–11.

Appel, M. (2022). Training and validation data for artiﬁcial neural networks using three-dimensional

partial convolutions to ﬁll gaps in satellite image time series.

Appel, M. and Pebesma, E. (2019). On-demand processing of data cubes from satellite image

collections with the gdalcubes library. Data, 4(3):92.

Appel, M. and Pebesma, E. (2020). Spatiotemporal multi-resolution approximations for analyzing

global environmental data. Spatial Statistics, 38:100465.

Camps-Valls, G., Svendsen, D. H., Cort´es-Andr´es, J., Mareno-Mart´ınez, ´A., P´erez-Suay, A.,
Adsuara, J., Mart´ın, I., Piles, M., Mu˜noz-Mar´ı, J., and Martino, L. (2021). Physics-aware
machine learning for geosciences and remote sensing. In 2021 IEEE International Geoscience
and Remote Sensing Symposium IGARSS, pages 2086–2089. IEEE.

Chollet, F. et al. (2015). Keras. https://keras.io.

Cressie, N. and Johannesson, G. (2008). Fixed rank kriging for very large spatial data sets. Journal

of the Royal Statistical Society: Series B (Statistical Methodology), 70(1):209–226.

De B´ezenac, E., Pajot, A., and Gallinari, P. (2019). Deep learning for physical processes: Incor-
porating prior scientiﬁc knowledge. Journal of Statistical Mechanics: Theory and Experiment,
2019(12):124009.

ElSaadani, M., Habib, E., Abdelhameed, A. M., and Bayoumi, M. (2021). Assessment of a spa-
tiotemporal deep learning approach for soil moisture prediction and ﬁlling the gaps in between
soil moisture observations. Frontiers in artiﬁcial intelligence, 4.

18

Fischer, R., Piatkowski, N., Pelletier, C., Webb, G. I., Petitjean, F., and Morik, K. (2020). No cloud
on the horizon: Probabilistic gap ﬁlling in satellite image series. In 2020 IEEE 7th International
Conference on Data Science and Advanced Analytics (DSAA), pages 546–555.

Gerber, F., de Jong, R., Schaepman, M. E., Schaepman-Strub, G., and Furrer, R. (2018). Predicting
missing values in spatio-temporal remote sensing data. IEEE Transactions on Geoscience and
Remote Sensing, 56(5):2841–2853.

Ghafarian Malamiri, H. R., Rousta, I., Olafsson, H., Zare, H., and Zhang, H. (2018). Gap-ﬁlling of
modis time series land surface temperature (lst) products using singular spectrum analysis (ssa).
Atmosphere, 9(9):334.

Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D.,
Wieser, E., Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S., van Kerkwijk,
M. H., Brett, M., Haldane, A., del R´ıo, J. F., Wiebe, M., Peterson, P., G´erard-Marchant, P.,
Sheppard, K., Reddy, T., Weckesser, W., Abbasi, H., Gohlke, C., and Oliphant, T. E. (2020).
Array programming with NumPy. Nature, 585(7825):357–362.

He, K., Zhang, X., Ren, S., and Sun, J. (2016). Deep residual learning for image recognition. In
2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770–778.

Keisler, R. (2022). Forecasting global weather with graph neural networks.

arXiv preprint

arXiv:2202.07575.

Kingma, D. P. and Ba, J. (2014). Adam: A method for stochastic optimization.

Liu, G., Reda, F. A., Shih, K. J., Wang, T.-C., Tao, A., and Catanzaro, B. (2018). Image inpainting
for irregular holes using partial convolutions. In Ferrari, V., Hebert, M., Sminchisescu, C., and
Weiss, Y., editors, Computer Vision – ECCV 2018, pages 89–105, Cham. Springer International
Publishing.

Meyer, H. and Pebesma, E. (2021). Predicting into unknown space? estimating the area of appli-

cability of spatial prediction models. Methods in Ecology and Evolution, 12(9):1620–1633.

R Core Team (2022). R: A Language and Environment for Statistical Computing. R Foundation

for Statistical Computing, Vienna, Austria.

Rasp, S. and Thuerey, N. (2021). Data-driven medium-range weather prediction with a resnet
pretrained on climate simulations: A new model for weatherbench. Journal of Advances in
Modeling Earth Systems, 13(2):e2020MS002405.

19

Reichstein, M., Camps-Valls, G., Stevens, B., Jung, M., Denzler, J., Carvalhais, N., et al.
(2019). Deep learning and process understanding for data-driven earth system science. Nature,
566(7743):195–204.

Ronneberger, O., Fischer, P., and Brox, T. (2015). U-net: Convolutional networks for biomedical
In Navab, N., Hornegger, J., Wells, W. M., and Frangi, A. F., editors,
image segmentation.
Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015, pages 234–241,
Cham. Springer International Publishing.

Sentinel-5P Mission Performance Centre (2021). Sentinel-5p carbon monoxide level 2 product

readme ﬁle. available online [accessed 2022-05-18].

v. Buttlar, J., Zscheischler, J., and Mahecha, M. D. (2014). An extended approach for spatiotem-
poral gapﬁlling: dealing with large and systematic gaps in geoscientiﬁc datasets. Nonlinear
Processes in Geophysics, 21(1):203–215.

Van Rossum, G. and Drake, F. L. (2009). Python 3 Reference Manual. CreateSpace, Scotts Valley,

CA.

Wang, G., Garcia, D., Liu, Y., de Jeu, R., and Johannes Dolman, A. (2012). A three-dimensional
gap ﬁlling method for large geophysical datasets: Application to global satellite soil moisture
observations. Environmental Modelling & Software, 30:139–142.

Xing, D., Hou, J., Huang, C., and Zhang, W. (2022). Spatiotemporal reconstruction of modis
normalized diﬀerence snow index products using u-net with partial convolutions. Remote Sensing,
14(8).

Zammit-Mangion, A. and Wikle, C. K. (2020). Deep integro-diﬀerence equation models for spatio-

temporal forecasting. Spatial Statistics, 37:100408.

20

