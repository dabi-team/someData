2
2
0
2

r
p
A
4

]
E
S
.
s
c
[

1
v
4
3
8
1
0
.
4
0
2
2
:
v
i
X
r
a

Lifelong Self-Adaptation: Self-Adaptation Meets Lifelong
Machine Learning

Omid Gheibi
Katholieke Universiteit Leuven
Leuven, Belgium
omid.gheibi@kuleuven.be

Danny Weyns
Katholieke Universiteit Leuven, Belgium
Linnaeus University, Sweden
danny.weyns@kuleuven.be

ABSTRACT
In the past years, machine learning (ML) has become a popular
approach to support self-adaptation. While ML techniques enable
dealing with several problems in self-adaptation, such as scalable
decision-making, they are also subject to inherent challenges. In this
paper, we focus on one such challenge that is particularly important
for self-adaptation: ML techniques are designed to deal with a set of
predefined tasks associated with an operational domain; they have
problems to deal with new emerging tasks, such as concept shift
in input data that is used for learning. To tackle this challenge, we
present lifelong self-adaptation: a novel approach to self-adaptation
that enhances self-adaptive systems that use ML techniques with a
lifelong ML layer. The lifelong ML layer tracks the running system
and its environment, associates this knowledge with the current
tasks, identifies new tasks based on differentiations, and updates the
learning models of the self-adaptive system accordingly. We present
a reusable architecture for lifelong self-adaptation and apply it to
the case of concept drift caused by unforeseen changes of the input
data of a learning model that is used for decision-making in self-
adaptation. We validate lifelong self-adaptation for two types of
concept drift using two cases.

ACM Reference Format:
Omid Gheibi and Danny Weyns. 2022. Lifelong Self-Adaptation: Self-
Adaptation Meets Lifelong Machine Learning. In 17th International Sym-
posium on Software Engineering for Adaptive and Self-Managing Systems
(SEAMS ‚Äô22), May 18‚Äì23, 2022, PITTSBURGH, PA, USA. ACM, New York, NY,
USA, 12 pages. https://doi.org/10.1145/3524844.3528052

1 INTRODUCTION
Self-adaptation equips a software system with a feedback loop that
monitors the system and its environment and applies changes to
the system when needed to realize a set of adaptation goals [16, 59].
Self-adaptation has been pivotal in automating tasks that otherwise
need to be realized by operators [23, 35], in particular tasks that
are related to uncertainties that the system may face during its
lifetime [20, 30].

Over the past years, we have observed an increasing trend in the
use of machine learning (ML in short) to support self-adaptation. A
recent systematic literature review [26] shows that the number of ar-
ticles published on this topic has been doubled every two years since
2014. For instance, ML has been used for efficient decision-making
by reducing large adaption spaces [45], for detecting abnormalities
in the flow of activities in the environment of the system [37], and
for learning changes of the system utility dynamically [24].

SEAMS ‚Äô22, May 18‚Äì23, 2022, PITTSBURGH, PA, USA
2022. ACM ISBN 978-1-4503-9305-8/22/05. . . $15.00
https://doi.org/10.1145/3524844.3528052

While ML techniques enable dealing with several problems in
software systems in general and self-adaptive systems in particular,
these techniques are subject to several engineering challenges. Ex-
amples are the need for specialized expertise when constructing ML
solutions, providing reliable and efficient testing of ML techniques,
dealing with unexpected events in the real operating environment
of the system, and obtaining adequate quality assurances for ML
applications [2, 38].

In this paper, we focus on one such challenge that is particularly
important for self-adaptive systems: dealing with new learning
tasks. In essence, ML techniques are designed to deal with a set
of predefined tasks that they solve based on data derived from
the operational domain of the system. Hence, they have problems
to deal with new emerging tasks and changes in the operational
domain. A typical example is new learning tasks that emerge due
to unforeseen changes of input data over time. Without proper
support, such problems require human intervention, which is time
consuming and costly. This leads us to the research problem that
we tackle in this paper:

How to enable self-adaptive systems that use machine
learning techniques to deal with new and changing
learning tasks during operation?

To tackle this research problem, we propose lifelong self-
adaptation: a novel approach to self-adaptation that enhances self-
adaptive systems with a lifelong ML layer. The lifelong ML layer
tracks the running system and its environment, associates the col-
lected knowledge with the current tasks, identifies new tasks based
on differentiations, and updates the learning models of the self-
adaptive system accordingly.

Lifelong self-adaptation leverages the principles of lifelong ma-
chine learning [15, 52] that offers an architectural approach for
continual learning of a machine learning system. Lifelong machine
learning adds a layer on top of a machine learning system that
selectively transfers the knowledge from previously learned tasks
to facilitate the learning of new tasks within an existing or new
domain [15]. Lifelong machine learning has been successfully com-
bined with a wide variety of learning techniques [15], including
supervised [50], interactive [3], and unsupervised learning [49].

Our focus in this paper is on self-adaptive systems that rely on
architecture-based adaptation [16, 18, 36, 61], where a self-adaptive
system consists of a managed system that operates in the environ-
ment and a managing system that manages the managed system to
deal with a set of adaptation goals. We focus on managing systems
that comply with the MAPE-K reference model, short for Monitor-
Analyse-Plan-Execute-Knowledge [35, 60]. Our particular focus
is on managing systems that use a ML technique to support any
of the MAPE-K functions. We make the assumption that dealing

 
 
 
 
 
 
SEAMS ‚Äô22, May 18‚Äì23, 2022, PITTSBURGH, PA, USA

Omid Gheibi and Danny Weyns

with new learning tasks does not require any runtime evolution
of the software of the managed and managing system; hence we
focus at handling new learning tasks that is realized by evolving
the learning models used by the managing system.

We study one concrete instance of new learning tasks in self-
adaptation: concept drift. Concept drift [58] refers to an unforeseen
change of the input data of a learning model that results in pre-
dictions becoming less accurate over time, which may jeopardize
the reliability of the system. We look at two types of concept drift:
sudden and incremental concept drift.

The concrete contributions of this paper are:

(1) A reusable architecture for lifelong self-adaptation;
(2) Two concrete instances of the architecture to deal with sud-

den and incremental concept drift respectively;

(3) A validation of the two instances of the architecture using
DeltaIoT [32] and a gas delivery system [54] respectively.

The remainder of this paper is structured as follows. In Sec-
tion 2, we provide a brief introduction of lifelong machine learn-
ing that provides the basic framework underlying lifelong self-
adaptation. Section 3 then introduces the novel approach for lifelong
self-adaptation. Next, we instantiate the architecture of a lifelong
self-adaptive system for sudden concept drift in Section 4 using
DeltaIoT for the evaluation. Section 5 instantiates the architecture
for incremental concept drift using a gas delivery case. In Section 6
we discuss threats to validity, and Section 7 presents related work.
Finally, we wrap up and outline opportunities for future research
in Section 8.

2 LIFELONG MACHINE LEARNING IN A

NUTSHELL

We briefly describe the basic principles of lifelong machine learning
that provide the basis for lifelong self-adaptation.

Lifelong machine learning is the ability of a machine-learning
system to learn new tasks that were not predefined when the sys-
tem was designed [53]. Technically, lifelong machine learning is a
continuous learning process of a learner [15]. Assume that at some
point in time, the learner has performed a sequence of ùëõ learning
tasks, T1, T2, ¬∑ ¬∑ ¬∑ , Tùëõ, called the previous tasks, that have their corre-
sponding data sets D1, D2, ¬∑ ¬∑ ¬∑ , Dùëõ. Tasks can be of different types
and from different domains. When faced with task Tùëõ+1 (called
the new or current task) with its data set Dùëõ+1, the learner can
leverage past knowledge maintained in a knowledge-base to help
learn task Tùëõ+1. The new task may be given by a stakeholder or
it may be discovered automatically by the system. Lifelong ma-
chine learning aims to optimize the performance of the learner
for the new task (or for an existing task by treating the rest of the
tasks as previous tasks). After completing learning task Tùëõ+1, the
knowledge base is updated with the new gained knowledge, e.g.,
using intermediate and final results obtained via learning. Updating
the knowledge can involve checking consistency, reasoning, and
mining meta-knowledge.

For example, consider a lifelong machine learning system for
the never-ending language learner [41] (NELL in short). NELL aims
at answering questions posed by users in natural language. To
that end, it sifts the Web 24/7 extracting facts, e.g., ‚ÄúParis is a city."
The system is equipped with a set of classifiers and deep learners

to categorize nouns and phrases, e.g., ‚Äúapple‚Äù can be classified
as ‚ÄúFood‚Äù and ‚ÄúCompany‚Äù falls under an ontology, and detecting
relations, e.g., ‚Äúserved-with‚Äù in ‚Äútea is served with biscuits.‚Äù NELL
can infer new beliefs from this extracted knowledge, and based on
the recently collected web documents, NELL can expand relations
between existing noun phrases or the ontology. This expansion
can be a change within existing ontological domains, e.g., politics
or sociology, or be a new domain like internet-of-things. Hence,
the expansion causes an emerging task like classifying new noun
phrases for the expanded part of the ontology.

Lifelong machine learning works together with different types of
learners. In lifelong supervised learning, every learning task aims at
recognizing a particular class or concept. E.g., in cumulative learn-
ing, identifying a new class or concept is used to build a new multi-
class classifier for all the existing and new classes using the old
classifier [21]. Lifelong unsupervised learning focuses on topic mod-
eling and lifelong information extraction, e.g., by mining knowledge
from topics resulting from previous tasks to help generating better
topics for new tasks [57]. In lifelong semi-supervised learning, the
learner enhances the number of relationships in its knowledge base
by learning new facts, for instance, in the NELL system [41]. Finally,
in lifelong reinforcement learning each environment is treated as
a task [51], or a continual-learning agent solves complex tasks by
learning easy tasks first [47]. Recently, lifelong learning has gained
increasing attention, in particular for autonomous learning agents
and robots based on neural networks [44].

One of challenges for lifelong machine learning is dealing with
catastrophic forgetting, i.e., the loss of what was previously learned
while learning new information, which can lead to system fail-
ures [42]. Another challenge for any machine learning pipeline is
under-specification, i.e., a significant decrease of the performance
of a learning model from training to deployment (or testing) [17].
Promising approaches have been proposed, see e.g., [44] for catas-
trofic forgetting or [46] for under-specification. Yet, more research
is required to transfer these techniques to real-world systems.

3 LIFELONG SELF-ADAPTATION
We now introduce the novel approach of lifelong self-adaptation
that enables self-adaptive systems that use machine learning tech-
niques to deal with new learning tasks during operation. We start
with assumptions and requirements for lifelong self-adaptation.
Then we present the architecture of a lifelong self-adaptive system,
explain how it deals with new tasks, and introduce instances for
two types of concept drift.

3.1 Assumptions for Lifelong Self-Adaptation
The assumptions that underlie the approach for lifelong self-
adaptation presented in this paper are:

‚Ä¢ The self-adaptive system comprises a managed system that
realizes the domain goals for users in the environment, and
a managing system that interacts with the managed system
and realizes the adaptation goals;

‚Ä¢ The managing system is equipped with a learner that sup-

ports the realization of self-adaptation;

‚Ä¢ The self-adaptive system provides the probes to collect the
data that is required for realizing lifelong self-adaptation; this

Lifelong Self-Adaptation: Self-Adaptation Meets Lifelong Machine Learning

SEAMS ‚Äô22, May 18‚Äì23, 2022, PITTSBURGH, PA, USA

Figure 1: The architecture of a lifelong self-adaptive system

may include an interface to the user to support the lifelong
self-adaptation process if needed;

‚Ä¢ The managing system provides the necessary interface to

adapt the learning models.

realize the adaptation goals. The managing system comprises the
MAPE components that share knowledge. A learner supports the
MAPE functions. The learning models are stored in the knowledge.
The system may request an operator for input (active learning).

In addition, we only consider new learning tasks that require
evolution of the learning models; runtime evolution of the software
of the managed or managing system is out of scope.

3.2 Requirements for Lifelong Self-Adaptation
The lifelong self-adaptive systems should:

R1 Provide the means to collect and manage the data that is

required to deal with new tasks;

R2 Be able to discover new tasks based on the collected data;
R3 Be able to determine the required evolution of the learning

models to deal with the new tasks;

R4 Evolve the learning models such that they can deal with the

new tasks.

3.3 Architecture of Lifelong Self-Adaptive

Systems

Figure 1 shows the architecture of a lifelong self-adaptive system.
We zoom in on the role of each component and explain the flow of
activities to deal with new and changing tasks.

Managed System. Takes input from the environment and realizes

the domain goals for the users of the system.

Managing System. Monitors the managed system and environ-
ment and executes adaptation actions on the managed system to

Lifelong Learning Loop. Adds a meta-layer on top of the manag-
ing system, leveraging the principles of lifelong machine learning.
This layer tracks the layers beneath and when it detects a new
learning task, it will evolve the learning models of the learner ac-
cordingly. We elaborate now on the components of the lifelong
learning loop and their interactions.

Knowledge Manager. Stores all knowledge that is relevant to the
learning tasks of the learner of the managing system (realizing
requirement R1). In each adaptation cycle, the knowledge manager
collects a knowledge triplet: ùëòùëñ = ‚ü®inputùëñ , stateùëñ , outputùëñ ‚ü©. Input are
the properties and uncertainties of the system and its environment
(activity 1.1). State refers to data of the managing system relevant
to the learning tasks, e.g., settings of the learner (1.2). Output refers
to the actions applied by the managing system to the managed
system (1.3). Sets of knowledge triplets are labeled with tasks, i.e.,
‚ü®tùëñ , {kùë¢ , kùë£, kùë§ }‚ü©, a responsibility of the task manager. The labeled
triplets are stored in the knowledge tasks repository.

Depending on the domain, the knowledge manager may reason
about new knowledge or mine the knowledge extracting (or up-
dating) meta-knowledge, such as a cache or an ontology (1.4). The
meta-knowledge can be used by the other components of the life-
long learning loop to enhance their performance. The knowledge
manager may synthesize parts of the knowledge to manage the

Managed Systemmonitor properties &uncertainties execute adaptationactionsKnowledge 1.1: observe monitored data1.3 observe¬† executed actions2.1: collect  new knowledgeTask Manager2.3: inform detected (new) tasksKnowledge-basedLearnerTask-basedKnowledge Miner3.1: query knowledge for tasks3.1.1: collect knowledge  for tasks3.2: return knowledge  for the tasksStakeholder/ Operatorrequest for input(optional)3.1.2: collect additional¬†knowledge for tasks (optional)3.1.3: update  knowledge (optional)2.2: update  knowledge tasks3.4: update learningmodelsLifelong Learning LoopLearning ModelsMAPE-based Feedback LoopEffectorProbeManaging System1.2: observestate of learner¬†1.4: process dataLearner Knowledge TasksKnowledge ManagerMeta-Knowlegde3.3: evolve  learning modelsSEAMS ‚Äô22, May 18‚Äì23, 2022, PITTSBURGH, PA, USA

Omid Gheibi and Danny Weyns

amount of stored knowledge (e.g., outdated or redundant tuples
may be marked or removed).

Task manager. Is responsible for detecting new learning tasks
(realizing R2). The task manager periodically retrieves new knowl-
edge triplets from the knowledge manager (2.1). The duration of
a period is domain-specific and can be one or more adaptation
cycles of the managing system. The task manager then identifies
task labels for the retrieved knowledge triplets. A triplet can be
assigned the label of an existing task or a new task. Each new task
label represents a (statistically) significant change in the data of
the knowledge triplets, e.g., a significant change in the distribution
of the data observed from the environment and managed system.
Hence, a knowledge triplet can be associated with multiple task
labels, depending on the overlap of their corresponding data (dis-
tributions). The task manager then returns the knowledge triplets
with the assigned task labels to the knowledge manager that up-
dates the knowledge accordingly (2.2). Finally, the task manager
informs the knowledge-based learner about the new tasks (2.3).

Knowledge-based learner. Decides how to evolve the learning
models of the learner of the managing system based on the collected
knowledge and associated tasks (realizing R3), and then enacts the
evolution of the learning models (realizing R4). To collect the knowl-
edge it needs for the detected learning tasks, the knowledge-based
learner queries the task-based knowledge miner (3.1) that returns
task-specific data (3.2); the working of the task-based knowledge
miner is explained below. The knowledge-based learner then uses
the collected data to evolve the learning models of the managing
system (3.3). This evolution is domain-specific and depends on
the type of learner at hand, e.g., tuning or retraining the learning
models for existing tasks, or generating and training new learn-
ing models for newly detected tasks. Finally, the knowledge-based
learner updates the learning models (3.4).

Task-based knowledge miner. Is responsible for collecting the data
that is required for evolving the learning models for given learning
task by the knowledge-based learner (supports realizing R3). As
a basis, the task-based knowledge miner retrieves the knowledge
triplets associated with the given task from the knowledge tasks
repository, possibly exploiting meta-knowledge, such as a cache
(3.1.1). Additionally, the task-based knowledge miner can mine the
knowledge repositories of the knowledge manager, e.g., to retrieve
knowledge of learning tasks that are related to the task requested
by the knowledge-based learner. Optionally, the task-based knowl-
edge miner may collect knowledge from stakeholders, for instance
to confirm labels of knowledge triplets (3.1.2). Finally, the miner
uses new knowledge to update the knowledge maintained in the
repositories by the knowledge manager (3.1.3), e.g., it may update
meta-knowledge about related tasks or add data to the knowledge
provided by stakeholders. For the use cases in the next sections, we
do not consider advanced reasoning and mining by the task-based
knowledge miner.

3.4 Lifelong Self-Adaptation for Concept Drift
The concrete problem of new learning tasks we tackle with lifelong
self-adaptation in this paper is concept drift. Concept drift refers to
a change of the statistical characteristics of data over time [6, 58],

which may deteriorate the performance of the learning models that
use that data to learn. Our focus is on co-variate drift, a common
form of concept drift, that arises when the distributions of labeled
data attributes change over time and the distribution of target values
remains invariant relative to the attributes [22, 58]. We study two
types of drift: sudden co-variate drift and incremental co-variate
drift. The next sections instantiate the architecture for lifelong
self-adaptation for these types and apply each solution to a case.

4 LIFELONG SELF-ADAPTATION TO DEAL
WITH SUDDEN CO-VARIATE DRIFT

To explain how lifelong self-adaption deals with sudden co-variate
drift we use the DeltaIoT artifact [32]. Figure 2 shows the setup
of the IoT network that consists of 15 battery-powered sensor
motes that measure parameters in the environment and send the
data via a wireless multi-hop network to a central gateway where
users can use the data. The communication in the network is time-
synchronized [40], i.e., neighboring motes are allocated slots where
they can send and receive messages over a wireless link as shown
in the figure.

Figure 2: DeltaIoT setup used for the evaluation [45]

The quality properties of interest in this paper are packet loss
and energy consumption. Figure 3 shows the utility preferences of
the stakeholders for the qualities of interest.

Figure 3: Utility preferences for qualities in DeltaIoT

The utility ùëàùëê of a network configuration is defined as:

ùëàùëê = 0.2 ¬∑ ùëùùëíùëê + 0.8 ¬∑ ùëùùëùùëô

(1)

with ùëùùëíùëê and ùëùùëùùëô the utility for energy consumption and packet
loss respectively, and 0.2 and 0.8 the weights associated with the

         [12,100][12,100][13,100][10,100][15,100][15,40]                  [12,60]  [12,10][12,90][7,100][8,100][2,100][8,100][2,100] [9,100][8,30]  [2,70]RFIDTemperatureMotionGateway[power,distribution]Wireless linkKEY[1][2][3][4][5][6][7][8][9][10][11][12][13][14][15][12][N] Node IdentifierExample sensor1100Packet loss (%)Utiliy preference113.4Energyconsumption (mC)Utiliy preference13.1130.50.25Lifelong Self-Adaptation: Self-Adaptation Meets Lifelong Machine Learning

SEAMS ‚Äô22, May 18‚Äì23, 2022, PITTSBURGH, PA, USA

quality properties. Users give max preference to an energy con-
sumption below 13 mC (milli Coulomb) and zero preference to
energy consumption above 13.4 mC. The utility for packet loss
decreases linearly between 0% and 100%.

The quality properties are affected by uncertainties. We consider
two types: network interference caused by environmental conditions
such as weather fluctuations, and load of messages generated by
motes that fluctuate based on different factors such as the presence
of people in the environment. The network interference affects the
Signal-to-Noise Ratio (SNR) [29] that determines packet loss.

To maximize the utility, we add a managing system at the gate-
way that monitors the managed system and its environment and
adapts the networks settings in each cycle. The power setting of
each node can be set (0 and 15), which will affect the SNR and
hence the packet loss, and the distribution of the messages along the
network links can be set (for motes with two links there settings
are: 0/100, 20/80, 40/60, 60/40, 80/20, 100/0). In total, there are
216 possible configurations.

The managing system decides about whether or not to adapt the
system after each communication cycle (8 minutes in our scenario).
To select a configuration, the managing system uses a learner that
predicts the quality attributes of the adaptation options (i.e., the
possible configurations), leveraging on [45]. Concretely, we use two
settings for the evaluation: a basic setting with a stochastic gradient
descent (SGD) regressor [48], and an additional setting that allows
switching between a SGD and a Hoeffding Adaptive Tree (HAT) [8].
An SGD regressor estimates the gradient of the loss for each data
sample and uses that to update the learning model with a decreasing
learning rate. A HAT regressor is an adaptive Hoeffding decision
tree that incrementally grows in different branches by detecting
different distributions in data. The regressors use feature vectors
that comprise the data of an adaptation option (power settings
and links‚Äô distributions) and the monitored uncertainties (SNR‚Äôs
of links and loads of messages). Based on these predictions, the
configuration with the highest utility is selected and used to adapt
the network configuration.

Figure 4: Global network interference in DeltaIoT; no con-
cept drift (green) vs. concept drift occurs recursively (gray)

Figure 5: Distributions of the signed differences of packet
loss between the true best options and the adaptation op-
tions selected by a SGD regressor with and without drift.

4.1 Problem
The problem is now that the distributions of input data that is
used by the regressors may drift over time. Figure 4 shows how
the global network interference changes when sudden concept
drift occurs. Such a concept drift may for instance occur due to
construction works in the neighbourhood of the IoT network where
some machinery may periodically produce extra noise affecting the
SNR of the network links [19].

Figure 5 shows the distribution of the signed difference between
the packet loss predicted by a SGD regressor (without lifelong self-
adaptation) and the true best options that are based on the true
values of the quality properties. We used here a scenario of 1500
adaptation cycles without and with drift.

The median of the signed error increases from 0.70% to 3.36% and
the mean from 0.98% to 6.84%, pointing to a significant increase in
packet loss. The underlying problem is that concept drift introduces
new emerging learning tasks that the regressors cannot handle. To
tackle this problem, we add a lifelong learning loop on top of the

managing system (instantiating the lifelong learning loop shown
in Figure 1).

4.2 Lifelong Learning Loop Instance
The lifelong learning loop is triggered every 20 adaptation cycles
of the managing system (empirically determined).

4.2.1 Knowledge Manager. Collects 20 new knowledge triplets per
cycle of the lifelong learning loop. Input of the triplets are packet
loss and energy consumption of the system (i.e., system properties),
and SNR‚Äôs for all links and the load of messages for each mote (i.e.,
uncertainties). State is meta-data about learner, including the con-
figuration of the learner such as the scaler used, the input vectors
that include the adaptation options, and the corresponding target
values predicted by the learning model. Output are the adaptation
actions applied for the selected adaptation option. In this instance,
the knowledge manager does not maintain any meta-knowledge.

02004006008001000120014000510152025303540No concept driftUnder concept driftAdaptation cycleNetwork Inteference (dB)No driftUnder drift‚àí5051015202530DiÔ¨Äerent scenariosSigned packet loss error (%)SEAMS ‚Äô22, May 18‚Äì23, 2022, PITTSBURGH, PA, USA

Omid Gheibi and Danny Weyns

4.2.2 Task Manager. Detects new tasks (i.e., new distribution of
features in the input data of knowledge triplets). We use auto-
encoders [4, 34, 62]. An auto-encoder is an artificial neural network
that learns to encode unlabeled data. Suppose at some point in
time, the system has knowledge about a set of previously detected
tasks denoted by T1, . . . , Tùëõ. These tasks have corresponding data
sets D1, . . . , Dùëõ, each data set consisting of knowledge triplets1,
and their corresponding auto-encoders AE1, . . . , AEùëõ. When trig-
gered, the task manager determines the statistical similarity2 be-
tween the outputs of each AEùëñ on the inputs of the newly observed
knowledge triplets and the outputs of AEùëñ on Dùëñ . If this similarity
is below a given threshold3 for all auto-encoders, the task manager
introduces a new task Tùëõ+1 with the new triplets as Dùëõ+1. Then the
task manager instantiates the auto-encoder AEùëõ+1 (i.e., selecting
the hyper-parameters: number of layers, neurons, etc.) for which
we use a Bayesian optimizer [43]. If the similarity is greater than the
threshold for at least one auto-encoder, the task manager assigns
label Tùëñ to corresponding triplets based on the highest achieved
similarity of AEùëñ . In the evaluation settings, we consider only the
case where a task manager detects one new task per cycle.

4.2.3 Knowledge-Based Learner. Evolves the learning models.
The function the knowledge-based learner is shown in Algo-
rithm 1. When informed about a detected (new) task (Line 1),
the knowledge-based learner queries appropriate knowledge spe-
cific to the task from the task-based knowledge miner (Line 2, see
the next part). Based on the collected data, the knowledge-based
learner determines the best learning models (Line 3 until Line 10).
The knowledge-based learner optimizes the hyper-parameters of
each learning model using a Bayesian optimizer (Line ??). The
knowledge-based learner then trains the best model based on the
collected training data (Line 8). When all learning models are
trained, they are updated in the knowledge repository of the feed-
back loop (Line 11).

4.2.4 Task-Based Knowledge Miner. Fetches the sets of knowledge
triplets from the knowledge manager for the tasks queried by the
knowledge-based learner. We limit the fetched data4 to keep the
training time of the knowledge-based learner at a constant and
appropriate level. The current instance of the task-based knowledge
miner applies no special mining.

4.3 Evaluation Results
We validated the instance of the lifelong self-adaptation architecture
using the DeltaIoT simulator. We used the setup presented above
(see Figure 2) and applied a scenario over 1500 adaptation cycles,
representing 10 days wall clock time, with and without concept
drift (see Figure 4). The evaluation was done on a computer with
an i7-3770 @ 3.40GHz processor and 16GB RAM. All material of
the evaluation is available at the project website [25].

1To speed up detection, we use 100 triplets; empirically determined.
2We use the p-value from a non-parametric Mann-Whitney-U test [39].
3We use p=0.025 to ensure high confidence of the decision. Note that if we denote
p-values in ascending order ùëù1, ùëù2, . . . , ùëùùëõ , the threshold ùëù will be adjusted by Holm‚Äôs
correction method [31] to
4We use the last 1000 task-specific data; empirically determined.

ùëù
ùëõ‚àíùëñ+1

for ùëùùëñ .

Algorithm 1 Function Knowledge-Based Learner (per task)

1: detected_task_id ‚Üê From Task Manager
2: queried_knowledge ‚Üê Task_Based_Knowledge_Manager.

query_knowledge_for_task(detected_task_id)

3: best_models ‚Üê []
4: for each learning_model ‚àà

queried_knowledge[state.learning_models] do
training_data ‚Üê queried_knowledge[input,output]
hypparam ‚Üê learning_model.hyper_param
best_model ‚Üê bayesian_optimizer(hypparam,

training_data)

5:

6:

7:

8:

best_model.train(training_data)
best_models.add(best_model)

9:
10: end for
11: Feedback_Loop.Knowledge

.update_learning_models(best_models)

Figure 6: Packet loss for different methods with/without
drift

We compared five approaches: (1) an optimal approach that
selects the best adaptation option by maximizing the expected util-
ity ùëàùëê based on the true values of the quality attributes in each
adaptation cycle (referred to as Baseline), (2) a state-of-the-art ap-
proach [11] that uses a regressor that retrains learning models
(SGDs) in each adaptation cycle with all previously collected data
(State-of-the-art), (3) incremental learning with a SGD regressor
but without a lifelong learning loop (SGD without LLL), (4) lifelong
self-adaptation with a lifelong learning loop and a SGD regressor
(SGD with LLL), and finally (5) lifelong self-adaptation with a life-
long learning loop that can switch the learner of the managing
system between a SGD regressor and HAT (SGD + HAT with LLL).
This last approach allows comparing the effect of incorporating
HAT, a learning method that is known to be suitable for dealing
with concept drift of input data.

We investigated the following two evaluation questions:

(1) To what extent can lifelong self-adaptation deal with concept
drift of input data for its learner on the quality properties
and system utility compared to the baseline?

(2) How does lifelong self-adaptation compare with the state-

of-the-art approach presented in [15]?

No driftUnder drift0102030405060BaselineState-of-the-artSGD without LLLSGD with LLL SGD + HAT with LLLDiÔ¨Äerent scenariosPacket loss (%)Lifelong Self-Adaptation: Self-Adaptation Meets Lifelong Machine Learning

SEAMS ‚Äô22, May 18‚Äì23, 2022, PITTSBURGH, PA, USA

a clean conceptual approach to deal with new learning tasks (in
our case tasks related to concept drift of input data of the learner).
The lifelong learning loop is drift-aware and provides first-class
support to identify and deal with concept drift. On the other hand,
the state-of-the-art approach we used in this paper exploits all the
previously collected knowledge to train the learner, while lifelong
self-adaptation relies on incremental training where the size of
the training data can be set based on the characteristics of the do-
main at hand. Figure 8 shows the cumulative training time over the
1500 adaptation cycles for the state-of-the-art approach and SGD
with LLL. We observe that the training time of the state-of-the-art
approach grows much faster. Consequently, the state-of-the-art
method consumes more computational resources for training the
learning models. In the DeltaIoT setting, a cycle of the lifelong
learning loop for SGD with LLL is only a fraction of the time win-
dow that is available to make an adaption decision at all times
(i.e., 9.5 minutes). On the other hand, after 6500 cycles, the time
required to complete an update of the learning models with the
state-of-the-art approach would exceed the available time window
for adaptation. Clearly, the state-of-the-art approach in its basic
form is not scalable over longer periods of time.

Figure 8: Cumulative training time of the state-of-the-art
method (retrain the model with all existing training data)
versus incremental learning under lifelong self-adaptation

In answer to the second evaluation question, we conclude that
lifelong self-adaptation performs similar to the state-of-the-art ap-
proach [15]. Yet, lifelong self-adaptation provides a clean conceptual
approach to deal with new learning tasks that emerge from con-
cept drift of the input data used by the learner of the managing
system, and the approach scales well over time in contrast to the
the state-of-the-art approach [15].

4.3.3 Detection of new tasks. Finally, we looked at how many new
tasks the lifelong learning loop detected in the evaluation scenario.
Figure 9 shows that in total 18 different new tasks were detected
over the period of 1500 cycles. In the period from cycle 1 to cycle 600,
the learning models are trained for the tasks at hand. This period
includes a first period of drift (from cycle 100 to cycle 350, see
Figure 4). From cycle 600 to cycle 750, when no concept drift occurs,
the system evolves the learning models for some of the learning
tasks based on relevant changes detected in the distributions of
input data. Then from cycle 750 until cycle 1100, the system faces
a new wave of drift and consequently a number of new learning

Figure 7: Utility for different methods with and without
drift
Impact on quality properties and system utility. Figure 6 sum-
4.3.1
marizes the results for packet loss of the network with the different
approaches. The results show that all approaches perform equally
well for a scenario without concept drift (boxplots on the left hand
side). For the scenario with concept drift (boxplots on the right
hand side), the median of packet loss for the baseline approach
(optimal approach based on the true values of quality properties)
increases from 5.25% to 8.84%, indicating an inherent impact of the
additional network interference. However, for a managing system
that uses a SGD regressor (without a lifelong learning loop) the
values increase from 6.23% to 19.56%. These results confirm earlier
findings of Chen [11] when applying incremental learning meth-
ods under concept drift in different domains, such as service-based
systems and cloud. The dramatic increase of packet loss (combined
with the effects on energy consumption) results in a substantial
decrease of 12% in the median of the expected utility of the IoT
network (for detailed results of energy consumption and utility, see
the project website [25]).

In contrast, when applying lifelong self-adaptation (LLL), the
results are similar to the baseline: the median of packet loss is
slightly higher, 2.69% for SGD with LLL and 1.18% for SGD + HAT
with LLL (compared to 10.72% for SGD without a lifelong learning
loop). The expected utility for the lifelong learning approaches is
only marginally smaller compared to the baseline: 1% and 2% for
SGD with LLL and SGD + HAT with LLL respectively (compared
to 12% for SGD without LLL). We observe that the performance of
the two lifelong self-adaptation approaches are very similar, so the
effect of including HAT as alternative for SGD is negligible.

In answer to the first evaluation question, we conclude that
lifelong self-adaptation can effectively deal with sudden concept
drift of input data for its learner on the qualities and system utility
and performs similar to the baseline.

4.3.2 Comparison with State-of-the-art Approach. When we com-
pare the two approaches for lifelong self-adaptation (SGD with LLL
and SGD + HAT with LLL) with the state-of-the-art approach [11],
we observe a very similar performance in the realization of the qual-
ity properties and overall utility of the system. Hence, a valid ques-
tion is what the competitive advantage of lifelong self-adaptation
would be compared to the state-of-the-art. The answer to this ques-
tion is twofold. On the one hand, lifelong self-adaptation offers

No driftUnder drift0.30.40.50.60.70.80.91BaselineState-of-the-artSGD without LLLSGD with LLL SGD + HAT with LLLDiÔ¨Äerent scenariosExpected uitlity200400600800100012001400020406080100120SGD with LLLState-of-the-artAdaptation cycleCumulative training time (s)SEAMS ‚Äô22, May 18‚Äì23, 2022, PITTSBURGH, PA, USA

Omid Gheibi and Danny Weyns

tasks are identified. In the remainder of the scenario until cycle 1500
no concept drift occurs anymore. During this period, the system
evolves the learning models for some of the learning tasks. Two
additional tasks are detected and learned at the end of the cycle due
to some gradual changes in the interference that were significant
enough to define new learning tasks.

shows the moving average (400 cycles window) of the data ob-
tained from one of the sensors, illustrating the drift of data over
time. This type of drift, characterized as incremental co-variate
drift, may affect the performance of the learner over time. To deal
with this problem, we add a lifelong learning loop on top of the
feedback loop, see Figure 10.

5.2 Lifelong Learning Loop Instance
We empirically determined that lifelong learning is triggered best
every 20 adaptation cycles of the managing system.

5.2.1 Knowledge Manager. Collects 20 new knowledge triplets per
cycle of the lifelong learning loop. Here, input of the triplets are
features of the sensor array data. State is meta-data about learner,
including the configuration of the learner and sets of pairs of sen-
sory data with labels checked per 100 cycles by the operator. Output
are the adaptation actions applied based on the classification label
of the sensory data. In this instance, the knowledge manager does
not maintain any meta-knowledge.

5.2.2 Task Manager. Uses the same algorithm of the task manager
in the first validation case. Yet, the similarity threshold is relaxed
to 0.05 (in contrast to 0.025 in the first case).

5.2.3 Knowledge-Based Learner. Evolves the learning models using
an algorithm similar to Algorithm 1. Based on the data received
from the task-based knowledge miner, the knowledge-based learner
determines the best learning model (optimizing the loss value for
the learner with a Bayesian optimizer). Then, it trains the best model
and updates the classification model in the knowledge repository
of the managing system.

5.2.4 Task-Based Knowledge Miner. Fetches the sets of knowledge
triplets from the knowledge manager for the tasks queried by the
knowledge-based learner. Due to uncertainties in the gas compo-
sition, the labels of the input in the state of these triplets may not
necessarily be correct. To that end, for new detected tasks, the task-
based knowledge miner selects the top five6 inputs (out of 20 newly
observed triplets) with the highest uncertainty.7 Then, task-based
knowledge miner asks the operator to check these labels and once
it receives the corrections, sends them to the knowledge manager
to use them for improving the performance of the learner. If the
detected task is not new, the task-based knowledge miner fetches
a sample of knowledge triplets for the detected task.8 The state of
the triplets contains correctly labeled data that can be used by the
knowledge-based learner for updating the learning model.

5.3 Evaluation Results
To validate lifelong self-adaptation for incremental co-variate drift,
we implemented a simplified simulation of the gas delivery setup
shown in Figure 10. Concretely, we implemented the feedback loop,
the lifelong learning loop, and the part that provides gas to users.
The remainder of the system and the environment are represented
as an extensive set of data [1]. This data set was generated over

6This number was experimentally determined.
7The uncertainty is proportional to the inverse of the standard deviation of distances
between the input and decision boundaries of SVC [28].
8The size of this sample can be determined based on the capacity of the learning
model [27]. We used up to 1000 samples for the evaluation case.

Figure 9: Tasks identified over 1500 adaptation cycles

5 LIFELONG SELF-ADAPTATION TO DEAL

WITH INCREMENTAL CO-VARIATE DRIFT
To explain how lifelong self-adaption deals with sudden co-variate
drift we use a case in the domain of gas delivery.

Figure 10 shows a schematic overview of the setting that is
inspired by [55]. The schedule of the system determines the type of
gas that needs to be produced and the user requirements for a given
period of time. Different types of gas can be generated by routing
different portions of pressurized chemicals to the tanker. The gas
delivery manager manages the mass flow controllers MFC1-3 to
generate gas according to the schedule. Yet, there is uncertainty
about the type of gas that is produced, which needs to be resolved
before gas is routed to the users. To that end, the feedback loop
collects sensor data from an array of 16 sensors at the gas tank
and stores the data in the knowledge repository. The classifier, a
multi-class support vector machine (SVC)5, labels the sensor data
with a gas type, yielding tuples ‚ü®sensor data, generated gas type‚ü©.
Periodically, the operator checks the labels and corrects them if
needed (batches of 100). The classifier uses this input to improve its
performance over time. Based on the gas type of the current data
tuple and the gas requirements of the users, the planner determines
the delivery of gas to the users. The executor then enacts these
settings to the gas delivery manager that sets the valves of the mass
flow controllers MFC4 to MFC7 routing the gas to the right users.

5.1 Problem
A problem with this setting is the potential degradation of the sur-
face of the sensors due to ageing or contamination, causing sensor
drift, a challenging problem in chemical sensing [55]. Figure 11

5SVC combines several binary support vector machines based on a given strategy [5].
Example strategies consider decision boundaries between training examples of every
two classes (‚Äúone vs. one‚Äù strategy) or training examples of each class against all others
(‚Äúone vs. all‚Äù strategy).

2004006008001000120014000246810121416Adaptation cycleTask identiÔ¨ÅerLifelong Self-Adaptation: Self-Adaptation Meets Lifelong Machine Learning

SEAMS ‚Äô22, May 18‚Äì23, 2022, PITTSBURGH, PA, USA

Figure 10: Gas delivery setup for the evaluation

three years in a controlled setting; it contains the sensor data and
the correct labels for the operator (ground truth). The classifier
of the feedback loop was realized as an ensemble of classifiers
based on support vector machines. The weighted combination of
these classifiers were trained at different points in time to solve a
gas discrimination problem with high accuracy. We used the same
computer setup as for the first case for the evaluation.

We compared three learners: (1) a SVC trained offline (Reference),
(2) a SVC with online training that uses the data of the previous
batch of monitored data (State-of-the-art [54]), and (3) the SVC of
(2) with a lifelong learning loop. We measured the classification
accuracy using the ground truth that is provided with the data
set [1]. Figure 12 shows the results over 13.7k cycles, grouped
in three zones. The results show low values for accuracy with the
reference approach in all zones. While the state-of-the-art approach
scores similar to the approach with a lifelong loop in the first zone,
its accuracy gradually decreases afterwards. The mean value of
the accuracy over the complete run was 0.35 for the reference
approach, 0.77 for the state-of-the-art, and 0.88 for the lifelong self-
adaptation approach. The results show that lifelong self-adaptation
can effectively deal with incremental concept drift.

Figure 11: Moving average (with 400 cycles window size) of
data from one sensor showing incremental co-variate drift

6 THREATS TO VALIDITY
The evaluation of lifelong self-adaption is subject to a number of
validity threats. We evaluated the approach only for two types of

Digital MFCinterfaceDigital MFCinterfaceChemical analyte 1Chemical analyte 1Zero grade dry airPressurized gas cylindersMFC 3User 1User 2User 3User 4Tank Generated GasMFC 2MFC 6MFC 4MFC 5MFC 7Sensor 1Sensor 2Sensor 16...Sensor arrayGas DeliveryMonitor......ClassiÔ¨ÅerPlannerfeatures of chemical sensors data¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†KnowledgeClassiÔ¨Åcation modelOperatorkeep up-to-datecheck labelssensor data sets<sensor data, generated gas type>Lifelong learning loopFeedback Loopquery to label a setof sensors datalabels ofqueried dataobserve adaptation actionsEnvironmentadapt gas delivery to users¬†set mass Ô¨Çow controllers ¬†MFC 1 to MFC 3MFC 1Executorread data batches¬†gas requirements users¬†update learning modelread properties learnerset mass Ô¨ÇowcontrollersMFC 4 to MFC 7ScheduleManager50010001500200030k40k50k60k70k80k90k100kChronological indexExpected response ofSensor1-Channel1 for gas type 1 (ppmv)SEAMS ‚Äô22, May 18‚Äì23, 2022, PITTSBURGH, PA, USA

Omid Gheibi and Danny Weyns

micro-services is proposed and compared with other architectural
styles. Vieira et al. [56] propose Driftage, a multi-agent framework
for concept drift detection that uses a MAPE-K loop. The monitor
and analyzer agents capture and predict concept drifts on data, and
the planner and executor agents determine whether the detected
concept drift should be alerted. The approach is applied to health
monitoring of muscle cells. Casimiro et al. [9] propose a framework
for self-adaptive systems with machine-learned components. The
authors outline a set of adaptation tactics to deal with misbehavior
of the machine-learned components, the required changes to the
MAPE-K loop for dealing with them, and the challenges associated
with developing this framework.

In contrast

to these approaches, we provide a domain-
independent architecture to deal with new emerging tasks in learn-
ing modules used by self-adaptive systems. The work of [12] and [9]
offer valuable solutions that can be used when instantiating the
architecture for lifelong self-adaptation.

Improving the Performance of Machine Learning for Self-
Adaptation. Jamshidi et al. [33] propose L2S (Learning to Sample),
an efficient approach for transferring knowledge across execution
environments to simplify the configuration, e.g., hardware, software
release. The approach progressively concentrates on interesting
regions of the configuration space. Chen and Bahsoon [13] present
a modeling approach for creating quality prediction models that use
data from the environment and control settings as inputs. The ap-
proach leverages adaptive multi-learners, selecting the best model
for prediction on the fly, and is evaluated in a cloud environment.
Chen et al. [14] apply a similar approach to deal with the problem
if resource allocation for cloud-based software services. Chen et
al. [10] propose the idea of ‚Äúexperience transfer‚Äù from one system
to another similar system, and demonstrate this for system con-
figuration tuning, where experiences are dependencies between
configuration parameters.

These related approaches target the efficiency of machine learn-
ing methods in the context of self-adaptation. Our work comple-
ments these approaches focusing on enhancing learning to handle
new learning tasks as required for concept drift.

8 CONCLUSIONS AND FUTURE WORK
Self-adaptive systems are characterized by their ability to deal with
uncertainty. Machine learning techniques on the other hand, which
are increasingly used in self-adaptive systems, face challenges with
uncertainties that were not considered as learning tasks during
design. To deal with new learning tasks, we presented lifelong
self-adaptation, a novel approach to self-adaptation that enhances
self-adaptive systems that use machine learning techniques with a
lifelong learning layer. We presented an architecture for lifelong
self-adaptation and applied it to deal with two types of concept
drift in two domains. The evaluation results show that lifelong
self-adaptation effectively resolves the problems of concept drift.

In future work, we plan to study and apply lifelong self-
adaptation for other types of concept drift, in particular class drift
and novel class appearance. Then, we plan to investigate how life-
long self-adaptation can be used to deal with new and changing
adaptation goals, which is a particularly challenging example of
uncertainties for self-adaptive systems.

Figure 12: Classification accuracy of the different ap-
proaches

concept drift, so we cannot generalize the findings for other types
of problems that require dealing with new learning tasks (external
validity). Additional research is required to study the usefulness
of the architecture for other challenges with new learning tasks in
self-adaptive systems. Additionally, we validated the architecture
for each type of concept drift with a single application. Evaluation
in different domains is required to increase the validity of the results
for the types of concept drift considered in this paper. We have
evaluated the instances of the architecture for particular settings.
The type and number of new learning tasks these settings generate
may have an effect on the difficulty of the problems (internal va-
lidity). We mitigated this threat by instantiating the architecture
for two different domains. However, additional evaluation in other
domains is required to increase the validity of the results for the
types of concept drift studied. For practical reasons, we used simu-
lation for the evaluation with data that contains uncertainty. The
results may be different if the study would be repeated (reliability).
We minimized this threat by considering data extracted from real
systems, and we evaluated the cases over long periods of time. We
also provide a replication package for the study [25].

7 RELATED WORK
We look at a selection of work at the crossing of machine learning
and self-adaptation, focusing on concept drift and performance of
machine learning in self-adaptive systems.

Dealing with Concept Drift in Self-Adaptation. T. Chen [12]
studied two methods to deal with concept drift in self-adaptation
with learning: retraining a new model in each cycle using all avail-
able data, and retraining the existing model using the newly arrival
data sample. In contrast to general beliefs about the choices between
the two, the author examines both modeling methods for distinct
domains of adaptive software and identifies evidence-based factors
that can be used to make well-informed decisions. Bierzynski et
al. [7] present the architecture of a self-learning lighting system that
equips a MAPE-K loop with a learner that learns activities and user
preferences. Another feedback loop on top of the learner determines
when the predictions of a learning model start to drift and then
adapts the learning model accordingly. A concrete instance based on

Adaptation cycle 1-6kAdaptation cycle 6k - 10kAdaptation cycle 10k - 13.7k0.20.40.60.81SVC oÔ¨Ñine training (Reference)SVC using a previous batch (State-of-the-art)SVC using a previous batch under LLLClassiÔ¨Åcation accuracyLifelong Self-Adaptation: Self-Adaptation Meets Lifelong Machine Learning

SEAMS ‚Äô22, May 18‚Äì23, 2022, PITTSBURGH, PA, USA

REFERENCES
[1] Gas

sensor array drift dataset at different concentrations data set.

http://archive.ics.uci.edu/ml/datasets/Gas+Sensor+Array+Drift+Dataset+
at+Different+Concentrations. Accessed: 2022-01-20.

[2] Amershi, S., Begel, A., Bird, C., DeLine, R., Gall, H., Kamar, E., Nagappan, N.,
Nushi, B., and Zimmermann, T. Software engineering for machine learning: A
case study. In 2019 IEEE/ACM 41st International Conference on Software Engineer-
ing: Software Engineering in Practice (ICSE-SEIP) (2019), IEEE, pp. 291‚Äì300.
[3] Ammar, H. B., Eaton, E., Luna, J. M., and Ruvolo, P. Autonomous cross-domain
knowledge transfer in lifelong policy gradient reinforcement learning. In Twenty-
Fourth International Joint Conference on Artificial Intelligence (2015).

[4] Andresini, G., Pendlebury, F., Pierazzi, F., Loglisci, C., Appice, A., and Cav-
allaro, L. Insomnia: Towards concept-drift robustness in network intrusion
detection. In Proceedings of the 14th ACM Workshop on Artificial Intelligence and
Security (2021), pp. 111‚Äì122.

[5] Angulo, C., Parra, X., and Catala, A. K-svcr. a support vector machine for

multi-class classification. Neurocomputing 55, 1-2 (2003), 57‚Äì77.

[6] Basseville, M., Nikiforov, I. V., et al. Detection of abrupt changes: theory and

application, vol. 104. Prentice hall Englewood Cliffs, 1993.

[7] Bierzynski, K., Lutskov, P., and Assmann, U. Supporting the self-learning of
systems at the network edge with microservices. In Smart Systems Integration;
13th International Conference and Exhibition on Integration Issues of Miniaturized
Systems (2019), pp. 1‚Äì8.

[8] Bifet, A., and Gavald√†, R. Adaptive learning from evolving data streams. In
Advances in Intelligent Data Analysis VIII (Berlin, Heidelberg, 2009), N. M. Adams,
C. Robardet, A. Siebes, and J.-F. Boulicaut, Eds., Springer Berlin Heidelberg,
pp. 249‚Äì260.

[9] Casimiro, M., Romano, P., Garlan, D., Moreno, G. A., Kang, E., and Klein, M.
Self-adaptation for machine learning based systems. In ECSA 2021 Companion
Volume, Virtual (originally: V√§xj√∂, Sweden), 13-17 September, 2021 (2021), R. Hein-
rich, R. Mirandola, and D. Weyns, Eds., vol. 2978 of CEUR Workshop Proceedings,
CEUR-WS.org.

[10] Chen, H., Zhang, W., and Jiang, G. Experience transfer for the configuration
tuning in large-scale computing systems. IEEE Transactions on Knowledge and
Data Engineering 23, 3 (2010), 388‚Äì401.

[11] Chen, T. All versus one: An empirical comparison on retrained and incremental
In 2019
machine learning for modeling performance of adaptable software.
IEEE/ACM 14th International Symposium on Software Engineering for Adaptive
and Self-Managing Systems (SEAMS) (2019), IEEE, pp. 157‚Äì168.

[12] Chen, T. All versus one: An empirical comparison on retrained and incremental
machine learning for modeling performance of adaptable software.
In Inter-
national Symposium on Software Engineering for Adaptive and Self-Managing
Systems (2019), IEEE.

[13] Chen, T., and Bahsoon, R. Self-adaptive and online qos modeling for cloud-
based software services. IEEE Transactions on Software Engineering 43, 5 (2017),
453‚Äì475.

[14] Chen, X., Lin, J., Lin, B., Xiang, T., Zhang, Y., and Huang, G. Self-learning and
self-adaptive resource allocation for cloud-based software services. Concurrency
and Computation: Practice and Experience 31, 23 (2019), e4463. e4463 CPE-17-0360.
[15] Chen, Z., and Liu, B. Lifelong machine learning. Synthesis Lectures on Artificial

Intelligence and Machine Learning 12, 3 (2018), 1‚Äì207.

[16] Cheng, B., et al. Software engineering for self-adaptive systems: A research
In Software Engineering for Self-Adaptive Systems. Springer Berlin

roadmap.
Heidelberg, Berlin, Heidelberg, 2009, pp. 1‚Äì26.

[17] D‚ÄôAmour, A., Heller, K., Moldovan, D., Adlam, B., Alipanahi, B., Beutel, A.,
Chen, C., Deaton, J., Eisenstein, J., Hoffman, M. D., et al. Underspecification
presents challenges for credibility in modern machine learning. arXiv preprint
arXiv:2011.03395 (2020).

[18] de Lemos et al., R. Software Engineering for Self-Adaptive Systems: A Second

Research Roadmap. Springer, Berlin, Heidelberg, 2013, pp. 1‚Äì32.

[19] Din, Z. U., and Bernold, L. E. Experimental study of signal behavior for wireless

communication in construction. Construction Innovation (2017).

[20] Esfahani, N., and Malek, S. Uncertainty in self-adaptive software sys-
tems. In Software Engineering for Self-Adaptive Systems II: International Seminar,
Dagstuhl Castle, Germany, October 24-29, 2010 Revised Selected and Invited Papers,
R. de Lemos, H. Giese, H. A. M√ºller, et al., Eds. Springer Berlin Heidelberg, 2013,
pp. 214‚Äì238.

[21] Fei, G., Wang, S., and Liu, B. Learning cumulatively to become more knowl-
edgeable. In Proceedings of the 22nd ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining (New York, NY, USA, 2016), KDD ‚Äô16,
Association for Computing Machinery, p. 1565‚Äì1574.

[22] Gama, J., ≈ΩliobaitÀôe, I., Bifet, A., Pechenizkiy, M., and Bouchachia, A. A
survey on concept drift adaptation. ACM computing surveys (CSUR) 46, 4 (2014),
1‚Äì37.

[23] Garlan, D., Cheng, S., Huang, A., et al. Rainbow: Architecture-based self-

adaptation with reusable infrastructure. Computer 37, 10 (2004), 46‚Äì54.

[24] Ghahremani, S., Adriano, C. M., and Giese, H. Training prediction models
for rule-based self-adaptive systems. In 2018 IEEE International Conference on
Autonomic Computing (ICAC) (2018), pp. 187‚Äì192.

[25] Gheibi, O., and Weyns, D. Project Website: Lifelong Self-Adaptation. In https:

// people.cs.kuleuven.be/ danny.weyns/ software/ LLSAS/ (1/2022).

[26] Gheibi, O., Weyns, D., and Quin, F. Applying machine learning in self-adaptive
systems: A systematic literature review. ACM Transactions on Autonomous and
Adaptive Systems 15 (2020).

[27] Gheibi, O., Weyns, D., and Quin, F. On the impact of applying machine learning
in the decision-making of self-adaptive systems. In 2021 International Symposium
on Software Engineering for Adaptive and Self-Managing Systems (SEAMS) (2021),
pp. 104‚Äì110.

[28] Guo, H., and Wang, W. An active learning-based svm multi-class classification

model. Pattern recognition 48, 5 (2015), 1577‚Äì1597.

[29] Haenggi, M., Andrews, J. G., Baccelli, F., Dousse, O., and Franceschetti, M.
Stochastic geometry and random graphs for the analysis and design of wireless
networks. IEEE journal on selected areas in communications 27, 7 (2009), 1029‚Äì1046.
[30] Hezavehi, S. M., Weyns, D., Avgeriou, P., Calinescu, R., Mirandola, R., and
Perez-Palacin, D. Uncertainty in self-adaptive systems: A research community
perspective. ACM Transactions on Autonomous and Adaptive Systems 15, 4 (2021).
[31] Holm, S. A simple sequentially rejective multiple test procedure. Scandinavian

journal of statistics (1979), 65‚Äì70.

[32] Iftikhar, M. U., Ramachandran, G. S., Bollans√©e, P., Weyns, D., and Hughes,
D. Deltaiot: A self-adaptive internet of things exemplar. In 2017 IEEE/ACM 12th
International Symposium on Software Engineering for Adaptive and Self-Managing
Systems (SEAMS) (2017), IEEE, pp. 76‚Äì82.

[33] Jamshidi, P., Velez, M., K√§stner, C., and Siegmund, N. Learning to sample:
Exploiting similarities across environments to learn performance models for
configurable systems.
In Proceedings of the 2018 26th ACM Joint Meeting on
European Software Engineering Conference and Symposium on the Foundations of
Software Engineering (2018), pp. 71‚Äì82.

[34] Jaworski, M., Rutkowski, L., and Angelov, P. Concept drift detection using
autoencoders in data streams processing. In International Conference on Artificial
Intelligence and Soft Computing (2020), Springer, pp. 124‚Äì133.

[35] Kephart, J. O., and Chess, D. M. The vision of autonomic computing. Computer

36, 1 (2003), 41‚Äì50.

[36] Kramer, J., and Magee, J. Self-managed systems: an architectural challenge.

pp. 259‚Äì268.

[37] Krupitzer, C., Otto, J., Roth, F. M., Fr√∂mmgen, A., and Becker, C. Adding
self-improvement to an autonomic traffic management system. In 2017 IEEE
International Conference on Autonomic Computing (ICAC) (2017), IEEE, pp. 209‚Äì
214.

[38] Kumeno, F. Sofware engneering challenges for machine learning applications: A
literature review. Intelligent Decision Technologies 13, 4 (2019), 463‚Äì476.
[39] Mann, H. B., and Whitney, D. R. On a test of whether one of two random
variables is stochastically larger than the other. The annals of mathematical
statistics (1947), 50‚Äì60.

[40] Mills, D. L. Computer network time synchronization: the network time protocol on

earth and in space. CRC press, 2017.

[41] Mitchell, T., Cohen, W., Hruschka, E., Talukdar, P., Yang, B., Betteridge, J.,
Carlson, A., Dalvi, B., Gardner, M., Kisiel, B., et al. Never-ending learning.
Communications of the ACM 61, 5 (2018), 103‚Äì115.

[42] Nguyen, C. V., Achille, A., Lam, M., Hassner, T., Mahadevan, V., and Soatto,
S. Toward understanding catastrophic forgetting in continual learning. CoRR
abs/1908.01091 (2019).

[43] O‚ÄôMalley, T., Bursztein, E., Long, J., Chollet, F., Jin, H., Invernizzi, L., et al.

Kerastuner. https://github.com/keras-team/keras-tuner, 2019.

[44] Parisi, G. I., Kemker, R., Part, J. L., Kanan, C., and Wermter, S. Continual
lifelong learning with neural networks: A review. CoRR abs/1802.07569 (2018).
[45] Quin, F., Weyns, D., Bamelis, T., Buttar, S. S., and Michiels, S. Efficient analysis
of large adaptation spaces in self-adaptive systems using machine learning. In
2019 IEEE/ACM 14th International Symposium on Software Engineering for Adaptive
and Self-Managing Systems (SEAMS) (2019), IEEE, pp. 1‚Äì12.

[46] Ribeiro, M. T., Wu, T., Guestrin, C., and Singh, S. Beyond accuracy: Behavioral
testing of NLP models with CheckList. In Proceedings of the 58th Annual Meeting
of the Association for Computational Linguistics (Online, July 2020), Association
for Computational Linguistics, pp. 4902‚Äì4912.

[47] Ring, M. Child: A first step towards continual learning. Machine Learning 28

(1997), 77‚Äì104.

[48] Saad, D. Online algorithms and stochastic approximations. Online Learning 5

(1998), 6‚Äì3.

[49] Shu, L., Liu, B., Xu, H., and Kim, A. Lifelong-rl: Lifelong relaxation labeling for
separating entities and aspects in opinion targets. In Proceedings of the Conference
on Empirical Methods in Natural Language Processing. Conference on Empirical
Methods in Natural Language Processing (2016), vol. 2016, NIH Public Access,
p. 225.

[50] Silver, D. L., Mason, G., and Eljabu, L. Consolidation using sweep task rehearsal:
overcoming the stability-plasticity problem. In Canadian Conference on Artificial

SEAMS ‚Äô22, May 18‚Äì23, 2022, PITTSBURGH, PA, USA

Omid Gheibi and Danny Weyns

Intelligence (2015), Springer, pp. 307‚Äì322.

[51] Tanaka, F., and Yamamura, M. An approach to lifelong reinforcement learning
through multiple environments. In 6th European Workshop on Learning Robots
(1998), p. 93‚Äì99.

[57] Wang, S., Chen, Z., and Liu, B. Mining aspect-specific opinion using a holistic
lifelong topic model. In 25th International Conference on World Wide Web (Republic
and Canton of Geneva, CHE, 2016), International World Wide Web Conferences
Steering Committee, p. 167‚Äì176.

[52] Thrun, S. Lifelong learning algorithms. In Learning to learn. Springer, 1998,

pp. 181‚Äì209.

[53] Thrun, S., and Mitchell, T. M. Lifelong robot learning. Robotics and Au-
tonomous Systems 15, 1 (1995), 25‚Äì46. The Biology and Technology of Intelligent
Autonomous Agents.

[54] Vergara, A., Vembu, S., Ayhan, T., Ryan, M. A., Homer, M. L., and Huerta, R.
Chemical gas sensor drift compensation using classifier ensembles. Sensors and
Actuators B: Chemical 166-167 (2012), 320‚Äì329.

[55] Vergara, A., Vembu, S., Ayhan, T., Ryan, M. A., Homer, M. L., and Huerta, R.
Chemical gas sensor drift compensation using classifier ensembles. Sensors and
Actuators B: Chemical 166 (2012), 320‚Äì329.

[56] Vieira, D., Fernandes, C., Lucena, C., and Lifschitz, S. Driftage: a multi-agent
system framework for concept drift detection. GigaScience 10, 6 (06 2021).

[58] Webb, G. I., Hyde, R., Cao, H., Nguyen, H. L., and Petitjean, F. Characterizing
concept drift. Data Mining and Knowledge Discovery 30, 4 (2016), 964‚Äì994.
[59] Weyns, D. An Introduction to Self-adaptive Systems: A Contemporary Software

Engineering Perspective. John Wiley & Sons, 2020.

[60] Weyns, D., Iftikhar, U., and Soderland, J. Do external feedback loops im-
prove the design of self-adaptive systems? a controlled experiment. In Software
Engineering for Adaptive and Self-Managing Systems (2013), IEEE.

[61] Weyns, D., Malek, S., and Andersson, J. FORMS: Unifying Reference Model
for Formal Specification of Distributed Self-adaptive Systems. ACM Transactions
on Autonomous and Adaptive Systems 7, 1 (2012).

[62] Yang, L., Guo, W., Hao, Q., Ciptadi, A., Ahmadzadeh, A., Xing, X., and Wang,
G. {CADE}: Detecting and explaining concept drift samples for security applica-
tions. In 30th {USENIX} Security Symposium ({USENIX} Security 21) (2021).

