Zipper Codes

Alvin Y. Sukmadji, Graduate Student Member, IEEE, Umberto Mart´ınez-Pe˜nas, and
Frank R. Kschischang, Fellow, IEEE

1

2
2
0
2

r
a

M
8
1

]
T
I
.
s
c
[

1
v
0
2
1
0
1
.
3
0
2
2
:
v
i
X
r
a

Abstract—Zipper codes are a framework for describing
spatially-coupled product-like codes. Many well-known codes,
such as staircase codes and braided block codes, are subsumed
into this framework. New types of codes such as tiled diagonal
and delayed diagonal zipper codes are introduced along with
their software simulation results. Stall patterns that can arise in
iterative decoding are analyzed, giving a means of error ﬂoor
estimation.

Index Terms—Spatially-coupled codes, product-like codes,

staircase codes, braided block codes, iterative decoding.

I. INTRODUCTION

Z IPPER codes [1], [2] represent a framework for de-

scribing spatially-coupled product-like error-correcting
codes that are widely implemented in optical communications
systems. Zipper codes encompass many well-known spatially-
coupled codes such as staircase codes [3], braided block
codes [4], diamond codes [5], continuously-interleaved Bose-
Chaudhuri-Hocquenghem (BCH) codes [6], swizzle codes [7],
oFEC [8], and spatially-coupled turbo product codes [9].

The general structure of zipper codes is closely related to
that of spatially-coupled generalized low-density parity-check
(SC-GLDPC) codes [10], [11], the main difference being that
the latter are designed to operate under soft-decision decod-
ing, whereas the former are designed to be decoded using
low-complexity, iterative, algebraic, hard-decision decoding
algorithms. The low energy complexity of hardware imple-
mentations of zipper codes makes them very attractive for
use in high throughput applications such as optical transport
networks, where data throughputs on the order of hundreds of
gigabits per second make it vital for error-correcting decoders
to have low complexity. Accordingly, spatially-coupled codes
with hard-decision decoding have gained in popularity due to
their lower decoding complexity when compared to codes with
soft-decision decoders [12]–[16].

In some applications, zipper codes are of interest as outer
codes in concatenated coding schemes [17]–[20], particularly
for high code rates, but they have also been considered as
inner codes [21], [22]. Efﬁcient hardware implementation of
zipper codes is considered in [23], where a decoder achieving a
throughput of 962 Gbps operating at 500 MHz clock frequency
is reported. Other related hardware implementations include
[24], [25].

Submitted for publication on March 16, 2022.

A. Y. Sukmadji and F. R. Kschischang are with the Edward S. Rogers Sr.
Department of Electrical & Computer Engineering, University of Toronto,
Canada. U. Mart´ınez-Pe˜nas is with the Department of Mathematics, Uni-
versity of Valladolid, Spain. Emails: alvin.sukmadji@mail.utoronto.ca, um-
berto.martinez@uva.es, frank@ece.utoronto.ca.
This paper was presented in part at the 16th Canadian Workshop on Informa-
tion Theory, June 2019 [1].

This paper provides a general overview of zipper codes,
organized as follows. The structure and main ingredients of a
zipper code are discussed in Sec. II. Several important code
families that can be described as zipper codes are given in
Sec. III. Software simulation results for a few example zipper
code designs are given in Sec. IV. Finally, “stall patterns,” a
type of error event for zipper codes, are discussed and analyzed
in Sec. V.

Throughout this paper, we will assume that all codes are
deﬁned over the binary ﬁeld F2 =
; however, analogous
}
formulations can be made for the non-binary case. For any
. The cardinal-
positive integer q, we let [q] =
ity (number of elements) of a ﬁnite set A is denoted as
.
The natural numbers are given as N =

0, 1, . . . , q
{

0, 1
{

A
|

1
}

−

|

.

0, 1, 2, . . .
}

{

II. STRUCTURE OF ZIPPER CODES

A. Constituent Codes, Buffer, Zipping Pair

∈

Let

[ni]; necessarily

C1, . . . be any sequence of binary linear constituent
C0,
N, where the ith code has length ni
codes indexed by i
and dimension ki. Denote any (ﬁxed) information set of
Ci
= ki. Codeword symbols in
as Ii ⊆
Ii|
|
positions indexed by Ii are called information symbols of
Ci, while codeword symbols in the complementary positions
Ii) are called parity symbols. In practice, we
(indexed by [ni]
\
will usually have
Ci in systematic form, in which case Ii = [ki]
(the ﬁrst ki positions of a codeword hold information symbols
ki positions hold parity symbols).
and the last ni −
A buffer associated with a given sequence of constituent
codes is any sequence of binary row vectors c = c0, c1, . . .
N. Thus, a buffer is a sequence
such that ci ∈
∈
of rows, with the ith row having ni positions, possibly (but not
N and any
necessarily) forming a codeword of
[ni] the jth symbol of the ith row of c is denoted as ci,j;
j
this symbol is said to have position (i, j) within buffer c. For
purposes of initialization (i.e., to establish suitable boundary
conditions), we extend the set of buffer positions to allow for
negative row indices by deﬁning ci,j = 0 for all i < 0 and all
N. Thus if we refer to a buffer symbol with a negative row
j
index, that symbol necessarily has value zero. When i < j we
will say that row i is older than row j (or, equivalently, that
row j is newer than row i).

Ci. For any i

Fni
2 for each i

∈

∈

∈

N, let Ai ⊆

As illustrated in Fig. 1, we will partition each row of a
buffer c as follows. For each i
Ii be any
(ﬁxed) subset of the information positions of
Ci, and let Bi =
Ai be the complementary set of positions. The buffer
[ni]
positions indexed by Ai form the virtual positions of the ith
row (the corresponding symbols are called virtual symbols),
while those indexed by Bi form the real positions (and the
corresponding symbols are called real symbols). As we will

∈

\

 
 
 
 
 
 
2

Equipped with a sequence

C1, . . . of constituent codes,
C0,
a zipping pair (A, B), and an interleaver map φ, we say that
a buffer c = c0, c1, . . . forms a valid zipper codeword if

1) ci,j = cφ(i,j) for all (i, j)
2) ci ∈ Ci for all i

N.

∈

A, and

∈

In other words, each virtual symbol of a valid zipper codeword
must be a copy of a real symbol as prescribed by the
interleaver map φ, and each row of a valid zipper codeword
must be a codeword of the corresponding constituent code.

Fig. 1. Example of a zipper code with a Ci = C constituent code with
n = ni = 14 and r = ri = 3. Tiles in the shaded region represent virtual
symbols, while tiles in the unshaded and ﬁlled regions represent real symbols.
The ﬁlled regions show the location of parity symbols. The two tiles connected
by arrows represent the two coordinates prescribed by the interleaver map. In
this example, we have φ(13, 2) = (1, 12) and c13,2 = c1,12 = 1. Each row
is a codeword of C. Rows with lower row indices correspond to “older” rows
while those with higher indices are regarded as “newer.”

soon see, only real symbols are transmitted over the channel;
each virtual symbol of a constituent codeword is a copy of
a real symbol from some other constituent codeword. When
Ci is in systematic form, we will usually take Ai = [mi] for
ki, thus designating the ﬁrst mi positions as virtual
some mi ≤
positions. Let

A =

(i, j) : j

(cid:91)
N{

i
∈

Ai}

∈

and B =

(cid:91)
N{

i

∈

(i, j) : j

Bi}

∈

denote the positions of the virtual symbols and the real
symbols, respectively. We refer to (A, B) as a zipping pair.
is called the virtual buffer, and
The set
ci,j : (i, j)
}
{
is called the real buffer. The set
the set
ci,j : (i, j)
}
{
is an index
B∗ = B
1,
∈ {−
set for an extended real buffer where negative row indices are
permitted. As already noted, symbols located in rows with a
negative row index have value zero.

∈
∈
(i, j) : i

, j
2, . . .
}

A
B

∪ {

−

N

∈

}

B. Interleaver Map

An interleaver map associated with a zipping pair (A, B) is
A,
∈
B∗ from

any function φ : A
the interleaver map gives a real position φ(i, j)
which to copy a symbol.

B∗. For each virtual position (i, j)

→

∈

We will often be interested in the row index from which
a real symbol is copied. To this end, we deﬁne coordinate
functions φ1 and φ2 such that φ(i, j) = (φ1(i, j), φ2(i, j)).
Thus φ1(i, j) returns the row index from which the virtual
symbol at position (i, j) is copied. If φ1(i, j) < 0, then the
copied symbol is necessarily zero.

For each real position (i, j)

B∗, let φ−

1(i, j) =

(i(cid:48), j(cid:48))

A : φ(i(cid:48), j(cid:48)) = (i, j)
}
mapping by φ. Then
|
copies of the real symbol in position (i, j).

∈
denote the inverse image of (i, j) under
gives the number of virtual
φ−

∈
1(i, j)

{

|

Fig. 1 illustrates a zipper codeword in a zipper code
speciﬁed in terms of a sequence of constituent codes having
ﬁxed length n = ni = 14 and ﬁxed dimension k = ki = 11.
The constituent codes are assumed to be in systematic form,
so that parity symbols fall into the last r = n
k = 3
positions in each row. The ﬁrst mi positions in each row are
the virtual positions, while the last n
mi positions are the
real positions. Note that mi is permitted to vary from row
to row. As illustrated, the interleaver map φ determines the
position at which to look up the value of a virtual symbol.

−

−

It is clear that the interleaver map determines the degree of
coupling among the various constituent codes. We will usually
focus on interleaver maps that are periodic and causal.

Deﬁnition 1. An interleaver map φ is said to be periodic
with period ν > 0, or simply ν-periodic, if φ(ν + i, j) =
A.
(ν, 0) + φ(i, j) for all (i, j)

∈

To support a ν-periodic interleaver map, we will require
that the zipping pair (A, B) is also ν-periodic in the sense
N. Most often we
that nν+i = ni, and Aν+i = Ai for all i
Ci for all i
will then also have

Cν+i =

∈
N.

∈

Deﬁnition 2. An interleaver map φ is said to be causal if
A and strictly causal if the
φ1(i, j)
≤
inequality is strict.

i for all (i, j)

∈

In other words, under a causal

interleaver map, virtual

symbols are never copied from later rows.

Some important classes of zipper codes (such as staircase
codes) have the property that each real symbol
is copied
exactly once into some virtual position, i.e., the inverse image
B under mapping by
φ−
φ is a singleton set
A. In this
}
situation we refer to the interleaver map as being bijective.

1(i, j) of every real position (i, j)

∈
for some (i(cid:48), j(cid:48))

(i(cid:48), j(cid:48))
{

∈

C. Encoding Zipper Codes

Recall that Ii ⊆

[ni] denotes an information set with

=
ki for the constituent code
Ci of length ni and dimension ki,
Ii is an index set for the virtual positions of the
and that Ai ⊆
ith buffer row ci. To encode ci, we assume that all rows cj with
j < i have already been encoded. This will be true even for c0,
since previous rows are then all-zero by assumption. Under the
assumption of a causal interleaver map, the encoding of zipper
codes is easily accomplished by the following procedure:

Ii|

|

symbols.

1) Fill in the positions indexed by Bi ∩
2) Fill in the virtual symbols by duplicating symbols from
the positions prescribed by the interleaver map, i.e., for
Ai, let ci,j = cφ(i,j). (Since φ is causal
each j

Ii with message

∈

oldnewmin−mi−rrVirtualReal012345678910111213...∈C1110010100011101100100101100101011001001101011000101111001001111111000111110001100111010000001100101010010010100010111011000001110011011111110101010101110101100100101100011101111111111010011001101ϕϕϕby assumption, cφ(i,j) is a symbol from a row already
encoded, or a symbol from the current row which was
input in the ﬁrst step.)

sitions indexed by [ni]
for

\

3) Complete the row by ﬁlling in the parity symbols in po-
Ii using an appropriate encoder

Ci, thereby fulﬁlling the condition that ci ∈ Ci.

In the zipper code of Fig. 1, for example, the shaded tiles in
row i are ﬁlled with symbols drawn from previous rows, the
unshaded tiles correspond to message symbols, and the ﬁlled
tiles correspond to parity symbols computed using the encoder
for

Ci.

D. Code Rate

We will always assume that only the symbols in the real
buffer, i.e., in positions indexed by B, are transmitted over the
channel, in some well-deﬁned order from oldest to newest. The
symbols in the virtual buffer, which are needed for purposes
of encoding and decoding, are not transmitted. As usual, let
denote the number of virtual symbols in row i.
mi =
Under the assumption of that only the real buffer is sent, the
rate of a zipper code is given as

Ai|

|

(cid:80)L

1

i=0 (ki −
i=0 (ni −
where, assuming the limits exist,

R = lim
L
→∞

(cid:80)L

−

−

1

mi)
mi)

=

m
m

,

k
n

−
−

(1)

k = lim
L
→∞

1
L
(cid:88)
−

i=0

ki
L

, n = lim
→∞

L

1
L
(cid:88)
−

i=0

ni
L

, m = lim
→∞

L

1
L
(cid:88)
−

i=0

mi
L

.

For example, staircase codes with staircase block size m
m
uses a ﬁxed constituent code of length 2m and dimension k.
Thus, n = 2m, k = k, and m = m, thereby achieving a rate
R = k

1 (assuming k

×

m > 1).

m −

E. Decoding

Suppose that we transmit real symbols in positions indexed
by B. At the receiver we can form a buffer c(cid:48) by ﬁlling
in the real positions from symbols received at the output of
the channel, and ﬁlling in virtual positions by copying real
received symbols as prescribed by the interleaver map φ. We
generally assume a hard-decision channel, i.e., we assume that
the channel outputs are elements of F2, though it is possible
to consider more general situations with various amounts of
reliability information in the form of erasures or log-likelihood
ratios. The received buffer c(cid:48)
is not necessarily a zipper
codeword, since, due to channel noise or other impairments
causing detection errors, the rows aren’t necessarily codewords
of the corresponding constituent codes. Ideally, the aim of
the decoder would be to recover a valid zipper codeword
while making as few changes to c(cid:48) as possible. However,
such optimal minimum Hamming distance decoding is often
too complicated to implement, so in practice some form of
iterative decoding is used, making changes to the rows one at
a time using the constraints imposed only by the constituent
code that constrains that row, and usually revisiting each row
a number of times.

3

−

−

M +1, c(cid:48)i

Decoding is typically performed within a sliding window
of M consecutive rows c(cid:48)i
M +2, . . . , c(cid:48)i from the
received buffer. Many of the virtual symbols in these rows
will, however, be copies of symbols from outside the sliding
window (which, ideally, will have been corrected by previous
decoding iterations). The decoder operates by decoding the
rows within the decoding window. When the decoder performs
correction operations (ﬂipping the value of one or more bits
in a row), all copies of the affected bits within the decoding
window (as determined by the interleaver map) will also
need to be ﬂipped. After a number of iterations have been
performed, the sliding window can be advanced (by one or,
more usually, several rows), and the corrected information
symbols leaving the window can be delivered as the decoder
output. Numerous variations of this basic scheme are possible.
In one round of so-called exhaustive decoding, every row
in the decoding window is visited (exactly once) by the
corresponding constituent decoder. Each bit is decoded (in a
round) as many times as it appears in the window. Exhaustive
decoding can be performed in serial fashion (one row at a
time), or in parallel (usually under the constraint that decoders
operating in parallel don’t operate on the same bits).

In one round of so-called pipelined decoding, only a subset
of the rows in the decoding window (every Lth row, say,
for some parameter L) are visited by constituent decoders.
This method may be faster than exhaustive decoding, but,
depending on the interleaver map, some bits may not be visited
by a decoder at all. Thus, pipelined decoding is suitable only
for certain types of interleaver maps that ensure that as many
bits as possible are visited by the constituent decoders. Similar
to exhaustive decoding, pipelined decoding can be done in
series or parallel.

Under both of these decoding methodologies, decoding can
be performed in multiple rounds, until no more errors can be
corrected or until some maximum number of allowed decoding
rounds is reached.

Additional strategies can also be applied to these decoding

procedures.

In chunk decoding, rather than advancing the sliding win-
dow one row at a time, the window is advanced only after a
speciﬁed number of new rows, called a chunk, is received.

In decoding with fresh/stale ﬂags, a “fresh/stale” status
indicator is maintained for each buffer row. The indicator is
set to “fresh” whenever a change is made to the row (for
example, if the row is newly arrived, or a bit has been ﬂipped
in that row due to a correction elsewhere); otherwise, after a
decoding it is set to “stale”. In each iteration, decoders can
skip over stale rows (since nothing has changed in that row
since the previous iteration, and therefore the row has either
been corrected or has been determined to be uncorrectable).
In decoding with periodic truncation, a fraction of the
message positions are reserved to be set to known values
(for example, zero). The known symbols do not need to be
transmitted, as they can be ﬁlled in perfectly at the receiver.
One approach would be to alternate between sending data
in, say, J consecutive rows, and not sending data (or, more
precisely, sending only parity symbols) in τ consecutive rows.
We call J and τ the transmission length and truncation length,

4

Fig. 2. Staircase code (left); corresponding zipper code (right).

respectively. This method is a generalization of staircase
code “termination” discussed in [26], and is a form of code
“shortening” as deﬁned in coding theory. The shortened code
will have a lower code rate than the zipper code from which
it is derived.

In dynamic decoding, the decoder is implemented with a
number of constituent decoders that can operate in parallel and
that can be assigned dynamically (according to a scheduling
module) to the rows to be decoded. Equipping a decoding
engine with the ﬂexibility to assign decoders to the rows
where work needs to be done results in increased hardware
utilization (reduced computational idling). Dynamic decoding
can achieve similar decoding performance with fewer compu-
tational resources than without dynamic decoding [27].

Although they fall outside the scope of this paper, a variety
of soft-decision or soft-aided decoder architectures are also
possible. Among these, we mention anchor decoding [28],
“trusted symbol” decoding [29], soft-aided decoding [30]–
[33], and error-and-erasure decoding [2], [34].

III. EXAMPLES

This section gives some examples of related spatially-
coupled codes that can be described as zipper codes. Due to
space constraints, only a few codes will be described in detail,
but other codes that can be described as zipper codes include
those in [5]–[9].

A. Staircase Codes

∈

×
N, every row of (cid:2)ST
i
of length 2m, where ST
i

Staircase codes [3] are characterized by having an inﬁnite
m: S0, S1, . . . such that,
sequence of matrices of size m
(cid:3) is a codeword of
for each i
Si+1
a systematic constituent code
is
C
the transpose of Si. The initial block S0 is all zero (and not
transmitted). The codes are so named because the sequence of
matrices form a staircase-like pattern when arranged as shown
in Fig. 2 (left), in which each row and each column must be a
codeword of
, and where the dark-ﬁlled regions hold parity
symbols.

C

Staircase codes correspond to zipper codes with a ﬁxed
of length 2m, and a zipping
(systematic) constituent code
C
N, i.e., the virtual positions
pair with Ai = [m] for all i
∈
comprise the ﬁrst m positions in each row. The interleaver
map φ is m-periodic and deﬁned to perform a transposition
operation, i.e.,

φ(mi + r, j) = (m(i

1) + j, m + r) , for r

[m].

∈

−

The resulting buffer then forms the pattern shown in Fig. 2
(right).

Fig. 3. Tightly braided code with (7, 4) Hamming constituent code (left);
corresponding zipper code (right), with numbers indexing constituent code-
words.

B. Braided Block Codes

Braided block codes [4] are a type of convolutional code
whose codewords can be represented as a subarray of an
inﬁnite two dimensional array constrained by two interacting
constituent codes, one providing constraints on rows and the
other providing constraints on columns. An example of a
codeword from a rate 1/7 tightly braided block code from [4]
is shown in Fig. 3 (left). In this example, each row and each
column in the diagram must form a codeword of the binary
(7, 4) Hamming code. The information positions are labelled
a, b, c, . . . and the positions of parity symbols are shown with
dark-ﬁlled tiles.

This tightly braided block code corresponds to a zipper code
with ﬁxed (7, 4) Hamming constituent code. The zipping pair
is deﬁned so that Ai = [3] when i is even, and Ai = [4] when
i is odd. The interleaver map is given as

φ(i, j) =






(i + 2j
−
2j
(i
−
1, 3)
(i

−
−

5, 6
j)
−
3, 4 + j)

for i even,
for i odd, j
= 3,
for i odd, j = 3,

where the last case corresponds to copying an information
symbol from the row above. In this example, only even-
numbered rows contain an information symbol. The name
“zipper code” derives from the buffer pattern formed in this
example.

C. Diagonal Zipper Codes

In this subsection, we introduce two interleaver maps that
couple the bits of a zipper code in a regular (“hardware-
friendly”) fashion. These interleaver maps generalize those of
staircase codes.

1) Tiled Diagonal Zipper Codes: Tiled diagonal zipper
codes are a generalization of staircase codes that are deﬁned
deﬁned in terms of w
w “tiles” of symbols, a ﬁxed (system-
with length 2Lw, and a zipping pair
atic) constituent code
with Ai = [Lw] (so that virtual positions comprise the ﬁrst
Lw positions in each buffer row), where the parameter L is
a positive integer. The interleaver map is deﬁned so that each
w tile within the virtual buffer is the transpose of some
w
w tile within the real buffer, as illustrated in Fig. 4.
w

×
C

×
×

ST0S1ST1S2ST2S3ST0S1ST2S3ST4000000000aˆa1ˆa2ˆa300˜a1bˆb1ˆb2ˆb30˜a2˜b1cˆc1ˆc2ˆc3˜a3˜b2˜c1dˆd1ˆd2ˆd3˜b3˜c2˜d1˜c3˜d2˜d301234567000aˆa1ˆa2ˆa3000a˜a1˜a2˜a300˜a1bˆb1ˆb2ˆb300ˆa1b˜b1˜b2˜b30˜a2˜b1cˆc1ˆc2ˆc30ˆa2ˆb1c˜c1˜c2˜c3˜a3˜b2˜c1dˆd1ˆd2ˆd3ˆa3ˆb2ˆc1d˜d1˜d2˜d301234567(cid:54)
5

Fig. 4. Tiled diagonal zipper code with L = 3, tile size w×w, and interleaver
map as described in (2).

IV. DESIGN EXAMPLES

Fig. 5. Delayed diagonal zipper code with m = 8 and various delay values δ.

To specify the interleaver map precisely, we must introduce
[2L]

a coordinate system for tiles. For a buffer c, for any s
and for any q

N, let

∈

∈






Tq,s =

cwq,ws
...
cwq+w

1,ws

−

cwq,ws+w
...

1

−

cwq+w

1,ws+w

1

−

−

· · ·
. . .

· · ·




 .

×

The w
w matrix Tq,s is a tile located within the buffer whose
top left entry has position (wq, ws). When s < L, such a tile
comprises only virtual symbols, and therefore it is called a
virtual tile; otherwise it is a real tile. For ﬁxed q, the set of
tiles

are said to form the qth tile row.
[2L]
Tq,s : s
}
∈
{
[L] (indexing a virtual tile), we would like to
For any s
∈
have Tq,s = T T
1,L+s. Thus the ﬁrst virtual tile in tile row
q
−
q is the transpose of the ﬁrst real tile located one tile row
earlier, the second virtual tile in tile row q is the transpose of
the second real tile located two tile rows earlier, and so on.
The interleaver map that accomplishes this task is given as

−

s

φ(wq + i, ws + j) = (w(q

s

−

−

1) + j, w(L + s) + i). (2)

Fig. 4 shows an example of a tiled diagonal zipper code with
L = 3.

When w = 1 (the case of 1

1 tiles) tiled diagonal zipper
×
codes recover the interleaving pattern of the continuously
interleaved BCH (CI-BCH) codes described in [6]. When
L = 1, tiled diagonal zipper codes are staircase codes.

2) Delayed Diagonal Zipper Codes: Delayed diagonal zip-
per codes are variants of tiled diagonal zipper codes with
w = 1 and an added “delay” in the interleaver map. Speciﬁ-
cally, the interleaver map is given by

φ(i, j) = (i

j

−

−

δ, j + m),

where the positive integer δ is the delay parameter. When
δ = 1, the interleaver map is identical to the interleaver map
(2) with w = 1. Fig. 5 illustrates the buffer of a delayed
diagonal zipper code with m = 8. As will show in Section V,
the introduction of delay in the interleaver map reduces the
multiplicity of minimal stall patterns. Delayed diagonal zipper
w tiles, with w > 1,
codes can be generalized to the case of w
in the obvious way.

×

In this section, we present software simulation results for
several tiled diagonal and delayed diagonal zipper code design
examples.

A. Simulation Setup

We simulate transmission of zipper codewords over a binary
symmetric channel with crossover probability p. This corre-
sponds to binary antipodal signalling over an additive white
Gaussian noise channel (Bi-AWGN) with hard-decision detec-
tion, but it may also model other communications scenarios
that give rise to independent and symmetrically distributed
bit errors. The Shannon limit at rate R for such a channel is
the largest crossover probability p for which it is theoretically
possible to communicate at rate R (bit/channel use) with
arbitrarily small probability of error. For the Bi-AWGN, this
value of p is achieved at some particular signal-to-noise
ratio (SNR). A code of ﬁnite length will achieve sufﬁciently
small error probability only at some crossover probability
smaller than the Shannon limit, corresponding to a larger Bi-
AWGN SNR. The “gap to the Shannon limit” is then deﬁned
as the difference (in decibels) between the Bi-AWGN SNR
corresponding to the Shannon limit and the Bi-AWGN SNR
at which the code achieves sufﬁciently small error probability.
By “sufﬁciently small error probability” we mean a post-
15 or smaller.
correction (post-FEC) bit error rate (BER) of 10−
As we cannot reliably measure such low error rates in any
reasonable amount of time using software simulations, we use
a least-squares ﬁt linear extrapolation (on the log-log scale)
of our measured error rates, in order to estimate the BSC
crossover probability p∗ at which the post-FEC BER achieves
10−

15.

In all of our design examples, we use shortened t-error-
correcting (n, k) BCH constituent codes, where n = 2m. We
made no attempt to optimize the positions at which the code
is shortened. The virtual buffer and the real buffer both have
width m. We use a causal, periodic, bijective interleaver map
that implements a diagonal or delayed diagonal zipper code.
Decoding is performed using exhaustive decoding, with at
most ﬁve rounds per window of size M rows (thus containing
M m real symbols). We use chunk decoding with chunk size
m, fresh/stale ﬂags, and periodic truncation with transmission
length J = 995m and τ = 5m.

TTq,2TTq,1TTq,0Tq,0Tq,1Tq,2φcw(q−1)+i,w+jcw(q−3)+j,4w+iwwδ=1δ=3δ=76

Fig. 6. Simulation results of rate 0.97 tiled diagonal zipper codes (w = 1,
t = 3 constituent code) with different decoding window size.

Fig. 8. Simulation results of rate 0.967 tiled diagonal zipper codes (t = 3
constituent code) with different delay parameters

Fig. 7. Simulation results of tiled diagonal zipper codes (w = 1, t = 3
constituent code) over different code rates. Error bars are located one standard
deviation from the mean.

Fig. 9. Simulation results of rate 0.967 delayed diagonal zipper codes (t = 3
constituent code) with different delay parameters

B. Varying Decoding Window Sizes

C. Different Code Rates

We simulated a rate 0.97 tiled diagonal zipper code with
w = 1 and m = 1200, (corresponding to a CI-BCH code [6])
having a (2400, 2364, t = 3) shortened BCH constituent code,
over varying decoding window sizes. As shown in Fig. 6, we
observe an improvement in the decoding performance as well
as disappearing error ﬂare as we increase the decoding window
sizes. This is due to the fact that larger decoding windows
provide each symbol with a larger number of decoding rounds.
However, as expected, we see a diminishing return as the
window size increases, with only slight improvement when
increasing the decoding window size from 4m2 = 5.76 Mb
to 5m2 = 7.20 Mb. Simulation results for a variety of
different tiled diagonal zipper codes indicate that choosing
the window size near 5m2 gives nearly best possible decoding
performance.

As shown in Fig. 7, we simulated the decoding of tiled
diagonal zipper codes with tile size w = 1 having different
code rates, as summarized in Table I. The decoding window
size was set to 5m2 in all cases. We see that the gap to
the Shannon limit decreases as the rate increases, which is
consistent with the theoretical analysis of [12].

TABLE I
SIMULATION PARAMETERS, THRESHOLDS, AND GAPS TO THE SHANNON
LIMIT

(n, k, t)

D.W. Size

Rate m
0.960 825 (1650, 1617, 3) 3.4 Mb 2.68 · 10−3
0.970 1200 (2400, 2364, 3) 7.2 Mb 2.03 · 10−3
0.975 1440 (2880, 2844, 3) 10.4 Mb 1.63 · 10−3
0.980 1800 (3600, 3564, 3) 16.2 Mb 1.24 · 10−3

p∗

Gap (dB)
0.503
0.412
0.398
0.393

1.9522.052.1·10−310−810−710−610−510−4crossoverprobabilitypost-FECBER2.88Mb3.24Mb3.60Mb3.96Mb4.32Mb5.76Mb7.20Mb1.522.53·10−310−910−810−710−610−510−4crossoverprobabilitypost-FECBER0.9800.9750.9700.9602.12.122.142.162.182.2·10−310−910−810−710−610−510−410−3crossoverprobabilitypost-FECBERw=1w=100w=500w=10002.12.122.142.16·10−310−910−810−710−610−510−4crossoverprobabilitypost-FECBERδ=1δ=100δ=200δ=300δ=3347

Fig. 11. Graph representation of a tiled diagonal zipper code with m = 4,
w = 1.

performance versus complexity for various rate 0.96 diagonal
zipper codes. As expected, the gap to the Shannon limit is
reduced by increasing the complexity of the constituent code,
but with diminishing returns.

V. STALL PATTERN ANALYSIS

This section will describe how error events in zipper
decoders are characterized via error and stall patterns. For
simplicity, throughout this section we will be focusing on
zipper codes whose interleaver maps are bijective.

A. Graph Representation of Zipper Codes

Due to the spatially-coupled structure of zipper codes, it
can be helpful to describe them as codes deﬁned on graphs.
Following the notation of Sec. II, we consider a zipper code
C1, . . ., with
corresponding to constituent code sequence
C0,
N, the
respective information sets I0, I1, . . .. For each i
virtual symbols in the ith row of a buffer are indexed by the
Ii. Fix a bijective interleaver map φ = (φ1, φ2). Let
set Ai ⊆

∈

φ1(Ai) =

φ1(i, j) : j
{

Ai} ∩

∈

N

be the set of row indices from which the virtual symbols in
row i are copied (excluding any negative row indices).

Deﬁne a graph G = (V, E) whose vertex set V = N is the

set of natural numbers, and whose edge set

E =

i, j

: i

N, j

.
φ1(Ai)
}

}

∈

{{

∈
The vertices then correspond to constituent codes, with an edge
joining two vertices if the corresponding codes have a symbol
in common. Parallel edges are permitted, thus we interpret
the edge set as a multiset (a set in which elements may have
multiplicity greater than one). The number of edges between
two vertices is then equal to the number of symbols that the
corresponding codes have in common. Allowing for parallel
edges, the degree of vertex i is equal to ni, the blocklength
of
Ci, unless some virtual symbols in row i are copied from
rows with negative row index, in which case the corresponding
edges are missing.
Example 1. Recall that the interleaver map of a tiled diagonal
1, m+j).
zipper code with w = 1 is given by φ(i, j) = (i
N.
N, we have φ1(Ai) =
For each i
i
{
Thus vertex i will have neighbours

−
−
2, . . . , i

1, i

}∩

m

−

−

−

∈

j

(i) =

i

1, i

2, . . . , i

m

N.

{

±

N

±
Vertices m, m + 1, m + 2, . . . therefore have degree n = 2m.
The graph of a tiled diagonal zipper code with m = 4, w = 1
(cid:74)
is shown in Fig. 11.

} ∩

±

Fig. 10. Gap to the Shannon limit for different decoding radius of a rate 0.96
delayed diagonal zipper code with δ = 1. The values of m and constituent
code parameters (n, k, t) are shown next to each point. In all cases, we have
the decoding window size to be 5m2 bits

D. Tiled Diagonal and Delayed Diagonal Zipper Codes

We simulated rate 0.967 codes with m = 1000, based
on a (2000, 1967, t = 3) shortened BCH constituent code,
with 5 Mb decoding window size. Various tiled and delayed
diagonal zipper codes having a variety of tile sizes w and
delay parameter δ, as summarized in Table II, were simulated.
Performance curves for the tiled diagonal codes are shown in
Fig. 8 and those for the delayed diagonal codes are shown in
Fig. 9.

In both cases, increasing w or δ helps improve the decoding
with an improvement to the gap to the Shannon limit of
0.039 dB when compared to the δ = w = 1 case. A
0.028
stall pattern analysis for tiled diagonal and delayed diagonal
zipper codes, which may provide theoretical justiﬁcation for
these performance improvements, is given in Sec. V.

∼

E. Performance versus Complexity

Let us deﬁne the performance of a zipper code as its gap
15 output bit error rate, and its
to the Shannon limit at 10−
complexity as the decoding radius t of its constituent code.
(A more appropriate complexity measure might be t2, as it is
known that the power consumption of a Berlekamp-Massey-
(t2) [35].) Fig. 10 plots
based BCH decoder circuits grows as

O

TABLE II
GAP TO THE SHANNON LIMIT AT 10−15 POST-FEC BER FOR TILED
DIAGONAL AND DELAYED DIAGONAL ZIPPER CODES

Type
tiled/delayed
tiled
tiled
tiled
delayed
delayed
delayed
delayed

w or δ
1
100
500
1000
100
200
300
334

p∗
2.015 · 10−3
2.036 · 10−3
2.060 · 10−3
2.099 · 10−3
2.035 · 10−3
2.048 · 10−3
2.071 · 10−3
2.073 · 10−3

Gap (dB)
0.536
0.526
0.514
0.497
0.526
0.520
0.509
0.508

23450.450.50.550.60.650.70.75decodingradiusofC(t)gaptotheShannonlimit(dB)m=500(1000,980,2)m=825(1650,1617,3)m=1200(2400,2352,4)m=1508(3016,2956,5)0123456789...8

Graph representations for zipper codes in which symbols
are copied more than once (i.e., when the interleaver map is
non-bijective) can be deﬁned by appealing to hypergraphs (in
which hyperedges comprise more than two vertices), to a bi-
partite representation such as a factor graph, or by introducing
additional constituent repetition-code constraints. We will not
pursue such representations in this paper.

B. Error and Stall Patterns

Recall that B is a set containing the positions of all real
symbols in a buffer. An error pattern S
B is any nonempty
subset of B containing the positions of erroneous symbols in
the real part of a received buffer. For any error pattern S, we
deﬁne

⊆

S∗ = S

φ−

1(s)

(cid:91)

∪

S

s

∈

to be the complete set of positions of errors and their duplicates
to
in the virtual set, and we deﬁne π(S∗) =
be the set of affected rows.

i : (i, j)
{

S∗

∈

}

C

∈

Ci =

For simplicity, throughout this section we assume that the
with
constituent code is identical for all rows, i.e.,
N. In addition, we assume
decoding radius ti = t for all i
that we use a genie-aided, miscorrection-free constituent de-
coder. Such a decoder is able to correct up to t errors in a
row, but always fails to decode (never miscorrecting) when
the number of errors in a row exceeds t. We assume that
this genie-aided decoder visits rows in a decoding window as
many times as is needed, reducing the error pattern size until
no further correction is possible. Should some errors remain
after this decoding procedure, we call the remaining errors a
stall pattern. In a stall pattern, we must have at least t + 1
errors in every remaining affected row.

We will consider only strictly causal interleaver maps that
induce at most one shared symbol between any two distinct
rows of a zipper code. This means that the resulting graph is
simple, i.e., it contains no parallel edges or self-loops. Each
edge of a such a simple graph corresponds to one codeword
symbol. We refer to such an interleaver map as scattering.

C. Decoding on a Graph

Assuming a scattering interleaver map, an error pattern S
can be represented as a subgraph of the graph representing
the zipper code. If the zipper code has graph representation
G = (V, E), the graph representation of S is GS = (VS, ES),
where VS = π(S∗)
V (i.e., the vertex set of S contains
vertices corresponding to the rows affected by S) and ES =
1
(i.e., the edges in Es
{{
correspond to symbols in error). From this construction, the
number of edges in GS is exactly the cardinality of S. We
the size of the error pattern S.
call

1 (i, k)
φ−
}

: (i, k)

S, j

i, j

=

⊆

∈

∈

}

Suppose that the constituent code

can correct up to t
errors. The action of the genie-aided decoder can then be
described as an edge-peeling process in the error pattern graph
GS = (VS, ES):

C

S
|

|

ES|

|

1) For each vertex v

VS with deg(v)

t, remove v from

VS as well as all edges in Es incident on v.

∈

≤

Fig. 12. Example of an error pattern with underlying stall pattern in both
array (top) and graph (bottom) forms. In this example, the constituent code
is double-error-correcting (t = 2).

2) Repeat step 1 until either the graph is empty or all

remaining vertices have degree t + 1 or higher.
This procedure will terminate either in an empty graph (suc-
cessful decoding), or in a (t + 1)-core of GS—the largest
induced subgraph of GS with the property that all vertices
have degree at least t + 1. Sometimes, though not always,
the (t + 1)-core will form a (t + 2)-clique, i.e., a subgraph
of GS comprising t + 2 vertices all of which are neighbours
(a complete subgraph). Such a pattern is uncorrectable by the
genie-aided decoder. More generally, we call GS a stall pattern
if each vertex in GS has degree at least t + 1, making it
uncorrectable.

The following example illustrates error and stall patterns in

both array and graph representations.
Example 2. Consider a zipper code with a constituent code
C
capable of correcting t = 2 errors. Suppose that we receive an
error pattern with seven errors as shown in Figure 12. Since
rows 1, 3, 6, and 8 have at least 3 errors each, we cannot
correct them. However, we can still correct row 4, which has
only one error. Thus we will remove the error from row 4 and
its corresponding entry in row 6, or equivalently, we remove
vertex 4 and its incident edges. However, the remaining errors
cannot be corrected and so those errors form a stall pattern.
The 4-clique formed by vertices 1, 3, 6, and 8 is a stall pattern
and it is also the 3-core of the error pattern graph from which
(cid:74)
we started.

D. Properties of Stall Patterns of Zipper Codes

The following theorem bounds the size of a stall pattern in
a zipper code with a bijective and scattering interleaver map.

Theorem 1. A stall pattern S for a zipper code with a t-
error-correcting constituent code and having a bijective and
scattering interleaver map satisﬁes

1
2 (t + 1)(t + 2).

S
|

| ≥

abcadebdgcegff01234567816384abcdefgstallpatterndecodable9

in its graph, the number of errors in a stall pattern is at least
(cid:24) t + 1
b

(t + 1).

1 +

(cid:25)(cid:19)

1
2

(cid:18)

Fig. 13. Graph representation of a stall pattern of size 6 of tiled diagonal
zipper code, w = 1, m = 3, t = 2.

E. Error Floor Approximation

Proof: Any vertex in a stall pattern graph must have at
neighbours. The result then follows from the

least
same argument as in the proof of Theorem 1.

(t + 1)/b
(cid:101)

(cid:100)

≥

Proof: Let GS = (VS, ES) be the graph representation
of stall pattern S, and let v be any vertex in VS. Then, since
GS is a stall pattern, deg(v)
t + 1. Suppose that
NS(v) =
are the neighbours of v in GS. Then, since
v1, v2, . . . , vdeg v}
{
each vi is a vertex in a stall pattern, deg(vi)
t + 1. Hence,
there must be at least deg(v) + 1
t + 2 vertices in GS with
each vertex having degree t + 1 or higher. By the handshaking
lemma of graph theory, we have

ES| ≥
|
2 (t+1)(t+2) is precisely the number
of edges of a complete graph with t + 2 vertices. In fact, we
will now show that the existence of a (t + 2)-clique in the
graph representation of the zipper code is a necessary and
sufﬁcient condition for the existence of a stall pattern of size
1
2 (t + 1)(t + 2).

It is worth noting that 1

(t+1)(t+2)
2

S
|

=

≥

≥

|

.

Proposition 1. Let G = (V, E) be the graph representation of
a zipper code with a t-error-correcting constituent code and a
bijective and scattering interleaver map. Then the code has a
stall pattern S of size 1
2 (t + 1)(t + 2) if and only if G contains
a (t + 2)-clique.

) Every (t + 2)-clique corresponds to a stall
2 (t + 1)(t + 2).

Proof: (
⇐
pattern of size 1
) Suppose by way of contradiction that a stall pattern S
(
⇒
of size 1
2 (t + 1)(t + 2) has a graph GS with more than t + 2
vertices. The average degree of the vertices is then less than
/(t + 2) = t + 1, which implies implies that VS contains
2
|
|
at least one vertex of degree t or lower, contradicting the fact
that S is a stall pattern. On the other hand, if GS contains
fewer than t + 2 vertices, then there exists a vertex in VS with
degree greater than t + 1, which is impossible in a simple
graph.

S

An example of an interleaver map that yields a stall pattern
of size 1
2 (t + 1)(t + 2) is the tiled diagonal zipper code with
tile size 1 (or delayed diagonal with delay 1). Fig. 13 shows an
example of a tiled diagonal zipper code with w = 1, m = 3,
t = 2.

Theorem 1 can be generalized to strictly causal non-
scattering interleaver maps that allow constituent codes to
have up to b bits in common, so that the resulting graph
representation has up to b parallel edges connecting any two
vertices.

The presence of stall patterns creates so-called “error ﬂoors”
in the performance curves of zipper codes. We may approx-
imate the location of the error ﬂoor using a union bound
technique similar that used in [3]. We consider a decoding
m, and denote the set of all stall patterns
window of size M
. We determine the error
in the decoding window to be
S
ﬂoor estimate by enumeration of
, evaluating (an upper
bound on) the probability that the particular error pattern arises
at the output of a binary symmetric channel with crossover
probability p. This then gives

×

S

BERﬂoor

1
M m

≤

(cid:88)

S

∈S

S

|

|.

S
p|
|

(3)

Suppose that we could determine exactly the sizes of stall
patterns that can occur in a decoding window. We could then
rewrite (3) as

BERﬂoor

1
M m

≤

(cid:88)

(cid:96)

∈L

N(cid:96)p(cid:96),

(4)

L

where
denotes the set of all stall-pattern sizes that can occur
in the decoding window of size M m and N(cid:96) denotes the
number of occurrences of stall patterns of size (cid:96). Note that
since we only consider stall patterns that can ﬁt in the decoding
window, we have (cid:96)

M m.

The possible sizes and the number of occurrences of stall
patterns of certain size depend on the interleaver map. For
example, it is possible to construct stall patterns of size 1
2 (t +
1)(t+2) in tiled diagonal zipper codes with tile size 1, but not
in staircase codes, whose smallest stall pattern size is (t + 1)2
[3], [36].

≤

L

≥

∈ L

Given a decoding window, a set

of possible stall pattern
sizes that can ﬁt in the window, and crossover probability p,
to be dominant if
we call the stall patterns of size (cid:96)∗
N(cid:96)∗ p(cid:96)∗
N(cid:96)p(cid:96) for all (cid:96)
. In general, the minimum-sized
stall patterns may not be dominant since it is possible that the
multiplicity of larger stall patterns causes a dominant N(cid:96)p(cid:96)
term. However, for sufﬁciently small p, we can assume that
stall patterns of minimum size are dominant. The error ﬂoor
can be then further approximated as the contribution of just
the minimum-sized stall patterns, i.e., the right hand side of
(4) is approximately N(cid:96)∗ p(cid:96)∗

, where (cid:96)∗ = min

∈ L

.
L

F. Eliminating Small-Sized Stall Patterns of Diagonal Zipper
Codes

Theorem 2. For a zipper code with t-error-correcting con-
stituent code having a strictly causal interleaver map that
allows up to b parallel edges between any pair of vertices

We will now describe a few strategies to eliminate stall
2 (t + 1)(t + 2) in tiled and delayed diagonal

patterns of size 1
zipper codes.

0123VirtualRealabcadedbffec0123abcdef10

≥

1) Tiled Diagonal: Our ﬁrst observation is that we can
reduce the multiplicity stall patterns of size 1
2 (t + 1)(t + 2)
by increasing the tile size. To see this, we will ﬁrst count the
occurrences of stall patterns of size 1
2 (t+1)(t+2). Denote the
tile size as w and assume that m = wL, M = wK (K > L),
and L
t + 1. In order to construct a stall pattern of size
1
2 (t + 1)(t + 2), we ﬁrst pick t + 1 tiles from the same row.
We then select a row index at which to place the errors. For
each of the t + 1 tiles, pick one column index at which to
place an error. Those errors will correspond to errors in t + 1
other rows. The positions of the remaining 1
2 t(t + 1) errors in
those rows are then forced. Thus, the number of stall patterns
of size 1

2 (t + 1)(t + 2) is given by

(cid:19)

L
1
(cid:88)
−

s=t

(cid:18)s
t

(K

s

−

−

1)wt+2

(cid:18) L

(cid:19)

≈

t + 1

Kwt+2.

(5)

Having larger tile size will make the values for K and L
lower assuming that the decoding window size is ﬁxed. This
will in turn reduce the multiplicity of stall patterns of size
1
t, it is
2 (t + 1)(t + 2) given by (5). Furthermore once L
impossible to form a stall pattern of size 1

2 (t + 1)(t + 2).

2) Delayed Diagonal: In delayed diagonal zipper codes,
the occurrences and size of the minimum-sized stall patterns
depends on δ. In particular, we will show that having larger
delay reduces the multiplicity of stall patterns of size 1
2 (t +
1)(t + 2).

≤

Proposition 2. For a delayed diagonal zipper code with t-
error-correcting constituent code and delay parameter δ, there
exists a stall pattern of size 1
2 (t + 1)(t + 2) if and only if
δ

m

1

.

−
t

≤

Proof: Without loss of generality, let the ﬁrst affected row

index of the stall pattern be zero.
) We claim that we can form a stall pattern of size
(
⇐
1
2 (t + 1)(t + 2) whose set of row indices is given by
. To see this, ﬁrst observe that
0, δ, 2δ, . . . , (t + 1)δ
I =
}
{
1. The neighbours of row i in
(t + 1)δ = tδ + δ
m + δ
−
the full zipper code graph are then indexed by

≤

(i) =

N

i

(δ + j) : j

[m]

∈

{
±
max(

N.

} ∩
0, i
{

N

N

(t + 1)δ

≤
⊆ N

(i)) and max

Thus, i + (t + 1)δ
} ≥
I. It follows that the
(i) for all i
(i)), so I
min(
rows in I are connected with each other and so it is possible
to form a (t + 2)-clique from I.
(
0, i1, . . . , it+1}
⇒
the row indices of a stall pattern of size 1
it must be true that

with 0 < ii < . . . < it+1 be
2 (t + 1)(t + 2). Then

) Let I =

−

∈

{

i1 ≥
i2 ≥
...
it+1 ≥

0 + δ = δ,
i1 + δ

2δ,

≥

it + δ

≥

(t + 1)δ.

However, we also require that row it+1 to be a neighbour
1. Hence,
of the ﬁrst row, i.e. we require it+1 ≤
m
.
(t + 1)δ
−

m + δ
1, and rearranging yields δ

m + δ

−
≤

≤

−
t

1

Fig. 14. Number of stall patterns of size 1
2 (t+1)(t+2) involving the ﬁrst row
of the decoding window in delayed diagonal zipper codes with m = 1000
and varying t, δ.

m

1

•

−
t

≤

Suppose that δ

. In order to construct a stall pattern
2 (t + 1)(t + 2) with the set of affected row index
, the following constraints must be

of size 1
i0 = 0, i1, . . . , it+1}
I =
{
satisﬁed:
Errors in row 0 must affect row it+1, i.e., it+1 ≤
m
For j = 1, . . . , t + 1, ij −
ij

Thus, the indices i1, . . . , it+1 must be taken from
δ, δ +
{
and any two indices must differ by at least δ.
1, . . . , δ +m
The number of possible combinations of such indices is given
by

1 ≥
−

1
}

δ +

−

−

1.

δ.

•

(cid:18)m

1)

−

t(δ
t + 1

−

(cid:19)

(cid:18)m

=

tδ + t

−
t + 1

(cid:19)

.

In a decoding window with M rows, the number of possible
combinations is therefore at most

(cid:18)m

M

tδ + t

−
t + 1

(cid:19)

.

Example 3. Figure 14 shows the number of stall patterns of
size 1
2 (t + 1)(t + 2) involving the ﬁrst row of the decoding
window in delayed diagonal zipper codes for m = 1000 and
t = 3, 4, 5. Observe that when δ = 1 and t = 3, there are

(cid:19)

(cid:18)1000
4

4.14

×

≈

1010

possible conﬁgurations involving the ﬁrst row. However, there
is only one possible conﬁguration for δ = 333 and stall
334. (cid:74)
patterns of size 1

2 (t + 1)(t + 2) do not exist for δ

≥

VI. CONCLUSIONS

Zipper codes provide a convenient framework for describ-
ing a wide variety of product-like spatially-coupled codes.
Such codes are of interest in high-throughput communication
systems because they can be decoded iteratively using low-
complexity power-efﬁcient constituent decoders while achiev-
ing a gap to the Shannon limit on the binary symmetric channel
of 0.5 dB or less at high code rates. We have introduced tiled

10010110210010410810121016δNumberofpatternst=3t=4t=511

[17] M. Barakatain, D. Lentner, G. B¨oecherer, and F. R. Kschischang,
“Performance-complexity tradeoffs of concatenated FEC for higher-
order modulation,” J. Lightw. Technol., vol. 38, no. 11, pp. 2944–2953,
Mar. 2020.

[18] S. Stern, M. Barakatain, F. Frey, J. Pfeiffer, J. K. Fischer, and R. F.
Fischer, “Coded modulation for four-dimensional signal constellations
with concatenated non-binary forward error correction,” in Proc. 2020
Eur. Conf. Opt. Commun. (ECOC), Dec. 2020, pp. 1–4.

[19] M. Barakatain and F. R. Kschischang, “Low-complexity rate- and
channel-conﬁgurable concatenated codes,” J. Lightw. Technol., vol. 39,
no. 7, pp. 1976–1983, Dec. 2021.

[20] T. Mehmood, M. P. Yankov, and S. Forchhammer, “Rate-adaptive
concatenated multilevel coding with ﬁxed decoding complexity,” in Proc.
11th Int. Symp. Topics Coding (ISTC), Sep. 2021, pp. 1–5.

[21] Y. Tian, Y. Lin, J. Zheng, J. Tang, Q. Huang, H. Ma, T. Rahman,
M. Kuschnerov, R. Leung, and L. Zhang, “800Gb/s-FR4 speciﬁcation
and interoperability analysis,” in Proc. 2021 Opt. Fiber Commun. Conf.
and Exhib. (OFC), Jun. 2021, pp. 1–3.
lane

[22] “200G per
white
2021.
200g-per-lane-for-future-800g-and-16t-modules

paper,”
[Online]. Available:

1.6T modules
Paper,
https://www.800gmsa.com/documents/

800G Pluggable MSA group, White

800G and

future

for

[23] Q. Xie, Z. Luo, S. Xiao, K. Wang, and Z. Yu, “High-throughput zipper
encoder for 800G optical communication system,” in Proc. IEEE Int.
Conf. Integr. Circuits, Technol. and Appl. (ICTA), Nov. 2021, pp. 214–
215.

[24] C. Fougstedt and P. Larsson-Edefors, “Energy-efﬁcient high-throughput
VLSI architectures for product-like codes,” J. Lightw. Technol., vol. 37,
no. 2, pp. 477–485, Jan. 2019.

[25] D. Truhachev, K. El-Sankary, A. Karami, A. Zokaei, and S. Li, “Efﬁcient
implementation of 400 Gbps optical communication FEC,” IEEE Trans.
Circuits Syst. I, vol. 68, no. 1, pp. 496–509, Jan. 2021.

[26] M. Qiu, L. Yang, Y. Xie, and J. Yuan, “Terminated staircase codes for
NAND ﬂash memories,” IEEE Trans. Commun., vol. 66, no. 12, pp.
5861–5875, Aug. 2018.

[27] K. Huang, S. Xiao, D. Chang, X. Yang, Q. Huang, H. Ma, and W. K.
Leung, “Dynamic decoding of zipper codes,” in Proc. 2021 Opt. Fiber
Commun. Conf. and Exhib. (OFC), Jun. 2021, pp. 1–3.

[28] C. H¨ager and H. D. Pﬁster, “Approaching miscorrection-free perfor-
mance of product codes with anchor decoding,” IEEE Trans. Commun.,
vol. 66, no. 7, pp. 2797–2808, Mar. 2018.

[29] C. Senger, “Improved iterative decoding of product codes based on
trusted symbols,” in Proc. 2019 IEEE Int. Symp. Inf. Theory (ISIT),
Jul. 2019, pp. 1342–1346.

[30] Y. Lei, B. Chen, G. Liga, X. Deng, Z. Cao, J. Li, K. Xu, and A. Alvarado,
“Improved decoding of staircase codes: The soft-aided bit-marking
(SABM) algorithm,” IEEE Trans. Commun., vol. 67, no. 12, pp. 8220–
8232, Oct. 2019.

[31] Y. Lei, B. Chen, G. Liga, A. Balatsoukas-Stimming, K. Sun, and
A. Alvarado, “A soft-aided staircase decoder using three-level channel
reliabilities,” J. Lightw. Technol., vol. 39, no. 19, pp. 6191–6203, Jul.
2021.

[32] A. Sheikh, A. Graell i Amat, G. Liva, and A. Alvarado, “Reﬁned
reliability combining for binary message passing decoding of product
codes,” J. Lightw. Technol., vol. 39, no. 15, pp. 4958–4973, May 2021.
[33] A. Sheikh, A. G. i. Amat, and A. Alvarado, “Novel high-throughput
decoding algorithms for product and staircase codes based on error-and-
erasure decoding,” J. Lightw. Technol., vol. 39, no. 15, pp. 4909–4922,
May 2021.

[34] L. Rapp and L. Schmalen, “Error-and-erasure decoding of product and
staircase codes,” IEEE Trans. Commun., vol. 70, no. 1, pp. 32–44, Jan.
2022.

[35] W. Liu, J. Rho, and W. Sung, “Low-power high-throughput BCH error
correction VLSI design for multi-level cell NAND ﬂash memories,” in
Proc. 2006 IEEE Workshop Signal Process. Syst. Design and Implemen-
tation, Oct. 2006, pp. 303–308.

[36] L. Holzbaur, H. Bartz, and A. Wachter-Zeh, “Improved decoding and er-
ror ﬂoor analysis of staircase codes,” Designs, Codes and Cryptography,
vol. 87, no. 2, pp. 647–664, Mar. 2019.

diagonal and delayed diagonal interleaver maps that couple
the constituent codes in regular (hardware-friendly) patterns.
These interleaver maps provide ﬂexibility in trading off de-
coding window size and code performance. A combinatorial
analysis of stall patterns that arise with such interleaver maps
shows that increasing tile size or delay can indeed have a
beneﬁcial effect on reducing the error ﬂoor of the code.

Further research on zipper codes is needed to address the
design of interleaver maps that give rise to codes with large
minimum Hamming distance or large dominant stall-pattern
size. Tradeoffs between code performance and decoding la-
tency should be better characterized. Can soft-decision (or
soft-aided) decoding methods be introduced without excessive
increase in decoding complexity and decoder power consump-
tion? No doubt many further interesting questions can be
formulated.

REFERENCES

[1] A. Y. Sukmadji, U. Mart´ınez-Pe˜nas, and F. R. Kschischang, “Zipper
codes: Spatially-coupled product-like codes with iterative algebraic
decoding,” in Proc. 16th Can. Workshop Inf. Theory (CWIT), Jun. 2019,
pp. 1–6.

[2] A. Y. Sukmadji, “Zipper codes: High-rate spatially-coupled codes with
algebraic component codes,” Master’s thesis, University of Toronto,
Canada, 2020.

[3] B. P. Smith, A. Farhood, A. Hunt, F. R. Kschischang, and J. Lodge,
“Staircase codes: FEC for 100 Gb/s OTN,” J. Lightw. Technol., vol. 30,
no. 1, pp. 110–117, Nov. 2012.

[4] A. Jim´enez Feltstr¨om, D. Truhachev, M. Lentmaier, and K. S. Zigan-
girov, “Braided block codes,” IEEE Trans. Inf. Theory, vol. 55, no. 6,
pp. 2640–2658, Jun. 2009.

[5] C. P. M. J. Baggen and L. M. G. M. Tolhuizen, “On diamond codes,”
IEEE Trans. Inf. Theory, vol. 43, no. 5, pp. 1400–1411, Sep. 1997.
[6] T. Coe, “Continuously interleaved error correction,” U.S. Patent

8 276 047, Sep., 2012.

[7] P. Northcott, “Cyclically interleaved dual BCH, with simultaneous
decode and per-codeword maximum likelihood reconciliation,” U.S.
Patent 8 479 084, Jul., 2013.

[8] M. A. Sluyski, “Open ROADM MSA 3.01 W-Port digital speciﬁcation
(200G-400G) white paper,” Open ROADM MSA, White Paper, Jul.
2019. [Online]. Available: https://0201.nccdn.net/1 2/000/000/141/b6c/
OpenROADM MSA3.01-W-Port-Digital-Speciﬁcation.docx

[9] G. Montorsi and S. Benedetto, “Design of spatially coupled turbo
product codes for optical communications,” in Proc. 11th Int. Symp.
Topics Coding (ISTC), Sep. 2021, pp. 1–5.

[10] D. J. Costello, D. G. M. Mitchell, P. M. Olmos, and M. Lentmaier,
“Spatially coupled generalized LDPC codes: Introduction and overview,”
in Proc. 10th IEEE Int. Symp. Turbo Codes and Iterative Inf. Process.
(ISTC), Nov. 2018, pp. 1–6.

[11] D. G. M. Mitchell, P. M. Olmos, M. Lentmaier, and D. J. Costello,
“Spatially coupled generalized LDPC codes: Asymptotic analysis and
ﬁnite length scaling,” IEEE Trans. Inf. Theory, vol. 67, no. 6, pp. 3708–
3723, Apr. 2021.

[12] Y. Jian, H. D. Pﬁster, and K. R. Narayanan, “Approaching capacity
at high rates with iterative hard-decision decoding,” IEEE Trans. Inf.
Theory, vol. 63, no. 9, pp. 5752–5773, Sep. 2017.

[13] M. Lentmaier, I. Andriyanova, N. Hassan, and G. Fettweis, “Spatial
coupling - a way to improve the performance and robustness of iterative
decoding,” in Proc. 2015 Eur. Conf. Netw. and Comm., Jun. 2015, pp.
1–2.

[14] M. Weiner, M. Blagojevic, S. Skotnikov, A. Burg, P. Flatresse, and
B. Nikolic, “27.7 A scalable 1.5-to-6Gb/s 6.2-to-38.1mW LDPC decoder
for 60GHz wireless networks in 28nm UTBB FDSOI,” in 2014 IEEE
Int. Solid-State Circuits Conf., Feb. 2014, pp. 464–465.

[15] T. Ou, Z. Zhang, and M. C. Papaefthymiou, “27.6 an 821MHz 7.9Gb/s
7.3pJ/b/iteration charge-recovery LDPC decoder,” in Proc. 2014 IEEE
Int. Solid-State Circuits Conf., Feb. 2014, pp. 462–463.

[16] Y. Lee, H. Yoo, J. Jung, J. Jo, and I. Park, “A 2.74-pJ/bit, 17.7-Gb/s
iterative concatenated-BCH decoder in 65-nm CMOS for NAND ﬂash
memory,” IEEE J. Solid-State Circuits, vol. 48, no. 10, pp. 2531–2540,
Oct. 2013.

