NOSNOC: A Software Package for Numerical
Optimal Control of Nonsmooth Systems

Armin Nurkanovi´c and Moritz Diehl

2
2
0
2

n
u
J

7

]

C
O
.
h
t
a
m

[

2
v
6
1
5
1
1
.
3
0
2
2
:
v
i
X
r
a

Abstract— This letter introduces the NOnSmooth Nu-
merical Optimal Control (NOSNOC) open-source software
package. It is a modular MATLAB tool based on CasADi
and IPOPT for numerically solving Optimal Control Prob-
lems (OCP) with piecewise smooth systems (PSS). The tool
supports: 1) automatic reformulation of systems with state
jumps into PSS (via the time-freezing reformulation [1])
and of PSS into computationally more convenient forms,
2) automatic discretization of the OCP via, e.g., the recently
introduced Finite Elements with Switch Detection [2] which
enables high accuracy optimal control and simulation of
PSS, 3) solution methods for the resulting discrete-time
OCP. The nonsmooth discrete-time OCP are solved with
techniques of continuous optimization in a homotopy pro-
cedure, without the use of integer variables. This enables
the treatment of a broad class of nonsmooth systems in a
uniﬁed way. Two tutorial examples are given. A benchmark
shows that NOSNOC provides both faster and more ac-
curate solutions than conventional approaches, including
mixed-integer formulations.

Index Terms— software, hybrid systems, optimal control,

numerical algorithms

I. INTRODUCTION

N ONSMOOTH and hybrid dynamical systems are a pow-

erful tool to model complex physical and cyber-physical
phenomena. Their theory is well established and many good
numerical simulation algorithms exist [3]. However, optimal
control of nonsmooth systems is yet not wide spread, mainly
due to the computational difﬁculty and lack of software. A
notable exception are mixed integer optimization approaches
[4]. However, they become intractable as soon as nonconvex-
ities appear or exact junction times need to be computed. The
open-source software package NOSNOC is designed to reduce
this gap [5]. We regard a nonsmooth OCP of the following
form:

T

fq(x(t), u(t))dt + fT(x(T ))

min
x(·),u(·)

0
Z

s.t. x0 = s0,

˙x(t) = fi(x(t), u(t)), if x ∈ Ri, i ∈ I, t ∈ [0,T ],

0 ≥ Gineq(x(t), u(t)), t ∈ [0, T ],
0 ≥ GT(x(T )),

(1a)

(1b)

(1c)
(1d)

(1e)

This research was supported by the DFG via Research Unit FOR

2401 and project 424107692 and by the EU via ELO-X 953348.

Armin Nurkanovi´c is with the Department of Microsystems
Engineering (IMTEK), University of Freiburg, Germany, Moritz
Diehl
is with the Department of Microsystems Engineering (IMTEK)
and Department of Mathematics, University of Freiburg, Germany,
{armin.nurkanovic,moritz.diehl}@imtek.uni-freiburg.de

where fq : Rnx × Rnu → R is the stage cost and fT : Rnx →
R is the terminal cost, s0 ∈ Rnx is a given parameter. The
path and terminal constraints are collected in the functions
Gineq : Rnx × Rnu → Rng1 and GT : Rnx → Rng2 ,
respectively. The ODE (1c) is a piecewise smooth system
(PSS), where I := {1, . . . , nf }. The regions Ri are disjoint,
nonempty, connected and open. The functions fi(·) are smooth
on an open neighborhood of Ri, which denotes the closure of
Ri.

The event of x reaching some boundary ∂Ri

is called
a switch. The right-hand side (r.h.s.) of (1c) is in general
discontinuous in x. Several classes of systems with state jumps
can be brought into the form of (1c) via the time-freezing
reformulation [1], [6], [7]. Thus, the focus on PSS enables
a uniﬁed treatment of many different kinds of nonsmooth
systems.

One might wonder why not just to apply standard direct
methods and existing software to problem with a smoothed
version of the r.h.s. of (1c)? The necessity for tailored methods
and software follows from two important results from the sem-
inal paper of Stewart and Anitescu [8]. First, in standard direct
approaches for (1c),
the numerical sensitivities are wrong
no matter how small the integrator step-size is. This often
yields artiﬁcial local minima and impairs the optimization
progress [9]. Second, smoothing delivers correct sensitivi-
ties only if the step-size shrinks faster than the smoothing
parameter. Consequently, even for moderate accuracy, many
optimization variables are needed.

These two difﬁculties are overcome by the recently in-
troduced Finite Elements with Switch Detection (FESD)
method [2]. In this method, the ODE (1c) is transformed
into a Dynamic Complementarity System (DCS). FESD relies
on Runge-Kutta (RK) discretizations of the DCS, but the
integrator step-sizes are left as degrees of freedom as ﬁrst pro-
posed by [10]. Additional constraints ensure implicit and exact
switch detection and eliminate spurious degrees of freedom.
The discretization yields Mathematical Programs with Com-
plementarity Constraints (MPCC). They are highly degenerate
and nonsmooth Nonlinear Programs (NLP) [11], [12], but with
suitable reformulations and homotopy procedures they can be
solved efﬁciently using techniques for smooth NLP, without
any integer variables.

The MATLAB tool NOSNOC [5] aims to automate the whole
tool-chain and to make nonsmooth optimal control problems
solvable for non-experts. In particular, it supports:

• automatic model reformulation of the PSS (1c) into the
©2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including
reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or
reuse of any copyrighted component of this work in other works.

 
 
 
 
 
 
computationally more suitable DCS.

• time-freezing reformulation for systems with state jumps,
reformulations to solve time-optimal control problems
both for PSS and systems with state jumps,

• automatic discretization of the OCP (1) via FESD or RK,
• several algorithms for solving the MPCC with a homo-

topy approach,

• rapid prototyping with different formulations and algo-

rithms for nonsmooth OCP.

It builds on the open-source software packages: CasADi [13]
which is a symbolic framework for nonlinear optimization
and the NLP solver IPOPT [14]. Having these packages as
a back-end enables good computational performance, despite
the fact that all user inputs are provided in MATLAB. All steps
above can be performed in a couple of lines of code without
needing a deep understanding of the numerical methods and
implementation details. In NOSNOC,
the user has only to
specify the functions in (1) and the sets Ri via constraint
functions c(x), cf. Section II. The reformulation, discretization
and solution of the nonsmooth OCP is completely automated.
Notation: The complementarity conditions for two vectors
a, b ∈ Rn read as 0 ≤ a ⊥ b ≥ 0, where a ⊥ b means a⊤b =
0. The so-called C-functions Φ : Rn × Rn → Rn have the
property Φ(a, b) = 0 ⇐⇒ 0 ≤ a ⊥ b ≥ 0, e.g., Φ(a, b) =
min(a, b). The concatenation of two column vectors a ∈ Rna,
b ∈ Rnb is denoted by (a, b) := [a⊤, b⊤]⊤, the concatenation
of several column vectors is deﬁned in an analogous way. A
column vector with all ones is denoted by e = (1, 1, . . . , 1) ∈
Rn, its dimensions is clear from the context. The closure of
a set C is denoted by C, its boundary as ∂C. Given a matrix
M ∈ Rn×m, its i-th row is denoted by Mi,• and its j-th
column is denoted by M•,j.

Outline: Section II describes the reformulation of PSS
into DCS. Section III describes the discretization methods
in NOSNOC with a focus on FESD. In Section IV, solution
strategies for the discrete-time OCP are discussed. Section V
provides two tutorials for the use of NOSNOC and a numerical
benchmark. Section VI outlines some future developments.

II. PROBLEM REFORMULATION

System with state jumps do not ﬁt in the form of (1c).
However, we use the time-freezing reformulation [1], [6], [7]
to automatically reformulate them into the from of (1c). An
example is given in Section V-C.

In this section, we detail how to compactly represent the
systems (1c) and a how to transform them into a Dynamic
Complementarity System (DCS) via Stewart’s approach [15].
Ri is a set

Ri = Rn and that Rn \

It is assumed that

i∈I
S

of measure zero. Moreover, we assume that Ri are deﬁned via
the zero level sets of the components of the smooth function
c : Rnx → Rnc. We use a sign matrix S ∈ Rnf ×nc with non
repeating rows for a compact representations as follows:

i∈I
S

For example, for the sets R1 = {x ∈ R | x > 0} and R2 =

{x ∈ R | x < 0}, we have c(x) = x and S =

1 −1

⊤

.

The dynamics are not deﬁned on ∂Ri and to have a
meaningful notion of solution for the PSS (1c) we use the
Filippov convexiﬁcation and deﬁne the following differential
inclusion [16]:

(cid:2)

(cid:3)

˙x ∈ FF(x, u) =

F (x)θ |

θi = 1, θi ≥ 0, θi = 0

n
if x /∈ Ri, ∀i ∈ I

i∈I
X

,

(3)

o

and F (x)

where θ = (θ1, . . . , θnf ) ∈ Rnf
:=
[f1(x), . . . , fnf (x)] ∈ Rnx×nf . Note that in the interior of a
set Ri we have FF(x) = {fi(x)} and on the boundary between
some regions the resulting vector ﬁeld is a convex combination
of the neighboring vector ﬁelds. To have a computationally
useful representation of the Filippov system (3), we transform
it into a DCS via Stewart’s reformulation [15]. In this refor-
mulation, it is assumed that the sets Ri are represented via the
discriminant functions gi(·):

Ri = {x ∈ Rnx | gi(x) < min
j∈I, j6=i

gj(x)}.

(4)

Given the more intuitive representation via the sign matrix S
in Eq. (2), it can be shown that the function g : Rnx → Rnf
whose components are gi(x) can be found as [2]:

g(x) = −Sc(x).

(5)

With this representation, the convex multipliers in the r.h.s. of
(3) can be found as a solution of a suitable Linear Program
(LP) [15], and (3) is equivalent to

˙x = F (x, u)θ(x),

θ(x) ∈ arg min
˜θ∈Rnf

g(x)⊤ ˜θ

s.t.

e⊤ ˜θ = 1, ˜θ ≥ 0.

(6a)

(6b)

We use a C-function Φ(·, ·) for the complementarity conditions
and write the KKT conditions of the LP (6b) as a nonsmooth
equation



= 0,

GLP(x, θ, λ, µ) :=

g(x) − λ − µe
1 − e⊤θ
Φ(θ, λ)
where λ ∈ Rnf
≥0 and µ ∈ R are the Lagrange multipliers
associated with the constraints of the LP (6b). Note that µ =
minj∈I gj(x). Finally, the Filippov system is equivalent to
the following DCS, which can be interpreted as a nonsmooth
differential algebraic equation:

(7)







˙x = F (x, u)θ,

0 = GLP(x, θ, λ, µ).

(8)

A fundamental property of the multipliers λ(·) and µ(·) is their
continuity in time [2, Lemma 5], whereas θ(·) is in general a
discontinuous function in time.

III. THE STANDARD AND FESD DISCRETIZATIONS FOR A
SINGLE CONTROL INTERVAL

1
1
...

. . .
. . .

S = 

1
1
...
. . .
−1 −1 . . . −1 −1
Ri = {x ∈ Rnx | diag(Si,•)c(x) > 0}.

1
1
1 −1
...











,

(2a)

(2b)

This section describes the discretization of a single control
interval in NOSNOC via standard RK methods and FESD.
We start with a standard RK method for the DCS (8). We
subsequently introduce step-by-step the additional constraints
which lead to FESD.

A. Standard Runge-Kutta Discretization

We consider a single control interval [0, T ] with a given
constant control input q and a given initial value x0 = s0.
We divide the control interval into NFE ﬁnite elements (i.e.,
integration intervals) [tn, tn+1] via the grid points 0 = t0 <
t1 < . . . < tNFE = T . On each of these intervals, we apply an
ns-stage RK scheme, which is deﬁned by its Butcher tableau
entries ai,j, bi, ci, i, j ∈ {1, . . . , ns} [17]. We denote the
step-size as hn = tn+1 − tn, n = 0, . . . , NFE − 1. The
approximation of the state at the grid points tn is denoted
by xn ≈ x(tn). The time derivative of the state at the stage
points tn + cihn, i = 1, . . . , ns, for a single ﬁnite element
are collected in the vector Vn := (vn,1, . . . , vn,ns) ∈ Rns·nx.
The stage values for the algebraic variable θ(·) are collected in
Θn := (θn,1, . . . , θn,ns) ∈ Rns·nf . The vectors Λn ∈ Rns·nf
and Mn ∈ Rns are deﬁned accordingly. Let xnext
denote the
value at the next time step tn+1, which is obtained after a
single RK step.

n

Now we can write the RK equations for the DCS (8) in
a compact differential form. We summarize all RK equations
of a ﬁnite element in Grk(xnext
, Zn, hn, q) = 0, where Zn =
(xn, Θn, Λn, Mn, Vn) collects all internal variables, and deﬁne

n

Grk(xnext

, Zn, hn, q) :=
n
vn,1 −F (xn + hn



ns
j=1 a1,jvn,j, q)θn,1

...
P
ns
j=1 ans,jvn,j, q)θn,ns



.

P

P
...













GLP(xn + hn

GLP(xn + hn

xnext
n − xn − hn

vn,ns −F (xn + hn
ns
j=1 a1,jvn,j, θn,1, λn,1, µn,1)

P
ns
j=1 ans,jvn,j, θn,ns, λn,ns , µn,ns)
ns
i=1 bivn,i












To summarize all conditions for a single control
interval
in a compact way, we introduce some new notation. The
variables for all ﬁnite elements of a single control interval are
collected in the following vectors x = (x0, xnext
, . . . , xNFE) ∈
R(2NFE+1)nx, V = (V0, . . . , VNFE−1) ∈ RNFEnsnx and h :=
(h0, . . . , hNFE−1) ∈ RNFE. The vectors Θ ∈ RNFEnsnf ,
Λ ∈ RNFEnsnf and M ∈ RNFEns are deﬁned analogously. The
vector Z = (x, Θ, Λ, M, V) collects all internal variables.

P

0

Finally, we can summarize all computations over a single
control interval and interpret it as a discrete-time nonsmooth
system:

s1 = Fstd(Z), 0 = Gstd(Z, h, s0, q)

(9)

with Fstd(Z) = xNFE and



Gstd(Z, h, s0, q) :=

Grk(xnext

, Z0, h0, q)

x0 − s0

0
x1 − xnext
...

0

Grk(xnext

NFE−1, ZNFE−1, hNFE−1, q)

xNFE − xnext

NFE−1

.





















Note that we keep a dependency on hn in (9), but hn is
implicitly given by the chosen discretization grid. This also
means that for a standard RK scheme for DCS, higher order
accuracy can be achieved only if the grid points tn coincide

with all switching points, which is in practice impossible to
achieve.

B. Cross-Complementarity

In FESD, the step-sizes hn are left as degrees of freedom
such that the grid points tn can coincide with the switching
times. Consequently, the switches should not happen on the
stages inside a ﬁnite element. To exploit the additional degrees
of freedom and to achieve these two effects we introduce
additional conditions to the RK equations (9) called cross
complementaries. A key assumption, of course, is that there
are more grid points in the interior of the grid than switching
points.

For ease of exposition, we focus on the case where the
right-boundary point of a ﬁnite element is also an RK-stage
point, i.e., cns = 1 and tn+1 = tn + cnshn. Extensions
can be found in [2]. To achieve implicit and exact switch
detection at the boundaries of [tn, tn+1] and to avoid switching
that λ(·) and µ(·)
inside an element we exploit
are continuous functions. We need their values at tn and
tn+1 which are denoted by λn,0, µn,0 and λn,ns , µn,ns,
respectively. Due to continuity, we impose that λn,ns = λn+1,0
and µn,ns = µn+1,0 and use only the right boundary points
of the ﬁnite elements (λn,ns and µn,ns) in the sequel. To
achieve the effects described above, we introduce the cross
complementarity conditions which read as [2]:

the fact

0 = Gcross(Θ, Λ):=

ns
i=1

P
ns
i=1

P
ns
j=0,
j6=i

1,iλ1,j

ns
j=1,j6=i θ⊤
...
θ⊤
NFE−1,iλNFE−1,j



.

(10)









P

P
This additional constraint ensures two very important proper-
ties: (i) we have the same active-set in (9) in Φ(θn,m, λn,m) for
all m and changes can happen only for different n, i.e., at grid
points tn, (ii) whenever the active-sets for two neighboring
ﬁnite elements differ in the i-th and j-th components of
Φ(θn,m, λn,m), then these two components of λn,ns must be
zero [2]. This will implicitly result in the constraint 0 =
gi(xn+1) − gj(xn+1) (which comes from (7) and the fact that
µn,ns = minj gj(xn+1)). This deﬁnes the boundary between
regions and Ri and Rj, cf. (4). Thus, it implicitly forces hn
to adapt for exact switch detection.

C. Step-Equilibration

If no switches occur then also no active-set changes happen,
hence the constraints (10) are trivially satisﬁed. Consequently,
the step-size hn can vary in a possibly undesired way and
the optimizer can play with the discretization accuracy. To
remove the spurious degrees of freedom we introduce an
the inner grid points
indicator function η(·) evaluated at
tn, n = 1, . . . , NFE − 1 and its value at tn is denoted by
ηn. It has the following property: if a switch happens at tn
its value is zero, otherwise it is strictly positive. We omit the
details on how a function η(·) is derived and refer to [2]. The
discrete-time function η(·) depends on the values of Θn and
Λn of neighboring ﬁnite elements and we deﬁne

ηn(Θ, Λ) := η(Θn−1, Λn−1, Θn, Λn).

Thus, the constraint 0 = Geq(h, Θ, Λ) removes the possible
spurious degrees of freedom in hn, where:

(h0, . . . , hNstg−1) all step-sizes. Finally the discretized OCP
reads as:

Geq(h, Θ, Λ):=




(h1 − h0)η1(Θ,Λ)
...
(hNFE−1 − hNFE−2)ηNFE−1(Θ,Λ)

.


(11)




We call the condition (11) step-equilibration. A consequence
of (11) are locally equidistant state discretization grids be-
tween switching point, within a single control interval. Since
this constraint can be quite nonlinear, NOSNOC offers several
reformulations and heuristics that help numerical convergence.

D. Finite Elements with Switch Detection

We now use the ingredients explained above to state the
FESD method. Similar to the standard RK scheme (9), we
summarize all computations over a single control interval
and interpret it as a discrete-time nonsmooth system where
internally exact switch detection is happening. The next step
is computed by

s1 = Ffesd(Z), 0 = Gfesd(Z, h, s0, q, T ),

(12)

and Ffesd(Z) = xNFE renders the state transition map and
the equation 0 = Gfesd(x, Z, q) collects all other internal
computations including all RK steps within the regarded
control interval:

Gstd(Z, h, s0, q)
Gcross(Θ, Λ)
Geq(h, Θ, Λ)
NFE−1
hn − T
n=0



.

Gfesd(Z, h, s0, q, T ) :=

P








The last condition ensures that the length of the considered
time-interval is unaltered. In contrast to (9), hn are now
degrees of freedom, s0, q and T are given parameters. The
formulation (12) can be used as an integrator with exact
switch detection for PSS (1c). This feature is implemented
in NOSNOC via the function integrator fesd(). It can
automatically handle all kinds of switching cases such as:
crossing a discontinuity, sliding mode, leaving a sliding mode
or spontaneous switches [16].

min
s,q,Z,H

s.t.

Nstg−1

ˆfq(sk, xk, qk) + ˆfT(sNstg )

k=0
X
s0 = ¯x0,
sk+1 = Ffesd(xk), k = 0, . . . , Nstg −1,
0 = Gfesd(xk, Zk, qk), k = 0, . . . , Nstg−1,
0 ≥ Gineq(sk, qk), k = 0, . . . , Nstg − 1,
0 ≥ GT(sNstg ),

(13a)

(13b)
(13c)

(13d)
(13e)

(13f)

where ˆfq : Rnx × R(NFE+1)nsnx × Rnu → R and ˆfT : Rnx →
R are the discrteized stage and terminal costs, respectively.

B. Reformulating and Solving MPCC

The discrete-time OCP (13) is an MPCC. It can be written

more compactly as

f (w)

min
w
s.t.

0 ≤ h(w),
0 ≤ w1 ⊥ w2 ≥ 0,

(14a)

(14b)

(14c)
where w = (w0, w1, w2) ∈ Rnw is a given decomposition
of the problem variables. MPCC are difﬁcult nonsmooth NLP
which violate e.g., the MFCQ at all feasible points [12]. Fortu-
nately, they can often be solved efﬁciently via reformulations
and homotopy approaches [11], [12]. We brieﬂy discuss the
different ways of solving MPCC that are implemented in
NOSNOC. They differ in how Eq. (14c) is handled. In all
cases, w1, w2 ≥ 0 is kept unaltered and the bilinear constraint
w⊤

1 w2 = 0 is treated differently.
In a homotopy procedure, we solve a sequence of more
regular, relaxed NLP related to (14) and parameterized by a
homotopy parameter σi ∈ R≥0. Every new NLP is initialized
with the solution of the previous one. In all approaches the
homotopy parameter is updated via the rule: σi+1 = κσi, κ ∈
(0, 1), σ0 > 0, where i is the index of the NLP in the
homotopy. In the limit as σi → 0 (or often even for a ﬁnite i
and σi) the solution of the relaxed NLP matches a solution of
(14). NOSNOC supports the following approaches:

IV. DISCRETIZING AND SOLVING A NONSMOOTH
OPTIMAL CONTROL PROBLEM

This section outlines how a nonsmooth OCP is discretized

in NOSNOC and how the resulting MPCC is solved.

A. Multiple Shooting-Type Discretization with FESD

One of the main goals of NOSNOC is to numerically solve
a discretized version of the OCP (1). We consider Nstg ≥ 1
control intervals of equal length, indexed by k, with piece-
wise constant controls collected in q = (q0, . . . , qNstg−1) ∈
RNstgnu. All internal variables are additionally equipped with
an index k. On every control interval k, we apply an FESD
discretization (12) with NFE internal ﬁnite elements. The
state values at the control interval boundaries are collected
in s = (s0, . . . , sNstg ) ∈ R(Nstg+1)nx . The vector Z =
(Z0, . . . , ZNstg−1) collects all internal variables and H =

w⊤

Smoothing and Relaxation: In smoothing the bilinear term
is replaced by the simpler constraint w⊤
1 w2 = σi and in
relaxation by w⊤
1 w2 ≤ σi. Under certain assumptions for
σi → 0 a solution of the initial MPCC (14) is obtained [11].
ℓ1-Penalty: In this approach, the bilinear constraint is
discarded and the term 1
1 w2 is added to the objective,
σi
which is a penalized ℓ1 norm of the complementarity residual.
When the penalty 1
exceeds a certain (often ﬁnite) threshold
σi
we have w⊤
1 w2 = 0 and the solution of such an NLP is a
solution to (14) [12].
Elastic Mode:

In elastic mode (sometimes called ℓ∞-
approach) [12], a bounded scalar slack variable γ ∈ [0, ¯γ] is
introduced. The relaxed bilinear constraint reads as w⊤
1 w2 ≤ γ
and we add to the objective 1
1 w2 = γ and
σi
1 w2 ≤ γ are supported as well. Once the penalty 1
−γ ≤ w⊤
σi
exceeds a certain (often ﬁnite) threshold, we have γ = 0 and
we recover a solution of (14) [12].

γ. Variants with w⊤

V. NOSNOC TUTORIALS AND A BENCHMARK

In this section, we provide two short tutorials on the use
of NOSNOC. A numerical benchmark where we compare our
software to conventional approaches is presented as well.

A. Solving a Time-Optimal Control Problem

We regard a time-optimal control problem of a double-
integrator car model with a normal and turbo mode. The state
vector x = (q, v) ∈ R2 consists of the car’s position q and
velocity v. The PSS reads as

˙x =

(v, u),
(v, 3u),

(

if v < ¯v
if v > ¯v

.

(15)

Following Section II, we have f1(x, u) = (q, u) (nominal),
f2(x, u) = (q, 3u) (turbo). The two regions R1 and R2
described by c(x) = v − ¯v and S =
. The car
should reach the state xgoal = (200, 0) in optimal time T .
Additionally, we have constraints on the velocity |v| ≤ vmax
and control |u| ≤ umax. The parameters are vmax = 25,
umax = 5 and ¯v = 10. This OCP is formulated and solved
with NOSNOC using the code:

−1 1

⊤

(cid:2)

(cid:3)

1 [settings] = default_settings_nosnoc();
2 settings.time_optimal_problem = 1;
3 settings.n_s = 2;
4 model.N_stg = 10; model.N_FE = 3; model.T = 1;
5 q = MX.sym(’q’); v = MX.sym(’v’);
6 model.x = [q;v]; model.x0 = [0;0];
7 model.lbx = [-inf;-25]; model.ubx = [inf;25];
8 u = SX.sym(’u’); model.u = u;
9 model.lbu = -5; model.ubu = 5;
10 f_1 = [v;u]; f_2 = [v;3*u];
11 model.F = [f_1 f_2];
12 model.c = v-10; model.S = [-1;1];
13 model.g_terminal = [q-200;v-0];
14 [results,stats,model,settings] = nosnoc_solver(

model,settings);

The function default settings nosnoc() returns a
MATLAB struct with default values for all possible tuning
parameters. The needed time-transformations are automated by
the ﬂag settings.time optimal problem = 1. For
the FESD-RK method we keep the default choice of a Radau
II-A, hence we have with ns = 2 an accuracy order of
3 [17]. The MATLAB struct named model stores user
input data, given in lines 4 to 13, which deﬁnes the OCP (1).
NOSNOC automates all deﬁnitions, reformulations and updates
the model with all CasADi expressions for the DCS (8).
Moreover, possible inconsistencies in the provided settings
are reﬁned. Finally, in line 14 we solve the discretized OCP
with a homotopy as described in Section IV-B. The solution
trajectory is given in Fig. 1. The user has access to all tuning
parameters, intermediate results for all homotopy iterations
and to all CasADi symbolic expressions and Function
objects. This facilitates rapid prototyping and detailed analysis
of solutions.

Fig. 1. The position of the car q(t) is shown in the left plot, the velocity
v(t) in the middle plot. Note the increase in acceleration in the turbo
mode for v > ¯v. The right plots shows the optimal control u(t).

Fig. 2. Comparison of NOSNOC to mixed integer formulations. The left
plot show CPU time as function of number of control intervals Nstg. The
right plot show the solution accuracy as function of CPU time in a Pareto
plot.

latter approach is closely related to the smoothing approach in
[8] and [9]. For the MPCC, we use in both cases the relaxation
approach as it is usually the most robust one. Additionally,
we make a big M reformulation of the PSS (15) and solve
a mixed integer nonlinear program (MINLP). Switches are
allowed only at the control interval boundaries, hence we have
two binary variables per control interval. We solve the MINLP
with the dedicated solver Bonmin [18]. Moreover, since the
only non-linearity is in time T , we ﬁx it and make a bisection-
type search in T . For every ﬁxed T we solve a MILP with
Gurobi. The MILP with the smallest T that is still feasible
delivers the optimal solution. We vary Nstg from 10 to 80 with
steps of 5. The computations are aborted if the time-limit of
10 minutes is exceeded.

The results of the benchmark are depicted in Fig. 2.
NOSNOC-FESD is slightly slower than NOSNOC-Std, since it
has NstgNFE more variables, as hn are degrees of freedom.
We compare also the solution quality by making a high-
accuracy simulation xsim(t) of (15) with the obtained optimal
controls q. We compare the terminal constraint satisfaction
E(T ) = kxsim(T ) − xgoalk. Due to the exact switch detection
property, NOSNOC-FESD has by far the most accurate solu-
tions. The outlier where NOSNOC-Std achieves high accuracy
corresponds to a local minima without switches. We see that
to solve with
even a simple nonsmooth OCP is difﬁcult
conventional approaches, whereas NOSNOC-FESD provides
faster and several orders of magnitude more accurate solu-
tions. Further detailed comparisons of FESD to the standard
approach can be found in [2].

B. Numerical Benchmark

C. An Example with State Jumps and Time-Freezing

We solve the OCP from the last section with four different
approaches. We use NOSNOC with the FESD discretization
(12) and NOSNOC with the standard discretization (9). The

In this subsection we illustrate how to use NOSNOC with
systems with state jumps. We consider a planar bouncing ball
with elastic impacts. The state vector is deﬁned as x = (q, v) ∈

R4 with q = (q1, q2) ∈ R2 and v = (v1, v2) ∈ R2 being the
ball’s position and velocity, respectively. The initial state is
x(0) = (0, 0.5, 0, 0) and the ball is controlled with some force
u ∈ R2. The ODE with state jumps reads as:

˙q = v,

˙v = u − (0, g),

v2(t+) = −ev2(t−), if q2(t) = 0 and v2(t) < 0.

(16a)

(16b)

where e ∈ (0, 1] is the coefﬁcient of restitution and determines
the post impact velocity. The goal is to reach qf = (4, 0.5) with
a minimal quadratic control effort modeled with the stage cost
fq(x, u) = u⊤u and a minimal terminal velocity expressed
via fT(x) = 100v⊤v, with T = 4. The control force is
bounded such that it is weaker than the gravitational force, i.e.,
u⊤u ≤ u2
max. The chosen parameters are e = 0.9, g = 9.81,
umax = 9. The following NOSNOC code solves the described
nonsmooth OCP with state jump:

1 [settings] = default_settings_fesd();
2 settings.time_freezing = 1; settings.n_s = 3;
3 model.T = 4; model.N_stg = 20; model.N_FE = 3;
4 q = MX.sym(’q’,2); v = MX.sym(’v’,2);
5 model.x = [q;v]; model.x0 = [0;0.5;0;0];
6 u = MX.sym(’u’,2); model.u = u;
7 model.c = q(2);
8 model.f = [v;u-[0;9.81]];
9 model.f_q = u’*u; model.f_q_T = 100*v’*v;
10 model.g_ineq = u’*u-9ˆ2;
11 model.g_terminal = q-[4;0.5];
12 [results,stats,model,settings] = nosnoc_solver(

model.e = 0.9;

model,settings);

The ﬂag settings.time freezing = 1 ensures that
system with state jumps (16) is transformed into a PSS of
the form of (1c) via the time-freezing reformulation [1]. A
solution trajectory is given in Figure 3, note the state jumps
in v2(t) in the middle plot.

Many more settings can be changed by the user, for exam-
ple, one can choose between different MPCC reformulations
via mpcc mode, control the sparsity of the cross comple-
mentarities cross complementarity mode and so on. A
few more examples and a detailed user manual are available
NOSNOC’s repository [5].

VI. CONCLUSION AND OUTLOOK

In this letter we presented NOSNOC, an open-source soft-
ware package for nonsmooth numerical optimal control. With
the help of the Finite Elements with Switch Detection (FESD)
method and the time-freezing reformulation, it enables prac-
tical and high accuracy optimal control of several different
classes of nonsmooth system in a uniﬁed way. The discretized
OCP are solved with techniques solely from continuous op-
timization, without the need for any integer variables. All
reformulations and details are hidden but accessible such that
a convenient use for users with different knowledge levels of
the ﬁeld is ensured.

In future work, we aim to implement a python version
of NOSNOC. Moreover, further algorithmic developments in
FESD, e.g., different reformulations of PSS into DCS, support
for time-freezing for other classes of hybrid systems will be
implemented.

Fig. 3. The illustration of the optimal solution q(t) is shown in the left
plot. The middle plot shows the optimal velocities v(t) as a function of
the physical time t, where the state jumps are recovered. The right plot
shows the optimal controls u(t).

REFERENCES

[1] A. Nurkanovi´c, T. Sartor, S. Albrecht, and M. Diehl, “A Time-Freezing
Approach for Numerical Optimal Control of Nonsmooth Differential
Equations with State Jumps,” IEEE Control Systems Letters, vol. 5, no. 2,
pp. 439–444, 2021.

[2] A. Nurkanovi´c, M. Sperl, S. Albrecht, and M. Diehl, “Finite Elements
with Switch Detection for Direct Optimal Control of Nonsmooth
Systems,” 2022. [Online]. Available: https://arxiv.org/abs/2205.05337
[3] B. Brogliato and A. Tanwani, “Dynamical systems coupled with mono-
tone set-valued operators: Formalisms, applications, well-posedness, and
stability,” SIAM Review, vol. 62, no. 1, pp. 3–129, 2020.

[4] A. Bemporad and M. Morari, “Control of systems integrating logic,
dynamics, and constraints,” Automatica, vol. 35, no. 3, pp. 407–427,
1999.

[5] “NOSNOC,” https://github.com/nurkanovic/nosnoc, 2022.
[6] A. Nurkanovi´c, S. Albrecht, B. Brogliato, and M. Diehl, “The Time-
Freezing Reformulation for Numerical Optimal Control of Complemen-
tarity Lagrangian Systems with State Jumps,” arXiv preprint, 2021.
[7] A. Nurkanovi´c and M. Diehl, “Continuous optimization for control of
hybrid systems with hysteresis via time-freezing,” Submitted to The
IEEE Control Systems Letters (L-CSS), 2022.

[8] D. E. Stewart and M. Anitescu, “Optimal control of systems with
discontinuous differential equations,” Numerische Mathematik, vol. 114,
no. 4, pp. 653–695, 2010.

[9] A. Nurkanovi´c, S. Albrecht, and M. Diehl, “Limits of MPCC Formula-
tions in Direct Optimal Control with Nonsmooth Differential Equations,”
in 2020 European Control Conference (ECC), 2020, pp. 2015–2020.

[10] B. T. Baumrucker and L. T. Biegler, “MPEC strategies for optimization
of a class of hybrid dynamic systems,” Journal of Process Control,
vol. 19, no. 8, pp. 1248–1256, 2009.

[11] S. Scholtes, “Convergence properties of a regularization scheme for
mathematical programs with complementarity constraints,” SIAM Jour-
nal on Optimization, vol. 11, no. 4, pp. 918–936, 2001.

[12] M. Anitescu, P. Tseng, and S. J. Wright, “Elastic-mode algorithms for
mathematical programs with equilibrium constraints: global convergence
and stationarity properties,” Mathematical Programming, vol. 110, no. 2,
pp. 337–371, 2007.

[13] J. A. E. Andersson, J. Gillis, G. Horn, J. B. Rawlings, and M. Diehl,
“CasADi – a software framework for nonlinear optimization and optimal
control,” Mathematical Programming Computation, vol. 11, no. 1, pp.
1–36, 2019.

[14] A. W¨achter and L. T. Biegler, “On the implementation of an interior-
point ﬁlter line-search algorithm for large-scale nonlinear programming,”
Mathematical Programming, vol. 106, no. 1, pp. 25–57, 2006.

[15] D. E. Stewart, “A high accuracy method for solving ODEs with
discontinuous right-hand side,” Numerische Mathematik, vol. 58, no. 1,
pp. 299–328, 1990.

[16] A. F. Filippov, Differential Equations with Discontinuous Righthand
Springer Science & Business Media, Series: Mathematics and

Sides.
its Applications (MASS), 2013, vol. 18.

[17] E. Hairer and G. Wanner, Solving Ordinary Differential Equations II –
Stiff and Differential-Algebraic Problems, 2nd ed. Berlin Heidelberg:
Springer, 1991.

[18] P. Bonami, L. Biegler, A. Conn, G. Cornu´ejols, I. Grossmann, C. Laird,
J. Lee, A. Lodi, F. Margot, N. Sawaya, and A. W¨achter, “An Algorithmic
Framework For Convex Mixed Integer Nonlinear Programs,” IBM T. J.
Watson Research Center, Tech. Rep., 2005.

