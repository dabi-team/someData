DFI: An Interprocedural Value-Flow Analysis
Framework that Scales to Large Codebases

Min-Yih Hsu
University of California, Irvine
United States
minyihh@uci.edu

Felicitas Hetzelt
University of California, Irvine
United States
fhetzelt@uci.edu

Michael Franz
University of California, Irvine
United States
franz@uci.edu

Abstract
Context- and flow-sensitive value-flow information is an im-
portant building block for many static analysis tools. Unfor-
tunately, current approaches to compute value-flows do not
scale to large codebases, due to high memory and runtime re-
quirements. This paper proposes a new scalable approach to
compute value-flows via graph reachability. To this end, we
develop a new graph structure as an extension of LLVM IR
that contains two additional operations which significantly
simplify the modeling of pointer aliasing. Further, by pro-
cessing nodes in the opposite direction of SSA def-use chains,
we are able to minimize the tree width of the resulting graph.
This allows us to employ efficient tree traversal algorithms
in order to resolve graph reachability.

We present a value-flow analysis framework, DFI, imple-
menting our approach. We compare DFI against two state-
of-the-art value-flow analysis frameworks, Phasar and SVF,
to extract value-flows from 4 real-world software projects.
Given 32GB of memory, Phasar and SVF are unable to com-
plete analysis of larger projects such as OpenSSL or FFmpeg,
while DFI is able to complete all evaluations. For the subset
of benchmarks that Phasar and SVF do handle, DFI requires
significantly less memory (1.5% of Phasar’s, 6.4% of SVF’s
memory footprint on average) and runs significantly faster
(23x speedup over Phasar, 57x compared to SVF). Our anal-
ysis shows that, in contrast to previous approaches, DFI’s
memory and runtime requirements scale almost linearly with
the number of analyzed instructions.

Keywords: dataflow analysis, value-flow analysis, program
analysis, scalability, graph theory

2
2
0
2

p
e
S
6

]
L
P
.
s
c
[

1
v
8
3
6
2
0
.
9
0
2
2
:
v
i
X
r
a

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for profit or commercial advantage and that copies bear
this notice and the full citation on the first page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior specific permission and/or a fee. Request
permissions from permissions@acm.org.
CGO ’23, Feb.25–Mar.03, 2023, Montreal, QC, Canada
© 2023 Association for Computing Machinery.
ACM ISBN 978-1-4503-XXXX-X/xx/xx. . . $15.00
https://doi.org/XXXXXXX.XXXXXXX

1

1 Introduction

Value-flow analysis is a subset of dataflow analysis that
helps to statically reason about the dependencies among
program constructs such as variables and memory blocks. It
underpins many crucial program analysis techniques that
are widely used in compiler optimizations and for finding
security vulnerabilities: points-to analysis [37], null pointer
analysis [20, 35], and taint analysis [10], to name a few. In
order to operate effectively, such techniques usually require
precise value-flow information that is context- and flow-
sensitive as well as interprocedural [34].

Seminal work by Reps et al. [27] demonstrated that inter-
procedural context- and flow-sensitive value-flow analysis
can be expressed as reachability between nodes within a pro-
gram graph. Their algorithmic framework IFDS operates on
a graph structure in which each node maps to a value-flow
statement within the target program. But, while solved in
theory, in practice the adoption of static value-flow frame-
works is still limited by severe scalability issues. In fact, as
we will show in Section 4, currently there exists no static
analysis framework that is able to determine precise value-
flows for larger real world codebases such as OpenSSL and
FFmpeg on single commodity PCs.

The memory and runtime requirements of static value-
flow analysis frameworks such as IFDS are largely governed
by the graph representation of the program and the perfor-
mance of the graph reachability algorithm. Indeed, previous
approaches to solving the scalability problem have often fo-
cused on working around the shortcomings of established
graph-reachability algorithms [1, 13, 19]. In contrast, in this
paper, we present a solution that is based on a novel sparse
graph representation, leading to a reachability algorithm
that is highly efficient in answering value-flow queries.

Our key insight is that program graphs representing value-
flow can be constructed to have a low tree width [28], which
is a measure of how similar a graph is to a tree. We found that
performing a depth-first traversal in the opposite direction of
SSA def-use chains will result in a graph with a significantly
reduced number of non-tree edges. Based on this insight, we
develop a novel graph reachability algorithm based on tree
traversal which significantly reduces processing time and
memory requirements compared to previous approaches. In
fact, our new algorithm allows us to determine dependencies
between two arbitrary instructions in constant time for most

 
 
 
 
 
 
CGO ’23, Feb.25–Mar.03, 2023, Montreal, QC, Canada

Min-Yih Hsu, Felicitas Hetzelt, and Michael Franz

queries. Additionally, the resulting graph representation is
sparse, thereby further reducing processing time and mem-
ory requirements by incorporating only program statements
relevant for value-flow propagation.

We implemented these ideas in a framework that we call
DFI1. To quantify the improved performance of our approach,
we evaluate DFI against two state-of-the art static value-flow
analysis frameworks: Phasar [29] and SVF [31]. Phasar is a
popular framework implementing the IFDS algorithm, while
SVF presents a different approach to compute precise static
value-flow information based on def-use chains that are con-
structed based on pre-computed points-to information. As
our evaluation shows, DFI is able to scale to significantly
larger codebases on commodity hardware than previous so-
lutions, using significantly less memory overall, and run-
ning significantly faster. Therefore, DFI constitutes the first
static solution to resolve interprocedural context- and flow-
sensitive value-flow for real-world software projects, reach-
ing to over a million lines of code, under realistic resource
limitations. In summary our contributions are the following:
• an extension of LLVM IR containing two new opera-
tions that significantly simplify the modeling of value-
flows in the presence of pointer aliasing,

• a resulting lightweight and precise sparse representa-
tion of def-use chains for value-flow analysis incorpo-
rating top-level and address-taken variables,

• an algorithm to solve value-flows via graph reacha-
bility that scales almost linearly with the number of
processed vertices, requires significantly less memory
and is significantly faster than previous solutions, and
• a full source-language agnostic implementation of our
technique based on LLVM IR that scales to large real-
world projects containing hundreds of thousands of
lines of code.

We further pledge to make the source code of our project
freely available under an open-source license.
2 Background
In this Section, we explain terminologies and concepts that
will serve as the building blocks for rest of the paper.
2.1 Flow-Sensitive Value-Flow Analysis
Value-flow analysis models the specific propagation of data
through a program’s storage locations. A flow-sensitive anal-
ysis respects the program’s control flow and calculates re-
sults for each program point. In contrast, flow-insensitive
analysis ignores statement ordering and computes a single
solution that is sound for all program points. Traditionally, to
achieve flow-sensitivity, value-flow analysis is built on top of
a monotone dataflow analysis framework [15]. The analysis
follows control flows in the control-flow graph (CFG), while
accounting for changes in dataflow facts made by each state-
ment. For example, in a null pointer analysis, a dataflow fact

1The name DFI pays homage to IFDS, while our reversal of the letters alludes
to the fact that our technique processes nodes in the reverse order.

2

is a set of potentially-null variables at a given program point.
For each statement 𝑖, the transfer function calculates two sets:
𝐼 𝑁𝑖 and 𝑂𝑈𝑇𝑖 , which represent the sets of dataflow facts that
hold right before and right after statement 𝑖. In the context
of a null pointer analysis, the transfer function might add (or
subtract) variables that are (or not) potentially-null. 𝐼 𝑁𝑖 is
equal to 𝑂𝑈𝑇𝑖−1 passed down from previous statement in the
control flow, in the case of having multiple predecessor state-
ments, 𝐼 𝑁𝑖 is the set union of 𝑂𝑈𝑇𝑝, ∀𝑝 ∈ 𝑝𝑟𝑒𝑑𝑒𝑐𝑒𝑠𝑠𝑜𝑟𝑠 (𝑖).
The algorithm repeatedly performs such updates on every
statement until it reaches a global fixed point.

This approach usually comes with a high performance
overhead. Dataflow facts are propagated to every program
point, despite the fact that only a small portion of them is
needed to answer the dataflow query we are interested in. In
addition, maintaining two sets per statement tends to create
a large memory footprint as well.

SSA-Based Sparse Value-Flow Analysis In recent years,
sparse value-flow analysis [11, 12, 25, 31] has introduced a
promising solution to the aforementioned problem. Sparse
value-flow analysis avoids propagating dataflow facts through
program statements that are unrelated to the analysis. A
common way is to perform the analysis on Static-Single
Assignment (SSA) form [8] of programs.

In SSA, each variable is defined exactly once in a “static”
view of the program, i.e., disregarding “dynamic” reassign-
ments of variables that may happen at the same program
location inside of loops. If there are multiple static defini-
tions of a variable in the original program (such as multiple
separate program locations that perform assignments to the
variable), then each such assignment of the original pro-
gram variable becomes a separate SSA variable or value. SSA
form expresses value definitions and usage information, also
called def-use chains, explicitly, so that tracing values to
their immediate uses becomes much easier. Therefore, def-
use chains can help us to rule out irrelevant data flows and
greatly improve the efficiency of value-flow analyses [26].
Tracking every variable in SSA form is difficult as it has
to account for potential aliasing among pointer variables. To
tackle this problem, mainstream compilers such as GCC [23]
and LLVM [17] adopt a variant of SSA called partial SSA
which divides variables into two categories: top-level and
address-taken. Top-level variables cannot be referenced indi-
rectly via a pointer and can be trivially converted into SSA
form; address-taken variables are referenced indirectly via
top-level pointer variables and are not represented in SSA
form at all. This additional layer of indirection makes it more
difficult for us to track value-flows on address-taken vari-
ables in partial SSA. In Section 3.1, we will show our solution
to this problem.
2.2 Value-Flow Analysis as Graph Reachability
Reps et al. pioneered the idea of solving traditional dataflow
analyses by turning them into graph reachability problems

DFI: An Interprocedural Value-Flow Analysis Framework that Scales to Large Codebases

CGO ’23, Feb.25–Mar.03, 2023, Montreal, QC, Canada

edge and back edge. They are defined using the interval rela-
tionship: for vertices 𝑘 and 𝑙, alone with their corresponding
intervals ⟨𝑠𝑘, 𝑒𝑘 ⟩ and ⟨𝑠𝑙, 𝑒𝑙 ⟩, Edge 𝑘 → 𝑙 is
• a cross edge if 𝑒𝑙 < 𝑠𝑘 ∨ 𝑒𝑘 < 𝑠𝑙 , and
• a back edge if ⟨𝑠𝑙, 𝑒𝑙 ⟩ ⊇ ⟨𝑠𝑘, 𝑒𝑘 ⟩.

For example, in Figure 1, edge 𝐸 → 𝐶 is a cross edge, and
edge 𝐻 → 𝐷 is a back edge.

By comparing the intervals of arbitrary two vertices, using
the subsuming relation defined earlier, we can easily know
whether they can reach each other through (spanning) tree
edges in constant time. However, this property only holds
for tree edges. For reachability queries on generic graphs,
we also need to consider paths that go through non-tree
edges. To answer those queries, several previous works [14,
33, 36] have proposed a variety of ad-hoc solutions on top
of DFT intervals. In Section 3.3, we are going to introduce
an augmented DFT-interval graph reachability algorithm to
solve this problem.

3 DFI Design and Implementation
DFI is designed to be programming-language agnostic on its
input program and can process any program compiled into
LLVM IR. Section 3.1 will cover necessary preprocessing to
convert this initial LLVM IR into a form more favorable to
value-flow analysis. Sections 3.2 to 3.4 will cover the details
of our main algorithm and implementation.
3.1 Preprocessing
DFI relies heavily on the sparse SSA program representation
to track value-flows efficiently. However, as discussed in
Section 2.1, the partial SSA form used by LLVM IR excludes
address-taken variables. To track the value-flows of address-
taken variables we convert the original input program into
a custom representation that improves handling of indirect
memory operations and pointers.

We implement this custom program representation using
MLIR [18], a versatile framework to create custom intermedi-
ate representations (IRs) for program analyses and compiler
optimizations. A custom IR is called dialect in MLIR. It con-
sists of a type system and various building blocks that define
the semantics like operation, block, region, and attribute, to
name a few. A program statement or LLVM IR instruction is
usually modeled by a MLIR operation. We create our own
DFI dialect on top of existing LLVM IR constructions with
two custom operations: dfi.store and dfi.call.

dfi.store operation A dfi.store operation has exactly
the same run-time behavior as an LLVM store instruction.
However, unlike a normal store instruction that doesn’t
produce a result, dfi.store produces a pointer as the result.
The result pointer has the same aliasing characteristics as
the destination pointer operand, i.e., the memory address to
which the value is stored.

dfi.store essentially applies the same SSA renaming
used by LLVM on pointer variables and adds explicit def-use

Figure 1. A graph annotated with DFT intervals

in their IFDS framework [27], inspiring a whole body of
research on graph reachability based program analysis [4,
16, 21, 32]. In IFDS, dataflow analysis is performed on an ex-
ploded supergraph, in which each vertex represents a dataflow
fact at a specific program point. Each statement has a local
transfer function that describes the vertex (i.e. dataflow facts)
mapping before and after the statement. Multiple such edges
transitively compose to a single PathEdge. Thus, an intrapro-
cedural dataflow query can boil down to answering whether
the vertex of a dataflow source reaches the program points
we are interested in via a PathEdge, which implies flow-
sensitivity. Interprocedurally, the PathEdge are extended
from a call site to a callee and back to the same call site.
Context-sensitivity is achieved by matching call and return
edges.

2.3 Reachability via Depth-First Tree Intervals
A Depth-First Tree (DFT) is a common approach to compute
graph reachability. A DFT is an ordered spanning tree derived
from the process of Depth-First Search (DFS) [7]. Each vertex
of a DFT is assigned an integer interval ⟨𝑠𝑣, 𝑒𝑣⟩: 𝑠𝑣 is the
discovery timestamp when 𝑣 is first visited and 𝑒𝑣 is the finish
timestamp when all out-neighbors of 𝑣 have been visited. The
timestamp is initialized with zero and it is increased by one
upon visiting a new out-neighbor from a vertex. Formally
speaking, an interval has the following invariant:

𝑠𝑣, 𝑒𝑣 ∈ Z, 𝑠𝑣 ≥ 0 ∧ 𝑒𝑣 ≥ 0 ∧ 𝑒𝑣 > 𝑠𝑣
Figure 1 shows an example graph with its DFT intervals. To
simplify the problem without losing generality, we always
add a pseudo vertex 𝛿 to connect every vertex in the graph,
such that the spanning tree has a single root.

For a given vertex in the spanning tree, its interval al-
ways subsumes the intervals of all vertices in its subtree. An
interval ⟨𝑠𝑘, 𝑒𝑘 ⟩ is said to subsume another interval ⟨𝑠𝑙, 𝑒𝑙 ⟩,
denoted by ⟨𝑠𝑘, 𝑒𝑘 ⟩ ⊇ ⟨𝑠𝑙, 𝑒𝑙 ⟩, if they have the following prop-
erties:

𝑠𝑘 ≤ 𝑠𝑙 ∧ 𝑒𝑘 ≥ 𝑒𝑙 =⇒ ⟨𝑠𝑘, 𝑒𝑘 ⟩ ⊇ ⟨𝑠𝑙, 𝑒𝑙 ⟩
Vertex 𝐹 in Figure 1, for example, has an interval of ⟨10, 15⟩,
which subsumes the intervals of its children ⟨11, 12⟩ and
⟨13, 14⟩. Conversely, vertex 𝐸 and 𝐹 are siblings so none of
their intervals subsumes one or the other. We distinguish
between tree edges (solid lines) and non-tree edges (dashed
lines) in Figure 1. There are two types of non-tree edges: cross

3

DEFGHABC𝛿〈0,17〉Tree edgeNon-tree edge〈7,16〉〈10,15〉〈13,14〉〈11,12〉〈8,9〉〈4,5〉〈1,6〉〈2,3〉CGO ’23, Feb.25–Mar.03, 2023, Montreal, QC, Canada

Min-Yih Hsu, Felicitas Hetzelt, and Michael Franz

chains for strong updates to an address-taken variable. More
specifically, upon each strong memory store, we rename the
original pointer to the result pointer produced by dfi.store.
Listing 1 shows a simple MLIR snippet consisting of mem-
ory load and store operations on function argument %p. List-
ing 2, on the other hand, is the same snippet with llvm.store
replaced by dfi.store. Take llvm.load operation on line 3
of Listing 1 as an example: before the replacement, it was
loading content from %p. But on the same line of Listing 2, we
can see that it’s now loading content from the result pointer
%p0 of dfi.store from the previous line.

The presence of dfi.store operations dramatically sim-
plifies the value-flow propagations on address-taken vari-
ables. We can now track memory dependencies w.r.t. strong
updates in the same way as tracking scalar value-flows. It is
similar to the idea proposed by Chow et al. [6] and Memo-
rySSA [24]. In contrast to previous works, dfi.store adopts
a lightweight design and excludes weak updates on address-
taken variables (i.e. MayDef and MayUse), which are more
expensive to compute, from its representation. Nevertheless,
a client analysis is capable of accounting for those weak
memory dependencies with the flexible framework provided
by DFI.

1 llvm . func @f (% v: i32 , %p: ! llvm . ptr < i32 >) {
%p

: ! llvm . ptr < i32 >

llvm . store %v ,

2

% v0 = llvm . load

llvm . store %v0 ,

% v1 = llvm . load

%p

%p

%p

: ! llvm . ptr < i32 >

: ! llvm . ptr < i32 >

: ! llvm . ptr < i32 >

3

4

5

6 }

Listing 1. IR before conversion to dfi.store

1 llvm . func @f (% v: i32 , %p: ! llvm . ptr < i32 >) {

%p0

= dfi . store %v ,

%p

: ! llvm . ptr < i32 >

% v0 = llvm . load

%p0

: ! llvm . ptr < i32 >

%p1

= dfi . store %v0 ,

%p0

: ! llvm . ptr < i32 >

% v1 = llvm . load

%p1

: ! llvm . ptr < i32 >

2

3

4

5

6 }

Listing 2. IR after conversion to dfi.store

dfi.call operation To support interprocedural analysis,
it is essential to capture value-flows of the callee function
at a given call site. For callees that have no side effects (e.g.
pure functions), it suffices to propagate value-flows through
function arguments and the return value. However, we also
need to consider output arguments where results are carried
through pointer type function parameters. In order to capture
the value-flows propagated through output arguments, DFI
replaces normal function call operations, llvm.call, with
custom dfi.call operations.

Similar to dfi.store, for each pointer argument in the
original llvm.call, we add a pointer-type result in the result

4

Figure 2. Structure of the analysis engine in DFI

Figure 3. DFT intervals in a MLIR function3

list of dfi.call. Listing 8 and 7 in the Appendix A.2 show
the result of replacing llvm.call with dfi.call. 2
3.2 Analysis Engine
Figure 2 shows the overall structure and workflow in DFI
after the preprocessing. DFI consists of two primary compo-
nents: the main analysis engine and the client analysis.

First, as further detailed in Section 3.3, intraprocedural
DFT intervals are computed by the analysis engine based
on value-flow mapping information provided by the client
analysis. Next, as described in Section 3.4, the intraprocedu-
ral value-flows will be propagated to their callers in order to
support interprocedural queries. Finally, the client analysis
will receive flow- and context-sensitive value-flow results
to solve its domain-specific applications.
3.3 Intra-procedural Analysis
This Section discusses the algorithm of tracking intraproce-
dural value-flows. As mentioned in Section 2.2, value-flow
analysis can be boiled down to a graph reachability problem,
where each vertex is a dataflow fact on a certain program
point and value-flow queries are answered by determining
the reachability of two vertices.

Similar to IFDS, DFI also approaches the intraprocedural
part of this problem by employing a local transfer function
for each statement and a graph reachability solving tech-
nique. However, instead of the tabulation-based strategy
used by the original IFDS technique, DFI adopts a novel
graph reachability solving technique based on depth-first
spanning tree intervals introduced in Section 2.3. The idea is
that for a given value-flow analysis problem, if every relevant
operation in the program is annotated with DFT intervals,
we are able to determine the reachability between two ar-
bitrary operations by comparing their intervals in nearly
constant time.

2For better readability, we will omit the type notation of all dfi.call
occurrences in rest of the paper.

DEFI Analysis EngineIntra-Procedural ModuleInterprocedural ModuleAnalysis ResultsClient AnalysisLocal Transfer Functions & Reversed RootsValue-Flow ApplicationsTarget Program(in MLIR form)Provide toWorkflow directionllvm.func @foo(%a:i32, %p:!llvm.ptr<i32>)->i32{  %t = llvm.alloca 1 x i32  %0 = dfi.store %a, %t : !llvm.ptr<i32>  %1 = llvm.load %p : !llvm.ptr<i32>  %2 = dfi.store 3, %p : !llvm.ptr<i32>  %3 = llvm.add 2, %1 : i32  llvm.return %3 : i32}〈6, 9〉〈0, 5〉〈1, 4〉〈2, 3〉〈7, 8〉DFI: An Interprocedural Value-Flow Analysis Framework that Scales to Large Codebases

CGO ’23, Feb.25–Mar.03, 2023, Montreal, QC, Canada

%q = dfi.store %v, %p
%v

%p

%r = llvm.add %a, %b

%a

%b

%v = llvm.load %p
%p

%q

%r
Figure 4. Local taint analysis transfer functions on Figure 3

%v

To demonstrate this concept, Figure 3 shows a MLIR func-
tion in which the values are annotated with DFT intervals.
For instance, value %𝑝 and %1 have ⟨0, 5⟩ and ⟨1, 4⟩ for their
intervals, respectively. These intervals are annotated on the
spanning trees derived from the SSA def-use graph, con-
sisting of edges that go from a single SSA value definition to
its uses.

Assume a taint analysis is performed on Figure 3 and %𝑝 is
a tainted value. To determine if the return value %3 is tainted
it is sufficient to check if its interval ⟨2, 3⟩ is subsumed by
that of %𝑝 ⟨0, 5⟩. In this case, since ⟨0, 5⟩ ⊇ ⟨2, 3⟩ per our
definition in Section 2.3, the return value is tainted. In fact,
both %1 and %3 are tainted, as their intervals are both inside
the subtree of ⟨0, 5⟩. On the other hand, %0, whose interval
is ⟨7, 8⟩, is not tainted because it resides in a different DFT
subtree rooted at ⟨6, 9⟩.

To calculate the trees and associated intervals shown in
Figure 3 the client analysis customizes the traversal mecha-
nism introduced in Section 2.3. First, for each function, the
client analysis chooses a set of root vertices to start the tra-
versal. Note that the traversal timestamp in each function
always starts from zero. Second, for each vertex in the func-
tion, a local transfer function is provided by client analysis
to dictate the out-going vertices to visit next. In the context
of taint analysis on Figure 3, the client analysis picks %𝑎 and
%𝑝 as the traversal roots. For the local transfer function, the
rules for each kind of operation are shown in Figure 4. Take
the rule for dfi.store as an example, in which the result
pointer %𝑞 is tainted only if the stored value %𝑣 is tainted. It
effectively stops the DFT traversal to go from %𝑝 to %𝑞, but
allows the path from %𝑣 to %𝑞.

The DFT interval scheme described in the previous ex-
ample only details the computation of reachability based
on (spanning) tree edges. In the following Section we will
discuss a more general reachability problem w.r.t both tree
and non-tree edges.

Non-Tree Edges in SSA Def-Use Graph Non-tree edges
inhibit the application of the simple interval-based graph
reachability algorithm on generic SSA def-use graphs. To
generalize our solution over those graphs, we first discuss
program constructs that result in non-tree edges.

1 llvm . func @f (% a: i32 , %b: i32 , %c: i32 ) -> i32 {
2
3
4

%t = llvm . add %a , %c : i32
%r = llvm . mul 3, %t : i32
llvm . return %r : i32

3To simplify the code, we "inline" the constant operands in both llvm.add
operations. Normally, those constants will be defined by a dedicated opera-
tion, llvm.constant.

5

%a

%c

%a

%c

llvm.return %r

%r

%t = llvm.add %a, %c

%r = llvm.mul 3, %t

%t

%t

%r = llvm.mul 3, %t

%t = llvm.add %a, %c

%r

llvm.return %r

%a

%a

%c

%c

(a) SSA def-use graph

(b) Reversed SSA def-use graph

Figure 5. SSA def-use graphs for Listing 3

5 }

Listing 3. A MLIR function
Figure 5a shows the SSA def-use graph for Listing 3. In Fig-
ure 5a, each vertex is labeled with an operation or value
and edges are labeled with the value being used. Starting
the creation of DFT intervals from function argument %𝑎
will produce three edges: %𝑎, %𝑡, and %𝑟 . However, when we
proceed to visit rest of the vertices, the edge between %𝑐 and
𝑙𝑙𝑣𝑚.𝑎𝑑𝑑 becomes a non-tree edge, since the latter operation
has been visited before. We observe that, with this scheme, a
non-tree edge appears if there is more than one operand in
an operation. The additional operands create multiple parent
vertices for the operation resulting in non-tree edges. There-
fore, the number of non-tree edges is proportional to the
number of operands. Unfortunately, the majority of nodes
in standard LLVM IR have more than one operand.

Reversed DFT Traversal To effectively reduce the number
of non-tree edges in a SSA def-use graph, DFI adopts a novel
solution: traversing the graph in the reverse direction when
building DFT intervals. In Figure 5a the traversal direction
goes from a SSA definition to its uses. If we reverse this
direction and go from a SSA use to its value definition, as
demonstrated in Figure 5b, the number of non-tree edges no
longer depends on the fixed number of operands. Instead, for
a given value, the number of non-tree edges is proportional
to the number of its SSA uses.

This led us to an important new realization: in most of the
real-world codebases, the majority of the SSA values have
a single or even no SSA use. Table 4 in the Appendix shows
the percentage of SSA values against different number of
SSA uses in 6 real-world codebases. The statistics show that
80% to 90% of the SSA values have a single or no use in all
benchmarks. In other words, if we traverse the SSA def-use
graphs in the opposite direction, the resulting number of
non-tree edges is far smaller than the number of tree edges.
Reversed DFT Root Reversed DFT traversal starts from
a set of vertices called reversed roots. They are the out-
neighbors of pseudo vertex 𝛿 introduced in Section 2.3. In
DFI, the client analysis can pick its own reversed roots to
begin the traversal. Since they have an implication on the set
of vertices to be visited, it is worth discussing the intuition
behind reversed roots in the context of value-flow analysis.
In a backward analysis, a reversed root naturally assumes
the role of value-flow origin. For example, for a query asking

CGO ’23, Feb.25–Mar.03, 2023, Montreal, QC, Canada

Min-Yih Hsu, Felicitas Hetzelt, and Michael Franz

if value 𝑥 is live on operation 𝐼 , a classic live-variable analysis,
we can pick values used by 𝐼 (i.e. its operands) as reversed
roots. On the other hand, reversed roots can be seen as all
possible destinations in a forward analysis setup. For instance,
in the taint analysis that asks if sensitive information (i.e.
tainted values) flows to any system call, we can pick all
system call sites as the reversed roots such that all possible
value-flow paths can be considered. It is worth noting that
DFI is able to consider all possible paths at once because our
algorithm is both time and space efficient, which we will
show in Section 4.

Augmented DFT-Interval Graph Reachability With re-
duced number of non-tree edges, DFI augments the DFT-
interval-based algorithm to solve graph reachability in re-
versed SSA def-use graphs. In short, this method duplicates
the interval upon encountering a non-tree edge, such that
we can use a similar subsuming relationship between two
intervals to determine their reachability.

To support our method, we introduce a new data structure:

interval set. An interval set Π is a collection of intervals
{⟨𝑠1, 𝑒1⟩, ⟨𝑠2, 𝑒2⟩, ..., ⟨𝑠𝑛, 𝑒𝑛⟩}
in which every element separates themselves with each other
by least one timestamp. i.e.

∀⟨𝑠𝑖, 𝑒𝑖 ⟩, ⟨𝑠 𝑗, 𝑒 𝑗 ⟩ ∈ Π, 𝑖 ≠ 𝑗 =⇒ 𝑒𝑖 < 𝑠 𝑗 − 1 ∨ 𝑒 𝑗 < 𝑠𝑖 − 1
An interval set Π𝑖 is said to subsume another set Π 𝑗 , namely
Π𝑖 ⊇ Π 𝑗 , if any of the interval in Π𝑖 can subsume another
interval in Π 𝑗 . i.e.

∃⟨𝑠𝑘, 𝑒𝑘 ⟩ ∈ Π𝑖, ⟨𝑠𝑙, 𝑒𝑙 ⟩ ∈ Π 𝑗 s.t. ⟨𝑠𝑘, 𝑒𝑘 ⟩ ⊇ ⟨𝑠𝑙, 𝑒𝑙 ⟩
Two interval sets Π𝑖 and Π 𝑗 can be merged by operator ∪,
denoted as Π𝑖 ∪Π 𝑗 . Let Π𝑘 be the merged interval set from Π𝑖
and Π 𝑗 , it can subsume both Π𝑖 and Π 𝑗 i.e. Π𝑘 ⊇ Π𝑖 ∧Π𝑘 ⊇ Π 𝑗 .
In our augmented DFT-interval-based reachability algorithm,
each SSA def-use graph vertex 𝑣 is associated with an interval
set Π𝑣 (rather than a single interval). Vertex 𝑣𝑖 can reach 𝑣 𝑗
if and only if Π𝑣𝑗 subsumes Π𝑣𝑖 . i.e.

𝑣𝑖 (cid:123) 𝑣 𝑗 ⇐⇒ Π𝑣𝑗 ⊇ Π𝑣𝑖 ∧ Π𝑣𝑖 ≠ ∅ ∧ Π𝑣𝑗 ≠ ∅
Note that since we build DFT intervals in reversed direction,
a vertex can reach another vertex if the interval set of the
destination subsumes that of the source. To build interval
sets for each vertex in the graph, the interval set of each
vertex is first initialized with a single interval created from a
normal DFT-interval building process (see Section 2.3). Next,
non-tree edges are incorporated.

Given a cross edge 𝑣𝑠 → 𝑣𝑑 , Π𝑣𝑑 is merged into Π𝑣𝑠 and
the interval sets of all of its ancestors. Figure 6a shows an
example of handling cross edge 𝐸 → 𝐷. The interval set for
destination vertex 𝐷, {⟨2, 3⟩}, is merged into the interval
sets of 𝐸, as well as its ancestors 𝐶 and 𝐴. This allows us to
account for graph reachability of two vertices that passes
through 𝐸 → 𝐷. For example, 𝐶 can reach 𝐷 because Π𝐶 ⊇
Π𝐷 . If 𝑣𝑠 → 𝑣𝑑 is a back edge, Π𝑣𝑑 will be merged into the

6

(a) Cross Edge

(b) Back Edge
Figure 6. Non-tree edge handling

interval sets of all vertices in the corresponding Strongly-
Connected Component (SCC). The intuition behind this is
that every vertex in such SCC belong to a subtree rooted at
𝑣𝑑 , per the definition of back edge mentioned in Section 2.3.
In other words, Π𝑣𝑑 subsumes the interval sets of all of those
vertices. Thus, our merging scheme here is able to reflect the
mutual connectivity of vertices in a SCC, including the back
edge. Figure 6b shows an example of handling back edge
𝐷 → 𝐴. The interval set for destination vertex 𝐴, {⟨0, 9⟩},
is merged into the interval sets of every other vertex in the
same SCC. Namely, vertices 𝐵, 𝐶, and 𝐷.

Meet Operator The meet operator specifies how value
flows are combined from different program paths e.g. at a
control flow merge point. In our algorithm, we use interval
set merge ∪ as our meet operator. Per our previous definition
of ∪, the merged interval set is always a safe approximation
for the incoming interval sets and thus ensures the sound-
ness.

3.4 Inter-procedural Analysis
This Section discusses how to apply our interval-based reach-
ability algorithm across interprocedural constructions e.g.
call sites. DFI uses a summary-based interprocedural value-
flow algorithm. We summarize the value-flows of each func-
tion in a function value-flow summary which is propagated to
all of its call sites. Since the newly introduced callee summary
alters value-flows inside the caller function, this process is
repeated until a fixed point is reached.

A function value-flow summary comprises of a set of
reachable relationships between function arguments and
(outgoing) results. The results of a function are returned
values or output (i.e. pointer) arguments. The summary de-
scribes the mapping between arguments and results which
is expressed through argument and result indices. The result
index is equal to the index of its counterpart in the result
list of the dfi.call operation (see Section 3.1). In every
dfi.call, the original returned value (if there is any) has
index 0, followed by pointer argument type results. We de-
note 𝐼 (𝑝) as the argument index of argument 𝑝. In addition,
𝑂 (𝑝) is defined as the result index of 𝑝 if 𝑝 is part of 𝑃𝑇𝑓 , a
subset of function arguments for 𝑓 containing all pointer ar-
guments. The value-flow summary for function 𝑓 is denoted
as 𝑆 𝑓 = 𝑆𝑅
𝑓 and 𝑆𝑃
𝑓 represent mappings from
function arguments to return value and to output arguments
respectively. Let 𝑅𝑓 and 𝑃𝑓 be the set of return values and

𝑓 . The sets 𝑆𝑅

𝑓 ∪𝑆𝑃

EBDA{〈0,11〉}{〈5,10〉,〈2,3〉}CF{〈6,7〉, 〈2,3〉}{〈8,9〉}{〈1,4〉}{〈2,3〉}CDABE{〈0,9〉}{〈1,8〉}{〈6,7〉}{〈2,5〉}{〈3,4〉}CDABE{〈0,9〉}{〈0,9〉}{〈6,7〉}{〈0,9〉}{〈0,9〉}DFI: An Interprocedural Value-Flow Analysis Framework that Scales to Large Codebases

CGO ’23, Feb.25–Mar.03, 2023, Montreal, QC, Canada

Value Interval Set Summarized Value-Flow

Value Interval Set Summarized Value-Flow

%r
%t
%a
%c

{⟨0, 7⟩}
{⟨1, 6⟩}
{⟨2, 3⟩}
{⟨4, 5⟩}

%a

%r

%b

%c

(On Call Site)

%t1
%t0
%k
%r

{⟨0, 7⟩}
{⟨1, 4⟩}
{⟨2, 3⟩}
{⟨5, 6⟩}

%k

%k’

%r

%r’

(a) Listing 3
Figure 7. Function value-flow summaries

(b) Listing 4, reversed root %t1

arguments in 𝑓 , respectively. 𝑆𝑅

𝑓 is defined as

{𝐼 (𝑝) (cid:123) 0 | 𝑝 (cid:123) 𝑟, ∀𝑝 ∈ 𝑃𝑓 , ∀𝑟 ∈ 𝑅𝑓 }
Figure 7a shows the value-flow summary of f along with
interval sets of relevant values. Since Π𝑟 ⊇ Π𝑎 and Π𝑟 ⊇ Π𝑐 ,
the value of 𝑆𝑅

𝑓 == 𝑆 𝑓 is {0 (cid:123) 0, 2 (cid:123) 0}

1 llvm . func @g (% k: ! llvm . ptr < i32 > , %r: ! llvm . ptr < i32 >) {
2
3
4 }

% t0 = llvm . load %k : ! llvm . ptr < i32 >
% t1 = dfi . store %t0 , %r : ! llvm . ptr < i32 >

Listing 4. A MLIR function with two pointer arguments

𝑆𝑃
𝑓 captures the potential value-flows applied on pointer
arguments in function 𝑓 . Specifically, it contains mappings
between pointer arguments and corresponding output re-
sults on the dfi.call sites. Since the result of a pointer
argument can be difficult to locate in the callee, we use the
reachability between pointer arguments and the reversed
roots as an approximation. For arbitrary two pointer argu-
ments 𝑝0 and 𝑝1, 𝑆𝑃
𝑓 is initialized with 𝐼 (𝑝0) (cid:123) 𝑂 (𝑝0) and
𝐼 (𝑝1) (cid:123) 𝑂 (𝑝1). If 𝑝0 and 𝑝1 can both reach a reversed root
𝜏, then we can add 𝐼 (𝑝0) (cid:123) 𝑂 (𝑝1) and 𝐼 (𝑝1) (cid:123) 𝑂 (𝑝0) into
𝑆𝑃
𝑓 . Formally speaking, let T𝑓 be the set of reversed roots in
𝑓 , 𝑆𝑃
{𝐼 (𝑝) (cid:123) 𝑂 (𝑘), 𝐼 (𝑘) (cid:123) 𝑂 (𝑝) | ∃𝜏 ∈ T𝑓 s.t.
𝑝 (cid:123) 𝜏 ∧ 𝑘 (cid:123) 𝜏, ∀𝑝, 𝑘 ∈ 𝑃𝑇𝑓 } ∪ {𝐼 (𝑝) (cid:123) 𝑂 (𝑝) | ∀𝑝 ∈ 𝑃𝑇𝑓 }

𝑓 is defined as

Figure 7b shows an example value-flow summary for func-
tion g in Listing 4. 𝑘 ′ and 𝑟 ′ correspond to the results of 𝑘
and 𝑟 at a call site, respectively. Since both 𝑘 and 𝑟 can reach
the reversed root %t1, 𝑆𝑃
{𝐼 (𝑘) (cid:123) 𝑂 (𝑘), 𝐼 (𝑘) (cid:123) 𝑂 (𝑟 ), 𝐼 (𝑟 ) (cid:123) 𝑂 (𝑟 ), 𝐼 (𝑟 ) (cid:123) 𝑂 (𝑘)}
which is equal to {0 (cid:123) 0, 0 (cid:123) 1, 1 (cid:123) 1, 1 (cid:123) 0}

𝑔 in this case can be written as

Value-Flow Summary Propagation Next, we propagate
the value-flow summary 𝑆 𝑓 to every call site of 𝑓 . On a high
level, 𝑆 𝑓 provides the missing local value-flow mappings
at every call site of 𝑓 . With this information in place, we
are able to add new value-flows to the caller functions to
improve precision. This process consists of two phases.

In the first phase, for each 𝑣𝑠 (cid:123) 𝑣𝑑 in 𝑆 𝑓 , we perform
another round of reversed DFT traversal in every caller
function. But this time, instead of using reversed roots desig-
nated by the client analysis, we will use the actual parameter
values of 𝑣𝑠 as revered roots.
1 llvm . func @f (% v: i32 , %p :! llvm . ptr < i32 >) -> i32 {
2

% t0 = llvm . load %p : ! llvm . ptr < i32 >

% t1 = dfi . store %v , %p : ! llvm . ptr < i32 >
llvm . return % t0 : i32

3
4
5 }
6 llvm . func @g (% k: i32 , %b :! llvm . ptr < i32 >) -> i32 {
7
8
9
10
11 }

% s0 = llvm . add %k , %k : i32
%s1 ,% s2 = dfi . call @f (% s0 , %b)
% s3 = dfi . store %k , % s2 : ! llvm . ptr < i32 >
llvm . return % s1 : i32

Listing 5. A simple MLIR snippet

In Listing 5, function g calls function f on line 8. In this
is {0 (cid:123)
snippet, we assume the value-flow summary 𝑆 𝑓
1, 1 (cid:123) 0, 1 (cid:123) 1}. On line 8, phase 1 performs a reversed
DFT traversal using %s0 (i.e. the actual parameter %v in f)
and %b (i.e. the actual parameter %p in f) as reversed roots.
In the second phase, the results from the first phase are
propagated in the opposite direction on every call site. In List-
ing 5 for example, the interval sets for %s0 and %b, obtained
in phase 1, are transitively merged into the interval sets of
its parent and ancestor vertices (e.g. %s3) in the augmented
DFT, until reaching the original reversed roots.

As mentioned earlier, propagating callee value-flow sum-
maries in the caller function might change its value-flow sum-
mary as well. DFI uses a worklist-based algorithm, shown
in Algorithm 1, to recursively propagate the changed sum-
maries to its callers until reaching a fixed point.

Algorithm 1 Interprocedural Worklist Algorithm
1: 𝑊 𝑜𝑟𝑘𝑙𝑖𝑠𝑡 = all functions
2: while 𝑊 𝑜𝑟𝑘𝑙𝑖𝑠𝑡 ≠ ∅ do
𝑓 := 𝑊 𝑜𝑟𝑘𝑙𝑖𝑠𝑡 .𝑝𝑜𝑝 ()
3:
𝑆 𝑓 := 𝐺𝑒𝑡𝑉 𝐹𝑆𝑢𝑚𝑚𝑎𝑟 𝑦 (𝑓 )
4:
if 𝑆 𝑓 has changed then
5:
6:
7:
8:
9:
10:
11:
12:
end if
13: end while

𝑃𝑟𝑜𝑝𝑎𝑔𝑎𝑡𝑒𝑆𝑢𝑚𝑚𝑎𝑟 𝑦 (𝑆 𝑓 , 𝑐)
if 𝑐 ∉ 𝑊 𝑜𝑟𝑘𝑙𝑖𝑠𝑡 then
𝑊 𝑜𝑟𝑘𝑙𝑖𝑠𝑡 .𝑝𝑢𝑠ℎ (𝑐)

for all 𝑐 ∈ 𝑐𝑎𝑙𝑙𝑒𝑟𝑠 (𝑓 ) do

end for

end if

In Algorithm 1, 𝐺𝑒𝑡𝑉 𝐹𝑆𝑢𝑚𝑚𝑎𝑟𝑦 (𝑓 ) returns 𝑆 𝑓 for func-
tion 𝑓 ; 𝑃𝑟𝑜𝑝𝑎𝑔𝑎𝑡𝑒𝑆𝑢𝑚𝑚𝑎𝑟𝑦 (𝑆 𝑓 , 𝑐) performs the two-phase
propagation introduced earlier with callee value-flow sum-
mary 𝑆 𝑓 in caller function 𝑐.

Reachable Functions Summary We are now able to cal-
culate interprocedural value-flows with flow and context-
sensitivity of two values 𝑣𝑎 and 𝑣𝑏 in the same function by
determining their reachability via interval sets i.e. Π𝑣𝑏 ⊇ Π𝑣𝑎 .
In this part, we generalize this ability for 𝑣𝑎 and 𝑣𝑏 that reside
in arbitrary functions.

In the previous Section, the value-flow summary of callee
function was propagated to the caller, in order to add context-
sensitive value-flows into the caller function. This process
is now augmented to additionally propagate a reachable

7

CGO ’23, Feb.25–Mar.03, 2023, Montreal, QC, Canada

Min-Yih Hsu, Felicitas Hetzelt, and Michael Franz

function summary. A reachable function summary Ψ(𝜀) pro-
vides a mapping from an endpoint 𝜀 to a set of transitively-
reachable endpoints. An endpoint 𝜀𝑖
𝑓 represents the 𝑖-th ar-
gument of function 𝑓 .

Target
FFmpeg
OpenSSL
SQLite 3
Lighttpd

Version # LOC # LOC (LLVM IR)

1.2M
532K
166K
97K

4.2
3.0.0
3.36.0
1.4.60
Table 1. Description of target codebases

4.6M
1.1M
376K
216K

# of Functions
17802
13490
1103
1258

Description
A/V encoder and decoder
Crypto and TLS
SQL database
Web server

dfi . call @g (% a0 )

1 llvm . func @f (% a0 : i32 , % a1 : i32 ) {
2
3 }
4 llvm . func @g (% a0 : i32 ) {
5
6
7 }
8 llvm . func @k (% a0 : i32 , % a1 : i32 , % a2 : i32 )

dfi . call @f (10 , % a0 )
dfi . call @k (23 , 75 , % a0 )

Listing 6. MLIR functions with interprocedural calls

Take Listing 6 as an example, the reachable function sum-
mary for 𝜀0
𝑓 (i.e. the first argument of function f) is

Ψ(𝜀0

𝑓 ) = {𝜀0

𝑔, 𝜀1

𝑓 , 𝜀2
𝑘 }

Because the first argument of f will be passed to the first
argument of g, which further passes it to the second and
third argument of f and k, respectively.

To calculate Ψ, we use the same infrastructure outlined
in Algorithm 1. Basically, for a given function 𝑓 with 𝑛 ar-
guments, Ψ(𝜀0...𝑛−1
) is repeatedly propagated to all of its
callers and merged with their summaries until reaching a
fixed point, namely, none of the reachable function sum-
maries changed. With reachable function summaries, we are
able to perform a two-stage process to answer the value-flow
query 𝑣𝑎 (cid:123) 𝑣𝑏, where 𝑣𝑎 and 𝑣𝑏 are in different functions 𝑓
and 𝑔, respectively. First, we calculate a set

𝑓

{𝜀𝑖

𝑒 | ∀𝑒 ∈ 𝑐𝑎𝑙𝑙𝑒𝑒𝑠 (𝑓 ) s.t. 𝑣𝑎 (cid:123) 𝜀𝑖
𝑒 }
Then, we check if any of the Ψ(𝜀𝑖
𝑒 ) contains an endpoint of 𝑔,
𝜀 𝑗
𝑔, for arbitrary argument index 𝑗. If not, that means function
𝑓 cannot even reach function 𝑔. Finally, in the second stage,
we can conclude that 𝑣𝑎 can reach 𝑣𝑏 only if endpoint 𝜀 𝑗
𝑔 can
reach 𝑣𝑏. Namely, 𝜀 𝑗
4 Evaluation
In this Section, we discuss two research questions:

𝑔 (cid:123) 𝑣𝑏 =⇒ 𝑣𝑎 (cid:123) 𝑣𝑏.

• RQ1: How well does DFI scale on large codebases
and how does it compare against other state-of-the-art
value-flow analysis tools? (§ 4.1 and § 4.2)

• RQ2: The efficiency of answering graph reachability
in DFI is strongly related to the size of the interval set
associated with each vertex. What is the size distribu-
tion of interval sets across all vertices? (§ 4.3)

We selected four open-source codebases from different do-
mains and of different sizes as our analysis targets: Lighttpd,
SQLite 3, OpenSSL, and FFmpeg. Table 1 details the selected
target programs, lines-of-code (LOC) are listed in textual as
well as LLVM 14 IR code, as DFI operates on LLVM IR input.
The targets are built using Link-Time Optimization (LTO)
to generate a monolithic executable without dynamic de-
pendencies. All experiments are performed on a commodity

8

desktop running Ubuntu 20.04 LTS with a 6-core, 12-thread
Intel i7-8700K CPU and 32GB of RAM.
4.1 Performance of Different Client Analyses
We measured the performance of DFI with two different
client analyses: taint analysis and read-only argument anal-
ysis, both analyses are flow and context-sensitive.

The taint analysis is designed to taint address-taken vari-
ables. If the address-taken variable is tainted, all related
pointer variables comprising of variables pointing to the
beginning of the object as well as pointers derived from an
offset, are tainted as well; any value loaded from a tainted
variable is also considered tainted. Our implementation tra-
verses the following operations: memory load, dfi.store,
and getelementptr which creates a new pointer by apply-
ing an offset to a base pointer.

Read-only argument analysis detects whether a pointer
argument is modified in the callee function. A pointer argu-
ment 𝑝 of callee function 𝑓 is considered modified (i.e. not
read-only) on a dfi.call call site if any of the argument
values, other than 𝑝, can reach the corresponding result of 𝑝
(i.e. result at index 𝑂 (𝑝)) on that call site. Our implementa-
tion traverses pointer values within 𝑓 through their def-use
chains. For all indirect memory stores on the path, we also
traverse the stored value and its def-use chains.

Table 2 lists the results of running our two client appli-
cations against the targets listed in Table 1. The runtime
measurement is split into two categories, Total time and
Analysis time. The total time accounts for the wall-clock
time spent on the entire process, while the analysis time
only measures the time spent in the main analysis (see Fig-
ure 8 for an overview of processing steps before and after
the main analysis). The memory consumption measures the
maximum amount of physical memory allocated during the
evaluation of each target, which is roughly equal to resi-
dent memory. The number of visited edges and vertices is
listed in the #V-Edge and #V-Vertex columns, respectively.
Our evaluation shows that read-only argument analysis vis-
ited roughly 20% ∼ 60% more vertices and edges compared to
taint analysis on every target, except for FFmpeg, where the
number of visited edges increased by 160% for taint analysis.
All experiments finished within 10 minutes using no more
than 4.5 GB of physical memory. In the next two paragraphs,
we will proceed to breakdown the performance and discuss
the scalability w.r.t different codebase sizes.
Performance Breakdown DFI is built using the standard
MLIR framework. We use the built-in MLIR parser to parse
our input and process it with a MLIR pass pipeline that runs
the preprocessor and analysis engine. In this pipeline, we
found that some built-in components that are not part of the

DFI: An Interprocedural Value-Flow Analysis Framework that Scales to Large Codebases

CGO ’23, Feb.25–Mar.03, 2023, Montreal, QC, Canada

Taint Analysis

Read-Only Argument Analysis

Target
FFmpeg
OpenSSL
SQLite 3
Lighttpd

#V-Edge
730.0K
250.9K
81.4K
27.2K

1.53M
549.1K
156.7K
62.0K

#V-Vertex Total time Analysis time Max resident memory
2.78s
1.15s
564.0ms
104.2ms

534.63s
101.47s
4.72s
1.09s
Table 2. Performance and memory consumption of DFI

#V-Vertex Total time Analysis time Max resident memory
5.42s
2.05s
1.71s
142.3ms

#V-Edge
1.9M
398.4K
128.1K
42.2K

3.19 GB
876.60 MB
337.55 MB
168.10 MB

4.08 GB
1.09 GB
424.19 MB
189.07 MB

497.66s
99.99s
3.47s
1.05s

2.6M
677.3K
202.3K
75.6K

Parsing

Preprocess

Analysis

Verification

Output

FFmpeg

OpenSSL

SQLite3

Lighttpd

0

0.2

0.4

0.6

0.8

1

Figure 8. Timing breakdown of read-only argument analysis

Visited Edges

Visited Vertices

Analysis Time, Max Memory

Taint Analysis

RO Argument Analysis

6

0
1
×
s
e
c
i
t
r
e
V

,
s
e
g
d
E
d
e
t
i
s
i
V
#

2

1.5

1

0.5

0

2

1.5

1

0.5

0

4

3

2

1

0

4

3

2

1

0

3

2

1

0

3

2

1

0

d
p
t
t
h
g
i
L

3
e
t
i
L
Q
S

L
S
S
n
e
p
O

g
e
p
m
F
F

6

4

2

0

6

4

2

0

)
c
e
s
(

e
m
T

i

)
B
G

(
y
r
o
m
e
M

d
p
t
t
h
g
i
L

3
e
t
i
L
Q
S

L
S
S
n
e
p
O

g
e
p
m
F
F

Figure 9. Scalability of time and memory consumption

DFI codebase comprise the majority of execution time. The
total pipeline execution time can be broken down into five
major components which are listed in Figure 8. We evaluate
the ratio of processing time spent in each component for
read-only argument analysis across all targets. Among them,
the MLIR parser always accounts for most of the runtime.
Other large contributors are the verifier, which verifies MLIR
code after each pass, and the output stage, these nonfactors
account for 55% ∼ 85% of the total execution time. The pre-
processor is part of DFI (see Section 3.1), though we argue
that its runtime is a single-shot cost that will be amortized by
the number of MLIR passes in the pipeline. For the scalability
evaluation we will therefore focus on the runtime and mem-
ory requirements of the main analysis, which constitutes the
core contribution of this paper.
Scalability of the Analysis To evaluate the scalability of
DFI, we measure the increase in analysis time and mem-
ory consumption against increases of the target code size
as represented by the number of edges and vertices in DFI’s
program graph. The results of the scalability evaluation are
shown in Figure 9. On the left hand side of the figure we

9

DFI

SVF [31]

497.66s
99.99s
3.47s
1.05s

Phasar [29]
Total time Max memory Total time Max memory Total time Max memory

Target
FFmpeg
OpenSSL
SQLite 3
Lighttpd
Table 3. Comparison of taint analysis performance and max-
imum resident memory consumption of DFI with Phasar and
SVF. OOM means out-of-memory; "-" means runtime error.

-
-
OOM
471.28 MB

3.19 GB
876.60 MB
337.55 MB
168.10 MB

OOM
OOM
6.31 GB
1.01 GB

N/A
N/A
192.04s
67.71s

-
-
N/A
24.97s

measure the runtime (top) and memory consumption (bot-
tom) of DFI based taint analysis across all targets. The results
demonstrate that the runtime as well as the memory con-
sumption of DFI increases by a factor that is bounded by the
increase in the number of vertices and edges respectively.
The same experiment is repeated for read-only argument
analysis, shown in the right half of the same figure, for which
we measure a comparable result.

We notice two exceptions i.e. analysis time of both anal-
yses on SQLite 3. We found that, in processing the SQLite
3 codebase, significantly more time was spent in the inter-
procedural worklist algorithm (Algorithm 1). Specifically,
the propagation of callee function summaries to call sites
in every caller functions. Further investigation reveals two
important factors contributing to this problem. First, SQLite
3 has a much denser call graph, in which each callee function
is called by 3x ∼ 4x more call sites on average, compared
to call graphs in other targets. Second, Table 1 shows that
functions in SQLite 3 contain more code on average, primar-
ily because the codebase has fewer functions compared to
other projects of comparable size. The fact that these two
factors multiply together (i.e. higher number of propagations
to many large-size caller functions) induces a higher perfor-
mance overhead in Algorithm 1. However, we argue that the
source code structure of SQLite 3, more specifically, their
interprocedural function call structure, is relatively unusual.

4.2 Comparison with Other Tools

Table 3 compares the performance of DFI against SVF and
Phasar. Phasar computes value-flow information using the
IFDS algorithm; SVF utilizes SSA def-use chains and incorpo-
rates address taken variables based on precomputed points-
to information. Note that, for this evaluation, we measure the
total time rather than analysis time for DFI, in order to pro-
vide a fair comparison. DFI and Phasar are evaluated by per-
forming taint analysis. For SVF we conservatively estimate
a lower bound for its runtime and memory consumption.
SVF builds a special Static Value-Flow Graph (SVFG), before
running the actual analysis. We found that SVF either runs

CGO ’23, Feb.25–Mar.03, 2023, Montreal, QC, Canada

Min-Yih Hsu, Felicitas Hetzelt, and Michael Franz

Taint Analysis

RO Argument Analysis

t
e
S

/

s
l
a
v
r
e
t
n
I

#

15

10

6
4
2
0

Lighthttpd

SQLite3

OpenSSL

FFmpeg

Figure 10. Size distribution of interval sets

out of memory or runs slower than DFI during the graph
construction phase. Thus, we only include performance of
the SVF graph construction phase. As depicted in Table 3
Phasar was unable to perform the analysis on FFmpeg and
OpenSSL due to segmentation faults; it ran out of memory
on SQLite 3; on Lighttpd, DFI ran 23x faster with 2.8x less
memory than Phasar. SVF ran out of memory on FFmpeg
and OpenSSL; on SQLite 3 and Lighttpd, DFI ran 55x ∼ 64x
faster and consumes 6x ∼ 19x less memory than SVF.
4.3 Size Distribution of Interval Set
Section 3.3 introduced the concept of an interval set Π𝑣 for a
vertex 𝑣 and its subsuming operator ⊇. The properties of an
interval set play an important role in efficiently determining
the reachability of two vertices. Specifically, given two inter-
val sets Π𝑝 and Π𝑞 with at most 𝑁 intervals each, the time
complexity for evaluating Π𝑝 ⊇ Π𝑞 is 𝑂 (𝑁 2).

Figure 10 shows the size distribution of interval sets across
all targets in both client analyses. In taint analysis, half of the
interval sets have at most 2 intervals; the maximum value of
this chart also tells us that majority of the interval sets have at
most 8 intervals. For read-only argument analysis, majority
of the interval sets have at most 17 intervals, while half of
them have no more than 4 intervals. These numbers show
that the average size of an interval set is usually small. Thus,
they offer additional evidence towards the effectiveness of
our novel reversed DFT traversal scheme in reducing the
number of non-tree edges.
5 Discussion
5.1 Fixpoint Convergence
The intraprocedural reversed DFT traversal, introduced in
Section 3.3, operates basically the same as normal DFS tra-
versal on spanning tree edges and thus ensures its fixpoint
convergence on those edges. While handling non-tree edges,
we never remove any interval or interval subset during the
propagation, therefore the process is monotonic with respect
to the partial orders of the interval sets. Thus, fixpoint con-
vergence is given. For the interprocedural case, we focus on
Algorithm 1. The terminating condition for Algorithm 1 is
dictated by changes to function summaries. These changes
are caused by transitively propagating any callee function
summary into the current function context. The propagation
is driven by the same traversal algorithm that is also used for
the intraprocedural case mentioned above. Thus, a fixpoint
convergence w.r.t. function summaries can be inducted from
the convergence of interval sets in callee functions, due to

10

the fact that a function summary is derived from interval
sets of the same function.
5.2 Comparison with IFDS
DFI replaces the IFDS reachability algorithm with a simple
interval lookup and avoids the accumulation of PathEdges
which constitute a large part of the memory footprint of
IFDS solvers [1, 13, 19]. Further, DFI processes only relevant
program statements by utilizing sparse SSA def-use chains,
whereas IFDS processes every program statement along con-
trol flow paths inducing memory and runtime overheads [13].
Lastly, DFI decouples DFT interval computation from specific
value-flow queries and can determine value-flows between
arbitrary nodes. In contrast, IFDS requires non-trvial num-
ber of recomputations on PathEdges [2] whenever there is a
change in value-flow sources.
6 Related Work
The original IFDS/IDE algorithm [27] together with practi-
cal extensions proposed by Naeem et al. [22] is nowadays
implemented by many analysis frameworks for JAVA [3, 5]
and C/C++ [29]. In addition, several approaches have been
proposed to further reduce memory consumption and pro-
cessing time of IFDS implementations. Sparsedroid [13] im-
proves the sparsity of the dataflow propagation. The number
of dataflow edges is reduced by connecting dataflow facts
directly to their next point of use, instead of the next node
in the CFG. DiskDroid [19] and CleanDroid [1] reduce the
footprint of the graph reachability algorithm by detecting
stale edges and either move them to disk or completely re-
move them from the working set. WALA [9] proposes an
efficient bitset representation of dataflow facts. Coyote [30]
improves the parallelism of bottom-up IFDS implementations
by increasing the granularity of caller-callee dependencies.
Intraprocedural analysis is split into multiple independent
parts which can then be run in parallel. All of the mentioned
approaches address shortcomings that are specific to the
original IFDS implementation and are therefore not directly
comparable to DFI.

Recent contributions such as BigSpa [38], Grapple [39],
GraSpan [34] and Chianina [40] work around scalability
issues of static analysis frameworks by developing core func-
tionalities inspired by big data analytics in order to support
certain classes of static analyzers. The actual analysis is then
implemented on top of the core API and can thereby be trans-
parently scaled to the available resources of the underlying
system. Systems approaches are orthogonal to DFI as they
aim to provide primitives to improve the resource utilization
of static analyzers but do not aim to optimize the analysis
algorithm itself.
7 Conclusion
Value-flow analysis is an important component of many
program optimizations. Previous researchers have made sig-
nificant contributions and created important tools, but true
scalability of these tools to large real-world codebases has so

DFI: An Interprocedural Value-Flow Analysis Framework that Scales to Large Codebases

CGO ’23, Feb.25–Mar.03, 2023, Montreal, QC, Canada

far proven elusive. We present a solution that is able to over-
come these scalability bottlenecks. Key to our approach is a
dialect of LLVM IR that simplifies the modeling of pointer
aliasing for analysis. This leads to a novel sparse intermedi-
ate representation that results in graphs with low tree widths.
The resulting graph algorithms have much lower resource
requirements and much better performance characteristics
than previous approaches and provide almost linear scalabil-
ity to truly large programs. Our prototype implementation
is based on LLVM, is source-language agnostic, and will be
open-sourced.
References
[1] Steven Arzt. 2021. Sustainable Solving: Reducing The Memory Foot-
print of IFDS-Based Data Flow Analyses Using Intelligent Garbage
Collection. In Proceedings of the 43rd International Conference on Soft-
ware Engineering (ICSE ’21). IEEE Press, Madrid, Spain, 1098–1110.
https://doi.org/10.1109/ICSE43902.2021.00102

[2] Steven Arzt and Eric Bodden. 2014. Reviser: Efficiently Updating IDE-
/IFDS-based Data-Flow Analyses in Response to Incremental Program
Changes. In Proceedings of the 36th International Conference on Software
Engineering (ICSE 2014). Association for Computing Machinery, New
York, NY, USA, 288–298. https://doi.org/10.1145/2568225.2568243
[3] Steven Arzt, Siegfried Rasthofer, Christian Fritz, Eric Bodden, Alexan-
dre Bartel, Jacques Klein, Yves Le Traon, Damien Octeau, and Patrick
McDaniel. 2014. FlowDroid: Precise Context, Flow, Field, Object-
Sensitive and Lifecycle-Aware Taint Analysis for Android Apps. In
Proceedings of the 35th ACM SIGPLAN Conference on Programming Lan-
guage Design and Implementation. ACM, Edinburgh United Kingdom,
259–269. https://doi.org/10.1145/2594291.2594299

[4] Osbert Bastani, Saswat Anand, and Alex Aiken. 2015. Specification
inference using context-free language reachability. In Proceedings of
the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of
Programming Languages. 553–566.

[5] Eric Bodden. 2012. Inter-Procedural Data-Flow Analysis with IFDS/IDE
and Soot. In Proceedings of the ACM SIGPLAN International Workshop
on State of the Art in Java Program Analysis (SOAP ’12). Association
for Computing Machinery, New York, NY, USA, 3–8. https://doi.org/
10.1145/2259051.2259052

[6] Fred Chow, Sun Chan, Shin-Ming Liu, Raymond Lo, and Mark Streich.
1996. Effective representation of aliases and indirect memory opera-
tions in SSA form. In International Conference on Compiler Construction.
Springer, 253–267.

[7] Thomas H Cormen, Charles E Leiserson, Ronald L Rivest, and Clifford

Stein. 2022. Introduction to algorithms. MIT press.

[8] Ron Cytron, Jeanne Ferrante, Barry K Rosen, Mark N Wegman, and
F Kenneth Zadeck. 1991. Efficiently computing static single assign-
ment form and the control dependence graph. ACM Transactions on
Programming Languages and Systems (TOPLAS) 13, 4 (1991), 451–490.
[9] Stephen Fink and Julian Dolby. Accessed: 2022. Watson Libraries for
Analysis. http://wala.sourceforge.net/wiki/index.php/Main_Page
[10] Neville Grech and Yannis Smaragdakis. 2017. P/taint: Unified points-to
and taint analysis. Proceedings of the ACM on Programming Languages
1, OOPSLA (2017), 1–28.

[11] Ben Hardekopf and Calvin Lin. 2009. Semi-sparse flow-sensitive
pointer analysis. ACM SIGPLAN Notices 44, 1 (2009), 226–238.
[12] Ben Hardekopf and Calvin Lin. 2011. Flow-sensitive pointer analy-
sis for millions of lines of code. In International Symposium on Code
Generation and Optimization (CGO 2011). IEEE, 289–298.

[13] Dongjie He, Haofeng Li, Lei Wang, Haining Meng, Hengjie Zheng,
Jie Liu, Shuangwei Hu, Lian Li, and Jingling Xue. 2019. Performance-
Boosting Sparsification of the IFDS Algorithm with Applications to
Taint Analysis. In 2019 34th IEEE/ACM International Conference on

11

Automated Software Engineering (ASE). 267–279. https://doi.org/10.
1109/ASE.2019.00034

[14] Hao He, Haixun Wang, Jun Yang, and Philip S Yu. 2005. Compact
reachability labeling for graph-structured data. In Proceedings of the
14th ACM international conference on Information and knowledge man-
agement. 594–601.

[15] John B Kam and Jeffrey D Ullman. 1977. Monotone data flow analysis

frameworks. Acta informatica 7, 3 (1977), 305–317.

[16] John Kodumal and Alex Aiken. 2004. The set constraint/CFL reachabil-
ity connection in practice. ACM Sigplan Notices 39, 6 (2004), 207–218.
[17] Chris Lattner and Vikram Adve. 2004. LLVM: A compilation frame-
work for lifelong program analysis & transformation. In International
Symposium on Code Generation and Optimization, 2004. CGO 2004.
IEEE, 75–86.

[18] Chris Lattner, Mehdi Amini, Uday Bondhugula, Albert Cohen, Andy
Davis, Jacques Pienaar, River Riddle, Tatiana Shpeisman, Nicolas Vasi-
lache, and Oleksandr Zinenko. 2021. Mlir: Scaling compiler infrastruc-
ture for domain specific computation. In 2021 IEEE/ACM International
Symposium on Code Generation and Optimization (CGO). IEEE, 2–14.
[19] Haofeng Li, Haining Meng, Hengjie Zheng, Liqing Cao, Jie Lu, Lian Li,
and Lin Gao. 2021. Scaling up the IFDS Algorithm with Efficient Disk-
Assisted Computing. In Proceedings of the 2021 IEEE/ACM International
Symposium on Code Generation and Optimization (CGO ’21). IEEE Press,
Virtual Event, Republic of Korea, 236–247. https://doi.org/10.1109/
CGO51591.2021.9370311

[20] Sen Ma, MingYang Jiao, ShiKun Zhang, Wen Zhao, and Dong Wei
Wang. 2015. Practical null pointer dereference detection via value-
dependence analysis. In 2015 IEEE International Symposium on Software
Reliability Engineering Workshops (ISSREW). IEEE, 70–77.

[21] David Melski and Thomas Reps. 2000. Interconvertibility of a class
of set constraints and context-free-language reachability. Theoretical
Computer Science 248, 1-2 (2000), 29–98.

[22] Nomair A. Naeem, Ondřej Lhoták, and Jonathan Rodriguez. 2010. Prac-
tical Extensions to the IFDS Algorithm. In Compiler Construction (Lec-
ture Notes in Computer Science), Rajiv Gupta (Ed.). Springer, Berlin,
Heidelberg, 124–144. https://doi.org/10.1007/978-3-642-11970-5_8

[23] Diego Novillo. 2004. Design and implementation of Tree SSA. In

Proceedings of GCC developers summit. Citeseer, 119–130.

[24] Diego Novillo et al. 2007. Memory SSA-a unified approach for sparsely
representing memory operations. In Proceedings of the GCC Developers’
Summit. Citeseer, 97–110.

[25] Hakjoo Oh, Kihong Heo, Wonchan Lee, Woosuk Lee, and Kwangkeun
Yi. 2012. Design and implementation of sparse global analyses for
C-like languages. In Proceedings of the 33rd ACM SIGPLAN conference
on Programming Language Design and Implementation. 229–238.
[26] John H Reif and Harry R Lewis. 1977. Symbolic evaluation and the
global value graph. In Proceedings of the 4th ACM SIGACT-SIGPLAN
Symposium on Principles of Programming Languages. 104–118.
[27] Thomas Reps, Susan Horwitz, and Mooly Sagiv. 1995. Precise interpro-
cedural dataflow analysis via graph reachability. In Proceedings of the
22nd ACM SIGPLAN-SIGACT symposium on Principles of programming
languages. 49–61.

[28] Neil Robertson and P.D Seymour. 1984. Graph minors. III. Planar tree-
width. Journal of Combinatorial Theory, Series B 36, 1 (1984), 49–64.
https://doi.org/10.1016/0095-8956(84)90013-3

[29] Philipp Dominik Schubert, Ben Hermann, and Eric Bodden. 2019.
PhASAR: An Inter-procedural Static Analysis Framework for C/C++.
In Tools and Algorithms for the Construction and Analysis of Systems
(Lecture Notes in Computer Science), Tomáš Vojnar and Lijun Zhang
(Eds.). Springer International Publishing, Cham, 393–410.
https:
//doi.org/10.1007/978-3-030-17465-1_22

[30] Qingkai Shi and Charles Zhang. 2020. Pipelining Bottom-up Data Flow
Analysis. In Proceedings of the ACM/IEEE 42nd International Conference
on Software Engineering. ACM, Seoul South Korea, 835–847. https:

CGO ’23, Feb.25–Mar.03, 2023, Montreal, QC, Canada

Min-Yih Hsu, Felicitas Hetzelt, and Michael Franz

//doi.org/10.1145/3377811.3380425

5 }

Listing 7. IR before conversion to dfi.call.

1 llvm . func @f (% v: i32 , %p: ! llvm . ptr < i32 >) -> i64 {

2

3

%r , %p0

= dfi . call @g (%v ,

%p )

%0 = llvm . load

%p0

: ! llvm . ptr < i32 >

llvm . return %r : i64

4
5 }
Listing 8. IR after conversion to dfi.call. The newly added
function call result %p0 on line 2 captures side effects induced
by the callee g w.r.t pointer argument %p.

[31] Yulei Sui and Jingling Xue. 2016. SVF: interprocedural static value-flow
analysis in LLVM. In Proceedings of the 25th international conference
on compiler construction. 265–266.

[32] Dimitrios Vardoulakis and Olin Shivers. 2010. CFA2: A context-free
approach to control-flow analysis. In European Symposium on Pro-
gramming. Springer, 570–589.

[33] Haixun Wang, Hao He, Jun Yang, Philip S Yu, and Jeffrey Xu Yu. 2006.
Dual labeling: Answering graph reachability queries in constant time.
In 22nd International Conference on Data Engineering (ICDE’06). IEEE,
75–75.

[34] Kai Wang, Aftab Hussain, Zhiqiang Zuo, Guoqing Xu, and Ardalan
Amiri Sani. 2017. Graspan: A Single-machine Disk-based Graph System
for Interprocedural Static Analyses of Large-scale Systems Code. ACM
SIGPLAN Notices 52, 4 (April 2017), 389–404. https://doi.org/10.1145/
3093336.3037744

[35] Xuezheng Xu, Yulei Sui, Hua Yan, and Jingling Xue. 2019. VFix: value-
flow-guided precise program repair for null pointer dereferences. In
2019 IEEE/ACM 41st International Conference on Software Engineering
(ICSE). IEEE, 512–523.

[36] Hilmi Yildirim, Vineet Chaoji, and Mohammed J Zaki. 2010. Grail:
Scalable reachability index for large graphs. Proceedings of the VLDB
Endowment 3, 1-2 (2010), 276–284.

[37] Jisheng Zhao, Michael G Burke, and Vivek Sarkar. 2018. Parallel
sparse flow-sensitive points-to analysis. In Proceedings of the 27th
International Conference on Compiler Construction. 59–70.

[38] Zhiqiang Zuo, Rong Gu, Xi Jiang, Zhaokang Wang, Yihua Huang,
Linzhang Wang, and Xuandong Li. 2019. BigSpa: An Efficient Inter-
procedural Static Analysis Engine in the Cloud. In 2019 IEEE Interna-
tional Parallel and Distributed Processing Symposium (IPDPS). 771–780.
https://doi.org/10.1109/IPDPS.2019.00086

[39] Zhiqiang Zuo, John Thorpe, Yifei Wang, Qiuhong Pan, Shenming Lu,
Kai Wang, Guoqing Harry Xu, Linzhang Wang, and Xuandong Li. 2019.
Grapple: A Graph System for Static Finite-State Property Checking
of Large-Scale Systems Code. In Proceedings of the Fourteenth EuroSys
Conference 2019 (EuroSys ’19). Association for Computing Machinery,
New York, NY, USA, 1–17. https://doi.org/10.1145/3302424.3303972
[40] Zhiqiang Zuo, Yiyu Zhang, Qiuhong Pan, Shenming Lu, Yue Li,
Linzhang Wang, Xuandong Li, and Guoqing Harry Xu. 2021. Chianina:
An Evolving Graph System for Flow- and Context-Sensitive Analyses
of Million Lines of C Code. In Proceedings of the 42nd ACM SIGPLAN
International Conference on Programming Language Design and Imple-
mentation (PLDI 2021). Association for Computing Machinery, New
York, NY, USA, 914–929. https://doi.org/10.1145/3453483.3454085

A Supplements
A.1 Tables

Benchmark name
libcrypto (OpenSSL)
libssl (OpenSSL)
SQLite 3
FFmpeg
Lighttpd
Servo
Table 4. Percentage of SSA values with the respective num-
ber of uses

no use
2 uses
1 use
3 uses
31.89% 59.65% 4.00%
1.53%
33.44% 59.97% 2.30%
1.55%
3.09%
30.70% 52.26% 9.53%
20.67% 59.98% 11.53% 3.59%
1.05%
30.50% 63.74% 2.08%
1.69%
37.19% 50.58% 7.43%

4+ uses
2.93%
2.74%
4.42%
4.23%
2.63%
3.11%

A.2 Listings

1 llvm . func @f (% v: i32 , %p: ! llvm . ptr < i32 >) -> i64 {

2

3

4

%r = llvm . call @g (%v ,

%p )

%0 = llvm . load

%p

: ! llvm . ptr < i32 >

llvm . return %r : i64

12

