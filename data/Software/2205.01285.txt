2
2
0
2

n
u
J

1

]
E
M

.
t
a
t
s
[

2
v
5
8
2
1
0
.
5
0
2
2
:
v
i
X
r
a

A FLEXIBLE APPROACH FOR PREDICTIVE BIOMARKER
DISCOVERY

Philippe Boileau
Graduate Group in Biostatistics and
Center for Computational Biology,
University of California, Berkeley, and
philippe_boileau@berkeley.edu

PREPRINT

Nina Ting Qi
Genentech Inc.
qit3@gene.com

Sandrine Dudoit
Department of Statistics,
Division of Biostatistics, and
Center for Computational Biology,
University of California, Berkeley
sandrine@stat.berkeley.edu

Mark van der Laan
Division of Biostatistics,
Department of Statistics, and
Center for Computational Biology,
University of California, Berkeley
laan@berkeley.edu

Ning Leng
Genentech Inc.
lengn@gene.com

ABSTRACT

An endeavor central to precision medicine is predictive biomarker discovery; they deﬁne patient
sub-populations which stand to beneﬁt most, or least, from a given treatment. The identiﬁcation of
these biomarkers is often the byproduct of the related but fundamentally different task of treatment
rule estimation. Using treatment rule estimation methods to identify predictive biomarkers in
clinical trials where the number of covariates exceeds the number of participants often results in
high false discovery rates. The higher than expected number of false positives translates to wasted
resources when conducting follow-up experiments for drug target identiﬁcation and diagnostic assay
development. Patient outcomes are in turn negatively affected. We propose a variable importance
parameter for directly assessing the importance of potentially predictive biomarkers, and develop
a ﬂexible nonparametric inference procedure for this estimand. We prove that our estimator is
double-robust and asymptotically linear under loose conditions on the data-generating process,
permitting valid inference about the importance metric. The statistical guarantees of the method are
veriﬁed in a thorough simulation study representative of randomized control trials with moderate and
high-dimensional covariate vectors. Our procedure is then used to discover predictive biomarkers
from among the tumor gene expression data of metastatic renal cell carcinoma patients enrolled
in recently completed clinical trials. We ﬁnd that our approach more readily discerns predictive
from non-predictive biomarkers than procedures whose primary purpose is treatment rule estimation.
An open-source software implementation of the methodology, the uniCATE R package, is brieﬂy
introduced.

Keywords Heterogeneous treatment effects · High-dimensional data · Nonparametric statistics · Precision medicine ·
Predictive biomarkers · Variable importance parameter

1

Introduction

Precision medicine is now a chief focus of the biomedical establishment. Its promise of tailored interventions and
therapies is impossible to overlook, potentially spelling major improvements in patient outcomes [Kraus, 2018, Ginsburg
and Phillips, 2018]. Much effort has therefore been invested in the development of quantitative methods capable of
uncovering patient sub-populations which beneﬁt more, or less, from novel therapies than the standard of care.

 
 
 
 
 
 
A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

These groups of patients are distinguished from one another based upon diverse biometric measurements referred to
as predictive biomarkers [Royston and Sauerbrei, 2008, Kraus, 2018]. Examples include age, sex at birth, ethnicity,
and gene expression data taken from various tissue samples. Once identiﬁed, these biomarkers may provide clinicians
and biologists with mechanistic insight about the disease or therapy, and spur the development of diagnostic tools for
targeted treatment regimes.

The statistical discovery of predictive biomarkers has, to date, largely been a byproduct of conditional average treatment
effect (CATE) estimation. This typically unknown parameter contrasts the expected outcomes of patients under different
treatments as a function of their characteristics, thereby deﬁning the optimal treatment rule. Employing an estimate of
the CATE, clinicians can identify a subgroup of patients that draws most beneﬁt from a therapy. When estimated using
sparse modelling or otherwise interpretable methods, interpretable machine learning algorithms can be used to ﬁnd
potentially predictive biomarkers [Robins et al., 2008, Tian et al., 2014, Luedtke and van der Laan, 2016, Chen et al.,
2017, Zhao et al., 2018, Wager and Athey, 2018, Fan et al., 2020, Bahamyirou et al., 2022, Hines et al., 2022a].

While CATE estimation procedures are demonstrably successful at predictive biomarker discovery in settings where
the number of features is small relative to the sample size, it is not so in modern clinical trial in which the number
of features frequently exceeds the number of enrolled patients. The high-dimensional nature of trial data make the
CATE estimation problem particularly difﬁcult. Methods proposed for this setting must rely on convenient — and
sometimes unveriﬁable — assumptions about the underlying data-generating process. Examples are sparsity, linear
associations, and negligible dependence structures [Tian et al., 2014, Chen et al., 2017, Zhao et al., 2018, Fan et al.,
2020, Bahamyirou et al., 2022]. When these assumptions are violated, as is the case when, for example, the set of
biomarkers is comprised of gene expression data, the CATE estimate will be biased but may be viable. The biomarkers
designated as predictive, however, will likely be false positives (as demonstrated in Section 4).

Hines et al. [2022a] recently proposed a collection of variable importance parameters that assess the impact of variables,
either individually or in predeﬁned sets, on the variance of the CATE. These parameters are based on popular variable-
dropout procedures and on previous work about the variance of the conditional treatment effect [Levy et al., 2021].
While the proposed estimators of these parameters are consistent and asymptotically linear under non-restrictive
assumptions about the data-generating process, Hines et al. [2022a] note that quantifying treatment effect modiﬁcation
in this way is misleading when variables are highly correlated. Dropout-based importance metrics may also be deceiving
when there are many variables; other features may act as surrogates for the omitted covariate(s) [Hastie et al., 2009,
Chap. 15]. This framework is therefore inappropriate for the discovery of predictive biomarkers in high dimensions.

Still other procedures not relying on CATE estimation have recently been proposed. Sechidis et al. [2018] developed an
information-theoretic approach for identifying these treatment effect modiﬁers, though the statistical properties of the
procedure are not established and the simulations do not consider high-dimensional data. Zhu et al. [2022] recently
developed a penalized linear modelling method for the identiﬁcation of predictive biomarkers in high dimensions that
accounts for the biomarker correlation structure. Like the previous method, however, no formal statistical guarantees
are provided.

Myriad methods attempting to identify high-dimensional interactions more generally might also be considered for
our task [for example, Hao and Zhang, 2014, Jiang and Liu, 2014, Tang et al., 2020]. They too generally rely on
untenable simplifying assumptions about the data-generating process. These include, but are not limited to, assumptions
of normality, sparsity of the main effects, sparsity of interaction effects, and bounds on the condition number of the
biomarker covariance matrix. Large sets of biomarkers are again unlikely to satisfy such conditions, barring these
methods’ use for predictive biomarker discovery in high-dimensions.

A simpler alternative is to ﬁt individual (generalized) linear models of the outcome for each biomarker. Each model is
comprised of the biomarker’s main effect and a treatment-biomarker interaction term. The effect size estimate of the
latter serves as a measure importance; larger magnitudes equate to increased treatment effect modiﬁcation. Hypothesis
testing about these treatment-biomarker interaction effects is also possible. As with CATE estimation methods, however,
this simple approach imposes stringent parametric conditions on the data-generating process. When the outcome is
continuous, for example, inference is only possible when all marginal biomarker-outcome relationships are truly linear.
In small samples, an additional assumption of Gaussian error terms is needed for valid hypothesis testing. Violation of
these unrealistic conditions again produces unreliable predictive biomarker identiﬁcation.

A lack of Type-I error control has marked repercussions in many biomedical applications. In drug target discovery, lim-
ited resources are wasted by performing biological follow-up experiments on false positives. In diagnostic development,
the inclusion of non-predictive biomarkers may dilute the signal from truly informative ones. In a sequencing-based
diagnostic, invalid biomarkers will compete with others for sequencing reads, reducing the sequencing depth and,
thereby, the quantiﬁcation accuracy of predictive biomarkers. These failings have direct, detrimental effects on patient
health outcomes.

2

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

Motivated by these drawbacks, we present in this work a ﬂexible approach for directly assessing the predictive potential
of individual biomarkers. That is, we estimate (a transformation of) each biomarker’s univariate CATE, a novel variable
importance parameter for treatment effect modiﬁcation. What is more, our procedure permits the formal statistical
testing of these biomarkers’ predictive effects under non-restrictive assumptions about the underlying data-generating
process, and we ﬁnd that it controls the false discovery rate (FDR) at the nominal level for realistic sample sizes. We
also demonstrate on real-world data that our method provides reasonable sub-population identiﬁcation results when
combined with standard clustering approaches.

We emphasize that our framework is not a competitor of treatment rule estimation procedures, it is complementary. The
estimation of the CATE and the identiﬁcation of predictive biomarkers are related but distinct pursuits. To highlight
this, we might consider a two-step procedure wherein the full set of biomarkers is ﬁltered using our method, and then
the CATE is estimated using the remaining features. The beneﬁts of such a strategy are numerous. The results of the
initial stage can help assess whether the assumption of sparsity used by existing methods is tenable, and therefore
whether estimating the CATE is feasible. If not, then the ranking of biomarkers might still provide biological or clinical
insight, or motivate further study. If so, the CATE may be estimated more accurately, thanks to the reduced number
of features considered, using ﬂexible methods like those of Tian et al. [2014], Luedtke and van der Laan [2016], or
Wager and Athey [2018]. Further, the rankings generated in the initial stage can impart intuition about the otherwise
uninterpretable treatment rule produced by “black-box” methods.

The remainder of the manuscript is organized as follows: In Section 2, the estimation setting and problem are detailed
in statistical terms. Section 3 then describes the proposed inferential procedures. The asymptotic behavior of our
method is then veriﬁed empirically through a comprehensive simulation study in Section 4. Application of the proposed
approach to clinical trial data then follows in Section 5. We end with a brief discussion of the method in Section 6.
Throughout, we emphasize inference about the univariate CATEs in a randomized control trial setting, though some
remarks on its application to observational data are also provided.

2 Variable Importance Parameters

random vectors Xi = (Wi, Ai, Y (1)

Consider n identically and independently distributed (i.i.d.)
) ∼ PX ,
i = 1, . . . , n, corresponding to complete but unobserved data generated by participants in an idealized randomized
control trial or observational study. We drop the indices for notational convenience where possible throughout the
remainder of the article. Here, W = (V, B) is a (q + p)-length random vector of q pre-treatment covariates, V , like
location and income, and p pre-treatment biomarkers, B, such as gene expression data, A is a binary random variable
representing a treatment assignment, and Y (1) and Y (0) are random variables corresponding to the potential outcomes
of clinical interest under both treatment and control conditions, respectively [Rubin, 1974]. The number of biomarkers
p is assumed to be approximately equal to or larger than n. Generally, only one potential outcome is observed per unit.
We ignore this point for now, and return to it in the next section.

, Y (0)
i

i

Clinically relevant predictive biomarkers are often those that have a strong inﬂuence on the outcome of interest on the
absolute scale. As such, an ideal target of inference when these outcomes are continuous and the number of covariates
small is the CATE conditioning on the set of biomarkers:

(cid:104)

EPX

Y (1) − Y (0)(cid:12)

(cid:12)B = b

(cid:105)

.

For reasons previously discussed, however, accurate and interpretable estimation of this parameter is generally challeng-
ing when p is large, preventing the accurate recovery of predictive biomarkers.
Indexing the biomarkers of by j = 1, . . . , p, such that B = (B1, . . . , Bp), centering them such that EPX [Bj] =
0, and assuming that EPX [B2
j ] > 0, we instead target the full-data variable importance parameter ΨF (PX ) =
(ΨF
p (PX )) where

1 (PX ), . . . , ΨF

ΨF

j (PX ) ≡

EPX

(cid:2)(cid:0)Y (1) − Y (0)(cid:1) Bj
(cid:2)B2

EPX

(cid:3)

j

(cid:3)

.

(1)

Under the assumption that the mean difference in potential outcomes admits a linear form when conditioning on
any given Bj, ΨF (PX ) is the vector of expected simple linear regression coefﬁcients produced by regressing the
difference in potential outcomes against each biomarker. While the true relationship between the difference of potential
outcomes and a predictive biomarker is almost surely nonlinear, ΨF (PX ) is a generally informative target of inference.
Biomarkers with the largest absolute values in ΨF (PX ) generally modify the effect of treatment the most.
Analogous simpliﬁcations of the high-dimensional regression problem are applicable to other types of outcome variables.
For binary outcomes, we might similarly wish to quantify the importance of biomarkers on the absolute risk scale using

3

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

a slightly modiﬁed univariate CATE parameter, ΨF (binary)(PX ) = (ΨF (binary)

1

ΨF (binary)

j

(PX ) ≡

EPx

(cid:2)(cid:0)PPx

(cid:2)Y (1) = 1(cid:12)

(cid:12)W (cid:3) − PPX
(cid:3)
(cid:2)B2
EPX

j

(PX ), . . . , ΨF (binary)
(cid:2)Y (0) = 1(cid:12)
(cid:3)

(cid:12)W (cid:3)(cid:1) Bj

p

(PX )), where:

(2)

for centered biomarkers j = 1, . . . , p. This is, in fact, the same parameter as ΨF (PX ) but presented in a more intuitive
form for the binary outcome context: assuming a linear relationship between the difference of the potential outcomes’
probability of success and the covariates, this variable importance parameter consists of the simple linear regression
coefﬁcients of the difference in the conditional potential outcome success probabilities regressed on each biomarker.
Again, the true relationship between the difference of potential outcome probabilities and covariates is unlikely to be
linear. Nevertheless, this parameter is telling of biomarkers’ predictive capacities.

We stress that the parameters in Equations (1) and (2) are reasonable approximations of all but pathological treatment
effect modiﬁcation relationships; they summarize the true, marginal functional parameters using interpretable linear
models. A case in which ΨF
j (PX ) will fail to capture treatment effect modiﬁcation due to biomarker j is when the
EP0[Y (1) − Y (0)|Bj] is parabolic: the orthogonal projection of Y (1) − Y (0) onto Bj produces a variable importance
parameter value of zero. If such relationships are suspected, however, it sufﬁces to target the corresponding variable
importance parameters of the squared biomarkers. Analogous parameters based on transformations of the biomarkers
should be considered when the data-generating process is assumed to possess other similarly troublesome nonlinearities.

3

Inference

As previously mentioned, only one of the potential outcomes, Y (0) or Y (1), is observed per unit. Instead of {Xi}n
i=1,
we have access to n i.i.d. random observations O = (W, A, Y ) ∼ P0 ∈ M, where W and and A are deﬁned as before,
and Y = AY (1) + (1 − A)Y (0) is a continuous or binary random outcome variable. P0 is the unknown data-generating
distribution of the observed data that is fully determined by PX and the (conditional) treatment assignment distribution
gA|W . That is, P0 is an element of the nonparametric statistical model M = {PPX ,gA|W : PX ∈ MX , gA|W }. In a
perfect RCT, gA|W = gA = Bernoulli(0.5). The challenge therefore lies in estimating the full-data, causal parameter
of Equations (1) and (2) with the observed data; it is generally impossible without making additional assumptions about
P0. We begin by providing such identiﬁcation conditions.

Throughout the remainder of the text, we represent the empirical distribution of P0 by Pn, the conditional outcome
regression function by ¯Q0(a, w) ≡ EP0[Y |A = a, W = w], and the treatment assignment mechanism by g0(a, w) ≡
PP0[A = a|W = w]. Where possible, we simplify notation further by writing ¯Q0(a, w) and g0(a, w) as ¯Q0 and g0,
respectively. All proofs are provided in Section S1 of the Appendix.
(A1) No unmeasured confounding: Y (a) ⊥ A|W for a = {0, 1}.
(A2) Positivity: There exists some constant (cid:15) > 0 such that PP0[(cid:15) < g0(1, W ) < 1 − (cid:15)] = 1.

A1 assures that there are no unmeasured confounders of treatment and outcome, allowing for treatment allocation to be
viewed as the product of a randomized experiment. A2 is an overlapping support condition stating that all observations
may be assigned to either treatment condition regardless of covariates. These conditions, regularly cited in the causal
inference literature, are generally satisﬁed in randomized control trials. Altogether, they lead to the following result:
Theorem 1. Under the conditions of A1 and A2, letting EP0 [Bj] = 0, and assuming that EP0 [B2

j ] > 0,

EP0

Ψj(P0) ≡

(cid:2)(cid:0) ¯Q0(1, W ) − ¯Q0(0, W )(cid:1) Bj
(cid:2)B2

(cid:3)

EP0

j

(cid:3)

(3)

= ΨF

j (PX )

for j = 1, . . . , p such that Ψ(P0) = (Ψ1(P0), . . . , Ψp(P0). Further, deﬁne the Augmented Inverse Probability Weight
(AIPW) transform as

Ta(O; ¯Q0, g0) =

I(A = a)
g0(A, W )

(Y − ¯Q0(A, W )) + ¯Q0(a, W ),

(4)

and let ˜T (O; P0) = T1(O; ¯Q0, g0) − T0(O; ¯Q0, g0). Then, the efﬁcient inﬂuence function (EIF) of Ψj(P ) for P ∈ M
and j = 1, . . . , p is given by

EIFj(O; P ) ≡

(cid:16) ˜T (O; P ) − Ψj(P )Bj
EP

(cid:2)B2

(cid:3)

j

(cid:17)

Bj

.

(5)

4

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

Having established the conditions under which ΨF (PX ) can be estimated from the observed data, we now focus on
inference about Ψ(P0). The EIF of Equation (5) informs the construction of nonparametric efﬁcient estimators of
Ψj(P0) under non-restrictive assumptions about the data-generating process [Bickel et al., 1993, Hines et al., 2022b].
Many approaches exist for deriving these efﬁcient estimators, such as one-step estimation [Pfanzagl and Wefelmeyer,
1985, Bickel et al., 1993], estimating equations [van der Laan and Robins, 2003, Chernozhukov et al., 2017, 2018], or
targeted maximum likelihood estimation [van der Laan and Rubin, 2006, van der Laan and Rose, 2011, 2018]. We use
the, in this case, straightforward method of estimating equations. The resulting estimator is intuitive: it corresponds to
the estimator of the simple linear regression coefﬁcient of centered biomarker j regressed on the adjusted predicted
differences in potential outcomes. Further, it is identical to the one-step estimator.
Corollary 1. Let Pm be the empirical distribution of another dataset of m random observations distributed according
to P0 and distinct of Pn. If such a dataset is not available, it might be generated using sample-splitting techniques. We
require that the size of Pm grows linearly with the size of Pn. That is, O(m) = O(n). This is trivially accomplished
when using most sample-splitting frameworks, like K-fold cross-validation. Then deﬁne ¯Qm and gm as estimates of the
nuisance parameters ¯Q0 and g0 ﬁt to Pm. The estimating equation estimator of Ψj(P0) is then given by:

Ψ(ee)
j

(Pn; Pm) =

(cid:80)n

i=1

˜T (Oi; Pm)Bij
(cid:80)n

i=1 B2
ij

,

(6)

where we again assume that the biomarkers are centered such that (cid:80) Bij = 0. This estimator is double robust.

The double-robustness property signiﬁes that Ψ(ee)
(Pn; Pm) is a consistent estimator of Ψj(P0) so long as either the
estimator of the conditional expectation or the estimator of the propensity score are consistent. In particular, when g0 is
known, as in most clinical trials, it is guaranteed to be consistent.

j

Under the following conditions, we can detail this estimator’s limiting distribution.
(A3) Known treatment assignment mechanism: g0 is known.
(A4) Nuisance parameter estimator convergence: (cid:107) ¯Qm − ¯Q0(cid:107)2 (cid:107)gm − g0(cid:107)2 = oP (n−1/2), where (cid:107)·(cid:107)2 denotes the
L2(P0) norm.
Theorem 2. If A3 or A4 are satisﬁed and EP0[B2

j ] > 0 for j = 1, . . . , p, then

(cid:16)

√

n

Ψ(ee)
j

(Pn; Pm) − Ψj(P0)

(cid:17) D→ N (0, VP0 [EIFj(O; P0)]) .

(7)

Again, A3 is generally satisﬁed in clinical trials, implying that the estimating equation estimator of Equation (6) is
asymptotically linear. Valid hypothesis testing is possible even when the conditional outcome regression is biased. This
results from the form of the EIF, and is discussed in the proof (Section S1 of the Appendix).

In observational settings, A4 requires that the conditional outcome regression estimates and the treatment assignment
rule estimates converge in probability to their respective true parameters at a rate faster than n−1/4. When the number
of biomarkers and covariates is moderate relative to sample size, these conditions are typically satisﬁed by estimating
these parameters using ﬂexible machine learning algorithms [van der Laan and Rose, 2011] like the Super Learner of
van der Laan et al. [2007]. Relying on the general asymptotic theory of cross-validated loss-based estimation [van der
Laan and Dudoit, 2003], the Super Learner method constructs a convex combination of estimators from a pre-speciﬁed
library that minimizes the cross-validated risk of a pre-deﬁned loss function. Even in a high-dimensional setting where
the number of biomarkers is far larger than n, recent results about Random Forests [Wager and Athey, 2018] and deep
neural networks [Farrell et al., 2021] suggest conditions for which A4 is satisﬁed. Generally, fast convergence of these
estimators in high dimensions requires strong smoothness and sparsity assumptions about the underlying parameters
[Hines et al., 2022b].

Under A1, A2, and either A3 or A4, Theorem 2 delivers the means by which to construct α-level Wald-type conﬁdence
intervals for Ψj(P0). However, the estimator of Equation (6) and any accompanying testing procedure require that the
nuisance parameters be estimated on a separate dataset.

Since practitioners rarely have access to two datasets from the same data-generating process, we propose a cross-
validated estimator that uses all available data. Begin by randomly partitioning the n observations of Pn into K
independent validation sets P 1
n,K of approximately equal size. For k = 1, . . . , K, deﬁne the training set as,
in a slight abuse of notation, P 0

n,1, . . . , P 1
n,k = Pn \ P 1

Ψ(CV)
j

(Pn) =

n,k. Then the cross-validated estimator of Ψj(P0) is deﬁned as:
n,k) ˜T (Oi; P 0
n,k)B2
ij

i=1 I(Oi ∈ P 1

i=1 I(Oi ∈ P 1

n,k)Bij

K
(cid:88)

1
K

(cid:80)n

(cid:80)n

,

k=1

(8)

5

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

and has the same limiting distribution as Ψ(ee)
accompanying cross-validated estimator of the EIF’s standard deviation for biomarker j is given by

(Pn; Pm) under conditions consistent with those of either A3 or A3. The

j

σ(CV)
j

(Pn) =

(cid:32)

1
K

(cid:34)

K
(cid:88)

k=1

1
i=1 I(Oi ∈ P 1

n,k)

(cid:80)n

I(Oi ∈ P 1

n,k) (cid:0)EIF(Oi; P 0

n,k)(cid:1)2

(cid:35)(cid:33)1/2

.

n
(cid:88)

i=1

The α-level Wald-type conﬁdence intervals for Ψj(P0) are then constructed as

Ψ(CV)
j

(Pn) ±

z(1−α/2)σ(CV)

√

j
n

(Pn)

,

where z(1−α/2) is the (1 − α/2)th quantile of a standard Normal distribution. Inference about Ψj(P0) is therefore
made possible under non-restrictive assumptions about the data-generating process when using data-adaptive methods
and cross-validation to the estimate nuisance parameters. Even in small samples where the limiting properties of
Ψ(ee)
(Pn; Pm) might not be attained, the generalized variance moderation technique of Hejazi et al. [2017] can be used
j
for Type-I error control.

In summary, we take as target of inference the simple linear regression slopes of the difference of predicted outcomes
under treatment and control conditions regressed on each biomarker. We suggest that these parameters be estimated
by learning the conditional outcome regression and treatment assignment rule (if necessary), using them to predict
the potential outcomes, and then ﬁtting simple linear regressions to the difference in predicted potential outcomes as
a function of each centered biomarker. Under the conditions outlined in A1, A2, and A3 or A4, we prove that our
estimator targets the causal parameter of interest and is asymptotically linear, providing a straightforward statistical test
to assess whether a biomarker modiﬁes the treatment effect. Even when the causal inference conditions of A1 and A2
are not satisﬁed, Ψ(P0) remains an interpretable statistical parameter. It captures the strength of treatment-biomarker
interactions in high dimensions, and inference about it can be performed using the same cross-validated procedure.

4 Simulation Study

4.1 Details

This work is motivated by the need to identify predictive biomarkers in clinical trials. Of particular interest is their
detection for drug target discovery and diagnostic assay development. The former requires the identiﬁcation of
biomarkers causally related to the outcome of interest, whereas the latter seeks a small set of strongly predictive
biomarkers. We therefore focus on these applications throughout the simulation study.

A varied collection of data-generating processes, deﬁned below, are considered to demonstrate that the theoretical
guarantees outlined in the previous section are achieved for a range of functional forms of the conditional outcome
regression. Recall that Y corresponds to the outcome, A the treatment assignment, W the covariates, and B the
biomarkers, a subset of the covariates. The treatment assignment rules, g0, are treated as known.

• Class 1: Moderate dimensions, non-sparse treatment-biomarker effects vector with independent biomarkers

– Linear conditional outcome regression:

W = B ∼ N (0, I100×100)
A|W = A ∼ Bernoulli(1/2)

Y |A, W ∼ N

(cid:16)

W (cid:62) (cid:16)

β + I(A = 1)γ(1) + I(A = 0)γ(0)(cid:17)

(cid:17)

, 1/2

.

Here, β = (β1, . . . , β100)(cid:62) such that β1 = . . . = β20 = 2 and β21 = . . . = β100 = 0, and γ(a) =
(γ(a)
100 = 0 for
a = {0, 1}.

50 = −5 and γ(1)

100)(cid:62) where γ(1)

1 = . . . = γ(0)

1 = . . . = γ(1)

51 = . . . = γ(1)

50 = 5, γ(0)

1 , . . . , γ(a)

– Kinked conditional outcome regression: W and A are distributed as above. The conditional outcome is

deﬁned as

Y |A, W ∼ N (cid:0)W (cid:62) (I(A = 1)γ + I(A = 0) diag(I(W > 0)) γ) , 1/2(cid:1) ,

where γ = (γ1, . . . , γ100), γ1 = . . . = γ50 = 10, γ51 = . . . = γ100 = 0, and diag(·) is a diagonal matrix
whose diagonal equals the input vector.

6

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

– Nonlinear conditional outcome regression: W and A are distributed as above. Then,

Y |A, W ∼ N (cid:0)exp (cid:8)|W (cid:62)β|(cid:9) + I(A = 1)W (cid:62)γ, 1/2(cid:1) ,

where β1 = . . . = β20 = 1 and β21 = . . . = β100 = 0, and where γ1 = . . . = γ50 = 5 and
γ51 = . . . = γ100 = 0.

• Class 2: High dimensions, sparse treatment-biomarker effects vector with correlated biomarkers

– Linear conditional outcome regression:

C ∼ Bernoulli(1/2)

W |C = B|C ∼ N (−I(C = 0) + I(C = 1), Σ500×500)

A|W = A ∼ Bernoulli(1/2)

Y |A, W ∼ N (cid:0)W (cid:62) (β + I(A = 1)γ) , 1/2(cid:1)

Here, C is an unobserved subgroup indicator, β = (2, 2, 2, 2, 2, 0, . . . , 0), and γ = (5, 5, 5, 5, 0, . . . , 0).
The biomarker covariance matrix, Σ, is the estimated gene expression correlation matrix of the 500 most
variable genes taken from the tumours of patients with metastatic or recurrent colorectal cancer [Watanabe
et al., 2011]. These genes were ﬁrst clustered using hierarchical clustering based on their Euclidean
distance with complete linkage, and the correlation matrix was then estimated using the cross-validated
estimation procedure of Boileau et al. [2021a] implemented in the cvCovEst R package [Boileau et al.,
2021b, R Core Team, 2022], relying on the banding and tapering estimators of Bickel and Levina [2008]
and Cai et al. [2010], respectively. The gene expression data has been made available by the Bioconductor
[Huber et al., 2015] experiment package curatedCRCdata [Parsana et al., 2021].

– Kinked conditional outcome regression: C, W and A are distributed as above. The conditional outcome

distribution is as follows:

Y |A, W ∼ N (cid:0)W (cid:62) (I(A = 1)γ + I(A = 0) diag(I(W > 0)) γ) , 1/2(cid:1) ,

where γ = (10, 10, 10, 10, 0, . . . , 0).

– Nonlinear conditional outcome regression: C, W and A are distributed as above. Then,

Y |A, W ∼ N (cid:0)exp (cid:8)|W (cid:62)β|(cid:9) + I(A = 1)W (cid:62)γ, 1/2(cid:1) ,

where β = (1, 1, 1, 1, 1, 0, . . . , 0) and γ = (5, 5, 5, 5, 0, . . . , 0).

The ﬁrst class of data-generating processes reﬂects the scenario in which a set of biomarkers known to be associated with
the outcome, perhaps based on prior clinical or biological investigations, are assessed for potential treatment-biomarker
interactions. Since they have been cherry-picked, a reasonable assumption is that a non-negligible proportion of these
biomarkers modify the effect of treatment on the outcome of interest. The second set of data-generating processes is
representative of exploratory scenarios wherein a vast number of biomarkers, like tumor gene expression data collected
prior to the start of treatment, are explored for strong effect modiﬁcation. Further, these data-generating processes
contain two subgroups, representing, for example, unknown patient subpopulations in a clinical trial. These models
each possess four non-zero treatment-biomarker interactions in the leading entries of γ or γ(0) and γ(1). The biomarkers
that modify the treatment effect are correlated mimicking a small gene set.

The collections of moderate and high-dimensional data-generating processes each contain three outcome regression
models. Their sketches are provided in Figure 1. The simplest “linear” models correspond to the functional form
assumed by many existing high-dimensional CATE estimation procedures for a continuous outcome [Tian et al., 2014,
Chen et al., 2017, Zhao et al., 2018, Ning et al., 2020]. The “kinked” data-generating processes are named so for
the kink in the marginal conditional outcome regression of its predictive biomarkers. These marginal relationships
are representative of predictive biomarkers in clinical trials assessing the efﬁcacy of the standard of care against
combinations of the standard of care and another drug, and where the treatment group outperforms the control group in
all biomarker deﬁned subpopulations, but with different treatment effect sizes. Finally, the “nonlinear” data-generating
mechanisms represent those whose conditional outcome regressions deviate most from assumptions of linearity. We
expect these to pose the greatest challenge with respect to identifying predictive biomarkers. We note that the linear
conditional outcome regression models are not identiﬁable, but this is not a concern for generative purposes.

Two hundred datasets of 125, 250, and 500 observations were generated for each of these data-generating processes —
3,600 in all — by sampling without replacement from simulated populations of 100,000 observations. Each model’s
Ψ(P0) was computed from its respective population. These random samples and estimands are used in the following

7

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

Figure 1: Sketches of predictive biomarkers’ marginal relationships with the outcome variable for the considered
conditional outcome regression models.

subsections to assess the ﬁnite sample performance of our proposed procedure and to benchmark its ability to discover
predictive biomarkers against that of popular CATE estimation methods.

The cross-validated estimator of Equation (8) is used to estimate the vector of univariate CATE simple linear regression
coefﬁcients in the simulated datasets using 5-fold cross-validation. Throughout the remainder of the text, we refer
to our proposed method as uniCATE. van der Laan et al. [2007]’s Super Learner procedure is used to estimate the
conditional outcome regressions. The library of candidate algorithms is made up of ordinary linear, LASSO, and elastic
net regressions [Tibshirani, 1996, Zou and Hastie, 2005], polynomial splines [Stone et al., 1997], XGboost [Chen and
Guestrin, 2016], Random Forests [Breiman, 2001], and the mean model.

4.2 Bias and Variance of Univariate CATE Estimator

The theoretical results of Section 3 are asymptotic, yet many clinical trials are made up of a small to moderate numbers
of participants. We therefore verify that uniCATE’s estimates, metrics of biomarkers’ predictive importance, are accurate
when computed under realistic sample sizes. We computed the empirical bias and variance of the cross-validated
estimator when applied to each data-generating process and at each simulated sample size. The results of our analysis
of the nonlinear models are presented in Figure 2. Those of the linear and kinked models, presented in Figures S1 and
S2, respectively, are virtually identical.

We ﬁnd that uniCATE is approximately unbiased across sample sizes regardless of the conditional outcome regressions’
complexities, as suggested by Theorem 2. However, the estimator is highly variable in the moderate dimension,
non-sparse (e.g. Figure 2A) scenarios when n = 125 and 250, and somewhat variable when n = 125 in the high
dimension, sparse data-generating processes (e.g. Figure 2B). As expected, the empirical variance of the estimator
decreases drastically in all simulation settings as sample sizes increase.

This is encouraging for diagnostic biomarker assay development: the ranking of predictive biomarkers reported by
uniCATE is reliable under realistic sample sizes and data-generating processes. These results suggest that our method
accurately and precisely evaluates biomarkers with respect to their predictive abilities when the number of truly
predictive biomarkers is small in samples possessing as few as 250 observations. Similar behavior is observed when
there are a large number of predictive biomarkers in trials of 500 subjects or more.

4.3 Type-I Error Control

In addition to evaluating the accuracy of uniCATE’s estimates, we assess the method’s ability to distinguish predictive
biomarkers from non-predictive biomarkers. This is of particular importance in applications requiring the reduction
of the pool of potential predictive biomarkers, as in the development of diagnostic assays, or generating hypotheses
for biological and clinical validation in drug target discovery. We therefore evaluate uniCATE’s Type-I error rate
control across the simulation scenarios using a target FDR [Benjamini and Hochberg, 1995] of 5%. The inferential
procedure described in Section 3 is used to test whether predictive biomarkers’ linear approximations of the univariate
CATE are signiﬁcantly different from zero. Nominal p-values are adjusted using the FDR-controlling procedure of
Benjamini and Hochberg [1995]. We note that nominal FDR control is not guaranteed by this adjustment method in the
high-dimensional simulations because of the biomarkers’ correlation structure. The results are presented in Figure 3.

Our method’s capacity to identify predictive biomarkers was compared to that of popular CATE estimation methods:
the modiﬁed covariates approach and its augmented counterpart [Tian et al., 2014, Chen et al., 2017]. Brieﬂy, the
former directly estimates the linear model coefﬁcients of the treatment-biomarker interactions, using a linear working

8

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

Figure 2: The empirical biases and variances of uniCATE estimates for all biomarkers across all simulation scenarios
with a nonlinear conditional outcome regression. Biomarkers colored blue are truly predictive, and those colored gold
are nonpredictive.

model for these terms, without having to model or estimate the main effects. While Tian et al. [2014]’s method is
ﬂexible since it avoids making any assumptions about the functional form of the main biomarker effects, it can lack
precision in small-sample, high-dimensional settings. Tian et al. [2014] and Chen et al. [2017] therefore proposed
“augmented” versions of this method that explicitly account for this source of variation. While Tian et al.’s [2014] and
Chen et al.’s [2017] augmentation procedures differ, they are identical in the randomized control trials with continuous
outcome variables [Chen et al., 2017]: they are equivalent to ﬁtting a (penalized) multivariate linear regression with
treatment-biomarker interaction terms.

We again emphasize that these methods are not true competitors of our procedure. Their primary goal, CATE
estimation, differs from that of uniCATE. However, Tian et al. [2014] and Chen et al. [2017] demonstrated that the
(augmented) modiﬁed covariates approach could identify potentially predictive biomarkers when ﬁt using regularized
linear regressions like the LASSO. Biomarkers with non-zero treatment-biomarker interaction coefﬁcient estimates are
classiﬁed as predictive. We therefore applied these approaches, using 10-fold cross-validation to select the LASSO
hyperparameters, to all simulated datasets. The implementations of these estimators provided by the personalized R
software package [Huling and Yu, 2021] was used.

The results pertaining to the moderate dimension simulations (p = 100) with 50 predictive biomarkers are presented in
Figure 3A. Only uniCATE is capable of controlling the Type-I error rate; it approximately achieves the nominal FDR of
5% in all settings with samples sizes of 250 and above. The modiﬁed covariates approach and its augmented counterpart
possess FDRs no lower than 25% across all scenarios. Indeed, their control of Type-I error generally worsens as sample
size increases. Our method’s superior performance with respect to FDR control is likely due to its conservativeness:
many of the predictive biomarkers are not recognized in smaller sample-size settings. As sample size grows, however,
so too does its true positive rate (TPR) while maintaining a near perfect true negative rate (TNR). When n = 500,
uniCATE generally identiﬁes close to or more predictive biomarkers than the modiﬁed covariates approach, and nearly
as many as the augmented modiﬁed covariates method.

Our procedure’s performance with respect to FDR control is again superior to that of the CATE estimation approaches
in the high dimensional simulation scenarios with 500 biomarkers (Figure 3B). While the adjustment procedure of
Benjamini and Hochberg [1995] does not guarantee FDR control at the desired rate in these scenarios due to the
correlation structure of the tests, it is nearly achieved in larger sample sizes. uniCATE also marginally outperforms

9

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

Figure 3: The empirical predictive biomarker classiﬁcation results for the moderate dimensions, non-sparse treatment-
biomarker interaction settings with uncorrelated biomarkers (A) and the high-dimension, sparse treatment-biomarker
interaction settings with correlated biomarkers(B).

other approaches in terms of the TNR. Unlike in the moderate sample-size simulations, however, our method identiﬁes
predictive biomarkers more efﬁciently than the other procedures considered.

These results demonstrate that uniCATE recovers truly predictive biomarkers more reliably than interpretable treatment
rule estimators. In most simulation scenarios, uniCATE provides well controlled Type-I error rates while its TNR and
TPR are comparable or superior to other methods. However, when the number of truly predictive biomarkers is large
and the sample size small, uniCATE’s biomarker classiﬁcation will be conservative. In this setting, our method still
provides good Type-I error control, limiting the waste of resources on the investigation of false positives, as would be
the result if using existing methods. If the investigator prefers a less conservative approach, since, for example, the cost
of follow-up experiments is low, the (augmented) modiﬁed covariate approach may be considered instead.

5 Application to IMmotion Trials

Until recently, Tyrosine kinase inhibitors targeting vascular endothelial growth factor (VEGF) were the standard of
care for patients with metastatic renal cell carcinoma (mRCC) [Rini et al., 2019]. Unfortunately, many patients with
mRCC ﬁnd these treatments, like sunitinib, ineffective, and most develop a resistance over time [Rini and Atkins, 2009].
Immune checkpoint inhibitors like atezolizumab can produce more durable results and improve overall survival in
pre-treated patients with mRCC [Motzer et al., 2015a,b, McDermott et al., 2018]. A combination of atezolizumab and
bevacizumab, the latter of which also binds to VEGF, was shown to improve the objective response rate (ORR) in
a Phase 1b study [Wallin et al., 2016]. Objective response is a binary indicator of clinically meaningful response to
treatment. These ﬁndings were supported by a Phase 2 study, IMmotion 150, which compared atezolizumab alone and
in combination with bevacizumab against sunitinib [McDermott et al., 2018]. In a subsequent Phase 3 study, IMmotion
151 [Rini et al., 2019], the atezolizumab and bevacizumab combination improved progression free survival and objective

10

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

Figure 4: Heatmaps of the modiﬁed covariates approach’s (A), augmented modiﬁed covariates approach’s (B), and
uniCATE procedure’s (C) predictive biomarkers’ log-transformed gene expression data from the IMmotion151 trial.
Rows and columns are ordered via hierarchical clustering with complete linkage and Euclidean distance.

response over sunitinib in patients whose cancer cells expressed the programmed death-1 ligand 1 (PD-L1), but not
all of these patients showed beneﬁt. These results motivate the search for biomarkers that are more predictive of this
treatment’s clinical beneﬁt than PD-L1 expression.

Potentially predictive biomarkers were found by applying uniCATE to subsets of the sunitinib (n = 71) and
atezolizumab-bevacizumab (n = 77) treatment arms of the IMmotion 150 trial. Only patients with pre-treatment tumor
RNA-seq samples were included. The 500 most variable genes based on this log-transformed RNA-seq data comprised
the collection of potentially predictive biomarkers. Details of the gene expression data collection and preparation have
previously been described by McDermott et al. [2018]. Objective response was used as the outcome variable. The
conditional outcome regression model was ﬁt with a Super Learner whose library contained (penalized) GLMs with
treatment-biomarker interaction terms, XGboost models, Random Forest models, and the mean model. A nominal FDR
cutoff of 5% was employed. The modiﬁed covariates and augmented modiﬁed covariates approach for binary outcomes
of Tian et al. [2014] were also applied to these data.

The uniCATE method identiﬁed 92 genes as predictive biomarkers, whereas the modiﬁed covariates approach and
its augmented counterpart identiﬁed 20 and 6, respectively. All results are listed in Table S1. That the approaches of
Tian et al. [2014] are more conservative than ours is a reversal of Section 4’s simulation results, but may be explained
by the more complex correlation structure of these data. Indeed, the former rely on sparse linear models which are
known to select but a few features from any given highly correlated set. Our procedure, however, uncovers sets of
correlated predictive biomarkers since their individual hypothesis testing results will also be associated. This property
is desirable when analyzing genomic data as large gene sets permit more thorough biological exploration and improved
interpretation than do single, uncorrelated genes [Subramanian et al., 2005]. The reporting of gene sets also improves
the reproducibility of ﬁndings [Subramanian et al., 2005].

We performed a gene set enrichment analysis (GSEA) of gene ontology (GO) terms with uniCATE’s 92 predictive
biomarkers using MSigDB [Subramanian et al., 2005, Liberzon et al., 2011]. The top results are presented in Table S2.
We found that these genes are generally associated with immune responses, including those mediated by B cells and
lymphocytes. Similar ﬁndings have been reported by Au et al. [2021] in the context of clear cell renal cell carcinoma
patients’ therapeutic responses to nivolumab, another immune checkpoint inhibitor.

Now, having learned of potentially predictive biomarkers, we assessed how well they delineate patient sub-populations
in the IMmotion 151 study. This study’s subjects are believed to be drawn from the same population as those enrolled
in IMmotion 150. Eight hundred and ten subjects possessed baseline tumor gene expression data for the 500 genes
considered in our IMmotion 150 analysis: 406 in the atezolizumab-bevacizumab combination arm, and 404 in the
sunitinib arm. Figure 4 presents the heatmaps of log-transformed gene expression data for each methods’ set of
predictive genes. Subgroups are easily discerned in uniCATE’s heatmap, but not so much in the other procedures’. This

11

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

Figure 5: Comparison of the ORR across the methods’ predicted subgroups in the IMmotion151 trial. The hierarchical
clustering with complete linkage and Euclidean distance applied to uniCATE’s predictive biomarkers was used to
iteratively deﬁne two, three, and four clusters (K). The points are slightly horizontally jittered along the x-axis to avoid
overplotting.

further emphasizes the beneﬁts of uniCATE’s capacity to identify sets of correlated predictive biomarkers. Note that the
most prominent cluster of patients in the modiﬁed covariates method’s heatmap is driven by the XIST gene. It is not
selected by the augmented modiﬁed covariates procedure or uniCATE. Upon further inspection, it does not appear to
have a strong predictive effect (Figure S3).

It is unclear from these heatmaps alone whether these subgroups correspond to clusters of patients that beneﬁt more
from one therapy than another. We therefore established subgroups by performing hierarchical clustering with complete
linkage using Euclidean distance on the methods’ selections of IMmotion 151’s log-transformed gene expression data.
The difference in ORR was then computed between patients receiving the atezolizumab-bevacizumab combination and
the sunitinib regiment within each of these subgroups. The subgroups identiﬁed by the (augmented) modiﬁed covariates
methods’ biomarkers had negligible differences in ORR (not shown). Instead, we used their estimated treatment rules
to predict whether each patient would beneﬁt more from the atezolizumab-bevacizumab combination or sunitinib, and
then computed the difference in ORR within these groups. The ﬁndings are presented in Figure 5.

Figure 5 evaluates the patient populations classiﬁed by each method. When classifying patients into subgroups, the
modiﬁed covariates approach and the augmented modiﬁed covariates approach subset patients into two groups. Ideally,
one of the patient groups should produce a large, positive ORR difference representing an increased beneﬁt from the
novel drug combination. Figure 5 shows that when two patient groups are of interest, uniCATE’s biomarkers-deﬁned
subgroups are comparable to the groups identiﬁed by the other two methods in terms of the effect size and the group
size. The unsupervised clustering approach used in uniCATE also permits the deﬁnition of multiple clusters, providing a
more reﬁned investigation of patient sub-populations. When considering three or four clusters (K = 3, 4), one subgroup
is found to respond much better on average to the atezolizumab-bevacizumab combination than to sunitinib. This
difference in ORR is greater than that of any subgroup deﬁned using treatment assignment rules.

These results suggest that uniCATE uncovered biomarkers that inﬂuence whether mRCC patients are more likely
to respond to tyrosyne kinase inhibitors alone or in combination with immune checkpoint inhibitors. More work is
necessary to validate these ﬁndings, and to determine whether these biomarkers could form the basis of assays that
inform treatment decisions. Demonstrating that these biomarkers are predictive of other clinical endpoints, like overall
survival, progression-free survival and safety, would make for compelling evidence. Recovering these biomarkers in a
comparison of this drug combination to the current standard of care would be more convincing still.

6 Discussion

In this work, we demonstrate how predictive biomarker discovery, typically a byproduct of treatment rule estimation, is
better addressed as a standalone variable importance estimation problem. We derive a novel nonparametric estimator
for a causal parameter which we argue is generally useful and interpretable, and show that this estimator is consistent
and asymptotically linear under non-restrictive assumptions. We then verify that our proposed procedure’s asymptotic
guarantees are approximately achieved across diverse data-generating distributions in a thorough simulation study of

12

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

moderate to high-dimensional randomized control trials. Our method is then used in an exploratory analysis of real
clinical trial data, producing biologically meaningful results that identify patient subgroups with greater treatment effect
heterogeneity than procedures not explicitly developed for predictive biomarker discovery.

While we derive theory for uniCATE’s application to observational data, we benchmarked it exclusively in randomized
control trial settings since they constitutes our primary application area of interest. Evaluating our method in quasi-
experimental settings, however, offers an interesting avenue of future research. Subsequent work may also explore
analogous (causal) variable importance parameters based on, for example, the relative CATE, or adapt the univariate
CATE for time-to-event outcomes. The study of other non and semiparametric estimators of these parameters, such
as one-step estimators or targeted maximum likelihood estimators, might also prove fruitful. Finally, future work
might assess whether treatment effect variable importance parameter inference procedures could be coupled with novel
multiple testing adjustment approaches, like that of Fithian and Lei [2020], to better account for the complex correlation
structures often found among biomarkers.

Software

The uniCATE method is implemented in the open-source uniCATE R software package at github.com/
insightsengineering/uniCATE. Internally, it relies on the cross-validated framework of the origami R pack-
age [Coyle and Hejazi, 2018] and on Super Learning framework of the sl3 R package [Coyle et al., 2021]. Version
0.1.0 of uniCATE was used to produce the results presented in Sections 4 and 5.

Reproducibility and Data Availability

Code to reproduce the simulation study of Section 4 and the analysis of Section 5 is available at github.com/
PhilBoileau/pub_uniCATE.

The clinical trial data are available on the clinical study data request platform (https://vivli.org/). The IMmo-
tion150 clinical data was from data cutoff date of Oct 17, 2016. The IMmotion151 clinical data was from data cutoff
date of Dec 3, 2019. For overall response rate (ORR) calculation in both studies, a responder is deﬁned as patients with
their best conﬁrmed overall response by investigator of Complete Response (CR) or Partial Response (PR) per RECIST
v1.1, and non-responder otherwise.

The RNAseq data are available at: https://ega-archive.org/datasets/EGAD00001004183 and https://
ega-archive.org/datasets/EGAD00001006618 The RNA-seq data was processed by removing patients with
missing baseline samples, and were transferred to log10(CPM+1). In total of 22,997 genes were included whose median
log10(CPM+1) is larger than 0.01.

Acknowledgement

PB gratefully acknowledges the support of the Fonds de recherche du Québec - Nature et technologies and the Natural
Sciences and Engineering Research Council of Canada. The authors thank James Duncan and Dr. Nima Hejazi for
helpful discussions about the methodology, and Dr. Romain Banchereau and Dr. Zoe Assaf for helpful discussions
about the analysis presented in Section 5. The authors would also like to thank Molly He for preliminary simulation
results that prompted this project. Conﬂicts of interest: none declared.

Appendix

S1 Proofs

Theorem 1: Identiﬁcation and efﬁcient inﬂuence function.

Proof. Standard results ensure that ΨF (PX ) is identiﬁed by Ψ(P0): By the law of double expectation, we ﬁnd that
EPX [Y (a)Bj] = EPX [EPX [Y (a)|W ]Bj], and by A1, A2 that EPX [Y (a)|W ] = ¯Q0(a, W ). We follow the general
guidelines in the review of Hines et al. [2022b] to derive the EIF of Ψj(P0). Deﬁne the ﬁxed distribution P whose
support is contained in the support of P0. We deﬁne the parametric submodel of P0 for t ∈ [0, 1] as

Pt = tP + (1 − t)P0.

13

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

d
dt

d
dt

d
dt

Then,

EIFj(O, P0) =

=

=

=

=

(cid:12)
(cid:12)
Ψj(Pt)
(cid:12)
(cid:12)t=0

EPt

(cid:8)EPt

(cid:2)(cid:0) ¯Qt(1, W ) − ¯Qt(0, W )(cid:1) Bj
(cid:2)B2
(cid:2)(cid:0) ¯Qt(1, W ) − ¯Qt(0, W )(cid:1) Bj

EPt

(cid:3)

(cid:3)

j

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)t=0
(cid:3)(cid:9) EPt

(cid:2)(cid:0) ¯Qt(1, W ) − ¯Qt(0, W )(cid:1) Bj

(cid:3) − EPt
(cid:3)2
(cid:2)B2

(cid:2)B2
j
EPt
(cid:2)(cid:0) ¯Q0(1, W ) − ¯Q0(0, W )(cid:1) Bj

j

(cid:3)(cid:17)

EP0

(cid:3)

(cid:2)B2

j

(cid:3) d
dt

(cid:8)EPt

(cid:2)B2

j

(cid:3)(cid:9)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)t=0

1
(cid:2)B2

j

(cid:3)2

EP0

(cid:16)(cid:16) ˜T (O, P0)Bj − EP0

−EP0
(cid:16) ˜T (O, P0) − Ψj(P0)Bj
EP0

(cid:2)B2

(cid:3)

j

(cid:2)(cid:0) ¯Q0(1, W ) − ¯Q0(0, W )(cid:1) Bj
(cid:17)

Bj

(cid:3) (cid:0)B2

j − EP0

(cid:2)B2

j

(cid:3)(cid:1)(cid:1)

Corollary 1: Estimating equation estimator derivation and double robustness.

Proof. The estimating equation estimator for the jth biomarker is given by:

n
(cid:88)

0 =

EIF(Oi; Pm)

=

=⇒ Ψ(ee)

j

(Pn; Pm) =

(cid:17)

Bij

i=1
(cid:80)n

i=1

(cid:80)n

i=1

(cid:80)n

(cid:16) ˜T (Oi; Pm) − ΨBij
i=1 B2
ij
˜T (Oi; Pm)Bij
(cid:80)n

.

i=1 B2
ij

Then, by the Weak Law of Large Numbers,

Ψ(ee)
j

(Pn; Pm) − Ψj(P0) →

EP0

j

(cid:105)

−

(cid:104) ˜T (O; Pm)Bj
(cid:2)B2
(cid:3)
EP0
(cid:18) g0(1, W )
gm(1, W )
(cid:18) g0(0, W )
gm(0, W )

−Bj

(cid:20)
Bj

(cid:19)

− 1

EP0

(cid:2)(cid:0) ¯Q0(1, W ) − ¯Q0(0, W )(cid:1) Bj
(cid:2)B2

(cid:3)

EP0

j

(cid:3)

(cid:0) ¯Q0(1, W ) − ¯Qm(1, W )(cid:1)
(cid:19)

(cid:0) ¯Q0(0, W ) − ¯Qm(0, W )(cid:1)

(cid:21)

.

− 1

∝ EP0

If gm = g0, then this estimator is consistent. The same is true if either (cid:107)gm − g0(cid:107)2,P0 = oP (1) or (cid:107) ¯Qm − ¯Q0(cid:107)2,P0 =
oP (1).

Theorem 2: Limiting distribution of the estimating equation estimator.

Proof. Deﬁne the plug-in estimator for the univariate CATE of biomarker j with nuisance parameters estimate using
Pm as Ψj(Pn; Pm). Then we have through the von Mises expansion of Ψj(·) about P0 that

√

n (Ψj(Pn; Pm) − Ψj(P0)) =

+

n
(cid:88)

EIF(O; P0) −

1
1
√
√
n
n
n (EPn − EP0 ) [EIF(O; Pm) − EIF(O; P0)] −

EIF(O; Pm)

i=1

i=1

√

n
(cid:88)

√

nR(P0, Pm).

(S1)

14

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

The ﬁrst term is the sum of mean-zero random variables, and so it converges to a Normal with variance equal to that
of the EIF, scaled by n, as n → ∞. The second term is the bias term that is accounted for by the estimating equation
estimator Ψ(ee)
(Pn; Pm). The third and fourth terms are the empirical process and remainder terms, respectively, and
we must show that they converge to zero in probability.

j

The analysis of empirical process term is identical to that of the average treatment effect presented in Zheng and van der
Laan [2011] due to the similarity of these parameters. Essentially, so long as the conditional outcome regression and
propensity score estimators converge in probability to some function under the L2 norm, the empirical process term is
bounded in probability.

We now study the remainder term:

−R(P0, Pm) =

EP0

=

=

=

EP0

EP0

EP0

j

1
(cid:2)B2
1
(cid:2)B2
1
(cid:2)B2

j

j

(cid:105)

(cid:17)

(cid:104)(cid:16) ˜T (O; Pm) − Ψ(Pm)Bj
EP0
(cid:104) ˜T (O; Pm)Bj − EP0

(cid:2)B2

EP0

Bj

(cid:3)

j

(cid:3)

+ (Ψj(Pm) − Ψj(P0))

(cid:2)B2

j

(cid:3) Ψj(P0)

(cid:105)

EP0

(cid:3)

(cid:2)Bj

(cid:0)T1(O; Pm) − ¯Q0(1, W ) − T0(O; Pm) + ¯Q0(0, W )(cid:1)(cid:3)

(cid:20)
Bj

EP0

(cid:3)

(cid:19)

− 1

(cid:0) ¯Q0(1, W ) − ¯Qm(1, W )(cid:1)

1
(cid:2)B2

j

(cid:3)

(cid:18)(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:20)

EP0

≤

EP0

(cid:19)

− 1

(cid:19)

− 1

(cid:0) ¯Q0(0, W ) − ¯Qm(0, W )(cid:1)

(cid:21)

(cid:0) ¯Q0(1, W ) − ¯Qm(1, W )(cid:1)

(cid:21)(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:18) g0(0, W )
gm(0, W )

(cid:19)

− 1

(cid:0) ¯Q0(0, W ) − ¯Qm(0, W )(cid:1)

(cid:19)

(cid:21)(cid:12)
(cid:12)
(cid:12)
(cid:12)

−Bj

(cid:18) g0(1, W )
gm(1, W )
(cid:18) g0(0, W )
gm(0, W )
(cid:18) g0(1, W )
gm(1, W )
(cid:20)
Bj

EP0

Bj

(cid:12)
(cid:12)
(cid:12)
(cid:12)

+

(cid:34)

B2
j

≤

EP0

1
(cid:2)B2

j

(cid:3)


EP0

(cid:18) g0(1, W ) − gm(1, W )
gn(1, W )

(cid:19)2(cid:35)1/2

EP0

(cid:104)(cid:0) ¯Q0(1, W ) − ¯Qm(1, W )(cid:1)2(cid:105)1/2

(cid:34)

+ EP0

B2
j

(cid:18) g0(1, W ) − gm(1, W )
gm(0, W )

(cid:19)2(cid:35)1/2

EP0

(cid:104)(cid:0) ¯Q0(0, W ) − ¯Qm(0, W )(cid:1)2(cid:105)1/2





(S2)

If g0 is known, as in a randomized control trial, then the remainder term is exactly zero. When neither g0 or ¯Q0 is now
known, then the remainder term of Equation (S1) is oP (1) under the conditions of A4. The conditions on convergence
rates can be relaxed even further: The remainder term converges to zero in probability so long as the last line of
Equation (S2) is oP (n−1/2). That is, we may obtain our desired result even if, say, ¯Qm converges at slower rate to ¯Q0
than n−1/4 in probability so long as gm converges more quickly to g0.

S2 Additional Simulation Results

15

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

Figure S1: The empirical biases and variances of uniCATE estimates for all biomarkers across all simulation scenarios
with a linear conditional outcome regression. Biomarkers coloured blue are truly predictive and those coloured gold are
nonpredictive.

16

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

Figure S2: The empirical biases and variances of uniCATE estimates for all biomarkers across all simulation scenarios
with a kinked conditional outcome regression. Biomarkers coloured blue are truly predictive and those coloured gold
are nonpredictive.

17

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

S3 Supporting Results from Application to IMmotion Trials

Method

Modiﬁed Covariates

Augmented Modiﬁed Co-
variates

uniCATE

Predictive Biomarkers
ADCY8, CDH17, COL6A6, CSMD3, CXCL5, EEF1A2, GJB6, GRIA4,
H19, IGKV1-9, KLK4, MMP3, MUC17, PZP, TCHH, TEX15, TRIM63,
VIL1, WFIKKN2, XIST

EEF1A2, IGKV1-9, MMP3, PZP, TEX15, TRIM63

WFIKKN2, NMRK2, KLK1, TRIM63, IGKV1-9, HHATL, UCHL1,
CLDN1, EEF1A2, C8A, KCNJ3, ITIH2, IGLV3-21, TCHH, ATP1A3,
IGLL5, ENPP3, IGKV3-15, IGLC3, SAA1, TEX15, IGKV1-16, IGKV1-5,
IGHG1, GRIN2A, IGHV2-5, SERPIND1, IGHV1-18, DEFB1, CYP2J2,
IGHV1-24, CES3, IGKV3-11, IGLV1-40, IGHV1-2, SLC17A4, KLK4,
MMP7, ANKRD36BP2, IGHV3-11, IGHV4-31, IGHV4-34, IGLV3-19,
HAMP, CSMD3, PDZK1IP1, IGHG3, MUC17, ALPK2, IGLV2-14, FRAS1,
DNAH11, IGHGP, SAA2, BMPER, IGLV1-47, MMP3, FOSB, HPD,
SYT13, IGHV4-59, SLC38A5, IGHA1, CYP2C9, IGKC, IGLC2, PGF,
IGHV3-21, H19, FCRL5, PVALB, IGHV3-74, SLC6A3, IGHV1-46, IGLV2-
23, IGLV3-1, HBA1, IGLV1-44, IGKV3-20, IGKV4-1, LAMA1, IGHV3-48,
IGHV5-51, IGHG2, HBA2, KNG1, IGKV1-27, IGHM, IGLV2-11, FGL1,
CYP4F22, IGLV1-51

Table S1: The list of genes classiﬁed as predictive biomarkers by the considered methods.

18

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

-
q
R
D
F

e
u
l
a
v

e
u
l
a
v
-
p

K
/
k

s
e
n
e
G

-
r
e
v
nO

i

p
a
l

)
k
(

n
o
i
t
p
i
r
c
s
e
D

t
e
S

)

K

(

n
i

s
e
n
e
G

e
m
a
N

t
e
S
e
n
e
G

k
n
a
R

0

0

0

0

0

0

0

0

0

0

0

0

0

0

-
i
t
n
e
d
i

o
w

t

f
o

d
e
s
o
p
m
o
c

s
i

m
r
o
f

l
a
c
i
n
o
n
a
c

s
t
i

n
i

t
a
h
t

x
e
l
p
m
o
c

n
i
e
t
o
r
p
A

t
h
g
i
l
n
i
l
u
b
o
l
g
o
n
u
m
m

i

l
a
c
i
t
n
e
d
i
o
w

t
d
n
a

s
n
i
a
h
c
y
v
a
e
h
n
i
l
u
b
o
l
g
o
n
u
m
m

i

l
a
c

h
t
i

w
d
e
x
e
l
p
m
o
c

s
e
m

i
t
e
m
o
s

d
n
a

s
d
n
o
b

e
d
ﬁ
l
u
s
i
d

y
b

r
e
h
t
e
g
o
t

d
l
e
h

,
s
n
i
a
h
c

4
2
0

.

7
3

e
h
t
n
i

d
e
d
d
e
b
m
e

e
b
y
a
m
x
e
l
p
m
o
c

n
i
l
u
b
o
l
g
o
n
u
m
m

i
n
A

.
s
n
i
e
t
o
r
p
l
a
n
o
i
t
i
d
d
a

7
5
1

X
E
L
P
M
O
C
_
N
I
L
U
B
O
L
G
O
N
U
M
M
I
_
C
C
O
G

t
n
e
m
e
l
p
m
o
c

e
h
t

f
o

s
p
e
t
s

e
h
t

f
o

y
n
a

f
o

n
o
i
t
a
v
i
t
c
a

e
h
t

n
i

d
e
v
l
o
v
n
i

s
s
e
c
o
r
p

y
n
A

f
o

l
a
s
o
p
s
i
d

e
h
t

,
s
e
b
o
r
c
i
m

f
o

g
n
i
l
l
i
k

t
c
e
r
i
d

e
h
t

r
o
f

s
w
o
l
l
a

h
c
i
h
w

,
e
d
a
c
s
a
c

l
a
i
t
i
n
i

e
h
t

;
s
e
s
s
e
c
o
r
p
e
n
u
m
m

i

r
e
h
t
o
f
o
n
o
i
t
a
l
u
g
e
r

e
h
t
d
n
a

,
s
e
x
e
l
p
m
o
c

e
n
u
m
m

i

]
9
4
1
5
3
7
1
8
7
0
:
N
B
S
I

s
a
e
r
a

l
a
s
o
c
u
m
n
i

,
e
c
a
p
s

r
a
l
u
l
l
e
c
a
r
t
x
e

e
h
t

n
i

t
n
e
s
e
r
p

r
o

e
n
a
r
b
m
e
m
a
m

s
a
l
p

,
l
j
:

C
O
G

,

d
d
a
:
C
O
G

[

.
h
p
m
y
l

r
o

d
o
o
l
b

e
h
t

n
i

g
n
i
t
a
l
u
c
r
i
c

r
o

,
s
e
u
s
s
i
t

r
e
h
t
o

r
o

]
6
9
1
5
6
7
1
8
7
0
:
N
B
S
I

4
2
0

.

6
3

,

d
d
a
:
C
O
G

,

2
2
0
0
0
0
0
:
F
E
R
_
O
G

[

.
s
u
l
u
c
s
u
m

s
u
M
n
i

d
n
u
o
f

s
i

s
s
e
c
o
r
p

s
i
h
t

f
o

9
4
1

-
T
A
L
U
C
R
C
_

I

e
l
p
m
a
x
e
n
A

.
n
i
l
u
b
o
l
g
o
n
u
m
m

i
d
e
t
e
r
c
e
s
n
o
p
u
t
n
e
d
n
e
p
e
d
e
s
n
o
p
s
e
r
e
n
u
m
m

i
n
A

-
E
R
_

E
N
U
M
M
I
_
L
A
R
O
M
U
H
_
P
B
O
G

I

Y
B
_
D
E
T
A
D
E
M
_
E
S
N
O
P
S

N
I
L
U
B
O
L
G
O
N
U
M
M
I
_
G
N

I

1
2
0

.

6
3

-
i
s
s
a
l
c

e
h
t

,
s
y
a
w
h
t
a
p

e
e
r
h
t

f
o

e
n
o

e
v
l
o
v
n
i

n
o
i
t
a
v
i
t
c
a

t
n
e
m
e
l
p
m
o
c

f
o

s
p
e
t
s

1
7
1

N
O
I
T
A
V
I
T
C
A
_
T
N
E
M
E
L
P
M
O
C
_
P
B
O
G

2
2
0

.

5
3

d
e
z
i
t
i
s
n
e
s

y
l
l
a
c
ﬁ
i
c
e
p
s

r
o

y
d
o
b
i
t
n
a

c
ﬁ
i
c
e
p
s

e
h
t

,
e
s
n
o
p
s
e
r

t
a
h
t

f
o

s
t
c
u
d
o
r
p

e
h
t

8
5
1

h
c
i
h
w

f
o

l
l
a

,

y
a
w
h
t
a
p

n
i
t
c
e
l

e
h
t

d
n
a

,
y
a
w
h
t
a
p

e
v
i
t
a
n
r
e
t
l
a

e
h
t

,
y
a
w
h
t
a
p

l
a
c

,

d
d
a
:
C
O
G

,

2
2
0
0
0
0
0
:
F
E
R
_
O
G

[

.
y
a
w
h
t
a
p
t
n
e
m
e
l
p
m
o
c

l
a
n
i
m
r
e
t

e
h
t
o
t
d
a
e
l

e
c
n
a
t
s
b
u
s

y
n
a

,

n
e
g
i
t
n
a

n
a

h
t
i

w
y
l
t
n
e
l
a
v
o
c
-
n
o
n

d
n
a

y
l
e
v
i
t
c
e
l
e
s

g
n
i
t
c
a
r
e
t
n
I

h
t
i

w
g
n
i
t
c
a
e
r

f
o
d
n
a
e
s
n
o
p
s
e
r
e
n
u
m
m

i
c
ﬁ
i
c
e
p
s
a
g
n
i
c
u
d
n
i

f
o
e
l
b
a
p
a
c
s
i
h
c
i
h
w

]
9
4
1
5
3
7
1
8
7
0
:
N
B
S
I

I

I

G
N
D
N
B
_
N
E
G
I
T
N
A
_
F
M
O
G

6
1
0

.

0
1
0

.

0
1
0

.

6
3

7
3

6
3

f
o
y
t
i
v
i
t
c
a

l
a
c
i
g
o
l
o
i
b
e
h
t

t
c
a
r
e
t
n
u
o
c
y
a
m
g
n
i
d
n
i
B

.
h
t
o
b
r
o
,
s
e
t
y
c
o
h
p
m
y
l
-
T

]
4
4
5
2
6
6
1
2
7
0
:
N
B
S
I

,
2
3
7
6
0
5
8
9
1
0
:
N
B
S
I

,
l
j
:

C
O
G

[

.
n
e
g
i
t
n
a

e
h
t

e
s
n
o
p
s
e
r

e
n
u
m
m

i

n
a

f
o

t
u
o

g
n
i
y
r
r
a
c

e
h
t

h
t
i

w

d
e
v
l
o
v
n
i

s
s
e
c
o
r
p

y
n
A

-
y
c

r
o

s
e
i
d
o
b
i
t
n
a

f
o

n
o
i
t
c
u
d
o
r
p

e
h
t

,
e
c
n
a
t
s
n
i

r
o
f

,
h
g
u
o
r
h
t

,
l
l
e
c

B

a

y
b

,

d
d
a
:
C
O
G

,

2
2
0
0
0
0
0
:
F
E
R
_
O
G

[

.
s
l
l
e
c
T
o
t
n
o
i
t
a
t
n
e
s
e
r
p
n
e
g
i
t
n
a

r
o
,
s
e
n
i
k
o
t

]
9
4
1
5
3
7
1
8
7
0
:
N
B
S
I

,

b
h
:
C
O
G

[

.

d
i
u
ﬂ

y
d
o
b

a

h
g
u
o
r
h
t

d
e
t
a
i
d
e
m

e
s
n
o
p
s
e
r

e
n
u
m
m

i

n
A

]
2
3
7
6
0
5
8
9
1
0
:
N
B
S
I

a

y
b

e
s
n
o
p
s
e
r

e
n
u
m
m

i

n
a

f
o

t
u
o

g
n
i
y
r
r
a
c

e
h
t

n
i

d
e
v
l
o
v
n
i

s
s
e
c
o
r
p

y
n
A

]
9
4
1
5
3
7
1
8
7
0
:
N
B
S
I

,
d
d
a
:
C
O
G

,
2
2
0
0
0
0
0
:
F
E
R
_
O
G

[

.
e
t
y
c
o
h
p
m
y
l

-
p
e
c
e
r

c
ﬁ
i
c
e
p
s

g
n
i
s
s
e
r
p
x
e

s
e
t
y
c
o
h
p
m
y
l
y
b
d
e
t
a
i
d
e
m
e
s
n
o
p
s
e
r

e
n
u
m
m

i
n
A

t
a
h
t

s
s
e
c
o
r
p

n
o
i
t
a
c
ﬁ
i
s
r
e
v
i
d

c
i
t
a
m
o
s

a

h
g
u
o
r
h
t

d
e
c
u
d
o
r
p

n
e
g
i
t
n
a

r
o
f

s
r
o
t

-

m

i

g
n
i
d
o
c
n
e

s
t
n
e
m
g
e
s

e
n
e
g

e
n
i
l

m
r
e
g

f
o

n
o
i
t
a
n
i
b
m
o
c
e
r

c
i
t
a
m
o
s

s
e
d
u
l
c
n
i

n
e
g
i
t
n
a

r
o
f

s
r
o
t
p
e
c
e
r

d
e
n
i
b
m
o
c
e
R

.
s
n
i
a
m
o
d

y
l
i

m
a
f
r
e
p
u
s

n
i
l
u
b
o
l
g
o
n
u
m

s
r
o
t
p
e
c
e
r

l
l
e
c
T
e
d
u
l
c
n
i

s
n
i
a
m
o
d
y
l
i

m
a
f
r
e
p
u
s
n
i
l
u
b
o
l
g
o
n
u
m
m

i
y
b
d
e
d
o
c
n
e

r
e
t
n
u
o
c
n
e

t
s
r
ﬁ
e
h
T

.
s
l
l
e
c
B
y
b

d
e
c
u
d
o
r
p

)
s
e
i
d
o
b
i
t
n
a
(

s
n
i
l
u
b
o
l
g
o
n
u
m
m

i

d
n
a

f
o

t
o
n

d
n
a

w
o
l
s

s
i

t
a
h
t

e
s
n
o
p
s
e
r

e
n
u
m
m

i

y
r
a
m

i
r
p

a

s
t
i
c
i
l
e

n
e
g
i
t
n
a

h
t
i

w

0

0

0
1
0

.

6
3

d
n
a

d
e
t
a
v
i
t
c
a

e
m
o
c
e
b

n
e
g
i
t
n
a

y
b

d
e
t
c
e
l
e
s

s
l
l
e
c
B
d
n
a
T

.
e
d
u
t
i
n
g
a
m

t
a
e
r
g

8
5
3

s
l
l
e
c

B

d
n
a

T

e
v
i
t
c
a
e
r
-
n
e
g
i
t
n
a

f
o

n
o
i
t
c
a
r
f

A

.
n
o
i
s
n
a
p
x
e

l
a
n
o
l
c

o
g
r
e
d
n
u

e
h
T

.
s
l
l
e
c

r
o
t
c
e
f
f
e
o
t
n
i

e
t
a
i
t
n
e
r
e
f
f
i
d
s
r
e
h
t
o
s
a
e
r
e
h
w

,
s
l
l
e
c
y
r
o
m
e
m
e
m
o
c
e
b

r
e
t
s
a
f
h
c
u
m
a

e
l
b
a
n
e

e
s
n
o
p
s
e
r
y
r
a
m

i
r
p
e
h
t
g
n
i
r
u
d
d
e
t
a
r
e
n
e
g
s
l
l
e
c
y
r
o
m
e
m

e
h
t

o
t

s
e
r
u
s
o
p
x
e

t
n
e
u
q
e
s
b
u
s

n
o
p
u

e
s
n
o
p
s
e
r

e
n
u
m
m

i

y
r
a
d
n
o
c
e
s

r
e
g
n
o
r
t
s

d
n
a

e
v
i
t
p
a
d
a

e
h
t

s
i

s
i
h
t

f
o

e
l
p
m
a
x
e
n
A

.
)
y
r
o
m
e
m

l
a
c
i
g
o
l
o
n
u
m
m

i
(
n
e
g
i
t
n
a

e
m
a
s

,

u
s
n
e
s
_
g
t
m
C
O
G

:

,

d
d
a
:
C
O
G

[

.
s
u
l
u
c
s
u
m

s
u
M
n
i

d
n
u
o
f

e
s
n
o
p
s
e
r

e
n
u
m
m

i

]
1
3
8
6
9
1
5
0
4
1
:
N
B
S
I

,
9
4
1
5
3
7
1
8
7
0
:
N
B
S
I

9
1
2

I

Y
T
I
N
U
M
M
I
_
D
E
T
A
D
E
M
_
L
L
E
C
_
B
_
P
B
O
G

3
7
3

1
5
3

-
I

D
E
M
_

E
T
Y
C
O
H
P
M
Y
L
_
P
B
O
G

Y
T
I
N
U
M
M
I
_
D
E
T
A

E
S
N
O
P
S
E
R
_
E
N
U
M
M
I
_
L
A
R
O
M
U
H
_
P
B
O
G

-

O
S
_

E
N
U
M
M
I
_
E
V
I
T
P
A
D
A
_
P
B
O
G

I

N
O
I
T
A
N
B
M
O
C
E
R
_
C
I
T
A
M

N
O
_
D
E
S
A
B
_
E
S
N
O
P
S
E
R
_

S
R
O
T
P
E
C
E
R
_
E
N
U
M
M
I
_
F
O
_

-

U
S
_

N
I
L
U
B
O
L
G
O
N
U
M
M
I
_
M
O
R
F
_
T
L
I
U
B
_

I

S
N
A
M
O
D
_
Y
L
I
M
A
F
R
E
P

0

0

0

0

4
2
0

.

7
2

t
n
e
m
e
l
p
m
o
c

f
o

t
n
e
t
x
e

r
o

e
t
a
r

,
y
c
n
e
u
q
e
r
f

e
h
t

s
e
t
a
l
u
d
o
m

t
a
h
t

s
s
e
c
o
r
p

y
n
A

]
s
r
o
t
a
r
u
c
_
o
g
:
C
O
G

[

.
n
o
i
t
a
v
i
t
c
a

-
r
e
t
x
e

f
o

t
n
e
m

f
l
u
g
n
e

e
h
t

n
i

s
t
l
u
s
e
r

t
a
h
t

s
s
e
c
o
r
p

t
r
o
p
s
n
a
r
t

d
e
t
a
i
d
e
m
-
e
l
c
i
s
e
v
A

e
h
T

.
e
m
o
s
o
s
y
l
e
h
t
o
t
y
r
e
v
i
l
e
d
r
i
e
h
t
d
n
a
s
e
t
y
c
o
g
a
h
p
y
b
l
a
i
r
e
t
a
m
e
t
a
l
u
c
i
t
r
a
p
l
a
n

4
1
1

-
E
L
P
M
O
C
_

F
O
_
N
O
I
T
A
L
U
G
E
R
_
P
B
O
G

N
O
I
T
A
V
I
T
C
A
_
T
N
E
M

.
s
e
l
c
i
t
r
a
p
e
h
t

f
o
n
o
i
t
s
e
g
i
d
t
c
e
f
f
e
o
t

s
e
m
o
s
o
s
y
l
y
r
a
m

i
r
p
h
t
i

w
e
s
u
f
n
e
h
t
h
c
i
h
w

]
2
3
7
6
0
5
8
9
1
0
:
N
B
S
I
[

.
a
t
a
d
0
5
1
n
o
i
t
o
m
M

I
g
n
i
s
u

s
r
e
k
r
a
m
o
i
b

e
v
i
t
c
i
d
e
r
p

d
e
t
c
e
l
e
s

s
’
E
T
A
C
i
n
u

r
o
f

s

m
r
e
t

O
G

f
o
A
E
S
G

:
2
S
e
l
b
a
T

9
0
0

.

5
3

,
)
s
e
m
o
s
o
g
a
h
p
(

s
e
l
o
u
c
a
v
c
i
t
y
c
o
g
a
h
p
n
i
h
t
i

w
d
e
n
i
a
t
n
o
c
y
l
l
a
i
t
i
n
i

e
r
a

s
e
l
c
i
t
r
a
p

4
7
3

S
I
S
O
T
Y
C
O
G
A
H
P
_
P
B
O
G

0
1

1

2

3

4

5

6

7

8

9

19

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

Figure S3: While the log-transformed XIST gene expression data can be used to deﬁne two patient subpopulations
within the IMmotion 151 study, it does not appear to have a strong predictive effect like the simulated biomarkers of
Figure 1 of the main text.

References

Virginia B. Kraus. Biomarkers as drug development tools: discovery, validation, qualiﬁcation and use. Nature
ISSN 1759-4804. doi:10.1038/s41584-018-0005-9. URL

Reviews Rheumatology, 14(6):354–362, Jun 2018.
https://doi.org/10.1038/s41584-018-0005-9.

Geoffrey S. Ginsburg and Kathryn A. Phillips. Precision medicine: From science to value. Health Affairs, 37(5):
694–701, 2018. doi:10.1377/hlthaff.2017.1624. URL https://doi.org/10.1377/hlthaff.2017.1624. PMID:
29733705.

Patrick Royston and Willi Sauerbrei.

Interactions between treatment and continuous covariates: A step toward
individualizing therapy. Journal of Clinical Oncology, 26(9):1397–1399, 2008. doi:10.1200/JCO.2007.14.8981.
URL https://doi.org/10.1200/JCO.2007.14.8981. PMID: 18349388.

James Robins, Liliana Orellana, and Andrea Rotnitzky. Estimation and extrapolation of optimal treatment and
testing strategies. Statistics in Medicine, 27(23):4678–4721, 2008. doi:https://doi.org/10.1002/sim.3301. URL
https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.3301.

Lu Tian, Ash A. Alizadeh, Andrew J. Gentles, and Robert Tibshirani. A simple method for estimating interactions
between a treatment and a large number of covariates. Journal of the American Statistical Association, 109(508):1517–
1532, 2014. doi:10.1080/01621459.2014.951443. URL https://doi.org/10.1080/01621459.2014.951443.
PMID: 25729117.

Alexander R. Luedtke and Mark J. van der Laan. Super-learning of an optimal dynamic treatment rule. The International
Journal of Biostatistics, 12(1):305–332, 2016. doi:doi:10.1515/ijb-2015-0052. URL https://doi.org/10.1515/
ijb-2015-0052.

Shuai Chen, Lu Tian, Tianxi Cai, and Menggang Yu. A general statistical framework for subgroup identiﬁcation and
comparative treatment scoring. Biometrics, 73(4):1199–1209, 2017. doi:https://doi.org/10.1111/biom.12676. URL
https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12676.

Qingyuan Zhao, Dylan S. Small, and Ashkan Ertefaie. Selective inference for effect modiﬁcation via the lasso, 2018.

Stefan Wager and Susan Athey. Estimation and inference of heterogeneous treatment effects using random forests.
Journal of the American Statistical Association, 113(523):1228–1242, 2018. doi:10.1080/01621459.2017.1319839.
URL https://doi.org/10.1080/01621459.2017.1319839.

20

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

Qingliang Fan, Yu-Chin Hsu, Robert P. Lieli, and Yichong Zhang. Estimation of conditional average treat-
Journal of Business & Economic Statistics, 0(0):1–15, 2020.

ment effects with high-dimensional data.
doi:10.1080/07350015.2020.1811102. URL https://doi.org/10.1080/07350015.2020.1811102.

Asma Bahamyirou, Mireille E. Schnitzer, Edward H. Kennedy, Lucie Blais, and Yi Yang. Doubly robust adaptive lasso
for effect modiﬁer discovery. The International Journal of Biostatistics, 2022. doi:doi:10.1515/ijb-2020-0073. URL
https://doi.org/10.1515/ijb-2020-0073.

Oliver Hines, Karla Diaz-Ordaz, and Stijn Vansteelandt. Variable importance measures for heterogeneous causal effects,

2022a. URL https://arxiv.org/abs/2204.06030.

Jonathan Levy, Mark van der Laan, Alan Hubbard, and Romain Pirracchio. A fundamental measure of treatment effect

heterogeneity. Journal of Causal Inference, 9(1):83–108, 2021.

Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The elements of statistical learning: Data mining, inference
and prediction. Springer, 2 edition, 2009. URL http://www-stat.stanford.edu/~tibs/ElemStatLearn/.

Konstantinos Sechidis, Konstantinos Papangelou, Paul D Metcalfe, David Svensson, James Weatherall, and Gavin
Brown. Distinguishing prognostic and predictive biomarkers: an information theoretic approach. Bioinformatics,
34(19):3365–3376, 05 2018. ISSN 1367-4803. doi:10.1093/bioinformatics/bty357. URL https://doi.org/10.
1093/bioinformatics/bty357.

Wencan Zhu, Céline Lévy-Leduc, and Nils Ternès. Identiﬁcation of prognostic and predictive biomarkers in high-

dimensional data with pplasso, 2022. URL https://arxiv.org/abs/2202.01970.

Ning Hao and Hao Helen Zhang. Interaction screening for ultrahigh-dimensional data. Journal of the American
Statistical Association, 109(507):1285–1301, 2014. doi:10.1080/01621459.2014.881741. URL https://doi.org/
10.1080/01621459.2014.881741. PMID: 25386043.

Bo Jiang and Jun S. Liu. Variable selection for general index models via sliced inverse regression. The Annals of

Statistics, 42(5), oct 2014. doi:10.1214/14-aos1233. URL https://doi.org/10.1214%2F14-aos1233.

Cheng Yong Tang, Ethan X Fang, and Yuexiao Dong. High-dimensional interactions detection with sparse principal

hessian matrix. J. Mach. Learn. Res., 21:19–1, 2020.

D.B. Rubin. Estimating causal effects of treatments in randomized and nonrandomized studies. Journal of Educational

Psychology, 66(5):688–701, 1974.

Peter J Bickel, Chris AJ Klaassen, YA’Acov Ritov, and Jon A Wellner. Efﬁcient and adaptive estimation for semipara-

metric models. Johns Hopkins University Press Baltimore, 1993.

Oliver Hines, Oliver Dukes, Karla Diaz-Ordaz, and Stijn Vansteelandt. Demystifying statistical learning based on
efﬁcient inﬂuence functions. The American Statistician, 0(ja):1–48, 2022b. doi:10.1080/00031305.2021.2021984.
URL https://doi.org/10.1080/00031305.2021.2021984.

J Pfanzagl and W Wefelmeyer. Contributions to a general asymptotic statistical theory. Statistics & Risk Modeling, 3

(3-4):379–388, 1985.

Mark J van der Laan and James M Robins. Uniﬁed Methods for Censored Longitudinal Data and Causality. Springer

Science & Business Media, 2003.

Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duﬂo, Christian Hansen, and Whitney Newey. Dou-
ble/debiased/neyman machine learning of treatment effects. American Economic Review, 107(5):261–65, May 2017.
doi:10.1257/aer.p20171038. URL https://www.aeaweb.org/articles?id=10.1257/aer.p20171038.

Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duﬂo, Christian Hansen, Whitney Newey, and James
Robins. Double/debiased machine learning for treatment and structural parameters. The Econometrics Journal, 21(1):
C1–C68, 01 2018. ISSN 1368-4221. doi:10.1111/ectj.12097. URL https://doi.org/10.1111/ectj.12097.

Mark J van der Laan and Daniel Rubin. Targeted maximum likelihood learning. The International Journal of

Biostatistics, 2(1), 2006.

Mark J van der Laan and Sherri Rose. Targeted learning: causal inference for observational and experimental data.

Springer Science & Business Media, 2011.

Mark J van der Laan and Sherri Rose. Targeted Learning in Data Science: Causal Inference for Complex Longitudinal

Studies. Springer Science & Business Media, 2018.

Mark J. van der Laan, Eric C Polley, and Alan E. Hubbard. Super learner. Statistical Applications in Genetics and
Molecular Biology, 6(1), 2007. doi:doi:10.2202/1544-6115.1309. URL https://doi.org/10.2202/1544-6115.
1309.

21

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

Mark J van der Laan and Sandrine Dudoit. Uniﬁed cross-validation methodology for selection among estimators and a
general cross-validated adaptive epsilon-net estimator: Finite sample oracle inequalities and examples. Working Paper
130, University of California, Berkeley, Berkeley, 2003. URL https://biostats.bepress.com/ucbbiostat/
paper130/.

Max H. Farrell, Tengyuan Liang, and Sanjog Misra. Deep neural networks for estimation and inference. Econometrica,
89(1):181–213, 2021. doi:https://doi.org/10.3982/ECTA16901. URL https://onlinelibrary.wiley.com/doi/
abs/10.3982/ECTA16901.

Nima S. Hejazi, Philippe Boileau, Mark J. van der Laan, and Alan E. Hubbard. A generalization of moderated statistics
to data adaptive semiparametric estimation in high-dimensional biology, 2017. URL https://arxiv.org/abs/
1710.05451.

Toshiaki Watanabe, Takashi Kobunai, Yoko Yamamoto, Keiji Matsuda, Soichiro Ishihara, Keijiro Nozawa, Hisae
Iinuma, Tsuyoshi Konishi, Hisanaga Horie, Hiroki Ikeuchi, Kiyoshi Eshima, and Tetsuichiro Muto. Gene expression
signature and response to the use of leucovorin, ﬂuorouracil and oxaliplatin in colorectal cancer patients. Clinical
and Translational Oncology, 13(6):419–425, Jun 2011. ISSN 1699-3055. doi:10.1007/s12094-011-0676-z. URL
https://doi.org/10.1007/s12094-011-0676-z.

Philippe Boileau, Nima S. Hejazi, Mark J. van der Laan, and Sandrine Dudoit. Cross-validated loss-based covariance

matrix estimator selection in high dimensions, 2021a. URL https://arxiv.org/abs/2102.09715.

Philippe Boileau, Nima S. Hejazi, Brian Collica, Mark J. van der Laan, and Sandrine Dudoit. cvCovEst: Cross-validated
covariance matrix estimator selection and evaluation in R. Journal of Open Source Software, 6(63):3273, 2021b.
doi:10.21105/joss.03273. URL https://doi.org/10.21105/joss.03273.

R Core Team. R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing,

Vienna, Austria, 2022. URL https://www.R-project.org/.

Peter J. Bickel and Elizaveta Levina. Regularized estimation of large covariance matrices. The Annals of Statistics, 36(1):
199 – 227, 2008. doi:10.1214/009053607000000758. URL https://doi.org/10.1214/009053607000000758.
T. Tony Cai, Cun-Hui Zhang, and Harrison H. Zhou. Optimal rates of convergence for covariance matrix estimation.
The Annals of Statistics, 38(4):2118 – 2144, 2010. doi:10.1214/09-AOS752. URL https://doi.org/10.1214/
09-AOS752.

Wolfgang Huber, Vincent J. Carey, Robert Gentleman, Simon Anders, Marc Carlson, Benilton S. Carvalho, Hec-
tor Corrada Bravo, Sean Davis, Laurent Gatto, Thomas Girke, Raphael Gottardo, Florian Hahne, Kasper D. Hansen,
Rafael A. Irizarry, Michael Lawrence, Michael I. Love, James MacDonald, Valerie Obenchain, Andrzej K. Ole´s,
Hervé Pagès, Alejandro Reyes, Paul Shannon, Gordon K. Smyth, Dan Tenenbaum, Levi Waldron, and Martin Morgan.
Orchestrating high-throughput genomic analysis with bioconductor. Nature Methods, 12(2):115–121, Feb 2015.
ISSN 1548-7105. doi:10.1038/nmeth.3252. URL https://doi.org/10.1038/nmeth.3252.

Princy Parsana, Markus Riester, and Levi Waldron. curatedCRCData: Clinically Annotated Data for the Colorectal
Cancer Transcriptome, 2021. This is a manually curated data collection for gene expression meta-analysis of patients
with colorectal cancer. This resource provides uniformly prepared microarray data with curated and documented
clinical metadata. It allows users to efﬁciently identify studies and patient subgroups of interest for analysis and
to perform meta-analysis immediately without the challenges posed by harmonizing heterogeneous microarray
technologies, study designs, expression data processing methods and clinical data formats.

Yang Ning, Peng Sida, and Kosuke Imai. Robust estimation of causal effects via a high-dimensional covariate balancing
propensity score. Biometrika, 107(3):533–554, 06 2020. ISSN 0006-3444. doi:10.1093/biomet/asaa020. URL
https://doi.org/10.1093/biomet/asaa020.

Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society. Series B
(Methodological), 58(1):267–288, 1996. ISSN 00359246. URL http://www.jstor.org/stable/2346178.
Hui Zou and Trevor Hastie. Regularization and variable selection via the elastic net. Journal of the Royal Statistical Soci-
ety: Series B (Statistical Methodology), 67(2):301–320, 2005. doi:https://doi.org/10.1111/j.1467-9868.2005.00503.x.
URL https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2005.00503.x.

Charles J. Stone, Mark Hansen, Charles Kooperberg, and Young K. Truong. Polynomial splines and their tensor

products in extended linear modeling. Ann. Statist, 25:1371–1470, 1997.

Tianqi Chen and Carlos Guestrin. XGBoost: A scalable tree boosting system. Proceedings of the 22nd
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 785–794, 2016.
doi:10.1145/2939672.2939785. URL http://doi.acm.org/10.1145/2939672.2939785.

Leo Breiman. Random forests. Machine Learning, 45(1):5–32, 2001. doi:10.1023/A:1010933404324. URL https:

//doi.org/10.1023/A:1010933404324.

22

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

Yoav Benjamini and Yosef Hochberg. Controlling the false discovery rate: A practical and powerful approach to
multiple testing. Journal of the Royal Statistical Society. Series B (Methodological), 57(1):289–300, 1995. ISSN
00359246. URL http://www.jstor.org/stable/2346101.

Jared D. Huling and Menggang Yu. Subgroup identiﬁcation using the personalized package. Journal of Statistical
Software, 98(5):1–60, 2021. doi:10.18637/jss.v098.i05. URL https://www.jstatsoft.org/index.php/jss/
article/view/v098i05.

Brian I Rini, Thomas Powles, Michael B Atkins, Bernard Escudier, David F McDermott, Cristina Suarez, Sergio
Bracarda, Walter M Stadler, Frede Donskov, Jae Lyun Lee, Robert Hawkins, Alain Ravaud, Boris Alekseev, Michael
Staehler, Motohide Uemura, Ugo De Giorgi, Begoña Mellado, Camillo Porta, Bohuslav Melichar, Howard Gurney,
Jens Bedke, Toni K Choueiri, Francis Parnis, Tarik Khaznadar, Alpa Thobhani, Shi Li, Elisabeth Piault-Louis,
Gretchen Frantz, Mahrukh Huseni, Christina Schiff, Marjorie C Green, and Robert J Motzer. Atezolizumab plus
bevacizumab versus sunitinib in patients with previously untreated metastatic renal cell carcinoma (immotion151): a
multicentre, open-label, phase 3, randomised controlled trial. The Lancet, 393(10189):2404–2415, 2019. ISSN 0140-
6736. doi:https://doi.org/10.1016/S0140-6736(19)30723-8. URL https://www.sciencedirect.com/science/
article/pii/S0140673619307238.

Brian I Rini and Michael B Atkins. Resistance to targeted therapy in renal-cell carcinoma. The Lancet Oncology,
10(10):992–1000, 2009. ISSN 1470-2045. doi:https://doi.org/10.1016/S1470-2045(09)70240-2. URL https:
//www.sciencedirect.com/science/article/pii/S1470204509702402.

Robert J. Motzer, Bernard Escudier, David F. McDermott, Saby George, Hans J. Hammers, Sandhya Srinivas, Scott S.
Tykodi, Jeffrey A. Sosman, Giuseppe Procopio, Elizabeth R. Plimack, Daniel Castellano, Toni K. Choueiri, Howard
Gurney, Frede Donskov, Petri Bono, John Wagstaff, Thomas C. Gauler, Takeshi Ueda, Yoshihiko Tomita, Fabio A.
Schutz, Christian Kollmannsberger, James Larkin, Alain Ravaud, Jason S. Simon, Li-An Xu, Ian M. Waxman,
and Padmanee Sharma. Nivolumab versus everolimus in advanced renal-cell carcinoma. New England Journal
of Medicine, 373(19):1803–1813, 2015a. doi:10.1056/NEJMoa1510665. URL https://doi.org/10.1056/
NEJMoa1510665. PMID: 26406148.

Robert J. Motzer, Brian I. Rini, David F. McDermott, Bruce G. Redman, Timothy M. Kuzel, Michael R. Harrison,
Ulka N. Vaishampayan, Harry A. Drabkin, Saby George, Theodore F. Logan, Kim A. Margolin, Elizabeth R.
Plimack, Alexandre M. Lambert, Ian M. Waxman, and Hans J. Hammers. Nivolumab for metastatic renal cell
carcinoma: Results of a randomized phase ii trial. Journal of Clinical Oncology, 33(13):1430–1437, 2015b.
doi:10.1200/JCO.2014.59.0703. URL https://doi.org/10.1200/JCO.2014.59.0703. PMID: 25452452.
David F. McDermott, Mahrukh A. Huseni, Michael B. Atkins, Robert J. Motzer, Brian I. Rini, Bernard Escudier,
Lawrence Fong, Richard W. Joseph, Sumanta K. Pal, James A. Reeves, Mario Sznol, John Hainsworth, W. Kimryn
Rathmell, Walter M. Stadler, Thomas Hutson, Martin E. Gore, Alain Ravaud, Sergio Bracarda, Cristina Suárez,
Riccardo Danielli, Viktor Gruenwald, Toni K. Choueiri, Dorothee Nickles, Suchit Jhunjhunwala, Elisabeth Piault-
Louis, Alpa Thobhani, Jiaheng Qiu, Daniel S. Chen, Priti S. Hegde, Christina Schiff, Gregg D. Fine, and Thomas
Powles. Clinical activity and molecular correlates of response to atezolizumab alone or in combination with
bevacizumab versus sunitinib in renal cell carcinoma. Nature Medicine, 24(6):749–757, 2018. doi:10.1038/s41591-
018-0053-3. URL https://doi.org/10.1038/s41591-018-0053-3.

Jeffrey J. Wallin, Johanna C. Bendell, Roel Funke, Mario Sznol, Konstanty Korski, Suzanne Jones, Genevive Hernandez,
James Mier, Xian He, F. Stephen Hodi, Mitchell Denker, Vincent Leveque, Marta Cañamero, Galina Babitski,
Hartmut Koeppen, James Ziai, Neeraj Sharma, Fabien Gaire, Daniel S. Chen, Daniel Waterkamp, Priti S. Hegde, and
David F. McDermott. Atezolizumab in combination with bevacizumab enhances antigen-speciﬁc t-cell migration
in metastatic renal cell carcinoma. Nature Communications, 7(1):12624, 2016. doi:10.1038/ncomms12624. URL
https://doi.org/10.1038/ncomms12624.

Aravind Subramanian, Pablo Tamayo, Vamsi K. Mootha, Sayan Mukherjee, Benjamin L. Ebert, Michael A. Gillette,
Amanda Paulovich, Scott L. Pomeroy, Todd R. Golub, Eric S. Lander, and Jill P. Mesirov. Gene set enrichment
analysis: A knowledge-based approach for interpreting genome-wide expression proﬁles. Proceedings of the
National Academy of Sciences, 102(43):15545–15550, 2005. ISSN 0027-8424. doi:10.1073/pnas.0506580102. URL
https://www.pnas.org/content/102/43/15545.

Arthur Liberzon, Aravind Subramanian, Reid Pinchback, Helga Thorvaldsdóttir, Pablo Tamayo, and Jill P. Mesirov.
Molecular signatures database (MSigDB) 3.0. Bioinformatics, 27(12):1739–1740, 05 2011. ISSN 1367-4803.
doi:10.1093/bioinformatics/btr260. URL https://doi.org/10.1093/bioinformatics/btr260.

Lewis Au, Emine Hatipoglu, Marc Robert de Massy, Kevin Litchﬁeld, Gordon Beattie, Andrew Rowan, Desiree
Schnidrig, Rachael Thompson, Fiona Byrne, Stuart Horswell, Nicos Fotiadis, Steve Hazell, David Nicol, Scott T.C.
Shepherd, Annika Fendler, Robert Mason, Lyra Del Rosario, Kim Edmonds, Karla Lingard, Sarah Sarker, Mary
Mangwende, Eleanor Carlyle, Jan Attig, Kroopa Joshi, Imran Uddin, Pablo D. Becker, Mariana Werner Sunderland,

23

A Flexible Approach for Predictive Biomarker Discovery

PREPRINT

Ayse Akarca, Ignazio Puccio, William W. Yang, Tom Lund, Kim Dhillon, Marcos Duran Vasquez, Ehsan Ghorani,
Hang Xu, Charlotte Spencer, José I. López, Anna Green, Ula Mahadeva, Elaine Borg, Miriam Mitchison, David A.
Moore, Ian Proctor, Mary Falzon, Lisa Pickering, Andrew J.S. Furness, James L. Reading, Roberto Salgado,
Teresa Maraﬁoti, Mariam Jamal-Hanjani, Chris Abbosh, Kai-Keen Shiu, John Bridgewater, Daniel Hochhauser,
Martin Forster, Siow-Ming Lee, Tanya Ahmad, Dionysis Papadatos-Pastos, Sam Janes, Peter Van Loo, Katey
Enﬁeld, Nicholas McGranahan, Ariana Huebner, Stephan Beck, Peter Parker, Henning Walczak, Tariq Enver,
Rob Hynds, Ron Sinclair, Chi wah Lok, Zoe Rhodes, David Moore, Reena Khiroya, Giorgia Trevisan, Peter
Ellery, Mark Linch, Sebastian Brandner, Crispin Hiley, Selvaraju Veeriah, Maryam Razaq, Heather Shaw, Gert
Attard, Mita Afroza Akther, Cristina Naceur-Lombardelli, Lizi Manzano, Maise Al-Bakir, Simranpreet Summan,
Nnenna Kanu, Sophie Ward, Uzma Asghar, Emilia Lim, Faye Gishen, Adrian Tookman, Paddy Stone, Caroline
Stirling, Nikki Hunter, Sarah Vaughan, Mary Mangwende, Lavinia Spain, Haixi Yan, Ben Shum, Eleanor Carlyle,
Nadia Yousaf, Sanjay Popat, Olivia Curtis, Gordon Stamp, Antonia Toncheva, Emma Nye, Aida Murra, Justine
Korteweg, Debra Josephs, Ashish Chandra, James Spicer, Ruby Stewart, Lara-Rose Iredale, Tina Mackay, Ben
Deakin, Debra Enting, Sarah Rudman, Sharmistha Ghosh, Lena Karapagniotou, Elias Pintus, Andrew Tutt, Sarah
Howlett, Vasiliki Michalarea, James Brenton, Carlos Caldas, Rebecca Fitzgerald, Merche Jimenez-Linan, Elena
Provenzano, Alison Cluroe, Grant Stewart, Colin Watts, Richard Gilbertson, Ultan McDermott, Simon Tavare, Emma
Beddowes, Patricia Roxburgh, Andrew Biankin, Anthony Chalmers, Sioban Fraser, Karin Oien, Andrew Kidd,
Kevin Blyth, Matt Krebs, Fiona Blackhall, Yvonne Summers, Caroline Dive, Richard Marais, Fabio Gomes, Mat
Carter, Jo Dransﬁeld, John Le Quesne, Dean Fennell, Jacqui Shaw, Babu Naidu, Shobhit Baijal, Bruce Tanchel,
Gerald Langman, Andrew Robinson, Martin Collard, Peter Cockcroft, Charlotte Ferris, Hollie Bancroft, Amy
Kerr, Gary Middleton, Joanne Webb, Salma Kadiri, Peter Colloby, Bernard Olisemeke, Rodelaine Wilson, Ian
Tomlinson, Sanjay Jogai, Christian Ottensmeier, David Harrison, Massimo Loda, Adrienne Flanagan, Mairead
McKenzie, Allan Hackshaw, Jonathan Ledermann, Kitty Chan, Abby Sharp, Laura Farrelly, Hayley Bridger, George
Kassiotis, Benny Chain, James Larkin, Charles Swanton, Sergio A. Quezada, Samra Turajlic, Ben Challacombe,
Ashish Chandra, Simon Chowdhury, William Drake, Archana Fernando, Karen Harrison-Phipps, Steve Hazell,
Peter Hill, Catherine Horsﬁeld, Tim O’Brien, Jonathon Olsburgh, Alexander Polson, Sarah Rudman, Mary Varia,
and Hema Verma. Determinants of anti-pd-1 response and resistance in clear cell renal cell carcinoma. Cancer
Cell, 39(11):1497–1518.e11, 2021. ISSN 1535-6108. doi:https://doi.org/10.1016/j.ccell.2021.10.001. URL https:
//www.sciencedirect.com/science/article/pii/S1535610821005432.

William Fithian and Lihua Lei. Conditional calibration for false discovery rate control under dependence, 2020. URL

https://arxiv.org/abs/2007.10438.

Jeremy R. Coyle and Nima S. Hejazi. origami: A generalized framework for cross-validation in r. Journal of Open
Source Software, 3(21):512, 2018. doi:10.21105/joss.00512. URL https://doi.org/10.21105/joss.00512.
Jeremy R Coyle, Nima S Hejazi, Ivana Malenica, and Oleg Sofrygin. sl3: Modern Pipelines for Machine Learning and

Super Learning, 2021. URL https://doi.org/10.5281/zenodo.1342293. R package version 1.4.2.

Wenjing Zheng and Mark J. van der Laan. Cross-Validated Targeted Minimum-Loss-Based Estimation, pages 459–474.
Springer New York, New York, NY, 2011. ISBN 978-1-4419-9782-1. doi:10.1007/978-1-4419-9782-1_27. URL
https://doi.org/10.1007/978-1-4419-9782-1_27.

24

