2
2
0
2

l
u
J

1
3

]
E
S
.
s
c
[

2
v
0
3
2
7
0
.
6
0
2
2
:
v
i
X
r
a

IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

1

Automating Dependency Updates in Practice:
An Exploratory Study on GitHub Dependabot

Runzhi He, Hao He, Yuxia Zhang, Minghui Zhou

Abstract—Dependency management bots automatically open pull requests to update software dependencies on behalf of developers.
Early research shows that developers are suspicious of updates performed by dependency management bots and feel tired of
overwhelming notiﬁcations from these bots. Despite this, dependency management bots are becoming increasingly popular. Such
contrast motivates us to investigate Dependabot, currently the most visible bot on GitHub, to reveal the effectiveness and limitations of
state-of-art dependency management bots. We use exploratory data analysis and a developer survey to evaluate the effectiveness of
Dependabot in keeping dependencies up-to-date, reducing update suspicion, and reducing notiﬁcation fatigue. We obtain mixed
ﬁndings. On the positive side, Dependabot is effective in reducing technical lag and developers are highly receptive to its pull requests.
On the negative side, its compatibility scores are too scarce to be effective in reducing update suspicion; developers tend to conﬁgure
Dependabot toward reducing the number of notiﬁcations; and 11.3% of projects have deprecated Dependabot in favor of other
alternatives. The survey conﬁrms our ﬁndings and provides insights about developers’ most wanted features for dependency
management bots. Based on our ﬁndings, we derive and summarize the key characteristics of an ideal dependency management bot
which can be grouped into four dimensions: conﬁgurability, autonomy, transparency, and self-adaptability.

Index Terms—Dependency Management, Software Engineering Bot, Dependabot, Mining Software Repositories

(cid:70)

1 INTRODUCTION

To update or not to update, that is the question haunting
software engineers for decades. The software engineering
“gurus” would argue that keeping software dependencies1
up-to-date minimizes technical debt, increases supply chain
security, and ensures software project sustainability in the
long term [1], [2]. Nonetheless, it requires not only sub-
stantial effort but also extra responsibility from developers.
Consequently, there is no surprise that many developers
adhere to the practice of “if it ain’t broke, don’t ﬁx it” and
the majority of existing software systems still use outdated
dependencies [3], [4].

One promising solution for this dilemma is to use bots
to automate all dependency updates. Therefore, dependency
management bots are invented to automatically open pull
requests (PRs) to update dependencies in a collaborative
coding platform (e.g., GitHub) in the hope of saving de-
veloper effort. Recently, dependency management bots are
increasingly visible and gaining high momentum among

• Runzhi He, Hao He, and Minghui Zhou are with School of Computer
Science, Peking University, Beijing, China, and Key Laboratory of High
Conﬁdence Software Technologies, Ministry of Education, Beijing, China.
Runzhi He and Hao He contributed equally to this work. Minghui Zhou
is the corresponding author.
Email: rzhe@pku.edu.cn, heh@pku.edu.cn, zhmh@pku.edu.cn

• Yuxia Zhang is with School of Computer Science and Technology, Beijing

Institute of Technology, Beijing, China.
Email: yuxiazh@bit.edu.cn

Manuscript received July 31, 2022

1. In this paper, we keep inline with developers’ common terminolo-
gies and use the term “dependency” to refer to any software that
other software depends on, such as libraries, packages, frameworks,
development tools, etc. The software is often managed by a depen-
dency management tool (e.g., npm for JavaScript) and declared in a
dependency speciﬁcation ﬁle (e.g., package.json for npm projects).

practitioners. The exemplars of these bots, including De-
pendabot [5], Renovate Bot [6], PyUp [7], and Synk Bot [8],
have opened millions of PRs on GitHub [9] and are adopted
by a variety of industry teams (according to their websites).
However, the simple idea of using a bot does not save
the world. The early work of Mirhosseini and Parnin [10]
on Greenkeeper [11] reveals that: only 32% of Greenkeeper
PRs are merged because developers become suspicious of
whether a bot update will break their code due to incom-
patibilities (i.e., update suspicion) and feel annoyed about the
large number of bot PRs (i.e., notiﬁcation fatigue). Since then,
many similar bots have emerged, evolved, and gained high
popularity, even knocking Greenkeeper out of competition.
However, it remains unknown to what extent can these new
bots overcome the two limitations of Greenkeeper identiﬁed
by Mirhosseini and Parnin [10] in 2017.

To shed light on improving dependency management
bots and software engineering bots in general, we present
an exploratory study on Dependabot, the most visible bot
on GitHub. More speciﬁcally, we attempt to evaluate its
effectiveness in keeping dependencies up-to-date, reducing
update suspicion, and reducing notiﬁcation fatigue, forming
the following research questions:

• RQ1: To what extent does Dependabot reduce the technical

lag of a project after its adoption?

• RQ2: How active do developers respond to and merge pull

requests opened by Dependabot?

• RQ3: How effective is Dependabot’s compatibility score in

allaying developers’ update suspicion?

• RQ4: How do projects conﬁgure Dependabot for automated

dependency update?

• RQ5: How and why do projects deprecate Dependabot?
• RQ6: What features do developers desire for dependency

management bots?

 
 
 
 
 
 
IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

2

To answer the research questions, we collect 1,823 ac-
tively maintained popular GitHub projects and 502,752 De-
pendabot PRs from these projects. We conduct exploratory
data analysis on this dataset and obtain mixed ﬁndings.
First, Dependabot does keep dependencies up-to-date for
these projects: 90 days after adoption, the average tech-
nical lag is reduced by half (48.2%) and more than one-
third (35.7%) of projects achieve zero technical lag. Second,
developers are much more receptive to Dependabot PRs
compared with Greenkeeper: more than 70% of the PRs are
merged with a median merge lag of only four hours.

However, compatibility scores are too scarce to be ef-
fective: only 3.4% of PRs and 0.5% of dependency version
pairs contain a compatibility score, which may be because
most dependency version pairs do not have sufﬁcient up-
date PRs and CI (Continuous Integration) checks. Although
the majority of projects conﬁgure Dependabot toward a
proactive update strategy, we observe multiple patterns of
noise avoidance from conﬁguration modiﬁcations. Finally, a
non-negligible portion (11.3%) of projects have deprecated
lack of desired
Dependabot due to notiﬁcation fatigue,
features, and excessive CI usage. More than two-thirds of
them have not lost faith in automating dependency updates
and they migrate to other alternatives such as Renovate Bot.
We conduct a survey with 131 developers from the stud-
ied projects, whose answers generally conﬁrm the ﬁndings
from data analysis. By analyzing the answers to open-ended
questions in the survey, we ﬁnd that many developers ex-
pect a dependency management bot to automatically group
update PRs, automatically merge update PRs under certain
conditions, and support more package managers.

Our results indicate that dependency management bots
open the ﬁrst practical path toward full update automation
but they still have a long way to go to be not only effective
but also painless in practice. Based on our ﬁndings, we de-
rive and summarize four dimensions of key characteristics
for an ideal dependency management bot:

• Conﬁgurability: The bot should offer the highest pos-
sible conﬁguration ﬂexibility for 1) controlling the in-
tensity of notiﬁcation & interaction, 2) deﬁning precise
update strategies, and 3) integration & co-evolution with
a given operating environment.

• Autonomy: The bot should be able to perform certain
updates autonomously without human intervention un-
der certain conditions (e.g., when all project tests pass
or a sound program analysis indicates the absence of
breaking changes).

• Transparency: The bot should make the risks and conse-
quences of an update highly transparent (by informing
developers of the changes and estimating the impact of
update) for easy human review and intervention.

• Self-Adaptability: The bot should automatically iden-
tify and self-adapt to a sensible default conﬁguration in
a certain project environment (e.g., programming lan-
guage, package manager, project workﬂow, active time
zone, developer preferences, etc.).

Realizing the above characteristics would require effort from
both software engineering researchers (e.g., breaking change
analysis, CI log analysis, recommending conﬁgurations) and
dependency management bot designers (e.g., providing the
conﬁguration options desired by the community).

We provide a replication package at Figshare.2 The repli-
cation package contains all the necessary data (as spread-
sheets) and scripts (as Jupyter Notebooks) for replicating
the results from exploratory data analysis. To preserve the
privacy of survey respondents, we choose not to disclose
any raw data from our survey responses.

The remainder of this paper is organized as follows.
Section 2 introduces the background and related work
about dependency updates, dependency management bots,
and Dependabot. Section 3 justiﬁes our research questions.
Section 4 provides an overview of our study design and
describes the collection of repository data and survey re-
sponses in detail. Section 5 describes the speciﬁc methods
used and results obtained for each research question. Sec-
tion 6 introduces the key characteristics we derive for an
ideal dependency management bot and discusses the po-
tential limitations of our study. Finally, Section 7 concludes
our paper and points to possible future research directions.

2 BACKGROUND AND RELATED WORK
2.1 Dependency Update

In modern software development, updating dependencies is
not only important but also non-trivial. A typical software
project may have tens to thousands of dependencies and
each of the outdated ones induces risks [1]. However, each
update may contain breaking changes which can be hard
to discover and ﬁx [12]. This situation inspires research
into understanding update practices, designing metrics, and
inventing approaches to support dependency updates.

In terms of update practices, Bavota et al. [13] investigate
the Apache ecosystem and ﬁnd that updates are generally
triggered by major changes or a large number of bug
ﬁxes in the new version, but may be prevented by API
removals. Kula et al. [3] discover that 81.5% of the 4600
studied Java/Maven projects on GitHub still keep outdated
dependencies for two reasons:

• Lack of Awareness: Developers are unaware of the new
releases and security issues in outdated dependencies.
• Extra Workload: Developers perceive dependency up-

dates as extra workload and responsibility.

Similar results are also obtained in mobile apps [4], [14].
Pashchenko et al. [15] ﬁnd through semi-structured inter-
views that developers face various trade-offs when up-
dating dependencies (e.g., security vulnerabilities, breaking
changes, company policy).

Researchers have proposed measurements to quantify
the “freshness” or “outdatedness” of software dependencies
and applied them to various software ecosystems. Cox et
al. [16] propose several metrics to quantify “dependency
freshness” and evaluate them on a dataset of industrial Java
systems. A series of studies [17], [18], [19], [20], [21], [22]
introduce the notion of technical lag, a metric for measuring
the extent of project dependencies lagging behind their lat-
est releases, and investigate the evolution of technical lag in
Debian [17], npm [18], [19], [20], the Libraries.io dataset [21],
and Docker images [22]. They ﬁnd that technical lag tends
to increase over time, induces security risks, and can be
mitigated using semantic versioning.

2. https://ﬁgshare.com/s/78a92332e4843d64b984

IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

3

There has been a long line of research in software engi-
neering for supporting the automated update of software.
Since API breaking changes form the majority of update
cost, most studies propose automated approaches to match
and adapt evolving APIs (e.g., [23], [24], [25], [26], [27]).
However, Cossette and Walker [28] reveal through manual
analysis that real API adaptation tasks are complex and
beyond the capability of previous automated approaches.
Recently, research interest on automated API adaptation is
surging again with works on Java [29], [30], JavaScript [31],
Python [32], and Android [33], [34]. Their technical bound-
aries and practical impact are yet to be seen.

On the other hand, practitioners often take more con-
servative approaches for dependency updates: upstream
developers typically use semantic versioning [35] for sig-
naling version compatibility; downstream developers per-
form most updates manually and detect incompatibilities
through release notes, compilation failures, and regression
testing. Unfortunately, several studies [36], [37], [38], [39]
reveal that none of them work well in guaranteeing update
compatibility. Generally, providing such guarantees is still a
challenging open problem [40].

2.2 Dependency Management Bots

Perhaps the most noticeable automation effort among prac-
titioners is dependency management bots (e.g., Depend-
abot [5], Greenkeeper [11], Renovate Bot [6], Synk Bot [8],
etc.). These bots automatically create pull requests (PRs) to
update dependencies either immediately after a new release
is available or when a security vulnerability is discovered
in the currently used version. In other words, dependency
management bots solve the lack of awareness problem [3] by
automatically pushing update notiﬁcations to developers.

Mirhosseini and Parnin [10] conduct a pioneering empir-
ical study on Greenkeeper and ﬁnd that developers indeed
update dependencies more frequently (1.6x in their analy-
sis) using Greenkeeper. Nonetheless, only 32% of the PRs
opened by Greenkeeper are merged and it suffers from two
major limitations:

• Update Suspicion: If an automated update PR breaks
their code, developers immediately become suspicious
of subsequent update PRs and reluctant to merge them.
• Notiﬁcation Fatigue: If too many automated update PRs
are generated, developers may feel annoyed about the
notiﬁcations and simply ignore all the update PRs.
Recently, Rombaut et al. [41] investigate how Greenkeeper
creates issue reports (GKIRs) for in-range breaking updates
and they discover that GKIRs induce a signiﬁcant mainte-
nance overhead for project maintainers and many GKIRs are
false alarms arising from in-project CI issues.

The limitations of Greenkeeper align well with chal-
lenges revealed in the literature on software engineering
(SE) bots. Wessel et al. [42] ﬁnd that SE bots on GitHub tend
to have interaction problems and provide poor decision-
making support. Erlenhov et al. [43] clarify the notion of
SE bots and identify two major challenges in “Alex”3 bot
design: establishing trust and reducing interruption / noise.

3. According to Erlenhov et al. [43], an Alex bot is an SE bot that
autonomously performs simple tasks on behalf of developers (e.g.,
opening PRs to update dependencies).

TABLE 1: Top GitHub Bots by # of PRs Opened [9]

GitHub Bot

Dep. Management Bot?

# of PRs

Dependabot [5]
Dependabot Preview [48]
Pull Bot [49]
Renovate Bot [6]
PyUp [7]
Greenkeeper [11]
Synk Bot [8]

Yes
Yes
No
Yes
Yes
Yes
Yes

3,022,938
1,222,893
1,005,816
487,672
148,615
134,218
104,628

Wyrich et al. [9] ﬁnd that PRs opened by bots have a lower
merge rate and need more time to be interacted with and
merged. Two subsequent studies by Wessel et al. [44], [45]
qualitatively show that noise is the central challenge in
SE bot design but it can be mitigated by certain design
strategies and the use of a “meta-bot.” Shihab et al. [46]
draw a picture of SE bot open challenges including technical
challenges (e.g., bot quality evaluation, bot coordination)
and socio-economic challenges (e.g., human-bot collabora-
tion, economic impact). Santhanam et al. [47] provides a
systematic mapping of the literature on SE bots.

Since the work of Mirhosseini and Parnin [10], many
other bots have emerged for automating dependency up-
dates, such as Dependabot [5] (preview release in May
2017) and Renovate Bot [6] (ﬁrst release in January 2017).
Greenkeeper itself reaches end-of-life in June 2020 and its
team merged with Synk Bot [8]. All these bots are widely
used: according to Wyrich et al. [9], they opened the vast
majority of bot PRs on GitHub (six out of the top seven, see
Table 1). The top two are occupied by Dependabot [5] and
Dependabot Preview [48] with ∼3 million PRs and ∼1.2 mil-
lion PRs, respectively. Recently, Erlenhov et al. [50] ﬁnd that
under a strict SE bot deﬁnition, almost all bots in an existing
bot commit dataset [51] are dependency management bots
and they are frequently adopted, discarded, switched, and
even simultaneously used by GitHub projects, indicating a
ﬁerce competition among them. However, there is currently
still a lack of systematic investigation on the effectiveness
of strategies taken by these new bots in overcoming the
limitations of Greenkeeper [10], [41].

2.3 Dependabot

Among different dependency management bots, Depend-
abot [5] is the most visible one in GitHub projects (Table 1).
Dependabot was co-founded by Grey Baker and Harry Marr
and ﬁrst released in May 27, 2017 [52]. Its initial function-
alities included only opening PRs to update dependencies
to the latest version. Since then, the number of registered
users rapidly surged and it was acquired by GitHub in
May 23, 2019 [53]. Later, GitHub started to offer security
updates with Dependabot [54] and launched the GitHub
native version of Dependabot for dependency updates [55].
In August 3, 2021, the original Dependabot service (i.e.,
Dependabot Preview in Table 1) was shut down in favor of
the new, GitHub native service [56]. Currently (July 2022),
Dependabot offers two main functionalities:

• Automated Dependency Update [57]: If a conﬁgura-
tion ﬁle named dependabot.yml is added to a GitHub
repository, Dependabot will begin to open PRs that
update project dependencies to the latest version. De-
velopers can specify the exact Dependabot behavior in

IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

4

dencies when we’re close to being ready to cut a release.

2) Also Dependabot tends to be pretty spammy, which is rather

annoying.
Despite the amount of anecdotal evidence pointing to the
limitations of Dependabot’s automated dependency update
feature, there is still a lack of a comprehensive empirical
evaluation on the positive and negative effects of adopt-
ing Dependabot for automating dependency updates. Such
knowledge on Dependabot, combined with ﬁndings from
previous literature, can help the formulation of general
design guidelines for dependency management bots. It can
also unveil important open challenges and future research
directions necessary for fulﬁlling these guidelines.

3 RESEARCH QUESTIONS
The goal of this paper is to evaluate the practical effective-
ness of the Dependabot’s automated dependency update
feature. We expect such an evaluation to generate insights
on dependency management bot design and reveal future
research directions for supporting the automated update of
dependencies. More speciﬁcally, we attempt to empirically
evaluate Dependabot on:
1) its effectiveness in keeping dependencies up-to-date;
2) its effectiveness in reducing update suspicion;
3) its effectiveness in reducing notiﬁcation fatigue.

To evaluate the effectiveness of Dependabot in keeping
dependencies up-to-date, we reuse metrics from the well-
established technical lag literature [18], [20] and ask RQ1: To
what extent does Dependabot reduce the technical lag of a project
after its adoption?

Alfadel et al. [60] observe that GitHub projects are highly
receptive and responsive to Dependabot security updates.
However, this may not be the case for automated depen-
dency updates (Section 2.3), given the low priority of regular
dependency update tasks perceived by developers [3] and
the considerably larger amount of PRs (Section 2.3). For
comparison, we ask RQ2: How active do developers respond
to and merge pull requests opened by Dependabot?

Since the compatibility score feature is the main counter-
measure for update suspicion in Dependabot, we ask RQ3:
How effective is Dependabot’s compatibility score in allaying
developers’ update suspicion?

For the notiﬁcation fatigue problem, Wessel et al. [44]
have recognized re-conﬁguring as a countermeasure against
noise. Thus, we expect that something about Dependabot
notiﬁcation noise can be learned by analyzing how and
when developers tweak their Dependabot conﬁgurations,
forming RQ4: How do projects conﬁgure Dependabot for auto-
mated dependency update?

During our analysis, we discover that a non-negligible
portion of projects in our studied corpus have abandoned
Dependabot and migrated to other alternatives. Since the
analysis of these projects may help reveal important De-
pendabot limitations, we ask RQ5: How and why do projects
deprecate Dependabot?

Finally, we want to hear from actual Dependabot users
about the features they desire for dependency management
bots and their general opinions about these bots. This forms
the last research question RQ6: What features do developers
desire for dependency management bots?

Fig. 1: A pull request opened by Dependabot

dependabot.yml, such as which dependency to update
or not update, update interval, the maximum number of
simultaneous Dependabot PRs, etc.

• Security Update [54]: Dependabot scans the entire
GitHub to ﬁnd repositories using dependencies with
security vulnerabilities. Even if no dependabot.yml is
supplied, Dependabot still alerts repository owners via
emails. Then, repository owners can manually tell De-
pendabot to open PRs that update vulnerable dependen-
cies to their patched versions.
Figure 1 shows an example PR opened by Depend-
abot [58]. Apart from all the details in this PR, one espe-
cially interesting Dependabot feature is the compatibility
score badge. According to GitHub documentation [59]: An
update’s compatibility score is the percentage of CI runs that
passed when updating between speciﬁc versions of the dependency.
In other words, the score uses the large-scale regression
testing data available in GitHub CI checks to estimate the
risk of breaking changes in a dependency update. This
looks like a promising direction for solving the update
suspicion problem, as previous studies have shown that
project test suites are often unreliable in detecting update
incompatibilities [38] and the false alarms introduce a sig-
niﬁcant maintenance overhead [41]. However, the score’s
effectiveness in practice remains unknown.

For the notiﬁcation fatigue problem, Wessel et al. [44]
suggest SE bots to provide ﬂexible conﬁgurations and send
only relevant notiﬁcations to developers. Both solutions
have been (principally) implemented by Dependabot, but
it is still unclear whether the speciﬁc conﬁguration options
and notiﬁcation strategies taken by Dependabot are really
effective in practice. Alfadel et al. [60] study security PRs
opened by Dependabot Preview and ﬁnd that developers
receive security PRs well: 65.42% of PRs are merged and
most are merged within a day. However, security PRs only
constitute a small portion of PRs opened by Dependabot
(6.9% in our dataset) and security updates are generally
perceived as highly relevant [15]. The effectiveness of au-
tomated dependency update in general seems to be more
problematic. Soto-Valero et al. [61] ﬁnd that Dependabot
often opens PRs on bloated dependencies. A recent study
by Cogo and Hassan [62] also provides evidence on how the
conﬁguration of Dependabot causes issues for developers.
As stated by two developers in a GitHub issue [63]:
1) I think we’d rather manage dependency upgrades ourselves,
on our own time. We’ve been frequently bitten by dependency
upgrades causing breakages. We tend to only upgrade depen-

IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

5

Fig. 2: An overview of our study

4 STUDY DESIGN

Figure 2 presents an overview of our study, which follows
a mix-method study design consisting of data collection
(Part I), exploratory data analysis (Part II), and a developer
survey (Part III). For RQ1 - RQ5, the survey serves as a
triangulation of results from data analysis, and we use the
survey responses for answering RQ6. In the remainder of
this Section, we will introduce the methods we use for data
collection (Part I) and developer survey (Part III) in greater
detail. We will present the speciﬁc analysis methods used in
Part II along with results in Section 5.

4.1 Data Collection

4.1.1 Project Selection

As the ﬁrst step, we need to collect engineered and main-
tained GitHub projects using or once used Dependabot
automated dependency update in their workﬂow. We focus
on the GitHub native Dependabot (released on June 1, 2020)
and do not include Dependabot Preview in our study be-
cause the former provides much richer features and allows
us to obtain the latest, state-of-the-art results.4

We begin with the latest dump of GHTorrent [64] (re-
leased on March 6, 2021), a large-scale dataset of GitHub
projects widely used in software engineering research (e.g.,
[9], [38]). We ﬁnd a noticeable gap in the GHTorrent dataset
from July 2019 to early January 2020 (also observed by
Wyrich et al. [9]). Focusing solely on GitHub native De-
pendabot allows us to circumvent threats caused by this
gap because all its PRs are created after January 2020.

We select projects with at least 10 merged Dependabot
PRs to keep only projects that have used Dependabot to
some degree. To ﬁlter out irrelevant, low-quality, or un-
popular projects, we retain only non-fork projects with at
least 10 stars, as inspired by previous works [61], [65], [66].5
Since projects without sustained activities may not perform
dependency updates on a regular basis and induce noise
in technical lag analysis (RQ1), we query GitHub APIs [67]
and retain projects with a median weekly commit of at least
one in the past year. To ﬁlter out projects that have never
utilized Dependabot for automated dependency update,

4. More precisely, all data in our study are collected from the GitHub

account dependabot[bot] instead of dependabot-preview[bot].

5. Munaiah et al. [65] show that a simple threshold of 10 stars can
already reach a precision of 97% when classifying engineered GitHub
projects. Other ﬁltering steps also contribute to the overall quality of
our ﬁnal project sample (e.g., sustained activity). See Table 3 for the
statistics of our ﬁnal collected projects.

we clone the projects and retain only projects with some
git modiﬁcation history on dependabot.yml. After all the
ﬁltering steps, we end up with 1,823 projects.

4.1.2 PR Collection

We use the GitHub REST APIs [67] and a web scraper to ﬁnd
all the latest Dependabot PRs (before Feburary 14, 2022) in
the 1,823 projects and collect PR statistics, bodies, CI check
results, and timeline events. By leveraging a distributed
pool of Cloudﬂare workers [68], this web scraper empowers
us to bypass the limitation of GitHub APIs (which is un-
handy for collecting CI check results for PRs) and retrieve
pull requests events and CI checks at scale. The PR body
can tell which dependency this PR is updating, its current
version, and its updated version. By the end of this stage,
we obtain 540,665 Dependabot pull requests (71.1% with
a CI check result), updating 15,390 dependencies between
167,841 version pairs.

Our next task is to identify security updates from all of
the PRs created by Dependabot. However, Dependabot is
no longer labeling security updates due to security reasons.
Instead, Dependabot is showing a banner on the PR web
page which is only visible to repository administrators by
default [54]. Therefore, we choose to construct a mirror of
the GitHub security advisory database [69] and identify
security PRs ourselves by checking whether the PR updates
a version with a vulnerability entry at the time of PR
creation. More speciﬁcally, we identify a pull request to be a
security update PR if:
1) the dependency and its current version matches a vul-
nerability in the GitHub security advisory database;
2) the updated version is newer than the version that ﬁxes
this vulnerability (i.e., no vulnerability after update);
3) the PR is not merged or closed before the vulnerability

disclosure.

Eventually, we identify 37,313 security update PRs (6.9%)
from the 540,665 Dependabot PRs in total.

4.1.3 Dataset Overview

As illustrated in Table 3, projects in our dataset are mostly
engineered, popular GitHub projects with a non-trivial code
base, active maintenance, rich development history, and fre-
quent Dependabot usage. We notice a long-tail distribution
in the metrics concerning the size of the project, i.e., number
of contributors, lines of code, and commit frequency, which
is expected and common in most mining software repository
(MSR) datasets [39], [70], [71].

PartI:DataCollectionGHTorrentDatasetGitHubAPI1,823ProjectsWebScraperGitHubAdvisory540,665PRsDeveloperSurveyPartII:Exploratory DataAnalysisPartIII:Developer SurveyAnalysisResultsRQ1RQ2RQ3RQ4RQ5TechnicalLagPRResponseComp.ScoreConfigurationDeprecationRQ1RQ2RQ3RQ4RQ5TechnicalLagPRResponseComp.ScoreConfigurationDeprecationRQ6Desired FeaturesvalidatesIEEE TRANSACTIONS ON SOFTWARE ENGINEERING

6

TABLE 2: Survey Questions and Their Results (131 Responses in Total)

5-Point Likert-Scale Questions

Distribution Avg.

(RQ1) Dependabot helps my project keep all dependencies up-to-date.

(RQ2) Dependabot PRs do not require much work to review and merge.
(RQ2) I respond to a Dependabot PRs fast if it can be safely merged.
(RQ2) I ignore the Dependabot PR or respond slower if it cannot be safely merged.
(RQ2) I handle a Dependabot PR with higher priority if it updates a vulnerable dependency.
(RQ2) It requires more work to review and merge a Dependabot PR if it updates a vulnerable dependency.
(RQ2) Dependabot often opens more PRs than I can handle.

(RQ3) Compatibility scores are often available in Dependabot PRs.
(RQ3) If a compatibility score is available, it is effective in indicating whether the update will break my code.

(RQ4) Dependabot can be conﬁgured to ﬁt the needs of my project.
(RQ4) I conﬁgure Dependabot to make it less noisy (i.e., only update certain dependencies, scan less frequently, etc.)

Multiple Choice Questions

(RQ5) Are your GitHub repositories still using Dependabot for automating version updates?
(RQ5) If not, why?
Open-Ended Questions∗

4.44

3.94
4.42
3.78
4.19
2.49
2.73

2.95
2.95

3.54
3.27

0.89

(Results in § 5.5)

(RQ6) Regardless of current availability, what are the features you want most for a bot that updates dependencies?
Do you have any further opinions or suggestions?

(Results in § 5.6)

∗ Where appropriate, we also use evidence from open-ended question responses to support the results in RQ1 - RQ5.

TABLE 3: Statistics of the 1,823 Studied Projects

4.2 Developer Survey

Statistics

#Stars

#Commits

Mean Median

Distribution

1423.92

66.00

2837.11 1040.50

#Contributors

26.50

12.00

LoC (thousands)

98.18

19.89

#Commits per Week

10.07

4.00

Age at Adoption (days) 1018.18

714.00

#Dependabot PRs

304.56

204.00

Most (44.1%) projects in our dataset utilize the npm
package ecosystem,
followed by Maven (12.3%), PyPI
(11.7%), and Go modules (7.8%). Among the Dependabot
PRs, those that update npm packages constitute even a
higher portion (64.9%), followed by PyPI (8.9%), Go mod-
ules (4.3%), Bundler (3.9%), and Maven (3.9%), as packages
in the npm ecosystem generally evolve faster [72].

Dependabot has opened hundreds of PRs for most
of the projects (mean = 304, median = 204), even up
to thousands for some of them. This likely indicates a
high workload for project maintainers. In terms of the
most updated dependencies, it is not surprising that all
top ﬁve comes from npm: @types/node (29,352 PRs),
eslint (13,193 PRs), @typescript-eslint/parser (11,833
PRs), @typescript-eslint/eslint-plugin (10,917 PRs),
and webpack (9,484 PRs). However, all these packages
are mainly used as devDependencies (static typing, lin-
ters, and module bundlers), which are typically only used
for development but not
in production. Since the ne-
cessity of updating devDependencies remains controver-
sial [3], [73], Dependabot’s frequent and massive updates
to devDependencies may be the ﬁrst alarming signal of
causing noise and notiﬁcation fatigue to developers.

To validate the results from data analysis, we additionally
design and conduct a survey with developers from the 1,823
projects. The survey consists of 11 5-point Likert scale [74]
questions for RQ1 - RQ4, two multiple choice questions
for RQ5, and two open-ended questions for collecting de-
velopers’ desired features for dependency management bot
and their general opinions (RQ6). To locate survey can-
didates, we ﬁnd developers that are authors of commits
that deprecate Dependabot, the most active respondents
to PRs, project owners, or the most active contributor in
each project. For each developer, we retrieve their email
addresses from git commits and exclude apparently invalid
emails (e.g., emails containing noreply). We get 1,295 devel-
opers after manually merging their identities. Among them,
we successfully deliver 1,226 emails and get 131 responses
within three weeks (response rate 10.7%). This response
rate represents a good maximum sample size [75] and is
comparable to previous SE surveys [71], [76]. The survey
questions and its results are summarized in Table 2.

We carefully take ethical considerations into account
when designing and executing our survey. We only select
the most relevant survey candidates and send personalized
emails to them (with information about how they used
Dependabot), to avoid being perceived as spam. We try
our best to follow common survey ethics [77], e.g., clearly
introducing the purpose of this survey, being transparent
about what we will do to their responses, etc. To increase
the chance of getting a response and to contribute back to
the open-source community, we offer to donate $5 to an
open-source project of the respondents’ choice if they opt
in. Therefore, we believe we have done minimal harm to the
open-source developers we have contacted, and the results
we get about Dependabot far outweigh the harm. In fact,
we get several highly welcoming responses from the survey
participants, such as: 1) keep up the good work! 2) If you would
like to consult more, just ping me on <email>...Cheers!

02040608002040600255075100010203040500204060800102030405001020304002040600204060800102030405001020304011825%50%75%101103105102104106102103104105100101102102104106103105107100101102100102104101103102103104IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

7

5 METHODS AND RESULTS
5.1 RQ1: Technical Lag

5.1.1 Method

We evaluate the effectiveness of Dependabot automated
dependency updates by comparing the project technical lag
at two time points: the day of Dependabot adoption (T0)
and 90 days after adoption (i.e., T0 + 90). We choose 90
days as the interval to avoid inﬂuence of deprecations as
more than 85% of them happen 90 days after adoption.
Since technical lag naturally increases over time [18], [20],
we include an additional time point for comparison: 90 days
before adoption (i.e., T0 − 90).

TABLE 4: Technical Lag (days) for 613 npm Projects

Metric

Mean Median

Distribution

techlag(p, T0 − 90)

73.68

∆ in Between

-24.96

16.27

0.00

techlag(p, T0)

48.99

13.96

∆ in Between

-23.61

techlag(p, T0 + 90)

25.38

-0.61

3.62

For a project p at time t ∈ {T0 − 90, T0, T0 + 90}, we
denote all its direct dependencies as deps(p, t) and deﬁne
its technical lag as:
(cid:80)

d∈deps(p,t) max (0, tlatest(d) − tcurrent(d))
|deps(p, t)|

techlag(p, t) =

Here tlatest(d) denotes the release time of d’s latest version
at time t and tcurrent(d) denotes the release time of d’s
current version (i.e., the version that p is using at time
t). We use max to guard against the occasional case of
tlatest(d) < tcurrent(d) (e.g., developers may continue to re-
lease 0.9.x versions after the release of 1.0.0).

This technical lag deﬁnition is inspired by Zerouali et
al. [20] but with several adjustments. First, we use only their
time-based variant instead of their version-based variant
because cross-project comparisons would not be intuitive
using the latter. Second, we use the mean value of all
dependencies instead of maximum or median as the overall
technical lag, because we intend to measure the overall
effectiveness of Dependabot for both keeping most depen-
dencies up-to-date and eliminating the most outdated ones.
We exclude projects with an age of fewer than 90 days at
Dependabot adoption and projects that deprecate Depend-
abot within 90 days. We also exclude projects that migrate
from Dependabot Preview since they may introduce bias
into results. Since the computation of technical lag based on
dependency speciﬁcation ﬁles and version numbers requires
non-trivial implementation work for each package ecosys-
tem, we only base our analysis on JavaScript/npm, the
most popular ecosystem in our dataset. We further exclude
projects with no eligible npm dependencies conﬁgured for
Dependabot in T0 − 90, T0, or T0 + 90. After all the ﬁltering,
we retain 613 projects for answering RQ1.

Finally, we adopt the Regression Discontinuity Design
(RDD) framework to estimate the impact of adopting De-
pendabot on project technical lags. RDD uses the level of
discontinuity before/after an intervention to measure its ef-
fect size while taking the inﬂuence of an overall background
trend into consideration. Given that technical lag tends to
be naturally increasing over time [18], [19], [20], RDD is a
more appropriate statistic modeling approach for our case
compared with hypothesis testing approaches (e.g., one-side
Wilcoxon rank-sum tests). Following previous works that
utilized RDD in SE [78], [79], we use “sharp RDD”, i.e.,
“segmented regression analysis of interrupted time series
data.” We treat project-level technical lag as a time series
function, compute the technical lag for each project every
15 days from T0 − 90 to T0 + 90, use ordinary least square

Fig. 3: Project-level technical lag changes (T0−90,T0,T0+90).

regression to ﬁt the RDD model, and watch for the presence
of discontinuity at the time of Dependabot adoption. More
speciﬁcally, we ﬁt the following model:

yi = α + β · timei + γ · intervention

+ θ · time_af ter_interventioni + σi

Here yi denotes the output variable (i.e., technical lag
for each project in our case); time stands for the number of
days from T0 − 90; intervention binarizes the presence of
Dependabot (0 before adopting Dependabot, 1 after adop-
tion); time_af ter_intervention counts the number of days
from T0 (0 when T0 − 90 ≤ time < T0).

5.1.2 Results

We present technical lags and their delta between time
points in Table 4. We plot diagrams in Figure 3 to reﬂect
how different projects increase/decrease their technical lag
between the three time points. The ﬁrst surprising fact
we notice is that the technical lag of approximately one-
third (216/613) of projects is already decreasing between
T0 − 90 and T0, even if technical lag generally increases over
time [18], [20]. This indicates that these projects are already
taking a proactive dependency update strategy even before
adopting Dependabot. On the other hand, for about half
(303/613) of the projects, the technical lag increases prior to
Dependabot adoption, and 94 projects keep the technical lag
unchanged at zero (i.e., all dependencies are up-to-date). For
all projects, the mean and median technical lag at T0 − 90
is 73.68 days and 16.27 days, respectively; they decrease at
T0 to 48.99 days and 13.96 days, respectively; at T0, 159
(25.9%) of the 613 projects have already achieved a zero
technical lag. Despite numerical differences, both decrease
and increase are not statistically signiﬁcant between T0 − 90
and T0 using one-tailed Wilcoxon signed-rank tests.

Between T0 and T0 + 90, projects lower their technical
lag even further from a mean of 48.99 days and a median
of 13.96 days to a mean of 25.38 days and a median of
3.62 days. The decrease is statistically signiﬁcant using a
one-tailed Wilcoxon signed-rank test (p < 0.001). Among

0501001502001005005010005010015020010050050100050100150200𝑇!−90𝑇!𝑇!+90613 Projects303216394212208394824070Legend:Tech. Lag DecreasesTech. Lag IncreasesTech. Lag is UnchangedNo DependabotUsing DependabotIEEE TRANSACTIONS ON SOFTWARE ENGINEERING

8

the 303 projects with an increasing technical lag between
T0 − 90 and T0, about two-thirds (220) of them see a
decrease after adopting Dependabot; among the 216 projects
with decreasing technical lag, nearly half (94) of them see
a decrease. More than one-third (219, 35.7%) of projects
achieve completely zero technical lag 90 days after Depend-
abot adoption. Although there are still some increases, the
magnitude is much smaller (e.g., 75% quantile of only +1.75
days between T0 and T0 + 90 compared with 75% quantile
of +14.37 days between T0 − 90 and T0).

TABLE 5: The Estimated Coefﬁcients and Signiﬁcance Lev-
els for the RDD Model We Fit (Section 5.1.1).

Feature

Coef.

Std. Err.

t

p

Intercept*
intervention*
time
time_af ter_intervention
∗ p < 0.001

66.5209
-31.2137
-0.0743
-0.1011

4.595
5.694
0.079
0.100

14.477
-5.306
-0.945
-1.008

0.000
0.000
0.345
0.314

Fig. 4: Project-level technical lag changes (from T0 − 90 to
T0 + 90). Red and green lines represents the liner-ﬁtted tech-
nical lag before/after Dependabot adoption respectively.

Table 5 shows that the regression variable intervention
has a statistically signiﬁcant negative coefﬁcient (coef. =
−31.2137, p < 0.001), indicating that the adoption of De-
pendabot did reduced technical lag and keep dependencies
up-to-date in the sampled 613 projects. A more straight-
forward look of this trend can be observed in Figure 4: at
T0, project-level technical lag has a signiﬁcant decrease, and
there is a discontinuity between the liner-ﬁtted technical lag
before/after adoption. time and time_af ter_intervention
have negative coefﬁcients, echoing with our earlier ﬁndings:
the technical lag of sampled projects is already on decrease
before Dependabot adoption and the introduction of De-
pendabot adds up to this decreasing trend. However, both
of the coefﬁcients is not comparable to that of intervention
and not statistically signiﬁcant (p > 0.3).

5.1.3 Validation with Survey

Several developers also mention that Dependabot serves
well as an automatic notiﬁcation mechanism that tells them
about new versions and pushes them to update their depen-
dencies. For example:
1) Dependabot is a wonderful way for me to learn about ma-

jor/minor updates to libraries.

2) Dependabot can be a bit noisy, but it makes me aware of my

dependencies.
However, some developers do not favor using Depend-
abot for automating dependency updates but only use De-
pendabot as a way of notiﬁcation:
1) We just use it for notiﬁcations about updates, but do them

manually and check if anything broke in the process.

2) I am just using Dependabot to tell me if there is something to
update and then update all in a single shot with plain package
managers.

This indicates that they do not trust the reliability of De-
pendabot for automated updates and they do not think the
current design of Dependabot can help them reduce the
manual workload of updates. More examples:
1) The thing is: Dependency management is currently much
easier just utilizing yarn/npm. We use Dependabot merely
because it has been recommended, but updating dependencies
was faster when I solely used the command line.

2) I think Dependabot is good if there are insecure vulnerabilities,
because it is good in updating only the package.lock. But for
everything else, it’s slower than manually updating dependen-
cies (plus, many dependencies can be updated in bulk, so one
PR per dependency is a tad verbose).

3) The way I’m using it right now is I will let the bot push
PR and notify me, but when I see it, especially if I see a ton
of them, I’ll update the dependency by myself and push the
commit - it’s faster and safer.
One developer suggests that as using Dependabot only
for update notiﬁcations has already become a common use
case, they would prefer a dedicated, less noisy tool solely
designed for this purpose (i.e., update notiﬁcation):

It (Dependabot) becomes more like an update notiﬁcation,
i.e. I’m leveraging only half of its capability. Could there be
something designed solely for this purpose? Less invasive,
more informative, and instead of creating a PR for every
package’s update, I would like to see a panel-style hub to
collect all the information for me to get a better overview
in one place.

Findings for RQ1:

Dependabot is effective in reducing technical lags: 90
days after adoption, projects decrease their technical
lag from an average of 48.99 days to an average of 25.38
days. The decrease is statistically signiﬁcant. More than
one-third of projects achieve zero technical lag 90 days
after adoption. Developers agree on the effectiveness of
Dependabot in notifying them to update, but question
its effectiveness in automating updates.

Developers also agree that Dependabot is helpful in keep-
ing their dependencies up-to-date: 55.8% responded with
Strongly Agree and 35.7% with Agree (Table 2). As noted
by one developer: Dependabot does a great job of keeping my
repositories current.

5.2 RQ2: Developers’ Response to Pull Requests

5.2.1 Method
We use the following metrics to measure the receptiveness
(i.e., how active developers merge) and responsiveness (i.e.,

−100−50050100050010001500# of days from Dependabot adoptionTechnical lag (in days)IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

TABLE 6: PR Statistics in Different Groups. All lags are
measured in days. ¯x represents the mean and µ represents
the median over all PRs in this group.

Statistics

# of PRs
Merge Rate
Close Lag
Merge Lag
Resp. Lag

regular

sec/conf

sec/nconf

502,752
70.13%
¯x=8.63, µ=3.00
¯x=1.76, µ=0.18
¯x=2.27, µ=0.17

13,406
73.71%
¯x=14.42, µ=5.00
¯x=3.45, µ=0.18
¯x=3.74, µ=0.17

23,907
76.01%
¯x=26.83, µ=5.71
¯x=8.15, µ=0.76
¯x=8.59, µ=0.51

how active developers respond) of Dependabot PRs:

• Merge Rate: The proportion of merged PRs.
• Close Lag: The time it takes for developers to close a PR.
• Merge Lag: The time it takes for developers to merge a

PR.

• Response Lag: The time it takes for a PR to have human
interactions, including any observable action in the PR’s
timeline, e.g., adding a label or assigning a reviewer.
The former three are also used by Alfadel et al. [60] and
the last one is inspired by Wyrich et al. [9]. We use merge
rate to measure receptiveness and the latter three to measure
responsiveness.

We assume that results may differ for PRs in different
groups. More speciﬁcally, we expect that 1) developers are
both more receptive and more responsive to security up-
dates due to their higher priority of eliminating security vul-
nerabilities; and 2) projects that use automated dependency
update (i.e., contain dependabot.ymls) are more responsive
to Dependabot PRs. To verify our expectations, we divide
all Dependabot PRs into three groups:

• regular: Dependabot PRs that update a package to its
latest version when the old version does not contain any
known security vulnerabilities.

• sec/conf: Security PRs that update a package with vul-
nerabilities to its patched version and are opened when
the project has a dependabot.yml ﬁle in its repository
(i.e., using Dependabot automated dependency update).
• sec/nconf: Security PRs opened when the project does
not have a dependabot.yml ﬁle in its repository. Such
PRs are opened either before the adoption or after the
deprecation of Dependabot automated dependency up-
date.

Where necessary, we examine the signiﬁcance of inter-group
metric differences with unpaired Mann-Whitney tests and
Cliff’s delta (denoted as δ).

5.2.2 Results

Table 6 summarizes the PR statistics we obtain for each
group. The high merge rates (all of which >70%) indicate
developers are highly receptive to Dependabot PRs, be
them automated dependency updates or security updates.
They are more receptive to security PRs: their merge rate is
74.53%, even higher than 65.42% reported on Dependabot
Preview security updates [60]. This may be because devel-
opers welcome security updates even more, or just because
the projects we selected are such.

Alfadel et al. [60] ﬁnd that Dependabot security PRs
take longer to close than to merge. Our data illustrate
a similar story, with the automated dependency updates
taking around four hours to merge and more than three days

9

to close on median. The difference is statistically signiﬁcant
with strong effect size (p < 0.001, δ = 0.91).

The response lag, however, does not differ much from
the merge lag in all groups, which conﬁrms the timeliness of
developers’ response towards Dependabot PRs. We observe
human activities in 360,126 (72.2%) automated dependency
update PRs, among which 280,276 (77.8%) take less than
one day to respond. However, this also indicates an incon-
sistency between fast responses and slow closes. As a glance
at what caused this inconsistency, we sample ten closed
PRs with developers’ activities before closing and inspect
their event history. We ﬁnd 9 out of 10 PRs are closed by
Dependabot itself, for the PR being obsolete due to the re-
lease of a newer version or a manual upgrade. Activities are
development-related (e.g., starting a discussion, assigning
reviewers) in 5 PRs, while the rest are interactions with
Dependabot (e.g., @dependabot rebase).

Contrary to our expectations, security updates require a
statistically longer time to merge (p < 0.001, δ = 0.87), close
(p < 0.001, δ = 0.72), and respond (p < 0.001, δ = 0.87)
regardless of whether the project is using automated de-
pendency updates. Though automated dependency update
users do process security updates quicker (at least merge
lag and response lag are noticeably shorter), this difference
is not that signiﬁcant with negligible or small effect sizes
(δ ≤ 0.23 for all metrics).

5.2.3 Validation with Survey

In general, developers agree that Dependabot PRs do not
require much work to review and merge (34.1% Strongly
Agree, 40.3% Agree, 14.0% Neutral).

We ﬁnd that they follow two different patterns of using
Dependabot. One pattern is to rapidly merge the PR if the
tests pass and manually perform the update by hand oth-
erwise (65.2% Strongly Agree, 19.7% Agree, 9.1% Neutral).
In the latter case, they will respond to the Dependabot PR
slower, or let Dependabot automatically close the PR after
the manual update (36.4% Strongly Agree, 26.5% Agree,
20.5% Neutral). For example:

I almost never have to look at Dependabot PRs because I
have tests, and 99.99% of PRs are merged automatically.
Rarely (when dependency changes API for example) I have
to manually add some ﬁxes/updates...

As mentioned in Section 5.1.3, another pattern is to use
Dependabot PRs solely as a way of notiﬁcation and always
perform manual updates. Both cases contribute to the much
larger close lag we observe in Dependabot PRs.

In terms of security updates, most developers do handle
security PRs with a higher priority (56.7% Strongly Agree,
16.3% Agree, 14.0% Neutral), but they do not think security
PRs require more work to review and merge (19.4% Totally
Disagree, 36.4% Disagree, 26.4% Neutral). One possible
explanation for the slower response, merge, and close of
security PRs is that developers consider some security vul-
nerabilities as irrelevant to them:

I want it (Dependabot) to ignore security vulnerabilities
in development dependencies that don’t actually get used
in production.
Developers have a mixed opinion on whether Depend-
abot opens more PRs than they can handle (15.9% Strongly

IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

10

Agree, 15.2% Agree, 22.0% Neutral, 20.5% Disagree, 26.5%
Totally Disagree). This indicates that whether the PR work-
load introduced by Dependabot is acceptable depends on
other factors, such as the number of project dependencies
and how fast packages evolve in an ecosystem:
1) The performance of Dependabot or other similar bots could
depend on the number of dependencies a project has. For
smaller projects, with a handful of dependencies, Dependabot
will be less noisy and usually safe as compared to large projects
with a lot of dependencies.

2) The utility of something like Dependabot depends heavily on
the stack and number of dependencies you have. JS is much
more noisy than Ruby, for example, both because Ruby moves
more slowly.

Findings for RQ2:

Developers are generally responsive and receptive to
Dependabot PRs: more than 70% of the PRs are merged
with a median merge lag of only four hours. Compared
with regular PRs, developers are less responsive (i.e.,
more time to respond, close or merge) but more recep-
tive (i.e., higher merge rate) to security PRs. Developers
tend to rapidly merge PRs that they consider “safe” and
perform manual updates for the remaining PRs.

5.3 RQ3: Compatibility Score

5.3.1 Method

We explore the effectiveness of compatibility scores in two
aspects: Availability, and Correlation with Merge Rate.

1) Availability: We begin our analysis by understanding
the data availability of compatibility scores, for they would
not take effect if they are absent from most of the PRs. For
this purpose, we obtain compatibility scores from badges
in PR bodies, which point to URLs deﬁned per dependency
version pair. That is, Dependabot computes one compatibility
score for each dependency version pair (cid:104)d, v1, v2(cid:105) and show
the score to all PRs that update dependency d from v1 to
v2. In case this computation fails, Dependabot generates an
unknown compatibility score for (cid:104)d, v1, v2(cid:105).

Since compatibility scores are computed in a data-driven
manner, we wonder if the popularity of the updated depen-
dencies affects their availability. As a quick evaluation, we
sample 20 npm dependencies with more than one million
downloads per week as representatives for popular depen-
dencies. Next, we retrieve the release history of these depen-
dencies by querying the npm registry API, retaining only
releases that came available after January 1, 2020 (recall that
all Dependabot PRs in our dataset are created after January
2020, Section 4). For the releases in each dependency, we
get all possible dependency version pairs from a Cartesian
product (1,629 in total) and query their compatibility scores
from corresponding Dependabot URLs.

2) Correlation with Merge Rate: In theory, if developers
perceive compatibility scores as reliable, PRs with higher
compatibility scores will be more likely to get merged. To
quantitatively evaluate this, we compare merge rates for PRs
with different compatibility scores. Since PRs that update
the same version pair share the same score, we further
utilize Spearman’s ρ to measure the correlation between a)

(a) Compatibility Score

(b) # of Available CI Checks

Fig. 5: Distribution of compatibility scores and available CI
checks over the version pairs of axios.

TABLE 7: Compatibility Score and PR Merge Rate

Compatibility Score

# of PRs Merge Rate

unknown
< 80%
< 90%, >= 80%
< 95%, >= 90%
< 100%, >= 95%
== 100%

485,501
1,321
1,605
1,794
2,228
10,303

69.96%
30.20%
67.48%
73.19%
84.43%
80.30%

compatibility score for a dependency version pair (cid:104)d, v1, v2(cid:105),
and b) merge rate for all PRs that update d from v1 to v2.

As we will show in Section 5.3.2, compatibility scores are
abnormally scarce. Although we have reached Dependabot
maintainers for explanations, they claim such information to
be conﬁdential and refuse to share us any details. To provide
possible explanations, we compute the number of CI check
results for each dependency version pair and analyze their
overall distribution.

5.3.2 Results
1) Availability: We ﬁnd that compatibility scores are
extremely scarce: only 3.4% of the PRs and 0.5% of the
dependency version pairs have a compatibility score other
than unknown. Merely 0.18% of the dependency version pairs
have a value other than 100%. Its scarcity does not become
better even among the most popular npm dependencies:
1,604 (98.5%) of the 1,629 dependency version pairs we
sample only have a compatibility score of unknown, 10 (0.6%)
have a compatibility score of 100%, and 15 (0.9%) have a
compatibility score less than 100%. As an example, we plot
a compatibility score matrix for axios, which has the most
(15) version pairs with compatibility scores, in Figure 5a.

2) Correlation with Merge Rate: We summarize the
merge rates for PRs with different compatibility scores in
Table 7. We can observe that for PRs with a compatibility
score, a high score indeed increases their chance of being
merged: if the score is higher than 90%, developers are more
likely to merge the PR. By contrast, if the score is lower than
80%, developers become very unlikely (30.20%) to merge.
The Spearman’s ρ between compatibility score and merge
rate is 0.37 (p < 0.001), indicating a weak correlation
according to Prion and Haerling’s interpretation [80].

Figure 6 shows the number of dependency version pairs
with more than x CI check results. We can observe an
extreme Pareto-like distribution: for the 167,053 dependency
version pairs in our dataset, less than 1,000 have more than

0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%0%96%0%0%97%0%0%0%0%0%0%0%0%0%0%96%0%0%0%0%0%0%0%0%0%0%98%0%100%0%0%0%0%0%0%0%0%87%83%0%88%0%0%0%0%0%0%0%83%0%0%75%100%0%0%0%0%0%0%82%0%0%91%67%100%0%0.19.10.19.20.20.00.21.00.21.10.21.20.21.30.21.40.22.00.23.00.24.00.24.00.23.00.22.00.21.40.21.30.21.20.21.10.21.00.20.00.19.20.19.1Current VersionUpdated Version000000000000000000000004800000000001267000000000471195000000001109300000000004600000001001124370000000063066000000041018450000004202085400.19.10.19.20.20.00.21.00.21.10.21.20.21.30.21.40.22.00.23.00.24.00.24.00.23.00.22.00.21.40.21.30.21.20.21.10.21.00.20.00.19.20.19.1Current VersionUpdated VersionIEEE TRANSACTIONS ON SOFTWARE ENGINEERING

11

Fig. 6: # of dependency version pairs with more than x CI
check results. Note that the y axis is log-scale.

50 CI check results and less than 100 have more than 150
CI check results. For the case of axios (Figure 5b), the
compatibility scores are indeed only available for version
pairs with available CI checks. It is hard to explain why the
scores are missing even for some version pairs with many
CI checks (e.g., the update from 0.19.2 to 0.20.0), as we
do not know the underlying implementation details.

5.3.3 Validation with Survey

Developers have diverged opinions on whether compatibil-
ity scores are available (7% Strongly Agree, 24.8% Agree,
38.8% Neutral, 17.8% Disagree, 11.6% Totally Disagree)
and whether compatibility scores are effective if they are
available (4.7% Strongly Agree, 21.7% Agree, 45.7% Neu-
tral, 19.4% Disagree, and 8.5% Totally Disagree). The an-
swer distributions and the high number of Neural responses
likely indicate that many developers do not know how to
rate the two statements [81], because compatibility scores
are too scarce and most developers have not been exposed
to this feature. For example:

Compatibility scores and vulnerable dependencies detec-
tion are great, I use Dependabot a lot but was not aware
they exist...(They) should be more visible to the user.

One developer do explicitly express concerns that com-
patibility scores are not effective, saying that Dependabot’s
compatibility score has never worked for me.

Further, many developers (6 responses in our survey)
hold the belief that Dependabot only works well in projects
with a high-quality test suite. For example:

1) Dependabot works best with a high test coverage and if it fails
people it’s likely because they have too little test coverage.
2) Dependabot without a good test suite is indeed likely too noisy,
but with good tests and an understanding of the code base it
is trivial to know whether an update is safe to update or not.

Findings for RQ3:

Compatibility scores are too scarce to be effective: only
3.4% of PRs have a known compatibility score. For
those PRs with one, the scores have a weak correlation
(ρ = 0.37) with PR merge rate. Its scarcity may be
because most dependency version pairs do not have
sufﬁcient CI check results (i.e., a Pareto-like distribu-
tion) for inferring update compatibility. Consequently,
developers think Dependabot’s automated updates are
only reliable in projects with a high-quality test suite.

5.4 RQ4: Conﬁguration

5.4.1 Method

Dependabot offers tons of conﬁguration options for integra-
tion with project workﬂows, such as who to review, how
to write commit messages, how to label, etc. In this research
question, we only focus on the options related to notiﬁcations
because we expect them to be possible countermeasures
against noise and notiﬁcation fatigue. More speciﬁcally, we
investigate the following options provided by Dependabot:
1) schedule.interval: This option is mandatory and spec-
iﬁes how often Dependabot scans project dependencies,
checks for new versions, and opens PRs to update de-
pendencies. Possible values include "daily", "weekly",
and "monthly".

2) open-pull-requests-limit: This option speciﬁes the
maximum number of simultaneously open Dependabot
PRs allowed in a project. The default value is ﬁve.

3) allow: This option tells Dependabot to only update on
a subset of project dependencies. By default, all depen-
dencies are updated.

4) ignore: This option tells Dependabot to ignore a subset
of project dependencies. By default, no dependency is
ignored.

The latter two options are very ﬂexible and may contain con-
straints exclusive to some package ecosystems, e.g., allow-
ing updates in production manifests or ignoring patch up-
dates according to the semantic versioning convention [35].
To understand developers’ current practice of conﬁg-
uring Dependabot, we parse 3,921 Dependabot conﬁg-
urations from 1,588 projects with a dependabot.yml in
their current working tree.6 For schedule.interval and
open-pull-requests-limit, we count the frequency of
each value. For allow and ignore, we parse different op-
tions and group them into three distinctive strategies:
1) default: allowing Dependabot to update all dependen-

cies, which is its default behavior;

2) permissive: conﬁguring Dependabot to ignore a subset

of dependencies;

3) restrictive: conﬁguring Dependabot to only update on a

subset of dependencies.

We further explore the modiﬁcation history of Depend-
abot conﬁgurations to observe how developers use con-
ﬁguration as a countermeasure against noise in the wild.
For this purpose, we ﬁnd all commits in the 1,823 projects
that modiﬁed dependabot.yml and extract eight types of
conﬁguration changes from ﬁle diffs:
1) +interval: Developers increase schedule.interval.
2) -interval: Developers decrease schedule.interval.
3) +limit: Developers increase open-pull-requests-limit.
4) -limit: Developers decrease open-pull-requests-limit.
5) +allow: Developers allow some more dependencies to

be automatically updated by Dependabot.

6) -allow: Developers no longer allow some dependencies

to be automatically updated by Dependabot.

6. Note that 235 of the 1,823 projects in our dataset do not have
dependabot.yml in their current working tree which we will investigate
in RQ5. One project may depend on more than one package ecosystem
(e.g., both npm and PyPI) and thus have separate conﬁgurations for
each package ecosystem.

05010015020025010100100010k100kThreshold for # of CI Checks# of Version PairsIEEE TRANSACTIONS ON SOFTWARE ENGINEERING

12

ten Dependabot bothers developers to a large extent, and
we are seeing developers of 336 projects increasing it in
868 conﬁgurations. We further conﬁrm this behavior as
a countermeasure against noise from a real-life example
where developers reduce the frequency to monthly to reduce
noise [82]. open-pull-requests-limit quantiﬁes the devel-
opers’ workload on each interaction, which is also noise-
related as indicated by a developers’ complaint: Dependabot
PRs quickly get out of hand [83]. If we focus on modiﬁcations
that happen 90 days after Dependabot adoption, we ﬁnd
nearly two-thirds (62.5%) of open-pull-requests-limit
changes belong to -limit. Our observations indicate the
following phenomenon. At the beginning of adoption, de-
velopers conﬁgure Dependabot to interact frequently and
update proactively. However, they later get overwhelmed
and suffer from notiﬁcation fatigue, which causes them to
reduce interaction with Dependabot or even deprecate De-
pendabot (RQ5). As an extreme case, one developer forces
Dependabot to open only 1 PR at a time to reduce noise [84].
Ignoring certain dependencies seems to be another noise
countermeasure, for developers tend to add an ignored
dependency more often than remove one (Figure 7). For
example, a commit says update ignored packages...so they are
never automatically updated to stop noise [85]. However, we
also observe cases where developers add ignored depen-
dencies due to other intentions, such as handling breaking
changes [86] and preserving backward compatibility [87].
For +allow and -allow, we observe an interesting burst of
-allow (Figure 8c) earlier but more +allow dependencies
later, but we do not ﬁnd any evidence explaining such trend.

5.4.3 Validation with Survey

Although more than half of respondents think Dependabot
can be conﬁgured to ﬁt their needs (25.6% Strongly Agree
and 30.2% Agree), some do not (7.8% Totally Disagree
and 14% Disagree). As a peek into this controversy, one
developer says, I think people that complain about how noisy it
is (I’ve seen a lot of this) just don’t conﬁgure things correctly.

More than half (50.4%) of respondents have conﬁgured
Dependabot to make it less noisy, but roughly one-third
(32.6%) have not (21.2% Strongly Agree, 29.5% Agree,
16.7% Neutral, 20.5% Disagree, 12.1% Totally Disagree). It
is possible that the default conﬁgurations of Dependabot
only work for projects with a limited number of depen-
dencies and these dependencies are not fast-evolving (see
Section 5.2.3); for other projects, developers need to tweak
the conﬁgurations multiple times to ﬁnd a sweet spot for
their projects. However, many respondents eventually ﬁnd
that Dependabot does not offer the options they want for
noise reduction, such as update grouping and auto-merge.
We will investigate this in-depth in RQ5 and RQ6.

Findings for RQ4:

The majority of Dependabot conﬁgurations tend to
preserve a proactive setting towards Dependabot PRs,
but we observe multiple patterns of noise avoidance
from conﬁguration modiﬁcations, such as increasing
schedule interval,
lowering the allowed number of
open PRs, and ignoring certain dependencies.

Fig. 7: Distribution of conﬁguration modiﬁcations by type.

(a) schedule.interval

(b) open-pull-requests-limit

(c) allow

(d) ignore

Fig. 8: Conﬁg. modiﬁcations since Dependabot adoption.

7) +ignore: Developers conﬁgure Dependabot to ignore

some dependencies for automated update.

8) -ignore: Developers conﬁgure Dependabot to no longer

ignore some dependencies for automated update.
Finally, we analyze conﬁguration modiﬁcations by time
since Dependabot adoption. We mainly focus on the bursts
of modiﬁcation patterns, because bursts illustrate the lag
from the developers’ perception of noise to their counter-
measures to mitigate the noise.

5.4.2 Results

The current conﬁgurations of Dependabot show that most
projects conﬁgure Dependabot toward a proactive update
strategy: 2,203 (56.2%) of schedule.interval are "daily"
them are a conservative
while merely 276 (7.04%) of
"monthly". 1,404 (35.8%) of the open-pull-requests-limit
conﬁgurations are higher above the default value while only
a negligible proportion (2.3%) are lower. For allow and
ignore options, most of the conﬁgurations (3,396, 86.7%)
adopt the default strategy, less (380, 9.7%) use permissive,
and a small proportion (50, 1.3%) use restrictive.

The modiﬁcations tell us another story. 776 (42.57%)
of the 1,823 projects in our dataset have modiﬁed the
Dependabot conﬁguration options we study (e.g., update
interval) and they contain 2.18 modiﬁcation commits on av-
erage (median = 1.00). Figure 7 illustrates the proportion of
each modiﬁcation type, which shows that projects increase
schedule.interval and lower open-pull-requests-limit
more frequently than doing the opposite. As demonstrated
in Figure 8, projects can increase schedule.interval any
time after Dependabot adoption but more likely to reduce
open-pull-requests-limit only after several months of
Dependabot usage. schedule.interval determines how of-

+ (197)+ (911)+ (868)+ (447)- (156)- (502)- (181)- (560)05001000allow ignore interval limit 0200400600Time since adoption (days)+interval-interval0200400600800Time since adoption (days)+limit-limit0200400600800Time since adoption (days)+allow-allow0200400600800Time since adoption (days)+ignore-ignoreIEEE TRANSACTIONS ON SOFTWARE ENGINEERING

13

TABLE 8: Reasons for Dependabot Deprecation

Reason

# of Deprecations∗

Notiﬁcation Fatigue
Lack of Grouped Update Support
Package Manager Incompatibility
Lack of Conﬁgurability
Absence of Auto-Merge
Dependabot Bugs
Unsatisfying Branching Support
Inability to Modify Custom Files

∗ 27 deprecations in total.

9 (33.33%)
7 (25.93%)
7 (25.93%)
5 (18.52%)
3 (11.11%)
2 (7.41%)
1 (3.70%)
1 (3.70%)

PRs as the central issue in their experience with Depend-
abot. As noted by one developer:

I’ve been going mad with dependabot alerts which are
annoying and pointless. I’d rather do manual upgrades
than use this [88].
2) Lack of Grouped Update Support (7 Deprecations):
By the Dependabot convention, each PR updates one de-
pendency and one dependency only, which comes unhandy
in two scenarios: a) related packages tend to follow similar
release schedules, which triggers Dependabot to raise a PR
storm on their updates [89]; b) in some cases, dependencies
must be updated together to avoid breakages [90].

The excessive notiﬁcations and additional manual work

quickly frustrate developers. For example:
a) My hope was that we can better group dependency upgrades.
With the default conﬁguration there is some grouping hap-
pening, but most dependencies would be upgraded individu-
ally [91];

b) Also, a lot of packages have to be updated together. Separate

PRs for everything isn’t very fun [92].
3) Package Manager Incompatibility (7 Deprecations):
Developers may encounter compatibility issues after the
introduction of a new package manager or a newer version
of the package manager. In the seven cases we have found,
ﬁve concern yarn v2, one concerns npm v7 (speciﬁcally
lockﬁle v3), and one concerns pnpm. To make matters
worse, Dependabot may even have undesirable behaviors,
e.g., messing around with yarn lockﬁles [93], when en-
countered with such incompatibilities. This contributes to
developers’ update suspicion, as merging pull requests leads
to possible breakages in dependency speciﬁcation ﬁles. At
the time of writing, Dependabot still has no clear timeline
on supporting pnpm [94] or yarn v2 [95]. For the unlucky
part of Dependabot users, it means to revert [96], to patch
Dependabot PRs manually or automatically [97], or to mi-
grate to an alternative, e.g., Renovate Bot [98].

4) Lack of Conﬁgurability (5 Deprecations): Depend-
abot is also deprecated due to developers’ struggle to tailor
a suitable conﬁguration. For example:
a) it appears that we’re not able to conﬁgure Dependabot to only

give us major / minor upgrades [99];

b) Dependabot would require too much conﬁguration long-term
– too easy to forget to add a new package directory [100].
Developers mention that other dependency management
bots can provide more ﬁne-grained conﬁguration options
such as update scope and schedule:

(Renovate Bot) has a load more options we could tweak
too compared to Dependabot if we want to reduce the
frequency further [101].

Fig. 9: Number of deprecations in each month.

5.5 RQ5: Deprecation

5.5.1 Method

To locate projects that have possibly deprecated De-
pendabot, we ﬁnd projects with no dependabot.yml in
their current working trees, resulting in 235 projects. For
each of them, we identify the last commit that removes
dependabot.yml, inspect their commit messages, and iden-
tify any referenced issues/PRs following the GitHub con-
vention. If the dependabot.yml removal turns out to be due
to a project restructure or stop of maintenance, we consider
it as a false positive and exclude it from further analysis.

For the remaining 206 projects, we analyze reasons for
deprecation from commit messages and issue/PR text (i.e.,
titles, bodies, and comments). Since a large proportion of
text in commit messages, issues, and PRs are irrelevant
to Dependabot deprecation reasons (e.g., remove depend-
abot.yml), two authors read and re-read all text in the corpus,
retaining only the relevant. They encode reasons from text
and discuss them until reaching a consensus. They do not
conduct independent coding and measure inter-rater agree-
ment because the corpus is very small (only 27 deprecations
contain documented reasons).

For each of the conﬁrmed deprecations, we check bot
conﬁguration ﬁles and commit/PR history to ﬁnd possible
migrations. We consider a project as having migrated to
another dependency management bot (or other automation
approaches) if it meets any of the following criteria:
1) developers have speciﬁed the migration target in the

commit message or issue/PR text;

2) dependabot.yml is deleted by another dependency man-
agement bot (e.g., Renovate Bot automatically deletes
dependabot.yml in its setup PR);

3) the project adopts another dependency management bot
within 30 days before or after Dependabot deprecation.

5.5.2 Results

We conﬁrm 206 of the 235 candidates to be real-life De-
pendabot deprecations, which is substantial considering
our dataset only contains 1,823 projects. From Figure 9,
we can observe that Dependabot deprecations are evenly
distributed over time in general with a few ﬂuctuations,
mostly coming from organization-wide deprecations. For
instance, the maximum value in December 2020 is caused by
26 Dependabot deprecations in octokit, the ofﬁcial GitHub
API client implementation.

We encode nine categories of reasons from the 27 depre-

cations that explicitly mentioned their reasons (Table 8):

1) Notiﬁcation Fatigue (9 Deprecations): Developers
do recognize Dependabot’s overwhelming notiﬁcations and

2020-072020-082020-092020-102020-112020-122021-012021-022021-032021-042021-052021-062021-072021-082021-092021-102021-112021-122022-012022-020102030102030Month# of DeprecationsIEEE TRANSACTIONS ON SOFTWARE ENGINEERING

14

5) Absence of Auto-Merge (3 Deprecations): Alfadel
et al. [60] illustrate that auto-merge features are tightly
associated with rapid PR merges. However, GitHub refused
to offer this feature in Dependabot [102], claiming that auto-
merge allows malicious dependencies to propagate beyond
the supervision of project maintainers. This may render De-
pendabot impractical, as claimed by a developer: (the absence
of auto-merge) creates clutter and possibly high maintenance load.
We notice a non-negligible proportion (8.17%) of pull
requests are merged by third-party auto-merge implemen-
tations, in the form of a CI workﬂow or a GitHub App.
Unfortunately, they may become dysfunctional on public
repositories after GitHub enforced a change on Dependabot
PR triggered workﬂows [103]. This turns out to be the last
straw for several Dependabot deprecations. As a developer
states, they dropped Dependabot because latest changes en-
forced by GitHub prevents using the action in Dependabot’s PR’s
context.

6) High CI Usage (3 Deprecations): Maintainers from
3 projects complain that Dependabot’s substantial, auto-
rebasing PRs have devoured their CI credits. In their words,
Dependabot’s CI usage is what killed us with Dependabot, and
a waste of money and carbon.

Other reasons for Dependabot deprecation include: 7)
Dependabot Bugs (2 Deprecations), 8) Unsatisfying of
Branch Support (1 Deprecation), and 9) Inability to Modify
Custom Files (1 Deprecation).

The deprecation of Dependabot does not necessarily
mean developers’ loss of faith in automating dependency
updates. Actually, more than two-thirds (141/206) of the
projects turn to another bot or set up custom CI workﬂows
to support their dependency updates. Among them, Reno-
vate Bot (122) is the most popular migration target, followed
by projen (15), npm-check-updates (2) and depfu (1).

5.5.3 Validation with Survey

Among the 131 surveyed developers, 14 (10.7%) tell us
they have deprecated Dependabot in their projects. Most
of the reasons they provide fall within our analysis and
the frequency distribution is highly similar. There are two
exceptions: one deprecates because Dependabot frequently
breaks code and one deprecates because their entire project
has been stalled.

Developers also respond in our survey that they think
automated dependency management is important and ben-
eﬁcial for their projects but the limitations of Dependabot
causes them to do the deprecation. For example: Dependabot
could be great, it just needs a few ﬁxes here and there. It’s unclear
why Dependabot hasn’t been polished. They also reply to us that
Renovate Bot does provide some features that they need
(e.g., grouped update PRs).

Findings for RQ5:

11.3% of the studied projects have deprecated De-
pendabot due to notiﬁcation fatigue, lack of grouped
update support, package manager incompatibility, lack
of conﬁgurability, etc. More than two-thirds of them
turn to other ways of automation, among which the
most common migration target is Renovate Bot (86.5%).

TABLE 9: Developers’ Desired Features

Desired Feature

# of Respondents∗

Group Updates PRs
Package Manager Support
Auto-Merge
Display Release Notes
Avoid Unnecessary Updates
Custom Update Action
Conﬁgurability
git Support
Breaking Change Impact Analysis
∗

84 respondents in total.

29 (34.52%)
20 (23.81%)
19 (22.62%)
8 (9.52%)
7 (9.76%)
5 (5.95%)
5 (5.95%)
4 (4.76%)
3 (3.57%)

5.6 RQ6: Desired Features

5.6.1 Method

To obtain the developers’ desired features for a dependency
management bot, we ask two optional open-ended ques-
tions at the end of the survey (Table 2):
1) Regardless of current availability, what are the features
you want most for a bot that updates dependencies?

2) Do you have any further opinions or suggestions?7
The two questions are answered by 97 and 46 developers,
respectively. To identify recurring patterns from the an-
swers, two authors of this paper (both with >6 years of
software development experience and familiar with using
Dependabot) conduct open coding [104] on the responses
to generate an initial set of codes for developers’ desired
features. More speciﬁcally, they ﬁrst read and re-read all
answers to familiarize themselves with and gain an initial
understanding of them. Then, one author assigns text in
answers to some initial codes that reﬂects some common
features in dependency management bots and discusses
with the other author to iteratively reﬁne the codes until
a consensus is reached. They further conduct independent
coding on the answers using the reﬁned codes and exclude
answers that do not reﬂect anything related to this RQ.
As each response may contain multiple codes, we use
MASI distance [105] to measure the distance between two
raters’ codes and Krippendorff’s alpha [106] to measure
inter-rater reliability. The Krippendorff’s alpha we obtain
is 0.865, which satisﬁes the recommended threshold of 0.8
and indicates a high reliability [107].

Finally, we identify nine major categories of developers’
desired features (each corresponds to one code) from the
answers provided by 84 respondents and discard the re-
maining categories that are only supported by one answer
(which thus may be occasional and not generalizable). We
will introduce the nine major categories in the next Section.

5.6.2 Results

Table 9 summarizes developers’ desired features for depen-
dency management bots. In this section, we will explain
each category in the order of popularity.

1) Group Update PRs (29 Respondents): This cate-
gory refers to the feature of automatically grouping some
dependency updates into one PR instead of opening one
PR for each update. It is most frequently mentioned and
developers consider this feature as an important measure

7. This question was originally not intended for RQ6, but we ﬁnd in
our responses that many respondents answer their desired features in
both questions, so we include both questions in the analysis of RQ6.

IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

15

for making the handling of bot PRs less tedious, repetitive,
and time-consuming. They want the bot to automatically
identify dependencies that should be updated together and
merge them into one PR update because many libraries (e.g.,
symfony, @typescript-eslint, babel) version all packages under
a single version. They also want the bot to automatically
ﬁnd and merge “safe” updates into one PR while leaving
“unsafe” updates as single PRs for more careful reviewing.
2) Package Manager Support (20 Respondents): This
category refers to the feature of supporting more package
managers (and their corresponding ecosystems) or features
for the bot to align with the conventions in the package man-
ager/ecosystem. Developers have expressed their desire for
the bot to support Gradle, Flatter, Poetry, Anaconda, C++,
yarn v2, Clojure, Cargo, CocoaPods, Swift Package Manager
(in iOS), etc., indicating that dependency management bots,
if well designed and implemented, can indeed beneﬁt a
wide range of developers and software development do-
mains. Dependabot does claim support for many package
managers mentioned before but it still needs to be tailored
and improved in, e.g., performance and update behaviors:
a) When I have 3 open Poetry updates I can merge one and then

have to wait 15 minutes for the conﬂicts to be resolved.

b) Perhaps for node.js projects the ability to update package.json
in addition to package.lock, so the dependency update is made
explicit.
3) Auto-Merge (19 Respondents): This category refers
to the feature of automatically merging some update PRs
into the repository if certain conditions are satisﬁed. As
mentioned in Section 5.3.3, some developers believe as long
as their projects have high-quality test suites, it will be trivial
to review the update PR and they would prefer them to be
merged automatically if the tests pass.

Despite the signiﬁcant demand, this feature also seems
to be especially controversial because doing this means
ofﬂoading trust and giving bot autonomy. Although GitHub
considers it unacceptable due to security risks [102], our
survey clearly indicates that many still want to do this
even if they are well aware of the risks. They also think
the responsibility of risk control, e.g., vetting new releases,
should be given to some capable central authority, not them.
Here are three response examples:
a) While this might be somewhat dangerous, and should be con-
ﬁgurable somehow, [auto-merge] is something that basically
already happens when I merge such PRs.

b) If I am merging with Dependabot like 60 deps a day - I don’t
know if some of the versions are not published by hackers who
took over the repository account, so it would be great if there
was some authority where humans actually check the changes
and mark them secure.

c) For me it’d be good if I could mute all notiﬁcations about
Dependabot PRs except for when tests failed, indicating that I
need to manually resolve some issues. Otherwise I’d be happy
not to hear about it updating my deps.
4) Display Release Notes (8 Respondents): This cate-
gory refers to the feature of always showing some sort of
release notes or change logs in update PRs to inform devel-
opers of the changes in an update. Although Dependabot
sometimes can provide release notes in PRs (Figure 1), it
fails for 24.8% of the PRs in our dataset. One possible reason

for this is that release notes are often missing or inaccessible
in open source projects [39], which is also conﬁrmed by one
of our survey respondents:

Most npm package updates feel unnecessary and the main-
tainers very often don’t bother to write meaningful release
notes...At the same time, I shouldn’t expect maintainers to
go through all of their dependencies’ changelogs either, so
perhaps the tool should ﬁnd those release notes for me.

5) Avoid Unnecessary Updates (7 Respondents): This
category refers to the feature of providing a default behav-
ior and conﬁguration options to avoid updates that most
developers in an ecosystem perceived as unnecessary. The
most frequently mentioned feature is the ability to deﬁne
separate update behaviors for development and production
(or runtime) dependencies. Many developers would avoid
the automatic update of development dependencies because
they perceive such updates as mostly noise and there is very
little gain in keeping development dependencies up-to-date.
Other mentioned features include the ability to detect and
avoid updates on bloated dependencies and to only provide
updates for dependencies with real security vulnerabilities.
6) Custom Update Action (5 Respondents): This cat-
egory of features refers to the ability to deﬁne custom
update behaviors (using, e.g., regular expressions) to update
dependencies in unconventional dependency ﬁles.

7) Conﬁgurability (5 Respondents): This category refers
to the case of developers expressing that dependency man-
agement bots should be highly conﬁgurable, but does not
provide any further information on the speciﬁc conﬁgura-
tion options they want, e.g., more conﬁguration options.

8) git Support (4 Respondents): This category of fea-
tures concerns the integration of dependency management
bots with the version control system (in our case, git). The
speciﬁc mentioned features include automatic rebase, merge
conﬂict resolution, squashing, etc., all of which help ensure
that bot PRs will not incur additional work on developers
(e.g., manipulating git branches and resolving conﬂicts).

9) Breaking Change Impact Analysis (3 Respondents):
This category of features refers to the ability to perform
program analysis to identify breaking changes and their
impact on client code. For example:

Something like a list of parts of my codebase that might
be impacted by the update would be useful. This could
be based on a combination of changes listed in the release
notes and an analysis of where the package is used in my
code.

The developers’ desired features we identify in RQ6
align well with the reasons of Dependabot deprecation we
ﬁnd in RQ5 (Section 5.5.2), indicating that feature availabil-
ity can be a key driver for the migrations and competitions
between dependency management bots.

Findings for RQ6:

We identify nine categories of developers’ desired fea-
tures for dependency management bots, among which
the most frequently mentioned are grouping update
PRs, package manager support, and auto-merging PRs.

IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

16

6 DISCUSSION

6.1 What Should be the Key Characteristics of a Depen-
dency Management Bot?

In this section, we try to summarize the key characteristics
of an ideal dependency management bot based on the
results from our analysis and previous work. We believe
they can serve as general design guidelines for practitioners
to design, implement, or improve dependency management
bots (or other similar automation solutions).

Conﬁgurability. Wessel et al. [44] argue that noise is
the central challenge in SE bot design and re-conﬁguration
should be the main countermeasure against noise. For the
case of Dependabot, we ﬁnd that Dependabot also causes
noise to developers by opening more PRs than developers
can handle (RQ2) and developers can re-conﬁgure multiple
times to reduce its noise (RQ4). However, re-conﬁguration
is not always successful due to the lack of certain features
in Dependabot (RQ6), causing deprecations and migrations
(RQ5). Just as many other software development activities,
it is also unlikely for a “silver bullet” to be present, as noted
by one of our survey respondents, ...there is no best practice
in dependency management which is easy, fast and safe.

Therefore, we argue that conﬁgurability, i.e., offering the
highest possible conﬁguration ﬂexibility for controlling its
update behavior, should be one of the key characteristics
of dependency management bots. This helps the bot to
minimize unnecessary update notiﬁcations and attempts so
that developers are less interrupted. Apart from the options
already provided by Dependabot, our study indicates that
the following conﬁguration options should be present in
dependency management bots:

1) Grouped Updates: Dependency management bots should
provide options to group multiple updates into one PR.
Possible options include to group all “safe” updates
(e.g., not breaking the CI checks) and updates of closely
related dependencies (e.g., different components from
the same framework).

2) Update Strategies: Dependency management bots should
allow developers to specify which dependency to update
based on more conditions, such as whether the depen-
dency is used in production, the severity of security
vulnerabilities, whether the dependency is bloated, etc.
3) Version Control System Integration: Dependency manage-
ment bots should allow developers to deﬁne how the
bot should interact with the version control system,
including which branch to monitor, how to manipulate
branches and handle merge conﬂicts, etc.

Autonomy. According to the SE bot deﬁnition by Erlen-
hov et al. [43], the key characteristics of an “Alex” type of
SE bot is its ability to autonomously handle (often simple)
development tasks and its central design challenges include
minimizing interruption and establishing trust with devel-
opers. However, without the auto-merge feature, Depend-
abot is hardly autonomous and this lack of autonomy is
disliked by many developers (RQ5, RQ6); in extreme cases,
developers use Dependabot entirely as a notiﬁcation tool
but not as a bot (Section 5.1.3). This lack of autonomy is
also causing a high level of interruption and workload to
developers using Dependabot in their projects (RQ6).

We argue that autonomy,

i.e., the ability to perform
dependency updates autonomously without human inter-
vention under certain conditions, should be one of the key
characteristics of dependency management bots. This char-
acteristic is only possible when the risks and consequences
of dependency updates are highly transparent and devel-
opers know when to trust these updates. Within the context
of GitHub, we believe the current dependency management
bots should offer the conﬁguration option to merge update
PRs when the CI pipeline passes. This option can be turned
on for projects that have a well-conﬁgured CI pipeline with
thorough static analysis, building, and testing stages, when
the developers believe that their pipeline can effectively de-
tect incompatibilities in dependency updates (Section 5.3.3).
With respect to the security concern of auto-merge be-
ing used to quickly propagate a malicious package across the
ecosystem [102], we argue that the responsibility of verifying
new releases in terms of security should not be given to
independent developers as they do not have the time and
expertise for this (RQ6). Instead, package hosting platforms
(e.g., npm, Maven, PyPI) should vet new package releases
and quickly take down malicious releases to minimize their
impact. These practices are also advocated in the literature
on software supply chain attacks [108].

Transparency. Multiple previous studies, both on SE bots
and on other kinds of software bots, point to the importance
of transparency in bot design. For example, Erlenhov et
al. [43] shows that developers need to establish the trust that
the bot can perform correct development tasks. Similarly,
Godulla et al. [109] argue that transparency is vital for
software bots used in corporate communications. In the
context of code review bots, Peng and Ma [110] ﬁnd that
contributors expect the bot to be transparent about why a
certain code reviewer is recommended. To reduce update
suspicion [10] in dependency management bots, developers
also need to know when to trust the bot to perform depen-
dency updates.

We argue that transparency, i.e., the ability to transpar-
ently demonstrate the risks and consequences of a depen-
dency update, should be one of the key characteristics of
dependency management bots. However, the Dependabot
compatibility score feature is hardly a success toward this
direction and developers only trust their own test suites.
Beyond compatibility scores and project test suites, the
following research directions may be helpful in enabling
transparency in dependency management bots and estab-
lishing trust in the bot users:
1) Program Analysis: One direction to achieve this is to
leverage program analysis techniques. There have been
signiﬁcant research and practitioner effort on breaking
change analysis [40], but it is unclear whether they will
be effective in assessing bot PRs. Given the extremely
large scale of bot PRs [9], one possible challenge is to
design an approach that are both lightweight, scalable,
and still sufﬁciently effective to be useful in practice.
2) CI Log Analysis: Another direction is to extend the idea
of compatibility score with sophisticated techniques that
learn more knowledge from CI checks. Since CI checks
are scarce for many version pairs (RQ3), it will be in-
teresting to explore techniques that transfer knowledge
from other version pairs so that the matrix in Figure 5a

IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

17

can be less sparse. The massive CI checks available from
Dependabot PRs would be a promising starting point.
3) Release Note Generation: Dependabot sometimes fails in
locating and providing a release note for the updated
dependency, and even if there is one, the maintainers very
often don’t bother to write meaningful release notes, as noted
by one respondent. This situation can be mitigated by
applying approaches on software change summarization
(e.g., [111]) and release note generation (e.g., [112]).
Self-Adaptability. The ability to adapt to the speciﬁc
environment and its dynamics is considered as one of the
key characteristics of a “rational agent” in artiﬁcial intelli-
gence [113], [114]. Dependency management bots can also
be considered as autonomous agents working in the artiﬁ-
cial environment of social coding platforms (e.g., GitHub).
However, for Dependabot, our ﬁndings reveal that De-
pendabot often cannot operate in the ways expected by
developers (RQ5, RQ6) and re-conﬁgurations are common
(RQ4). Such failures (e.g., update actions, package manager
incompatibility, git branching behaviors) will lead to inter-
ruption and extra work for developers.

We argue that self-adaptability, i.e., the ability to automat-
ically identify and self-adapt to a sensible default conﬁg-
uration in a project’s environment, should be one of the
key characteristics of dependency management bots. For
GitHub projects, its environment can include its major pro-
gramming languages, package managers & ecosystems, the
workﬂows used, the active timezone, developer preferences
and recent activities, etc. A dependency management bot
should have the ability to automatically generate a con-
ﬁguration ﬁle based on such information, and recommend
conﬁguration changes when the environment has changed
(e.g., developer responses to bot PRs become slower than
usual). This can be implemented via providing a semi-
automatic recommender system for recommending an ini-
tial conﬁguration to developers and prompting bot PRs for
modifying its own conﬁgurations after bot adoption.

6.2 Comparison with Previous Work

Several previous studies have also made similar recom-
mendations based on results from Greenkeeper or Depend-
abot [10], [41], [60], [62]. Studies on Greenkeeper [10], [41]
shows that dependency management bot causes noise to
developers and project CI checks are unreliable, but they do
not investigate the effectiveness of bot conﬁgurations as a
countermeasure against noise. Studies on Dependabot [60],
[62] either focuses on a different aspect (i.e., security up-
dates [60]) or provides speciﬁc recommendations on De-
pendabot features [62]. The recommendations from Cogo
and Hassan [62] can be conﬁrmed using the results from
our study and two dimensions of our recommendations
are not mentioned in their work (namely, Self-Adaptability
and Autonomy). To the best of our knowledge, we are
also the ﬁrst to quantitatively investigate the impact of
Dependabot adoption using the technical lag metric and
the RDD framework. To summarize, compared with the
previous studies, the contributions of our study are: 1) a sys-
tematic investigation of Dependabot usage in the wild, and
2) a comprehensive four-dimension framework for guiding
dependency management bot design.

The implications of our study is also somewhat related
to the larger literature of SE bots and dependency man-
agement. With respect to the two ﬁelds of studies, the
contribution of our study is a unique lens of observation,
i.e., Dependabot, that results in a set of tailored recommen-
dations for dependency management bot design. We have
carefully discussed in Section 6.1 how the implications of
our study conﬁrms, extends, or echoes with the results from
the literature on SE bots and dependency management.

6.3 Threats to Validity

6.3.1 Internal Validity

Several approximations are used throughout our analysis.
In RQ2, we resort to identify security PRs ourselves which
may introduce hard-to-conﬁrm errors (only repository own-
ers know whether their PRs are security related). In RQ3,
Dependabot’s compatibility scores may change over time
and it is impossible to know the score at time of PR creation.
In RQ4, Dependabot supports ecosystem speciﬁc matchers
in dependency speciﬁcations, e.g., @angular/*, which we
do not consider when parsing conﬁguration ﬁles. However,
we believe the noise introduced above should be minor and
will not invalidate our ﬁndings or hinder the reproducibility
of our data analysis. Like other studies involving manual
coding, our analysis of developer discussions and survey
responses are vulnerable to author bias. To mitigate this
threat, two authors double-check all results and validate
ﬁndings with project commit/PR histories for RQ5; they
further conduct inter-rater reliability analysis for RQ6 when
the dataset becomes larger. Finally, our own interpretation of
the data (RQ1 - RQ5) may also be biased towards our own
judgment. To mitigate this threat, we triangulate our key
ﬁndings using a developer survey and derive implications
based on both our analysis and developers’ feedback.

6.3.2 External Validity

Just like all case studies, generalizing our speciﬁc ﬁndings
in each RQ to other dependency management bots and even
to other projects that use Dependabot should be cautious.
Our dataset only contains popular and actively maintained
GitHub projects, many of which are already taking proac-
tive updating strategies. Therefore, our ﬁndings may not
generalize to projects of a smaller scale or more reluctant
to update dependencies. The outcome of Dependabot usage
may also not generalize to other dependency management
bots due to their functionality and user base differences.
However, we believe the implications we obtain for de-
pendency management bot design (Section 6.1) should be
general, as both Greenkeeper and Renovate Bot suffer from
noise and the limitations of using test results to indicate
breaking changes. The key characteristics we propose form
a roadmap for practitioners to improve existing dependency
management bots or develop new bots. Our methodology
could be applied in future studies to compare the effective-
ness of different bots.

7 CONCLUSION

In this paper, we have presented an exploratory study
on GitHub Dependabot, which we settle down into clear

IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

18

implications on dependency management bot design. We
ﬁnd that the current implementation of Dependabot is ef-
fective in notifying developers to update dependencies, but
has several limitations in automating dependency updates
and can hardly reduce dependency management work-
load for developers. From our ﬁndings, we derive a four-
dimension framework of ideal dependency management
bot characteristics (conﬁgurability, autonomy, transparency,
self-adaptation) in the hope that it can help dependency
management bot design and inspire more research work on
related ﬁelds.

Our study provides a unique lens of observation, i.e.,
dependency management bots, into the complexity of de-
pendency management and its automation in modern soft-
ware development. With the increasing awareness of supply
chain security in the software industry, we believe that
keeping dependencies up-to-date will be recognized as a
dependency management best practice by more and more
developers. As acknowledged by one of our survey respon-
dents, the alternative to keep up-to-date with dependency updates
is that your own project/library is slowly dying. We envision that
dependency management bots will play a pivotal role in its
automation but they are still far from being well polished
and various state-of-the-art software engineering research
can be integrated for improving the current practice.

Several possible directions of future work immediately
arises from our study. For example, an investigation and
comparison of other dependency management bots, espe-
cially Renovate Bot, can help verify the generalizability of
our framework for dependency management bot design. It
will also be interesting to investigate the recommendation
of bot conﬁgurations to developers, or to study how differ-
ent approaches (e.g., program analysis, machine learning,
release note generation) can help developers assess the
compatibility of bot update PRs.

ACKNOWLEDGMENTS

This work is supported by the National Key R&D Program
of China Grant 2018YFB1004201 and the National Natural
Science Foundation of China Grant 61825201. We would like
to sincerely thank the open source developers who have
participated in our survey.

REFERENCES

[1]

[2]

[3]

[4]

[5]

of

the

(2021,

January)

software
State
[Online]. Available: https://www.sonatype.

Inc.
Sonatype,
supply chain.
com/resources/state-of-the-software-supply-chain-2021
T. Winters, T. Manshreck, and H. Wright, Software Engineering at
Google: Lessons Learned from Programming over Time. O’Reilly
Media, 2020.
R. G. Kula, D. M. Germán, A. Ouni, T. Ishio, and K. Inoue, “Do
developers update their library dependencies? - an empirical
study on the impact of security advisories on library migration,”
Empir. Softw. Eng., vol. 23, no. 1, pp. 384–417, 2018. [Online].
Available: https://doi.org/10.1007/s10664-017-9521-5
E. Derr, S. Bugiel, S. Fahl, Y. Acar, and M. Backes, “Keep me
updated: An empirical study of third-party library updatability
on android,” in Proceedings of the 2017 ACM SIGSAC Conference on
Computer and Communications Security, CCS 2017, Dallas, TX, USA,
October 30 - November 03, 2017, 2017, pp. 2187–2200. [Online].
Available: https://doi.org/10.1145/3133956.3134059
(2022, January) Dependabot. [Online]. Available: https://github.
com/dependabot

[6]

[7]

[8]

January) Renovate bot.

[Online]. Available: https:

(2022,
//github.com/renovatebot
(2022, January) Python dependency security. [Online]. Available:
https://pyup.io/
(2022, January) Synk bot. [Online]. Available: https://github.
com/snyk-bot

[10]

and C. Parnin,

[9] M. Wyrich, R. Ghit, T. Haller, and C. Müller, “Bots don’t mind
waiting, do they? comparing the interaction with automatically
requests,” in 3rd IEEE/ACM
and manually created pull
International Workshop on Bots in Software Engineering, BotSE@ICSE
2021, Madrid, Spain, June 4, 2021.
IEEE, 2021, pp. 6–10. [Online].
Available: https://doi.org/10.1109/BotSE52550.2021.00009
S. Mirhosseini
“Can automated pull
requests encourage software developers to upgrade out-of-date
dependencies?” in Proceedings of the 32nd IEEE/ACM International
Conference on Automated Software Engineering, ASE 2017, Urbana,
IL, USA, October 30 - November 03, 2017, G. Rosu, M. D. Penta,
and T. N. Nguyen, Eds.
IEEE Computer Society, 2017, pp. 84–94.
[Online]. Available: https://doi.org/10.1109/ASE.2017.8115621
(2022,
management. [Online]. Available: https://greenkeeper.io/
[12] C. Bogart, C. Kästner, J. D. Herbsleb, and F. Thung, “When
and how to make breaking changes: Policies and practices in
18 open source software ecosystems,” ACM Trans. Softw. Eng.
Methodol., vol. 30, no. 4, pp. 42:1–42:56, 2021. [Online]. Available:
https://doi.org/10.1145/3447245

January) Greenkeeper | automated dependency

[11]

[13] G. Bavota, G. Canfora, M. D. Penta, R. Oliveto, and S. Panichella,
“How the apache community upgrades dependencies: an
evolutionary study,” Empir. Softw. Eng., vol. 20, no. 5, pp.
1275–1317, 2015. [Online]. Available: https://doi.org/10.1007/
s10664-014-9325-9

[15]

[16]

[14] P. Salza, F. Palomba, D. D. Nucci, C. D’Uva, A. D.
Lucia, and F. Ferrucci, “Do developers update third-party
libraries in mobile apps?” in Proceedings of the 26th Conference
on Program Comprehension, ICPC 2018, Gothenburg, Sweden, May
27-28, 2018, F. Khomh, C. K. Roy,
and J. Siegmund,
Eds. ACM, 2018, pp. 255–265.
[Online]. Available: https:
//doi.org/10.1145/3196321.3196341
I. Pashchenko, D. L. Vu, and F. Massacci, “A qualitative study of
dependency management and its security implications,” in CCS
’20: 2020 ACM SIGSAC Conference on Computer and Communica-
tions Security, Virtual Event, USA, November 9-13, 2020, J. Ligatti,
X. Ou, J. Katz, and G. Vigna, Eds. ACM, 2020, pp. 1513–1531.
[Online]. Available: https://doi.org/10.1145/3372297.3417232
and
J. Cox, E. Bouwers, M. C.
J. Visser, “Measuring dependency freshness
in software
systems,” in 37th IEEE/ACM International Conference on Software
Engineering, ICSE 2015, Florence, Italy, May 16-24, 2015, Volume 2,
A. Bertolino, G. Canfora, and S. G. Elbaum, Eds.
IEEE
Computer Society, 2015, pp. 109–118.
[Online]. Available:
https://doi.org/10.1109/ICSE.2015.140
J. M. González-Barahona, P. Sherwood, G. Robles, and
D. Izquierdo-Cortazar, “Technical lag in software compilations:
is,” in
Measuring how outdated a software deployment
Open Source Systems: Towards Robust Practices - 13th IFIP WG 2.13
International Conference, OSS 2017, Buenos Aires, Argentina, May
22-23, 2017, Proceedings, ser.
IFIP Advances in Information
and Communication Technology, F. Balaguer, R. D. Cosmo,
A. Garrido, F. Kon, G. Robles, and S. Zacchiroli, Eds.,
[Online]. Available: https:
vol.
//doi.org/10.1007/978-3-319-57735-7_17

J. D. van Eekelen,

2017, pp.

182–192.

496,

[17]

[18] A. Decan, T. Mens, and E. Constantinou, “On the evolution of
technical
lag in the npm package dependency network,”
in 2018 IEEE International Conference on Software Maintenance
and Evolution, ICSME 2018, Madrid, Spain, September 23-29, 2018.
IEEE Computer Society, 2018, pp. 404–414. [Online]. Available:
https://doi.org/10.1109/ICSME.2018.00050

[19] A. Zerouali, E. Constantinou, T. Mens, G. Robles, and J. M.
González-Barahona, “An empirical analysis of technical lag in
npm package dependencies,” in New Opportunities for Software
Reuse - 17th International Conference, ICSR 2018, Madrid, Spain, May
21-23, 2018, Proceedings,
in Computer
Science, R. Capilla, B. Gallina, and C. Cetina, Eds., vol.
10826.
[Online]. Available:
https://doi.org/10.1007/978-3-319-90421-4_6

ser. Lecture Notes

2018, pp.

Springer,

95–110.

[20] A. Zerouali, T. Mens,

J. M. González-Barahona, A. Decan,
E. Constantinou, and G. Robles, “A formal framework for

IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

19

[21]

measuring technical lag in component repositories - and its
application to npm,” J. Softw. Evol. Process., vol. 31, no. 8, 2019.
[Online]. Available: https://doi.org/10.1002/smr.2157
J. Stringer, A. Tahir, K. Blincoe, and J. Dietrich, “Technical lag of
dependencies in major package managers,” in 27th Asia-Paciﬁc
Software Engineering Conference, APSEC 2020, Singapore, December
1-4, 2020.
[Online]. Available:
https://doi.org/10.1109/APSEC51365.2020.00031

IEEE, 2020, pp. 228–237.

[22] A. Zerouali, T. Mens, A. Decan,

and G. Robles, “A multi-dimensional analysis of
lag in Debian-based docker
vol. 26, no. 2, p. 19, 2021.
//doi.org/10.1007/s10664-020-09908-6

J. M. González-Barahona,
technical
images,” Empir. Softw. Eng.,
[Online]. Available: https:

[23] K. Chow and D. Notkin, “Semi-automatic update of applications
in response to library changes,” in 1996 International Conference
on Software Maintenance (ICSM ’96), 4-8 November 1996, Monterey,
CA, USA, Proceedings.
IEEE Computer Society, 1996, p. 359.
[Online]. Available: https://doi.org/10.1109/ICSM.1996.565039
J. Henkel and A. Diwan, “CatchUp!: capturing and replaying
refactorings to support API evolution,” in 27th International
Conference on Software Engineering (ICSE 2005), 15-21 May 2005,
St. Louis, Missouri, USA, G. Roman, W. G. Griswold, and
B. Nuseibeh, Eds. ACM, 2005, pp. 274–283. [Online]. Available:
https://doi.org/10.1145/1062455.1062512

[24]

[25] Z. Xing and E. Stroulia, “API-evolution support with Diff-
CatchUp,” IEEE Trans. Software Eng., vol. 33, no. 12, pp. 818–836,
[Online]. Available: https://doi.org/10.1109/TSE.2007.
2007.
70747

[26] H. A. Nguyen, T. T. Nguyen, G. W. Jr., A. T. Nguyen, M. Kim,
and T. N. Nguyen, “A graph-based approach to API usage
adaptation,” in Proceedings of the 25th Annual ACM SIGPLAN
Conference on Object-Oriented Programming, Systems, Languages,
and Applications, OOPSLA 2010, October 17-21, 2010, Reno/Tahoe,
Nevada, USA, W. R. Cook,
and M. C.
Rinard, Eds. ACM, 2010, pp. 302–321. [Online]. Available:
https://doi.org/10.1145/1869459.1869486

S. Clarke,

[27] B. Dagenais and M. P. Robillard, “Recommending adaptive
framework evolution,” ACM Trans. Softw. Eng.
changes
Methodol., vol. 20, no. 4, pp. 19:1–19:35, 2011. [Online]. Available:
https://doi.org/10.1145/2000799.2000805

for

[28] B. Cossette and R. J. Walker, “Seeking the ground truth: a
retroactive study on the evolution and migration of software
libraries,” in 20th ACM SIGSOFT Symposium on the Foundations
of Software Engineering (FSE-20), SIGSOFT/FSE’12, Cary, NC, USA
- November 11 - 16, 2012, W. Tracz, M. P. Robillard, and
T. Bultan, Eds. ACM, 2012, p. 55.
[Online]. Available:
https://doi.org/10.1145/2393596.2393661
S. Xu, Z. Dong, and N. Meng, “Meditor: inference and application
of API migration edits,” in Proceedings of the 27th International
Conference on Program Comprehension, ICPC 2019, Montreal, QC,
Canada, May 25-31, 2019, Y. Guéhéneuc, F. Khomh, and F. Sarro,
Eds.
IEEE / ACM, 2019, pp. 335–346. [Online]. Available:
https://doi.org/10.1109/ICPC.2019.00052

[29]

[30] K. Huang, B. Chen, L. Pan, S. Wu, and X. Peng, “REPFINDER:
ﬁnding replacements for missing APIs in library update,”
in 36th IEEE/ACM International Conference on Automated Software
Engineering, ASE 2021, Melbourne, Australia, November 15-19, 2021.
IEEE, 2021, pp. 266–278. [Online]. Available: https://doi.org/10.
1109/ASE51524.2021.9678905

[32]

[31] B. B. Nielsen, M. T. Torp, and A. Møller, “Semantic patches for
adaptation of JavaScript programs to evolving libraries,” in 43rd
IEEE/ACM International Conference on Software Engineering, ICSE
2021, Madrid, Spain, 22-30 May 2021.
IEEE, 2021, pp. 74–85.
[Online]. Available: https://doi.org/10.1109/ICSE43902.2021.
00020
S. A. Haryono, F. Thung, D. Lo,
Jiang,
“MLCatchUp: Automated update of deprecated machine-
in Python,” in IEEE International Conference
learning APIs
on Software Maintenance and Evolution, ICSME 2021, Luxembourg,
September 27 - October 1, 2021.
IEEE, 2021, pp. 584–588. [Online].
Available: https://doi.org/10.1109/ICSME52107.2021.00061
[33] M. Fazzini, Q. Xin, and A. Orso, “Automated API-usage
update for android apps,” in Proceedings of the 28th ACM
SIGSOFT International Symposium on Software Testing and Analysis,
ISSTA 2019, Beijing, China, July 15-19, 2019, D. Zhang and
A. Møller, Eds. ACM, 2019, pp. 204–215. [Online]. Available:
https://doi.org/10.1145/3293882.3330571

J. Lawall, and L.

[37]

[34]

[36]

[35]

and X. Wang,

S. A. Haryono, F. Thung, D. Lo, L. Jiang, J. Lawall, H. J.
Kang, L. Serrano, and G. Muller, “AndroEvolve: Automated
Android API update with data ﬂow analysis and variable
denormalization,” Empir. Softw. Eng., vol. 27, no. 3, p. 73, 2022.
[Online]. Available: https://doi.org/10.1007/s10664-021-10096-0
(2022, January) Semantic versioning 2.0.0. [Online]. Available:
https://semver.org/
S. Mostafa, R. Rodriguez,
“Experience
paper: a study on behavioral backward incompatibilities
Java software libraries,” in Proceedings of the 26th ACM
of
SIGSOFT International Symposium on Software Testing and Analysis,
Santa Barbara, CA, USA, July 10 - 14, 2017, T. Bultan and
K. Sen, Eds. ACM, 2017, pp. 215–225. [Online]. Available:
https://doi.org/10.1145/3092703.3092721
S. Raemaekers, A. van Deursen, and J. Visser, “Semantic
versioning and impact of breaking changes in the Maven
repository,” J. Syst. Softw., vol. 129, pp. 140–158, 2017. [Online].
Available: https://doi.org/10.1016/j.jss.2016.04.008
J. Hejderup and G. Gousios, “Can we trust tests to automate
Java projects,” J.
dependency updates? A case study of
Syst. Softw., vol. 183, p. 111097, 2022.
[Online]. Available:
https://doi.org/10.1016/j.jss.2021.111097
J. Wu, H. He, W. Xiao, K. Gao, and M. Zhou, “Demystifying
software release note issues on GitHub,” in Proceedings of the
30th IEEE/ACM International Conference on Program Comprehension,
ICPC 2022, Pittsburgh, USA, May 16-17, 2022. ACM, 2022.
[40] P. Lam, J. Dietrich, and D. J. Pearce, “Putting the semantics
into semantic versioning,” in Proceedings of the 2020 ACM
SIGPLAN International Symposium on New Ideas, New Paradigms,
and Reﬂections on Programming and Software, Onward! 2020, Virtual,
November, 2020. ACM, 2020, pp. 157–179. [Online]. Available:
https://doi.org/10.1145/3426428.3426922

[38]

[39]

[41] B. Rombaut, F. R. Cogo, B. Adams, and A. E. Hassan, “There’s
no such thing as a free lunch: Lessons learned from exploring
the overhead introduced by the Greenkeeper dependency bot in
npm,” ACM Transactions on Software Engineering and Methodology,
2022. [Online]. Available: https://doi.org/10.1145/3522587
[42] M. S. Wessel, B. M. de Souza, I. Steinmacher, I. S. Wiese,
I. Polato, A. P. Chaves, and M. A. Gerosa, “The power of bots:
Characterizing and understanding bots in OSS projects,” Proc.
ACM Hum. Comput. Interact., vol. 2, no. CSCW, pp. 182:1–182:19,
2018. [Online]. Available: https://doi.org/10.1145/3274451
[43] L. Erlenhov, F. G. de Oliveira Neto, and P. Leitner, “An empirical
study of bots in software development: characteristics and
challenges from a practitioner’s perspective,” in ESEC/FSE ’20:
28th ACM Joint European Software Engineering Conference and Sym-
posium on the Foundations of Software Engineering, Virtual Event,
USA, November 8-13, 2020, P. Devanbu, M. B. Cohen, and
[Online].
T. Zimmermann, Eds. ACM, 2020, pp. 445–455.
Available: https://doi.org/10.1145/3368089.3409680

[44] M. S. Wessel, I. Wiese, I. Steinmacher, and M. A. Gerosa,
“Don’t disturb me: Challenges of interacting with software bots
on open source software projects,” Proc. ACM Hum. Comput.
Interact., vol. 5, no. CSCW2, pp. 1–21, 2021. [Online]. Available:
https://doi.org/10.1145/3476042

[45] M. S. Wessel, A. Abdellatif, I. Wiese, T. Conte, E. Shihab, M. A.
Gerosa, and I. Steinmacher, “Bots for pull requests: The good,
the bad, and the promising,” in 44th IEEE/ACM 44th International
Conference on Software Engineering, ICSE 2022, Pittsburgh, PA, USA,
May 25-27, 2022.
IEEE, 2022, pp. 274–286. [Online]. Available:
https://ieeexplore.ieee.org/document/9793907

[47]

[46] E. Shihab, S. Wagner, M. A. Gerosa, M. Wessel, and
J. Cabot, “The present and future of bots
in software
engineering,” IEEE Software, 2022. [Online]. Available: https:
//doi.org/10.1109/MS.2022.3176864
S. Santhanam, T. Hecking, A. Schreiber, and S. Wagner,
“Bots in software engineering: a systematic mapping study,”
PeerJ Comput. Sci., vol. 8, p. e866, 2022. [Online]. Available:
https://doi.org/10.7717/peerj-cs.866
(2022,
January) Dependabot preview.
https://github.com/apps/dependabot-preview
(2022,
January) Github apps
https://github.com/apps/pull

[Online]. Available:

[Online]. Available:

- pull.

[49]

[48]

[50] L. Erlenhov, F. G. de Oliveira Neto, and P. Leitner, “Dependency
management bots in open-source systems - prevalence and
adoption,” PeerJ Comput. Sci., vol. 8, p. e849, 2022. [Online].
Available: https://doi.org/10.7717/peerj-cs.849

IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

20

code,”

[51] T. Dey, S. Mousavi, E. Ponce, T. Fry, B. Vasilescu, A. Filippova,
and A. Mockus, “Detecting and characterizing bots that
in MSR ’20: 17th International Conference on
commit
Mining Software Repositories, Seoul, Republic of Korea, 29-30 June,
2020, S. Kim, G. Gousios, S. Nadi, and J. Hejderup,
Eds. ACM, 2020, pp. 209–219.
[Online]. Available: https:
//doi.org/10.1145/3379597.3387478
(2018,

and
Available:
living-off-our-savings-and-growing-our-saas-to-740-mo-696f9b110f

savings
our
[Online].
https://www.indiehackers.com/interview/

off
$740/mo.

January)
saas

Living
to

[52] G.

growing

Baker.

our

[53] ——.

(2019,

January) Dependabot was acquired by github!
[Online]. Available: https://www.indiehackers.com/product/
dependabot/acquired-by-github--LgT7DN1rGEZM2O4srhF

[54] GitHub,

Inc.

(2022,

January)

Documentation

for
https:

alerts.

security

dependabot
//docs.github.com/en/code-security/supply-chain-security/
managing-vulnerabilities-in-your-projects-dependencies/
about-alerts-for-vulnerable-dependencies#
access-to--dependabot-alerts

[Online]. Available:

[55] ——.

[56] ——.

The

release

January)

github
(2020,
native dependabot.
[Online]. Available: https://github.blog/
2020-06-01-keep-all-your-packages-up-to-date-with-dependabot
preview,
[Online]. Available: https://github.blog/

hello dependabot!
2021-04-29-goodbye-dependabot-preview-hello-dependabot/

January) Goodbye

dependabot

(2021,

blog

of

[57] ——.

(2022,

January)

Documentation

for

[Online].

conﬁguration.

pendabot
//docs.github.com/en/code-security/supply-chain-security/
keeping-your-dependencies-updated-automatically/
conﬁguration-options-for-dependency-updates
(2022, January) Pull request #1127 of datadesk/baker. [Online].
Available: https://github.com/datadesk/baker/pull/1127

Available:

[58]

de-
https:

Inc.

(2022,

About

scores.

January)

[Online].

Available:

com-
https:

[59] GitHub,
patibility
//docs.github.com/en/code-security/supply-chain-security/
managing-vulnerabilities-in-your-projects-dependencies/
about-dependabot-security-updates#about-compatibility-scores
[60] M. Alfadel, D. E. Costa, E. Shihab, and M. Mkhallalati, “On the
use of Dependabot security pull requests,” in 18th IEEE/ACM
International Conference on Mining Software Repositories, MSR 2021,
Madrid, Spain, May 17-19, 2021. IEEE, 2021, pp. 254–265. [Online].
Available: https://doi.org/10.1109/MSR52588.2021.00037
[61] C. Soto-Valero, T. Durieux, and B. Baudry, “A longitudinal
in ESEC/FSE
analysis
bloated Java dependencies,”
’21: 29th ACM Joint European Software Engineering Conference and
Symposium on the Foundations of Software Engineering, Athens,
Greece, August 23-28, 2021, D. Spinellis, G. Gousios, M. Chechik,
and M. D. Penta, Eds. ACM, 2021, pp. 1021–1031. [Online].
Available: https://doi.org/10.1145/3468264.3468589

of

[62] F. R. Cogo and A. E. Hassan, “Understanding the customization
of dependency bots: The case of dependabot,” IEEE Software,
[Online]. Available: https://doi.org/10.1109/MS.2022.
2022.
3179484
(2022,
request #4317 of caddyserver/caddy.
[Online]. Available: https://github.com/caddyserver/caddy/
pull/4317

January) Pull

[63]

[64] G. Gousios,

“The GHTorrent dataset

suite,”
in Proceedings of the 10th Working Conference on Mining Software
Repositories,
Piscataway, NJ, USA:
’13.
IEEE
[Online]. Available:
pp.
http://dl.acm.org/citation.cfm?id=2487085.2487132

ser. MSR

and tool

233–236.

Press,

2013,

[65] N. Munaiah, S. Kroh, C. Cabrey, and M. Nagappan, “Curating
GitHub for engineered software projects,” Empir. Softw. Eng.,
vol. 22, no. 6, pp. 3219–3253, 2017.
[Online]. Available:
https://doi.org/10.1007/s10664-017-9512-6

and rationales,”

[66] H. He, R. He, H. Gu, and M. Zhou, “A large-scale
study on Java library migrations: prevalence,
empirical
in ESEC/FSE ’21: 29th ACM Joint
trends,
European Software Engineering Conference and Symposium on the
Foundations of Software Engineering, Athens, Greece, August 23-28,
2021, D. Spinellis, G. Gousios, M. Chechik, and M. D.
Penta, Eds. ACM, 2021, pp. 478–490.
[Online]. Available:
https://doi.org/10.1145/3468264.3468571

[67] GitHub, Inc. (2022, January) Github rest api. [Online]. Available:

https://docs.github.com/en/rest

[68]

(2022, January) Cloudﬂare workers. [Online]. Available: https:
//workers.cloudﬂare.com/

[69] GitHub, Inc. (2022, January) Github advisory database. [Online].

Available: https://github.com/advisories

[70] M. Goeminne and T. Mens, “Evidence for the Pareto principle in
open source software activity,” in the Joint Porceedings of the 1st
International workshop on Model Driven Software Maintenance and
5th International Workshop on Software Quality and Maintainability.
Citeseer, 2011, pp. 74–82.

[71] Y. Zhang, M. Zhou, A. Mockus, and Z.

Jin, “Companies’
participation in OSS development-an empirical
study of
OpenStack,” IEEE Trans. Software Eng., vol. 47, no. 10, pp.
2242–2259, 2021. [Online]. Available: https://doi.org/10.1109/
TSE.2019.2946156

[72] A. Decan, T. Mens, and P. Grosjean, “An empirical comparison
of dependency network evolution in seven software packaging
ecosystems,” Empir. Softw. Eng., vol. 24, no. 1, pp. 381–416, 2019.
[Online]. Available: https://doi.org/10.1007/s10664-017-9589-y
(2022,
[Online]. Available:
https://github.com/dependabot/dependabot-core/issues/4146
[74] R. Likert, “A technique for the measurement of attitudes.”

January) Dependabot

feedback.

[73]

[75]

Archives of Psychology, 1932.
(2022, March) How to choose a sample size (for
the
statistically challenged). [Online]. Available: https://tools4dev.
org/resources/how-to-choose-a-sample-size/

[76] X. Tan, M. Zhou, and Z. Sun, “A ﬁrst look at good ﬁrst
issues on GitHub,” in ESEC/FSE ’20: 28th ACM Joint European
Software Engineering Conference and Symposium on the Foundations
of Software Engineering, Virtual Event, USA, November 8-13, 2020,
P. Devanbu, M. B. Cohen, and T. Zimmermann, Eds. ACM,
2020, pp. 398–409. [Online]. Available: https://doi.org/10.1145/
3368089.3409746
(2022, July) Ethical issues to consider when conducting survey
research. [Online]. Available: https://www.qualtrics.com/blog/
ethical-issues-for-online-surveys/

[77]

[78] Y. Zhao, A. Serebrenik, Y. Zhou, V. Filkov, and B. Vasilescu, “The
impact of continuous integration on other software development
study,” in Proceedings of
practices: a large-scale empirical
the 32nd IEEE/ACM International Conference on Automated Software
Engineering, ASE 2017, Urbana, IL, USA, October 30 - November 03,
2017, G. Rosu, M. D. Penta, and T. N. Nguyen, Eds.
IEEE Computer Society, 2017, pp. 60–71. [Online]. Available:
https://doi.org/10.1109/ASE.2017.8115619

[80]

[82]

[83]

[79] N. Cassee, B. Vasilescu, and A. Serebrenik, “The silent helper:
The impact of continuous integration on code reviews,” in 27th
IEEE International Conference on Software Analysis, Evolution and
Reengineering, SANER 2020, London, ON, Canada, February 18-21,
2020, K. Kontogiannis, F. Khomh, A. Chatzigeorgiou, M. Fokaefs,
and M. Zhou, Eds.
IEEE, 2020, pp. 423–434. [Online]. Available:
https://doi.org/10.1109/SANER48275.2020.9054818
S. Prion and K. Haerling, “Making sense of methods and mea-
surement: Spearman-rho ranked-order correlation coefﬁcient,”
Clinical Simulation in Nursing, vol. 10, p. 535–536, 10 2014.
[81] P. Sturgis, C. Roberts, and P. Smith, “Middle alternatives revis-
ited: How the neither/nor response acts as a way of saying “i
don’t know”?” Sociological Methods & Research, vol. 43, no. 1, pp.
15–38, 2014.
(2022, January) Pull request #259 of dropbox/stone. [Online].
Available: https://github.com/dropbox/stone/pull/259
(2022,
tuist/tuist.
Available: https://github.com/tuist/tuist/pull/3155
(2022,
ros-ci.
action-ros-ci/pull/663
(2022,
justeat/httpclient-
interception. [Online]. Available: https://github.com/justeat/
httpclient-interception/commit/b337b5f
(2022,
dotnet.
protoactor-dotnet/pull/1260
(2022,
January) Commit #a06b0e4 of azure/bicep.
Available: https://github.com/Azure/bicep/commit/a06b0e4
(2022, January) Pull request #134 of skytable/skytable. [Online].
Available: https://github.com/skytable/skytable/pull/134
Comment
(2022,
of

January) Pull request #1260 of asynkron/protoactor-
[Online]. Available: https://github.com/asynkron/

January) Pull
ros-tooling/action-
[Online]. Available: https://github.com/ros-tooling/

January) Pull request #3155 of

dependabot/dependabot-core.

January) Commit

request #663 of

#1190
Avail-

#b337b5f

[Online].

[Online].

[Online].

January)

issue

from

[89]

[84]

[86]

[88]

[85]

[87]

of

IEEE TRANSACTIONS ON SOFTWARE ENGINEERING

21

[90]

[91]

[92]

[93]

[94]

[95]

[96]

[97]

[98]

[99]

Issue

January)

January)

https://github.com/dependabot/dependabot-core/

#1736 of dependabot/dependabot-
[Online]. Available: https://github.com/dependabot/

#1296 of dependabot/dependabot-
[Online]. Available: https://github.com/dependabot/

able:
issues/1190#issuecomment-926414839
(2022,
core.
dependabot-core/issues/1296
(2022,
request #2635 of giantswarm/happa.
January) Pull
[Online]. Available: https://github.com/giantswarm/happa/
pull/2635
(2022, January) Commit #8ecef22 of fate-grand-automata/fga.
[Online]. Available: https://github.com/Fate-Grand-Automata/
FGA/commit/8ecef22
(2022,
request #1976 of stoplightio/spectral.
January) Pull
[Online]. Available: https://github.com/stoplightio/spectral/
pull/1976
(2022,
core.
dependabot-core/issues/1736
(2022,
core.
dependabot-core/issues/1297
(2022,
hashnode.
gatsby-source-hashnode/issues/202
(2022, January) Issue #26 of replygirl/tc. [Online]. Available:
https://github.com/replygirl/tc/issues/26
(2022,
request #1987 of stoplightio/spectral.
[Online]. Available: https://github.com/stoplightio/spectral/
pull/1987
(2022,
codalab/codalab-
worksheets. [Online]. Available: https://github.com/codalab/
codalab-worksheets/pull/2916

#1297 of dependabot/dependabot-
[Online]. Available: https://github.com/dependabot/

nitzano/gatsby-source-
[Online]. Available: https://github.com/nitzano/

January) Pull

January) Pull

#2916 of

January)

January)

request

Issue

Issue

Issue

#202

of

[100] (2022,

January) Pull request #126 of

lyft/clutch.

[Online].

Available: https://github.com/lyft/clutch/pull/126

[102] (2022,

[101] (2022, January) Pull request #3622 of video-dev/hls.js. [Online].
Available: https://github.com/video-dev/hls.js/pull/3622
Comment

#1973
Avail-
https://github.com/dependabot/dependabot-core/

dependabot/dependabot-core.

of
able:
issues/1973#issuecomment-640918321

[Online].

January)

issue

from

[103] (2022,

January)

dependabot-auto-merge.
com/ahmadnassri/action-dependabot-auto-merge/issues/60

#60

ahmadnassri/action-
[Online]. Available: https://github.

Issue

of

[104] S. H. Khandkar, “Open coding,” University of Calgary, vol. 23, p.

2009, 2009.

[105] R.

and pragmatic

J. Passonneau,
for
(MASI)

“Measuring agreement on set-valued
items
annotation,”
semantic
in Proceedings of the Fifth International Conference on Language
Resources and Evaluation, LREC 2006, Genoa, Italy, May 22-28, 2006,
N. Calzolari, K. Choukri, A. Gangemi, B. Maegaard,
J. Mariani,
European
Language Resources Association (ELRA), 2006, pp. 831–836.
[Online]. Available: http://www.lrec-conf.org/proceedings/
lrec2006/summaries/636.html

and D. Tapias, Eds.

J. Odijk,

[106] K. Krippendorff, “Computing krippendorff’s alpha-reliability,”

2011.

[107] ——, Content Analysis: An Introduction to its Methodology.

Sage

publications, 2018.

[108] M. Zimmermann, C. Staicu, C. Tenny, and M. Pradel,
“Small world with high risks: A study of security threats
in the npm ecosystem,” in 28th USENIX Security Symposium,
USENIX Security 2019, Santa Clara, CA, USA, August 14-16, 2019,
N. Heninger and P. Traynor, Eds. USENIX Association, 2019,
pp. 995–1010.
[Online]. Available: https://www.usenix.org/
conference/usenixsecurity19/presentation/zimmerman

[109] A. Godulla, M. Bauer, J. Dietlmeier, A. Lück, M. Matzen, and
F. Vaaßen, “Good bot vs. bad bot: Opportunities and conse-
quences of using automated software in corporate communica-
tions,” 2021.

[110] Z. Peng and X. Ma, “Exploring how software developers
work with mention bot in github,” CCF Trans. Pervasive Comput.
Interact., vol. 1, no. 3, pp. 190–203, 2019. [Online]. Available:
https://doi.org/10.1007/s42486-019-00013-2

[111] L.

L. Vásquez,

F. Cortes-Coy, M.

and
D. Poshyvanyk,
commit
messages via summarization of source code changes,” in
14th IEEE International Working Conference on Source Code Analysis
and Manipulation, SCAM 2014, Victoria, BC, Canada, September 28-

automatically

J. Aponte,

generating

“On

29, 2014.
Available: https://doi.org/10.1109/SCAM.2014.14

IEEE Computer Society, 2014, pp. 275–284. [Online].

[112] L. Moreno, G. Bavota, M. D. Penta, R. Oliveto, A. Marcus, and
G. Canfora, “ARENA: an approach for the automated generation
of release notes,” IEEE Trans. Software Eng., vol. 43, no. 2, pp.
106–127, 2017. [Online]. Available: https://doi.org/10.1109/TSE.
2016.2591536

[113] D. Poole, A. Mackworth, and R. Goebel, Computational Intelli-

gence. Oxford University Press, 1998.

[114] S. J. Russell, Artiﬁcial Intelligence: A Modern Approach.

Pearson

Education, Inc., 2010.

Runzhi He is currently an undergraduate stu-
dent at the School of Electronics Engineering
and Computer Science (EECS), Peking Univer-
sity. His research mainly focuses on open source
sustainability and software supply chain. He can
be contacted via rzhe@pku.edu.cn

Hao He is currently a Ph.D. student at the School
of Computer Science, Peking University. Before
that, he received his B.S. degree in Computer
Science from Peking University in 2020. His re-
search addresses socio-technical sustainability
problems in open source software communities,
ecosystems, and supply chains. More informa-
tion can be found on his personal website https:
//hehao98.github.io/ and he can be reached at
heh@pku.edu.cn.

Yuxia Zhang is currently an assistant profes-
sor at
the School of Computer Science and
Technology, Beijing Institute of Technology (BIT).
She received her Ph.D.
in 2020 from the
School of Electronics Engineering and Com-
puter Science (EECS), Peking University. Her re-
search interests include mining software repos-
itories and open-source software ecosystems,
mainly focusing on commercial participation in
open-source. She can be contacted at yuxi-
azh@bit.edu.cn.

Minghui Zhou received the BS, MS, and Ph.D.
degrees in computer science from the National
University of Defense Technology in 1995, 1999,
and 2002, respectively. She is a professor in the
School of Computer Science at Peking Univer-
sity. She is interested in software digital sociol-
ogy, i.e., understanding the relationships among
people, project culture, and software products
through mining the repositories of software
projects. She is a member of the ACM and IEEE.
She can be reached at zhmh@pku.edu.cn.

