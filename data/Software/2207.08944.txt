: Interactive Toolbox Supporting Precise Data Annotation

for Robust Vision Learning

2
2
0
2

l
u
J

8
1

]

V
C
.
s
c
[

1
v
4
4
9
8
0
.
7
0
2
2
:
v
i
X
r
a

Chonghan Chen * 1 Haohan Wang * 1 2 Leyang Hu 3 Yuhao Zhang 4 Shuguang Lyu 5 Jingcheng Wu 1
Xinnuo Li 6 Linjing Sun 3 Eric P. Xing 1 7

Abstract

We introduce the initial release of our software
Robustar, which aims to improve the robustness
of vision classiﬁcation machine learning mod-
els through a data-driven perspective. Building
upon the recent understanding that the lack of
machine learning model’s robustness is the ten-
dency of the model’s learning of spurious features,
we aim to solve this problem from its root at the
data perspective by removing the spurious fea-
tures from the data before training. In particular,
we introduce a software that helps the users to
better prepare the data for training image clas-
siﬁcation models by allowing the users to anno-
tate the spurious features at the pixel level of im-
ages. To facilitate this process, our software also
leverages recent advances to help identify poten-
tial images and pixels worthy of attention and to
continue the training with newly annotated data.
Our software is hosted at the GitHub Repository
https://github.com/HaohanWang/Robustar.

1. Introduction

Machine learning has achieved remarkable performances
over i.i.d benchmarks in recent years, which has greatly
encouraged the community to test the methods in other sce-
narios beyond the i.i.d settings, leading to multiple other

*Equal contribution 1School of Computer Science, Carnegie
Mellon University 2School of Information Science, University
of Illinois Urbana-Champaign 3School of Computer Science,
University of Nottingham Ningbo China 4School of Computer
Science, University of Nottingham 5Bren School of Informa-
tion and Computer Sciences University of California, Irvine
6College of Literature, Science and the Arts, University of
Michigan 7Mohamed bin Zayed University of Artiﬁcial In-
telligence. Correspondence to: Robustar Github Repository
<https://github.com/HaohanWang/Robustar>.

DataPerf Workshop @ 39th International Conference on Machine
Learning, Baltimore, Maryland, USA, 2022. Copyright 2022 by
the author(s).

topics such as the study of cross-domain robustness includ-
ing domain adaptation (Ben-David et al., 2007; 2010), do-
main generalization (Muandet et al., 2013), and the recent
advances beyond the settings (Ye et al., 2021; Huang et al.,
2022), as well as the study of robustness against predeﬁned
perturbations such as adversarial robustness (Szegedy et al.,
2014; Goodfellow et al., 2015).

While there is a diverse set of topics regarding machine
learning robustness over different directions, recently lit-
erature suggests that a central theme of these challenges
is the existence of spurious features that are not semantics
but associated with the labels (Wang et al., 2020). Corre-
spondingly, a proliferation of machine learning robustness
methods are designed by explicitly or implicitly countering
the model’s tendency in learning spurious features (Wang
et al., 2021).

While the central theme of countering the learning of spuri-
ous features can potentially guide the development of many
robust machine learning methods (Wang et al., 2021), we
nonetheless consider the repeated case-by-case design and
implementation of machine learning methods over different
applications might be inconvenient at certain scenarios.

Therefore, in this project, we aim to solve this problem in
the scope of image classiﬁcation with a model-free manner,
by focusing on the data perspective at the image pixel level.
We introduce a software that allow the users or domain
experts to annotate the pixels that are associated with the
label in the spurious manner. The annotation will allow the
system to continue to train the model with established robust
learning methods of data augmentation strategies.

In summary, we introduce the software Robustar with the
following functions:

• Core Function: to allow users interact with the train-
ing samples, annotating features that are useless used
potentially used by the models to help train a robust
model to the request of the domain expert.

• Supporting Functions:

– We use inﬂuence function to help identify the

 
 
 
 
 
 
Robustar: Interactive Toolbox for Robust Vision Classiﬁcation

samples that need attention.

– We use saliency-map style interpretation to help
the user identify the features need attention.

– We use segmentation models to help the user se-

lect certain pixels more efﬁciently.

– We use data augmentation and regularizations to
help train models invariant to the identiﬁed pixels.

The remainder of this manuscript will be structured as fol-
lows. We will ﬁrst offer an overview of our system and the
main pipeline of the use case in Section 2. Then in Sec-
tion 3, we will introduce the core functions presented in our
software. Finally, we will offer some discussions before we
conclude in Section 5.

2. System Overview

Figure 1 shows the overview of the software Robustar
pipeline, which consists of ﬁve major steps.

1. The model can be trained elsewhere and then fed into

the software.

2. With new test samples, the model can help identify the
samples that are responsible for the prediction through
inﬂuence function.

3. The software offers saliency map to help the user know
which part of the features the model are paying neces-
sary attention.

4. The users can use the drawing tools to brush out the

spurious pixels.

5. New annotation of these images will serve as the role

as augmented images for continued training.

The software can work with models trained elsewhere, as
long as these are standard vision models and have the stan-
dard pytorch checkpoints available. If the inﬂuence function
results are also calculated, the software can guide the users
to the samples that are believed to be responsible for the
incorrect classiﬁcation of the images. Further, our software
will also guide the user’s attention of the features by the
saliency-style interpretation of the models. Then the users
can user canvas tool to annotate the spurious pixels of the
images. Finally, with the newly annotated spurious features,
we can continue to update the model with data augmenta-
tion and consistency regularization to help us discard these
spurious features.

3. Major Functions

In this section, we will introduce the functions our software
offer following the natural order of the pipeline of our pack-

Figure 1. The major working ﬂow of Robustar.

age will help the domain experts to annotate the spurious
pixels in image classiﬁcation.

Image Browsing Our system allows the users to examine
every samples in the training set through the image browsing
interface (Figure 2,(upper)).

Through the interface, the users can directly view the each
image from either the training or the testing set. If the user
click one image, the sidebar on the right-hand-side will
display multiple relevant statistics of the image of interest.
For example, the prediction summary will indicate what
the model believes the current image to be, offering the
users the information of whether the prediction align with
the user’s p perception of the images well. The remaining
statistics at the sidebar will be discussed later.

This interface allows the user to check every image in the
training sample and identify the ones with spurious features
for further annotation.

Automatic Identifying Misleading Samples
Ideally, to
achieve a robust learning system, the domain experts will
scrutinize the training samples annotate any spurious pixel
features. However, this examination process might poten-
tially require an unrealistic amount of working load, despite
it potentially signiﬁcantly amount of robustness gain. Thus,
to suit the need for some users’ concerns in devoting the
efforts of examining every samples, we allow the system to
propose the suspiciously misleading samples (samples with
spurious features learned by the model) ﬁrst.

The central assumption that enables the automatic proposal
of misleading samples is that the spurious features are not
shared between training samples and testing samples, so that
when a test sample is misclassiﬁed, it is mostly due to the
fact that the model learns a biased signal that accounts for
the misclassiﬁcation. This allows us to identify the samples
with spurious features. Inﬂuence function (Koh & Liang,
2017) conveniently allows us to identify the samples that

Robustar: Interactive Toolbox for Robust Vision Classiﬁcation

Figure 2. Screenshots of main functions of Robustar: above: the image list to view training images and their role in the model; below: the
canvas to annotate the details of one image.

account for the misclassiﬁcation: for every test samples,
we calculate the most relevant training samples from the
training set, and these samples are proposed to the users to
pay particular attention especially when the test samples are
misclassiﬁed.

Annotation of Spurious Pixel Features The user can
choose to enter the annotation page (Figure 2 (bottom right))
by clicking on any images of interest. In the annotation page,
the user can choose to use pencil to brush out the pixels that
are considered spurious.

In addition, to reduce the efforts for user to identify and
brushing out, the system offers two other alternative ways
of annotating the images, as shown in (Figure 2 (bottom
left)): the users can choose to directly ﬁlter out all the pixels
with certain ranges, we also offer a pretrained segmentation
model (He et al., 2017) that can automatically ﬁlter out the
background pixels. In our experiments, we notice that the
segmentation model can save signiﬁcant efforts in natural
images, although not perfect. However, we also notice that,
in medical images such as X-ray, the segmentation model is
not always able to reduce a signiﬁcant amount of efforts.

Interpret Model’s Decision While it will be better to ask
the user to identify all the pixels in the background, it might
not be required for all the background pixels to be annotated
for continued training: only the pixels that are learned by
the machine learning model as spurious features need to be
annotated and later countered through the continued training
process. Therefore, to further reduce the users’ efforts in
annotation, the system to show where the current model
focuses on the images (Figure 2).

For the visualization of the model’s decision, we simply
uses the pioneering model-interpretation methods, activation
maximization (Erhan et al., 2009), and we notice that the
method can fulﬁll our need well enough, especially when the
model is already trained to be invariant to high-frequency
signals of the images.

Continued Training with Randomized Pixels With an-
notation of spurious features all misleading samples, the
users can directly use our system to update the model to
improve its robustness against its tendency in learning the
spurious features through our task center (Figure 3).

In particular, to sufﬁciently force the model to drop the

Robustar: Interactive Toolbox for Robust Vision Classiﬁcation

Figure 3. Task center and paired training

Figure 4. GUI console

learning of spurious features, we leverage the recent train-
ing paradigm with data augmentation and consistency regu-
larization (Wang et al., 2022): to train the model with the
original image and an augmented image whose spurious
pixel features are replaced by random noises and a regular-
ization forcing the model’s logits (pre-softmax embedding)
to be the same from both set of images.

We refer to this training paradigm as paired training. Wang
et al. (2022) showed that this generic training paradigm
can efﬁciently improve the robustness of models empiri-
cally better than models speciﬁcally designed for the tested
applications, with signiﬁcantly less computing costs.

This software paper omits the demonstration of the machine
learning performances through these techniques, but one can
refer to (Wang et al., 2022) for the superior performances
led by data augmentation and alignment regularization.

4. Usage Instructions

Preparation As the goal of this system is to counter the
model’s tendency in learning spurious features, we recom-
mend the users to start with a model with reasonably small
training and testing errors. Users can either upload such
a model to the system or use the functions offered by the
system to start from scratch and train a new model. In either
case, the whole training dataset is expected to be available
for the annotation.

To take the most advantage of the system, we recommend
the user to use out-of-domain test samples (i.e., test sam-
ples from an independent data collection instead of from a
cross-validated split), because the test data from the same
collection (distribution) with training data tend to share the
same spurious features with training data, thus may be in-
adequate to help identify the spurious features. As long as
the test samples can represent a wider range of distributions,
we do not need a large number of test samples.

Setup and Run With Docker installed, the users can run
Robustar with a single-line command, if the user has pulled
the relevant docker images with another command line,
which is only required before the ﬁrst run.

To run the system, the users need to feed in several path for
the Docker to mount, including the folders of the data (with
PyTorch ImageFolder structure), folder of inﬂuence images
(precomputed or empty folder path), folder of checkpoints,
and a conﬁguration ﬁle with information such as number of
classes and model conﬁguration. Details of these informa-
tion can be found at the Robustar GitHub Repository.

GUI Console For users not comfortable using command
line, we also offer a GUI console for the users to setup the
above the conﬁgurations and monitor the running of the
system (Figure 4).

5. Discussion and Conclusion

We aim to improve machine learning robustness from its
root at the data perspective by allowing the users to train a
model with spurious features annotated. For this purpose,
we offer a software for the users to inspect the training data
and annotate the spurious image features. Our software can
be found as https://github.com/HaohanWang/Robustar.

In addition to the facilitate machine learning robustness, we
believe our system can also serve multiple purposes in the
machine learning community from the data perspective. For
example, we expect our system to also help the community
to inspect the properties of the data to understand how to
annotate and prepare the data better at the pixel level, and
our software has the potential to generate massive amount
of data along the interactive process between human and
the model, leading to another possibility to automatically
understand the properties of the data.

Robustar: Interactive Toolbox for Robust Vision Classiﬁcation

Wang, H., Huang, Z., Zhang, H., and Xing, E. To-
ward learning human-aligned cross-domain robust mod-
els by countering misaligned features. arXiv preprint
arXiv:2111.03740, 2021.

Wang, H., Huang, Z., Wu, X., and Xing, E. P. Toward learn-
ing robust and invariant representations with alignment
regularization and data augmentation. arXiv preprint
arXiv:2206.01909, 2022.

Ye, N., Li, K., Hong, L., Bai, H., Chen, Y., Zhou, F., and Li,
Z. Ood-bench: Benchmarking and understanding out-of-
distribution generalization datasets and algorithms. arXiv
preprint arXiv:2106.03721, 2021.

Acknowledgements

The project team would like to thank Donglin Chen for his
contribution at the early-stage of the development.

References

Ben-David, S., Blitzer, J., Crammer, K., Pereira, F., et al.
Analysis of representations for domain adaptation. Ad-
vances in neural information processing systems, 19:137,
2007.

Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A.,
Pereira, F., and Vaughan, J. W. A theory of learning from
different domains. Machine learning, 79(1-2):151–175,
2010.

Erhan, D., Bengio, Y., Courville, A., and Vincent, P. Visual-
izing higher-layer features of a deep network. University
of Montreal, 1341(3):1, 2009.

Goodfellow, I. J., Shlens, J., and Szegedy, C. Explaining
and harnessing adversarial examples. In Bengio, Y. and
LeCun, Y. (eds.), 3rd International Conference on Learn-
ing Representations, ICLR 2015, San Diego, CA, USA,
May 7-9, 2015, Conference Track Proceedings, 2015.

He, K., Gkioxari, G., Doll´ar, P., and Girshick, R. Mask r-
cnn. In Proceedings of the IEEE international conference
on computer vision, pp. 2961–2969, 2017.

Huang, Z., Wang, H., Huang, D., Lee, Y. J., and Xing,
E. P. The two dimensions of worst-case training and the
integrated effect for out-of-domain generalization. arXiv
preprint arXiv:2204.04384, 2022.

Koh, P. W. and Liang, P. Understanding black-box predic-
tions via inﬂuence functions. In International conference
on machine learning, pp. 1885–1894. PMLR, 2017.

Muandet, K., Balduzzi, D., and Sch¨olkopf, B. Domain
generalization via invariant feature representation.
In
International Conference on Machine Learning, pp. 10–
18, 2013.

Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan,
D., Goodfellow, I. J., and Fergus, R. Intriguing properties
of neural networks. In Bengio, Y. and LeCun, Y. (eds.),
2nd International Conference on Learning Representa-
tions, ICLR 2014, Banff, AB, Canada, April 14-16, 2014,
Conference Track Proceedings, 2014.

Wang, H., Wu, X., Huang, Z., and Xing, E. P. High-
frequency component helps explain the generalization
of convolutional neural networks. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition, pp. 8684–8694, 2020.

