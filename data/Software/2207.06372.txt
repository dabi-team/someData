2
2
0
2

l
u
J

3
1

]

M

I
.
h
p
-
o
r
t
s
a
[

1
v
2
7
3
6
0
.
7
0
2
2
:
v
i
X
r
a

The Monitoring Logging and Alarm System of the ASTRI
Mini-Array gamma-ray air-Cherenkov experiment at the
Observatorio del Teide

Federico Incardonaa, Alessandro Costaa, Kevin Munaria, Salvatore Gambadoroa,e, Stefano
Germanib, Pietro Brunoa, Andrea Bulgarellid, Vito Confortid, Fulvio Gianottid, Alessandro
Grilloa, Valerio Pastored, Federico Russod, Joseph Schwarzc, Gino Tostib, and Salvatore
Cavalierie, for the ASTRI Project1

aINAF, Osservatorio Astroﬁsico di Catania, Via S Soﬁa 78, I-95123 Catania, ITALY
bUniversit`a di Perugia, Dipartimento di Fisica e Geologia, IT
cINAF, Osservatorio Astronomico di Brera, IT
dINAF, Osservatorio di Astroﬁsica e Scienza dello Spazio di Bologna, IT
eUniversit`a degli Studi di Catania, Dipartimento Ingegneria Elettrica Elettronica Informatica,
IT
1http://www.astri.inaf.it/en/library/

ABSTRACT

The ASTRI Mini-Array is a project for the Cherenkov astronomy in the TeV energy range. ASTRI Mini-
Array consists of nine Imaging Atmospheric Cherenkov telescopes located at the Teide Observatory (Canarias
Islands). Large volumes of monitoring and logging data result from the operation of a large-scale astrophysical
observatory. In the last few years, several “Big Data” technologies have been developed to deal with such volumes
of data, especially in the Internet of Things (IoT) framework. We present the Monitoring, Logging, and Alarm
(MLA) system for the ASTRI Mini-Array aimed at supporting the analysis of scientiﬁc data and improving the
operational activities of the telescope facility. The MLA system was designed and built considering the latest
software tools and concepts coming from Big Data and IoT to respond to the challenges posed by the operation
of the array. A particular relevance has been given to satisfying the reliability, availability, and maintainability
requirements towards all the array sub-systems and auxiliary devices. The system architecture has been designed
to scale up with the number of devices to be monitored and with the number of software components to be
considered in the distributed logging system.

Keywords: ASTRI, monitoring, logging, alarms, Cherenkov Telescope, CTA

1. INTRODUCTION

The ASTRI (Astroﬁsica con Specchi a Tecnologia Replicante Italiana) project started in 2010 to support the
development of technologies within the Cherenkov Telescope Array 1. The ASTRI Mini-Array project 2 has
expanded becoming an international eﬀort led by the Italian National Institute for Astrophysics (INAF). It is
planned to consist of nine Cherenkov telescopes and cameras in full operations 3, 4, and is based on the experience
provided by the ASTRI prototype.
Internet of Things (IoT) is an emerging technology that is becoming a major topic of interest among technology
giants and business communities. The data generated by IoT devices is large in volume and needs to be analyzed
using Big Data analytics engine (see, e.g. 5) in order to extract the critical information and detect behavioral
patterns.
This paper presents the monitoring, logging, and alarm software architecture currently under development for
the ASTRI Mini-Array (see, also 6). This architecture takes advantage of continuing technological evolution 7 to

Further author information: (Send correspondence to F. Incardona)
F. Incardona: E-mail: federico.incardona@inaf.it

 
 
 
 
 
 
respond to the challenges posed by the operation of the array, in particular, to satisfy the reliability, availability,
and maintainability requirements of all its sub-systems and auxiliary devices. The system architecture is based
on the ALMA Common Software∗ (ACS 8) and has been designed to scale up with the number of devices to
be monitored and with the number of software components to be taken into account in the distributed logging
system.

2. LOGGING, MONITORING AND ALARM SYSTEMS ARCHITECTURE

The Monitoring, Logging, and Alarm (MLA) System monitors the overall performance of the ASTRI Mini-Array
through the acquisition of environmental housekeeping data, log ﬁles, and alarms from instruments, and generates
status reports or notiﬁcations to the operator via an Operator Human Machine Interface (HMI). In the context
of ASTRI Software 9, the HMI provides the interested users with a set of diﬀerent Graphical User Interfaces
(GUIs), accessible from the web, desktop, and mobile clients, through which they can watch in real-time the
data streaming, and can browse and query the historical one. It is made up of a backend exposing data through
HTTP/GraphQL† APIs and Websockets‡ to multiple front-ends.
The Alarm System provides the service that gathers, ﬁlters, exposes, and persists all the relevant alarms raised
by both devices (such as telescopes and other devices) and Supervisory Control And Data Acquisition (SCADA)
processes. The monitoring, logging, and alarm data are saved in the MLA Archives, which are databases opti-
mized for real-time applications 10 (high read-write throughput§) used to keep historical events. These archives
are able to resolve any queries coming from operators and engineering GUIs and are periodically transferred to
the ASTRI Data Center.

3. THE MONITORING SYSTEM

The ASTRI Mini-Array system will generate a signiﬁcant amount of monitoring data, collecting information on
the performance of a variety of critical and complex electrical and mechanical components. We foresee about
20000 monitoring points, and the updating frequency will be no higher than about 1 Hz, except for short-
term debugging campaigns that may require more frequent updates. This monitoring information enriches and
complements observational data, and is crucial for most troubleshooting eﬀorts performed by engineering teams.
The Monitoring System (Fig. 1) will enable the staﬀ to use a systematic approach to fault detection and diagnosis
and support corrective and predictive maintenance to minimize the downtime of the system.
The Monitoring System provides the services that gather monitoring data from the telescopes, the Environmental
Monitoring System, and other instruments, and saves them in the Monitoring Archive.
It also provides a
framework for the evaluation and analysis of abnormal situations. The Monitoring System works continuously
to record any monitoring data. It provides a global base support service and is supposed to be up, running, and
available to any client that wants to use it at all times. The Monitoring System functionality can be broadly
classiﬁed into three main areas: collection, persistence, and (limited) processing.

• Collection: anything collected by the monitoring subsystem is associated with a time-stamp. Monitoring
System collects sensor data and other similar data that change over time, status, and other information.

• Persistence: most monitoring data are persisted for later analysis and processing. The persisting may
operate on the raw monitoring data, or on slightly processed material. The Monitoring System is able
to acquire, process, and save environmental condition data and monitoring points into the Monitoring
Archive.

• Processing capabilities: (i) suppression of duplicate values, e.g., if there is no need to keep repeating with
full frequency a sensor’s value or a component’s state as long as that value or state does not change; (ii)
comparison functions, so that processing emits a value only if an incoming monitoring point lies within
a predeﬁned window of values; (iii) statistical processing; (iv) sensor values ﬁltering, depending on their
status.

∗ACS: https://www.eso.org/projects/alma/develop/acs/
†HTTP/GraphQL: https://graphql.org/learn/serving-over-http/
‡The WebSocket Protocol: https://tools.ietf.org/html/rfc6455
§Apache Cassandra: https://cassandra.apache.org/

Figure 1. Monitoring System Architecture

The Monitoring System allows also browsing of the monitoring data oﬄine either to reconstruct past events or
for further investigations, and it provides the capability to re-sample the monitoring information coming in the
form of irregular and unevenly-spaced time-series data to a consistent and regular frequency.

The breakdown structure of the Monitoring System is the following (see Fig. 1):

• Data Collector is responsible for retrieving monitoring points from the hardware devices (through the
OPC-UA¶ and ACS components 8). The Data Collector is also in charge of data processing, ﬁltering out
duplicate values, and normalizing retrieved data in a common format (i.e., Apache AVRO ‖). It reads the
data sources (i.e., OPC-UA and ACS endpoints) and the set of nodes from which collecting data from the
Conﬁguration Database (CDB), which is responsible for storing the System Conﬁguration Data Model.
The Data Collector is optimized for eﬃciency. In particular, the OPC-UA subscriptions are grouped by
the sampling interval.

• Mon Queue takes formatted and validated monitoring points from the Data Collector. It uses a very fast-
in-memory database discarding data after a given retention period and serves as a: (i) buﬀer to synchronize
data collectors, (ii) dispatchers that operate at diﬀerent speeds, (iii) subscription/notiﬁcation service to
any clients interested in receiving streaming of real-time monitoring data.

¶The OPC Uniﬁed Architecture (UA): https://opcfoundation.org/about/opc-technologies/opc-ua/
‖Apache AVRO: https://avro.apache.org/

Figure 2. Logging System Architecture

• Monitoring Point Dispatcher consumes data from the Mon Queue, delivering them to a long-term data

storage and to the HMI.

• Monitor Manager acts as a coordinator:

its tasks are to start and stop the entire subsystem and to

provide the current status of the monitoring subsystem components.

4. LOGGING SYSTEM

The ASTRI Mini-Array System can generate a signiﬁcant amount of log ﬁles, in the order of about 200 Mbps,
and the logging architecture must be designed taking into account its impact on the performance of the system
as a whole. Particular attention has been paid to enabling ﬁltering of log events both at the device and central
level. Such ﬁltering capability is based on log priority and it can be conﬁgured at the system level. Logs will
not only be useful to diagnose failures detected during operation but they will also be needed for long-term
performance analysis.
The Logging System (LOUD 11) (Fig. 2) gets logging information from relevant software and hardware compo-
nents. It ingests software logs produced by: (i) subsystems using the control framework, (ii) observation scripts,
and (iii) low-level ﬁrmware, which requires reformatting to adapt to the rest of the logs, (iv) hardware systems,
(v) records of actions of the user over the HMIs, in order to keep track of the activities that the operators perform
on the system.

Figure 3. Alarm System Architecture

The breakdown structure of the Logging System is the following (see Fig. 2):

• Log Collector is responsible for reading and collecting log records from the system components and User
Interfaces. It also processes them, generating a log entry according to the log data model and sending them
to the Log Queue. The list of the component endpoints is stored in the Conﬁguration Database.

• Log Queue acts as a buﬀer to synchronize the other components of the subsystem that could operate at

diﬀerent speeds.

• Log Consumer sends log entries to the Log Archive and communicates with the Operator HMI to provide

selected near-real-time logging information.

• Logging Manager acts as a coordinator:

its tasks are to start and stop the entire subsystem and to

provide the current status of the logging subsystem components.

5. ALARM SYSTEM

The Alarm System (AS) (Fig. 3) provides the service that gathers, ﬁlters, exposes, and persists all the relevant
alarms raised by devices (such as the telescopes) and software processes (e.g., Monitoring System, Logging
System, Array Data Acquisition System 12, 13, Telescope Control System 14, etc.). It also creates and ﬁlters
new alarms based on a selection of the most critical monitoring points. The alarms, which by deﬁnition require
human attention and response, are sent to Operators via the HMI. The current implementation of the alarm
system is a customization of the Integrated Alarm System∗∗ (IAS 15) (Fig. 4).

The breakdown structure of the Alarm System is the following (see Fig. 3):

∗∗IAS: https://integratedalarmsystem-group.github.io

Figure 4. Alarm System Queue

• Data Acquisition is a software component that interfaces with the ACS remote control software. It is
also in charge of ﬁltering out and discarding duplicate values. The acquisition is performed by the so-called
PluginQueue (Fig. 4) that sends the collected Basic Alarm events (from ACS) to a dedicated Apache Kafka
†† data stream.

• Data Processing is performed by the Converter in the IAS context. It takes the data points from the
PluginQueue and normalizes them in a common data structure, as deﬁned in the data model. Then it
sends them back to the general Alarm Queue that, in the Alarm System framework, is a Kafka data stream
named Back Stage Database (BSDB).

• Supervisor is the core of the subsystem. Its task is to evaluate the inputs provided by the remote systems
through the Basic Alarm Queue against the model and the deﬁned rules (found in the Conﬁguration
Database), and ultimately generates a number of alarms, either set or cleared. The Supervisor receives
also a selection of monitoring values with the aim of combining them and calculating corresponding alarms.
The Supervisor manages a set of Distributed Alarm System Computing Units (DASUs), which interact with
the BSDB to gather input values and generate outputs in terms of new Alarms or synthetic parameters.
The DASUs output is obtained in one or more steps from the inputs by the Alarm System Computing
Elements (ASCEs).

• Alarm Queue (Fig. 4) serves as temporary storage both of a subset of monitoring points and actual
alarm events. It also acts as a buﬀer to synchronize the other consumer components of the subsystem that

††Apache Kafka https://kafka.apache.org

could operate at diﬀerent speeds. The Alarm Queue is the BSDB, the BASIC ALARM Queue, and the
PluginQueue; it is based on Apache Kafka.

• Alarm Dispatcher is performed by a Kafka Consumer; it notiﬁes and sends alarm data points both to

the long-term alarm archive and operator GUIs.

• Alarm Manager acts as a coordinator with the task to start and stop the entire Alarm System and

provides the current status of AS components.

6. CONCLUSION AND FUTURE DEVELOPMENTS

We presented the architecture of the Monitoring, Logging, and Alarm System that monitors and logs the data
needed to check and improve the operational activities of a large-scale telescope array such as ASTRI. The MLA
prototype was designed and built considering the current software tools and concepts coming from Big Data
and Internet of Things 16. The software stack is based on open-source software, thus reducing the need for
unnecessary extra software development. Future work is planned to integrate Machine Learning algorithms to
perform anomaly detection and failure prediction.

ACKNOWLEDGMENTS

This work was conducted in the context of the ASTRI Project thanks to the support of the Italian Ministry
of University and Research (MUR) as well as the Ministry for Economic Development (MISE) with funds
speciﬁcally assigned to the Italian National Institute of Astrophysics (INAF). We acknowledge support from the
Brazilian Funding Agency FAPESP (Grant 2013/10559-5) and from the South African Department of Science and
Technology through Funding Agreement 0227/2014 for the South African Gamma-Ray Astronomy Programme.
IAC is supported by the Spanish Ministry of Science and Innovation (MICIU). This work has also been partially
supported by H2020-ASTERICS, a project funded by the European Commission Framework Programme Horizon
2020 Research and Innovation action under grant agreement n. 653477. The ASTRI project is becoming a reality
thanks to Giovanni “Nanni” Bignami, Nicol`o “Nichi” D’Amico two outstanding scientists who, in their capability
of INAF Presidents, provided continuous support and invaluable guidance. While Nanni was instrumental to
start the ASTRI telescope, Nichi transformed it into the Mini Array in Tenerife. Now the project is being built
owing to the unfaltering support of Marco Tavani, the current INAF President. Paolo Vettolani and Filippo
Zerbi, the past and current INAF Science Directors, as well as Massimo Cappi, the Coordinator of the High
Energy branch of INAF, have been also very supportive to our work. We are very grateful to all of them. Nanni
and Nichi, unfortunately, passed away but their vision is still guiding us. This article has gone through the
internal ASTRI review process.

REFERENCES

[1] Acharya, B. et al., “Introducing the cta concept,” Astroparticle physics 43, 3–18 (2013).
[2] Pareschi, G. et al., “The astri sst-2m prototype and mini-array for the cherenkov telescope array (cta),” in
[Ground-based and Airborne Telescopes VI ], 9906, 99065T, International Society for Optics and Photonics
(2016).

[3] Scuderi, S. et al., “The astri mini-array of cherenkov telescopes at the observatorio del teide,” Journal of

High Energy Astrophysics (2022).

[4] Vercellone, S. et al., “Astri mini-array core science at the observatorio del teide,” Journal of High Energy

Astrophysics (2022).

[5] Pena, E. et al., “Framework to use modern big data software tools to improve operations at the paranal
observatory,” in [Observatory Operations: Strategies, Processes, and Systems VII], 10704, 107042J, Inter-
national Society for Optics and Photonics (2018).

[6] Costa, A., Munari, K., Incardona, F., Bruno, P. G., Germani, S., Grillo, A., Oya, I., Sciacca, E., Becciani,
U., and Raciti, M., “The Monitoring, Logging, and Alarm system for the Cherenkov Telescope Array,” in
[Proceedings of 37th International Cosmic Ray Conference — PoS(ICRC2021)], 395, 700 (2021).

[7] Costa, A. et al., “Big Data Architectures for Logging and Monitoring Large Scale Telescope Arrays,” in
[Proc. ICALEPCS’19], International Conference on Accelerator and Large Experimental Physics Control
Systems, 268–271, JACoW Publishing, Geneva, Switzerland (08 2020).

[8] Chiozzi, G. et al., “The alma common software: a developer-friendly corba-based framework,” in [Advanced
Software, Control, and Communication Systems for Astronomy], 5496, 205–218, International Society for
Optics and Photonics (2004).

[9] Bulgarelli, A. et al., “The Software Architecture and development approach for the ASTRI Mini-Array
gamma-ray air-Cherenkov experiment at the Observatorio del Teide,” in Software and Cyberinfrastructure
for Astronomy VII, edited by Jorge Ibsen, Gianluca Chiozzi, Proc. of SPIE 12189-15 .

[10] Incardona, F. et al., “Optimization of the storage database for the Monitoring system of the Cherenkov

Telescope Array,” in [Proc. ADASSXXXI 2021],

[11] Incardona, F., Costa, A., Munari, K., Bruno, P. G., Bulgarelli, A., Germani, S., Grillo, A., Schwarz, J.,
Sciacca, E., Tosti, G., Vitello, F., and Tudisco, G., “LOgging UniﬁeD for ASTRI Mini Array,” in [Proceedings
of 37th International Cosmic Ray Conference — PoS(ICRC2021) ], 395, 195 (2021).

[12] Conforti, V., Gianotti, F., Pastore, V., Trifoglio, M., Bulgarelli, A., Addisa, A., L., B., Capalbi, M., Fioretti,
V., Parmiggiani, N., Sangiorgi, P., Corpora, M., Catalano, O., Costa, A., Incardona, F., and Russo, F., “The
Array Data Acquisition System software architecture of the ASTRI Mini-Array Project,” in Software and
Cyberinfrastructure for Astronomy VII, edited by Jorge Ibsen, Gianluca Chiozzi, Proc. of SPIE 12189-25 .
[13] Pastore, V., Conforti, V., Gianotti, F., Bulgarelli, A., Parmiggiani, N., Incardona, F., Costa, A., and Russo,
F., “Array Data Acquisition System interface for online distribution of acquired data in the ASTRI Mini-
Array project,” in Software and Cyberinfrastructure for Astronomy VII, edited by Jorge Ibsen, Gianluca
Chiozzi, Proc. of SPIE 12189-77 .

[14] Russo, F., Tosti, G., et al., “The telescope control system for the ASTRI mini-array of imaging atmospheric
Cherenkov telescopes,” in Software and Cyberinfrastructure for Astronomy VII, edited by Jorge Ibsen, Gi-
anluca Chiozzi, Proc. of SPIE 12189-91 .

[15] Caproni, A. and Schmid, E., “The integrated alarm system for the alma observatory,” in [”Proceedings,
16th International Conference on Accelerator and Large Experimental Physics Control Systems (ICALEPCS
2017)” ], (10 2017).

[16] Costa, A., Tosti, G., Schwarz, J., Bruno, P., Bulgarelli, A., Calanducci, A., Conforti, V., Germani, S.,
Gianotti, F., Grillo, A., Incardona, F., Munari, K., Russo, F., Sciacca, E., and Vitello, F., “Architectural
design and prototype for the logging, monitoring, and alarm system for the ASTRI mini-array,” in [Software
and Cyberinfrastructure for Astronomy VI ], Guzman, J. C. and Ibsen, J., eds., 11452, International Society
for Optics and Photonics, SPIE (2020).

