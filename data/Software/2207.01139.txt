ON THE ROLE OF TIKHONOV REGULARIZATIONS IN STANDARD
OPTIMIZATION PROBLEMS

J. ADRIAZOLA

2
2
0
2

l
u
J

6

]

C
O
.
h
t
a
m

[

2
v
9
3
1
1
0
.
7
0
2
2
:
v
i
X
r
a

Abstract. Tikhonov regularization is a common technique used when solving poorly behaved
optimization problems. Often, and with good reason, this technique is applied by practitioners
in an ad hoc fashion. In this note, we systematically illustrate the role of Tikhonov regulariza-
tions in two simple, yet instructive examples. In one example, we use regular perturbation theory
to predict the impact Tikhonov regularizations have on condition numbers of symmetric, positive
semi-deﬁnite matrices. We then use a numerical example to conﬁrm our result.
In another ex-
ample, we construct an exactly solvable optimal control problem that exhibits a boundary layer
phenomena. Since optimal control problems are rarely exactly solvable, this brings clarity to how
vital Tikhonov regularizations are for the class of problems this example represents. We solve the
problem numerically using MATLAB’s built-in optimization software and compare results with a
Galerkin-type/genetic algorithm. We ﬁnd the second method generally outperforms MATLAB’s
optimization routines and we provide the MATLAB code used to generate the numerics.

1. Introduction

Ill-posed and ill-conditioned problems frequently arise in applied and computational mathemat-
ics. To overcome this common challenge, one typically introduces a type of regularization that
either converts the problem to a well-posed one or better conditions the resulting computational
problem. The Tikhonov regularization technique is often chosen as the ﬁrst strategy toward this
goal and has been successfully applied in several contexts ranging from ill-posed optimal control
problems [1,2,9,11,13] to the numerical solution of poorly-conditioned integral equations [15,18–21].
In statistics, the method is better known as ridge regression [10].

To illustrate how Tikhonov regularizations apply in a general optimization setting, consider the

problem of ﬁnding x∗ such that

(1)

subject to

J(x∗) = min
x∈X

J(x),

(2)
f (x) = 0,
where J : X → R is called an objective functional, f : X → Y is a constraint function, and
X, Y are general Banach spaces. Although the problem may be solvable, it may either be too
computationally intensive to solve or fail to admit solutions which remain feasible to implement in
a scientiﬁc or technological application. Thus, one often seeks to deﬁne a modiﬁed problem

(3)

Jε(x) = J(x) + εK(x)

while still remaining faithful to the originally intended goal.
Of the many possible pitfalls that may be encountered when attempting to solve an ill-posed
problem, one important example is where the optimal solution x∗ ∈ X lacks a desired degree

Department of Mathematics, University of California, Santa Barbara, CA, USA, 93106
E-mail address: jadriazola@ucsb.edu.
Date: July 8, 2022.

1

 
 
 
 
 
 
of regularity or smoothness. A Tikhonov regularization enforces smoothness of solutions to this
problem by modifying the objective to include a penalization. A typical choice is setting

(4)

K(x) = (cid:107)x(cid:107) 2

˙H 1(Ω)

in Equation (3), where Ω ⊂ Cn, n ∈ Z+, and ε ∈ R+. The notation ˙H 1(Ω) indicates a ho-
mogeneous Sobolev space with norm given by (cid:107)Dx(cid:107)L2(Ω) , where L2(Ω) is the standard Lebesgue
(Hilbert) space [12] and D indicates diﬀerentiation with respect to elements from Ω. Simply put,
the introduction of the regularization penalizes solutions that rapidly vary over Ω.

The problem of ﬁnding an optimal value of ε is known in statistics as the so-called bias-variance
dilemma [14]. Although an optimal choice of the Tikhonov parameter ε is known in certain cir-
cumstances [23], the parameter is typically chosen in an ad hoc manner. Through the simple
and instructive examples studied here, we reveal suitable regularization parameters in simpler set-
tings which may guide choices in more complex ones. Of course, choosing suitable regularization
parameters in more complex, real-world applications remains to be done on a case-by-case basis.

This work is organized as follows. Section 2 shows how the Tikhonov technique better conditions
a symmetric, positive semi-deﬁnite matrix whose inverse is desired. There, we quantitatively show
the type of impact a small Tikhonov regularization can have on an extremely ill-conditioned matrix.
In Section 3, we show an example of an optimal control problem admitting a closed-form solution.
Since the problem is exactly solvable, this provides a testbed for standard optimization meth-
ods of which we compare two; an interior-point method [4] implemented by MATLAB’s fmincon
and a method, due to Calarco, et al. [6, 7], called the Chopped Random Basis (CRAB) method
which we also implement in MATLAB. In Appendix A, we provide MATLAB code reﬂecting our
implementation of the methods used to solve the optimal control problem discussed in Section 3.

2. Regularizing an Ill-Conditioned Matrix
The ﬁrst example we consider is matrix inversion of an ill-conditioned matrix. Let n ∈ Z+ and

consider the following optimization problem:

(5)

min
x∈Rn

J = min
x∈Rn

(cid:26) 1
2

xTAx − xTb +

(cid:27)

xTDTDx

ε
2

where A is some real, symmetric, and positive semi-deﬁnite n × n matrix, b ∈ Rn, D is some, as of
yet, unspeciﬁed n × m matrix, m ∈ Z+, and ε is a small, real number. The restrictions placed on
A are done so its spectrum can be analyzed in detail.

By taking the gradient of the objective J in Equation (5) with respect to the variable x, we see

that the optimal vector x∗ satisﬁes

(6)

(cid:16)

A + εDTD

(cid:17)

x∗ = b.

Note that in the case ε = 0, the solution to Equation (6) is given by x∗ = A−1b. If A is singular,
then the task of ﬁnding x∗ is ill-posed, and if A is nearly-singular, computing x∗ is challenging and
often requires substantial computational resources for large n.

It is well-known that the condition number of a symmetric, positive semi-deﬁnite matrix A, with
condition number denoted by c(A), is given by the ratio of its largest eigenvalue to its smallest
eigenvalue [17]. For this reason, we aim to better understand the eﬀect of the Tikhonov regularizer
εDTD on the spectrum of A for small enough ε since this informs us of the condition number of
the regularized matrix A + εDTD.

2

To this end, further assume the eigenvalues of A are simple, and consider the asymptotic expan-

sions

(7a)

(7b)

λ(ε) ∼

ν(ε) ∼

∞
(cid:88)

j=0
∞
(cid:88)

j=0

λjεj

as ε → 0,

νjεj

as ε → 0,

where ν0 and λ0 are deﬁned as the respective eigenvector/eigenvalue pair of the matrix A. To
leading order, we have

(8)

Aν0 = λ0ν0,

which is automatically satisﬁed by the deﬁnition of ν0 and λ0.

To next order, i.e., O(ε), we have

(9)

(A − λ0I)ν1 = (λ1 − DTD)ν0,
where I is the n × n identity matrix. The Fredholm alternative [17] requires the right-hand side to
be orthogonal to the left-eigenvector of A so that Equation (9) is solvable. Since A is symmetric,
the left eigenvector of A is simply νT

0 . The solvability condition of Equation (9) is then given by

(10)

λ1 =

0 DTDν0
νT
νT
0 ν0

.

Thus, the resulting condition number is
λmax
λmin ∼

c(A + εDTD) =

(11)

0 + ελmax
λmax
0 + ελmin
λmin

1

1

+ O(ε2),

as ε → 0,

where λmin/max
0
λmin/max
1
zero, so long as λmin

1

are, respectively, the smallest and largest eigenvalues satisfying Equation (8) while
is nearly

are the smallest and largest numbers satisfying Equation (10). Presumably, λmin

0

is not, the regularization has a high likelihood of being eﬀective.

Indeed, the asymptotic formula (11) gives a criteria for ﬁnding eﬀective A−speciﬁc Tikhonov

matrices, i.e., the Tikhonov matrix D solves the following max-min problem

(12)

max
D∈D

min
ν0∈V

(cid:26) νT

0 DTDν0
νT
0 ν0

(cid:27)

,

where D is the space of all n × m matrices and V is the set of eigenvectors of the ill-conditioned
matrix A. We do not take up a study of Equation (12) here, and instead leave further investigation
for future study.

To better illustrate the eﬀect a Tikhonov regularization has on a nearly singular operator, take

as an example the symmetric, positive-deﬁnite matrix

(13)

which has eigenvalues

A =

(cid:18)1

1

1 1 + µ

(cid:19)

,

µ > 0

(14)

λmin
0 =

(cid:16)

1
2

µ + 2 −

(cid:112)

µ2 + 4

(cid:17)

,

λmax
0 =

(cid:16)

1
2

µ + 2 +

(cid:112)

µ2 + 4

(cid:17)

.

and corresponding eigenvectors

(15)

νmin
0 =

(cid:16)

(cid:32) 1
2

−µ − (cid:112)µ2 + 4
1

(cid:17)

(cid:33)

(cid:16)

(cid:32) 1
2

−µ + (cid:112)µ2 + 4
1

(cid:17)

(cid:33)

,

,

νmax
0 =

3

Indeed, for µ = 10−6, the
Clearly, A is ill-conditioned since c(A) → ∞ as µ → 0 from above.
condition number c(A) = 4 × 106 to seven digits of precision. However, the asymptotic result (11)
predicts that simply choosing D to be the forward diﬀerence operator

(16)

D =





1
0
1
−1
0 −1



 ,

a choice consistent with Equation (4) in this ﬁnite-dimensional setting, and a small regularization
parameter of ε = 0.01, the regularized condition number c(A + εDTD) = 203 to three digits of
precision; a noteworthy improvement. In fact, the asymptotic result is well within the same order
of magnitude of the true value of the condition number

(17)

c(A + εDTD) =

2 + 4ε + µ + (cid:112)4 − 8ε + 4ε2 + µ2
2 + 4ε + µ − (cid:112)4 − 8ε + 4ε2 + µ2

which is 67 to two digits of precision.

Rounding out the example, we choose an example vector b = (cid:0) 1

(cid:1)T to demonstrate that we
can still solve the matrix inversion in a meaningful way. When ε = 0, the exact solution is given
by xunreg = (cid:0) 1
2 , 0(cid:1)T , while, to three digits of precision and when ε = 0.01, the solution xreg =
(cid:0)0.248, 0.248(cid:1)T . The regularized solution has a residual, i.e., J(xreg) when ε = 0, of 1.24×10−5. The
vast improvement on the condition number of A, while still remaining faithful to the unregularized
numerical computation, clearly demonstrates that even a small Tikhonov regularization can greatly
mitigate an extremely ill-conditioned numerical computation.

2 , 1

2

3. Regularizing an Exactly Solvable Optimal Control Problem

The second example we consider is an optimal control problem representative of optimization
problems that frequently arise in controlling dispersive waves, e.g. [1, 2, 11]. This optimal control
problem, by virtue of its exact solution, helps reveal some of the typical numerical diﬃculties
exhibited by this class of problems. Consider the following Lagrange control problem

(18)

min
u∈U

J = min
u∈U

(cid:32)

x +

(cid:90) π

0

u2 +

1
2

(cid:18) du
dt

ε
2

(cid:19)2(cid:33)

dt,

where the admissible class U = (cid:8)u ∈ H 1([0, π]) : u(0) = u(π) = 0(cid:9) , subject to the forced harmonic
oscillator

(19a)

(19b)

dx
dt
dp
dt

= p,

x(0) = 0,

= u − x,

p(0) = 0.

The prescription of boundary conditions in deﬁning the class of admissible controls U will soon play
a critical role when considering the unregularized case, i.e., ε = 0. For ease of notation in what
follows, we use overhead dots to denote diﬀerentiation with respect to time, e.g., ˙x = dx
dt .

We recast the problem into a form more amenable to standard tools from the calculus of varia-
tions. Using Lagrange multipliers, or costates in the language of optimal control theory and denoted
here by λ(t) and µ(t), the equivalent unconstrained saddle-point problem is given by

(20)

min
u∈U

= min
u∈U

(cid:90) π

0
(cid:90) π

0

L (x, ˙x, p, ˙p, λ, µ, u, ˙u) dt

(cid:18)

x +

u2 +

1
2

ε
2

˙u2 + λ( ˙x − p) + µ( ˙p + x − u)

(cid:19)

dt.

4

The Euler-Lagrange equations (see, for example, [5, 8, 24]) are given by

(21a)

(21b)

(21c)

(21d)

(21e)

δL
δx
δL
δp
δL
δλ
δL
δµ
δL
δu

=

=

=

=

=

∂L
∂x
∂L
∂p
∂L
∂λ
∂L
∂µ
∂L
∂u

−

−

d
dt
d
dt

∂L
∂ ˙x
∂L
∂ ˙p

= 1 − ˙λ + µ = 0,

= λ − ˙µ = 0,

∂L
∂ ˙x
∂L
∂ ˙p

(cid:12)
(cid:12)
(cid:12)
(cid:12)t=π
(cid:12)
(cid:12)
(cid:12)
(cid:12)t=π

= λ(π) = 0,

= µ(π) = 0,

= ˙x − p = 0,

= ˙p + x − u = 0,

x(0) = 0,

p(0) = 0,

−

d
dt

∂L
∂ ˙u

= u − µ − ε¨u = 0,

u(0) = u(π) = 0.

Note that the costates’ terminal conditions, present in Equations (21a) and (21b), are a result of an
integration by parts again test functions ϕ ∈ C∞([0, T ]), which do not necessarily vanish at t = π,
in the derivation of the Euler-Lagrange equations.

By direct integration, it’s easy to see the following functions

(22a)

(22b)

λ∗ = − sin(t),
µ∗ = − cos(t) − 1
are the optimal costates. This implies, after using the method of variation of parameters, see
e.g. [3], to solve Equation (21e), the optimal control is
(cid:16) π√

(cid:16) π−t√

(cid:16) t√

(cid:17) (cid:16)

(cid:17)(cid:17)

(cid:17)

− cos(t) − ε − 1

(ε + 2) sinh

+ ε sinh

csch

(23)

u∗ =

ε

ε

ε + 1

ε

.

Additionally, we solve for the optimal state x∗ in a similar fashion which results in

√

(cid:1)

(cid:18)

(cid:19)

(cid:18) t
√

ε3/2 sinh

(24) x∗ =

εcsch (cid:0) π
ε
(ε + 1)2
√
ε(ε + 2)csch (cid:0) π
ε
(ε + 1)2
while the optimal objective J ∗ is found to be


ε
(cid:18)

(cid:18)√

sinh

+

ε

(cid:1)

(25)

J∗ =

ε tanh

√

− ε sin(t)

−

(cid:19)

t sin(t)
2(ε + 1)
(cid:18) π
√
ε

− sinh

(cid:19)

(cid:18) π − t
√
ε

+ cos(t) − 1

(cid:19)

(cid:19)

cos(t)

+ cosh

(cid:19)

(cid:18) π
√
ε

(cid:19)

sin(t)

,

(cid:18) π
√
2

(cid:19)



ε

coth2 (cid:16) π

√

2

ε

(cid:17)

(ε + 1)2 + 1



 −

π(2ε + 3)
4(ε + 1)

.

With these calculations in hand and further considering any time 0 < t ≤ T , we may take these

optimal functions’ limits as ε approaches zero from above. We ﬁnd that

(26a)

(26b)

(26c)

lim
ε→0+

lim
ε→0+

lim
ε→0+

u∗ := ulimit = −1 − cos(t)

x∗ := xlimit = −

J∗ := Jlimit = −

t sin(t) + cos(t) − 1

1
2
3π
4

.

Although the unregularized problem exhibits no features of an ill-posed problem, note that the
limiting optimal control fails to remain in the admissible class U since ulimit does not vanish at
t = 0. However, from the explicit calculation, we have that for each ε > 0, there exists a u ∈ U
which solves the optimal control problem (18). Thus, taking small values of the regularization
parameter ε manifests in a type of boundary layer in the vicinity of t = 0 for optimal control u∗.
5

That is, the optimal control develops a steep gradient at t = 0 as ε → 0+, and, consequently,
limε→0+ (cid:107)u∗ − ulimit(cid:107) H 1([0,T ]) (cid:54)= 0. The eﬀect this has on numerical computations will be discussed
shortly.

We numerically solve optimal control problem (18) in two ways. The ﬁrst, performed pointwise
in time, is to use MATLAB’s fmincon which implements an interior-point method [4]. The second
is to use a method due to Calarco, et al. [6,7], called the Chopped Random Basis (CRAB) method.
It relies on choosing controls from the span of an appropriately chosen ﬁnite set of basis functions
so that the optimization is performed over a set of unknown coeﬃcients. The choice of basis is
problem-speciﬁc but is always chosen so that controls remain in the appropriate admissible space.
The choice of representation we make here is the following sine series:

(27)

ur(t) =

N
(cid:88)

j=1

rj
j2 sin

(cid:18) 2jπ
T

(cid:19)

,

t ∈ [0, T ],

where the coeﬃcients rj ∈ [−1, 1] are parameters to be optimized over. Note that we choose
the amplitudes in Equation (27) to decay quadratically because the Fourier series of absolutely
continuous functions exhibits this type of decay [22]. In this way, the search space of amplitudes is
not severely restricted, yet early iterations of the controls generated by the CRAB method are not
highly oscillatory.

Figure 1. A numerical solution of optimal control problem (18), with ε=1, via the
CRAB method and MATLAB’s fmincon. Left Panel: The controls found via both
numerical methods and the exact optimal control given in closed-form by Equa-
tion (23). Right Panel: The states found via both numerical methods and the exact
state given in closed-form by Equation (24).

The CRAB method is of Galerkin-type. Recall that the intent behind any Galerkin method
is to choose the number of basis functions N simultaneously large enough to deﬁne an accurate
approximation, yet small enough so that the overall procedure remains computationally inexpensive.
For this problem, we ﬁnd that just 12 modes are suﬃcient. The optimization problem is now a
small-scale nonlinear programming (NLP) problem and can be solved using any number of industry-
standard techniques. The technique we use to solve the resulting NLP problem is Diﬀerential
Evolution (DE) [16].

In our numerical study, we focus on investigating the role of the Tikhonov parameter ε. To this
end, we set ε = 1 and show the numerical solution of Problem (18) in Figure 1. We solve the
6

state equations (19) with MATLAB’s ODE45 solver. The numerics shown there demonstrate the
adequacy of both methods used to solve Problem (18). The numerical implementation of these
methods is provided in the form of MATLAB code in Appendix A.

By setting ε = 1, we ﬁnd that we have strongly regularized the problem. This is seen in a
pointwise comparison between x∗, shown in Figure 1, and xlimit, shown in Figure 2, especially for
later times t. Yet, by taking ε = 0.001, we ﬁnd that both optimization methods struggle to resolve
the sharp transition of the control in the boundary layer near t = 0. We ﬁnd ε = 0.04 to be a
good intermediate value under the tension of under- and over-regularizing the control problem (the
bias-variance dilemma). In this case, we see that the CRAB method successfully ﬁnds the optimal
control u∗, while fmincon develops undesirable oscillations in the control near the boundary layer.

Figure 2. Examples of when the Tikhonov parameter ε is small. The conventions
here are consistent with Figure 1. The top panels correspond to ε = 0.001 while the
bottom panels have ε = 0.04. The bottom panels also include the limiting control
and state functions given by Equation (26).

4. Concluding Remarks

In this work, we provide a pair of standard optimization problems where an application of the
Tikhonov regularization technique is crucial. Moreover, they provide instructive examples which
can be used in basic courses on numerical linear algebra and optimization. We also demonstrate
7

the utility of the CRAB method, over more standard numerical optimization methods, when trying
to solve control problems that exhibit sharp transition regions in the optimal control.

The author gratefully acknowledges helpful discussions with T. Witelski, R.H. Goodman, and

M. Porter.

5. Acknowledgments

References

[1] J. Adriazola and R. H. Goodman. Optimal control approach to gradient-index design for beam reshaping. Journal

of the Optical Society of America A, 39(5):907, apr 2022.

[2] J. Adriazola and R. H. Goodman. Reduction-based strategy for optimal control of bose-einstein condensates.

Physical Review E, 105(2), feb 2022.

[3] C. S. Bender and S. Orszag. Advanced mathematical methods for scientists and engineers I: Asymptotic methods

and perturbation theory. Springer-Verlag New York Inc., New York, NY, 2010.

[4] S. Boyd and L. Vandenberghe. Convex optimization, volume 1. Cambridge University Press, Cambridge, 2004.
[5] A. E. Bryson and Y.-C. Ho. Applied optimal control: optimization, estimation, and control. Hemisphere Pub-

lishing Corporation, 1975.

[6] T. Caneva, T. Calarco, and S. Montangero. Chopped random-basis quantum optimization. Phys. Rev. A,

84:022326, Aug 2011.

[7] P. Doria, T. Calarco, and S. Montangero. Optimal control technique for many-body quantum dynamics. Phys.

Rev. Lett., 106:190501, May 2011.

[8] I. Gelfand and S. Fomin. Calculus of Variations. Prentice-Hall, Englewood Cliﬀs, New Jersey, 1963.
[9] M. Hintermuller, D. Marahrens, P. A. Markowich, and C. Sparber. Optimal bilinear control of Gross-Pitaevskii
equations. SIAM (Society for Industrial and Applied Mathematics) Journal on Control and Optimization,
51(3):2509–2543, 2013.

[10] A. E. Hoerl and R. W. Kennard. Ridge regression: Biased estimation for nonorthogonal problems. Soviet Math-

ematics, 12(1):55–67, 1970.

[11] U. Hohenester, P. K. Rekdal, A. Borzi, and J. Schmiedmayer. Optimal quantum control of Bose-Einstein con-

densates in magnetic microtraps. Physical Review A, 75(2):023602, 2007.

[12] E. Lieb and M. Loss. Analysis. American Mathematical Society (AMS), Philadelphia, PA, second edition, 2010.
[13] J. Mennemann, D. Matthes, R. Weishaupl, and T. Langen. Optimal control of Bose-Einstein condensates in

three dimensions. New Journal of Physics, 17(11):113027, 2015.

[14] B. Neal. On the bias-variance tradeoﬀ: Textbooks need an update. CoRR, abs/1912.08286, 2019.
[15] D. L. Phillips. A technique for the numerical solution of certain integral equations of the ﬁrst kind. Journal of

the ACM, 9:84–97, 1963.

[16] R. Storn and K. Price. Diﬀerential evolution–a simple and eﬃcient heuristic for global optimization over contin-

uous spaces. Journal of Global Optimization, 11(4):341–359, 1997.

[17] G. Strang. Introduction to linear algebra, volume 3. Wellesley-Cambridge Press, Wellesley, MA, 1993.
[18] A. N. Tikhonov. On the stability of inverse problems. Doklady Akademii Nauk SSSR, 39(5):195–198, 1943.
[19] A. N. Tikhonov. Solution of incorrectly formulated problems and the regularization method. Soviet Mathematics,

39(5):1035–1038, 1963.

[20] A. N. Tikhonov and V. Y. Arsenin. Solution of Ill-posed Problems. Winston and Sons, 1977.
[21] A. N. Tikhonov, A. V. Goncharsky, V. V. Stepanov, and A. G. Yagola. Numerical Methods for the Solution of

Ill-Posed Problems. Springer, Dordrecht, 1995.

[22] L. N. Trefethen. Spectral methods in MATLAB. Society for Industrial and Applied Mathematics (SIAM), New

York, NY, 2000.

[23] G. Wahba. Spline Models for Observational Data. Society for Industrial and Applied Mathematics, 1990.
[24] T. Witelski and M. Bowen. Methods of Mathematical Modeling. Spring Undergraduate Mathematics Series,

Cham, 2016.

8

%% Solves an Optimal Control Problem via CRAB and fmincon
clear, close all

Appendix A. Main Script

% Tikhonov weight g and Optimal control in closed-form
g=.04;
uExact=@(x)(-1).*(1+g).^(-1).*(1+g+cos(x)+(-1).*csch(g.^(-1/2).*pi).*((2+g).* ...

sinh(g.^(-1/2).*(pi+(-1).*x))+g.*sinh(g.^(-1/2).*x)));

% Initial conditions for the state and control boundary conditions
x0=[0 0];
u0=0;uT=0;t0=0;T=pi;

%Define the objectives for each case and number of optimization points
JCRAB=@(u)getObjective(u,g,false,x0,t0,T);
Jfmin=@(u)getObjective(u,g,true,x0,t0,T);

% Differential Evolution Parameters
DEParams.F=0.8;DEParams.CR=0.7;
DEParams.NP=120;DEParams.Nmax=300;
DEParams.ND=12;

% Amplitude hyperrectangle for the CRAB method
l=zeros(1,DEParams.ND);
for j=1:DEParams.ND

l(j)=(2*rand-1)/j^2;

end

% Execute differential evolution
optimalamps=diffevoND(JCRAB,l,DEParams);

% Reconstruct the control from the CRAB amplitudes and compute resulting state
uCRAB=recon(linspace(t0,T,1000),optimalamps(:,end));

% Prepare for a blackbox optimization
options = optimoptions(@fmincon,’Display’,’iter’,’Algorithm’,’interior-point’);

% Keep number of function evaluations consistent with CRAB
options.MaxFunctionEvaluations=DEParams.NP*DEParams.Nmax;
fminPts=15;
t=linspace(t0,T,fminPts);

% initial guess on the control
u00=t.*(t-T);

% set equality constraints on the control
Aeq = zeros(fminPts);
Aeq(1,1)=1;

9

Aeq(end,end)=1;
beq=zeros(fminPts,1);

% Execute an interior-point method using MATLAB’s fmincon
ufmin=fmincon(Jfmin,u00,[],[],Aeq,beq,[],[],[],options);
ufmin=spline(t,ufmin);
ufmin=@(t)ppval(t,ufmin);

% Solve for the states
xCRAB =SolveStates(t0,T,uCRAB,x0);
xfmin =SolveStates(t0,T,ufmin,x0);
xExact=SolveStates(t0,T,uExact,x0);

Appendix B. Functions Used

function x=SolveStates(t0,T,u,x0)
% Solve for states using ODE45
[~,states]=ode45(@(t,x)StateRHS(t,x,u),[t0 T],x0);
x=states(:,1);x=spline(t,x);x=@(t)ppval(t,x);
end

function dxdt=StateRHS(t,x,u)
dxdt=[x(2)

u(t)-x(1)];

end

function J=getObjective(u,g,blackbox,x0,t0,T)
if blackbox

% this is coming from fmincon
t=linspace(t0,T,length(u));
dt=t(2)-t(1);
u=spline(t,u);
u=@(t)ppval(t,u);

else

% this is coming from CRAB
t=linspace(t0,T,1000);
dt=t(2)-t(1);
u=recon(t,u);

end
% solve for the states
x=SolveStates(t0,T,u,x0);
% compute the derivative of the control
udot=gradient(u(t),dt);
% the objective functional
J=trapz(t,x(t)+.5*u(t).^2+.5*g*udot.^2);
end

function u=recon(t,params)
% reconstruct the control from the CRAB amplitudes

10

t0=t(1);T=t(end)-t0;
sinepart=0;
for i=1:length(params)

sinepart=sinepart+params(i)*sin(i*pi*(t-t0)’/T);

end
u=sinepart;
u=spline(t,u);
u=@(t)ppval(t,u);
end

function optimalamps=diffevoND(f,l,DEparams)
%Minimizes f(x) using the differential evolution algorithm
%of Storn, Price
%Inputs:
%f is the function handle we want to minimize
%l is the length of the interval for the defined function
%DEparams.CR,DEparams.NP,DEparams.F are the diffevo
%parameters discussed in the literature
%Output: the possible global minimizer
%Initialize a population of candidate minimizers from the intervals [-l,l]
pop=zeros(DEparams.ND,DEparams.NP);
for j=1:DEparams.ND

for i=1:DEparams.NP

pop(j,i)=(l(j)*(2*rand-1));

end

end
fpop=zeros(DEparams.NP,1);
z=zeros(DEparams.ND,1);
for i=1:DEparams.NP

fpop(i)=f(pop(:,i));

end

%Set DEparams.tolerance and maximum number of iterations
counter=0;tic
while counter<DEparams.Nmax

newpop=pop;
newfpop=fpop;
for i=1:DEparams.NP

for j=1:DEparams.ND

currentmember=pop(j,i);
%Choose 3 distinct elements different from current member
randind=randsample(DEparams.NP,3);
while length(unique(randind))<3||~isempty(find(randind==i,1))

randind=randsample(DEparams.NP,3);

end
a=pop(j,randind(1));
b=pop(j,randind(2));
c=pop(j,randind(3));

11

%Compute currentmember’s potentially new location y
r=rand;
%Potential Cross Over
if r<DEparams.CR

y=a+DEparams.F*(b-c);

else

y=currentmember;

end
z(j)=y;

end
fCandidate=f(z);
if fCandidate<fpop(i)
newpop(:,i)=z;
newfpop(i)=fCandidate;

end

end
%Update
counter=counter+1;
pop=newpop;
fpop=newfpop;
fprintf(’%f cost after %i iterations of DE complete in %f seconds.\n’,...

min(fpop),counter,toc)

[~,optindex]=min(fpop);
optimalamps(:,counter)=pop(:,optindex);

end
end

12

