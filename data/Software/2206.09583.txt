Prepared for submission to JINST

Rebalance and Smear for Multi-jet Background Estimation

Samuel Bein1 Christian Sander2

1Universität Hamburg, Luruper Chaussee 149, 22761 Hamburg, Germany
2Deutsches Elektronen-Synchrotron DESY, Notkestr. 85, 22607 Hamburg, Germany

E-mail: samuel.bein@cern.ch

Abstract: For many particle collider searches for physics beyond the Standard Model in ﬁnal
states with jets and missing transverse momentum, events from QCD multi-jet processes are an
important and challenging background contribution. The CMS and ATLAS experiments have
previously developed data-driven methods designed to succeed where Monte Carlo methods suﬀer
large theoretical and experimental uncertainties. One such method is Rebalance and Smear (R&S),
which predicts QCD backgrounds by applying a series of folding and unfolding techniques to
data control regions. A top-to-bottom description of the R&S method is presented, along with a
discussion of its applicability and limitations. A software application is provided that performs the
R&S method using public, non-proprietary tools, interfacing with data sets produced by Delphes3.
In general, the method is suitable for predicting multi-jet backgrounds in searches for stable non-
detectable particles, such as dark matter candidates. A case study is carried out in simulated events
𝑠 = 14 TeV in the context of a potential search for Higgsino dark
of proton-proton collisions at
matter produced in the decay products of supersymmetric quark partners. Sources of potential bias
are explored and prescriptions for evaluating systematic uncertainties are suggested.

√

2
2
0
2

l
u
J

0
3

]
x
e
-
p
e
h
[

2
v
3
8
5
9
0
.
6
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
Contents

1 Motivation

2 Rebalance and Smear methodology

Impact on events with real and fake /𝑝

2.1
2.2 Analyzing the prediction sample
2.3 Event samples
2.4 QCD jet and event model

T

2.4.1 Likelihood of response
2.4.2

Prior probability distribution for /𝑝

T

2.5 Rebalance procedure
2.6 Events with well-measured objects

3 Example: search for Higgsino dark matter

3.1 Signal model attributes
3.2 Event selection

3.2.1
Pre-selection and classiﬁer training
3.2.2 Baseline and signal region selection

4 Systematic uncertainty evaluation

5 Summary

A Framework/code, simulation

1

3
3
4
4
4
4
5
7
8

8
10
10
10
11

14

15

17

1 Motivation

The possibility of observing new particles beyond the Standard Model (SM) at the energy frontier
is the subject of much investigation, particularly at the Large Hadron Collider (LHC) [1]. A leading
factor motivating this eﬀort is the observation of dark matter (DM) as the dominant contribution to
the mass of galaxies and the cosmic medium [2–4]. A rich programme of DM searches is performed
at the LHC, in particular by the ATLAS [5] and CMS [6] experiments, and large progress has been
made in excluding parameter regions of various models identiﬁed as consistent with the dark matter
hypothesis [7], which serve as complementary constraints to direct detection experiments [8–11].
The sensitivity of the LHC experiments to such a production of DM is maximal when consid-
ering scenarios in which new, strongly-interacting particles are produced and each decay into one
or more jets and a DM particle. The most prominent example for an extension of the SM that allows
for this topology is supersymmetry (SUSY) [12–18] with 𝑅-parity conservation [19, 20]. The
supersymmetric partners (superpartners) of the gluon (gluino) and quarks (squarks) are expected to

– 1 –

be produced at the LHC if their masses are light enough, while the lightest neutralino—a mixture of
superpartners of the neutral gauge and Higgs bosons—acts as the DM candidate. Such scenarios, if
realized in nature, would lead at the LHC to signatures with jets with anomalously large transverse
momentum and events with signiﬁcant imbalance in the transverse momentum calculated from all
reconstructed particles, /𝒑T with magnitude /𝑝

T.

Although events from multi-jet processes from quantum chromodynamic (QCD) interactions
have only little genuine missing transverse momentum, e.g., from neutrinos being produced in
electroweak heavy ﬂavour decays, they can exhibit large values of /𝑝
T after the event reconstruction
as a result of mis-measured jet momentum. The yield of such events after the selection cuts
is typically expected to be small, but its estimation is challenging because several features of
QCD multi-jet events are poorly modelled in Monte Carlo (MC) simulation, owing largely to their
governance by non-perturbative interactions. These quantities include the production cross section,
jet multiplicity, heavy ﬂavour jet multiplicity, and angular relations among jets. Further challenges
arise in the modelling of instrumental eﬀects that can cause /𝑝
T, such as energy loss from non-
instrumented or disabled detector regions, jets from calorimetric noise, beam induced background,
or cases with pile-up jets being wrongly identiﬁed to originate from the hard-scatter interaction.
This motivates the development of data-driven techniques to estimate the multi-jet (or 𝛾 + jets)
background. Ideally, approaches rely on simulation only for particularly well-modelled quantities,
but derive the most important features using real data. As with any data-driven approach, the
method must be robust against possible signal contamination that may bias the prediction.

T

√
/

T signiﬁcance at low jet multplicity, deﬁned as 𝑆 = /𝑝

For searches focusing on large jet multiplicity, the ATLAS collaboration developed a technique
to measure the shape of the /𝑝
𝐻T, where 𝐻T
is the scalar sum of all transverse jet momenta in the event. This shape is used to extrapolate from
low to high 𝑆 values at high jet multiplicity, where the QCD multi-jet background is dominant [21].
For searches at lower jet multiplicity, various techniques have been used: early searches by CMS
used, among other techniques, so-called as ABCD methods that exploit that the signal region is
deﬁned by requirements on two highly separating observables, e.g., /𝑝
T and the minimal azimuthal
angular distance between the leading jets and /𝒑T.
Inverting one or both of those requirements
establishes a multi-jet enriched control region that can be used to estimate the multi-jet contribution
for the signal region. The dominant uncertainties arise from the modelling of the correlation of the
two chosen observables [22]. Another approach used by the ATLAS collaboration is the so-called
jet smearing method [23]. The main idea is to select well-measured multi-jet events at low 𝑆
values, so called seed events, and then smear the jets of those events with jet response distributions.
The smearing can be performed multiple times to increase the statistics of the produced pseudo
data set. For the above methods, large systematic uncertainties often arise as a result of the highly
approximate nature of the underlying assumptions of the respective models, or from limited statistics
of control regions used by the estimation procedure.

This document presents the concepts and particulars of the Rebalance and Smear (R&S)
method, which is essentially a data-driven, generative QCD model that aims to mitigate issues
associated with other estimation methods. A complementary code package is also made available
which serves as a generic implementation that interfaces with public tools. Early development of
the method was carried out at CMS [24] to measure fake /𝑝
T backgrounds for searches, and later
developments were carried out as a component of a series of CMS searches in the all-hadronic

– 2 –

channel [22, 25, 26]. A modiﬁed version of the method has been used by ATLAS for the search
for invisibly decaying Higgs bosons produced in Vector Boson Fusion [27]. The version presented
here makes use of the Delphes3 [28] framework, and the method has been extended to predict
backgrounds in ﬁnal states other than the all-hadronic channel, including channels with one or more
photons.

Section 2 gives an introduction to the technical details of the method and describes the various
required inputs. An example use case based on a hypothetical search for pure Higgsino DM is
presented in Section 3. Section 4 provides a discussion of relevant systematic uncertainties along
with a list of potential failure modes. Finally, Section 5 concludes with an outlook about future
applications of the method.

2 Rebalance and Smear methodology

The R&S method is an event-by-event unfolding of, and subsequent application of, the response
of the detector to jets. In the version presented, the unfolding makes use of Bayesian inference to
obtain probable values for the true momenta of jets in a seed event from data under the hypothesis
that the event originated from a QCD multi-jet process. This inference is made using a model of
the jet response as well as prior knowledge of the distribution of true missing transverse momentum
in multi-jet events. Other implementations of R&S adjust the momenta of the jets of the seed event
within their uncertainties via a kinematic ﬁt in such a way that no missing transverse momentum is
present after rebalancing.

The subsequent application of the detector response to the jets amounts to a smearing, or
rescaling, of each jet’s momentum by a value randomly sampled from the jet response function.
The rebalanced and smeared events constitute a sample that is a proxy for the fake-/𝑝
T background,
referred to as the prediction sample. The prediction sample is then treated like an ordinary MC data
set, namely, the analysis is run over the prediction sample to obtain the predicted background yield
in a chosen search region. The following subsection explains why and in which circumstances the
prediction sample can provide a reliable background estimate.

T

2.1

Impact on events with real and fake /𝑝
When events in an inclusive sample without real /𝑝
T are processed through the Rebalance and Smear
procedure, the resulting sample conforms well to the original; moreover, the processed events
preserve the exponentially-suppressed /𝑝
T tail and jet multiplicity distribution native to the input
distribution. However, when events in an ensemble with real /𝑝
T are subjected to the same process,
the output conforms to a much more suppressed /𝑝
T tail than the input. In practice, a typical seed
event sample contains a mixture of real and fake-/𝑝
T events, but because the inclusive cross sections
of electroweak processes are negligible compared to QCD multi-jet production, the contribution
of real /𝑝
It
follows that the procedure can be safely applied on real data seed samples, and that the output events
populating the /𝑝

T seed events to the rebalanced and smeared /𝑝

T tail is correspondingly negligible.

T tail are a good proxy for the fake-/𝑝

T contribution.

In order for the prediction sample to represent an unbiased estimate of the QCD multi-jet,
T,
T would deplete the seed sample, causing an

two criteria must be satisﬁed. First, the seed sample must be inclusive with respect to the /𝑝
i.e. any pre-selection or trigger requirement on the /𝑝

– 3 –

T such that the contribution of real /𝑝

underestimate and shape distortion in the prediction sample. Second, the signal region (SR) must
have suﬃciently large /𝑝
T events to the prediction is suppressed.
To quantify the remaining contamination, simulated signal events can be processed through the
R&S steps to estimate the rate of the signal’s contribution to the background estimate for a given
SR. In typical cases, such contamination is found to be negligible with large /𝑝
T thresholds on the
order of 100 GeV.

2.2 Analyzing the prediction sample

After rebalancing and smearing the seed events, the prediction sample can be sorted into SRs
using the ordinary selection requirements employed by the analysis. If the luminosity of the seed
sample is the same as that of the ﬁnal target data, and if an event’s jets are smeared just once,
then the unweighted counts from the prediction sample in each SR serve as a properly-normalized
approximation to the fake /𝑝
T background. In some cases, appropriate event weights have to be
considered, since the seed sample may be selected from data with prescaled triggers. To gain
additional statistics in the prediction sample, each unfolded seed event can be subjected to this
smearing process multiple times. Each smearing iteration operates on the rebalanced event via a
unique random sampling of the jet response, yielding a diﬀerent conﬁguration of jets each time.
This technique can be useful for ﬁlling out tails of distributions for signal regions deﬁned by very
tight cuts. With a suﬃciently large number of smearing iterations, a non-zero prediction in each
SR is reachable. An event weight of 1/𝑛 restores the prediction to the correct scale, where 𝑛 is
the total number of smearing iterations applied to the corresponding seed event. The assignment
of statistical uncertainty to a prediction sample in which seeds have been re-used in this manner is
carried out using a bootstrapping technique. Here, a number of small subsets, advisably order 10
or larger, are drawn from the complete seed sample, and the prediction is made once per subset. A
weight is applied to the prediction from each subset equal to the ratio of total number of seed events
to the number of seeds in the subset. From the ensemble of predictions, the standard deviation
taken to represent the statistical uncertainty in the prediction.

2.3 Event samples
This background estimation implementation is based on simulated 𝑝 𝑝 collision events with center-
of-mass energy of 14 TeV generated and hadronized using Pythia8.1 [29]. For these samples, the
production ﬂag sets HardQCD:all, SUSY:gg2squarkantisquark, ffbar2W, and ffbar2gmZ are
used. After hadronization and simulated parton showering, events are processed with the detector
simulation program Delphes3 [28] using a CMS-like detector geometry and resolution. Jets are
clustered using the anti-𝑘T jet algorithm implemented within FastJet [30] with a jet cone size
parameter of 0.4. Generator-level jets are clustered from the generated particles with Pythia
status=1, neglecting neutrinos. Reco-level jets are obtained by clustering all reconstructed ﬁnal
state particles identiﬁed by Delphes3, which includes electrons, muons, photons, and hadrons.

2.4 QCD jet and event model

2.4.1 Likelihood of response

Both the R&S steps rely on a supplied model for the jet energy response distribution. In the presented
implementation, the response distribution is derived from simulated QCD multi-jet events with the

– 4 –

response deﬁned for a matched pair of reco-level and generator-level jet as the ratio of the reco-level
jet energy to the generator-level jet energy. Further, it is assumed that the directions of the 𝑛 𝑗 jets
in a given event are measured with ideal accuracy, which is well motivated by comparing the good
angular resolution of the detectors to their larger energy resolution:

𝑱reco = ˆ𝐶 𝑱true,

(2.1)

where 𝑱reco and 𝑱true are respectively length-𝑛 𝑗 vectors of the reconstructed and true jet four-vectors,
ˆ𝐶 is a diagonal matrix of jet mis-measurement scale factors (𝑐1, 𝑐2, ..., 𝑐𝑛). The probability for
a measurement to correspond to a particular 𝑐𝑖 given a true momentum 𝑝𝑖,true is the single-jet
likelihood

𝐿𝑖 ≡ 𝑃( 𝑝𝑖,reco/𝑝𝑖,true| 𝑝𝑖,true) = 𝑃(𝑐𝑖 | 𝑝𝑖,true),

(2.2)

also referred to as the probability density function (PDF) of the jet response. The response is binned
in ranges of 𝑝T and 𝜂, and a few examples are shown in Figure 1 (left). The response function
for a single jet is obtained by linearly interpolating between binned PDF functions. A reasonably
accurate model of the jet response is key, as the associated systematic uncertainty is often the
predominant one.

The choice to neglect the energy of neutrinos when clustering generator-level jets ensures that
the response is approximately the same for diﬀerent jet ﬂavours. This allows a single set of jet
response templates to be used rather than multiple sets for jet ﬂavour categories. In a scenario with
data and not simulated events, either the shape of the jet response should be extracted directly from
the data, or the width and scale of the distributions derived from simulated data or by other means
should be validated and corrected for any mis-modelling. The association of generator-level and
reco-level jets used for the construction of the likelihood is made via a matching criterion given by

An isolation criterion of 𝑝sum
where

T

Δ𝑅( 𝒑reco

, 𝒑true) < 0.4.

(2.3)

/𝑝T < 0.01 is applied to each selected generator-level (reco-level) jet,

𝑛jets
∑︁

( 𝑝T)𝑖

(2.4)

𝑝sum
T =

𝑖=1
is the sum over generator-level (reco-level) jets within Δ𝑅 < 0.5 of the selected jet, excluding the
selected jet. This ensures a clean deﬁnition of the jet energy response with no artiﬁcial eﬀects, e.g.
from one generator-level jet being reconstructed as two reco-level jets, which would lead to very
small response values.

2.4.2 Prior probability distribution for /𝑝

T

Rebalancing additionally relies on a provided PDF of the true missing transverse momentum of
QCD multi-jet events, as well as the azimuthal angle Δ𝜙( /𝒑hard
) between the leading jet and
the true /𝑝
T (prior). These two PDFs are treated as separable, and are taken from generator-level
events. They are parametrized in categories of the multiplicity of 𝑏-tagged jets, where the 𝑏-tagging
emulation from Delphes3 is used. The distribution of the generator-level /𝑝
T is shown in Figure 1
(right). These PDFs give expression to the prior probability for an arrangement of jets in a given
event as

𝑗1
T

, 𝒑

T

– 5 –

(a)

(b)

(c)

Figure 1: Jet response implemented for the Delphes simulation for three diﬀerent choices of
ranges for 𝑝T and 𝜂 (a), used as input to the likelihood and as smearing templates. PDF of the
generator-level /𝑝hard
(c) of in simulated QCD multi-jet
events, factors in the rebalancing prior.

(b) and azimuthal angle with respect to /𝑝hard

T

T

𝜋( 𝑱true) = 𝑃[Δ𝜙

( 𝑱true)] · 𝜋0( 𝑱true),

, (cid:174)𝑝1
T
where 𝜋0( 𝑱true) is an initial prior (“ur"-prior) on the parton jet four-vectors, taken to be a constant
so as not to impose a bias on the 𝑝𝑇 spectrum of jets.

/𝒑hard
T

(2.5)

The quantity that constrains the posterior density the most is the prior density for the true /𝑝

T.
For QCD multi-jet events, the true /𝑝
T is characteristically small since a ﬁnite value arises only
from low-momentum neutrinos appearing in the decays of heavy-ﬂavour hadrons in jets, or from
particles falling outside of the acceptance of the selection used when computing the /𝑝
T. At high
instantaneous luminosities additional jets from pile-up interactions are present, typically with small
𝑝T. Those additional jets deteriorate the /𝑝
T against
T or /𝑝hard
eﬀects from pile-up, it is practical to consider a proxy for the /𝑝
,
T

T resolution, and therefore, to stabilize the /𝑝
T referred to here as hard /𝑝

– 6 –

00.511.522.53genT/precoTp00.010.020.030.040.050.060.070.080.09unit normalized|=0-0.4h=200-300 GeV, |Tp|=2.5-6h=20-25 GeV, |Tp|=0-0.4h=20-25 GeV, |Tp0102030405060708090100 [GeV]hardTp00.010.020.030.040.050.060.070.08unit normalizedn(b-jets)=0n(b-jets)=12‡n(b-jets)00.511.522.53)j1Tp, hardTp(fD00.0050.010.0150.020.0250.030.0350.040.045unit normalizedn(b-jets)=0n(b-jets)=12‡n(b-jets)deﬁned as

/𝑝hard
T =

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

−

𝑛obj
∑︁

𝑖

( 𝒑T𝑖 · Θ( 𝑝T𝑖 − 30 GeV) · Θ(5 − |𝜂𝑖 |)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

(2.6)

The Heaviside functions Θ serve to remove many jets with low 𝑝T originating from pileup interac-
tions, and reduce the number of dynamic objects contributing to the sum. The hard /𝑝
T is highly
correlated to the traditional /𝑝
T and is suitable for DM searches. At a later stage, this choice results
in a more manageable number of free parameters present in the rebalance step of the procedure.
For the remainder of this document we adopt the /𝑝hard

T
To prevent biases that originate from jets migrating during the R&S phases across the 𝑝T
threshold of the considered analysis, i.e. 30 GeV, a looser 𝑝T criterion, i.e. 15 GeV, is used for the
jets to enter the R&S procedure.

T in all cases.

in place of /𝑝

2.5 Rebalance procedure

The goal is to estimate the probable conﬁguration of jets 𝑱true for each event, given that a particular
set of measured jet momenta 𝑱reco has been made, that a well-deﬁned model for the jet response
function is available, and that some prior knowledge of the true /𝑝hard
of QCD multi-jet events. In
this context, Bayes’ theorem states

T

𝑃( 𝑱true| 𝑱reco) = 𝑃( 𝑱reco| 𝑱true) · 𝜋( 𝑱true),

(2.7)

where 𝜋( 𝑱true) is the 𝑛-dimensional prior probability density for the true jet collection, which
encodes the low-/𝑝
T constraint as well as information about the angle of azimuthal incidence
between the leading jet and the vectorial /𝑝hard
. Treating the jets as independent from each other
and assuming the directionality of jet momenta is measured precisely allows the likelihood to be
factorized and written as

T

𝑃( 𝑱reco| 𝑱true) =

𝑛 𝑗
(cid:214)

𝑖=1

𝐿𝑖 =

𝑛 𝑗
(cid:214)

𝑖=1

𝑃(𝑐𝑖 | 𝒑𝑖,true).

(2.8)

Combining Eqs. 2.7, 2.8 gives

𝑃( 𝑱true| 𝑱reco) =

𝑛 𝑗
(cid:214)

𝑖=1

𝑃( 𝑝𝑖,reco| 𝑐𝑖) · 𝑃[ /𝑝hard

T

( 𝑱true)] · 𝑃[Δ𝜙

/𝒑hard
T

, (cid:174)𝑝1
T

( 𝑱true)] · 𝜋0( 𝑱true).

(2.9)

This posterior density is maximized for each seed event, which leads to a single best-ﬁt
conﬁguration 𝑱∗
true, corresponding to a vector of best-ﬁt 𝑐𝑖 values for each event. The 𝑝𝑇 values of
jets are then smeared according to the jet response, and events are analyzed to form the prediction.
The following are choices made in this implementation regarding the rebalancing procedure that
have been tested and found to work adequately.

Before calling the maximization routine, a suitable initialization of the 𝑐𝑖 values is searched for
that helps to ensure convergence by placing the initial density on the smooth, well-deﬁned portion
of the posterior PDF. For the initialization, it is checked whether a reasonable value of hard /𝑝
T can
be obtained via the scaling of a single jet 𝑝T, where reasonable means that /𝑝hard
true) resides

( 𝑱∗

T

– 7 –

somewhat near the maximum value of the PDF, where 𝐽∗ is a vector of the modiﬁed (initialization)
values of the jets. An initialization target /𝑝hard

is identiﬁed for a given event as

T

target /𝑝hard

T = max [30 GeV, min[90 GeV, 𝐻T/3]],

(2.10)

where 𝐻T is the magnitude of the scalar sum of all jets in the event. It is then checked whether any
single jet can have its magnitude re-scaled such that the re-calculated hard /𝑝
T assumes the above
target value. If such a solution exists, which results in |𝑐init
𝑖 − 1| < 0.8 for jet 𝑖, the corresponding
conﬁguration is chosen for the initialization, and other jets are initialized to their unscaled values.
The maximization is performed with the ROOT TMinuit package in order to rebalance the
event, where each 𝑐𝑖 is allowed to ﬂoat with a step size 0.05. The PDF’s for the likelihood (and
prior) are linearly interpolated between the bins of 𝑝T and 𝜂 (𝐻T). This ensures a mostly smooth
gradient for the posterior density. A discontinuity can however occur if the multiplicity of 𝑏-tagged
jets changes during the rebalancing procedure, but such cases are found to be rare.

T

Several of the above choices have been developed empirically. The convergence rate for
simulated QCD multi-jet events is found to exceed 99% overall. Events for which the maximization
fails to converge are discarded, as well as any events which fail to arrive at a suﬃciently small value
of the rebalanced /𝑝hard
, in the case of the example presented, of 100 GeV. As a demonstration that
the /𝑝
T prior meaningfully restores truth-level information of an event with one or more poorly-
reconstructed jets, a test is performed on a sample of simulated events passing a baseline selection
> 200 GeV and 𝑛 𝑗 ≥ 2. The distribution of the 𝑝T ratio of the reconstructed
that requires hard /𝑝hard
and matched generator-level jets, i.e. the jet response distributions, are compared for the leading and
sub-leading jets in Figure 2, before and after rebalancing. While the original response distributions
exhibit evidence of severe mis-measurement, those of the rebalanced jets are found to peak more
narrowly at 1.

T

2.6 Events with well-measured objects

Objects who’s momentum and and energy are expected to be very well-measured compared to
jets, e.g., electrons, photons, and muons over common kinematic ranges, are not modiﬁed during
rebalancing or smearing. In a generic way, an appropriate resolution model can be applied to these
objects to be used for rebalancing and smearing, but it is generally found that ﬁxing such objects’
momentum at their measured values suﬃces to provide a description without visibly biasing the
background estimate.

3 Example: search for Higgsino dark matter

The CMS and ATLAS experiments have excluded DM masses up to a maximum of around 1–2 TeV
in gluino models and to several hundred GeV in certain models with squark pair production [31, 32].
Despite huge improvements in sensitivity during Run-1 and Run-2 of data taking, no clear
signal of DM production has been observed yet. However, there remain prominent regions of
still-unexplored phase space with the potential to provide a DM candidate, which would have been
produced abundantly in the data sets already collected by CMS and ATLAS. Canonical examples
are so-called compressed regions of simpliﬁed models [33–35], where a DM candidate particle and

– 8 –

(a)

(b)

Figure 2: Distributions of the jet response of in a sample of simulated QCD multi-jet events before
(red) and after (black) rebalancing for the leading (a) and sub-leading (b) jet in events with large
> 120 GeV). The response distributions are constructed as
missing transverse momentum (/𝑝
histograms of the ratio of the reconstructed or rebalanced jet 𝑝T to the generator-level 𝑝T. Events
are selected in a signal region with large, which enhances the prevalence of jet mis-measurements.

T

an associated heavier particle have masses near to each other, with a mass diﬀerence in the range of
a few or several hundred GeV. For such scenarios, the momentum of the visible decay products is
limited, resulting in low transverse and missing transverse momentum and thus a loss of acceptance
in the analyze search regions.

An example of a non-excluded compressed region a model with a kinematically accessible
squark and a Higgsino dark matter candidate, which means that the lightest neutralino is almost a
pure superpartner of the Higgs boson. Higgsinos can fully account for the dark matter relic density
Ωℎ if they have a mass of around 1.1 TeV [36], which puts them slightly beyond the boundary of
limits established by searches for squarks (or gluinos) decaying into DM at the Run-2 LHC—for
example, the searches by CMS [31], and likewise by ATLAS [32], indicate the sensitivity boundary
falling short of this LSP mass value despite large signal production cross sections.

In general, the sensitivity diminishes as the model spectrum becomes more compressed because
signal events exhibit more background-like characteristics, most importantly, they exhibit a more
rapidly falling /𝑝
T spectrum. To target these scenarios, signal regions with low thresholds on the /𝑝
T
must be employed, but these regions are characteristically overrun by events from the so-called fake-
/𝑝
T background. This background refers to SM events free of high-𝑝𝑇 neutrinos that nonetheless
have a large transverse momentum imbalance among the reconstructed objects due to detector
resolution eﬀects. The most prominent example of this background arises from QCD multi-jet
production, which by far accounts for the majority of events produced at the LHC. Depending
on the selection, it is a signiﬁcant background to searches in the all-hadronic channel, as well as
channels with one or more photon.

As proof of principle of the R&S method, a possible search for evidence of Higgsino DM

– 9 –

00.511.522.53genT/precoTp00.010.020.030.040.050.060.07normalizedreco jetsrebalanced reco jets00.511.522.53genT/precoTp00.010.020.030.040.050.060.07normalizedreco jetsrebalanced reco jetsis explored with simulated events. The characteristic small mass diﬀerence of the lightest and
next-to-lightest supersymmetric particles leads to ﬁnal states with not too large values of /𝑝
T and
consequently the sensitivity of the search improved if the QCD multi-jet background is reliably
estimated. The data-driven R&S method is applied to the simulated events to predict the QCD
multi-jet yield for a signal enriched selection. The performance of the method can be quantiﬁed by
a comparison of the R&S prediction with the yields obtained directly from the simulated samples.

3.1 Signal model attributes

The model for the signal process is a simpliﬁed model for direct squark production, which is referred
to as the T2qq model and which is commonly used in CMS and ATLAS papers for interpreting
searches for supersymmetry A schematic diagram of the squark production process is shown in
Fig. 3. Speciﬁcally, signal events feature the pair production a quark/anti-squark pair, where each
(anti-) squark decays into an (anti-) quark and a neutralino ( ˜𝑞 → 𝑞 ˜𝜒1
0), the neutralino being the
stable dark matter candidate.
In the present work, the more optimistic version of the model is
assumed, where the squark has an 8-fold degeneracy among the ﬁrst and second generation ﬂavour
states, each having a left- and right-handed squark. Such scenarios appear in constrained SUSY
models such as the cMSSM [37].

Figure 3: Schematic diagram representing a simpliﬁed T2qq model. Each produced heavy particle,
i.e. the two squarks in this example, decay into one quark and an undetectable particle, i.e. the
neutralino.

As mentioned, the Higgsino LSP ˜𝜒0

1 must have a mass of around 1.1 TeV in order to fully
explain the DM relic density. Therefore, a benchmark signal model point is chosen corresponding
to a Higgsino mass of 1.1 TeV and a squark mass of 1.15 TeV, a set of parameters that remains not
excluded by searches from CMS and ATLAS [31, 32]. This conﬁguration occupies the compressed
region, where the phase space of the visible squark decay products is limited due to the small mass
diﬀerence between the squark and neutralino.

3.2 Event selection

3.2.1 Pre-selection and classiﬁer training
An event pre-selection is deﬁned to be consistent with LHC searches and with standard /𝑝
Events are required to satisfy

T triggers.

– 10 –

˜q˜q˜χ˜χqq• /𝑝hard
T

> 120 GeV, computed with jets with 𝑝𝑇 > 30 GeV and |𝜂| < 5.0;

• 𝑛jets > 0, counting jets with 𝑝𝑇 > 30 GeV and |𝜂| < 2.4;

• 𝑛b-jets = 0, where a b-tagging eﬃciency of ∼80% is employed;

• 𝑛electron = 𝑛muon = 0;

• and 𝐻𝑇 > /𝑝hard

T

.

The pre-selection is applied on all simulated events, as well as on all rebalanced and smeared
simulated events. Note that events are and must be rebalanced and smeared before the application
of the pre-selection, given the looser object selection used during the R&S procedure. Each
rebalanced event is copied and independently smeared 100 times to increase the statistical precision
of the prediction in the baseline and signal regions.

A multivariate classiﬁer (BDT) is trained using the simulated signal and background events
passing the pre-selection using the ROOT TMVA package [38]. The classiﬁer is trained to dis-
criminate between T2qq events (signal) and electroweak boson events (background). Note that
the rebalanced and smeared events can also be used as input to the training, but in the idealized
detector it is found that the signal events most signiﬁcant kinematic overlap with the electroweak
background. A comprehensive set of event kinematical observables is used as input to the BDT,
including the hard /𝑝hard
, the 𝐻𝑇 , as well as the 𝑝𝑇 , 𝜂, and 𝜙 of the four highest-𝑝𝑇 jets. For events
with fewer than four jets, the inputs coding information from the non-existent jets are set to 0. The
azimuthal coordinates of all jets 𝜙 are taken with respect to the /𝒑T vector. The BDT is chosen to
have 200 trees and a maximum depth of 4. No over-training is observed in comparisons between
the training samples and a statistically independent validation sample.

T

3.2.2 Baseline and signal region selection

The baseline selection is deﬁned as the set of events passing the pre-selection, as well as passing a
tighter cut on the hard /𝑝hard
of 250 GeV. This requirement insures that the events are fully eﬃcient
with respect to typical /𝑝hard
triggers employed by CMS and ATLAS, and serves to improve the
T
signal-to-background ratio.

T

Distributions of the signal and background events passing the baseline selection are shown in
Figure 4. The stack of shaded histograms show the background predictions where the QCD multi-
jet estimate is given as the distribution of the rebalanced and smeared data set, and the non-QCD
background is taken directly from simulation. The QCD distribution taken directly from simulation
is drawn as black dots with error bars and is compared bin-by-bin to the R&S prediction in the ratio
panel. The QCD prediction is seen to give reasonable agreement with the simulated QCD, with no
evidence of a statistically-signiﬁcant deviation beyond about 20%.

The distributions of events passing the baseline selection are dominated by SM background, and
it is clear that further puriﬁcation is necessary. The distribution of the classiﬁer BDT is also shown
for events passing the baseline selection in Fig. 5, along with other kinematic distributions passing
a loosened BDT selection of BDT> 0.5. An advantage of the Rebalance and Smear technique can
be seen from the fact that a statistically precise modelling of the QCD background is established in
the signal region, even though only a handful of seed events exist to ﬁll out this region.

– 11 –

(a)

(b)

(c)

(d)

Figure 4: Distributions of the analysis observables for signal and background events after the event
pre-selection. The QCD background obtained directly from simulation is shown as black dots,
while the QCD prediction obtained from the R&S method, is shown in turquoise, and the lower
panel indicates the ratio of the two. The QCD prediction is seen to give reasonable agreement with
the simulated QCD.

– 12 –

250300350400450500550HardMet210310410510610710EventsWeak_YesAcmeTop_YesAcmeR&S prediction (Run3)QCD (simulated)T2qqSq1150Chi1100Delphes)-1 = 13 TeV (300 fbs250300350400450500550HardMet00.511.52R&S/multi-jet00.511.522.53MinDPhiHardMet210310410510610710EventsWeak_YesAcmeTop_YesAcmeR&S prediction (Run3)QCD (simulated)T2qqSq1150Chi1100Delphes)-1 = 13 TeV (300 fbs00.511.522.53MinDPhiHardMet00.511.52R&S/multi-jet12345678910NJets210310410510610710EventsWeak_YesAcmeTop_YesAcmeR&S prediction (Run3)QCD (simulated)T2qqSq1150Chi1100Delphes)-1 = 13 TeV (300 fbs12345678910NJets00.511.52R&S/multi-jet5001000150020002500HT210310410510610710EventsWeak_YesAcmeTop_YesAcmeR&S prediction (Run3)QCD (simulated)T2qqSq1150Chi1100Delphes)-1 = 13 TeV (300 fbs5001000150020002500HT00.511.52R&S/multi-jet(a)

(b)

(c)

(d)

Figure 5: Distributions of the analysis observables for signal and background events after the ﬁnal
event selection, namely, for events passing the pre-selection with a BDT score greater than 0.5.
The QCD background obtained directly from simulation is shown as black dots, while the QCD
prediction obtained from the R&S method, is shown in turquoise, and the lower panel indicates
the ratio of the two. The QCD prediction is seen to give reasonable agreement with the simulated
QCD.

– 13 –

0.4-0.2-00.20.40.6MvaScore210310410510610710EventsWeak_YesAcmeTop_YesAcmeR&S prediction (Run3)QCD (simulated)T2qqSq1150Chi1100Delphes)-1 = 13 TeV (300 fbs0.4-0.2-00.20.40.6MvaScore00.511.52R&S/multi-jet00.511.522.53MinDPhiHardMet210310410510610EventsWeak_YesAcmeTop_YesAcmeR&S prediction (Run3)QCD (simulated)T2qqSq1150Chi1100Delphes)-1 = 13 TeV (300 fbs00.511.522.53MinDPhiHardMet00.511.52R&S/multi-jet12345678910NJets210310410510610EventsWeak_YesAcmeTop_YesAcmeR&S prediction (Run3)QCD (simulated)T2qqSq1150Chi1100Delphes)-1 = 13 TeV (300 fbs12345678910NJets00.511.52R&S/multi-jet5001000150020002500HT210310410510610EventsWeak_YesAcmeTop_YesAcmeR&S prediction (Run3)QCD (simulated)T2qqSq1150Chi1100Delphes)-1 = 13 TeV (300 fbs5001000150020002500HT00.511.52R&S/multi-jetProcess
QCD multi-jet
Non-QCD multĳet
Total background
T2qq (1150,1100)

SR (BDT>0.67) 𝜎(SR)

81 ± 20
279 ± 17
360 ± 26
125 ± 32

2.67

Table 1: Event counts and estimated uncertainties of the relevant processes after the signal region
(SR) selection. The entry in the last column is a simpliﬁed signiﬁcance calculated from the quoted
yields and assumed uncertainties.

To select a ﬁnal signal region, a scan is performed on the BDT threshold, and a tight cut of
BDT>0.67 is found to yield a region with around 30% signal purity, with still over 100 signal events
surviving. Table 1 provides a summary of the yields of the relevant processes, and estimate of the
signiﬁcance of the signal region.

The uncertainty in the non-QCD estimate is taken to be around 5%, consistent with the
lost-lepton and invisible 𝑍 + jets background estimates made for signal regions with comparable
background counts in Reference [31]. The signal uncertainty, corresponding to 25%, is taken by
summing in quadrature the sources listed in Reference [31] for the scale, initial-state radiation,
jet energy scale, jet energy resolution, pile-up modelling, trigger eﬃciencies, and 𝐻𝑇 and 𝐻miss
modelling. An uncertainty of 25% is assigned to the R&S QCD estimate to cover any possible non-
closure, as well as typical uncertainties related to the jet response model. A discussion of possible
additional systematic uncertainties is given in the following. The signiﬁcance 𝜎 is computed in a
simpliﬁed way as 𝜎 =

√

𝑇

.

𝑠
𝑠+𝑏+( 𝛿𝑠) 2+( 𝛿𝑏) 2

4 Systematic uncertainty evaluation

Three main sources of systematic uncertainty have been identiﬁed, as well as a number of mi-
nor sources. The main sources, as well as the methods considered for evaluating and assigning
systematics are given in the following.

1. Statistical: The number of events in the seed sample is very large compared to the weighted
count in the signal region. However, there is a probability that a single seed event enters
the signal region more than once, and so the statistical uncertainty may not be that of a
single Poisson distribution. A boot strapping method is employed whereby the prediction is
performed multiple times, each time based on a randomly selected subset of the seed sample.
In practice, as few as ten random subsets can be used and result in an ensemble of 10 estimates
who’s mean and RMS are taken as the central value and statistical uncertainty.

2. Jet response: The jet responses, used both in the rebalancing and smearing steps, are typically
derived from simulation, and modiﬁed to match the data, with an associated uncertainty. It
is incumbent upon the particular experiment to characterize the uncertainty in the used jet
response model. Ideally, this uncertainty accounts for potential mis-modelling of the Gaussian
core of the jet response, as well as the tails. In practice, one or two variants of the jet response

– 14 –

function, corresponding to a one-𝜎 widening of the Gaussian width or tail fraction of the jet
response, are used to independently determine the QCD multi-jet prediction, and the variation
in the predicted value is taken as a systematic.

3. Non-closure: A closure test based on simulation, such as that shown in the ratio panels of
Figs. 4 and 5, can reveal any discrepancies that may be the result of assumptions of the
method. These assumptions include, but are not limited to, the factorisability of the prior into
/𝑝
T PDF and a Δ𝜙( /𝒑hard
) PDF, or any rare non-convergent behaviour of the rebalancing
ﬁt.

𝑗1
T

, 𝒑

T

5 Summary

The Rebalance and Smear method for estimating the fake-/𝑝
T background for search regions with
moderate or large /𝑝
T has been presented in detail. The method, originally developed within the
CMS experiment and deployed in both CMS and ATLAS, is found to be suitable for predicting the
multi-jet backgrounds in a range of ﬁnal states, including ﬁnal states deﬁned by cuts on or shapes
of multivariate classiﬁers that correlate many event-level observables. We ﬁnd that such classiﬁers
may be needed to maximize the BSM programme of LHC searches, e.g., for exploring Higgsino
dark matter scenarios, and so the method’s utility may only be expected to increase. We present a
stand-alone methodology and tool set, consisting of software that interfaces with public tools such
as Delphes3. Provided code computes and maximizes the posterior density, and performs both the
rebalancing and smearing steps. Because of its simplicity and modularity, the code is adaptable to
a speciﬁc experiment’s or analysis’ needs. The likelihood has also been developed to allow for a
mixture of objects with large and small momentum resolution, i.e. jets, leptons, and photons. R&S
is a generative model, and its statistical power has been showcased, illustrating how the statistical
precision of the seed sample can be boosted to an arbitrary degree through repeated smearing steps.
Prescriptions for assigning systematic uncertainties have been suggested, including those necessary
to cover errors associated with the repeated smearing.

References

[1] L. Evans and P. Bryant, LHC Machine, JINST 3 (2008) S08001.

[2] F. Zwicky, On the Masses of Nebulae and of Clusters of Nebulae, Astrophys. J. 86 (1937) 217.

[3] V.C. Rubin and W.K. Ford, Jr., Rotation of the Andromeda Nebula from a Spectroscopic Survey of

Emission Regions, Astrophys. J. 159 (1970) 379.

[4] D. Clowe, M. Bradac, A.H. Gonzalez, M. Markevitch, S.W. Randall, C. Jones et al., A direct

empirical proof of the existence of dark matter, Astrophys. J. 648 (2006) L109 [astro-ph/0608407].

[5] ATLAS collaboration, The ATLAS Experiment at the CERN Large Hadron Collider, JINST 3 (2008)

S08003.

[6] CMS collaboration, The CMS experiment at the CERN LHC, JINST 3 (2008) S08004.

[7] A. Boveia and C. Doglioni, Dark Matter Searches at Colliders, Ann. Rev. Nucl. Part. Sci. 68 (2018)

429 [1810.12238].

– 15 –

[8] XENON collaboration, Dark Matter Search Results from a One Ton-Year Exposure of XENON1T,

Phys. Rev. Lett. 121 (2018) 111302 [1805.12562].

[9] PandaX-II collaboration, Dark Matter Results From 54-Ton-Day Exposure of PandaX-II Experiment,

Phys. Rev. Lett. 119 (2017) 181302 [1708.06917].

[10] LUX collaboration, Results from a search for dark matter in the complete LUX exposure, Phys. Rev.

Lett. 118 (2017) 021303 [1608.07648].

[11] DarkSide collaboration, Low-Mass Dark Matter Search with the DarkSide-50 Experiment, Phys. Rev.

Lett. 121 (2018) 081307 [1802.06994].

[12] Y.A. Golfand and E.P. Likhtman, Extension of the Algebra of Poincare Group Generators and

Violation of p Invariance, JETP Lett. 13 (1971) 323.

[13] D.V. Volkov and V.P. Akulov, Is the Neutrino a Goldstone Particle?, Phys. Lett. B46 (1973) 109.

[14] J. Wess and B. Zumino, Supergauge Transformations in Four-Dimensions, Nucl. Phys. B70 (1974) 39.

[15] J. Wess and B. Zumino, Supergauge invariant extension of quantum electrodynamics, Nucl. Phys. B

78 (1974) 1.

[16] S. Ferrara and B. Zumino, Supergauge invariant Yang-Mills theories, Nucl. Phys. B 79 (1974) 413.

[17] A. Salam and J. Strathdee, Super-symmetry and non-Abelian gauges, Phys. Lett. B 51 (1974) 353.

[18] S.P. Martin, A Supersymmetry Primer, Adv. Ser. Direct. High Energy Phys. 18 (1998) 1

[hep-ph/9709356].

[19] H. Goldberg, Constraint on the Photino Mass from Cosmology, Phys. Rev. Lett. 50 (1983) 1419.

[20] J. Ellis, J. Hagelin, D.V. Nanopoulos, K.A. Olive and M. Srednicki, Supersymmetric relics from the

big bang, Nucl. Phys. B 238 (1984) 453.

[21] ATLAS collaboration, Search for new phenomena in ﬁnal states with large jet multiplicities and

𝑠 = 7 TeV 𝑝 𝑝 collisions with the ATLAS detector, JHEP 11

missing transverse momentum using
(2011) 099 [1110.2299].

√

[22] CMS collaboration, Search for new physics with jets and missing transverse momentum in pp

collisions at

𝑠 = 7 TeV, JHEP 08 (2011) 155 [1106.4503].

√

[23] ATLAS collaboration, Search for squarks and gluinos with the ATLAS detector in ﬁnal states with jets

√

𝑠 = 7 TeV proton-proton collision data, Phys.

and missing transverse momentum using 4.7 fb−1 of
Rev. D 87 (2013) 012008 [1208.0949].

[24] S.A. Koay, A Search for Dark Matter Production with Jets and Missing Momentum Signature in

Proton-Proton Collisions at 7 TeV, Ph.D. thesis, UC, Santa Barbara, 2011.

[25] CMS collaboration, Search for supersymmetry in the all-hadronic ﬁnal state using top quark tagging

in pp collisions at

𝑠 = 13 TeV, Phys. Rev. D96 (2017) 012004 [1701.01954].

√

[26] CMS collaboration, Search for new phenomena with the 𝑀T2 variable in the all-hadronic ﬁnal state
𝑠 = 13 TeV, Eur. Phys. J. C 77 (2017) 710 [1705.04650].

produced in proton–proton collisions at

√

[27] ATLAS collaboration, Search for invisible Higgs-boson decays in events with vector-boson fusion
signatures using 139 fb−1 of proton-proton data recorded by the ATLAS experiment, 2202.07953.

[28] DELPHES 3 collaboration, DELPHES 3, A modular framework for fast simulation of a generic

collider experiment, JHEP 02 (2014) 057 [1307.6346].

[29] T. Sjostrand, S. Mrenna and P.Z. Skands, A Brief Introduction to PYTHIA 8.1, Comput. Phys.

Commun. 178 (2008) 852 [0710.3820].

– 16 –

[30] M. Cacciari, G.P. Salam and G. Soyez, FastJet user manual, Eur. Phys. J. C 72 (2012) 1896

[1111.6097].

[31] CMS collaboration, Search for supersymmetry in proton-proton collisions at 13 TeV in ﬁnal states

with jets and missing transverse momentum, JHEP 10 (2019) 244 [1908.04722].

[32] ATLAS collaboration, Search for squarks and gluinos in ﬁnal states with jets and missing transverse
𝑠 =13 TeV 𝑝 𝑝 collision data with the ATLAS detector, JHEP 02 (2021)

√

momentum using 139 fb−1 of
143 [2010.14293].

[33] J. Alwall, M.-P. Le, M. Lisanti and J.G. Wacker, Searching for directly decaying gluinos at the

Tevatron, Phys. Lett. B 666 (2008) 34 [0803.0019].

[34] J. Alwall, P. Schuster and N. Toro, Simpliﬁed Models for a First Characterization of New Physics at

the LHC, Phys. Rev. D 79 (2009) 075020 [0810.3921].

[35] LHC New Physics Working Group, Simpliﬁed Models for LHC New Physics Searches, J. Phys. G 39

(2012) 105005 [1105.2838].

[36] A. Delgado and M. Quirós, Higgsino Dark Matter in the MSSM, Phys. Rev. D 103 (2021) 015024

[2008.00954].

[37] G.L. Kane, C.F. Kolda, L. Roszkowski and J.D. Wells, Study of constrained minimal supersymmetry,

Phys. Rev. D 49 (1994) 6173 [hep-ph/9312272].

[38] Höcker, Andreas and others, TMVA - Toolkit for Multivariate Data Analysis, PoS ACAT (2007) 040

[physics/0703039].

[39] Samuel Bein, “Rebalance and Smear: Unfolding procedure for estimating QCD backgrounds.”

https://github.com/sbein/BayesQcd/, 2020.

A Framework/code, simulation

A framework for the implementation of Rebalance and Smear is maintained in [39]. The core
Rebalance and Smear functions are encoded in the header ﬁle

BayesQcd/src/BayesRandS.h.

The library contains a number of global observables used to track the collections of original,
rebalanced, and smeared jets, as well as parameters involved in the ﬁtting procedure. Noteworthy
functions contained therein, and their main utility, are:

• GleanTemplatesFromFile: gather the 𝑝𝑇 and 𝜂 slices of the jet response PDF (likelihood), as

well as the hard 𝐸 miss

𝑇

prior into one object.

• ﬁndJetToPin: identiﬁes a starting point for the rebalancing ﬁt parameters. Pairs of jets are

rescaled so as to result in a small 𝐸 miss

𝑇

.

• fcn: the rebalancing posterior density function determines the value of the posterior PDF for

a particular arrangement of jets.

• RebalanceJets: returns a vector of rebalanced jets after running the posterior maximization.

– 17 –

• smearJets: returns a vector of rebalanced and smeared jets by applying a rescaling to the

rebalanced jets derived via a random sampling of the jet response PDF for each jet.

These functions are roughly called in order within the skimming script

tools/skimDataRebalanceAndSmear.py,

which provides a working example of running Rebalance and Smear over Delphes3 simulated input
data. A ROOT TTree littletree is constructed with a number of branches intended for use in the
physics analysis. Within the event loop, the quantities corresponding to the branches are computed
from the input Delphes3 collections, as well as from the rebalanced and smeared collections. Both
the original and rebalanced and smeared collections are saved interleaved within the same tree, and
a binary branch IsRandS identiﬁes if a particular entry corresponds to an original or rebalanced and
smeared event. A simple auxiliary TTree tcounter is deﬁned with no branches and is ﬁlled once per
event before any cuts, which serves to keep track of the total number of events analyzed.

A histogram drawing script,

tools/DrawAnalyze.py,

is included that runs over the above produced skim and draw properly weighted histograms of
desired quantities, from which ﬁgures as well as information for limit setting can be derived.

A key input to the above analysis chain is the ﬁle used in the skimmer script as ftemplate,
which organizes the PDFs used for the likelihood and prior calculations. This ﬁle must be built
from scratch using properties of the jets and the detector of the project of interest, and is created by
running the script

tools/LlhdPriorHistmaker.py.

This script must be run over a high-statistics sample of simulated QCD multi-jet events in order
to arrive at an appropriate set of prior and likelihood PDFs. The output of this code is a set of
histograms, which must be further processed using the script

tools/articulateSplines.py,

which performs a smoothing of the histograms into diﬀerentiable functions and endows them with
an appropriate naming scheme.

In total, 2.6 · 106 QCD multi-jet, 3 · 107 𝑊 + jets and 𝑍 + jets boson, 2 · 106 𝑡 ¯𝑡, simulated
background MC have been generated using LO Pythia8, using the production keys HardQCD:all
= on, WeakBosonAndParton:all = on, and Top:all = on, respectively. In addition, 6 · 105
signal events have been simulated using the same software and conﬁguration.

– 18 –

