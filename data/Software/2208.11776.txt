2
2
0
2

g
u
A
4
2

]

V
C
.
s
c
[

1
v
6
7
7
1
1
.
8
0
2
2
:
v
i
X
r
a

Comprehensive Dataset of Face Manipulations for
Development and Evaluation of Forensic Tools

Brian DeCann (brian.decann@str.us), Kirill Trapeznikov (kirill.trapeznikov@str.us)
STR, Woburn, Massachusetts, United States

1 Introduction

Digital media (e.g., photographs, video) can be easily created, edited, and shared. Tools for

editing digital media are capable of doing so while also maintaining a high degree of photo-

realism. In other words, edits to digital media can be made to be unrecognizable to the

human eye. Many edits to digital media are generally benign. For example, color-balancing

or contrast-enhancement of photographs improves visual acuity and is aesthetically pleas-

ing. However, edits can also be applied for malicious purposes. State-of-the-art face editing

tools and software, for example, can artiﬁcially make a person appear to be smiling at an

inopportune time, or depict authority ﬁgures as frail and tired in order to discredit indi-

viduals. At present, these editing models are generally based on StyleGAN [8][10][14][12],

although image diﬀusion approaches [1][7][9][11][6][1] also perform very well. Additionally,

NERF-based approaches [2] have also been developed. These approaches are all generally

well performing while being quite diﬀerent from one another, illustrating a variety of meth-

ods a user could utilize. Examples of edited (facial) photographs are illustrated in Figure

1. The example edits illustrated show a variety of semantic changes made to a face (e.g.,

neutral pose to smile and appearing older) in both controlled, portrait-style frontal face

images as well as in-the-wild, full-scene images.

Given the increasing ease of editing digital media and the potential risks from misuse,

a substantial amount of eﬀort has gone into media forensics. To this end, we created a

challenge dataset of edited facial images to assist the research community in developing

novel approaches to address and classify the authenticity of digital media. Our dataset

includes edits applied to controlled, portrait-style frontal face images and full-scene in-the-

1

 
 
 
 
 
 
Figure 1: Examples of face manipulations in media. State-of-the-art models are capable

of applying photorealistic manipulations in portrait-style (left), video (center), and in-the-

wild media. Here, manipulations are generated using the approaches from Roich et al. [8],

and Tzaban et al. [10].

wild images that may include multiple (i.e., more than one) face per image. The goals of

our dataset is to address the following challenge questions:

1. Can we determine the authenticity of a given image (edit detection)?

2. If an image has been edited, can we localize the edit region?

3. If an image has been edited, can we deduce (classify) what edit type was performed?

The majority of research in image forensics generally attempts to answer item (1),

detection. To the best of our knowledge, there are no formal datasets speciﬁcally curated

to evaluate items (2) and (3), localization and classiﬁcation, respectively. Our hope is that

our prepared evaluation protocol will assist researchers in improving the state-of-the-art in

image forensics as they pertain to these challenges.

2 Face Manipulations in Portrait Images

A portrait image is a type of face image where a signiﬁcant majority of the image foreground

denotes a human face. Example portrait-style images are illustrated in Figure 2.

2

Figure 2: Examples of portrait-style images from the CelebA-HQ dataset [4].

2.1 Portrait Image Dataset

2.1.1 Dataset

We compiled a dataset of edited portrait-style images. The image data was sourced from

a subset of the CelebA-HQ dataset [4]. The CelebA-HQ dataset is a high-quality subset

of the Large-Scale CelebFaces Attributes (CelebA) dataset [5]. The CelebA-HQ dataset

consists of 30,000 high-quality versions of images in the CelebA dataset. The images denote

square-cropped faces from photographs captured in-the-wild and are saved at a resolution

of 1024x1024 pixels (versions at 128x128 and 256x256 pixels also exist). In our subset, we

only consider identities that appear at least twice (i.e., there are at least two images of a

given identity) in the image data.

We created two partitions of image data for training and testing purposes. The training

partition contains a total of 6,846 total images. Each sampled CelebA-HQ image in the

training partition is manipulated in ﬁve (5) separate instances, in combination with the

original (unedited) image. Each sampled CelebA-HQ image is also paired with a separate

(unedited) image of the same face identity as a reference. The ﬁve manipulations consist of

“smile” (smile added or enhanced), “not smile” (smile removed or reduced), “young” (face is

modiﬁed to appear younger), “old” (face is modiﬁed to appear older), and “surprised” (face

is modiﬁed to include a surprised expression). We applied the Pivotal Tuning approach by

Roich et al. to create each manipulated image [8]. The testing partition contains a total

3

of 7,644 images and includes the same types of manipulated images as in the training

partition and an additional seven manipulated images for a total of twelve images per

identity (plus the original and a reference). In the testing partition there are additional

examples for “smile”, “not smile”, “young”, and “old”, where the edit magnitude is reduced.

In addition, there are three novel manipulations not present in the training partition. These

include “purple hair” (hair is modiﬁed to have a purple color), “angry” (face is modiﬁed

to depict an angry expression), and “Taylor Swift” (face shape and features modiﬁed to

appear similar to Taylor Swift). Each manipulation type is summarized in Table 1. An

example of a subject with the set of applied manipulations is illustrated in Figure 3. In

this example, each of the fourteen images would denote one subject in the testing partition.

Labels that are italicized would not appear for a given subject in the training partition.

Table 1: Caption

Edit Type

Remark

“smile”

Smile added or enhanced

“not smile”

Smile removed or reduced

“young”

Face is modiﬁed to appear younger

“old”

Face is modiﬁed to appear older

“surprised”

Face is modiﬁed to depict a surprised expression

“purple hair” Hair is modiﬁed to have a purple color

“angry”

Face is modiﬁed to depict an angry expression

“Taylor Swift” Face shape and features modiﬁed to appear similar to Taylor Swift

We remark that some identities may appear more than once in a given partition (training

or testing), however an identity appearing in the training set will not appear in the testing

set (and vice-versa). Both partitions are available in .png and .jpg format.

Image Count

Unique Edit Types

Table 2: Caption

Training Partition Test Partition

7644

8

6846

5

4

Figure 3: Examples of a set of images for a given subject in our manipulation dataset. Here,

labels that are italicized denote manipulations that exist strictly in the testing partition

and are not present in the training partition.

2.2 Evaluation Protocol

For our portrait-style face manipulation dataset, we supply two challenges: detection and

classiﬁcation. A description of both challenges and associated outputs are described in the

following sections.

2.2.1 Detection

The objective of the detection experiment is to identify whether a given image has been

manipulated. For a given image in the testing partition return:

• (string) “<ﬁlename>” : Image ﬁlename

• (bool) [0,1] : Not edited or Edited

We measure balanced detection accuracy as the proportion of images that are correctly

5

recognized as either edited or not edited.

2.2.2 Classiﬁcation

The objective of the classiﬁcation experiment is to classify the type of edit in a manipulated

image. For a given image in the testing partition return:

• (string) “<ﬁlename>” : Image ﬁlename

• (string) “pristine” : if not edited; “<edit type>” :

if Edited

We measure classiﬁcation accuracy as the proportion of edited images that are correctly

recognized of being a given edit type.

3 Face Manipulation in the Wild

An in-the-wild image can be described as an image where the principal foreground com-

ponents (e.g., objects, people, animals) do not occupy the majority of the spatial image

area and a large background is present. In-the-wild images are sometimes unconstrained in

terms of lighting or camera angles. Unprocessed, or raw in-the-wild images can also vary

greatly in terms of spatial resolution.

3.1 In-the-Wild Image Dataset

3.1.1 Dataset

We compiled a dataset of edited in-the-wild-style images. The image data was sourced

from a subset of the Flickr-Faces-HQ (FFHQ) [3]. The FFHQ dataset consists of 70,000

high-quality in-the-wild images. The authors of the FFHQ datset posit that the FFHQ

data is much more variant in terms of age, ethnicity, background, and presence of facial

covariates (e.g., eyeglasses, headwear) compared to CelebA-HQ. A version of the dataset

consists futher of 70,000 detected, aligned, and cropped faces, which are saved at a resolution

of 1024x1024 (a version at 128x128 also exists), but we only consider the raw, full-scene

images. Example in-the-wild images from the FFHQ dataset are illustrated in Figure 4.

6

Figure 4: Examples of in-the-wild images from the FFHQ dataset [3].

Our edited in-the-wild dataset consists of a randomly sampled subset of the 70,000 raw

in-the-wild FFHQ images. In our subset, we allow for the possibility that an image contains

more than one person (face). This potentially adds an additional challenge in detecting and

localizing edited faces. We created two partitions of image data for training and testing

(validation) purposes. The training partition and test partition contain totals of 1,508

and 1,403 images, respectively. Within each partition, approximately 50% of the images

are edited, while the remaining images are “pristine” (i.e., not edited).

In the training

partition, 759 images are edited and 750 are pristine. For the testing partition, 652 images

are edited and 750 are pristine. All images are saved in .jpg format with a randomly chosen

quality factor in the set Qf ∈ [75, 80, 85, 90]. Summary information for the in-the-wild

dataset is listed in Table 3.

Unlike the portrait-style images, each edited image is only subject to a single edit type.

In other words, there are not multiple copies of the same underlying image but with diﬀerent

edits applied. Images that are edited are subject to one of six possible manipulations. These

include “smile”, “not smile”, “young”, “old”, “male”, “female”. We adopt the approach

from Tzaban et al. to inject edits to in-the-wild images [10].

For our in-the-wild face manipulation dataset, edits are localized to a region of the

7

Table 3: In-the-wild face manipulation dataset summary

Training Partition Test Partition

Image Count

Pristine Images

Edited Images

1,508

750

759

Resolution

Variable

Image Format

.jpg

1,403

750

652

Variable

.jpg

Table 4: Types of image edits appearing in our in-the-wild face manipulation dataset

Edit Type Remark

“smile”

Smile added or enhanced

“not smile”

Smile removed or reduced

“young”

Face is modiﬁed to appear younger

“old”

Face is modiﬁed to appear older

“male”

Face is modiﬁed to appear more masculine

“female”

Face is modiﬁed to appear more feminine

full-scene image. This is in contrast to the portrait-style face manipulation dataset, where

images are fully synthesized from face-based GAN’s. For the images in the in-the-wild face

manipulation dataset that are edited, we also provide a binary mask that captures the

spatial image region where the edit was performed and transplanted back into the image.

The edit region is identiﬁed using a modiﬁed BiSeNet for faces [13]. Figure 7 illustrates

examples of binary edit masks associated with edited in-the-wild images with one and

multiple persons. Additionally, Figure 8 reports the proportion of the edit region for edited

images. Typically, the size of the edit region is between 8% and 20% of the spatial image

area.

8

Figure 5: Face counts in our image set, separated by training and test partition. Note that

the number of face counts is relatively well balanced for each partition and that a signiﬁcant

majority of images have one or two faces.

Figure 6: Examples of “pristine” (left) and “edited” (right) images in our in-the-wild face

manipulation dataset.

9

Figure 7: Examples of edit masks associated with edited in-the-wild images.

Figure 8: Proportion of edit region in our in-the-wild images. Note that the typical edit

region size is approximately 10% of the image.

10

3.2 Evaluation Protocol

For our in-the-wild face manipulation dataset, we supply three challenges: detection, local-

ization, and classiﬁcation. A description of each challenge and outputs are described in the

following sections.

3.2.1 Detection

The objective of the detection experiment is to identify whether a given image has been

manipulated. For a given image in the testing partition return:

• (string) “<ﬁlename>” : Image ﬁlename

• (bool) [0,1] : Not edited or Edited

3.2.2 Localization

The objective of the localization experiment is to identify the speciﬁc image-region where

an edit exists. For a given image in the testing partition, users must generate a binary
mask, ˆM , denoting the estimated edit region. The estimated mask is compared against the

ground truth, M using Matthews Correlation Coeﬃcient (MCC). The MCC (phi coeﬃcient,

or mean-square contingency coeﬃcient) is a measure of association for binary variables.

MCC is computed from the confusion matrix of the pixel-based binary estimations. This is
mathematically described in Equation (1), where TP denotes True Positive (Mk = ˆMk = 1),
TN denotes True Negative (Mk = ˆMk = 0), FP denotes False Positive (Mk = 0, ˆMk = 1),
and FN denotes False Negative (Mk = 1, ˆMk = 0).

M CC =

T P · T N − F P · F N
(cid:112)(T P + F P )(T P + F N )(T N + F P )(T N + F N )

(1)

3.2.3 Classiﬁcation

The objective of the classiﬁcation experiment is to classify the type of edit in a manipulated

image. For a given image in the testing partition return:

• (string) “<ﬁlename>” : Image ﬁlename

11

• (string) “pristine” : if not edited; “<edit type>” :

if Edited

In our in-the-wild face manipulation dataset the types of edits that are present in the

training partition are also represented in the testing partition. Similarly, the types of edits

that are in the testing partition are also represented in the training partition. Thus, the

classiﬁcation problem for this dataset is closed-set. This is in contrast to the portrait-style

data, where novel edit types exist in the testing partition. We encourage users utilizing

this data and challenge problem to consider open-set solutions as the set of potential edit

types is near-unlimited.

Acknowledgement. This material is based upon work supported by the Defense Ad-

vanced Research Projects Agency (DARPA) under Contract No. HR001120C0129. The

views, opinions and/or ﬁndings expressed are those of the author and should not be in-

terpreted as representing the oﬃcial views or policies of the Department of Defense or the

U.S. Government.

References

[1] T. Dockhorn, A. Vahdat, and K. Kreis. Score-based generative modeling with critically-

damped langevin diﬀusion. arXiv preprint arXiv:2112.07068, 2021. 1

[2] J. Gu, L. Liu, P. Wang, and C. Theobalt. Stylenerf: A style-based 3d-aware generator

for high-resolution image synthesis. arXiv preprint arXiv:2110.08985, 2021. 1

[3] T. Karras, S. Laine, and T. Aila. A style-based generator architecture for generative
adversarial networks. In Proceedings of the IEEE/CVF conference on computer vision
and pattern recognition, pages 4401–4410, 2019. 6, 7

[4] C.-H. Lee, Z. Liu, L. Wu, and P. Luo. Maskgan: Towards diverse and interactive
In IEEE Conference on Computer Vision and Pattern

facial image manipulation.
Recognition (CVPR), 2020. 3

[5] Z. Liu, P. Luo, X. Wang, and X. Tang. Deep learning face attributes in the wild. In
Proceedings of International Conference on Computer Vision (ICCV), December 2015.
3

[6] K. Preechakul, N. Chatthee, S. Wizadwongsa, and S. Suwajanakorn. Diﬀusion au-
toencoders: Toward a meaningful and decodable representation. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10619–
10629, 2022. 1

[7] A. Ramesh, P. Dhariwal, A. Nichol, C. Chu, and M. Chen. Hierarchical text-conditional

image generation with clip latents. arXiv preprint arXiv:2204.06125, 2022. 1

[8] D. Roich, R. Mokady, A. H. Bermano, and D. Cohen-Or. Pivotal tuning for latent-

based editing of real images. arXiv preprint arXiv:2106.05744, 2021. 1, 2, 3

12

[9] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer. High-resolution image
synthesis with latent diﬀusion models. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pages 10684–10695, 2022. 1

[10] R. Tzaban, R. Mokady, R. Gal, A. H. Bermano, and D. Cohen-Or. Stitch it in time:
Gan-based facial editing of real videos. arXiv preprint arXiv:2201.08361, 2022. 1, 2, 7

[11] Z. Xiao, K. Kreis, and A. Vahdat. Tackling the generative learning trilemma with

denoising diﬀusion gans. arXiv preprint arXiv:2112.07804, 2021. 1

[12] F. Yin, Y. Zhang, X. Cun, M. Cao, Y. Fan, X. Wang, Q. Bai, B. Wu, J. Wang,
and Y. Yang. Styleheat: One-shot high-resolution editable talking face generation via
pretrained stylegan. arXiv preprint arXiv:2203.04036, 2022. 1

[13] C. Yu, J. Wang, C. Peng, C. Gao, G. Yu, and N. Sang. Bisenet: Bilateral segmentation
network for real-time semantic segmentation. In Proceedings of the European conference
on computer vision (ECCV), pages 325–341, 2018. 8

[14] Y. Zhang, H. Ling, J. Gao, K. Yin, J.-F. Laﬂeche, A. Barriuso, A. Torralba, and
S. Fidler. Datasetgan: Eﬃcient labeled data factory with minimal human eﬀort. In
CVPR, 2021. 1

13

A Additional Example Images

In this section, we provide additional examples of manipulated face images from the portrait
and in-the-wild image sets.

A.1 Portrait Images

Additional examples of edited portrait-style images are illustrated in Figures 9-11.

Figure 9: Manipulated portrait-style images with an added smile (middle left) and to appear
younger (middle right). The right-most image denotes a reference (i.e., diﬀerent image) for
the same person.

Figure 10: Manipulated portrait-style images with an added smile (middle left) and to
appear younger (middle right). The right-most image denotes a reference (i.e., diﬀerent
image) for the same person.

14

Figure 11: Manipulated portrait-style images with an added smile (middle left) and to
appear younger (middle right). The right-most image denotes a reference (i.e., diﬀerent
image) for the same person.

A.2 In-the-Wild Images

Additional examples of edited in-the-wild images are illustrated in Figure 12 and 13.

Figure 12: Manipulated in-the-wild image edited to remove smile.

15

Figure 13: Manipulated in-the-wild image edited to add glasses

16

