CSL Technical Report SRI-CSL-2022-01 • March 30, 2022

DesCert: Design for Certiﬁcation

Natarajan Shankar Devesh Bhatt
Minyoung Kim
Jorge Navas
Huascar Sanchez

Michael Ernst

Srivatsan Varadarajan Suzanne Millstein
Jason Biatek
Anitha Murugesan
Hao Ren
Honeywell Research

University of Washington

SRI International

2
2
0
2

r
a

M
9
2

]
E
S
.
s
c
[

1
v
8
7
1
5
1
.
3
0
2
2
:
v
i
X
r
a

Supported by DARPA under agreement number FA8750-20-C-0226. The views
and conclusions contained herein are those of the authors and should not be in-
terpreted as necessarily representing the ofﬁcial policies or endorsements, either
expressed or implied, of DARPA or the U.S. Government.

Computer Science Laboratory•333 Ravenswood Ave.•Menlo Park, CA 94025•(650) 326-6200 •Facsimile: (650) 859-2844

 
 
 
 
 
 
Abstract

The goal of the DARPA Automated Rapid Certiﬁcation Of Software (ARCOS)
program is to “automate the evaluation of software assurance evidence to enable
certiﬁers to determine rapidly that system risk is acceptable.” As part of this
program, the DesCert project focuses on the assurance-driven development of new
software. The DesCert team consists of SRI International, Honeywell Research,
and the University of Washington. We have adopted a formal, tool-based approach
to the construction of software artifacts that are supported by rigorous evidence.
The DesCert workﬂow integrates evidence generation into a design process that
goes from requirements capture and analysis to the decomposition of the high-level
software requirements into architecture properties and software components with
assertional contracts, and on to software that can be analyzed both dynamically and
statically. The generated evidence is organized by means of an assurance ontology
and integrated into the RACK knowledge base.

Contents

1 Introduction

1

2 The DesCert Approach

7
7
2.1 Assurance-Driven Development (ADD) . . . . . . . . . . . . . . . . .
8
. . . . . . . . . . . . .
2.2 Designing for Eﬃcient Assurance Arguments
11
2.3 Motivation: The Eight Variables Model
. . . . . . . . . . . . . . . .
15
2.4 The Radler Architecture Framework . . . . . . . . . . . . . . . . . .
17
2.5 A Motivating Example: Room Temperature Regulation . . . . . . .
2.6 Aligning the Assurance Argument Structure with DO-178C Guidance 21
23
2.7 Assurance Ontology . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
2.8 ArduCopter Challenge Problem . . . . . . . . . . . . . . . . . . . . .
26
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.9 Assurance Tools
27
2.10 Current Limitations of DesCert Assurance Methodology . . . . . . .

3 Phase 1 Challenge Problem: Advanced Fail Safe (AFS) Case Study 30
31
3.1 Concept of Operations . . . . . . . . . . . . . . . . . . . . . . . . . .
33
3.2 Mission Scenario and Assumptions . . . . . . . . . . . . . . . . . . .
36
3.3 System and Software Architectures . . . . . . . . . . . . . . . . . . .
39
3.4 High Level Behavioral Description of AFS Function . . . . . . . . . .

4 DesCert Evidence Ontology

4.1 DesCert Enables Property-Based Assurance . . . . . . . . . . . . . .
4.2 DesCert Ontology Description . . . . . . . . . . . . . . . . . . . . . .
4.2.1 Ontology for Checking Speciﬁc Properties against a Model of
Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2.2 Ontology for Checking Generic Properties of Requirements
.
4.2.3 Ontology for Test Generation from Requirements . . . . . . .

42
43
45

45
46
46

i

SRI International

DesCert: Design for Certiﬁcation

March 2022

5 Tools for Evidence Generation

quirements

to Sally model

tic Synthesis Model

5.1 Notation and Tools for Requirements Speciﬁcation, Analysis, and
Test Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1.1 CLEAR: Constrained Language Enhanced Approach to Re-
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1.2 Text2Test Tool Overview . . . . . . . . . . . . . . . . . . . .
5.1.2.1 From RequirementSet to Text2Test internal Seman-
. . . . . . . . . . . . . . . . . .
5.1.3 Checking Generic Properties of Requirements . . . . . . . . .
Sally Model Generation and Speciﬁc Property Veriﬁcation . .
5.1.4
5.1.4.1 From Text2Test internal Semantic Synthesis Model
. . . . . . . . . . . . . . . . . . . . .
5.1.4.2 Checking speciﬁc properties against the Sally model
5.1.4.3 Examples of Properties . . . . . . . . . . . . . . . .
5.1.4.4 Temporal extension to Sally query . . . . . . . . . .
. . . . . . . . . . . . . .
5.1.5.1 CLEAR Testing Theory . . . . . . . . . . . . . . . .
5.2 Architecture Speciﬁcation and Analysis using Radler . . . . . . . . .
5.2.1 The Radler Model of Computation . . . . . . . . . . . . . . .
5.2.2 The Radler Architecture Deﬁnition Language . . . . . . . . .
5.3 Lightweight Code Analysis Tools . . . . . . . . . . . . . . . . . . . .
5.3.1 Randoop: Feedback-Directed Random Test Generation . . . .
5.3.2 Daikon: Dynamically Detection of Program Invariants . . . .
5.3.3 The Checker Framework: Pluggable Extensible TypeChecking
5.4 SeaHorn Tool for Static Code Analysis . . . . . . . . . . . . . . . . .
5.4.1 Progress on Analysis of C code . . . . . . . . . . . . . . . . .
5.4.2 New Tag Analysis
. . . . . . . . . . . . . . . . . . . . . . . .
5.4.3 Progress on Evidence Formats for Independent Checkers . . .

5.1.5 Test Generation from Requirements

53

53

54
58

59
64
65

66
66
68
69
71
71
74
75
76
85
85
87
87
88
89
90
91

6 Continuous Assurance Workﬂow: Baseline DesCert

93
94
6.1 Continuous Assurance with Baseline DesCert . . . . . . . . . . . . .
6.2 Baseline DesCert’s Gradle Plugins
95
. . . . . . . . . . . . . . . . . . .
6.3 Track, Compare, and Visualize Your Evidence . . . . . . . . . . . . . 100

7 DesCert Evidence Generation

7.1 AFS High-Level Software Requirements

103
. . . . . . . . . . . . . . . . 105
7.1.1 CLEAR Features for AFS HLR . . . . . . . . . . . . . . . . . 106
7.1.2 AFS Requirements in CLEAR . . . . . . . . . . . . . . . . . 109
7.2 AFS Evidence Generation from Sally Model Checking . . . . . . . . 114
7.3 AFS Test Generation from Text2Test . . . . . . . . . . . . . . . . . . 116

ii

SRI International

DesCert: Design for Certiﬁcation

March 2022

7.3.1 Analysis of Generic Properties of Requirements . . . . . . . . 116
7.3.2 Requirements-based Test Case Generation . . . . . . . . . . . 118
7.4 AFS RADL Architecture Evidence Generation . . . . . . . . . . . . 120

8 Conclusions

126

iii

List of Figures

1.1 DesCert Project Goals . . . . . . . . . . . . . . . . . . . . . . . . . .

2.1 DesCert Assurance Driven Development Methodology . . . . . . . .
2.2 The Eight Variables Model
. . . . . . . . . . . . . . . . . . . . . . .
2.3 Assurance Argument Structure . . . . . . . . . . . . . . . . . . . . .
2.4 Eight-Variable Model for Thermostat Room Temperature Controller
2.5 Thermostat Behavior in Radler . . . . . . . . . . . . . . . . . . . . .
2.6 The DO-178C objectives and argument structure . . . . . . . . . . .
2.7 DesCert Assurance Claims and Artifacts . . . . . . . . . . . . . . . .
2.8 ArduPilot Platform Architecture (From https://ardupilot.org/
dev/docs/learning-ardupilot-introduction.html) . . . . . . . .
2.9 DesCert Tool Suite . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.1 Phase 1 Mission Operation . . . . . . . . . . . . . . . . . . . . . . .
3.2 Geofences during Mission Operation . . . . . . . . . . . . . . . . . .
3.3 Battery Energy Levels . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4 System Architecture with Advanced Fail-Safe (AFS) Software Com-
ponent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4

9
13
14
18
19
22
23

25
27

31
32
35

37

4.1 Property Speciﬁcation and Analysis for Architecture and Requirements 43
47
4.2 Speciﬁcation and Checking of Speciﬁc Properties of Requirements . .
48
4.3 Ontology Schema for Properties . . . . . . . . . . . . . . . . . . . . .
4.4 The Core Structures in W3C PROV . . . . . . . . . . . . . . . . . .
48
4.5 Ontology for Checking Properties against the Sally Model of Require-
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.6 Ontology for Generation of Sally Model from Requirements . . . . .
4.7 Ontology for Checking Generic Properties of Requirements
. . . . .
4.8 Evidence Flow for Test Generation from Requirements . . . . . . . .
4.9 Ontology for Test Generation from Requirements . . . . . . . . . . .

49
50
50
51
52

ments

5.1 Requirements Analysis Evidence Generation Overview . . . . . . . .

53

iv

SRI International

DesCert: Design for Certiﬁcation

March 2022

55
5.2 An overview of the design principles of CLEAR.
. . . . . . . . . . .
59
5.3 Requirement Types/Structure in CLEAR . . . . . . . . . . . . . . .
60
. . . . . . . . . . . . . . . . . . .
5.4 Architecture of the Text2Test Tool
5.5 Requirement set example for a state variable SOME STATE.
62
. . . .
62
5.6 State transition subgraph before and after merge. . . . . . . . . . . .
67
5.7 Checking Speciﬁc Properties of Requirements using Sally . . . . . .
70
5.8 Temporal property translation and Sally model augmentation. . . . .
72
5.9 Testing Criteria in DO-178C . . . . . . . . . . . . . . . . . . . . . . .
73
5.10 Example of Derivation of Test Oracles from a Requirement Set . . .
5.11 Deﬁnition of Test Oracles for Switch Operator
74
. . . . . . . . . . . .
5.12 Example of Code Error Caught by the Test Oracle of Switch Operator 74
5.13 Nodes (in ellipse) and topics (in rectangle) of the example of room
temperature regulator. . . . . . . . . . . . . . . . . . . . . . . . . . .
5.14 A Randoop Unit Test Example . . . . . . . . . . . . . . . . . . . . .
5.15 Checker Framework Example: NullnessExample.java . . . . . . . . .

81
86
88

94
6.1 Baseline DesCert . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
96
6.2 Randoop plugin conﬁguration . . . . . . . . . . . . . . . . . . . . . .
97
. . . . . . . . . . . . . . . . . . . . . . . .
6.3 Randoop plugin evidence
98
6.4 Daikon plugin conﬁguration . . . . . . . . . . . . . . . . . . . . . . .
98
6.5 Daikon plugin evidence . . . . . . . . . . . . . . . . . . . . . . . . . .
6.6 Rack data import conﬁguration . . . . . . . . . . . . . . . . . . . . .
99
6.7 Baseline DesCert execution on descert-example repository . . . . . . 101
6.8 Experiment tracking Baseline DesCert . . . . . . . . . . . . . . . . . 102

7.1 AFS DesCert Evidence Generated and Populated in RACK . . . . . 104
7.2 AFS State Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
7.3 Prioritized Contingency Management . . . . . . . . . . . . . . . . . . 108
7.4 XYZVector Deﬁnition in CLEAR . . . . . . . . . . . . . . . . . . . . 109
7.5 XYZVector terms and distance function usage in CLEAR . . . . . . 109
7.6 Low Battery Requirements
. . . . . . . . . . . . . . . . . . . . . . . 110
7.7 GPS Lock Loss Requirements . . . . . . . . . . . . . . . . . . . . . . 111
7.8 Breach Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
7.9 Communication Requirements . . . . . . . . . . . . . . . . . . . . . . 113
7.10 An overview of the Sally model creation and checking process. . . . . 114
7.11 AFS Generic Properties . . . . . . . . . . . . . . . . . . . . . . . . . 117
7.12 AFS Generic Properties Analysis Output
. . . . . . . . . . . . . . . 118
. . . . . . . . . . . . . . . . . . . . . . 119
7.13 AFS Test Report - Template
7.14 AFS Test Report - Vector . . . . . . . . . . . . . . . . . . . . . . . . 120
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
7.15 AFS Test Vector

v

SRI International

DesCert: Design for Certiﬁcation

March 2022

7.16 AFS Status Report . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
7.17 Nodes (in ellipse) and topics (in rectangle) of the AFS subsystem . . 122

vi

Chapter 1

Introduction

Software has become a core component of many safety-critical systems. Software
is slowly taking over functions that were previously handled by electromechanical
devices.
In cars, antilock braking systems use software to delicately and rapidly
“pumping the brakes” in order to avoid skidding due to the wheels locking up. Many
of the timing, control, safety, climate control, and infotainment subsystems of the
vehicle are now handled largely by software. The use of software supports greater
ﬂexibility, resilience, and versatility in the design and maintenance of a system.
While software is not subject to wear-and-tear, it can be a signiﬁcant source of
system failure due to bugs and security vulnerabilities since even a small design or
coding error can have big consequences.

Software assurance is a way of ensuring the safety of a system containing software
components before it is deployed.
In the context of system safety, a hazard is a
potentially dangerous event caused by a failure. A failure is a deviation from the
intended behavior. A failure can be caused by an error in the functioning of a
component. This error itself might result from a fault such as a missing check in the
software. An assurance case captures the rationale behind the safety of the software
in the context of the system design, its concept of operations, and the mission needs.
The assurance case ensures that all of the hazards, the consequential ways in which
the software might cause the system to fail, have been mitigated in the design. An
assurance case for software consists of claims supported by arguments and evidence.
The claims must cover the software requirements, design, architecture, code, and
platform (including hardware, communication network, systems software, and other
libraries) to demonstrate that software behavior is ﬁt for its intended purpose and
does not compromise system safety.

At the highest level, the desired qualities of the software are captured in the
requirements spanning both the functional requirements and the performance char-

1

acteristics. It is well-known that many software projects fail because of erroneous
or ill-deﬁned requirements. The requirements process starts with an enumeration
of the hazards and an argument that this enumeration is exhaustive. The software
requirements are then constructed to specify the intended behavior while mitigating
these hazards. The requirements capture properties of the behavior of the software
including assumptions on the environment, actions that the software must take in
response to inputs, and states that the software must avoid. Some properties are
generic in that they are satisﬁed by a general class of systems. For example, the
software must free from deadlock, type violations, and runtime errors. Other prop-
erties are speciﬁc to the intent of the system such as ensuring the accuracy of the
navigational data. The requirements must be shown to be consistent, complete, and
veriﬁable. The software design correctly delivering these requirements decomposes
into the architecture, namely the generic way in which software functions are decom-
posed into interacting modules, and the low-level requirements (LLRs) which are the
contracts imposed on the software modules. Models play a critical role in the design
and assurance of a software design capturing environmental assumptions, platform
assumptions, operator behavior, as well as the behavior of the physical components
including the plant (the physical system being controlled), sensors, and actuators.
These models must be suﬃciently accurate approximations of the real behavior of
these components and subsystems given the architecture that mediates the interac-
tion between the software and the physical world. The hardware platform together
with the operating system, libraries, and glue code must be shown to correctly im-
plement the architecture. The source code for the software components must satisfy
the contracts and be correctly compiled into executable code that is properly com-
posed within the architecture. Integrating all of these claims and evidence into an
watertight assurance case for the system is therefore a signiﬁcant challenge.

What is the purpose of an assurance case? The claims, argument, and evidence
presented in the assurance case can be examined, probed, and attacked in isolation
to ensure that they do indeed make a compelling pre-deployment case for system
safety. These steps in the argument can fail for a variety of reasons: missing, in-
correct, or ambiguous requirements or assumptions; untrustworthy tools; imprecise
or mismatched semantics; invalid justiﬁcations; incorrect designs; and buggy code.
The strength or the eﬃciency of an assurance case is the ease with which a skep-
tical reviewer can identify the ﬂaws in the case by examining its individual steps
without having to test or analyze the fully integrated system. Eﬃciency is achieved
by using languages and notations with precise semantics, trustworthy tools that are
compatible with the semantics, and reusable artifacts such as testing theories, code
generators, proof assistants, typecheckers, static analyzers, and compilers.
If, in
spite of the eﬃciency of the assurance case, no ﬂaws are found, then the software
along with its assurance case can be conﬁdently certiﬁed for deployment.

2

If our goal is to reduce the cost of software certiﬁcation while increasing its
rigor, then the steps in the assurance argument sketched above must be eﬃcient in
the above sense. It must be easy for evaluators to identify any gaps or ﬂaws. If
the argument fails, the source of the failure must be egregious. This means that
we have to rely on precise claims established by reusable tools and design concepts
like a sound testing theory, requirements analyzers, model checkers, typecheckers,
architecture frameworks, code generators, and compilers. The deployment of such
reusable tools and concepts ampliﬁes the falsiﬁcation space, since the generic claims
associated with these tools, e.g., the soundness of a typechecker, can be falsiﬁed by
any instance where the tool fails even outside of its use within the system under
assurance. Clearly, it can more costly to establish the high-level claims such as the
soundness of model checkers, typecheckers, and static analyzers, but this cost can be
amortized over the multiple uses of the tool. Eﬃciency is not merely a characteristic
of an assurance argument, but a design heuristic that favors design choices such as
rigorous architectural frameworks and semantically precise notations that amplify
the salience of any design ﬂaws.

There are numerous standards for evaluating assurance cases for certiﬁcation.
IEC 62304 is a standard for the certiﬁcation of medical device software that pre-
scribes the evidence artifacts needed for the device to be declared safe for devices
that operate at hazard levels where either no injury is possible (Class A), no seri-
ous injuries are possible (Class B), and death or serious injuries are possible (Class
C). The automotive industry standard ISO 26262 for functional safety spanning the
system design lifecycle covering requirements, software, and hardware [ISO11]. MIL-
STD-882E prescribes the processes and procedures for certifying system safety for
military aerospace systems [DoD12]. In the civil aviation setting, SAE ARP4754 de-
scribes the guidelines for developing Civil Aircraft and Systems [SAE96a], and SAE
ARP 4761 outlines the techniques to be used in system safety assessment [SAE96b].
These are used in conjunction with RTCA standards such as DO-254 for hardware
design assurance [RTC00] and DO-178C for software safety standards [Inc11]. DO-
178-C spells out around 71 assurance objectives that must be fully or partially met
in order to certify software for hazard levels ranging from catastrophic (A) to minor
(D).

Many safety standards are prescriptive in terms of development processes, assur-
ance objectives, and assessment procedures. These activities only indirectly impact
system safety. Overarching Properties (OPs) takes a more direct view of safety
assessment in terms of three large objectives [Hol18]. One, that the intent of the
system has been accurately captured. Two, the system as designed is correct with
respect to the intent. Three, that any additional functionality in the system that
is not traceable to intent must be innocuous or acceptable, i.e., must be shown to
not impact system safety. The OPs approach can be used in conjunction with other

3

Figure 1.1: DesCert Project Goals

standards as long as the arguments can be made to align with the intent, correctness,
and innocuity objectives.

Software certiﬁcation complying with the above standards is an arduous labor-
intensive process of collecting evidence and constructing an assurance case that
In safety-critical settings, certiﬁcation is the
passes muster with the evaluators.
most expensive aspect of software development in terms of time and money. The
ARCOS program aims to reduce the cost and increase the eﬃciency of developing
and certifying safety-critical software. The program decomposes assurance case con-
struction into three phases: evidence generation, evidence curation, and assurance
case development. The DesCert project addresses the evidence generation phase
with a focus on new software development. As shown in Figure 1.1, the project is
directed at achieving dramatic improvements in all phases of high-assurance software
development in three speciﬁc dimensions: the formal rigor underlying the claims and
evidence associated with the software artifacts, the composability of evidence gen-
erated at diﬀerent levels of abstraction, and the eﬃciency with which the evidence
can be integrated into an assurance argument and assessed by an evaluator. Toward
this goal, the DesCert approach emphasizes

1. Automated tools that generate rigorous, semantically coherent evidence

2. Languages and type systems, such as ontic typing, that capture the intent of

the design

3. Compositional certiﬁcation of complex systems

4

4. Eﬃcient, easily veriﬁable arguments for capturing software and system safety

5. Reusable and trustworthy automated tools and techniques with a low amor-

tized certiﬁcation cost

6. Continuous evidence generation and validation throughout the design lifecycle.

The DesCert team consists of SRI International, Honeywell Research, and the
University of Washington. The DesCert continuous certiﬁcation workﬂow integrates
a number of requirements modeling, design, and code analysis tools, including the
CLEAR requirements description language [BMH+18, HBM+18], the Text2Test for
generating test cases and models from requirements, the PVS interactive proof as-
sistant, the Sally model checker, the Radler Architecture Deﬁnition Language, the
Checker Framework for pluggable typechecking, the Randoop system for generating
unit tests, the Daikon system for learning putative assertional properties of software,
and the SeaHorn static analyzer. For continuous assurance, we have developed the
Baseline DesCert workﬂow tool for monitoring and maintaining the status of the
assurance artifacts. This tool also interacts with the RACK tool for curating and
ingesting assurance artifacts in accordance with an assurance ontology.

The DesCert approach to evidence generation for new software loosely follows the
DO-178C objectives. We employ the CLEAR language for capturing software High-
Level Requirements (HLRs) in terms of the input/output state-machine behavior
of software components. The HLRs are used to generate test inputs that drive
the input space of the operations used in the requirements and the possible state
changes, along with test oracles for judging whether the software component exhibits
the right behavior on the test inputs. The design of the software complying with
the HLRs consists of the software architecture with its model of computation and
interaction as well as the component low-level requirements. We use the Sally model
checker [DJN18a] to analyze the CLEAR HLRs both at the component level and the
integrated behaviors in the context of the architectural assumptions. The software
architecture is captured within the multi-rate, quasi-periodic model of computation
used by Radler [LS14, LGS15]. The use of Radler allows HLRs to be established
from architecture properties and component code contracts. We employ static and
dynamic analysis tools for analyzing the code for generic properties such as well-
typedness and the absence of certain classes of runtime errors, as well as for speciﬁc
properties expressed by precondition/post-condition contracts. Ontic type systems
are used to connect data values with the phenomenal quantities that they represent,
e.g., ground speed vs. air speed, terrain altitude vs. barometric altitude, private vs.
publishable data, encrypted vs. unencrypted messages, and ﬁltered vs. unﬁltered
sensor inputs. These ontic labels are used in a consistent way at the requirements,
design, and code levels to detect a broad class of data misuse errors that are not

5

detected by ordinary type systems. The assurance workﬂow is implemented and
monitored in a framework called Baseline DesCert that maintains the claims and
evidence as the design evolves.

We present an outline of the DesCert approach to evidence generation within
an assurance-driven methodology for the development of safety-critical software in
Chapter 2. The details of our approach are ﬂeshed out in subsequent chapters. In
Chapter 3, we describe the case study of our system under assurance, namely, an
Advanced Fail Safe (AFS) module of the ArduCopter platform that is used to detect
and recover from speciﬁc classes of failures. Chapter 4 outlines our evidence ontol-
ogy. The details of the assurance tools and their integration are given in Chapter 5.
The Baseline DesCert continuous assurance ﬂow manager is described in Chapter 6.
The details of evidence generation using the DesCert methodology on the AFS case
study are laid out in Chapter 7. Concluding observations are given in Chapter 8.

6

Chapter 2

The DesCert Approach

In the DesCert project, we have adopted an Assurance-Driven Development (ADD)
approach to software where the design objective is to create software that is sup-
ported by semantically rigorous evidence that can be incorporated into an eﬃcient
argument. The evidence artifacts we create are aligned with the DO-178C objec-
tives but are also compatible with the goals of intent, correctness, and innocuity
associated with Overarching Properties. We illustrate our approach to rigorous evi-
dence generation with an Advanced Fail Safe module for the Arducopter rotorcraft
platform.

2.1 Assurance-Driven Development (ADD)

The products of engineering have been engines, bridges, buildings, factories, planes,
and automotives. These products are designed based on abstractions of chemical,
structural, mechanical, and electrical laws and processes that are observable with
reasonable precision and reproducible with uncanny accuracy. Software is a diﬀer-
ent kind of beast. Each piece of software is sui generis. Software-intensive systems
have to meet a stringent range of demands spanning functionality, performance,
reliability, persistence, security, and maintainability. Software designs can be ex-
ceedingly complex. Such systems can be composed of many, deeply nested layers of
abstraction. There are few general laws that help in modeling and understanding
software behavior. The operation of software is typically only indirectly observ-
able. Software-related failures can range from annoying issues like memory leaks
and poor search results to design ﬂaws, security holes, and bugs. Even minor errors
like numerical overﬂows can have catastrophic consequences, as was illustrated in
the failure of the Ariane-5 launch. Software-intensive systems exhibit high internal
structural complexity, as well as high external complexity in meeting a broad range

7

of requirements and use cases. Since it is not possible for testing to span the inter-
nal and external complexity, it is important to independently certify the behavior
of the software for its intended use. Certifying software-intensive systems is hugely
expensive due to the combination of internal and external complexity.

Performing a post facto certiﬁcation of a completed software project suﬀers from
conﬁrmation bias. Any gaps uncovered late in the software lifecycle during the cer-
tiﬁcation process are likely to be too costly to ﬁx. The DesCert project approaches
certiﬁcation as an integral part of the software lifecycle. We achieve software certi-
ﬁcation through an assurance-driven development (ADD) methodology where

• The primary objective of the development is an assurance argument that can

be maintained along with the software, and

• The claims, arguments, and supporting evidence are developed and reﬁned

through the software lifecycle

The ADD methodology tracks the software development artifacts (high-level re-
quirements, architecture, low-level requirements, source code, object code) through
each stage of the lifecycle. Tools are employed at each stage to generate evidence to
show that

1. The reﬁnement of the development artifacts from one stage to the next is

correct.

2. The development artifacts produced in each stage are accurate and consistent,

and exhibit runtime safety and security properties.

In Phase 1 of the ARCOS program, we have focused on the ADD infrastructure
in the form of requirements deﬁnition and analysis, architecture and build systems,
trusted tools for static and dynamic code analysis, and continuous assurance and
evidence integration workﬂows.

2.2 Designing for Eﬃcient Assurance Arguments

On 2 September 2006, an RAF Nimrod XV230 “suﬀered a catastrophic mid-air
ﬁre” while ﬂying in Helmand province, Afghanistan. All fourteen people aboard the
plane died. The ﬁre happened 90 seconds following air-to-air refuelling (AAR). The
Nimrod, developed from the de Havilland Comet, has been ﬂying since 1969 but the
AAR had been added by BAE ﬁrst in 1982 and upgraded in 1989, and certiﬁed on
the basis of a safety case developed by BAE in consultation with QinetiQ during
2001-2004. The cause of the ﬁre was a fuel leak around the AAR that was ignited by

8

Figure 2.1: DesCert Assurance Driven Development Methodology

contact with an exposed (due to frayed/inadequate insulation) element of the cross-
feed (CF) duct (1969-75) and Supplementary Conditioning Pack (SCP) duct (1979-
84) that transported hot (470◦C) air. The cross-feed duct was placed dangerously
close to a fuel tank. The accident was the subject of an investigation by Charles
Haddon-Cave [HC09]. The report from this investigation pointed out a number of
things that were wrong with the design of the AAR system as well as the “safety
case”. A key point noted by the report is

As a matter of good engineering practice, it would be extremely unusual
(to put it no higher) to co-locate an exposed source of ignition with a
potential source of fuel, unless it was designated a ﬁre zone and provided
with commensurate protection. Nevertheless, this is what occurred within
the Nimrod.

9

The report also observes that:

A Safety Case itself is deﬁned as “a structured argument, supported by
a body of evidence, that provides a compelling, comprehensible and valid
case that a system is safe for a given application in a given environment”.

The basic aims, purpose and underlying philosophy of Safety Cases were
clearly deﬁned, but there was limited practical guidance as to how, in fact,
to go about constructing a Safety Case. . . . If the Nimrod Safety Case had
been properly carried out, the loss of XV230 would have been avoided.

The Nimrod XV230 accident and a number of other accidents demonstrate that
failures can arise from a combination of many sources: poor regulation, inept man-
agement, bad design, defective engineering, inadequate maintenance, and improper
operation. If a safety case or assurance argument covered each of these sources of
failure in their full complexity, it would fail to be convincing. No evaluator would
have the resources to draw out all of the ﬂaws in such a complex assurance case.
With the Nimrod, the safety case as presented drew attention away from the sim-
ple requirement that fuel and ignition should not interact outside the combustion
chamber. This would mean that any heat sinks would need to be physically and
thermally isolated from fuel both as part of the design and maintenance. Any de-
viation from this restriction would be easily detected. More importantly, the need
to develop such an eﬃcient argument for safety serves as a design heuristic: avoid
design features that lack eﬃcient arguments.

An eﬃcient argument requires designs with proven background theories, large
safety margins, trusted tools and processes, secure platforms, and architectures that
oﬀer strong guarantees. The trusted processes must include the use of powerful mod-
eling and analysis tools for analyzing requirements. For example, in the DesCert
project, we use the CLEAR modeling language to capture requirements in a precise
and cogent notation. The requirements are analyzed through model checking and
testing. Ontic types are used to connect a data representation with the quantity it
represents. Ontic type analysis can rule out a number of potential design ﬂaws such
as sending unencrypted data over a public channel, allowing sensitive operations
to operate on tainted inputs, giving unauthenticated users access to sensitive data,
or performing calculations with raw, unﬁltered sensor input. The software architec-
ture must also support strong claims for isolating functionality so that they can only
interact through the “oﬃcial channels” supported by the architecture. The archi-
tecture can thus guarantee correct timing and functional behavior while protecting
against Denial of Service (DoS) and side-channel attacks. Similarly, a certiﬁed build
system and a secure platform can guarantee the provenance and ﬁdelity of the soft-
In Descert, we rely on Radler to oﬀer guarantees on the
ware that is executed.

10

architecture and the build process. We also employ static and dynamic analysis
tools to deliver strong guarantees for the safe execution of C, C++, and Java code
used in the implementation. We also gain eﬃciency by employing a safety monitor
to observe the execution of the system and ensure that the safety policies are not
being violated.

We can illustrate the contrast between an eﬃcient and ineﬃcient argument with a
few simple examples. The use of a separation kernel to guarantee isolation between
processes yields an eﬃcient argument in contrast to a ﬁne-grained argument for
separation bases on analyzing the memory accesses of the individual processes. The
former argument rests on the correctness of the separation kernel, which might be a
substantive assurance exercise, but one with a much larger falsiﬁcation space. Claims
about the separation kernel can be evaluated once and reused multiple times even
within the same assurance argument, whereas any analysis of the memory accesses
would have to be repeated for each instance. Similarly, one could use a programming
language with a strong type system such that a type-safe program cannot crash.
This argument depends on assurance regarding the soundness of the typechecker,
where the cost of this assurance case can be amortized over multiple uses of the
programming language. The claim for the soundness of the typechecker also fails
easily if there is any bug, including those that are irrelevant to the programs in the
current project. The key design strategies for eﬃcient arguments are

• Precise claims

• Validatable models and assumptions

• Amortized cost through trusted and reusable design tools/artifacts

• Architectural separation of concerns

• Rigorous chain of reasoning and evidence

Eventually, when we have enough data on certiﬁcation costs, we can quantify the
eﬃciency of the argument by comparing the amortized cost of an eﬃciently argued
claim against the cost of an ineﬃcient, one-time argument. In summary, DesCert
evidence generation supports strong, reusable claims through the use of the CLEAR
requirements notation, Sally model checking, Radler architecture deﬁnition, Ontic
type analysis, and powerful static and dynamic code analysis.

2.3 Motivation: The Eight Variables Model

The ADD methodology shown in Figure 2.1 illustrates the above aspects of assur-
ance with corresponding development and veriﬁcation activities. The development

11

artifacts in successive lifecycle stages are shown in the center column of this ﬁgure,
with veriﬁcation activities denoted by green arcs on the left and right sides. The arcs
going from a development artifact to a higher level one show compliance — i.e., the
correctness of reﬁnement (Goal 1). The self arcs analyze a particular development
artifact to show accuracy, consistency, runtime safety, and security (Goal 2).

Tools are used to automate the veriﬁcation activities at each stage of the lifecycle,
thus enabling incremental, continuous assurance throughout the lifecycle. The use
of automated tools also enables a systematic process of iterative reﬁnement and
defect removal in early lifecycle stages. For example, requirements consistency and
completeness defects, reported by Text2Test tool, can be iteratively removed before
proceeding to the next stage.
In this respect, the DesCert approach is similar
to recent agile and test-driven-development methods as opposed to the traditional
waterfall method. Chapter 6 describes the continuous assurance ﬂow automation in
DesCert.

The ADD methodology employs both review and testing based methods (shown
on the left side of Figure 2.1) and formal methods (shown on the right), both
supported by tools. The two types of methods can support complementary assurance
objectives or can be used for the same objectives to lower the testing burden/cost
and to increase conﬁdence. The concept of properties, essential to this approach, is
described in Section 4.1. The tools and their usage to generate evidence is described
in Chapter 5.

Our speciﬁc instantiation of the assurance-driven development (ADD) follows
our Eight Variables Model (8VM) of cyber-physical systems. The model as shown
in Figure 2.2 categorizes the classes of components, agents, or actors in the design
and the variables that capture the observable behavior of these components and
their interactions.1
In a typical cyber-physical system, there is a physical plant,
such as a vehicle or a building. The Pose of the plant is a class of variables that
includes the position, orientation, temperature, etc. of the plant. The plant is also
interacting with an external physical World covering the terrain, wind, friction, and
other factors. We can measure some of the physical variables, namely, the Monitored
ones, in the Plant and Environment through Sensors. The Sensor observes these
physical values of the Monitored variables and writes these observations as digital
values of the class of Input variables. The Input variables are processed by the
Controller, i.e., the software component, along with any Operator Commands, to
produce the Output to the actuator and updates to the operator Display. The
Output drives the Actuator to produce the Controlled input to the Plant. Note
that the Environment, Pose, Command, and Display are the externally observable

1The variables here are just labels for the observable behaviors of the actors and their interac-

tions, and should not be confused with program variables.

12

Figure 2.2: The Eight Variables Model

variables, and the Controlled, Monitored, Input, and Output variables are internal.
The Environment, Pose, Controlled, and Monitored variables are physical variables.
The Input, Command, Display, and Output variables are digital variables. Also,
the Controlled, Monitored, Input, and Output variables are Parnas’s original Four
Variables.

We typically work with models of the World, Plant, Sensor, and Actuator, and

even the Operator. The top-level claim for the whole System has the form below

WorldModel(Environment) AND
PlantModel(Environment, Control, Pose, Monitored) AND
SensorAccuracy(Monitored, Input) AND
ActuatorResponse(Output, Control) AND
ControllerOutput(Input, Command, Output, Display) AND
OperatorModel(Display, Command)

IMPLIES
Requirement(Command, Environment, Pose, Display)

In DesCert Phase 1, we are primarily focused on the Software Requirements
which are captured by the ControllerOutput predicate. The physical variables can
be continuous or switched continuous. In the latter case, the variable is characterized
by a series of epochs deﬁned by the switching times switch(i). For each time t, there
is a function epoch(t) that indicates the epoch to which the time t belongs. For
example, the torque delivered by the engine might be a switched variable that is
switched by means of gear shifts. The digital variables are switched but, unlike
physical variables, the values are latched within each epoch. For example, the
variable input is a sampled sequence of values of the physical variable monitor.

13

Figure 2.3: Assurance Argument Structure

The SensorAccuracy predicate constrains the discrepancy between the value of the
physical variable and its sampled counterpart.

The software requirements in the ControllerOutput speciﬁcation are imple-
mented by the Architecture and the Component Contracts (the Low Level Require-
ments or LLRs). The Architecture consists of the Logical Architecture and the Phys-
ical Architecture. The Logical Architecture speciﬁes the nodes (with their periods,
step functions, their list of published and subscribed topics) and the topics. The
Physical Architecture maps nodes to virtual machines on actual physical hardware
platforms, and topic channels to speciﬁc communication mechanisms. The assur-
ance argument is factored so that the ControllerOutput speciﬁcation is entailed by
the Component Contracts and the Logical Architecture. The Physical Architecture
can be shown to imply the assumptions made in the Logical Architecture regarding
scheduling jitter, worst-case execution time (WCET) and communication latencies
and throughput. The semantic structure of the assurance argument is described
in Figure 2.3. In supporting this argument, we need to ensure that we also have
empirical or analytical evidence to support the argument nodes (the circles) as well.

The validity of the argument rests on the strengths of the inference nodes. These
inference nodes can be inductive, as in supporting a claim with test evidence, deduc-
tive, as in deductively decomposing a claim into subclaims, or probabilistic, as when
the probability of failure is computed. The inference nodes represent argumentation
patterns that are used repeatedly and hence compatible with the eﬃcient argument
goal.

14

2.4 The Radler Architecture Framework

The Radler framework employs a distributed quasi-periodic model of computation
where individual computation nodes interact within a publish/subscribe architec-
ture [LS14, LGS15]. The logical architecture consists of nodes and topics. Each node
publishes on a collection of topics, where each topic has at most one publisher node,
and subscribe to another collection of topics. The nodes execute periodically with
minimum and maximum bounds on the period between two successive executions.
In each execution, a node reads its subscription mailbox to extract the inputs to
which it applies a step function. The outputs of the step function are then published
to the corresponding subscriber mailboxes. A number of useful properties can be de-
rived directly from Radler logical architecture. The physical architecture maps the
nodes to virtual machines which are themselves mapped to physical machines, and
the mailbox semantics is implemented using physical communication channels and
buﬀers. Within the Radler architecture, behavioral properties of the state machines
can be established using the step function precondition/postcondition contracts and
the logical architecture. The step function code can be independently analyzed for
compliance with the contract, the worst-case execution time bounds, and for generic
properties such as the absence of runtime errors or ontic type violations. Traceabil-
ity information can be maintained tracking requirements to state machines which
are decomposed into Radler nodes with step functions implemented by code. Radler
also provides a certiﬁed build system so that the executables are created with the
glue code needed for execution and interaction.

A Radler software architecture is speciﬁed in the Radler Architecture Deﬁnition
Language (RADL) as a publish/subscribe system with periodically executing nodes
publishing on bounded latency channels. An example .radl ﬁle with the architec-
ture deﬁnition is shown in Section 5.2.2. A RADL architecture deﬁnition consists of
a logical architecture and a physical architecture. The logical architecture speciﬁes
nodes and topics. Each topic has a unique publisher node and a message type. Each
node speciﬁes a set of topics to which it subscribes along with the buﬀer sizes, and
a set of topics on which it publishes. In addition, the node descriptions captures the
minimum/maximum period, the expected latency on each subscribed channel, and
the step function that maps the subscription message buﬀers to published messages.
The channel latency is measured from when the publisher starts executing its step
function so it includes the worst-case execution time. A node might also be attached
to and exchanging data with zero or more devices. The physical architecture maps
nodes to processors and virtual machines and maps each topic channel between a
publisher/subscriber pair for a topic to a physical channel on a communication bus
connecting the two endpoints.

From the logical architecture, we can derive a number of useful theorems that

15

have been formally veriﬁed using PVS. These theorems can be used to derive Archi-
tectureProperties that capture the end-to-end latencies and other timing properties
in the architecture. By factoring out these properties, we can modify the logi-
cal architecture while preserving the Architecture properties so as to maintain the
structure and validity of the assurance argument.

LogicalArchitecture(Nodes, Topics)
IMPLIES
ArchitectureProperties(Input, Command, Output, Display, Nodes, Topics)

Let min(n) and max (n) be the minimum and maximum periods of node n, and let
Dmn be the message latency between publisher m and subscriber n. We then have
the following claims:

1. If min(m) > Dmn, then n received messages from m in the same order in

which they were sent. (No Overtaking)

2. Subscriber n can conservatively detect the failure of m by observing when
k consecutive periods have transpired with no new messages from m for
k.min(n) > Dmn + max (m). (Failure Detection)

3. Messages can be lost because the buﬀer is over-written by newer messages
from the publisher. Under the assumption of No Overtaking and a buﬀer size
of L messages, no more than M − L consecutive messages can be lost for
smallest M such that M.min(m) > Dmn + max (n). This is a crucial property
that ensures that in each step, the subscriber n sees at least one of every
M − L + 1 consecutive messages sent by m, and that n’s buﬀer contains the
last L messages received. (Bounded Message Loss)

4. The age of a message from m to n is the time elapsed between when it is
published by m and and the time it is processed by the subscriber n. The
maximum age of a message is bounded by Dmn + max (m). (Bounded Age)

The upshot of these architecture properties is that if a publisher is signalling a
condition, then it has to be aware that due to Bounded Message Loss, the condition
has to be signalled in at least M − L + 1 consecutive messages in case M − L of
these messages are over-written in the buﬀer. Conversely, a subscriber’s published
values are based on inputs with published age constrained by the Bounded Age
assumption. In the case of the room temperature controller, the latter assumptions
bounds the delay between sensing the temperature and the actuation of the heater.
When combined with bounds on the leakage rate and the heating rate, and the

16

component contracts, the architecture properties can be used to demonstrate that
the room temperature eventually stabilizes to a range between Min and Max, and
remains stably in this interval.
In general, temporal properties like this can be
derived from the combination of the step function contracts and the architecture
properties.

The ArchitectureProperties follow from the logical architecture description,
which in turn is satisﬁed by the mapping to the physical architecture and the prop-
erties we assume of the physical platform.

PlatformProperties(VirtualMachines, TransportMedium) AND
PhysicalArchitectureMapping(Nodes, VirtualMachines,

Topics, TransportMedium)

IMPLIES LogicalArchitecture(Nodes, Topics)

The Radler architecture framework also includes a software build system that
takes as input the logical and physical architecture deﬁnition and the associated
source ﬁles for the step functions and creates a collection of executable binary im-
ages that can be launched on the physical platform. The software running on the
platform implement the architecture in terms of the nodes executing periodically
and communicating on the topic channels. The Radler build system also adds mon-
itors to check that the speciﬁed latency bounds are not breached and adds a ﬂag to
the message to indicate if the contents are based on stale inputs (which can occur
even with normal behavior) or missing inputs (which is abnormal). We extended
Radler to integrate nodes deﬁned using Java code running on a Java Virtual Ma-
chine (JVM). We speciﬁcally added a Java-deﬁned node executing the BeepBeep3
safety monitoring framework. Unlike the AFS node which executes recovery ac-
tions, the safety monitor is a passive component that ensures that any failure event
or combination of events does trigger the appropriate recovery action.

2.5 A Motivating Example: Room Temperature Regu-

lation

We can illustrate the argument template using a simple example of a thermostat-
based room temperature controller which captures the structure of the argument
and the forms of evidence. The temperature controller can be mapped on to the
eight-variables model as shown in Figure 2.4. The thermostat turns the heater on
or oﬀ, and the thermometer senses the room temperature at a speciﬁc location. The
operator can switch the thermostat on or oﬀ and set the desired temperature.

If we consider a simple system like a thermostat, the main requirement is that it
maintains the room temperature around the set temperature between Low and High

17

Figure 2.4: Eight-Variable Model for Thermostat Room Temperature Controller

by switching the thermostat on when the sensed temperature falls below Low + ∆,
and oﬀ when the sensed temperature exceeds High − ∆. There might be additional
requirements, for example, that there is some hysteresis built into the switch for the
heater so that it is not damaged by being switched on and oﬀ too frequently. We
assume (SensorAccuracy) that there is an error of (cid:15) in sensing the temperature,
and the room temperature can rise (ActuatorResponse) or fall (PlantModel) at no
more than a rate of rho degrees per second. We also assume that when the heater
is on, the room temperature rises at a rate of at least ρ− degrees per second, for
0 < ρ− < ρ.

The thermostat example is not as trivial as it might seem. Assumptions about
the sensor, actuator, plant, and environment are needed to achieve the desired be-
havior. Additionally, the architectural model contributes timing latencies that need
to be factored into the argument. The desired property is that the room temper-
ature is maintained between Low and High when the thermostat is on. However,
this might not hold at the initial point when the thermostat is switched on. If the
initial temperature is already above High, then there is no way to force the tem-
perature to within the acceptable range since the system only heats and does not
cool. When the initial temperature θ0 is below Low, it will take some time, at least
Low−θ0
ρ− , from when the heater is switched on before the temperature converges to
within this bound. Since there is a latency of at most τ , in sensing the temper-
ature and switching on the heater, the temperature could drop to θ0 − ρτ within
this time, we need to allow at least Low−θ0−ρτ
seconds following the switching on of

ρ−

18

the thermostat, for convergence to have occurred. Once the thermostat has been
switch on and enough time has elapsed for the room temperature to converge to
the acceptable range, it can be shown that it remains within this range. This is
because, when the temperature is below Low + ∆, then either the heater is already
switched on, and the temperature is rising, or it is oﬀ. The latter condition can only
arise when temperature was above Low + ∆ − (cid:15) at least τ seconds ago. As long as
Low+∆−(cid:15)
< τ , we can ensure that the temperature does not drop below Low before
ρ+

the heater is switched on. Symmetrically, we see that as long as High−∆+(cid:15)
< τ , the
temperature does not exceed High. If we ensure a High − ∆ exceeds Low + ∆ by at
least a positive quantity γ > 2(cid:15), then we can fulﬁl the hysteresis requirement that
the heater not be switch on or oﬀ too frequently. This is because there will be a gap
of at least γ−2(cid:15)

ρ+ between the heater being switched on and the oﬀ, or vice-versa.

ρ+

Figure 2.5: Thermostat Behavior in Radler

The correct behavior of the temperature controller depends on some crucial
architecture properties of the Radler model. The interaction between the physical
room temperature, the digital sampled sensed temperature, and the activation of
the heater is shown in Figure 2.5. The thermometer, the thermostat controller can
be viewed as independent nodes in the architecture. The thermometer samples the
room temperature at a rate, say, of 10Hz. The thermostat switches the heater on or
oﬀ depending on whether the detected temperature falls below Low + ∆ or exceeds
High − ∆. A temperature reading of ˆθ might represent an actual temperature θ
in the range ˆθ ± (cid:15) and drift by at most ρ/10 between readings. When the sensed
temperature falls below Low + ∆, it will be sampled within a tenth of a second.

19

If we assume that the message latency between the temperature sensor that the
heater controller is at most a tenth of a second. If we assume that the thermostat is
operating at 2Hz, then the end-to-end delay between the temperature falling below
Low + ∆ and the heater being switched oﬀ could exceed .5 + .1 + .1 = .7 seconds. In
order for the thermostat to regulate the room temperature within the [Low, High]
interval, we have assume that rate of change of temperature, both during heating and
cooling, is bounded. We need to ensure that the delays introduced by the sampling
rates and message communication is suﬃciently small that the temperature remains
within the safe interval in the time between the temperature triggers Low + ∆ and
High − ∆ are detected, and the heater is turned on or oﬀ.

In the above argument, we are relying on the Radler architecture properties
as well as component contracts regarding the step functions associated with the
individual nodes. These component contracts are just precondition/post-condition
pairs associated with these step functions relative to the mailbox inputs on their
subscribed channels and the outputs on their published channels. For example, the
thermostat contract is that it must direct the heater to be switched on (respectively,
oﬀ) when the sensed temperature falls below Low + ∆ (respectively, exceeds High −
∆).

The argument supporting the ControllerOutput claim can be stated as

ArchitectureProperties(Input, Command, Output,

Display, Nodes, Topics) AND

ComponentContracts(Input, Command, Output, Display, Nodes)
IMPLIES ControllerOutput(Input, Command, Output, Display)

As we saw in the case of the thermostat, assumptions SensorAccuracy, Actuator-
Response, WorldModel, PlantModel, and OperatorModel might all factor into the
design of the Controller since certain couplings between variables might hold only
because of these external constraints. As an example, an interlock in the operator
console might mean that certain commands are impossible in speciﬁc modes. The
key takeaways are that

1. The Eight Variables model decomposes the argument for a system into pre-
cisely stated modeling assumptions about the environment, physical plant,
sensors, actuators, and operator under which the software requirements must
be met.

2. Writing software requirements even for simple systems such as a temperature

controller can be quite subtle.

20

3. The model of computation used in the architecture allows independent soft-
ware components to be be independently developed with their individual com-
ponent contracts.

4. The argument that the software requirements have been implemented follows
from the architecture properties, the logical architecture, and the component
contracts.

5. The assurance case must also demonstrate that the physical architecture sat-
isﬁes the assumptions regarding scheduling, worst-case execution time, and
channel latencies speciﬁed in the logical architecture.

The ArduCopter system is more complicated than a thermostat, but the struc-
ture of the decomposition into claims and subclaims remains the same, and much
of the underlying reasoning follows the same pattern.

2.6 Aligning the Assurance Argument Structure with

DO-178C Guidance

The assurance driven workﬂow and argumentation structure shown in Figure 2.1
aligns with the DO-178C scaﬀold as shown in Figure 2.6. The RTCA DO-178C
guidelines specify certiﬁcation objectives based on ﬁve design assurance levels (DAL)
that correlate with the impact of anomalous behavior: Catastrophic (Level A), Haz-
ardous (Level B), Major (Level C), Minor (Level D), No Eﬀect (Level E). Figure 2.6
(taken from https://en.wikipedia.org/wiki/DO-178C) shows the objectives and
activity for each DAL, with required traceability between artifacts.

The assurance argument in our case is for the AFS component, and it consists

of claims for

1. Tool validity: These will support the validity of the claims and counterexam-

ples generated by the individual tools as supported by tool qualiﬁcation

2. Validity of high-level requirements: Consistency, completeness, veriﬁability,

and compliance with system-level requirements, including traceability.

3. Validity of mapping from high-level requirements to low-level requirements

(LLR), including traceability: Radler architecture + Sally models.

4. Validity of source code: absence of runtime errors, and compliance with LLR,

including traceability.

5. Validity of object code: generation of tests from high- and low-level require-

ments and test execution on object code, including traceability.

21

Figure 2.6: The DO-178C objectives and argument structure

The claims and artifacts are captured in Figure 2.7 (claims are in green colored
boxes on the right, other boxes denote evidence artifacts). The evidence generated
to support the above claims include

1. Tool Qualiﬁcation evidence for CLEAR, Text2Test, Clear2Sally, Sally, Radler,

Seahorn, Randoop, Daikon, Toradocu, and the Checker Framework.

2. High-level requirements in CLEAR partitioned module-wise into Requirement

sets.

3. Test oracles

4. Test suites

5. Radler architecture properties supported by test traces

6. Sally model-checking claims and counterexamples.

7. Code analysis: static and dynamic analysis evidence.

22

Figure 2.7: DesCert Assurance Claims and Artifacts

2.7 Assurance Ontology

The assurance artifacts created and maintained in the DesCert project are ingested
into RACK. These artifacts are either data (papers, requirements, test cases, anal-
ysis results, architecture deﬁnitions, proofs, and code, or metadata (requirement
labels, traceability, tool conﬁguration, ﬁle handles). The data is provided in the
form of ﬁles in a separate directory. The metadata is ingested into RACK. The
DesCert ontology is deﬁned in the SADL language. In representing the evidence
data in the TA2 Rack-in-a-Box framework, we employ the Provenance ontology
schema (see Figure 4.4) consisting of entities Agents, Activities, and Artifacts,
and relations:

1. ActedOnBehalfOf(Agent, Agent).

2. WasAssociatedWith(Activity, Agent)

3. WasAttributedTo(Entity, Agent)

4. WasDerivedFrom(Entity, Entity)

5. Used(Activity, Entity)

6. WasGeneratedBy(Entity, Activity)

7. WasInformedBy(Activity, Activity)

23

In the TA2 ontology, the activities are System development, Requirements de-
velopment, Hazard Identiﬁcation, Code development, Test development, Test execu-
tion. For DesCert, we add the Software Architecture and Low-Level Requirements
activities. The evidence schemas we employ consist of

1. High-Level Requirements and Test Development using CLEAR and Text2Test

to develop Requirements sets mitigating hazards.

2. Property Checks using Sally Tool covering both speciﬁc and generic properties

associated with requirement sets

3. High-Level Requirement Analysis by Text2Test Tool generating Requirements

Analysis results

4. Software Architecture and Code Contract (Low-Level Requirements) Devel-
opment using the Radler Architecture Deﬁnition Language (RADL) and build
system as well as speciﬁc software libraries

5. Property Analysis of Source Code by SeaHorn connecting code to Low-Level

Requirements on code components

6. Property Analysis of Source Code by Randoop and Daikon connecting code

to Low-Level Requirements on code components

7. Property (Type) Analysis of Source Code by Checker Framework connecting

code to Low-Level Requirements on code components

We have also extended the ontology to connect properties with the corresponding

DO-178C objectives. The DesCert ontology is described in detail in Chapter 4.

2.8 ArduCopter Challenge Problem

The DesCert approach to assurance-driven development of new software is proto-
typed using the ArduPilot platform. The ArduPilot is an open source platform for
controllers for a range of vehicles including rovers, ﬁxed-wing aircraft, and rotor-
craft. In DesCert, we employ the ArduCopter instantiation of the ArduPilot. The
platform architecture for the ArduPilot is shown in Figure 2.8. The architecture has
a Hardware Abstraction Layer (HAL) that supports a number of hardware/OS plat-
forms, a shared library for control-related computations, and vehicle-speciﬁc code
which in our case is the ArduCopter rotorcraft. The platform supports a number
of simulation engines, and in our project we use the Software-In-The-Loop (SITL)
simulator.

24

Figure 2.8: ArduPilot Platform Architecture (From https://ardupilot.org/dev/
docs/learning-ardupilot-introduction.html)

Though the ArduCopter has a basic Advanced Fail Safe (AFS) functionality for
recovering from glitches, it is embedded into the main control loop. We decided to
deﬁne an independent AFS functionality that uses data from the primary control
software. Our AFS system is located on the companion computer which is connected
to the primary computer through MAVLink. We deployed our Radler architecture
running on the Robot Operating System (ROS) by introducing a gateweay Radler
node representing the interface with the primary ArduPilot platform. The communi-
cation between the gateway node and the primary computer employs the MAVROS
transport channel.

The assurance case study for the Advanced FailSafe (AFS) component of the
ArduCopter focused on a concept of operations (ConOps) where the ArduCopter
autonomously executes a mission plan by ﬂying through a sequence of way points
at speciﬁed altitudes. The AFS monitor detects events such as range violations,
geofence breaches, GPS loss, communication loss, and battery depletion to trigger
appropriate recovery actions. When a potential failure event is detected, the AFS

25

monitor executes a recovery action to keep the vehicle safe either by returning to the
launch site, hovering in place, or landing. The Radler architecture for the challenge
problem also integrated BeepBeep3, a Java application for safety monitoring. The
details of the AFS Challenge Problem are spelled out in Chapter 3.

2.9 Assurance Tools

As already noted, a design workﬂow supporting eﬃcient arguments requires trusted
tools with semantically coherent interfaces that can be composed for evidence gener-
ation. The DesCert workﬂow employs CLEAR as a notation for capturing high-level
behavioral software requirements (HLRs). CLEAR requirements capture temporal
properties specifying the reactive behavior of state machines such as the AFS mod-
ule. They also specify certain safety and timing properties that must be satisﬁed by
the state machines. From the CLEAR requirements, we use the Text2Test tool to
generate test inputs and test oracles for the state machines in the form of control-
lable inputs and observable outputs. Test generation is based on a testing theory for
exploring and monitoring the implementation of each operator used in the require-
ments deﬁnition. The Text2Test tool also generates transition system models from
the CLEAR requirements in the Sally language. These transition system models can
be individually or jointly analyzed for temporal properties, speciﬁcally invariants,
using the Sally model checker. The software HLRs are reﬁned to a design given
by the Radler architecture which implements each state machine component as a
Radler node. We have used SRI’s Prototype Veriﬁcation System (PVS) [ORSvH95],
an interactive proof assistant, to verify certain key architectural propertes of the
Radler architecture. As we showed in Section 2.5, these architecture properties can
be used to reﬁne the HLRs in terms of precondition/post-condition contracts on the
step functions employed by the nodes. These contracts as well as generic properties
of the source code such as type correctness and the absence of certain classes of
runtime errors are established using dynamic and static analysis. The static analy-
sis tools include the Checker Framework for annotated Java code, and SeaHorn for
LLVM bit code. The dynamic analysis tools include the Randoop unit test genera-
tor and the Daikon analyzer for likely program assertions, as well as the Text2Test
tool. We also integrate BeepBeep3 as an runtime safety monitor.

While we generated some modest tool qualiﬁcation evidence, we did not take a
serious stab at tool qualiﬁcation. A rigorous tool qualiﬁcation following the guide-
lines in RTCA DO-330 would be an extremely costly exercise that would distract us
from the research goal of developing a proof-of-concept evidence generating design
workﬂow. The DesCert assurance tools are summarized in the table in Figure 2.9.

26

Phase
Tool Qualiﬁcation

Tools
Self Analysis

System Requirements

Operational Scenarios

Hazard Analysis

Sally

Software High Level Requirements

Software Low Level Requirements

Executable Object Code

CLEAR
Text2Test
PVS
Sally
SeaHorn
Randoop
Daikon
Checker Framework
BeepBeep3
Text2Test

Figure 2.9: DesCert Tool Suite

Artifacts
Test+Analysis
Consistency
Completeness
Model Checking

Consistency
Completeness
Validation

Static/Dynamic Analysis

Safety Monitoring

2.10 Current Limitations of DesCert Assurance Method-

ology

The DesCert assurance-driven development workﬂow is aimed at creating a paradigm
for the automated certiﬁcation of safety-critical systems. The Phase 1 eﬀort was
largely exploratory. We centered our workﬂow on the creation of designs that sup-
ported eﬃcient arguments. The Radler model of computation plays a key role in
facilitating an eﬃcient argument structure. Our assurance-driven development fol-
lows the structure of an assurance case complying with the guidance in DO-178C.
We track several of the Level C and D objectives and traceability relations suggested
by the DO-178C standard. However, our approach generates evidence during the
design lifecycle where the goal of the design is the creation of a software system
supported with the design and assurance artifacts. This is in contrast to a post
facto approach to certiﬁcation where the evidence chain is constructed to comply
with the DO-178C objectives as a postscript to the design lifecycle. We also fo-
cus on constructing evidence that targets the behavior of the software and not the
process by which it is constructed and analyzed. Since we generate evidence from
diﬀerent phases of the design, we target evidence that is semantically coherent so
that the behavioral models and claims at the diﬀerent levels are consistent with each
other. In particular, any software failure can be connected to a ﬂaw in the assurance
argument constructed from the evidence.

Broadly, the DesCert approach to assurance-driven development starts with the
formalization of the intent of the system in the form of precise requirements deﬁned

27

in the CLEAR language. The analysis of the requirements captured in CLEAR
cover both generic properties that must hold of any requirements as well as speciﬁc
properties that constrain the software application under certiﬁcation. We use ontic
type annotations to capture the representational intent of the data objects consis-
tently throughout the design. The software design is centered around a choice of an
architectural model of computation, which in our case is the Radler framework. The
architecture, deﬁned in the Radler Architecture Deﬁnition Language (RADL), cap-
tures the logical architecture in the form of nodes operating quasi-periodically, and
communicating over publish-subscribe channels with speciﬁed latency bounds. The
RADL physical architecture maps the nodes to processes within a virtual machine
and the topic channels are implemented through mailboxes connected to their pub-
lishers through a transport protocol. Radler architectures are ﬂexible about how the
physical architecture is actually realized as long as the period, communication, and
communication latency assumptions are satisﬁed. The software services provided
by each node are implemented as step functions with their own precondition/post-
condition contracts.

While the above outline of a high-assurance design process can be made fully
rigorous, there are some limitations with the Phase 1 work that need to be addressed
in future work.

1. CLEAR has only been applied to a limited set of case studies. Both the
behavioral language and the background libraries of useful operations need to
be expanded.

2. We have not yet deﬁned an Ontic type framework that spans the design stages

from requirements to source code.

3. The experience with translating CLEAR state machine requirements to Sally
is limited to a few examples. This translation will need to be expanded to
handle complex requirements.

4. Sally itself only implements model checking for invariants and cannot handle

more complex temporal properties.

5. The soundness of the translation from CLEAR to Sally needs to be certiﬁed.

6. Though we have a broad and mature suite of tools, only the HiLite tool has

gone through a tool qualiﬁcation process.

7. While we have the source code analysis tools and did apply them to isolated
examples, we did not make a systematic eﬀort into generate and integrate
evidence from the analysis of source code components since the High-Level
Requirements and Design levels took up a fair amount of eﬀort.

28

8. The Baseline DesCert continuous integration workﬂow only has a small number
of plug-ins, mainly Randoop and Daikon, and we will be working to expand
the number of plug-ins in future work.

29

Chapter 3

Phase 1 Challenge Problem:
Advanced Fail Safe (AFS) Case
Study

We are using the open source ArduPilot ([ard20]) platform for the the Phase 1
case study/challenge problem. The ArduPilot Project provides an advanced, full-
featured and reliable open source autopilot software system. The ﬁrst ArduPilot
open code repository was created in 2009 - since then it has been developed by
a team of diverse professional engineers, academics, computer scientists, and other
members of our global community. It is capable of controlling almost any vehicle sys-
tem imaginable: conventional and VTOL airplanes, gliders, multirotors, helicopters,
sailboats, powered boats, submarines, ground vehicles and even Balance-Bots.

ArduPilot is a deeply tested and trusted autopilot system and the open-source
code base means that it is rapidly evolving, always at the cutting edge of tech-
nology development, whilst sound release processes provide conﬁdence to the end
user. With many peripheral suppliers creating interfaces, users beneﬁt from a broad
ecosystem of sensors, companion computers and communication systems. Since
the source code is open, it can be audited to ensure compliance with security and
secrecy requirements. The software suite is installed in vehicles from many manu-
facturers, such as many from our Partners, and more broadly throughout the global
autonomous systems industry. It is also used for testing and development by large
institutions and corporations such as NASA, Intel and Insitu/Boeing, as well as
countless colleges and universities around the world.

ArduPilot works with a wide variety of hardware platforms1, as well as a range

1https://ardupilot.org/copter/docs/common-autopilots.html

30

of simulators2. We selected the rotorcraft ArduCopter platform in the context of the
Software-In-The-Loop (SITL) simulator since it has navigation software functional-
ity that is similar (in principle) to the NAV system in legacy Boeing AH-64 Apache
platform provided by TA4 in ARCOS, and our results in ArduPilot can then be
easily reproduced/repeated. Further we can faithfully simulate the actual software
execution on an actual platform in a SITL simulation thereby alleviating the need
to deal with time-consuming hardware/platform integration issues. We focus on the
Advance Fail Safe (AFS) runtime monitor software component that checks where
the ArduCopter is ﬂying within the established limits while executing the mission
plan and initiates planned contingency recovery actions when any violations are
detected.

To summarize, we chose this ArduPilot platform for the following reasons: (i)
allows for easy access, modiﬁcation and distribution of source code associated with
diﬀerent software pieces (ii) has representative complexity of the typical function-
ality on the aircraft (iii) easy to to demonstrate enabling certiﬁcation technologies
developed within ARCOS for the evaluation teams using releases of pre-installed
necessary software in Virtual Machines (iv) easy to integrate and packages solution
of certiﬁcation tool technologies along with the systems and software that needs to
certiﬁed.

3.1 Concept of Operations

Figure 3.1: Phase 1 Mission Operation

2https://ardupilot.org/dev/docs/simulation-2.html

31

As shown in Figure 3.1, we envision an ArduCopter Rotorcraft (VTOL) per-
forming Autonomous Surveillance mission during a nominal operation where no
contingency situations are encountered during operation and the operation is to be
performed in a location with communication proximity to a Ground Control Station
(GCS) that expected to oversee the ArduCopter operation. All coordinates shown
are in triplet (latitude, longitude, altitude) and in meters as units. Also altitude
is speciﬁed relative height above origin, which is also assumed to be the home po-
sition or site of launch L i.e. where mission begins as well as site of return once
the mission is completed. The mission involved following a sequence of waypoints
L, W 1, W 2, W 3, ..., W 6, L. After reaching the launch position, the craft will land.

As part of the mission conﬁguration, Rally Points are also speciﬁed e.g. R1, R2.
These are pre-speciﬁed points where the ArduCopter can proceed to, as alternative
to Home point or waypoint, during emergencies or contingencies. For example,
ArduCopter can proceed to the closest Rally Point, rather than proceeding all the
way back to the Home position, and can loiter at that location, and perform an
automated landing there.

Figure 3.2: Geofences during Mission Operation

ArduPilot supports alarms generated by several types of Fences (boundaries de-
scribed by latitude/longitude and/or altitude) to prevent the vehicle from traveling
higher or further than desired, or into unwanted areas. Types of Fences supported
varies by vehicle. Upon Fence breach, selectable actions are taken. As part of mis-

32

sion conﬁguration and illustrated in Figure 3.2, the ArduCopter has Geo-Fences
pre-speciﬁed. The Cylindrical Geo-Fence is a simple “tin-can” centered around
home. Cylindrical Geo-Fence restriction has two checks associated with it (i) max
altitude check (height of cylinder) and (ii) a range check (radius of cylinder). Ad-
ditionally, there is an arbitrary shaped Polygonal Geo-Fence restriction to ensure
ArduCopter ﬂies speciﬁc locations within the polygonal boundary. Cylindrical and
Polygon Geo Fence Breach Checks are both Inclusion fences to keep vehicle from
ﬂying “out-of the fence”. Note, Exclusion fence available but not utilized in the
current mission conﬁguration setup to keep vehicle from ﬂying “into the fence”.

3.2 Mission Scenario and Assumptions

The primary objectives of the mission are for the ArduCopter to :

• Successfully complete a surveillance mission that is pre-conﬁgured before start
and includes takeoﬀ from home/launch, visit all waypoints in sequence and
ﬁnally return to launch and land (Objective 1)

• Complete the mission with full autonomous control of the ArduCopter :

– Without any remote pilot assistance from Ground Control System (GCS)

(Objective 2)

– Without any loss of control of the ArduCopter in both nominal and oﬀ-
nominal/contingency/emergency situations enumerated apriori (Objec-
tive 3)

– Without physically losing track of the ArduCopter whereby GCS is noti-
ﬁed of the location of the ArduCopter during the whole mission duration
(Objective 4)

• Complete the mission operation safely:

– By limiting potential hazards (e.g. collision) risks exposed to humans,
properties and other airborne assets during the operation of the mission
by restricting the Arducopter to ﬂying within a pre-conﬁgured Geofence
i.e. Operational Safety Zone (Objective 5)

– Without crashing (destroying) the ArduCopter during takeoﬀ, cruising

through the waypoints or during landing (Objective 6)

We would ideally like to satisfy all missions objectives, if possible, and if there
are conﬂicts/trade-oﬀs then we require mission objectives prioritization (from high

33

to low) be in the order: (5), (6), (3), (4), (1), (2). As an example of prioritization,
landing immediately at some point when insuﬃcient battery emergencies occurs
rather than going towards at Home/Launch shows prioritization of objectives (5) &
(6) over (1).

There are a variety of assumptions related to the validity of the mission related

conﬁguration:

• Mission Waypoints trajectory are correctly speciﬁed in a loop: L → W 1 →

W 2 → · · · → W n → L

• Geofence conﬁguration (max altitude, range, polygon) is correctly speciﬁed:

– Cylinder (2.π.range×max altitude), Polytope (2D Polygon × max altitude)

deﬁned

– Operational Safety Zone = Cylinder ∩ Polytope i.e. Common 3D space

intersecting Cylinder and Polytope must be non-zero

– Minimizes potential hazards (e.g. collision) risks exposed to humans,
properties and other airborne assets as long as the operation of the mis-
sion is restricted within this operational safety zone

• Mission Waypoints trajectory is feasible if it completely within the Geofence:

– All waypoints and points en-route between waypoints are completely

within Operational Safety Zone = Cylinder ∩ Polytope

– All waypoints and points between waypoints along L → W 1 → W 2 →
· · · → W n → L satisfy (1) range check , (2) max altitude check and (3)
polygon check

• Emergency Rallypoints R1, R2, · · · Rn are suitably chosen:

– All rallypoints are within Geofence and satisfy (1) range Check , (2)

max altitude check and (3) polygon check

– In case of reacting to a speciﬁc emergency/oﬀ-nominal/contingency situ-
ation, rather than having to only proceed to the Launch/Home position
always (which might be far oﬀ depending on where in the trajectory
ArduCopter is currently ﬂying), Rallypoints are suitable “alternate” lo-
cation choices for the ArduCopter to proceed to e.g. within Line of Sight
(LOS) of Ground Control Station (GCS)

– Apriori conﬁgure within the mission “closest” Rallypoints associated dif-
ferent waypoint and paths between waypoints. E.g. R1 Rallypoint for
L → W 1 → W 2 → W 3 → W 4 and R2 for W 4 → W 5 → W 6 → W 7

34

• Mission Waypoints and trajectory en-route between waypoints as well as Ral-
lypoints are within communication range of the Ground Control Station (GCS)
in normal/nominal situations. Note: Oﬀ-nominal complete loss of communi-
cation as well as discontinuity in service (intermittent service) is expected

• Mission Waypoints and trajectory en-route between waypoints as well as Ral-
lypoints typically have access to GPS satellites and GPS Fix signals for navi-
gation in normal/nominal situations. Note: Oﬀ-nominal complete loss of GPS
signal as well as discontinuity in service (intermittent service) is expected. In
these situation the on-board navigation (e.g. EKF ﬁlter) is expected to supply
location information continuously to the ArduCopter to coast for a while using
only primary inertial sensor IMU (accelerometer, gyros) measurements until
aiding sensor GPS ﬁx signals may be obtained later (no guarantee for that
GPS Fix signal to happen).

• Remaining Battery Energy Level is suﬃciently provisioned/budgeted and con-
ﬁgurations appropriately setup for [100% > TN OM > TRT L > TLAN D > 0%]
as shown in Figure 3.3

Figure 3.3: Battery Energy Levels

– Nominally the full mission can be completed with (100%−TN OM ) battery
energy and some spare battery level remaining at TN OM . No guarantees
in oﬀ-nominal situations requiring tough maneuvers, battery drainage
etc.

– TRT L remaining battery threshold level is so chosen such TRT L battery
energy is good enough with spare to return to launch/home and do the
necessary vehicle maneuvers to go from anywhere within mission trajec-
tory in a normal/nominal condition. No guarantee in oﬀ-nominal situa-
tions

– TLAN D battery threshold level is so chosen such TLAN D battery energy
is good enough with spare to vertically land on the ground immediately
and safely from any altitude within max altitude in normal/nominal con-
ditions

35

3.3 System and Software Architectures

For the phase 1 challenge problem, we envision a system architecture built with
associated software components depicted in Figure 3.4. In particular, phase 1 focus
will be limited to generation of evidences for compliance and certiﬁcation a single
software component associated with Advanced Fail-Safe (AFS) function, shown to
the top right of Figure 3.4. The vision is that the Ground Control Station (GCS)
performs remote pilot operations (monitors and potentially does control interven-
tions) of the ArduCopter using some wireless channel of communication (5G/4G,
Radio on WiFi, SATCOM etc). We use MAVLink as the message transport proto-
col for the communication between GCS and ArduCopter including a bi-directional
periodic heartbeats, status updates, sending/receiving command, data and acknowl-
edgments (ACKs). Note that MAVLink oﬀers no guarantees for message delivery
and repeated state checks may have to be done by underlying software to ascertain
reliable delivery.

The GCS Software used MAVProxy and Flight Software (on-board software on
ArduCopter) has the vehicle speciﬁc ﬂight code and in phase 1, we do not make
any changes to these code and use the code as is. As shown in the bottom left
of Figure 3.4, the ﬂight software has multiple layers/parts: (1) Implements the
ArduCopter ﬂight control modes including: Takeoﬀ, Loiter, Land, Auto (autopi-
lot), Altitude-Hold, Stabilize, Return-to-Launch (RTL) etc. (ii) Shared Libraries to
support multiple drivers for various navigation sensors e.g. GPS, IMU and other
inertial sensors, barometer, camera etc (iii) Navigation function implemented using
Extended Kalman Filter (EKF), Position/Attitude and Motor/Servo control etc for
teh diﬀerent mode speciﬁcations (iv) hardware abstraction layer (HAL) to support
portability to lots of diﬀerent platforms. and (v) OS support for Linux etc and
various hardware support code (processor, IO, sensor interfaces).

Our primary focus in phase 1 is to certify a single software component developed
as new software within ArduPilot and which architecturally integrates with the rest
of ArduCopter system and software in a seamless manner. We design and develop the
Advanced Fail Safe (AFS) function in a principled manner i.e. with a view to ease
certiﬁcation by minimizing defect escapes and lowering veriﬁcation costs through
automation. The objective of AFS function is to take safe corrective action in
abnormal situations – identifying the following six contingency situations triggering
the appropriate recovery response actions:

1. Cylindrical Geofence breach: Max Altitude check violation

2. Cylindrical Geofence breach: Range check violation

3. Polygon Geofence breach: polygon boundary check violation

36

t
n
e
n
o
p
m
o
C
e
r
a
w
t
f
o
S

)
S
F
A
(

e
f
a
S
-
l
i
a
F

d
e
c
n
a
v
d
A
h
t
i
w
e
r
u
t
c
e
t
i
h
c
r
A
m
e
t
s
y
S

:
4
.
3

e
r
u
g
i
F

37

4. GPS Lock Loss

5. Ground Station Communication Loss

6. Insuﬃcient Battery

A shown in the bottom right of Figure 3.4, the AFS function is built as a separate
software component in a companion computer i.e. separate computer hardware that
also communicates with the ArduCopter ﬂight software using MAVLink over another
independent channel. The channel itself can be a wired communication medium like
a serial interface or ethernet interface or another potentially another wireless inter-
face. Alternatively the AFS function can also be loaded on the ArduCopter ﬂight
hardware and co-hosted as separate software software partition along with ﬂight
software partition and the inter-partition communication still leveraging MAVLink
transport interface. This ﬂexibility in architectural separation of AFS functionality
allows us to develop the AFS software component independently and leveraging the
time-space partitioning strategy (e.g. ARINC 653 partition [KR07]) for demonstrat-
ing veriﬁcation of the AFS software component in isolation. Subsequently, we would
then focus on the dependencies of the AFS function with the rest of the system i.e.
veriﬁcation of the integrated system and it’s multiple components in a systematic
manner. To reiterate, in phase 1 and in this report, we limit our focus still to
generating evidence for a single AFS software component.

AFS software component is built on top of Robot Operating System, version 1
(ROS1 [Kou17]) for a Linux operating system on top of which all ArduPilot soft-
ware code is built. We leverage MAVROS, ROS-based extendable communication
node, which enables MAVLink extendable communication between computers run-
ning ROS (1) for any MAVLink enabled autopilot, ground station, or peripheral.
MAVROS is the ”oﬃcial” supported bridge between ROS (1) and the MAVLink pro-
tocol. AFS Function is built using Robot Architecture Deﬁnition Language (RADL)
speciﬁcation and associated Radler 4 5 code generation tool and build environment
to generate executables that ensures the software code executing in a ROS envi-
ronment adheres to the speciﬁcation. We discuss in Section 5.2 the details of the
RADL architectural speciﬁcations, the nice properties inherited due to the architec-
tural paradigm when the system and associated software components strictly adhere
to the speciﬁcation and the Radler build tool that assembles the requisite software
for execution on the ROS platform. The AFS speciﬁc RADL speciﬁcation i.e afs.radl
is discussed in Section 7.4. We design the AFS system architecture using Radler
as a collection of nodes (with periods, publish/subscribe topics) and topics. The
system can be tested using the SITL simulator of ArduPilot.

4Radler 1.0 documentation: https://sri-csl.github.io/radler/
5Radler examples: https://github.com/SRI-CSL/radler

38

Radler architecture speciﬁcation consists of the logical and physical parts. The
logical part is speciﬁed in terms of node and topic similar to ROS. The nodes execute
independently and periodically, and publish and/or subscribe topics. AFS Function
node (afs function) executes its step function with period of 100 milliseconds and
publishes 4 recovery actions subscriber ROS nodes: (i) AFS Geofence Breach Re-
covery for 3 diﬀerent kinds (altitude, range, polygon) (ii) AFS GCS Comm Loss
Recovery (iii) AFS GPS Lock Loss Recovery (iv) AFS Battery Insuﬃciency Recov-
ery. The AFS Gateway node (afs gateway) acts as bridge between AFS Function
and through the MAVROS/MAVLink connects to the on-board ﬂight controls on
the ArduCopter.

More speciﬁcally, AFS Gateway node forwards back-and-forth messages between
AFS Function and ROS/MAVROS/MAVLink interface on the companion computer.
It remotely collects events from ﬂight controls e.g. GPS Lock Loss, Remaining
battery energy, Comm Loss, Geofence Breach events and forwards that to the AFS
Function. The AFS Function implements the Recovery action logic and sends control
commands back (e.g. change of ﬂight mode ) to AFS Gateway which then send the
command to the ﬂight controls on the ArduCOpter via the MAVLink.

Physical part of the AFS RADL speciﬁcation map nodes to the process on speciﬁc
machines, in this case companion computer. Radler build process, using source codes
(afs gateway.h, afs gateway.cpp, afs function.h, afs function.cpp), does some explicit
checks and also generates the glue code for scheduling, communication, and failure
detection such as timeout or staleness of data. Note that in Phase 1, we exclusively
focus on the AFS Function and not on the AFS Gateway.

3.4 High Level Behavioral Description of AFS Function

The primary objective of intent speciﬁcation and formally capturing requirements is
to be able to demonstrate, with conﬁdence, evidence of implementation deployed on
actual system meets the intent. We will be specifying the intent of the AFS Function
and the associated requirements for triggering recovery actions during contingency
events in the Constrained Language Enhanced Approach to Requirements (CLEAR)
notation. The formalized requirements are analyzed for consistency, completeness
and other generic properties to ensure latent defects do not enter during require-
ments writing phase that can subsequently manifest in implementation where it can
be trickier to diagnose. From requirements, we use Text2Test to automate genera-
tion of test cases and test oracles that are tightly traceable to these requirements.
The high-level requirements are also model-checked using the Sally translation of
the CLEAR requirements together with the node-level code contracts (speciﬁc prop-
erties) and architecture properties are also satisﬁed due to Radler speciﬁcation and

39

associated build.The node-level contracts are analyzed using the dynamic and static
code-analysis tools. The tools associated with such evidence evidence generation is
the subject matter for Section 5 and the AFS speciﬁc evidence that is generated
is also discussed in Section 7. In this section below we discuss the high level be-
havioral description of AFS Function that informs all the requirements discussed in
subsequent sections.

Broadly there are six AFS Monitor Events due Oﬀ-nominal situations trigger-
ing the appropriate recovery/response actions below. Note that AFS Prioritization
when multiple AFS events occur from high to low is: (6), (4), [(1), (2), (3)], (5)

1. Cylindrical Geofence breach due to Max Altitude check violation

• Potential contingency scenario: Weather/Wind causing trajectory to ei-
ther overshoot the fence or too close to it with respect to tolerance mar-
gins to handle navigation error.

• AFS recovery/response action: Try to drop to “Target Altitude” i.e.
(Max Altitude - margin) within 5 sec.
If Target Altitude is achieved,
continue with mission. If not achieved, then land and communicate land-
ing location to GCS and terminate mission.

2. Cylindrical Geofence breach due to Range check violation

• Potential contingency scenario: Weather/Wind causing trajectory to ei-
ther overshoot the fence or too close to it with respect to tolerance mar-
gins to handle navigation error.

• AFS recovery/response action: Try to drop to “Target Position” i.e.
(Max Range - margin) within 5 sec. If Target Position is achieved, con-
tinue with mission. If not achieved, then land and communicate landing
location to GCS and terminate mission.

3. Polygon Geofence breach due to Polygon Boundary check violation

• Potential contingency scenario: Weather/Wind causing trajectory to ei-
ther overshoot the fence or too close to it with respect to tolerance mar-
gins to handle navigation error.

• AFS recovery/response action: Try to drop to “Target Position” i.e.
(Polygon Boundary - margin) within 5 sec. If Target Position is achieved,
continue with mission. If not achieved, then land and communicate land-
ing location to GCS and terminate mission.

4. GPS Lock Loss: Loss of GPS signal for 3 seconds

40

• Potential contingency scenario: GPS Denied/Degraded Environment,
navigation drifts when coasting on pure IMU/Inertial without GPS ﬁxes.
• AFS recovery/response action: First loiter or hover at the current loca-
tion i..e waypoint or in transit between way points for 5 seconds. If GPS
recovered within 5 seconds then resume mission and proceed to next way-
point. If GPS not recovered within 5 seconds, then go to last completed
“Waypoint” with last known GPS Fix and using ONLY IMUs without
GPS ﬁxes (coasting drifts) in transition and then at that position land
and communicate landing location to GCS and terminate mission. Note
that last waypoint has better potential than rallypoint in this scenario for
GPS ﬁx possibility while GPS signal availability at rallypoint is unknown.

5. Ground Station Communication Loss: does not receive a heartbeat message

for a period of 3 seconds

• Potential contingency scenario: MAVLink loss of Heartbeat messages
from/to GCS, outside radio communication range, no cell towers etc.
• AFS recovery/response action: Go to a pre-conﬁgured Rally Point (Emer-
gency Hovering point) and “loiter” and Try to re-establish communication
connection for 5 seconds duration without loss. If still no communica-
tion reestablishment, then return to launch and terminate mission.
If
communication established, then complete the remaining mission; Incre-
ment strike counter to track communication disruptions history. If strike
counter ≥ 3 then return to launch as comms deemed unreliable and ter-
minate mission.

6. Insuﬃcient Battery

• Potential contingency scenario: Over consumption of energy due to dif-
ﬁcult vehicle maneuvers during the mission, battery drainage/leaks etc.
• AFS recovery/response action: If battery level ≤ TRT L and ≥ TLAN D
then return to launch and terminate mission. If battery level < TLAN D
then land immediately to the ground and communicate landing location
to GCS after you have landed and terminate mission.

41

Chapter 4

DesCert Evidence Ontology

In this chapter, we describe the DesCert ontology for the evidence that can repre-
sent all aspects of assurance as illustrated in Figure 2.1. The ontology allows the
speciﬁcation of the following types of evidence:

• Evidence of development activities and artifacts such as requirements, archi-

tecture, design, code.

• Evidence of veriﬁcation activities and artifacts such as requirements analysis,

test generations, architecture analysis, code analysis, etc.

• Semantic relationships of these evidence items to each other and to assurance

claims and arguments.

• Use of a tool to perform (automate) an activity, using input evidence artifacts

and producing output artifacts.

Our approach enables property-based assurance by providing classes and rich
semantics to specify properties supporting an assurance claim. Properties typically
hold over a development artifact such as requirement set, architecture, design, code
— i.e., the artifact satisﬁes the property.

Many additional concepts are needed (e.g., use of tools) for various aspects of
assurance that are not supported by speciﬁc classes in the base RACK ontology. This
didn’t allow us to capture the proper semantics needed to connect diﬀerent parts of
the evidence. Thus, in the SRI overlay, we added several classes (and relationships
with speciﬁc semantics) to represent the evidence. The following sections describe
each type of evidence and its relationships.

42

4.1 DesCert Enables Property-Based Assurance

Figure 2.1 provides our approach to assurance where tools are used to do veriﬁca-
tion on artifacts produced by the development process. Both testing based methods
(shown on left) and formal methods (shown on right) are used. To enable property-
based assurance, the formal methods are based on establishing properties of a par-
ticular development artifact (or a set of artifacts) and the proving them using a
tool.

Figure 4.1 shows the ﬂow of evidence to capture properties of architecture and
requirements and using tools to perform analysis, resulting in proofs that the prop-
erty holds.
In this ﬁgure, development or veriﬁcation activities are indicated by
grey boxes, development artifacts are denoted by blue boxes whereas veriﬁcation
artifacts are denoted by green shapes. A beige rhombus denotes the tool used to
perform an activity. (note: other aspects of system development and veriﬁcation,
e.g. code development and testing are not shown in this ﬁgure)

Figure 4.1: Property Speciﬁcation and Analysis for Architecture and Requirements

43

The system development starts with the system ConOps which are successively
developed into a sequence of artifacts including system requirements, system ar-
chitecture, software high-level requirements, software low-level requirements, and
source code. At each stage of this successive development, it is essential to assure
that a development artifact satisﬁes certain properties to meet the following types
of assurance objectives:

• The artifact complies with a parent artifact from which it is derived/reﬁned.
E.g.: software high-level requirements comply with system requirements and
system architecture.

• The artifact mitigates certain speciﬁc hazards. E.g., speed never exceeds more
than 120 miles/hr, copter doesn’t run out of battery power in air (it would
fall to ground and cause hazard otherwise).

• The artifact’s speciﬁcation doesn’t exhibit any abnormal behavior that can
cause a hazard. E.g.: source code doesn’t contain any null-reference exception.

• The artifact’s speciﬁcation satisﬁes certain properties that support generic
assurance claims/arguments. E.g.: communication messages are delivered in
order, requirements are consistent with each other.

To this end, we have deﬁned the ontology for speciﬁcation and analysis of prop-
erties, giving a ﬁrst-class status to properties and their relationships, as described
below.

Generic and Speciﬁc Properties. We classify properties into two broad cate-
gories: Generic Properties and Speciﬁc Properties:

• Generic Property: A generic property is a declaration that an artifact (scope of
the property) must satisfy some general desired characteristics related to veri-
ﬁcation objectives, or must exhibit absence of certain generic defects that can
cause hazards. Generic properties are established for the type of development
artifact (e.g., requirements, architecture, design, code) and are automatically
applied to that particular type of artifact regardless of the application. Fig-
ure 4.1 provides examples of generic properties for architecture and require-
ments. Other examples: code doesn’t exhibit numeric overﬂow, code doesn’t
exhibit null-reference-pointer exceptions, etc.

• Speciﬁc Property: A speciﬁc property is, by deﬁnition, application speciﬁc. It
declares that an artifact (scope of the property) must satisfy certain application-
speciﬁc behaviors and must not violate certain application-speciﬁc constraints

44

to prevent hazards. Examples: speed never exceeds more than 120 miles/hr,
thermostat always turns heat on when temperature is below 50 degrees F. Fig-
ure 4.2 shows the evidence ﬂow for the speciﬁcation and checking of speciﬁc
properties of requirements.

As we have stated earlier, both generic and speciﬁc properties must be veriﬁed
at each level of the development artifacts in order to meet diﬀerent parts of the set
of all assurance objectives. The type and technique of analysis used for each of these
properties as well as the assurance objective they relate to are signiﬁcantly diﬀerent.
Figure 4.3 shows the ontology schema for properties in UML notation, that de-
rives from base W3C PROV schema described in section 4.2. The Generic Property
class has a propertyScope relationship to an ENTITY (e.g., a requirement set, archi-
tecture, code) over which the property must hold (note: Speciﬁc Property inherits
all relationships and attributes of Generic Property). An ANALYSIS activity uses
a property to try to prove the property(against the entity in its scope). A property
can mitigate a potential hazard (via mitigates relationship), satisfy a particular ver-
iﬁcation objective, and/or have a basis in a higher-level development artifacts from
which the property is inferred. For example, a property to be veriﬁed on code could
be inferred from software high-level requirements.

4.2 DesCert Ontology Description

This section provides a description of the salient aspects of DesCert Ontology. The
DesCert ontology is based on the ontology classes in RACK (Rapid Assurance Cu-
ration Kit) database3 being used in the ARCOS program. RACK in turn derives
from the core provenance model PROV deﬁned by W3C. Figure 4.4 depicts the core
structures in PROV. An Entity captures a thing in the world (in a particular state)
— e.g., a particular version of a development or veriﬁcation artifact. The entity was
derived from some other entity, and was generated by an Activity that used other
entities. An Agent (e.g. a person or tool) was associated with the activity, and the
entity that was generated by the activity was attributed to that agent.

4.2.1 Ontology for Checking Speciﬁc Properties against a Model

of Requirements

As mentioned in section 4.1, properties are central to the DesCert evidence ﬂow;
Figure 4.3 depicts the basic concept of Generic and Speciﬁc Properties. Using these
basic concepts, Figure 4.2 shows the evidence ﬂow for the speciﬁcation and checking

3GE RACK: https://github.com/ge-high-assurance/RACK

45

of speciﬁc properties of requirements using the Sally tool. The ontology schema
for this usage is shown in Figure 4.5.
In the upper left quadrant of this ﬁgure
is the SallyTransitionSystemModel, which is generated by another activity (shown
fully in Figure 4.6. The Sally model is completely based upon the RequirementSet,
as denoted by the wasDerivedFrom relationship.Sally model uses the SallyNotation.
SallyModelChecking activity uses the Sally model and a SpeciﬁcProperty to attempt
to prove that the property holds on the Sally model, and by extension, on the
RequirementSet. The results of the this are in ANALYSIS OUTPUT.

Figure 4.6 shows the ontology for the auto generation of the SallyTransitionSys-
temModel from a RequirementSet. At the center of this ﬁgure is the activity that
invokes the Text2Test tool and pass it parameters that contain the name of the
RequirementSet, execution period, and any requirements and dictionary ﬁles ref-
erenced by the RequirementSet. This produces that SallyTransitionSystemModel
that traces to the RequirementSet via the wasDerivedFrom relationship. The Sal-
lyTransitionSystemModel is then used for checking SpeciﬁcProperties against it as
shown in Figures 4.2 and 4.5.

4.2.2 Ontology for Checking Generic Properties of Requirements

Figure 4.1 depicts the checking of generic properties of requirements and the evi-
dence ﬂow. Figure 4.7 shows the ontology for this evidence. The Text2Test tool is
invoked by the RequirementAnalysis activity to analyze a Requirementset against
several predeﬁned ClearGenericProperties. The requirements contained in the Re-
quirementset are expressed in the ClearNotation which is supported by userGuide
and semantics documents. The ClearGenericProperties trace to satisfy parts of DO-
178C objectives. A high-level view of these properties is shown in Figure 4.1; details
of the properties are described in Section 5.1.3.

4.2.3 Ontology for Test Generation from Requirements

Figure 4.8 depicts the tool usage and evidence ﬂow for generation of tests from
software high-level requirements (HLR) and the execution of those tests. Software
HLR for each software component are ﬁrst developed using system requirements
and architecture as inputs; the architecture provides an embedding context of the
component within the system. The Text2Test tool is used for the generation of Test
Oracles and Tests from the HLR.

Figure 4.9 depicts the ontology for generations of tests from software high-level
requirements. Test Oracles and TESTs are generated by this activity. A Test Oracle
traces to a requirement (and speciﬁc operator within that requirement) and is based
upon the CLEAR Testing Theory described in more detail in Section 5.1.5.1.

46

s
t
n
e
m
e
r
i
u
q
e
R

f
o

s
e
i
t
r
e
p
o
r
P
c
ﬁ
i
c
e
p
S

f
o

g
n
i
k
c
e
h
C
d
n
a

n
o
i
t
a
c
ﬁ
i
c
e
p
S

:
2
.
4

e
r
u
g
i
F

47

Figure 4.3: Ontology Schema for Properties

Figure 4.4: The Core Structures in W3C PROV

48

s
t
n
e
m
e
r
i
u
q
e
R

f
o

l
e
d
o
M
y
l
l
a
S

e
h
t

t
s
n
i
a
g
a

s
e
i
t
r
e
p
o
r
P
g
n
i
k
c
e
h
C
r
o
f

y
g
o
l
o
t
n
O

:
5
.
4

e
r
u
g
i
F

49

Figure 4.6: Ontology for Generation of Sally Model from Requirements

Figure 4.7: Ontology for Checking Generic Properties of Requirements

50

s
t
n
e
m
e
r
i
u
q
e
R
m
o
r
f

n
o
i
t
a
r
e
n
e
G

t
s
e
T
r
o
f

w
o
l
F

e
c
n
e
d
i
v
E

:
8
.
4

e
r
u
g
i
F

51

Figure 4.9: Ontology for Test Generation from Requirements

52

Chapter 5

Tools for Evidence Generation

We describe the assurance-driven development tools used in the DesCert workﬂow.
These include tools for requirements capture and analysis, model checking, test
generation, software architecture, and code analysis.

5.1 Notation and Tools for Requirements Speciﬁcation,

Analysis, and Test Generation

Figure 5.1 shows the high-level overview of requirement speciﬁcation, the types of
requirements analysis that and the respective evidence generated.

Figure 5.1: Requirements Analysis Evidence Generation Overview

53

In essence, specifying requirements in the CLEAR notation allows us to use the
Text2Test tool to automatically perform the following analysis and generate related
evidences for assurance:

Formal Analysis : The requirements are semantically analysed for consistency,
completeness and non-ambiguity using formal solvers such as SMT at the
backend. The results of the formal analysis are automatically captured in a
tabular, easy-to-understand web page format.

Test Vectors : The tool automatically generates requirements-based test vectors
in a Comma-separated textual ﬁle format. With the help of a test harness,
these test cases can be used to verify and assure that the implementation
indeed meets the requirements.

Test Reports : Along with the test cases, the Text2Test also automatically gen-
erates various reports that quantiﬁes the veriﬁability of the requirements as
well as the provides a detailed explanation of which part of the requirement
each test case checks. This serves as the traceability between the requirement
and the test cases.

Sally Model : From the functional requirement speciﬁcations the Text2Test tool
automatically generates Sally model, that can be used by the Sally model
checker to verify speciﬁc properties (such as safety properties).

5.1.1 CLEAR: Constrained Language Enhanced Approach to Re-

quirements

Typically, software requirements are written purely as natural language, which is
expressive and, when written well, understandable without learning a speciﬁc no-
tation. However, natural language is also subject to interpretation and ambiguity.
Sometimes a formal notation is used to capture software requirements, which elim-
inates ambiguity and opens up possibilities for software analysis, but the syntax
required is generally opaque to the untrained eye. In addition, formal software re-
quirements can be hard to relate to the real world which is often much messier than
the formal realm can easily capture.

CLEAR’s approach attempts to combine the best of both worlds by deﬁning a
formal language that can generally be read as English, but in fact conforms to a tra-
ditional language grammar [BHM+21]. A set of CLEAR requirements can generally
be read and understood without any experience with the notation. The phrases and
constructs available in CLEAR have been carefully considered to be as unambiguous
as possible, which acts as a strictly-enforced style guide on requirements. Because it

54

Figure 5.2: An overview of the design principles of CLEAR.

is a formal language, it can be parsed and analyzed without guessing at the intent
or meaning of the requirements.

Single expressions of intent. For example, consider two requirements for a
microwave:

Each requirement captures a single speciﬁc intent for the behavior of the mi-
crowave: when cooking, the microwave should be heating up the food. When the
door is open, the magnetron must not be active. Both are reasonable expectations,
but when considered together they are contradictory. If the door is opened while
cooking, one requirement says to continue cooking while the other says to stop. In
a large set of requirements, such conﬂicting requirements may be far apart in the

55

document, making it diﬃcult to spot the inconsistency. Text2Test performs this
analysis and produces an error.

The ability to capture individual intents and consider them both individually and
in combination is a diﬀerent approach than writing a program and allows for thinking
about the software in a diﬀerent way than programming. Much like a developer
writing a test case may think of things that she did not consider when writing
the implementation, deﬁning the behavior of a program in individual requirement
statements is a diﬀerent thought process than writing code. By deﬁnition, a program
operates on the complete input space; that is, for any possible input the code will
respond to it in one way or another, even if that particular input was not considered
by the author of the code. Requirements, on the other hand, just specify intended
behavior. If there is a gap in the input space, it will become apparent that this
behavior needs to be deﬁned. The following Section 5.1.3 describes the analyses that
are performed on CLEAR requirements for ﬁnd inconsistencies (conﬂicts) among
requirements and gaps.

Text2Test is the name of the tool which takes CLEAR ﬁles as input and parses,
processes, and analyzes the requirements, producing reports and test cases. Each
requirement is transformed into a data ﬂow diagram. If multiple requirements deﬁne
values for a particular output, these results are combined and checked to ensure
that no contradictions exist (i.e., two requirements that prescribe diﬀerent outputs
under the same conditions). Text2Test can also analyze the conditions speciﬁed
by the requirements for a particular output and produce a warning if there are
inputs that have no applicable requirement. Text2Test is described in more detail
in Section 5.1.2.

CLEAR Notation Features. CLEAR provides requirements constructs to spec-
ify a variety of behaviors in a precise manner, while also providing a way to build
abstractions and factory the requirements space for complex behaviors. The follow-
ing are the salient features of the notation:

• Each requirement is a declarative statement that can be independently re-
viewed and tested; requirements are additive — adding requirements com-
pletes the behaviors required

• CLEAR allows speciﬁcation of the following aspects of behaviors:

– State-based, event-triggered, time-triggered behaviors and combinations

thereof.

– Algorithmic aspects using combination of mathematical, relational, and
Boolean expressions, sets/selections, interval arithmetic, interpolation ta-
bles.

56

– CLEAR includes a large library of math functions including numeric ma-

nipulation, trigonometric, exponential, ﬁlters, etc.

• Constructs for creating abstractions and for factoring of complex behaviors:

– Tabular format for generalized truth tables, precedence tables (as alter-

native to while requirements and clauses) and interpolation tables

– Creating common deﬁnitions of speciﬁc behaviors or input conditions

referenced from several requirements

– Creating complex types of objects and conditions/behaviors associated

with them

– Creating intermediate abstractions (states, variables) to create a frame-

work for the speciﬁcation of complex behaviors

• Support for ontic concepts and types:

– Basic ontic concepts of real-world time intervals, events, sensor input

validity speciﬁcation, and units.

– Higher-level concepts such as XYZ Vectors of position, velocity, vector

diﬀerence, concept of moving average of sensor values, etc.

– Future extensions: Ontic type system around basic physical (and cyber)
concepts such as position, velocity, time, temperature, pressure, angles
and attributes of units and relationships applied to them. Users will
create application-speciﬁc subtypes.

CLEAR Semantics. The CLEAR semantics provide a number of useful concepts
and structures useful for writing software requirements:

• Objects have (discrete or continuous) time-varying values

• Conditions are predicates over the values of objects at a given time

• Events are changes in conditions

• Actors are systems or components

• Functions are computed on object values at a given time or over a time interval

• Responses are functional updates to values of internal or output objects of an

actor

57

• Responses can be condition-based, event-triggered, time-triggered (or combi-

nation): CLEAR is agnostic about the Model of Computation (MoC)

• Functions and structural aspects

– Algorithmic aspects using combination of mathematical, relational, and
Boolean expressions, sets/selections, interval arithmetic, generalized truth
tables, interpolation tables.

∗ CLEAR includes a large library of math functions (including tran-

scendentals, ﬁlters, integrators)

– Type system with support for ontic types (more future work)

– Factoring of complex behaviors into multiple deﬁnitions/requirements

CLEAR: Structure of Requirements. CLEAR requirements can take one of
a few general forms which are fully described in Figure 5.3. If the system must do
something unconditionally, a “shall” statement can simply specify the output and
its value. Responses to events, such as an input crossing a threshold or changing
to a particular value, use the word “when” followed by the condition and then the
response to that event. Variables can be marked as state variables, and requirements
that apply in a particular state can be speciﬁed using a “while” statement. If the
software can be conﬁgured with features enabled or disabled, the word “where” is
used to specify that a requirement only applies when a particular feature is enabled.
Exceptional or abnormal conditions can be speciﬁed with the word “if” instead of
“when”, overriding other requirements even if they would normally apply. By giving
“if” statements priority, requirement authors can write the majority of requirements
to deal with nominal cases without having to specify a lack of error in every single
requirement, and only need to address the exceptional cases in “if” statements.
Finally, many of these features can be composed together in various conﬁgurations.

5.1.2 Text2Test Tool Overview

Text2Test is a powerful tool capable of automatically generating evidence artifacts
for CLEAR requirements in textual form. Figure 5.4 shows the architecture of
Text2Test tool. It takes the CLEAR requirement set from front-end requirement
editor, as well as metadata such as variable data type, units, and other ontic type
speciﬁcations in separate dictionary ﬁles, as inputs. Then it creates a minimum-scale
but semantic-equivalent internal block diagram model for the requirement set called
Semantic Synthesis Model. This internal model not only provides a visualization,
but also is suitable for the model-based analysis including test generation, static
analysis (e.g, range propagation), and formal veriﬁcation (against generic properties

58

Figure 5.3: Requirement Types/Structure in CLEAR

as listed in subsection 5.1.3). The internal model also serves as a medium which can
be translated to models for other veriﬁcation tools.

5.1.2.1 From RequirementSet to Text2Test internal Semantic Synthesis

Model

Data-Flow Semantic Graph creation. A data-ﬂow semantic graph (called
”raw model”) is ﬁrst created from the requirement, capturing the data ﬂow and
semantics of the behavior operators used in requirement clauses and subexpressions.
The raw model preserves the semantics of each and every individual requirement in

59

l
o
o
T
t
s
e
T
2
t
x
e
T
e
h
t

f
o

e
r
u
t
c
e
t
i
h
c
r
A

:
4
.
5

e
r
u
g
i
F

60

the requirement set, but it is not fully functional as a whole in mainly two aspects.
Firstly, a switch block may have, at one of its data input ports, connection to the
Invalid block that cannot be executed or propagated through. This is due to the
fact that the switch block is created from a selection requirement (for example, a
“when..., then...” requirement) incomplete by itself. Secondly, if a feedback path is
formed, it often misses a unit delay implied by the keyword “transition to” without
an explicit time shifting keyword “previous”, which is needed for unit delay block
creation in the raw model. Other than the system-level semantics imperfection, the
raw model often contains redundant logical blocks, and lacks non-primitive blocks
(state transition for example). These all make the raw model less user-friendly for
reading and examining.

It is not hard to see that, the common root cause of these “imperfection” is
that the incompleteness of individual requirement gets carried to the raw model
whose creation process does not possess system perspective. To address these, a
system-level aggregation will be performed on the raw model through a block merge
process. Block merge is based on graph search and pattern recognition, aiming to
fuse low level primitive blocks into blocks of richer semantics, ﬁlling semantic gaps
as well as eliminating redundancy. The next subsection elaborates the merge of a
set of blocks exhibiting state transition behavior, resulting in a fully functional state
transition substructure of much more compact form.

State transition block merge to create Semantic Synthesis Model. A
typical state transition behavior consists of state initialization, and a state transition
function that determines the current state value based on the previous state value
and/or external transition triggering signals (also called non-state trigger). In the
CLEAR requirement set, the state transition behavior of one state variable is often
distributed in multiple individual requirements, each of which contributes a partial
statement of either state initialization or one transition action as the example shown
in Figure 5.5. In a typical state transition action requirement, the “while” clause is to
specify the previous (source) state value and the “when” clause is to specify the non-
state triggering condition, followed by the clause that sets the current (destination)
state value.

The left hand side of Figure 5.6 shows the raw model subgraph representing the
state transition behavior in Figure 5.5. In the raw model creation process, for each
requirement, primitive blocks are created, explicitly mapping to CLEAR functional
and logical keywords (e.g., switch block maps to keyword“While/When”, not block
maps to logical operator “not”), then proper connection is added, forming a feedback
loop path. A Combiner block is created as a routing hub node aggregating all state
value set and get for the common state variable. The initialization requirement is

61

Figure 5.5: Requirement set example for a state variable SOME STATE.

simply converted to a constant block feeding to the Combiner.

Figure 5.6: State transition subgraph before and after merge.

The state transition block merge starts from identifying the Combiner block
in the raw model and its associated feedback paths. Then the Combiner block is
replaced by a StateTransitionBlock (STB ) block whose functionality is deﬁned by
an inherent transition matrix (initialized as an empty matrix) as shown in Table 5.1.
Next, each feedback path is analyzed to identify the associated non-state trigger and
the source state value(s). Both of them are then recorded into the state transition
matrix as row elements (for semantic richness) so that the entire feedback path is
no longer explicitly needed thus removed from the subgraph (for simplicity), while
the non-state trigger is reconnected directly to the STB block input. Requirement
ID is also recorded as row info (for traceability). The Invalid block is removed (for
execution), since the transition matrix is presumptive to be input-complete if the
requirement set is input-complete. For assurance, the input completeness will be
formally veriﬁed as a generic property in a later stage after merge. Lastly, a simple
feedback path of unit delay outside the STB is added (for temporal correctness),
providing the state value memory for the merged state transition subgraph. Note

62

that, unit delay is initialized by the initial state value, therefore, the initialization
path in the raw model is also removed (for simplicity), rendering the STB itself as
a memoryless non-timedependent block.

State transition matrix

Initialization

Transition
actions

non-state triggers
trigger 1
...
trigger n

s0

source
{s1}
...
{s2, s3, s4}

destination
s2
...
s0

requirement ID
“Initial Condition”

“action 1”
...
“action n”

Table 5.1: A complete state transition matrix for SOME STATE

The current CLEAR language supports a wide range of variations of state tran-
sition behavior speciﬁcation other than the typical form in Figure 5.5, consequently
corresponding to variations of subgraph structures in the raw model. For instances,
1) a state transition system can have a reset trigger that instantly overrides all
other transition triggers once activated, 2) diﬀerent triggers are associated with
the same source state value(s), causing branching on a feedback path and/or in-
tertwining among feedback paths, or 3) the current state value is determined by
the non-trivial history of the state values instead of one-step memory of the previ-
ous state value, resulting in a time-dependent block such as timer in the feedback
path in the raw model. By analyzing the structural features of the raw model sub-
graph (e.g., feedback paths, branching nodes, locations of key functional blocks,
etc.), Text2Test block merge is able to recognize those advanced state transition
behaviors and achieve semantics-preserving and semantics-completing translation
to the merged model. The merged model is the ﬁnal stage semantically correct and
complete model interpretation of the requirement set. It is the model that all the
downstream formal analysis and test generation within Test2Test is based on. It
also serves as the generic model from which semantically equivalent models for other
tools (Sally for example) are obtained through proper translation. The sections be-
low use the term “internal model” to denote the merged semantic synthesis model
unless speciﬁed otherwise.

The following capabilities are implemented in Text2Test tool using the internal

model; these are described in subsequent subsections:

Generic property checking and defect report generation Text2Test utilizes
the SMT-based property checking capabilities implemented on the internal model
obtained above. Text2Test checks against a set of system generic properties as
listed in subsection 5.1.3, to detect possible fundamental defect(s) of the requirement
set. Model/Requirement defects (with defect information such as defect type, root

63

requirement IDs, variables and counterexample, etc.) are recorded in a .xml ﬁle for
manual review purposes. These model checkings also serve the “sanity check” of
the internal model, only defect-free models proceed to be converted to other tool
models (e.g., Sally model in the following subsection) for further model checking
against speciﬁc properties.

Translation to Sally model The Text2Test internal model is a correct and
Its block diagram structure with well-
complete model for the requirement set.
deﬁned block functionalities and clear connection relation make it easy to be further
translated to Sally model as elaborated in subsection 5.1.4.

Test generation As a critical and legacy tool capability, test generation is elab-
orated in subsection 5.1.5.

5.1.3 Checking Generic Properties of Requirements

Section 4.1 introduces the notion of properties, that we intend to analyze, into two
broad categories: Generic Properties and Speciﬁc Properties.

In the context of requirement speciﬁcation, generic properties are those that
are fundamental to any good requirements speciﬁcation, irrespective of the system
under consideration, such as consistency, completeness, veriﬁability, non-ambiguity,
etc. We analyze the requirements for the following types of properties:

• Consistency: that ensures that the requirements are free of

– Conﬂicts across multiple requirements such as two or more requirements
specify diﬀerent values for the same output variable under overlapping
input conditions. For example, the following requirements of a ther-
mostat system are inconsistent since they specify conﬂicting values for
Display Indicator when the both their antecedents are true at the same
time.
REQ 1: While HVAC Mode is ‘Heat Oﬀ ’, the Thermostat shall set Dis-
play Indicator to ‘White’.
REQ 2: While HVAC SetUp is true, the Thermostat shall set Display Indicator
to ‘Blue’.

– Cycles in requirement data ﬂow, without state transition

• Accuracy: that assures that the requirements are accurately speciﬁed with

speciﬁc logical and mathematical outcomes.

64

• Non-Ambiguity: that assures that the requirements do not use combinations
of natural-language phrases or mathematical expression that can interpreted
ambiguously.

• Completeness (“internal”) that identiﬁes gaps in requirements wrt

– Input Gaps: Certain combinations of input conditions missing in re-
quirement set. For example, the following requirement is considered
input space incomplete if there are no other requirements that specify
behaviours when HVAC Mode is ‘Heat ON’.
REQ: While HVAC Mode is ‘Heat Oﬀ ’, the Thermostat shall set Dis-
play Indicator to ‘White’.

– Output Gaps: Certain output values not produced by any requirement
in the requirement set. For example, the above requirement is considered
output space incomplete if the value of Display Indicator is deﬁned to
be an enumeration of several colors, but there are no requirements to set
values of Display Indicator other than ‘White’.

• Requirements Veriﬁability/Testability that ensures if there is any

– state in a requirement that is not reachable

– condition in a requirement that is not achievable

• Advanced properties based upon Ontic type information helps ensures:

– Simple ontic-type violations – e.g., adding altitude to runway length

– Margins (values, time) used in decisions are not adequate based upon
the real-world nature of inputs; e.g., improper time-debouncing or hys-
teresis of sensor input values (Margins are derived based on constraints
associated with Ontic type for the sensor input)

– Mode Thrashing is an advanced analysis based on margins, such as the
system switching back-and-forth (metastable) between two states rapidly
(general case: cycle through multiple states)

Section 7.3.1 provide instances of generic properties that were checked on the

AFS requirements.

5.1.4 Sally Model Generation and Speciﬁc Property Veriﬁcation

Sally is a model checker for inﬁnite state systems described as transition systems.
Sally has both bounded model checking (BMC) engine and k-induction (kind) engine

65

for the veriﬁcation of transition systems. That is to say, integrating Sally with
Text2Test provides advanced capability of speciﬁc property veriﬁcation other than
the generic ones for the requirement set, given that the requirement set can be
modeled as a transition system. In our tool chain, the integration is achieved by
translating Text2Test internal model to Sally model. This subsection introduces the
model translation process, as well as the enhanced capability of speciﬁc property
veriﬁcation enabled by the tools integration and the extension.

5.1.4.1 From Text2Test internal Semantic Synthesis Model to Sally model

Model translation Sally model is a script model with inputs, states, and the
state transitions. On the other hand, Text2Test internal model is a functional block
diagram model which may or may not possess intended state transition behavior.
But because there exists underlying system frequency for the internal model, it
essentially can be remodeled as a transition system that responds to instantaneous
In this translation process, blocks/structures of the internal model are
changes.
converted to the script segments (declaration, initialization, and state transition) in
Sally model, following the summarized rules in Table 5.2. Because Sally script is
based on the SMT lib 2.0 format, the translation order of the blocks/structures is
irrelevant.

Text2Test internal model responds to system input(s) instantaneous at the same
time step, while in Sally model system input(s) are used to update system state(s) in
the next time step. Therefore to eliminate the one-step response gap at the system
inputs interface, a system input variable and an auxiliary input state variable are
created in pair in Sally model , where the state is one step lag the input. Thus,
the auxiliary input state(s) update simultaneously with all the other system states,
all states as a whole exhibiting equivalent behavior of the corresponding Text2Test
internal model.

5.1.4.2 Checking speciﬁc properties against the Sally model

Figure 5.7 shows the evidence ﬂow for checking a Speciﬁc Property against a Sally
model (adapted from Figure 4.2).
In a nutshell, the Sally model checker helps
rigorously ensure that the speciﬁc properties (typically speciﬁed from system re-
quirements to mitigate hazards) are satisﬁed by model (that is derived from the
high-level functional requirements).

Specifying properties with system inputs The generic Sally query has one
inconvenience on property speciﬁcation with system inputs.
In the query .mcmt
ﬁle, an input condition cannot be directly encoded as part of the query formula,

66

Case I: A system input block

Sally

1) System input declaration: A system input variable.
2) State declaration: An auxiliary input state variable.

counterparts: 3) State initialization: None.

Note:

4) State transition: Next step value of the input state equals to input.
All states update simultaneously lagging by one step of system input(s).

Case II: An STB block and the associated unit delay and output block

Sally

1) State declaration: A Sally state variable.

counterparts: 2) State initialization: Same value as the unit delay’s initial value.

Note:

3) State transitions: Transition matrix in Sally language.
This structure as a whole corresponds to one single Sally state.

Case III: A time-dependent block

Sally

1) State declaration: A Sally state variable.
counterparts: 2) State initialization: Same value as the block’s initial value.

Note:

3) State transitions: Transfer function in Sally language.
Case III excludes the unit delay block instances from Case II category.

Case IV: A non-time-dependent block

Sally
counterparts:

Note:

1) State declaration: A Sally state variable.
2) State initialization: None.
3) State transitions: Block’s math/logical function in Sally language.
A memoryless state has no initialization.

Table 5.2: Text2Test internal model to Sally model translation.

Figure 5.7: Checking Speciﬁc Properties of Requirements using Sally

67

like the way that most other model checkers can. Although Sally tool provides
an assumption annex for the input conditions as a supplement to the query, so
that the input conditions are treated as the extra system assumptions. But it is
verbose and more importantly still does not address the issue that some property
may have clause involving the relationship between input and state (something like
“State s is always greater than input x.”). Nevertheless, in our Text2Test Sally
integration, each system input has a corresponding auxiliary input state in the Sally
model created during model translation (as shown in Table 5.2 Case I). Therefore,
it is strongly recommended to use the input state variable, rather than the input
variable, in the property query formula whenever possible to be more ﬂexible in
expressiveness.

5.1.4.3 Examples of Properties

Mode-thrashing Mode-thrashing is a hazardous phenomenon that often occurs
in cases involving continuous value triggered mode switch. For example in the
thermostat example in Section 2.5 Figure 2.4, if the maximum sensing ﬂuctuation
(denoted by ﬂucmax) of the thermometer sensed temperature (denoted by tsensed)
is larger than the thermostat threshold margin (diﬀerence of ON/OFF temperature
threshold values), then thermostat may send frequently oscillating ON/OFF control
signals (denoted by ctrl) to the heater when the actual room temperature (denoted
by troom) is an unchanging value in-between or near the thermostat threshold values.
In the extreme case where ﬂucmax is as small as exact half of the threshold margin,
mode-thrashing could still occur when troom happens to stay at the midpoint value of
two threshold values. Absence of potential mode-thrashing has an LTL formulation:

(troom − ﬂucmax ≤ tsensed ≤ troom + ﬂucmax) ⇒ ¬(ctrl = ON X ctrl = OFF),

for all unchanging troom, where X is the temporal operator “next” in LTL language.
The encoding of this formula in Sally requires temporal extension to Sally generic
query, which is elaborated in the following subsection 5.1.4.4. The reason that here
ﬂucmax is not naively compared with the thermostat threshold margin (or its half) is
that, in a more general case, the continuous condition value and its ﬂuctuation may
go through some non-trivial transform before becoming triggering signal of the mode
switch, so directly checking if undesired mode switch can occur is the only universal
detection method. Detecting potential mode-thrashing is non-trivial but also not
too complex to be encoded as a generic property of requirement set in Text2Test.
Therefore, it is performed on both Text2Test internal model and the corresponding
Sally model, the results are compared to showcase the semantic equivalence between
two models.

68

5.1.4.4 Temporal extension to Sally query

Motivation Generic Sally query does not allow basic temporal operators such as
“next.” and “prev.”, although “next.” is used in the Sally model script to denote
the next time step. Queries are checked at all time step without an explicit temporal
operator. This is to say, one cannot write a generic query formula about a state
s in speciﬁc future or past time step(s). This is due to implementation limitation
rather than the power of reasoning engines. A workaround solution is to create
time-shifted auxiliary state variables (for instances, prev s, next s), and add their
proper declarations and state transitions into the Sally model, so that they can be
used in the query. It is non-automatic, and it is tedious and error-prone in the case
of specifying a property across multiple time steps that requires one auxiliary state
variable for each related state at each time step. To enrich temporal logic semantics
and take most advantage of the reasoning power, temporal extension to Sally query
is developed as part of the tools integration.

Approach Two basic temporal operators X and F, denoting “next” and “eventu-
ally” respectively, and time step syntax sugar are introduced to augment the query
language. Let t and t(cid:48)
>t denote the beginning and end time of the temporal domain,
and generic pred be an SMT Lib 2.0 format Boolean predicate of the state vari-
ables from the generic Sally model, we have the following general form of temporal
extended predicates below:

• X(t, t(cid:48)][generic pred ]— meaning that “generic pred holds for all time steps in

between t (not included) to t(cid:48) (included).”

• F(t, t(cid:48)][generic pred ]— meaning that “generic pred holds for any time step in

between t (not included) to t(cid:48) (included).”

Note that both t and t(cid:48) are integer multiple of the system period. They can
be negative, 0, or positive numbers, corresponding to past, current, or future time
respectively. A temporal extended predicate can be embedded in a larger query
formula the same way a generic predicate does. As a simple example, the property
“In system sys, when state p is true, state q shall be true for the next 2 seconds.”
can be formulated as:

(query sys (⇒ p X[0, 2][q])).

(5.1)

Property translation and Sally model augmentation A temporal extended
property is ﬁrstly translated into an equivalent generic Sally query before Sally tool

69

takes it as input. The translation is a straightforward process of temporal unfolding
and (sometimes) shifting. Supposing system period is 1 second, Formula 5.1 is
unfolded to

(query sys (⇒ p (and q next q next2 q))),

(5.2)

where next q and next2 q are auxiliary state variables denoting 1 and 2 time steps
forward shifts of q respectively. Note the diﬀerence between the preﬁx “next ” in
the auxiliary state variable name and the temporal operator “next.”. In case that
the temporal operator is F instead of X, Formula 5.1 is unfolded to

(query sys (⇒ p (or q next q next2 q))).

Each of the newly created auxiliary state variables needs to be declared and given
a state transition in the Sally model. The state transition is given by the form of
assigning the next time step state value. While an auxiliary state variable of the
past time step can be easily assigned as “(= next.prev s state.s)”, it is not easy
to assign a future state variable without introducing more auxiliary variables than
what are needed in the property. Naturally, entire Formula 5.2 can be shifted 2 time
steps towards past, resulting in the plain Sally query in the generic form:

(query sys (⇒ prev2 p (and prev2 q prev q q))),

(5.3)

where prev q and prev2 q are auxiliary state variables denoting 1 and 2 time steps
backward shifts of q respectively.

Now, all state variables in Formula 5.3 are either on current or past time step.
Their declarations and state transitions can be added to the original Sally model
without introducing further more auxiliary state variables. The augmented Sally
model is thereby a property-speciﬁc Sally model, because the choice of auxiliary
state variables are property-speciﬁc. The entire process is done in an automatic
fashion. Lastly, Sally tool veriﬁes the property-speciﬁc Sally model against the
plain Sally query. The complete data ﬂow is summarized in Figure 5.8.

Figure 5.8: Temporal property translation and Sally model augmentation.

70

5.1.5 Test Generation from Requirements

Figure 5.4 provides an overview of the Text2Test tool. An important capability
provided by Text2Test is the auto-generation of tests from a set of requirements
[RBH16]. Figure 4.8 shows the ﬂow of evidence artifacts for test development
from software high-level-requirements (HLR). The test development, automated by
Text2Test, generates two artifacts:

1. Test Oracles: The test obligations for speciﬁc behavior operator instances used

in requirement clauses/subclauses across the requirement set.

2. Tests: Each test consists of a sequence test vectors containing input values
and expected output values of the component under test. A test traces to the
Test Oracles it satisﬁes.

As described in Section 5.1.2.1, the Text2Test tool creates an internal represen-
tation of the requirement set - the semantic synthesis model. The nodes in this
diagram are the behavioral operators instances that are derived from the clauses/-
subclauses of all requirements in the set. Behavioral operators include Boolean logic
operators, relational operators, mathematical operators and functions, time-based
operators, selection operators, event-based operators, and state-changing operators.
This forms the basis for generation of test oracles and tests. As part of the
Text2Test tool conﬁguration, there is a formal deﬁnition of test oracle criteria and
equivalence class deﬁnition of the required test obligation for each type of behavioral
operator. The CLEAR testing theory, described in the next subsection.

5.1.5.1 CLEAR Testing Theory

“Testing can only reveal the presence of errors, not their absence.” –
Dijkstra (and DO-178C)

Testing is inherently incomplete and cannot be formalized in logic. The chal-
lenge is to make testing more rigorous and bring some notion of “completeness.”
One way to accomplish this is to base testing on some reasonable applicable criteria.
The CLEAR Testing Theory uses the well-established guidance in DO-178C [Inc11]
to this end. DO-178C clearly establishes that tests must be based upon require-
ments and posits the criteria shown in Figure 5.9, and brings notions of rigor and
“completeness” within that framework.

The CLEAR Testing Theory consists of a set of arguments and derivations to
establish the claim that the Test Oracles and Tests, created for a given set of require-
ments in CLEAR notation, fully satisfy the “applicable criteria” for requirement-
based testing for those requirements. A second claim is that a Test Harness correctly

71

Figure 5.9: Testing Criteria in DO-178C

executes the Tests (and the implied test procedure) on the software component and
produces pass/fail results of each test. The following is the summary of claims of
CLEAR Testing Theory:

• Claim 1: The Test Oracles and Tests satisfy all applicable criteria (e.g.: equiv-
alence class / boundary value, time-related functions, state transitions) per
DO-178C sections 6.4.2.1 and 6.4.2.2 for the set of requirements in CLEAR
notation.

This claim is supported by the following subclaims:

Subclaim 1: A set of Test Oracle is created for each instance of an oper-
ator (behavioral sub-clause/subexpression) within a requirement in CLEAR

72

notation.

Subclaim 2: The set of Test Oracles for an operator satisﬁes all applicable
criteria (e.g.: equivalence class / boundary value, time-related functions, state
transitions) per DO-178C sections 6.4.2.1 and 6.4.2.2.

Subclaim 3: A Test is created for each Test Oracle by 1) backward propa-
gating the operator’s inputs to component under test inputs, using principles
of controllability, and 2) by forward propagating the operator’s output to an
observable output of the component using principles of observability.

• Claim 2: A Test Harness concretizes and correctly executes the Tests (and
its implied procedure) on the target software and produces pass/fail results of
each test case.

Figure 5.10: Example of Derivation of Test Oracles from a Requirement Set

Figure 5.10 shows examples of derivation of test oracles from a requirement set
using the Text2Test tool. As discussed previously in Section 5.1.2 and Figure 5.4,
semantic transformations are applied to requirements to create a semantic synthesis
model. The nodes in this model are the operators in the requirements (implied
by natural language subclauses and mathmatical/logical subexpressions). For each
operator, there is a set of test oracles, each oracle deﬁnes the equivalence class of
input and output values for that a particular behavior of that operator.

Figure 5.11 shows the test oracle deﬁnition for a switch operator which represents
the logic of a “while ... otherwise ...” requirement. The essential point to note here
that the equivalence class deﬁnition speciﬁes that the values at the two inputs of the
switch (x and y in the requirement) need to be diﬀerent so that one can ascertain

73

Figure 5.11: Deﬁnition of Test Oracles for Switch Operator

that the proper branch in the code was chosen. Such test will detect the type of
variable substitution error in the code shown in Figure 5.12.

Figure 5.12: Example of Code Error Caught by the Test Oracle of Switch Operator

5.2 Architecture Speciﬁcation and Analysis using Radler

The Radler Architecture Deﬁnition Language decomposes the design into a logical
architecture based on a pub/sub quasi-period model of computation. Radler nodes
execute periodically and communicate with other nodes over bounded latency chan-
nels. We are using the MAVROS capability to support a Radler architecture for the
ArduPilot. In particular, the ArduCopter Failsafe component will be implemented
as an independent Radler node running on a companion computer so that its failure
modes are independent from the base platform. The use of Radler also serves as a
step toward the Phase 2 challenge problem where we have to coordinate between
multiple components while ensuring security properties.

We have the deﬁned a Radler architecture for the ArduCopter with the AFS
module running on an independent companion computer. The AFS module uses
MAVROS as the transport layer to subscribe to messages from the ArduCopter
module, the Ground Control Station (GCS), and the Remote Control (RC). The

74

AFS module receives status updates from the ArduCopter Base module and is able
to change modes and set certain ﬂight parameters.
It is also able to annunciate
warnings to the GCS and RC Pilot.

We have enhanced Radler to integrate nodes that are implemented in Java us-
ing the Java Native Interface. We plan to use this capability to deﬁne capabilities
like logging and database access that leverage Java interfaces but are not critical
to the real-time responsiveness of the system. We have developed a tutorial (both
in the forms of a video and use case in Radler git repository) demonstrating the
Radler code generation and its execution on SITL (software in the loop) simulator
for the Arducopter AFS (advanced fail safe).
In the tutorial, the Radler archi-
tecture consists of AFS gateway, battery, altitude, and log nodes communicating
with Arducopter via MAVROS (ROS-based extendable communication node) on
the companion computer.

We constructed a SITL/MAVROS/Radler deployment in a virtual machine en-
vironment using Vagrant and provided a sequence to create a pre-built image for
the Boeing/TA4 Evaluation. We are currently evaluating Java-based runtime veri-
ﬁcation tools that we can use to monitor the behavior of the AFS module.

5.2.1 The Radler Model of Computation

A Model of Computation (MoC) speciﬁes the execution of individual nodes in a dis-
tributed system and their interaction through shared memory or message-passing
channels. Radler implements distributed systems within a publish/subscribe archi-
tecture with a quasi-periodic model of computation. The nodes repeatedly execute
a step function with a minimum and maximum bound on the period between two
successive execution. The nodes communicate through topic channels with an asso-
ciated message type. Each topic has exactly one publisher node, but can have zero
or more subscriber nodes. Each node speciﬁes a buﬀer size and a latency bound for
the mailbox associated with each of its subscription channels. On each execution
step, a node reads its input mailboxes, applies its step function to these inputs,
and then sends thes outputs to the respective mailboxes for the topics on which it
publishes.

There are several important theorems about RADL’s multi-rate, quasi-periodic

model of computation that have been proved in PVS[LS14]. These include:

1. Bounded processing latency for message: A message sent by publisher node
P at time t to subscriber node S on topic A with maximal latency L(A, S) is
processed by node S within time t + L(A, S) + max (S) unless it is superseded
by a subsequent message from P . The maximal delay occurs when a message
sent by P at time t is received by S at a time just after τS(i) and processed
by S at τS(i + 1) where τS(i + 1) − τS(i) = max (S).

75

2. No overtaking, with timing assumptions: If L(A, S) < min(P ), then messages
are received by S in the order sent by P since the i’th message from P will be
received by S before the i + 1’st message is sent.

3. Bounded consecutive message loss: Assuming a buﬀer size of one, if M is the
small integer such that M.min(P ) > L(A, S) + max (S), then at least one of
M consecutive messages is read by the subscriber (assuming no overtaking).
The fastest rate at which message can be sent is 1/min(P ), and the maximum
number of messages that can arrive in the interval from τS(i) to τS(i + 1) are
those sent in the interval from τS(i) − L(A, S) to τS(i + 1).

4. Bounded queue length to eliminate message loss: Under the same assumptions
as the previous bullet, with a queue length of Q, at most M − Q consecutive
messages are lost.

5. Bounded age MA(m) of a message input m used by subscriber S in a step
function: MA(m) < L(A, S) + max (P ) (without overtaking). The quantity
L(A, S)+max (P ) is the biggest gap between rstream(P )(i) and rstream(P )(i+
1).

Bounds can also be computed for the scenario where overtaking is possible [LS14].

5.2.2 The Radler Architecture Deﬁnition Language

A RADL description ﬁle is a text ﬁle, preferably encoded in utf8, with extension
“.radl”. Such a ﬁle is called in short a radl ﬁle. A radl ﬁle deﬁnes a module whose
name is the ﬁle name. A ﬁle MODULE.radl deﬁnes an implicit scoping region for its
content whose name is MODULE.

Meta Syntax Rules A module is a set of value declarations. A declaration may
be an alias, used to declare a value equal to another one but with a new name. The
name of a value may be omitted, note that it’ll prevent the user to reference this
value. The type of a value may also be omitted, note that if the type is ambiguous,
the inference will choose one. When deﬁning a class ﬁeld, one may declare a new
value or refer to another value by its identiﬁer.

Grammar A RADL speciﬁcation is a set of typed value deﬁnitions following this
simple grammar:

76

module := decl*
decl := alias | NAME? (’:’ TYPE)? TYPEVALUE | NAME? (’:’ CLASS)? class_value
alias := NAME = identifier
class_value := ’{’ field * ’}’
field := FIELDNAME value +
value := identifier | decl
identifier := root_name | identifier ’.’ NAME
root_name := NAME

The two main classes used to describe the logical level are node and topic. Their
full deﬁnitions may be found in https://github.com/SRI-CSL/radler/blob/master/
radler/radlr/language.py. The most important elements are:

class node

PUBLISHES publication *
SUBSCRIBES subscription *
CXX cxx_class
PERIOD duration
WCET duration

class topic

FIELDS int8/uint8/int16/uint16/int32/uint32/int64/uint64/

float32/float64/
bool/struct/array/duration/time +

When creating a node, Radler will construct one instance of the provided C++
class (the CXX ﬁeld). The step method of this instance will be called at a ﬁxed
frequency deﬁned by the node’s period (the PERIOD ﬁeld). This step function needs
to be proven to have a worst case execution time no greater than the one described
here in the WCET ﬁeld. At each call, the step function is provided with the messages
received from its subscriptions and is required to write the messages it has to publish.
A topic (deﬁned uniquely by its name) is a purely logical way to deﬁne point-
to-point communications between one producer and multiple consumers. There can
be exactly one node publishing to a topic while many nodes can subscribe to it.

Any user code needing libraries has to be declared as using a library with the LIB
ﬁeld. This ﬁeld allows two forms of libraries, cmake library and static library:

77

class cxx_file

PATH string ?
FILENAME string *
LIB cmake_library/static_library *

class cmake_library

PATH string ?
CMAKE_MODULE string
CMAKE_COMPONENTS string *
CMAKE_VAR_LIBRARIES string ?
CMAKE_VAR_INCLUDE_DIRS string ?

class static_library

PATH string ?
HEADER_PATHS string *
CXX cxx_file *

#defaults to {CMAKE_MODULE}_LIBRARIES
#defaults to {CMAKE_MODULE}_INCLUDE_DIRS

Static libraries are of the simplest form, gathering a set of source ﬁles in their CXX
ﬁeld while the library header ﬁles are found in the HEADER PATHS paths. The cmake
library enables the use of arbitrarily complex libraries since it is a user deﬁned cmake
script. The CMAKE MODULE ﬁeld provides the cmake module name used to ﬁnd it in
the working directory. COMPONENTS are the required components from this module,
used when calling the cmake find module command.

When a value is type annotated, it is checked to be of this type.

If no type
annotation is provided, the kind of the value is extracted from the ones possible in
the value declaration context. Subtyping allows for example to use a 16bits integer
(int16) where a 32bits integer is required (int32). For now, subtyping is only done
on sized types by allowing a type to be used in a bigger version. sized types and
possible sizes are explicit in the language. User values are checked to ﬁt the type’s
size with the function check type size.

User code Each node is a Mealy machine. The user provides a class which will
be instantiated with the default constructor to generate an instance representing
the state of the machine. Then, the step method of this instance will be called to
execute one step of the machine. The signature of the step method is required to
be:

void step(const radl_in_t* in, const radl_in_flags_t* inflags,

radl_out_t* out, radl_out_flags_t* outflags)

The four argument types are structures deﬁned in the generated header ﬁle. The
input structure radl in t has one ﬁeld per subscription of the node. The ﬁeld name
is the radl name of the subscription. Each ﬁeld is in turn a structure reﬂecting the
topic of the subscription, whose ﬁelds are the name of the radl topic FIELDS. The
output structure radl out t is similar to the input structure except that is used by

78

the step function to publish its publications. To this eﬀect, the step function has to
ﬁll the output structure.

Freshness and timeout Similar to the input and output structures, the ﬂag
structures radl in flags t and radl out flags t have a ﬁeld for each subscrip-
tion and publication, respectively. The main idea of ﬂags is to have some Boolean
metadata attached to messages, which by default propagate through nodes. To this
eﬀect, the default value of the output ﬂags of each publication of a node are set to
the logical OR of all the ﬂags of its subscriptions. Subsequently, the input ﬂags are
given to the step function as read-only while the preset output ﬂags are provided to
the step function to give it a chance to turn on or oﬀ the desired ﬂags. Therefore,
if the step function has not change the output ﬂags, they will propagate the input
ﬂags.

The input ﬂag radl STALE has the broad meaning that its associated value is
not “fresh”. More precisely, it either means that the publisher of the value ﬂagged
it as stale (by automatic propagation or by choice) or that no new message arrived
since the last call to the step function. In the latter case, the step function gets the
same input value (the mailbox has not changed) but it is ﬂagged as stale. To check
if a subscription s is stale, one simply calls radl is stale(in flags->s) which
returns a Boolean.

The input ﬂag radl TIMEOUT has the broad meaning that its associated value
has violated the timing constraints. More precisely, it either means that the pub-
lisher of the value ﬂagged it as timeout (by automatic propagation or by choice)
or that we have not received a message since period of the publisher plus the
MAXLATENCY. In the latter case, timing constraints are exceeded and something un-
expected is happening. To check if a subscription s is timeout, one simply calls
radl is timeout(in flags->s) which returns a Boolean.

The function radl turn on is used to turn on a ﬂag. For example to turn on

the stale ﬂag of the publication p the following should be used:

radl_turn_on(radl_STALE, &out_flags->p);

To turn oﬀ ﬂags, the similar function radl turn off should be used.

Plant The physical speciﬁcation describes the machines used in the realization of
the overall system. A physical description is provided by a value of type plant. The
most important ﬁeld is the MACHINES ﬁeld listing the machines of the system. A
machine is typically deﬁned by the operating system that it runs (OS ﬁeld). Their
use is mostly geared towards system code generation and conﬁguration, done by the
Radler tool.

79

class plant

MACHINES machine *

class machine

OS linux/lynxsecure/certikos

class linux

NODES_UID uint16
IP ip ?
IMG string ?
NODES node *

Software Build System The Radler build tool takes the architecture deﬁnition
and individual local functions as inputs and generate executables for the overall
system as output. Radler synthesizes glue code for the communication layer based
on the logical description and binds it to the source code for node functions to
generate a code executable. In addition, Radler utilizes the physical architecture
part of RADL to realize the ﬁnal system. During the build process, it can instrument
the system so that platform assumptions such as node periods and channel latencies
can be checked at runtime.

On the implementation side, Radler uses ROS as a backend. Each node and
communication channels are dynamically setup by ROS. Radler generates ﬁles from
a radl ﬁle into a ROS catkin structure, then a call to catkin make will generate the
executables as usual. If a module deﬁnes a plant, Radler generates a ROS launch
ﬁle to run the requested nodes.

The Example of Room Temperature Regulation Figure 5.13 shows the
nodes and communications between them via topics for the example of room tem-
perature regulator introduced in Section 2.5.

Five nodes (in ellipse) communicate through six topics (in rectangle). The
button node publishes to thermostat button and thermostat set topics to
generate signals that control the behavior of thermostat by means of switching
on/oﬀ and setting the target temperature, respectively. The thermostat node
subscribes from thermostat button , thermostat set , thermometer data top-
ics and publishes to thermostat data topic to regulate a room temperature within
min/max. The thermometer node subscribes from house data topic and pub-
lishes to heater data topic to measure the room temperature with sensing noise.
The heater node is the actuator that subscribes from thermostat data and
publishes to heater data . The house node provides the physical room temper-
ature by subscribing from heater data and publishing to house data while the
thermometer node provides the digital sampled sensed temperature. A system
consisting of these nodes was deﬁned in a RADL description with user code in each

80

Figure 5.13: Nodes (in ellipse) and topics (in rectangle) of the example of room
temperature regulator.

step function. The Radler build process generates the glue code for scheduling,
communications, and failure detections for executables.

At the logical level, there are two main value types; node and topic. Excerpt

from the example system’s RADL description below:

basic_rate : duration 50msec

thermometer_data : topic { FIELDS temp : float32 75 }
thermostat_button : topic { FIELDS status : bool true }
thermostat_set : topic { FIELDS temp : float32 75 }

thermostat_data : topic { FIELDS switch_on : bool true }

thermostat : node {

SUBSCRIBES

thermometer_temp { TOPIC thermometer_data MAXLATENCY 1msec }
thermostat_switch { TOPIC thermostat_button MAXLATENCY 1msec }
thermostat_set_temp { TOPIC thermostat_set MAXLATENCY 1msec }

PUBLISHES

heater_switch { TOPIC thermostat_data }

PATH "src"
CXX

{ HEADER "thermostat.h" FILENAME "thermostat.cpp" CLASS "Thermostat" }

PERIOD basic_rate

}

A node is described with ﬁelds such as PERIOD, PUBLISHES, and SUBSCRIBES.
When the thermostat node is created, Radler constructs one instance of the pro-
vided C++ class speciﬁed in the CXX ﬁeld. The step function of this instance will

81

be called at a ﬁxed frequency deﬁned by the node’s period (the PERIOD ﬁeld).
At each call, the step function is provided with the messages received from its
subscriptions and is required to write the messages that it has to publish (the
SUBSCRIBES and PUBLISHES ﬁelds). A topic is uniquely deﬁned by its name. For
example, thermometer data , thermostat button , thermostat set topics are
referenced as thermometer temp , thermostat switch , thermostat set temp ,
respectively. The thermostat node publishes to the thermostat data topic ref-
erenced as heater switch and heater node subscribes from it. A topic is a
purely logical way of deﬁning point-to-point communications between one producer
and multiple consumers. That is, there can be exactly one node publishing to a topic
(e.g., house data ) while many nodes (e.g., thermometer 1 ... thermometer n
in case of multiple sensors) can subscribe from it. The communication occurs via
bounded latency channel (the MAXLATENCY ﬁeld) for each topic.

Below code segment shows the step function of the thermostat node, that
is provided by the user (C++ class speciﬁed in the CXX ﬁeld under the directory
speciﬁed in the PATH ﬁeld, as being exempliﬁed in the RADL description above).

void Thermostat::step(const radl_in_t* in, const radl_in_flags_t* inflags,

radl_out_t* out, radl_out_flags_t* outflags)

{

// change the set temperature
this->set_temp = in->thermostat_set_temp->temp;

// set the status
this->status = in->thermostat_switch->status;

// decide whether to switch on the heater
if (in->thermometer_temp->temp > (this->set_temp + this->tol)) {

out->heater_switch->switch_on = false;

} else if (this->status && (in->thermometer_temp->temp < this->set_temp)) {

out->heater_switch->switch_on = true;

} else {

out->heater_switch->switch_on = this->status;

}

}

A class will be instantiated with the default constructor to generate an instance
representing the state of the Mealy machine. Subsequently, the step function of
this instance will be called to execute one step of the machine. The signature of
the step function should specify the input (radl in t*) and output (radl out t*)
structures deﬁne the node’s subscription and publication, respectively. In the ex-
ample, the step function of the thermostat node regulates the room temperature
by switching on/oﬀ state of the heater. The ﬂag structures (radl inflags t*,
radl outflags t*) can be used to check if a subscription, e.g., thermometer temp ,
is stale or timeout by calling radl is stale(iflag->thermometer temp) or radl

82

is timeout(iflag->thermometer temp), respectively. These Boolean metadata
attached to messages are by default propagate through nodes unless the explicitly
being turned oﬀ (radl turn off).

A physical speciﬁcation is provided by a value of type plant:

sys1 : linux {

IP 192.168.1.201
NODES heater

}

sys2 : linux {

IP 192.168.1.202
NODES thermostat

}

sys3 : linux {

IP 192.168.1.203
NODES thermometer house buttons

}

plant : plant {

MACHINES

house_heater { OS sys1 }
house_computer {

OS l1 : lynxsecure {

VMS

vm1 { OS sys2 }
vm2 { OS sys3 }

}

}

}

The MACHINES ﬁeld lists the machines that will be used by the system. In the
example, three machines are deﬁned by the operating system that it runs (the OS
ﬁeld). The IP and NODES ﬁelds specify the IP address assigned for the OS and
the nodes that run on the OS. In the example, three nodes (i.e., thermometer ,
house , buttons ) run on the Linux with IP address of 192.168.1.203 while
heater and thermostat nodes run on a separate Linux machine. SRI’s open-
source release http://radler.csl.sri.com under permissive license together with
documentations also provides use-cases for the heterogeneous platforms including
AR.Drone, ArduPilot, RaspberryPi, and Android device. Some use-cases work with
both core ROS and secure ros (SRI’s fork of core ROS packages to enable secure
communication among ROS nodes) http://secure-ros.csl.sri.com.

Inception of Java Radler supports embedding for the existing Java components
using the Java Native Interface (JNI). An example of such existing Java components
is BeepBeep stream processing engine https://liflab.github.io/beepbeep-3

83

that allows processing log data and live event feeds. Speciﬁcally, BeepBeep can
provide Radler with runtime monitoring capabilities by analyzing and transforming
the event stream through a chain of basic event processors. Values subscribed from
the topics can be piped as input to the stream processing engine. Similarly, the
realtime output event streams can be piped to the topics to be published.

A simple use-case below shows a node monitoring point distance between two
(x,y) positions. A radl ﬁle should include cmake library information for JNI mod-
ule, which is passed as LIB ﬁeld in the node description:

jni : cmake_library {
CMAKE_MODULE "JNI"
CMAKE_VAR_LIBRARIES "JNI_LIBRARIES"
CMAKE_VAR_INCLUDE_DIRS "JNI_INCLUDE_DIRS"

}
monitor : node {

...
CXX { HEADER "monitor.h" FILENAME "monitor.cpp" CLASS "Monitor" LIB jni }

}

Java Virtual Machine (JVM) creation should be in the class constructor by call-
ing JNI CreateJavaVM with JavaVMOption to load and initialize the JVM. JNI calls,
e.g., FindClass, GetStaticMethodID, CallStaticVoidMethod, are made inside of
the step function. In the step function, a class loader (FindClass) has to ﬁnd the
right class by searching for an appropriate .class ﬁle that was provided at JVM
initialization (-Djava.class.path). The class is then passed to GetStaticMethod
to ﬁnd the method of the class with the given signature. The method can be called
with CallStaticVoidMethod since a static method is independent of any object.

Monitor::Monitor()
{

...
JavaVMOption* options = new JavaVMOption[2];
options[0].optionString = "-Djava.class.path=/path/to/BeepBeepCore&Plugin"
vm_args.options = options;
jint res = JNI_CreateJavaVM(&vm, (void **)&this->env, &this->vm_args);

}

void Monitor::step(const radl_in_t* in, const radl_in_flags_t* inflags,

radl_out_t* oout, radl_out_flags_t* outflags)

{

...
double x1 = in->position->x;
double y1 = in->position->y;
jclass cls = env->FindClass("PointDistance");
jmethodID mid = env->GetStaticMethodID(cls, "getPointDistance", "(FFFF)V");
env->CallStaticVoidMethod(cls, mid,

jfloat(x1), jfloat(y1), jfloat(x2), jfloat(y2));

...

}

84

5.3 Lightweight Code Analysis Tools

The University of Washington research team led by Professor Michael Ernst have
developed a suite of lightweight analysis tools for Java. These tools are used ex-
tensively in industry for checking large codebases for bugs and software quality
assurance. The three main tools that we integrate in the DesCert project are

1. The Randoop tool for synthesizing unit tests

2. The Daikon tool for the dynamic detection of program assertions

3. The Checker Framework for pluggable and extensible typechecking

These tools can be used for ﬁnding bugs as well as establishing generic and

speciﬁc properties of code components.

5.3.1 Randoop: Feedback-Directed Random Test Generation

Randoop synthesizes unit tests for Java classes in the JUnit format [PE07].
It
uses feedback-directed random test generation to build and compose sequences of
constructor operations and method calls to explore portions of the state space that
na¨ıve test generation might not cover. The unit tests synthesized by Randoop can
be used to uncover and ﬁx bugs or as regression tests that can veriﬁed whenever the
software changes. Randoop has been applied to large codebases and has successfully
uncovered bugs in widely-used libraries including Sun’s and IBM’s JDKs and a core
.NET component.

Figure 5.14 shows an example of an error-revealing unit test generated by Ran-
doop in the OpenJDK library. This test demonstrates the construction of a set s1
on which the generated assertion for the reﬂexivity of the equality test fails. The
unit test requires the construction of a list object and a TreeSet object (containing
the list object) to which we apply the reﬂexive equality test.

Tests can reveal errors by failing generated assertions, violating explicit con-
tracts, or throwing unexpected exceptions. The classiﬁcation of test results as er-
rors or expected behavior is under user control since in many cases, the thrown
exceptions might be appropriate given the inputs. The generated tests can also be
minimized to avoid redundant or irrelevant steps.

As described in Chapter 6, we have developed a Baseline DesCert plug-in for
Randoop to collect the error-revealing and regression tests for Java class libraries.
These test suites are maintained as evidence artifacts along with the test analysis
results.

85

// This test shows that the JDK collection classes
// can create an object that is not equal to itself.
@Test
public static void test1()

LinkedList list = new LinkedList();
Object o1 = new Object();
list.addFirst(o1);

// A TreeSet is an ordered collection. According to the API
// documentation, this constructor call should throw a
// ClassCastException because the list element is not Comparable. But
// the constructor silently (and problematically) accepts the list.
TreeSet t1 = new TreeSet(list);

Set s1 = Collections.synchronizedSet(t1);

// At this point, we have successfully created a set (s1)
// that violations reflexivity of equality: it is not equal
// to itself! This assertion fails at run time on OpenJDK.
org.junit.Assert.assertEquals(s1, s1);

Figure 5.14: A Randoop Unit Test Example

86

5.3.2 Daikon: Dynamically Detection of Program Invariants

Unit tests such as those generated by Daikon can be used to generate traces for Java
programs. These traces can be mined for assertions that hold at speciﬁc program
points including loop invariants and preconditions and post-conditions for method
calls. The Daikon tool dynamically analyzes program behaviors to automatically
learn useful assertions [EPG+07].
It is important to remember that these asser-
tions might not valid since the only hold on the test runs, but in many cases, the
information generated by Daikon is quite helpful. Consider, for example, a Java
class that implements a stack with push, pop, top, topAndPop, isEmpty, isFull,
and makeEmpty methods, using an array representation for the stack content and a
topOfStack slot that is -1 when the stack is empty. Daikon can detect that the
array component is never equal to null and that the topOfStack slot is always at
least -1. It can also detect that the size of the array is always one more than the
value of the topOfStack ﬁeld. These are indeed valid invariants. Daikon operates by
generating and testing a number of assertions. The generation of assertions is smart
and based on instrumentation to track the interaction between values in a program.
For instance, it will check if an array is sorted when the elements in the array look
comparable, and the sortedness property appears to be relevant to the behavior of
the program. Once a set of useful putative invariants have been identiﬁed, other
tools, including the Checker Framework can be used to verify if the invariant is in
fact valid.

5.3.3 The Checker Framework: Pluggable Extensible TypeCheck-

ing

Java is a strongly typed object-oriented programming language, but a number of
common errors are not caught by the Java compiler. Java 8 adopted the Type An-
notation Speciﬁcation as a notation for inserting annotations into comments. The
Checker Framework uses the Type Annotation Speciﬁcation to support pluggable
typecheckers for additional program properties [PACJ+08, DDE+11a]. One such
example is the nullness checker where the System.out.println method is invoked
on a possibly null object myObject.toString. The nullness checker ﬂags this incon-
sistency. Fields and variables can be annotated with @NonNull types, but these can
also be derived by the type inference tool which saves the labor of hand-annotating
the code with types.

The Checker Framework has been extended with a number of other checkers.
The Regex checker ensures that regular expressions strings are actually well-formed
regular expressions. The Taint checker ensures that tainted user input does not pol-
lute the input to sensitive operations such as a database query on a malicious query

87

public class NullnessExample

public static void main(String[] args)

Object myObject = null;

if (args.length > 2)

myObject = new Object();

System.out.println(myObject.toString());

Figure 5.15: Checker Framework Example: NullnessExample.java

string. The Encryption checker uses the @Encrypted annotation tag to ensure that
sensitive data is encrypted when placed on a publicly visible channel. The Checker
Framework ships with over twenty ﬁve custom type checkers for properties such as
initialization, resource leaks, locks, bounds of index variables, purity (absence of
side-eﬀects), and units of measurement. There are also around twenty checkers that
have been developed by third parties spanning information ﬂow, determinism, im-
mutability, and typestate. Many of these are examples of Ontic type systems that
are relevant to the DesCert project.

The Checker Framework was applied BeepBeep3 runtime monitoring library [HK17]

which is used to monitor runtime safety within our ArduCopter AFS subsystem. The
analysis revealed a number of issues. For example, it revealed an inconsistency in
annotation of the getProvenanceTree which is declared to return a non-null result
in one ﬁle but is deﬁned to return a null result in another. These ﬂaws have been
reported to the developers of the BeepBeep3 tool.

5.4 SeaHorn Tool for Static Code Analysis

SeaHorn [GKKN15] is a veriﬁcation framework for LLVM-based languages. SeaHorn
performs a whole-program points-to analysis [GN17] to translate LLVM bitcode into
a set of veriﬁcation conditions (VCs) whose satisﬁability implies that the program
is safe. Currently, SeaHorn focuses on reachability properties. Speciﬁcally, SeaHorn
checks for predeﬁned errors such as memory errors and user-deﬁned assertions. The
details of these VCs and how SeaHorn checks for predeﬁned errors and assertions
vary depending on the back-end solver. SeaHorn provides three main back-end
solvers:

88

• a model-checker, called Spacer [KGC14], based on Property-Directed Reacha-
bility (PDR) [Bra11] that produces (a) proofs, consisting of loop invariants and
procedure summaries, (b) counterexamples if the program cannot be proven
safe, or otherwise, (c) it returns “unknown”. For practical reasons, Spacer
does not precisely model certain aspects of the semantics of the program. For
instance, malloc is modeled as a function that returns non-deterministically
a pointer, ignoring important details such as alignment and memory layout.
Alternatively, SeaHorn uses Sally [JD16] if all functions and procedures can
be inlined since Sally cannot model them. The beneﬁt of using Sally is in the
use of PDR combined with k-induction, a powerful technique for inferring loop
invariants that Spacer does not support.

• a bounded-model checker (BMC) that models more precisely the semantics of
programs (including memory allocation) at the expense of producing bounded
proofs (i.e., proofs that only hold for a ﬁnite number of loop iterations) but it
is very eﬀective at ﬁnding bugs in programs.

• a static analysis based on Abstract Interpretation [CC77], called Crab, that
produces proofs, consisting also of loop invariants and procedure summaries
but it cannot produce counterexamples. Due to the nature of abstractions,
Crab is often more eﬃcient than Spacer/Sally and BMC but it can produce
many more false positives. Crab provides a rich set of ﬁxpoint solvers, abstract
domains and analyses. For instance, Crab provides a Memory analysis that can
prove absence of memory errors such as null dereferences and buﬀer overﬂows.

In this phase, we have focused on Crab, the SeaHorn abstract interpreter. More

speciﬁcally, we have focused on the following tasks:

• Improve Crab capabilities to perform analysis of relevant C projects.

• Implement a new Tag analysis that models many interesting ontic properties.

• Start developing evidence formats (i.e., certiﬁcates) for independent checkers.

5.4.1 Progress on Analysis of C code

We have developed a new memory model, called region-based memory model (RBMM),
that enables more eﬃcient analysis of C code with few restrictions with respect to
the standard C memory model. This work has been published in [GN21].

Standard C memory model partitions memory into memory objects. A pointer
points to an oﬀset within a memory object. RBMM further partitions memory into
regions. A region can span multiple objects. The key diﬀerence is that pointers

89

pointing to diﬀerent regions cannot alias even if they point to the same memory
object. RBMM makes two key assumptions in order to allow eﬃcient analysis of C
programs: (a) matched pairs of memory writes-reads must access the same number
of bytes, and (b) it assumes that programs do not have undeﬁned behavior (UB). As-
sumption (a) excludes non-portable code. Although it may seem counter-intuitive,
assumption (b) does not limit our analysis from proving absence of UB. As shown
by Conway et al. [CDNB08], conditionally sound analyses can prove absence of er-
rors (e.g., memory violations) or otherwise, produce one counterexample although it
cannot produce all possible counterexamples. In summary, the approach described
in [GN21] works as follows:

1. apply SeaHorn whole-program pointer analysis on the LLVM program so that
memory is statically partitioned into regions. The analysis also identiﬁes which
parts of the program might not satisfy the assumptions of RBMM;

2. translate the LLVM program into a novel intermediate-representation (IR),
called CrabIR, where all LLVM memory instructions are translated to in-
structions over regions and references;

3. perform abstract interpretation on CrabIR using Crab ﬁxpoint solvers and

abstract domains.

In [GN21], we apply Crab using our new region-based aware IR (CrabIR) on ﬁve
popular C projects: bftpd, brotli, curl, thttpd, and vsftpd. Sizes vary from 5K
to 50K lines of code. The results show that Crab can prove that around 60% of all
non-trivial1 pointer accesses cannot be null. This number is promising considering
that the environment for these programs is conservatively ignored and no specialized
abstract domains are used.

5.4.2 New Tag Analysis

In this phase, we have also developed a new Tag analysis in Crab, where memory
locations can be tagged with a numerical identiﬁer (i.e., tag) and then the Crab
forward analysis propagates those tags through memory. Upon completion of the
analysis, Crab clients can ask whether a memory location is tagged with a particular
set of tags. Taint analysis is an example of tagging.

As a pilot study, we have applied the Tag analysis on thttpd (8K lines of code)
in order to perform taint analysis where sources are systems calls such as read and
mmap and sinks are systems calls such as write and writev. Each source and each

1A memory dereference is considered trivial if LLVM analyses can already prove that it is not

null (e.g., global variables).

90

sink is assigned a diﬀerent tag. The analysis runs in few seconds and infer 24 of the
72 relationships between the 7 sources and 8 sinks in thttpd. In the next phase,
we plan to focus on more speciﬁc ontic properties (e.g., security related properties)
and apply the Tag analysis on a broader set of relevant programs.

5.4.3 Progress on Evidence Formats for Independent Checkers

We have developed an approach that uses program invariants produced by an ab-
stract interpreter as evidence that can be checked by independent checkers. We plan
to start implementing a prototype in the context of eBPF programs.

Any abstract interpreter produces program invariants at each basic block or
program location. More precisely, an abstract interpreter produces an invariant
map, InvM ap, that maps a location l to Invl, a formula deﬁned on a subset of
program variables, expressed in the restricted form allowed by the abstract domain
(Invl : AbsState). The formula Invl expresses a set of facts that holds at location
l expressible in the particular abstract domain.

In our approach, the tuple (cid:104)P, (cid:116), ⇒, TrFn, InvM ap(cid:105) constitutes the certiﬁcate
that needs to be checked, where P is the program, ⇒: AbsState × AbsState (cid:55)→ Bool
is the abstract implication, (cid:116) : AbsState × AbsState (cid:55)→ AbsState is the abstract
join, and TrFn : AbsState (cid:55)→ AbsState represents the abstract transfer functions for
each transition from location l(cid:48) to l.

Then, the checker receives a certiﬁcate and it must verify for each location l in

P that:

(cid:71)

(TrFnl(cid:48) → l(InvM ap(l(cid:48)))) ⇒ InvM ap(l)

l(cid:48)∈pred(l)

where pred returns the predecessors of a given location.

Note that any other abstract interpreter diﬀerent from the one that generated
the certiﬁcate can be used as checker. Another possibility is to translate program
invariants (AbsState) into some ﬁrst-order logic fragment expressed by some combi-
nation of SMT theories so that the checker can be replaced by a SMT solver. This
would need also to replace (cid:70) with logical disjunction, abstract implication with
logical implication, and the abstract transfer function TrFnl(cid:48) → l with the logical
encoding of each transition l(cid:48) → l.

We plan to implement the ideas from this section in the context of eBPF pro-
grams. An eBPF program is a bytecode program that can be executed in the kernel
without recompiling the kernel. The price to pay for such as ﬂexibility is that the
kernel needs to verify that the program is memory safe before executing it. In a pre-
vious work [GAG+19], we developed an abstract interpreter based on Crab, called

91

Prevail, that outperforms the existing veriﬁer in the Linux Kernel. The main limi-
tation is that Prevail must be run in user space. Recently, Windows OS has adopted
the eBPF technology and chosen Prevail as the veriﬁer. Currently, Windows OS runs
Prevail in a secure environment which is not an ideal solution either. To solve this
problem, we plan to use Prevail to generate certiﬁcates in user space and implement
a lightweight checker more suitable to be run in a secure environment.

92

Chapter 6

Continuous Assurance
Workﬂow: Baseline DesCert

A growing trend in software engineering is continuous development — a prac-
tice where software updates are made continuously, piece-by-piece, rather than
in one large batch. Continuous development considers the entire software life-
cycle, within which other continuous activities can be positioned, e.g., continuous
planning[KRC+01], continuous integration[SB14], continuous reasoning[O’H18], and
so forth. Software projects that can successfully implement continuous development
can anticipate strategic beneﬁts[FS17], including:

1. Maximize engineering productivity,

2. Run more experiments before a general release, and

3. Fix errors faster.

The way humans assess software artifacts throughout the entire software life-
cycle, from system requirements to source code, is interactive. It comprises a se-
quence of steps aimed at making sure that properties of these artifacts meet certain
assurance objectives (e.g., speed never exceeds more than 120 miles/hr). These
steps are inter-connected and thus their execution closely resembles the concept of
continuous development. We believe that if property-based assurance of software
artifacts is done in a continuous fashion, where formal methods can automatically
establish properties of a set of artifacts that we can prove using a program analysis
tool, then we can anticipate the same quality and consistency beneﬁts of continuous
development. Continuous assurance is done with artifacts changes, and will feed
back information to developers in tune with their development workﬂows.

93

In the following sections, we describe the Baseline DesCert workﬂow, a tool for

the continuous assurance of software as part of a build process.

6.1 Continuous Assurance with Baseline DesCert

In this section, we describe the Baseline DesCert workﬂow, a tool for monitoring
and maintaining the status of the assurance artifacts during continuous assurance.
This tool also interacts the Rack system in order to curate and ingest assurance
artifacts in accordance with the DesCert ontology (see Section 4).

In Baseline DesCert, continuous assurance starts with evidence generation. Ev-
idence generation occurs on a changing codebase in a fashion that mirrors the con-
tinuous model of software development. Baseline DesCert views a codebase as a
changing artifact that evolves through modiﬁcations submitted by programmers.
Baseline DesCert’s operating mechanism is centered around the use Gradle and
Gradle plugins to record evidence as part of the build process. It integrates diﬀer-
ent tools into Gradle through plugins so that these tools can be applied as software
artifacts are created or updated. The recorded evidence will be maintained within
the GE TA2 Rack system. Figure 6.1 shows Baseline DesCert’s main components.

Figure 6.1: Baseline DesCert

We have chosen to develop the Baseline DesCert workﬂow on top of the Gradle
build system for a few reasons. Gradle is breaking new ground in open-source
software development. Its native support is constantly evolving. It can build not

94

Developer+ reqs+ design  +codeTestsProofsTool Quals...{DesCert}GitqueriesBaseline DesCert CI PipelineConsistencyAnalysisandTestGenerationText2Test,ToradocuModelChecking,Edge-case,andUnit TestGenerationSally,RandoopStatic,CorrectnessAnalysisSeaHorn,DaikonPropertyProvingSeaHorn,CheckerFrameworkTestExecution,EmulationTestHarness(CLEAR)MonitorAggregateandCorrelateEvidenceonly Java projects but also Android and C/C++ ones, giving us the ﬂexibility for
project selection. Also, Gradle’s plugins portal1 oﬀers numerous plugins for a wide
variety of capabilities relevant to Baseline DesCert; e.g., C/C++ plugin.

As illustrated in Figure 6.1, Baseline DesCert aims at chaining many evidence
generation steps. Each of these steps is wrapped into a Gradle plugin. Each plu-
gin (1) conﬁgures a set of evidence generation tools and (2) then executes them
on codebase modiﬁcations. Particularly, Baseline DesCert aims at integrating
(1) Text2Test and Toradocu[BGK+18] for consistency analysis and test oracle gen-
eration, (2) Sally[DJN18b] and Randoop[PE07] for model checking and unit test
generation, (3) SeaHorn[GKKN15] and Daikon[EPG+07] for both static and cor-
rectness analysis, (4) SeaHorn[GKKN15] and the Checker Framework[DDE+11b]
for property proving, (5) Test hardness for test execution and emulation, and (6) a
monitoring tool for assurance evidence management. On each run, Baseline Descert
is going to monitor not only the execution of its components but also their output,
aggregating and correlating recorded evidence in the process. At this point, the de-
veloper who submitted software modiﬁcations can initiate the ingestion of assurance
artifacts into Rack in accordance with the DesCert ontology.

The ﬂow of evidence recorded by Baseline DesCert’s executions is going to cap-
ture properties of architecture and requirements of artifacts representing the system
ConOps. At each stage of this successive evidence generation process, the objective
is to work towards the construction of an assurance argument that can be maintained
along with the software’s evolution.

6.2 Baseline DesCert’s Gradle Plugins

Baseline DesCert is a work-in-progress tool. We have currently implemented Gradle
plugins for the University of Washington tools: Daikon and Randoop, and are inte-
grating the Checker Framework. Moreover, we have also implemented a Rack data
import plugin. This plugin is responsible for pushing the data generated by the plug-
ins into the Rack system. In addition to the Randoop, Daikon, and Rack data import
plugins, we are working on building more plugins for the other tools shown in Fig-
ure 6.1. For example, we have started the deﬁnition of plugins for CLEAR require-
ments checking, Text2Test, Sally, and SeaHorn. We have documented their main
API and how this API could be used and what type of evidence it can generate. Plu-
gins can be found at https://github.com/SRI-CSL/daikon-gradle-plugin.git
and https://github.com/SRI-CSL/randoop-gradle-plugin.git.

The Randoop plugin, for example, integrates the Randoop [PE07] tool to auto-
matically create unit tests for a set of classes, in JUnit format. The Randoop tool

1https://gradle.plugins.org

95

uses feedback-directed random test generation to generate sequences of method/con-
structor invocations for the classes under test. To use the plugin, one must add apply
plugin: ‘‘com.sri.gradle.randoop’’ to the root project’s build.gradle. Individ-
ual Randoop settings should be also speciﬁed in the build.gradle. At least, one
should specify, (1) the path to the Randoop tool, (2) the JUnit package name (the
location of the classes under tests), and (3) the Randoop output directory. Figure 6.2
shows a complete conﬁguration of the Randoop plugin.

plugins {

id ’ java ’
id ’ maven - publish ’
id ’ com . sri . gradle . randoop ’ version ’0.0.1 - SNAPSHOT ’

}

runRandoop {

randoopJar = file (" libs / randoop . jar ")
junitOutputDir = file (" $ { projectDir }/ src / test / java ")
// Maximum number of seconds to spend generating tests .
// Zero means no limit . If nonzero , Randoop is n ondeterministic :
// it may generate different test suites on different runs .
timeoutSeconds = 30
// Stop generation as soon as one error - revealing test
// has been generated .
stopOnErrorTest = false
// What to do if Randoop generates a flaky test :
// (1) halt , (2) discard , (3) output
fl aky Test Beh avi or = ’ output ’
// A flag that determines whether to output
// error - revealing tests .
n o E r r o r R e v e a l i n g T e s t s = true
// A flag that determines whether to use
// JUnit ’ s standard reflective mechanisms
// for invoking tests .
j u n i t R e f l e c t i o n A l l o w e d = false
usethreads = true
outputLimit = 2000
junitPackageName = ’ com . foo ’

}

Figure 6.2: Randoop plugin conﬁguration

Once conﬁgured, the plugin can be run by invoking either the runRandoop or the
randoopEvidence tasks. The former only generates the unit tests while the latter
generates both the unit tests and a set of evidence ﬁles summarizing the execution
of the Randoop tool. Figure 6.3 shows the output of the randoopEvidence task.

The Daikon plugin integrates the Daikon[EPG+07] invariant detector to report
likely program invariants. Daikon runs a program (e.g., unit tests generated by Ran-
doop), observes the values that the program computes, and then reports properties
that were true over the observed executions. The plugin can detect whether the

96

{

" Evidence ": {

" R a n d o o p J U n i t T e s t G e n e r a t i o n ": {

" INVOKEDBY ": " R a n d o op G r a d l e P l u g i n " ,
" AUTOMATEDBY ": " R a n d o o p G r a d l e P l u g i n " ,
" PARAMETERS ": "[ - - time - limit :30 , -- flaky - test - behavior : output ,

-- output - limit :2000 , -- usethread : true ,
--no - error - revealing - tests : true , -- stop - on - error - test : false ,
-- junit - reflection - allowed : false , -- junit - package - name : com . foo ,
-- junit - output - dir : src / test / java ]"

} ,
...
" R a n d o o p T e s t s A n d M e t r i c s ": {

" BRANCH ": " master " ,
" EXPLORED_CLASSES ": "2" ,
" COMMIT ": "6 fb16d1 " ,
" PUBLIC_MEMBERS ": "6" ,
" N ORM AL_ EXEC UTI ONS ": "314804" ,
" R E G R E S S I O N _ T E S T _ C O U N T ": "885" ,
" E R R O R _ R E V E A L I N G _ T E S T _ C O U N T ": "0" ,
" A V G _ E X C E P T I O N A L _ T E R M I N A T I O N _ T I M E ": "0.224" ,
" MEMORY_USAGE ": "4647 MB " ,
" E X C E P T I O N A L _ E X E C U T I O N S ": "0" ,
" G E N E R A T E D _ T E S T _ F I L E S _ C O U N T ": "3" ,
" A V G _ N O R M A L _ T E R M I N A T I O N _ T I M E ": "0.0572" ,
" G E N E R A T E D _ T E S T _ F I L E S ": [

" src / test / java / com / foo / R egr essio nT est0 . java " ,
" src / test / java / com / foo / R egr essio nT est1 . java " ,
" src / test / java / com / foo / R e g r e s s i o n T e s t D r i v e r . java "

] ,
" CHANGES ": " local " ,
" I N V A L I D _ T E S T S _ G E N E R A T E D ": "0" ,
" N UMB ERO FTES TCA SES ": "885"

}

}

}

Figure 6.3: Randoop plugin evidence

unit tests to execute were generated by Randoop (executed through the Randoop
plugin) or not. If there were not generated by the Randoop tool, the plugin would
search for a test driver (i.e., a test class that contains a static main method) it could
run. If the plugin cannot ﬁnd a test driver, then the Daikon plugin assumes the
project under test has its own unit tests and thus it generates a test driver that can
execute these tests.

to

Similar

the Randoop

plugin,
apply plugin:
‘‘com.sri.gradle.daikon’’ to the root project’s build.gradle and a few other
settings to run the plugin. The Daikon plugin can be run by invoking either
the runDaikon or the daikonEvidence tasks. Figs. 6.4 and 6.5 show a complete

one must

add

97

plugins {

id ’ java ’
id ’ maven - publish ’
id ’ com . sri . gradle . daikon ’ version ’0.0.2 - SNAPSHOT ’

}

runDaikon {

outputDir = file (" $ { projectDir }/ build / daikon - output ")
// the project directory where daikon . jar , ChicoryPremain . jar ,
// and dcomp_ *. jar files exist
requires = file (" libs ")
// * TestDriver package name . Daikon tool requires
// a test driver . If you use Randoop ,
// then Randoop will generate one for you .
// Otherwise , tell the plugin to generate a test driver ,
// simply by using the - Pdriver property when executing
// the plugin .
te stD rive rPa cka ge = " com . foo "

}

Figure 6.4: Daikon plugin conﬁguration

conﬁguration of the Daikon plugin and the generated evidence respectively.

{

" Evidence ": {

" Da i ko n Pl ug i nC o nf ig ": {

" OUTPUT_DIR ": " build / daikon - output " ,

} ,
...
" D a i k o n I n v s A n d M e t r i c s ": {

" CORES ": "16" ,
" J V M _ M E M O R Y _ L I M I T _ I N _ B Y T E S ": "477626368" ,
" SUPPORT_FILES ": [

" build / daikon - output / R e g r e s s i o n T e s t D r i v e r . dtrace . gz " ,
" build / daikon - output / R e g r e s s i o n T e s t D r i v e r . decls - DynComp " ,
" build / daikon - output / R e g r e s s i o n T e s t D r i v e r . inv . gz "

] ,
" PP_COUNT ": "5" ,
" INVARIANTS_FILE ": " build / daikon - output / R e g r e s s i o n T e s t D r i v e r . inv . txt " ,
" M E M O R Y _ A V A I L A B L E _ T O _ J V M _ I N _ B Y T E S ": "432013312" ,
" CLASSES_COUNT ": "1" ,
" TEST_DRIVER ": " src / test / java / com / foo / R e g r e s s i o n T e s t D r i v e r . java " ,
" TESTS_COUNT ": "4" ,
" INVARIANT_COUNT ": "0"

}

}

}

Figure 6.5: Daikon plugin evidence

98

The third plugin is the Rack data import. This plugin is responsible for loading
the Randoop and Daikon evidence JSON ﬁles, transforming these ﬁles into a format
that the Rack system can ingest, and then (if the Rack system is running) pushing
the transformed ﬁles into the Rack system. The conﬁguration is simple. This plugin
has only one dependency: the Gradle plugin com.jetbrains.python.envs, version
0.0.30. The Rack data import uses this plugin to create an Anaconda environment
that contains all the dependencies needed for running the Rack CLI. The Rack CLI2
is a tool that exposes a set of APIs for setting up ontologies and also pushing data
into the Rack system. Once the Anaconda environment is created, the Rack data
import plugin uploads the DesCert ontology to the Rack system. If the Randoop
and Daikon evidence ﬁles are available, the plugin pushes the evidence data to the
Rack system. Otherwise, it immediately returns. Figure 6.6 shows the Rack data
import plugin’s conﬁguration.

plugins {

...
id " com . jetbrains . python . envs " version "0.0.30"

}

envs {

b oo t st ra p Di re c to r y = new File ( buildDir , ’ bootstrap ’)
envsDirectory = new File ( buildDir , ’ envs ’)

conda " Miniconda3 " , " Miniconda3 - latest " , "64"
condaenv " descert " , "3.8.5" , " Miniconda3 " , [" numpy "]

}

task setupRackCli ( type : Exec ) {

dependsOn ’ build_envs ’
executable "./ rack - descert . sh "
args " cli " , " - - conda = Miniconda3 " , " - - condaenv = descert "

}

task setupRackArcos ( type : Exec ) {

dependsOn ’ setupRackCli ’
executable "./ rack - descert . sh "
args " init " , " - - conda = Miniconda3 " , " - - condaenv = descert "

}

task importData ( type : Exec ) {

executable "./ rack - descert . sh "
args " import " , " - - conda = Miniconda3 " , " - - condaenv = descert "

}

Figure 6.6: Rack data import conﬁguration

2https://github.com/ge-high-assurance/RACK/tree/master/cli

99

The rack-descert.sh script shown in Figure 6.6 contains functionality for (1) in-
stalling the Rack CLI, (2) checking whether a Rack instance is running, (3) setting
up the DesCert ontology in Rack, (4) curating evidence data, and (5) ingesting the
curated evidence data into the Rack system.

The curation step is a key operation of this plugin.

It transforms recorded
evidence data to a new format that matches the DesCert ontology in the Rack sys-
tem. For example, it turns the Randoop’s evidence data (See Figure 6.3) into a set
of concepts that describe the ontology of the Randoop evidence: the RandoopJu-
nitTestGeneration activity is invoked by a user entity (e.g., developer). This activity
is automated by the Randoop tool entity given some user-speciﬁed tool conﬁgura-
tion and a target source code entity. The results of a RandoopJunitTestGeneration
execution are captured in the RandoopTestsAndMetrics entity.

We have created an illustrative descert-example project (See https://github.
com/SRI-CSL/descert-example.git), its Docker image, its conﬁguration, and its
documentation. This project generates evidence for a basic Java project, as part of
its building process, using the Randoop and Daikon Gradle plugins. This project
can algo transforms the generated evidence into a format that the Rack system can
handle during its data import task. If a local version of Rack is running, a user can
trigger the uploading of the evidence data to the Rack system. Figure 6.7 shows
Baseline DesCert’s execution on the descert-example repository.

6.3 Track, Compare, and Visualize Your Evidence

At a ﬁrst glance, evidence generation with Baseline DesCert looks a lot like contin-
uous software development. But there are some key diﬀerences. Unlike continuous
software development, the essential unit of progress in Baseline DesCert is an ex-
periment, meaning programmers are going to be able to track what they doing in
the pipeline. With Baseline DesCert, we aim at automatically linking programmers’
experiments to latest git commits in the software repository of a project under
assessment. Our goal to facilitate to programmers a mechanism for easily compar-
ing any subset of experiments with visualizations, trying to achieve tool agreement
whenever possible. The agreement of tools on speciﬁc generated evidence is an in-
dicator of the quality of the generated evidence. Figure 6.8 illustrate our vision for
experiment tracking in Baseline DesCert.

With experiment tracking, programmers now have new capabilities. They can
vary evidence generation tools, change versions of a particular codebase, and even
adjust more general settings of each evidence generation tool. For example, on a
new experiment, one can change Sally and Daikon with SeaHorn or with Facebook’s
Infer[CDD+15, CDO15] and then track the quality of newly generated evidence

100

Figure 6.7: Baseline DesCert execution on descert-example repository

using the new tools.

As Figure 6.8 suggests, comparing the results of each experiment is going to
facilitate collaboration between the users of Baseline DesCert. Drawing inspiration
from continuous integration systems like Travis-CI and others, our goal is allow
users, or diﬀerent teams, to access the “continuous assurance” history of a codebase
at any time. Users can also watch other users’ experiments unfold in real-time and
even provide feedback if requested. We hypothesize that the ability to see evidence
evolution over many executions and many tool combinations (through experiment
tracking and visualizations) is going to provide a sense of progress with respect to
the quality of the generated evidence for a changing codebase.

101

Figure 6.8: Experiment tracking Baseline DesCert

102

90 %infermastererrorprone0timecoveragemerge requestaccept requestDesCert pipeline executionsvisualize resultstool agreement +Generated evidencefile1, ….,master (w/Sally & Daikon)infererrorproneVisualize Evidence Performanceover many executions and toolsPipeline executionChapter 7

DesCert Evidence Generation

In this section we show the diﬀerent certiﬁcation evidence for AFS, case study de-
scribed in Section 3, that is generated using DescCert tools described in Section 5
and how that evidence is populated in RACK using the ontology described in Sec-
tion 4. The evidence generation as well as the population of RACK with ingestion
data is shown in Figure 7.1.

At a high level, the left side of Figure 7.1 shows typical design/development
process starting from system ConOps deﬁnitions and from it developing system re-
quirements and architectures (both system and software) and then specifying intent
and software behavior in software high level requirements (HLRs) and after design
of software capturing implementation details of software with low level requirements
(LLRs) speciﬁcations. The middle parts of the Figure 7.1 shows the diﬀerent AFS
development and evidence artifacts generated while the right side of the ﬁgure in-
dicates the diﬀerent ontological class items populated within the RACK.

The rest of this sections is organized as follows: the top layers of the Figure 7.1,
left-to-right, shows DesCert evidence associated with generic properties of architec-
tural RADL speciﬁcations and is described in detail in Section 7.4; the middle layers
within the ﬁgure that deals with AFS requirements and the associated requirements
analysis evidence of satisfaction of certain generic properties are described in Sec-
tion 7.1 while the test evidence that are automatically generated from Software
HLRs are detailed in Section 7.3; ﬁnally the lower layers of the ﬁgure shows the au-
tomatic model generation from HLRs and veriﬁcation of speciﬁc properties through
model checking and is described in Section 7.2.

103

K
C
A
R
n
i

d
e
t
a
l
u
p
o
P
d
n
a

d
e
t
a
r
e
n
e
G
e
c
n
e
d
i
v
E
t
r
e
C
s
e
D
S
F
A

:
1
.
7

e
r
u
g
i
F

104

7.1 AFS High-Level Software Requirements

Without a doubt, the most fundamental step of any system development is captur-
ing a good set of requirements in a systematic way such that it is accurate, complete,
veriﬁable etc. However, this is not always an easy, straightforward task for most
complex systems, including the AFS system. Though the ConOps described the
contingencies and the recovery actions at a high level, specifying precise require-
ments for AFS such that it can be subject to a variety of analysis was not without
challenges. We begin this section with a brief note about some of the challenges we
encountered while specifying requirements, followed by details of the formalization
and analysis of the AFS requirements.

Initially, we captured the requirements of each contingency independently, as
speciﬁed in ConOps in Section 3. However, a deeper look at the failure conditions
and the recovery actions reveled that (a) there was a lack of detail about desired
behaviour when multiple failures occur at the same time; (b) some of the recovery
actions had critical dependency on proper functioning of components whose con-
tingencies and recovery actions have been deﬁned within the same ConOps. For
example, the copter is expected to return to launch, when the battery level of the
AFS system is below a certain level; however, without proper functioning of GPS,
the copter would not be able to return to launch. Despite having identiﬁed GPS fail-
ures as one of the contingencies in the ConOps, the respective recovery was assigned
a low priority than battery. So, it was imperative that we not only capture the prior-
ity among the contingencies, but also take into account dependencies in the recovery
actions. Also, on collectively analysing the recovery actions, we found that all of
them describe response actions to the same actuator of the copter and broadcast
messages to the same messaging channel. Hence, it was crucial for us to carefully
specify a consistent and correct response when multiple failures occur. Further, the
ConOps indicated that all the three geofence conditions have the level of priority.
Thought this may be acceptable, it will lead to non-deterministic behaviours and,
eventually implementation. Hence, we had to explore means to provide some sort
of precedence among those equally prioritized contingencies.

Given all the above challenges, after several round of brainstorming and explor-
ing multiple approaches, we ﬁnally decided to use the notion of states to abstractly
conceptualize the condition of the AFS during various contingencies and the tran-
sition conditions deﬁning when and how the system shifts between those states.
However, to handle the priority and dependencies among contingencies, a ﬂat state-
transition was not adequate. We explored the notion of deﬁning each contingency
independently and specify an arbiter [MRH13], to ﬁnally decide a recovery action.
However, the issue was that, to deﬁne the ﬁnal recovery action, it became necessary
to repeat the speciﬁcation of each failure conditions again in the arbiter since there

105

were dependencies. Hence, we took an hierarchical state machine approach [Har87]
where we encoded the notion of hierarchy, sequence and dependency of recover ac-
tions into the requirements.

It is worth to mention that, although state machines and hierarchies are often
correlated with design models, we ave found that they also provide a comprehensible
means to conceive and describe the requirements of complex systems. Hence, we
have used it purely to capture the AFS contingency requirements in a concise and
precise manner. This does not impose any restrictions on the way the system will
be designed or implemented.

7.1.1 CLEAR Features for AFS HLR

We formally captured the AFS requirements using the CLEAR notation explained in
Section 3. We deﬁned the requirements of each contingency as separate requirement
sets. A requirement set stands alone such that it suﬃciently describes the necessary
capabilities, and constraints of the contingency considered. All the variables and
enumerations that are used across all the requirement sets are collectively deﬁned
in a common dictionary or deﬁnition ﬁles.

State Machines States are widely used as abstraction to capture mutually ex-
clusive sets of discrete, dynamic system behaviors. The description of the states
and the rules deﬁning when and how the system transitions between those states,
collectively known as state machines, provided a coherent, concise means to express
the AFS requirements.

To that end, using the state deﬁnition construct in CLEAR notation, we deﬁned
AFS State to represent the various contingency states of the AFS system, as shown
in Figure 7.2. This state deﬁnition has several beneﬁts, such as succinctly spec-
ify the behaviours and helps deﬁne precedence among the behaviours in an easily
understandable manner.

Precedence and Priority Among Requirements By deﬁnition, ensuring that
all contingencies are addressed per the requirements is required or mandatory. How-
ever, at a given instant in time, when more than one contingency scenario occur, all
the requirements are not all equal in terms of current importance or severity of the
addressing the situation. For example, handling contingency related to low/failed
battery in a system has the highest precedence over failed ground communication.
Further, to meet a speciﬁc contingency requirement (with higher precedence con-
tingency management), correct functioning of another contingency (of lower prece-
dence) may be necessary. For example, to safely land a ﬂight at a emergency landing

106

Figure 7.2: AFS State Deﬁnition

location in the event of low/failed battery situation requires the proper function-
ing of navigation aids; otherwise, there has to be an alternate course of contingency
actions. Hence, at the time of speciﬁcation, it is crucial to determine the relative ne-
cessity of the requirements given the possible combinations of contingency scenarios
that may occur at operational time.

For AFS, as per the concept of operations discussed in Section 3.1, we ranked
the contingency scenarios in the order of precedence or priority. The Figure 7.3,
visualizes the priority using grouping and hierarchical state machine representation.
The insuﬃcient battery contingency states (grouped and colored red are labeled
InSuﬀ-Bat States) were speciﬁed to have the highest priority, i.e., when the system
is any non-low battery state and a battery contingency condition occurs, the system
will transition to the low battery contingency states. The next in priority was the
GPS Lock loss (states and transitions colored pink); i.e., when the system is in any
of the Breach states (colored blue), or communication loss states (colored yellow)
or normal ﬂight state (colored green), if there is GPS Lock loss event when there
are no battery contingency, the system will transition to the GPS lock loss state.
Similarly, we grouped and captured the other contingencies depending upon the
priority identiﬁed in the ConOps. In the following sections, we delve into the details

107

Figure 7.3: Prioritized Contingency Management

of specifying each of these contingency requirements in detail.

108

Ontic Type Support for Navigation Entities One of the new ontic types we
deﬁned in CLEAR for AFS is XYZVector type, a coordinate system deﬁnition that
allows uniquely deﬁning the location of geographical and navigational entities. The
coordinate system convention used for most vehicles, including aircraft, is based on
an XYZ system, where X and Y represent the horizontal position on ground and Z
represents the altitude from ground. When specifying the requirements of aerospace
systems, the notion of three dimensional coordinate systems is inevitable to express
position of air vehicles in space, their distance to other entities in space, etc. In
CLEAR notation users can deﬁne terms (or variables) of type XYZ coordinates as
shown in Figure 7.4.

Figure 7.4: XYZVector Deﬁnition in CLEAR

To allow deﬁning the notion of distance between two XYZ Coordinate terms,
CLEAR notation provides the distance between construct. The distance between
two XYZ points (x1, y1, z1) and (x2, y2, z2) are computed using the following formula,

distance = (cid:112){(x2

2) + (y2
Figure 7.5 illustrates the usage of this construct in one of the requirements of

2) + (z2

1 − x2

1 − y2

1 − z2

2)}

the AFS.

Figure 7.5: XYZVector terms and distance function usage in CLEAR

7.1.2 AFS Requirements in CLEAR

We now describe the CLEAR speciﬁcation of the AFS contingencies in detail.

Insuﬃcient Battery As mentioned earlier, the Insuﬃcient Battery contingency
has the highest priority. Per the ConOps, if the battery level is critically low (less

109

than the T land), the system should land immediately; whereas, if the battery is be-
tween the T rtl (Return To Launch) and T land, the system shall return to launch.
While we originally deﬁned two states for this contingency, as we were analyzing and
formally capturing the requirements, we found that the system needs the GPS to
function normally for returning to launch. Hence, to capture these scenarios, we has
to deﬁne three diﬀerent states for this contingency – namely ‘Return to launch due
to low battery’, ‘Land immediately due to low battery and no GPS’ and ‘Land imme-
diately due to Battery Critically Low’. The conditions to each of these states as well
as their behaviour (expected output) are diﬀerent. A snippet of the formalization
in CLEAR notation is shown in Figure 7.6.

Figure 7.6: Low Battery Requirements

GPS Lock Loss Requirements The next in priority was the GPS Lock loss
(states and transitions colored pink in Figure 7.3); In other words, the GPS lock
loss related contingency requirements need to come into play only when there are no
battery contingency. To capture that condition within the requirement, we deﬁned
a boolean variable called No Abonormal Batt Event that would be true when the

110

battery level is more than T rtl. The response for GPS loss requires that the
system waits by hovering for a certain amount time to allow going back the mission
when GPS recovers, or terminate and land otherwise. Further, the goal was also to
abandon the mission if there are more than a certain number of GPS failures.

Figure 7.7: GPS Lock Loss Requirements

To capture these behaviours, we deﬁned three states for the GPS lock loss –
namely ‘GPS Loss Hover’, ‘Flight Terminated due to GPS Loss’ and ‘Mission Aban-
doned’ – and the respective transition conditions. While we explicitly deﬁned a
counter (GPS Loss Count) to keep track of the number of GPS losses, the CLEAR
notation construct ‘has been ... for ... seconds’ helps specify the notion of timers.
Figure 7.7 shows a small snippet of the requirements in CLEAR.

Geofence Breach Requirements The third in priority is the various breach
contingency responses; In other words, when altitude, range or polygon breach oc-
curred, if there are no battery or GPS related failures, then the system shall attempt
to correct the breach situation within a certain amount of time, otherwise, the sys-
tem shall land. While the ConOps indicated that the breach conditions have equal

111

priority, in order to avoid non-deterministic implementation, it was decided that the
altitude, polygon and range breach conditions will be respectively given precedence.

Figure 7.8: Breach Requirements

To capture the notion of third in line priority while specifying requirements, we
had to deﬁne a boolean condition whole value is true if there are no battery and GPS
related failures at each instant in time. Further, to be able to specify that the system
is not already in a state with higher priority, we used CLEAR notation’s construct
to deﬁne custom sets, i.e, deﬁne a select sub-set of states among the AFS State. For
instance, we deﬁned sets such as GPS Loss States and Breach States indicating
the group of all states related to GPS loss and breach contingencies respectively.
This helped specify the requirements in reasonably modular and terse manner, as
shown in the Figure 7.9. Moreover, to capture the precedence among the breach
conditions, we leveraged the ‘...as deﬁned in the following precedence order...’ con-
struct in CLEAR notation. This construct allowed us to specify the response in a
precedence order, as shown the snippet 7.8. As mentioned earlier, instead of explic-
itly deﬁning a timer to capture the temporal aspect of this contingency, we used
the in-built CLEAR construct ‘has been ... for ... seconds’ to concisely capture the
requirements.

Communication Loss Requirements The communication loss related contin-
gency has the least priority; this means that only when the system is in normal
ﬂight state when the communication failures, the related contingency behaviours
are exhibited. Similar to the GPS loss requirements, the system shall attempt
to reestablish the communication and get back to normal course within a certain

112

amount of time, otherwise will return to launch. Moreover, when the total number
of communication loss (denoted by GS Comm Distruption Count in requirement)
incidents exceeds a certain threshold, the system shall return to launch. To capture
this in CLEAR, we deﬁned 5 diﬀerent states. Since this had the least priority, we
had to take into account the absence of other failures in every requirement relating
the transition among the communication loss states. Hence, we deﬁned a boolean
variable for that purpose, called No Abonormal Batt GPS Breach Events, as the
name suggests, indicates the absence of other failure conditions. A snippet of the
formalization in CLEAR notation is shown in Figure 7.9.

Figure 7.9: Communication Requirements

These requirements speciﬁed in CLEAR help automate a number of rigorous
analysis and veriﬁcation tasks. In the rest of this section, we describe in detail how
we generate test oracles and test scenarios from these requirements. We also trans-
late these requirements to the Sally transition system language for checking against
the architecture model and the low-level requirements. We have been developing
the formal semantics for the mapping between CLEAR and the input language of
the Sally model checker using the Text2Test tool infrastructure. We have also de-
ﬁned a precise ontology and representation format for the evidence artifacts at the
requirements level within the TA2 provenance ontology. We have also developed a
simple climate control example in order to explain the construction of the assurance

113

argument. This example is used to communicate how the diﬀerent pieces of the
assurance argument ﬁt together.

7.2 AFS Evidence Generation from Sally Model Check-

ing

Figure 7.10: An overview of the Sally model creation and checking process.

Two main artifacts are required for checking properties against the software
requirements: a Sally model, which is generated by Text2Test from a set of CLEAR
high level requirements, and the properties themselves, which are ﬁrst expressed
in natural language and then formalized into a Sally query (Figure 7.10). The
Sally model checker takes the model and the query as inputs, using them to either
verify that the property holds or produce a counterexample demonstrating that
the property does not hold. (That is, assuming that a conclusion can be reached
in a reasonable amount of time. The complexity of the model’s state will grow
exponentially as more steps are required to reach a conclusion.)

We developed a set of formal properties to check against the CLEAR require-
ments. This feature of Text2Test is under active development, and future versions
will have more integration with the CLEAR document. For now, properties are
formalized and speciﬁed as Sally queries.

As described in Chapter 4, these properties ﬁt into the DesCert ontology. For
each, there is a set of software requirements, and a speciﬁc property that holds for
those requirements. Two tools are used: Text2Test, which generates a Sally model
based on the requirement set and the property itself, and Sally, which is run on the
resulting model and property to verify the property’s correctness.

For

the

Insuﬃcient Battery

requirement

set,

the model

ﬁle

is

114

found in the ﬁle
AFS Insuff Battery Req sally.mcmt.
AFS Insuff Battery Property 1.mcmt, and states
the battery level
falls below a certain threshold, the AFS state must not be normal. The following
command was used to verify this property with Sally:

The property is
if

that

sally -- engine kind -v 1 -- show - trace \

A F S _ I n s u f f _ B a t t e r y _ R e q _ s a l l y . mcmt \
A F S _ I n s u f f _ B a t t e r y _ P r o p e r t y _ 1 . mcmt

The formal property for the Insuﬃcient Battery set was as follows:

( assume - input A F S _ I n s u f f _ B a t t e r y _ R e q _ s y s

(= bat_level 19)

)

( query A F S _ I n s u f f _ B a t t e r y _ R e q _ s y s

(= > ( and not_initial_step true ) ( not (= AFS_State 0)))

)

To constrain an input variable, the assume-input function is required. A more
ﬂexible approach to constrain inputs is to use an internal variable which always
mirrors the input, but that requires either tool support for generating such a variable
with the model or modifying the model by hand. We must also exclude the initial
step from checking because the initial values of all internal variables are undeﬁned
in the ﬁrst step, which allows the model checker to choose anything and will always
cause a counterexample to be generated. After the ﬁrst step, the model’s internal
variables will have been initialized based on the ﬁrst step’s input variables and proper
checking can begin. The not initial step variable is generated by Text2Test for
this purpose, and simply starts out false for one step and then remains true forever.
is
found in the ﬁle AFS GPS LockLoss.mcmt. The property being tested is in
AFS GPS LockLoss Property 1.mcmt, and checks that if the GPS loss count exceeds
the maximum, the AFS state must not be normal. At this stage in tool develop-
ment, it was necessary to use an internal variable of the model in the property itself
to access the previous value fo the GPS loss count. In the future, properties will
be speciﬁed at the CLEAR level, and Text2Test will generate both the Sally model
and the Sally query. This way, properties will be speciﬁed with expressions, inde-
pendently of whatever internal variables are found in the requirement set. To verify
this property, the following command was used:

For the GPS Lock Loss requirement set,

the generated Sally model

sally -- engine kind -v 1 -- show - trace \

A F S _ G P S _ L o c k _ L o s s _ R e q _ s a l l y . mcmt \
A F S _ G P S _ L o c k L o s s _ P r o p e r t y _ 1 . mcmt

115

For the GS Communication Loss requirement set, the generated Sally model
is AFS GS Communication Loss Property 1.mcmt and the property being tested is
in AFS GS Communication Loss sally.mcmt. It states that if the communication
disruption count has exceeded 3, the AFS state must not be normal. This property
was veriﬁed with the following command:

sally -- engine kind -v 1 -- show - trace \

A F S _ G S _ C o m m u n i c a t i o n _ L o s s _ s a l l y . mcmt

The ﬁnal requirement set deﬁnes nominal operation, with the Ground Con-
trol Station setting the state of the AFS. The Sally model is found in the ﬁle
AFS Nominal Requirements sally.mcmt, and the property being checked is in the
ﬁle AFS Nominal Requirements Property 1.mcmt. This property states that under
these requirements, the incoming GCS message should be set directly as the AFS
state. The command used to verify this property was:

sally -- engine pdkind -- solver yices2 -v 1 -- show - trace \

A F S _ N o m i n a l _ R e q u i r e m e n t s _ s a l l y . mcmt \
A F S _ N o m i n a l _ R e q u i r e m e n t s _ P r o p e r t y _ 1 . mcmt

7.3 AFS Test Generation from Text2Test

One of the main drivers behind the CLEAR notation is to be able to automate
formal-methods based analysis and test case generation. Text2Test is the main tool
that performs requirements analysis and test generation. Given a set of require-
ments, Text2Test performs a synthesis for this purposes from the data-ﬂow model.
It then uses Honeywell’s internal HiLiTE tool that provides comprehensive static
analysis and data-ﬂow test generation that has been used extensively for certiﬁcation
in many product lines.

7.3.1 Analysis of Generic Properties of Requirements

Text2Test utilizes public domain SMT Solvers (e.g., Z3); analysis objective are for-
mulated into an SMT problem and the solver is used to provide consistency analysis
and (limited) completeness analysis. A variety of arithmetic (including non-linear),
logical, and time-based constructs are supported as part of these capabilities to al-
low the tools to be used for large-scale industrial problems. Requirement analysis
is enabled for each output variable. In Text2Test data-ﬂow synthesized model, all
the requirements specifying the same output variable are combined and chained.

For each requirement set of the AFS system, we analyzed its generic properties,

described in Section 5.1.3, and shown below in Figure 7.11.

116

Figure 7.11: AFS Generic Properties

The errors found by the SMT solver (Z3) is reported in an XML ﬁle. The report
is a consolidation of all the generic property requirements issues found in a given set
of requirements. While there were no consistency and mode-thrashing errors, the
tool reported the lack of input and output completeness along with the input and
output domain values which made the set of requirements incomplete.

The analysis is performed on groups of individual requirement statements that
concern the same output attribute. The requirement defects analysis loops over
each of the output variables and lists the generic issues found in each of them.
Hence, the errors are displayed in a tabular format for every output attribute. The
Figure 7.12 shows the report of the insuﬃcient battery requirements analysis. In the
ﬁgure, the Unspeciﬁed combination of input values lists one combination of input
values (aka. counterexample) for which the requirements set in consideration do
not specify a value for a response. In other words, for the combination of inputs
(GPS Fix = Available; bat level= 51.0; copter position = 0.1), there is no
value speciﬁed for the output copter command. This does not indicate a problem
with the system, rather this combination of input values occur when the system is in
normal state; hence, this completeness issue reported shows that the requirement set
under analysis does not include the set of requirement that specify normal system
behaviours. Along the same lines, the Unspeciﬁed output values lists all missing
value assignments to output copter command and AFS State (as per its deﬁnition)
speciﬁed by the set of requirements. Again this is not an indication of problem with
the AFS, rather the result of analysing individual set of contingency requirements,
while the deﬁnitions include the values speciﬁed by other sets of requirements. In
the next phases of the project, we plan to deﬁne a concrete approach that would
compartmentalize the notion of requirement set, such that they can be veriﬁed in

117

Figure 7.12: AFS Generic Properties Analysis Output

isolation (without these issues), as well as in a compositional manner with other
requirement sets.

7.3.2 Requirements-based Test Case Generation

Using the HiLiTE tool at the back end, the Text2Test automatically generates re-
quirements based test cases from the synthesized model of requirements set. HiLiTE
generates speciﬁc tests at the model level for each block embedded in the model,
using either heuristic test case templates via backward propagation, or the formal
speciﬁcation of equivalence class via SMT-solving. The theory behind the test case
generation is explained in detail in Section 5. Once executed the Text2Test creates
a number of report ﬁles and test vectors for each of AFS’s requirement set.

Test Vector Report and Test Vectors The test report contains tables of the
test case templates and generated test vectors for each block. Figure 7.13 shows
the templates part of the test vector report that was generated for AFS. Test case
templates deﬁne the input and output requirements for each test for each block.
In the portion of the Figure 7.13, the template that speciﬁes the input values that

118

Figure 7.13: AFS Test Report - Template

should produce the expected output values is shown. The column header in yellow
shows the name of the variables for the block under test.

Figure 7.14 shows the vector part of the test vector report for AFS. The Gen-
erated Test Vectors show the actual values input to the block under test and the
value at the block’s output port. The template requires that Input1 and Input2
have values of 0 and 1, but since these ports are not directly accessible, Text2Test
must determine what values to give the model inputs to aﬀect the correct values. In
the generated test vector shown, notice that the block under test receives the sys-
tem‘s input (cells colored blue cells at the top of the Test Vectors table), constants
(colored in teal color cells at the top of the Test Vectors table) and intermediate
values (colored white). The system’s input values were determined from the require-
ments whereas the intermediate values are the result of intermediate computation
performed before the values can be propagated to the output (cell colored bright
green).

Further, Text2Test also generates test vectors in a machine-readable (csv) ﬁle
contains all the actual vectors that can be used with a suitable harness to test
the system in consideration. Figure 7.15 shows the comma separated vector ﬁle
displayed in Excel.

Test Generation Status Reports The Figure 7.16 shows the status report for
the AFS execution, that summarizes the execution and any issues encountered in
analyzing the requirements and list which test cases were generated or could not be
generated for each requirement. The detailed coverage metrics are displayed in this

119

Figure 7.14: AFS Test Report - Vector

Figure 7.15: AFS Test Vector

report.

7.4 AFS RADL Architecture Evidence Generation

As mentioned in the beginning of Section 7, in this Section 7.4 we will focus on how
DesCert AFS related evidence associated with generic properties of architectural
RADL speciﬁcations are created and this is illustrated in the top layers, left-to-
right, of the Figure 7.1.

We have described the RADL architectural language speciﬁcations, which con-
sists of both the logical and physical parts/layers of the system, the methodology to
perform software builds using Radler and associated architectural analysis in Sec-
tion 5.2. We have also introduced the ArduCopter system architecture and where
the AFS subsystem (software component) resides in the larger system in Section 3.3.

120

Figure 7.16: AFS Status Report

The speciﬁc RADL speciﬁcation for the AFS subsystem is captured in afs.radl in
the DesCert Github repository.1

Figure 7.17 shows the nodes and communications between them via topics for the
AFS subsystem which consists of two nodes. The AFS Function (afs function)

node both publishes to as well as subscribes from AFS Gateway (afs gateway)
AFS Gateway acts as a bridge between AFS Function and MAVROS
node.
which in turn interfaces with the ArduCopter ﬂight code through the MAVLink.
AFS Gateway captures all messages from ArduCopter and extracts battery infor-
mation, raw GPS position information,Geo-fence breach events and other health of
the ArduCopter health information, GCS heartbeat information etc and publishes
these as topics to AFS Function subscriber. The AFS Function node then ex-
ecutes its step function with period of 100 milliseconds and publishes 4 recovery
actions subscriber ROS nodes: (i) AFS Geofence Breach Recovery for 3 diﬀerent
kinds (altitude, range, polygon) (ii) AFS GCS Comm Loss Recovery (iii) AFS GPS
Lock Loss Recovery (iv) AFS Battery Insuﬃciency Recovery. The AFS Function
node then publishes as topics ﬂight controls command (e.g. change in ﬂight controls
mode or switching sensor information etc) to AFS Gateway subscriber which trans-

1Contact the authors for permission to access the repository.

121

lated the command appropriately and sends them via MAVROS to ArduCopter
via MAVLink transport (potentially repeatedly messages may needed to sent to
ArduCopter until ACKs on receipt of the message is conﬁrmed).

Figure 7.17: Nodes (in ellipse) and topics (in rectangle) of the AFS subsystem

We next describe below how the diﬀerent generic properties associated with ar-
chitecture for AFS RADL speciﬁcation, illustrated in the top layer of Figure 7.1, is
proven using architectural analysis.

122

Architecture Generic Property 1:

Software architecture of ArduPilot Advanced Fail Safe (AFS) subsystem
conforms and is restricted to quasi-periodic multi-rate computational model.

Architecture Generic Property 1 met rationale: ArduPilot Advanced Fail Safe
(AFS) subsystem include afs gateway and afs function that are speciﬁed in afs.radl
discussed above. Radler build process used the afs.radl speciﬁcation which included
multiple rates of diﬀerent computational nodes (tasks running at ﬁxed period) with
communicating topics/messages between publishers and subscribers over channels
with expectation of guaranteed delivery and latency/timing/delays. Radler compiles
the associated software source code related to afs gateway and afs function (RADL
nodes of AFS) and then executes the code within a ROS environment with a ﬁxed
period that is may or may not vary but is bounded (i.e. period may vary between
min and max clock).

Architecture Generic Property 2:

Quasi-periodic computational model of any RADL architecture and in par-
ticular ArduPilot Advanced Fail Safe (AFS) subsystem has the following 5
properties:

1. Bounded processing latency for any message/topic between every pair

of publisher and subscriber

2. Communication messages are delivered in order i.e. no overtaking,

with timing assumptions

3. Given ﬁxed buﬀer (including size 1), consecutive message losses can

be bounded

4. Message Loss can be eliminated with Bounded queue length which
can be used to provision communication channel for transporting mes-
sage/topic between publisher & subscribers appropriately

5. Age and/or Freshness of any message at any subscriber in terms of

time steps is bounded.

Architecture Generic Property 2 met rationale: Analysis results, based on PVS

proofs, are presented in paper [LS14] and discussed in Section 5.2.

123

Architecture Generic Property 3:

Radler, validates platform/physical layer performance when mapped and
bound to logical layer functions as well as any other assumptions on the
architectural model used in verifying any other properties listed in Archi-
tecture Generic Property 2. For any RADL Speciﬁcation, and in particular
ArduPilot Advanced Fail Safe (AFS) subsystem RADL speciﬁcation, the
following 4 properties are always held at run-time due to Radler run-time
checks/validation:

1. No stale message received after it’s latency and period

2. Every message is never received more than it’s timeout duration la-

tency and period

3. System healthy and no failures

4. Max latencies, node periods, execution times adheres to the RADL

speciﬁcations.

Architecture Generic Property 3 met rationale: Radler enforces for each node, a
state structure, an initialization function, a step function, and a ﬁnish function code
structure as well as generates the communication layer (glue code), the scheduler,
the overall compilation script and conﬁguration ﬁles, and builds an executable for
each machine. Radler also instruments the code for runtime monitoring and vali-
dation of platform performance and assumptions. Please see detailed rationale in
paper [LGS15] and discussions in Section 5.2.

Architecture Generic Property 4:

Physical Layer of RADL Architectural Speciﬁcation and in particular
ArduPilot Advanced Fail Safe (AFS) subsystem physical layer has robust
time and space partitioning.

Architecture Generic Property 4 met rationale: Robust space Partitioning based
on the memory partitioning strategy in the speciﬁcation depending on whether the
two RADL nodes in are in (1) same virtual machine within a single RTOS or (2) two
diﬀerent virtual machines with diﬀerent individual RTOS but in the same hypervisor
within a single machine or (3) two machines. Radler will then ensure provisioning
respectively for (1) a shared memory ring buﬀer (intra partition) or (2) a ring buﬀer
will be setup in a memory region shared between those two virtual machine with

124

message passing APIs (inter-partition) and (3) IP-based communication will be used
with queuing and sampling ports (inter-partition) appropriately.

Robust time partitioning with WCETs for every step function (computation
duration) within each RADL node being speciﬁed in the RADL speciﬁcation and
also subsequently Radler tool is also able to generate an instrumented version of the
software code and monitor the system with runtime checks for violations of timing
properties such as maximum latency of channels, node periods, execution times,
etc. The radler tool also generates local system log that radler can be analyzed and
validated against the architecture speciﬁcation. Such runtime checks are often the
only way of validating the timing parameters assumed by the model. Please see
detailed rationale in paper [LGS15] and discussions in Section 5.2.

125

Chapter 8

Conclusions

In this report, we have spelled out the details of the DesCert approach to assurance-
driven development of safety-critical software. The high-level goal of the project is to
raise the level of rigor, composability, eﬃciency, and automation in generating and
composing evidence for software safety claims. We adopt a continuous certiﬁcation
approach where the evidence is generated and curated during the design lifecycle.
We organize the assurance argument using an Eight Variables Model for control
systems that interact with a physical plant in a physical environment through sensors
and actuators to execute commands from an operator. The High-Level Requirement
is that the control software must carry out the planned mission while maintaining
the safety of the pose of the Plant and responding to the Operator commands. It
must do this in the face of disturbances from the Environment and uncertainty in
the readings taken by the Sensor and the responsiveness of the Actuator.

Our goal is to support an assurance-driven development methodology where the
designs are optimized to deliver eﬃcient arguments, where any latent ﬂaws can be
easily unmasked by a skeptical evaluator. In order to design for the eﬃciency of the
argument, we have used a precise formal language for capturing requirements, and a
rigorous model of distributed computation with multirate, quasi-periodic computa-
tion and communication. We have developed techniques for extracting models from
the requirements and analyzing them for generic and speciﬁc properties. We have
done some preliminary work on ontic type systems that capture the intent under-
lying data representations in order to identify bugs due to data misuse and deliver
eﬃcient arguments for the absence of such bugs. We have also developed support
for evidence generation from code analysis tools including test generators, dynamic
analyzers, and static analyzers.

We have undertaken a substantial case study of an Advanced FailSafe (AFS)
module for the ArduCopter rotorcraft that is required to execute a ﬂight mission.

126

The AFS module implements recovery mechanisms for handling failures due to GPS
Lock Loss, Battery Insuﬃciency, Ground Communication Loss, and breaches of
Altitude, Range, and Polygonal Geofences.

The elements of our approach as captured in this case study include

1. Requirements deﬁnition using CLEAR

2. Generic and speciﬁc properties of artifacts

3. Ontic types to capture the interpretation of a data representations as a URL,
IP address, (authenticated) User ID, SQL query, etc., applied in traceable
manner across the design artifacts

4. Requirements analysis using model checking (with Text2Test and Sally)

5. Logical and Physical Architecture deﬁnition (using RADL)

6. Radler Architecture properties established using a proof assistant (PVS)

7. Radler glue code for scheduling and communication, and build process

8. Code contracts for the step functions in the Radler nodes

9. Static analysis for type correctness and other speciﬁc and generic properties

10. Dynamic property checking using Randoop and Daikon on Java source code,
Text2Test on object code, and runtime safety monitoring on running systems.

We have instrumented the tools generated evidence data and metadata from this
case study for automatic ingestion into the ARCOS Rack Knowledge Base developed
by GE Research. This evidence has been employed in the construction of prototype
assurance cases by the ARCOS TA4 teams.

Our future work within the ARCOS project focuses on

1. Broader ontic type analysis with traceability from requirements to code

2. Multi-component requirements and software architecture

3. Security and Fault-tolerance properties

4. Expressive static analysis of source code components

5. Proof-carrying code infrastructure for eBPF for certifying kernel modules

6. Automated continuous assurance workﬂow spanning the design lifecycle

127

7. Incremental assurance integrated with version control

8. Assurance dashboard for monitoring repairing evidence status

9. CLEAR customizations for domain-speciﬁc operations

10. Open-source evidential marketplace for software components/libraries

To conclude, in Phase 1 of the DesCert project, we have developed the outline
of a methodology for continuous assurance using a rigorous workﬂow supported by
tools that can generate and compose semantically coherent evidence for constructing
eﬃcient assurance arguments. Current and future work is directed at demonstrating
the scalability of this approach for multi-component systems with complex safety
and security requirements.

128

Bibliography

[ard20]

ArduPilot. https://ardupilot.org/, 2020. [Online].

[BGK+18] Arianna Blasi, Alberto Goﬃ, Konstantin Kuznetsov, Alessandra Gorla,
Michael D. Ernst, Mauro Pezz`e, and Sergio Delgado Castellanos. Trans-
lating code comments to procedure speciﬁcations. In ISSTA 2018, Pro-
ceedings of the 2018 International Symposium on Software Testing and
Analysis, pages 242–253, Amsterdam, Netherlands, July 2018.

[BHM+21] Devesh Bhatt, Brendan Hall, Anitha Murugesan, Jason Biatek, Tomas
Kratochvila, Hao Ren, and Srivatsan Varadarajan. Constrained lan-
guage enhanced approach to requirements (CLEAR) user guide. Tech-
nical report, Honeywell International, ARCOS Program Tech Report,
August 2021.

[BMH+18] Devesh Bhatt, Anitha Murugesan, Brendan Hall, Hao Ren, and Yo-
gananda Jeppu. The clear way to transparent formal methods.
In
4th Workshop on Formal Integrated Development Environment - FLoC
2018, 2018.

[Bra11]

[CC77]

Aaron R Bradley. SAT-based model checking without unrolling.
In
International Workshop on Veriﬁcation, Model Checking, and Abstract
Interpretation, pages 70–87. Springer, 2011.

Patrick Cousot and Radhia Cousot. Abstract interpretation: A uniﬁed
lattice model for static analysis of programs by construction or approx-
imation of ﬁxpoints. In Proceedings of the Fourth Annual Symposium
on Principles of Programming Languages, pages 238–252, 1977.

[CDD+15] Cristiano Calcagno, Dino Distefano, J´er´emy Dubreil, Dominik Gabi,
Pieter Hooimeijer, Martino Luca, Peter O’Hearn, Irene Papakonstanti-
nou, Jim Purbrick, and Dulma Rodriguez. Moving fast with soft-
ware veriﬁcation. In NASA Formal Methods Symposium, pages 3–11.
Springer, 2015.

129

[CDNB08] Christopher L. Conway, Dennis Dams, Kedar S. Namjoshi, and
Clark W. Barrett. Pointer analysis, conditional soundness, and proving
the absence of errors. In SAS, volume 5079, pages 62–77, 2008.

[CDO15]

Cristiano Calcagno, Dino Distefano, and Peter O’Hearn. Open-sourcing
facebook infer: Identify bugs before you ship. code. facebook. com blog
post, 11, 2015.

[DDE+11a] Werner Dietl, Stephanie Dietzel, Michael D Ernst, Kivan¸c Mu¸slu, and
Todd W Schiller. Building and using pluggable type-checkers. In Pro-
ceedings of the 33rd International Conference on Software Engineering,
pages 681–690, 2011.

[DDE+11b] Werner Dietl, Stephanie Dietzel, Michael D. Ernst, Kivan¸c Muslu, and
Todd W. Schiller. Building and using pluggable type-checkers.
In
Richard N. Taylor, Harald C. Gall, and Nenad Medvidovic, editors,
Proceedings of the 33rd International Conference on Software Engineer-
ing, ICSE 2011, Waikiki, Honolulu, HI, USA, May 21-28, 2011, pages
681–690. ACM, 2011.

[DJN18a] Bruno Dutertre, Dejan Jovanovic, and Jorge A. Navas. Veriﬁcation of
fault-tolerant protocols with Sally. In Aaron Dutle, C´esar A. Mu˜noz,
and Anthony Narkawicz, editors, NASA Formal Methods - 10th In-
ternational Symposium, NFM 2018, Newport News, VA, USA, April
17-19, 2018, Proceedings, volume 10811 of Lecture Notes in Computer
Science, pages 113–120. Springer, 2018.

[DJN18b] Bruno Dutertre, Dejan Jovanovi´c, and Jorge A Navas. Veriﬁcation of
fault-tolerant protocols with sally. In NASA Formal Methods Sympo-
sium, pages 113–120. Springer, 2018.

[DoD12]

Department of Defense, Washington, DC. Military Standard MIL-STD-
882E: Department of Defense Standard Practice: System Safety, May
2012.

[EPG+07] Michael D. Ernst, Jeﬀ H. Perkins, Philip J. Guo, Stephen McCamant,
Carlos Pacheco, Matthew S. Tschantz, and Chen Xiao. The Daikon
system for dynamic detection of likely invariants. Science of Computer
Programming, 69(1–3):35–45, December 2007.

[FS17]

Brian Fitzgerald and Klaas-Jan Stol. Continuous software engineering:
A roadmap and agenda. Journal of Systems and Software, 123:176–189,
2017.

130

[GAG+19] Elazar Gershuni, Nadav Amit, Arie Gurﬁnkel, Nina Narodytska,
Jorge A. Navas, Noam Rinetzky, Leonid Ryzhyk, and Mooly Sagiv.
Simple and precise static analysis of untrusted Linux kernel extensions.
In Kathryn S. McKinley and Kathleen Fisher, editors, Proceedings of
the 40th ACM SIGPLAN Conference on Programming Language De-
sign and Implementation, PLDI 2019, Phoenix, AZ, USA, June 22-26,
2019, pages 1069–1084. ACM, 2019.

[GKKN15] Arie Gurﬁnkel, Temesghen Kahsai, Anvesh Komuravelli, and Jorge A.
Navas. The SeaHorn veriﬁcation framework. In Computer Aided Veriﬁ-
cation - 27th International Conference, CAV 2015, San Francisco, CA,
USA, July 18-24, 2015, Proceedings, Part I, pages 343–361, 2015.

[GN17]

Arie Gurﬁnkel and Jorge A. Navas. A context-sensitive memory model
for veriﬁcation of C/C++ programs.
In Francesco Ranzato, editor,
Static Analysis - 24th International Symposium, SAS 2017, New York,
NY, USA, August 30 - September 1, 2017, Proceedings, volume 10422
of Lecture Notes in Computer Science, pages 148–168. Springer, 2017.

[GN21]

Arie Gurﬁnkel and Jorge A. Navas. Abstract interpretation of LLVM
with a region-based memory model.
In Veriﬁed Software. Theories,
Tools, and Experiments - 13th International Conference, VSTTE, 2021.

[Har87]

David Harel. Statecharts: A visual formalism for complex systems.
Science of computer programming, 8(3):231–274, 1987.

[HBM+18] Brendan Hall, Devesh Bhatt, Anitha Murugesan, Ron Kilmer, Bob
Arnold, Jose Colunga, and Jon Bartling. A CLEAR adoption of ears.
In 2018 1st International Workshop on Easy Approach to Requirements
Syntax (EARS), pages 14–15. IEEE, 2018.

[HC09]

The Nimrod Review:

review into the broader

An indepen-
Charles Haddon-Cave.
dent
loss of
the RAF Nimrod MR2 Aircraft XV230 in Afghanistan in 2006.
Report, The Stationery Oﬃce, London, UK, October 2009.
Available at http://www.official-documents.gov.uk/document/
hc0809/hc10/1025/1025.pdf.

surrounding the

issues

[HK17]

Sylvain Hall´e and Rapha¨el Khoury. Event stream processing with beep-
beep 3. In RV-CuBES, pages 81–88, 2017.

131

[Hol18]

[Inc11]

[ISO11]

[JD16]

[KGC14]

[Kou17]

[KR07]

C. Michael Holloway. Understanding the overarching properties: First
steps. Technical report, Federal Aviation Administration, September
2018.

RTCA Inc. RTCA DO-178C, software considerations in airborne sys-
tems and equipment certiﬁcation, 2011.

International Organization for Standardization, Geneva, Switzerland.
Road Vehicle—Functional Safety, 2011.
ISO Standard 26262 (in 10
parts).

Dejan Jovanovi´c and Bruno Dutertre. Property-directed k-induction.
In Proceedings of the 16th Conference on Formal Methods in Computer-
Aided Design, pages 85–92. FMCAD Inc, 2016.

Anvesh Komuravelli, Arie Gurﬁnkel, and Sagar Chaki. Smt-based
model checking for recursive programs. In Computer Aided Veriﬁcation
- 26th International Conference, CAV 2014, Held as Part of the Vi-
enna Summer of Logic, VSL 2014, Vienna, Austria, July 18-22, 2014.
Proceedings, pages 17–34, 2014.

Anis Koubaa. Robot Operating System (ROS): The Complete Reference
(Volume 2). Springer Publishing Company, Incorporated, 1st edition,
2017.

Jim Krodel and G. Romanski. Real-time operating systems and compo-
nent integration considerations in integrated modular avionics systems
report. Technical Report DOT/FAA/AR-07/39, Air Traﬃc Organiza-
tion Operations Planning and Development Oﬃce of Aviation Research,
Washington, DC, 2007.

[KRC+01] S Knight, Gregg Rabideau, Steve Chien, Barbara Engelhardt, and Rob
Sherwood. Casper: Space exploration through continuous planning.
IEEE Intelligent Systems, 16(5):70–75, 2001.

[LGS15] Wenchao Li, L´eonard G´erard, and Natarajan Shankar. Design and
veriﬁcation of multi-rate distributed systems. In MEMOCODE, pages
20–29. IEEE, 2015.

[LS14]

Robin Larrieu and Natarajan Shankar. A framework for high-assurance
quasi-synchronous systems. In MEMOCODE, pages 72–83. IEEE, 2014.

132

[MRH13]

Anitha Murugesan, Sanjai Rayadurgam, and Mats PE Heimdahl.
Modes, features, and state-based modeling for clarity and ﬂexibility. In
2013 5th International Workshop on Modeling in Software Engineering
(MiSE), pages 13–17. IEEE, 2013.

[O’H18]

Peter W O’Hearn. Continuous reasoning: Scaling the impact of formal
methods. In Proceedings of the 33rd Annual ACM/IEEE Symposium
on Logic in Computer Science, pages 13–25, 2018.

[ORSvH95] Sam Owre, John Rushby, Natarajan Shankar, and Friedrich von Henke.
Formal veriﬁcation for fault-tolerant architectures: Prolegomena to the
design of PVS. IEEE Transactions on Software Engineering, 21(2):107–
125, February 1995. PVS home page: http://pvs.csl.sri.com.

[PACJ+08] Matthew M Papi, Mahmood Ali, Telmo Luis Correa Jr, Jeﬀ H Perkins,
and Michael D Ernst. Practical pluggable types for Java. In Proceedings
of the 2008 international symposium on Software testing and analysis,
pages 201–212, 2008.

[PE07]

[RBH16]

[RTC00]

[SAE96a]

[SAE96b]

Carlos Pacheco and Michael D Ernst. Randoop: feedback-directed ran-
dom testing for java. In Companion to the 22nd ACM SIGPLAN con-
ference on Object-oriented programming systems and applications com-
panion, pages 815–816, 2007.

Hao Ren, Devesh Bhatt, and Jan Hvozdovic. Improving an industrial
test generation tool using SMT solver. In NASA Formal Methods Sym-
posium, pages 100–106. Springer, 2016.

Requirements and Technical Concepts for Aviation (RTCA), Washing-
ton, DC. DO-254: Design Assurance Guidelines for Airborne Electronic
Hardware, April 2000.

Society of Automotive Engineers. Aerospace Recommended Practice
(ARP) 4754: Certiﬁcation Considerations for Highly-Integrated or
Complex Aircraft Systems, November 1996. Also issued as EUROCAE
ED-79; revised as ARP 4754A, December 2010.

Society of Automotive Engineers. Aerospace Recommended Practice
(ARP) 4761: Guidelines and Methods for Conducting the Safety As-
sessment Process on Civil Airborne Systems and Equipment, December
1996.

133

[SB14]

Daniel St˚ahl and Jan Bosch. Modeling continuous integration practice
diﬀerences in industry software development. Journal of Systems and
Software, 87:48–59, 2014.

134

