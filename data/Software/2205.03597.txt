2
2
0
2

y
a
M
7

]
E
S
.
s
c
[

1
v
7
9
5
3
0
.
5
0
2
2
:
v
i
X
r
a

Evolving Collaboration, Dependencies, and Use in
the Rust Open Source Software Ecosystem

William Schueller1,†, Johannes Wachs1,2,†, Vito D. P. Servedio1, Stefan Thurner1,3,4,*, and
Vittorio Loreto5,6,1

1Complexity Science Hub Vienna, A-1080 Vienna, Austria
2Vienna University of Economics and Business, A-1020 Vienna, Austria
3Medical University Vienna, A-1090 Vienna, Austria
4Santa Fe Institute, Santa Fe, USA
5Sony Computer Science Laboratories, 75005 Paris, France
6Physics Department, Sapienza University of Rome, 00185 Rome, Italy
*Corresponding author: stefan.thurner@meduniwien.ac.at
†These authors contributed equally to this work

ABSTRACT

Open-source software (OSS) is widely spread in industry, research, and government. OSS represents an effective development
model because it harnesses the decentralized efforts of many developers in a way that scales. As OSS developers work
independently on interdependent modules, they create a larger cohesive whole in the form of an ecosystem, leaving traces
of their contributions and collaborations. Data harvested from these traces enable the study of large-scale decentralized
collaborative work. We present curated data on the activity of tens of thousands of developers in the Rust ecosystem and
the evolving dependencies between their libraries. The data covers seven years of developer contributions to Rust libraries
and can be used to reconstruct the ecosystem’s development history, such as growing developer collaboration networks or
dependency networks. These are complemented by statistics on downloads and popularity, tracking the dynamics of use and
success over time. Altogether the data give a comprehensive view of several dimensions of the ecosystem.

Background & Summary

Open Source Software (OSS) has recently been described as the “infrastructure” of the digital society1. OSS is an excellent
example of open collaboration among many individuals that has a signiﬁcant impact on the economy2–5. Within speciﬁc OSS
ecosystems - collections of software programs or libraries usually delineated by the use of a particular programming language
like Rust, Python, or PHP - developers contribute software that depends on software already in the ecosystem, often created
by strangers. For instance, a library that generates data from probability distributions may use a random number generator
from another library rather than writing a new one. The outsourcing of core functions leads to a rich structure of technical
dependencies, often represented as a network6. These libraries are usually hosted on coding platforms like GitHub or Gitlab.
The nature of OSS contributions is such that the traces of activity of individuals are observable, i.e., what they contributed
to which libraries and when. The cumulative efforts of thousands of developers can reveal a great deal about the nature of
collaborative projects and work7. Information on the use and popular success of individual libraries can be tracked over time8,
along with the co-evolution of technical dependencies and social collaboration9. Such data can give insight into the dynamics
of massive and decentralized collaborations6 and how these digital ecosystems evolve.

Here, we present a comprehensive dataset on one such ecosystem built around the Rust programming language. Rust, a
relatively young language, has recently seen a sharp increase in popularity. Besides its signiﬁcant connections with Mozilla10,
it is, as of December 2021, the second approved language of the Linux kernel besides C. For several years now, it has been
voted the “most loved” language in the Stack Overﬂow Developer Survey1. We have collected and curated temporal data on the
technical dependencies, developer contributions, and the use and success of individual libraries. Speciﬁcally, we can observe
when a developer made an elemental contribution of code to a speciﬁc library, what other libraries that library depends on, and
how widely used and popular the library is. We record over three million distinct contributions of over 34 thousand developers,
contributing to over 31 thousand libraries over seven years.

Our data processing pipeline, available as open-source software, combines data from Cargo (the Rust ecosystem library

1https://insights.stackoverflow.com/survey/2021

 
 
 
 
 
 
Figure 1. Data processing pipeline. We collect data from Cargo, the package registry of the Rust programming language, and
complement it with data from the code hosting platforms GitHub and Gitlab. The processed result integrates information on
package dependencies, use (downloads and stars), and authors.

manager) and the code hosting platforms GitHub and Gitlab. It considers and handles a host issues common to the study of
collaborative software development data11: contributor disambiguation12, 13, bot detection14, and the identiﬁcation of nested
projects and merged work. The result is a database tracking the evolution of a large, interconnected software ecosystem at a
ﬁne scale.

In contrast to other data sources on collaborative software development, our dataset contains more accurate and complete
data for the Rust software ecosystem. Focusing on Rust allows us to integrate developer contributions with data on software
dependencies and usage. In this way, our data is richer and more focused than what can be found in more extensive databases
such as GHTorrent15, GHArchive2, Software Heritage16, or World of Code17. Moreover, as we highlight in the Technical
Validation section, we achieve a broader coverage by focusing on the Rust ecosystem: 15% of the packages in our dataset are
not in the GHTorrent database. Our dataset also requires signiﬁcantly less storage space than the sources mentioned above
and can be directly analysed by researchers with minimal computing infrastructure requirements. At the same time, Rust is a
large ecosystem that has evolved in a decentralized manner with contributions from thousands of developers hosted on multiple
platforms, differentiating it from data sourced from single projects like the Linux Kernel or Apache projects18.

We plan to update the dataset annually provided that the primary upstream sources (crates.io, GitHub & Gitlab) remain
stable. Researchers can also use our pipeline to reconstruct the dataset, a process that requires some data storage space (around
150 GB, though this volume will likely increase over time as the dataset is updated) and several days to query the data sources
and process the results. Our code can also be adapted to collect data from other ecosystems, such as the Julia programming
language’s ecosystem. However, we note that not all ecosystems offer the same scope of data as Rust.

We proceed as follows: ﬁrst, we describe our data collection and wrangling process and the resulting database. We compare
our data coverage against GHTorrent, a widely used database of OSS contributions, ﬁnding that our data is more complete.
We then outline usage notes for researchers interested in topics such as online cooperation7, 19 and collaborative innovation20,
success21, and supply chain networks22, 23 in software. Our data can easily be represented as, for example, dynamic networks of
collaborating developers, time series of usage statistics, growing networks of interdependent libraries, or combinations thereof.

2https://www.gharchive.org/

2/10

CargoDependenciesRust PackagesGitHubDownloadsDaily DumpParsed URLsGit ReposGitlabCloneCommitsAuthorsStars & ForksMergeDisambiguateID BotsFollowers, SponsorsFrom GitHub/Lab GraphQL APIMethods

We describe the data sources, and how we combine and curate data from various sources to create a comprehensive overview of
the Rust ecosystem. We provide a visual overview of the established data processing pipeline in Figure 1.

Data Sources and Collection
Cargo: Libraries and Dependencies
Our ﬁrst source of data is the Cargo package (which are called crates in the Rust community) registry. Registries, often called
package managers, play an important role in nearly all OSS ecosystems. They allow users to download and update different
libraries while resolving dependencies and managing conﬂicts. Other examples of registries around different programming
languages include PyPI for Python, CRAN for R, Rubygems for Ruby, and NPM for Node. We use Cargo as a source of
technical dependencies and downloads for Rust. These are available as part of a daily dump from crates.io3.

The data can be directly imported in a PostgreSQL database, and contains package names and creation dates, their versions,
a list of dependencies for each version with the semantic versioning (semver) syntax associated to them, and the daily downloads
per version of each package. For a relevant discussion of the importance of semantic versioning in OSS ecosystems, see recent
work by Decan and Mens24. Packages are also often associated to a repository URL and a documentation URL, but those are
not always provided and depend on maintainer input.

Code Repositories: GitHub and Gitlab
To understand who contributes to which library, we turn to the social coding platforms on which these packages are hosted. In
the case of Rust, nearly all packages in Cargo are hosted on either GitHub or Gitlab. Speciﬁcally, 63,578 packages had links
to either platform. Of these links, 44,379 were unique and 40,927 of them could be cloned from either GitHub (39,536) or
Gitlab (1,391). The inclusion of data from Gitlab represents an important extension over the most widely used databases in
OSS research GHTorrent and GH Archive, which only use data from GitHub. Both of these platforms use Git version control,
making projects hosted on either alternative comparable.

The elemental code contributions to OSS projects using the Git version control system are called commits and are associated
to an email address belonging to the contributor. GitHub and Gitlab both host Git projects (called repositories or repos, for
short), which we downloaded and used to extract information about activity and collaboration. The mapping between repos
and the libraries hosted on Cargo is not one-to-one and requires additional processing, described below. The Git version
control history of a project allows us to examine in detail the contribution histories of all developers working on a project.
Indeed, previous work has shown how this highly granular data can be exploited to study collaboration and interactions among
developers25, 26. To do so, we “clone” (download) each repo locally. We also make use of the GitHub and Gitlab GraphQL
APIs to disambiguate contributors.

Measuring Use and Success: Downloads and Stars
We quantify two dimensions of the use of libraries: the number of times they are downloaded and the number of times they
received positive social feedback (stars) on GitHub. The two metrics highlight different aspects of use. Downloads, sourced
directly from Cargo, present a more technical measurement of use. GitHub’s stars are more suggestive of visibility. For
example, a highly technical library that provides background functions may be downloaded many times but have relatively few
stars. The social aspect of GitHub and platforms is known to play an important role in collaborative software engineering27, 28.
GitHub stars and other forms of social feedback including followers and sponsors matter as information signals in the software
development community for both libraries and contributors29, 30, for example on the labour market31. We collected GitHub
stars and forks, a measure of code reuse, for repos with timestamps directly from the GitHub GraphQL API. At the developer
(GitHub/Gitlab user) level, we also collected data on the number of followers and sponsors each user has using the same API.
GitHub implemented sponsorships for developers in 201932, enabling developers to crowdfund from users who appreciate their
work directly on their GitHub pages.

Data Processing
Several additional curation steps need to be taken to insure the data collected is useful for the purposes of research into digital
collaboration. We describe three speciﬁc steps here.

Repositories, Projects, Forks
One would easily assume individual packages of the Rust ecosystem tracked by Cargo correspond one-to-one with repositories
on GitHub or Gitlab, and this is generally the case. However, some repositories host several packages. For example modules or
plugins that extend a core package are often hosted together in the same repo, but are distinguished in Cargo. This presents a
data challenge: dependencies are recorded between packages, while contributions are recorded at the repo level.

3https://crates.io/data-access

3/10

For each package listed in the registry, one or several URLs are typically provided. They correspond to a link to the code
and/or the documentation. Here, we take the URL corresponding to the code, and if empty, coalesce it with the documentation
URL. We parse the individual URLs by recognizing the preﬁxes synonyms of github.com and gitlab.com and the pattern
github.com/<owner>/<name> corresponding to a repository.

Repositories are sometimes renamed, and both URLs can be present in distinct packages. The old URL typically redirects
to the new one. To resolve this and be able to merge repositories under one entity, we use the <owner>/<name> returned by
the GraphQL API when querying about the repository, for example when collecting information about forks.

After downloading the repositories (also called cloning), we analyse the commit data and retrieve commit hash, author
email and name, and commit parents. We also compute the number of lines added and deleted for each commit. We analyse all
available branches, and the unique hash ensures that we do not count commits twice per repository. However, commits can
appear in several repositories, when one repository is a fork of another. We keep attribution of commits to each repository
where they appear, but we also attribute each commit to a main repository, supposed to be its origin. For this, we retrieve the
information about forks from the GitHub or Gitlab GraphQL API, and take as origin the highest repository in the fork tree
containing the commit. When this method is unsuccessful (e.g., undeclared forks, or forks between different Git platforms), we
take the repository having the oldest package, using its creation date from the package manager.

Dependencies
When analysing the dependencies between packages sourced from Cargo, and aggregating the network to dependencies between
repositories, we noted the presence of cycles. In this context a cycle represents a pattern like: Package A depends on Package
B, Package B depends on Package C, and Package C depends on Package A. Though there were only few of such examples, we
decided to prune dependencies to remove such cycles for two reasons. The ﬁrst is that they represent a logical inconsistency in
what dependency should mean. Second, without cycles, the resulting dependency network is a directed acyclic graph (DAG).
DAGs are themselves interesting data structures appearing in a variety of data science contexts33. Given the small number
of packages involved in cycles, we manually inspected them. Dependency cycles in package space correspond mainly to
unnecessary dependency links or even fake packages for the sake of testing dependency declarations. Repository space cycles
are more complex to prune. We adopted the heuristic to remove the dependencies (in both repo and package space) in cycles of
length 2 by pruning the dependency of the oldest node to the newest (by creation date or earliest date of the repo’s corresponding
packages), and naturally removing dependency cycles of length 1. The remaining cycles were inspected manually, and the
cycles were broken by removing the dependency links where it made more sense, in most cases from a repository having one of
the highest download counts to one having one of the lowest. One remaining repository, although corresponding to numerous
downloads, has been pruned from all dependencies to it because of the high number of cycles of the dependency network
involving it. We included these pruned dependencies in the dataset for the sake of completeness, but we ﬂagged them for easy
removal, or for letting the possibility to investigate other link removal policies. We guarantee absence of cycles for the state
of the dependency network at the end of the dataset (2022-03-14) and at the end of the preceding year (2021-12-31) in both
spaces, but not at any arbitrary timestamp.

Merging of Developer Identities
There are many potential ways to disambiguate the identities of contributors12, 13, each presenting tradeoffs. In general, Git
commits are signed by an email address, not a platform-speciﬁc username. Developers often commit code from different
computers or environments with different email addresses in their conﬁguration ﬁles, and this can result in a signiﬁcant
disambiguation problem. Rather than attempting to infer which email addresses potentially refer to the same person, we query
the GitHub API for the GitHub account linked to each commit34. While this ignores the potential that developers use multiple
accounts, we argue that it makes a larger amount of highly justiﬁable merges among commit author identities than an email
address based approach. Email address-based author identity disambiguation would scale better in larger systems at the cost of
accuracy.

For each email address, we carry out this process for the most recent commit registered for that email, and if this
fails to return an account, we try again with a randomly sampled commit among all those corresponding to this email.
After doing the same for Gitlab, we also merge matching GitHub and Gitlab logins 84. An additional step is to parse the
emails and discard obviously belonging to GitHub, following the patterns <login>@users.noreply.github.com or
<randomint>+<login>@users.noreply.github.com.

Bot Accounts
Bots play an important role in modern software development35, 36, but need to be handled with care in any study of software
systems, as they can make orders of magnitude more contributions than any human developer. Ignoring them would skew
any analysis of cooperation between human developers11, 14. While bots have interesting effects on project evolution35, we
chose to detect and mark bots and more generally invalid accounts in our dataset with a view to excluding them as we are

4/10

Description
Parenthood relationships between commits. Typically one parent/commit.
The repos to which commits belong. At least one, but can be several (via forks).
Metadata about speciﬁc commits
Packages which are ﬁltered when appearing as a dependency to avoid cycles

Table Name
commit_parents
commit_repos
commits
filtered_deps_package
filtered_deps_packageedges Edges between packages directly discarded in the dependency graph
filtered_deps_repo
filtered_deps_repoedges
followers
forks
identities
identity_types
issues
merged_identities
merged_repositories
package_dependencies
package_version_downloads
package_versions
packages
repo_languages
repositories
sources
sponsors_user
stars
urls
user_languages
users

Repositories which are ﬁltered when appearing as a dependency to avoid cycles
Edges between repositories directly discarded in the dependency graph
Followers of GitHub accounts
Forks declared on GitHub
Individual identities of developers (email, GitHub account, Gitlab account; hashed)
Identity types (email, GitHub account, Gitlab account)
Issues per repository
Identities that have been merged
Repositories that have been merged (after identifying renaming or typo in URL)
Package dependencies (version to package with semver)
Daily downloads of package versions
Versions of packages
Packages
Language composition of repositories, as reported by GitHub
Repositories
Data sources
Sponsorships of developers
Starring events of repositories
Retrieved URLs, and their parsed equivalent
Language composition of GitHub user contributions (beyond the dataset)
Users (who can have several identities: email, GitHub, Gitlab)

Table 1. Table of tables in the database. A full database schema is available on Figshare:
https://figshare.com/s/93158d03416765444650.

primarily interested in the patterns of contributions of developers. To identify bots, we used a two-step ﬁltering process. First,
we extracted all bots on a curated list used as ground truth for bot detection in the software engineering community14. We then
ﬁltered remaining Github accounts with the substrings “*[bot]”, “*-bot”,“*-bors”,“bors-*”,“dependabot-*” in their usernames,
and ﬁnally inspecting manually each individual account with pattern “*bot*”. After ﬁltering out bot accounts labelled this
way, a manual inspection of the 100 most active remaining accounts was conducted, as well as of all accounts containing the
substring “bot”. The manual inspection took the following steps: checking the GitHub webpage of a user for a clear name,
looking at the description, looking at the commit/PR comments. The 100 most active accounts by number of commits across
the full timespan of the dataset were considered, as well the 100 most active accounts in the year 2020.

For users that could not be associated to a GitHub account, their emails are ﬁltered when the last part of their preﬁx
(separated by ., - or +) is equal to “bot”, “ghbot”, “bors”, “travis” or “bot”. A few remaining email strings without “@” were
discarded, like “localhost”, “N/A” or empty string. Manual inspection of the most active 100 emails without a GitHub account
revealed a few more bots. The list of manually discarded bots is available in the ﬁle botlist.csv. Our dataset includes the
bots among the users, ﬂagged with a Boolean “is_bot” attribute to enable ﬁltering.

Data Records

We host our data on Figshare and the code used to collect and process the data from our sources on GitHub. Both platforms
track the history of the data and code, allowing researchers to use any version they prefer as we continue to update and extend
both. We share data in several formats, noting that in no format does the data exceed 5 GB when compressed.

Before we describe the data, we discuss data pseudoanymisation. To preserve developer privacy, we provide data that is
scrubbed of information that can directly be used to identify individuals. We do so in the following way: we discard name
attributes and hash (via MD5 with a random salt) email address preﬁxes and GitHub/Gitlab logins. Researchers interested in
studying social or demographic characteristics of developers, such as gender37, 38, geography39–41, or both42, could adapt our
approach to data collection and analyse these attributes. However, they should consider potential ethical issues that arise when

5/10

Figure 2. Data coverage: we check the number of Rust packages for which we could identify and download a corresponding
Git repo (from GitHub or Gitlab) in terms of their use, measured in downloads. We could link a large majority of packages to
repos, and have a signiﬁcantly higher success rate if we consider packages that have been downloaded more often.

associating such information to users43.

We now proceed to describe the tables in the database. In Table 1, we list the tables in the database along with a description
of their content and purpose. For the sake of brevity, we refer the reader to the accompanying materials on Figshare for a
schema of the database and a description of the variables included.

Technical Validation

In this section, we report statistics on the completeness of our data. An advantage of deﬁning the Rust ecosystem as all those
packages hosted on Cargo, is that we can precisely measure how many packages we can successfully integrate into our database.
In particular, we can report the share of packages that we can connect to repos on the social coding platforms GitHub and
Gitlab. As we will see below, we have a very high rate of linkage. Moreover, the packages that we could not integrate are
typically those with very few downloads. This suggests that most projects on Cargo that do not appear on GitHub or Gitlab are
small personal projects or preliminary work.

Package Coverage among Repositories
Some Rust packages hosted on Cargo could not be linked to repos on GitHub or Gitlab. They either are on a different platform,
for example on Bitbucket, Google Cloud, Sourceforge, or on personal websites. Still others had a link to a GitHub or Gitlab
domain (i.e. a repo) but could not be cloned. This can happen if a link was incorrectly transcribed, if the repo was deleted, or
if the package is listed only for name squatting or test purposes and does not correspond to any repository. Speciﬁcally, out
of 78,935 packages, 63,578 were linked to a repository on GitHub or Gitlab and 59,106 of these were successfully cloned,
although only 44,379 packages pointed to distinct URLs (and 40,927 were cloned). Hypothesizing that the most important
packages are the most downloaded ones, we can see in Figure 2 that our coverage increases among the most important packages,
measured by use (downloads).

Across the cloned repos, we gathered 4,921,359 commits, the elemental units of contribution in the git version control
system. Excluding 162 bots identiﬁed among the GitHub accounts, these contributions were made by 51,663 GitHub users
and 440 Gitlab users. The raw data contains 78,197 identifying email addresses, highlighting the signiﬁcant amount of
disambiguation of author identities our pipeline implements. 12,051 of them could not be associated to a GitHub or Gitlab
account.

Comparison with data from GHTorrent
We compared our data with data collected in the GHTorrent project15. The GHTorrent project aims to collect all activity on
GitHub for use in research. As we have already noted, most activity in the Rust ecosystem takes place on GitHub, with a small
but signiﬁcant share taking place on Gitlab. Besides the inclusion of Gitlab data, we observed that our data contains a signiﬁcant
amount of activity hosted on GitHub that is missing from the GHTorrent database (the SQL version), when comparing the
data in our dataset tagged as happening before the last date of user creation in the GHTorrent database – May 31st 2019, just
before midnight – and corresponding to the repositories that could be cloned. Speciﬁcally, we found only 14,596 unique users
(vs. 22,066 GitHub users in our database), 13,68616,608 unique repos (vs 15,992 identiﬁed GitHub repos in our database),
and 1,315,396 unique commits (vs 1,934,310 GitHub hosted commits in our database before the last date of GHTorrent). The

6/10

Figure 3. Illustrative plots from demonstration notebooks indicating potential data-processing workﬂows. A) Average number
of dependencies per package at the beginning of each year. B) Evolution of the number of transitive dependencies per package.
C) The dependency network of the 100 most downloaded Rust packages in early 2022. D) Time series of monthly downloads
of three successful Rust packages. E) Bipartite adjacency matrix of users/developers and the repos they work on in the year
2021, lightly ﬁltered. F) Developer-developer collaboration network in 2021. G) Developer-developer collaboration network,
ﬁltered for developers collaborating on at least three repos.

GHTorrent project uses the GitHub REST API and collects data from the public event timeline using user-donated API keys.
Outages on either the GHTorrent side or on the GitHub REST API, or rate limited API keys may explain missing data. While
GHTorrent remains an excellent source of dataset for all of GitHub, these comparisons suggests that for a focused look at
a single ecosystem, a customised pipeline can signiﬁcantly increase data coverage. More detailed statistics concerning the
comparison can be found on Figshare in the ﬁle ghtorrent_comparison.yml.

Usage Notes

To demonstrate how to read in and analyse the database, we provide short Jupyter notebooks that extract data and carry out
elementary data manipulations, with the data aggregated at the monthly level. These notebooks are included with the other
software in our materials. In one, we create the dependency network of the Rust ecosystem at different times and measure its
growth. This data can be used to study ecosystem health, as errors and issues are known to spread through these networks6. In
another, we plot the time series of stars and downloads of speciﬁc repositories over time. Such time series can be used to study
the dynamics of success at a ﬁne-grained level8. In a third, we show how to load in the data of developers and packages as a
rectangular matrix, which can be analysed as a bipartite network or, after a projection, as a developer-developer collaboration
network. The bipartite network could be used to study the overall complexity of the ecosystem44, 45, while the developer
network reveals patterns of collaborations between projects46. In Figure 3 we present several illustrative examples of descriptive
analyses resulting from the demonstration notebooks.

These vignettes together indicate how this dataset can be used to explore the interactions between social collaboration,
technical dependencies, and the success and usage of components of a large software system. The dynamic interactions
between these layers of the data offer signiﬁcant potential for research relating to massive decentralized cooperation (similar to
Wikipedia47, 48), the dynamics of teams and their success in digital communities21, and the evolution of software systems49.

Code availability

Code to recreate the database is included in our Figshare upload: https://figshare.com/s/93158d03416765444650.
The software is written in the Python programming language. The database can be created as either PostgreSQL or SQLite
database. Version requirements are recorded in the project’s Readme ﬁle.

7/10

Acknowledgements

The extraction and construction of the database has been partially funded by Sony Computer Science Laboratories Paris under
a dedicated contract with the Complexity Science Hub Vienna. This work has also been partially supported by the Austrian
Research Promotion Agency FFG project # 882184: CSH-Fortsetzung. The authors thank Amélie Desvars-Larrive for advice
regarding the manuscript.

Author contributions statement

WS, JW, VDPS, VL, ST coordinated the production of the dataset. WS designed the database schema, created the tables, and
carried out the dataset validation checks. JW implemented the exploratory analyses and demonstrations. VL and ST supervised
and mentored the team. All authors contributed to writing the data descriptor.

Competing interests

The authors declare no competing interests.

References

1. Eghbal, N. Working in public: The making and maintenance of open source software (Stripe Press, 2020).

2. Lerner, J. & Tirole, J. Some simple economics of open source. The J. Ind. Econ. 50, 197–234 (2002).

3. Greenstein, S. & Nagle, F. Digital dark matter and the economic contribution of Apache. Res. Policy 43, 623–631 (2014).

4. Nagle, F. Learning by contributing: Gaining competitive advantage through contribution to crowdsourced public goods.

Organ. Sci. 29, 569–587 (2018).

5. Nagle, F. Open source software and ﬁrm productivity. Manag. Sci. 65, 1191–1215 (2019).

6. Decan, A., Mens, T. & Grosjean, P. An empirical comparison of dependency network evolution in seven software packaging

ecosystems. Empir. Softw. Eng. 24, 381–416 (2019).

7. Zöller, N., Morgan, J. H. & Schröder, T. A topology of groups: What github can tell us about online collaboration. Technol.

Forecast. Soc. Chang. 161, 120291 (2020).

8. Sinatra, R., Wang, D., Deville, P., Song, C. & Barabási, A.-L. Quantifying the evolution of individual scientiﬁc impact.

Science 354, aaf5239 (2016).

9. Cataldo, M., Herbsleb, J. D. & Carley, K. M. Socio-technical congruence: a framework for assessing the impact of technical
and work dependencies on software development productivity. In Proceedings of the Second ACM-IEEE international
symposium on Empirical software engineering and measurement, 2–11 (2008).

10. Jung, R., Jourdan, J.-H., Krebbers, R. & Dreyer, D. Safe systems programming in rust. Commun. ACM 64, 144–152

(2021).

11. Kalliamvakou, E. et al. An in-depth study of the promises and perils of mining GitHub. Empir. Softw. Eng. 21, 2035–2071

(2016).

12. Fry, T., Dey, T., Karnauch, A. & Mockus, A. A dataset and an approach for identity resolution of 38 million author ids
extracted from 2b git commits. In Proceedings of the 17th international conference on mining software repositories,
518–522 (2020).

13. Gote, C. & Zingg, C. gambit–An Open Source Name Disambiguation Tool for Version Control Systems.
IEEE/ACM 18th International Conference on Mining Software Repositories (MSR), 80–84 (IEEE, 2021).

In 2021

14. Golzadeh, M., Decan, A., Legay, D. & Mens, T. A ground-truth dataset and classiﬁcation model for detecting bots in

GitHub issue and PR comments. J. Syst. Softw. 175, 110911 (2021).

15. Gousios, G. & Spinellis, D. Ghtorrent: Github’s data from a ﬁrehose. In 2012 9th IEEE Working Conference on Mining

Software Repositories (MSR), 12–21 (IEEE, 2012).

16. Pietri, A., Spinellis, D. & Zacchiroli, S. The software heritage graph dataset: public software development under one roof.
In 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), 138–142 (IEEE, 2019).

17. Ma, Y., Bogart, C., Amreen, S., Zaretzki, R. & Mockus, A. World of code: an infrastructure for mining the universe of
open source vcs data. In 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), 143–154
(IEEE, 2019).

8/10

18. Roberts, J. A., Hann, I.-H. & Slaughter, S. A. Understanding the motivations, participation, and performance of open

source software developers: A longitudinal study of the apache projects. Manag. science 52, 984–999 (2006).

19. Szell, M. & Thurner, S. Measuring social dynamics in a massive multiplayer online game. Soc. networks 32, 313–329

(2010).

20. Monechi, B., Pullano, G. & Loreto, V. Efﬁcient team structures in an open-ended cooperative creativity experiment. Proc.

Natl. Acad. Sci. 116, 22088–22093 (2019).

21. Klug, M. & Bagrow, J. P. Understanding the group dynamics and success of teams. Royal Soc. open science 3, 160007

(2016).

22. Ma, Y. Constructing supply chains in open source software. In 2018 IEEE/ACM 40th International Conference on Software

Engineering: Companion (ICSE-Companion), 458–459 (IEEE, 2018).

23. Ohm, M., Plate, H., Sykosch, A. & Meier, M. Backstabber’s knife collection: A review of open source software supply
chain attacks. In International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment, 23–43
(Springer, 2020).

24. Decan, A. & Mens, T. What do package dependencies tell us about semantic versioning? IEEE Transactions on Softw.

Eng. 47, 1226–1240 (2019).

25. Scholtes, I., Mavrodiev, P. & Schweitzer, F. From Aristotle to Ringelmann: a large-scale analysis of team productivity and

coordination in Open Source Software projects. Empir. Softw. Eng. 21, 642–683 (2016).

26. Gote, C., Scholtes, I. & Schweitzer, F. git2net-mining time-stamped co-editing networks from large git repositories. In

2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), 433–444 (IEEE, 2019).

27. Dabbish, L., Stuart, C., Tsay, J. & Herbsleb, J. Social coding in GitHub: transparency and collaboration in an open software
repository. In Proceedings of the ACM 2012 conference on computer supported cooperative work, 1277–1286 (2012).

28. Marlow, J., Dabbish, L. & Herbsleb, J. Impression formation in online peer production: activity traces and personal proﬁles

in GitHub. In Proceedings of the 2013 conference on Computer supported cooperative work, 117–128 (2013).

29. Borges, H. & Valente, M. T. What’s in a GitHub star? Understanding repository starring practices in a social coding

platform. J. Syst. Softw. 146, 112–129 (2018).

30. Moldon, L., Strohmaier, M. & Wachs, J. How gamiﬁcation affects software developers: Cautionary evidence from a natural
experiment on GitHub. In 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE), 549–561
(IEEE, 2021).

31. Papoutsoglou, M., Ampatzoglou, A., Mittas, N. & Angelis, L. Extracting knowledge from on-line sources for software

engineering labor market: A mapping study. IEEE Access 7, 157595–157613 (2019).

32. Shimada, N., Xiao, T., Hata, H., Treude, C. & Matsumoto, K. Github sponsors: Exploring a new way to contribute to open

source. arXiv preprint arXiv:2202.05751 (2022).

33. Corominas-Murtra, B., Goñi, J., Solé, R. V. & Rodríguez-Caso, C. On the origins of hierarchy in complex networks. Proc.

Natl. Acad. Sci. 110, 13316–13321 (2013).

34. Montandon, J. E., Silva, L. L. & Valente, M. T. Identifying experts in software libraries and frameworks among GitHub
users. In 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), 276–287 (IEEE, 2019).

35. Wessel, M. et al. The power of bots: Characterizing and understanding bots in OSS projects. Proc. ACM on Human-

Computer Interact. 2, 1–19 (2018).

36. Wessel, M. et al. Bots for pull requests: The good, the bad, and the promising. In Proceedings of the 44th ACM/IEEE

International Conference on Software Engineering (ICSE’22), vol. 26, 16 (ACM/IEEE, 2022).

37. Vasilescu, B. et al. Gender and tenure diversity in github teams. In Proceedings of the 33rd annual ACM conference on

human factors in computing systems, 3789–3798 (2015).

38. Rossi, D. & Zacchiroli, S. Worldwide gender differences in public code contributions: and how they have been affected by
the covid-19 pandemic. In 2021 IEEE/ACM 44th International Conference on Software Engineering (ICSE) (2022).

39. Rastogi, A., Nagappan, N., Gousios, G. & van der Hoek, A. Relationship between geographical location and evaluation of
developer contributions in GitHub. In Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software
Engineering and Measurement, 1–8 (2018).

40. Braesemann, F., Stoehr, N. & Graham, M. Global networks in collaborative programming. Reg. Studies, Reg. Sci. 6,

371–373 (2019).

9/10

41. Wachs, J., Nitecki, M., Schueller, W. & Polleres, A. The Geography of Open Source Software: Evidence from GitHub.

Technol. Forecast. Soc. Chang. 176, 121478 (2022).

42. Prana, G. A. A. et al.

Including everyone, everywhere: Understanding opportunities and challenges of geographic

gender-inclusion in OSS. IEEE Transactions on Softw. Eng. (2021).

43. Gousios, G. & Spinellis, D. Mining software engineering data from GitHub. In 2017 IEEE/ACM 39th International

Conference on Software Engineering Companion (ICSE-C), 501–502 (IEEE, 2017).

44. Hidalgo, C. A. & Hausmann, R. The building blocks of economic complexity. Proc. national academy sciences 106,

10570–10575 (2009).

45. Servedio, V. D. P., Buttà, P., Mazzilli, D., Tacchella, A. & Pietronero, L. A new and stable estimation method of country

economic ﬁtness and product complexity. Entropy 20, 783 (2018).

46. Singh, P. V. The small-world effect: The inﬂuence of macro-level properties of developer collaboration networks on

open-source project success. ACM Transactions on Softw. Eng. Methodol. (TOSEM) 20, 1–27 (2010).

47. Brandes, U., Kenis, P., Lerner, J. & Van Raaij, D. Network analysis of collaboration structure in wikipedia. In Proceedings

of the 18th international conference on World wide web, 731–740 (2009).

48. Mestyán, M., Yasseri, T. & Kertész, J. Early prediction of movie box ofﬁce success based on wikipedia activity big data.

PloS one 8, e71226 (2013).

49. Solé, R. & Valverde, S. Evolving complexity: how tinkering shapes cells, software and ecological networks. Philos.

Transactions Royal Soc. B 375, 20190325 (2020).

10/10

