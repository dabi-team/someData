2
2
0
2

n
u
J

4

]

G
L
.
s
c
[

1
v
9
0
9
1
0
.
6
0
2
2
:
v
i
X
r
a

Toward Learning Robust and Invariant Representations with
Alignment Regularization and Data Augmentation

Haohan Wang
Carnegie Mellon University
Pittsburgh, PA, USA
haohanw@cs.cmu.edu

Xindi Wu
Carnegie Mellon University
Pittsburgh, PA, USA
xindiw@andrew.cmu.edu

Zeyi Huang
University of Wisconsin-Madison
Madison, WI, USA
zeyih@andrew.cmu.edu

Eric P. Xing
Carnegie Mellon University
Pittsburgh, PA, USA
epxing@cs.cmu.edu

ABSTRACT
Data augmentation has been proven to be an eï¬€ective technique
for developing machine learning models that are robust to known
classes of distributional shifts (e.g., rotations of images), and align-
ment regularization is a technique often used together with data
augmentation to further help the model learn representations in-
variant to the shifts used to augment the data. In this paper, mo-
tivated by a proliferation of options of alignment regularizations,
we seek to evaluate the performances of several popular design
choices along the dimensions of robustness and invariance, for
which we introduce a new test procedure. Our synthetic exper-
iment results speak to the beneï¬ts of squared â„“2 norm regular-
ization. Further, we also formally analyze the behavior of align-
ment regularization to complement our empirical study under as-
sumptions we consider realistic. Finally, we test this simple tech-
nique we identify (worst-case data augmentation with squared â„“2
norm alignment regularization) and show that the beneï¬ts of this
method outrun those of the specially designed methods. We also
release a software package in both TensorFlow and PyTorch for
users to use the method with a couple of lines1.

CCS CONCEPTS
â€¢ Computing methodologies â†’ Regularization; Computer vi-
sion; Supervised learning.

KEYWORDS
machine learning, data augmentation, robustness, trustworthy

ACM Reference Format:
Haohan Wang, Zeyi Huang, Xindi Wu, and Eric P. Xing. 2022. Toward
Learning Robust and Invariant Representations with Alignment Regular-
ization and Data Augmentation. In Proceedings of the 28th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (KDD â€™22), August

1https://github.com/jyanln/AlignReg

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proï¬t or commercial advantage and that copies bear this notice and the full citation
on the ï¬rst page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
KDD â€™22, August 14â€“18, 2022, Washington, DC, USA
Â© 2022 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-9385-0/22/08.
https://doi.org/10.1145/3534678.3539438

14â€“18, 2022, Washington, DC, USA. ACM, New York, NY, USA, 13 pages.
https://doi.org/10.1145/3534678.3539438

1 INTRODUCTION
Data augmentation, i.e., to increase the dataset size through gener-
ating new samples by transforming the existing samples with some
predeï¬ned functions, is probably one of the most often used tech-
niques to improve a machine learning modelâ€™s performance. It has
helped machine learning models achieve high prediction accuracy
over various benchmarks [e.g., 8, 19, 31, 38, 42, 70].

In addition to improving prediction accuracy, the community
has also leveraged data augmentation to help the models learn
more robust representations that can generalize to the datasets dis-
tributed diï¬€erently [e.g., 32, 45, 51, 69]. To improve robustness, the
community usually designed the transformation functions used to
augment the data in correspondence to the transformations we see
in the real world [28], such as the changes of image texture or con-
trast. Thus, models trained with these augmented data are more
likely to be invariant to these designed transformations, such as
the texture or contrast variations of the input images.

To further help a model learn representations invariant to the
transformations, we can regularize the model so that the distance
between representations learned by the model from a pair of data
(the original one and the transformed counterpart) will be small.
This regularization has been used extensively recently to help mod-
els learn more robust and invariant representations [e.g., 26, 36, 40,
65]. Motivated by this popularity, this paper mainly studies the
behaviors of this regularization, which we refer to as alignment
regularization (AR). In particular, we seek to answer the question:
how should we use alignment regularization to take advantage of the
augmented data to the fullest extent to learn robust and invariant
models?

To answer this, we ï¬rst conduct a range of experiments over im-
age classiï¬cation benchmarks to evaluate how popular variants of
AR contribute to learning robust and invariant models. We test for
accuracy, robustness, and invariance, for which we propose a new
test procedure. Our empirical study favors the squared â„“2 norm.
Our contributions of this paper are as follows.

 
 
 
 
 
 
KDD â€™22, August 14â€“18, 2022, Washington, DC, USA

Wang, et al.

â€¢ With a new invariance test, we show that alignment regulariza-
tion is important to help the model learn representations invari-
ant to the transformation function, and squared â„“2 norm is con-
sidered the favorable choice as assessed by a variety of empirical
evaluations (Section 4).

â€¢ We formalize a generalization error bound for models trained

with AR and augmented data (Section 5).

â€¢ We test the method we identiï¬ed (squared â„“2 norm as AR) in
multiple scenarios. We notice that this generic approach can
compete with methods specially designed for diï¬€erent scenarios,
which we believe endorses its empirical strength (Section 6).

2 RELATED WORK AND KEY DIFFERENCES
Tracing back to the earliest convolutional neural networks, [60],
we notice that even early models for the MNIST dataset have been
boosted by data augmentation [1, 39, 50]. Later, the rapidly grow-
ing machine learning community has seen a proliferate develop-
ment of data augmentation techniques that have helped models
climb the state-of-the-art ladder [49]. Among the augmentation
techniques, the most relevant one to this paper is to generate the
samples (with constraint) that maximize the training loss along
with training [16].

While the above paragraph mainly discusses how to generate
the augmented samples, we mainly study how to train the models
with augmented samples. For example, instead of directly mixing
augmented samples with the original samples, one can consider
regularizing the representations (or outputs) of original samples
and augmented samples to be close under a distance metric (which
we refer to as alignment regularization, AR). Many concrete ideas
have been explored in diï¬€erent contexts. For example, â„“2 distance
and cosine similarities between internal representations in speech
recognition [40], squared â„“2 distance between logits [36], or KL
divergence between softmax outputs [65] in adversarially robust
vision models, Jensenâ€“Shannon divergence (of three distributions)
between embeddings for texture invariant image classiï¬cation [26].
These are but a few highlights of the concrete and successful imple-
mentations for diï¬€erent applications out of a vast collection (e.g.,
[4, 24, 47, 48, 62, 63, 68, 69]), and we can expect methods permuting
these three elements (distance metrics, representation or outputs,
and applications) to be discussed in the future. Further, given the
popularity of GAN [21] and domain adversarial neural network
[17], we can also expect the distance metric generalizes to a spe-
cialized discriminator (i.e., a classiï¬er), which can be intuitively
understood as a calculated (usually maximized) distance measure,
and one example here is the Wasserstein-1 metric [3, 23].

Key Diï¬€erences: With this rich collection of regularizing choices,

which one method should we consider in general? More impor-
tantly, do we need the regularization at all? These questions are
important for multiple reasons, especially since sometimes AR may
worsen the results [35]. In this paper, we ï¬rst conduct an empirical
study to show that AR (especially squared â„“2 norm) can help learn
robust and invariant models, we then also derive generalization
error bounds to complement our empirical conclusion.

There are also several previous discussions regarding the de-
tailed understandings of data augmentation [10, 15, 20, 30, 46, 64,

66], among which, [64] is probably the most relevant as it also de-
fends the usage of the AR. In addition to what is reported in [64],
our work also connects to invariance and shows that another ad-
vantage of AR is to learn invariant representations.

3 ACCURACY, ROBUSTNESS, AND

INVARIANCE

This section discusses the three major evaluation metrics we will
use to test AR. We will ï¬rst recapitulate the background of accu-
racy and robustness. Then we will introduce our deï¬nition of in-
variance and our proposed evaluation.

Notations (X, Y) denotes the data, where X âˆˆ Rğ‘›Ã—ğ‘ and Y âˆˆ
{0, 1}ğ‘›Ã—ğ‘˜ (one-hot vectors for ğ‘˜ classes). (x, y) denotes a sample.
ğ‘“ (, ğœƒ) denotes the model, which takes in the data and outputs the
softmax (probabilities of the prediction) and ğœƒ denotes the corre-
sponding parameters. ğ‘”() completes the prediction (i.e., mapping
softmax to one-hot prediction). ğ‘() denotes a function for data aug-
mentation, i.e., a transformation function. ğ‘ âˆˆ A, which is the
set of transformation functions of interest. P denotes the distribu-
tion of (x, y). For any sampled (x, y), we can have (ğ‘(x), y), and
we use Pğ‘ to denote the distribution of these transformed samples.
ğœƒ ) for
Further, we use Q
(x, y) âˆ¼ P. ğ· (Â·, Â·) is a distance measure over two distributions. ğ‘Ÿ (ğœƒ)
Â· denotes the estimation of the term Â·,
denotes the risk of model ğœƒ.
e.g.,

ğœƒ ) denotes the empirical risk of the estimated model.

to denote the distribution of ğ‘“ (ğ‘(x);

ğ‘ (x),
ğœƒ

b

b

ğ‘ŸP (

b

b

b
3.1 Accuracy
The community studying the statistical property of the error bound
usually focuses on the expected risk deï¬ned as

ğ‘ŸP (

ğœƒ) = E(x,y)âˆ¼P
b

I[ğ‘”(ğ‘“ (x;

ğœƒ )) â‰  y],

(1)

where I[c] is a function that returns 1 if the condition c holds.

b

In practice, the error is evaluated by replacing P with a hold-out

test dataset, and the accuracy is 1 âˆ’ ğ‘ŸP (

ğœƒ ).

3.2 Robustness
We deï¬ne robustness as the worst-case expected risk when the test
data is allowed to be transformed by functions in A, following [e.g.,
22, 52]. Formally, we study the worst-case error as

b

ğ‘ŸP,A (

ğœƒ ) = E(x,y)âˆ¼P max
ğ‘âˆ¼A
b

b

I[ğ‘”(ğ‘“ (ğ‘(x);

ğœƒ )) â‰  y],

(2)

where we use ğ‘ŸP,A (
ğœƒ ) to denote the robust error as it will depend
on A. In practice, the robust error is also evaluated by replacing P
with a hold-out dataset.

b

3.3 Invariance
Further, high robustness performances do not necessarily mean the
model is truly invariant to the transformation functions [29], and
we continue to introduce a new test to evaluate the modelâ€™s behav-
ior in learning representations invariant to the transformations.

Invariance. If the model can learn a representation invariant to
the transformation functions, it will map the samples of diï¬€erent
transformations to the same representation. Intuitively, to measure

Toward Learning Robust and Invariant Representations with Alignment Regularization and Data Augmentation

KDD â€™22, August 14â€“18, 2022, Washington, DC, USA

how invariant a model is to the transformations in A, we can cal-
culate the distances between each pair of the two transformed sam-
ples when a sample is transformed with functions in A. Thus, we
deï¬ne the following term to measure invariance:

ğ¼P,A (

ğœƒ) = sup

ğ‘1,ğ‘2 âˆˆA

b

ğ· (Q

ğ‘1 (x),
ğœƒ

, Q

ğ‘2 (x),
ğœƒ

),

(3)

b

b

We suggest using Wasserstein metric as ğ· (Â·, Â·), considering its fa-
vorable properties (e.g., see practical examples in Figure 1 of [14]
or theoretical discussions in [57]).

In practice, we also need to replace P with a hold-out dataset so
that the evaluation can be performed. In addition, we notice that
ğ¼P,A (
ğœƒ ), although intuitive, is not convenient in practice because
the evaluated values are not bounded. Thus, we reformulate it into
the following invariance test procedure, whose ï¬nal score will be
bounded between 0 and 1 (the higher, the better). Therefore, the
score can be conveniently discussed together with accuracy and
robust accuracy, which are also bounded between 0 and 1.

b

ğ‘2 , . . . , X(ğ‘–)

Invariance test. Given a family of transformation functions used
in data augmentation A = {ğ‘1(), ğ‘2 (), . . . , ğ‘ğ‘¡ ()} of ğ‘¡ elements, and
a collection of samples (from the hold-out dataset) of the same la-
bel ğ‘–, denoted as X(ğ‘–) , the evaluation procedure is as follows. We
ï¬rst generate the transformed copies of X(ğ‘–) with A, resulting in
X(ğ‘–)
ğ‘1 , X(ğ‘–)
ğ‘ğ‘¡ . We combined these copies into a dataset, de-
noted as X (ğ‘–) . For every sample x in X (ğ‘–) , we retrieve its ğ‘¡ nearest
neighbors of other samples in X (ğ‘–), and calculate the overlap of
the retrieved samples with the transformed copies of x by A, i.e.,
{ğ‘1 (x), ğ‘2 (x), . . . , ğ‘ğ‘¡ (x)}. The calculated overlap score will be in
[0, 1] in general, but since the identity map is usually in A, this
score will usually be in [1/ğ‘¡, 1].

During the retrieval of nearest neighbors, we consider the dis-

tance function of the two samples (namely x and xâ€²) as

ğ‘‘ (ğ‘“ (x;

ğœƒ ), ğ‘“ (xâ€²;

ğœƒ ))

b
ğœƒ is the model we are interested in examining. In the em-
, where
pirical study later, we consider ğ‘‘ (u, v) = ku âˆ’ vk1, with u and v
denoting two vectors. If we use other distance functions, the re-
ported values may diï¬€er, but we notice that the rank of the meth-
ods compared in terms of this test barely changes.

b

b

Finally, we iterate through label ğ‘– and report the averaged score
for all the labels as the ï¬nal score. A higher score indicates the
model

ğœƒ is more invariant to the transformation functions in A.
This invariance test procedure is formally presented in Algo-

b
rithm 1 below.

4 EMPIRICAL STUDY
In this section, we conduct experiments to study the relationship
between robustness and invariance, as well as how training with
AR can help improve the invariance score. In short, our empirical
study in this section will lead us to the following three major con-
clusions:

â€¢ High robust accuracy does not necessarily mean a high invari-

ance score and vice versa.

â€¢ AR can help improve the invariance score.

Algorithm 1: Invariance test

ğ¼ (

ğœƒ )

Result:
Input: a family of transformation functions A = {ğ‘1 (), ğ‘2 (), . . . , ğ‘ğ‘¡ () }, a hold-out

b

b

dataset (X, Y) , the model of interest

ğœƒ , and a distance metric ğ‘‘ () ;

for every label ğ‘– do

identify all the samples from (X, Y) with label ğ‘–, name this set of samples X(ğ‘–) ;
for every ğ‘ () âˆˆ A do
generate X

(ğ‘–)
ğ‘ by applying ğ‘ () to every x âˆˆ X(ğ‘–) ;

b

end
(ğ‘–)
X (ğ‘–) = X
ğ‘1
for every x âˆˆ X(ğ‘–) do

(ğ‘–)
ğ‘2

âˆª X

âˆª, . . . , âˆªX

(ğ‘–)
ğ‘ğ‘¡ ;

generate set ğ‘‡ = {ğ‘1 (x), ğ‘2 (x), . . . , ğ‘ğ‘¡ (x) };
for every xâ€² âˆˆ X (ğ‘–) do

calculate the distance between x and xâ€² with ğ‘‘ ( ğ‘“ (x;

ğœƒ ), ğ‘“ (xâ€²;

ğœƒ )) ;

end
b
retrieve the ğ‘¡ nearest neighbors of x out of X (ğ‘–) , and name this set of
samples ğ¾ ;

b

calculate the score for x with |ğ‘‡ âˆ© ğ¾ |/|ğ‘‡ |, where |ğ‘‡ | denotes the cardinality

of the set ğ‘‡ ;

end
calculate the score for label ğ‘– as the average score across all x âˆˆ X(ğ‘–) ;

end

calculate the ï¬nal score

ğ¼ (

ğœƒ ) as the average score across all the labels;

b

b

â€¢ Squared â„“2 norm over logits is considered the empirically most
favorable AR option for learning robust and invariant represen-
tations.

4.1 Experiment Setup
Our empirical investigation is conducted over two benchmark datasets
(MNIST dataset with LeNet architecture and CIFAR10 dataset with
ResNet18 architecture) and three sets of the transformations.

Transformation Functions. We consider three sets of transforma-

tion functions:
â€¢ Texture: we use Fourier transform to perturb the texture of
the data by discarding the high-frequency components cut-oï¬€
by a radius ğ‘Ÿ , following [61]. The smaller ğ‘Ÿ is, the fewer high-
frequency components the image has. We consider

A = {ğ‘0(), ğ‘12 (), ğ‘10 (), ğ‘8 (), ğ‘6 ()}
, where the subscript denotes the radius ğ‘Ÿ except that ğ‘0 () is the
identity map. We consider A during test time, but only ğ‘0 () and
ğ‘6 () during training.

â€¢ Rotation: we rotate the images clockwise ğ‘Ÿ degrees with A =
{ğ‘0(), ğ‘15 (), ğ‘30 (), ğ‘45 (), ğ‘60 ()}, where the subscript denotes the
degree of rotation and ğ‘0 () is the identity map. We consider A
during test time, but only ğ‘()0 and ğ‘60 () during training.

â€¢ Contrast: we create the images depicting the same visual in-
formation, but with diï¬€erent scales of the pixels, including the
negative color representation. Therefore, we have A = {ğ‘0 (x) =
x, ğ‘1 (x) = x/2, ğ‘2 (x) = x/4, ğ‘3(x) = 1âˆ’x, ğ‘4 (x) = (1âˆ’x)/2, ğ‘5(x) =
(1 âˆ’ x)/4, where x stands for the image whose pixel values have
been set to be between 0 and 1. We consider A during test time,
but only ğ‘0 () and ğ‘3() during training.

Alignment Regularizations. We consider the following popular

choices of AR (with u and v denoting two vector embeddings):
L: â„“1 norm of the vector diï¬€erences, i.e., ku âˆ’ vk1
S: squared â„“2 norm of the vector diï¬€erences, i.e., ku âˆ’ vk2
2
C: cosine similarity, i.e., uğ‘‡ v/kuk Â· kvk

KDD â€™22, August 14â€“18, 2022, Washington, DC, USA

Wang, et al.

Table 1: Test results on MNIST dataset for diï¬€erent ARs over three evaluation metrics and three distribution shifts. B denotes
Baseline, i.e., the model does not use any data augmentation; V denotes vanilla augmentation, i.e., the model uses data aug-
mentation but not AR; L denotes â„“1 norm; S denotes squared â„“2 norm; C denotes cosine similarity; K denotes KL divergence;
W denotes Wasserstein-1 metric; D denotes GAN discriminator.

Texture

Rotation

Contrast

Accuracy
Robustness
Invariance
Accuracy
Robustness
Invariance
Accuracy
Robustness
Invariance

B
99.2Â±0.0
98.3Â±0.3
92.4Â±0.0
99.2Â±0.0
28.9Â±0.6
20.6Â±0.4
99.2Â±0.0
26.0Â±1.0
20.7Â±1.1

V
99.2Â±0.0
99.0Â±0.0
99.2Â±0.0
99.0Â±0.1
93.6Â±0.3
58.3Â±2.2
98.9Â±0.3
95.4Â±2.6
37.5Â±6.9

L
99.0Â±0.1
99.0Â±0.0
100Â±0.0
99.3Â±0.0
95.2Â±0.1
66.0Â±3.8
99.4Â±0.0
96.8Â±0.8
41.4Â±0.3

S
99.1Â±0.0
99.0Â±0.0
100Â±0.0
99.3Â±0.0
95.1Â±0.1
65.4Â±3.5
99.4Â±0.0
97.4Â±0.6
41.3Â±0.4

C
99.4Â±0.0
99.1Â±0.0
99.0Â±0.0
99.0Â±0.0
93.5Â±0.1
29.1Â±0.6
99.2Â±0.0
97.9Â±0.4
26.3Â±1.1

K
68.7Â±41
68.7Â±41
76.0Â±34
98.8Â±0.0
94.5Â±0.2
71.9Â±2.8
98.9Â±0.0
88.4Â±4.5
40.3Â±0.9

W
98.7Â±0.1
98.4Â±0.1
60.7Â±2.9
98.5Â±0.4
92.3Â±0.8
48.7Â±1.9
98.7Â±0.0
87.2Â±9.6
28.4Â±1.7

D
99.1Â±0.1
98.8Â±0.1
35.0Â±6.7
98.9Â±0.0
93.2Â±0.7
39.3Â±6.9
99.1Â±0.0
97.7Â±0.6
20.0Â±0.1

Table 2: Test results on CIFAR10 dataset for diï¬€erent ARs over three evaluation metrics and three distribution shifts. Notations
are the same as in Table 1.

Texture

Rotation

Contrast

Accuracy
Robustness
Invariance
Accuracy
Robustness
Invariance
Accuracy
Robustness
Invariance

B
88.5Â±1.7
38.3Â±0.7
44.7Â±0.5
88.5Â±1.7
15.3Â±1.1
47.3Â±0.6
88.5Â±1.7
54.5Â±0.8
53.1Â±1.6

V
86.3Â±0.3
76.5Â±0.0
94.1Â±0.6
81.1Â±2.3
49.0Â±0.4
54.6Â±2.0
85.2Â±4.5
77.7Â±0.8
67.5Â±0.1

L
82.8Â±0.4
79.1Â±0.2
100Â±0.0
80.3Â±4.7
50.7Â±2.6
40.7Â±1.4
88.8Â±1.3
83.1Â±1.3
69.8Â±4.8

S
82.0Â±0.0
79.4Â±0.1
100Â±0.0
78.1Â±2.2
51.1Â±1.0
55.2Â±1.6
86.9Â±2.0
83.4Â±1.1
71.3Â±2.3

C
86.8Â±0.1
76.8Â±0.1
94.2Â±1.2
80.7Â±1.8
47.0Â±0.6
55.7Â±1.1
89.6Â±0.9
80.7Â±2.4
53.6Â±4.7

K
84.6Â±0.4
75.6Â±0.1
96.7Â±1.0
80.4Â±6.8
46.6Â±4.5
55.5Â±1.0
83.4Â±3.7
79.5Â±2.9
73.0Â±2.2

W
86.8Â±0.1
76.8Â±0.1
93.4Â±0.4
87.5Â±1.6
49.4Â±0.9
55.7Â±1.3
87.2Â±2.2
82.8Â±1.0
74.6Â±0.8

D
86.5Â±0.4
77.3Â±0.2
95.4Â±0.8
83.7Â±4.0
47.7Â±1.7
54.5Â±0.7
89.7Â±0.9
80.8Â±5.6
66.6Â±4.3

K: KL divergence over a batch of paired embeddings; the second

â€¢ Robustness: the worst-case accuracy when each sample can be

argument are augmented samples.

transformed with ğ‘ âˆˆ A.

W: Wasserstein-1 metric over a batch of paired embeddings, with

implementation following Wasserstein GAN [3, 23]

D: a vanilla GAN discriminator over a batch of paired embeddings,
the one-layer discriminator is trained to classify samples vs. aug-
mented samples.

We mainly discuss applying the AR to logits (embeddings prior
to the ï¬nal softmax function). We have also experimented with
applying to the ï¬nal softmax output and the embeddings one layer
prior to logits. Both cases lead to substantially worse results, so we
skip the discussion.

Hyperparameters. We use standard data splits. We ï¬rst train the
baseline models to get reasonably high performances (for MNIST,
we train 100 epochs with learning rate set to be 10âˆ’4; for CIFAR10,
we train 200 epochs with learning rate initialized to be 10âˆ’1 and
reduced one magnitude every 50 epochs; batch sizes in both cases
are set to be 128). Then we train other augmented models with the
same learning rate and batch size etc. The regularization weight is
searched with 8 choices evenly split in the logspace from 10âˆ’7 to 1.
For each method, the reported score is from the weight resulting
in the highest robust accuracy. We test with three random seeds.

Evaluation Metrics: We consider the three major evaluation met-

rics as we discussed in Section 3:

â€¢ Accuracy: test accuracy on the original test data.

â€¢ Invariance: the metric to test whether the learned represen-
tations are invariant to the transformation functions, as intro-
duced in Section 3.3.

4.2 Results and Discussion
Tables 1 and 2 show the empirical results across the three distribu-
tion shifts and the three evaluation metrics. First of all, no method
can dominate across all these evaluations, probably because of the
tradeoï¬€ between accuracy and robustness [54, 61, 65]. Similarly,
the tradeoï¬€ between accuracy and invariance can be expected from
the role of the regularization weight: when the weight is small, AR
has no eï¬€ect, and the model is primarily optimized for improving
accuracy; when the weight is considerable, the model is pushed
toward a trivial solution that maps every sample to the same em-
bedding, ignoring other patterns of the data. This is also the reason
that results in Tables 1 and 2 are selected according to the robust
accuracy.

Due to the tradeoï¬€s, it may not be strategic if we only focus
on the highest number of each row. Instead, we suggest studying
the three rows of each test case together and compare the trade-
oï¬€s, which is also a reason we reformulate the invariance test in
Section 3.3 so that we can have bounded invariance scores directly
comparable to accuracy and robust accuracy.

For example, in the texture rows of Table 1, while cosine simi-
larity can outperform squared â„“2 norm in accuracy and robustness

Toward Learning Robust and Invariant Representations with Alignment Regularization and Data Augmentation

KDD â€™22, August 14â€“18, 2022, Washington, DC, USA

with 0.3 and 0.1 margins, respectively, it is disadvantageous in in-
variance with a larger margin (1.0). Similarly, for rotation rows of
Table 1, KL-divergence shows the overall highest scores, followed
by â„“1 norm and squared â„“2 norm. For contrast rows, both â„“1 norm
and squared â„“2 norm stand out. Overall, experiments in MNIST sug-
gest the desired choice to be â„“1 norm or squared â„“2 norm, and we
believe squared â„“2 norm is marginally better.

On the other hand, the experiments in CIFAR10 in Table 2 mostly
favor â„“1 norm and squared â„“2 norm. Good performances can also be
observed from Wasserstein-1 metric for rotation. Also, we notice
that squared â„“2 norm, in general, outperforms â„“1 norm.

Thus, our empirical study recommends squared â„“2 norm for AR
to learn robust and invariant models, with â„“1 norm as a runner-up.

5 ANALYTICAL SUPPORT
According to our discussions in Section 3.3, Wasserstein metric is
supposed to be a favorable option as AR. However, its empirical
performance does not stand out. We believe this disparity is mainly
due to the diï¬ƒculty in calculating the Wasserstein metric in prac-
tice.

On the other hand, norm-based consistency regularizations stand
out. We are interested in studying the properties of these metrics.
In particular, this section aims to complement the empirical study
by showing that norm-based AR can lead to bounded robust gen-
eralization error under certain assumptions.

Also, our experiments only use two transformation functions
from A during training but are tested with all the functions in A.
We also discuss the properties of these two functions and argue
that training with only these two functions can be a good strategy
when certain assumptions are met.

5.1 Overview of Analytical Results
All together, we need six assumptions (namely, A1-A6). Out of
these assumptions, A1 is necessary for using data augmentation,
and A4 is necessary for deriving machine learning generalization
error bound. A2 and A3 are properties of data transformation func-
tions, and A5 and A6 are technical assumptions. Along with intro-
ducing these assumptions, we will also oï¬€er empirical evidence
showing that these assumptions are likely to hold in practice.

In particular, we will show that

â€¢ With A2 holds, â„“1 norm can replace the empirical Wasserstein
metric to regularize invariance (Proposition A.2) and then we
can derive a bounded robust error if all the functions in A are
available (Theorem 5.1).

â€¢ With the above result and A3, we can derive a bounded robust
error if only two special functions in A (which we refer to as
vertices) are available (Lemma 5.2).

5.2 Assumptions Setup
5.2.1 Assumptions on Data Augmentation Functions. Our ï¬rst three
assumptions are for the basic properties of the data transforma-
tion functions used. These properties are formally introduced as
assumptions below.

A1: Dependence-preservation:

the transformation function will
not alter the dependency regarding the label (i.e., for any ğ‘() âˆˆ A,

ğ‘(x) will have the same label as x) or the features (i.e., ğ‘1 (x1) and
ğ‘2 (x2) are independent if x1 and x2 are independent).

Intuitively, â€œDependence-preservationâ€ has two perspectives: Label-
wise, the transformation cannot alter the label of the data, which
is a central requirement of almost all the data augmentation func-
tions in practice. Feature-wise, the transformation will not intro-
duce new dependencies between the samples.

We consider the label-wise half of this argument as a fundamen-
tal property of any data augmentations. It has to be always true
for data augmentation to be a useful technique. On the other hand,
the feature-wise half of this argument is a fundamental property
required to derive the generalization error bounds. Intuitively, we
believe this property holds for most data augmentation techniques
in practice.

A2: Eï¬ƒciency: for

ğœƒ and any ğ‘() âˆˆ A, ğ‘“ (ğ‘(x);

ğœƒ ) is closer to x than

any other samples under a distance metric ğ‘‘ğ‘’ (Â·, Â·), i.e.,

ğ‘‘ğ‘’ (ğ‘“ (ğ‘(x);

b
ğœƒ ), ğ‘“ (x;

ğœƒ )) â‰¤ min
xâ€² âˆˆXâˆ’x

b
ğ‘‘ğ‘’ (ğ‘“ (ğ‘(x);

ğœƒ ), ğ‘“ (xâ€²;

ğœƒ )).

b
We deï¬ne ğ‘‘ğ‘’ (Â·, Â·) to be â„“1 norm.
Intuitively, the eï¬ƒciency property means the augmentation should

b

b

b

only generate new samples of the same label as minor perturba-
tions of the original one. If a transformation violates this property,
there should exist other simpler transformations that can generate
the same target sample.

A3: Vertices: For a model

ğœƒ and a transformation ğ‘(), we use P

ğœƒ
ğ‘,
ğœƒ ) for (x, y) âˆ¼ P. â€œVerticesâ€
to denote the distribution of ğ‘“ (ğ‘(x);
b
argues that exists two extreme elements in A, namely ğ‘+ and ğ‘âˆ’,
with certain metric ğ‘‘ğ‘¥ (Â·, Â·), we have
) = sup

, P

, P

b

b

)

ğ‘‘ğ‘¥ (P

ğ‘‘ğ‘¥ (P

ğ‘+,
ğœƒ

ğ‘âˆ’,
ğœƒ

b

b

ğ‘1,ğ‘2 âˆˆA

ğœƒ
ğ‘1,

ğœƒ
ğ‘2,

b

b

We deï¬ne ğ‘‘ğ‘¥ (Â·, Â·) to be Wasserstein-1 metric.
Intuitively, â€œVerticesâ€ suggests that there are extreme cases of
the transformations. For example, if one needs the model to be
invariant to rotations from 0â—¦ to 60â—¦, we consider the vertices to be
0â—¦ rotation function (thus identity map) and 60â—¦ rotation function.
In practice, one usually selects the transformation vertices with
intuitions or domain knowledge.

Notice that we do not need to argue that A3 always holds. All
we need is that A3 can sometimes hold, and when it holds, we can
directly train with the regularized vertex augmentation. Thus, any-
time RVA empirically performs well is a favorable argument for
A3. To show that RVA can sometimes perform well, we compare
the RVA with vanilla (non-regularized) worst-case data augmen-
tation (VWA) method across our synthetic experiment setup. We
notice that out of six total scenarios ({texture, rotation, contrast}
Ã— {MNIST, CIFAR10}), RVA outperforms VWA frequently. This sug-
gests that the domain-knowledge of vertices can help in most cases,
although not guaranteed in every case.

5.2.2 Assumptions on Background and Generalization Error Bound.
In an abstract manner, when the test data and train data are from
the same distribution, several previous analyses on the generaliza-
tion error can be sketched as (see examples in A4):

ğ‘ŸP (

ğœƒ ) â‰¤

ğ‘ŸP (

ğœƒ ) + ğœ™ (|Î˜|, ğ‘›, ğ›¿)

(4)

b

b

b

KDD â€™22, August 14â€“18, 2022, Washington, DC, USA

Wang, et al.

b

b

ğœƒ) can be bounded by
which suggests that the expected risk ğ‘ŸP (
ğœƒ ) and a function of hypothesis space |Î˜|
ğ‘ŸP (
the empirical risk
b
and number of samples ğ‘›; ğ›¿ accounts for the probability when the
bound holds. ğœ™ () is a function of these three terms. Dependent on
the details of diï¬€erent analyses, diï¬€erent concrete examples of this
generic term will need diï¬€erent assumptions. We use a generic as-
sumption A4 to denote the assumptions required for each example.
Following our main goal to study how alignment regularization
and data augmentation help in accuracy, robustness, and invari-
ance, our strategy in theoretical analysis is to derive error bounds
for accuracy and robustness, and the error bound directly contains
terms to regularize the invariance. Further, as robustness naturally
bounds accuracy (i.e., ğ‘ŸP (
ğœƒ) following the deï¬nitions in
ğœƒ ) â‰¤ ğ‘ŸP,A (
(1) and (2) respectively), we only need to study the robust error.

To study the robust error, we need two additional technical as-
sumptions. A5 connects the distribution of expected robust risk
and the distribution of empirical robust risk, and A6 connects the
0-1 classiï¬cation error and cross-entropy error.

b

b

A4: We list two examples here:

â€“ when A4 is â€œÎ˜ is ï¬nite, ğ‘™ (Â·, Â·) is a zero-one loss, samples are i.i.dâ€,

ğœ™ (|Î˜|, ğ‘›, ğ›¿) =

(log(|Î˜|) + log(1/ğ›¿))/2ğ‘›

â€“ when A4 is â€œsamples are i.i.dâ€, ğœ™ (|Î˜|, ğ‘›, ğ›¿) = 2R (L)+

p

(log 1/ğ›¿)/2ğ‘›,

where R (L) stands for Rademacher complexity and L = {ğ‘™ğœƒ | ğœƒ âˆˆ
Î˜}, where ğ‘™ğœƒ is the loss function corresponding to ğœƒ.

p

For more information or more concrete examples of the generic
term, one can refer to relevant textbooks such as [7].

A4 stands for the fundamental assumptions used to derive stan-
dard generalization bounds. We rely on this assumption as how
previous theoretical works rely on them.

A5: the distribution for expected robust risk equals the distribution for

empirical robust risk, i.e.,

arg max
Pâ€² âˆˆğ‘‡ (P,A)

ğ‘ŸPâ€² (

ğœƒ ) = arg max
Pâ€² âˆˆğ‘‡ (P,A)

b

ğ‘ŸPâ€² (

ğœƒ )

b

b

where ğ‘‡ (P, A) is the collection of distributions created by elements
in A over samples from P.

b

Eq. (2) can be written equivalently into the expected risk over a
pseudo distribution Pâ€² (see Lemma 1 in [55]), which is the distribu-
tion that can sample the data leading to the expected robust risk.
ğœƒ ) as a surro-
Thus, equivalently, we can consider supPâ€² âˆˆğ‘‡ (P,A) ğ‘ŸPâ€² (
gate of ğ‘ŸP,A (
ğœƒ), where ğ‘‡ (P, A) denotes the set of possible result-
ing distributions. Following the empirical strength of techniques
such as adversarial training [44], we introduce an assumption re-
lating the distribution of expected robust risk and the distribution
of empirical robust risk (namely, A5, in Appendix 5.2). Thus, the
bound of our interest (i.e., supPâ€² âˆˆğ‘‡ (P,A) ğ‘ŸPâ€² (
ğœƒ )) can be analogously
analyzed through supPâ€² âˆˆğ‘‡ (P,A)

ğ‘ŸPâ€² (
A5 is likely to hold in practice: Assumption A5 appears very
b
strong, however, the successes of methods like adversarial training
[44] suggest that, in practice, A5 might be much weaker than it
appears.

ğœƒ ).

b

b

b

A6: With (x, y) âˆˆ (X, Y), the sample maximizing cross-entropy loss
ğœƒ follows:

and the sample maximizing classiï¬cation error for model

âˆ€x,

yâŠ¤ ğ‘“ (x;
infğ‘ âˆˆA yâŠ¤ ğ‘“ (ğ‘(x);

ğœƒ )

b

ğœƒ )

â‰¥ exp

I(ğ‘”(ğ‘“ (x;

b
ğœƒ )) â‰  ğ‘”(ğ‘“ (xâ€²;

ğœƒ )))

(cid:0)

b

b

(cid:1)
(5)

where xâ€² stands for the sample maximizing classiï¬cation error, i.e.,

b

xâ€² = arg min

x

yâŠ¤ğ‘”(ğ‘“ (x;

ğœƒ ))

b

Also,

âˆ€x,

| inf
ğ‘ âˆˆA

yâŠ¤ ğ‘“ (ğ‘(x);

ğœƒ )| â‰¥ 1

(6)

b

Intuitively, although Assumption A6 appears complicated, it de-
scribes the situations of two scenarios:
ğœƒ )) = ğ‘”(ğ‘“ (xâ€²;

ğœƒ )), which means either the sample is
If ğ‘”(ğ‘“ (x;
ğœƒ or A is not rich enough for a transformation
misclassiï¬ed by
function to alter the prediction, the RHS of Eq. 5 is 1, thus Eq. 5
always holds (because A has the identity map as one of its ele-
ments).

b

b

b

b

b

ğœƒ )) â‰  ğ‘”(ğ‘“ (xâ€²;

If ğ‘”(ğ‘“ (x;

ğœƒ )), which means a transformation alters
the prediction. In this case, A6 intuitively states that the A is rea-
sonably rich and the transformation is reasonably powerful to cre-
ate a gap of the probability for the correct class between the orig-
inal sample and the transformed sample. The ratio is described as
the ratio of the prediction conï¬dence from the original sample over
the prediction conï¬dence from the transformed sample is greater
than ğ‘’.

5.3 Analytical Support

Regularized Worst-case Augmentation. To have a model with a
small invariance score, we should probably directly regularize the
empirical counterpart of Eq. (3). However, Wasserstein distance is
diï¬ƒcult to calculate in practice. Fortunately, Proposition A.2 con-
veniently allows us to use â„“1 norm to replace Wasserstein metric.
With Proposition A.2, now we can oï¬€er our main technical result
to study the robust error ğ‘ŸP,A

ğœƒ (as deï¬ned in Eq. (2)).

Theorem 5.1. With Assumptions A1, A2, A4, A5, and A6, with

b

probability at least 1 âˆ’ ğ›¿, we have

ğ‘ŸP,A

ğœƒ â‰¤

ğ‘ŸP (

ğœƒ ) +

||ğ‘“ (xğ‘–;

ğœƒ ) âˆ’ ğ‘“ (xâ€²
ğ‘– ;

ğœƒ )||1 + ğœ™ (|Î˜|, ğ‘›, ğ›¿)

b

Ã•ğ‘–
and xâ€² = ğ‘(x), where ğ‘ = arg minğ‘ âˆˆA yâŠ¤ ğ‘“ (ğ‘(x);
deï¬ned in A4.

b

b

b

b

ğœƒ ). ğœ™ (|Î˜|, ğ‘›, ğ›¿) is

b

This technical result immediately inspires the method to guaran-
tee worst case performance, as well as to explicitly enforce the con-
cept of invariance. The method ğ‘ = arg minğ‘ âˆˆA yâŠ¤ ğ‘“ (ğ‘(x);
ğœƒ ) is se-
lecting the transformation function maximizing the cross-entropy
loss (notice the sign diï¬€erence between here and the cross-entropy
loss), which we refer to as worst-case data augmentation. This
method is also closely connected to adversarial training [e.g., 44].

b

Regularized Vertex Augmentation. As A in practice usually has
a large number of (and possibly inï¬nite) elements, we may not
always be able to identify the worst-case transformation function

Toward Learning Robust and Invariant Representations with Alignment Regularization and Data Augmentation

KDD â€™22, August 14â€“18, 2022, Washington, DC, USA

with reasonable computational eï¬€orts. We further leverage the ver-
tex property (boundary cases of transformation functions, discussed
as Assumption A3 in the appendix) of the transformation function
to bound the worst-case generalization error:

Lemma 5.2. With Assumptions A1-A6, assuming there is a ğ‘â€²() âˆˆ
ğ‘ŸPğ‘âˆ’ (
, with probability at least

ğœƒ ) +

ğœƒ )

ğœƒ ) = 1
2

ğ‘ŸPğ‘+ (
(cid:0)
b
ğœƒ ) +

b
ğ‘ŸPğ‘âˆ’ (

(cid:1)

b

b
ğœƒ )

A where
ğ‘ŸPğ‘â€² (
1 âˆ’ ğ›¿, we have:
1
2
+

b
ğœƒ ) â‰¤

ğ‘ŸP,A (

b

b
ğ‘ŸPğ‘+ (
(cid:0)
b
Ã•ğ‘–

b

||ğ‘“ (ğ‘+(xğ‘– );
b

(cid:1)

ğœƒ ) âˆ’ ğ‘“ (ğ‘âˆ’(xâ€²);
b

ğœƒ )||1 + ğœ™ (|Î˜|, ğ‘›, ğ›¿),

b
where ğ‘+ () and ğ‘âˆ’() are deï¬ned in A3, and ğœ™ (|Î˜|, ğ‘›, ğ›¿) in A4.

b

This result corresponds to the method that can be optimized con-
veniently without searching for the worst-case transformations.
However, the method requires good domain knowledge of the ver-
tices (i.e., boundary cases) of the transformation functions.

Thus, our theoretical discussions have complemented our em-
pirical ï¬ndings in Section 4 by showing that norm-based regular-
izations can lead to bounded robust error. There is a disparity that
our analytical result is about â„“1 norm while our empirical study
suggests squared â„“2 norm. We conjecture the disparity is mainly
caused by the diï¬ƒculty in passing the gradient of â„“1 norm in prac-
tice.

6 EXPERIMENTS WITH ADVANCED

METHODS

We continue to test the methods we identiï¬ed in comparison to
more advanced methods. Although we argued for the value of in-
variance, for a fair comparison, we will test the performances eval-
uated by the metrics the previous methods are designed for. Our
method will use the same generic approach and the same transfor-
mation functions as in the previous empirical study, although these
functions are not necessarily part of the distribution shift we test
now. In summary, our method can outperform (or be on par with)
these SOTA techniques in the robustness metric they are designed
for (Section 6.2). In addition, we run a side test to show that our
method can also improve accuracy (Section 6.3).

6.1 Methods
Section 4 and Section 5 lead us to test the following two methods:
â€¢ RVA (regularized vertex augmentation): using squared â„“2 norm
as AR over logits between the original samples and the aug-
mented samples of a ï¬xed vertex transformation function (orig-
inal samples are considered as from another vertex).

â€¢ RWA (regularized worst-case augmentation): using squared â„“2
norm as AR over logits between the original samples and the
worst-case augmented samples identiï¬ed at each iteration. Worst-
case samples are generated by the function with the maximum
loss when we iterate through all the transformation functions.

6.2 Robustness

Rotation. We compare our results with rotation-invariant mod-
els, mainly Spatial Transformer (ST) [34], Group Convolution (GC)
[12], and Equivariant Transformer Network (ETN) [53]. We also

tried to run CGNet [37], but the method does not seem to scale to
the CIFAR10 and ResNet level. All these methods are tested with
ResNet34 following popular settings in the community. The results
are in Table 3. We test the models every 15â—¦ rotation from 0â—¦ ro-
tation to 345â—¦ rotation. Augmentation-related methods use the A
of â€œrotationâ€ in synthetic experiments, so the testing scenario goes
beyond what the augmentation methods have seen during train-
ing.

We report two summary results in Table 3. â€œmainâ€ means the
average prediction accuracy from images rotated from 300â—¦ to 60â—¦
(passing 0â—¦), when the resulting images are highly likely to pre-
serve the class label. â€œallâ€ means the average accuracy of all rota-
tions.

Our results can be interpreted from two perspectives. First, by
comparing all the columns in the ï¬rst panel to the ï¬rst column
of the other three panels, data augmentation and AR can boost
a vanilla model to outperform other advanced techniques. On the
other hand, by comparing the columns within each panel, data aug-
mentation and AR can further improve the performances of these
techniques.

Interestingly, the baseline model with our generic approach (RWA

in the ï¬rst panel) can almost compete with the advanced methods
even when these methods also use augmentation and AR (RWA in
GC panel). We believe this result strongly indicates the potential
of this simple augmentation and regularization method to match
the advanced methods.

In summary, RWA can boost the vanilla model to outperform ad-
vanced methods. Data augmentation and squared â„“2 AR can further
improve the performances when plugged onto advanced methods.

Texture & Contrast. We follow [5] and compare the models for a
nine super-class ImageNet classiï¬cation [33] with class-balanced
strategies. Also, we follow [5] to report standard accuracy (Acc.),
weighted accuracy (WAcc.), a scenario where samples with un-
usual texture are weighted more, and accuracy over ImageNet-A
[27], a collection of failure cases for most ImageNet trained mod-
els. Additionally, we also report the performance over ImageNet-
Sketch [58], an independently collected ImageNet test set with only
sketch images. As [5] mainly aims to overcome the texture bias,
we also use our texture-wise functions in Section 4 for augmen-
tation. However, there are no direct connections between these
functions and the distribution shift of the test samples. Also, we
believe the distribution shifts here, especially the one introduced
by our newly added ImageNet-Sketch, are more than texture, and
also correspond to the contrast case of our study.

Following [5], the base network is ResNet, and we compare with
the vanilla network (Base), and several methods designed for this
task: including StylisedIN (SIN) [18], LearnedMixin (LM) [11], RUBi
(RUBi) [9] and ReBias (RB) [5]. Results are in Table 4.

The results favor our generic method in most cases. RVA outper-
forms other methods in standard accuracy, weighted accuracy, and
ImageNet-Sketch, and is shy from ReBias on ImageNet-A. RWA
shows the same pattern as that of RVA and further outperforms
RVA. Overall, these results validate the empirical strength of data
augmentation (even when the augmentation is not designed for
the task) and squared â„“2 norm AR for learning robust models.

KDD â€™22, August 14â€“18, 2022, Washington, DC, USA

Wang, et al.

Table 3: Comparison to advanced rotation-invariant models. We report the accuracy on the test sets rotated. â€œmainâ€ means the
resulting images are highly likely to be semantically the same as the original ones. â€œallâ€ means the average accuracy of all rota-
tions. The underlined scores show that data augmentation and AR can help a vanilla model to compete with advanced methods.
The bold scores (highest at each row) show that data augmentation and AR can further improve the advanced methods.

ResNet

Base
45.4
31.2

RVA RWA Base
38.5
71.1
66.5
26.7
52.8
48.1

main
all

GC
RVA RWA Base
45.9
73.8
72.2
32.1
55.0
54.4

ST
RVA RWA Base
56.9
62.9
58.3
39.5
42.7
40.2

ETN
RVA RWA
57.7
65.1
46.1
52.6

Table 4: Comparison to advanced methods on 9 super-class
ImageNet classiï¬cation with diï¬€erent distribution shifts.

Acc. WAcc.
Base
88.8
90.8
SIN
86.6
88.4
LM 67.9
65.9
RUBi
88.6
90.5
RB
90.5
91.9
RVA
91.2
92.2
RWA
91.6
92.8

ImageNet-A ImageNet-S

24.9
24.6
18.8
27.7
29.6
28.0
28.8

41.1
40.5
36.8
42.3
41.8
42.5
43.2

Table 5: The generic methods can also improve standard ac-
curacy.

ResNet18

ResNet50

ResNet101

B
75.6
93.1

RVA RWA
77.2
100
93.8
100

B
77.4
93.9

RVA RWA
78.2
100
94.4
100

B
77.8
94.4

RVA RWA
78.7
100
94.9
100

Top-1
Top-5

6.3 Accuracy
Further, these experiments help us notice that the generic tech-
nique can also help improve the accuracy, although the technique
is motivated by robustness and invariance. Therefore, we follow
the widely accepted CIFAR100 test pipeline and test the performances
of diï¬€erent architectures of the ResNet family. The results are re-
ported in Table 5, where Base stands for the baseline model with
the default accuracy boosting conï¬gurations.

For both top-1 and top-5 accuracies and across the three ResNet
architectures, our techniques can help improve the accuracy. In
addition, we notice that our techniques can help bridge the gap of
diï¬€erent architectures within the ResNet family: for example, RWA
helps ResNet50 to outperform the vanilla ResNet101.

7 CONCLUSION
In this paper, we seek to answer how to train with augmented data
so that augmentation can be taken to the fullest extent. We ï¬rst de-
ï¬ned a new evaluation metric called invariance and conducted a
line of empirical studies to show that norm-based alignment regu-
larization can help learn robust and invariant models. Further, we
complement our observations with formal derivations of bounded
generalization errors. We notice that regularizing squared â„“2 norm
between the logits of the originals samples and those of the aug-
mented samples is favorable: the trained model tends to have the
most favorable performances in robust accuracy and invariance. In

general, the method we recommend is â€œregularized worst-case aug-
mentationâ€ with squared â„“2 norm as the alignment regularization.
One can also consider â€œregularized vertex augmentationâ€ when
extra assumptions on the vertex properties of the transformation
functions are met. Lastly, we would like to remind a potential limi-
tation of alignment regularization: it may not always help improve
the i.i.d accuracy due to the tradeoï¬€ between accuracy and robust-
ness or invariance. In addition, to simplify the procedure of users
in leveraging our contribution, we also release a software pack-
age in both TensorFlow and PyTorch for users to use our identiï¬ed
methods with a couple lines of code.

ACKNOWLEDGMENTS
This work was supported by NIH R01GM114311, NIH P30DA035778,
and NSF IIS1617583; NSF CAREER IIS-2150012 and IIS-2204808.
The authors would like to thank Hanru Yan for the implementa-
tion of the software package.

REFERENCES
[1] Yaser S Abu-Mostafa. 1990. Learning from hints in neural networks. Journal of

complexity 6, 2 (1990), 192â€“198.

[2] Alessandro Achille and Stefano Soatto. 2018.

Information dropout: Learning
optimal representations through noisy computation. IEEE transactions on pattern
analysis and machine intelligence 40, 12 (2018), 2897â€“2905.

[3] Martin Arjovsky, Soumith Chintala, and LÃ©on Bottou. 2017. Wasserstein GAN.

arXiv:1701.07875 [stat.ML]

[4] Akari Asai and Hannaneh Hajishirzi. 2020.

Logic-Guided Data Aug-
for Consistent Question Answering.

mentation
arXiv:2004.10157 [cs.CL]

and Regularization

[5] Hyojin Bahng, Sanghyuk Chun, Sangdoo Yun, Jaegul Choo, and Seong Joon Oh.
2020. Learning De-biased Representations with Biased Representations. 119
(2020), 528â€“539.

[6] Sergey Bobkov and Michel Ledoux. 2019. One-dimensional empirical measures,
order statistics, and Kantorovich transport distances. Vol. 261. American Mathe-
matical Society.

[7] Olivier Bousquet, StÃ©phane Boucheron, and GÃ¡bor Lugosi. 2003.

Introduction
to statistical learning theory. In Summer School on Machine Learning. Springer,
169â€“207.

[8] Alexander Buslaev, Vladimir I. Iglovikov, Eugene Khvedchenya, Alex Parinov,
Mikhail Druzhinin, and Alexandr A. Kalinin. 2020. Albumentations: Fast and
Flexible Image Augmentations. Inf. 11, 2 (2020), 125.

[9] Remi Cadene, Corentin Dancette, Matthieu Cord, Devi Parikh, et al. 2019. Rubi:
Reducing unimodal biases for visual question answering. In Advances in neural
information processing systems. 841â€“852.

[10] Shuxiao Chen, Edgar Dobriban, and Jane H Lee. 2019. A Group-Theoretic Frame-

work for Data Augmentation. arXiv:1907.10905 [stat.ML]

[11] Christopher Clark, Mark Yatskar, and Luke Zettlemoyer. 2019. Donâ€™t Take the
Easy Way Out: Ensemble Based Methods for Avoiding Known Dataset Biases.
arXiv preprint arXiv:1909.03683 (2019).

[12] Taco Cohen and Max Welling. 2016. Group equivariant convolutional networks.

In International conference on machine learning. 2990â€“2999.

[13] Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le.
2019. Autoaugment: Learning augmentation strategies from data. In Proceedings
of the IEEE conference on computer vision and pattern recognition. 113â€“123.

[14] Marco Cuturi and Arnaud Doucet. 2014.

Fast computation of Wasserstein

barycenters. (2014).

Toward Learning Robust and Invariant Representations with Alignment Regularization and Data Augmentation

KDD â€™22, August 14â€“18, 2022, Washington, DC, USA

[15] Tri Dao, Albert Gu, Alexander Ratner, Virginia Smith, Chris De Sa, and Christo-
pher RÃ©. 2019. A Kernel Theory of Modern Data Augmentation. In Proceedings of
the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019,
Long Beach, California, USA (Proceedings of Machine Learning Research, Vol. 97),
Kamalika Chaudhuri and Ruslan Salakhutdinov (Eds.). PMLR, 1528â€“1537.
[16] Alhussein Fawzi, Horst Samulowitz, Deepak S. Turaga, and Pascal Frossard. 2016.
Adaptive data augmentation for image classiï¬cation. In 2016 IEEE International
Conference on Image Processing, ICIP 2016, Phoenix, AZ, USA, September 25-28,
2016. IEEE, 3688â€“3692.

[17] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
Larochelle, FranÃ§ois Laviolette, Mario Marchand, and Victor Lempitsky. 2016.
Domain-adversarial training of neural networks. The Journal of Machine Learn-
ing Research 17, 1 (2016), 2096â€“2030.

[18] Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A.
Wichmann, and Wieland Brendel. 2019. ImageNet-trained CNNs are biased to-
wards texture; increasing shape bias improves accuracy and robustness.. In In-
ternational Conference on Learning Representations.

[19] Golnaz Ghiasi, Yin Cui, Aravind Srinivas, Rui Qian, Tsung-Yi Lin, Ekin D. Cubuk,
Quoc V. Le, and Barret Zoph. 2020. Simple Copy-Paste is a Strong Data Aug-
mentation Method for Instance Segmentation. CoRR abs/2012.07177 (2020).
arXiv:2012.07177

[20] Atin Ghosh and Alexandre H. Thiery. 2021. On Data-Augmentation and
Consistency-Based Semi-Supervised Learning. In International Conference on
Learning Representations.

[21] Ian Goodfellow. 2016. NIPS 2016 tutorial: Generative adversarial networks. arXiv

preprint arXiv:1701.00160 (2016).

[22] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and

harnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014).

[23] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin,
Improved Training of Wasserstein GANs.

and Aaron Courville. 2017.
arXiv:1704.00028 [cs.LG]

[24] Hao Guo, Kang Zheng, Xiaochuan Fan, Hongkai Yu, and Song Wang. 2019. Vi-
sual Attention Consistency Under Image Transforms for Multi-Label Image Clas-
siï¬cation. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR
2019, Long Beach, CA, USA, June 16-20, 2019. Computer Vision Foundation / IEEE,
729â€“739.

[25] Dan Hendrycks and Thomas Dietterich. 2019. Benchmarking Neural Network
Robustness to Common Corruptions and Perturbations. Proceedings of the Inter-
national Conference on Learning Representations (2019).

[26] Dan Hendrycks, Norman Mu, Ekin Dogus Cubuk, Barret Zoph, Justin Gilmer,
and Balaji Lakshminarayanan. 2020. AugMix: A Simple Data Processing Method
to Improve Robustness and Uncertainty. In 8th International Conference on Learn-
ing Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenRe-
view.net.

[27] Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song.
2019. Natural adversarial examples. arXiv preprint arXiv:1907.07174 (2019).
[28] Alex Hernandez-Garcia. 2020. Data augmentation and image understanding.

arXiv preprint arXiv:2012.14185 (2020).

[29] Alex HernÃ¡ndez-GarcÃ­a, Peter KÃ¶nig, and Tim C Kietzmann. 2019. Learning ro-
bust visual representations using data augmentation invariance. arXiv preprint
arXiv:1906.04547 (2019).

[30] Alex HernÃ¡ndez-GarcÃ­a and Peter KÃ¶nig. 2018. Data augmentation instead of

explicit regularization. arXiv:1806.03852 [cs.CV]

[31] Daniel Ho, Eric Liang, Xi Chen, Ion Stoica, and Pieter Abbeel. 2019. Population
Based Augmentation: Eï¬ƒcient Learning of Augmentation Policy Schedules. In
Proceedings of the 36th International Conference on Machine Learning, ICML 2019,
9-15 June 2019, Long Beach, California, USA (Proceedings of Machine Learning
Research, Vol. 97), Kamalika Chaudhuri and Ruslan Salakhutdinov (Eds.). PMLR,
2731â€“2741.

[32] Zeyi Huang, Haohan Wang, Eric P. Xing, and Dong Huang. 2020.

Self-
challenging Improves Cross-Domain Generalization. In Computer Vision - ECCV
2020 - 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings,
Part II (Lecture Notes in Computer Science, Vol. 12347), Andrea Vedaldi, Horst
Bischof, Thomas Brox, and Jan-Michael Frahm (Eds.). Springer, 124â€“140.
[33] Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon
Tran, and Aleksander Madry. 2019. Adversarial examples are not bugs, they are
features. In Advances in Neural Information Processing Systems. 125â€“136.
[34] Max Jaderberg, Karen Simonyan, Andrew Zisserman, et al. 2015. Spatial trans-
former networks. In Advances in neural information processing systems. 2017â€“
2025.

[35] Jisoo Jeong, Seungeui Lee, Jeesoo Kim, and Nojun Kwak. 2019. Consistency-
based Semi-supervised Learning for Object detection. In Advances in Neural In-
formation Processing Systems. 10758â€“10767.

[36] Harini Kannan, Alexey Kurakin, and Ian Goodfellow. 2018. Adversarial Logit

Pairing. arXiv:1803.06373 [cs.LG]

[37] Risi Kondor, Zhen Lin, and Shubhendu Trivedi. 2018. Clebschâ€“gordan nets: a
fully fourier space spherical convolutional neural network. In Advances in Neu-
ral Information Processing Systems. 10117â€“10126.

[38] Ilya Kostrikov, Denis Yarats, and Rob Fergus. 2020.

Image Augmentation Is
All You Need: Regularizing Deep Reinforcement Learning from Pixels. CoRR
abs/2004.13649 (2020).

[39] Yann LeCun, LÃ©on Bottou, Yoshua Bengio, and Patrick Haï¬€ner. 1998. Gradient-
based learning applied to document recognition. Proc. IEEE 86, 11 (1998), 2278â€“
2324.

[40] Davis Liang, Zhiheng Huang, and Zachary C Lipton. 2018. Learning noise-
invariant representations for robust speech recognition. In 2018 IEEE Spoken
Language Technology Workshop (SLT). IEEE, 56â€“63.

[41] Percy Liang. 2016. CS229T/STAT231: Statistical Learning Theory (Winter 2016).
[42] Sungbin Lim, Ildoo Kim, Taesup Kim, Chiheon Kim, and Sungwoong Kim. 2019.
Fast AutoAugment. In Advances in Neural Information Processing Systems 32: An-
nual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, De-
cember 8-14, 2019, Vancouver, BC, Canada, Hanna M. Wallach, Hugo Larochelle,
Alina Beygelzimer, Florence dâ€™AlchÃ©-Buc, Emily B. Fox, and Roman Garnett
(Eds.). 6662â€“6672.

[43] Raphael Gontijo Lopes, Dong Yin, Ben Poole, Justin Gilmer, and Ekin D Cubuk.
Improving robustness without sacriï¬cing accuracy with patch gaussian

2019.
augmentation. arXiv preprint arXiv:1906.02611 (2019).

[44] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
Adrian Vladu. 2018. Towards Deep Learning Models Resistant to Adversarial
Attacks. In 6th International Conference on Learning Representations, ICLR 2018,
Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings.
OpenReview.net.

[45] Junghyun Min, R. Thomas McCoy, Dipanjan Das, Emily Pitler, and Tal Linzen.
2020. Syntactic Data Augmentation Increases Robustness to Inference Heuristics.
In ACL.

[46] Shashank Rajput, Zhili Feng, Zachary Charles, Po-Ling Loh, and Dimitris Papail-
iopoulos. 2019. Does Data Augmentation Lead to Positive Margin?. In Interna-
tional Conference on Machine Learning. 5321â€“5330.

[47] Mehdi Sajjadi, Mehran Javanmardi, and Tolga Tasdizen. 2016. Regularization
with stochastic transformations and perturbations for deep semi-supervised
learning. In Advances in neural information processing systems. 1163â€“1171.
[48] Meet Shah, Xinlei Chen, Marcus Rohrbach, and Devi Parikh. 2019. Cycle-
Consistency for Robust Visual Question Answering. In The IEEE Conference on
Computer Vision and Pattern Recognition (CVPR).

[49] Connor Shorten and Taghi M Khoshgoftaar. 2019. A survey on image data aug-

mentation for deep learning. Journal of Big Data 6, 1 (2019), 60.

[50] Patrice Simard, Bernard Victorri, Yann LeCun, and John S Denker. 1991. Tangent
prop-a formalism for specifying selected invariances in an adaptive network. In
NIPS.

[51] Sining Sun, Ching-Feng Yeh, Mari Ostendorf, Mei-Yuh Hwang, and Lei Xie. 2018.
Training Augmentation with Adversarial Examples for Robust Speech Recogni-
tion. In ISCA.

[52] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Er-
han, Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties of neural net-
works. arXiv preprint arXiv:1312.6199 (2013).

[53] Kai Sheng Tai, Peter Bailis, and Gregory Valiant. 2019. Equivariant Transformer

Networks. arXiv preprint arXiv:1901.11399 (2019).

[54] Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
Aleksander Madry. 2018. Robustness May Be at Odds with Accuracy. In Interna-
tional Conference on Learning Representations.

[55] Zhuozhuo Tu, Jingwei Zhang, and Dacheng Tao. 2019. Theoretical analysis of
adversarial learning: A minimax approach. In Advances in Neural Information
Processing Systems. 12259â€“12269.

[56] CÃ©dric Villani. 2003. Topics in optimal transportation. Number 58. American

Mathematical Soc.

[57] CÃ©dric Villani. 2008. Optimal transport: old and new. Vol. 338. Springer Science

& Business Media.

[58] Haohan Wang, Songwei Ge, Zachary C. Lipton, and Eric P. Xing. 2019. Learning
, 10506â€“

Robust Global Representations by Penalizing Local Predictive Power.
10518 pages.

[59] Haohan Wang, Zexue He, Zachary C. Lipton, and Eric P. Xing. 2019. Learning
Robust Representations by Projecting Superï¬cial Statistics Out. In 7th Interna-
tional Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA,
May 6-9, 2019. OpenReview.net.

[60] Haohan Wang and Bhiksha Raj. 2017. On the origin of deep learning. arXiv

preprint arXiv:1702.07800 (2017).

[61] Haohan Wang, Xindi Wu, Zeyi Huang, and Eric P. Xing. 2020. High Fre-
quency Component Helps Explain the Generalization of Convolutional Neural
Networks. In Computer Vision and Pattern Recognition (CVPR).

[62] Xindi Wu, Yijun Mao, Haohan Wang, Xiangrui Zeng, Xin Gao, Eric P. Xing, and
Min Xu. 2019. Regularized Adversarial Training (RAT) for Robust Cellular Elec-
tron Cryo Tomograms Classiï¬cation. In 2019 IEEE International Conference on
Bioinformatics and Biomedicine, BIBM 2019, San Diego, CA, USA, November 18-21,
2019, Illhoi Yoo, Jinbo Bi, and Xiaohua Hu (Eds.). IEEE, 1â€“6.

[63] Saining Xie, Tianbao Yang, Xiaoyu Wang, and Yuanqing Lin. 2015. Hyper-class
augmented and regularized deep learning for ï¬ne-grained image classiï¬cation.

KDD â€™22, August 14â€“18, 2022, Washington, DC, USA

Wang, et al.

In Proceedings of the IEEE conference on computer vision and pattern recognition.
2645â€“2654.

[64] Fanny Yang, Zuowen Wang, and Christina Heinze-Deml. 2019.

Invariance-
inducing regularization using worst-case transformations suï¬ƒces to boost ac-
curacy and spatial robustness. In Advances in Neural Information Processing Sys-
tems. 14757â€“14768.

[65] Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P. Xing, Laurent El Ghaoui, and
Michael I. Jordan. 2019. Theoretically Principled Trade-oï¬€ between Robustness
and Accuracy. In Proceedings of the 36th International Conference on Machine
Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA (Proceedings of
Machine Learning Research, Vol. 97), Kamalika Chaudhuri and Ruslan Salakhut-
dinov (Eds.). PMLR, 7472â€“7482.

[66] Linjun Zhang, Zhun Deng, Kenji Kawaguchi, Amirata Ghorbani, and James Zou.
2021. How Does Mixup Help With Robustness and Generalization?. In Interna-
tional Conference on Learning Representations.

[67] Richard Zhang. 2019. Making convolutional networks shift-invariant again.

arXiv preprint arXiv:1904.11486 (2019).

[68] Zhirui Zhang, Shuangzhi Wu, Shujie Liu, Mu Li, Ming Zhou, and Tong Xu. 2019.
Regularizing neural machine translation by target-bidirectional agreement. In
Proceedings of the AAAI Conference on Artiï¬cial Intelligence, Vol. 33. 443â€“450.

[69] Stephan Zheng, Yang Song, Thomas Leung, and Ian Goodfellow. 2016. Improving
the robustness of deep neural networks via stability training. In Proceedings of
the ieee conference on computer vision and pattern recognition. 4480â€“4488.
[70] Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, and Yi Yang. 2020. Random

Erasing Data Augmentation. In AAAI.

Toward Learning Robust and Invariant Representations with Alignment Regularization and Data Augmentation

KDD â€™22, August 14â€“18, 2022, Washington, DC, USA

APPENDICES
A PROOF OF THEORETICAL RESULTS
A.1 Lemma A.1 and its proof

A.3 Proof of Theorem 5.1

Theorem. With Assumptions A1, A2, A4, A5, and A6, with prob-

ability at least 1 âˆ’ ğ›¿, we have

Lemma A.1. With Assumptions A1, A4, and A5, with probability

ğ‘ŸP,A (

ğœƒ) â‰¤

ğ‘ŸP (

ğœƒ ) +

at least 1 âˆ’ ğ›¿, we have

b

b

b

||ğ‘“ (xğ‘–;

ğœƒ ) âˆ’ ğ‘“ (xâ€²
ğ‘– ;

ğœƒ )||1 + ğœ™ (|Î˜|, ğ‘›, ğ›¿)

(7)

b

b

Ã•ğ‘–

I(ğ‘”(ğ‘“ (ğ‘(x);

ğœƒ )) â‰  y) + ğœ™ (|Î˜|, ğ‘›, ğ›¿)

and xâ€² = ğ‘(x), where ğ‘ = arg minğ‘ âˆˆA yâŠ¤ ğ‘“ (ğ‘(x);

ğœƒ ).

ğ‘ŸP,A (

ğœƒ ) â‰¤

1
ğ‘› Ã•(x,y)âˆ¼P

sup
ğ‘ âˆˆA

b

b
Proof. With Assumption A5, we have

arg max
Pâ€² âˆˆğ‘‡ (P,A)

ğ‘ŸPâ€² (

ğœƒ ) = arg max
Pâ€² âˆˆğ‘‡ (P,A)

ğ‘ŸPâ€² (

ğœƒ ) = Pğ‘¤

b

b

b

we can analyze the expected risk following the standard classical
techniques since both expected risk and empirical risk are studied
over distribution Pğ‘¤.

Now we only need to make sure the classical analyses (as dis-

cussed in A4) are still valid over distribution Pğ‘¤:
â€¢ when A4 is â€œÎ˜ is ï¬nite, ğ‘™ (Â·, Â·) is a zero-one loss, samples are i.i.dâ€,

log(|Î˜|) + log(1/ğ›¿)
2ğ‘›

ğœ™ (|Î˜|, ğ‘›, ğ›¿) =
uses Hoeï¬€dingâ€™s inequality, which only requires independence
of random variables. One can refer to Section 3.6 in [41] for the
detailed proof.

. The proof of this result

r

â€¢ when A4 is â€œsamples are i.i.dâ€, ğœ™ (|Î˜|, ğ‘›, ğ›¿) = 2R (L) +

r

The proof of this result relies on McDiarmidâ€™s inequality, which
also only requires independence of random variables. One can
refer to Section 3.8 in [41] for the detailed proof.

log 1/ğ›¿
2ğ‘›

Assumption A1 guarantees the samples from distribution Pğ‘¤ are
still independent, thus the generic term holds for at least these two
concrete examples, thus the claim is proved.

(cid:3)

A.2 Proposition A.2 and Proof

Proposition A.2. With A2, for any ğ‘ âˆˆ A, we have

| (X,Y) |

ğ‘Š1 (

Q

,

x,
ğœƒ

Q

ğ‘ (x),
ğœƒ

) =

Ã•ğ‘–

||ğ‘“ (xğ‘–;

ğœƒ ) âˆ’ ğ‘“ (ğ‘(xğ‘–);

ğœƒ )||1,

b

b

b
denotes the empirical distribution of ğ‘“ (x;

b

b

b

ğœƒ ) for (x, y) âˆˆ

b

where
(X, Y).

Q

b

x,
ğœƒ

b

Proof. We use the order statistics representation of Wasser-
stein metric over empirical distributions (e.g., see Section 4 in [6])

| (X,Y) |

Ã•ğ‘–

ğ‘Š1 (

Q

,

x,
ğœƒ

Q

ğ‘ (x),
ğœƒ

)) = inf
ğœ

b

b

b

b

||ğ‘“ (xğ‘–;

ğœƒ ) âˆ’ ğ‘“ (ğ‘(xğœ (ğ‘–)),

ğœƒ )||1

b

b

where ğœ stands for a permutation of the index, thus the inï¬mum is
taken over all possible permutations. With Assumption A2, when
ğ‘‘ğ‘’ (Â·, Â·) in A2 chosen to be â„“1 norm, we have:

||ğ‘“ (xğ‘– ;

ğœƒ ) âˆ’ ğ‘“ (ğ‘(xğ‘–);

ğœƒ )||1 â‰¤ min
ğ‘—â‰ ğ‘–

||ğ‘“ (xğ‘–;

ğœƒ ) âˆ’ ğ‘“ (ğ‘(xğ‘— ),

ğœƒ )||1

b

b

Thus, the inï¬mum is taken when ğœ is the natural order of the sam-
(cid:3)
ples, which leads to the claim.

b

b

.

With A6, we can continue with:

Proof. First of all, in the context of multiclass classiï¬cation,
where ğ‘”(ğ‘“ (x, ; ğœƒ)) predicts a label with one-hot representation, and
y is also represented with one-hot representation, we can have the
empirical risk written as:

b

ğ‘ŸP (

ğœƒ) = 1 âˆ’

b

b

1
ğ‘› Ã•(x,y)âˆ¼P

yâŠ¤ğ‘”(ğ‘“ (x;

ğœƒ ))

b

Thus,

sup
Pâ€² âˆˆğ‘‡ (P,A)

ğ‘ŸPâ€² (

ğœƒ ) =

ğ‘ŸP (

ğœƒ ) +

b

b

b
=
ğ‘ŸP (

b
ğœƒ ) +

sup
Pâ€² âˆˆğ‘‡ (P,A)
1
ğ‘›

sup

ğ‘ŸPâ€² (

ğœƒ ) âˆ’

ğ‘ŸP (

ğœƒ)

b

b

b

b
yâŠ¤ğ‘”(ğ‘“ (x;

ğœƒ ))

b

b
âˆ’

Ã•(x,y)âˆ¼Pâ€²

Pâ€² âˆˆğ‘‡ (P,A) (cid:0) Ã•(x,y)âˆ¼P
yâŠ¤ğ‘”(ğ‘“ (x;

ğœƒ ))

(cid:1)

b

b

sup
Pâ€² âˆˆğ‘‡ (P,A)

1
ğ‘›

ğ‘ŸPâ€² (

ğœƒ ) â‰¤

ğ‘ŸP (

ğœƒ) +

b

b

b

b
âˆ’

sup

Pâ€² âˆˆğ‘‡ (P,A) (cid:0) Ã•(x,y)âˆ¼P
yâŠ¤ log(ğ‘“ (x;

ğœƒ ))

yâŠ¤ log(ğ‘“ (x;

ğœƒ ))

b

Ã•(x,y)âˆ¼Pâ€²

(cid:1)

b

If we use ğ‘’ (Â·) = âˆ’yâŠ¤ log(Â·) to replace the cross-entropy loss, we
simply have:

sup
Pâ€² âˆˆğ‘‡ (P,A)

1
ğ‘›

ğ‘ŸPâ€² (

ğœƒ ) â‰¤

ğ‘ŸP (

ğœƒ) +

b

b

b

b
âˆ’

Ã•(x,y)âˆ¼P

sup

ğ‘’ (ğ‘“ (x;

ğœƒ ))

Pâ€² âˆˆğ‘‡ (P,A) (cid:0) Ã•(x,y)âˆ¼Pâ€²
ğœƒ ))
ğ‘’ ((ğ‘“ (x;

b

(cid:1)

b

Since ğ‘’ (Â·) is a Lipschitz function with constant â‰¤ 1 (because of A6,
Eq.(6)) and together with the dual representation of Wasserstein
metric (See e.g., [56]), we have

sup
Pâ€² âˆˆğ‘‡ (P,A)

ğ‘ŸPâ€² (

ğœƒ ) â‰¤

ğ‘ŸP (

ğœƒ ) + ğ‘Š1 (

Q

,

x,
ğœƒ

Q

ğ‘ (x),
ğœƒ

))

b

b

b

b

b
where xâ€² = ğ‘(x), where ğ‘ = arg minğ‘ âˆˆA yâŠ¤ ğ‘“ (ğ‘(x);
notes the empirical distribution of ğ‘“ (ğ‘(x);
Note that ğ‘ŸP,A (

b
ğœƒ), by deï¬nition, is a shorthand notation for

b

ğœƒ ) for (x, y) âˆˆ (X, Y).
b

b

ğœƒ );

Q

x,
ğœƒ

de-

b

b

b

b

sup
Pâ€² âˆˆğ‘‡ (P,A)

ğ‘ŸPâ€² (

ğœƒ )

b

.

Further, we can use the help of Proposition B.2 to replace Wassertein

metric with â„“1 distance. Finally, we can conclude the proof with As-
(cid:3)
sumption A5 as how we did in the proof of Lemma B.1.

KDD â€™22, August 14â€“18, 2022, Washington, DC, USA

Wang, et al.

Clean

23.9
23.6
22.4
24.5
22.8
23
27.2
22.4
25.2

Gauss
79
78
61
67
69
73
69
65
61

B
RVA
RWA
SU
AA
MBP
SIN
AM
AMS

Noise
Shot
80
78
63
68
68
74
70
66
62

Impulse
82
79
63
70
72
76
70
67
61

Blur

Weather

Digital

Defocus
82
74
68
74
77
74
77
70
69

Glass
90
87
75
83
83
86
84
80
77

Motion
84
79
65
81
80
78
76
66
63

Zoom
80
76
66
77
81
77
82
66
72

Snow
86
78
70
80
79
77
74
75
66

Frost
81
75
69
74
75
72
75
72
68

Fog
75
69
64
75
64
63
69
67
63

Bright
65
58
56
62
56
56
65
58
59

Contrast
79
68
55
77
70
68
69
58
52

Elastic
91
85
70
84
88
86
80
79
74

Pixel
77
75
61
71
57
71
64
69
60

JPEG
80
75
63
71
71
71
77
69
67

mCE

80.6
75.6
64.6
74.3
72.7
73.4
73.3
68.4
64.9

Table 6: Comparison to advanced models over ImageNet-C data. Performance reported (mCE) follows the standard in
ImageNet-C data: mCE is the smaller the better.

B
0.1204
0.2408

InfoDrop
0.1224
0.256

HEX
0.1292
0.2564

PAR
0.1306
0.2627

VA
0.1362
0.2715

RVA
0.1405
0.2793

RSC
0.1612
0.3078

VWA
0.1432
0.2846

RWA
0.1486
0.2933

Top-1
Top-5

Table 7: Comparison to advanced cross-domain image classiï¬cation models, over ImageNet-Sketch dataset. We report top-1
and top-5 accuracy following standards on ImageNet related experiments.

A.4 Proof of Lemma 5.2
Lemma. With Assumptions A1-A6, assuming there is a ğ‘â€²() âˆˆ A
, with probability at least 1 âˆ’ğ›¿,
where
we have:
b
ğœƒ ) â‰¤

ğ‘ŸPğ‘+ (
(cid:0)
b
ğœƒ )

ğœƒ ) = 1
2

ğ‘ŸPğ‘âˆ’ (

ğ‘ŸPğ‘â€² (

ğœƒ) +

(8)

ğœƒ )

b

b

b

(cid:1)

ğ‘ŸP,A (

b
1
2
+

ğ‘ŸPğ‘+ (
(cid:0)
ğ‘ŸPğ‘âˆ’ (
b

b
ğœƒ )

(cid:1)

b

b

b

+

Ã•ğ‘–

||ğ‘“ (ğ‘+(xğ‘– );

ğœƒ ) âˆ’ ğ‘“ (ğ‘âˆ’(xâ€²);

ğœƒ )||1 + ğœ™ (|Î˜|, ğ‘›, ğ›¿)

b

b

(9)

Proof. We can continue with

sup
Pâ€² âˆˆğ‘‡ (P,A)

ğ‘ŸPâ€² (

ğœƒ ) â‰¤

ğ‘ŸP (

ğœƒ ) + ğ‘Š1 (

Q

,

x,
ğœƒ

Q

ğ‘ (x),
ğœƒ

)),

b

b

Q

b
denotes the empirical distribution of ğ‘“ (ğ‘(x);
where
(X, Y). from the proof of Theorem 5.2. With the help of Assump-
tion A3, we have:

x,
ğœƒ

b

b

b

b

b

ğœƒ ) for (x, y) âˆˆ

b

b

b

ğ‘‘ğ‘¥ (ğ‘“ (ğ‘+ (x),

ğœƒ ), ğ‘“ (ğ‘âˆ’(x),

ğœƒ )) â‰¥ ğ‘‘ğ‘¥ (ğ‘“ (x,

ğœƒ ), ğ‘“ (xâ€²,

ğœƒ ))

When ğ‘‘ğ‘¥ (Â·, Â·) is chosen as Wasserstein-1 metric, we have:
b

b

b

b

sup
Pâ€² âˆˆğ‘‡ (P,A)

ğ‘ŸPâ€² (

ğœƒ) â‰¤

ğ‘ŸP (

ğœƒ ) + ğ‘Š1 (

Q

ğ‘+ (x),
ğœƒ

,

Q

ğ‘âˆ’ (x),
ğœƒ

))

b

b

b

b

b

b

b

b

,

Q

Q

ğ‘+ (x),
ğœƒ

Further, as the LHS is the robust risk generated by the transfor-
ğœƒ) is independent of the term
mation functions within A, and
ğ‘ŸP (
ğ‘Š1 (
ğœƒ ) with the risk
)), WLOG, we can replace
b
of an arbitrary distribution generated by the transformation func-
tion in A. If we choose to use
,
we can conclude the proof with help from Proposition B.2 and As-
(cid:1)
b
(cid:3)
sumption A5 as how we did in the proof of Theorem 5.2.

b
b
ğœƒ ) +
ğ‘ŸPğ‘+ (
(cid:0)
b

ğœƒ) = 1
2

ğ‘ŸPğ‘âˆ’ (

ğ‘âˆ’ (x),
ğœƒ

ğ‘ŸPğ‘â€² (

ğ‘ŸP (

ğœƒ )

b

b

b

b

b

b

b

b

b

B ADDITIONAL RESULTS FOR

COMPARISONS WITH ADVANCED
METHODS

We have also conducted two full ImageNet level experiments. How-
ever, due to the limitation of resources, we cannot tune the models
substantially. Our current trial suggest that our techniques can im-
prove the vanilla model to compete with SOTA models, limited by

our resources, we cannot do wide-range hyperparameters search
to outperform them. Also, considering the fact that many of these
methods are signiï¬cantly more complicated than us and also uses
data augmentation specially designed for the tasks, we consider
our experiments a success indication of the empirical strength of
our methods.

Texture-perturbed ImageNet classiï¬cation. We also test the per-
formance on the image classiï¬cation over multiple perturbations.
We train the model over standard ImageNet training set and test
the model with ImageNet-C data [25], which is a perturbed ver-
sion of ImageNet by corrupting the original ImageNet validation
set with a collection of noises. Following the standard, the reported
performance is mCE, which is the smaller the better. We compare
with several methods tested on this dataset, including Patch Uni-
form (PU) [43], AutoAugment (AA) [13], MaxBlur pool (MBP) [67],
Stylized ImageNet (SIN) [25], AugMix (AM) [26], AugMix w. SIN
(AMS) [26]. We use the performance reported in [26]. Again, our
augmention only uses the generic texture with perturbation (the
A in our texture synthetic experiments with radius changed to
20, 25, 30, 35, 40). The results are reported in Table 6, which shows
that our generic method outperform the current SOTA methods
after a continued ï¬netuning process with reducing learning rates.

Cross-domain ImageNet-Sketch Classiï¬cation. We also compare
to the methods used for cross-domain evaluation. We follow the
set-up advocated by [59] for domain-agnostic cross-domain pre-
diction, which is training the model on one or multiple domains
without domain identiï¬ers and test the model on an unseen do-
main. We use the most challenging setup in this scenario: train the
models with standard ImageNet training data, and test the model
over ImageNet-Sketch data [58], which is a collection of sketches
following the structure ImageNet validation set. We compare with
previous methods with reported performance on this dataset, such
as InfoDrop [2], HEX [59], PAR [58], RSC [32] and report the perfor-
mances in Table 7. Notice that, our data augmentation also follows
the requirement that the characteristics of the test domain cannot
be utilized during training. Thus, we only augment the samples

Toward Learning Robust and Invariant Representations with Alignment Regularization and Data Augmentation

KDD â€™22, August 14â€“18, 2022, Washington, DC, USA

with a generic augmentation set (A of â€œcontrastâ€ in synthetic ex-
periments). The results again support the usage of data augmenta-
tion and alignment regularization.

