MASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

1

Inverse-Dynamics MPC via Nullspace Resolution

Carlos Mastalli† Saroj Prasad Chhatoi† Thomas Corb`eres Steve Tonneau Sethu Vijayakumar

2
2
0
2

p
e
S
2
1

]

O
R
.
s
c
[

1
v
5
7
3
5
0
.
9
0
2
2
:
v
i
X
r
a

Abstract—Optimal control (OC) using inverse dynamics pro-
vides numerical beneﬁts such as coarse optimization, cheaper
computation of derivatives, and a high convergence rate. How-
in order to take advantage of these beneﬁts in model
ever,
predictive control (MPC) for legged robots, it is crucial to handle
its large number of equality constraints efﬁciently. To accomplish
this, we ﬁrst (i) propose a novel approach to handle equality
constraints based on nullspace parametrization. Our approach
balances optimality, and both dynamics and equality-constraint
feasibility appropriately, which increases the basin of attraction
to good local minima. To do so, we then (ii) modify our feasibility-
driven search by incorporating a merit function. Furthermore, we
introduce (iii) a condensed formulation of the inverse dynamics
that considers arbitrary actuator models. We also develop (iv)
a novel MPC based on inverse dynamics within a perceptive
locomotion framework. Finally, we present (v) a theoretical
comparison of optimal control with the forward and inverse
dynamics, and evaluate both numerically. Our approach enables
the ﬁrst application of inverse-dynamics MPC on hardware,
resulting in state-of-the-art dynamic climbing on the ANYmal
robot. We benchmark it over a wide range of robotics problems
and generate agile and complex maneuvers. We show the com-
putational reduction of our nullspace resolution and condensed
formulation (up to 47.3%). We provide evidence of the beneﬁts
of our approach by solving coarse optimization problems with
a high convergence rate (up to 10 Hz of discretization). Our
algorithm is publicly available inside CROCODDYL.

Index Terms—model predictive control,

inverse dynamics,

nullspace parametrization, legged robots, agile maneuvers.

I. INTRODUCTION

O PTIMAL control (OC) of rigid body systems is a power-

ful tool to synthesize robot motions and controls. It aims
to achieve complex motor maneuvers in real time, as shown
in Fig. 1, while formally considering its intrinsic properties [1]:
nonholonomic, actuation limits, balance, kinematic range, etc.
We can describe rigid body dynamics through its forward or
inverse functions, and efﬁciently compute them via recursive
algorithms [2]. Similarly, we can formulate optimal control
problems for rigid body systems using their forward and
inverse dynamics. Yet, recent works on MPC (e.g., [3], [4], [5])

This research was supported by (1) the European Commission under the
Horizon 2020 project Memory of Motion (MEMMO, project ID: 780684),
Natural Intelligence (project ID: 101016970) (2) the Engineering and Physical
Sciences Research Council (EPSRC) UK RAI Hub for Offshore Robotics
for Certiﬁcation of Assets (ORCA, grant reference EP/R026173/1), and (3)
the Alan Turing Institute. †These are the leading authors of this work.
(Corresponding author: Carlos Mastalli)

Carlos Mastalli is with the School of Engineering and Physical Sciences,

Heriot-Watt University, U.K. (e-mail: c.mastalli@hw.ac.uk).

Saroj Prasad Chhatoi is with Centro di Ricerca “Enrico Piaggio”, Universit`a

di Pisa, Italy (e-mail: s.chhatoi@studenti.unipi.it).

Thomas
are with
U.K.
sethu.vijayakumar@ed.ac.uk).

Corb`eres,
the
(e-mail:

School

Steve
of

Tonneau

Informatics, University

and

Sethu

Vijayakumar
of Edinburgh,
stonneau@exseed.ed.ac.uk;

t.corberes@sms.ed.ac.uk;

Fig. 1. ANYmal climbing up a damaged staircase using our inverse-
dynamics MPC via our nullspace parametrization. In the instance shown by
this ﬁgure, ANYmal is crossing the gap incurred by a missing tread. The
dimension of this gap is 26 cm in length and 34 cm in height, which represents
an inclination of 37° and around half of the ANYmal robot. The footstep plan
shown in the bottom-left corner is computed online thanks to our perceptive
locomotion pipeline. Details of our perceptive locomotion pipeline will be
described in an upcoming publication. To watch the video, click the ﬁgure or
see https://youtu.be/NhvSUVopPCI.

are based only on forward dynamics, as they can be efﬁciently
solved via differential dynamic programming (DDP) [6]. In-
deed, model predictive control with inverse dynamics poses
new challenges. It requires handling equality constraints ef-
ﬁciently and exploiting its temporal and functional structure.
With temporal structure, we refer to the inherent Markovian
dynamics commonly encountered in optimal control problems.
Instead, with functional structure, we refer to the sparsity
pattern deﬁned by the inverse dynamics itself.

When formulating an optimal control problem via inverse
dynamics and direct transcript [7], we decouple the integrator
and robot dynamics. This imposes two different equality
constraints on the nonlinear program. Such a strategy dis-
tributes the nonlinearities of both constraints, which helps to
deal with coarse discretization and poor initialization and to
improve the convergence rate. Moreover, the time complexity
of computing the inverse dynamics is lower than the forward
dynamics [2]. This also applies to the recursive algorithms
that compute their analytical derivatives [8]. Both are among
the most expensive computations when solving a nonlinear
optimal control problem. Finally, the control inputs of inverse-
dynamics formulations are the generalized accelerations and
contact forces, instead of the joint torques as in forward-
dynamics settings. This allows us to compute feedback policies
for the generalized accelerations and contact forces, which can
be easily integrated into an instantaneous controller (e.g., [9],
[10]) to further ensure dynamics, balance, actuation limits, etc.,
at a higher control frequency. Having such advantages in MPC
for legged robots helps to generate complex maneuvers such

 
 
 
 
 
 
MASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

2

as the ones needed to climb up a damaged staircase (Fig. 1).
The DDP algorithm exploits the structure of optimal control
problems based on the forward models of the dynamics. This
is a critical aspect for the deployment of model predictive
controllers in legged robots, as we can see in recent works [3],
[4], [5], [11]. However, in contrast to the forward-dynamics
formulations, there are no algorithms available that exploit the
structure of problem formulations based on inverse models.
This is a limiting factor to deploy inverse-dynamics MPC in
legged robots. To address this issue, we propose an algorithm
that takes advantage of the structure of optimal control prob-
lems with inverse-dynamics constraints. We summarize our
method as follows. First, to exploit the temporal structure,
we parametrize the inverse-dynamics constraints using its
nullspace basis. This allows us to perform parallel computa-
tions that reduce its algorithmic complexity. Second, to exploit
the functional structure, we condense the inverse dynamics and
inject this sparsity into the computation of the action-value
function.

A. Contribution

The main contribution of this work is an efﬁcient method
for solving optimal control problems with inverse dynamics,
which enables the application of inverse-dynamics MPC in
legged robots. It relies on four technical contributions:

(i) an efﬁcient method based on nullspace parametrization

for handling equality constraints,

(ii) a feasibility-driven search and merit function approach
that considers both dynamics and equality-constraint fea-
sibility,

(iii) a condensed inverse-dynamics formulation that handles

arbitrary actuation models, and

(iv) a novel feedback MPC based on inverse dynamics inte-

grated into a perceptive locomotion pipeline.

novel

optimal-control

algorithm enables

inverse-
Our
dynamics MPC in legged robots, resulting in state-of-the-art
dynamic climbing on the ANYmal robot. It uses acceleration
and contact force policies to increase execution accuracy,
which forms an integral part of feedback MPC approaches.
Below, after introducing the related work, we present a brief
theoretical description of optimal control with the forward
and inverse dynamics. This section aims to provide details
that help us to understand the beneﬁts and challenges of
inverse-dynamics MPC.

II. RELATED WORK

There is a recent interest in solving optimal control (OC)
problems with inverse dynamics. Some of the motivations
are faster computation of inverse dynamics and their deriva-
tives [2], [8], convergence within fewer iterations [12], [13],
and coarse problem discretization [14]. Although OC with
inverse dynamics improves convergence rate and coarse dis-
cretization, these methods are slow for MPC applications.
The main reason is that they do not exploit the temporal
and functional structure efﬁciently. In addition, their compu-
tational complexity increases with respect to the number of

Fig. 2.
Illustration of various locomotion gaits optimized using our inverse-
dynamics formulation and solver for ANYmal with a Kinova arm. These
motions were optimized in less than 20 iterations and 500 milliseconds. (top)
Multiple walking gaits with 25 cm of step length. (middle) Multiple trotting
gaits with 10 cm of step length. (bottom) Multiple jumping gaits with 30 cm
of length. To watch the video, click the ﬁgure or see https://youtu.
be/NhvSUVopPCI?t=10.

contacts. These reasons might explain why recently predic-
tive controllers on legged robots are based only on forward
dynamics [3], [4], [5], [11]. Below, we begin by describing
the state of the art in OC in rigid body systems and MPC in
legged robots.

A. Optimal control in rigid body systems

The forward dynamics ﬁts naturally into classical opti-
mal control formulations, which includes rigid body sys-
tems subject
to any constraints (e.g., holonomic contact
constraints [15]). It allows us to condense the rigid body
dynamics thanks to the application of Gauss’s principle of
least constraint [16]. Moreover, this formulation can be solved
efﬁciently via the DDP algorithm, as it exploits the temporal
structure through the Riccati factorization (well known as
Riccati recursion) [17]. Both aspects boost the computational
efﬁciency as the cache access is effective in smaller and dense
matrices rather than large and sparse ones (see benchmarks
in [18]). Indeed, state-of-the-art solvers for sparse linear
algebra are not as efﬁcient as factorizing through a Riccati
recursion [19]. Despite that, they are commonly used to solve
optimal control problems with general-purpose numerical opti-
mization programs such as SNOPT [20], KNITRO [21], and
IPOPT [22].

In the case of optimal control with inverse dynamics, there
are pieces of evidence on the numerical beneﬁts of such kinds
of formulations. Concretely, there are two recent works based
on direct transcription and inverse dynamics, which resolve
the optimal control problem via a general-purpose nonlinear
program [13] or a custom-made nonlinear optimal control
solver [12]. The ﬁrst work relies on KNITRO, an advanced
general-purpose nonlinear solver, and benchmarks results with
INTERIOR/DIRECT [23] and the sparse linear solvers provided
by HSL [24] software: MA27, MA57, and MA97. Instead,
the second work factorizes the linear system through a Riccati

MASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

3

recursion. We name this approach INTERIOR/RICCATI. Both
INTERIOR/DIRECT and INTERIOR/RICCATI techniques han-
dle the inequality constraints using primal-dual interior point
and line search. However, INTERIOR/RICCATI is signiﬁcantly
faster (at least 1 order of magnitude) than INTERIOR/DIRECT.
This is because the Riccati recursions exploit the problem’s
temporal structure. Nevertheless, INTERIOR/RICCATI scales
cubically to the number of equality constraints. This reduces
importantly its efﬁciency on problems with contact constraints.
Furthermore, as reported in [13], INTERIOR/DIRECT often
struggles to get solutions with very low feasibility (i.e., lower
than 10−9) in a few iterations. In this work, we provide
a method that
i.e., an approach that
converges fast with high feasibility. Fig. 2 shows a sequence
of optimized motions computed efﬁciently with our approach.

tackles these issues,

B. MPC and legged locomotion

are used such as

In most of the state-of-the-art MPC approaches, reduced-
order dynamics
inverted pendulum
model [25], [26] or the single-rigid body dynamics [27], [28],
[29], [30] that may also include the robot’s full kinemat-
ics [31], [32]. The motivation for doing is to reduce the
computational complexity by ignoring the limb’s dynamics,
as robots are often designed to have lightweight
legs or
arms. However, recent evidence suggests that they still play a
signiﬁcant role in the control of those types of robots [33]. In
contrast, there is a wave of recent works that focus on MPC
with the robot’s forward dynamics [3], [4], [5], [11]. Using
the robot’s full-body dynamics brings beneﬁts in terms of
whole-body manipulation [3], [11] and agile locomotion and
control [5], [34]. Nevertheless, to date, there is no single MPC
approach that relies on inverse dynamics. This is due to
the algorithmic complexity of handling equality constraints is
much higher than its counterpart.

Feedback MPC computes optimal

trajectories and local
controllers that aim to increase tracking performances. This
improvement in tracking performance is because these local
controllers compensate for model errors and disturbances be-
tween MPC updates. Building local controllers is challenging
as simpliﬁcations of the robot’s dynamics tend to produce
aggressive controllers. For instance, when we assume that
the robot behaves as a single-rigid body, the DDP algorithm
computes feedback gains for a hypothetical system with higher
bandwidth. This assumption produces feedback controllers
that cannot stabilize the robot (c.f. [32]). To deal with this
issue, we can augment the dynamics with a ﬁlter, use the full
kinematics, and deﬁne a frequency-dependent cost function as
in [32]. However, this augmented system is larger than the full-
body system. This in itself increases the time complexity of
algorithms for optimal control. Alternatively, we can employ
the robot’s rigid-body dynamics to model the bandwidth of
the full-body system. Despite that, this model neglects the
actuation bandwidth. This assumption seems to hold for a
wide range of legged robots as we can build feedback con-
trollers even in robots with serial elastic actuators such as
ANYmal [5]. Note that the actuation bandwidth is lower in
robots with elastic elements.

III. OPTIMAL CONTROL OF RIGID BODY SYSTEMS

In this section, we discuss the differences between for-
ward and inverse optimal control formulations for rigid body
systems subject to predeﬁned contact sequences. We use a
general problem formulation that considers arbitrary high-
order integrators.

A. Optimal control with the forward dynamics

Classical optimal control formulations (e.g., [35]) involve

the use of the forward dynamics:

min
(qs,vs),(τ s,λs)

(cid:96)N (qN , vN ) +

N −1
(cid:88)

(cid:90) tk+1

k=0

tk

(cid:96)k(qk, vk, τ k, λk) dt

s.t.

[qk+1, vk+1] = ψ(qk, vk, FD(qk, vk, τ k, λk)),

qk ∈ Q, vk ∈ V, τ k ∈ P, λk ∈ F,

(1)

where qk, vk, τ k, and λk are the decision variables and
describe the conﬁguration point, generalized velocity, joint
torque commands, and contact forces of the rigid body system
at node k; N deﬁnes the optimization horizon; ψ(·) deﬁnes the
integrator function; FD(·) represents the forward dynamics,
which computes the generalized accelerations ˙v through the
articulate body algorithm (ABA) [2]:

M ˙v = τ bias + J(cid:62)

c λ,

or through the contact dynamics [15], [36]:
(cid:21)−1 (cid:20)τ bias
−ac

(cid:20)M J(cid:62)
c
0
Jc

(cid:20) ˙v
−λ

=

(cid:21)

(cid:21)

.

(2)

Note that M is the joint-space inertia matrix; τ bias includes
the torque inputs, Coriolis effect and gravitation ﬁeld; ac
is the desired acceleration in the constraint space, which
includes the Baumgarte stabilization [37]; Jc is the stack of
contact Jacobian (expressed in the local frame) that models
the holonomic scleronomic constraints. Additionally, all the
trajectories (qs, vs, τ s, λs) lie in their respective admissible
sets. These admissible sets commonly deﬁne the robot’s joint
limits, friction cone, task constraints, etc.

B. Optimal control with the inverse dynamics

In an inverse-dynamics OC formulation, we substitute the
dynamical system with an equality constraint and include the
generalized accelerations as decision variables:

[qk+1, vk+1] = ψ(qk, vk, ak),
ID(qk, vk, ak, τ k, λk) = 0,

(3)

where ID(·) is the inverse-dynamics function. This function
is typically computed through the recursive Newton-Euler
algorithm (RNEA) [2] if we do not consider the contact
constraints Jc ˙v − ac = 0. This formulation can be interpreted
as a kinodynamic motion optimization (e.g., [9]), in which
we kinematically integrate the system while guaranteeing its
dynamics through constraints. Note that the decision variables
for the k node are now qk, vk, ak, τ k, and λk, which increases
compared to the forward-dynamics OC formulations.

MASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

4

One compelling motivation for optimal control approaches
based on inverse dynamics is the numerical beneﬁts of de-
coupling the integrator and robot dynamics. This helps to
solve coarse optimization problems, handle poor initialization,
and improve the convergence rate. Indeed, as shown later
in Section VII, our approach has the same advantages as
reported in the literature.

C. Inverse vs forward dynamics in optimal control

We can compute the inverse dynamics more efﬁciently
than the forward dynamics, as the algorithm complexity of
the RNEA is lower than the ABA [2]. The same applies to
the computation of their derivatives [8]. However, we can-
not condense the contact forces or generalized accelerations
decision variables if we are unwilling to sacriﬁce physical
realism in the contact dynamics [38], [14]. This, unfortunately,
increases the problem dimension and the computation time
needed to factorize the Karush-Kuhn-Tucker (KKT) problem
of each node. In contrast,
in the forward dynamics case,
we can condense these variables thanks to the application of
Gauss’s principle of least constraint [16]. Indeed, our recent
work [36] showed highly-efﬁcient computation of optimal
control problems using forward dynamics, which enables MPC
applications in quadrupeds [5] and humanoids [11].

Inverse-dynamics formulations are not as dense as their
counterparts. One example of this fact can be seen if we
observe that it increases the number of decision variables.
is about 3000 extra decision variables (or
This increment
38%) for a quadruped robot and an optimization horizon of
100 nodes (or 1 s). To solve these problems, we need to
handle equality constraints efﬁciently and to further exploit
its structure. However, the algorithm complexity of state-of-
the-art approaches scales cubically to the number of equality
constraints.

D. Our nullspace approach in a nutshell

Fig. 3 shows a comparison between optimal control with the
forward dynamics and our inverse dynamics approach (blue
blocks). The method we developed can be interpreted as a
reduction in the system dimensionality so as to increase the
effectiveness of optimal control with inverse dynamic This
reduction is due to a nullspace parametrization in our OC
solver and condensed representation of the inverse dynamics.
Before introducing our condensed representation, we begin by
describing our nullspace method for solving efﬁciently OC
problems using inverse dynamics. Our method uses exact
algebra and exploits the problem’s structure as shown below.

IV. RESOLUTION OF OPTIMAL CONTROL WITH INVERSE
DYNAMICS

In this section, we describe our approach to handling
inverse-dynamics (equality) constraints. These types of con-
straints are nonlinear and can be fulﬁlled within a single

Fig. 3. Comparison of optimal control using forward dynamics and our inverse
dynamic approach. In forward-dynamics settings, we can apply Gauss’s
principle of least constraint
to reduce the number of decision variables,
as we have a compact representation that depends on q, v, and τ only.
In contrast,
this principle cannot be applied to inverse-dynamics models
to reduce the number of decision variables. Instead, our inverse-dynamics
approach can be interpreted as a reduction in the system dimensionality by
ﬁrst condensing the dynamics and then using a nullspace parametrization.
Note that uz is a representation of (τ , λ) that comes from a nullspace
parametrization. Section IV-A and V-A provide a rigorous description of the
nullspace parametrization and condensed inverse dynamics, respectively.

node. Here, we are interested in solving the following optimal
control problem efﬁciently:

min
xs,us

(cid:96)N (xN ) +

N −1
(cid:88)

k=0

(cid:96)k(xk, uk)

(4)

s.t. xk+1 = fk(xk, uk), hk(xk, uk) = 0,

where, similarly to Eq. (3), f (·) deﬁnes the kinematic evolution
of the system (i.e., integrator), h(·) ensures the feasibility of
the dynamics through its inverse-dynamics function, x ∈ X
lies in a differential manifold (with dimension nx), and u ∈
Rnu are the input of the system.

To introduce our method, we begin by developing the KKT
conditions of Eq. (4) for a single node (Section IV-A).
This allows us to exploit
the temporal structure inherent
in optimal control as in DDP [6]. Then, we describe our
nullspace parametrization and compare it with the state of the
art: the Schur-complement approach (Section IV-B). Finally,
we present our method to drive the dynamics and equality
constraint infeasibilities to zero (Section IV-D). It boils down
to a novel combination of feasibility-driven search and merit
function.

A. Equality constrained differential dynamic programming

If we apply the Newton method to the KKT conditions
of Eq. (4) and the Bellman principle of optimality, we can now
solve recursively the following system of linear equations per
each node k:









Lxx L(cid:62)
ux h(cid:62)
x
Lux Luu h(cid:62)
u
hu
hx
fu
fx









f (cid:62)
x
f (cid:62)
u

−I
−I V (cid:48)

xx









δx
δu
γ+
ξ+
δx(cid:48)









= −









(cid:96)x
(cid:96)u
¯h
¯f
V (cid:48)
x









,

(5)

Gauss's principleof least constraintCondensedinverse dynamicsNullspaceparametrizationour inverse-dynamicsforward-dynamicsMASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

5

with

x · fxx,
x · fuu,

Lxx := (cid:96)xx + V (cid:48)
Luu := (cid:96)uu + V (cid:48)
ξ+ := ξ + δξ,
¯f := f (x, u) (cid:9) x(cid:48),

x · fxu,

Lxu := (cid:96)xu + V (cid:48)
γ+ := γ + δγ,
¯h := h(x, u),

x, V (cid:48)

where (cid:96)w, hw, fw, describe the ﬁrst derivatives of the cost,
equality constraint, and system dynamics with respect
to
w, respectively; fww is the second derivative of the system
dynamics; V (cid:48)
xx are the gradient and Hessian of the value
function; γ, ξ are the Lagrange multipliers associated with
the equality constraint and system dynamics; ¯h, ¯f describe the
gaps in the equality constraint and dynamics; δx, δu, δx(cid:48) and
δγ, δξ provides the search direction computed for the primal
and dual variables, respectively; (cid:9) is the difference operator
needed to optimize over manifolds [39]. This notation is in-
spired by [40] and adopted in CROCODDYL [36]. Finally, note
that (i) w is a hypothetical decision variable that represents x
or u, (ii) we have dropped the node index k for the sake of
simplicity, and (iii) ¯f corresponds to the kinematic gap while
¯h to the inverse-dynamics and contact-acceleration gaps.

1) Where does this equation come from?: Eq. (5) exploits
the temporal structure of the optimal control problem, as it
breaks this large problem into smaller sub-problems. Those
sub-problems are solved recursively and backwards in time.
We can do so because the following relationship holds for all
the nodes

xxδx.

ξ+ = V (cid:48)

x + V (cid:48)
This equation connects the derivatives of the value function
with the next costate ξ+. Such a connection should not surprise
us if we observe that Pontryagin’s maximum principle (PMP)
and KKT conditions are two equivalent ways to deﬁne the
local minima. Indeed, Bellman recognized this connection in
his groundbreaking work [41], which is better known for
establishing the Hamilton-Jacobi-Bellman (HJB) equation in
the continuous-time domain. Alternatively, we encourage the
readers to see [17] that revisits this connection. From now
on, we will elaborate on the different concepts used by our
algorithm.

B. Search direction and factorization

Due to the temporal structure introduced by the system
dynamics in Eq. (5) and the dynamic programming principle,
we can condense this linear system of equations and describe
this problem as

∆V = min
δu

s.t.

(cid:20)δx
1
δu
2
(cid:2)hx hu

(cid:3)

(cid:21)(cid:62) (cid:20)Qxx Q(cid:62)
ux
Qux Quu
(cid:21)

+ ¯h = 0,

(cid:20)δx
δu

(cid:21)

(cid:21) (cid:20)δx
δu

+

(cid:21)

(cid:20)δx
δu

(cid:21)(cid:62) (cid:20)Qx
Qu

(6)

where the Q’s describe the local approximation of the action-
value function in the free space:
Qx = (cid:96)x + f (cid:62)
x V (cid:48)
u V (cid:48)

Qu = (cid:96)u + f (cid:62)
u V +
x ,
u V (cid:48)
Qux = Lux + f (cid:62)

Qxx = Lxx + f (cid:62)
Quu = Luu + f (cid:62)

x V +
x ,
xxfx,
xxfu,

xxfx,

(7)

x := V (cid:48)

x + V (cid:48)
xx

¯f representing the gradient of the value
with V +
function after the deﬂection produced by the dynamics gap
¯f (see [36], [17]). Furthermore, the local quadratic program
deﬁned in Eq. (6) has the following ﬁrst-order necessary
conditions of optimality

(cid:20)Quu h(cid:62)

u

hu

(cid:21)

(cid:21) (cid:20)δu
γ+

= −

(cid:20)Qu + Quxδx
¯h + hxδx

(cid:21)

,

which are the same conditions of Eq. (5) after condensing this
linear system of equations. Note that this equation forms a
dense saddle point system.

This problem can be solved by what we call a Schur-
complement factorization (e.g., [42]). However, this approach
increases the algorithm complexity of the Riccati recursion.
This increment is related to the number of equality constraints.
Instead, we propose a nullspace factorization approach that
does not increase the algorithm complexity needed to han-
dle the equality constraints. This is particularly important
in inverse-dynamics formulations, as these problems have a
large number of equality constraints. Below, we ﬁrst introduce
the Schur-complement factorization and then our nullspace
factorization. With this, we explain the drawbacks of the state
of the art and then justify the computational beneﬁts of our
method.

1) Schur-complement factorization: We can compute the
control policy (for the primal decision variable δu) by factor-
izing this problem through the Schur-complement approach:

δu = −k − Kδx − ΨsQ−1
γ+ := ˆQuu(ˆks + ˆKs δx),

uuh(cid:62)

u γ+,

uuh(cid:62)

uuQu, K = Q−1
where k = Q−1
uuQux are the feed-forward
u , ˆQuu =
and feedback gain on the free space, Ψs = Q−1
u )−1, ˆks = ¯h − huk, ˆKs = hx − huK are
(huQ−1
terms associated with the computation of the feed-forward and
feedback gain on the constrained space. Thus, the ﬁnal control
policy has the form

uuh(cid:62)

δu = −πs − Πs δx,

with

πs := k + (ˆk(cid:62)
ˆQuuΨ(cid:62)
s
ˆQuuΨ(cid:62)
Πs := K + ( ˆK(cid:62)
s

s )(cid:62) (feed-forward),
s )(cid:62) (feedback gain).

(8)

This factorization technique requires performing two Cholesky
uu and ˆQuu. It means that
decompositions for computing Q−1
the computational complexity of obtaining the control policy
increases cubically with respect to the number of equality
constraints as well. Note that ˆQuu is a square matrix with
a dimension equal to the number of equality constraints of the
node.

2) Nullspace factorization: Using the fundamental basis of
hu, we can decompose/parametrize the decision variable δu
as follows

δu = Yδuy + Zδuz,

where Z ∈ Rnu×nz is the nullspace basis of hu (with nz as
its nullity), Y is chosen such that [Y Z] spans Rnu . Then,

MASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

6

by substituting δu into the above optimality conditions and
observing that huZ = 0, we obtain
(cid:20)Z(cid:62)QuuZ Z(cid:62)QuuY

(cid:21)

(cid:21)

= −

(cid:20)Z(cid:62)(Qu + Quxδx)
¯h + hxδx

.

(cid:21) (cid:20)δuz
δuy

huY

This equation allows us to compute the control policy as:

δu = −πn − Πn δx,

with

πn := Zˆkn + ˆQzzΨn¯h (feed-forward),
(feedback gain),

Πn := Z ˆKn + ˆQzzΨnhx

(9)

zz Qz, ˆKn = Q−1

where ˆkn = Q−1
zz Qzx are the feed-forward
and feedback gain associated with the nullspace of the equality
constraint, ˆQzz = I − ZQ−1
zz Qzu, Ψn = Y(huY)−1 are
terms that project the constraint into both spaces: range and
nullspace. Note that Qz = Z(cid:62)Qu, Qzx = Z(cid:62)Qux, Qzu =
Z(cid:62)Quu, Qzz = QzuZ describe the local approximation of
the action-value function in the nullspace.

Now, we observe that our nullspace factorization re-
quires performing three decompositions for computing Q−1
zz ,
(huY)−1, and the constraint basis for the image and nullspace
[Y Z]. The two formers can be inverted efﬁciently via the
Cholesky and LU with partial pivoting decompositions, re-
spectively, as these matrices are positive deﬁnite and square
invertible by construction. Instead, the constraint basis can be
computed using any rank-revealing decomposition such as LU
with full pivoting or QR with column pivoting [43].

3) Why is our nullspace approach more efﬁcient?: Al-
though the nullspace factorization requires an extra decom-
position compared with the Schur-complement approach, its
i.e., Ψn = Y(huY)−1,
computation can be parallelized,
Ψn¯h, Ψnhx, and [Y Z]. Thus, the computational complexity
of the Riccati recursion does not grow with the number of
equality constraints, as it runs in the nullspace of the con-
straints. Indeed, its asymptotic complexity is O(N (nx+nu)3),
where nx deﬁnes the dimension of the state and nu of the
control vector. Furthermore, these computations can be reused
when the algorithm runs the Riccati recursion twice or more,
e.g., when the Riccati recursion fails. Fig. 4 depicts the
operations performed by a Riccati recursion based on our
nullspace approach.

4) Beneﬁts compared to a nullspace projection: Our ap-
proach uses a parametrization of the nullspace, in contrast
to the nullspace projection proposed in [44]. It means that
our approach does not need to pose a singular optimal
control problem. It also performs more efﬁciently the Ric-
cati recursion, as it does not require replacing the Cholesky
decomposition with a Moore-Penrose pseudo-inverse, which
is based on an expensive singular value decomposition.

C. Value function in a single node

The quadratic approximation of value function in a given

node is

∆V = ∆V1 +

∆V2
2

+ δx(cid:62)Vx +

1
2

δx(cid:62)Vxxδx

Fig. 4. Operations performed by our Riccati recursion based on a nullspace
parametrization. The manifold of the inverse-dynamics constraint is noncon-
vex, smooth, and differentiable (pink geometry). When parametrizing the
constraint using the fundamental basis of hu, we search the direction along
its null and range spaces (blue planes). This allows us to perform parallel
computations for computing δuy of each node, which reduces the algorithmic
complexity of the Riccati recursion as we only need to compute δuz in
sequence. Note that, for the sake of clarity, we translate the range-space
plane.

with

∆V1 = −π(cid:62)Qu,
Vx = Qx + Π(cid:62)(Quuπ − Qu) − Qxuπ,
Vxx = Qxx + (Π(cid:62)Quu − 2Qxu)Π,

∆V2 = π(cid:62)Quuπ,

(10)

where π, Π can be computed with Eq. (9) or (8). Note that, in
essence, computing this approximation of the value function
is similar to the unconstrained DDP. However, in contrast to
this unconstrained case, we cannot simplify its expression (as
in [45]) because the feed-forward and feedback terms depend
on the Jacobians of the equality constraint as well.

D. Nonlinear step and merit function

Instead of a classical line-search procedure (see [46, Chap-
ter 3]), we try the search direction along a feasibility-driven
nonlinear rollout of the dynamics:

0 = ˜x0 ⊕ (α − 1)¯f0,
x+
k = uk + αkk + Kkδx+
u+
k ,
k , u+
k+1 = f (x+
x+

k ) ⊕ (α − 1)¯fk+1,

(11)

k = x+

for k = {0, · · · , N } and δx+
k (cid:9) xk, where a backtrack-
ing procedure tries different step lengths α; x+
k , u+
k describes
the potential new guess for the node k; ˜x0 is the initial state
(constraint) of the system; ⊕ is the integrator operator needed
to optimize over manifolds [39].

To evaluate the goodness of a given step length α ∈ (0, 1],
we ﬁrst compute the expected cost reduction using the local
approximation of the value function. However, the quadratic
approximation in Eq. (10) does not consider the expected evo-
lution of the gaps in the system dynamics ¯fs = (¯f0, · · · , ¯fN ),
which is critical for increasing the basin of attraction to
good local minima of our algorithm and for generating agile
acrobatic maneuvers (see Section VII and [17]). Therefore, to

null-spaceconstraint    manifoldparallelcomputationsequentialcomputationrange spaceMASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

7

account for the multiple-shooting effect of ¯fs, we compute a
feasibility-aware expected improvement as

∆(cid:96)(α) = α

N −1
(cid:88)

(cid:18)

k=0

∆(cid:96)1k +

(cid:19)

α∆(cid:96)2k

,

1
2

(12)

where, by closing the gaps as proposed in [36] in the linear
rollout, we have:

∆(cid:96)1k = π(cid:62)

k Quk + ¯f (cid:62)

k (Vxk − Vxxk δx+

∆(cid:96)2k = π(cid:62)

k Quuk πk + ¯f (cid:62)

k (2Vxxk δx+

k − Vxxk

(13)

k ),
¯fk).

This expected improvement matches the quadratic approxima-
tion of the value function in Eq. (10) if there is no dynamics
infeasibility, i.e., ¯fk = 0 for all 0 < k < N .

We then compute an (cid:96)1 merit function of the form:

φ(xs, us; ν) =

N −1
(cid:88)

k=0

(cid:96)(xk, uk) + ν(cid:15)(xk, uk),

(14)

with

(cid:15)(xk, uk) := (cid:107)f (xk, uk) (cid:9) xk+1(cid:107)1 + (cid:107)h(xk, uk)(cid:107)1,

where (cid:15)(·) measures the infeasibility of the current guess at
node k, and ν is the penalty parameter that balances optimality
and feasibility. We update this parameter at every iteration as

E. Regularization and stopping criteria

To increase the algorithm’s robustness, we regularize V (cid:48)
xx
and Luu in such a way that changes the search direction from
Newton to steepest descent conveniently and handles potential
concavity. Concretely, our regularization procedure follows a
Levenberg-Marquardt scheme [48] to update µ, i.e.,

xx ← V (cid:48)

µ ← βi,dµ, V (cid:48)

x fx, Luu ← Luu + µI,

xx + µf (cid:62)
where βi and βd are the factors used to increase and decrease
the regularization value µ, respectively. Our updating rule is
as follows: we increase µ when the Cholesky decomposition
in Eq. (9) (or in Eq. (8)) fails or when the forward pass
accepts a step length smaller than α0 or (cid:80)N −1
k=0 (cid:96)2k is lower to
κ0 ≤ 10−3. This latter condition allows the algorithm to focus
on reducing the infeasibility in the equality constraints after
reaching a certain level of optimality. Instead, we decrease µ
when the forward pass accepts steps larger than α1.

The V (cid:48)

xx term is deﬁned as Lxx +µf (cid:62)

x fx, which can be also
interpreted as a banded regularization as it corrects the matrix
inertia that condenses the future nodes (i.e., V (cid:48)
xx). These type
of strategies for inertia correction are similarly implemented
in general-purpose nonlinear programming solvers such as
IPOPT [22].

1) Stopping criteria: We consider both optimality and
feasibility in the stopping criteria by employing the following
function:

(cid:32)N −1
(cid:88)

max

(cid:15)(xk, uk), |∆(cid:96)(1)|

(cid:33)
.

(cid:32)

ν ← max

ν,

∆(cid:96)(1)
(1 − ρ) (cid:80)N −1
k=0 (cid:15)(xk, uk)

(cid:33)

,

(15)

k=0

We say that the algorithm has converged to a local minimum
when the value of the above stopping criteria function is lower
than a user-deﬁned tolerance, which is 10−9 in our results.

given 0 < ρ < 1, which is a tunable hyper-parameter.
Our updating rule is inspired by [47], where ∆(cid:96)(1) can be
interpreted as the objective function of the tangential sub-
problem and (cid:80)N −1
k=0 (cid:15)(xk, uk) as the reduction provided by
the normal step.

Finally, we accept a step δwα

s = α[δx(cid:62)
following Goldstein-inspired condition holds:

s δu(cid:62)

s ](cid:62) if the

φ(w+α
s

; ν)−φ(ws; ν) ≤

(cid:40)

η1∆Φ(ws; ν)
η2∆(cid:96)(α)

if ∆Φ(ws; ν) ≤ 0
otherwise

with ∆Φ(ws; ν) = D(φ(ws; ν); δwα
s ), where ws contains the
current (guess) state and control trajectories (xs, us), w+α
:=
ws ⊕ αδws is the next guess under trial, 0 < η1 < 1 and
0 < η2 are user-deﬁned parameters, and

s

D(φ(ws; ν); δwα

s ) := ∆(cid:96)(α) + α

N −1
(cid:88)

k=0

(cid:15)(xk, uk)

denotes the directional derivative of φ(·) along the direction
δwα
s . Our Goldstein-inspired condition allows the algorithm
to accept ascend directions in ∆Φ(ws; ν), which might occur
during iterations that are dynamically infeasible (i.e., ¯fs (cid:54)=
0). Note that we use η2∆(cid:96)(α) in the second condition, as it
quantiﬁes the dynamics infeasibility only.

F. Algorithm summary

Algorithm 1 summarizes our novel equality-constrained
DDP algorithm. It considers infeasibility for both dynamics
and equality constraints and includes the Schur-complement
and nullspace factorizations. As described above, the complex-
ity of the Schur-complement factorization scales with respect
to the dimension of the equality constraints. This is obvious if
we observe that requires performing a “projected” Cholesky
decomposition (line 16) as well. Instead, our nullspace fac-
torization performs a single Cholesky decomposition with the
dimension of the kernel of hu, which is lower than the nu
(i.e., dimension of the full-space Cholesky in line 15).

Our nullspace parametrization provides a competitive ben-
eﬁt compared to barrier methods such as augmented La-
grangian [49], [50] or interior-point [12], [51] as well. The
reasons are due to (i) the reduction in the dimension of the
matrix needed to be decomposed using Cholesky method (see
again Fig. 4), and (ii) the use of exact algebra to handle
these types of constraints. This factorization also allows us
to perform partial computation in parallel of Y, Z, (huY)−1,
Ψn¯h, and Ψnhx (lines 4 and 5) terms. We try the search
direction with a nonlinear step (based on system rollout), as
it leads to faster convergence in practice. Similar empirical
results have been reported in [52] for unconstrained problems.

MASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

8

Algorithm 1: Equality constrained DDP

1 for k ← 0 to N do in parallel
2

residual and derivatives: ¯h, ¯f , (cid:96)w, Lww, fw, hw
if nullspace factorization then

nullspace and decomposition: Y, Z, (huY)−1
feed-forward/back in rank-space: Ψn¯h, Ψnhx

x ← (cid:96)xN , V (cid:48)

xx ← LxxN

6 terminal value function: V (cid:48)
7 for k ← N − 1 to 0 do
8

local action-value function
regularization: V (cid:48)
if nullspace factorization then

xx, Luu

Eq. (7)

nullspace action-value: Qz, Qzz, Qzx, Qzu
nullspace Cholesky: Q−1
feed-forward and feedback: πn, Πn

zz , kn, Kn, ˆQzz

Eq. (9)

else

full-space Cholesky: Q−1
projected Cholesky: (huQ−1
free-space terms: Ψs, ˆks, ˆKs
feed-forward and feedback: πs, Πs

uu, k, K
uuh(cid:62)

u )−1

value function: ∆V, Vx, Vxx
2 , · · · , 1
2n

(cid:9) do

20 for α ∈ (cid:8)1, 1

for k ← 0 to N do

nonlinear rollout: ˆxk, ˆuk
expected improvement: ∆(cid:96)(α)
merit penalty parameter: ν
merit function: φ(xs, us; ν)
if success step then

go to 1 until convergence

Eq. (8)

Eq. (10)

Eq. (11)

Eq. (12)
Eq. (15)
Eq. (14)

3

4

5

9

10

11

12

13

14

15

16

17

18

19

21

22

23

24

25

26

27

Finally, in each iteration, we update the penalty parameter
in the merit function to balance optimality and feasibility
(lines 24 and 25).

V. FUNCTIONAL STRUCTURE OF INVERSE DYNAMICS
PROBLEM

As described in Section III-B, the decision variables are q,
v, a, τ , and λ. The ﬁrst couple of variables naturally describe
the state of the system x = [q(cid:62) v(cid:62)](cid:62), while the latter ones
describe its control inputs u = [a(cid:62) τ (cid:62) λ(cid:62)](cid:62). Therefore, the
linearization of the nonlinear equality constraints has the form:

hx
(cid:125)(cid:124)

(cid:122)
(cid:34) ∂IDA
∂q
− ∂ac

∂IDA
∂v

∂q − ∂ac

∂v

(cid:21)

(cid:123)
(cid:35) (cid:20)δq
δv

+

hu
(cid:125)(cid:124)
(cid:122)
(cid:20)M − ∂A
∂τ −J(cid:62)
0
0
Jc

c

(cid:123)
(cid:21)





δa
δτ
δλ

,

(16)



 = −

(cid:21)

(cid:20)¯hID
¯hλ

with

∂IDA
∂q

=

∂ID
∂q

−

∂A
∂q

,

∂IDA
∂v

=

∂ID
∂v

−

∂A
∂v

,

∂q , ∂ID

∂q , ∂ac
∂v , ∂A

∂v are the RNEA derivatives [8], ∂ac
∂q , ∂A

where ∂ID
∂v are
the derivatives of the frame acceleration, and ∂A
∂τ are
the derivatives of the arbitrary actuation model A(q, v, τ ).
The dimension of the control input is nv + nj + nf with
nv as the dimension of the generalized velocity, nj as the
number of joints, and nf as the dimension of the contact-
force vector. However, it is possible to condense this equation.
This in turn reduces the computation time as the algorithm
complexity depends on the dimension of u. We name this
new formulation condensed, instead, we call the representation
above redundant. Below we will provide more details about
the condensed representation.

A. Condensed inverse-dynamics

Including both joint torques and contact forces create redun-
dancy and increases sparsity. However, it is more efﬁcient to
condense them as the asymptotic complexity of our equality-
constrained DDP algorithm depends on the dimension of the
system’s dynamics (i.e. nx + nu). We can do so by assuming
that the RNEA constraint is always feasible (i.e., ¯hID = 0),
which leads to the following expression
(cid:18) ∂A
∂τ

(cid:19)−1 (cid:18) ∂IDA
∂q

∂IDA
∂v

δτ =

δq +

δv

(cid:19)

,

and if we plug this expression in Eq. (16), then we obtain a
condensed formulation:

(cid:122)
(cid:34)

hx
(cid:125)(cid:124)

S ∂IDA
∂q
− ∂ac

S ∂IDA
∂v
∂q − ∂ac

∂v

(cid:21)

(cid:123)
(cid:35) (cid:20)δq
δv

+

,

(17)

hu
(cid:122)
(cid:125)(cid:124)
(cid:20)M −J(cid:62)
c
0
Jc

(cid:21)

(cid:123)
(cid:21) (cid:20)δa
δλ

= −

(cid:21)

(cid:20)¯hA
¯hλ

(cid:1)−1

(cid:0) ∂A
∂τ

with S = I − ∂A
, which is a matrix that selects
∂τ
under-actuated joints. This matrix is often constant in robotics
platforms (e.g., quadrotors, manipulators, and legged robots)
and can be computed at once. Therefore, we now eliminate the
joint torque and reduce the dimension of the control input to
u = [a(cid:62) λ(cid:62)](cid:62). Although a similar procedure was described
in [12], this approach does not consider arbitrary actuation
models such as propellers in quadrotors.

B. Exploiting the functional structure

The control inputs for both inverse-dynamics formulations
deﬁne a functional sparsity, which does not appear in optimal
control with forward-dynamics cases. Concretely, this sparsity
is in the partial derivatives of system dynamics with respect
u, i.e.

fu = (cid:2)fa 0(cid:3) ,

where fa is the partial derivatives with respect to the gener-
alized accelerations, and the null block represents the partial
derivatives of the remaining components (i.e., λ and/or τ ).
Furthermore, the structure of fa depends on the conﬁguration
manifold and chosen integrator.

MASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

9

We inject this structure into the computation of the local
approximation of the action-value function. Thus, we adapt
the terms in Eq. (7) as follows

u V +
f (cid:62)

x =

(cid:21)

(cid:20)f (cid:62)
a V +
x
0

,

u V (cid:48)
f (cid:62)

xxfu,x =

(cid:20)f (cid:62)

(cid:21)
a V (cid:48)
xxfa,x 0
0
0

.

From now on, we will describe our inverse-dynamics MPC,
which is the heart of our perceptive locomotion pipeline.
This MPC formulation is possible thanks to the computational
advantages of our equality-constrained DDP algorithm.

3) Inverse-dynamics MPC and feedback policy: The
inverse-dynamics MPC (our contribution) computes whole-
body motions, contact forces, and feedback policies for the
generalized acceleration and contact forces at a ﬁxed opti-
mization horizon (1 s in our experiments). The feedback-policy
controller builds a control policy in the joint-torque space. In
order to do so, we map the MPC policy into the joint-torque
space based on the generalized acceleration and contact forces.
This equivalent policy is a function composition of the MPC
policy and inverse-dynamics function, i.e.,

π∗

τ (x) = ID∗ ◦ π∗

MPC(x),

VI. INVERSE-DYNAMICS MPC AND PIPELINE

Our inverse-dynamics MPC is formulated via time-based
hybrid dynamics as described above. This formulation is
inspired by our previous work [5]. But, before describing
our MPC approach, we start by introducing our perceptive
locomotion pipeline.

where ◦ is the composition operator, ID∗ is the inverse
dynamics at the optimal solution (x∗, u∗), π∗
MPC is the policy
computed by the MPC, and π∗
τ is the same policy expressed
in the joint-torque space. Note that π∗
τ and π∗
MPC contains
the feed-forward and feedback terms computed using our
nullspace factorization for equality-constrained DDP. Below
we provide more details about our inverse-dynamics MPC and
feedback policy.

A. Perceptive locomotion pipeline

B. MPC formulation

The core of our perceptive locomotion pipeline is a unique
inverse-dynamics MPC approach that computes control poli-
cies, maps them to the joint-torque space, and sends them
to a feedback-policy controller. Our inverse-dynamics MPC is
designed to track the footstep plans given a reference velocity
command from a joystick and a terrain map perceived by a
depth camera. This allows us to avoid the ill-posed nature
of the linear complementary constraints (e.g. [53], [54], [55],
[56]). Fig. 5 illustrates the different modules of our locomotion
pipeline used to evaluate our inverse-dynamics MPC. Note that
we brieﬂy describe each module below for the sake of clarity.
However, more details will be presented in an upcoming
publication.

1) Terrain elevation and segmentation: We represent the
terrain through a set of safe footstep regions similarly to [57],
[58], [59], [60]. These regions are computed from a terrain
elevation map, which is commonly used in locomotion frame-
works, e.g., [61], [62], [63], [64]. Concretely, using a depth
camera, we build online a local terrain elevation map around
the robot [65]. To do so, we fuse proprioceptive information
(IMU and leg odometry) with LiDAR localization at 400 Hz.
Finally, given the elevation map and the robot pose in the
odometry frame, we extract a set of convex surfaces suitable
for selecting the footstep regions.

2) Footstep placement and region selection: We break the
combinatorics associated with the discrete choice of footstep
regions when selecting footstep placements. Our approach
ﬁrst selects footstep regions and then determines footstep
placements given the terrain map. We use tools from mixed-
integer convex (MIC) and quadratic programming to plan in
real-time a sequence of footsteps, which is inspired by our
previous work [66]. Concretely, our system plans six footsteps
placements and regions at 10 Hz and the quadratic program
adapts the swing-foot trajectories within the MPC horizon at
50 Hz.

At each MPC step, we solve an OC problem with inverse
dynamics. It computes whole-body motions and contact forces
given a predeﬁned footstep plan as follows:

N −1
(cid:88)

(cid:107)qk (cid:9) qref (cid:107)2

Q + (cid:107)vk(cid:107)2

N + (cid:107)uk(cid:107)2

R + (cid:107)λCk (cid:107)2
K

min
xs,us

k=0
s.t. q0 = ˆq0,
v0 = ˆv0,
if contact-gain transition:

(initial pos.)

(initial vel.)

qk+1 = qk,
(cid:20) vk+1
−λCk

=

(cid:21)

else:

(cid:20)Mk J(cid:62)
Ck
0
JCk

(cid:21)−1 (cid:20)τ I

biask
−aI
Ck

(cid:21)

,

(impulse dyn.)

[qk+1, vk+1] = ψ(qk, vk, ak),
ID(qk, vk, ak, λCk ) = 0,
λGk = 0,
CλCk ≥ c,
log (W p−1
C,Gk
− W ˙pref
W ˙p−1
C,Gk
C,Gk
x ≤ xk ≤ ¯x,
u ≤ uk ≤ ¯u,

· W pref
C,Gk
= 0,

) = 0,

(kin. integrator)

(inverse dyn.)

(non-contact for.)

(friction-cone)

(contact pos.)

(contact velocity)

(state bounds)

(control bounds)
(18)
where the state is deﬁned by x = [q(cid:62) v(cid:62)](cid:62), the control
inputs by the joint torques and contact forces u = [a(cid:62) λ(cid:62)](cid:62),
(xs, us) describes the state trajectory and control sequence,
N is the optimization horizon, the linearized friction cone
is deﬁned by (C, c), log(·) operator deﬁnes the logarithmic
map needed to handle contact placement that lies on a SE(3)
manifold, W p−1
C,G describes the inverse composition
between the reference and current contact placements [67],
Ck and Gk are the set of active and swing contacts given

C,G · W pref

MASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

10

Fig. 5. Overview of our perceptive locomotion pipeline. Our inverse-dynamics MPC computes updated policies, maps them to the joint space, and transmits
them to a feedback-policy controller that closes the loop with state estimation and sensing. The footstep planner computes swing-foot trajectories that reach
a selected footstep region and avoid obstacles. These selected regions are chosen to track the desired robot velocity (commanded from a joystick) while
guaranteeing footstep feasibility. We use different colors to describe the frequency of each module in our locomotion pipeline. Our key contribution is an
inverse-dynamics MPC (Section VI-B) that combines a novel nullspace factorization for equality-constrained DDP (Section IV-A), condensed inverse dynamics
(Section V-A), and a feedback policy in the joint-torque space (Section VI-C). More details of our perceptive locomotion pipeline will be presented in an
upcoming publication.

the running node k. Both contact positions and velocities
(cid:0)W pC,G, W ˙pC,G

(cid:1) are expressed in the inertial frame W.

1) Inverse dynamics and contact forces: Eq. (18) formu-
lates inverse dynamics as a function of the kinematic integrator
ψ and nonlinear equality constraints describing the condensed
inverse dynamics (see Eq. (17)) and contact forces for feet
that swing. To pose well the discontinuities when contacts are
gained, we use the impulse dynamics during these contact-gain
transitions (a name coined by [2]). Regarding the analytical
derivatives, Section V-A describes how to compute them for
the condensed inverse dynamics. Instead, for the impulse
dynamics, we obtain the analytical derivatives of post-impact
velocity and impulse force as explained in [5].

2) Inequalities constraints via quadratic penalty: We de-
ﬁne quadratic penalty functions for the friction-cone, contact
position and velocity, and bound constraints. This approach
shows effective results in practice.

3) Implementation details: The MPC horizon is 1 s, which
is described through 100 nodes with timesteps of 10 ms.
Each node is numerically integrated using a symplectic Euler
scheme. We compensate for delays in the communication
(often around 1 ms), by estimating the initial position and
velocity. These initial conditions are imposed in the MPC.
On the other hand, we initialize our algorithm with the
previous MPC solution and regularization value. The idea
is to encourage the numerical evolution encountered in the
optimal control case. However, the penalty parameter ν is
always updated as in Eq. (15) to account for infeasibilities
in the initial node and unseen nodes. Note that we refer to
unseen nodes as the nodes that appear in each MPC step after
receding the horizon.

C. Feedback MPC in joint-torque space

momenta [1], as Brockett theorem [69] suggests that these
systems cannot be stabilized with continuous time-invariant
feedback control laws (i.e., a whole-body controller). In prac-
tice, this translates into angular momentum tracking errors.
This in turn affects the joint torques, swing-foot position and
velocities tracking. To avoid these issues, we develop a novel
feedback strategy for MPC with inverse dynamics as described
below.

Our inverse-dynamics MPC computes control policies for

the generalized acceleration and contact forces, i.e.,

(cid:21)

(cid:20)δa∗
δλ∗

= −

(cid:21)

(cid:20)πa
πλ

−

(cid:21)

(cid:20)Πa
Πλ

δx,

(19)

where πa, πa are the feed-forward commands for the refer-
ence generalized acceleration a∗ and λ∗, respectively, and Πa,
Πa are their feedback gains. However, joint-level controllers
often track reference joint torque commands, positions and
velocities (e.g., [70], [71]).

To map the policy in Eq. (19) into the joint-torque space,

we use the inverse dynamics, i.e.,

δτ ∗ = −πτ − Πτ δx,

τ (A∗

= (S∗)−1ID(q∗, v∗, δa∗, δλ∗),
(cid:12)
(cid:12)
(cid:12)q∗,v∗

τ )−1, with A∗
where S∗ = I − A∗
selection matrix linearized around the optimal state that is
described by q∗, v∗. This boils down into two procedures, one
for each term: feed-forward and feedback. First, we compute
the feed-forward joint torque commands πτ by injecting the
feed-forward terms only, i.e.,

τ = ∂A
∂τ

, is the

πτ = (S∗)−1 ID(q∗, v∗, πa, πλ),

= (S∗)−1 (cid:0)M(q∗)πa + h(q∗, v∗) − J(cid:62)

c (q∗)πλ

(cid:1) ,

(20)

As reported in our previous work [5], classical whole-body
controllers (e.g. [68], [10]) do not track the angular momentum
accurately. This is related to the nonholonomy in the kinetic

where h(q∗, v∗) describes the Coriolis and gravitational
forces, M(q∗) the joint-space inertia matrix, and Jc(q∗)
the stack of contact Jacobian evaluated in the optimal robot

MASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

11

conﬁguration q∗ and velocity v∗. Second, we calculate the
feedback joint torque gains Πτ using a similar procedure, i.e.,
by injecting the feedback terms as follows:
Πτ = (S∗)−1 (cid:0)M(q∗)Πa − J(cid:62)

c (q∗)Πλ

(21)

(cid:1) .

With Eq. (20) and (21), we compute the joint-torque control
policy within the duration of the node.

This concludes the description of our OC solver, condensed
inverse dynamics, MPC formulation and feedback policy.
Below, we provide evidence of the beneﬁts of our method and
demonstrate the ﬁrst application of inverse-dynamics MPC in
hardware. Our inverse-dynamics MPC results in state-of-the-
art dynamic climbing on the ANYmal robot.

VII. RESULTS

We implemented in C++ both factorizations for the equality-
constrained DDP algorithm as well as both inverse-dynamics
formulations within the CROCODDYL library [36]. A com-
the Schur-
parison of our nullspace factorization against
complement approach highlights the beneﬁts of handling efﬁ-
ciently nonlinear equality constraints (Section VII-B). Results
of our feasibility-driven search, merit function and regular-
ization scheme show a greater basin of attraction to local
minima (Section VII-C). This enables us to solve nonlinear
optimal control problems with poor initialization and generate
athletic maneuvers (Section VII-D). Moreover, we compare the
numerical effect of condensing the inverse dynamics against
the redundant formulation (Section VII-E).

As observed in the literature, our inverse-dynamics approach
handles coarse optimization problems better than its forward-
dynamics counterpart (Section VII-F). Our approach solves
optimal control problems as quick as the forward-dynamics
formulation for a range of different robotics problems (Sec-
tion VII-G). Indeed, we show that it enables feedback MPC
based on inverse dynamics, which allowed the ANYmal robot
to climb up stairs with missing treads (Section VII-H). Below,
we begin by introducing the optimal control problems, PC and
solver parameters.

A. Problem speciﬁcations and setup

We tested our approach in multiple challenging robotic
problems. This allowed us to evaluate the performance of our
equality-constrained DDP algorithm with different nonlinear
constraints and several decision variables and constraints. The
robotic problems are (i) an acrobot
to reach an up-ward
position (pend); (ii) a quadrotor to ﬂy through multiple targets
(quad); (iii) various quadrupedal gaits: walk (walk), trot-
bound (trotb), and pace-jump (pjump) gaits; and (iv) a
humanoid reaching a number of grasping points (hum). For
the sake of comparison, we use a quadratic-penalty cost to
encode a soft friction-cone constraint.

We conducted all the experiments on an Intel® Core™
i9-9980HK CPU @ 2.40GHz × 16 running Ubuntu
20.04. We compiled our code with clang++10 using
the native architecture ﬂag (i.e., -march=native), which
enables the compiler to use the all instructions supported by
our CPU. We run our code using 8 threads. We disabled

Fig. 6. Normalized computation time for solving different optimal control
problems with different factorization approaches. For all the cases, we observe
that the nullspace factorizations (null-lu/qr) are always faster than the
Schur-complement one (schur). Furthermore, there is a higher reduction
in the computation time with the redundant formulations as the number of
constraints increases. Indeed, the computation reduction for the a quadrupedal
walking problem (walk) is 47.3%, which is higher than the pace-jump
(27%, pjump) or trot-bound (27.9%, trotb) cases. Finally, we include
the minimum computation time for each problem at the top of the bar charts.

TurboBoost to reduce variability in benchmark timings. We
used the following values for the hyper-parameters: ρ = 0.3,
η1 = 0.1, η2 = 2, α0 = 0.01, α1 = 0.5, κ0 = 10−4, βi = 106
and βd = 10.

B. Nullspace vs Schur-complement factorizations

Our nullspace factorization always leads to a reduction
in the computation time (up to 47.3%) when compared to
the Schur-complement approach, as shown in Fig. 6. This
reduction is higher in problems with a larger number of
equality constraints, i.e., the redundant inverse-dynamics for-
mulation with a larger number of contact constraints (walk).
The nullspace factorization also reduces the computation time
per iteration as both factorizations converge within the same
number of iterations. We obtained the average computation
time and its standard deviation over 500 trials using 8
threads, with the same initialization. We expect a higher
improvement if we increase the number of threads. We pro-
vided results for nullspace factorizations based on both rank-
revealing decompositions: LU with full pivoting (null-lu)
and QR with column pivoting (null-qr). We used the rank-
revealing decompositions available in the EIGEN library [18]:
LU with full pivoting (Eigen::FullPivLU) and QR with
column pivoting (Eigen::ColPivHouseholderQR). It
also relies on Eigen’s LU decomposition with partial pivot-
ing (Eigen::PartialPivLU) to compute (huY)−1 efﬁ-
ciently, as this matrix is square-invertible.

C. Beneﬁts of feasibility-driven search

Coldstart or poor initialization affects the convergence of
optimal control problems. It is especially relevant in the gen-
eration of agile maneuvers such as jumping gaits (e.g., pjump
problem). Furthermore, the use of equality constraints to en-
code the robot’s dynamics (i.e., inverse-dynamics constraints)

pendquadpjumptrotbwalkhum1.01.21.4normalized total time(0.03s)(0.35s)(0.19s)(0.13s)(0.14s)(14.96s)redundant formulationnull-lunull-qrschurpendquadpjumptrotbwalkhum1.001.051.101.15normalized total time(0.12s)(0.3s)(0.15s)(0.11s)(0.11s)(8.65s)condensed formulationnull-lunull-qrschurMASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

12

(a)

(b)

(c)

(d)

Fig. 7. Snapshots of different maneuvers computed using our inverse-dynamics formulations and equality-constrained DDP. (a) a gymnastic routine performed
by the Talos robot. (b) reaching multiple grasping points with the Talos robot. (c) a sequence of walking, trotting, and jumping gaits executed by the ANYmal
robot. (d) Talos legs squatting to avoid an obstacle. To watch the video, click the ﬁgure or see https://youtu.be/NhvSUVopPCI.

TABLE I. Percentage of successful resolutions, average cost and iterations
using random initialization when the solver handles or not the dynamics
feasibility.

with dyn. feasibility

without dyn. feasibility

Formulations

Iter.

Cost

Succ.

Iter.

Cost

Succ.

redundant
condensed

11.8
11.9

2838
2839

100%
100%

27.5
28.4

3031
3069

91.8%
91%

helps the algorithm’s convergence by balancing optimality and
feasibility properly. However, it is also imperative to balance
the feasibility of the dynamics (i.e., kinematic evolution) as
well, which is ignored in the DDP algorithm. To support this
claim, we obtained the percentage of successful resolutions,
average cost and iterations with and without dynamics feasi-
bility support.

We computed the average cost from trials that have con-
verged only. In addition, we initialized the algorithm with a
random control sequence and constant state trajectory using
the robot’s nominal posture. We used the pace-jump problem
(pjump) and performed 500 trials. In Table I, results show that
handling dynamics feasibility increases the algorithm basin of
attraction, convergence rate, and solutions on both inverse-
dynamics formulations. Note that we disabled the feasibility
by closing the dynamics gaps ¯fs in the nonlinear rollout. To
do so, we performed the DDP’s forward pass and ignored the
gaps in the computation of the expected improvement, i.e.,
in Eq. (12).

D. Generation of complex maneuvers

Our approach can generate a range of different agile or
complex maneuvers within a few iterations. Fig. 7 shows the
optimal motions computed by our method for different robotic
platforms and tasks. These motions converged between 10 to
50 iterations, except for the gymnastic on the Talos robot
(Fig. 7a) which took circa 500 iterations. For the problems
with the Talos and ANYmal robot (Fig. 7a-c), we provided the
sequence of contact constraints and their timings. Furthermore,
we did not specify the desired swing motion or encode any
heuristic in the generation of the Talos’ motions (Fig. 7a,b).
Indeed, its balancing behaviors came from the ﬁrst principles
of optimization. It is the same for the obstacle task in Fig. 7d.
Here, the squatting motion is needed to avoid obstacles with
the magenta sphere.

E. Redundant vs condensed formulations

We compared the numerical effects of the condensed formu-
lation against the redundant one, as the former assumes that
the RNEA constraints are always feasible (see Section V-A). In
Fig. 8, we can see the normalized cost and (cid:96)1-norm feasibility
evolution (dynamics and equality constraints) for both inverse-
dynamics formulations. There we see that both approaches
converged within the same number of iterations and total cost,
if the feasibility evolved similarly (quad, pjump, trotb and
walk). This is contrary to cases where the optimality and
feasibility did not always decrease monotonically (pend and
hum). This trade-off is balanced by our merit function, as de-

MASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

13

Fig. 9. Total computation time for solving different optimal control problems
with different formulations. Except for pend, the condensed inverse-dynamics
formulation solved these problems faster than forward-dynamics formulations.

realistic MPC setups (around 1.2 s of horizon and 120 nodes)
and can run at 50 Hz.

H. MPC and dynamic locomotion

We evaluated the capabilities of our inverse-dynamics MPC
and feedback-policy controller to perform dynamic locomo-
tion over complex terrains with the ANYmal robot. Fig. 10
shows relevant instances and ANYmal’s perception when it
traversed multiple pallets, beams, and a damaged industrial-
like stair. We display three different instances of the ANY-
mal robot in Fig. 10a and 10b. In each instance, we show
the optimal swing-foot trajectories computed by the inverse-
dynamics MPC within its prediction horizon. Furthermore,
our perception pipeline extracted and updated different convex
surfaces from a terrain elevation map online. With these
surfaces, we select a set of feasible footstep regions to track
a velocity command from a joystick.

In Fig. 10a,

the height of the ﬁrst and last pallets is
19 cm. The gap and height difference of the pallet in the
middle is 15 cm and 31 cm, respectively. Instead, in the stair-
climbing trial reported in Fig. 10c, we removed two treads to
emulate a damaged staircase after a disaster. This scaffolding
staircase is typically used on construction sites and offshore
platforms. Its riser heights and tread lengths are 17 cm and
26 cm, respectively. It has an inclination of 33°. However,
when removing a tread, there is a gap of 26 cm in length
and 34 cm in height. These are challenging conditions for a
robot. Now the equivalent inclination is 37° and the distance
of the gap is around half of the ANYmal robot. Indeed, to

TABLE II. Number of iterations required by different problem
discretizations and formulations. The most robust formulation is highlighted
in bold.

Fig. 8. Cost and feasibility evolution for redundant and condensed for-
mulations. (left) normalized cost per iteration. (right) (cid:96)1-norm of the total
feasibility (both dynamics and equality constraints) per iteration. A redundant
formulation allows our solver to handle the entire problem’s feasibility and
optimality, while a condensed one imposes RNEA feasibility. This is key to
reducing the total cost in the pend and hum problems.

ﬁned by Eq. (14). Indeed, redundant formulations increase the
possibility that our algorithm balances more effectively both
optimality and feasibility. However, this does not represent an
overall beneﬁt in most practical cases as the condensed for-
mulations speed up the computation time as shown in Fig. 6.

F. Solving coarse optimization problems

We compared the convergence rate using different dis-
cretization resolutions. We deﬁned the same cost functions for
each problem repetitively but transcribed them with different
step integrations For sake of simplicity, we employed a sym-
plectic Euler integrator and initialized the algorithms with the
robot’s nominal posture and quasic-static inputs at each node
of the trajectory. We used the feasibility-driven DDP (FDDP)
algorithm [36] provided in CROCODDYL for the forward-
dynamics results. Instead, for the inverse-dynamics cases, we
used our equality-constrained DDP algorithm and condensed
formulation.

Table II reports the number of iterations required for conver-
gence. These results show that our inverse-dynamics formula-
tion is more likely to converge in very coarse optimizations
(e.g., pjump and trotb) and with fewer iterations. Both
aspects provide evidence of the beneﬁts of optimal control
using inverse dynamics.

G. Computation time and convergence rate

Problems

100

We report

the total computation time of our approach
and the forward-dynamics formulation on six different prob-
lems. Fig. 9 shows that
the solutions with our equality-
constrained DDP and condensed formulation are often faster
than with the (compact) forward-dynamics formulation pro-
posed in [36]. Our nullspace factorization and condensed
formulation are key factors in reducing the computation time.
locomotion (i.e.,
The results reported for the quadrupedal
pjump, trotb, walk) were intentionally designed to mimic

quad

pjump

trotb

walk

forward
inverse

forward
inverse

forward
inverse

forward
inverse

10
6

20
20

15
9

10
9

frequencies (Hz)

80

10
6

21
19

16
9

9
10

60

11
6

23
21

18
12

10
12

50

11
6

24
22

25
16

10
8

40

12
6

40
19

99
36

12
50

20

14
8

(cid:55)
41

(cid:55)
153

48
14

10

17
9

(cid:55)
199

(cid:55)
199

99
92

(cid:55) algorithm does not ﬁnd a solution within 200 iterations.

01020304050iterations0.00.20.40.60.81.0normalized costredundant formulationpendquadpjumptrotbwalkhum01020304050iterations10131010107104101102feasibility L1-normredundant formulationpendquadpjumptrotbwalkhum01020304050iterations0.00.20.40.60.81.0normalized costcondensed formulationpendquadpjumptrotbwalkhum01020304050iterations10141011108105102101feasibility L1-normcondensed formulationpendquadpjumptrotbwalkhumpendquadpjumptrotbwalk0.10.20.3computation time (s)total timecondensedredundantforwardMASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

14

(a)

(b)

(c)

Fig. 10. Snapshots of different locomotion maneuvers computed by our inverse-dynamics MPC. All these experimental trials use the feedback-policy controller
and onboard state estimation and perception. (a) walking over a set of pallets of different heights. (b) crossing a gap between two beams. (c) climbing up
industrial stairs with missing steps. To watch the video, click the ﬁgure or see https://youtu.be/NhvSUVopPCI?t=161.

MASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

15

Fig. 13. Comparison between the nullspace and Schur-complement factor-
izations during a dynamic trotting gait with the ANYmal robot. The Schur-
complement is more expensive to compute, and our MPC cannot run at
50 Hz. These delays in the control loop produced instability in the trotting
gait (bottom). Instead, the nullspace allowed the MPC to run at 50 Hz and
generated a stable trotting gait (top).

stair. It also tracked accurately the desired footstep placements
and swing-foot trajectories. This allowed the ANYmal robot
to navigate carefully through narrow regions (beams) and
obstacles (stairs). Our previous work [5] also demonstrated
that the joint-torque feedback policy computed by the MPC
signiﬁcantly enhanced the tracking of angular momentum,
joint torque, and swing-foot motion. Fig. 11 shows the linear
and angular momentum tracking when the ANYmal robot
crossed the ﬁrst missed tread in Fig. 10c. Instead, Fig. 12
shows the torque and RF-foot force tracking during the same
moment.

J. MPC and nullspace efﬁciency

We compared the nullspace and Schur-complement factor-
izations during a dynamic trotting gait with the ANYmal robot.
Similarly to Fig. 6, we found that the Schur-complement fac-
torization cannot run our MPC as fast as needed (i.e., 50 Hz).
The average frequency was around 38 Hz. This translated into
very unstable trotting motions as reported in Fig. 13. Instead,
the efﬁciency of the nullspace factorization allowed us to run
the MPC at 50 Hz, which is needed to stabilize this trotting
gait.

K. Push recovery and feasibility

We analyzed the capabilities of our inverse-dynamics MPC
to reject multiple body disturbances during locomotion. To do
so, we evaluated the feasibility evolution of the kinematics
and inverse-dynamics (equality) constraints. Our equality-
constrained DDP algorithm increased the infeasibility (espe-
cially for the inverse-dynamics constraints) when we pushed
the ANYmal robot (Fig. 14). This is because our merit function
balances optimality and feasibility in real
time. However,
these increments in the infeasibility of the current solution
are quickly reduced in the next MPC iterations. While this
might appear to be a disadvantage, it is an element that keeps
the solver iterating around a desired push-recovery behavior,
which increases convergence rate and locomotion robustness.

Fig. 11. Linear (top) and angular (bottom) momentum tracking of our
feedback-policy controller when the ANYmal robot crossed the ﬁrst missed
tread in the stair-climbing experiment. Blue are reference/desired and red are
measured values. Our feedback-policy controller accurately tracks the desired
momenta.

Fig. 12.
Joint torque and RF-foot force tracking when the ANYmal robot
crossed the ﬁrst missed tread in the stair-climbing experiment. Blue are
reference/desired and red are measured values. Our feedback-policy controller
accurately tracks the joint torque commands and desired contact forces.

the most recent knowledge of the authors, this experimental
trial shows ANYmal (or any legged robot) crossed a damaged
stair for the ﬁrst time. It demonstrates the importance of using
the robot’s full dynamics, computing the optimal policy, and
having a high convergence rate. Finally, we tested our inverse-
dynamics MPC in these conditions a few times as reported in
the video.

I. MPC and feedback policy

Our feedback MPC adapted the robot’s posture to maximize
stability and the kinematics needed to transverse the challeng-
ing pallets’ heights and the missing treads in the industrial

VIII. CONCLUSION
In this paper, we propose a novel equality-constrained DDP
algorithm for solving optimal control problems with in-
verse dynamics efﬁciently. Our approach uses a nullspace

505560time (s)−10010lx (Ns)505560time (s)−20−10010ly (Ns)505560time (s)−50510lz (Ns)505560time (s)−5.0−2.50.02.55.0kx (Nms)505560time (s)−4−2024ky (Nms)505560time (s)−20kz (Nms)505560time (s)−40−2002040HAA (Nm)505560time (s)−40−2002040HFE (Nm)505560time (s)−40−2002040KFE (Nm)505560time (s)−1000100λx (N)505560time (s)−2000200λy (N)505560time (s)−2000200λz (N)MASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

16

Author contributions

Carlos Mastalli devised the main ideas behind the nullspace
parametrization, condensed inverse-dynamics, MPC formu-
lation, and feedback control, and took the lead in writing
the manuscript and preparing the video. Saroj Prasad Chha-
toni developed the Schur-complement approach and redun-
dant formulation. Thomas Corb`eres integrated the inverse-
dynamics MPC in a perceptive locomotion pipeline, developed
its main components, and supported the experimental trials on
the ANYmal robot. Sethu Vijayakumar and Steve Tonneau
provided critical feedback and helped shape the manuscript.

REFERENCES

[1] P.-B. Wieber, “Holonomy and nonholonomy in the dynamics of articu-
lated motion,” in Fast Motions in Biomechanics and Robotics, 2005.
[2] R. Featherstone, Rigid Body Dynamics Algorithms. Berlin, Heidelberg:

Springer-Verlag, 2007.

[3] J. Koenemann, A. Del Prete, Y. Tassa, E. Todorov, O. Stasse, M. Ben-
newitz, and N. Mansard, “Whole-body model-predictive control applied
to the HRP-2 humanoid,” in IEEE/RSJ Int. Conf. Intell. Rob. Sys. (IROS),
2015.

[4] M. Neunert, M. St¨auble, M. Giftthaler, C. D. Bellicoso, J. Carius,
C. Gehring, M. Hutter, and J. Buchli, “Whole-Body Nonlinear Model
Predictive Control Through Contacts for Quadrupeds,” IEEE Robot.
Automat. Lett. (RA-L), vol. 3, 2018.

[5] C. Mastalli, W. Merkt, G. Xin, J. Shim, M. Mistry, I. Havoutis, and
S. Vijayakumar, “Agile Maneuvers in Legged Robots: a Predictive
Control Approach,” 2022.

[6] D. Mayne, “A second-order gradient method for determining optimal
trajectories of non-linear discrete-time systems,” International Journal
of Control, 1966.

[7] J. T. Betts, Practical Methods for Optimal Control and Estimation Using
Nonlinear Programming, 2nd ed. USA: Cambridge University Press,
2009.

[8] J. Carpentier and N. Mansard, “Analytical Derivatives of Rigid Body
Dynamics Algorithms,” in Robotics: Science and Systems (RSS), 2018.
[9] A. Herzog, S. Schaal, and L. Righetti, “Structured contact force opti-
mization for kino-dynamic motion generation,” in IEEE/RSJ Int. Conf.
Intell. Rob. Sys. (IROS), 2016.

[10] S. Fahmi, C. Mastalli, M. Focchi, and C. Semini, “Passive Whole-
Body Control for Quadruped Robots: Experimental Validation Over
Challenging Terrain,” IEEE Robot. Automat. Lett. (RA-L), vol. 4, 2019.
[11] E. Dantec, R. Budhiraja, A. Roig, T. Lembono, G. Saurel, O. Stasse,
P. Fernbach, S. Tonneau, S. Vijayakumar, S. Calinon, M. Taix, and
N. Mansard, “Whole Body Model Predictive Control with a Memory
of Motion: Experiments on a Torque-Controlled Talos,” in IEEE Int.
Conf. Rob. Autom. (ICRA), 2021.

[12] S. Katayama and T. Ohtsuka, “Efﬁcient solution method based on inverse
dynamics for optimal control problems of rigid body systems,” in IEEE
Int. Conf. Rob. Autom. (ICRA), 2021.

[13] H. Ferrolho, V. Ivan, W. Merkt, I. Havoutis, and S. Vijayakumar, “Inverse
Dynamics vs. Forward Dynamics in Direct Transcription Formulations
for Trajectory Optimization,” in IEEE Int. Conf. Rob. Autom. (ICRA),
2021.

[14] T. Erez and E. Todorov, “Trajectory optimization for domains with
contacts using inverse dynamics,” in IEEE/RSJ Int. Conf. Intell. Rob.
Sys. (IROS), 2012.

[15] R. Budhiraja, J. Carpentier, C. Mastalli, and N. Mansard, “Differential
Dynamic Programming for Multi-Phase Rigid Contact Dynamics,” in
IEEE Int. Conf. Hum. Rob. (ICHR), 2018.

[16] F. Udwadia and R. Kalaba, “A New Perspective on Constrained Mo-
tion,” Proceedings of the Royal Society A: Mathematical, Physical and
Engineering Sciences, 1992.

[17] C. Mastalli, J. Marti-Saumell, W. Merkt, J. Sola, N. Mansard, and
S. Vijayakumar, “A Feasibility-Driven Approach to Control-Limited
DDP,” Autom. Robots., 2022.

[18] G. Guennebaud, B. Jacob et al., “Eigen v3,” http://eigen.tuxfamily.org,

2010.

[19] J. B. J. G. Frison, “Efﬁcient implementation of the Riccati recursion
for solving linear-quadratic control problems,” in IEEE Int. Conf. Contr.
Apps. (CCA), 2013.

Fig. 14. Kinematics and dynamics feasibility evolution during multiple body
disturbances while the ANYmal was walking. Every time that we pushed
the robot, our inverse-dynamics MPC computed the optimal trajectories and
feedback policies to balance the ANYmal robot while walking dynamically in
place (top). When this happens, our solver increases the infeasibility instantly,
which helps to quickly ﬁnd a solution (bottom). The bottom plots show the L1-
norm of the kinematics |¯fs| and dynamics |¯hs| constraints using a logarithm
scale.

parametrization, which leads to an algorithm complexity that
does not grow with respect to the number of equality con-
straints. Quite the opposite, it reduces the dimensionality of
the matrix to be decomposed using Cholesky in the Riccati
recursion (a serial computation). This is possible as we can
partially parallelize some of the computations needed in the
Riccati recursion. We provided evidence that our method
reduces the computational time (up to 47.3%) and can solve
coarse optimal control problems with different robots and
constraints (up to 10 Hz of trajectory discretization).

Our algorithm is designed to drive both dynamics and
equality-constraint feasibility towards zero. To achieve this, it
employs a Goldstein-inspired condition based on a feasibility-
aware expected improvement and merit function. This in-
creases the robustness against poor initialization, enables the
generation of agile and complex maneuvers, and allows our
predictive controller to adapt quickly to body disturbances.

To further improve computation efﬁciency, we presented a
condensed formulation of inverse dynamics that can handle
arbitrary actuation models. To do so, we assumed that the
inverse-dynamics constraint is always feasible and deﬁned an
under-actuation constraint. This assumption was validated em-
pirically, and we found that most of the time this assumption
had no impact on numerical behavior

Our approach enables the generation of complex maneuvers
as fast as needed for MPC applications. Indeed, we presented
the ﬁrst application of an inverse-dynamics MPC in a legged
robot. We also proposed a novel approach to compute feedback
policy in the joint-torque space, which allows us to directly
control the robot. Within a perceptive locomotion pipeline,
both the inverse-dynamics MPC and feedback policy enabled
the ANYmal robot to navigate over complex terrains such as
damaged staircases.

2224262830time (s)10−1410−1010−610−2102feasibility L1-norm|̂fs|2224262830time (s)100101102103|̂hs|MASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

17

[20] P. E. Gill, W. Murray, and M. A. Saunders, “SNOPT: An SQP Algorithm
for Large-Scale Constrained Optimization,” SIAM Rev., vol. 47, pp. 99–
131, 2005.

[47] R. H. Byrd, M. E. Hribar, and J. Nocedal, “An Interior Point Algorithm
for Large-Scale Nonlinear Programming,” SIAM Journal on Optimiza-
tion, vol. 9, 1999.

[21] R. H. Byrd, J. Nocedal, and R. A. Waltz, “KNITRO: An integrated pack-
age for nonlinear optimization,” in Large Scale Nonlinear Optimization,
35–59, 2006, 2006, pp. 35–59.

[22] A. W¨achter and L. T. Biegler, “On the implementation of an interior-
point ﬁlter line-search algorithm for large-scale nonlinear programming,”
Mathematical Programming, vol. 106, pp. 25–57, 2006.

[23] R. A. Waltz, J. L. Morales, J. Nocedal, and D. Orban, “An Interior
Algorithm for Nonlinear Optimization That Combines Line Search and
Trust Region Steps,” Math. Program., 2006.

[24] “Harwell Subroutine Library, AEA Technology, Harwell, Oxfordshire,

England. A catalogue of subroutines,” http://www.hsl.rl.ac.uk/.

[25] P.-B. Wieber, “Trajectory Free Linear Model Predictive Control for
Stable Walking in the Presence of Strong Perturbations,” in IEEE Int.
Conf. Hum. Rob. (ICHR), 2006.

[26] ——, “Viability and predictive control

for safe locomotion,” in

IEEE/RSJ Int. Conf. Intell. Rob. Sys. (IROS), 2008.

[27] J. Di Carlo, P. M. Wensing, B. Katz, G. Bledt, and S. Kim, “Dynamic
Locomotion in the MIT Cheetah 3 Through Convex Model-Predictive
Control,” in IEEE/RSJ Int. Conf. Intell. Rob. Sys. (IROS), 2018.
[28] G. Bledt and S. Kim, “Extracting Legged Locomotion Heuristics with
Regularized Predictive Control,” in IEEE Int. Conf. Rob. Autom. (ICRA),
2020.

[29] O. Villarreal, V. Barasuol, P. M. Wensing, D. G. Caldwell, and C. Sem-
ini, “MPC-based Controller with Terrain Insight for Dynamic Legged
Locomotion,” in IEEE Int. Conf. Rob. Autom. (ICRA), 2020.

[30] N. Rathod, A. Bratta, M. Focchi, M. Zanon, O. Villarreal, C. Semini, and
A. Bemporad, “Model Predictive Control With Environment Adaptation
for Legged Locomotion,” IEEE Access, vol. 9, 2021.

[31] F. Farshidian, E. Jelavic, A. Satapathy, M. Giftthaler, and J. Buchli,
“Real-time motion planning of legged robots: A model predictive control
approach,” in IEEE Int. Conf. Hum. Rob. (ICHR), 2017.

[32] R. Grandia, F. Farshidian, R. Ranftl, and M. Hutter, “Feedback MPC for
Torque-Controlled Legged Robots,” in IEEE/RSJ Int. Conf. Intell. Rob.
Sys. (IROS), 2019.

[33] T. Corberes, T. Flayols, P.-A. Leziart, R. Budhiraja, P. Soueres,
G. Saurel, and N. Mansard, “Comparison of predictive controllers for
locomotion and balance recovery of quadruped robots,” IEEE Int. Conf.
Rob. Autom. (ICRA), 2021.

[34] S. Katayama and T. Ohtsuka, “Whole-body model predictive control
with rigid contacts via online switching time optimization,” 2022.
[35] M. Diehl, H. G. Bock, H. Diedam, and P.-B. Wieber, “Fast Direct
Multiple Shooting Algorithms for Optimal Robot Control,” in Proc. on
Fast Mot. in Bio. Rob. Springer Berlin Heidelberg, 2006.

[36] C. Mastalli, R. Budhiraja, W. Merkt, G. Saurel, B. Hammoud,
M. Naveau, J. Carpentier, L. Righetti, S. Vijayakumar, and N. Mansard,
“Crocoddyl: An Efﬁcient and Versatile Framework for Multi-Contact
Optimal Control,” in IEEE Int. Conf. Rob. Autom. (ICRA), 2020.
[37] J. Baumgarte, “Stabilization of constraints and integrals of motion in
dynamical systems,” Computer Methods in Applied Mechanics and
Engineering, 1972.

[38] E. Todorov, “Convex and analytically-invertible dynamics with contacts
and constraints: Theory and implementation in MuJoCo,” in IEEE Int.
Conf. Rob. Autom. (ICRA), 2014.

[39] D. Gabay, “Minimizing a differentiable function over a differential

manifold,” J. Optim. Theory Appl., vol. 37, 1982.

[40] U. Frese, “A Framework for Sparse Non-Linear Least Squares Problems

on Manifolds,” Ph.D. dissertation, Universit¨at Bremen, 2008.

[41] R. E. Bellman, “The Theory of Dynamic Programming,” Bull. Amer.

Math. Soc, 1954.

[42] F. Farshidian, M. Neunert, A. W. Winkler, G. Rey, and J. Buchli,
“An efﬁcient optimal planning and control framework for quadrupedal
locomotion,” in IEEE Int. Conf. Rob. Autom. (ICRA), 2017.
[43] G. H. Golub and C. F. V. Loan, Matrix computations, 4th ed.

The

Johns Hopkins University Press, 2013.

[44] M. Giftthaler and J. Buchli, “A projection approach to equality con-
strained iterative linear quadratic optimal control,” in IEEE Int. Conf.
Hum. Rob. (ICHR), 2017.

[45] Y. Tassa, T. Erez, and E. Todorov, “Synthesis and stabilization of
complex behaviors through online trajectory optimization,” in IEEE/RSJ
Int. Conf. Intell. Rob. Sys. (IROS), 2012.

[46] J. Nocedal and S. Wright, Numerical Optimization, 2nd ed. New York,

USA: Springer, 2006.

[48] R. Fletcher, “A modiﬁed Marquardt subroutine for non-linear least

squares,” J. Math. Sci., 1971.

[49] T. A. Howell, B. Jackson, and Z. Manchester, “ALTRO: A Fast Solver
for Constrained Trajectory Optimization,” in IEEE/RSJ Int. Conf. Intell.
Rob. Sys. (IROS), 2019.

[50] S. Kazdadi, J. Carpentier, and J. Ponce, “Equality Constrained Differ-
ential Dynamic Programming,” in IEEE Int. Conf. Rob. Autom. (ICRA),
2021.

[51] A. Pavlov, I. Shames, and C. Manzie, “Interior Point Differential
Dynamic Programming,” IEEE Trans. Contr. Sys. Tech. (TCST), vol. 29,
2021.

[52] L. zhi Liao and C. A. Shoemaker, “Advantages of Differential Dynamic
Programming Over Newton’s Method for Discrete-Time Optimal Con-
trol Problems,” Cornell University, Tech. Rep., 1992.

[53] M. Posa, C. Cantu, and R. Tedrake, “A direct method for trajectory
optimization of rigid bodies through contact,” The Int. J. of Rob. Res.
(IJRR), vol. 33, 2014.

[54] H. Dai, A. Valenzuela, and R. Tedrake, “Whole-body motion planning
with centroidal dynamics and full kinematics,” in IEEE Int. Conf. Hum.
Rob. (ICHR), 2014.

[55] C. Mastalli, I. Havoutis, M. Focchi, D. G. Caldwell, and C. Semini, “Hi-
erarchical planning of dynamic movements without scheduled contact
sequences,” in IEEE Int. Conf. Rob. Autom. (ICRA), 2016.

[56] S. Dafarra, G. Romualdi, and D. Pucci, “Dynamic Complementarity
Conditions and Whole-Body Trajectory Optimization for Humanoid
Robot Locomotion,” IEEE Trans. Robot. (T-RO), 2022.

[57] R. Deits and R. Tedrake, “Footstep planning on uneven terrain with
mixed-integer convex optimization,” in IEEE Int. Conf. Hum. Rob.
(ICHR), 2014.

[58] B. Aceituno-Cabezas, C. Mastalli, H. Dai, M. Focchi, A. Radulescu,
D. G. Caldwell, J. Cappelletto, J. C. Grieco, G. Fernandez-Lopez, and
C. Semini, “Simultaneous Contact, Gait, and Motion Planning for Ro-
bust Multilegged Locomotion via Mixed-Integer Convex Optimization,”
IEEE Robot. Automat. Lett. (RA-L), vol. 3, 2018.

[59] S. Tonneau, D. Song, P. Fernbach, N. Mansard, M. Ta¨ıx, and A. Del
Prete, “SL1M: Sparse L1-norm Minimization for contact planning on
uneven terrain,” in IEEE Int. Conf. Rob. Autom. (ICRA), 2020.

[60] R. Grandia, A. J. Taylor, A. D. Ames, and M. Hutter, “Multi-Layered
Safety for Legged Robots via Control Barrier Functions and Model
Predictive Control,” in IEEE Int. Conf. Rob. Autom. (ICRA), 2021.
[61] M. Kalakrishnan, J. Buchli, P. Pastor, M. Mistry, and S. Schaal, “Learn-
ing, planning, and control for quadruped locomotion over challenging
terrain,” The Int. J. of Rob. Res. (IJRR), vol. 30, no. 2, 2011.

[62] C. Mastalli, M. Focchi, I. Havoutis, A. Radulescu, S. Calinon, J. Buchli,
D. G. Caldwell, and C. Semini, “Trajectory and foothold optimization
using low-dimensional models for rough terrain locomotion,” in IEEE
Int. Conf. Rob. Autom. (ICRA), 2017.

[63] P. Fankhauser, M. Bjelonic, C. Dario Bellicoso, T. Miki, and M. Hutter,
“Robust Rough-Terrain Locomotion with a Quadrupedal Robot,” in
IEEE Int. Conf. Rob. Autom. (ICRA), 2018.

[64] C. Mastalli, I. Havoutis, M. Focchi, D. G. Caldwell, and C. Semini,
“Motion Planning for Quadrupedal Locomotion: Coupled Planning,
Terrain Mapping and Whole-Body Control,” IEEE Trans. Robot. (T-RO),
vol. 36, 2020.

[65] P. Fankhauser, M. Bloesch, C. Gehring, M. Hutter, and R. Siegwart,
“Robot-centric elevation mapping with uncertainty estimates,” in Int.
Conf. on Climb. and Walk. Rob. and the Supp. Techn. for Mob. Mach.
(CLAWAR), 2014.

[66] F. Risbourg, T. Corb`eres, P.-A. Leziart, T. Flayols, N. Mansard, and
time footstep planning and control of the Solo
S. Tonneau, “Real
quadruped robot in 3D environments,” in IEEE/RSJ Int. Conf. Intell.
Rob. Sys. (IROS), 2022.

[67] J.-L. Blanco, “A tutorial on SE(3) transformation parameterizations and
on-manifold optimization,” University of Malaga, Tech. Rep., 2010.
[68] D. Bellicoso, C. Gehring, J. Hwangbo, P. Fankhauser, and M. Hutter,
“Perception-less terrain adaptation through whole body control and
hierarchical optimization,” in IEEE Int. Conf. Hum. Rob. (ICHR), 2016.
[69] R. W. Brockett, “Asymptotic stability and feedback stabilization,” in

Differential Geometric Control Theory, 1983, pp. 181–191.

[70] T. Boaventura, C. Semini, J. Buchli, M. Frigerio, M. Focchi, and D. G.
Caldwell, “Dynamic torque control of a hydraulic quadruped robot,” in
IEEE Int. Conf. Rob. Autom. (ICRA), 2012.

MASTALLI et al.: INVERSE-DYNAMICS MPC VIA NULLSPACE RESOLUTION

18

[71] M. Hutter, C. Gehring, D. Jud, A. Lauber, C. D. Bellicoso, V. Tsou-
nis, J. Hwangbo, K. Bodie, P. Fankhauser, M. Bloesch, R. Diethelm,
S. Bachmann, A. Melzer, and M. Hoepﬂinger, “ANYmal - a highly
mobile and dynamic quadrupedal robot,” in IEEE/RSJ Int. Conf. Intell.
Rob. Sys. (IROS), 2016.

Carlos Mastalli
received the M.Sc. degree in
mechatronics engineering from the Sim´on Bol´ıvar
University, Caracas, Venezuela,
in 2013 and the
Ph.D. degree in bio-engineering and robotics from
the Istituto Italiano di Tecnologia, Genoa, Italy, in
2017.

He is currently an Assistant Professor at Heriot-
Watt University, Edinburgh, U.K. He is the Head of
the Robot Motor Intelligence (RoMI) Lab afﬁliated
to the National Robotarium and Edinburgh Centre
for Robotics. He is also appointed as Research
Scientist at IHMC, USA. Previously, he conducted cutting-edge research
in several world-leading labs: Istituto Italiano di Tecnologia (Italy), LAAS-
CNRS (France), ETH Z¨urich (Switzerland), and the University of Edinburgh
(UK). His research focuses on building athletic intelligence for robots with
legs and arms. Carlos’ research work is at the intersection of model predictive
control, numerical optimization, machine learning, and robot co-design.

Sethu Vijayakumar received the Ph.D. degree in
computer science and engineering from the Tokyo
Institute of Technology, Tokyo, Japan, in 1998.

He is Professor of Robotics and Founding Direc-
tor of the Edinburgh Centre for Robotics, where he
holds the Royal Academy of Engineering Microsoft
Research Chair in Learning Robotics within the
School of Informatics at the University of Edin-
burgh, U.K. He also has additional appointments as
an Adjunct Faculty with the University of Southern
California, Los Angeles, CA, USA and a Visiting
Research Scientist with the RIKEN Brain Science Institute, Tokyo. His
research interests include statistical machine learning, whole body motion
planning and optimal control in robotics, optimization in autonomous systems
as well as optimality in human motor motor control and prosthetics and
exoskeletons. Professor Vijayakumar is a Fellow of the Royal Society of
Edinburgh. In his recent role as the Programme Director for Artiﬁcial
Intelligence and Robotics at The Alan Turing Institute, Sethu helps shape
and drive the UK national agenda in Robotics and Autonomous Systems.

Saroj Prasad Chhatoi received his M.Sc. degree in
physics from the Institute of Mathematical Sciences,
Chennai, India in 2019.

He is currently pursuing a Ph.D. degree in In-
formation Engineering at Centro di Ricerca “Enri-
co Piaggio”, Universit`a di Pisa, Italy. His research
interests include legged locomotion, control of soft
robotic systems, model predictive control.

Thomas Corb`eres received his M.Sc. degree in
informatics and computing engineering from the
University of Toulouse, Toulouse, France in 2020.

He is currently pursuing a Ph.D. degree in robotics
and autonomous systems at the University of Ed-
inburgh under the supervision of S. Tonneau. His
research interests include legged locomotion, model
predictive control, and contact planning.

Steve Tonneau received the Ph.D. degree in hu-
manoid robotics from the INRIA/IRISA, France, in
2015.

He is a Lecturer at the University of Edinburgh,
Edinburgh, U.K.. Previously, he was a Postdoctoral
Researcher at LAAS-CNRS in Toulouse, France.
His research focuses on motion planning based on
the biomechanical analysis of motion invariants.
Applications include computer graphics animation
as well as robotics.

