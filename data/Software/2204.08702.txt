Software Engineering Approaches for TinyML based IoT
Embedded Vision: A Systematic Literature Review

Shashank Bangalore Lakshman
Boise State University
Boise, ID, USA
shashankbangalor@u.boisestate.edu

Nasir U. Eisty
Boise State University
Boise, ID, USA
nasireisty@boisestate.edu

2
2
0
2

r
p
A
9
1

]
E
S
.
s
c
[

1
v
2
0
7
8
0
.
4
0
2
2
:
v
i
X
r
a

ABSTRACT
Internet of Things (IoT) has catapulted human ability to control our
environments through ubiquitous sensing, communication, com-
putation, and actuation. Over the past few years, IoT has joined
forces with Machine Learning (ML) to embed deep intelligence at
the far edge. TinyML (Tiny Machine Learning) has enabled the
deployment of ML models for embedded vision on extremely lean
edge hardware, bringing the power of IoT and ML together. How-
ever, TinyML powered embedded vision applications are still in
a nascent stage, and they are just starting to scale to widespread
real-world IoT deployment. To harness the true potential of IoT
and ML, it is necessary to provide product developers with ro-
bust, easy-to-use software engineering (SE) frameworks and best
practices that are customized for the unique challenges faced in
TinyML engineering. Through this systematic literature review,
we aggregated the key challenges reported by TinyML developers
and identified state-of-art SE approaches in large-scale Computer
Vision, Machine Learning, and Embedded Systems that can help
address key challenges in TinyML based IoT embedded vision. In
summary, our study draws synergies between SE expertise that em-
bedded systems developers and ML developers have independently
developed to help address the unique challenges in the engineering
of TinyML based IoT embedded vision.

CCS CONCEPTS
• Software and its engineering → Software development meth-
ods.

KEYWORDS
Software Engineering; IoT; TinyML; Embedded Vision; Systematic
Literature Review

ACM Reference Format:
Shashank Bangalore Lakshman and Nasir U. Eisty. 2022. Software Engineer-
ing Approaches for TinyML based IoT Embedded Vision: A Systematic Liter-
ature Review. In 4th International Workshop on Software Engineering Research
and Practice for the IoT (SERP4IoT’22), May 19, 2022, Pittsburgh, PA, USA.
ACM, New York, NY, USA, 8 pages. https://doi.org/10.1145/3528227.3528569

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
SERP4IoT’22, May 19, 2022, Pittsburgh, PA, USA
© 2022 Association for Computing Machinery.
ACM ISBN 978-1-4503-9332-4/22/05. . . $15.00
https://doi.org/10.1145/3528227.3528569

1 INTRODUCTION
The desire for a better lifestyle and the growing abundance of chal-
lenges faced on the planet have necessitated technological break-
throughs. ‘Edge Intelligence’ aims to harness the combined power
of IoT and ML to solve unique problems at scale, right at the place
where the data gets generated [28]. Millions of ubiquitous smart
embedded vision systems (cameras with local computing power
and network connectivity) are deployed and will be deployed at the
edge in various domestic, industrial, and commercial applications
(some examples are illustrated in Figure 1). IoT sensor networks
collect gigabytes of data every minute, and their computational sys-
tems must process the data streams in real-time to provide valuable,
actionable insights to people, and other systems [28]. IoT embedded
vision systems are being deployed at the far edge for valuable gains
in speed, power efficiency, cost efficiency, privacy, and autonomy
[28]. Many previously intractable problems that previously required
human experts and sophisticated hardware-software systems for
decision-making are now starting to be automated by deploying
start-of-art ML models on lean embedded IoT.

SE for ML has evolved over the last decade [12], aimed at field-
ing a plethora of challenges faced by ML developers to harness the
power of Deep Neural Networks (DNN). Similarly, SE for IoT embed-
ded systems has also evolved over the past decade into a successful
research domain [22]. Because TinyML combines ML for computer
vision (CV) with IoT embedded systems, engineering, deployment,
and maintenance of TinyML applications, requires a well-defined
and customized SE approach to address the unique challenges in
the domain. Without a guiding set of SE approaches for TinyML
based IoT embedded vision, product development lifecycle can in-
volve high costs, low productivity, and weaknesses in the field [12].
The need for low latency, low power, low cost, and robustness in
these applications requires SE processes to be aware of systems
architecture, algorithms, and challenges in real-world deployments.
Our research summarizes state-of-art SE approaches applicable to
solve the unique challenges in TinyML engineering and proposes a
streamlined SE workflow to simplify the development, deployment,
and maintenance of IoT embedded vision applications, in addition
to suggestions for developer tools.

Figure 1: Emerging embedded vision IoT applications

 
 
 
 
 
 
SERP4IoT’22, May 19, 2022, Pittsburgh, PA, USA

S. Bangalore Lakshman et al.

2 BACKGROUND
It is projected that a total of 2.5 billion edge AI devices will ship with
a TinyML chipset in 2030 [25]. Early Proof-of-Concept (POC) appli-
cations using TinyML based IoT embedded vision have showcased
huge potential to enable smart manufacturing, smart home, smart
city, smart devices, infotainment, autonomy, and smart agriculture
applications on extremely lean IoT systems. However, this approach
is yet to scale into massively deployed products and solutions in
the real world, as these systems are challenged by portability, ro-
bustness, reliability, development costs, and skill gaps [30].

The rapid growth in CV applications powered by Deep Learn-
ing (DL) approaches is due to DNN-based approaches extracting
features automatically from training data, without the need for
heuristic rules [16]. Typical CV applications are driven by Con-
volutional Neural Networks (CNN) as visual information has rich
spatial information. Trained models also must be trained with the
appropriate quantity and quality of data based on an understanding
of input data expected in real-world deployments. As DL became
popular over the decade, there was an uncontrolled growth in the
size of DL models. This growth resulted in steep demand for both
computing power and memory availability in training as well as
inference systems [31].

Migrating such monstrous DL models into leaner IoT embed-
ded systems for inferencing tasks is a unique challenge that re-
quires a systematic overhaul towards hardware-aware engineering
[31]. Typical advanced MCUs are those that are capable of running
highly-optimized, compressed DNN models by leveraging only a
few 100 kBs of memory, computing speed in the order of MIPS
(Million Instructions Per Second) or GIPS (Giga Instructions Per
Second) at a power consumption of <1W [8]. ‘Model reduction’,
‘parameter quantization’, ’knowledge distillation’, and ’Neural archi-
tecture search’ are the key tools for overcoming machine learning
challenges on the edge [13] [30] [31].

IoT embedded vision applications offer the advantage of low
latency, real-time actionable insights, lower cost of data transmis-
sion, higher reliability under economy of scale. TinyML can be
broadly defined as ML approaches capable of performing on-device
analytics for a spectrum of sensing modalities at “mW” (or below)
power range, on lean and battery-operated devices. A few examples
of off-the-shelf IoT embedded vision hardware capable of running
TinyML applications are showcased in Figure 2. A comparison of
their key technical specifications is presented in Table 1. If the
TinyML engineering process can be made more efficient, then the
lifetime cost of applications can be driven further low by the mas-
sive market potential for IoT embedded vision applications.

ML has gained massive popularity with application developers
due to the availability of hardware-agnostic open-source ML frame-
works such as TensorFlow and PyTorch. Similarly, TinyML has
embraced a framework approach to simplify developer experience
and amplify productivity. TinyML has multiple frameworks such as
TensorFlow Lite Micro (TFLM), uTensor, STM32Cube.AI, and Em-
bedded Learning Library (ELL). However, our research only focused
on TFLM framework due to its popularity and being independent
on the hardware.

TFLM is an open-source ML inference framework (developed by
Google and Harvard University) for running deep-learning models

Figure 2: Example IoT embedded vision devices [7]

on MCU based embedded systems with very lean computing and
memory infrastructure. TFLM addresses the resource constraints
faced with running DL models on embedded systems with 32-bit
MCUs and a few 100kB of memory, without hardware-specific
customizations [8]. In TFLM, the trained model is interpreted by
the application code by giving it pre-processed input data and then
performing post-processing of model output and output handling
[32].

A large part of modern CV research and development has been
driven by approaches unconstrained by hardware infrastructure,
resulting in very large DL models. To democratize CV on the edge
[8], it is necessary to take a hardware-aware approach to ML engi-
neering, so that inference can be performed on lean IoT systems
while maintaining compatibility to multiple MCU platforms.

Lack of SE expertise in both IoT embedded vision systems and
ML engineering creates an open gap in SE approaches required for
TinyML powered IoT embedded vision applications. A summary of
key challenges involved in TinyML engineering is listed in Table
2. In addition, the challenges are grouped under key milestones in
the TinyML engineering lifecycle.

3 RESEARCH METHODOLOGY
The previous section described the numerous challenges faced by
TinyML application developers. Our systematic literature survey
addresses two research questions to summarize SE best practices
reported in the literature and visualizes a streamlined workflow
for TinyML engineering. TinyML launched only in 2018 and hence,
there is a lack of published research into software engineering
approaches and best practices. Our research performed a systematic
literature review of related prior art in TinyML, Machine Learning,
Computer Vision, and Embedded Systems, with the overall goals
described here:

• Summarization of SE best practices applicable to TinyML

engineering for computer vision applications.

• Visualization of a SE workflow that can enable quick and
easy-to-manage TinyML engineering for developing and
deploying CV applications on edge.

• Suggestion of ideas for new developer support features in
production tools (IDE, packages, test tools, etc.) to accelerate
market adoption of TinyML for CV applications.

SE approaches for TinyML based IoT Embedded Vision

SERP4IoT’22, May 19, 2022, Pittsburgh, PA, USA

Table 1: Comparison of hardware specifications of off-the-shelf IoT embedded vision hardware [7]

IoT device
Compute

HIMAX WE-I Plus EVB
WE-I Plus ASIC (HX6537-A), ARC 32-
bit EM9D DSP with FPU @400MHz
2MB flash and 2MB SRAM

Memory
Vision sensor Himax HM0360 AoS TM ultra-low
power VGA CCM, 1/6", 640×480 pixels
@60FPS
$65

Device cost

OPENMV Cam H7 R2
ARM 32-bit Cortex-M7 CPU w/ Double
Precision FPU @480MHz
2MB flash and 1MB SRAM
MT9M114: CMOS Image Sensor, 1/6",
640×480 pixels @40FPS

ARDUCAM Pico4ML
RP2040 Dual-core Arm Cortex-M0+ pro-
cessor @133MHz
2MB flash and 256kB SRAM
Himax HM01B0 CCM, 1/11", 320 x 240
pixels @60FPS

$65

$50

3.1 Research Questions (RQs)
We identified two Research Questions (RQs) that span SE challenges
and approaches in large ML domain as well as IoT.

• RQ1: Which widely used SE practices from large pro-
duction AI/ML engineering are applicable to TinyML
engineering?
– Need: To identify SE practices used in generic large AI/ML
systems as well as CV-centric large AI/ML systems from a
thorough literature survey of state-of-art while determin-
ing their applicability to TinyML engineering.

– RQ1 aggregates SE solutions already prevalent in practice
while ensuring their applicability to challenges imposed
on the model size by TinyML constraints.

• RQ2: Which widely used SE practices from traditional

embedded systems engineering are applicable to TinyML
engineering?
– Need: To identify SE practices used in embedded systems
engineering from a thorough literature survey of state-
of-art while determining their applicability to TinyML
engineering.

– RQ2 aggregates SE solutions that are already prevalent in
practice while ensuring their applicability to challenges
imposed by TinyML vision applications.

3.2 Research protocol
TinyML and TFLM were introduced in 2018, and the published
scientific literature is limited. Only a handful of papers pertain to
embedded vision applications. Additionally, the TinyML literature
is mostly gray literature, tutorials, workshops, talks, and blogs. To
address challenges in TinyML engineering reported in the literature,
the systematic literature survey focused on aggregating solutions
from a broad spectrum of information sources.

We gathered 43 information sources from arXiv, IEEE, ACM Dig-
ital Library, Springer Link, ML conference tutorials, and workshops
using sample search queries described in Table 3. Then, we studied
the abstract and conclusions from the gathered literature to refine
the source pool to 20. Finally, we forward and backward snowballed
on Google Scholar, Google Search, and related Blogs to derive 13
additional sources. In total, we have 33 information sources as the
primary pool for this study.

4 RESULTS AND DISCUSSION
The first section ties various findings into the research questions
defined at the start of the project. The second section ties the SE

approaches and best practices to derive a SE workflow for TinyML
CV application developers. In the interest of brevity, only the most
compelling results relevant to IoT embedded vision systems are
presented. Challenges and solutions in TinyML engineering are
presented in Table 4 and 5, with classification based on steps in-
volved in TinyML workflow process. Answers from RQ1 and RQ2
were evaluated for applicability to TinyML engineering of edge CV
applications through thorough study.

4.1 RQ1 findings
Established SE practices in large-scale AI/ML and CV engineering
are applicable broadly to solve many of the challenges in IoT em-
bedded vision engineering. However, there is a significant need
for hardware-aware Neural Architecture Search (NAS) approaches,
hardware-aware co-optimization approaches, reference datasets for
IoT embedded vision applications, and standardized benchmarking
techniques and metrics.

4.2 RQ2 findings
It is to be noted that established SE practices from embedded/IoT en-
gineering largely apply to IoT embedded vision systems. However,
there is a significant need for portable libraries for pre-processing
and post-processing functions that are key components of the ML
inference architecture. SE practices need tools capable of design
space search and automatic version control for deployment-ready
TinyML models.

4.3 SE workflow for TinyML engineering
Based on the results of the systematic literature survey, we see
the need to define a software engineering workflow specifically
to cater to TinyML engineering. Inspired by CRISP-DM, Microsoft
ML workflow, and TFLM workflows, we present a modified work-
flow in Figure 3. The workflow can be adopted by CV application
developers alongside results summarized by this systematic liter-
ature survey. The proposed SE workflow divides the engineering
process into steps that are suggested to be performed ‘in situ’ aka
‘training environment with CPU and GPU’ and to be performed ’in
vivo’ aka ’lean edge hardware performing inference in real-world
deployment’.

It is beneficial to break down the business requirements (cus-
tomer requirements) into three inter-related components: model
requirements, data requirements, and system requirements. This
approach helps delegate ownership of delivering individual compo-
nents to different individuals or teams. It also enables autonomy

SERP4IoT’22, May 19, 2022, Pittsburgh, PA, USA

S. Bangalore Lakshman et al.

Table 2: Key challenges in TinyML based IoT embedded vision engineering

CHALLENGE
Requirements specifications
and design

Data and model search

Model development and val-
idation

Application development
and deployment

SE methodologies

DESCRIPTION
System design choices: No clear decision framework or benchmark that can guide TinyML based IoT
embedded vision application developers with regard to hardware/model design choices to be made for a
given application/market/customer requirement [21].
Compiler choices: Embracing sophisticated compilers can help optimize for specific MCU targets. However,
this affects portability, and hence, it challenges large-scale deployment under availability constraints. Need
to enable platform specific optimizations without need for specialized compiler [8].
Ensuring the security of embedded devices is a challenge for IoT applications [18] [26].
Requirements in the field may evolve, and the system needs to grow its intelligence to meet the goals [12].
IoT embedded vision devices need to be "less chatty" to reduce the power consumed by communications [18].
IoT embedded devices have a high degree of heterogeneity [5].
Although hand coding and code generation can leverage specific optimizations at the cost of flexibility [5].
On-device training is challenging in small memory footprint devices [6]
Lack of curated datasets derived from IoT embedded vision sensors for different applications [5].
Lack of standard tools to compare performances between different algorithms against different MCU
systems [5].
Challenging to assess the impact of different levels of quantization and precision as well as model peak
memory requirements [5].
Due to the wide spectrum of MCU designs, it is beneficial to take a framework with generic compiler
features for design portability. However, this generic compiler might not be able to fully utilize unique
hardware features offered in some families of MCUs [8].
TinyML workflow is not hardware-aware due to limitations in generic frameworks [8].
Naive joint optimization techniques such as Neural Architecture Search (NAS), Quantization and Pruning
have cross-interactions which may result in sub-optimal results [27].
Lack of emulation tools for TinyML engineering increases the time and effort spent on model develop-
ment [11].
Application portability across different devices and different vendors is a challenge in TinyML engineer-
ing [24].
Power profiling is complex since data paths and pre-processing steps can vary significantly between
devices [5].
TinyML powered applications are lean, and they lack tools for measurement and visualization of data. This
imposes additional challenges to debuggability during model development and deployment due to memory
constraints [5].
TinyML capable devices have drastically different power consumption, which makes it harder to maintain
accuracy consistently across the devices [5].
Real-world conditions can rapidly evolve due to changes in the sensing environment or the aging of vision
sensors. TinyML improves a significant challenge to online learning due to the low amount of compute
available [26].
Since edge CV applications may be used to drive time-critical decisions, the reliability of TinyML systems
needs to be high. Robustness needs to be built into the TinyML models to enable safe fail-over mechanisms
in the case of ambiguous environments [26].
Models deployed on TinyML vision systems must be capable of being upgraded without significant
intervention or system downtime.
Not much is known about efficient, best practices for TinyML application IoT embedded vision product
development, deployment and maintenance.
Agile development practices for TinyML engineering are not well established.
TinyML CV application requires expertise in embedded systems, computer vision, and machine learning.
Since TinyML is still in a nascent stage, there is a lack of skilled engineers who have sufficient expertise to
address challenges in TinyML engineering for CV apps [24]

SE approaches for TinyML based IoT Embedded Vision

SERP4IoT’22, May 19, 2022, Pittsburgh, PA, USA

Table 3: Protocol summary of systematic literature review

Research Questions

Sample Search strings

Search strategy

Inclusion Criteria

Exclusion Criteria

Study type

RQ1: Which widely used SE practices from large production AI/ML engineering are applicable to TinyML
engineering?
RQ2: Which widely used SE practices from traditional embedded systems engineering are applicable to
TinyML engineering?
"TinyML" AND "Computer Vision"
"Software Engineering" AND "Edge Computer Vision"
"Software Engineering" AND "Machine Learning"
"Software Engineering" AND "Embedded Systems"
DB search: arXiv, IEEE, ACM Digital Library, Springer Link
Backward and forward snowballing using Google Scholar
Manual search using TinyML.org and Google Search
The paper is written in English
Grey-literature is accepted since TinyML is quite recent
The paper is related to software engineering applied to traditional computing
TinyML powered by non-TFLM (TensorFlow Lite Micro) frameworks
Primary and Secondary studies

Figure 3: SE workflow for TinyML engineering for CV applications

for those teams to understand requirements to apply their exper-
tise in system design, model search, and setting up pipelines for
data collection, cleaning, and labeling. Once the system design
is generated, it will provide additional inputs to constrain model
search and data engineering. Given that the application must run
on a lean MCU resource, system design provides the boundary con-
ditions on computing-memory complexity of algorithms used in
data engineering (pre-processing and post-processing) and machine
learning.

Main application development can be carried out concurrently
with model development. Concurrent development allows embed-
ded developers to develop and debug heuristic pipelines to perform
sensing and actuation based on expected outcomes from the ML

model. They can also debug this code using calibration functions
to emulate outputs of the final ML model. The model development
process can continue after model search and data engineering steps.
Using best practices in model training, a suitable model can be
derived and evaluated against a validation data set. Feedback from
the evaluation step can lead model developers into model search or
model training to reconfigure the model or its hyper-parameters.
Once the model validation is satisfactory, the model can proceed
to the compilation steps, which are automatically taken care of
by the TFLM framework. Hardware-specific libraries can be used
during this process to take advantage of custom hardware features
available in target MCUs. After the model is compiled successfully,
compiled model evaluation can be carried out in a simulator in the

SERP4IoT’22, May 19, 2022, Pittsburgh, PA, USA

S. Bangalore Lakshman et al.

Table 4: SE challenges and solutions in TinyML engineering for edge CV apps

WORKFLOW STEP
Business (Customer)
Understanding

CHALLENGE
TinyML engineering requires expertise in AI, ML,
CV, and Embedded Systems.

Customer needs are changing dynamically.

System
ments

Require-

Deployment in real-world environments is chal-
lenging.
Mismatch in hardware systems and portability of
models across a family of hardware is required.

Performance degradation in a real-world scenario
is a major challenge to TinyML CV systems on
the edge.

Model Requirements Determination of models applicable to TinyML

projects is not well documented.

Determining useful models for lean edge is not
an easy task.

Data Requirements

Data sets available can have very limited data.

System Design

Data Engineering

Model development tools are tedious to maintain
for different target hardware systems.
Model development involved high complexity
when catering to an array of applications.

Vision data related to videos often contain re-
dundant information temporally, and it leads to
additional unnecessary computation on the lean
edge hardware.
Data derived from different sensors and sources
can have various file formats.
Real-world conditions might not be represented
in distributions found on data sets.

Model Training

Hyperparameter search process can experience
issues in reproducibility.

Training TinyML CV models with a performance
driven perspective is hard.
TinyML application developers might lack deep
expertise in ML and DL.

PROPOSED SOLUTION(S)
Decoupling teams which create systems, data, and
model data is helpful to carry out work concur-
rently [1].
In order to streamline the TinyML engineer-
ing process, customer needs must be version-
controlled to pursue incremental improvement
on tail features requested by the customer [12].
Define common implicit assumptions related to
visual data (illumination, shadows, etc).
Need to manage the combinatorial explosion
of hardware devices using strict control of de-
vice types and chipsets used in the TinyML sys-
tems [9].
Design decisions must be driven by environmen-
tal challenges that the TinyML CV application is
likely to experience. Data augmentation of the
training data set is necessary [9].
TinyML systems need to select target MCU hard-
ware for their projects based on requirements of
model size, inference speed, and power limita-
tions necessary for the application [5].
Constrained Neural Architectural Search (NAS)
can be used to narrow down model architectures
relevant to the system design choices [10] [23].
Test-driven development can be used to ensure
test data is not used during training as well as to
identify ways to test corner cases based on system
specs [12].
Setting up TinyML TFLM framework infrastruc-
ture correctly at start will help iterate faster [8].
Model management and version control are very
important for streamlining TinyML development
efforts [9].
Event-based approaches to visual information
processing can be applied to reduce the burden
imposed by redundant computations [29].

No direct access to data, only programmatic inter-
faces (8-bit RGB image instead of image.jpg) [9].
Data augmentation can be used to simulate real-
world conditions (scaling, noise, shadows, color,
lighting conditions, etc.).
Usage of deterministic randomness (using ex-
posed random seeds) is helpful for iteration with
hyperparameter tuning [9].
Building training pipeline by adding verification-
based counter-examples will be helpful [9] [17].
TinyML application developers must leverage Au-
toML tools to automate the training process, es-
pecially when a large amount of training and val-
idation data is available.

ORIGIN
RQ1

RQ1

RQ1

RQ2

RQ1

RQ2

RQ1

RQ2

RQ1

RQ1

RQ1

RQ1

RQ1

RQ1

RQ1

RQ1

SE approaches for TinyML based IoT Embedded Vision

SERP4IoT’22, May 19, 2022, Pittsburgh, PA, USA

Table 5: SE challenges and solutions in TinyML engineering (continued)

WORKFLOW STEP
Model
(contd.)

Training

Model Evaluation

CHALLENGE
Web automation of TinyML engineering.

TinyML models need to be robust to take care of
environmental anomalies and noise.
Lack of standardized TinyML performance met-
rics in reported literature.

Model Compilation

Performance cannot be measured until an appli-
cation is deployed on the edge device system.

Compiled
Evaluation

Model

Application Design

Application Evalua-
tion

Application Deploy-
ment

Compiler settings need to be optimized for hard-
ware system targeted by the system design
choices.
It is hard to debug compiled model performance
on the edge device due to compute constraints.

Design tradeoffs are hard to optimize until the
model is optimized.
Application issues are harder to debug since the
system involves heuristic code, as well as trained
TinyML model.
Testing TinyML models can be derailed due to
bias in tests.
Real-world deployment of TinyML is hard even
after successful validation of models in training
environment.
Fixing bugs in embedded application deployment
is hard.

Application Monitor-
ing

Performance improvements in the field is chal-
lenging due to limitations on edge hardware.

It is hard to measure the performance of the
TinyML CV application in the field.

PROPOSED SOLUTION(S)
EdgeImpulse and Qeexo among other startups
offer AutoML capabilities that are delivered over
web, directly into edge CV applications [2].
Test-driven development must rely on measuring
local and global adversarial robustness [17].
MLPerfTiny benchmark has been published by
MLCommons to provide the first industry stan-
dard benchmark suite for ultra low power ML
systems [3].
Compilers must be capable of providing access to
performance metrics for MCUs as they are typi-
cally single-threaded [8].
Hardware aware compiler is helpful to take desir-
able tradeoffs automatically without the need for
understanding of MCU architectures [15] [33].
Device simulators and emulators must be used in
TinyML development. Device simulators can help
contrast performance of raw models and various
flavors of compiled TinyML models [9].
Automated tools can aid the search for tradeoffs
between performance, accuracy, and power [4].
Review of bug taxonomy for IoT applications,
can help avoid critical
issues in application
code [19] [14].
Dedicated QA teams can help with fair debug
with developer bias [9].
Reproducibility is driven when algorithms, param-
eters, and data/labels are ‘uniquely identifiable’
and ‘retrievable’ in real-world. [9].
Over-the-air (OTA) updates must be available to
seamlessly deliver bug fixes and upgrades for both
firmware and TinyML model [20].
Continuous Integration (CI) of Labeling and Re-
training using feedback from monitoring can help
drive application performance with new data dis-
tributions are encountered in the field [9].
Device-level monitoring tools can be used to im-
prove debuggability in the field [9].

ORIGIN
RQ1

RQ1

RQ1

RQ1

RQ1

RQ2

RQ1

RQ2

RQ2

RQ1

RQ2

RQ1

RQ2

training environment or on-device inference environment based on
the availability. The advantage of executing this step in a simulator
environment has been described earlier in the results section. If
there is a significant drop in model performance after compilation,
the feedback must be relayed back to the model compilation step
so that necessary actions can be taken.

Once the compiled model delivers performance comparable to
the original ML model, the model can be delivered to the application
integration team, which will integrate the model into the applica-
tion code, followed by application testing with test data set and
deployment in the field. Monitoring application performance in the
real-world situations can provide valuable feedback, which can be
used for Continuous Integration (CI) and guide the augmentation
or addition of suitable new data from real-world distributions.

4.4 Future IoT embedded vision developer

support tools

We are proposing certain key features for next-generation IoT em-
bedded vision developer support tools. These features enable a
better developer experience, reduce bugs, improve debuggability,
and productize scale IoT embedded vision applications.

(1) Embedded IoT developer tools must integrate TinyML frame-
works such as TFLM, through an interactive user-interface.
(2) SE workflow must be integrated into the toolchain to guide
developers through the application design, development, and
deployment process.

(3) Allow developers to import MCU models into the tool and vi-
sualize the MCU architecture. Allow comparison of different

SERP4IoT’22, May 19, 2022, Pittsburgh, PA, USA

S. Bangalore Lakshman et al.

MCU choices to guide design choices based on application
performance targets (FPS, TOPS, Precision support, etc).
(4) Allow emulation of devices to test the compatibility of com-
piled models prior to deployment on physical hardware. This
creates an opportunity to visualize application and model
operation without significant constraints on measurability.
(5) Automatically capture device capabilities and set constraints
into the design space to guide the TinyML development
process.

(6) Allow integration of custom libraries into the toolchain to
extend generic compiler capabilities to help developers lever-
age unique hardware features on the target MCU.

(7) Support multiple device management for IoT embedded sys-
tems including the capability to send firmware, code, and
model updates over-the-air (OTA).

(8) Allow configuration and interaction with a large number of
IoT embedded vision devices through RESTful API interfaces.

5 THREATS TO VALIDITY
As TinyML is evolving at a fast pace, framework designs are bound
to evolve rapidly and new SE approaches might be necessary. Hence,
the study lacks the perspective that may be obtained through sur-
veys and interviews of TinyML CV application developers in the
industry. Amount of TinyML literature is limited since TinyML
and TFLM concepts were introduced very recently (2018). It is hard
to quantify existing TinyML SE practices from only a handful of
peer-review publications.

As the field evolves rapidly, additional challenges and best prac-
tices will come to light which can challenge some of the conclusions
drawn by our study. Novel model architectures, model search ap-
proaches, TinyML development techniques may significantly alter
the proposed SE workflow and developer tool features.

6 CONCLUSION
There is significant scope for more profound research into SE ap-
proaches for production-scale engineering of IoT embedded vision
applications. Hardware-aware generic TinyML compiler tool fea-
tures will be required to extract full performance out of lean edge
devices. At the same time, application portability continues to chal-
lenge fixed-form compilers that focus on narrow optimizations for
highly specific hardware systems.

The proposed SE workflow is useful for concurrent work by
model developers, application code developers, and data engineers,
with high potential to evolve with TinyML research. This workflow
also accelerates the TinyML engineering process by delegating work
to teams with the necessary expertise. The integration of the CI
approach into the workflow provides a robust approach for refining
the TinyML product in the field without requiring expensive recalls
or repairs.

Further experimental research on the proposed SE best practices
and workflow will help validate and refine the SE approaches for
production-scale engineering TinyML CV applications.

REFERENCES
[1] S. Amershi, A. Begel, C. Bird, R. DeLine, H. Gall, E. Kamar, N. Nagappan, B. Nushi,
and T. Zimmermann. Software engineering for machine learning: A case study.

In 2019 IEEE/ACM 41st ICSE: SE in Practice (SEIP), pages 291–300, 2019.

[2] Arm. TinyML brings AI to smallest arm devices, Aug 2021.
[3] C. Banbury, V. J. Reddi, P. Torelli, J. Holleman, N. Jeffries, C. Kiraly, P. Montino,
D. Kanter, S. Ahmed, D. Pau, U. Thakker, A. Torrini, P. Warden, J. Cordaro, G. D.
Guglielmo, J. Duarte, S. Gibellini, V. Parekh, H. Tran, N. Tran, N. Wenxu, and
X. Xuesong. MLPerf Tiny Benchmark, 2021.

[4] C. Banbury, C. Zhou, I. Fedorov, R. M. Navarro, U. Thakker, D. Gope, V. J. Reddi,
M. Mattina, and P. N. Whatmough. Micronets: Neural network architectures for
deploying tinyml applications on commodity microcontrollers, 2021.

[5] C. R. Banbury, V. J. Reddi, M. Lam, W. Fu, A. Fazel, J. Holleman, X. Huang,
R. Hurtado, D. Kanter, A. Lokhmotov, D. Patterson, D. Pau, J. sun Seo, J. Sier-
acki, U. Thakker, M. Verhelst, and P. Yadav. Benchmarking TinyML Systems:
Challenges and Direction, 2021.

[6] H. Cai, C. Gan, L. Zhu, and S. Han. Tiny transfer learning: Towards memory-

efficient on-device learning. CoRR, abs/2007.11622, 2020.

[7] H. Chaudhary. Comparison of ai vision boards with onboard camera: We-i plus

evb vs openmv cam h7 vs pico4ml, Jul 2021.

[8] R. David, J. Duke, A. Jain, V. J. Reddi, N. Jeffries, J. Li, N. Kreeger, I. Nappier,
M. Natraj, S. Regev, R. Rhodes, T. Wang, and P. Warden. Tensorflow lite micro:
Embedded machine learning on TinyML systems, 2021.

[9] D. Doria, I. Ernst, and B. Kadlec. CVPR18: Tutorial: Software Engineering in

Computer Vision Systems. ComputerVisionFoundation, Jun 2018.

[10] I. Fedorov, R. P. Adams, M. Mattina, and P. N. Whatmough. Sparse: Sparse

architecture search for cnns on resource-constrained microcontrollers, 2019.

[11] M. Gielda. Running tf lite on microcontrollers without hardware in renode, Feb

2022.

[12] G. Giray. A software engineering perspective on engineering machine learn-
ing systems: State of the art and challenges. Journal of Systems and Software,
180:111031, 2021.

[13] A. Goel, C. Tung, Y. Lu, and G. K. Thiruvathukal. A survey of methods for
low-power deep learning and computer vision. CoRR, abs/2003.11066, 2020.
[14] M. J. Islam, G. Nguyen, R. Pan, and H. Rajan. A comprehensive study on deep

learning bug characteristics, 2019.

[15] L. Lai, N. Suda, and V. Chandra. Cmsis-nn: Efficient neural network kernels for

arm cortex-m cpus, 2018.

[16] Y. Lecun, Y. Bengio, and G. Hinton. Deep learning. Nature, 521(7553):436–444,

2015.

[17] A. Lomuscio. TinyML talks: Verification of ML-based AI systems and its applicability

in edge ML. tinyML, Oct 2021.

[18] M. Loukides. TinyML: The challenges and opportunities of low-power ML

applications, Oct 2019.

[19] A. Makhshari and A. Mesbah.

Iot bugs and development challenges. 2021
IEEE/ACM 43rd International Conference on Software Engineering (ICSE), pages
460–472, 2021.

[20] V. Mehta. Challenges of edge AI inference, Jul 2021.
[21] S. Mukherjee, Y. Verma, A. Gopani, and A. Choudhary. What are the challenges

of establishing a TinyML ecosystem, Mar 2020.

[22] R. Oshana and M. Kraeling. Software engineering for embedded systems: Methods,

practical techniques, and applications. Newnes, 2019.

[23] F. Paissan, A. Ancilotto, and E. Farella. PhiNets: a scalable backbone for low-

power ai at the edge, 2021.

[24] V. J. Reddi, B. Plancher, S. Kennedy, L. Moroney, P. Warden, A. Agarwal, C. Ban-
bury, M. Banzi, M. Bennett, B. Brown, S. Chitlangia, R. Ghosal, S. Grafman,
R. Jaeger, S. Krishnan, M. Lam, D. Leiker, C. Mann, M. Mazumder, D. Pajak,
D. Ramaprasad, J. E. Smith, M. Stewart, and D. Tingley. Widening access to
applied machine learning with TinyML, 2021.

[25] A. Research. Global shipments of TinyML devices to reach 2.5 billion by 2030.
[26] M. Shafique, M. Naseer, T. Theocharides, C. Kyrkou, O. Mutlu, L. Orosa, and J. Choi.
Robust machine learning systems: Challenges, current trends, perspectives, and
the road ahead. IEEE Design Test, 37(2):30–57, 2020.

[27] M. Shafique, T. Theocharides, V. Reddy, and B. Murmann. TinyML: Current
progress, research challenges, and future roadmap. In 2021 58th ACM/IEEE Design
Automation Conference, DAC 2021, Proceedings - Design Automation Conference,
pages 1303–1306. Institute of Electrical and Electronics Engineers Inc., Dec.
[28] W. Shi, J. Cao, Q. Zhang, Y. Li, and L. Xu. Edge computing: Vision and challenges.

IEEE Internet of Things Journal, 3(5):637–646, 2016.

[29] A. Sironi. TinyML talks: Machine learning for event cameras. tinyML, Oct 2021.
[30] S. Soro. TinyML for ubiquitous edge AI, 2021.
[31] V. Sze, Y.-H. Chen, J. Emer, A. Suleiman, and Z. Zhang. Hardware for machine
learning: Challenges and opportunities. 2017 IEEE Custom Integrated Circuits
Conference (CICC), Apr 2017.

[32] P. Warden and D. Situnayake. TinyML: Machine Learning with TensorFlow Lite on
Arduino and ultra-low power microcontrollers. OReilly Media Inc., 2020.
[33] D. Xu, T. Li, Y. Li, X. Su, S. Tarkoma, T. Jiang, J. Crowcroft, and P. Hui. Edge

intelligence: Architectures, challenges, and applications, 2020.

