The Unnecessity of Assuming Statistically
Independent Tests in Bayesian Software Reliability
Assessments

Kizito Salako
Centre for Software Reliability
City, University of London
Northampton sq. EC1V 0HB, U.K.
k.o.salako@city.ac.uk

Xingyu Zhao
Department of Computer Science
University of Liverpool
Ashton Street L69 3BX, U.K.
xingyu.zhao@liverpool.ac.uk

Abstract—When assessing a software-based system, the results
of statistical inference on operational testing data can provide
strong support for software reliability claims. For inference, this
data (i.e. software successes and failures) is often assumed to
arise in an independent, identically distributed (i.i.d.) manner.
In this paper we show how conservative Bayesian approaches
make this assumption unnecessary, by incorporating one’s doubts
about the assumption into the assessment. We derive conservative
conﬁdence bounds on a system’s probability of failure on demand
(pfd), when operational testing reveals no failures. The generality
and utility of the conﬁdence bounds are demonstrated in the
assessment of a nuclear power-plant safety-protection system,
under varying levels of skepticism about the i.i.d. assumption.

Index Terms—conservative Bayesian inference, software reli-
ability assessment, dependability claims, independent software
failures, statistical testing, operational testing

I. INTRODUCTION

Consider a software-based on-demand system subjected
to black-box operational testing. During testing, an assessor
the software – as it
observes the system – in particular,
responds to demands in a statistically representative sequence
of demands. By noting those demands the software correctly
responds to, and those it fails on, the assessor intends to
gain enough conﬁdence to support claims of the system being
sufﬁciently reliable1. For example, conﬁdence in the system’s
unknown probability of failure on demand (pfd) – X say –
being sufﬁciently small. A Bayesian approach to gaining such
conﬁdence requires 2 things of our assessor: i) prior to opera-
tional testing, the assessor must scrutinise all evidence related
to the system’s operational readiness. Via such probing and the
assessor’s domain expertise, the assessor forms beliefs about
which ranges of pfd values are most likely, and which ranges
are less so; ii) the assessor must postulate a statistical model
– in essence, a family of stochastic processes, any of which
could characterise the occurrence of the system’s successes
and failures during operation. These processes should exhibit
statistical properties consistent with the assessor’s beliefs.

1This work focuses on software reliability; i.e. only software failures are

considered to cause system failure.

For the statistical model it’s often assumed that software
failures and successes are the outcomes of independent, identi-
cally distributed (i.i.d.) Bernoulli trials. This is mathematically
convenient and guarantees the strong law of large numbers
– i.e., operational testing statistics converge almost surely to
dependability measures of interest (e.g. pfd). The i.i.d. assump-
tion can also be reasonable on practical grounds. A typical
justiﬁcation is when demands are rare, and the states/properties
of the software and its operational environment are effectively
“reset” inbetween these rare demand occurrences. Neverthe-
less, we must point out that any statistical model used in
reliability assessment – including one reliant on the i.i.d.
assumption – is necessarily a postulate. One does not (cannot?)
know with complete certainty that such model assumptions
are valid in practice. The skeptical assessor allows for the
possibility that the i.i.d. assumption does not hold, even if this
is unlikely. By incorporating their skepticism into the assess-
ment, our assessor can investigate whether their doubts have a
signiﬁcant impact on their conﬁdence in the system. In the best
case, their conﬁdence is insensitive to signiﬁcant departures
from the i.i.d. assumption. But in the worst case, ignoring the
slightest failure correlations could lead to seriously misplaced
conﬁdence and dangerously optimistic reliability claims.

This work presents statistical tools to aid the skeptical asses-
sor – i.e., a conservative Bayesian inference (CBI) approach
to reliability assessment that incorporates skepticism about the
i.i.d. assumption. The paper’s research contributions are:

1) formalising informal notions of “doubting” the i.i.d. as-
sumption, and providing statistical methods for including
such doubts in reliability assessments (see section IV);
2) showing how the i.i.d. assumption can lead to extremely
optimistic assessments. Sensitivity analysis reveals model
parameter ranges for which this happens (see section V);
3) novel CBI methods that account for correlated operational
testing outcomes (sections III, IV and appendices B, C);
4) illustrating these CBI approaches in the assessment of a
nuclear power-plant safety protection system (section V);
5) explicit solutions and algorithms for computing conser-

2
2
0
2

l
u
J

1
3

]
E
S
.
s
c
[

1
v
2
6
4
0
0
.
8
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
vative posterior conﬁdence bounds on a system’s pfd (see
section IV and appendices B, D);

This paper is outlined as follows. Section II gives critical
context. Section III introduces a statistical model for (possibly)
dependent system failures and successes. A CBI theorem for
conservative conﬁdence bounds on pfd is stated in section IV,
applied under various scenarios in section V, and discussed in
section VI to conclude the paper.

II. RELATED WORK

Statistical models with the i.i.d. assumption have a long
history of being used in software reliability assessment. Thayer
et al.’s [1] model was one of the earliest, used in early works
on random testing [2]. The independence assumption has been
recommended by regulatory bodies to be used in reliability
assessments under appropriate circumstances [3].

But there are reasons to doubt the assumption. For in-
stance, the possibility of “failure clustering”; where a system
receives sequences of inputs from its operational environment
that cause the system to fail. These inputs form trajectories
through a system’s failure region – the subset of inputs
that cause system failure. Failure regions were discovered to
have topologically interesting properties that allow for failure
clustering [4], [5]. These observations informed subsequent
approaches for assessing systems employing recovery block
fault-tolerance [6], [7] and approaches for random testing [8].
Various statistical models that weaken the i.i.d. assumption
have been developed. These include Chen and Mill’s binary
Markov chain [9], Goseva-Popstojanova and Trivedi’s Markov
renewal process [10] and Bondavalli et al.’s Markov model
with benign-failure states [11]. Classical statistical inference
produces “point estimates” for these models’ parameters,
using only data from operational testing. Such estimates do
not reﬂect an assessor’s uncertainty about whether the i.i.d.
assumption holds or not. Indeed, ﬁtted parameter values imply
that the models either exhibit dependence, or they don’t – there
is no room for uncertainty here. In contrast, Bayesian inference
– our preferred approach – allows for such uncertainty. In this
paper, within a Bayesian framework, we model the system’s
failure process as a Markov chain introduced by Klotz [12].
The Klotz model predates, and is consistent with, the models
in [9], [10]. It is also no more complex than these models.

Another advantage of Bayesian approaches is the assessor’s
beliefs (about the unknown pfd) are explicitly accounted for
in the assessment. Beliefs that are justiﬁed by various forms
of reliability evidence. And, although models of dependent
system failures/successes have been developed, none of the
assessment approaches using these models provide demonstra-
bly conservative statistical support for the skeptical assessor.
Particularly when such support
is justiﬁed by operational
testing and other forms of reliability evidence. To the best
of our knowledge, ours is the ﬁrst approach to guarantee
conservatism in the face of i.i.d. uncertainty.

Bayesian methods have been applied in various assessment
scenarios, e.g., [13], [14] involve hierarchical models, while
[15]–[18] all use families of Beta prior distributions. More

recently, conservative Bayesian inference (CBI) methods have
been developed to: i) address the usual challenge of eliciting
a suitable prior distribution from an assessor – a prior that
captures all, and only all, of an assessor’s beliefs/views about
the pfd; ii) give support for the most pessimistic reliability
claims allowed by the available reliability evidence. Thereby,
CBI prevents dangerously optimistic claims.

Bishop et al. [19] introduced CBI by illustrating its use
in assessing safety-critical systems. Povyakalo et al. [20] use
CBI to obtain the smallest probability of the system surviving
future demands, and Salako [21] applies CBI to assessing
binary classiﬁers. While Flynn et al. [22] apply CBI to the
problem of assessing autonomous vehicle safety. Littlewood
et al. [23] show how CBI supports dependability claims when
evidence suggests a new system is an “improvement” over an
older system it replaces. Salako et al. [24] extend this work,
by considering more general “improvement arguments” for a
wider range of assessment scenarios. Our application of CBI
differs from these in 2 important ways: it allows for dependent
testing outcomes during operational testing, and it incorporates
skepticism of the i.i.d. assumption into assessments.

CBI methods are closely related to robust Bayesian analysis
[25]–[28], which studies how the results of Bayesian inference
are impacted by uncertainty about the inputs to inference
– inputs such as the prior distribution and the statistical
model. In particular, Lavine [27] outlines methods that reveal
how uncertainty about the statistical model (speciﬁcally, about
the so-called sampling distribution) impacts inference. This
uncertainty is represented by a suitably general joint prior
distribution over the family of stochastic processes deﬁned
by the statistical model. Subject to constraints on this prior,
algorithms give the largest and smallest values for posterior
measures of interest – such as posterior expectations. Our
results are less abstract and more directly applicable in reliabil-
ity assessments than those of Lavine. Also, Lavine considers
likelihoods consisting of products of the same functional form,
while we do not (in order to weaken the i.i.d. assumption).

Draper [29] also tackles the problem of statistical model un-
certainty in Bayesian inference, but offers an alternative solu-
tion. If one is uncertain about a model’s assumptions – specif-
ically, assumptions that constrain the structural/functional
forms of the related family of stochastic processes – one could
replace the model with an expanded model. This expanded
model should encompass all of the stochastic processes deﬁned
under the original model, as well as other stochastic processes
that do not satisfy the assumptions in question. A suitable prior
distribution over this expanded model will have to be deﬁned.
Draper argues for this Bayesian hierarchical model as a way
of addressing model uncertainty. We concur, and further argue
for the inference to be conservative; our results are guaranteed
to be conservative, while Draper’s aren’t.

For uncertainty about a ﬁnite number of alternative statisti-
cal models, Pericchi et al. [30] use discrete prior distributions
over these alternatives. In principle, this is a hierarchical model
akin to Draper’s approach, but in more abstract terms within
the robust Bayesian analysis framework. Our results can be

viewed as concrete solutions of a hybrid of Pericchi et al.’s
abstract formulation and Draper’s model expansions, within a
reliability assessment context.

III. A STATISTICAL MODEL OF TESTING OUTCOMES

The Klotz model [12] is a simple stationary random process
consisting of possibly dependent Bernoulli trials. As a model
of a system’s failure process it generalises the i.i.d. Bernoulli
process used in reliability assessments. During operational
testing, a random sequence of demands is submitted to the
system. On each demand, the system could either successfully
handle the demand or fail. This success or failure behaviour is
modelled as the outcomes of a sequence of random variables
T1, . . . , Tn, each taking the values 0 or 1 – corresponding to
success or failure, respectively2.

The Klotz model is characterised by a “frequency” parame-
ter x and a “dependence” parameter λ. Here, x is the system’s
pfd while λ is the probability that a failure is followed by
another failure. So, P [Ti = 1] = x and P [Ti = 1 | Ti−1 =
1] = λ for i = 2, . . . , n. By requiring the process be 1st-order
stationary, we have (see appendix A)

P [Ti = 1 | Ti−1 = 0] =

(1 − λ)x
1 − x

,

i = 2, . . . , n

which yields the Markov model shown in Fig. 1.

Fig. 1: The Klotz model with dependent Bernoulli trials [12].

The transition probabilities of the Klotz model in Fig. 1 lie

between zero and one, implying the constraints:

0 (cid:54) x (cid:54) 1, max {0, (2x − 1)/x} (cid:54) λ (cid:54) 1

(1)

Suppose the system succeeds on all n demands during
operational testing. For given (x, λ), the Klotz likelihood gives
the probability of observing this sequence of successes:

often – i.e. negative dependence. In the extreme, x = 1
2−λ
and we have L( 1

2−λ , λ; n) = 0.

Both x and λ are unknown to the assessor3 – this is captured
by a prior distribution of (X, Λ). The assessor’s posterior
conﬁdence in the pfd X being no larger than a bound b is:

P (X (cid:54) b | n demands without failure)

=

=

P (X (cid:54) b , n demands without failure)
P (n demands without failure)

E[L(X, Λ; n)1X(cid:54)b]
E[L(X, Λ; n)]

(3)

where 1S is an indicator function – it equals 1 for S true, and
0 for S false. Next, via CBI (i.e. constrained nonlinear opti-
misation of (3)), we derive conservative posterior conﬁdence.

IV. CONSERVATIVE POSTERIOR CONFIDENCE BOUNDS
In this section we present conservative posterior conﬁdence
bounds on pfd for the skeptical assessor. We begin by for-
malising the assessor’s beliefs as a collection of 4 constraints
called “prior knowledge”. These PKs only weakly specify the
joint prior distribution of (X, Λ). Firstly, the assessor’s prior
distribution of X is continuous.

Prior Knowledge 1 (continuous prior distribution of X). A
density function f (x) gives the assessor’s prior conﬁdence in
pfd bound u – i.e. P (X (cid:54) u) = (cid:82) u
0 f (x) dx – for all u ∈ [0, 1].
the assessor does not rule out negatively or

Secondly,

positively correlated testing outcomes (see Fig. 2a).

Prior Knowledge 2 (conﬁdence in negative correlation).
φ1 × 100% conﬁdence that the outcomes of successive tests
are negatively correlated, i.e. P (Λ < X) = φ1.

Prior Knowledge 3 (conﬁdence in positive correlation).
φ2 × 100% conﬁdence that the outcomes of successive tests
are positively correlated, i.e. P (Λ > X) = φ2.

Thirdly, the assessor is relatively conﬁdent that the i.i.d.
assumption holds, and bound b is satisﬁed, but not so conﬁdent
as to make testing unnecessary. A straightforward extension of
the theorem presented here accounts for less conﬁdence.

Prior Knowledge 4 (conﬁdence in bound and independence).
For a target system pfd b, φ1 (cid:54) P (X (cid:54) b) (cid:54) 1 − φ2

An assessor with these 4 beliefs has conservative posterior

conﬁdence bounds given by this theorem (see appendix B):

L(x, λ; n) = (1 − x)

1 −

(cid:18)

(cid:19)n−1

(1 − λ)x
1 − x

(2)

Theorem. Let D be the set of all prior distributions over R
and assume 0 < b < 1/2. The optimisation problem

Different values of (x, λ) can alter the dependence structure
and functional form of the Klotz likelihood: i) x = λ is
the special case of independent failures and successes, with
L(x, x; n) = (1 − x)n; ii) When λ > x, failures and successes
tend to cluster during testing – i.e. positive dependence. In the
extreme, λ = 1 and we have L(x, 1; n) = (1 − x); iii) Lastly,
when λ < x, failures and successes tend to alternate more

2Upper-case letters for random variables, lower-case for their realisations.

P ( X (cid:54) b | n demands without failure)

inf
D
P K1, P K2, P K3, P K4

s.t.

has a solution given by the prior illustrated in Fig. 2b, since
P ( X (cid:54) b | n demands without failure) from such a prior is
the inﬁmum. The inﬁmum takes the form 1

1+Q , where Q is:

3By postulate, knowing x and λ allows the assessor to completely charac-

terise the system’s failure process.

(cid:82) 1
b
(cid:16)

(cid:0)(1 − x)n1(b,c∗
(1 − x)n1(0,c1

(cid:82) b
0

1 )∪(c∗

2 ,1) + (1 − x)1(c∗
1 ,c∗
2 )
∗,b) + (1−2x)n−1
(1−x)n−2 1(c1

∗,c2
∗)

∗)∪(c2

(cid:1) f (x) dx
(cid:17)

f (x) dx

and the unique pfd values c1

∗, c2

∗, c∗

1, c∗

2 solve

(4)

s.t.

arg min
0(cid:54)r<s(cid:54)b

| gl(r) − gl(s) |, arg min
b(cid:54)v<w(cid:54)1

| gu(v) − gu(w) |

gl(0) (cid:54) gl(r), gl(b) (cid:54) gl(s) ,
gu(b) (cid:54) gu(v), gu(1) (cid:54) gu(w) ,
r f (x) dx = φ1 , (cid:82) w
(cid:82) s

v f (x) dx = φ2 ,

0 (cid:54) r < s (cid:54) b (cid:54) v < w (cid:54) 1

for gl : [0, 1/2] → [0, 1] and gu : [0, 1] → [0, 1] deﬁned as

gl(x) = (L(x, x; n) − L(x, 0; n))10(cid:54)x(cid:54) 1
gu(x) = (L(x, 1; n) − L(x, x; n))10(cid:54)x(cid:54)1

2

(5)

In practice, numerical estimates for c1

∗, c2

∗, c∗

1, c∗

2 may be

computed using algorithms such as that in appendix D.

Corollary. Let Q be given by (4) in the theorem, when φ1 =
φ2 = 0. Then the inﬁmum is given by traditional Bayesian
inference, using the prior density f (x). That is,

P ( X (cid:54) b | n demands without failure)

inf
D

=

(cid:82) b
0 L(x, x; n)f (x) dx
(cid:82) 1
0 L(x, x; n)f (x) dx
This is a general property of CBI methods: if an assessor
can specify a prior distribution fully (instead of only partially
via PKs), CBI simpliﬁes to traditional Bayesian inference.

V. RESULTS

The theorem gives conservative posterior conﬁdence in a pfd
bound under various scenarios. A bound such as b = 10−4;
a target pfd used in the assessment of the Sizewell-B nuclear
power plant safety protection system in the United Kingdom
[31], [32]. To gain 99% conﬁdence in this bound – using
inference
the i.i.d. assumption under a classical statistical
approach – requires between 104 and 105 test demands [32],
[33]. We will use similar orders of magnitude of test demands
to illustrate the theorem’s use. The analyses in this section
shows how: i) conﬁdence based on i.i.d. assumptions can
be very optimistic as failure-free tests accumulate; ii) some
forms of doubt about the i.i.d. assumption signiﬁcantly impact
conﬁdence, while other forms do not; iii) surprisingly, failure-
free testing can eventually undermine conﬁdence in the system
satisfying the bound.

The prior density f (x) can be from any family of continuous
distributions over the interval [0, 1]. Beta priors are commonly
used in practice [3], [15], [17]. We consider 3 alternative
f (x); the Beta distributions in Fig. 3a with parameters and
properties summarised in Table. I. These represent the beliefs
of 3 assessors that (prior to testing) are increasingly conﬁdent
in the system satisfying the bound.

(a)

(b)

TABLE I: A summary of the Beta prior distributions of pfd

Fig. 2: a) The support R of the Klotz likelihood and subsets of R related
to PKs 2 and 3. The support of any prior distribution of (X, Λ) must lie
in R; b) A prior distribution that gives the inﬁmum in the theorem. The
distribution is depicted “from above”, looking down on its domain R. Here,
pfds c1
2 all satisfy the theorem’s constraints. This prior assigns
non-zero probability density only to the indicated black line segments in R.
The rest of R is assigned zero probability (see appendix B).

∗, c∗

∗, c2

1, c∗

The CBI prior in Fig. 2b assigns probability density only to
the indicated thick black line segments. The rest of the prior’s
domain R is assigned zero probability. For example, prior to
testing, the conservative assessor expects to observe negatively
dependent, or positively dependent, test outcomes with prob-
abilities φ1 = P (c1
f (x) dx and
∗
φ2 = P (c∗
1

∗
c1
∗
f (x) dx, respectively.

(cid:54) X (cid:54) c2
2, Λ = 1) = (cid:82) c∗

∗, Λ = 0) = (cid:82) c2

(cid:54) X (cid:54) c∗

2
c∗
1

If the assessor has no doubts about the i.i.d. assumption,

this CBI result is given by traditional Bayesian inference.

α

2
1
0.1

β

E[X] = α
α+β

P (X (cid:54) 10−4)

20000
10000
1000

0.0001
0.0001
0.0001

0.6
0.63
0.83

The assessors are a little skeptical of the tests being i.i.d.
(e.g. φ1 = φ2 = 0.05), Fig. 3b shows the posterior conﬁdence
resulting from the Beta priors as operational testing evidence
mounts. For each prior, the posterior conﬁdence under an i.i.d.
assumption is plotted against the posterior conﬁdence for our
skeptic. In all cases, the conﬁdence from assuming indepen-
dence is initially comparable to conservative conﬁdence – the
relevant pair of curves for each prior almost overlap initially.
However, as more failure-free testing is observed – i.e. as
n grows – “i.i.d.-based” conﬁdence grows and tends towards
certainty. While conservative conﬁdence grows more slowly,
reaches a maximum, and then tends towards zero. Appendix
C proves this zero limiting behaviour will occur whenever an

(a) Beta prior distributions of pfd

(b) φ1 = 0.05, φ2 = 0.05, b = 0.0001

(c) φ2 = 0.05, b = 0.0001, Beta(1, 10000)

(d) φ2 = 0.05, b = 0.0001, Beta(2, 20000)

(e) φ1 = 0.05, b = 0.0001, Beta(1, 10000)

(f) φ1 = 0.05, b = 0.0001, Beta(2, 20000)

Fig. 3: Sensitivity analysis showing which forms of PK have the biggest impact on conservative posterior conﬁdence.

assessor allows for the possibility of positively correlated tests
(i.e. φ2 > 0). In the limit of large n, “i.i.d.-based” conﬁdence
can be the most optimistic conﬁdence can be, while still
remaining consistent with an assessor’s informed views/beliefs
about the unknown pfd.

If the evidence available to an assessor before testing
justiﬁes being very conﬁdent in the bound, then the initial
closeness between the “i.i.d.-based” posterior conﬁdence and
the conﬁdence given by CBI can continue for longer before
ultimately diverging. Indeed, in Fig. 3b the pair of curves for
the Beta(0.1,1000) prior – i.e. for the very conﬁdent assessor –
stay closer together for longer, compared to the curves for the
least conﬁdent assessor with prior Beta(2,20000). The greater
the prior conﬁdence in the bound, the greater the posterior
conﬁdence when testing begins (i.e. small n).

The nature of an assessor’s skepticism determines whether
their conservative posterior conﬁdence ultimately grows or
shrinks during operational testing. At one extreme, some forms
of doubt have no noticeable impact on conﬁdence when no

failures are observed during testing. The possibility (however
likely) of negatively correlated tests has no apparent effect
on conservative conﬁdence. For example, an assessor might
intentionally ”stress” the software during testing, by randomly
including a disproportionate number of test demands that are
thought will likely cause the software’s failure. If stressful
demands are adequately interspersed with signiﬁcantly less
stressful ones, one might expect the testing outcomes (i.e.
the software’s successes/failures) to exhibit some negative
dependence (i.e. a non-zero φ1) – so a failure is quickly
followed by a success, followed by another failure relatively
soon afterwards, and so on. However, when no failures are
seen during testing, Fig.s 3c and 3d show that the “rise and
fall” of CBI conﬁdence in Fig. 3b is completely unaffected by
varying non-zero φ1 – i.e. by varying one’s prior conﬁdence
in negative dependence.

This is unsurprising since, the more successes are observed,
the less likely these could be arising from a system undergoing
negatively dependent tests.

At the other extreme are positively correlated tests. Fig.s 3e,
3f both show that the smaller φ2 is, the closer conservative
conﬁdence gets to the conﬁdence under the i.i.d. assumption.
Indeed, when φ2 is zero, conservative conﬁdence grows to
certainty as the number of successes grows (see appendix C).
While the larger φ2 is, the more conservative the conﬁdence
becomes. Here, conﬁdence in positive correlations (i.e. large
φ2) may be due to pessimistic reasons for the failure-free tests
– i.e. “success clustering” can occur even if the software is
unreliable. The tests could be unrepresentatively “easy” for the
software to correctly respond to, or the test oracle is incorrect
so failures aren’t detected [34], [35].

VI. DISCUSSION AND FUTURE WORK

Software reliability assessments should be conservative: to
wit, only when test results stand up to the most critical scrutiny
can conﬁdence be justiﬁably placed in the system satisfying a
pfd bound. Conservative assessments require a skeptical asses-
sor. In Bayesian terms, our assessor holds conservative beliefs
about what the evidence implies for a system’s reliability, and
about the validity of statistical modelling assumptions.

If the assessor begins operational testing with the PK beliefs
of section IV – i.e. beliefs that only partially specify a joint
prior distribution of (X, Λ) – then the CBI theorem identiﬁes
a joint prior that is consistent with these beliefs, is unique up
to zero probability events, and that gives the smallest posterior
conﬁdence in the bound. This joint prior encodes conservative
beliefs. In particular, the pfds c1
2 indicate where
doubts in the i.i.d. assumption should be placed (i.e. locations
in region R) for conservative posterior conﬁdence.

1, c∗

∗, c∗

∗, c2

∗, 0) to (c2

1, 1) to (c∗

In Fig. 2b the R locations from (c1

∗, 0) along the
λ = 0 edge represent statistical dependence that is unlikely
to produce failure-free testing if
the unknown pfd actually
satisﬁes the bound. And if the pfd does not satisfy the bound,
the locations from (c∗
2, 1) along λ = 1 represent
dependence likely to produce failure-free testing. Note that
the assessor has been unable to rule out these extreme beliefs
prior to testing, since these beliefs are consistent with the PKs.
These beliefs depend on the number n of required failure-
the “c”s become smaller if n becomes bigger.
free tests;
Because, the “c”s are deﬁned with respect to the stationary
points of the theorem’s “g” functions – themselves dependent
on n. Fig. 4a plots how these stationary points tend toward
zero as n increases. Fig. 4b shows the consequence of this –
∗ decreases towards zero and c2
c1
∗ decreases towards a non-zero
value dependent on f (x). While Fig. 4c tells a similar story
– c∗
2 decreases
towards a non-zero value dependent on f (x).

1 decreases towards the bound 10−4 while c∗

Our presented method illustrates a general,

incremental
approach to dealing with doubts about any statistical model
assumptions. A demonstrably conservative form of Draper’s
initial ideas [29]. For a model property that’s in doubt, one
chooses a slightly more general form of the model (that
has the original model as a special case) for inference. The
slight generalisation keeps models from getting unnecessarily
complex. It ensures model extensions are applicable in all

scenarios covered by the previous model. It also minimizes
having to elicit increasingly complex prior distributions.

This incremental approach is a “win-win”. If the i.i.d.
assumption is not
too optimistic, “i.i.d.-based” conﬁdence
doesn’t depart signiﬁcantly from conservative conﬁdence. If
the i.i.d. assumption is too optimistic, sensitivity analysis using
the CBI theorem can reveal this – in such circumstances,
caution is warranted when relying on “i.i.d.-based” reliability
claims. Moreover, if shortcomings of the Klotz model make
an assessor skeptical, a slightly more general model could be
considered that has the Klotz model as a special case.

Let’s highlight some Klotz model shortcomings. It doesn’t
distinguish between different success/failure types. Possible
extensions in future work might consider the models of [11],
[36], [37] with CBI. These models account for the cumulative
impact of benign failures on system dependability. The Klotz
model relies on a single λ parameter to capture all forms
of positive (or negative) correlation. In practice however, the
frequencies of apparently correlated events typically exhibit
to successes (i.e.
asymmetries – so failures often transit
relatively quick system recovery) but successes rarely transit
to failures. The Klotz model is also unable to express non-
stationary dependence, such as may be due to system upgrades,
or the ageing of physical components in the system. The model
can’t capture dependence across time either, such as periodic
correlations. For example, the system being more prone to
failures when consumer demand is highest (e.g. during ofﬁce
hours) or when operating conditions are stressful more often
(e.g. during times of the year when unfavourable weather is
more likely). CBI with model extensions that exhibit time-
dependent correlation are worth exploring in future work.

On the use of pfds we make the following comment.
When the failure process is stationary, pfds make sense. The
probability of the system failing on the n-th demand is the
same for all n. But for time-dependent failure probabilities,
there are more suitable dependability measures – such as the
probability of future failure-free operation. Strigini [37] makes
a related point in a classical inference context. Even in the
present context of posterior conﬁdence bounds on pfd, it’s
worth investigating whether other dependability measures are
more (or less) robust to i.i.d. assumption doubts.

We have also illustrated how any Bayesian reliability assess-
ment using a continuous prior, f (x), can conservatively incor-
porate doubts about “i.i.d.”. However, when eliciting an f (x)
proves too challenging, future work could extend the theorem
to account for only a partially speciﬁed f (x). In general, the
“elicitation challenge” remains an open problem for Bayesian
approaches. In light of this, best practice approaches should be
followed in eliciting the PKs [38], [39]. While the sensitivity
analysis illustrated in section V is crucial and practical, for
checking the robustness of the conservative conﬁdence bounds
to changes in the PKs.

This work has not considered model selection or validation.
One might envisage applying CBI to conservatively gain conﬁ-
dence in the i.i.d. assumption. Or using Bayes factors and CBI
to conservatively determine which modelling assumptions lead

(a) stationary points for gl and gu

(b) φ1 = 0.05, φ2 = 0.05, b = 0.0001

(c) φ1 = 0.05, φ2 = 0.05, b = 0.0001

Fig. 4: The stationary points of gl, gu and the pfds c1

∗, c2

∗, c∗

1, c∗

2 are all monotonically decreasing functions of n.

to more trustworthy predictions about future system reliability.
The theorem could be extended to account for failures dur-
ing testing, e.g. when assessing machine learning applications.
In future work, the presented methods may be extended to
support conservative claims about software modules in a fault-
tolerant conﬁguration (e.g. extending Singh et al. [16]).

APPENDIX A
TRANSITION PROBABILITIES IN THE KLOTZ MODEL
1st-order stationarity requires that the probability of being
in a given state after n trials is the same for all n. In particular,
the probability of being in a successful state after two trials
is the same as the probability after one trial, i.e. 1 − x. So,
upon writing the shorthand p = P [T2 = 0 | T1 = 0], we have
1 − x = x(1 − λ) + (1 − x)p. Consequently, by solving for
p, we ﬁnd P [T2 = 0 | T1 = 0] = p = 1 − (1−λ)x
and
1−x
P [T2 = 1 | T1 = 0] = 1 − p = (1−λ)x
1−x .

APPENDIX B
PROOF OF THE THEOREM
Proof. Choose any F ∈ D that satisﬁes the constraints of the
optimisation and denote the Klotz likelihood (2) as L. The
objective function in the theorem, computed using F , is

(cid:82)

{x(cid:54)b}∩R L dF
(cid:82)
R L dF

=

1

1 +

(cid:82)

(cid:82)

{x>b}∩R L dF
{x(cid:54)b}∩R L dF

Consequently, we focus on the equivalent optimisation

(cid:82)
{x>b}∩R L dF
(cid:82)
{x(cid:54)b}∩R L dF

sup
D

(6)

subject to the same constraints.

From F , one can construct a sequence of priors {F ∗
k }
(for k = 1, 2, . . .) that: i) all give larger values than F for
the objective function in (6); and ii) give objective function
values that converge to the objective function value given by
some F ∗ ∈ D. The construction is as follows. Consider the

sequence {Pk} of partitions of the interval [0, 1], deﬁned by
Pk = {[0, 1/2k), [1/2k, 2/2k), . . . , [1 − 1/2k, 1]}. Each partition
induces a partition of R into vertical strips, as illustrated in
Fig. 5a. Within the ith strip, denote the region above the
diagonal as ria, the region below the diagonal as rib, and
the diagonal segment within the strip as rid. Let i∗ denote the
unique index for the strip containing the vertical line x = b.
Then, for each F , partition Pk allows the objective function
in (6) to be rewritten,

(cid:80)
i∗<i(cid:54)2k
(cid:82)
(cid:80)
1(cid:54)i<i∗

(cid:82)
ria∪rib∪rid

L dF + (cid:82)

{x∈(b,i∗/2k)}∩R L dF

ria∪rib∪rid

L dF + (cid:82)

{x∈[(i∗ − 1)/2k,b]}∩R L dF

(7)

L is continuous and bounded over R. So we may bound (7)
from above by reallocating the probability mass that F assigns
within each region/diagonal segment in each strip. All of the
mass is reassigned to a point in the relevant region/segment,
within 1
2k distance from where L is largest (when x > b) or
smallest (when x (cid:54) b). These locations at which L takes its
largest and smallest values are limit points4 of the respective
regions/diagonal segment within each strip, as illustrated in
Fig. 5b. The reallocations deﬁne a prior F ∗
k with a discrete
marginal distribution of pfd. For each k, F ∗
k satisﬁes
(cid:82)
{x>b}∩R L dF ∗
(cid:82)
{x(cid:54)b}∩R L dF ∗

{x>b}∩R L dF
{x(cid:54)b}∩R L dF

>

(cid:82)

(cid:82)

k

k

By construction, the objective function values from the F ∗
k
converge to the objective function value for some prior F ∗
with continuous marginal density f (x). So, for each F ,
(cid:82)

(cid:82)

{x>b}∩R L dF ∗
{x(cid:54)b}∩R L dF ∗

(cid:82)

(cid:62) inf
k

(cid:82)

{x>b}∩R L dF ∗
{x(cid:54)b}∩R L dF ∗

k

k

(cid:62)

(cid:82)
{x>b}∩R L dF
(cid:82)
{x(cid:54)b}∩R L dF
(8)

4Deﬁnition: for the “open balls” topology associated with the 2D Euclidean
plane, a limit point of a subset of the plane is a point that is arbitrarily well-
approximated by sequences of points within the subset [40], [41].

Since this holds for arbitrary F ∈ D, we have

(cid:82)

L dF ∗

(cid:82)

L dF ∗
k

sup
D∗

{x>b}∩R
(cid:82)

L dF ∗

(cid:62) sup
D

inf
k

{x(cid:54)b}∩R

{x>b}∩R
(cid:82)

{x(cid:54)b}∩R

L dF ∗
k

(cid:82)

L dF

(cid:62) sup
D

{x>b}∩R
(cid:82)

L dF

{x(cid:54)b}∩R

(9)
where D∗ (a subset of D) contains all of the F ∗ priors.
Because D∗ is a subset of D, the following is also true.

(cid:82)

(cid:82)

{x>b}∩R L dF ∗
{x(cid:54)b}∩R L dF ∗

sup
D∗

(cid:54) sup
D

(cid:82)

(cid:82)

{x>b}∩R L dF
{x(cid:54)b}∩R L dF

(10)

Hence, (9) and (10) together imply the three equivalent forms
of the optimisation,

(cid:82)

L dF ∗
L dF ∗ = sup

D

sup
D∗

{x>b}∩R
(cid:82)

{x(cid:54)b}∩R

(cid:82)

L dF ∗
k

inf
k

{x>b}∩R
(cid:82)

{x(cid:54)b}∩R

L dF ∗
k

= sup
D

(cid:82)

L dF

{x>b}∩R
(cid:82)

L dF

{x(cid:54)b}∩R

(11)

Thus, we restrict the optimisation to sequences of priors {F ∗

k }.

(a)

(b)

Fig. 5: (a) Pk partitions R into vertical strips; (b) example support of F ∗
k

For all sufﬁciently large k, the width of the strips can be
made as small as we please. Consequently, by considering
sufﬁciently large k, we may treat the location of masses within
each strip as lying on the same vertical line, with masses
on the diagonal segment or on the λ = 0, 1 borders of R.
Consider then an arbitrary prior F ∗
k (with discrete marginal)
for sufﬁciently large k. The probability masses in a pair of
strips can be reallocated within each strip to construct a new
prior that gives a larger objective function value. One does
this as follows.

Let the functions gl(x) and gu(x) be as deﬁned in (5). De-
note the unique x values at which gl(x) and gu(x) attain their
maxima as xl and xu, respectively. There are 4 possibilities
for reallocating probability masses, based on the relative sizes
of xl, xu and b.

Case 1) xl < b and xu < b: Let F ∗

k be as depicted in
Fig. 5b. Consider two vertical strips, as shown in Fig. 8a. The
strips lie to the left of the vertical line x = xl. For ∆ = 0, let
the probabilities M1 − ∆, M2 + ∆, M3 + ∆ and M4 − ∆ be

(a)

(b)

Fig. 6: (a) An example density f (x); (b) example maxima for gl, gu

initially assigned to the 4 depicted locations (2 in each strip).
These “M ”s are constant and consistent with the constraints
of the problem, and ∆ is a sufﬁciently small amount of
probability mass. The derivative of the objective function with
respect to ∆ exists, because the objective function is a rational
function of ∆. The sign of this derivative is determined by
the function gl(x) in Fig. 6b. That is, the expression for the
derivative is negative iff gl(x2) − gl(x1) > 0 (where, for
x1 < x2 < xl < b, x1 is in the leftmost strip and x2 is
in the other strip). But this is true because gl(x) is unimodal.

(a)

(b)

Fig. 7: Plots of the pair of functions that deﬁne (a) gl, (b) gu

The unimodality of both gl(x) and gu(x) can be seen from
arguments illustrated by Fig.s 7a and 7b. These ﬁgures depict
the pair of functions that deﬁne each “g” function. Each pair
consists of two convex, monotonically decreasing functions
that are equal at x = 0, and have the same tangent slope at a
unique x value in their shared domain. This is the x value at
which the respective “g” function attains its maximum – the
values xl and xu. These values lie in the interval 0 (cid:54) x < 1/2.
Since the objective function’s derivative with respect to ∆ is
negative, ∆ should be made as small as possible, which makes
the objective function as large as possible. Roughly speaking,
mass in the “x1” strip should be placed on the diagonal, while
mass in the “x2” strip should be placed along the λ = 0 line.
Similar arguments justify the mass re-allocations illustrated in
Fig.s 8b and 8c, using gl(x) and gu(x) respectively.

The general rule is, for a pair of strips containing x values
less than b, the strip that is closest to containing xl should have

as much mass as possible below the diagonal, while the other
strip should have as much mass as possible on or above the
diagonal. Similarly, for two strips with x values greater than b,
the strip closest to containing xu should have as much mass
as possible above the diagonal, while the other strip should
have as much mass as possible on or below the diagonal.
This is how, by construction, a discrete prior F ∗

Fig. 5b) is replaced by a more extreme F ∗∗
k
Further reallocation is not possible when c1
∗, c2
have been identiﬁed that solve

k (e.g.
(e.g. Fig. 8d).
1 and c∗
∗, c∗
2

s.t.

arg min
0(cid:54)r<s(cid:54)b

| gl(x) − gl(y) |, arg min
b(cid:54)v<w(cid:54)1

| gu(v) − gu(w) |

(a)

(b)

gl(0) (cid:54) gl(r), gl(b) (cid:54) gl(s) ,
gu(b) (cid:54) gu(v), gu(1) (cid:54) gu(w) ,
k = (cid:82) s
k = (cid:82) w
0 < r < xl < s (cid:54) b , 0 < xu < b (cid:54) v < w (cid:54) 1

(cid:82)
{x∈[r,s]}∩R dF ∗∗
(cid:82)
{x∈[b,w]}∩R dF ∗∗

r f (x) dx = φ1 ,
b f (x) dx = φ2 ,

In particular, since xu < b implies c∗

1 = b, we can restrict
the optimisation to these more extreme priors F ∗∗
k . For such
priors, the objective function (7) is comprised of sums that are
integrals (with respect to F ∗∗

k ) of simple functions. That is:
{x∈(b,2i∗/2k)}∩R L dF ∗∗

k

L dF ∗∗

(cid:82)
ria∪rib∪rid

(cid:80)
i∗<i(cid:54)2k
(cid:82)
(cid:80)
ria∪rib∪rid
1(cid:54)i<i∗
(cid:82)

{x∈(b,c∗

L dF ∗∗

k + (cid:82)
k + (cid:82)
k + (cid:82)

2 )}∩R L dF ∗∗
k + (cid:82)
2 ) + L31xi∈(c∗

∗)}∩R L dF ∗∗
(cid:0)L11xi∈(b,c∗

{x∈(0,c1

{x∈(c∗

k

{x∈[2i∗−1/2k,b]}∩R L dF ∗∗
2 ,1)}∩R L dF ∗∗
∗)∪(c2

∗,b)}∩R L dF ∗∗
(cid:1) (cid:82)
dF ∗∗
k

2 ,1)

k

k

(cid:0)L21xi∈(c1

∗) + L31xi∈(0,c1

∗,c2

∗)∪(c2

∗,b)

ith strip
(cid:1) (cid:82)

dF ∗∗
k

ith strip

(cid:80)
i∗<i(cid:54)2k

(cid:0)L11xi∈(b,c∗

2 ) + L31xi∈(c∗

2 ,1)

i
2k
(cid:82)

(cid:1)

i−1
2k

f (x) dx

(cid:82)

{x∈(c1
∗,c2
(cid:80)
i∗<i(cid:54)2k
(cid:80)
1(cid:54)i(cid:54)i∗

=

=

=

(c)

(d)

Fig. 8: F ∗∗
k

is constructed from F ∗

k by reallocating probability mass

where c1

∗, c2

∗, c∗

1 and c∗

2 have been identiﬁed that solve

s.t.

arg min
0(cid:54)r<s(cid:54)b

| gl(x) − gl(y) |, arg min
b(cid:54)v<w(cid:54)1

| gu(v) − gu(w) |

gl(0) (cid:54) gl(r), gl(b) (cid:54) gl(s) ,
gu(b) (cid:54) gu(v), gu(1) (cid:54) gu(w) ,
k = (cid:82)
k = (cid:82)
0 < r < xl < s (cid:54) b , 0 < b (cid:54) v < xu < w (cid:54) 1

(cid:82)
{x∈[r,s]}∩R dF ∗∗
(cid:82)
{x∈[v,w]}∩R dF ∗∗

[r,s] f (x) dx = φ1 ,
[v,w] f (x) dx = φ2 ,

(cid:80)
1(cid:54)i(cid:54)i∗

(cid:0)L21xi∈(c1

∗) + L31xi∈(0,c1

∗,c2

∗)∪(c2

∗,b)

i
2k
(cid:82)

(cid:1)

i−1
2k

f (x) dx

Case 3) xl > b and xu < b: An analogous argument to

case 1 gives the solution

where xi ∈ [ i−1
L3 := (1 − xi)n

2k , i

2k ), L1 := (1 − xi), L2 := (1−2xi)n−1

(1−xi)n−2 and

By the dominated convergence theorem (see [42]),
the
continuity of L over R implies that the sums converge to
integrals with respect to the density f (x) as k → ∞, so

(cid:0)(1 − x)1(b,c∗
(cid:82) 1
b
(cid:16) (1−2x)n−1
(1−x)n−2 1(c1

(cid:82) b
0

2 ) + (1 − x)n1(c∗
2 ,1)
∗,b) + (1 − x)n1(0,c1
∗)

(cid:1) f (x) dx
(cid:17)

f (x) dx

where c1

∗, c2

∗, c∗

1 and c∗

2 have been identiﬁed that solve

(cid:0)(1 − x)1(b,c∗

(cid:82) 1
b
(cid:16) (1−2x)n−1
(1−x)n−2 1(c1

∗,c2

2 ) + (1 − x)n1(c∗
∗) + (1 − x)n1(0,c1

2 ,1)

(cid:82) b
0

(cid:1) f (x) dx
(cid:17)

∗)∪(c2

∗,b)

f (x) dx

.

s.t.

Case 2) xl < b and xu > b: An analogous argument to

case 1 gives the solution

arg min
0(cid:54)r<s(cid:54)b

| gl(x) − gl(y) |, arg min
b(cid:54)v<w(cid:54)1

| gu(v) − gu(w) |

gl(0) (cid:54) gl(r), gl(b) (cid:54) gl(s) ,
gu(b) (cid:54) gu(v), gu(1) (cid:54) gu(w) ,
k = (cid:82) b
k = (cid:82) w
0 < r < s (cid:54) b < xl , 0 < xu < b (cid:54) v < w (cid:54) 1

(cid:82)
{x∈[r,b]}∩R dF ∗∗
(cid:82)
{x∈[b,w]}∩R dF ∗∗

r f (x) dx = φ1 ,
b f (x) dx = φ2 ,

(cid:0)(1 − x)1(c∗
(cid:82) 1
1 ,c∗
b
(cid:16) (1−2x)n−1
(1−x)n−2 1(c1

∗,c2

2 ) + (1 − x)n1(b,c∗
∗) + (1 − x)n1(0,c1

(cid:82) b
0

1 )∪(c∗

2 ,1)

∗)∪(c2

∗,b)

(cid:1) f (x) dx
(cid:17)

f (x) dx

In particular, because xl > b, xu < b, we have c2

1 = b.
Case 4) xl > b and xu > b: An analogous argument to

∗ = b, c∗

case 1 gives the solution

where c1

∗, c2

∗, c∗

1 and c∗

2 have been identiﬁed that solve

(cid:18)

Ll(x; x1) =

n(x1 − x) + 1 − x1

(1 − x1)n−1

(cid:0)(1 − x)1(c∗
(cid:82) 1
b
(cid:16) (1−2xi)n−1
(cid:82) b
0

(1−xi)n−2 1(c1

2 ) + (1 − x)n1(b,c∗

1 )∪(c∗
∗,b) + (1 − x)n1(0,c1
∗)

1 ,c∗

2 ,1)
(cid:17)

(cid:1) f (x) dx

f (x) dx

s.t.

arg min
0(cid:54)r<s(cid:54)b

| gl(x) − gl(y) |, arg min
b(cid:54)v<w(cid:54)1

| gu(v) − gu(w) |

gl(0) (cid:54) gl(s), gl(b) (cid:54) gl(s) ,
gu(b) (cid:54) gu(v), gu(1) (cid:54) gu(w) ,
k = (cid:82) b
k = (cid:82) w
0 < r < s (cid:54) b < xl , 0 < b (cid:54) v < xu < w (cid:54) 1

(cid:82)
{x∈[r,b]}∩R dF ∗∗
(cid:82)
{x∈[v,w]}∩R dF ∗∗

r f (x) dx = φ1 ,
v f (x) dx = φ2 ,

In particular, because xl > b, we must have c2

∗ = b.

APPENDIX C
ASYMPTOTICS OF POSTERIOR CONFIDENCE BASED ON
FAILURE-FREE OPERATION

Claim. In the theorem,

lim
n→∞

Q =

(cid:26) 0,
∞,

if φ2 = 0
if φ2 > 0

. Since

the assessor’s conservative posterior conﬁdence in the bound
1
1+Q , the assessor either becomes certain that b has been
b is
satisﬁed, or they become certain that it has not.

Proof. We will show that
(cid:0)(1 − x)n1(b,c∗
(1 − x)n1(0,c1

(cid:82) 1
b
(cid:16)

1 )∪(c∗

∗)∪(c2

(cid:82) b
0

(cid:1) f (x) dx
(cid:17)

f (x) dx

2 ,1) + (1 − x)1(c∗
1 ,c∗
2 )
∗,b) + (1−2x)n−1
(1−x)n−2 1(c1
(cid:26) 0,
∞,

∗,c2
∗)
if φ2 = 0
if φ2 > 0

n→∞−−−−→

(12)

1 = c∗

Since φ2 = 0 implies c∗
(cid:82) 1
b (1 − x)nf (x) dx
∗,b) + (1−2x)n−1

(1 − x)n1(0,c1

∗)∪(c2

(cid:82) b
0

(cid:16)

(1−x)n−2 1(c1

∗,c2
∗)

2, the lhs of (12), i.e. Q, becomes

For constants x1 and x2 such that 0 (cid:54) x1 < x2 (cid:54) 1, deﬁne
the straight lines Lu(x; x1, x2) and Ll(x; x1) (see Fig. 9):

Lu(x; x1, x2) = (1 − x1)n

(cid:19)

(cid:18) x2 − x
x2 − x1

(cid:19)

(cid:18) x − x1
x2 − x1

+ (1 − x2)n
(cid:19)

The curve (1−x)n is convex, so Lu lies above the curve when
x1 < x < x2. While Ll is tangent at x = x1, so lies below
the curve. These are Jensen’s inequalities [43]. Therefore:

Ll(E1

∗X; E1

∗X) (cid:54)

∗

(cid:82) c1
0 (1 − x)nf (x) dx
(cid:82) c1
0 f (x) dx
∗

(cid:54) Lu(E1

∗X; 0, c1
∗)

(14)

Ll(E2

∗X; E2

∗X) (cid:54)

(cid:82) b
c2
∗

(1 − x)nf (x) dx
(cid:82) b
c2
∗

f (x) dx

(cid:54) Lu(E2

∗X; c2

∗, b)

(15)

Ll(EX; EX) (cid:54)

(cid:82) 1
b (1 − x)nf (x) dx
(cid:82) 1
b f (x) dx

(cid:54) Lu(EX; b, 1)

(16)

(cid:82) c1
∗
0 xf (x) dx
(cid:82) c1
∗
0 f (x) dx

∗X =

where E1
(cid:82) 1
b xf (x) dx
(cid:82) 1
b f (x) dx
Using the bounds in (14)–(16), we can bound Q (i.e. (13)):

, EX =

∗X =

, E2

f (x) dx

.

xf (x) dx

(cid:82) b
c2
∗
(cid:82) b
c2
∗

0 (cid:54) Q (cid:54)
Lu(EX; b, 1) (cid:82) 1
c1
∗(cid:82)

f (x) dx + Ll(E2

b f (x) dx

Ll(E1

∗X; E1

∗X)

∗[X]; E2

∗[X])

b
(cid:82)

f (x) dx

(cid:17)

f (x) dx

(13)

=

(cid:16) 1−E1
1−b

∗X

0

(cid:16) 1−EX
1−b

(cid:17) (cid:82) 1

(cid:17)n (cid:82) c1

∗

0 f (x) dx +

b f (x) dx
(cid:16) 1−E2
∗X
1−b

c2
∗

(cid:17)n(cid:82) b
c2
∗

f (x) dx

(17)

0

(cid:17)

∗X

∗,c2

(1−2x)n−1
(1−x)n−2 1(c1

We used the fact that (cid:82) b

∗X < b < 1, we have

∗) f (x) dx > 0 to
bound Q from above – by removing this term from Q’s de-
(cid:16) 1−E2
nominator. Since 0 < E2
> 1.
1−b
So, taking limits in (17) as n → ∞, c2
∗ tends to a non-zero
value less than b, (cid:82) b
f (x) dx tends to a non-zero value less
c2
∗
(cid:17)n
than 1, E2
tends to ∞, and lim
n→∞

∗X tends to a non-zero value less than b,

(cid:16) 1−E2
1−b

Q = 0.

1 < c∗

If instead, φ2 > 0, then5 c∗

2 and Q is given by the
quotient on the lhs of (12). Taking limits as n → ∞, the
integrals of (1 − x)n in Q all tend to 0, for all feasible φ2
values, by the monotone convergence theorem (m.c.t.) [42].
(cid:82) b
The m.c.t. also implies lim
∗) f (x) dx =
0
n→∞
Q = ∞.
0 . Therefore,

(1−2x)n−1
(1−x)n−2 1(c1

∗,c2

∗X

lim
n→∞

5In particular, (cid:82) c∗
2
c∗
1

(1 − x)f (x) dx > 0

Fig. 9: Geometric illustration of Jensen’s inequalities

The integrals of (1 − x)n in (13) can be bounded by a
suitable choice of straight lines. We construct these as follows.

APPENDIX D

ALGORITHM FOR NUMERICAL ESTIMATES OF c1
For brevity, we omit the analogous algorithm for c∗

∗, c2
∗
1, c∗
2.

Algorithm Bisection Method based Algorithm for c1

∗, c2
∗

Input: The pfd density f (x), an intermediate function gl(x),
the target pfd bound b, a tolerance (cid:15) and the doubts φ1, φ2.

∗, c2
∗

0 f (u) du > φ1 then
xl = arg max gl(x)
if xl > b then

Output: c1
1: if (cid:82) b
2:
3:
4:
5:
6:

else

∗ = solve((cid:82) b
c1
∗ = b; return c1
c2

∗, c2
∗

x f (u) du = φ1, x ∈ [0, b))

7:

8:

9:
10:
11:
12:
13:
14:

15:
16:
17:

18:

19:
20:
21:

22:
23:
24:

25:

26:
27:

c = solve(gl(x) = gl(b), x ∈ [0, xl))
if (cid:82) b
c f (u) du < φ1 then
∗ = solve((cid:82) b
c1
∗ = b; return c1
c2

x f (u) du = φ1, x ∈ [0, b))

∗, c2
∗
(cid:46) Start of the bisection method

else

c2
∗ = b
tmplb = xl
tmpub = b
tmpφ1 = (cid:82) b
while | tmpφ1 − φ1 |> (cid:15) do
if tmpφ1 > φ1 then
tmpub = c2
∗
∗ = c2
∗+tmplb
c2
2

c f (u) du

else

tmplb = c2
∗
∗ = c2
∗+tmpub
c2
2
end if
∗ = solve(gl(x) = gl(c2
c1
tmpφ1 = (cid:82) c2

f (u) du

∗
c1
∗

∗), x ∈ [0, xl))

(cid:46) End of the bisection method

end while

end if
return c1

∗, c2
∗

end if

28:
29:
30: else
31:
32: end if

(cid:46) This is the case when (cid:82) b

0 f (u) du < φ1

print(“PK4 violated!”)

REFERENCES

[1] R. A. Thayer, M. Lipow, and E. C. Nelson, Software Reliability. North-

Holland, 1978.

[2] J. W. Duran and S. C. Ntafos, “An evaluation of random testing,” IEEE
Transactions on Software Engineering, vol. SE-10, no. 4, pp. 438–444,
1984.

[3] C. Atwood, J. LaChance, H. Martz, D. Anderson, M. Englehardt,
D. Whitehead, and T. Wheeler, “Handbook of parameter estimation for
probabilistic risk assessment,” U.S. Nuclear Regulatory Commission,
Washington, DC, Report NUREG/CR-6823, 2003.

[4] P. E. Ammann and J. C. Knight, “Data diversity: an approach to software
fault tolerance,” IEEE transactions on computers, vol. 37, no. 4, pp.
418–425, 1988.

[5] P. Bishop, “The variation of software survival time for different opera-
tional input proﬁles (or why you can wait a long time for a big bug to
fail),” in FTCS-23 The Twenty-Third International Symposium on Fault-
Tolerant Computing.
IEEE, 1993, pp. 98–107.

[6] A. Csenki, “Reliability analysis of recovery blocks with nested clusters
of failure points,” IEEE transactions on reliability, vol. 42, no. 1, pp.
34–43, 1993.

[7] L. A. Tomek, J. K. Muppala, and K. S. Trivedi, “Modeling correlation in
software recovery blocks,” IEEE Transactions on Software Engineering,
vol. 19, no. 11, pp. 1071–1086, 1993.

[8] R. Huang, W. Sun, Y. Xu, H. Chen, D. Towey, and X. Xia, “A survey on
adaptive random testing,” IEEE Transactions on Software Engineering,
vol. 47, no. 10, pp. 2052–2083, 2021.

[9] S. Chen and S. Mills, “A binary Markov process model for random
testing,” IEEE Transactions on Software Engineering, vol. 22, no. 3,
pp. 218–223, 1996.

[10] K. Goseva-Popstojanova and K. S. Trivedi, “Failure correlation in
software reliability models,” IEEE Transactions on Reliability, vol. 49,
no. 1, pp. 37–48, 2000.

[11] A. Bondavalli, S. Chiaradonna, F. Di Giandomenico, and L. Strigini,
“Dependability models for iterative software considering correlation
between successive inputs,” in Proc. of IEEE Int. Computer Performance
and Dependability Symposium. Erlangen, Germany: IEEE, 1995, pp.
13–21.

[12] J. Klotz, “Statistical Inference in Bernoulli Trials with Dependence,”

The Annals of Statistics, vol. 1, no. 2, pp. 373–379, 1973.

[13] K. P¨orn, “The two-stage Bayesian method used for the T-Book applica-
tion,” Reliability Engineering & System Safety, vol. 51, no. 2, pp. 169
– 179, 1996.

[14] C. Bunea, T. Charitos, R. M. Cooke, and G. Becker, “Two-stage
Bayesian models—application to ZEDB project,” Reliability Engineer-
ing & System Safety, vol. 90, no. 2, pp. 123 – 130, 2005.

[15] K. W. Miller, L. J. Morell, R. E. Noonan, S. K. Park, D. M. Nicol,
B. W. Murrill, and M. Voas, “Estimating the probability of failure when
testing reveals no failures,” IEEE Transactions on Software Engineering,
vol. 18, no. 1, pp. 33–43, 1992.

[16] H. Singh, V. Cortellessa, B. Cukic, E. Gunel, and V. Bharadwaj, “A
bayesian approach to reliability prediction and assessment of compo-
nent based systems,” in Proc. 12th Int. Symp. on Software Reliability
Engineering.
IEEE Computer Society, 2001, pp. 12–21.

[17] B. Littlewood, P. Popov, and L. Strigini, “Assessing the reliability of
diverse fault-tolerant software-based systems,” Safety Science, vol. 40,
no. 9, pp. 781–796, 2002.

[18] P. Popov, “Bayesian reliability assessment of legacy safety-critical
systems upgraded with fault-tolerant off-the-shelf software,” Reliability
engineering & system safety, vol. 117, pp. 98–113, 2013.

[19] P. Bishop, R. Bloomﬁeld, B. Littlewood, A. Povyakalo, and D. Wright,
“Toward a formalism for conservative claims about the dependability of
software-based systems,” IEEE Transactions on Software Engineering,
vol. 37, no. 5, pp. 708–717, 2011.

[20] L. Strigini and A. Povyakalo, “Software fault-freeness and reliability
predictions,” in Computer Safety, Reliability, and Security, ser. LNCS,
vol. 8153. Springer Berlin Heidelberg, 2013, pp. 106–117.

[21] K. Salako, “Loss-size and reliability trade-offs amongst diverse re-
dundant binary classiﬁers,” in Quantitative Evaluation of Systems,
M. Gribaudo, D. N. Jansen, and A. Remke, Eds. Springer International
Publishing, 2020, pp. 96–114.

[22] X. Zhao, V. Robu, D. Flynn, K. Salako, and L. Strigini, “Assessing
the Safety and Reliability of Autonomous Vehicles from Road Testing,”

in the 30th Int. Symp. on Software Reliability Engineering.
Germany: IEEE, 2019, pp. 13–23.

Berlin,

[23] B. Littlewood, K. Salako, L. Strigini, and X. Zhao, “On reliability
assessment when a software-based system is replaced by a thought-
to-be-better one,” Reliability Engineering & System Safety, vol. 197, p.
106752, 2020.

[24] K. Salako, L. Strigini, and X. Zhao, “Conservative Conﬁdence Bounds
in Safety, from Generalised Claims of Improvement & Statistical Evi-
dence,” in 51st Annual IEEE/IFIP Int. Conf. on Dependable Systems and
Networks, ser. DSN’21. Taipei Taiwan: IEEE/IFIP, 2021, pp. 451–462.
[25] J. O. Berger, “An overview of robust Bayesian analysis,” Test, vol. 3,

no. 1, pp. 5–124, 1994.

[26] ——, “Robust Bayesian analysis : Sensitivity to the prior,” journal of

statistical planning and inference, vol. 25, pp. 303–328, 1990.

[27] M. Lavine, “Sensitivity in Bayesian Statistics: The Prior and the Likeli-
hood,” Journal of the American Statistical Association, vol. 86, no. 414,
pp. 396–399, 1991.

[28] J. Berger and E. Moreno, “Bayesian robustness in bidimensional models:
Prior independence,” Journal of statistical planning and inference,
vol. 40, no. 2, pp. 161–176, 1994.

[29] D. Draper, “Assessment and propagation of model uncertainty,” Journal
of the Royal Statistical Society. Series B (Methodological), vol. 57, no. 1,
pp. 45–97, 1995.

[30] L. R. Pericchi and M. E. Perez, “Posterior robustness with more than one
sampling model,” Journal of Statistical Planning and Inference, vol. 40,
no. 2, pp. 279–294, 1994.

[31] D. M. Hunns and N. Wainwright, “Software-based protection for
sizewell b: the regulator’s perspective,” in Int. Conf. on Electrical and
Control Aspects of the Sizewell B Power Station, 1992, pp. 198–203.

[32] NuSAC study group on the safety of operational computer systems, The
Health and safety

use of computers in safety-critical applications.
Commission, London, UK, 1998.

[33] D. L. Parnas, A. J. van Schouwen, and S. P. Kwan, “Evaluation of
safety-critical software,” Commun. ACM, vol. 33, no. 6, p. 636–648,
1990.

[34] B. Littlewood and D. Wright, “The use of multilegged arguments to
increase conﬁdence in safety claims for software-based systems: A study
based on a BBN analysis of an idealized example,” IEEE Transactions
on Software Engineering, vol. 33, no. 5, pp. 347–365, 2007.

[35] E. T. Barr, M. Harman, P. McMinn, M. Shahbaz, and S. Yoo, “The
oracle problem in software testing: A survey,” IEEE Transactions on
Software Engineering, vol. 41, no. 5, pp. 507–525, 2015.

[36] A. Bondavalli, S. Chiaradonna, F. D. Giandomenico, and S. L. Torre,
“Modelling the effects of input correlation in iterative software,” Relia-
bility Engineering & System Safety, vol. 57, no. 3, pp. 189–202, 1997.
[37] L. Strigini, “On testing process control software for reliability assess-
ment: the effects of correlation between successive failures,” Software
Testing, Veriﬁcation and Reliability, vol. 6, no. 1, pp. 33–48, 1996.
[38] PRA Working Group, “A Review of NRC Staff uses of Probabilistic
Risk Assessment,” U. S. Nuclear Regulatory Commission, Tech. Rep.
NUREG-1489, 1994.
[Online]. Available: https://www.nrc.gov/docs/
ML0635/ML063540593.pdf

[39] A. O’Hagan, C. Buck, A. Daneshkhah, J. Eiser, P. Garthwaite, D. Jenkin-
son, J. Oakley, and T. Rakow, Uncertain Judgements: Eliciting Experts’
Probabilities, ser. Statistics in Practice. Wiley, 2006.

[40] W. Rudin, Principles of Mathematical Analysis, 3rd ed., ser. International

series in pure and applied mathematics. McGraw-Hill, 1976.

[41] V. Bryant, Metric Spaces: Iteration and Application.

Cambridge

University Press, 1985.

[42] R. L. Schilling, Measures, Integrals and Martingales.

Cambridge

University Press, 2005.

[43] C. D. Aliprantis and K. C. Border, Inﬁnite dimensional analysis: a

hitchhiker’s guide, 2nd ed. London;Berlin;: Springer, 1999.

