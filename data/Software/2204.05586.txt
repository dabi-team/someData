2
2
0
2

r
p
A
2
1

]
h
p
-
t
n
a
u
q
[

1
v
6
8
5
5
0
.
4
0
2
2
:
v
i
X
r
a

Spinsim: a GPU optimized python package for simulating
spin-half and spin-one quantum systems

Alex Tritt1, Joshua Morris1, 3, Joel Hochstetter1, 4, R. P. Anderson5, 6, James
Saunderson2, and L. D. Turner1

1School of Physics & Astronomy, Monash University, Victoria 3800, Australia.
2Department of Electrical and Computer Systems Engineering, Monash University,
Victoria 3800, Australia.
3Vienna Center for Quantum Science and Technology (VCQ), Faculty of Physics,
University of Vienna, 1010 Vienna, Austria.
4Department of Applied Mathematics and Theoretical Physics, Centre for Mathematical
Sciences, University of Cambridge, Cambridge, UK.
5School of Molecular Sciences, La Trobe University, PO box 199, Bendigo, Victoria
3552, Australia.
6Q-CTRL Pty. Ltd

April 13, 2022

Abstract

The Spinsim python package simulates spin-half and spin-one quantum mechanical systems fol-
lowing a time dependent Shr¨odinger equation. It makes use of numba.cuda, which is an LLVM (Low
Level Virtual Machine) compiler for Nvidia Cuda compatible systems using GPU parallelization.
Along with other optimizations, this allows for speed improvements from 3 to 4 orders of magnitude
while staying just as accurate, compared to industry standard packages. It is available for installation
on PyPI, and the source code is available on github. The initial use-case for the Spinsim will be to
simulate quantum sensing-based ultracold atom experiments for the Monash University School of
Physics & Astronomy spinor Bose-Einstein condensate (spinor BEC) lab, but we anticipate it will be
useful in simulating any range of spin-half or spin-one quantum systems with time dependent Hamil-
tonians that cannot be solved analytically. These appear in the ﬁelds of nuclear magnetic resonance
(NMR), nuclear quadrupole resonance (NQR) and magnetic resonance imaging (MRI) experiments
and quantum sensing, and with the spin-one systems of nitrogen vacancy centres (NVCs), ultracold
atoms, and BECs.

1 Overview

1.1

Introduction

1.1.1 Motivation

Ultracold rubidium atoms have proven their eﬀectiveness in state of the art technologies in quantum
sensing [1], the use of quantum mechanics to make precise measurements of small signals. These atoms
can be modelled as quantum spin systems, which is the quantum mechanical model for objects with
angular momentum. The simplest spin system, spin-half (i.e. spin quantum number of 1
2 , also referred
to as a qubit), is quantized into just two quantum spin levels, and this describes the motion of some
fundamental particles such as electrons. However, systems more practical for sensing, such as ultracold

1

 
 
 
 
 
 
rubidium atoms, are more accurately described as a spin-one quantum system (i.e. spin quantum number
of 1, also referred to as a qutrit), which is quantized into three quantum spin levels.

The design of sensing protocols requires many steps of veriﬁcation, including simulation. This is
especially important, since running real experiments can be expensive and time consuming, so it is
more practical to debug such protocols quickly and cheaply on a computer. In general, any design of
experiments using spin systems could beneﬁt from a fast, accurate method of simulation.

In the past, the spinor Bose Einstein condensate (spinor BEC) lab at Monash University used an in-
house, cython based script, on which this package, Spinsim, is based, and standard diﬀerential equation
solvers (such as Mathematica’s [2] function NDSolve) to solve the Schr¨odinger equation for quantum
sensing spin systems. However, these methods are not completely optimized for our use-case, and therefore
come with some issues.

First, while the execution time for these solvers is acceptable for running a small number of experi-
ments, for certain experiments involving large arrays of independent atom clouds (which require many
thousands of simulations to be run), this time accumulates to the order of many hours, or even multiple
days. A crude method often used to combat this involves approximating spin-one systems as spin-half
for a faster execution time, at the cost of not modelling all eﬀects in the system. With Spinsim, this is
something we would like to avoid.

One option not explored by these generic methods is parallelization, speciﬁcally across graphics pro-
cessing unit (GPU) cores. While there do already exists parallelized algorithms to solve general diﬀerential
equations [3], there are properties speciﬁc to the spin system that allow for much more fast and elegant
parallelization in our use-case. We use these properties (see Section 1.2.4) to write a parallel, GPU based
solver that runs faster than industry standard non-parallel algorithms by up to 4 orders of magnitude.

Second, the Schr¨odinger equation has the geometric property of being norm preserving.

In other
words, the time-evolution operator for a system between two points in time must be unitary. As such,
numerical solutions to the Schr¨odinger equation should also preserve norms. For many numerical methods
like those in the Runge Kutta family, the approximations used are in general not norm preserving, so
the evaluated quantum state may diverge towards an inﬁnite norm, or converge to zero if run for many
iterations. To avoid this, we use a geometric integration technique for our solver (see Section 1.2.2).

Third, our system (and similar spin systems) can be very oscillatory. Standard integration methods
require very small time-steps in order to accurately depict these oscillations. For this reason we use a
fourth order Magnus expansion [4, 5] based solver for our geometric integrator to make larger time-steps
accurate (see Section 1.2.2). We also use a dynamically changing rotating frame to slow down the eﬀective
rotations in the system, and thus reduce the size of integration steps being done, making each step more
accurate (see Section 1.2.5).

1.1.2 Comparison to recent specialized packages

While we benchmark Spinsim only against industry standard integrators, we also note that application
speciﬁc quantum numerical simulator packages are regularly being released. However, none of these
packages are designed speciﬁc to quantum sensing, and so these releases are not suitable for simulations
highly accurate at high time resolutions required in this ﬁeld. See Section 3.1 for use cases where Spinsim
is advantageous.

One application of simulations of spin systems is nuclear magnetic resonance (NMR). In this ﬁeld, the
simulator part of the PULSEE [6] package uses up to the 3rd order Magnus expansion just once to solve
the complete system, rather than using it many times as a time stepping method. Nested integrals of
commutators are numerically evaluated on a CPU using Euler integration. This is likely to be slow (due
to the Euler-integrated nested integrals of commutators) and inaccurate (due to using the expansion over
a large time step), and potentially not even convergent in general (also due to the large time step) for
solving complicated time dependent systems in quantum sensing. With that said, this may not matter
for the kinds of problems this NMR simulation package is looking at. This is an application that would
beneﬁt from Spinsim’s speed.

An application of spin system simulation that would beneﬁt to a lesser extent is quantum optimal
control (QOC). In QOC, researchers look at how to design robust pulse sequences to control spin systems

2

using machine learning techniques. Particularly, this means that simulators used here require automatic
diﬀerentiation [7], which Spinsim does not currently support. A main use of QOC is to design control
sequences in quantum computers. Many of these pulse sequences are trains of hard pulses (which are
physically constant bursts of radiation), which, if using the accuracy reducing rotating wave approxima-
tion (RWA), can have simpliﬁed time evolution operators. This paradigm, used in the recent Qulacs [8],
QOpt [9] and QSim [10], is not suitable for accurately simulating more complicated (especially when
looking from the lab frame of reference) pulse shapes found in quantum sensing. However, all of these
packages do allow for simulating entanglement (important for quantum computing, but not for all sensing
applications), which Spinsim does not and, like Spinsim, all have versions optimized for parallelization
(although QSim does sacriﬁce accuracy here for the sake of speed, by using single-precision ﬂoats). Dal-
gaard and Motzoi [11] have recently proposed Magnus integration techniques for use in QOC, but have
not provided any open source implementation to do so.

1.2 Implementation and architecture

1.2.1 Quantum mechanics background

The Spinsim package solves the time-dependent Schr¨odinger equation

i(cid:126) dψ(t)
dt

= H(t)ψ(t),

(1)

where the quantum state ψ(t) ∈ CN is assumed normalized, and the Hamiltonian H(t) ∈ CN ×N is
Hermitian. Here N is the number of levels in the quantum system. Often we are considering systems
with spin of half (N = 2 case) or one (N = 3). We set (cid:126) = 1, so that the Hamiltonian has physical
dimension of angular frequency.

Rather than parameterizing the problem in terms of the matrix elements of H(t), we consider time

varying real coeﬃcients in a linear combination of a basis of ﬁxed operators,

H(t) =

N 2−1
(cid:88)

j=1

ωj(t)Aj.

(2)

Here we exclude the identity so that the Hamiltonian is traceless, which corresponds to choosing a
physically meaningless energy zero point. It is well known [12, (p74)] that a charged spin-half system
with magnetic moment −→µ , and gyromagnetic ratio γ, in a magnetic ﬁeld

−→
B (t), has Hamiltonian

H(t) = −

−→
B (t) · −→µ

= −γ (Bx(t)Jx + By(t)Jy + Bz(t)Jz)
= ωx(t)Jx + ωy(t)Jy + ωz(t)Jz.

(3)

(4)

(5)

Here Jx, Jy and Jz are spin operators, equal to the Pauli matrices [12, (p169)] halved. Motivated by this,
we deﬁne our basis for the spin-half model with A1 = Jx, A2 = Jy and A3 = Jz. Additionally, because
of the equivalence of the magnetic ﬁeld components Bj(t) and the ωj(t), we henceforth refer to the latter
as ﬁeld functions.

In the spin-one case there is no universal standard basis of operators Aj. Choices include the Gell-
Mann matrices [13], and multiple dipole-quadrupole bases [14, 15]. In general, we can choose any basis
from the 8-dimensional Lie algebra su(3), which is the vector space of traceless Hermitian operators that
can generate transformations (from the corresponding Lie group SU (3)) in the spin-one system. We
focus on a particular subfamily of spin-one systems for which the Hamiltonian is a linear combination of
matrices from a 4-dimensional subspace of su(3), consisting of the spin matrices Jx, Jy and Jz, (labelled
Lx, Ly and Lz in Reference [14]) and a single quadrupole operator Q = diag(1, −2, 1)/3,

H(t) = ωx(t)Jx + ωy(t)Jy + ωz(t)Jz + ωq(t)Q.

(6)

3

Note that Q is proportional to J 2

z (up to a change in energy zero point), and Qzz [14] and Q0 [15]
from alternative quadrupole bases. The Jx, Jy, Jz and Q are the only operators necessary to simulate
many spin-one quantum systems in arbitrary bias ﬁelds, but with single-photon coupling. This includes
quadratic Zeeman splitting described by the Breit-Rabi formula [16], important to experiments in our
lab. The Spinsim simulator can also be conﬁgured to solve a general spin-one system by setting the
Hamiltonian to an arbitrary point in su(3) using the full quadrupole basis, which extends the possible
Hamiltonian to

H(t) =ωx(t)Jx + ωy(t)Jy + ωz(t)Jz + ωq(t)Q

+ ωu1(t)U1 + ωu2(t)U2 + ωv1(t)V1 + ωv2(t)V2.

(7)

Here the additional operators are those deﬁned in [15]. Note that this is included for completeness, but
has not been thoroughly tested, as our lab has no physical context for modelling the U1, U2, V1 and V2
operators.

As well as integrating the Schr¨odinger equation, Spinsim also has the functionality to calculate the
−→
expected spin projection (cid:104)
J (cid:105)(t) of a system from its state. In an experimental setting, one cannot measure
the value of the state itself, and must instead measure observables such as spin projection. If this is done
for an ensemble of systems, the average spin projection over all systems will converge to the expected
value as calculated here. As an alternative to solving the Schr¨odinger equation, if one is only interested
−→
in the dynamics of the expected spin projection, one can instead solve for (cid:104)
J (cid:105)(t) directly using the Bloch
equations [17]. These are three coupled real equations as compared to three coupled complex equations
for the spin-one Schr¨odinger equation. However, the Bloch equations cannot be used to compute ψ(t),
and can only fully model spin-half systems (and spin-one systems approximated to spin-half). Thus, with
Spinsim we choose to solve the full Schr¨odinger equation instead.

1.2.2 Unitary time evolution and the Magnus expansion

Since H(t) is Hermitian, it follows from Equation (1) that (cid:107)ψ(t)(cid:107)2 = (cid:107)ψ(t0)(cid:107)2 for all t. Therefore it is
possible to write ψ(t) in terms of a unitary transformation U(t, t0) of the state ψ(t0), for any time t0,
that is, ψ(t) = U(t, t0)ψ(t0). It then follows from Equation (1) that U(t, t0) also follows a Schr¨odinger
equation,

i(cid:126) dU(t, t0)
dt

= H(t)U(t, t0).

(8)

Thus, to solve Equation (1) for ψ(t) given a particular ψ(t0), one only needs to solve Equation (8)
for U(t, t0). Since U(t, t0) is unitary, it can be written as a matrix exponential of a anti-Hermitian (also
termed skew-Hermitian) matrix. If the Hamiltonian is a of constant value H(t) = H, then this exponential
is

U(t, t0) = exp(−i(t − t0)H).

(9)

For a time varying Hamiltonian, the general solution for U(t, t0) is much more complex, because it encap-
sulates the full solution to the time-dependent Schr¨odinger equation. The well known Dyson series [18]
gives an explicit expression for U(t, t0) in terms of multiple time integrals over nested time commutators
of H(t(cid:48)). While the Dyson series has recently been used numerically [18], it is challenging to work with
because once truncated, it is in general no longer unitary.

The Magnus series, in contrast, gives U(t, t0) in terms of an exponential of a series of anti-Hermitian

operators, speciﬁcally

U(t, t0) = exp (Ω(t, t0)) = exp

(cid:33)

Ωm(t, t0)

.

(cid:32) ∞
(cid:88)

m=1

(10)

As such, the Magnus series explicitly preserves unitarity when truncated [4]. The terms in the Magnus
series are integrals over nested time commutators of the anti-Hermitian matrix A(t(cid:48)), where, in the case

4

of quantum mechanics, A(t(cid:48)) = −iH(t(cid:48)). For instance, the ﬁrst three terms are [5]

Ω1(t, t0) =

(cid:90) t

dt1A(t1),

Ω2(t, t0) =

dt2[A(t1), A(t2)],

0
(cid:90) t
1
2

t0
(cid:90) t

(cid:90) t1

t0
(cid:90) t1

dt1

dt1

Ω3(t, t0) =

1
6

t0

t0

t0

(cid:90) t2

dt2

dt3 ([A(t1), [A(t2), A(t3)]] + [A(t3), [A(t2), A(t1)]]) ,

(13)

(11)

(12)

where [X, Y ] = XY − Y X is the commutator. Note that, when truncated to ﬁrst order, the Magnus
expansion U(t, t0) = exp
average value over the interval [t0, t].

reduces to Equation (9), with H(t) approximated by its

dt1 (−iH(t1))

(cid:16)(cid:82) t
t0

(cid:17)

dt1(cid:107)H(t1)(cid:107)2 < ξ ≈ 1.08686870 . . .

Convergence of the Magnus series for U(t, t0) is not in general guaranteed, but it is under the condition
that (cid:82) t
[5]. Furthermore, each subsequent term in the expansion
t0
increases in complexity rapidly. For these reasons, the Magnus expansion is generally used as a time-
stepping method rather than a single step to solve the complete system. Designing a Magnus-based solver
is a trade-oﬀ between the number of terms used in each expansion, and the number of time-steps used.
Time stepping is based on the fact that time evolution operators can be split into a product via

U(t, t0) = U(t, tn−1)U(tn−1, tn−2) · · · U(t2, t1)U(t1, t0).

(14)

Each of the time-evolution operators can be approximated by a Magnus expansion.

Many unitary time-stepping techniques have been developed based on the Magnus expansion [19].
Some of these techniques use Gauss-Legendre quadrature sampling and the Baker–Campbell–Hausdorﬀ
formula to respectively avoid the integration and time commutators of the Hamiltonian, producing simple
expressions that can be used for unitary time-stepping [20].

In particular, we use the commutator free, fourth order method (CF4) from Reference [19]. Suppose
we wish to evaluate a time-step of U(t + δt, t) using the CF4 method. The Hamiltonians are sampled at
times

t1 = t +

t2 = t +

(cid:18)

1 −

(cid:18)

1 +

1
2
1
2

(cid:19)

(cid:19)

1
√
3
1
√
3

δt and

δt,

based on the second order Gauss-Legendre quadrature

H 1 =

H 2 =

√

√

3 + 2
12
3 − 2
12

3

3

H(t1) +

H(t1) +

√

√

3 − 2
12
3 + 2
12

3

3

H(t2)

and

H(t2).

Then

U(t + δt, t) = exp(−iH 2 δt) exp(−iH 1 δt) + O(δt5),

is used to approximate the time-evolution operator.

1.2.3 Lie-Trotter based exponentiator

(15)

(16)

(17)

(18)

(19)

Evaluating matrix exponentials is a core part of the integration algorithm. Rather than exponentiating
the Hamiltonian directly as in Equation (19), Spinsim works with the ﬁeld functions ωj(t).

5

For spin-half, the exponentiator is in an analytic form in ωx, ωy and ωz. For spin-one, an exponentiator

based on the Lie-Trotter product formula [21]

exp (X + Y ) = lim
n→∞

exp

(cid:18)

(cid:19)

(cid:18) X
n

exp

(cid:19)(cid:19)n

,

(cid:18) Y
n

(20)

is used. An advantage of the Lie-Trotter approach is that exp(−iAk/n) has known analytic forms for
the Lie algebra basis elements Ak. Hence the unitary time-evolution operator is approximated by U =
exp(−iH δt) = T n + O(δt3), where
(cid:18) −iωxJx
n

(cid:18) −iωyJy
n

(cid:18) −iωzJz
n

(cid:18) −iωqQ
n

T = exp

(21)

exp

exp

exp

(cid:19)

(cid:19)

(cid:19)

(cid:19)

.

In fact, commutation relations between the Lie basis operators and the leapfrog splitting method [22]
allow us to instead write

(cid:18)

T = exp

−i

1
2

(cid:19)

(cid:18)

Dz,q

exp(−iΦJφ) exp

−i

(cid:19)

Dz,q

.

1
2

(22)

y/n, φ = arctan2(ωy, ωx) (where arctan2(y, x) is the two
Here z = ωz/n, q = ωq/n, Φ =
argument arctangent [23]), Dz,q = zJz + qQ and Jφ = cos(φ)Jx + sin(φ)Jy. The element-wise analytic
form of this is

x + ω2

ω2

(cid:113)







T =

2

(cid:0)cos (cid:0) Φ
−i√
2
− (cid:0)sin (cid:0) Φ

(cid:1) e−iz/2e−iq/6(cid:1)2
sin(Φ)eiq/6e−iz/2eiφ
(cid:1) e−iq/6eiφ(cid:1)2

2

sin(Φ)eiq/6e−iz/2e−iφ − (cid:0)sin (cid:0) Φ

−i√
2

cos(Φ)ei4q

−i√
2

sin(Φ)eiq/6eiz/2eiφ

2

(cid:1) eiq/6e−iφ(cid:1)2
sin(Φ)eiq/6eiz/2e−iφ
(cid:1) eiz/2e−iq/6(cid:1)2

−i√
2
(cid:0)cos (cid:0) Φ

2







.

(23)

Matrix exponentiation is completed by raising T to an integer n. To approximate the limit in Equa-
tion (20), n must be a large number. We choose n to be of the form n = 2τ , as raising matrices to powers
of two can be done eﬃciently by iterative squaring. While there are some loose upper bounds for the n
required to reach a desired accuracy for the matrix exponential [24], using these to choose a value of n
can, in practice, cause ﬂoating-point errors from over-squaring. Instead, we tested the formula on 105
matrices for diﬀerent values of τ , and compared them to results given by scipy.linalg.expm(), from
the popular python library SciPy [25]. We found that the error minimized after a number of squares of
τ = 24. Thus, by default, n = 224.

In addition to those introduced by the Lie-Trotter approximation, we ﬁnd errors when manipulating
matrices close to the identity. Because n is very large, T is very close to the identity.
In particular,
the limited precision of ﬂoating-point numbers is unable to represent the diagonal of T and its squares
accurately. Errors appear in two forms. One form is that iterative squaring of matrices close to the
It can be avoided by working with the diﬀerence
identity produces ﬂoating-point cancellation errors.
of the matrices from the identity when iteratively squaring. That is, if A = I + a, then instead of
calculating the square S = I + s = A2, we ﬁnd s = (a + 2I)a. The other form of error is that if we use
this method, we must initially calculate T − I accurately, rather than T . This cannot be done by simply
subtracting the identity from Equation (23), as doing so would introduce cancellation error. It can be
avoided by replacing the exponentials and trigonometric functions along the diagonal with specialized
implementations of functions such as expm1(x) = exp(x) − 1, designed for this purpose [26]. The identity
is added to the result of the iterative residual squaring and the full exponential is returned.

This spin-one exponentiator evolves Hamiltonians spanned by Jx, Jy, Jz and Q which is suﬃcient for
three level systems in arbitrary bias ﬁelds, but with single-photon coupling. An exponentiator capable of
evolving an arbitrary spin-one Hamiltonian, for example with diﬀerent coupling between the lower and
upper pairs of states, or with two-photon coupling, is included in the package. When assessing accuracy
for spin-one problems, we have used the single-photon exponentiator.

Note that, the methods for both spin-half and spin-one use analytic forms of matrix exponentials so
that T is unitary by construction; U = T n is then also unitary. Simulations in Spinsim thus maintain
unitarity and so conserve probability even over very large numbers of time-steps.

6

1.2.4 Discretization and parallelization

Frequently we wish to sample the state at times tk spaced more coarsely than the integration time-step.
Consider discrete times tk = t0 + ∆t · k where ∆t is the time-step of the time-series, in contrast to δt, the
time-step of the integration. Denoting ψk = ψ(tk) and Uk = U(tk, tk−1), the time-series of states ψk and
time-evolution operators Uk satisfy

ψk = Ukψk−1.

(24)

This presents an opportunity for parallelism. While ψk depends on ψk−1, the operators Uk depend only
on the ﬁeld functions, and not on previous states ψk(cid:48) or previous operators Uk(cid:48). Hence, the time-evolution
operators Uk can be calculated in parallel.

Spinsim splits the full simulation into time intervals [tk−1, tk], and calculates time-evolution operators
Uk for these intervals in parallel on a GPU. When all the Uk are calculated, the CPU then multiplies them
together (a comparatively less demanding job than calculating them) using Equation (24) to determine
the output samples ψk of the evolving state.

Beyond discretization for parallelization, we discretize our time-evolution operator into individual
0 of L time-evolution

integration time-steps. Each of the Uk is further split into products uk
operators, now separated by the integration time-step δt = ∆t/L.

L−1 · · · uk

To choose an appropriate value of δt, users can refer to the accuracy plots in Figures 2a and 2c under
Section 1.3.1. To choose an appropriate value of ∆t, users must consider three factors. For the most
beneﬁt out of GPU parallelization, users should choose ∆t so that the number of time samples K is at
least as large as the number of GPU cores available for Spinsim. Users should also make sure that ∆t
−→
represents a large enough sample rate for the state ψk or expected spin projection (cid:104)
J (cid:105)k to be used in
their further analysis. Finally, if K is too large, then the GPU will run out of memory on compilation,
which will raise an exception. We found that the 10GiB GeForce RTX 3080 could run at full memory
capacity with 60 million sample points for spin-one mode and 120 million sample points for spin-half.

1.2.5 Dynamically rotating frame

Hamiltonians which have dominant and slowly-varying terms induce rotations around a primary axis,
which is usually chosen to be the quantization axis (which is the z axis when representing spin operators
with the Pauli matrices). Transforming from the lab (standard) frame of reference into one rotating
around this axis by rotation operator Rωr (t) = exp(iωrJzt), the resulting system follows a new Hamilto-
nian

Hr(t) = Rωr (t)(ωx(t)Jx + ωy(t)Jy)Rωr (−t) + (ωz(t) − ωr)Jz + ωq(t)Q

(25)

It is a common technique in solving quantum mechanical problems to enter rotating frames, and their
more abstract counterparts of interaction pictures [12, (p336,338)]. This is almost always done to enable
the rotating wave approximation (RWA), which is an assumption that the oscillatory components of Hr(t)
on average make minor contributions to time evolution, and can be ignored. In some cases, this allows
one to obtain analytic, but approximate, solutions to the quantum system. Note that the RWA is never
invoked by Spinsim, as doing this would reduce the accuracy of simulation results; although a problem
already expressed in a rotating frame can of course be input by the user if desired. In fact, because of
the speed increase of Spinsim compared to alternatives, users who would have previously simulated their
systems using the RWA due to speed concerns may now wish to use Spinsim to simulate beyond RWA
eﬀects that would previously have been missed.

Instead we take advantage of rotating frames to increase numerical accuracy. By our assumption that
|ωr| ≈ |ωz(t)| ≥ |ωx(t)|, |ωy(t)|, |ωq(t)| for the duration we have entered the frame, then the rotating frame
Hamiltonian will have a smaller norm than the lab frame Hamiltonian. This will yield more accurate
results when making discrete time-steps by the integrator, as the distances stepped are smaller.

A diﬀerent rotating frame is entered by Spinsim for each time interval [tk−1, tk]. This dynamic
application allows for the rotating frame to be used even during sweeps of the dominant term ωz(t) where

7

it is only approximately constant locally. Here we choose ωr = ωz(tk−1 +∆t/2) as an approximate average
value of ωz(t) over the duration. The calculated time-evolution operator U r
k is then transformed back to
the lab frame as

Uk = Rωr (−∆t)U r
k .

(26)

This functionality can be disabled for systems that do not ﬁt these criteria.

1.2.6

Integrator architecture

Figure 1: The mathematical and computational breakdown of Spinsim. The procedural problem of eval-
uating the state time series ψk is broken into the parallel problem of evaluating time-evolution operators
Uk. Each of the Uk are found independently on a separate GPU thread. The problem is brought into a
dynamic rotating frame to increase numerical accuracy. The Uk are broken further into time-stepping op-
erators uk, each of which are evaluated using the Magnus CF4 method. Matrix exponentials are evaluated
using a Lie-Trotter based method, including a residual squaring technique to avoid over-squaring.

A visual summary of the structure of Spinsim is shown in Figure 1. The integrator in the Spinsim
package calls a kernel (multithreaded function) to be run on a Cuda capable Nvidia GPU in parallel,
with a diﬀerent thread being allocated to each of the Uk. Alternatively, the kernel can be run in parallel
on a multicore CPU if a compatible GPU is not available. The kernel returns when each of the Uk have
been evaluated.

Each thread begins with initialization of variables, which includes moving into the rotating frame. It
then starts a loop to ﬁnd each of the time-stepping operators uk
l . Within the loop, the integrator enters a
device function to sample the user-provided ﬁeld functions ωj(t) (device functions are GPU subroutines,
and in practice all device functions here are compiled inline for speed). After this, it applies the rotating
frame transformation Rωr (t), before calculating the Gauss-Legendre weightings H 1 and H 2. Next, the
matrix exponentials are taken within another device function. Finally, uk
k (which
l
is initialized to the identity), and the loop continues.

is premultiplied to U r

When the loop has ﬁnished, U r

k is transformed to Uk as in Equation (26), and this is returned. Once

8

all threads have executed, using Equation (24), the state ψk is calculated in a (CPU) numba.jit()ed
function from the Uk and an initial condition ψinit = ψ(t0).

1.2.7 Compilation of integrator

The Spinsim integrator is constructed and compiled just-in-time (JIT), using the Numba [27] python
package. This is achieved via the numba.cuda.jit() decorator, which compiles python functions into
Nvidia Cuda [28] kernels using an LLVM [29] (Low Level Virtual Machine) compiler. The particular
device functions used are not predetermined, but are instead chosen based on user input to decide on a
closure. This technique has multiple advantages. First, the ﬁeld functions ωj(t) are provided by the user
as a plain python method. Note that this method must be numba.cuda.jit() compatible. This allows
users to deﬁne ωj(t) in a way that compiles and executes fast, does not put many restrictions on the
form of the function, and returns the accurate results of analytic functions (compared to the errors seen
in interpolation). Compiling the simulator also allows the user to set meta-parameters, and choose the
features they want to use in a way that does not require experience with the numba.cuda library. This was
especially useful for running benchmarks comparing integration methods from previous versions of the
software to the current one, CF4. The default settings should be optimal for most users, although tuning
the values of Cuda meta-parameters max registers and threads per block could improve performance
for diﬀerent GPUs. Third, JIT compilation also allows the user to select a target device other than Cuda
for compilation, so the simulator can run, using the same algorithm, on a multicore CPU in parallel
instead of a GPU. In particular, this allows for compatibility with products running Apple’s MacOS
10.14 Mojave and later, which are incompatible with Cuda devices and software.

Customization and execution of the simulator is interfaced through an object of class spinsim.Simulator.

The Cuda kernel is deﬁned as per the user’s instructions on construction of the instance, and it is used by
calling the method spinsim.Simulator.evaluate(). Users are returned an instance of spinsim.Results
including the time, state, time-evolution operator, and expected spin projection. Note that, to avoid
making unnecessary calculations, the expected spin projection is calculated as a lazy parameter if needed
rather than returned by the simulator object.

The Spinsim package is designed so that a single simulator instance can be used to execute many
simulations, sweeping through parameters while not needing to be recompiled. This is done through
the sweep parameters[] argument to the user-provided ﬁeld functions ωj(t). First the user must in-
stantiate a spinsim.Simulator object. They can then set the value for sweep parameters[] for a
particular simulation each time spinsim.Simulator.evaluate() is called. As sweep parameters[] is
a numpy.ndarray [30], one can use this functionality to sweep many parameters using the same simu-
lator object. For a use-case example, an MRI experimentalist might want to simulate many spin sys-
tems at diﬀerent locations (x, y), in a magnetic ﬁeld gradient ωz(t) = x − 2y. To do this they could
choose to set sweep parameters = [x, y], and deﬁne field sample[2] = sweep parameters[0] -
2*sweep parameters[1]. This feature is demonstrated with examples in the documentation.

1.3 Quality control

1.3.1 Evaluation of accuracy

All accuracy benchmarks were run in Cuda mode, on the desktop computer with the Ryzen 7 5800X and
GeForce RTX 3080, which from Figure 4 are the fastest CPU and GPU from the devices tested. Note that
these benchmarks do not take into account the amount of time required to JIT compile simulation code
for the ﬁrst time (order of seconds), as we want to look at this in the limit of running many simulations
while sweeping through a parameter that diﬀers in each one.

Benchmarks were performed using neural-sense.sim.benchmark (where neural-sense [31] is the
quantum sensing package that Spinsim was written for). This simulation involves continuously driving
transitions in the system for 100 ms, while exposing it to a 1 ms pulsed signal that the system should be
able to sense. The system has the Hamiltonian

H(t) = ωJz + 2Ω cos(ωt)Jx + Ωpsinp(Ω(t − tp))Jz,

(27)

9

where ω = 2π · 700 kHz, Ω = 2π · 1 kHz,Ωp = 2π · 70 Hz, tp = 233 ms and sinp is a single cycle of a sine
wave.

We ﬁrst wanted to test the accuracy of the diﬀerent integration techniques for various integration
time-steps. Here we wanted to test the advantages of using a Magnus-based integration method. Accu-
racy was calculated by taking the quantum state simulation evaluations of a typical quantum sens-
ing experiment and ﬁnding the root mean squared (RMS) error from a baseline simulation run by
scipy.integrate.ivp solve() as part of the SciPy python package, via

(cid:15) =

1
K

(cid:118)
(cid:117)
(cid:117)
(cid:116)

K−1
(cid:88)

j
(cid:88)

k=0

mj =−j

|ψk,(mj ) − ψbaseline

k,(mj ) |2,

(28)

where j ∈ { 1
2 , 1} is the spin quantum number of the system. This baseline was computed in 2.4 hours (in
comparison to order of 100 ms these Spinsim tests were executed in), and was also used for comparisons
to other software packages.

Error vs time-step plots are shown in Figures 2a and 2c.

In order to ﬁnd how long a simulation
method takes to complete for a given accuracy, we also measured the execution time for each of the
simulations. These plots are shown in Figures 2b and 2d. The former sets of plots will be of interest to
users choosing an appropriate time-step for simulations, and the latter for estimating the execution time
of such simulations. In all of these comparisons, errors above 10−3 were counted as a failed simulation,
as quantum states cannot be arbitrarily far away from each other given that they are points on a unit
complex sphere. Errors below 10−11 were also excluded, as this was the order of magnitude of the errors
in the reference simulation.

The integration techniques tested were the Magnus-based CF4, as well as two Euler-based sampling
methods. A midpoint Euler method was chosen as the simplest (and fastest for a given integration time-
step) possible sampling method, whereas a Heun-Euler sampling method was used as a comparison to
previous versions of this code. These are respectively labelled as the modiﬁed Euler method and the
improved Euler method in Reference [32, p328]. We benchmarked these methods both while using and
not using the rotating frame option. This was done separately for spin-one and spin-half systems, to
ensure they both yield accurate results.

From Figure 2, we ﬁnd that overall, the results that Spinsim gives are accurate to those of SciPy.
Figures 2a, and 2c show that using the Magnus-based integration method is up to 3 orders of magnitude
more accurate when compared the Euler-based methods. Also, using the rotating frame increased the
accuracy here by 4 orders of magnitude for any individual integration method. When comparing speed
vs accuracy in Figures 2b, and 2d, the advantage that CF4 gives in terms of accuracy far outweighs its
slower execution speed when compared to midpoint Euler methods.

1.3.2 Comparison to alternatives

We ran the same error and execution time benchmarks on some alternative packages, listed in Table 1,
to compare Spinsim’s performance to theirs. To obtain simulation results of diﬀerent accuracies, the
step sizes of the alternative integrators were limited to a maximum value. In some cases, the maximum
number of steps was modiﬁed in some cases to allow for the smaller step sizes. Apart from that, the
integrator settings were left untouched from the default values, as a representation of what a user would
experience using a generic solver for spin system problems.

Similarly to the internal Spinsim benchmarks (see Section 1.3.1), the expected spin projection was
evaluated in each case, but only the states were compared to calculate a relative error via Equation (28).
Again, we used the longest running SciPy simulation as a baseline for comparison, as the accuracy of
Mathematica plateaus at small time-steps. Functions used for sampling were compiled to LLVM and
cython in Spinsim and QuTip respectively. In both cases, the time taken to complete a simulation was
measured using a second simulation using the already compiled functions, to represent the use-case of
sweeping through many simulations.

The speed of only one simulation was measured for each benchmark. However, it might be possible
to increase the average speed of many benchmarks from Mathematica and SciPy packages by using

10

(a)

(b)

(c)

(d)

Figure 2: Speed and accuracy of the spin-one and spin-half options of Spinsim. A simulation of a typical
sensing experiment for our lab was run for every integration time-step, for each of the possible integration
techniques (Magnus-based commutator free 4, and two Euler methods). In the simulation, transitions are
continuously driven in the spin system for a duration of 100 ms, and an additional small signal is injected
for 1 ms. See Equation (27). Each technique was tested while both using and not using a transformation
into a rotating frame. Both execution time and error were recorded for each of the simulations. Error is
RMS error compared to a long running SciPy baseline.

multithreading to run multiple simulations at a time. We attempted doing 8 way multithreading (on an
8 core Ryzen 7 5800X ) with Mathematica, but the solver crashed due to insuﬃcient RAM (of 32 GiB).
Multithreading was not attempted using SciPy, due to the fact that running the full set of benchmarks
of only a single simulation per integration time-step already consumes over 11 hours of computational
time. Regardless, for a fair comparison, both Mathematica and SciPy results are plotted with an artiﬁcial
reduction in execution time by a factor of 8 (dotted line in Figures 2b and 2d), which is an upper bound
for the speed increase that could be obtained by running them parallel on an 8 core processor. Simulations
from Spinsim and QuTip automatically run multithreaded, so this comparison is not plotted for these
packages.

From Figure 3, for any given error tolerance, Spinsim is over 3 orders of magnitude faster than
Mathematica and QuTip, and 4 orders of magnitude more accurate than SciPy. In practice, this means
that a 25 minute SciPy simulation is reduced to 50ms, and a three week long SciPy batch simulation of
1000 separate systems (a realistic situation for testing quantum sensing protocols) would take less than

11

Table 1: The software packages used for and veriﬁcation of Spinsim.

Software package Function
Spinsim

Simulator()

QuTip [33]

sesolve()

Mathematica [2]

NDSolve()

Details
The best performing Spinsim conﬁgura-
tion, using the CF4 integrator and the ro-
tating frame mode. This was run both on
CPU and GPU.
The Schr¨odinger equation solver from the
popular python quantum mechanics li-
brary, QuTip. This was chosen as a com-
parison to a specially designed solver used
within the physics community for this ap-
plication. Some quantum mechanics sim-
ulation packages such as the recent sc-
qubits [34] use QuTip for calculating time
evolution. Like Spinsim, QuTip allows
users to sample from compiled functions,
and uses parallelization.
A generic ODE solver from the Mathe-
matica software. This was chosen as it
has been historically popular with our lab
group for simulating quantum sensing ex-
periments.

SciPy [25]

integrate.ivp solve() A generic ODE solver from the popular
python scientiﬁc computing library. This
was chosen as a comparison to a generic
solver from within the python ecosystem.

one minute in Spinsim. Note that while the three week long SciPy example could be parallelized over a
computer cluster, saving some, Spinsim allows users to avoid the need for using clusters and, given that
a single SciPy simulation still takes 25 minutes to run, the Spinsim batch would still be faster.

1.3.3 Parallelization performance

Once the algorithm behind Spinsim was developed, we wanted to check its execution speed while running
on various devices. The main reason for this test was to quantify the speed increase of parallelization
by comparing execution speeds on highly parallel devices (being GPUs), and highly procedural devices
(being CPUs). Speed benchmarks were performed using neural-sense.sim.benchmark, by comparing
the evaluation speed of typical spin-one sensing experiments on diﬀerent devices. Results are of these
benchmarks are shown in Figure 4. The integration code was compiled by numba for multicore CPUs,
CPUs running single threaded, and Nvidia Cuda compatible GPUs. The compiled code was then run on
diﬀerent models of each of these devices. These test devices are given in Table 2.

The results in Figure 4 show the beneﬁt to using parallelization when solving a spin system problem.
Moving from the 6 core Core i7-8750H CPU to the 12 core Ryzen 9 5900X CPU doubles the execution
speed, as does moving from the 384 core Quadro K620 GPU to the 768 core Quadro T1000 GPU. So, in
these cases, performance scales in proportion to thread count. Moving from a single core processor to a
high end GPU increases performance by well over an order of magnitude on three of the ﬁve computers
used for testing. Even the low end Quadro K620 was an improvement over the Core i7-6700 used by
the same computer. Execution speed vs number of cuda cores starts to plateau as the number of cores
increases. This happens because the time it takes to transfer memory from RAM to VRAM (dedicated
graphics memory), which is independent on the number of cores of the GPU, becomes comparable to the
execution time of the simulator logic. However, there is still a large improvement from using the high end

12

Figure 3: Speed vs accuracy of two alternative integration packages. A simulation of a typical sens-
ing experiment for our lab was run for every integration time-step, for each of alternative packages
(qutip.sesolve() from QuTip, NDSolve() from Mathematica, and scipy.integrate.ivp solve()
from SciPy). In the simulation, transitions are continuously driven in the spin system for a duration
of 100 ms, and an additional small signal is injected for 1 ms. See Equation (27). Both execution time
and error were recorded for each of the simulations. Error is RMS error compared to a long running
SciPy baseline. The Mathematica and SciPy results are also shown with a speed up by a factor of 8 to
represent the upper bound of hypothetical parallelization across an 8 core CPU.

Table 2: Devices used in the parallelization speed test. These devices are part of individual computers,
which are separated here by horizontal lines.

Name
RAM (GiB) Cores Cooling
Device
Core i7-6700
4
Intel CPU
16
384
Quadro K620
Nvidia GPU 2
6
16
Core i7-8750H
Intel CPU
2048
GeForce GTX 1070 Nvidia GPU 8
6
Intel CPU
Core i7-10850H
32
768
Nvidia GPU 4
Quadro T1000
12
32
AMD CPU
Ryzen 9 5900X
GeForce RTX 3070 Nvidia GPU 8
5888
8
Ryzen 7 5800X
32
8704
GeForce RTX 3080 Nvidia GPU 10

Air
Air
Air
Air
Air
Air
Air
Air
Liquid
Air

AMD CPU

GeForce RTX 3070 to the GeForce RTX 3080, with the latter simulating the experiment almost twice
as fast as it would take to run the simulated experiment in the real world.

Surprisingly, we found that the Ryzen 7 5800X 8 core CPU was able to execute the benchmark faster
than the Ryzen 9 5900X 12 core CPU. This can be explained by the fact that the Ryzen 7 5800X was
cooled by liquid rather than air, meaning it was likely able to boost to a higher core clock, and resist
thermal throttling.

Users can view Figure 4 to decide on how much their current or future hardware will be able to take
advantage of Spinsim’s parallelism. Another factor not shown in the plot is that, in practice, running
highly code parallel code on a CPU on a personal computer will severely limit the responsiveness of
other applications, as it can utilize the entire CPU (as it should).
In contrast, this does not happen
when running a GPU based program, as it requires very little CPU utilization to function. This can be
convenient when running simulations on a personal laptop or desktop, as other work on the computer
does not have to halt while simulations are being run.

13

Figure 4: Evaluation speed of a simulation of a typical spin-one sensing experiment for our lab on both
CPUs and GPUs. Integration time-step is set to 100 ns. Transitions are continuously driven in the spin
system for a duration of 100 ms, and an additional small signal is injected for 1 ms. See Equation (27).
Evaluation time is determined by an average of 100 similar simulations for each device, where each
individual simulation varies in dressing amplitude (transition frequency).

14

1.3.4 Testing

During the accuracy tests, it was conﬁrmed that all possible modes of Spinsim agree with a baseline
SciPy simulation, as close as the user wants up to the error of 10−11 of that baseline. Therefore, Spinsim
can be trusted for accuracy. The Lie Trotter matrix exponentiator was tested separately from the full
system, as well as benchmarked separately against scipy.linalg.expm() from SciPy. These tests and
benchmarks were run as part of the neural sense package. The simulator has also been adopted by
members of our lab, who have given advice on user experience.

The kernel execution was proﬁled thoroughly, and changes were made to optimize VRAM and register
usage and transfer. This was done speciﬁcally for the development hardware of the GeForce GTX 1070,
so one may get some performance increases by changing some GPU speciﬁc meta parameters when
instantiating the spinsim.Simulator object.

A good way to conﬁrm that Spinsim is functioning properly after an installation is to run the tutorial
code provided and compare the outputs. Otherwise, one can reproduce the benchmarks shown here using
neural sense.sim.benchmark.

2 Availability

Operating system

Developed and tested on Windows 10. CPU functionality tested on MacOS 10.16 Big Sur (note that
MacOS 10.14 Mojave and higher is not compatible with Cuda hardware and software). The package
(including Cuda functionality) is in principle compatible with Linux, but functionality has not been
tested.

Programming language

Python (3.7 or greater)

Additional system requirements

To use the (default) Nvidia Cuda GPU parallelization, one needs to have a Cuda compatible Nvidia
GPU [35]. For Cuda mode to function, one also needs to install the Nvidia Cuda toolkit [36]. If Cuda is
not available on the system, the simulator will automatically parallelize over multicore CPUs instead.

Dependencies

numba (0.50.1 or greater)
numpy (1.19.3)
matplotlib (for example code, 3.2)
neuralsense (for benchmark code)

Software location:

Archive

Name: Monash Bridges
Persistent identiﬁer: 10.26180/13285460
Licence: Apache 2.0
Publisher: Alex Tritt
Version published: 1.0.0
Date published: 2022-04-11

15

Code repository

Name: GitHub
Persistent identiﬁer: https://github.com/alexander-tritt-monash/spinsim
Licence: BSD 3 Clause
Date published: 2020-11-18

Languages

English.

3 Reuse potential

3.1 Applications

The Spinsim package will be useful for any research group needing quick, accurate, and/or large numbers
of simulations involving spin-half or spin-one systems. In particular, the package can simulate a system
with complicated (i.e.not just hard pulses), analytic or time series driving ﬁelds, with no approximations
like the RWA required, at a high time resolution. This includes simulating a Hamiltonian of an arbitrary
number of tones, of any polarization, that can be modulated by frequency, amplitude and/or phase. We
stress that many application speciﬁc simulators are designed for the paradigm of using the RWA and/or
hard pulse approximations [8–10], which both sacriﬁce accuracy for the sake of speed. While this is viable
for some areas of physics research, when designing quantum sensing protocols we need to take all eﬀects
of the spin system and surrounding lab environment into account. Thus, Spinsim’s primary use is to ﬁll
in this gap of simulators for use of developing new quantum sensing protocols with spin-half and spin-one
systems, and so should be useful to many within the ﬁeld of quantum sensing. Moreover, Spinsim is fast
and accurate enough that there is no need to simplify the problem to compromise accuracy for speed.

The package was written for the context of testing a particular ultracold atom magnetic sensing
protocol design. This project aims to be able to measure neural signals using ultracold atoms. Electrical
pulses made by neurons are currently measured using electrical probes [37], which is intrusive and damages
the cells. We, and others in the ﬁeld [38–41] instead propose to sense the small magnetic ﬁelds that these
electrical currents produce. Rubidium ultracold atom clouds can potentially be made sensitive enough
to these small magnetic waveforms that we can use them as sensors. The Spinsim package was written
to simulate possible measurement protocols for this, showing the behavior of the array of spin-one atoms
interacting with the magnetic ﬁelds of the neurons, control signals, and the lab environment.

Aside from cold atom based sensors, Spinsim could be used to simulate sensors made from nitrogen
vacancy centres (NVCs). These are spin-one structures found in diamond doped with Nitrogen atoms.
Similar to ultracold atoms, NVCs can be placed and addressed in 2D arrays in order to take many samples
in one measurement. As work ﬁrst started on Spinsim, Parashar et al [40] published results on simulation
experiments of magnetic neural pulse sensing using NVCs. This is a ﬁeld Spinsim could be useful in.

With some restrictions of not being able to model mixed states, Spinsim could be used for simulations
in various areas of NMR. There are many atomic nuclei with spins of half (eg protons, Carbon 13) and,
and some that have spins of one (eg Lithium 6, Nitrogen 14) [42], which, if relaxation and interactions
between systems are not important for the application, Spinsim could be used to simulate for spectroscopy
experiments, for example. The inclusion of a quadrupole operator means that Spinsim should be able
to simulate nuclear quadrupole resonance (NQR) spectroscopy for spin-one nuclei [43], such as Nitrogen
14, provided a suitable coordinate system is chosen. This technique measures energy level diﬀerences
between levels split by electric ﬁeld gradients, rather than static magnetic bias ﬁelds. Another possible
use-case could be for magnetic resonance imaging (MRI) simulation and pulse sequence design. MRI uses
measures the response of spins of an array of spin-half protons to a spatially varying pulse sequence [44],
which essentially just corresponds to many separate Spinsim simulations of spins at diﬀerent positions
in space. This package oﬀers some advantages over state of the art simulators in the ﬁeld [45], with its

16

use of quantum mechanics over classical mechanics, and its absence of rotating wave approximations, its
parametrized pulse sequence deﬁnitions and geometric integrator.

The ﬁeld of Quantum Optimal Control (QOC) requires many simulations in order to optimize a pulse
sequence to be robust to the noisy environment of the system, using machine learning techniques [11].
The ability to automatically diﬀerentiate [7] the simulator is important for this application. This is not
currently a feature of Spinsim. However, it could be added in the future, especially since it might also
be helpful for some quantum sensing applications.

3.2 Support

Documentation for Spinsim is available on Read the Docs (https://spinsim.readthedocs.io/en/latest/).
This documentation contains a thorough tutorial of examples on how to use the package, and installation
instructions.

For direct support with the Spinsim package, one can open an issue in the github repository. One can
also use this contact to suggest extensions to the package. Spinsim is planned to be used and maintained
by the Monash University School of Physics & Astronomy spinor BEC lab into the future.

4 Acknowledgements

Thank you to past and present members the Monash University School of Physics & Astronomy spinor
BEC lab group. In particular, Chris Bounds, Hamish Taylor, Travis Hartley, and Sam White, who have
been using Spinsim to simulate new ideas for quantum sensing protocols, and have given useful feedback
of their user experience with the package.

5 Funding statement

AT acknowledges support through an Australian Government Research Training Program Scholarship.
JS is the recipient of an Australian Research Council Discovery Early Career Researcher Award (project
number DE210101056) funded by the Australian Government.
LDT acknowledges funding from the Australian Research Council Linkage Project (project number
LP200100082).

6 Competing interests

The authors declare that they have no competing interests.

References

[1] Degen, C., Reinhard, F. and Cappellaro, P.

, Quantum sensing, Reviews of Modern Physics

89(3), 035002.
DOI: https://doi.org/10.1103/RevModPhys.89.035002

[2] Wolfram Research, I. , Mathematica.

URL: https://www.wolfram.com/mathematica

[3] Lions, J.-L., Maday, Y. and Turinici, G. , R´esolution d’EDP par un sch´ema en temps parar´eel,

Comptes Rendus de l’Acad´emie des Sciences - Series I - Mathematics 332(7), 661–668.
DOI: https://doi.org/10.1016/S0764-4442(00)01793-6

[4] Magnus, W. , On the exponential solution of diﬀerential equations for a linear operator, Communi-

cations on Pure and Applied Mathematics 7(4), 649–673.
DOI: https://doi.org/10.1002/cpa.3160070404

17

[5] Blanes, S., Casas, F., Oteo, J. A. and Ros, J. , The Magnus expansion and some of its applications,

Physics Reports 470(5), 151–238.
DOI: https://doi.org/10.1016/j.physrep.2008.11.001

[6] Candoli, D., Sanna, S. and Mitrovi´c, V. F. , PULSEE: A software for the quantum simulation of an
extensive set of nuclear magnetic and quadrupole resonance observables, arXiv:2107.02737 [physics,
physics:quant-ph] .
URL: https://arxiv.org/abs/2108.11415v1

[7] Griewank, A. , Who Invented the Reverse Mode of Diﬀerentiation?, Documenta Mathematica p. 12.

[8] Suzuki, Y., Kawase, Y., Masumura, Y., Hiraga, Y., Nakadai, M. et al. , Qulacs: a fast and versatile

quantum circuit simulator for research purpose, Quantum 5, 559.
DOI: https://doi.org/10.22331/q-2021-10-06-559

[9] Teske, J. D., Cerfontaine, P. and Bluhm, H. , qopt: An experiment-oriented Qubit Simulation and

Quantum Optimal Control Package, arXiv:2107.02737 [physics, physics:quant-ph] .
URL: https://arxiv.org/abs/2110.05873v1

[10] Isakov, S. V., Kafri, D., Martin, O., Heidweiller, C. V., Mruczkiewicz, W. et al. , Simulations
of Quantum Circuits with Approximate Noise using qsim and Cirq, arXiv:2107.02737 [physics,
physics:quant-ph] .
URL: https://arxiv.org/abs/2111.02396v1

[11] Dalgaard, M. and Motzoi, F. , Fast, high precision dynamics in quantum optimal control theory,

arXiv:2107.02737 [physics, physics:quant-ph] .
URL: https://arxiv.org/abs/2110.06187v1

[12] J J Sakurai (Jun John) , Modern quantum mechanics, 2nd ed. edn, Addison-Wesley, Boston.

[13] Gell-Mann, M. , Symmetries of Baryons and Mesons, Physical Review 125(3), 1067–1084.

DOI: https://doi.org/10.1103/PhysRev.125.1067

[14] Hamley, C. D., Gerving, C. S., Hoang, T. M., Bookjans, E. M., Chapman, M. S. , Spin-nematic

squeezed vacuum in a quantum gas, Nature Physics 8(4), 305–308.
DOI: https://doi.org/10.1038/nphys2245

[15] Di, Y., Wang, Y. and Wei, H. , Dipole–quadrupole decomposition of two coupled spin 1 systems,

Journal of Physics A: Mathematical and Theoretical 43(6), 065303.
DOI: https://doi.org/10.1088/1751-8113/43/6/065303

[16] Mockler, R. C. , Atomic Beam Frequency Standards, in L. Marton, ed., Advances in Electronics and

Electron Physics, Vol. 15, Academic Press, pp. 1–71.
DOI: https://doi.org/10.1016/S0065-2539(08)60931-2

[17] Bloch, F. , Nuclear Induction, Physical Review 70(7-8), 460–474.

DOI: https://doi.org/10.1103/PhysRev.70.460

[18] Kalev, A. and Hen, I. , An integral-free representation of the Dyson series using divided diﬀerences,

arXiv:2010.09888 [cond-mat, physics:hep-th, physics:math-ph, physics:nucl-th, physics:quant-ph] .
URL: http://arxiv.org/abs/2010.09888

[19] Auer, N., Einkemmer, L., Kandolf, P. and Ostermann, A. , Magnus integrators on multicore CPUs

and GPUs, Computer Physics Communications 228, 115–122.
DOI: https://doi.org/10.1016/j.cpc.2018.02.019

[20] Blanes, S. and Moan, P. C. , Fourth- and sixth-order commutator-free Magnus integrators for linear

and non-linear dynamical systems, Applied Numerical Mathematics 56(12), 1519–1537.
DOI: https://doi.org/10.1016/j.apnum.2005.11.004

18

[21] Moler, C. and Van Loan, C. , Nineteen Dubious Ways to Compute the Exponential of a Matrix,

Twenty-Five Years Later, SIAM Review 45(1), 3–49.
URL: https://www.jstor.org/stable/25054364

[22] Barthel, T. and Zhang, Y. , Optimized Lie–Trotter–Suzuki decompositions for two and three non-

commuting terms, Annals of Physics 418, 168165.
DOI: https://doi.org/10.1016/j.aop.2020.168165

[23] Organick, E. I. , A Fortran IV primer, Addison-Wesley, Reading, Mass.

[24] Suzuki, M. , Generalized Trotter’s formula and systematic approximants of exponential operators
and inner derivations with applications to many-body problems, Communications in Mathematical
Physics 51(2), 183–190.
DOI: https://doi.org/10.1007/BF01609348

[25] Virtanen, P., Gommers, R., Oliphant, T. E., Haberland, M., Reddy, T. et al. , SciPy 1.0: fundamental

algorithms for scientiﬁc computing in Python, Nature Methods 17(3), 261–272.
DOI: https://doi.org/10.1038/s41592-019-0686-2

[26] Hewlett-Packard , HP 48G Series Advanced User’s Reference Manual.

URL: https://www.hpcalc.org/details/6036

[27] Lam, S. K., Pitrou, A. and Seibert, S. , Numba: a LLVM-based Python JIT compiler, in Proceedings
of the Second Workshop on the LLVM Compiler Infrastructure in HPC - LLVM ’15, ACM Press,
Austin, Texas, pp. 1–6.
DOI: https://doi.org/10.1145/2833157.2833162

[28] Nickolls, J., Buck, I., Garland, M. and Skadron, K. , Scalable Parallel Programming with CUDA: Is
CUDA the parallel programming model that application developers have been waiting for?, Queue
6(2), 40–53.
DOI: https://doi.org/10.1145/1365490.1365500

[29] Lattner, C. and Adve, V. , LLVM: a compilation framework for lifelong program analysis trans-
formation, in International Symposium on Code Generation and Optimization, 2004. CGO 2004.,
pp. 75–86.

[30] Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P. et al. , Array

programming with NumPy, Nature 585(7825), 357–362.
DOI: https://doi.org/10.1038/s41586-020-2649-2

[31] Tritt, A. , Neural Sense.

URL: https://github.com/alexander-tritt-monash/neural-sense

[32] S¨uli, E. and Mayers, D. F. , An Introduction to Numerical Analysis, University Press, Cambridge.

[33] Johansson, J. R., Nation, P. D. and Nori, F. , QuTiP 2: A Python framework for the dynamics of

open quantum systems, Computer Physics Communications 184(4), 1234–1240.
DOI: https://doi.org/10.1016/j.cpc.2012.11.019

[34] Groszkowski, P. and Koch, J.
arXiv:2107.08552 [quant-ph] .
URL: http://arxiv.org/abs/2107.08552

, Scqubits:

a Python package for superconducting qubits,

[35] Nvidia , CUDA GPUs.

URL: https://developer.nvidia.com/cuda-gpus

[36] Nvidia , CUDA Toolkit.

URL: https://developer.nvidia.com/cuda-toolkit

19

[37] Mitterdorfer, J. and Bean, B. P. , Potassium Currents during the Action Potential of Hippocampal

CA3 Neurons, Journal of Neuroscience 22(23), 10106–10115.
DOI: https://doi.org/10.1523/JNEUROSCI.22-23-10106.2002

[38] Barry, J. F., Turner, M. J., Schloss, J. M., Glenn, D. R., Song, Y. et al. , Optical magnetic detection
of single-neuron action potentials using quantum defects in diamond, Proceedings of the National
Academy of Sciences 113(49), 14133–14138.
DOI: https://doi.org/10.1073/pnas.1601513113

[39] Xu, N., Jiang, F., Tian, Y., Ye, J., Shi, F. et al. , Wavelet-based fast time-resolved magnetic sensing

with electronic spins in diamond, Physical Review B 93(16), 161117.
DOI: https://doi.org/10.1103/PhysRevB.93.161117

[40] Parashar, M., Saha, K. and Bandyopadhyay, S. , Axon hillock currents enable single-neuron-
resolved 3D reconstruction using diamond nitrogen-vacancy magnetometry, Communications physics
3(1), 174.

[41] Webb, J. L., Troise, L., Hansen, N. W., Frellsen, L. F., Osterkamp, C. et al. , High speed microcircuit
and synthetic biosignal wideﬁeld imaging using nitrogen vacancies in diamond, arXiv:2107.14156
[cond-mat, physics:physics, physics:quant-ph] .
URL: http://arxiv.org/abs/2107.14156

[42] Fuller, G. H. , Nuclear Spins and Moments, Journal of Physical and Chemical Reference Data

5(4), 835–1092.
DOI: https://doi.org/10.1063/1.555544

[43] Bain, A. D. and Khasawneh, M. , From NQR to NMR: The complete range of quadrupole interac-

tions, Concepts in Magnetic Resonance Part A 22A(2), 69–78.
DOI: https://doi.org/https://doi.org/10.1002/cmr.a.20013

[44] McKinnon, G. , The Physics of Ultrafast MRI, in J. F. Debatin and G. C. McKinnon, eds, Ultrafast

MRI: Techniques and Applications, Springer, Berlin, Heidelberg, pp. 1–51.
DOI: https://doi.org/10.1007/978-3-642-80384-0_1

[45] Kose, R., Setoi, A. and Kose, K. , A Fast GPU-optimized 3D MRI Simulator for Arbitrary k -space

Sampling, Magnetic Resonance in Medical Sciences 18(3), 208–218.

20

