Search-based Software Testing Driven by Automatically
Generated and Manually Defined Fitness Functions
Federico Formica
Mehrnoosh Askarpour
Claudio Menghi
formicaf@mcmaster.ca
askarpom@mcmaster.ca
menghic@mcmaster.ca
McMaster University
McMaster University
McMaster University
Hamilton, Ontario, Canada
Hamilton, Ontario, Canada
Hamilton, Ontario, Canada

2
2
0
2

l
u
J

2
2

]
E
S
.
s
c
[

1
v
6
1
0
1
1
.
7
0
2
2
:
v
i
X
r
a

ABSTRACT
Search-based software testing (SBST) typically relies on fitness
functions to guide the search exploration toward software failures.
There are two main techniques to define fitness functions: (a) auto-
mated fitness function computation from the specification of the
system requirements and (b) manual fitness function design. Both
techniques have advantages. The former uses information from the
system requirements to guide the search toward portions of the
input domain that are more likely to contain failures. The latter
uses the engineersâ€™ domain knowledge.

We propose ATheNA, a novel SBST framework that combines fit-
ness functions that are automatically generated from requirements
specifications and manually defined by engineers. We design and
implement ATheNA-S, an instance of ATheNA that targets SimulinkÂ®
models. We evaluate ATheNA-S by considering a large set of models
and requirements from different domains. We compare our solution
with an SBST baseline tool that supports automatically generated
fitness functions, and another one that supports manually defined
fitness functions. Our results show that ATheNA-S generates more
failure-revealing test cases than the baseline tools and that the
difference between the performance of ATheNA-S and the base-
line tools is not statistically significant. We also assess whether
ATheNA-S could generate failure-revealing test cases when applied
to a large case study from the automotive domain. Our results show
that ATheNA-S successfully revealed a requirement violation in our
case study.

KEYWORDS
Testing, Falsification, Fitness Functions, CPS

1 INTRODUCTION
Software failures in cyber-physical systems (CPS) can have cat-
astrophic and costly consequences. For example, automotive soft-
ware failures led to severe injuries and the loss of human lives
(e.g., [40, 88, 91]). Car manufacturers had to recall their vehicles,
causing reputation damage and millions of U.S. Dollars lost (e.g., [40,
45, 54, 77, 78, 87, 89]).

To prevent these scenarios, CPS engineers extensively test their
systems to detect safety-critical software failures [8, 29, 38, 99]. This
activity is facilitated by automated testing tools (e.g., [4, 10, 62, 67])
that are regularly used in safety critical CPS domains, including
automotive (e.g., [62]), aerospace (e.g., [67]), and medical (e.g., [57]).
Automated testing often (e.g., [67]) relies on search-based soft-
ware testing (SBST). SBST iteratively generates test cases until a
software failure is detected or the SBST framework exceeds the
time budget allotted for the testing activity. Different techniques
were studied to build effective SBST frameworks that proposed

1

the usage of different (a) optimization algorithms (e.g., [23, 59]),
(b) input types (e.g., [76]), (c) surrogate models (e.g., [67]), and
(d) fitness functions (e.g., [62]). We focus on the fitness function
design, a challenging task for designing effective SBST frameworks
([5, 7, 12, 19, 79â€“81, 95]).

Fitness functions guide SBST frameworks in generating new test
cases. They provide metrics (a.k.a. fitness values) that estimate
how close the test cases are to detecting a failure [42]. To effec-
tively and efficiently generating failure-revealing test cases, it is
critical to select appropriate fitness functions [12, 19, 80, 95]. The
fitness function design is usually supported by fitness landscape
analysis activities (e.g. [5, 52, 75]) that evaluate how the fitness
value changes over the search space. Fitness landscape analysis can
help understand the search process and its probability of success
(e.g. [44, 51, 52]). However, despite the breadth and diversity of
testing domains and solutions, the fitness functions design is still
complex and time-consuming (e.g., [7, 9, 81]).

There are two mainstream techniques to define fitness functions:

automated generation and manual definition.

Automated generation of the fitness function (e.g., [14, 27, 34, 56,
66, 73, 92]) derives the fitness function from other artifacts without
any human intervention. For example, many SBST frameworks
(e.g., [10, 32, 67, 93]) use fitness functions to compute the robust-
ness values derived from temporal logic specifications expressing
system requirements (e.g., [34, 41, 68, 73]). These functions typ-
ically use the requirement structure to guide the search toward
portions of the input domain that are more likely to lead to system
failures. Automatically generated fitness functions support SBST in
the detection of failures (e.g., [14, 27, 41, 92]), were used to detect
failures in industrial models (e.g., [47, 67]), and are used within in-
ternational tool competitions (e.g., [33]). They are general purpose.
However, they typically do not use engineersâ€™ domain knowledge
for the fitness value computation.

Unlike the automated approach, manual fitness function defini-
tion (e.g., [4, 20, 61, 63, 95]) requires engineers to design the fitness
functions using their experience and domain knowledge. For exam-
ple, engineers can manually define fitness functions to guide the
search toward the generation of inputs that are more likely to show
the violation of liveness, stability, smoothness, and responsiveness
requirements [62]. Manually defined fitness functions effectively
and efficiently support SBST: they enable the detection of failures
that domain experts could not find by manual testing (e.g., [62]).
Manual fitness function design enables engineers to write model-
specific fitness functions that guide the search toward specific areas
of the input domain that are more likely to contain failures, e.g., the
boundaries of the input domain. However, in some cases, manually

 
 
 
 
 
 
defined fitness functions are biased and may concentrate the search
on areas of the input domains that do not contain failures.

This work proposes ATheNA (AuTomatic-maNuAl) search-based
testing, a novel SBST framework driven by automatically gener-
ated and manually defined fitness functions. ATheNA combines the
benefits of automatically generated and manually defined fitness
functions: it exploits both the structure of the requirements and the
engineersâ€™ domain knowledge to guide the search toward specific
areas of the input domain that are likely to reveal software failures.
In addition, we define ATheNA-S, an instance of ATheNA that sup-
ports SimulinkÂ® models. We consider SimulinkÂ® models since they
are widely-used for specifying the behavior of CPSs in a variety
of domains including [21, 55], automotive [62], energy [47] and
medical [82]. We implement ATheNA-S as a plugin for S-Taliro [10],
a well-known SBST framework for SimulinkÂ® models recently clas-
sified as ready for industrial usage [48].

We evaluate the effectiveness and efficiency of ATheNA-S in gen-
erating failure-revealing test cases. We compare ATheNA-S with
S-Taliro [10], a tool that supports automatically generated fit-
ness functions, and ATheNA-SM, a customization of ATheNA-S that
supports manually defined fitness functions. We consider seven
models and 27 requirements from ARCH 2021 [11, 33], an inter-
national SBST competition for SimulinkÂ® models that is held as
a part of the international conference on computer safety, relia-
bility, and security (SAFECOMP) [1]. For each requirement, we
considered a set of assumptions for the inputs of the model. In total,
we compare the tools by considering 39 assumption-requirement
combinations. Our results show that (a) ATheNA-S performs better
than the baseline tools for â‰ˆ 79% of our assumption-requirement
combinations, (b) ATheNA-S generates more failure-revealing test
cases than S-Taliro (+6.3%) and ATheNA-SM (+8.6%), and (c) the
difference between the performance of ATheNA-S and the baseline
tools is not statistically significant. Additionally, we assess how
applicable and useful is ATheNA-S in generating failure-revealing
test cases for a large SimulinkÂ® model. We consider the SimulinkÂ®
model of an electrical automotive software control system [18]
developed as a part of the EcoCAR Mobility Challenge [30], a com-
petition sponsored by the U.S. Department of Energy [25], General
Motors [39], and MathWorks [60], and use the insights of a lead
engineer in a large automotive company to inject a practical fault
in the model. We evaluate whether ATheNA-S could generate any
failure-revealing test cases. Our results show that ATheNA-S could
generate a failure-revealing test within practical time limits.

To summarize, our contributions are:

â€¢ We propose the ATheNA framework (Section 2);
â€¢ We define ATheNA-S, an instance of ATheNA that supports SimulinkÂ®

models (Section 3);

â€¢ We implement ATheNA-S as a plugin for S-Taliro (Section 4);
â€¢ We empirically assess the benefits of ATheNA (Section 5);
â€¢ We discuss the impact of our findings on the software engineering

practice (Section 6).

This work is organized as follows. Section 2 presents ATheNA.
Section 3 describes the instance of ATheNA that targets SimulinkÂ®
models. Section 4 provides implementation details. Section 5 em-
pirically assesses our contribution. Section 6 discusses our findings

2

ğœ‘

5 Automatic
Fitness

ğ‘“ğ‘

ğ´

ğ‘†

1 Input
Generation

i

2 System
Execution

ğ‘† (i)

ğ‘“ (ğ‘† (i))

4 ATheNA
Fitness

ğ‘“

3 Fitness
Assessment

Formica, et al.

6 Manual
Fitness

ğ‘“ğ‘š

tc(i)/NFF

ğ‘‡

Figure 1: Overview of the ATheNA testing framework.

and presents threats to validity. Section 7 presents related work.
Section 8 concludes the work.

2 AUTOMATIC-MANUAL SBST
Figure 1 provides an overview of the ATheNA (AuTomatic-maNuAl)
search-based testing framework. Squared boxes report the steps
of ATheNA. Incoming and outgoing arrows describe the inputs and
outputs of the different steps. Arrows with no source represent
the inputs of the ATheNA framework. Arrows with no destination
represent the outputs of the ATheNA framework. Arrows connecting
two boxes link subsequent steps.

ATheNA has four inputs: a model of the system to be tested (ğ‘†);
an assumption on the system inputs (ğ´), a time budget (ğ‘‡ ), and a
requirement (ğœ‘). The output of ATheNA is a failure-revealing test
case (tc(i)) or an indication that no failure-revealing test case was
found (NFF â€” No Failure Found) within the time budget.

To detect a failure-revealing test case, ATheNA iteratively repeats

the steps presented in figure 1:

â€¢ Input Generation ( 1 ). It generates an input (i) for the system

model (ğ‘†) that satisfies the assumption (ğ´);

â€¢ System Execution ( 2 ). It runs the system model (ğ‘†) with the
generated input (i) and obtains a system execution (ğ‘† (i)).

â€¢ Fitness Assessment ( 3 ). It computes the fitness value (ğ‘“ (ğ‘† (i)))
associated with the obtained system execution (ğ‘† (i)) and assesses
whether the fitness value is below a threshold value.

A test case (tc(i)) associated with the input (i) is failure-revealing
if: (a) the input satisfies the assumption (ğ´), i.e., i |= ğ´, and (b) the
fitness value (ğ‘“ (ğ‘† (i))) is smaller than a threshold value (typically
the value 0).

The ATheNA framework terminates when a failure-revealing test
case (tc(i)) is detected or when the framework exceeds the time
budget (ğ‘‡ ) without finding any failure-revealing test case. For the
former case, ATheNA returns the failure-revealing test case. For the
latter case, ATheNA returns the NFF value.

The fitness value (ğ‘“ (ğ‘† (i))) is used to guide the ATheNA frame-
work. The search algorithm tries to find an input that minimizes the
fitness value. To reach this goal, it uses the fitness value computed
in step 3 to drive the generation of the next input ( 1 ).

Search-based Software Testing Driven by Automatically Generated and Manually Defined Fitness Functions

To compute the fitness value, ATheNA combines manually defined
and automatically generated fitness functions and has the following
steps:
â€¢ ATheNA Fitness ( 4 ). It returns a fitness function (ğ‘“ ) that combines
the values computed by the manually defined and automatically
generated fitness functions. Depending on the testing necessities,
the fitness function ğ‘“ can prioritize one of the two values. The
function can also change the prioritization policy dynamically
during the search if the fitness value is not effectively guiding
the SBST framework.

â€¢ Automatic Fitness ( 5 ). It returns a fitness function (ğ‘“ğ‘) automati-
cally generated from requirement ğœ‘. The requirement is automat-
ically compiled into a function that, given a system execution
ğ‘† (i), computes a fitness value (ğ‘“ğ‘).

â€¢ Manual Fitness ( 6 ). It returns a fitness function (ğ‘“ğ‘š) manually
defined by the engineers. It computes a fitness value for the
system execution ğ‘† (i).
ATheNA can be instantiated by considering different modeling
formalisms. One possible instance of ATheNA is presented in the
next section.

3 AUTOMATIC-MANUAL SBST FOR

SIMULINKÂ®

This section describes ATheNA-S, an instance of ATheNA that sup-
ports SimulinkÂ®, a graphical language for model design.

Figure 2 presents our running example: the variation of the
Automatic Transmission (AT) model provided by Mathworks [16],
used in the applied verification for continuous and hybrid systems
competition [11, 33].

SimulinkÂ® provides visual constructs to design a system model (ğ‘†).
Blocks typically represent operations and constant values. They are
aggregated into subsystems labeled with ports that identify the
inputs and outputs of the subsystems. For example, Engine is one
of the subsystems of the SimulinkÂ® model of figure 2. It has two in-
put ports (Ti and Throttle) and one output port (Ne). Connections
link input and output ports. For example, a connection links the
output port NE of the Engine subsystem to the input port NE of the
Transmission subsystem. The inputs and outputs of a SimulinkÂ®
model are represented by the inports and outports blocks. For ex-
ample, in figure 2, there are two inputs (Throttle, and Brake) and
three outputs (Speed, RPM, and Gear).

We instantiated ATheNA to support SimulinkÂ® models as follows.
Input Generation ( 1 ). The input generation step generates a set
of signals i = {ğ‘–1, ğ‘–2, . . . , ğ‘–ğ‘š }, one per inport. For example, for the
AT model, ATheNA generates the input signals for the Throttle and
Brake inports. Let T = [0, ğ‘] be a non-singular bounded interval of
R representing the simulation time domain of system ğ‘†, a signal is a
function ğ‘“ : T â†’ R. The SimulinkÂ® simulator requires engineers to
specify the input of the simulation. Figure 3a presents an example of
an input for the AT model. The input contains the two input signals
for the Throttle and Brake inports defined over the simulation
time domain [0, 50]s.

Assumption ğ´ guides the generation of new input signals. For
each input signal iğ‘– âˆˆ i, it contains a triple âŸ¨ğ‘–ğ‘›ğ‘¡ğ‘–, ğ‘…ğ‘–, ğ‘›ğ‘– âŸ© made of
an interpolation function (ğ‘–ğ‘›ğ‘¡ğ‘– ), a value range (ğ‘…ğ‘– ) and a number of
control points. ATheNA-S generates each input signal iğ‘– by selecting

Figure 2: SimulinkÂ® model of the AT example.

ğ‘›ğ‘– time instants, i.e., ğ‘¡1, ğ‘¡2, . . . , ğ‘¡ğ‘›ğ‘– , within the time domain T =
[0, ğ‘], such that ğ‘¡1 = 0, ğ‘¡ğ‘›ğ‘– = ğ‘ and ğ‘¡1 < ğ‘¡2 < . . . < ğ‘¡ğ‘›ğ‘– . The
values of ğ‘¡1, ğ‘¡2, . . . , ğ‘¡ğ‘›ğ‘– can also be chosen to ensure a fixed difference
between consecutive time instants, i.e., for all ğ‘¡ ğ‘— , ğ‘¡ ğ‘—+1 with ğ‘— âˆˆ
{1, 2, . . . ğ‘›ğ‘– âˆ’ 1}, the value of ğ‘¡ ğ‘—+1 âˆ’ ğ‘¡ ğ‘— is fixed. Then, ATheNA-S
selects a value iğ‘– (ğ‘¡ ğ‘— ) from value range ğ‘…ğ‘– for each time instant
ğ‘¡ ğ‘— . The interpolation function (e.g., piecewise constant, linear or
piecewise cubic) is then used to generate the values assumed by
input signal iğ‘– over the rest of time domain T. For example, the
input signals for the Throttle and Brake reported in figure 3a are
generated by considering the value range [0, 100] for the throttle
percentage applied to the engine (%), and [0, 325] for the pound-foot
(lb - ft) torque applied by the brake. To generate the input signals,
10 control points and the Piecewise Cubic Hermite Interpolating
Polynomial (pchip) interpolation function [74] are considered. The
values selected for the time instants are indicated in the figure 3a
with the â€œâ—¦â€ symbol on the x-axis. The points on the input signals
labeled with theâ€œâˆ—â€ symbol indicate the values selected for the input
signals at these time instants.

System Execution ( 2 ). ATheNA-S uses the SimulinkÂ® simulator to
execute system ğ‘† for input i and to produce output o, i.e., o = ğ‘† (i).
The output is a set o = {ğ‘œ1, ğ‘œ2, . . . , ğ‘œğ‘š } of signals (a.k.a. output
signals), one per outport. Figure 3b shows the output of the AT
model corresponding to the input in figure 3a. The output is made
by three output signals associated with the Speed, RPM, and Gear
outports.

Fitness Assessment ( 3 ). ATheNA-S computes fitness measure
ğ‘“ (o) associated with the output of the system execution. Notice
that since connections within the SimulinkÂ® model can directly
connect inports to outports, fitness measures can also use informa-
tion from inputs signals to guide the search. ATheNA-S implements
the ATheNA framework by enabling the computation of the fitness
measure as explained in steps 4 - 6 .

ATheNA Fitness ( 4 ). It is a function that combines the values
computed by the manually defined and automatically generated
fitness functions as follows:

3

brake3Gear2RPM1SpeedVehicleNegearNoutTiToutTransmissiongearthrottledown_thup_thrun()ThresholdCalculationspeedup_thdown_thgearCALC_TH()ShiftLogicTiThrottleNeEngine1Throttle2BrakeImprellerTorqueEngineRPMTransmissionRPMdown_thrup_thrSpeedTorqueFormica, et al.

(a) Example of input signals for the AT model.

(b) Output signals for the AT model for the input of figure 3a.

Figure 3: Example input and output for the AT SimulinkÂ® model.

ğ‘“ = ğ‘“ğ‘ Â· ğ‘ + ğ‘“ğ‘š Â· (1 âˆ’ ğ‘)
where ğ‘ is a parameter within the range [0, 1]. ATheNA-S considers
solely the value of the automatic fitness when ğ‘ = 1, and solely
the value of the manual fitness when ğ‘ = 0. The higher the value
of ğ‘, the more the automatic fitness value is prioritized. The lower
the value of ğ‘, the more the manual fitness value is prioritized. For
example, engineers may set the parameter ğ‘ to the value 0.5 to
equally prioritize manual and automatic fitness measures when
analyzing the AT model.

Notice that ATheNA-S can use more complex functions to com-
bine the manual and automatic fitness measures or it can dynami-
cally change the fitness function during the search (e.g., [96]).

Automatic Fitness ( 5 ). ATheNA-S enables engineers to automat-
ically generate fitness functions from a requirement ğœ‘ expressed
using a temporal logic-based formalism, such as Signal Temporal
Logic (STL) [58] or Restricted Signals First-Order Logic (RFOL) [68].
For example, consider requirement AT1 that specifies that the value
of the Speed output signal shall be lower than 120rpm for every in-
stant within [0, 20] time interval. The requirement can be expressed
in STL as

G [0,20] (Speed < 120),
where â€œSpeed<120â€ is a predicate indicating that the â€œSpeedâ€ is
lower than the value â€œ120â€, G is the â€œgloballyâ€ temporal operator,
and [0, 20] is a time interval indicating that the predicate must
hold from the time instant â€œ0â€ to the time instant â€œ20â€. ATheNA-S
automatically translates the STL specification into a fitness function
ğ‘“ğ‘. The value generated by the fitness function ğ‘“ğ‘ is negative if the
property is violated and positive otherwise. In addition, the higher
is the positive value computed by ğ‘“ğ‘, the farther the system from
violating its requirement; and the lower is the negative value, the
farther the system from satisfying its requirement.

Manual Fitness ( 6 ). ATheNA-S enables engineers to define a fit-
ness function that considers the output (o) of the SimulinkÂ® simula-
tion, the model of system ğ‘†, and assumption ğ´ for the computation

4

of fitness value ğ‘“ğ‘š. For example, the function below is a possible
fitness function for the AT model, given a property that requires
the vehicle speed to be lower than 120ğ‘šğ‘â„ at all times.

ğ‘“ğ‘š = ğ‘šğ‘’ğ‘ğ‘›(Brake) âˆ’ ğ‘šğ‘’ğ‘ğ‘›(Throttle),

where ğ‘šğ‘’ğ‘ğ‘›(Throttle) and ğ‘šğ‘’ğ‘ğ‘›(Brake) are the average values
assumed by the Throttle and Brake input signals over the simu-
lation time. The value assumed by ğ‘šğ‘’ğ‘ğ‘›(Throttle) increases as
the average value assumed by the input signal Throttle increases.
The value assumed by ğ‘šğ‘’ğ‘ğ‘›(Brake) decreases as the average value
assumed by the input signal Brake decreases. Since ATheNA min-
imizes the value computed by the fitness function, the function
ğ‘“ğ‘š guides the search toward areas of the input domain with high
Throttle and low Brake values that are more likely to make the
speed of the vehicle higher than 120ğ‘šğ‘â„. Specifically, the higher
the value of the ğ‘šğ‘’ğ‘ğ‘›(Throttle), the lower the value computed
by ğ‘“ğ‘š, and the lower the value of the ğ‘šğ‘’ğ‘ğ‘›(Brake), the lower the
value computed by ğ‘“ğ‘š.

4 IMPLEMENTATION
We implement ATheNA-S as a plugin for S-Taliro [10], an open-
source SBST tool. We selected S-Taliro, among other alternatives
(e.g., Breach [26], FalCAuN [94], falsify [97], FalStar [31, 93], Fore-
See [98]) due to its recent classification as ready for industrial de-
velopment [48], and its use in several industrial systems (e.g., [90]).
In addition, this choice makes our solution applicable with other
S-Taliro plugins, such as Aristeo [67].

ATheNA-S reuses the modules provided by S-Taliro to imple-
ment the input generation ( 1 ) and system execution ( 2 ) steps
of ATheNA. For the input generation step, S-Taliro provides a set
of alternatives that rely on different search algorithms, such as
Simulated Annealing [2], Monte Carlo [70], and gradient descent
methods [3]. For the system execution step, S-Taliro relies on the
sim command of Matlab [85] to run the SimulinkÂ® simulator.

05101520253035404550020406080100051015202530354045500501001502002503000510152025303540455005010015005101520253035404550020004000051015202530354045501234Search-based Software Testing Driven by Automatically Generated and Manually Defined Fitness Functions

Listing 1: ATheNA-S Implementation.

c l a s s d e f

( A b s t r a c t ) F _ A s s e s s m e n t

methods

( A b s t r a c t = t r u e )

f a = a u t F i t n e s s ( S , A , phi , i , o ) ;
fm= m a n F i t n e s s ( S , A , phi , i , o ) ;
f = a t h e n a F i t n e s s ( S , A , phi , i , o ) ;
s = s t o p C r i t e r i o n ( S , A , phi , i , o ) ;

end

7
8 end
9

c l a s s d e f AT1_F_Assessment < F _ A s s e s s m e n t

methods

f u n c t i o n f a = a u t F i t n e s s ( S , A , phi , i , o )
r e t u r n c a l l T a l i r o ( o , phi , [ . . . ] ) ;

end
f u n c t i o n fm= m a n F i t n e s s ( S , A , phi , i , o )

t h r o t t l e f = s c a l e ( mean ( i ( : , 1 ) ) , A ( 1 ) . R ) ;
b r a k e f = s c a l e ( mean ( i ( : , 2 ) ) , A ( 2 ) . R ) ;
r e t u r n b r a k e f âˆ’ t h r o t t l e f ;

end
f u n c t i o n f = a t h e n a F i t n e s s ( S , A , phi , i , o )
r e t u r n 0 . 5 âˆ— a u t F i t n e s s ( S , A , phi , i , o )

+ 0 . 5 âˆ— m a n F i t n e s s ( S , A , phi , i , o ) ;

end
f u n c t i o n s = s t o p C r i t e r i o n ( S , A , phi , i , o )
r e t u r n a u t F i t n e s s ( S , A , phi , i , o ) < 0 ;

end

1

2

3

4

5

6

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

end

27
28 end

ATheNA-S modifies the fitness assessment step of S-Taliro ( 3 )
as described in Section 3. Specifically, we modified the source code
of S-Taliro to receive a subclass of the F_Assessment abstract
class as input to compute the fitness measure. The abstract class
F_Assessment detailed in Listing 1 (Lines 1-8) describes the generic
common functionalities of ATheNA-S fitness functions. More pre-
cisely, it specifies that each ATheNA-S fitness measure has three
methods: autFitness (Line 3), that specifies how the automatic
fitness measure is computed ( 5 ), manFitness (Line 4), that speci-
fies how the manual fitness measure is computed ( 6 ), and athena
Fitness (Line 5), that specifies how the automatic and manual fit-
ness values are combined ( 4 ). Finally, the stopCriterion method
defines the condition that stops the search.

ATheNA-S allows for model-specific fitness functions that com-
bine manually defined and automatically generated fitness func-
tions. For example, the subclass AT1_F_Assessment, detailed in
Listing 1 (Lines 10-28), provides the implementation for the meth-
ods of the class F_Assessment for the requirement AT1 of AT.

The method autFitness (Lines 12-14), that computes the value
of the automated fitness function, is implemented by using the
method callTaliro provided by S-Taliro. As done in the default
implementation of S-Taliro, we provided the output signals (o)
generated by running the SimulinkÂ® model as inputs to the method
CallTaliro, together with the property phi, and some additional
configuration parameters omitted for brevity ([...] in Line 13).

Method manFitness (Lines 15-19) implements the manual fit-
ness function by defining variables throttlef (Line 16) and brakef
(Line 17). The variable throttlef contains the average (mean(i
(:,1))) of the values stored in the first column (i (:,1)) of the
input (i), that is average of the values assumed by the Throttle
input signal. This value is scaled (scale) within [0, 1], by consider-
ing the value range (A(1).R) for the throttle. The higher the values

5

associated with the Throttle, the higher is the value assumed by
the variable throttlef. The variable brakef contains the aver-
age (mean(i(:,2))) of the values stored in the second column (i
(:,2)) of the input (i), that is the average of the values assumed by
the Brake input signal, scaled within the range [0, 1]. The manual
fitness function value is the difference between the value of the
variable brakef and the value of the variable throttlef (Line 18),
which is within the range [âˆ’1, 1]. The value âˆ’1 means throttle
is maximum and no brake is applied and the value 1 indicates the
opposite. Notice that, since the goal of the search is to minimize
the fitness value, our manual fitness function ensures that input
signals with high Throttle and low Brake are prioritized during
the search.

The athenaFitness method (Lines 20-23), that computes the
value of the ATheNA fitness function, computes the sum of the
product of the values assumed by the automated and the manual
fitness functions and the value 0.5. Since the values of automated
and manual fitness functions are within the range [âˆ’1, 1], this
fitness function ensures that the ATheNA fitness value is also within
the range [âˆ’1, 1] and both the manual and the automated fitness
functions are equally prioritized.

The stopCriterion method (Lines 24-26), implementing the
stopping criterion, aborts the search whenever the value computed
by the automated fitness function is lower than 0. This stopping cri-
terion reflects the robustness semantics of STL [36], i.e., a negative
value indicates that the STL specification of the AT1 requirement
is violated.

5 EVALUATION
In this section, we empirically evaluate ATheNA-S by considering
the following research questions:

RQ1 How effective is ATheNA-S in generating failure-revealing

test cases? (Section 5.1)

RQ2 How efficient is ATheNA-S in generating failure-revealing

test cases? (Section 5.2)

RQ3 How applicable and useful is ATheNA-S in generating failure-
revealing test cases for a large automotive model? (Sec-
tion 5.3)

To evaluate the effectiveness (RQ1) and efficiency (RQ2) of our
solution, we compare ATheNA-S with existing SBST frameworks
that only support either automatic or manual fitness functions. We
consider S-Taliro as baseline framework supporting automatic
fitness functions for the reasons explained in Section 4. We could
not identify a SBST framework to be used as baseline for manual
fitness functions since (a) SBST frameworks that rely on manual fit-
ness functions are generally problem-specific, (b) we are not aware
of a generic SBST framework based on manual fitness functions
for SimulinkÂ® models. Thus, for manual fitness functions, we con-
sider ATheNA-S and use an alternative implementation for the class
F_Assessment (Listing 1) that forces the â€œathenaFitnessâ€ method
(Line 5) to return the value computed by the manual fitness func-
tion, that is the value computed by the method â€œmanFitnessâ€. The
implementation is obtained by considering the function ğ‘“ presented
in Section 3 and by setting 0 as value for the parameter ğ‘. We refer
to this instance of ATheNA as ATheNA-SM.

Table 1: Identifier (MID), description, number of blocks (#Blocks), inports (#Inport), outports (#Outport), simulation time in
seconds (Ts), and requirements (#Reqs) of our benchmark models.

Formica, et al.

MID Description

#Blocks

#Inport

#Outport

Ts

#Reqs

AT
AFC
NN
WT
CC
F16
SC

A model of a car automatic transmission with gears from 1 to 4.
A controller for the air-fuel ratio in an engine.
A Neural Network controller for a levitating magnet above an electromagnet.
A model of a wind turbine that takes as input the wind speed.
A simulation of a system formed by five cars.
Simulation of an F16 ground collision avoidance controller.
Dynamic model of steam condenser, controlled by a Recurrent Neural Network.

69
302
111
161
13
55
172

2
2
1
1
2
0
1

3
3
1
6
5
4
4

50
50
40
630
100
15
35

10
3
2
4
6
1
1

Table 2: Identifier (RID), formal specification, and description for the requirements of the different models.

RID

STL Specification

Description

G [0,20] (Speed < 120)
G [0,10] (RPM < 4750)

AT1
AT2
AT51 G [0,30] ( (Â¬ğ‘”1 âˆ§ F [0.001,0.1] ğ‘”1) =â‡’ F [0.001,0.1 ( G [0,2.5] ğ‘”1))
AT52 G [0,30] ( (Â¬ğ‘”2 âˆ§ F [0.001,0.1] ğ‘”2) =â‡’ F [0.001,0.1] ( G [0,2.5] ğ‘”2))
AT53 G [0,30] ( (Â¬ğ‘”3 âˆ§ F [0.001,0.1] ğ‘”3) =â‡’ F [0.001,0.1] ( G [0,2.5] ğ‘”3))
AT54 G [0,30] ( (Â¬ğ‘”4 âˆ§ F [0.001,0.1] ğ‘”4) =â‡’ F [0.001,0.1] ( G [0,2.5] ğ‘”4))
( G [0,30] (RPM < 3000)) =â‡’ ( G [0,4] (Speed < 35))
AT6a
( G [0,30] (RPM < 3000)) =â‡’ ( G [0,8] (Speed < 50))
AT6b
( G [0,30] (RPM < 3000)) =â‡’ ( G [0,20] (Speed < 65))
AT6c
AT6abc AT6a âˆ§ AT6b âˆ§ AT6c
AFC27 G [11,50] ( (ğ‘Ÿğ‘–ğ‘ ğ‘’ âˆ¨ ğ‘“ ğ‘ğ‘™ğ‘™) â†’ ( G [1,5] |ğœ‡ | < 0.008))
AFC29 G [11,50] ( |ğœ‡ | < 0.007)
AFC33 G [11,50] ( |ğœ‡ | < 0.007)
NN

G [1,37] ( ( |ğ‘ƒğ‘œğ‘  âˆ’ ğ‘…ğ‘’ ğ‘“ | > (0.005 + 0.03 |ğ‘…ğ‘’ ğ‘“ |)) â†’
F [0,2] G [0,1] Â¬(0.005 + 0.03 |ğ‘…ğ‘’ ğ‘“ | â‰¤ |ğ‘ƒğ‘œğ‘  âˆ’ ğ‘…ğ‘’ ğ‘“ |))
F [0,1] (ğ‘ƒğ‘œğ‘  > 3.2) âˆ§ F [1,1.5] ( G [0,0.5] (1.75 < ğ‘ƒğ‘œğ‘  < 2.25)) âˆ§
G [2,3] (1.825 < ğ‘ƒğ‘œğ‘  < 2.175)
G [30,630] (ğœƒ â‰¤ 14.2)
G [30,630] (21000 â‰¤ ğ‘€ğ‘”,ğ‘‘ â‰¤ 47500)
G [30,630] (Î© â‰¤ 14.3)
G [30,630] F [0,5] ( |ğœƒ âˆ’ ğœƒğ‘‘ | â‰¤ 1.6)
G [0,100] (ğ‘¦5 âˆ’ ğ‘¦4 â‰¤ 40)
G [0,70] F [0,30] (ğ‘¦5 âˆ’ ğ‘¦4 â‰¥ 15)
G [0,80] ( ( G [0,20] (ğ‘¦2 âˆ’ ğ‘¦1 â‰¤ 20)) âˆ¨ ( F [0,20] (ğ‘¦5 âˆ’ ğ‘¦4 â‰¥ 40)))

G [0,65] F [0,30] G [0,20] (ğ‘¦5 âˆ’ ğ‘¦4 â‰¥ 8)
G [0,72] F [0,8] ( ( G [0,5] (ğ‘¦2 âˆ’ ğ‘¦1 â‰¥ 9)) â†’ ( G [5,20] (ğ‘¦5 âˆ’ ğ‘¦4 â‰¥
9)))

NNx

WT1
WT2
WT3
WT4

CC1
CC2
CC3

CC4
CC5

SC

CCx (cid:211)ğ‘–=1..4 G [0,50] (ğ‘¦ğ‘–+1 âˆ’ ğ‘¦ğ‘– > 7.5)
G [0,15] (ğ‘ğ‘™ğ‘¡ğ‘–ğ‘¡ğ‘¢ğ‘‘ğ‘’ > 0)
F16
G [30,35] (87 â‰¤ ğ‘ğ‘Ÿğ‘’ğ‘ ğ‘ ğ‘¢ğ‘Ÿğ‘’ â‰¤ 87.5)
âˆ— ğ‘Ÿğ‘–ğ‘ ğ‘’ = (ğœƒ < 8.8) âˆ§ ( F [0,0.005] (ğœƒ > 40.0)),
â€  The range of the throttle angle is 0 â‰¤ ğœƒ < 61.2.
Â§ The range of the throttle angle is 61.2 â‰¤ ğœƒ â‰¤ 81.2.

The value of the speed within the interval [0, 20]s shall be lower than 120mph.
The value of the motor speed within the interval [0, 10]s shall be lower than 4750rpm.
If gear one is engaged at any time in [0, 30]s, it shall remain engaged for at least 2.5s.
If gear two is engaged at any time in [0, 30]s, it shall remain engaged for at least 2.5s.
If gear three is engaged at any time in [0, 30]s, it shall remain engaged for at least 2.5s.
If gear four is engaged at any time in [0, 30]s, it shall remain engaged for at least 2.5s.
If RPM is lower than 3000 within [0, 30]s, then Speed shall be lower than 35 in the interval [0, 4]s.
If RPM is lower than 3000 within [0, 30]s, then Speed shall be lower than 50 in the interval [0, 8]s.
If RPM is lower than 3000 within [0, 30]s, then Speed shall be lower than 65 in the interval [0, 20]s.
The requirements with RID AT6a, AT6b, AT6c shall be satisfied.

If within [11, 50]s the throttle angle rises or falls, then the error (ğœ‡) shall be lower than 0.008.âˆ—
Within [11, 50]s, the error shall be lower than 0.007.â€ 
Within [11, 50]s, the error shall be lower than 0.007.Â§

The discontinuities between the levitating magnet position (ğ‘ƒğ‘œğ‘ ) and the reference position (ğ‘…ğ‘’ ğ‘“ )
shall be at least 3 time units apart.
The magnet position (ğ‘ƒğ‘œğ‘ ) shall be higher than 3.2 within [0, 1]s, lower than 2.175 and higher than
1.825 within [2, 3]s, and higher than 1.75 and lower than 2.25 for 0.5s within whithin [2, 3]s.

The pitch angle shall be smaller than 14.2deg.
The torque shall be between 21000 and 47500NÂ·m.
The rotor speed shall be lower than 14.3rpm.
The absolute difference between the commanded and the measured pitch angles is lower than 1.6deg.

Within the interval [0, 100]ğ‘ , the difference between ğ‘¦5 and ğ‘¦4 shall be lower than 40.
For every instant in [0, 70]ğ‘ , the value of ğ‘¦5 âˆ’ ğ‘¦4 shall exceed 15 in one instant within the next 30s.
For every instant in [0, 70]ğ‘ , either ğ‘¦2 âˆ’ ğ‘¦1 shall be lower than 20 for the next 20s or the value of
ğ‘¦5 âˆ’ ğ‘¦4 shall be higher than 40 for the next 20s.
For every instant in [0, 65]s, within the next 30s, ğ‘¦5 âˆ’ ğ‘¦4 shall be higher than 8 for at least 20s.
For every time instant in [0, 72]s, if within the next 8s the value of ğ‘¦2 âˆ’ ğ‘¦1 is higher than 9 for at least
5s, after 5s the value of ğ‘¦5 âˆ’ ğ‘¦4 shall be higher than 9 and remain higher than 9 for the following 15s.
Within the interval [0, 50]ğ‘ , the difference between ğ‘¦ğ‘–+1 and ğ‘¦ğ‘– shall be higher than 7.5.
Within the interval [0, 15]ğ‘ , the altitude shall be higher than 0.

Within the interval [30, 35]ğ‘ , the pressure shall be lower than 87.5 and higher than 87.

ğ‘“ ğ‘ğ‘™ğ‘™ = (ğœƒ > 40.0) âˆ§ ( F [0,0.005] (ğœƒ < 8.8)),

0 â‰¤ ğœƒ < 61.2

To evaluate the effectiveness of the tools, we considered a bench-
mark made by seven models and 27 requirements. We evaluate the
capability of each tool in generating failure-revealing test cases.
To assess the efficiency of the tools, we compare the number of
search iterations (see figure 1) required by each tool to generate
the failure-revealing test cases.

To assess the applicability (RQ3) of ATheNA-S, we evaluate its
effectiveness and efficiency in a large and representative case study
from the automotive domain. We inject a fault in the model by
relying on the insights of a lead engineer in a large automotive
company and evaluate whether ATheNA-S could generate a failure-
revealing test case.

Implementation and Data Availability. Our (sanitized) models,

data, and tool are publicly available [17].

5.1 Effectiveness â€” RQ1
We compare the effectiveness of S-Taliro, ATheNA-SM and ATheNA-S
in generating failure-revealing test cases.

Benchmark. We consider the models of the ARCH competi-
tion [33] â€“ an international competition among testing tools for
continuous and hybrid systems [11]. This benchmark consists of
seven models: Automatic Transmission (AT), Fuel Control on Auto-
motive Powertrain (AFC), Neural Network Controller (NN), Wind

6

Search-based Software Testing Driven by Automatically Generated and Manually Defined Fitness Functions

Table 3: Interpolation function (int), value range (R and Râ€²), and number of control points (n) for the input signals.

RID

int

R

Râ€²

n

RID int

R

Râ€²

n

[0, 100], [0, 325]
[0, 100], [0, 325]
[0, 100], [0, 325]
[0, 100], [0, 325]
[0, 100], [0, 325]
[0, 100], [0, 325]
[0, 100], [0, 325]
[0, 100], [0, 325]
[0, 100], [0, 325]
[0, 100], [0, 325]

pchip,pchip
AT1
pchip,pchip
AT2
pchip,pchip
AT51
pchip,pchip
AT52
pchip,pchip
AT53
pchip,pchip
AT54
pchip,pchip
AT6a
pchip,pchip
AT6b
pchip,pchip
AT6c
AT6abc pchip,pchip
AFC27
AFC29
AFC33
NN

const,pconst [900, 1100], [0, 61.2]
const,pconst [900, 1100], [0, 61.2]
const,pconst [900, 1100], [61.2, 81.2]
[1, 3]
pchip

[0, 110], [0, 100]
[0, 90], [32, 325]

7, 3
7, 3
7, 3
7, 3
7, 3
7, 3
[0, 47], [172, 325] 7, 3
[0, 48], [169, 325] 7, 3
[0, 44], [182, 325] 7, 3
[0, 44], [182, 325] 7, 3
1, 10
1, 10
1, 10
3

[1, 2]

NNx pchip
WT1 pchip
WT2 pchip
WT3 pchip
WT4 pchip
pchip,pchip
CC1
pchip,pchip
CC2
pchip,pchip
CC3
pchip,pchip
CC4
CC5
pchip,pchip
CCx pchip,pchip
const,const,
F16
const
pchip,pchip

SC

[1.95, 2.05]
[8, 16]
[8, 16]
[8, 16]
[8, 16]
[0, 1], [0, 1]
[0, 1], [0, 1]
[0, 1], [0, 1]
[0, 1], [0, 1]
[0, 1], [0, 1]
[0, 1], [0, 1]
[0.63, 0.89], [âˆ’1.26, âˆ’1.10],
[âˆ’1.18, âˆ’0.39]
[3.99, 4.01]

[0, 0.82], [0.18, 1]

[1.95, 2.14]
[7.5, 16.5]

3
126
126
126
126
7, 3
7, 3
7, 3
7, 3
7, 3
7, 3
[0.16, 0.89], [âˆ’1.26, âˆ’0.63], 1, 1,
[âˆ’1.83, âˆ’0.39]
[3.984, 4.016]

1
20

pchip: piecewise cubic,

const: constant signal,

pconst: piecewise constant signal.

Table 4: Manual fitness functions description for our benchmark requirements.

RID

Manual Fitness Description

Maximizes the lowest throttle value within [0, 17]s and minimizes the highest brake value within [0, 25]s.
AT1
Maximizes the average throttle value within [0, 8]s, then minimizes the average brake value within [0, 25]s.
AT2
Maximizes the lowest throttle value within [0, 33]s and minimizes the highest brake value within [0, 25]s.
AT51
Maximizes the lowest throttle value within [0, 33]s and minimizes the highest brake value within [0, 25]s.
AT52
Maximizes the lowest throttle value within [0, 33]s and minimizes the highest brake value within [0, 25]s.
AT53
Maximizes the lowest throttle value within [0, 33]s and minimizes the highest brake value within [0, 25]s.
AT54
Makes the average throttle value within [0, 33]s as close as possible to 45% and minimizes the average brake value within [0, 25]s.
AT6a
Makes the average throttle value within [0, 33]s as close as possible to 45% and minimizes the average brake value within [0, 25]s.
AT6b
Makes the average throttle value within [0, 33]s as close as possible to 45% and minimizes the average brake value within [0, 25]s.
AT6c
AT6abc Makes the average throttle value within [0, 33]s as close as possible to 45% and minimizes the average brake value within [0, 25]s.

AFC27
AFC29
AFC33

Increases the two control points adjacent to the lowest one until they are both above 40 deg, then minimizes the lowest value within [10, 50]s.
Minimizes the lowest throttle value within [10, 50]s.
Minimizes the engine speed value.

NN
NNx

WT1
WT2
WT3
WT4

CC1
CC2
CC3
CC4
CC5
CCx

F16

SC

Minimizes the reference position control point at 20s.
Maximizes the lowest reference position within [0, 20]s.
Maximizes the steepest positive slope between two consecutive control points within [30, 630]s.
Maximizes the steepest negative slope between two consecutive control points within [30, 630]s.
Maximizes the steepest positive slope between two consecutive control points within [30, 630]s.
Maximizes the average distance between consecutive control points within [30, 630]s.
Maximizes the lowest throttle value within [0, 100]s and minimizes the highest brake value within [0, 100]s.
Minimizes the highest throttle value within [0, 100]s and maximizes the lowest brake value within [0, 100]s.
Maximizes the lowest throttle value within [0, 100]s and minimizes the highest brake value within [0, 100]s.
Minimizes the minimum distance between car 4 and 5 within [0, 100]s.
Makes the average throttle value within [0, 33]s as close as possible to 0.3 and maximizes the average brake value within [0, 50]s.
Maximizes the throttle control point at 0ğ‘  and minimizes the throttle control point at 17ğ‘ .

Maximizes the initial roll angle and minimizes the initial pitch angle.

Maximizes the peak-to-peak distance of the steam flow rate within [29.5, 35]s.

Turbine (WT), Chasing Cars (CC), Aircraft Ground Collision Avoid-
ance System (F16), and Steam Condenser (SC). For each model,
Table 1 contains a model identifier (MID), a short description of
the model, the number of SimulinkÂ® blocks (#Blocks), inports (#In-
port), outports (#Outport), simulation time (Ts), and number of
requirements (#Reqs). The number of blocks, inports, and outputs
respectively varies across the different models.

The models of the ARCH competition are associated with the 27
requirements presented in Table 2. Table 2 presents the STL specifi-
cation and a short description for each requirement. Requirements
are associated with a requirement identifier (RID) that starts with
the identifier of the model. For example, the requirement with iden-
tifier AT54 refers to the AT model. The symbols â€œGâ€ and â€œF â€ used
in the STL specification represent the â€œgloballyâ€ and â€œeventuallyâ€

temporal operators. The â€œgloballyâ€ temporal operator is discussed
in Section 3. The â€œeventuallyâ€ temporal operator is labeled with a
subscript containing the time interval to consider when assessing
the operator. For example, â€œF [0,10] â€ indicates that the â€œeventuallyâ€
temporal operator must be assessed over the time interval [0, 10]s.
The operator scopes a condition that shall eventually hold within
the time interval. For example, â€œF [0,10] ğ‘¥ < 5â€ indicates that the
value of ğ‘¥ shall be lower than 5 at some point within the inter-
val [0, 10]s. The requirements of our benchmark have a different
structure and use various temporal operators.

For each requirement, Table 3 presents the assumptions con-
sidered in the ARCH competition that we use for generating the
test cases. Specifically, for each requirement of our benchmark, the
table reports the interpolation function (ğ‘–ğ‘›ğ‘¡), value range (ğ‘… and ğ‘…â€²),

7

Table 5: Percentage of failure-revealing runs for each of the tool and assumption-requirement combination of Table 3.

RID

AT1
AT2
AT51
AT52
AT53
AT54
AT6a
AT6b
AT6c

S-Taliro

ATheNA-SM

ATheNA-S

0 % (18 %)
100 % (92 %)
100 %
100 %
100 %
100 %
100 % (58 %)
88 % (38 %)
90 % (6 %)

2 % (78 %)
100 % (88 %)
100 %
100 %
100 %
100 %
40 % (36 %)
34 % (32 %)
54 % (32 %)

2 % (78 %)
100 % (92 %)
100 %
100 %
100 %
100 %
96 % (86 %)
92 % (56 %)
90 % (18 %)

RID

AT6abc
AFC27
AFC29
AFC33
NN
NNx
WT1
WT2
WT3

S-Taliro

ATheNA-SM

ATheNA-S

96 % (6 %)
38 %
100 %
0 %

74 % (78 %)
0 % (90 %)
2 % (94 %)
92 %
92 %

46 % (32 %)
52 %
100 %
0 %

68 % (86 %)
0 % (100 %)
2 % (94 %)
92 %
82 %

98 % (18 %)
48 %
100 %
0 %

68 % (82 %)
0 % (100 %)
4 % (96 %)
92 %
90 %

RID

WT4
CC1
CC2
CC3
CC4
CC5
CCX
F16
SC

S-Taliro

ATheNA-SM

ATheNA-S

50 %
100 % (100 %)
84 %
92 %
0 %
84 %
62 %
76 % (90 %)
0 % (34 %)

42 %
98 % (96 %)
92 %
88 %
0 %
98 %
42 %
100 % (98 %)
0 % (30 %)

58 %
100 % (100 %)
96 %
94 %
6 %
98 %
80 %
100 % (96 %)
0 % (34 %)

Formica, et al.

and the number of control points (ğ‘›) considered for generating the
test input signals. Comma-separated values are related to different
input signals. For example, for AT1, [0, 100] and [0, 325] are respec-
tively the value ranges considered for generating the Throttle and
the Brake input signals. Notice that while the configuration of the
ARCH competition includes the input ranges, it does not include
the number of control points and the interpolation functions as
different SBST frameworks can use different strategies to generate
the input signals. Thus, we select the setting used by Aristeo in the
last competition since the complete replication package is publicly
available [13]. For some of the requirements for which the tools
are showing a similar behavior considering the value range ğ‘… of
the ARCH 2021 competition (see the Results paragraph), we con-
sider an additional value range ğ‘…â€² that enables a wider comparison
between the tools.

In total, Table 3 leads to 39 assumption-requirement combina-
tions. Each combination consists of a requirement and an assump-
tion generated by considering the interpolation function, the num-
ber of control points, and one of the value ranges specified for
that requirement. For example, two combinations are present for
requirement AT1, generated by considering value ranges ğ‘… and ğ‘…â€².
In our evaluation, we compare the behavior of the different tools
by considering each assumption-requirement combination.

Configuration of the Tools. We configure our tools as follows.
For S-Taliro, we use its Simulated Annealing, its default search
algorithm. We set the value 300 for the maximum number of itera-
tions since this is the value considered by the ARCH competition.
We configure ATheNA-SM by designing a manual fitness func-
tion for each requirement by reverse-engineering the model and
performing some trial error experiments. Table 4 presents the man-
ual fitness functions defined for each requirement. For example,
for the AT1 requirement, we design a fitness function that max-
imizes the value of Throttle and minimizes the value of Brake
(Section 3). Since ATheNA-SM relies on S-Taliro, we considered
the same configuration as S-Taliro for the common parameters.
We configure ATheNA-S by considering the implementation of
the method athenaFitness that equally prioritizes the manual and
the automated fitness functions (Listing 1). For the other parameters
we considered the same configuration of ATheNA-SM.

Methodology. We execute S-Taliro, ATheNA-SM, and ATheNA-S
for each of the 39 assumption-requirement combinations of Table 3.
For each combination, we run each experiment 50 times to consider
the stochastic nature of the algorithm, as done in similar works
(e.g., [67]) and mandated by the ARCH competition [33]. We run
our experiments on a large computing platform and, for each tool,

we record which of the 50 runs is a failure-revealing run, i.e., it
returns a failure-revealing test case.

Results. Running all the experiments required approximately
35 days. We reduced the time to seven days by exploiting the paral-
lelization facilities of our computing platform.1

For each tool and assumption-requirement combination, Table 5
presents the percentage of failure-revealing runs (over 50 runs). The
table reports the results obtained by considering the assumption-
requirement combination obtained by considering the value range
ğ‘…, and the one obtained by considering the value range ğ‘…â€² (within
round brackets). For example, for the AT1 requirement, S-Taliro
returned a failure-revealing test case for 0% and 18% of the runs for
the assumptions obtained from the value ranges ğ‘… and ğ‘…â€².

For â‰ˆ 79% of the combinations (31 out of 39), represented using
non-bold characters in Table 5, the percentage of failure-revealing
runs of ATheNA-S is higher than or equal to the one of S-Taliro
and ATheNA-SM. For these combinations, ATheNA-S has to be pre-
ferred since, in the worst-case, it works as the best among S-Taliro
and ATheNA-SM. The increment ATheNA-S provides on the percent-
age of failure-revealing runs is on average 6.8% (min=0%, max=60%,
StdDev=12.6%) when ATheNA-S is compared with S-Taliro, and
it is 9.9% (min=0%, max=58%, StdDev=17.5%) when ATheNA-S is
compared with ATheNA-SM.

Remarkably, unlike S-Taliro and ATheNA-SM, ATheNA-S gener-
ated failure-revealing test cases for CC4, i.e., ATheNA-S detected
failures other tools could not find.

For only â‰ˆ 21% of the assumption-requirement combinations (8
out of 39), represented using bold characters in Table 5, ATheNA-S
generated less failure-revealing runs than (at least one of) the base-
lines. For these cases, the penalty of ATheNA-S is negligible: the
percentage of failure-revealing runs is only 4% (for AT6a), 14% (for
AT6c), 14% (for AT6abc), 4% (for AFC27), 6% and 4% (for NN), 2%
(for WT3), 2% (for F16) lower than the best baseline framework. The
decrement of ATheNA-S in the percentage of failure-revealing runs
is on average 4.0% (min=2%, max=6%, StdDev=2.0%) when it is com-
pared with S-Taliro and 7.6% (min=2%, max=14%, StdDev=5.9%)
when it is compared with ATheNA-SM.

Considering all the 39 assumption-requirement combinations,
the percentage of failure-revealing runs of ATheNA-S is on average
6.3% (min=âˆ’6%, max=60%, StdDev=11.6%) and 8.6% (min=âˆ’14%,
max=58%, StdDev=18.5%) higher than S-Taliro and ATheNA-SM.

11109 nodes, 64 cores, memory 249G or 2057500M, CPU 2 x AMD Rome 7532 2.40
GHz 256M cache L3.

8

Search-based Software Testing Driven by Automatically Generated and Manually Defined Fitness Functions

RQ2 - Efficiency

The answer to RQ2 is that, for our assumption-requirement
combinations, ATheNA-S requires slightly more iterations
than S-Taliro (avg=6.9, min=âˆ’61.5, max=72.2, StdDev=24.8),
and slightly less than ATheNA-SM (avg=âˆ’1.6, min=âˆ’116.5,
max=42.0, StdDev=27.1) to generate failure-revealing test
cases.

5.3 Usefulness â€” RQ3
To assess the usefulness of ATheNA-S, we evaluate its applicability
to a large automotive case study.

Case Study. Our case study is the SimulinkÂ® model of a hybrid-
electric vehicle (HEV) developed for the EcoCAR Mobility Chal-
lenge [30], a competition sponsored by the U.S. Department of
Energy [25], General Motors [39], and MathWorks [60]. The HEV
motor converts electrical energy into mechanical energy. A soft-
ware controller regulates the behavior of the motor.

The HEV model includes multiple subsystems built using Add-
Ons components of SimulinkÂ®, including Simscape [83], Simscape
Electrical [84], and Simscape Driveline [28]. The controller is mod-
eled with SimulinkÂ® Stateflow [86]. The controller input is the speed
demand, i.e., the required speed in Kph (kilometer per hour), and
its output is the vehicle speed. The HEV model contains three input
exemplars with the speed demand for three urban driving scenarios.
Methodology. To generate realistic driving scenarios, we con-
sider one of the three urban driving scenarios exemplars and slightly
variate the speed demand. Specifically, we add the input signal
delta_i_speed to the HEV model that represents the variation
applied to the speed demand of the urban driving scenario we con-
sidered. We set the value 400s for the simulation time, since it is
the simulation time provided for the HEV mdoel.

To use ATheNA-S, we first need to design assumptions for the
delta_i_speed input signal. We set [0, 4]Kph as the value range
for the assumption since it is a sufficiently small range for the varia-
tion of the speed demand. We consider five control points to ensure
speed variations occurring every 100s. We set the pchip interpola-
tion function [74] since it generates smooth and continuous signals
for the variations of the speed demand.

The requirement we consider specifies that the difference be-
tween the desired speed and the vehicle speed after 0.7s shall be
lower than a threshold value. We express the requirement in STL as

G [0,400] (delta_o_speed < threshold),
The variable delta_o_speed represents an output signal comput-
ing the difference between the vehicle speed and the desired demand
0.7s before. The temporal operator G [0,400] requires the value of
delta_o_speed to be lower than the threshold value within the
interval [0, 400]s. We set 3Kph for the threshold value since, for the
urban driving scenario we considered, delta_o_speed was always
lower than this value.

To prioritize inputs that generate significant changes for the
speed demand, we define a manual fitness function that minimizes
and maximizes the values of two consecutive control points of the
input signal delta_i_speed. We use the implementation for the
method athenaFitness from Listing 1 since it equally prioritizes
the manual and the automated fitness functions.

Figure 4: Number of iterations of S-Taliro, ATheNA-SM, and
ATheNA. Diamonds depict the average.

The Wilcoxon rank sum test [65] confirms that ATheNA-S gen-
erates more failure-revealing runs than S-Taliro and ATheNA-SM
with level of significance 0.174.
RQ1 - Effectiveness

The answer to RQ1 is that, ATheNA-S is preferrable over the
baseline tools for â‰ˆ 79% of our assumption-requirement com-
binations. ATheNA-S generated on average 6.3% (min=âˆ’6%,
max=60%, StdDev=11.6%) and 8.6% (min=âˆ’14%, max=58%,
StdDev=18.5%) more failure-revealing runs than S-Taliro
and ATheNA-SM. For one combination, unlike S-Taliro and
ATheNA-SM, ATheNA-S generated failure-revealing test cases.

5.2 Efficiency â€” RQ2
To compare the efficiency of S-Taliro, ATheNA-SM, and ATheNA-S
in generating failure-revealing test cases, we proceed as follows.

Methodology. We analyze the results of the experiment con-
ducted for answering RQ1. Since for each iteration, the difference
in the execution time of S-Taliro, ATheNA-SM, and ATheNA-S is
negligible, we use the number of iterations as the metric to compare
the efficiency of the considered tools. For each tool, we consider
the failure-revealing runs from RQ1 and extract the number of
iterations required to generate the failure-revealing test cases.

Results. The box plots in figure 4 report the number of iter-
ations S-Taliro, ATheNA-SM, and ATheNA-S require to generate
the failure-revealing test cases. Our results show that ATheNA-S
requires on average more iterations than S-Taliro (avg=6.9, min=
âˆ’61.5, max=72.2, StdDev=24.8) and less iterations than ATheNA-SM
(avg=âˆ’1.6, min=âˆ’116.5, max=42.0, StdDev=27.1). However, the
overhead ATheNA-S brings about over S-Taliro tools is negligible:
the time required by ATheNA-S to perform one iteration for the
WT model, the model that requires the highest time to perform an
iteration, is 3s. Therefore, for the model with the highest simulation
time, the average overhead introduced by ATheNA-S is only 21s
(3s Ã— 6.9iterations). This is acceptable for practical applications
since the maximum overhead (less than 1m) is significantly lower
than the time required to develop the models, typically months for
large industrial models [21].

The Wilcoxon rank sum test [65] confirms that, for the tools we
compared, there is no statistical difference between the number of
iterations required to generate failure-revealing test cases (p=0.05).

9

We set the value 300 for the number of iterations. Then, we
run ATheNA-S once. As expected, ATheNA-S could not generate any
failure-revealing test case.

We use the insights of a lead engineer from a large automotive
company to inject a representative fault in the model: we change
the threshold that makes the car switch from the Cruise_mode to
the Accelerate_mode by 50%.

We run ATheNA-S and check whether it could generate failure-

revealing test cases for the faulty model.

Results. ATheNA-S generated a failure-revealing test in 12 itera-

ATheNA-S explicitly targets SimulinkÂ® models. Other instances of
ATheNA can target different model types or software programs. We
conjecture that our results are also generalizable to these domains.
More empirical studies, such as that presented in this paper, will
determine whether our conjecture holds.

Internal Validity. The values assigned to the configuration param-
eters of our tools are a threat to the internal validity of our results.
However, our configuration does not favor any of the frameworks
as the common configuration parameters of S-Taliro, ATheNA-SM,
and ATheNA share the same values.

Formica, et al.

tions requiring 199s (â‰ˆ3min).
RQ3 - Usefulness

The answer to RQ3 is that, ATheNA-S was able to compute a
failure-revealing test case for a large automotive case study.

6 DISCUSSION AND THREATS TO VALIDITY
For the benchmark models and requirements we consider, our re-
sults show that ATheNA-S is more effective in detecting failure-
revealing test cases than the baseline frameworks with no signif-
icant performance overhead. Additionally, ATheNA-S was able to
generate a failure-revealing test case for CC4 the baselines could
not find. Finally, ATheNA-S was able to generate a failure-revealing
test case for our case study. Based on these results, we recommend
the following workflow. Engineers should initially use SBST frame-
works based on automated fitness functions since they do not re-
quire manual effort to define the fitness functions and may already
return failure-revealing test cases. If no failure-revealing test case
is detected, engineers should use SBST frameworks based on man-
ually defined fitness functions since they guide the search toward
portions of the input domain that are more likely to contain fail-
ures. Finally, engineers should use SBST frameworks that combine
automatically generated and manually defined fitness functions
and can detect failures other frameworks can not find.

External Validity. The selection of the models and requirements
is a threat to the external validity of our results. However, the
benchmark models considered in RQ1 and RQ2 (a) were extensively
used in the SBST literature (e.g., [27, 33, 34, 37, 47, 67]), (b) are
representative from different CPS systems, i.e., AT, AFC, CC are
from the automotive domain, NN is from the ML domain, WT
is from the electrical domain, F16 is from the aerospace domain,
(c) some of the models were developed by engineers working in
the industry, i.e., AFC is from Toyota [47]. The case study used to
answer RQ3 is a large and complex case study representative of
industrial systems developed by MathWorks [60] and linked to the
EcoCAR Mobility Challenge [30], a competition sponsored by the
U.S. Department of Energy [25], General Motors [39].

The reverse-engineering process we used to define the man-
ual fitness functions for ATheNA-SM (see Section 5.1), the fitness
function of ATheNA-S, and the fault we injected are a threat to the
external validity of our results. However, the results of ATheNA-SM
and ATheNA-S are likely to improve when the designers of the fit-
ness functions are knowledgeable about the domain and engineered
the SimulinkÂ® models. For the fault definition, we use the insights
of a lead engineer in a large automotive company.

10

7 RELATED WORK
Despite the vast research literature on SBST and the considerable
number of surveys on the topic (e.g., [6, 22, 43, 50, 53, 69]), we
did not find any existing work classifying fitness functions into
automatically generated and manually defined. In addition, we are
not aware of any work proposing a framework that combines these
two types of fitness functions. Therefore, this section summarizes
related work targeting either automatically generated or manually
defined fitness functions.

Automated generation of fitness function techniques often com-
pute fitness functions from logic-based specifications (e.g., [27,
35, 36, 68, 73]). Well established SBST tools, such as Breach [26],
S-Taliro [10], Aristeo [67], and FalStar [93], rely on these fit-
ness functions. For each atomic proposition, these fitness functions
typically compute a value indicating a satisfaction degree for the
proposition at every time instant. There are alternative ways to
compute fitness values associated with temporal operators, such
as the use of min and max operators [35, 36], distance operators
computing smooth approximations of the min and max operators
(e.g., [73]), arithmetic and geometric mean along a time interval
(e.g., [56, 66, 92]), cumulative values over a time horizon (e.g., [41]).
Some approaches also consider perturbations that may shift the
signal values over time to compute the fitness value (e.g., [27]).

A variety of manually defined fitness functions was proposed
in the literature. Manually defined fitness functions can guide the
search to produce test outputs with diverse shapes [63], maximize
or minimize the outputs of a system characterizing its critical be-
havior [20], maximize diversity in output signals [64], quantify the
difference between a reference and an output signal [15], and mini-
mize the difference between the expected and simulated behaviour
of a CPS [46]. Many manually defined fitness functions were also
proposed to guide SBST frameworks that analyze software code. For
example, some recent manually defined fitness functions measure
line coverage, input coverage, output coverage (e.g., [49]), branch
distances (e.g., [72]), test length, method sequence diversity, and
crash distance [24], the cumulative number of defects and the total
amount of code to inspect [71]. Manually defined fitness functions
can also compute exploration measures [61], and combine of cover-
age based and feature interaction measures [4].

Differently from these works, we proposed a framework that
combines automatically generated and manually defined fitness
functions and showed the benefits of our framework by considering
a large benchmark made by seven models and 27 requirements and
one complex case study from the automotive domain.

Search-based Software Testing Driven by Automatically Generated and Manually Defined Fitness Functions

8 CONCLUSION
We presented ATheNA, a novel SBST framework that combines au-
tomatically generated and manually defined fitness functions. We
defined ATheNA-S, an instance of ATheNA that supports SimulinkÂ®
models. We assessed the benefits of ATheNA-S in generating failure-
revealing test cases. ATheNA-S is preferrable over the baseline tools
for â‰ˆ 79% of our assumption-requirement combinations we consid-
ered in our evaluation. ATheNA-S generated more failure-revealing
test cases than two baseline SBST frameworks that rely on automat-
ically generated (+6.3%) and manually defined (+8.6%) fitness func-
tions. ATheNA-S did not show statistically significant differences
in efficiency compared with the baseline tools. Finally, ATheNA-S
generated a failure-revealing test case for a large representative
automotive case study. We discussed the impacts of our results on
software engineering practices, and we suggested a workflow that
combines ATheNA and SBST frameworks driven by automatically
generated and manually defined fitness functions.

ACKNOWLEDGMENTS
We acknowledge the support of the Natural Sciences and Engi-
neering Research Council of Canada (NSERC), [funding reference
number RGPIN-2022-04622].

This research was enabled in part by support provided by Com-
pute Ontario (www.computeontario.ca) and Compute Canada (www.
computecanada.ca).

REFERENCES
[1] 2021. Computer Safety, Reliability, and Security (SAFECOMP). Springer. https:

//doi.org/10.1007/978-3-030-83903-1

[2] Houssam Abbas, Bardh Hoxha, Georgios Fainekos, and Koichi Ueda. 2014.
Robustness-guided temporal logic testing and verification for stochastic cyber-
physical systems. In International Conference on Cyber Technology in Automation,
Control and Intelligent. IEEE, 1â€“6.

[3] Houssam Abbas, Andrew Winn, Georgios Fainekos, and A Agung Julius. 2014.
Functional gradient descent method for metric temporal logic specifications. In
American Control Conference. IEEE, 2312â€“2317.

[4] Raja Ben Abdessalem, Annibale Panichella, Shiva Nejati, Lionel C Briand, and
Thomas Stifter. 2018. Testing autonomous cars for feature interaction failures
using many-objective search. In International Conference on Automated Software
Engineering. IEEE, 143â€“154.

[5] Aldeida Aleti, Irene Moser, and Lars Grunske. 2017. Analysing the fitness land-
scape of search-based software testing problems. Automated Software Engineering
24, 3 (2017), 603â€“621. https://doi.org/10.1007/s10515-016-0197-7

[6] Shaukat Ali, Lionel C. Briand, Hadi Hemmati, and Rajwinder Kaur Panesar-
Walawege. 2010. A Systematic Review of the Application and Empirical Inves-
tigation of Search-Based Test Case Generation. IEEE Transactions on Software
Engineering 36, 6 (2010), 742â€“762. https://doi.org/10.1109/TSE.2009.52

[7] Hussein Almulla and Gregory Gay. 2020. Learning How to Search: Generating
Exception-Triggering Tests Through Adaptive Fitness Function Selection. In
International Conference on Software Testing, Validation and Verification. IEEE,
63â€“73.

[8] Harald Altinger, Franz Wotawa, and Markus Schurius. 2014. Testing Methods
Used in the Automotive Industry: Results from a Survey. In Joining AcadeMiA
and Industry Contributions to Test Automation and Model-Based Testing. ACM,
1â€“6.

[9] Boukhdhir Amal, Marouane Kessentini, Slim Bechikh, Josselin Dea, and Lam-
jed Ben Said. 2014. On the Use of Machine Learning and Search-Based Software
Engineering for Ill-Defined Fitness Function: A Case Study on Software Refactor-
ing. In International Symposium on Search-Based Software Engineering. Springer,
31â€“45.

[10] Yashwanth Annpureddy, Che Liu, Georgios Fainekos, and Sriram Sankara-
narayanan. 2011. S-TaLiRo: A Tool for Temporal Logic Falsification for Hybrid
Systems. In Tools and Algorithms for the Construction and Analysis of Systems.
Springer, 254â€“257.

[11] ARCH 2022 [Online]. International Competition on Verifying Continuous and
Hybrid Systems. https://cps-vo.org/group/ARCH/FriendlyCompetition

[12] Andrea Arcuri and Lionel Briand. 2011. A practical guide for using statistical
tests to assess randomized algorithms in software engineering. In International
Conference on Software Engineering. ACM, 1â€“10.

[13] ARIsTEOWeb 2022 [Online]. ARIsTEO â€” AppRoxImation-based TEst generatiOn.

https://github.com/SNTSVV/ARIsTEO.

[14] Aitor Arrieta, Joseba A. Agirre, and Goiuria Sagardui. 2020. A Tool for the
Automatic Generation of Test Cases and Oracles for Simulation Models Based
on Functional Requirements. In International Conference on Software Testing,
Verification and Validation Workshops. ACM/IEEE, 1â€“5.

[15] Aitor Arrieta, Jon Ayerdi, Miren Illarramendi, Aitor Agirre, Goiuria Sagardui,
and Maite Arratibel. 2021. Using Machine Learning to Build Test Oracles: an
Industrial Case Study on Elevators Dispatching Algorithms. In International
Conference on Automation of Software Test. IEEE, 30â€“39.

[16] ATBenchmark 2022 [Online].

Modeling an Automatic Transmission
https://www.mathworks.com/help/simulink/slref/modeling-an-

Controller.
automatic-transmission-controller.html.

[17] ATheNA 2022 [Online]. ATheNA. https://github.com/ATheNA-SBST/ATheNA.
[18] AUT 2022 [Online]. Automotive Electrical System Simulation and Con-
trol. https://it.mathworks.com/matlabcentral/fileexchange/25674-automotive-
electrical-system-simulation-and-control.

[19] Anu Bajaj and Om Prakash Sangwan. 2019. A Systematic Literature Review
IEEE Access 7 (2019),

of Test Case Prioritization Using Genetic Algorithms.
126355â€“126375. https://doi.org/10.1109/ACCESS.2019.2938260

[20] Raja Ben Abdessalem, Shiva Nejati, Lionel C. Briand, and Thomas Stifter. 2018.
Testing Vision-Based Control Systems Using Learnable Evolutionary Algorithms.
In International Conference on Software Engineering. ACM, 1016â€“1026.

[21] Alexander Boll, Florian Brokhausen, Tiago Amorim, Timo Kehrer, and Andreas
Vogelsang. 2021. Characteristics, potentials, and limitations of open-source
Simulink projects for empirical research. Software and Systems Modeling 20, 6
(2021), 2111â€“2130.

[22] Matteo Brunetto, Giovanni Denaro, Leonardo Mariani, and Mauro PezzÃ¨. 2021.
On introducing automatic test case generation in practice: A success story and
lessons learned. Journal of Systems and Software 176 (2021), 110933.

[23] Max H. Cohen and Calin Belta. 2021. Model-Based Reinforcement Learning for
Approximate Optimal Control with Temporal Logic Specifications. In Interna-
tional Conference on Hybrid Systems: Computation and Control. ACM, 1â€“12.
[24] Pouria Derakhshanfar, Xavier Devroey, Andy Zaidman, Arie van Deursen, and
Annibale Panichella. 2020. Good Things Come In Threes: Improving Search-
based Crash Reproduction With Helper Objectives. In International Conference
on Automated Software Engineering. IEEE/ACM, 211â€“223.

[25] DOE 2022 [Online]. United States Department of Energy. httpshttps://www.

energy.gov/.

[26] Alexandre DonzÃ©. 2010. Breach, A Toolbox for Verification and Parameter Syn-
thesis of Hybrid Systems. In Computer Aided Verification. Springer, 167â€“170.
[27] Alexandre DonzÃ© and Oded Maler. 2010. Robust Satisfaction of Temporal Logic
over Real-Valued Signals. In Formal Modeling and Analysis of Timed Systems.
Springer, 92â€“106.

[28] Driveline 2022 [Online]. Simscape Driveline Model and simulate rotational
and translational mechanical systems. https://www.mathworks.com/products/
simscape-driveline.html.

[29] Pengfei Duan, Ying Zhou, Xufang Gong, and Bixin Li. 2018. A systematic mapping
study on the verification of cyber-physical systems. IEEE Access 6 (2018), 59043â€“
59064.

[30] EcoCAR 2022 [Online]. The EcoCAR Mobility Challenge . https://it.mathworks.

com/academia/student-competitions/ecocar.html.

[31] Gidon Ernst, Sean Sedwards, Zhenya Zhang, and Ichiro Hasuo. 2018. Fast Falsifi-
cation of Hybrid Systems using Probabilistically Adaptive Input. In International
Conference on Quantitative Evaluation of Systems. Springer, 165â€“181.

[32] Gidon Ernst, Sean Sedwards, Zhenya Zhang, and Ichiro Hasuo. 2021. Falsification
of hybrid systems using adaptive probabilistic search. Transactions on Modeling
and Computer Simulation (TOMACS) 31, 3 (2021), 1â€“22.

[33] Gidon Ernst et al. Paolo Arcaini, Ismail Bennani, Aniruddh Chandratre, Alexandre
DonzÃ©, Georgios Fainekos, Goran Frehse, Khouloud Gaaloul, Jun Inoue, Tanmay
Khandait, Logan Mathesen, Claudio Menghi, Giulia Pedrielli, Marc Pouzet, Masaki
Waga, Shakiba Yaghoubi, Yoriyuki Yamagata, and Zhenya Zhang. 2021. ARCH-
COMP Category Report: Falsification with Validation of Results. In Workshop
on Applied Verification of Continuous and Hybrid Systems, Vol. 80. EasyChair,
133â€“152.

[34] Georgios Fainekos, Bardh Hoxha, and Sriram Sankaranarayanan. 2019. Robust-
ness of specifications and its applications to falsification, parameter mining,
and runtime monitoring with S-TaLiRo. In International Conference on Runtime
Verification. Springer, 27â€“47.

[35] Georgios E Fainekos and George J Pappas. 2006. Robustness of temporal logic
specifications. In Formal Approaches to Software Testing and Runtime Verification.
Springer, 178â€“192.

[36] Georgios E Fainekos and George J Pappas. 2009. Robustness of temporal logic
specifications for continuous-time signals. Theoretical Computer Science 410, 42
(2009), 4262â€“4291. https://doi.org/10.1016/j.tcs.2009.06.021

11

[37] Ansgar Fehnker and Franjo IvanÄiÄ‡. 2004. Benchmarks for hybrid systems verifi-
cation. In International Workshop on Hybrid Systems: Computation and Control.
Springer, 326â€“341.

[38] Vahid Garousi, Michael Felderer, Ã‡aÄŸrÄ± Murat KarapÄ±Ã§ak, and UÄŸur YÄ±lmaz. 2018.
Testing embedded software: A survey of the literature. Information and Software
Technology 104 (2018), 14â€“45.

[39] GM 2022 [Online]. General Motors. https://www.gm.com/.
[40] GMD 2022 [Online]. General Motors recalling 4.3 million vehicles for airbag de-
fect. https://www.cbc.ca/news/business/general-motors-recall-airbag-software-
1.3755030.

[41] Iman Haghighi, Noushin Mehdipour, Ezio Bartocci, and Calin Belta. 2019. Control
from Signal Temporal Logic Specifications with Smooth Cumulative Quantitative
Semantics. In Conference on Decision and Control. IEEE, 4361â€“4366.

[42] M. Harman and J. Clark. 2004. Metrics are fitness functions too. In International

Symposium on Software Metrics. IEEE, 58â€“69.

[43] Mark Harman, Yue Jia, and Yuanyuan Zhang. 2015. Achievements, Open Problems
and Challenges for Search Based Software Testing. In International Conference on
Software Testing, Verification and Validation. IEEE, 1â€“12.

[44] Emma Hart and Peter Ross. 2001. Gavel-a new tool for genetic algorithm visual-

ization. Transactions on Evolutionary Computation 5, 4 (2001), 335â€“348.
[45] Honda 2022 [Online]. Honda recalls 1.4M U.S. vehicles for software, other
problems. https://www.nbcnews.com/business/consumer/honda-recalls-1-4m-
u-s-vehicles-software-other-problems-n1251496.

[46] Dmytro Humeniuk, Giuliano Antoniol, and Foutse Khomh. 2021. Data Driven
Testing of Cyber Physical Systems. In International Workshop on Search-Based
Software Testing. IEEE/ACM, 16â€“19.

[47] Xiaoqing Jin, Jyotirmoy V Deshmukh, James Kapinski, Koichi Ueda, and Ken Butts.
2014. Powertrain control verification benchmark. In International conference on
Hybrid systems: computation and control. ACM, 253â€“262.

[48] James Kapinski, Jyotirmoy V Deshmukh, Xiaoqing Jin, Hisahiro Ito, and Ken Butts.
2016. Simulation-based approaches for verification of embedded control systems:
An overview of traditional and advanced modeling, testing, and verification
techniques. IEEE Control Systems Magazine 36, 6 (2016), 45â€“64.

[49] Maria Kechagia, Xavier Devroey, Annibale Panichella, Georgios Gousios, and Arie
van Deursen. 2019. Effective and Efficient API Misuse Detection via Exception
Propagation and Search-Based Testing. In International Symposium on Software
Testing and Analysis. ACM SIGSOFT, 192â€“203.

[50] Manju Khari and Prabhat Kumar. 2019. An extensive evaluation of search-
based software testing: a review. Soft computing 23, 6 (2019), 1933â€“1946. https:
//doi.org/10.1007/s00500-017-2906-y

[51] Yong-Hyuk Kim and Byung-Ro Moon. 2002. Visualization of the fitness landscape,
A steady-state genetic search, and schema traces. In Annual Conference on Genetic
and Evolutionary Computation. Morgan Kaufmann, 686â€“686.

[52] Yong-Hyuk Kim and Byung-Ro Moon. 2003. New usage of Sammonâ€™s mapping
for genetic visualization. In Genetic and Evolutionary Computation Conference.
Springer, 1136â€“1147.

[53] Florian KlÃ¼ck, Martin Zimmermann, Franz Wotawa, and Mihai Nica. 2019. Per-
formance Comparison of Two Search-Based Testing Strategies for ADAS System
Validation. In International Conference on Testing Software and Systems. Springer,
140â€“156.

[54] LandRover 2022 [Online]. Software bug causes Land Rover recall. https://www.
themanufacturer.com/articles/almost-36500-jlr-vehicles-recalled-in-china/.
[55] Grischa Liebel, Nadja Marko, Matthias Tichy, Andrea Leitner, and JÃ¶rgen Hansson.
2018. Model-based engineering in the embedded systems domain: an industrial
survey on the state-of-practice. Software and Systems Modeling 17, 1 (2018),
91â€“113. https://doi.org/10.1007/s10270-016-0523-3

[56] Lars Lindemann and Dimos V. Dimarogonas. 2019. Robust control for signal
temporal logic specifications using discrete average space robustness. Automatica
101 (2019), 377â€“387.

[57] John J Majikes, Rahul Pandita, and Tao Xie. 2013. Literature review of test-
ing techniques for medical device software. In Medical Cyber-Physical Systems
Workshop. Citeseer.

[58] Oded Maler and Dejan Nickovic. 2004. Monitoring temporal properties of con-
In Formal Techniques, Modelling and Analysis of Timed and

tinuous signals.
Fault-Tolerant Systems. Springer, 152â€“166.

[59] Logan Mathesen, Shakiba Yaghoubi, Giulia Pedrielli, and Georgios Fainekos. 2019.
Falsification of Cyber-Physical Systems with Robustness Uncertainty Quantifi-
cation Through Stochic optimization with Adaptive Restart. In International
Conference on Automation Science and Engineering. IEEE, 991â€“997.
[60] MathWorks 2022 [Online]. MathWorks. https://www.mathworks.com.
[61] Reza Matinnejad, Shiva Nejati, Lionel Briand, and Thomas Brcukmann. 2014. MiL
Testing of Highly Configurable Continuous Controllers: Scalable Search Using
Surrogate Models. In International Conference on Automated Software Engineering.
ACM/IEEE, 163â€“174.

[62] Reza Matinnejad, Shiva Nejati, Lionel Briand, Thomas Bruckmann, and Claude
Poull. 2015. Search-based automated testing of continuous controllers: Frame-
work, tool support, and case studies. Information and Software Technology 57
(2015), 705â€“722. https://doi.org/10.1016/j.infsof.2014.05.007

12

Formica, et al.

[63] Reza Matinnejad, Shiva Nejati, Lionel C. Briand, and Thomas Bruckmann. 2016.
Automated Test Suite Generation for Time-Continuous Simulink Models. In
International Conference on Software Engineering. ACM/IEEE, 595â€“606.

[64] Reza Matinnejad, Shiva Nejati, Lionel C Briand, and Thomas Bruckmann. 2016.
Automated test suite generation for time-continuous simulink models. In Inter-
national Conference on Software Engineering. ACM, 595â€“606.
[65] John H McDonald. 2009. Handbook of biological statistics. Vol. 2.
[66] Noushin Mehdipour, Cristian-Ioan Vasile, and Calin Belta. 2019. Arithmetic-
Geometric Mean Robustness for Control from Signal Temporal Logic Specifica-
tions. In American Control Conference. IEEE, 1690â€“1695.

[67] Claudio Menghi, Shiva Nejati, Lionel Briand, and Yago Isasi Parache. 2020.
Approximation-Refinement Testing of Compute-Intensive Cyber-Physical Mod-
els: An Approach Based on System Identification. In International Conference on
Software Engineering. IEEE/ACM, 372â€“384.

[68] Claudio Menghi, Shiva Nejati, Khouloud Gaaloul, and Lionel C Briand. 2019. Gen-
erating automated and online test oracles for simulink models with continuous
and uncertain behaviors. In joint meeting on european software engineering con-
ference and symposium on the foundations of software engineering. ACM, 27â€“38.
[69] Andrew L. Nelson, Gregory J. Barlow, and Lefteris Doitsidis. 2009. Fitness func-
tions in evolutionary robotics: A survey and analysis. Robotics and Autonomous
Systems 57, 4 (2009), 345â€“370. https://doi.org/10.1016/j.robot.2008.09.009
[70] Truong Nghiem, Sriram Sankaranarayanan, Georgios Fainekos, Franjo IvanciÄ‡,
Aarti Gupta, and George J Pappas. 2010. Monte-carlo techniques for falsification
of temporal properties of non-linear hybrid systems. In International conference
on Hybrid systems: computation and control. ACM, 211â€“220.

[71] Annibale Panichella, Carol V. Alexandru, Sebastiano Panichella, Alberto Bacchelli,
and Harald C. Gall. 2016. A Search-Based Training Algorithm for Cost-Aware
Defect Prediction. In Genetic and Evolutionary Computation Conference. ACM,
1077â€“1084.

[72] Annibale Panichella, Fitsum Meshesha Kifetew, and Paolo Tonella. 2018. Auto-
mated Test Case Generation as a Many-Objective Optimisation Problem with
Dynamic Selection of the Targets. IEEE Transactions on Software Engineering 44,
2 (2018), 122â€“158. https://doi.org/10.1109/TSE.2017.2663435

[73] Yash Vardhan Pant, Houssam Abbas, and Rahul Mangharam. 2017. Smooth
operator: Control using the smooth robustness of temporal logic. In Conference
on Control Technology and Applications. IEEE, 1235â€“1240.

[74] PCHIP 2022 [Online]. Piecewise Cubic Hermite Interpolating Polynomial (PCHIP).

https://it.mathworks.com/help/matlab/ref/pchip.html.

[75] Hartmut Pohlheim. 1999. Visualization of evolutionary algorithms-set of stan-
dard techniques and multidimensional visualization. In Genetic and Evolutionary
Computation Conference, Vol. 1. 533â€“540.

[76] Zahra Ramezani, Alexandre DonzÃ©, Martin Fabian, and Knut Ã…kesson. 2021. Tem-
poral logic falsification of cyber-physical systems using input pulse generators.
EPiC Series in Computing 80 (2021), 195â€“202.

[77] Recall-problem 2022 [Online]. The auto industryâ€™s growing recall problemâ€”and
how to fix it. https://www.alixpartners.com/media/14438/ap_auto_industry_
recall_problem_jan_2018.pdf.

[78] Recalls 2022 [Online]. The Current State of Automotive Software Related Re-
calls. https://sibros.medium.com/the-current-state-of-automotive-software-
related-recalls-ef5ca95a88e2.

[79] Zahra Sadri-Moshkenani, Justin Bradley, and Gregg Rothermel. 2022. Survey
on test case generation, selection and prioritization for cyber-physical systems.
Software Testing, Verification and Reliability 32, 1 (2022), e1794.

[80] Omur Sahin and Bahriye Akay. 2016. Comparisons of metaheuristic algorithms
and fitness functions on software test data generation. Applied Soft Computing
49 (2016), 1202â€“1214. https://doi.org/10.1016/j.asoc.2016.09.045

[81] Alireza Salahirad, Hussein Almulla, and Gregory Gay. 2020. Choosing the fitness
function for the job: Automated generation of test suites that detect real faults.
Software Testing, Verification and Reliability 30, 7-8 (2020). https://doi.org/10.
1002/stvr.1758

[82] Sriram Sankaranarayanan and Georgios Fainekos. 2012. Simulating insulin
infusion pump risks by in-silico modeling of the insulin-glucose regulatory
system. In International Conference on Computational Methods in Systems Biology.
Springer, 322â€“341.

[83] Simscape 2022 [Online]. Simscape Model and simulate multidomain physical

systems. https://www.mathworks.com/products/simscape.html.

[84] SimscapeElectrical 2022 [Online]. Simscape Electrical Model and simulate elec-
tronic, mechatronic, and electrical power systems . https://www.mathworks.
com/products/simscape-electrical.html.

[85] Simulink 2022 [Online]. Simulate a Simulink model. https://it.mathworks.com/

help/simulink/slref/sim.html.

[86] Stateflow 2022 [Online]. Model and simulate decision logic using state machines

and flow charts. https://www.mathworks.com/products/stateflow.

[87] StellantiDefects 2022 [Online]. Stellantis recalls 370,000 Ram, Dodge vehi-
cles; Ford recalls 150,000 F-150s. https://www.autonews.com/regulation-safety/
stellantis-recalls-370000-ram-dodge-vehicles-ford-recalls-150000-f-150s.

Search-based Software Testing Driven by Automatically Generated and Manually Defined Fitness Functions

[88] TeslaCrash 2022 [Online]. A Tesla driver is charged in a crash involving Autopilot
that killed 2 people. https://www.npr.org/2022/01/18/1073857310/tesla-autopilot-
crash-charges.

[89] TeslaDefects 2022 [Online]. Tesla recalls over 26K U.S. vehicles over software
problem. https://globalnews.ca/news/8605915/tesla-recall-software-problem/.
[90] Cumhur Erkan Tuncali, Bardh Hoxha, Guohui Ding, Georgios Fainekos, and
Sriram Sankaranarayanan. 2018. Experience report: Application of falsification
methods on the UxAS system. In NASA Formal Methods Symposium. Springer,
452â€“459.

[91] Uber 2022 [Online]. How terrible software design decisions led to Uberâ€™s deadly
2018 crash. https://arstechnica.com/cars/2019/11/how-terrible-software-design-
decisions-led-to-ubers-deadly-2018-crash/.

[92] Peter Varnai and Dimos V. Dimarogonas. 2020. On Robustness Metrics for

Learning STL Tasks. In American Control Conference. IEEE, 5394â€“5399.

[93] Masaki Waga. 2020. Falsification of Cyber-Physical Systems with Robustness-
Guided Black-Box Checking. In International Conference on Hybrid Systems: Com-
putation and Control. ACM, Article 11, 13 pages.

[94] Masaki Waga. 2020. Falsification of cyber-physical systems with robustness-
guided black-box checking. In International Conference on Hybrid Systems: Com-
putation and Control. ACM, 11:1â€“11:13.

[95] Josh L. Wilkerson and Daniel R. Tauritz. 2011. A Guide for Fitness Function De-
sign. In Annual Conference Companion on Genetic and Evolutionary Computation.
ACM, 123â€“124.

[96] Xiong Xu, Li Jiao, and Ziming Zhu. 2018. A dynamic fitness function for search
based software testing. In Genetic and Evolutionary Computation Conference
Companion. IEEE, 320â€“321.

[97] Yoriyuki Yamagata, Shuang Liu, Takumi Akazaki, Yihai Duan, and Jianye Hao.
2021. Falsification of cyber-physical systems using deep reinforcement learning.
IEEE Transactions on Software Engineering 47, 12 (2021), 2823â€“2840.
https:
//doi.org/10.1109/TSE.2020.2969178

[98] Zhenya Zhang, Deyun Lyu, Paolo Arcaini, Lei Ma, Ichiro Hasuo, and Jianjun
Zhao. 2021. Effective Hybrid System Falsification Using Monte Carlo Tree Search
Guided by QB-Robustness. In Computer Aided Verification. Springer, 1â€“24.
[99] Xin Zhou, Xiaodong Gou, Tingting Huang, and Shunkun Yang. 2018. Review on
testing of cyber physical systems: Methods and testbeds. IEEE Access 6 (2018),
52179â€“52194.

13

