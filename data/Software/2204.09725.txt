Volumetric Benchmarking of Error Mitigation with Qermit

Cristina Cirstoiu1,4, Silas Dilkes1,4, Daniel Mills1,4, Seyon Sivarajah1, and Ross Duncan1,2,3

1Cambridge Quantum Computing Ltd, Terrington House, 13-15 Hills Road, Cambridge CB2 1NL, UK

2Department of Computer and Information Sciences, University of Strathclyde, 26 Richmond Street, Glasgow G1 1XH, UK

3Department of Physics and Astronomy, University College London, Gower Street, London, WC1E 6BT, UK

4These authors contributed equally

The detrimental eﬀect of noise accumulates
as quantum computers grow in size.
In the
case where devices are too small or noisy to
perform error correction, error mitigation may
be used. Error mitigation does not increase
the ﬁdelity of quantum states, but instead aims
to reduce the approximation error in quantities
of concern, such as expectation values of ob-
servables. However, it is as yet unclear which
circuit types, and devices of which character-
istics, beneﬁt most from the use of error mit-
igation. Here we develop a methodology to
assess the performance of quantum error mit-
igation techniques. Our benchmarks are volu-
metric in design, and are performed on diﬀer-
ent superconducting hardware devices. Exten-
sive classical simulations are also used for com-
parison. We use these benchmarks to identify
disconnects between the predicted and practi-
cal performance of error mitigation protocols,
and to identify the situations in which their use
is beneﬁcial. To perform these experiments,
and for the beneﬁt of the wider community,
we introduce Qermit – an open source python
package for quantum error mitigation. Qer-
mit supports a wide range of error mitigation
methods, is easily extensible and has a modu-
lar graph-based software design that facilitates
composition of error mitigation protocols and
subroutines.

1 Introduction

Noise inhibits the development of quantum processors
[1, 2]. Techniques for reducing the level and eﬀects
of noise have been proposed, and act at each layer in
the quantum computing stack. At the hardware level,
noise reduction may be achieved through calibration
[3], dynamical decoupling [4], pulse-level optimisation
[5], etc. At the highest level of abstraction, fault-
tolerant methods for encoding and processing infor-
mation with logical qubits may be used [6, 7].

Between these two extremes there exists two classes
of noise reduction techniques. The ﬁrst are those that
increase process ﬁdelity through operations at com-
pile time. This class includes noise-aware routing and

qubit allocation [8, 9], noise tailoring [10], and circuit
optimisation [9]. The second are those which do not
increase the ﬁdelity of prepared states directly, but
instead improve accuracy when measuring quantities
of concern, such as expected values of observables.

Several such error mitigation protocols have been
proposed, including Zero-Noise Extrapolation (ZNE)
[11–13], Probabilistic Error Cancellation (PEC) [11],
Cliﬀord Data Regression (CDR) [14], Virtual Distilla-
tion [15], and many others [16–18]. Importantly, both
of these classes of noise reduction techniques require
less information about the experimental setup than
do hardware level approaches. Additionally, neither
compile time error reduction nor error mitigation pro-
tocols require a signiﬁcant overhead in the number of
qubits, as in the case of error correction [19, 20]. This
often comes at the cost of an increase in the number
of circuits and shots in the case of error mitigation.

The importance of noise suppression at the hard-
ware and logical levels is clear as both are vital to
the development of scalable fault-tolerant quantum
processors. Compile time approaches to noise reduc-
tion have also been extensively benchmarked [21] and
shown to perform strongly. What’s unclear is the im-
pact of error mitigation. While proof of principle ex-
periments have shown improved accuracy when using
these techniques [11–14], there has been no systematic
study of their practical eﬀectiveness and limitations.
As such it is unclear which circuit dimensions and
types, nor quantum computing devices of which char-
acteristics, are well suited to the use of error mitiga-
tion. Indeed, the diﬀering assumptions made about
the underlying noise by each error mitigation protocol
may manifest as unpredictable practical performance.
We clarify the practical utility of error mitigation
by introducing and implementing a methodology for
the benchmarking of error mitigation protocols. Our
benchmarking experiments compare the accuracy of
operator expectation value calculations when a selec-
tion of error mitigation protocols are employed, and
when they are not.

The design of our benchmarks is inspired by vol-
umetric benchmarks of quantum processors [22], al-
lowing us to estimate the ‘volume’ of the circuit
depth and width where the error mitigation proto-
cols perform well. The particular circuits used are

1

2
2
0
2

r
p
A
0
2

]
h
p
-
t
n
a
u
q
[

1
v
5
2
7
9
0
.
4
0
2
2
:
v
i
X
r
a

 
 
 
 
 
 
constructed from a variety of application-motivated
circuit classes [21]. This ensures our benchmarks are
indicative of practical performance, which we use to
identify classes of computations where error mitiga-
tion may be used fruitfully. Taking a volumetric ap-
proach ensures that results of these benchmarks may
be quickly compared, and that a wide range of circuit
sizes are covered. In this work, we benchmark CDR
and ZNE, but our method is applicable to a broad
class of error mitigation protocols.

We conduct our experiment on real quantum com-
puting devices, and using classical simulators. How-
ever, each error mitigation method makes diﬀerent as-
sumptions about the underlying noise, and as such it
is diﬃcult to compare error mitigation methods using
noisy simulations without introducing bias. This is
particularly true since existing noise models are poor
predictors of hardware behaviour beyond a few qubits.
As such we perform our benchmarks on real hardware,
and demonstrate reduced performance as compared
with noisy classical simulation, across diﬀerent error
mitigation methods.

For the beneﬁt of the community, and in order to
conduct these benchmarking experiments, we have de-
veloped Qermit. Qermit is an open-source python
package for the design and automated execution of er-
ror mitigation protocols.1 The error mitigation proto-
cols presently available through Qermit include those
explored in our benchmarking experiments, namely
ZNE and CDR. Qermit also includes implementations
of PEC, error mitigation based on frame randomisa-
tion [10], and protocols performing correction through
characterisation of State Preparation And Measure-
ment (SPAM) errors. In all cases, several variations
of each protocol are provided. Qermit provides a
common interface to this selection of error mitigation
schemes, simplifying their use. Further, Qermit sup-
ports the straightforward construction and combina-
tion of error mitigation protocols and sub routines,
facilitating quick prototyping of new protocols. By
virtue of being implemented using Tket [9], Qermit
is platform-agnostic, and so may be used with a wide
range of quantum hardware, and in conjunction with
several common quantum software development kits.
The remainder of this paper is structured as follows.
In Section 2 we give an overview of error mitigation
and the particular schemes that we investigate in this
work. In Section 3 we introduce Qermit and details of
the implementations of CDR and ZNE. In Section 4
we introduce the design of our benchmarks, and the
philosophy that motivates them. In Section 5 we give
the results of the experiments we have conducted. Fi-

1Qermit is complementary to Mitiq [23], which is an open-
source Python toolkit that implements an overlapping set of er-
ror mitigation schemes. Qermit takes a diﬀerent approach that
breaks-down the implementation of each protocol into stan-
dalone modular units, to be easily re-used, modiﬁed and com-
posed.

nally we conclude in Section 6.

2 Quantum Error Mitigation

Error mitigation protocols typically have many steps
In Section 2.1 we describe a general
in common.
framework for error mitigation of observables which
takes into account the practical aspects of their im-
plementation on quantum hardware. Recent works
[24, 25] have also exploited these common features
to analyse the overhead in sample complexity, and to
determine (universal) lower bounds. Our approach fo-
cusses on the modularity of error mitigation protocols,
also exploited by the design of Qermit, and takes into
account all quantum and classical resources required
for an error mitigation experiment. In Section 2.2 and
Section 2.3 we use this framework to describe ZNE
and CDR. In Section 2.4 we describe the noise pro-
ﬁle assumptions that justify the design choices made
when developing ZNE and CDR.

2.1 Unifying Framework

Consider a target input quantum circuit given by a se-
quence of gates U = U1U2...Ud, an initial (pure) state
ρ0, and an observable O.2 The error mitigation pro-
tocols studied here output an estimator h ˆOiEM of the
true expectation value hOi = tr(U ρ0U †O). This esti-
mator should reduce the noise bias in the estimation
of this quantity on the backend.

To achieve this, error mitigation protocols run the
given circuit and/or other quantum circuits on back-
ends, such as quantum processing units or (noisy)
classical simulators. The outputs from backends are
binary strings, called shots, which may be combined
to produce, for example, expectation values.

In generating the estimator h ˆOiEM , many error

mitigation protocols employ the following steps.

Data Collection: The ﬁrst step consists of a noise
characterisation procedure N that takes as input
the target experiment(s) (U, ρ0, O), along with
a set of resource parameters R. R can include:
the total number of distinct circuits K, shots per
each circuit (ni)K
i=1, and allowed qubits; the type
and amount of classical simulation used; and the
backend q with ﬁxed speciﬁcations such as the
compilation strategy, architecture, and noise fea-
tures.

N involves (i) a series of sub-processes N1, ...,
NK, each of which modify the input circuit U in
a method-speciﬁc way and (ii) measurement cir-
cuits M1(O), ..., MM (O) with classical estimator
function om,i(z) for m = 1, ..., M and i = 1, ..., k
where z labels the measurements outcomes.

2This may also be extended to a class of circuits or a set of

observables.

2

The data collection step returns a set of (labelled)
complex parameters given by D = (Dq
),
i,m, Dc
indexed by each of the sub-processes, where

i,m

Dq

i,m

=

1

ni

niX

X

s=1

z

om,i(z)Zs(z)

(1)

indicator

with Zs an independent identically distributed
(i.i.d)
random variable over mea-
surement outcomes obtained from evaluating
Mm(O)Ni(U )(ρ0) on the quantum device q.
If
required and available, Dc
i,m corresponds to the
exact classical simulation.

of this function by artiﬁcially increasing the noise pa-
rameter to diﬀerent levels λ1, λ2, ..., λk. An extrap-
olation process then produces an estimate of the ex-
pected value for λ = 0, the ideal case where no phys-
ical errors occur.

There are several ways in which one may boost
physical errors aﬀecting a quantum circuit. One
method involves increasing the duration of pulses in-
volved in producing each gate within the circuit [11].
A second approach, which we review here, is to in-
troduce additional gates to obtain a higher depth but
equivalent unitary circuit [13].

Functional Model: An implicit mapping F (or a set
thereof) between the output parameters of the
noise characterisation step and the (unknown) er-
ror mitigated estimator h ˆOiEM so that

Data Collection: ZNE involves a series of sub-
processes Nλ1, ..., Nλk , that take the input circuit
U = U1U2 ... Ud and produce a modiﬁed (or folded,
using the terminology of [13]) circuit

F(D, h ˆOiEM ) = 0.

(2)

The speciﬁc form of this function is typically mo-
tivated by assumptions on the noise characteris-
tics of the quantum device.

Data Processing: This step, is completely classical
and aims to produce an output estimator h ˆOiEM
based on ﬁtting the data D to the functional
model F. Depending on the particular function
this may be a simple summation or a classical op-
timisation algorithm to determine the coeﬃcients
of F.

All the processes involved in producing D may be
described in the quantum combs formalism, which
generalises quantum channels to higher order opera-
tions [26]. N will generally depend on the type of noise
a particular method is aiming to mitigate. For exam-
ple, a set of the sub-processes and measurements may
be independent of U or O, with the aim to produce
(partial) tomographic information [11]. The frame-
work also allows for adaptive processes, which is to
say that Ni may depend on outcomes D1,m... Di−1,m
for a subset of the measurement circuits m. Typically
the Data Collection step will include the identity pro-
cess, which does not modify the circuit U or observ-
able, and produces a noisy (sample mean) estimator
h ˆOiN of the expectation value of the observable given
resources R.

2.2 Zero Noise Extrapolation

The Zero Noise Extrapolation (ZNE) method was
originally introduced in Refs. [11, 12] and assumes
that noise may be controlled by a parameter λ (or
more generally a set of parameters) which can be
viewed as a proxy for average gate error rates.

Then, for a given quantum circuit, the noisy expec-
tation value of a target observable will be a function
depending on λ. One may produce diﬀerent samples

1

2

d

)αi

)αi

Nλi

1 U2(C2C †

2 ... Ud(CdC †

(U ) = U1(C1C †

)αi
d .
(3)
Here CiC †
= I so as to not introduce logical error,
i
and αi
j are positive integers. There is ﬂexibility in the
choice of the Ci unitaries, and [13] analyse diﬀerent
d 6=
folding variations: (i) circuit folding when only αi
0 and Cd = U1...Ud, (ii) random gate folding with
Cj = Uj and αi
j chosen uniformly at random for a
ﬁxed noise level λi = P

+ 1).

the ﬁrst step will be D :=
The output of
(Dλ1 , Dλ2 , ..., Dλk
) where each entry is a sam-
ple mean estimator
expectation value
(U )]†) of the target observable with
tr(ONλi
respect to the modiﬁed circuit at each noise level,
given the ﬁxed set of resources (i.e number of shots).

(U )ρ0[Nλi

the

for

(2αi
j

j

In the case of ZNE, there are
Functional Model:
several possibilities for the data-ﬁtting functional. We
outline several below which have been explored in
Refs. [11, 13].

a) The polynomial extrapolation assumes that the
dependency on the noise level parameter λ can be
expressed as a truncated Taylor series so that the data
is ﬁtted to the function

Dλ = h ˆOiEM +

K
X

i=1

Fiλi,

(4)

with negligible higher order terms O(λK+1) and un-
known (complex) parameters Fi.
If the number of
data points, or equivalently in our case the number of
noise parameters k, is at least K + 1, the number of
unknown parameters, then the extrapolation is well
In the special case when k = K + 1 there
deﬁned.
are analytic expression to derive the coeﬃcients and
the method is referred to as Richardson extrapolation
[16].

b) The exponential extrapolation assumes the ex-
pected values of observables decay exponentially with

3

the noise level parameter λ and the data can then be
ﬁtted to

Dλ = e−λf h ˆOiEM + F (1 − e−λf )

(5)

c) The poly-exponential extrapolation assumes that
the exponential decay with the noise level has a poly-
nomial expansion so it is ﬁtted to the function

Dλ = e

PK

i=1

λiFi h ˆOiEM

(6)

2.3 Cliﬀord Data Regression

Cliﬀord Data Regression (CDR) [14] is a machine
learning approach to error mitigation. The method
relies on the idea that circuits containing a number of
T gates logarithmic in the number of qubits can be
eﬃciently simulated [27].

Data Collection: CDR involves a series of sub-
processes N0(U ) = U and N1, ..., Nk, each of which
modiﬁes the input U , synthesized into a universal Clif-
ford + T gate set, to produce a circuit where all ex-
cept a small number Nnc of T gates are replaced by a
single-qubit Cliﬀord gate {1, S, S†, Z}. The resulting
unitary circuits Ni(U ) are eﬃciently simulated clas-
sically and so measurements of O will involve both
quantum and classical evaluation. The output will
be D = (Dq
), ..., (Dq
)) where each pair
consists of the ideal classically simulated expectation
value of the target observable O with respect to the
(U )]†) and re-
modiﬁed circuit Dc
i
spectively Dq
i a corresponding sample mean estimator
evaluated on quantum device with resources R.

= tr(ONi(U )ρ0[Ni

0, (Dq

k, ˜Dc

1, Dc
1

k

Functional Model: The functional that relates an
error mitigated estimate h ˆOiEM of the ideal expected
value hOi = tr(OU ρ0U †) to the data obtained in the
noise characterisation is

h ˆOiEM = f (Dq

0

),

(7)

where f = ming∈F ||Dc − g(Dq)||2
2 minimises the dis-
tance measure ||Dc − g(Dq)||2
)]2
2
over all (invertible) functions g in a speciﬁed class F.
In particular, in [14] the class of ﬁtting functions F
was assumed to be linear so that f (x) := F1x + F0
and (assuming F1 6= 0)

i − g(Dq

= Pk

[Dc

i=1

i

h ˆOiEM = F1Dq

0

+ F0.

(8)

2.4 Noise Proﬁle Assumptions

The use of diﬀerent ﬁtting functions in ZNE and
CDR are motivated by an incoherent, Markovian
noise model. Such a model is described by the quan-
tum channel N = (1 − λ)I + λE with I the iden-
tity operation, and E an arbitrary process. There-
fore, the noisy implementation of the target unitary

4

1

k

channel U(·) := U (·)U † is given by ˜U := U1 ◦ N ◦
U2 ◦ N ... ◦ Ud ◦ N . We can expand this out in
terms of linear combinations of channels with coef-
ﬁcients depending on the noise parameter λ to get
˜U = (1 − λ)d U + λ(1 − λ)d−1(cid:0)d
(cid:1)E (1) + .... + λd E (d),
where the notation E (k) is an average over all processes
in the expansion of ˜U that have exactly k errors E. In
total there are (cid:0)d
(cid:1) diﬀerent ways k errors occur within
the circuit. Therefore, ˜U and the corresponding noisy
expectation value can be expressed in terms of a power
series in λ with degree at most d, thus motivating the
polynomial ﬁt. Alternatively, the analysis in [28] con-
siders approximating the binomial coeﬃcients in the
expansion of U with a Poisson distribution so that
λk(1 − λ)d−k(cid:0)d
and therefore, this noise
k!
model with the assumption that λ = O(1/d) makes
the approximation ˜U ≈ e−dλ[U + Pd
¯E (k)]
valid. The noisy expectation value will then take a
similar form which motivates the use of exponential
and poly-exponential ﬁtting functions. In particular,
for a global depolarising noise model (where E out-
puts a ﬁxed state ψ0) the noisy and exact expected
values have a linear relationship

(cid:1) ≈ e−dλ (dλ)k

(dλ)k
k!

k=1

k

hOiN = (1 − λ)dhOi + (1 − (1 − λ)d)tr(Oψ0).

(9)

In such a case, the linear ﬁt in CDR and polynomial
ﬁt in ZNE (with K ≤ d) are not susceptible to noise
bias so the true expectation can be recovered exactly,
up to ﬁnite sampling size errors.

3 Qermit Implementation Details

Qermit has a graph based architecture design, which
splits the execution of error mitigation methods into
atomic functional processes. These sub-processes may
be the submission of a circuit to a QPU, the modiﬁca-
tion of a circuit for the purposes of error mitigation,
or the ﬁtting of models. This software architecture
allows for vertices to be amended to adapt the pro-
tocol where necessary. A modular design additionally
means sub-graphs and graphs may be reused in other
original error mitigation protocols. As a result it is
ensured that Qermit: is easily extensible; allows one
to readily combine error mitigation protocols; and fa-
cilitates quick prototyping of new protocols through
the reuse of existing sub-protocols. Combining error
mitigation protocols has been shown to be a fruitful
endeavour [28–30], and one which is simpliﬁed in Qer-
mit.

3.1 MitRes and MitEx

There are two types of error mitigation methods in
Qermit: MitRes methods, which modify the distri-
bution of shots retrieved from a backend; and MitEx
methods, which return a modiﬁed expectation value
estimator of some observable. In general a MitRes or

Figure 1: MitRes TaskGraph. The CircuitsToHandles
MitTask takes circuits and a number of shots as input. It en-
sures the inputted circuits adhere to the requirements of the
backend, then submits the circuits to the backend; returning
identifying results handles. HandlesToResults uses the in-
putted results handles to retrieve results from the backend,
retuning them as outputs.

MitEx object may perform any modiﬁcation matching
this form, or no modiﬁcation at all. The instances of
MitRes and MitEx objects in Qermit are designed to
perform error mitigation.

MitRes and MitEx objects are constructed as
dataﬂow graphs, called a TaskGraph. Each node of a
TaskGraph is a MitTask object; itself a function that
computes some step or sub-process of an error mitiga-
tion protocol. Edges of the graph move data between
MitTask objects which depend on each other. When
the run function is called on a MitRes or MitEx ob-
ject, a topological sort is applied to the graph to order
these tasks sequentially. The tasks are then run lo-
cally in this sequential order.

In its default construction, as displayed in Fig. 1, a
MitRes object will simply run each circuit through a
backend and gather the results. Similarly, the default
construction of a MitEx object, as displayed in Fig. 2,
will simply estimate the expectation of each desired
observable without applying any mitigation methods.
To do so it will modify the circuit, appropriately ro-
tating the measurement basis according to the target
observable An example of such a use of the default
MitRes object can be seen in Appendix A.1, and of
the default MitEx object in Appendix A.2.1.

3.2 ZNE in Qermit

Figure 2: MitEx TaskGraph. The MitRes task may be ex-
panded as in Fig. 1. Other MitTask objects featuring here
include: FilterObservableTracker, which takes as input a
description of the circuit to be implemented, and the observ-
able to be measured, returning circuits modiﬁed to perform
the measurements necessary to calculate the expectation
of the requested observable; CollateExperimentCircuits,
which reformats the list of circuits to facilitate paral-
lelism; SplitResults, which undoes this reformatting; and
GenerateExpectations, which uses the results to calculate
the requested expectation values.

An example TaskGraph which corresponds to a
ZNE MitEx can be seen in Fig. 3. One notices in
particular that the initial circuit is duplicated by the
Duplicate MitTask, before each duplicate is passed
to a iFoldMitEx MitTask. Each iFoldMitEx in-
creases the noise in the circuit by a factor of i, and
runs the resulting circuit. The original circuit is
also passed through a default MitEx, as displayed in
Fig. 2. The results are collated and used to pro-
duce an error mitigated expectation value by the
CollateZNEResults MitTask. An example of a use
of ZNE within Qermit can be seen in Appendix A.2.2.

Several options exist in Qermit for both noise scaling
and extrapolation to the zero noise limit. Each noise
scaling operation available is of the digital variety, and
includes: circuit folding, random gate folding, and
odd gate folding. Extrapolation functions available
include: exponential, linear, poly-exponential, poly-
nomial, and Richardson. Those chosen for our exper-
iments are discussed in Section 5.

3.3 CDR in Qermit

One approach to generating the near Cliﬀord train-
ing circuit set required for CDR uses Markov chain
Monte Carlo techniques [14]. Here a ﬁrst training cir-
cuit is produced, where all but a ﬁxed number of non-
Cliﬀord gates are randomly replaced with nearest Clif-
ford gates according to a weighted distribution. Sub-

5

Inputs00CircuitsToHandles00HandlesToResults00OutputsInputs00FilterObservableTracker010CollateExperimentCircuits0101GenerateExpectations00MitRes001SplitResults00Outputsproblem-dependent) user-deﬁned maximal likelihood
function. A second option, implemented in Qermit,
and used in the experiments of Section 5 replaces
uniformly at random npairs of non-Cliﬀord/Cliﬀord
pairs in the ﬁrst training circuit, without producing a
chained training set.

Parameters specifying an instance of a CDR MitEx
include the device backend, the classical simulator
backend, the number of non-Cliﬀord gates in the
training circuits, the number of pair replacements,
and the total number of training circuits. An exam-
ple TaskGraph which corresponds to a CDR MitEx
can be seen in Fig. 4. The initial circuit is trans-
formed by CCLStateCircuits to prepare it for three
diﬀerent experiments. Respectively these are to: run
the original circuit on the given backend, run train-
ing circuits with a reduced number of non-Cliﬀord
gates on the same given backend, and run the train-
ing circuits on an ideal classical simulator. Once these
experiments have been conducted, a series of checks
QualityCheckCorrect ensure that the training data
gives a well-conditioned (least-squares) optimisation.
CDRCorrect ﬁnds the ﬁt parameters and produces an
error mitigated estimator. An example of the use of
CDR can be found in Appendix A.2.3.

4 Benchmark Design

Here we develop a benchmark procedure which can be
used to compare error mitigation methods on diﬀer-
ent backends. To assess the performance of an error
mitigation protocol, we introduce the relative error
of mitigation in Section 4.1. We further discuss in
Section 4.2 factors that inﬂuence such performance.
Our benchmarks are volumetric by design, with the
required circuit structure, presentation style and re-
sults interpretation discussed in Section 4.3. Finally
we detail the precise circuits we use in Section 4.4.

4.1 Accuracy Measures for Error Mitigation

In order to asses the performance of an error miti-
gation strategy we propose the following criteria that
such a performance metric should satisfy (i) faithful
– takes a ﬁxed (zero) value when the error mitigated
estimator matches the exact value (ii) operational –
relates to improvement in a computational task (iii)
eﬃciently estimable from experimental data and clas-
sical processing – allows for scalability.

Figure 3: ZNE TaskGraph. This TaskGraph includes:
CompileToBacked, which ensures the circuit obeys the
connectivity and gate set restraints of the backend used;
Duplicate, which created copies of the inputted circuit;
iFoldMitEx, which increases the noise in the circuit by a fac-
tor i, and runs the resulting circuit using a MitEx of Fig. 2;
and CollateZNEResults, which gathers the experiment re-
sults and extrapolates to the zero noise limit. Note that
other MitTask objects appearing in this ﬁgure have paral-
Indeed the iFoldMitEx contains a MitEx
lels in Fig. 2.
TaskGraph, which we do not expand for succinctness, as
well as a MitTask perfoing the noise scaling.

sequent steps generate circuits sequentially by ran-
domly replacing npairs of the Cliﬀord gates in the
previously generated circuit with their original non-
Cliﬀord, and similarly npairs non-Cliﬀord gates with
(nearest) Cliﬀord gates. At each step the new train-
ing circuit is accepted/rejected according to a (usually

Deﬁnition 4.1. Let O be an observable with ideal ex-
pectation hOi with respect to the target state ψ, h ˆOiN
a sample mean estimator for the corresponding noisy
state ρ and h ˆOiEM the sample mean estimator for the
expectation value after applying the error mitigation
method. The absolute error and absolute mitigation

6

Inputs00CompileToBackend00FilterObservableTracker010CollateExperimentCircuits0101GenerateExpectations00MitRes001SplitResults0012CollateZNEResults00Outputs03FoldMitEx005FoldMitEx00Duplicate012error are respectively

(cid:15)N = |h ˆOiN − hOi|
(cid:15)EM = |h ˆOiEM − hOi|

The relative mitigation error is deﬁned as

(cid:15)(O) = |h ˆOiEM − hOi|
|h ˆOiN − hOi|

.

(10)

(11)

(12)

The intuition for the above deﬁnition is that we
want a measure that expresses how much closer to
the true value is the mitigated estimator compared to
the noisy expectation. Note that the relative mitiga-
tion error has the following operational properties (i)
faithful (cid:15) = 0 iﬀ corrected expectation values matches
the exact value and (ii) whenever (cid:15) ≤ 1 the mitigation
of errors was successful.

Generally, the measures in Deﬁnition 4.1 involve a
classical simulation computing the true expectation
value, and therefore are limited to determine perfor-
mance of error mitigation schemes in these regimes.
In Appendix E.1 we discuss the problem of certifying
error mitigation for target states or circuit classes for
which there is no available classical simulation. We
introduce several performance metrics that satisfy (i)
- (iii) and are based on mirroring, or eﬃciently sim-
ulable circuits. For example, mirrored circuits give
scalable benchmarks since the exact expectation val-
ues depend only on the input (product) state and ob-
servable itself; no classical simulation of the circuits is
needed in this case. We make use of this approach to
benchmarking in Section 5. However, we leave for fu-
ture work to determine how well these measures pre-
dict the general performance of error mitigation on
quantum hardware, particularly in regimes approach-
ing quantum advantage.

Furthermore, since both h ˆOEM i and h ˆOiN are es-
timators they incur a variance due to ﬁnite sampling
statistics.
In general the ratio of two random vari-
ables does not have a well deﬁned variance and the
ratio of two normally distributed variables with zero
mean gives rise to the Cauchy distribution, which is
typically heavy tailed. However, under mild condi-
tions one can show [31] that (cid:15) can be approximated
by normal distribution with mean µ = µEM
and vari-
µN
ance

σ(cid:15) =

σ2
EM
(µN − hOi)2

+ σ2

N

(µEM − hOi)2
(µN − hOi)4

(13)

EM and σ2

where σ2
N are the variance of estimators
h ˆOiEM and h ˆOiN due to ﬁnite sampling statistics
and µEM = Eh ˆOiEM , µN = Eh ˆOiN correspond to
the means in the limit of an inﬁnite number of sam-
ples. We discuss in Appendix E.2 the conditions un-
der which the above approximation holds.

7

Figure 4: CDR TaskGraph. Besides those MitTask objects
which are common to Fig. 2, this TaskGraph additionally in-
cludes: CCLStateCircuits, which outputs the original cir-
cuits as output 0, and training circuits copied as outputs 1
and 2; StatSimMitEx, which runs these two sets of circuits
through a given backend and an ideal classical simulator, re-
turning the results; QualityCheckCorrect, which assesses
the expected quality of the resulting function model; and
CDRCorrect, which uses the results from the original and
training circuits to ﬁnd a function model and produce an
error mitigated result. Note that StateSimMitEx would ex-
pand to reveal a MitEx for the inputted backend, and a MitEx
for an ideal classical simulator.

Inputs00CCL_State_Circuits0120FilterObservableTracker010CollateExperimentCircuits0101GenerateExpectations00MitRes001SplitResults001QualityCheckCorrect010Outputs01StatesSimMitex001CDRCorrect04.2 Performance of Error Mitigation Methods

gated estimator is then

There are a series of factors that can aﬀect the per-
formance of error mitigation methods. Firstly, ﬁnite
sampling eﬀects are ampliﬁed in the error mitigated
estimator which incurs a higher variance than the
noisy expectation value estimator for a ﬁxed num-
ber of shots. This limitation has previously been dis-
cussed in Ref. [32] and recent work [24] derives theo-
retical lower bounds on the sample complexity over-
head of error mitigation in terms of the maximal noise
bias and distinguishability measures.
In particular,
for a local depolarising noise model the number of
shots required to produce a mitigated estimator with
the same accuracy as the noisy estimator scales expo-
nentially with the circuit depth [24, 33]. Practically,
if the architecture has a restricted topology then this
scaling can even depend exponentially on the num-
ber of qubits for sparser graphs that require an O(n)
routing overhead [34].

Secondly, the functional model used to produce the
error mitigated estimator will generally not fully cap-
ture the underlying backend noise eﬀects. This is par-
ticularly restrictive for real hardware, where h ˆOiEM
will therefore be susceptible to noise bias.

Thirdly, ﬁtting parameters to the functional model
involves a classical optimisation that may be ill con-
ditioned or unstable, partly due to the increased vari-
ance in the ﬁnite sampling or in the functional ﬁt.

Finally there are several speciﬁc regimes where the
above issues can be more detrimental to the perfor-
mance of error mitigation strategies. For example if
low levels of noise occur then h ˆOiN already produces
a good estimator of hOi with high accuracy and due
to the additional sampling overhead error mitigation
will not, on average, improve upon that estimator for
a ﬁxed shot budget. Typically error mitigation strate-
gies involve reconstructing the surface deﬁned by F
from the noisy samples D in the data collection step
– however, if the ﬁnite sample error dominates then
solutions to the ﬁt parameters will be unstable. This
situation can occur for high levels of noise and is typ-
ically exacerbated when the target observables have
low expected values. In the following section and Ap-
pendix E.2 we make these observations more precise.

4.2.1 Ampliﬁcation of ﬁnite sampling variance in the
error mitigated estimator
Recall that the error mitigated estimator h ˆOiEM
is produced by classical post-processing which ﬁts
the experimental
to a functional model
F(D, h ˆOiEM ) = 0. The terms Dq
i,m are sample mean
estimators that will introduce ﬁnite sampling eﬀects.
In the simplest case one might have a linear functional
where h ˆOiEM = P
i,m for some (real) coef-
ﬁcients Fi,m and where Dq
i,m are deﬁned in Eq. (1).
The variance due to ﬁnite sampling in the error miti-

i,m Fi,mDq

results

σ2
EM

: = V ar[ ˆOEM ] = X

i,mV ar[Dq
F 2

i,m

]

m,i

= X
m,i

F 2

i,mom,i
ni

σ2
i

(14)

(15)

:= P

z om,i(z)2 are constants pre-
where om,i
determined from the target observables (and any
modiﬁed observables required in the data collection
step) and recall that ni are the number of indepen-
dent samples {Zs}ni

s=1 each with variance σ2
i .

4.3 Volumetric Benchmarking

Volumetric benchmarking of error mitigation assesses
the overall performance of a method on a speciﬁc
backend with a ﬁxed set of total resources R. We
employ circuit classes with increasing depth d (as de-
termined by the number of layers of primitive circuits)
and qubit number n (which is ti say the number of
qubits the circuit acts on). Our methodology is in-
spired by volumetric benchmarks of quantum proces-
sors [22] and consists of:

1. Select a class of circuits C(n, d) and a probability
distribution or method to sample C individual
circuits.

2. Select a (Pauli) observable O (or set thereof) with

ﬁxed locality.

3. Determine relative mitigation error (cid:15)i(O) for each

circuit C(n, d) labelled by i ∈ {1, ..., C}.

4. Determine the median relative mitigation error

over the sampled circuits

¯(cid:15) = medC

i=1

[(cid:15)i(O, n, d)].

The choice of circuit classes and sampling methods
are ﬂexible and we discuss them in detail in the fol-
lowing section. In our benchmarks we will consider
global observables, acting non-trivially on each qubit.
Measurements of global observables are typically af-
fected by all errors occurring throughout a circuit
whereas a local observable is aﬀected by errors within
its light-cone. Indeed, if the noisy operations outside
the light-cone are described by completely positive
trace-preserving maps, then their action on the iden-
tity observable cancels out. This assumption may fail
if, for example, correlated errors across the cone par-
tition occur. Therefore the choice of a global observ-
able will place stronger constraints on depths/qubit
numberss at which error mitigation gives improved
estimators. One might also consider observables with
a ﬁxed locality constraint determined by applications
of interest.

There are two motivations behind the use of medi-
ans as a measure of overall success. First, we discussed

8

how ﬁnite sampling statistics can give a long-tailed
distribution of the relative mitigation error. Secondly
we observe for multiple experiments a similar long-
tailed behaviour for the distribution over diﬀerent cir-
cuits in the same class C(n, d).

4.4 Circuits

In this section, we formally deﬁne and motivate the
circuits used in benchmarking error mitigation meth-
ods. In particular, for each circuit class we deﬁne a
primitive layer type, providing pseudocode generat-
ing it. A layer acts on n qubits, where n is called
the qubit number of the circuit. We specify the depth
of a layer, and discuss how layers are composed to
create a depth d circuit from the given class. This
terminology corresponds to that used in Section 4.3.
While the qubit number and depth are indicative of
the circuit sizes, the exact number of gates will vary
between circuit classes. The compiled circuits will ad-
ditionally depend on the architecture of the backend.
This is discussed and displayed in Fig. 5. The partic-
ular implementation generating the circuits used in
our experiments is available as speciﬁed in the Data
Availability.

The circuit classes that we make use of are Ran-
dom Circuits, introduced in Section 4.4.1 and inspired
by those used for quantum volume experiments [21,
35], and Pauli-Gadget Circuits,
introduced in Sec-
tion 4.4.2 and inspired by ansatz circuits for NISQ
algorithms [36, 37]. Collectively, this selection of cir-
cuit classes encompass several important potential ap-
plications of quantum computing, covering circuits of
varied depth, connectivity, and gate types, strength-
ening the predictive power of our benchmarks.

We avoid favouring any device in particular by the
design of the benchmark circuits used here. The con-
nectivity and the gate-set assumed by the circuits is
very general to ensure we benchmark the error miti-
gation schemes as general purpose schemes. A com-
pilation step will be required to execute these circuits
on a real device. The compilation strategy used may
also inﬂuence the performance of the error mitiga-
tion scheme. While the same compilation strategy is
used during error mitigated runs as with noisy runs,
compilation passes may have diﬀerent eﬀects on error
mitigated and unaltered circuits. As such we ﬁx the
compilation scheme used during our benchmarks to
avoid this dependency and describe in Section 5 the
particular compilation passes used. Note in particular
that caution should be taken in the case of mirrored
circuits (see Section 4.4.3) to ensure that the circuits
are not compiled to the identity.

4.4.1 Random Circuits

While circuits required for applications are typically
not random, sampling from the output distributions
of random circuits built from two-qubit gates has been

suggested as a means to demonstrate quantum com-
putational supremacy [38–41]. By utilising uniformly
random two-qubit unitaries and all-to-all connectiv-
ity, Random Circuits, introduced now, provide a com-
prehensive benchmark.

The circuits used here – taken from Ref. [21] and
similar to those used for the quantum volume bench-
mark [35] – are generated according to Algorithm 1,
and are illustrated in Fig. 6. This circuit class con-
sist of d layers of two-qubit gates acting between a
bipartition of the qubits.

By utilising uniformly random two-qubit unitaries,
Random Circuits test the ability of the error mitiga-
tion scheme to mitigate errors acting on a universal
gate set. Allowing two-qubit gates to act between
any pair of qubits in the uncompiled circuit, means
Random Circuits avoid favouring any device in par-
ticular. This choice adheres closely to our motivations
of being hardware-agnostic. Because of this general-
ity Random Circuits are complementary to the other
classes introduced in this work.

4.4.2 Pauli-Gadget Circuits

Pauli gadgets [43] are quantum circuits implementing
an operation corresponding to exponentiating a Pauli
tensor. Sequences of Pauli gadgets acting on qubits
form product formula circuits, most commonly used
in Hamiltonian simulation [44]. Many algorithms em-
ploying these circuits require fault-tolerant devices,
but they are also the basis of trial state preparation
circuits in many variational algorithms, which are the
most promising applications of noisy quantum com-
puters.

A notable example of this in quantum chemistry
is the physically-motivated Unitary Coupled Cluster
family of trial states used in the variational quan-
tum eigensolver (VQE) [36, 37]. Motivated by these
practical applications, we include in our benchmarks
circuits with a similar structure. The Pauli-Gadget
Circuits are built as in Algorithm 2, and may be vi-
sualised as in Fig. 6. They are constructed from sev-
eral layers of Pauli Gadgets, each acting on a random
subset of n qubits. Note that the circuits in this class
diﬀer from running end-to-end VQE. Focusing on the
state preparation portion of a VQE circuit, we might
deduce performance of error mitigation when running
the VQE on ansatze of similar type.

4.4.3 Mirrored Circuits

Besides the division by circuit class, given by the spe-
ciﬁc layer type, circuits are also deﬁned as being mir-
rored or un-mirrored. While un-mirrored circuits con-
sist of independently generated random layers of a
ﬁxed type, mirrored circuits consist of randomly gen-
erated layers, each followed by their inverse. Mirrored
circuits correspond to an identity operation and thus
have the property that their expectation values can

9

Figure 5: CX gate count of circuits used in the experiments of Section 5. These circuits are not mirrored. Compilation is
onto the ibm lagos device, as discussed in Appendix B. Bars give the mean CX gate count over the circuits.

be eﬃciently computed with increasing qubit number
and depth.

In both Algorithm 1 and Algorithm 2 the option
to generate mirrored circuits is provided as an input
parameter. This has the eﬀect of inverting each layer
of the circuit once the layer has been applied. Ran-
dom layers are generated and inverted a total of b d
2 c
times to ensure that the ﬁnal depth is d, assuming that
d ∈ 2Z. This results in a circuit implementing the
identity, with ideal expectation value that depends
only on the observable and input state. Therefore,
mirrored circuits can provide scalable benchmarks to
assess the performance of error mitigation strategies.
We discuss this further in Appendix E.1.

4.4.4 Experiment Design

In our experiments, for a given qubit number and
depth we choose a ﬁxed number of random instances
from each class of Random and Pauli-Gadget circuits
and their mirrored versions. The measurements are
in the computational basis with the target observ-
ables set to O = Nn
i=0 Zi and input state ρ0 = |0i⊗n.
The choice of a global observable was motivated in
Section 4.3.

From the randomly generated circuit instances we
select those with ideal expectation values within a
ﬁxed range (speciﬁcally we select values from 0.4 to
0.6). As the circuit size increases the probability
of generating circuits with expectation values in this
range falls exponentially. This limits the size of such
circuits that we can generate, demonstrating an ad-
ditional advantage of the mirrored circuits which in
this case have a ﬁxed ideal expectation value 1.

We require this control of the ideal expectation
value for the following reason: Random circuits show
anti-concentration properties with increasing depth,
meaning that for Pauli observables the expectation
values will be close to zero with high probability[45].
However, our experiments, particularly the hardware
runs, are limited by ﬁnite size sampling so that the
obtained data D = {Dq
i,m}i,m incurs a variance de-
pending on the ﬁxed number of shots. Fitting this
data to the surface F(D, h ˆOiEM ) = 0 to determine an
error mitigated estimator can be numerically unstable

if the variance due to ﬁnite sampling is comparable to
the value of the noisy data D itself. This is particu-
larly relevant for very low ideal expected values since
accumulation of noise within the circuit results in a
further decreased such value (typically dropping ex-
ponentially with number of noisy gates). To avoid this
situation where the performance decrease in the error
mitigation with increasing depth can be (partly) at-
tributed to the random generation of benchmark cir-
cuits we restrict to high/ﬁxed range expected values.
We refer to Appendix E.4 for further details.

5 Results

We use the benchmarks introduced in Section 4 to
assess the performance of ZNE and CDR on both
superconducting hardware and noisy simulator back-
ends. In Fig. 7 and Fig. 8 we present volumetric plots
displaying the relative error of mitigation for Pauli-
Gadget Circuits and Random Circuits respectively,
when run on both ibm lagos and ibmq casablanca.
Extensive noisy simulations are provided in the Ap-
pendix D.

5.1 Noisy Classical Simulations

The ﬁrst set of benchmarks employ a local depolar-
ising noise model with error rate of e1 = 10−3 and
e2 = 10−2 for single and two qubit gates respec-
tively.3 These values are chosen to be broadly inline
with those reported by several hardware providers,
but do not correspond to any device in particular. In
this case there is no restriction on the pairs of qubits
between which two qubit gates can act. As such only
minimal compilation to the simulator’s gate set is re-
quired.

The results of these experiments are presented in
the volumetric plots of Figs. 11 and 12. For each
ﬁxed qubit number/depth (i.e square) 10 circuits are
sampled from the speciﬁed class, with 5 × 105 shots
per circuit for each error mitigation protocol, and 105

3To create this model we make use of the qiskit noise model
module, as described at https://qiskit.org/documentation/
apidoc/aer_noise.html.

10

Algorithm 1 The pattern for building Random Cir-
cuits.

Input: Width, n ∈ Z, depth, d ∈ Z and

mirrored ∈ {True, False}
Output: Circuit, Cn

1: Initialise n qubits, labelled q1, ..., qn, to |0i
2:
3: if mirrored then
d = b d
2 c
4:
5: end if
6: for each layer t up to depth m do
7:
8:
9:

Divide the qubits into b n

. This loop’s content constitutes a layer.

2 c pairs {qi,1, qi,2} at

random.

10:
11:
12:
13:

14:

15:

16:

17:

for all i ∈ Z, 0 ≤ i ≤ b n

2 c do

Generate U i,t ∈ SU (4) uniformly at ran-

dom according to the Haar measure.

Enact the gate corresponding to the uni-

tary U i,t on qubits qi,1 and qi,2.

. Decompositions of this gate can be

found in [42]

if mirrored then

Enact the gate corresponding to the

unitary U †
i,t
end if

on qubits qi,1 and qi,2.

end for

18:
19:
20:
21:
22: end for
23:
24: Measure all qubits in the computational basis.

in the case of the noisy expected value. This shot
count is higher than could be taken from real back-
ends at our disposal in a reasonable runtime. This
high shot count is used here to present an idealised
scenario and illustrate boundaries of qubit count and
circuit depth beyond which error mitigation fails to
improve the noisy estimator of the expected value. In
particular, such boundaries align with the theoretical
analysis limiting the depth to scale with a constant
inverse of the error rate d = O(1/e2) [25, 46].

In the case of ZNE, we use an exponential ﬁt and
the target circuit is folded repeatedly for a number
of λ = 1, 3, 5, 7, 9 times. The shot budget is dis-
tributed equally between these noise scaling values.
Curve ﬁtting is achieved via a least-square optimisa-
tion. For CDR, we distribute the total shot budget
equally to each of the 21 required circuits; namely 20
near-Cliﬀord circuits, and 1 unaltered circuit. Gen-
eration of the training set ﬁxes the number of non-

11

Cliﬀord operations to 10 and uniformly at random
generates the new near-Cliﬀord circuits by pair re-
placements from an initial seed circuit.
In the case
where the total number of non-Cliﬀord gates is less
than 10, at least one non-Cliﬀord gate is replaced at
random. Additionally, using the classical simulation
of these circuits we test that the training data gives a
well-conditioned matrix for the linear regression to be
performed and generate new training circuits if that
is not the case.

Comparing ﬁrst the performance of CDR and ZNE,
we note from Figs. 11a and 11b that for Random Cir-
cuits in the size ranges explored, both show an im-
provement over the case where error mitigation is not
used. ZNE appears to perform particularly well in
this domain, outperforming CDR for each circuit size
explored. To identify the limits of the utility of CDR
and ZNE we extend the depth of the circuit explored
using mirrored circuits, as discussed in Section 4.4.
We see from Figs. 11c and 11d that while ZNE out-
performs CDR for smaller circuit sizes, the range of
circuit sizes where CDR outperforms the use of no
error mitigation appears to be larger than for ZNE.

Comparing Fig. 12 to Fig. 11 we note that while
ZNE outperform CDR in case of Random Circuits,
this appears not to be the case for Pauli-Gadget Cir-
cuits. As shown in Fig. 5, the CX gate count of cir-
cuits with a ﬁxed qubit number and depth are sim-
ilar between the Random Circuits and Pauli-Gadget
Circuits classes. As such this improved relative per-
formance of CDR is likely because there are a smaller
proportion of non-Cliﬀord gates in Pauli-Gadget Cir-
cuits than Random Circuits. In the case where there
are few non-Cliﬀord circuits, the training circuits are
little diﬀerent from the original circuit, which im-
proved the accuracy of the CDR training procedure.
The second set of benchmarks employ device emula-
tion that includes many properties of the correspond-
ing real backend used in Section 5.2.4 These prop-
erties include connectivity of the architecture, avail-
able gate set, and an expansion of the noise model to
include thermal relaxation and readout errors, in ad-
dition to a local depolarising model with parameters
corresponding to calibration results. Exact values of
these propertied can be found in Appendix B. The
parameters used for ZNE and CDR are identical in
this case to those used when performing depolarising
noise simulation, with the exception that the total
shot budget is reduced to 1.6 × 105 for the mitigated
experiment, and 0.32 × 105 for the unmitigated ex-
periments. The shot budget is reduced to match that
of the real device experiments, where computing re-
sources are more scarce.

Comparing Figs. 11a, 11c, 12a and 12c to Figs. 13a,
13c, 14a and 14c we see a marked fall in the perfor-

4To achieve device emulation use the pytket IBMQEm-
ulatorBackend as described at https://cqcl.github.io/
pytket-extensions/api/qiskit/api.html.

0
,
c
n2
b
U

q1 = |0i

q2 = |0i

q3 = |0i

qn = |0i

0
,
0
U

...

n
,
c
n2
b
U

n
,
0
U

...

q1 = |0i

q2 = |0i

q3 = |0i

qn = |0i

(cid:17)
0
α
0j
s

j

N
(cid:16)

i

p
x
e

...

(cid:17)
d
α
dj
s

j

N
(cid:16)

i

p
x
e

...

(a) An example of Random Circuits, as generated by Algorithm 1.

(b) An example of Pauli-Gadget Circuits, as gener-
ated by Algorithm 2.

Figure 6: Example circuits. These particular examples have mirrored set to false.

Circuits, one can imagine appending the gate exp
of mirrored Random Circuits, one can imagine appending the gate U †
random circuit class act between 2 randomly selected qubits.

(cid:16)

−i N

jαt(cid:17)

j st

after the gate exp

In the case of mirrored Pauli-Gadget
i N

jαt(cid:17)
i,t after the gate U i,t. Note that the gates U i,t in the

. Respectively in the case

j st

(cid:16)

mance of ZNE when additional device constraints are
impose by emulation.

5.2 Quantum Hardware Backend

Finally, we perform volumetric benchmarks to assess
and compare the performance of ZNE and CDR error
mitigation on ibmq lagos and ibmq casablanca as
measured by the relative error of mitigation.

The experiments used in the volumetric bench-
marks are produced according to Section 4.4 and em-
ploy the two types of circuit classes as described in
Section 4.4.4. For each ﬁxed qubit number and depth
we use 5 circuits on which we sequentially perform
CDR, ZNE and no error mitigation. The same sets
of circuits are used on both ibmq casablanca and
ibm lagos. As discussed, the parameters used for
ZNE and CDR are the same as in the case of the
depolarising noise simulations, and the device emu-
lation experiments. As in the case of the emulation
experiments, the shot budget is set to 1.6 × 105 for
the error mitigated experiments, and 0.32 × 105 for
the unmitigated experiments.

It’s important to emphasize that for any given cir-
cuit we run the two mitigation schemes, and the un-
mitigated experiments, back-to-back so that any time
drift in the device’s noise parameters do not skew the
performance comparison. For both devices the cali-
bration data during these experiments can be found
in Table 2 and Table 1. Furthermore, they share the
same architecture connectivity.

As seen in Figs. 7 and 8, for a ﬁxed qubit number
and depth (as measured by the number of layers from
a speciﬁc circuit class), we typically found at least
one sampled circuit for which error mitigation does
not improve upon the noisy expectation value. This
occurred for both error mitigation methods even when
their median performance gave a 2-fold or higher error
reduction (i.e ¯(cid:15) ≤ 0.5). This stands in contrast with
the emulation results, where there was a signiﬁcant

size region with diﬀerent (n, d) for which error miti-
gation was successful even in the worst case. Method
parameters and shot budget were the same for emu-
lation and device experiments.

Strikingly, whilst the dominating two qubit error
rates are within 10% for the two devices, perfor-
mance of error mitigation drastically decreased on
ibm lagos. In particular, as seen in Figs. 7a and 7c,
the structured Pauli-Gadget Circuits showed little
to no improvement over the noisy expectation value
when exponential ZNE was performed. This is not
due to ibm lagos producing results with low abso-
lute error. As indicated in Tables 3 and 4 the absolute
error of the results from ibm lagos are in fact typi-
cally higher than that of ibmq casablanca. Compar-
atively, as seen in Fig. 7e, on ibmq casablanca for
small qubit sizes n = 3 and 2, ZNE mitigation was
successful with a median relative error of 0.51 respec-
tively 0.50 for 4 Pauli circuit layers. However, com-
paring Figs. 7f and 7h against Figs. 7b and 7d, we see
that the performance of CDR was consistent between
the two devices for this circuit class, and on average
scaled well to the largest circuit sizes considered.

On the other hand, we see from Fig. 8 that for Ran-
dom circuits both ZNE and CDR had worse perfor-
mance on ibm lagos compared to ibmq casablanca,
with the limits ¯(cid:15) > 1 reached within the sizes consid-
ered in both depth and qubit number. For this circuit
class, as seen in Figs. 8e and 8g, the performance of
ZNE on ibm casablanca consistently reached on av-
erage a reduction in the noisy estimator’s absolute er-
ror by 2 or more for all sizes considered. This was gen-
erally slightly better than CDR, although both meth-
ods still improved the noisy estimators even for larger
qubit sizes and depths.

In the case of mirrored circuits, the performance
was more consistent between the two devices. No-
tably, as seen in Figs. 7d and 7h, on mirrored Pauli
gadget circuits CDR decreased, on average, the abso-
lute error in the noisy estimator by up to an order of

12

Algorithm 2 The pattern for building Pauli-Gadget
Circuits.

Input: Width, n ∈ Z, depth, d ∈ Z and

mirrored ∈ {True, False}
Output: Circuit, Cn

1: Initialise n qubits, labelled q1, ..., qn, to |0i.
2:
3: if mirrored then
d = b d
2 c
4:
5: end if
6: for each layer t up to depth d do
7:
8:
9:

. This loop’s content constitutes a layer.

Select a random string st ∈ {1, X, Y, Z}n
Generate random angle αt ∈ [0, 2π]
Enact the Pauli gadget corresponding to the
jαt(cid:17)

on qubits q1, ..., qn.

i N

j st

(cid:16)

unitary exp

. Decompositions of this gate can be found in

[43]

if mirrored then

Enact the Pauli gadget corresponding to
jαt(cid:17)
on qubits q1, ..., qn.

−i N

j st

(cid:16)

the unitary exp

10:
11:

12:

13:
14:

end if

15:
16:
17: end for
18:
19: Measure all qubits in the computational basis

magnitude for most circuit sizes. This corresponds in
Fig. 7 to a median relative error of mitigation of 0.1
or less, and the results were similar for both devices.
Comparing Figs. 7a and 7e against Figs. 7c and 7g
shows ZNE mirrored Pauli circuits were a good pre-
dictor of the poor performance of non-mirrored cir-
cuits with similar dimensions. Surprisingly, the rela-
tive error of mitigation for mirrored random circuits
improved from 0.45 on ibmq casablanca to 0.15 on
ibm lagos for n = 5 qubits, as seen in Fig. 8g and
Fig. 8c, respectively. This suggests that while mir-
rored circuits may provide scalable benchmarks to as-
sess performance of error mitigation, they generally
overestimate the median relative error for circuits of
similar sizes using both of the methods considered.

Finally, since all parameters including total shot
budget per mitigated expected value are ﬁxed, the
discrepancy in performance between the two devices
can be attributed to the noise bias and diﬀerent noise
proﬁles. Therefore it would be of interest to determine
how the results of the volumetric benchmarks change
for the same device at diﬀerent calibration times.
This was not possible in the case of ibm casablanca
as the machine was retired during our experiments,
so we leave this type of assessment for future work.

13

6 Conclusions and Outlook

In this work we introduce Qermit – an open source
package for error mitigation with a composable soft-
ware architecture that allows for combining diﬀerent
error mitigation methods and facilitates development
of new techniques.

A key question we address is given a particular de-
vice and class of circuits, which error mitigation has,
on average, a better performance? To that aim, we
design volumetric benchmarks to assess the perfor-
mance of error mitgation methods for a given class
of quantum circuits with varying qubit number and
depth. The methodology is based on frameworks for
benchmarking quantum devices [22]. We use this
framework here to delineate the boundary beyond
which a given error mitigation technique fails on av-
erage to give an improved estimator of the target ex-
pectation value.

In this setup, we compare the performance of ZNE
and CDR implementations on current superconduct-
ing hardware. We show how noise in real devices
places even stronger constraints on the scalability of
error mitigation than theoretical lower bounds as for
example derived in [24] or determined from classical
noisy simulations [29]. Qualitatively, we found that
even for a low total shot budget (≈ 105 per mit-
igated expected value) CDR generally outperforms
ZNE on structured Pauli circuits and slightly under-
performs on random SU(4) circuits. This generic be-
haviour is captured by the emulation which includes
depolarisation, thermal relaxation and readout in the
noise model as well as the device’s architecture. How-
ever, emulation largely overestimates the performance
with successful mitigation for signiﬁcantly larger cir-
cuit sizes compared to those accessible with real hard-
ware.
In contrast, a simpliﬁed depolarising noise
model without connectivity constraints fails to pre-
dict even qualitative features of error mitigation per-
formance.

On real hardware, we ﬁnd that for circuits of the
same type and depth the relative error of mitigation
can vary extensively. Often, it results in unsuccessful
mitigation in the worst case even when on average the
error in the expectation value is reduced by an order
of magnitude. We run the same benchmarks on two
superconducting devices with the same connectivity
and comparable calibration data and ﬁnd a high level
of variability in the performance of both error mit-
igation methods. This was particularly striking for
ZNE, where the use of digitised method to artiﬁcially
increase noise level may be more succeptible to the
diﬀerent noise proﬁles. These results ﬂag two issues;
ﬁrst, that ﬁne grained noise characterisation is needed
to predict behaviour of error mitigation on hardware
and second, that without access to the ideal expecta-
tion value one needs to validate that error mitigation
has succeeded.

(a) ibm lagos, ZNE, Pauli-Gadget
Circuits.

(b)
ibm lagos,
Gadget Circuits.

CDR, Pauli-

ibm lagos,

ZNE,
Pauli-Gadget

(c)
Mirrored
Circuits.

ibm lagos,

CDR,
Pauli-Gadget

(d)
Mirrored
Circuits.

(e) ibmq casablanca, ZNE, Pauli-
Gadget Circuits.

(f) ibmq casablanca, CDR, Pauli-
Gadget Circuits.

(g)
ZNE, Mirrored
Gadget Circuits.

ibmq casablanca,
Pauli-

(h)
CDR, Mirrored
Gadget Circuits.

ibmq casablanca,
Pauli-

Figure 7: Volumetric plots for performance of error mitigation on Pauli-Gadget Circuits. ibm lagos and ibmq casablanca
are used with ZNE or CDR on Pauli-Gadget Circuits and mirrored Pauli-Gadget Circuits. Median ¯(cid:15) (outer square) and worst-
case (inner square) relative error of mitigation over the sampled circuits are shown, metric that ranges between (0, 1) for
successful mitigation with lower values corresponding to better performance. Each square corresponds to 5 sampled circuits
of the speciﬁed type with a total 1.6 × 105 total shot budget per each mitigated expectation value.

Our benchmarks also include mirrored circuits of a
speciﬁed class, for which expectation values can be
eﬃciently computed classically for increasing sizes.
Given a ﬁxed qubit number and depth, mirrored cir-
cuits produced, on average, lower relative error of mit-
igation for both methods compared to un-mirrored
circuits from the same class. This illustrates that mir-
rored circuits can provide scalable benchmarks, how-
ever, they will generally overestimate the error miti-
gation performance on similarly sized circuits that are
un-mirrored.

Due to the emphasis on composability, Qermit is
particularly well suited to explore the application of
multiple noise tailoring and mitigation techniques for
the same circuit and observable. In future work we
will explore the performance of combined methods,
which is particularly well motivated by recent results
[47] that show signiﬁcant improvements when using
Pauli frame randomisation, ZNE and dynamical de-
coupling. In particular, for these combined methods
the error mitigated estimates of magnetisation gave
a better approximation than the leading approximate

classical tensor network simulations for 2D Ising mod-
els on up to N = 27 qubits. This makes Qermit suit-
able for testing how useful error mitigation can be to
achieve practical quantum advantage over best known
classical algorithms with noisy quantum devices.

Data Availability A complete set of results can be
found in [48]. This additionally includes the circuits
used, and other data required to reproduce the exper-
iments.

Qermit Installation and Usage Information on
the installation and use of Qermit is available in the
documentation at:

https://cqcl.github.io/qermit/

and the user manual at:

https://cqcl.github.io/qermit/manual/

Qermit is available for the Mac, Linux and Windows
operating systems via PyPI. Qermit may be installed
using the command line operation:

14

(a) ibm lagos, ZNE, random.

(b) ibm lagos, CDR, Random Cir-
cuits.

(c) ibm lagos, ZNE, Mir-
rored Random Circuits.

(d) ibm lagos, CDR, Mir-
rored Random Circuits.

(e) ibmq casablanca, ZNE, Ran-
dom Circuits.

(f) ibmq casablanca, CDR, Ran-
dom Circuits.

(g)
ibmq casablanca,
ZNE, Mirrored Random
Circuits.

(h)
ibmq casablanca,
CDR, Mirrored Random
Circuits.

Figure 8: Volumetric plots for performance of error mitigation on Random Circuits. ibm lagos and ibmq casablanca
are used with ZNE or CDR on Random Circuits and mirrored Random Circuits. Median ¯(cid:15) (outer square) and worst-case
(inner square) relative error of mitigation over the sampled circuits are shown, metric that ranges between (0, 1) for successful
mitigation with lower values corresponding to better performance. Each square corresponds to 5 sampled circuits of the
speciﬁed type with a total 1.6 × 105 total shot budget per each mitigated expectation value.

pip install qermit

The source code for Qermit is hosted at:

https://github.com/CQCL/qermit

Acknowledgements Thanks to Steven Herbert
and Hussain Anwar for insightful feedback. This work
was supported by Innovate UK Project No: 10001712.
“Noise Analysis and Mitigation for Scalable Quan-
tum Computation”. We acknowledge the use of IBM
Quantum services for this work. The views expressed
are those of the authors, and do not reﬂect the oﬃcial
policy or position of IBM or the IBM Quantum team.

References

[1] John Preskill. “Quantum computing in the
NISQ era and beyond”. In: Quantum 2 (2018),
p. 79.

[2] Aram W. Harrow and Ashley Montanaro.
“Quantum computational supremacy”. In: Na-
ture 549.7671 (Sept. 2017), pp. 203–209. issn:
1476-4687. doi: 10.1038/nature23458. url: htt
p://dx.doi.org/10.1038/nature23458.
[3] Sarah Sheldon et al. “Procedure for systemati-
cally tuning up cross-talk in the cross-resonance
gate”. In: Phys. Rev. A 93 (6 June 2016),
p. 060302. doi: 10.1103/PhysRevA.93.060302.
url: https://link.aps.org/doi/10.1103/
PhysRevA.93.060302.

[4] Lorenza Viola, Emanuel Knill, and Seth
Lloyd. “Dynamical Decoupling of Open Quan-
tum Systems”. In: Phys. Rev. Lett. 82 (12
Mar. 1999), pp. 2417–2421. doi: 10.1103/Phys-
RevLett.82.2417. url: https : / / link . aps .
org/doi/10.1103/PhysRevLett.82.2417.
[5] Andre R. R. Carvalho et al. “Error-Robust
Quantum Logic Optimization Using a Cloud
Quantum Computer Interface”. In: Phys. Rev.
Applied 15 (6 June 2021), p. 064054. doi:
10.1103/PhysRevApplied.15.064054. url: htt

15

ps : / / link . aps . org / doi / 10 . 1103 /
PhysRevApplied.15.064054.

[6] Peter W. Shor. “Scheme for reducing decoher-
ence in quantum computer memory”. In: Phys.
Rev. A 52 (4 Oct. 1995), R2493–R2496. doi:
10.1103/PhysRevA.52.R2493. url: https : / /
link.aps.org/doi/10.1103/PhysRevA.52.
R2493.

[7] Barbara M. Terhal. “Quantum error correc-
tion for quantum memories”. In: Rev. Mod.
Phys. 87 (2 Apr. 2015), pp. 307–346. doi:
10.1103/RevModPhys.87.307. url: https : / /
link.aps.org/doi/10.1103/RevModPhys.87.
307.

[8] Prakash Murali et al. Noise-Adaptive Com-
piler Mappings for Noisy Intermediate-Scale
Quantum Computers. 2019. arXiv: 1901.11054
[quant-ph].

[9] Seyon Sivarajah et al. “t|ket〉: a retargetable
compiler for NISQ devices”. In: Quantum Sci-
ence and Technology 6.1 (Nov. 2020), p. 014003.
doi: 10.1088/2058-9565/ab8e92. url: https://
doi.org/10.1088/2058-9565/ab8e92.
[10] Joel J Wallman and Joseph Emerson. “Noise
tailoring for scalable quantum computation via
randomized compiling”. In: Physical Review A
94.5 (2016), p. 052325. url: https://arxiv.
org/abs/1512.01098.

[11] Kristan Temme, Sergey Bravyi, and Jay M
Gambetta. “Error mitigation for short-depth
quantum circuits”. In: Physical review letters
119.18 (2017), p. 180509.

[12] Ying Li and Simon C Benjamin. “Eﬃcient vari-
ational quantum simulator incorporating active
error minimization”. In: Physical Review X 7.2
(2017), p. 021050.

[13] Tudor Giurgica-Tiron et al. “Digital zero noise
extrapolation for quantum error mitigation”. In:
arXiv preprint arXiv:2005.10921 (2020).
[14] Piotr Czarnik et al. “Error mitigation with
Cliﬀord quantum-circuit data”. In: Quantum
5 (Nov. 2021), p. 592. issn: 2521-327X. doi:
10.22331/q-2021-11-26-592. url: https : / / do
i.org/10.22331/q-2021-11-26-592.

[15] William J Huggins et al. “Virtual distillation for
quantum error mitigation”. In: Physical Review
X 11.4 (2021), p. 041036.

[16] Suguru Endo

et

“Hybrid Quantum-
al.
Classical Algorithms and Quantum Error
Mitigation”. In: Journal of the Physical So-
ciety of Japan 90.3 (2021), p. 032001. doi:
10.7566/JPSJ.90.032001.
https :
//doi.org/10.7566/JPSJ.90.032001. url:
https://doi.org/10.7566/JPSJ.90.032001.

eprint:

[17] Kishor Bharti et al. “Noisy intermediate-scale
quantum algorithms”. In: Rev. Mod. Phys. 94
(1 Feb. 2022), p. 015004. doi: 10.1103/RevMod-
Phys.94.015004. url: https://link.aps.org/
doi/10.1103/RevModPhys.94.015004.
[18] B´alint Koczor. “Exponential error suppression
for near-term quantum devices”. In: Physical
Review X 11.3 (2021), p. 031057.

[19] Austin G. Fowler et al. “Surface codes: Towards
practical large-scale quantum computation”. In:
Phys. Rev. A 86 (3 Sept. 2012), p. 032324. doi:
10.1103/PhysRevA.86.032324. url: https : / /
link.aps.org/doi/10.1103/PhysRevA.86.
032324.

[20] Joe O’Gorman and Earl T. Campbell. “Quan-
tum computation with realistic magic-state fac-
tories”. In: Phys. Rev. A 95 (3 Mar. 2017),
p. 032338. doi: 10.1103/PhysRevA.95.032338.
url: https://link.aps.org/doi/10.1103/
PhysRevA.95.032338.

[21] Daniel Mills et al. Application-Motivated, Holis-
tic Benchmarking of a Full Quantum Com-
puting Stack. 2020. arXiv: 2006 . 01273
[quant-ph].

[22] Robin Blume-Kohout and Kevin C. Young.
“A volumetric framework for quantum com-
puter benchmarks”. In: Quantum 4 (Nov. 2020),
p. 362. issn: 2521-327X. doi: 10.22331/q-2020-
11-15-362. url: https://doi.org/10.22331/
q-2020-11-15-362.

[23] Ryan LaRose et al. Mitiq: A software package
for error mitigation on noisy quantum comput-
ers. 2021. arXiv: 2009.04417 [quant-ph].

[24] Ryuji Takagi et al. “Fundamental

limits of
quantum error mitigation”. In: arXiv preprint
arXiv:2109.04457 (2021).

[25] Zhenyu Cai. “A Practical Framework for Quan-
In: arXiv preprint

tum Error Mitigation”.
arXiv:2110.05389 (2021).

[26] G. Chiribella, G. M. D’Ariano, and P. Perinotti.
In: Phys.
“Quantum Circuit Architecture”.
Rev. Lett. 101 (6 Aug. 2008), p. 060401. doi:
10.1103/PhysRevLett.101.060401. url: https:
//link.aps.org/doi/10.1103/PhysRevLett.
101.060401.

[27] Sergey Bravyi and David Gosset. “Improved
Classical Simulation of Quantum Circuits Dom-
inated by Cliﬀord Gates”.
In: Phys. Rev.
Lett. 116 (25 June 2016), p. 250501. doi:
10.1103/PhysRevLett.116.250501. url: https:
//link.aps.org/doi/10.1103/PhysRevLett.
116.250501.

16

[28] Zhenyu Cai. “Multi-exponential error extrap-
olation and combining error mitigation tech-
niques for NISQ applications”. In: npj Quantum
Information 7.1 (May 2021). issn: 2056-6387.
doi: 10.1038/s41534-021-00404-3. url: http :
//dx.doi.org/10.1038/s41534-021-00404-
3.

[29] Daniel Bultrini et al. Unifying and bench-
marking state-of-the-art quantum error miti-
gation techniques. 2021. arXiv: 2107 . 13470
[quant-ph].

[30] Andrea Mari, Nathan Shammah, and William
J. Zeng. “Extending quantum probabilistic er-
ror cancellation by noise scaling”. In: Physical
Review A 104.5 (Oct. 2021). issn: 2469-9934.
doi: 10.1103/physreva.104.052607. url: http:
/ / dx . doi . org / 10 . 1103 / PhysRevA . 104 .
052607.

[31] Elo´ısa D´ıaz-Franc´es and Francisco J Rubio. “On
the existence of a normal approximation to the
distribution of the ratio of two independent nor-
mal random variables”. In: Statistical Papers
54.2 (2013), pp. 309–323.

[32] Suguru Endo et al. “Hybrid quantum-classical
algorithms and quantum error mitigation”. In:
arXiv preprint arXiv:2011.01382 (2020).
[33] Samson Wang et al. “Can error mitiga-
tion improve
trainability of noisy varia-
tional quantum algorithms?” In: arXiv preprint
arXiv:2109.01051 (2021).

[34] Alexander Cowtan et al. “On the Qubit
(2019). doi:
Routing Problem”.
10.4230/LIPICS.TQC.2019.5. url:
http :
/ / drops . dagstuhl . de / opus / volltexte /
2019/10397/.

en.

In:

[35] Andrew W. Cross et al. “Validating quantum
computers using randomized model circuits”.
In: Phys. Rev. A 100 (3 Sept. 2019), p. 032328.
doi: 10.1103/PhysRevA.100.032328. url: http
s://link.aps.org/doi/10.1103/PhysRevA.
100.032328.

[36] Alberto Peruzzo et al. “A variational eigen-
value solver on a photonic quantum proces-
sor”. In: Nature Communications 5.1 (July
2014), p. 4213. issn: 2041-1723. doi: 10.1038/n-
comms5213. url: https://doi.org/10.1038/
ncomms5213.

[37] Panagiotis Kl. Barkoutsos et al. “Quantum al-
gorithms for electronic structure calculations:
Particle-hole Hamiltonian and optimized wave-
function expansions”.
In: Phys. Rev. A 98
(2 Aug. 2018), p. 022322. doi: 10.1103/Phys-
RevA.98.022322. url: https : / / link . aps .
org/doi/10.1103/PhysRevA.98.022322.

17

[38] Adam Bouland et al. “Quantum Supremacy and
the Complexity of Random Circuit Sampling”.
In: (2018). arXiv: 1803 . 04402 [quant-ph].
url: https://arxiv.org/abs/1803.04402.

[39] Ramis Movassagh. “Eﬃcient unitary paths and
quantum computational supremacy: A proof
of average-case hardness of Random Circuit
Sampling”. In: (2018). arXiv: 1810 . 04681
[quant-ph]. url: https://arxiv.org/abs/
1810.04681.

[40] Sergio Boixo et al. “Characterizing quan-
tum supremacy in near-term devices”. In: Na-
ture Physics 14.6 (June 2018), pp. 595–600.
issn: 1745-2481. doi: 10.1038/s41567-018-0124-
x. url: https://doi.org/10.1038/s41567-
018-0124-x.

[41] Scott Aaronson and Lijie Chen. “Complexity-
Theoretic Foundations of Quantum Supremacy
Experiments”. In: (2016). arXiv: 1612 . 05903
[quant-ph]. url: https://arxiv.org/abs/
1612.05903.

[42] Robert R. Tucci. An Introduction to Cartan’s
KAK Decomposition for QC Programmers.
2005. arXiv: quant-ph/0507171 [quant-ph].

[43] Alexander Cowtan et al. “Phase Gadget Syn-
thesis for Shallow Circuits”. In: Electronic Pro-
ceedings in Theoretical Computer Science 318
(Apr. 2020), pp. 214–229. issn: 2075-2180. doi:
10.4204/eptcs.318.13. url: http : / / dx . doi .
org/10.4204/EPTCS.318.13.

[44] Dominic W. Berry et al. “Eﬃcient Quantum Al-
gorithms for Simulating Sparse Hamiltonians”.
In: Communications in Mathematical Physics
270.2 (Mar. 2007), pp. 359–371. issn: 1432-
0916. doi: 10.1007/s00220-006-0150-x. url: htt
ps://doi.org/10.1007/s00220-006-0150-x.

[45] Alexander M Dalzell, Nicholas Hunter-Jones,
and Fernando GSL Brandao. “Random Quan-
tum Circuits Anticoncentrate in Log Depth”.
In: PRX Quantum 3.1 (2022), p. 010333.

[46] Zhenyu Cai. “Multi-exponential error extrap-
olation and combining error mitigation tech-
niques for nisq applications”. In: arXiv preprint
arXiv:2007.01265 (2020).

[47] Youngseok Kim et al. “Scalable error mitiga-
tion for noisy quantum circuits produces com-
petitive expectation values”. In: arXiv preprint
arXiv:2108.09197 (2021).

[48] Cristina Cirstoiu et al. Volumetric Benchmark-
ing of Error Mitigation with Qermit: Experi-
mental Data. Version 1.0. Zenodo, Apr. 2022.
doi: 10.5281/zenodo.6472281. url: https : / /
doi.org/10.5281/zenodo.6472281.

A Code Snippets

A.1 MitRes

The MitRes.run method takes a list of CircuitShots
objects as an argument. Each CircuitShots objects
contains the basic information required to run a cir-
cuits, namely; a state preparation circuit, and the
number of shots to run for the circuit.

The example code snippet:

from qermit import MitRes , CircuitShots
from pytket import Circuit
from pytket . extensions . qiskit import

AerBackend

mitres = MitRes ( backend = AerBackend () )
c = Circuit (2 , 2) . H (0) . Rz (0.25 , 0) . CX (1 ,

0) . measure_all ()

results = mitres . run ([ CircuitShots (

Circuit =c , Shots =50) ])
print ( results [0]. get_counts () )

1

2

3

4

5

6

7

8

9

10

graph = mitres . get_task_graph ()

produces the output:

1

Counter ({(0 , 0) : 30 , (1 , 0) : 20})

with graph being the TaskGraph of Fig. 1.

A.2 MitEx

a

list

takes

objects

MitEx.run method

ObservableExperiment

The
of
ObservableExperiment objects as an argument.
Each
contains
the basic information required to estimate the
expectation value of an observable: a state prepa-
ration circuit, a dictionary between symbols and
parameter values
(where appropriate), a pytket
QubitPauliOperator detailing the operator being
measured and used for preparing measurement
circuits, and the number of shots to run for each
measurement circuit. The following is an example of
an ObservableExperiment set up.

1

2

3

4

5

6

7

8

9

from qermit import AnsatzCircuit ,

ObservableExperiment ,
ObservableTracker , SymbolsDict

from pytket . pauli import Pauli ,

QubitPauliString
from pytket . utils import
QubitPauliOp erator

from pytket import Circuit , Qubit

qubit_pa uli_st ring = QubitPauliString ([

Qubit (1) , Qubit (2) ] , [ Pauli .Z , Pauli .
Z ])

qubit _p au li _ope r ato r =

QubitPauliOp erator ({
qubit_pauli_ string : 1.0})
ansatz_circuit = AnsatzCircuit (

Circuit = Circuit (3) . X (0) . X (1) , Shots

=50 , SymbolsDict = SymbolsDict ()

10

11

12

13

14

)
experiment = O bserv abl eE xp er im en t (

AnsatzCircuit = ansatz_circuit ,
Obs ervableTracker = ObservableTracker (

qu bit_ paul i_o perat or ) ,

)

In the following we discuss the deﬁnition of a
In each we will use
MitEx object in several cases.
the ObservableExperiment deﬁned above.
In all
cases an experiment returns a QubitPauliOperator
object containing an expectation value for each
QubitPauliString.

A.2.1 Default MitEx Example

In its default version, a MitEx object will append a
measurement circuit for each QubitPauliString to
the ansatz circuit and execute it through the pytket
Backend the MitEx object is deﬁned by. In particular
the example code snippet:

from qermit import MitEx
from pytket . extensions . qiskit import

IB MQE mulatorB acke nd

device_backend = IBMQEmulato rB ackend ( ’

ibm_lagos ’ , hub = ’ ’ , group = ’ ’ , project
= ’ ’)

mitex = MitEx ( backend = device_backend )
mitex_results = mitex . run ([ experiment ])
print ( mitex_results [0])

graph = mitex . get_task_graph ()

produces the output:

{( Zq [1] , Zq [2]) : -0.920000000000000}

with graph being the TaskGraph of Fig. 2. Not that
as we have used a noisy simulator, the returned value
is diﬀerent from the ideal value of −1.

A.2.2 ZNE MitEx in Qermit

The ZNE MitEx has the required inputs: backend,
the backend on which the circuits will be run; and
noise scaling list, a list of factors by which the
noise is scaled. Optionally the type of folding used
can be speciﬁed via the folding type keyword argu-
ment. This expects a Folding object. The ﬁt used to
extrapolate results can be speciﬁed via the fit type
keyword argument. This expects a Fit object.

The example code snippet:

from qermit . z e r o _ n o i s e _ ex t r a po l a t io n

import gen_ZNE_MitEx , Folding , Fit

zne_mitex = gen_ZNE_MitEx (

backend = device_backend ,
nois e_ sc aling_list =[3 , 5] ,
folding_type = Folding . circuit ,
fit_type = Fit . exponential ,

)

1

2

3

4

5

6

7

8

9

1

1

2

3

4

5

6

7

8

18

9

10

11

12

13

1

1

2

3

4

5

6

7

8

9

10

11

12

13

14

mitex_results = zne_mitex . run ([

experiment ])

print ( mitex_results [0])

graph = zne_mitex . get_task_graph ()

produces the output:

{( Znode [1] , Znode [2]) :
-0.986666667477977}

with graph being the TaskGraph of Fig. 3. Note that
ZNE had returned a value closer to the ideal value of
−1 than did the example in Appendix A.2.1 where no
error mitigation was used.

A.2.3 CDR MitEx in Qermit

has

CDR

MitEx

required

The
inputs:
device backend, the possibly noisy backend used
to approximate the expectation of the inputted
classical
circuits;
simulator; n non cliffords, the number of non-
Cliﬀord gates in the training circuits; n pairs; and
total state circuits, the total number of training
circuits to use.

simulator backend,

an ideal

The example code snippet:

from qermit .

c l i f f o r d _ n o i s e _ c h a r a c t e r i s a t i o n
import gen_CDR_MitEx

cdr_mitex = gen_CDR_MitEx (

device_backend = device_backend ,
simulator_ backend = AerBackend () ,
n_non_cliffords =2 ,
n_pairs =2 ,
total _s ta te _c i rcu i ts =50 ,

)

mitex_results = cdr_mitex . run ([

experiment ])

print ( mitex_results [0])

graph = cdr_mitex . get_task_graph ()

produces the output:

1

{( Zq [1] , Zq [2]) : -1.00000000000000}

with graph being the TaskGraph of Fig. 4. Here we
again see an improvement on the result from Ap-
pendix A.2.1.

B Backend Properties

connectiv-
The
coupling map,
ity between the qubits, of
the ibm lagos and
ibmq casablanca devices is as seen in Fig. 9. The
gates available on the both devices are:

describing

the

0

1

2

3

4

5

6

Figure 9: ibm lagos and ibmq casablanca coupling map.
Vertices in the coupling map correspond to qubits, while
edges indicate that 2-qubit gates can be acted between the
qubits which correspond to the vertices connected by the
edge.

Property

Average Value

T1 time
T2 time
Single qubit error rate
CX error rate
Readout error rate

128.1
99.50
2.307 × 10−4
8.973 × 10−3
1.164 × 10−2

Table 1: ibm lagos device properties.

Emulation of the devices requires compilation to the
coupling map described in Fig. 9, and a rebasing of the
gates used by the circuits to the limited but universal
set of Eq. (16).

Average noise properties reported by the devices
over the time our experiments were conducted are
seen in Tables 1 and 2

C Additional Results Details

Here we present some additional details about the ex-
periments discussed in Section 5. In particular in Ta-
ble 3 and Table 4 we give the average absolute errors
and absolute mitigation errors, as deﬁned in Deﬁni-
tion 4.1, for the results presented in Fig. 7 and Fig. 8
respectively. Note that we present mean values here,
rather than medians as in Fig. 7 and Fig. 8.

Property

Average Value

T1 time (µs)
T2 time (µs)
Single qubit error rate
CX error rate
Readout error rate

108.5
124.1
1.713 × 10−4
8.075 × 10−3
2.081 × 10−2

{CX, RZ, SX, X, 1}

(16)

Table 2: ibm casablanca device properties.

19

mirrored

ibm lagos

un-mirrored

ibmq casablanca

mirrored

un-mirrored

Width

Depth

none ZNE CDR none ZNE CDR none ZNE CDR none ZNE CDR

2
2
2
2
3
3
3
4
4
5

2
3
4
5
2
3
4
2
3
2

0.026 0.034 0.020

0.047 0.049 0.023

0.053 0.046 0.016 0.025 0.426 0.119 0.062 0.052 0.012 0.032 0.016 0.178
0.035 0.010 0.031
0.078 0.104 0.005 0.070 0.110 0.098 0.079 0.033 0.052 0.068 0.029 0.047
0.055 0.049 0.039
0.189 0.321 0.070 0.073 0.509 0.018 0.163 0.604 0.084 0.063 0.050 0.008
0.237 0.384 0.232
0.562 0.721 0.059 0.254 1.017 0.043 0.350 0.286 0.163 0.211 0.403 0.030
0.508 0.642 0.051 0.253 0.898 0.256 0.307 0.305 0.024 0.252 0.435 0.180
0.359 1.222 0.455
0.562 0.595 0.017 0.365 1.209 0.282 0.335 0.604 0.015 0.335 0.427 0.141

0.227 1.152 0.051

0.495 1.367 0.180

Average

0.325 0.404 0.036 0.184 0.677 0.109 0.216 0.314 0.058 0.165 0.302 0.134

Table 3: Mean absolute error and absolute mitigation error for Pauli-Gadget Circuits experiments presented in Fig. 7.

mirrored

ibm lagos

un-mirrored

ibmq casablanca

mirrored

un-mirrored

Width

Depth

none ZNE CDR none ZNE CDR none ZNE CDR none ZNE CDR

2
2
2
2
3
3
3
4
4
5

2
3
4
5
2
3
4
2
3
2

0.063 0.069 0.095

0.071 0.032 0.090

0.076 0.009 0.019 0.048 0.048 0.036 0.089 0.011 0.018 0.062 0.026 0.031
0.110 0.046 0.037
0.121 0.028 0.028 0.040 0.053 0.067 0.125 0.011 0.029 0.089 0.028 0.065
0.112 0.052 0.067
0.089 0.040 0.051 0.119 0.095 0.136 0.116 0.042 0.035 0.082 0.042 0.057
0.303 0.248 0.339
0.328 0.404 0.213 0.183 0.321 0.233 0.252 0.122 0.093 0.112 0.211 0.110
0.232 0.048 0.203 0.246 0.669 0.285 0.177 0.055 0.270 0.144 0.068 0.185
0.243 0.080 0.180
0.244 0.050 0.244 0.223 0.584 0.259 0.227 0.102 0.193 0.224 0.416 0.352

0.288 1.100 0.368

0.208 0.092 0.203

Average

0.182 0.097 0.126 0.199 0.306 0.177 0.164 0.057 0.106 0.148 0.122 0.142

Table 4: Mean absolute error and absolute mitigation error for Random Circuits experiments presented in Fig. 8.

20

D Behaviour of EM Methods Under
Noise Models

D.1 Global Depolarising Noise Model

Depolarising noise acts isotropically on quantum
states, hence its eﬀect on error mitigation schemes is
straightforward to analyse. It takes any state ρ acting
on N qubits to

D(ρ) = (1 − p)ρ + p

I
2N

(17)

where p is the depolarisation factor. It commutes with
any other linear map so D ◦ U = U ◦ D for any unitary
channel U. Suppose that a unitary circuit U contains
d1 single qubit gates and d2 two-qubit gates, with
average error p1 and p2 respectively.

If we model the error as globally depolarising, then
we have that for any traceless observable O the noisy
expected value hOiN (in the limit of inﬁnite shots)
depends on the exact value hOi via

hOiN = (1 − p1)d1(1 − p2)d2hOi

(18)

For this simpliﬁed noise model, the relative mitigation
error remains constant and is independent of the ob-
servable and the speciﬁc circuit structure. It depends
only on the error mitigation method and the number
of noisy gates and their average errors.

D.1.1 Zero Noise Extrapolation - Polynomial Fit

We assume that the error rates are increased artiﬁ-
cially via unitary folding with noise stretching factors
α0 = 1, α1 = 2k1 + 1 and α2 = 2k2 + 1. Then the
mitigated expected value under a polynomial ﬁt via
Richardson extrapolation is

hOiEM = F0hP iα0

+ F1hP iα1

+ F2hP iα2

(19)

where the coeﬃcients satisfy

Fi = Y

i6=j

αj
αi − αj

(20)

and hOiαi
Therefore the relative error mitigation factor is

= γαihOi where γ := (1 − p1)d1(1 − p2)d2 .

Figure 10: Contour plot of relative mitigation error in terms
of D (x-axix) and error rate p (y-axis) for ZNE with polyno-
mial extrapolation

for two levels of noise α0, α1 and therefore in the ab-
sence of ﬁnite sampling errors (cid:15)ZN E,exp = 0.

D.1.3 Learning with Cliﬀord Data Regression

Cliﬀord-based learning is speciﬁcally designed for
(global) stochastic Pauli noise, case in which the linear
ansatz exactly matches the noisy expectation values
i.e

hOiN = F1hOi + F0

(23)

Therefore,
in the absence of sampling errors the
method should fully correct for the depolarising noise
model

(cid:15)CDR = 0

(24)

D.2 Noisy Classical Simulations

We perform extensive classical simulations of the ex-
periments conducted in Section 5, with the results
also discussed there. In particular depolarising noise
simulations with Random Circuits and Pauli-Gadget
Circuits are found in Fig. 11 and Fig. 12 respec-
tively. Emulations additionally classically simulates
noise, motivated by properties of the device. In the
case of the emulates experiments shown here this noise
models includes:

(cid:15)ZN E,poly =

1 − F0γ − F1γα1 − F2γα2
1 − γ

(21)

Readout error: Single qubit readout errors on mea-

surements.

For example, the minimal number of folds e.g k1 = 1
and k2 = 2 gives F0 = 15

4 and F2 = 3
8 .

8 , F1 = − 5

D.1.2 Zero Noise Extrapolation - Exponential Fit

The eﬀect of global depolarising noise model is so that
= γαihOi, which means
for diﬀerent noise levels hOiαi
that an exponential ZNE ﬁt exactly captures the un-
derlying noise model with the error mitigated observ-
able given by

hOiEM = (hOiα0

)

α1

α1−α0 (hOiα1

α0
α0−α1

)

(22)

21

Single-qubit errors: depolarizing error followed by
a thermal relaxation error on each qubit the gate
acts on.

Two-qubit gate errors: depolarizing error followed
by single-qubit thermal relaxation error on each
qubit participating in the gate.

In particular, emulations with Random Circuits
and Pauli-Gadget Circuits are found in Fig. 13 and
Fig. 14 respectively.

(a) Random Circuits mitigated using ZNE.

(b) Random Circuits mitigated using CDR.

(c) Mirrored Random Circuits mitigated using ZNE.

(d) Mirrored Random Circuits mitigated using CDR.

Figure 11: Random Circuits run on a depolarising noise simulator. Each square presents the results of 10 circuits. 500,000
shots are taken in total for each circuit by ZNE and CDR, and 100,000 in the case of the un-mitigated runs.

(a) Pauli-Gadget Circuits mitigated with ZNE.

(b) Pauli-Gadget Circuits mitigated with CDR.

(c) Mirrored Pauli-Gadget Circuits mitigated with ZNE.

(d) Mirrored Pauli-Gadget Circuits mitigated with CDR.

Figure 12: Pauli-Gadget Circuits run on a depolarising noise simulator. Each square presents the results of 10 circuits.
500,000 shots are taken in total for each circuit by ZNE and CDR, and 100,000 in the case of the un-mitigated runs.

22

(a) Random Circuits mitigated with ZNE.

(b) Random Circuits mitigated with CDR.

(c) Mirrored Random Circuits mitigated with ZNE.

(d) Mirrored Random Circuits mitigated with CDR.

Figure 13: Random Circuits on emulator backend. Each square presents the results of 10 circuits. 160,000 shots are taken
in total for each circuit by ZNE and CDR, and 32,000 in the case of the un-mitigated runs.

(a) Pauli-Gadget Circuits mitigated with ZNE.

(b) Pauli-Gadget Circuits mitigated with CDR.

(c) Pauli-Gadget Circuits mitigated with ZNE.

(d) Pauli-Gadget Circuits mitigated with CDR.

Figure 14: Pauli-Gadget Circuits on emulator backend. Each square presents the results of 10 circuits. 160,000 shots are
taken in total for each circuit by ZNE and CDR, and 32,000 in the case of the un-mitigated runs.

23

E Performance of Error Mitigation

E.1 Certifying Error Mitigation

In practical applications we don’t have a priori ac-
cess to the exact value hOi, as this is the quan-
tity we aim to estimate in the ﬁrst place. Typi-
cally proof of principle demonstrations of error miti-
gation strategies require a classical simulation to com-
pare against, and the measures introduced in Deﬁni-
tion 4.1 also assume that hOi can be directly com-
puted. Therefore, the problem of assesing the per-
formance of error mitigation on a speciﬁc circuit/ob-
servable in regimes beyond classical simulations be-
comes similar to that of certifying quantum compu-
tations. For the purpose of benchmarking the tech-
niques for increasing depth and qubit number one
may employ scalable benchmarks consisting, for ex-
ample, of mirrored circuits. Mirrored circuits – with
the general form C(n, d) := U1U †
d where
Ci are sampled from a speciﬁed class of primitive
circuits. Then for any observable the ideal expecta-
tion of the target state ρmirror = C(n, d)ρ0C(n, d)† is
tr(Oρmirror) = tr(Oρ0). For example, if O is a Pauli
observable and ρ0 corresponds to the pure product
state |0i⊗w, then the mirrored circuits will give ideal
expected values of either {0, 1, −1}, which can be ef-
ﬁciently determined. Then the relative error of miti-
gation for the mirrored circuit

2 ...UdU †

1 U2U †

(cid:15)mirror(P ) = |hP iEM, ˜ρmirror − hP iρ0|
|hP iN, ˜ρmirror − hP iρ0 |

(25)

can be used as a proxy for the performance of error
mitigation on the target state ρ = U1...Ud ρ0 U †
1 ....U †
and observable P .

d

E.2 Relative Error of Mitigation Under Finite
Sampling Statistics

In [31] the authors derive conditions for when the ra-
tio of two independent normally distributed random
variables can itself be approximated by a normal dis-
tribution. The following is a direct corrolary of that
result.

Lemma E.1. Let X, Y be two independent normal
variables with positive means µX , µY and variances
X and σ2
σ2
Suppose the coeﬃcient of variation
Y .
≤ λ < 1. ∀(cid:15) > 0 there exists a value η((cid:15))
δY := σY
µY
such that if 0 < δY ≤ η((cid:15)) then the probablity distribu-
tion function FZ of Z = X/Y approximates a normal
distribution G with mean µ = µX
µY

and variance

σ = µ2
X
µ2
Y

(cid:18) σ2
X
µ2
X

+ σ2
Y
µ2
Y

(cid:19)

(26)

with |FZ(z) − G(z)| ≤ (cid:15) on the interval z ∈ [µ − σ
σ
λ

] .

λ , µ +

In our case, X = h ˆOiEM − hOi corresponds to the
diﬀerence between the error mitigated estimator and
the exact value and Y = h ˆOiN − hOi corresponds to
the diﬀerence between the noisy estimator and exact
value of the target expectation value. The expected
values are then µX = EhOiEM − hOi respectively
µY = EhOiN − hOi with variances V ar[h ˆOiEM ] =
EM and V ar[h ˆOiN ] = σ2
σ2
N .
Since we are interested in relative error of mitiga-
tion and this corresponds to absolute values of Z, then
one can assume that µX and µY are positive quanti-
ties because if that happens not to be the case for a
ﬁxed observable then we have the freedom to rede-
ﬁne the random variable X and Y so as to ensure the
positivity constraint.

In the following section we discuss the remaining
condition that controls the signal to noise ratio and
how the tension between low levels of noise and high
variance in the noisy estimators make it diﬃcult to
quantify the performance of error mitigation in this
regime.

E.3 Detrimental Eﬀect of Low Noise Level

Therefore the only condition left to ensure that
Lemma E.1 can be directly applied to (cid:15)(O) is that the
coeﬃcent of variation δY =
EhOiN −hOi is suﬃciently
small. As in the main text if ρ = U1 ... Udρ0U †
d ... U †
1
is the target quantum state hOi = T r(Oρ) and its
noisy implementation ˜ρ := E1 ◦ U1 ◦ ... ◦ Ed ◦ Ud(ρ0)
then EhOiN = tr(O ˜ρ). Now we are looking at the
diﬀerence,

σN

µN = |tr(O(ρ − ˜ρ)| ≤ ||O||∞||ρ − ρ0||1

(27)

≤ ||O||∞||U1 ◦ ... ◦ Ud − E1 ◦ U1... ◦ Ed ◦ Ud||(cid:5)

(28)

where we have used the Holder inequality in the
ﬁrst bound, and then taken a supremum over
all possible ρ to bound by the diamond norm
||Φ||(cid:5) = supX:||X||1≤1||(Φ ⊗ I)(X)||1. For conditions
of Lemma E.1 to be met we want that µN ≥ σN
λ for
some λ ≤ 1. This along with sub-multiplicativity of
the diamond norm implies that

σN ≤ λ||O||∞demax

(29)

where emax is maximal (gate) error rate. Since σ2
N
is the variance of the sample mean estimator for the
noisy expectation value h ˆOiN , it will depend on the
number shots n0 so that σN = σ0√
, where σ0 is the
n0
variance of an individual (i.i.d) sample of a single mea-
surement. The condition Eq. (29) becomes

σ0√
n0

≤ λ d emax ||O||∞.

(30)

In particular this shows that, if one is to ensure that
the relative error of mitigation follows a normal dis-
tribution under ﬁnite sampling then one must have

24

the above trade-oﬀs between the the number of shots
and depth. The condition also puts a lower bound on
the depth of the circuit.

E.4 Eﬀect of Finite Sampling on the Classical
Optimisation to Determine Fit Parameters

In this section we consider the eﬀect of ﬁnite size sam-
pling on ﬁtting the parameters of the functional model
F. This type of analysis depends not only on the form
of the functional F itself but also on the classical opti-
mization algorithm used to ﬁt the function with noisy
data D.

For simplicity, we will assume that step III involves
a linear least square optimisation and we recall the
following analytical expression for the ﬁt parameter
in a linear model yi = Axi + B for K data samples

PK

ˆA =

i=1
PK
ˆB = ¯y − ˆA¯x

(xi − ¯x)(yi − ¯y)
(xi − ¯x)2

i=1

(31)

(32)

where the estimators minimise the mean square er-
ror PK
(yi − Axi − B)2. In the examples considered
i=1
below, for CDR and ZNE the ﬁnite size sampling er-
rors imply that the yi’s can be viewed as normally
distributed random variables.

CDR We consider a linear functional model as in
Eq. (8) with least square optimisation as a classical
method to determine the model parameters. Then,
the objective function is minimised by the values

PK

j=1

ˆF1 =

(Dc
PK
ˆF0 = ¯Dq − ˆF1

j=1

¯Dc

j − ¯Dq)

j − ¯Dc)(Dq
(Dc

j − ¯Dc)2

(33)

(34)

where ¯Dq = 1
j=1 Dq
the error mitigated estimator is given by

j and ¯Dc = 1

PK

K

K

PK

j=1 Dc

j and

h ˆOiEM = h ˆOiN − ˆF0

ˆF1

If ˆF1 were a constant ﬁxed value F1 then

σ2
EM

=

1
F 2
1

σ2
N .

(35)

(36)

ˆF1 itself

However,
is an unbiased estimator con-
structed out of (noisy) sample mean estimators so it
incurs a variance due to ﬁnite number of shots so that
j − ¯Dc)2
C 2

V ar[ ˆF1] =

1
K 2

K
X

K
X

(Dc

!

−

σ2
j
nk

σ2
j
nj

(37)
j − ¯Dc)2. Under the assump-
for C := PK
tion that shots are equally distributed and σj = σ0

(Dc

j=1

k=1

j=1

C

σ2
0
n2
0

with nj = n0 for every circuit evaluation it sim-
pliﬁes to V ar[ ˆF1] = 1
K−1
. Putting it all to-
K
gether, and treating ˆF1 and h ˆOiN as (normally-
distributed) independent random variables then the
variance in the error mitigated estimator would be
σ2

EM
ZNE We consider exponential extrapolation and
= F0eF1λi
the parameters in the functional model Dλi
with h ˆOiEM = ˆF0 determined via linear least square
optimisation. Linearisation of the exponential func-
tion results in the following estimators via a linear
regression

= V ar[ h ˆOiN − ˆF0

ˆF1

].

ˆF0 = exp( ¯D − ˆF1
PK

ˆF1 =

i=1

¯λ)
(λi − ¯λ)(logDq
(λi − ¯λ)2
PK

i=1

λi

− ¯D)

(38)

(39)

. There-

(40)

where ¯λ = 1
i=1 logDq
λi
fore the error mitigated estimator becomes

i λi and ¯D = 1

PK

P

K

K

ˆF0 =

K
Y

i=1

(Dq
λi

)( 1

K − ¯λ

C (λi−¯λ))

where we denoted by C := PK
i=1

(λi − ¯λ)2.

25

 
