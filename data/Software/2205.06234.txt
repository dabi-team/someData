SIBILA:  High-performance 
and 
interpretable  machine  learning  join  efforts  toward 
personalised  medicine  in  a  novel  decision-making 
tool 

computing 

Antonio Jes√∫s Banegas-Lunaa,*, Horacio P√©rez-S√°ncheza 

a Structural Bioinformatics and High-Performance Computing Research Group (BIO-HPC), 
Universidad Cat√≥lica de Murcia (UCAM), Murcia 30107, Spain 

Keywords 

deep learning, high-performance computing, explainable artificial intelligence, personalised 
medicine, consensus, decision-making 

Abstract 

Background and Objectives 

Personalised medicine remains a major challenge for scientists. The rapid growth of Machine 
learning  and  Deep  learning  has  made  it  a  feasible  alternative  for  predicting  the  most 
appropriate therapy for individual patients. However, the lack of interpretation of their results 
and high computational requirements make many reluctant to use these methods. 

Methods 

Several  Machine  learning  and Deep learning models  have been  implemented  into  a single 
software tool, SIBILA. Once the models are trained, SIBILA applies a range of interpretability 
methods  to  identify  the  input  features  that  each  model  considered  the  most  important  to 
predict.  In  addition,  all  the  features  obtained  are  put  in  common  to  estimate  the  global 
attribution of each variable to the predictions. To facilitate its use by non-experts, SIBILA is 
also available to all users free of charge as a web server at https://bio-hpc.ucam.edu/sibila/. 

Results 

SIBILA  has  been  applied  to  three  case  studies  to  show  its  accuracy  and  efficiency  in 
classification  and  regression  problems.  The  first  two  cases  proved  that  SIBILA  can  make 
accurate  predictions  even on  uncleaned datasets. The  last case  demonstrates that  SIBILA 
can be applied to medical contexts with real data. 

Conclusion 

With  the  aim  of  becoming  a  powerful  decision-making  tool  for  clinicians,  SIBILA  has  been 
developed. SIBILA is a novel software tool that leverages interpretable machine learning to 

 
make accurate predictions and explain how models made those decisions. SIBILA can be run 
on high-performance computing platforms, drastically reducing computing times. 

1. Introduction 

The rapid development of technologies has helped artificial intelligence (AI) become a well-
known and reliable tool for researchers in academia and industry. Its ability  to analyse vast 
amounts of data has become a powerful tool in science and businesses. Looking for repetitive 
patterns  among  such  datasets  is  a  complex  but  necessary  task  that  needs  to  be  done  to 
extract knowledge from past events. Once the rules managing raw data have been identified, 
AI models can use them to make predictions about new unexplored samples. 

Machine  learning  (ML)  and  deep  learning  (DL)  are the  two types  into  which AI  models  are 
often classified [1], depending on the complexity of the algorithm used. Both types of models 
are  flexible  enough  to  analyse  a  range  of  datasets,  including  tabular  data,  time  series  and 
images. This adaptability to different contexts has propelled their application in traditional and 
fundamental areas of science, such as biology [2,3], chemistry [4,5] and medicine [6]. But not 
only  classical  scientific  areas  can  profit  from  ML  and  DL,  but  also  new  and  related 
multidisciplinary  fields.  This  is  the  case  for  genomics  [7,8],  bioinformatics  [9]  and  drug 
discovery [10-12], to name a few. 

Of all the scientific areas mentioned, medicine is probably the one with the highest visibility in 
society.  Advances  related  to medicine  are  frequently  considered  highly  relevant;  therefore, 
any help is always welcome. Consequently, how ML and DL help learn how diseases could 
be cured or treated is a timely topic. As a result, more than a few examples of both methods 
applied  to  medicine  can  be  found  in  the  literature.  P√©rez-Gand√≠a  et  al.  [13]  developed  a 
decision  support  system  that  helps  patients  with  type  1  diabetes  mellitus  to  monitor  their 
glucose levels daily. This way, abnormal situations can be anticipated, and measures can be 
taken earlier than a traditional follow-up.  

Evaluating  and  predicting  therapy  outcomes  may  be  of  great  help  for  doctors  in  decision 
making. An extensive revision of works about outcome prediction in patients with depression 
was made by  Lee et  al.  [14].  Even  more  dramatic  than mood  disorders  is  the  incidence  of 
cancer in the population. Early detection is often believed to be the most effective treatment. 
Hence it is one of the significant targets of DL when applied to cancer therapy. In the case of 
colorectal  cancer  (CRC),  the  effectiveness  of  colonoscopy  is  measured  by  its  adenoma 
detection  rate,  which  can  be  increased  by  using  convolutional  neural  networks  (CNN)  for 
image processing [15]. Furthermore, ML algorithms can predict the presence of lymph node 
metastasis, which represent a risk factor for patients  who need surgery, therefore reducing 
the  number  of unnecessary  surgeries [16].  Although  many  other  works  applied  ML  and DL 
algorithms to medical contexts, being able to adapt a standard therapy to an individual patient, 
the so-called personalised therapies, remains a challenge [17-20]. 

Although DL models are a powerful tool for decision making in medicine and the number of 
clinical studies in the field of ML has grown a lot in the last years [21], they still lack the level 
of  interpretation  required  to  be  understood  by  physicians.  Thus,  an  extra  layer  should  be 
added on top of the architecture to make the raw predictions provided by the models easier to 

 
 
 
 
understand by  the general public.  Additionally,  this extra layer  increases the computational 
resources,  programming  complexity  and  user  interactivity  difficulties  required  to  train  the 
model  and  make  predictions.  The  models  would  have  to  be  run  on  high-performance 
computing (HPC) platforms,  and even then, the whole process might take several hours or 
days [22].  

In this paper, and to solve previously described problems, we describe SIBILA, a command-
line  code  that  implements  a  novel  ML  and  DL  engine  that  can  be  run  locally  or  on  a 
supercomputing  platform,  resulting  in  very  competitively  response  times  and  ease  of  use. 
Moreover, it applies a diversity of interpretability methods to provide the final user with a deep 
insight  into  the  decisions  that  led  the  model  to  make  a  prediction.  In  addition,  SIBILA 
functionalities  are  also  available  through  a  freely  accessible  web  server  at  https://bio-
hpc.ucam.edu/sibila/. Three case studies will be presented in this paper to discuss and prove 
the effectiveness of the models. 

2. Materials and Methods 

This  section  describes  the  main  features  of  SIBILA,  including  the  ML/DL  models  and 
interpretability methods available, how the consensus works and its implementation in HPC. 
SIBILA  has  been  programmed  in  python3,  and  it  relies  on  a set  of  widely  used  libraries  to 
implement both the models and interpretability methods. 

2.1.  Machine learning and deep learning models 

SIBILA implements a collection of ML and DL models in a flexible way that could easily be 
extended in the future. Table 1  summarises  the  available models,  algorithms,  libraries and 
whether they support regression and classification. 

Table 1. List of models and algorithms implemented by SIBILA. 

MODEL 

NAME 

LIBRARY 

CLASSIFICATIO
N 

REGRESSION 

DT 

RF 

Decision Tree 

Random Forest 

SVM 

Support Vector Machine 

scikit-learn 

scikit-learn 

scikit-learn 

XGBOOST  eXtreme Gradient Boosting 

xgboost 

KNN 

ANN 

K-Nearest Neighbours 

scikit-learn 

Artificial Neural Network 

TensorFlow 2 

RIPPER 

Repeated Incremental Pruning to 
Produce Error Reduction 

Wittgenstein 

RLF 

RuleFit 

refit 

Yes 

Yes 

Yes 

Yes 

Yes 

Yes 

Yes 

Yes 

Yes 

Yes 

Yes 

Yes 

Yes 

Yes 

No 

No 

All  models,  except  ANN,  perform  an  automatic  grid  search  which  means  that  SIBILA  tries 
several model configurations and chooses the best one. The case of ANN is different because 
of the difficulties of creating different topologies. Therefore, an ‚Äúexternal" grid search method 
is implemented, which generates a JSON file for each model. 

 
 
 
 
2.2.  Evaluation metrics 

To assess the accuracy of the models, some metrics are calculated based on the test data. 
Since different metrics measure classification and regression problems, a good set has been 
implemented in SIBILA. Table 2 lists all available metrics. 

Table 2. Evaluation metrics for classification and regression problems. 

CLASSIFICATION 

REGRESSION 

Confusion matrix 
Accuracy 
Precision 
F1 score 
Recall 
Specificity 
Area Under the Curve (AUC) 

Pearson coefficient 
Coefficient of determination (R2) 
Mean average precision 
Mean absolute error (MAE) 
Mean squared error (MSE) 

2.3. 

Interpretability methods 

As well as performance metrics, many interpretability algorithms are employed to detect the 
most  relevant  input features,  their  relevance and,  in some cases,  their positive  or  negative 
contribution. Table 3 summarises these algorithms. It is not the aim of this manuscript to go 
into the algorithms; therefore, only those details that are relevant for understanding the output 
of SIBILA will be given. Additionally, all information regarding the attributions calculated by the 
algorithms is bulked into CSV files so that users can see the raw data provided by SIBILA. 
They can then use it for further analysis. 

Table 3. Interpretability methods are available. 

Permutation importance 

scikit-learn 

[23, 24] 

METHOD 

LIBRARY 

REF 

Local Interpretable Model-Agnostic Explanations (LIME) 

Shapley values 

Integrated gradients 

lime 

shap 

alibi 

[24, 25] 

[24, 26] 

[27] 

Diverse Counterfactual Explanations (DiCE) 

dice-ml 

[24, 28] 

Partial Dependence Plot (PDP) + Individual Conditional Expectation (ICE) 

scikit-learn 

[24, 29] 

Accumulated Local Effects (ALE) 

alibi 

[24, 30] 

While PDP and ALE create individual graphs for each input variable, the rest of the methods 
make  one  graph  displaying  the  attribution  of  all  inputs.  Additionally,  since  LIME,  Shapley 
values, integrated gradients, and DiCE plot attributions by individual samples, it was decided 

 
 
 
 
 
to add a global graph to display the average attribution of the variables across all samples. 
This way users have an overview of the global attribution of each input. 

2.4.  Execution on HPC platforms 

As  mentioned  above,  SIBILA  offers  the  possibility  to  be  run  either  locally  or  in  a  parallel 
environment. To facilitate  its  execution  and  increase  its  portability,  a Singularity  [31]  image 
containing all the dependencies required by the engine was created. This way, it can be run 
on any computer that supports Singularity.  

Singularity  was  chosen  as  the  container  because  of  the  current  trend  of  using  Singularity 
instead of Docker in most HPC infrastructures [32] and because of the availability on most of 
the  supercomputing  platforms  we  have  access  to.  Besides,  SIBILA  supports  the  queue 
parameter  (-q),  which  allows  the  execution  of  each  interpretability  algorithm  on  a  separate 
node of the HPC platform. This way of working dramatically reduces the time needed to obtain 
the results. 

2.5.  Consensus 

SIBILA  can  run  several  models  on  the  same  dataset  and,  for  each  model,  a  collection  of 
interpretability models is calculated. Having generated such a large amount of data, it can be 
challenging to identify the most relevant input features to make a decision. In addition, different 
models and algorithms may return different results, leading to inconsistencies. 

To reduce uncertainty in interpreting results, a consensus stage was implemented. The three 
types of consensuses provided by SIBILA are introduced. As proposed in a recent study [33], 
a synthetic dataset for binary classification was created to simulate a real input. The dataset, 
consisting of 17 input variables with values in the range [0,1] and 1948 samples, was built with 
some hidden rules to determine the output class (Eq. 1). The aim of our tests was to identify 
such  rules  with  the  consensus  functionality.  Once  interpretability  was  calculated,  the 
consensus was executed. 

ùëêùëôùëéùë†ùë†  = (ùëñùëì 0.7  <=  ùêπ3  <=  0.9) ùê¥ùëÅùê∑ (0.2  <= ùêπ6  <= 0.35) ùë°‚Ñéùëíùëõ 1 ùëíùëôùë†ùëí 0 

Equation 1. Rules implemented in the test dataset. 

 
 
 
 
Figure 1. Consensus is calculated by the attribution given by one single interpretability method on many models. 

Firstly,  for  each  interpretability  method,  the  attributions  of  the  inputs  for  each  model  are 
averaged (Fig. 1). Since models with a low AUC may not be reliable, a cut-off is introduced to 
disregard them and avoid wrong interpretations. The default cut-off is 0.75, but the users can 
modify it. According to Shapley values, as shown in Figure 1, F6 and F3 are the most relevant 
features because they have been given the highest attributions.  

 
 
 
 
Figure 2. Consensus is calculated by the ranking established by one single interpretability method on many 
models. 

Although the attributions may be the best metric for assessing the importance of the variables, 
the  different  methods  applied  may  not  be  aligned,  resulting  in  unequal  attribution  values. 
Based on this assumption, the second type of consensus averages the ranking of the input 
variables (Fig. 2). Again, Figure 2 shows that F6 and F3 are clearly the best ranked features 
and, consequently, the most important ones. 

 
 
 
 
 
 
 
 
 
Figure 3. Consensus is calculated by the ranking given to one single model by many interpretability methods. 

Finally, instead of grouping by interpretability method, all the explanations obtained for a given 
model are merged (Fig. 3). Note that this consensus is based on the ranking of the features 
because  each  interpretability  algorithm  ranks  attributions  on  a  different  scale.  According  to 
this calculation, F6 and F3 remain the most important features when using the ANN model. 

2.6.  Code modularisation 

The  code  of  SIBILA  has  been  conceived  to  be  modular  and  flexible  to  be  extended  in  the 
future.  Based  on  this  idea,  different  modules  were  implemented  (Fig.  4).  The  blue  boxes 
represent the modules the code is structured in. They are all surrounded by a continuous red 
line  meaning  that  they  are integrated  into  the  core  of  SIBILA. In addition,  some  scripts  are 
provided for pre- and post-processing tasks, such as the encoding of a dataset with the one-
hot encoding technique, the creation of synthetic datasets following a given set of rules and 
the calculation of three types of consensuses. 

When using the queue parameter, the interpretability algorithms are executed in parallel, as 
shown in Figure 5. 

 
 
 
 
Figure 4. Schematic representation of the SIBILA modules. 

Figure 5. Parallelisation of interpretability algorithms in SIBILA. 

3. Results 

This section introduces SIBILA through three case studies. The aim of the first two samples is 
to  show  the  ability  of  SIBILA  to  make  predictions  in  both  classification  and  regression 
problems. Finally, we demonstrate that SIBILA is useful in the medical field. It is used to predict 
the chances of suffering from a heart attack. 

3.1. Bike rental prediction 

The first case study is based on Molnar [24]. We use SIBILA to estimate the number of bike 
rentals  in  the  future  and  identify  what  features  lead  to  such  predictions.  We  tested  all  the 
models supporting the regression and chose the coefficient of determination (R2) as the metric 
to assess the accuracy of the models. We observed that ANN (R2=1), XGBOOST(R2=1) and 
RF (R2=0.999) outperformed the other models; therefore, the consensus was calculated for 
them to identify the most relevant features. 

 
 
 
 
Figure 6. Correlation between actual and predicted values for ANN (left), XGBOOST (middle) and RF (right) 
models. 

Figure 7. List of the most relevant features for ANN, XGBOOST and RF models. 

According to ANN, the date is the most important feature, followed by the closely related year 
and month. Subsequently, the number of registered and casual users seems to be relevant. 
XGBOOST pays attention to the number of registered and casual users and the reservation 
date. RF returns the same explanation as XGBOOST. In short, it can be said that the number 
of rentals is closely linked to the number of reservations and the date, which indicates that 
depending on the season, people may feel like making a reservation or not. 

Regarding computational cost, RF and XGBOOST took almost 1 minute to be trained, while 
ANN only needed 11 seconds. The low number of epochs and validation splits required to find 
the optimal solution made the network very efficient. Once the models were trained, our tool 
computed interpretability, taking 58 minutes to explain the results for RF and XGBOOST and 

 
 
 
 
 
 
90  minutes to  build  explanations  for ANN.  In  this  case,  the  interpretable nature  of  RF  and 
XGBOOST accelerated this stage. 

3.2. Robustness of predictions in noisy datasets 

To prove how SIBILA can distinguish between valuable and noisy data, a synthetic dataset 
was created for a binary classification problem. The dataset contains 2000 samples and 100 
input features with values between 0 and 1. The output class is calculated according to Eq. 2. 

ùëêùëôùëéùë†ùë†  =  ùëñùëì ((0.1 <= ùêπ4 <= 0.5) ùê¥ùëÅùê∑ (ùêπ10 >= 0.6) ùê¥ùëÅùê∑ (ùêπ20 <= 0.8) ùê¥ùëÅùê∑                     (ùêπ31

<= 0.25)  ùê¥ùëÅùê∑ (0.4 <= ùêπ57 <= 0.7) ùê¥ùëÅùê∑ (ùêπ85 >= 0.4)) ùë°‚Ñéùëíùëõ 1 ùëíùëôùë†ùëí 0 

Equation 2. Rules implemented in the test dataset. 

Working with this dataset, we expect SIBILA to identify F4, F10, F20, F31, F57 and F85 as 
the most indicative features. Any subset of these variables would also be considered a good 
approximation because there could be unknown hidden dependencies in the data. 

First,  all  models  were  trained,  with  ANN,  RF,  RLF,  RP,  SVM  and XGBOOST  obtaining the 
perfect  classification  (AUC=1).  In  addition,  KNN  also  returned  a  high  classification  rate 
(AUC=0.976). Secondly, we ran the consensus scripts, which produced the expected result 
(Figure 8). 

Figure 8. The consensus was obtained from the six perfect classifiers (ANN, XGBOOST, RP, SVM, RF, RLF). 

Results prove that at least four of the six selected models have identified the six features ruling 
the dataset. Moreover, ANN and RF identified all the variables as the top ranked ones, while 
RLF and SVM found them among the top seven. 

 
 
 
 
 
 
 
 
Figure 9. The boosting machine model clearly segregated the samples based on F4 and F10. Edge values (F4 ‚Üí 
0.1 and F10 ‚Üí 0.6) match Eq. 2. 

Finally, we examine in detail those models based on rules, with the intention of discovering 
edge values. The boosting machine model clearly separates the samples by a cut-off value of 
F4 and F10 (Fig. 9). Other rule-based algorithms, such as RP and RLF, returned a set of rules 
in which only the variables of Eq.2 were present. 

Regarding computational time, it should be noted that the training phase took a few seconds 
for all the models, and interpretability took up to 3 hours. 

3.3. Heart attack prediction 

Finally, SIBILA is used to predict the probability of a patient suffering a heart attack. Data was 
imported  from  the  Kaggle  repository  [34]  and  curated  to  model  it  as  a  binary  classification 
problem. 

After  running  all  models,  the  highest  scoring  ones  obtained  similar  accuracy:  ANN 
(AUC=0.870),  RF  (AUC=0.895),  RLF  (AUC=0.810),  RP  (AUC=0.844)  and  XGBOOST 
(AUC=0.863). Contrary to them, DT (AUC=0.5), SVM (AUC=0.612) and KNN (AUC=0.723) 
achieved worse results and were disregarded. Then, two samples that RF predicted as class 
0 or 1 with the highest probability (1.00) were analysed to identify the most critical features. 
RF was chosen as the reference model because it returned the highest AUC, and LIME was 
used due to its explanatory ability. 

 
 
 
 
 
Figure 10. Features used by LIME to predict the probabilities of a heart attack. A) Sample classified as class 1; 
B) Sample classified as class 0. Red arrows point to the relevant features identified from the explanations. 

LIME shows the actual values of each sample on the right. In the orange background are the 
features that lead to classifying the sample as class 1 (high probability of suffering an attack) 
and in the blue background are the ones classifying the sample as class 0 (low probability of 
suffering an attack). The left side shows the probability with which the model predicted that 
sample as class 0 or 1. The middle column depicts the explanation of the sample, including 
the rules and edge values extracted from the model. An orange bar means that, according to 
the  actual  value  of  the feature,  the sample should  be  classified  as class  1,  and a blue  bar 
represents the features that indicate that the sample should belong to class 0. 

Based on this representation, Figure 10 shows two samples clearly classified as class 1 and 
0, respectively. According to the actual values of Figure 10a, most of the features indicate that 
the  sample  represents  a  patient  with  a  high  probability  of  a  heart  attack  (class  1),  and  as 
expected, the model classified the patient in that class. Next,  looking at the most attributed 
features, it can be concluded that when ST_Slope is around 0 (flat), ChestPainType is close 
to 4 (asymptomatic), ExerciseAngina is close to 1 (yes) and Oldpeak ranges between 1.65 
and 2.35, the chances of suffering a heart attack are higher.  

Figure 10b analyses the prediction of a patient with a low probability of suffering a heart attack. 
It is worth highlighting two findings: 

‚óè  Only Sex, RestingBP and RestingECG indicate that the patient is not prone to suffering 

an attack. 

 
 
 
 
‚óè  Although the features identified in Figure 10a remain in orange, they range differently. 
If ST_Slope is close to 1 (upsloping), ExerciseAngine is far from 1 (no), ChestPainType 
ranges between 1.50 and 2.50 (atypical angina) and Oldpeak ranges between -0.65 
and 0.45, the patient has few chances of suffering an attack. 

Despite the  overlapping in  the features  involved,  it  can  be  seen that  both explanations are 
consistent  and  mutually  exclusive.  Therefore,  we  could  conclude 
that  ST_Slope, 
ExerciseAngina, ChestPainType and Oldpeak are good markers to predict whether a patient 
will be at risk. Figure 11 summarises the average attributions given by LIME. 

Figure 11. Top 10 features attributed by LIME. The X-axis shows the averaged attribution of each feature, and the 
Y-axis represents the top 10 most important features. Black horizontal lines depict the standard deviation of the 
attribution values given to the features. 

In  terms  of  performance,  amongst  the  most  accurate  models,  the  most  computationally 
expensive was ANN, which only took nearly 1 minute to train the model. Additionally, SIBILA 
took 39 extra minutes to compute interpretability with the slowest model (RP). Although SIBILA 
calculates  interpretability  for  more  samples  in  this  dataset  (1472  explanations)  than  in  the 
previous one (400 explanations), it was three times faster. The reason could be that time spent 
on  explaining  the  results  is  mainly  linked  to  the  number  of  input  features  rather  than  the 
number  of  samples  because  the  algorithm  must  assess  the  importance  of  every  individual 
feature. Based on this idea, the heart attack dataset, which only contains 11 features, should 
be much faster than the synthetic one, which stored 100 variables. 

 
 
 
4. Discussion 

The bike rental prediction example demonstrated that SIBILA can predict continuous outputs 
in regression problems. The results indicate that the total rentals depend on the number of 
reservations and the date. Since the dataset has not been curated, there is a high correlation 
between the date and other input features such as month, year, and season. In this example, 
the date seems to be the preferred feature to estimate the number of rentals. A cleaning stage 
could be performed on the dataset, and the results would be expected to remain similar. 

To  test  the  impact  of  noise  in  the  predictions,  a  synthetic  dataset  was  created  for  binary 
classification. The dataset consisted of 6 input features that determined the output class and 
94 additional features to simulate noise in the data. Aiming to keep it as random as possible, 
it was populated with random numbers between 0 and 1 to avoid discrepancies in the range 
of the variables.  

Despite the high number of disturbing features, SIBILA focused on the relevant features to 
identify the inherent rule (Eq. 1). Six models achieved the perfect classification (AUC=1), and 
four highlighted all the expected features within the ten most valued. The rest of highlighted 
variables could be a consequence of the random nature of the dataset. These results reveal 
that SIBILA is very little influenced by noise, which is essential when working with unexplored 
datasets whose internal rules are unknown. 

Finally, a novel dataset with samples of patients who suffered or did not suffer a heart attack 
was used to simulate a real case. Five out of eight models outperformed the others with an 
AUC  higher  than  0.8.  On  the  contrary,  DT  could  only  find  a  random  classifier  (AUC=0.5), 
probably because this model is too simplistic for a complex dataset. Among the most accurate 
models, RF performed the best (AUC=0.895). We therefore used it as a baseline to explore 
the results. 

To prove the consistency of our explanations, LIME was chosen to interpret the results of the 
RF model. The idea behind LIME is to explain the behaviour of a model through the creation 
of  explainable internal  models  [24].  A  significant advantage of  LIME  is  its  ability  to present 
edge values in the form of mathematical rules along with the actual values of each sample, 
which makes it easy to understand by non-experts. To explain the way the RF model worked, 
two samples, which were undoubtedly classified in both classes, have been selected. 

Table 4. Rules found by LIME to predict the output class. 

Sample #538 (Class 1) 

#Sample 107 (Class 0) 

-0.50 < ST_Slope <= 0.50 

ST_Slope > 0.50 

ChestPainType > 3.50 

1.50 < ChestPainType <= 2.50 

ExerciseAngina > 0.50 

ExerciseAngina <= 0.50 

Sex <= 1.50 

Sex <= 1.50 

1.65 < Oldpeak <= 2.35 

-0.65 < Oldpeak <= 0.45 

201.50 < Cholesterol <= 278.50 

201.50 < Cholesterol <= 278.50 

 
 
 
 
 
109.50 < MaxHR <= 129.50 

166.50 < MaxHR <= 183.00 

FastingBS > 0.50 

FastingBS <= 0.50 

50.50 < Age <= 54.50 

1.50 < RestingECG <= 2.50 

129.00 < RestingBP <= 133.50 

140.50 < RestingBP <= 182.50 

LIME  uses  different  rules  to  classify  samples.  However,  most  of  them  rely  on  the  same 
variables (Table 4). As stated in Table 4, Sex and Cholesterol follow the same rule, so they 
are not good candidates to discriminate the class. In addition, Age and RestingECG are only 
applicable  to  samples  of  a  given  class.  Thus,  they  may  not  be  discriminatory  enough. 
Consequently, there are only seven features which we should look at to make predictions like 
the  model  would  do.  Looking  at  the  attribution  given  by  LIME  to  these  features  (Fig.  10), 
ST_Slope,  ChestPainType,  ExerciseAngina,  and  Oldpeak  are  the  ones  with  the  highest 
attribution.  Therefore,  interpretability  suggests  trusting  them.  Although  they  worked  on 
different datasets, other manuscripts support these findings [35, 36]. 

5. Conclusions 

ML and DL are  powerful  tools for  decision-making  systems,  but their  lack  of  interpretability 
remains  a  significant  challenge.  Without  interpretability,  physicians,  lawyers,  brokers, 
politicians, etc., will never trust ML/DL predictions, and society will miss the opportunity to take 
advantage of these techniques. Aiming to bring some light on this scenario, SIBILA has been 
developed. SIBILA consists of several ML/DL models and a web server accessible at no cost 
at https://bio-hpc.ucam.edu/sibila/ to facilitate its use by any user. Its source code is available 
on Github (https://github.com/bio-hpc/sibila). In addition, to speed up its calculations, it can be 
run  on  supercomputing  clusters  with  no  extra  configuration  because  all  the  necessary 
dependencies are packaged in a container. 

The results prove that SIBILA performs well on both classification and regression problems. 
Furthermore, the results demonstrate that the interpretability calculation is a computationally 
expensive  task  that  can  take  several  hours,  especially  when  the  dataset  has  many  input 
features. To cope with this inconvenience, that stage is parallelised on different nodes of an 
HPC cluster. 

When suitably trained, SIBILA can be a good choice for doctors choosing the best practice for 
each patient. Its scope of application is not restricted, and it could be helpful in the treatment 
of diseases such as cardiovascular problems or cancer, as shown in section 3.3. Even more, 
it  can  be  applied  to  biological  or  pharmaceutical  datasets  to  find  unknown  biomarkers  and 
effective drug combinations. 

Source code 

The source code is available at https://github.com/bio-hpc/sibila.git. 

 
 
 
Funding 

This work has been funded by grants from the European Project Horizon 2020 SC1-BHC-02-
2019  [REVERT,  ID:848098];  Fundaci√≥n  S√©neca  del  Centro  de  Coordinaci√≥n  de  la 
Investigaci√≥n de la Regi√≥n de Murcia [Project 20988/PI/18]; and Spanish Ministry of Economy 
and Competitiveness [CTQ2017-87974-R]. 

Declaration of competing interest 

The authors declare no competing interest. 

Acknowledgements 

[CTQ2017-87974-R].  Supercomputing  resources 

This work has been funded by grants from the European Project Horizon 2020 SC1-BHC-02-
2019  [REVERT,  ID:848098];  Fundaci√≥n  S√©neca  del  Centro  de  Coordinaci√≥n  de  la  Inves-
tigaci√≥n de la Regi√≥n de Murcia [Project 20988/PI/18]]; and Spanish Ministry of Economy and 
Competitiveness 
this  work  were 
supported  by  the  Poznan  Supercomputing  Center‚Äôs  infrastructures,  the  e-infrastructure 
program of the Research Council of Norway, and the supercomputing centre of UiT‚Äîthe Arctic 
University  of  Norway,  by  the  Plataforma  Andaluza  de  Bioinform√°tica  of  the  University  of 
M√°laga, the supercomputing infrastructure of the NLHPC (ECM-02, Powered@NLHPC), and 
the Extremadura Research Centre for Advanced Technologies (CETA‚àíCIEMAT), funded by 
the European Regional Development Fund (ERDF). CETA‚àíCIEMAT is part of CIEMAT and 
the Government of Spain.  

in 

References 

[1] Y. Xin, L. Kong, Z. Liu, Y. Chen, Y. Li, H. Zhu, M. Gao, H. Hou, C. Wang. Machine 
Learning and Deep Learning. IEEE Access, 6 (2018), pp. 35365-35381, 
109/ACCESS.2018.2836950 
[2] T. Ching, D. S. Himmelstein, B. K. Beaulieu-Jones, A. A. Kalinin, B. T. Do, G. P. Way, E. 
Ferrero, P.-M. Agapow, M. Zietz et al. Opportunities and obstacles for deep learning in 
biology and medicine. J. R. Soc. Interface, 15(141) (2018), pp. 20170387, 
10.1098/rsif.2017.0387 
[3] Q. Bai, J. Ma, S. Liu, T. Xu, A.J. Banegas-Luna, H. P√©rez-S√°nchez, Y. Tian, J. Huang, H. 
Liu, X. Yao. WADDAICA: A webserver for aiding protein drug design by artificial intelligence 
and classical algorithm. Comput. Struct. Biotechnol. J., 19 (2021), pp. 
10.1016/j.csbj.2021.06.017 
[4] A.C. Mater, M.L. Coote. Deep Learning in Chemistry. J. Chem. Inf. Model., 59(6) (2019), 
pp. 2545-2559, 10.1021/acs.jcim.9b00266 
[5] G.B. Goh, N.O. Hodas, A. Vishu. Deep learning for computational chemistry. J. Comput. 
Chem., 38(16) (2017), pp. 1291-1307, 10.1002/jcc.24764 
[6] R. Miotto, F. Wang, S. Wang, X. Jiang, J.T. Dudley. Deep learning for healthcare: review, 
opportunities and challenges. Brief. Bioinform., 19(6) (2018), pp. 1236-1246, 
10.1093/bib/bbx044 
[7] J. Zou, M. Huss, A. Abid, P. Mohammadi, A. Torkamani, A. Telenti. A primer on deep 
learning in genomics. Nat. Genet., 51(1) (2019), pp. 12-18, 10.1038/s41588-018-0295-5 

[8] G. Eraslan, Z. Avsec, J. Gagneur, F.J. Theis. Deep learning: new computational 
modelling techniques for genomics. Nat. Rev. Genet., 20(7) (2019), pp. 389-403, 
10.1038/s41576-019-0122-6 
[9] S. Min, B. Lee, S. Yoon. Deep learning in bioinformatics. Brief. Bioinform., 18(5) (2017), 
pp. 851-869, 10.1093/bib/bbw068 
[10] E. Gawehn, J.A. Hiss, G. Schneider. Deep Learning in Drug Discovery. Mol. Inform., 
35(1) (2016), pp. 3-14, 10.1002/minf.201501008 
[11] E.H.B. Maia, L.C. Assis, T.A. de Oliveira, A.M. da Silva, A.G. Taranto. Structure-Based 
Virtual Screening: From Classical to Artificial Intelligence. Front. Chem., 8 (2020), pp. 343, 
10.3389/fchem.2020.00343 
[12] L. Patel, T. Shukla, X. Huang, D.W. Ussery, S. Wang. Machine Learning Methods in 
Drug Discovery. Molecules, 25(22) (2020), pp. 5277, 10.3390/molecules25225277 
[13] C. P√©rez-Gand√≠a, G. Garc√≠a-S√°ez, D. Sub√≠as, A. Rodr√≠guez-Herrero, E.J. G√≥mez, M. 
Rigla, M.E. Hernando. Decision Support in Diabetes Care: The Challenge of Supporting 
Patients in Their Daily Living Using a Mobile Glucose Predictor. J. Diabetes Sci. Technol., 
12(2) (2018), pp. 243-250, 10.1177/1932296818761457 
[14] Y.Lee, R.M. Raggett, R.B. Mansur, J.J. Boutilier, J.D. Rosenblat, A. Trevizol, E. 
Brietzke, K. Lin, Z. Pan, M. Subramaniapillai, T.C.Y. Chan, D. Fus, C. Park, N. Musial, H. 
Zuckerman, V.C.H. Chen, R. Ho, C. Rong, R.S. McIntyre. Applications of machine learning 
algorithms to predict therapeutic outcomes in depression: A meta-analysis and systematic 
review. J. Affect. Disord., 241 (2018), pp. 519-532, 10.1016/j.jad.2018.08.073 
[15] M. Misawa, S.E. Kudo, Y. Mori, T. Cho, S. Kataoka, A. Yamauchi, Y. Ogawa, Y. Maeda, 
K. Takeda, K. Ichimasa, H. Nakamura, Y. Yagawa, et al. Artificial Intelligence-Assisted Polyp 
Detection for Colonoscopy: Initial Experience. Gastroenterology, 154(8) (2018), pp. 2027-
2029, 10.1053/j.gastro.2018.04.003 
[16] K. Ichimasa, S.E. Kudo, Y. Mori, M. Misawa, S. Matsudaira, Y. Kouyama, T. Baba, E. 
Hidaka, K. Nakamura, T. Hayashi, T. Kudo, T. Ishigaki, Y. Yagawa, et al. Artificial 
intelligence may help in predicting the need for additional surgery after endoscopic resection 
of T1 colorectal cancer. Endoscopy, 50(3) (2018), pp. 230-240, 10.1055/s-0043-122385 
[17] P. Hamet, J. Tremblay. Artificial intelligence in medicine. Metabolism, 69S (2017), pp. 
S36-S40, 10.1016/j.metabol.2017.01.011 
[18] N.J. Schork. Artificial Intelligence and Personalized Medicine. Cancer Treat. Res., 178 
(2019), 265-283, 10.1007/978-3-030-16391-4_11 
[19] O. Khan, J.H. Badhiwala, G. Grasso, M.G. Fehlings. Use of Machine Learning and 
Artificial Intelligence to Drive Personalized Medicine Approaches for Spine Care. World 
Neurosurg., 140 (2020), pp. 512-518, 10.1016/j.wneu.2020.04.022 
[20] G.S. Handelman, H.K. Kok, R.V. Chandra, A.H. Razavi, M.J. Lee, H. Asadi. eDoctor: 
machine learning and the future of medicine. J. Intern. Med., 284(6) (2018), pp. 603-619, 
10.1111/joim.12822 
[21] C. Zippel, S. Bohnet-Joschko. Rise of Clinical Studies in the field of Machine Learning: 
A Review of Data Registered in ClinicalTrials.gov. Int. J. Environ. Res. Public Health, 18 
(2021), pp. 5072, 10.3390/ijerph18105072 
[22] R. Miotto, F. Wang, S. Wang, X. Jiang, J.T. Dudley. Deep learning for healthcare: 
review, opportunities and challenges. Brief. Bioinform., 19(6) (2018), pp. 1236‚Äì1246, 
10.1093/bib/bbx044 
[23] Permutation_importance. https://scikit-
learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html?highlig

ht=permutation_importance#sklearn.inspection.permutation_importance. Accessed on 25th 
February 2022. 
[24] C. Molnar. Interpretable Machine Learning. A Guide for Making Black Box Models 
Explainable. 2nd Edition. 
[25]  Lime. https://github.com/marcotcr/lime. Accessed on 25th February 2022. 
[26] SHAP. https://shap.readthedocs.io/en/latest/index.html. Accessed on 25th February 
2022. 
[27] Alibi - Integrated Gradients. 
https://docs.seldon.io/projects/alibi/en/latest/methods/IntegratedGradients.html. Accessed on 
10th February 2022. 
[28] Diverse Counterfactual Explanations (DiCE) for ML. http://interpret.ml/DiCE/. Accessed 
on 25th February 2022. 
[29] Plot_partial_dependence. https://scikit-
learn.org/stable/modules/generated/sklearn.inspection.plot_partial_dependence.html?highlig
ht=partial%20dependence%20plot#sklearn.inspection.plot_partial_dependence. Accessed 
on 25th February 2022. 
[30] Accumulated Local Effects. 
https://docs.seldon.io/projects/alibi/en/stable/methods/ALE.html. Accessed on 25th February 
2022. 
[31] Singularity container. https://sylabs.io/guides/3.5/user-guide/index.html. Accessed on 
25th February 2022. 
[32] G. Hu, Y. Zhang, W. Chen. Exploring the Performance of Singularity for High-
Performance Computing Scenarios. 2019 IEEE 21st International Conference on High-
Performance Computing and Communications; IEEE 17th International Conference on 
Smart City; IEEE 5th International Conference on Data Science and Systems 
(HPCC/SmartCity/DSS), (2019), pp. 2587-2593, 10.1109/HPCC/SmartCity/DSS.2019.00362 
[33] Y. Liu, S. Khandagale, C. White, W. Neiswanger. Synthetic Benchmarks for Scientific 
Research in Explainable Machine Learning. arXiv:2106.12543v4, 
doi.org/10.48550/arXiv.2106.12543 
[34] fedesoriano. (September 2021). Heart Failure Prediction Dataset. Retrieved 10th 
February 2022 from https://www.kaggle.com/fedesoriano/heart-failure-prediction. 
[35] S.B. Patil, Y.S. Kumaraswamy. Extraction of Significant Patterns from Heart Disease 
Warehouses for Heart Attack Prediction. International Journal of Computer Science and 
Network Security, 9(2) (2009), pp. 228-235. 
[36] H.D. Masethe, M.A. Masethe. Prediction of Heart Disease using Classification 
Algorithms. Lect. Notes Eng. Comp., 2, 2014, pp.809-812. 

