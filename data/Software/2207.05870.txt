2
2
0
2

l
u
J

2
1

]

G
L
.
s
c
[

1
v
0
7
8
5
0
.
7
0
2
2
:
v
i
X
r
a

RCTORCH
A PYTORCH RESERVOIR COMPUTING PACKAGE WITH AUTOMATED
HYPER-PARAMETER OPTIMIZATION

Hayden Joy, Marios Mattheakis, Pavlos Protopapas
John A. Paulson School of Engineering and Applied Sciences
Harvard University
Cambridge, Massachusetts 02138, United States
hnjoy@mac.com, mariosmat@seas.harvard.edu, pavlos@seas.harvard.edu

ABSTRACT

Reservoir computers (RCs) are among the fastest to train of all neural networks, especially when
they are compared to other recurrent neural networks. RC has this advantage while still handling
sequential data exceptionally well. However, RC adoption has lagged other neural network models
because of the model’s sensitivity to its hyper-parameters (HPs). A modern uniﬁed software package
that automatically tunes these parameters is missing from the literature. Manually tuning these
numbers is very difﬁcult, and the cost of traditional grid search methods grows exponentially with
the number of HPs considered, discouraging the use of the RC and limiting the complexity of the
RC models which can be devised. We address these problems by introducing RcTorch, a PyTorch
based RC neural network package with automated HP tuning. Herein, we demonstrate the utility
of RcTorchby using it to predict the complex dynamics of a driven pendulum being acted upon by
varying forces. This work includes coding examples. Example Python Jupyter notebooks can be
found on our GitHub repository https://github.com/blindedjoy/RcTorch and documentation
can be found at https://rctorch.readthedocs.io/.

Keywords Reservoir Computing
Control Dynamical Systems

Neural Networks

·
Machine Learning

Echo State Networks
AI

Data Driven

·

Bayesian Optimization

PyTorch

·

·

·

·

·

·

1

Introduction

Reservoir computers (RCs), also known as echo state networks, are specialized, artiﬁcial neural networks. They are
powerful and train very fast. However, today RC is not as commonly employed by the machine learning community
at large as other classes of neural network models. Unlike most neural networks, the majority of RC weights are not
optimized via the backpropagation algorithm. Instead, the weights are generated via a stochastic process that is very
sensitive to a few numbers, typically less than 10, called hyper-parameters (HPs). In a simple feed forward neural
network, rather than being optimized during training, HPs govern the learning process. The optimization of HPs is
a signiﬁcant challenge to the widespread adoption of the RC. Other classes of neural networks, which are extremely
popular today, have faced similar signiﬁcant challenges in the past. At times, pessimism about neural networks and,
thus, AI more broadly, has led to aversion to these models by the scientiﬁc community at large, resulting in an AI
winter: a “period following a massive wave of hype for AI characterized by a disillusionment that causes a freeze in
funding and publications"1.

———————————–
Preprint. Under Review

 
 
 
 
 
 
PRIME AI paper

AI winters (both generally and for speciﬁc models) follow a general historical pattern. First, a new model is introduced
that creates great excitement. Next, a technical barrier is introduced that causes the network to fall out of favor and
stagnate. Finally, a solution is introduced, which removes the barrier. This leads to technical breakthroughs and,
subsequently, to a ﬂood of new papers, attention, and funding2.

In this study, we attempt to remove barriers to use for RC by introducing RcTorch: a library for RC that makes reservoir
computing easy and accessible. To the best of our knowledge, such a uniﬁed and maintained RC library with automated
HP tuning does not exist. Our package is ﬂexible and modern - it is written in the popular machine learning framework
PyTorch.

This manuscript has many sections which may be of varying interest to the reader. Section 1 gives an overview of the
RC. Section 2 puts the RC in the context of the history of other neural networks, which is crucial to understanding their
importance in modern machine learning, but a reader who is more focused on the speciﬁc technical details of the RC
may skip this part and start reading from Section 3. The remainder of this work demonstrates how to use RcTorch, as
well as its powerful predictive ability, on a forced pendulum example.

1.1

Introduction to the RC

Reservoir computers are a specialized subset of recurrent neural networks (RNNs), so it is important to understand
RNNs and their shortcomings. RNNs are a class of artiﬁcial neural networks where the hidden states at time-step t
depend on the previous hidden states. This establishes temporal dynamic behavior that yields a computation platform
with an internal memory. The ability of RNNs to make predictions based on past events makes them powerful tools for
handling temporal and sequential data. However, training an RNN is difﬁcult and time-consuming due to its recurrent
connections. Also, the problems of exploding and vanishing gradients are often observed.3 RC was ﬁrst introduced4 as
a subset of RNN architectures that are considerably less computationally expensive to train. The RC consists of three
layers: input, reservoir (hidden), and output (readout). Training the RC is efﬁcient because only the weights connecting
the reservoir to the output layer are updated during the network training (or ﬁtting) phase. In the RC architecture, the
hidden layer has randomly and sparsely connected neurons. These are collectively known as a ‘reservoir’ of neurons.4
As opposed to the typical RNN, the connections of the neurons in the input layer and the recurrent hidden nodes in
the reservoir layer of an RC are ﬁxed. Because of these frozen weights, the RC can utilize a large number of hidden
neurons. This in turn allows for sufﬁcient complexity to develop an intelligent device.

The simplicity of the RC architecture, and its substantially reduced learning cost compared to iterative learning
algorithms, has attracted a large amount of attention in the machine learning and artiﬁcial intelligence (AI) communities.
Even as early as 2012, RC had been employed in applications as diverse as robotic control, ﬁnancial forecasting, and
the detection of epileptic seizures5. More recently, it has been shown that unsupervised reservoir computers can solve
ordinary differential equations6 and that the use of “observer" time-series can assist in the analysis of chaotic data7,8,9
and to model turbulent ﬂow.10
One of the most interesting aspects of RC is that it can form physical hardware neuromorphic reservoir computers11.
This can lead to networks that are orders of magnitude faster than software-based computational methods. In recent
years, several neuromorphic RC architectures have also been implemented in physical reservoirs on dedicated hardware,
such as photonic integrated circuits12, photonic cavities13, optoelectronic technology14, and nonlinear wave dynamics.15
These architectures can potentially be deployed for real-time machine learning predictions. However, even in hardware
RC the discovery of high quality HPs remains a signiﬁcant challenge.

1.1.1 The crux of RC: Optimizing the hyper-parameters

While RC networks train extremely quickly, there is no free lunch in optimization problems. That is, “there is no
optimization algorithm that can outperform all optimizers when solving all problems”.16,17,18 The architecture of the RC
is mostly determined by HPs that are not learned during the training process. The RC is extremely sensitive to its HPs.
The difﬁcult task of ﬁne-tuning the optimal HPs, which often varies for different problems, has kept the RC a niche
model mostly used by experts. Conventionally, the HPs of RC were tuned by using a simple grid search. However,
the computational cost of this method scales exponentially as the number of HPs increases. Given n HPs, the space
searched for the real-valued HPs is n-dimensional. Therefore, adding an HP involves adding a dimension to the search
space. This is a signiﬁcant challenge for a simple grid search, as the search time explodes exponentially as more and
more HPs are added. In practice, grid search and manual tuning quickly becomes infeasible when n > 3, forcing the
user to design relatively simple models. One solution to this problem is Bayesian optimization (BO).19 BO is a powerful
method for optimizing the HPs of computationally expensive tasks such as neural network optimization. As Geoffrey
Hinton suggested in a NeurIPS workshop 2016: “[BO] replaces the graduate student who ﬁddles around with all these
different settings for the hyper-parameters”.20

2

PRIME AI paper

1.1.2 Bayesian Optimization and RcTorch

In this study, we present a new RC library called RcTorchwhich creates RC networks and also has a powerful BO
class capable of optimizing the RC HPs. RcTorch is capable of training many networks in parallel and then evaluating
their performance, that is, generating a score for each model. These scores are then reported to the RcBayes class
which performs BO. Thus, RcTorch generates many RC architectures and then selects the best one based on a robust
and efﬁcient process which can converge in as few as a hundred iterations. BO is an active ﬁeld of research and is
well documented in the literature.21,22,23 In particular RcTorch utilizes a PyTorch library called BoTorch which is
concerned with BO techniques and was released by the Facebook AI Lab.24
RcTorch employs the TuRBO algorithm, which is a local BO method.25,24 While global BO methods do not subset the
HP search space, TuRBO effectively divides different parts of the HP search space. Global methods tend to over-explore
the search space, optimizing poorly in local regions. Moreover, TuRBO can be parallelized and thus, it is faster and
returns higher quality HPs than global BO methods. By employing TuRBO BO, RcTorch is able to optimize many HPs
efﬁciently and can ﬁnd better HPs than standard BO methods. More technical details about BO and TuRBO in RcTorch
can be found in section 5.7.

Automated BO has the potential to make the RC a popular model by eliminating the tedious task of searching for
optimal HPs. In the next section, to emphasize the signiﬁcance of enabling widespread adoption of effective models,
we give historical examples of the challenges of other neural networks. We also examine the outcomes of overcoming
those challenges.

2 A brief history: Cycles of AI winters

2.1 The ﬁrst AI winter: Feed Forward Neural Networks (FFNNs) and their initial challenges (1958 - 1986)

The earliest neural network, the single-layer perceptron, was introduced by Frank Rosenblatt in 1958 and was greeted
with hyperbolic fanfare.a,1 The New Yorker reported that “[Rosenblatt’s perceptron] is the ﬁrst serious rival to a
human brain ever devised”. The New York Times claimed, in turn, that “The navy revealed the embryo of an electronic
computer today that it expects will be able to walk, talk, see, write, reproduce itself, and be conscious of its own
existence". The paper then reported that “[Rosenblatt] said Perceptrons might be ﬁred to the planets as mechanical
space explorers".1 However, this overzealous excitement did not last.

While at ﬁrst it appeared that Rosenblatt had created the ﬁrst universal learning machine, by 1969 Marvin Minsky of
MIT famously proved that Rosenblatt’s perceptron failed to approximate the simple logical function “exclusive or"
(XOR). The perceptron more generally failed to solve functions that were not linearly separable. This was particularly
devastating to the popular perception of AI because in the late 1950s and early 1960s, it was thought that solving AI
essentially boils down to solving the rules of logic. Minsky speciﬁcally proved that a multi-layer model would be
needed to solve this fundamental problem, but an algorithm capable of training such a network was not then known.
The gap between dramatic proclamations of the promise of artiﬁcial intelligence and the limitations of the single-layer
perceptron led to pessimism and aversion by the scientiﬁc community at large. Thus began the ﬁrst AI winter.

2.2 The spring of FFNNs and the rise of Recurrent Neural Networks (RNNs)

In 1986 Rumelhart et al.2 popularized backpropagation (backprop) - the algorithm that solved the training of a multi-
layer neural network. Backprop ended the ﬁrst AI winter and brought attention back to neural networks. In that same
article, the authors introduced the ﬁrst RNN.b RNNs have an additional set of neurons, known as the hidden states, that
pass information (a context vector) from one time-step to the next. This context vector can be viewed as the recurrent
memory of the network. An RNN may also be seen as a Euler approximation of a time dependent ordinary differential
equation (ODE)6, which gives a strong theoretical justiﬁcation for their use in time dependent problems. However,
RNNs can also be unwrapped and viewed as a very deep feed forward neural network, with as many layers as the time
steps of the input data. More than being just an interesting technical perspective, this fact brings a host of challenges
which were nearly debilitating during the RNN’s inception in the 1980’s and 1990’s.

aThe so-called perceptron, consisted of a single layer of simulated neurons.
bIn his seminal 1975 thesis, Werbos ﬁrst described the process of training neural networks through the backpropagation of errors.2

3

PRIME AI paper

2.2.1 The Vanishing Gradient Problem: The crux of RNNs

Very deep networks are notoriously difﬁcult to train due to the vanishing gradient problemc, which is the tendency of
gradients to explode or shrink in deep neural networks. To perform gradient descent with backprop to ﬁnd the optimal
set of weights, we have to take derivatives. Backprop works by using the chain rule to calculate the gradient of the loss
function with respect to the weights of the network. This is done from the ﬁnal layer of the network back toward the
input layer. For an RNN this means that the gradients must be calculated at every time step. Such a large application of
the chain rule through a lot of layers amounts to a massive product - numbers slightly larger than one or less than one
will tend to explode towards inﬁnity or vanish towards zero, respectively.d When a number is too large or too small,
the computer cannot represent it with sufﬁcient precision, and information is lost. If we had inﬁnite precision in our
instruments, this would not occur, but alas. Thus, simple (or vanilla) RNNs struggle to train sequential data longer than
20 to 50 discrete time-steps.26

2.2.2 Three key properties of an effective time dependent model

In the same 1994 paper, where Bengio et al.26 performed one of the ﬁrst rigorous analyses of the vanishing gradient
problem in RNNs, they also laid out three necessary qualities of a good time-dependent model. In this study we judge
our AI software by these criteria. The model should: (1) be able to work over an arbitrary time duration, (2) be robust
to noise, and (3) be capable of solving problems in reasonable amounts of time. Bengio et al. showed empirically that
vanilla RNNs failed all of these criteria even for simple problems. The RNNs were not “efﬁciently trainable" with
gradient descent, were not robust to noise, and could not solve problems for longer than 50 time steps.26 RNNs were
initially thrown out in the cold due to these difﬁcult challenges. Like the feed forward networks before them, RNNs
were waiting for their day in the sun.

2.2.3 Long Short Term Memory models and the Golden Age of RNNs (1997-2019)

In 1997 the Long Short Term Memory (LSTM) (a class of RNN) was proposed to address the vanishing gradient
problem.27 The authors proved that by allowing the gradients to ﬂow directly (via a linear activation and so-called
“memory gates”) RNNs could make longer predictions. While these models empowered RNNs to make longer
predictions, the computationally expensive nature of their training (and the insufﬁcient processing power of computers
in the late 1990’s and 2000’s) caused them to fade. This represented the onset of the second AI winter, a period
during the early 2000’s when neural networks fell out of favor with the rise of decision tree models and support vector
machines.

By the late 2000s, the second winter would begin to thaw and between 2010 and 2015 relentless interest and funding
ﬂooded back to neural networks. Hinton et al. employed GPU acceleration to empower deep neural networks (deep
learning) and progressively beat records in computer vision and speech recognition. Soon his students were being hired
at top tech companies.e For example, in 2011 one of Hinton’s pupils, Navdeep Jaitly, went to Google where he interned
with the speech recognition team. Shortly thereafter Google’s previous solution to speech recognition was thrown out in
favor of a new neural network approach.1 In 2015, Google used LSTMs to reduce speech transcription errors by 50%.
By 2016, they cut translation errors by 60%.28 Adoption of RNNs for natural language processing by other large tech
companies soon followed. In 2017, Apple and Amazon announced separately that they had introduced LSTMs into Siri
and Alexa, respectively,29,30,31; Facebook and Microsoft soon followed suite32,33. However, despite a meteoric rise in
the language model space, these models still suffered from the gradient vanishing problem to a degree and slow training
and since 2019 their use has declined, the natural language processing was dethroned by attention based models such as
transformers.34 While the RC does not suffer from the weaknesses of LSTMs, it has its own barriers to use.

2.3 The current winter of the RC

For RC, the problem of the HPs has been a barrier similar to the barrier of training a multi-layer perceptron in the
1960s and 1970s or RNNs in the early 1990s. While there are many useful RC software packages, such as pyESN and

calso known as the gradient vanishing/exploding problem
dGradients vanish and explode when training RNNs because we must backprop back in time through their hidden states. This
amounts to a very large application of the chain rule. Given an error function E, a prediction vector ˆy = (y1, ..., yn) an output
network weight U , and hidden states h1, h2, hk, ...hn the derivative of the loss function with respect to the output weight is as
follows: dLt

∂hj
∂hj−1
eBy 2010 two of his students were hired at Microsoft and jump started their artiﬁcial intelligence research division. This

∂hk
∂U where ∂ht
∂hk

dU = (cid:80)t

= (cid:81)t

∂ht
∂hk

∂Lt
∂ ˆyt

ˆyt
∂ht

j=k+1

k=1

.

represented big tech’s ﬁrst serious attempt to integrate neural networks in its products.

4

others35,36,37,38, these packages lack automated hyper-parameter tuning capabilities.f This makes using the RC feel
more like guess-and-check work rather than machine learning. Typically, the researcher must use another software
package or utilize an independent approach for the discovery of the optimal HPs. RcTorch seeks to remove the barrier
of the difﬁcult task of hyper-parameter optimization with automated HPs tuning via BO. Due to the crucial role the HPs
play in determining the architecture of the RC network, it is appropriate to introduce them in that context.

PRIME AI paper

3 The RC Architecture

3.1 The general architecture of the RC

The critical HPs of the RC are related to its architecture. We adopt a similar notation as that used in by Ott. et al.9
The RC is made up of three sets of weights: input weights Win with M input nodes, reservoir weights Wres with
N hidden (reservoir) nodes, and output weights Wout with P output nodes. In particular, the total set of weights
P . While the application in this
W =
study is time dependent, the input and output to the RC can more generally be any sequential data.

Win, Wres, Wout
{

N , and Wout

where Win

M , Wres

RN

RN

RN

∈

∈

∈

}

×

×

×

RC is a subset of RNNs; thus, the following formulation describes any RNN of this form. We consider sequential data
IRM where k
that comprise M different sequences with K sequential data-points, hence we read an input vector uk
∈
IRN that form a
is the sequential index. The input vector feeds an RNN that consists of N hidden recurrent states hk
reservoir of hidden neurons. The evolution of the hidden states in this study is given by:

∈

hk = (1

α) hk

−

1 + αf (Wres

hk

−

1 + Win

·

·

−

uk + b) ,

(1)

where the dot indicates the inner product operator, α is a leaking rate that controls the evolution of the hidden states
N is
(smaller the α slower the evolution), f (
∈
M ,
an adjacency matrix that contains the weights of the connections between the hidden neurons, and Win
×
b

) is an arbitrary nonlinear activation function, the matrix Wres
·

1 denote, respectively, the weights and biases of the input layer. g

×
IRN

IRN

∈

IRN

×

The network is performing a regression task and predicts a vector of P sequences ˆsk
recurrent states through the relationship described by Eq. (3) where c denotes a constant bias vector.h

∈

IRP that depends linearly on the

∈

ˆsk = Wout

hk + c.

·

(3)

Equations (1), (3) deﬁne forward propagation through an RNN where, in principle, all the weights and biases are
trainable parameters.

The transition from a standard RNN to an RC occurs when we ﬁx the parameters of the input and hidden layers while
we train only the weights and biases of the output layer. The loss function that needs to be minimized in the training
phase is given by:

L =

K
(cid:88)

k=1

(ˆsk

−

sk)2 + βTr (cid:2)WoutWT

out

(cid:3) ,

(4)

where sk
the ridge regularization penalty9 used to avoid overﬁtting, and β

∈

IRP is a vector that contains the ground truth data used to train the network. The second term in Eq. (4) is

0 is the ridge regularization coefﬁcient.i

≥

f An exception is the excellent library written by Reinier Maat, which was the ﬁrst library to demonstrate that the HPs of the RC
could be efﬁciently tuned with BO. However, the packages upon which that library was built — gpyopt — is no longer maintained.
RcTorchis written in PyTorch, considered by many to be the best AI language for researchers and is constantly maintained.39

gThis is but one implementation of an RNN. Hidden states could more generally be represented by hk = φ (Wres, hk−1, uk)
where the function φ represents a more general function of hidden states and inputs. RC or RNN formulations can be more complex
than the simple Gated Recurrent Network like formulation of the RC imposed herein.

hMore generally given an invertible output activation function fout the output layer can be expressed by Eq. (2). Wout ∈ IRN ×P

and c ∈ IR1×P denote, respectively, the weights and biases of the output readout layer of the network.

f −1
out (ˆsk) = Wout · hk + c,

(2)

iThe regularization parameter can also be solved for via cross validation during training. This capability is under development

for RcTorch.

5

PRIME AI paper

Figure 1: The standard RC architecture. The input uk is projected to a high dimensional vector space via Win described
by the hidden vector hk (not shown) that evolves in time tk.

Having to optimize only the output linear layer, the network optimization simpliﬁes to a ridge regularized linear
regression problem. Considering that this problem has a closed form solution4,9,40, RC networks can be trained
extremely quickly, making RC a very efﬁcient RNN.

Let the input and output at time-step k be uk and sk. Fitting an RcTorchmodel consists of two steps: 1) constructing
the hidden states and 2) training the output weights. Like a support vector machine, the RC uses its input weights
to make a high dimensional projection of the input vector. The hidden state vectors h1, h2, ..., hk can be considered
as a non-linear and non-orthogonal set of basis functions which the RC linearly combines to approximate the target
(response) variable. The HPs, with the exception of the ridge regression coefﬁcient, determine the architecture of
the hidden states, which are not learned by the network. During BO, we progressively search for different HP sets
Si
|. Crucially, the weights of the reservoir are randomly chosen from distributions that are determined by some
of the HPs.

IR|

∈

Si

3.2 HP overview

An overview of the main HPs used in this study is given by table (3.2). N represents the total number of nodes in the
reservoir. The spectral radius ρ is the maximum eigenvalue of the adjacency matrix (the adjacency matrix determines
the structure of the reservoir). The hyper-parameter ζ is the connectivity of the adjacency matrix. The bias b0 used in
the calculation of the hidden states and the leakage rate α controls the memory of the network, i.e. how much the hidden
1. The ridge regression coefﬁcient β determines the strength of regularization
state hk depends on the hidden state hk
at inference when solving, in one shot, for Wout.

−

HP Description
N
ρ
ζ
b0
α
β

number of reservoir neurons
spectral radius max eigenvalue of Wres
connectivity of the reservoir (1 - sparsity)
bias used in the calculation of hk
leakage rate
ridge regression coefﬁcient

Search Space
typically 100 to 500
[0,1]
logarithmic
[-1,1]
[0,1]
logarithmic

Although table (3.2) summarizes the HPs used in this study, RcTorch is adaptive framework and more HPs can be
easily hard-coded in RcTorchcode. For example, an RcTorch user might want to add non-linear dense layers on top of
the RC. If the user wants to add multiple non-linear dense layers to the RC then a one-shot solution for the best output
weights is no longer possible and gradient decent must be performed. In this case, the learning rate λ would be an
additional HP that could be optimized with BO.

4 Software application of RcTorch: the forced pendulum

We demonstrate the effectiveness of the proposed RcTorch AI tool through an application; we solve the forced
pendulum problem. An undamped driven pendulum is represented by the system of non-linear ordinary differential

6

PRIME AI paper

equations represented by Eq. (5) and Eq.(6) where x is the position of the mass of the pendulum assumed to be one and
p represents its momentum.

˙x = p

˙p =

−

sin(x) + αf (ω, t)

(5)

(6)

In Eq. (6), f (ω, t) is a real value external driven force function bounded within [-1, 1], where ω and α are, respectively,
the frequency and amplitude of the force. The forced pendulum can display wildly different behavior depending on the
external driven force. Fig. 2 shows trajectory plots (above) and phase space plots (below) for various αf (ω, t). Vertical
pairs of plots correspond to a particular force.

Figure 2: Top row: Example trajectories of the forced pendulum generated with the odeint package which employs
LSODA algorithm from the FORTRAN library odepack.41 Here, the force is deﬁned by α sin(ωx). Plotted in blue and
orange are the position x(t) and the momentum p(t), respectively. Bottom row: The momentum is plotted versus the
position called the phase-space. The middle trajectory is resonant where the motion is not clearly bounded. From left to
right the values of (α, ω) are [(0.3, 0.5), (0.5, 0.85), (0.2, 0.95)]. These plots demonstrate that the forced pendulum can
behave in wildly different ways when only varying the force applied. For all sets the value of the initial conditions are
x0 = 0.5, p0 = 0.5.

For small initial position and velocity, the pendulum is a nonlinear periodic system, but for certain sets of ω and α
the system begins to behave in a more complex way. The upper and lower middle panels of the second of Fig. 1
demonstrate this behavior. Note that all data used in this study were generated using the scipy.integrate.odeint
implementation of the Fortran package written in Python.42

The RC can perform two types of tasks: “pure prediction" and “parameter aware prediction". In the former case, the
model does not have any information about the future dynamics. A standard example is the prediction of a stock price.
This is in contrast to the parameter-aware case where some physical information or future variables of the system can
be inferred. For example, in many robotics applications, the user knows the driven force applied by the robot, which is
a given parameter that helps predict how the system will react to the force.

In our software demonstration, in the case of a driven pendulum, we ﬁrst perform pure prediction with the RC using
RcTorch. Pure prediction is when the RC takes time as input and is trained on the ground truth (x, p). Then, we
improve upon this result with a parameter-aware RC. That is, the driven force is assumed to be a known function.
Next, we show that RcTorch can recover the underlying dynamics of the system even from noisy data. Finally, we
demonstrate a transfer learning application of the RC: After learning one set of HPs optimized for a particular input
force, our system can learn with a high degree of accuracy how the system will respond to other forces.

7

0200400tx,p0200400t0200400t−0.50.00.5xp050x−202xPRIME AI paper

This software application builds up to demonstrating that for non-resonant frequencies, RcTorch can predict the forced
pendulum trajectories for forces outside the training regime. This means that the RC is capable of learning the general
underlying dynamics of physical systems. Thus, the HPs of the RC can be viewed as encoding a rich latent embedding:
a high-dimensional general representation of a system.

Figure 3 shows three cases of a particular trajectory of the forced pendulum: the ground truth relationship, noisy data,
and the RC prediction of a particular trajectory. All three plots are shown in phase space; where the position along
the position (x) plotted against the momentum (p). Figure 3 demonstrates that the RC recovered the dynamics of the
system. However, when the force is different enough from the original force, the model can begin to struggle, and new
HPs should be found. We demonstrate how to ﬁnd new HPs in section 5.7 which shows how to use the RcBayes class
to perform BO. Following the same procedure, a practitioner can recover the underlying dynamics and forecast dynamic
behavior given noisy sequential data.

Figure 3: Left (blue): The ground truth phase space of the forced pendulum. Center (gold, dotted): The phase space of
the data, which was noisy and hard to discern. Right (red, dashed-line): the phase space recovered by the RC trained
only on the noisy data.

5 Software Application Part 1: Forecasting

In this section we demonstrate how we can use RcTorch to solve the forced pendulum. Note that >>> represents a
command being entered by the user.

5.1

RcTorch resources and installation

The RcTorch github repo can be visited at Githubrepo:https://github.com/blindedjoy/RcTorch. In addition
RcTorch has clean and effective documentation that can be accessed at the link at https://rctorch.readthedocs.
io.

RcTorch can be easily installed via pip:

5.2 Pure prediction with RcTorch

>>> p i p i n s t a l l

r c t o r c h

A pure forecasting problem is a task where when making a prediction we do not have any knowledge of concurrent
information (technically no time-series concurrent to the target). An example of pure prediction, as previously mentioned,
is the prediction of a single stock price prediction as concurrent information is in the future and is inaccessible.

5.2.1 Setting up the HPs

To get started with the software we use the following HP set which acts as a recipe for the RC.

8

−1.0−0.50.00.51.0x−0.6−0.4−0.20.00.20.40.6p−1.0−0.50.00.51.0x−1.0−0.50.00.51.0xPRIME AI paper

>>> i m p o r t
>>> h p s = { ‘ c o n n e c t i v i t y ’ : 0 . 4 0 7 1 4 4 9 7 4 6 8 9 6 9 8 3 ,

r c t o r c h

‘ s p e c t r a l _ r a d i u s ’ : 1 . 1 3 2 9 1 0 7 2 8 4 5 4 5 8 9 8 ,
‘ n_nodes ’ : 2 0 2 ,
‘ r e g u l a r i z a t i o n ’ : 1 . 6 8 6 2 0 2 1 4 5 0 9 2 7 9 2 2 ,
‘ l e a k i n g _ r a t e ’ : 0 . 0 0 9 8 0 8 5 2 3 5 8 0 4 3 1 9 3 8 ,
‘ b i a s ’ : 0 . 4 8 5 0 9 5 8 8 8 3 7 6 2 3 5 9 6 }

This HP set was optimized via BO for f = α
search for an optimal HP set.

∗

sin(ωx) with α = 0.5 and ω = 0.2. In section 5.7 we show how to

5.2.2 RcTorch: Declaring an RcNetwork object

Given this HP set we seek to generate a phase plot like Fig. (1). In order to do so we demonstrate how to build, train,
and test an RcTorch RcNetwork class model. Classes in python are declared with function notation, so in order to
build a speciﬁc instance object of the RcNetwork class, we run the following line of code:

>>> my_rc = RcNetwork ( * * hps ,

r a n d o m _ s t a t e = 2 1 0 ,
f e e d b a c k = T r u e )

Upon initialization, the RcNetwork class object builds the reservoir and other necessary matrices. The HPs are passed
as an unzipped dictionary to the RcNetwork class. The argument random_state ensures that the random stochastic
(statistical) processes generating the network architecture are the same from realization to realization. This allows us to
search for stable and optimal architectures. If this was not done, we would generate a different network architecture
every single time we ran the code even when the HPs stayed consistent. The feedback argument is crucial for longer
predictions as it passes the output of the network at time-step t as an input to the network at time t + 1, which allows
the network to make longer and better predictions in general; this is also known as teacher-forcing. Next, we ﬁt our
model on unseen data.

5.2.3 RcTorch: Fitting an RC

When the ﬁt method is called, RcTorch iterates over time while building the hidden states using Eq. (1). Once this is
completed, the network solves for the optimal output weights for the last layer of the network.

>>> my_rc . f i t ( y = t a r g e t _ t r a i n )

In RcTorch y represents the target time-series which the network is supposed to predict and X represents the input
time series. In this case we did not need to enter X because as we are doing a pure prediction task (the default value of
X is N one, meaning that the only input is time).j Next we test our model on unseen data. Here y is described by the
system of equations ˙x = p, ˙ρ =
sin(x) + 0.5 sin(0.2x) with no noise added. This is achieved by concatenating the
two vectors.

−

5.2.4 RcTorch: Testing the model

>>> s c o r e , p r e d i c t i o n = my_rc . t e s t ( y = t a r g e t _ t e s t )

The test method ﬁst runs the predict method and subsequently calculates the mean square error (MSE) of the
prediction versus the ground truth. The user can pass any other custom loss function by modifying the criterion
argument of the test method. k. The test method returns a tuple of the overall loss (the score) and the prediction. Next,
we can run the combined_plot method to see our model predictions.

jTechnically by default if X is not provided to RcTorch, it will default to a vector of ones (X = [1, 1, 1, ...]), though using

discrete time-steps X = [0.1, 0.2, 0.3, ...] is also effective.

kAlthough the test method takes target_test as an argument to score the result, target_test is not passed to the predict

method

9

5.2.5 RcTorch: Plotting RC predictions and residuals

>>> my_rc . c o m b i n e d _ p l o t ( )

PRIME AI paper

Figure 4: The combined_plot method plots both the prediction (above) and the log-residuals (below) versus time. The
dotted blue vertical line separates the training and testing regimes. In yellow and blue on the left hand side of the
prediction plot we see the position and momentum of the forced pendulum training sets and in green and red we see the
RC predictions. The ground truth data for x and p are plotted as dashed black lines.

While Fig. 4 demonstrates that the model did well in capturing the general timing of large wave-like ﬂuctuations,
RcTorch is capable of better performance. This is despite the fact that the result is impressive within the context of the
20%-80% train-test-split and the fact that the data were a very long sequence of 12000 discrete time steps. The RC
works with data over a long duration (many discrete time steps) and trains quickly, which is not true for other RNNs,
which struggle over long sequences and are generally slow. The overall test set MSEl (M SE)
0.141 and the model
took 7.93 seconds not including plotting time. All experiments were run on a MacBook Pro (2019) with a 2.4 GHz
8-Core Intel Core i9 processor and 64 GB 2667 MHz DDR4 of memory. All code was run in Python Jupyter notebooks
without access to GPUs.

≈

Figure 5: Phase space plots; x (position) is plotted against p (momentum). The real data is plotted in the left panel with
a solid blue line. The RcTorch RcNetwork prediction is plotted at right with a dashed red line.

lM SE =

(cid:80)

k (sk−ˆsk)2
(cid:80)
k(sk)2

10

−0.50.00.5x,p0255075100125150175t10−810−3MSE−0.75−0.50−0.250.000.250.500.75x−0.4−0.20.00.20.4p−0.75−0.50−0.250.000.250.500.75x5.3 Making a Parameter aware RC with RcTorch

To improve the model, the force applied to the pendulum can be fed to the RC as input. In this “parameter-aware" case,
the force is assumed to be known. In control theory and robotics such known forces are called “observers".9 RcTorch
can learn the mapping from the force to the dynamics, namely to x and p of the system. Note that X should be two
dimensional (either a numpy.nd.array or a PyTorch tensor).m

PRIME AI paper

>>> my_rc = RcNetwork ( * * hps ,

r a n d o m _ s t a t e = 2 1 0 ,

a c t i v a t i o n _ f u n c t i o n = " t a n h " ,

f e e d b a c k = T r u e )

>>> my_rc . f i t ( X = i n p u t _ t r a i n , y = t a r g e t _ t r a i n )
>>> s c o r e , p r e d i c t i o n = my_RC . t e s t (X = i n p u t _ t e s t ,

y = t a r g e t _ t e s t )

Figure 6: In this set of phase plots the parameter aware RC prediction (right) more closely resembles the ground truth
(left) than in the pure prediction case.

As demonstrated by Fig. 8 the parameter aware RC captured the dynamics of the system much better than the pure-
prediction RC. This is demonstrated, in particular, by the more accurate forecast of the underlying phase-space. The
overall MSE reported on the test set was

0.085 and the model took 9.53 seconds to ﬁt the data.

≈

5.4 Modifying activation functions with RcTorch

5.4.1 Output activation functions

Choosing an appropriate activation function is an efﬁcient way to improve the performance of a neural network (such
as an RC). For example, we might make the assumption that the forced pendulum problem under consideration is a
bounded problem. There are a host of other problems where bounding the output is reasonable, from planetary motion
to the movement of a robotic arm. Other systems must obey the conservation of energy.43 RcTorch can apply an
activation function to the ﬁnal layer of the network, which is by default the identity function. Because the range of the
prediction seems to be bounded above and below, we can apply the hyperbolic tangent (tanh) as its output is bounded
between -1 and 1.n

5.4.2 Multiple activation functions

RcTorch allows the user to control the activation functions used throughout the RC, not just in the output. In the
following code snippet, multiple activation functions were used instead of one. RcTorch employs multiple activation
functions to make hidden states more expressive. Namely, we get more complex dynamics of the states with more
activation functions. o

mThis is the reason for the capital X. By convention, uppercase letters represent matrices, and lowercase letters represent vectors.
ntanh is an invertible function. Therefore, we can use it as an output activation function, provided that the data that are fed to the
RC lie in the domain [-1,1]. RcTorch automatically scales the data for the user so that this is true, provided the training set and the
testing set lie in similar ranges.

oWe ran a rigorous study of whether multiple activation functions or the output activation function is more critical to ﬁnding a
lower loss and found that overall having varying activation functions was more impactful. This work can be found in the Appendix.
In fact we used a special version of ReLu which is only linear when for some input x, |x| ≤ θ∗ and otherwise is tanh.

11

−0.75−0.50−0.250.000.250.500.75x−0.4−0.20.00.20.4p−0.75−0.50−0.250.000.250.500.75xPRIME AI paper

>>> my_rc = RcNetwork ( * * hps ,
f e e d b a c k = True ,
o u t p u t _ a c t i v a t i o n = ‘ t a n h ’ ,
: 0 . 1 ,
a c t i v a t i o n _ f u n c t i o n = { ‘ t a n h ’
‘ r e l u ’
: 0 . 9 ,
‘ s i n ’ : 0 . 0 5 } )

r a n d o m _ s t a t e = 2 1 0 ,

Above, RcTorch assigns each reservoir node with an activation function with a probability weight proportional to the
value of the dictionary above (90% for ReLu, 10% for tanh, 5% for sin). RcTorch re-normalizes these probability
weights internally so that they sum to one.

Figure 7: From top to bottom: trajectory plot, middle residual plot, and phase-space plots plots. The ground truth phase
space plot is at the bottom left and the RC prediction is at bottom right. After using multiple activation functions the
non-linear non-orthogonal set of time dependent basis functions that make up the hidden states became more expressive
and thus the prediction of the RC is even closer to the ground truth than the combined plot method output shown in Fig
7. However, because both predictions are excellent, this difference is subtle.

The trajectory and phase-space plots for this experiment are shown in Fig. 7. The ﬁt is very accurate. The experiment
took 11.4 seconds to train with MSE = 0.005, or about 30 times less than the error in the ﬁrst RC ﬁt, the result of which
is shown in Fig. 4.p

pNote that the activation function was assigned as a Python dictionary.

12

−0.50.00.5x,p0255075100125150175t10−1010−4MSE−0.75−0.50−0.250.000.250.500.75x−0.4−0.20.00.20.4p−0.75−0.50−0.250.000.250.500.75xSo far, we have demonstrated that RcTorch satisﬁes two of the three of Bengio’s criteria for a successful time-dependent
model. The RC works with data for a long duration (many discrete time steps) and trains quickly. However, we have
not yet demonstrated its performance on noisy data.

PRIME AI paper

5.5 Noisy Data

To test our model on noisy data, we selected a new force f = 0.5000 sin(0.3867t) and generated new data with an
odeint integrator. Using a 40-60% train-test split, we ﬁt an RC on 8000 time-steps and predict an additional 12000
time-steps with the same HPs as in the previous section. However, this time we added random uniform noise to the
training data where y was perturbed by (cid:15), which is drawn from a uniform distribution within the range -0.15 and 0.15. In
Fig. 8 we demonstrate that the RC is able to recover the phase space and therefore was able to discover the underlying
dynamics of the system despite a signiﬁcant amount of noise. This clearly demonstrates the robustness of RcTorch to
noise.q

Figure 8: Top panel: Ground truth data without (left, blue) and with (right, gold) noise. Lower panel: 2 RcTorch
RcNetworks were trained on the noisy data. RcTorch RC predictions are plotted in red with a dashed line. The RC
prediction plotted at lower left was a pure prediction and the lower right prediction was parameter-aware.

qNote that the parameter-aware RC outperforms the pure-prediction RC as expected.

13

−0.6−0.4−0.20.00.20.40.6p−1.0−0.50.00.51.0x−0.6−0.4−0.20.00.20.40.6p−1.0−0.50.00.51.0xPRIME AI paper

5.6 Force comparison/Transfer learning

Previously, we demonstrated that the RC can solve the driven pendulum for a particular force. In order to demonstrate
the robustness of the RC, here we show how the RC performs when the problem is slightly altered. In general, a set of
RC HPs (and the hidden states that result from those HPs) can be seen as a high dimensional embedding of a problem
on which the RC is trained. In this section, we show that HPs can be transferred between similar experiments without a
signiﬁcant drop in performance. We generated new data with the odeint integrator for varying values of α and ω in
order to change the driven force of the pendulum.r Some examples of the effect of changing α and ω were visualized in
the trajectory and phase space plots in Fig. 2.

Figure 9: This ﬁgure shows the performance of RCs that are trained on different driven forces of the forced pendulum.
The heat-maps in the left hand column (top left and bottom left) plot scores of RCs doing pure prediction. The heat-maps
in the right hand column (top right and bottom right) plot the scores of parameter aware RCs. To generate the upper row
RC predictions (top left and top right) data was simulated from an integrator using a forced pendulum where the force
f = α sin (ωt). The lower row RC predictions (bottom left and bottom right) were trained based on data generated
with force f = α sin (ωt) cos (ωt). The MSE is represented by the red color value that is shown on a logarithmic scale.
Resonant frequencies in blue have been removed.

In Fig. 9 each rectangle represents a trained RC. It is important to note that all these RCs shared the same set of
HPs, which were introduced in section 5.2.1. The color of the rectangles corresponds to the MSE of that network,
ranging from dark red (low error) to light red (high error). Forces that resulted in resonance (unstable/aperiodic
behavior) are colored blue and are ignored. We compare pure prediction RCs (top left and bottom left heat maps) and
parameter aware RCs (top right and bottom right heat maps) side by side. It is clear from the darker color values that
the parameter-aware RCs perform better. In addition, we manipulate the forces by using two different base equations,
which are f = α sin (ωt) (the top left and top right heat-maps) and f = α sin (ωt) cos (ωt) (the bottom left and bottom
right heat-maps) in the ﬁrst and second rows of Fig. 9.

rIn particular we expressed the force as follows: f (α, ω, t) = α ∗ f (ωt), f ∈ sin(), cos(), sin() cos().

14

0.10.20.30.40.50.6α0.10.20.30.40.50.60.70.80.9ω0.10.20.30.40.50.60.70.8α0.10.20.30.40.50.60.70.80.9ω10−410−310−210−1100PRIME AI paper

Overall, low MSE values represented by large swaths of dark color indicate that the RC is robust to changes in force.
This implies that the RC hidden states learn something fundamental about the dynamics of the forced pendulum so
that we can conduct transfer learning for similar forces. However, there are small regions of the heat-maps with high
MSE values. These light colored patches correspond to values of α and ω for which the RC did not perform as well.
These regions, where the loss is larger, are found mostly on the edge of resonant behavior (blue patches), for example
(α = 0.1, ω = 0.95), force = sin() and (α = 0.5, ω = 0.5), force = sin()cos(). In the next section, we address this
issue by solving for new HPs.

5.7 Bayesian Optimization

RcTorch takes some of the best BO methods that have come out of Facebook, Uber, and MIT, and synthesizes them
to empower and automate RC. In particular, RcTorch relies on a custom implementation of the TuRBO algorithm in
combination with the BoTorch package.24,25 We modiﬁed the TuRBO algorithm outlined in a BoTorch tutorial.25,24
TuRBO, like global BO methods, is robust to noisy observations and has rigorous uncertainty estimates. However, an
advantage of TuRBO over other BO algorithms is that it does not suffer from “the overemphasized exploration that
results from global optimization" and does not “scale poorly to high dimensions".25 Turbo performs well by breaking
down the global optimization problem into many smaller local optimization problems. Moreover, Turbo has been shown
to be faster than other state-of-the-art black-box evaluation methods and has been shown to ﬁnd better global maxima.25

In order to obtain the set of HPs from the previous sections (ﬁrst introduced in section 5.2.1 and used until this point),
RcTorch RcBayes was run on data generated with an integrator where the driven force f = 0.5 sin(0.2t). From Fig.
9 we notice that the RC performed poorly for sin() cos() forces near α = 0.5 and ω = 0.6. These two sets of dynamics
are dissimilar enough to warrant the selection of a new set of HPs. An integrator was used to generate new data based on
sin(x) + 0.5 sin(0.6t) cos(0.6t).s
the new equation for the derivative of the momentum of the forced pendulum: ˙p =
For the initial position x0 = 0.1 and the initial velocity v0 = 0.1 Fig. 10 shows the corresponding trajectory.

−

Figure 10: Trajectory plot. The position and velocity are plotted in blue and yellow respectively, of the forced pendulum
when f = 0.5 sin(0.6t) cos(0.6t). The shape of this trajectory is different enough (based on the transfer learning loss
function heat-maps) shown in the previous section, to warrant a new HP search.

The RcTorch RcBayes class does the hard work of tuning the RC’s HPs. While at ﬁrst glance this class may seem very
complicated, it is in fact very easy to use. First, the bounds_dict deﬁnes the search bounds within which to search for
the HPs. Next, an RcBayes class object is declared. In this example, feedback was used. RcTorch was instructed to
use six localized TuRBO arms in parallel by including the n_jobs = 6 argument. The random seeds for the reservoirs
to be created were also speciﬁed and multiple activation functions were employed.

sOne problem with RNNs in general is the fact that the timestep interval dt must be ﬁxed. Here, dt was changed from 1/(200π)

to 1/(20π).

15

PRIME AI paper

Figure 11: Phase plots. In the left panel, the ground truth data is plotted for the forced pendulum when f =
0.5 sin(0.6t) cos(0.6t). In the center panel, the prediction is plotted from an RC which deﬁned by the HPs from the
previous section. In the right panel, the RC prediction with the new re-optimized HPs is plotted. The ground truth data
is plotted with a blue line. The RC predictions were plotted in a red dashed line.

>>> b o u n d s _ d i c t = { ‘ l o g _ c o n n e c t i v i t y ’

:

( − 2 , − 0 . 1 ) ,

:

‘ s p e c t r a l _ r a d i u s ’
‘ n_nodes ’
:
‘ l o g _ r e g u l a r i z a t i o n ’
‘ l e a k i n g _ r a t e ’
‘ b i a s ’ :

( 0 , 1 ) }

:

( 2 5 0 , 2 5 3 ) ,

( 0 , 1 ) ,

( 0 . 6 , 2 ) ,

:

( − 3 , 3 ) ,

>>> r c _ b a y e s = RcBayesOpt ( b o u n d s = b o u n d s _ d i c t ,

f e e d b a c k = True ,
s c o r i n g _ m e t h o d = ‘ nmse ’ ,
n _ j o b s = 6 ,
i n i t i a l _ s a m p l e s = 1 0 ,
r a n d o m _ s e e d = 2 1 0 ,
a c t i v a t i o n _ f u n c t i o n =
: 0 . 3 3 ,
: 0 . 5 ,
: 0 . 1 } )

{ ‘ r e l u ’
‘ t a n h ’
‘ s i n ’

Next, we call the optimize method to run the BO. We run TuRBO which will train n parallel local BO arms in parallel.

>>> o p t _ h p s = r c _ b a y e s . o p t i m i z e ( n _ t r u s t _ r e g i o n s = 6 ,

m a x _ e v a l s = 1 2 0 0 ,
x = i n p u t _ t r ,
y = t a r g e t _ t r )

>>> o p t _ h p s
{ ‘ c o n n e c t i v i t y ’ : 0 . 3 4 2 7 5 3 4 5 9 9 9 3 4 3 7 9 5 ,

‘ s p e c t r a l _ r a d i u s ’ : 1 . 5 7 3 1 1 2 8 4 5 4 2 0 8 3 7 4 ,
‘ n_nodes ’ : 2 5 1 ,
‘ r e g u l a r i z a t i o n ’ : 0 . 1 8 8 0 5 3 5 3 5 0 5 9 4 4 8 7 ,
‘ l e a k i n g _ r a t e ’ : 0 . 0 3 2 7 9 4 6 0 2 2 1 5 2 9 0 0 7 ,
‘ b i a s ’ : 0 . 8 6 2 5 0 6 5 0 8 8 2 7 2 0 9 5 }

By comparing the phase-space plots in Fig. 11 the dynamics of the system are clearly well captured. In particular, the
M SE = 0.879 with the old HPs and with the new HPs the M SE = 0.0009.t

tRcTorch has a useful method called recover_hps which can recover the best scoring HPs if the BO run hangs. This can be
achieved either by directly calling the method if the practitioner is running code in a Jupyter notebook, or by wrapping the BO code
with a try except catch.

16

−1.0−0.50.00.51.0x−1.0−0.50.00.51.0p−1.0−0.50.00.51.0x−1.0−0.50.00.51.0xPRIME AI paper

6 Conclusion

Reservoir computing holds great promise for the future of AI research and applications. Here, we introduce RcTorch
as the ﬁrst uniﬁed PyTorch RC library with user-friendly hyper-parameter tuning. The library is written to be updated
very easily.

It is easy to install RcTorch using the command pip install rctorch and to apply it to a new data set. The associ-
ated documentation can be found on our github page: https://github.com/blindedjoy/RcTorch or at readthe-
docs https://rctorch.readthedocs.io/en/latest/Pages/tutorials/forced_pendulum.html. This pa-
per aims to allow researchers all over the world to download RcTorchand use it to rapidly solve problems described by
sequential data.

References

[1] Andrey Kurenkov. “A Brief History of Neural Nets and Deep Learning”. In: Skynet Today (2020).
[2] David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams. Learning representations by back-propagating errors. URL:

https://www.nature.com/articles/323533a0#citeas.

[3] Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. “On the difﬁculty of training recurrent neural networks”. In: (), p. 9.
[4] H. Jaeger. “The”echo state”approach to analysing and training recurrent neural networks”. In: 2001.
[5] Mantas Lukoševiˇcius, Herbert Jaeger, and Benjamin Schrauwen. “Reservoir Computing Trends”. In: KI - Künstliche Intelligenz
26.4 (Nov. 2012), pp. 365–371. ISSN: 0933-1875, 1610-1987. DOI: 10 . 1007 / s13218 - 012 - 0204 - 5. URL: http :
//link.springer.com/10.1007/s13218-012-0204-5 (visited on 11/18/2021).

[6] Marios Mattheakis, Hayden Joy, and Pavlos Protopapas. “Unsupervised Reservoir Computing for Solving Ordinary Differential
Equations”. In: arXiv:2108.11417 [physics] (Aug. 25, 2021). arXiv: 2108.11417. URL: http://arxiv.org/abs/2108.
11417 (visited on 11/18/2021).
Jaideep Pathak et al. “Model-Free Prediction of Large Spatiotemporally Chaotic Systems from Data: A Reservoir Computing
Approach”. In: Phys. Rev. Lett. 120 (2 2018), p. 024102. DOI: 10.1103/PhysRevLett.120.024102.

[7]

[8] George Neofotistos et al. “Machine Learning With Observers Predicts Complex Spatiotemporal Behavior”. In: Frontiers in
Physics 7 (Mar. 5, 2019), p. 24. ISSN: 2296-424X. DOI: 10.3389/fphy.2019.00024. URL: https://www.frontiersin.
org/article/10.3389/fphy.2019.00024/full (visited on 11/18/2021).

[9] Zhixin Lu et al. “Reservoir observers: Model-free inference of unmeasured variables in chaotic systems”. In: Chaos: An

[10]

Interdisciplinary Journal of Nonlinear Science 27.4 (2017), 041102–1–041102–8. DOI: 10.1063/1.4979665.
Sandeep Pandey and Jörg Schumacher. “Reservoir computing model of two-dimensional turbulent convection”. In: Physical
Review Fluids 5.11 (Nov. 19, 2020), p. 113506. ISSN: 2469-990X. DOI: 10 . 1103 / PhysRevFluids . 5 . 113506. URL:
https://link.aps.org/doi/10.1103/PhysRevFluids.5.113506 (visited on 11/21/2021).

[11] A. Lugnan et al. “Photonic neuromorphic information processing and reservoir computing”. In: APL Photonics 5.2 (Feb. 1,
2020), p. 020901. ISSN: 2378-0967. DOI: 10.1063/1.5129762. URL: http://aip.scitation.org/doi/10.1063/1.
5129762 (visited on 12/03/2021).

[12] Andrew Katumba et al. “Low-loss photonic reservoir computing with multimode photonic integrated circuits”. eng. In:
SCIENTIFIC REPORTS 8.1 (2018), 2653:1–2653:10. ISSN: 2045-2322. DOI: 10.1038/s41598- 018- 21011- x. URL:
http://dx.doi.org/10.1038/s41598-018-21011-x.

[13] Satoshi Sunada and Atsushi Uchida. “Photonic reservoir computing based on nonlinear wave dynamics at microscale”. In:

SCIENTIFIC REPORTS 9.1 (2019), 19078:1–19078:10. DOI: 10.1038/s41598-019-55247-y.

[14] Laurent Larger et al. “High-Speed Photonic Reservoir Computing Using a Time-Delay-Based Architecture: Million Words
per Second Classiﬁcation”. In: Physical Review X 7.1 (Feb. 6, 2017), p. 011015. ISSN: 2160-3308. DOI: 10.1103/PhysRevX.
7.011015. URL: https://link.aps.org/doi/10.1103/PhysRevX.7.011015 (visited on 11/19/2021).

[15] Giulia Marcucci, Davide Pierangeli, and Claudio Conti. “Theory of Neuromorphic Computing by Waves: Machine Learning
by Rogue Waves, Dispersive Shocks, and Solitons”. In: Physical Review Letters 125.9 (Aug. 26, 2020), p. 093901. ISSN:
0031-9007, 1079-7114. DOI: 10.1103/PhysRevLett.125.093901. URL: https://link.aps.org/doi/10.1103/
PhysRevLett.125.093901 (visited on 11/19/2021).

[16] D.H. Wolpert and W.G. Macready. “No free lunch theorems for optimization”. In: IEEE Transactions on Evolutionary
Computation 1.1 (Apr. 1997), pp. 67–82. ISSN: 1089778X. DOI: 10.1109/4235.585893. URL: http://ieeexplore.
ieee.org/document/585893/ (visited on 11/18/2021).

[17] Y.C. Ho and D.L. Pepyne. “Simple Explanation of the No-Free-Lunch Theorem and Its Implications”. In: Journal of
Optimization Theory and Applications 115.3 (Dec. 2002), pp. 549–570. ISSN: 0022-3239, 1573-2878. DOI: 10.1023/A:
1021251113462. URL: http://link.springer.com/10.1023/A:1021251113462 (visited on 11/18/2021).

17

PRIME AI paper

[18]

Faris Hossam et al. “Optimizing the Learning Process of Feedforward Neural Networks Using Lightning Search Algorithm.”
In: International Journal on Artiﬁcial Intelligence Tools 25.6 (Oct. 28, 2016). DOI: doi:10.1142/S0218213016500330.
(Visited on 11/16/2021).
Jacob Reinier Maat, Nikos Gianniotis, and Pavlos Protopapas. “Efﬁcient Optimization of Echo State Networks for Time
Series Datasets”. In: 2018 International Joint Conference on Neural Networks (IJCNN) (July 2018), pp. 1–7. DOI: 10.1109/
IJCNN.2018.8489094. arXiv: 1903.05071. URL: http://arxiv.org/abs/1903.05071 (visited on 04/02/2022).
[20] Colin Reckons. Lecture 16.3 — Bayesian optimization of hyper-parameters [Neural Networks for Machine Learning]. Feb. 5,

[19]

2016. URL: https://www.youtube.com/watch?v=con_ONbhD2I (visited on 11/18/2021).

[21] Huong Ha et al. Bayesian Optimization with Unknown Search Space. 2019. arXiv: 1910.13092 [stat.ML].
[22] Zhongxiang Dai, Kian Hsiang Low, and Patrick Jaillet. Federated Bayesian Optimization via Thompson Sampling. 2020.

[23]

arXiv: 2010.10154 [cs.LG].
Jacob Reinier Maat, Nikos Gianniotis, and Pavlos Protopapas. “Efﬁcient Optimization of Echo State Networks for Time
Series Datasets”. In: 2018 International Joint Conference on Neural Networks (IJCNN). 2018, pp. 1–7. DOI: 10.1109/IJCNN.
2018.8489094.

[24] Maximilian Balandat et al. “BoTorch: A Framework for Efﬁcient Monte-Carlo Bayesian Optimization”. In: Advances in
Neural Information Processing Systems. Ed. by H. Larochelle et al. Vol. 33. Curran Associates, Inc., 2020, pp. 21524–21538.
URL: https://proceedings.neurips.cc/paper/2020/file/f5b1b89d98b7286673128a5fb112cb9a-Paper.pdf.
[25] David Eriksson et al. Scalable Global Optimization via Local Bayesian Optimization. 2020. arXiv: 1910.01739 [cs.LG].
[26] Y. Bengio, P. Simard, and P. Frasconi. “Learning long-term dependencies with gradient descent is difﬁcult”. In: IEEE
Transactions on Neural Networks 5.2 (Mar. 1994), pp. 157–166. ISSN: 1045-9227, 1941-0093. DOI: 10.1109/72.279181.
URL: https://ieeexplore.ieee.org/document/279181/ (visited on 11/18/2021).
Sepp Hochreiter and Jürgen Schmidhuber. “Long Short-Term Memory”. In: Neural Computation 9.8 (1997), pp. 1735–1780.
[27]
[28] Zander Danko. Neon prescription... or rather, New transcription for Google Voice. July 2015. URL: https://blog.google/

products/google-voice/neon-prescription-or-rather-new/.

[29] Dr. Werner Vogels. Bringing the Magic of Amazon AI and Alexa to Apps on AWS. Nov. 2016. URL: https : / / www .

allthingsdistributed.com/2016/11/amazon-ai-and-alexa-for-all-aws-apps.html.

[30] How Alexa is learning to converse more naturally. Amazon Science. Aug. 27, 2018. URL: https://www.amazon.science/

blog/how-alexa-is-learning-to-converse-more-naturally (visited on 04/02/2022).

[31] Tim Capes et al. “Siri On-Device Deep Learning-Guided Unit Selection Text-to-Speech System”. In: INTERSPEECH. 2017.
olly18/Depositphotos. Microsoft’s speech recognition system is now as good as a human. 2017. URL: https://newatlas.
[32]
com/microsoft-speech-recognition-equals-humans/50999/.

[33] Thuy Ong. Facebook’s translations are now powered completely by AI. 2017. URL: https://www.theverge.com/2017/

8/4/16093872/facebook-ai-translations-artificial-intelligence.

[34] Deep Transfer Learning for NLP with Transformers. Manning. Mar. 27, 2021. URL: https://freecontent.manning.

com/deep-transfer-learning-for-nlp-with-transformers/ (visited on 12/06/2021).

[35] Clemens Korndörfer. Echo State Networks in Python. original-date: 2015-02-04T19:34:55Z. Mar. 8, 2022. URL: https:

//github.com/cknd/pyESN (visited on 04/02/2022).

[36] Nils Schaetti. nschaetti/EchoTorch. original-date: 2017-04-06T08:41:57Z. Mar. 29, 2022. URL: https://github.com/

nschaetti/EchoTorch (visited on 04/02/2022).

[37] Fabrizio Damicelli. echoes. original-date: 2019-11-27T14:03:50Z. Mar. 27, 2022. URL: https : / / github . com /

fabridamicelli/echoes (visited on 04/02/2022).

[38] Stefano Nardo. PyTorch-ESN. original-date: 2018-03-25T22:28:33Z. Mar. 29, 2022. URL: https : / / github . com /

stefanonardo/pytorch-esn (visited on 04/02/2022).

[39] Claire D. Costa. Reasons to Choose PyTorch for Deep Learning. Medium. Apr. 6, 2020. URL: https : / /
towardsdatascience . com / reasons - to - choose - pytorch - for - deep - learning - c087e031eaca (visited on
11/19/2021).

[40] Pietro Verzelli et al. “INPUT REPRESENTATION IN RECURRENT NEURAL NETWORKS DYNAMICS”. In: arXiv

(2020), p. 2004.11234.

[41] Linda Petzold. “Automatic Selection of Methods for Solving Stiff and Nonstiff Systems of Ordinary Differential Equations”.
In: SIAM Journal on Scientiﬁc and Statistical Computing 4.1 (Mar. 1983), pp. 136–148. ISSN: 0196-5204, 2168-3417. DOI:
10.1137/0904010. URL: http://epubs.siam.org/doi/10.1137/0904010 (visited on 12/03/2021).
scipy.integrate.odeint — SciPy v1.7.1 Manual. URL: https://docs.scipy.org/doc/scipy/reference/generated/
scipy.integrate.odeint.html (visited on 11/21/2021).

[42]

[43] Marios Mattheakis et al. “Hamiltonian neural networks for solving equations of motion”. In: Phys. Rev. E 105 (6 2022),

p. 065305. DOI: 10.1103/PhysRevE.105.065305.

18

