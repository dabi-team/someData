2
2
0
2

l
u
J

4
1

]

G
L
.
s
c
[

1
v
9
8
0
7
0
.
7
0
2
2
:
v
i
X
r
a

JULY 2022

1

A Personalized Zero-Shot ECG Arrhythmia Monitoring System:
From Sparse Representation Based Domain Adaption to
Energy Efﬁcient Abnormal Beat Detection for Practical ECG
Surveillance

Mehmet Yamac¸∗1, Mert Duman∗1, Ilke Adalıo˘glu1, Serkan Kiranyaz2, and Moncef Gabbouj1

1Tampere University, Faculty of Information Technology and Communication Sciences, Tampere, Finland
2Department of Electrical Engineering, Qatar University, Qatar

This paper proposes a low-cost and highly accurate ECG-
monitoring system intended for personalized early arrhythmia
detection for wearable mobile sensors. Earlier supervised ap-
proaches for personalized ECG monitoring require both abnor-
mal and normal heartbeats for the training of the dedicated
classiﬁer. However, in a real-world scenario where the personal-
ized algorithm is embedded in a wearable device, such training
data is not available for healthy people with no cardiac disorder
history. In this study, (i) we propose a null space analysis on
the healthy signal space obtained via sparse dictionary learning,
and investigate how a simple null space projection or alternatively
regularized least squares-based classiﬁcation methods can reduce
the computational complexity, without sacriﬁcing the detection
accuracy, when compared to sparse representation-based clas-
siﬁcation. (ii) Then we introduce a sparse representation-based
domain adaptation technique in order to project other existing
users’ abnormal and normal signals onto the new user’s signal
space, enabling us to train the dedicated classiﬁer without having
any abnormal heartbeat of the new user. Therefore, zero-shot
learning can be achieved without the need for synthetic abnormal
heartbeat generation. An extensive set of experiments performed
on the benchmark MIT-BIH ECG dataset shows that when this
domain adaptation-based training data generator is used with
a simple 1-D CNN classiﬁer, the method outperforms the prior
work by a signiﬁcant margin. (iii) Then, by combining (i) and
(ii), we propose an ensemble classiﬁer that further improves the
performance. This approach for zero-shot arrhythmia detection
achieves an average accuracy level of 98.2% and an F1-Score of
92.8%. Finally, a personalized energy-efﬁcient ECG monitoring
scheme is proposed using the above-mentioned innovations. The
software implementation of the proposed technique is publicly
available at https://github.com/MertDuman/Zero-Shot-ECG.

Index Terms—Zero-Shot Anomaly Detection, Personalized

ECG Monitoring, Sparse Representation, Dictionary Learning

I. INTRODUCTION

A N abnormal heart rhythm, i.e., cardiac arrhythmia can

be a predictor of a major health threat such as stroke or
heart failure. In fact, the past statistics show that cardiovascular
diseases continue to be the number one cause of death, i.e,
32.84% of all deaths in 2019 were caused by cardiovascular
diseases [1]. Real-time detection of cardiac arrhythmias using
computer technology can signiﬁcantly reduce the number
of casualties. Numerous methods have been proposed for
identifying electrocardiogram (ECG) waveforms using signal

*These authors contributed equally to this work

processing and machine learning, such as frequency analysis
[2], support vector machines (SVMs) [3], statistical analysis
[4], etc. The majority of these methods, however, are based
on a set of handcrafted features, making them inﬂexible to
changes in ECG patterns. Depending on the circumstances
and even from heartbeat to heartbeat, ECG morphology can
show variations [5]. Additionally, ECG morphology is unique
to each individual according to their cardiovascular system [6].
As a result, robust person identiﬁcation from ECG signals has
become a popular research topic recently [7], [8]. Therefore, it
is essential to design a person-based (personalized) arrhythmia
detection system, which is not possible by the traditional
methods mentioned above.

A personalized classiﬁcation and arrhythmia detection sys-
tem is proposed in [9], [10], [11]. In [12], Zhai et al.
represented 1-D ECG signals in 2-D by taking the outer
product of two adjacent dual-beats. This 2-D coupling matrix
captures the morphology of a single heartbeat as well as
the temporal morphological characteristics of the adjacent
beats. In [13], various features (e.g. R-R intervals, beat-to-
beat correlation, etc.) are extracted from the ECG signals and
stacked to create 3-D inputs to a convolutional neural network
(CNN). Nevertheless, such methods require both normal and
abnormal heartbeats from a patient in order to train a dedicated
classiﬁer. Therefore, they cannot serve as an early detection
system for an otherwise healthy person who has no history
of heart disease. As an alternative, the landmark study in
[14] has proposed a system to model the degradation between
normal and abnormal beats by learning linear ﬁlters from
several arrhythmia patients. After that, for a new user, the
potential abnormal beats can be synthesized directly from the
normal beats, and ﬁnally, a dedicated 1-D CNN is trained over
synthesized abnormal heartbeats and real normal heartbeats to
monitor signs of arrhythmia of the user.

Sparse approximation (SA) is a procedure that involves
determining a set of waveforms known as a dictionary or
a basis set. Then, a signal can be embodied as a linear
combination of a small number of these predeﬁned dictionary
elements, or in other words, as a sparse code representation.
Some of the recent applications of sparse decomposition
include compressed sensing (CS) [15], classiﬁcation [16], and
encrypted ECG monitoring [17]. In recent works [18], [19]
SA has been successfully used in ECG classiﬁcation tasks.

 
 
 
 
 
 
JULY 2022

These methods, however, attempt to learn SA dictionaries
from the extracted features, rather than directly from the
raw data. Therefore, their performance is still limited by the
discrimination power of the handcrafted features.

An alternative approach that bypasses the need to collect
abnormal ECG data [20], and uses only normal heartbeats in
the training phase relies on an outlier detection scheme. The
methods in [20], and [21] propose a sparse approximation
method that learns the dictionary directly from the normal
beats of a speciﬁc user without the need for any abnormal beat
synthesis. The underlying principle is that normal heartbeats
live in the learned subspace while abnormal heartbeats do not.
Thus, during the monitoring phase, a heartbeat is considered
abnormal if it cannot be sparsely represented in the person-
speciﬁc dictionary. However, they use only 1-D features and a
simple classiﬁcation technique to detect the anomaly. Adler et
al. [21] have tried to separate sparse and non-sparse residuals
by using consecutive heartbeats via group sparsity. As a
feature, they use the energy of each sparse error. The methods
proposed in [20], and [22], have also used a simple feature
which is the energy of sparse approximation error (SAE). Their
studies show us that Sparse Codes (SCs) are highly informative
in ECG classiﬁcation and more easily adaptable to changes in
ECG patterns. It appears that SC-based arrhythmia monitoring
has the potential for signiﬁcant improvements.

In this study, we begin with the approach in [20], [21],
and [22] to learn personalized dictionaries representative of
normal beats. We investigate novel ways to improve anomaly
detection performance by instrumenting advanced machine
learning tools without using any abnormal beats and only a
small amount of normal beats for a speciﬁc user. The novel
and signiﬁcant contributions of this study can be introduced
as follows. (i) First, we introduce the left null space matrix
of the normal dictionary. This provides a faster way to obtain
approximated representation error similar to the one proposed
in [20], [22]. The proposed null space analysis-based classiﬁer
performs very similarly to the SA analysis in [20], [22] with
a signiﬁcantly reduced computational cost. Additionally, we
analyze how the classiﬁer based on the regularized least square
solution can be used as an alternative to the null space-based
classiﬁer, with a similar classiﬁcation accuracy and compu-
tational complexity. (ii) A domain transformation technique
is presented in this study for projecting the heartbeats of
a patient to the space of a new user’s heartbeats without
knowledge of the new user’s abnormal data. Different from
[14], the transformation is linearly approximated in this case
and the linear mapping is estimated using sparse representation
where only the normal heartbeat dictionaries of the target
(i.e. new users with no abnormal heartbeats, but a small
normal heartbeat collection) and source (i.e. registered patients
with both normal and abnormal heartbeats) users are used.
The anomaly detection performance is signiﬁcantly improved
compared to the SOTA methodology proposed in [14] when
the same classiﬁer is trained and used.

(iii) Moreover, by combining innovations (i) and (ii), we
developed a decision-making strategy that enhanced SOTA
performance even further. (iv) Finally, a novel and energy-
efﬁcient ECG monitoring system is proposed to detect ar-

Variable
sp
i ∈ RN
D ∈ RN ×n
e ∈ RN
xp
i ∈ Rn
(cid:101)e(cid:96)1 = Dp
F p ∈ RN −n×N
(cid:101)e = F psp

i

i − sp
(cid:98)xp

i

(cid:101)e(cid:96)2 = Dp

i − sp
(cid:98)xp

i

Synonyms
ith ECG beat of
user p
Sparsifying dictionary
Representation error
Sparse coefﬁcients of sp
i
Sparse Approximation
Error (SAE)
Left annihilator matrix
Null Space Projection
Error (NPE)
Least Squares Approximation
Error (LAE)

Ql→p ∈ RN ×N

Morphology Transformation
Matrix (MTM)

2

Properties

Sparse in D

i = Dpxp
sp

i + e

(cid:107)x(cid:107)0 ≤ k if k-sparse
(cid:98)xp
i is the solution of
any SR algorithm
F pDp = 0

(cid:98)xp
i is the Least
Squares estimate
ECG beat linear domain
adaptation matrix from
user l to user p

TABLE I: Frequently used variables throughout the article.

rhythmia at the moment it occurs. In this system, the ECG
is ﬁrst projected onto the left null space of the normal
dictionary using matrix-vector multiplication, which requires
insigniﬁcant power. Then, ECG beats are pre-classiﬁed (in
real-time and possibly on the sensor) by using the energy
of these projected signals, and only the suspected ones are
further classiﬁed using the proposed methods in (ii) or (iii).
Thus, using this lightweight monitoring scheme, the energy
of the sensors can be preserved considerably with minimal
sacriﬁce on the detection performance.

The rest of the paper is organized as follows. In Section
I-A, the notations are introduced. A brief literature survey is
presented in Section II. The proposed null space projection-
based classiﬁcation and sparse representation-based domain
adaptation are explained in Section III. In Section IV, ex-
perimental results and comparative evaluations are presented.
Finally, Section VI and Section VII discuss the performance
and limitations of the proposed system with possible future
extensions and highlight important conclusions.

A. Notations
Throughout the article, the (cid:96)p-norm of a vector x ∈ RN is
deﬁned as (cid:107)x(cid:107)p = ((cid:80)N
i=1 |xi|p)1/p for p ≥ 1. In addition, the
number of non-zero coefﬁcients of x is calculated with the
i=1 |xi|p = #{l : xl (cid:54)= 0}. A
(cid:96)0-norm, i.e., (cid:107)x(cid:107)0 = limp→0
strictly k-sparse signal contains at most k number of non-zero
coefﬁcients, i.e., (cid:107)x(cid:107)0 ≤ k. As a convenience to readers, we
provide a list of frequently used variables, their deﬁnitions,
and their abbreviations in Table I.

(cid:80)N

II. RELATED WORKS

A. Sparse Representation Based Classiﬁcation
Let sp

i ∈ RN be the ith ECG heartbeat of the pth user
which can be represented [20] by a linear combination of n
wave-forms, i.e.,

sp
i = Dpxp
i ,
where Dp ∈ RN ×n is the dictionary of these wave-forms
(atoms) and xp
i ∈ Rn is the corresponding coefﬁcient vector.
In the case of being overcomplete (n > N ) the representation

(1)

JULY 2022

3

will be enriched; however, the representation formed by (1)
will not be unique. It is possible to make it unique by making
it represent the signal in Dp with the smallest number of
signiﬁcant coefﬁcients (i.e. sparseness), i.e.,
subject to Dpxp

(cid:107)xp

(2)

i = sp
i ,

i (cid:107)(cid:96)n

0

min
xp
i

which is known as the sparse representation of the signal sp
i .
A signal is said to be strictly k-sparse if the number of non-
zero coefﬁcients representing it in the dictionary is less than
a constant k, i.e., (cid:107)x(cid:107)0 ≤ k. The most common solutions for
solving the sparse optimization problem are convex relaxation,
like Basis Pursuit and Basis Pursuit Denoising [23], or greedy
algorithms like orthogonal matching pursuit (OMP) [24].

The sparse representation in (2) is still valid in under-
complete dictionaries i.e, N > n. For instance, the authors of
[20] use n number of atoms with n < N , e.g., n = 20 where
N = 256, and get the highest performance in representing the
normal ECG heartbeats. The authors of [20] use the energy
of Sparse Approximation Error (SAE) to detect anomalies,
which can be calculated as

ri = (cid:107)Dp ˆxp

i − sp

i (cid:107)2
2 ,

(3)

where Dp is the user-speciﬁc dictionary learned by using the
KSVD method [25] from the normal heartbeats. Normal beats
are assumed to be collected for a limited duration from a new
user without obtaining or labeling the abnormal beats. Having
the pre-trained dictionary, when a new ECG beat sp
i comes
into the picture, its sparse coefﬁcients are obtained with the
OMP algorithm. Then, the estimation ˆxp
i is back-projected to
the dictionary and the residual or SAE is calculated as in Eq.
(3). Then, they use a simple thresholding method on ri to
detect anomaly i.e., detect anomaly if ri > γ, where γ is the
deﬁned threshold.

B. Abnormal Beat Synthesis for Early Arrhythmia Detection

Using both normal and abnormal ECG beats collected from
the patient, an anomaly ECG beat detection system can easily
be trained. The problem, however, is that in real life, if we
want
to develop an early warning system, we may never
have the real anomaly beats for a healthy user who has just
registered to the system. To resolve this problem, the authors of
[14] introduced a personalized abnormal beat synthesis (ABS)
method. In this system, when a new user enters the system,
the normal ECG beats of this new user are collected for a
short period of time. Since the assumption is that there are
no anomalous heartbeats in these signals, synthetic anomaly
heartbeats are generated from them.

To develop their system, the authors ﬁrst modeled the effect
of common causes of heart disease on the measurement of
ECG beat signals. In this model, a certain group of heart
diseases morphologically distort normal heartbeat signals to
convert them into a certain type of abnormal heartbeat signals.
The authors modeled this transformation from a normal heart-
beat to an abnormal heartbeat as a linear time-invariant (LTI)
system. Mathematically speaking, the assumption is that any
observed abnormal signal sl
A of user l can be approximated

as the linearly degraded version of a latent unknown normal
signal sl

N , i.e.,

sl
N

(cid:126) hl = sl

A,

(4)

where hl ∈ RM is the M -length ﬁlter coefﬁcient vector of the
LTI system and (cid:126) is the convolution operation. As part of the
process of obtaining a ﬁlter-bank, the authors ﬁrst select an
average normal beat for a user l, by taking the average of all
normal beats of the user and ﬁnding the normal beat closest
to the average. Then, using this average normal beat ¯sl
N , for
A, a ﬁlter hl is estimated from
each abnormal observation sl
Equation ¯sl
A via regularized least-squares ﬁltering.
N
The ﬁnal ABS ﬁlter library is the remaining set of ﬁlters after
similar ones have been pruned.

(cid:126)hl = sl

When a new user p registers to the system, the average
normal beat ¯sp
N of this new user is calculated from the
collected beats. Then, a kernel is picked up from the afore-
mentioned ﬁlter bank of some user l. Finally, a synthetic
abnormal beat sp
A is generated by applying this ﬁlter to ¯sp
N
A = ¯sp
as sp
(cid:126) hl. This way, the personalized training data for
user p is generated as a collection of p’s own normal beats and
generated abnormal beats using the ABS ﬁlter library. Such
artiﬁcial generation of the personalized training data enables
the training of an ordinary classiﬁer, e.g., a 1-D CNN. Figure 1
illustrates the use of linear degradation estimates of an existing
user on a new user’s normal ECG signals.

N

l

r
e
s
U

p
r
e
s
U

N l

N l N l

N p N p N p

Linear
Degrading
System

Hl( )

Linear
Degrading
System

H l( )

N l

Al

N l

N p

Ap

N p

Fig. 1: The schema of ABS [14]: The estimated linear degrading system of
the existing user j can be applied to the healthy ECG beats of a new user p
in order to synthesize possible abnormal beats for user p.

C. Generative Adversarial Network Based Synthesizers

Typically, certain arrhythmia types occasionally occur in an
ECG recording acquired even from arrhythmia patients. Most
of the GAN-based ECG generator algorithms [26], [27], [28],
[29], [30], [31] were developed to provide data augmentation
so as to overcome the data imbalance problem during training
rather than to provide a personalized zero-shot (personalized
zero-shot refers to being entirely blind to the person’s anomaly
signal during training) solution. In the sequel, a brief overview
of the developments in GAN-based ECG data generation
technologies is presented.

JULY 2022

4

In [32], Delaney et al. trained various GANs to generate
synthetic signals and used dynamic time warping (DTW) and
maximum mean discrepancy (MMD) to evaluate the quality
of the generated signals. Similar to [32], [33] used GANs for
data generation and evaluated their performances by using an
SVM classiﬁer. Zhu et al. [34] used GANs with bidirectional
LSTM-CNNs for data augmentation and used percent root
mean square distance (PRD), root mean square error (RMSE),
and Fr´echet distance (FD) for synthesizer evaluation. In these
approaches, the aim was once again to generate synthetic
ECG data, hence they neither train a classiﬁer nor test the
classiﬁcation performance.

In [35], Zhou et al. proposed the most akin method to
ours, which can therefore be categorized as personalized zero-
shot learning. The authors trained a global generative network,
where the generator synthesizes a 2-D coupling matrix belong-
ing to one of ﬁve beat classes, and the discriminator works as
an auxiliary classiﬁer to determine both the beat class and its
genuinity. After the initial training, the discriminator is ﬁne-
tuned into a patient-dependent classiﬁer by further training
on normal beats as well as generated abnormal beats from a
speciﬁc patient.

Among the aforementioned GAN-based ECG generator
algorithms which try to overcome the data imbalance problem,
we select one of the SOTA methods [31] as a competing
algorithm even though direct comparison is not fair since in
our setup we do not have access to any anomaly of the person
of interest while they do. Similar to [35], Shaker et al. [31]
trained a global GAN synthesizer for data augmentation; how-
ever, they trained a separate classiﬁer for arrhythmia detection.
Even though this method is neither zero-shot nor personalized
(which brings advantages compared to our zero-shot solution
in any comparison), we still compare our performance as it
can be intuitively seen as an upper band for our task of data
generation for the case where there is access to at least a
few anomalies for the patient. Despite such disadvantages, the
proposed algorithm in this study can still achieve comparable
results as discussed in Section VI.

III. PROPOSED SOLUTION(S)

A. Null Space Projection Based Classiﬁer (Proposed Solu-

tion I)

As in [20], we also assume that a normal ECG beat can
be represented in a pre-deﬁned dictionary representing normal
beat space with a relatively small approximation error, i.e.,
i = Dpxp
sp

i + e,

(5)

where e can be called as representation error, or residual
(later will be called as SAE when xp
is sparse). For the
i
ideal case where e = 0 and Dp satisﬁes some properties, the
uniqueness of the solution of (5) can be guaranteed [36] with
SR given in (2) with an assumption that xp
i is strictly sparse.
In a real-world ECG classiﬁcation task, one can easily assume
that sparse approximation errors, e, always occur and the
representation coefﬁcients, x are not exactly but approximately
sparse. Moreover, as the (cid:96)0-norm is a non-convex function,
the optimization problem in Eq. (2) is NP-hard. By replacing

the (cid:96)0-norm with the closed convex norm, (cid:96)1-norm, this (cid:96)0-
minimization problem can be relaxed:

(cid:107)sp

i − Dpxp

i (cid:107)2

2 + λ (cid:107)xp

i (cid:107)1 ,

min
xp
i

(6)

which is also known as the Lasso formulation [37], and known
to provide a stable solution in noisy and approximate sparse
cases, and a stable solution in noise-free cases [38] given
the dictionary satisﬁes some properties. There exist numerous
techniques in order to handle the optimization problem deﬁned
in Eq. (6). We implemented the proposed algorithm based on
the alternating direction method of multipliers (ADMM) [39].
As can be seen in Figure 2, a normal ECG beat sp
i can be
well represented in Dp, i.e., sp
i , while abnormal
ones having larger representation error when represented in
Dp.

i ≈ Dpxp

Dictionary Learning: As stated in Section II-A, by using the
nice properties of sparse representation, in the methods [20],
[22], the user-speciﬁc dictionary Dp is learned only from the
normal ECG beat collection of user p. Different from their
work, where K-SVD is used to learn dictionaries for a pre-
determined ﬁxed number of non-zero coefﬁcients, k, we use
the following Lasso formulation, in which the estimated sparse
signal coefﬁcients have a more ﬂexible structural behavior:
(cid:107)Sp − DpX p(cid:107)2

2 + λ (cid:107)X p(cid:107)1 ,

(7)

min
X p, Dp

where Sp ∈ RN ×T is the collection of T number of normal
ECG beats of user p and X p ∈ Rn×T is the corresponding
sparse coefﬁcient matrix. In order to solve the optimization
problem deﬁned in Eq. (7), we implement a variant of the
method of optimal directions (MOD) [40]. All ECG beat
samples considered in the study have been used only after
they have been normalized to unit energies, i.e., (cid:107)si(cid:107)2 = 1.
Energy-Efﬁcient Classiﬁcation: Having the dictionary Dp
of the healthy ECG beat space, when a new set of test signals
Sp
i are acquired, one can solve the sparse recovery problem
in Eq. (6). Then, by using the SAE outlined in Eq. (3), the
class can be determined using a predeﬁned threshold [20].
Besides the severe threshold sensitivity, such sparse recovery
algorithms still work in an iterative manner, which increases
the computational cost.

On the other hand,

leveraging only a few atoms (e.g.,
n = 20) compared to the beat signal size (e.g., N = 128)
is enough to represent normal signal (beat) space. In such a
scenario (i.e., N > n), the left null space of Dp exists and,
in the sequel we will show that by projecting the test signal
on it, the computational complexity of the classiﬁcation task
can be reduced signiﬁcantly. Let F p ∈ RN −n×N be the left
annihilator matrix of Dp, i.e., F pDp = 0. We ﬁnd such
matrix by orthonormalizing the left-null space basis of Dp.
i , the pre-constructed and user-
speciﬁc normal signal component annihilator matrix, F p, is
i.e., F psp
applied from the left,
the
resulting vector (cid:101)e, which we call Null Space Projection Error
(NPE), can be cast as
(cid:101)e = F psp

Given the test signal, sp

i . By using Eq. (5),

i = F p (Dpxp

i + e) = F pe.

(8)

JULY 2022

5

By doing so,

the normal ECG beat component can be
removed through simple matrix-vector multiplication. It
is
the energy of NPE would be
straightforward to see that
small enough for a healthy ECG signal, but would be much
greater in the case of an abnormal signal. Indeed, we will
demonstrate in Section IV that the energy of the SAE and
the energy of the NPE can be very close when applied to
real ECG beats. Consequently, we can signiﬁcantly reduce the
computational complexity as compared to the case where the
sparse coefﬁcients are estimated ﬁrst by (cid:96)1-minimization, and
then the SAE is calculated.

Fig. 2: Example of normal, S-type, and V-type ECG signals from patient 100,
and their sparse approximation errors. From 2d it is clear that both types of
abnormal beats have noticeably large SAE compared to a normal beat.

Fig. 3: Sparse codes calculated through (cid:96)1 and (cid:96)2 minimization for a normal
ECG beat and a dictionary with n = 20 atoms.

B. Classiﬁcation by Least-Squares Approximation as An

Alternative Solution

Indeed, SAE-based classiﬁcation is a special case of the
well-known sparse representation-based classiﬁcation (SRC)
[41]. The original SRC targets a multi-class classiﬁcation
problem. After SRC gained popularity, the authors of [42]
proved that in many multi-class classiﬁcation problems, simi-
lar classiﬁcation performance to SRC can be achieved by using
(cid:96)2 regularization instead of (cid:96)0 or (cid:96)1. The approach is called
Collaborative Representation based Classiﬁcation (CRC) and
can signiﬁcantly reduce the computational complexity com-
pared to SRC.

By adopting a similar strategy, we can swap the l1 term
2 to get the ridge formulation of the

in Eq. (6) with λ (cid:107)xp

i (cid:107)2

problem, and solve it using the method of regularized least
squares:

(cid:98)xp
i =

(cid:16)

(cid:124)

DpT Dp + λIN ×N

(cid:17)−1

(cid:123)(cid:122)
Lp

sp
i

DpT
(cid:125)

(9)

(cid:16)

(cid:17)−1

i − sp

DpT Dp + λIN ×N

DpT and λ is a small
where Lp =
positive scalar. Having the estimation (cid:98)xp
i , the Least-Squares
Approximation Error (LAE) can be calculated easily as
(cid:101)e(cid:96)2 = Dp ˆxp
i . We will show that LAE and NPE require
signiﬁcantly less computational cost when compared to SAE,
and provide almost identical classiﬁcation results with the
simple thresholding-based classiﬁer. In Figure 3, an example
pair of estimated representation coefﬁcients with (cid:96)1 and (cid:96)2
regularizes are given respectively. Although, (cid:96)1-minimization
can provide a slightly sparser (more ideal) estimation of rep-
resentation coefﬁcient vector, the energy of the representation
errors (SAE, LAE) are almost identical for this speciﬁc task.
Complexity Analysis: Given the pre-constructed annihilator
matrix, F p ∈ R(N −n)×N , and a single ECG beat, sp
i ∈ RN ,
the NPE can be calculated through matrix-vector multipli-
cation. Thus,
the exact number of required ﬂoating-point
operations (FLOPs) for calculating the NPE is TNPE(N, n) =
2 · N · (N − n) FLOPs.

When calculating the LAE, as Dp is calculated beforehand,
we can pre-construct Lp deﬁned in Eq 9. Then, the Least-
Squares Approximation Error (LAE) is expressed as,

(cid:101)e(cid:96)2 = sp

i − DpLpsp
i ,

(10)

which involves a matrix-vector multiplication of Lp ∈ Rn×N
and sp
i ∈ RN , followed by another matrix-vector multiplica-
tion of Dp ∈ RN ×n and the intermediate result, and ﬁnally
a subtraction with the original signal. Thus, the computa-
tional complexity of calculating the LAE is TLAE(N, n) =
(4 · n + 1) · N FLOPs. It
is worth noting that one could
also pre-construct IN ×N − DpLp in Eq. (10) and cal-
culate LAE with a single matrix-vector multiplication, i.e.,
(cid:101)e(cid:96)2 = (IN ×N − DpLp). In that case, the computational
complexity would be TLAE(N ) = 2 · N 2 FLOPs. The more
suitable approach can be chosen depending on N and n,
and the computational platform. Although the ﬁrst approach
may require fewer FLOPs, the second approach may be more
efﬁcient when it comes to computation time since all the inner
products can be computed in a parallel manner.

As multiple factors play a role in the number of FLOPs
needed to calculate the SAE, such as the sparse recovery
algorithm and the number of iterations, calculating the exact
number of FLOPs is more challenging. In [20], OMP was
used to ﬁnd sparse codes, following which these sparse codes
were used to estimate the sparse approximation error, i.e.,
(cid:101)e(cid:96)1 = Dp ˆxp
i . In their algorithm, the authors of [20]
also ﬁx the number of non-zero coefﬁcients of ˆxp
to a
i
predetermined number (e.g., k = 5). In this way, the number
of iterations in the OMP algorithm is ﬁxed, therefore the
number of FLOPs required for OMP can be approximated as
2 · N · k · (k + 1.5) + 2 · k · n · (N + 1). Having the sparse
codes, SAE can be calculated in (2 · n + 1) · N FLOPs. In

i − sp

JULY 2022

6

Error AUC
SAE

Complexity (FLOPs)

0.97019 ≈ 2 · N · k · (k + 1.5) +

2 · k · n · (N + 1) + (2 · n + 1) · N

0.96993 2 · N · (N − n)

NPE
LAE 0.97002 (i) 2 · N 2 or (ii) (4 · n + 1) · N

TABLE II: Number of FLOPs needed for calculating different approximation
errors.

Error CPU Runtime (µs) GPU Runtime (µs)
SAE
NPE
LAE (1)
LAE (2)
CNN

11.6808
0.1032
0.1062
0.1196
9.0496

4.7933
0.2047
0.2498
0.2133
21.0028

TABLE III: The processing time of a single ECG beat for the discussed
methods on an i7-10870H CPU and an RTX 3080 Laptop GPU. The
measurements are averaged over 10 runs and 1000 beats.

Tables II and III, the number of required FLOPs for different
approximation errors and their execution times are listed.

When a simple thresholding algorithm is applied to the
energy of these error vectors, namely SAE, NPE, and LAE,
they result in almost the same AUC performance. Among
them, for the rest of the paper, we prefer NPE achieves
the lowest computational complexity especially when parallel
processing units are available.

C. Sparse Representation Based Domain Adaptation

As it has been mentioned several times in past studies,
ECG morphology differs between individuals depending on
their cardiovascular systems [6]. This is why recent research
on biometrics of ECG signals has gained popularity [7], [8].
The authors of [14] studied how a normal heartbeat signal
can be transformed into an abnormal one, and found that this
transformation can be approximated with a linear transforma-
tion. Using this work as an inspiration, we investigate for the
ﬁrst time in the literature the relationship between the ECG
morphology of user l and p. In the sequel, we will demonstrate
that such a relationship can also be modeled accurately enough
with a linear transformation.

i, we want the transformed beat (cid:98)sl

Regardless of whether it is an anomaly or not, when an
ECG heartbeat signal sl
i of user l is linearly transformed,
i.e, (cid:98)sl
i = Ql→psl
i to have
the same morphology as the real ECG beats of user p. We
would like to emphasize that this morphology transformation
matrix (MTM), Ql→p ∈ RN ×N , pertains speciﬁcally to the
transition from the ECG heartbeat domain of user l to the one
of user p. Such a transformation system is illustrated in Figure
4.

Such transformation matrices are challenging to learn since
there are only a limited number of healthy beats with no
abnormal data available for user p. This may lead any learning
algorithm to overﬁt
to this small number of samples. If
we consider the concept of the sparse representation-based
dictionary learning as shown in Eq. (7), we should assume

that when a set of real heartbeats, Sp, belonging to user p
arrive, this set will be represented in a profound (as a result
of dictionary learning deﬁned in Eq. (7)) dictionary Dp with
relatively small errors in representation. Nonetheless, as shown
in Figure 5a, if we acquire a new set of healthy signals, Sl,
belonging to a different user such as user l, we can assume
that this set will not be well represented in the dictionary of
user p despite the absence of abnormal beats.

Linear
Transformation
System

N l

Al

N l

Ql→p( )

User l

N p

Ap

N p

User p

Fig. 4: Linear Morphology Transformation System.

Fig. 5: The histogram of sparse approximation errors of normal beats of users
p and l on user p’s dictionary, Dp. (cid:101)e(cid:96)1 for l is high even for normal beats on
Dp (upper), whereas after domain adaptation the error energy more closely
resembles the ones of p (lower).

Based on the discussion above, we formulate our MTM
learning problem as ﬁnding a transformation matrix, Ql→p ∈
RN ×N , which results in the Sl being sparsely represented in
Dp after transformation:

ˆQl→p, ˆX l = arg min
Ql→p, X l

(cid:107)Ql→pSl − DpX l(cid:107)2
2

+ λ(cid:107)X l(cid:107)1 + γ(cid:107)Sl − Ql→pSl(cid:107)2
2

(11)

where λ and γ are positive hyper-parameters and the last term,
γ(cid:107)Sl − Ql→pSl(cid:107)2
2, is a trade-off term. For large values of γ,
it ensures that (cid:98)Sl does not deviate much from Sl. For small
values of γ, (cid:98)Sl ﬁts better onto dictionary Dp. Without the last
term, or for γ = 0, Eq. (11) has a trivial minimum at X l = 0
and Ql→p = 0. In other words, Eq (11) solves for a mapping
that compromises between projecting the signal onto subspace
Dp and remaining close to the original signal.

In order to solve the problem deﬁned in Eq. (11), we follow
an iterative optimization strategy: Given Dp and Sl at each
iteration, ﬁrst, the current solution for Ql→p is ﬁxed and the

JULY 2022

7

sparse codes X are estimated; then, the solution for X is ﬁxed
and Ql→p is updated. We would like to remind that the ECG
beats and dictionary atoms are always normalized to have unit
energy, i.e., (cid:13)
(cid:13)(cid:98)sl
i
At each iteration, given the current solution Ql→p, each
i in the set Sl is linearly projected onto Ql→p, i.e.,
i, and then normalized. In order to estimate X,

signal sl
i = Ql→psl
(cid:98)sl
Eq. (11) can be reduced to

(cid:13) = (cid:107)di(cid:107) = (cid:13)
(cid:13)

(cid:13)
(cid:13) = 1.

(cid:13)sl
i

ˆX l ← arg min

X l

(cid:13)
(cid:13)

(cid:13) (cid:98)Sl − DpX l(cid:13)

2
(cid:13)
(cid:13)
2

+ λ (cid:13)

(cid:13)X l(cid:13)

(cid:13)1 .

(12)

Then, for a ﬁxed X, the optimization problem in Eq. (11) is
recast as

ˆQl→p = arg min
Ql→p

(cid:107)Ql→pSl − DpX l(cid:107)2
2

+ γ(cid:107)Sl − Ql→pSl(cid:107)2
2.

(13)

The function to be minimized in Eq. (13) is a quadratic
function. Even though the closed-form solution is available,
we updated the solution with gradient descent steps in order to
prevent undesirable jumps. The overall pseudocode to estimate
domain adaptation or morphology transformation matrix is
given in Algorithm 1. In Figure 5b we show the representation
errors of the transformed set of healthy signals of user l on
Dp.

Algorithm 1 SR-based MTM Finding Algorithm

1: procedure DOMAIN ADAPTATION(Dp, Sl, γ, η, epochs)
2:
3:
4:

Ql→p ← IN ×N
for i ← 1 to epochs do
(cid:98)Sl ← Ql→pSl
i ← (cid:98)sl
i
(cid:98)sl
(cid:13)
(cid:13)
(cid:13)(cid:98)sl
(cid:13)2
(cid:13) (cid:98)Sl − DpX l(cid:13)
X l ← arg min
∇Ql→p ← ((1 + γ) Ql→p − γIN ×N ) SlSlT

(cid:46) Domain Adaptation

(cid:46) Normalization

(cid:13)X l(cid:13)
(cid:13)1

+ λ (cid:13)

2
(cid:13)
(cid:13)
2

(cid:13)
(cid:13)

X l

i

5:

6:

7:

− DpX lSlT

Ql→p ← Ql→p − η∇Ql→p

8:
9:
10:
11: end procedure

end for
return Ql→p

D. Ensemble Learning

In Sections III-A and III-B, we explain two different
methods to efﬁciently calculate approximation errors for ECG
signals. In [20], Carrera et al. show that approximation errors
can be used to classify normal and abnormal heartbeats by
thresholding. However, in their work the threshold must be
determined experimentally, thus they report the AUC of their
method’s Receiver Operating Characteristic (ROC) curve. We
propose a probabilistic method to determine the classiﬁcation
threshold automatically from the generated training data for
a speciﬁc user (the dataset generation will be explained in
Section IV-C). First, we calculate the NPE for normal and

abnormal beats as described in Section III-A. Then, we esti-
mate the parameters of two probability distributions that model
the normal and abnormal errors using maximum likelihood
estimation (MLE). Finally, during testing, we calculate the
likelihood of the test signal’s NPE belonging to one of the
two distributions, and classify it to the one with the higher
likelihood. Instead of solely depending on this system for ECG
classiﬁcation, however, we train a 1-D CNN classiﬁer for each
user, and consult this probabilistic classiﬁer only when the
CNN’s conﬁdence level is low. By doing so, we create an
ensemble classiﬁer.

IV. RESULTS

A. Experimental Setup

In our experiments, we used the ECG data from the bench-
mark MIT-BIH arrhythmia database [43], [44]. The database
consists of two-channel ECG records from 48 different pa-
tients. Each record is approximately half-hour long with beat
labels for different types of heartbeats.

We set each beat to be represented by 128 samples by
resampling it. In the literature, there are two common ways of
representing a beat: a single beat and a beat-trio. In both repre-
sentations, the central R-peak is considered to be the reference
point for the given beat. To get the single beat representation,
we ﬁnd the adjacent R-peaks and move 10% inwards towards
the central peak, extract that segment and resample to 128
samples. To capture the temporal morphological characteristics
of the beats, we construct a beat-trio. To get the beat-trio
representation, we again ﬁnd the adjacent R-peaks but now
move 10% outwards, thus the segment includes the adjacent R-
peaks. Examples of single beat and beat-trio pairs are plotted
in Figure 7. We use the annotations provided by the MIT-
BIH database to locate any R-peaks, but for cases where peak
locations are not readily available, many automated robust
QRS detection algorithms have been proposed [45], [46].

Similar to the experimental setup in [14], in this study
the Association for the Advancement of Medical Instrumen-
tation (AAMI) recommendations [47] are followed: AAMI
categorizes heartbeat types as N (beats occurring in the si-
nus mode), V (ventricular ectopic beats), S (supraventricular
ectopic beats), F (fusion beats) and Q (uncategorizable beats).
In this study, we considered N beats as normal beats and
the other 4 types as abnormal beats. Among the 48 patient
records in the MIT-BIH arrhythmia database, 34 records are
used. Patients 102, 104, 107, 217 are excluded because their
records come from a pacemaker. Patients 105, 114, 201, 202,
207, 209, 213, 222, 223, and 234 are excluded as they show
high variations among their beats. In order to comply with the
AAMI recommendation, when training an individual user’s
classiﬁer, only normal heartbeats recorded within the ﬁrst ﬁve
minutes are included in the training data, and any abnormal
beats are excluded. This small set of normal heartbeats is
then combined with the datasets of the remaining 33 users
according to the algorithms described in Section IV-C (e.g.,
with/without domain adaptation, ABS, etc.). The abnormal
beats from the ﬁrst ﬁve minutes and the beats in the remaining
twenty-ﬁve minutes make up that user’s test data.

JULY 2022

8

Fig. 6: CNN architecture used in all experiments. K is the ﬁlter size, and N is the number of neurons in the layer.

Performance of the proposed and competing methods are

assessed using the following metrics:

F1-Score = 2 ·

Precision · Recall
Precision + Recall
TN
TN + FP
TP
TP + FP

,

,

Speciﬁcity =

Precision =

Recall =

TP
TP + FN

,

,

(14)

(15)

(16)

(17)

where a positive response corresponds to an abnormal beat,
and true positives (TP), true negatives (TN), false positives
(FP), and false negatives (FN) are computed from the predicted
and ground-truth binary labels. We used the macro-average
method for overall tables unless otherwise noted. In some
speciﬁc cases, we analyzed user-speciﬁc performance metrics.

B. SAE vs NPE-based Anomaly Detection

Fig. 7: Single normal heartbeat and a beat-trio.

For our ﬁrst experiment, we consider only the sparse
representation-based classiﬁer with the aforementioned meth-
ods to obtain representation errors, namely SAE, NPE, and
LAE. The dictionary for each user is constructed using only
the healthy beats from their ﬁrst ﬁve minutes of recording.
In all our experiments, we used N = 128, n = 20, which is
experimentally observed as slightly the best setup. In the test
case, the energy of the representation error is calculated in
three different ways: SAE, NPE, and LAE. Then, a predeﬁned
threshold is applied to decide whether the signal is abnormal
or not. There is no question that the threshold chosen will
affect the receiver operating characteristic of the classiﬁer. As
mentioned previously, ECG beats used for both training and
testing are normalized to have unit energy. We can clearly
see from Figure 8 that the behavior of the F1 curve is almost
identical for SAE, NPE, and LAE when we draw the F1-Score
for thresholds in the interval [0, 1].

Fig. 8: F1-Score with different thresholds for different representation error
calculation techniques.

JULY 2022

9

Method
CNN
Kiranyaz et al. [9] (cid:5)
Zhai et al. [12] (cid:5)
Li et al. [13]
GAN
Zhou et al. [35] (cid:5) ∗
Shaker et al. Two-stage [31]
Shaker et al. End-to-end [31]
SR-based (cid:5) ∗
SAE-based
NPE-based (ours)
CNN (cid:5) ∗
ABS [14]
Baseline (ours)
Domain Adaptation (ours)
Ensemble (ours)
Ensemble (avg.) (ours)
Energy-efﬁcient (40%) (ours)

Accuracy

Speciﬁcity

Precision

Recall

F1-Score

0.959
0.968
0.920

0.979
0.986
0.987

0.947
0.947

0.977
0.965
0.978
0.982
0.981
0.973

0.971
0.976
0.918

0.989
0.988
0.990

0.968
0.968

0.995
0.987
0.987
0.988
0.988
0.990

0.842
0.879
0.628

0.908
0.886
0.901

0.779
0.779

0.956
0.899
0.911
0.919
0.918
0.920

0.888
0.920
0.933

0.897
0.964
0.959

0.794
0.794

0.825
0.809
0.907
0.937
0.926
0.859

0.864
0.899
0.751

0.902
0.924
0.929

0.786
0.786

0.886
0.852
0.909
0.928
0.922
0.888

TABLE IV: Comparison of ABS [14], NPE-based (ours), Baseline (ours), Domain Adaptation (ours), Ensemble Classiﬁcation (ours), and Energy-efﬁcient
Classiﬁcation (ours) methods. The classiﬁcation performance of former studies, including global and one-shot classiﬁers, are presented. The results show that
our personalized zero-shot ensemble classiﬁer surpasses in F1-Score all the other methods, and is on-par with [31], even though [31] is a global one-shot
GAN-based classiﬁer with a signal size of 300 (as opposed to 128). The conﬁdence threshold for the ensemble classiﬁer is chosen using the validation set.
The average ensemble classiﬁer results show the average over all possible conﬁdence thresholds.
(cid:5) Personalized classiﬁers.
* Zero-shot classiﬁers.

C. 1-D CNN Classiﬁer with Baseline vs ABS vs SR-based

Domain Adaptation

To build personalized classiﬁers for every user, we choose
the SOTA classiﬁer for ECG anomaly detection described in
[14] and train it with user-speciﬁc training data. Following the
recommendations of AAMI, only the normal heartbeats from
the ﬁrst ﬁve minutes of the recording are included in that user’s
training data. After that, this small dataset of normal signals
is combined with both normal and abnormal signals of other
users using three different strategies:

(i) Baseline Method: The normal heartbeat dataset of user p
is directly combined with the dataset of other users including
both normal and abnormal signals without any changes (other
than a standard normalization). Speciﬁcally, all of the abnor-
mal signals for the remaining 33 users are added along with
some of their healthy signals so that the number of abnormal
beats is equal to the number of normal beats.

(ii) Abnormal Beat Synthesis: The normal heartbeat dataset
of user p is combined with the abnormal beat synthesis
technique explained in detail in Section II-B.

(iii) Sparse Representation Based Domain Adaptation: The
proposed sparse representation-based domain adaptation tech-
nique is applied to the training dataset explained in the baseline
method. As such, when creating the training dataset of user p,
33 different MTMs are estimated that transform the beats of
each registered user l to user p. The MTMs are applied to both
normal and abnormal beats of the registered users. The results
presented here use γ = 0.2 with a learning rate of 0.002 and
25 steps.

As a classiﬁer, we use a 1-D CNN with 3 convolutional
layers followed by 2 fully-connected layers. The convolutional

layers have a kernel size of 7, no padding, and a stride of
1. Each convolutional layer is followed by a max-pooling
layer with a stride of 3, and a hyperbolic tangent activation
function. The ﬁrst fully-connected layer has a rectiﬁed linear
unit activation function, and the ﬁnal layer has a log-softmax
activation. The number of neurons per layer is 32, 16, 16,
and 32 respectively and the ﬁnal (output) layer has 2 neurons,
one for each class. A diagram of the network structure can
be found in Figure 6. We used the same network structure for
ABS and the proposed domain adaptation based training data
generator in order to make a fair comparison. The training
and assessment of the model are performed as follows. First,
the datasets are generated per patient for both single and beat-
trio beat representations, using the baseline method and our
domain adaptation method. These datasets are then split into
training and validation datasets with an 80% training ratio.
Then, single beats and beat-trios are fed together as two-
channel inputs to the CNN. We used cross-entropy loss and the
weight-decayed Adam optimizer [48] to update the weights.
The model keeps training until 15 epochs have passed without
improving the validation loss. The weights that achieve the
lowest validation loss are then used for evaluation. We average
our results over 10 independent training runs to minimize the
effect of the randomly initialized parameters.

As it can be seen in Tables IV and VI the proposed domain
adaptation method vastly improves the baseline approach and
surpasses the abnormal beat generation strategy in terms of re-
call and F1-Score. We show that domain adaptation can greatly
enhance arrhythmia detection, resulting in a fewer number
of missed arrhythmia beats. Moreover, domain adaptation is
especially effective for patients with normal beats that are

JULY 2022

dissimilar to that of other patients’ normal beats. The AAMI
standard classiﬁes normal beats (N), left bundle branch block
beats (L), right bundle branch block beats (R), atrial escape
beats (e), and nodal (junctional) escape beats (j) as normal
beats. However, those beats may show variations among them,
to the extent that the normal beats of user p are very distinct
from the normal beats of user l, as shown in Figure 9.

Ground Truth

d
e
t
c
i
d
e
r
P

A

N

A

N

A 3361

185

A 9054

218

N 10449

2965

N 4756

2932

TABLE V: Confusion matrices for patient 232, obtained with the Baseline
(left) and Domain Adaptation (right) methods, accumulated over 10 indepen-
dent training runs. A = Abnormal, N = Normal.

Ground Truth

d
e
t
c
i

d
e
r
P

A

N

A

N

A 64447

7210

A 72212

7065

N 15183 557070

N

7418

557215

TABLE VI: Confusion matrices of the Baseline (left) and Domain Adapta-
tion (right) methods, accumulated over 10 independent training runs. A =
Abnormal, N = Normal.

The maximum likelihood estimate for the parameter β is

(cid:98)β = arg max

β

n
(cid:89)

i=1

1
β

e−xi/β =

(cid:80)n

i=1 xi
n

,

10

(19)

which is the sample mean. Similarly, the PDF of the Gaussian
distribution is

f (x; µ, σ) =

1
√
2π

σ

2 ( x−µ

σ )2

e− 1

,

(20)

and the maximum likelihood estimate for the parameters µ
and σ are

(cid:98)µ =

1
n

n
(cid:88)

i=1

xi,

(cid:98)σ =

(cid:118)
(cid:117)
(cid:117)
(cid:116)

1
n

n
(cid:88)

i=1

(xi − µ),

(21)

which are the sample mean and sample standard deviation
respectively.

At test time, the CNN output is passed through the softmax
function instead of log-softmax. Then, we choose the greater
neuron output as the conﬁdence of the CNN. If the conﬁdence
is above some threshold, C, then the network output is used
for classiﬁcation. Otherwise, the NPE of the test sample is
calculated and the probabilistic model is used for classiﬁcation.
Evidently, if C ≤ 0.5, then only the CNN is used, and if
C ≥ 1, only the probabilistic model is used. We choose C as
the conﬁdence that maximizes F1-Score in the validation set.
In the case of equally performing conﬁdences, we choose the
greater conﬁdence. Though, in Figure 10, we show that any
choice of C results in a performance improvement.

Fig. 9: A set of R-type healthy beats and N-type healthy beats from patients
232 and 100, respectively. This set of R-type beats has distinct morphological
differences from N-type beats.

D. Ensemble Classiﬁcation

After the CNN is trained, we estimate the parameters of the
probabilistic model as described in Section III-D. For all of our
experiments, we model the normal NPEs with an exponential
distribution, and abnormal NPEs with a Gaussian distribution.
The probability density function (PDF) of the exponential
distribution is

f (x; β) =

(cid:40) 1

β e−x/β x ≥ 0
x < 0
0

.

(18)

Fig. 10: F1-Score for all possible values of conﬁdence level threshold. Values
too close or equal to 1 force the system to use the simple representation
error-based classiﬁer, thus achieving lower F1-Scores.

In Table IV, a comprehensive analysis on the comparison
of different algorithms is done. Among competing algorithms,
only ABS [14], SAE [20], a GAN-based ECG generation
study [35], and the variants of the proposed algorithms are
personalized zero-shot methods. The comparison is made
among only personalized zero-shot methods which are marked
with (cid:5) ∗. In addition to personalized zero-shot methods, the
table includes a few SOTA CNN-based algorithms [9], [12],
[13], as well as a SOTA GAN-based technology [31]. Among

JULY 2022

11

NPE and the suspicious ones can be ﬁltered out to be analyzed
through the proposed approach. The proposed energy-saving
ECG monitoring scheme is illustrated Figure 12.

Figure 11 shows that up to 40% of all the 64391 samples in
the test dataset can be classiﬁed solely based on NPE without
sacriﬁcing signiﬁcantly from the F1 performance.

Fig. 11: Energy efﬁciency over F1-Scores, where the x-axis shows the
percentage of test samples that are classiﬁed solely based on NPE, hence
being more computationally efﬁcient.

them, CNN-based algorithms are trained person-speciﬁc or
globally, and GAN-based one is one of the aforementioned
SOTA algorithms that tackle data imbalance problems. Those
algorithms rely on the abnormal dataset of a given patient,
partly or completely. Therefore, they cannot be directly com-
pared to the personalized zero-shot methods.

The baseline method can be considered as the one where
a person-speciﬁc network is trained in a personalized manner
by using the global dataset excluding the abnormal data of
the person of interest. Due to the variation in hearth beat
morphology across users, such a vanilla approach has limited
performance, as can be seen in Table IV. This is especially
true for users whose healthy (normal) heartbeat morphology
differs signiﬁcantly from the majority of users. We examine
patient 232 from the MIT-BIH dataset as an example. As
can be seen from Table V that the proposed algorithm can
signiﬁcantly improve the performance of personalized zero-
shot classiﬁcation performance.

As can be seen in Table IV, our ensemble classiﬁer greatly
improves our domain adaptation method and achieves the best
accuracy, recall, and F1-Score among all methods, improving
recall by over 11% and F1-Score by over 4% compared to
ABS [14]. The overall confusion matrix associated with the
proposed solution can be found in Table VII. As mentioned
in Section IV-D, the ’conﬁdence level’ threshold determines
which classiﬁer is to be used. This threshold is determined
from the validation set
in a completely zero-shot manner
over the generated abnormal beats. However, any choice of
this threshold makes the proposed approach outperform all
to competing algorithms as shown in Figure 10. In Table
IV we also include the average performance for 50 different
thresholds selected uniformly in the interval [0.50, 0.99].

Ground Truth

Fig. 12: Overall system model of the energy-saving ECG monitoring scheme.

d
e
t
c
i

d
e
r
P

A

N

A

N

A 73759

6577

A 74618

6590

N

5871

557703

N

5012

557690

TABLE VII: Confusion matrices of the Ensemble Classiﬁer averaged over all
C (left) and C chosen from the validation set (right), accumulated over 10
independent training runs. A = Abnormal, N = Normal.

V. A PRACTICAL ECG MONITORING SCHEME WITH
ENERGY-SAVING MECHANISM

Continuous cardiac monitoring on wearable devices has the
potential to increase early diagnosis, provide personalized care,
and reduce the risk of sudden cardiovascular issues. However,
on-device neural network-based solutions or wireless trans-
mission for off-device arrhythmia detection may be energy
inefﬁcient to be continuously employed on mobile wear [20],
[49]. Thus, in this section, we describe an energy-preserving
ECG monitoring scheme for use in wearable devices.

The idea is that a signiﬁcant number of normal beats can be
classiﬁed with very high conﬁdence using simple and energy
efﬁcient NPE or LAE techniques. In this manner in a practical
continuous monitoring system, beats can be ﬁrst classiﬁed with

VI. DISCUSSION

A. How Does Representation Based Anomaly Detection
Differ from Representation Based Classiﬁers (Sparse and
collaborative Representations)?

The conventional representation-based (dictionary-based)
classiﬁcation schemes include a pre-established linear repre-
sentation dictionary that contains sub-dictionaries that each
store representation atoms that correspond to a speciﬁc class.
After a test query sample has been received, the representation
coefﬁcient x is estimated either by (cid:96)1-minimization or by
the regularized least-squares. If it is estimated with sparse
recovery algorithms such as (cid:96)1-minimization, the method is
referred to as sparse representation-based classiﬁcation (SRC
[41] ); likewise, if it is estimated by the least-squares solution,
the method is called collaborative representation (CRC [42]).
Indeed, both SRC and CRC are collaborative representation
methods since the representation coefﬁcient vector is calcu-
lated over an overall dictionary instead of using class-speciﬁc
sub-dictionaries [42]. The problem of anomaly detection with-
out the abnormal data during the training phase is a one-
class classiﬁcation problem, in which the dictionary contains

JULY 2022

12

representative atoms for one class only, therefore it cannot be
categorized as a collaborative representation.

B. Limitations and Future Work

This paper provides a complete pipeline of continuous
ECG monitoring for the following realistic scenario: A new
user is registered to the (monitoring) system, and only a
few minutes of normal (healthy) beats are acquired for a
continuous monitoring afterwards. The pipeline consists of
person-speciﬁc calibration of the algorithm and a strategy to
improve the battery life span by only choosing the suspicious
beats to be analyzed using the proposed approach. The person-
alized zero-shot anomaly detection was considered only in a
few prior works, and our sparse representation-based domain
adaption signiﬁcantly improves the SOTA performance. For
a fair comparison, we use the same network structure which
was used in the competing SOTA algorithm. In that way, we
proved that the proposed realistic data generation technique
is highly efﬁcient. As a near-feature plan, more advanced
network structures will be investigated. For the ﬁrst time in this
study, we provide a complete scheme with energy-efﬁcient pre-
ﬁltering of the suspicious beats. We use the left null space basis
as a simple projection matrix and achieve up to %40 reduction
in the overall complexity. Therefore, this serves as the pilot
study; however, we believe that there is still room to improve
both the performance and the computational efﬁciency. For this
purpose, we will be investigating more advanced projection
matrices.

VII. CONCLUSION

In this paper, we have addressed the problem of zero-
shot personalized abnormal heartbeat detection through sparse
coding, domain adaptation, and various deep learning methods.
We have achieved signiﬁcant computational improvements (up
to 20 times) for representation-based classiﬁcation without any
performance drawbacks. Additionally, we proposed a baseline
method for the classiﬁer without requiring the abnormal beats
of the (new) user, and introduced a sparse-representation
based domain adaptation method that drastically improves the
classiﬁcation performance over the baseline method. On top of
that, our work introduces an ensemble classiﬁer that consults
a probabilistic classiﬁer based on NPE when the personalized
is below a certain threshold. We
CNN’s conﬁdence level
demonstrated that the ensemble classiﬁer is vastly superior
to all of the methods described in our work. Finally, by
utilizing the computational efﬁciency of representation-based
classiﬁcation together with our compact and robust CNN
classiﬁer, we proposed an energy-efﬁcient online monitoring
scheme for wearable devices.

REFERENCES

[1] C. J. Murray, A. Y. Aravkin, P. Zheng, C. Abbafati, K. M. Abbas,
M. Abbasi-Kangevari, F. Abd-Allah, A. Abdelalim, M. Abdollahi,
I. Abdollahpour et al., “Global burden of 87 risk factors in 204 countries
and territories, 1990–2019: a systematic analysis for the global burden
of disease study 2019,” The Lancet, vol. 396, no. 10258, pp. 1223–1249,
2020.

[2] K.-i. Minami, H. Nakajima, and T. Toyoshima, “Real-time discrim-
ination of ventricular tachyarrhythmia with fourier-transform neural
network,” IEEE transactions on Biomedical Engineering, vol. 46, no. 2,
pp. 179–185, 1999.

[3] S. Osowski, L. T. Hoai, and T. Markiewicz, “Support vector machine-
based expert system for reliable heartbeat recognition,” IEEE transac-
tions on biomedical engineering, vol. 51, no. 4, pp. 582–589, 2004.
[4] J. L. Willems and E. Lesaffre, “Comparison of multigroup logistic and
linear discriminant ecg and vcg classiﬁcation,” Journal of electrocardi-
ology, vol. 20, no. 2, pp. 83–92, 1987.

[5] R. Hoekema, G. J. Uijen, and A. Van Oosterom, “Geometrical aspects
of the interindividual variability of multilead ecg recordings,” IEEE
Transactions on Biomedical Engineering, vol. 48, no. 5, pp. 551–559,
2001.

[6] M. Merone, P. Soda, M. Sansone, and C. Sansone, “Ecg databases
for biometric systems: A systematic review,” Expert Systems with
Applications, vol. 67, pp. 189–202, 2017.

[7] R. D. Labati, E. Mu˜noz, V. Piuri, R. Sassi, and F. Scotti, “Deep-ecg:
Convolutional neural networks for ecg biometric recognition,” Pattern
Recognition Letters, vol. 126, pp. 78–85, 2019.

[8] N. Ibtehaz, M. E. Chowdhury, A. Khandakar, S. Kiranyaz, M. S.
Rahman, A. Tahir, Y. Qiblawey, and T. Rahman, “Edith: Ecg biometrics
aided by deep learning for reliable individual authentication,” arXiv
preprint arXiv:2102.08026, 2021.

[9] S. Kiranyaz, T. Ince, and M. Gabbouj, “Real-time patient-speciﬁc ecg
classiﬁcation by 1-d convolutional neural networks,” IEEE Transactions
on Biomedical Engineering, vol. 63, no. 3, pp. 664–675, 2016.
[10] P. de Chazal and R. B. Reilly, “A patient-adapting heartbeat classiﬁer us-
ing ecg morphology and heartbeat interval features,” IEEE transactions
on biomedical engineering, vol. 53, no. 12, pp. 2535–2543, 2006.
[11] W. Jiang and S. G. Kong, “Block-based neural networks for personalized
ecg signal classiﬁcation,” IEEE Trans. Neural Networks, vol. 18, no. 6,
pp. 1750–1761, 2007.

[12] X. Zhai and C. Tin, “Automated ecg classiﬁcation using dual heartbeat
coupling based on convolutional neural network,” IEEE Access, vol. 6,
pp. 27 465–27 472, 2018.

[13] F. Li, Y. Xu, Z. Chen, and Z. Liu, “Automated heartbeat classiﬁcation
using 3-d inputs based on convolutional neural network with multi-ﬁelds
of view,” IEEE Access, vol. 7, pp. 76 295–76 304, 2019.

[14] S. Kiranyaz, T. Ince, and M. Gabbouj, “Personalized monitoring and
advance warning system for cardiac arrhythmias,” Scientiﬁc Reports,
vol. 7, no. 1, p. 9270, 2017.

[15] E. J. Cand`es et al., “Compressive sampling,” in Proceedings of the
international congress of mathematicians, vol. 3. Madrid, Spain, 2006,
pp. 1433–1452.

[16] M. Yamac¸, M. Ahishali, A. Degerli, S. Kiranyaz, M. E. Chowdhury, and
M. Gabbouj, “Convolutional sparse support estimator-based covid-19
recognition from x-ray images,” IEEE Transactions on Neural Networks
and Learning Systems, 2021.

[17] M. Impi¨o, M. Yamac¸, and J. Raitoharju, “Multi-level reversible en-
cryption for ecg signals using compressive sensing,” in ICASSP 2021-
2021 IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP).

IEEE, 2021, pp. 1005–1009.

[18] H. F. Huang, G. S. Hu, and L. Zhu, “Sparse representation-based
heartbeat classiﬁcation using independent component analysis,” Journal
of medical systems, vol. 36, no. 3, pp. 1235–1247, 2012.

[19] S. M. Mathews, L. F. Polan´ıa, and K. E. Barner, “Leveraging a discrim-
inative dictionary learning algorithm for single-lead ecg classiﬁcation,”
in Biomedical Engineering Conference (NEBEC), 2015 41st Annual
Northeast.

IEEE, 2015, pp. 1–2.

[20] D. Carrera, B. Rossi, D. Zambon, P. Fragneto, and G. Boracchi, “Ecg
monitoring in wearable devices by sparse models,” in Joint Euro-
pean Conference on Machine Learning and Knowledge Discovery in
Databases. Springer, 2016, pp. 145–160.

[21] A. Adler, M. Elad, Y. Hel-Or, and E. Rivlin, “Sparse coding with
anomaly detection,” Journal of Signal Processing Systems, vol. 79, no. 2,
pp. 179–188, 2015.

[22] D. Carrera, B. Rossi, P. Fragneto, and G. Boracchi, “Online anomaly
detection for long-term ecg monitoring using wearable devices,” Pattern
Recognition, vol. 88, pp. 482–492, 2019.

[23] S. S. Chen, D. L. Donoho, and M. A. Saunders, “Atomic decomposition
by basis pursuit,” SIAM review, vol. 43, no. 1, pp. 129–159, 2001.
[24] Y. C. Pati, R. Rezaiifar, and P. S. Krishnaprasad, “Orthogonal matching
pursuit: Recursive function approximation with applications to wavelet
decomposition,” in Signals, Systems and Computers, 1993. 1993 Con-
ference Record of The Twenty-Seventh Asilomar Conference on.
IEEE,
1993, pp. 40–44.

JULY 2022

13

[48] I. Loshchilov and F. Hutter, “Decoupled weight decay regularization,”

arXiv preprint arXiv:1711.05101, 2017.

[49] H. Mamaghanian, N. Khaled, D. Atienza, and P. Vandergheynst, “Com-
pressed sensing for real-time energy-efﬁcient ecg compression on wire-
less body sensor nodes,” IEEE Transactions on Biomedical Engineering,
vol. 58, no. 9, pp. 2456–2466, 2011.

[25] M. Aharon, M. Elad, A. Bruckstein et al., “K-svd: An algorithm for
designing overcomplete dictionaries for sparse representation,” IEEE
Transactions on signal processing, vol. 54, no. 11, p. 4311, 2006.
[26] T. Golany and K. Radinsky, “Pgans: Personalized generative adversarial
networks for ecg synthesis to improve patient-speciﬁc deep ecg classiﬁ-
cation,” in Proceedings of the AAAI Conference on Artiﬁcial Intelligence,
vol. 33, no. 01, 2019, pp. 557–564.

[27] Y. Wang, L. Sun, and S. Subramani, “Cab: classifying arrhythmias
based on imbalanced sensor data,” KSII Transactions on Internet and
Information Systems (TIIS), vol. 15, no. 7, pp. 2304–2320, 2021.
[28] T. Golany, D. Freedman, and K. Radinsky, “Ecg ode-gan: Learning
ordinary differential equations of ecg dynamics via generative adver-
sarial learning,” in Proceedings of the AAAI Conference on Artiﬁcial
Intelligence, vol. 35, no. 1, 2021, pp. 134–141.

[29] T. Golany, K. Radinsky, and D. Freedman, “Simgans: Simulator-based
generative adversarial networks for ecg synthesis to improve deep
ecg classiﬁcation,” in International Conference on Machine Learning.
PMLR, 2020, pp. 3597–3606.

[30] P. Wang, B. Hou, S. Shao, and R. Yan, “Ecg arrhythmias detection using
auxiliary classiﬁer generative adversarial network and residual network,”
Ieee Access, vol. 7, pp. 100 910–100 922, 2019.

[31] A. M. Shaker, M. Tantawi, H. A. Shedeed, and M. F. Tolba, “Gener-
alization of convolutional neural networks for ecg classiﬁcation using
generative adversarial networks,” IEEE Access, vol. 8, pp. 35 592–
35 605, 2020.

[32] A. M. Delaney, E. Brophy, and T. E. Ward, “Synthesis of realistic ecg us-
ing generative adversarial networks,” arXiv preprint arXiv:1909.09150,
2019.

[33] N. Wulan, W. Wang, P. Sun, K. Wang, Y. Xia, and H. Zhang, “Generating
electrocardiogram signals by deep learning,” Neurocomputing, vol. 404,
pp. 122–136, 2020.

[34] F. Zhu, F. Ye, Y. Fu, Q. Liu, and B. Shen, “Electrocardiogram generation
with a bidirectional lstm-cnn generative adversarial network,” Scientiﬁc
reports, vol. 9, no. 1, pp. 1–11, 2019.

[35] Z. Zhou, X. Zhai, and C. Tin, “Fully automatic electrocardiogram clas-
siﬁcation system based on generative adversarial network with auxiliary
classiﬁer,” Expert Systems with Applications, vol. 174, p. 114809, 2021.
[36] E. J. Candes, “The restricted isometry property and its implications for
compressed sensing,” Comptes rendus mathematique, vol. 346, no. 9-10,
pp. 589–592, 2008.

[37] R. Tibshirani, “Regression shrinkage and selection via the lasso,” Jour-
nal of the Royal Statistical Society: Series B (Methodological), vol. 58,
no. 1, pp. 267–288, 1996.

[38] E. J. Candes and Y. Plan, “A probabilistic and ripless theory of
compressed sensing,” IEEE transactions on information theory, vol. 57,
no. 11, pp. 7235–7254, 2011.

[39] S. Boyd, N. Parikh, E. Chu, B. Peleato, J. Eckstein et al., “Distributed
optimization and statistical learning via the alternating direction method
of multipliers,” Foundations and Trends® in Machine learning, vol. 3,
no. 1, pp. 1–122, 2011.

[40] K. Engan, S. O. Aase, and J. H. Husoy, “Method of optimal directions
for frame design,” in 1999 IEEE International Conference on Acous-
tics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No.
99CH36258), vol. 5.

IEEE, 1999, pp. 2443–2446.

[41] J. Wright, A. Y. Yang, A. Ganesh, S. S. Sastry, and Y. Ma, “Robust
face recognition via sparse representation,” IEEE transactions on pattern
analysis and machine intelligence, vol. 31, no. 2, pp. 210–227, 2008.

[42] L. Zhang, M. Yang, and X. Feng, “Sparse representation or collaborative
representation: Which helps face recognition?” in 2011 International
conference on computer vision.

IEEE, 2011, pp. 471–478.

[43] G. B. Moody and R. G. Mark, “The impact of the mit-bih arrhyth-
mia database,” IEEE Engineering in Medicine and Biology Magazine,
vol. 20, no. 3, pp. 45–50, 2001.

[44] A. L. Goldberger, L. A. Amaral, L. Glass, J. M. Hausdorff, P. C.
Ivanov, R. G. Mark, J. E. Mietus, G. B. Moody, C.-K. Peng, and H. E.
Stanley, “Physiobank, physiotoolkit, and physionet: components of a
new research resource for complex physiologic signals,” Circulation,
vol. 101, no. 23, pp. e215–e220, 2000.

[45] J. Pan and W. J. Tompkins, “A real-time qrs detection algorithm,” IEEE
transactions on biomedical engineering, no. 3, pp. 230–236, 1985.
[46] C. Li, C. Zheng, and C. Tai, “Detection of ecg characteristic points using
wavelet transforms,” IEEE Transactions on biomedical Engineering,
vol. 42, no. 1, pp. 21–28, 1995.

[47] A. for the Advancement of Medical Instrumentation, “Recommended
practice for testing and reporting performance results of ventricular
arrhythmia detection algorithms.” Arlington, VA, 1987.

