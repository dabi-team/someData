2
2
0
2

y
a
M
4
2

]
E
S
.
s
c
[

1
v
8
8
3
2
1
.
5
0
2
2
:
v
i
X
r
a

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

1

DASP: A Framework for Driving the Adoption of
Software Security Practices

Enrique Larios-Vargas, Member, IEEE, Omar Elazhary, Soroush Youseﬁ, Derek
Lowlind, Michael L. W. Vliek, and Margaret-Anne Storey, Member, IEEE

Abstract—Implementing software security practices is a critical concern in modern software development. Industry practitioners,
security tool providers, and researchers have provided standard security guidelines and sophisticated security development tools to
ensure a secure software development pipeline. But despite these efforts, there continues to be an increase in the number of
vulnerabilities that can be exploited by malicious hackers. There is thus an urgent need to understand why developers still introduce
security vulnerabilities into their applications and to understand what can be done to motivate them to write more secure code. To
understand and address this problem further, we propose DASP, a framework for diagnosing and driving the adoption of software
security practices among developers. DASP was conceived by combining behavioral science theories to shape a cross-sectional
interview study with 28 software practitioners. Our interviews lead to a framework that consists of a comprehensive set of 33 drivers
grouped into 7 higher-level categories that represent what needs to happen or change so that the adoption of software security
practices occurs. Using the DASP framework, organizations can design interventions suitable for developers’ speciﬁc development
contexts that will motivate them to write more secure code.

Index Terms—Software security, Developer-centric security, Behavior change, Software security practices.

(cid:70)

1 INTRODUCTION

Software security is undeniably one of the most critical and
ongoing concerns in modern software development. In 2021,
the NIST Computer Security Division1 identiﬁed over 18,000
software vulnerabilities, and this number has been steadily
increasing from 2016 [1]. Flawed applications might behave
unpredictably, and these weaknesses are often abused by
malicious hackers [2]. For example, recent reports show that
malicious attackers use unique platforms and search engines,
e.g., Shodan2, to scan for networks that are exposed to known
vulnerabilities and exploit them before a victim can apply a
patch [3].

Software developers are responsible for many of these vul-
nerabilities. Notably, around 60% of vulnerabilities identiﬁed by
Veracode3 in a study of 130,000 active applications highlighted
that a developer’s lack of careful development and maintenance
was a signiﬁcant reason for the introduction of vulnerabilities.
These vulnerabilities occur because developers face pressure
to meet customer requirements and deliver features quickly.
In addition, they often treat security as a less important non-
functional requirement, typically not considering security until
the last stages of the software development life cycle. Often
security is not a concern unless security compliance is imposed
by employers or application users [43]. The delayed consider-

• E. Larios-Vargas, O. Elazhary, S. Youseﬁ, D. Lowlind, and M. A. Storey
are with the Department of Computer Science, University of Victoria,
Canada.
E-mail: elariosvargas@uvic.ca
• M. Vliek is with Leiden University.

Manuscript received April 19, 2005; revised August 26, 2015.

1. https://nvd.nist.gov/
2. https://www.shodan.io/
3. https://info.veracode.com/report-state-of-software-security-volume-

11

ation of security issues makes it more challenging and even
more expensive to address in later stages [41].

Neglecting software security is a well-recognized problem in
any industry. As a result, there are many ongoing efforts to ﬁx
it by leading cybersecurity organizations of different business
types, such as the MITRE corporation4, OWASP5, the CERT
Division6, and NIST7. These organizations provide security
standards and excellent resources to help practitioners ensure a
secure software product. There are also hundreds of free online
resources available for practitioners to learn software security
practices. Furthermore, there is a huge active community of
security professionals and researchers behind the development
of security tools and keeping up-to-date security guidelines
aimed at ensuring a secure software development life cycle.
However, despite the availability of these many resources,
developers continue to introduce security vulnerabilities in
source code, and organizations still lack proper guidelines for
designing strategies to mitigate poor security.

This situation pushes forward the need to properly under-
stand developer behaviors—speciﬁcally, what drives developers
to adopt software security practices. With this knowledge, orga-
nizations would be better positioned to design interventions to
foster behavior change, leading developers to write more secure
code. To understand developer behaviour towards the adoption
of security practices, we conducted a cross-sectional interview
study with a cohort of 28 software practitioners and used the
COM-B Model for behavior change [11] as a diagnosis tool
to understand the capabilities, opportunities, and motivations
behind the adoption of software security practices.

4. https://attack.mitre.org/
5. https://owasp.org/
6. https://www.sei.cmu.edu/about/divisions/cert/
7. https://www.nist.gov/

 
 
 
 
 
 
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

The insights from our study have led to a novel actionable
framework that organizations and developers can use to drive
the adoption of software security practices. The framework cap-
tures 33 drivers across seven categories of behavior change. In
addition, we exhaustively compared our ﬁndings with current
literature, noticing that previous research did not report three
of our drivers. Our framework can be used by organizations
to diagnose security challenges and to design strategies that
inﬂuence the adoption of security practices within their speciﬁc
context. This is the ﬁrst study that considers behavior change
in software security, opening the door for future research. Our
framework can support future researchers by leveraging the
power of well-known behavioral psychology theories to under-
stand and drive improvement in secure software development.
The following section (Section 2) provides some background
on the behavioral theories that shaped the design of our study.
Then we describe the cross-sectional interview methodology
and our analysis approach in Section 3. We present our ﬁndings
in Section 4,and review related work in Section 5. Next, we
discuss how organizations can use our framework in Section 6
and provide implications for developers, security specialists,
and researchers. In Section 7, we detail the threats to the
validity of our research and conclude the paper in Section 8.

2 BACKGROUND
Understanding human behavior is challenging due to the di-
verse number of psychological factors that may impact positive
and negative change. As a result, behavioral science disciplines,
such as psychology and behavioral economics, offer many
theories and models that describe drivers of behavior, such as
attitudes, motivations, norms, habits, and behavioral control.
Many of these theories and models can be further used to
predict human decision-making and behaviors (e.g., [5], [6],
[7], [8], [9], [10]). Similarly, it is a challenge to understand what
drives change in human behaviors in software development
activities such as software security, but doing so may help
organizations understand how to improve the adoption of
practices that will encourage developers to write more secure
code. In the following, we describe three behavioral theories
and models used to study behavior change. Later we discuss
how we used these theories to design our novel study of the
potential for behavior change in software security.

2.1 Behavioral Theories and Models

We present three behavioral theories and models: (1) the COM-
B model and the Behavior Change Wheel, (2) the Self-Efﬁcacy
Theory, and (3) the Response efﬁcacy concept.

2.1.1 The COM-B Model and The Behavior Change Wheel

Michie et al. proposed the Behavior Change Wheel (BCW) as
a synthesis of 19 different theories and models of behavior
change identiﬁed in a systematic literature review [11]. Some of
these frameworks suggest that behavior is primarily driven by
beliefs and perceptions, while others signiﬁcantly emphasize
unconscious biases or the social environment [12]. Figure 1
shows the BCW that aims to incorporate the standard features
of all these frameworks and link them to a model of behavior.
At the center of the BCW resides the COM-B model, shown
in Figure 2, which is composed of three vital conditions: capa-
bility (C), opportunity (O), motivation (M), and behavior (B).

2

Fig. 1. The Behavior Change Wheel: The green layer refers to the COM-
B model (sources of behavior), the blue layer represents the intervention
functions, and the grey layer refers to the policy categories.

The COM-B model provides a clear starting point to understand
behavior in a speciﬁc context, and guides the design and
development of interventions. For example, according to the
model, to engage in a particular behavior, someone must be
physically and psychologically capable, have the social and
physical opportunity, and be motivated to perform the target
behavior more than any other competing behaviors. In addition,
the model presents motivation from an automatic (habits) and
reﬂective (rational intentions) perspective.

Figure 1 depicts the COM-B model as the hub of the BCW;
it identiﬁes and explains the sources of the behavior, in other
words, what needs to happen or change so the target behavior
occurs. Surrounding the COM-B model, two extra layers repre-
sent 9 intervention functions that will help address any issue
identiﬁed in any of the COM-B model components (capability,
opportunity, or motivation). Subsequently, the external layer
comprises 7 policy categories that organizations can use to
deliver the intervention functions. For more details, Table 1
and Table 2 provide the landscape of intervention functions
and policy categories, including their respective deﬁnitions.

The COM-B model and the BCW have been applied in sev-
eral settings, from understanding behavior change by individ-
uals, to groups, sub-populations, and populations, and within
different organizations and systems [26]. For instance, Barker
et al. propose a successful application of the COM-B model
and the BCW to develop an intervention to promote regular,
long-term use of hearing aids by adults with acquired hearing
loss [13]. When applying the model, the investigation exposes
that behavioral planning for hearing-aid use on the side of
the audiologists should be part of the routine audiological
practice, which requires a complex intervention that addresses
psychological, capability, physical, and social opportunity, and
reﬂective and automatic motivation.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

3

TABLE 1
Intervention function deﬁnitions from the BCW.

Intervention function

Deﬁnition

Education
Persuasion
Incentivization
Coercion
Training

Restriction

Increasing knowledge or understanding
Using communication to induce positive or negative feelings or stimulate action
Creating an expectation of reward
Creating an expectation of punishment or cost
Imparting skills

Using rules to reduce the opportunity to engage in the target behaviour (or to
increase the target behaviour by reducing the opportunity to engage in competing
behaviours)

Environmental restructuring
Modeling

Changing the physical or social context
Providing an example for people to aspire to or imitate

Enablement

Increasing means/reducing barriers to increase capability (beyond education and
training) or opportunity (beyond environmental restructuring)

TABLE 2
Policy category deﬁnitions from the BCW.

Policy categories

Deﬁnition

Communication/marketing

Using print, electronic, telephonic, or broadcast media

Guidelines

Creating documents that recommend or mandate practice. This includes all
changes to service provision

Fiscal measures
Regulation
Legislation
Environmental/social planning
Service provision

Using the tax system to reduce or increase the ﬁnancial cost
Establishing rules or principles of behaviour or practice
Making or changing laws
Designing and/or controlling the physical or social environment
Delivering a service

TABLE 3
COM-B model components and examples in the context of software security.

COM-B model component

Description

Examples

Technical capability

Having the technical skills to perform security practices

Non-Technical capability

Having the non-technical skills to perform security practices

Having the skill to understand technical aspects of security
exploits and apply security patches

Having the skill to communicate and discuss security issues
with all stakeholders compromised in a security incident

Psychological capability

Being aware of the negative consequences of not adopting
security practices
Having the knowledge or conﬁdence to apply security practices

Awareness of the compliance standards that regulate
data protection and privacy, such as GDPR, PCI, and HIPPA

Technical opportunity

Having the opportunity afforded by the environment involving
time, resources, tools, and locations

Having tools that can be easily integrated into the
development workﬂow and alert developers of potential risks

Social opportunity

Having the opportunity afforded by interpersonal inﬂuences,
social and cultural norms that inﬂuence the way developers
think about things

Having people around implementing security practices
reminds developers why to invest extra effort in security

Reﬂective motivation

Reﬂective processes involving plans (self-conscious intentions)
and evaluations (beliefs about what is good and bad)

Intending to follow security guidelines after understanding
their value and the rationale behind them

Automatic motivation

Automatic processes involving emotional reactions, desires,
(wants and needs), impulses, inhibitions, drive states, and
reﬂex responses

Developers feeling frustrated due to the lack of support from
management when prioritizing security over other tasks

2.1.2 Self-Efﬁcacy Theory
The Self-Efﬁcacy Theory (SET) is an essential contribution from
social cognitive theory to understand individuals’ behaviors
based on a self-evaluation of their abilities [29]. Bandura pro-
posed the SET and deﬁned it as people’s beliefs about their
capabilities to produce designated levels of performance that
exercise inﬂuence over events that affect their lives [28]. There-
fore, high levels of self-efﬁcacy reinforce people’s convictions
about their abilities to perform a task successfully [30].

The SET introduces four signiﬁcant sources of efﬁcacy
beliefs: mastery experiences, vicarious experiences, verbal per-
[28]. First,
suasion, and emotional and physiological states
individual self-efﬁcacy is boosted by having success or direct

mastery experience. Additionally, observing people around us
having successful experiences, especially individuals sharing
similar characteristics or backgrounds, increases our beliefs
that we can also achieve success by mastering the required
activities. Moreover, inﬂuential people around us encourage
us and raise our beliefs that we can succeed by mastering
certain activities. Finally, individuals holding positive emotions
are more likely to have conﬁdence in their skills to successfully
perform particular activities.

2.1.3 Response Efﬁcacy

The Response-Efﬁcacy Concept (REC) has its origins in Ban-
dura’s social cognitive theory [29]. Bandura used the term

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

4

perform the behavior. Physical capabilities represent having the
physical skills to conduct the behavior, for instance, having
more physical strength and overcoming physical limitations.
In the context of software security, since physical capabilities
are not an essential component, they turned into having the
technical and non-technical skills to adopt software security
practices.

One aspect of the COM-B model emphasizes social and
physical opportunities. On the one side, social opportunities
refer to having the opportunity afforded by interpersonal in-
ﬂuences or social and cultural norms within the organization.
On the other side, physical opportunity implies having the
resources required to perform the behavior. The term physical
turned into technical opportunities to make it more explicit to
the software security context. But, keeping the exact deﬁnition
and including resources such as tools, time, and money. Finally,
concerning motivations, we used the same terminology and
deﬁnitions proposed by the COM-B model. Table 3 8 provides
examples and more detail of each component deﬁnition.

3 RESEARCH METHOD

Our study goal is to understand what needs to happen or
change, so the adoption of software security practices occurs.
To that aim, our research methodology consists of a cross-
sectional interview study [14]. Interview-based research is suit-
able for gathering thoroughly detailed participant experiences
and stories [14]. Our study design includes the following three
stages: (a) Study preparation, (b) data collection, and (c) data
analysis and results validation. Our methodology is depicted in
Figure 3. In the following sections, we explain our methodology
in detail. Private information from participants and companies
has been anonymized. The authors do not have the partici-
pants’ authorization to make the raw interview scripts available
as they contain conﬁdential information.

3.1 Study Preparation

Our ﬁrst step was to identify potential participants for the study
and deﬁne the selection criteria at this stage. Subsequently, we
designed the interview script considering demographics and
the different behavioral science theories we wanted to explore
to understand developers’ behaviors. Finally, we conducted
pilots to ensure questions’ comprehensibility, ensuring that
sufﬁcient time is allowed for the interviewer to conduct the
interview, and reducing interviewees’ cognitive load.

Participants recruitment. Our selection criteria was to recruit
participants who had at least two years of professional work
experience. Our pool of participants included two different
roles, engineers and security specialists. The engineers’ group
consisted of software developers, tech leads, DevOps engi-
neers, and CTOs. The security specialists’ group consisted of
application security specialists, pen testers, security program
managers, security developers, etc.

The pool of interviewees from the Engineers’ group came
from convenience sampling [18]. The authors of this paper
invited their industry contacts to participate in the study. The
ﬁrst author of this paper sent 42 email invitations, receiving 24

8. To clarify the deﬁnitions of the COM-B model components in the
context of software security, the descriptions and examples in Table 3
emerged from our ﬁndings.

Fig. 2. The COM-B model: To engage in a particular behavior, someone
must have the capabilities, have the opportunity, and feel motivated to
perform the target behavior more than any other competing behaviors.

outcome expectancies to refer to beliefs about the consequences
of performing a behavior, which is the foundation of REC.
Response-efﬁcacy is deﬁned as one’s belief that acting in a
speciﬁc manner is likely to mitigate threats, which is why it
is generally adopted in research on fear and fear appeals [31],
[32]. Outcome expectancies are somewhat broader and form
an essential part of people’s beliefs about an attitude-object
(e.g., a product, event, or behavior). The construct has its
origin in Fishbein and Ajzen’s expectancy-value theory [6] and
is captured under behavioral beliefs (leading to attitudes) in
the theory of planned behavior [33]. People generally develop
favorable attitudes toward behaviors they believe lead to de-
sirable consequences and form unfavorable attitudes toward
behaviors they believe lead to undesirable consequences. Gen-
eralized outcome expectancies are employed under traits such
as optimism, where people generally hold that the future will
turn out positively, which does not necessarily include actual
behavior [34].

2.2 Combining the Three Behavioral Models in the
Context of Software Security

To study why developers fail to adopt software security prac-
tices, we used the COM-B model as a practical diagnosis tool
to highlight the capabilities, opportunities, and motivations
that potentially inﬂuence developers to adopt software security
practices. Additionally, we used the Self-Efﬁcacy Theory (SET)
and Response-Efﬁcacy Concept (REC) to complement and en-
rich the diagnosis: SET assisted with understanding developers’
beliefs regarding their capabilities and their conﬁdence for
performing software security practices (and what can inﬂuence
that conﬁdence), and REC aided in understanding how devel-
opers’ perceived success in adopting security practices affects
their security adoption behaviors.

The COM-B model was designed as a generic diagnosis tool.
To use it in software security, we needed to adapt some of
its components. The COM-B model highlights the capabilities
in terms of psychological and physical features. Psychological
capabilities refer to being aware of the knowledge required to

CapabilityMotivationOpportunityBehaviorJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

5

Fig. 3. Research Method: Three main stages, Data Preparation, Data Collection, and Data Analysis and Validation.

TABLE 4
Proﬁle of our participants (N=28). Companies are anonymized. MC column denotes participants who joined a member-checking session. (E1-E19)
Engineering (Developer, Tech lead, Dev Ops engineer), (S1-S9) Security Specialist.

MC

Interviewee

Company

Business

Company size

Region

Role/Function

Years of Exp.

E1
E2
E3
E4
E5
E6
E7
E8
E9
E10
E11
E12
E13
E14
E15
E16
E17
E18
E19

S1
S2
S3
S4
S5
S6
S7
S8
S9

*

*
*
*
*

*

*

*

*

*
*

*

C1
C2
C3
C4
C5
C6
C7
C8
C9
C10
C11
C4
C7
C12
C13
C14
C15
C16
C17

C18
C19
C20
C21
C22
C23
C24
C11
C25

E-commerce
E-commerce
Telecommunications
ERP Systems
Beauty and Personal Care
Embedded Systems
Education
Health Services
CRM Systems
Booking and Rental Services
Professional Design
ERP Systems
Research
CRM Systems
Health Services
Video Games
Embedded Systems
Telecommunications
Digital Publishing

Health Care Services
Security
Financial Services
Security
Security
Security
Telecommunications
Professional Design
IT and Software

50+
1000+
5000+
10000+
10+
10000+
5000+
10000+
5000+
100+
1000+
10000+
5000+
100+
1000+
100+
1000+
50+
100+

10000+
50+
1000+
1000+
10+
5000+
10000+
1000+
10000+

North America
Europe
South America
North America
North America
Europe
Europe
North America
Europe
North America
Oceania
North America
Europe
South America
Europe
North America
Europe
North America
North America

North America
North America
Europe
Oceania
North America
North America
North America
Oceania
North America

Software Developer
Software Developer
Software Developer
Senior Software Developer
Development Team Lead
Scientiﬁc Software Developer
Lecturer/Software Engineer
Senior Software Developer
Principal Software Engineer
Development Team Lead
Software Developer
Software Developer
Scientiﬁc Software Engineer
Software Developer
Software Developer
Senior DevOps Engineer
Software Engineer
VP Systems Enginnering
CTO

Technical Product Manager
Application Security Engineer
Application Security Engineer
Senior Security Developer Advocate
CTO/Pen tester
Information Security Specialist
Application Security Specialist
Software and Security Engineer
Security Program Manager

6
2
7
9
20
2
2
20
7
16
9
5
2
3
7
18
4
10
32

15
20
4
15
15
10
20
12
6

Prepare Interview ScriptRecruit ParticipantsConduct PilotReﬁne Interview ScriptConduct InterviewsTranscribe InterviewsCode E1 InterviewCode E9 InterviewCode E16 InterviewAgreement Session E1Agreement Session E9Agreement Session E16CodebookCode Remaining Interviews (Engineers)Thematic Analysis (Engineers)ThemesMember CheckingCode S5 InterviewCode S2 InterviewCode S3 InterviewAgreement Session S5Agreement Session S2Agreement Session S3Code Remaining Interviews (Security)Thematic Analysis (Security)Data PreparationData CollectionData Analysis and Validation Security SpecialistsEngineersJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

satisfactory responses to join the study. The ﬁrst 5 participants
were considered for piloting the interviews and reﬁning the
interview questions. Additionally, the participants from the
security specialists group came from purposive sampling [18].
The ﬁrst author identiﬁed and invited software security experts
using the LinkedIn platform. We sent 22 invitations, resulting
in 9 of the specialists agreeing to join the study.

In the end, our ﬁnal pool of interviewees included 28
practitioners, 19 engineers (identiﬁed as E1-E19 throughout
this paper), and 9 security professionals (identiﬁed as S1-S9).
Our participants came from 25 different companies that work
in 16 diverse industry types. The professional experience of our
interviewees ranged from 2 years to 32 years, having a median
of 9 years of work experience. In Table 4, we provide more
details about our participants.

Interview Script Preparation. We designed semi-structured
interviews to collect our participants’ experiences, stories, and
challenges. Semi-structured interviews foster interviewees to
freely share their experiences, enabling interviewers to explore
new ideas based on the participant’s answers [19]. Our inter-
view script design was guided by the COM-B model and supple-
mented with insights from SET and RET. A complete list of the
interview questions is available in our online appendix [49]. The
overall structure of our interview script included the following
topics:

(a) the practitioners’ demographics and context to understand
essential aspects of the environment where software secu-
rity practices’ adoption (or not adoption) occurs.

(b) how conﬁdent participants feel about their ability to per-

form speciﬁc software security tasks (self-efﬁcacy).

(c) to what extent do participants feel their adoption of soft-
ware security practices impact the overall adoption in their
organizations or professional network (Response efﬁcacy
Theory), and

(d) participants’ capabilities, opportunities, and motivations

for adopting software security practices (COM-B model).

Pilot Interviews and Interview Script Reﬁnement. The au-
thors conducted ﬁve pilot interviews with developers aiming to
increase the comprehensibility of the interview questions and
reduce participants’ cognitive load during the interview. As a
result, the 115 min initial interview duration was considerably
reduced in each iteration, resulting in 60 minutes approxi-
mately. Two researchers were always involved during the pilots,
the ﬁrst author collaborating with one of the other researchers.
The interviewers also asked participants their feedback regard-
ing the questions’ understandability and suggestions regarding
the overall study. After each pilot interview, both researchers
discussed the feedback collected and introduced the respective
adjustments. After the ﬁfth interview, the researchers agreed
that the questions were mature enough. During the pilot, our
interview participants pointed out that we should provide a
standard deﬁnition of software security practices to avoid any
potential misunderstanding at the beginning of the interviews.
Additionally, our pilot participants highlighted that the in-
terview duration should be reduced considerably, forcing us
to select the most relevant questions for understanding the
adoption of security practices.

6

3.2 Data Collection

The authors conducted 28 semi-structured interviews over
the Zoom platform from May 31st to July 16th in 2021. Two
researchers were involved during the interviews, one researcher
leading the interview, actively asking questions and interacting
with the interviewee, and the other researcher noting down
relevant aspects of the participant’s story and experience. We
started each interview by going through our base set of ques-
tions and slightly adapting them based on the participant’s role
and context. For instance, we focused our questions for security
professionals on their last interaction or collaboration with the
engineering team instead of their personal experience as de-
velopers, which was not applicable in most cases. In addition,
immediately after each interview, both researchers discussed
any potential misinterpretation based on the notes taken and
agreed whether the data collected reached theoretical satura-
tion. According to Strauss and Corbin [23], sampling should
be discontinued once the data gathered no longer provides
new information. Each interview lasted between 55 min and
75 min, and with the participant’s permission, it was recorded,
producing around 32 hours of recorded audio. Subsequently,
recorded audios were transcribed, anonymized, and prepared
for analysis.

3.3 Data Analysis and Findings Validation

The next stage was conducting thematic analysis to identify
themes and patterns in our qualitative data [20]. Our data
analysis consisted of inductively developing codes from the
transcripts and identifying themes associated with participants’
adoption (or not adoption) of software security practices. We
divided our data analysis into two steps. First, we analyzed
data coming from the engineers’ group; then, we analyzed the
data from the security specialists’ group. In this way, coders
are not switching criteria and perspectives while analyzing the
data. In addition, we followed an open coding approach [21];
during the open coding process, codes emerged and were
removed or merged depending on the researchers’ discussions.
The discussions helped reduce any potential bias introduced
by the coders.

At the beginning of the coding phase, the ﬁrst two au-
thors coded every excerpt of the same transcript. An excerpt
represents a “dialog segment” used as a unit of analysis as-
sociated with an interviewees’ response to a question. The
coding phase started with the engineers’ group transcripts (E1).
Both researchers coded transcript E1 independently and then
calibrated their understandings of the codes in an agreement
session. We deﬁned coder agreement as an excerpt where both
researchers had at least one code for the excerpt in common.
Subsequently, both researchers selected another participant
and continued this process iteratively until reaching an inter-
rater agreement level of 85%. Following E1, the subsequent
transcripts coded were E9 and E16, respectively. Our agreement
sessions involved extensive discussions on the meaning and
use of the codes in our codebook, resulting in a ﬁrst consensed
version of our codebook. After both researchers understood
each code, they started coding the remaining transcripts inde-
pendently.

To reach our study goal, we developed themes based on
thematic synthesis [20] of our coded data. We conducted 5
thematic analysis sessions with the engineers’ group data,

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

7

Fig. 4. The seven considerations (categories) that organizations and stakeholders should pay attention to foster the adoption of software
security practices by developers.

each including a different subset of participants. During the
thematic analysis sessions, similarities and differences between
codes were discussed and then grouped in higher-level themes.
Subsequently, each theme was associated with one or more
of the three components of the COM-B model (Capabilities,
Opportunities, and Motivations). To validate the correct inter-
pretation of the codes and themes creation, we counted with
the feedback of an expert reviewer, the 6th author of this paper,
who helped us reduce any bias the researchers might introduce
in the analysis. Additionally, to validate the association between
themes and COM-B model components, we had the assistance
of a domain expert in behavioral psychology, the 5th author of
this paper.

Once the thematic analysis of the engineers’ group ﬁnished,
we started the open coding process for the security specialists’
group. We followed a similar approach to the engineers’ group.
The coding phase in this group started with the ﬁrst two
authors coding transcript S5, then calibrating their understand-
ing of the codes in an agreement session. Following S5, the
subsequent transcripts coded were S2 and S3, respectively,
reaching an average agreement of 75%. As a result, no new
code was added to the initial codebook obtained from coding
the engineers’ group. Consequently, the researchers conducted
two thematic analysis sessions. As a result, we added three new
themes to the initial set of themes coming from the engineers’
group. Similarly, in this stage, we counted with the support
of an expert reviewer and a behavioral psychology expert to
ensure the correct codes interpretation, themes creation, and
association with the COM-B model components.

After thematic analysis, we performed member-checking
sessions [22] with the study participants. We sent email invi-
tations to all participants to join a member checking meeting
to verify whether our ﬁndings are relatable to them and the
context of their organizations. 12 participants accepted to join,
8 engineers and 4 security specialists. The member checking
sessions lasted around 45 min and consisted of the following 5

steps: (1) the ﬁrst author presenting the motivation and study
participants’ demographic data, (2) explicitly indicating what
we want to collect in the session, (3) presenting the ﬁndings
(drivers), (4) for each driver presented, discussing to what
extent the driver is relatable to them and their organizations,
and (5) asking for any potential driver that we overlooked in
our ﬁndings. We used all participants’ feedback to validate our
ﬁndings and ensure the interpretation of qualitative data col-
lected from the interviews was correct. The member-checking
presentation slides and a table summarizing the feedback
collected from our participants are available in our online
appendix [49].

4 FINDINGS
We used the COM-B model as a diagnosis tool to understand
what needs to happen or change so that developers adopt
software security practices. Based on the codes that emerged
from the analysis of the interview transcripts, we associated all
the excerpts from our participants’ stories with the different
components of the COM-B-model, capabilities, opportunities,
and motivations. This resulted in 33 drivers that we then
grouped into seven categories based on similarity: Figure 4
shows the list of the seven categories that emerged from our
study.

In Table 5, we detail the entire landscape of drivers from
our analysis. In the following, we describe the seven categories
in detail using the components of the COM-B model associated
with them, and the role of these drivers in the overall adoption
of software security practices. To facilitate the description of
each driver, we use the term practitioner when referring to both
engineers and security specialists. As described in Section 3,
the term engineers includes developers, tech lead, DevOps engi-
neers, and CTOs, and security specialists consists of application
security engineers, pentesters, security developers.

TABLE 5
The 33 drivers that emerged from our study, (E1-E19) Engineering (Developer, Tech lead, Dev Ops engineer), (S1-S9) Security Specialist.

E1

E2

E3

E4

E5

E6

E7

E8

E9

E10

E11

E12

E13

E14

E15

E16

E17

E18

E19

S1

S2

S3

S4

S5

S6

S7

S8

S9

E

S

Totals

Building an organizational security culture

D1
D2
D3
D4

D5

D6

D7

Organization promoting/mandating security
Prioritizing security practices
Having a security-speciﬁc role ﬁlled
Overcoming the resistance to change

Fostering collaboration between engineering and security teams

Awareness of the social perception of security adoption in one’s own
organization and professional network

Providing awareness of external incentives and compliance

Facilitating the adoption of software security by developers

D8
D9
D10
D11

Shaping developer’s attitude towards security
Tool awareness
Standard guidelines geared at developers
Reduction of system complexity

Understanding risks, beneﬁts, and trade-offs

D12
D13
D14
D15

Awareness of potential risks and security incidents
Learning from actual incidents
Fear of non-adoption consequences
Knowledge of beneﬁts

Providing contextual information to motivate developers to write secure code

D16

Promoting a customer satisfaction/protection mindset

D17

D18

Awareness of the inﬂuential role of the industry type in developers’
disposition towards security compliance

Awareness of developers’ perceptions of the need for software security
based on application characteristics

D19

Aligning the perspective of what "good enough" security means

Providing justiﬁcation for necessary tools and process constraints

D20
D21

Consideration of tool constraints on developers’ autonomy
Awareness of developers’ perception of security-imposed restrictions

Providing (cognitive) support to developers for writing secure code

D22
D23
D24
D25

Availability of reminders, i.e., checklists, dashboards, etc.
Improving the usability (complexity reduction) and accuracy of security tools
Reducing the effort required to learn or apply security
Integrating tools into the development workﬂow

Facilitating developers’ acquisition of security-speciﬁc skills

D26
D27
D28
D29
D30
D31
D32
D33

Accessibility to learning resources
Using security practices as learning tools
Providing security education
Fostering hands-on learning/self-learning/osmosis
Creating and participating in communities of practice
Having non-technical skills
Conﬁdence in their technical abilities
Awareness of necessary security skills

•

•

•

•

•
•

•

•

•

•
•

•
•

•
•
•
•
•
•
•
•

•
•
•

•

•

•

•
•

•

•

•

•

•
•
•

•

•
•

•
•

•
•

•

•
•
•

•

•

•

•

•

•

•

•
•

•
•
•
•

•

•

•

•

•

•

•

•

•

•
•

•

•

•

•

•
•
•

•
•

•

•

•
•

•

•

•
•

•

•

•

•

•

•
•
•
•

•
•

•

•

•

•
•
•
•

•

•

•

•

•
•

•
•
•

•
•
•

•

•

•

•

•

•

•

•

•
•
•

•
•
•

•

•

•
•

•

•

•

•

•
•

•
•

•
•
•

•
•
•
•

•

•

•
•

•

•
•

•

•

•

•

•

•

•
•
•

•

•
•

•

•

•
•
•

•
•
•
•

•

•

•

•

•

•
•
•
•
•
•
•

•
•
•

•

•

•

•

•
•
•
•

•

•

•

•
•
•
•

•

•
•

•
•
•

•
•
•

•

•

•

•

•

•
•

•

•

•

•

•
•

•
•

•
•
•
•
•
•
•
•

•
•

•

•

•
•
•
•

•

•

•
•

•
•
•
•

•

•
•
•

•
•
•

•

•

•

•
•
•
•

•

•

•
•

•

•
•

•
•
•
•
•
•
•
•

•
•
•

•

•

•

•
•

•

•
•

•

•

•

•

•
•

•
•

•

•
•
•

•
•
•

•

•

•

•

•

•

•

•

•

•

•

•

•
•

•
•

•

•

•

•
•
•
•

•

•

•

•

•

•
•

•
•
•

•
•
•
•

•

•

•

•
•

•

•

•

•

•
•

•

•

•
•
•
•

•

•

•

•
•

•

•
•

•

•

•

•

•

•
•
•

•
•
•

•

•

•
•

•
•
•
•

•

•

•
•

•

•
•
•
•

•
•
•
•

•

•
•
•
•

•
•

•

•
•
•
•
•
•

•

•
•
•

•

•

•
•
•

•

•

•

•

•
•

•
•
•
•
•
•
•
•

•
•

•

•

•

•
•

•
•
•
•

•

•

•

•

•
•

•
•

•
•

•
•

•

•
•
•

•

•

•
•
•

•
•

•

•

•

•

•

•

•

•
•
•
•

•

•
•
•
•

•

•

•

•

•
•

•

•

•

•

•

•

•

•
•
•
•
•
•

•
•
•

•

•

•

•

•

•
•

•

•

•

•

•
•

•
•
•
•
•
•

•
•
•

•

•

•

•
•

•

•
•

•

•

•

•

•

•
•

•
•
•
•
•
•

•
•

•

•

•
•

•

•
•

•

•

•
•

•

•
•

•

•
•
•
•
•
•

18
14
11
4

13

19

4

11
9
8
8

19
6
12
15

4

10

13

16

9
13

13
6
18
5

13
6
15
10
11
19
19
11

9
9
7
2

7

9

5

7
7
5
1

7
3
7
9

3

4

6

7

2
6

5
0
9
6

6
3
8
7
9
9
6
9

27
23
18
6

20

28

9

18
16
13
9

26
9
19
24

7

14

19

23

11
19

18
6
27
11

19
9
23
17
20
28
25
20

J
O
U
R
N
A
L
O
F
LA
T
E
X
C
L
A
S
S
F
I
L
E
S

,

V
O
L
.
1
4
,

N
O

.
8
,

A
U
G
U
S
T
2
0
1
5

8

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

9

rity practices. Strategies to disseminate security guidelines and
practices across the organization inﬂuence developers’ motiva-
tions for adopting software security practices. These strategies
are perceived by developers as a good sign of proactiveness
towards security, and they make practitioners reﬂect on their
practices and align them with the rest of the organization.
For example, E16 said: “The company is pushing for security.
Sending in the monthly newsletter what new security rules have
been put in place.”

Automatic motivations: Engineers experience frustration
when organizations, particularly management and other de-
partments, do not treat security as a ﬁrst-class citizen, making
it difﬁcult for developers to prioritize security over other tasks.
Sometimes management pushes developers to ensure a secure
product despite time pressure issues and several barriers their
organizations introduce that can delay the delivery of a feature
or product. These delays might be caused by waiting for
feedback or approval from a security team or legal and privacy
department. For instance, E7 pointed out: “So currently, we are
annoyed by the slowness of the organization, so there is a legal
department and privacy department, and they need to evaluate
our system in terms of security, and they’re just really slow in
doing so.”

D2: Prioritizing security practices. Not all organizations prior-
itize security in the same way. Depending on how critical the
data managed by the application is and the resources avail-
able, organizations, if needed, will introduce different security
practices across the development pipeline to ensure a secure
product. Shifting security to the left, at the design stage, or
leaving security to later stages during testing or operational
stages are standard practices seen in the industry.

Technical opportunities: Organizations that prioritize se-
curity provide developers with opportunities to adopt security
practices by enabling them with the appropriate resources and
processes to ensure a ﬂawless product. Typically, organizations
introduce several security inspection mechanisms during the
software development pipeline to rigorously identify potential
vulnerabilities in the supply chain and ensure that malicious
hackers cannot compromise personally identiﬁable informa-
tion from customers. For instance, E18 highlighted: “Security is
essential for us ... There’s a considerable amount of privacy work
that you have to do upfront in terms of getting the consent,
ensuring that you’re handling the data properly ... We do regular
audits and reviews from the privacy side that covers the security
of the application.”

D3: Having a security-speciﬁc role ﬁlled. Practitioners agreed
that the presence of a security role within the organization can
promote, maintain, and enforce security practices. Concerning
the COM-B model, we identiﬁed that organizations employing
a security role provides them with social opportunities and
reﬂective motivations. Social opportunities are relevant due to
the inﬂuential role of a security specialist in adopting soft-
ware security practices within the organization. Additionally,
reﬂective motivations represent how the presence of a security-
speciﬁc role pushes developers to think about the security
implications of their technical decisions.

Fig. 5. Building an organizational security culture: D1: Organization
promoting/mandating security, D2: Prioritizing security practices, D3:
Having a security-speciﬁc role ﬁlled, D4: Overcoming the resistance to
change, D5: Fostering collaboration between engineering and security
teams, D6: Awareness of the social perception of security adoption in
one’s own organization and professional network, and D7: Providing
awareness of external incentives and compliance.

4.1 Building an organizational security culture

Practitioners consider culture an essential driver to boost the
adoption of security practices in an organization. Organizations
that promote or mandate security usually exhibit a good secu-
rity posture by having a role such as a security champion or a
security team in the company. Figure 5 shows the relationships
between the COM-B model components and drivers.

D1: Organization promoting/mandating security. Organiza-
tions should carefully pay attention to their inﬂuential role in
developers’ adoption of software security practices. We used
the COM-B model as a diagnosis tool to highlight the social
opportunities, reﬂective motivations, and automatic motivations
of the behaviors related to the adoption of software secu-
rity practices. Social opportunities represent the organization’s
norms and values inﬂuencing developers’ attitudes towards
security. Reﬂective motivations indicate how those norms and
values encourage developers to reﬂect on their practices and
adopt new habits, and automatic motivations indicate how
developers’ emotions react to those norms and values.

Social opportunities: Practitioners indicated that organiza-
tional culture highly inﬂuences developers’ attitudes towards
security. Developers are willing to adopt security practices if
organizations give them the proper time and opportunity to
learn and apply security in their workﬂow. For instance, in
the words of E9, “Adopting security requires support from the
organization by facilitating the solution of a security issue.”
Sometimes organizations might treat security as a second-class
citizen. For example, E16 emphasizes: “Making it work is more
important in my organization than doing it securely.”

Reﬂective motivations: Engineers revealed that organiza-
tions interested in embracing security as part of their culture
care about developers’ motivations for adopting software secu-

Social opportunities:

Practitioners highlighted the im-
portance of having a security role in the organization. An
organization that promotes a software security culture des-

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

ignates a speciﬁc position for security matters. In addition,
developers are willing to adopt software security practices if
organizations allow them to shadow security specialists to learn
and understand how security issues are handled and patched.
For instance, E1 stated: “I will learn from them, see how people
ﬁx the problem, how they prioritize the problem, and that’s one
thing the company is really good at, letting you see what happens
behind the scenes so you can get a good understanding of it. And
eventually, that will translate into me working on more and
more security-related tickets.”

Reﬂective motivations: Security specialists can facilitate
organizational discussions about security practices, the conse-
quences of security issues, and potential threats to the system.
Hence, developers will be aware of more profound implications
of security issues and, as a result, will understand the rationale
behind security guidelines and feel motivated to incorporate
them into their software development workﬂow. For example,
E10 pointed out: “Having a security role in the organization,
probably fosters a better environment for adopting security
practices. I think that if you have that kind of security experts
scattered about your organization, I think that brings everyone’s
security knowledge level up.”

D4: Overcoming the resistance to change. Practitioners also
implied that in some particular cases, developers might be
reluctant to adopt new engineering practices, speciﬁcally se-
curity, because software security requires extra effort in their
regular workﬂow—a scenario that developers are not willing
to accept and a highly compelling reason behind their lack of
interest.

Social opportunities: Engineers perceived that adopting
security practices require convincing senior management that
security is necessary and involves a cultural change where
security is promoted from top management to the rest of
the organization. In addition, it requires changing a collective
mindset from just delivering everything as fast as possible to
building a trustworthy and secure product. For example, E19
emphasized: “For adopting security, executive sponsorship is
going to be the most important, making sure that you’ve got the
backing. Then it’s just a standard change management practice.
So make sure that you’ve got the executive sponsorship that
understands the value of security and will ﬁght for it. That’s
probably the most important.”

Reﬂective motivations: In particular cases, engineers are
reluctant to change their usual engineering practices and adopt
new ones. Some developers with extensive experience in de-
velopment might have a negative attitude towards adopting
security practices. For instance, E18 pointed out: “Some people
just might like their workﬂow so much, and they just don’t
feel like much of adopting security. They feel that the type of
stuff they’re working on, or the type of code they are developing,
wouldn’t be better by adding security.”

D5: Fostering collaboration between engineering and se-
curity teams. Practitioners highlighted the need to provide
effective mechanisms to enhance collaboration between en-
gineering and security teams. Typically, when software security
is mandated on organizations, developers negatively perceive
a security team’s involvement in technical decisions across the
development pipeline. For instance, some negative effects as
perceived by developers are: extra work, delays, rework, or

10

conﬂicting perspectives to prioritize and solve an issue.

Social opportunities: According to security specialists, most
developers perceive security teams as the carrier of bad news.
The ones who will notify them about their security mistakes.
Especially when a security vulnerability is identiﬁed or as soon
as an application is attacked, for instance, S4 emphasized:
“Security team is usually going to be traditionally the ones that
engage with devs to try and ﬁnd out how to ﬁx something that
they’ve identiﬁed in a particular deployment.”

Reﬂective motivations: Security specialists perceived it is
essential to work in close collaboration with developers. De-
velopers will be encouraged to follow security practices if
they feel supported by security experts during security-related
tasks, facilitating the learning process and reducing the effort
to apply security in their regular workﬂow. For example, S3
highlighted: “For collaborations to happen is vital to understand
one another, like understanding how development works and
how security works. Because when one doesn’t know how the
other works, they will assume things and do things on how they
best understand. So the other one can be put aside by mistake,
and the collaboration can fail.”

D6: Awareness of the social perception of security adoption
in one’s own organization and professional network. Most
engineers perceived that adopting software security practices
is a collaborative effort that’s strongly inﬂuenced by their pro-
fessional community. For instance, developers being aware of
their peers’ efforts to adopt software security practices provides
an opportunity to join a collective effort.

Social opportunities: Practitioners indicated that having
people around them adopting security practices helps them
follow the security procedures and reminds them why to invest
extra effort for adopting those practices. For instance, E15
pointed out: “What helps you as an external motivation to the
team is having people around you that have the procedures in
place. And remind you why we have those procedures, because
some people don’t like that, but I think it’s important, so I don’t
mind putting extra effort into it.”

Reﬂective motivations: The overall adoption within the
organization signiﬁcantly inﬂuences developers’ perception of
software security practice adoption. Not having people within
the organization adopting security will considerably diminish
developers’ motivations to adopt security. For example, E16
pointed out: “if nobody else takes it seriously, I’ll never take it
seriously. If it’s not part of the culture, if it’s just one guy saying
security, security, security, then people will do the bare minimum
to adopt security, which might be better than nothing. Still, it
needs to be a part of everyone. Everybody has to care about it for
you to feel like you’re making secure software.”

D7: Providing awareness of external incentives and com-
pliance. Organizations aware of external incentives, such as
potential government subsidies for security testing, particularly
among start-ups, represent an excellent opportunity to adopt
software security practices. Additionally, developers perceive
that organizations should promote awareness among develop-
ers of external regulations and compliance from the beginning
of the software project, explicitly highlighting the practices,
technical considerations, and justiﬁcation or rationale behind
the compliance.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

Psychological capabilities: Practitioners perceived it is vi-
tal for organizations to bring awareness of the compliance
standards that regulate data protection and privacy, such as
GDPR 9, PCI 10, and HIPPA 11. To achieve compliance, orga-
nizations reinforce speciﬁc procedures to ensure the privacy
and security of all customers’ data managed by the application.
For instance, some standard security practices observed are en-
cryption mechanisms and regular penetration testing activities.
Additionally, external incentives play a crucial role in adopting
software security practices. For example, government incen-
tives such as IRAP 12 allow startup organizations in Canada
to subsidize 24 hours of security testing. For example, S5
highlighted: “We work with many startups that the government
subsidizes their testing. So I think that’s an excellent option for
startups. It’s only a three-day engagement, but it’s a perfect start
to get an idea of where they’re at. If we ﬁnd that they have many
input validation issues, that shows that there’s something wrong
with the process that needs to be addressed. If we see many
conﬁguration issues, you know, you might get insight into where
they’re having problems. So that can give them kind of focused
advice.”

Social opportunities: Practitioners perceived organizations
dealing with sensitive customer data or safety-critical systems
adopt software security practices for compliance reasons. How-
ever, without the support of the business, the adoption will not
occur. For example, S7 pointed out: “Security is a thing that
they need to do for compliance or contractual reasons. But if the
business does not support security concerns, they will not adopt
it. Some organizations might be willing to sacriﬁce security and
take penalties on contracts if that works out business-wise in
their favor.”

4.2 Facilitating the adoption of software security by
developers

Developers pointed out that they usually do not see the im-
mediate beneﬁts of adopting security practices but instead the
adverse effects of introducing security practices that affect their
development pipeline, e.g., delays. Based on our analysis, we
describe the organization’s crucial role in easing the adoption
of software security by developers. Figure 6 shows the relation-
ships between the COM-B model components and the drivers
from our analysis.

D8: Shaping developers’ attitudes towards security. Soft-
ware practitioners indicated that it is easier for developers
to identify the disadvantages of adopting security instead of
the immediate beneﬁts, introducing negative attitudes towards
its adoption. Developers perceived that organizations have a
relevant role in shaping developers’ attitudes towards security
by introducing security as a “fun activity” and providing oppor-
tunities, e.g., through gamiﬁcation, to adopt and learn software
security practices effortlessly.

Social opportunities: Organizations play a crucial role in
fostering opportunities to shape developers’ attitudes towards
security. Organizations that provide the conditions to get de-
velopers involved in security incident ﬁxing processes posi-

9. https://gdpr-info.eu/
10. https://www.pcisecuritystandards.org/
11. https://www.hhs.gov/hipaa/index.html
12. https://nrc.canada.ca/en/support-technology-innovation/about-nrc-

industrial-research-assistance-program

11

Fig. 6. Facilitating the adoption of software security by developers:
D8: Shaping developers’ attitudes towards security, D9: Tool awareness,
D10: Standard guidelines geared at developers, and D11: Reduction of
system complexity.

tively affect developers’ attitudes. Practitioners perceived this
scenario as a promising chance to learn new technical skills
as part of their regular development work. For example, E1
said: “That’s one of the things the company is good at, letting
you see what happens behind the scenes so you can get a good
understanding of it. And eventually, that will translate into me
working on more and more security-related tickets.”

Automatic motivations: Developers working in organiza-
tions that promote software security practices often perceive
security as challenging but rewarding work. In addition, de-
velopers with a positive attitude towards security feel highly
motivated to adopt security practices to protect customers,
users, and the company. For instance, E1 highlighted: “I think
of security as a chess game. I play one side; the attackers play
the other side. It can be quite challenging, it’s hard work, but
it’s rewarding in the end, so my motivation is to protect people
and protect the company.” Additionally, developers appreciate
organizations’ effort to introduce security as a fun activity. For
example, E2 pointed out: “My team did the hack your own
product day, and that’s a fun experience.”

D9: Tool awareness. Organizations that aim to facilitate the
adoption of software security practices typically provide the
technical resources developers require to adopt it, speciﬁcally
specialized security tools. Developers ﬁnd it easier to adopt
security if they are able to access appropriate tools.

Technical opportunities: Engineers believe that organiza-
tions eager to create a culture around security should actively
introduce tools as part of the teams’ discussions. Developers
found valuable tools that can be easily integrated into their
development workﬂow and notify them of issues or alert them
of potential risks. For instance, E5 highlighted: “Tools involved
in the process, that make a lot of sense, providing educational
resources where needed. But of course, the challenge with some
tools is that you don’t realize them till later. The earlier we can
identify that stuff, the better.”

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

D10: Standard guidelines geared at developers. Engineers
often perceive that guidelines focused on software security
are quite abstract and overly complicated for their particular
information needs. Organizations play a signiﬁcant role in
customizing security guidelines to a developer’s context and
workﬂow. Developers will then be eager to use those security
guidelines, perceive their beneﬁt, and apply them to their
regular practice.

Technical opportunities: Practitioners perceived that most
security guidelines are not developer friendly. There is still
much work needed to make those guidelines comprehensible
by all security stakeholders, particularly developers. For ex-
ample, S3 emphasized: “We have a considerable fragmentation
in the current application security culture. So let’s say you’re a
developer and I’m a tester. I can’t communicate with you through
a uniﬁed standard. I can use CWE, CVSS, anything you can think
of. And the developer will not understand what I’m talking to
them.”

D11: Reduction of system complexity. Practitioners recognized
that applications evolve innately, increasing in size and com-
plexity, making maintenance and security management harder.
Developers acknowledge organizations’ effort to simplify the
adoption of security by abstracting security to a speciﬁc layer/-
component/service in the application, e.g., applying separation
of concerns.

Technical opportunities: Inevitably, systems grow continu-
ously, making their management more complex from a security
point of view. Developers perceived useful when organizations
simpliﬁed security from development by fostering the adoption
of security frameworks, and protocols or treating security as
a core feature in the application under the management of
specialized teams. For example, E11 highlighted: “Many security
details are abstracted away from development. So they are just
part of the policies or the plan. And occasionally, you can contact
the security team to suspend speciﬁc user permissions, but from
my point of view, it’s just very well embedded in the process.
We don’t need to know about the details, but we need to know
who needs to be contacted and which requirements need to be
fulﬁlled from a security standpoint.”

4.3 Understanding risks, beneﬁts, and trade-offs

Practitioners perceived that bringing awareness about security
risks, providing information about the consequences of not
adopting security practices, and discussing the beneﬁts of
building security into the development pipeline will incentivize
them to adopt security. Furthermore, being aware of the trade-
offs of adopting software security practices will help developers
maintain their positive attitude towards security and continu-
ous interest in inspecting security defects in their products.
Figure 7 shows the relationships between the COM-B model
components and drivers.

D12: Awareness of potential risks and security incidents.
Being aware of existing threats and vulnerabilities that software
products face is one of the critical motivations for developers
to adopt security practices. In addition, by being aware of what
risks other organizations face, developers can identify what
is required to secure an application and prioritize activities
accordingly.

Psychological capabilities: Developers often use security
news on the Internet to learn about security incidents and be

12

Fig. 7. Understanding risks, beneﬁts, and trade-offs: D12: Aware-
ness of potential risks and security incidents, D13: Learning from actual
incidents, D14: Fear of non-adoption consequences, and D15: Knowl-
edge of beneﬁts.

aware of how similar organizations have been exploited as a
measure to prevent those situations from happening in their
organizations. For instance, E1 stated: “Just digging around,
seeing what information I could learn about on the Internet and
see what was going on. You read many security news articles
about people getting hacked, and I was just curious to see how
they did it.”

Reﬂective motivations: Developers perceived that when
security is a signiﬁcant concern in the business they belong
to, they constantly gather information about security exploits
in the industry. Therefore, this situation pushes developers to
carefully examine their security practices to ensure a secure
product for their customers. For example, E19 emphasized: “It’s
hard to get a computer science degree or a software engineering
degree and not be mindful and aware of security. People in this
ﬁeld tend to keep up with the latest news related to technol-
ogy, both out of personal interest and professional interest. It’s
pretty much impossible to ignore what’s happening with all
the security breaches occurring all the time. So it’s part of the
consciousness of most developers.” Additionally, E7 pointed out:
“We do care a lot about security, especially we started caring
a bit more about security after some similar organizations got
hacked. So we decided to look closely and see if we are doing
everything up to standards.”

D13: Learning from actual incidents. Practitioners indicated
that having the experience of being hacked is one of the best
learning resources for adopting software security practices. For
instance, studying how security exploits happened, investigat-
ing how they occurred, and what the attackers were aiming
for are crucial resources to prevent security incidents from
happening again. In addition, patching a security vulnerability
allows developers to build more conﬁdence in handling secu-
rity issues and keeps them engaged in actively incorporating
security into their software development workﬂow.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

Psychological capabilities: To perform security tasks, as
highlighted by the COM-B model, practitioners should feel
conﬁdent about executing them. Developers can gain this
conﬁdence by examining security incidents and breaches and
understanding why the incidents happened in the ﬁrst place.
By knowing the reasons and studying a way to mitigate them,
they will be more conﬁdent in assessing their own product’s
security. For instance, E13 stated: “My main outcome of being
hacked is my own experience that I learned from the mistakes.
I’ve also seen and analyzed the results of what errors other people
make. So, I guess it’s helping more towards my experience with
security.”

Reﬂective motivations: Maintaining practitioners’ motiva-
tions towards adopting software security practices is a compli-
cated task. However, learning about security incidents allows
developers to reﬂect on their practices and keep them mo-
tivated. In addition, they become aware that the chances of
having a security breach are not small if they do not incorporate
security into their product. For example, E7 pointed out: “The
hack of other organizations was an alert; we need to make
sure that we do it better than whatever they did. And that’s
when we said let’s introduce security restrictions to everything
to maximum essentially. So there were many security features
available to us that we were not using because they were
potentially cumbersome.”

D14: Fear of non-adoption consequences. Practitioners con-
sidered that acknowledging the negative consequences of not
adopting security in software development inﬂuences their
need for adopting security.

Psychological capabilities: Awareness of the dire conse-
quences of not adopting security in the development workﬂow
is highly motivating for software practitioners. Among the
top three adverse effects that practitioners perceive relevant
are:
losing time due to the considerable amount of time
organizations need to invest in ﬁxing vulnerabilities; losing
money due to the number of resources required for patching
and reinforcing security in the software product as well as in
the engineering pipeline; and losing reputation which could
lead to losing customers, subsequently causing severe ﬁnancial
issues in the organization. For example, E12 pointed out: “The
negative consequences of not adopting; it’s undoubtedly a risk
of breaches, data leaking, and risk of people getting access to
something they shouldn’t. And If you take it to the extreme,
somebody could look remote in and wipe your whole system.”

Reﬂective motivations: The severe negative consequences
of not adopting software security practices makes developers
reﬂect on to what extent their software product is “secure
enough” and motivates them to minimize any possibility of
exposure to exploits due to vulnerabilities in the software. For
instance, E5 highlighted: “I would like to protect my clients. I
would like to make sure that I’m protected. I would like to make
sure that our reputation is protected, then I’ll be able to sleep at
night.”

Automatic motivations: One of the main motives for prac-
titioners to think about security in their software development
workﬂow is to avoid experiencing a security incident. However,
the fear of exposing conﬁdential information is always a good
reminder for developers to be careful about security imple-
mentations. For example, E6 emphasized: “Adopting security is

13

part of being a professional software developer and keeping your
job’s quality level and ethics. So it’s in some sense, the quality of
your work reﬂects your quality as a professional. So what would
be very bad for the client would be very bad for me because
I would probably get ﬁnancial and legal charges and personal
repercussions.”

D15: Knowledge of beneﬁts. Practitioners recognized that
awareness of the advantages of adopting security might indi-
rectly inﬂuence their perspectives towards prioritizing security.
For instance, most developers perceived that organizations
reinforcing security practices build conﬁdence among their
employees to ensure a secure product for their customers.
However, developers do not see the immediate beneﬁts of
adopting security in many situations; instead, they see the
disadvantages of its adoption.

Reﬂective motivations: Awareness of the beneﬁts or the
importance of adopting security practices makes practitioners
reﬂect on the value of introducing security at earlier stages of
the software development pipeline. This way, they will avoid
severe costs due to security bug ﬁxing or paying ransomware.
For instance, E7 stated: “Starting with security much earlier in
your design than what we see is like quick-to-market things.
That reduces the chances that you will have to deal with email-
ing all your customers because of security leaks or paying ﬁnes
for losing data or getting hacked and losing all your information
due to ransomware attacks and paying that off.”

Automatic motivations: Practitioners acknowledged that
they felt motivated to adopt security practices because they rec-
ognized the value of security as a selling point. Organizations
that care about the security and privacy of their customers’
data allow organizations to operate at a bigger scale and
use it for advertising and promoting trustworthiness in their
products and services. For instance, E4 stated: “Security is my
organization’s most important selling point. Without security,
we can’t operate at scale.” Additionally, developers indicated
that they feel satisfaction when accomplishing good work by
adopting security. Developers consider it rewarding to be able
to prevent future headaches due to security vulnerabilities
exploits. For example, E10 emphasized: “It makes me feel like
I’ve done a better job and that I’m helping prevent future pain
from everyone else on my team.”

4.4 Providing contextual information to motivate devel-
opers to write secure code

Practitioners recognized that being aware of the context for
adopting software security matters. For example, contextual
information such as industry type, application characteristics,
and the importance of customers’ data signiﬁcantly inﬂuence
developers’ perceptions of the need to adopt software security
practices. Figure 8 shows the relationships between the COM-B
model components and drivers.

D16: Promoting a customer satisfaction/protection mindset.
Organizations promoting a software security mindset oriented
towards protecting customers’ data better communicate the
need to adopt software security practices. Developers pointed
out that feeling responsible for protecting customers’ data
inﬂuences their mindset and priorities for security.

Automatic motivations: Practitioners feel satisfaction from
adopting security practices that ensure a secure and reliable

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

14

tices. Developers perceived that the security considerations
in their technical decisions differ signiﬁcantly depending on
features such as the application type, volume of users, or to
what extent applications are exposed to internet trafﬁc.

Technical opportunities: Practitioners indicated that not all
applications have the same security concerns. The application’s
technical speciﬁcations play a crucial role in identifying the
value of introducing security practices. In addition, security
requirements might scale to a different level in the system
architecture, i.e., at a network or infrastructure level instead of
at an application level. For example, E14 highlighted: “Because
usually, my code or application uses something that doesn’t need
input. If you don’t have an input, usually, it works by itself. So
what you need to check is that your platform or your server is
secure, but not your code because there’s nothing outside that
can change it.”

Reﬂective motivations: Web applications, mobile applica-
tions, and embedded systems have different characteristics,
and therefore, multiple security considerations. Developers do
not feel motivated to adopt security when developing speciﬁc
applications due to their perception of the reduced likeli-
hood of exposure to potential risks. For instance, developers
who write code for embedded systems feel security is not a
signiﬁcant issue while developing software, or they are not
even aware of security guidelines for this particular type of
application. For example, E17 pointed out: “Security is related
to the type of your application. We develop embedded systems,
so I don’t know if there are security rules. Thus, we do not care
about the security of our code. It should be secure from a higher
level.”

D19: Aligning the perspective of what “good enough” security
means. Practitioners had a negative perception of the conﬂicts
among different stakeholders involved in security decisions.
Each stakeholder has a different priority and perspective for
security, and these differing views about how the organization
should apply security in software development become barriers
to its adoption. Developers considered it critical for organiza-
tions to align stakeholders’ perspectives to mitigate this barrier.

Social opportunities: Practitioners indicated that when
several stakeholders are involved in security decisions, conﬂicts
naturally arise due to the different perspectives and priorities
each stakeholder holds regarding security. For example, E9
highlighted: “POs usually get together when the deﬁnition of
done includes security concerns. POs and the security team
should clarify and check them. The stakeholders would be
mainly the PO, the user, and the security team in this case.
Discussions are about understanding why the bug is an issue,
how to ﬁx it, and whether to prioritize it.”

Reﬂective motivations: Developers perceived that believing
they have a fully secure software product is not realistic; there is
always something to improve or learn about software security.
This uncertainty keeps them motivated to stay up-to-date
and adopt security practices to minimize potential risks. For
instance, E5 stated: “I believe we’re doing a reasonable job,
but I would like to continue improving it. So, we use things
that we know are very high risk, such as credit card processing.
We use third-party services which are certiﬁed to handle all of
that sort of stuff. But we believe our software is secure, but I
know that we could do better. I know that things are stepping

Fig. 8. Providing contextual information to motivate developers to
write secure code: D16: Promoting a customer satisfaction/protection
mindset, D17: Awareness of the inﬂuential role of the industry type in
developers’ disposition towards security compliance, D18: Awareness
of developers’ perceptions of the need for software security based on
application characteristics, and D19: Aligning the perspective of what
“good enough” security means.

product for their customers. They feel it is their responsibility
to protect customers’ private information from being exposed
to malicious hackers. This is particularly relevant in the case
of safety-critical systems such as health care applications. For
example, E15 emphasized: “My motivation is that people should
be conﬁdent that their doctor and their medical record are in
good hands and that somebody does not steal it and keeps being
private. So health care can continue providing services without
the system being down because of some hacker attack.”

D17: Awareness of the inﬂuential role of the industry type in
developers’ disposition towards security compliance. Practi-
tioners noticed how the prioritization of security signiﬁcantly
differs among some industries. For example, if developers are
not dealing with sensitive information, as some practitioners
disclosed in the gaming industry, they might think spending
resources and time on security is unnecessary.

Reﬂective motivations: In contrast to the gaming industry,
some industries are more known for their security require-
ments. For instance, developers that work with sensitive data
such as customers’ payment information are more likely to
feel the need to pay attention to the security implications
of their technical decisions. Therefore, they feel motivated to
adopt software security practices. For example, E9 emphasized:
“Major customers are coming from the ﬁnancial services, so my
security concern is very high.” Additionally, E16 pointed out: “In
the video game industry, software security is not taken seriously.
Some industries require like PCI compliance but not for video
game industry.”

D18: Awareness of developers’ perceptions of the need for
software security based on application characteristics. An
application’s characteristics remarkably inﬂuence practitioners’
perception regarding the need to adopt software security prac-

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

15

Technical opportunities: Some practitioners have a neg-
ative perception of adopting software security practices due
to the strict restrictions while choosing any tool to develop
software. For instance, E9 emphasized: “Adopting security limits
the freedom to choose what libraries we can use for development,
or many security checks need to be passed.”

Reﬂective motivations: Developers like the freedom to
choose the most suitable tool for doing their work. Organi-
zations imposing strict restrictions negatively affect develop-
ers’ motivations to adopt security practices. For example, E13
stated: “I think developers just like freedom of what they are
doing because some people choose small companies and startups
speciﬁcally for the freedom of doing what you want and how you
want to do it. In big companies, it is always more restrictive.”

D21: Awareness of developers’ perception of security-imposed
restrictions. Developers perceived that adopting software se-
curity practices introduces many disruptions to their regular
workﬂow. For instance, delays due to security inspections,
waiting for feedback during security code review, or delays
caused by the security team regarding the authorization to use
a third-party component or library. On top of that, following
security guidelines might introduce more complexity to the ap-
plication, making its maintenance difﬁcult. Therefore, software
practitioners encourage organizations to identify developers’
negative attitudes towards software security to foster its adop-
tion.

Automatic motivations: Developers’ motivations to adopt
security are inﬂuenced by the perception that some security
guidelines are unhelpful and unnecessary, especially when they
introduce more complexity to the system design instead of a
straightforward solution; Therefore, causing extra work in terms
of maintainability. For instance, E3 emphasized: “I work in a
private network in this telecommunication company, so we are
not open to the Internet. So using these Web services instead of
a simple protocol, which is faster, doesn’t make sense. So I think
that was unnecessary. That’s a barrier I’ve found; some security
guidelines are unhelpful and unnecessary.”

4.6 Providing (cognitive) support to developers for
writing secure code

Practitioners ﬁnd it challenging to incorporate software security
practices into their software development workﬂow due to the
overwhelming number of topics they need to assimilate to write
proper secure code. On top of that, developers perceive that
security tools are pretty complex and sometimes inaccurate,
which considerably affects their adoption. Figure 10 shows
the relationships between the COM-B model components and
drivers.

D22: Availability of reminders, i.e., checklists, dashboards,
etc. Most engineers indicated that software security is not a
topic off the top of their heads. Reminders such as check-
lists are helpful resources to prevent overlooking any security
considerations during code reviews. Another useful reminder
perceived by developers is security tool notiﬁcations containing
actionable feedback. In some particular cases, organizations
with strict security policies will not allow practitioners to move
forward in the development pipeline until any security concern
raised by the tool is ﬁxed.

Technical opportunities: Practitioners acknowledged that
reminders are helpful to prevent overlooking security concerns

Fig. 9. Providing justiﬁcation for necessary tools and process con-
straints: D20: Consideration of tool constraints on developers’ auton-
omy, and D21: Awareness of developers’ perception of security-imposed
restrictions.

up regarding what’s happening with the tech, and we could
continue to improve substantially.”

4.5 Providing justiﬁcation for necessary tools and pro-
cess constraints

Practitioners’ negative attitudes towards security are usually
driven by their beliefs that adopting security restricts their free-
dom of choice or autonomy for selecting the most convenient
tools, libraries, or technologies to perform development tasks.
Figure 9 shows the relationships between the COM-B model
components and drivers.

D20: Consideration of tool constraints on developers’ auton-
omy. Typically, organizations with an innate security culture
reinforce security practices by limiting the set of develop-
ment tools, third-party libraries, or in general, any software
component that developers can use in their regular workﬂow.
Engineers perceive this situation affects their autonomy and
freedom to choose the most convenient technologies to per-
form their work. Practitioners indicated that proper dissemi-
nation of the beneﬁts and rationale behind those restrictions
are crucial to mitigate any negative attitude caused by imposed
restrictions.

Social opportunities: Some practitioners had a negative
perception of the standard security practices in organizations
that impose restrictive policies for using tools or any third-
party component in a software project. In this context, the role
of a security or compliance team is to inspect and approve
any potential artifact developers may want to introduce in the
project and has not been validated previously. So, for instance,
E12 pointed out: “An independent security and compliance
team that has to review pretty much anything. Any external
dependency you introduce has to go through the security team.
Any new artifact that we produce, I think, has to be reviewed by
security. So there are various checks to make sure that you aren’t
shipping something that could be a vector for problems.”

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

16

D24: Reducing the effort required to learn or apply security.
Software security is a broad topic for developers. Considerable
effort and dedication are required to learn and gain enough ex-
perience to write secure code correctly. Developers highlighted
that organizations’ efforts to reduce the scope of learning topics
and provide a learning roadmap customized to developers’
information needs would facilitate their disposition to adopt
software security. For instance, considering topics focused on
their particular applications’ attack surface, programming lan-
guage, frameworks, etc., are highly valued by developers.

Automatic motivations: Engineers perceived that adopting
software security practices demands a lot of cognitive effort,
such as investing a signiﬁcant amount of time for learning
different techniques, absorbing a lot of information, and keep-
ing up-to-date knowledge. These challenges highly inﬂuence
developers’ motivations to adopt security practices and become
a signiﬁcant concern for organizations interested in promoting
security practices in their organizational culture. For instance,
E6 stated: “Security shouldn’t be complex. If it’s difﬁcult, people
will not follow it. So it seems that it’s in the company’s best
interest to make it straightforward for developers by giving
developers clear guidelines, being more proactive, and making
those guidelines available when people are dubious about if
something is secure or not. So let’s say a good company doesn’t
make security difﬁcult.”

D25: Integrating tools into the development workﬂow Au-
tomating software security assessments is perceived by devel-
opers as a signiﬁcant facilitator to adopt security practices.
Furthermore, integrating security tools into the Continuous
Integration (CI) pipeline allows developers to count on proper
feedback regarding any potential security ﬂaw in their source
code and react accordingly.

Technical opportunities: Security specialists highlighted the
importance of automating security by integrating security tools
into the CI/CD pipeline. This way, security scanning can be
performed automatically and expose potential vulnerabilities
before deployment. For example, S1 emphasized: “Once you
integrate security into the CI/CD pipeline, you make sure that
your code is clean. So if you use tools like OWASP Zap 13
or Arcane, you know they’re going to tell you whether you
have a broken URL or you are managing passwords or secret
information incorrectly, and this is going to spew them out
during scanning time. Then, you can quickly ﬁx them before
you go to deployment.”

4.7 Facilitating developers’ acquisition of security-
speciﬁc skills

The ability to perform security-related tasks does not necessar-
ily depend only on technical skills. Practitioners perceived that
having support from their organizations helps them acquire
the necessary technical and non-technical skills to understand
security challenges. In addition, support from organizations
relies on providing developers with the right tools and learning
resources to facilitate the adoption of software security prac-
tices. Figure 11 shows the relationships between the COM-B
model components and drivers.

D26: Accessibility to learning resources. Practitioners per-
ceived that, now more than ever, there is a massive diversity of

13. https://www.zaproxy.org/

Fig. 10. Providing (cognitive) support to developers for writing se-
cure code: D22: Availability of reminders, i.e., checklists, dashboards,
etc., D23: Improving the usability (complexity reduction) and accuracy
of security tools, D24: Reducing the effort required to learn or apply
security, and D25: Integrating tools into the development workﬂow.

while developing software. Besides security checklists, practi-
tioners recognize the usefulness of dashboards, a visual tool
that usually contains graphics and comprehensive summaries
of crucial information regarding Q&A and security metrics. For
instance, E2 pointed out: “We have a reminder to check the
dashboard. Otherwise, we will forget because it’s not always
on top of our minds. The dashboard highlights vulnerabilities
at the level of hosts, containers, and packages. In addition, it
shows how many high/medium/low vulnerability issues exist in
the application.”

D23: Improving the usability (complexity reduction) and
accuracy of security tools. Practitioners pointed out that most
security tools contain usability issues, making them complex
to use and manage, a situation that discourages them from
adopting software security practices. Additionally, security tools
require sophisticated conﬁguration to avoid a high volume
of
false-positive results. Default conﬁgurations result in a
high level of inaccuracy and are a detriment to the value
and usefulness of the tool. In this regard, developers highly
appreciate security specialists’ support for appropriate tools
conﬁgurations.

Technical opportunities: Engineers are very conscious of
the importance of security tools in adopting security prac-
tices. They recognized that better tools and security analyzers
would help in their application of security practices during
software development. However, some barriers to adopting
security tools rely on usability and accuracy characteristics. For
example, E13 highlighted: “What would help me apply security
practices? Having better tools, for sure, so better analyzers that
would prompt right away where there is a security vulnerability.
However, this needs to be ﬁxed ... working here made me
understand that these tools are unreliable and can give errors
and false positives.”

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

17

Fig. 11. Facilitating developers’ acquisition of security-speciﬁc skills: D26: Access to learning resources, D27: Using security practices as
learning tools, D28: Providing security education, D29: Fostering hands-on learning / self-learning / osmosis, D30: Creating and participating in
Communities of Practice, D31: Having non-technical skills, D32: Conﬁdence in their technical abilities, and D33: Awareness of necessary security
skills.

learning resources to boost technical skills in software security.
For example, developers might access free online courses,
conferences, specialized blogs, and publicly available security
guidelines to keep up-to-date in their knowledge of security
topics.

Technical opportunities: Practitioners indicated that they
can boost their technical skills in security by beneﬁting from
learning resources provided by organizations. An organization
that offers its developers courses, training, and conferences
fosters an environment for security learning. For instance,
S2 stated: “There are great webinars by OWASP. Companies
like SecureIdeas, TrustedSec, Black Hills Information Security,
among others, provide these worthy webinars. It’s like baking
cyber security into your development process because they’re just
like introductory level. For example, organizations, having their
development team watching one of those webinars every quarter
or doing a secure coding tournament from Secure Code Warrior
will get developers thinking about security and start them on
that path.”

D27: Using security practices as learning tools. Engineers
recognized the signiﬁcant value of being involved in security
practices within the organization. This situation provides an
effective way to learn software security. For example, devel-
opers highlighted that the feedback they receive from security
code reviews, especially when the security team is involved,
helps them identify anti-patterns in their coding practices and
comprehend security ﬂaws.

Psychological capabilities: Engineers perceived that they
gain more conﬁdence by being involved in security practices.
Experiencing how to tackle a real security issue helps develop-
ers build conﬁdence in their capabilities. Additionally, security
specialists highlighted that security games are an effective
learning tool for getting developers familiar with potential
threats and building a security mindset. For instance, S3 stated:
“I usually recommend STRIDE and Elevation of Privileges Game
which contains 12 threats per category. It’s kind of a game

where developers play cards to see which threat hits on your
application or your service. This game is something that they
can start up with because that’s around 50 threats.”

Social opportunities: Organizations play an essential role in
providing developers with experiential learning resources using
security practices. Practices such as code review and pair pro-
gramming help practitioners have a deeper understanding of
security issues. In addition, organizations that foster knowledge
sharing using security practices bring more opportunities for
their developers to adopt security. For instance, E12 pointed
out: “I learned more through colleagues, best practices, and
being mentored. In that regard, code review is an excellent
avenue for learning. As I grew as a professional, I learned a
lot through people, like pointing things out in code review.”

D28: Providing security education. Engineers perceived con-
tinuous learning and proper training as crucial to mastering
software security practices. Developers emphasized the vital
role of organizations in providing developers with the op-
portunities to keep up-to-date in their security knowledge.
Additionally, practitioners highlighted the need to improve
security education at the university level by integrating coding
best practices with security compliance source code.

Technical opportunities: Most practitioners do not take
exclusively security-related courses as part of their formal edu-
cation in computer science. Instead, software security is a topic
that they pick up along the way while developing technical
expertise. For example, E10 highlighted: “Security was a topic
included in many of those courses that had things to do with
networks and systems. So there were some security topics when
we got into things like developing Web applications. But I would
say it was rudimentary at best. It was mostly just elementary
stuff. There was much more emphasis on it when we were doing
things like setting up networks or conﬁguring a Web server on
Linux or things like that. But when it comes to writing secure
software, I would say that education at the university level didn’t
treat security as important as those other security aspects.”

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

D29: Fostering hands-on learning/self-learning/osmosis.
Practitioners recognized the value of organizations in providing
developers with opportunities to learn software security by
being indirectly involved in ﬁxing security vulnerabilities or
shadowing specialists while patching a security ﬂaw. Addition-
ally, organizations providing developers with the necessary time
to learn software security by themselves or the opportunity of
being mentored by a specialist are perceived by developers as
highly effective methods to motivate developers to write secure
code.

Technical capabilities: Practitioners perceived that the abil-
ity to self-learn is crucial for starting a career in software
security. A self-directed learning approach is vital to engage
with the security learning process. Software security is a broad
topic and requires, besides formal training, to keep up-to-date
knowledge of the security exploits happening every day. For
instance, S6 pointed out: “First, I was just learning security by
myself and studying on the Internet. Then I got more formal
training and got involved with the community by going to
conferences and giving some presentations. I think networking is
a big thing in security. To start learning, I would say start small.
Start with one type of vulnerability. Understand it properly,
understand how to ﬁx it. Look for that in your code or the
codebase you’re responsible for, and then go to other categories.
We can’t follow all the vulnerabilities and issues that happen
every day and every week. So start small, don’t try to learn about
everything.”

Social opportunities: Practitioners recognized that advocat-
ing for security within the organization is vital to demonstrate
the need to adopt security practices to all stakeholders. A
starting point could be using a proof of concept to expose the
security issues identiﬁed in the codebase and the implications
for the organization if we overlook them. For example, S9
highlighted: “To keep developers’ motivations to adopt security,
it’s important to advocate for additional security controls in your
environment; you can demonstrate using a proof of concept that
there are severe security issues. That can help motivate folks to
take action and ﬁnd time to work on it. Self-learning is essential,
like OWASP, and we also have the purple folks. Those are our two
best resources right now, and they just partnered together to offer
classes and stuff, which is fantastic. It’s kind of like demystifying
security in the company.”

D30: Creating and participating in communities of practice.
Practitioners emphasized the crucial role of communities of
practice to learn software security. Practitioners perceived that
a relevant characteristic of a good security culture is organiza-
tions creating and promoting an environment where people
interested in security-related topics gather together to learn
and share knowledge. Additionally, practitioners considered it
essential to join efforts with external communities since being
hacked could affect any organization or business.

Social opportunities: Currently, developers are using ex-
ternal communities to get help on security issues. For example,
communities such as OWASP provide an excellent environment
for practitioners to learn about security. Similarly, developers
perceived that organizations that form communities inside the
company and gather all the practitioners who show security in-
terest help build a supportive environment to facilitate security
learning. For instance, S8 emphasized: “There are many gangs
in the community and people doing similar things helping each

18

other solve security issues and learning.”

D31: Having non-technical skills. Besides having proper tech-
nical skills in software security, developers emphasized having
non-technical or soft skills. Ensuring a secure software product
is a collaborative effort and demands the participation of
several stakeholders. Inevitably, conﬂicts between stakehold-
ers may arise due to different priorities and perspectives of
approaching and applying security. In these situations, devel-
opers emphasized the critical role of having soft skills such
as communication, critical thinking, empathy, etc., to facilitate
discussions and mitigate any potential conﬂict.

Non-Technical capabilities: Practitioners indicated that
communication is one of the most important non-technical
skills required to conduct software security practices. For in-
stance, they believe communication is essential when describ-
ing the importance of security to other stakeholders, discussing
security issues with developers, and handling security inci-
dents. Furthermore, developers need to elaborate the situation
to the management team and other stakeholders to discuss
further actions when an incident happens. For example, E8
pointed out: “Besides communication, researching is also a
critical non-technical skill because you have to deeply investigate
what went wrong when you are facing a security issue.”

D32: Conﬁdence in their technical abilities. Engineers indi-
cated that conﬁdence in their technical abilities in software
security signiﬁcantly inﬂuences the adoption of software se-
curity practices. Developers’ low conﬁdence in their technical
skills will discourage them from adopting security practices.
Contrarily, over-conﬁdence is perceived negatively and as a
deterrent to their motivation to keep up-to-date knowledge to
improve their security practices.

Psychological capabilities: Practitioners perceived that
conﬁdence is essential to perform any engineering task. De-
velopers become conﬁdent in their technical abilities to con-
duct software security tasks because of their experience facing
security threats or due to the collective expertise of their
software teams. Having someone on the team who has security
experience boosts the entire team’s conﬁdence. For instance,
E16 pointed out: “Academic knowledge can get you close to
ensuring secure software. However, having expertise or having
someone on your team who has experienced a security threat
will give you more conﬁdence to say you have a secure product.”

Reﬂective motivations: Most engineers recognized that
security is not their primary focus at work; It is not a topic
that they need to apply daily. However, developers are familiar
with self-learning and hands-on learning techniques within a
software development context, which are also essential and
commonly used in software security. Therefore, it is not a
drastic transition for a developer to feel motivated to dig
deeper in software security and become a security champion
or an application security specialist. Due to the deluge of
available security information, it is also vital for practitioners to
recognize that security is a never-ending learning cycle; There
are new sophisticated mechanisms, tools, guidelines, and best
practices to learn. Such intense and dynamic context motivates
developers to aggregate security to their professional proﬁle.
For instance, E5 stated: “So the ﬁrst question is how comfortable
am I with security? I think I know enough that I don’t know
much, but I’m not starting from zero. I know that there are

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

many more sophisticated mechanisms out there right now. And
I know that we’ve got a lot of development experience that we
can just use it.”

D33: Awareness of necessary security skills. Engineers per-
ceived that awareness of what they should know to properly
adopt and apply software security practices signiﬁcantly inﬂu-
ences their motivation to adopt security practices. For instance,
developers considered it relevant to know about malicious
hackers’ mindsets, their methods, most common attack vectors,
and the best coding practices to prevent them.

Technical capabilities: Developers acknowledged that it is
essential to have a solid understanding of the security basics
to understand technical aspects of security exploits, follow
security guidelines, and apply security patches, and therefore,
prevent harmful consequences in a potential system attack. For
instance, E11 highlighted: “Knowledge of defensive program-
ming patterns and how to sanitize inputs is valuable. Knowing
about security issues and what is needed to solve them it’s part
of the job.” Additionally, E15 emphasized: “You need to know
about software architecture, software testing, many technical
issues like how you design software to be secure? And you need to
know what type of threats are there? How can you do the testing?
How do you do penetration testing? Also, to let other people do
that. So you should always think you should always question
your security knowledge because you can think about everything
upfront. However, still, somebody else will be able to penetrate
the system.”

Non-Technical capabilities: Practitioners recognized that
to ensure a secure software product, it is crucial to consider
the human aspects of the product in addition to the technical
features. In this context, it is valuable to acquire knowledge
about the users, where the product is used, and what abnormal
product usage could potentially occur. In other words, to
analyze upfront what can go wrong due to a misuse of the
application by the end-user. For example, E15 emphasized: “Re-
garding non-technical skills, I need to have domain knowledge
and knowledge about end-users. That’s very important where
the system is used, what can happen if that something doesn’t
work or goes wrong or how people enter the system, if they share
their password data or how people work with that.”

5 RELATED WORK

We brieﬂy provide an overview of the related research and
how it aligns with the drivers (shown in italics) our study
revealed. We searched the ACM, IEEE Xplore, and Springer
research databases and found 15 papers that studied the
adoption of software security practices, many of which were
published quite recently. Two of these papers were systematic
literature reviews of work on this topic [35], [38]. We found
that most (30/33) of the drivers that emerged from our study
also appeared in this other research. Although most papers
reported between 3 and 19 of the drivers we found, Mokhberi
and Beznosov’s [38] systematic literature review reported 28 of
our drivers. This overlap further strengthens the relevance of
our work, but we were surprised that several of the drivers we
found to be quite important were not mentioned in these 15
papers. These drivers are (1) awareness of the inﬂuential role
of the industry type in developers’ disposition towards security
compliance, (2) consideration of tool constraints on developers’

19

autonomy, and (3) using security practices as learning tools. We
summarize how our research relates to the related research in
Table 6. This table can be used to not only see which of the
drivers have been reported before, but it also provides an index
into further reading about these drivers, while highlighting that
some of them may perhaps call for further research.

Building an organizational security culture. Some researchers
have extensively studied how organizations build a security
culture, speciﬁcally organizations promoting or mandating se-
curity (D1). For instance, Rauf et al. [35], Jones and Rastogi [36],
and Mokhberi and Beznosov [38] exposed the lack of security
culture in teams and organizations as a signiﬁcant deterrent
to the adoption of security. In particular, Jones and Rastogi
highlighted that management should be responsible for dis-
seminating the security policies, standards, guidelines, and
procedures across all teams in the organization [36]. Addition-
ally, some research literature has revealed the relevant role of
organizations in prioritizing security practices (D2). For exam-
ple, Mokhberi and Beznosov [38] and Poller et al. [41] agreed
that organizations that do not provide the necessary resources
prevent developers from implementing security. Speciﬁcally,
Poller et al. pointed out that when managers see security as
a resource conﬂict with feature development, developers also
perceive implementing security as not worth the time and
energy [41].

Several other researchers have emphasized the critical func-
tion of a security-speciﬁc role in the organization (D3). For
example, Xie et al. [40] pointed out that security experts usually
act as security supervisors of the whole development process.
However, Xie et al. [40] also indicated in the same study that
developers might exhibit a more relaxed attitude towards secu-
rity when there are experts to back them up. Moreover, Poller
et al. [41] highlighted that security inspections conducted by
external security consultants become an eye-opener, fostering
awareness among developers about the security topics they
need to look after in their daily work. Furthermore, some
researchers recognized the importance of the awareness of the
social perception of security adoption (D6). For example, when
the whole team is responsible for security, the motivation for
adopting and implementing security could have a snowball
effect and lead to motivating more team members to acknowl-
edge the value of adopting security [43], [44].

Facilitating developers software security adoption. Other re-
searchers have found that organizations play a crucial role in
shaping developers’ attitudes towards security (D8). For instance,
Rauf et al. [35], Jones and Rastogi [36], and Mokhberi and
Beznosov [38] found that developers usually do not perceive the
usefulness of security practices. Their studies highlighted that
most developers might have an attitude that security is some-
one else’s responsibility [35], or perceive it as a hindrance [36],
or in contrast, consider security to be a shared responsibil-
ity [38]. Furthermore, other researchers also emphasized that
interaction through a gamiﬁcation approach is an effective tool
to engage developers in security practices as developers often
enjoy the physical aspects of a game [39].

Several researchers have pointed out tool awareness (D9)
as a relevant driver. For example, the lack of awareness of
security tools and vulnerabilities [35] reduces the likelihood of
developer involvement in security practices. A similar lack of
adoption occurs when organizations do not provide the proper

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

20

TABLE 6
Key drivers associated with the adoption of software security practices that have emerged in the previous literature.

]
8
3
[

v
o
s
o
n
z
e
B
d
n
a

i
r
e
b
h
k
o
M

•
•
•
•
•

•

•

•
•
•
•

•
•
•
•

•

•

•

•
•
•

•

•
•
•
•
•
•

]
7
3
[

.
l
a

t
e

r
e
g
n

i
l
r
e
W

•

•

•

•

•

•

]
6
3
[

i
g
o
t
s
a
R
d
n
a

s
e
n
o
J

•
•
•
•
•

•

•

•
•
•

•

•

•

•

•

•

•
•

18

6

28

]
9
3
[

.
l
a

t
e

z
e
p
o
L

•

•

•
•
•

5

]
5
3
[

.
l
a

t
e

f
u
a
R

•
•

•

•

•

•
•
•
•

•

•

•
•
•

•

•
•
•
•

19

]
4
2
[

.
l
a

t
e

y
e
n
a
H

•

•

•

•

•
•
•

7

]
4
4
[

n
o
s
s
a
i
h
C
d
n
a

l
a
s
s
A

•
•

•

•

•
•

•

•

]
3
4
[

n
o
s
s
a
i
h
C
d
n
a

l
a
s
s
A

•
•
•
•

•

•
•

•

•
•

•

•

•

•

•
•

•
•

]
1
4
[

.
l
a

t
e

r
e
l
l
o
P

•
•
•
•

•

]
2
4
[

.
l
a

t
e

n
a
w
j
a
S

•

•

•

•

]
0
4
[

.
l
a

t
e

e
i
X

•
•

•

•

•

•

•

•

•

•

•

•

•

•

•
•
•

•

•

•

•
•
•

•
•

9

10

14

18

8

]
8
4
[

s
g
a
l
k
s
s
o
r
G
d
n
a

r
e
h
c
s
i
F

]
6
4
[

.
l
a

t
e

r
i
e
W

]
7
4
[

.
l
a

t
e

z
a
r
B

•

•

•

•

5

•

•

•

•

3

•

•

3

]
5
4
[

.
l
a

t
e

a
k
p
i
t
o
V

•

•
•

•

•

•
•

7

s
l
a
t
o
T

6
10
7
6
4

7

5

10
6
3
4

10
1
3
4

7

0

3

6

0
5

3
4
5
1

6
0
5
3
4
5
9
8

Building an organizational security culture

D1
D2
D3
D4
D5

D6

D7

Organization promoting/mandating security
Prioritizing security practices
Having a security-speciﬁc role ﬁlled
Overcoming the resistance to change
Fostering collaboration between engineering and security teams

Awareness of the social perception of security adoption in one’s own
organization and professional network

Providing awareness of external incentives and compliance

Facilitating the adoption of software security by developers

D8
D9
D10
D11

Shaping developer’s attitudes towards security
Tool awareness
Standard guidelines geared at developers
Reduction of system complexity

Understanding risks, beneﬁts, and trade-offs

D12
D13
D14
D15

Awareness of potential risks and security incidents
Learning from actual incidents
Fear of non-adoption consequences
Knowledge of beneﬁts

Providing contextual information to motivate developers to write secure code

D16

Promoting a customer satisfaction/protection mindset

D17

D18

Awareness of the inﬂuential role of the industry type in developers’
disposition towards security compliance

Awareness of developers’ perceptions of the need for software security
based on application characteristics

D19

Aligning the perspective of what "good enough" security means

Providing justiﬁcation for necessary tools and process constraints

D20
D21

Consideration of tool constraints on developers’ autonomy
Awareness of developers’ perception of security-imposed restrictions

Providing (cognitive) support to developers for writing secure code

D22
D23
D24
D25

Availability of reminders, i.e., checklists, dashboards, etc.
Improving the usability (complexity reduction) and accuracy of security tools
Reducing the effort required to learn or apply security
Integrating tools into the development workﬂow

Facilitating developers’ acquisition of security-speciﬁc skills

D26
D27
D28
D29
D30
D31
D32
D33

Accessibility to learning resources
Using security practices as learning tools
Providing security education
Fostering hands-on learning/self-learning/osmosis
Creating and participating in communities of practice
Having non-technical skills
Conﬁdence in their technical abilities
Awareness of necessary security skills

Totals

training for using security tools. As a result, developers usually
use security tools without a complete understanding of tool
functionality [38]. Additionally, a few other researchers have
emphasized the importance of organizations providing stan-
dard guidelines geared at developers (D10) and the reduction of
system complexity. For instance, Mokhberi and Beznosov [38]
reported that developers often face a lack of general security
guidelines and no one in charge of ensuring that those security
requirements are followed.

Understanding risks, beneﬁts, and stakeholders’ trade-offs.
Several researchers have recognized the value of understanding

risks, beneﬁts, and stakeholders’ trade-offs, in particular, the
awareness of potential risks and security incidents (D12). For
instance, Rauf et al. [35] pointed out that developers might
misplace trust on frameworks or third-party APIs. As a result,
developers can introduce vulnerabilities into the source code,
assuming that frameworks or libraries properly handle security
by default. Additionally, Lopez et al. [39] highlighted that pub-
lic incidents enable information trading and risk awareness.
Developers usually build awareness by expanding on technical
information and providing additional scenarios and examples
from their personal experiences.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

Other researchers have emphasized the crucial role of
drivers such as fear of non-adoption consequences (D14) and
knowledge of beneﬁts (D15). For instance, organizations’ se-
curity efforts are less effective when developers perceive a
disinterest in adopting software security practices. This situ-
ation usually happens when there are no perceived negative
consequences to the customers or the business from the lack of
security in the SDLC [44]. Additionally, Assal and Chiasson [43]
highlighted that developers feel motivated to adopt security
practices when they are aware of similar software (to the
one they work on) suffering a security breach—this situation
becomes an “eye-opener” for them. Finally, Mokhberi and
Beznososv [38] recognized that having experienced a real secu-
rity issue (D13) is the primary driver that increases awareness
and concerns about security among developers in the long
run. As a result, adopting security practices and learning about
security mechanisms to protect their code becomes a priority.

Providing contextual
information to motivate developers
to write secure code. Some researchers have emphasized
the relevant role of the organization in providing contextual
information to motivate developers to write secure code. In
particular, Xie et al. [40] highlighted the importance of pro-
moting a customer satisfaction/protection mindset (D16). They
pointed out that a critical motivator for developers is the
concerns of the customer or client: If the customer cares about
security, the company has to care about security. Furthermore,
Poller et al. [41] conﬁrmed a similar result, highlighting that
any feedback from the customer motivates developers to write
secure code. Furthermore, Assal and Chiasson [43] emphasized
that developers who care about their users’ security and privacy
feel encouraged to adopt security practices.

Other researchers have pointed out that aligning the per-
spective of what “good enough” security means (D19) and aware-
ness of developers’ perceptions of the need for software security
(D18) are vital drivers that organizations should pay careful
attention to in order to encourage developers to implement
security practices. For instance, Werlinger et al. [37] highlighted
that developers have to communicate with other stakeholders
that hold different perceptions of risks, sometimes considering
security as a second priority and not having security culture
training. Therefore, developers feel the need to persuade these
stakeholders of the importance of security controls, which
sometimes becomes frustrating. Additionally, Xie et al. [40]
highlighted that developers’ perceptions of the need for software
security (D18) are inﬂuenced by the applications’ characteris-
tics. For instance, they pointed out that middleware developers
might not be concerned about adopting security practices since
they believe security should only be an issue for front-end
applications. Moreover, Assal and Chiasson [43] emphasized
that developers’ perceptions of the need for software security
might be inﬂuenced by false assumptions that the software
they develop is not prone to security attacks. They might also
believe that users will not be technically capable of doing
anything malicious for fear of losing their jobs. Interestingly,
no study reported the importance of developers’ perceptions
and disposition towards security compliance based on the type
of business (D17) they develop software for.

Providing justiﬁcation for necessary tools and process con-
straints. Researchers have agreed that the awareness of develop-
ers’ perception of security-imposed restrictions (D21) is a crucial

21

driver to motivate developers to write secure code. Speciﬁcally,
Jones and Rastogi [36] emphasized that developers perceive
security as a barrier to functionality, adding constraints and
reducing ﬂexibility. Additionally, Xie et al. [40] highlighted that
developers consider security as an expense and potentially
time-consuming activity. So when the budget is limited, soft-
ware security is one of the concerns that can be overlooked.
Furthermore, sometimes developers commonly perceive that
by focusing more on software security, companies might lose
their business opportunities [43]. Surprisingly, we found no
studies that reported the consideration of tool constraints on
developers’ autonomy (D20).

Providing (cognitive) support to developers for writing secure
code. Researchers have recognized that organizations should
provide developers with cognitive support to facilitate the
adoption of security practices. Speciﬁcally, Werlinger et al. [37]
emphasized that developers feel discouraged to adopt security
practices when security tools’ usability and accuracy (D23)
become part of the problem instead of being a facilitator to ﬁx
security vulnerabilities. For instance, they pointed out several
security tool issues that require attention from tool providers,
such as better support for collaboration, decreased complex-
ity, support to disseminate knowledge, ﬂexible reporting, and
better integration of security tools with communication chan-
nels used in an organization. Additionally, other researchers
recognized that reducing the effort required to learn or apply
security (D24) is a relevant driver that organizations should not
overlook. For example, Fischer and Grossklags [48] proposed
encouraging developers to write secure code by providing them
with reminders and recommendations that prioritize security.
In this way, developers would be capable of making safer
choices that lead to writing more secure code. They performed
two experiments that nudged developers while copying/pasting
code from Stack overﬂow and searching for code snippets in
Google.

A few researchers have also highlighted that it is impor-
tant for organizations to integrate tools into the development
workﬂow (D25) [38] and provide developers with reminders
(D22) [35], [48]. For instance, Rauf et al. [35] emphasized that
developers often add security as an afterthought and forget
to give attention to secure coding practices. Therefore, there
is a need to remind developers about security concerns while
developing software. However, Braz et al. [47] highlighted that
during code reviews, developers, despite receiving a tailored
security checklist as a reminder, they can not ﬁnd more vul-
nerabilities than when are just instructed to focus on security
issues. Additionally, Mokhberi and Beznosov [38] acknowledged
that a lack of integration with the development environment
becomes a deterrent for developers to use security tools and
reduces their engagement with security practices.

Facilitating developers’ acquisition of security-speciﬁc skill
sets. Several researchers have highlighted three vital drivers to
motivate developers to write secure code: having conﬁdence
in their technical abilities (D32), an awareness of the necessary
security skill set (D33), and accessibility to learning resources
(D26). For instance, Mokhberi and Beznosov [38] pointed out
the role of personality as one of the human dimensions of
developers’ challenges in engineering secure software. Lack
of conﬁdence and false conﬁdence are reasons developers
mistakenly believe that their code is secure. Thus, they are

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

unable to recognize vulnerabilities in their code. Additionally,
Votipka et al. [45] acknowledged that the primary reason why
teams do not implement security is due to a lack of knowledge
and, above all, experience in different types of vulnerabilities.
Furthermore, Sajwan et al. [42] emphasized that organizations
usually employ traditional training resources and methods that
developers do not feel are practical and actionable. Most of
these learning resources focus on policies and protocols, read-
ing, watching videos, or ofﬁce conversation by either internal
teams or external parties.

Other researchers have highlighted four essential drivers
that inﬂuence developers in the adoption of security prac-
tices: providing security education (D28), having non-technical
skills (D31), creating and participating in communities of
practice (D30), and fostering hands-on learning, self-teaching,
and osmosis (D29). For instance, Weir et al. [46] pointed out
that security-related workshops facilitated by managers appear
more effective than those facilitated by developers or security
specialists. Additionally, Haney et al. [24] emphasized the rele-
vance of having interpersonal skills, in particular, communica-
tion skills for dealing with all stakeholders involved in a security
issue. Furthermore, researchers have reported that knowledge
sharing is crucial for learning security practices. Developers
learn the best from talking to other people in their teams as
they can learn more technical skills while applying existing
knowledge [42]. Researchers have also emphasized the crucial
role of peer-based learning as an effective method to learn
security practices. Developers usually perceive mentoring as an
effective way to understand the rationale behind threats and
techniques to mitigate them [46]. Interestingly, no previous
studies have pointed out the essential role of using security
practices as learning tools (D27).

Comparing and contrasting drivers identiﬁed in our study
with current literature. In the above, we compared the drivers
from our study with those found in the literature we reviewed.

In particular, the Mokhberi and Beznosov’s [38] recent
systematic literature review is the closest to our work. They pre-
sented a set of 17 areas of challenges across three dimensions:
human, organizational, and technological. Their results align
with 28 of our drivers, but they mentioned two factors that did
not emerge from our ﬁndings. First, sometimes responsibilities
and roles deﬁned in the software teams might conﬂict with
applying security, and therefore, developers will not follow
security practices. Second, developers may misuse APIs/libraries,
which leads to decreasing security in an application, making
it easier to exploit. Another study related to our work is the
systematic literature review conducted by Rauf et al. [35]. The
authors presented a catalog of factors that inﬂuence devel-
opers’ security behavior. Their work introduced 17 internal
factors and 11 external factors analyzed from three different
perspectives: knowledge deﬁcit, attention deﬁcit, and intention
deﬁcit. Their set of factors aligns with 19 of our drivers, and
they did not mention any other drivers that we did not ﬁnd in
our study.

As we indicated before, three of our 33 drivers have not
been identiﬁed in the literature we reviewed. They are D17:
awareness of the inﬂuential role of the industry type in develop-
ers’ disposition towards security compliance, D20: consideration
of tool constraints on developers’ autonomy, and D27: using
security practices as learning tools. We were surprised that these

22

drivers did not appear in any of the 15 papers we reviewed (two
of which were quite comprehensive systematic reviews). In the
related literature, we did not ﬁnd any studies that highlighted
how developers’ disposition towards security compliance is
highly inﬂuenced by, what the general industry mindset con-
siders relevant, in terms of security. For example, developers
working in the game industry or chip manufacturing tend to be
more reluctant to adopt software security practices because the
entire industry focuses on security, not at the application level
but the infrastructure level. Additionally, researchers have given
less attention to developers’ perceptions regarding how the use
of tools for security could affect their autonomy. Therefore,
tools can become a deterrent to adopting security due to
the restrictions imposed on developers’ workﬂows. Moreover,
we did not ﬁnd related literature that explores the effects
of security learning when performing security practices, even
though the feedback collected while implementing a security
practice can be a tremendous learning tool for developers.
Section 4 describes these drivers in more detail.

6 DISCUSSION
In this section, we review the implications of our ﬁndings.
First, we discuss the implications for organizations, and our
recommendations for developers and security specialists when
adopting or advocating security practices. Then, we discuss
how researchers can use the power of behavioral theories to
understand and frame research on software security.

6.1 Implications for Organizations

Since organizations play the most crucial role in fostering the
adoption of software security practices, our study pointed to
several recommendations for them. In the following, we discuss
how they can use the DASP framework as a diagnosis tool to
help identify which aspects of their security practices could
be improved. Then, we discuss what organizations need to
consider when understanding the perspectives of developers
and security specialists, and additional considerations they
should be aware of when applying the DASP framework.

6.1.1 How to use the DASP framework

Organizations interested in promoting software security prac-
tices across different teams and stakeholders should carefully
consider developers’ behaviors and identify their perceptions
and attitudes regarding their capabilities, opportunities avail-
able to them, and their motivations for adopting software
security practices. Based on our ﬁndings, we propose DASP,
a framework that consists of a comprehensive list of 33 drivers
that represent what needs to change or happen so that the
adoption of software security practices occurs. In Table 5, we
present the complete list of drivers. Following the Behavior
Change Wheel (BCW) approach, these drivers are the starting
point to design interventions to foster an effective organiza-
tional security culture and motivate developers to write secure
code. As we described in Section 2, we recommend that orga-
nizations use DASP to conduct the steps indicated in Figure 12.

Stage 1: The goal of this stage is to use the DASP framework
to identify which drivers apply to the organization’s particular
context. To achieve this, organizations should conduct focus
groups or semi-structured interviews, considering the perspec-
tives of most stakeholders, from developers to managers. In the

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

23

Fig. 12. The Three Stages of the Behavior Change Wheel including some intervention functions, policy categories, and behavior change techniques,
as indicated in Fig. 1.

case of big corporations, where collecting data could be chal-
lenging due to the signiﬁcant number of stakeholders involved
in ensuring a secure product, another potential mechanism is
to conduct a survey. A survey could help collect the level of
agreement or disagreement concerning the drivers inﬂuencing
stakeholders to adopt software security practices. In the end,
the output of this stage is a subset of drivers that are relatable
to the organization’s context.

Stage 2: The goal of this stage is to identify the most appro-
priate intervention functions and then select their respective
policy categories, which will serve as the foundation to design
and deliver an intervention.

To select the most relevant intervention functions, organi-
zations should use the subset of drivers identiﬁed in Stage 1
to shift from diagnosis to intervention. Organizations need to
build a matrix using the COM-B model components and the
9 intervention functions proposed by the BCW. As detailed in
Section 2, the COM-B model components to take into account
are Technical Capabilities, Non-technical Capabilities, Psycho-
logical Capabilities, Technical Opportunities, Social Opportuni-
ties, Reﬂective Motivations, and Automatic Motivations, and the
intervention functions to consider are Education, Persuasion,
Incentivisation, Coercion, Training, Restriction, Environmental
restructuring, Modeling, and Enablement. By using this ma-
trix, organizations should be able to identify the interven-
tion functions associated with their context. For example, our
study identiﬁed a strong relationship between Training and
Psychological capabilities. Developers perceived that having
tailored security training is crucial for building conﬁdence in
implementing software security practices.

The next step in developing an intervention strategy is to
select the policy categories that can help deliver and implement
the intervention. The BCW indicates which policy categories
are the most suitable in supporting each intervention function.
Following these indications, organizations should select the
most appropriate policy categories associated with their in-
tervention functions. For example, concerning Training, some
essential policy categories are Guidelines, Fiscal measures, Reg-
ulation, Legislation, and Service provision. A complete list of the

7 policy categories and their deﬁnitions is detailed in Table 2.

Stage 3: The goal of this stage is to determine which Behavior
Change Techniques (BCTs) can support the delivery of the
identiﬁed intervention functions under the relevant policy cat-
egories. Michie et al. [12] deﬁnes a BCT as an active component
of an intervention designed to change behavior. BCTs are also
observable, replicable, and irreducible components of an inter-
vention. Michie et al. [27] introduces a taxonomy of 93 BCTs as
a method for specifying interventions. With this knowledge, or-
ganizations may select the most frequently used BCTs for their
particular intervention functions. For example, in the case of
the Training intervention function, some of the most frequently
used BCTs are Feedback on behavior, Feedback on outcome(s) of
behavior, Monitoring of behavior by others without evidence of
feedback, Monitoring of outcome of behavior by others without
evidence of feedback, and Self-monitoring of behavior. For ex-
ample, a description of the content of an intervention would
be “Organizations should set the goal of training developers to
identify potential risks in their source code, enabling them to
understand security standards, associate those standards with
threats and compliant code examples.”

6.1.2 What organizations need to take into account when
understanding developers’ perspectives
Our work revealed several attitudes and beliefs that are useful
for organizations and researchers to understand the developer
mindset behind software security practices. First, developers
often perceive the disadvantages of adopting security more
quickly than the immediate beneﬁts, e.g., time-consuming, de-
lay feature delivery, add restrictions to their workﬂow, etc. De-
velopers’ mindsets typically have the time-pressure concern as
their goals focus on delivering features. If security is not baked
into the development pipeline, it will usually be overlooked if
there are competing priorities. Additionally, developers are in-
ﬂuenced to adopt security practices when other team members
embrace the same practices. However, management becomes
a deterrent if they do not support developers’ proactiveness
towards security. When a security role is present on the team,
developers usually ignore or delegate security practices as they
consider those practices outside their core responsibilities.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

Furthermore, developers might self-assess their security
knowledge and capabilities with high scores. Extensive devel-
opment experience can produce false conﬁdence in the ability
to effectively conduct a security practice without knowing the
necessary security skill set required. Finally, most developers
who are passionate about security have experienced security
exploits in the past. The fear of suffering another attack is
their primary motivation to keep their security knowledge up-
to-date and advocate security concerns among peers. External
events that impact developers’ emotions have a high likelihood
of sticking in a developer’s mind for a longer period of time and
will shape their attitude towards understanding and evaluating
future risks. By default, it is relevant to acknowledge that it
is not part of the developer’s mindset to think upfront about
risks and what could go wrong when customers misuse the
applications they develop. Therefore, it is essential that any
corporate security training highlight these potential scenarios.

6.1.3 What organizations need to take into account when
understanding security specialists’ perspectives

Developers and security professionals have different mindsets.
Security specialists are usually more pessimistic because they
tend to prioritize risks over product features. Moreover, since
security is the day-to-day work for a security professional,
they usually employ technical communication that developers
typically are not familiar with. As a result, their perspectives
concerning the impact of patching a security vulnerability
might considerably differ from developers or engineers. Finally,
since a security professional’s primary focus is on identifying
potential risks/threats and complying with security guidelines,
their biased perspective might make it more challenging to
see the overall impact of any change on the application. This
situation becomes a threat in the organization when security
teams analyze the trade-offs of applying security without the
collaboration of developers and software architects.

6.1.4 Additional considerations organizations should be
aware of when applying the framework

The following considerations were emphasized by our partici-
pants during the member-checking sessions.

A security diagnosis should be conducted periodically. Us-
ing the COM-B model as a diagnosis tool implies identifying
what drives developers to adopt software security practices.
However, practitioners’ perceptions, attitudes, and motivations
can change over time due to external factors or events. In
this scenario, the applicability of speciﬁc drivers to the current
organization’s context could be outdated. Therefore, it is essen-
tial to acknowledge these potential changes and periodically
monitor them to ensure that the strategies or interventions are
not based on inaccurate facts or observations.

A just enough security approach for startup companies. In
the case of startup companies, the concern around adopting
software security practices when developing a product-market
ﬁt is only addressed if the targeted consumer demands it.
Otherwise, other non-functional requirements will have higher
priority. Security specialists recommend startups with limited
resources focus on delivering a just enough secure product, and
if required, invest in training developers in security practices
instead of hiring specialized resources. If available, external

24

incentives, such as IRAP 14 in Canada, may be beneﬁcial to
introduce security testing practices provided by external parties
to guarantee a certain level of quality in terms of security. This
opportunity will also help developers acknowledge their typical
security mistakes and which topics to focus on in their self-
directed security learning process.

Non-technical skills matter. Practitioners highlighted how it
is essential to be aware of the security skill set required
to implement security in the software development pipeline.
Although most of our participants’ ﬁrst thoughts pointed out
several security technical skills, they also mentioned different
challenges related to interpersonal skills that, surprisingly, are
usually not discussed in organizational security training. And
when overlooked, it could seriously impact how security is han-
dled within the organization, especially when multiple stake-
holders are involved in security decisions and product devel-
opment. It is worth mentioning that most security challenges
are indirectly related to conﬂict management, negotiation skills,
communication ability, and empathy. Therefore, we encourage
organizations to include topics related to non-technical skills
as part of any security training program, which is helpful in the
context of security and boosts collaboration and productivity
in the company.

6.2 Recommendations for Developers When Adopting
Security Practices

In addition to organizational recommendations, the drivers
identiﬁed in our study point to speciﬁc recommendations for
developers:

• Passionate software developers care about the quality of
their code. Security is an essential quality aspect of any
software product, and its adoption gradually grows with
experience. In addition, when learning a new software
technology, e.g., a programming language or a framework,
developers should take the necessary time to learn how to
use it securely, not just assume that default conﬁgurations
or standard ways to use it are secure.

• If security is not part of the organizational culture, this can
be an excellent opportunity to advocate the relevance of
baking security into the development workﬂow. Develop-
ers should look for sponsorship at the management level.
With management’s support, any effort towards security
will be more straightforward and signiﬁcant.

• When advocating for security, there can be some re-
luctance to change. Different stakeholders have different
perspectives and priorities regarding security. To advocate
for security more effectively, developers need to acquire
the ability to translate security threats into technical and
business risks. Arguments based on risks are more com-
pelling and easier to understand.

• The adoption of security practices has an undeniable
social connotation. It is recommended that developers
start advocating for security among their peers. Raising
a collective need or concern for security from engineering
teams will signiﬁcantly impact management levels more
than any individual approach.

• Including security in the software development pipeline
introduces several policies and restrictions around tools,

14. https://nrc.canada.ca/en/support-technology-innovation/about-

nrcindustrial-research-assistance-program

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

25

frameworks, and open-source components. Developers
should recognize that having full autonomy in technical
decisions will cause a chaotic development environment,
making it challenging for any stakeholder to ensure a
secure development workﬂow and product.

• Developers should leverage their current working environ-
ment to customize their learning path. The presence of a
security-speciﬁc role in the organization willing to mentor
through peer-to-peer learning or osmosis is a practical and
valuable learning approach. For example, some realistic
scenarios are developers shadowing a security specialist or
being indirectly involved in ﬁxing security vulnerabilities.
• Developers should take advantage of software security
practices conducted within the organization. They are an
important opportunity for developers to follow a learning-
by-doing approach, master software security skills, and
receive actionable feedback to improve their development
practices, e.g., through security code reviews.

• We recommend developers participate in communities of
practice led by software security professionals. They are an
active community in the industry, continuously organizing
meet-ups, conferences, and workshops where they share
valuable security resources and their experiences dealing
with security vulnerabilities.

• We recommend developers use software security practices
such as code reviews to self-assess their software security
skills. Feedback from security code reviews can help devel-
opers identify ﬂaws in their coding practices and suggest
topics to include in an organizational security training
program.

• Conﬁdence in performing software security tasks is an
essential aspect that developers achieve through proper
training and experience. However, developers should be
aware that overconﬁdence is a deterrent to improving their
security practices, assimilating feedback, and maintaining
the knowledge required to deal with security exploits that
are getting more sophisticated and harmful.

6.3 Recommendations for Security Specialists When
Advocating for Security

The drivers we identiﬁed in our study also suggest a number of
recommendations for security specialists:

• The developers in our study perceived that most security
guidelines are abstract and not developer friendly. We
suggest security specialists facilitate the comprehension
of security guidelines by highlighting the relationship
between security threats, non-compliant code examples,
and compliant solutions. In other words, when designing
security guidelines, security professionals should use a
technical vocabulary that developers are more familiar
with.

• Most developers typically access Q&A forums, e.g., Stack
Overﬂow15, to gather knowledge, share expertise, and
address security and development concerns. Therefore,
security professionals should proactively approach Q&A
forums to get one step closer to developers’ communities,
advocating for security while interacting with developers
by building awareness of security tools, potential security

15. https://stackoverﬂow.com/

threats, and the risks of overlooking secure coding prac-
tices.

• Developers demand tailored security training that reﬂects
their particular information needs and software develop-
ment context. Developers perceive generic security train-
ing as too abstract, time-consuming, and ineffective. When
designing security training to meet developers’ needs,
security teams or security specialists should identify devel-
opers’ typical security mistakes through their interactions
with engineering teams. For example, the interactions
during security code reviews can be a valuable source of
information.

• Developers who are passionate about security are usu-
ally self-taught software security practitioners. However,
the amount of resources and topics to learn is typically
overwhelming. Therefore, security teams should facilitate
developers’ learning process by allowing them to know the
rationale behind the compliance with security guidelines
and the necessary skills to tackle their typical security mis-
takes. In this way, developers will learn faster, remember
security guidelines easier, gradually build conﬁdence in
their technical skills, and reduce the chance of repeating
the same security mistakes.

6.4 The Power of Behavioral Theories for Software Se-
curity Researchers

Our work is related to developer-centric security research. Since
software development is intensely human driven, researchers
must consider developers’ behaviors, attitudes, beliefs, per-
ceptions, and motivations to introduce any positive change
in software engineering practices. Our study highlights the
opportunity for the software engineering research community
to analyze software security challenges through the lens of
behavioral science theories. Most efforts from industry and
academia in the area of software security has focused on
providing exceptional security standards, sophisticated security
tools, free online learning resources, understanding the effec-
tiveness of having speciﬁc security roles in the engineering
teams, and encouraging shifting security to the left or earlier
stages of the software development pipeline. However, little
attention has been dedicated to allowing organizations to
design effective interventions to foster the adoption of software
security practices among developers.

Additionally, our work exposes a holistic view of all behav-
ioral aspects that affect how developers adopt a target behavior,
such as capabilities, opportunities, and motivations. Developers
will be willing to adopt a new practice if they feel conﬁdent and
capable of doing it, have the right opportunities and conditions
in their work environment, and feel motivated to perform the
target behavior. Our study opens the door to further research to
introduce behavior change techniques to understand developer
and other stakeholder behaviors. This knowledge will serve as
the foundation to design interventions to motivate them to
adopt software security practices.

7 THREATS TO VALIDITY

In the following, we address the validity of this study in the
context of qualitative research [16], [17].

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

26

7.1 Transferability

Transferability is the degree to which we can transfer our results
to other contexts. Our study was based on semi-structured in-
terviews gathering the experiences of 28 software engineers and
security specialists. Given that their experiences, companies,
technology stacks, and business domains varied considerably,
the drivers identiﬁed in our study should ﬁt most software
development organizations. However, we did not include open-
source developers in our work, geographical and cultural de-
terminants to analyze our data, such as cultural differences
in power distance and individualism-collectivism [50]. In addi-
tion, we did not consider group dynamics that might inﬂuence
security adoption, such as organization identity, organization
climate, and culture [51]. Therefore, we suggest future research
to understand whether the open-source community considers
our ﬁndings relevant for their context and how geographical,
cultural, and group dynamics-related factors may inﬂuence
developers’ adoption of security practices.

7.2 Credibility

Credibility concerns whether the research ﬁndings are correctly
drawn from the original data. We applied three strategies to
ensure credibility: (a) the list of drivers was iteratively devel-
oped by two researchers and examined by an expert reviewer
in each iteration. In addition, two researchers performed the
open coding of the transcribed interview data. At the beginning
of the open coding process, two open coding iterations were
conducted to align the perspectives of both researchers. After
achieving at least 75% inter-rater agreement, both researchers
started coding independently, then (b) the set of drivers, cat-
egories, and ﬁndings were discussed several times between all
the authors of this paper to mitigate bias from any particular
researcher involved in the study, and (c) the drivers were
validated through 12 member-checking sessions.

7.3 Conﬁrmability

Conﬁrmability is the degree to which other researchers can
conﬁrm the ﬁndings. We do not have the participants’ permis-
sion to share the transcriptions of the interviews. However, we
tried to show as much evidence as possible for each driver by
quoting participants when describing our results. Our interview
script is available in our online appendix [49].

8 CONCLUSIONS
Adopting software security practices is a signiﬁcant concern
for any industry. The exponential
increase in security vul-
nerabilities exploited by malicious hackers pushes the need
to understand why software security is neglected and why
developers persist in introducing security ﬂaws into their ap-
plications. In this study, using the lens of the COM-B model,
we systematically explore what needs to change or happen
so the adoption of software security practices occurs. As a
result, we propose DASP, which consists of a comprehensive
set of 33 drivers that describes the software security adoption
phenomena. Our work is the ﬁrst to introduce a behavioral
change approach to understand developers’ behaviors when
adopting software security practices. Using DASP as a starting
point, we foresee that organizations will be able to design
appropriately geared interventions following the Behavioral

Change Wheel framework. We hope our study insights will help
organizations help developers write better, more secure code,
ensuring a reliable and secure software product.

ACKNOWLEDGMENTS
The authors would like to thank the 28 interviewees for their
availability in this study, Dr. James Gibson for his remarkable
insights in behavioral psychology at the beginning of our study,
and the members of the CHISEL group at UVic for their
invaluable feedback. We also acknowledge the support of the
Natural Sciences and Engineering Research Council of Canada
(NSERC).

REFERENCES

[1] NIST, National vulnerability database, 2021, accessed: 2021-10-04. [On-

line]. Available: https://nvd.nist.gov

[2] State

of

Software

2021,
https://www.veracode.com/blog/research/announcing-state-software-
security-v11-open-source-edition, Accessed: 2021-10-05.

Security

Volume

11,

-

[3] The Daily Swig, https://portswigger.net/daily-swig/malicious-hackers-
are-exploiting-known-vulnerabilities-because-organizations-arent-
quick-enough-to-patch-report, Accessed: 2021-10-05.

[4] J. van der Pligt and M. Vliek, The psychology of inﬂuence: Theory,

research and practice, Routledge/Taylor & Francis Group, 2017.

[5] C. I. Hovland, , I. L. Janis, and H. H. Kelley, (1953). Communication and
persuasion: psychological studies of opinion change, New Haven: Yale
University Press.

[6] M. Fishbein and J. Ajzen, (1975), Belief, attitude, intention and behavior:

an introduction to theory and research, MA: Addison-Wesley.

[7] N. K. Janz, and M. H. Becker, (1984), The health belief model: A decade

later, Health education quarterly, 11(1), 1-47.

[8] D. Kahneman and A. Tversky, (1979), Prospect theory: an analysis of

decisions under risk, Econometrica,47, 263–291.

[9] F. Strack and R. Deutsch, (2004), Reﬂective and impulsive determinants
of social behavior, Personality and social psychology review, 8(3), 220-
247.

[10] A. Bandura, (1982), Self-efﬁcacy mechanism in human agency, Ameri-

can psychologist, 37(2), 122-127.

[11] S. Michie, M. M. van Stralen, R. West, The behaviour change wheel:
a new method for characterising and designing behaviour change in-
terventions, Implement Sci., 2011, doi: 10.1186/1748-5908-6-42. PMID:
21513547; PMCID: PMC3096582.

[12] S. Michie, L. Atkins, and R. West, The behaviour change wheel: A guide

to designing interventions, 1st ed., London: Silverback, 2014

[13] F. Barker, L. Atkins, S. de Lusignan, Applying the COM-B behaviour
model and behaviour change wheel to develop an intervention to
improve hearing-aid use in adult auditory rehabilitation, Int J Audiol,
2016, doi: 10.3109/14992027.2015.1120894. Epub 2016 Jan 12. PMID:
27420547.

[14] J. W. Creswell, Research design: Qualitative, quantitative, and mixed

methods approaches, Sage, 2013.

[15] H. H. Hiller and L. DiLuzio, The Interviewee and the Research
Interview: Analysing a Neglected Dimension in Research. Cana-
dian Review of Sociology and Anthropology, 41(1), 1–26, 2004,
https://doi.org/10.1111/j.1755-618X.2004.tb02167.x

[16] E.G. Guba, Criteria for assessing the trustworthiness of naturalistic

inquiries, 75, 1981, https://doi.org/10.1007/BF02766777

[17] I. Korstjens, A. Moser, Series: Practical guidance to qualitative research.
Part 4: Trustworthiness and publishing, 2018 Dec;24(1):120-124. doi:
10.1080/13814788.2017.1375092.

[18] I. Etikan, S. A. Musa, R. S. Alkassim, Comparison of Conve-
nience Sampling and Purposive Sampling, American Journal of The-
oretical and Applied Statistics. Vol. 5, No. 1, 2016, pp. 1-4. doi:
10.11648/j.ajtas.20160501.11

[19] S. E. Hove and B. Anda, Experiences from conducting semi-structured
interviews in empirical software engineering research, 11th IEEE Inter-
national Software Metrics Symposium (METRICS’05), 2005, pp. 10 pp.-
23, doi: 10.1109/METRICS.2005.24.

[20] D. S. Cruzes and T. Dyba, Recommended Steps for Thematic Synthesis
in Software Engineering, 2011 International Symposium on Empiri-
cal Software Engineering and Measurement, 2011, pp. 275-284, doi:
10.1109/ESEM.2011.36.

JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015

27

[42] L. Sajwan, J. Noble, C. Anslow, R. Biddle, Why do Programmers
do What they do? A Theory of Inﬂuences on Security Practices, In
Proceedings of the HATS Workshop on Usable Security and Privacy
(USEC), 2021.

[43] H. Assal, S. Chiasson, Think secure from the beginning: A Survey
with Software Developers, Proceedings of the 2019 CHI Conference
on Human Factors in Computing Systems, Association for Com-
puting Machinery, New York, NY, USA, Paper 289, 1–13, 2019. doi:
10.1145/3290605.3300519

[44] H. Assal, S. Chiasson, Motivations and Amotivations for Software

Security, 2018.

[45] D. Votipka, K.R Fulton, J. Parker, M. Hou, M.L. Mazurek, M.W. Hicks,
Understanding security mistakes developers make: Qualitative analysis
from Build It, Break It, Fix It, USENIX Security Symposium, 2020.
[46] C. Weir, I. Becker, L. Blair, A Passion for Security: Intervening to
Help Software Developers, IEEE/ACM 43rd International Conference
on Software Engineering: Software Engineering in Practice (ICSE-SEIP),
2021, pp. 21-30, doi: 10.1109/ICSE-SEIP52600.2021.00011.

[47] L. Braz, C. Aeberhard, G. Çalikli, A. Bacchelli, Less is More: Supporting
Developers in Vulnerability Detection during Code Review, IEEE/ACM
44th International Conference on Software Engineering (ICSE), 2022,
doi: 10.1145/3510003.3511560.

[48] F. Fischer, J. Grossklags, Nudging Software Developers Toward Secure
Code, in IEEE Security & Privacy, vol. 20, no. 02, pp. 76-79, 2022, doi:
10.1109/MSEC.2022.3142337.

[49] E. Larios-Vargas, O. Elazhary, S. Youseﬁ, D. Lowlind, M. L. W. Vliek,
and Margaret-Anne D. Storey. (2022). DASP: A Framework for Driving
the Adoption of Software Security Practices (v1.0), [Appendix]. Zenodo.
https://doi.org/10.5281/zenodo.6502947

[50] V. Taras, B. L. Kirkman, and P. Steel, (2010), Examining the impact
of Culture’s consequences: a three-decade, multilevel, meta-analytic
review of Hofstede’s cultural value dimensions, The Journal of applied
psychology, 95(3), 405–439. https://doi.org/10.1037/a0018938

[51] B. Schneider, M. Ehrhart, and W. Macey, (2012), Organizational Cli-
mate and Culture, Annual review of psychology. 64. 10.1146/annurev-
psych-113011-143809.

[21] J.M. Corbin, A. Strauss, Grounded theory research: Procedures,
criteria, Qual Sociol 13, 3–21 (1990).

canons, and evaluative
https://doi.org/10.1007/BF00988593

[22] M. B. Miles, A. M. Huberman, and J. Saldana, Qualitative data analysis:

A methods sourcebook, 2014.

[23] A. L. Strauss and J. M. Corbin, Grounded theory in practice, Sage

Publications, Inc, 1997.

[24] J. Haney, W. Lutters and J. Jacobs, Cybersecurity Advocates: Force
Multipliers in Security Behavior Change, in IEEE Security & Privacy, vol.
19, no. 4, pp. 54-59, July-Aug. 2021, doi: 10.1109/MSEC.2021.3077405.

[25] J. Haney and W. Lutters, Security Awareness Training for the Workforce:
Moving Beyond “Check-the-Box” Compliance, in Computer, vol. 53, no.
10, pp. 91-95, Oct. 2020, doi: 10.1109/MC.2020.3001959.

[26] S. Michie, L. Atkins, and H.L. Gainforth, Changing Behaviour to

Improve Clinical Practice and Policy, 2016.

[27] S. Michie, M. Richardson, M. Johnston, C. Abraham, J. Francis, W.
Hardeman, MP Eccles, J. Cane, CE. Wood CE, The behavior change tech-
nique taxonomy (v1) of 93 hierarchically clustered techniques: building
an international consensus for the reporting of behavior change inter-
ventions. Ann Behav Med, 2013, Aug;46(1):81-95. doi: 10.1007/s12160-
013-9486-6. PMID: 23512568.

[28] A. Bandura, Self-efﬁcacy, In V. S. Ramachaudran (Ed.), Encyclopedia
of human behavior (Vol. 4, pp. 71-81). New York: Academic Press.
(Reprinted in H. Friedman[Ed.], Encyclopedia of mental health. San
Diego: Academic Press, 1998).

[29] A. Bandura, Self-efﬁcacy: Toward a unifying theory of behavioral
change, Advances in Behaviour Research and Therapy, Volume 1, Issue
4, 1978, Pages 139-161, ISSN 0146-6402, https://doi.org/10.1016/0146-
6402(78)90002-4.

[30] A. D. Stajkovic, F. Luthans, Social cognitive theory and self-efﬁcacy:
Going beyond traditional motivational and behavioral approaches,
Organizational Dynamics, Volume 26, Issue 4, 1998, Pages 62-74, ISSN
0090-2616, https://doi.org/10.1016/S0090-2616(98)90006-7.

[31] R. W. Rogers, 1975. A Protection Motivation Theory of Fear Ap-
peals and Attitude Change, Journal of Psychology (91), pp.93-114,
https://doi.org/10.1080/00223980.1975.9915803

[32] K. Witte, and M. Allen, (2000), A meta-analysis of fear appeals:
implications for effective public health campaigns, Health education
& behavior : the ofﬁcial publication of the Society for Public Health Ed-
ucation, 27(5), 591–615. https://doi.org/10.1177/109019810002700506

[33] I. Ajzen, (1991), The theory of planned behavior, Organizational Be-

havior and Human Decision Processes, 50(2), 179-211.

[34] C. Carver and M. Scheier, (1982), Control theory: A useful conceptual
framework for personality-social, clinical, and health psychology, Psy-
chological bulletin. 92. 111-35. 10.1037/0033-2909.92.1.111.

[35] I. Rauf, M. Petre, T. Tun, T. Lopez, P. Lunn, D. Van Der Linden, J. Towse,
H. Sharp, M. Levine, A. Rashid, and B. Nuseibeh, The Case for Adaptive
Security Interventions, ACM Trans. Softw. Eng. Methodol. 31, 1, Article
9 (January 2022), 52 pages. DOI:https://doi.org/10.1145/3471930
[36] R. Jones, A. Rastogi, Secure Coding: Building Security into the Software
Development Life Cycle, Information Systems Security. 13. 29-39, 2004,
doi: 10.1201/1086/44797.13.5.20041101/84907.5.

[37] R. Werlinger, K. Hawkey, D. Botta, K. Beznosov, Security practitioners in
context: Their activities and interactions with other stakeholders within
organizations, International Journal of Human-Computer Studies, 67.
584-606, 2009, doi: 10.1016/j.ijhcs.2009.03.002.

[38] A. Mokhberi, K. Beznosov, SoK: Human, Organizational, and Tech-
nological Dimensions of Developers’ Challenges in Engineering Secure
Software, In European Symposium on Usable Security - EuroUSEC
2021, Association for Computing Machinery, New York, NY, USA, 59–75,
2021, doi: 10.1145/3481357.3481522

[39] T. Lopez, H. Sharp, T. Tun, A. Bandara, M. Levine, B. Nuseibeh, Talking
About Security with Professional Developers, IEEE/ACM Joint 7th Inter-
national Workshop on Conducting Empirical Studies in Industry (CESI)
and 6th International Workshop on Software Engineering Research and
Industrial Practice (SER&IP), 2019, pp. 34-40, doi: 10.1109/CESSER-
IP.2019.00014.

[40] J. Xie, H.R. Lipford, B. Chu, Why do programmers make security errors?,
IEEE Symposium on Visual Languages and Human-Centric Computing
(VL/HCC), 161-164, 2011.

[41] A. Poller, L. Kocksch, S. Turpe, F. Anand Epp, K. Kinder-Kurlanda,
Can Security Become a Routine? A Study of Organizational Change
in an Agile Software Development Group, In Proceedings of the 2017
ACM Conference on Computer Supported Cooperative Work and Social
Computing - CSCW 2017, Association for Computing Machinery, New
York, NY, USA, 2489–2503, 2017, doi: 10.1145/2998181.2998191

