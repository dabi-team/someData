2
2
0
2

n
u
J

0
3

]
E
N
.
s
c
[

1
v
8
3
2
5
1
.
6
0
2
2
:
v
i
X
r
a

Runtime Analysis of Competitive co-Evolutionary
Algorithms for Maximin Optimisation
of a Bilinear Function∗

Per Kristian Lehre

School of Computer Science
University of Birmingham
United Kingdom

July 1, 2022

Abstract

Co-evolutionary algorithms have a wide range of applications, such as
in hardware design, evolution of strategies for board games, and patching
software bugs. However, these algorithms are poorly understood and ap-
plications are often limited by pathological behaviour, such as loss of gra-
dient, relative over-generalisation, and mediocre objective stasis. It is an
open challenge to develop a theory that can predict when co-evolutionary
algorithms ﬁnd solutions eﬃciently and reliable.

This paper provides a ﬁrst step in developing runtime analysis for
population-based competitive co-evolutionary algorithms. We provide a
mathematical framework for describing and reasoning about the perfor-
mance of co-evolutionary processes. An example application of the frame-
work shows a scenario where a simple co-evolutionary algorithm obtains a
solution in polynomial expected time. Finally, we describe settings where
the co-evolutionary algorithm needs exponential time with overwhelm-
ingly high probability to obtain a solution.

1

Introduction

Many real-world optimisation problems feature a strategic aspect, where the so-
lution quality depends on the actions of other – potentially adversarial – players.
There is a need for adversarial optimisation algorithms that operate under re-
alistic assumptions. Departing from a traditional game theoretic setting, we
assume two classes of players, choosing strategies from “strategy spaces” X and

∗To appear in Proceedings of the Genetic and Evolutionary Computation Conference

(GECCO’ 22).

1

 
 
 
 
 
 
Y respectively. The objectives of the players are to maximise their individual
“payoﬀs” as given by payoﬀ functions f, g : X × Y → R.

A fundamental algorithmic assumption is that there is insuﬃcient compu-
tational resources available to exhaustively explore the strategy spaces X and
Y. In a typical real world scenario, a strategy could consist of making n bi-
nary decisions. This leads to exponentially large and discrete strategy spaces
X = Y = {0, 1}n. Furthermore, we can assume that the players do not have
access to or the capability to understand the payoﬀ functions. However, it
is reasonable to assume that players can make repeated queries to the payoﬀ
function Fearnley and Savani (2016). Together, these assumptions render many
existing approaches impractical, e.g., Lemke-Howson, best response dynamics,
mathematical programming, or gradient descent-ascent.

Co-evolutionary algorithms (CoEAs) (see (Popovici et al., 2012) for a sur-
vey) could have a potential in adversarial optimisation, partly because they
make less strict assumptions than the classical methods. Two populations are
co-evolved (say one in X , the other in Y), where individuals are selected for
reproduction if they interact successfully with individuals in the opposite popu-
lation (e.g. as determined by the payoﬀ functions f, g). The hoped for outcome
is that an artiﬁcial “arms race” emerges between the populations, leading to
increasingly sophisticated solutions. In fact, the literature describe several suc-
cessful applications, including design of sorting networks Hillis (1990), software
patching Arcuri and Yao (2008), and problems arising in cyber security O’Reilly
et al. (2020).

It is common to separate co-evolution into co-operative and competitive co-
evolution. Co-operative co-evolution is attractive when the problem domain
allows a natural division into sub-components. For example, the design of a
robot can be separated into its morphology and its control Pollack et al. (2001).
A cooperative co-evolutionary algorithm works by evolving separate “species”,
where each species is responsible for optimising one sub-component of the overall
solution. To evaluate the ﬁtness of a sub-component, it is combined with sub-
components from the other species to form a complete solution. Ideally, there
will be a selective pressure for the species to cooperate, so that they together
produce good overall designs Potter and Jong (2000).

The behaviour of CoEAs can be abstruse, where pathological population
behaviour such as loss of gradient, focusing on the wrong things, and relativism
Watson and Pollack (2001) prevent eﬀective applications. It has been a long-
standing open problem to develop a theory that can explain and predict the
performance of co-evolutionary algorithms (see e.g. Section 4.2.2 in Popovici
et al. (2012)), notably runtime analysis. Runtime analysis of EAs Doerr and
Neumann (2020) have provided mathematically rigorous statements about the
runtime distribution of evolutionary algorithms, notably how the distribution
depends on characteristics of the ﬁtness landscape and the parameter settings
of the algorithm.

The only rigorous runtime analysis of co-evolution the author is aware of fo-
cuses on co-operative co-evolution. In a pioneer study, Jansen and Wiegand con-
sidered the common assumption that co-operative co-evolution allows a speedup

2

for separable problems Jansen and Wiegand (2004). They compared rigorously
the runtime of the co-operative co-evolutionary (1+1) Evolutionary Algorithm
(CC (1+1) EA) with the classical (1+1) EA. Both algorithms follow the same
template: They keep the single best solution seen so far, and iteratively pro-
duce new candidate solution by “mutating” the best solution. However, the
algorithms use diﬀerent mutation operators. The CC (1+1) EA restricts mu-
tation to the bit-positions within one out of k blocks in each iteration. The
choice of the current block alternates deterministically in each iteration, such
that in k iterations, every block has been active once. The main conclusion
from their analysis is that problem separability is not a suﬃcient criterion to
determine whether the CC (1+1) EA performs better than the (1+1) EA. In
particular, there are separable problems where the (1+1) EA outperforms the
CC (1+1) EA, and there are inseparable problems where the converse holds.
What the authors ﬁnd is that CC (1+1) EA is advantageous when the problem
separability matches the partitioning in the algorithm, and there is a beneﬁt
from increased mutation rates allowed by the CC (1+1) EA.

Much work remains to develop runtime analysis of co-evolution. Co-operative
co-evolution can be seen as a particular approach to traditional optimisation,
where the goal is to maximise a given objective function.
In contrast, com-
petitive co-evolutionary algorithms are employed for a wide range of solution
concepts Ficici (2004). It is unclear to what degree results about co-operative
CoEAs can provide insights about competitive CoEAs. Finally, the existing
runtime analysis considers the CC (1+1) EA which does not have a popula-
tion. However, it is particularly important to study co-evolutionary population
dynamics to understand the pathologies of existing CoEAs.

This paper makes the following contributions: Section 2 introduces a generic
mathematical framework to describe a large class of co-evolutionary processes.
We then discuss how the population-dynamics of these processes can be de-
scribed by a stochastic process. Section 3 deﬁnes “runtime” in the context of
generic co-evolutionary processes and presents an analytical tool (a co-evolutionary
level-based theorem) which can be used to derive upper bounds on the expected
runtime. Section 4 specialises the problem setting to maximin-optimisation,
and introduces a theoretical benchmark problem Bilinear which we envisage
could play the role of OneMax for traditional runtime analysis. Section 5 in-
troduces the algorithm PD-CoEA which is a particular co-evolutionary process
tailored to maximin-optimisation. We then analyse the runtime of PD-CoEA on
Bilinear using the level-based theorem, showing that there are settings where
the algorithm obtains a solution in polynomial time. Finally, in Section 6 we
demonstrate that the PD-CoEA possesses an “error threshold”, i.e., a mutation
rate above which the runtime is exponential for any problem. Due to space
limitations, substantial parts of the technical analysis have been moved to the
appendix.

3

1.1 Preliminaries

For any natural number n ∈ N, we deﬁne [n] := {1, 2, . . . , n} and [0..n] :=
{0}∪[n]. For a ﬁltration (Ft)t∈N and a random variable X we use the shorthand
notation Et [X] := E [X | Ft]. A random variable X is said to stochastically
dominate a random variable Y , denoted X (cid:23) Y , if and only if Pr (Y ≤ z) ≥
Pr (X ≤ z) for all z ∈ R. The Hamming distance between two bitstrings x and
y is denoted H(x, y). For any bitstring z ∈ {0, 1}n, |z| := (cid:80)n
i=1 zi, denotes the
number of 1-bits in z.

2 Co-Evolutionary Algorithms

This section describes in mathematical terms a broad class of co-evolutionary
processes (Algorithm 1). The deﬁnition takes inspiration from level-processes
(see Algorithm 1 in Corus et al. (2018)) used to describe non-elitist evolutionary
algorithms.

Algorithm 1 Co-evolutionary Process
Require: Population size λ ∈ N and strategy spaces X and Y.
Require: Initial populations P0 ∈ X λ and Q0 ∈ Y λ.
1: for each generation number t ∈ N0 do
2:

for each interaction number i ∈ [λ] do

Sample an interaction (x, y) ∼ D(Pt, Qt).
Set Pt+1(i) := x and Qt+1(i) := y.

3:
4:
5:
6: end for

end for

We assume that in each generation, the algorithm has two1 populations
P ∈ X λ and Q ∈ Y λ which we sometimes will refer to as the “predators”
and the “prey”. We posit that in each generation, the populations interact λ
times, where each interaction produces in a stochastic fashion one new predator
x ∈ X and one new prey y ∈ Y. The interaction is modelled as a probability
distribution D(P, Q) over X × Y that depends on the current populations. For
a given instance of the framework, the operator D encapsulates all aspects that
take place in producing new oﬀspring, such as pairing of individuals, selection,
mutation, crossover, etc. (See Section 5 for a particular instance of D).

As is customary in the theory of evolutionary computation, the deﬁnition
of the algorithm does not state any termination criterion. The justiﬁcation for
this omission is that the choice of termination criterion does not impact the
deﬁnition of runtime we will use.

Notice that the predator and the prey produced through one interaction are
not necessarily independent random variables. However, each of the λ inter-
actions in one generation are independent and identically distributed random
variables.

1The framework can be generalised to more populations.

4

2.1 Tracking the algorithm state

We will now discuss how the state of Algorithm 1 can be captured with a
stochastic process. To determine the trajectory of a co-evolutionary algorithm,
it is insuﬃcient to track only one of the populations, as the dynamics of the
algorithm is determined by the relationship between the two populations.

We shall see that it will be convenient to describe the state of the algorithm
via the Cartesian product Pt × Qt. In particular, for subsets A ⊂ X and B ⊂ Y ,
we will study the drift of the stochastic process Zt := |(Pt × Qt) ∩ (A × B)|.
Naturally, there will be multiple probability dependencies among the λ2 pairs in
the product Pt × Qt. In order to not have to explicitly take these dependencies
into account later in the paper, we now characterise properties of the distribution
of Zt in Lemma 1.

Lemma 1. Given subsets A ⊂ X , B ⊂ Y, assume that for any δ > 0 and
γ ∈ (0, 1), the sample (x, y) ∼ D(Pt, Qt) satisﬁes

Pr (x ∈ A) Pr (y ∈ B) ≥ (1 + δ)γ.

Then the random variable Zt+1 := |(Pt+1 × Qt+1) ∩ A × B| satisﬁes
1) Et [Zt+1] ≥ λ(λ − 1)(1 + δ)γ.
2) Et

(cid:2)e−ηZt+1(cid:3) ≤ e−ηλ(γλ−1) for 0 < η ≤ (1 − (1 + δ)−1/2)/λ

3) Pr t (Zt+1 < λ(γλ − 1)) ≤ e

−δ1γλ

(cid:18)

(cid:113) 1+δ1
1+δ

1−

(cid:19)

for δ1 ∈ (0, δ).

Proof. In generation t + 1, the algorithm samples independently and identically
λ pairs (Pt+1(i), Qt+1(i))i∈[λ] from distribution D(Pt, Qt). For all i ∈ [λ], deﬁne
:= 1{Qt+1(i)∈B}. Then since
the random variables X (cid:48)
the algorithm samples each pair (Pt+1(i), Qt+1(i)) independently, and by the
assumption of the lemma, there exists p, q ∈ (0, 1] such that X (cid:48) := (cid:80)λ
i ∼
Bin(λ, p), and Y (cid:48) := (cid:80)λ
i ∼ Bin(λ, q), where pq ≥ γ(1 + δ). By these
deﬁnitions, it follows that Zt+1 = X (cid:48)Y (cid:48).

i := 1{Pt+1(i)∈A} and Y (cid:48)
i

i=1 X (cid:48)

i=1 Y (cid:48)

Note that X (cid:48) and Y (cid:48) are not necessarily independent random variables be-
cause X (cid:48)
i are not necessarily independent. However, by deﬁning two
independent binomial random variables X ∼ Bin(λ, p), and Y ∼ Bin(λ, q), we
readily have the stochastic dominance relation

i and Y (cid:48)

Zt+1 = X (cid:48)Y (cid:48) (cid:23) XY −

λ
(cid:88)

i=1

XiYi.

(1)

The ﬁrst statement of the lemma is now obtained by exploiting (1), Lemma 27,

and the independence between X and Y

(cid:34)

Et [Zt+1] ≥ E

XY −

λ
(cid:88)

i=1

(cid:35)

XiYi

= E [X] E [Y ] −

λ
(cid:88)

i=1

E [Xi] Et [Yi]

= pλqλ − λpq = pqλ(λ − 1) ≥ (1 + δ)γλ(λ − 1).

5

√

For the second statement, we apply Lemma 18 wrt X, Y , and the parameters
1 + δ − 1 and z := γ. By the assumption on p and q, we have pq ≥

σ :=
(1 + δ)γ = (1 + σ)2z, furthermore the constraint on parameter η gives
(cid:19)

√

(cid:18)

η ≤

1 −

√

=

1
1 + δ

1 + δ − 1
√
1 + δ
λ

=

σ
(1 + σ)λ

.

1
λ

The assumptions of Lemma 18 are satisﬁed, and we obtain from (1)
(cid:32)

(cid:33)(cid:35)

(cid:34)

Et

(cid:2)e−ηZt+1(cid:3) ≤ E

exp

−ηXY + η

XiYi

λ
(cid:88)

< eηλ · E (cid:2)e−ηXY (cid:3) < eηλ · e−ηγλ2

= e−ηλ(γλ−1).

i=1

Given the second statement, the third statement will be proved by a standard
Chernoﬀ-type argument. Deﬁne δ2 > 0 such that (1 + δ1)(1 + δ2) = 1 + δ. For

η :=

(cid:18)

1 −

1
λ

√

1
1 + δ2

(cid:19)

=

1
λ

(cid:32)

1 −

(cid:33)

(cid:114) 1 + δ1
1 + δ

and a := λ(γλ − 1), it follows by Markov’s inequality

Pr t (Zt+1 ≤ a) = Pr t

(cid:0)e−ηZt+1 ≥ e−ηa(cid:1) ≤ eηa · Et
≤ eηa · exp (−ηλ(γ(1 + δ1)λ − 1))
= eηa−ηa−ηγλ2δ1 = e−ηγλ2δ1
(cid:33)
(cid:32)
(cid:114) 1 + δ1
1 + δ

= exp

−δ1

1 −

γλ

(cid:32)

(cid:33)

(cid:2)e−ηZt+1(cid:3)

,

where the last inequality applies statement 2.

The next lemma is a variant of Lemma 1, and will be used to compute the
probability of producing individuals in “new” parts of the product space X × Y
(see condition (G1) of Theorem 3).

Lemma 2. For A ⊂ X and B ⊂ Y deﬁne

r := Pr ((Pt+1 × Qt+1) ∩ A × B (cid:54)= ∅) .

If for (x, y) ∼ D(Pt, Qt), it holds Pr (x ∈ A) Pr (y ∈ B) ≥ z, then
1
r

3
z(λ − 1)
Proof. Deﬁne p := Pr (x ∈ A) , q := Pr (y ∈ B) and λ(cid:48) := λ − 1. Then by the
deﬁnition of r and Lemma 25

+ 1.

<

r ≥ Pr (∃k (cid:54)= (cid:96) s.t. Pt+1(k) = u ∧ Qt+1((cid:96)) = v)

≥ (1 − (1 − p)λ)(1 − (1 − q)λ(cid:48)

) >

(cid:18) λ(cid:48)p

(cid:19) (cid:18) λ(cid:48)q

(cid:19)

1 + λ(cid:48)p

1 + λ(cid:48)q

≥

λ(cid:48)2z
1 + λ(cid:48)(p + q) + λ(cid:48)z

≥

λ(cid:48)2z
1 + 2λ(cid:48) + λ(cid:48)2z

.

6

Finally, 1

r ≤ 2

zλ(cid:48) + 1

zλ(cid:48)2 + 1 < 3

zλ(cid:48) + 1.

3 A Level-based Theorem for Co-Evolutionary

Processes

This section deﬁnes a notion of runtime for Algorithm 1, and provides a generic
tool (Theorem 3) for deriving upper bounds on the runtime. The proof of this
theorem has been moved to Section A.

We will restrict ourselves to solution concepts that can be characterised as
ﬁnding a given target subset S ⊆ X × Y. This captures for example maximin
optimisation or ﬁnding pure Nash equilibria. Within this context, the goal of
Algorithm 1 is now to obtain populations Pt and Qt such that their product
intersects with the target set S. We then deﬁne the runtime of an algorithm A
as the number of interactions before the target subset has been found.

Deﬁnition 1 (Runtime). For any instance A of Algorithm 1 and subset S ⊆
X × Y, deﬁne TA,S := min{tλ ∈ N | (Pt × Qt) ∩ S (cid:54)= ∅}.

We follow the convention in analysis of population-based EAs that the gran-
ularity of the runtime is in generations, i.e., multiples of λ. The deﬁnition
overestimates the number of interactions before a solution is found by at most
λ − 1.

We now present a level-based theorem for co-evolution, which is one of the
main contributions of this paper. The theorem states four conditions (G1),
(G2a), (G2b), and (G3) which when satisﬁed imply an upper bound on the
runtime of the algorithm. To apply the theorem, it is necessary to provide a
sequence (Aj ×Bj)j∈[m] of subsets of X ×Y called levels, where A1 ×B1 = X ×Y,
and where Am × Bm is the target set. It is recommended that this sequence
overlaps to some degree with the trajectory of the algorithm. The “current
level” j corresponds to the latest level occupied by at least a γ0-fraction of the
pairs in Pt × Qt. Condition (G1) states that the probability of producing a pair
in the next level is strictly positive. Condition (G2a) states that the proportion
of pairs in the next level should increase by a multiplicative factor larger than
1. Condition (G2a) implies that the fraction of pairs in the current level should
not decrease below γ0. Finally, Condition (G3) states a requirement in terms of
the population size.

In order to make the “current level” of the populations well deﬁned, we need
to ensure that for all populations P ∈ X λ and Q ∈ Y λ, there exists at least one
level j ∈ [m] such that |(P × Q) ∩ (Aj × Bj)| ≥ γ0λ2. This is ensured by deﬁning
an initial level A1 × B1 := X × Y.

Notice that the notion of “level” here is more general than in the classical
level-based theorem Corus et al. (2018), in that they do not need to form a
partition of the search space.

Finally, in this initial work, we have not made an eﬀort in optimising the
expression for the expected runtime. We conjecture that the dependency on λ
can be reduced below λ3, and that the leading constant c(cid:48)(cid:48) is relatively small.

7

Theorem 3. Given subsets Aj ⊆ X , Bj ⊆ Y for j ∈ [m] where A1 := X
and B1 := Y, deﬁne T := min{tλ | (Pt × Qt) ∩ (Am × Bm) (cid:54)= ∅}, where
for all t ∈ N, Pt ∈ X λ and Qt ∈ Y λ are the populations of Algorithm 1 in
generation t. If there exist z1, . . . , zm−1, δ ∈ (0, 1], and γ0 ∈ (0, 1) such that for
any populations P ∈ X λ and Q ∈ Y λ with “current level” j := max{i ∈ [m − 1] |
|(P × Q) ∩ (Ai × Bi)| ≥ γ0λ2}

(G1) for (x, y) ∼ D(P, Q)

Pr (x ∈ Aj+1) Pr (y ∈ Bj+1) ≥ zj,

(G2a) for all γ ∈ (0, γ0) if |(P × Q) ∩ (Aj+1 × Bj+1)| ≥ γλ2, then for (x, y) ∼

D(P, Q),

Pr (x ∈ Aj+1) Pr (y ∈ Bj+1) ≥ (1 + δ)γ,

(G2b) for (x, y) ∼ D(P, Q),

Pr (x ∈ Aj) Pr (y ∈ Bj) ≥ (1 + δ)γ0,

(G3) and the population size λ ∈ N satisﬁes for a suﬃciently large constant c(cid:48),

where z∗ := mini∈[m−1] zi,

then for a constant c(cid:48)(cid:48) > 0, E [T ] ≤ c(cid:48)(cid:48)λ

(cid:16)

λ2m + (cid:80)m−1

i=1 1/zi

(cid:17)

.

λ ≥ c(cid:48) log(m/z∗),

4 Maximin Optimisation of Bilinear Functions

4.1 Maximin Optimisation Problems

This section introduces maximin-optimisation problems which is an important
domain for competitive co-evolutionary algorithms Jensen (2004); Al-Dujaili
et al. (2019); Miyagi et al. (2021). We will then describe a class of maximin-
optimisation problems called Bilinear.

It is a common scenario in real-world optimisation that the quality of can-
didate solutions depend on the actions taken by some adversary. Formally, we
can assume that there exists a function

g : X × Y → R,

where g(x, y) represents the “quality” of solution x when the adversary takes
action y.

A cautious approach to such a scenario is to search for the candidate solution
which maximises the objective, assuming that the adversary takes the least
favourable action for that solution. Formally, this corresponds to the maximin
optimisation problem, i.e., to maximise the function

f (x) := min
y∈Y

g(x, y).

(2)

8

It is desirable to design good algorithms for such problems because they have im-
portant applications in economics, computer science, machine learning (GANs),
and other disciplines.

However, maximin-optimisation problems are computationally challenging
because to accurately evaluate the function f (x), it is necessary to solve a
minimisation problem. Rather than evaluating f directly, the common approach
is to simultaneously maximise g(x, y) with respect to x, while minimising g(x, y)
with respect to y. For example, if the gradient of g is available, it is popular to
do gradient ascent-gradient descent.

Following conventions in theory of evolutionary computation Droste et al.
(2006), we will assume that an algorithm has oracle access to the function g.
This means that the algorithm can evaluate the function g(x, y) for any selected
pair of arguments (x, y) ∈ X × Y, however it does not have access to any other
information about g, including its deﬁnition or the derivative. Furthermore, we
will assume that X = Y = {0, 1}n. To develop a co-evolutionary algorithm for
maximin-optimisation, we will rely on the following dominance relation on the
set of pairs X × Y.

Deﬁnition 2. Given a function g : X ×Y → R and two pairs (x1, y1), (x2, y2) ∈
X ×Y, we say that (x1, y1) dominates (x2, y2) wrt g, denoted (x1, y1) (cid:23)g (x2, y2),
if and only if

g(x1, y2) ≥ g(x1, y1) ≥ g(x2, y1).

4.2 The Bilinear Problem

In order to develop appropriate analytical tools to analyse the runtime of evo-
lutionary algorithms, it is necessary to start the analysis with simple and well-
understood problems Wegener (2002). We therefore deﬁne a simple class of
a maximin-optimisation problems that has a particular clear structure. The
maximin function is deﬁned for two parameters α, β ∈ (0, 1) by

Bilinear(x, y) := |y|(|x| − βn) − αn|x|,

(3)

where we recall that for any bitstring z ∈ {0, 1}n, |z| := (cid:80)n
i=1 zi denotes the
number of 1-bits in z. The function is illustrated in Figure 1 (left). Extended
to the real domain, it is clear that the function is concave-convex, because
f (x) = g(x, y) is concave (linear) for all y, and h(y) = g(x, y) is convex (linear)
for all x. The gradient of the function is ∇g = (|y| − αn, |x| − βn). Clearly, we
have ∇g = 0 when |x| = βn and |y| = αn.

Assuming that the prey (in Y) always responds with an optimal decision for
every x ∈ X, the predator is faced with the unimodal function f below which
has maximum when |x| = βn.

f (x) := min

y∈{0,1}n

g(x, y) =

(cid:40)

|x|(1 − αn) − βn if |x| ≤ βn
if |x| > βn.
−αn|x|

We now characterise the dominated solutions wrt Bilinear.

9

Figure 1: Left: Bilinear for α = 0.4 and β = 0.6. Right: Dominance relation-
ships in Bilinear.

Lemma 4. Let g :=Bilinear. For all pairs (x1, y1), (x2, y2) ∈ X ×Y, (x1, y1) (cid:23)g
(x2, y2) if and only if

|y2|(|x1| − βn) ≥ |y1|(|x1| − βn) ∧
|x1|(|y1| − αn) ≥ |x2|(|y1| − αn).

Proof. The proof follows from the deﬁnition of (cid:23)g and g:

g(x1, y2) ≥ g(x1, y1)

⇐⇒ |x1||y2| − αn|x1| − βn|y2| ≥ |x1||y1| − αn|x1| − βn|y1|
⇐⇒ |y2|(|x1| − βn) ≥ |y1|(|x1| − βn).

The second part follows analogously from g(x1, y1) ≥ g(x2, y1).

Figure 1 (right) illustrates Lemma 4, where the x-axis and y-axis correspond
to the number of 1-bits in the predator x, respectively the number of 1-bits in
the prey y. The ﬁgure contains four pairs, where the shaded area corresponds
to the parts dominated by that pair: The pair (x1, y1) dominates (x2, y2), the
pair (x2, y2) dominates (x3, y3), the pair (x3, y3) dominates (x4, y4), and the
pair (x4, y4) dominates (x1, y1). This illustrates that the dominance-relation is
intransitive. Lemma 5 states this and other properties of (cid:23)g.

Lemma 5. The relation (cid:23)g is reﬂexive, antisymmetric, and intransitive for
g = Bilinear.

Proof. Reﬂexivity follows directly from the deﬁnition. Assume that (x1, y1) (cid:23)g
(x2, y2) and (x1, y1) (cid:54)= (x2, y2). Then, either g(x1, y2) > g(x1, y2), or g(x1, y1) >
g(x2, y1), or both. Hence, (x2, y2) (cid:54)(cid:23)g (x1, y1), which proves that the relation is
antisymmetric.

10

To prove intransitivity, it can be shown for any ε > 0, that p1 (cid:23)g p2 (cid:23)g

p3 (cid:23)g p2 (cid:23)g p1 where

p1 = (β + ε, α − 2ε)
p3 = (β − ε, α + 2ε)

p2 = (β − 2ε, α − ε)
p4 = (β + 2ε, α + ε).

We will frequently use the following simple lemma, which follows from the

dominance relation and the deﬁnition of Bilinear.

Lemma 6. For Bilinear, consider two samples (x1, y1), (x2, y2) ∼ Unif(P ×
Q). Then the following conditional probabilities hold.

Pr ((x1, y1) (cid:23) (x2, y2) | y1 ≤ y2 ∧ x1 > βn ∧ x2 > βn) ≥ 1/2
Pr ((x1, y1) (cid:23) (x2, y2) | y1 ≥ y2 ∧ x1 < βn ∧ x2 < βn) ≥ 1/2
Pr ((x1, y1) (cid:23) (x2, y2) | x1 ≥ x2 ∧ y1 > αn ∧ y2 > αn) ≥ 1/2
Pr ((x1, y1) (cid:23) (x2, y2) | x1 ≤ x2 ∧ y1 < αn ∧ y2 < αn) ≥ 1/2.

Proof. All the statements can be proved analogously, so we only show the ﬁrst
statement. If y1 ≤ y2 and x1 > βn, x2 > βn, then by Lemma 4, (x1, y1) (cid:23)
(x2, y2) if and only if x1 ≤ x2.

Since x1 and x2 are independent samples from the same (conditional) dis-

tribution, it follows that

1 ≥ Pr (x1 > x2) + Pr (x1 < x2) = 2 Pr (x1 > x1)

(4)

Hence, we get Pr (x1 ≤ x2) = 1 − Pr (x1 > x2) ≥ 1 − 1/2 = 1/2.

5 A co-Evolutionary Algorithm for Maximin Op-

timisation

We now introduce a co-evolutionary algorithm for maximin optimisation (see
Algorithm 2).

The predator and prey populations of size λ each are initialised uniformly
at random in lines 1-3. Lines 6-17 describe how each pair of predator and prey
are produced, ﬁrst by selecting a predator-prey pair from the population, then
applying mutation.
In particular, the algorithm selects uniformly at random
two predators x1, x2 and two prey y1, y2 in lines 7-8. The ﬁrst pair (x1, y1)
is selected if it dominates the second pair (x2, y2), otherwise the second pair
is selected. The selected predator and prey are mutated by standard bitwise
mutation in lines 14-15, i.e., each bit ﬂips independently with probability χ/n
(see Section C3.2.1 in Back et al. (1997)). The algorithm is a special case of the
co-evolutionary framework in Section 2, where line 3 in Algorithm 1 corresponds
to lines 6-17 in Algorithm 2.

Next, we will analyse the runtime of PD-CoEA on Bilinear using Theo-
rem 3. For an arbitrary constant ε > 0, we will restrict the analysis to the

11

Algorithm 2 Pairwise Dominance CoEA (PD-CoEA)
Require: Min-max-objective function g : {0, 1}n × {0, 1}n → R.
Require: Population size λ ∈ N and mutation rate χ ∈ (0, n]
1: for i ∈ [λ] do
2:
3:
4: end for
5: for t ∈ N until termination criterion met do
6:

Sample P0(i) ∼ Unif({0, 1}n)
Sample Q0(i) ∼ Unif({0, 1}n)

for i ∈ [λ] do

7:
8:
9:
10:
11:
12:

Sample (x1, y1) ∼ Unif(Pt × Qt)
Sample (x2, y2) ∼ Unif(Pt × Qt)
if (x1, y1) (cid:23)g (x2, y2) then

(x, y) := (x1, y1)

else

(x, y) := (x2, y2)

end if
Obtain x(cid:48) by ﬂipping each bit in x with prob. χ/n.
Obtain y(cid:48) by ﬂipping each bit in y with prob. χ/n.
Set Pt+1(i) := x(cid:48) and Qt+1(i) := y(cid:48).

13:
14:
15:
16:
17:
18: end for

end for

Figure 2: Partitioning of search space X × Y of Bilinear.

12

case where α − ε > 4/5, and β < ε. Our goal is to estimate the time until the
algorithm reaches within an ε-factor of the maximin-optimal point (βn, αn).

In this setting, the behaviour of the algorithm can be described intuitively
as follows. The population dynamics will have two distinct phases. In Phase 1,
most prey have less than αn 1-bits, while most predators have more than βn
1-bits. During this phase, predators and prey will decrease the number of 1-bits.
In Phase 2, a suﬃcient number of predators have less than βn 1-bits, and the
number of 1-bits in the prey-population will start to increase. The population
will then reach the ε-approximation described above.

From this intuition, we will now deﬁne a suitable sequence of levels. We will
start by dividing the space X × Y into diﬀerent regions, as shown in Figure 2.
Again, the x-axis corresponds to the number of 1-bits in the predator, while the
y-axis corresponds to the number of 1-bits in the prey.

For any k ∈ [0, (1 − β)n], we partition X into three sets

S0 := {x ∈ X | 0 ≤ |x| < βn}

S1(k) := {x ∈ X | βn ≤ |x| < n − k} , and
S2(k) := {x ∈ X | n − k ≤ |x| ≤ n} .

Similarly, for any (cid:96) ∈ [0, αn), we partition Y into three sets

R0 := {y ∈ Y | αn ≤ |y| ≤ n}

R1((cid:96)) := {y ∈ Y | (cid:96) ≤ |y| < αn} , and
R2((cid:96)) := {y ∈ Y | 0 ≤ |y| < (cid:96)} .

(5)
(6)

(7)

(8)

(9)

(10)

For ease of notation, when the parameters k and (cid:96) are clear from the context,
we will simply refer to these sets as S0, S1, S2, R0, R1, and R2. Given two
populations P and Q, and C ⊆ X × Y, deﬁne

p(C) :=

Pr
(x,y)∼Unif(P ×Q)

((x, y) ∈ C)

psel(C) :=

Pr
(x,y)∼select(P ×Q)

((x, y) ∈ C) .

In the context of subsets of X × Y, the set Si refers to Si × Y, and Ri refers to
X × Ri. With the above deﬁnitions, we will introduce the following quantities
which depend on k and (cid:96):

p0 := p(S0)

p(k) := p(S1(k))

q0 := p(R0)

q((cid:96)) := p(R1((cid:96)))

During Phase 1, the typical behaviour is that only a small minority of the
individuals in the Q-population belong to region R0. In this phase, the algorithm
“progresses” by decreasing the number of 1-bits in the P -population. In this
phase, the number of 1-bits will decrease in the Q-population, however it will
not be necessary to analyse this in detail. To capture this, we deﬁne the levels
for Phase 1 for j ∈ [0..(1 − β)n] as A(1)
:= R2((α − ε)n).
During Phase 2, the typical behaviour is that there is a suﬃciently large
number of P -individuals in region S0, and the algorithm progresses by increasing

:= S0 ∪ S1(j) and B(1)

j

j

13

the number of 1-bits in the Q-population. The number of 1-bits in the P -
population will decrease or stay at 0. To capture this, we deﬁne the levels for
:= S0 and B(2)
Phase 2 for j ∈ [0, (α − ε)n] A(2)

:= R1(j).

j

j

The overall sequence of levels used for Theorem 3 becomes

(A(1)

0 × B(1)

0 ), . . . , (A(1)

(1−β)n, B(1)

(1−β)n),

(A(2)

0 × B(2)

0 ), . . . , (A(2)

(α−ε)n, B(2)

(α−ε)n),

The notion of “current level” from Theorem 3 together with the level-
structure can be exploited to infer properties about the populations, as the
following lemma demonstrates.

Lemma 7. If the current level is A(1)

j × B(1)

j

, then p0 < γ0/(1 − q0).

Proof. Assume by contradiction that p0(1−q0) ≥ γ0. Note that by (10), it holds
R2(0) = ∅. Therefore, 1 − q(0) − q0 = 0 and q(0) = 1 − q0. By the deﬁnitions of
the levels in Phase 2 and (9),

(cid:12)
(cid:12)(P × Q) ∩ (A(2)
(cid:12)

(cid:12)
0 × B(2)
(cid:12)
(cid:12) = |(P × Q) ∩ (S0 × R1(0))|
0 )
= p0q(0)λ2 = p0(1 − q0)λ2 ≥ γ0λ2,

implying that the current level must be level A(2)
Phase 2, contradicting the assumption of the lemma.

0 × B(2)

0

or a higher level in

5.1 Ensuring Condition (G2) during Phase 1

The purpose of this section is to provide the building-blocks necessary to estab-
lish conditions (G2a) and (G2b) during Phase 1. The progress of the population
during this phase will be jeopardised if there are too many Q-individuals in R0.
We will employ the negative drift theorem for populations Lehre (2010) to prove
that it is unlikely that Q-individuals will drift via region R1 to region R0. This
theorem applies to algorithms that can be described on the form of Algorithm 3
which makes few assumptions about the selection step. The Q-population in
Algorithm 2 is a special case of Algorithm 3.
We now state the negative drift theorem.

Theorem 8 (Negative Drift Theorem for Populations Lehre (2010)). Given
Algorithm 3 on Y = {0, 1}n with population size λ ∈ poly(n), and transition
matrix pmut corresponding to ﬂipping each bit independently with probability
χ/n. Let a(n) and b(n) be positive integers s.t.
b(n) ≤ n/χ and d(n) :=
b(n) − a(n) = ω(ln n). For an x∗ ∈ {0, 1}n, let T (n) be the smallest t ≥ 0,
s.t. minj∈[λ] H(Pt(j), x∗) ≤ a(n). Let Rt(i) := (cid:80)λ
j=1[It(j) = i]. If there are
constants α0 ≥ 1 and δ > 0 such that

1) E [Rt(i) | a(n) < H(Pt(i), x∗) < b(n)] ≤ α0 for all i ∈ [λ]

14

Algorithm 3 Population Selection-Variation Algorithm Lehre (2010)
Require: Finite state space Y.
Require: Transition matrix pmut over Y.
Require: Population size λ ∈ N.
Require: Initial population Q0 ∈ Y λ.
1: for t = 0, 1, 2, . . . until the termination condition is met do
2:
3:
4:

Choose It(i) ∈ [λ], and set x := Qt(It(i)).
Sample x(cid:48) ∼ pmut(x) and set Qt+1(i) := x(cid:48).

for i = 1 to λ do

end for

5:
6: end for

2) ψ := ln(α0)/χ + δ < 1, and
(cid:110) 1

3) b(n)

n < min

5 , 1

2 − 1

2

(cid:111)
(cid:112)ψ(2 − ψ)
,

then Pr (cid:0)T (n) ≤ ecd(n)(cid:1) ≤ e−Ω(d(n)) for some constant c > 0.

To apply this theorem, the ﬁrst step is to estimate the reproductive rate

Lehre (2010) of Q-individuals in R0 ∪ R1.

Lemma 9. If there exist constants δ1, δ2 ∈ (0, 1) such that q + q0 ≤ 1 − δ1,
p0 < (cid:112)2(1 − δ2) − 1, and p0q = 0, then there exists a constant δ ∈ (0, 1) such
that psel(R0 ∪ R1)/p(R0 ∪ R1) < 1 − δ.

Lemma 10. If p0 = 0 and q0 + q ≤ 1/3, then no Q-individual in Q ∩ (R0 ∪ R1)
has reproductive rate higher than 1.

Proof. Consider any individual z ∈ Q ∩ (R0 ∪ R1). The probability of selecting
this individual in a given iteration is less than

Pr (y1 = z ∧ y2 ∈ R0 ∪ R1) Pr ((x1, y1) (cid:23) (x2, y2) | y1 = z ∧ y2 ∈ R0 ∪ R1)
+ Pr (y2 = z ∧ y1 ∈ R0 ∪ R1) Pr ((x1, y1) (cid:54)(cid:23) (x2, y2) | y2 = z ∧ y1 ∈ R0 ∪ R1)
+ Pr (y2 = z ∧ y1 ∈ R2) Pr ((x1, y1) (cid:54)(cid:23) (x2, y2) | y2 = z ∧ y1 ∈ R2)

≤

2
λ

(q0 + q) + (1 − q − q0)/(2λ) =

1
2λ

(1 + 3(q + q0)) ≤

1
λ

.

Hence, within one generation of λ iterations, the expected number of times this
individual is selected is at most 1.

We now have the necessary ingredients to prove the required condition about

the number of Q-individuals in R0.

Lemma 11. Assume that λ ∈ poly(n), and for two constants α, ε ∈ (0, 1) with
α − ε ≥ 4/5, the mutation rate is χ ≤ 1/(1 − α + ε). Let T be as deﬁned in

15

Theorem 14. For any τ ≤ ecn where c is a suﬃciently small constant, deﬁne
τ∗ := min{T /λ − 1, τ }, then

(cid:32) τ∗(cid:95)

Pr

(cid:33)

(Qt ∩ R0) (cid:54)= ∅

≤ τ e−Ω(n) + τ e−Ω(λ).

t=0

Proof. Each individual in the initial population Q0 is sampled uniformly at
random, with n/2 ≤ (α − ε)n/(1 + 3/5) expected number of 1-bits. Hence,
by a Chernoﬀ bound Motwani and Raghavan (1995) and a union bound, the
probability that the initial population Q0 intersects with R0 ∪ R1 is no more
than λe−Ω(n) = e−Ω(n).

We divide the remaining t − 1 generations into a random number of phases,
where each phase lasts until p0 > 0, and we assume that the phase begins with
q0 = 0.

If a phase begins with p0 > 0, then the phase lasts one generation. Further-
more, it must hold that q((α − ε)n) = 0, otherwise the product Pt × Qt contains
a pair in S0 ×R1((α−ε)n), i.e., an ε-approximate solution has been found, which
contradicts that t < T /λ. If q((α − ε)n) = 0, then all Q-individuals belong to
region R2. In order to obtain any Q-individual in region R0, it is necessary that
at least one of λ individuals mutates at least εn 0-bits, an event which holds
with probability at most λ · (cid:0) n

≤ λe−Ω(n) = e−Ω(n).

(cid:1)εn

(cid:1) (cid:0) χ
n

εn

If a phase begins with p0 = 0, then we will apply Theorem 8 to show that
it is unlikely that any Q-individual will reach R0 within ecn generations, or the
phase ends. We use the parameter x∗ := 1n, a(n) := (1 − α)n, and b(n) :=
(1 − α + ε)n < n/χ. Hence, d(n) := b(n) − a(n) = εn = ω(ln(n)).

We ﬁrst bound the reproductive rate of Q-individuals in R1. For any gen-
eration t, if q0 + q < (1 − δ2), then by Lemma 9, and a Chernoﬀ bound,
|Qt+1 ∩ R0 ∪ R1| ≤ (q0 + q)λ with probability 1 − e−Ω(λ). By a union bound,
this holds with probability 1 − te−Ω(λ) within the next t generations. Hence,
by Lemma 10, the reproductive rate of any Q-individual within R0 ∪ R1 is
at most α0 := 1, and condition 1 of Theorem 8 is satisﬁed. Furthermore,
ψ := ln(α0)/χ + δ = δ(cid:48) < 1 for any δ(cid:48) ∈ (0, 1) and χ > 0, hence condition 2
is satisﬁed. Finally, condition 3 is satisﬁed as long as δ(cid:48) is chosen suﬃciently
small. It follows by Theorem 8 that the probability that a Q-individual in R0
is produced within a phase of length at most τ < ecn is e−Ω(n).

The lemma now follows by taking a union bound over the at most τ phases.

We can now proceed to analyse Phase 1, assuming that q0 = 0. For a lower
bound and to simplify calculations, we pessimistically assume that the following
event occurs with probability 0

(x1, y1) ∈ S1 × R1 ∪ R2 ∧ (x2, y2) ∈ S2 ∪ R0.

Lemma 12. If there exist constants δ, ψ ∈ (0, 1) such that
1) p0 ≤ (cid:112)2(1 − δ) − 1

16

2) q0 ≤ (cid:112)2(1 − δ) − 1

3) p0q = 0

then if (p0 + p)(1 − q − q0) ≤ ψ, it holds that

ϕ :=

psel(S0 ∪ S1)
p(S0 ∪ S1)

·

psel(R2)
p(R2)

≥ 1 + δ(1 − (cid:112)ψ),

otherwise, if (p0 + p)(1 − q − q0) ≥ ψ, then psel(S0 ∪ S1)psel(R2) ≥ ψ.

Proof. Given the assumptions, Lemma 23 and Lemma 24 imply

ϕ ≥ (1 + δ(1 − p − p0))(1 + δ(q + q0)) ≥ 1.

(11)

For the ﬁrst statement, we consider two cases:

√

Case 1:
(1 + δ(1 −

√

If p0 + p <
ψ)) · 1.

√

Case 2: If p0 + p ≥

ψ, then by assumption (1 − q − q0) ≤

1 − p − p0 ≥ 0, it follows that ϕ ≥ 1 · (1 + δ(1 −

For the second statement, (11) implies

√

ψ)).

ψ, then by (11) and q0 + q ≥ 0, it follows ϕ ≥

√

ψ. By (11) and

psel(S0 ∪ S1)psel(R2) = ϕp(S0 ∪ S1)p(R2)

= ϕ(p0 + p)(1 − q − q0) ≥ 1 · ψ.

5.2 Ensuring Condition (G2) during Phase 2

We now proceed to analyse Phase 2.

Corollary 13. For any constant δ ∈ (0, 1), if γ0 < 1 − δ and 0 ≤ q0 < δ/1200
and p0 ∈ (1/3, 1], then there exists a constant δ(cid:48) > 0 such that

psel(S0)
p(S0)

psel(R1)
p(R1)

> 1 + δ(cid:48).

Proof. We distinguish between two cases.
If p0 ∈ (1/3, 1 − δ/10), we apply
Lemma 19. The conditions of Lemma 19 hold for the parameter δ1 := δ/10,
and the statement follows for δ(cid:48) = δ(cid:48)
1. If p0 ∈ (1 − δ/10, 1], the statement follows
immediately from Lemma 19 for the parameter δ(cid:48) = 23δ/300.

5.3 Main Result

We now obtain the main result: Algorithm 2 can eﬃciently locate an ε-approximate
solution to an instance of Bilinear.

Theorem 14. Assume that for a suﬃciently large constant c, it holds c log(n) ≤
λ ∈ poly(n). Let α, β, ε ∈ (0, 1) be three constants where α − ε ≥ 4/5. Deﬁne
T := min{λt | (Pt ×Qt)∩S0 ×R1((α−ε))n}where Pt and Qt are the populations
of Algorithm 2 applied to Bilinear α,β. Then if the mutation rate χ is a
suﬃciently small constant, and at most 1/(1 − α + ε), there exists a constant c0
such that for all r ∈ poly(n), it holds Pr (cid:0)T > c0rλ3n(cid:1) ≤ (1/r)(1 + o(1)).

17

6 A Co-Evolutionary Error Threshold

The previous section presented a scenario where Algorithm 2 obtains an ap-
proximate solution eﬃciently. We now present a general scenario where the
algorithm is ineﬃcient. In particular, we show that there exists a critical muta-
tion rate above which the algorithm fails on any problem, as long as the problem
does not have too many optima. The critical mutation rate is called the “error
threshold” of the algorithm Ochoa (2006); Lehre (2010). As far as the author is
aware, this is the ﬁrst time an error threshold has been identiﬁed in co-evolution.

Theorem 15. There exists a constant c > 0 such that the following holds.
If A and B are subsets of {0, 1}n with min{|A|, |B|} ≤ ecn, and Algorithm 2
is executed with population size λ ∈ poly(n) and constant mutation rate χ >
ln(2)/(1 − 2δ) for any constant δ ∈ (0, 1/2), then there exists a constant c(cid:48) such
that Pr

TA×B < ec(cid:48)n(cid:17)

= e−Ω(n).

(cid:16)

Proof. Without loss of generality, assume that |B| ≤ |A|. For a lower bound on
TA×B, it suﬃces to compute a lower bound on the time until the Q-population
contains an element in B.

For any y ∈ B, we will apply Theorem 8 to bound Ty := min{t | H(Qt, y) ≤
0}, i.e., the time until the Q population contains y. Deﬁne a(n) := 0 and
1 − δ2, 1/χ}. Since δ is a constant, it follows
b(n) := n min{1/5, 1/2 − (1/2)
that d(n) = b(n) − a(n) = ω(ln n). Furthermore, by deﬁnition, b(n) ≤ n/χ.

√

We now show that condition 1 of Theorem 8 holds for α0 := 2. For any
individual u ∈ Y, the probability that the individual is selected in lines 7-12 is
at most 1 − Pr (y1 (cid:54)= u ∧ y2 (cid:54)= u) = 1 − (1 − 1/λ)2 = (1/λ)(2 − 1/λ). Thus within
the λ iterations, individual u is selected less than 2 times in expectation. This
proves condition 1.

Condition 2 is satisﬁed because by the assumption on the mutation rate,
ψ := ln(α0)/χ + δ ≤ 1 − δ < 1. Finally, condition 3 trivially holds because
b(n) ≤ n/5 and 1/2 − (cid:112)ψ(2 − ψ)/2 ≤ 1/2 −

1 − δ2/2 ≤ b(n)/n.

√

All conditions are satisﬁed, and Theorem 8 imply that for some constant c(cid:48),
(cid:16)
Ty∗ < ec(cid:48)n(cid:17)
= e−Ω(n). Taking a union bound over all elements in B, we get

Pr

(cid:16)

TA×B < ec(cid:48)n(cid:17)

≤ Pr

(cid:16)

TB×Y < ec(cid:48)n(cid:17)

≤ (cid:80)

y∈B Pr

(cid:16)

Ty < ec(cid:48)n(cid:17)

≤

for suﬃciently small c Pr
ecn · e−Ω(n) = e−Ω(n).

7 Conclusion

Co-evolutionary algorithms have gained wide-spread interest, with a number of
exciting applications. However, their population dynamics tend to be signiﬁ-
cantly more complex than in standard evolutionary algorithms. A number of
pathological behaviours are reported in the literature, preventing the potential
of these algorithms. There has been a long-standing goal to develop a rigorous

18

theory for co-evolution which can explain when they are eﬃcient. A major ob-
stacle for such a theory is to reason about the complex interactions that occur
between multiple populations.

This paper provides the ﬁrst step in developing runtime analysis for population-

based, competitive co-evolutionary algorithms. A generic mathematical frame-
work covering a wide range of CoEAs is presented, along with an analytical
tool to derive upper bounds on their expected runtimes. To illustrate the
approach, we deﬁne a new co-evolutionary algorithm PD-CoEA and analyse
its runtime on a bilinear maximin-optimisation problem Bilinear. For some
problem instances, the algorithm obtains a solution within arbitrary constant
approximation ratio to the optimum within polynomial time O(rλ3n) with
probability 1 − (1/r)(1 + o(1)) for all r ∈ poly(n), assuming population size
λ ∈ Ω(log n) ∩ poly(n) and suﬃciently small (but constant) mutation rate. Ad-
ditionally, we present a setting where PD-CoAE is ineﬃcient. In particular, if
the mutation rate is too high, the algorithm needs with overwhelmingly high
probability exponential time to reach any ﬁxed solution. This constitutes a
co-evolutionary “error threshold”.

Future work should consider broader classes of problems, as well as other

co-evolutionary algorithms.

Acknowledgements

Lehre was supported by a Turing AI Fellowship (EPSRC grant ref EP/V025562/1).

References

Abdullah Al-Dujaili, Shashank Srikant, Erik Hemberg, and Una-May O’Reilly.
2019. On the application of Danskin’s theorem to derivative-free minimax
problems. AIP Conference Proceedings 2070, 1 (Feb. 2019), 020026. https:
//doi.org/10.1063/1.5089993 Publisher: American Institute of Physics.

Andrea Arcuri and Xin Yao. 2008. A novel co-evolutionary approach to au-
tomatic software bug ﬁxing. In 2008 IEEE Congress on Evolutionary Com-
putation (IEEE World Congress on Computational Intelligence). 162–168.
https://doi.org/10.1109/CEC.2008.4630793 ISSN: 1941-0026.

Thomas Back, David B. Fogel, and Zbigniew Michalewicz. 1997. Handbook of

Evolutionary Computation (1st ed.). IOP Publishing Ltd., GBR.

Dogan Corus, Duc-Cuong Dang, Anton V. Eremeev, and Per Kristian Lehre.
2018. Level-Based Analysis of Genetic Algorithms and Other Search Pro-
cesses. IEEE Transactions on Evolutionary Computation 22, 5 (Oct. 2018),
707–719. https://doi.org/10.1109/TEVC.2017.2753538

Duc-Cuong Dang and Per Kristian Lehre. 2016. Runtime Analysis of Non-
elitist Populations: From Classical Optimisation to Partial Information.

19

Algorithmica 75, 3 (July 2016), 428–461.
s00453-015-0103-x

https://doi.org/10.1007/

Benjamin Doerr and Frank Neumann (Eds.). 2020. Theory of Evolutionary

Computation. Springer.

Stefan Droste, Thomas Jansen, and Ingo Wegener. 2006. Upper and Lower
Bounds for Randomized Search Heuristics in Black-Box Optimization. Theory
of Computing Systems 39, 4 (July 2006), 525–544.
https://doi.org/10.
1007/s00224-004-1177-z

John Fearnley and Rahul Savani. 2016. Finding Approximate Nash Equilib-
ria of Bimatrix Games via Payoﬀ Queries. ACM Trans. on Economics and
Computation 4, 4 (Aug. 2016), 1–19. https://doi.org/10.1145/2956579

Sevan G Ficici. 2004. Solution Concepts in Coevolutionary Algorithms. Ph. D.

Dissertation. Brandeis University.

W. Daniel Hillis. 1990. Co-evolving parasites improve simulated evolution as an
optimization procedure. Physica D: Nonlinear Phenomena 42, 1 (June 1990),
228–234. https://doi.org/10.1016/0167-2789(90)90076-2

Thomas Jansen and R. Paul Wiegand. 2004. The Cooperative Coevolutionary
https:

(1+1) EA. Evolutionary Computation 12, 4 (Dec. 2004), 405–434.
//doi.org/10.1162/1063656043138905

Mikkel T. Jensen. 2004. A New Look at Solving Minimax Problems with Coevo-
lutionary Genetic Algorithms. In Metaheuristics: Computer Decision-Making,
Mauricio G. C. Resende and Jorge Pinho de Sousa (Eds.). Springer US,
Boston, MA, 369–384. https://doi.org/10.1007/978-1-4757-4137-7_17

Per Kristian Lehre. 2010. Negative Drift in Populations. In Proceedings of
the 11th International Conference on Parallel Problem Solving from Nature
(PPSN 2010) (LNCS, Vol. 6238). Springer Berlin / Heidelberg, 244–253.
https://doi.org/10.1007/978-3-642-15844-5_25

Per Kristian Lehre. 2011. Fitness-levels for non-elitist populations. Proceedings
of the 13th annual conference on Genetic and evolutionary computation -
GECCO ’11 (2011), 2075. https://doi.org/10.1145/2001576.2001855

Atsuhiro Miyagi, Kazuto Fukuchi, Jun Sakuma, and Youhei Akimoto. 2021.
Adaptive scenario subset selection for min-max black-box continuous opti-
mization. In Proceedings of the Genetic and Evolutionary Computation Con-
ference (GECCO ’21). Association for Computing Machinery, New York, NY,
USA, 697–705. https://doi.org/10.1145/3449639.3459291

Rajeev Motwani and Prabhakar Raghavan. 1995. Randomized Algorithms. Cam-

bridge University Press.

20

Gabriela Ochoa. 2006. Error Thresholds in Genetic Algorithms. Evolutionary
Computation 14, 2 (June 2006), 157–182. https://doi.org/10.1162/evco.
2006.14.2.157

Una-May O’Reilly, Jamal Toutouh, Marcos Pertierra, Daniel Prado Sanchez,
Dennis Garcia, Anthony Erb Luogo, Jonathan Kelly, and Erik Hemberg. 2020.
Adversarial genetic programming for cyber security: a rising application do-
main where GP matters. Genetic Programming and Evolvable Machines 21, 1-
2 (June 2020), 219–250. https://doi.org/10.1007/s10710-020-09389-y

Jordan B. Pollack, Hod Lipson, Gregory Hornby, and Pablo Funes. 2001. Three
Generations of Automatically Designed Robots. Artiﬁcial Life 7, 3 (July
2001), 215–223. https://doi.org/10.1162/106454601753238627

Elena Popovici, Anthony Bucci, R. Paul Wiegand, and Edwin D. De Jong.
2012. Coevolutionary Principles. In Handbook of Natural Computing, Grze-
gorz Rozenberg, Thomas B¨ack, and Joost N. Kok (Eds.). Springer Berlin
Heidelberg, Berlin, Heidelberg, 987–1033.
https://doi.org/10.1007/
978-3-540-92910-9_31

Mitchell A. Potter and Kenneth A. De Jong. 2000. Cooperative Coevolu-
tion: An Architecture for Evolving Coadapted Subcomponents. Evolution-
ary Computation 8, 1 (March 2000), 1–29.
https://doi.org/10.1162/
106365600568086

Richard A. Watson and Jordan B. Pollack. 2001. Coevolutionary Dynamics in a
Minimal Substrate. In Proceedings of the 3rd Annual Conference on Genetic
and Evolutionary Computation (GECCO’01). Morgan Kaufmann Publishers
Inc., San Francisco, CA, USA, 702–709.
http://dl.acm.org/citation.
cfm?id=2955239.2955343 event-place: San Francisco, California.

Ingo Wegener. 2002. Methods for the Analysis of Evolutionary Algorithms
on Pseudo-Boolean Functions. In Evolutionary Optimization, Ruhul Sarker,
Masoud Mohammadian, and Xin Yao (Eds.). Springer US, Boston, MA, 349–
369. https://doi.org/10.1007/0-306-48041-7_14

21

A Proof of the Level-based Theorem

This section provides the proof of the level-based theorem. The proof follows
closely the proof of the original level-based theorem, however there are some no-
table diﬀerences, particularly in the assumptions about the underlying stochas-
tic process and the choice of the “level-functions”. For ease of comparison, we
have kept the proof identical to the classical proof where possible.

Deﬁnition 3 (Corus et al. (2018)). A function g : ({0} ∪ [λ2]) × [m] → R is
called a level function if the following three conditions hold

1. ∀x ∈ {0} ∪ [λ2], ∀y ∈ [m − 1] :

g(x, y) ≥ g(x, y + 1),

2. ∀x ∈ {0} ∪ [λ2 − 1], ∀y ∈ [m] :

g(x, y) ≥ g(x + 1, y),

3. ∀y ∈ [m − 1] :

g(λ2, y) ≥ g(0, y + 1).

It follows directly from the deﬁnition that the set of level-functions is closed

under addition.

Lemma 16 (Corus et al. (2018)). If Yt+1 ≥ Yt, then for any level function g

(cid:16)

g

X (Yt+1+1)
t+1

, Yt+1

(cid:17)

(cid:16)

≤ g

X (Yt+1)
t+1

, Yt

(cid:17)

.

Proof. The statement is trivially true when Yt = Yt+1. On the other hand, if
Yt+1 ≥ Yt + 1, then the conditions in Deﬁnition 3 imply

(cid:16)

g

X (Yt+1+1)
t+1

, Yt+1

(cid:17)

≤ g (0, Yt+1) ≤ g (0, Yt + 1)
≤ g (cid:0)λ2, Yt

X (Yt+1)
t+1

(cid:1) ≤ g

(cid:16)

, Yt

(cid:17)

.

Proof of Theorem 3. We apply Theorem 26 (the additive drift theorem) with
respect to the parameter a = 0 and the process Zt := g
is a level-function, and (Yt)t∈N and (X (j)
)t∈N for j ∈ [m] are stochastic processes,
which will be deﬁned later. (Ft)t∈N is the ﬁltration induced by the populations
(Pt)t∈N and (Qt)t∈N.

X (Yt+1)

, where g

, Yt

(cid:16)

(cid:17)

t

t

We will assume w.l.o.g.

that conditions (G2a) and (G2b) are also satis-
ﬁed for j = m − 1, for the following reason. Given Algorithm 1 with a cer-
tain mapping D, consider Algorithm 1 with a diﬀerent mapping D(cid:48)(P, Q): If
(P × Q) ∩ (Am × Bm) = ∅, then D(cid:48)(P, Q) = D(P, Q); otherwise D(cid:48)(P, Q) as-
signs probability mass 1 to some pair (x, y) of P × Q that is in Am, e. g., to
the ﬁrst one among such elements. Note that D(cid:48) meets conditions (G1) and
(G2). Moreover, (G2a) and (G2b) hold for j = m − 1. For the sequence
1, . . . of Algorithm 1 with mapping D(cid:48), we
0, Q(cid:48)
of populations P (cid:48)
can put T (cid:48) := min{λt | (P (cid:48)
t) ∩ (Am × Bm) (cid:54)= ∅}. Executions of the original
algorithm and the modiﬁed one before generation T (cid:48)/λ are identical. On gen-
eration T (cid:48)/λ both algorithms place elements of Am into the populations for the

1, . . . and Q(cid:48)
t × Q(cid:48)

0, P (cid:48)

22

ﬁrst time. Thus, T (cid:48) and T are equal in every realisation and their expectations
are equal.

For any level j ∈ [m] and time t ≥ 0, let the random variable X (j)

:= |(Pt ×
Qt)∩(Aj ×Bj)| denote the number of pairs in level Aj ×Bj at time t. The current
t ≥ γ0λ2(cid:111)
level Yt of the algorithm at time t is deﬁned as Yt := max
Note that (X (j)
)t∈N and (Yt)t∈N are adapted to the ﬁltration (Ft)t∈N because
they are deﬁned in terms of the populations (Pt)t∈N and (Qt)t∈N.
When Yt < m, there exists a unique γ ∈ [0, γ0) such that

(cid:12)
(cid:12) X (j)
(cid:12)

j ∈ [m]

(cid:110)

t

t

.

X (Yt+1)
t
X (Yt)

= |(Pt × Qt) ∩ (AYt+1 × BYt+1)| = γλ2, and

t = |(Pt × Qt) ∩ (AYt × BYt)| ≥ γ0λ2.

(12)

(13)

Finally, we deﬁne the process (Zt)t∈N as Zt := 0 if Yt = m, and otherwise,

if Yt < m, we let

Zt := g

(cid:16)
X (Yt+1)

t

(cid:17)

,

, Yt

where for all k ∈ [λ2], and for all j ∈ [m − 1], g(k, j) := g1(k, j) + g2(k, j) and

g1(k, j) :=

η
1 + η


g2(k, j) := ϕ ·



· ((m − j)λ2 − k)

e−ηk
qj

+

m−1
(cid:88)

i=j+1



 ,

1
qi

where the parameters η, ϕ ∈ (0, 1) will be speciﬁed later, and for j ∈ [m − 1],
qj := λzj/(4 + λzj).

Both functions have partial derivatives ∂gi

∂j < 0, hence they
satisfy properties 1 and 2 of Deﬁnition 3. They also satisfy property 3 because
for all j ∈ [m − 1]

∂k < 0 and ∂gi

g1(λ2, j) =

g2(λ2, j) >

η
1 + η
m−1
(cid:88)

i=j+1

((m − j)λ2 − λ2) = g1(0, j + 1)

ϕ
qi

= g2(0, j + 1).

Therefore g1 and g2 are level-functions, and thus also their linear combination
g is a level function.

Due to properties 1 and 2 of level-functions (see Deﬁnition 3), it holds for

23

all k ∈ [0..λ2] and j ∈ [m − 1]

0 ≤ g(k, j) ≤ g(0, 1) <

ηmλ2
1 + η

+

m−1
(cid:88)

i=1

ϕ
qi

m−1
(cid:88)

+ ϕ

<

ηmλ2
1 + η
(cid:18)

< m

2ηλ2 +

i=1
4ϕ
λz∗

4 + λzi
λzi

(cid:19)

.

(14)

(15)

(16)

Hence, we have 0 ≤ Zt < g(0, 1) < ∞ for all t ∈ N which implies that condition
2 of the drift theorem is satisﬁed.

The drift of the process at time t is Et [∆t+1], where

∆t+1 := g

(cid:16)

X (Yt+1)

t

, Yt

(cid:17)

(cid:16)

− g

X (Yt+1+1)
t+1

, Yt+1

(cid:17)

.

We bound the drift by the law of total probability as

Et [∆t+1] = (1 − Pr t (Yt+1 < Yt))Et [∆t+1 | Yt+1 ≥ Yt]

+ Pr t (Yt+1 < Yt) Et [∆t+1 | Yt+1 < Yt] .

(17)

The event Yt+1 < Yt holds if and only if X (Yt)
t+1 < γ0λ2, which by Lemma 1 state-
ment 3, condition (G2b), and condition (G3) with a suﬃciently large constant
c(cid:48) such that c(cid:48)λ > (2/c) log(4m/z∗) is upper bounded by

Pr t (Yt+1 < Yt) = Pr t

(cid:16)

t+1 < γ0λ2(cid:17)
X (Yt)

< e−cλ < e−(c/2)λe−(c/2)λ

<

48
(cλ)3 ·

z∗
4m

,

(18)

(19)

where the last inequality uses ex > x3/3! from the Maclaurin series of the
exponential function. Given the low probability of the event Yt+1 < Yt, it
suﬃces to use the pessimistic bound (16)

Et [∆t+1 | Yt+1 < Yt] ≥ −g(0, 1)

(20)

If Yt+1 ≥ Yt, we can apply Lemma 16

Et [∆t+1 | Yt+1 ≥ Yt]
(cid:16)
X (Yt+1)

≥ Et

(cid:104)
g

t

, Yt

(cid:17)

(cid:16)

− g

X (Yt+1)
t+1

, Yt

(cid:17)

| Yt+1 ≥ Yt

(cid:105)

.

If X (Yt+1)
t

= 0, then X (Yt+1)

t

≤ X (Yt+1)
t+1

and

(cid:16)

(cid:104)
g1

Et

X (Yt+1)

t

, Yt

(cid:17)

(cid:16)

− g1

X (Yt+1)
t+1

, Yt

(cid:17)

| Yt+1 ≥ Yt

(cid:105)

≥ 0,

24

because the function g1 satisﬁes property 2 in Deﬁnition 3. Furthermore, we
have the lower bound
(cid:17)

(cid:16)

(cid:17)

(cid:16)

(cid:105)

(cid:104)
g2

Et

X (Yt+1)

t

, Yt

− g2

, Yt

| Yt+1 ≥ Yt

X (Yt+1)
t+1
(cid:16)

> Pr t

X (Yt+1)

(cid:17)
t+1 ≥ 1

(g2 (0, Yt) − g2 (1, Yt)) ≥

ηϕ
1 + η

.

where the last inequality follows because

(cid:16)

X (Yt+1)

(cid:17)
t+1 ≥ 1

Pr t

= Pr t ((Pt+1 × Qt+1) ∩ (AYt+1 × BYt+1) (cid:54)= ∅)

due to condition (G1) and Lemma 2, and

≥ qYt,

g2 (0, Yt) − g2 (1, Yt) = (ϕ/qYt)(1 − e−η) ≥

ϕη
(1 + η)qYt

In the other case, where X (Yt+1)

t
imply for ϕ := δ(1 − δ(cid:48)) for an arbitrary constant δ(cid:48) ∈ (0, 1),

= γλ2 ≥ 1, Lemma 1 and condition (G2a)

(cid:16)

(cid:104)
g1

Et

X (Yt+1)

t

(cid:16)

X (Yt+1)
t+1

, Yt

(cid:17)

− g1
(cid:104)

Et

(cid:17)

=

, Yt
η
1 + η
η
1 + η

| Yt+1 ≥ Yt
(cid:105)

η
1 + η
η
1 + η

(cid:105)

(cid:105)

X (Yt+1)
t+1

| Yt+1 ≥ Yt

−

X (Yt+1)

t

≥

(λ(λ − 1)(1 + δ)γ − γλ2) >

δ(1 − δ(cid:48)) =

ηϕ
1 + η

,

(21)

where the last inequality is obtained by choosing the minimal value γ = 1/λ2.
For the function g2, we get

(cid:16)

(cid:104)
g2

Et

X (Yt+1)

(cid:17)

(cid:16)

X (Yt+1)
t+1

(cid:17)

t

, Yt

− g2

, Yt
ϕ
qYt
where the last inequality is due to statement 2 of Lemma 1 for the parameter
η := (1 − (1 + δ)−1/2)/λ.

| Yt+1 ≥ Yt
(cid:16)

(cid:104)
e−ηX (Yt+1)

e−ηX (Yt+1)

− Et

> 0,

(cid:105)(cid:17)

=

t+1

t

Taking into account all cases, we have

Et [∆t+1 | Yt+1 ≥ Yt] ≥

ηϕ
1 + η

.

(22)

We now have bounds for all the quantities in (17) with (19), (20), and (22),

and we get

Et [∆t+1] = (1 − Pr t (Yt+1 < Yt))Et [∆t+1 | Yt+1 ≥ Yt]

−

+ Pr t (Yt+1 < Yt) Et [∆t+1 | Yt+1 < Yt]
(cid:18)
ηϕ
1 + η
ηϕ(1 − δ(cid:48)(cid:48))
1 + η

48
(cλ)3

4mϕ
λz∗

m2ηλ2 +

z∗
4m

+

ηϕ
1 + η

≥

>

(cid:19)

25

for an arbitrary small constant δ(cid:48)(cid:48) as long as m and λ are suﬃciently large.

We now verify condition 3 of Theorem 26, i. e., that T has ﬁnite expec-
tation. Let p∗ := min{(1 + δ)(1/λ2), z∗} > 0, and note by conditions (G1)
and (G2a) that the current level increases by at least one with probability
Pr t (Yt+1 > Yt) ≥ (p∗)γ0λ. Due to the deﬁnition of the modiﬁed process D(cid:48), if
Yt = m, then Yt+1 = m. Hence, the probability of reaching Yt = m is lower
bounded by the probability of the event that the current level increases in all
of at most m consecutive generations, i. e., Pr t (Yt+m = m) ≥ (p∗)γ0λm > 0. It
follows that E [T ] < ∞.

By Theorem 26 and the upper bound on g(0, 1) in (15),

E [T ] ≤ λ ·

(1 + η)g(0, 1)
ηϕ(1 − δ(cid:48)(cid:48))

λ(1 + η)
(1 − δ(cid:48)(cid:48))

λ(1 + η)
(1 − δ(cid:48)(cid:48))

·

·

m2ηλ2 + 4ϕ
λ
ηϕ

(cid:80)m−1
i=1

1
zi

(cid:32)

2λ2m
ϕ

+

4
λη

(cid:33)

m−1
(cid:88)

i=1

1
zi

<

=

≤

2λ2m
δ(1 − δ(cid:48))

+

4
1 − (1 + δ)−1/2

(cid:33)

m−1
(cid:88)

i=1

1
zi

(cid:32)

λ
(1 − δ(cid:48)(cid:48))
(cid:32)

≤ c(cid:48)(cid:48)λ

λ2m +

m−1
(cid:88)

i=1

(cid:33)

,

1
zi

assuming that c(cid:48)(cid:48) is a suﬃciently large constant.

B Other proofs moved due to space limitations

Proof of Lemma 9. The conditions of Lemma 24 are satisﬁed. Hence, for δ :=
δ1δ2, we get

psel(R0 ∪ R1) = 1 − psel(R2)

≤ 1 − (1 + δ2(q0 + q))p(R2)
= 1 − (1 + δ2(q0 + q))(1 − q − q0)
= (q0 + q)(1 − (1 − q − q0)δ2)
≤ (q0 + q)(1 − δ1δ2)
= p(R0 ∪ R1)(1 − δ).

Lemma 17 (Lemma 18 in Lehre (2011)). If Z ∼ Bin(λ, r) with r ≥ α(1 + δ),
then for any κ ∈ (0, δ], E (cid:2)e−κX (cid:3) ≤ e−καλ.

26

Lemma 18. Consider any pair of independent binomial random variables X ∼
Bin(λ, p) and Y ∼ Bin(λ, q), where pq ≥ (1 + σ)2z, p, q, z ∈ (0, 1) and σ > 0.
Then E (cid:2)e−ηXY (cid:3) ≤ e−ηzλ2
for all η where 0 < η ≤ σ

(1+σ)λ .

Proof. The proof applies Lemma 17 twice.

First, we apply Lemma 17 for the parameters Z := X, α := (z/q)(1 + σ) and
= α(1 + σ)
(1+σ)λ ≤ σ, i.e., the conditions of Lemma 17 are satisﬁed. This then

κ := ηY . The assumptions of the lemma then imply p ≥ z(1+σ)2
and κ ≤ σY
gives

q

E (cid:2)e−ηXY | Y (cid:3) = E (cid:2)e−κX | Y (cid:3) ≤ e−καλ = exp

(cid:18)

−

ηz
q

(cid:19)

(1 + σ)λY

.

(23)

Secondly, we apply Lemma 17 for the parameters Z := Y , α := q/(1 + σ)
q (1 + σ)λ. We have q = α(1 + σ), and by the assumption on η and

and κ := zη
the fact that 1 ≥ q ≥ z > 0, it follows that

κ ≤

σ
(1 + σ)λ

z
q

(1 + σ)λ ≤ σ.

The conditions of Lemma 17 are satisﬁed, giving

(cid:20)

(cid:18)

exp

−

E

ηz
q

(cid:19)(cid:21)

(1 + σ)λY

= E (cid:2)e−κY (cid:3) ≤ e−καλ

(24)

(cid:18)

= exp

−

zη
q

(1 + σ)λ

(cid:19)

q
1 + σ

λ

= e−ηzλ2

.

(25)

By (23), (25), and the tower property of the expectation, it follows that

E (cid:2)e−ηXY (cid:3) = E (cid:2)E (cid:2)e−ηXY (cid:3) | Y (cid:3) < e−ηzλ2

.

Lemma 19. For any constant δ1 ∈ (0, 1), if 1/3 < p0 < 1 −δ1 and q0 ≤ δ1/120,
then there exists a constant δ(cid:48)

ϕ :=

Proof.

1 > 0 such that
psel(R1)
psel(S0)
p(R1)
p(S0)

> 1 + δ(cid:48)
1.

ϕ >

(cid:18) 3
2

(2 − p0)p0(1 − q) + q − 4q0

(cid:19)

×

1
2

((1 − q0)(3 + q0) − p0(1 − q0(2 + q0)))

(3(2 − p0)p0(1 − q) + 2q − 8q0)

× (3 − q0(2 + q0) − p0 + p0q0(2 + q0)

(3(2 − p0)p0 + q(2 − 3(2 − p0)p0) − 8q0)

>

>

1
4

1
4

× (3 − p0 − 4q0)

27

Considering the variable q independently, we distinguish between two cases.
Case 1: 2 < 3(2 − p0)p0(1 − q). In this case, the expression is minimised for

q = 1, giving

ϕ >

>

>

1
4
1
4
1
4

(2 − 8q0) (3 − p0 − 4q0)

(2 − 8q0) (2 + δ1 − 4q0)

(2(2 + δ1) − 8q0 − (2 + δ1)8q0)

> 1 + δ1/2 − 8q0
> 1 + δ1/4.

Case 2: 2 ≥ 3(2 − p0)p0(1 − q). In this case, the expression is minimised for

q = 0, giving

ϕ >

>

>

1
4
3
4
3
4

(3(2 − p0)p0 − 8q0) (3 − p0 − 4q0)

(2 − p0)p0(3 − p0) −

q0
4

(4 · 3(2 − p0)p0 + 8(3 − p0))

(2 − p0)p0(3 − p0) − 12q0

√

7)/2 < x < 1 and f (cid:48)(x) > 0 if 1/3 < x < (5 −

Note that the function f (x) := (2 − x)(3 − x)x has derivative f (cid:48)(x) < 0 for
(5 −
7)/2. Hence, to determine
the minimum of the expression, it suﬃces to evaluate f at the extremal values
x = 1/3 and x = 1, where f (1/3) = 40/27 and f (1) = 2. Hence, in case 2, we
lower bound ϕ by ϕ > 3

27 − 12q0 > 1 + 1
90 .

4 · 40

√

Lemma 20. For any constant δ ∈ (0, 1), if p0q < γ0 < 1 − δ, p0 > 1 − δ/10
and q0 < δ/90 then

psel(S0)
p(S0)

psel(R1)
p(R1)

> 1 +

23δ
300

.

Proof. Note ﬁrst that the assumptions imply

3p0q0 < δ/30.

(26)

When p0 is suﬃciently large, it suﬃces to only consider the cases where both
x1 and x2 are selected in S0. More precisely, conditional on the event x1 ∈
S0 ∧ x2 ∈ S0, the probability of selecting an element in R1 is

psel(R1 | x1 ∈ S0 ∧ x2 ∈ S0)
≥ Pr (y1 ∈ R1 ∧ y2 ∈ R1)

+ Pr (y1 ∈ R1 ∧ y2 ∈ R2) /2
+ Pr (y1 ∈ R2 ∧ y2 ∈ R1)

= q2 + q(1 − q − q0)/2 + (1 − q − q0)q

=

q
2

(3 − q − 3q0).

28

Hence, the unconditional probability of selecting a pair in R1 is

psel(R1) >

>

>

p2
0q
2
p0q
2
p0q
2

(3 − q − 3q0)

(3(1 − δ/10) − (1 − δ) − 3p0q0)

(2 + δ − δ(3/10) − δ/30)

= p0q (1 + δ/3) .

Using that p(R1) = q, and psel(S0) ≥ p2

0, we get

psel(S0)
p(S0)

psel(R1)
p(R1)

≥

p2
0
p0

psel(R1)
p(R1)

> (1 − δ/10)2 (1 + δ/3)
δ3
300

17δ2
300

= 1 +

+

−

2δ
15
23δ
300

.

> 1 +

Lemma 21.

ϕ :=

psel(S0)
p(S0)

≥

1
2

((3 + q0)(1 − q0) − p0(1 − q0(2 + q0)))

Proof. Using Lemma 6, we get

psel(S0) = Pr (x1 ∈ S0 ∧ x2 ∈ S0) +
+ Pr (x1 ∈ S0 ∧ x2 (cid:54)∈ S0)

× Pr ((x1, y1) (cid:23) (x2, y2) | x1 ∈ S0 ∧ x2 (cid:54)∈ S0)

+ Pr (x1 (cid:54)∈ S0 ∧ x2 ∈ S0)

× (1 − Pr ((x1, y1) (cid:23) (x2, y2) | x1 (cid:54)∈ S0 ∧ x2 ∈ S0))

≥ Pr (x1 ∈ S0 ∧ x2 ∈ S0) +

+ Pr ((x1, y1) ∈ S0 × R1 ∪ R2 ∧ (x1, y1) ∈ S1 ∪ S2 × R1 ∪ R2) /2
+ Pr (x1 (cid:54)∈ S0 ∧ x2 ∈ S0) (1 − Pr (y1 ∈ R0 ∧ y2 ∈ R0))
0 + p0(1 − p0)(1 − q0)2/2 + p0(1 − p0)(1 − q2
≥ p2
0)

Recalling that p(S0) = p0, we get

ϕ ≥ p0 + (1 − p0)(1 − q0)2/2 + (1 − p0)(1 − q2
0)

=

1
2

((3 + q0)(1 − q0) − p0(1 − q0(2 + q0)))

29

Lemma 22.

ϕ :=

psel(R1)
p(R1)

>

3
2

(2 − p0)p0(1 − q) + q − 4q0.

Proof. Using Lemma 6, we get

psel(R1) = Pr (y1 ∈ R1 ∧ y2 ∈ R1) +
+ Pr (y1 ∈ R1 ∧ y2 (cid:54)∈ R1)

× Pr ((x1, y1) (cid:23) (x2, y2) | y1 ∈ R1 ∧ y2 (cid:54)∈ R1)

+ Pr (y1 (cid:54)∈ R1 ∧ y2 ∈ R1)

× (1 − Pr ((x1, y1) (cid:23) (x2, y2) | y1 (cid:54)∈ R1 ∧ y2 ∈ R1))

≥ Pr (y1 ∈ R1 ∧ y2 ∈ R1) +

+ Pr ((x1, y1) ∈ S0 × R1 ∧ (x2, y2) ∈ S0 × R2) /2
+ Pr ((x1, y1) ∈ S0 × R1 ∧ (x2, y2) ∈ S1 ∪ S2 × R2)
+ Pr ((x1, y1) ∈ S1 × R1 ∧ (x2, y2) ∈ S1 × R0) /2
+ Pr ((x1, y1) ∈ S1 × R1 ∧ (x2, y2) ∈ S2 × R0)
+ Pr ((x1, y1) ∈ S2 × R1 ∧ (x2, y2) ∈ S2 × R0) /2
+ Pr (y2 ∈ R1)

× (1 − Pr (y1 ∈ R1)

− Pr ((x1, y1) ∈ S0 × R0 ∧ x2 ∈ S0)
− Pr ((x1, y1) ∈ S1 × R2 ∧ x2 ∈ S1 ∪ S2)
− Pr ((x1, y1) ∈ S2 × R2 ∧ x2 ∈ S2))

≥ q2 + qp0(1 − q − q0)(p0/2 + 1 − p0)+

+ qpq0(p/2 + 1 − p − p0) + q(1 − p − p0)2q0/2
+ q(1 − q − p2

0q0

− (1 − q − q0)(p(1 − p0) + (1 − p − p0)2)

Recalling that p(R1) = q and noting that (4 − p0)p0 < 4, it follows that

ϕ >

3
2

(2 − p0)p0(1 − q) + q
(cid:19)

(cid:18) 3
2

+ q0

− (4 − p0)p0

+ p(1 − q − q0)(1 − p − p0)

>

3
2

(2 − p0)p0(1 − q) + q − 4q0.

Lemma 23. If there exists a constant δ > 0 such that
1) q0 ≤ (cid:112)2(1 − δ) − 1

30

then

ϕ :=

psel(S0 ∪ S1)
p(S0 ∪ S1)

> 1 + δ(1 − p − p0).

Proof. Using Lemma 6, we get

psel(S0 ∪ S1)
= Pr (x1 ∈ S0 ∪ S1 ∧ x2 ∈ S0 ∪ S1) +
+ Pr (x1 ∈ S0 ∪ S1 ∧ x2 (cid:54)∈ S0 ∪ S1)

× Pr ((x1, y1) (cid:23) (x2, y2) | x1 ∈ S0 ∪ S1 ∧ x2 (cid:54)∈ S0 ∪ S1)

+ Pr (x1 (cid:54)∈ S0 ∪ S1 ∧ x2 ∈ S0 ∪ S1)

× (1 − Pr ((x1, y1) (cid:23) (x2, y2) | x1 (cid:54)∈ S0 ∪ S1 ∧ x2 ∈ S0 ∪ S1))

≥ Pr (x1 ∈ S0 ∪ S1 ∧ x2 ∈ S0 ∪ S1) +

+ Pr ((x1, y1) ∈ S0 ∪ S1 × R0 ∪ R1 ∧ (x2, y2) ∈ S2 × R0 ∪ R1) /2
+ Pr (x2 ∈ S0 ∪ S1)

× (1 − Pr (y2 ∈ R0 ∧ (x1, y1) ∈ S2 × R0) − Pr (x1 ∈ S0 ∪ S1))

≥ (p0 + p)2 + (p0 + p)(1 − q0)2(1 − p − p0)/2+

+ (p0 + p)(1 − (p0 + p) − q2

0(1 − p − p0))

Recalling that p(S0 ∪ S1) = p0 + p, and the assumption of the lemma, it follows
that

ϕ ≥ 1 + (1 − p − p0)((1 − q0)2/2 − q0)

= 1 + (1 − p − p0)(1/2 − q0(1 − q0/2))
≥ 1 + (1 − p − p0)(1/2 − (1 − 2δ)/2)
= 1 + δ(1 − p − p0).

Lemma 24. If there exist a constant δ > 0 such that

1) p0q = 0.
2) p0 < (cid:112)2(1 − δ) − 1

then

ϕ :=

psel(R2)
p(R2)

≥ 1 + δ(q0 + q).

31

Proof. Using Lemma 6, we get

psel(R2)
= Pr (y1 ∈ R2 ∧ y2 ∈ R2) +
+ Pr (y1 ∈ R2 ∧ y2 (cid:54)∈ R2)

× Pr ((x1, y1) (cid:23) (x2, y2) | y1 ∈ R2 ∧ y2 (cid:54)∈ R2)

+ Pr (y1 (cid:54)∈ R2 ∧ y2 ∈ R2)

× (1 − Pr ((x1, y1) (cid:23) (x2, y2) | y1 (cid:54)∈ R2 ∧ y2 ∈ R2))

≥ Pr (y1 ∈ R2 ∧ y2 ∈ R2) +

+ Pr ((x1, y1) ∈ S1 ∪ S2 × R2 ∧ (x2, y2) ∈ S1 ∪ S2 × R0 ∪ R1) /2
+ Pr (y2 ∈ R2)

× (1 − Pr ((x1, y1) ∈ S0 × R1)

− Pr ((x1, y1) ∈ S0 × R0 ∧ y2 ∈ R2) − Pr (y1 ∈ R2))

= (1 − q − q0)2

+ (1 − q − q0)(1 − p0)2(q0 + q)/2
+ (1 − q − q0)(1 − p0q − p2

0q0 − (1 − q − q0))

From p(R2) = 1 − q − q0 and the assumptions of the lemma,

ϕ ≥ 1 + (1 − p0)2(q0 + q)/2 − p0q − p2
= 1 + (q0 + q)/2 − p0q0(1 + p0/2)
≥ 1 + (q0 + q)/2 − q0(1/2 − δ)
≥ 1 + (q0 + q)δ.

0q0

C Proof of the main theorem

Proof of Theorem 14. Note that we can guarantee χ ≤ 1/(α + ε), for a suﬃ-
ciently small constant χ.

Deﬁne τ := c0rλ3n ∈ poly(n) and τ∗ := min{T /λ − 1, τ }. We will condition
on the event that q0 = 0 holds for the ﬁrst τ∗ generations, and consider the
run a failure otherwise. By Lemma 11, the probability of such a failure is no
more than τ e−Ω(λ) + τ e−Ω(n) = e−Ω(λ) + e−Ω(n), assuming that the constraint
λ ≥ c log(n) holds for a suﬃciently large constant c.
We apply Theorem 3 with the m = O(n) levels

(A(1)

0 × B(1)

0 ), . . . , (A(1)

(1−β)n, B(1)

(1−β)n),

(A(2)

0 × B(2)

0 ), . . . , (A(2)

(α−ε)n, B(2)

(α−ε)n),

deﬁned in Section 5. It will suﬃce to choose the parameter γ0 such that 1/3 <
γ0 ≤ (cid:112)2(1 − δ) − 1 (e.g., γ0 = 2/5 assuming that δ is suﬃciently small).

32

We now prove conditions (G1), (G2a), and (G2b) separately for Phase 1 and

Phase 2.

Phase 1: Assume that the current level belongs to phase 1 for any j ∈
[0, (1 − β)n]. To prove that condition (G2a) holds, we will now show that the
conditions of Lemma 12 are satisﬁed for the parameter ψ := γ0. By Lemma 7,
we have p0 < γ0 ≤ (cid:112)2(1 − δ) − 1, hence condition 1 is satisﬁed. Condition
2 is satisﬁed by the assumption on q0 = 0. By the deﬁnition of the level,
(p0 + p)(1 − q − q0) < γ0 = ψ. Finally, we can assume that p0q = 0, otherwise
the algorithm has already found an ε-approximate solution. All three conditions
of Lemma 12 are satisﬁed. To produce an individual in A(1)
j+1, it suﬃces to
select and individual in A(1)
j+1 and not mutate any of the bits, and analogously
to produce an individual in B(1)
j+1. In overall, for a sample (x, y) ∼ D(P, Q), this
gives

(cid:16)

Pr

x ∈ A(1)
j+1

(cid:17)

(cid:16)

Pr

y ∈ B(1)
j+1

(cid:17)

j+1)psel(B(1)
j+1)
√
γ0))p(A(1)

(cid:16)

(cid:17)2n

1 −

χ
n
j+1)p(B(1)

≥ psel(A(1)

≥ (1 + δ(1 −
≥ (1 + δ(cid:48)(cid:48))γ,

j+1)e−2χ(1 − o(1))

(27)

(28)

(29)

(30)

assuming suﬃciently small mutation rate χ and parameter δ(cid:48)(cid:48) > 0. Condition
(G2a) of the level-based theorem is therefore satisﬁed for Phase 1. To prove
(G2b), we apply Lemma 12 with parameter ψ = γ0(1 + δ). If p(A(1)
j )p(B(1)
) ≥
If
γ0(1 + δ), then (G2b) follows from the second statement of Lemma 12.
γ0 ≤ p(A(1)
) ≤ γ0(1 + δ), then (G2b) follows from the ﬁrst statement of
Lemma 12.

j )p(B(1)

j × B(1)

Assume that p(A(1)

) = (p0 + p)(1 − q − q0) ≥ γ0 and (x, y) ∼ D(P, Q)
j+1 by selecting an individual in A(1)
Then, a P -individual can be obtained in A(1)
,
and mutate one of n − j ≥ βn 1-bits, and no other bits, an event which occurs
with probability at least

j

j

j

j

(cid:16)

Pr

x ∈ A(1)
j+1

(cid:17)

≥ psel(A(1)

j )(n − j)

(cid:17)n−1

(cid:16)

1 −

χ
n

χ
n

≥ psel(A(1)

j ) · Ω(1).

A Q-individual can be obtained in B(1)
j+1 by selecting an individual in B(1)
not mutate any bits. By (30), this event occurs with probability at least

j+1 and

(cid:16)

Pr

y ∈ B(1)
j+1

(cid:17)

≥ psel(B(1)

j

)

(cid:16)

1 −

(cid:17)n

χ
n

≥

Ω(1)
psel(A(1)
j )

.

Hence, for a sample (x, y) ∼ D(P, Q), we obtain

(cid:16)

Pr

x ∈ A(1)
j+1

(cid:17)

(cid:16)

Pr

y ∈ B(1)
j+1

(cid:17)

= Ω(1),

33

hence condition (G1) will be satisﬁed for some parameter zj ∈ Ω(1).

Phase 2: The analysis is analogous for this phase. To prove (G2a), assume
that the current level belongs to phase 2 for any j ∈ [0, (α − ε)n]. By the
deﬁnitions of the levels in this phase, we must have p0q(j − 1) ≥ γ0, thus
p0 ≥ γ0 > 1/3 where the last inequality follows from our choice of γ0. Together
with the assumption q0 = 0, Corollary 13 gives
(cid:16)

(cid:17)

(cid:17)

(cid:16)

Pr

x ∈ A(2)

j

Pr

y ∈ B(2)

j

(31)

≥ psel(A(2)

j )psel(B(2)

j

(cid:16)

)

1 −

(cid:17)2n

χ
n

≥ (1 + δ(cid:48))p(A(1)
≥ (1 + δ(cid:48)(cid:48))γ,

j )p(B(1)

j

)e−2χ(1 − o(1))

(32)

(33)

(34)

assuming suﬃciently small mutation rate χ and parameter δ(cid:48)(cid:48) > 0. Condition
(G2b) can be proved analogously to Phase 1, with the help of Corollary 13.

To prove condition (G1), we proceed as for Phase 1 and observe that to
and
j+1, it suﬃces to select
and ﬂip one of the at least (1 − ε)n = Θ(n) number of

produce an individual in A(2)
not mutate any of the bits. To produce an individual in B(2)
a Q-individual in B(2)

j+1, it suﬃces to select an P -individual in A(2)

j

j

y ∈ B(2)
0-bits. Again, we obtain Pr
j+1
(G1) will be satisﬁed for some parameter zj = Ω(1).

x ∈ A(2)
j+1

Pr

(cid:16)

(cid:17)

(cid:16)

(cid:17)

= Ω(1), hence condition

Condition (G3) is satisﬁed as long as λ ≥ c(cid:48) log(m/z∗).
All the conditions are satisﬁed, and assuming that q0 = 0, it follows that the

expected time to reach an ε-approximation of Bilinear is no more than

(cid:32)

E [T ] ≤ c(cid:48)(cid:48)λ

λ2m +

(cid:33)

m−1
(cid:88)

i=1

1
zi

= O(λ3n).

By Markov’s inequality, the probability that a solution has not been obtained
in O(rλ3n) time is less than 1/r. Hence, in overall, we obtain for some constant
c0 > 0 and λ ≥ log(n) and λ ∈ poly(n)

Pr (cid:0)T > c0rλ3n(cid:1) ≤ 1/r + e−Ω(n) + e−Ω(λ) ≤ (1/r)(1 + o(1)).

D Additional technical results

Lemma 25 (Dang and Lehre (2016)). For n ∈ N and x ≥ 0, we have 1 − (1 −
x)n ≥ 1 − e−xn ≥ xn
1+xn

Theorem 26 (Additive drift theorem Corus et al. (2018)). Let (Zt)t∈N be a
discrete-time stochastic process in [0, ∞) adapted to any ﬁltration (Ft)t∈N. De-
ﬁne Ta := min{t ∈ N | Zt ≤ a} for any a ≥ 0. For some ε > 0 and constant
0 < b < ∞, deﬁne the conditions

34

1.1) E [Zt+1 − Zt + ε ; t < Ta | Ft] ≤ 0 for all t ∈ N,

1.2) E [Zt+1 − Zt + ε ; t < Ta | Ft] ≥ 0 for all t ∈ N,

2) Zt < b for all t ∈ N, and

3) E [Ta] < ∞.

If 1.1), 2), and 3) hold, then E [Ta | F0] ≤ Z0/ε.
If 1.2), 2), and 3) hold, then E [Ta | F0] ≥ (Z0 − a)/ε.

Lemma 27. Let X and Y be two non-negative random variables with ﬁnite
expectations. If X (cid:23) Y , then E [X] ≥ E [Y ].

Proof. By deﬁnition, X (cid:23) Y implies Pr (Y ≤ z) ≥ Pr (X ≤ z) for all z ∈ R.
Using that X and Y are non-negative random variables,

E [X] =

(cid:90) ∞

0

1 − Pr (X ≤ z) dz ≥

(cid:90) ∞

0

1 − Pr (Y ≤ z) dz = E [Y ] .

35

