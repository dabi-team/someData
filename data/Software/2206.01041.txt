2
2
0
2

t
c
O
8
1

]

R
C
.
s
c
[

3
v
1
4
0
1
0
.
6
0
2
2
:
v
i
X
r
a

End-to-End Security for Distributed Event-Driven Enclave
Applications on Heterogeneous TEEs

GIANLUCA SCOPELLITI, Ericsson AB, Sweden and KU Leuven, Belgium
SEPIDEH POUYANRAD, JOB NOORMAN, and FRITZ ALDER, KU Leuven, Belgium
CHRISTOPH BAUMANN, Ericsson AB, Sweden
FRANK PIESSENS and JAN TOBIAS MÜHLBERG, KU Leuven, Belgium

This paper presents an approach to provide strong assurance of the secure execution of distributed event-driven
applications on shared infrastructures, while relying on a small Trusted Computing Base. We build upon and
extend security primitives provided by Trusted Execution Environments (TEEs) to guarantee authenticity and
integrity properties of applications, and to secure control of input and output devices. More specifically, we
guarantee that if an output is produced by the application, it was allowed to be produced by the application’s
source code based on an authentic trace of inputs.

We present an integrated open-source framework to develop, deploy, and use such applications across
heterogeneous TEEs. Beyond authenticity and integrity, our framework optionally provides confidentiality and
a notion of availability, and facilitates software development at a high level of abstraction over the platform-
specific TEE layer. We support event-driven programming to develop distributed enclave applications in Rust
and C for heterogeneous TEE, including Intel SGX, ARM TrustZone and Sancus.

In this article we discuss the workings of our approach, the extensions we made to the Sancus processor, and
the integration of our development model with commercial TEEs. Our evaluation of security and performance
aspects show that TEEs, together with our programming model, form a basis for powerful security architectures
for dependable systems in domains such as Industrial Control Systems and the Internet of Things, illustrating
our framework’s unique suitability for a broad range of use cases which combine cloud processing, mobile
and edge devices, and lightweight sensing and actuation.

1 INTRODUCTION
Trusted Execution Environments (TEEs) allow an application to execute in a hardware-protected
environment, often called enclave. Enclaves are isolated and protected from the rest of the system,
ensuring strong confidentiality and integrity guarantees. Cryptographic primitives and credential
management, with keys that are unique per enclave and that can only be used by that enclave, enable
secure communication and remote attestation; the latter is a mechanism to obtain cryptographic
proof that an application is running under enclave protection on a specific processor. There are
several TEEs available, both in industry and research. Open-source TEEs include Sancus and
Keystone; proprietary options are, e.g., Software Guard Extensions (SGX) for Intel processors,
Secure Encrypted Virtualization (SEV) for AMD, TrustZone for ARM, and others [36]. Developing
distributed applications that execute on heterogeneous TEEs is difficult, in particular for scenarios
that combine Internet-of-Things, Edge, and cloud hardware: each TEE requires a platform-specific
software implementation, comes with different approaches to key management and attestation, a
different Trusted Computing Base (TCB) footprint, and provides slightly different hardware features
and security guarantees.

The development of a distributed application composed of multiple modules running on heteroge-
neous hardware is non-trivial by itself, but becomes an even bigger challenge when the application
has stringent security requirements that demand the use of TEE architectures. A developer needs

Authors’ addresses: Gianluca Scopelliti, gianluca.scopelliti@ericsson.com, Ericsson AB, Stockholm, Sweden , imec-DistriNet
and KU Leuven, Leuven, Belgium, 3001; Sepideh Pouyanrad, sepideh.pouyanrad@kuleuven.be; Job Noorman, job.noorman@
kuleuven.be; Fritz Alder, fritz.alder@kuleuven.be, imec-DistriNet, KU Leuven, Leuven, Belgium, 3001; Christoph Baumann,
christoph.baumann@ericsson.com, Ericsson AB, Stockholm, Sweden; Frank Piessens, frank.piessens@kuleuven.be; Jan
Tobias Mühlberg, jantobias.muehlberg@kuleuven.be, imec-DistriNet, KU Leuven, Leuven, Belgium, 3001.

 
 
 
 
 
 
2

Scopelliti and Pouyanrad et al.

to make choices as to which security features are required for which components, adapt the code
of each component to multiple specific platforms, arrange for different deployment and attestation
strategies, and implement secure interaction between the components. Open-source projects such
as Open Enclave SDK and Google Asylo aim to bridge the development gap between different
TEEs. However, software engineers still need to account for the communication between different
modules, which has to be properly secured with cryptographic operations for data encryption and
authentication. In particular, the responsibility for deploying the distributed application, loading
and attesting each enclave, establishing session keys and secure connections between distributed
components, is still left to the application developer and operator. Overall, ensuring strong security
guarantees in distributed scenarios poses a challenge to the adoption of TEE technology.

Fig. 1. A smart irrigation system as an example for distributed application networks we can support. Light-
weight sensing and actuation nodes are deployed in a field. Application AppA controls irrigation units (through
driver Drv2) and water supply (Drv3), based on soil moisture (obtained through Drv1). Application AppB
provides similar functionality but has access to additional data sources, e.g., aerial surveillance and data
aggregation on central infrastructure. All application components execute in enclaves (colored) and the
actual composition and configuration of components can change dynamically. Directed data flows through
untrusted networks (colored arrows) are at least authenticated and integrity protected; attestation precedes
the establishment of all data flows, and mutual authentication is established between enclaves. All other
software in the scenario is untrusted regarding our security properties, which leads to a very small run-time
application TCB. Guaranteeing availability properties may require a different compartmentalization strategy.
The concept is also applicable across, e.g., the different control units within a car or in an autonomous robot.

This paper studies the problem of securely executing distributed applications on such a shared,
heterogeneous TEE-infrastructure, while relying on a small run-time TCB. We want to provide the
owner of such an application with strong assurance that their application is executing securely. We
focus on (1) authenticity and integrity properties of (2) event-driven distributed applications. For this
selection of security property and class of applications, we specify the exact security guarantees
offered by our approach. We believe our approach to be valuable for any kind of distributed
application (event-driven or not). In particular, our prototype supports arbitrary C and Rust code
for building distributed applications.

We distinguish physical events, such as sensor inputs or actuation, from logical events that are
generated and consumed by application components. Roughly speaking, our notion of authentic
execution is the following: if the application produces a physical output event (e.g., turns on an LED),
then there must have happened a sequence of physical input events such that that sequence, when

AppASancus - FieldEvManAppBDrv1Drv2OSTrustZone - DroneEvManAppBDrv1OSAppASancus - FieldEvManAppBDrv1Drv2OSTrustZone - GWEvManAppBOSTrustZone - GWEvManAppBOSSGX - CentralEvManAppBOSApplication enclaves &secure communication.Trust is established through(remote) attestation ofinteracting components.Local communication(between enclaves onthe same processor) issecured butnot depictedin this illustration. Toprovide availabilityguarantees (e.g. for AppA),a protected schedulerenclave needs to be addedto the Sancus nodes.Untrusted componentsMalicious interactionsor bugs in untrustedcode do not harmsecurity but may, onsome platforms, harmavailability or lead toresource exhaustion.AppASancus - FieldEvManDrv3OSEnd-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

3

processed by the application (as specified in the high-level source code), produces that output event.
This notion of security is roughly equivalent to the concept of robust safety in later literature [2].
Our approach has been experimented with in previous work, where we secure smart distributed
applications in the context of smart metering infrastructures [43], automotive computing [59], and
precision agriculture [54], which we generalize and partly formalize under the name “authentic
execution” in [47], and use as a training and tutorial scenario to explain attestation and secure
communication with heterogeneous TEEs [44].

1.1 Use Case and Security Objectives
As a running example we discuss an automated irrigation system, as illustrated in Figure 1, which
involves a series of light-weight sensors and actuators in the field that, e.g., monitor soil moisture
and crop growth, and control water supply. The system can be connected to edge infrastructure or
cloud services for centralized configuration and maintenance, to integrate reporting and billing, and
to minimize water consumption based on weather predictions. Naturally, smart farming systems
are security critical since malicious interactions can potentially lead to huge costs and may destroy
a crop; they also feature a high level of dynamicity where equipment needs to be reconfigured for
specific sensing and actuation tasks that depend on the type of crop [52] and, e.g., sustainability
objectives [56], and demand a high level of dependability where events must be guaranteed to be
processed in a timely manner. With our approach to building such applications as event-driven
systems, we intend to support developers with an intuitive programming paradigm and automated
enclave deployment to achieve the security objectives highlighted below, and which is applicable
to many domains such as home and factory automation, smart grids, or automotive computing.

We consider an open system as the basis for our framework. In this open system, software is
deployed dynamically and multiple stakeholders may run applications on the same infrastructure,
including light-weight IoT and Edge hardware. Thus, we consider scenarios where arbitrary new
code can be loaded at run time and we consider powerful attackers that can manipulate all the
software on the infrastructure (unless that software is isolated in enclaves), can manipulate network
traffic, but cannot break crypto. Attacks against the hardware are out of scope.

Under this attacker model, isolation and mutual attestation of all application components, includ-
ing peripheral drivers, result in the initial authenticity and integrity guarantees, where all observed
outputs can be explained in terms of a trace of (authentic) inputs and the (integrity protected) source
code of the application. Using the sealing capabilities of TEEs, this guarantee can be extended to
also provide confidentiality of application events and state. However, in many application scenarios,
such as automotive computing and safety-critical systems in general, confidentiality is not a desired
property as it limits backwards-compatibility and investigation of incidents. We work towards
availability extensions that allow individual enclaves to execute with strong guarantees for respon-
siveness and progress, which allows for these enclaves to timely detect and react upon availability
issues across the application. As highlighted in [4], strong availability require hardware extensions
that are not available in current commercial TEEs. We currently do not consider protection from
side-channel leakage as part of the framework but as part of the developer’s task to address.

1.2 Security Guarantees
First, authentic execution does provide strong integrity guarantees: it rules out both spoofed events
as well as tampering with the execution of the program. Informally, if the executing program
produces an output event, it must also have produced that same event if no attacker was present.
Any physical output event can be explained by means of the untampered code of the application,
and the actual physical input events that have happened. Second, while our implementation does
offer confidentiality, this is not the focus of this paper: we specify authentic execution without

4

Scopelliti and Pouyanrad et al.

𝐷T1

Tick

𝐷S1

Sensor driver
Clock driver
𝑀FloS1
𝑀AggS1
Untrusted OS

𝑁𝑆1

r
o
s
n
e
S

𝐷T2

Tick

e
r
u
t
s
i
o
M

Flooded

𝐷S2

Sensor driver
Clock driver
𝑀FloS2
𝑀AggS2
Untrusted OS

𝑁𝑆2

𝑀Agg
Untrusted OS

𝑁Agg

𝐷A
Tap on/off

Tap

𝐷D
Moisture:
55%

Display

r
o
s
n
e
S

Flooded

MoistChanged

Actuator
driver
𝑀FloA
Untrusted OS

𝑁𝐴

Display
driver
𝑀AggD
Untrusted OS

𝑁𝐷

Fig. 2. Our running example with two applications, 𝐴Agg (purple) and 𝐴Flo (dark orange). Hardware (𝑁∗ and
𝐷∗) is trusted; the OS and the network are untrusted. E.g., the 𝐴Flo deployer creates the three red Software
Modules (SMs) (cf. Fig. 3a) with a trusted compiler, attests the shared sensor-, clock- and display drivers and
sets-up connections between the SMs. Remote attestation assures authentic execution of 𝐴Agg and 𝐴Flo.

confidentiality guarantees, i.e., attackers can observe events in the system. Indeed, securing applica-
tions in domains such as safety-critical control systems requires authenticity, while confidentiality
is typically not desired so as to simplify system monitoring and forensics. Third, it is clear that
authentic execution, by default, gives no availability guarantees: if the execution never produces
any output, then it is vacuously secure. Extending our approach with availability guarantees is
a challenging direction for future work towards which we have undertaken first steps in [4] by
extending a light-weight embedded TEE architectures so as to provide strong temporal isolation
guarantees to multiple, mutually distrusting applications.

1.3 Contributions
The main contributions of this paper are:

• We reflect on the design and implementation of an approach for authentic execution of
event-driven programs on heterogeneous distributed systems, under the assumption that
the execution infrastructure offers specific security primitives – standard enclaves [55] plus
support for secure I/O [48] (Sect. 3); we comprehensively discuss corner cases and hurdles
regarding the use of secure I/O in distributed enclave applications;

• We provide a revised open-source implementation of the approach for Intel SGX, ARM
TrustZone, and for Sancus (an OpenMSP430-based TEE where all security primitives are
implemented in hardware), which supports software development in Rust and C (Sect. 4); we
elaborate on implementation challenges towards achieving comparable security guarantees
in heterogeneous TEE deployments;

• An evaluation of the performance and security aspects of that implementation (Sect. 5) that
considers dynamic system updates, showing that our approach allows for the deployment of
complex distributed software systems with a very small run-time application TCB;

• We design and implement a light-weight symmetric attestation scheme for ARM TrustZone,

inspired by and providing security guarantees comparable to Sancus.

Our complete implementation of the authentic execution framework and the evaluation use case are
available at https://github.com/AuthenticExecution/main. Earlier supplementary material, including
a formalization and proof sketch of our security guarantees, is available at https://people.cs.kuleuven.
be/~jantobias.muehlberg/stm17/.

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

5

2 RUNNING EXAMPLE, INFRASTRUCTURE & OBJECTIVES
Fig. 2 (source code in Fig. 3) shows a running example for the kind of system we consider. The
figure zooms in on the light-weight in-field sensing and actuation on the left side in Fig. 1 and
details application modules and event flows in an agricultural sensor network with two soil
moisture sensors. The infrastructure can be reused for multiple applications which can be provided
by different stakeholders. Applications include visualizing soil moisture, targeted irrigation, or
detection of flooding or leakage. We show two of these applications: one (𝐴Flo) that detects flooding
or leakage and disconnects the water supply in case of emergency, and another (𝐴Agg) that aggregates
and displays data on soil moisture.

2.1 The Shared Infrastructure
The infrastructure is a collection of nodes (𝑁i), where each node consists of a processor, memory,
and a number of I/O devices (𝐷i). Multiple mutually distrusting stakeholders share the infrastructure
to execute distributed applications (𝐴i). For simplicity, we assume processors are simple micropro-
cessors, such as the OpenMSP430 used in our prototype, to explain the underlying concepts and
security guarantees of our approach. As we detail in Section 4 and thereafter, our implementation
does support the commercial TEEs TrustZone and Intel SGX, and we evaluate our approach on an
integrated scenario that involves these TEEs.

An I/O device interfaces the processor with the physical world and facilitates (1) sensing phys-
ical quantities (e.g., the state of a switch), (2) influencing physical quantities (e.g., an LED), and
(3) notifying the processor of state change (e.g., a key being pressed) by issuing an interrupt.

In our running example there are 5 nodes. Two of these (𝑁S1 and 𝑁S2) are each attached to two
input devices (a clock 𝐷Ti and a soil moisture sensor 𝐷Si), and are installed in a field, e.g., along a
row of crops. Two other nodes (𝑁A and 𝑁D) are connected to actuator and display devices (𝐷A, 𝐷D)
to control the water supply and show application output. One node (𝑁Agg) is not connected to any
I/O device but performs general-purpose computations, e.g., aggregate data from sensor nodes.

module FloS1
on Sensor ( reading ):

if reading >= SATURATED : flooded = 1
else :

flooded = 0
count
= 0
Flooded ( false )

on Tick ():

if flooded : count = count + 1
if count > MAX : Flooded ( true )

module FloS2
# Similar to FloS1
module FloA
on Flooded1 ( true )

f1 = true ;
if f2 = true : Tap ( off )

on Flooded2 ( true ):

# Similar to Flooded1

(a) 𝐴Flo

module AggS1
on Sensor ( reading ):
Moisture ( reading )

module AggS2
# Similar to AggS1

module Agg
on Moisture1 ( reading ):
l1 . append ( reading )
del l1 [: -100]
MoistChanged ( reading - avg )
avg = sum ( l1 ) / len ( l1 )

on Moisture2 ( reading ):

# Similar to Moisture1

module AggD
on MoistChanged ( delta )

Display ( delta )

(b) 𝐴Agg

Fig. 3. Pseudo-code of the applications from Fig. 2. in a Python-like syntax. Enclaved application components
are declared using the module keyword and span until the next module or the end of the file. The on statement
starts an event handler which can connect to an output of another application component, or to a physical
I/O channel. Outputs are implicitly declared when invoked through a function call-like syntax.

6

Scopelliti and Pouyanrad et al.

2.2 Modules & Applications
We use an event-driven application model and modules (𝑀i) contain input- and output channels.
Upon reception of an event on an input channel, the corresponding event handler is executed
atomically and new events on the module’s output channels may be produced.

An application, then, is a collection of modules together with a deployment descriptor. This
descriptor specifies on which nodes the modules should be installed as well as how the modules’
channels should be connected. Channels can be connected in two ways. First, one module’s output
channel can be connected to another’s input channel, behaving like a buffered queue of events.
Second, the infrastructure can provide a number of physical I/O channels which can be connected to
a module’s I/O channels. The infrastructure must ensure that events on such channels correspond
to physical events: An event received on a physical input could correspond to a button press or,
similarly, an event produced on a physical output could turn on an LED. An important contribution
of this paper is a design to securely connect modules to physical I/O channels (Sects. 3.4 and 4.1.5).
In our example applications (Fig. 2), 𝐴Flo consists of three modules: two (𝑀FloS1 and 𝑀FloS2) are
deployed in a field and detect excess moisture (flooding or leakage) and one (𝑀FloA) actuates a
central tap to disconnect water supply if needed. The two in-field modules have two inputs that are
connected to input devices provided by the infrastructure: one that produces events for changes in
soil moisture (𝐷Si) and another that sends periodical timer events (𝐷Ti). As the source code (Fig. 3a)
shows, these modules first wait for changes in critical changes in soil moisture, then wait for a
maximum number of timer events, and finally produce an output event to indicate an emergency.
These output events are connected to the inputs of 𝑀FloA which in turn produces output events
and sends them to the output actuator 𝐷A. A second application 𝐴Agg shares access to the sensor
drivers with 𝐴Flo to obtain sensor readings that are then aggregated and displayed.

2.3 Attacker Model
We consider powerful attackers that can manipulate all the software on the nodes. Attackers
can deploy their own applications on the infrastructure, but they can also tamper with the OS.
Attackers can also control the communication network that nodes use to communicate with each
other. Attackers can sniff the network, modify traffic, or mount man-in-the-middle attacks. With
respect to the cryptographic capabilities of the attacker, we follow the Dolev-Yao model [17].

Attacks against the hardware are out of scope. We assume the attacker to not have physical
access to the nodes, neither can they physically tamper with I/O devices. We also do not consider
side-channel attacks against our implementation. Physical protection and side-channel resistance
are important but orthogonal and complementary to the protection offered by our approach.

2.4 Security Objective
The deployer uses his own (trusted) computing infrastructure to compile the application 𝐴, to
deploy the modules to the nodes in the shared infrastructure, and to configure connections between
modules, and between modules and physical I/O channels. At run-time, an actual trace of physical
I/O events will happen, and the deployer can observe an actual sequence of physical output events.
We say that this sequence of outputs is authentic for an application 𝐴 if it is allowed by 𝐴’s modules
and deployment descriptor in response to the actual trace of input events: the source code of 𝐴
explains the physical outputs on the basis of actual physical inputs that have happened.

For instance for 𝐴Flo, suppose we have physical events where excess moisture is detected at
sensor 1, MAX clock ticks pass and then the water supply is disconnected. The trace of outputs is an
authentic trace for 𝐴Flo, because its source code allows for this actuator event given the physical

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

7

input events. A trace for the same sequence of physical events, but now ending with the water
supply being re-connected, is not authentic.

Our objective is to design a deployment algorithm such that the deployer can easily certify
the authenticity of traces. If the correctness of the deployment is verified, then our approach
guarantees that any subsequent trace of output events observed by the deployer will be authentic.
This security notion rules out a wide range of attacks, including attacks where event transmissions
on the network are spoofed or reordered, and attacks where malicious software tampers with
the execution of modules. Other relevant attacks are not covered by this security objective. As
discussed earlier, there are no general availability guarantees – e.g., the attacker can suppress
network communication. However, TEE extensions such as [4] and the use of real-time operating
systems can provide notions of availability that are relevant to maintain system safety in, e.g.,
autonomous control systems. There are also no confidentiality guarantees: the attacker is not
prevented from observing events flowing in the system. Although this is not the focus of our design,
our implementation does come with substantial protection of the confidentiality of the application’s
state as well as the information in events (Sect. 6.1).

3 AUTHENTIC EXECUTION OF DISTRIBUTED APPLICATIONS
We outline our requirements for the infrastructure wrt. security features, and show how these
features are used effectively to accomplish our security goals.

3.1 Underlying Architecture: TEEs
Given the shared nature of the infrastructure assumed in our system model, we require the ability
to isolate source modules from other code running on a node. Since an important non-functional
goal is to minimize the TCB, relying on a classical omnipotent kernel to provide isolation is ruled
out. Therefore, we assume the underlying architecture is a TEE [55].

While details vary between TEEs, isolation of software modules is understood as follows: A
module must be able to specify memory locations containing data that are accessible by the module’s
code only (data isolation). The code of a module must be immutable and a module must specify a
number of entry points through which its code can be executed (code isolation). For simplicity we
further assume that both a module’s code and data are located in contiguous memory areas called,
respectively, its code section and its data section. We expect TEEs to implement a 𝑊 ⊕ 𝑋 policy so
as to prevent code modification and code generation at runtime.

We also expect the availability of a compiler that targets Software Modules (SMs) on the under-
lying architecture. The input to this compiler is as follows: (1) a list of entry point functions; (2)
a list of non-entry functions; (3) a list of variables that should be allocated in the isolated data
section; and (4) a list of constants that should be allocated in the isolated code section. The output
of the compiler should be an SM suitable for isolation on the underlying architecture.

Besides isolation, we expect the TEE to provide a way to attest the correct isolation of an SM.
Attestation provides proof that an SM with a certain identity has been isolated on the node,
where the identity of an SM should give the deployer assurance that this SM will behave as the
corresponding source code module.

After enabling isolation, the TEE should be capable of establishing a confidential, integrity
protected and authenticated communication channel between an SM and its deployer. Although
the details of how this works may differ from one TEE to another, for simplicity we assume the
TEE establishes a shared secret between an SM and its deployer and provides an authenticated
encryption primitive. We refer to this shared secret as the module key. The authentication property
of the communication channel refers to an SM’s identity and hence to attestation. Thus, the TEE

8

Scopelliti and Pouyanrad et al.

def SetKey ( payload ):

try :

conn_id , io_id , key = Decrypt ( payload )
conn = Connection ( conn_id , io_id , key )
ConnectionTable [ conn_id ] = conn

except : pass

def HandleInput ( conn_id , payload ):

try :

conn = ConnectionTable [ conn_id ]
if conn != 0:

cb = CbTable [ conn . io_id ]
key = conn . key
nonce = conn . nonce
cb ( Decrypt ( nonce , payload , key ))
conn . incrementNonce ()

except : pass

def HandleOutput ( conn_id , data ):

conn = ConnectionTable [ conn_id ]
if conn != 0:

nonce = conn . nonce
key = conn . key
payload = Encrypt ( nonce , data , key )
conn . incrementNonce ()
HandleLocalEvent ( conn_id , payload )

def Attest ( challenge ):

try :

ev = GenAttestationEvidence ( challenge )
return ev

except :

return None # attestation failed

Fig. 4. Pseudocode of the SetKey entry point.
Note that Decrypt uses the module key to de-
crypt the payload and throws an exception if the
operation failed (i.e., the payload’s MAC is incor-
rect).

Fig. 5. Pseudocode of the HandleInput entry
point. Erroneous accesses to the tables as well
as errors during Decrypt cause exceptions. Thus,
these events, as well as those for which no input
key has been set, are ignored. Decrypt takes a key
and the expected associated data as arguments.

Fig. 6. Pseudocode of the generated output wrap-
per. Since the compiler generates calls to this func-
tion that cannot be called from outside the module,
the connection identifier is always valid and no
error checking is necessary.

of

the

Attest

Fig. 7. Pseudocode
entry
point. Since the attestation of an SM is
TEE-specific, we use a high-level
function
GenAttestationEvidence to retrieve the attesta-
tion evidence. The actual implementation of this
function depends on the TEE used.

ensures that if a deployer receives a message created with a module key, it can only have been
created by the corresponding, correctly isolated, SM.

3.2 Mapping source modules to SMs
To map a source module to an SM, we use the following procedure. First, each of the source module’s
inputs and outputs is assigned a unique I/O identifier, and each of the connections between source
modules is assigned a unique connection identifier. The format of these identifiers is unimportant,
provided that they uniquely specify a particular input/output or a particular connection, respectively.
By having a clear distinction between I/O identifiers and connection identifiers, many-to-many
connections are supported, which means that: (1) a source module’s output can be connected to
multiple inputs of other source modules (e.g., a keyboard that sends key press events to both a
key-logger and an LCD screen), and (2) a source module’s input can be reached by multiple outputs
of other source modules (e.g., a key-logger that records key presses of two different keyboards).

Second, a table (ConnectionTable) is added to the SM’s variables that maps connection identifiers
to a Connection data structure, such that every connection has one entry associated with it. These
entries will be initialized to all zeros by the underlying architecture, which is interpreted as an
unestablished connection. For establishing a connection, an entry point is generated (SetKey). This
entry point takes a connection identifier, an I/O identifier and a key – encrypted using the module
key – as input and updates the corresponding mapping in ConnectionTable (Fig. 4). Since every
connection needs to be protected from reordering and replay attacks, the Connection structure
also includes a nonce.

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

9

Fig. 8. Memory layout of the compiled version of
module 𝑀FloS1 in application 𝐴Flo (Fig. 3a). The
code- and data sections are shaded in light orange
and purple, respectively. The numbers on the left
labels correspond to the compiler inputs while the
right labels indicate whether parts are implicitly
generated by the compiler or correspond to source
code.

(1) En-
try points

(2) Non-entry
functions

(4) Constants

(3) Variables

· · ·
Standard entry stub

SetKey

Attest
HandleInput

HandleOutput

Sensor
Tick
CbTable
SATURATED
MAX
· · ·
Standard runtime
data (stack,. . . )

ConnectionTable
flooded
count
· · ·

Generated

Event handlers

Generated

Constants

Generated

Globals

Third, all the module’s event handlers are marked as non-entry functions. A callback table
(CbTable) is added to the SM’s constants, mapping input identifiers to the corresponding event
handlers. This table is used by the entry point HandleInput, which is called when an event is
delivered to the SM. HandleInput takes two arguments: a plain-text connection identifier and an
encrypted payload. If ConnectionTable has a connection for the given identifier, its key is used
to decrypt the payload (using the expected nonce as associated data), which is then passed to the
callback function stored in CbTable, retrieved using the I/O identifier stored in the Connection
structure. If any of these operations fails, the event is ignored (Fig. 5). From a programmer’s
perspective, an input callback will only be called for events generated by entities with access to
valid connection keys.

Fourth, each call to an output is replaced by a call to a non-entry wrapper function HandleOutput.
This function takes a connection identifier and a payload, encrypts the payload together with the
current nonce using the corresponding connection key, then publishes the encrypted event (via
HandleLocalEvent, cf. 3.3.2). If the output is unconnected, the output event is dropped (Fig. 6).

Fifth, an entry point Attest is generated, which will be called by the deployer to attest the
SM. This function takes a challenge as input and returns an attestation evidence as response. The
attestation procedure and the content of the attestation evidence may vary from one TEE technology
to the other; nonetheless, the input challenge is typically used as a freshness parameter to prevent
replay attacks. On some TEEs, the attestation process also includes the generation of a shared
secret between the SM and the deployer, which will be used as the module key (Fig. 7).

To conclude, the following SM definition is given as input to the TEE compiler: (1) SetKey,
Attest and HandleInput as entry points; (2) input event handlers and HandleOutput as non-entry
functions; (3) ConnectionTable as a global variable; and (4) CbTable as a constant. Fig. 8 shows
the compiled memory layout of one of the example modules.

3.3 Untrusted Software on the Nodes
To support the deployment of modules and the exchange of events between modules, untrusted
(and unprotected) software components need to be installed on each node, as outlined below.

3.3.1 Module Loader. The module loader is an untrusted software component running on every
node. The module loader provides services for external entities to interact with modules on a node.
To this end, the module loader listens for two types of remote requests: LoadModule and CallEntry.
LoadModule takes a compiled SM as input, loads it into the TEE and returns the module’s unique
identifier together with all information necessary for attestation and module key establishment.

10

Scopelliti and Pouyanrad et al.

What exactly this information is and how the attestation and key establishment is performed is
specific to the used TEE. CallEntry takes an SM’s identifier, the identifier of an entry point and
potentially some arguments and calls the entry point with the given arguments.

3.3.2 Event Manager. The event manager is another untrusted software component running
on every node that is used to route events from outputs to inputs. It recognizes three types of
requests: AddConnection, HandleLocalEvent and HandleRemoteEvent. A deployer can invoke
AddConnection remotely to connect the output of a module to the input of another. How exactly
inputs and outputs are identified is implementation specific but it will in some form involve
specifying (1) a node address (e.g., an IP address); (2) an SM identifier; and (3) a connection
identifier. As will become clear later, AddConnection only needs to be called on the event manager
of the node where the output source module is deployed.

HandleLocalEvent is used by modules to publish an event; i.e., inside the output wrappers. The
arguments are the module and connection identifiers and the event payload. Based on the identifiers,
the event manager looks up the destination event manager and invokes its HandleRemoteEvent API,
providing the identifiers of the input to which the request should be routed. For a HandleRemoteEvent
request, the event manager will check if the destination module exists and, if so, invoke its
HandleInput entry point, passing the connection identifier and payload as arguments.

Implementation. Although we introduced the module loader and the event manager as two
3.3.3
separate software components, in our prototype we merged the functionalities of both in the same
application, which we simply call the Event Manager. This design choice was made for the sake of
simplicity: the actual implementation of such logical components is unimportant as long as each
node provides the functionalities described above.

3.4 Physical Input and Output Channels
We assume that the infrastructure offers physical input and output channels using protected driver
modules that translate application events into physical events and vice versa. Driver modules
control these physical events – sensing and actuation – within the boundaries of the processor
executing the driver. For input channels, these modules generate events that correspond to physical
events and provide a way for application modules to authenticate the generated events. For output
channels, a driver module (𝑀D) must have exclusive access to its I/O device (𝐷) and allow an
application module (𝑀A) to take exclusive access over the driver. That is, the driver will only accept
events – and hence translate them to physical events – from the application module currently
connected to it.

Here we assume that A1: the infrastructure provider configures the physical I/O devices as expected,
i.e., the desired peripherals are connected to the right pins and thus mapped to the correct Memory-
Mapped I/O (MMIO) addresses in the node. Since misconfiguration in the physical world cannot be
detected by remote attestation, we need to assume that I/O devices are set up correctly.

However, A2: the infrastructure must provide a way for the deployer of 𝑀A to attest that it has
exclusive access to the driver module 𝑀D and that 𝑀D also has exclusive access to its I/O device 𝐷. The
deployer must be able to attest 𝑀D to ensure that it indeed only accepts events from the module
currently having exclusive access and that it does not release this exclusive access without being
asked to do so by the module itself.

We also need to assume that, A3: after a microcontroller is turned on, only authenticated driver
modules may take control of I/O devices. Once control is taken it is exclusive and never released.
This prevents attackers from taking direct control of output devices after a node resets. Driver
modules are thus part of the trusted computing base and their module keys are only known to the

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

11

infrastructure provider who authorizes exclusive connections to driver modules upon request from
the deployer and keeps track of the “ownership” of the driver modules.

Finally, we demand that A4: output driver modules do not produce outputs unless requested by the
application module, while input driver modules only generate outputs to application modules that
correspond to physical inputs.

To summarize, we have modeled physical output channels in such a way that:
(1) At startup, authenticated output driver modules take ownership over the (correct) output
devices. Unauthorized access and connection attempts from other software are forbidden;
(2) Application modules can take ownership of an output driver module only if the latter is not
already connected to other modules, and only if authorized by the infrastructure provider;
(3) After connecting to an output driver module, an application module retains exclusive access
to the output device until explicitly released. Thanks to point (1), exclusive access is retained
even across resets, although all connections need to be re-established.

For input modules, exclusive access is not strictly required. However, exclusive access to input
devices can be configured in the same way as for outputs, if desired. These conditions lead to the
following security properties:

• Assume that for a time interval 𝑇 the infrastructure provider only ever authorizes application
module 𝑀A to take control of device 𝐷 via driver module 𝑀D. If the deployer attests within 𝑇
that 𝑀A has taken exclusive access over output driver module 𝑀D, then from that moment until
the end of 𝑇 every output from 𝐷 can be explained alone by the code semantics of 𝑀A and 𝑀D
in relation to the inputs received by 𝑀A, i.e., no other module may cause outputs of 𝐷.

• If the deployer attests that 𝑀A has taken access over an input driver module 𝑀D, then from that
moment on until the access is released any output from 𝑀A can be explained alone by the code
semantics of 𝑀A and 𝑀D in relation to the physical inputs to 𝐷 and any other inputs received
by 𝑀A, i.e., an attacker cannot spoof inputs to 𝐷 for 𝑀A.

In practice, I/O devices may produce initialization outputs when a driver module takes control
of them after a reset. Handling these outputs is parts of the specificities of a driver implementation,
which we ignore where for simplicity.

3.5 Deployment
Deployment is the act of installing application modules on their nodes and setting up connections
between outputs and inputs. A5: The channel between deployer and infrastructure provider is assumed
to be secure, whereas communication with modules is performed over an untrusted network.

In phase 1, the deployer requests the infrastructure provider access to the driver modules
connected to physical I/O devices. For output devices, the deployer requests exclusive access, while
for input devices the deployer can choose between exclusive or shared access. Before granting
such access, A6: the infrastructure provider needs to ensure the authenticity of the driver module
controlling the I/O device, e.g., via attestation. If, for any reason, the infrastructure provider cannot
give access to some I/O devices (e.g., because an output device is already taken by someone else), the
deployment is aborted. Otherwise, the deployer receives connection keys from the infrastructure
provider (one for each I/O device), along with the guarantee that driver modules have correctly
taken control of the physical I/O devices (Sect. 3.4).

Phase 2 consists of deploying the application on the infrastructure. First, the deployer starts
by compiling each source module into a loadable image. Second, the deployment descriptor is
used to find the node on which the module should be deployed and sends its module loader a
LoadModule request. The deployer then performs the TEE-specific method of attestation calling the
Attest entry point of each SM, eventually setting up the module key. At the end of this step, the

12

Scopelliti and Pouyanrad et al.

deployer has a secure communication channel with each of its deployed source modules. Finally,
the deployer sets up the connections between modules, as well as the connections to the driver
modules. Regarding the former, the deployer generates a unique connection key and sends it to
both endpoints of the connection; for each endpoint, such key is encrypted using the module key
and passed to the SetKey entry point using the CallEntry API. Concerning the latter, instead,
connections are established via a similar interface, using the keys obtained in phase 1.

Security Discussion. During phase 1, the infrastructure provider plays an important role as a
trusted party, providing exclusive access to driver modules. A7: It is assumed that the provider does
not leak the driver module keys and that exclusive access to a device is reserved for the deployer until
they request to release it or a time T has passed (to which both the deployer and the provider have
agreed upon). In other words, no one else can acquire credentials to connect to the driver module
during that time.

If a reset on a node N occurs, then all driver modules belonging to that node need to be re-
initialized, and exclusive access re-configured (if previously set). Concerning the latter, A8: the
infrastructure must provide replay protection for messages exchanged in the protocol to establish
exclusive driver access, otherwise replay attacks might cause exclusive access to be unintentionally
set up for modules that formerly had access, but should not have it anymore.

Concerning application modules instead, a reset on node N would cause all modules of that node
to be re-deployed, re-attested, and connections for them to be re-established. Here, an attacker
could technically mount a sophisticated replay attack to restore a previous configuration of an
application; however, if replay protections for driver modules are correctly in place (as discussed
above), the attacker would not be able to trigger any illicit or stale outputs.

Note that the strong requirements on physical output drivers do not apply for virtual outputs to
software endpoints, such as secure databases or nodes belonging to a trusted party like the deployer.
Such receivers can verify the authenticity and freshness of outputs via cryptographic means and
reject replayed messages automatically, which is not possible for physical outputs to the real world.

3.6 Security Argument
Our goal is to ensure that all physical output events can be explained by the application’s source
code and the observed physical input events. More precisely: Consider a time frame starting at the
end of phase 1 of deployment (Sect. 3.5), and ending at a point where the deployer releases exclusive
access to any of the output devices they control. Assume the deployer has observed a specific sequence
of physical output events on one of these devices 𝐷O in the considered time frame, then there have been
contiguous sequences of physical input events on the input devices connected to the application such
that the observed outputs follow from these inputs according to the application source code semantics.
As an example, consider 𝐴Flo (Fig. 3a). If, after the application has been deployed, the water
supply is turned off, then there must have been physical input events that caused the field to flood.
Output events can only be produced by the application’s SMs; the assumption of a correct
compiler and the successful attestation then lead to the desired property. Due to assumptions A1-
A4, (1) a physical output event can only be produced by the corresponding device (𝐷O); (2) output
drivers have exclusive access to their device; and (3) an SM (𝑀O) has exclusive access to the driver;
thus only 𝑀O can initiate physical outputs on 𝐷O. Even if exclusive access is lost, e.g., due to a reset of
the corresponding node triggered by an attacker, the infrastructure prevents that any other module
can take control of 𝐷O and produce rogue outputs, thanks to assumptions A5-A8. The construction
of SMs ensures that a module can only be invoked through its two entry points. Of these, only
HandleInput can result in output events (Figs. 4 and 5). Since HandleInput authenticates its input,
output events are always the result of correct input events. Finally, as our deployment scheme only

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

13

allows for two types of correct input events, physical input events and outputs from other modules,
our security property follows.

3.7 Software Updates and Re-Deployment
In Sect. 3.5, we described a static deployment where the whole application is deployed at once;
however, it is also possible to deploy application modules dynamically. Specifically in scenarios
where the the configuration of an application may change during its lifetime due to the recon-
figuration, addition, or removal of sensors or processing nodes, or the deployment of additional
applications on existing infrastructure, software updates become essential. In our smart irrigation
system from Figure 1, this may, e.g., happen with changing environmental conditions or when
plots are re-allocated for different crops.

Two common scenarios that may occur at runtime are software updates and re-deployments. The
former consists of deploying an updated version of an SMs that, e.g., provides new functionality
or fixes some bugs; the latter does not necessarily require code changes but may be needed when
an SM crashes or needs to be migrated to another node. Our design for software updates and
re-deployments consists of three steps:

(1) Deployment of the new SM. In the first step, the new SM is compiled, deployed on the infras-
tructure alongside the already running SMs, and finally attested. If any of these operations
fails, the update is aborted. Note that the new SM will not process any events until connections
are configured through its SetKey entry point (step 3).

(2) Deactivation of the old SM. In this step, the old SM is removed from the infrastructure. This is
the point in time from which the application will start suffering from connectivity loss, until
the new SM will be completely configured. Optionally, state may be transferred to the new
SM before taking down the old one.

(3) Re-establishment of connections. Here, all the connections associated to the old SM must be
re-configured in order to point to the new SM. This process involves calling the SetKey
and AddConnection entry points on the involved SMs and event managers, as for a static
deployment (Sect. 3.5); each connection retains its connection identifier, but keys are rotated
for security reasons. Similarly, connections between the SM and I/O devices must be re-
configured as well, if any (Sect. 3.4). At the end of this step, the update will be completed.

We evaluate the impact of software updates in Section 5.2.4. Note that actions 2 and 3 can also be
executed in reverse order, if desired. Re-establishing the connections before disabling the old SM
would result in a smaller availability disruption, but it may also cause inconsistent state if events
are generated during the update. For example, some events might be processed by the old SM and
some other events by the new SM, causing undefined behavior. As our framework mainly focuses
on integrity rather than availability, we should prevent such inconsistencies from occurring, for
example by implementing a sort of synchronization mechanism between old and new SMs during
the update. However, this would increase the complexity of our framework without providing
substantial benefits compared to our original update strategy. Hence, we decided not to investigate
this option further.

Transferring the state from the old to the new SM may be done in several ways. For instance, the
sealing feature of certain TEEs (such as Intel SGX) allows an SM to securely store data persistently
on disk, although it requires the new SM to be deployed on the same node as the old one. Our
design already provides some basic support for state transfer by creating a temporary connection
between the two SMs. In particular, a transfer output in the old SM may be connected to a restore
input in the new SM, then the state migration can be triggered by calling a save entry point in the
old SM that generates the transfer event. This would allow state to be securely transferred between

14

Scopelliti and Pouyanrad et al.

the two modules, even in different nodes. Of course, the deployer still needs to manually implement
the save and restore functions in order to specify what data needs to be migrated. This protocol,
however, requires the old SM to be up and running at the time of the update, and therefore cannot
be applied if the module was disabled before, e.g., due to a crash or a reset on the node.

4 IMPLEMENTATION
Originally [47], we created a fully functional prototype of our design based on the hardware-only
embedded TEE Sancus [46]. In later work [54], we extended our support to the commercial Intel
SGX [42], a TEE for high-end x86 processors. Lately, we added support for a third TEE, based on
ARM devices equipped with TrustZone technology [5].

As the implementations for all TEEs are compatible with each other, we can support heteroge-
neous deployments in which an SM can send protected events to any other SMs, regardless of the
actual TEE technologies used. This enables a wide variety of use cases that combine sensing and
actuation with clod and edge processing. As such, our running example in precision agriculture
is scalable from small local applications such as an automated irrigation system to more complex
deployments that feature, e.g., a wide range of sensors and actuators, and that involve complex
data aggregation and processing. For example, we could have an authentic trace that starts from a
Sancus sensor that leverages Secure I/O to collect measurements, then continues on a TrustZone
gateway that forwards the measurements to an Intel SGX aggregator in the cloud, and finally ends
with a command to actuate an output I/O device, sent back to a Sancus output driver through the
same TrustZone gateway.

This chapter is structured as follows: Sect. 4.1, 4.2 and 4.3 describe each of these three implemen-
tations separately, emphasizing on the features of their underlying TEEs. For each implementation
we describe: (1) the underlying security architecture, including data and code isolation as well as
the root of trust, (2) the process of compiling applications into security modules and the processing
of inputs and outputs, (3) the untrusted runtime, in particular the realization of the LoadModule
and CallEntry requests, (4) the attestation protocol including the generation of attestation evidence
and the establishment of module keys, (5) the configuration of secure communication endpoints,
and (6) where available, the realization of secure I/O channels and protected driver modules. The
main differences of the three implementations are then summarized in Sect. 4.4. Next, Sect. 4.5 illus-
trates the deployment phase. Finally, Sect. 4.6 introduces an optional component used to facilitate
attestation and key management.

4.1 Sancus
Sancus [46] is an OpenMSP430-based TEEs designed for low-cost and low-power embedded appli-
cations. As described in Sect. 3.1, Sancus divides SMs in two sections, the (public) code section and
the (private) data section, enforcing strict access rules for both. An SM’s code section can only be
entered through a single entry point: its first instruction. The compiler assigns each user-defined
entry point an integer identifier and adds an entry stub that evaluates such an identifier, dispatching
to the correct entry point. Besides, private data is only accessible by the module’s code.

4.1.1 Enclave development. The Sancus toolchain comes with a C compiler, libraries, and other
tools that are needed to develop and build applications composed of one or more Sancus enclaves.
Developers can define enclaves by annotating code and data using special macros defined in the
Sancus trusted library: functions can be marked as either entry points or internal functions, using
the SM_ENTRY and SM_FUNC macros respectively. Besides, variables annotated with SM_DATA will be
allocated in the private data section, making it accessible only from inside the enclave.

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

15

Fig. 9. A translation of module 𝑀FloS1 (Figs. 2
and 3a) to C using the annotations understood
by our compiler.

SM_OUTPUT ( FloS1 , Flooded );
SM_DATA ( FloS1 ) int flooded , count ;

SM_INPUT ( FloS1 , Sensor , data , len ) {

if ( len > 0) {

if ( data [0] >= SATURATED ) {

flooded = 1;

} else {

flooded = count = 0;
Flooded (& flooded , sizeof ( flooded ));

}

}

}
SM_INPUT ( FloS1 , Tick , data , len ) {
if ( flooded && ++ count > MAX ) {

Flooded (& flooded , sizeof ( flooded ));

}

}

Furthermore, Sancus provides an untrusted library to initialize enclaves and call their entry
points. Pointers passed to an entry point must be properly sanitized to ensure that they do not
point to enclave memory. Return values, instead, are copied from trusted to untrusted memory.
The untrusted library also provides a function to dynamically load new enclaves at runtime; in our
framework, this functionality is used to deploy application SMs.

At compile time, the Sancus compiler builds the application into a single binary that includes both
untrusted runtime (e.g., the main function) and static enclaves. Such binary can then be loaded into
a Sancus microcontroller using the dedicated loader. Besides, the Sancus toolchain also provides
a tool to retrieve the module key of an enclave given a binary file, which is essential in order to
attest the enclave from outside the microcontroller (Sect. 4.1.4).

4.1.2 APIs. Our implementation is a literal translation of the design outlined in Sect. 3.2. All
modifications to the Sancus compiler are extensions, and all original Sancus features are still
available to programmers (e.g., calling external functions or other SMs). On top of the existing
annotations we added two new ones: SM_INPUT and SM_OUTPUT for specifying inputs and outputs.
Fig. 9 shows an example module written in C using our annotations.

SM_OUTPUT expects a name as argument (more specifically, a valid C identifier). For every output,
the compiler generates a function with the following signature: uint16_t name(char* data,
size_t len). This function can be called to produce an output event. For input handlers, SM_INPUT
generates a function with the same signature as above. In this function, the programmer has access
to a buffer containing the (unwrapped) payload of the event that caused its execution. For both
inputs and outputs, the names provided in annotations are used in the deployment descriptor.

4.1.3 Untrusted Runtime. The untrusted runtime consists of a single application, the event manager,
which implements all the untrusted API requests described in Sect. 3.3. The ELF binary is compiled
together with a ported version of RIOT OS [7], an operating system specifically designed for devices
with limited resources such as our OpenMSP430-based Sancus.

Our event manager was initially developed for an experimental version of Sancus RIOT [4].
Future work will adapt the event manager to the latest Sancus hardware and RIOT, in order to fully
leverage common OS features as well as the protected scheduler, a fundamental component for
providing availability guarantees to Sancus enclaves, as discussed in 6.2.

4.1.4 Attestation and secure channels. Sancus uses a three-level key hierarchy for remote attestation
and secure communication. Every node contains a node key, which is only known by the node’s
owner, the infrastructure provider. Every vendor who is to install SMs on a particular node is
assigned a unique identifier. The second level of keys, vendor keys, is derived from the node key and
these vendor identifiers. Finally, module keys are derived from a vendor key using an SMs module

16

Scopelliti and Pouyanrad et al.

identity. This module identity – the concatenation of the contents of the module’s code section
and the load addresses of both its sections – is used for authentication and attestation. The module
key is calculated by the Sancus hardware when a module is loaded and can also be calculated by
the module’s vendor. Since the hardware ensures that module keys can only be accessed by the
corresponding SM, it is guaranteed that the use of a certain module key (e.g., by creating a Message
Authentication Code (MAC)) implicitly attests the module’s identity.

The Attest entry point (Sect. 3.2) leverages a challenge-response protocol to verify that a Sancus
SM is up and running on a specific node at a certain time. The challenge consists of a random
sequence of bytes generated by the deployer, long enough to prevent replay attacks. The Sancus
SM computes a MAC over the challenge using its module key, and sends the result back to the
deployer. The latter performs the same operation: attestation can be considered successful if the
result matches the response provided by the SM.

Sancus’ crypto engine uses SpongeWrap [9] as encryption algorithm with spongent [10] as
the underlying hash function to calculate MACs. The interface to the crypto engine is provided by
two instructions: Encrypt takes a plaintext buffer, associated data (which will be authenticated
but not encrypted), and a key and produces the ciphertext and an authentication tag (i.e., a MAC);
Decrypt, given the ciphertext, associated data, tag and key, produces the original plaintext or raises
an error if the tag is invalid. For both instructions, the key is an optional argument with the calling
module’s key as a default value. As with the original version of Sancus, this is the only way for a
module to use its key.

Secure I/O. This section describes how protected drivers can be implemented using Sancus.
4.1.5
Remember that, for output channels, we want an application module to have exclusive access
to a driver (Sect. 3.4). This, in turn, implies that the driver should have exclusive access to the
physical I/O device. Although for input channels the requirements are less strict – we only need to
authenticate a device – for simplicity, we also use exclusive device access here.

Exclusive Access to Device Registers. Sancus, being based on the OpenMSP430 architecture, uses
Memory-Mapped I/O (MMIO) to communicate with devices. Thus, providing exclusive access to
device registers is supported out of the box by mapping the driver’s private section over the device’s
MMIO region. There is one difficulty, however, caused by the private section of Sancus modules
being contiguous and the OpenMSP430 having a fixed MMIO region (i.e., the addresses used for
MMIO cannot be remapped). Thus, a Sancus module can use its private section either for MMIO or
for data but not for both. Therefore, a module using MMIO cannot use any memory, including a
stack, severely limiting the functionality this module can implement.

We decided to solve this in software: Driver modules can be split in two modules, one performing
only MMIO (mod-mmio) and one using the API provided by the former module to implement the
driver logic (mod-driver). The task of mod-mmio is straightforward: for each available MMIO
location it implements entry points for reading and writing this location, and ignores calls by
modules other than mod-driver. This task is simple enough to be implemented using only registers
for data storage, negating the need for an extra data section.

This technique lets us implement exclusive access to device registers on Sancus without changing
the hardware representation of modules. Yet, it incurs a non-negligible performance impact because
mod-mmio has to attest mod-driver on every call to one of its entry points. Doing the attestation
once and only checking the module identifier on subsequent calls is not applicable because it
requires memory for storing the identifier. We address this by hard-coding the expected identifier
of mod-driver in the code section of mod-mmio. During initialization, mod-driver checks if it is
assigned the expected identifier and otherwise aborts. mod-driver also attests mod-mmio, verifying
module integrity and exclusive access to the device’s MMIO registers. On failure, mod-driver

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

17

aborts as well. The expected identifier of mod-driver can be easily deduced as Sancus assigns
identifiers in order: the first loaded module takes identifier 1, the second 2, and so forth.

Sancus did not support caller authentication [46], which we require for mod-mmio to ensure
invocation by mod-driver only. We added this feature by storing the identifier of the previously
executing module in a new register, and added instructions to read and verify this SM identity.

Secure Interrupts. On the OpenMSP430, interrupt handlers are registered by writing their address
to the interrupt vector, a specific memory location. Thus, handling interrupts inside SMs is done by
registering a module’s entry point as an interrupt handler. If the SM also supports “normal” entry
points, a way to detect whether the entry point is called in response to an interrupt is required.

More generally, we need a way to identify which interrupt caused an interrupt handler to be
executed. Otherwise an attacker might be able to inject events into an application by spoofing
calls to an interrupt handler. To this end, we extended the technique used for caller authentication.
When an interrupt occurs, the processor stores a special value specific to that interrupt in the
new register to keep track of the previously executing module. This way, an interrupt handler can
identify by which interrupt it was called in the same way modules can identify which module
called one of their entry points. The processor ensures that these special values used to identify
interrupts are never assigned to any SM.

Interfacing with Applications. Our implementation follows the design in Sect. 3.4 to connect an
application SM to a driver SM via connection keys. As we assume that driver modules are provided by
the infrastructure, a deployer needs to interact with the infrastructure provider for the distribution
of connection keys to the drivers. In fact, these keys need to be encrypted and authenticated using
an SM’s module key which, for driver modules, are only known by the infrastructure provider.

In our implementation, driver and MMIO modules are static enclaves embedded in the application
binary loaded in the Sancus microcontroller (Sect. 4.1.1). At startup, these modules are immediately
initialized to gain exclusive access to their I/O devices (A3). To change this behavior, an attacker
would require physical access to the microcontroller in order to upload a malicious binary; however,
this is out of scope (Sect. 2.3).

The infrastructure provider can then keep track of which deployer has exclusive access to a
driver SM at a certain time, denying requests coming from other deployers for the whole duration
of the exclusive access period, or until the deployer explicitly gives up access (A7).

In our case, giving exclusive access means encrypting and authenticating the connection key
(provided by the deployer) with the driver’s module key, sending the result data back to the deployer;
the communication between deployer and infrastructure provider should be done via a secure
channel. The deployer would then be able to gain exclusive access to the driver SM by calling its
SetKey entry point (or equivalent) using the encrypted payload as argument. Regarding input
drivers, the infrastructure provider may allow non-exclusive access by simply accepting requests
from multiple deployers at the same time; if needed, a deployer may ask for exclusive access by
adding an additional bit of information to the request. To prevent replay attacks, the payload passed
to the SetKey entry point contains a unique nonce that the driver SM can verify against a reference
stored in memory (A8). This nonce must be rotated every time exclusive access is reconfigured.

In summary, our design for Secure I/O in Sancus consists of the following protocol:

(1) The deployer sends an initial request to the driver SM asking for its current nonce. The driver

retrieves the nonce from secure memory and sends it back to the deployer.

(2) The deployer then sends the nonce and the connection key to the infrastructure provider via
a secure channel (A5). Due to the static driver setup in Sancus, the provider knows that only
authentic drivers have control of I/O devices (A6). The provider only ensures that the driver

18

Scopelliti and Pouyanrad et al.

SM is not already taken by someone else and, if so, may grant the deployer exclusive access.
To this end, the provider encrypts and authenticates the input data with the driver’s module
key, returning it to the deployer.

(3) The deployer then forwards the encrypted payload to the driver SM, which decrypts and
authenticates it. If the nonce matches with the one stored in memory, the driver establishes
exclusive access by storing the connection key into memory and using said key to decrypt
future payloads. Finally, the driver sends an authenticated confirmation to the deployer using
the same connection key, then generates a new nonce for the next run of the protocol.

Since only authentic drivers can decrypt the data using their module keys and complete the
protocol illustrated above, the reception of the confirmation message allows the deployer to conclude
that they indeed have acquired exclusive access to the desired I/O device (A2). If the protocol
does not complete for any reason (e.g., an attacker blocks one of the messages between driver
and deployer), the deployer would never receive a confirmation from the driver SM; as such, the
deployer would not trust outputs generated by that driver.

In case of node resets, the deployer would not lose exclusive access to the driver because the
infrastructure provider would not complete step (2) of the protocol with another deployer (A7).
However, the original deployer would have to run the protocol again to restore connectivity,
rotating connection keys to prevent replay attacks.

An important aspect to consider is that monotonic counters as nonces are not enough to prevent
replay attacks, because in case of resets on the node the driver module would lose information
about the current nonce. This problem can be solved by either (1) storing the current nonce in
secure persistent storage, or (2) generating a random nonce each time. As Sancus currently provides
neither persistent storage nor an RNG, we leave this issue to future work.

4.2 Intel SGX
Intel SGX is a TEE included in commercial Intel processors, consisting of hardware primitives and
a set of instructions that can be used to isolate code and data of an application in protected memory
regions called enclaves. Access to an enclave is restricted to specific entry points, which memory is
encrypted at runtime and only accessible from within the enclave. Thus, neither the host OS nor
other software can access enclaves’ code and memory, which results in a reduced TCB.

The architecture of Intel SGX provides an enclave with two measurement registers, called
MRENCLAVE and MRSIGNER. The former contains the enclave identity, which consists of an SHA-
256 hash over the content of the enclave’s code and data and some additional information regarding
the build and initialization process. The latter, instead, contains the author identity, i.e., the hash of
the author’s public key – the author is the entity who signs the enclave before distribution. These
two identities are then used as reference values for both local and remote attestation, as well as to
generate sealing keys that allow the enclave to securely store persistent data on disk.

4.2.1 Enclave development. To develop an Intel SGX application, Intel provides its own SDK written
in C/C++. Here, the application is partitioned into two sections: the untrusted code and the enclave.
Communication between trusted and untrusted applications is made through a specific interface,
defined by the developer using a C-like syntax called Enclave Definition Language (EDL). Calls from
the untrusted application to the enclave are made via well-defined entry points named ECALLs,
while untrusted functions are made available to the enclave via OCALLs.

Recently, new frameworks have been introduced that allow developers to write enclaves in
modern languages and with reduced effort. In our framework, we leverage Fortanix Enclave
Development Platform (EDP) [20], an SDK written entirely in the memory-safe Rust. EDP abstracts
the Intel SGX layer away from a developer, who can write an enclave similar to native application;

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

19

Fig. 10. A translation of module 𝑀FloS1 (Figs. 2
and 3a) to Rust using the annotations understood
by our Intel SGX parser.

/* global variables definition omitted for brevity */

// @ sm_output ( Flooded )

// @ sm_input
pub fn Sensor ( data : &[ u8 ]) {

if data . len () > 0 {

if data [0] >= SATURATED {

flooded = true ;

} else {

flooded = false ;
Flooded (&[0]);

}

}

}
// @ sm_input
pub fn Tick ( _data : &[ u8 ]) {

if flooded {

count += 1;
if count > MAX {
Flooded (&[1]);

}

}

}

the necessary bindings are automatically added at compile time. EDP is seamlessly integrated with
the Rust standard library, although some functionalities are not available for security reasons.

4.2.2 APIs. Our implementation of the design illustrated in Sect. 3.2 aims to reduce the development
effort as much as possible. As described above, Fortanix EDP already gives huge benefits to a
developer by abstracting the Intel SGX layer away, taking care of secure argument passing, data
and code isolation, etc. In addition, our framework provides a simple mechanism to declare outputs
and inputs by using code annotations, which are parsed by the framework at deployment time in
order to retrieve information about the module’s endpoints and to inject required code. These
annotations are analogous to the Sancus implementation described in Sect. 4.1.2, although we rely
on special single-line comments instead of using macros (Fig. 10).

Output and input events are designed to be asynchronous: after an output event is generated, the
SM resumes its execution immediately, and no return values are expected. Asynchronous events
work well if they are generated from physical events (e.g., a button press), as the only purpose of
the associated SM is to notify one or more other SMs to which it has active connections. However,
in some other cases synchronous events might be necessary, for example for querying a database.
Here, a return value is expected and the SM that generated the output event might want to block
the execution until the value is received. To address this need, the Intel SGX implementation comes
with two additional annotations: //@ sm_request and //@ sm_handler. Request-handler events
are similar to output-input events, however a request blocks the execution until the connected
handler (if exists) returns a value.

4.2.3 Untrusted Runtime. The untrusted runtime consists of an untrusted Linux process that
implements the logic illustrated in Sect. 3.3. Concerning the execution of new SMs, Fortanix EDP
provides a default runner for Intel SGX enclaves called ftxsgx-runner, responsible for loading and
executing an enclave. Thus, when a new LoadModule request arrives, the event manager spawns a
new process using the Rust’s std::process::Command API, executing ftxsgx-runner and passing
as argument the enclave’s binary and signature. To realize CallEntry requests, our SGX compiler
adds a simple TCP server as a front-end to the SM. At compile time, each SM is assigned a free
port in the same network namespace as the event manager, so that they can exchange events with
each other via localhost.

20

Scopelliti and Pouyanrad et al.

4.2.4 Remote attestation and secure channels. In a nutshell, the remote attestation of an Intel SGX
enclave consists of the following steps: (1) an attestation request sent to the enclave, issued by a
remote entity (the challenger). The request should contain a challenge that will be included in the
attestation evidence to provide freshness; (2) the generation of an attestation evidence, also called
Quote, which includes information about the identity of the enclave and the platform where the
enclave is running (hardware information, BIOS version, etc.); (3) the verification of the quote, first
to ensure its authenticity and then to verify that the enclave and hardware are in a good state.

A quote is generated by a dedicated enclave called Quoting Enclave (QE), which resides on the
same platform as the enclave to be attested. The quote is protected using cryptographic keys unique
to that particular platform. A trusted third party is then responsible for the quote verification, to
ensure that (1) the quote is authentic, and (2) the hardware and firmware of the platform are up to
date. After that, the challenger verifies the identity of the enclave, ensures that the quote is fresh
(i.e., the challenge is included in the quote), and finally decides whether to trust or not the enclave.
Our framework supports the Enhanced Privacy ID (EPID) attestation scheme1 [25], for which a
Rust implementation already existed2. The scheme also involves a mutually-authenticated Diffie-
Hellman key exchange between challenger and enclave; we leverage this protocol to establish a
shared secret between a module and its deployer, which will be used as the module key.

Secure I/O. Unfortunately, SGX does not support secure I/O channels out of the box. In
4.2.5
fact, it is by design impossible to map DMA devices into enclave memory [14]. While academic
solutions have been proposed to overcome these issues (Sect. 7.3), they usually require additional
trusted hardware [66] and software [32, 50, 63] to establish tamper-proof, exclusive channels to
I/O devices. Hence, our framework does not support physical I/O channels for SGX-based SMs.
Nevertheless, in the IoT settings we envision, SGX-based modules will likely be deployed in edge
or cloud computing platforms where physical inputs and outputs are less relevant. Instead, such
modules may be used for monitoring and control of a number of IoT gateways or devices. As such,
they would be connected to virtual endpoints in the deployer’s trusted back-end system using
credentials that are securely stored in enclave memory.

4.3 ARM TrustZone
TrustZone is a very common TEE implemented in the different flavors of recent ARM processors,
which applies strong system-level isolation by separating both system hardware and software
resources into two domains, namely the Normal World, and the Secure World, protecting the code
and data in the secure world from being directly accessed or modified by the normal world [51].
To perform the secure context switching between worlds, ARM Cortex-A processors introduced
a new CPU mode called monitor mode, which runs at the highest execution level of the secure
world. The monitor mode can be entered via an interrupt, external abort, or explicit call of a
special privileged instruction: Secure Monitor Call. Then, the value of the least significant bit of the
Secure Configuration Register, known as the Non-Secure bit is changed and propagated through
the AXI system bus to the memory and peripherals to preserve the process security state. On
ARM Cortex-M processors, hardware is responsible for the transition between worlds, which
optimizes switching overhead [45, 51]. In this paper, we only focused on the features of TrustZone
for Cortex-A processors.

The normal world runs a general-purpose operating system, such as Linux or Android, and
untrusted (client) applications, while a lightweight TEE operating system and trusted applications

1We implemented EPID for simplicity, though other attestation schemes could be supported as well. From a security
perspective, all these schemes would provide similar guarantees.
2https://github.com/ndokmai/rust-sgx-remote-attestation

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

21

(TAs) run in the secure world. In this paper we rely on Open Portable Trusted Execution Envi-
ronment (OP-TEE) [33], which implements a secure operating system (the OP-TEE OS), a secure
monitor, a non-secure user-space library called OP-TEE client exposed to the client applications,
and a set of build toolchains to facilitate the development of TAs.

TrustZone relies on a secure boot process to prevent a system from being attacked during the
booting process and enforce a strong system integrity policy. Secure boot forms a Chain of Trust
by leveraging a signature scheme based on RSA to verify system images before their execution [37].
Concretely, the boot process operates as a sequence of stages, each former boot stage loads and
checks the signatures of the next follow-on stage, usually initiated from the root of trust (RoT).
RoT is usually a public key that is stored in the trusted root-key storage registers and cannot be
modified [6].

4.3.1 TA development. To develop a TA, OP-TEE provides its own SDK to both build and sign the
TA binary with a private RSA key, then the signature is verified by OP-TEE OS upon loading of the
TA to check its integrity. A TA must implement a couple of mandatory C-like syntax entry points
to allocate some session resources and execute the target services. Communication with a TA is
established by initiating a request from the client application through some defined entry points
in the OP-TEE client to load the intended TA binary and its libraries into the secure memory. To
identify a TA to be used, the client provides a unique 16-byte value called UUID that is generated
by the developer. Then, the desired services in the TA are invoked from the client application by
passing a so-called command ID which is also defined at compile time.

4.3.2 API. In our framework, we intend to provide a high-level abstraction over the TEE layer
that allows developers to focus only on application logic. Further to the abstraction provided by
GlobalPlatform TEE Internal Core API in OP-TEE, we define annotations SM_ENTRY, SM_INPUT,
and SM_OUTPUT similar to the mechanism described in Sect. 4.1.2 to specify respectively entry
points, inputs, and outputs of each TA. The provided annotations take a name as an argument
that is chosen by the developer. Then, our framework produces the desired functions using some
defined macros at deployment time. Likewise, the remaining required codes for developing a TA
such as communication with a client application and cryptographic operations are injected by our
framework automatically. Thereby, the provided abstraction enables the developer to implement
complex logic without knowledge of the TA implementation in OP-TEE.

4.3.3 Untrusted Runtime. The untrusted runtime involves an unprotected application running on
Linux which is called the event manager to implement all the components outlined in Sect. 3.3.
Our event manager leverages the GlobalPlatform TEE Client API implemented in OP-TEE client
library to communicate with TAs. This API provides a set of functionalities for initializing and
running TAs in the secure world as well as mechanisms for passing data to them. Therefore, when
a new LoadModule request arrives, the event manager first establishes a connection with TEE
through TEEC_InitializeContext(...) function which returns a context object ctx. Second, a logical
connection with a specific TA within the scope of ctx is created by passing UUID of the desired
TA to TEEC_OpenSession(...) function. When a session is opened, the TA’s binary and its libraries
are loaded into the secure memory. This session is then used to invoke the TA’s entry points for
CallEntry requests using TEEC_ InvokeCommand(...), which takes as parameters a command ID
defined for the intended entry point as well as the expected payload. Our event manager uses
this operation payload to exchange events with a TA through shared memory. It is noteworthy to
mention that the entry points verify the type of parameters before using them to check its value
according to the expected parameter. In addition, the data passed to entry points is encrypted and

22

Scopelliti and Pouyanrad et al.

Fig. 11. Our remote attestation process for ARM
TrustZone with OP-TEE.

authenticated. Thereby, any malicious attempts to call an undesired entry point or modify the
payload would result in a failed cryptographic operation.

4.3.4 Remote attestation and secure channels. Remote attestation is a crucial security feature for
our framework that provides an authorized party with cryptographic proof that a known and
benign TA is initially loaded on a valid TrustZone device. In contrast to Sancus and Intel SGX, the
TrustZone specification offers no mechanism for remote attestation. Some existing approaches
leverage hardware components such as a hardware Trusted Platform Module (TPM) or a firmware-
based TPM (e.g., Microsoft’s fTPM [53]) that provides security guarantees similar to a hardware
TPM, to perform attestation. In our work we avoid the added complexity and substantial increase
of the TCB, and introducing no additional hardware. Instead we propose an attestation mechanism
based on native TrustZone features.

Our design is based on Sancus’ remote attestation scheme (Sect. 4.1). Analogously, our approach
relies on symmetric cryptography and a three-level key hierarchy. We build upon an OP-TEE
proof-of-concept implementation for remote attestation that requires minimal hardware features
and assumptions3, avoiding the use of an TPM/fTPM as they are not available on many platforms.
We implemented an attestation protocol derived from the OP-TEE proof-of-concept to address the
requirements of our framework, while minimizing the run-time TCB.

Our scheme assumes that each TrustZone device is equipped with a Hardware Unique Key (HUK)
(also called endorsement key in other technologies), which can be created at manufacture time and
stored either in hardware fuses or the secure eMMC partition. Similar to hardware devices like the
TPM or Sancus, the HUK is protected from unauthorized access and can be used as root-of-trust
of the TrustZone device. Since the secure boot process guarantees system integrity, OP-TEE can
be treated as the trusted base for accessing the HUK, and the isolation properties provided by
TrustZone protect secure-world code at run-time. Thus, we get a strong guarantee that the HUK
can only be accessed by privileged code in the secure world.

To leverage the HUK and provide attestation primitives to the TAs, we developed an attestation
Pseudo Trusted Application (PTA)4 that is statically built into the OP-TEE core and runs at the
same privileged execution level as the OP-TEE OS. Analogous to Sancus attestation, this PTA uses
a Key Derivation Function (KDF) to retrieve symmetric vendor and module keys from the HUK. In
particular, the vendor key is computed as follows:

𝑣𝑒𝑛𝑑𝑜𝑟 _𝑘𝑒𝑦 := 𝐾𝐷𝐹 (𝐻𝑈 𝐾 ∥ 𝑣𝑒𝑛𝑑𝑜𝑟 _𝑖𝑑)

3See https://github.com/OP-TEE/optee_os/issues/3189/ and https://github.com/OP-TEE/optee_os/pull/4011/. Very recently,
attestation is being picked up and included in release 3.17 (April 2022) by the OP-TEE team again.
4PTAs are an OP-TEE concept. They provide interfaces that are exposed by the OP-TEE Core to client TAs. See https:
//optee.readthedocs.io/en/latest/architecture/trusted_applications.html for more details.

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

23

Identically to Sancus (cf. Section 4.1), vendor_id is a unique identifier assigned to the software
vendor, and the vendor_key needs to be securely communicated out-of-band. The vendor_id is
then embedded in the TA code and passed to the PTA during the attestation process. The module
key, instead, is computed as:

𝑚𝑜𝑑𝑢𝑙𝑒_𝑘𝑒𝑦 := 𝐾𝐷𝐹 (𝑣𝑒𝑛𝑑𝑜𝑟 _𝑘𝑒𝑦 ∥ 𝑇 𝐴_ℎ𝑎𝑠ℎ)
The TA hash is used by the OP-TEE OS to verify the integrity of the TA at load time5. We made
minimal changes to the OP-TEE OS to store the hash in secure memory after loading a TA, so that
it could be retrieved by the attestation PTA for computing the module key. The module key can be
also used to establish a secure communication channel between the TA and the remote party.

Our remote attestation process shown in Fig. 11 is illustrated in detail as follows:
(1) The verifier sends an attestation request to the client application running in the normal
world on the target device. The request contains a randomly generated challenge to provide
freshness. Then, the client application passes the received challenge to the intended TA
through shared memory.

(2) The TA leverages the attestation PTA to obtain the module key K. The attestation PTA
performs a double derivation to retrieve the module key from the HUK, as explained above.
To do so, the vendor identifier is passed as parameter by the TA itself, whereas the TA hash is
fetched from secure memory. After receiving K, the TA calculates a MAC D of the provided
challenge.

(3) The TA sends D to the client application through shared memory and then D is forwarded to

the remote verifier.

(4) The verifier derives the same module key K from the vendor key and TA hash. Then, the
verifier uses K to compute a MAC of challenge and then compares it with the received MAC.
If the two values match, the target device is authenticated and the TA integrity is verified.
The KDF used in our proof-of-concept is a simple SHA-256 hash, though we truncate the module
key to 128 bits to align its size with the other TEE implementations. For MAC function we leveraged
the AES-128-GCM authenticated encryption scheme, using the challenge as associated data.

Similarly to Sancus, attestation binds a TA to a specific node because the module key is (indirectly)
derived from the HUK. Deploying the TA on a different node would result in a different module
key. Since the TA’s UUID is hard-coded, multiple instances of the same TA would have different
hashes and consequently different module keys, provided that each instance uses a different UUID.
This attestation scheme gives strong guarantees that a TA is running expected code on a particular
TrustZone node. The freshness of the challenge prevents replay attacks, ensuring that the TA is up
and running at the time of the attestation. Adversaries cannot learn the module key by sniffing
the network traffic, nor can they impersonate a TA to compute the response to the challenge.
Besides, any attempt to modify the messages between TA and verifier would only result in a failed
attestation. However, the scheme relies on the security of the HUK and vendor key: if a HUK is
leaked, all TAs deployed on its corresponding TrustZone node are compromised, while leaks of
a vendor key only compromises the TAs of its corresponding software vendor deployed on its
corresponding node. Hence, a device manufacturer should provide software vendors with a secure
interface (e.g., an authenticated API) to retrieve the vendor key for a specific TrustZone node.

Secure I/O. TrustZone leverages dedicated hardware components to enforce hardware iso-
4.3.5
lation to the I/O devices. Specifically, TrustZone introduces the TrustZone Protection Controller
to define the access restrictions for peripherals and configure them as secure and non-secure

5The TA’s binary structure and loading process are described in detail at https://optee.readthedocs.io/en/latest/architecture/
trusted_applications.html.

24

Scopelliti and Pouyanrad et al.

Table 1. Comparison of TEE hardware features and the resulting security guarantees and application capabil-
ities in our framework. This table is derived and adapted from [36]. Footnotes — a: We consider TrustZone
with the OP-TEE OS and our extensions for attestation.

n

n

n

P r o t e c ti o
A tt e s t a ti o
A tt e s t a ti o
o r y
a li n
M e m
e
S

e

S

g

o

d

C

C

C

B

T

o
e c

n

I s o l a ti o
S W

Sancus

SGX

TrustZonea

n ti a lit y

e

d

fi

n

u r e I/ O

T

n l y
g r a
p

C

e
d
P r e

B

b l e
a
e m

D

B
C
n
a m ic

T
p ti o
n
y

H W - O

U

u t

o

y

a

L

Target ISA

MSP430 (16-bit)

x86_64 (64-bit)

ARM (32-bit)

= Yes;

= Possible;

= No

dynamically or statically. This is achieved by the reflection of Non-Secure bit into the respective
peripheral. Several works take the advantage of TrustZone to establish a trusted I/O path for
different purposes [15, 31, 57, 71] (Sect. 7.3). Our framework does not support physical I/O channels
for TrustZone-based modules yet but rather interfaces Sancus-enabled I/O devices.

4.4 Comparison: SMs on different TEEs
Tab. 1 summarizes the features of each TEE and highlights their main differences. This table is
derived and adapted from [36]. Note that for TrustZone we consider OP-TEE OS with our attestation
extensions. The key points that distinguish our TEEs are a) software isolation which is supported
by all three TEEs and where we provide common interfaces to control isolation and event handling;
b) attestation primitives, which are not available on all TEEs and we provide attestation support
as necessary and establish common Attest entry point and event handler abstracting for our
framework; and c) secure I/O, which is only natively supported with Sancus and where we design
generic scheme that can hopefully be instantiated by other TEEs, in particular by ARM TrustZone.
Software isolation and attestation are strict requirements in our design (Sect. 3.1), which are fully
satisfied by Intel SGX and Sancus. For TrustZone, instead, we relied on OP-TEE OS for isolation,
whereas we designed and implemented our own attestation protocol based on Sancus (Sect. 4.3.4).
Other than code integrity and authenticity, attestation may also provide additional information,
such as the security configuration of the underlying TCB (Intel SGX), or the guarantee that an SM
is running on a specific node (Sancus and TrustZone). The latter is particularly useful when dealing
with driver modules (Sect. 3.4). Besides, only Intel SGX protects the integrity and authenticity of
data from physical attacks, thanks to its Memory Encryption Engine (MEE).

Both Intel SGX and TrustZone support sealing, i.e., storing data securely on permanent storage.
However, our framework does not currently provide any abstraction over sealing primitives,
meaning that developers need to manually implement code to call such primitives. Similarly, code
confidentiality (i.e., deploying encrypted SMs in order to protect sensitive code and static data)
is a feature supported by all architectures, though not essential for the use cases we consider.
Nevertheless, both sealing and code confidentiality could be addressed in future work. Besides,
Sancus fully supports secure I/O (Sect. 4.1.5), while on TrustZone and Intel SGX some extensions
are needed, as proposed in related work (Sect. 7.3).

Concerning architectural features, only Sancus provides an hardware-only trusted computing
base. In fact, Intel SGX relies on software parts such as microcode and attestation enclaves, while
TrustZone includes the whole OP-TEE operating system in its TCB. However, software can be easily
upgraded to provide new functionalities or fix bugs, which is why Intel SGX and TrustZone support
TCB upgrades. Furthermore, both TrustZone and Intel SGX have full support for interrupts and

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

25

nodes :
- type : sancus

name : node_sancus
host : node - sancus
vendor_id : 4660
vendor_key : 0 b7bf3ae40880a8be430d0da34fb76f0
reactive_port : 6000

modules :
- type : sgx

name : webserver
node : node_sgx
vendor_key : cred / vendor_key . pem
ra_settings : cred / settings . json

connections :
- from_module : button_driver

from_output : button_pressed
to_module : gateway
to_input : button_pressed
encryption : spongent

Fig. 12. Excerpt from a deployment descriptor in
YAML format. Three main sections are defined:
nodes, modules and connections. Each node and
module has a type field indicating the TEE tech-
nology used; besides the fields that are common to
all TEEs, each platform also requires other specific
parameters. The fields of a connection, instead,
do not change. The complete deployment descrip-
tor (in JSON format) used in this example can be
found at https://github.com/AuthenticExecution/
examples/blob/main/button-led/descriptor.json.

dynamic layout (i.e., virtual memory). Sancus, being an embedded TEE, does not support virtual
memory, whereas for interrupts we offer partial support (Sect. 4.1.5).

4.5 Deployment
We developed a Python script called reactive-tools to ease the deployment and initialization of
a distributed application. In essence, this script builds the SMs and then communicates with the
remote event managers to bootstrap enclaves and establish connections (Sect. 3.3). reactive-tools
takes as input a deployment descriptor, a configuration file that contains a high-level description of
the application to deploy.

4.5.1 Deployment descriptor. The deployment descriptor contains three main sections: nodes,
modules and connections. Fig. 12 shows an excerpt from one of our sample applications.

As shown in the figure, a module is statically assigned to a node and a specific TEE technology.
This is a limitation of our framework as each TEE implementation uses its own API and program-
ming language. A possible direction for future work could be to use an unified language for defining
modules, which can be an existing programming language such as Rust or a custom language
such as the pseudocode we used in Fig. 3; then, the framework could automatically select the right
compiler/toolchain according to the node in which the SM is going to be deployed. However, it is
worth noting that not all TEEs provide the same features: for example, Intel SGX supports data
sealing, whereas Sancus does not support persistent storage at all.

In the connections section, the deployer declares connections between SMs. A connection links
together two endpoints, each of them identified by the pair <SM_name,endpoint_name>. Moreover,
each connection must indicate the authenticated encryption algorithm to use for protecting events
in transit. Currently, both Intel SGX and TrustZone support aes-Galois-Counter Mode (GCM) and
spongent (both with 128 bits of security), whereas Sancus only supports spongent.

4.5.2 Deploying a new application. reactive-tools provides separate commands for the deploy-
ment and attestation of modules, as well as for the establishment of connections. To this end, the
deployer would run the deploy, attest, and connect commands in sequence, each time providing
as input the same deployment descriptor. If all these commands succeed, the deployment is complete
and the application is ready to process events.

Interfacing with the application. At runtime, the deployer might want to interact with the
4.5.3
application in a secure way, e.g., to initialize a web server or to get some metrics from a database.
However, the CallEntry API provided by the event managers to call modules’ entry points is not

26

Scopelliti and Pouyanrad et al.

secure, as for this kind of message the data is transmitted unencrypted over the network. Hence,
the deployer would need to manually implement encryption and/or authentication mechanisms for
data exchanged with the application.

Nevertheless, to facilitate the secure communication between a deployer and their SMs, our
framework provides a convenient feature called direct connections. Unlike normal connections
between two modules, a direct connection uses the deployer’s machine as source endpoint. Since
connection keys are generated and distributed at deployment time by our script, it is possible to also
use such keys to generate output (or request) events and send them directly to running modules.
These connections can be defined in the deployment descriptor together with the others, and
are characterized by the additional direct:true field. The deployer can then either generate
new events manually or automatically using reactive-tools; either way, the receiving module
processes these events just as any other event. Since the deployer’s machine is assumed to be
trusted, the same security guarantees as normal connections apply for direct connections as well.

4.6 Attestation and key management
To ease the attestation of modules and the storage of encryption keys, we developed an optional
component called the Attestation Manager. It consists of an Intel SGX enclave that is deployed on
the infrastructure together with the applications, and to which the deployer and reactive-tools
can send requests through a dedicated command-line interface.

When the attestation manager is deployed, it first needs to be attested using the usual Intel SGX
attestation process. Similarly to the attestation of SMs, a shared secret is exchanged between the
challenger (i.e., the deployer) and the enclave, which is then used to establish a secure channel.

After the initialization is complete, the attestation manager is ready to receive Attest requests
from the deployer; the attestation manager then takes care of executing the actual attestation
logic, based on the TEE technology used by the module. If the attestation succeeds, the attestation
manager stores the module key securely in the enclave memory, and it can be fetched (or used
indirectly) by the deployer at any time.

4.6.1 Advanced usages. The attestation manager, when used, may enable additional use cases.
Below, we shortly describe some of them. Note that we only aim to provide an informal and high-
level outline of such use cases, to motivate the usage of a centralized attestation/key management
component. As such, we will not go into details on the design nor perform a security analysis.

• Key management. The simplest use case is to merely store credentials (i.e., module and
connection keys), which can be accessed by the deployer or any other authorized entities
when needed. Credentials can be stored in enclave memory or persisted in storage using
sealing capabilities of TEEs such as Intel SGX. Note that the latter case may introduce
vulnerabilities against rollback attacks [3].

• Distributed confidential computing. Certain applications process privacy-sensitive information,
such as health-related data. TEEs already protect against honest-but-curious infrastructure
providers, while attestation ensures the authenticity of application code and proves that
the isolation mechanisms of a TEE are correctly in place. However, in some cases it may
be desirable to conceal sensitive data even from the deployer, who normally has access to
connection keys and could potentially decrypt data in transit between modules. Therefore,
the attestation manager could be used to generate and distribute connection keys to modules
without the deployer learning any information about their value.

• Root of Trust in edge devices. In some edge scenarios such as automotive/Vehicle-to-Everything
(V2X), nodes may be part of a local network that does not have continuous access to Internet
services. In such cases, it might be useful to deploy an attestation manager on the network

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

27

responsible for the initialization and attestation of local enclaves. For instance, we could
envision a TrustZone gateway in a car that initializes all Sancus’ Electronic Control Units
(ECUs) when the engine is turned on, refusing to start the car if any of the attestations fails
[59]. In this scenario, the gateway acts as the root of trust of the system, and its remote
attestation would be possible as soon as the system comes back online.

5 EVALUATION

5.1 Testing environment
Our testing environment leverages Docker6 and Docker Compose7 to set up new deployments with
relatively low effort. All the experiments were conducted on an Intel(R) Core(TM) i5-1035G1 CPU
with 8GB of RAM. Each Intel SGX node is a docker container that runs the event-manager-sgx
image, which includes the corresponding event manager along with its dependencies. To be able
to spawn new enclaves, the Intel SGX device (e.g., /dev/isgx) must be attached to the container.
Furthermore, to perform attestation, the AESM service, installed on the host, must be mounted.

TrustZone nodes run on an emulated ARM Versatile Express with ARMv8-A architecture using
QEMU. By default, QEMU will create a SLiRP user network, which provides a full TCP/IP stack
to implement a virtual NAT’d network and an appropriate virtual network device. After booting
QEMU, eth0 will automatically receive an IP address from QEMU via DHCP using the SLiRP user
networking feature. We provide a docker image called event-manager-trustzone that spawns an
isolated instance of the emulator, running our modified OP-TEE installed on the host and mounted
to the container. In this way, multiple TrustZone nodes can be spawned on the same physical host.
Sancus nodes, instead, are 16-bit OpenMSP430 microcontrollers running at 8MHz, connected
to the Linux machine using UART. Communication to and from a Sancus node is bridged by a
container called event-manager-sancus. In essence, this container runs a TCP server used to
receive events from the deployer and other event managers; events are then sent through the UART
interface to the event manager running in the microcontroller. Similarly, data received from the
Sancus board is converted to TCP packets and sent to destination.

The deployer’s console is another container that runs the reactive-tools image, which includes
the reactive-tools script along with all its dependencies, such as the TEE toolchains needed to
build the SMs. Furthermore, the attestation manager can optionally be deployed on the system as
an independent container.

Thanks to Docker Compose, it is easy to handle all these containers in a managed way. Each
deployment runs on an isolated network and all containers can be started or stopped at the same
time. The declaration of the containers and their parameters are specified on a configuration file
called docker-compose.yml. Also, logs from each container are automatically aggregated, which
facilitates the collection of metrics such as timestamps.

Docker Compose is highly effective on single-host deployments. To deploy containers on different

hosts, other solutions such as Docker Swarm8 or Kubernetes9 could be leveraged instead.

5.2 Micro-benchmarks
We performed a detailed performance analysis of a simple ping-pong application, as depicted
in Fig. 13. The two endpoints are an Intel SGX (ping) and a Sancus (pong) enclave, bridged by a
TrustZone enclave (gateway). Due to some physical limitations, the Sancus microcontroller was

6https://www.docker.com/
7https://docs.docker.com/compose/
8https://docs.docker.com/engine/swarm/
9https://kubernetes.io/

28

Scopelliti and Pouyanrad et al.

Linux

QEMU

gateway

ping

Dept. network

Linux

TCP
server

UART

Sancus

pong

SGX SM

TrustZone SM

Sancus SM

Encrypted data

Fig. 13. Setup of the ping-pong application used to perform the performance analysis. The communication
is initiated by ping, which sends out N bytes of dummy data. The data is then received by gateway and
forwarded to the next hop. Eventually, the data reaches pong, which in turn sends it back to the sender
through the same path. The orange line represents the traffic exchanged between the three SMs, which is
encrypted and authenticated.

Crypto algorithm

Data size
(bytes)

aes-gcm-128

aes-gcm-128

spongent-128

spongent-128

8

32

8

32

Native
(ms)

0.08

0.08

32.05

51.57

Intel SGX
(ms)

TrustZone
(ms)

Sancus
(ms)

1.69

1.87

964.76

1559.81

1.86

1.85

80.40

128.67

-

-

0.17

0.17

Table 2. Average time to perform a crypto operation (either encryption or decryption) using different libraries
and on different TEEs. As a reference, we also measured the average time spent by a normal Linux process
without TEE protection (i.e., the Native column). All measurements are in milliseconds.

not attached to the same machine used to run the docker-compose deployment, instead it was
connected to another machine running on the same departmental network. This did not have
any impact on the application’s logic; however, slightly higher network delays might have been
measured during the experiments. We carried out several experiments using different settings each
time, such as the payload size and the encryption algorithms used. In particular, we measured the
round-trip time using 8 bytes of payload, and we evaluated the delay caused by crypto operations
performed both in hardware and software, for 8 and 32 bytes of data.

5.2.1 Cryptographic operations. Tab. 2 shows the average time calculated on each TEEs to perform
crypto operations using either aes-gcm or spongent as authenticated encryption library, with
128 bits of security. To provide a reference, we also carried out the same experiments on a simple
Linux process without TEE protection, whose results are depicted in the third column (Native).
Concerning Native, Intel SGX, and TrustZone, each experiment has been repeated 110 times and
the average has been computed after removing the 10% of outliers. Regarding Sancus, instead, the
measurements have been extrapolated from previous experiments [48].

Modern x86 and ARM processors include aes instructions in their instruction set, allowing them
to perform cryptographic operations in hardware for improved performance and security. As shown
in the table, a single aes encryption/decryption is extremely fast natively, taking 80 𝜇𝑠 for both 8
and 32 bytes of data. The overhead caused by the enclaved execution in Intel SGX significantly
slows down the execution of these functions, with a factor of around 21 and 23 respectively. Similar
considerations apply for TrustZone (∼23x slower than native), also considering the virtualization
layer offered by QEMU. This overhead, though non-negligible, might still be acceptable in a wide
number of real-time applications. Sancus does not include an aes module in its architecture, but it

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

29

Operation
aes instructions
spongent HW instructions
spongent SW instructions
Host-enclave boundary
Network delay
Other

RTT

Time (ms) % of RTT
2.8
0.1
63.7
7.8
21.8
3.8

7.10
0.34
160.80
19.60
55.02
9.72

252.58

100.0

Table 3. End-to-end measurements of the ping-
pong application, aggregating the average time
spent for performing specific tasks. The last row
shows the round-trip time (RTT), which consists
of the sum of all the intermediate times. In the
third column, we show the impact of each task
on the RTT.

implements the spongent crypto engine to provide authenticated encryption. As a consequence,
we could not provide any data to measure the performance of aes in Sancus.

The lack of an aes engine in Sancus is a serious issue for our framework, as it prevents Sancus
modules to communicate securely with modules of other TEEs and the deployer. To circumvent
this problem, a software implementation of the spongent crypto library was implemented in
previous work, in both C/C++ and Rust [62]. Thus, both Intel SGX and TrustZone modules can
leverage such library to exchange protected events with Sancus modules. However, the overhead
for performing such operations in software is enormous: as shown in the table, a single operation
for 8 bytes is around 400 times slower than aes natively, and this factor increases with the size
of the data (644 times slower for 32 bytes). As expected, the performance degrades even more
in an Intel SGX enclave, which takes almost one second to encrypt 8 bytes of data (570x slower
than aes), and around one and half seconds for 32 bytes (834x slower).10 Unfortunately, this poor
performance may completely compromise the real-time requirements of certain use cases, and
replacing spongent with aes might be appropriate, depending on the acceptable processing time
and power consumption on Sancus nodes for a specific use case. The impact in TrustZone is
significant but less prominent, with 80.40 ms for 8 bytes of data (43x slower than aes) and 128.67 ms
for 32 bytes (70x slower). Thus, a possible temporary workaround for the slow spongent execution
time in Intel SGX could be to put a TrustZone gateway between Intel SGX and a Sancus modules,
similarly to our ping-pong scenario. This way, Intel SGX modules do not need to use spongent
at all, but rather they use aes to communicate with the TrustZone modules. A more efficient and
permanent solution could be to include an aes crypto engine in the Sancus architecture.

5.2.2 End-to-end measurements and RTT. We performed end-to-end experiments to assess the
execution time at each stage of our ping-pong application, and to measure the round-trip time (RTT);
the results are shown in Fig. 14. The flow of events is triggered by an external source calling ping’s
start entry point: as a consequence, the enclave generates an event by encrypting N bytes of data
(N is passed as input by the caller). Then, the event is published to the local event manager through
HandleLocalEvent and sent to the TrustZone node via HandleRemoteEvent. After that, the event
manager calls HandleInput to deliver the event to gateway, which decrypts the data and generates
a new event for pong, this time using spongent as encryption algorithm. The rest of the flow
follows the same steps; eventually, the event returns to ping and the execution ends.

It is worth mentioning that all events have a fixed header of 21 bytes: one byte for the type of
event (i.e., HandleLocalEvent), two for the length of the payload, two for the connection identifier
and sixteen for the MAC. Additional two bytes are used in HandleRemoteEvent messages for
the recipient’s SM identifier. Whether these overheads are acceptable or not will depend on the
application. Yet, we feel that they are reasonable in the light of the security guarantees and TCB
reduction provided by our approach.

10The spongent [10] family of light-weight hash functions are optimized for hardware implementation. We have confirmed
in independent experiments that the implementation in Sancus indeed outperforms a software implementation on other
architectures by several orders of magnitude.

30

Scopelliti and Pouyanrad et al.

Intel SGX node

ping

EM

start

1.66ms

HandleLocalEvent
0.66ms

252.58ms

Enclave

Event Manager

Application logic

aes operation

spongent operation

External event

Host-enclave boundary

Node boundary

TrustZone node

EM

gateway

EM

Sancus node

EM

pong

HandleRemoteEvent
2.87ms

HandleInput
6.43ms

1.75ms

78.93ms

HandleLocalEvent
4.45ms

HandleInput
2.62ms

81.87ms

1.97ms

HandleRemoteEvent
24.64ms

HandleRemoteEvent
24.64ms

HandleInput
0.25ms

0.17ms

0.17ms

HandleLocalEvent
0.25ms

0.75ms

HandleLocalEvent
4.28ms

HandleRemoteEvent
2.87ms

HandleInput
0.66ms

1.72ms

end

Fig. 14. Sequence diagram showing the control flow and timings of the ping-pong application in Fig. 13. The
timings refer to measurements performed over 8 bytes of encrypted data; bar lengths are not to scale.

Time was recorded to measure the performance impact of the most important steps: encryp-
tions/decryptions, host-enclave boundary crosses and transmission times. We also measured the
end-to-end RTT, consisting of the difference in time between the start and end points in ping. The
sequence diagram shows average timings for 8 bytes of encrypted data. The average RTT was
252.58 milliseconds, which includes 8 encryptions/decryptions (4 using aes and 4 using spongent),
8 host-enclave boundary crosses and 4 network transmissions between nodes. To better understand
the performance impact of each operation, timing values have been aggregated and shown in Tab. 3.
As already stated in Sect. 5.2.1, crypto operations performed in hardware are generally fast,
taking a total of 7.10 ms for aes and 336 𝜇s for spongent. As expected, huge impact on the RTT
was caused by spongent operations performed in software, taking 160.80 ms (∼63.7% of the RTT).
Crossing the boundary between host and enclave accounted for the 7.8% of the RTT (19.60 ms);
in particular, we observed that the slowest transitions between untrusted and trusted domains
were registered in the TrustZone node, with an average of 4.45 ms for each transition. Domain
transitions in Sancus proved to be extremely fast, each of them requiring only around 250 𝜇s.

Poor network performance had a significant impact on our measurements. In fact, the average
total transmission time was 55.02 ms, which represents the 21.8% of the RTT. As described in
Sect. 5.1, the causes of such delay were essentially two: (1) the poor performance offered by the
networking backend of QEMU (i.e., SLIRP); (2) the low baud rate (57600 bps) of the UART interface

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

31

TEE

Intel SGX

Sancus

TrustZone

Build

1.557

0.295

1.017

Deploy

Attest

Connect

0.284

2.331

0.534

1.797

1.538

0.093

0.056

0.138

0.132

Total

3.700

4.344

1.804

Table 4. Average time to perform a software update on different TEEs, all measurements are in seconds. We
carried out the experiments on the ping-pong application, using the same setup described in Fig. 13. Build-,
deployment-, and attestation times are highly application-specific; in our case, all modules were re-deployed
without code changes and no state transfer between old and new instances was implemented.

and the overhead caused by the TCP server used to communicate with the Sancus microcontroller. In
both cases, the event transmission could be significantly improved by using different communication
medias/network backends, and by relying on real hardware instead of using emulation.

Finally, an average of 9.72 ms (∼3.8% of the RTT) was due to other application logic that was not
measured during the experiments. In the sequence diagram, this consists of the grey rectangles
minus the time spent for performing cryptographic operations. For example, this logic includes the
time spent for the look up of a Connection structure given a specific connection ID, or for finding
the correct SM to which deliver an event. The performance of such operations is implementation-
specific, and may be improved by using more efficient logic and data structures.

Secure I/O. The ping-pong application did not use any peripherals such as sensors or ac-
5.2.3
tuators, therefore we could not measure the performance of secure I/O operations performed by
Sancus microcontrollers. However, we extensively evaluated Sancus in our previous work [47];
thus, the main objective of our evaluation was to assess and evaluate the inter-operation between
different TEEs and measure the communication overhead across different implementations.

5.2.4 Module update. Real-world applications require changes at runtime, e.g., software updates or
module migration from one node to another. This process impacts on the availability of the whole
application, because updating the application unavoidably results in temporary loss of connectivity.
Therefore, we evaluated the overhead of a software update in our framework, for all our supported
TEEs. Again, we carried out our experiments on the ping-pong application (Figure 13); results are
shown in Tab. 4, each value representing the average over 10 iterations.

In our experiments, we re-deployed the original SMs without any code changes. As shown in
Tab. 4, the build time was rather small for all TEEs, ranging from nearly 300 ms for Sancus to around
1.5 seconds for Intel SGX. However, the time to build the new SM highly depends on the amount of
changes made to the original code, and whether the compiler’s cache was used or not. Hence, these
measurements are not really interesting because highly variable. Similarly, deploying the new SM
on the infrastructure depends on the size of the SM itself and the bandwidth of the communication
medium. It can be observed from the table that the deployment of a Sancus module is a slow process,
taking an average of 2.331 seconds; this can be explained by the slow communication channel
between the Sancus node and the deployer, as explained in Sect. 5.2.2. The deployment process for
Intel SGX and TrustZone takes only 284 ms and 534 ms, respectively; similarly to Sancus, the latter
is affected by a slow network transmission as well. Binary sizes of each SM are shown in Tab. 5.

Our experiments show that the attestation time greatly varies according to the TEE used. Attesting
an Intel SGX enclave took an average of 1.797 s; in fact, the modified sigma protocol used in our
framework consists of several steps, including the involvement of the Intel Attestation Server (IAS)
to decrypt the quote (Sect. 4.2.4). For TrustZone, instead, we use a simple challenge-response
protocol, as described in Sect. 4.3.4. Thus, attesting a TrustZone module is very fast and takes an
average of 93 ms. Sancus uses a similar mechanism, though its attestation takes much longer, i.e,

32

Scopelliti and Pouyanrad et al.

Component

Src (LOC) Bin (B)

RIOT OS
Event Manager
Total untrusted

Stub code and libraries
pong
Total trusted

TCB reduction (%)
Dev. effort (%)

9713
1312
11025

797
7
804

93.2
0.9

35638

5223
5223

87.2

(a) Sancus

Component

Src (LOC)

Bin (B)

Component

Src (LOC)

Bin (B)

Host OSa
Event Manager
Total untrusted

Fortanix EDP
Stub code
3rd party libraries
ping
Total trusted

TCB reduction (%)
Dev. effort (%)

>700M 314.3M
1.2M
>700M 315.5M

623

>20K
992
∼20K
21
>41K

99.9
2.1

2.6M
2.6M

99.2

(b) Intel SGX

Host OSa
Event Manager
Total untrusted

OP-TEE OS
Stub code
gateway
Total trusted

1267

>700M 314.3M
7.5K
>700M 314.3M
244Kb

286K
1086
18

107.2K
287K 351.2K

TCB reduction (%)
Dev. effort (%)

99.9
1.6

99.9

(c) TrustZone

Table 5. Size (“Src”: source code, “Bin”: binary size) of the software for running the evaluation scenario.
The shaded components are part of the run-time software TCB. For a fair comparison, we only consider
source code (e.g., C/C++, Rust files), and not build scripts or other similar files. Besides, our evaluation does
not include compilers, standard libraries, and other software layers such as hypervisors. TCB reduction is
calculated as untrusted code over total code, while developer’s effort as application logic (e.g., gateway) over
total trusted code, which includes stub code but excludes third party libraries. Footnotes — a: We use Debian
11 (bullseye) as reference [16]; b: As of 2016, according to the official documentation.

1.538 s on average. However, we observed that the majority of this time was actually spent on the
deployer’s side to compute the module key from the module’s binary; the actual challenge-response
protocol only took less than 100 milliseconds.

Finally, after the new module is ready (i.e., deployed and attested), all connections need to be
redirected from the old to the new instance. Following the update strategy illustrated in Sect. 3.7,
this is the time in which the application would suffer from temporary connectivity loss. However,
our experiments show that this process only takes a very short amount of time, ranging from 56 ms
for Intel SGX to 138 ms for Sancus. It has to be noted, though, that these values only represent the
time to deliver all the events to the SMs and event managers (SetKey and AddConnection events,
respectively), and do not include the processing time in the nodes. Hence, the effective time would
be a bit higher. Besides, this time is linearly dependent on the number of connections to re-establish;
in our case, we only had two connections for Sancus and Intel SGX, and four for TrustZone.

In conclusion, the overall time for a software update is very variable and depends on the
application and the amount of changes that need to be made. Nevertheless, the connectivity loss is
only perceived during the Connect phase which roughly takes less than a hundred milliseconds for
each connection to re-establish.

5.3 Macro-benchmarks
We performed a code evaluation of our ping-pong application, results are shown in Tab. 5. Our
analysis focuses on two main aspects: first, the TCB size in relation to the whole software stack;
second, an estimation of the developer’s effort. Concerning the TCB, we calculated both lines of
code and binary sizes, while for the developer’s effort we only focused on the code.

One of the most important benefits of process-based TEEs is a substantial reduction of the TCB,
leading to a considerably reduced attack surface on each node. Tab. 5 shows that the reduction
in Sancus is 93.2% in lines of code (LOCs) and 87.2% in binary size, while on SGX this reduction
is more prominent with more than 99% reduction in both code and binary sizes. Interestingly,
TrustZone achieves a 99.9% reduction in both, which means that OP-TEE is only a thin software
layer compared to a classic operating system. It has to be noted that the code reduction in SGX and

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

33

TrustZone is enhanced by the fact that our reference host OS (Debian 11) consists of more than 700
million C/C++ LOCs, and more than one billion LOCs overall [16].

Our framework strives to simplify the development of distributed enclave applications. As shown
in Sects. 3 and 4, our API allows a developer to only specify the core logic of a software module,
while the rest of the code is added at compile time by the framework. Our evaluation of the
developer’s effort consists of the ratio between the LOCs written by the developer and the total
LOCs of a module, including stub code but excluding third party libraries. Results show that the
amount of code written by the developer is minimal: only 0.9% for Sancus, 2.1% for SGX and 1.6%
for TrustZone. However, these numbers may greatly vary: our ping-pong application is a basic
example that only consists of a few lines of code, while more complex applications would require
more development effort.

The above evaluation can only provide rough estimates of the benefits of our framework: Per-
forming a precise code evaluation is not a trivial task. Kernels and operating systems typically make
extensive use of conditional compilation to enable/disable specific features or to target different
hardware architectures. Thus, even though an operating system may have millions or more LOCs,
most of them are not used during compilation. Besides, the number of LOCs is often magnified
by auxiliary files such as build scripts, Makefiles, etc. It is debatable whether these files should be
included in the calculation or not: they are not part of the core logic of a software, but they can
nevertheless introduce vulnerabilities at compile time. Applications, instead, may include several
third-party libraries which size might not be easy to calculate: examples are closed-source and
dynamic libraries. Finally, our evaluation did not consider software components such as bootloaders,
firmware/BIOS, hypervisors, compilers, standard libraries, etc. While some of these are untrusted,
others are part of the TCB and must be taken into account for a complete evaluation.

6 DISCUSSION

6.1 Integrity versus Confidentiality
We have focused our security objective on integrity and authenticity, and an interesting question is
to what extent we can also provide confidentiality guarantees. It is clear that, thanks to the isolation
properties of protected modules and to the confidentiality properties of authenticated encryption,
our prototype already provides substantial protection of the confidentiality of both the state of the
application as well as the information contained in events. However, providing a formal statement
of the confidentiality guarantees offered by our approach is non-trivial: some information leaks to
the attacker, such as for instance when (and how often) modules send events to each other. This in
turn can leak information about the internal state of modules or about the content of events. The
ultimate goal would be to make compilation and deployment fully abstract [1] (indicating roughly
that the compiled system leaks no more information than can be understood from the source code),
but our current approach is clearly not fully abstract yet. Hence, we decided to focus on strong
integrity first, and leave confidentiality guarantees for future work.

6.2 Availability
Our authentic execution framework focuses on the notion that if a valid input to a module is
received, we can deduce that it must have originated from an authentic event at the source. By
definition, this notion does not give any availability guarantees: only if we receive such a valid
input can we make claims about the authentic event, whereas nothing can be claimed otherwise.
However, there has been recent work on enforcing availability guarantees for TEEs, specifically
for Sancus [4]. At its core, this related work enables strict availability guarantees to enclaves on
Sancus, such as that an enclave will be executed periodically or be enabled to serve an interrupt

34

Scopelliti and Pouyanrad et al.

within a predictable time frame. This allows to make claims about how specific enclaves will
behave and when these enclaves will react upon events they receive. At the same time, it is still not
possible to make any availability claims about events that exceed the device boundary, i.e., events
that cross beyond the device itself and that are communicated over a shared untrusted medium
such as a network. Overall, it may be possible to make strong claims about when and how fast a
received event will be processed by an enclave, but it is not possible to guarantee that an event will
necessarily arrive over the untrusted network.

Thus, we see availability as a complementary guarantee for authentic execution: If an event
arrives at the device boundary, earlier work such as Aion [4] can guarantee that this event can be
handled within a strict time frame, depending on the scenario’s needs. Furthermore, the same work
can guarantee that if no event is received within the expected time, the enclave will also be able to
react within a guaranteed time window. This may be useful for a specific set of scenarios where
disrupted availability could lead to unwanted or dangerous outcomes. By employing availability as
a safeguard, the absence of events could, e.g., be used to trigger mode change and activate a local
control loop to emergency-shutoff equipment until an authentic event is received.

While we do believe that this complementary notion of availability can have a benefit to certain
scenarios that utilize authentic execution, we leave the combination of these two orthogonal
research directions for future work.

6.3 Hardware Attacks and Side-Channels
Although hardware attacks and side-channels are explicitly ruled out by our attacker model
(Sect. 2.3), it is necessary to discuss the impact in case an attacker would have given access to such
techniques. We leave an analysis of our implementation for side-channels for future work.

An attacker that successfully circumvents the hardware protections on a node would be able
to manipulate and impersonate all modules running on that node. That is, the attacker would be
able to inject events into an application but only for those connections that originate from the
compromised node. The impact on the application obviously depends on the kind of modules that
run on the node. If it is an output module, the application is completely compromised since the
attacker can now produce any output they want. If, on the other hand, it is one among many sensor
nodes, that get aggregated on another node, the impact may be minor.

Depending on the node type different attack vectors apply. A wealth of literature targets Intel
processors and SGX enclaves [11, 22, 58, 61, 64] that enable the extraction of cryptographic keys or
other application secrets. On embedded TEE processors such as Sancus, many side-channels such
as cache timing attacks [23, 35] or page fault channels [69] are not applicable. Interrupt-based side
channels [60] do pose a challenge and have been mitigated in orthogonal research in hardware [12]
and in software [65].

7 RELATED WORK

7.1 TEE frameworks
In recent years, TEEs have gained more and more popularity in both research and industry, due to
their properties and the security guarantees they provide. However, developing TEE applications
is not trivial as software developers are normally required to have some expertise in the field;
moreover, more and more TEEs are emerging nowadays, which makes it more difficult to write
heterogeneous applications or simply to port an application from one TEE to another.

To this end, Keystone [28] is an open source framework for building customized TEEs; it provides
generic primitives such as isolation and attestation, and hardware manufacturers and programmers
can tailor the TEE design based on what they actually need. More software-based frameworks

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

35

such as OpenEnclave [49] and Google Asylo [21] aim to provide a general API for writing enclave
applications, allowing developers to write code that is not tied to a specific TEE and can therefore
be easily ported to multiple platforms. Our framework uses a different approach, which consists
of abstracting the TEE layer away from developers in order to write enclave applications just
like normal ones. Other projects such as Enarx [18], follow the same principles as ours, although
they mainly focus on high-end TEEs such as Intel SGX, TDX, and AMD SEV. To the best of our
knowledge, our framework is the only one that support heterogeneous architectures, combining
high-end systems, IoT devices, and small embedded microcontrollers.

Process-based TEEs such as Intel SGX strive in minimizing the TCB, as only the critical part of
an application can be moved to the enclave. However, this comes with significant performance
penalties, especially when crossing the boundary between the enclave and the untrusted domain.
Instead, VM-based TEEs such as AMD SEV [26] and the new Intel TDX [24] are substantially better
in terms of performance, but have a much bigger attack surface as the entire virtual machine is
part of the TCB. As future work, we might investigate the use of VM-based TEEs combined with
lightweight operating systems such as the formally-verified seL4 microkernel [27].

7.2 Mutually authenticated enclaves
At deployment time, our framework leverages symmetric connection keys to establish secure and
mutually-authenticated channels between modules. Modules do not need to explicitly attest each
other, but rather they rely on the fact that connection keys are securely distributed to modules
only after successful attestation. The implicit assumption here is that such keys are known only
by the modules and their deployer, and are always kept in secure memory and transmitted over
encrypted channels. A similar idea was applied to the automotive scenario by creating a mesh of
mutually-authenticated Sancus enclaves to provide integrity and authenticity of CAN messages
exchanged between the ECUs of a vehicle [59].

In [70], multiple Intel SGX enclaves of an application establish mutual trust during the initial-
ization of TLS sessions, using certificates previously generated by central servers upon successful
attestation. Marblerun [38] uses the same principle to create a service mesh between enclaves in a
Kubernetes cluster. Our framework, instead, relies on symmetric encryption for the establishment
of secure channels, as public-key cryptography is not supported on small microcontrollers like
Sancus. Although asymmetric encryption and client certificates seem a better choice in terms of
key management and authentication, we decided to leverage symmetric connection keys even on
Intel SGX and TrustZone in order to allow communication with Sancus modules.

7.3 Secure I/O
There are several intensive previous solutions aiming to provide a trusted path between an au-
thorized trusted application and I/O devices that guarantees the integrity and authenticity of I/O
data. McCune et al. [40] have proposed a BitE framework that leverages a trusted mobile device to
establish an encrypted and authenticated input channel between I/O devices and an application
running on a TPM-equipped untrusted platform. However, data inside the host platform is not
isolated, hence the OS kernel must be part of the TCB. Bumpy [41], a succeeding work from the
same research group, addresses this limitation by relying on the Flicker TEE [39] and using the
encryption-capable keyboard to provide a safe pathway from input devices through untrusted
environments. Bumpy uses dedicated hardware and hence cannot generalize to arbitrary I/O devices.
Our approach to trusted I/O improves over Bumpy by greatly reducing the size of the software
TCB, from a full OS to less than 1 kLOC. By using Sancus as a TEE, we enable the integration of
attestable software and I/O encryption directly into the input device. When communicating with a

36

Scopelliti and Pouyanrad et al.

host that interacts with Sancus nodes, technologies such as Flicker, TrustZone or Intel SGX can be
used to protect host services and to further reduce the TCB.

Several studies investigated a hypervisor-based approach. The techniques offered by Zhou et
al. [72, 73] aim to establish a trusted path between an input peripheral and an application using
a hypervisor to run the untrusted OS and application endpoints providing the necessary device
drivers in separate VMs. DriverGuard [13] is a hypervisor-based mechanism that leverages a
combination of cryptographic and virtualization techniques to protect I/O device control, I/O data
flows against attacks from a malicious guest kernel. These systems rely on hardware interfaces,
peripherals, and the USB bus to behave according to specification. Rogue devices on the USB bus,
e.g. hardware keyloggers, can intercept messages between an I/O device and the host. Although
our design focuses on integrity guarantees, our prototype protects communication channels using
authenticated encryption. A more recent work, SGXIO [63], provides support for generic, trusted I/O
paths for enclaves in Intel SGX by a composite of TPM, Intel SGX, and hypervisor techniques. Thus,
SGXIO introduces a formally verified hypervisor (seL4 is recommended) to establish a trusted path
while Intel SGX is in charge of protecting user applications from an untrusted OS. This approach
improves upon existing generic trusted paths for x86 systems using Intel SGX’s easy programming
model. Similarly, Aurora [32] utilizes a hypervisor running in the Secure Management Mode (SMM)
of Intel x86 processors as well drivers in the Driver eXecution Environment of open-source UEFI
firmware to implement a concept not unlike the protected driver modules from our work. A TPM
is used to store Intel Boot Guard measurements of the firmware and hypervisor, enabling mutual
attestation between the SMM side and application modules in SGX enclaves. Omitting a hypervisor
layer, BASTION-SGX [50] introduces a trusted Bluetooth controller and application support to
establish a trusted channel between SGX enclaves and Bluetooth devices. SGX-USB [66], instead,
places a proxy device between the host and an I/O peripheral connected through USB, to establish
a secure path to an Intel SGX enclave. Unlike the other SGX-based solutions, SGX-USB does not
rely on software modifications or additional trusted hardware in the host platform.

Fidelius [19] leverages only hardware settings with no reliance on hypervisor security assump-
tions to assist the establishment of a trusted path from input and output peripherals to a hardware
enclave. More specifically, Fidelius utilizes a trusted dongle (e.g., Raspberry Pi) to protect the
entire I/O path between the keyboard/screen and a small JavaScript interpreter that runs inside
an Intel SGX enclave during web browsing sessions under a compromised OS and browser. The
trusted dongle captures user input and sends a stream of encrypted keystrokes to an attested local
enclave. Then, the web enclave decrypts and updates the state of the relevant trusted input field
and eventually forwards it to the remote server. In the opposite direction, a series of encrypted
overlays are sent from the enclave to the display. The trusted path between a dongle and the web
enclave is established through pre-shared symmetric keys. Conversely, the web enclave and remote
server attest each other and establish a secure channel. Fidelius uses an LED indicator on each
dongle and a status bar on the screen to ensure the establishment of the trusted paths; however,
this leads to a high cognitive load on the users as they must monitor continuously different security
indicators. Fidelius leverages a trusted external device to guarantee the integrity and authenticity of
the transferred I/O data, while our solution for secure I/O relies only on the isolation and attestation
properties in Sancus and does not suffer from micro-architectural attacks and relay attacks.

ARM TrustZone provides isolated execution combined with generic trusted I/O paths. In Trust-
Zone, different peripherals, including parts of RAM, IO devices, and interrupts, can be dynamically
configured by a set of hardware controllers to be accessible only in the secure mode. This is achieved
by the reflection of the NS bit into the respective peripheral. In contrast to Intel SGX, TrustZone
assumes that all secure application processes are trusted and does not isolate them in hardware.
However, several prior works take the advantage of TrustZone to establish a trusted I/O path with

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

37

much focus on balancing the size of TCB against functionality. For example, TrustUI [31] builds
trusted paths by splitting device drivers into an untrusted backend and a trusted front-end. The two
parts communicate through shared memory by leveraging proxy modules running in both worlds.
Similarly, TruZ-Droid [67] runs only half part of the HTTP and SSL protocols in the secure world
to reduce the TCB size. VeriUI [34] proposes a login protection mechanism by moving all layers
of the communication stack and UI library into TrustZone. TrustOTP [57] relies on tiny drivers
running in the secure world to protect the one-time password display. Secure I/O in TrustZone is a
well-researched topic that has got a great deal of attention in the past years. Apart from the projects
described above, many others exist in the literature [29, 30, 68, 71]. More recently, a notion of trusted
I/O was also implemented in Android smartphones to protect user transactions [15]. In our work,
we did not implement a secure I/O solution for TrustZone, but rather we interfaced Sancus-enabled
I/O devices with Intel SGX and TrustZone enclaves, providing exclusive and confidential access to
isolated host drivers without trusting the underlying communication channels.

8 SUMMARY & CONCLUSIONS
In this article we present a software architecture to securely execute distributed applications on
shared, heterogeneous TEE-infrastructures. We have extended Sancus, a light-weight embedded TEE
with support for secure I/O, interfaced it with the commercial of-the-shelf TEEs ARM TrustZone and
Intel SGX, and implemented and evaluated a software development framework which enables the
execution of reactive (event-driven) distributed applications on a shared infrastructure with strong
authenticity guarantees and in the presence of capable attackers, while relying on a very small TCB.
We have implemented (and foresee many more) compelling use cases in IoT and control systems.
While much of our work is focused on small embedded microprocessors, we demonstrate that
our solution to be generally applicable to, e.g., build secure distributed applications that integrate
IoT sensing and actuation with cloud-based data processing or aggregation. Yet, implementing
secure I/O is more challenging on non-embedded architectures. Extensions to our work would be
to strengthen security guarantees while maintaining a small TCB, fully integrating a notion of
availability based on [4], and to formalize the security argument using recently proposed logics
(e.g., [8]) for reasoning about TEEs.

ACKNOWLEDGMENTS
This research is partially funded by the Research Fund KU Leuven and by the Flemish Research Pro-
gramme Cybersecurity. Specific funding was provided under the SAFETEE project by the Research
Fund KU Leuven. This research has received funding under EU H2020 MSCA-ITN action 5GhOSTS,
grant agreement no. 814035. Fritz Alder is supported by a grant of the Research Foundation –
Flanders (FWO).

REFERENCES
[1] Martín Abadi. 1999. Protection in Programming-Language Translations. In Secure Internet Prog., Security Issues for

Mobile and Distributed Objects. Springer, 19–34.

[2] Carmine Abate, Roberto Blanco, Deepak Garg, Catalin Hritcu, Marco Patrignani, and Jérémy Thibault. 2019. Journey
beyond full abstraction: Exploring robust property preservation for secure compilation. In 2019 IEEE 32nd Computer
Security Foundations Symposium (CSF). IEEE, 256–25615.

[3] Fritz Alder, Arseny Kurnikov, Andrew Paverd, and N Asokan. 2018. Migrating SGX enclaves with persistent state. In
2018 48th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). IEEE, 195–206.
[4] Fritz Alder, Jo Van Bulck, Frank Piessens, and Jan Tobias Mühlberg. 2021. Aion: Enabling Open Systems through

Strong Availability Guarantees for Enclaves. In CCS ’21. ACM, Seoul, South Korea.

[5] Tiago Alves and Don Felton. 2004. TrustZone: Integrated hardware and software security. ARM white paper 3, 4 (2004),

18–24.

38

Scopelliti and Pouyanrad et al.

[6] ARM-software. [n.d.]. Trusted Board Boot. https://github.com/ARM-software/arm-trusted-firmware/blob/master/

docs/design/trusted-board-boot.rst

[7] Emmanuel Baccelli, Oliver Hahm, Mesut Günes, Matthias Wählisch, and Thomas C Schmidt. 2013. RIOT OS: Towards
an OS for the Internet of Things. In 2013 IEEE conference on computer communications workshops (INFOCOM WKSHPS).
IEEE, 79–80.

[8] Manuel Barbosa, Bernardo Portela, Bogdan Warinschi, and Guillaume Scerri. 2016. Foundations of Hardware-Based

Attested Computation and Application to SGX. In Euro S&P. IEEE.

[9] Guido Bertoni, Joan Daemen, Michaël Peeters, and Gilles Van Assche. 2011. Duplexing the Sponge: Single-pass

authenticated encryption and other applications. In SAC. Springer, 320–337.

[10] Andrey Bogdanov, Miroslav Knezevic, Gregor Leander, Deniz Toz, Kerem Varici, and Ingrid Verbauwhede. 2012.
SPONGENT: The Design Space of Lightweight Cryptographic Hashing. IEEE Trans. Comput. 99, PrePrints (2012), 1.
[11] Ferdinand Brasser, Urs Müller, Alexandra Dmitrienko, Kari Kostiainen, Srdjan Capkun, and Ahmad-Reza Sadeghi.
2017. Software grand exposure:{SGX} cache attacks are practical. In 11th USENIX Workshop on Offensive Technologies
(WOOT 17).

[12] Matteo Busi, Job Noorman, Jo Van Bulck, Letterio Galletta, Pierpaolo Degano, Jan Tobias Mühlberg, and Frank Piessens.
2021. Securing Interruptible Enclaved Execution on Small Microprocessors. Transactions on Programming Languages
and Systems (TOPLAS) (2021). https://doi.org/10.1145/3470534

[13] Yueqiang Cheng, Xuhua Ding, and RobertH. Deng. 2011. DriverGuard: A Fine-Grained Protection on I/O Flows. In

ESORICS. LNCS, Vol. 6879. Springer.

[14] Victor Costan and Srinivas Devadas. 2016.

Intel SGX Explained.

IACR Cryptol. ePrint Arch. (2016), 86.

http:

//eprint.iacr.org/2016/086

[15] Janis Danisevskis. [n.d.]. Android Protected Confirmation: Taking transaction security to the next level. https://android-

developers.googleblog.com/2018/10/android-protected-confirmation.html

[16] DebianStats 2022. Debian 11 (bullseye) statistics. https://sources.debian.org/stats/bullseye/.
[17] D. Dolev and A. C. Yao. 1981. On the Security of Public Key Protocols. In SFCS. IEEE, 350–357.
[18] Enarx 2021. Enarx. https://github.com/enarx/enarx/.
[19] Saba Eskandarian, Jonathan Cogan, Sawyer Birnbaum, Peh Chang Wei Brandon, Dillon Franke, Forest Fraser, Gaspar
Garcia, Eric Gong, Hung T. Nguyen, Taresh K. Sethi, Vishal Subbiah, Michael Backes, Giancarlo Pellegrino, and Dan
Boneh. 2019. Fidelius: Protecting User Secrets from Compromised Browsers. In 2019 IEEE Symposium on Security and
Privacy (SP). 264–280. https://doi.org/10.1109/SP.2019.00036

[20] FortanixEDP 2021. Fortanix Enclave Development Platform. https://edp.fortanix.com/.
[21] GoogleAsylo 2022. Google Asylo. https://asylo.dev/.
[22] Johannes Götzfried, Moritz Eckert, Sebastian Schinzel, and Tilo Müller. 2017. Cache attacks on Intel SGX. In Proceedings

of the 10th European Workshop on Systems Security. 1–6.

[23] Ralf Hund, Carsten Willems, and Thorsten Holz. 2013. Practical Timing Side Channel Attacks Against Kernel Space

ASLR. In Symp. S&P. IEEE.

[24] IntelTDX 2022. Intel Trust Domain Extensions. https://www.intel.com/content/www/us/en/developer/articles/technical/intel-

trust-domain-extensions.html.

[25] Simon Johnson, Vinnie Scarlata, Carlos Rozas, Ernie Brickell, and Frank Mckeen. 2016. Intel software guard extensions:

EPID provisioning and attestation services. White Paper 1, 1-10 (2016), 119.

[26] David Kaplan, Jeremy Powell, and Tom Woller. 2016. AMD memory encryption. White paper (2016).
[27] Gerwin Klein, Kevin Elphinstone, Gernot Heiser, June Andronick, David Cock, Philip Derrin, Dhammika Elkaduwe,
Kai Engelhardt, Rafal Kolanski, Michael Norrish, et al. 2009. seL4: Formal verification of an OS kernel. In Proceedings
of the ACM SIGOPS 22nd symposium on Operating systems principles. 207–220.

[28] Dayeol Lee, David Kohlbrenner, Shweta Shinde, Krste Asanović, and Dawn Song. 2020. Keystone: An open framework
for architecting trusted execution environments. In Proceedings of the Fifteenth European Conference on Computer
Systems. 1–16.

[29] Wenhao Li, Haibo Li, Haibo Chen, and Yubin Xia. 2015. Adattester: Secure online mobile advertisement attestation
using trustzone. In Proceedings of the 13th annual international conference on mobile systems, applications, and services.
75–88.

[30] Wenhao Li, Shiyu Luo, Zhichuang Sun, Yubin Xia, Long Lu, Haibo Chen, Binyu Zang, and Haibing Guan. 2018. Vbutton:
Practical attestation of user-driven operations in mobile apps. In Proceedings of the 16th annual international conference
on mobile systems, applications, and services. 28–40.

[31] Wenhao Li, Mingyang Ma, Jinchen Han, Yubin Xia, Binyu Zang, Cheng-Kang Chu, and Tieyan Li. 2014. Building
trusted path on untrusted device drivers for mobile devices. In Proceedings of 5th Asia-Pacific Workshop on Systems.
1–7. https://doi.org/10.1145/2637166.2637225

End-to-End Security for Distributed Event-Driven Enclave Applications on Heterogeneous TEEs

39

[32] Hongliang Liang, Mingyu Li, Yixiu Chen, Lin Jiang, Zhuosi Xie, and Tianqi Yang. 2020. Establishing Trusted I/O Paths
for SGX Client Systems With Aurora. IEEE Trans. Inf. Forensics Secur. 15 (2020), 1589–1600. https://doi.org/10.1109/
TIFS.2019.2945621

[33] Linaro. [n.d.]. OP-TEE Documentation. https://optee.readthedocs.io/
[34] Dongtao Liu and Landon P Cox. 2014. Veriui: Attested login for mobile devices. In Proceedings of the 15th workshop on

mobile computing systems and applications. 1–6.

[35] Fangfei Liu, Yuval Yarom, Qian Ge, Gernot Heiser, and Ruby B. Lee. 2015. Last-Level Cache Side-Channel Attacks are

Practical. In Symp. S&P. IEEE, 605–622.

[36] P. Maene, J. Götzfried, R. de Clercq, T. Müller, F. Freiling, and I. Verbauwhede. 2017. Hardware-Based Trusted Computing

Architectures for Isolation and Attestation. IEEE Trans. Comput. 99 (2017).

[37] Pieter Maene, Johannes Götzfried, Ruan de Clercq, Tilo Müller, Felix C. Freiling, and Ingrid M. R. Verbauwhede. 2018.
IEEE Trans. Comput. 67 (2018),

Hardware-Based Trusted Computing Architectures for Isolation and Attestation.
361–374.

[38] Marblerun 2022. Marblerun. https://marblerun.sh/.
[39] Jonathan M. McCune, Bryan J. Parno, Adrian Perrig, Michael K. Reiter, and Hiroshi Isozaki. 2008. Flicker: An Execution

Infrastructure for TCB Minimization. In Eurosys. ACM, 315–328.

[40] Jonathan M. McCune, Adrian Perrig, and Michael K. Reiter. 2006. Bump in the Ether: A Framework for Securing

Sensitive User Input. In ATEC. USENIX.

[41] Jonathan M. McCune, Adrian Perrig, and Michael K. Reiter. 2009. Safe Passage for Passwords and Other Sensitive Data.

In NDSS.

[42] Frank McKeen, Ilya Alexandrovich, Alex Berenzon, Carlos V. Rozas, Hisham Shafi, Vedvyas Shanbhogue, and Uday R.
Savagaonkar. 2013. Innovative Instructions and Software Model for Isolated Execution. In HASP. ACM, 10:1–10:1.
[43] Jan Tobias Mühlberg, Sara Cleemput, A. Mustafa Mustafa, Jo Van Bulck, Bart Preneel, and Frank Piessens. 2016. An
Implementation of a High Assurance Smart Meter using Protected Module Architectures. In WISTP ’16 (LNCS, Vol. 9895).
Springer, Heidelberg, 53–69.

[44] Jan Tobias Mühlberg and Jo Van Bulck. 2018. Tutorial: Building Distributed Enclave Applications with Sancus and

SGX. In DSN ’18. IEEE.

[45] Bernard Ngabonziza, Daniel Martin, Anna Bailey, Haehyun Cho, and Sarah Martin. 2016. TrustZone Explained:
Architectural Features and Use Cases. 2016 IEEE 2nd International Conference on Collaboration and Internet Computing
(CIC) (2016), 445–451.

[46] Job Noorman, Pieter Agten, Wilfried Daniels, Raoul Strackx, Anthony Van Herrewege, Christophe Huygens, Bart
Preneel, Ingrid Verbauwhede, and Frank Piessens. 2013. Sancus: Low-cost trustworthy extensible networked devices
with a zero-software trusted computing base. In USENIX Sec. Symp. USENIX, 479–494.

[47] Job Noorman, Jan Tobias Mühlberg, and Frank Piessens. 2017. Authentic Execution of Distributed Event-Driven

Applications with a Small TCB. In STM ’17 (LNCS). Springer, Heidelberg.

[48] Job Noorman, Jo Van Bulck, Jan Tobias Mühlberg, Frank Piessens, Pieter Maene, Bart Preneel, Ingrid Verbauwhede,
Johannes Götzfried, Tilo Müller, and Felix Freiling. 2017. Sancus 2.0: A Low-Cost Security Architecture for IoT Devices.
ACM Transactions on Privacy and Security (TOPS) 20 (2017), 7:1–7:33. Issue 3.

[49] OpenEnclaveSDK 2022. Open Enclave SDK. https://openenclave.io/sdk/.
[50] Travis Peters, Reshma Lal, Srikanth Varadarajan, Pradeep Pappachan, and David Kotz. 2018. BASTION-SGX: bluetooth
and architectural support for trusted I/O on SGX. In Proceedings of the 7th International Workshop on Hardware and
Architectural Support for Security and Privacy, HASP@ISCA 2018, Los Angeles, CA, USA, June 02-02, 2018, Jakub Szefer,
Weidong Shi, and Ruby B. Lee (Eds.). ACM, 3:1–3:9. https://doi.org/10.1145/3214292.3214295

[51] Sandro Pinto and Nuno Santos. 2019. Demystifying Arm TrustZone: A Comprehensive Survey. ACM Computing

Surveys (CSUR) 51 (2019), 1 – 36.

[52] Barath Raghavan, Bonnie Nardi, Sarah T. Lovell, Juliet Norton, Bill Tomlinson, and Donald J. Patterson. 2016. Computa-
tional Agroecology: Sustainable Food Ecosystem Design. In Proceedings of the 2016 CHI Conference Extended Abstracts on
Human Factors in Computing Systems. ACM, San Jose California USA, 423–435. https://doi.org/10.1145/2851581.2892577
[53] Himanshu Raj, Stefan Saroiu, Alec Wolman, Ronald Aigner, Jeremiah Cox, Paul England, Chris Fenner, Kinshuman
Kinshumann, Jork Löser, Dennis Mattoon, Magnus Nyström, David Robinson, Rob Spiger, Stefan Thom, and David
Wooten. 2016. fTPM: A Software-Only Implementation of a TPM Chip. In USENIX Security Symposium.

[54] Gianluca Scopelliti. 2020. Securing Smart Environments with Authentic Execution. Master’s thesis. Politecnico Di Torino.

https://distrinet.cs.kuleuven.be/software/sancus/publications/scopelliti2020.pdf.

[55] Raoul Strackx, Job Noorman, Ingrid Verbauwhede, Bart Preneel, and Frank Piessens. 2013. Protected software module

architectures. In ISSE 2013 Securing Electronic Business Processes. Springer, 241–251.

[56] Adam Streed, Michael Kantar, Bill Tomlinson, and Barath Raghavan. 2021. How Sustainable is the Smart Farm?

Workshop on Computing within Limits (June 2021). https://doi.org/10.21428/bf6fb269.f2d0adaf

40

Scopelliti and Pouyanrad et al.

[57] He Sun, Kun Sun, Yuewu Wang, and Jiwu Jing. 2015. TrustOTP: Transforming smartphones into secure one-time
password tokens. In Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security.
976–988.

[58] Jo Van Bulck, Marina Minkin, Ofir Weisse, Daniel Genkin, Baris Kasikci, Frank Piessens, Mark Silberstein, Thomas F
Wenisch, Yuval Yarom, and Raoul Strackx. 2018. Foreshadow: Extracting the Keys to the Intel {SGX} Kingdom with
Transient {Out-of-Order} Execution. In 27th USENIX Security Symposium (USENIX Security 18). 991–1008.

[59] Jo Van Bulck, Jan Tobias Mühlberg, and Frank Piessens. 2017. VulCAN: Efficient Component Authentication and

Software Isolation for Automotive Control Networks. In ACSAC ’17. ACM, New York, NY, USA, 225–237.

[60] Jo Van Bulck, Frank Piessens, and Raoul Strackx. 2018. Nemesis: Studying microarchitectural timing leaks in rudi-
mentary CPU interrupt logic. In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications
Security. 178–195.

[61] Stephan van Schaik, Andrew Kwong, Daniel Genkin, and Yuval Yarom. 2020. SGAxe: How SGX fails in practice.

https://sgaxe.com/files/SGAxe.pdf

[62] Sten Verbois. 2018. Safe Interacting Enclaves for Heterogeneous Protected Module Architectures. Master’s thesis. KU

Leuven. https://distrinet.cs.kuleuven.be/software/sancus/publications/verbois18thesis.pdf.

[63] Samuel Weiser and Mario Werner. 2017. SGXIO: Generic Trusted I/O Path for Intel SGX. (01 2017). https://doi.org/10.

1145/3029806.3029822

[64] Ofir Weisse, Jo Van Bulck, Marina Minkin, Daniel Genkin, Baris Kasikci, Frank Piessens, Mark Silberstein, Raoul
Strackx, Thomas F Wenisch, and Yuval Yarom. 2018. Foreshadow-NG: Breaking the virtual memory abstraction with
transient out-of-order execution. (2018).

[65] Hans Winderix, Jan Tobias Mühlberg, and Frank Piessens. 2021. Compiler-Assisted Hardening of Embedded Software
Against Interrupt Latency Side-Channel Attacks. In EuroS&P ’21. IEEE, Washington, DC, USA, 667 – 682. https:
//doi.org/10.1109/EuroSP51992.2021.00050

[66] Jang Yeong Jin. 2017. Building trust in the user I/O in computer systems. Ph.D. Dissertation. Georgia Institute of

Technology.

[67] Kailiang Ying, Amit Ahlawat, Bilal Alsharifi, Yuexin Jiang, Priyank Thavai, and Wenliang Du. 2018. Truz-droid:
Integrating trustzone with mobile operating system. In Proceedings of the 16th annual international conference on mobile
systems, applications, and services. 14–27.

[68] Kailiang Ying, Priyank Thavai, and Wenliang Du. 2019. Truz-view: Developing trustzone user interface for mobile os
using delegation integration model. In Proceedings of the Ninth ACM Conference on Data and Application Security and
Privacy. 1–12.

[69] Marcus Peinado Yuanzhong Xu, Weidong Cui. 2015. Controlled-Channel Attacks: Deterministic Side Channels for

Untrusted Operating Systems. In Symp. S&P. IEEE.

[70] Haofan Zheng and Owen Arden. 2021. Secure Distributed Applications the Decent Way. In Proceedings of the 2021

International Symposium on Advanced Security on Software and Systems. 29–42.

[71] Xianyi Zheng, Lulu Yang, Jiangang Ma, Gang Shi, and Dan Meng. 2016. TrustPAY: Trusted mobile payment on security
enhanced ARM TrustZone platforms. In 2016 IEEE Symposium on Computers and Communication (ISCC). IEEE, 456–462.
[72] Zongwei Zhou, Virgil Gligor, James Newsome, and Jonathan McCune. 2012. Building Verifiable Trusted Path on
Commodity x86 Computers. Proceedings - IEEE Symposium on Security and Privacy, 616–630. https://doi.org/10.1109/
SP.2012.42

[73] Zongwei Zhou, Miao Yu, and Virgil Gligor. 2015. Dancing with Giants: Wimpy Kernels for On-Demand I/O Isolation.
Proceedings - IEEE Symposium on Security and Privacy 13 (03 2015), 38–46. https://doi.org/10.1109/MSP.2015.26

