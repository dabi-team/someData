COREQQA - A COmpliance REQuirements Understanding using
Question Answering Tool

Sallam Abualhaija
sallam.abualhaija@uni.lu
University of Luxembourg
Luxembourg

Chetan Arora
chetan.arora@deakin.edu.au
Deakin University
Australia

Lionel Briand
lionel.briand@uni.lu
University of Luxembourg
Luxembourg
& University of Ottawa
Canada

2
2
0
2

n
u
J

1
2

]
E
S
.
s
c
[

1
v
3
3
2
0
1
.
6
0
2
2
:
v
i
X
r
a

ABSTRACT
We introduce COREQQA, a tool for assisting requirements engi-
neers in acquiring a better understanding of compliance require-
ments by means of automated Question Answering. Extracting
compliance-related requirements by manually navigating through
a legal document is both time-consuming and error-prone. CORE-
QQA enables requirements engineers to pose questions in natu-
ral language about a compliance-related topic given some legal
document, e.g., asking about data breach. The tool then automat-
ically navigates through the legal document and returns to the
requirements engineer a list of text passages containing the possi-
ble answers to the input question. For better readability, the tool
also highlights the likely answers in these passages. The engineer
can then use this output for specifying compliance requirements.
COREQQA is developed using advanced large-scale language mod-
els from BERT‚Äôs family. COREQQA has been evaluated on four legal
documents. The results of this evaluation are briefly presented in
the paper. The tool is publicly available on Zenodo [2].

CCS CONCEPTS
‚Ä¢ Software and its engineering ‚Üí Requirements analysis; ‚Ä¢
Computing methodologies ‚Üí Information extraction.

KEYWORDS
Requirements Engineering (RE), Regulatory Compliance, Natural
Language Processing (NLP), Question Answering, Language Models
(LMs), BERT.

ACM Reference Format:
Sallam Abualhaija, Chetan Arora, and Lionel Briand. 2022. COREQQA - A
COmpliance REQuirements Understanding using Question Answering Tool.
In Proceedings of The 30th ACM Joint European Software Engineering Confer-
ence and Symposium on the Foundations of Software Engineering (ESEC/FSE
2022). ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/nnnnnnn.
nnnnnnn

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ESEC/FSE 2022, 14 - 18 November, 2022, Singapore
¬© 2022 Association for Computing Machinery.
ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn

Figure 1: Example of COREQQA‚Äôs QA assistance on
GDPR [12].

1 INTRODUCTION

With the growing reliance on personal data and confidential in-
formation, software systems are increasingly subject to compliance
against regulations to enforce necessary safeguards for informa-
tion protection and human safety [14, 17]. Failing to comply with
relevant regulations can lead to legal, fiscal or reputational impli-
cations for an organization. Regulatory compliance is regarded as
an essential yet challenging task by the Requirements Engineering
(RE) community [6, 19, 22].

In this paper, we propose the tool COREQQA (Compliance
Requirements Understanding using Question Answering). CORE-
QQA is motivated by actual practical needs, considering that re-
quirements engineers are being increasingly involved in software
compliance against relevant regulations, e.g., all software systems
in Europe must comply with GDPR (Regulation (EU) 2016/679) ‚Äì
the European regulation on data protection, privacy and personal
data transfer [12]. Manually handling compliance requirements is
tedious and error-prone since requirements engineers have to read
through entire legal documents. Such documents are usually hefty,
contain complicated natural language (NL) structures, frequently

  When the personal data breach is likely to result in a high risk to the rights and freedoms of natural persons, the controller shall communicate the personal data breach to the data subject without undue delay. (‚Ä¶)As soon as the controller becomes aware that a personal data breach has occurred, the controller should notify the personal data breach to the supervisory authority without undue delay and , where feasible, not later than 72 hours after having become aware of it (‚Ä¶)The controller should communicate to the data subject a personal data breach, without undue delay, where that personal data breach is likely to result in a high risk to the rights and freedoms of the natural person in order to allow him or her to take the necessary precautions (‚Ä¶)Relevant Context Span #1What is the procedure for handling personal data breach?Requirements EngineerRelevant Context Span #2Relevant Context Span #3Requirements EngineerRegulation (EU) 2016/679 - GDPR Document 
 
 
 
 
 
ESEC/FSE 2022, 14 - 18 November, 2022, Singapore

Abualhaija, et al.

refer to external regulations, and are not easy to peruse without
legal expertise [3, 21].

An automated Question Answering (QA) tool such as CORE-
QQA helps requirements engineers efficiently navigate through the
compliance-related content of legal documents. QA is the task of
automatically finding the answer to a question posed in NL from a
given text passage. In our work, we refer to a single text passage as
a context span. Instead of reviewing long, complex legal documents,
COREQQA enables requirements engineers to ask a question about
a compliance-related topic, and then returns a list of relevant con-
text spans in which the answer is likely to be found. This way,
COREQQA pinpoints the requirements engineers to the portions
of the legal document where they need to invest their efforts and
time.

We illustrate in Figure 1, the QA assistance provided by CORE-
QQA to a requirements engineer, who is interested in understanding
the regulations related to personal data breach. The example ques-
tion is specifically related to the process for handling personal data
breaches. The answer to this question is mined in the GDPR text.
The legal obligations with regard to handling data breaches can
have a significant impact on the software development process,
e.g., sending notifications to different responsible agents within
legally-binding time constraints. COREQQA assists the require-
ments engineer in retrieving relevant information to define the
respective compliance requirements for handling data breaches
for the software system under development. As we elaborate in
Section 2, COREQQA returns as output the top-ùëÅ 1 relevant con-
text spans from a given legal document and the potential answers
highlighted in the context spans. COREQQA builds on large-scale
natural language processing (NLP) language models for solving
the QA task (also widely known as machine reading comprehension
(MRC) task [15]). QA models for MRC generally assume that for
each question, the relevant context span (containing the answer) is
known a priori. Developing a practical QA tool with this restriction
is infeasible, as requirements engineers have no means of know-
ing the exact context span with the correct answer in advance.
Therefore, in COREQAA we first find top-ùëÅ relevant context spans
which likely contain the answer. To do so, we compute the semantic
similarity between each context span in the legal document and
the input question. Then, we demarcate the answer to the input
question using the QA models.

We further observe that information relevant to answering the
question could be found in multiple non-contiguous context spans
(i.e., different sections in the same legal document). For example, the
top-3 context spans selected in Figure 1 are all directly relevant for
answering the question. The first two spans (retrieved from differ-
ent sections of the document) explain the process of communicating
breach details to the data subject, while the third span specifies how
to communicate breach details to the supervisory authorities. Thus,
by retrieving multiple relevant spans and further highlighting the
likely answers, COREQQA enables the requirements engineer to
specify a complete and precise set of compliance requirements. We
leave configuring the ùëÅ parameter to the requirements engineer.
While selecting higher values of ùëÅ entails more time and effort for

reviewing the retrieved context spans, we believe that using CORE-
QQA is still much more cost-effective in practice than manually
traversing the entire legal document for the answer.

In the remainder of this tool demonstration paper, we elabo-
rate the architecture of the tool, the dataset that we generated for
developing COREQQA as well as an end-to-end usage scenario.

2 TOOL ARCHITECTURE

The end-to-end architecture of COREQQA is illustrated in Fig-
ure 2. COREQQA aims at answering a given question posed by a
requirements engineer in NL on some legal document. Below, we
elaborate the main steps of the tool marked as 1 ‚Äì 3 in Figure 2. We
implemented COREQQA in Python 3.8.

2.1 Text Preprocessing
In the first step, COREQQA parses the legal document and applies
a simple NLP pipeline which is composed of tokenization and sen-
tence splitting. The tool then applies a set of regular expressions
for normalizing the text (e.g., removing periods from the ending of
acronyms, ‚ÄúArt.‚Äù becomes ‚ÄúArt‚Äù). The motivation for normalizing
the text is to improve the accuracy of sentence splitting. We opera-
tionalize the NLP pipeline using NLTK library [7, 18], and the re
module in Python for regular expressions2. In this step, we further
partition the legal document into context spans. Due to technical
constraints of underlying QA models, the maximum size of each
context span is 512 tokens. To maintain coherence, we split the
document into paragraphs first, and then check their size. Each
paragraph fitting this size limitation is regarded as one context
span. Otherwise, we split the paragraph into half, and check the
size again. This process is iteratively performed until size limita-
tions are met. The output of this step is the list of context spans
representing the input legal document.

2.2 Relevant Context Retrieval
In the second step, COREQQA computes the semantic similar-
ity between the input question and each context span generated
from the previous step. We implement this step using the BERT
cross-encoder (BCE) model available in the Sentence-Transformer
2.1.0 [20] provided by Hugging Face3. BCE takes as input two text
fragments, and returns as output a score between 0 and 1 indicating
how semantically similar the two fragments are, with 1 being iden-
tical. To assess the relevance of the context span, we first compute
BCE between the question and each sentence in the context span
and then assign to the context span the maximum score achieved
by any sentence. The intuition behind this computation strategy is
that only a portion of the context span is expected to contain the
likely answer to the input question.

Once we compute a score per context span, we rank the spans in
descending order. We do this using the sort function from pandas
in Python4. The result of this step is a list of top-ùëÅ relevant context
spans to the input question. We keep the value N as a parameter
that can be initialized by the requirements engineer. The value of
ùëÅ depends on the practical context in which COREQQA is applied.

1ùëÅ is a configurable parameter and is set ùëÅ = 3 for the example question in the figure

2https://docs/python.org/3.8/library/re/
3https://huggingface.co/
4https://pandas.pydata.org

COREQQA - A COmpliance REQuirements Understanding using Question Answering Tool

ESEC/FSE 2022, 14 - 18 November, 2022, Singapore

Figure 2: Overview of the end-to-end architecture of COREQQA.

Selecting large values (e.g., ‚â• 10) entails that the requirements engi-
neer will review many context spans to gain a better understanding
of the compliance requirements associated with the question. Se-
lecting small ùëÅ values (e.g., ‚â§ 3) entails less context spans to be
reviewed, but also a higher risk for the right answer not to be found
in any of the top-ùëÅ relevant spans. In Figure 1, we show an example
of top-3 context spans retrieved in this step. The default value of
the configurable parameter ùëÅ is set to 5 in COREQQA, based on
previous experiments [3].

2.3 Answer Extraction
In the last step, we pass on the top-ùëÅ context spans deemed relevant
in the previous step together with the input question to a pre-
trained QA model. In our work, we apply the Transformers library
to extract answers for the given question using the RoBERTa QA
model (roberta-base-squad2-distilled). RoBERTa then extracts from
each context span a potential answer for the input question. In
Figure 1, we highlight the extracted answers in green. We note that
the engineer has access to the context spans already in the previous
step. Thus, this step is not essential for providing assistance to the
requirements engineer in understanding the questions related to
compliance requirements. However, highlighting the answer in the
context span improves readability and leads to a more efficient
reviewing process. In practice, when the engineer selects a larger
number ùëÅ (say 10), it is then advantageous to demarcate the answer
automatically to help the engineer quickly navigate through the
context spans.

2.4 Final Output Representation
For presenting the final output of the tool to the requirements
engineer, we export for each question the top-ùëÅ context spans
and the highlighted answers within these context spans as a Mi-
crosoft Word document. The document also shows for each context

span a confidence score (range 0‚Äì1) of the answer highlighted in
the span. This confidence score is automatically assigned to the
extracted answer by the QA model. We use the python-docx li-
brary v0.8.11 (https://python-docx.readthedocs.io) for exporting
the output and visualizing highlighted answers in the relevant
top-ùëÅ context spans.

3 EVALUATION
COREQQA has been evaluated on four legal documents, wherein
the question-answer pairs were identified by two experts ‚Äì one
expert in legal informatics and the other in requirements engineer-
ing [3]. In the following, we describe the four documents:
‚Ä¢ GDPR or General Data Protection Regulation (EU) 2016/679 is the
European privacy law that harmonises the data protection, privacy
and personal data transfer requirements [12]. The experts identified
36 question-answer pairs from the entire document. The document
was partitioned in 301 context spans by the ‚ÄúText Preprocessing‚Äù
step of Figure 2.
‚Ä¢ Directive (EU) 2019/770 is the European directive for regulating
the supply of digital content or digital services, and laying down
rules for contracts between any trader and consumer of digital
content or service [10]. The experts identified 33 question-answer
pairs in this document, and the document was split into 120 context
spans.
‚Ä¢ Directive (EU) 2019/771 is the European directive concerning the
sale of goods [11]. Directive (EU) 2019/771 complements Directive
(EU) 2019/770, as it formalises the contracts on the sale of goods that
contain digital elements that require digital content or service. For
example, the regulations related to the contracts of the smartphone
are covered by Directive (EU) 2019/771, whereas the regulations for
operating systems or apps on the smartphone might be covered by
Directive (EU) 2019/770. The experts identified 19 question-answer

Legal DocumentRequirements EngineerQUESTION?Text Preprocessing and Partitioning1TokenizeationSentence SplittingNormalizationREGEX (.*)Context Span GenerationCONTEXT SPANSRELEVANT CONTEXT SPANS CONTEXTs & ANSWERs C1, A1CN, ANPOSSIBLE ANSWERSAnswer ExtractionAnswer DemarcatorRoBERTa-QARelevant Context RetrievalRankingSelectionSimilarity Computation$NBCEReview234Final Output RepresentationESEC/FSE 2022, 14 - 18 November, 2022, Singapore

Abualhaija, et al.

are thus subject to compliance. Some of these functionalities are
related to the security of collected personal data. We assume here
that Daisy or her team are aware of the relevant legal documents for
their project. Suggesting relevant documents is beyond the scope
of COREQQA. Accounting to possible security threats, Daisy poses
a question (‚ÄúWhat is the procedure for handling a personal data
breach?‚Äù) using the COREQQA tool on the GDPR [12]. COREQQA
in turn provides the output shown in Figure 1.

From the output of COREQQA, Daisy is able to formulate the
following compliance requirements (prefixed with the ID ùê∂ùëÖ) under
the label Users Data Breach.
Notify Users about the Data Breach.
ùê∂ùëÖ1. If a data breach is identified on the KoopaApp server, the
KoopaApp-NotifyService shall inform the affected users.
ùê∂ùëÖ2. The KoopaApp-NotifyService shall email the affected users on
the registered email address and store the ‚Äòuser informed‚Äô response
on the server.
ùê∂ùëÖ3. The KoopaApp-NotifyService shall notify the affected users
on the app and store the ‚Äòread‚Äô response on the server.
Notify the CIO about the Data Breach.
ùê∂ùëÖ4. If a data breach is identified on the KoopaApp server, the
KoopaApp-NotifyService shall send an email to the Chief Informa-
tion Officer notifying the breach, within 72 hours of its occurrence.
The four compliance requirements fulfill the regulations pro-

vided in Figure 1.

5 CONCLUSION
We presented COREQQA ‚Äì a tool for assisting requirements engi-
neers in better understanding compliance requirements through
question-answering based on regulatory or legal documents. CORE-
QQA is developed using a manually created dataset that combines
a joint effort of a requirements engineer and a legal expert over
four diverse legal documents. The tool is based on recent large-
scale language models that are pre-trained for question-answering.
Specifically, the tool applies the Sentence BERT cross encoder for
retrieving the most relevant text passages from a legal document for
a given question. The tool further employs the RoBERTa question-
answering model for highlighting the likely answers to the question
in the retrieved text passages.

In future, we plan to conduct a user study to assess how useful

COREQQA is in practice.

ACKNOWLEDGMENTS
This paper was supported by Central Legislative Service (SCL) ‚Äì
Government of Luxembourg, the Luxembourg National Research
Fund (FNR) under grants PUBLIC2-17/IS/11801776, and by NSERC
of Canada under the Discovery and CRC programs.

pairs in Directive (EU) 2019/771, and the document text was split
into 102 context spans.
‚Ä¢ Luxembourg Law of 25 March 2020 is an amendment to nu-
merous existing finance and banking related laws in Luxembourg.
The amendment was intended to set due diligence measures for a
central electronic data retrieval system related to bank accounts and
safe-deposit boxes in Luxembourg, and was a step towards tackling
money laundering [1]. The experts identified 19 question-answer
pairs in this legal document. The document text was split into 23
context spans.

To identify the most accurate similarity metric for context span
retrieval, we compared BCE (Section 2.2) with TF-IDF similarity [4]
‚Äì a metric commonly used in the NLP domain. BCE was significantly
more accurate than TF-IDF in our experiments. Overall, from the
107 questions over the four documents, BCE retrieves the correct
context span for 100 questions (for the top-5 spans). In addition to
RoBERTa, we further evaluated three QA models, namely BERT [9],
ALBERT [16], ELECTRA [8] for answer extraction (Section 2.3).
RoBERTa was deemed the most accurate as it correctly extracted
the answers for 97 questions.

We also analyzed the questions where COREQQA did not highly
rank the correct context span (within top-5) or RoBERTa model did
not extract the correct answer. Our analysis showed that generic
questions, such as the ones formulated for defining or elaborating
on a legal concept, were not correctly answered. This is because the
legal document (or even a given context span) would usually contain
several instances of such legal concept, thus misleading both the
context span retrieval and answer extraction steps of COREQQA.
We also realized that complicated questions (e.g., with composite
conditions) were difficult to answer for COREQQA.

Last but not least, COREQQA answers questions within reason-
able execution time. Thus, in short, our evaluation indicates that
COREQQA produces accurate results and is fit for use by require-
ments engineers in practice. For answering one question from a
legal document including an average of 620 sentences, COREQQA
requires a total of ‚âà34 seconds.

4 USAGE SCENARIO

In this section, we describe an end-to-end example illustrating
how our tool can be applied in practice by a requirements engineer.
Let KoopaApp be a new system under development. KoopaApp is a
gym fitness app for maintaining users‚Äô workout information and
other health-related data. KoopaApp accesses personal information
such as the location from other apps on the users‚Äô smartphone.
During the pandemic, such applications often raised concerns about
privacy. For example, several health applications were analyzed for
privacy-related issues in the RE literature [5, 13].

A requirements engineer (Daisy) is in charge of specifying the
KoopaApp requirements, including compliance requirements. As
an example, we focus only on a subset of compliance requirements
related to privacy and data protection. Daisy (as is often the case
in most software projects) is not very familiar with the privacy
regulations, yet she knows well the functionalities and characteris-
tics of the KoopaApp. During the elicitation of requirements, Daisy
identifies a set of functionalities that make use of personal data and

COREQQA - A COmpliance REQuirements Understanding using Question Answering Tool

ESEC/FSE 2022, 14 - 18 November, 2022, Singapore

REFERENCES
[1] 2020. Law of 25 March 2020 (coordinated version) establishing a central electronic
data retrieval system related to IBAN accounts and safe-deposit boxes. https:
//www.cssf.lu/en/Document/law-of-25-march-2020-data-retrieval/

[2] Sallam Abualhaija, Chetan Arora, and Lionel Briand. 2022. COREQQA - A COm-
https:

pliance REQuirements Understanding using Question Answering Tool.
//doi.org/10.5281/zenodo.6653514

[3] Sallam Abualhaija, Chetan Arora, Amin Sleimi, and Lionel Briand. 2022. Au-
tomated Question Answering for Improved Understanding of Compliance Re-
quirements: A Multi-Document Study. In 30th IEEE International Requirements
Engineering Conference (RE‚Äô22).

[4] Akiko Aizawa. 2003. An information-theoretic perspective of tf‚Äìidf measures.

Information Processing & Management 39, 1 (2003), 45‚Äì65.

[5] Muneera Bano, Chetan Arora, Didar Zowghi, and Alessio Ferrari. 2021. The Rise
and Fall of COVID-19 Contact-Tracing Apps: when NFRs Collide with Pandemic.
In 2021 IEEE 29th International Requirements Engineering Conference (RE). IEEE,
106‚Äì116.

[6] Brian Berenbach, Daniel J Paulish, Juergen Kazmeier, and Arnold Rudorfer. 2009.
Software & systems requirements engineering: in practice. McGraw-Hill Education.
[7] Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural Language Processing

with Python. O‚ÄôReilly.

[8] Kevin Clark, Minh-Thang Luong, Quoc V. Le, and Christopher D. Manning. 2020.
ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators.
CoRR abs/2003.10555 (2020). arXiv:2003.10555

[9] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT:
Pre-training of Deep Bidirectional Transformers for Language Understanding.
CoRR abs/1810.04805 (2018). arXiv:1810.04805

[10] EU (2019/770). 2019. Directive (EU) 2019/770 of the European Parliament and
of the Council of 20 May 2019 on certain aspects concerning contracts for the
supply of digital content and digital services, OJ L 136, 22.5.2019, p. 1‚Äì27. http:
//data.europa.eu/eli/dir/2019/770/oj

[11] EU (2019/771). 2019. Directive (EU) 2019/771 of the European Parliament and of
the Council of 20 May 2019 on certain aspects concerning contracts for the sale
of goods, amending Regulation (EU) 2017/2394 and Directive 2009/22/EC, and
repealing Directive 1999/44/EC, OJ L 136, 22.5.2019, p. 28‚Äì50. http://data.europa.

eu/eli/dir/2019/771/oj

[12] EU (GDPR). 2016. Regulation (EU) 2016/679 of the European Parliament and of
the Council of 27 April 2016 on the protection of natural persons with regard
to the processing of personal data and on the free movement of such data, and
repealing Directive 95/46/EC (General Data Protection Regulation), OJ L 119,
4.5.2016, p. 1‚Äì88. http://data.europa.eu/eli/reg/2016/679/oj

[13] Mattia Fazzini, Hourieh Khalajzadeh, Omar Haggag, Zhaoqing Li, Humphrey
Obie, Chetan Arora, Waqar Hussain, and John Grundy. 2022. Characterizing
Human Aspects in Reviews of COVID-19 Apps. In 9th IEEE/ACM International
Conference on Mobile Software Engineering and Systems.

[14] Marijn Janssen, Paul Brous, Elsa Estevez, Luis S Barbosa, and Tomasz Janowski.
2020. Data governance: Organizing data for trustworthy Artificial Intelligence.
Government Information Quarterly 37, 3 (2020), 101493.

[15] Dan Jurafsky and James H. Martin. 2020. Speech and Language Processing (3rd

ed.). https://web.stanford.edu/~jurafsky/slp3/ (visited on 2022-01-04).

[16] Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush
Sharma, and Radu Soricut. 2019. ALBERT: A Lite BERT for Self-supervised Learn-
ing of Language Representations. CoRR abs/1909.11942 (2019). arXiv:1909.11942
[17] Dorothy E Leidner and Olgerta Tona. 2021. The CARE Theory of Dignity Amid

Personal Data Digitalization. MIS Quarterly 45, 1 (2021).

[18] Edward Loper and Steven Bird. 2002. NLTK: The Natural Language Toolkit.
In Proceedings of the ACL-02 Workshop on Effective Tools and Methodologies for
Teaching Natural Language Processing and Computational Linguistics.

[19] Paul N Otto and Annie I Ant√≥n. 2007. Addressing legal requirements in require-
ments engineering. In 15th IEEE international requirements engineering conference
(RE 2007). IEEE, 5‚Äì14.

[20] Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings
using Siamese BERT-Networks. CoRR abs/1908.10084 (2019). arXiv:1908.10084
[21] Amin Sleimi, Marcello Ceci, Nicolas Sannier, Mehrdad Sabetzadeh, Lionel Briand,
and John Dann. 2019. A Query System for Extracting Requirements-Related
Information from Legal Texts. In 27th IEEE International Requirements Engineering
Conference. IEEE.

[22] Amin Sleimi, Nicolas Sannier, Mehrdad Sabetzadeh, Lionel Briand, and John
Dann. 2018. Automated Extraction of Semantic Legal Metadata using Natural
Language Processing. In Proceedings of the 26th IEEE International Requirements
Engineering Conference.

