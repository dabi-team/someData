2
2
0
2

y
a
M
7
2

]
E
S
.
s
c
[

1
v
2
7
8
3
1
.
5
0
2
2
:
v
i
X
r
a

1

Self-Admitted Technical Debt in the Embedded
Systems Industry: An Exploratory Case Study

Yikun Li, Mohamed Soliman, Paris Avgeriou, and Lou Somers

Abstract—Technical debt denotes shortcuts taken during software development, mostly for the sake of expedience. When such
shortcuts are admitted explicitly by developers (e.g., writing a TODO/Fixme comment), they are termed as Self-Admitted Technical
Debt or SATD. There has been a fair amount of work studying SATD management in Open Source projects, but SATD in industry is
relatively unexplored. At the same time, there is no work focusing on developers’ perspectives towards SATD and its management. To
address this, we conducted an exploratory case study in cooperation with an industrial partner to study how they think of SATD and
how they manage it. Speciﬁcally, we collected data by identifying and characterizing SATD in different sources (issues, source code
comments and commits) and carried out a series of interviews with 12 software practitioners. The results show: 1) the core
characteristics of SATD in industrial projects; 2) developers’ attitudes towards identiﬁed SATD and statistics; 3) triggers for practitioners
to introduce and repay SATD; 4) relations between SATD in different sources; 5) practices used to manage SATD; 6) challenges and
tooling ideas for SATD management.

Index Terms—technical debt, self-admitted technical debt, mining software repositories, source code comment, issue tracking system,
commit, empirical study

(cid:70)

1 INTRODUCTION

Technical debt (TD) refers to compromising the long-term
maintainability and evolvability of software systems by se-
lecting sub-optimal solutions, in order to achieve short-term
goals [1]. When software developers incur technical debt,
they sometimes explicitly admit it; for example, software
developers may write TODO or Fixme in a source code com-
ment, indicating a sub-optimal solution in that part of the
code. Potdar and Shihab [2] called these textual statements
Self-Admitted Technical Debt (SATD). SATD can be found in
several sources such as source code comments [2], issues in
issue tracking systems [3], [4] and commit messages [5].

The SATD that can be identiﬁed in such sources is
complementary to the technical debt that can be identiﬁed in
source code through static analysis. This is because, certain
types of technical debt cannot be identiﬁed by analyzing
source code. For example, partially implemented requirements
is a type of requirement debt [4] that can be identiﬁed from
source code comments or issue tracking systems but not
from running source code analysis tools: “TODO: This class
only has partial Undo support (basically just those members that
had it as part of a previous implementation) [from Apache Ar-
goUML1].” Therefore it is important to identify and further

• Yikun Li, Mohamed Soliman, Paris Avgeriou are with the Bernoulli
Institute for Mathematics, Computer Science and Artiﬁcial Intelligence,
University of Groningen, The Netherlands.
E-mail: {yikun.li, m.a.m.soliman, p.avgeriou}@rug.nl
Lou Somers is with the Department of Mathematics and Computer
Science, Eindhoven University of Technology, The Netherlands.

•

Manuscript received; revised. This work was supported by ITEA3 and RVO
under grant agreement No. 17038 VISDOM (https://visdom-project.github.
io/website).

1. https://github.com/argouml-tigris-org/argouml/blob/
d5cd45cb4409c6f50747a3a2671219111b443c48/src/argouml-app/
src/org/argouml/notation/NotationSettings.java#L108

manage SATD, in addition to the more traditional approach
of managing technical debt in source code.

There has been a fair amount of work investigating the
identiﬁcation [6], [7], measurement [8], prioritization [9],
and repayment [10], [11] of SATD. However, to the best
of our knowledge, all previous studies (but one, namely
[5]) identiﬁed SATD in open-source projects; we actually
know little about SATD in industrial projects. Moreover,
none of the previous studies has surveyed software devel-
opers about SATD, in order to capture their perspectives
towards SATD management, and tooling support for dif-
ferent sources. Without involving software developers to
investigate SATD, researchers risk developing theories or
approaches, which do not align with the needs and practices
of software engineers.

To address these shortcomings, we conducted an ex-
ploratory case study in collaboration with an industrial
partner to investigate how SATD is managed and how this
can be supported. We collected data in two steps. First, we
identiﬁed and characterized SATD in projects within that
company from three sources: issues, source code comments
and commits. This step took place by using pre-trained
machine learning models [12]. Second, we carried out a
series of interviews with 12 software practitioners from that
organization to understand their perception of what SATD
really is, how it is managed, and how this management
can be potentially improved. The contributions and main
ﬁndings of this study, are summarized as follows:

• Characterizing SATD in industrial projects. The re-
sults indicate that most technical debt is admitted in
issues, followed by source code comments and com-
mit messages. Non-SATD issues take a signiﬁcantly
shorter time to close, compared to SATD issues.
• Reporting developers’ attitudes towards identiﬁed

 
 
 
 
 
 
SATD and statistics. Most interviewees acknowl-
edged the identiﬁed SATD. However, they do need
more information to assess the importance of indi-
vidual SATD items.

• Reporting relations between SATD from different
sources. We found that SATD in code comments and
issues is referenced in the other sources, while SATD
in commits is not referenced in other sources.

• Reporting triggers on SATD introduction and re-
payment. The results show developers have different
reasons to introduce and pay back SATD, depending
on the data source (code comments, issues, commits).
• Reporting practices used to manage SATD. We sum-
marize and report practices that are used to assist in
SATD prioritization and repayment.

• Reporting tooling support for SATD management.
We report tool features that developers suggested as
useful for SATD identiﬁcation, traceability, prioriti-
zation, and repayment.

The rest of this paper is organized as follows. Section 2
discusses related work. The case study design is elaborated
in Section 3. Section 4 presents the results, and Section 5
discusses the implications of these results on researchers
and practitioners. Finally, threats to validity are evaluated
in Section 6 and conclusions are drawn in Section 7.

2 RELATED WORK

To facilitate comparison to our work, we split the related
work into two parts: work associated with SATD in Open-
Source Software and work associated with SATD in indus-
trial settings.

2.1 SATD in Open-Source Software

Potdar and Shihab [2] were the ﬁrst to study SATD in source
code comments. They analyzed four open-source projects
and identiﬁed SATD in them. They found that 2.4% to 31%
of source ﬁles contain SATD comments and only 26.3% to
63.5% of SATD are removed after introduction. Moreover,
the results of Potdar and Shihab show that experienced
developers tend to introduce more SATD compared to in-
experienced developers. Building on this work, Maldonado
and Shihab [13] focused on the types of SATD in open-
source projects. They analyzed 33K code comments from
ﬁve projects and categorized SATD into ﬁve categories:
design, requirement, defect, documentation, and test debt.
The results indicated that design debt is the most common
type of SATD, as 42% to 84% of classiﬁed SATD is design
debt.

Subsequently, there was a signiﬁcant focus on automatic
SATD identiﬁcation. Maldonado et al. [6] manually classi-
ﬁed source code comments into different types of SATD
from ten open-source projects and utilized the maximum
entropy classiﬁer to automatically identify design debt
and requirement debt. Similarly, Huang et al. [14] used
the feature selection method to select the most important
features and adopted the ensemble learning technique to
leverage different machine learning approaches to accu-
rately identify SATD, again from source code comments.
Furthermore, different machine learning approaches were

2

applied to achieve higher predictive performance for SATD
identiﬁcation. Speciﬁcally, Ren et al. [7] proposed a Con-
volutional Neural Network-based approach to accurately
identify SATD from source code comments. Wang et al. [15]
proposed an attention-based neural network to automati-
cally detect SATD. In addition to using source code com-
ments, few studies focused on identifying SATD from other
sources. Dai and Kruchten [3] manually analyzed 8K issue
tickets and used the Naive Bayes method to classify SATD
issues and non-SATD issues. In our previous work [16], we
examined 23K issue sections and proposed a Convolutional
Neural Network-based approach to identify SATD from
issue tracking systems.

In addition to SATD identiﬁcation, there has been work
related to measurement, prioritization, and repayment of
SATD. Kamei et al. [8] explored ways to measure the interest
of SATD and suggested to use LOC and Fan-In measures.
The results indicated that 42.2% to 44.2% of SATD incurs
positive interest (i.e. technical debt costs more to repay in the
future), while 8.1% to 13.8% of SATD incurs negative interest
(i.e., technical debt costs less to pay back in the future).
Mensah et al. [9] introduced a SATD prioritization scheme
which consists of identiﬁcation, examination, and rework
effort estimation. The results showed that a rework effort
of modifying 10 to 25 commented LOC per SATD source
ﬁle is required for highly prioritized SATD tasks. Besides,
Maldonado et al. [10] analyzed ﬁve open-source projects to
investigate the repayment of SATD. The results indicated
that most of SATD is removed eventually and the payback
is mostly done by those that incurred the SATD in the ﬁrst
place. They also found that SATD lingers in the code for
approximately 18 to 172 days. In a similar study, Zampetti
et al. [11] looked into how SATD is resolved in ﬁve open-
source projects. They found that between 20% to 50% of
SATD comments are removed by accident, and 8% of SATD
repayment is documented in commit messages.

Compared to all aforementioned studies, our study has
the following differences: a) we utilized machine learning
models to identify and characterize SATD; b) we performed
this analysis on a number of different sources, instead of
only one; c) we work in an industrial setting instead of open-
source systems; d) we explored developers’ perspectives
towards both the nature of SATD and its management.

2.2 SATD in Industrial Settings

SATD in industrial settings is relatively unexplored; there is
only one work that studied SATD in industrial settings and
compared it with open-source settings [5]. Speciﬁcally, Zam-
petti et al. surveyed 52 industrial developers and 49 open-
source project contributors. They focused on technical debt
admitted in source code comments and found that technical
debt annotation practices and the typical content of SATD
comments are similar in industrial and open-source settings.
Furthermore, the results showed that admitted technical
debt in industrial projects is implicitly discouraged by the
fear of taking on responsibilities. The results indicated that
technical debt is also admitted in other sources, including,
among others, commit messages, pull request, and issue
trackers.

In contrast to Zampetti et al. [5], who only investigated
source code comments, we focus on analyzing SATD from

multiple sources (i.e., source code comments, commit mes-
sages, and issue tracking systems). In addition, we use
machine learning techniques to identify SATD from differ-
ent sources in industrial settings, demonstrate the charac-
teristics of SATD, and present the interviewees’ attitudes
towards the identiﬁed SATD and statistics. Finally, we also
study the process of managing SATD, as well as how to
improve it from the point of view of software practitioners.

3 STUDY DESIGN
3.1 Objective and Research Questions

The goal of this study, formulated according to the Goal-
Question-Metric [17] template is to “analyze self-admitted
technical debt in source code comments, issue tracking systems,
and commit messages for the purpose of understanding and im-
provement with respect to the nature and management process of
self-admitted technical debt in practice from the point of view
of software engineers in the context of the embedded systems
industry.” To be more precise, we aim at understanding both
the nature of SATD per se and the process of managing it, as
well as improving this process. Consequently, we formulate
three main research questions (RQs) that are further reﬁned
into sub-questions. In Section 4 we will not answer the main
RQs directly, but only indirectly through answering the sub-
questions.

• RQ1: What is the nature of SATD in industry?

◦ RQ1.1: What are the types, amounts, resolution
time and sources of SATD items in industrial
settings?
Rationale: There are signiﬁcant differences
between open-source projects and industrial
projects concerning project management, tool-
ing, as well as collaboration and communica-
tion [18], [19]. Thus, developers may admit
technical debt differently in the two cases.
Meanwhile, as mentioned in Section 2, all
(but one, namely [5]) previous studies on
SATD have focused on open-source projects.
Thus, determining the types of SATD (e.g.
requirements, design, code debt), amount of
SATD (i.e. number and percentages of SATD
items), and the sources of SATD (e.g. issue
tracker or source code comments) in indus-
trial projects, and comparing them with open-
source projects could help researchers under-
stand what SATD looks like in practice, and
practitioners to better manage SATD in both
cases.

◦ RQ1.2: How is automatically identiﬁed SATD re-

garded by professional software engineers?
Rationale: The identiﬁcation of SATD can be
automated, e.g. by using machine learning
techniques [7], [16]. However, as far as soft-
ware engineers are concerned, the identiﬁed
SATD items could be obsolete, inaccurate, ir-
relevant, or inconsistent with the code. We aim
at understanding how far software engineers
consider that the SATD items are indeed im-
portant and relevant for their system. We also

3

want to understand whether software engi-
neers agree with the main statistics of the iden-
tiﬁed SATD (e.g. percentage of backlog items
and the lifetime of SATD items). This can help
us understand the strengths and weaknesses
of automated SATD identiﬁcation.

◦ RQ1.3: What are the relations between SATD in

source code,

different sources?
Rationale: The different sources where SATD
is documented (e.g.
issues,
commits), are implicitly or explicitly related
to each other. Thus, developers sometimes
choose to document the same technical debt
in more than one sources. For example, when
developers encounter SATD in code comments
and they consider this debt as important, they
might document it in issue tracking systems
for more exposure and visibility. In these cases,
we are interested in understanding the con-
nections between the SATD items in these
different sources. This can assist in improving
the traceability of SATD in different sources.

• RQ2: How is SATD being managed in industry?

◦ RQ2.1: When is technical debt (not) admitted in
source code comments, issue tracking systems, and
commit messages?
Rationale: It is important to understand the
reasons for documenting or not documenting
technical debt in different sources. This can
help researchers in coming up with guide-
lines and practices for SATD documentation.
Furthermore, this could help develop tools to
assist in documenting SATD.

◦ RQ2.2: What are the pros and cons of admitting

technical debt in different sources?
Rationale: Each source has its advantages and
disadvantages in terms of documenting tech-
nical debt. For example, technical debt that
is admitted in code comments, allows devel-
opers reading those comments to also exam-
ine the problem in the adjacent code. On the
downside, SATD in code comments has lim-
ited visibility for team leads and project man-
agers and typically does not get added to the
backlog. Understanding the pros and cons of
different sources for documenting SATD could
help developers make better use of different
sources to document technical debt.

◦ RQ2.3: What are the triggers to pay back or not

pay back SATD?
Rationale: Developers are more likely to pay
back SATD in certain cases. We plan to in-
vestigate the developers’ motivation both for
repayment and for deciding to leave SATD in
the system. This could help researchers un-
derstand the reasons for SATD repayment and
develop a tool to assist practitioners in paying
back TD.

◦ RQ2.4: What practices are used to support SATD

management in industrial settings?

4

Fig. 1. The framework of our approach.

Rationale: While, a number of studies have
investigated TD management in industry, we
know very little about managing self-admitted
TD. This RQ can help in understanding the
current practices of SATD management
in
industrial settings. For example, developers
could group similar SATD to facilitate the
SATD repayment. Software practitioners may
be able to use some of these practices in their
own context, while researchers may investi-
gate ways of supporting them.

• RQ3: How can we improve SATD management?

◦ RQ3.1: What challenges do software practitioners

face when managing SATD?
Rationale: Understanding the challenges for
SATD management can help researchers to
provide support for addressing those chal-
lenges. For example, prioritization of technical
debt items is a typical challenge in any kind of
technical debt, including self-admitted. If we
obtain an in-depth understanding of why it is
difﬁcult to prioritize SATD in speciﬁc, we are
in a a better position to propose practices, tools
or guidelines to address this challenge.

◦ RQ3.2: What features should tools have to effec-

tively manage SATD?
Rationale: As mentioned in Section 2, there are
tools supporting SATD identiﬁcation. How-
ever, we currently lack tools to assist in other
activities of SATD management such as pri-
oritization or repayment [20]. Answering this
question can support the development of new
tools or improvement of existing ones that
could help practitioners better and easier man-
age SATD.

Fig. 1 presents the overall framework of our approach
to answer the research questions. The two major processes
(i.e., data collection and data analysis) are elaborated in the
following sub-sections.

3.2 Cases and Units of Analysis

This case study is designed as a single embedded case study
[21]. Our case is a large software company in the embedded
systems industry that chooses to remain anonymous. The
software development in this company adopts Scrum devel-
opment practices.

Because we focus on understanding SATD and its man-
agement process, as well as improving the latter, we col-
lected data from two types of units. The ﬁrst type of unit
is software artifacts, and includes source code, commits,
and issue tracking systems. We identiﬁed and analyzed the
nature of SATD from these software artifacts. The second
type of unit is software engineers that participated in the
development of a speciﬁc project. More speciﬁcally, each
engineer represents a single unit. We conducted interviews
with software engineers to derive their opinons on the
aforementioned SATD nature, as we well to understand and
improve SATD management. Details about the background
of the practitioners are presented in Table 2.

3.3 Data Collection

As seen in Fig. 1, data is collected through analysis of work
artifacts and interviews, which are third- and ﬁrst degree data
collection methods respectively, according to Lethbridge et
al. [22]. These two methods are explained in the following
subsections in detail.

3.3.1 Analysis of Work Artifacts:

In order to answer the research questions, we choose a large-
scale industrial project which contains eight sub-projects.
More speciﬁcally, the selected project has over 475K lines
of comments, 21K commits, and 130K ﬁles (including doc-
umentation, test ﬁles, conﬁguration ﬁles etc.). Regarding
issues, we collected 78K issues from the issue tracking
system. We note that, all embedded software in the selected
company uses the same issue tracking system; thus, the
collected issues come from all embedded software while
comments and commits are from the selected project where
we had access. Because we focus on three different types of
work artifacts, namely source code comments, issue tracking

Git RepositoryIdentified SATD  Issue TrackerIdentification of SATDUsing Machine LearningModelsProcessDatabaseDataFlow DirectionCollectingBackgroundInformationIndividualInterviewsAnalyzing InterviewsUsing ConstantComparative MethodInterviewsAnswering RQ1.1Final Coding Mining Software RepositoriesData CollectionCollecting IssuesCollecting CommitsExtracting Code CommentsData AnalysisAnswering RQ1.2to RQ 3.2Answering RQsTABLE 1
Questions for Individual Interviews.

5

Question
Do you acknowledge the identiﬁed SATD items from the different sources?
Do you consider identiﬁed SATD items to be important?
Is the percentage of different types of SATD in line with your expectation?
What do you think about the average time to close different types of SATD issues and non-SATD issues?
Do these SATD items and statistics give you new information or insights about this project?
What do you think are the relations between TD documented in different sources?
Do you record TD in your project?
Which TD items do you usually record and which not?
Where do you typically record TD?
Do you have any constraints on recording TD?
Which types of TD do you usually record?
What do you think are the differences between TD documented in different sources?
How do you decide on resolving one of the recorded TD items?
How do you manage the recorded TD items in practice?
How do you prioritize documented TD items in practice?
What strategies do you follow to pay back documented TD?
What challenges do you encounter when you manage recorded TD?
What features would you like to have from an ideal tool to manage SATD?

Related RQs
RQ1.2
RQ1.2
RQ1.2
RQ1.2
RQ1.2
RQ1.3
RQ2.1, RQ2.2
RQ2.1, RQ2.2
RQ2.1, RQ2.2
RQ2.1, RQ2.2
RQ2.1, RQ2.2
RQ2.1, RQ2.2
RQ2.3
RQ2.4
RQ2.4
RQ2.4
RQ3.1
RQ3.2

systems, and commits, we obtained data from these differ-
ent sources separately. For source code comments, we cre-
ated a script to ﬁrst retrieve all code changes in git and then
extract all source code comments using the CommentParser
tool2. For issue tracking systems, we extracted all issue
descriptions for analysis using the API of the issue tracker
used by the company (Microsoft TFS). Lastly, for commits,
we obtained all commit descriptions in git. The scripts for
collecting data are included in the replication package3. We
analyzed the latest version of the selected industrial project
on July 7th, 2021.

3.3.2 Interviews:

We have conducted semi-structured interviews to collect
data from practitioners and answer the research questions.
Semi-structured interviews were selected as they are an
effective approach to explore participants’ thoughts and
experiences in depth [23]. The selection of the participants
was done using purposive sampling based on their experience
and role in the industrial project.

Before the interviews, we extracted work artifacts from
the selected project as aforementioned and identiﬁed SATD
from them, as illustrated in Fig. 1. Then we selected a sample
of 15 SATD items, to show to the practitioner in order to
help them gain a basic understanding of what automatically
identiﬁed SATD looks like and prepare for the interviews.
The sample of 15 SATD items was randomly selected from
the set of identiﬁed SATD items in the previous step, and
consisted of 5 items from source code comments, 5 items
from commit messages, and 5 items from issues. For exam-
ple, two of the presented SATD items were: “stupid code,

2. https://github.com/jeanralphaviles/comment parser
3. https://drive.google.com/drive/folders/

1ki-GmyWeRjt3xylH1uvUHrblI RVZKet?usp=sharing

why isn’t this part of [function name]?” and “adding sanity
check on timing.” Besides, we provided practitioners with
an introductory document on SATD (including a deﬁnition
and examples of SATD as well as the high-level goal of this
study).

TABLE 2
Background information of interview participants.

Interviewee ID

Role in the Company

I1
I2
I3
I4
I5
I6
I7
I8
I9
I10
I11
I12

Architect
Architect
Architect
Software developer
Software developer
Software developer
Software developer
Software developer
Team lead
Software developer
Team lead
Project manager

Years of
Experience
22
19
20
22
22
20
32
17
18
34
32
24

Practitioners were then interviewed one by one by at
least two of the authors via a web-based platform. We
asked practitioners to answer questions relating to their
background, namely their role in the company and years
of experience. This background information is presented in
Table 2. After the background information collection step,
we asked interviewees some introductory questions (e.g.,
What is your understanding of technical debt? Can you tell
me some examples of technical debt?). These “warm-up”
questions encouraged interviewees to think about their own

experiences with technical debt so that they can answer the
rest of the questions based on those experiences. During
the interviews, we provided statistics on SATD (such as
numbers and percentages of different types of SATD from
different sources) in the selected project and the sample of
identiﬁed SATD items. Practitioners were asked to think
about the SATD examples and statistics before answering
interview questions. Finally, the main part of the inter-
view consisted of several questions aimed at answering
the Research Questions (as shown in Table 1); these were
developed by following the interview guidelines of Seid-
man [24]. We asked the practitioners to talk about their
ideas and opinions freely without restrictions. During the
interviews, we also asked follow-up questions to delve into
their experiences and understanding. Each interview took
approximately 30 minutes. After obtaining permission from
interviewees, interviews were recorded to be transcribed for
analysis.

3.4 Data Analysis

3.4.1 Analysis of Work Artifacts:

To identify SATD from work artifacts, we ﬁrst collect data
from the selected projects, as discussed in Section III-C.
Subsequently, we followed the results of our previous work
[12] to identify SATD from different sources using a deep
learning approach. This work is the only one focusing on ac-
curately capturing SATD from different sources; speciﬁcally,
the trained deep learning model achieved an f1-score (i.e.,
the harmonic mean of precision and recall) of 0.666, 0.644,
0.557 when identifying SATD from source code comments,
commit messages, and issue tracking systems respectively.

3.4.2 Interviews:

To analyze the interviews, we ﬁrst transcribed all interview
recordings. It is noted that one of the interviewees did not
grant us permission to record the interview, so this interview
was transcribed on the ﬂy during the meeting. Then, we fol-
lowed an iterative qualitative data analysis process accord-
ing to the Constant Comparative method of Grounded Theory
[25], [26]. Speciﬁcally, the analysis process is composed of
three main steps. The ﬁrst step is open coding, which breaks
the transcript text down to discrete textual segments, which
are subsequently coded (i.e. labeled). When reading the
interview transcripts, we continuously added new codes or
changed current codes when necessary. The scope of codes
varies, as it could be a phrase, a sentence, or a paragraph.
Second, we applied selective coding, by constantly comparing
different codes and annotations, and then merging similar
codes. Third, we worked on the theoretical coding to establish
conceptual relations between codes.

To ensure the agreement on codes, the ﬁrst and second
authors independently performed the Constant Comparative
analysis process, discussed and compared the generated
codes to eliminate bias. Any disagreements between the two
authors were subsequently resolved.

We used a professional qualitative analysis tool (AT-
LAS.ti4) to analyze the interview data. Analysis results and
interview protocol are available in the replication package3.

4. https://atlasti.com

6

4 RESULTS
4.1 (RQ1.1) What Are the Types, Amounts, Resolution
Time and Sources of SATD Items in Industrial Settings?

Table 3 presents the number of different types of SATD from
different sources. It is noted that, in this and subsequent
tables, the highest values are highlighted in bold, while the
lowest values are underlined. We can observe that most of
the identiﬁed SATD is code/design debt (79.1%), followed
by documentation debt and requirement debt (9.5% and 7.7%
respectively). The least amount of identiﬁed SATD is test
debt (3.7%).

TABLE 3
Number of Different Types of SATD Items from Different Sources.

Debt Type

Code/Design debt
Req. debt
Doc. debt
Test debt
All SATD

Comment
3,139
602
225
63
4,029

Source
Issue
9,318
702
1,350
540
11,910

Commit
2,236
119
199
93
2,647

Total

14,693
1,423
1,774
696
18,586

As mentioned in Section III-C, the issues come from
all of embedded software, while comments and commits
only from one (large) project. Thus, we cannot compare the
absolute numbers of SATD items directly between sources.
Thus, we look into the percentages of items across the
different sources that contain SATD of different types (see
Table 4). We observe that the percentage of issues or
commits being SATD issues or commits is signiﬁcantly
greater than source code comments (16.3% and 12.7%
versus 2.6%). Finally, the percentage of issues being SATD is
slightly greater than commits.

TABLE 4
Percentages of Different Types of SATD Items from Different Sources.

Debt Type

Code/Design debt
Req. debt
Doc. debt
Test debt
All SATD

Comment
2.0%
0.4%
0.2%
0.0%
2.6%

Source
Issue
12.8%
1.0%
1.9%
0.7%
16.3%

Commit
10.7%
0.6%
1.0%
0.4%
12.7%

Total

5.9%
0.6%
0.7%
0.3%
-

Fig. 2 presents the number of cumulative technical debt
admitted in different sources over time. As can be seen,
software developers keep documenting technical debt in
different sources. In the beginning of the studied period
(before January 2017), the number of SATD in source code
comments is comparable with the number of SATD in
issues. Afterwards, the rate of admitting technical debt in
issues increases compared to source code comments.

Because issue tracking systems provide additional infor-
mation (e.g., issue type, issue status, issue closed time) that
is related to SATD introduction and repayment, we further
investigate SATD in issue tracking systems. Speciﬁcally, we
investigate the time required to resolve issues (with and

TABLE 6
Comparison of Average Time to Close Issues Between Different Types
of SATD and Non-SATD Issues.

7

Pairwise Comparison

p-value

Code/Design debt
Req. debt
Doc. debt
Test debt
Code/Design debt
Req. debt
Doc. debt
Non-SATD
Code/Design debt
Req. debt
Test debt
Non-SATD
Code/Design debt
Doc. debt
Test debt
Non-SATD
Req. debt
Doc. debt
Test debt
Non-SATD

& Non-SATD

& Test debt

& Doc. debt

& Req. debt

& Code/Design debt

1.1e-20
1.3e-4
9.9e-4
3.3e-7
0.014
0.361
0.020
3.3e-7
0.641
0.160
0.020
9.9e-4
0.247
0.160
0.361
1.3e-4
0.247
0.641
0.014
1.1e-20

Cliff’s
Delta
0.12
0.24
0.20
0.19
0.07
-0.06
-0.01
-0.19
0.07
-0.06
0.01
-0.20
0.12
0.06
0.06
-0.24
-0.12
-0.07
-0.07
-0.12

provide a function that helps developers categorize and
track the progress of speciﬁc types of work [30]. In the
studied case company, the issue tracking system (Microsoft
TFS) similarly supports specifying different types of issues.
The most common issue types used by the case company, are
feature, backlog item, task, bug, and test. The hierarchy of issue
types is illustrated in Fig. 3. The studied organization uses
these ﬁve issue types as deﬁned by Microsoft [31]: feature
is the highest-level type of work, it is associated with a
speciﬁc product feature, and it is the parent of backlog item
and bug. Backlog item is used to track development work,
while bug is for tracking code defects. Moreover, task is
used to track ﬁne-grained work, i.e. it is a child of both
backlog item and bug. Additionally, test-related issue types
are used independently of other types. Because there are
three test-related types, namely test case, test plan, and test
suite, we group them together under the category of test.
Table 7 presents the number of different types of SATD in
accordance with these different issue types. As we can see,
most of SATD is identiﬁed as backlog item and task (4,822
and 4,492 respectively). This indicates that backlog item and
task are the two most popular issue types to admit technical

Fig. 3. Hierarchy of issue types.

Fig. 2. Cumulative number of SATD items in different sources over time.

without SATD), and the types of issues (e.g. backlog item
or bug) with SATD. These are presented in the rest of this
sub-section.

Table 5 presents the average time to close different types
of issues and the percentage of different types of issues that
are closed. As we can see, the average time to close different
types of issues varies: the average time to close non-SATD
issues is shorter (47.2 days) compared to different types of
SATD issues; test debt issues take the longest average time
to close (80.7 days). Moreover, non-SATD issues achieve the
highest closed rate (75.5%), while requirement debt issues
have the lowest closed rate (60.8%).

TABLE 5
Average Time to Close Issues and Percentage of Closed Issues.

Type
Code/Design debt
Req. debt
Doc. debt
Test debt
Non-SATD

Avg. Time to Close (d)
62.5
70.2
60.4
80.7
47.2

Pct. of Closed (%)
71.3
60.8
72.0
67.0
75.5

Speciﬁcally, to evaluate the signiﬁcance level and the
effect size of closing time between different types of is-
sues, we choose Mann-Whitney test [27] and Cliff’s delta
[28]. The Mann-Whitney test is used to determine if two
groups are signiﬁcantly different from each other and is
widely used in software engineering studies [4], [14]. The
results are demonstrated in Table 6, while the p-value
is highlighted when it is less than 0.05, which indicates
the result has statistical signiﬁcance. We can notice that,
in contrast to previous research ﬁndings [29], there are
signiﬁcant differences between the closing time of non-
SATD issues and different types of SATD issues (p-values
are 1.1e−20, 1.3e−4, 9.9e−4, and 3.3e−7 respectively). Fur-
thermore, closing time differences between test debt issues
and code/design debt issues or documentation debt issues
are statistically signiﬁcant (p-values are 0.014 and 0.020).
As speciﬁed by the effect size in Table 6, we ﬁnd that
the closing time differences between non-SATD issues and
different types of SATD issues are greater than the closing
time between different types of SATD issues.

Next, we study the occurrence of the types of SATD
items (e.g. design or test debt) in the different types of
issues (e.g. backlog or bug). Issue tracking systems typically

Jul 2016Jan 2017Jul 2017Jan 2018Jul 2018Jan 2019Jul 2019Jan 2020Jul 2020Jan 202102k4k6k8k10k12kIssuesCommitsCode CommentsNumber of technical debt admitted in Different Sources over TimeDateNumber of SATD ItemsFeatureBacklog ItemTaskBugTestIssue TypeIs Parent Ofdebt.

TABLE 7
Number of Different Types of SATD Items in Different Types of Issues.

Debt Type

Code/Design debt
Req. debt
Doc. debt
Test debt
All SATD

Issue Type

Feature

695
58
85
47
885

Backlog
Item
3,770
350
512
190
4,822

Bug

1,204
37
46
46
1,333

Task

3,355
211
701
250
4,492

Test

220
10
0
17
247

Because the total numbers of the different types of is-
sues vary, it is unclear which issue type has the highest
percentage of SATD issues. To address this, we show the
percentage of different types of SATD in accordance with
different issue types in Table 8. We can notice that although
backlog item and task have similar number of SATD issues
(4,822 versus 4,492) in Table 7, backlog item has a signiﬁcantly
higher percentage of SATD issues compared to task (24.5%
versus 12.4%). This means that backlog item has the highest
percentage and number of SATD issues among all issue
types; in other words, it is the most used issue type for
admitting technical debt. This is in line with the deﬁnition
of technical debt [1]: while defects and poorly/partially
implemented features are symptoms of technical debt, pure
technical debt items concern issues that directly affect the
maintenance and evolution of a software system.

TABLE 8
Percentage of Different Types of SATD Items in Different Types of
Issues.

Debt Type

Code/Design debt
Req. debt
Doc. debt
Test debt
All

Issue Type

Feature

16.7%
1.4%
2.0%
1.1%
21.2%

Backlog
Item
19.2%
1.8%
2.6%
1.0%
24.5%

Bug

Task

Test

12.4%
0.4%
0.5%
0.5%
13.8%

9.2%
0.6%
1.9%
0.6%
12.4%

12.9%
0.6%
0.0%
1.0%
14.5%

4.2 (RQ1.2) How Is Automatically Identiﬁed SATD Re-
garded by Professional Software Engineers?

We report here the opinions of the interviewees on identiﬁed
SATD and corresponding statistics produced by the auto-
mated SATD analysis. First, we present the attitude towards
SATD identiﬁed from different sources (two examples of
identiﬁed SATD are shown in Section 3):

• Attitude towards SATD identiﬁed from code comments.
We found that eight out of ten interviewees that
commented on this, conﬁrmed that SATD identiﬁed
from code comments is indeed technical debt from
their perspective: “yeah, those are the typical things
[technical debt] that we enter in the code indeed.” The
other two interview participants also identiﬁed the
vast majority of the discussed SATD items but were

8

not very sure about one or two items: “the ﬁrst one I
would say difﬁcult, it could also be a matter of taste; [...]
the last one is the same as the ﬁrst one, really depends on
the situation.”

• Attitude towards SATD identiﬁed from issues. Six out of
seven interviewees acknowledged SATD identiﬁed
from issues as debt: “I expect them to be part of the
backlog list, but I cannot explain to you one by one; I think
they are technical debt.” Meanwhile, one interviewee
found it difﬁcult to judge whether it is SATD or not.
• Attitude towards SATD identiﬁed from commits. Seven
out of eight participants conﬁrmed that SATD iden-
tiﬁed from commits is technical debt from their
point of view. Interestingly, four out of these seven
participants pointed out that SATD in commits con-
cerns documentation of paying back technical debt
instead of incurring technical debt: “do you recognize
technical debt in commits? yeah, but I think these are
[documented] when somebody solves the technical debt in
commit messages.” There is one interviewee that did
not acknowledge SATD in commits: “we always added
text block in commits but not technical debt in commit
messages.”

Second, we discuss the participants’ opinions about the
importance of the identiﬁed SATD items. Five out of nine
interviewees mentioned that they need more information
to determine the importance: “you have to know the imple-
mentation to have some insights on how severe such a thing
is and how much work it will be to solve it; it [importance]
is not immediately clear from the TODO itself.”. Besides, two
out of nine participants believed that some of the items are
not important, while the others need more information to
evaluate: “the ﬁrst one that I would say it’s something that isn’t
really going to be resolved [...] the third one - it looks like it
depends a bit on the on the functionality; is this really important
or not, which is difﬁcult to determine.” Meanwhile, the rest
two of the nine interviewees pointed out that none of the
identiﬁed SATD are important: “it does not have urgency to be
solved.”

Third, we report on the engineers’ opinions on the
percentages of SATD identiﬁed from different sources (see
Table 3), e.g., most of the technical debt is admitted in issues
(64.1%), followed by source code comments (21.7%) and
commits (14.2%). Three interview participants thought the
percentages are in line with their expectations: “I think this is
realistic and right.” Meanwhile, ﬁve interviewees anticipated
percentages to be different. More speciﬁcally, four of them
expected that there would be less technical debt in issues:
“I’m positively surprised that much [technical debt] is already in
issues.” The other interviewee expected more technical debt
admitted in commits: “the ﬁgure is kind of strange that the
number of technical debt in commits is much less than technical
debt in issues because people usually resolve issues with multiple
commits.”

Fourth, we describe the attitudes towards average time
to close issues (see Tables 5 and 6). Seven out of nine
participants expected the same as the ﬁgure shown: “I think
that is correct, which is about the balancing I told you between
new functionality and technical debt.” One interviewee agreed
that technical debt items take a longer time to be resolved

compared to non-debt items, but he also pointed out that
he expected documentation debt to take the longest time
to be solved among all types of debt: “I did not expect test
debt takes that long; I would have expected the documentation
debt to be there the biggest one.” Besides, one participant
had different expectations than the results: “I think it’s a
matter of calculation; it’s the other way around [compared to the
expectation].”

Fifth, we report thoughts of participants towards all the
presented statistics (see Tables 3 to 8 and Fig. 2) and identi-
ﬁed SATD items (some examples are shown in Section 3):

•

• Giving insights on how technical debt is managed. Five
interviewees indicated that statistics help them un-
derstand how technical debt is managed in their
projects: “if you look at the statistics, I think that’s the
objective view of how things are managed.” Furthermore,
two of the participants considered it useful that
the statistics provide information about the different
types of SATD and the average time spent on SATD
items and non-debt items.
Showing what are the focus points. One participant
mentioned that statistics also show what the team
emphasizes during SATD management: “do you think
statistics is useful? yeah, [...] I would say [I know] what
is focused on.”
Increasing the awareness of SATD. Five interviews re-
vealed that statistics and identiﬁed SATD help devel-
opers be conscious of technical debt in the projects:
“it could always help to make us aware of technical debt.”
• Providing insights on future improvement. One inter-
viewee stated that statistics could help developers
become better and achieve higher productivity: “it
gives some insight on how can you improve and be more
efﬁcient in your work.”

•

4.3 (RQ1.3) What Are the Relations Between SATD in
Different Sources?

The relations between SATD items in different sources, as
derived from the data, are summarized and presented in
Fig. 4. It is evident that technical debt admitted in code
comments and issues is referenced in the other two sources,
while technical debt admitted in commits is not mentioned
in other sources. Because each issue has a unique issue ID,
developers can refer to that ID when referencing a SATD
issue: “in most cases, we try to add the issue ID within the
comments.” We call this reference a speciﬁc reference. On the
other hand, since there is no unique identiﬁer for each
source code comment, it is impossible to reference speciﬁc
comments. Thus, such references are usually approximate
references. We describe the relations in detail as they are
numbered in Fig. 4:

1) Technical debt admitted in code comments is referenced
in issues. Two interviewees mentioned that it is not
common to reference SATD code comments within
issues: “in the issues, nine out of ten times, [develop-
ers] never write down which actually line or ﬁle [is]
related.” However, one of them also pointed out
that developers sometimes note down in issues the
approximate location of technical debt which has

9

Fig. 4. Relations between SATD items in different sources.

been documented in code comments: “[developers]
only specify a certain piece of code where the problem
resides.”

2) Technical debt admitted in issues is referenced in code
comments. The links from issues to code comments
are mentioned by four interview participants. They
tend to add issue IDs (unique identiﬁer) in the code
comments to establish clear links: “sometimes you add
a link to the issue in the code.”

3) Technical debt admitted in issues is referenced in commit
messages. Two interviewees mentioned that SATD in
issues is also referenced in commits: “in the commit,
we are able to tag the issue item, and then the link
between commits and issues is made automatically.” This
gives developers a better understanding about the
changes in the commits: “I do not know if it was
a single line commit message, which is vague, short,
and without explanation [...] we need to have more
information in the commit or a link to the issues.”
4) Technical debt admitted in code comments is referenced
in commit messages. One interviewee indicated that
the repayment of SATD in code comments might
be documented in commit messages: “there could be
a link if you have the previous one in comments, when
somebody solved it, probably in the commit message you
might record the resolve of it.”

4.4 (RQ2.1) When Is Technical Debt (Not) Admitted in
Source Code Comments, Issue Tracking Systems, and
Commit Messages?

During the interviews, we established that software engi-
neers tend to admit technical debt in different sources for
different reasons. For each source (i.e., source code com-
ments, issue tracking systems, and commit messages), we
report several cases why technical debt is being admitted.
We start ﬁrst with the source code comments:

•

•

Scale of technical debt is small. Three interviewees
mentioned that developers tend to document small
technical debt items in source code comments: “if it
[technical debt] is too small, just admit it in the code com-
ments.” Regarding what small technical debt actually
means, as an interviewee stated: “if you look at things
in source code, they are typically smaller; those things are
just magic number or making this as parameter...”
Solving technical debt brings little or no beneﬁt. When
solving technical debt yields small or negligible ben-
eﬁt, developers tend to document it in comments: “if

2)3)IssuesCommit Messages1)4)Code CommentsSourceApproximate referenceSpecific referencewe will not gain the advantage over anyway, then probably
something will be noted in the software [...] a comment
will be added.”

• Deciding not to ﬁx the technical debt. If developers reach
an agreement on not ﬁxing the technical debt, they
usually just document it in code comments: “if we
already decide not to ﬁx this technical debt, then probably
it will remain as comments.”

• Helping other developers to become familiar with technical
debt related to code and its rationale. Two interviewees
mentioned that it is important to document techni-
cal debt and its rationale to help other developers
become aware of problematic code and the reasons
behind it: “the comments in software to make sure that
when people are facing troubles and having a look at the
software again that they know about the facts that have
been made to some different choices and which could result
in a problem.”
It concerns requirement debt. Three interviews reveal
that if the technical debt is of the type requirement
debt, such as partially implemented requirements,
developers prefer to document it in source code
comments: “because we have not ﬁnished yet, it [code
comment] is typically written down while developing the
feature.”

•

Second, for issue tracking systems, technical debt is docu-

mented in the following cases:

•

Scale of technical debt is big. Two interview participants
indicated that developers always document large-
scale technical debt in issue trackers: “If you look at
issue tracker... you have to ﬁx this entire piece of code,
that’s a bigger span, while in code it’s basically for the
next line.”

•

• Technical debt is part of the future plan. Five intervie-
wees pointed out that developers always document
technical debt in issues when they actually plan to
ﬁx them in the future: “I think that we create issues for
them [technical debt] to make sure that they will become
part of the future plans.”
Features only supported by the issue tracker. Issue track-
ing systems provide features that are not provided
by code comments or commits, such as uploading
attachments and assigning severity level for issues.
An interviewee mentioned that he always summa-
rizes technical debt and designs in a word document
on a daily basis, then uploads it as an attachment
when creating the new issue.

• Track technical debt repayment in the engineering phase.
Developers in this case study refer to software de-
velopment in later iterations with engineering phase,
which is different from the early phase of develop-
ment. When developers want to track what changes
will be made to solve technical debt in the engineer-
ing phase, they create issues: “I think in engineering
phase [when I] have to clean something up, I will deﬁnitely
make issues, so you can always see what has been done; in
the early phase, it’s just about what works are expected.”
• Duplicate existing technical debt admitted in code com-
ments. Some software engineers believe existing tech-
nical debt in comments should also be admitted in

10

issues to facilitate their tracking: “if there are still
TODOs in the code, there should also be an issue that
something still needs to be done.”

Third, developers document technical debt in commit

messages, in the following cases:

• Commits introducing Technical Debt. One interviewee
pointed out that, if commits include workarounds
that are typical of technical debt, they usually doc-
ument those problems, as well as the related issue
keys in the commit messages: “we have certain commits
which indicate that we have to make shortcuts or we have
implemented a temporary situation.”

• Commits related to technical debt repayment. Three inter-
views disclosed that if commits are about technical
debt repayment, they always document it in commit
messages: “these are when somebody solved technical
debt in these commit messages.”

Finally, we also summarize the cases when technical debt

is ignored or not documented in artifacts:

• Developers are under pressure and forget to document
technical debt. One participant pointed out that if the
pressure is very high, developers usually focus on
other work and postpone technical debt documenta-
tion; in most cases, it is eventually forgotten: “if the
pressure is really high, [...] you will do that [technical
debt] tomorrow, and tomorrow has another thing that got
forgotten.”

• Certain types of technical debt are ignored. According
to four interviews, some developers do not consider
certain types of technical debt to be important and
choose not to document them. Speciﬁcally, intervie-
wees believed that developers pay less attention to
documenting test debt: “I think we don’t have that
many technical debt items for missing test cases; I think
you more or less know about them, but no real documen-
tation about test cases and actual implementation.”
Scale of technical debt is small. When the scale of
technical debt is small, developers may decide not to
document it at all because of its low impact: “what are
the reasons not documenting technical debt? [it depends
on] how big is the technical debt, if just a small thing, it’s
probably not.”

•

• Technical debt in legacy code. Two interviewees re-
ported that developers are aware of the limitations of
technical debt in old parts of the system and choose
not to document it, because they know it will not
be ﬁxed anyway: “[if] the architecture is already ﬁfteen
years old [...], you know what the limitations are, you can
still writes technical debt to make it better, but you know
it will not be ﬁxed anyway.”
Short life of technical debt. We noticed that when de-
velopers think the technical debt will be solved in the
near future, they might choose not to document it: “I
know that for the old release, we make a quick workaround,
but we don’t mark [it] as technical debt because we make
the actual good solution in our mainline immediately.”
• Direction is unclear in early phases. Because of un-
certainties in the early phases of projects, software
engineers may choose not to document it: “At the

•

beginning of the project, it can go anywhere, so if you put
a lot of effort in explaining why something is done, it takes
lots of time.”

• The responsibility of other developers. In some cases,
developers are in charge of certain parts of software
development or documentation update. When other
developers encounter technical debt, they prefer to
let the responsible person document it: “if it’s someone
else’s documentation, I might mention it to someone. I
usually do not create an issue for that.”

4.5 (RQ2.2) What Are the Pros and Cons of Admitting
Technical Debt in Different Sources?

The pros and cons of documenting technical debt in source
code comments are summarized as below:

•

•

• Pointing to problems in the code. Three interview par-
ticipants pointed out that technical debt documented
in code comments could help developers understand
the existing technical debt in code and potentially
solve it: “make sure that people are looking at the software
[reading source code], they will be familiar with the fact
that there is technical debt in code.”
Long lifetime of code. One interview participant indi-
cated that code is a very stable artifact compared
to others. In contrast to other artifacts, comments in
source code will not disappear in the future: “I have
seen tools coming and gone; ﬁve years back we [switched
the issue tracker] [...], [but] I have code older than ﬁve
years, maybe ten years old, so I don’t know the change
request anymore from seven years back and the rationale;
the only thing I have is just the source code.”
Limited visibility. On the one hand, documenting tech-
nical debt in code comments causes less disturbance
to other developers: “too many detailed task [in issues]
does not help which could bother teammates [...] just admit
them in the code comments, [...] because you intend to
solve it soon anyway.” On the other hand, it could
restrict the visibility of technical debt, resulting in
paying less attention to it: “they are not visible anymore,
only if you run into that.”

•

11

systems provide several features that support tech-
nical debt management. Speciﬁcally, issue trackers
can give developers an overview of all documented
technical debt: “it’s a good thing that technical debt is
mostly recorded in the issue tracker because this gives
an overview.” It also supports uploading technical
debt information as attachments, assigning the issue
type, and assigning the issue severity. Finally, its
support keeping track of what has been done about
the technical debt: “I will make an issue, so you can
always see what’s has been done.”
Support planning to resolve technical debt. Interviewees
reported that technical debt documented in issues
will be a part of the future plan and be resolved
eventually. This is because, in addition to developers,
team managers also participate in the management
of SATD in issues: “[as the team lead] once they are in
issues, they are in my list of choosing priorities, that I can
deal with it.”

Finally, the pros and cons of recording technical debt in

commits is presented as below:

• Providing explanation for TD changes. Two intervie-
wees mentioned that commits are important to ex-
plain what TD changes are made to the repository,
such as introducing TD, modifying TD, and repaying
TD: “commit messages should include what has changed
and what has been done, also for changes to technical
debt.”
Limited visibility. Similar to code comments, technical
debt admitted in commits has limited visibility. From
the viewpoint of the team lead, it is not visible to him:
“if they are in comments or commits, they’re not on my
desk.”

•

• Resolving it depends on the initiative of developers. There
is no guarantee that technical debt admitted in com-
mits will be resolved. It depends on the developers
to solve it or leave it. The team lead only manages
technical debt documented in issues: “I don’t manage
technical debt in code comments and commits at all, that’s
really depending on the engineer’s responsibility.”

• Resolving it depends on the initiative of developers. Three
interviewees reported that it highly depends on soft-
ware developers to solve or leave technical debt
admitted in code comments: “you need be lucky that
someone will be working on this to get a solution.” Thus,
documenting technical debt in the source code can
act both as an advantage (if it gets resolved) and a
disadvantage (if it is ignored).

Subsequently, we list the main pros and cons of admit-

ting technical debt in issues:

• Visible to the whole team. Five interviewees mentioned
that technical debt admitted in issues has the advan-
tage of being visible to everyone in the team, helping
developers to keep track of it: “issue tracker is used for
recording important technical debt which is shared in the
team.”
Issue trackers provide features not supported by other arti-
facts. Three interviewees revealed that issue tracking

•

4.6 (RQ2.3) What Are the Triggers to Pay Back or Not
Pay Back SATD?

According to the interview responses, software developers
tend to repay SATD in the following cases:

•

•

SATD is involved in upcoming changes. Based on six
interviews, developers always choose to repay SATD
when changes are going to take place in the same
part of the system. This is because technical debt
could make the changes more difﬁcult: “for instance
the parameterize thingy, if I was doing a change which
actually needs that or in the same area, I would take that
along because that would really help me if I solve it.”
SATD is related to bugs. In another case, two intervie-
wees reported that when they ﬁnd SATD connected
to bugs, they will solve the technical debt: “my expe-
rience is that during the investigation of bugs when we
encounter TD that is causing the bugs, we will pick it
up.”

•

Small SATD that can be solved easily. Based on two in-
terviews, we found that when developers encounter
SATD and think the debt can be paid back easily,
they prefer to solve it straight away: “if there is a small
[technical debt], there is time left in your sprint then you
could pick up such a small item.”

• The same SATD keeps annoying developers. One re-
sponse indicates that when developers encounter a
technical debt item, which is repeatedly of concern
to them, they will take some time to solve it: “if you
hit the same technical debt item and it annoys you enough,
then it will be solved.”

• Certain types of SATD are valued more than others.
Some developers believe that certain types of SATD
are more important than others, and they choose to
repay them with higher priority. More speciﬁcally,
two interviewees stated that they prioritize test debt:
“I would prioritize test debt; that’s critical on the code
quality.” On the other hand, two participants men-
tioned they always give design debt higher priority:
“you also see preferences more to the design debt to
documentation debt.”

•

• Too much SATD in the area. Four participants pointed
out that when too much SATD is accumulated in a
speciﬁc part of the system, it gets to be paid earlier
rather than later: “if there is a lot of technical debt in
those modules, you might want to pick up earlier, cause
if there is some TD there, maybe something wrong in the
design...”
SATD is signiﬁcantly big. Two participants reported
that they choose to repay SATD that is too big to
ignore: “we consider them [technical debt] as important
in the case that they are sufﬁciently big enough to pay
attention to.”
Location of SATD is special. One interview participant
mentioned that SATD in different parts of the project
are treated differently. They always give high priority
to SATD in certain modules: “it is up to the part of the
project if I make a shortcut that should not be in; I am
aware of it and will resolve it.”

•

• Potential risk of SATD is high. According to two inter-
views, when the potential risk of SATD is very high,
SATD should be worked on: “I think you should work
on the most important things, the highest risk things.”
• Have sufﬁcient time. Another interviewee indicates
that when they have sufﬁcient time, they will take
some time to solve SATD: “when do I decide to solve
technical debt apart? when I have time in the program.”
Software craftsmanship. Two interview participants
indicate that some developers have the attitude of
striving to deliver software of high quality: “[if] I
have craftsmanship, I deliver software as the input and
believe the software needs to be correct and needs to be
maintainable.”

•

Meanwhile, in the following cases, SATD is ignored and

left unresolved:

• Repaying SATD brings small beneﬁt. Three intervie-
wees mentioned that if the software works, repaying
SATD yields only a small beneﬁt. Thus, developers

12

tend to not pay back the debt: “if it already works, why
make it better? someone pays for it.”

• Repaying SATD takes too much effort. Four participants
had concerns about the considerable effort required
to pay back SATD: “we don’t want to invest in it, due to
[...] too much effort.”

• Potential risks of paying back SATD. Two interviewees
expressed the concern that it could be risky to re-
pay SATD, as it might break existing functionalities:
“there is some regression risk involved; it should be simple
but sometimes takes a long time to ﬁnish.”

• Certain types of SATD are ignored during repayment. As
one of the participants mentioned: “the one writing
[documentation] typically isn’t the user of
it”; some
developers simply give documentation debt low pri-
ority: “I don’t like writing documentation, so I really
try to postpone writing the document.” Besides, two
participants stated that some developers do not see
test debt as important and choose not to repay it:
“[some] engineers don’t see writing tests really helps them,
because you have implemented something; it runs on a
machine and it works.” Moreover, another interviewee
pointed out that architecture debt is sometimes ig-
nored in the maintenance phase: “architecture debt is
addressed differently than design and test debt because it
more prevents production; architecture debt also depends
on the development phase; if it goes to maintenance phase
from earlier phases of building a new product, we often
keep the debt as long as it doesn’t break functionality.”
Learning effect for the SATD creator. Another intervie-
wee believed that the debt creator should solve it,
to be able to learn from it: “it is important to close
the feedback loop; if others resolve it [technical debt], the
people who created it will never learn from it.”

•

• Careless developers. Lastly, one interview revealed that
irresponsible developers also lead to SATD unsolved:
“some people say we should solve it, and then they don’t
stick to it.”

4.7 (RQ2.4) What Practices Are Used to Support SATD
Management in Industrial Settings?

In the following, we summarize practices used to assist in
SATD management. First, we describe practices that help
prioritize SATD using different criteria:

•

• Custom list. Three interviewees indicated that they
maintain a list of SATD with an order of priority.
Speciﬁcally, they usually put the high priority SATD
on the top of the list for quicker repayment: “[we] try
to prioritize the list, and the most important items are on
the top that needs to be solved ﬁrst.”
Severity level of tickets. Issue tracking systems always
support setting the priority for each issue ticket (e.g.,
block, minor, and trivial) [32]. One interview par-
ticipant mentioned they also use the issue tracker’s
built-in function to set the priority of each issue:
“most items are already categorized with a severity.”
• Type of tickets. Five interviewees mentioned that issue
types have impact on the priorities of issue tickets.
They choose different issue types when creating is-
sues with different priorities. For example, the in-

terviewees considered that bugs have higher priority
than backlog items: “I would say I had a task if it is for
short term, if you intend to solve it within this sprint, if
[...] you create a backlog item, [it could just] disappear, so
it would be better to write the bug then at least you have
a process to handle these.”

• Referencing issue keys. One participant indicated that
when adding a reference to an issue ticket, the SATD
in code comments will get higher priority: “if that
comment references an issue, it will automatically get
more priority.”

Second, we report two common practices to efﬁciently

pay back SATD:

• Grouping related technical debt items. Two participants
indicated they usually group related technical debt
items and investigate them together: “we group them
[technical debt] together; that’s we say, those four or ﬁve
items are in the same area, let’s now take a look at them
together, to be more effective.”

• Grouping technical debt and development tasks. Two
interviews revealed that developers also group tech-
nical debt and development tasks (e.g., ﬁxing bugs,
creating new features, and adding tests). Then they
solve them jointly: “when we take technical debt we also
resolve other things, which is more efﬁcient.”

4.8 (RQ3.1) What Challenges Do Software Practitioners
Face When Managing SATD?

In the following, we summarize challenges for SATD man-
agement:

• Convincing developers not to introduce technical debt,
when not necessary. Three interviewees indicated that
some technical debt can be paid back easily, so it
should not be incurred in the ﬁrst place: “many of
these [comments] seem to be ﬁxed in ﬁve minutes, I think
they shouldn’t write these comments; they do not look like
effort-intensive.”.

• Prioritizing SATD. Five interviewees pointed out that
it is hard to determine priorities of SATD and other
works: “the biggest challenge is setting the priorities [...]
the challenge is always what’s the best to do, a piece of
functionality or technical debt?”

• Getting resources to pay back SATD. Based on two
interviews, we found that getting resources for debt
repayment remains challenging: “to get technical debt
on the agenda is a difﬁcult task [...] there’s always an
argument to not work [on them].”

• Dealing with undocumented technical debt. Three inter-
view participants mentioned the difﬁculty of deal-
ing with undocumented debt: “we struggle with the
ones [technical debt] we are not aware of or somebody
identiﬁed without clearly communicated as being technical
debt.” One interviewee speciﬁed that it is especially
challenging when dealing with technical debt in old
parts of the system without documentation: “what
challenges did you face when dealing with technical debt?
dealing with legacy code in general [...] re-engineering the
code or design sometimes is difﬁcult [...] it could be a lot
of helpful if there is some code documentation.”

13

• No guideline for SATD documentation. Four intervie-
wees pointed out the problem of not having concrete
guidelines for SATD documentation: “we don’t have
any agreements on when you have technical debt and want
to add some comments within the software, then please use
certain tags.”

• No guideline for SATD repayment. Besides, two inter-
viewees report that there is no guideline for repaying
SATD: “there is no complete guideline; if you have to solve
this, then you should do this, this, and this.”

• Dealing with consequences of SATD. Two interviewees
found that it is challenging to deal with an increasing
list of SATD items, as it causes SATD items to be ig-
nored or not to document new technical debt: “some-
times the technical debt items get out of sight because the
list is becoming too long and you forgot about it; I am not
sure how to deal with that growing list of technical debt
items.” Meanwhile, another participant stated the
harmfulness of accumulating technical debt without
proper management: “in another project, it was horrible;
the big redesigns block the whole development, which also
affects the trust of the software.”

4.9 (RQ3.2) What Features Should Tools Have to Effec-
tively Manage SATD?

In the following, we report the tool features that develop-
ers thought useful for SATD management. We categorize
features into four groups: SATD identiﬁcation, SATD trace-
ability, SATD prioritization, and SATD repayment. SATD
identiﬁcation-related features are reported as follows:

• Automated SATD identiﬁcation. Six interviewees men-
tioned that it would be useful to be able to automati-
cally identify SATD from different sources: “I think
[the tool should support] the identiﬁcation of technical
debt, scanning code or issues.” The interviewees sug-
gested the following ways to present the identiﬁed
SATD:

◦

◦

◦

Show the list of identiﬁed SATD. Two interviews
indicated that identiﬁed SATD items should
be listed: “if the tool could make some kind of
printouts of technical debt items in your source
code, then I can imagine that I will sit together
with some engineers, walk through the list, ﬁnd the
most important, and solve them.”
Show the quantity of SATD in the system. One
participant suggested showing the number of
SATD items in the dashboard to increase the
visibility of SATD in code: “this dashboard will
show you how much TODO in our code, so that is
visible for the whole team.”
Show the evolution of SATD quantity over time.
Another participant mentioned that it would
be useful to have a function showing the num-
ber of SATD over time to know when they
introduce more SATD or less SATD: “[the tool
should show] total amount technical debt in the
system evolving during the development of the sys-
tem, [so we can know] do we have more technical
debt in the early phase.”

◦

Show the quantity of SATD in different modules.
As mentioned in Section 4.6, if too much SATD
is accumulated in a part of the system or
in some speciﬁc modules, developers would
give the debt higher priority. Thus, they would
like the tool to show the quantity of SATD in
different modules: “what would you like to see?
[I want to have] some insights into which module
has a lot of technical debt.”

• Automated differentiation between ﬁxed SATD and un-
ﬁxed SATD. As stated in Section 4.4, the identiﬁed
SATD may be either repaid or not. There needs to be
a distinction between them; as one participant stated:
“I am curious only about the open ones [unsolved debt].”
The participants mentioned the following means to
visualize the distinction between solved and un-
solved SATD:

◦

◦

◦

Show the period between SATD introduction and
repayment. One interviewee mentioned that he
wanted to know the repayment time of SATD:
“[the tool should show] how much time is in
between when we decided to introduce technical
debt and when will things be solved.”
Show how long unsolved SATD survives. Another
interviewee indicated that
the tool should
show the survival time of SATD: “[the tool
should show] how long technical debt is there.”
Show the timeline of ﬁxed and not ﬁxed SATD
items. Another interviewee was interested in
the point in time when they decide to either
pay the TD back or not: “[the tool should show]
what is the moment we solve most technical debt?
when do we decide to leave technical debt in the
system and stop working on them?”

Next, SATD traceability-related features are presented:

• Automated tracing between SATD in different sources.
In Section 4.3, we observed some relations between
SATD in different sources. But, some of these rela-
tions (e.g., technical debt admitted in code comments
referenced in issues) are rarely documented. Thus,
some interviewees think it would be very helpful
if the tool could build traces automatically between
SATD in different sources: “linking back and forth
would really help in getting an overview about technical
debt things.”

• Automated tracing between SATD and code. Two par-
ticipants mentioned that it would be useful to know
the location of SATD in the code: “I would like to know
which area of code the technical debt is located at.”

• Automated tracing between SATD and related develop-
ment tasks. As described in Section 4.6, when SATD
is involved in upcoming changes, it is usually prior-
itized. Thus, developers are interested in which to-
do items (e.g., ﬁxing bugs, creating new features, or
adding tests) are related to the SATD: “[the tool should
ﬁnd] related work to it.”

Subsequently, we report the suggested features related

to SATD prioritization:

14

• Automated SATD prioritization. Two interviewees
wanted to automatically prioritize SATD: “I’m looking
to which part of technical debt could be left and which part
of technical debt really needs to pay attention to.”

• Automated identiﬁcation of SATD risk. Three par-
ticipants mentioned that SATD risk identiﬁcation
should be supported by the tool: “I am looking at
[...] what is the pain? do I need to solve it? what are the
consequences [of] not solving it?”

• Automated estimation of beneﬁts to solve SATD. Two
interviewees indicated that estimating the beneﬁts of
solving SATD (e.g. how much technical debt interest
will be saved) could be one of the tool’s functions:
“need to know what the beneﬁt of it [solving SATD], what
is gained by it.”

• Automated estimation of cost to solve SATD. Based on
four interviews, developers mentioned that auto-
mated estimation of SATD repayment cost (also re-
ferred to as the principal of technical debt) is useful:
“the other thing is how much effort does it take to get rid
of this technical debt.”

Finally, there is one feature related to SATD repayment:

• Automated SATD solution suggestion. Two interview
participants asked for the tool to provide some po-
tential solutions (e.g. refactorings) for paying back
SATD: “the other tool could [provide] [...] possible routes
of solution.”

5 DISCUSSION

As mentioned in Section 3, there are signiﬁcant differences
between open-source and industrial projects. It is important
to know these differences in order to understand how to
better manage SATD in the two cases: what works for each
case, what works for both, and what can be reused from one
to the other. Thus, we compare the characteristics of SATD in
industrial and open-source projects. Table 9 summarizes the
percentages of SATD in different sources in industrial and
open-source settings. Speciﬁcally, the data from industrial
projects are obtained from Table 4, while the data from open-
source projects are acquired from our previous study [12].
As can be seen in Table 9, the percentages of technical debt
admitted in industrial and open-source projects are compa-
rable. Interestingly, less technical debt is admitted in code
comments (-2.6%), while more technical debt is admitted
in issues and commits (+3.3% and +1.4%) in the studied
industrial projects compared to the open-source ones. This is
likely related to the practices for SATD management that are
followed in the two types of projects. Within our industrial
partner, we established a preference for documenting SATD
in issues for better tracking. However, we can conclude that
we do not ﬁnd substantial evidence that industrial projects
differ from open source projects when it comes to which
source is preferred for admitting technical debt. Researchers
could further investigate if this is true more generally with
further studies in industry.

Previous work by Bellomo et al. hypothesized that tech-
nical debt issues take a longer time to resolve than non-
technical debt issues [29]. However, they found that the
average open days of issues vary greatly, and the results did

TABLE 9
Comparison Between SATD Percentages in Different Sources in
Industrial and Open-Source Projects.

Source

Comment
Issue
Commit

Percentage of SATD
Industrial Projects Open-Source Projects Difference

2.6%
16.3%
12.7%

5.2%
13.0%
11.3%

-2.6%
3.3%
1.4%

not support their hypothesis. In this paper, we investigate
the same research question in industrial settings (see Sec-
tion 4.1). The results showed in Tables 5 and 6 indicate that
technical debt issues take a longer time to resolve compared
to non-technical debt issues (with statistical signiﬁcance).
This supports the hypothesis proposed by the previous
study [29]. It is noted that our study focuses on SATD in
industrial settings. This hypothesis still needs to be tested
in open-source settings. Moreover, our results show that
certain types of SATD take a signiﬁcantly longer time to
resolve than certain other types of SATD. For example, test
debt issues take a longer time to resolve than code/design
debt issues (p-value is 0.014). The detailed reasons behind
the observations still need to be investigated.

Implication 1: The hypothesis that technical debt issues
take a longer time to resolve than non-technical debt
issues is supported by our study in industrial settings.
Researchers could further examine this hypothesis in
open-source settings and compare the results.

In Section 4.2, we observed that most of the interview
participants acknowledged the automatically-identiﬁed
SATD. Furthermore, we saw that ﬁve out of eight inter-
viewees had different expectations with the percentages
of technical debt admitted in different sources. Most of
them mentioned that they were positively surprised about
the results; as one interviewee mentioned, they were not
well-trained to create issues for found technical debt. We
encourage researchers to study the reasons behind these
differences and develop better practices and processes for
admitting technical debt.

Implication 2: Most of the interviewees acknowledged
the automatically identiﬁed SATD, while more than half
of them had different expectations for the percentages
of SATD in different sources. Researchers could study
the reasons why expectations are not in line with the ob-
servations. Practitioners can also discuss the differences
between their expectations and the data to understand
SATD better and how to improve its documentation.

In Section 4.4 we saw seven distinct cases that cause
technical debt to be ignored and stay undocumented. Such
implicit technical debt can have grave consequences for
the development team. Researchers could look into this
and propose solutions to avoid missing documentation

15

for important technical debt. Moreover, as pointed out in
Section 4.8, there are no concrete guidelines on technical
debt documentation. Thus, we suggest that researchers and
practitioners create comprehensive guidelines and develop
tools to help technical debt documentation in different cases
based on our ﬁndings. Furthermore, the pros and cons of
documenting technical debt in different sources described
in Section 4.5 can also be of assistance in creating the
aforementioned guidelines and tools, by building on the
pros and working to avoid the cons.

Implication 3: Researchers and practitioners could cre-
ate guidelines and build tools to assist in technical debt
documentation in different sources.

In Section 4.3, we observed that it is common for source
code comments or commit messages to reference related
technical debt issues; the reverse is not common. Mean-
while, developers believed it could be very useful if related
SATD is linked together. Thus, we argue that researchers
and practitioners need to study the relations between SATD
in different sources and build tools that aid in establishing
traces between SATD in different sources and properly
visualizing them.

Implication 4: Researchers and practitioners could fur-
ther investigate the relations between SATD in different
sources and build tools to automate and visualize trace-
ability between SATD in different sources.

In Section 4.6, we reported the triggers for paying back
and not paying back SATD. However, some of the triggers
are conﬂicting. For example, some developers saw test debt
as a trigger to repay SATD, while some others believed it
should be ignored. We encourage researchers to evaluate
all the triggers, identify the reasons behind them, and ﬁlter
out improper triggers. This could be helpful for creating
inclusive guidelines and tools for SATD prioritization, based
on those triggers. Moreover, researchers could also study
how to eliminate the effects of SATD accumulation caused
by triggers for not paying back technical debt.

Implication 5: Researchers could investigate triggers
for repaying and not repaying SATD, and create guide-
lines and tools for SATD prioritization based on those
triggers. Besides, strategies to mitigate the effects of
SATD accumulation caused by triggers for not paying
back SATD need to be studied.

In Section 4.7, we reported the practices used to support
SATD prioritization. These practices are not acknowledged
by all the interviewees.; for example, in contrast to the
practice using issue types (e.g., bug, task, and backlog item)
to set priorities of SATD, one participant did not ﬁnd
signiﬁcant differences between issue types. This is due to
the organization not using such issue types in a standard-
ized manner. Researchers should study and propose such
practices for SATD prioritization that can be standardized

across organizations.

Implication 6: Researchers could study and use the
practices to support SATD prioritization by embedding
them in tools or processes.

In Section 4.7, we also report on two strategies for
efﬁciently paying back SATD. We found that adopting such
strategies heavily depend on developers’ personal opinions
and discussions with their colleagues. Researchers could
investigate how much effort (i.e. technical debt interest) is
saved by using these strategies and how to automatically
group SATD and other tasks for higher repayment efﬁciency.

Implication 7: Researchers could investigate the efﬁ-
ciency of SATD repayment strategies and build tools to
help developers utilize these strategies.

In Section 4.8, we list the challenges faced by intervie-
wees when dealing with SATD. We suggest that researchers
examine the impacts of listed challenges, and propose strate-
gies and tools to tackle challenges. Some of the challenges
can be addressed directly within the development team, e.g.
convincing developers not to introduce technical debt when
not necessary. Practitioners could discuss these challenges
in their team and decide which they can tackle and how.

Implication 8: Researchers can evaluate the impact of
challenges, and propose strategies and tools to tackle
them. Practitioners can also review them and discuss
which ones they can address.

In Section 4.9, a serial of tool features is proposed by
interview participants. However, the usefulness of each
feature and the difﬁculties of implementing each feature are
different. We recommend that researchers and practitioners
evaluate the added value of each proposed feature, imple-
ment tools including most important features, and test the
effectiveness of such tools.

Implication 9: Researchers and practitioners could eval-
uate the feasibility of proposed tool features, implement
the most signiﬁcant features, and assess their effective-
ness.

6 THREATS TO VALIDITY
6.1 Construct validity

Threats to construct validity concern the correctness of oper-
ational measures for the studied subjects. One of the threats
to construct validity in the study concerns the potentially
different interpretations of discussed topics between inter-
viewees and researchers. Because we focus on SATD in this
study and most of the interviewees were not familiar with
this concept, we tried to avoid the misunderstanding of this
term by 1) explaining the basic concept of technical debt;
2) asking them to give some examples of it to make sure

16

they have the correct comprehension; 3) reminding them,
during the interviews, that we focus on technical debt that
is documented in different sources to avoid confusion.

Another threat to construct validity is related to the pos-
sible reluctance of interviewees to express negative opinions
on their organization or admit mistakes made in the past. To
minimize this threat, we emphasized that we are bound by
a conﬁdentiality agreement, and no sensitive or personal
information would be revealed after the interviews.

6.2 Reliability

Reliability is concerned with the bias that researchers may
induce in data collection and analysis. One threat to reli-
ability could be different results obtained from work ar-
tifacts’ analysis. Speciﬁcally, when extracting source code
comments from studied projects, because the projects could
use multiple programming languages, deﬁning and using
simple heuristic rules might not be able to extract all com-
ments from different programming languages. To reliably
and accurately extract code comments, instead of deﬁning
such heuristic rules ourselves, we chose to use a third-party
library (CommnetParser), which supports multiple program-
ming languages, such as C++, Go, Python, Java, and Ruby.
Another threat to reliability could be the impact of re-
searchers’ opinions on interviewees. To mitigate this threat,
all authors followed a speciﬁc protocol for the interviews
which is included in the replication package3. Besides, at
least two authors attended each interview, to ensure that
one interviewer did not bias the questions asked.

The last threat to reliability comes from analyzing the
interview data. To minimize this threat, the ﬁrst and sec-
ond authors carried out the Constant Comparative analysis
process [25], [26] independently; in case of discrepancy, we
compared and discussed the results until we were able to
reach an agreement.

6.3 External validity

Threats to external validity concern the generalizability of
the results. In this study, we analyzed work artifacts and
conducted interviews in a large software company in the
embedded systems industry. Thus, our ﬁndings may be
generalized to other industrial projects of this application
domain and of similar size and complexity. We can not claim
any further generalization.

7 CONCLUSION
In this paper, we analyzed SATD in industrial projects
using machine learning techniques and conducted 12 inter-
views to understand: 1) characteristics of SATD in industrial
projects; 2) developers’ attitudes towards identiﬁed SATD
and statistics; 3) triggers to introduce and repay SATD; 4)
relations between SATD in source code comments, issues,
and commits; 5) practices used to manage SATD; 6) chal-
lenges and tooling ideas for SATD management.

The results present characteristics of SATD in indus-
trial projects and shed light on developers’ opinions on
SATD management and tooling support. This promotes
future studies in this area, targeting to support developers
in terms of SATD introduction, traceability, prioritization,
repayment, and tool support.

17

[22] T. C. Lethbridge, S. E. Sim, and J. Singer, “Studying software
engineers: Data collection techniques for software ﬁeld studies,”
Empirical software engineering, vol. 10, no. 3, pp. 311–341, 2005.
[23] M. DeJonckheere and L. M. Vaughn, “Semistructured interviewing
in primary care research: a balance of relationship and rigour,”
Family Medicine and Community Health, vol. 7, no. 2, 2019.

[24] I. Seidman, Interviewing as qualitative research: A guide for researchers

in education and the social sciences. Teachers college press, 2006.

[25] A. Strauss and J. Corbin, Basics of qualitative research.

Sage

publications, 1990.

[26] K.-J. Stol, P. Ralph, and B. Fitzgerald, “Grounded theory in soft-
ware engineering research: a critical review and guidelines,” in
Proceedings of the 38th International Conference on Software Engineer-
ing, 2016, pp. 120–131.

[27] H. B. Mann and D. R. Whitney, “On a test of whether one of two
random variables is stochastically larger than the other,” The annals
of mathematical statistics, pp. 50–60, 1947.

[28] R. J. Grissom and J. J. Kim, Effect sizes for research: A broad practical

approach. Lawrence Erlbaum Associates Publishers, 2005.

[29] S. Bellomo, R. L. Nord, I. Ozkaya, and M. Popeck, “Got technical
debt? surfacing elusive technical debt in issue trackers,” in 2016
IEEE/ACM 13th Working Conference on Mining Software Repositories
(MSR).

IEEE, 2016, pp. 327–338.

[30] Atlassian Corporation Plc, “What are issue types?” [Online]. Avail-
https://support.atlassian.com/jira-cloud-administration/

able:
docs/what-are-issue-types/

Corporation,
boards

[31] Microsoft

“Deﬁne

features

and

azure
portfolio

organize
[Online].

to
backlogs.”

in
and
//docs.microsoft.com/en-us/azure/devops/boards/backlogs/
deﬁne-features-epics?view=azure-devops&tabs=scrum-process/
“Deﬁning priority ﬁeld val-
[Online]. Available: https://conﬂuence.atlassian.com/

ues.”
adminjiraserver/deﬁning-priority-ﬁeld-values-938847101/

your
Available:

[32] Atlassian Corporation Plc,

epics
product
https:

REFERENCES

[1] P. Avgeriou, P. Kruchten, I. Ozkaya, and C. Seaman, “Manag-
ing Technical Debt in Software Engineering (Dagstuhl Seminar
16162),” Dagstuhl Reports, vol. 6, no. 4, pp. 110–138, 2016.

[2] A. Potdar and E. Shihab, “An exploratory study on self-admitted
technical debt,” in 2014 IEEE International Conference on Software
Maintenance and Evolution.

IEEE, 2014, pp. 91–100.

[3] K. Dai and P. Kruchten, “Detecting technical debt through issue

trackers.” in QuASoQ@ APSEC, 2017, pp. 59–65.

[4] Y. Li, M. Soliman, and P. Avgeriou, “Identiﬁcation and Reme-
diation of Self-Admitted Technical Debt in Issue Trackers,” Pro-
ceedings - 46th Euromicro Conference on Software Engineering and
Advanced Applications, SEAA 2020, pp. 495–503, 2020.

[5] F. Zampetti, G. Fucci, A. Serebrenik, and M. Di Penta, “Self-
admitted technical debt practices: a comparison between industry
and open-source,” Empirical Software Engineering, vol. 26, no. 6, pp.
1–32, 2021.

[6] E. da Silva Maldonado, E. Shihab, and N. Tsantalis, “Using natural
language processing to automatically detect self-admitted techni-
cal debt,” IEEE Transactions on Software Engineering, vol. 43, no. 11,
pp. 1044–1062, 2017.

[7] X. Ren, Z. Xing, X. Xia, D. Lo, X. Wang, and J. Grundy, “Neural
network-based detection of self-admitted technical debt: From
performance to explainability,” ACM Transactions on Software Engi-
neering and Methodology (TOSEM), vol. 28, no. 3, pp. 1–45, 2019.

[8] Y. Kamei, E. d. S. Maldonado, E. Shihab, and N. Ubayashi, “Using
analytics to quantify interest of self-admitted technical debt.” in
QuASoQ/TDA@ APSEC, 2016, pp. 68–71.
S. Mensah, J. Keung, J. Svajlenko, K. E. Bennin, and Q. Mi, “On
the value of a prioritization scheme for resolving self-admitted
technical debt,” Journal of Systems and Software, vol. 135, pp. 37–54,
2018.

[9]

[10] E. d. S. Maldonado, R. Abdalkareem, E. Shihab, and A. Serebrenik,
“An empirical study on the removal of self-admitted technical
debt,” in 2017 IEEE International Conference on Software Maintenance
and Evolution (ICSME).

IEEE, 2017, pp. 238–248.

[11] F. Zampetti, A. Serebrenik, and M. Di Penta, “Was self-admitted
technical debt removal a real removal? an in-depth perspective,”
in 2018 IEEE/ACM 15th International Conference on Mining Software
Repositories (MSR).
IEEE, 2018, pp. 526–536.

[12] Y. Li, M. Soliman, and P. Avgeriou, “Automatic identiﬁcation of

self-admitted technical debt from different sources,” 2022.

[13] E. d. S. Maldonado and E. Shihab, “Detecting and quantifying
different types of self-admitted technical debt,” in 2015 IEEE 7th
International Workshop on Managing Technical Debt (MTD).
IEEE,
2015, pp. 9–15.

[14] Q. Huang, E. Shihab, X. Xia, D. Lo, and S. Li, “Identifying self-
admitted technical debt in open source projects using text min-
ing,” Empirical Software Engineering, vol. 23, no. 1, pp. 418–451,
2018.

[15] X. Wang, J. Liu, L. Li, X. Chen, X. Liu, and H. Wu, “Detecting
and explaining self-admitted technical debts with attention-based
neural networks,” in Proceedings of the 35th IEEE/ACM International
Conference on Automated Software Engineering, 2020, pp. 871–882.

[16] Y. Li, M. Soliman, and P. Avgeriou, “Identifying self-admitted
technical debt in issue tracking systems using machine learning,”
2022.

[17] R. van Solingen, V. Basili, G. Caldiera, and H. D. Rombach, “Goal
Question Metric (GQM) approach,” in Encyclopedia of Software Eng.
Hoboken, NJ, USA: John Wiley & Sons, Inc., jan 2002, pp. 528–532.
[18] A. Yamashita, M. Zanoni, F. A. Fontana, and B. Walter, “Inter-smell
relations in industrial and open source systems: A replication
and comparative analysis,” in 2015 IEEE International conference
on software maintenance and evolution (ICSME).
IEEE, 2015, pp.
121–130.

[19] A. Bosu, J. C. Carver, C. Bird, J. Orbeck, and C. Chockley, “Pro-
cess aspects and social dynamics of contemporary code review:
Insights from open source development and industrial practice at
microsoft,” IEEE Transactions on Software Engineering, vol. 43, no. 1,
pp. 56–75, 2016.

[20] G. Sierra, E. Shihab, and Y. Kamei, “A survey of self-admitted
technical debt,” Journal of Systems and Software, vol. 152, pp. 70
– 82, 2019. [Online]. Available: http://www.sciencedirect.com/
science/article/pii/S0164121219300457

[21] P. Runeson, M. Host, A. Rainer, and B. Regnell, Case study research
John Wiley & Sons,

in software engineering: Guidelines and examples.
2012.

