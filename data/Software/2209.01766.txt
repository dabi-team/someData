1

2
2
0
2

p
e
S
5

]
E
S
.
s
c
[

1
v
6
6
7
1
0
.
9
0
2
2
:
v
i
X
r
a

Exploring the Verifiability of Code Generated by GitHub
Copilot

DAKOTA WONG, University of Waterloo, Canada
AUSTIN KOTHIG, University of Waterloo, Canada
PATRICK LAM, University of Waterloo, Canada

GitHub‚Äôs Copilot generates code quickly. We investigate whether it generates good code. Our approach is to
identify a set of problems, ask Copilot to generate solutions, and attempt to formally verify these solutions
with Dafny. Our formal veriÔ¨Åcation is with respect to hand-crafted speciÔ¨Åcations. We have carried out this
process on 6 problems and succeeded in formally verifying 4 of the created solutions. We found evidence
which corroborates the current consensus in the literature: Copilot is a powerful tool; however, it should not
be ‚ÄúÔ¨Çying the plane" by itself.
CCS Concepts: ‚Ä¢ Software and its engineering ‚Üí General programming languages; ‚Ä¢ Social and pro-
fessional topics ‚Üí History of programming languages;

Additional Key Words and Phrases: GitHub Copilot, Program Synthesis, Software VeriÔ¨Åcation.

ACM Reference Format:
Dakota Wong, Austin Kothig, and Patrick Lam. 2022. Exploring the VeriÔ¨Åability of Code Generated by GitHub
Copilot. Proc. ACM Program. Lang. 1, HATRA, Article 1 (December 2022), 9 pages.

1 INTRODUCTION

In aviation, commercial airplanes have two yokes (controls) which allows for sharing of respon-
sibilities and workload between a primary pilot and a copilot. Both operators are fully trained,
informed, and capable of Ô¨Çying the aircraft; however, only one of them needs to be controlling the
aircraft at any one moment. In software development, traditionally, code is written by an individ-
ual. In team environments, this code is typically scrutinized and assessed by a number of people,
but originally it had to be developed by an individual. Similar to a pilot, software developers are
ordinarily well trained, informed, and capable of programming; however, ineÔ¨Écient or incorrect
code segments can potentially slip between the cracks and into code-bases when a developer does
not fully understand their tools, the domain, or the required program speciÔ¨Åcations.

GitHub, with the use of OpenAI‚Äôs Codex [Chen et al. 2021], has released an ‚ÄúAI pair program-
mer‚Äù to assist in software development [GitHub 2022]. This programming partner is aptly named
Copilot. The aim of this tool is to shift the programmer‚Äôs time and attention away from boiler-
plate and repetitive code patterns, and toward the critical design of the system. Copilot works by
providing implementation suggestions based on natural language descriptions of the required code.
Copilot is currently capable of generating code in eleven programming languages, including C,
C++, C#, Go, Java, JavaScript, PHP, Python, Ruby, Scala, and TypeScript1.

The community is struggling to understand what Copilot can and can‚Äôt do, and proofs are a good
indicator of where Copilot might stand in terms of generating correct code. Thus, in this work,
we explore the veriÔ¨Åability of Copilot‚Äôs generated code with respect to the software veriÔ¨Åcation
language Dafny [Leino 2010], and discuss our Ô¨Åndings about the veriÔ¨Åability of the generated code.

1https://docs.github.com/en/copilot/overview-of-github-copilot/about-github-copilot

Authors‚Äô addresses: Dakota Wong, University of Waterloo, Canada, d82wong@uwaterloo.ca; Austin Kothig, University of
Waterloo, Canada, akothig@uwaterloo.ca; Patrick Lam, University of Waterloo, Canada, patrick.lam@uwaterloo.ca.

2022. 2475-1421/2022/12-ART1 $15.00
https://doi.org/

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

 
 
 
 
 
 
1:2

Dakota Wong, Austin Kothig, and Patrick Lam

2 RELATED WORK
There has been a great deal of scrutiny of Copilot and of the code it produces. Early studies which
aim to empirically evaluate Copilot [Nguyen and Nadi 2022] have found that while this early ver-
sion of the model is not perfect, its current results are impressive. In their work, Nguyen and Nadi
tested Copilot against 33 LeetCode2 questions (4 from the easy category, 17 from the medium
category, and 12 from the hard category) using four programming languages (Python, JavaScript,
Java, C), ran the generated code against the LeetCode test cases, and examined the percentage of
passing cases. Java performed best, being able to solve all test cases for 19 of the 33 problems. The
authors found that, often, the code that Copilot generated could be simpliÔ¨Åed, and that sometimes
the generated code would require methods or packages that have not been deÔ¨Åned or declared.

Copilot generates code diÔ¨Äerently from traditional genetic programming paradigms. Sobania et al.

[2022] found that Copilot could generate correct solutions to a variety of problems, with compa-
rable accuracy to genetic programming. The improvement that Copilot makes over traditional
approaches is that it was trained on a 159 GB dataset of unlabelled data, whereas genetic pro-
gramming requires the dataset to be rigorously labeled. Thus, Sobania et al. claimed that the code
Copilot generates is often easier to read and understand compared to that generated by genetic
programming.

It is clear from the current research that Copilot is not a magic wand solution to problems in
software engineering. With its Ô¨Çaws, how are developers able to beneÔ¨Åt from this tool eÔ¨Äectively?
Dakhel et al. [2022] compared Copilot‚Äôs proposed solutions against human programmers on a set
of fundamental problems. The authors found that Copilot was unable to understand certain limita-
tions embedded in the problem description, and while understanding the fundamentals of what is
being requested, it can sometimes create errors when it does not understand. They conclude that
while the generated code from Copilot is not a perfect solution, it can still be incorporated and
modiÔ¨Åed into a project for faster early-stage prototyping.

3 METHODOLOGY
Our goal is to apply veriÔ¨Åcation techniques to code generated by GitHub Copilot. We came up with
sample problems and tasked Copilot with generating solutions in Python. We then used Dafny to
verify that Copilot‚Äôs generated code satisÔ¨Åes the requirements.

More speciÔ¨Åcally, our methodology is as follows. First, we chose 6 problems to give to Copilot
(Ô¨Åve that we chose ourselves and one from Nguyen and Nadi [2022]). We wanted to test whether
Copilot could generate a function which would solve the problems; by ‚Äúsolve‚Äù, we mean that the
generated code satisÔ¨Åes the problem‚Äôs formal speciÔ¨Åcations. Thus, we wrote formal speciÔ¨Åcations
in Dafny for each problem, consisting of requires and ensures statements.

Having deÔ¨Åned the problems, we then asked Copilot to generate solutions in Python. To give
Copilot the best chance of generating a good solution, we gave it a full function signature, includ-
ing a descriptive function name, parameter name(s), parameter type(s), and an output type. With
this input, Copilot then generated the function implementation. Since our goal was to test the
capabilities of Copilot, we always chose the Ô¨Årst suggested function.

Next, we carefully translated each Copilot implementation from Python to Dafny and added the
speciÔ¨Åcations that we had created. We took care to preserve the behaviour of the implementation.
In all cases, the implementations contained a loop of some type. Hence, the provided requires
and ensures statements were inadequate to generate a proof that veriÔ¨Åed the implementation. We
thus attempted to manually derive loop invariants so that Dafny could verify the implementation.

2https://leetcode.com/

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

Exploring the Verifiability of Code Generated by GitHub Copilot

1:3

During the veriÔ¨Åcation process, we added extra requires and ensures clauses, if they were needed
to verify the program, along with additional helper functions and methods when necessary.

4 RESULTS

We have attempted to verify 6 Copilot implementations, one of which intersects the LeetCode
problems in [Nguyen and Nadi 2022]. Table 1 summarizes the algorithms, implementations, and
veriÔ¨Åcation attempts. Incidentally, during testing, consistent with Nguyen and Nadi [2022], we
found that Copilot would periodically include packages or methods that had not been deÔ¨Åned; it
happened to not do so for any of the implementations we describe here.

We have archived the current version of the Copilot-generated implementations and our Dafny

code at https://zenodo.org/record/7040924.

Table 1. Algorithm implementations generated by Copilot. Dafny verification attempt statistics.

Algorithm
Name
Binary Search (4.1)
Two Sums (4.2)
Largest Sum
Sort Array
Prime Factors (4.3)
Max Heapify (4.4)

Python VeriÔ¨Åcation VeriÔ¨Åed SpeciÔ¨Åcation # Invariants

LOC DiÔ¨Éculty

12 Easy
5 Medium
10 Medium
6 Medium
12 Hard
14 Hard

X
X
X
X

LOC
5
6
2
4
3
4

3
7
3
11
> 23
> 4

Figure 1 presents the Copilot prompts that we used to generate implementations.

def binary_search(arr: list, target: int) -> int:
def twoSum(self, nums, target): // LeetCode; types on omitted subsequent lines
def largest_sum(nums: list) -> int:
def sortArray(arr: list) -> list:
def primeFactors(val: int) -> list:
def maxHeapify(arr: list) -> list:

Fig. 1. Copilot prompts for our algorithms.

We were able to create a valid proof in Dafny for 4 of the 6 solutions generated by Copilot; we

next discuss 2 of the valid proofs and our 2 failed attempts.

4.1 Binary Search
‚ÄúBinary Search‚Äù is an algorithm which searches a sorted array for the index of a target element.
The algorithm is appealing as it has a worst-case linear time complexity ùëÇ (ùëõ). Implementations
are recognizable and simple to understand, making this algorithm a good candidate for our Ô¨Årst
veriÔ¨Åcation example.

This example was inspired by a Dafny guide written by Arie GurÔ¨Ånkel3. Our Ô¨Årst observation
was that Copilot‚Äôs implementation of Binary Search is diÔ¨Äerent from that in the Dafny guide,
leading to a diÔ¨Äerent veriÔ¨Åcation process.

We constructed formal speciÔ¨Åcations for binary search. As input, the implementation will take
an array of distinct sorted integers and an integer target. It should then search the array for the

3https://ece.uwaterloo.ca/~agurÔ¨Ånk/stqam/rise4fun-Dafny

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

1:4

Dakota Wong, Austin Kothig, and Patrick Lam

target, returning the index of the target if found. If the target is not found, the program should
have a return value (r.v) of ‚àí1. These speciÔ¨Åcations can be expressed as:

requires Sorted(ùëéùëüùëü )
requires Distinct(ùëéùëüùëü )
ensures

ùëü .ùë£ ‚â† ‚àí1 =‚áí found(ùëéùëüùëü , ùë°ùëéùëüùëîùëíùë°, ùëü .ùë£)
ùëü .ùë£ = ‚àí1 =‚áí not_found(ùëéùëüùëü , ùë°ùëéùëüùëîùëíùë°)

ensures

In the speciÔ¨Åcations above, Sorted, Distinct, found, and not_found are all predicates. Sorted checks
whether an array is sorted in ascending order and Distinct checks whether all elements of an array
are distinct. We require that valid inputs satisfy these predicates. Next, we have the predicate found,
which checks to see if the target was found at the index returned by the algorithm. This predicate
should be true when the returned index is not ‚àí1. To handle the case where the target is not found,
we have predicate not_found that checks that the target does not exist in the array. This predicate
is implied to be true when the return value is ‚àí1.

In parallel with manually producing speciÔ¨Åcations, we used Copilot to generate an implemen-

tation, given the following signature:

1

def binary_search ( arr : list , target : int ) -> int :

We accepted the Ô¨Årst suggested implementation by Copilot based on the provided input:

def binary_search ( arr : list , target : int ) -> int :

low = 0
high = len ( arr ) - 1
while low <= high :

mid = ( low + high ) / / 2
if arr [ mid ] = = target :

return mid

elif arr [ mid ] < target :

low = mid + 1

else :

high = mid - 1

return -1

1
2
3
4
5
6
7
8
9
10
11
12

As stated above, we manually translated the implementation to Dafny, and added the formal
speciÔ¨Åcations that we came up with. This also involved deÔ¨Åning the predicates Sorted and Distinct.
Given a speciÔ¨Åcation and implementation, we could start veriÔ¨Åcation.

However, Dafny also requires loop invariants. To provide them, we needed to (manually) reason
about what happens in the implementation‚Äôs while loop. From our familiarity with binary search,
we know that it uses two indices, high and low. High starts at the last element of the array; low
starts at the Ô¨Årst. In each iteration, the indices move closer together, closing the window of ele-
ments where the target can exist. In particular, we know that the target cannot exist at indices less
than or equal to that of the low pointer or at indices greater than equal to that of the high pointer.
This logic was to implement the primarily loop invariant of the algorithm. In Ô¨Årst-order logic,

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

Exploring the Verifiability of Code Generated by GitHub Copilot

1:5

‚àÄùëñ ¬∑ 0 ‚â§ ùëñ ‚â§ low ‚àß high ‚â§ ùëñ < arr.Length =‚áí arr[ùëñ] ‚â† target.

With the loop invariants, Dafny was able to verify the implementation. So, in this case, Copilot
was able to successfully generate an implementation which satisÔ¨Åed our formal speciÔ¨Åcations for
binary search. This implementation could be veriÔ¨Åed without adding any extra requires or ensures
statements beyond what we had initially identiÔ¨Åed as the speciÔ¨Åcation.

4.2 Two Sums

We next picked a problem from LeetCode that was used in the study by Nguyen and Nadi [2022].
‚ÄúTwo sums‚Äù takes an array of integers and an integer target, and returns two distinct indices in
the array where the elements at those indices sum to the target. The Copilot input was:

1
2
3
4
5
6

def twoSum ( self , nums , target ) :

"""
: type nums : List [ int ]
: type target : int
: rtype : List [ int ]
"""

The solution that Copilot generated passed all of the LeetCode test cases. LeetCode provides a
number of constraints on the inputs‚Äînotably that a valid answer always exists. We used the con-
straints to formulate the following requires and ensures clauses:

requires 2 ‚â§ nums.Length
requires ‚àÉùëñ, ùëó ¬∑ (0 ‚â§ ùëñ < ùëó < nums.Length ‚àß nums[ùëñ] + nums[ ùëó ] == target)
ensures

index1 ‚â† index2
0 ‚â§ index1 < nums.Length
0 ‚â§ index2 < nums.Length
nums[index1] + nums[index2] == target

ensures
ensures

ensures

We converted the Python to Dafny and, with moderate eÔ¨Äort, we then managed to write invari-
ants that enabled Dafny to verify the generated solution. The 5 lines of Python cost resulted in 8
lines of Dafny. We added 7 invariants (3 in the outer loop and 4 in the inner loop) to enable the
veriÔ¨Åcation.

Hence, in this case, Copilot generated a solution that passes the LeetCode test cases and that we

managed to verify.

4.3 Prime Factors

‚ÄúPrime Factors‚Äù is an algorithm that takes an integer and returns a list of prime numbers, which,
when multiplied together, reproduce the original number. For example, the number 18 decomposes
into the list [2, 3, 3]. The algorithm is ùëÇ (ùëõ), but does contain a nested loop.

We formally speciÔ¨Åed this algorithm; it accepts an integer greater than or equal to 2, and returns

a list of prime factors of the integer. Our (arithmetic-heavy) speciÔ¨Åcations were:

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

1:6

Dakota Wong, Austin Kothig, and Patrick Lam

requires val ‚â• 2

len(arr)

ensures

arr[i] == val

i=0
√ñ

With these simple formal speciÔ¨Åcations deÔ¨Åned, we were ready to prompt Copilot to generate

our algorithm. We provided Copilot with the following function signature:

1

def primeFactors ( val : int ) - > list :

which prompted Copilot to suggest the following Python implementation:

1
2
3
4
5
6
7
8
9
10
11
12

def primeFactors ( val : int ) - > list :

factors = []
while val % 2 = = 0:

factors . append (2)
val = val / / 2

for i in range (3 , int ( val * * 0.5) + 1 , 2) :

while val % i == 0:

factors . append ( i )
val = val // i

if val > 2:

factors . append ( val )

return factors

To convert to Dafny: 1) As with previous implementations, we adapted Python for loops into
while loops. 2) We had to implement integer square root in Dafny. Verifying integer square root
is nontrivial; however, we found a veriÔ¨Åed implementation4 which we used as a library. 3) We had
to choose a Dafny data structure equivalent to a dynamic array.

For dynamic arrays (the Python equivalent of list), we used the Dafny seq<int> (sequence of
integers), as it had a built in concatenate method which acts by adding to sequences to produce
a new sequence which can be assigned. However, initialization was a challenge: Dafny does not
permit empty sequences. We thus initialized our sequence with multiplicative unit 1; though this
is not identical to the Python solution, it is reasonably equivalent.

We also created a function for multiplying the elements of the sequence, adding invariants to

check that the current product times the remaining value produces the original value.

Using our chosen invariants, we encountered Dafny timeout issues and failed to verify the im-
plementation. As a last resort, to try to help the proof resolve with ‚Äúwhat we know to be true", we
added lemmas which assumed false, allowing us to say two speciÔ¨Åc ensures clauses were true:

4https://homepage.cs.uiowa.edu/~tinelli/classes/181/Spring11/Tools/Dafny/Examples/square-root.dfy

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

Exploring the Verifiability of Code Generated by GitHub Copilot

1:7

ensures

len(arr)

¬∑ ùë£ == val

arr[i]
!
len(arr)

i=0
√ñ

ensures (ùë£ == 1) =‚áí

arr[i]
!

== val

i=0
√ñ

before and after each append of a new value to the list of factors. Even assuming these two clauses
to be true, the Dafny solver continued to hit the time limit for Ô¨Ånding a proof. Thus, although we
believe that Copilot generated a correct implementation, we have not yet been able to verify it.

4.4 Max Heapify

‚ÄúMax Heapify‚Äù is an algorithm for turning an array into a max-heap data structure. The array is
conceptually a complete binary tree, where each index holds the value of a particular node, and
that node‚Äôs left and right children‚Äôs indices are found using the following mapping:

left_child = (index ‚àó 2) + 1
right_child = (index ‚àó 2) + 2.

A max-heap satisÔ¨Åes the property that each node is greater than or equal to its left and right child.
Since this property is recursive, it implies that any particular node is (transitively) larger than
every node in both its right and left children, so the largest element in the tree should be at the
root.

With this in mind, we wrote formal speciÔ¨Åcations:

requires arr is a list of distinct integers
ensures ‚àÄùë• ¬∑ (0 ‚â§ ùë• < len(arr)) =‚áí

(((2ùë• + 1 < len(arr)) =‚áí (arr[ùë•] ‚â• a[2ùë• + 1])) ‚àß
((2ùë• + 2 < len(arr)) =‚áí (arr[ùë•] ‚â• a[2ùë• + 2]))).

That is, the input array‚Äôs values are unique; and the resulting list has the properties of a max-heap.
Simultaneously, we provided the following function signature to Copilot:

1

def maxHeapify ( arr : list ) - > list :

Copilot produced a 14-line Python implementation, which we translated into Dafny and at-
tempted to verify. We designed a predicate based on the ensures clause, which checks that each
node is greater than or equal to the node at its childrens‚Äô indices, if those indices are not out of
bounds for the array.

We noticed that the Copilot implementation diÔ¨Äers from more traditional implementations by
sifting down rather than sifting up: the recursive call to maxHeapify is given the entire (mutated)
array. Often, implementations of max-heap traverse all non-leaf nodes backwards to the root and
sift-up (with a recursive call) starting at any nodes that are out of place.

Prior to formal Dafny veriÔ¨Åcation, we tested the the generated algorithm on a series of random
inputs to ensure it produced a max-heap each time. Inspecting the algorithm with Python debug-
ging tools showed that the trace-tree for this implementation goes quite deep. The implementation
appears to make recursive calls, starting from the root, enough times to ensure that eventually the

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

 
 
1:8

Dakota Wong, Austin Kothig, and Patrick Lam

max-heap property holds. This would make Ô¨Ånding a veriÔ¨Åable proof diÔ¨Écult. Instead of the stan-
dard heapify algorithm running in ùëÇ (ùëõ ùëôùëúùëî ùëõ), the version Copilot generated for us appears to run
in time ùëÇ (ùëõ2).

We tried a number of diÔ¨Äerent invariants to show that the array was partially heapiÔ¨Åed for each
step in the loop. However, we were unable to prove termination of the loop to begin with. For this
reason, we were unable to formally verify the generated algorithm.

5 DISCUSSION

Copilot is undoubtedly good at generating code. In this work, we took a formal veriÔ¨Åcation ap-
proach to investigating the code that Copilot generates, using Dafny. Of the 6 examples we tried,
we managed to verify the 4 simpler problems. One of the problems appeared in [Nguyen and Nadi
2022], which used LeetCode test suites to establish correctness of Copilot-generated code.

Our work produced corroborating evidence that Copilot‚Äôs generated code might be dubious. It
also explored the diÔ¨Éculty of using Dafny to verify implementations; although Dafny is powerful,
it can be nontrivial to verify implementations using it.

We believe that our work reinforces the fact that to eÔ¨Äectively deploy Copilot, one should know
what is needed. Similar to the work by Dakhel et al. [2022], we found that Copilot appears to skip
over certain constraints imposed on the input space. As a speciÔ¨Åc example, the ‚Äútwo sums‚Äù example
assumes that a solution exists; we had to manually record that assumption in our speciÔ¨Åcation.
Humans are not good at reasoning about edge cases [Wheeler 2021], and Copilot reproduces that
bias. Thus, to productively use Copilot, it remains incredibly important to reason carefully about
what the problem speciÔ¨Åcations should be.

We also found that verifying the generated software with Dafny was somewhat diÔ¨Écult, both
due to Dafny implementation language limitations, and‚Äîmore importantly‚ÄîveriÔ¨Åability reasons.
Some Python idioms do not translate cleanly to Dafny; we had to reformulate Python generator
objects (e.g., range in a for loop) as while loops. Other Python data types such as list don‚Äôt have
an obvious substitution in Dafny. Dafny also omits math operations such as Ô¨Çoor and square root,
which Copilot generated in its Python solutions.

In the LeetCode study [Nguyen and Nadi 2022], not all of the Copilot-generated solutions passed
the LeetCode test cases. In this work, we did not attempt to verify any solutions that failed their
test cases. Of course, we expect such solutions to be unveriÔ¨Åable. However, attempting veriÔ¨Åcation
could provide another way to understand how the solutions are incorrect, beyond simply inspect-
ing the generated code. As is true of veriÔ¨Åcation in general, an attempted veriÔ¨Åcation can provide
insight into the code, complementing a test-based lens.

We believe that algorithms designed with veriÔ¨Åability in mind are more likely to be easier to
prove. A proof of correctness of binary search halves the search space at each step. If an imple-
mentation follows suit, we can focus on solving a subset of the problem in its proof. In reasoning
about a sorting algorithm, we would like to be able to show that each step of a loop results in the
array being partially sorted.

When we were choosing algorithms to verify, we thought that max-heap would be simple, as it
has very clear sub-problems which, when solved, result in a well-deÔ¨Åned data structure. However,
the Copilot-generated implementation does not obviously reduce to sub-problems. We believe that
an iterative version of the max-heap algorithm which walks backwards through the tree would
have been easier to verify than the recursive version which Copilot generated for us.

Of course, we have not established that proving the generated max-heap implementation is
impossible. Per Leino [2010], Dafny veriÔ¨Åcation often requires an expert, and it is not an easy
task for the average programmer. Leino and W√ºstholz [2014] have also identiÔ¨Åed that, for some
problems, the solver timing out can be a barrier to veriÔ¨Åability. There are some shortcuts which

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

Exploring the Verifiability of Code Generated by GitHub Copilot

1:9

can be taken in the proof to avoid timing out; however, these shortcuts require a great amount of
practice to identify. Max-heapify has been formally veriÔ¨Åed [Tafat and March√© 2011] using other
software veriÔ¨Åcation techniques, but the proof and its description are both reasonably lengthy.

Our Python-mediated translation process meant that we avoided Dafny‚Äôs treatment of programs
with pointers and pointer arithmetic. Because we asked Copilot for Python implementations, and
these implementations do not include pointer and memory management, we could not explore
how Dafny can be used to verify functional correctness for pointer-based programs [Leino 2010].

Concluding thoughts. In our experience, Copilot is a powerful tool for quickly producing (pro-
totype) implementations: it can generate code faster than one could possibly write it. However,
Copilot is certainly not a magic wand. A programmer using Copilot would be well advised to not
only look at what Copilot has produced, but also ensure it is correct and appropriate for the in-
tended use case. If not with formal veriÔ¨Åcation, one ought to at least rigorously vet the generated
code with a test suite, prior to integrating it into any system. One should also consider copyright
issues [Howard 2021]. Of course, in principle, one should vet any code before integrating into a
system, whether human produced or machine produced.

We observed that Copilot was quite capable when generating solutions to well known or es-
tablished problems, likely related to the fact that Copilot‚Äôs training data came from user data on
GitHub. Like Dakhel et al. [2022], we found that Copilot generated sub-optimal and possibly in-
correct solutions to some of our problems, e.g., Max Heapify. Due to how Copilot is trained, we
do not believe that it would work as well on esoteric problems; it would be interesting to explore
that point.

REFERENCES
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri
Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating large language models trained on code. arXiv preprint
arXiv:2107.03374 (2021).

Arghavan Moradi Dakhel, Vahid Majdinasab, Amin Nikanjam, Foutse Khomh, Michel C Desmarais, Zhen Ming, et al. 2022.

GitHub Copilot AI pair programmer: Asset or Liability? arXiv preprint arXiv:2206.15331 (2022).

GitHub. 2022. Your AI pair programmer. (2022). https://github.com/features/copilot Accessed: 2022-07-31.
Gavin D Howard. 2021. GitHub Copilot: Copyright, Fair Use, Creativity, Transformativity, and Algorithms. (2021).
K Rustan M Leino. 2010. Dafny: An automatic program veriÔ¨Åer for functional correctness. In International Conference on

Logic for Programming ArtiÔ¨Åcial Intelligence and Reasoning. Springer, 348‚Äì370.

K Rustan M Leino and Valentin W√ºstholz. 2014. The Dafny integrated development environment.

arXiv preprint

arXiv:1404.6602 (2014).

Nhan Nguyen and Sarah Nadi. 2022. An Empirical Evaluation of GitHub Copilot‚Äôs Code Suggestions. In 2022 IEEE/ACM

19th International Conference on Mining Software Repositories (MSR). IEEE, 1‚Äì5.

Dominik Sobania, Martin Briesch, and Franz Rothlauf. 2022. Choose your programming Copilot: a comparison of the pro-
gram synthesis performance of GitHub copilot and genetic programming. In Proceedings of the Genetic and Evolutionary
Computation Conference. 1019‚Äì1027.

Asma Tafat and Claude March√©. 2011. Binary heaps formally veriÔ¨Åed in Why3. Technical Report [Research Report] RR-7780.

INRIA.

David

A. Wheeler.

2021.

The

Apple

goto

fail

vulnerability:

lessons

learned.

https://dwheeler.com/essays/apple-goto-fail.html. (Jan 2021). Accessed 1 September 2022.

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

