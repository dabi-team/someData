1

2
2
0
2

p
e
S
5

]
E
S
.
s
c
[

1
v
6
6
7
1
0
.
9
0
2
2
:
v
i
X
r
a

Exploring the Verifiability of Code Generated by GitHub
Copilot

DAKOTA WONG, University of Waterloo, Canada
AUSTIN KOTHIG, University of Waterloo, Canada
PATRICK LAM, University of Waterloo, Canada

GitHub’s Copilot generates code quickly. We investigate whether it generates good code. Our approach is to
identify a set of problems, ask Copilot to generate solutions, and attempt to formally verify these solutions
with Dafny. Our formal veriﬁcation is with respect to hand-crafted speciﬁcations. We have carried out this
process on 6 problems and succeeded in formally verifying 4 of the created solutions. We found evidence
which corroborates the current consensus in the literature: Copilot is a powerful tool; however, it should not
be “ﬂying the plane" by itself.
CCS Concepts: • Software and its engineering → General programming languages; • Social and pro-
fessional topics → History of programming languages;

Additional Key Words and Phrases: GitHub Copilot, Program Synthesis, Software Veriﬁcation.

ACM Reference Format:
Dakota Wong, Austin Kothig, and Patrick Lam. 2022. Exploring the Veriﬁability of Code Generated by GitHub
Copilot. Proc. ACM Program. Lang. 1, HATRA, Article 1 (December 2022), 9 pages.

1 INTRODUCTION

In aviation, commercial airplanes have two yokes (controls) which allows for sharing of respon-
sibilities and workload between a primary pilot and a copilot. Both operators are fully trained,
informed, and capable of ﬂying the aircraft; however, only one of them needs to be controlling the
aircraft at any one moment. In software development, traditionally, code is written by an individ-
ual. In team environments, this code is typically scrutinized and assessed by a number of people,
but originally it had to be developed by an individual. Similar to a pilot, software developers are
ordinarily well trained, informed, and capable of programming; however, ineﬃcient or incorrect
code segments can potentially slip between the cracks and into code-bases when a developer does
not fully understand their tools, the domain, or the required program speciﬁcations.

GitHub, with the use of OpenAI’s Codex [Chen et al. 2021], has released an “AI pair program-
mer” to assist in software development [GitHub 2022]. This programming partner is aptly named
Copilot. The aim of this tool is to shift the programmer’s time and attention away from boiler-
plate and repetitive code patterns, and toward the critical design of the system. Copilot works by
providing implementation suggestions based on natural language descriptions of the required code.
Copilot is currently capable of generating code in eleven programming languages, including C,
C++, C#, Go, Java, JavaScript, PHP, Python, Ruby, Scala, and TypeScript1.

The community is struggling to understand what Copilot can and can’t do, and proofs are a good
indicator of where Copilot might stand in terms of generating correct code. Thus, in this work,
we explore the veriﬁability of Copilot’s generated code with respect to the software veriﬁcation
language Dafny [Leino 2010], and discuss our ﬁndings about the veriﬁability of the generated code.

1https://docs.github.com/en/copilot/overview-of-github-copilot/about-github-copilot

Authors’ addresses: Dakota Wong, University of Waterloo, Canada, d82wong@uwaterloo.ca; Austin Kothig, University of
Waterloo, Canada, akothig@uwaterloo.ca; Patrick Lam, University of Waterloo, Canada, patrick.lam@uwaterloo.ca.

2022. 2475-1421/2022/12-ART1 $15.00
https://doi.org/

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

 
 
 
 
 
 
1:2

Dakota Wong, Austin Kothig, and Patrick Lam

2 RELATED WORK
There has been a great deal of scrutiny of Copilot and of the code it produces. Early studies which
aim to empirically evaluate Copilot [Nguyen and Nadi 2022] have found that while this early ver-
sion of the model is not perfect, its current results are impressive. In their work, Nguyen and Nadi
tested Copilot against 33 LeetCode2 questions (4 from the easy category, 17 from the medium
category, and 12 from the hard category) using four programming languages (Python, JavaScript,
Java, C), ran the generated code against the LeetCode test cases, and examined the percentage of
passing cases. Java performed best, being able to solve all test cases for 19 of the 33 problems. The
authors found that, often, the code that Copilot generated could be simpliﬁed, and that sometimes
the generated code would require methods or packages that have not been deﬁned or declared.

Copilot generates code diﬀerently from traditional genetic programming paradigms. Sobania et al.

[2022] found that Copilot could generate correct solutions to a variety of problems, with compa-
rable accuracy to genetic programming. The improvement that Copilot makes over traditional
approaches is that it was trained on a 159 GB dataset of unlabelled data, whereas genetic pro-
gramming requires the dataset to be rigorously labeled. Thus, Sobania et al. claimed that the code
Copilot generates is often easier to read and understand compared to that generated by genetic
programming.

It is clear from the current research that Copilot is not a magic wand solution to problems in
software engineering. With its ﬂaws, how are developers able to beneﬁt from this tool eﬀectively?
Dakhel et al. [2022] compared Copilot’s proposed solutions against human programmers on a set
of fundamental problems. The authors found that Copilot was unable to understand certain limita-
tions embedded in the problem description, and while understanding the fundamentals of what is
being requested, it can sometimes create errors when it does not understand. They conclude that
while the generated code from Copilot is not a perfect solution, it can still be incorporated and
modiﬁed into a project for faster early-stage prototyping.

3 METHODOLOGY
Our goal is to apply veriﬁcation techniques to code generated by GitHub Copilot. We came up with
sample problems and tasked Copilot with generating solutions in Python. We then used Dafny to
verify that Copilot’s generated code satisﬁes the requirements.

More speciﬁcally, our methodology is as follows. First, we chose 6 problems to give to Copilot
(ﬁve that we chose ourselves and one from Nguyen and Nadi [2022]). We wanted to test whether
Copilot could generate a function which would solve the problems; by “solve”, we mean that the
generated code satisﬁes the problem’s formal speciﬁcations. Thus, we wrote formal speciﬁcations
in Dafny for each problem, consisting of requires and ensures statements.

Having deﬁned the problems, we then asked Copilot to generate solutions in Python. To give
Copilot the best chance of generating a good solution, we gave it a full function signature, includ-
ing a descriptive function name, parameter name(s), parameter type(s), and an output type. With
this input, Copilot then generated the function implementation. Since our goal was to test the
capabilities of Copilot, we always chose the ﬁrst suggested function.

Next, we carefully translated each Copilot implementation from Python to Dafny and added the
speciﬁcations that we had created. We took care to preserve the behaviour of the implementation.
In all cases, the implementations contained a loop of some type. Hence, the provided requires
and ensures statements were inadequate to generate a proof that veriﬁed the implementation. We
thus attempted to manually derive loop invariants so that Dafny could verify the implementation.

2https://leetcode.com/

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

Exploring the Verifiability of Code Generated by GitHub Copilot

1:3

During the veriﬁcation process, we added extra requires and ensures clauses, if they were needed
to verify the program, along with additional helper functions and methods when necessary.

4 RESULTS

We have attempted to verify 6 Copilot implementations, one of which intersects the LeetCode
problems in [Nguyen and Nadi 2022]. Table 1 summarizes the algorithms, implementations, and
veriﬁcation attempts. Incidentally, during testing, consistent with Nguyen and Nadi [2022], we
found that Copilot would periodically include packages or methods that had not been deﬁned; it
happened to not do so for any of the implementations we describe here.

We have archived the current version of the Copilot-generated implementations and our Dafny

code at https://zenodo.org/record/7040924.

Table 1. Algorithm implementations generated by Copilot. Dafny verification attempt statistics.

Algorithm
Name
Binary Search (4.1)
Two Sums (4.2)
Largest Sum
Sort Array
Prime Factors (4.3)
Max Heapify (4.4)

Python Veriﬁcation Veriﬁed Speciﬁcation # Invariants

LOC Diﬃculty

12 Easy
5 Medium
10 Medium
6 Medium
12 Hard
14 Hard

X
X
X
X

LOC
5
6
2
4
3
4

3
7
3
11
> 23
> 4

Figure 1 presents the Copilot prompts that we used to generate implementations.

def binary_search(arr: list, target: int) -> int:
def twoSum(self, nums, target): // LeetCode; types on omitted subsequent lines
def largest_sum(nums: list) -> int:
def sortArray(arr: list) -> list:
def primeFactors(val: int) -> list:
def maxHeapify(arr: list) -> list:

Fig. 1. Copilot prompts for our algorithms.

We were able to create a valid proof in Dafny for 4 of the 6 solutions generated by Copilot; we

next discuss 2 of the valid proofs and our 2 failed attempts.

4.1 Binary Search
“Binary Search” is an algorithm which searches a sorted array for the index of a target element.
The algorithm is appealing as it has a worst-case linear time complexity 𝑂 (𝑛). Implementations
are recognizable and simple to understand, making this algorithm a good candidate for our ﬁrst
veriﬁcation example.

This example was inspired by a Dafny guide written by Arie Gurﬁnkel3. Our ﬁrst observation
was that Copilot’s implementation of Binary Search is diﬀerent from that in the Dafny guide,
leading to a diﬀerent veriﬁcation process.

We constructed formal speciﬁcations for binary search. As input, the implementation will take
an array of distinct sorted integers and an integer target. It should then search the array for the

3https://ece.uwaterloo.ca/~agurﬁnk/stqam/rise4fun-Dafny

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

1:4

Dakota Wong, Austin Kothig, and Patrick Lam

target, returning the index of the target if found. If the target is not found, the program should
have a return value (r.v) of −1. These speciﬁcations can be expressed as:

requires Sorted(𝑎𝑟𝑟 )
requires Distinct(𝑎𝑟𝑟 )
ensures

𝑟 .𝑣 ≠ −1 =⇒ found(𝑎𝑟𝑟 , 𝑡𝑎𝑟𝑔𝑒𝑡, 𝑟 .𝑣)
𝑟 .𝑣 = −1 =⇒ not_found(𝑎𝑟𝑟 , 𝑡𝑎𝑟𝑔𝑒𝑡)

ensures

In the speciﬁcations above, Sorted, Distinct, found, and not_found are all predicates. Sorted checks
whether an array is sorted in ascending order and Distinct checks whether all elements of an array
are distinct. We require that valid inputs satisfy these predicates. Next, we have the predicate found,
which checks to see if the target was found at the index returned by the algorithm. This predicate
should be true when the returned index is not −1. To handle the case where the target is not found,
we have predicate not_found that checks that the target does not exist in the array. This predicate
is implied to be true when the return value is −1.

In parallel with manually producing speciﬁcations, we used Copilot to generate an implemen-

tation, given the following signature:

1

def binary_search ( arr : list , target : int ) -> int :

We accepted the ﬁrst suggested implementation by Copilot based on the provided input:

def binary_search ( arr : list , target : int ) -> int :

low = 0
high = len ( arr ) - 1
while low <= high :

mid = ( low + high ) / / 2
if arr [ mid ] = = target :

return mid

elif arr [ mid ] < target :

low = mid + 1

else :

high = mid - 1

return -1

1
2
3
4
5
6
7
8
9
10
11
12

As stated above, we manually translated the implementation to Dafny, and added the formal
speciﬁcations that we came up with. This also involved deﬁning the predicates Sorted and Distinct.
Given a speciﬁcation and implementation, we could start veriﬁcation.

However, Dafny also requires loop invariants. To provide them, we needed to (manually) reason
about what happens in the implementation’s while loop. From our familiarity with binary search,
we know that it uses two indices, high and low. High starts at the last element of the array; low
starts at the ﬁrst. In each iteration, the indices move closer together, closing the window of ele-
ments where the target can exist. In particular, we know that the target cannot exist at indices less
than or equal to that of the low pointer or at indices greater than equal to that of the high pointer.
This logic was to implement the primarily loop invariant of the algorithm. In ﬁrst-order logic,

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

Exploring the Verifiability of Code Generated by GitHub Copilot

1:5

∀𝑖 · 0 ≤ 𝑖 ≤ low ∧ high ≤ 𝑖 < arr.Length =⇒ arr[𝑖] ≠ target.

With the loop invariants, Dafny was able to verify the implementation. So, in this case, Copilot
was able to successfully generate an implementation which satisﬁed our formal speciﬁcations for
binary search. This implementation could be veriﬁed without adding any extra requires or ensures
statements beyond what we had initially identiﬁed as the speciﬁcation.

4.2 Two Sums

We next picked a problem from LeetCode that was used in the study by Nguyen and Nadi [2022].
“Two sums” takes an array of integers and an integer target, and returns two distinct indices in
the array where the elements at those indices sum to the target. The Copilot input was:

1
2
3
4
5
6

def twoSum ( self , nums , target ) :

"""
: type nums : List [ int ]
: type target : int
: rtype : List [ int ]
"""

The solution that Copilot generated passed all of the LeetCode test cases. LeetCode provides a
number of constraints on the inputs—notably that a valid answer always exists. We used the con-
straints to formulate the following requires and ensures clauses:

requires 2 ≤ nums.Length
requires ∃𝑖, 𝑗 · (0 ≤ 𝑖 < 𝑗 < nums.Length ∧ nums[𝑖] + nums[ 𝑗 ] == target)
ensures

index1 ≠ index2
0 ≤ index1 < nums.Length
0 ≤ index2 < nums.Length
nums[index1] + nums[index2] == target

ensures
ensures

ensures

We converted the Python to Dafny and, with moderate eﬀort, we then managed to write invari-
ants that enabled Dafny to verify the generated solution. The 5 lines of Python cost resulted in 8
lines of Dafny. We added 7 invariants (3 in the outer loop and 4 in the inner loop) to enable the
veriﬁcation.

Hence, in this case, Copilot generated a solution that passes the LeetCode test cases and that we

managed to verify.

4.3 Prime Factors

“Prime Factors” is an algorithm that takes an integer and returns a list of prime numbers, which,
when multiplied together, reproduce the original number. For example, the number 18 decomposes
into the list [2, 3, 3]. The algorithm is 𝑂 (𝑛), but does contain a nested loop.

We formally speciﬁed this algorithm; it accepts an integer greater than or equal to 2, and returns

a list of prime factors of the integer. Our (arithmetic-heavy) speciﬁcations were:

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

1:6

Dakota Wong, Austin Kothig, and Patrick Lam

requires val ≥ 2

len(arr)

ensures

arr[i] == val

i=0
Ö

With these simple formal speciﬁcations deﬁned, we were ready to prompt Copilot to generate

our algorithm. We provided Copilot with the following function signature:

1

def primeFactors ( val : int ) - > list :

which prompted Copilot to suggest the following Python implementation:

1
2
3
4
5
6
7
8
9
10
11
12

def primeFactors ( val : int ) - > list :

factors = []
while val % 2 = = 0:

factors . append (2)
val = val / / 2

for i in range (3 , int ( val * * 0.5) + 1 , 2) :

while val % i == 0:

factors . append ( i )
val = val // i

if val > 2:

factors . append ( val )

return factors

To convert to Dafny: 1) As with previous implementations, we adapted Python for loops into
while loops. 2) We had to implement integer square root in Dafny. Verifying integer square root
is nontrivial; however, we found a veriﬁed implementation4 which we used as a library. 3) We had
to choose a Dafny data structure equivalent to a dynamic array.

For dynamic arrays (the Python equivalent of list), we used the Dafny seq<int> (sequence of
integers), as it had a built in concatenate method which acts by adding to sequences to produce
a new sequence which can be assigned. However, initialization was a challenge: Dafny does not
permit empty sequences. We thus initialized our sequence with multiplicative unit 1; though this
is not identical to the Python solution, it is reasonably equivalent.

We also created a function for multiplying the elements of the sequence, adding invariants to

check that the current product times the remaining value produces the original value.

Using our chosen invariants, we encountered Dafny timeout issues and failed to verify the im-
plementation. As a last resort, to try to help the proof resolve with “what we know to be true", we
added lemmas which assumed false, allowing us to say two speciﬁc ensures clauses were true:

4https://homepage.cs.uiowa.edu/~tinelli/classes/181/Spring11/Tools/Dafny/Examples/square-root.dfy

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

Exploring the Verifiability of Code Generated by GitHub Copilot

1:7

ensures

len(arr)

· 𝑣 == val

arr[i]
!
len(arr)

i=0
Ö

ensures (𝑣 == 1) =⇒

arr[i]
!

== val

i=0
Ö

before and after each append of a new value to the list of factors. Even assuming these two clauses
to be true, the Dafny solver continued to hit the time limit for ﬁnding a proof. Thus, although we
believe that Copilot generated a correct implementation, we have not yet been able to verify it.

4.4 Max Heapify

“Max Heapify” is an algorithm for turning an array into a max-heap data structure. The array is
conceptually a complete binary tree, where each index holds the value of a particular node, and
that node’s left and right children’s indices are found using the following mapping:

left_child = (index ∗ 2) + 1
right_child = (index ∗ 2) + 2.

A max-heap satisﬁes the property that each node is greater than or equal to its left and right child.
Since this property is recursive, it implies that any particular node is (transitively) larger than
every node in both its right and left children, so the largest element in the tree should be at the
root.

With this in mind, we wrote formal speciﬁcations:

requires arr is a list of distinct integers
ensures ∀𝑥 · (0 ≤ 𝑥 < len(arr)) =⇒

(((2𝑥 + 1 < len(arr)) =⇒ (arr[𝑥] ≥ a[2𝑥 + 1])) ∧
((2𝑥 + 2 < len(arr)) =⇒ (arr[𝑥] ≥ a[2𝑥 + 2]))).

That is, the input array’s values are unique; and the resulting list has the properties of a max-heap.
Simultaneously, we provided the following function signature to Copilot:

1

def maxHeapify ( arr : list ) - > list :

Copilot produced a 14-line Python implementation, which we translated into Dafny and at-
tempted to verify. We designed a predicate based on the ensures clause, which checks that each
node is greater than or equal to the node at its childrens’ indices, if those indices are not out of
bounds for the array.

We noticed that the Copilot implementation diﬀers from more traditional implementations by
sifting down rather than sifting up: the recursive call to maxHeapify is given the entire (mutated)
array. Often, implementations of max-heap traverse all non-leaf nodes backwards to the root and
sift-up (with a recursive call) starting at any nodes that are out of place.

Prior to formal Dafny veriﬁcation, we tested the the generated algorithm on a series of random
inputs to ensure it produced a max-heap each time. Inspecting the algorithm with Python debug-
ging tools showed that the trace-tree for this implementation goes quite deep. The implementation
appears to make recursive calls, starting from the root, enough times to ensure that eventually the

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

 
 
1:8

Dakota Wong, Austin Kothig, and Patrick Lam

max-heap property holds. This would make ﬁnding a veriﬁable proof diﬃcult. Instead of the stan-
dard heapify algorithm running in 𝑂 (𝑛 𝑙𝑜𝑔 𝑛), the version Copilot generated for us appears to run
in time 𝑂 (𝑛2).

We tried a number of diﬀerent invariants to show that the array was partially heapiﬁed for each
step in the loop. However, we were unable to prove termination of the loop to begin with. For this
reason, we were unable to formally verify the generated algorithm.

5 DISCUSSION

Copilot is undoubtedly good at generating code. In this work, we took a formal veriﬁcation ap-
proach to investigating the code that Copilot generates, using Dafny. Of the 6 examples we tried,
we managed to verify the 4 simpler problems. One of the problems appeared in [Nguyen and Nadi
2022], which used LeetCode test suites to establish correctness of Copilot-generated code.

Our work produced corroborating evidence that Copilot’s generated code might be dubious. It
also explored the diﬃculty of using Dafny to verify implementations; although Dafny is powerful,
it can be nontrivial to verify implementations using it.

We believe that our work reinforces the fact that to eﬀectively deploy Copilot, one should know
what is needed. Similar to the work by Dakhel et al. [2022], we found that Copilot appears to skip
over certain constraints imposed on the input space. As a speciﬁc example, the “two sums” example
assumes that a solution exists; we had to manually record that assumption in our speciﬁcation.
Humans are not good at reasoning about edge cases [Wheeler 2021], and Copilot reproduces that
bias. Thus, to productively use Copilot, it remains incredibly important to reason carefully about
what the problem speciﬁcations should be.

We also found that verifying the generated software with Dafny was somewhat diﬃcult, both
due to Dafny implementation language limitations, and—more importantly—veriﬁability reasons.
Some Python idioms do not translate cleanly to Dafny; we had to reformulate Python generator
objects (e.g., range in a for loop) as while loops. Other Python data types such as list don’t have
an obvious substitution in Dafny. Dafny also omits math operations such as ﬂoor and square root,
which Copilot generated in its Python solutions.

In the LeetCode study [Nguyen and Nadi 2022], not all of the Copilot-generated solutions passed
the LeetCode test cases. In this work, we did not attempt to verify any solutions that failed their
test cases. Of course, we expect such solutions to be unveriﬁable. However, attempting veriﬁcation
could provide another way to understand how the solutions are incorrect, beyond simply inspect-
ing the generated code. As is true of veriﬁcation in general, an attempted veriﬁcation can provide
insight into the code, complementing a test-based lens.

We believe that algorithms designed with veriﬁability in mind are more likely to be easier to
prove. A proof of correctness of binary search halves the search space at each step. If an imple-
mentation follows suit, we can focus on solving a subset of the problem in its proof. In reasoning
about a sorting algorithm, we would like to be able to show that each step of a loop results in the
array being partially sorted.

When we were choosing algorithms to verify, we thought that max-heap would be simple, as it
has very clear sub-problems which, when solved, result in a well-deﬁned data structure. However,
the Copilot-generated implementation does not obviously reduce to sub-problems. We believe that
an iterative version of the max-heap algorithm which walks backwards through the tree would
have been easier to verify than the recursive version which Copilot generated for us.

Of course, we have not established that proving the generated max-heap implementation is
impossible. Per Leino [2010], Dafny veriﬁcation often requires an expert, and it is not an easy
task for the average programmer. Leino and Wüstholz [2014] have also identiﬁed that, for some
problems, the solver timing out can be a barrier to veriﬁability. There are some shortcuts which

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

Exploring the Verifiability of Code Generated by GitHub Copilot

1:9

can be taken in the proof to avoid timing out; however, these shortcuts require a great amount of
practice to identify. Max-heapify has been formally veriﬁed [Tafat and Marché 2011] using other
software veriﬁcation techniques, but the proof and its description are both reasonably lengthy.

Our Python-mediated translation process meant that we avoided Dafny’s treatment of programs
with pointers and pointer arithmetic. Because we asked Copilot for Python implementations, and
these implementations do not include pointer and memory management, we could not explore
how Dafny can be used to verify functional correctness for pointer-based programs [Leino 2010].

Concluding thoughts. In our experience, Copilot is a powerful tool for quickly producing (pro-
totype) implementations: it can generate code faster than one could possibly write it. However,
Copilot is certainly not a magic wand. A programmer using Copilot would be well advised to not
only look at what Copilot has produced, but also ensure it is correct and appropriate for the in-
tended use case. If not with formal veriﬁcation, one ought to at least rigorously vet the generated
code with a test suite, prior to integrating it into any system. One should also consider copyright
issues [Howard 2021]. Of course, in principle, one should vet any code before integrating into a
system, whether human produced or machine produced.

We observed that Copilot was quite capable when generating solutions to well known or es-
tablished problems, likely related to the fact that Copilot’s training data came from user data on
GitHub. Like Dakhel et al. [2022], we found that Copilot generated sub-optimal and possibly in-
correct solutions to some of our problems, e.g., Max Heapify. Due to how Copilot is trained, we
do not believe that it would work as well on esoteric problems; it would be interesting to explore
that point.

REFERENCES
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri
Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating large language models trained on code. arXiv preprint
arXiv:2107.03374 (2021).

Arghavan Moradi Dakhel, Vahid Majdinasab, Amin Nikanjam, Foutse Khomh, Michel C Desmarais, Zhen Ming, et al. 2022.

GitHub Copilot AI pair programmer: Asset or Liability? arXiv preprint arXiv:2206.15331 (2022).

GitHub. 2022. Your AI pair programmer. (2022). https://github.com/features/copilot Accessed: 2022-07-31.
Gavin D Howard. 2021. GitHub Copilot: Copyright, Fair Use, Creativity, Transformativity, and Algorithms. (2021).
K Rustan M Leino. 2010. Dafny: An automatic program veriﬁer for functional correctness. In International Conference on

Logic for Programming Artiﬁcial Intelligence and Reasoning. Springer, 348–370.

K Rustan M Leino and Valentin Wüstholz. 2014. The Dafny integrated development environment.

arXiv preprint

arXiv:1404.6602 (2014).

Nhan Nguyen and Sarah Nadi. 2022. An Empirical Evaluation of GitHub Copilot’s Code Suggestions. In 2022 IEEE/ACM

19th International Conference on Mining Software Repositories (MSR). IEEE, 1–5.

Dominik Sobania, Martin Briesch, and Franz Rothlauf. 2022. Choose your programming Copilot: a comparison of the pro-
gram synthesis performance of GitHub copilot and genetic programming. In Proceedings of the Genetic and Evolutionary
Computation Conference. 1019–1027.

Asma Tafat and Claude Marché. 2011. Binary heaps formally veriﬁed in Why3. Technical Report [Research Report] RR-7780.

INRIA.

David

A. Wheeler.

2021.

The

Apple

goto

fail

vulnerability:

lessons

learned.

https://dwheeler.com/essays/apple-goto-fail.html. (Jan 2021). Accessed 1 September 2022.

Proceedings of the ACM on Programming Languages, Vol. 1, No. HATRA, Article 1. Publication date: December 2022.

