2
2
0
2

r
a

M
8
2

]
t
e
d
-
s
n
i
.
s
c
i
s
y
h
p
[

1
v
6
3
2
7
1
.
3
0
2
2
:
v
i
X
r
a

Mamba: a systematic software solution for beamline
experiments at HEPS

Yu Liu1,∗, Yan-Da Geng2, Xiao-Xue Bi1, Xiang Li1,3,
Ye Tao1,3, Jian-She Cao1,3, Yu-Hui Dong1,3, Yi Zhang1,3,∗

Synopsis

Keywords: Bluesky; experiment control; ﬂy scan; high-throughput experiment; software archi-

tecture.

Mamba is a Bluesky-based experiment control framework being developed for HEPS; its fron-
tend and backend collaborate through a RPC service, and most importantly command injec-
tion. Improvement of Bluesky’s support for high-frequency and high-throughput applications is in
progress, with Mamba Data Worker as a key component. Other plans, including an experiment
parameter generator and Mamba GUI Studio, are also discussed.

Abstract

To cater for the diverse experiment requirements at the High Energy Photon Source (HEPS)
with often limited human resources, Bluesky is chosen as the basis for our software framework,
Mamba. In our attempt to address Bluesky’s lack of integrated GUIs, command injection with
feedback is chosen as the main way for the GUIs to cooperate with the CLI; a RPC service is
provided, which also covers functionalities unsuitable for command injection, as well as pushing
of status updates. In order to fully support high-frequency applications like ﬂy scans, Bluesky’s
support for asynchronous control is being improved; to support high-throughput experiments,
Mamba Data Worker (MDW ) is being developed to cover the complexity in asynchronous online
data processing for these experiments. To systematically simplify the speciﬁcation of metadata,
scan parameters and data-processing graphs for each type of experiments, an experiment parameter
generator (EPG) will be developed; experiment-speciﬁc modules to automate preparation steps will
also be made. The integration of oﬀ-the-shelf code in Mamba for domain-speciﬁc needs is under
investigation, and Mamba GUI Studio (MGS ) is being developed to simplify the implementation
and integration of GUIs.

1

Introduction

With the upgrade of synchrontron radiation facilities across the world, great progress is be-
ing continously made in providing X-ray beams with better emittance and coherence, as well as
employing optical components and detectors with higher performance. Experiments with high com-
munication frequencies or high data throughputs, as well as experiments involving multiple modes,
complex in situ environments or automated changing of samples, are becoming increasingly preva-
lent. While allowing for the multi-scale, multi-feature and in situ characterisation of samples, this
also poses fundamental challenges to experiment control and data acquisition/processing, both in
experiments themselves and the preparation steps before them. The large number of beamlines
at many facilities, especially new facilities under construction, also result in the hard demand to

∗ Correspondence e-mail: liuyu91@ihep.ac.cn, zhangyi88@ihep.ac.cn.
1 Institute of High Energy Physics, Chinese Academy of Sciences, Beijing 100049, People’s Republic of China.
2 Kuang Yaming Honors School, Nanjing University, Nanjing 210093, People’s Republic of China.
3 University of Chinese Academy of Sciences, Beijing 100049, People’s Republic of China.

1

 
 
 
 
 
 
implement diverse experiment requirements with a manageable codebase. At the High Energy
Photon Source (HEPS) (Jiao et al., 2018), a 4th-generation synchrotron radiation facility, where
14 beamlines will be provided in 2025 in its Phase I and up to 90 beamlines in total can be served
in further phases, all issues above are to be expected. In order to address these issues while keeping
our codebase maintainable with often limited human resources, proper architecture design must
be carried out for the software components involved.

The foundation of Mamba, our software framework, is the Python-based Bluesky (Allan et al.,
2019); before making the choice, we had researched multiple well-known alternatives for similar
applications, like GDA (Gibbons, Heron and Rees, 2011), Sardana (Coutinho et al., 2011), Karabo
(Hauf et al., 2019) and py4syn (Slepicka et al., 2015). Here we avoid discussing the details of our
choice, and instead note that the choice is not based on the availability of readily usable features,
but based on the total eﬀorts needed to adapt the publicly available codebase to our applications.
When saying “total eﬀorts”, we not only include the eﬀorts in development and maintenance of
our own codebase, but also include those in understanding, ﬁxing and customising the provided
codebase. After our research, we concluded that because of the quite well-designed device interfaces
(classes from ophyd ) in conjunction with the simple yet relatively powerful mechanism to combine
them in interlocked actions (RunEngine from bluesky) and represent extracted data in a friendly
format (the “documents”) in real time, Bluesky is likely to fulﬁll a satisfactory fraction of the
requirements at HEPS with the best cost-to-eﬀect ratio. A ﬁrst issue with Bluesky is the lack of
integrated graphical user interfaces (GUIs); we discuss our approach to this issue in Section 2. For
other challenges we note in the above, we give our plan of ongoing development in Section 3.

2 Mamba’s backend and frontend

The ﬁrst issue we observe with Bluesky, in comparison with its easily composable programming
interfaces, is the lack of integrated GUIs. For some experiment tasks this is more like just an
obstacle to users with a relatively weak background in programming, but there are also tasks that
are fundamentally easier with GUIs than only with keyboards. One good example is a requirement
from the hard X-ray high-resolution spectroscopy beamline (B5) at HEPS (cf. also Huotari et al.,
2017), where many regions of interest (ROIs) need to be speciﬁed that properly cover individual
light spots in sample images taken from area detectors (and light spots in images that will follow);
another example is the manipulation of data-pipe graphs for Mamba Data Worker (cf. Section 3).
Since Bluesky recommends the IPython interactive command line interface (CLI) of Python for
its regular use on beamlines, we have designed Mamba with cooperation between the CLI (Mamba
backend) and our GUIs (Mamba frontend) in mind; inspired by AutoCAD-like software (called
parametric modeling software in its industry), we extensively use what we call command injection
(Figure 1) to implement this cooperation. Before discussing the communication architecture of
Mamba in detail, we note that its frontend is still very immature in terms of internal structure and
robustness; however, the architecture between the backend and frontend, which is the subject of
this section, has been tested successfully in a real tomography experiment on a testbed for HEPS.
With command injection, we basically treat GUIs as code generators: most user operations
with GUIs are translated into equivalent commands that get injected into the CLI, where they are
actually executed. This design is beneﬁcial in many ways, in terms of both user friendliness and
architectural soundness. Users can naturally learn to use the CLI from using GUIs, and those more
proﬁcient in programming may abstract repeated tasks into succinct yet reusable CLI snippets.
Sometimes in order to perform some tasks that are not yet implemented or simply inﬂexible with
GUIs, developers may even ask users to execute a few lines of code in the CLI; this is particularly
meaningful when considering that developing the GUI for an application is typically much more
complex than developing its CLI counterpart. The emphasis of GUIs as code generators also
helps developers to naturally design optimal interfaces when implementing requirements, which
increases modularity and consequently facilitates maintenance (especially automated testing). To
summarise the above up, command injection allows the CLI and GUIs to complement each other
constructively, reducing workload for both users and developers.

The actual communication architecture between the backend and frontend of Mamba is shown
in Figure 2. The backend is run as a subprocess of a wrapping program, which is based on the

2

Figure 1: Command injection in Mamba, showing an error caused by attempting to log out twice
after a successful experiment session; we explicitly note that appearance of the GUIs may vary in
the future due to ongoing frontend refactoring

pexpect library and forwards input from the user and output from the subprocess; the forwarding
program also listens on a socket (ZeroMQ REP) that command injection clients can connect to,
which send the actual injection requests (Figure 3(d)). This way, commands are injected as if they
were from the user’s keyboard. A problem with pexpect-based command injection is the lack of
feedback: because the wrapping program does not understand the input semantics of the program
(eg. IPython) it wraps, it only knows whether some command has been successfully injected, instead
of the ﬁnal result (return value or exception in Python, cf. Figure 1) of its execution. For this
reason, we encapsulate command injection with a remote procedure call (RPC) service started by
the server_start function in the Mamba-speciﬁc startup script for IPython (Figure 4); the RPC
service is a native Python thread with access to relevant IPython interfaces, so it can capture the
results of injected commands and return them to its clients.

Figure 2: Mamba’s communication architecture

So the Mamba backend provides a RPC service that supports command injection with feedback;
however, there are also communication requirements between the backend and frontend that are
unsuitable for command injection. A ﬁrst example is passwords which should not appear in clear
text on the CLI because of the command line history mechanism; additionally, many status queries
(eg. listing known motors and detectors) are only required by GUIs, and are inessential for CLI-
only use of Mamba, so the appearance of relevant commands on the CLI would be mostly useless
to users. Therefore we also provide special RPCs for these requirements (Figure 3(a)); however

3

pexpectIPythonRPC threadStatus informationOutput tothe consoleInput fromthe keyboardOther clients forcommand injectionCommand injectionfrom RPCsRPC serviceRPC clients(eg. GUIs)Figure 3: Example Mamba communication: (a) normal request/reply, (b) replies upon errors, (c)
notiﬁcation, (d) raw communication to pexpect; except for (d) which uses raw byte strings, all
other (RPC) communication uses a JSON-based format

because RPCs need dedicated encapsulation code (RPC-speciﬁc syntax checks etc), we have formed
the policy that special RPCs should usually not be added for communication essential for CLI-only
use. Noticing the need for the frontend to get status updates (Figure 3(c)) and the intrinsic
weakness of polling (polling too often wastes system resources, while polling too scarcely risks loss
of updates), in addition to a request/reply socket (ZeroMQ REP) for regular RPCs, a notiﬁcation
socket (ZeroMQ PUB) is also provided by the RPC service to proactively push updates to clients.
To further simplify our codebase, the ﬁner details in Mamba have also undergone careful de-
sign, for which we give two examples. One is the introduction of ZError, a subclass of Python’s
Exception, that can be raised by handlers in the RPC service to give ﬁne-grained reports for
errors that have been anticipated by developers (cf. Figure 1 and 3(b)). The RPC service will
return information extracted from ZError to clients, instead of the more generic information it
will return upon other types of exceptions; this way, RPC clients can set up exception handlers
accordingly, and only use a generic handler as a last resort. Another example is the use of variables
M and D to group motors and detectors respectively in the global scope of IPython (cf. Figure 1,
4 and 3(a)), just like how RE is recommended by Bluesky developers for the RunEngine instance
in the same scope. We ﬁnd this much more natural as a way to mark the “movability” of devices
than alternatives, like passing two ad hoc dictionaries as arguments to server_start which has
the disadvantage that the device lists cannot be modiﬁed dynamically. We have even gone one
step further and modiﬁed core ophyd code to allow device object names like M.m1 that contain
dots, so that we can enforce a policy that the name of a device object must be a Python expression
referencing exactly the same object, which has proven to again save quite a lot of code.

3 Further plans on Mamba

After a quite extensive research on the eligibility of Bluesky for the applications at HEPS, we
concluded that apart from the lack of GUI integration, Bluesky is able to cover most low-frequency
low-throughput (typically with < 10 Hz communication between the computer and devices in-
volved, and data rates < 100 MB/s) needs at HEPS, in both regular step-scan experiments and
certain preparation steps (eg. the automated arming of samples, including the ﬁne tuning of their
positions; cf. also the requirement from the B5 beamline at HEPS mentioned in Section 2). Never-
theless, because HEPS is a 4th-generation synchrotron radiation facility, its small X-ray spots and
high brightness not only facilitates high-resolution imaging, but also necessitates continuous scans
(ﬂy scans) to handle the signiﬁcantly larger number of data points and the much more serious
radiation damage of samples. So both high-frequency and high-throughput applications – exactly
where we ﬁnd Bluesky to be currently not very good at – are essential to HEPS; if these weak-

4

(a)MambaRPCtolistdevices:{"typ":"dev/keys","path":"M"}Thebackend’sreplytotherequestabove:{"err":"","ret":["M.m1","M.m2"]}(b)Examplereplyuponageneralexception:{"err":"exc","desc":"ZeroDivisionError:divisionbyzero"}Replyuponanexceptionmadewith‘‘raiseZError("error","description")’’:{"err":"error","desc":"description"}(c)Examplestatusupdatenotification:{"typ":"scan/start","id":1234}(d)Examplecommandinjectionrequesttopexpect,expressedasaPythonexpression:b"1/0\n"pexpectreturnsanemptystringtoconfirmsuccessfulcommandinjection:b""Figure 4: Example IPython startup script for Mamba

nesses are somehow addressed, Bluesky will be able to provide a solid uniﬁed basis for beamline
experiments at HEPS.

We begin with high-frequency applications, represented by ﬂy scans; a typical high-frequency
(but low-throughput) application is sound recording, which we compare ﬂy scans to. When per-
forming ﬂy scans (sound recording), because regular computers cannot handle the inﬂux of data
points at too high frequencies, we instead use dedicated controllers (sound recorders) to do the
handling; the computer reads data from the controllers in a block-by-block (instead of point-by-
point) fashion, and other than that just sends control messages like “start”, “stop” or “pause”.
From the above we can see that the key to high-frequency applications is asynchronous control (in-
directly with dedicated controllers), which currently does not seem quite easy to do with Bluesky’s
RunEngine. In fact the latter already has primitive support for simple ﬂy scans which only need
“start” (the kickoff operation in RunEngine) and “stop” (the complete operation), where the
data readout is mainly done oﬄine (the collect operation run after complete). At HEPS, we
are currently exploring an implementation of ﬂy scans that allows real-time tuning of the scanning
behaviours (adaptive speed/step-size tuning, automatic pausing/resuming etc) based on online pro-
cessing of the data read from controllers. This might be of particular interest in requirements like
obtaining the optimal X-ray spot size and wavefront for focus alignment, as well as enabling ultra-
high stability of the sample and X-ray probe during multi-dimensional scanning measurements at
the hard X-ray nanoprobe beamline (B2) at HEPS.

Bluesky supports online data processing using Python packages from the SciPy ecosystem,
but this is currently done through synchronous point-by-point callbacks; similar to how point-by-
point processing of sound data cannot be done synchronously with regular computers, synchronous
processing is unsuitable for high-throughput applications. The solution is also similar – use asyn-
chronous processing instead; noticing the discussion in the previous paragraph, we can see that the
same asynchronous mechanism we envision also covers the data-processing needs for high-frequency
experiments naturally. To address the complexity in both the asynchronous collaboration of worker
processes (buﬀering, polling/pushing, error handling etc, plus the resource management for pro-
cessing of big data) and the diverse domain-speciﬁc logics we need to support, we are developing
what we call the Mamba Data Worker (MDW ) framework, which will be to an extent like HiDRA
(Fischer et al., 2017) and Odin (Yendell et al., 2017). However, instead of focusing more on data
producers, MDW will treat producers and consumers equally, also handling the diverse format-
ing requirements of raw data from beamline experiments at HEPS (Hu et al., 2021a). The same
requirements are to our knowledge not something actively pursued by Bluesky’s databroker, aside

5

print("Examplebeamlineinitscriptloading...")#...`import'statementsomitted...classAttrDict(dict):def__init__(self,*args,**kwargs):super().__init__(*args,**kwargs)self.__dict__=selfM=AttrDict(m1=EpicsMotor("IOC:m1",name="M.m1"),m2=EpicsMotor("IOC:m2",name="M.m2"))D=AttrDict(ad=MyAreaDetector("13SIM1:",name="D.ad"))D.ad.cam.trigger_mode.set(0).wait()D.ad.cam.image_mode.set(1).wait()D.ad.cam.num_images.set(1).wait()D.ad.warmup()RE=RunEngine()U=server_start(M,D,RE)print("Beamlineinitscriptloaded.")from the problem we notice that databroker is not performant enough when there is heavy disk I/O
on the same machine. Moreover, instead of mainly supporting linear processing pipelines, MDW
will support full-ﬂedged graphs of data pipes (Figure 5), perhaps implemented in cooperation with
the Daisy project (Hu et al., 2021b); this is crucial for the real-time tuning of ﬂy scans, and will
also be very helpful in complex multimodal experiments.

Figure 5: Partial data-pipe graph for a simple high-throughput tomography experiment

As has also been discussed by Hu et al. (2021a), aside from the diverse needs for processing of
“real” data from experiments, the challenges posed by the many types of experiments possible at
HEPS also include the complexity in management of the scientiﬁc metadata for these experiments,
which will directly aﬀect the formatting of raw data by MDW. From the data producers’ side, for
each type of experiment at a certain beamline, the number of parameters intended to be tuned by
users (especially typical users) are usually much smaller than the total number of parameters for
devices accessible on the beamline. Therefore it is also necessary to extend Bluesky’s RunEngine
for each type of beamline experiments, so that users’ need to care about irrelevant parameters are
systematically minimised. Noticing the strong correlation between the speciﬁcation of scientiﬁc
metadata, device parameters and data-pipe graphs, we are designing an experiment parameter
generator (EPG) mechanism. Given an experiment schema, the EPG should accept a minimised
group of inputs; while the inputs are selected for typical needs, the output should be in a form
both customisable by advanced users and friendly to automation mechanisms. In the same spirit of
simplifying user operations, we will also develop Mamba modules to automate experiment-speciﬁc
preparation steps as are mentioned in the beginning of this section; considering the small X-ray
spots allowed at HEPS, this will help greatly in reducing time costed by tasks like the the ﬁne
tuning of beams. We ﬁnd that “intelligent” techniques, eg. those based on statistical learning, are
often useful in these steps, and we believe the architecture of Mamba will help to incorporate these
techniques into our workﬂow.

For both the backend and frontend of Mamba, we fully realise the necessity to reuse oﬀ-the-shelf
code from open-source projects to avoid unnecessary duplication of eﬀorts in providing domain-
speciﬁc abstractions. Integration of code from projects, eg. xrayutilities and diﬀcalc (for SPEC -like
access to crystallographic coordinates) on the backend side, as well as TomoPy and PyFAI (for
requirements in tomography) on the frontend side, are already under investigation. We also realise
the dominant status of certain projects in speciﬁc ﬁelds, eg. MXCuBE (Oscarsson et al., 2019) in
macromolecular crystallography, and will consider ways to provide a smooth experience at HEPS to
users familiar with these projects. We may reuse Mamba components just enough to integrate the
upstream project into the workﬂow at HEPS, or conversely integrate upstream components into
Mamba, or even (if preferable) reimplement functionalities in Mamba and just emulate the GUIs for
them; the actual way will be chosen depending on the speciﬁc project, in friendly cooperation with
upstream developers, with the goal of minimising the eﬀorts on both sides in mind. We also note
the necessity to support control systems other than EPICS, which is certainly doable with Bluesky
but just not a focus to its developers. This is imperative for high-throughput area detectors which
are non-trivial to support cleanly with the areaDetector framework in EPICS, and we are working
on direct ophyd support for them with MDW integration. There may also be systematic demand

6

OnlinevisualisationMetadatageneratorFurtherprocessing...Downsamplingand/or zoomingImagecompressionNeXusformattingProjectionsSinogramsRaw images(HDF5)Full raw data(NeXus)AreadetectorBig-matrixTranspositionfor other devices unsupported by EPICS that cannot be replaced with supported workalikes, which
has fortunately not yet been encountered by us.

To reduce the eﬀorts necessary for implementation and integration of GUIs, we are making
what we call Mamba GUI Studio (MGS ) to provide reusable utility widgets and allow drag-and-
drop composition of high-level GUI components, similar to what is done by Sobhani and Vescovo
(2020). A feature commonly requested for Mamba is cross-platform use of its frontend, but we
ﬁnd it really complex to expose its RPC service (especially the command injection mechanism) to
the network without harming security. For this reason, we only allow the backend and frontend of
Mamba to run on the same host, but meanwhile we plan to use the xpra utility (Figure 6), with
communication secured with SSH, to provide access on remote computers with operating systems
supported by xpra. Since xpra supports multiple coexisting “virtual screens” and simultaneous
access to one virtual screen by multiple clients, users can additionally collaborate either using
self-chosen groups of GUIs or using GUI groups shared by others; proper coordination is obviously
needed between users, perhaps using walkie-talkies or some chat software, to avoid conﬂicts between
their operations.

Figure 6: xpra provides “virtual screens”, each of which can be accessed by multiple clients simul-
taneously

4 Conclusion

We are developing the Bluesky-based Mamba software framework for the diverse experiment
requirements at HEPS. We use command injection with feedback to allow the CLI and GUIs of
Mamba to complement each other constructively; considering certain functionalities unsuitable
for command injection, Mamba provides a RPC service which also supports proactive pushing of
status updates. We take multiple measures to further simplify the codebase of Mamba, like the
use of ZError to simplify error handling, and the use of M and D to respectively group motors and
detectors. We ﬁnd Bluesky’s weaknesses in high-frequency and high-throughput experiments to
be exactly where it lacks in requirements at HEPS, and plan to address the former by improving
Bluesky’s support for asynchronous control. To fully address the complexity in data processing for
high-throughput experiments, we are developing Mamba Data Worker, which will cover the en-
tire process from producers to consumers, as well as support full-ﬂedged graphs of data pipes. To
simplify the speciﬁcation of scientiﬁc metadata, device parameters and data-pipe graphs, we will de-
velop an experiment parameter generator; the generation will be tailored systematically according
to the experiment type, and its output will be customisable yet machine-friendly. Experiment-
speciﬁc modules to automate preparation steps will be developed similarly. We are investigating
the integration of oﬀ-the-shelf code into Mamba to provide domain-speciﬁc functionalities, and
are also developing Mamba GUI Studio to simplify the implementation and integration of GUIs.
We plan to use a xpra-based mechanism to allow cross-platform access to Mamba, which will also
enable easy collaboration between users.

7

xpra serverCLI windowvirtual screen 1GUI window A1virtual screen 2GUI window A2GUI window A3GUI window B1virtual screen 3GUI window B2xpra client 1xpra client 2xpra client 3Acknowledgements

This work was supported by the National Basic Research Program of China (2017YFA0504900),
the One-Hundred Talents Program of Chinese Academy of Sciences (Y851552), the Strategic Pri-
ority Research Program of Chinese Academy of Sciences (XDB37000000), the Specialised Program
for Informatisation of Chinese Academy of Sciences (CAS-WX2021PY-0106) and the National
Science Foundation for Young Scientists of China (Grant No. 12005253).

References

Allan, D., Caswell, T., Campbell, S. and Rakitin, M., 2019. Bluesky’s ahead: A multi-facility
collaboration for an a la carte software project for data acquisition and management. Synchrotron
radiat. news, 32(3), pp.19–22.

Coutinho, T., Cun´ı, G., Fern´andez-Carreiras, D., Klora, J., Pascual-Izarra, C., Reszela, Z. and
Su˜n´e, R., 2011. Sardana: The software for building scadas in scientiﬁc environments. Proceed-
ings of the 13th international conference on accelerators and large experimental physics control
systems (icalepcs2011). Grenoble, France, WEAAUST01, pp.607–609.

Fischer, M., Gasthuber, M., Giesler, A., Hardt, M., Meyer, J., Prabhune, A., Rigoll, F., Schwarz, K.
and Streit, A., 2017. Advancing data management and analysis in diﬀerent scientiﬁc disciplines.
J. phys.: Conf. ser., 898, p.082026.

Gibbons, E.P., Heron, M.T. and Rees, N.P., 2011. Gda and epics: Working in unison for science
driven data acquisition and control at diamond light source. Proceedings of the 13th interna-
tional conference on accelerators and large experimental physics control systems (icalepcs2011).
Grenoble, France, TUAAUST01, pp.529–532.

Hauf, S., Heisen, B., Aplin, S., Beg, M., Bergemann, M., Bondar, V., Boukhelef, D., Danilevsky, C.,
Ehsan, W., Essenov, S., Fabbri, R., Flucke, G., Marsa, D.F., G¨ories, D., Giovanetti, G., Hickin,
D., Jarosiewicz, T., Kamil, E., Khakhulin, D., Klimovskaia, A., Kluyver, T., Kirienko, Y., Kuhn,
M., Maia, L., Mamchyk, D., Mariani, V., Mekinda, L., Michelat, T., M¨unnich, A., Padee, A.,
Parenti, A., Santos, H., Silenzi, A., Teichmann, M., Weger, K., Wiggins, J., Wrona, K., Xu, C.,
Youngman, C., Zhu, J., Fangohr, H. and Brockhauser, S., 2019. The karabo distributed control
system. J. synchrotron rad., 26(5), pp.1448–1461.

Hu, H., Qi, F.Z., Zhang, H.M., Tian, H.L. and Luo, Q., 2021a. The design of a data management

system at heps. J. synchrotron rad., 28(1), pp.169–171.

Hu, Y., Li, L., Tian, H.L., Liu, Z.B., Huang, Q.L., Zhang, Y., Hu, H. and Qi, F.Z., 2021b. Daisy:
Data analysis integrated software system for x-ray experiments. Epj web conf., 251, p.04020.

Huotari, S., Sahle, C.J., Henriquet, C., Al-Zein, A., Martel, K., Simonelli, L., Verbeni, R., Gon-
zalez, H., Lagier, M.C., Ponchut, C., Sala, M.M., Krisch, M. and Monaco, G., 2017. A large-
solid-angle x-ray raman scattering spectrometer at id20 of the european synchrotron radiation
facility. J. synchrotron rad., 24(2), pp.521–530.

Jiao, Y., Xu, G., Cui, X.H., Duan, Z., Guo, Y.Y., He, P., Ji, D.H., Li, J.Y., Li, X.Y., Meng, C.,
Peng, Y.M., Tian, S.K., Wang, J.Q., Wang, N., Wei, Y.Y., Xu, H.S., Yan, F., Yu, C.H., Zhao,
Y.L. and Qin, Q., 2018. The heps project. J. synchrotron rad., 25(6), pp.1611–1618.

Oscarsson, M., Beteva, A., Flot, D., Gordon, E., Guijarro, M., Leonard, G., McSweeney, S.,
Monaco, S., Mueller-Dieckmann, C., Nanao, M., Nurizzo, D., Popov, A., Stetten, D. von,
Svensson, O., Rey-Bakaikoa, V., Chado, I., Chavas, L., Gadea, L., Gourhant, P., Isabet, T.,
Legrand, P., Savko, M., Sirigu, S., Shepard, W., Thompson, A., Mueller, U., Nan, J., Eguiraun,
M., Bolmsten, F., Nardella, A., Mil`an-Otero, A., Thunnissen, M., Hellmig, M., Kastner, A.,
Schmuckermaier, L., Gerlach, M., Feiler, C., Weiss, M.S., Bowler, M.W., Gobbo, A., Papp, G.,
Sinoir, J., McCarthy, A., Karpics, I., Nikolova, M., Bourenkov, G., Schneider, T., Andreu, J.,
Cun´ı, G., Juanhuix, J., Boer, R., Fogh, R., Keller, P., Flensburg, C., Paciorek, W., Vonrhein,

8

C., Bricogne, G. and Sanctis, D. de, 2019. Mxcube2: the dawn of mxcube collaboration. J.
synchrotron rad., 26(2), pp.393–405.

Slepicka, H.H., Canova, H.F., Beniz, D.B. and Piton, J.R., 2015. Py4syn: Python for synchrotrons.

J. synchrotron rad., 22(5), pp.1182–1189.

Sobhani, B.A. and Vescovo, E., 2020. Drag and drop creation of bluesky guis. Fall 2020 epics
collaboration meeting. Online. Available from: https://indico.fhi-berlin.mpg.de/event/
52/contributions/579/.

Yendell, G., Pedersen, U., Tartoni, N., Williams, S., Nicholls, T. and Greer, A., 2017. Odin –
a control and data acquisition framework for excalibur 1m and 3m detectors. Proceedings of
the 16th international conference on accelerators and large experimental physics control systems
(icalepcs2017). Barcelona, Spain, TUPHA212, pp.966–969.

9

