What are the Practices for Secret Management in
Software Artifacts?

Setu Kumar Basak∗, Lorenzo Neil†, Bradley Reaves‡ and Laurie Williams§
Department of Computer Science, North Carolina State University, USA
Email: ∗sbasak4@ncsu.edu, †lcneil@ncsu.edu, ‡bgreaves@ncsu.edu, §lawilli3@ncsu.edu

2
2
0
2

g
u
A
4
2

]
E
S
.
s
c
[

1
v
0
8
2
1
1
.
8
0
2
2
:
v
i
X
r
a

Abstract—Throughout 2021, GitGuardian’s monitoring of pub-
lic GitHub repositories revealed a two-fold increase in the
number of secrets (database credentials, API keys, and other
credentials) exposed compared to 2020, accumulating more than
six million secrets. A systematic derivation of practices for
managing secrets can help practitioners in secure development.
The goal of our paper is to aid practitioners in avoiding the
exposure of secrets by identifying secret management practices
in software artifacts through a systematic derivation of practices
disseminated in Internet artifacts. We conduct a grey literature
review of Internet artifacts, such as blog articles and question
and answer posts. We identify 24 practices grouped in six
categories comprised of developer and organizational practices.
Our ﬁndings indicate that using local environment variables and
external secret management services are the most recommended
practices to move secrets out of source code and to securely
store secrets. We also observe that using version control system
scanning tools and employing short-lived secrets are the most
recommended practices to avoid accidentally committing secrets
and limit secret exposure, respectively.

Index Terms—secret management, practices, empirical study,

grey literature, secure development

I. INTRODUCTION

In March 2022, GitGuardian stated that

the number of
secrets exposed on public GitHub repositories doubled in 2021
when compared to 2020, reaching a total of over six million
secrets [1]. Software uses external web services for essential
functionality. APIs for payment systems, location services, and
social networking platform integration, to name a few, are all
examples of external web services. To perform authentication
across software artifacts as part of system integration, software
developers need secrets (database credentials, API keys, and
other credentials). During software development, these secrets
may need to be shared by developers working on a team, and
after deployment may need to be distributed to applications.
In 2019, Meli et al. studied a 13% snapshot of public
GitHub repositories and found over 200K API keys and
tokens checked into the repositories [2]. Secrets are not only
pushed into version control system (VCS) repositories by
developers but they are also kept in Android and iOS appli-
cation packages. One in every 200 Android apps is leaking
sensitive information, such as Twitter and AWS API keys [3],
according to a security research ﬁrm that reverse-engineered
approximately 16K Android apps. Secrets in software artifacts
(CWE-798: Use of Hard-coded Credentials [4]) have also
been identiﬁed as a CWE Top 25 Most Dangerous Software
Weaknesses [5].

The presence of software secrets in VCS repositories neces-
sitates the integration of adequate secret management practices
for secure development. However, such integration may be
difﬁcult due to the lack of a comprehensive set of practices
related to managing secrets. For example, developers seem
to query online forums to ﬁnd the best practices for storing
secrets [6]. Secret management practices can be derived sys-
tematically to help practitioners in limiting the exposure of
secrets. In addition, the derived set of practices can be utilized
by practitioners as a comparison point for their existing secret
management practices.

Analyzing Internet artifacts, such as blog articles and online
forum question and answer (Q&A) posts, is one way to derive
secret management practices in software artifacts. In previous
studies,
the importance of Internet artifacts has also been
recognized in determining security practices [7], [8].

The goal of our paper is to aid practitioners in avoiding
the exposure of secrets by identifying secret management
practices in software artifacts through a systematic derivation
of practices disseminated in Internet artifacts.

We answer the following research question: RQ: What are
the practices used by practitioners for secret management
in software artifacts?

We conducted a grey literature review [9] and collected 54
Internet artifacts, such as blog articles and Q&A posts. From
the collected Internet artifacts, we conducted a qualitative
analysis approach called open coding [10] and determined
practices that are speciﬁc to secret management in software
artifacts.

Our contribution is a set of practices that practitioners can

follow to avoid exposure of secrets in software artifacts.

The rest of our paper is structured as follows: The method-
ology used in our work is described in Section II. We provide
our ﬁndings in Section III. Section IV summarizes previous
research ﬁndings that are pertinent to our paper. The implica-
tions and limitations of our paper are addressed in Section V
Finally, Section VI draws the paper’s conclusion.

II. METHODOLOGY

To identify practices used by practitioners for secret man-
agement in software artifacts, two authors conduct a grey
literature review independently. Grey literature is deﬁned as
“... literature that is not formally published in sources, such as
books or journal articles” [9]. A grey literature review differs
from a systematic literature review (SLR) or a systematic

 
 
 
 
 
 
Fig. 1. An overview of our grey literature review methodology.

mapping study (SMS) as researchers leverage peer-reviewed
literature indexed in scholar databases in the case of SLR or
SMS. Grey literature review, on the other hand, makes use
of non peer-reviewed artifacts such as online videos, blog
articles, and Q&A posts that are available on the Internet [11].
Grey literature provides better coverage of emerging research
topics [7], [12]. We are inspired by academics who have
analyzed Internet artifacts to determine security practices that
can be used in the software development process [7], [8]. We
hypothesize that by collecting and analyzing Internet artifacts
systematically, we can ﬁnd practices for secret management
in software artifacts.

Figure 1 shows a summary of our grey literature review
methodology. The following is a breakdown of each stage in
our methodology.

A. Search Internet Artifacts

Using a set of search strings, we collect Internet artifacts.
As our research study focuses on the practices for managing
secrets in software artifacts, we begin with the search string
“practice for managing secrets in source code”. Next, we
choose the top 100 results determined by Google search
engine’s page rank algorithm as a search stopping criteria [12]
and collect the results. We observe practitioners referring to
“secrets” as “credentials”, “passwords” and “sensitive informa-
tion” based on a manual examination of the 100 search results.
Based on the observations above, we include these keywords
as part of the search construction process and conduct our
search procedure using four search strings, which are stated
below:

• practice for managing secrets in source code
• practice for managing credentials in source code
• practice for managing passwords in source code
• practice for managing sensitive information in source

code

Altogether, we collect 400 Internet artifacts, 100 for each
of the four search strings. To avoid a conﬂict with the authors’

Fig. 2. Application of inclusion criteria on our grey literature dataset to collect
the set of 54 Internet artifacts that we use in our study. Grey literature dataset
is available online [13].

browsing history, we search in incognito mode of the Google
Chrome browser.

B. Apply Inclusion Criteria

To ﬁnd Internet artifacts relevant to our research study, we

use the following inclusion criteria:

• The artifact is not a duplicate of another artifact;
• The artifact is available for reading;
• The artifact is written in English; and
• The artifact discusses at least one practice for secret

management in software artifacts

We determine 54 Internet artifacts after applying the inclu-
sion criteria. Three Q&A posts and 51 blog articles comprise
our collection of 54 Internet artifacts. Figure 2 depicts a
detailed breakdown of our ﬁltering procedure.

C. Find Secret Management Practices

We apply open coding [10] to our collected grey literature
artifacts. Open coding is a qualitative analysis technique that
can reveal the underlying theme from unstructured textual
information [10]. Open coding is widely utilized to identify
patterns from Internet artifacts [7], [14]. The ﬁrst and second
authors review each Internet artifact and extract the stated
practices as part of the open coding process. After the ﬁrst
and second authors ﬁnish their open coding individually, the
identiﬁed practices are cross-checked by both authors. We use
a negotiated agreement [15] to resolve the disagreed-upon
is an approach to discuss
practices. Negotiated agreement
the disagreements among the raters in an effort to resolve
disagreements when two or more raters code the same artifacts
[15]. We resolve disagreements either by discarding practices

Search Internet Artifacts (Google Search)Apply Inclusion CriteriaOpen CodingFind Secret Management PracticesNon-Duplicate :  258Duplicate-based filteringAvailable:  251Search Result:  400Availability-based filteringWritten in English: 250English-based filteringMention of Practice: 54Practice-based filteringFinal Set: 54that are not suitable for managing secrets or combining similar
practices into one practice. We group each identiﬁed practice
into a category that solves a speciﬁc issue of secret man-
agement, such as developer practices for avoiding accidental
secrets commit or organizational practices to enforce policies
for secrets protection.

III. RESULTS

Based on our ﬁndings, we identiﬁed 24 practices classiﬁed
into six categories. In the following subsections, we provide
the details of the identiﬁed practices of each of the six
categories and the number of Internet artifacts that discuss
the practices. For example, the ‘Practices for Keeping Secrets
Out of Source Code (OSC)’ category has four practices, and
18 of the 54 Internet artifacts mention the ‘OSC-1: Use Local
Environment Variables’ practice.

A. Practices for Keeping Secrets Out of Source Code (OSC)

Beyond allowing developers to set permissions on their
accounts, VCS does not ensure the security of secrets to
remain in a secured and controlled environment. Practitioners
recommend the below four practices to keep secrets out of
source code or VCS repositories.

1) OSC-1: Use Local Environment Variables (18): Local
environment variables, which are dynamic objects deﬁned
outside of the application and used to avoid storing secrets in
VCS or conﬁguration (conﬁg) ﬁles, are recommended by prac-
titioners. The Twelve-Factor App methodology [16] is a set
of 12 language-agnostic guidelines for building software-as-a-
service applications with portability and resilience. The third
factor, Conﬁg principle of the Twelve-Factor App method-
ology, also states that conﬁg information should be kept as
environment variables and injected into the application at
runtime [16]. Libraries, such as dotenv [17], can be used
to load variables into the running process. Without modify-
ing any code, environment variables can easily be changed
between released versions. On the other hand, practitioners
also advise avoiding local environment variables for client-
side applications as secrets can be extracted using the browser
dev tools [18].

2) OSC-2: Move Secrets to Conﬁguration File (15):
Practitioners recommend moving secrets to external conﬁg
ﬁles such as web.config and config.yaml ﬁles. Conﬁg
ﬁles are environment-speciﬁc and can be updated at any
time without redeploying the application, as the lifecycle
is independent of the application. Instead of checking the
original conﬁg ﬁle into VCS, developers are suggested to
add a template conﬁg ﬁle. The template conﬁg ﬁles such
as database.sample.yaml ﬁle of Ruby on Rails and
web.default.config ﬁle of ASP.NET will contain min-
imum conﬁgurations with dummy values which developers
will replace in their development environment. Using template
conﬁg ﬁles reduces the chance of secrets being checked into
VCS, thus preventing potential secret exposure.

3) OSC-3: Ignore Sensitive Files (11): Practitioners rec-
ommend to avoid committing sensitive ﬁles, such as .env and
.conﬁg ﬁles, into VCS repositories. Even a .DS_Store (a
hidden ﬁle present in every folder on an OS X system) can
leak the names of the ﬁles and folders present on a web
server. A search on GitHub for .DS_Store returns more
than 800K results [19]. To avoid committing sensitive ﬁles,
all repositories should include a .gitignore ﬁle. GitHub
has published a collection of useful .gitignore templates
for different technologies [20].

4) OSC-4: Add Server-Side Implementation for Client-Side
Applications (2): Secrets present in client-side applications,
such as Javascript and Android applications, can be exposed
by the developer console or by decompiling the binary ﬁles
(APK or iPA ﬁles) [3]. To avoid keeping secrets in client-
side applications for fetching data from different web services,
practitioners recommend implementing the web service func-
tionality on the server-side. The server will use the appropriate
secrets and fetch data for the client-side, thus removing the
necessity to keep secrets in client-side applications.

B. Practices for Securely Storing Secrets (SSC)

Developers can store secrets insecurely in source code or
VCS repositories. Practitioners recommend the following three
practices to store secrets securely.

1) SSC-1: Use External Secret Management Systems (28):
As emails can be forwarded and messaging applications
can be hacked, practitioners recommend to avoid sending
secrets through emails or any messaging applications, such
as Microsoft Teams or Slack. Only one compromised account
is enough to expose sensitive data. When secrets are ex-
changed through internal networks, bad actors can use secrets
to migrate laterally between services. Instead, practitioners
recommend to use external secret management systems, such
as HashiCorp Vault [21], AWS KMS [22] and Knox [23].
These hardware security modules can safely store secrets
with tightly-controlled access. Developers can be assigned to
groups based on the teams they work on, and secrets can be
shared with the groups by granting proper permissions. If any
developer switches teams or leaves the company, the secrets
used by the developer can easily be invalidated using external
secret management systems. The ability to set up dynamic
secrets, lease-based secret management (limiting access for
a ﬁxed period before automatic revocation), and audit trails,
which allow administrators to check for any breaches, are other
important features. The ability to rotate secrets over time by
giving speciﬁc states for secret versions is a unique feature of
Knox that is not found in other systems. A secret version can
be tagged as ‘primary’ to denote that the secret is the current
recommended, ‘active’ to denote that the secret is still usable,
or ‘inactive’ to denote that the secret is disabled. Administra-
tors can use this mechanism to roll secrets across machines
without impacting the service. External secret management
systems minimize human involvement in creating, distribut-
ing, and maintaining secrets. Practitioners have recommended
SSC-1 practice the most among all the practices for managing

secrets, though a signiﬁcant investment of time and money is
needed.

2) SSC-2: Store Encrypted Secrets (14): Practitioners rec-
ommend avoiding Base64 encoding of secrets as encoded
secrets can be decoded easily. Instead, for a project having
a single developer or a small
team, practitioners suggest
encrypting secrets-containing ﬁles in VCS. Several tools such
as git-crypt [24] and git-secret [25] which use GPG
to encrypt content are available for encrypting sensitive ﬁles
containing secrets. Technologies, such as Ruby on Rails,
starting with Version 5.1, have included built-in capabilities
to encrypt secrets with VCS [26]. Though developers have
to manage encryption keys securely (keep out of VCS) and
no role-based access control of secrets is present, the beneﬁt
of using encryption tools is that the implementation does not
need additional infrastructure.

3) SSC-3: Private Repositories Are Not Safe (2): One
practitioner stated: “A secret
in a private repo is like a
password written on a $20 bill, you might trust the person
you gave it to, but that bill can end up in hundreds of peoples
hands as a part of multiple transactions and within multiple
cash registers” [27]. Since repositories can be forked into new
projects and cloned onto new machines, secrets present in the
history of a repository will be propagated to the forked and
cloned repositories. Only one compromised developer account
or a misconﬁguration will be enough to get access to all
secrets present in private repositories. For example, in 2021,
a repository misconﬁguration of setting the default username
and password combination of admin/admin resulted in
Nissan source code being exposed online [28].

C. Practices to Limit Secrets Exposure (LSE)

Practitioners recommend below four practices to limit the

exposure of secrets.

1) LSE-1: Use Short-lived Secrets (15): Short-lived secrets,
according to practitioners, prevent previously-undetected data
breaches from becoming a threat by terminating access even
if the breach is not identiﬁed. If a validity period cannot be
assigned to secrets, practitioners advise revoking and redis-
tributing the secrets periodically. Practitioners also suggest
rotating and redistributing the secrets correctly to avoid any
failure. For example, in 2021, Microsoft Azure experienced a
14-hour downtime due to an error in secret rotation used for
authentication [29].

2) LSE-2: Restrict API Access and Permissions (8):
Because attackers frequently use secrets within their scope,
detecting when they are doing so maliciously may be challeng-
ing. Practitioners suggest that damage and lateral movement
can be limited by restricting access and permissions to secrets.
For example, a leaked AWS S3 key, which had the permission
to spin up AWS EC2 instances, resulted in a $6000 bill
overnight as an attacker spun up 140 instances [30]. IP white-
listing adds another degree of protection against attackers who
try to exploit APIs maliciously. For example, GitHub IP white-
listing [31] can be employed to restrict insecure sources from
accessing the repositories. External service users can set API

key usage restrictions by making API keys accessible from
speciﬁc URLs. The key will be useless to the attacker if the
attacker cannot invoke the service from the allowed URLs. A
daily limit on API key usage should also be set to avoid bill
spikes.

3) LSE-3: Revoke Secrets and Sanitize VCS History (6):
Secrets will not be removed entirely by removing them in
another commit, as secrets will remain in the VCS history.
Practitioners advise sanitizing VCS history in two steps.
The ﬁrst step is to revoke the secrets present in the code.
The second step is to purge and rewrite the VCS history
using tools such as git-filter-branch [32], BFG repo
cleaner [33], or git-filter-repo [34]. GitHub docu-
mentation [35] suggests using BFG repo cleaner instead
of other tools. To avoid anomalies, the best practice is to close
all pull requests before scanning VCS history using the tools.
GitHub suggests contacting them with the repository name to
clear the secrets from their cache and advised to tell the project
collaborators to do git rebase instead of git merge as
merge can introduce some of the tainted history [35].

4) LSE-4: Audit All Code Uploaded to VCS and Review
VCS Audit Logs for Suspicious Activity (4): Practitioners
recommend auditing all code uploaded to VCS on a regular
basis. For example, legacy code may be used as part of an
organization’s new software. The problem with integrating
legacy code is that what was once secure might not be
anymore, as secrets may be present in legacy code. Therefore,
auditing any code uploaded to VCS will be advantageous
for the software’s long-term integrity, even if the procedure
is time-consuming. The administrator of an organization can
also review the activities of other team members using the
audit log feature of VCS. Suspicious activities can be ﬂagged
and tracked by constructing a trace proﬁle based on the user’s
activity, the action’s location, and the time of the event. For
example, GitLab [36] provide the archive of audit logs where
the admin can search for events between any period or any
speciﬁc user action.

D. Practices for Avoiding Accidental Secrets Commit (ASC)

Developers can accidentally push secrets into VCS repos-
itories. Practitioners recommend the below three practices to
avoid accidental committing of secrets.

1) ASC-1: Use VCS Scan Tools (16): Though code reviews
can detect logical ﬂaws and maintain coding practices, prac-
titioners do not recommend relying on code reviews to detect
secrets. If secrets are added in one commit and removed in
another commit, the net difference in code changes will be
zero. The reviewer only sees the net difference, but secrets
will remain in the VCS history, thus allowing an attacker to
ﬁnd secrets from the prior revisions. Practitioners recommend
running VCS scan tools such as TruffleHog [37], Gitrob
[38] and git-all-secrets [39] in the VCS repository to
ﬁnd out the presence of secrets. Via a pre-commit hook,
VCS scan tools can reject any commit containing secrets that
manual searches and reviews will miss. VCS scan tools can
also ﬁnd secrets buried in logs and histories. VCS scan tools

are also recommended to use with continuous integration or
continuous deployment (CI/CD) pipelines to actively break
build/deploy when secrets are found in source code. Practi-
tioners also mention that VCS scan tools will return a lot of
false positives, which developers will need to ﬁlter manually
[40].

2) ASC-2: Add Files to the Staging Area Explicitly (5): One
simple practice suggested by practitioners to avoid exposing
secrets accidentally is to add ﬁles explicitly in the VCS staging
area. Developers should avoid using wildcard commands (git
add -A, git add . and git add *) when adding ﬁles
to have full control over what is committed. One practitioner
also suggested: “Committing early and committing often will
not only help navigate ﬁle history and break up otherwise
large tasks, in addition it will reduce the temptation to use
wildcard commands.” [27].

3) ASC-3: Use VCS Hooks to Check Files Prior to
Committing (5): To prevent secrets from pushing into VCS
repositories, practitioners advise implementing VCS hooks
[41] which allow scripts to be executed before or after a
speciﬁc action in the VCS repository. The pre-commit and
post-commit hooks can be used to ﬁlter and smudge secrets
before commit or after pull, respectively [42]. Each contributor
to the VCS repository needs to set up VCS hooks individually.
According to practitioners, VCS hook scripts need extra effort
to write properly since putting all of the secret behavior in the
script is challenging.

E. Practices for Managing Secrets in Deployment (MSD)

Developers can expose secrets during deployment. Practi-
tioners recommend the following four practices to manage
secrets in deployment securely.

1) MSD-1: Use Secret Variables in CI/CD (6): Practitioners
recommend removing hard-coded secrets from CI/CD scripts,
and use the secret variables of the build/deploy systems, such
as Heroku [43] and Azure Pipeline [44]. VCS such as
GitHub [45] and GitLab [46] have also secret variables which
can be used in the CI/CD pipeline. The secret variables are
set as environment variables in the deployment environment
and hidden from any logs. Practitioners also suggest keeping
secret variables settings disabled for pull requests to avoid
inadvertently passing secrets during builds for pull requests.
2) MSD-2: Use Conﬁguration Management Systems (4):
The conﬁgurations of different machines are coordinated
by Conﬁguration Management System (CMS) tools from
a centralized location. Practitioners recommend using se-
cret management systems supported by CMS tools, such
as Chef-Vault [47] and Ansible-Vault [48]. Using
shared secrets, these CMS tools keep secrets out of revision
history and from other machines. Secrets can be distributed to
speciﬁc machines using the same mechanism which ensures
each machine receives the correct conﬁguration.

3) MSD-3: Use Different Secrets for Each Environment
(3): Practitioners recommend to avoid using the same secrets
for multiple environments so that exposure to the secrets of
one environment does not compromise other environments.

The secrets of production environments should be different
from development or pre-production environments. Practition-
ers also recommend keeping production environment secrets
limited to a small set of owners to avoid the risk of failure.

4) MSD-4: Keep Dot Files out of Root Directory (2): Dur-
ing deployment, practitioners recommend keeping dot ﬁles,
such as .git, .gitignore and .env ﬁles, out of the root
directory. Proper access restrictions should be applied to dot
ﬁles on production servers to avoid exposing secrets [49]. If
the .git folder is not kept out of the root directory, then the
whole history of committed changes will be exposed to the
attacker. Previous research [2] has also found secrets in the
.gitignore ﬁle despite the .gitignore ﬁle is designed
to restrict unintended source ﬁles committing into VCS.

F. Organizational Practices to Enforce Policies for Secrets
Protection (OEP)

Organizations can adopt general practices to enforce policies
in VCS for developers. These general practices can minimize
vulnerabilities which in turn helps in avoiding exposure of
secrets. Practitioners recommend the below six practices for
enforcing policies.

1) OEP-1: Tightly Manage Developer Permissions (6):
According to practitioners, organizations should follow the
principle of least privilege. Organizations should not give
developers more permissions than the required scope, such as
changing repository visibility and adding external contributors.
If the repository contains secrets, the more developers who
have permission to change the visibility of the repository,
the higher the risk of failure. For example, GitHub has
organization-level settings to restrict the ability to change the
visibility of the repository to anyone with admin access or
organization owners [50]. One practitioner stated: “The higher
the turnover of external contributors, the higher the security
risks” [51]. External contributors can be strictly managed to
reduce the number of redundant developers and their access
to the repositories. Limiting access and permission-granting
privileges to organization owners is one way to handle external
contributors. For example, GitHub has organization-level set-
tings for allowing the permission to add external contributors
to the organization owners only [52].

2) OEP-2: Enforce Two-Factor Authentication (6): To pre-
vent source code leakage via insecure developer accounts,
practitioners recommend enforcing two-factor authentication
(2FA). When logging into VCS, such as GitLab and GitHub,
2FA provides an added layer of security which can be enforced
through organization-level settings [53], [54].

3) OEP-3: Require Commit Signing (3): A malicious user
can push exploitable code into VCS by pretending to be
someone else and remain untraceable by altering the username
and email address in the git config. For veriﬁcation and
traceability of code merge, commit signing [55], which is a
cryptographic code-signing technique, can be used. Commit
signing is done through GPG, and the signed commit gets
a ‘veriﬁed’ badge. A malicious user’s commit can easily be
traced as the commit will not have a ‘veriﬁed’ badge.

4) OEP-4: Add a security.md File (3): Practitioners recom-
mend adding a security.md ﬁle [56] in a VCS repository
to ofﬁcially document security-related processes and proce-
dures, such as token accessibility, authentication requirements,
and vulnerability reporting. The security.md ﬁle can serve
as a helpful reference for developers as well as a centralized
space for the organization’s security expectations.

5) OEP-5: Implement Single Sign-On (2): SAML single
sign-on (SSO) [57] is a VCS feature practitioners recommend.
Access to VCS resources, such as speciﬁc repositories and pull
requests, can be managed by explicitly providing permissions
to resources by leveraging SAML SSO. SAML SSO also
allows to set up of approved identity providers, which enables
the organization to force the developers to sign in using
the organization’s accounts instead of privately-owned VCS
accounts [57].

6) OEP-6: Disable Forking (1): A Git feature called fork-
ing allows a developer to duplicate a repository and is useful
for testing and sandboxing. However, practitioners recommend
to disable forking. A fork can reveal secrets to the public
though the repository is originally private. With each fork,
the risk grows exponentially, resulting in a chain of security
vulnerabilities. For example, GitHub has organization-level
settings to disallow forking of repositories [58].

IV. RELATED WORK

Prior work has found that root causes for widespread secret
leakage were insecure developer practices, such as embed-
ding hard-coded credentials [59], [60], organizational issues
inﬂuencing software security vulnerabilities [40], [61]–[63],
and compromising security for functionality when managing
software dependencies [64]. Researchers have looked into
instances of such insecure developer practices within open-
source projects [2], [65], [66]. Researchers have discovered
hard-coded secrets as a very common development practice
which has resulted in thousands of repositories on open-source
coding platforms, such as GitHub and OpenStack, leaking
hard-coded secrets [2], [66], [67]. Within Infrastructure as
Code (IaC) scripts, Rahman et al. [67]–[69] looked for security
smells, which are repeating coding patterns that indicate a
security ﬂaw. Results from Rahman’s work conclude that
developers commonly commit multiple security smells within
their development practices, and hard-coded credential is the
most occurring smell. In another study, Rahman et al. [7]
analyzed Internet artifacts and identiﬁed 12 secret management
practices related to IaC. The mentioned practices for IaC, such
as separation of vaults from VCS and secret rotation, relate
to the ‘Ignore Sensitive Files (OSC-3)’ and ‘Use Short-lived
Secrets (LSE-1)’ practices, respectively. We take motivation
from the aforementioned studies and concentrate our research
efforts on ﬁnding secret management practices for software
artifacts in general, instead of speciﬁc technology such as IaC.

V. DISCUSSION

In this section, we discuss the implications and limitations

of our paper.

Implication for Practitioners: Our derivation indicates how
secrets should be kept out of source code or VCS to avoid
being exposed. Insufﬁcient application of practices related to
secret management can result in unfavorable outcomes. The
identiﬁed practices can help practitioners manage secrets in
software artifacts and act as a comparison point for practition-
ers with their existing secret management practices.
Implications for Researchers and Tool Developers: Further
research can be conducted in the ﬁeld of secret management
by leveraging our ﬁndings. For example, researchers can
look into how many of the practices speciﬁed in Section
III are followed in commercial and open-source software.
We hypothesize that systematic follow of secret management
practices is not prevalent based on the presence of secrets in
software artifacts. If empirical studies support our hypothesis,
researchers can look into the contributing factors to ignoring
secret management practices. Our ﬁndings will also assist
tool developers in determining whether to create new tools
or improve existing ones to help practitioners manage secrets
more effectively. The false-positive rate of VCS scan tools, for
example, can be improved.
Limitations: Since the identiﬁed practices are bound to the
Internet artifacts which we analyzed in our study, our ﬁndings
are subject to external validity and may not generalize to
another collection of Internet artifacts. We account for the
constraint by employing four search strings to collect and ﬁlter
Internet artifacts in a systematic way. Manual analysis may
induce bias while identifying practices. We account for this
bias by adding a second rater who identiﬁed practices from
the same set of Internet artifacts independently. Finally, the
sets of practices of each rater are cross-checked to mitigate
bias.

VI. CONCLUSION

In addition to users, software also relies heavily on the
use of secrets for authentication and authorization, and the
exposure of secrets is increasing each day. The presence of
secrets in software artifacts substantiates the practitioner’s lack
of knowledge on securely managing secrets. A set of secret
management practices can help practitioners avoid exposing
secrets in software artifacts. To identify practices for secret
management in software artifacts, we conducted a grey lit-
erature review of 54 Internet artifacts. Our analysis identi-
ﬁed 24 practices grouped into six categories and comprised
of developer and organizational practices. According to our
ﬁndings, the most recommended practices for moving secrets
out of source code and securely storing secrets include using
local environment variables (OSC-1) and external secret man-
agement services (SSC-1). We also observed that using VCS
scan tools (ASC-1) and employing short-lived secrets (LSE-
1) are the most recommended practices to avoid accidentally
committing secrets and limit secrets exposure. Our ﬁndings
can also be beneﬁcial for researchers and tool developers who
can investigate how the secret management process can be
enhanced to facilitate secure development.

ACKNOWLEDGMENT

[22] “AWS Key Management Service,” https://aws.amazon.com/kms, [On-

This work was supported by the National Science Founda-
tion grant 2055554. The authors would also like to thank the
North Carolina State University Realsearch research group for
their valuable input on this paper.

REFERENCES

[1] T. Segura, “The State of Secrets Sprawl 2022,” https://blog.gitguardian.
[Online; accessed May 19,

\com/the-state-of-secrets-sprawl-2022,
2022].

[2] M. Meli, M. R. McNiece, and B. Reaves, “How bad can it git?
characterizing secret leakage in public github repositories.” in NDSS,
2019.

[3] S. Nichols, “Popular mobile apps

leaking aws keys, exposing
user data,” https://www.techtarget.com/searchsecurity/news/252500361/
Popular-mobile-apps-leaking-AWS-keys-exposing-user-data,
[Online;
accessed March 25, 2022].

[4] “CWE: Common Weakness Enumeration,” https://cwe.mitre.org/data/

def\initions/798.html, [Online; accessed April 28, 2022].

[5] “2021 CWE Top 25 Most Dangerous Software Weaknesses,” https://cwe.
\mitre.org/top25/archive/2021/2021 cwe top25.html, [Online; accessed
May 16, 2022].

[6] “Best practice for storing sensitive connection data when connecting to
a db,” https://stackoverﬂow.com/questions/66070209, [Online; accessed
May 16, 2022].

[7] A. Rahman, F. L. Barsha, and P. Morrison, “Shhh!: 12 practices for
secret management in infrastructure as code,” in 2021 IEEE Secure
Development Conference (SecDev), 2021, pp. 56–62.

[8] A. A. U. Rahman and L. Williams, “Software security in devops: Syn-
thesizing practitioners’ perceptions and practices,” in 2016 IEEE/ACM
International Workshop on Continuous Software Evolution and Delivery
(CSED), 2016, pp. 70–76.

[9] C. Lefebvre, E. Manheimer, and J. Glanville, Searching for Studies.
John Wiley & Sons, Ltd, 2008, ch. 6, pp. 95–150. [Online]. Available:
https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470712184.ch6

[10] J. Salda˜na, The coding manual for qualitative researchers, 2015.
[11] V. Garousi, M. Felderer, M. V. M¨antyl¨a, and A. Rainer, Beneﬁtting
from the Grey Literature in Software Engineering Research. Cham:
Springer
[Online].
International Publishing, 2020, pp. 385–413.
Available: https://doi.org/10.1007/978-3-030-32489-6 14

[12] V. Garousi, M. Felderer, and M. V. M¨antyl¨a, “Guidelines for including
grey literature and conducting multivocal literature reviews in software
engineering,” Information and Software Technology, vol. 106, pp.
101–121, 2019.
[Online]. Available: https://www.sciencedirect.com/
science/article/pii/S0950584918301939
review dataset,”
Secret-Management-Practices-Grey-Literature-Review-Dataset,
[Online; accessed August 23, 2022].

https://github.com/setu1421/

[13] “Grey

literature

[14] M. M. Hasan, F. A. Bhuiyan, and A. Rahman, “Testing practices
for infrastructure as code,” ser. LANGETI 2020. New York, NY,
USA: Association for Computing Machinery, 2020, p. 7–12. [Online].
Available: https://doi.org/10.1145/3416504.3424334

[15] J. L. Campbell, C. Quincy, J. Osserman, and O. K. Pedersen, “Coding in-
depth semistructured interviews: Problems of unitization and intercoder
reliability and agreement,” Sociological Methods & Research, vol. 42,
no. 3, pp. 294–320, 2013.

[16] “The Twelve-Factor App,” https://12factor.net/conﬁg, [Online; accessed

April 22, 2022].

[17] “dotenv,” https://www.npmjs.com/package/dotenv,

[Online; accessed

[18] P.

April 22, 2022].
Adajah,
in

“Best
frontend

secrets
best-practices-for-managing-and-storing-secrets-in-frontend-development,
[Online; accessed April 22, 2022].

development,”

for managing

storing
and
https://blog.logrocket.com/

practices

[19] “Scanning the alexa top 1m for .ds store ﬁles,” https://en.internetwache\
.org/scanning-the-alexa-top-1m-for-ds-store-ﬁles-12-03-2018, [Online;
accessed April 20, 2022].

[20] “Gitignore templates,” https://github.com/github/gitignore, [Online; ac-

cessed April 13, 2022].

[21] “HashiCorp Vault,” https://www.vaultproject.io,

[Online;

accessed

March 3, 2022].

line; accessed March 3, 2022].

[23] “Pinterest Knox,” https://github.com/pinterest/knox, [Online; accessed

March 3, 2022].

[24] “git-crypt,”

https://github.com/AGWA/git-crypt,

[Online;

accessed

March 23, 2022].

[25] “git-secret,” https://github.com/sobolevn/git-secret,

[Online; accessed

March 23, 2022].

[26] “Ruby on rails 5.1 release notes,” https://edgeguides.rubyonrails.org/5

1\ release notes.html, [Online; accessed April 21, 2022].

[27] M. Jackson, Best practices for managing and storing secrets in-
cluding API keys and other credentials, https://blog.gitguardian.com/
secrets-api-management.

Cimpanu,
repo

[28] C.
git
nissan-source-code-leaked-online-after-git-repo-misconﬁguration,
[Online; accessed April 12, 2022].

after
https://www.zdnet.com/article/

“Nissan
source
misconﬁguration,”

leaked

online

code

[29] A.

Hernandez,

“What

azure

crosoft
what-do-we-know-about-microsoft-azure-outage,
April 20, 2022].

do
outage?”

we

about

know
the mi-
https://www.venaﬁ.com/blog/
accessed
[Online;

[30] S. Gooding,

result

“Ryan

hellyer’s

access
in a $6,000 bill overnight,” https://wptavern.com/

keys
ryan-hellyers-aws-nightmare-leaked-access-keys-result-in-a-6000-bill-overnight,
[Online; accessed March 19, 2022].
your

nightmare: Leaked

organization

https://docs.

aws

[31] “Keeping

secure,”
github.com/en/enterpris\e-cloud@latest/organizations/
keeping-your-organization-secure,
2022].

[Online;

accessed March

18,

[32] “Git ﬁlter branch,” https://git-scm.com/docs/git-ﬁlter-branch, [Online;

accessed April 7, 2022].

[33] “BFG Repo Cleaner,” https://rtyley.github.io/bfg-repo-cleaner, [Online;

accessed April 7, 2022].

[34] “Git ﬁlter repo,” https://github.com/newren/git-ﬁlter-repo, [Online; ac-

cessed April 29, 2022].

[35] “Removing sensitive data from a repository,” https://docs.github.

com/en/\authentication/keeping-your-account-and-data-secure/
removing-sensitive-data-from-a-repository, [Online; accessed April 10,
2022].

[36] “Audit events,” https://docs.gitlab.com/ee/administration/audit events.

ht\ml, [Online; accessed May 13, 2022].

[37] “TrufﬂeHog,” https://github.com/trufﬂesecurity/trufﬂeHog, [Online; ac-

cessed March 23, 2022].

[38] “Gitrob,” https://github.com/michenriksen/gitrob,

[Online;

accessed

March 23, 2022].

[39] “git-all-secrets,” https://github.com/anshumanbh/git-all-secrets, [Online;

accessed March 23, 2022].

[40] M. R. Rahman, N. Imtiaz, M.-A. Storey, and L. Williams, “Why secret
detection tools are not enough: It’s not just about false positives-an
industrial case study,” Empirical Software Engineering, vol. 27, no. 3,
pp. 1–29, 2022.

[41] “Git

Hooks,”

https://git-scm.com/book/en/v2/

Customizing-Git-Git-Hooks, [Online; accessed March 21, 2022].
[42] “Smudge and clean your git working directory,” https://www.atlassian.
[Online; accessed March

\com/git/tutorials/saving-changes/gitignore,
21, 2022].

[43] “Heroku Conﬁg Vars,” https://devcenter.heroku.com/articles/conﬁg-vars,

[Online; accessed March 17, 2022].

[45] “GitHub

[44] “Azure Pipeline Variables,” https://docs.microsoft.com/en-us/azure/
devo\ps/pipelines/process/variables, [Online; accessed March 17, 2022].
https://docs.github.com/en/actions/
security-guides/encrypted-secrets, [Online; accessed March 17, 2022].
https://docs.microsoft.com/en-us/azure/
accessed March 17,

[46] “GitLab CI/CD variables,”

Encrypted

secrets,”

[Online;

devop\s/pipelines/process/variables,
2022].

[47] “Chef Vault,” https://docs.chef.io/workstation/chef vault, [Online; ac-

cessed March 15, 2022].

[48] “Ansible Vault,” https://docs.ansible.com/ansible/latest/cli/ansible-vault.

\html, [Online; accessed March 15, 2022].

[49] “Source code disclosure via exposed .git folder,” https://pentester.land/

\tutorials/2018/10/25/source-code-disclosure-via-exposed-git-folder.
html, [Online; accessed March 10, 2022].

[50] “Restricting repository visibility changes in your organization,” https:
//docs.github.com/en/organizations/managing-organization-settings\
/restricting-repository-visibility-changes-in-your-organization, [Online;
accessed April 08, 2022].

[51] “Security best practices for GitHub,” https://spectralops.io/resources/ho\

w-to-choose-a-secret-scanning-solution-to-protect-credentials-in-your-c\
ode, [Online; accessed March 23, 2022].
permissions

[52] “Setting
rators,”
latest/organizations/managing-organization\-settings/
setting-permissions-for-adding-outside-collaborators, [Online; accessed
May 08, 2022].

collabo-
https://docs.gith\ub.com/en/enterprise-cloud@

outside

adding

for

[53] “Requiring two-factor authentication in your organization,” https:
//docs.\github.com/en/organizations/keeping-your-organization-secure/
managin\g-two-factor-authentication-for-your-organization/
requiring-two-factor-authentication-in-your-organization,
accessed May 04, 2022].

[Online;

[54] “Enforce two-factor authentication,” https://docs.gitlab.com/ee/security/
\two factor authentication.html, [Online; accessed May 04, 2022].
[55] “Managing commit signature veriﬁcation,” https://docs.github.com/en/
[Online; ac-

au\thentication/managing-commit-signature-veriﬁcation,
cessed May 14, 2022].

[56] “Adding

a

security

policy

to

your

repository,”

https://docs.github.com/en\/code-security/getting-started/
adding-a-security-policy-to-your-repositor\y,
May 03, 2022].

[Online;

accessed

[57] “About

authentication

sign-
SAML
https://docs.github\.com/en/enterprise-cloud@latest/

single

with

on,”
authentication/authenticating-with-sam\l-single-sign-on/
about-authentication-with-saml-single-sign-on,
May 05, 2022].
the

forking

policy

your

for

[58] “Managing

organization,”

https:

[Online;

accessed

//docs.githu\b.com/en/organizations/managing-organization-settings/
managing-the-fo\rking-policy-for-your-organization, [Online; accessed
April 19, 2022].

[59] E.

Montalbano,

Medical

Due
medical-data-leaked-on-github-due-to-developer-errors/158653.

Developer

to

Data
Errors,

Leaked

on

GitHub
https://threatpost.com/

[60] J. Ursem and DataBreaches.net, No

hack when
https://www.databreaches.net/wp-content/uploads/

need

to

it’s
No-need-to-hack-when-its-leaking.pdf.

leaking,

[61] H. Assal and S. Chiasson, “’think secure from the beginning’ a survey
with software developers,” in Proceedings of the 2019 CHI conference
on human factors in computing systems, 2019, pp. 1–13.

[62] J. Xie, H. R. Lipford, and B. Chu, “Why do programmers make security
errors?” in 2011 IEEE symposium on visual languages and human-
centric computing (VL/HCC).

IEEE, 2011, pp. 161–164.

[63] S. Nadi, S. Kr¨uger, M. Mezini, and E. Bodden, “Jumping through hoops:
Why do java developers struggle with cryptography apis?” in Proceed-
ings of the 38th International Conference on Software Engineering,
2016, pp. 935–946.

[64] I. Pashchenko, D.-L. Vu, and F. Massacci, “A qualitative study of de-
pendency management and its security implications,” in Proceedings of
the 2020 ACM SIGSAC Conference on Computer and Communications
Security, 2020, pp. 1513–1531.

[65] V. S. Sinha, D. Saha, P. Dhoolia, R. Padhye, and S. Mani, “Detecting
and mitigating secret-key leaks in source code repositories,” in 2015
IEEE/ACM 12th Working Conference on Mining Software Repositories,
2015, pp. 396–400.

[66] M. R. Rahman, A. Rahman, and L. Williams, “Share, but be aware:
Security smells in python gists,” in 2019 IEEE International Conference
on Software Maintenance and Evolution (ICSME).
IEEE, 2019, pp.
536–540.

[67] A. Rahman and L. Williams, “Different kind of smells: Security smells
in infrastructure as code scripts,” IEEE Security & Privacy, vol. 19,
no. 3, pp. 33–41, 2021.

[68] A. Rahman, C. Parnin, and L. Williams, “The seven sins: Security smells
in infrastructure as code scripts,” in 2019 IEEE/ACM 41st International
Conference on Software Engineering (ICSE).
IEEE, 2019, pp. 164–175.
[69] A. Rahman, M. R. Rahman, C. Parnin, and L. Williams, “Security smells
in ansible and chef scripts: A replication study,” ACM Transactions on
Software Engineering and Methodology (TOSEM), vol. 30, no. 1, pp.
1–31, 2021.

