2
2
0
2

y
a
M
3
2

]
E
S
.
s
c
[

1
v
3
2
0
1
1
.
5
0
2
2
:
v
i
X
r
a

AdaptivePaste: Code Adaptation through Learning
Semantics-aware Variable Usage Representations

Xiaoyu Liu
Microsoft
Redmond, WA, USA

Jinu Jang
Microsoft
Redmond, WA, USA

Neel Sundaresan
Microsoft
Redmond, WA, USA

Miltiadis Allamanis
Microsoft Research
Cambridge, UK

Alexey Svyatkovskiy
Microsoft
Redmond, WA, USA

ABSTRACT
In software development, it is common for programmers to copy-
paste code snippets and then adapt them to their use case. This
scenario motivates code adaptation task ‚Äì a variant of program
repair which aims to adapt all variable identifiers in a pasted snippet
of code to the surrounding, preexisting source code. Nevertheless,
no existing approach have been shown to effectively address this
task. In this paper, we introduce AdaptivePaste, a learning-based
approach to source code adaptation, based on the transformer model
and a dedicated dataflow-aware deobfuscation pre-training task to
learn meaningful representations of variable usage patterns. We
evaluate AdaptivePaste on a dataset of code snippets in Python.
Evaluation results suggest that our model can learn to adapt copy-
pasted code with 79.8% accuracy.

KEYWORDS
Variable usage representation, neural networks, code adaptation

ACM Reference Format:
Xiaoyu Liu, Jinu Jang, Neel Sundaresan, Miltiadis Allamanis, and Alexey
Svyatkovskiy. 2022. AdaptivePaste: Code Adaptation through Learning
Semantics-aware Variable Usage Representations. In Proceedings of ACM
Conference (Conference‚Äô17). ACM, New York, NY, USA, 11 pages. https:
//doi.org/10.1145/nnnnnnn.nnnnnnn

1 INTRODUCTION
Knowledge reuse through adapting source code from Stack Over-
flow and GitHub is very common among software developers. In-
deed, according to a study [1], one out of every four users visiting
a Stack Overflow question copies something within five minutes
of hitting the page. That adds up to 2.9 million copies across half a
million posts and comments on average every day. While standing
on the shoulders of giants and adapting and reusing code from the
web, developers may still introduce compilation issues, bugs, or
even security issues into their code when copying-pasting [28]. One
common code adaptation scenario is to manually rename variables

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
Conference‚Äô17, July 2017, Washington, DC, USA
¬© 2022 Association for Computing Machinery.
ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn

in the copied snippet to align them with the surrounding context.
Automatically adapting the copy-pasted code using AI could reduce
errors and relieve developers from the effort required.

Code adaptation is a variant of bug detection and repair tasks,
which aims to intelligently adjust a given (pasted) snippet to pre-
existing partially written program [4]. An example bug that may
emerge as a result of copy-pasting is a variable misuse bug [33].
To resolve it manually, a software developer would have to find
program locations where buggy variables are used and guess the
correct variable names for the identified locations. There are nu-
merous systems [5, 6, 20, 33] proposed to tackle variable misuse
problem with machine learning. These approaches focus on classi-
fying the variable locations as faulty or correct and then replacing
the faulty variables through a joint prediction of classification, lo-
calization and repair [33] or an enumerative prediction of each
buggy location [5]. Unfortunately, none of these approaches takes
programming language semantics, especially the long-range depen-
dencies of variables usages, into consideration.

In this paper, we propose AdaptivePaste: a code adaptation sys-
tem based on the transformer neural network that adjusts pasted
code to the surrounding code context. Given a preexisting partially
written program and a code snippet copied from an external source ‚Äì
for instance, Stack Overflow or list of suggestions by IntelliCode AI
‚Äì AdaptivePaste performs program analysis and obfuscates source
code identifiers in a pasted code snippet in a dataflow-sensitive way,
and learns to predict a mapping of obfuscated (masked) variables
to the target names via self-supervised translation. Inspired by re-
cent success of transformers [19, 34], we implement AdaptivePaste
in two variants: a traditional encoder-decoder transformer, and a
multi-decoder transformer model architecture.

The paper contributions are as follows: (i) we formulate a learning-
based approach to source code adaptation and introduce Adap-
tivePaste, a transformer-based model with a uni-decoder variant
as well as a multi-decoder variant, (ii) we introduce a specialized
dataflow-aware deobfuscation pre-training objective, a variant of
DOBF for pasted code snippet adaptation, (iii) we evaluate Adap-
tivePaste on a dataset of code snippets in Python and show that
our model achieves a 79.8% accuracy of adapting copy-pasted code,
beating existing state-of-the-art models, and (iv) we show the perfor-
mance of AdaptivePaste as a pre-training objective by fine-tuning
the trained model on multiple downstream code intelligence tasks.

 
 
 
 
 
 
Conference‚Äô17, July 2017, Washington, DC, USA

Xiaoyu Liu, Jinu Jang, Neel Sundaresan, Miltiadis Allamanis, and Alexey Svyatkovskiy

2 MOTIVATING EXAMPLE
To provide an intuition about how our code adaptation approach
works and to define the core concepts, we begin with a motivating
example of two code copy-paste scenarios.

In code adaptation problem, pasted code snippet may be a piece
of code copied from a website (e.g. StackOverflow), a code search
retrieval tool, or from an existing project, pasted into an existing
context snippet. In a pasted code snippet, we distinguish two kinds
of variables to be adapted: (i) bound variables ‚Äì identifiers defined in
the preexisting code context in the scope of the pasted code snippet,
and (ii) free variables ‚Äì identifiers that are defined and used inside
of the pasted code snippet.

Context snippet contains a number of variables/symbols ùëâ =
{ùë£ùëñ }. The pasted snippet uses and defines a set of variables ùêµ =
{ùõΩ ùëó }. The AdaptivePaste task is to create an injective mapping
A : ùêµ ‚Üí ùëâ ‚à™ Œ£ that maps each variable in the pasted snippet to
either a unique symbol ùë£ùëñ in the context or a declares this as new
variable Œ£, not currently defined1. Every A (ùõΩ ùëó ) ‚àà ùëâ is a variable
bound to the context, whereas if A (ùõΩ ùëó ) ‚àà Œ£ it is a free variable.
Note, that for semantic correctness A must only correctly map the
bound variables. AdaptivePaste can be seen as the task of correctly
‚Äúwiring‚Äù the pasted snippet into the context.

Figure 1 shows an example of pasting a code snippet recom-
mended by an AI-based search retrieval tool2, into a source code
file actively developed by a software engineer. As shown in Figure 1,
a code snippet suggestion served by IntelliCode API Usage Example
extension (right) is copy-pasted as is into the source code file (left),
pasted region highlighted in red square. In the pasted code shown in
upper left sub-figure of Figure 1, values of four method arguments
(self.introspector.parameters(), self.config.lr1, self.
config.weight_decay1, self.config.milestones) are not de-
fined in the existing context, resulting in a syntactically incorrect
code that would not run. Indeed, the traditional code search tools
only focus on the relevance of retrieved code to a query provided
by a user failing to adapt the code to the preexisting surrounding
context. The lower left sub-figure of Figure 1 displays the same
example scenario, but with AdaptivePaste re-wiring the pasted code
snippet to form a syntactically and semantically correct program
given the preexisting context.

To properly adapt and re-wire the pasted code snippet in the
example shown in Figure 1, developers would need to understand
the context code semantics, access the code dependencies carefully
and choose from local declared variable candidates wisely. One can
easily miss crucial information and ignore renaming, for example,
self.introspector.parameters() to
optimizer_grouped_parameters in Figure 1. How can we ensure
all relevant structural and semantic information in the context code
are properly considered for code adaptation?

Motivated by the fact that developers carefully declare variables
with proper names that precisely describe the purpose they fulfill,
we propose code adaptation through learning semantics-aware vari-
able usage using AdaptivePaste, in which we model the surrounding
context to learn to prioritize the code snippets fulfilling the same
intent as the target variable over other source code content.

3 DATASET
We collect the dataset from publicly available open source non-fork
GitHub repositories with at least 20 stars. To ensure the quality of
the dataset, we follow the same constraints and rules from [17] to
further filter out collected repositories. For example, we require
each project should be used by at least one other project. In addition,
we filtered out all unit test files and short code files with less than
three lines of code. Overall, we collect 4.3 √ó 106 files, which include
1.4 √ó 109 lines of code, across 238 √ó 103 repos.

For model training and evaluation, we randomly split the dataset
into training set, validation set and test set in the proportion 80-
10-10 on the repository level. Samples for each set were extracted
by randomly selecting ‚Äúpastable‚Äù blocks, which are defined as se-
quences of code statements that are reusable after adaptation, from
each method. Pastable blocks are identified by traversing through
the code blocks in CST. Specifically, while traversing syntax trees
of source code files, a series of statements is extracted when non-
terminal nodes of the LibCST3 grammar of the following types are
encountered : Module, SimpleStatementSuite,
SimpleStatementLine, IndentedBlock, If, With, For, While, Else,
Try, Finally, ExceptHandler. To mimic the common cases of past-
ing code snippets from popular resources such as Stack Overflow,
we set the max number of lines of code in a pastable block to 6. In
summary, we extract 29,176,497 pastable snippet samples for model
training and 1,774,995 samples for model evaluation.

4 BASELINE MODELS
In this section, we present two baseline models that we implemented
for controlled experiments around code adaptation.

4.1 Masked Language Modeling for Code

Adaptation

The Masked Language Modeling (MLM) pre-training objective
involves recovering the original document given the corrupted
one [15]. We choose MLM as our baseline because it allows to for-
mulate code adaptation task as masked token infilling given the
surrounding left and right contexts.

Model Training We utilize the standard MLM objective, in
which a fraction of tokens from the original sequence is selected
uniformly at random and replaced with [MASK] symbol, disregard-
ing the token lexical types. Which results in masking not only
identifier names, but also delimiters, and programming language
keywords. The fraction of meaningful code tokens masked by the
MLM objective is 80%, which means that the remaining 20% of the
code tokens will stay unchanged. We train a RoBERTa model [23]
having 12 layers in the encoder, 12 attention heads and a hidden
dimension of 768.

Recovering Identifier Names During the inference, the MLM
for code adaptation model predicts each masked identifier name
independently. Then for each pasted code snippet, all the results
are summarized into a dictionary mapping masks to recovered
identifier names.

1We assume that Œ£ contains all valid variable names not in the context.
2Visual Studio IntelliCode API Usage Example extension []

3https://github.com/Instagram/LibCST

AdaptivePaste: Code Adaptation through Learning Semantics-aware Variable Usage Representations

Conference‚Äô17, July 2017, Washington, DC, USA

Figure 1: An illustration of two copy-paste scenarios when developing software: (right) method suggested by IntelliCode API
Usage Example extension, (left) code snippet pasted into a preexisting context without adaptation (upper left) and after adap-
tation (lower left).

4.2 DOBF Model
Recent research [21] shows that self-supervised pre-training objec-
tive for programming languages based on deobfuscation (DOBF)
achieves superior results on multiple tasks such as code search,
code summarization, and unsupervised code translation, as com-
pared to BERT [23] and BART [22] models, pre-trained with natural
language specific denoising objectives. We utilize the DOBF model
for code adaptation task as our baseline.

Model Training DOBF leverages the particular structure of
programming languages, which is achieved by obfuscating code
snippets by replacing class, function and variable names with cor-
responding special symbols: CLASS_NN, FUNC_NN, and VAR_NN, in
which NN is a unique number. Then a DOBF model is trained to
recover the original names of these special symbols. The DOBF
model for code adaptation is a sequence-to-sequence transformer

model, composed of 6 encoder and 6 decoder layers. It has 8 atten-
tion heads for both encoder and decoder. It is trained to translate
an obfuscated code snippet represented as a sequence of tokens
with masks into a dictionary mapping of predefined mask symbols
to recovered original names.

Identifier Deobfuscation At inference time, the model sug-
gests meaningful names for the obfuscated class, function, and
variables in pasted code. The output is serialized as a sequence of
tokens where entries are separated by a delimiter symbol ‚Äú|". As a
final step, entries in the output are postprocessed into a dictionary
of masks to identifier name mappings.

...classModel():deftrain(self, model, lr, weight_decay):no_decay = ["bias", "LayerNorm.weight"]optimizer_grouped_parameters = [{"params": [p forn, p inmodel.named_parameters() if not any(nd inn fornd inno_decay)], "weight_decay": weight_decay,}, ]optimizer = AdamW(self.introspector.parameters,lr=self.config.lr1,weight_decay=self.config.weight_decay1)scheduler = get_cosine_schedule_with_warmup(optimizer, self.config.step_size)  # Example 2 out of 3defconfigure_optimizer(self):    optimizer = AdamW( self.introspector.parameters,          lr=self.config.lr1,          weight_decay=   self.config.weight_decay1    )    scheduler =  get_cosine_schedule_with_warmup(     optimizer,        self.config.step_size          )return [optimizer], [scheduler]...classModel():deftrain(self, model, lr, weight_decay):no_decay = ["bias", "LayerNorm.weight"]optimizer_grouped_parameters = [{"params": [p forn, p inmodel.named_parameters() if not any(nd inn fornd inno_decay)], "weight_decay": weight_decay,}, ]optimizer = AdamW(optimizer_grouped_parameters,lr=lr,weight_decay=weight_decay)scheduler = get_cosine_schedule_with_warmup(optimizer,self.step_size)     Conference‚Äô17, July 2017, Washington, DC, USA

Xiaoyu Liu, Jinu Jang, Neel Sundaresan, Miltiadis Allamanis, and Alexey Svyatkovskiy

5 ADAPTIVEPASTE: NEURAL MODEL FOR

CODE ADAPTATION

In this section we introduce AdaptivePaste ‚Äì a transformer-based
model for code adaptation task. Given a partially written preex-
isting context snippet and a code snippet copied from an external
source, it tries to re-wire the pasted snippet to form a syntactically
and semantically correct program. The key technical innovation
around AdaptivePaste is twofold: (1) the model is trained with
a dedicated dataflow-aware deobfuscation pre-training objective,
and (2) it introduces a multi-decoder transformer model variant
that decodes masked symbols independently. In addition to using
a traditional transformer encoder-decoder model, namely Adap-
tivePaste uni-decoder (AP-uni), the AdaptivePaste multi-decoder
(AP-multi) variant allows to encode context snippets once but de-
code a target mapping for each adapted variable independently, to
leverage ‚Äúdefine-use‚Äù relationships across masked symbols. Figure 2
illustrates the architecture of AdaptivePaste.

5.1 Adaptive Paste Training
Since there is no large (supervised) dataset that matches the task,
we propose a self-supervised training objective. Given some preex-
isting code, (e.g. a file from an open-source project) we randomly
pick one or more contiguous statements as the pasted snippet, and
anonymize all occurrences of a variable within the snippet to an un-
informative name of the form ___vNN, where NN is a unique number.
Note that this anonymization preserves the data-flow relationships
within the pasted snippet. The surrounding code becomes the con-
text and remains unchanged. Finally, we train the model to match
the anonymized variables to those defined in the original code. This
self-supervised setting allows us to create a large training dataset
required by modern transformers.

Variables in pasted code can be subdivided into two broad cate-

gories:

(1) Bound variables: symbols used or defined in the context

falling in the scope of the pasted snippet.

(2) Free variables: identifiers that are defined and used exclu-
sively inside the pasted code snippet. These variables could
arguably be named to an arbitrary non-conflicting name
without changing semantics. However, AdaptivePaste aims
to predict a descriptive, useful variable name following best
coding practices.

Figure 2 illustrates the learning task: a pasted code snippet is
anonymized by renaming the variables declared in the context block
(x, x_recon) and free variables declared outside the block (recon_n,
loss) with the symbols ___v11, ___v51, ___v122, ___v131.

Technical Details. Specifically, during the process of traversing
the syntax tree of the pasted snippet, when the visited CST node is
a variable declared in the class scope, which is the usual case in vari-
able usage, the name of the corresponding node is obfuscated. We
assign mask symbols at a granularity of lexical code tokens, which
may map to multiple BPE subtokens. Differently from DOBF [21],
the surrounding preexisting code context is not anonymized, which
allows the model to attend to the existing identifier names that are
defined in scope. Indeed, our analysis shows that in 77.1% of the
cases bound variables are called to in pasted snippets, serving as

targets of deobfuscation. Besides that, we do not encode lexical type
information into masks since in some programming languages, like
Python, types of variables are dynamic. We randomize the order
of masks, to prevent the model from memorizing the order and
numerics but apply obfuscation noise preserving data-flow. One
important distinction from the standard masked language modeling
(MLM) objective is each mask can appear multiple times throughout
the input sequence, which makes this learning task quite different
from the standard NLP.

5.2 Neural Model Architecture
5.2.1 Uni-decoder Transformer. Traditional transformer [34] has a
single decoder composed of multiple layers of multi-headed self-
attention and cross-attention blocks followed by a two-layer multi-
layer perceptron (MLP), as shown in Figure 3a. In a machine trans-
lation setting, an input sequence is encoded by the encoder and is
attended to by the cross-attention block of the decoder.

The uni-decoder model follows a standard autoregressive de-
coder formulation. Given an input sequence composed of the con-
text snippet and an anonymized pasted snippet, the task for the
model is to learn an injective mapping A : ùêµ ‚Üí ùëâ ‚à™ Œ£ that maps
each variable in the pasted snippet to a unique symbol in the context
or a declares a new variable not currently defined. The learnt map-
ping, ùë¶ = A (ùë•), is represented as a string of the following format:
‚Äù___v31 weight_decay | ___v40 scheduler | ___v27optimizer‚Äù.
The uni-decoder models the following probability distribution:
ùëÉ (ùë¶ùëñ ; E (ùë•), ùë¶ùëñ‚àí1), ùëñ = 1...ùëÅ ,

(1)

where ùëÅ is the number of symbols to de-anonymize.

5.2.2 Multi-decoder Transformer. While the uni-decoder model
allows us to de-anonymize all variables jointly, it does not calculate
an individual probability for each symbol, i.e., in the uni-decoder
model the probability of the name of each symbol is conditioned on
the ones predicted before. Thus we cannot estimate the uncertainty
of de-anonymizing any particular symbol. For example in Figure 2,
de-anonymizing might be straightforward for all symbols except
from ___v122. However, the uni-decoder model would assign a low
probability to the entire output sequence. To alleviate this problem,
we propose a multi-decoder model ‚Äì a variant of the multi-decoder
transformer [19] ‚Äì which creates a copy of the decoder (with shared
weights) for each anonymized symbol in the anonymized pasted
snippet. Then, each decoder predicts a name independently from
the rest, factorizing the output distribution per-symbol.

Specifically, as shown in Fig. 3b, the multi-decoder consists of a
standard encoder E encoding the input sequence ùë• once (as in the
uni-decoder model). Then, for each sample we spawn ùëÅ decoders
(where ùëÅ is the number of distinct anonymized symbols in an input
ùë•) tasked with de-anonymizing each symbol independently. In lieu
of the standard start-of-sequence token, each decoder accepts as
initial input the name of the anonymized symbol that it should
predict. This factorized the output probability distribution as

ùëÅ
(cid:214)

ùëñ=1

ùëÉ (ùë¶ùëñ ; E (ùë•), ùë£ùëéùëüùëñ ),

(2)

where ùëÅ is the number of symbols being de-anonymized. Finally,
note that due to the quadratic compute and memory performance

AdaptivePaste: Code Adaptation through Learning Semantics-aware Variable Usage Representations

Conference‚Äô17, July 2017, Washington, DC, USA

Figure 2: An overview of AdaptivePaste architecture: We start with extracting extended context and local context by travers-
ing through the terminal nodes of CST tree and prioritizing class-level and method-level syntactic elements; Next, in local
context pasted code is anonymized by replacing the variables with a set of pre-defined placeholder identifiers; Then, extended
context and local context are concatenated and tokenized before being sent to pre-trained AdaptivePaste for code adaptation
prediction; The output of AdaptivePaste is serialized as a sequence of tokens with entries separated by a delimiter symbol ‚Äú|‚Äù

(a) Uni-Decoder: A traditional encoder-decoder transformer gener-
ates a single sequence with the predicted names of the anonymized
variables.

(b) Multi-Decoder: Multiple weight-tied decoders are instan-
tiated and each accepts as initial input the target variable to
predict.

Figure 3: Transformer model architectures for Adap-
tivePaste.

the multi-decoder model has a reduced memory footprint compared
to the uni decoder (O (ùëõùëò2) vs O (ùëõ2ùëò2) where ùëõ is the number of
anonymized variables and ùëò is the size of the longest sequence of
subtokens), since the predicted sequences are shorter and there is
no attention among them.

5.3 Context Prioritization and Anonymization
The input to the model is a source code file with preexisting code
and a pasted code snippet. And the output is a mapping of mask
symbols to predicted names. Since transformers have a quadratic
performance with respect to the sequence length, we shorten the
context relevant by utilizing eWASH [13]. This prioritizes syntax
hierarchies which are most relevant to the pasted snippet region.
Extracting syntactic hierarchies from the entire source code files,
as opposed to the tokens immediately preceding the pasted snippet
location, we are able to retain bound variables, such as class-level
fields and method arguments, which are highly relevant for de-
anonymizing variables in the pasted code snippet. Starting with a
concrete syntax tree of a source file, we organize and prioritize class-
level and method-level syntactic elements such as global import
statements and assigned values, class attributes, method signatures,
class docstring, and global expressions in the input. A special sym-
bol ‚Äú..." is introduced to denote locations in the code where syntax
hierarchies are truncated.

Finally, we assign anonymized symbols as special symbols where
all other code tokens and whitespace maps to one or more BPE
subtokens. In practice, we use Hugging Face‚Äôs byte-level BPE tok-
enizer4.

4https://huggingface.co/docs/transformers/tokenizer_summary#bytelevel-bpe

___v131recon_n___v51x___v122loss___v11x_reconExternal Code Database:StackOverflow, IntelliCode AIProgram with Pasted RegionData Flow AnalysiseWASH Context ExtractionPasted Snippet ObfuscationNeural ModelPredicted Mappingimporttorchimporttorch.nn.functional asF...defrecon_loss(x, x_recon):___v131 = ___v51.size(0)___v122 = F.foo(___v11, ___v51)return___v122  importtorchimporttorch.nn.functional asF...defrecon_loss(x, x_recon):recon_n = x.size(0)loss= F.foo(x_recon, x)returnlossx1x4x6recon_n3x_recon2x_recon5loss7loss8EncoderDecoderCross Attention___v31 weight_decay___v40 scheduler ___v27 optimizer<s>EncoderDecoderDecoderDecoderCross Attention___v27___v40___v31‚Ä¶weight_decayscheduleroptimizerConference‚Äô17, July 2017, Washington, DC, USA

Xiaoyu Liu, Jinu Jang, Neel Sundaresan, Miltiadis Allamanis, and Alexey Svyatkovskiy

6 IMPLEMENTATION DETAILS
The offline training module of AdaptivePaste is implemented in
Python, which makes use of CUDA 11.4, GPU accelerated library
of primitives from CuDNN 8.2, Pytorch 1.10.0 and NVIDIA col-
lective communication library (NCCL). The model is trained on 6
STANDARD_NC24rs_v3 Azure Virtual Machines5 managed with
Kubernetes, each having 8 V100 GPUs with 32GB memory.

During model training, a large number of parameters are learnt .
These number of parameters scales quadratically with the number
of hidden units of transformer blocks. Both the best performing
AdaptivePaste uni-decoder and multi-decoder models have 16 lay-
ers, including 8 encoder transformer blocks and 8 decoder trans-
former blocks. Each encoder/decoder block has 8 attention heads.
The vocabulary size of BPE tokenizer is 50000. The dimension of
embedding space is 512. The model is trained using zero redun-
dancy optimizer [27] with Adam stochastic optimization. The base
learning rate is 5 √ó 10‚àí5 and cumulative batch size is 288.

7 RESEARCH QUESTIONS
RQ1. How effective is AdaptivePaste in adapting pasted code
snippets?

We evaluate AdaptivePaste‚Äôs code adaptation performance in
terms of the exact string match accuracy of adapted code snippet
to the ground truth and a less restrictive semantic validity metric.
We also provide a comparison AdaptivePaste to baseline MLM and
DOBF approaches.

RQ2. Can we improve the accuracy of AdaptivePaste by

introducing a confidence threshold on its predictions?

We perform a systematic study of the AdaptivePaste uni-decoder
and multi-decoder model predictions as a function of the confidence
threshold to determine if it can improve code adaptation quality,
and result in higher accuracy and semantic validity metrics. We ex-
pect low confidence predictions to be of low quality or break pasted
snippet semantics. To estimate its potential effect, we have mea-
sured the model performance in 20 equal-sized confidence threshold
bins.

RQ3. How AdaptivePaste performs on bound variables and

free variables?

We investigate how effective is AdaptivePaste in predicting vari-
able names of each variable category (bound and free). For this
purpose, we estimate a per-variable de-anonymization accuracy
and estimate how often does the model predict a variable category
(bound of free) correctly. More specifically, we estimate a fraction
of correctly predicted bound variables, fraction of bound variables
predicted as bound, and repeat this for the free variable category.
In addition, we also investigate if we can improve the accuracy on
bound variables and free variables by sacrificing recall. To achieve
this goal, we follow the same steps and adopt the same range of
thresholds presented in RQ2.

RQ4. How AdaptivePaste perform on downstream code

model on three tasks from CodeXGLUE [24], a standard benchmark
for code intelligence.

8 EVALUATION
8.1 Evaluation Metrics
To assess code adaptation performance, we identify two evaluation
metrics:

‚Ä¢ Accuracy of the exact string match of the adapted code snip-
pet prediction as compared to the ground truth (user code),
and

‚Ä¢ ValidPaste: a fraction of the semantically valid paste instances,
which measures the percentage of predicted code snippets
with all bound variables de-anonymized correctly.

Among the two metrics, the exact match accuracy is stricter, as
it measures both the correctness of identifier adaptations which are
defined in the preexisting context snippet as well as the exact nam-
ing of new variables declared in the pasted snippet. Fortunately, the
latter does not affect the semantics correctness of the source code,
and renaming the variables declared and used in a pasted snippet
arbitrarily would keep the paste instance semantically equivalent.
In addition to the above evaluation metrics which are calculated
per pasted code snippet, we calculate per-variable accuracy of de-
anonymization ‚Äì VarAcc, and the accuracy of predicting the variable
category (bound or free) ‚Äì CatAcc.

Finally, given that each anonymization symbol ___vNN in the
pasted snippet may to a code token composed of multiple subtokens
which only differ by the casing conventions (i.e. camelCase versus
snake_case), we consider a casing-insensitive evaluation metrics.
Namely, average harmonic mean of the precision6 and recall7 for
retrieving the original case-insensitive free variable subtokens (Avg.
F1-Subtoken). Free variable subtokens are determined by break-
ing the corresponding free variable name into subtokens using
uppercase letters for camelCase and underscores for snake_case.

AdaptivePaste

Baselines

Multi-Decoder Uni-Decoder

DOBF-Adapt MLM-Adapt

Accuracy
ValidPaste

63.9%
79.0%

67.8%
83.9%

22.3%
34.7%

22.5%
29.7%

Table 1: AdaptivePaste and baseline models evaluated in
terms of top-1 accuracy of code snippet adaptation and the
fraction of semantically valid paste instances.

8.2 Results
In this section we discuss the results of our proposed research
questions.

RQ1. How effective is AdaptivePaste in adapting pasted

intelligence tasks?

code snippets?

One of the technical innovations of the AdaptivePaste is its
self-supervised pretraining objective. To evaluate the power of the
AdaptivePaste pre-training objective, we fine-tune AdaptivePaste

5https://docs.microsoft.com/en-us/azure/virtual-machines/ncv3-series

As seen in Table 1, both AdaptivePaste model variants beat base-
lines across all the evaluation metrics. Especially the uni-decoder

6Percentage of predicted free variable subtokens are correct with respect to the ground
truth
7Percentage of actual free variable subtokens are predicted as correct

AdaptivePaste: Code Adaptation through Learning Semantics-aware Variable Usage Representations

Conference‚Äô17, July 2017, Washington, DC, USA

(a) Accuracy vs. Pct. of Variables Making Suggestions

(b) ValidPaste vs. Pct. of Variables Making Suggestions

Figure 4: Comparing AdaptivePaste multi-decoder model (AP-multi) with AdaptivePaste uni-decoder model (AP-uni) in an
offline evaluation of exact match accuracy (Accuracy) and percentage of valid paste (ValidPaste) after ùë°‚Ñéùëüùëíùë†‚Ñéùëúùëôùëëùë† ‚àà [0.7, 0.985]
applied. Regarding the evaluation of Accuracy, AdaptivePaste multi-decoder model benefits most from thresholds with much
more accurate predictions and slightly lower percentage of variables making suggestions. Meanwhile, AdaptivePaste multi-
decoder model achieves much higher ValidPaste with comparatively more compromise in percentage of variables making
suggestions.

(a) VarAcc of Predicted Bound Variables vs.
Thresholds

(b) VarAcc of Predicted Free Variables vs.
Thresholds

(c) Avg. F1-subtoken of Free Variables vs.
Thresholds

Figure 5: Comparing AdaptivePaste multi-decoder model (AP-multi) with AdaptivePaste uni-decoder model (AP-uni) in an
offline evaluation of bound variables and free variables adaptation after ùë°‚Ñéùëüùëíùë†‚Ñéùëúùëôùëëùë† ‚àà [0.7, 0.985] applied. Consistent with
Figure 4, AdaptivePaste multi-decoder model benefits most from thresholds with more accurate prediction, especially we
observe more accurately adapted free variables.

model, which achieves 67.8% accuracy of code adaptation surpass-
ing the best performing baseline (MLM) by 45.3%. Furthermore, it
exceeds the best baseline results in terms of the ValidPaste met-
ric, which measures the percentage of semantically valid paste
instances, achieved by the DOBF for code adaptation model, by
49.2% at 83.9%.

RQ2. Can we improve the accuracy of AdaptivePaste by

introducing a confidence threshold on its predictions?

To perform this study, we exponentiated the log-probability
scores of output sequences generated by AdaptivePaste to fit them
into the 0 to 1 probability range. For the multi-decoder model
variant each adapted variable gets a unique confidence score, while
the uni-decoder model variant assigns a single confidence score
to all the adapted variables in a given sample. Our analysis shows

that in 89% of the adapted variables have scored in the range of
0.7‚Äî0.985, which was selected as a probability range in which this
study was performed.

To better evaluate whether certain thresholds can improve the
performance of code adaption, we compute the exact match accu-
racy (accuracy) as well as the ValidPaste, as described in Section 7,
at thresholds in the range of 0.7-0.985. Figure 4a shows the accuracy
versus the percentage of variables making suggestions as threshold
increases. It is clear that as the threshold increases, AdaptivePaste
models predict more accurately adapted pasted code snippets. Es-
pecially AdaptivePaste multi-decoder variant achieves larger in-
creases in accuracy with slightly lower percentage of variables
have suggestions, so that the thresholds appear most beneficial for
AdaptivePaste multi-decoder variant.

Conference‚Äô17, July 2017, Washington, DC, USA

Xiaoyu Liu, Jinu Jang, Neel Sundaresan, Miltiadis Allamanis, and Alexey Svyatkovskiy

AdaptivePaste Variants

Multi-Decoder Uni-Decoder

Both Variable Categories

VarAcc

77.6

Bound Variable Adaptation

VarAcc
CatAcc

88.3
97.1

Free Variable Adaptation

VarAcc
CatAcc

41.7
88.1

Per Free Variable Adaptation

Avg. F1-Subtoken(%)

48.4

79.8

89.9
96.7

45.4
91.5

51.6

Table 2: Evaluation of AdaptivePaste model variants in
terms of per-variable top-1 accuracy of de-anonymization
(VarAcc) and the top-1 accuracy of predicting the variable
category (CatAcc).

Figure 4b shows the ValidPaste vs. percentage of variables mak-
ing suggestions by the same range of thresholds to test how much
they can improve the prediction of valid pastes. We see the same
overall benefits of thresholds in AdaptivePaste, and particularly
even more improvements in AdaptivePaste multi-decoder variant
with, however, more loss in percentage of adapted variables is
observed. This interesting observation supports our hypothesis
that thresholds are beneficial to AdaptivePaste code adaptation.
Especially for multi-decoder variant, which thresholds can help to
boost with predicting a more accurately adapted code but more
compromise in percentage of adaptable variables adapted.

RQ3. How AdaptivePaste performs on bound variables and

free variables?

As the answer to RQ1 suggests that before thresholds are applied
on both AdaptivePaste variants, AdaptivePaste uni-decoder model
can predict more accurate pasted code. To gain additional insights,
we report the performance in terms of adapting different type of
variables (i.e., bound variables and free variables) separately. To
do so, in addition to Accuracy and ValidPaste, Table 2 reports the
evaluation results of proposed metrics for bound variables and free
variables before any threshold is applied.

First, we find that in terms of de-anonymizing both categories of
variables, AdaptivePaste uni-decoder model (column "Uni-Decoder")
predicts more accurate variables names as exact at 79.8%. This ob-
served results are reported under the ‚ÄúBoth Variable Categories‚Äù
row in Table 2.

Second, we compare AdaptivePaste performance on only bound
variables, which account for 77.1% of the total adapted variables in
our dataset. The results of their dedicated evaluation metrics are
shown under the ‚ÄúPer bound Variable‚Äù row in Table 2. As we can see,
AdaptivePaste uni-decoder model (column "Uni-Decoder") predicts

more bound variables as exact at 89.9%, while AdaptivePaste multi-
decoder model (column "Multi-Decoder") predicts more bound vari-
ables as bound at 97.1%. Meanwhile, the performance of both Adap-
tivePaste variants on bound variables are quite comparable with
the improvements at 1.6% at most.

Third, the performance on only free variables, evaluated in three
dedicated metrics, are reported in Table 2 under the ‚ÄúPer Free Vari-
able‚Äù row and ‚ÄúPer Free Variable Adaptation‚Äù row. As the results
show, AdaptivePaste uni-decoder model not only adapts more ex-
actly matched free variables at 45.4%, but also predicts more free
variables as not bound variables at 91.5%, which is 2.4% better than
its multi-decoder variant. Moreover, due to the nature of free vari-
able that they are not included in the context for code adaptation,
we are also interested in how accurate per each predicted free
variable. The results of "F1-subtoken" suggests that AdaptivePaste
uni-decoder can predict more partially matched free variables at
51.6%.

Since thresholds have positive impact on the performance of
AdaptivePaste code adaptation, we further expand this study for
more insights on whether thresholds can help AdaptivePaste to
adapt more bound variables and free variables correctly. Figure 5
shows that thresholds can significantly improve the prediction ac-
curacy on both types of variables. Particularly, Figure 5a shows
that AdaptivePaste multi-decoder variant can predict more accurate
bound variables than uni-decoder variant. More encouragingly, Fig-
ure 5 shows that thresholds can significantly improves the VarAcc
of free variables (5b) and average F1-subtoken of predicted free
variables (5c). Especially, thresholds improves the performance of
AdaptivePaste multi-decoder variant even more as VarAcc of free
variables are improved to 65% with average F1-subtoken scored at
67.5% when threshold=0.8, which is 15% and 11.3% better than the
uni-decoder variant. respectively.

In summary, before thresholds are applied, AdaptivePaste unit-
decoder variant achieves better performance in adapting both free
variables and bound variables. After thresholds are applied, Adap-
tivePaste multi-decoder benefits most by predicting more accurate
free and bound variables. Especially when adapting free variables,
thresholds significantly boost the performance of AdaptivePaste
multi-decoder by achieving as much as 15% more accurate cases
than uni-decoder variant.

Code Summarization NL Code Search
(MRR)

(BLEU)

Transformer
MLM
CodeBERT
GraphCodeBERT
DOBF

AdaptivePaste

16.43 %
17.95 %
18.22 %
18.51 %
18.24 %

18.52%

0.025
0.308
0.315
0.377
0.383

0.161

Table 3: Results on CodeXGLUE downstream tasks for Adap-
tivePaste and baseline models. Model pre-trained with Adap-
tivePaste outperforms all baselines on code summarization
task but falls behind on NL code search task.

AdaptivePaste: Code Adaptation through Learning Semantics-aware Variable Usage Representations

Conference‚Äô17, July 2017, Washington, DC, USA

RQ4. How AdaptivePaste performs on downstream code

intelligence tasks?

Given AdaptivePaste is pre-trained on dataset of code snippets
in Python, the following tasks are chosen for which the training
sets, validation sets and test sets in Python are publicly available:

‚Ä¢ CodeXGLUE Code Summarization: In this task, the model is
trained to generate natural language comments for a given
code snippet. To perform this task, we fine-tune the entire
AdaptivePaste model with the given training set and then
evaluate the fine-tuned model on the provided test set using
BLEU score Papineni et al. [25].

‚Ä¢ CodeXGLUE NL Code Search: Given a natural language code
search query, the model has to search through a collection
of code snippets and find the one that is most relevant to the
natural language query. Considering the architecture is a
encoder only transformer-based model, we only fine-tune the
encoders of AdaptivePaste model on the provided training
set to encode natural language query and the candidate code
snippets separately and then compute relevance score of
each candidate code snippet using the dot product between
the first hidden states of the encoders‚Äô last layers. Due to
the ranking nature of NL code search task, we evaluate the
model on the provided test set using the Mean Reciprocal
Rank (MRR) metric.

For baselines, we consider a list of the models which achieved the
best performance in CodeXGLUE tasks, including randomly initial-
ized transformer model, a model pre-trained with MLM only [15],
CodeBERT [17], GraphCodeBERT [18], and DOBF [21]. All baseline
models are pre-trained model that publicly available. Finetuning
and evaluation of the baselines are performed by following the
instructions and scripts provided in the open source reproduction
package8.

The results of pre-training objectives on downstream tasks are
reported in Table 3. Since the AdaptivePaste uni-decoder model
is the best code adaptation performer before any thresholds are
applied, we only use the model pre-trained with AdaptivePaste
uni-decoder architecture in downstream tasks. Table 3 shows that
the model based on AdaptivePaste obtains state-of-the-art results
on code summarization task, outperforming DOBF, GraphCode-
BERT, CodeBERT and MLM, which shows that code summarization
task benefits most from the AdaptivePaste pre-training objective.
Especially, AdaptivePaste beats both DOBF and CodeBERT by a
wide margin, showing that anonymizing all identfiers and natural
language in code snippet are not necessary to train an effective
model on this task. As for NL code search task, the AdaptivePaste
model outperforms transformer-based model with no pre-training,
which suggests that pre-training is particular important for NL code
search task.

9 THREATS TO VALIDITY
Threats to internal validity can occur in our hyperparameter con-
figuration. Due to substantial training time requirement, we didn‚Äôt
perform hyperparameter search. To address this concern, we reuse

8https://github.com/facebookresearch/CodeGen/tree/main/CodeXGLUE

configurations suggested in the literature. In addition, we experi-
ment with multiple AdaptivePaste variants with different model
configurations and report their results.

Threats to external validity concern the generalization of our
findings, which can occur during model comparison with baseline.
To avoid such threats, we train and evaluate both proposed Adap-
tivePaste and baseline models using the same training set and test
set extracted from the same code snippets.

10 RELATED WORK
Our work is related to a broad set literature on code generation,
code deobfuscation, and program repair.

Transformers for Code. Transformer-based pre-training objec-
tives, especially masked language modeling, have shown to be
effective for source code tasks. Feng et al. [17] proposed CodeBERT,
a RoBERTa-based MLM model, to support natural language code
search and code documentation generation. Guo et al. [18] extended
the work by proposing an GraphCodeBERT to predict edges in the
data flow graph. Svyatkovskiy et al. [31] presented GPT-C. which
leveraged generative transformer model trained on source code for
line-level code completion. Clement et al. [12] proposed a Python
method text-to-text transfer transformer model called PyMT5 for
method generation and code summarization. Tufano et al. applied
the state-of-the-art transformer model to learn to generate assert
statements [32]. Chen et al. [11] introduced Codex, which is a GPT
language model fine-tuned on publicly available code from GitHub,
to support developers in tasks such as code completion and method
generation.

Code Deobfuscation. Informative identifier names can make code
more understandable and easier to maintain [10]. This fact moti-
vated researchers to study deobfuscation of identifier names. Al-
lamanis et al. [2, 3] leverage n-gram model to suggest identifier
names such as method and class names. Raychev et al. [29] present
a approach for predicting program properties with a probabilistic
model learnt from massive codebases. Bavishi et al. [9] presents a
recurrent neural networks based technique to infer natural identi-
fier names for minified names. Alon et al. [7] train a Conditional
Random Field with features extracted from Abstract Syntax Tree
(AST) paths to suggest variable and method names. David et al.
[14] use augmented representation obtained from static analysis
to predict procedure names in binary files. Recently, Lachaux et al.
[21] introduce a deobfuscation pre-training objective for program-
ming languages (DOBF) model, which outperforms other approach
in many source code related tasks. None of these work, however,
applied code deobfuscation approach to adapt variable names in
pasted code. Furthermore, our evaluation results show than our pro-
posed AdaptivePaste model outperforms deobfuscation approach
in code adaptation task.

Program Repair and Synthesis. Program repair, especially vari-
able misuse repair, is considered as the most relevant task to code
adaptation. Pradel and Sen [26] propose DeepBugs to use an MLP
over a limited window of code tokens to detect wrong operators,
operands, and argument swappings. Dinella et al. [16] present Hop-
pity to learn to perform graph transformation to replicate code
refactoring, introducing functionality, bug fixing, etc.

Conference‚Äô17, July 2017, Washington, DC, USA

Xiaoyu Liu, Jinu Jang, Neel Sundaresan, Miltiadis Allamanis, and Alexey Svyatkovskiy

There are several approach proposed to tackle variable misuse
bugs. Allamanis and Brockschmidt [4] designed a set of deep neural
models to adapt given snippet to surrounding code. Vasic et al. [33]
propose a joint approach to classify the variable locations as faulty
or correct and then replace the faulty variables. Hellendoorn et al.
[20] aim at variable misuse identification with Graph Relational
Embedding Attention Transformers. Allamanis et al. [6] present
BugLab to co-train a detector to detect as well as repair bugs in
code and a selector to create buggy code for the detector to use
as training data. Even though AdaptivePaste tackles a task sim-
ilar to variable misuse repair, it leverages sequence-to-sequence
with multi-decoder transformer pre-training to learn programming
language semantics, including the long-range dependencies of vari-
ables usages, to adapt variables in pasted snippet of code.

Our work is remotely related to work on program synthesis us-
ing sketches [30] and automated code transplantation [8]. However,
both approaches require specifications (e.g. input-output examples,
test suites) and cannot be used to adapt code statically. These ap-
proaches can be thought as complementary to AdaptivePaste, since
it learns to statically adapt the code.

11 CONCLUSIONS AND FUTURE WORK
In this paper, we introduce AdaptivePaste, a dedicated dataflow-
aware deobfuscation pre-training model, and show that it can learn
meaningful representations of variable usage patterns to adapt all
variable identifiers to the surrounding, preexisting source code.
Both AdaptivePaste variants, AdaptivePaste uni-decoder and Adap-
tivePaste multi-decoder, achieves state-of-the-art performance, out-
performs MLM-based and DOBF-based code adaptation model. Ad-
ditionally, given a pre-selected threshold applied, the Exact Match
of code adaptation can be further improved to as much as around
95% with 25% loss in recall. Furthermore, we demonstrated that
AdaptivePaste is effective as pre-training objectives for other code
intelligence tasks, including code summarization and natural lan-
guage code search. Especially for code summarization task, the
model pre-trained based on AdaptivePaste uni-decoder architec-
ture outperforms DOBF, GraphCodeBERT, CodeBERT and MLM
pre-training models. These results show that AdaptivePaste lever-
ages the variable names anonymization to the input sequence in a
particularly effective way. Future work will investigate additional
objectives such as MLM on docstrings and non-variable identifiers,
which can provide unstructured noise that can be complementary
to code adaptation and other code intelligence tasks.

REFERENCES
[1] 2021. How often do people actually copy and paste from Stack Overflow? Now
we know. https://stackoverflow.blog/2021/12/30/how-often-do-people-actually-
copy-and-paste-from-stack-overflow-now-we-know/

[2] Miltiadis Allamanis, Earl T Barr, Christian Bird, and Charles Sutton. 2014. Learn-
ing natural coding conventions. In Proceedings of the 22nd ACM SIGSOFT Interna-
tional Symposium on Foundations of Software Engineering. 281‚Äì293.

[3] Miltiadis Allamanis, Earl T Barr, Christian Bird, and Charles Sutton. 2015. Sug-
gesting accurate method and class names. In Proceedings of the 2015 10th Joint
Meeting on Foundations of Software Engineering. 38‚Äì49.

[4] Miltiadis Allamanis and Marc Brockschmidt. 2017. Smartpaste: Learning to adapt

source code. arXiv preprint arXiv:1705.07867 (2017).

[5] Miltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. 2018. Learning
to Represent Programs with Graphs. In International Conference on Learning
Representations.

[6] Miltiadis Allamanis, Henry Jackson-Flux, and Marc Brockschmidt. 2021. Self-
Supervised Bug Detection and Repair. Advances in Neural Information Processing

Systems 34 (2021).

[7] Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. 2018. A general path-
based representation for predicting program properties. ACM SIGPLAN Notices
53, 4 (2018), 404‚Äì419.

[8] Earl T Barr, Mark Harman, Yue Jia, Alexandru Marginean, and Justyna Petke.
2015. Automated software transplantation. In Proceedings of the 2015 International
Symposium on Software Testing and Analysis. 257‚Äì269.

[9] Rohan Bavishi, Michael Pradel, and Koushik Sen. 2018. Context2Name: A deep
learning-based approach to infer natural variable names from usage contexts.
arXiv preprint arXiv:1809.05193 (2018).

[10] Simon Butler, Michel Wermelinger, Yijun Yu, and Helen Sharp. 2009. Relating
identifier naming flaws and code quality: An empirical study. In 2009 16th Working
Conference on Reverse Engineering. IEEE, 31‚Äì35.

[11] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira
Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman,
et al. 2021. Evaluating large language models trained on code. arXiv preprint
arXiv:2107.03374 (2021).

[12] Colin Clement, Dawn Drain, Jonathan Timcheck, Alexey Svyatkovskiy, and
Neel Sundaresan. 2020. PyMT5: multi-mode translation of natural language and
Python code with transformers. In Proceedings of the 2020 Conference on Empirical
Methods in Natural Language Processing (EMNLP). 9052‚Äì9065.

[13] Colin Clement, Shuai Lu, Xiaoyu Liu, Michele Tufano, Dawn Drain, Nan Duan,
Neel Sundaresan, and Alexey Svyatkovskiy. 2021. Long-Range Modeling of
Source Code Files with eWASH: Extended Window Access by Syntax Hierarchy.
In Proceedings of the 2021 Conference on Empirical Methods in Natural Language
Processing. 4713‚Äì4722.

[14] Yaniv David, Uri Alon, and Eran Yahav. 2020. Neural reverse engineering of
stripped binaries using augmented control flow graphs. Proceedings of the ACM
on Programming Languages 4, OOPSLA (2020), 1‚Äì28.

[15] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:
Pre-training of deep bidirectional transformers for language understanding. arXiv
preprint arXiv:1810.04805 (2018).

[16] Elizabeth Dinella, Hanjun Dai, Ziyang Li, Mayur Naik, Le Song, and Ke Wang.
2020. Hoppity: Learning graph transformations to detect and fix bugs in programs.
In International Conference on Learning Representations (ICLR).

[17] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong,
Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, et al. 2020. CodeBERT: A Pre-
Trained Model for Programming and Natural Languages. In Proceedings of the
2020 Conference on Empirical Methods in Natural Language Processing: Findings.
1536‚Äì1547.

[18] Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu, Long
Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, et al. 2020. GraphCodeBERT:
Pre-training code representations with data flow. arXiv preprint arXiv:2009.08366
(2020).

[19] Daya Guo, Alexey Svyatkovskiy, Jian Yin, Nan Duan, Marc Brockschmidt, and
Miltiadis Allamanis. 2022. Learning to Complete Code with Sketches. In Interna-
tional Conference on Learning Representations. https://openreview.net/forum?id=
q79uMSC6ZBT

[20] Vincent J Hellendoorn, Charles Sutton, Rishabh Singh, Petros Maniatis, and David
Bieber. 2019. Global relational models of source code. In International conference
on learning representations.

[21] Marie-Anne Lachaux, Baptiste Roziere, Marc Szafraniec, and Guillaume Lam-
ple. 2021. DOBF: A Deobfuscation Pre-Training Objective for Programming
Languages. Advances in Neural Information Processing Systems 34 (2021).
[22] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman
Mohamed, Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019. Bart: Denoising
sequence-to-sequence pre-training for natural language generation, translation,
and comprehension. arXiv preprint arXiv:1910.13461 (2019).

[23] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A
Robustly Optimized BERT Pretraining Approach. arXiv:1907.11692 [cs.CL]
[24] Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambro-
sio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, et al. 2021.
CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understand-
ing and Generation. In Thirty-fifth Conference on Neural Information Processing
Systems Datasets and Benchmarks Track (Round 1).

[25] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a
method for automatic evaluation of machine translation. In Proceedings of the
40th annual meeting of the Association for Computational Linguistics. 311‚Äì318.

[26] Michael Pradel and Koushik Sen. 2018. Deepbugs: A learning approach to name-
based bug detection. Proceedings of the ACM on Programming Languages 2,
OOPSLA (2018), 1‚Äì25.

[27] Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. 2020. Zero:
Memory optimizations toward training trillion parameter models. In SC20: Inter-
national Conference for High Performance Computing, Networking, Storage and
Analysis. IEEE, 1‚Äì16.

[28] Baishakhi Ray, Miryung Kim, Suzette Person, and Neha Rungta. 2013. Detect-
ing and characterizing semantic inconsistencies in ported code. In 2013 28th

AdaptivePaste: Code Adaptation through Learning Semantics-aware Variable Usage Representations

Conference‚Äô17, July 2017, Washington, DC, USA

IEEE/ACM International Conference on Automated Software Engineering (ASE).
IEEE, 367‚Äì377.

[29] Veselin Raychev, Martin Vechev, and Andreas Krause. 2015. Predicting program
properties from" big code". ACM SIGPLAN Notices 50, 1 (2015), 111‚Äì124.
[30] Armando Solar-Lezama. 2008. Program synthesis by sketching. University of

California, Berkeley.

[31] Alexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, and Neel Sundaresan. 2020.
Intellicode compose: Code generation using transformer. In Proceedings of the 28th
ACM Joint Meeting on European Software Engineering Conference and Symposium
on the Foundations of Software Engineering. 1433‚Äì1443.

[32] Michele Tufano, Dawn Drain, Alexey Svyatkovskiy, and Neel Sundaresan. 2020.
Generating accurate assert statements for unit test cases using pretrained trans-
formers. arXiv preprint arXiv:2009.05634 (2020).

[33] Marko Vasic, Aditya Kanade, Petros Maniatis, David Bieber, and Rishabh Singh.
2019. Neural program repair by jointly learning to localize and repair. arXiv
preprint arXiv:1904.01720 (2019).

[34] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in neural information processing systems. 5998‚Äì6008.

