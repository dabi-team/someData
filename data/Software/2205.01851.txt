IEEE/CAA JOURNAL OF AUTOMATICA SINICA, VOL. X, NO. X, X X

1

Toward Data-Driven Digital Therapeutics Analytics:
Literature Review and Research Directions

Uichin Lee, Gyuwon Jung, Eun-Yeol Ma, Jin San Kim, Heepyung Kim,
Jumabek Alikhanov, Youngtae Noh, Heeyoung Kim

2
2
0
2

p
e
S
9
1

]

C
H
.
s
c
[

3
v
1
5
8
1
0
.
5
0
2
2
:
v
i
X
r
a

Abstract—With the advent of Digital Therapeutics (DTx), the
development of software as a medical device (SaMD) for mobile
and wearable devices has gained signiﬁcant attention in recent
years. Existing DTx evaluations, such as randomized clinical
trials, mostly focus on verifying the effectiveness of DTx products.
To acquire a deeper understanding of DTx engagement and be-
havioral adherence, beyond efﬁcacy, a large amount of contextual
and interaction data from mobile and wearable devices during
ﬁeld deployment would be required for analysis. In this work,
the overall ﬂow of the data-driven DTx analytics is reviewed to
help researchers and practitioners to explore DTx datasets, to
investigate contextual patterns associated with DTx usage, and
to establish the (causal) relationship between DTx engagement
and behavioral adherence. This review of the key components
of data-driven analytics provides novel research directions in the
analysis of mobile sensor and interaction datasets, which helps
to iteratively improve the receptivity of existing DTx.

Index Terms—Digital Therapeutics, Data-Driven Analytics

Framework

I. INTRODUCTION

Digital

treatments
therapeutics (DTx), unlike traditional
such as pills, uses software installed in smartphones or wear-
able devices as software as a medical device (SaMD) to cure
diseases and improve health conditions, which is a major
departure from existing wellness products (e.g., Fitbits) [1].
As with traditional therapeutics, DTx also requires clinical
validation of efﬁcacy through systematic clinical trials [2].

The US FDA has already authorized a number of digital
therapeutic products, for example, WellDoc’s BlueStar [3] for
diabetes management, and Pear Therapeutics’ reSET [4] for
drug addiction recovery, opening up new DTx possibilities,
such as doctors’ prescriptions and insurance reimbursement.
Unlike the traditional drug development, the cost of DTx
development is relatively low, and new DTx markets are
growing rapidly. The DTx Alliance, which was formed in
2017, consists of both startups (e.g., Omada Health [5] and
Akili [6]) and global pharma (e.g., Novartis and Bayer). The
DTx market is estimated to increase to $8.7 billion in 2025,
with an average annual growth rate of 20% [7].

DTx therapies mostly consider behavioral changes in
chronic diseases
(e.g., diabetes and cardiovascular dis-
eases) [8], [9] and neuropsychiatric diseases (e.g., depression,
sleep disorders, and attention deﬁcit hyperactivity disorder

U. Lee, G. Jung, E. Ma, H. Kim, and H. Kim are afﬁliated with KAIST.
J. S. Kim and J. Alikhanov are afﬁliated with Inha University. Y. Noh is
afﬁliated with KENTECH.

We thank Dr. Yoonsup Choi for carefully reviewing this manuscript and

providing constructive feedback.

(ADHD)) [10]. These are the areas in which the treatment
effects of cognitive behavior therapies are signiﬁcant. DTx
therapies can deliver patient-centered care by supplementing
the areas in which treatment is difﬁcult or poorly managed
through existing treatment methods (e.g., lifestyle coaching
and cognitive behavior therapies), to improve the quality of
care at lower costs.

One of the important components of traditional drug devel-
opment is the selection and optimization of a drug delivery
system that aims to effectively deliver a speciﬁc drug to
the desired target (e.g., sustained release with microneedle
patches) [11]. Digital therapeutics can deliver various inter-
ventions through digital technologies (e.g., interactive mobile
content, videos, chatbots, and push notiﬁcations) [12], [13].
Thus, it is very important to analyze and optimize the engage-
ment and receptivity of “DTx delivery systems” using mobile
and wearable devices.

The existing drug delivery systems can be evaluated in
controlled environments. However, DTx usage is a daily
occurrence in the lives of patients, and thus, it is very difﬁcult
to evaluate the real-world user experiences and the efﬁcacy of
DTx in a laboratory setting [13]. Traditional clinical trials on
DTx mostly focus on measuring the endpoints or proximal/dis-
tal outcomes in the wild, but less attention has been paid
to systematically understanding DTx user engagement and
adherence patterns, which are essential for DTx improvement.
Furthermore, there is a lack of agreement on the methods and
criteria for evaluating DTx related user experiences [14].

The receptivity to DTx relates to the overall process of
intervention delivery using digital devices (e.g., notiﬁcation
delivery, notiﬁcation perception/checking, and behavioral ad-
herence) [15]. DTx aims to induce behavioral changes in users,
and it is very important to analyze patient DTx engagement
and receptivity to shorten the DTx development time and
to maximize the effectiveness of DTx. This review aims to
illustrate the ﬂow and key components of data-driven DTx
analytics to help researchers and practitioners to investigate
the user engagement and intervention receptivity to DTx by
analyzing digital footprint data (known as digital phenotype
data) collected from mobile and wearable devices. Data-
driven DTx analytics for user engagement and intervention
receptivity in DTx delivery systems will provide key insights
for the improvements of DTx, possibly innovating the existing
paradigm of DTx development processes.

Data-driven DTx analytics is closely related to automation
research because DTx replaces human-based health inter-
ventions with mobile-based counterparts. Furthermore, intel-

 
 
 
 
 
 
2

IEEE/CAA JOURNAL OF AUTOMATICA SINICA, VOL. X, NO. X, X X

Section II
DTx Background

Section III
Recent DTx Apps

Section IV
Overview of Data-Driven Analytics

DTx Design Improvement Insights

Iterative Exploration

DTx Design &
Development

Experiment
Design &
Field Trial

DTx Data
Collection &
Pre-Processing

Mobile Intervention

Experiment Design

Mobile and Wearable Data

Context
Analysis &
Causal Inference

Technical Engagement
(DTx App Usage)

Data
Visualization &
Decision Making

Data Visualization

Multiple Interventions

In-the-wild Experiment

Context Sensing

Behavioral Engagement
(Adherence to Interventions)

Causal Inference

Interactive Exploration
& Decision Making

Contextual Analytics
Causal Inference
Data Viz

Interactive Data
Exploration

V. Key Components

Section V.E
DTx Design and
Development Process

VI. Research Directions

Section VI.D
DTx Design and
Development Process

Section V.C.1)
Experimental Design for
Data-Driven DTx Analytics

Section V.A
Data Collection and 
User Management

Section V.B
Data-Driven Models
for Engagement and
Adherence

Section V.C.2)
Causal Inference
Methods for Data-
Driven DTx Analytics

Section V.D
Data Visualization
for Data-Driven DTx
Analytics

Section VI.A
Data Collection and Data-
Driven Delivery Optimization

Section VI.E
Privacy and
Ethics

Section VI.B
Causal Inference for
Data-Driven DTx Analytics

Section VI.C
Data Visualization for
Data-Driven DTx Analytics

Fig. 1. A conceptual diagram of data-driven DTx analytics: a process overview (Section IV) and key component reviews (Section V)

ligent agents leverage context sensing and data processing
to automate and personalize health services. This topic is
also related to human-in-the-loop system design for proactive
guiding of user behavior where an operator’s behavior and
machine intelligence act as human-cyber-physical systems that
are critical for automation performance [16]. Automation ﬁelds
have a long tradition of using sensor data to optimize the
performance of human-machine collaboration. This work on
data-driven DTx analytics broadens the scope of existing
automation research.

The remainder of this paper is organized as follows (Fig.
1). In Section II, background information (e.g., DTx deﬁnition
and regulations) is provided. In Section III, an overview of
recent DTx is provided, and opportunities for adopting just-
in-time interventions in DTx are discussed. In Sections IV
and V, an overview of the ﬂow of data-driven DTx analytics
and a detailed review of key components are provided. In
Section VI, to conclude, several directions for future research
are discussed.

II. DTX BACKGROUND

A. Deﬁning DTx and its Relationship to Digital Health

The Digital Therapeutics Alliance, an industry association
in the digital health area, deﬁnes DTx as “evidence-based
therapeutic interventions to patients that are driven by high-
quality software programs to prevent, manage, or treat a

medical disorder or disease” [2]. In academia, DTx is similarly
deﬁned: e.g., “a new treatment modality in which digital
systems (e.g., smartphone apps) are used as regulatory body-
approved, prescribed therapeutic interventions to treat medical
conditions” [1]. Existing DTx mostly target chronic diseases
with continuous intervention support to change behaviors or
lifestyles and to help patients manage their health conditions
effectively. The coverage of therapeutics includes obesity, pre-
diabetes, hypertension, hyperlipidemia, smoking-related dis-
eases, chronic pain, chronic obstructive pulmonary disease
and asthma, diabetes, alcoholism, coronary artery disease, and
serious mental illnesses [17], [18].

Although DTx has recently been in the spotlight, the use of
digital products in providing therapeutic interventions has been
studied for a long time. As Webb et al. [19] state in their study,
researchers have designed therapeutic interventions on theoret-
ical bases, applied behavioral change techniques in them, and
delivered them via the Internet. The term “digital therapeutics”
was ﬁrst mentioned in a study published in 2015 [20], deﬁning
it as “evidence-based behavioral treatments delivered online
that can increase accessibility and effectiveness of health care.”
As this deﬁnition implies, it became important to verify the
effectiveness of DTx treatments (i.e., the actual outcome of
the DTx treatment in the real world) [21], [22]. Additionally,
the industry has also begun to set up standards for clinical
evidence.

LEE et al.: TOWARD DATA-DRIVEN DIGITAL THERAPEUTICS ANALYTICS: LITERATURE REVIEW AND RESEARCH DIRECTIONS

3

Digital therapeutics is deeply related to digital health and
mHealth and is generally classiﬁed as a subset of digital
health. According to the World Health Organization, the origin
of digital health is eHealth, which is deﬁned as “the use
of information and communications technology in support
of health and health-related ﬁelds.” This deﬁnition includes
mHealth, which is “the use of mobile wireless technologies
for health.” As a subset of eHealth, mHealth expands its
scope to emerging technologies, such as big data analysis,
artiﬁcial intelligence, and genomics [23]. The US FDA, on
the other hand, extends the area of digital health to cover
“mobile health (mHealth), health information technology,
wearable devices, telehealth, telemedicine, and personalized
medicine” [24]. There is another subset of digital health
named “digital medicine,” which is deﬁned as “high-quality
hardware and software that support the practice of medicine
broadly” for measurement and intervention in health-related
services [25], [26]. For instance, digital medicine may include
pills with built-in sensors for monitoring tumors inside the
body or wearables that continuously track the glucose level
or heart rate. Healthcare providers or consumers then utilize
the collected data to manage the health status by changing
treatment decisions or medication doses. In this sense, digital
medicine can be seen as a broader concept than DTx [27].
Compared with digital medicine, most DTx products focus
only on software and emphasize making direct changes in
health conditions or adjusting treatments based on the col-
lected health data.

Digital health uses technology to deliver information and
enable communication, with the purpose of monitoring and
managing patients and consequently improving their health
conditions [28]. Moreover, this approach reduces the burden of
health care, allows patients to manage their health even outside
traditional hospitals, and individualizes the treatment by imple-
menting behavior change theory or techniques [9]. Following
these deﬁnitions and descriptions, digital therapeutics can be
considered part of digital health. In particular, during the
COVID-19 era, the US government relaxed the regulations
for noninvasive remote monitoring devices and reduced direct
contact between patients and healthcare providers [29]. This
is expected to increase the use of DTx in everyday life and
eventually address health inequalities by supporting patients
who cannot easily access medical facilities, such as people
living in rural areas [30].

Various studies on DTx have been conducted in the area of
digital health using different digital platforms (e.g., web and
mobile apps). Digital health research targets many diseases or
health issues, such as diabetes [8], cardiovascular diseases [9],
asthma [31], mental health (e.g., depression, anxiety, ADHD,
autism spectrum disorders, and eating disorder) [10], weight
management [32], and smoking cessation [33]. In addition,
digital health solutions could be utilized to manage various
types of cancer tumors [34], support patients in rehabilitation
from neurological diseases (e.g., stroke, Parkinson’s disease,
and multiple sclerosis) [35], [36], and prevent and treat
HIV [37], [38]. A report published in 2017 showed that there
are more than 318,000 digital health apps publicly available to
consumers through Apple Store and Google Play, with more

than 200 apps added each day [39].

However, not all apps can be classiﬁed as “digital thera-
peutics” because clinical evidence and real-world outcomes
(e.g., managing, preventing, or treating a medical disorder,
or optimizing medication) have to be satisﬁed for regulatory
purposes. Therapeutic interventions must also be certiﬁed by
regulatory bodies in terms of efﬁcacy and safety for intended
use [26]; by demonstrating clinical evidence (or efﬁcacy) via
randomized controlled trials (RCTs) in which participants are
randomly assigned to the clinical interventions or the control
group set up for comparison; the control could be a placebo
or no intervention at all [39]. Research communities on digital
health have been striving to conduct RCTs to obtain clinical
evidence. However, the generation of clinical evidence for
efﬁcacy and safety is still scarce because of the time and
cost of running large-scale RCTs, which has become one of
the main challenges in DTx. Further issues might arise such
as the technology becoming outdated during the trial, ethical
considerations, infeasible placebo control groups, or privacy
concerns arising from remote informed consent [1].

To summarize,

the relationship between digital health,
mHealth, and DTx can be described as shown in Fig. 2. Both
mHealth and DTx are subsets of digital health and overlap in
some areas.

1 mHealth and DTx: DTx products that deliver therapeutic
interventions via mobile devices are included in this area.
Most mobile applications and major DTx products use
this format.

2 mHealth but not DTx: Digital health apps are available
on mobile devices (usually smartphones), but they do not
demonstrate clinical evidence or real-world outcomes.
3 DTx but not mHealth: DTx products that do not utilize
mobile or wearable platforms. These products may be in
the form of software applications or web applications.
4 Digital health, neither mHealth nor DTx: Digital health
apps available as a form of software application or
web application (not smartphones), but have only the
ability to capture, store, display, or transmit health data
and information with no direct therapeutic interventions,
clinical evidence, or real-world outcomes (e.g., health
information technology, telehealth, and medical imaging)

B. DTx Regulations

The development of the digital healthcare sector has led to
the emergence of new software concepts such as software as
a medical device (SaMD). The International Medical Device
Regulator Forum, which is a coalition of regulators from
various countries, deﬁnes SaMD as “software intended to be
used for one or more medical purposes that perform these pur-
poses without being part of a hardware medical device” [57].
In general, SaMD includes DTx as well as other clinical
decision-making software such as computer-aided diagnosis
for radiologists. Similarly to hardware-based medical devices,
SaMDs have highlighted the need for regulatory oversight and
approvals. the US FDA requires SaMD to receive approval
by demonstrating safety and effectiveness either through the
Premarket Notiﬁcation 510 (K) process of comparison with

4

IEEE/CAA JOURNAL OF AUTOMATICA SINICA, VOL. X, NO. X, X X

Category

Disorder/Disease

DTx name

Company

TABLE I
RECENT DIGITAL THERAPEUTICS

Mental
disorder

Physical
disorder

ADHD

Depression

Insomnia

Panic disorder

Substance abuse

Asthma

Cancer

Diabetes

Diabetes,
Hypertension

HIV
Stroke,
Neurological
disorders

EndeavorRx [6]
deprexis [40]
Woebot [41]
Somryst [42]
FREESPIRA [43]
NightWare [44]
reSET [4]
reSET-O [45]
Propeller [46]
NuvoAir [47]
Oleena [48]
BlueStar [3]
Insulia [49]
Transform [50]
Virta [51]
Dario [52]
Omada [5]
Livongo [53]
PositiveLinks [38]
Constant Therapy [54]
NeuroEyeCoach [55]
Nirvana [56]

Akili Interactive Labs
GAIA-AG
Woebot Health
Pear Therapeutics
Freespira
NightWare
Pear Therapeutics
Pear Therapeutics
Propeller Health
NuvoAir
Voluntis
WellDoc
Voluntis
Virgin Pulse
Virta Health
DarioHealth
Omada Health
Teladoc Health
PositiveLinks Platform
Constant Therapy Health
NovaVision
BTS Bioengineering

Intention

Status
FDA De Novo
Treat
Manage
FDA 510 (K)
-
Manage
Manage
FDA 510 (K)
Manage
FDA 510 (K)
Manage
FDA De Novo
Treat
FDA De Novo
Treat
FDA De Novo
Optimize
FDA 510 (K)
Manage
FDA 510 (K)
Manage
FDA 510 (K)
Manage
FDA 510 (K)
Manage
FDA 510 (K)
Manage
CDC DPP
-
Manage
Manage
FDA 510 (K)
Manage
CDC DPP
Manage
FDA 510 (K)
-
Manage
FDA Breakthrough Manage
Manage
FDA 510 (K)
Manage
-

Digital Health

mHealth

DTx

2

1

3

4

Fig. 2. Relation among Digital Health, mHealth, and Digital Therapeutics
(DTx). There are four different categories in Digital Health depending on
whether the system utilizes mobile devices (mHealth) and whether it has
sufﬁcient direct therapeutic intervention or clinical evidence (DTx).

similar legally marketed devices (known as substantial equiv-
alence proof) [58], or the De Novo classiﬁcation process if a
comparison is not feasible (new technology) [59]. In 2018, US
FDA further introduced breakthrough designations for SaMDs
with more effective treatment or diagnosis of life-threatening
human diseases such that manufacturers can interact with the
FDA’s experts to expedite such review processes [60].

There is also a newly created pre-certiﬁcation program that
certiﬁes SaMD “developers” instead of SaMD “products” so
that the total product lifecycle can be managed (e.g., product
quality, patient safety, and cybersecurity) [61].

To date, most applications and services, classiﬁed as DTx,
have received 510 (K) clearance by submitting RCT results
from users with new technology and those with make-believe
technology as a placebo to demonstrate their effectiveness.
WellDoc’s BlueStar diabetes management system was one
of the ﬁrst FDA 510 (K) submissions approved in January
2017. Pear Therapeutics reSET (drug addiction) and Akili’s

EndeavorRx (attention deﬁcit) were approved via the De
Novo process and validated by comparing existing treatment
methods with and without the newly developed techniques [6],
[62].

Besides the US FDA approvals, for diabetes management,
there is another certiﬁcation called the full Centers for Dis-
ease Control and Prevention (CDC) recognition for Diabetes
Prevention Program (DPP). Several commercial DTx prod-
ucts have received full CDC recognition for DPP, such as
Noom [63] and Omada [64], which provide users with diabetes
programs based on computerized cognitive behavioral therapy.
They were recognized for the effectiveness of diabetes man-
agement through clinical trials for participants in the National
DPP program, which lasted more than 16 weeks [5], [65].

III. REVIEW OF RECENT DTX THERAPIES

Digital therapeutics apps use a variety of behavior change
techniques such as feedback on behavior and goal setting,
social support, instructional guidelines, and self-monitoring of
behavior, and outcome(s) of the behavior. As DTx apps are
not yet well established, to grasp the trends, a non-probability
sampling method—snowball sampling—was performed. Po-
tential DTx apps were identiﬁed online based on our judgment
of mental and physical disorder categories until the required
sample size was reached. A solid effort was made to embrace
most DTx apps introduced/released in the last three years, as
well as those with FDA certiﬁcates (i.e., De Novo and 510 (K))
and recognition by the CDC. This paper may not exhaustively
review all relevant literature, but it clearly reﬂects the state-of-
the-art technology of DTx apps. The insights obtained from the
process are summarized according to the therapeutic areas and
diseases they target. For each DTx, regulatory endorsement is
checked (e.g., 510 (K), De Novo, and CDC full recognition),
and intended use is categorized based on Digital Therapeutics
Alliance [2] categories: (1) management or prevention of a

LEE et al.: TOWARD DATA-DRIVEN DIGITAL THERAPEUTICS ANALYTICS: LITERATURE REVIEW AND RESEARCH DIRECTIONS

5

App name
(target disease)

A-CHESS
(alcoholism)
[66]

Q-Sense
(smoking)
[67]

DietAlert
(obesity)
[68]

JITAI components

Distal outcome
Proximal outcome
Tailoring variables
Intervention options

Decision points

Decision rules

Distal outcome
Proximal outcome

Tailoring variables

Intervention options

Decision points
Decision rules
Distal outcome
Proximal outcome
Tailoring variables
Intervention options
Decision points
Decision rules

TABLE II
DIGITAL THERAPEUTICS WITH JITAI

Contents

Regular reduction on the number of risky drinking days (4, 8, and 12 months after discharge)
Weekly Brief Alcohol Monitoring (BAM) index result
Location of the individual
Helping patients stay sober by prompting them if they go near the high risk places
The moment when the user gets closer to high-risk location
When the user presses the panic button
Whether the user gets closer to the high-risk location or not
Whether the panic button is pressed or not
Smoking abstinence
Reduced stays within high risk locations
Location of the individual
User self-reports (i.e., mood, stress, urge, current context, and whether other smokers
are present) collected when the user starts smoking during the pre-quit phase
Tailored support message (preﬁlled based on the user’s demographics and smoking survey)
Feedback messages based on the user’s smoking reports
When the user enters and stays in the high risk location for more than 5 minutes
Whether the user enters and stays in the high risk location for more than 5 minutes
Weight loss
If exceeding calorie limit or not
21 tailoring variables (temptation, boredom, hunger, and planning food intake, exercise, etc.)
157 subdivided elements provided (e.g., think of something fun to try right now)
When the user replies to an EMA prompt
Use supervised machine learning to identify risk for lapse occurrence

Data types

numeric
numeric
object
string
timestamp
timestamp
boolean
boolean
boolean
numeric
object

mixed

string
string
timestamp
boolean
numeric
boolean
numeric
string
timestamp
numeric

medical disorder/disease, (2) medication optimization, and (3)
medical disease or disorder treatment.

As shown in Table. I, the established DTx apps span two
therapeutic areas, namely, mental and physical disorders. The
mental disorders include ADHD [6], depression [40], [41],
insomnia [42], panic disorder [43], and substance abuse [4],
[45]. Among DTx apps in this area, Pear Therapeutics’s
reSET [4] is the ﬁrst prescription DTx product (i.e., De Novo)
designed to deliver behavioral therapy to treat substance use
disorder; reSET-O [45] is another prescription DTx product
designed to deliver cognitive behavioral therapy for opioid
use disorder. As a research prototype, EndeavorRx [6] is a
home-based, video game-like digital app for the treatment of
inattention and cognitive dysfunction in pediatric patients with
ADHD.

Another major branch of DTx apps is physical disorders,
such as asthma [46], cancer [48], diabetes [3], [49], [51], dia-
betes/hypertensions [52], [5], [53], and diabetes/obesity [50].
Among the DTx apps in this area, BlueStar [3], a digital
therapeutic app developed by WellDoc, has assisted patients
and providers in improving glucose control by using real-
time data and feedback to support healthy behaviors, such as
medication adherence, diet and exercise control, and psychoso-
cial wellness. BlueStar has demonstrated the capacity to shift
HbA1c levels in populations with diabetes. Interestingly, the
Dario Blood Glucose Monitoring System [69] by DarioHealth,
Omada [70] by Omada Health and Livongo [71] by Teladoc
Health combine the DPP with hypertension, as 80% of people
with type 2 diabetes also have high blood pressure. Both
hypertension and diabetes result from metabolic syndromes.
Thus, they develop sequentially in the same individual [72],
[73].

DTx apps can incorporate just-in-time support which is
an attempt to provide the right type (or amount) of support

at the right time (i.e., neither too early nor too late). For
example, the ongoing monitoring of an individual with mobile
sensing can identify when these events/conditions occur (i.e.,
when support is needed). As an emerging technology-driven,
behavior change-oriented intervention type, just-in-time adap-
tive intervention (JITAI) capitalizes on real-time sensor data
collected via mobile sensing technology (e.g., smartphones
and wearables) to adaptively trigger appropriate support in
situ [74]. The major components of DTx with JITAI can be
summarized as follows:

• Distal outcome: the long-term goal (i.e., behavior change)
of a DTx app (e.g., reduction of sedentary behavior in
older adults [75]).

• Proximal outcome: the short-term goal of a DTx product,
which mediates the effect of the intervention on the distal
outcome. In other words, the proximal outcome ensures
progress toward the distal outcome (e.g., increased num-
ber of active breaks from prolonged sitting over a day).
• Tailoring variables: the collection of behavioral and
contextual data that can identify when behavioral support
might be most effective (e.g., accumulated sitting time,
location of individual, time of day, response to support
prompts sent earlier, and frequency of support prompts).
• Intervention options: adequate intervention options (e.g,
suggestions of light movements, positive feedback, and
encouragements to repeat the light movements) that are
delivered to the user when an opportune moment for
behavior change support is detected.

• Decision points: a marked moment when a decision to
send an intervention option is made considering tailoring
variables (e.g., the time between 5 pm and 9 pm).

• Decision rules: systematic rules of whether to provide
certain intervention options based on past intervention
options and tailoring variables (e.g., location-based feed-

6

IEEE/CAA JOURNAL OF AUTOMATICA SINICA, VOL. X, NO. X, X X

back is provided if a user becomes sedentary for more
than 30 minutes).

JITAI-based DTx apps were further reviewed in the context
of JITAI with relevant data types in Table. II, which describes
DTx apps that target alcohol addiction [66], tobacco addic-
tion [67], and obesity [68].

Alcohol addiction: A-CHESS [66] offers JITAIs to reduce
risky drinking days (i.e., distal outcome) for patients with
alcohol use disorder after leaving a treatment facility. A-
CHESS monitors data collected via mobile sensing to trigger
just-in-time interventions in the form of messages and tracks
the reduced brief alcohol monitoring index (i.e., proximal
outcomes) weekly to make progress toward the distal outcome.
The app uses tailoring variables (e.g., location of an individual,
user data submissions, messages sent/received via the app) and
intervention options such as sending a prompt notice if the user
comes near places associated with a high risk for drinking. A-
CHESS deﬁnes the moment when the user’s location is close
to the high-drinking-risk place and the moment when the panic
button is pressed as decision rules and decision points.

Cigarette smoking: JITAI for smoking cessation can lever-
age self-reports and automatic sensing for risk assessment.
Smart-T [76], [77] estimated the risk of smoking using the
user’s self-report data via ecological momentary assessment
(EMA) (e.g., urge to smoke, stress, alcohol consumption, and
availability of cigarettes). Sense2Stop [78] leverages automatic
stress sensing mechanisms to deliver support messages when
high-stress moments are detected. Q-Sense [67] learns a
user’s smoking behavior, emotional conditions, and places via
EMA, and the user’s high-risk locations are tracked to deliver
just-in-time support messages. Q-Sense leverages user self-
assessment and mobile sensing to trigger just-in-time support
messages for smoking abstinence (i.e., distal outcome). It
also tracks proximal outcomes (i.e., not staying in a high-
risk location) to make progress toward the distal outcome.
Self-assessment and location are used as tailoring variables
to trigger the intervention. Q-Sense checks whether a user
stays in high-risk locations for longer than 5 min (known
as a geofensing technique), which is considered a decision
rule, and the current timestamp becomes the decision point.
Intervention options include tailored support and feedback
messages. Tailored support messages are pre-populated based
on the user’s demographics and smoking survey. Feedback
messages are sent based on the smoking behavior pattern of
the user and on user self-reports (e.g.,“Based on 12 reports,
did you know you smoke 25% of the time when working?”).
Obesity: DietAlert [68] focuses on lapses in a weight-control
diet among overweight and obese individuals. For just-in-
time intervention, the app tracks whether the user exceeds
the calorie limit as the proximal outcome. DietAlert tracks
21 tailoring variables (e.g., temptation, boredom, hunger, and
exercise) and 157 subdivided elements (e.g., thinking of some-
thing fun for boredom). DietAlert uses supervised machine
learning to identify lapse occurrence risk as a decision rule
and keeps track of the user responses for decision points
(six semi-random time intervals throughout the day, spaced
approximately 2–3 h apart).

IV. OVERVIEW OF DATA-DRIVEN DTX ANALYTICS

This section provides an overview of the core elements
of data-driven DTx analytics (Fig. 3). The major ﬂow of
data-driven DTx analytics involves DTx user experience, DTx
usage, and behavior adherence (proximal and distal outcomes).
These elements are closely related to the offered DTx mech-
anisms (e.g., goals and strategies) and users’ intervention
contexts (e.g., user traits and environments). In addition to
traditional clinical trials with RCTs, we discuss how sensor
and interaction data can be used to enable contextual and
causal analytics.

DTx engagement: We used the existing conceptual model
engagement by Yardley et al. [79], which made distinctions
between engagement with technological and behavioral as-
pects. Engagement with technological aspects (i.e., DTx user
experience and DTx usage) refers to how a user makes use
of software for behavior changes. In contrast, engagement
with behavioral aspects refers to how a user initiates and
sustains behavior changes, which can possibly lead to “positive
outcomes” (e.g., reaching weight loss goals). Intervention soft-
ware plays an important role in scaffolding behavior changes,
so that sustained usage of intervention software is no longer
necessary for achieving “positive outcomes.” In other words, if
a user has ﬁnished mastering a skill offered by the intervention
software, behavioral changes can be successfully maintained
even without software usage. This distinction was also used
in Alshurafa et al.’s work [80], where engagement with
intervention software referred to DTx usage (e.g., duration
and frequency of app usage) and engagement with behavior
changes referred to adherence to the intervention (e.g., prox-
imal outcomes). In this work, “engagement” refers to DTx
software usage and user experience, and “adherence” refers to
behavior changes prompted by intervention. In Section V-B,
the modeling of engagement and adherence using datasets is
further discussed.

DTx mechanisms: Existing intervention models include the
behavior intervention technology (BIT) model [12] and Fogg’s
model [81]. The BIT model is a software-based intervention
at both theoretical and technical levels: (1) theoretical aspects
include intervention goals (e.g., weight loss and healthy eating)
and behavioral intervention strategies (e.g., goal setting, edu-
cation, monitoring, and feedback), and (2) technical aspects
include behavioral
intervention technology elements (e.g.,
information delivery, data collection, and reports), technical
characteristics (e.g., medium, complexity, aesthetics, and per-
sonalization), and workﬂow of the intervention to determine
when to deliver the intervention to the user (e.g., context-based
scheduling).

Intervention contexts: These include both personal charac-
teristics and contextual factors. An existing behavior change
model for Internet interventions [82] considers (1) user char-
acteristics (e.g., disease states, demographics, traits, beliefs
and attitudes, physiological factors, and skills), (2) intervention
experiences (e.g., user preferences, perceived burdens/fatigue,
and habituation), and (3) intervention environments (e.g., per-
sonal, professional, and community aspects). This “contextual”
model can be further extended by using existing context

LEE et al.: TOWARD DATA-DRIVEN DIGITAL THERAPEUTICS ANALYTICS: LITERATURE REVIEW AND RESEARCH DIRECTIONS

7

Engagement with DTx

DTx intervention mechanisms
(e.g., BIT Model): goals, elements, characteristics, 
workflow, and technical implementation

DTx User Experiences

DTx Mechanisms

Intervention Contexts

Personal characteristics: disease state, 
demographics, personality, health beliefs/attitudes, 
cognitive/psychological factors, skills, intervention 
factors (preference, burden/fatigue, habituation)

Personal/social/environmental contexts: 
activity, availability, emotion, location, resources  

Fig. 3. Data-driven DTx analytics framework

BeActive
(“Don’t sit too long and 
have an active break!)

DTx Usage 

Following suggestions

Behavioral Adherence 
(=Proximal Outcome)

Engagement with Behavior Changes 

Data-driven DTx analytics

Contextual analytics:

using observational data to support 
exploratory tasks of investigating 
intervention contexts, DTx usage, and 
behavioral routines  

Causal inference: 

using observational data to perform 
counterfactual inferences; e.g., contextual 
factors vs. user states, and contextual 
and engagement factors vs. adherence 

DTx Distal Outcome

2,000

5,000

8-week avg. 
daily step count

representation models for ubiquitous computing where mobile,
wearable, and Internet-of-Things (IoT) devices are used to
enable context-aware services [83], [84]. Additional contextual
information includes both human factors (e.g., users’ cognitive
and affective states, social environment, and tasks) and physi-
cal environments (e.g., location/place, lighting condition, and
temperature). Intervention context data can be collected via
user self-reports and automatic inferences from sensor data
collected passively via machine learning.

it

Data-driven DTx analytics: An RCT, as the gold stan-
dard for clinical evaluation, helps to evaluate the efﬁcacy
of a newly developed digital intervention, as opposed to the
is difﬁcult for RCTs to
traditional approach. However,
identify the key contextual patterns and intervention factors
that inﬂuence efﬁcacy. Sensor and interaction data passively
collected during RCTs can be used in contextual and causal
analytics. Contextual analytics supports exploratory tasks of
understanding contextual factors related to DTx usage such
as lifestyle (behavioral routines), intervention contexts, and
psychological states of the user (e.g., emotion and stress)
over the intervention period. Causal analytics (counterfactual
inference) helps to investigate how individual intervention
elements and user engagement inﬂuence behavioral adherence
(i.e., proximal and distal outcomes).

V. KEY COMPONENTS OF DATA-DRIVEN DTX ANALYTICS
FLOW

The overall ﬂow of data-driven DTx analytics is shown in
Fig. 1. Conducting large-scale RCTs is very expensive and
time-consuming and constitutes a major bottleneck in rapid
software iteration. The goal of data-driven DTx analytics is
not only to evaluate the efﬁcacy of the intervention, but also to
acquire design and clinical insights through a comprehensive
analysis of the passively collected sensor and interaction data

from DTx ﬁeld trials. The major components of a DTx analysis
ﬂow include (1) data collection and user management in ﬁeld
trials, (2) data-driven models for engagement and adherence,
(3) experimental design and contextual/causal analytics, (4)
data visualization, and (5) DTx design and development pro-
cesses, which are reviewed in detail as follows.

A. Data Collection and User Management

We review technologies enabling data collection and user
management, such as clinical trial management systems and
general-purpose platforms. Data sources are largely based on
sensor and interaction data from smart devices (e.g., phones,
wearables, and IoT devices); thus, smart devices and their
interactions are discussed.

1) Clinical Trial Management System: As stakeholders
perform various clinical trials with a certain level of quality,
it is necessary to utilize an information technology system to
support data collection and user management in standardized
clinical trial processes, to comply with relevant regulations.
Based on a commonly agreed upon standardized process,
a clinical trial management system (CTMS) was designed
and developed as a comprehensive system to comply with
privacy and security regulations. Table. III summarizes the
representative CTMSs [94] and states the eight key support-
ing features required to conduct standardized clinical trials,
as discussed in [95]. These features include (1) milestone
management (e.g., managing timeline of clinical trial such
as regulatory completion), (2) education management (e.g.,
training of researchers of the study by CTMS expertise team
or providing educational services to ensure that subject re-
mains in the study), (3) resource management (e.g., managing
medical devices and clinical drug import and export), (4)
subject management (e.g., managing the health information of
the subject and subject recruitment and scheduling), (5) data

8

IEEE/CAA JOURNAL OF AUTOMATICA SINICA, VOL. X, NO. X, X X

TABLE III
COMPARING MAJOR FEATURES OF EXISTING CTMS SYSTEMS

CTMS

ArisGlobal [85]
BioClinica [86]
Bio-Optronics [87]
DSG [88]
eResearch Technology [86]
MedNet Solutions [89]
Medidata Solutions [90]
PAREXEL International [91]
Trial By Fire Solutions [92]
Veeva Systems [93]
O: Supported

Milestone mgmt
O
O
O
O
O
O
O
O
O
O

Education mgmt
O
O
O
O
O
O
O
O

O

Resource mgmt
O
O
O
O
O
O
O
O

Major features supported
Subject mgmt
O
O
O
O
O
O
O
O
O
O

Data collection
O
O
O
O
O
O
O
O
O
O

Data analytics
O
O

O
O
O
O

O

Legal service
O
O
O
O
O
O
O
O
O
O

Financial service
O
O
O
O

O
O
O
O
O

collection (e.g., using electronic data capture (EDC) system
to collect clinical data in electronic format for human clinical
trials instead of the traditional paper-based data collection
methodology, to streamline data collection, and to expedite the
time for marketing the drugs and medical devices), (6) data
analytics (e.g., providing visualization of clinical research data
using dashboard or analyzing clinical data using other analytic
modules), (7) regulatory services (e.g., adhering to guidance
and directives from the regulatory agencies such as FDA and
European Medicines Agency), and (8) ﬁnancial services (e.g.,
ﬁnancial management of clinical trials).

Ten well-known CTMSs reported in a recent study [94] were
selected for this review. Product brochures, publicly available
videos, and white papers were scrutinized to check whether
the eight essential features were supported. Most systems fully
support the key features; however, several systems do not
provide some of the features, possibly because their focus is
on speciﬁc customer segments. It is interesting to note that
Medidata Solutions [90] and Parexel International [91] provide
additional EDC support to collect sensor data (e.g., pulse
oximeters, blood pressure meters, activity trackers, glucome-
ters, spirometers, body weight scales, and ECG) and wear-
ables. The other CTMSs do not closely match these standards.
Major players include IBM Watson Health [96], Oracle [97],
Nextrials [98], and Winchester Business Systems [99].

2) General-Purpose Mobile Sensing Platforms: Compared
with CTMS, research communities in mobile and ubiqui-
tous computing have made intensive efforts to build general-
purpose platforms to collect sensor data from mobile and
wearable devices (e.g., smartwatches and smartbands). As
shown in Fig. 4, here, the platform components are con-
ceptualized with a layered architecture. (1) Data source and
Communication interfaces layer includes the collection of
sensor data (e.g., accelerometers, gyroscopes, magnetometers,
and GPS) from smartphones and other wirelessly connected
devices (e.g., smartwatches, smartbands, and IoT devices).
Through a communication interface (i.e., Bluetooth, WiFi),
data from the devices are transferred to smartphones and stored
locally. (2) Data acquisition layer includes the implementation
of an agent that performs basic functions (e.g., device registra-
tion, connection, subscription, and data queries), sampling rate
adjustment for sensing, and connection failure management
(e.g., wireless connectivity failures between a wearable and
smartphone). The obtained data are then archived into a local
database. (3) Data processing and analytics layer implements

local data preprocessing and remote cloud computing for
context analytics and causal inference. Various machine learn-
ing algorithms can be executed on either local devices (e.g.,
smartphones or local servers) or remote servers. Lightweight
machine learning algorithms on edge devices process raw sen-
sor data to extract contextual features and behavioral markers
(e.g., mobility features, physical activities, and users’ cognitive
and psychological states). Computationally intensive analytics
can be performed via remote cloud computing infrastructure.
For example, causal inference helps to establish causality of
the effect of the provided DTx treatments, and contextual
analytics helps to understand users’ intervention contexts, such
as problematic situations and the inﬂuence of user contexts
on adherence. (4) DTx layer includes the main components
of DTx applications and user interactions. DTx applications
(e.g., smoking cessation and depression management) usu-
ally contain pipe-lined procedures (i.e., planning and goal
setting, context tracking, reminding/reinforcement, and self-
reﬂection). The participant’s interactions involve behavioral
interventions, user self-reporting to the platform, and visual-
ization of the user’s daily (or longer-term) summary toward
the goal. A more detailed review on DTx mechanisms can be
found in Section V-E.

General-purpose platforms mainly focus on providing reli-
able and scalable sensor data collection, and therefore, com-
pared to CTMS, offer only a limited number of function-
alities, such as research resource/progress management and
logistics support. Recently, several well-known data-collection
platforms have been introduced, including OpenDataKit [100],
AWARE [101], and mCerebrum [102], which enable re-
searchers to collect user self-reports and stream high-frequency
sensor data to the remote cloud for storage and data process-
ing. OpenDataKit adopts a middleware design approach that
allows third-party app developers to minimize their efforts in
sensor-speciﬁc codes via reusable sensor drivers. For example,
it is possible to download new sensor capabilities from the
application market and use them without any need for modiﬁ-
cations. OpenDataKit further manages the discovery, commu-
nication channels, and data buffers for extensibility. AWARE
provides mobile data-logging tools and supports external sen-
sor plugins for the collection and abstraction of sensor data
for context-aware service delivery. System scalability is an
important issue for these platforms. mCerebrum signiﬁcantly
improves the scalability of storage for high-rate sensor data
and provides several ﬁne-tuned features, such as sensor duty

LEE et al.: TOWARD DATA-DRIVEN DIGITAL THERAPEUTICS ANALYTICS: LITERATURE REVIEW AND RESEARCH DIRECTIONS

9

[ DTx Applications ]

Main Components and User Interactions

Main Components of DTx Applications

Participant’s Interactions

Planning & 
Goal Setting

Context
Tracking

Reminder/
Reinforcement

Self-
reflection

Intervention

Self-Report

Data Visualization

Data Processing and Analytics

Local Data Pre-Processing

Remote Cloud Computing

Mobility & 
Activities

Social 
Context

Cognitive 
State

Psychological 
State

Context Fusion

Context Analysis

Causal Inference

Data Acquisition

Basic Features

Device 
Registration

Device 
Connection

Data
Subscription

Data 
Queries

Sampling 
Configuration

Disconnection
Management

Data Sources and Communication Interfaces

Smartphones

Wearable Devices

IoT Devices

Interaction
Data

Sensor
Data

Comm. 
Interfaces

Interaction
Data

Sensor
Data

Comm. 
Interfaces

Interaction
Data

Sensor
Data

Comm. 
Interfaces

Fig. 4. The architecture of data-driven DTx analytics platform

cycling, energy-optimized context inference computation as a
shared service, and sensor data quality assessment. AWARE
and mCerebrum can deliver local interventions, but the cloud
components of these frameworks are limited to automatically
triggered interventions based on past user data. Data collection
requires sustained user engagement. SARA [103] integrates
gamiﬁed engagement strategies, including contingent rewards,
badges for completing active health tasks, funny memes/gifs
and life insights, and health-related reminders or notiﬁcations
to incentivize data collection.

There are other data collection platforms such as the Per-
sonal Health Intervention Toolkit (PHIT) [104] that exclusively
target health interventions. PHIT is a framework that facilitates
mobile data collection and supports health interventions for
research purposes. PHIT allows researchers to explore and
perform health status analysis, intervention recommendations,
and self-help activities, and to explore uploaded data through
a Web-based portal. The major departure of PHIT from
CTMS and general-purpose data collection platforms is that
it provides an intelligent virtual advisor that analyzes real-
time data from devices and facilitates tailored interventions.
A recent study proposed Duty [105], [106], which integrates
mindfulness-based relaxation, behavioral education in sleep
quality and alcohol use, and psychometric and psychophysio-
logical data capture. Duty used PHIT as a personalized health
intervention framework for acquiring data,
including self-
report instruments, EMA diaries, cognitive tests, and game-
like activities.

3) Smart Devices and User Interactions: Current com-
mercial DTx apps (e.g., Woebot and reSET) are mostly in
software format using off-the-shelf smartphones, but they also
leverage wearable trackers (e.g., Fitbit and Apple Watch)

and IoT devices (e.g., Propeller Health’s Bluetooth inhalers
and Insulia’s Blood Glucose Meters). Mobile, wearable, and
IoT technologies support ﬁne-grained sensing and tracking
of users’ states ranging from physiological signals, such as
heart rates and skin temperature, to physical activities, social
interactions, and user’s interactions with digital devices (also
known as human-computer or human-machine interactions).
These smart devices provide physical actuation (e.g., control-
ling light bulbs or thermometers) or virtual actuation (e.g.,
launching apps and sending emails). Beyond local physical
sensing, it is possible to use Web-based sensor data such as
weather and air quality data via open application programming
interfaces (APIs) as virtual sensors [107].

Existing DTx apps that consider just-in-time support often
use diverse real-time sensing features such as activity tracking.
For example, the BeActive system continuously monitors a
user’s physical activity and provides just-in-time feedback
when the user becomes sedentary for more than 50 min [108].
This type of real-time monitoring can be supported by the use
of diverse sensors. Current off-the-shelf smartphones include
various sensors, such as microphones, GPS, motion sensors,
a compass, a light sensor, and cameras. Sensor data can be
passively collected in the background (known as opportunistic
sensing; e.g., tracking a user’s location traces), or users are
asked to perform speciﬁc tasks for data collection (known
as participatory sensing; e.g., taking a photo for food jour-
naling) [109]. In particular, sensor and interaction data from
smartphones or smartwatches facilitate a ﬁne-grained under-
standing of user contexts and the detection of various events
of interest, such as activity tracking with motion sensors and
social interaction tracking with audio sensing or call/SMS log
tracking. Wearable devices such as smartwatches and activity

10

IEEE/CAA JOURNAL OF AUTOMATICA SINICA, VOL. X, NO. X, X X

trackers offer a similar level of sensing, but the key departure
is their support for sensing physiological signals, such as heart
rate and skin temperature, which are useful for detecting stress
and emotions (see Cowley et al.’s review [110]). Consumer
electronics offer only limited capabilities for data collection,
whereas wearable sensors for research purposes (e.g., Empat-
ica E4 and Shimmer3) provide APIs for accessing raw data;
however, their cost is an order of magnitude greater.

IoT devices can be classiﬁed based on their functionality
and embeddedness. The major functionalities of IoT devices
in domestic and ofﬁce environments include IoT control
(e.g., hubs or voice assistants), actuation (e.g., lighting and
switches), and sensors (e.g., motion, temperature, and air qual-
ity). Most IoT devices are standalone products so that users can
wirelessly control the connected door locks and thermostats
through the Internet. Recent smart appliances, such as air
conditioners, refrigerators, and air puriﬁers, are equipped with
smart features such as state monitoring (e.g., operating condi-
tion logging and environment states) and remote control (e.g.,
temperature control). Unlike human activity monitoring with
standalone IoT devices, smart appliances naturally come with
sensors. As human appliance interactions are naturally part
of activities of daily living, they provide useful information
for health behavior monitoring (e.g., cognitive decline track-
ing [111]). Furthermore, smart appliances can help closely
monitor home environments such as room temperature and
air quality states (e.g., CO2, PM2.5, and VOC). IoT devices
or IoT-enabled appliances are typically connected to central
hubs for integrated control over the Internet. Voice assistants
include Amazon Echo and Google Home, which provide
natural language support for information activities (e.g., Q&A)
and device control (e.g., turning off bulbs). The type of IoT
device control offered by IoT hubs, such as SmartThings Hub,
provides a novel means of enabling DTx; for example, IoT
devices can offer context-aware intervention for personalized
sleep education (e.g., automatically turning off lights) [112].

B. Data-Driven Models for Engagement and Adherence

The digital intervention and passive sensor data are used to
measure user engagement in digital intervention (or software
usage) and user adherence to behavioral changes. Compared
to “software engagement,” adherence to behavioral changes is
relatively easy to measure by tracking the user behavior based
on user interactions (e.g., whether the content is consumed?)
and passive sensing (e.g., whether physical activity has hap-
pened?) or by asking users to self-report. Diverse data-driven
models for user engagement are discussed next; reviewing
such models provides insight into the types of data that can
be collected for data-driven DTx analytics.

A simple approach to measuring user engagement (and
behavioral adherence) involves collecting self-reported feed-
back (e.g., level of satisfaction) [113]. Self-reports can be
submitted at the end of experiments using well-known user
engagement and usability scales, such as the system usability
scale [114], usefulness, satisfaction, and ease of use question-
naire (USE) [115], and the user engagement scale (UES) [116].
These metrics consider diverse dimensions; for example, UES

considers attention, usability, aesthetics, endurability, novelty,
and involvement, and USE considers usefulness, ease of use,
ease of learning, and satisfaction. In the case of digital
health apps, information quality, trust, and security are also
important [117]. While users typically answer these kinds of
survey questionnaires at the end of an intervention period,
it is also possible for participants to report their experiences
on a shorter time scale (e.g., whenever some events happen
or once a day) via EMA. An in-depth understanding of user
engagement is difﬁcult to acquire from surveys; in this case,
follow-up interviews and thematic analysis of the interview
data are required [118].

Prior studies examined various usage metrics of digital
interventions [80], [113], [119]. Basic usage metrics include
the frequency of app use, user responses to proactive prompts,
and on-demand usage that can be aggregated over a speciﬁc
time window (e.g., per day or per week) [119]. In addition,
interaction-level metrics can be considered. For a given use
instance, the frequency of ﬁne-grained interaction types, such
as glancing, checking, and brief/detailed reviewing and their
durations [80] can be summarized. In-depth interaction pat-
terns can also be analyzed, such as the inter-checking intervals
and receptivity to push notiﬁcations [113]. It is also possible
to build a composite engagement index, a simple approach
for a linear weighted sum of usage metrics [113] such as the
number of pages viewed per session, frequency of app access,
receptivity to push notiﬁcations, inter-checking intervals, and
self-reported feedback (satisfaction).

In addition to such usage metrics, prior studies have exam-
ined the use of passive sensor data. Traditional engagement
models based on ﬂow theory mainly consider user alloca-
tion of attentional resources and their affective states. It is
possible to measure a user’s attention via behavioral and
physiological sensor data, such as eye-tracking, facial expres-
sion, mouse movements, electrodermal activity (EDA), ECG,
and electroencephalogram (EEG) data. Martey et al. [120]
analyzed how passive sensor data (e.g., EDA and mouse
movements/clicks) can be used to estimate self-reported en-
gagement. Lascio et al. [121] explored how EDA data can
be used to model a student’s emotional engagement (i.e.,
enthusiasm and enjoyment) with the support vector machine
(SVM). Mathur et al. [122] used EEG data to model user
engagement from mobile context data and identiﬁed a strong
correlation between automatically detected engagement scores
and users’ subjective perception of engagement. Pielot et
al. [123] considered consumption of recommended content
as “engagement” and used machine learning (i.e., XGBoost)
to identify latent engagement factors, which are based on
diverse passive data collected ranging from mobile app usage
to mobile sensing data. This type of mobile phone data can
also be utilized on a larger scale (e.g., understanding people’s
behaviors and activities at the community level) [124]. Recent
advances in mobile, wearable, and IoT technologies have en-
abled a wide array of novel health care consumer applications
using big data analytics [125].

LEE et al.: TOWARD DATA-DRIVEN DIGITAL THERAPEUTICS ANALYTICS: LITERATURE REVIEW AND RESEARCH DIRECTIONS

11

Causal Analysis

Experimental Design

Randomized

Random assignment

Randomized controlled trials

Definite causality

Micro-randomized trials

Control
(A)

Treatment
(B)

A - A - B - A - … - A
B - A - B - B - … - A

…

…

B - A - B - A - … - A

Single-case studies
(n-of-1 trials)

Baseline - Treatment - Baseline - …

Indefinite causality / 
Correlation

Quasi-experiments

Non-random assignment

Control
(A)

Treatment
(B)

Observational studies

Non-randomized

Fig. 5. Experimental design and data analysis framework of DTx

Motion

Compass

App use

Everyday
Activities

Labels

GPS

Light

Touch

Passive Sensor
Data Collection

Sensor Data 
Windowing

Fig. 6. Data analysis pipeline for DTx analytics

Self-report or behavior tracking

Feature 
Extraction

Context Analysis
(e.g., activity, cognitive and 
psychological states)

Z

X

Y

Causal Inference 
(e.g., engagement with DTx
and behavior changes)

C. Experimental Design and Data Analysis Methods for DTx

Similarly to the development procedure of conventional
therapeutics, the development and application of DTx depend
heavily on the choice of experimental design and subsequent
data analysis (Fig. 5). Various existing experimental designs
suggested for eHealth or mHealth experiments can be applied
to DTx to establish a causal relationship (i.e., evidence-
based treatment). RCTs are the gold standard, whereby each
experimental unit (or human subject) is randomly assigned to
treatments (or conditions), and the outcomes are measured.
The causal effect of the introduced treatment on the out-
come variables is investigated by comparing the values of
the outcome variables before and after the intervention while
accounting for confounders.

The experimental design of data-driven DTx analytics fur-
ther involves continuous passive data collection. Beyond es-
tablishing a causal relationship between the treatment and
outcome variables, passively observed sensor data provide
additional opportunities for DTx optimization by extracting
various context and intervention variables (Fig. 6). Passive

sensor data analyses can be used to understand intervention
contexts, improve delivery mechanisms, evaluate intervention
components, and personalize treatments (see Section V-E). In
reality, RCTs are very expensive as they require hundreds
(or even thousands) of participants, and are even less prac-
tical when DTx software has already been deployed. In the
following subsection, both randomized and non-randomized
experimental designs are reviewed along with the associated
context analysis and causal effect inference methods applicable
to data-driven DTx analytics.

1) Experimental Design for Data-Driven DTx Analytics:
As with conventional therapeutics development, RCTs are the
most appropriate experimental designs for DTx. In RCTs, the
subjects are randomly assigned to either the experimental or
control group. The treatment outcomes of the experimental
group are compared with those of the control group to assess
treatment effectiveness. In the RCT for DTx, the experimen-
tal group is given a digital or mobile platform, such as a
smartphone application, and receives the desired intervention
through the platform. In contrast, the control group can be

12

IEEE/CAA JOURNAL OF AUTOMATICA SINICA, VOL. X, NO. X, X X

deﬁned in multiple ways: subjects in the control group may
be given either conventional treatments, applications without
any intended treatment effects, or no intervention at all [126].
Comprehensive reviews on RCTs for DTx regarding diseases
such as depression, anxiety, and type 2 diabetes have been
published [126], [127], [128].

Another type of randomized design applicable to DTx is the
micro-randomized trial (MRT) [129], [130], which is a design
proposed speciﬁcally for JITAI mHealth experiments [74].
In MRTs, the intervention a subject receives is randomized
at every decision point, that is, a point in time during the
experiment where an intervention may be effective. As a result,
the interventions for each subject are sequentially random-
ized hundreds to thousands of times during the experiment,
making the experiment resemble a sequential factorial design.
Repeated randomizations for every subject point to two main
advantages of using MRTs in DTx experiments. First, the
time-varying causal effects of treatments can be assessed for
the outcomes of interest. Second, both between-subject and
within-subject comparisons are allowed in MRTs, making the
experiments efﬁcient. Randomizations may be stratiﬁed so that
the number of interventions a subject receives is sufﬁcient for
all conditions (e.g., the stress level of subjects) [131].

In cases where an RCT is not applicable, designs such
as quasi-experimental studies and observational studies,
in
which the assignment to the treatment or control group is not
randomized, may be conducted for DTx. Quasi-experimental
studies are experimental studies in which interventions are
manipulated by the researchers without random assignments
or full control over all extraneous confounding variables.
Observational studies are non-experimental studies in which
interventions are not controlled by researchers. Although these
studies cannot draw any deﬁnite conclusions about the causal
treatment effect because of the presence of confounders, they
can be used to initially investigate the introduced interven-
tions. For example, a mobile application to aid the treatment
of diabetes may be provided to patients who would use
the app freely without any explicit intervention by the re-
searchers during the ﬁeld trial [132]. Quasi-experimental stud-
ies such as pretest-posttest designs [133], [134] or matching
designs [135], [136], have also been conducted to investigate
the efﬁcacy of mobile applications.

Single-case (also known as n-of-1) designs are a family
of experimental designs applicable to DTx that contain as-
pects of both randomized and non-randomized trials. Single-
case trials are experiments in which each subject acts as
its own control, usually because the available sample size
is very small. Similarly to MRTs, single-case trials capture
the temporal dynamics within the study, as is often required
by DTx studies. In general, single-case trials consist of two
phases: the baseline and treatment. First, data are collected
during the baseline period with no intervention, which serves
as the control for the subject. Afterward, the intervention
of interest is given to the subjects, and data for the same
variables are collected. The causal effect of the intervention is
estimated by comparing the treatment and baseline periods. In
many cases, the baseline and treatment periods are repeatedly
alternated (possibly with washout periods) for the “replication”

of experiments or a clearer distinction of the causal effect of
the treatment, by controlling for the confounding variables. In
addition, different types of interventions or gradual changes in
the intervention may be introduced after each baseline period,
if necessary. When the baseline and treatment periods are
randomly allocated within subjects, the trial is called an n-
of-1 RCT. A more detailed review of single-case studies can
be found in [137], [138].

2) Context Analysis Methods for DTx Analytics: The goal
of context analysis is to use observational data to support
exploratory tasks of investigating intervention contexts and
behavioral routines or patterns, which can be captured using
a set of observable characteristics of an individual through
mobile and wearable devices such as activity trackers and
smartphone loggers [139], [140]. The data sources range from
passive sensor data (e.g., self-trackers and smartphone logging)
and social media use to active self-reporting (e.g., mood and
stress).

Mobile and wearable devices allow the performing of
continuous and unobtrusive measurements of user contexts
and help to infer users’ health and behaviors [141]. Prior
studies have proposed several methods for analyzing users’
intervention contexts and behavioral patterns. Here, “context”
typically means “any information that can be used to char-
acterize the situation of a person” [142]. A context refers
to a situation and environment in which a device or user is
situated by a set of relevant features, such as human factors
(e.g., user, social setting, and tasks) and physical factors (e.g.,
location and infrastructure) [143]. Harari et al. [140] proposed
a three-dimensional context model, which included social
interaction, daily activities, and mobility patterns. Behavioral
patterns in each dimension are further deﬁned based on the
data processing of user contexts (e.g., the duration of social
interaction). Similarly, Mohr et al. [144] proposed a hier-
archical contextual feature model in which low-level sensor
data were transformed into low-level features that constituted
high-level behavioral patterns. Most low-level features, such
as location and activity types, are human-interpretable. High-
level behavioral patterns may include intervention contexts or
behavioral patterns related to mobility patterns (e.g., number
of signiﬁcant places visited) or interaction patterns (e.g., daily
phone use frequency).

For context sensing, motion sensors can be used to detect
various types of physical activity, such as movement [145],
sleeping [146], eating [147], and agitation [148]. For example,
a user’s sedentary state can be easily calculated by comparing
the arithmetic difference between accelerometer samples. Eat-
ing gestures can be recognized by applying machine learning
(e.g., random forest) to wrist motion data measured using
smartwatches [147]. GPS location traces can be processed to
detect signiﬁcant places (e.g., home and work) using clustering
techniques [149]. In addition to physical activity tracking via
sensors, prior studies used passive sensor data to infer cog-
nitive and psychological states, such as depression [149] and
social anxiety [150]. To identify the depressive symptoms of
an individual, for example, mobility features (e.g., signiﬁcant
places visited) were extracted from smartphone GPS traces
and personalized machine learning models with a support

LEE et al.: TOWARD DATA-DRIVEN DIGITAL THERAPEUTICS ANALYTICS: LITERATURE REVIEW AND RESEARCH DIRECTIONS

13

vector machine (SVM) classiﬁer were tested [149]. One way of
optimizing intervention contexts is to provide timely delivery
of intervention with mobile, wearable, and IoT technologies,
owing to obtrusive modality usage (e.g., visual, vibration, and
sound notiﬁcations). However, interruptive messages result in
productivity loss, increased stress, and time pressure [151],
implying that less opportune delivery of intervention may
lead to a low level of intervention adherence [152]. A user’s
behavioral routines can be leveraged to ﬁnd opportune mo-
ments (e.g., activity transition times) [153]. A user’s contextual
model based on temporal and location contexts can be further
used to deﬁne the complex rules for delivery timing.

3) Causal Inference Methods for Data-Driven DTx Ana-
lytics: Data-driven DTx analytics focuses on estimating the
treatment effect under the potential outcomes (Neyman-Rubin
causal) framework [154], [155], whereby the potential out-
comes (both factual and counterfactual) or a contrast (e.g., dif-
ference and ratio) are estimated either nonparametrically or by
using models such as generalized estimating equation (GEE)
and multilevel model (MLM). These models assume certain
parametric regression form, in which the ﬁtted model explains
the causal effects of the treatment variables. For example,
in MRTs, the average treatment effect under the potential
outcome framework can be estimated through standard GEE
or MLM regression, where the estimated coefﬁcient of the
treatment variable represents the mean difference in proximal
outcomes between when the intervention is given and when it
is not [129]. Furthermore, various estimation methods tailored
for MRTs, such as the centered and weighted least-squares
method [156], have also been proposed as a direct application
of the models, which may lead to unstable estimation due
to time-varying or endogenous covariates [131], [156], [157],
[158]. Similarly, the GEE and MLM can be used to estimate
the treatment effect in single-case studies with appropriate
modiﬁcations [159], [160].

In the case of quasi-experimental or observational studies, it
is difﬁcult to identify deﬁnite causality because confounders
are not controlled. Despite this limitation, it is common to
compare the treatment and control groups to obtain a sense of
the efﬁcacy of an intervention [133], [134]. For example, as
a pretest-posttest regarding the effect of a digital intervention
on cardiovascular risk factors in postmenopausal women with
obesity, the outcome variable (e.g., blood pressure) was mea-
sured before and after the experiment for both the treatment
and control groups, and the difference in outcomes between
the groups was compared [133]. A statistically signiﬁcant
difference between the groups suggests that the interventions
are effective, although conclusions regarding the causal effect
of the intervention cannot be made. Correlational analyses can
also be conducted for the same purpose.

One possible approach for estimating causal effects using
observational data is to adjust for the effects of confounders
using methods such as stratiﬁcation, matching, standardization,
and weighting [161]. Adjustment methods can be applied
either nonparametrically by calculating the necessary estimates
from the data or parametrically by ﬁtting some models to
obtain the estimates (e.g., parametric G-formula and marginal
structural models). It is common to use propensity scores [162]

(or other types of balancing scores) to estimate the probabil-
ity that the subject is placed in the treatment group, given
covariate values, instead of directly using the observed vari-
ables. These methods attempt to create a pseudo-population
or matched population from an observational dataset such
that the treatment and control groups display a similar co-
variate distribution. For example, in a behavioral study using
smartphone sensor data, the causal effects of various lifestyle
factors (mobile phone use) on stress levels (emotional state)
were analyzed by creating a matched population from context
variables extracted from the sensor data [135], [136]. A
practical tutorial on matching methods can be found in this
reference [163].

Traditional adjustment methods are not generalizable to
time-varying treatments and confounders, thereby resulting in
biased estimates. To handle more complex longitudinal ob-
servational data with time-varying covariates, a more general
class of models called G-methods for time-varying treatments
was developed by Robins et al. [164]. These models, un-
der appropriate assumptions, provide consistent estimates on
contrasts of average treatment effects in scenarios with time-
varying treatments and confounders by taking into consider-
ation the “history” (the value of treatment and confounding
variables up to the time point of interest) of subjects.

This review focuses on the potential outcomes framework.
In contrast, the causal inference developed by Pearl [165],
based on causal graphs and structural causal models, can also
be implemented for similar purposes. In Pearl’s framework,
each node represents a variable, and the directed edges repre-
sent direct causation from one variable to another. The causal
relationships encoded in causal graphs can be translated into
structural models and various causal inference tasks, such
as causal structure discovery, which retrieves the underlying
causal graph from observational data, and then treatment effect
estimation from observational data can be conducted.

Another notion of causality often encountered in the liter-
ature is predictive causality. Granger causality [166], one of
the most common concepts of predictive causality, measures
whether a time series is predictive of another by testing
whether the lagged values of one variable have predictive
power for the upcoming values. In the case of dynamic systems
where variables exhibit deterministic relationships, convergent
cross mapping [167] can be used to discover the causality
of two time series by leveraging time-delayed embeddings.
These methods have been used to explore predictive causality
in mobile data [168], [169]. Readers can ﬁnd a comparative
analysis of these approaches in [170].

D. Data Visualization for DTx

Data visualization aims to visually represent datasets to
help people perform exploratory tasks more effectively [171].
Existing data visualization tools often support various user
interactions such as changing visual encodings and navigat-
ing datasets (e.g., zooming, slicing, and projecting), thereby
facilitating data-driven reasoning or decision-making, which
is referred to as visual analytics [172].

Data-driven DTx analytics is based on personal big data
collected from mobile and wearable devices. Passively col-

14

IEEE/CAA JOURNAL OF AUTOMATICA SINICA, VOL. X, NO. X, X X

lected DTx datasets are characterized by a high volume and
velocity data-stream of sensor and interaction data with dif-
ferent spatiotemporal granularities (e.g., temporal: event time
or day/week/month windowing, spatial: GPS points, places,
or regions), semantic hierarchies (e.g., semantic grouping
of sensors), and data types (quantitative, categorical, and
unstructured). Visual analytics tools should support visual
data exploration (e.g., charting datasets) and automated data
analysis (e.g., data mining and machine learning) [172]. Visual
data exploration, on the other hand, helps users check data
quality and test research hypotheses visually. In addition,
insightful information can be extracted by interacting with
the data (e.g., examining and comparing different datasets
and, zooming in on different parts). These insights, in turn,
help build better models for data analyses and visualization
explorations. In data-driven DTx analytics, this type of value-
sensitive visualization is critical. Clinicians or developers may
want to inspect user contexts, DTx usage, and behaviors not
only to understand user engagement and behavioral adherence
but also to acquire design insights for DTx improvements.

When visualizing time-oriented data, the ﬁrst step is to
characterize the key characteristics of time-series data, such
as temporal primitives (i.e., time points vs.
intervals) and
the structure of time (e.g., linear vs. cyclic as in seasons
of the year) [173]. As reviewed by Brehmer et al. [174],
effective timeline visualization requires careful exploration of
the design space such as visual representation (e.g., linear,
radial, grid, or spiral), scale of a timeline (e.g., sequential,
chronological, relative, or logarithmic), and layout of views
(e.g., single vs. multiple timelines, and segmented timelines).
In addition, analytic reasoning for time-series data can be
facilitated by supporting diverse user-interaction techniques
(e.g., zooming, faceting, focus, and context) [175]. Thus,
data visualization support for DTx must carefully consider
data characteristics of mobile and wearable data and analytic
reasoning tasks.

Visualizing a large volume of personal big data is chal-
lenging; thus, it is important to support visual summaries
of multidimensional time-series data. A simple visualization
of the data streams collected from mobile and wearable
devices would not be scalable; for example, a minute-level
“behaviorgram” of smartphone data [176] could be quickly
cluttered as the number of data streams increases. For effective
visualization, DataMD [177] provides a visual dashboard for
clinicians with visual summaries and trend lines of user
activities for data-driven consultation. Interactive visualization
allows users to compare multiple relevant timelines to help
explore rich contextual data (e.g., identifying stressors by ex-
amining stress levels across different contexts over time [178]).
Advanced machine learning techniques can be used to ﬁnd
key relevant features such as behavioral markers related to
cognitive decline [176]. Event sequence mining can be used
to uncover temporal patterns such as the event patterns before
the occurrence of smoking [179].

E. DTx Design and Development Process

Digital therapeutics can be developed and improved during
the product lifecycle. In this section, a review of DTx design

and development processes is provided to illustrate how data-
driven DTx analytics can help improve DTx services (Fig. 7).
1) DTx Design and Development Process Review: The
concept of DTx is highly related to that of digital health and
persuasive technology in that software is used to persuade
users to change their behaviors. Thus, a literature review is
provided regarding the design and development process: (1)
plan and target setting, (2) design and development, and (3)
evaluation of efﬁcacy.

Plan and target setting: The ﬁrst step is to identify the target
medical disorder or disease. Fogg mentioned “a simple target
behavior to change” as the ﬁrst consideration for designing
a successful persuasive technology [81]. Since the design
process of DTx is mainly rooted in pervasive technology,
a target disease or behavior should be selected ﬁrst. The
behavioral changes mentioned here could be the detailed goals
of a larger objective (i.e., dealing with medical disorders). For
example, patients with prediabetes can set detailed goals for
exercise or diet management to prevent diabetes. After setting
the target disease, researchers should identify the needs of
the target user and draw design implications. It is crucial to
understand the patients’ point of view on digital health product
use to implement what they need for the behavior change
through “patient-centered design” methods, which involve
patients in the process of development [180]. In addition, it is
necessary to identify the theoretical basis and existing evidence
underlying the design of the intervention, which provides the
rationale for selecting speciﬁc target diseases and behaviors,
target users, and behavioral change techniques [19]. Evidence
from existing research can be collected using a systematic
review of RCTs, or by testing relevant proven methods before
development [181].

Design and development: The second step begins with the
implementation of behavior change techniques. The behavior
change technique (BCT) refers to “an observable, replicable,
and irreducible component of an intervention designed to alter
or redirect causal processes that regulate behavior. [182]”
For example, for the purpose of physical activities, various
BCTs, such as providing guidance for a speciﬁc behavior,
providing feedback on the user’s performance, and setting
goals of behavior and outcome are widely used [183]. During
this process, the number and type of BCTs that can be applied
to DTx should be determined based on the identiﬁed target
diseases, users, and theoretical/evidence bases. BCTs are then
instantiated with certain intervention components to allow
patients to interact directly with them. During this process,
the medium to use, timing, and frequency of delivery of the
intervention should also be considered [12]. As an iterative
development process, pilot tests should be conducted on po-
tential users (in this case, patients with the target disease) to
examine the acceptability and feasibility of DTx intervention,
user engagement, and adherence to the instructions.

Evaluation of efﬁcacy: The third step is to evaluate the
efﬁcacy of the DTx intervention. The assessment of the
efﬁcacy can measure different endpoints: (1) how much the
patient behavior changed (i.e., proximal outcome) and (2) the
degree of disease prevention or treatment (i.e., distal outcome).
Randomized controlled (or clinical) trials are favored for

LEE et al.: TOWARD DATA-DRIVEN DIGITAL THERAPEUTICS ANALYTICS: LITERATURE REVIEW AND RESEARCH DIRECTIONS

15

DTx Design &
Development Process

Data-Driven
DTx Analytics Platform

Improve the delivery mechanism
• Delivery modality (how to deliver)
• Delivery timing (opportune moments)

BCT3

BCT1

BCT2

Digital
Therapeutics

Digital Therapeutics

Patient

Evaluate the intervention components
• Control persuasion levels

& tailor therapeutic intervention contents

• Modify intervention strategies

Personalize the treatment
• Segment the target group
• Provide data-driven consultation
• Adjust treatment and medication

1

2

Improvement insights for DTx

Plan and target setting 

• Identify target medical
disorder or disease

• Identify target user needs

and draw design implications

• Identify theoretical ground

and existing evidence

Design and development

• Implement Behavior

Change Techniques (BCTs)

• Conduct iterative

development process
with user feedback

Evaluation of efficacy

• Evaluate the efficacy of
digital therapeutics with
scientific experiments

Fig. 7. DTx Design and Development Process Overview: (1) DTx design and development process with a) Plan and target setting, b) Design and development,
c) Evaluation of efﬁcacy, and (2) Data-driven DTx analytics for acquiring insights for improvement in three ways—a) Improve the delivery mechanism, b)
Evaluate the intervention components, and c) Personalize the treatment. These insights can be re-fed back into the development process to iteratively improve
DTx.

assessing the relative effectiveness of DTx between treatment
and control groups to reduce potential biases (e.g., selection
bias). According to a report, RCTs and meta-analysis studies
evaluating the clinical efﬁcacy of digital health apps are
gradually increasing [39].

2) Data-Driven DTx Analytics for Optimizing DTx Deliv-
ery: Data-driven DTx analytics can improve the efﬁcacy of
existing DTx by uncovering insights to improve therapeutics
and apply them to the iterative development cycle based on the
patient data. Since existing clinical trials have evaluated the ef-
ﬁcacy of digital health interventions mainly with the difference
in endpoints, it becomes a challenge to understand how certain
elements of DTx induce differences and which factors beyond
DTx affect patients’ health concurrently [23]. Beyond efﬁcacy
evaluation, data-driven DTx analytics can play an important
role in further improving DTx by (1) improving the delivery
mechanism, (2) evaluating the intervention components, and
(3) personalizing treatments.

Improve delivery mechanisms: For the delivery of health
interventions, it is necessary to determine the channels of
interaction between DTx and the patient. The appropriate
channels of sensory input and output, or modalities, may vary
depending on user preference (i.e., the preferred device or
modality) or context (i.e., whether the intervention is palpable
or interruption by sound notiﬁcation is allowed) [13]. The
patient’s context and the actual response for each modality can
be analyzed in real time to suggest an effective method that
most likely changes the patient’s behavior. Modality selection

can be automatic, considering the trade-off between the most
effective modality and its availability. (e.g., converting sound
notiﬁcation into mute and LED light during a meeting).
Depending on the context, the patient may or may not be
aware of the DTx instructions and hence may not adhere to
them. Therefore, it is crucial to detect “opportune moments”
to interrupt patients to deliver timely health interventions to
maximize efﬁcacy. These moments can be determined by
context-sensing methods speciﬁc to the platform or feature
extraction by machine learning [13]. During this process,
sensor data may be utilized from smartphones (e.g., ambient
light, sound, or acceleration of the device) for interaction (e.g.,
touching or sliding the screen) to understand the context of
the user, as suggested in [184]. It is also possible to divide
the delivery process of the intervention into several stages to
identify the point at which the process fails [15]. As suggested
in this study, whether the patient (1) perceives the intervention,
(2) is available to respond, (3) adheres to the intervention, and
(4) performs the target behavior can be affected by several
contexts. Thus, contextual data are collected and utilized to
build a model that can improve delivery mechanisms.

Evaluate the intervention components: During the develop-
ment process of DTx, BCTs are determined based on a theo-
retical basis or existing proven research. However, such BCTs
may not result in the same efﬁcacy because of differences in
the target medical disorder, target user traits, or the context
of therapeutic use. Data-driven DTx analytics can be used
to evaluate the extent to which each BCT component affects

16

IEEE/CAA JOURNAL OF AUTOMATICA SINICA, VOL. X, NO. X, X X

the target behavior (proximal outcome). A component-wise
evaluation is less practical because of its complexity and cost.
Instead, the observed sensor data can be used to determine
this type of component-wise efﬁcacy via a pseudo-experiment
design. This helps determine the relative importance of com-
ponents and guides designers and clinicians on how to improve
the components or to better evaluate BCTs (experimental
design). In addition, it may be possible to identify inter-
relationships and causal relationships of the components,
similarly to a model describing correlations and interactions
among health-related attitudes [185]. This evaluation can help
develop a new strategy, such as emphasizing certain BCT
components by similar patient groups or deploying motivators
to enhance their use. Compliance with persuasion for DTx
may vary depending on the patient’s personality traits, such
as extraversion, agreeableness, conscientiousness, neuroticism,
and openness to experience [186]. The data collected can be
used to create a “persuasion proﬁle” to predict how many
different types of persuasion principles (e.g., authority, con-
sensus, commitment, or scarcity) would affect patients with
different personalities [187]. Thus, the persuasion level can
be controlled by changing the intensity of the wording, the
frequency of sending persuasive messages, and personalizing
the
persuasion principles to each individual. In addition,
patterns of interaction can differ with intervention content
because the patient may have difﬁculty in understanding the
content, lose interest in the content, or not be motivated to
learn. Data-driven analytics then utilizes interaction patterns
to design intervention coursework or recommend content that
may engage the patient’s interest. Recently, Yue et al. [188]
reviewed widely used techniques for content recommendation,
such as content-based (i.e., content with similar features),
collaborative ﬁltering-based (i.e., modeling user behavior), and
hybrid methods. These approaches can also be adapted to the
intervention content recommendations in DTx.

Personalize the treatment: DTx can be further improved or
“personalized” through an understanding of the target group
via contextual analytics. Patients can be divided into subgroups
based on their engagement in or adherence to therapeutics. For
example, Alshurafa et al. [80] classiﬁed clusters of patients
who showed similar health behavior changes in four categories
(i.e., “healthy and steady,” “unhealthy and steady,” “decliners,”
and “improvers”). This approach may help predict changes in
health activities by considering the characteristics of patient
groups to formulate appropriate strategies. In addition, more
personalized treatments can be achieved by adding personal
traits. For instance, the outcome of behavior change can be
analyzed in relation to certain variables, such as demographics,
health status, and psychosocial features [189]. This process
enables the analysis of more speciﬁc target segments and
even covers niche patient groups using upgraded DTx. The
analytics platform can also help health coaches understand
patient engagement and adherence to DTx based on collected
data (e.g., the patients’ context, therapeutic usage pattern, and
proximal and distal outcomes). Moreover, the platform may
suggest the advice needed for the patient by visualizing ac-
tivity data. With this information, the coach can provide data-
driven, personalized discussions to the patient and improve

the efﬁcacy of therapeutics. DTx can be used independently
or along with other traditional treatments. If the patient takes
medicine as part of DTx (e.g., Pear Therapeutics’ substance
use disorder intervention), the analytics can be used to increase
the effectiveness of the medication in use and result in better
outcomes. For example, in the case of depression, DTx allows
the patient to record the degree of depression, quality of sleep,
and activities performed. Based on these data, a clinician can
control the type, combination, or dose of medication when the
patient visits the hospital.

VI. RESEARCH DIRECTIONS FOR DATA-DRIVEN DTX
ANALYTICS
A. Data Collection and Data-Driven Delivery Optimization

Data quality management: While conducting a large-scale
experiment in the wild, a general-purpose data platform guar-
antees that all necessary data from users are collected with
data quality support (e.g., format, completeness, and fresh-
ness [190]). When data quality is compromised, the analytics
platform can notify key stakeholders (e.g., data providers,
managers, or DTx developers) for further intervention (e.g.,
checking mobile apps or ﬁxing software errors). Moreover,
the analytics platform may need to detect a user’s abnormal
behavior for quality management (i.e., injecting fake data to
maximize rewards or violation of experimental guidelines).
These abnormalities can be easily captured by outlier detection
with suitable feature tracking (e.g., local outlier detection [191]
and machine learning [192]). Existing CTMSs or data collec-
tion platforms can consider implementing additional features
to enhance data quality management.

Intervention delivery optimization: Another research direc-
tion related to receptivity improvement of analytics platforms
is opportune moment detection and modality selection; these
analyze tailoring variables (i.e., user’s behavioral and con-
textual data) and intervention components to ﬁnd the most
effective time that maximizes user engagement. This includes
deferring the intervention until the predicted deadline [193].
Furthermore,
the analytics platform requires selecting an
appropriate modality in a multi-device environment (e.g.,
laptops, smartphones, smartwatches, and IoT appliances) to
consider user preferences, device accessibility, and proper-
ties of the intervention [194]. Finally, ﬁnding an opportune
moment and modality selection should be cross-optimized to
improve receptivity to the DTx software, which is an open and
interesting research area.

B. Causal Inference for Data-Driven DTx Analytics

In DTx scenarios, observational studies are conducted along
with randomized studies because of the cost or difﬁculty of
conducting complex experiments. For example, the number of
conditions increases exponentially with the number of factors
(e.g., intervention components). Recent advances in artiﬁcial
intelligence and deep learning have led to high-performing
causal inference models for observational data, which han-
dle the lack of randomized controlled environments through
model architecture [195], [196], [197], [198], [199], [200].
In these studies, individual treatment effect estimation was

LEE et al.: TOWARD DATA-DRIVEN DIGITAL THERAPEUTICS ANALYTICS: LITERATURE REVIEW AND RESEARCH DIRECTIONS

17

performed through counterfactual inference, in which machine
learning models, including deep neural networks [196], [197],
[199], [200] and tree-based models [195], [198], were used
to estimate all potential outcomes and thus the causal effect.
Counterfactual inference models that use sequential models
such as recurrent neural networks have also been proposed to
handle the bias from time-varying confounders [201], [202],
[203]. Similar counterfactual inference frameworks can be
applied to data-driven DTx analytics in which the effect of
treatments delivered through digital or mobile platforms is
estimated through deep networks based on passively collected
DTx datasets. Various deﬁnitions of treatments can be explored
and implemented accordingly, depending on the causal analy-
sis of interest, through effect estimation models. For example,
treatment variables can be deﬁned based on the engagement
levels of the DTx software, or various sets of actions can
be observed via passively collected data. Regardless of how
the treatment variables are deﬁned, an appropriate model
architecture that incorporates all aspects of passively collected
DTx data is required to estimate all potential outcomes for
accurate causal analysis of DTx.

C. Data Visualization for Data-Driven DTx Analytics

One of the critical challenges in data visualization is the
volume of personal stream big data. During a clinical trial, a
stream of sensor and interaction data can be collected from
hundreds or thousands of people over a few months. As
discussed in Section VI-D, it is also possible to collect data
after deployments for continuous improvements (from those
who opt-in for data collection). Prior studies explored vari-
ous interactive visualization techniques to efﬁciently navigate
through large-scale disease or patient datasets [204], [205];
for example, CareFlow helps visualize the outcome data of
50,000 patients in a tree-like timeline and provides a high-
level overview of similar groups of patients [205]. Large-
scale datasets are processed to extract hundreds or thousands
of features for contextual and causal analytics. Visualization
of such high-dimensional data is challenging. As in existing
machine learning studies, dimensionality reduction techniques
such as principal component analysis or t-distributed stochastic
neighbor embedding can be used for dataset exploration and
annotation. Leveraging domain knowledge as well as prior
data-driven DTx analytics experience can also help focus on
speciﬁc sensor and interaction data types. As illustrated earlier,
DTx design and development are mainly led by prior domain
knowledge on theoretical grounds and existing evidence [19].
According to a recent survey on depression, several key
behavioral features include location, physical activity, and
sleep [206]. Data-driven DTx analytics, including correlation
analyses and causal inference, allows for further reduction
of the feature space. As a result, clinicians can manually
examine the reduced feature space to effectively explore
hypotheses on contextual and intervention factors affecting
engagement and behavioral adherence. It is envisioned that
artiﬁcial intelligence-inspired ranking mechanisms will auto-
matically generate a ranked list of hypotheses to be examined.

D. DTx Design and Development Process

The existing literature on DTx design mostly focuses on
design principles, and there is a lack of practical guidelines
on how software development and evaluation methods can
be incorporated into the design and development process. As
shown earlier, the US FDA introduced a pre-certiﬁcation pilot
program that certiﬁes SaMD “developers” instead of SaMD
“products” to manage the total product lifecycle (TPLC),
which “enables the evaluation and monitoring of a soft-
ware product from pre-market development to post-market
performance, along with the continued demonstration of the
organization’s excellence” [61]. It is important to collect and
analyze real-world datasets for DTx to continuously improve
product safety and effectiveness and to deal with potential
risks.

The challenge is to establish user-centered agile software
development (UCASD) practices and principles for DTx de-
sign, development, and evaluation, as recommended by Pach
et al. [207] (e.g., minimizing the complexity of DTx design
and jointly conducting app development and evaluation). Well-
known UCASD principles can be applied to DTx. Software
design and development occur in short iterations, with incre-
mental improvements. Design, development, and evaluation
occur in parallel interwoven tracks, and stakeholders (e.g.,
patients, clinicians, and developers) are actively involved in the
entire process [118], [208]. In UCASD, evaluation can occur
at various stages: initial (pre)design phases (e.g., plan/target
setting and implementation of behavior change techniques),
iterative development of DTx software, clinical evidence
evaluation (for clinical trials), and in-the-wild deployments.
Existing user-centered design techniques (e.g., small-scale user
studies by interviewing participants) can consider “data-driven
DTx analytics.” It
to systematically examine
how diverse datasets collected during different evaluation
stages can be used by key stakeholders to acquire design
insights for DTx improvements (e.g., data mining for usability
issue identiﬁcation [209]). For example, during the clinical
evaluation stage, RCTs can be conducted using passive data
collection for data-driven analytics. When considering the
TPLC of DTx, data-driven analytics helps a company not
only with continuous monitoring of product safety and risk
factors but also in providing opportunities for iterative design
improvements. Further case studies on DTx design and devel-
opment processes using data-driven DTx analytics should be
conducted to establish practical DTx design and development
practices and principles.

is important

The review and discussion in this work mostly focused
on conventional mobile and wearable application designs for
DTx. It is increasingly important to consider new comput-
ing platforms for BCT delivery, such as virtual reality and
metaverse (e.g., Facebook’s Horizon Workrooms, Microsoft
Mesh, and NVIDIA Omniverse) [210] and conversational
agents (e.g., Google Assistant) [211]. Further studies must
be conducted to understand user engagement and adherence
patterns in novel platforms, such as tracking an avatar’s
behaviors in the metaverse for data-driven DTx analytics.
In addition, the delivery of therapeutic interventions can be

18

IEEE/CAA JOURNAL OF AUTOMATICA SINICA, VOL. X, NO. X, X X

extended using physically embodied smart agents, such as
robots. In terms of human-robot interaction, diverse responses
are collected from users, such as visual/vocal nonverbal cues
or subjective feelings during the interaction, which are then
utilized to evaluate and improve interventions [212], [213].

mobile and wearable environments, much like earlier studies
that thoroughly studied the design space of privacy notice and
choices [221], [222]. We anticipate that implementing dynamic
consents will enhance the MyData vision in DTx contexts.

VII. CONCLUSION

E. Privacy and Ethics in DTx Analytics

Given the DTx analytics uses a vast amount of personal data
collected from mobile, wearable, and IoT devices (e.g., GPS
locations, phone usage, and emotion samples), privacy and
ethics must be carefully evaluated. Recent studies examined
user motivations and concerns when collecting data on mobile
and wearable devices [214], [215]. The two main reasons
why users provide their data are ﬁnancial gain and altru-
istic beneﬁts (e.g., scientiﬁc advances) [215]. According to
Rooksby et al. [214], the major concerns are related to negative
user experiences of data collection; e.g., privacy concerns of
sensitive data collection, negative thoughts and feelings about
self-reporting, and detrimental effects on device performance.
Although the majority of data contributors are not typically
concerned with privacy, Lee et al. [215] further showed that
privacy concerns are related to feelings of surveillance, the
identiﬁcation of daily routines, and data breach.

For ethical reasons, Huh-Yoo et al. [216] stressed the
signiﬁcance of communicating with the study participants as
part of the informed consent process by elaborating on the
known potential risks (as well as their additional concerns) and
how to mitigate those risks. In DTx settings, it is critical to
communicate the types of behavioral and sensor data that are
gathered, whether any of it contains any personally identiﬁable
information, and the potential risks associated with sharing
sensor data. However, it was found that users frequently have
incorrect mental models regarding the types of data collected
from mobile and wearable devices, and how they are used to
build AI models [215]. Therefore, researchers must provide
intuitive explanations about the types of data collected and
allow users to access their own data by supporting interactive
data visualization tools (e.g., minute-level behaviorgram of
sensor data streams [217]). In fact, DTx analytics could lever-
age the MyData vision that empowers users by offering direct
access and control of their own data [218]. The MyData vision
extends the EU’s General Data Protection Regulation (GDPR)
that intends to enhance users’ control and rights over personal
data. Further study is required to develop novel user-friendly
tools that allow users to directly access and control their own
data as part of DTx data analytics platforms, similar to Privacy
Bird [219], a user-friendly web data privacy management tool
for the Platform for Privacy Preferences (P3P).

Data collection requires informed consents from participants
where researchers and clinicians must
inform participants
about the risks and beneﬁts of study participation. Before
collecting any data, one-time informed consents are normally
obtained. Recent research has supported the usage of dynamic
informed consents, which enable users to adaptively modify
their consents in response to their contextual needs, such as
turning off GPS while visiting hospitals [220]. Future research
should investigate the design space of dynamic consents in

it

is critical

Digital therapeutics as SaMD aims to cure diseases and
improve health conditions, which is a major departure from
existing wellness products. Health interventions are delivered
through digital technologies (e.g., mobile content, chatbots,
to analyze and
and push notiﬁcations); thus,
optimize the engagement and receptivity to DTx delivery
systems. We proposed a data-driven DTx analytics framework
that allows researchers and practitioners to collect mobile,
wearable, and IoT data as part of ﬁeld experiments and to
perform contextual analytics and causal inference for DTx
delivery optimization. We reviewed the core components of
data-driven DTx analytics such as data collection and user
management, data-driven modeling for DTx usage and be-
havioral adherence, experimental design and contextual/causal
analytics, data visualization, and DTx design optimization.
Finally, we discussed research directions for data-driven DTx
analytics, such as causal inference, data visualization, delivery
optimization, design process optimization, and the privacy and
ethics of data-driven DTx. Over the last few decades, there
have been signiﬁcant advances in mobile sensing and machine
learning, and observational data have provided new opportu-
nities for DTx development and optimization. However, data-
driven DTx analytics faces novel challenges such as privacy
risks due to extensive data surveillance and development and
operation risks due to the heterogeneity of mobile platforms
and IoT devices (e.g., iOS vs. Android). Despite these chal-
lenges, we hope that our work serves as a foundation for this
new research direction, and we call for further research on
data-driven DTx analytics.

ACKNOWLEDGMENT

This

research was

supported by Basic Science Re-
search Program through the National Research Foundation
of Korea (NRF) funded by the Korea government (MSIT)
(2020R1A4A1018774)

REFERENCES

[1] O. Sverdlov, J. Van Dam, K. Hannesdottir, and T. Thornton-Wells,
“Digital Therapeutics: An Integral Component of Digital Innovation in
Drug Development,” Clinical Pharmacology & Therapeutics, vol. 104,
no. 1, pp. 72–80, 2018.

[2] Digital Therapeutics Alliance, “Digital Therapeutics: Combining Tech-
nology and Evidence-based Medicine to Transform Personalized
Patient Care,” 2018, https://dtxalliance.org/wp-content/uploads/2021/
01/DTA DTx-Deﬁnition-and-Core-Principles.pdf (accessed: 2022-03-
06).

[3] C. C. Quinn, M. D. Shardell, M. L. Terrin, E. A. Barr, S. H.
Ballew, and A. L. Gruber-Baldini, “Cluster-Randomized Trial of a
Mobile Phone Personalized Behavioral Intervention for Blood Glucose
Control,” Diabetes Care, vol. 34, no. 9, pp. 1934–1942, 2011.

[4] A. N. Campbell, E. V. Nunes, A. G. Matthews, M. Stitzer, G. M.
Miele, D. Polsky, E. Turrigiano, S. Walters, E. A. McClure, T. L. Kyle
et al., “Internet-Delivered Treatment for Substance Abuse: A Multisite
Randomized Controlled Trial,” American Journal of Psychiatry, vol.
171, no. 6, pp. 683–690, 2014.

LEE et al.: TOWARD DATA-DRIVEN DIGITAL THERAPEUTICS ANALYTICS: LITERATURE REVIEW AND RESEARCH DIRECTIONS

19

[5] S. C. Sepah, L. Jiang, R. J. Ellis, K. McDermott, and A. L. Peters,
“Engagement and Outcomes in a Digital Diabetes Prevention Program:
3-Year Update,” BMJ Open Diabetes Research and Care, vol. 5, no. 1,
p. e000422, 2017.

[6] S. H. Kollins, D. J. DeLoss, E. Ca˜nadas, J. Lutz, R. L. Findling,
R. S. Keefe, J. N. Epstein, A. J. Cutler, and S. V. Faraone, “A
Novel Digital Intervention for Actively Reducing Severity of Paediatric
ADHD (STARS-ADHD): A Randomised Controlled Trial,” The Lancet
Digital Health, vol. 2, no. 4, pp. e168–e178, 2020.

[7] Grand View Research, “Digital Therapeutics Market Size & Share,
Industry Report, 2018–2025,” 2017, https://www.grandviewresearch.
com/industry-analysis/digital- therapeutics- market (accessed: 2022-03-
06).

[8] D. A. Greenwood, P. M. Gee, K. J. Fatkin, and M. Peeples, “A Sys-
tematic Review of Reviews Evaluating Technology-Enabled Diabetes
Self-Management Education and Support,” Journal of diabetes science
and technology, vol. 11, no. 5, pp. 1015–1027, 2017.

[9] R. J. Widmer, N. M. Collins, C. S. Collins, C. P. West, L. O. Lerman,
and A. Lerman, “Digital Health Interventions for the Prevention of
Cardiovascular Disease: A Systematic Review and Meta-Analysis,”
Mayo Clinic Proceedings, vol. 90, no. 4, pp. 469–480, 2015.

[10] C. Hollis, C. J. Falconer, J. L. Martin, C. Whittington, S. Stockton,
C. Glazebrook, and E. B. Davies, “Annual Research Review: Digital
Health Interventions for Children and Young People with Mental
Health Problems–A Systematic and Meta-Review,” Journal of Child
Psychology and Psychiatry, vol. 58, no. 4, pp. 474–503, 2017.
[11] D. Liu, F. Yang, F. Xiong, and N. Gu, “The Smart Drug Delivery
System and Its Clinical Potential,” Theranostics, vol. 6, no. 9, p. 1306,
2016.

[12] D. C. Mohr, S. M. Schueller, E. Montague, M. N. Burns, and P. Rashidi,
“The Behavioral Intervention Technology Model: An Integrated Con-
ceptual and Technological Framework for eHealth and mHealth In-
terventions,” Journal of medical Internet research, vol. 16, no. 6, p.
e3077, 2014.

[13] U. Lee, K. Han, H. Cho, K. Chung, H. Hong, S.-J. Lee, Y. Noh,
S. Park, and J. M. Carroll, “Intelligent Positive Computing with
Mobile, Wearable, and IoT Devices: Literature Review and Research
Directions,” Ad Hoc Networks, vol. 83, pp. 8–24, 2019.

[14] B. K. Wiederhold, “Data-Driven Digital Therapeutics: The Path For-

ward,” pp. 631–632, 2021.

[15] W. Choi, S. Park, D. Kim, Y.-k. Lim, and U. Lee, “Multi-Stage
Receptivity Model for Mobile Just-In-Time Health Intervention,” Pro-
ceedings of the ACM on interactive, mobile, wearable and ubiquitous
technologies, vol. 3, no. 2, pp. 1–26, 2019.

[16] J. Zhou, Y. Zhou, B. Wang, and J. Zang, “Human–Cyber–Physical
Systems (HCPSs) in the Context of New-Generation Intelligent Man-
ufacturing,” Engineering, vol. 5, no. 4, pp. 624–636, 2019.

[17] J. C. Kvedar, A. L. Fogel, E. Elenko, and D. Zohar, “Digital Medicine’s
March on Chronic Disease,” Nature biotechnology, vol. 34, no. 3, pp.
239–246, 2016.

[18] N. A. Patel and A. J. Butte, “Characteristics and Challenges of the
Clinical Pipeline of Digital Therapeutics,” NPJ digital medicine, vol. 3,
no. 1, pp. 1–5, 2020.

[19] T. Webb, J. Joseph, L. Yardley, S. Michie et al., “Using the Internet
to Promote Health Behavior Change: A Systematic Review and Meta-
analysis of the Impact of Theoretical Basis, Use of Behavior Change
Techniques, and Mode of Delivery on Efﬁcacy,” Journal of medical
Internet research, vol. 12, no. 1, p. e1376, 2010.

[20] S. C. Sepah, L. Jiang, and A. L. Peters, “Long-Term Outcomes of a
Web-Based Diabetes Prevention Program: 2-Year Results of a Single-
Arm Longitudinal Study,” Journal of medical Internet research, vol. 17,
no. 4, p. e4052, 2015.

[21] E. Capobianco, “On Digital Therapeutics,” Frontiers in Digital Hu-

manities, vol. 2, p. 6, 2015.

[22] C. Sepah, “The Double-Edged Sword of Digital Health (The Downside
https://medium.com/goactualize/the-

Will Surprise You),”
double-edged-sword-of-digital- health-the-downside-will-surprise-
you-8eaf5c3c84df (accessed: 2022-03-06).

2017,

[23] World Health Organization, WHO Guideline: Recommendations on
Digital Interventions for Health System Strengthening. World Health
Organization, 2019.

[24] U.S. Food & Drug Administration, “Digital Health,” 2020, https://

www.fda.gov/medical- devices/digital- health- center-excellence/what-
digital- health (accessed: 2022-03-06).

[25] Digital Medicine Society (DiMe), “Deﬁning Digital Medicine,”
2021, https://www.dimesociety.org/about-us/deﬁning-digital- medicine/
(accessed: 2022-03-06).

[26] Digital Therapeutics Alliance, “Digital Health Industry Categoriza-
tion,” 2019, https://dtxalliance.org/wp-content/uploads/2019/11/DTA
Digital- Industry-Categorization Nov19.pdf (accessed: 2022-03-06).

[27] T. Aungst and J. Murdock, “What’s the Difference Between Digital
Health, Digital Medicine, and Digital Therapeutics?” 2021, https://
www.goodrx.com/healthcare- access/telehealth/digital- therapeutics- vs-
digital- medicine- vs-digital- health (accessed: 2022-03-06).

[28] G. E. Iyawa, M. Herselman, and A. Botha, “Digital Health Innovation
Ecosystems: From Systematic Literature Review to Conceptual Frame-
work,” Procedia Computer Science, vol. 100, pp. 244–252, 2016.
[29] U.S. Food & Drug Administration, “Enforcement Policy for Non-
Invasive Remote Monitoring Devices Used to Support Patient
Monitoring During the Coronavirus Disease 2019 (COVID-19) Public
Health Emergency (Revised),” 2020, https://www.fda.gov/regulatory-
information/search-fda-guidance- documents/enforcement- policy-non-
invasive- remote-monitoring-devices- used-support-patient- monitoring-
during (accessed: 2020-03-06).

[30] Digital Therapeutics Alliance, “Digital Therapeutics: Reducing Rural
Health Inequalities,” 2020, https://dtxalliance.org/wp-content/uploads/
2021/01/DTA Rural-Health r13 110220.pdf (accessed: 2020-03-06).
[31] D. Morrison, S. Wyke, K. Agur, E. J. Cameron, R. I. Docking, A. M.
MacKenzie, A. McConnachie, V. Raghuvir, N. C. Thomson, and F. S.
Mair, “Digital Asthma Self-Management Interventions: A Systematic
Review,” Journal of medical Internet research, vol. 16, no. 2, p. e2814,
2014.

[32] A. Khaylis, T. Yiaslas, J. Bergstrom, and C. Gore-Felton, “A Review
of Efﬁcacious Technology-Based Weight-Loss Interventions: Five Key
Components,” Telemedicine and e-Health, vol. 16, no. 9, pp. 931–938,
2010.

[33] K. Ghorai, S. Akter, F. Khatun, and P. Ray, “mHealth for Smoking
Cessation Programs: A Systematic Review,” Journal of personalized
medicine, vol. 4, no. 3, pp. 412–423, 2014.

[34] M. Aapro, P. Bossi, A. Dasari, L. Fallowﬁeld, P. Gasc´on, M. Geller,
K. Jordan, J. Kim, K. Martin, and S. Porzig, “Digital Health for
Optimal Supportive Care in Oncology: Beneﬁts, Limits, and Future
Perspectives,” Supportive Care in Cancer, vol. 28, no. 10, pp. 4589–
4612, 2020.

[35] M.-J. Choi, H. Kim, H.-W. Nah, and D.-W. Kang, “Digital Therapeu-
tics: Emerging New Therapy for Neurologic Deﬁcits After Stroke,”
Journal of stroke, vol. 21, no. 3, p. 242, 2019.

[36] G. Abbadessa, F. Brigo, M. Clerico, S. De Mercanti, F. Trojsi,
G. Tedeschi, S. Bonavita, and L. Lavorgna, “Digital Therapeutics in
Neurology,” Journal of Neurology, pp. 1–16, 2021.

[37] J. M. Simoni, B. A. Kutner, and K. J. Horvath, “Opportunities and
Challenges of Digital Technology for HIV Treatment and Prevention,”
Current HIV/AIDS Reports, vol. 12, no. 4, pp. 437–440, 2015.
[38] C. E. Canan, M. E. Waselewski, A. L. D. Waldman, G. Reynolds,
T. E. Flickinger, W. F. Cohn, K. Ingersoll, and R. Dillingham, “Long
Term Impact of PositiveLinks: Clinic-deployed Mobile Technology to
Improve Engagement with HIV Care,” PLOS ONE, vol. 15, no. 1, pp.
1–14, 01 2020.

[39] M. Aitken, B. Clancy, and D. Nass, “The Growing Value of Digital
Health: Evidence and Impact on Human Health and the Healthcare Sys-
tem,” 2017, https://www.iqvia.com/insights/the-iqvia- institute/reports/
the-growing-value-of-digital- health (accessed: 2022-03-06).

[40] B. Meyer, T. Berger, F. Caspar, C. Beevers, G. Andersson, and
M. Weiss, “Effectiveness of a Novel Integrative Online Treatment
for Depression (Deprexis): Randomized Controlled Trial,” Journal of
medical Internet research, vol. 11, no. 2, p. e1151, 2009.

[41] K. K. Fitzpatrick, A. Darcy, and M. Vierhile, “Delivering Cognitive
Behavior Therapy to Young Adults with Symptoms of Depression and
Anxiety Using a Fully Automated Conversational Agent (Woebot): a
Randomized Controlled Trial,” JMIR mental health, vol. 4, no. 2, p.
e7785, 2017.

[42] L. M. Ritterband, F. P. Thorndike, L. A. Gonder-Frederick, J. C. Magee,
E. T. Bailey, D. K. Saylor, and C. M. Morin, “Efﬁcacy of an Internet-
Based Behavioral Intervention for Adults with Insomnia,” Archives of
general psychiatry, vol. 66, no. 7, pp. 692–698, 2009.

[43] D. F. Tolin, P. B. McGrath, L. R. Hale, D. N. Weiner, and R. Gue-
orguieva, “A Multisite Benchmarking Trial of Capnometry Guided
Respiratory Intervention for Panic Disorder in Naturalistic Treatment
Settings,” Applied psychophysiology and biofeedback, vol. 42, no. 1,
pp. 51–58, 2017.

[44] NightWare, “NightWare Improves Sleep in Patients with Nightmare
Disorder,” 2021, https://nightware.com/ (accessed: 2022-03-06).
[45] D. R. Christensen, R. D. Landes, L. Jackson, L. A. Marsch, M. J.
Mancino, M. P. Chopra, and W. K. Bickel, “Adding an Internet-

20

IEEE/CAA JOURNAL OF AUTOMATICA SINICA, VOL. X, NO. X, X X

Delivered Treatment to an Efﬁcacious Treatment Package for Opioid
Dependence.” Journal of Consulting and Clinical Psychology, vol. 82,
no. 6, p. 964, 2014.

[46] R. K. Merchant, R. Inamdar, and R. C. Quade, “Effectiveness of
Population Health Management Using the Propeller Health Asthma
Platform: A Randomized Clinical Trial,” The Journal of Allergy and
Clinical Immunology: In Practice, vol. 4, no. 3, pp. 455–463, 2016.

[47] NuvoAir, “Respiratory Care for COPD and Asthma,” 2021, https://

www.nuvoair.com/ (accessed: 2022-03-06).

[48] Oleena, “Oleena® Digital Therapeutic for Cancer Symptom Manage-

ment,” 2020, https://oleena.com/ (accessed: 2022-03-06).

[49] Insulia, “Insulia,” 2017, https://insulia.com/ (accessed: 2022-03-06).
[50] M. F. Alwashmi, G. Mugford, W. Abu-Ashour, and M. Nuccio, “A
Digital Diabetes Prevention Program (Transform) for Adults with
Prediabetes: Secondary Analysis,” JMIR diabetes, vol. 4, no. 3, p.
e13904, 2019.

[51] S. J. Athinarayanan, R. N. Adams, S. J. Hallberg, A. L. McKenzie,
N. H. Bhanpuri, W. W. Campbell, J. S. Volek, S. D. Phinney, and
J. P. McCarter, “Long-Term Effects of a Novel Continuous Remote
Care Intervention Including Nutritional Ketosis for the Management of
Type 2 Diabetes: A 2-Year Non-randomized Clinical Trial,” Frontiers
in endocrinology, vol. 10, p. 348, 2019.

[52] DarioHealth, “DarioHealth: Digital Health Solutions For Chronic Con-
ditions,” 2021, https://www.dariohealth.com/ (accessed: 2022-03-06).
[53] J. Downing, J. Bollyky, J. Schneider et al., “Use of a Connected
Glucose Meter and Certiﬁed Diabetes Educator Coaching to Decrease
the Likelihood of Abnormal Blood Glucose Excursions: the Livongo
for Diabetes Program,” Journal of medical Internet research, vol. 19,
no. 7, p. e6659, 2017.
[54] Constant Therapy Health,

“Constant Therapy,”

https://

2020,

constanttherapyhealth.com/ (accessed: 2022-03-06).
“NeuroEyeCoach,”

[55] NovaVision,

2021,

https://novavision.com/

neuroeyecoach/ (accessed: 2022-03-06).

[56] BTS Bioengineering, “Nirvana - Virtual reality applied to neuromotor
rehabilitation,” 2021, https://www.btsbioengineering.com/nirvana/ (ac-
cessed: 2022-03-06).

[57] IMDRF SaMD Working Group, “Software as a Medical Device
(SaMD): Key Deﬁnitions, IMDRF SaMD Working Group,” 2013,
https://www.imdrf.org/sites/default/ﬁles/docs/imdrf/ﬁnal/technical/
imdrf-tech-131209-samd-key-deﬁnitions-140901.pdf
2022-03-06).

(accessed:

2020,

[58] U.S. Food & Drug Administration, “Premarket Notiﬁcation 510(k),
https://www.fda.gov/medical- devices/premarket-

US-FDA,”
submissions/premarket- notiﬁcation- 510k (accessed: 2022-03-06).
[59] U.S. Food & Drug Administration, “De Novo Classiﬁcation Request,
https://www.fda.gov/medical- devices/premarket-

US-FDA,”
submissions/de-novo-classiﬁcation- request (accessed: 2022-03-06).

2019,

[60] J. L. Johnston, S. S. Dhruva, J. S. Ross, and V. K. Rathi, “Early
Experience with the FDA’s Breakthrough Devices Program,” Nature
Biotechnology, vol. 38, pp. 933–938, 2010.

[61] U.S. Food & Drug Administration,

Precertiﬁcation
www.fda.gov/medical- devices/digital- health/digital- health- software-
precertiﬁcation- pre-cert-program (accessed: 2022-03-06).

Program, US-FDA,”

(Pre-Cert)

“Digital Health Software
https://

2019,

[62] U.S. Food & Drug Administration, “FDA-De Novo Classiﬁcation
Request for ReSET,” 2016, https://www.accessdata.fda.gov/cdrh docs/
reviews/DEN160018.pdf (accessed: 2022-03-06).

[63] M. Caffrey, “Digital Health Provider Noom Wins Full CDC
Recognition for Mobile, Online Applications,” 2017, https://www.
ajmc.com/newsroom/digital- health- provider-noom-wins-full-cdc-
recognition- for-mobile-online- applications (accessed: 2022-03-06).

[64] M. Caffrey,

“Omada Health Receives Full CDC Recognition
for Diabetes Prevention,” 2018, https://www.ajmc.com/newsroom/
omada-health-receives- full-cdc-recognition- for-diabetes- prevention
(accessed: 2022-03-06).

[65] A. Michaelides, C. Raby, M. Wood, K. Farr, and T. Toro-Ramos,
“Weight Loss Efﬁcacy of a Novel Mobile Diabetes Prevention Pro-
gram Delivery Platform with Human Coaching,” BMJ Open Diabetes
Research and Care, vol. 4, no. 1, p. e000264, 2016.

[66] D. H. Gustafson, F. M. McTavish, M.-Y. Chih, A. K. Atwood, R. A.
Johnson, M. G. Boyle, M. S. Levy, H. Driscoll, S. M. Chisholm,
L. Dillenburg, A. Isham, and D. Shah, “A Smartphone Application
to Support Recovery From Alcoholism: A Randomized Clinical Trial,”
JAMA psychiatry, vol. 71, no. 5, pp. 566–572, 2014.

[67] F. Naughton, S. Hopewell, N. Lathia, R. Schalbroeck, C. Brown,
C. Mascolo, A. McEwen, and S. Sutton, “A Context-Sensing Mobile

Phone App (Q Sense) for Smoking Cessation: A Mixed-Methods
Study,” JMIR mHealth and uHealth, vol. 4, no. 3, p. e5787, 2016.
[68] S. P. Goldstein, B. C. Evans, D. Flack, A. Juarascio, S. Manasse,
F. Zhang, and E. M. Forman, “Return of the JITAI: Applying a Just-
In-Time Adaptive Intervention Framework to the Development of m-
Health Solutions for Addictive Behaviors,” International journal of
behavioral medicine, vol. 24, no. 5, pp. 673–682, 2017.

[69] DarioHealth, “Diabetes Management with Blood Glucose Monitor-
ing System,” 2021, https://www.dariohealth.com/solutions/diabetes-
management/ (accessed: 2022-03-06).

[70] D. Muoio, “Omada Health Expands Digital Platform with Type
2, Hypertension Programs, New Features,” 2018, https://www.
mobihealthnews.com/content/omada-health- expands-digital- platform-
type-2-hypertension- programs-new-features (accessed: 2022-03-06).

[71] Livongo Public Relations,

“Livongo Launches Hypertension,”
https://www.mylivongo.com/Livongo-Launches-Hypertension/

2018,
(accessed: 2022-03-06).

[72] H. W. Rodbard,

“Treating Hypertension Reduces CV Risks
in Diabetes Care,” 2019, https://www.healio.com/news/cardiology/
20190807/treating- hypertension- reduces-cv-risks-in-diabetes- care (ac-
cessed: 2022-03-06).

[73] B. M. Cheung and C. Li, “Diabetes and Hypertension: Is There a
Common Metabolic Pathway?” Current atherosclerosis reports, vol. 14,
no. 2, pp. 160–166, 2012.

[74] I. Nahum-Shani, S. N. Smith, B.

J. Spring, L. M. Collins,
K. Witkiewitz, A. Tewari, and S. A. Murphy, “Just-In-Time Adaptive
Interventions (JITAIs) in Mobile Health: Key Components and Design
Principles for Ongoing Health Behavior Support,” Annals of Behavioral
Medicine, vol. 52, no. 6, pp. 446–462, 2018.

[75] J. G. Thomas and D. S. Bond, “Behavioral Response to a Just-In-Time
Adaptive Intervention (JITAI) to Reduce Sedentary Behavior in Obese
Adults: Implications for JITAI Optimization.” Health Psychology,
vol. 34, pp. 1261–1267, 2015.

[76] M. S. Businelle, P. Ma, D. E. Kendzor, S. G. Frank, D. J. Vidrine, and
D. W. Wetter, “An Ecological Momentary Intervention for Smoking
Cessation: Evaluation of Feasibility and Effectiveness,” Journal of
Medical Internet Research, vol. 18, no. 12, p. e6058, 2016.

[77] E. T. H´ebert, C. K. Ra, A. C. Alexander, A. Helt, R. Moisiuc, D. E.
Kendzor, D. J. Vidrine, R. K. Funk-Lawler, and M. S. Businelle, “A
Mobile Just-In-Time Adaptive Intervention for Smoking Cessation: Pi-
lot Randomized Controlled Trial,” Journal of medical Internet research,
vol. 22, no. 3, 2020.

[78] B. Spring, “Sense2stop: Mobile Sensor Data to Knowledge,” 2017,
(accessed:

https://clinicaltrials.gov/ct2/show/study/NCT03184389
2022-03-06).

[79] L. Yardley, B. J. Spring, H. Riper, L. G. Morrison, D. H. Crane, K. Cur-
tis, G. C. Merchant, F. Naughton, and A. Blandford, “Understanding
and Promoting Effective Engagement With Digital Behavior Change
Interventions,” American journal of preventive medicine, vol. 51, no. 5,
pp. 833–842, 2016.

[80] N. Alshurafa, J. Jain, R. Alharbi, G. Iakovlev, B. Spring, and A. Pfam-
matter, “Is More Always Better?: Discovering Incentivized mHealth
Intervention Engagement Related to Health Behavior Trends,” Pro-
ceedings of the ACM on interactive, mobile, wearable and ubiquitous
technologies, vol. 2, no. 4, pp. 1–26, 2018.

[81] B. J. Fogg, “Creating Persuasive Technologies: An Eight-step Design
Process,” in Proceedings of the 4th international conference on per-
suasive technology. New York, NY, USA: Association for Computing
Machinery, 2009, pp. 1–6.

[82] L. M. Ritterband, F. P. Thorndike, D. J. Cox, B. P. Kovatchev, and
L. A. Gonder-Frederick, “A Behavior Change Model for Internet
Interventions,” Annals of Behavioral Medicine, vol. 38, no. 1, pp. 18—
-27, 2009.

[83] A. Schmidt, M. Beigl, and H.-W. Gellersen, “There is More to Context
than Location,” Computers & Graphics, vol. 23, no. 6, pp. 893–901,
1999.

[84] B. Schilit, N. Adams, and R. Want, “Context-Aware Computing Ap-
plications,” in 1994 First Workshop on Mobile Computing Systems and
Applications. Los Alamitos, CA, USA: IEEE Computer Society Press,
1994, pp. 85–90.

[85] ArisGlobal, “Cloud Based End-to-End Drug Development Platform
- ArisGlobal,” 2020, https://www.arisglobal.com/ (accessed: 2022-03-
06).

[86] Clario, “Endpoint Technology Services For Clinical Trial Management

- Clario,” 2021, https://www.bioclinica.com/ (accessed: 2022-03-06).

[87] Advarra, “Advarra: Enabling Safer, Smarter, Faster Clinical Research,”

2018, https://www.advarra.com/ (accessed: 2022-03-06).

LEE et al.: TOWARD DATA-DRIVEN DIGITAL THERAPEUTICS ANALYTICS: LITERATURE REVIEW AND RESEARCH DIRECTIONS

21

[88] DSG, “DSG Clinical Trial Software and Data Management Solutions,”

2022, https://dsg-us.com/index.html (accessed: 2022-03-06).

[89] Mednet, “eClinical Platform for Clinical Trials - Mednet,” 2019, https://

www.mednetsolutions.com/ (accessed: 2022-03-06).

[90] Medidata, “Medidata - Uniﬁed Life Science Platform,” 2021, https://

www.medidata.com/ (accessed: 2022-03-06).

[91] Parexel International Corporation, “Clinical Research Organization
(CRO) & Biopharmaceutical Services,” 2020, https://www.parexel.
com/ (accessed: 2022-03-06).

[92] SimpleTrials, “SimpleTrials - Clinical Trial Management System,”

2020, https://www.simpletrials.com/ (accessed: 2022-03-06).

[93] Veeva, “Veeva Systems,” 2019, https://www.veeva.com/ (accessed:

2022-03-06).

[94] Global

(CTMS),”
trial- management-systems-ctms.html (accessed: 2022-03-06).

Inc., “Clinical Trial Management Systems
https://m.giikorea.co.kr/report/go240200-clinical-

Information,
2019,

[95] Y. R. Park, Y. J. Yoon, H. Koo, S. Yoo, C.-M. Choi, S.-H. Beck, and
T. W. Kim, “Utilization of a Clinical Trial Management System for
the Whole Clinical Trial Process as an Integrated Database: System
Development,” Journal of medical Internet research, vol. 20, no. 4, p.
e9312, 2018.

[96] IBM, “IBM Watson Health - AI Healthcare Solutions,” 2022, https://

www.ibm.com/watson-health (accessed: 2022-03-06).

[97] Oracle,

“Siebel Clinical Trial Management System - Oracle,”
https://www.oracle.com/industries/life-sciences/clinical- trial-

2020,
management.html (accessed: 2022-03-06).

[109] N. D. Lane, E. Miluzzo, H. Lu, D. Peebles, T. Choudhury, and A. T.
Campbell, “A Survey of Mobile Phone Sensing,” IEEE Communica-
tions Magazine, vol. 48, no. 9, pp. 140–150, 2010.

[110] B. Cowley, M. Filetti, K. Lukander, J. Torniainen, A. Henelius, L. Aho-
nen, O. Barral, I. Kosunen, T. Valtonen, M. Huotilainen, N. Ravaja,
and G. Jacucci, “The Psychophysiology Primer: A Guide to Methods
and a Broad Review with a Focus on Human-Computer Interaction,”
Foundations and Trends in Human-Computer Interaction, vol. 9, no.
3-4, pp. 151–308, 2016.

[111] M. L. Lee and A. K. Dey, “Reﬂecting on Pills and Phone Use: Support-
ing Awareness of Functional Abilities for Older Adults,” in Proceedings
of the SIGCHI Conference on Human Factors in Computing Systems.
New York, NY, USA: Association for Computing Machinery, 2011, p.
2095–2104.

[112] J. Lee, E. Walker, W. Burleson, M. Kay, M. Buman, and E. B. Hekler,
“Self-Experimentation for Behavior Change: Design and Formative
Evaluation of Two Approaches,” in Proceedings of the 2017 CHI
Conference on Human Factors in Computing Systems. New York, NY,
USA: Association for Computing Machinery, 2017, pp. 6837–6849.

[113] S. Taki, S. Lymer, C. G. Russell, K. Campbell, R. Laws, K.-L. Ong,
R. Elliott, E. Denney-Wilson et al., “Assessing User Engagement
of an mHealth Intervention: Development and Implementation of
the Growing Healthy App Engagement Index,” JMIR mHealth and
uHealth, vol. 5, no. 6, p. e7236, 2017.

[114] J. Brooke, “SUS: A ‘Quick and Dirty’ Usability Scale,” Usability

evaluation in industry, vol. 189, no. 3, 1996.

[115] A. M. Lund, “Measuring Usability with the Use Questionnaire12,”

[98] PRA Prism, “PRA Prism,” 2022, https://www.nextrials.com/ (accessed:

Usability interface, vol. 8, no. 2, pp. 3–6, 2001.

2022-03-06).

[99] Winchester Business Systems, “Winchester Business Systems – Mov-
ing Science Forward,” 2020, https://wbsnet.com/ (accessed: 2022-03-
06).

[100] M. Rose, “Open Data Kit,” 2013, https://opendatakit.org/ (accessed:

2022-03-06).

[101] D. Ferreira, V. Kostakos, and A. K. Dey, “AWARE: Mobile Context
Instrumentation Framework,” Frontiers in ICT, vol. 2, no. 6, pp. 1–9,
2015.

[102] S. M. Hossain, T. Hnat, N. Saleheen, N. J. Nasrin, J. Noor, B.-
J. Ho, T. Condie, M. Srivastava, and S. Kumar, “mCerebrum: A
Mobile Sensing Software Platform for Development and Validation
of Digital Biomarkers and Interventions,” in proceedings of the 15th
ACM Conference on Embedded Network Sensor Systems. New York,
NY, USA: Association for Computing Machinery, 2017, pp. 1–14.

[103] M. Rabbi, M. Philyaw-Kotov, J. Lee, A. Mansour, L. Dent, X. Wang,
R. Cunningham, E. Bonar, I. Nahum-Shani, P. Klasnja et al., “SARA:
A Mobile App to Engage Users in Health Data Collection,” in
Proceedings of
the 2017 ACM International Joint Conference on
Pervasive and Ubiquitous Computing and Proceedings of the 2017
ACM International Symposium on Wearable Computers. New York,
NY, USA: Association for Computing Machinery, 2017, pp. 781–789.
[104] R. P. Eckhoff, P. N. Kizakevich, V. Bakalov, Y. Zhang, S. P. Bryant, and
M. A. Hobbs, “A Platform to Build Mobile Health Apps: The Personal
Health Intervention Toolkit (PHIT),” JMIR mHealth and uHealth,
vol. 3, no. 2, p. e4202, 2015.

[105] P. N. Kizakevich, R. C. Hubal, J. Brown, J. Lyden, J. L. Spira,
R. Eckhoff, Y. Zhang, S. Bryant, and G. Munoz, “PHIT for Duty,
a Mobile Approach for Psychological Health Intervention.” Annual
Review of Cybertherapy and Telemedicine, vol. 181, pp. 268–272, 2012.
[106] P. N. Kizakevich, R. Eckhoff, J. Brown, S. J. Tueller, B. Weimer,
S. Bell, A. Weeks, L. L. Hourani, J. L. Spira, and L. A. King, “PHIT for
Duty, a Mobile Application for Stress Reduction, Sleep Improvement,
and Alcohol Moderation,” Military medicine, vol. 183, no. suppl 1, pp.
353–363, 2018.

[107] J. Nakazawa, H. Tokuda, and T. Yonezawa, “Sensorizer: An Architec-
ture for Regenerating Cyber Physical Data Streams from the Web,” in
Adjunct Proceedings of the 2015 ACM International Joint Conference
on Pervasive and Ubiquitous Computing and Proceedings of the 2015
ACM International Symposium on Wearable Computers. New York,
NY, USA: Association for Computing Machinery, 2015, pp. 1599–
1606.

[108] J. Sun, S. Park, G. Jung, Y. Jeong, U. Lee, K.-M. Chung, C. Lee,
H. Kim, S. Ahn, A. Khandoker et al., “Beactive: Encouraging physical
activities with just-in-time health intervention and micro ﬁnancial
incentives,” in Proceedings of
the 2020 Symposium on Emerging
Research from Asia and on Asian Contexts and Cultures. New York,
NY, USA: Association for Computing Machinery, 2020, pp. 17–20.

[116] H. L. O’Brien, P. Cairns, and M. Hall, “A Practical Approach to
Measuring User Engagement with the Reﬁned User Engagement Scale
(UES) and New UES Short Form,” International Journal of Human-
Computer Studies, vol. 112, pp. 28–39, 2018.

[117] S. R. Stoyanov, L. Hides, D. J. Kavanagh, O. Zelenko, D. Tjondrone-
goro, and M. Mani, “Mobile App Rating Scale: A New Tool for
Assessing the Quality of Health Mobile Apps,” JMIR mHealth and
uHealth, vol. 3, no. 1, p. e3422, 2015.

[118] M. Brhel, H. Meth, A. Maedche, and K. Werder, “Exploring Principles
of User-Centered Agile Software Development: A Literature Review,”
Information and software technology, vol. 61, pp. 163–181, 2015.

[119] D. Ben-Zeev, E. A. Scherer, J. D. Gottlieb, A. J. Rotondi, M. F.
Brunette, E. D. Achtyes, K. T. Mueser, S. Gingerich, C. J. Brenner,
M. Begale et al., “mHealth for Schizophrenia: Patient Engagement
With a Mobile Phone Intervention Following Hospital Discharge,”
JMIR mental health, vol. 3, no. 3, p. e6348, 2016.

[120] R. M. Martey, K. Kenski, J. Folkestad, L. Feldman, E. Gordis, A. Shaw,
J. Stromer-Galley, B. Clegg, H. Zhang, N. Kaufman et al., “Measuring
Game Engagement: Multiple Methods and Construct Complexity,”
Simulation & Gaming, vol. 45, no. 4-5, pp. 528–547, 2014.

[121] E. Di Lascio, S. Gashi, and S. Santini, “Unobtrusive Assessment of
Students’ Emotional Engagement during Lectures Using Electrodermal
Activity Sensors,” Proceedings of the ACM on Interactive, Mobile,
Wearable and Ubiquitous Technologies, vol. 2, no. 3, pp. 1–21, 2018.
[122] A. Mathur, N. D. Lane, and F. Kawsar, “Engagement-Aware Comput-
ing: Modelling User Engagement from Mobile Contexts,” in Proceed-
ings of the 2016 ACM International Joint Conference on Pervasive
and Ubiquitous Computing. New York, NY, USA: Association for
Computing Machinery, 2016, pp. 622–633.

[123] M. Pielot, B. Cardoso, K. Katevas, J. Serr`a, A. Matic, and N. Oliver,
“Beyond Interruptibility: Predicting Opportune Moments to Engage
Mobile Phone Users,” Proceedings of the ACM on Interactive, Mobile,
Wearable and Ubiquitous Technologies, vol. 1, no. 3, pp. 1–25, 2017.
[124] M. Ghahramani, M. Zhou, and G. Wang, “Urban Sensing Based
on Mobile Phone Data: Approaches, Applications, and Challenges,”
IEEE/CAA Journal of Automatica Sinica, vol. 7, no. 3, pp. 627–637,
2020.

[125] S. Imran, T. Mahmood, A. Morshed, and T. Sellis, “Big Data Analytics
in Healthcare- A Systematic Literature Review and Roadmap for
Practical Implementation,” IEEE/CAA Journal of Automatica Sinica,
vol. 8, no. 1, pp. 1–22, 2021.

[126] J. Firth, J. Torous, J. Nicholas, R. Carney, A. Pratap, S. Rosenbaum,
and J. Sarris, “The Efﬁcacy of Smartphone-Based Mental Health Inter-
ventions for Depressive Symptoms: A Meta-Analysis of Randomized
Controlled Trials,” World Psychiatry, vol. 16, no. 3, pp. 287–298, 2017.
[127] J. Firth, J. Torous, J. Nicholas, R. Carney, S. Rosenbaum, and J. Sarris,
“Can Smartphone Mental Health Interventions Reduce Symptoms of
Anxiety? A Meta-Analysis of Randomized Controlled Trials,” Journal
of affective disorders, vol. 218, pp. 15–22, 2017.

22

IEEE/CAA JOURNAL OF AUTOMATICA SINICA, VOL. X, NO. X, X X

[128] M. Cui, X. Wu, J. Mao, X. Wang, and M. Nie, “T2DM Self-
Management via Smartphone Applications: A Systematic Review and
Meta-Analysis,” PloS one, vol. 11, no. 11, p. e0166718, 2016.
[129] P. Klasnja, E. B. Hekler, S. Shiffman, A. Boruvka, D. Almirall,
A. Tewari, and S. A. Murphy, “Micro-Randomized Trials: An Exper-
imental Design for Developing Just-In-Time Adaptive Interventions,”
Health Psychology, vol. 34, pp. 1220–1228, 2015.

[130] P. Liao, P. Klasnja, A. Tewari, and S. A. Murphy, “Sample Size
Calculations for Micro-Randomized Trials in mHealth,” Statistics in
Medicine, vol. 35, no. 12, pp. 1944–1971, 2016.

[131] W. Dempsey, P. Liao, P. Klasnja, I. Nahum-Shani, and S. A. Murphy,
“Randomised Trials for the Fitbit Generation,” Signiﬁcance, vol. 12,
no. 6, pp. 20–23, 2015.

[132] E. Littlewood, A. Duarte, C. Hewitt, S. Knowles, S. Palmer, S. Walker,
P. Andersen, R. Araya, M. Barkham, P. Bower, S. Brabyn, G. Brierley,
C. Cooper, L. Gask, D. Kessler, H. Lester, K. Lovell, U. Muhammad,
G. Parry, D. A. Richards, R. Richardson, D. Tallon, P. Tharmanathan,
D. White, and S. Gilbody, “A Randomised Controlled Trial of Comput-
erised Cognitive Behaviour Therapy for the Treatment of Depression
in Primary Care: The Randomised Evaluation of the Effectiveness
and Acceptability of Computerised Therapy (REEACT) Trial,” Health
Technology Assessment, vol. 19, no. 101, 2015.

[133] M. J. Park and H. S. Kim, “Evaluation of Mobile Phone and Internet
Intervention on Waist Circumference and Blood Pressure in Post-
Menopausal Women with Abdominal Obesity,” International Journal
of Medical Informatics, vol. 81, no. 6, pp. 388–394, 2012.

[134] S. Nundy, J. J. Dick, C. H. Chou, R. S. Nocon, M. H. Chin, and M. E.
Peek, “Mobile Phone Diabetes Project Led to Improved Glycemic
Control and Net Savings for Chicago Plan Participants,” Health Affairs,
vol. 33, no. 2, pp. 265–272, 2014.

[135] F. Tsapeli and M. Musolesi, “Investigating Causality in Human Behav-
ior from Smartphone Sensor Data: A Quasi-Experimental Approach,”
EPJ Data Science, vol. 4, no. 1, p. 24, 2015.

[136] A. Mehrotra, F. Tsapeli, R. Hendley, and M. Musolesi, “MyTraces:
Investigating Correlation and Causation between Users’ Emotional
States and Mobile Phone Interaction,” Proceedings of the ACM on
Interactive, Mobile, Wearable and Ubiquitous Technologies, vol. 1,
no. 3, pp. 1–21, 2017.

[137] J. Dallery, R. N. Cassidy, and B. R. Raiff, “Single-Case Experimental
Designs to Evaluate Novel Technology-Based Health Interventions,” J
Med Internet Res, vol. 15, no. 2, p. 22, 2013.

[138] S. McDonald, F. Quinn, R. Vieira, N. O’Brien, M. White, D. W. John-
ston, and F. F. Sniehotta, “The State of the Art and Future Opportunities
for Using Longitudinal N-of-1 Methods in Health Behaviour Research:
A Systematic Literature Overview,” Health Psychology Review, vol. 11,
no. 4, pp. 307–323, 2017.

[139] S. H. Jain, B. W. Powers, J. B. Hawkins, and J. S. Brownstein, “The
Digital Phenotype,” Nature Biotechnology, vol. 33, no. 5, p. 462, 2015.
[140] G. M. Harari, N. D. Lane, R. Wang, B. S. Crosier, A. T. Campbell,
and S. D. Gosling, “Using Smartphones to Collect Behavioral Data
in Psychological Science: Opportunities, Practical Considerations, and
Challenges,” Perspectives on Psychological Science, vol. 11, no. 6, pp.
838–854, 2016.

[141] T. R. Insel, “Digital Phenotyping: Technology for a New Science of

Behavior,” JAMA, vol. 318, no. 13, pp. 1215–1216, 2017.

[142] A. K. Dey, “Understanding and Using Context,” Personal and Ubiqui-

tous Computing, vol. 5, no. 1, pp. 4–7, 2001.

[143] A. Schmidt, M. Beigl, and H.-W. Gellersen, “There is More to Context
Than Location,” Computers & Graphics, vol. 23, no. 6, pp. 893–901,
1999.

[144] D. C. Mohr, M. Zhang, and S. M. Schueller, “Personal Sensing:
Understanding Mental Health using Ubiquitous Sensors and Machine
Learning,” Annual Review of Clinical Psychology, vol. 13, pp. 23–47,
2017.

[145] S. Van Dantzig, G. Geleijnse, and A. T. van Halteren, “Toward a Per-
suasive Mobile Application to Reduce Sedentary Behavior,” Personal
and Ubiquitous Computing, vol. 17, no. 6, pp. 1237–1246, 2013.
[146] S. Abdullah, M. Matthews, E. L. Murnane, G. Gay, and T. Choudhury,
“Towards Circadian Computing: Early to Bed and Early to Rise Makes
Some of Us Unhealthy and Sleep Deprived,” in Proceedings of the
2014 ACM International Joint Conference on Pervasive and Ubiquitous
Computing.
New York, NY, USA: Association for Computing
Machinery, 2014, pp. 673–684.

[147] E. Thomaz, I. Essa, and G. D. Abowd, “A Practical Approach for
Recognizing Eating Moments with Wrist-mounted Inertial Sensing,”
the 2015 ACM International Joint Conference
in Proceedings of

on Pervasive and Ubiquitous Computing.
Association for Computing Machinery, 2015, pp. 1029–1040.
[148] R. Alam, J. Gong, M. Hanson, A. Bankole, M. Anderson, T. Smith-
Jackson, and J. Lach, “Motion Biomarkers for Early Detection of
Dementia-related Agitation,” in Proceedings of the 1st Workshop on
Digital Biomarkers. New York, NY, USA: Association for Computing
Machinery, 2017, pp. 15–20.

New York, NY, USA:

[149] L. Canzian and M. Musolesi, “Trajectories of Depression: Unobtrusive
Monitoring of Depressive States by Means of Smartphone Mobility
Traces Analysis,” in Proceedings of the 2015 ACM International Joint
Conference on Pervasive and Ubiquitous Computing. New York, NY,
USA: Association for Computing Machinery, 2015, pp. 1293–1304.

[150] Y. Huang, J. Gong, M. Rucker, P. Chow, K. Fua, M. S. Gerber,
B. Teachman, and L. E. Barnes, “Discovery of Behavioral Markers
of Social Anxiety from Smartphone Sensor Data,” in Proceedings of
the 1st Workshop on Digital Biomarkers.
New York, NY, USA:
Association for Computing Machinery, 2017, pp. 9–14.

[151] G. Mark, V. M. Gonzalez, and J. Harris, “No Task Left Behind?:
Examining the Nature of Fragmented Work,” in Proceedings of the
SIGCHI Conference on Human Factors in Computing Systems. New
York, NY, USA: Association for Computing Machinery, 2005, pp. 321–
330.

[152] P. D. Adamczyk and B. P. Bailey, “If Not Now, When?: The Effects
of Interruption at Different Moments Within Task Execution,” in Pro-
ceedings of the SIGCHI Conference on Human Factors in Computing
Systems. New York, NY, USA: Association for Computing Machinery,
2004, pp. 271–278.

[153] J. Ho and S. S. Intille, “Using Context-aware Computing to Reduce
the Perceived Burden of Interruptions from Mobile Devices,” in Pro-
ceedings of the SIGCHI Conference on Human Factors in Computing
Systems. New York, NY, USA: Association for Computing Machinery,
2005, pp. 909–918.

[154] P. W. Holland, “Statistics and Causal Inference,” Journal of

the
American statistical Association, vol. 81, no. 396, pp. 945–960, 1986.
[155] D. B. Rubin, “Causal Inference Using Potential Outcomes: Design,
Modeling, Decisions,” Journal of the American Statistical Association,
vol. 100, no. 469, pp. 322–331, 2005.

[156] A. Boruvka, D. Almirall, K. Witkiewitz, and S. A. Murphy, “Assessing
Time-Varying Causal Effect Moderation in Mobile Health,” Journal of
the American Statistical Association, vol. 113, no. 523, pp. 1112–1121,
2018.

[157] T. Qian, P. Klasnja, and S. A. Murphy, “Linear Mixed Models with
Endogenous Covariates: Modeling Sequential Treatment Effects with
Application to a Mobile Health Study,” Statistical science: a review
journal of the Institute of Mathematical Statistics, vol. 35, no. 3, p.
375, 2020.

[158] T. Qian, H. Yoo, P. Klasnja, D. Almirall, and S. A. Murphy, “Estimating
Time-Varying Causal Excursion Effects in Mobile Health with Binary
Outcomes,” Biometrika, vol. 108, no. 3, pp. 507–527, 2021.

[159] W. Van den Noortgate and P. Onghena, “The Aggregation of Single-
Case Results Using Hierarchical Linear Models.” The Behavior Analyst
Today, vol. 8, no. 2, pp. 196–209, 2007.

[160] E. J. Daza, “Causal Analysis of Self-Tracked Time Series Data Using a
Counterfactual Framework for N-of-1 Trials,” Methods of Information
in Medicine, vol. 57, pp. e10–e21, 2018.

[161] M. A. Hern´an and J. M. Robins, Causal Inference: What If. Boca

Raton: Chapman & Hall/CRC, 2020.

[162] P. R. Rosenbaum and D. B. Rubin, “The Central Role of the Propensity
Score in Observational Studies for Causal Effects,” Biometrika, vol. 70,
no. 1, pp. 41–55, 1983.

[163] S. Sizemore and R. Alkurdi, “Matching Methods for Causal Inference:
A Machine Learning Update,” 2019, https://humboldt-wi.github.io/
blog/research/applied predictive modeling 19/matching methods/
(accessed: 2022-03-06).

[164] J. M. Robins and M. A. Hernan, “Estimation of the Causal Effects of
Time-Varying Exposures,” in Longitudinal Data Analysis, G. Fitzmau-
rice, M. Davidian, G. Verbeke, and G. Molenberghs, Eds. Chapman
& Hall/CRC, 2009, ch. 23, pp. 553–597.

[165] J. Pearl, Causality, 2nd ed. Cambridge University Press, 2009.
[166] C. W. Granger, “Investigating Causal Relations by Econometric Models
and Cross-spectral Methods,” Econometrica: journal of the Economet-
ric Society, vol. 37, no. 3, pp. 424–438, 1969.

[167] G. Sugihara, R. May, H. Ye, C.-h. Hsieh, E. Deyle, M. Fogarty, and
S. Munch, “Detecting Causality in Complex Ecosystems,” Science, vol.
338, no. 6106, pp. 496–500, 2012.

[168] J. M. Twenge, G. N. Martin, and W. K. Campbell, “Decreases in
Psychological Well-Being Among American Adolescents after 2012

LEE et al.: TOWARD DATA-DRIVEN DIGITAL THERAPEUTICS ANALYTICS: LITERATURE REVIEW AND RESEARCH DIRECTIONS

23

and Links to Screen Time During the Rise of Smartphone Technology.”
Emotion, vol. 18, no. 6, pp. 765–780, 2018.

[169] Z. Sarsenbayeva, G. Marini, N. van Berkel, C. Luo, W. Jiang, K. Yang,
G. Wadley, T. Dingler, V. Kostakos, and J. Goncalves, “Does Smart-
phone Use Drive our Emotions or vice versa? A Causal Analysis,”
in Proceedings of
the 2020 CHI conference on human factors in
computing systems. New York, NY, USA: Association for Computing
Machinery, 2020, pp. 1–15.

[170] A. E. Yuan and W. Shou, “Data-Driven Causal Analysis of Observa-

tional Time Series in Ecology,” bioRxiv, 2021.

[171] T. Munzner, Visualization Analysis and Design. CRC press, 2014.
[172] K. A. Cook and J. J. Thomas, “Illuminating the Path: The Research
and Development Agenda for Visual Analytics,” 2005, https://www.
osti.gov/biblio/912515 (accessed: 2022-03-06).

[173] W. Aigner, S. Miksch, W. M¨uller, H. Schumann, and C. Tominski,
“Visualizing Time-Oriented Data—A Systematic View,” Computers &
Graphics, vol. 31, no. 3, pp. 401–409, 2007.

[174] M. Brehmer, B. Lee, B. Bach, N. H. Riche, and T. Munzner, “Timelines
Revisited: A Design Space and Considerations for Expressive Story-
telling,” IEEE transactions on visualization and computer graphics,
vol. 23, no. 9, pp. 2151–2164, 2016.

[175] J. Walker, R. Borgo, and M. W. Jones, “TimeNotes: A Study on Effec-
tive Chart Visualization and Interaction Techniques for Time-Series
Data,” IEEE transactions on visualization and computer graphics,
vol. 22, no. 1, pp. 549–558, 2015.

[176] R. Chen, F. Jankovic, N. Marinsek, L. Foschini, L. Kourtis, A. Sig-
norini, M. Pugh, J. Shen, R. Yaari, V. Maljkovic et al., “Developing
Measures of Cognitive Impairment in the Real World from Consumer-
Grade Multimodal Sensor Streams,” in Proceedings of the 25th ACM
SIGKDD International Conference on Knowledge Discovery & Data
Mining. New York, NY, USA: Association for Computing Machinery,
2019, pp. 2145–2155.

[177] Y. Kim, E. Heo, H. Lee, S. Ji, J. Choi, J.-W. Kim, J. Lee, and S. Yoo,
“Prescribing 10,000 Steps Like Aspirin: Designing a Novel Interface
for Data-Driven Medical Consultations,” in Proceedings of the 2017
CHI Conference on Human Factors in Computing Systems. New York,
NY, USA: Association for Computing Machinery, 2017, pp. 5787–
5799.

[178] M. Sharmin, A. Raij, D. Epstien,

I. Nahum-Shani, J. G. Beck,
S. Vhaduri, K. Preston, and S. Kumar, “Visualization of Time-Series
Sensor Data to Inform the Design of Just-In-Time Adaptive Stress
Interventions,” in Proceedings of the 2015 ACM International Joint
Conference on Pervasive and Ubiquitous Computing. New York, NY,
USA: Association for Computing Machinery, 2015, pp. 505–516.
[179] P. J. Polack Jr, S.-T. Chen, M. Kahng, K. D. Barbaro, R. Basole,
M. Sharmin, and D. H. Chau, “Chronodes: Interactive Multifocus
Exploration of Event Sequences,” ACM Transactions on Interactive
Intelligent Systems (TiiS), vol. 8, no. 1, pp. 1–21, 2018.

[180] F. Birnbaum, D. M. Lewis, R. Rosen, and M. L. Ranney, “Patient
Engagement and the Design of Digital Health,” Academic emergency
medicine: ofﬁcial
the Society for Academic Emergency
Medicine, vol. 22, no. 6, p. 754, 2015.

journal of

[181] K. Skivington, L. Matthews, S. A. Simpson, P. Craig, J. Baird, J. M.
Blazeby, K. A. Boyd, N. Craig, D. P. French, E. McIntosh et al.,
“Framework for the Development and Evaluation of Complex Interven-
tions: Gap Analysis, Workshop and Consultation-Informed Update.”
Health Technol Assess, vol. 25, no. 57, pp. 1–132, 2021.

[182] S. Michie, M. Richardson, M. Johnston, C. Abraham, J. Francis,
W. Hardeman, M. P. Eccles, J. Cane, and C. E. Wood, “The behavior
change technique taxonomy (v1) of 93 hierarchically clustered tech-
niques: building an international consensus for the reporting of behavior
change interventions,” Annals of behavioral medicine, vol. 46, no. 1,
pp. 81–95, 2013.

[183] D. E. Conroy, C.-H. Yang, and J. P. Maher, “Behavior Change Tech-
niques in Top-Ranked Mobile Apps for Physical Activity,” American
journal of preventive medicine, vol. 46, no. 6, pp. 649–652, 2014.

[184] D. Chen, Z. Ding, C. Yan, and M. Wang, “A Behavioral Authentication
Method for Mobile Based on Browsing Behaviors,” IEEE/CAA Journal
of Automatica Sinica, vol. 7, no. 6, pp. 1528–1541, 2019.

[185] R. Orji, R. L. Mandryk, and J. Vassileva, “Towards a Data-Driven
Approach to Intervention Design: A Predictive Path Model of Healthy
Eating Determinants,” in Proceedings of the 7th International Confer-
ence on Persuasive Technology: Design for Health and Safety. Berlin,
Heidelberg: Springer Berlin Heidelberg, 2012, pp. 203–214.

[186] N. Alkıs¸ and T. T. Temizel, “The Impact of Individual Differences on
Inﬂuence Strategies,” Personality and Individual Differences, vol. 87,
pp. 147–152, 2015.

[187] M. Kaptein, P. Markopoulos, B. De Ruyter, and E. Aarts, “Person-
alizing Persuasive Technologies: Explicit and Implicit Personalization
Using Persuasion Proﬁles,” International Journal of Human-Computer
Studies, vol. 77, pp. 38–51, 2015.

[188] W. Yue, Z. Wang, J. Zhang, and X. Liu, “An Overview of Recommen-
dation Techniques and Their Applications in Healthcare,” IEEE/CAA
Journal of Automatica Sinica, vol. 8, no. 4, pp. 701–717, 2021.
[189] S. E. Boslaugh, M. W. Kreuter, R. A. Nicholson, and K. Naleid,
“Comparing Demographic, Health Status and Psychosocial Strategies
of Audience Segmentation to Promote Physical Activity,” Health
Education Research, vol. 20, no. 4, pp. 430–438, 2005.

[190] N. Askham, D. Cook, M. Doyle, H. Fereday, M. Gibson, U. Landbeck,
R. Lee, C. Maynard, G. Palmer, and J. Schwarzenbach, “The Six Pri-
mary Dimensions for Data Quality Assessment,” DAMA UK Working
Group, pp. 432–435, 2013.

[191] M. M. Breunig, H.-P. Kriegel, R. T. Ng, and J. Sander, “LOF:
Identifying Density-Based Local Outliers,” in Proceedings of the 2000
ACM SIGMOD international conference on Management of data. New
York, NY, USA: Association for Computing Machinery, 2000, pp. 93–
104.

[192] P. Malhotra, L. Vig, G. Shroff, P. Agarwal et al., “Long Short Term
Memory Networks for Anomaly Detection in Time Series,” in 23rd
European Symposium on Artiﬁcial Neural Networks (ESANN 2015),
2015, pp. 89–94.

[193] A. Mehrotra, R. Hendley, and M. Musolesi, “NotifyMeHere: Intelligent
Notiﬁcation Delivery in Multi-Device Environments,” in Proceedings of
the 2019 Conference on Human Information Interaction and Retrieval.
New York, NY, USA: Association for Computing Machinery, 2019, pp.
103–111.

[194] D. Weber, A. Voit, P. Kratzer, and N. Henze, “In-situ Investigation
of Notiﬁcations in Multi-device Environments,” in Proceedings of the
2016 ACM International Joint Conference on Pervasive and Ubiquitous
Computing.
New York, NY, USA: Association for Computing
Machinery, 2016, pp. 1259–1264.

[195] J. L. Hill, “Bayesian Nonparametric Modeling for Causal Inference,”
Journal of Computational and Graphical Statistics, vol. 20, no. 1, pp.
217–240, 2011.

[196] U. Shalit, F. D. Johansson, and D. Sontag, “Estimating Individual Treat-
ment Effect: Generalization Bounds and Algorithms,” in International
Conference on Machine Learning. PMLR, 2017, pp. 3076–3085.

[197] A. M. Alaa, M. Weisz, and M. van der Schaar, “Deep Counterfactual
Networks with Propensity-Dropout,” Proceedings of the 34th Interna-
tional Conference on Machine Learning, pp. 1–5, 2017.

[198] S. Wager and S. Athey, “Estimation and Inference of Heterogeneous
Treatment Effects Using Random Forests,” Journal of the American
Statistical Association, vol. 113, no. 523, pp. 1228–1242, 2018.
[199] J. Yoon, J. Jordon, and M. van der Schaar, “GANITE: Estimation of
Individualized Treatment Effects using Generative Adversarial Nets,”
in International Conference on Learning Representations, 2018, pp.
1–22.

[200] C. Shi, D. Blei, and V. Veitch, “Adapting Neural Networks for the
information

Estimation of Treatment Effects,” Advances in neural
processing systems, vol. 32, pp. 1–11, 2019.

[201] B. Lim, A. Alaa, and M. Van Der Schaar, “Forecasting Treatment
Responses Over Time Using Recurrent Marginal Structural Networks,”
in Proceedings of the 32nd International Conference on Neural Infor-
mation Processing Systems. Red Hook, NY, USA: Curran Associates
Inc., 2018, p. 7494–7504.

[202] I. Bica, A. M. Alaa, J. Jordon, and M. van der Schaar, “Estimating
Counterfactual Treatment Outcomes over Time Through Adversarially
Balanced Representations,” International Conference on Learning Rep-
resentations, pp. 1–28, 2020.

[203] R. Liu, C. Yin, and P. Zhang, “Estimating Individual Treatment
Effects with Time-Varying Confounders,” in 2020 IEEE International
Conference on Data Mining (ICDM). Los Alamitos, CA, USA: IEEE
Computer Society, 2020, pp. 382–391.

[204] D. Brodbeck, R. Gasser, M. Degen, S. Reichlin, and J. Luthiger,
“Enabling Large-Scale Telemedical Disease Management through In-
teractive Visualization,” European Notes in Medical Informatics, vol. 1,
no. 1, pp. 1172–1177, 2005.

[205] A. Perer and D. Gotz, “Data-Driven Exploration of Care Plans for Pa-
tients,” in CHI’13 Extended Abstracts on Human Factors in Computing
Systems. New York, NY, USA: Association for Computing Machinery,
2013, pp. 439–444.

[206] D. A. Rohani, M. Faurholt-Jepsen, L. V. Kessing, and J. E. Bardram,
“Correlations Between Objective Behavioral Features Collected From
Mobile and Wearable Devices and Depressive Mood Symptoms in

24

IEEE/CAA JOURNAL OF AUTOMATICA SINICA, VOL. X, NO. X, X X

Patients With Affective Disorders: Systematic Review,” JMIR mHealth
and uHealth, vol. 6, no. 8, p. e9691, 2018.

[207] D. Pach, A. A. Rogge, J. Wang, and C. M. Witt, “Five Lessons Learned
From Randomized Controlled Trials on Mobile Health Interventions:
Consensus Procedure on Practical Recommendations for Sustainable
Research,” JMIR mHealth and uHealth, vol. 9, no. 2, p. e20630, 2021.
[208] S. E. Lord, A. N. Campbell, M. F. Brunette, L. Cubillos, S. M. Bartels,
W. C. Torrey, A. L. Olson, S. H. Chapman, J. A. Batsis, D. Polsky
et al., “Workshop on Implementation Science and Digital Therapeutics
for Behavioral Health,” JMIR Mental Health, vol. 8, no. 1, p. e17662,
2021.

[209] M. P. Gonz´alez, J. Lor´es, and A. Granollers, “Enhancing Usability
Testing through Datamining Techniques: A Novel Approach to Detect-
ing Usability Problem Patterns for a Context of Use,” Information and
software technology, vol. 50, no. 6, pp. 547–568, 2008.

[210] J. I. Gold, M. SooHoo, A. M. Laikin, A. S. Lane, and M. J. Klein,
“Effect of an Immersive Virtual Reality Intervention on Pain and
Anxiety Associated With Peripheral Intravenous Catheter Placement
in the Pediatric Setting: A Randomized Clinical Trial,” JAMA Network
Open, vol. 4, no. 8, pp. e2 122 569–e2 122 569, 2021.

[211] L. T. Car, D. A. Dhinagaran, B. M. Kyaw, T. Kowatsch, S. Joty,
Y.-L. Theng, and R. Atun, “Conversational Agents in Health Care:
Scoping Review and Conceptual Analysis,” Journal of medical Internet
research, vol. 22, no. 8, p. e17158, 2020.

[212] Z. Shen, A. Elibol, and N. Y. Chong, “Understanding Nonverbal
Communication Cues of Human Personality Traits in Human-Robot
Interaction,” IEEE/CAA Journal of Automatica Sinica, vol. 7, no. 6,
pp. 1465–1477, 2020.

[213] Z. Liu, M. Wu, W. Cao, L. Chen, J. Xu, R. Zhang, M. Zhou, and
J. Mao, “A Facial Expression Emotion Recognition Based Human-
Robot Interaction System,” IEEE/CAA Journal of Automatica Sinica,
vol. 4, no. 4, pp. 668–676, 2017.

[214] J. Rooksby, A. Morrison, and D. Murray-Rust, “Student perspectives
on digital phenotyping: The acceptability of using smartphone data
to assess mental health,” in Proceedings of the 2019 CHI Conference
on Human Factors in Computing Systems. New York, NY, USA:
Association for Computing Machinery, 2019, p. 1–14.

[215] H. Lee, S. Kang, and U. Lee, “Understanding privacy risks and
perceived beneﬁts in open dataset collection for mobile affective
computing,” Proceedings of the ACM on Interactive, Mobile, Wearable
and Ubiquitous Technologies, vol. 6, no. 2, pp. 1–26, 2022.

[216] J. Huh-Yoo, R. Kadri, and L. R. Buis, “Pervasive healthcare irbs
and ethics reviews in research: Going beyond the paperwork,” IEEE
Pervasive Computing, vol. 20, no. 1, pp. 40–44, 2021.

[217] R. Chen, F. Jankovic, N. Marinsek, L. Foschini, L. Kourtis, A. Sig-
norini, M. Pugh, J. Shen, R. Yaari, V. Maljkovic, M. Sunga, H. H. Song,
H. J. Jung, B. Tseng, and A. Trister, “Developing measures of cognitive
impairment in the real world from consumer-grade multimodal sensor
streams,” in Proceedings of
the 25th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining. New York, NY,
USA: Association for Computing Machinery, 2019, p. 2145–2155.

[218] A. Alorwu, S. Kheirinejad, N. van Berkel, M. Kinnula, D. Ferreira,
A. Visuri, and S. Hosio, “Assessing mydata scenarios: Ethics, concerns,
and the promise,” in Proceedings of the 2021 CHI Conference on
Human Factors in Computing Systems.
New York, NY, USA:
Association for Computing Machinery, 2021, pp. 1–11.

[219] L. F. Cranor, P. Guduru, and M. Arjula, “User interfaces for pri-
vacy agents,” ACM Trans. Comput.-Hum. Interact., vol. 13, no. 2, p.
135–178, 2006.

[220] H. Lee and U. Lee, “Dynamic consent for sensor-driven research,” in
2021 Thirteenth International Conference on Mobile Computing and
Ubiquitous Network (ICMU).

IEEE, 2021, pp. 1–6.

[221] F. Schaub, R. Balebako, A. L. Durity, and L. F. Cranor, “A design
space for effective privacy notices,” in Eleventh Symposium On Usable
Privacy and Security (SOUPS 2015). Ottawa: USENIX Association,
2015, pp. 1–17.

[222] Y. Feng, Y. Yao, and N. Sadeh, “A design space for privacy choices:
Towards meaningful privacy control in the internet of things,” in Pro-
ceedings of the 2021 CHI Conference on Human Factors in Computing
Systems. New York, NY, USA: Association for Computing Machinery,
2021, pp. 1–16.

