READLE: A FORMAL FRAMEWORK FOR DESIGNING AI-BASED
EDGE SYSTEMS

2
2
0
2

y
a
M
8
1

]
E
S
.
s
c
[

1
v
9
3
2
9
0
.
5
0
2
2
:
v
i
X
r
a

Aftab Hussain
University of Houston
Houston, Texas, USA
ahussain27@uh.edu

ABSTRACT

With the wide spread use of AI-driven systems in the edge (a.k.a edge intelligence systems), such as
autonomous driving vehicles, wearable biotech devices, intelligent manufacturing, etc., such systems
are becoming very critical for our day-to-day lives. A challenge in designing edge intelligence
systems is that we have to deal with a large number of constraints in two design spaces that form the
basis of such systems: the edge design space and the deep learning design space. Thus in this work,
a new systematic, extendable, manual approach, READLE, is proposed for creating representations of
speciﬁcations in edge intelligent systems, capturing constraints in the edge system design space (e.g.
timing constraints and other performance constraints) and constraints in the deep learning space (e.g.
model training duration, required level of accuracy) in a coherent fashion. In particular, READLE
leverages beneﬁts of real-time logic and binary decision diagrams to generate uniﬁed speciﬁcations.
Several insights learned in building READLE are also discussed, which should help in future research
in the domain of formal speciﬁcations for edge intelligent systems.

Keywords real-time logic · system design · deep neural networks

1

Introduction

With the rapid advances in AI towards making fast and accurate predictions, we are today witnessing the adoption of AI
in a wide range of application domains, such as autonomous driving systems, unmanned aerial vehicles (UAVs), voice
assistants in mobile phones, and even software code development [1, 2, 3, 4]. The key reason behind the growth of AI is
the increasingly growing capabilities of deep learning (DL) systems, also referred to as deep neural networks (DNNs).
Today, advances in storage size and computation power of computing systems has made it possible to train very large
DNNs (containing in the order of billions of neurons), which could thereby be used to make accurate inferences (or
predictions) in a wide range of domains.

An important application domain where deep learning is rapidly being adopted is edge systems [5]. Edge systems
comprise of computing systems being put close to data generators, e.g. sensors, in order to enable rapid processing of
data locally. In contrast, client-server based systems store the majority of the data in servers, which require transmission
of data between the client and servers – hence creating a delay in getting an output from the computation of an
input data. While these delays may still be in the order of seconds, in many mission-critical scenarios, for example
autonomous driving or automated industrial assembly, such delays may be costly leading to catastrophic consequences.
Edge systems thereby reduce this transmission overhead by providing a temporary data storage (via caches) and a
computation platform close to the data producers [3]. Consequently, edge systems have been adopted in a wide spectrum
of application areas including, virtual reality, 3D printers, self-driving cars, robots, intelligent manufacturing, etc.

The quest for further improving edge systems have led practitioners to bring AI to the edge, leading to the development
of edge intelligence systems. However, building such systems has been challenging. Deep learning algorithms used
in DNNs are highly compute-intensive, whereas edge systems are constrained by compute resources. Furthermore,
depending on the application context, edge systems have speciﬁc functional constraints, e.g. timing constraints and

 
 
 
 
 
 
READLE: A Formal Framework for Designing AI-based Edge Systems

security requirements. (We look in further detail into the operation of DNNs and the constraints of edge systems in
Sections 2.4 and 2.3, respectively).

While many approaches have been proposed to bridge the computation gap between DNNs and edge systems, some of
which we explore in Section 5, choosing the right approach for a given edge system can be a challenging task. As we
explain in Section 3.3, DNNs can have a wide range of conﬁgurations and settings under which they are trained, and
thus ﬁnding the right ﬁt for a given edge system is difﬁcult. Moreover, different edge systems come with their own
share of multifarious constraints and requirements, adding further complexity to the problem of ﬁnding the right DNN
for a given edge system.

We thus focus on the following research problem: How can we clearly reason about our design decisions in
developing an edge intelligence system? The complexity of choices and restrictions in the two design paradigms of an
edge intelligence system (the edge design space and the DNN design space) calls for a need to systematically map the
edge intelligence system design process in some form of a common medium. In addition, it has often been seen that
when disciplines operate independently of each other towards designing any system, major deﬁciencies may arise [6].

To address this, we thus develop a novel formal systematic framework, READLE, geared towards representing speciﬁca-
tions of edge intelligence systems. READLE is based on Real-time Logic (RTL) [7] and Binary Decision Diagrams
(BDDs) [8, 9], reaping beneﬁts from both representation systems. RTL is useful for creating speciﬁcations of event-
action models (models that capture data dependency and temporal ordering of computational actions that should be
taken when certain events occur within a real-time system [10]). The main beneﬁt of RTL representations is that they
can be mechanically manipulated, and thus are amenable for automated processing and veriﬁcation [10]. Furthermore,
they are also easily readable and widely accepted by system design practitioners. On the other hand, BDDs offer
compactness – they are concise graphical representations of Boolean logic formulas [10]. While formal methods have
been previously used for verifying DL systems, e.g. [11, 12], in this work, we focus on how to build a clear design
pathway for building DL systems in the edge (edge intelligece systems.)

The main motivation behind proposing READLE was to provide a coherent, uniﬁed representation of the design
speciﬁcations in designing edge intelligence systems. Given the different characteristics of the two underlying design
spaces of edge intelligence systems, where the edge space is more event-driven than the DNN design space, building
READLE required appropriately mapping features of DNNs into an event-based context. This allowed the use of RTL to
represent constraints in both the design spaces, and thus create uniﬁed representations of the entire edge intelligence
system.

Contributions. Overall we make the following contributions in this paper:

• We present a new systematic, extendable framework, READLE, for creating for representations of speciﬁcations

in edge intelligence systems.

• READLE represents constraints in the edge system design space (e.g. timing constraints and other performance
constraints) and constraints in the deep neural network space (e.g. training duration, required level of accuracy)
in a coherent fashion.

• We present several insights in building READLE that should help in future development of formal representa-
tions of speciﬁcations in the space of edge intelligence systems and even other AI-equipped systems bounded
by real-time systems and DNN constraints.

Paper Organization. The rest this paper is organized as follows: In Section 2, we discuss the preliminary ideas behind
READLE, in particular RTL, BDDs, edge intelligence systems, and deep learning systems. In Section 3, we describe the
READLE approach, and subsequently, in Section 4, provide a discussion about READLE and possible future directions.
In Section 5, we outline some works in DNN optimization for edge systems, where READLE may be applied, and also
present works that have used formal methods for verifying DL systems. We conclude the paper in Section 6.

2 Preliminaries

In this section, we describe the notations of the two building blocks of READLE: RTL (Subsection 2.1) and BDDs
(Subsection 2.2). In addition, we present some relevant background knowledge on edge systems (Subsection 2.3) and
deep neural networks (Subsection 2.4).

2

READLE: A Formal Framework for Designing AI-based Edge Systems

Figure 1: BDD of the formula: (p ∧ q) ∨ (r ∧ s).

2.1 Real-Time Logic (RTL)

RTL follows the notations of ﬁrst order logic, with additional features that capture event based timing constraints of an
event-action model [10]. This makes them very appropriate for modelling most edge systems, for example autonomous
driving systems. The notations are described below, following the deﬁnitions in [10]:

• @(...) - an occurrence function that assigns time values to event occurrences.

For example,
@(F orkApproach, i) = x, means the ith instance of the event F orkApproach (a driver-less car approaches
a fork while commuting on a freeway) in an autonomous driving system, occurs at time x.

• @(↑ ...) - If an ↑ precedes the event name, the event represents the beginning of an action, e.g. @(↑

ReduceSpeed)

• @(↓ ...) - If a ↓ precedes the event name, the event represents the end of an action.

2.2 Binary Decision Diagrams (BDDs)

BDDs are an improved way of representing Boolean logic formulas, over former representations like truth tables,
Karnaugh maps, and canonical sum-of-products, which can contain an exponential number of redundant entries [10].
BDDs remove the redundancy by representing a Boolean logic formula in a binary decision tree, where:

• the non-leaf nodes correspond to variables in the Boolean logic formula,
• each non-leaf node has two outgoing edges labeled with 0 or 1 (which correspond to the truth value of the

variable), and

• there are two leaf nodes labelled with 0 or 1, that correspond to the truth value of the entire formula.

Figure 1, shows an example of a BDD for a simple Boolean formula. Starting from the root variable node, we can
incrementally deduce the value of the formula by following either of the two outgoing edges (that correspond to a 0 or 1
input value) of each variable node that we encounter, until we reach a leaf node (shown in gray in Figure 1).

2.3 Edge Systems

The edge (or an edge system) refers to a distributed computing paradigm that brings data computation and storage
closer to the sources of data, which obviates the need of transferring data to perform computations on them, and thus
improves response times [13]. An insightful example of an edge system is an autonomous vehicle, which consists of
hundreds of sensors collecting data for collision detection. In such systems, time is of the essence in making decisions,
and thus all data processing happens locally within the autonomous driving system, rather in a cloud server (which
would entail costly delays).

Edge systems can have a wide range of performance requirements such as low latency and security. Some performance
requirements arise from limitations in available resources of edge systems, for example the need to be energy efﬁcient
due to limited availability of battery power. We show how these requirements can be captured in Section 3.

2.4 Deep Neural Networks (DNNs)

In a nutshell, a DNN model takes in set of input values, e.g. pixel values of an image, and makes an inference or
prediction, for e.g. whether an image consists of a given stop sign or not. Before a DNN can make inferences on unseen

3

prq0s100111010READLE: A Formal Framework for Designing AI-based Edge Systems

Figure 2: A simple neural network [14].

data, it goes through a training phase, where it learns from existing datasets about patterns in the dataset. The training
phase yields a pretrained version of the model. Typically, this phase is carried out in a local support system, outside the
edge system – only the trained model is loaded into the edge system to perform inferences. This is because training can
be costly, where a model is trained with very a large dataset over several iterations (or training steps), each of which can
take up to several hours.

In order to understand the different ways in which a DNN can be conﬁgured (as elaborated upon in Section 3.3), let us
take a look at some of the internal components of a DNN.

A DNN consists of layers of neurons (mathematical functions), interconnected with each other via weighted edges.
The values in these weighted edges are learned during the training phase. Each neuron performs speciﬁc operations
on the input values it receives. Figure 2 shows a simple neural network, consisting of an input layer, a hidden layer,
and an output layer. DNNs extend the design of a simple neural network by adding more layers, and more neurons in
each layer (in the order of billions), and hence can get computationally very expensive (by requiring a high order of
ﬂoating point operations). The manner in which the layers of neurons are connected with each other and perform these
computations is what distinguishes one DNN from the other. For example, computer vision AI applications, which
have been widely used in edge systems [3], use Convolutional Neural Networks (CNNs). CNNs apply a mathematical
operation called convolution in some of its layers [15].

3 The READLE Approach

In this section, we ﬁrst present the workﬂow of the proposed approach, READLE, Then we identify features of the
edge design space and the DNN design space, explaining how the design features can be captured using READLE
(Subsections 3.2, 3.3).

3.1 Overall Methodology

Figure 3, shows the overall workﬂow of READLE. The ﬁrst step involves identifying available resources in the two
design spaces, for example, storage memory, battery lifetime, etc. Next, depending on these resources we specify
the requirements, in English, for each design space. Since the DNN model resides in the edge system, some of
the requirements and resources in the edge space also affects the requirements in the DNN design space. Once all
requirements are speciﬁed in both spaces, RTL speciﬁcations are generated, and then ﬁnally combined by conjunction
(AND operator), from which a BDD is constructed in the manner explained in Section 2.2. The key attribute of READLE
lies in the fact that allows systematically connecting related requirements in two design spaces, and obtain a uniﬁed
representation of the speciﬁcation deduced from two design spaces. We next go into further details into how the
requirements in the two spaces are captured, in the subsequent subsections.

3.2 Capturing Requirements in the Edge Design Space

As we can see from Figure 3, there are two types of requirements in the edge design space: functional and performance
requirements.

4

READLE: A Formal Framework for Designing AI-based Edge Systems

Figure 3: The READLE Methodology

• Functional requirements (FRs) specify what the system should do given an event, e.g., if an autonomous
vehicle comes close to a red trafﬁc light, it should stop – In READLE, this speciﬁcation can be stated as follows
∀x@(RedLightApproach, x) <= @(↑ BraketoStop, x).

• Performance requirements (PRs) are those that follow temporal or energy consumption constraints, e.g. how
fast should an autonomous vehicle react when witnessing a stop light, or how an autonomous car can control
its acceleration without consuming power greater than a given threshold? A sample performance requirement
is that a car battery needs at least P Watts of power to come to a safe stop – In READLE, this speciﬁcation can
be stated as f orallx@(P owerBelow : P + threshold, x) <= @(↑ T riggerU nsaf etoDriveW arning, x).
Notice how in READLE we modiﬁed the use of RTL to incorporate non-temporal constraints.

As shown in Figure 3, the resources available governs the performance requirements of a system. Consequently,
performance requirements (e.g. required accuracy of predictions, maximum allowable down times) and resources also
affects the operation requirements of the pretrained DNN model, which resides in the edge system, which we observe
next.

3.3 Capturing Requirements in the DNN Design Space

Requirements in the DNN design space arise from a number of decisions related to training settings and model
parameters that need to be considered while deploying DNNs in a given edge system, such as an autonomous vehicle.
These decisions are governed primarily by two application-context dependent factors – (1) the availability of resources
(e.g. storage memory, processor capacity, battery power), and the (2) the performance requirements from the edge
space. We present some of those training settings and parameters below that can be speciﬁed by the READLE approach:

• Training duration. The length of training (number of training steps) determines to a large extent the quality
of the predictions of a model, the longer the training, the better the performance. As previously mentioned,
training is supported by a system outside the edge system, due to the long duration training can take, and
is typically performed when the edge system is down. Thus while setting the training duration, it is less
than the maximum allowable downtime of the edge system. In READLE, we can state this requirement as
follows: f orallx@(↓ T rainM odel, x) − (↑ T rainM odel, x) <= f orallx@(↓ SystemDown, x) − @(↑
SystemDown, x) + M odelLoadT ime. Edge systems can also stipulate a certain level of accuracy that a
trained model must meet in making predictions.

5

DNNEdgeSystem (ES)DNN Local Support System(Outside ES)Edge Performance RequirementsEdge Functional RequirementsResourcesDNN Operation RequirementsResourcesEdge Design SpaceDNN Design Space3. Get  Edge Requirements1. Identify  available Resources2. Identify available Resources4. Get DNN Requirements based on Edge Requirements and available resources5. Generate RTL constraints for each group of requirementsRTL1RTL2RTL36. Combine RTL constraints  using Conjunction Operator and form a single BDD.BDDREADLE: A Formal Framework for Designing AI-based Edge Systems

• Training batch size. Bigger training batch sizes, allow for more training data to be processed through a model
during training during each iteration, and hence increases the training speed. However, this batch size is
restricted by the amount of memory size available in the system that hosts the training process.

• Size of the Model. This parameter refers to the total number of neurons in the model, which can be controlled
by specifying the number of nodes in each layer of the model. The amount of available storage in the edge is
the main constraint that governs how big a pretrained model can be.

4 Discussion and Future Directions

Composability of READLE. The ﬁrst step in the READLE approach of identifying resources can be wide ranging, given
the vast number of functions an edge system (for example an autonomous driving system) can perform. To tackle this
scenario the edge system design can be divided into separate spaces based on the function it performs, and then READLE
can be applied to each subdivision. Since READLE allows compositional construction of constraints, speciﬁcations for
all the subdivisions can be combined under a single BDD using READLE.

Codifying noise and attacks on DNNs into speciﬁcations. Deep neural networks can also exhibit interesting behaviour
when faced with noisy training data (in which case it can memorize the data [16, 17]), or even malicious behaviour
when faced with adversarial examples. For example, it has been found that a DNN can mis-classify stop-signs when a
yellow Post-it note attached to them as speed-limit signs [18]. Such scenarios can clearly affect the outcome of DNNs
in edge systems, and thus we need to explore how checks against such scenarios can be represented in the design
speciﬁcations of edge intelligence systems.

User studies to assess cognitive burden. For a more comprehensive analysis of how well READLE achieves its goal of
providing coherent, uniﬁed representations of edge intelligence system design speciﬁcations in designing, there is a
need for systematic user studies of applying READLE on designing edge intelligence systems in the real-world, with a
focus on measuring the cognitive burden of the designers.

5 Related Works

DNN optimizations for the edge that READLE can potentially capture. Arising from the limited resources of edge
systems, and the huge computation costs of DL systems, there have been several optimizations made to using deep
learning systems, so that they may be feasibly deployed in the edge. These optimizations entail modiﬁcations in the
DNN which may also be codiﬁed in the READLE framework. Examples of such optimizations include network pruning
approaches e.g. [19, 20], which remove irrelevant weights in DNN models that have too many redundant neurons. Other
techniques have deployed adaptive NNs, e.g. [21, 22], which skip some layers of the NN to perform computations, for
easy inputs. For example BranchyNet [22] uses early-exit to skip layers of the NN for easy input images. Quantization
techniques address the large memory requirements of large DNNs by encoding the model weights with lower precision,
without signiﬁcantly compromising the accuracy of the model, (e.g. by converting weights and activations from a 32-bit
ﬂoating point representation level to a 16-bit ﬂoating point representation level) [23, 24]. For interested readers, an
elaborate survey on DNN optimization techniques for the edge is provided in [3, 25].

Use of Formal methods for veriﬁcation of DL systems. Gehr et al. [26] present AI2, a scalable analyzer based on
abstract interpretation framework [27] for deep neural networks, which can automatically prove safety properties
(e.g., robustness) of DNNs like convolutional neural networks (CNNs). They deﬁne abstract transformers that capture
the behavior of common neural network layers (e.g. max pooling and convolutional layers in a CNN). Scheibler et
al. [28] use bounded model checking technique for verifying NNs. Huang et al. [29] showed a SMT solver based
veriﬁcation framework for feed forward multilayer NNs. Guy et al. [30] extend the simplex algorithm for solving linear
programming instances in order to verify ReLU (Rectiﬁed Linear Unit) activation function constraints in NNs.

6 Conclusion

This work presents READLE, a new approach for creating representations of speciﬁcations in edge intelligence systems,
capturing constraints in the edge system design space (e.g. timing constraints and other performance constraints) and
constraints in the deep learning space (e.g. model training duration, required level of accuracy) in a coherent fashion.
READLE leverages beneﬁts of real-time logic and binary decision diagrams to generate uniﬁed speciﬁcations. READLE
is extendable, and may be used to represent multifarious settings (at different levels of abstraction) of building and
using DNNs in edge systems. This work thus serves as an idea/perspective paper, which should help in future research
towards the development of coherent design approaches for building edge intelligence systems.

6

READLE: A Formal Framework for Designing AI-based Edge Systems

Acknowledgments

This work is part of a project done for the Fall 2022 Real-time Systems Course at the University of Houston under
the supervision of Professor Albert Cheng, who provided useful feedback for this work and also provided beneﬁcial
guidance towards understanding the core foundations of this work, and the motivations behind them.

References

[1] Uri Alon, Omer Levy, and Eran Yahav. code2seq: Generating sequences from structured representations of code.

In International Conference on Learning Representations, 2019.

[2] Uri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. Code2vec: Learning distributed representations of

code. Proc. ACM Program. Lang., 3(POPL):40:1–40:29, January 2019.

[3] Di Liu, Hao Kong, Xiangzhong Luo, Weichen Liu, and Ravi Subramaniam. Bringing AI to edge: From deep

learning’s perspective. Neurocomputing, 485:297–320, 2022.

[4] Lucas Prado Osco, José Marcato Junior, Ana Paula Marques Ramos, Lúcio André de Castro Jorge, Sarah Narges
Fatholahi, Jonathan de Andrade Silva, Edson Takashi Matsubara, Hemerson Pistori, Wesley Nunes Gonçalves,
and Jonathan Li. A review on deep learning in uav remote sensing. International Journal of Applied Earth
Observation and Geoinformation, 102:102456, 2021.

[5] Eric Hamilton. Ieee computer society’s top 12 technology trends for 2020, December 2019.
[6] Don Norman. The Design of Everyday Things. Basic Books, New York, NY, revised edition, 2013.
[7] Farnam Jahanian and Aloysius Ka-Lau Mok. Safety analysis of timing properties in real-time systems. IEEE

Transactions on Software Engineering, SE-12(9):890–904, 1986.

[8] Choong Y. Lee. Representation of switching circuits by binary-decision programs. Bell System Technical Journal,

38:985–999, 1959.

[9] Sheldon B. Akers. Binary decision diagrams. IEEE Transactions on Computers, C-27:509–516, 1978.
[10] Albert M. K. Cheng. Real-time systems: Scheduling, analysis, and veriﬁcation. Wiley-Interscience, Hoboken, NJ,

2nd. edition, 2002.

[11] Yedi Zhang, Zhe Zhao, Guangke Chen, Fu Song, and Taolue Chen. Bdd4bnn: A bdd-based quantitative analysis

framework for binarized neural networks, 2021.

[12] Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat Chaudhuri, and Martin Vechev.
Ai2: Safety and robustness certiﬁcation of neural networks with abstract interpretation. In 2018 IEEE Symposium
on Security and Privacy (SP), pages 3–18, 2018.

[13] Eric Hamilton. What is edge computing: The network edge explained, December 2018.
[14] Wikipedia. Neural network, May 2022.
[15] I. Goodfellow, Y. Bengio, and A. Courville. Deep Learning. Adaptive computation and machine learning. MIT

Press, 2016.

[16] Md Raﬁqul Islam Rabin, Aftab Hussain, Vincent J. Hellendoorn, and Mohammad Amin Alipour. Memorization

and generalization in neural code intelligence models, 2021.

[17] Devansh Arpit, Stanisław Jastrz˛ebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S. Kanwal,
Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, and Simon Lacoste-Julien. A closer look at
memorization in deep networks. arXiv preprint arXiv:1706.05394v2, 2017.

[18] Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. Badnets: Identifying vulnerabilities in the machine

learning model supply chain, 2017.

[19] Yann LeCun, John Denker, and Sara Solla. Optimal brain damage. In D. Touretzky, editor, Advances in Neural

Information Processing Systems, volume 2. Morgan-Kaufmann, 1989.

[20] B. Hassibi, D.G. Stork, and G.J. Wolff. Optimal brain surgeon and general network pruning. In IEEE International

Conference on Neural Networks, pages 293–299 vol.1, 1993.

[21] Tolga Bolukbasi, Joseph Wang, Ofer Dekel, and Venkatesh Saligrama. Adaptive neural networks for fast test-time

prediction. CoRR, abs/1702.07811, 2017.

[22] Surat Teerapittayanon, Bradley McDanel, and H. T. Kung. Branchynet: Fast inference via early exiting from deep

neural networks. CoRR, abs/1709.01686, 2017.

7

READLE: A Formal Framework for Designing AI-based Edge Systems

[23] Jiaxiang Wu, Cong Leng, Yuhang Wang, Qinghao Hu, and Jian Cheng. Quantized convolutional neural networks

for mobile devices, 2015.

[24] Jiaxiang Wu, Cong Leng, Yuhang Wang, Qinghao Hu, and Jian Cheng. Quantized convolutional neural networks

for mobile devices, 2015.

[25] Dianlei Xu, Tong Li, Yong Li, Xiang Su, Sasu Tarkoma, Tao Jiang, Jon Crowcroft, and Pan Hui. Edge intelligence:

Empowering intelligence to the edge of network. Proceedings of the IEEE, 109(11):1778–1837, 2021.

[26] Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat Chaudhuri, and Martin Vechev.
Ai2: Safety and robustness certiﬁcation of neural networks with abstract interpretation. In 2018 IEEE Symposium
on Security and Privacy (SP), pages 3–18, 2018.

[27] Patrick Cousot and Radhia Cousot. Abstract Interpretation Frameworks. Journal of Logic and Computation,

2(4):511–547, 08 1992.

[28] Karsten Scheibler, Leonore Winterer, Ralf Wimmer, and Bernd Becker. Towards veriﬁcation of artiﬁcial neural

networks. In MBMV, pages 30–40. Sächsische Landesbibliothek, 2015.

[29] Xiaowei Huang, Marta Kwiatkowska, Sen Wang, and Min Wu. Safety veriﬁcation of deep neural networks, 2016.
[30] Guy Katz, Clark Barrett, David Dill, Kyle Julian, and Mykel Kochenderfer. Reluplex: An efﬁcient smt solver for

verifying deep neural networks, 2017.

8

